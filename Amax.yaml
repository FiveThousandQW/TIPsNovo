# ===================== ① 最常改（每次跑基本都会确认/调整） =====================
run_name: NewTrainCode_Proteometools300w   # 本次实验名；同时影响日志与中间分片目录（见下）
#train_path: /data/48/wuqian/Proteometools/SystemMHC/dataSet/SysteMHC_PTM_filtered_class2_val_Spect.parquet
#valid_path: /data/48/wuqian/Proteometools/SystemMHC/dataSet/SysteMHC_PTM_filtered_class1_val_Spect.parquet # 不再支持分组验证
train_path: /data/48/wuqian/Proteometools/allPart/spectrum/part123_clear.parquet
valid_path: /data/48/wuqian/Proteometools/SystemMHC/dataSet/SysteMHC_PTM_filtered_classI_II_val_Spect.parquet

train_subset: 1                                   # 训练采样比例；正式训练设为 1.0
valid_subset: 1                                     # 验证采样比例；调参可小一点加快


epochs: 30
learning_rate: 1e-4
train_batch_size: 196                               # 训练 batch；显存不够可配合 grad_accumulation
grad_accumulation: 1                                # 有效 batch = train_batch_size * grad_accumulation
predict_batch_size: 128                             # 验证/推理 batch；受显存影响较大
n_peaks: 200                                        # 选取前 k 个峰；与显存/速度和精度权衡
max_length: 40                                      # 最大肽段长度；compile_model=True 时也用于固定 padding
n_beams: 1                                          # 解码 beam size；大一些更准但更慢

# ===================== ② 训练过程与资源（较常改） =====================
device: auto
fp16: true                                          # GPU 上建议开；CPU 会被自动关掉
use_flash_attention: true                           # 需兼容的 PyTorch/CUDA，显著省显存提速
compile_model: true                                 # 需固定长度输入（已在数据集侧自动 pad/截断）
num_workers: 2                                      # 训练 DataLoader worker 数
prefetch_factor: 2                                  # 每个 worker 预取批数
eval_prefetch_factor: 1

# ===================== ③ 日志/监控（偶尔改） =====================
console_logging_steps: 50
tensorboard_logging_steps: 500
num_sanity_val_steps: 0
profiler: false
tb_summarywriter: "/data/48/wuqian/fast/TipsNovo/log"  # 本地 TB 根目录

# ===================== ④ 优化与训练稳定性（偶尔改） =====================
warmup_iters: 480
weight_decay: 1e-5
gradient_clip_val: 10.0

# ===================== ⑤ 模型结构（相对固定，换模型时才改） =====================
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
conv_peak_encoder: false                             # 若开，会用直方图输入（与 n_peaks 配置不同）

# ===================== ⑥ 光谱与前体筛选（数据侧策略，偶尔改） =====================
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50                               # ppm
isotope_error_range: [0, 1]
validate_precursor_mass: false                       # 大数据集会比较慢

# ===================== ⑦ 数据加载与分片（一般不改，但要明白作用） =====================
lazy_loading: false                                  # SDF 是否延迟加载
max_shard_size: 1_000_000                            # SDF 分片大小（影响落盘分片数量）
preshuffle_shards: false                             # 跨分片预打乱（lazy 模式下更有意义）
perform_data_checks: true                            # 残基合法性、前体等检查
verbose_loading: true                                # 加载期输出更详细日志
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/

# ===================== ⑧ Checkpoint（偶尔改） =====================
save_model: true
save_weights_only: false
ckpt_interval: 6000                                  # 以“训练步数”为单位（不是 epoch）
train_from_scratch: true
resume_checkpoint:

# ===================== ⑨ 残基表（除非换词表/修饰，基本不动） =====================
residues:
  "G": 57.021464
  "A": 71.037114
  "S": 87.032028
  "P": 97.052764
  "V": 99.068414
  "T": 101.047670
  "C": 103.009185
  "L": 113.084064
  "I": 113.084064
  "N": 114.042927
  "D": 115.026943
  "Q": 128.058578
  "K": 128.094963
  "E": 129.042593
  "M": 131.040485
  "H": 137.058912
  "F": 147.068414
  "R": 156.101111
  "Y": 163.063329
  "W": 186.079313
  "M[147]": 147.035400    # Oxidation (+15.995)
  # 其余可按需开启：
  # "P[113]": 113.047679
  # "W[202]": 202.074228
  # "E[111]": 111.032028
  # "Q[111]": 111.032029
