[2025-08-10 10:30:39,489][__main__][INFO] - Initializing training.
[2025-08-10 10:30:39,489][__main__][INFO] - Python version: 3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:24:24) [GCC 13.3.0]
[2025-08-10 10:30:39,489][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-10 10:30:39,490][__main__][INFO] - CUDA version: 12.1
[2025-08-10 10:30:39,496][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/1461_high/*.parquet
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 128
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: instanovo_300raw_high
train_subset: 1.0
valid_subset: 0.02
val_check_interval: 1.0
lazy_loading: true
max_shard_size: 1000000
preshuffle_shards: true
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-10 10:30:39,502][__main__][INFO] - Starting transformer training
[2025-08-10 10:30:39,502][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-10 10:30:39,502][__main__][INFO] - Loading data
[2025-08-10 10:31:03,554][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-10 10:31:03,610][instanovo.utils.data_handler][INFO] - Pre-shuffling across 002 shards. This may take a while...
[2025-08-10 10:31:03,610][instanovo.utils.data_handler][INFO] - Computing new mapping per original shard
[2025-08-10 10:31:03,659][instanovo.utils.data_handler][INFO] - Extracting rows to create shuffled shards
[2025-08-10 10:31:48,345][instanovo.utils.data_handler][INFO] - Writing shuffled shard 000/002 to /tmp/tmpw7dh7_6i/temp_7c70aecaadb8481392f8abdb38b486f4.parquet [00:00:44/00:00:44, 44.686s/it]
[2025-08-10 10:33:35,623][instanovo.utils.data_handler][INFO] - Writing shuffled shard 001/002 to /tmp/tmpw7dh7_6i/temp_515ed449a97c484fb23c5fd45046b3b9.parquet [00:02:31/00:00:00, 75.982s/it]
[2025-08-10 10:33:35,624][instanovo.utils.data_handler][INFO] - Removing unshuffled shards
[2025-08-10 10:33:58,415][instanovo.utils.data_handler][INFO] - Pre-shuffle complete
[2025-08-10 10:34:21,699][__main__][INFO] - Validation path not specified, generating from training set.
[2025-08-10 10:36:56,688][__main__][INFO] - Data splits saved to /data/48/wuqian/fast/TipsNovo/model_save/splits.csv
[2025-08-10 10:36:56,689][__main__][INFO] - Checking for unknown residues in 1,262,032 rows.
[2025-08-10 10:37:01,421][__main__][WARNING] - Unsupported residues found in evaluation set! These rows will be dropped.
[2025-08-10 10:37:01,421][__main__][INFO] - New residues found: 
{'O'}
[2025-08-10 10:37:01,421][__main__][INFO] - Residues supported: 
{'Y[UNIMOD:21]', 'D', '[UNIMOD:385]', 'S', 'Y', '[UNIMOD:1]', 'L', 'C[UNIMOD:4]', 'K', '[PAD]', 'W', '[SOS]', 'T', 'Q', '[UNIMOD:5]', 'F', 'T[UNIMOD:21]', 'I', 'S[UNIMOD:21]', 'Q[UNIMOD:7]', 'M[UNIMOD:35]', 'E', 'M', 'P', 'C', 'A', 'N[UNIMOD:7]', 'V', 'G', 'R', 'H', 'N', '[EOS]'}
[2025-08-10 10:39:37,826][__main__][WARNING] - 1 (0.00%) training rows dropped.
[2025-08-10 10:39:37,826][__main__][WARNING] - 0 (0.00%) validation rows dropped.
[2025-08-10 10:42:27,914][__main__][INFO] - Data loaded: 945,150 training samples; 6,292 validation samples
[2025-08-10 10:42:28,301][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-10 10:42:28,319][__main__][INFO] - No data leakage!
[2025-08-10 10:42:28,319][__main__][INFO] - Model checkpointing every 0.27 epochs.
[2025-08-10 10:42:28,320][__main__][INFO] - Updates per epoch: 7,384, step_scale=0.25
[2025-08-10 10:42:47,877][__main__][INFO] - Sample batch:
[2025-08-10 10:42:47,878][__main__][INFO] -  - spectra.shape=torch.Size([128, 200, 2])
[2025-08-10 10:42:47,878][__main__][INFO] -  - precursors.shape=torch.Size([128, 3])
[2025-08-10 10:42:47,878][__main__][INFO] -  - spectra_mask.shape=torch.Size([128, 200])
[2025-08-10 10:42:47,878][__main__][INFO] -  - peptides.shape=torch.Size([128, 41])
[2025-08-10 10:42:47,878][__main__][INFO] -  - peptides_mask.shape=torch.Size([128, 41])
[2025-08-10 10:42:48,082][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-10 10:42:48,082][__main__][INFO] - Test forward pass:
[2025-08-10 10:42:56,133][__main__][INFO] -  - y.shape=torch.Size([128, 42, 33])
[2025-08-10 10:42:57,726][__main__][INFO] - Model saving enabled
[2025-08-10 10:42:57,727][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save
[2025-08-10 10:42:57,727][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-10 10:42:57,742][__main__][INFO] - InstaNovo training started.
[2025-08-10 10:55:26,331][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-10 10:56:07,157][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000012] [Batch 00012/03692] [00:00:06/00:32:45, 0.534s/it]: train_loss_raw=3.3393, running_loss=3.5884, LR=0.000002
[2025-08-10 10:56:13,699][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/03692] [00:00:12/00:32:59, 0.540s/it]: train_loss_raw=3.0705, running_loss=3.5395, LR=0.000005
[2025-08-10 10:56:20,310][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000036] [Batch 00036/03692] [00:00:19/00:33:06, 0.543s/it]: train_loss_raw=2.9695, running_loss=3.4790, LR=0.000007
[2025-08-10 10:56:26,896][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/03692] [00:00:26/00:33:05, 0.545s/it]: train_loss_raw=2.9607, running_loss=3.4202, LR=0.000010
[2025-08-10 10:56:33,495][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000060] [Batch 00060/03692] [00:00:32/00:33:02, 0.546s/it]: train_loss_raw=2.8631, running_loss=3.3625, LR=0.000012
[2025-08-10 10:56:40,049][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/03692] [00:00:39/00:32:56, 0.546s/it]: train_loss_raw=2.8064, running_loss=3.3012, LR=0.000015
[2025-08-10 10:56:46,557][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000084] [Batch 00084/03692] [00:00:45/00:32:47, 0.545s/it]: train_loss_raw=2.7872, running_loss=3.2413, LR=0.000017
[2025-08-10 10:56:53,009][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/03692] [00:00:52/00:32:37, 0.544s/it]: train_loss_raw=2.7266, running_loss=3.1850, LR=0.000020
[2025-08-10 10:56:59,568][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000108] [Batch 00108/03692] [00:00:58/00:32:32, 0.545s/it]: train_loss_raw=2.7483, running_loss=3.1335, LR=0.000022
[2025-08-10 10:57:06,083][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/03692] [00:01:05/00:32:24, 0.544s/it]: train_loss_raw=2.7481, running_loss=3.0871, LR=0.000025
[2025-08-10 10:57:12,511][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000132] [Batch 00132/03692] [00:01:11/00:32:15, 0.544s/it]: train_loss_raw=2.7023, running_loss=3.0452, LR=0.000027
[2025-08-10 10:57:18,958][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/03692] [00:01:18/00:32:07, 0.543s/it]: train_loss_raw=2.7073, running_loss=3.0068, LR=0.000030
[2025-08-10 10:57:25,382][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000156] [Batch 00156/03692] [00:01:24/00:31:58, 0.543s/it]: train_loss_raw=2.7165, running_loss=2.9729, LR=0.000032
[2025-08-10 10:57:31,781][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/03692] [00:01:31/00:31:49, 0.542s/it]: train_loss_raw=2.7155, running_loss=2.9426, LR=0.000035
[2025-08-10 10:57:38,231][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000180] [Batch 00180/03692] [00:01:37/00:31:42, 0.542s/it]: train_loss_raw=2.7058, running_loss=2.9151, LR=0.000037
[2025-08-10 10:57:44,767][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/03692] [00:01:44/00:31:36, 0.542s/it]: train_loss_raw=2.6767, running_loss=2.8904, LR=0.000040
[2025-08-10 10:57:51,401][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000204] [Batch 00204/03692] [00:01:50/00:31:31, 0.542s/it]: train_loss_raw=2.6528, running_loss=2.8682, LR=0.000042
[2025-08-10 10:57:57,986][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/03692] [00:01:57/00:31:26, 0.543s/it]: train_loss_raw=2.6875, running_loss=2.8481, LR=0.000045
[2025-08-10 10:58:04,610][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000228] [Batch 00228/03692] [00:02:03/00:31:21, 0.543s/it]: train_loss_raw=2.6886, running_loss=2.8310, LR=0.000047
[2025-08-10 10:58:11,084][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/03692] [00:02:10/00:31:14, 0.543s/it]: train_loss_raw=2.6823, running_loss=2.8143, LR=0.000050
[2025-08-10 10:58:17,673][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000252] [Batch 00252/03692] [00:02:16/00:31:09, 0.543s/it]: train_loss_raw=2.6853, running_loss=2.7996, LR=0.000052
[2025-08-10 10:58:24,170][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/03692] [00:02:23/00:31:02, 0.543s/it]: train_loss_raw=2.6447, running_loss=2.7866, LR=0.000055
[2025-08-10 10:58:30,680][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000276] [Batch 00276/03692] [00:02:29/00:30:55, 0.543s/it]: train_loss_raw=2.6897, running_loss=2.7743, LR=0.000057
[2025-08-10 10:58:37,236][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/03692] [00:02:36/00:30:49, 0.543s/it]: train_loss_raw=2.6515, running_loss=2.7639, LR=0.000060
[2025-08-10 10:58:43,774][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000300] [Batch 00300/03692] [00:02:43/00:30:43, 0.543s/it]: train_loss_raw=2.6778, running_loss=2.7540, LR=0.000062
[2025-08-10 10:58:50,261][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/03692] [00:02:49/00:30:36, 0.543s/it]: train_loss_raw=2.6954, running_loss=2.7461, LR=0.000065
[2025-08-10 10:58:56,763][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000324] [Batch 00324/03692] [00:02:56/00:30:29, 0.543s/it]: train_loss_raw=2.6807, running_loss=2.7365, LR=0.000067
[2025-08-10 10:59:03,207][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/03692] [00:03:02/00:30:22, 0.543s/it]: train_loss_raw=2.6623, running_loss=2.7292, LR=0.000070
[2025-08-10 10:59:09,833][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000348] [Batch 00348/03692] [00:03:09/00:30:16, 0.543s/it]: train_loss_raw=2.6661, running_loss=2.7226, LR=0.000072
[2025-08-10 10:59:16,399][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/03692] [00:03:15/00:30:10, 0.543s/it]: train_loss_raw=2.6815, running_loss=2.7178, LR=0.000075
[2025-08-10 10:59:23,026][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000372] [Batch 00372/03692] [00:03:22/00:30:05, 0.544s/it]: train_loss_raw=2.6536, running_loss=2.7118, LR=0.000077
[2025-08-10 10:59:29,581][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/03692] [00:03:28/00:29:59, 0.544s/it]: train_loss_raw=2.6965, running_loss=2.7059, LR=0.000080
[2025-08-10 10:59:36,166][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000396] [Batch 00396/03692] [00:03:35/00:29:52, 0.544s/it]: train_loss_raw=2.6775, running_loss=2.7008, LR=0.000082
[2025-08-10 10:59:42,682][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/03692] [00:03:41/00:29:46, 0.544s/it]: train_loss_raw=2.6510, running_loss=2.6965, LR=0.000085
[2025-08-10 10:59:49,268][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000420] [Batch 00420/03692] [00:03:48/00:29:40, 0.544s/it]: train_loss_raw=2.6783, running_loss=2.6921, LR=0.000087
[2025-08-10 10:59:55,874][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/03692] [00:03:55/00:29:34, 0.544s/it]: train_loss_raw=2.6535, running_loss=2.6868, LR=0.000090
[2025-08-10 11:00:02,495][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000444] [Batch 00444/03692] [00:04:01/00:29:28, 0.544s/it]: train_loss_raw=2.6370, running_loss=2.6817, LR=0.000092
[2025-08-10 11:00:09,086][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/03692] [00:04:08/00:29:22, 0.545s/it]: train_loss_raw=2.6706, running_loss=2.6768, LR=0.000095
[2025-08-10 11:00:15,547][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000468] [Batch 00468/03692] [00:04:14/00:29:15, 0.544s/it]: train_loss_raw=2.6499, running_loss=2.6730, LR=0.000097
[2025-08-10 11:00:22,013][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/03692] [00:04:21/00:29:08, 0.544s/it]: train_loss_raw=2.6144, running_loss=2.6702, LR=0.000100
[2025-08-10 11:00:28,444][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000492] [Batch 00492/03692] [00:04:27/00:29:01, 0.544s/it]: train_loss_raw=2.6772, running_loss=2.6655, LR=0.000100
[2025-08-10 11:00:34,971][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/03692] [00:04:34/00:28:54, 0.544s/it]: train_loss_raw=2.6400, running_loss=2.6624, LR=0.000100
[2025-08-10 11:00:41,560][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000516] [Batch 00516/03692] [00:04:40/00:28:48, 0.544s/it]: train_loss_raw=2.6677, running_loss=2.6592, LR=0.000100
[2025-08-10 11:00:48,154][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/03692] [00:04:47/00:28:42, 0.544s/it]: train_loss_raw=2.6407, running_loss=2.6562, LR=0.000100
[2025-08-10 11:00:54,739][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000540] [Batch 00540/03692] [00:04:53/00:28:36, 0.544s/it]: train_loss_raw=2.6528, running_loss=2.6527, LR=0.000100
[2025-08-10 11:01:01,374][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/03692] [00:05:00/00:28:30, 0.545s/it]: train_loss_raw=2.6713, running_loss=2.6504, LR=0.000100
[2025-08-10 11:01:07,962][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000564] [Batch 00564/03692] [00:05:07/00:28:23, 0.545s/it]: train_loss_raw=2.6221, running_loss=2.6472, LR=0.000100
[2025-08-10 11:01:14,536][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/03692] [00:05:13/00:28:17, 0.545s/it]: train_loss_raw=2.6064, running_loss=2.6417, LR=0.000100
[2025-08-10 11:01:21,133][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000588] [Batch 00588/03692] [00:05:20/00:28:11, 0.545s/it]: train_loss_raw=2.5277, running_loss=2.6368, LR=0.000100
[2025-08-10 11:01:27,674][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/03692] [00:05:26/00:28:04, 0.545s/it]: train_loss_raw=2.5548, running_loss=2.6322, LR=0.000100
[2025-08-10 11:01:34,179][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000612] [Batch 00612/03692] [00:05:33/00:27:58, 0.545s/it]: train_loss_raw=2.5333, running_loss=2.6284, LR=0.000100
[2025-08-10 11:01:40,766][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/03692] [00:05:40/00:27:51, 0.545s/it]: train_loss_raw=2.5857, running_loss=2.6256, LR=0.000100
[2025-08-10 11:01:47,264][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000636] [Batch 00636/03692] [00:05:46/00:27:45, 0.545s/it]: train_loss_raw=2.5715, running_loss=2.6203, LR=0.000100
[2025-08-10 11:01:53,793][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/03692] [00:05:53/00:27:38, 0.545s/it]: train_loss_raw=2.6539, running_loss=2.6188, LR=0.000100
[2025-08-10 11:02:00,226][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000660] [Batch 00660/03692] [00:05:59/00:27:31, 0.545s/it]: train_loss_raw=2.5448, running_loss=2.6149, LR=0.000100
[2025-08-10 11:02:06,677][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/03692] [00:06:05/00:27:24, 0.545s/it]: train_loss_raw=2.6451, running_loss=2.6113, LR=0.000100
[2025-08-10 11:02:13,104][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000684] [Batch 00684/03692] [00:06:12/00:27:17, 0.544s/it]: train_loss_raw=2.6115, running_loss=2.6071, LR=0.000100
[2025-08-10 11:02:19,614][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/03692] [00:06:18/00:27:10, 0.544s/it]: train_loss_raw=2.6242, running_loss=2.6048, LR=0.000100
[2025-08-10 11:02:26,153][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000708] [Batch 00708/03692] [00:06:25/00:27:04, 0.544s/it]: train_loss_raw=2.5834, running_loss=2.6023, LR=0.000100
[2025-08-10 11:02:32,693][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/03692] [00:06:31/00:26:57, 0.544s/it]: train_loss_raw=2.5313, running_loss=2.6003, LR=0.000100
[2025-08-10 11:02:39,131][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000732] [Batch 00732/03692] [00:06:38/00:26:50, 0.544s/it]: train_loss_raw=2.5349, running_loss=2.5962, LR=0.000100
[2025-08-10 11:02:45,705][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/03692] [00:06:44/00:26:44, 0.544s/it]: train_loss_raw=2.5859, running_loss=2.5914, LR=0.000100
[2025-08-10 11:02:52,320][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000756] [Batch 00756/03692] [00:06:51/00:26:38, 0.544s/it]: train_loss_raw=2.6075, running_loss=2.5872, LR=0.000100
[2025-08-10 11:02:58,845][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/03692] [00:06:58/00:26:31, 0.544s/it]: train_loss_raw=2.4574, running_loss=2.5839, LR=0.000100
[2025-08-10 11:03:05,304][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000780] [Batch 00780/03692] [00:07:04/00:26:25, 0.544s/it]: train_loss_raw=2.5257, running_loss=2.5783, LR=0.000100
[2025-08-10 11:03:11,784][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/03692] [00:07:11/00:26:18, 0.544s/it]: train_loss_raw=2.5322, running_loss=2.5749, LR=0.000100
[2025-08-10 11:03:18,268][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000804] [Batch 00804/03692] [00:07:17/00:26:11, 0.544s/it]: train_loss_raw=2.5164, running_loss=2.5691, LR=0.000100
[2025-08-10 11:03:24,760][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/03692] [00:07:24/00:26:04, 0.544s/it]: train_loss_raw=2.5448, running_loss=2.5663, LR=0.000100
[2025-08-10 11:03:31,264][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000828] [Batch 00828/03692] [00:07:30/00:25:58, 0.544s/it]: train_loss_raw=2.4883, running_loss=2.5648, LR=0.000100
[2025-08-10 11:03:37,839][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000840] [Batch 00840/03692] [00:07:37/00:25:51, 0.544s/it]: train_loss_raw=2.5763, running_loss=2.5632, LR=0.000100
[2025-08-10 11:03:44,454][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000852] [Batch 00852/03692] [00:07:43/00:25:45, 0.544s/it]: train_loss_raw=2.4798, running_loss=2.5596, LR=0.000100
[2025-08-10 11:03:50,859][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000864] [Batch 00864/03692] [00:07:50/00:25:38, 0.544s/it]: train_loss_raw=2.5245, running_loss=2.5565, LR=0.000100
[2025-08-10 11:03:57,293][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000876] [Batch 00876/03692] [00:07:56/00:25:31, 0.544s/it]: train_loss_raw=2.5794, running_loss=2.5543, LR=0.000100
[2025-08-10 11:04:03,846][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000888] [Batch 00888/03692] [00:08:03/00:25:25, 0.544s/it]: train_loss_raw=2.5686, running_loss=2.5517, LR=0.000100
[2025-08-10 11:04:10,449][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000900] [Batch 00900/03692] [00:08:09/00:25:19, 0.544s/it]: train_loss_raw=2.5039, running_loss=2.5491, LR=0.000100
[2025-08-10 11:04:16,921][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000912] [Batch 00912/03692] [00:08:16/00:25:12, 0.544s/it]: train_loss_raw=2.5144, running_loss=2.5452, LR=0.000100
[2025-08-10 11:04:23,401][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000924] [Batch 00924/03692] [00:08:22/00:25:05, 0.544s/it]: train_loss_raw=2.5436, running_loss=2.5447, LR=0.000100
[2025-08-10 11:04:29,864][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000936] [Batch 00936/03692] [00:08:29/00:24:59, 0.544s/it]: train_loss_raw=2.5522, running_loss=2.5444, LR=0.000100
[2025-08-10 11:04:36,354][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000948] [Batch 00948/03692] [00:08:35/00:24:52, 0.544s/it]: train_loss_raw=2.4680, running_loss=2.5413, LR=0.000100
[2025-08-10 11:04:42,912][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000960] [Batch 00960/03692] [00:08:42/00:24:45, 0.544s/it]: train_loss_raw=2.4917, running_loss=2.5395, LR=0.000100
[2025-08-10 11:04:49,534][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000972] [Batch 00972/03692] [00:08:48/00:24:39, 0.544s/it]: train_loss_raw=2.5544, running_loss=2.5382, LR=0.000100
[2025-08-10 11:04:56,053][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000984] [Batch 00984/03692] [00:08:55/00:24:33, 0.544s/it]: train_loss_raw=2.5303, running_loss=2.5387, LR=0.000100
[2025-08-10 11:05:02,586][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000996] [Batch 00996/03692] [00:09:01/00:24:26, 0.544s/it]: train_loss_raw=2.5768, running_loss=2.5400, LR=0.000100
[2025-08-10 11:05:09,176][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001008] [Batch 01008/03692] [00:09:08/00:24:20, 0.544s/it]: train_loss_raw=2.5540, running_loss=2.5354, LR=0.000100
[2025-08-10 11:05:15,743][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001020] [Batch 01020/03692] [00:09:14/00:24:13, 0.544s/it]: train_loss_raw=2.5018, running_loss=2.5295, LR=0.000100
[2025-08-10 11:05:22,288][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001032] [Batch 01032/03692] [00:09:21/00:24:07, 0.544s/it]: train_loss_raw=2.4782, running_loss=2.5294, LR=0.000100
[2025-08-10 11:05:28,849][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001044] [Batch 01044/03692] [00:09:28/00:24:00, 0.544s/it]: train_loss_raw=2.5362, running_loss=2.5283, LR=0.000100
[2025-08-10 11:05:35,464][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001056] [Batch 01056/03692] [00:09:34/00:23:54, 0.544s/it]: train_loss_raw=2.4781, running_loss=2.5276, LR=0.000100
[2025-08-10 11:05:42,061][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001068] [Batch 01068/03692] [00:09:41/00:23:48, 0.544s/it]: train_loss_raw=2.6024, running_loss=2.5293, LR=0.000100
[2025-08-10 11:05:48,688][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001080] [Batch 01080/03692] [00:09:47/00:23:41, 0.544s/it]: train_loss_raw=2.4818, running_loss=2.5259, LR=0.000100
[2025-08-10 11:05:55,373][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001092] [Batch 01092/03692] [00:09:54/00:23:35, 0.545s/it]: train_loss_raw=2.4850, running_loss=2.5227, LR=0.000100
[2025-08-10 11:06:01,979][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001104] [Batch 01104/03692] [00:10:01/00:23:29, 0.545s/it]: train_loss_raw=2.4912, running_loss=2.5216, LR=0.000100
[2025-08-10 11:06:08,282][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001116] [Batch 01116/03692] [00:10:07/00:23:22, 0.544s/it]: train_loss_raw=2.5173, running_loss=2.5201, LR=0.000100
[2025-08-10 11:06:14,740][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001128] [Batch 01128/03692] [00:10:13/00:23:15, 0.544s/it]: train_loss_raw=2.5110, running_loss=2.5195, LR=0.000100
[2025-08-10 11:06:21,184][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001140] [Batch 01140/03692] [00:10:20/00:23:08, 0.544s/it]: train_loss_raw=2.5534, running_loss=2.5192, LR=0.000100
[2025-08-10 11:06:27,516][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001152] [Batch 01152/03692] [00:10:26/00:23:01, 0.544s/it]: train_loss_raw=2.5490, running_loss=2.5198, LR=0.000100
[2025-08-10 11:06:33,822][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001164] [Batch 01164/03692] [00:10:33/00:22:54, 0.544s/it]: train_loss_raw=2.4663, running_loss=2.5172, LR=0.000100
[2025-08-10 11:06:40,486][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001176] [Batch 01176/03692] [00:10:39/00:22:48, 0.544s/it]: train_loss_raw=2.4151, running_loss=2.5144, LR=0.000100
[2025-08-10 11:06:47,138][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001188] [Batch 01188/03692] [00:10:46/00:22:42, 0.544s/it]: train_loss_raw=2.4889, running_loss=2.5130, LR=0.000100
[2025-08-10 11:06:53,690][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001200] [Batch 01200/03692] [00:10:52/00:22:35, 0.544s/it]: train_loss_raw=2.4192, running_loss=2.5104, LR=0.000100
[2025-08-10 11:07:00,231][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001212] [Batch 01212/03692] [00:10:59/00:22:29, 0.544s/it]: train_loss_raw=2.5100, running_loss=2.5098, LR=0.000100
[2025-08-10 11:07:06,874][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001224] [Batch 01224/03692] [00:11:06/00:22:23, 0.544s/it]: train_loss_raw=2.5629, running_loss=2.5060, LR=0.000100
[2025-08-10 11:07:13,527][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001236] [Batch 01236/03692] [00:11:12/00:22:16, 0.544s/it]: train_loss_raw=2.4557, running_loss=2.5063, LR=0.000100
[2025-08-10 11:07:20,119][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001248] [Batch 01248/03692] [00:11:19/00:22:10, 0.544s/it]: train_loss_raw=2.5362, running_loss=2.5055, LR=0.000100
[2025-08-10 11:07:26,593][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001260] [Batch 01260/03692] [00:11:25/00:22:03, 0.544s/it]: train_loss_raw=2.5290, running_loss=2.5051, LR=0.000100
[2025-08-10 11:07:33,110][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001272] [Batch 01272/03692] [00:11:32/00:21:57, 0.544s/it]: train_loss_raw=2.5393, running_loss=2.5028, LR=0.000100
[2025-08-10 11:07:39,771][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001284] [Batch 01284/03692] [00:11:39/00:21:50, 0.544s/it]: train_loss_raw=2.5522, running_loss=2.5013, LR=0.000100
[2025-08-10 11:07:46,069][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001296] [Batch 01296/03692] [00:11:45/00:21:43, 0.544s/it]: train_loss_raw=2.4421, running_loss=2.5007, LR=0.000100
[2025-08-10 11:07:52,649][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001308] [Batch 01308/03692] [00:11:51/00:21:37, 0.544s/it]: train_loss_raw=2.5165, running_loss=2.4963, LR=0.000100
[2025-08-10 11:07:59,216][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001320] [Batch 01320/03692] [00:11:58/00:21:31, 0.544s/it]: train_loss_raw=2.3585, running_loss=2.4940, LR=0.000100
[2025-08-10 11:08:05,489][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001332] [Batch 01332/03692] [00:12:04/00:21:24, 0.544s/it]: train_loss_raw=2.4521, running_loss=2.4911, LR=0.000100
[2025-08-10 11:08:11,832][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001344] [Batch 01344/03692] [00:12:11/00:21:17, 0.544s/it]: train_loss_raw=2.5355, running_loss=2.4909, LR=0.000100
[2025-08-10 11:08:18,410][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001356] [Batch 01356/03692] [00:12:17/00:21:10, 0.544s/it]: train_loss_raw=2.5055, running_loss=2.4875, LR=0.000100
[2025-08-10 11:08:25,074][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001368] [Batch 01368/03692] [00:12:24/00:21:04, 0.544s/it]: train_loss_raw=2.4225, running_loss=2.4846, LR=0.000100
[2025-08-10 11:08:31,636][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001380] [Batch 01380/03692] [00:12:30/00:20:58, 0.544s/it]: train_loss_raw=2.4455, running_loss=2.4828, LR=0.000100
[2025-08-10 11:08:38,253][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001392] [Batch 01392/03692] [00:12:37/00:20:51, 0.544s/it]: train_loss_raw=2.4419, running_loss=2.4810, LR=0.000100
[2025-08-10 11:08:44,754][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001404] [Batch 01404/03692] [00:12:44/00:20:45, 0.544s/it]: train_loss_raw=2.4652, running_loss=2.4786, LR=0.000100
[2025-08-10 11:08:51,384][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001416] [Batch 01416/03692] [00:12:50/00:20:38, 0.544s/it]: train_loss_raw=2.4191, running_loss=2.4773, LR=0.000100
[2025-08-10 11:08:57,960][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001428] [Batch 01428/03692] [00:12:57/00:20:32, 0.544s/it]: train_loss_raw=2.4693, running_loss=2.4787, LR=0.000100
[2025-08-10 11:09:04,487][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001440] [Batch 01440/03692] [00:13:03/00:20:25, 0.544s/it]: train_loss_raw=2.4585, running_loss=2.4769, LR=0.000100
[2025-08-10 11:09:11,140][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001452] [Batch 01452/03692] [00:13:10/00:20:19, 0.544s/it]: train_loss_raw=2.5095, running_loss=2.4754, LR=0.000100
[2025-08-10 11:09:17,734][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001464] [Batch 01464/03692] [00:13:16/00:20:12, 0.544s/it]: train_loss_raw=2.4297, running_loss=2.4718, LR=0.000100
[2025-08-10 11:09:24,353][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001476] [Batch 01476/03692] [00:13:23/00:20:06, 0.544s/it]: train_loss_raw=2.4178, running_loss=2.4707, LR=0.000100
[2025-08-10 11:09:30,962][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001488] [Batch 01488/03692] [00:13:30/00:20:00, 0.544s/it]: train_loss_raw=2.3922, running_loss=2.4688, LR=0.000100
[2025-08-10 11:09:37,611][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001500] [Batch 01500/03692] [00:13:36/00:19:53, 0.545s/it]: train_loss_raw=2.4487, running_loss=2.4683, LR=0.000100
[2025-08-10 11:09:44,258][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001512] [Batch 01512/03692] [00:13:43/00:19:47, 0.545s/it]: train_loss_raw=2.4248, running_loss=2.4659, LR=0.000100
[2025-08-10 11:09:50,969][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001524] [Batch 01524/03692] [00:13:50/00:19:41, 0.545s/it]: train_loss_raw=2.4567, running_loss=2.4636, LR=0.000100
[2025-08-10 11:10:26,613][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001536] [Batch 01536/03692] [00:14:25/00:20:15, 0.564s/it]: train_loss_raw=2.4491, running_loss=2.4638, LR=0.000100
[2025-08-10 11:10:33,275][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001548] [Batch 01548/03692] [00:14:32/00:20:08, 0.564s/it]: train_loss_raw=2.4452, running_loss=2.4629, LR=0.000100
[2025-08-10 11:10:39,785][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001560] [Batch 01560/03692] [00:14:39/00:20:01, 0.563s/it]: train_loss_raw=2.5422, running_loss=2.4617, LR=0.000100
[2025-08-10 11:10:46,381][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001572] [Batch 01572/03692] [00:14:45/00:19:54, 0.563s/it]: train_loss_raw=2.5049, running_loss=2.4606, LR=0.000100
[2025-08-10 11:10:53,011][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001584] [Batch 01584/03692] [00:14:52/00:19:47, 0.563s/it]: train_loss_raw=2.3879, running_loss=2.4614, LR=0.000100
[2025-08-10 11:10:59,597][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001596] [Batch 01596/03692] [00:14:58/00:19:40, 0.563s/it]: train_loss_raw=2.4741, running_loss=2.4607, LR=0.000100
[2025-08-10 11:11:06,202][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001608] [Batch 01608/03692] [00:15:05/00:19:33, 0.563s/it]: train_loss_raw=2.4035, running_loss=2.4599, LR=0.000100
[2025-08-10 11:11:12,643][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001620] [Batch 01620/03692] [00:15:11/00:19:26, 0.563s/it]: train_loss_raw=2.4304, running_loss=2.4587, LR=0.000100
[2025-08-10 11:11:19,025][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001632] [Batch 01632/03692] [00:15:18/00:19:19, 0.563s/it]: train_loss_raw=2.4474, running_loss=2.4547, LR=0.000100
[2025-08-10 11:11:25,622][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001644] [Batch 01644/03692] [00:15:24/00:19:12, 0.563s/it]: train_loss_raw=2.5041, running_loss=2.4537, LR=0.000100
[2025-08-10 11:11:32,142][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001656] [Batch 01656/03692] [00:15:31/00:19:05, 0.562s/it]: train_loss_raw=2.5082, running_loss=2.4534, LR=0.000100
[2025-08-10 11:11:38,774][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001668] [Batch 01668/03692] [00:15:38/00:18:58, 0.562s/it]: train_loss_raw=2.4694, running_loss=2.4508, LR=0.000100
[2025-08-10 11:11:45,483][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001680] [Batch 01680/03692] [00:15:44/00:18:51, 0.562s/it]: train_loss_raw=2.4529, running_loss=2.4491, LR=0.000100
[2025-08-10 11:11:52,011][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001692] [Batch 01692/03692] [00:15:51/00:18:44, 0.562s/it]: train_loss_raw=2.4296, running_loss=2.4456, LR=0.000100
[2025-08-10 11:11:58,650][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001704] [Batch 01704/03692] [00:15:57/00:18:37, 0.562s/it]: train_loss_raw=2.3908, running_loss=2.4415, LR=0.000100
[2025-08-10 11:12:05,263][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001716] [Batch 01716/03692] [00:16:04/00:18:30, 0.562s/it]: train_loss_raw=2.4435, running_loss=2.4425, LR=0.000100
[2025-08-10 11:12:11,854][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001728] [Batch 01728/03692] [00:16:11/00:18:23, 0.562s/it]: train_loss_raw=2.4683, running_loss=2.4417, LR=0.000100
[2025-08-10 11:12:18,609][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001740] [Batch 01740/03692] [00:16:17/00:18:17, 0.562s/it]: train_loss_raw=2.3575, running_loss=2.4405, LR=0.000100
[2025-08-10 11:12:25,201][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001752] [Batch 01752/03692] [00:16:24/00:18:10, 0.562s/it]: train_loss_raw=2.4488, running_loss=2.4382, LR=0.000100
[2025-08-10 11:12:31,897][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001764] [Batch 01764/03692] [00:16:31/00:18:03, 0.562s/it]: train_loss_raw=2.4981, running_loss=2.4384, LR=0.000100
[2025-08-10 11:12:38,514][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001776] [Batch 01776/03692] [00:16:37/00:17:56, 0.562s/it]: train_loss_raw=2.4195, running_loss=2.4356, LR=0.000100
[2025-08-10 11:12:45,024][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001788] [Batch 01788/03692] [00:16:44/00:17:49, 0.562s/it]: train_loss_raw=2.4755, running_loss=2.4352, LR=0.000100
[2025-08-10 11:12:51,641][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001800] [Batch 01800/03692] [00:16:50/00:17:42, 0.562s/it]: train_loss_raw=2.4047, running_loss=2.4328, LR=0.000100
[2025-08-10 11:12:58,206][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001812] [Batch 01812/03692] [00:16:57/00:17:35, 0.562s/it]: train_loss_raw=2.4113, running_loss=2.4308, LR=0.000100
[2025-08-10 11:13:04,752][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001824] [Batch 01824/03692] [00:17:04/00:17:28, 0.561s/it]: train_loss_raw=2.3762, running_loss=2.4272, LR=0.000100
[2025-08-10 11:13:11,380][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001836] [Batch 01836/03692] [00:17:10/00:17:21, 0.561s/it]: train_loss_raw=2.3684, running_loss=2.4260, LR=0.000100
[2025-08-10 11:13:17,878][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001848] [Batch 01848/03692] [00:17:17/00:17:14, 0.561s/it]: train_loss_raw=2.4334, running_loss=2.4235, LR=0.000100
[2025-08-10 11:13:24,492][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001860] [Batch 01860/03692] [00:17:23/00:17:08, 0.561s/it]: train_loss_raw=2.3776, running_loss=2.4203, LR=0.000100
[2025-08-10 11:13:31,124][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001872] [Batch 01872/03692] [00:17:30/00:17:01, 0.561s/it]: train_loss_raw=2.4712, running_loss=2.4195, LR=0.000100
[2025-08-10 11:13:37,710][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001884] [Batch 01884/03692] [00:17:36/00:16:54, 0.561s/it]: train_loss_raw=2.4459, running_loss=2.4178, LR=0.000100
[2025-08-10 11:13:44,215][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001896] [Batch 01896/03692] [00:17:43/00:16:47, 0.561s/it]: train_loss_raw=2.3460, running_loss=2.4161, LR=0.000100
[2025-08-10 11:13:50,683][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001908] [Batch 01908/03692] [00:17:49/00:16:40, 0.561s/it]: train_loss_raw=2.3808, running_loss=2.4133, LR=0.000100
[2025-08-10 11:13:57,306][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001920] [Batch 01920/03692] [00:17:56/00:16:33, 0.561s/it]: train_loss_raw=2.4448, running_loss=2.4124, LR=0.000100
[2025-08-10 11:14:03,917][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001932] [Batch 01932/03692] [00:18:03/00:16:26, 0.561s/it]: train_loss_raw=2.4263, running_loss=2.4132, LR=0.000100
[2025-08-10 11:14:10,503][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001944] [Batch 01944/03692] [00:18:09/00:16:19, 0.561s/it]: train_loss_raw=2.4127, running_loss=2.4150, LR=0.000100
[2025-08-10 11:14:17,109][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001956] [Batch 01956/03692] [00:18:16/00:16:13, 0.561s/it]: train_loss_raw=2.4433, running_loss=2.4156, LR=0.000100
[2025-08-10 11:14:23,643][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001968] [Batch 01968/03692] [00:18:22/00:16:06, 0.560s/it]: train_loss_raw=2.4413, running_loss=2.4147, LR=0.000100
[2025-08-10 11:14:30,289][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001980] [Batch 01980/03692] [00:18:29/00:15:59, 0.560s/it]: train_loss_raw=2.4280, running_loss=2.4158, LR=0.000100
[2025-08-10 11:14:36,891][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001992] [Batch 01992/03692] [00:18:36/00:15:52, 0.560s/it]: train_loss_raw=2.4365, running_loss=2.4156, LR=0.000100
[2025-08-10 11:14:47,629][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002004] [Batch 02004/03692] [00:18:46/00:15:49, 0.562s/it]: train_loss_raw=2.4601, running_loss=2.4144, LR=0.000100
[2025-08-10 11:14:54,177][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002016] [Batch 02016/03692] [00:18:53/00:15:42, 0.562s/it]: train_loss_raw=2.3224, running_loss=2.4123, LR=0.000100
[2025-08-10 11:15:00,668][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002028] [Batch 02028/03692] [00:18:59/00:15:35, 0.562s/it]: train_loss_raw=2.4298, running_loss=2.4100, LR=0.000100
[2025-08-10 11:15:07,125][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002040] [Batch 02040/03692] [00:19:06/00:15:28, 0.562s/it]: train_loss_raw=2.3573, running_loss=2.4081, LR=0.000100
[2025-08-10 11:15:13,772][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002052] [Batch 02052/03692] [00:19:13/00:15:21, 0.562s/it]: train_loss_raw=2.3987, running_loss=2.4076, LR=0.000100
[2025-08-10 11:15:20,374][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002064] [Batch 02064/03692] [00:19:19/00:15:14, 0.562s/it]: train_loss_raw=2.3779, running_loss=2.4055, LR=0.000100
[2025-08-10 11:15:26,905][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002076] [Batch 02076/03692] [00:19:26/00:15:07, 0.562s/it]: train_loss_raw=2.4018, running_loss=2.4019, LR=0.000100
[2025-08-10 11:15:33,562][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002088] [Batch 02088/03692] [00:19:32/00:15:00, 0.562s/it]: train_loss_raw=2.3974, running_loss=2.4018, LR=0.000100
[2025-08-10 11:15:40,153][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002100] [Batch 02100/03692] [00:19:39/00:14:54, 0.562s/it]: train_loss_raw=2.3934, running_loss=2.4004, LR=0.000100
[2025-08-10 11:15:46,802][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002112] [Batch 02112/03692] [00:19:46/00:14:47, 0.562s/it]: train_loss_raw=2.3912, running_loss=2.4002, LR=0.000100
[2025-08-10 11:15:53,368][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002124] [Batch 02124/03692] [00:19:52/00:14:40, 0.561s/it]: train_loss_raw=2.3756, running_loss=2.3985, LR=0.000100
[2025-08-10 11:15:59,933][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002136] [Batch 02136/03692] [00:19:59/00:14:33, 0.561s/it]: train_loss_raw=2.3984, running_loss=2.3982, LR=0.000100
[2025-08-10 11:16:06,548][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002148] [Batch 02148/03692] [00:20:05/00:14:26, 0.561s/it]: train_loss_raw=2.3578, running_loss=2.3970, LR=0.000100
[2025-08-10 11:16:13,093][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002160] [Batch 02160/03692] [00:20:12/00:14:19, 0.561s/it]: train_loss_raw=2.3480, running_loss=2.3907, LR=0.000100
[2025-08-10 11:16:19,704][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002172] [Batch 02172/03692] [00:20:18/00:14:13, 0.561s/it]: train_loss_raw=2.3617, running_loss=2.3905, LR=0.000100
[2025-08-10 11:16:26,317][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002184] [Batch 02184/03692] [00:20:25/00:14:06, 0.561s/it]: train_loss_raw=2.4186, running_loss=2.3855, LR=0.000100
[2025-08-10 11:16:32,929][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002196] [Batch 02196/03692] [00:20:32/00:13:59, 0.561s/it]: train_loss_raw=2.3485, running_loss=2.3858, LR=0.000100
[2025-08-10 11:16:39,586][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002208] [Batch 02208/03692] [00:20:38/00:13:52, 0.561s/it]: train_loss_raw=2.3312, running_loss=2.3850, LR=0.000100
[2025-08-10 11:16:45,990][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002220] [Batch 02220/03692] [00:20:45/00:13:45, 0.561s/it]: train_loss_raw=2.3392, running_loss=2.3845, LR=0.000100
[2025-08-10 11:16:52,437][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002232] [Batch 02232/03692] [00:20:51/00:13:38, 0.561s/it]: train_loss_raw=2.3495, running_loss=2.3848, LR=0.000100
[2025-08-10 11:16:58,953][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002244] [Batch 02244/03692] [00:20:58/00:13:31, 0.561s/it]: train_loss_raw=2.3340, running_loss=2.3815, LR=0.000100
[2025-08-10 11:17:05,298][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002256] [Batch 02256/03692] [00:21:04/00:13:24, 0.561s/it]: train_loss_raw=2.2778, running_loss=2.3791, LR=0.000100
[2025-08-10 11:17:11,672][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002268] [Batch 02268/03692] [00:21:10/00:13:17, 0.560s/it]: train_loss_raw=2.3483, running_loss=2.3801, LR=0.000100
[2025-08-10 11:17:18,177][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002280] [Batch 02280/03692] [00:21:17/00:13:11, 0.560s/it]: train_loss_raw=2.4448, running_loss=2.3805, LR=0.000100
[2025-08-10 11:17:24,625][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002292] [Batch 02292/03692] [00:21:23/00:13:04, 0.560s/it]: train_loss_raw=2.3754, running_loss=2.3816, LR=0.000100
[2025-08-10 11:17:31,201][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002304] [Batch 02304/03692] [00:21:30/00:12:57, 0.560s/it]: train_loss_raw=2.2912, running_loss=2.3778, LR=0.000100
[2025-08-10 11:17:37,778][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002316] [Batch 02316/03692] [00:21:37/00:12:50, 0.560s/it]: train_loss_raw=2.3609, running_loss=2.3775, LR=0.000100
[2025-08-10 11:17:44,295][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002328] [Batch 02328/03692] [00:21:43/00:12:43, 0.560s/it]: train_loss_raw=2.2491, running_loss=2.3733, LR=0.000100
[2025-08-10 11:17:50,836][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002340] [Batch 02340/03692] [00:21:50/00:12:36, 0.560s/it]: train_loss_raw=2.4027, running_loss=2.3750, LR=0.000100
[2025-08-10 11:17:57,480][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002352] [Batch 02352/03692] [00:21:56/00:12:30, 0.560s/it]: train_loss_raw=2.2922, running_loss=2.3728, LR=0.000100
[2025-08-10 11:18:04,072][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002364] [Batch 02364/03692] [00:22:03/00:12:23, 0.560s/it]: train_loss_raw=2.2790, running_loss=2.3703, LR=0.000100
[2025-08-10 11:18:10,576][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002376] [Batch 02376/03692] [00:22:09/00:12:16, 0.560s/it]: train_loss_raw=2.3227, running_loss=2.3695, LR=0.000100
[2025-08-10 11:18:17,146][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002388] [Batch 02388/03692] [00:22:16/00:12:09, 0.560s/it]: train_loss_raw=2.3319, running_loss=2.3664, LR=0.000100
[2025-08-10 11:18:23,633][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002400] [Batch 02400/03692] [00:22:22/00:12:02, 0.560s/it]: train_loss_raw=2.4131, running_loss=2.3669, LR=0.000100
[2025-08-10 11:18:30,210][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002412] [Batch 02412/03692] [00:22:29/00:11:56, 0.559s/it]: train_loss_raw=2.4113, running_loss=2.3674, LR=0.000100
[2025-08-10 11:18:36,717][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002424] [Batch 02424/03692] [00:22:35/00:11:49, 0.559s/it]: train_loss_raw=2.3158, running_loss=2.3648, LR=0.000100
[2025-08-10 11:18:43,349][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002436] [Batch 02436/03692] [00:22:42/00:11:42, 0.559s/it]: train_loss_raw=2.4167, running_loss=2.3671, LR=0.000100
[2025-08-10 11:18:49,887][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002448] [Batch 02448/03692] [00:22:49/00:11:35, 0.559s/it]: train_loss_raw=2.3189, running_loss=2.3640, LR=0.000100
[2025-08-10 11:18:56,572][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002460] [Batch 02460/03692] [00:22:55/00:11:29, 0.559s/it]: train_loss_raw=2.4217, running_loss=2.3650, LR=0.000100
[2025-08-10 11:19:03,091][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002472] [Batch 02472/03692] [00:23:02/00:11:22, 0.559s/it]: train_loss_raw=2.3568, running_loss=2.3631, LR=0.000100
[2025-08-10 11:19:09,695][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002484] [Batch 02484/03692] [00:23:08/00:11:15, 0.559s/it]: train_loss_raw=2.3559, running_loss=2.3611, LR=0.000100
[2025-08-10 11:19:16,312][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002496] [Batch 02496/03692] [00:23:15/00:11:08, 0.559s/it]: train_loss_raw=2.4489, running_loss=2.3572, LR=0.000100
[2025-08-10 11:19:22,804][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002508] [Batch 02508/03692] [00:23:22/00:11:01, 0.559s/it]: train_loss_raw=2.2932, running_loss=2.3534, LR=0.000100
[2025-08-10 11:19:29,284][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002520] [Batch 02520/03692] [00:23:28/00:10:55, 0.559s/it]: train_loss_raw=2.3868, running_loss=2.3494, LR=0.000100
[2025-08-10 11:19:35,899][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002532] [Batch 02532/03692] [00:23:35/00:10:48, 0.559s/it]: train_loss_raw=2.3934, running_loss=2.3515, LR=0.000100
[2025-08-10 11:19:42,416][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002544] [Batch 02544/03692] [00:23:41/00:10:41, 0.559s/it]: train_loss_raw=2.3548, running_loss=2.3495, LR=0.000100
[2025-08-10 11:19:48,868][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002556] [Batch 02556/03692] [00:23:48/00:10:34, 0.559s/it]: train_loss_raw=2.3486, running_loss=2.3483, LR=0.000100
[2025-08-10 11:19:55,405][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002568] [Batch 02568/03692] [00:23:54/00:10:27, 0.559s/it]: train_loss_raw=2.4218, running_loss=2.3495, LR=0.000100
[2025-08-10 11:20:01,904][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002580] [Batch 02580/03692] [00:24:01/00:10:21, 0.559s/it]: train_loss_raw=2.4120, running_loss=2.3499, LR=0.000100
[2025-08-10 11:20:08,402][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002592] [Batch 02592/03692] [00:24:07/00:10:14, 0.559s/it]: train_loss_raw=2.3184, running_loss=2.3502, LR=0.000100
[2025-08-10 11:20:15,013][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002604] [Batch 02604/03692] [00:24:14/00:10:07, 0.558s/it]: train_loss_raw=2.2768, running_loss=2.3470, LR=0.000100
[2025-08-10 11:20:21,638][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002616] [Batch 02616/03692] [00:24:20/00:10:00, 0.558s/it]: train_loss_raw=2.3271, running_loss=2.3465, LR=0.000100
[2025-08-10 11:20:28,281][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002628] [Batch 02628/03692] [00:24:27/00:09:54, 0.558s/it]: train_loss_raw=2.3449, running_loss=2.3464, LR=0.000100
[2025-08-10 11:20:34,906][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002640] [Batch 02640/03692] [00:24:34/00:09:47, 0.558s/it]: train_loss_raw=2.2654, running_loss=2.3490, LR=0.000100
[2025-08-10 11:20:41,450][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002652] [Batch 02652/03692] [00:24:40/00:09:40, 0.558s/it]: train_loss_raw=2.3425, running_loss=2.3478, LR=0.000100
[2025-08-10 11:20:48,054][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002664] [Batch 02664/03692] [00:24:47/00:09:33, 0.558s/it]: train_loss_raw=2.3165, running_loss=2.3443, LR=0.000100
[2025-08-10 11:20:54,561][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002676] [Batch 02676/03692] [00:24:53/00:09:27, 0.558s/it]: train_loss_raw=2.3079, running_loss=2.3424, LR=0.000100
[2025-08-10 11:21:01,021][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002688] [Batch 02688/03692] [00:25:00/00:09:20, 0.558s/it]: train_loss_raw=2.2521, running_loss=2.3420, LR=0.000100
[2025-08-10 11:21:07,520][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002700] [Batch 02700/03692] [00:25:06/00:09:13, 0.558s/it]: train_loss_raw=2.2942, running_loss=2.3379, LR=0.000100
[2025-08-10 11:21:14,061][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002712] [Batch 02712/03692] [00:25:13/00:09:06, 0.558s/it]: train_loss_raw=2.3169, running_loss=2.3400, LR=0.000100
[2025-08-10 11:21:20,741][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002724] [Batch 02724/03692] [00:25:19/00:09:00, 0.558s/it]: train_loss_raw=2.4071, running_loss=2.3429, LR=0.000100
[2025-08-10 11:21:27,221][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002736] [Batch 02736/03692] [00:25:26/00:08:53, 0.558s/it]: train_loss_raw=2.3339, running_loss=2.3406, LR=0.000100
[2025-08-10 11:21:33,648][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002748] [Batch 02748/03692] [00:25:32/00:08:46, 0.558s/it]: train_loss_raw=2.2762, running_loss=2.3380, LR=0.000100
[2025-08-10 11:21:40,142][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002760] [Batch 02760/03692] [00:25:39/00:08:39, 0.558s/it]: train_loss_raw=2.3611, running_loss=2.3376, LR=0.000100
[2025-08-10 11:21:46,695][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002772] [Batch 02772/03692] [00:25:45/00:08:33, 0.558s/it]: train_loss_raw=2.3096, running_loss=2.3402, LR=0.000100
[2025-08-10 11:21:53,157][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002784] [Batch 02784/03692] [00:25:52/00:08:26, 0.558s/it]: train_loss_raw=2.3217, running_loss=2.3378, LR=0.000100
[2025-08-10 11:21:59,738][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002796] [Batch 02796/03692] [00:25:58/00:08:19, 0.558s/it]: train_loss_raw=2.3239, running_loss=2.3380, LR=0.000100
[2025-08-10 11:22:06,262][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002808] [Batch 02808/03692] [00:26:05/00:08:12, 0.558s/it]: train_loss_raw=2.3250, running_loss=2.3362, LR=0.000100
[2025-08-10 11:22:12,799][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002820] [Batch 02820/03692] [00:26:12/00:08:06, 0.557s/it]: train_loss_raw=2.3211, running_loss=2.3351, LR=0.000100
[2025-08-10 11:22:19,481][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002832] [Batch 02832/03692] [00:26:18/00:07:59, 0.557s/it]: train_loss_raw=2.2904, running_loss=2.3316, LR=0.000100
[2025-08-10 11:22:26,101][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002844] [Batch 02844/03692] [00:26:25/00:07:52, 0.557s/it]: train_loss_raw=2.3230, running_loss=2.3317, LR=0.000100
[2025-08-10 11:22:32,750][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002856] [Batch 02856/03692] [00:26:32/00:07:46, 0.557s/it]: train_loss_raw=2.2400, running_loss=2.3280, LR=0.000100
[2025-08-10 11:22:39,167][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002868] [Batch 02868/03692] [00:26:38/00:07:39, 0.557s/it]: train_loss_raw=2.3928, running_loss=2.3276, LR=0.000100
[2025-08-10 11:22:45,770][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002880] [Batch 02880/03692] [00:26:45/00:07:32, 0.557s/it]: train_loss_raw=2.3197, running_loss=2.3240, LR=0.000100
[2025-08-10 11:22:52,328][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002892] [Batch 02892/03692] [00:26:51/00:07:25, 0.557s/it]: train_loss_raw=2.2875, running_loss=2.3223, LR=0.000100
[2025-08-10 11:22:58,723][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002904] [Batch 02904/03692] [00:26:57/00:07:19, 0.557s/it]: train_loss_raw=2.3399, running_loss=2.3229, LR=0.000100
[2025-08-10 11:23:05,208][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002916] [Batch 02916/03692] [00:27:04/00:07:12, 0.557s/it]: train_loss_raw=2.2718, running_loss=2.3209, LR=0.000100
[2025-08-10 11:23:11,708][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002928] [Batch 02928/03692] [00:27:10/00:07:05, 0.557s/it]: train_loss_raw=2.2606, running_loss=2.3194, LR=0.000100
[2025-08-10 11:23:18,113][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002940] [Batch 02940/03692] [00:27:17/00:06:58, 0.557s/it]: train_loss_raw=2.2188, running_loss=2.3188, LR=0.000100
[2025-08-10 11:23:24,703][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002952] [Batch 02952/03692] [00:27:23/00:06:52, 0.557s/it]: train_loss_raw=2.2901, running_loss=2.3221, LR=0.000100
[2025-08-10 11:23:31,345][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002964] [Batch 02964/03692] [00:27:30/00:06:45, 0.557s/it]: train_loss_raw=2.2605, running_loss=2.3187, LR=0.000100
[2025-08-10 11:23:37,960][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002976] [Batch 02976/03692] [00:27:37/00:06:38, 0.557s/it]: train_loss_raw=2.3831, running_loss=2.3196, LR=0.000100
[2025-08-10 11:23:44,241][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002988] [Batch 02988/03692] [00:27:43/00:06:31, 0.557s/it]: train_loss_raw=2.3357, running_loss=2.3192, LR=0.000100
[2025-08-10 11:23:50,644][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003000] [Batch 03000/03692] [00:27:49/00:06:25, 0.557s/it]: train_loss_raw=2.3006, running_loss=2.3214, LR=0.000100
[2025-08-10 11:23:57,219][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003012] [Batch 03012/03692] [00:27:56/00:06:18, 0.557s/it]: train_loss_raw=2.2466, running_loss=2.3208, LR=0.000100
[2025-08-10 11:24:03,943][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003024] [Batch 03024/03692] [00:28:03/00:06:11, 0.557s/it]: train_loss_raw=2.2819, running_loss=2.3184, LR=0.000100
[2025-08-10 11:24:10,599][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003036] [Batch 03036/03692] [00:28:09/00:06:05, 0.557s/it]: train_loss_raw=2.3172, running_loss=2.3165, LR=0.000100
[2025-08-10 11:24:17,212][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003048] [Batch 03048/03692] [00:28:16/00:05:58, 0.557s/it]: train_loss_raw=2.3995, running_loss=2.3165, LR=0.000100
[2025-08-10 11:24:23,790][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003060] [Batch 03060/03692] [00:28:23/00:05:51, 0.557s/it]: train_loss_raw=2.3232, running_loss=2.3163, LR=0.000100
[2025-08-10 11:24:30,405][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003072] [Batch 03072/03692] [00:28:29/00:05:45, 0.557s/it]: train_loss_raw=2.3205, running_loss=2.3135, LR=0.000100
[2025-08-10 11:24:37,068][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003084] [Batch 03084/03692] [00:28:36/00:05:38, 0.557s/it]: train_loss_raw=2.2765, running_loss=2.3122, LR=0.000100
[2025-08-10 11:24:43,425][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003096] [Batch 03096/03692] [00:28:42/00:05:31, 0.556s/it]: train_loss_raw=2.3344, running_loss=2.3093, LR=0.000100
[2025-08-10 11:24:49,698][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003108] [Batch 03108/03692] [00:28:48/00:05:24, 0.556s/it]: train_loss_raw=2.2943, running_loss=2.3081, LR=0.000100
[2025-08-10 11:24:55,951][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003120] [Batch 03120/03692] [00:28:55/00:05:18, 0.556s/it]: train_loss_raw=2.3600, running_loss=2.3085, LR=0.000100
[2025-08-10 11:25:02,571][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003132] [Batch 03132/03692] [00:29:01/00:05:11, 0.556s/it]: train_loss_raw=2.2966, running_loss=2.3074, LR=0.000100
[2025-08-10 11:25:09,111][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003144] [Batch 03144/03692] [00:29:08/00:05:04, 0.556s/it]: train_loss_raw=2.2328, running_loss=2.3050, LR=0.000100
[2025-08-10 11:25:15,596][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003156] [Batch 03156/03692] [00:29:14/00:04:58, 0.556s/it]: train_loss_raw=2.2161, running_loss=2.3016, LR=0.000100
[2025-08-10 11:25:22,004][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003168] [Batch 03168/03692] [00:29:21/00:04:51, 0.556s/it]: train_loss_raw=2.3455, running_loss=2.3005, LR=0.000100
[2025-08-10 11:25:28,486][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003180] [Batch 03180/03692] [00:29:27/00:04:44, 0.556s/it]: train_loss_raw=2.3165, running_loss=2.2976, LR=0.000100
[2025-08-10 11:25:34,922][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003192] [Batch 03192/03692] [00:29:34/00:04:37, 0.556s/it]: train_loss_raw=2.2923, running_loss=2.2939, LR=0.000100
[2025-08-10 11:25:41,233][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003204] [Batch 03204/03692] [00:29:40/00:04:31, 0.556s/it]: train_loss_raw=2.2682, running_loss=2.2924, LR=0.000100
[2025-08-10 11:25:47,483][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003216] [Batch 03216/03692] [00:29:46/00:04:24, 0.556s/it]: train_loss_raw=2.2873, running_loss=2.2925, LR=0.000100
[2025-08-10 11:25:53,781][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003228] [Batch 03228/03692] [00:29:53/00:04:17, 0.555s/it]: train_loss_raw=2.3788, running_loss=2.2923, LR=0.000100
[2025-08-10 11:25:59,985][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003240] [Batch 03240/03692] [00:29:59/00:04:11, 0.555s/it]: train_loss_raw=2.3434, running_loss=2.2929, LR=0.000100
[2025-08-10 11:26:06,407][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003252] [Batch 03252/03692] [00:30:05/00:04:04, 0.555s/it]: train_loss_raw=2.3011, running_loss=2.2926, LR=0.000100
[2025-08-10 11:26:12,997][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003264] [Batch 03264/03692] [00:30:12/00:03:57, 0.555s/it]: train_loss_raw=2.3624, running_loss=2.2929, LR=0.000100
[2025-08-10 11:26:19,616][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003276] [Batch 03276/03692] [00:30:18/00:03:50, 0.555s/it]: train_loss_raw=2.3959, running_loss=2.2920, LR=0.000100
[2025-08-10 11:26:26,266][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003288] [Batch 03288/03692] [00:30:25/00:03:44, 0.555s/it]: train_loss_raw=2.3224, running_loss=2.2917, LR=0.000100
[2025-08-10 11:26:32,863][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003300] [Batch 03300/03692] [00:30:32/00:03:37, 0.555s/it]: train_loss_raw=2.2147, running_loss=2.2873, LR=0.000100
[2025-08-10 11:26:39,365][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003312] [Batch 03312/03692] [00:30:38/00:03:30, 0.555s/it]: train_loss_raw=2.2183, running_loss=2.2844, LR=0.000100
[2025-08-10 11:26:45,843][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003324] [Batch 03324/03692] [00:30:45/00:03:24, 0.555s/it]: train_loss_raw=2.2255, running_loss=2.2820, LR=0.000100
[2025-08-10 11:26:52,333][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003336] [Batch 03336/03692] [00:30:51/00:03:17, 0.555s/it]: train_loss_raw=2.3967, running_loss=2.2800, LR=0.000100
[2025-08-10 11:26:58,749][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003348] [Batch 03348/03692] [00:30:58/00:03:10, 0.555s/it]: train_loss_raw=2.2588, running_loss=2.2784, LR=0.000100
[2025-08-10 11:27:05,278][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003360] [Batch 03360/03692] [00:31:04/00:03:04, 0.555s/it]: train_loss_raw=2.2649, running_loss=2.2787, LR=0.000100
[2025-08-10 11:27:11,832][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003372] [Batch 03372/03692] [00:31:11/00:02:57, 0.555s/it]: train_loss_raw=2.1536, running_loss=2.2772, LR=0.000100
[2025-08-10 11:27:18,334][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003384] [Batch 03384/03692] [00:31:17/00:02:50, 0.555s/it]: train_loss_raw=2.2352, running_loss=2.2773, LR=0.000100
[2025-08-10 11:27:24,889][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003396] [Batch 03396/03692] [00:31:24/00:02:44, 0.555s/it]: train_loss_raw=2.2040, running_loss=2.2762, LR=0.000100
[2025-08-10 11:27:31,328][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003408] [Batch 03408/03692] [00:31:30/00:02:37, 0.555s/it]: train_loss_raw=2.3734, running_loss=2.2750, LR=0.000100
[2025-08-10 11:27:37,800][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003420] [Batch 03420/03692] [00:31:37/00:02:30, 0.555s/it]: train_loss_raw=2.1848, running_loss=2.2696, LR=0.000100
[2025-08-10 11:27:44,266][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003432] [Batch 03432/03692] [00:31:43/00:02:24, 0.555s/it]: train_loss_raw=2.3310, running_loss=2.2670, LR=0.000100
[2025-08-10 11:27:50,695][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003444] [Batch 03444/03692] [00:31:49/00:02:17, 0.555s/it]: train_loss_raw=2.2868, running_loss=2.2686, LR=0.000100
[2025-08-10 11:27:57,237][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003456] [Batch 03456/03692] [00:31:56/00:02:10, 0.555s/it]: train_loss_raw=2.2297, running_loss=2.2700, LR=0.000100
[2025-08-10 11:28:03,861][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003468] [Batch 03468/03692] [00:32:03/00:02:04, 0.555s/it]: train_loss_raw=2.2861, running_loss=2.2717, LR=0.000100
[2025-08-10 11:28:10,517][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003480] [Batch 03480/03692] [00:32:09/00:01:57, 0.555s/it]: train_loss_raw=2.1352, running_loss=2.2673, LR=0.000100
[2025-08-10 11:28:17,130][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003492] [Batch 03492/03692] [00:32:16/00:01:50, 0.555s/it]: train_loss_raw=2.1743, running_loss=2.2666, LR=0.000100
[2025-08-10 11:28:23,766][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003504] [Batch 03504/03692] [00:32:23/00:01:44, 0.555s/it]: train_loss_raw=2.2986, running_loss=2.2689, LR=0.000100
[2025-08-10 11:28:30,364][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003516] [Batch 03516/03692] [00:32:29/00:01:37, 0.554s/it]: train_loss_raw=2.2822, running_loss=2.2681, LR=0.000100
[2025-08-10 11:28:36,872][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003528] [Batch 03528/03692] [00:32:36/00:01:30, 0.554s/it]: train_loss_raw=2.2294, running_loss=2.2684, LR=0.000100
[2025-08-10 11:28:43,381][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003540] [Batch 03540/03692] [00:32:42/00:01:24, 0.554s/it]: train_loss_raw=2.2551, running_loss=2.2694, LR=0.000100
[2025-08-10 11:28:49,989][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003552] [Batch 03552/03692] [00:32:49/00:01:17, 0.554s/it]: train_loss_raw=2.2133, running_loss=2.2716, LR=0.000100
[2025-08-10 11:28:56,554][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003564] [Batch 03564/03692] [00:32:55/00:01:10, 0.554s/it]: train_loss_raw=2.2951, running_loss=2.2717, LR=0.000100
[2025-08-10 11:29:03,156][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003576] [Batch 03576/03692] [00:33:02/00:01:04, 0.554s/it]: train_loss_raw=2.2505, running_loss=2.2721, LR=0.000100
[2025-08-10 11:29:09,726][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003588] [Batch 03588/03692] [00:33:08/00:00:57, 0.554s/it]: train_loss_raw=2.2924, running_loss=2.2679, LR=0.000100
[2025-08-10 11:29:16,305][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003600] [Batch 03600/03692] [00:33:15/00:00:50, 0.554s/it]: train_loss_raw=2.2017, running_loss=2.2634, LR=0.000100
[2025-08-10 11:29:22,789][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003612] [Batch 03612/03692] [00:33:22/00:00:44, 0.554s/it]: train_loss_raw=2.3149, running_loss=2.2624, LR=0.000100
[2025-08-10 11:29:29,364][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003624] [Batch 03624/03692] [00:33:28/00:00:37, 0.554s/it]: train_loss_raw=2.2053, running_loss=2.2613, LR=0.000100
[2025-08-10 11:29:35,962][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003636] [Batch 03636/03692] [00:33:35/00:00:31, 0.554s/it]: train_loss_raw=2.2961, running_loss=2.2623, LR=0.000100
[2025-08-10 11:29:42,547][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003648] [Batch 03648/03692] [00:33:41/00:00:24, 0.554s/it]: train_loss_raw=2.3308, running_loss=2.2613, LR=0.000100
[2025-08-10 11:29:49,019][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003660] [Batch 03660/03692] [00:33:48/00:00:17, 0.554s/it]: train_loss_raw=2.2416, running_loss=2.2601, LR=0.000100
[2025-08-10 11:29:55,572][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003672] [Batch 03672/03692] [00:33:54/00:00:11, 0.554s/it]: train_loss_raw=2.2771, running_loss=2.2589, LR=0.000100
[2025-08-10 11:30:02,185][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003684] [Batch 03684/03692] [00:34:01/00:00:04, 0.554s/it]: train_loss_raw=2.1450, running_loss=2.2568, LR=0.000100
[2025-08-10 11:30:12,196][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-10 11:30:15,062][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003693] [Batch 00011/00025] [00:00:02/00:00:03, 0.239s/it]
[2025-08-10 11:30:53,749][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003693] [Batch 00023/00025] [00:00:41/00:00:01, 1.731s/it]
[2025-08-10 11:31:10,590][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=2.25549, valid_loss=2.23427
[2025-08-10 11:31:10,591][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-10 11:31:10,591][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.857
[2025-08-10 11:31:10,592][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.018
[2025-08-10 11:31:10,592][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.019
[2025-08-10 11:31:10,592][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.000
[2025-08-10 11:31:10,595][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:35:09, remaining time 16:59:45, 00:35:09 per epoch
[2025-08-10 11:31:12,567][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003696] [Batch 00004/03692] [00:00:01/00:26:25, 0.430s/it]: train_loss_raw=2.2435, running_loss=2.2784, LR=0.000100
[2025-08-10 11:31:19,083][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003708] [Batch 00016/03692] [00:00:08/00:31:32, 0.515s/it]: train_loss_raw=2.3472, running_loss=2.2773, LR=0.000100
[2025-08-10 11:31:25,605][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003720] [Batch 00028/03692] [00:00:14/00:32:11, 0.527s/it]: train_loss_raw=2.3350, running_loss=2.2754, LR=0.000100
[2025-08-10 11:31:32,094][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003732] [Batch 00040/03692] [00:00:21/00:32:19, 0.531s/it]: train_loss_raw=2.1457, running_loss=2.2727, LR=0.000100
[2025-08-10 11:31:38,561][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003744] [Batch 00052/03692] [00:00:27/00:32:19, 0.533s/it]: train_loss_raw=2.2372, running_loss=2.2707, LR=0.000100
[2025-08-10 11:31:45,002][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003756] [Batch 00064/03692] [00:00:34/00:32:16, 0.534s/it]: train_loss_raw=2.2075, running_loss=2.2682, LR=0.000100
[2025-08-10 11:31:51,441][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003768] [Batch 00076/03692] [00:00:40/00:32:11, 0.534s/it]: train_loss_raw=2.3150, running_loss=2.2672, LR=0.000100
[2025-08-10 11:31:57,982][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003780] [Batch 00088/03692] [00:00:47/00:32:10, 0.536s/it]: train_loss_raw=2.3543, running_loss=2.2655, LR=0.000100
[2025-08-10 11:32:04,581][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003792] [Batch 00100/03692] [00:00:53/00:32:10, 0.537s/it]: train_loss_raw=2.3039, running_loss=2.2640, LR=0.000100
[2025-08-10 11:32:11,152][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003804] [Batch 00112/03692] [00:01:00/00:32:07, 0.538s/it]: train_loss_raw=2.2440, running_loss=2.2613, LR=0.000100
[2025-08-10 11:32:17,775][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003816] [Batch 00124/03692] [00:01:06/00:32:05, 0.540s/it]: train_loss_raw=2.3181, running_loss=2.2594, LR=0.000100
[2025-08-10 11:32:24,280][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003828] [Batch 00136/03692] [00:01:13/00:32:00, 0.540s/it]: train_loss_raw=2.1929, running_loss=2.2551, LR=0.000100
[2025-08-10 11:32:30,663][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003840] [Batch 00148/03692] [00:01:19/00:31:51, 0.539s/it]: train_loss_raw=2.2826, running_loss=2.2527, LR=0.000100
[2025-08-10 11:32:37,033][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003852] [Batch 00160/03692] [00:01:26/00:31:42, 0.539s/it]: train_loss_raw=2.1795, running_loss=2.2521, LR=0.000100
[2025-08-10 11:32:43,443][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003864] [Batch 00172/03692] [00:01:32/00:31:34, 0.538s/it]: train_loss_raw=2.1404, running_loss=2.2490, LR=0.000100
[2025-08-10 11:32:49,697][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003876] [Batch 00184/03692] [00:01:38/00:31:24, 0.537s/it]: train_loss_raw=2.2012, running_loss=2.2474, LR=0.000100
[2025-08-10 11:32:55,938][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003888] [Batch 00196/03692] [00:01:45/00:31:14, 0.536s/it]: train_loss_raw=2.3139, running_loss=2.2465, LR=0.000100
[2025-08-10 11:33:02,405][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003900] [Batch 00208/03692] [00:01:51/00:31:08, 0.536s/it]: train_loss_raw=2.2874, running_loss=2.2468, LR=0.000100
[2025-08-10 11:33:09,035][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003912] [Batch 00220/03692] [00:01:58/00:31:05, 0.537s/it]: train_loss_raw=2.2044, running_loss=2.2453, LR=0.000100
[2025-08-10 11:33:15,693][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003924] [Batch 00232/03692] [00:02:04/00:31:01, 0.538s/it]: train_loss_raw=2.2159, running_loss=2.2433, LR=0.000100
[2025-08-10 11:33:22,252][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003936] [Batch 00244/03692] [00:02:11/00:30:56, 0.539s/it]: train_loss_raw=2.2801, running_loss=2.2404, LR=0.000100
[2025-08-10 11:33:28,816][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003948] [Batch 00256/03692] [00:02:17/00:30:51, 0.539s/it]: train_loss_raw=2.1562, running_loss=2.2396, LR=0.000100
[2025-08-10 11:33:35,494][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003960] [Batch 00268/03692] [00:02:24/00:30:48, 0.540s/it]: train_loss_raw=2.2112, running_loss=2.2397, LR=0.000100
[2025-08-10 11:33:42,098][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003972] [Batch 00280/03692] [00:02:31/00:30:43, 0.540s/it]: train_loss_raw=2.2721, running_loss=2.2398, LR=0.000100
[2025-08-10 11:33:48,703][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003984] [Batch 00292/03692] [00:02:37/00:30:38, 0.541s/it]: train_loss_raw=2.2384, running_loss=2.2391, LR=0.000100
[2025-08-10 11:33:55,350][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003996] [Batch 00304/03692] [00:02:44/00:30:33, 0.541s/it]: train_loss_raw=2.3357, running_loss=2.2387, LR=0.000100
[2025-08-10 11:34:06,511][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004008] [Batch 00316/03692] [00:02:55/00:31:16, 0.556s/it]: train_loss_raw=2.2449, running_loss=2.2373, LR=0.000100
[2025-08-10 11:34:13,045][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004020] [Batch 00328/03692] [00:03:02/00:31:08, 0.555s/it]: train_loss_raw=2.2402, running_loss=2.2341, LR=0.000100
[2025-08-10 11:34:19,645][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004032] [Batch 00340/03692] [00:03:08/00:31:01, 0.555s/it]: train_loss_raw=2.1732, running_loss=2.2334, LR=0.000100
[2025-08-10 11:34:26,165][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004044] [Batch 00352/03692] [00:03:15/00:30:53, 0.555s/it]: train_loss_raw=2.2510, running_loss=2.2326, LR=0.000100
[2025-08-10 11:34:32,690][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004056] [Batch 00364/03692] [00:03:21/00:30:45, 0.555s/it]: train_loss_raw=2.2375, running_loss=2.2311, LR=0.000100
[2025-08-10 11:34:39,218][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004068] [Batch 00376/03692] [00:03:28/00:30:37, 0.554s/it]: train_loss_raw=2.1449, running_loss=2.2293, LR=0.000100
[2025-08-10 11:34:45,852][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004080] [Batch 00388/03692] [00:03:35/00:30:30, 0.554s/it]: train_loss_raw=2.2469, running_loss=2.2290, LR=0.000100
[2025-08-10 11:34:52,403][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004092] [Batch 00400/03692] [00:03:41/00:30:23, 0.554s/it]: train_loss_raw=2.1354, running_loss=2.2275, LR=0.000100
[2025-08-10 11:34:58,870][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004104] [Batch 00412/03692] [00:03:48/00:30:15, 0.553s/it]: train_loss_raw=2.2683, running_loss=2.2296, LR=0.000100
[2025-08-10 11:35:05,299][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004116] [Batch 00424/03692] [00:03:54/00:30:07, 0.553s/it]: train_loss_raw=2.1718, running_loss=2.2263, LR=0.000100
[2025-08-10 11:35:11,749][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004128] [Batch 00436/03692] [00:04:00/00:29:59, 0.553s/it]: train_loss_raw=2.2166, running_loss=2.2246, LR=0.000100
[2025-08-10 11:35:18,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004140] [Batch 00448/03692] [00:04:07/00:29:51, 0.552s/it]: train_loss_raw=2.2559, running_loss=2.2236, LR=0.000100
[2025-08-10 11:35:24,845][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004152] [Batch 00460/03692] [00:04:13/00:29:44, 0.552s/it]: train_loss_raw=2.2189, running_loss=2.2225, LR=0.000100
[2025-08-10 11:35:31,457][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004164] [Batch 00472/03692] [00:04:20/00:29:37, 0.552s/it]: train_loss_raw=2.2958, running_loss=2.2221, LR=0.000100
[2025-08-10 11:35:38,072][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004176] [Batch 00484/03692] [00:04:27/00:29:31, 0.552s/it]: train_loss_raw=2.2551, running_loss=2.2213, LR=0.000100
[2025-08-10 11:35:44,593][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004188] [Batch 00496/03692] [00:04:33/00:29:23, 0.552s/it]: train_loss_raw=2.2380, running_loss=2.2184, LR=0.000100
[2025-08-10 11:35:51,065][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004200] [Batch 00508/03692] [00:04:40/00:29:16, 0.552s/it]: train_loss_raw=2.0777, running_loss=2.2190, LR=0.000100
[2025-08-10 11:35:57,458][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004212] [Batch 00520/03692] [00:04:46/00:29:08, 0.551s/it]: train_loss_raw=2.2434, running_loss=2.2173, LR=0.000100
[2025-08-10 11:36:03,978][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004224] [Batch 00532/03692] [00:04:53/00:29:01, 0.551s/it]: train_loss_raw=2.2055, running_loss=2.2177, LR=0.000100
[2025-08-10 11:36:10,536][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004236] [Batch 00544/03692] [00:04:59/00:28:54, 0.551s/it]: train_loss_raw=2.1308, running_loss=2.2137, LR=0.000100
[2025-08-10 11:36:16,981][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004248] [Batch 00556/03692] [00:05:06/00:28:46, 0.551s/it]: train_loss_raw=2.2087, running_loss=2.2133, LR=0.000100
[2025-08-10 11:36:23,462][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004260] [Batch 00568/03692] [00:05:12/00:28:39, 0.550s/it]: train_loss_raw=2.2432, running_loss=2.2110, LR=0.000100
[2025-08-10 11:36:30,104][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004272] [Batch 00580/03692] [00:05:19/00:28:32, 0.550s/it]: train_loss_raw=2.1382, running_loss=2.2123, LR=0.000100
[2025-08-10 11:36:36,565][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004284] [Batch 00592/03692] [00:05:25/00:28:25, 0.550s/it]: train_loss_raw=2.2017, running_loss=2.2158, LR=0.000100
[2025-08-10 11:36:43,015][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004296] [Batch 00604/03692] [00:05:32/00:28:18, 0.550s/it]: train_loss_raw=2.1916, running_loss=2.2143, LR=0.000100
[2025-08-10 11:36:49,466][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004308] [Batch 00616/03692] [00:05:38/00:28:10, 0.550s/it]: train_loss_raw=2.3968, running_loss=2.2130, LR=0.000100
[2025-08-10 11:36:55,813][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004320] [Batch 00628/03692] [00:05:44/00:28:03, 0.549s/it]: train_loss_raw=2.2233, running_loss=2.2125, LR=0.000100
[2025-08-10 11:37:02,270][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004332] [Batch 00640/03692] [00:05:51/00:27:55, 0.549s/it]: train_loss_raw=2.2460, running_loss=2.2124, LR=0.000100
[2025-08-10 11:37:08,805][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004344] [Batch 00652/03692] [00:05:57/00:27:49, 0.549s/it]: train_loss_raw=2.2117, running_loss=2.2101, LR=0.000100
[2025-08-10 11:37:15,406][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004356] [Batch 00664/03692] [00:06:04/00:27:42, 0.549s/it]: train_loss_raw=2.2334, running_loss=2.2082, LR=0.000100
[2025-08-10 11:37:22,033][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004368] [Batch 00676/03692] [00:06:11/00:27:36, 0.549s/it]: train_loss_raw=2.1888, running_loss=2.2037, LR=0.000100
[2025-08-10 11:37:28,694][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004380] [Batch 00688/03692] [00:06:17/00:27:29, 0.549s/it]: train_loss_raw=2.1932, running_loss=2.2029, LR=0.000100
[2025-08-10 11:37:35,145][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004392] [Batch 00700/03692] [00:06:24/00:27:22, 0.549s/it]: train_loss_raw=2.3012, running_loss=2.2069, LR=0.000100
[2025-08-10 11:37:41,372][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004404] [Batch 00712/03692] [00:06:30/00:27:14, 0.548s/it]: train_loss_raw=2.2066, running_loss=2.2060, LR=0.000100
[2025-08-10 11:37:47,615][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004416] [Batch 00724/03692] [00:06:36/00:27:06, 0.548s/it]: train_loss_raw=2.1887, running_loss=2.2074, LR=0.000100
[2025-08-10 11:37:53,977][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004428] [Batch 00736/03692] [00:06:43/00:26:59, 0.548s/it]: train_loss_raw=2.2669, running_loss=2.2088, LR=0.000100
[2025-08-10 11:38:00,558][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004440] [Batch 00748/03692] [00:06:49/00:26:52, 0.548s/it]: train_loss_raw=2.2268, running_loss=2.2091, LR=0.000100
[2025-08-10 11:38:07,182][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004452] [Batch 00760/03692] [00:06:56/00:26:46, 0.548s/it]: train_loss_raw=2.1181, running_loss=2.2091, LR=0.000100
[2025-08-10 11:38:13,754][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004464] [Batch 00772/03692] [00:07:02/00:26:39, 0.548s/it]: train_loss_raw=2.2533, running_loss=2.2108, LR=0.000100
[2025-08-10 11:38:20,337][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004476] [Batch 00784/03692] [00:07:09/00:26:33, 0.548s/it]: train_loss_raw=2.0149, running_loss=2.2063, LR=0.000100
[2025-08-10 11:38:26,925][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004488] [Batch 00796/03692] [00:07:16/00:26:26, 0.548s/it]: train_loss_raw=2.2151, running_loss=2.2073, LR=0.000100
[2025-08-10 11:38:33,492][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004500] [Batch 00808/03692] [00:07:22/00:26:19, 0.548s/it]: train_loss_raw=2.2436, running_loss=2.2089, LR=0.000100
[2025-08-10 11:38:40,012][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004512] [Batch 00820/03692] [00:07:29/00:26:13, 0.548s/it]: train_loss_raw=2.2218, running_loss=2.2073, LR=0.000100
[2025-08-10 11:38:46,509][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004524] [Batch 00832/03692] [00:07:35/00:26:06, 0.548s/it]: train_loss_raw=2.1040, running_loss=2.2055, LR=0.000100
[2025-08-10 11:38:53,025][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004536] [Batch 00844/03692] [00:07:42/00:25:59, 0.548s/it]: train_loss_raw=2.2532, running_loss=2.2068, LR=0.000100
[2025-08-10 11:38:59,620][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004548] [Batch 00856/03692] [00:07:48/00:25:53, 0.548s/it]: train_loss_raw=2.1770, running_loss=2.2073, LR=0.000100
[2025-08-10 11:39:06,218][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004560] [Batch 00868/03692] [00:07:55/00:25:46, 0.548s/it]: train_loss_raw=2.2075, running_loss=2.2051, LR=0.000100
[2025-08-10 11:39:12,645][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004572] [Batch 00880/03692] [00:08:01/00:25:39, 0.547s/it]: train_loss_raw=2.1596, running_loss=2.2049, LR=0.000100
[2025-08-10 11:39:19,267][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004584] [Batch 00892/03692] [00:08:08/00:25:33, 0.548s/it]: train_loss_raw=2.1986, running_loss=2.2012, LR=0.000100
[2025-08-10 11:39:25,896][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004596] [Batch 00904/03692] [00:08:15/00:25:26, 0.548s/it]: train_loss_raw=2.2152, running_loss=2.2009, LR=0.000100
[2025-08-10 11:39:32,433][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004608] [Batch 00916/03692] [00:08:21/00:25:20, 0.548s/it]: train_loss_raw=2.2430, running_loss=2.2029, LR=0.000100
[2025-08-10 11:39:38,807][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004620] [Batch 00928/03692] [00:08:27/00:25:12, 0.547s/it]: train_loss_raw=2.2799, running_loss=2.1999, LR=0.000100
[2025-08-10 11:39:45,347][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004632] [Batch 00940/03692] [00:08:34/00:25:06, 0.547s/it]: train_loss_raw=2.1831, running_loss=2.1983, LR=0.000100
[2025-08-10 11:39:51,930][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004644] [Batch 00952/03692] [00:08:41/00:24:59, 0.547s/it]: train_loss_raw=2.1967, running_loss=2.1970, LR=0.000100
[2025-08-10 11:39:58,335][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004656] [Batch 00964/03692] [00:08:47/00:24:52, 0.547s/it]: train_loss_raw=2.1612, running_loss=2.1955, LR=0.000100
[2025-08-10 11:40:04,956][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004668] [Batch 00976/03692] [00:08:54/00:24:46, 0.547s/it]: train_loss_raw=2.1688, running_loss=2.1950, LR=0.000100
[2025-08-10 11:40:11,554][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004680] [Batch 00988/03692] [00:09:00/00:24:39, 0.547s/it]: train_loss_raw=2.2088, running_loss=2.1929, LR=0.000100
[2025-08-10 11:40:18,089][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004692] [Batch 01000/03692] [00:09:07/00:24:33, 0.547s/it]: train_loss_raw=2.1030, running_loss=2.1910, LR=0.000100
[2025-08-10 11:40:24,585][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004704] [Batch 01012/03692] [00:09:13/00:24:26, 0.547s/it]: train_loss_raw=2.0961, running_loss=2.1898, LR=0.000100
[2025-08-10 11:40:31,042][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004716] [Batch 01024/03692] [00:09:20/00:24:19, 0.547s/it]: train_loss_raw=2.1555, running_loss=2.1850, LR=0.000100
[2025-08-10 11:40:37,572][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004728] [Batch 01036/03692] [00:09:26/00:24:12, 0.547s/it]: train_loss_raw=2.2011, running_loss=2.1858, LR=0.000100
[2025-08-10 11:40:44,151][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004740] [Batch 01048/03692] [00:09:33/00:24:06, 0.547s/it]: train_loss_raw=2.0813, running_loss=2.1828, LR=0.000100
[2025-08-10 11:40:50,615][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004752] [Batch 01060/03692] [00:09:39/00:23:59, 0.547s/it]: train_loss_raw=2.1904, running_loss=2.1787, LR=0.000100
[2025-08-10 11:40:57,232][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004764] [Batch 01072/03692] [00:09:46/00:23:53, 0.547s/it]: train_loss_raw=2.1552, running_loss=2.1764, LR=0.000100
[2025-08-10 11:41:03,793][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004776] [Batch 01084/03692] [00:09:52/00:23:46, 0.547s/it]: train_loss_raw=2.2116, running_loss=2.1761, LR=0.000100
[2025-08-10 11:41:10,241][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004788] [Batch 01096/03692] [00:09:59/00:23:39, 0.547s/it]: train_loss_raw=2.1954, running_loss=2.1794, LR=0.000100
[2025-08-10 11:41:16,437][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004800] [Batch 01108/03692] [00:10:05/00:23:32, 0.547s/it]: train_loss_raw=2.1278, running_loss=2.1785, LR=0.000100
[2025-08-10 11:41:22,883][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004812] [Batch 01120/03692] [00:10:12/00:23:25, 0.546s/it]: train_loss_raw=2.1657, running_loss=2.1759, LR=0.000100
[2025-08-10 11:41:29,344][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004824] [Batch 01132/03692] [00:10:18/00:23:18, 0.546s/it]: train_loss_raw=2.1863, running_loss=2.1730, LR=0.000100
[2025-08-10 11:41:35,914][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004836] [Batch 01144/03692] [00:10:25/00:23:12, 0.546s/it]: train_loss_raw=2.1866, running_loss=2.1710, LR=0.000100
[2025-08-10 11:41:42,392][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004848] [Batch 01156/03692] [00:10:31/00:23:05, 0.546s/it]: train_loss_raw=2.2120, running_loss=2.1732, LR=0.000100
[2025-08-10 11:41:48,986][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004860] [Batch 01168/03692] [00:10:38/00:22:58, 0.546s/it]: train_loss_raw=2.2268, running_loss=2.1730, LR=0.000100
[2025-08-10 11:41:55,533][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004872] [Batch 01180/03692] [00:10:44/00:22:52, 0.546s/it]: train_loss_raw=2.2265, running_loss=2.1764, LR=0.000100
[2025-08-10 11:42:02,125][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004884] [Batch 01192/03692] [00:10:51/00:22:45, 0.546s/it]: train_loss_raw=2.2260, running_loss=2.1778, LR=0.000100
[2025-08-10 11:42:08,552][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004896] [Batch 01204/03692] [00:10:57/00:22:39, 0.546s/it]: train_loss_raw=2.1468, running_loss=2.1734, LR=0.000100
[2025-08-10 11:42:15,161][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004908] [Batch 01216/03692] [00:11:04/00:22:32, 0.546s/it]: train_loss_raw=2.1664, running_loss=2.1704, LR=0.000100
[2025-08-10 11:42:21,603][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004920] [Batch 01228/03692] [00:11:10/00:22:25, 0.546s/it]: train_loss_raw=2.2591, running_loss=2.1750, LR=0.000100
[2025-08-10 11:42:27,824][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004932] [Batch 01240/03692] [00:11:16/00:22:18, 0.546s/it]: train_loss_raw=2.1341, running_loss=2.1748, LR=0.000100
[2025-08-10 11:42:34,217][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004944] [Batch 01252/03692] [00:11:23/00:22:11, 0.546s/it]: train_loss_raw=2.2691, running_loss=2.1765, LR=0.000100
[2025-08-10 11:42:40,773][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004956] [Batch 01264/03692] [00:11:29/00:22:05, 0.546s/it]: train_loss_raw=2.2202, running_loss=2.1728, LR=0.000100
[2025-08-10 11:42:47,373][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004968] [Batch 01276/03692] [00:11:36/00:21:58, 0.546s/it]: train_loss_raw=2.2306, running_loss=2.1739, LR=0.000100
[2025-08-10 11:42:54,006][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004980] [Batch 01288/03692] [00:11:43/00:21:52, 0.546s/it]: train_loss_raw=2.1840, running_loss=2.1752, LR=0.000100
[2025-08-10 11:43:00,464][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004992] [Batch 01300/03692] [00:11:49/00:21:45, 0.546s/it]: train_loss_raw=2.2090, running_loss=2.1747, LR=0.000100
[2025-08-10 11:43:06,681][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005004] [Batch 01312/03692] [00:11:55/00:21:38, 0.546s/it]: train_loss_raw=2.2263, running_loss=2.1768, LR=0.000100
[2025-08-10 11:43:12,961][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005016] [Batch 01324/03692] [00:12:02/00:21:31, 0.545s/it]: train_loss_raw=2.0725, running_loss=2.1714, LR=0.000100
[2025-08-10 11:43:19,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005028] [Batch 01336/03692] [00:12:08/00:21:24, 0.545s/it]: train_loss_raw=2.0506, running_loss=2.1644, LR=0.000100
[2025-08-10 11:43:25,449][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005040] [Batch 01348/03692] [00:12:14/00:21:17, 0.545s/it]: train_loss_raw=2.2589, running_loss=2.1670, LR=0.000100
[2025-08-10 11:43:31,683][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005052] [Batch 01360/03692] [00:12:20/00:21:10, 0.545s/it]: train_loss_raw=2.1786, running_loss=2.1681, LR=0.000100
[2025-08-10 11:43:37,944][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005064] [Batch 01372/03692] [00:12:27/00:21:03, 0.545s/it]: train_loss_raw=2.1460, running_loss=2.1657, LR=0.000100
[2025-08-10 11:43:44,123][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005076] [Batch 01384/03692] [00:12:33/00:20:56, 0.544s/it]: train_loss_raw=2.1870, running_loss=2.1632, LR=0.000100
[2025-08-10 11:43:50,379][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005088] [Batch 01396/03692] [00:12:39/00:20:49, 0.544s/it]: train_loss_raw=2.2819, running_loss=2.1646, LR=0.000100
[2025-08-10 11:43:56,620][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005100] [Batch 01408/03692] [00:12:45/00:20:42, 0.544s/it]: train_loss_raw=2.0612, running_loss=2.1634, LR=0.000100
[2025-08-10 11:44:02,854][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005112] [Batch 01420/03692] [00:12:52/00:20:35, 0.544s/it]: train_loss_raw=2.1622, running_loss=2.1618, LR=0.000100
[2025-08-10 11:44:09,101][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005124] [Batch 01432/03692] [00:12:58/00:20:28, 0.543s/it]: train_loss_raw=2.1566, running_loss=2.1616, LR=0.000100
[2025-08-10 11:44:15,512][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005136] [Batch 01444/03692] [00:13:04/00:20:21, 0.543s/it]: train_loss_raw=2.1136, running_loss=2.1621, LR=0.000100
[2025-08-10 11:44:21,761][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005148] [Batch 01456/03692] [00:13:10/00:20:14, 0.543s/it]: train_loss_raw=2.1683, running_loss=2.1619, LR=0.000100
[2025-08-10 11:44:28,166][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005160] [Batch 01468/03692] [00:13:17/00:20:07, 0.543s/it]: train_loss_raw=2.1636, running_loss=2.1580, LR=0.000100
[2025-08-10 11:44:34,698][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005172] [Batch 01480/03692] [00:13:23/00:20:01, 0.543s/it]: train_loss_raw=2.1436, running_loss=2.1583, LR=0.000100
[2025-08-10 11:44:41,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005184] [Batch 01492/03692] [00:13:30/00:19:54, 0.543s/it]: train_loss_raw=2.1684, running_loss=2.1564, LR=0.000100
[2025-08-10 11:44:47,815][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005196] [Batch 01504/03692] [00:13:36/00:19:48, 0.543s/it]: train_loss_raw=2.1297, running_loss=2.1561, LR=0.000100
[2025-08-10 11:44:54,286][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005208] [Batch 01516/03692] [00:13:43/00:19:41, 0.543s/it]: train_loss_raw=2.1827, running_loss=2.1584, LR=0.000100
[2025-08-10 11:45:00,867][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005220] [Batch 01528/03692] [00:13:50/00:19:35, 0.543s/it]: train_loss_raw=2.1003, running_loss=2.1584, LR=0.000100
[2025-08-10 11:45:07,489][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005232] [Batch 01540/03692] [00:13:56/00:19:29, 0.543s/it]: train_loss_raw=2.2188, running_loss=2.1557, LR=0.000100
[2025-08-10 11:45:14,127][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005244] [Batch 01552/03692] [00:14:03/00:19:22, 0.543s/it]: train_loss_raw=2.1852, running_loss=2.1580, LR=0.000100
[2025-08-10 11:45:20,697][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005256] [Batch 01564/03692] [00:14:09/00:19:16, 0.543s/it]: train_loss_raw=2.0041, running_loss=2.1527, LR=0.000100
[2025-08-10 11:45:27,156][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005268] [Batch 01576/03692] [00:14:16/00:19:09, 0.543s/it]: train_loss_raw=2.1664, running_loss=2.1504, LR=0.000100
[2025-08-10 11:45:33,626][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005280] [Batch 01588/03692] [00:14:22/00:19:03, 0.543s/it]: train_loss_raw=2.0225, running_loss=2.1491, LR=0.000100
[2025-08-10 11:45:40,220][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005292] [Batch 01600/03692] [00:14:29/00:18:56, 0.543s/it]: train_loss_raw=2.1907, running_loss=2.1522, LR=0.000100
[2025-08-10 11:45:46,775][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005304] [Batch 01612/03692] [00:14:35/00:18:50, 0.543s/it]: train_loss_raw=2.1217, running_loss=2.1514, LR=0.000100
[2025-08-10 11:45:53,330][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005316] [Batch 01624/03692] [00:14:42/00:18:43, 0.543s/it]: train_loss_raw=2.0708, running_loss=2.1487, LR=0.000100
[2025-08-10 11:45:59,925][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005328] [Batch 01636/03692] [00:14:49/00:18:37, 0.543s/it]: train_loss_raw=2.2364, running_loss=2.1524, LR=0.000100
[2025-08-10 11:46:06,616][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005340] [Batch 01648/03692] [00:14:55/00:18:31, 0.544s/it]: train_loss_raw=2.1086, running_loss=2.1505, LR=0.000100
[2025-08-10 11:46:13,185][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005352] [Batch 01660/03692] [00:15:02/00:18:24, 0.544s/it]: train_loss_raw=2.1218, running_loss=2.1499, LR=0.000100
[2025-08-10 11:46:19,824][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005364] [Batch 01672/03692] [00:15:08/00:18:18, 0.544s/it]: train_loss_raw=2.1382, running_loss=2.1486, LR=0.000100
[2025-08-10 11:46:26,315][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005376] [Batch 01684/03692] [00:15:15/00:18:11, 0.544s/it]: train_loss_raw=2.1382, running_loss=2.1476, LR=0.000100
[2025-08-10 11:46:32,764][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005388] [Batch 01696/03692] [00:15:21/00:18:04, 0.544s/it]: train_loss_raw=2.1313, running_loss=2.1428, LR=0.000100
[2025-08-10 11:46:39,263][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005400] [Batch 01708/03692] [00:15:28/00:17:58, 0.544s/it]: train_loss_raw=2.0719, running_loss=2.1441, LR=0.000100
[2025-08-10 11:46:45,706][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005412] [Batch 01720/03692] [00:15:34/00:17:51, 0.544s/it]: train_loss_raw=2.1972, running_loss=2.1411, LR=0.000100
[2025-08-10 11:46:52,238][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005424] [Batch 01732/03692] [00:15:41/00:17:45, 0.544s/it]: train_loss_raw=2.1647, running_loss=2.1431, LR=0.000100
[2025-08-10 11:46:58,612][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005436] [Batch 01744/03692] [00:15:47/00:17:38, 0.543s/it]: train_loss_raw=2.1413, running_loss=2.1405, LR=0.000100
[2025-08-10 11:47:05,168][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005448] [Batch 01756/03692] [00:15:54/00:17:32, 0.543s/it]: train_loss_raw=2.0927, running_loss=2.1379, LR=0.000100
[2025-08-10 11:47:11,646][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005460] [Batch 01768/03692] [00:16:00/00:17:25, 0.543s/it]: train_loss_raw=2.0055, running_loss=2.1372, LR=0.000100
[2025-08-10 11:47:18,133][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005472] [Batch 01780/03692] [00:16:07/00:17:19, 0.543s/it]: train_loss_raw=2.1203, running_loss=2.1386, LR=0.000100
[2025-08-10 11:47:24,638][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005484] [Batch 01792/03692] [00:16:13/00:17:12, 0.543s/it]: train_loss_raw=2.1864, running_loss=2.1377, LR=0.000100
[2025-08-10 11:47:31,237][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005496] [Batch 01804/03692] [00:16:20/00:17:06, 0.543s/it]: train_loss_raw=2.1052, running_loss=2.1326, LR=0.000100
[2025-08-10 11:47:37,859][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005508] [Batch 01816/03692] [00:16:27/00:16:59, 0.544s/it]: train_loss_raw=2.2452, running_loss=2.1348, LR=0.000100
[2025-08-10 11:47:44,504][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005520] [Batch 01828/03692] [00:16:33/00:16:53, 0.544s/it]: train_loss_raw=2.1504, running_loss=2.1352, LR=0.000100
[2025-08-10 11:47:51,080][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005532] [Batch 01840/03692] [00:16:40/00:16:46, 0.544s/it]: train_loss_raw=2.1683, running_loss=2.1373, LR=0.000100
[2025-08-10 11:47:57,643][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005544] [Batch 01852/03692] [00:16:46/00:16:40, 0.544s/it]: train_loss_raw=2.2266, running_loss=2.1387, LR=0.000100
[2025-08-10 11:48:04,266][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005556] [Batch 01864/03692] [00:16:53/00:16:33, 0.544s/it]: train_loss_raw=1.9399, running_loss=2.1386, LR=0.000100
[2025-08-10 11:48:10,798][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005568] [Batch 01876/03692] [00:16:59/00:16:27, 0.544s/it]: train_loss_raw=2.0969, running_loss=2.1379, LR=0.000100
[2025-08-10 11:48:17,353][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005580] [Batch 01888/03692] [00:17:06/00:16:20, 0.544s/it]: train_loss_raw=2.1490, running_loss=2.1378, LR=0.000100
[2025-08-10 11:48:23,659][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005592] [Batch 01900/03692] [00:17:12/00:16:14, 0.544s/it]: train_loss_raw=2.1099, running_loss=2.1383, LR=0.000100
[2025-08-10 11:48:30,298][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005604] [Batch 01912/03692] [00:17:19/00:16:07, 0.544s/it]: train_loss_raw=2.0994, running_loss=2.1364, LR=0.000100
[2025-08-10 11:48:36,944][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005616] [Batch 01924/03692] [00:17:26/00:16:01, 0.544s/it]: train_loss_raw=2.1374, running_loss=2.1351, LR=0.000100
[2025-08-10 11:48:43,631][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005628] [Batch 01936/03692] [00:17:32/00:15:54, 0.544s/it]: train_loss_raw=2.1236, running_loss=2.1322, LR=0.000100
[2025-08-10 11:48:50,201][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005640] [Batch 01948/03692] [00:17:39/00:15:48, 0.544s/it]: train_loss_raw=2.1602, running_loss=2.1323, LR=0.000100
[2025-08-10 11:48:56,683][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005652] [Batch 01960/03692] [00:17:45/00:15:41, 0.544s/it]: train_loss_raw=2.0258, running_loss=2.1291, LR=0.000100
[2025-08-10 11:49:03,320][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005664] [Batch 01972/03692] [00:17:52/00:15:35, 0.544s/it]: train_loss_raw=2.1610, running_loss=2.1289, LR=0.000100
[2025-08-10 11:49:09,923][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005676] [Batch 01984/03692] [00:17:59/00:15:28, 0.544s/it]: train_loss_raw=2.0986, running_loss=2.1285, LR=0.000100
[2025-08-10 11:49:16,606][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005688] [Batch 01996/03692] [00:18:05/00:15:22, 0.544s/it]: train_loss_raw=2.2051, running_loss=2.1320, LR=0.000100
[2025-08-10 11:49:23,145][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005700] [Batch 02008/03692] [00:18:12/00:15:16, 0.544s/it]: train_loss_raw=2.1961, running_loss=2.1323, LR=0.000100
[2025-08-10 11:49:29,715][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005712] [Batch 02020/03692] [00:18:18/00:15:09, 0.544s/it]: train_loss_raw=2.2151, running_loss=2.1340, LR=0.000100
[2025-08-10 11:49:36,296][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005724] [Batch 02032/03692] [00:18:25/00:15:03, 0.544s/it]: train_loss_raw=2.0905, running_loss=2.1312, LR=0.000100
[2025-08-10 11:49:42,768][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005736] [Batch 02044/03692] [00:18:31/00:14:56, 0.544s/it]: train_loss_raw=2.1135, running_loss=2.1307, LR=0.000100
[2025-08-10 11:49:49,210][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005748] [Batch 02056/03692] [00:18:38/00:14:49, 0.544s/it]: train_loss_raw=2.0645, running_loss=2.1273, LR=0.000100
[2025-08-10 11:49:55,640][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005760] [Batch 02068/03692] [00:18:44/00:14:43, 0.544s/it]: train_loss_raw=1.9706, running_loss=2.1239, LR=0.000100
[2025-08-10 11:50:02,080][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005772] [Batch 02080/03692] [00:18:51/00:14:36, 0.544s/it]: train_loss_raw=2.0795, running_loss=2.1225, LR=0.000100
[2025-08-10 11:50:08,526][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005784] [Batch 02092/03692] [00:18:57/00:14:30, 0.544s/it]: train_loss_raw=2.1197, running_loss=2.1244, LR=0.000100
[2025-08-10 11:50:14,954][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005796] [Batch 02104/03692] [00:19:04/00:14:23, 0.544s/it]: train_loss_raw=2.1599, running_loss=2.1261, LR=0.000100
[2025-08-10 11:50:21,592][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005808] [Batch 02116/03692] [00:19:10/00:14:17, 0.544s/it]: train_loss_raw=2.0172, running_loss=2.1235, LR=0.000100
[2025-08-10 11:50:28,173][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005820] [Batch 02128/03692] [00:19:17/00:14:10, 0.544s/it]: train_loss_raw=2.1198, running_loss=2.1239, LR=0.000100
[2025-08-10 11:50:34,763][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005832] [Batch 02140/03692] [00:19:23/00:14:04, 0.544s/it]: train_loss_raw=2.1215, running_loss=2.1227, LR=0.000100
[2025-08-10 11:50:41,222][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005844] [Batch 02152/03692] [00:19:30/00:13:57, 0.544s/it]: train_loss_raw=2.2010, running_loss=2.1236, LR=0.000100
[2025-08-10 11:50:54,657][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005856] [Batch 02164/03692] [00:19:43/00:13:55, 0.547s/it]: train_loss_raw=2.0620, running_loss=2.1193, LR=0.000100
[2025-08-10 11:51:00,865][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005868] [Batch 02176/03692] [00:19:50/00:13:49, 0.547s/it]: train_loss_raw=2.1115, running_loss=2.1223, LR=0.000100
[2025-08-10 11:51:07,175][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005880] [Batch 02188/03692] [00:19:56/00:13:42, 0.547s/it]: train_loss_raw=2.1317, running_loss=2.1203, LR=0.000100
[2025-08-10 11:51:13,631][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005892] [Batch 02200/03692] [00:20:02/00:13:35, 0.547s/it]: train_loss_raw=2.0204, running_loss=2.1166, LR=0.000100
[2025-08-10 11:51:20,269][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005904] [Batch 02212/03692] [00:20:09/00:13:29, 0.547s/it]: train_loss_raw=2.1379, running_loss=2.1164, LR=0.000100
[2025-08-10 11:51:26,757][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005916] [Batch 02224/03692] [00:20:15/00:13:22, 0.547s/it]: train_loss_raw=2.1314, running_loss=2.1146, LR=0.000100
[2025-08-10 11:51:33,372][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005928] [Batch 02236/03692] [00:20:22/00:13:16, 0.547s/it]: train_loss_raw=2.1233, running_loss=2.1139, LR=0.000100
[2025-08-10 11:51:39,972][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005940] [Batch 02248/03692] [00:20:29/00:13:09, 0.547s/it]: train_loss_raw=2.1541, running_loss=2.1153, LR=0.000100
[2025-08-10 11:51:46,598][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005952] [Batch 02260/03692] [00:20:35/00:13:03, 0.547s/it]: train_loss_raw=2.0002, running_loss=2.1150, LR=0.000100
[2025-08-10 11:51:53,196][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005964] [Batch 02272/03692] [00:20:42/00:12:56, 0.547s/it]: train_loss_raw=2.0716, running_loss=2.1144, LR=0.000100
[2025-08-10 11:51:59,768][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005976] [Batch 02284/03692] [00:20:48/00:12:49, 0.547s/it]: train_loss_raw=2.0662, running_loss=2.1151, LR=0.000100
[2025-08-10 11:52:06,403][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005988] [Batch 02296/03692] [00:20:55/00:12:43, 0.547s/it]: train_loss_raw=2.0611, running_loss=2.1138, LR=0.000100
[2025-08-10 11:52:12,986][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006000] [Batch 02308/03692] [00:21:02/00:12:36, 0.547s/it]: train_loss_raw=2.1695, running_loss=2.1153, LR=0.000100
[2025-08-10 11:52:25,020][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006012] [Batch 02320/03692] [00:21:14/00:12:33, 0.549s/it]: train_loss_raw=2.0862, running_loss=2.1137, LR=0.000100
[2025-08-10 11:52:31,664][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006024] [Batch 02332/03692] [00:21:20/00:12:26, 0.549s/it]: train_loss_raw=2.0660, running_loss=2.1136, LR=0.000100
[2025-08-10 11:52:38,251][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006036] [Batch 02344/03692] [00:21:27/00:12:20, 0.549s/it]: train_loss_raw=2.0960, running_loss=2.1124, LR=0.000100
[2025-08-10 11:52:44,909][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006048] [Batch 02356/03692] [00:21:34/00:12:13, 0.549s/it]: train_loss_raw=2.1552, running_loss=2.1096, LR=0.000100
[2025-08-10 11:52:51,454][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006060] [Batch 02368/03692] [00:21:40/00:12:07, 0.549s/it]: train_loss_raw=2.0674, running_loss=2.1082, LR=0.000100
[2025-08-10 11:52:58,095][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006072] [Batch 02380/03692] [00:21:47/00:12:00, 0.549s/it]: train_loss_raw=2.1626, running_loss=2.1081, LR=0.000100
[2025-08-10 11:53:04,728][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006084] [Batch 02392/03692] [00:21:53/00:11:54, 0.549s/it]: train_loss_raw=1.9912, running_loss=2.1070, LR=0.000100
[2025-08-10 11:53:11,300][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006096] [Batch 02404/03692] [00:22:00/00:11:47, 0.549s/it]: train_loss_raw=2.0074, running_loss=2.1033, LR=0.000100
[2025-08-10 11:53:17,839][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006108] [Batch 02416/03692] [00:22:06/00:11:40, 0.549s/it]: train_loss_raw=2.1593, running_loss=2.1027, LR=0.000100
[2025-08-10 11:53:24,317][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006120] [Batch 02428/03692] [00:22:13/00:11:34, 0.549s/it]: train_loss_raw=1.9546, running_loss=2.0993, LR=0.000100
[2025-08-10 11:53:30,784][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006132] [Batch 02440/03692] [00:22:19/00:11:27, 0.549s/it]: train_loss_raw=2.1132, running_loss=2.1020, LR=0.000100
[2025-08-10 11:53:37,329][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006144] [Batch 02452/03692] [00:22:26/00:11:20, 0.549s/it]: train_loss_raw=2.0563, running_loss=2.1026, LR=0.000100
[2025-08-10 11:53:43,893][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006156] [Batch 02464/03692] [00:22:33/00:11:14, 0.549s/it]: train_loss_raw=2.1353, running_loss=2.1019, LR=0.000100
[2025-08-10 11:53:50,553][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006168] [Batch 02476/03692] [00:22:39/00:11:07, 0.549s/it]: train_loss_raw=2.1103, running_loss=2.1023, LR=0.000100
[2025-08-10 11:53:57,030][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006180] [Batch 02488/03692] [00:22:46/00:11:01, 0.549s/it]: train_loss_raw=2.0667, running_loss=2.1002, LR=0.000100
[2025-08-10 11:54:03,461][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006192] [Batch 02500/03692] [00:22:52/00:10:54, 0.549s/it]: train_loss_raw=2.1354, running_loss=2.0986, LR=0.000100
[2025-08-10 11:54:09,960][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006204] [Batch 02512/03692] [00:22:59/00:10:47, 0.549s/it]: train_loss_raw=2.0915, running_loss=2.0941, LR=0.000100
[2025-08-10 11:54:16,397][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006216] [Batch 02524/03692] [00:23:05/00:10:41, 0.549s/it]: train_loss_raw=2.0829, running_loss=2.0944, LR=0.000100
[2025-08-10 11:54:22,870][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006228] [Batch 02536/03692] [00:23:12/00:10:34, 0.549s/it]: train_loss_raw=2.1311, running_loss=2.0952, LR=0.000100
[2025-08-10 11:54:29,397][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006240] [Batch 02548/03692] [00:23:18/00:10:27, 0.549s/it]: train_loss_raw=2.0503, running_loss=2.0923, LR=0.000100
[2025-08-10 11:54:36,043][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006252] [Batch 02560/03692] [00:23:25/00:10:21, 0.549s/it]: train_loss_raw=2.1223, running_loss=2.0939, LR=0.000100
[2025-08-10 11:54:42,683][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006264] [Batch 02572/03692] [00:23:31/00:10:14, 0.549s/it]: train_loss_raw=2.0908, running_loss=2.0960, LR=0.000100
[2025-08-10 11:54:49,377][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006276] [Batch 02584/03692] [00:23:38/00:10:08, 0.549s/it]: train_loss_raw=2.0802, running_loss=2.0955, LR=0.000100
[2025-08-10 11:54:55,952][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006288] [Batch 02596/03692] [00:23:45/00:10:01, 0.549s/it]: train_loss_raw=2.0362, running_loss=2.0967, LR=0.000100
[2025-08-10 11:55:02,602][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006300] [Batch 02608/03692] [00:23:51/00:09:55, 0.549s/it]: train_loss_raw=1.9470, running_loss=2.0910, LR=0.000100
[2025-08-10 11:55:09,301][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006312] [Batch 02620/03692] [00:23:58/00:09:48, 0.549s/it]: train_loss_raw=2.1546, running_loss=2.0889, LR=0.000100
[2025-08-10 11:55:15,998][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006324] [Batch 02632/03692] [00:24:05/00:09:42, 0.549s/it]: train_loss_raw=2.0958, running_loss=2.0895, LR=0.000100
[2025-08-10 11:55:22,662][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006336] [Batch 02644/03692] [00:24:11/00:09:35, 0.549s/it]: train_loss_raw=2.0437, running_loss=2.0902, LR=0.000100
[2025-08-10 11:55:29,211][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006348] [Batch 02656/03692] [00:24:18/00:09:28, 0.549s/it]: train_loss_raw=2.1063, running_loss=2.0889, LR=0.000100
[2025-08-10 11:55:35,513][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006360] [Batch 02668/03692] [00:24:24/00:09:22, 0.549s/it]: train_loss_raw=2.0986, running_loss=2.0858, LR=0.000100
[2025-08-10 11:55:41,953][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006372] [Batch 02680/03692] [00:24:31/00:09:15, 0.549s/it]: train_loss_raw=2.1060, running_loss=2.0879, LR=0.000100
[2025-08-10 11:55:48,098][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006384] [Batch 02692/03692] [00:24:37/00:09:08, 0.549s/it]: train_loss_raw=2.0854, running_loss=2.0885, LR=0.000100
[2025-08-10 11:55:54,493][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006396] [Batch 02704/03692] [00:24:43/00:09:02, 0.549s/it]: train_loss_raw=2.0828, running_loss=2.0930, LR=0.000100
[2025-08-10 11:56:01,056][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006408] [Batch 02716/03692] [00:24:50/00:08:55, 0.549s/it]: train_loss_raw=2.1227, running_loss=2.0914, LR=0.000100
[2025-08-10 11:56:07,710][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006420] [Batch 02728/03692] [00:24:56/00:08:48, 0.549s/it]: train_loss_raw=2.1343, running_loss=2.0905, LR=0.000100
[2025-08-10 11:56:14,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006432] [Batch 02740/03692] [00:25:03/00:08:42, 0.549s/it]: train_loss_raw=2.1102, running_loss=2.0929, LR=0.000100
[2025-08-10 11:56:20,961][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006444] [Batch 02752/03692] [00:25:10/00:08:35, 0.549s/it]: train_loss_raw=2.0764, running_loss=2.0896, LR=0.000100
[2025-08-10 11:56:27,609][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006456] [Batch 02764/03692] [00:25:16/00:08:29, 0.549s/it]: train_loss_raw=2.0791, running_loss=2.0881, LR=0.000100
[2025-08-10 11:56:34,213][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006468] [Batch 02776/03692] [00:25:23/00:08:22, 0.549s/it]: train_loss_raw=2.0571, running_loss=2.0854, LR=0.000100
[2025-08-10 11:56:40,812][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006480] [Batch 02788/03692] [00:25:29/00:08:16, 0.549s/it]: train_loss_raw=2.1458, running_loss=2.0880, LR=0.000100
[2025-08-10 11:56:47,342][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006492] [Batch 02800/03692] [00:25:36/00:08:09, 0.549s/it]: train_loss_raw=2.0451, running_loss=2.0868, LR=0.000100
[2025-08-10 11:56:53,872][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006504] [Batch 02812/03692] [00:25:43/00:08:02, 0.549s/it]: train_loss_raw=2.0700, running_loss=2.0846, LR=0.000100
[2025-08-10 11:57:00,443][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006516] [Batch 02824/03692] [00:25:49/00:07:56, 0.549s/it]: train_loss_raw=2.0638, running_loss=2.0844, LR=0.000100
[2025-08-10 11:57:07,078][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006528] [Batch 02836/03692] [00:25:56/00:07:49, 0.549s/it]: train_loss_raw=1.9720, running_loss=2.0858, LR=0.000100
[2025-08-10 11:57:13,677][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006540] [Batch 02848/03692] [00:26:02/00:07:43, 0.549s/it]: train_loss_raw=2.0426, running_loss=2.0838, LR=0.000100
[2025-08-10 11:57:20,309][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006552] [Batch 02860/03692] [00:26:09/00:07:36, 0.549s/it]: train_loss_raw=1.9762, running_loss=2.0851, LR=0.000100
[2025-08-10 11:57:26,887][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006564] [Batch 02872/03692] [00:26:16/00:07:29, 0.549s/it]: train_loss_raw=2.1419, running_loss=2.0867, LR=0.000100
[2025-08-10 11:57:33,518][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006576] [Batch 02884/03692] [00:26:22/00:07:23, 0.549s/it]: train_loss_raw=1.9967, running_loss=2.0871, LR=0.000100
[2025-08-10 11:57:40,173][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006588] [Batch 02896/03692] [00:26:29/00:07:16, 0.549s/it]: train_loss_raw=2.1758, running_loss=2.0886, LR=0.000100
[2025-08-10 11:57:46,763][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006600] [Batch 02908/03692] [00:26:35/00:07:10, 0.549s/it]: train_loss_raw=2.0561, running_loss=2.0869, LR=0.000100
[2025-08-10 11:57:53,397][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006612] [Batch 02920/03692] [00:26:42/00:07:03, 0.549s/it]: train_loss_raw=2.0483, running_loss=2.0863, LR=0.000100
[2025-08-10 11:57:59,987][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006624] [Batch 02932/03692] [00:26:49/00:06:57, 0.549s/it]: train_loss_raw=2.0866, running_loss=2.0889, LR=0.000100
[2025-08-10 11:58:06,577][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006636] [Batch 02944/03692] [00:26:55/00:06:50, 0.549s/it]: train_loss_raw=2.0097, running_loss=2.0886, LR=0.000100
[2025-08-10 11:58:13,089][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006648] [Batch 02956/03692] [00:27:02/00:06:43, 0.549s/it]: train_loss_raw=2.0484, running_loss=2.0875, LR=0.000100
[2025-08-10 11:58:19,532][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006660] [Batch 02968/03692] [00:27:08/00:06:37, 0.549s/it]: train_loss_raw=1.9824, running_loss=2.0843, LR=0.000100
[2025-08-10 11:58:26,052][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006672] [Batch 02980/03692] [00:27:15/00:06:30, 0.549s/it]: train_loss_raw=1.9599, running_loss=2.0821, LR=0.000100
[2025-08-10 11:58:32,600][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006684] [Batch 02992/03692] [00:27:21/00:06:24, 0.549s/it]: train_loss_raw=2.1371, running_loss=2.0785, LR=0.000100
[2025-08-10 11:58:39,032][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006696] [Batch 03004/03692] [00:27:28/00:06:17, 0.549s/it]: train_loss_raw=2.0658, running_loss=2.0776, LR=0.000100
[2025-08-10 11:58:45,475][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006708] [Batch 03016/03692] [00:27:34/00:06:10, 0.549s/it]: train_loss_raw=1.9815, running_loss=2.0740, LR=0.000100
[2025-08-10 11:58:51,777][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006720] [Batch 03028/03692] [00:27:40/00:06:04, 0.549s/it]: train_loss_raw=2.1623, running_loss=2.0754, LR=0.000100
[2025-08-10 11:58:58,152][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006732] [Batch 03040/03692] [00:27:47/00:05:57, 0.548s/it]: train_loss_raw=2.1014, running_loss=2.0753, LR=0.000100
[2025-08-10 11:59:04,676][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006744] [Batch 03052/03692] [00:27:53/00:05:50, 0.548s/it]: train_loss_raw=2.0601, running_loss=2.0728, LR=0.000100
[2025-08-10 11:59:11,218][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006756] [Batch 03064/03692] [00:28:00/00:05:44, 0.548s/it]: train_loss_raw=1.9938, running_loss=2.0707, LR=0.000100
[2025-08-10 11:59:17,792][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006768] [Batch 03076/03692] [00:28:06/00:05:37, 0.548s/it]: train_loss_raw=2.1315, running_loss=2.0747, LR=0.000100
[2025-08-10 11:59:24,378][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006780] [Batch 03088/03692] [00:28:13/00:05:31, 0.548s/it]: train_loss_raw=2.0396, running_loss=2.0714, LR=0.000100
[2025-08-10 11:59:30,977][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006792] [Batch 03100/03692] [00:28:20/00:05:24, 0.548s/it]: train_loss_raw=2.0049, running_loss=2.0735, LR=0.000100
[2025-08-10 11:59:37,614][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006804] [Batch 03112/03692] [00:28:26/00:05:18, 0.548s/it]: train_loss_raw=2.1100, running_loss=2.0724, LR=0.000100
[2025-08-10 11:59:44,179][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006816] [Batch 03124/03692] [00:28:33/00:05:11, 0.548s/it]: train_loss_raw=2.0473, running_loss=2.0724, LR=0.000100
[2025-08-10 11:59:50,846][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006828] [Batch 03136/03692] [00:28:39/00:05:04, 0.548s/it]: train_loss_raw=2.0607, running_loss=2.0718, LR=0.000100
[2025-08-10 11:59:57,454][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006840] [Batch 03148/03692] [00:28:46/00:04:58, 0.548s/it]: train_loss_raw=2.0999, running_loss=2.0708, LR=0.000100
[2025-08-10 12:00:04,070][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006852] [Batch 03160/03692] [00:28:53/00:04:51, 0.548s/it]: train_loss_raw=2.0926, running_loss=2.0691, LR=0.000100
[2025-08-10 12:00:10,682][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006864] [Batch 03172/03692] [00:28:59/00:04:45, 0.548s/it]: train_loss_raw=1.9773, running_loss=2.0700, LR=0.000100
[2025-08-10 12:00:17,409][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006876] [Batch 03184/03692] [00:29:06/00:04:38, 0.549s/it]: train_loss_raw=2.0218, running_loss=2.0708, LR=0.000100
[2025-08-10 12:00:24,123][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006888] [Batch 03196/03692] [00:29:13/00:04:32, 0.549s/it]: train_loss_raw=2.0845, running_loss=2.0713, LR=0.000100
[2025-08-10 12:00:30,836][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006900] [Batch 03208/03692] [00:29:19/00:04:25, 0.549s/it]: train_loss_raw=1.9089, running_loss=2.0652, LR=0.000100
[2025-08-10 12:00:37,273][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006912] [Batch 03220/03692] [00:29:26/00:04:18, 0.549s/it]: train_loss_raw=2.0621, running_loss=2.0680, LR=0.000100
[2025-08-10 12:00:43,497][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006924] [Batch 03232/03692] [00:29:32/00:04:12, 0.548s/it]: train_loss_raw=2.1089, running_loss=2.0700, LR=0.000100
[2025-08-10 12:00:49,908][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006936] [Batch 03244/03692] [00:29:39/00:04:05, 0.548s/it]: train_loss_raw=2.1361, running_loss=2.0713, LR=0.000100
[2025-08-10 12:00:56,476][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006948] [Batch 03256/03692] [00:29:45/00:03:59, 0.548s/it]: train_loss_raw=2.0791, running_loss=2.0715, LR=0.000100
[2025-08-10 12:01:02,996][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006960] [Batch 03268/03692] [00:29:52/00:03:52, 0.548s/it]: train_loss_raw=2.0502, running_loss=2.0705, LR=0.000100
[2025-08-10 12:01:09,708][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006972] [Batch 03280/03692] [00:29:58/00:03:45, 0.548s/it]: train_loss_raw=2.1262, running_loss=2.0754, LR=0.000100
[2025-08-10 12:01:16,378][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006984] [Batch 03292/03692] [00:30:05/00:03:39, 0.548s/it]: train_loss_raw=2.0793, running_loss=2.0750, LR=0.000100
[2025-08-10 12:01:22,958][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006996] [Batch 03304/03692] [00:30:12/00:03:32, 0.548s/it]: train_loss_raw=2.0541, running_loss=2.0726, LR=0.000100
[2025-08-10 12:01:29,620][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007008] [Batch 03316/03692] [00:30:18/00:03:26, 0.548s/it]: train_loss_raw=2.0771, running_loss=2.0712, LR=0.000100
[2025-08-10 12:01:36,154][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007020] [Batch 03328/03692] [00:30:25/00:03:19, 0.548s/it]: train_loss_raw=2.0618, running_loss=2.0720, LR=0.000100
[2025-08-10 12:01:42,692][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007032] [Batch 03340/03692] [00:30:31/00:03:13, 0.548s/it]: train_loss_raw=2.1246, running_loss=2.0717, LR=0.000100
[2025-08-10 12:01:49,212][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007044] [Batch 03352/03692] [00:30:38/00:03:06, 0.548s/it]: train_loss_raw=2.1641, running_loss=2.0677, LR=0.000100
[2025-08-10 12:01:55,797][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007056] [Batch 03364/03692] [00:30:44/00:02:59, 0.548s/it]: train_loss_raw=2.0807, running_loss=2.0625, LR=0.000100
[2025-08-10 12:02:02,374][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007068] [Batch 03376/03692] [00:30:51/00:02:53, 0.548s/it]: train_loss_raw=2.0991, running_loss=2.0659, LR=0.000100
[2025-08-10 12:02:08,958][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007080] [Batch 03388/03692] [00:30:58/00:02:46, 0.548s/it]: train_loss_raw=2.0563, running_loss=2.0634, LR=0.000100
[2025-08-10 12:02:15,438][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007092] [Batch 03400/03692] [00:31:04/00:02:40, 0.548s/it]: train_loss_raw=2.0435, running_loss=2.0571, LR=0.000100
[2025-08-10 12:02:22,008][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007104] [Batch 03412/03692] [00:31:11/00:02:33, 0.548s/it]: train_loss_raw=2.1025, running_loss=2.0603, LR=0.000100
[2025-08-10 12:02:28,641][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007116] [Batch 03424/03692] [00:31:17/00:02:26, 0.548s/it]: train_loss_raw=2.0947, running_loss=2.0606, LR=0.000100
[2025-08-10 12:02:35,204][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007128] [Batch 03436/03692] [00:31:24/00:02:20, 0.548s/it]: train_loss_raw=2.0613, running_loss=2.0622, LR=0.000100
[2025-08-10 12:02:41,623][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007140] [Batch 03448/03692] [00:31:30/00:02:13, 0.548s/it]: train_loss_raw=2.1313, running_loss=2.0646, LR=0.000100
[2025-08-10 12:02:48,311][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007152] [Batch 03460/03692] [00:31:37/00:02:07, 0.548s/it]: train_loss_raw=2.1353, running_loss=2.0615, LR=0.000100
[2025-08-10 12:02:54,902][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007164] [Batch 03472/03692] [00:31:44/00:02:00, 0.548s/it]: train_loss_raw=2.0959, running_loss=2.0602, LR=0.000100
[2025-08-10 12:03:01,409][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007176] [Batch 03484/03692] [00:31:50/00:01:54, 0.548s/it]: train_loss_raw=2.0510, running_loss=2.0588, LR=0.000100
[2025-08-10 12:03:07,885][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007188] [Batch 03496/03692] [00:31:57/00:01:47, 0.548s/it]: train_loss_raw=2.0823, running_loss=2.0571, LR=0.000100
[2025-08-10 12:03:14,405][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007200] [Batch 03508/03692] [00:32:03/00:01:40, 0.548s/it]: train_loss_raw=2.0809, running_loss=2.0589, LR=0.000100
[2025-08-10 12:03:21,018][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007212] [Batch 03520/03692] [00:32:10/00:01:34, 0.548s/it]: train_loss_raw=2.0916, running_loss=2.0541, LR=0.000100
[2025-08-10 12:03:27,514][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007224] [Batch 03532/03692] [00:32:16/00:01:27, 0.548s/it]: train_loss_raw=2.1280, running_loss=2.0512, LR=0.000100
[2025-08-10 12:03:33,974][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007236] [Batch 03544/03692] [00:32:23/00:01:21, 0.548s/it]: train_loss_raw=2.1164, running_loss=2.0506, LR=0.000100
[2025-08-10 12:03:40,469][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007248] [Batch 03556/03692] [00:32:29/00:01:14, 0.548s/it]: train_loss_raw=1.9859, running_loss=2.0487, LR=0.000100
[2025-08-10 12:03:47,013][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007260] [Batch 03568/03692] [00:32:36/00:01:07, 0.548s/it]: train_loss_raw=2.0908, running_loss=2.0500, LR=0.000100
[2025-08-10 12:03:53,598][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007272] [Batch 03580/03692] [00:32:42/00:01:01, 0.548s/it]: train_loss_raw=2.0579, running_loss=2.0496, LR=0.000100
[2025-08-10 12:04:00,261][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007284] [Batch 03592/03692] [00:32:49/00:00:54, 0.548s/it]: train_loss_raw=1.9961, running_loss=2.0517, LR=0.000100
[2025-08-10 12:04:06,728][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007296] [Batch 03604/03692] [00:32:55/00:00:48, 0.548s/it]: train_loss_raw=1.9519, running_loss=2.0504, LR=0.000100
[2025-08-10 12:04:13,237][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007308] [Batch 03616/03692] [00:33:02/00:00:41, 0.548s/it]: train_loss_raw=2.0778, running_loss=2.0504, LR=0.000100
[2025-08-10 12:04:19,827][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007320] [Batch 03628/03692] [00:33:08/00:00:35, 0.548s/it]: train_loss_raw=2.0710, running_loss=2.0504, LR=0.000100
[2025-08-10 12:04:26,451][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007332] [Batch 03640/03692] [00:33:15/00:00:28, 0.548s/it]: train_loss_raw=2.0542, running_loss=2.0508, LR=0.000100
[2025-08-10 12:04:33,089][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007344] [Batch 03652/03692] [00:33:22/00:00:21, 0.548s/it]: train_loss_raw=2.1155, running_loss=2.0533, LR=0.000100
[2025-08-10 12:04:39,644][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007356] [Batch 03664/03692] [00:33:28/00:00:15, 0.548s/it]: train_loss_raw=1.9793, running_loss=2.0537, LR=0.000100
[2025-08-10 12:04:46,067][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007368] [Batch 03676/03692] [00:33:35/00:00:08, 0.548s/it]: train_loss_raw=1.9903, running_loss=2.0538, LR=0.000100
[2025-08-10 12:04:52,597][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007380] [Batch 03688/03692] [00:33:41/00:00:02, 0.548s/it]: train_loss_raw=1.9871, running_loss=2.0551, LR=0.000100
[2025-08-10 12:05:30,003][__main__][INFO] - [VALIDATION] [Epoch 01/29] Starting validation.
[2025-08-10 12:06:07,540][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 007385] [Batch 00011/00025] [00:00:37/00:00:40, 3.128s/it]
[2025-08-10 12:06:25,926][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 007385] [Batch 00023/00025] [00:00:55/00:00:02, 2.330s/it]
[2025-08-10 12:06:27,099][__main__][INFO] - [VALIDATION] [Epoch 01/29] train_loss=2.05496, valid_loss=2.00637
[2025-08-10 12:06:27,100][__main__][INFO] - [VALIDATION] [Epoch 01/29] Metrics:
[2025-08-10 12:06:27,100][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_er      0.767
[2025-08-10 12:06:27,100][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_prec    0.026
[2025-08-10 12:06:27,100][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_recall  0.026
[2025-08-10 12:06:27,100][__main__][INFO] - [VALIDATION] [Epoch 01/29] - pep_recall 0.000
[2025-08-10 12:06:27,104][__main__][INFO] - [TRAIN] [Epoch 01/29] Epoch complete, total time 01:10:26, remaining time 16:26:09, 00:35:13 per epoch
[2025-08-10 12:06:31,379][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007392] [Batch 00008/03692] [00:00:03/00:30:34, 0.498s/it]: train_loss_raw=2.0199, running_loss=2.0963, LR=0.000100
[2025-08-10 12:06:38,014][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007404] [Batch 00020/03692] [00:00:10/00:32:29, 0.531s/it]: train_loss_raw=2.0817, running_loss=2.0912, LR=0.000100
[2025-08-10 12:06:44,646][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007416] [Batch 00032/03692] [00:00:17/00:32:53, 0.539s/it]: train_loss_raw=2.0777, running_loss=2.0857, LR=0.000100
[2025-08-10 12:06:51,270][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007428] [Batch 00044/03692] [00:00:23/00:32:59, 0.543s/it]: train_loss_raw=2.0959, running_loss=2.0816, LR=0.000100
[2025-08-10 12:06:57,992][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007440] [Batch 00056/03692] [00:00:30/00:33:06, 0.546s/it]: train_loss_raw=1.9881, running_loss=2.0747, LR=0.000100
[2025-08-10 12:07:04,609][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007452] [Batch 00068/03692] [00:00:37/00:33:03, 0.547s/it]: train_loss_raw=2.0398, running_loss=2.0715, LR=0.000100
[2025-08-10 12:07:10,877][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007464] [Batch 00080/03692] [00:00:43/00:32:43, 0.544s/it]: train_loss_raw=2.0926, running_loss=2.0692, LR=0.000100
[2025-08-10 12:07:17,379][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007476] [Batch 00092/03692] [00:00:49/00:32:35, 0.543s/it]: train_loss_raw=2.0274, running_loss=2.0686, LR=0.000100
[2025-08-10 12:07:23,937][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007488] [Batch 00104/03692] [00:00:56/00:32:30, 0.544s/it]: train_loss_raw=1.9814, running_loss=2.0610, LR=0.000100
[2025-08-10 12:07:30,535][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007500] [Batch 00116/03692] [00:01:03/00:32:26, 0.544s/it]: train_loss_raw=2.0731, running_loss=2.0601, LR=0.000100
[2025-08-10 12:07:37,164][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007512] [Batch 00128/03692] [00:01:09/00:32:22, 0.545s/it]: train_loss_raw=2.1096, running_loss=2.0600, LR=0.000100
[2025-08-10 12:07:43,816][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007524] [Batch 00140/03692] [00:01:16/00:32:18, 0.546s/it]: train_loss_raw=1.8804, running_loss=2.0557, LR=0.000100
[2025-08-10 12:07:50,478][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007536] [Batch 00152/03692] [00:01:23/00:32:14, 0.547s/it]: train_loss_raw=2.1158, running_loss=2.0529, LR=0.000100
[2025-08-10 12:07:57,082][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007548] [Batch 00164/03692] [00:01:29/00:32:09, 0.547s/it]: train_loss_raw=2.0117, running_loss=2.0492, LR=0.000100
[2025-08-10 12:08:03,650][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007560] [Batch 00176/03692] [00:01:36/00:32:02, 0.547s/it]: train_loss_raw=2.0033, running_loss=2.0471, LR=0.000100
[2025-08-10 12:08:10,188][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007572] [Batch 00188/03692] [00:01:42/00:31:55, 0.547s/it]: train_loss_raw=1.9749, running_loss=2.0454, LR=0.000100
[2025-08-10 12:08:16,791][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007584] [Batch 00200/03692] [00:01:49/00:31:50, 0.547s/it]: train_loss_raw=2.0359, running_loss=2.0451, LR=0.000100
[2025-08-10 12:08:23,292][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007596] [Batch 00212/03692] [00:01:55/00:31:42, 0.547s/it]: train_loss_raw=2.0564, running_loss=2.0430, LR=0.000100
[2025-08-10 12:08:29,835][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007608] [Batch 00224/03692] [00:02:02/00:31:35, 0.547s/it]: train_loss_raw=1.9587, running_loss=2.0386, LR=0.000100
[2025-08-10 12:08:36,322][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007620] [Batch 00236/03692] [00:02:08/00:31:28, 0.546s/it]: train_loss_raw=2.0023, running_loss=2.0366, LR=0.000100
[2025-08-10 12:08:42,858][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007632] [Batch 00248/03692] [00:02:15/00:31:21, 0.546s/it]: train_loss_raw=1.9809, running_loss=2.0359, LR=0.000100
[2025-08-10 12:08:49,475][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007644] [Batch 00260/03692] [00:02:22/00:31:15, 0.546s/it]: train_loss_raw=2.0329, running_loss=2.0352, LR=0.000100
[2025-08-10 12:08:55,981][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007656] [Batch 00272/03692] [00:02:28/00:31:08, 0.546s/it]: train_loss_raw=2.0548, running_loss=2.0311, LR=0.000100
[2025-08-10 12:09:02,452][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007668] [Batch 00284/03692] [00:02:35/00:31:00, 0.546s/it]: train_loss_raw=2.1636, running_loss=2.0327, LR=0.000100
[2025-08-10 12:09:08,997][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007680] [Batch 00296/03692] [00:02:41/00:30:54, 0.546s/it]: train_loss_raw=1.9366, running_loss=2.0341, LR=0.000100
[2025-08-10 12:09:15,589][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007692] [Batch 00308/03692] [00:02:48/00:30:47, 0.546s/it]: train_loss_raw=2.0314, running_loss=2.0370, LR=0.000100
[2025-08-10 12:09:22,186][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007704] [Batch 00320/03692] [00:02:54/00:30:41, 0.546s/it]: train_loss_raw=2.0022, running_loss=2.0372, LR=0.000100
[2025-08-10 12:09:28,829][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007716] [Batch 00332/03692] [00:03:01/00:30:36, 0.546s/it]: train_loss_raw=2.0120, running_loss=2.0394, LR=0.000100
[2025-08-10 12:09:35,460][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007728] [Batch 00344/03692] [00:03:08/00:30:30, 0.547s/it]: train_loss_raw=1.9404, running_loss=2.0341, LR=0.000100
[2025-08-10 12:09:41,719][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007740] [Batch 00356/03692] [00:03:14/00:30:20, 0.546s/it]: train_loss_raw=2.0052, running_loss=2.0295, LR=0.000100
[2025-08-10 12:09:48,018][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007752] [Batch 00368/03692] [00:03:20/00:30:12, 0.545s/it]: train_loss_raw=2.0559, running_loss=2.0278, LR=0.000100
[2025-08-10 12:09:54,374][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007764] [Batch 00380/03692] [00:03:26/00:30:03, 0.545s/it]: train_loss_raw=2.0730, running_loss=2.0319, LR=0.000100
[2025-08-10 12:10:00,809][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007776] [Batch 00392/03692] [00:03:33/00:29:56, 0.544s/it]: train_loss_raw=2.0551, running_loss=2.0323, LR=0.000100
[2025-08-10 12:10:07,382][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007788] [Batch 00404/03692] [00:03:39/00:29:50, 0.545s/it]: train_loss_raw=2.0410, running_loss=2.0331, LR=0.000100
[2025-08-10 12:10:14,025][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007800] [Batch 00416/03692] [00:03:46/00:29:44, 0.545s/it]: train_loss_raw=1.9873, running_loss=2.0335, LR=0.000100
[2025-08-10 12:10:20,579][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007812] [Batch 00428/03692] [00:03:53/00:29:38, 0.545s/it]: train_loss_raw=2.0017, running_loss=2.0347, LR=0.000100
[2025-08-10 12:10:27,149][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007824] [Batch 00440/03692] [00:03:59/00:29:32, 0.545s/it]: train_loss_raw=2.0535, running_loss=2.0367, LR=0.000100
[2025-08-10 12:10:33,689][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007836] [Batch 00452/03692] [00:04:06/00:29:25, 0.545s/it]: train_loss_raw=1.9614, running_loss=2.0345, LR=0.000100
[2025-08-10 12:10:40,292][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007848] [Batch 00464/03692] [00:04:12/00:29:19, 0.545s/it]: train_loss_raw=1.8832, running_loss=2.0330, LR=0.000100
[2025-08-10 12:10:46,887][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007860] [Batch 00476/03692] [00:04:19/00:29:13, 0.545s/it]: train_loss_raw=2.1075, running_loss=2.0323, LR=0.000100
[2025-08-10 12:10:53,169][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007872] [Batch 00488/03692] [00:04:25/00:29:04, 0.545s/it]: train_loss_raw=2.1058, running_loss=2.0309, LR=0.000100
[2025-08-10 12:10:59,394][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007884] [Batch 00500/03692] [00:04:32/00:28:56, 0.544s/it]: train_loss_raw=2.1124, running_loss=2.0284, LR=0.000100
[2025-08-10 12:11:05,617][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007896] [Batch 00512/03692] [00:04:38/00:28:48, 0.543s/it]: train_loss_raw=2.0256, running_loss=2.0302, LR=0.000100
[2025-08-10 12:11:11,800][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007908] [Batch 00524/03692] [00:04:44/00:28:39, 0.543s/it]: train_loss_raw=1.9860, running_loss=2.0306, LR=0.000100
[2025-08-10 12:11:18,006][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007920] [Batch 00536/03692] [00:04:50/00:28:31, 0.542s/it]: train_loss_raw=1.9276, running_loss=2.0253, LR=0.000100
[2025-08-10 12:11:24,254][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007932] [Batch 00548/03692] [00:04:56/00:28:23, 0.542s/it]: train_loss_raw=1.9455, running_loss=2.0245, LR=0.000100
[2025-08-10 12:11:30,488][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007944] [Batch 00560/03692] [00:05:03/00:28:15, 0.541s/it]: train_loss_raw=2.0807, running_loss=2.0296, LR=0.000100
[2025-08-10 12:11:36,690][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007956] [Batch 00572/03692] [00:05:09/00:28:07, 0.541s/it]: train_loss_raw=2.0619, running_loss=2.0281, LR=0.000100
[2025-08-10 12:11:42,963][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007968] [Batch 00584/03692] [00:05:15/00:27:59, 0.540s/it]: train_loss_raw=2.0548, running_loss=2.0305, LR=0.000100
[2025-08-10 12:11:49,229][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007980] [Batch 00596/03692] [00:05:21/00:27:51, 0.540s/it]: train_loss_raw=2.0066, running_loss=2.0302, LR=0.000100
[2025-08-10 12:11:55,634][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007992] [Batch 00608/03692] [00:05:28/00:27:44, 0.540s/it]: train_loss_raw=2.0551, running_loss=2.0280, LR=0.000100
[2025-08-10 12:12:06,973][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008004] [Batch 00620/03692] [00:05:39/00:28:02, 0.548s/it]: train_loss_raw=2.0157, running_loss=2.0262, LR=0.000100
[2025-08-10 12:12:13,441][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008016] [Batch 00632/03692] [00:05:46/00:27:55, 0.548s/it]: train_loss_raw=2.0879, running_loss=2.0260, LR=0.000100
[2025-08-10 12:12:20,075][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008028] [Batch 00644/03692] [00:05:52/00:27:49, 0.548s/it]: train_loss_raw=2.0520, running_loss=2.0260, LR=0.000100
[2025-08-10 12:12:26,661][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008040] [Batch 00656/03692] [00:05:59/00:27:42, 0.548s/it]: train_loss_raw=1.8924, running_loss=2.0213, LR=0.000100
[2025-08-10 12:12:32,967][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008052] [Batch 00668/03692] [00:06:05/00:27:34, 0.547s/it]: train_loss_raw=2.0592, running_loss=2.0246, LR=0.000100
[2025-08-10 12:12:39,509][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008064] [Batch 00680/03692] [00:06:12/00:27:28, 0.547s/it]: train_loss_raw=2.0976, running_loss=2.0259, LR=0.000100
[2025-08-10 12:12:46,037][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008076] [Batch 00692/03692] [00:06:18/00:27:21, 0.547s/it]: train_loss_raw=2.0212, running_loss=2.0227, LR=0.000100
[2025-08-10 12:12:52,665][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008088] [Batch 00704/03692] [00:06:25/00:27:15, 0.547s/it]: train_loss_raw=2.1464, running_loss=2.0277, LR=0.000100
[2025-08-10 12:12:59,239][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008100] [Batch 00716/03692] [00:06:31/00:27:08, 0.547s/it]: train_loss_raw=2.0377, running_loss=2.0258, LR=0.000100
[2025-08-10 12:13:05,516][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008112] [Batch 00728/03692] [00:06:38/00:27:00, 0.547s/it]: train_loss_raw=1.9738, running_loss=2.0239, LR=0.000100
[2025-08-10 12:13:11,697][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008124] [Batch 00740/03692] [00:06:44/00:26:52, 0.546s/it]: train_loss_raw=1.9180, running_loss=2.0246, LR=0.000100
[2025-08-10 12:13:17,925][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008136] [Batch 00752/03692] [00:06:50/00:26:45, 0.546s/it]: train_loss_raw=1.9751, running_loss=2.0211, LR=0.000100
[2025-08-10 12:13:24,539][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008148] [Batch 00764/03692] [00:06:57/00:26:38, 0.546s/it]: train_loss_raw=2.0951, running_loss=2.0208, LR=0.000100
[2025-08-10 12:13:31,141][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008160] [Batch 00776/03692] [00:07:03/00:26:32, 0.546s/it]: train_loss_raw=1.8714, running_loss=2.0175, LR=0.000100
[2025-08-10 12:13:37,634][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008172] [Batch 00788/03692] [00:07:10/00:26:25, 0.546s/it]: train_loss_raw=2.0454, running_loss=2.0177, LR=0.000100
[2025-08-10 12:13:44,131][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008184] [Batch 00800/03692] [00:07:16/00:26:18, 0.546s/it]: train_loss_raw=2.0521, running_loss=2.0156, LR=0.000100
[2025-08-10 12:13:50,689][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008196] [Batch 00812/03692] [00:07:23/00:26:12, 0.546s/it]: train_loss_raw=1.9676, running_loss=2.0122, LR=0.000100
[2025-08-10 12:13:57,240][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008208] [Batch 00824/03692] [00:07:29/00:26:05, 0.546s/it]: train_loss_raw=2.1431, running_loss=2.0128, LR=0.000100
[2025-08-10 12:14:03,746][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008220] [Batch 00836/03692] [00:07:36/00:25:59, 0.546s/it]: train_loss_raw=2.0358, running_loss=2.0108, LR=0.000100
[2025-08-10 12:14:10,305][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008232] [Batch 00848/03692] [00:07:42/00:25:52, 0.546s/it]: train_loss_raw=2.0312, running_loss=2.0072, LR=0.000100
[2025-08-10 12:14:16,897][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008244] [Batch 00860/03692] [00:07:49/00:25:46, 0.546s/it]: train_loss_raw=2.0414, running_loss=2.0086, LR=0.000100
[2025-08-10 12:14:23,555][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008256] [Batch 00872/03692] [00:07:56/00:25:39, 0.546s/it]: train_loss_raw=1.9326, running_loss=2.0080, LR=0.000100
[2025-08-10 12:14:30,090][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008268] [Batch 00884/03692] [00:08:02/00:25:33, 0.546s/it]: train_loss_raw=1.9461, running_loss=2.0061, LR=0.000100
[2025-08-10 12:14:36,587][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008280] [Batch 00896/03692] [00:08:09/00:25:26, 0.546s/it]: train_loss_raw=2.0295, running_loss=2.0071, LR=0.000100
[2025-08-10 12:14:43,123][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008292] [Batch 00908/03692] [00:08:15/00:25:19, 0.546s/it]: train_loss_raw=2.0858, running_loss=2.0156, LR=0.000100
[2025-08-10 12:14:49,640][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008304] [Batch 00920/03692] [00:08:22/00:25:13, 0.546s/it]: train_loss_raw=2.1050, running_loss=2.0195, LR=0.000100
[2025-08-10 12:14:56,254][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008316] [Batch 00932/03692] [00:08:28/00:25:06, 0.546s/it]: train_loss_raw=2.0580, running_loss=2.0209, LR=0.000100
[2025-08-10 12:15:02,821][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008328] [Batch 00944/03692] [00:08:35/00:25:00, 0.546s/it]: train_loss_raw=1.9701, running_loss=2.0153, LR=0.000100
[2025-08-10 12:15:09,342][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008340] [Batch 00956/03692] [00:08:41/00:24:53, 0.546s/it]: train_loss_raw=2.1000, running_loss=2.0116, LR=0.000100
[2025-08-10 12:15:16,042][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008352] [Batch 00968/03692] [00:08:48/00:24:47, 0.546s/it]: train_loss_raw=1.9495, running_loss=2.0088, LR=0.000100
[2025-08-10 12:15:22,598][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008364] [Batch 00980/03692] [00:08:55/00:24:41, 0.546s/it]: train_loss_raw=2.0153, running_loss=2.0128, LR=0.000100
[2025-08-10 12:15:28,994][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008376] [Batch 00992/03692] [00:09:01/00:24:34, 0.546s/it]: train_loss_raw=1.9943, running_loss=2.0121, LR=0.000100
[2025-08-10 12:15:35,485][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008388] [Batch 01004/03692] [00:09:08/00:24:27, 0.546s/it]: train_loss_raw=2.0511, running_loss=2.0089, LR=0.000100
[2025-08-10 12:15:41,931][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008400] [Batch 01016/03692] [00:09:14/00:24:20, 0.546s/it]: train_loss_raw=2.0165, running_loss=2.0085, LR=0.000100
[2025-08-10 12:15:48,412][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008412] [Batch 01028/03692] [00:09:21/00:24:13, 0.546s/it]: train_loss_raw=2.0611, running_loss=2.0106, LR=0.000100
[2025-08-10 12:15:54,977][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008424] [Batch 01040/03692] [00:09:27/00:24:07, 0.546s/it]: train_loss_raw=1.9957, running_loss=2.0055, LR=0.000100
[2025-08-10 12:16:01,429][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008436] [Batch 01052/03692] [00:09:34/00:24:00, 0.546s/it]: train_loss_raw=2.1028, running_loss=2.0138, LR=0.000100
[2025-08-10 12:16:07,889][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008448] [Batch 01064/03692] [00:09:40/00:23:53, 0.546s/it]: train_loss_raw=2.0125, running_loss=2.0179, LR=0.000100
[2025-08-10 12:16:14,323][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008460] [Batch 01076/03692] [00:09:46/00:23:46, 0.545s/it]: train_loss_raw=2.0251, running_loss=2.0110, LR=0.000100
[2025-08-10 12:16:20,792][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008472] [Batch 01088/03692] [00:09:53/00:23:40, 0.545s/it]: train_loss_raw=1.9124, running_loss=2.0088, LR=0.000100
[2025-08-10 12:16:27,217][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008484] [Batch 01100/03692] [00:09:59/00:23:33, 0.545s/it]: train_loss_raw=2.0818, running_loss=2.0083, LR=0.000100
[2025-08-10 12:16:33,634][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008496] [Batch 01112/03692] [00:10:06/00:23:26, 0.545s/it]: train_loss_raw=2.0851, running_loss=2.0109, LR=0.000100
[2025-08-10 12:16:40,123][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008508] [Batch 01124/03692] [00:10:12/00:23:19, 0.545s/it]: train_loss_raw=2.0691, running_loss=2.0115, LR=0.000100
[2025-08-10 12:16:46,585][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008520] [Batch 01136/03692] [00:10:19/00:23:13, 0.545s/it]: train_loss_raw=2.0127, running_loss=2.0124, LR=0.000100
[2025-08-10 12:16:53,033][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008532] [Batch 01148/03692] [00:10:25/00:23:06, 0.545s/it]: train_loss_raw=2.0429, running_loss=2.0086, LR=0.000100
[2025-08-10 12:16:59,484][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008544] [Batch 01160/03692] [00:10:32/00:22:59, 0.545s/it]: train_loss_raw=1.9824, running_loss=2.0110, LR=0.000100
[2025-08-10 12:17:05,883][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008556] [Batch 01172/03692] [00:10:38/00:22:52, 0.545s/it]: train_loss_raw=1.9996, running_loss=2.0116, LR=0.000100
[2025-08-10 12:17:12,368][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008568] [Batch 01184/03692] [00:10:44/00:22:46, 0.545s/it]: train_loss_raw=1.9690, running_loss=2.0125, LR=0.000100
[2025-08-10 12:17:18,820][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008580] [Batch 01196/03692] [00:10:51/00:22:39, 0.545s/it]: train_loss_raw=2.0530, running_loss=2.0127, LR=0.000100
[2025-08-10 12:17:25,269][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008592] [Batch 01208/03692] [00:10:57/00:22:32, 0.545s/it]: train_loss_raw=1.8842, running_loss=2.0113, LR=0.000100
[2025-08-10 12:17:31,641][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008604] [Batch 01220/03692] [00:11:04/00:22:25, 0.544s/it]: train_loss_raw=2.0392, running_loss=2.0117, LR=0.000100
[2025-08-10 12:17:38,124][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008616] [Batch 01232/03692] [00:11:10/00:22:19, 0.544s/it]: train_loss_raw=1.9119, running_loss=2.0091, LR=0.000100
[2025-08-10 12:17:44,673][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008628] [Batch 01244/03692] [00:11:17/00:22:12, 0.544s/it]: train_loss_raw=2.0444, running_loss=2.0117, LR=0.000100
[2025-08-10 12:17:51,246][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008640] [Batch 01256/03692] [00:11:23/00:22:06, 0.544s/it]: train_loss_raw=2.0490, running_loss=2.0083, LR=0.000100
[2025-08-10 12:17:57,859][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008652] [Batch 01268/03692] [00:11:30/00:21:59, 0.545s/it]: train_loss_raw=2.0253, running_loss=2.0072, LR=0.000100
[2025-08-10 12:18:04,304][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008664] [Batch 01280/03692] [00:11:36/00:21:53, 0.544s/it]: train_loss_raw=1.9477, running_loss=2.0079, LR=0.000100
[2025-08-10 12:18:10,793][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008676] [Batch 01292/03692] [00:11:43/00:21:46, 0.544s/it]: train_loss_raw=1.9513, running_loss=2.0076, LR=0.000100
[2025-08-10 12:18:17,396][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008688] [Batch 01304/03692] [00:11:50/00:21:40, 0.544s/it]: train_loss_raw=1.8624, running_loss=2.0048, LR=0.000100
[2025-08-10 12:18:23,991][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008700] [Batch 01316/03692] [00:11:56/00:21:33, 0.545s/it]: train_loss_raw=2.0199, running_loss=2.0054, LR=0.000100
[2025-08-10 12:18:30,593][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008712] [Batch 01328/03692] [00:12:03/00:21:27, 0.545s/it]: train_loss_raw=2.0009, running_loss=2.0054, LR=0.000100
[2025-08-10 12:18:37,181][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008724] [Batch 01340/03692] [00:12:09/00:21:20, 0.545s/it]: train_loss_raw=2.0241, running_loss=2.0046, LR=0.000100
[2025-08-10 12:18:43,708][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008736] [Batch 01352/03692] [00:12:16/00:21:14, 0.545s/it]: train_loss_raw=2.1320, running_loss=2.0054, LR=0.000100
[2025-08-10 12:18:50,259][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008748] [Batch 01364/03692] [00:12:22/00:21:07, 0.545s/it]: train_loss_raw=1.9755, running_loss=2.0029, LR=0.000100
[2025-08-10 12:18:56,773][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008760] [Batch 01376/03692] [00:12:29/00:21:01, 0.545s/it]: train_loss_raw=2.0420, running_loss=2.0023, LR=0.000100
[2025-08-10 12:19:03,109][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008772] [Batch 01388/03692] [00:12:35/00:20:54, 0.544s/it]: train_loss_raw=1.8886, running_loss=1.9985, LR=0.000100
[2025-08-10 12:19:09,670][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008784] [Batch 01400/03692] [00:12:42/00:20:47, 0.544s/it]: train_loss_raw=1.9990, running_loss=2.0021, LR=0.000100
[2025-08-10 12:19:16,239][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008796] [Batch 01412/03692] [00:12:48/00:20:41, 0.545s/it]: train_loss_raw=2.0234, running_loss=2.0016, LR=0.000100
[2025-08-10 12:19:22,854][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008808] [Batch 01424/03692] [00:12:55/00:20:35, 0.545s/it]: train_loss_raw=1.9683, running_loss=2.0001, LR=0.000100
[2025-08-10 12:19:29,482][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008820] [Batch 01436/03692] [00:13:02/00:20:28, 0.545s/it]: train_loss_raw=1.9659, running_loss=1.9960, LR=0.000100
[2025-08-10 12:19:36,004][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008832] [Batch 01448/03692] [00:13:08/00:20:22, 0.545s/it]: train_loss_raw=2.1017, running_loss=1.9998, LR=0.000100
[2025-08-10 12:19:42,541][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008844] [Batch 01460/03692] [00:13:15/00:20:15, 0.545s/it]: train_loss_raw=2.0034, running_loss=1.9958, LR=0.000100
[2025-08-10 12:19:49,190][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008856] [Batch 01472/03692] [00:13:21/00:20:09, 0.545s/it]: train_loss_raw=1.9183, running_loss=1.9950, LR=0.000100
[2025-08-10 12:19:55,768][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008868] [Batch 01484/03692] [00:13:28/00:20:02, 0.545s/it]: train_loss_raw=2.0453, running_loss=1.9993, LR=0.000100
[2025-08-10 12:20:02,248][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008880] [Batch 01496/03692] [00:13:34/00:19:56, 0.545s/it]: train_loss_raw=1.9009, running_loss=1.9981, LR=0.000100
[2025-08-10 12:20:08,869][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008892] [Batch 01508/03692] [00:13:41/00:19:49, 0.545s/it]: train_loss_raw=2.0002, running_loss=1.9999, LR=0.000100
[2025-08-10 12:20:15,298][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008904] [Batch 01520/03692] [00:13:47/00:19:43, 0.545s/it]: train_loss_raw=2.0080, running_loss=1.9997, LR=0.000100
[2025-08-10 12:20:21,728][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008916] [Batch 01532/03692] [00:13:54/00:19:36, 0.545s/it]: train_loss_raw=2.0394, running_loss=2.0007, LR=0.000100
[2025-08-10 12:20:51,469][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008928] [Batch 01544/03692] [00:14:24/00:20:02, 0.560s/it]: train_loss_raw=1.9600, running_loss=2.0002, LR=0.000100
[2025-08-10 12:20:58,123][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008940] [Batch 01556/03692] [00:14:30/00:19:55, 0.560s/it]: train_loss_raw=2.0047, running_loss=1.9995, LR=0.000100
[2025-08-10 12:21:04,616][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008952] [Batch 01568/03692] [00:14:37/00:19:48, 0.559s/it]: train_loss_raw=1.8289, running_loss=1.9982, LR=0.000100
[2025-08-10 12:21:11,104][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008964] [Batch 01580/03692] [00:14:43/00:19:41, 0.559s/it]: train_loss_raw=1.9357, running_loss=1.9969, LR=0.000100
[2025-08-10 12:21:17,676][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008976] [Batch 01592/03692] [00:14:50/00:19:34, 0.559s/it]: train_loss_raw=1.9764, running_loss=1.9959, LR=0.000100
[2025-08-10 12:21:24,230][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008988] [Batch 01604/03692] [00:14:56/00:19:27, 0.559s/it]: train_loss_raw=2.0698, running_loss=1.9981, LR=0.000100
[2025-08-10 12:21:30,823][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009000] [Batch 01616/03692] [00:15:03/00:19:20, 0.559s/it]: train_loss_raw=2.1229, running_loss=2.0013, LR=0.000100
[2025-08-10 12:21:37,450][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009012] [Batch 01628/03692] [00:15:10/00:19:13, 0.559s/it]: train_loss_raw=1.8717, running_loss=1.9985, LR=0.000100
[2025-08-10 12:21:44,080][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009024] [Batch 01640/03692] [00:15:16/00:19:06, 0.559s/it]: train_loss_raw=1.9826, running_loss=1.9962, LR=0.000100
[2025-08-10 12:21:50,619][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009036] [Batch 01652/03692] [00:15:23/00:19:00, 0.559s/it]: train_loss_raw=1.9846, running_loss=1.9937, LR=0.000100
[2025-08-10 12:21:57,220][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009048] [Batch 01664/03692] [00:15:29/00:18:53, 0.559s/it]: train_loss_raw=1.8802, running_loss=1.9916, LR=0.000100
[2025-08-10 12:22:03,730][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009060] [Batch 01676/03692] [00:15:36/00:18:46, 0.559s/it]: train_loss_raw=1.9876, running_loss=1.9908, LR=0.000100
[2025-08-10 12:22:10,218][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009072] [Batch 01688/03692] [00:15:42/00:18:39, 0.559s/it]: train_loss_raw=1.9326, running_loss=1.9919, LR=0.000100
[2025-08-10 12:22:16,619][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009084] [Batch 01700/03692] [00:15:49/00:18:32, 0.558s/it]: train_loss_raw=1.9808, running_loss=1.9946, LR=0.000100
[2025-08-10 12:22:23,024][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009096] [Batch 01712/03692] [00:15:55/00:18:25, 0.558s/it]: train_loss_raw=1.9695, running_loss=1.9899, LR=0.000100
[2025-08-10 12:22:29,525][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009108] [Batch 01724/03692] [00:16:02/00:18:18, 0.558s/it]: train_loss_raw=2.0106, running_loss=1.9910, LR=0.000100
[2025-08-10 12:22:36,018][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009120] [Batch 01736/03692] [00:16:08/00:18:11, 0.558s/it]: train_loss_raw=1.9959, running_loss=1.9900, LR=0.000100
[2025-08-10 12:22:42,453][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009132] [Batch 01748/03692] [00:16:15/00:18:04, 0.558s/it]: train_loss_raw=2.0602, running_loss=1.9921, LR=0.000100
[2025-08-10 12:22:48,871][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009144] [Batch 01760/03692] [00:16:21/00:17:57, 0.558s/it]: train_loss_raw=1.9172, running_loss=1.9878, LR=0.000100
[2025-08-10 12:22:55,445][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009156] [Batch 01772/03692] [00:16:28/00:17:50, 0.558s/it]: train_loss_raw=1.9413, running_loss=1.9847, LR=0.000100
[2025-08-10 12:23:02,099][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009168] [Batch 01784/03692] [00:16:34/00:17:43, 0.558s/it]: train_loss_raw=1.9781, running_loss=1.9868, LR=0.000100
[2025-08-10 12:23:08,561][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009180] [Batch 01796/03692] [00:16:41/00:17:36, 0.557s/it]: train_loss_raw=1.9156, running_loss=1.9858, LR=0.000100
[2025-08-10 12:23:15,053][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009192] [Batch 01808/03692] [00:16:47/00:17:30, 0.557s/it]: train_loss_raw=2.0940, running_loss=1.9870, LR=0.000100
[2025-08-10 12:23:21,493][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009204] [Batch 01820/03692] [00:16:54/00:17:23, 0.557s/it]: train_loss_raw=1.8961, running_loss=1.9880, LR=0.000100
[2025-08-10 12:23:28,033][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009216] [Batch 01832/03692] [00:17:00/00:17:16, 0.557s/it]: train_loss_raw=1.9752, running_loss=1.9857, LR=0.000100
[2025-08-10 12:23:34,654][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009228] [Batch 01844/03692] [00:17:07/00:17:09, 0.557s/it]: train_loss_raw=2.1316, running_loss=1.9849, LR=0.000100
[2025-08-10 12:23:41,161][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009240] [Batch 01856/03692] [00:17:13/00:17:02, 0.557s/it]: train_loss_raw=2.1016, running_loss=1.9817, LR=0.000100
[2025-08-10 12:23:47,629][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009252] [Batch 01868/03692] [00:17:20/00:16:55, 0.557s/it]: train_loss_raw=1.9949, running_loss=1.9801, LR=0.000100
[2025-08-10 12:23:54,137][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009264] [Batch 01880/03692] [00:17:26/00:16:48, 0.557s/it]: train_loss_raw=1.8746, running_loss=1.9831, LR=0.000100
[2025-08-10 12:24:00,543][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009276] [Batch 01892/03692] [00:17:33/00:16:41, 0.557s/it]: train_loss_raw=2.1210, running_loss=1.9822, LR=0.000100
[2025-08-10 12:24:07,109][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009288] [Batch 01904/03692] [00:17:39/00:16:35, 0.557s/it]: train_loss_raw=1.9834, running_loss=1.9791, LR=0.000100
[2025-08-10 12:24:13,641][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009300] [Batch 01916/03692] [00:17:46/00:16:28, 0.556s/it]: train_loss_raw=1.9360, running_loss=1.9782, LR=0.000100
[2025-08-10 12:24:20,152][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009312] [Batch 01928/03692] [00:17:52/00:16:21, 0.556s/it]: train_loss_raw=1.9293, running_loss=1.9796, LR=0.000100
[2025-08-10 12:24:26,661][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009324] [Batch 01940/03692] [00:17:59/00:16:14, 0.556s/it]: train_loss_raw=1.9770, running_loss=1.9779, LR=0.000100
[2025-08-10 12:24:33,174][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009336] [Batch 01952/03692] [00:18:05/00:16:07, 0.556s/it]: train_loss_raw=1.9926, running_loss=1.9788, LR=0.000100
[2025-08-10 12:24:39,680][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009348] [Batch 01964/03692] [00:18:12/00:16:01, 0.556s/it]: train_loss_raw=2.0248, running_loss=1.9778, LR=0.000100
[2025-08-10 12:24:45,992][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009360] [Batch 01976/03692] [00:18:18/00:15:54, 0.556s/it]: train_loss_raw=1.8918, running_loss=1.9754, LR=0.000100
[2025-08-10 12:24:52,597][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009372] [Batch 01988/03692] [00:18:25/00:15:47, 0.556s/it]: train_loss_raw=2.0226, running_loss=1.9759, LR=0.000100
[2025-08-10 12:24:59,175][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009384] [Batch 02000/03692] [00:18:31/00:15:40, 0.556s/it]: train_loss_raw=1.9668, running_loss=1.9784, LR=0.000100
[2025-08-10 12:25:05,766][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009396] [Batch 02012/03692] [00:18:38/00:15:33, 0.556s/it]: train_loss_raw=1.8611, running_loss=1.9786, LR=0.000100
[2025-08-10 12:25:12,298][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009408] [Batch 02024/03692] [00:18:44/00:15:27, 0.556s/it]: train_loss_raw=1.9101, running_loss=1.9789, LR=0.000100
[2025-08-10 12:25:18,765][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009420] [Batch 02036/03692] [00:18:51/00:15:20, 0.556s/it]: train_loss_raw=1.9716, running_loss=1.9814, LR=0.000100
[2025-08-10 12:25:25,213][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009432] [Batch 02048/03692] [00:18:57/00:15:13, 0.556s/it]: train_loss_raw=1.8960, running_loss=1.9807, LR=0.000100
[2025-08-10 12:25:31,687][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009444] [Batch 02060/03692] [00:19:04/00:15:06, 0.555s/it]: train_loss_raw=1.9677, running_loss=1.9810, LR=0.000100
[2025-08-10 12:25:38,165][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009456] [Batch 02072/03692] [00:19:10/00:14:59, 0.555s/it]: train_loss_raw=1.9570, running_loss=1.9796, LR=0.000100
[2025-08-10 12:25:44,670][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009468] [Batch 02084/03692] [00:19:17/00:14:52, 0.555s/it]: train_loss_raw=2.0072, running_loss=1.9786, LR=0.000100
[2025-08-10 12:25:51,146][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009480] [Batch 02096/03692] [00:19:23/00:14:46, 0.555s/it]: train_loss_raw=1.9934, running_loss=1.9773, LR=0.000100
[2025-08-10 12:25:57,637][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009492] [Batch 02108/03692] [00:19:30/00:14:39, 0.555s/it]: train_loss_raw=1.9363, running_loss=1.9744, LR=0.000100
[2025-08-10 12:26:04,050][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009504] [Batch 02120/03692] [00:19:36/00:14:32, 0.555s/it]: train_loss_raw=1.8950, running_loss=1.9748, LR=0.000100
[2025-08-10 12:26:10,500][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009516] [Batch 02132/03692] [00:19:43/00:14:25, 0.555s/it]: train_loss_raw=2.0319, running_loss=1.9717, LR=0.000100
[2025-08-10 12:26:16,914][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009528] [Batch 02144/03692] [00:19:49/00:14:18, 0.555s/it]: train_loss_raw=1.9323, running_loss=1.9677, LR=0.000100
[2025-08-10 12:26:23,304][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009540] [Batch 02156/03692] [00:19:55/00:14:12, 0.555s/it]: train_loss_raw=2.0143, running_loss=1.9660, LR=0.000100
[2025-08-10 12:26:29,676][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009552] [Batch 02168/03692] [00:20:02/00:14:05, 0.555s/it]: train_loss_raw=1.9248, running_loss=1.9695, LR=0.000100
[2025-08-10 12:26:36,117][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009564] [Batch 02180/03692] [00:20:08/00:13:58, 0.554s/it]: train_loss_raw=2.0359, running_loss=1.9708, LR=0.000100
[2025-08-10 12:26:42,547][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009576] [Batch 02192/03692] [00:20:15/00:13:51, 0.554s/it]: train_loss_raw=2.0075, running_loss=1.9710, LR=0.000100
[2025-08-10 12:26:48,970][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009588] [Batch 02204/03692] [00:20:21/00:13:44, 0.554s/it]: train_loss_raw=1.9694, running_loss=1.9697, LR=0.000100
[2025-08-10 12:26:55,491][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009600] [Batch 02216/03692] [00:20:28/00:13:37, 0.554s/it]: train_loss_raw=1.8566, running_loss=1.9692, LR=0.000100
[2025-08-10 12:27:02,078][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009612] [Batch 02228/03692] [00:20:34/00:13:31, 0.554s/it]: train_loss_raw=1.9385, running_loss=1.9673, LR=0.000100
[2025-08-10 12:27:08,589][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009624] [Batch 02240/03692] [00:20:41/00:13:24, 0.554s/it]: train_loss_raw=1.8869, running_loss=1.9708, LR=0.000100
[2025-08-10 12:27:15,029][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009636] [Batch 02252/03692] [00:20:47/00:13:17, 0.554s/it]: train_loss_raw=1.9915, running_loss=1.9722, LR=0.000100
[2025-08-10 12:27:21,466][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009648] [Batch 02264/03692] [00:20:54/00:13:10, 0.554s/it]: train_loss_raw=2.0022, running_loss=1.9721, LR=0.000100
[2025-08-10 12:27:27,966][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009660] [Batch 02276/03692] [00:21:00/00:13:04, 0.554s/it]: train_loss_raw=1.9675, running_loss=1.9744, LR=0.000100
[2025-08-10 12:27:34,545][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009672] [Batch 02288/03692] [00:21:07/00:12:57, 0.554s/it]: train_loss_raw=2.0908, running_loss=1.9747, LR=0.000100
[2025-08-10 12:27:41,230][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009684] [Batch 02300/03692] [00:21:13/00:12:50, 0.554s/it]: train_loss_raw=2.0093, running_loss=1.9709, LR=0.000100
[2025-08-10 12:27:47,811][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009696] [Batch 02312/03692] [00:21:20/00:12:44, 0.554s/it]: train_loss_raw=2.0229, running_loss=1.9731, LR=0.000100
[2025-08-10 12:27:54,371][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009708] [Batch 02324/03692] [00:21:26/00:12:37, 0.554s/it]: train_loss_raw=1.9597, running_loss=1.9699, LR=0.000100
[2025-08-10 12:28:00,993][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009720] [Batch 02336/03692] [00:21:33/00:12:30, 0.554s/it]: train_loss_raw=1.9028, running_loss=1.9690, LR=0.000100
[2025-08-10 12:28:07,480][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009732] [Batch 02348/03692] [00:21:40/00:12:24, 0.554s/it]: train_loss_raw=2.0428, running_loss=1.9700, LR=0.000100
[2025-08-10 12:28:13,812][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009744] [Batch 02360/03692] [00:21:46/00:12:17, 0.554s/it]: train_loss_raw=1.9217, running_loss=1.9721, LR=0.000100
[2025-08-10 12:28:20,194][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009756] [Batch 02372/03692] [00:21:52/00:12:10, 0.553s/it]: train_loss_raw=1.9266, running_loss=1.9717, LR=0.000100
[2025-08-10 12:28:26,784][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009768] [Batch 02384/03692] [00:21:59/00:12:03, 0.553s/it]: train_loss_raw=1.9472, running_loss=1.9719, LR=0.000100
[2025-08-10 12:28:33,289][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009780] [Batch 02396/03692] [00:22:05/00:11:57, 0.553s/it]: train_loss_raw=2.0071, running_loss=1.9669, LR=0.000100
[2025-08-10 12:28:39,725][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009792] [Batch 02408/03692] [00:22:12/00:11:50, 0.553s/it]: train_loss_raw=1.9276, running_loss=1.9671, LR=0.000100
[2025-08-10 12:28:46,242][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009804] [Batch 02420/03692] [00:22:18/00:11:43, 0.553s/it]: train_loss_raw=1.9928, running_loss=1.9685, LR=0.000100
[2025-08-10 12:28:52,761][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009816] [Batch 02432/03692] [00:22:25/00:11:37, 0.553s/it]: train_loss_raw=1.9882, running_loss=1.9675, LR=0.000100
[2025-08-10 12:28:59,332][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009828] [Batch 02444/03692] [00:22:31/00:11:30, 0.553s/it]: train_loss_raw=2.0121, running_loss=1.9699, LR=0.000100
[2025-08-10 12:29:05,869][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009840] [Batch 02456/03692] [00:22:38/00:11:23, 0.553s/it]: train_loss_raw=1.8542, running_loss=1.9715, LR=0.000100
[2025-08-10 12:29:12,294][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009852] [Batch 02468/03692] [00:22:44/00:11:16, 0.553s/it]: train_loss_raw=1.9444, running_loss=1.9745, LR=0.000100
[2025-08-10 12:29:18,525][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009864] [Batch 02480/03692] [00:22:51/00:11:10, 0.553s/it]: train_loss_raw=2.0584, running_loss=1.9753, LR=0.000100
[2025-08-10 12:29:24,762][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009876] [Batch 02492/03692] [00:22:57/00:11:03, 0.553s/it]: train_loss_raw=1.8912, running_loss=1.9722, LR=0.000100
[2025-08-10 12:29:30,986][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009888] [Batch 02504/03692] [00:23:03/00:10:56, 0.553s/it]: train_loss_raw=1.8717, running_loss=1.9690, LR=0.000100
[2025-08-10 12:29:37,286][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009900] [Batch 02516/03692] [00:23:09/00:10:49, 0.552s/it]: train_loss_raw=1.9418, running_loss=1.9697, LR=0.000100
[2025-08-10 12:29:43,553][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009912] [Batch 02528/03692] [00:23:16/00:10:42, 0.552s/it]: train_loss_raw=1.9078, running_loss=1.9650, LR=0.000100
[2025-08-10 12:29:49,777][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009924] [Batch 02540/03692] [00:23:22/00:10:36, 0.552s/it]: train_loss_raw=1.9907, running_loss=1.9640, LR=0.000100
[2025-08-10 12:29:56,173][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009936] [Batch 02552/03692] [00:23:28/00:10:29, 0.552s/it]: train_loss_raw=1.9143, running_loss=1.9637, LR=0.000100
[2025-08-10 12:30:02,695][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009948] [Batch 02564/03692] [00:23:35/00:10:22, 0.552s/it]: train_loss_raw=1.9905, running_loss=1.9628, LR=0.000100
[2025-08-10 12:30:08,947][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009960] [Batch 02576/03692] [00:23:41/00:10:15, 0.552s/it]: train_loss_raw=1.9214, running_loss=1.9611, LR=0.000100
[2025-08-10 12:30:15,322][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009972] [Batch 02588/03692] [00:23:47/00:10:09, 0.552s/it]: train_loss_raw=1.9900, running_loss=1.9595, LR=0.000100
[2025-08-10 12:30:21,918][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009984] [Batch 02600/03692] [00:23:54/00:10:02, 0.552s/it]: train_loss_raw=1.8993, running_loss=1.9615, LR=0.000100
[2025-08-10 12:30:28,493][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009996] [Batch 02612/03692] [00:24:01/00:09:55, 0.552s/it]: train_loss_raw=1.9346, running_loss=1.9568, LR=0.000100
[2025-08-10 12:30:39,833][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010008] [Batch 02624/03692] [00:24:12/00:09:51, 0.554s/it]: train_loss_raw=2.0089, running_loss=1.9601, LR=0.000100
[2025-08-10 12:30:46,436][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010020] [Batch 02636/03692] [00:24:19/00:09:44, 0.554s/it]: train_loss_raw=1.9679, running_loss=1.9592, LR=0.000100
[2025-08-10 12:30:52,992][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010032] [Batch 02648/03692] [00:24:25/00:09:37, 0.553s/it]: train_loss_raw=1.9830, running_loss=1.9615, LR=0.000100
[2025-08-10 12:30:59,556][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010044] [Batch 02660/03692] [00:24:32/00:09:31, 0.553s/it]: train_loss_raw=1.9535, running_loss=1.9580, LR=0.000100
[2025-08-10 12:31:06,114][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010056] [Batch 02672/03692] [00:24:38/00:09:24, 0.553s/it]: train_loss_raw=1.9436, running_loss=1.9608, LR=0.000100
[2025-08-10 12:31:12,653][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010068] [Batch 02684/03692] [00:24:45/00:09:17, 0.553s/it]: train_loss_raw=1.8709, running_loss=1.9587, LR=0.000100
[2025-08-10 12:31:19,214][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010080] [Batch 02696/03692] [00:24:51/00:09:11, 0.553s/it]: train_loss_raw=1.9471, running_loss=1.9591, LR=0.000100
[2025-08-10 12:31:25,674][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010092] [Batch 02708/03692] [00:24:58/00:09:04, 0.553s/it]: train_loss_raw=1.9649, running_loss=1.9609, LR=0.000100
[2025-08-10 12:31:32,245][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010104] [Batch 02720/03692] [00:25:04/00:08:57, 0.553s/it]: train_loss_raw=1.9373, running_loss=1.9563, LR=0.000100
[2025-08-10 12:31:38,837][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010116] [Batch 02732/03692] [00:25:11/00:08:51, 0.553s/it]: train_loss_raw=1.9540, running_loss=1.9545, LR=0.000100
[2025-08-10 12:31:45,397][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010128] [Batch 02744/03692] [00:25:18/00:08:44, 0.553s/it]: train_loss_raw=1.8833, running_loss=1.9547, LR=0.000100
[2025-08-10 12:31:51,836][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010140] [Batch 02756/03692] [00:25:24/00:08:37, 0.553s/it]: train_loss_raw=1.8663, running_loss=1.9586, LR=0.000100
[2025-08-10 12:31:58,316][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010152] [Batch 02768/03692] [00:25:30/00:08:31, 0.553s/it]: train_loss_raw=1.9760, running_loss=1.9573, LR=0.000100
[2025-08-10 12:32:04,873][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010164] [Batch 02780/03692] [00:25:37/00:08:24, 0.553s/it]: train_loss_raw=2.0149, running_loss=1.9578, LR=0.000100
[2025-08-10 12:32:11,378][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010176] [Batch 02792/03692] [00:25:43/00:08:17, 0.553s/it]: train_loss_raw=2.0053, running_loss=1.9550, LR=0.000100
[2025-08-10 12:32:17,973][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010188] [Batch 02804/03692] [00:25:50/00:08:11, 0.553s/it]: train_loss_raw=1.9405, running_loss=1.9555, LR=0.000100
[2025-08-10 12:32:24,400][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010200] [Batch 02816/03692] [00:25:57/00:08:04, 0.553s/it]: train_loss_raw=1.8848, running_loss=1.9542, LR=0.000100
[2025-08-10 12:32:30,924][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010212] [Batch 02828/03692] [00:26:03/00:07:57, 0.553s/it]: train_loss_raw=1.9036, running_loss=1.9552, LR=0.000100
[2025-08-10 12:32:37,557][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010224] [Batch 02840/03692] [00:26:10/00:07:51, 0.553s/it]: train_loss_raw=1.9103, running_loss=1.9559, LR=0.000100
[2025-08-10 12:32:44,150][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010236] [Batch 02852/03692] [00:26:16/00:07:44, 0.553s/it]: train_loss_raw=1.9860, running_loss=1.9571, LR=0.000100
[2025-08-10 12:32:50,649][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010248] [Batch 02864/03692] [00:26:23/00:07:37, 0.553s/it]: train_loss_raw=1.8606, running_loss=1.9555, LR=0.000100
[2025-08-10 12:32:57,178][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010260] [Batch 02876/03692] [00:26:29/00:07:31, 0.553s/it]: train_loss_raw=1.8618, running_loss=1.9508, LR=0.000100
[2025-08-10 12:33:03,657][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010272] [Batch 02888/03692] [00:26:36/00:07:24, 0.553s/it]: train_loss_raw=1.8680, running_loss=1.9518, LR=0.000100
[2025-08-10 12:33:10,073][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010284] [Batch 02900/03692] [00:26:42/00:07:17, 0.553s/it]: train_loss_raw=2.0106, running_loss=1.9512, LR=0.000100
[2025-08-10 12:33:16,505][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010296] [Batch 02912/03692] [00:26:49/00:07:11, 0.553s/it]: train_loss_raw=1.8430, running_loss=1.9536, LR=0.000100
[2025-08-10 12:33:22,881][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010308] [Batch 02924/03692] [00:26:55/00:07:04, 0.552s/it]: train_loss_raw=1.9609, running_loss=1.9548, LR=0.000100
[2025-08-10 12:33:29,473][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010320] [Batch 02936/03692] [00:27:02/00:06:57, 0.552s/it]: train_loss_raw=1.8618, running_loss=1.9521, LR=0.000100
[2025-08-10 12:33:36,102][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010332] [Batch 02948/03692] [00:27:08/00:06:51, 0.552s/it]: train_loss_raw=1.9726, running_loss=1.9493, LR=0.000100
[2025-08-10 12:33:42,643][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010344] [Batch 02960/03692] [00:27:15/00:06:44, 0.552s/it]: train_loss_raw=2.0217, running_loss=1.9496, LR=0.000100
[2025-08-10 12:33:49,129][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010356] [Batch 02972/03692] [00:27:21/00:06:37, 0.552s/it]: train_loss_raw=2.0504, running_loss=1.9485, LR=0.000100
[2025-08-10 12:33:55,497][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010368] [Batch 02984/03692] [00:27:28/00:06:31, 0.552s/it]: train_loss_raw=1.9786, running_loss=1.9501, LR=0.000100
[2025-08-10 12:34:01,939][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010380] [Batch 02996/03692] [00:27:34/00:06:24, 0.552s/it]: train_loss_raw=2.0095, running_loss=1.9514, LR=0.000100
[2025-08-10 12:34:08,289][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010392] [Batch 03008/03692] [00:27:40/00:06:17, 0.552s/it]: train_loss_raw=1.9164, running_loss=1.9503, LR=0.000100
[2025-08-10 12:34:14,703][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010404] [Batch 03020/03692] [00:27:47/00:06:11, 0.552s/it]: train_loss_raw=1.9524, running_loss=1.9502, LR=0.000100
[2025-08-10 12:34:20,989][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010416] [Batch 03032/03692] [00:27:53/00:06:04, 0.552s/it]: train_loss_raw=1.8729, running_loss=1.9456, LR=0.000100
[2025-08-10 12:34:27,535][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010428] [Batch 03044/03692] [00:28:00/00:05:57, 0.552s/it]: train_loss_raw=1.9050, running_loss=1.9465, LR=0.000100
[2025-08-10 12:34:34,025][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010440] [Batch 03056/03692] [00:28:06/00:05:51, 0.552s/it]: train_loss_raw=1.9240, running_loss=1.9430, LR=0.000100
[2025-08-10 12:34:40,505][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010452] [Batch 03068/03692] [00:28:13/00:05:44, 0.552s/it]: train_loss_raw=1.9427, running_loss=1.9426, LR=0.000100
[2025-08-10 12:34:47,041][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010464] [Batch 03080/03692] [00:28:19/00:05:37, 0.552s/it]: train_loss_raw=1.9660, running_loss=1.9457, LR=0.000100
[2025-08-10 12:34:53,521][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010476] [Batch 03092/03692] [00:28:26/00:05:31, 0.552s/it]: train_loss_raw=1.9798, running_loss=1.9469, LR=0.000100
[2025-08-10 12:35:00,073][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010488] [Batch 03104/03692] [00:28:32/00:05:24, 0.552s/it]: train_loss_raw=1.9643, running_loss=1.9439, LR=0.000100
[2025-08-10 12:35:06,657][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010500] [Batch 03116/03692] [00:28:39/00:05:17, 0.552s/it]: train_loss_raw=2.0101, running_loss=1.9461, LR=0.000100
[2025-08-10 12:35:13,243][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010512] [Batch 03128/03692] [00:28:45/00:05:11, 0.552s/it]: train_loss_raw=1.9542, running_loss=1.9476, LR=0.000100
[2025-08-10 12:35:19,725][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010524] [Batch 03140/03692] [00:28:52/00:05:04, 0.552s/it]: train_loss_raw=1.8763, running_loss=1.9465, LR=0.000100
[2025-08-10 12:35:26,162][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010536] [Batch 03152/03692] [00:28:58/00:04:57, 0.552s/it]: train_loss_raw=1.8663, running_loss=1.9486, LR=0.000100
[2025-08-10 12:35:32,632][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010548] [Batch 03164/03692] [00:29:05/00:04:51, 0.552s/it]: train_loss_raw=2.0023, running_loss=1.9460, LR=0.000100
[2025-08-10 12:35:39,117][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010560] [Batch 03176/03692] [00:29:11/00:04:44, 0.552s/it]: train_loss_raw=1.8583, running_loss=1.9439, LR=0.000100
[2025-08-10 12:35:45,568][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010572] [Batch 03188/03692] [00:29:18/00:04:37, 0.551s/it]: train_loss_raw=1.9183, running_loss=1.9427, LR=0.000100
[2025-08-10 12:35:52,032][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010584] [Batch 03200/03692] [00:29:24/00:04:31, 0.551s/it]: train_loss_raw=1.9954, running_loss=1.9419, LR=0.000100
[2025-08-10 12:35:58,515][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010596] [Batch 03212/03692] [00:29:31/00:04:24, 0.551s/it]: train_loss_raw=1.9506, running_loss=1.9439, LR=0.000100
[2025-08-10 12:36:04,988][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010608] [Batch 03224/03692] [00:29:37/00:04:18, 0.551s/it]: train_loss_raw=1.9315, running_loss=1.9431, LR=0.000100
[2025-08-10 12:36:11,549][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010620] [Batch 03236/03692] [00:29:44/00:04:11, 0.551s/it]: train_loss_raw=2.1100, running_loss=1.9431, LR=0.000100
[2025-08-10 12:36:18,060][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010632] [Batch 03248/03692] [00:29:50/00:04:04, 0.551s/it]: train_loss_raw=2.0114, running_loss=1.9451, LR=0.000100
[2025-08-10 12:36:24,533][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010644] [Batch 03260/03692] [00:29:57/00:03:58, 0.551s/it]: train_loss_raw=2.0103, running_loss=1.9501, LR=0.000100
[2025-08-10 12:36:31,149][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010656] [Batch 03272/03692] [00:30:03/00:03:51, 0.551s/it]: train_loss_raw=2.0629, running_loss=1.9500, LR=0.000100
[2025-08-10 12:36:37,713][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010668] [Batch 03284/03692] [00:30:10/00:03:44, 0.551s/it]: train_loss_raw=1.8909, running_loss=1.9474, LR=0.000100
[2025-08-10 12:36:44,299][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010680] [Batch 03296/03692] [00:30:16/00:03:38, 0.551s/it]: train_loss_raw=1.9566, running_loss=1.9484, LR=0.000100
[2025-08-10 12:36:50,951][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010692] [Batch 03308/03692] [00:30:23/00:03:31, 0.551s/it]: train_loss_raw=1.9648, running_loss=1.9473, LR=0.000100
[2025-08-10 12:36:57,591][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010704] [Batch 03320/03692] [00:30:30/00:03:25, 0.551s/it]: train_loss_raw=1.8527, running_loss=1.9430, LR=0.000100
[2025-08-10 12:37:04,070][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010716] [Batch 03332/03692] [00:30:36/00:03:18, 0.551s/it]: train_loss_raw=1.9634, running_loss=1.9431, LR=0.000100
[2025-08-10 12:37:10,638][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010728] [Batch 03344/03692] [00:30:43/00:03:11, 0.551s/it]: train_loss_raw=1.9217, running_loss=1.9428, LR=0.000100
[2025-08-10 12:37:17,216][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010740] [Batch 03356/03692] [00:30:49/00:03:05, 0.551s/it]: train_loss_raw=1.8583, running_loss=1.9458, LR=0.000100
[2025-08-10 12:37:23,721][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010752] [Batch 03368/03692] [00:30:56/00:02:58, 0.551s/it]: train_loss_raw=1.8961, running_loss=1.9452, LR=0.000100
[2025-08-10 12:37:30,270][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010764] [Batch 03380/03692] [00:31:02/00:02:51, 0.551s/it]: train_loss_raw=1.9541, running_loss=1.9421, LR=0.000100
[2025-08-10 12:37:36,813][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010776] [Batch 03392/03692] [00:31:09/00:02:45, 0.551s/it]: train_loss_raw=1.8376, running_loss=1.9422, LR=0.000100
[2025-08-10 12:37:43,370][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010788] [Batch 03404/03692] [00:31:15/00:02:38, 0.551s/it]: train_loss_raw=1.9467, running_loss=1.9470, LR=0.000100
[2025-08-10 12:37:49,928][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010800] [Batch 03416/03692] [00:31:22/00:02:32, 0.551s/it]: train_loss_raw=2.0645, running_loss=1.9455, LR=0.000100
[2025-08-10 12:37:56,469][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010812] [Batch 03428/03692] [00:31:29/00:02:25, 0.551s/it]: train_loss_raw=1.9228, running_loss=1.9457, LR=0.000100
[2025-08-10 12:38:03,076][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010824] [Batch 03440/03692] [00:31:35/00:02:18, 0.551s/it]: train_loss_raw=1.9657, running_loss=1.9443, LR=0.000100
[2025-08-10 12:38:09,573][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010836] [Batch 03452/03692] [00:31:42/00:02:12, 0.551s/it]: train_loss_raw=1.9843, running_loss=1.9436, LR=0.000100
[2025-08-10 12:38:16,021][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010848] [Batch 03464/03692] [00:31:48/00:02:05, 0.551s/it]: train_loss_raw=1.9656, running_loss=1.9444, LR=0.000100
[2025-08-10 12:38:22,423][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010860] [Batch 03476/03692] [00:31:55/00:01:59, 0.551s/it]: train_loss_raw=2.0447, running_loss=1.9463, LR=0.000100
[2025-08-10 12:38:28,921][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010872] [Batch 03488/03692] [00:32:01/00:01:52, 0.551s/it]: train_loss_raw=1.9934, running_loss=1.9457, LR=0.000100
[2025-08-10 12:38:35,433][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010884] [Batch 03500/03692] [00:32:08/00:01:45, 0.551s/it]: train_loss_raw=1.9023, running_loss=1.9429, LR=0.000100
[2025-08-10 12:38:41,924][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010896] [Batch 03512/03692] [00:32:14/00:01:39, 0.551s/it]: train_loss_raw=1.9937, running_loss=1.9377, LR=0.000100
[2025-08-10 12:38:48,383][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010908] [Batch 03524/03692] [00:32:20/00:01:32, 0.551s/it]: train_loss_raw=1.7990, running_loss=1.9388, LR=0.000100
[2025-08-10 12:38:54,797][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010920] [Batch 03536/03692] [00:32:27/00:01:25, 0.551s/it]: train_loss_raw=1.9473, running_loss=1.9387, LR=0.000100
[2025-08-10 12:39:01,252][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010932] [Batch 03548/03692] [00:32:33/00:01:19, 0.551s/it]: train_loss_raw=1.9515, running_loss=1.9379, LR=0.000100
[2025-08-10 12:39:07,853][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010944] [Batch 03560/03692] [00:32:40/00:01:12, 0.551s/it]: train_loss_raw=1.9209, running_loss=1.9395, LR=0.000100
[2025-08-10 12:39:14,279][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010956] [Batch 03572/03692] [00:32:46/00:01:06, 0.551s/it]: train_loss_raw=1.8656, running_loss=1.9400, LR=0.000100
[2025-08-10 12:39:20,670][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010968] [Batch 03584/03692] [00:32:53/00:00:59, 0.551s/it]: train_loss_raw=1.9635, running_loss=1.9425, LR=0.000100
[2025-08-10 12:39:27,090][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010980] [Batch 03596/03692] [00:32:59/00:00:52, 0.551s/it]: train_loss_raw=1.8929, running_loss=1.9394, LR=0.000100
[2025-08-10 12:39:33,576][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010992] [Batch 03608/03692] [00:33:06/00:00:46, 0.550s/it]: train_loss_raw=1.8747, running_loss=1.9387, LR=0.000100
[2025-08-10 12:39:40,102][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011004] [Batch 03620/03692] [00:33:12/00:00:39, 0.550s/it]: train_loss_raw=1.9854, running_loss=1.9429, LR=0.000100
[2025-08-10 12:39:46,596][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011016] [Batch 03632/03692] [00:33:19/00:00:33, 0.550s/it]: train_loss_raw=1.8870, running_loss=1.9381, LR=0.000100
[2025-08-10 12:39:53,193][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011028] [Batch 03644/03692] [00:33:25/00:00:26, 0.550s/it]: train_loss_raw=1.9113, running_loss=1.9351, LR=0.000100
[2025-08-10 12:39:59,760][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011040] [Batch 03656/03692] [00:33:32/00:00:19, 0.550s/it]: train_loss_raw=1.9784, running_loss=1.9397, LR=0.000100
[2025-08-10 12:40:06,308][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011052] [Batch 03668/03692] [00:33:38/00:00:13, 0.550s/it]: train_loss_raw=1.9563, running_loss=1.9389, LR=0.000100
[2025-08-10 12:40:12,827][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011064] [Batch 03680/03692] [00:33:45/00:00:06, 0.550s/it]: train_loss_raw=1.7809, running_loss=1.9393, LR=0.000100
[2025-08-10 12:40:19,418][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011076] [Batch 03692/03692] [00:33:52/00:00:00, 0.550s/it]: train_loss_raw=1.9319, running_loss=1.9385, LR=0.000100
[2025-08-10 12:40:24,913][__main__][INFO] - [VALIDATION] [Epoch 02/29] Starting validation.
[2025-08-10 12:41:02,498][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 011077] [Batch 00011/00025] [00:00:37/00:00:40, 3.132s/it]
[2025-08-10 12:41:20,738][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 011077] [Batch 00023/00025] [00:00:55/00:00:02, 2.326s/it]
[2025-08-10 12:41:21,896][__main__][INFO] - [VALIDATION] [Epoch 02/29] train_loss=1.93847, valid_loss=1.87853
[2025-08-10 12:41:21,897][__main__][INFO] - [VALIDATION] [Epoch 02/29] Metrics:
[2025-08-10 12:41:21,897][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_er      0.748
[2025-08-10 12:41:21,897][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_prec    0.027
[2025-08-10 12:41:21,897][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_recall  0.028
[2025-08-10 12:41:21,897][__main__][INFO] - [VALIDATION] [Epoch 02/29] - pep_recall 0.001
[2025-08-10 12:41:21,901][__main__][INFO] - [TRAIN] [Epoch 02/29] Epoch complete, total time 01:45:21, remaining time 15:48:10, 00:35:07 per epoch
[2025-08-10 12:41:28,270][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011088] [Batch 00012/03692] [00:00:06/00:31:15, 0.510s/it]: train_loss_raw=1.9913, running_loss=1.9777, LR=0.000100
[2025-08-10 12:41:34,829][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011100] [Batch 00024/03692] [00:00:12/00:32:17, 0.528s/it]: train_loss_raw=1.9552, running_loss=1.9733, LR=0.000100
[2025-08-10 12:41:41,096][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011112] [Batch 00036/03692] [00:00:18/00:32:03, 0.526s/it]: train_loss_raw=1.8910, running_loss=1.9665, LR=0.000100
[2025-08-10 12:41:47,408][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011124] [Batch 00048/03692] [00:00:25/00:31:57, 0.526s/it]: train_loss_raw=1.8385, running_loss=1.9606, LR=0.000100
[2025-08-10 12:41:53,941][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011136] [Batch 00060/03692] [00:00:31/00:32:04, 0.530s/it]: train_loss_raw=1.8875, running_loss=1.9562, LR=0.000100
[2025-08-10 12:42:00,491][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011148] [Batch 00072/03692] [00:00:38/00:32:07, 0.532s/it]: train_loss_raw=2.0336, running_loss=1.9548, LR=0.000100
[2025-08-10 12:42:06,835][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011160] [Batch 00084/03692] [00:00:44/00:31:59, 0.532s/it]: train_loss_raw=1.9125, running_loss=1.9498, LR=0.000100
[2025-08-10 12:42:13,044][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011172] [Batch 00096/03692] [00:00:50/00:31:46, 0.530s/it]: train_loss_raw=1.8546, running_loss=1.9491, LR=0.000100
[2025-08-10 12:42:19,271][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011184] [Batch 00108/03692] [00:00:57/00:31:35, 0.529s/it]: train_loss_raw=2.0279, running_loss=1.9474, LR=0.000100
[2025-08-10 12:42:25,593][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011196] [Batch 00120/03692] [00:01:03/00:31:28, 0.529s/it]: train_loss_raw=1.9370, running_loss=1.9430, LR=0.000100
[2025-08-10 12:42:31,861][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011208] [Batch 00132/03692] [00:01:09/00:31:20, 0.528s/it]: train_loss_raw=1.9731, running_loss=1.9441, LR=0.000100
[2025-08-10 12:42:38,115][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011220] [Batch 00144/03692] [00:01:15/00:31:11, 0.528s/it]: train_loss_raw=1.9629, running_loss=1.9444, LR=0.000100
[2025-08-10 12:42:44,406][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011232] [Batch 00156/03692] [00:01:22/00:31:04, 0.527s/it]: train_loss_raw=1.9143, running_loss=1.9428, LR=0.000100
[2025-08-10 12:42:50,656][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011244] [Batch 00168/03692] [00:01:28/00:30:56, 0.527s/it]: train_loss_raw=1.8770, running_loss=1.9373, LR=0.000100
[2025-08-10 12:42:56,935][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011256] [Batch 00180/03692] [00:01:34/00:30:49, 0.527s/it]: train_loss_raw=1.9390, running_loss=1.9328, LR=0.000100
[2025-08-10 12:43:03,206][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011268] [Batch 00192/03692] [00:01:41/00:30:42, 0.526s/it]: train_loss_raw=2.0027, running_loss=1.9307, LR=0.000100
[2025-08-10 12:43:09,640][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011280] [Batch 00204/03692] [00:01:47/00:30:37, 0.527s/it]: train_loss_raw=1.8150, running_loss=1.9276, LR=0.000100
[2025-08-10 12:43:16,024][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011292] [Batch 00216/03692] [00:01:53/00:30:32, 0.527s/it]: train_loss_raw=1.8956, running_loss=1.9270, LR=0.000100
[2025-08-10 12:43:22,298][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011304] [Batch 00228/03692] [00:02:00/00:30:25, 0.527s/it]: train_loss_raw=1.9339, running_loss=1.9285, LR=0.000100
[2025-08-10 12:43:28,615][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011316] [Batch 00240/03692] [00:02:06/00:30:18, 0.527s/it]: train_loss_raw=1.9713, running_loss=1.9276, LR=0.000100
[2025-08-10 12:43:34,948][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011328] [Batch 00252/03692] [00:02:12/00:30:12, 0.527s/it]: train_loss_raw=1.8922, running_loss=1.9263, LR=0.000100
[2025-08-10 12:43:41,264][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011340] [Batch 00264/03692] [00:02:19/00:30:06, 0.527s/it]: train_loss_raw=1.9872, running_loss=1.9260, LR=0.000100
[2025-08-10 12:43:47,665][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011352] [Batch 00276/03692] [00:02:25/00:30:00, 0.527s/it]: train_loss_raw=1.8739, running_loss=1.9248, LR=0.000100
[2025-08-10 12:43:53,957][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011364] [Batch 00288/03692] [00:02:31/00:29:54, 0.527s/it]: train_loss_raw=1.9735, running_loss=1.9236, LR=0.000100
[2025-08-10 12:44:00,326][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011376] [Batch 00300/03692] [00:02:38/00:29:48, 0.527s/it]: train_loss_raw=1.9869, running_loss=1.9224, LR=0.000100
[2025-08-10 12:44:06,555][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011388] [Batch 00312/03692] [00:02:44/00:29:41, 0.527s/it]: train_loss_raw=1.8995, running_loss=1.9212, LR=0.000100
[2025-08-10 12:44:12,870][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011400] [Batch 00324/03692] [00:02:50/00:29:34, 0.527s/it]: train_loss_raw=1.8322, running_loss=1.9200, LR=0.000100
[2025-08-10 12:44:19,394][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011412] [Batch 00336/03692] [00:02:57/00:29:30, 0.528s/it]: train_loss_raw=1.9390, running_loss=1.9211, LR=0.000100
[2025-08-10 12:44:25,785][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011424] [Batch 00348/03692] [00:03:03/00:29:24, 0.528s/it]: train_loss_raw=1.9527, running_loss=1.9242, LR=0.000100
[2025-08-10 12:44:32,281][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011436] [Batch 00360/03692] [00:03:10/00:29:19, 0.528s/it]: train_loss_raw=1.9169, running_loss=1.9233, LR=0.000100
[2025-08-10 12:44:38,752][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011448] [Batch 00372/03692] [00:03:16/00:29:14, 0.528s/it]: train_loss_raw=1.9155, running_loss=1.9232, LR=0.000100
[2025-08-10 12:44:45,383][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011460] [Batch 00384/03692] [00:03:23/00:29:10, 0.529s/it]: train_loss_raw=1.8828, running_loss=1.9226, LR=0.000100
[2025-08-10 12:44:52,008][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011472] [Batch 00396/03692] [00:03:29/00:29:06, 0.530s/it]: train_loss_raw=1.8948, running_loss=1.9230, LR=0.000100
[2025-08-10 12:44:58,433][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011484] [Batch 00408/03692] [00:03:36/00:29:00, 0.530s/it]: train_loss_raw=2.0583, running_loss=1.9210, LR=0.000100
[2025-08-10 12:45:04,801][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011496] [Batch 00420/03692] [00:03:42/00:28:54, 0.530s/it]: train_loss_raw=1.9573, running_loss=1.9230, LR=0.000100
[2025-08-10 12:45:11,171][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011508] [Batch 00432/03692] [00:03:49/00:28:48, 0.530s/it]: train_loss_raw=1.9130, running_loss=1.9192, LR=0.000100
[2025-08-10 12:45:17,427][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011520] [Batch 00444/03692] [00:03:55/00:28:41, 0.530s/it]: train_loss_raw=1.7369, running_loss=1.9176, LR=0.000100
[2025-08-10 12:45:23,826][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011532] [Batch 00456/03692] [00:04:01/00:28:35, 0.530s/it]: train_loss_raw=1.7205, running_loss=1.9159, LR=0.000100
[2025-08-10 12:45:30,198][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011544] [Batch 00468/03692] [00:04:08/00:28:28, 0.530s/it]: train_loss_raw=1.8344, running_loss=1.9125, LR=0.000100
[2025-08-10 12:45:36,435][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011556] [Batch 00480/03692] [00:04:14/00:28:21, 0.530s/it]: train_loss_raw=1.9082, running_loss=1.9141, LR=0.000100
[2025-08-10 12:45:42,886][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011568] [Batch 00492/03692] [00:04:20/00:28:15, 0.530s/it]: train_loss_raw=1.8771, running_loss=1.9117, LR=0.000100
[2025-08-10 12:45:49,422][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011580] [Batch 00504/03692] [00:04:27/00:28:10, 0.530s/it]: train_loss_raw=1.9607, running_loss=1.9112, LR=0.000100
[2025-08-10 12:45:55,959][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011592] [Batch 00516/03692] [00:04:33/00:28:05, 0.531s/it]: train_loss_raw=1.8261, running_loss=1.9121, LR=0.000100
[2025-08-10 12:46:02,442][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011604] [Batch 00528/03692] [00:04:40/00:27:59, 0.531s/it]: train_loss_raw=1.9437, running_loss=1.9120, LR=0.000100
[2025-08-10 12:46:08,848][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011616] [Batch 00540/03692] [00:04:46/00:27:53, 0.531s/it]: train_loss_raw=1.9667, running_loss=1.9159, LR=0.000100
[2025-08-10 12:46:15,291][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011628] [Batch 00552/03692] [00:04:53/00:27:47, 0.531s/it]: train_loss_raw=1.8754, running_loss=1.9130, LR=0.000100
[2025-08-10 12:46:21,846][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011640] [Batch 00564/03692] [00:04:59/00:27:42, 0.531s/it]: train_loss_raw=1.9964, running_loss=1.9131, LR=0.000100
[2025-08-10 12:46:28,422][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011652] [Batch 00576/03692] [00:05:06/00:27:36, 0.532s/it]: train_loss_raw=1.8538, running_loss=1.9147, LR=0.000100
[2025-08-10 12:46:34,609][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011664] [Batch 00588/03692] [00:05:12/00:27:29, 0.531s/it]: train_loss_raw=1.7418, running_loss=1.9131, LR=0.000100
[2025-08-10 12:46:40,962][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011676] [Batch 00600/03692] [00:05:18/00:27:22, 0.531s/it]: train_loss_raw=1.9352, running_loss=1.9101, LR=0.000100
[2025-08-10 12:46:47,242][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011688] [Batch 00612/03692] [00:05:25/00:27:16, 0.531s/it]: train_loss_raw=1.9582, running_loss=1.9115, LR=0.000100
[2025-08-10 12:46:53,443][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011700] [Batch 00624/03692] [00:05:31/00:27:08, 0.531s/it]: train_loss_raw=1.8559, running_loss=1.9147, LR=0.000100
[2025-08-10 12:46:59,659][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011712] [Batch 00636/03692] [00:05:37/00:27:01, 0.531s/it]: train_loss_raw=1.9761, running_loss=1.9152, LR=0.000100
[2025-08-10 12:47:05,927][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011724] [Batch 00648/03692] [00:05:43/00:26:54, 0.531s/it]: train_loss_raw=1.8182, running_loss=1.9117, LR=0.000100
[2025-08-10 12:47:12,264][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011736] [Batch 00660/03692] [00:05:50/00:26:48, 0.530s/it]: train_loss_raw=1.9088, running_loss=1.9072, LR=0.000100
[2025-08-10 12:47:18,753][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011748] [Batch 00672/03692] [00:05:56/00:26:42, 0.531s/it]: train_loss_raw=2.0447, running_loss=1.9067, LR=0.000100
[2025-08-10 12:47:25,372][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011760] [Batch 00684/03692] [00:06:03/00:26:37, 0.531s/it]: train_loss_raw=1.9718, running_loss=1.9092, LR=0.000100
[2025-08-10 12:47:31,780][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011772] [Batch 00696/03692] [00:06:09/00:26:31, 0.531s/it]: train_loss_raw=1.9730, running_loss=1.9066, LR=0.000100
[2025-08-10 12:47:38,266][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011784] [Batch 00708/03692] [00:06:16/00:26:25, 0.531s/it]: train_loss_raw=1.8202, running_loss=1.9084, LR=0.000100
[2025-08-10 12:47:44,851][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011796] [Batch 00720/03692] [00:06:22/00:26:19, 0.532s/it]: train_loss_raw=1.8991, running_loss=1.9083, LR=0.000100
[2025-08-10 12:47:51,452][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011808] [Batch 00732/03692] [00:06:29/00:26:14, 0.532s/it]: train_loss_raw=1.8555, running_loss=1.9093, LR=0.000100
[2025-08-10 12:47:57,906][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011820] [Batch 00744/03692] [00:06:35/00:26:08, 0.532s/it]: train_loss_raw=1.8599, running_loss=1.9103, LR=0.000100
[2025-08-10 12:48:04,269][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011832] [Batch 00756/03692] [00:06:42/00:26:01, 0.532s/it]: train_loss_raw=1.9149, running_loss=1.9096, LR=0.000100
[2025-08-10 12:48:10,704][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011844] [Batch 00768/03692] [00:06:48/00:25:55, 0.532s/it]: train_loss_raw=1.9458, running_loss=1.9067, LR=0.000100
[2025-08-10 12:48:17,171][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011856] [Batch 00780/03692] [00:06:55/00:25:49, 0.532s/it]: train_loss_raw=1.9534, running_loss=1.9108, LR=0.000100
[2025-08-10 12:48:23,426][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011868] [Batch 00792/03692] [00:07:01/00:25:42, 0.532s/it]: train_loss_raw=1.9297, running_loss=1.9103, LR=0.000100
[2025-08-10 12:48:29,737][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011880] [Batch 00804/03692] [00:07:07/00:25:35, 0.532s/it]: train_loss_raw=1.8344, running_loss=1.9110, LR=0.000100
[2025-08-10 12:48:36,204][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011892] [Batch 00816/03692] [00:07:14/00:25:29, 0.532s/it]: train_loss_raw=1.8730, running_loss=1.9113, LR=0.000100
[2025-08-10 12:48:42,705][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011904] [Batch 00828/03692] [00:07:20/00:25:23, 0.532s/it]: train_loss_raw=1.8549, running_loss=1.9060, LR=0.000100
[2025-08-10 12:48:49,150][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011916] [Batch 00840/03692] [00:07:26/00:25:17, 0.532s/it]: train_loss_raw=1.9515, running_loss=1.9030, LR=0.000100
[2025-08-10 12:48:55,620][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011928] [Batch 00852/03692] [00:07:33/00:25:11, 0.532s/it]: train_loss_raw=1.9647, running_loss=1.9008, LR=0.000100
[2025-08-10 12:49:01,825][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011940] [Batch 00864/03692] [00:07:39/00:25:04, 0.532s/it]: train_loss_raw=1.8053, running_loss=1.8984, LR=0.000100
[2025-08-10 12:49:08,267][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011952] [Batch 00876/03692] [00:07:46/00:24:58, 0.532s/it]: train_loss_raw=1.8767, running_loss=1.8942, LR=0.000100
[2025-08-10 12:49:14,854][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011964] [Batch 00888/03692] [00:07:52/00:24:52, 0.532s/it]: train_loss_raw=1.8557, running_loss=1.8935, LR=0.000100
[2025-08-10 12:49:21,349][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011976] [Batch 00900/03692] [00:07:59/00:24:46, 0.532s/it]: train_loss_raw=1.8401, running_loss=1.8925, LR=0.000100
[2025-08-10 12:49:27,737][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011988] [Batch 00912/03692] [00:08:05/00:24:40, 0.532s/it]: train_loss_raw=1.8283, running_loss=1.8925, LR=0.000100
[2025-08-10 12:49:34,185][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012000] [Batch 00924/03692] [00:08:12/00:24:33, 0.533s/it]: train_loss_raw=1.8985, running_loss=1.8955, LR=0.000100
[2025-08-10 12:49:45,186][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012012] [Batch 00936/03692] [00:08:23/00:24:41, 0.537s/it]: train_loss_raw=1.9591, running_loss=1.8948, LR=0.000100
[2025-08-10 12:49:51,706][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012024] [Batch 00948/03692] [00:08:29/00:24:34, 0.538s/it]: train_loss_raw=1.8842, running_loss=1.8968, LR=0.000100
[2025-08-10 12:49:58,121][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012036] [Batch 00960/03692] [00:08:35/00:24:28, 0.537s/it]: train_loss_raw=1.9423, running_loss=1.8954, LR=0.000100
[2025-08-10 12:50:04,571][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012048] [Batch 00972/03692] [00:08:42/00:24:21, 0.537s/it]: train_loss_raw=1.8829, running_loss=1.8973, LR=0.000100
[2025-08-10 12:50:11,197][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012060] [Batch 00984/03692] [00:08:49/00:24:15, 0.538s/it]: train_loss_raw=1.8371, running_loss=1.8961, LR=0.000100
[2025-08-10 12:50:17,695][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012072] [Batch 00996/03692] [00:08:55/00:24:09, 0.538s/it]: train_loss_raw=1.8816, running_loss=1.8997, LR=0.000100
[2025-08-10 12:50:24,301][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012084] [Batch 01008/03692] [00:09:02/00:24:03, 0.538s/it]: train_loss_raw=1.8820, running_loss=1.9002, LR=0.000100
[2025-08-10 12:50:30,886][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012096] [Batch 01020/03692] [00:09:08/00:23:57, 0.538s/it]: train_loss_raw=1.8232, running_loss=1.8986, LR=0.000100
[2025-08-10 12:50:37,508][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012108] [Batch 01032/03692] [00:09:15/00:23:51, 0.538s/it]: train_loss_raw=1.9400, running_loss=1.8988, LR=0.000100
[2025-08-10 12:50:44,188][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012120] [Batch 01044/03692] [00:09:22/00:23:45, 0.538s/it]: train_loss_raw=1.9189, running_loss=1.8994, LR=0.000100
[2025-08-10 12:50:50,842][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012132] [Batch 01056/03692] [00:09:28/00:23:39, 0.539s/it]: train_loss_raw=1.9602, running_loss=1.8986, LR=0.000100
[2025-08-10 12:50:57,392][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012144] [Batch 01068/03692] [00:09:35/00:23:33, 0.539s/it]: train_loss_raw=1.8787, running_loss=1.8970, LR=0.000100
[2025-08-10 12:51:03,945][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012156] [Batch 01080/03692] [00:09:41/00:23:27, 0.539s/it]: train_loss_raw=1.9584, running_loss=1.8959, LR=0.000100
[2025-08-10 12:51:10,385][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012168] [Batch 01092/03692] [00:09:48/00:23:20, 0.539s/it]: train_loss_raw=1.9485, running_loss=1.8983, LR=0.000100
[2025-08-10 12:51:16,843][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012180] [Batch 01104/03692] [00:09:54/00:23:14, 0.539s/it]: train_loss_raw=1.9104, running_loss=1.8989, LR=0.000100
[2025-08-10 12:51:23,272][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012192] [Batch 01116/03692] [00:10:01/00:23:07, 0.539s/it]: train_loss_raw=1.8208, running_loss=1.8964, LR=0.000100
[2025-08-10 12:51:29,592][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012204] [Batch 01128/03692] [00:10:07/00:23:00, 0.539s/it]: train_loss_raw=1.8195, running_loss=1.8905, LR=0.000100
[2025-08-10 12:51:35,990][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012216] [Batch 01140/03692] [00:10:13/00:22:54, 0.538s/it]: train_loss_raw=1.8699, running_loss=1.8928, LR=0.000100
[2025-08-10 12:51:42,610][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012228] [Batch 01152/03692] [00:10:20/00:22:48, 0.539s/it]: train_loss_raw=1.8984, running_loss=1.8909, LR=0.000100
[2025-08-10 12:51:49,203][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012240] [Batch 01164/03692] [00:10:27/00:22:41, 0.539s/it]: train_loss_raw=1.8454, running_loss=1.8911, LR=0.000100
[2025-08-10 12:51:55,866][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012252] [Batch 01176/03692] [00:10:33/00:22:35, 0.539s/it]: train_loss_raw=1.8066, running_loss=1.8893, LR=0.000100
[2025-08-10 12:52:02,482][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012264] [Batch 01188/03692] [00:10:40/00:22:29, 0.539s/it]: train_loss_raw=1.8676, running_loss=1.8895, LR=0.000100
[2025-08-10 12:52:09,098][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012276] [Batch 01200/03692] [00:10:46/00:22:23, 0.539s/it]: train_loss_raw=1.9124, running_loss=1.8879, LR=0.000100
[2025-08-10 12:52:15,449][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012288] [Batch 01212/03692] [00:10:53/00:22:16, 0.539s/it]: train_loss_raw=1.9094, running_loss=1.8900, LR=0.000100
[2025-08-10 12:52:21,594][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012300] [Batch 01224/03692] [00:10:59/00:22:09, 0.539s/it]: train_loss_raw=1.8703, running_loss=1.8903, LR=0.000100
[2025-08-10 12:52:27,795][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012312] [Batch 01236/03692] [00:11:05/00:22:02, 0.539s/it]: train_loss_raw=1.8116, running_loss=1.8900, LR=0.000100
[2025-08-10 12:52:34,054][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012324] [Batch 01248/03692] [00:11:11/00:21:55, 0.538s/it]: train_loss_raw=1.9833, running_loss=1.8904, LR=0.000100
[2025-08-10 12:52:40,322][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012336] [Batch 01260/03692] [00:11:18/00:21:48, 0.538s/it]: train_loss_raw=1.7936, running_loss=1.8922, LR=0.000100
[2025-08-10 12:52:46,625][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012348] [Batch 01272/03692] [00:11:24/00:21:42, 0.538s/it]: train_loss_raw=1.8134, running_loss=1.8917, LR=0.000100
[2025-08-10 12:52:52,905][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012360] [Batch 01284/03692] [00:11:30/00:21:35, 0.538s/it]: train_loss_raw=1.7979, running_loss=1.8910, LR=0.000100
[2025-08-10 12:52:59,150][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012372] [Batch 01296/03692] [00:11:36/00:21:28, 0.538s/it]: train_loss_raw=1.9793, running_loss=1.8872, LR=0.000100
[2025-08-10 12:53:05,581][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012384] [Batch 01308/03692] [00:11:43/00:21:22, 0.538s/it]: train_loss_raw=1.7776, running_loss=1.8882, LR=0.000100
[2025-08-10 12:53:12,081][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012396] [Batch 01320/03692] [00:11:49/00:21:15, 0.538s/it]: train_loss_raw=1.7329, running_loss=1.8846, LR=0.000100
[2025-08-10 12:53:18,722][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012408] [Batch 01332/03692] [00:11:56/00:21:09, 0.538s/it]: train_loss_raw=1.8774, running_loss=1.8835, LR=0.000100
[2025-08-10 12:53:25,226][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012420] [Batch 01344/03692] [00:12:03/00:21:03, 0.538s/it]: train_loss_raw=1.8155, running_loss=1.8760, LR=0.000100
[2025-08-10 12:53:31,691][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012432] [Batch 01356/03692] [00:12:09/00:20:56, 0.538s/it]: train_loss_raw=1.8714, running_loss=1.8739, LR=0.000100
[2025-08-10 12:53:38,195][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012444] [Batch 01368/03692] [00:12:16/00:20:50, 0.538s/it]: train_loss_raw=1.9419, running_loss=1.8765, LR=0.000100
[2025-08-10 12:53:44,705][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012456] [Batch 01380/03692] [00:12:22/00:20:44, 0.538s/it]: train_loss_raw=1.8277, running_loss=1.8767, LR=0.000100
[2025-08-10 12:53:51,187][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012468] [Batch 01392/03692] [00:12:29/00:20:37, 0.538s/it]: train_loss_raw=1.8805, running_loss=1.8794, LR=0.000100
[2025-08-10 12:53:57,557][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012480] [Batch 01404/03692] [00:12:35/00:20:31, 0.538s/it]: train_loss_raw=2.0266, running_loss=1.8836, LR=0.000100
[2025-08-10 12:54:03,966][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012492] [Batch 01416/03692] [00:12:41/00:20:24, 0.538s/it]: train_loss_raw=1.8613, running_loss=1.8826, LR=0.000100
[2025-08-10 12:54:10,373][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012504] [Batch 01428/03692] [00:12:48/00:20:17, 0.538s/it]: train_loss_raw=1.8724, running_loss=1.8830, LR=0.000100
[2025-08-10 12:54:16,749][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012516] [Batch 01440/03692] [00:12:54/00:20:11, 0.538s/it]: train_loss_raw=1.8786, running_loss=1.8836, LR=0.000100
[2025-08-10 12:54:23,103][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012528] [Batch 01452/03692] [00:13:00/00:20:04, 0.538s/it]: train_loss_raw=1.8544, running_loss=1.8873, LR=0.000100
[2025-08-10 12:54:29,572][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012540] [Batch 01464/03692] [00:13:07/00:19:58, 0.538s/it]: train_loss_raw=1.8570, running_loss=1.8839, LR=0.000100
[2025-08-10 12:54:36,153][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012552] [Batch 01476/03692] [00:13:13/00:19:52, 0.538s/it]: train_loss_raw=1.8080, running_loss=1.8814, LR=0.000100
[2025-08-10 12:54:42,595][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012564] [Batch 01488/03692] [00:13:20/00:19:45, 0.538s/it]: train_loss_raw=1.8623, running_loss=1.8811, LR=0.000100
[2025-08-10 12:54:49,029][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012576] [Batch 01500/03692] [00:13:26/00:19:39, 0.538s/it]: train_loss_raw=1.8765, running_loss=1.8797, LR=0.000100
[2025-08-10 12:54:55,499][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012588] [Batch 01512/03692] [00:13:33/00:19:32, 0.538s/it]: train_loss_raw=1.7726, running_loss=1.8804, LR=0.000100
[2025-08-10 12:55:01,934][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012600] [Batch 01524/03692] [00:13:39/00:19:26, 0.538s/it]: train_loss_raw=1.8667, running_loss=1.8759, LR=0.000100
[2025-08-10 12:55:08,394][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012612] [Batch 01536/03692] [00:13:46/00:19:19, 0.538s/it]: train_loss_raw=1.8712, running_loss=1.8741, LR=0.000100
[2025-08-10 12:55:15,007][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012624] [Batch 01548/03692] [00:13:52/00:19:13, 0.538s/it]: train_loss_raw=1.8183, running_loss=1.8683, LR=0.000100
[2025-08-10 12:55:21,612][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012636] [Batch 01560/03692] [00:13:59/00:19:07, 0.538s/it]: train_loss_raw=1.8130, running_loss=1.8706, LR=0.000100
[2025-08-10 12:55:28,103][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012648] [Batch 01572/03692] [00:14:05/00:19:00, 0.538s/it]: train_loss_raw=1.9053, running_loss=1.8702, LR=0.000100
[2025-08-10 12:55:34,609][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012660] [Batch 01584/03692] [00:14:12/00:18:54, 0.538s/it]: train_loss_raw=1.8133, running_loss=1.8706, LR=0.000100
[2025-08-10 12:55:41,185][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012672] [Batch 01596/03692] [00:14:19/00:18:48, 0.538s/it]: train_loss_raw=1.7420, running_loss=1.8690, LR=0.000100
[2025-08-10 12:55:47,693][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012684] [Batch 01608/03692] [00:14:25/00:18:41, 0.538s/it]: train_loss_raw=1.8863, running_loss=1.8739, LR=0.000100
[2025-08-10 12:55:54,093][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012696] [Batch 01620/03692] [00:14:31/00:18:35, 0.538s/it]: train_loss_raw=1.8966, running_loss=1.8752, LR=0.000100
[2025-08-10 12:56:00,463][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012708] [Batch 01632/03692] [00:14:38/00:18:28, 0.538s/it]: train_loss_raw=1.8942, running_loss=1.8743, LR=0.000100
[2025-08-10 12:56:07,086][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012720] [Batch 01644/03692] [00:14:44/00:18:22, 0.538s/it]: train_loss_raw=1.8358, running_loss=1.8735, LR=0.000100
[2025-08-10 12:56:13,638][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012732] [Batch 01656/03692] [00:14:51/00:18:16, 0.538s/it]: train_loss_raw=1.9566, running_loss=1.8742, LR=0.000100
[2025-08-10 12:56:20,107][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012744] [Batch 01668/03692] [00:14:57/00:18:09, 0.538s/it]: train_loss_raw=1.8433, running_loss=1.8728, LR=0.000100
[2025-08-10 12:56:26,580][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012756] [Batch 01680/03692] [00:15:04/00:18:03, 0.538s/it]: train_loss_raw=1.8274, running_loss=1.8702, LR=0.000100
[2025-08-10 12:56:33,013][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012768] [Batch 01692/03692] [00:15:10/00:17:56, 0.538s/it]: train_loss_raw=1.8492, running_loss=1.8716, LR=0.000100
[2025-08-10 12:56:39,409][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012780] [Batch 01704/03692] [00:15:17/00:17:50, 0.538s/it]: train_loss_raw=1.8038, running_loss=1.8712, LR=0.000100
[2025-08-10 12:56:45,926][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012792] [Batch 01716/03692] [00:15:23/00:17:43, 0.538s/it]: train_loss_raw=1.9678, running_loss=1.8695, LR=0.000100
[2025-08-10 12:56:52,410][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012804] [Batch 01728/03692] [00:15:30/00:17:37, 0.538s/it]: train_loss_raw=1.7901, running_loss=1.8695, LR=0.000100
[2025-08-10 12:56:59,069][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012816] [Batch 01740/03692] [00:15:36/00:17:31, 0.538s/it]: train_loss_raw=2.0082, running_loss=1.8661, LR=0.000100
[2025-08-10 12:57:05,590][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012828] [Batch 01752/03692] [00:15:43/00:17:24, 0.538s/it]: train_loss_raw=1.8681, running_loss=1.8636, LR=0.000100
[2025-08-10 12:57:12,074][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012840] [Batch 01764/03692] [00:15:49/00:17:18, 0.539s/it]: train_loss_raw=1.7928, running_loss=1.8654, LR=0.000100
[2025-08-10 12:57:18,638][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012852] [Batch 01776/03692] [00:15:56/00:17:11, 0.539s/it]: train_loss_raw=1.8794, running_loss=1.8663, LR=0.000100
[2025-08-10 12:57:25,271][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012864] [Batch 01788/03692] [00:16:03/00:17:05, 0.539s/it]: train_loss_raw=1.8971, running_loss=1.8655, LR=0.000100
[2025-08-10 12:57:31,826][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012876] [Batch 01800/03692] [00:16:09/00:16:59, 0.539s/it]: train_loss_raw=1.7357, running_loss=1.8617, LR=0.000100
[2025-08-10 12:57:38,326][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012888] [Batch 01812/03692] [00:16:16/00:16:52, 0.539s/it]: train_loss_raw=1.8958, running_loss=1.8610, LR=0.000100
[2025-08-10 12:57:44,866][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012900] [Batch 01824/03692] [00:16:22/00:16:46, 0.539s/it]: train_loss_raw=1.8224, running_loss=1.8610, LR=0.000100
[2025-08-10 12:57:51,413][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012912] [Batch 01836/03692] [00:16:29/00:16:40, 0.539s/it]: train_loss_raw=1.7768, running_loss=1.8594, LR=0.000100
[2025-08-10 12:57:57,912][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012924] [Batch 01848/03692] [00:16:35/00:16:33, 0.539s/it]: train_loss_raw=1.7798, running_loss=1.8610, LR=0.000100
[2025-08-10 12:58:04,515][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012936] [Batch 01860/03692] [00:16:42/00:16:27, 0.539s/it]: train_loss_raw=1.8757, running_loss=1.8615, LR=0.000100
[2025-08-10 12:58:10,982][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012948] [Batch 01872/03692] [00:16:48/00:16:20, 0.539s/it]: train_loss_raw=1.7883, running_loss=1.8585, LR=0.000100
[2025-08-10 12:58:17,505][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012960] [Batch 01884/03692] [00:16:55/00:16:14, 0.539s/it]: train_loss_raw=1.8688, running_loss=1.8595, LR=0.000100
[2025-08-10 12:58:24,058][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012972] [Batch 01896/03692] [00:17:01/00:16:08, 0.539s/it]: train_loss_raw=1.8821, running_loss=1.8614, LR=0.000100
[2025-08-10 12:58:30,622][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012984] [Batch 01908/03692] [00:17:08/00:16:01, 0.539s/it]: train_loss_raw=1.9185, running_loss=1.8595, LR=0.000100
[2025-08-10 12:58:37,090][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012996] [Batch 01920/03692] [00:17:14/00:15:55, 0.539s/it]: train_loss_raw=1.9030, running_loss=1.8579, LR=0.000100
[2025-08-10 12:58:43,402][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013008] [Batch 01932/03692] [00:17:21/00:15:48, 0.539s/it]: train_loss_raw=1.8164, running_loss=1.8577, LR=0.000100
[2025-08-10 12:58:49,895][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013020] [Batch 01944/03692] [00:17:27/00:15:42, 0.539s/it]: train_loss_raw=1.8626, running_loss=1.8597, LR=0.000100
[2025-08-10 12:58:56,475][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013032] [Batch 01956/03692] [00:17:34/00:15:35, 0.539s/it]: train_loss_raw=1.9098, running_loss=1.8572, LR=0.000100
[2025-08-10 12:59:03,033][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013044] [Batch 01968/03692] [00:17:40/00:15:29, 0.539s/it]: train_loss_raw=1.8732, running_loss=1.8584, LR=0.000100
[2025-08-10 12:59:09,681][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013056] [Batch 01980/03692] [00:17:47/00:15:23, 0.539s/it]: train_loss_raw=1.9161, running_loss=1.8629, LR=0.000100
[2025-08-10 12:59:16,259][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013068] [Batch 01992/03692] [00:17:54/00:15:16, 0.539s/it]: train_loss_raw=1.8413, running_loss=1.8626, LR=0.000100
[2025-08-10 12:59:22,808][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013080] [Batch 02004/03692] [00:18:00/00:15:10, 0.539s/it]: train_loss_raw=1.8283, running_loss=1.8595, LR=0.000100
[2025-08-10 12:59:29,389][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013092] [Batch 02016/03692] [00:18:07/00:15:03, 0.539s/it]: train_loss_raw=1.8692, running_loss=1.8613, LR=0.000100
[2025-08-10 12:59:35,864][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013104] [Batch 02028/03692] [00:18:13/00:14:57, 0.539s/it]: train_loss_raw=1.8042, running_loss=1.8604, LR=0.000100
[2025-08-10 12:59:42,412][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013116] [Batch 02040/03692] [00:18:20/00:14:50, 0.539s/it]: train_loss_raw=1.7618, running_loss=1.8579, LR=0.000100
[2025-08-10 12:59:48,972][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013128] [Batch 02052/03692] [00:18:26/00:14:44, 0.539s/it]: train_loss_raw=1.8501, running_loss=1.8578, LR=0.000100
[2025-08-10 12:59:55,575][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013140] [Batch 02064/03692] [00:18:33/00:14:38, 0.539s/it]: train_loss_raw=1.9079, running_loss=1.8595, LR=0.000100
[2025-08-10 13:00:02,149][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013152] [Batch 02076/03692] [00:18:39/00:14:31, 0.539s/it]: train_loss_raw=1.7825, running_loss=1.8611, LR=0.000100
[2025-08-10 13:00:08,684][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013164] [Batch 02088/03692] [00:18:46/00:14:25, 0.540s/it]: train_loss_raw=1.9907, running_loss=1.8606, LR=0.000100
[2025-08-10 13:00:15,348][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013176] [Batch 02100/03692] [00:18:53/00:14:19, 0.540s/it]: train_loss_raw=1.9013, running_loss=1.8599, LR=0.000100
[2025-08-10 13:00:21,950][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013188] [Batch 02112/03692] [00:18:59/00:14:12, 0.540s/it]: train_loss_raw=1.8048, running_loss=1.8599, LR=0.000100
[2025-08-10 13:00:28,497][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013200] [Batch 02124/03692] [00:19:06/00:14:06, 0.540s/it]: train_loss_raw=1.8775, running_loss=1.8634, LR=0.000100
[2025-08-10 13:00:34,959][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013212] [Batch 02136/03692] [00:19:12/00:13:59, 0.540s/it]: train_loss_raw=1.7972, running_loss=1.8559, LR=0.000100
[2025-08-10 13:00:41,468][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013224] [Batch 02148/03692] [00:19:19/00:13:53, 0.540s/it]: train_loss_raw=1.8237, running_loss=1.8553, LR=0.000100
[2025-08-10 13:00:55,170][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013236] [Batch 02160/03692] [00:19:33/00:13:51, 0.543s/it]: train_loss_raw=1.9377, running_loss=1.8567, LR=0.000100
[2025-08-10 13:01:01,591][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013248] [Batch 02172/03692] [00:19:39/00:13:45, 0.543s/it]: train_loss_raw=1.7586, running_loss=1.8522, LR=0.000100
[2025-08-10 13:01:08,093][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013260] [Batch 02184/03692] [00:19:45/00:13:38, 0.543s/it]: train_loss_raw=1.8390, running_loss=1.8475, LR=0.000100
[2025-08-10 13:01:14,585][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013272] [Batch 02196/03692] [00:19:52/00:13:32, 0.543s/it]: train_loss_raw=1.7485, running_loss=1.8508, LR=0.000100
[2025-08-10 13:01:21,098][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013284] [Batch 02208/03692] [00:19:58/00:13:25, 0.543s/it]: train_loss_raw=1.8566, running_loss=1.8542, LR=0.000100
[2025-08-10 13:01:27,681][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013296] [Batch 02220/03692] [00:20:05/00:13:19, 0.543s/it]: train_loss_raw=1.7703, running_loss=1.8527, LR=0.000100
[2025-08-10 13:01:34,315][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013308] [Batch 02232/03692] [00:20:12/00:13:12, 0.543s/it]: train_loss_raw=1.8308, running_loss=1.8509, LR=0.000100
[2025-08-10 13:01:40,733][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013320] [Batch 02244/03692] [00:20:18/00:13:06, 0.543s/it]: train_loss_raw=2.0369, running_loss=1.8527, LR=0.000100
[2025-08-10 13:01:47,267][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013332] [Batch 02256/03692] [00:20:25/00:12:59, 0.543s/it]: train_loss_raw=1.8823, running_loss=1.8531, LR=0.000100
[2025-08-10 13:01:53,706][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013344] [Batch 02268/03692] [00:20:31/00:12:53, 0.543s/it]: train_loss_raw=1.9593, running_loss=1.8536, LR=0.000100
[2025-08-10 13:02:00,195][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013356] [Batch 02280/03692] [00:20:38/00:12:46, 0.543s/it]: train_loss_raw=1.8186, running_loss=1.8546, LR=0.000100
[2025-08-10 13:02:06,663][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013368] [Batch 02292/03692] [00:20:44/00:12:40, 0.543s/it]: train_loss_raw=1.9379, running_loss=1.8522, LR=0.000100
[2025-08-10 13:02:13,085][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013380] [Batch 02304/03692] [00:20:50/00:12:33, 0.543s/it]: train_loss_raw=1.8570, running_loss=1.8540, LR=0.000100
[2025-08-10 13:02:19,491][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013392] [Batch 02316/03692] [00:20:57/00:12:27, 0.543s/it]: train_loss_raw=1.8703, running_loss=1.8506, LR=0.000100
[2025-08-10 13:02:25,947][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013404] [Batch 02328/03692] [00:21:03/00:12:20, 0.543s/it]: train_loss_raw=1.7618, running_loss=1.8467, LR=0.000100
[2025-08-10 13:02:32,354][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013416] [Batch 02340/03692] [00:21:10/00:12:13, 0.543s/it]: train_loss_raw=1.7509, running_loss=1.8424, LR=0.000100
[2025-08-10 13:02:38,889][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013428] [Batch 02352/03692] [00:21:16/00:12:07, 0.543s/it]: train_loss_raw=1.8009, running_loss=1.8406, LR=0.000100
[2025-08-10 13:02:45,494][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013440] [Batch 02364/03692] [00:21:23/00:12:00, 0.543s/it]: train_loss_raw=1.7826, running_loss=1.8431, LR=0.000100
[2025-08-10 13:02:51,933][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013452] [Batch 02376/03692] [00:21:29/00:11:54, 0.543s/it]: train_loss_raw=1.6939, running_loss=1.8437, LR=0.000100
[2025-08-10 13:02:58,379][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013464] [Batch 02388/03692] [00:21:36/00:11:47, 0.543s/it]: train_loss_raw=1.8442, running_loss=1.8470, LR=0.000100
[2025-08-10 13:03:04,966][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013476] [Batch 02400/03692] [00:21:42/00:11:41, 0.543s/it]: train_loss_raw=1.8518, running_loss=1.8447, LR=0.000100
[2025-08-10 13:03:11,535][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013488] [Batch 02412/03692] [00:21:49/00:11:34, 0.543s/it]: train_loss_raw=1.7633, running_loss=1.8445, LR=0.000100
[2025-08-10 13:03:18,017][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013500] [Batch 02424/03692] [00:21:55/00:11:28, 0.543s/it]: train_loss_raw=1.7829, running_loss=1.8374, LR=0.000100
[2025-08-10 13:03:24,440][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013512] [Batch 02436/03692] [00:22:02/00:11:21, 0.543s/it]: train_loss_raw=1.7870, running_loss=1.8336, LR=0.000100
[2025-08-10 13:03:30,887][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013524] [Batch 02448/03692] [00:22:08/00:11:15, 0.543s/it]: train_loss_raw=1.6643, running_loss=1.8347, LR=0.000100
[2025-08-10 13:03:37,333][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013536] [Batch 02460/03692] [00:22:15/00:11:08, 0.543s/it]: train_loss_raw=1.9373, running_loss=1.8340, LR=0.000100
[2025-08-10 13:03:43,882][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013548] [Batch 02472/03692] [00:22:21/00:11:02, 0.543s/it]: train_loss_raw=1.8410, running_loss=1.8374, LR=0.000100
[2025-08-10 13:03:50,383][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013560] [Batch 02484/03692] [00:22:28/00:10:55, 0.543s/it]: train_loss_raw=1.8700, running_loss=1.8373, LR=0.000100
[2025-08-10 13:03:56,809][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013572] [Batch 02496/03692] [00:22:34/00:10:49, 0.543s/it]: train_loss_raw=1.9821, running_loss=1.8364, LR=0.000100
[2025-08-10 13:04:03,427][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013584] [Batch 02508/03692] [00:22:41/00:10:42, 0.543s/it]: train_loss_raw=1.8983, running_loss=1.8382, LR=0.000100
[2025-08-10 13:04:10,104][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013596] [Batch 02520/03692] [00:22:47/00:10:36, 0.543s/it]: train_loss_raw=1.8471, running_loss=1.8394, LR=0.000100
[2025-08-10 13:04:16,557][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013608] [Batch 02532/03692] [00:22:54/00:10:29, 0.543s/it]: train_loss_raw=1.8459, running_loss=1.8423, LR=0.000100
[2025-08-10 13:04:23,089][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013620] [Batch 02544/03692] [00:23:00/00:10:23, 0.543s/it]: train_loss_raw=1.9186, running_loss=1.8392, LR=0.000100
[2025-08-10 13:04:29,532][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013632] [Batch 02556/03692] [00:23:07/00:10:16, 0.543s/it]: train_loss_raw=1.9320, running_loss=1.8405, LR=0.000100
[2025-08-10 13:04:35,965][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013644] [Batch 02568/03692] [00:23:13/00:10:10, 0.543s/it]: train_loss_raw=1.8444, running_loss=1.8349, LR=0.000100
[2025-08-10 13:04:42,391][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013656] [Batch 02580/03692] [00:23:20/00:10:03, 0.543s/it]: train_loss_raw=1.8547, running_loss=1.8362, LR=0.000100
[2025-08-10 13:04:48,857][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013668] [Batch 02592/03692] [00:23:26/00:09:56, 0.543s/it]: train_loss_raw=1.8763, running_loss=1.8383, LR=0.000100
[2025-08-10 13:04:55,309][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013680] [Batch 02604/03692] [00:23:33/00:09:50, 0.543s/it]: train_loss_raw=1.7961, running_loss=1.8380, LR=0.000100
[2025-08-10 13:05:01,812][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013692] [Batch 02616/03692] [00:23:39/00:09:43, 0.543s/it]: train_loss_raw=1.8958, running_loss=1.8351, LR=0.000100
[2025-08-10 13:05:08,276][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013704] [Batch 02628/03692] [00:23:46/00:09:37, 0.543s/it]: train_loss_raw=1.8453, running_loss=1.8331, LR=0.000100
[2025-08-10 13:05:14,786][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013716] [Batch 02640/03692] [00:23:52/00:09:30, 0.543s/it]: train_loss_raw=1.8041, running_loss=1.8320, LR=0.000100
[2025-08-10 13:05:21,328][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013728] [Batch 02652/03692] [00:23:59/00:09:24, 0.543s/it]: train_loss_raw=1.7870, running_loss=1.8310, LR=0.000100
[2025-08-10 13:05:27,836][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013740] [Batch 02664/03692] [00:24:05/00:09:17, 0.543s/it]: train_loss_raw=1.8876, running_loss=1.8349, LR=0.000100
[2025-08-10 13:05:34,468][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013752] [Batch 02676/03692] [00:24:12/00:09:11, 0.543s/it]: train_loss_raw=1.7185, running_loss=1.8290, LR=0.000100
[2025-08-10 13:05:40,929][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013764] [Batch 02688/03692] [00:24:18/00:09:04, 0.543s/it]: train_loss_raw=1.8567, running_loss=1.8277, LR=0.000100
[2025-08-10 13:05:47,489][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013776] [Batch 02700/03692] [00:24:25/00:08:58, 0.543s/it]: train_loss_raw=1.7317, running_loss=1.8236, LR=0.000100
[2025-08-10 13:05:54,036][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013788] [Batch 02712/03692] [00:24:31/00:08:51, 0.543s/it]: train_loss_raw=1.9315, running_loss=1.8283, LR=0.000100
[2025-08-10 13:06:00,572][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013800] [Batch 02724/03692] [00:24:38/00:08:45, 0.543s/it]: train_loss_raw=1.9488, running_loss=1.8281, LR=0.000100
[2025-08-10 13:06:06,997][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013812] [Batch 02736/03692] [00:24:44/00:08:38, 0.543s/it]: train_loss_raw=1.7316, running_loss=1.8283, LR=0.000100
[2025-08-10 13:06:13,396][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013824] [Batch 02748/03692] [00:24:51/00:08:32, 0.543s/it]: train_loss_raw=1.9303, running_loss=1.8271, LR=0.000100
[2025-08-10 13:06:19,798][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013836] [Batch 02760/03692] [00:24:57/00:08:25, 0.543s/it]: train_loss_raw=1.7298, running_loss=1.8257, LR=0.000100
[2025-08-10 13:06:26,154][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013848] [Batch 02772/03692] [00:25:04/00:08:19, 0.543s/it]: train_loss_raw=1.8546, running_loss=1.8274, LR=0.000100
[2025-08-10 13:06:32,613][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013860] [Batch 02784/03692] [00:25:10/00:08:12, 0.543s/it]: train_loss_raw=1.9458, running_loss=1.8280, LR=0.000100
[2025-08-10 13:06:39,095][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013872] [Batch 02796/03692] [00:25:16/00:08:06, 0.543s/it]: train_loss_raw=1.9075, running_loss=1.8290, LR=0.000100
[2025-08-10 13:06:45,525][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013884] [Batch 02808/03692] [00:25:23/00:07:59, 0.543s/it]: train_loss_raw=1.7815, running_loss=1.8259, LR=0.000100
[2025-08-10 13:06:52,082][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013896] [Batch 02820/03692] [00:25:29/00:07:53, 0.543s/it]: train_loss_raw=1.6751, running_loss=1.8242, LR=0.000100
[2025-08-10 13:06:58,542][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013908] [Batch 02832/03692] [00:25:36/00:07:46, 0.543s/it]: train_loss_raw=1.8620, running_loss=1.8234, LR=0.000100
[2025-08-10 13:07:04,886][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013920] [Batch 02844/03692] [00:25:42/00:07:39, 0.542s/it]: train_loss_raw=1.9477, running_loss=1.8268, LR=0.000100
[2025-08-10 13:07:11,045][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013932] [Batch 02856/03692] [00:25:48/00:07:33, 0.542s/it]: train_loss_raw=1.8304, running_loss=1.8276, LR=0.000100
[2025-08-10 13:07:17,288][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013944] [Batch 02868/03692] [00:25:55/00:07:26, 0.542s/it]: train_loss_raw=1.8157, running_loss=1.8300, LR=0.000100
[2025-08-10 13:07:23,538][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013956] [Batch 02880/03692] [00:26:01/00:07:20, 0.542s/it]: train_loss_raw=1.7772, running_loss=1.8278, LR=0.000100
[2025-08-10 13:07:29,928][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013968] [Batch 02892/03692] [00:26:07/00:07:13, 0.542s/it]: train_loss_raw=1.8615, running_loss=1.8226, LR=0.000100
[2025-08-10 13:07:36,471][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013980] [Batch 02904/03692] [00:26:14/00:07:07, 0.542s/it]: train_loss_raw=1.7769, running_loss=1.8222, LR=0.000100
[2025-08-10 13:07:42,814][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013992] [Batch 02916/03692] [00:26:20/00:07:00, 0.542s/it]: train_loss_raw=1.8430, running_loss=1.8177, LR=0.000100
[2025-08-10 13:07:53,290][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014004] [Batch 02928/03692] [00:26:31/00:06:55, 0.543s/it]: train_loss_raw=1.7687, running_loss=1.8159, LR=0.000100
[2025-08-10 13:07:59,697][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014016] [Batch 02940/03692] [00:26:37/00:06:48, 0.543s/it]: train_loss_raw=1.8422, running_loss=1.8151, LR=0.000100
[2025-08-10 13:08:05,997][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014028] [Batch 02952/03692] [00:26:43/00:06:42, 0.543s/it]: train_loss_raw=1.8063, running_loss=1.8181, LR=0.000100
[2025-08-10 13:08:12,182][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014040] [Batch 02964/03692] [00:26:50/00:06:35, 0.543s/it]: train_loss_raw=1.8590, running_loss=1.8205, LR=0.000100
[2025-08-10 13:08:18,465][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014052] [Batch 02976/03692] [00:26:56/00:06:28, 0.543s/it]: train_loss_raw=1.9373, running_loss=1.8218, LR=0.000100
[2025-08-10 13:08:24,871][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014064] [Batch 02988/03692] [00:27:02/00:06:22, 0.543s/it]: train_loss_raw=1.7798, running_loss=1.8163, LR=0.000100
[2025-08-10 13:08:31,220][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014076] [Batch 03000/03692] [00:27:09/00:06:15, 0.543s/it]: train_loss_raw=1.8164, running_loss=1.8163, LR=0.000100
[2025-08-10 13:08:37,571][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014088] [Batch 03012/03692] [00:27:15/00:06:09, 0.543s/it]: train_loss_raw=1.7852, running_loss=1.8142, LR=0.000100
[2025-08-10 13:08:43,993][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014100] [Batch 03024/03692] [00:27:21/00:06:02, 0.543s/it]: train_loss_raw=1.8269, running_loss=1.8139, LR=0.000100
[2025-08-10 13:08:50,493][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014112] [Batch 03036/03692] [00:27:28/00:05:56, 0.543s/it]: train_loss_raw=1.9162, running_loss=1.8165, LR=0.000100
[2025-08-10 13:08:56,921][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014124] [Batch 03048/03692] [00:27:34/00:05:49, 0.543s/it]: train_loss_raw=1.8453, running_loss=1.8128, LR=0.000100
[2025-08-10 13:09:03,369][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014136] [Batch 03060/03692] [00:27:41/00:05:43, 0.543s/it]: train_loss_raw=1.7417, running_loss=1.8087, LR=0.000100
[2025-08-10 13:09:10,029][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014148] [Batch 03072/03692] [00:27:47/00:05:36, 0.543s/it]: train_loss_raw=1.8898, running_loss=1.8125, LR=0.000100
[2025-08-10 13:09:16,678][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014160] [Batch 03084/03692] [00:27:54/00:05:30, 0.543s/it]: train_loss_raw=1.7362, running_loss=1.8153, LR=0.000100
[2025-08-10 13:09:23,265][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014172] [Batch 03096/03692] [00:28:01/00:05:23, 0.543s/it]: train_loss_raw=1.8847, running_loss=1.8124, LR=0.000100
[2025-08-10 13:09:29,782][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014184] [Batch 03108/03692] [00:28:07/00:05:17, 0.543s/it]: train_loss_raw=1.7510, running_loss=1.8105, LR=0.000100
[2025-08-10 13:09:37,162][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014196] [Batch 03120/03692] [00:28:15/00:05:10, 0.543s/it]: train_loss_raw=1.7972, running_loss=1.8087, LR=0.000100
[2025-08-10 13:09:44,057][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014208] [Batch 03132/03692] [00:28:21/00:05:04, 0.543s/it]: train_loss_raw=1.8089, running_loss=1.8095, LR=0.000100
[2025-08-10 13:09:50,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014220] [Batch 03144/03692] [00:28:28/00:04:57, 0.543s/it]: train_loss_raw=1.7006, running_loss=1.8095, LR=0.000100
[2025-08-10 13:09:57,544][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014232] [Batch 03156/03692] [00:28:35/00:04:51, 0.544s/it]: train_loss_raw=1.7047, running_loss=1.8059, LR=0.000100
[2025-08-10 13:10:04,142][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014244] [Batch 03168/03692] [00:28:41/00:04:44, 0.544s/it]: train_loss_raw=1.7986, running_loss=1.8089, LR=0.000100
[2025-08-10 13:10:10,787][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014256] [Batch 03180/03692] [00:28:48/00:04:38, 0.544s/it]: train_loss_raw=1.8647, running_loss=1.8060, LR=0.000100
[2025-08-10 13:10:17,433][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014268] [Batch 03192/03692] [00:28:55/00:04:31, 0.544s/it]: train_loss_raw=1.8147, running_loss=1.8059, LR=0.000100
[2025-08-10 13:10:24,071][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014280] [Batch 03204/03692] [00:29:01/00:04:25, 0.544s/it]: train_loss_raw=1.7456, running_loss=1.8048, LR=0.000100
[2025-08-10 13:10:30,729][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014292] [Batch 03216/03692] [00:29:08/00:04:18, 0.544s/it]: train_loss_raw=1.7431, running_loss=1.8072, LR=0.000100
[2025-08-10 13:10:37,101][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014304] [Batch 03228/03692] [00:29:14/00:04:12, 0.544s/it]: train_loss_raw=1.8349, running_loss=1.8069, LR=0.000100
[2025-08-10 13:10:43,545][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014316] [Batch 03240/03692] [00:29:21/00:04:05, 0.544s/it]: train_loss_raw=1.8833, running_loss=1.8067, LR=0.000100
[2025-08-10 13:10:49,920][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014328] [Batch 03252/03692] [00:29:27/00:03:59, 0.544s/it]: train_loss_raw=1.7931, running_loss=1.8036, LR=0.000100
[2025-08-10 13:10:56,404][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014340] [Batch 03264/03692] [00:29:34/00:03:52, 0.544s/it]: train_loss_raw=1.7905, running_loss=1.8042, LR=0.000100
[2025-08-10 13:11:02,815][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014352] [Batch 03276/03692] [00:29:40/00:03:46, 0.544s/it]: train_loss_raw=1.7327, running_loss=1.8043, LR=0.000100
[2025-08-10 13:11:09,121][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014364] [Batch 03288/03692] [00:29:46/00:03:39, 0.543s/it]: train_loss_raw=1.8079, running_loss=1.8046, LR=0.000100
[2025-08-10 13:11:15,571][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014376] [Batch 03300/03692] [00:29:53/00:03:33, 0.543s/it]: train_loss_raw=1.7802, running_loss=1.8030, LR=0.000100
[2025-08-10 13:11:22,167][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014388] [Batch 03312/03692] [00:30:00/00:03:26, 0.543s/it]: train_loss_raw=1.7920, running_loss=1.8021, LR=0.000100
[2025-08-10 13:11:28,817][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014400] [Batch 03324/03692] [00:30:06/00:03:20, 0.544s/it]: train_loss_raw=1.8089, running_loss=1.8032, LR=0.000100
[2025-08-10 13:11:35,391][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014412] [Batch 03336/03692] [00:30:13/00:03:13, 0.544s/it]: train_loss_raw=1.8608, running_loss=1.8035, LR=0.000100
[2025-08-10 13:11:42,024][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014424] [Batch 03348/03692] [00:30:19/00:03:06, 0.544s/it]: train_loss_raw=1.8658, running_loss=1.8042, LR=0.000100
[2025-08-10 13:11:48,563][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014436] [Batch 03360/03692] [00:30:26/00:03:00, 0.544s/it]: train_loss_raw=1.8889, running_loss=1.8065, LR=0.000100
[2025-08-10 13:11:55,160][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014448] [Batch 03372/03692] [00:30:33/00:02:53, 0.544s/it]: train_loss_raw=1.8039, running_loss=1.8057, LR=0.000100
[2025-08-10 13:12:01,792][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014460] [Batch 03384/03692] [00:30:39/00:02:47, 0.544s/it]: train_loss_raw=1.8371, running_loss=1.8057, LR=0.000100
[2025-08-10 13:12:08,334][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014472] [Batch 03396/03692] [00:30:46/00:02:40, 0.544s/it]: train_loss_raw=1.6569, running_loss=1.8031, LR=0.000100
[2025-08-10 13:12:14,923][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014484] [Batch 03408/03692] [00:30:52/00:02:34, 0.544s/it]: train_loss_raw=1.9087, running_loss=1.8082, LR=0.000100
[2025-08-10 13:12:21,574][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014496] [Batch 03420/03692] [00:30:59/00:02:27, 0.544s/it]: train_loss_raw=1.8814, running_loss=1.8056, LR=0.000100
[2025-08-10 13:12:28,259][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014508] [Batch 03432/03692] [00:31:06/00:02:21, 0.544s/it]: train_loss_raw=1.7403, running_loss=1.8086, LR=0.000100
[2025-08-10 13:12:34,867][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014520] [Batch 03444/03692] [00:31:12/00:02:14, 0.544s/it]: train_loss_raw=1.8586, running_loss=1.8039, LR=0.000100
[2025-08-10 13:12:41,410][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014532] [Batch 03456/03692] [00:31:19/00:02:08, 0.544s/it]: train_loss_raw=1.8361, running_loss=1.8009, LR=0.000100
[2025-08-10 13:12:47,950][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014544] [Batch 03468/03692] [00:31:25/00:02:01, 0.544s/it]: train_loss_raw=1.6684, running_loss=1.7994, LR=0.000100
[2025-08-10 13:12:54,565][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014556] [Batch 03480/03692] [00:31:32/00:01:55, 0.544s/it]: train_loss_raw=1.8579, running_loss=1.7981, LR=0.000100
[2025-08-10 13:13:00,980][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014568] [Batch 03492/03692] [00:31:38/00:01:48, 0.544s/it]: train_loss_raw=1.7993, running_loss=1.7939, LR=0.000100
[2025-08-10 13:13:07,260][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014580] [Batch 03504/03692] [00:31:45/00:01:42, 0.544s/it]: train_loss_raw=1.8468, running_loss=1.7967, LR=0.000100
[2025-08-10 13:13:13,619][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014592] [Batch 03516/03692] [00:31:51/00:01:35, 0.544s/it]: train_loss_raw=1.8605, running_loss=1.7955, LR=0.000100
[2025-08-10 13:13:19,917][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014604] [Batch 03528/03692] [00:31:57/00:01:29, 0.544s/it]: train_loss_raw=1.8333, running_loss=1.7943, LR=0.000100
[2025-08-10 13:13:26,185][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014616] [Batch 03540/03692] [00:32:04/00:01:22, 0.544s/it]: train_loss_raw=1.8533, running_loss=1.7950, LR=0.000100
[2025-08-10 13:13:32,574][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014628] [Batch 03552/03692] [00:32:10/00:01:16, 0.543s/it]: train_loss_raw=1.6037, running_loss=1.7966, LR=0.000100
[2025-08-10 13:13:38,967][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014640] [Batch 03564/03692] [00:32:16/00:01:09, 0.543s/it]: train_loss_raw=1.7388, running_loss=1.7942, LR=0.000100
[2025-08-10 13:13:45,460][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014652] [Batch 03576/03692] [00:32:23/00:01:03, 0.543s/it]: train_loss_raw=1.6811, running_loss=1.7935, LR=0.000100
[2025-08-10 13:13:52,010][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014664] [Batch 03588/03692] [00:32:29/00:00:56, 0.543s/it]: train_loss_raw=1.8014, running_loss=1.7929, LR=0.000100
[2025-08-10 13:13:58,637][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014676] [Batch 03600/03692] [00:32:36/00:00:49, 0.543s/it]: train_loss_raw=1.7157, running_loss=1.7917, LR=0.000100
[2025-08-10 13:14:05,218][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014688] [Batch 03612/03692] [00:32:43/00:00:43, 0.543s/it]: train_loss_raw=1.6826, running_loss=1.7899, LR=0.000100
[2025-08-10 13:14:11,806][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014700] [Batch 03624/03692] [00:32:49/00:00:36, 0.544s/it]: train_loss_raw=1.8925, running_loss=1.7893, LR=0.000100
[2025-08-10 13:14:18,574][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014712] [Batch 03636/03692] [00:32:56/00:00:30, 0.544s/it]: train_loss_raw=1.8460, running_loss=1.7902, LR=0.000100
[2025-08-10 13:14:25,160][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014724] [Batch 03648/03692] [00:33:03/00:00:23, 0.544s/it]: train_loss_raw=1.6812, running_loss=1.7873, LR=0.000100
[2025-08-10 13:14:31,572][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014736] [Batch 03660/03692] [00:33:09/00:00:17, 0.544s/it]: train_loss_raw=1.7894, running_loss=1.7873, LR=0.000100
[2025-08-10 13:14:37,900][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014748] [Batch 03672/03692] [00:33:15/00:00:10, 0.544s/it]: train_loss_raw=1.8274, running_loss=1.7884, LR=0.000100
[2025-08-10 13:14:44,218][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014760] [Batch 03684/03692] [00:33:22/00:00:04, 0.543s/it]: train_loss_raw=1.8082, running_loss=1.7865, LR=0.000100
[2025-08-10 13:15:25,438][__main__][INFO] - [VALIDATION] [Epoch 03/29] Starting validation.
[2025-08-10 13:16:00,837][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 014769] [Batch 00011/00025] [00:00:35/00:00:38, 2.950s/it]
[2025-08-10 13:16:18,548][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 014769] [Batch 00023/00025] [00:00:53/00:00:02, 2.213s/it]
[2025-08-10 13:16:19,660][__main__][INFO] - [VALIDATION] [Epoch 03/29] train_loss=1.78225, valid_loss=1.71767
[2025-08-10 13:16:19,661][__main__][INFO] - [VALIDATION] [Epoch 03/29] Metrics:
[2025-08-10 13:16:19,662][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_er      0.704
[2025-08-10 13:16:19,662][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_prec    0.054
[2025-08-10 13:16:19,662][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_recall  0.056
[2025-08-10 13:16:19,662][__main__][INFO] - [VALIDATION] [Epoch 03/29] - pep_recall 0.010
[2025-08-10 13:16:19,667][__main__][INFO] - [TRAIN] [Epoch 03/29] Epoch complete, total time 02:20:18, remaining time 15:12:02, 00:35:04 per epoch
[2025-08-10 13:16:21,729][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014772] [Batch 00004/03692] [00:00:01/00:27:08, 0.442s/it]: train_loss_raw=1.8553, running_loss=1.7941, LR=0.000100
[2025-08-10 13:16:28,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014784] [Batch 00016/03692] [00:00:08/00:32:13, 0.526s/it]: train_loss_raw=1.8311, running_loss=1.7921, LR=0.000100
[2025-08-10 13:16:34,747][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014796] [Batch 00028/03692] [00:00:14/00:32:14, 0.528s/it]: train_loss_raw=1.6816, running_loss=1.7887, LR=0.000100
[2025-08-10 13:16:41,200][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014808] [Batch 00040/03692] [00:00:21/00:32:18, 0.531s/it]: train_loss_raw=1.7630, running_loss=1.7864, LR=0.000100
[2025-08-10 13:16:47,694][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014820] [Batch 00052/03692] [00:00:27/00:32:21, 0.533s/it]: train_loss_raw=1.6884, running_loss=1.7863, LR=0.000100
[2025-08-10 13:16:54,048][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014832] [Batch 00064/03692] [00:00:34/00:32:12, 0.533s/it]: train_loss_raw=1.6104, running_loss=1.7834, LR=0.000100
[2025-08-10 13:17:00,105][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014844] [Batch 00076/03692] [00:00:40/00:31:49, 0.528s/it]: train_loss_raw=1.6499, running_loss=1.7797, LR=0.000100
[2025-08-10 13:17:06,522][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014856] [Batch 00088/03692] [00:00:46/00:31:46, 0.529s/it]: train_loss_raw=1.8656, running_loss=1.7790, LR=0.000100
[2025-08-10 13:17:13,085][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014868] [Batch 00100/03692] [00:00:53/00:31:48, 0.531s/it]: train_loss_raw=1.7757, running_loss=1.7770, LR=0.000100
[2025-08-10 13:17:19,666][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014880] [Batch 00112/03692] [00:00:59/00:31:48, 0.533s/it]: train_loss_raw=1.7274, running_loss=1.7776, LR=0.000100
[2025-08-10 13:17:26,190][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014892] [Batch 00124/03692] [00:01:06/00:31:45, 0.534s/it]: train_loss_raw=1.8792, running_loss=1.7810, LR=0.000100
[2025-08-10 13:17:32,439][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014904] [Batch 00136/03692] [00:01:12/00:31:35, 0.533s/it]: train_loss_raw=1.6864, running_loss=1.7773, LR=0.000100
[2025-08-10 13:17:38,741][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014916] [Batch 00148/03692] [00:01:18/00:31:26, 0.532s/it]: train_loss_raw=1.7726, running_loss=1.7759, LR=0.000100
[2025-08-10 13:17:45,295][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014928] [Batch 00160/03692] [00:01:25/00:31:23, 0.533s/it]: train_loss_raw=1.7715, running_loss=1.7721, LR=0.000100
[2025-08-10 13:17:51,840][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014940] [Batch 00172/03692] [00:01:31/00:31:20, 0.534s/it]: train_loss_raw=1.7841, running_loss=1.7689, LR=0.000100
[2025-08-10 13:17:58,391][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014952] [Batch 00184/03692] [00:01:38/00:31:16, 0.535s/it]: train_loss_raw=1.6413, running_loss=1.7698, LR=0.000100
[2025-08-10 13:18:04,905][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014964] [Batch 00196/03692] [00:01:44/00:31:11, 0.535s/it]: train_loss_raw=1.6938, running_loss=1.7726, LR=0.000100
[2025-08-10 13:18:11,222][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014976] [Batch 00208/03692] [00:01:51/00:31:03, 0.535s/it]: train_loss_raw=1.8688, running_loss=1.7757, LR=0.000100
[2025-08-10 13:18:17,533][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014988] [Batch 00220/03692] [00:01:57/00:30:55, 0.534s/it]: train_loss_raw=1.7615, running_loss=1.7729, LR=0.000100
[2025-08-10 13:18:23,687][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015000] [Batch 00232/03692] [00:02:03/00:30:45, 0.533s/it]: train_loss_raw=1.7909, running_loss=1.7732, LR=0.000100
[2025-08-10 13:18:29,832][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015012] [Batch 00244/03692] [00:02:09/00:30:35, 0.532s/it]: train_loss_raw=1.7690, running_loss=1.7729, LR=0.000100
[2025-08-10 13:18:36,166][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015024] [Batch 00256/03692] [00:02:16/00:30:28, 0.532s/it]: train_loss_raw=1.9099, running_loss=1.7718, LR=0.000100
[2025-08-10 13:18:42,597][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015036] [Batch 00268/03692] [00:02:22/00:30:22, 0.532s/it]: train_loss_raw=1.8020, running_loss=1.7688, LR=0.000100
[2025-08-10 13:18:49,140][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015048] [Batch 00280/03692] [00:02:29/00:30:17, 0.533s/it]: train_loss_raw=1.7260, running_loss=1.7687, LR=0.000100
[2025-08-10 13:18:55,620][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015060] [Batch 00292/03692] [00:02:35/00:30:12, 0.533s/it]: train_loss_raw=1.7647, running_loss=1.7660, LR=0.000100
[2025-08-10 13:19:02,149][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015072] [Batch 00304/03692] [00:02:42/00:30:07, 0.534s/it]: train_loss_raw=1.6986, running_loss=1.7671, LR=0.000100
[2025-08-10 13:19:08,659][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015084] [Batch 00316/03692] [00:02:48/00:30:02, 0.534s/it]: train_loss_raw=1.7779, running_loss=1.7646, LR=0.000100
[2025-08-10 13:19:15,183][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015096] [Batch 00328/03692] [00:02:55/00:29:57, 0.534s/it]: train_loss_raw=1.7310, running_loss=1.7622, LR=0.000100
[2025-08-10 13:19:21,838][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015108] [Batch 00340/03692] [00:03:01/00:29:53, 0.535s/it]: train_loss_raw=1.7291, running_loss=1.7641, LR=0.000100
[2025-08-10 13:19:28,465][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015120] [Batch 00352/03692] [00:03:08/00:29:48, 0.536s/it]: train_loss_raw=1.7079, running_loss=1.7600, LR=0.000100
[2025-08-10 13:19:35,070][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015132] [Batch 00364/03692] [00:03:15/00:29:43, 0.536s/it]: train_loss_raw=1.8086, running_loss=1.7588, LR=0.000100
[2025-08-10 13:19:41,638][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015144] [Batch 00376/03692] [00:03:21/00:29:38, 0.536s/it]: train_loss_raw=1.6930, running_loss=1.7628, LR=0.000100
[2025-08-10 13:19:48,240][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015156] [Batch 00388/03692] [00:03:28/00:29:33, 0.537s/it]: train_loss_raw=1.7960, running_loss=1.7605, LR=0.000100
[2025-08-10 13:19:54,792][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015168] [Batch 00400/03692] [00:03:34/00:29:28, 0.537s/it]: train_loss_raw=1.7108, running_loss=1.7602, LR=0.000100
[2025-08-10 13:20:01,359][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015180] [Batch 00412/03692] [00:03:41/00:29:22, 0.537s/it]: train_loss_raw=1.6066, running_loss=1.7601, LR=0.000100
[2025-08-10 13:20:07,954][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015192] [Batch 00424/03692] [00:03:47/00:29:17, 0.538s/it]: train_loss_raw=1.8409, running_loss=1.7594, LR=0.000100
[2025-08-10 13:20:14,549][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015204] [Batch 00436/03692] [00:03:54/00:29:11, 0.538s/it]: train_loss_raw=1.7702, running_loss=1.7557, LR=0.000100
[2025-08-10 13:20:21,151][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015216] [Batch 00448/03692] [00:04:01/00:29:06, 0.538s/it]: train_loss_raw=1.8012, running_loss=1.7549, LR=0.000100
[2025-08-10 13:20:27,741][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015228] [Batch 00460/03692] [00:04:07/00:29:00, 0.539s/it]: train_loss_raw=1.7628, running_loss=1.7552, LR=0.000100
[2025-08-10 13:20:34,091][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015240] [Batch 00472/03692] [00:04:14/00:28:53, 0.538s/it]: train_loss_raw=1.7999, running_loss=1.7557, LR=0.000100
[2025-08-10 13:20:40,621][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015252] [Batch 00484/03692] [00:04:20/00:28:47, 0.539s/it]: train_loss_raw=1.8418, running_loss=1.7581, LR=0.000100
[2025-08-10 13:20:46,867][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015264] [Batch 00496/03692] [00:04:26/00:28:39, 0.538s/it]: train_loss_raw=1.6822, running_loss=1.7589, LR=0.000100
[2025-08-10 13:20:53,166][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015276] [Batch 00508/03692] [00:04:33/00:28:32, 0.538s/it]: train_loss_raw=1.7147, running_loss=1.7585, LR=0.000100
[2025-08-10 13:20:59,406][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015288] [Batch 00520/03692] [00:04:39/00:28:24, 0.537s/it]: train_loss_raw=1.7276, running_loss=1.7569, LR=0.000100
[2025-08-10 13:21:05,811][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015300] [Batch 00532/03692] [00:04:45/00:28:17, 0.537s/it]: train_loss_raw=1.8213, running_loss=1.7568, LR=0.000100
[2025-08-10 13:21:12,305][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015312] [Batch 00544/03692] [00:04:52/00:28:11, 0.537s/it]: train_loss_raw=1.7617, running_loss=1.7564, LR=0.000100
[2025-08-10 13:21:18,879][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015324] [Batch 00556/03692] [00:04:58/00:28:05, 0.538s/it]: train_loss_raw=1.8760, running_loss=1.7619, LR=0.000100
[2025-08-10 13:21:25,327][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015336] [Batch 00568/03692] [00:05:05/00:27:59, 0.538s/it]: train_loss_raw=1.8131, running_loss=1.7631, LR=0.000100
[2025-08-10 13:21:31,593][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015348] [Batch 00580/03692] [00:05:11/00:27:52, 0.537s/it]: train_loss_raw=1.8247, running_loss=1.7639, LR=0.000100
[2025-08-10 13:21:37,822][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015360] [Batch 00592/03692] [00:05:17/00:27:44, 0.537s/it]: train_loss_raw=1.6861, running_loss=1.7607, LR=0.000100
[2025-08-10 13:21:43,921][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015372] [Batch 00604/03692] [00:05:23/00:27:36, 0.536s/it]: train_loss_raw=1.8076, running_loss=1.7608, LR=0.000100
[2025-08-10 13:21:50,413][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015384] [Batch 00616/03692] [00:05:30/00:27:30, 0.536s/it]: train_loss_raw=1.8187, running_loss=1.7627, LR=0.000100
[2025-08-10 13:21:57,017][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015396] [Batch 00628/03692] [00:05:37/00:27:24, 0.537s/it]: train_loss_raw=1.8091, running_loss=1.7632, LR=0.000100
[2025-08-10 13:22:03,628][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015408] [Batch 00640/03692] [00:05:43/00:27:18, 0.537s/it]: train_loss_raw=1.6686, running_loss=1.7642, LR=0.000100
[2025-08-10 13:22:10,215][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015420] [Batch 00652/03692] [00:05:50/00:27:13, 0.537s/it]: train_loss_raw=1.6108, running_loss=1.7602, LR=0.000100
[2025-08-10 13:22:16,762][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015432] [Batch 00664/03692] [00:05:56/00:27:07, 0.537s/it]: train_loss_raw=1.9390, running_loss=1.7625, LR=0.000100
[2025-08-10 13:22:23,238][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015444] [Batch 00676/03692] [00:06:03/00:27:00, 0.537s/it]: train_loss_raw=1.7392, running_loss=1.7588, LR=0.000100
[2025-08-10 13:22:29,504][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015456] [Batch 00688/03692] [00:06:09/00:26:53, 0.537s/it]: train_loss_raw=1.6572, running_loss=1.7604, LR=0.000100
[2025-08-10 13:22:35,732][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015468] [Batch 00700/03692] [00:06:15/00:26:46, 0.537s/it]: train_loss_raw=1.8480, running_loss=1.7620, LR=0.000100
[2025-08-10 13:22:42,018][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015480] [Batch 00712/03692] [00:06:22/00:26:39, 0.537s/it]: train_loss_raw=1.8054, running_loss=1.7601, LR=0.000100
[2025-08-10 13:22:48,507][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015492] [Batch 00724/03692] [00:06:28/00:26:32, 0.537s/it]: train_loss_raw=1.7157, running_loss=1.7574, LR=0.000100
[2025-08-10 13:22:54,891][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015504] [Batch 00736/03692] [00:06:34/00:26:26, 0.537s/it]: train_loss_raw=1.7306, running_loss=1.7540, LR=0.000100
[2025-08-10 13:23:01,361][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015516] [Batch 00748/03692] [00:06:41/00:26:19, 0.537s/it]: train_loss_raw=1.8093, running_loss=1.7570, LR=0.000100
[2025-08-10 13:23:07,707][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015528] [Batch 00760/03692] [00:06:47/00:26:13, 0.537s/it]: train_loss_raw=1.8251, running_loss=1.7565, LR=0.000100
[2025-08-10 13:23:14,156][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015540] [Batch 00772/03692] [00:06:54/00:26:06, 0.537s/it]: train_loss_raw=1.7643, running_loss=1.7541, LR=0.000100
[2025-08-10 13:23:20,681][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015552] [Batch 00784/03692] [00:07:00/00:26:00, 0.537s/it]: train_loss_raw=1.8360, running_loss=1.7545, LR=0.000100
[2025-08-10 13:23:27,183][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015564] [Batch 00796/03692] [00:07:07/00:25:54, 0.537s/it]: train_loss_raw=1.7383, running_loss=1.7542, LR=0.000100
[2025-08-10 13:23:33,438][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015576] [Batch 00808/03692] [00:07:13/00:25:47, 0.536s/it]: train_loss_raw=1.6998, running_loss=1.7524, LR=0.000100
[2025-08-10 13:23:39,894][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015588] [Batch 00820/03692] [00:07:19/00:25:40, 0.537s/it]: train_loss_raw=1.7728, running_loss=1.7529, LR=0.000100
[2025-08-10 13:23:46,503][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015600] [Batch 00832/03692] [00:07:26/00:25:34, 0.537s/it]: train_loss_raw=1.8308, running_loss=1.7520, LR=0.000100
[2025-08-10 13:23:53,181][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015612] [Batch 00844/03692] [00:07:33/00:25:29, 0.537s/it]: train_loss_raw=1.7602, running_loss=1.7524, LR=0.000100
[2025-08-10 13:23:59,767][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015624] [Batch 00856/03692] [00:07:39/00:25:23, 0.537s/it]: train_loss_raw=1.8088, running_loss=1.7516, LR=0.000100
[2025-08-10 13:24:06,345][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015636] [Batch 00868/03692] [00:07:46/00:25:17, 0.537s/it]: train_loss_raw=1.7624, running_loss=1.7514, LR=0.000100
[2025-08-10 13:24:12,985][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015648] [Batch 00880/03692] [00:07:53/00:25:11, 0.538s/it]: train_loss_raw=1.7905, running_loss=1.7494, LR=0.000100
[2025-08-10 13:24:19,510][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015660] [Batch 00892/03692] [00:07:59/00:25:05, 0.538s/it]: train_loss_raw=1.7293, running_loss=1.7533, LR=0.000100
[2025-08-10 13:24:26,057][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015672] [Batch 00904/03692] [00:08:06/00:24:59, 0.538s/it]: train_loss_raw=1.6936, running_loss=1.7549, LR=0.000100
[2025-08-10 13:24:32,356][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015684] [Batch 00916/03692] [00:08:12/00:24:52, 0.538s/it]: train_loss_raw=1.8790, running_loss=1.7548, LR=0.000100
[2025-08-10 13:24:38,623][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015696] [Batch 00928/03692] [00:08:18/00:24:45, 0.537s/it]: train_loss_raw=1.7184, running_loss=1.7513, LR=0.000100
[2025-08-10 13:24:44,857][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015708] [Batch 00940/03692] [00:08:24/00:24:38, 0.537s/it]: train_loss_raw=1.7907, running_loss=1.7492, LR=0.000100
[2025-08-10 13:24:51,097][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015720] [Batch 00952/03692] [00:08:31/00:24:31, 0.537s/it]: train_loss_raw=1.7613, running_loss=1.7495, LR=0.000100
[2025-08-10 13:24:57,305][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015732] [Batch 00964/03692] [00:08:37/00:24:24, 0.537s/it]: train_loss_raw=1.7131, running_loss=1.7462, LR=0.000100
[2025-08-10 13:25:03,568][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015744] [Batch 00976/03692] [00:08:43/00:24:17, 0.536s/it]: train_loss_raw=1.7992, running_loss=1.7475, LR=0.000100
[2025-08-10 13:25:09,631][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015756] [Batch 00988/03692] [00:08:49/00:24:09, 0.536s/it]: train_loss_raw=1.7640, running_loss=1.7447, LR=0.000100
[2025-08-10 13:25:15,805][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015768] [Batch 01000/03692] [00:08:55/00:24:02, 0.536s/it]: train_loss_raw=1.6987, running_loss=1.7408, LR=0.000100
[2025-08-10 13:25:22,035][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015780] [Batch 01012/03692] [00:09:02/00:23:55, 0.536s/it]: train_loss_raw=1.7777, running_loss=1.7450, LR=0.000100
[2025-08-10 13:25:28,571][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015792] [Batch 01024/03692] [00:09:08/00:23:49, 0.536s/it]: train_loss_raw=1.6208, running_loss=1.7432, LR=0.000100
[2025-08-10 13:25:35,116][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015804] [Batch 01036/03692] [00:09:15/00:23:43, 0.536s/it]: train_loss_raw=1.7727, running_loss=1.7465, LR=0.000100
[2025-08-10 13:25:41,508][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015816] [Batch 01048/03692] [00:09:21/00:23:36, 0.536s/it]: train_loss_raw=1.6965, running_loss=1.7459, LR=0.000100
[2025-08-10 13:25:48,073][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015828] [Batch 01060/03692] [00:09:28/00:23:30, 0.536s/it]: train_loss_raw=1.7354, running_loss=1.7459, LR=0.000100
[2025-08-10 13:25:54,562][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015840] [Batch 01072/03692] [00:09:34/00:23:24, 0.536s/it]: train_loss_raw=1.7375, running_loss=1.7465, LR=0.000100
[2025-08-10 13:26:01,035][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015852] [Batch 01084/03692] [00:09:41/00:23:18, 0.536s/it]: train_loss_raw=1.7230, running_loss=1.7454, LR=0.000100
[2025-08-10 13:26:07,394][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015864] [Batch 01096/03692] [00:09:47/00:23:11, 0.536s/it]: train_loss_raw=1.6846, running_loss=1.7455, LR=0.000100
[2025-08-10 13:26:13,949][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015876] [Batch 01108/03692] [00:09:53/00:23:05, 0.536s/it]: train_loss_raw=1.6451, running_loss=1.7418, LR=0.000100
[2025-08-10 13:26:20,593][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015888] [Batch 01120/03692] [00:10:00/00:22:59, 0.536s/it]: train_loss_raw=1.7579, running_loss=1.7410, LR=0.000100
[2025-08-10 13:26:27,181][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015900] [Batch 01132/03692] [00:10:07/00:22:53, 0.536s/it]: train_loss_raw=1.7787, running_loss=1.7416, LR=0.000100
[2025-08-10 13:26:33,794][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015912] [Batch 01144/03692] [00:10:13/00:22:47, 0.537s/it]: train_loss_raw=1.7713, running_loss=1.7407, LR=0.000100
[2025-08-10 13:26:40,364][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015924] [Batch 01156/03692] [00:10:20/00:22:41, 0.537s/it]: train_loss_raw=1.7316, running_loss=1.7397, LR=0.000100
[2025-08-10 13:26:46,983][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015936] [Batch 01168/03692] [00:10:27/00:22:34, 0.537s/it]: train_loss_raw=1.7748, running_loss=1.7366, LR=0.000100
[2025-08-10 13:26:53,547][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015948] [Batch 01180/03692] [00:10:33/00:22:28, 0.537s/it]: train_loss_raw=1.6999, running_loss=1.7370, LR=0.000100
[2025-08-10 13:27:00,169][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015960] [Batch 01192/03692] [00:10:40/00:22:22, 0.537s/it]: train_loss_raw=1.7383, running_loss=1.7355, LR=0.000100
[2025-08-10 13:27:06,748][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015972] [Batch 01204/03692] [00:10:46/00:22:16, 0.537s/it]: train_loss_raw=1.6712, running_loss=1.7351, LR=0.000100
[2025-08-10 13:27:13,367][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015984] [Batch 01216/03692] [00:10:53/00:22:10, 0.537s/it]: train_loss_raw=1.5651, running_loss=1.7344, LR=0.000100
[2025-08-10 13:27:19,705][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015996] [Batch 01228/03692] [00:10:59/00:22:03, 0.537s/it]: train_loss_raw=1.7092, running_loss=1.7359, LR=0.000100
[2025-08-10 13:27:31,353][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016008] [Batch 01240/03692] [00:11:11/00:22:07, 0.541s/it]: train_loss_raw=1.6768, running_loss=1.7324, LR=0.000100
[2025-08-10 13:27:37,579][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016020] [Batch 01252/03692] [00:11:17/00:22:00, 0.541s/it]: train_loss_raw=1.8955, running_loss=1.7350, LR=0.000100
[2025-08-10 13:27:43,914][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016032] [Batch 01264/03692] [00:11:23/00:21:53, 0.541s/it]: train_loss_raw=1.6885, running_loss=1.7329, LR=0.000100
[2025-08-10 13:27:50,092][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016044] [Batch 01276/03692] [00:11:30/00:21:46, 0.541s/it]: train_loss_raw=1.7825, running_loss=1.7332, LR=0.000100
[2025-08-10 13:27:56,321][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016056] [Batch 01288/03692] [00:11:36/00:21:39, 0.541s/it]: train_loss_raw=1.8241, running_loss=1.7329, LR=0.000100
[2025-08-10 13:28:02,586][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016068] [Batch 01300/03692] [00:11:42/00:21:32, 0.540s/it]: train_loss_raw=1.6742, running_loss=1.7321, LR=0.000100
[2025-08-10 13:28:09,167][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016080] [Batch 01312/03692] [00:11:49/00:21:26, 0.541s/it]: train_loss_raw=1.7841, running_loss=1.7308, LR=0.000100
[2025-08-10 13:28:15,457][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016092] [Batch 01324/03692] [00:11:55/00:21:19, 0.540s/it]: train_loss_raw=1.7348, running_loss=1.7347, LR=0.000100
[2025-08-10 13:28:21,838][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016104] [Batch 01336/03692] [00:12:01/00:21:13, 0.540s/it]: train_loss_raw=1.8093, running_loss=1.7352, LR=0.000100
[2025-08-10 13:28:28,404][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016116] [Batch 01348/03692] [00:12:08/00:21:06, 0.540s/it]: train_loss_raw=1.7366, running_loss=1.7347, LR=0.000100
[2025-08-10 13:28:35,021][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016128] [Batch 01360/03692] [00:12:15/00:21:00, 0.540s/it]: train_loss_raw=1.7512, running_loss=1.7359, LR=0.000100
[2025-08-10 13:28:41,208][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016140] [Batch 01372/03692] [00:12:21/00:20:53, 0.540s/it]: train_loss_raw=1.8701, running_loss=1.7353, LR=0.000100
[2025-08-10 13:28:47,457][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016152] [Batch 01384/03692] [00:12:27/00:20:46, 0.540s/it]: train_loss_raw=1.5994, running_loss=1.7317, LR=0.000100
[2025-08-10 13:28:53,674][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016164] [Batch 01396/03692] [00:12:33/00:20:39, 0.540s/it]: train_loss_raw=1.7065, running_loss=1.7268, LR=0.000100
[2025-08-10 13:28:59,972][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016176] [Batch 01408/03692] [00:12:40/00:20:32, 0.540s/it]: train_loss_raw=1.7257, running_loss=1.7277, LR=0.000100
[2025-08-10 13:29:06,638][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016188] [Batch 01420/03692] [00:12:46/00:20:26, 0.540s/it]: train_loss_raw=1.7128, running_loss=1.7294, LR=0.000100
[2025-08-10 13:29:13,255][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016200] [Batch 01432/03692] [00:12:53/00:20:20, 0.540s/it]: train_loss_raw=1.7968, running_loss=1.7297, LR=0.000100
[2025-08-10 13:29:19,708][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016212] [Batch 01444/03692] [00:12:59/00:20:13, 0.540s/it]: train_loss_raw=1.6662, running_loss=1.7301, LR=0.000100
[2025-08-10 13:29:25,752][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016224] [Batch 01456/03692] [00:13:05/00:20:06, 0.540s/it]: train_loss_raw=1.6600, running_loss=1.7291, LR=0.000100
[2025-08-10 13:29:31,936][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016236] [Batch 01468/03692] [00:13:11/00:19:59, 0.539s/it]: train_loss_raw=1.7378, running_loss=1.7312, LR=0.000100
[2025-08-10 13:29:38,430][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016248] [Batch 01480/03692] [00:13:18/00:19:53, 0.540s/it]: train_loss_raw=1.6312, running_loss=1.7252, LR=0.000100
[2025-08-10 13:29:45,019][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016260] [Batch 01492/03692] [00:13:25/00:19:47, 0.540s/it]: train_loss_raw=1.7366, running_loss=1.7230, LR=0.000100
[2025-08-10 13:29:51,488][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016272] [Batch 01504/03692] [00:13:31/00:19:40, 0.540s/it]: train_loss_raw=1.7517, running_loss=1.7247, LR=0.000100
[2025-08-10 13:29:58,061][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016284] [Batch 01516/03692] [00:13:38/00:19:34, 0.540s/it]: train_loss_raw=1.7615, running_loss=1.7226, LR=0.000100
[2025-08-10 13:30:04,582][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016296] [Batch 01528/03692] [00:13:44/00:19:27, 0.540s/it]: train_loss_raw=1.7181, running_loss=1.7217, LR=0.000100
[2025-08-10 13:30:11,102][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016308] [Batch 01540/03692] [00:13:51/00:19:21, 0.540s/it]: train_loss_raw=1.5594, running_loss=1.7191, LR=0.000100
[2025-08-10 13:30:17,552][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016320] [Batch 01552/03692] [00:13:57/00:19:14, 0.540s/it]: train_loss_raw=1.7039, running_loss=1.7179, LR=0.000100
[2025-08-10 13:30:24,145][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016332] [Batch 01564/03692] [00:14:04/00:19:08, 0.540s/it]: train_loss_raw=1.6586, running_loss=1.7213, LR=0.000100
[2025-08-10 13:30:30,718][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016344] [Batch 01576/03692] [00:14:10/00:19:02, 0.540s/it]: train_loss_raw=1.7331, running_loss=1.7242, LR=0.000100
[2025-08-10 13:30:37,281][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016356] [Batch 01588/03692] [00:14:17/00:18:55, 0.540s/it]: train_loss_raw=1.5959, running_loss=1.7250, LR=0.000100
[2025-08-10 13:30:43,929][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016368] [Batch 01600/03692] [00:14:23/00:18:49, 0.540s/it]: train_loss_raw=1.8242, running_loss=1.7253, LR=0.000100
[2025-08-10 13:30:50,550][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016380] [Batch 01612/03692] [00:14:30/00:18:43, 0.540s/it]: train_loss_raw=1.8513, running_loss=1.7273, LR=0.000100
[2025-08-10 13:30:56,726][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016392] [Batch 01624/03692] [00:14:36/00:18:36, 0.540s/it]: train_loss_raw=1.7108, running_loss=1.7241, LR=0.000100
[2025-08-10 13:31:02,909][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016404] [Batch 01636/03692] [00:14:42/00:18:29, 0.540s/it]: train_loss_raw=1.7149, running_loss=1.7214, LR=0.000100
[2025-08-10 13:31:09,318][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016416] [Batch 01648/03692] [00:14:49/00:18:23, 0.540s/it]: train_loss_raw=1.6957, running_loss=1.7231, LR=0.000100
[2025-08-10 13:31:15,721][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016428] [Batch 01660/03692] [00:14:55/00:18:16, 0.540s/it]: train_loss_raw=1.7615, running_loss=1.7261, LR=0.000100
[2025-08-10 13:31:21,781][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016440] [Batch 01672/03692] [00:15:01/00:18:09, 0.539s/it]: train_loss_raw=1.6796, running_loss=1.7265, LR=0.000100
[2025-08-10 13:31:28,051][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016452] [Batch 01684/03692] [00:15:08/00:18:02, 0.539s/it]: train_loss_raw=1.7434, running_loss=1.7249, LR=0.000100
[2025-08-10 13:31:34,301][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016464] [Batch 01696/03692] [00:15:14/00:17:56, 0.539s/it]: train_loss_raw=1.6926, running_loss=1.7248, LR=0.000100
[2025-08-10 13:31:40,631][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016476] [Batch 01708/03692] [00:15:20/00:17:49, 0.539s/it]: train_loss_raw=1.7886, running_loss=1.7257, LR=0.000100
[2025-08-10 13:31:46,845][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016488] [Batch 01720/03692] [00:15:26/00:17:42, 0.539s/it]: train_loss_raw=1.7692, running_loss=1.7243, LR=0.000100
[2025-08-10 13:31:53,410][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016500] [Batch 01732/03692] [00:15:33/00:17:36, 0.539s/it]: train_loss_raw=1.7442, running_loss=1.7214, LR=0.000100
[2025-08-10 13:31:59,911][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016512] [Batch 01744/03692] [00:15:39/00:17:29, 0.539s/it]: train_loss_raw=1.6389, running_loss=1.7227, LR=0.000100
[2025-08-10 13:32:06,252][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016524] [Batch 01756/03692] [00:15:46/00:17:23, 0.539s/it]: train_loss_raw=1.6695, running_loss=1.7220, LR=0.000100
[2025-08-10 13:32:12,723][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016536] [Batch 01768/03692] [00:15:52/00:17:16, 0.539s/it]: train_loss_raw=1.6993, running_loss=1.7228, LR=0.000100
[2025-08-10 13:32:18,858][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016548] [Batch 01780/03692] [00:15:58/00:17:10, 0.539s/it]: train_loss_raw=1.6699, running_loss=1.7218, LR=0.000100
[2025-08-10 13:32:25,225][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016560] [Batch 01792/03692] [00:16:05/00:17:03, 0.539s/it]: train_loss_raw=1.6294, running_loss=1.7180, LR=0.000100
[2025-08-10 13:32:31,364][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016572] [Batch 01804/03692] [00:16:11/00:16:56, 0.538s/it]: train_loss_raw=1.7970, running_loss=1.7187, LR=0.000100
[2025-08-10 13:32:37,392][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016584] [Batch 01816/03692] [00:16:17/00:16:49, 0.538s/it]: train_loss_raw=1.6661, running_loss=1.7179, LR=0.000100
[2025-08-10 13:32:43,549][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016596] [Batch 01828/03692] [00:16:23/00:16:42, 0.538s/it]: train_loss_raw=1.7560, running_loss=1.7152, LR=0.000100
[2025-08-10 13:32:49,621][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016608] [Batch 01840/03692] [00:16:29/00:16:36, 0.538s/it]: train_loss_raw=1.7471, running_loss=1.7142, LR=0.000100
[2025-08-10 13:32:56,131][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016620] [Batch 01852/03692] [00:16:36/00:16:29, 0.538s/it]: train_loss_raw=1.7016, running_loss=1.7134, LR=0.000100
[2025-08-10 13:33:02,605][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016632] [Batch 01864/03692] [00:16:42/00:16:23, 0.538s/it]: train_loss_raw=1.6586, running_loss=1.7138, LR=0.000100
[2025-08-10 13:33:09,213][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016644] [Batch 01876/03692] [00:16:49/00:16:16, 0.538s/it]: train_loss_raw=1.6705, running_loss=1.7092, LR=0.000100
[2025-08-10 13:33:15,695][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016656] [Batch 01888/03692] [00:16:55/00:16:10, 0.538s/it]: train_loss_raw=1.7372, running_loss=1.7087, LR=0.000100
[2025-08-10 13:33:22,091][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016668] [Batch 01900/03692] [00:17:02/00:16:04, 0.538s/it]: train_loss_raw=1.7503, running_loss=1.7073, LR=0.000100
[2025-08-10 13:33:28,645][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016680] [Batch 01912/03692] [00:17:08/00:15:57, 0.538s/it]: train_loss_raw=1.6424, running_loss=1.7111, LR=0.000100
[2025-08-10 13:33:35,195][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016692] [Batch 01924/03692] [00:17:15/00:15:51, 0.538s/it]: train_loss_raw=1.5908, running_loss=1.7103, LR=0.000100
[2025-08-10 13:33:41,790][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016704] [Batch 01936/03692] [00:17:21/00:15:44, 0.538s/it]: train_loss_raw=1.7217, running_loss=1.7131, LR=0.000100
[2025-08-10 13:33:48,351][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016716] [Batch 01948/03692] [00:17:28/00:15:38, 0.538s/it]: train_loss_raw=1.7024, running_loss=1.7134, LR=0.000100
[2025-08-10 13:33:55,001][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016728] [Batch 01960/03692] [00:17:35/00:15:32, 0.538s/it]: train_loss_raw=1.6846, running_loss=1.7138, LR=0.000100
[2025-08-10 13:34:01,612][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016740] [Batch 01972/03692] [00:17:41/00:15:25, 0.538s/it]: train_loss_raw=1.6277, running_loss=1.7165, LR=0.000100
[2025-08-10 13:34:08,161][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016752] [Batch 01984/03692] [00:17:48/00:15:19, 0.538s/it]: train_loss_raw=1.6593, running_loss=1.7206, LR=0.000100
[2025-08-10 13:34:14,830][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016764] [Batch 01996/03692] [00:17:54/00:15:13, 0.539s/it]: train_loss_raw=1.6828, running_loss=1.7161, LR=0.000100
[2025-08-10 13:34:21,437][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016776] [Batch 02008/03692] [00:18:01/00:15:06, 0.539s/it]: train_loss_raw=1.7784, running_loss=1.7166, LR=0.000100
[2025-08-10 13:34:27,922][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016788] [Batch 02020/03692] [00:18:07/00:15:00, 0.539s/it]: train_loss_raw=1.8422, running_loss=1.7157, LR=0.000100
[2025-08-10 13:34:34,432][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016800] [Batch 02032/03692] [00:18:14/00:14:54, 0.539s/it]: train_loss_raw=1.6415, running_loss=1.7142, LR=0.000100
[2025-08-10 13:34:40,958][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016812] [Batch 02044/03692] [00:18:20/00:14:47, 0.539s/it]: train_loss_raw=1.5169, running_loss=1.7123, LR=0.000100
[2025-08-10 13:34:47,468][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016824] [Batch 02056/03692] [00:18:27/00:14:41, 0.539s/it]: train_loss_raw=1.6218, running_loss=1.7066, LR=0.000100
[2025-08-10 13:34:54,066][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016836] [Batch 02068/03692] [00:18:34/00:14:34, 0.539s/it]: train_loss_raw=1.6980, running_loss=1.7062, LR=0.000100
[2025-08-10 13:35:00,610][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016848] [Batch 02080/03692] [00:18:40/00:14:28, 0.539s/it]: train_loss_raw=1.6223, running_loss=1.7037, LR=0.000100
[2025-08-10 13:35:07,197][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016860] [Batch 02092/03692] [00:18:47/00:14:22, 0.539s/it]: train_loss_raw=1.8129, running_loss=1.7028, LR=0.000100
[2025-08-10 13:35:13,766][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016872] [Batch 02104/03692] [00:18:53/00:14:15, 0.539s/it]: train_loss_raw=1.6577, running_loss=1.7043, LR=0.000100
[2025-08-10 13:35:20,213][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016884] [Batch 02116/03692] [00:19:00/00:14:09, 0.539s/it]: train_loss_raw=1.7467, running_loss=1.7037, LR=0.000100
[2025-08-10 13:35:26,824][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016896] [Batch 02128/03692] [00:19:06/00:14:02, 0.539s/it]: train_loss_raw=1.8083, running_loss=1.7038, LR=0.000100
[2025-08-10 13:35:33,386][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016908] [Batch 02140/03692] [00:19:13/00:13:56, 0.539s/it]: train_loss_raw=1.6768, running_loss=1.7048, LR=0.000100
[2025-08-10 13:35:39,946][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016920] [Batch 02152/03692] [00:19:19/00:13:50, 0.539s/it]: train_loss_raw=1.5921, running_loss=1.7010, LR=0.000100
[2025-08-10 13:35:46,495][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016932] [Batch 02164/03692] [00:19:26/00:13:43, 0.539s/it]: train_loss_raw=1.6974, running_loss=1.6966, LR=0.000100
[2025-08-10 13:35:53,089][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016944] [Batch 02176/03692] [00:19:33/00:13:37, 0.539s/it]: train_loss_raw=1.6843, running_loss=1.6992, LR=0.000100
[2025-08-10 13:35:59,698][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016956] [Batch 02188/03692] [00:19:39/00:13:30, 0.539s/it]: train_loss_raw=1.6815, running_loss=1.6978, LR=0.000100
[2025-08-10 13:36:06,223][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016968] [Batch 02200/03692] [00:19:46/00:13:24, 0.539s/it]: train_loss_raw=1.5589, running_loss=1.6957, LR=0.000100
[2025-08-10 13:36:12,747][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016980] [Batch 02212/03692] [00:19:52/00:13:18, 0.539s/it]: train_loss_raw=1.6505, running_loss=1.6959, LR=0.000100
[2025-08-10 13:36:18,943][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016992] [Batch 02224/03692] [00:19:58/00:13:11, 0.539s/it]: train_loss_raw=1.7269, running_loss=1.6996, LR=0.000100
[2025-08-10 13:36:25,300][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017004] [Batch 02236/03692] [00:20:05/00:13:04, 0.539s/it]: train_loss_raw=1.7750, running_loss=1.6994, LR=0.000100
[2025-08-10 13:36:31,903][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017016] [Batch 02248/03692] [00:20:11/00:12:58, 0.539s/it]: train_loss_raw=1.5787, running_loss=1.7015, LR=0.000100
[2025-08-10 13:36:38,493][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017028] [Batch 02260/03692] [00:20:18/00:12:52, 0.539s/it]: train_loss_raw=1.6881, running_loss=1.7014, LR=0.000100
[2025-08-10 13:36:44,865][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017040] [Batch 02272/03692] [00:20:24/00:12:45, 0.539s/it]: train_loss_raw=1.7288, running_loss=1.7012, LR=0.000100
[2025-08-10 13:36:51,017][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017052] [Batch 02284/03692] [00:20:31/00:12:38, 0.539s/it]: train_loss_raw=1.6435, running_loss=1.7009, LR=0.000100
[2025-08-10 13:36:57,531][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017064] [Batch 02296/03692] [00:20:37/00:12:32, 0.539s/it]: train_loss_raw=1.6423, running_loss=1.7013, LR=0.000100
[2025-08-10 13:37:04,118][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017076] [Batch 02308/03692] [00:20:44/00:12:26, 0.539s/it]: train_loss_raw=1.7786, running_loss=1.7001, LR=0.000100
[2025-08-10 13:37:10,673][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017088] [Batch 02320/03692] [00:20:50/00:12:19, 0.539s/it]: train_loss_raw=1.7298, running_loss=1.6964, LR=0.000100
[2025-08-10 13:37:16,840][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017100] [Batch 02332/03692] [00:20:56/00:12:12, 0.539s/it]: train_loss_raw=1.7605, running_loss=1.6939, LR=0.000100
[2025-08-10 13:37:23,103][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017112] [Batch 02344/03692] [00:21:03/00:12:06, 0.539s/it]: train_loss_raw=1.6583, running_loss=1.6935, LR=0.000100
[2025-08-10 13:37:29,473][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017124] [Batch 02356/03692] [00:21:09/00:11:59, 0.539s/it]: train_loss_raw=1.7765, running_loss=1.6921, LR=0.000100
[2025-08-10 13:37:35,765][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017136] [Batch 02368/03692] [00:21:15/00:11:53, 0.539s/it]: train_loss_raw=1.6786, running_loss=1.6949, LR=0.000100
[2025-08-10 13:37:42,098][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017148] [Batch 02380/03692] [00:21:22/00:11:46, 0.539s/it]: train_loss_raw=1.7209, running_loss=1.6957, LR=0.000100
[2025-08-10 13:37:48,744][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017160] [Batch 02392/03692] [00:21:28/00:11:40, 0.539s/it]: train_loss_raw=1.5394, running_loss=1.6932, LR=0.000100
[2025-08-10 13:37:55,100][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017172] [Batch 02404/03692] [00:21:35/00:11:33, 0.539s/it]: train_loss_raw=1.7478, running_loss=1.6956, LR=0.000100
[2025-08-10 13:38:01,408][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017184] [Batch 02416/03692] [00:21:41/00:11:27, 0.539s/it]: train_loss_raw=1.6980, running_loss=1.6943, LR=0.000100
[2025-08-10 13:38:07,842][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017196] [Batch 02428/03692] [00:21:47/00:11:20, 0.539s/it]: train_loss_raw=1.5218, running_loss=1.6914, LR=0.000100
[2025-08-10 13:38:14,243][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017208] [Batch 02440/03692] [00:21:54/00:11:14, 0.539s/it]: train_loss_raw=1.7745, running_loss=1.6922, LR=0.000100
[2025-08-10 13:38:20,886][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017220] [Batch 02452/03692] [00:22:00/00:11:08, 0.539s/it]: train_loss_raw=1.6643, running_loss=1.6941, LR=0.000100
[2025-08-10 13:38:27,514][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017232] [Batch 02464/03692] [00:22:07/00:11:01, 0.539s/it]: train_loss_raw=1.6070, running_loss=1.6925, LR=0.000100
[2025-08-10 13:38:34,112][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017244] [Batch 02476/03692] [00:22:14/00:10:55, 0.539s/it]: train_loss_raw=1.7908, running_loss=1.6942, LR=0.000100
[2025-08-10 13:38:40,670][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017256] [Batch 02488/03692] [00:22:20/00:10:48, 0.539s/it]: train_loss_raw=1.6053, running_loss=1.6932, LR=0.000100
[2025-08-10 13:38:47,139][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017268] [Batch 02500/03692] [00:22:27/00:10:42, 0.539s/it]: train_loss_raw=1.6819, running_loss=1.6906, LR=0.000100
[2025-08-10 13:38:53,402][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017280] [Batch 02512/03692] [00:22:33/00:10:35, 0.539s/it]: train_loss_raw=1.7195, running_loss=1.6923, LR=0.000100
[2025-08-10 13:38:59,701][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017292] [Batch 02524/03692] [00:22:39/00:10:29, 0.539s/it]: train_loss_raw=1.5581, running_loss=1.6860, LR=0.000100
[2025-08-10 13:39:05,858][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017304] [Batch 02536/03692] [00:22:45/00:10:22, 0.539s/it]: train_loss_raw=1.6732, running_loss=1.6874, LR=0.000100
[2025-08-10 13:39:12,021][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017316] [Batch 02548/03692] [00:22:52/00:10:16, 0.538s/it]: train_loss_raw=1.5600, running_loss=1.6851, LR=0.000100
[2025-08-10 13:39:18,326][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017328] [Batch 02560/03692] [00:22:58/00:10:09, 0.538s/it]: train_loss_raw=1.7411, running_loss=1.6850, LR=0.000100
[2025-08-10 13:39:24,627][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017340] [Batch 02572/03692] [00:23:04/00:10:02, 0.538s/it]: train_loss_raw=1.6713, running_loss=1.6888, LR=0.000100
[2025-08-10 13:39:30,814][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017352] [Batch 02584/03692] [00:23:10/00:09:56, 0.538s/it]: train_loss_raw=1.7462, running_loss=1.6898, LR=0.000100
[2025-08-10 13:39:37,037][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017364] [Batch 02596/03692] [00:23:17/00:09:49, 0.538s/it]: train_loss_raw=1.6251, running_loss=1.6898, LR=0.000100
[2025-08-10 13:39:43,310][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017376] [Batch 02608/03692] [00:23:23/00:09:43, 0.538s/it]: train_loss_raw=1.6197, running_loss=1.6854, LR=0.000100
[2025-08-10 13:39:49,517][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017388] [Batch 02620/03692] [00:23:29/00:09:36, 0.538s/it]: train_loss_raw=1.6774, running_loss=1.6832, LR=0.000100
[2025-08-10 13:39:55,812][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017400] [Batch 02632/03692] [00:23:35/00:09:30, 0.538s/it]: train_loss_raw=1.7713, running_loss=1.6816, LR=0.000100
[2025-08-10 13:40:02,109][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017412] [Batch 02644/03692] [00:23:42/00:09:23, 0.538s/it]: train_loss_raw=1.7483, running_loss=1.6849, LR=0.000100
[2025-08-10 13:40:08,382][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017424] [Batch 02656/03692] [00:23:48/00:09:17, 0.538s/it]: train_loss_raw=1.5946, running_loss=1.6830, LR=0.000100
[2025-08-10 13:40:14,758][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017436] [Batch 02668/03692] [00:23:54/00:09:10, 0.538s/it]: train_loss_raw=1.6610, running_loss=1.6869, LR=0.000100
[2025-08-10 13:40:21,312][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017448] [Batch 02680/03692] [00:24:01/00:09:04, 0.538s/it]: train_loss_raw=1.6542, running_loss=1.6809, LR=0.000100
[2025-08-10 13:40:27,776][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017460] [Batch 02692/03692] [00:24:07/00:08:57, 0.538s/it]: train_loss_raw=1.6606, running_loss=1.6821, LR=0.000100
[2025-08-10 13:40:34,314][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017472] [Batch 02704/03692] [00:24:14/00:08:51, 0.538s/it]: train_loss_raw=1.4576, running_loss=1.6800, LR=0.000100
[2025-08-10 13:40:40,554][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017484] [Batch 02716/03692] [00:24:20/00:08:44, 0.538s/it]: train_loss_raw=1.7164, running_loss=1.6804, LR=0.000100
[2025-08-10 13:40:46,674][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017496] [Batch 02728/03692] [00:24:26/00:08:38, 0.538s/it]: train_loss_raw=1.5981, running_loss=1.6815, LR=0.000100
[2025-08-10 13:40:53,076][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017508] [Batch 02740/03692] [00:24:33/00:08:31, 0.538s/it]: train_loss_raw=1.7280, running_loss=1.6795, LR=0.000100
[2025-08-10 13:40:59,302][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017520] [Batch 02752/03692] [00:24:39/00:08:25, 0.538s/it]: train_loss_raw=1.6954, running_loss=1.6750, LR=0.000100
[2025-08-10 13:41:05,859][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017532] [Batch 02764/03692] [00:24:45/00:08:18, 0.538s/it]: train_loss_raw=1.7040, running_loss=1.6728, LR=0.000100
[2025-08-10 13:41:12,466][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017544] [Batch 02776/03692] [00:24:52/00:08:12, 0.538s/it]: train_loss_raw=1.6995, running_loss=1.6712, LR=0.000100
[2025-08-10 13:41:19,089][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017556] [Batch 02788/03692] [00:24:59/00:08:06, 0.538s/it]: train_loss_raw=1.6685, running_loss=1.6709, LR=0.000100
[2025-08-10 13:41:25,610][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017568] [Batch 02800/03692] [00:25:05/00:07:59, 0.538s/it]: train_loss_raw=1.6758, running_loss=1.6682, LR=0.000100
[2025-08-10 13:41:32,153][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017580] [Batch 02812/03692] [00:25:12/00:07:53, 0.538s/it]: train_loss_raw=1.6051, running_loss=1.6668, LR=0.000100
[2025-08-10 13:41:38,760][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017592] [Batch 02824/03692] [00:25:18/00:07:46, 0.538s/it]: train_loss_raw=1.5914, running_loss=1.6698, LR=0.000100
[2025-08-10 13:41:45,285][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017604] [Batch 02836/03692] [00:25:25/00:07:40, 0.538s/it]: train_loss_raw=1.6542, running_loss=1.6696, LR=0.000100
[2025-08-10 13:41:51,952][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017616] [Batch 02848/03692] [00:25:31/00:07:34, 0.538s/it]: train_loss_raw=1.7978, running_loss=1.6741, LR=0.000100
[2025-08-10 13:41:58,448][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017628] [Batch 02860/03692] [00:25:38/00:07:27, 0.538s/it]: train_loss_raw=1.7443, running_loss=1.6774, LR=0.000100
[2025-08-10 13:42:04,820][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017640] [Batch 02872/03692] [00:25:44/00:07:21, 0.538s/it]: train_loss_raw=1.5708, running_loss=1.6746, LR=0.000100
[2025-08-10 13:42:11,371][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017652] [Batch 02884/03692] [00:25:51/00:07:14, 0.538s/it]: train_loss_raw=1.6257, running_loss=1.6740, LR=0.000100
[2025-08-10 13:42:18,038][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017664] [Batch 02896/03692] [00:25:58/00:07:08, 0.538s/it]: train_loss_raw=1.8130, running_loss=1.6723, LR=0.000100
[2025-08-10 13:42:24,598][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017676] [Batch 02908/03692] [00:26:04/00:07:01, 0.538s/it]: train_loss_raw=1.5544, running_loss=1.6725, LR=0.000100
[2025-08-10 13:42:30,939][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017688] [Batch 02920/03692] [00:26:10/00:06:55, 0.538s/it]: train_loss_raw=1.7433, running_loss=1.6734, LR=0.000100
[2025-08-10 13:42:37,032][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017700] [Batch 02932/03692] [00:26:17/00:06:48, 0.538s/it]: train_loss_raw=1.7031, running_loss=1.6734, LR=0.000100
[2025-08-10 13:42:43,270][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017712] [Batch 02944/03692] [00:26:23/00:06:42, 0.538s/it]: train_loss_raw=1.6991, running_loss=1.6702, LR=0.000100
[2025-08-10 13:42:49,570][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017724] [Batch 02956/03692] [00:26:29/00:06:35, 0.538s/it]: train_loss_raw=1.5861, running_loss=1.6733, LR=0.000100
[2025-08-10 13:42:55,605][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017736] [Batch 02968/03692] [00:26:35/00:06:29, 0.538s/it]: train_loss_raw=1.6766, running_loss=1.6729, LR=0.000100
[2025-08-10 13:43:01,648][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017748] [Batch 02980/03692] [00:26:41/00:06:22, 0.537s/it]: train_loss_raw=1.6318, running_loss=1.6700, LR=0.000100
[2025-08-10 13:43:07,745][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017760] [Batch 02992/03692] [00:26:47/00:06:16, 0.537s/it]: train_loss_raw=1.6321, running_loss=1.6680, LR=0.000100
[2025-08-10 13:43:13,878][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017772] [Batch 03004/03692] [00:26:53/00:06:09, 0.537s/it]: train_loss_raw=1.8165, running_loss=1.6705, LR=0.000100
[2025-08-10 13:43:19,939][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017784] [Batch 03016/03692] [00:26:59/00:06:03, 0.537s/it]: train_loss_raw=1.5617, running_loss=1.6667, LR=0.000100
[2025-08-10 13:43:26,027][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017796] [Batch 03028/03692] [00:27:06/00:05:56, 0.537s/it]: train_loss_raw=1.7385, running_loss=1.6712, LR=0.000100
[2025-08-10 13:43:32,312][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017808] [Batch 03040/03692] [00:27:12/00:05:50, 0.537s/it]: train_loss_raw=1.6920, running_loss=1.6734, LR=0.000100
[2025-08-10 13:43:38,927][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017820] [Batch 03052/03692] [00:27:18/00:05:43, 0.537s/it]: train_loss_raw=1.6656, running_loss=1.6762, LR=0.000100
[2025-08-10 13:43:45,184][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017832] [Batch 03064/03692] [00:27:25/00:05:37, 0.537s/it]: train_loss_raw=1.7030, running_loss=1.6777, LR=0.000100
[2025-08-10 13:43:51,327][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017844] [Batch 03076/03692] [00:27:31/00:05:30, 0.537s/it]: train_loss_raw=1.6848, running_loss=1.6746, LR=0.000100
[2025-08-10 13:43:57,691][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017856] [Batch 03088/03692] [00:27:37/00:05:24, 0.537s/it]: train_loss_raw=1.4697, running_loss=1.6717, LR=0.000100
[2025-08-10 13:44:04,175][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017868] [Batch 03100/03692] [00:27:44/00:05:17, 0.537s/it]: train_loss_raw=1.5618, running_loss=1.6685, LR=0.000100
[2025-08-10 13:44:10,776][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017880] [Batch 03112/03692] [00:27:50/00:05:11, 0.537s/it]: train_loss_raw=1.7510, running_loss=1.6669, LR=0.000100
[2025-08-10 13:44:17,356][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017892] [Batch 03124/03692] [00:27:57/00:05:04, 0.537s/it]: train_loss_raw=1.5015, running_loss=1.6631, LR=0.000100
[2025-08-10 13:44:23,969][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017904] [Batch 03136/03692] [00:28:04/00:04:58, 0.537s/it]: train_loss_raw=1.7475, running_loss=1.6656, LR=0.000100
[2025-08-10 13:44:30,137][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017916] [Batch 03148/03692] [00:28:10/00:04:52, 0.537s/it]: train_loss_raw=1.6269, running_loss=1.6644, LR=0.000100
[2025-08-10 13:44:36,394][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017928] [Batch 03160/03692] [00:28:16/00:04:45, 0.537s/it]: train_loss_raw=1.5953, running_loss=1.6662, LR=0.000100
[2025-08-10 13:44:42,724][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017940] [Batch 03172/03692] [00:28:22/00:04:39, 0.537s/it]: train_loss_raw=1.6683, running_loss=1.6671, LR=0.000100
[2025-08-10 13:44:48,931][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017952] [Batch 03184/03692] [00:28:28/00:04:32, 0.537s/it]: train_loss_raw=1.6168, running_loss=1.6648, LR=0.000100
[2025-08-10 13:44:55,145][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017964] [Batch 03196/03692] [00:28:35/00:04:26, 0.537s/it]: train_loss_raw=1.5763, running_loss=1.6651, LR=0.000100
[2025-08-10 13:45:01,738][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017976] [Batch 03208/03692] [00:28:41/00:04:19, 0.537s/it]: train_loss_raw=1.5858, running_loss=1.6664, LR=0.000100
[2025-08-10 13:45:08,092][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017988] [Batch 03220/03692] [00:28:48/00:04:13, 0.537s/it]: train_loss_raw=1.6986, running_loss=1.6644, LR=0.000100
[2025-08-10 13:45:14,330][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018000] [Batch 03232/03692] [00:28:54/00:04:06, 0.537s/it]: train_loss_raw=1.6625, running_loss=1.6632, LR=0.000100
[2025-08-10 13:45:25,305][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018012] [Batch 03244/03692] [00:29:05/00:04:01, 0.538s/it]: train_loss_raw=1.5926, running_loss=1.6656, LR=0.000100
[2025-08-10 13:45:31,581][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018024] [Batch 03256/03692] [00:29:11/00:03:54, 0.538s/it]: train_loss_raw=1.6254, running_loss=1.6651, LR=0.000100
[2025-08-10 13:45:37,885][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018036] [Batch 03268/03692] [00:29:17/00:03:48, 0.538s/it]: train_loss_raw=1.5220, running_loss=1.6633, LR=0.000100
[2025-08-10 13:45:44,351][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018048] [Batch 03280/03692] [00:29:24/00:03:41, 0.538s/it]: train_loss_raw=1.7064, running_loss=1.6660, LR=0.000100
[2025-08-10 13:45:50,817][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018060] [Batch 03292/03692] [00:29:30/00:03:35, 0.538s/it]: train_loss_raw=1.6699, running_loss=1.6657, LR=0.000100
[2025-08-10 13:45:57,247][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018072] [Batch 03304/03692] [00:29:37/00:03:28, 0.538s/it]: train_loss_raw=1.6837, running_loss=1.6695, LR=0.000100
[2025-08-10 13:46:03,758][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018084] [Batch 03316/03692] [00:29:43/00:03:22, 0.538s/it]: train_loss_raw=1.5114, running_loss=1.6678, LR=0.000100
[2025-08-10 13:46:10,354][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018096] [Batch 03328/03692] [00:29:50/00:03:15, 0.538s/it]: train_loss_raw=1.6378, running_loss=1.6679, LR=0.000100
[2025-08-10 13:46:16,950][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018108] [Batch 03340/03692] [00:29:56/00:03:09, 0.538s/it]: train_loss_raw=1.6296, running_loss=1.6627, LR=0.000100
[2025-08-10 13:46:23,604][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018120] [Batch 03352/03692] [00:30:03/00:03:02, 0.538s/it]: train_loss_raw=1.6925, running_loss=1.6621, LR=0.000100
[2025-08-10 13:46:30,213][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018132] [Batch 03364/03692] [00:30:10/00:02:56, 0.538s/it]: train_loss_raw=1.5855, running_loss=1.6621, LR=0.000100
[2025-08-10 13:46:36,494][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018144] [Batch 03376/03692] [00:30:16/00:02:50, 0.538s/it]: train_loss_raw=1.6818, running_loss=1.6628, LR=0.000100
[2025-08-10 13:46:42,500][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018156] [Batch 03388/03692] [00:30:22/00:02:43, 0.538s/it]: train_loss_raw=1.8003, running_loss=1.6635, LR=0.000100
[2025-08-10 13:46:48,605][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018168] [Batch 03400/03692] [00:30:28/00:02:37, 0.538s/it]: train_loss_raw=1.7357, running_loss=1.6618, LR=0.000100
[2025-08-10 13:46:54,642][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018180] [Batch 03412/03692] [00:30:34/00:02:30, 0.538s/it]: train_loss_raw=1.7775, running_loss=1.6641, LR=0.000100
[2025-08-10 13:47:00,829][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018192] [Batch 03424/03692] [00:30:40/00:02:24, 0.538s/it]: train_loss_raw=1.7266, running_loss=1.6645, LR=0.000100
[2025-08-10 13:47:07,088][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018204] [Batch 03436/03692] [00:30:47/00:02:17, 0.538s/it]: train_loss_raw=1.8686, running_loss=1.6677, LR=0.000100
[2025-08-10 13:47:13,261][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018216] [Batch 03448/03692] [00:30:53/00:02:11, 0.537s/it]: train_loss_raw=1.5910, running_loss=1.6677, LR=0.000100
[2025-08-10 13:47:19,487][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018228] [Batch 03460/03692] [00:30:59/00:02:04, 0.537s/it]: train_loss_raw=1.6942, running_loss=1.6672, LR=0.000100
[2025-08-10 13:47:25,556][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018240] [Batch 03472/03692] [00:31:05/00:01:58, 0.537s/it]: train_loss_raw=1.6352, running_loss=1.6674, LR=0.000100
[2025-08-10 13:47:31,638][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018252] [Batch 03484/03692] [00:31:11/00:01:51, 0.537s/it]: train_loss_raw=1.6092, running_loss=1.6656, LR=0.000100
[2025-08-10 13:47:37,635][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018264] [Batch 03496/03692] [00:31:17/00:01:45, 0.537s/it]: train_loss_raw=1.7331, running_loss=1.6665, LR=0.000100
[2025-08-10 13:47:44,082][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018276] [Batch 03508/03692] [00:31:24/00:01:38, 0.537s/it]: train_loss_raw=1.4626, running_loss=1.6585, LR=0.000100
[2025-08-10 13:47:50,576][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018288] [Batch 03520/03692] [00:31:30/00:01:32, 0.537s/it]: train_loss_raw=1.7399, running_loss=1.6616, LR=0.000100
[2025-08-10 13:47:57,109][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018300] [Batch 03532/03692] [00:31:37/00:01:25, 0.537s/it]: train_loss_raw=1.7106, running_loss=1.6601, LR=0.000100
[2025-08-10 13:48:03,547][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018312] [Batch 03544/03692] [00:31:43/00:01:19, 0.537s/it]: train_loss_raw=1.6103, running_loss=1.6599, LR=0.000100
[2025-08-10 13:48:09,564][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018324] [Batch 03556/03692] [00:31:49/00:01:13, 0.537s/it]: train_loss_raw=1.7350, running_loss=1.6639, LR=0.000100
[2025-08-10 13:48:15,693][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018336] [Batch 03568/03692] [00:31:55/00:01:06, 0.537s/it]: train_loss_raw=1.6762, running_loss=1.6656, LR=0.000100
[2025-08-10 13:48:21,725][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018348] [Batch 03580/03692] [00:32:01/00:01:00, 0.537s/it]: train_loss_raw=1.5711, running_loss=1.6675, LR=0.000100
[2025-08-10 13:48:27,866][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018360] [Batch 03592/03692] [00:32:07/00:00:53, 0.537s/it]: train_loss_raw=1.6364, running_loss=1.6675, LR=0.000100
[2025-08-10 13:48:34,101][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018372] [Batch 03604/03692] [00:32:14/00:00:47, 0.537s/it]: train_loss_raw=1.6088, running_loss=1.6639, LR=0.000100
[2025-08-10 13:48:40,288][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018384] [Batch 03616/03692] [00:32:20/00:00:40, 0.537s/it]: train_loss_raw=1.5644, running_loss=1.6603, LR=0.000100
[2025-08-10 13:48:46,335][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018396] [Batch 03628/03692] [00:32:26/00:00:34, 0.536s/it]: train_loss_raw=1.5094, running_loss=1.6551, LR=0.000100
[2025-08-10 13:48:52,353][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018408] [Batch 03640/03692] [00:32:32/00:00:27, 0.536s/it]: train_loss_raw=1.7019, running_loss=1.6546, LR=0.000100
[2025-08-10 13:48:58,407][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018420] [Batch 03652/03692] [00:32:38/00:00:21, 0.536s/it]: train_loss_raw=1.6362, running_loss=1.6540, LR=0.000100
[2025-08-10 13:49:04,499][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018432] [Batch 03664/03692] [00:32:44/00:00:15, 0.536s/it]: train_loss_raw=1.6756, running_loss=1.6521, LR=0.000100
[2025-08-10 13:49:10,558][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018444] [Batch 03676/03692] [00:32:50/00:00:08, 0.536s/it]: train_loss_raw=1.7084, running_loss=1.6537, LR=0.000100
[2025-08-10 13:49:16,578][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018456] [Batch 03688/03692] [00:32:56/00:00:02, 0.536s/it]: train_loss_raw=1.7337, running_loss=1.6546, LR=0.000100
[2025-08-10 13:49:24,044][__main__][INFO] - [VALIDATION] [Epoch 04/29] Starting validation.
[2025-08-10 13:49:59,328][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 018461] [Batch 00011/00025] [00:00:35/00:00:38, 2.940s/it]
[2025-08-10 13:50:17,332][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 018461] [Batch 00023/00025] [00:00:53/00:00:02, 2.220s/it]
[2025-08-10 13:50:18,442][__main__][INFO] - [VALIDATION] [Epoch 04/29] train_loss=1.65401, valid_loss=1.57216
[2025-08-10 13:50:18,442][__main__][INFO] - [VALIDATION] [Epoch 04/29] Metrics:
[2025-08-10 13:50:18,442][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_er      0.659
[2025-08-10 13:50:18,442][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_prec    0.068
[2025-08-10 13:50:18,443][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_recall  0.071
[2025-08-10 13:50:18,443][__main__][INFO] - [VALIDATION] [Epoch 04/29] - pep_recall 0.024
[2025-08-10 13:50:18,446][__main__][INFO] - [TRAIN] [Epoch 04/29] Epoch complete, total time 02:54:17, remaining time 14:31:28, 00:34:51 per epoch
[2025-08-10 13:50:23,171][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018468] [Batch 00008/03692] [00:00:04/00:34:13, 0.557s/it]: train_loss_raw=1.6671, running_loss=1.7185, LR=0.000100
[2025-08-10 13:50:29,257][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018480] [Batch 00020/03692] [00:00:10/00:32:16, 0.527s/it]: train_loss_raw=1.6284, running_loss=1.7114, LR=0.000100
[2025-08-10 13:50:35,629][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018492] [Batch 00032/03692] [00:00:16/00:32:14, 0.529s/it]: train_loss_raw=1.7570, running_loss=1.7106, LR=0.000100
[2025-08-10 13:50:42,133][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018504] [Batch 00044/03692] [00:00:23/00:32:21, 0.532s/it]: train_loss_raw=1.5843, running_loss=1.7016, LR=0.000100
[2025-08-10 13:50:48,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018516] [Batch 00056/03692] [00:00:30/00:32:29, 0.536s/it]: train_loss_raw=1.6345, running_loss=1.6948, LR=0.000100
[2025-08-10 13:50:55,263][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018528] [Batch 00068/03692] [00:00:36/00:32:27, 0.538s/it]: train_loss_raw=1.7530, running_loss=1.6913, LR=0.000100
[2025-08-10 13:51:01,803][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018540] [Batch 00080/03692] [00:00:43/00:32:25, 0.539s/it]: train_loss_raw=1.5125, running_loss=1.6866, LR=0.000100
[2025-08-10 13:51:08,237][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018552] [Batch 00092/03692] [00:00:49/00:32:17, 0.538s/it]: train_loss_raw=1.4949, running_loss=1.6758, LR=0.000100
[2025-08-10 13:51:14,297][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018564] [Batch 00104/03692] [00:00:55/00:31:57, 0.534s/it]: train_loss_raw=1.6930, running_loss=1.6763, LR=0.000100
[2025-08-10 13:51:20,360][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018576] [Batch 00116/03692] [00:01:01/00:31:40, 0.531s/it]: train_loss_raw=1.6706, running_loss=1.6715, LR=0.000100
[2025-08-10 13:51:26,353][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018588] [Batch 00128/03692] [00:01:07/00:31:23, 0.528s/it]: train_loss_raw=1.5942, running_loss=1.6703, LR=0.000100
[2025-08-10 13:51:32,412][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018600] [Batch 00140/03692] [00:01:13/00:31:09, 0.526s/it]: train_loss_raw=1.7055, running_loss=1.6692, LR=0.000100
[2025-08-10 13:51:38,539][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018612] [Batch 00152/03692] [00:01:19/00:30:59, 0.525s/it]: train_loss_raw=1.6461, running_loss=1.6665, LR=0.000100
[2025-08-10 13:51:44,611][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018624] [Batch 00164/03692] [00:01:25/00:30:47, 0.524s/it]: train_loss_raw=1.7637, running_loss=1.6634, LR=0.000100
[2025-08-10 13:51:50,662][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018636] [Batch 00176/03692] [00:01:31/00:30:36, 0.522s/it]: train_loss_raw=1.5465, running_loss=1.6631, LR=0.000100
[2025-08-10 13:51:56,746][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018648] [Batch 00188/03692] [00:01:38/00:30:27, 0.521s/it]: train_loss_raw=1.5829, running_loss=1.6593, LR=0.000100
[2025-08-10 13:52:02,757][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018660] [Batch 00200/03692] [00:01:44/00:30:16, 0.520s/it]: train_loss_raw=1.7330, running_loss=1.6551, LR=0.000100
[2025-08-10 13:52:08,723][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018672] [Batch 00212/03692] [00:01:50/00:30:05, 0.519s/it]: train_loss_raw=1.6874, running_loss=1.6546, LR=0.000100
[2025-08-10 13:52:14,996][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018684] [Batch 00224/03692] [00:01:56/00:30:00, 0.519s/it]: train_loss_raw=1.7109, running_loss=1.6557, LR=0.000100
[2025-08-10 13:52:21,564][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018696] [Batch 00236/03692] [00:02:02/00:29:59, 0.521s/it]: train_loss_raw=1.7130, running_loss=1.6549, LR=0.000100
[2025-08-10 13:52:28,079][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018708] [Batch 00248/03692] [00:02:09/00:29:56, 0.522s/it]: train_loss_raw=1.6012, running_loss=1.6530, LR=0.000100
[2025-08-10 13:52:34,733][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018720] [Batch 00260/03692] [00:02:16/00:29:55, 0.523s/it]: train_loss_raw=1.6045, running_loss=1.6517, LR=0.000100
[2025-08-10 13:52:41,334][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018732] [Batch 00272/03692] [00:02:22/00:29:53, 0.524s/it]: train_loss_raw=1.6757, running_loss=1.6506, LR=0.000100
[2025-08-10 13:52:47,874][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018744] [Batch 00284/03692] [00:02:29/00:29:49, 0.525s/it]: train_loss_raw=1.6453, running_loss=1.6470, LR=0.000100
[2025-08-10 13:52:54,417][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018756] [Batch 00296/03692] [00:02:35/00:29:46, 0.526s/it]: train_loss_raw=1.7512, running_loss=1.6474, LR=0.000100
[2025-08-10 13:53:00,996][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018768] [Batch 00308/03692] [00:02:42/00:29:43, 0.527s/it]: train_loss_raw=1.7201, running_loss=1.6442, LR=0.000100
[2025-08-10 13:53:07,561][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018780] [Batch 00320/03692] [00:02:48/00:29:39, 0.528s/it]: train_loss_raw=1.5876, running_loss=1.6425, LR=0.000100
[2025-08-10 13:53:14,139][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018792] [Batch 00332/03692] [00:02:55/00:29:35, 0.528s/it]: train_loss_raw=1.7168, running_loss=1.6419, LR=0.000100
[2025-08-10 13:53:20,734][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018804] [Batch 00344/03692] [00:03:02/00:29:31, 0.529s/it]: train_loss_raw=1.4963, running_loss=1.6426, LR=0.000100
[2025-08-10 13:53:27,236][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018816] [Batch 00356/03692] [00:03:08/00:29:26, 0.530s/it]: train_loss_raw=1.5995, running_loss=1.6411, LR=0.000100
[2025-08-10 13:53:33,828][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018828] [Batch 00368/03692] [00:03:15/00:29:22, 0.530s/it]: train_loss_raw=1.6366, running_loss=1.6399, LR=0.000100
[2025-08-10 13:53:40,500][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018840] [Batch 00380/03692] [00:03:21/00:29:18, 0.531s/it]: train_loss_raw=1.6267, running_loss=1.6380, LR=0.000100
[2025-08-10 13:53:46,677][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018852] [Batch 00392/03692] [00:03:27/00:29:10, 0.531s/it]: train_loss_raw=1.6825, running_loss=1.6383, LR=0.000100
[2025-08-10 13:53:52,755][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018864] [Batch 00404/03692] [00:03:34/00:29:02, 0.530s/it]: train_loss_raw=1.5056, running_loss=1.6359, LR=0.000100
[2025-08-10 13:53:58,800][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018876] [Batch 00416/03692] [00:03:40/00:28:53, 0.529s/it]: train_loss_raw=1.6030, running_loss=1.6357, LR=0.000100
[2025-08-10 13:54:04,847][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018888] [Batch 00428/03692] [00:03:46/00:28:44, 0.528s/it]: train_loss_raw=1.6285, running_loss=1.6376, LR=0.000100
[2025-08-10 13:54:11,002][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018900] [Batch 00440/03692] [00:03:52/00:28:36, 0.528s/it]: train_loss_raw=1.6333, running_loss=1.6387, LR=0.000100
[2025-08-10 13:54:17,169][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018912] [Batch 00452/03692] [00:03:58/00:28:29, 0.528s/it]: train_loss_raw=1.6652, running_loss=1.6368, LR=0.000100
[2025-08-10 13:54:23,332][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018924] [Batch 00464/03692] [00:04:04/00:28:21, 0.527s/it]: train_loss_raw=1.4953, running_loss=1.6357, LR=0.000100
[2025-08-10 13:54:29,391][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018936] [Batch 00476/03692] [00:04:10/00:28:13, 0.527s/it]: train_loss_raw=1.6033, running_loss=1.6363, LR=0.000100
[2025-08-10 13:54:35,636][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018948] [Batch 00488/03692] [00:04:16/00:28:06, 0.526s/it]: train_loss_raw=1.4233, running_loss=1.6347, LR=0.000100
[2025-08-10 13:54:42,120][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018960] [Batch 00500/03692] [00:04:23/00:28:01, 0.527s/it]: train_loss_raw=1.6139, running_loss=1.6334, LR=0.000100
[2025-08-10 13:54:48,721][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018972] [Batch 00512/03692] [00:04:30/00:27:57, 0.527s/it]: train_loss_raw=1.6972, running_loss=1.6311, LR=0.000100
[2025-08-10 13:54:55,170][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018984] [Batch 00524/03692] [00:04:36/00:27:51, 0.528s/it]: train_loss_raw=1.6960, running_loss=1.6304, LR=0.000100
[2025-08-10 13:55:01,613][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018996] [Batch 00536/03692] [00:04:42/00:27:45, 0.528s/it]: train_loss_raw=1.6614, running_loss=1.6325, LR=0.000100
[2025-08-10 13:55:08,021][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019008] [Batch 00548/03692] [00:04:49/00:27:39, 0.528s/it]: train_loss_raw=1.5321, running_loss=1.6319, LR=0.000100
[2025-08-10 13:55:14,562][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019020] [Batch 00560/03692] [00:04:55/00:27:34, 0.528s/it]: train_loss_raw=1.6469, running_loss=1.6320, LR=0.000100
[2025-08-10 13:55:21,141][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019032] [Batch 00572/03692] [00:05:02/00:27:29, 0.529s/it]: train_loss_raw=1.7475, running_loss=1.6325, LR=0.000100
[2025-08-10 13:55:27,708][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019044] [Batch 00584/03692] [00:05:08/00:27:24, 0.529s/it]: train_loss_raw=1.7053, running_loss=1.6342, LR=0.000100
[2025-08-10 13:55:33,867][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019056] [Batch 00596/03692] [00:05:15/00:27:17, 0.529s/it]: train_loss_raw=1.5478, running_loss=1.6310, LR=0.000100
[2025-08-10 13:55:39,917][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019068] [Batch 00608/03692] [00:05:21/00:27:09, 0.528s/it]: train_loss_raw=1.6606, running_loss=1.6291, LR=0.000100
[2025-08-10 13:55:46,137][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019080] [Batch 00620/03692] [00:05:27/00:27:02, 0.528s/it]: train_loss_raw=1.6129, running_loss=1.6283, LR=0.000100
[2025-08-10 13:55:52,699][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019092] [Batch 00632/03692] [00:05:33/00:26:57, 0.528s/it]: train_loss_raw=1.6264, running_loss=1.6285, LR=0.000100
[2025-08-10 13:55:59,035][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019104] [Batch 00644/03692] [00:05:40/00:26:50, 0.528s/it]: train_loss_raw=1.6775, running_loss=1.6263, LR=0.000100
[2025-08-10 13:56:05,215][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019116] [Batch 00656/03692] [00:05:46/00:26:43, 0.528s/it]: train_loss_raw=1.5632, running_loss=1.6242, LR=0.000100
[2025-08-10 13:56:11,785][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019128] [Batch 00668/03692] [00:05:53/00:26:38, 0.529s/it]: train_loss_raw=1.6478, running_loss=1.6223, LR=0.000100
[2025-08-10 13:56:18,425][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019140] [Batch 00680/03692] [00:05:59/00:26:33, 0.529s/it]: train_loss_raw=1.5095, running_loss=1.6217, LR=0.000100
[2025-08-10 13:56:25,076][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019152] [Batch 00692/03692] [00:06:06/00:26:28, 0.529s/it]: train_loss_raw=1.7462, running_loss=1.6249, LR=0.000100
[2025-08-10 13:56:31,656][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019164] [Batch 00704/03692] [00:06:12/00:26:22, 0.530s/it]: train_loss_raw=1.6739, running_loss=1.6230, LR=0.000100
[2025-08-10 13:56:38,151][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019176] [Batch 00716/03692] [00:06:19/00:26:17, 0.530s/it]: train_loss_raw=1.6256, running_loss=1.6212, LR=0.000100
[2025-08-10 13:56:44,782][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019188] [Batch 00728/03692] [00:06:26/00:26:11, 0.530s/it]: train_loss_raw=1.5171, running_loss=1.6204, LR=0.000100
[2025-08-10 13:56:51,434][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019200] [Batch 00740/03692] [00:06:32/00:26:06, 0.531s/it]: train_loss_raw=1.6385, running_loss=1.6207, LR=0.000100
[2025-08-10 13:56:57,959][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019212] [Batch 00752/03692] [00:06:39/00:26:00, 0.531s/it]: train_loss_raw=1.6634, running_loss=1.6202, LR=0.000100
[2025-08-10 13:57:04,508][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019224] [Batch 00764/03692] [00:06:45/00:25:55, 0.531s/it]: train_loss_raw=1.6843, running_loss=1.6225, LR=0.000100
[2025-08-10 13:57:11,033][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019236] [Batch 00776/03692] [00:06:52/00:25:49, 0.531s/it]: train_loss_raw=1.5399, running_loss=1.6244, LR=0.000100
[2025-08-10 13:57:17,672][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019248] [Batch 00788/03692] [00:06:58/00:25:43, 0.532s/it]: train_loss_raw=1.6465, running_loss=1.6206, LR=0.000100
[2025-08-10 13:57:24,226][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019260] [Batch 00800/03692] [00:07:05/00:25:38, 0.532s/it]: train_loss_raw=1.6681, running_loss=1.6201, LR=0.000100
[2025-08-10 13:57:30,824][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019272] [Batch 00812/03692] [00:07:12/00:25:32, 0.532s/it]: train_loss_raw=1.7313, running_loss=1.6258, LR=0.000100
[2025-08-10 13:57:37,378][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019284] [Batch 00824/03692] [00:07:18/00:25:26, 0.532s/it]: train_loss_raw=1.6648, running_loss=1.6266, LR=0.000100
[2025-08-10 13:57:43,910][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019296] [Batch 00836/03692] [00:07:25/00:25:20, 0.533s/it]: train_loss_raw=1.7085, running_loss=1.6312, LR=0.000100
[2025-08-10 13:57:50,083][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019308] [Batch 00848/03692] [00:07:31/00:25:13, 0.532s/it]: train_loss_raw=1.5115, running_loss=1.6273, LR=0.000100
[2025-08-10 13:57:56,147][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019320] [Batch 00860/03692] [00:07:37/00:25:06, 0.532s/it]: train_loss_raw=1.6702, running_loss=1.6272, LR=0.000100
[2025-08-10 13:58:02,153][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019332] [Batch 00872/03692] [00:07:43/00:24:58, 0.531s/it]: train_loss_raw=1.5483, running_loss=1.6218, LR=0.000100
[2025-08-10 13:58:08,167][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019344] [Batch 00884/03692] [00:07:49/00:24:51, 0.531s/it]: train_loss_raw=1.5541, running_loss=1.6241, LR=0.000100
[2025-08-10 13:58:14,229][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019356] [Batch 00896/03692] [00:07:55/00:24:43, 0.531s/it]: train_loss_raw=1.5851, running_loss=1.6183, LR=0.000100
[2025-08-10 13:58:20,351][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019368] [Batch 00908/03692] [00:08:01/00:24:36, 0.530s/it]: train_loss_raw=1.6180, running_loss=1.6185, LR=0.000100
[2025-08-10 13:58:26,369][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019380] [Batch 00920/03692] [00:08:07/00:24:29, 0.530s/it]: train_loss_raw=1.6248, running_loss=1.6212, LR=0.000100
[2025-08-10 13:58:32,461][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019392] [Batch 00932/03692] [00:08:13/00:24:22, 0.530s/it]: train_loss_raw=1.6520, running_loss=1.6218, LR=0.000100
[2025-08-10 13:58:38,590][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019404] [Batch 00944/03692] [00:08:19/00:24:15, 0.530s/it]: train_loss_raw=1.5167, running_loss=1.6174, LR=0.000100
[2025-08-10 13:58:44,605][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019416] [Batch 00956/03692] [00:08:25/00:24:07, 0.529s/it]: train_loss_raw=1.7598, running_loss=1.6204, LR=0.000100
[2025-08-10 13:58:50,650][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019428] [Batch 00968/03692] [00:08:31/00:24:00, 0.529s/it]: train_loss_raw=1.6518, running_loss=1.6233, LR=0.000100
[2025-08-10 13:58:56,717][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019440] [Batch 00980/03692] [00:08:38/00:23:53, 0.529s/it]: train_loss_raw=1.5497, running_loss=1.6237, LR=0.000100
[2025-08-10 13:59:02,816][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019452] [Batch 00992/03692] [00:08:44/00:23:46, 0.528s/it]: train_loss_raw=1.4823, running_loss=1.6170, LR=0.000100
[2025-08-10 13:59:08,983][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019464] [Batch 01004/03692] [00:08:50/00:23:39, 0.528s/it]: train_loss_raw=1.5474, running_loss=1.6163, LR=0.000100
[2025-08-10 13:59:15,244][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019476] [Batch 01016/03692] [00:08:56/00:23:33, 0.528s/it]: train_loss_raw=1.5423, running_loss=1.6186, LR=0.000100
[2025-08-10 13:59:21,743][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019488] [Batch 01028/03692] [00:09:03/00:23:27, 0.528s/it]: train_loss_raw=1.8229, running_loss=1.6220, LR=0.000100
[2025-08-10 13:59:28,287][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019500] [Batch 01040/03692] [00:09:09/00:23:21, 0.528s/it]: train_loss_raw=1.5542, running_loss=1.6207, LR=0.000100
[2025-08-10 13:59:34,836][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019512] [Batch 01052/03692] [00:09:16/00:23:15, 0.529s/it]: train_loss_raw=1.6101, running_loss=1.6151, LR=0.000100
[2025-08-10 13:59:41,350][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019524] [Batch 01064/03692] [00:09:22/00:23:09, 0.529s/it]: train_loss_raw=1.6441, running_loss=1.6180, LR=0.000100
[2025-08-10 13:59:47,867][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019536] [Batch 01076/03692] [00:09:29/00:23:03, 0.529s/it]: train_loss_raw=1.7312, running_loss=1.6162, LR=0.000100
[2025-08-10 13:59:54,379][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019548] [Batch 01088/03692] [00:09:35/00:22:57, 0.529s/it]: train_loss_raw=1.6551, running_loss=1.6160, LR=0.000100
[2025-08-10 14:00:00,960][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019560] [Batch 01100/03692] [00:09:42/00:22:51, 0.529s/it]: train_loss_raw=1.6141, running_loss=1.6163, LR=0.000100
[2025-08-10 14:00:07,323][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019572] [Batch 01112/03692] [00:09:48/00:22:45, 0.529s/it]: train_loss_raw=1.6735, running_loss=1.6191, LR=0.000100
[2025-08-10 14:00:13,339][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019584] [Batch 01124/03692] [00:09:54/00:22:38, 0.529s/it]: train_loss_raw=1.7036, running_loss=1.6150, LR=0.000100
[2025-08-10 14:00:19,357][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019596] [Batch 01136/03692] [00:10:00/00:22:31, 0.529s/it]: train_loss_raw=1.5285, running_loss=1.6116, LR=0.000100
[2025-08-10 14:00:25,455][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019608] [Batch 01148/03692] [00:10:06/00:22:24, 0.529s/it]: train_loss_raw=1.5264, running_loss=1.6079, LR=0.000100
[2025-08-10 14:00:31,549][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019620] [Batch 01160/03692] [00:10:12/00:22:17, 0.528s/it]: train_loss_raw=1.3574, running_loss=1.6084, LR=0.000100
[2025-08-10 14:00:37,657][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019632] [Batch 01172/03692] [00:10:18/00:22:10, 0.528s/it]: train_loss_raw=1.5772, running_loss=1.6071, LR=0.000100
[2025-08-10 14:00:43,766][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019644] [Batch 01184/03692] [00:10:25/00:22:04, 0.528s/it]: train_loss_raw=1.4892, running_loss=1.6030, LR=0.000100
[2025-08-10 14:00:49,889][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019656] [Batch 01196/03692] [00:10:31/00:21:57, 0.528s/it]: train_loss_raw=1.6528, running_loss=1.6022, LR=0.000100
[2025-08-10 14:00:56,124][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019668] [Batch 01208/03692] [00:10:37/00:21:50, 0.528s/it]: train_loss_raw=1.5978, running_loss=1.6004, LR=0.000100
[2025-08-10 14:01:02,343][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019680] [Batch 01220/03692] [00:10:43/00:21:44, 0.528s/it]: train_loss_raw=1.6192, running_loss=1.5987, LR=0.000100
[2025-08-10 14:01:08,496][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019692] [Batch 01232/03692] [00:10:49/00:21:37, 0.527s/it]: train_loss_raw=1.5594, running_loss=1.5985, LR=0.000100
[2025-08-10 14:01:14,491][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019704] [Batch 01244/03692] [00:10:55/00:21:30, 0.527s/it]: train_loss_raw=1.5515, running_loss=1.5984, LR=0.000100
[2025-08-10 14:01:20,593][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019716] [Batch 01256/03692] [00:11:01/00:21:23, 0.527s/it]: train_loss_raw=1.5050, running_loss=1.5988, LR=0.000100
[2025-08-10 14:01:27,194][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019728] [Batch 01268/03692] [00:11:08/00:21:17, 0.527s/it]: train_loss_raw=1.5811, running_loss=1.6003, LR=0.000100
[2025-08-10 14:01:33,845][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019740] [Batch 01280/03692] [00:11:15/00:21:12, 0.527s/it]: train_loss_raw=1.5396, running_loss=1.5999, LR=0.000100
[2025-08-10 14:01:40,384][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019752] [Batch 01292/03692] [00:11:21/00:21:06, 0.528s/it]: train_loss_raw=1.6682, running_loss=1.5998, LR=0.000100
[2025-08-10 14:01:46,892][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019764] [Batch 01304/03692] [00:11:28/00:21:00, 0.528s/it]: train_loss_raw=1.6362, running_loss=1.6025, LR=0.000100
[2025-08-10 14:01:53,279][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019776] [Batch 01316/03692] [00:11:34/00:20:54, 0.528s/it]: train_loss_raw=1.5513, running_loss=1.5992, LR=0.000100
[2025-08-10 14:01:59,409][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019788] [Batch 01328/03692] [00:11:40/00:20:47, 0.528s/it]: train_loss_raw=1.6162, running_loss=1.5984, LR=0.000100
[2025-08-10 14:02:05,582][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019800] [Batch 01340/03692] [00:11:46/00:20:40, 0.528s/it]: train_loss_raw=1.6094, running_loss=1.5956, LR=0.000100
[2025-08-10 14:02:12,022][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019812] [Batch 01352/03692] [00:11:53/00:20:34, 0.528s/it]: train_loss_raw=1.6463, running_loss=1.5984, LR=0.000100
[2025-08-10 14:02:18,628][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019824] [Batch 01364/03692] [00:11:59/00:20:28, 0.528s/it]: train_loss_raw=1.6040, running_loss=1.5989, LR=0.000100
[2025-08-10 14:02:25,081][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019836] [Batch 01376/03692] [00:12:06/00:20:22, 0.528s/it]: train_loss_raw=1.4889, running_loss=1.5942, LR=0.000100
[2025-08-10 14:02:31,684][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019848] [Batch 01388/03692] [00:12:12/00:20:16, 0.528s/it]: train_loss_raw=1.5178, running_loss=1.5965, LR=0.000100
[2025-08-10 14:02:37,998][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019860] [Batch 01400/03692] [00:12:19/00:20:10, 0.528s/it]: train_loss_raw=1.5656, running_loss=1.5966, LR=0.000100
[2025-08-10 14:02:44,014][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019872] [Batch 01412/03692] [00:12:25/00:20:03, 0.528s/it]: train_loss_raw=1.6212, running_loss=1.5966, LR=0.000100
[2025-08-10 14:02:50,077][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019884] [Batch 01424/03692] [00:12:31/00:19:56, 0.528s/it]: train_loss_raw=1.6194, running_loss=1.5960, LR=0.000100
[2025-08-10 14:02:56,077][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019896] [Batch 01436/03692] [00:12:37/00:19:49, 0.527s/it]: train_loss_raw=1.5905, running_loss=1.5945, LR=0.000100
[2025-08-10 14:03:02,121][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019908] [Batch 01448/03692] [00:12:43/00:19:43, 0.527s/it]: train_loss_raw=1.5637, running_loss=1.5966, LR=0.000100
[2025-08-10 14:03:08,423][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019920] [Batch 01460/03692] [00:12:49/00:19:36, 0.527s/it]: train_loss_raw=1.6218, running_loss=1.5983, LR=0.000100
[2025-08-10 14:03:14,483][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019932] [Batch 01472/03692] [00:12:55/00:19:29, 0.527s/it]: train_loss_raw=1.6713, running_loss=1.6030, LR=0.000100
[2025-08-10 14:03:20,609][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019944] [Batch 01484/03692] [00:13:01/00:19:23, 0.527s/it]: train_loss_raw=1.6002, running_loss=1.6049, LR=0.000100
[2025-08-10 14:03:26,935][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019956] [Batch 01496/03692] [00:13:08/00:19:17, 0.527s/it]: train_loss_raw=1.6362, running_loss=1.5999, LR=0.000100
[2025-08-10 14:03:33,487][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019968] [Batch 01508/03692] [00:13:14/00:19:11, 0.527s/it]: train_loss_raw=1.4738, running_loss=1.5972, LR=0.000100
[2025-08-10 14:03:39,863][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019980] [Batch 01520/03692] [00:13:21/00:19:04, 0.527s/it]: train_loss_raw=1.6759, running_loss=1.5952, LR=0.000100
[2025-08-10 14:03:46,130][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019992] [Batch 01532/03692] [00:13:27/00:18:58, 0.527s/it]: train_loss_raw=1.5477, running_loss=1.5973, LR=0.000100
[2025-08-10 14:03:56,464][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020004] [Batch 01544/03692] [00:13:37/00:18:57, 0.530s/it]: train_loss_raw=1.6101, running_loss=1.5983, LR=0.000100
[2025-08-10 14:04:02,540][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020016] [Batch 01556/03692] [00:13:43/00:18:50, 0.529s/it]: train_loss_raw=1.6004, running_loss=1.5991, LR=0.000100
[2025-08-10 14:04:08,549][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020028] [Batch 01568/03692] [00:13:49/00:18:44, 0.529s/it]: train_loss_raw=1.5958, running_loss=1.5981, LR=0.000100
[2025-08-10 14:04:14,599][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020040] [Batch 01580/03692] [00:13:55/00:18:37, 0.529s/it]: train_loss_raw=1.6242, running_loss=1.5974, LR=0.000100
[2025-08-10 14:04:20,682][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020052] [Batch 01592/03692] [00:14:01/00:18:30, 0.529s/it]: train_loss_raw=1.5556, running_loss=1.5968, LR=0.000100
[2025-08-10 14:04:26,781][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020064] [Batch 01604/03692] [00:14:08/00:18:23, 0.529s/it]: train_loss_raw=1.6901, running_loss=1.5981, LR=0.000100
[2025-08-10 14:04:32,897][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020076] [Batch 01616/03692] [00:14:14/00:18:17, 0.529s/it]: train_loss_raw=1.5273, running_loss=1.5975, LR=0.000100
[2025-08-10 14:04:39,482][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020088] [Batch 01628/03692] [00:14:20/00:18:11, 0.529s/it]: train_loss_raw=1.6010, running_loss=1.5933, LR=0.000100
[2025-08-10 14:04:46,041][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020100] [Batch 01640/03692] [00:14:27/00:18:05, 0.529s/it]: train_loss_raw=1.4990, running_loss=1.5899, LR=0.000100
[2025-08-10 14:04:52,561][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020112] [Batch 01652/03692] [00:14:33/00:17:59, 0.529s/it]: train_loss_raw=1.5771, running_loss=1.5903, LR=0.000100
[2025-08-10 14:04:59,083][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020124] [Batch 01664/03692] [00:14:40/00:17:52, 0.529s/it]: train_loss_raw=1.6561, running_loss=1.5875, LR=0.000100
[2025-08-10 14:05:05,673][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020136] [Batch 01676/03692] [00:14:46/00:17:46, 0.529s/it]: train_loss_raw=1.5749, running_loss=1.5891, LR=0.000100
[2025-08-10 14:05:12,268][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020148] [Batch 01688/03692] [00:14:53/00:17:40, 0.529s/it]: train_loss_raw=1.4871, running_loss=1.5877, LR=0.000100
[2025-08-10 14:05:18,828][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020160] [Batch 01700/03692] [00:15:00/00:17:34, 0.529s/it]: train_loss_raw=1.7034, running_loss=1.5854, LR=0.000100
[2025-08-10 14:05:25,414][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020172] [Batch 01712/03692] [00:15:06/00:17:28, 0.530s/it]: train_loss_raw=1.5789, running_loss=1.5860, LR=0.000100
[2025-08-10 14:05:32,042][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020184] [Batch 01724/03692] [00:15:13/00:17:22, 0.530s/it]: train_loss_raw=1.5979, running_loss=1.5856, LR=0.000100
[2025-08-10 14:05:38,459][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020196] [Batch 01736/03692] [00:15:19/00:17:16, 0.530s/it]: train_loss_raw=1.6600, running_loss=1.5870, LR=0.000100
[2025-08-10 14:05:44,532][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020208] [Batch 01748/03692] [00:15:25/00:17:09, 0.530s/it]: train_loss_raw=1.4615, running_loss=1.5845, LR=0.000100
[2025-08-10 14:05:50,642][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020220] [Batch 01760/03692] [00:15:31/00:17:03, 0.530s/it]: train_loss_raw=1.6493, running_loss=1.5855, LR=0.000100
[2025-08-10 14:05:56,734][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020232] [Batch 01772/03692] [00:15:38/00:16:56, 0.529s/it]: train_loss_raw=1.6341, running_loss=1.5846, LR=0.000100
[2025-08-10 14:06:02,918][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020244] [Batch 01784/03692] [00:15:44/00:16:49, 0.529s/it]: train_loss_raw=1.5370, running_loss=1.5878, LR=0.000100
[2025-08-10 14:06:09,101][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020256] [Batch 01796/03692] [00:15:50/00:16:43, 0.529s/it]: train_loss_raw=1.5578, running_loss=1.5890, LR=0.000100
[2025-08-10 14:06:15,401][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020268] [Batch 01808/03692] [00:15:56/00:16:36, 0.529s/it]: train_loss_raw=1.5784, running_loss=1.5872, LR=0.000100
[2025-08-10 14:06:21,962][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020280] [Batch 01820/03692] [00:16:03/00:16:30, 0.529s/it]: train_loss_raw=1.7000, running_loss=1.5895, LR=0.000100
[2025-08-10 14:06:28,358][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020292] [Batch 01832/03692] [00:16:09/00:16:24, 0.529s/it]: train_loss_raw=1.5985, running_loss=1.5871, LR=0.000100
[2025-08-10 14:06:34,669][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020304] [Batch 01844/03692] [00:16:15/00:16:18, 0.529s/it]: train_loss_raw=1.4247, running_loss=1.5845, LR=0.000100
[2025-08-10 14:06:41,190][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020316] [Batch 01856/03692] [00:16:22/00:16:11, 0.529s/it]: train_loss_raw=1.6691, running_loss=1.5847, LR=0.000100
[2025-08-10 14:06:47,469][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020328] [Batch 01868/03692] [00:16:28/00:16:05, 0.529s/it]: train_loss_raw=1.5680, running_loss=1.5805, LR=0.000100
[2025-08-10 14:06:53,507][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020340] [Batch 01880/03692] [00:16:34/00:15:58, 0.529s/it]: train_loss_raw=1.6624, running_loss=1.5819, LR=0.000100
[2025-08-10 14:06:59,628][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020352] [Batch 01892/03692] [00:16:40/00:15:52, 0.529s/it]: train_loss_raw=1.6330, running_loss=1.5826, LR=0.000100
[2025-08-10 14:07:05,801][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020364] [Batch 01904/03692] [00:16:47/00:15:45, 0.529s/it]: train_loss_raw=1.5476, running_loss=1.5821, LR=0.000100
[2025-08-10 14:07:11,853][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020376] [Batch 01916/03692] [00:16:53/00:15:39, 0.529s/it]: train_loss_raw=1.6148, running_loss=1.5830, LR=0.000100
[2025-08-10 14:07:18,034][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020388] [Batch 01928/03692] [00:16:59/00:15:32, 0.529s/it]: train_loss_raw=1.5554, running_loss=1.5785, LR=0.000100
[2025-08-10 14:07:24,136][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020400] [Batch 01940/03692] [00:17:05/00:15:26, 0.529s/it]: train_loss_raw=1.5181, running_loss=1.5770, LR=0.000100
[2025-08-10 14:07:30,578][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020412] [Batch 01952/03692] [00:17:11/00:15:19, 0.529s/it]: train_loss_raw=1.5529, running_loss=1.5744, LR=0.000100
[2025-08-10 14:07:37,008][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020424] [Batch 01964/03692] [00:17:18/00:15:13, 0.529s/it]: train_loss_raw=1.5276, running_loss=1.5723, LR=0.000100
[2025-08-10 14:07:43,327][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020436] [Batch 01976/03692] [00:17:24/00:15:07, 0.529s/it]: train_loss_raw=1.6056, running_loss=1.5711, LR=0.000100
[2025-08-10 14:07:49,869][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020448] [Batch 01988/03692] [00:17:31/00:15:00, 0.529s/it]: train_loss_raw=1.6425, running_loss=1.5777, LR=0.000100
[2025-08-10 14:07:56,415][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020460] [Batch 02000/03692] [00:17:37/00:14:54, 0.529s/it]: train_loss_raw=1.4850, running_loss=1.5782, LR=0.000100
[2025-08-10 14:08:02,969][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020472] [Batch 02012/03692] [00:17:44/00:14:48, 0.529s/it]: train_loss_raw=1.6025, running_loss=1.5784, LR=0.000100
[2025-08-10 14:08:09,323][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020484] [Batch 02024/03692] [00:17:50/00:14:42, 0.529s/it]: train_loss_raw=1.5724, running_loss=1.5777, LR=0.000100
[2025-08-10 14:08:15,876][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020496] [Batch 02036/03692] [00:17:57/00:14:36, 0.529s/it]: train_loss_raw=1.5536, running_loss=1.5755, LR=0.000100
[2025-08-10 14:08:22,335][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020508] [Batch 02048/03692] [00:18:03/00:14:29, 0.529s/it]: train_loss_raw=1.6918, running_loss=1.5777, LR=0.000100
[2025-08-10 14:08:28,577][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020520] [Batch 02060/03692] [00:18:09/00:14:23, 0.529s/it]: train_loss_raw=1.7114, running_loss=1.5780, LR=0.000100
[2025-08-10 14:08:34,854][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020532] [Batch 02072/03692] [00:18:16/00:14:17, 0.529s/it]: train_loss_raw=1.5617, running_loss=1.5755, LR=0.000100
[2025-08-10 14:08:41,053][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020544] [Batch 02084/03692] [00:18:22/00:14:10, 0.529s/it]: train_loss_raw=1.5169, running_loss=1.5767, LR=0.000100
[2025-08-10 14:08:47,416][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020556] [Batch 02096/03692] [00:18:28/00:14:04, 0.529s/it]: train_loss_raw=1.4875, running_loss=1.5763, LR=0.000100
[2025-08-10 14:08:54,039][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020568] [Batch 02108/03692] [00:18:35/00:13:58, 0.529s/it]: train_loss_raw=1.6058, running_loss=1.5749, LR=0.000100
[2025-08-10 14:09:00,638][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020580] [Batch 02120/03692] [00:18:41/00:13:51, 0.529s/it]: train_loss_raw=1.4780, running_loss=1.5769, LR=0.000100
[2025-08-10 14:09:07,231][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020592] [Batch 02132/03692] [00:18:48/00:13:45, 0.529s/it]: train_loss_raw=1.5371, running_loss=1.5721, LR=0.000100
[2025-08-10 14:09:13,615][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020604] [Batch 02144/03692] [00:18:54/00:13:39, 0.529s/it]: train_loss_raw=1.6021, running_loss=1.5703, LR=0.000100
[2025-08-10 14:09:19,869][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020616] [Batch 02156/03692] [00:19:01/00:13:32, 0.529s/it]: train_loss_raw=1.5619, running_loss=1.5719, LR=0.000100
[2025-08-10 14:09:39,277][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020628] [Batch 02168/03692] [00:19:20/00:13:35, 0.535s/it]: train_loss_raw=1.4628, running_loss=1.5709, LR=0.000100
[2025-08-10 14:09:45,343][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020640] [Batch 02180/03692] [00:19:26/00:13:29, 0.535s/it]: train_loss_raw=1.3294, running_loss=1.5673, LR=0.000100
[2025-08-10 14:09:51,414][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020652] [Batch 02192/03692] [00:19:32/00:13:22, 0.535s/it]: train_loss_raw=1.4833, running_loss=1.5612, LR=0.000100
[2025-08-10 14:09:57,407][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020664] [Batch 02204/03692] [00:19:38/00:13:15, 0.535s/it]: train_loss_raw=1.4938, running_loss=1.5615, LR=0.000100
[2025-08-10 14:10:03,465][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020676] [Batch 02216/03692] [00:19:44/00:13:09, 0.535s/it]: train_loss_raw=1.4584, running_loss=1.5600, LR=0.000100
[2025-08-10 14:10:09,578][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020688] [Batch 02228/03692] [00:19:50/00:13:02, 0.534s/it]: train_loss_raw=1.6379, running_loss=1.5622, LR=0.000100
[2025-08-10 14:10:15,619][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020700] [Batch 02240/03692] [00:19:56/00:12:55, 0.534s/it]: train_loss_raw=1.5256, running_loss=1.5580, LR=0.000100
[2025-08-10 14:10:21,776][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020712] [Batch 02252/03692] [00:20:03/00:12:49, 0.534s/it]: train_loss_raw=1.5951, running_loss=1.5624, LR=0.000100
[2025-08-10 14:10:28,188][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020724] [Batch 02264/03692] [00:20:09/00:12:42, 0.534s/it]: train_loss_raw=1.5378, running_loss=1.5660, LR=0.000100
[2025-08-10 14:10:34,685][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020736] [Batch 02276/03692] [00:20:15/00:12:36, 0.534s/it]: train_loss_raw=1.4975, running_loss=1.5666, LR=0.000100
[2025-08-10 14:10:41,092][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020748] [Batch 02288/03692] [00:20:22/00:12:30, 0.534s/it]: train_loss_raw=1.6022, running_loss=1.5663, LR=0.000100
[2025-08-10 14:10:47,522][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020760] [Batch 02300/03692] [00:20:28/00:12:23, 0.534s/it]: train_loss_raw=1.4506, running_loss=1.5661, LR=0.000100
[2025-08-10 14:10:54,005][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020772] [Batch 02312/03692] [00:20:35/00:12:17, 0.534s/it]: train_loss_raw=1.6919, running_loss=1.5667, LR=0.000100
[2025-08-10 14:11:00,471][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020784] [Batch 02324/03692] [00:20:41/00:12:10, 0.534s/it]: train_loss_raw=1.5588, running_loss=1.5660, LR=0.000100
[2025-08-10 14:11:07,027][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020796] [Batch 02336/03692] [00:20:48/00:12:04, 0.534s/it]: train_loss_raw=1.5282, running_loss=1.5658, LR=0.000100
[2025-08-10 14:11:13,605][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020808] [Batch 02348/03692] [00:20:54/00:11:58, 0.534s/it]: train_loss_raw=1.6148, running_loss=1.5673, LR=0.000100
[2025-08-10 14:11:20,163][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020820] [Batch 02360/03692] [00:21:01/00:11:51, 0.535s/it]: train_loss_raw=1.6941, running_loss=1.5666, LR=0.000100
[2025-08-10 14:11:26,699][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020832] [Batch 02372/03692] [00:21:07/00:11:45, 0.535s/it]: train_loss_raw=1.5943, running_loss=1.5640, LR=0.000100
[2025-08-10 14:11:33,232][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020844] [Batch 02384/03692] [00:21:14/00:11:39, 0.535s/it]: train_loss_raw=1.6326, running_loss=1.5636, LR=0.000100
[2025-08-10 14:11:39,716][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020856] [Batch 02396/03692] [00:21:21/00:11:32, 0.535s/it]: train_loss_raw=1.4790, running_loss=1.5624, LR=0.000100
[2025-08-10 14:11:46,320][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020868] [Batch 02408/03692] [00:21:27/00:11:26, 0.535s/it]: train_loss_raw=1.5095, running_loss=1.5623, LR=0.000100
[2025-08-10 14:11:52,748][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020880] [Batch 02420/03692] [00:21:34/00:11:20, 0.535s/it]: train_loss_raw=1.4980, running_loss=1.5621, LR=0.000100
[2025-08-10 14:11:59,160][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020892] [Batch 02432/03692] [00:21:40/00:11:13, 0.535s/it]: train_loss_raw=1.4226, running_loss=1.5607, LR=0.000100
[2025-08-10 14:12:05,629][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020904] [Batch 02444/03692] [00:21:46/00:11:07, 0.535s/it]: train_loss_raw=1.5937, running_loss=1.5624, LR=0.000100
[2025-08-10 14:12:12,101][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020916] [Batch 02456/03692] [00:21:53/00:11:00, 0.535s/it]: train_loss_raw=1.5391, running_loss=1.5610, LR=0.000100
[2025-08-10 14:12:18,510][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020928] [Batch 02468/03692] [00:21:59/00:10:54, 0.535s/it]: train_loss_raw=1.4967, running_loss=1.5588, LR=0.000100
[2025-08-10 14:12:24,902][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020940] [Batch 02480/03692] [00:22:06/00:10:48, 0.535s/it]: train_loss_raw=1.4879, running_loss=1.5613, LR=0.000100
[2025-08-10 14:12:31,421][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020952] [Batch 02492/03692] [00:22:12/00:10:41, 0.535s/it]: train_loss_raw=1.5066, running_loss=1.5614, LR=0.000100
[2025-08-10 14:12:37,978][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020964] [Batch 02504/03692] [00:22:19/00:10:35, 0.535s/it]: train_loss_raw=1.5184, running_loss=1.5648, LR=0.000100
[2025-08-10 14:12:44,574][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020976] [Batch 02516/03692] [00:22:25/00:10:29, 0.535s/it]: train_loss_raw=1.4882, running_loss=1.5622, LR=0.000100
[2025-08-10 14:12:51,193][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020988] [Batch 02528/03692] [00:22:32/00:10:22, 0.535s/it]: train_loss_raw=1.4797, running_loss=1.5619, LR=0.000100
[2025-08-10 14:12:57,719][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021000] [Batch 02540/03692] [00:22:39/00:10:16, 0.535s/it]: train_loss_raw=1.6080, running_loss=1.5616, LR=0.000100
[2025-08-10 14:13:04,189][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021012] [Batch 02552/03692] [00:22:45/00:10:09, 0.535s/it]: train_loss_raw=1.4453, running_loss=1.5607, LR=0.000100
[2025-08-10 14:13:10,642][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021024] [Batch 02564/03692] [00:22:51/00:10:03, 0.535s/it]: train_loss_raw=1.5629, running_loss=1.5588, LR=0.000100
[2025-08-10 14:13:17,150][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021036] [Batch 02576/03692] [00:22:58/00:09:57, 0.535s/it]: train_loss_raw=1.6251, running_loss=1.5595, LR=0.000100
[2025-08-10 14:13:23,601][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021048] [Batch 02588/03692] [00:23:04/00:09:50, 0.535s/it]: train_loss_raw=1.6635, running_loss=1.5601, LR=0.000100
[2025-08-10 14:13:30,100][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021060] [Batch 02600/03692] [00:23:11/00:09:44, 0.535s/it]: train_loss_raw=1.5107, running_loss=1.5573, LR=0.000100
[2025-08-10 14:13:36,585][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021072] [Batch 02612/03692] [00:23:17/00:09:37, 0.535s/it]: train_loss_raw=1.5991, running_loss=1.5565, LR=0.000100
[2025-08-10 14:13:42,941][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021084] [Batch 02624/03692] [00:23:24/00:09:31, 0.535s/it]: train_loss_raw=1.4518, running_loss=1.5524, LR=0.000100
[2025-08-10 14:13:49,425][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021096] [Batch 02636/03692] [00:23:30/00:09:25, 0.535s/it]: train_loss_raw=1.6993, running_loss=1.5538, LR=0.000100
[2025-08-10 14:13:55,851][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021108] [Batch 02648/03692] [00:23:37/00:09:18, 0.535s/it]: train_loss_raw=1.5623, running_loss=1.5554, LR=0.000100
[2025-08-10 14:14:02,364][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021120] [Batch 02660/03692] [00:23:43/00:09:12, 0.535s/it]: train_loss_raw=1.6295, running_loss=1.5565, LR=0.000100
[2025-08-10 14:14:08,977][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021132] [Batch 02672/03692] [00:23:50/00:09:05, 0.535s/it]: train_loss_raw=1.4446, running_loss=1.5553, LR=0.000100
[2025-08-10 14:14:15,578][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021144] [Batch 02684/03692] [00:23:56/00:08:59, 0.535s/it]: train_loss_raw=1.6885, running_loss=1.5529, LR=0.000100
[2025-08-10 14:14:22,240][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021156] [Batch 02696/03692] [00:24:03/00:08:53, 0.535s/it]: train_loss_raw=1.3893, running_loss=1.5492, LR=0.000100
[2025-08-10 14:14:28,812][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021168] [Batch 02708/03692] [00:24:10/00:08:46, 0.535s/it]: train_loss_raw=1.4900, running_loss=1.5527, LR=0.000100
[2025-08-10 14:14:35,307][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021180] [Batch 02720/03692] [00:24:16/00:08:40, 0.536s/it]: train_loss_raw=1.5609, running_loss=1.5551, LR=0.000100
[2025-08-10 14:14:41,805][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021192] [Batch 02732/03692] [00:24:23/00:08:34, 0.536s/it]: train_loss_raw=1.3596, running_loss=1.5539, LR=0.000100
[2025-08-10 14:14:48,184][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021204] [Batch 02744/03692] [00:24:29/00:08:27, 0.536s/it]: train_loss_raw=1.4085, running_loss=1.5500, LR=0.000100
[2025-08-10 14:14:54,586][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021216] [Batch 02756/03692] [00:24:35/00:08:21, 0.536s/it]: train_loss_raw=1.5021, running_loss=1.5501, LR=0.000100
[2025-08-10 14:15:01,123][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021228] [Batch 02768/03692] [00:24:42/00:08:14, 0.536s/it]: train_loss_raw=1.5872, running_loss=1.5517, LR=0.000100
[2025-08-10 14:15:07,722][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021240] [Batch 02780/03692] [00:24:49/00:08:08, 0.536s/it]: train_loss_raw=1.5811, running_loss=1.5560, LR=0.000100
[2025-08-10 14:15:14,278][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021252] [Batch 02792/03692] [00:24:55/00:08:02, 0.536s/it]: train_loss_raw=1.5259, running_loss=1.5527, LR=0.000100
[2025-08-10 14:15:20,951][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021264] [Batch 02804/03692] [00:25:02/00:07:55, 0.536s/it]: train_loss_raw=1.5363, running_loss=1.5510, LR=0.000100
[2025-08-10 14:15:27,269][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021276] [Batch 02816/03692] [00:25:08/00:07:49, 0.536s/it]: train_loss_raw=1.5890, running_loss=1.5532, LR=0.000100
[2025-08-10 14:15:33,663][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021288] [Batch 02828/03692] [00:25:14/00:07:42, 0.536s/it]: train_loss_raw=1.4503, running_loss=1.5546, LR=0.000100
[2025-08-10 14:15:40,187][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021300] [Batch 02840/03692] [00:25:21/00:07:36, 0.536s/it]: train_loss_raw=1.5273, running_loss=1.5542, LR=0.000100
[2025-08-10 14:15:46,747][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021312] [Batch 02852/03692] [00:25:28/00:07:30, 0.536s/it]: train_loss_raw=1.6306, running_loss=1.5538, LR=0.000100
[2025-08-10 14:15:53,196][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021324] [Batch 02864/03692] [00:25:34/00:07:23, 0.536s/it]: train_loss_raw=1.5002, running_loss=1.5527, LR=0.000100
[2025-08-10 14:15:59,667][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021336] [Batch 02876/03692] [00:25:40/00:07:17, 0.536s/it]: train_loss_raw=1.4704, running_loss=1.5510, LR=0.000100
[2025-08-10 14:16:06,172][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021348] [Batch 02888/03692] [00:25:47/00:07:10, 0.536s/it]: train_loss_raw=1.6796, running_loss=1.5494, LR=0.000100
[2025-08-10 14:16:12,609][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021360] [Batch 02900/03692] [00:25:53/00:07:04, 0.536s/it]: train_loss_raw=1.5410, running_loss=1.5450, LR=0.000100
[2025-08-10 14:16:19,220][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021372] [Batch 02912/03692] [00:26:00/00:06:57, 0.536s/it]: train_loss_raw=1.7224, running_loss=1.5517, LR=0.000100
[2025-08-10 14:16:25,801][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021384] [Batch 02924/03692] [00:26:07/00:06:51, 0.536s/it]: train_loss_raw=1.5769, running_loss=1.5550, LR=0.000100
[2025-08-10 14:16:32,328][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021396] [Batch 02936/03692] [00:26:13/00:06:45, 0.536s/it]: train_loss_raw=1.6224, running_loss=1.5537, LR=0.000100
[2025-08-10 14:16:38,793][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021408] [Batch 02948/03692] [00:26:20/00:06:38, 0.536s/it]: train_loss_raw=1.4888, running_loss=1.5487, LR=0.000100
[2025-08-10 14:16:45,167][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021420] [Batch 02960/03692] [00:26:26/00:06:32, 0.536s/it]: train_loss_raw=1.5711, running_loss=1.5529, LR=0.000100
[2025-08-10 14:16:51,565][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021432] [Batch 02972/03692] [00:26:32/00:06:25, 0.536s/it]: train_loss_raw=1.5554, running_loss=1.5528, LR=0.000100
[2025-08-10 14:16:58,030][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021444] [Batch 02984/03692] [00:26:39/00:06:19, 0.536s/it]: train_loss_raw=1.6515, running_loss=1.5512, LR=0.000100
[2025-08-10 14:17:04,528][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021456] [Batch 02996/03692] [00:26:45/00:06:13, 0.536s/it]: train_loss_raw=1.6395, running_loss=1.5471, LR=0.000100
[2025-08-10 14:17:10,952][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021468] [Batch 03008/03692] [00:26:52/00:06:06, 0.536s/it]: train_loss_raw=1.5783, running_loss=1.5475, LR=0.000100
[2025-08-10 14:17:17,488][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021480] [Batch 03020/03692] [00:26:58/00:06:00, 0.536s/it]: train_loss_raw=1.4544, running_loss=1.5485, LR=0.000100
[2025-08-10 14:17:23,905][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021492] [Batch 03032/03692] [00:27:05/00:05:53, 0.536s/it]: train_loss_raw=1.4889, running_loss=1.5498, LR=0.000100
[2025-08-10 14:17:30,296][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021504] [Batch 03044/03692] [00:27:11/00:05:47, 0.536s/it]: train_loss_raw=1.6482, running_loss=1.5510, LR=0.000100
[2025-08-10 14:17:36,780][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021516] [Batch 03056/03692] [00:27:18/00:05:40, 0.536s/it]: train_loss_raw=1.6750, running_loss=1.5544, LR=0.000100
[2025-08-10 14:17:43,116][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021528] [Batch 03068/03692] [00:27:24/00:05:34, 0.536s/it]: train_loss_raw=1.6489, running_loss=1.5512, LR=0.000100
[2025-08-10 14:17:49,616][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021540] [Batch 03080/03692] [00:27:30/00:05:28, 0.536s/it]: train_loss_raw=1.5924, running_loss=1.5524, LR=0.000100
[2025-08-10 14:17:56,005][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021552] [Batch 03092/03692] [00:27:37/00:05:21, 0.536s/it]: train_loss_raw=1.5562, running_loss=1.5517, LR=0.000100
[2025-08-10 14:18:02,434][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021564] [Batch 03104/03692] [00:27:43/00:05:15, 0.536s/it]: train_loss_raw=1.6321, running_loss=1.5532, LR=0.000100
[2025-08-10 14:18:08,888][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021576] [Batch 03116/03692] [00:27:50/00:05:08, 0.536s/it]: train_loss_raw=1.5405, running_loss=1.5556, LR=0.000100
[2025-08-10 14:18:15,366][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021588] [Batch 03128/03692] [00:27:56/00:05:02, 0.536s/it]: train_loss_raw=1.6694, running_loss=1.5515, LR=0.000100
[2025-08-10 14:18:21,906][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021600] [Batch 03140/03692] [00:28:03/00:04:55, 0.536s/it]: train_loss_raw=1.5618, running_loss=1.5487, LR=0.000100
[2025-08-10 14:18:28,489][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021612] [Batch 03152/03692] [00:28:09/00:04:49, 0.536s/it]: train_loss_raw=1.5675, running_loss=1.5479, LR=0.000100
[2025-08-10 14:18:35,037][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021624] [Batch 03164/03692] [00:28:16/00:04:43, 0.536s/it]: train_loss_raw=1.6490, running_loss=1.5481, LR=0.000100
[2025-08-10 14:18:41,538][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021636] [Batch 03176/03692] [00:28:22/00:04:36, 0.536s/it]: train_loss_raw=1.5874, running_loss=1.5469, LR=0.000100
[2025-08-10 14:18:47,977][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021648] [Batch 03188/03692] [00:28:29/00:04:30, 0.536s/it]: train_loss_raw=1.5899, running_loss=1.5454, LR=0.000100
[2025-08-10 14:18:54,582][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021660] [Batch 03200/03692] [00:28:35/00:04:23, 0.536s/it]: train_loss_raw=1.6096, running_loss=1.5486, LR=0.000100
[2025-08-10 14:19:01,123][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021672] [Batch 03212/03692] [00:28:42/00:04:17, 0.536s/it]: train_loss_raw=1.5003, running_loss=1.5460, LR=0.000100
[2025-08-10 14:19:07,754][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021684] [Batch 03224/03692] [00:28:49/00:04:10, 0.536s/it]: train_loss_raw=1.5892, running_loss=1.5474, LR=0.000100
[2025-08-10 14:19:14,375][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021696] [Batch 03236/03692] [00:28:55/00:04:04, 0.536s/it]: train_loss_raw=1.5946, running_loss=1.5471, LR=0.000100
[2025-08-10 14:19:20,902][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021708] [Batch 03248/03692] [00:29:02/00:03:58, 0.536s/it]: train_loss_raw=1.5277, running_loss=1.5469, LR=0.000100
[2025-08-10 14:19:27,426][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021720] [Batch 03260/03692] [00:29:08/00:03:51, 0.536s/it]: train_loss_raw=1.4667, running_loss=1.5465, LR=0.000100
[2025-08-10 14:19:33,860][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021732] [Batch 03272/03692] [00:29:15/00:03:45, 0.536s/it]: train_loss_raw=1.6298, running_loss=1.5478, LR=0.000100
[2025-08-10 14:19:40,301][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021744] [Batch 03284/03692] [00:29:21/00:03:38, 0.536s/it]: train_loss_raw=1.4680, running_loss=1.5437, LR=0.000100
[2025-08-10 14:19:46,766][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021756] [Batch 03296/03692] [00:29:28/00:03:32, 0.536s/it]: train_loss_raw=1.4395, running_loss=1.5452, LR=0.000100
[2025-08-10 14:19:53,250][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021768] [Batch 03308/03692] [00:29:34/00:03:25, 0.536s/it]: train_loss_raw=1.4391, running_loss=1.5456, LR=0.000100
[2025-08-10 14:19:59,655][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021780] [Batch 03320/03692] [00:29:40/00:03:19, 0.536s/it]: train_loss_raw=1.5351, running_loss=1.5469, LR=0.000100
[2025-08-10 14:20:06,269][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021792] [Batch 03332/03692] [00:29:47/00:03:13, 0.536s/it]: train_loss_raw=1.5232, running_loss=1.5437, LR=0.000100
[2025-08-10 14:20:12,753][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021804] [Batch 03344/03692] [00:29:54/00:03:06, 0.536s/it]: train_loss_raw=1.3854, running_loss=1.5405, LR=0.000100
[2025-08-10 14:20:19,235][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021816] [Batch 03356/03692] [00:30:00/00:03:00, 0.537s/it]: train_loss_raw=1.6444, running_loss=1.5411, LR=0.000100
[2025-08-10 14:20:25,692][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021828] [Batch 03368/03692] [00:30:06/00:02:53, 0.537s/it]: train_loss_raw=1.6402, running_loss=1.5419, LR=0.000100
[2025-08-10 14:20:32,061][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021840] [Batch 03380/03692] [00:30:13/00:02:47, 0.536s/it]: train_loss_raw=1.6093, running_loss=1.5451, LR=0.000100
[2025-08-10 14:20:38,403][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021852] [Batch 03392/03692] [00:30:19/00:02:40, 0.536s/it]: train_loss_raw=1.4635, running_loss=1.5415, LR=0.000100
[2025-08-10 14:20:44,882][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021864] [Batch 03404/03692] [00:30:26/00:02:34, 0.536s/it]: train_loss_raw=1.5324, running_loss=1.5399, LR=0.000100
[2025-08-10 14:20:51,318][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021876] [Batch 03416/03692] [00:30:32/00:02:28, 0.536s/it]: train_loss_raw=1.4593, running_loss=1.5381, LR=0.000100
[2025-08-10 14:20:57,717][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021888] [Batch 03428/03692] [00:30:39/00:02:21, 0.536s/it]: train_loss_raw=1.4759, running_loss=1.5368, LR=0.000100
[2025-08-10 14:21:04,151][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021900] [Batch 03440/03692] [00:30:45/00:02:15, 0.536s/it]: train_loss_raw=1.5021, running_loss=1.5333, LR=0.000100
[2025-08-10 14:21:10,773][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021912] [Batch 03452/03692] [00:30:52/00:02:08, 0.537s/it]: train_loss_raw=1.5237, running_loss=1.5314, LR=0.000100
[2025-08-10 14:21:17,171][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021924] [Batch 03464/03692] [00:30:58/00:02:02, 0.537s/it]: train_loss_raw=1.4355, running_loss=1.5300, LR=0.000100
[2025-08-10 14:21:23,632][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021936] [Batch 03476/03692] [00:31:04/00:01:55, 0.537s/it]: train_loss_raw=1.5654, running_loss=1.5332, LR=0.000100
[2025-08-10 14:21:30,042][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021948] [Batch 03488/03692] [00:31:11/00:01:49, 0.537s/it]: train_loss_raw=1.2794, running_loss=1.5287, LR=0.000100
[2025-08-10 14:21:36,540][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021960] [Batch 03500/03692] [00:31:17/00:01:43, 0.537s/it]: train_loss_raw=1.4884, running_loss=1.5285, LR=0.000100
[2025-08-10 14:21:43,113][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021972] [Batch 03512/03692] [00:31:24/00:01:36, 0.537s/it]: train_loss_raw=1.4115, running_loss=1.5263, LR=0.000100
[2025-08-10 14:21:49,680][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021984] [Batch 03524/03692] [00:31:30/00:01:30, 0.537s/it]: train_loss_raw=1.6285, running_loss=1.5279, LR=0.000100
[2025-08-10 14:21:56,192][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021996] [Batch 03536/03692] [00:31:37/00:01:23, 0.537s/it]: train_loss_raw=1.4598, running_loss=1.5269, LR=0.000100
[2025-08-10 14:22:06,983][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022008] [Batch 03548/03692] [00:31:48/00:01:17, 0.538s/it]: train_loss_raw=1.6408, running_loss=1.5283, LR=0.000100
[2025-08-10 14:22:13,449][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022020] [Batch 03560/03692] [00:31:54/00:01:10, 0.538s/it]: train_loss_raw=1.5286, running_loss=1.5296, LR=0.000100
[2025-08-10 14:22:20,053][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022032] [Batch 03572/03692] [00:32:01/00:01:04, 0.538s/it]: train_loss_raw=1.5507, running_loss=1.5332, LR=0.000100
[2025-08-10 14:22:26,623][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022044] [Batch 03584/03692] [00:32:07/00:00:58, 0.538s/it]: train_loss_raw=1.6391, running_loss=1.5330, LR=0.000100
[2025-08-10 14:22:33,049][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022056] [Batch 03596/03692] [00:32:14/00:00:51, 0.538s/it]: train_loss_raw=1.4721, running_loss=1.5344, LR=0.000100
[2025-08-10 14:22:39,459][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022068] [Batch 03608/03692] [00:32:20/00:00:45, 0.538s/it]: train_loss_raw=1.6613, running_loss=1.5336, LR=0.000100
[2025-08-10 14:22:45,941][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022080] [Batch 03620/03692] [00:32:27/00:00:38, 0.538s/it]: train_loss_raw=1.5105, running_loss=1.5319, LR=0.000100
[2025-08-10 14:22:52,497][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022092] [Batch 03632/03692] [00:32:33/00:00:32, 0.538s/it]: train_loss_raw=1.4940, running_loss=1.5314, LR=0.000100
[2025-08-10 14:22:59,013][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022104] [Batch 03644/03692] [00:32:40/00:00:25, 0.538s/it]: train_loss_raw=1.4411, running_loss=1.5290, LR=0.000100
[2025-08-10 14:23:05,411][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022116] [Batch 03656/03692] [00:32:46/00:00:19, 0.538s/it]: train_loss_raw=1.4722, running_loss=1.5311, LR=0.000100
[2025-08-10 14:23:11,782][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022128] [Batch 03668/03692] [00:32:53/00:00:12, 0.538s/it]: train_loss_raw=1.5423, running_loss=1.5293, LR=0.000100
[2025-08-10 14:23:18,219][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022140] [Batch 03680/03692] [00:32:59/00:00:06, 0.538s/it]: train_loss_raw=1.5018, running_loss=1.5261, LR=0.000100
[2025-08-10 14:23:51,348][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022152] [Batch 03692/03692] [00:33:32/00:00:00, 0.545s/it]: train_loss_raw=1.6417, running_loss=1.5261, LR=0.000100
[2025-08-10 14:23:56,406][__main__][INFO] - [VALIDATION] [Epoch 05/29] Starting validation.
[2025-08-10 14:24:32,519][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 022153] [Batch 00011/00025] [00:00:36/00:00:39, 3.009s/it]
[2025-08-10 14:24:51,188][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 022153] [Batch 00023/00025] [00:00:54/00:00:02, 2.283s/it]
[2025-08-10 14:24:52,345][__main__][INFO] - [VALIDATION] [Epoch 05/29] train_loss=1.52605, valid_loss=1.42565
[2025-08-10 14:24:52,345][__main__][INFO] - [VALIDATION] [Epoch 05/29] Metrics:
[2025-08-10 14:24:52,346][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_er      0.609
[2025-08-10 14:24:52,346][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_prec    0.119
[2025-08-10 14:24:52,346][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_recall  0.124
[2025-08-10 14:24:52,346][__main__][INFO] - [VALIDATION] [Epoch 05/29] - pep_recall 0.072
[2025-08-10 14:24:52,349][__main__][INFO] - [TRAIN] [Epoch 05/29] Epoch complete, total time 03:28:51, remaining time 13:55:26, 00:34:48 per epoch
[2025-08-10 14:24:58,669][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022164] [Batch 00012/03692] [00:00:06/00:30:53, 0.504s/it]: train_loss_raw=1.6443, running_loss=1.4362, LR=0.000100
[2025-08-10 14:25:05,144][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022176] [Batch 00024/03692] [00:00:12/00:31:53, 0.522s/it]: train_loss_raw=1.4468, running_loss=1.4436, LR=0.000100
[2025-08-10 14:25:11,684][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022188] [Batch 00036/03692] [00:00:19/00:32:15, 0.529s/it]: train_loss_raw=1.4665, running_loss=1.4465, LR=0.000100
[2025-08-10 14:25:18,209][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022200] [Batch 00048/03692] [00:00:25/00:32:22, 0.533s/it]: train_loss_raw=1.4876, running_loss=1.4515, LR=0.000100
[2025-08-10 14:25:24,757][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022212] [Batch 00060/03692] [00:00:32/00:32:25, 0.536s/it]: train_loss_raw=1.6200, running_loss=1.4559, LR=0.000100
[2025-08-10 14:25:31,326][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022224] [Batch 00072/03692] [00:00:38/00:32:25, 0.538s/it]: train_loss_raw=1.6503, running_loss=1.4646, LR=0.000100
[2025-08-10 14:25:37,886][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022236] [Batch 00084/03692] [00:00:45/00:32:24, 0.539s/it]: train_loss_raw=1.5362, running_loss=1.4691, LR=0.000100
[2025-08-10 14:25:44,412][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022248] [Batch 00096/03692] [00:00:51/00:32:19, 0.539s/it]: train_loss_raw=1.4720, running_loss=1.4737, LR=0.000100
[2025-08-10 14:25:50,844][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022260] [Batch 00108/03692] [00:00:58/00:32:12, 0.539s/it]: train_loss_raw=1.4484, running_loss=1.4792, LR=0.000100
[2025-08-10 14:25:56,894][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022272] [Batch 00120/03692] [00:01:04/00:31:53, 0.536s/it]: train_loss_raw=1.5648, running_loss=1.4845, LR=0.000100
[2025-08-10 14:26:03,043][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022284] [Batch 00132/03692] [00:01:10/00:31:39, 0.533s/it]: train_loss_raw=1.5167, running_loss=1.4919, LR=0.000100
[2025-08-10 14:26:09,510][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022296] [Batch 00144/03692] [00:01:16/00:31:34, 0.534s/it]: train_loss_raw=1.5825, running_loss=1.4948, LR=0.000100
[2025-08-10 14:26:16,096][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022308] [Batch 00156/03692] [00:01:23/00:31:32, 0.535s/it]: train_loss_raw=1.5584, running_loss=1.4964, LR=0.000100
[2025-08-10 14:26:22,621][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022320] [Batch 00168/03692] [00:01:29/00:31:27, 0.536s/it]: train_loss_raw=1.5233, running_loss=1.4973, LR=0.000100
[2025-08-10 14:26:28,996][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022332] [Batch 00180/03692] [00:01:36/00:31:20, 0.535s/it]: train_loss_raw=1.3841, running_loss=1.4973, LR=0.000100
[2025-08-10 14:26:35,083][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022344] [Batch 00192/03692] [00:01:42/00:31:07, 0.534s/it]: train_loss_raw=1.5572, running_loss=1.5001, LR=0.000100
[2025-08-10 14:26:41,427][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022356] [Batch 00204/03692] [00:01:48/00:31:00, 0.533s/it]: train_loss_raw=1.4820, running_loss=1.5028, LR=0.000100
[2025-08-10 14:26:47,530][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022368] [Batch 00216/03692] [00:01:54/00:30:49, 0.532s/it]: train_loss_raw=1.3916, running_loss=1.5009, LR=0.000100
[2025-08-10 14:26:53,993][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022380] [Batch 00228/03692] [00:02:01/00:30:43, 0.532s/it]: train_loss_raw=1.5075, running_loss=1.5043, LR=0.000100
[2025-08-10 14:27:00,540][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022392] [Batch 00240/03692] [00:02:07/00:30:39, 0.533s/it]: train_loss_raw=1.4256, running_loss=1.5051, LR=0.000100
[2025-08-10 14:27:06,625][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022404] [Batch 00252/03692] [00:02:14/00:30:29, 0.532s/it]: train_loss_raw=1.6021, running_loss=1.5014, LR=0.000100
[2025-08-10 14:27:12,908][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022416] [Batch 00264/03692] [00:02:20/00:30:21, 0.531s/it]: train_loss_raw=1.4111, running_loss=1.5016, LR=0.000100
[2025-08-10 14:27:19,379][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022428] [Batch 00276/03692] [00:02:26/00:30:16, 0.532s/it]: train_loss_raw=1.4812, running_loss=1.5006, LR=0.000100
[2025-08-10 14:27:25,902][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022440] [Batch 00288/03692] [00:02:33/00:30:11, 0.532s/it]: train_loss_raw=1.4965, running_loss=1.5008, LR=0.000100
[2025-08-10 14:27:32,461][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022452] [Batch 00300/03692] [00:02:39/00:30:07, 0.533s/it]: train_loss_raw=1.5984, running_loss=1.4978, LR=0.000100
[2025-08-10 14:27:39,014][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022464] [Batch 00312/03692] [00:02:46/00:30:02, 0.533s/it]: train_loss_raw=1.4995, running_loss=1.4983, LR=0.000100
[2025-08-10 14:27:45,134][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022476] [Batch 00324/03692] [00:02:52/00:29:53, 0.532s/it]: train_loss_raw=1.3941, running_loss=1.4954, LR=0.000100
[2025-08-10 14:27:51,161][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022488] [Batch 00336/03692] [00:02:58/00:29:43, 0.531s/it]: train_loss_raw=1.4832, running_loss=1.4941, LR=0.000100
[2025-08-10 14:27:57,478][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022500] [Batch 00348/03692] [00:03:04/00:29:36, 0.531s/it]: train_loss_raw=1.4492, running_loss=1.4970, LR=0.000100
[2025-08-10 14:28:04,022][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022512] [Batch 00360/03692] [00:03:11/00:29:31, 0.532s/it]: train_loss_raw=1.5701, running_loss=1.5030, LR=0.000100
[2025-08-10 14:28:10,384][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022524] [Batch 00372/03692] [00:03:17/00:29:24, 0.532s/it]: train_loss_raw=1.5183, running_loss=1.5007, LR=0.000100
[2025-08-10 14:28:16,917][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022536] [Batch 00384/03692] [00:03:24/00:29:19, 0.532s/it]: train_loss_raw=1.4144, running_loss=1.5040, LR=0.000100
[2025-08-10 14:28:23,142][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022548] [Batch 00396/03692] [00:03:30/00:29:12, 0.532s/it]: train_loss_raw=1.4625, running_loss=1.5011, LR=0.000100
[2025-08-10 14:28:29,220][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022560] [Batch 00408/03692] [00:03:36/00:29:03, 0.531s/it]: train_loss_raw=1.5143, running_loss=1.5042, LR=0.000100
[2025-08-10 14:28:35,345][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022572] [Batch 00420/03692] [00:03:42/00:28:55, 0.530s/it]: train_loss_raw=1.4043, running_loss=1.5004, LR=0.000100
[2025-08-10 14:28:41,463][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022584] [Batch 00432/03692] [00:03:48/00:28:46, 0.530s/it]: train_loss_raw=1.5142, running_loss=1.4992, LR=0.000100
[2025-08-10 14:28:47,961][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022596] [Batch 00444/03692] [00:03:55/00:28:41, 0.530s/it]: train_loss_raw=1.4050, running_loss=1.4981, LR=0.000100
[2025-08-10 14:28:54,476][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022608] [Batch 00456/03692] [00:04:01/00:28:36, 0.530s/it]: train_loss_raw=1.5382, running_loss=1.5024, LR=0.000100
[2025-08-10 14:29:00,592][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022620] [Batch 00468/03692] [00:04:07/00:28:28, 0.530s/it]: train_loss_raw=1.4905, running_loss=1.5028, LR=0.000100
[2025-08-10 14:29:06,605][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022632] [Batch 00480/03692] [00:04:13/00:28:19, 0.529s/it]: train_loss_raw=1.5727, running_loss=1.5009, LR=0.000100
[2025-08-10 14:29:12,639][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022644] [Batch 00492/03692] [00:04:20/00:28:11, 0.528s/it]: train_loss_raw=1.4986, running_loss=1.5039, LR=0.000100
[2025-08-10 14:29:18,759][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022656] [Batch 00504/03692] [00:04:26/00:28:03, 0.528s/it]: train_loss_raw=1.5316, running_loss=1.5038, LR=0.000100
[2025-08-10 14:29:24,835][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022668] [Batch 00516/03692] [00:04:32/00:27:55, 0.528s/it]: train_loss_raw=1.5615, running_loss=1.5043, LR=0.000100
[2025-08-10 14:29:30,835][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022680] [Batch 00528/03692] [00:04:38/00:27:47, 0.527s/it]: train_loss_raw=1.5696, running_loss=1.5017, LR=0.000100
[2025-08-10 14:29:37,352][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022692] [Batch 00540/03692] [00:04:44/00:27:41, 0.527s/it]: train_loss_raw=1.5103, running_loss=1.5041, LR=0.000100
[2025-08-10 14:29:43,639][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022704] [Batch 00552/03692] [00:04:51/00:27:35, 0.527s/it]: train_loss_raw=1.5497, running_loss=1.5034, LR=0.000100
[2025-08-10 14:29:49,655][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022716] [Batch 00564/03692] [00:04:57/00:27:27, 0.527s/it]: train_loss_raw=1.4167, running_loss=1.4996, LR=0.000100
[2025-08-10 14:29:55,767][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022728] [Batch 00576/03692] [00:05:03/00:27:19, 0.526s/it]: train_loss_raw=1.5063, running_loss=1.4998, LR=0.000100
[2025-08-10 14:30:01,978][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022740] [Batch 00588/03692] [00:05:09/00:27:13, 0.526s/it]: train_loss_raw=1.4336, running_loss=1.5025, LR=0.000100
[2025-08-10 14:30:08,531][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022752] [Batch 00600/03692] [00:05:15/00:27:07, 0.527s/it]: train_loss_raw=1.4807, running_loss=1.5052, LR=0.000100
[2025-08-10 14:30:15,039][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022764] [Batch 00612/03692] [00:05:22/00:27:02, 0.527s/it]: train_loss_raw=1.4569, running_loss=1.5012, LR=0.000100
[2025-08-10 14:30:21,598][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022776] [Batch 00624/03692] [00:05:28/00:26:57, 0.527s/it]: train_loss_raw=1.6008, running_loss=1.5023, LR=0.000100
[2025-08-10 14:30:28,144][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022788] [Batch 00636/03692] [00:05:35/00:26:52, 0.528s/it]: train_loss_raw=1.4123, running_loss=1.5015, LR=0.000100
[2025-08-10 14:30:34,666][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022800] [Batch 00648/03692] [00:05:42/00:26:46, 0.528s/it]: train_loss_raw=1.4689, running_loss=1.4974, LR=0.000100
[2025-08-10 14:30:41,305][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022812] [Batch 00660/03692] [00:05:48/00:26:41, 0.528s/it]: train_loss_raw=1.6576, running_loss=1.5019, LR=0.000100
[2025-08-10 14:30:48,074][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022824] [Batch 00672/03692] [00:05:55/00:26:37, 0.529s/it]: train_loss_raw=1.3813, running_loss=1.5022, LR=0.000100
[2025-08-10 14:30:54,668][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022836] [Batch 00684/03692] [00:06:02/00:26:32, 0.529s/it]: train_loss_raw=1.5824, running_loss=1.5030, LR=0.000100
[2025-08-10 14:31:01,184][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022848] [Batch 00696/03692] [00:06:08/00:26:26, 0.530s/it]: train_loss_raw=1.4241, running_loss=1.4974, LR=0.000100
[2025-08-10 14:31:07,792][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022860] [Batch 00708/03692] [00:06:15/00:26:21, 0.530s/it]: train_loss_raw=1.5212, running_loss=1.4959, LR=0.000100
[2025-08-10 14:31:14,161][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022872] [Batch 00720/03692] [00:06:21/00:26:14, 0.530s/it]: train_loss_raw=1.5854, running_loss=1.4962, LR=0.000100
[2025-08-10 14:31:20,240][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022884] [Batch 00732/03692] [00:06:27/00:26:07, 0.530s/it]: train_loss_raw=1.5556, running_loss=1.4939, LR=0.000100
[2025-08-10 14:31:26,738][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022896] [Batch 00744/03692] [00:06:34/00:26:01, 0.530s/it]: train_loss_raw=1.4335, running_loss=1.4903, LR=0.000100
[2025-08-10 14:31:33,221][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022908] [Batch 00756/03692] [00:06:40/00:25:55, 0.530s/it]: train_loss_raw=1.4148, running_loss=1.4883, LR=0.000100
[2025-08-10 14:31:39,289][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022920] [Batch 00768/03692] [00:06:46/00:25:48, 0.530s/it]: train_loss_raw=1.3935, running_loss=1.4879, LR=0.000100
[2025-08-10 14:31:45,809][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022932] [Batch 00780/03692] [00:06:53/00:25:42, 0.530s/it]: train_loss_raw=1.6009, running_loss=1.4875, LR=0.000100
[2025-08-10 14:31:52,236][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022944] [Batch 00792/03692] [00:06:59/00:25:36, 0.530s/it]: train_loss_raw=1.5585, running_loss=1.4823, LR=0.000100
[2025-08-10 14:31:58,516][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022956] [Batch 00804/03692] [00:07:05/00:25:29, 0.530s/it]: train_loss_raw=1.4622, running_loss=1.4874, LR=0.000100
[2025-08-10 14:32:04,892][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022968] [Batch 00816/03692] [00:07:12/00:25:23, 0.530s/it]: train_loss_raw=1.4845, running_loss=1.4890, LR=0.000100
[2025-08-10 14:32:10,961][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022980] [Batch 00828/03692] [00:07:18/00:25:16, 0.529s/it]: train_loss_raw=1.5090, running_loss=1.4895, LR=0.000100
[2025-08-10 14:32:17,076][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022992] [Batch 00840/03692] [00:07:24/00:25:09, 0.529s/it]: train_loss_raw=1.6566, running_loss=1.4936, LR=0.000100
[2025-08-10 14:32:23,154][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023004] [Batch 00852/03692] [00:07:30/00:25:01, 0.529s/it]: train_loss_raw=1.4996, running_loss=1.4920, LR=0.000100
[2025-08-10 14:32:29,655][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023016] [Batch 00864/03692] [00:07:37/00:24:55, 0.529s/it]: train_loss_raw=1.4749, running_loss=1.4886, LR=0.000100
[2025-08-10 14:32:36,182][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023028] [Batch 00876/03692] [00:07:43/00:24:50, 0.529s/it]: train_loss_raw=1.5355, running_loss=1.4899, LR=0.000100
[2025-08-10 14:32:42,719][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023040] [Batch 00888/03692] [00:07:50/00:24:44, 0.529s/it]: train_loss_raw=1.6672, running_loss=1.4916, LR=0.000100
[2025-08-10 14:32:49,067][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023052] [Batch 00900/03692] [00:07:56/00:24:38, 0.529s/it]: train_loss_raw=1.4905, running_loss=1.4943, LR=0.000100
[2025-08-10 14:32:55,079][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023064] [Batch 00912/03692] [00:08:02/00:24:30, 0.529s/it]: train_loss_raw=1.4435, running_loss=1.4913, LR=0.000100
[2025-08-10 14:33:01,376][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023076] [Batch 00924/03692] [00:08:08/00:24:24, 0.529s/it]: train_loss_raw=1.4696, running_loss=1.4965, LR=0.000100
[2025-08-10 14:33:07,652][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023088] [Batch 00936/03692] [00:08:15/00:24:17, 0.529s/it]: train_loss_raw=1.4953, running_loss=1.4976, LR=0.000100
[2025-08-10 14:33:13,709][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023100] [Batch 00948/03692] [00:08:21/00:24:10, 0.529s/it]: train_loss_raw=1.3707, running_loss=1.4962, LR=0.000100
[2025-08-10 14:33:19,734][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023112] [Batch 00960/03692] [00:08:27/00:24:03, 0.528s/it]: train_loss_raw=1.5578, running_loss=1.4968, LR=0.000100
[2025-08-10 14:33:25,839][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023124] [Batch 00972/03692] [00:08:33/00:23:56, 0.528s/it]: train_loss_raw=1.5740, running_loss=1.4981, LR=0.000100
[2025-08-10 14:33:32,083][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023136] [Batch 00984/03692] [00:08:39/00:23:49, 0.528s/it]: train_loss_raw=1.6319, running_loss=1.4980, LR=0.000100
[2025-08-10 14:33:38,512][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023148] [Batch 00996/03692] [00:08:45/00:23:43, 0.528s/it]: train_loss_raw=1.5688, running_loss=1.4964, LR=0.000100
[2025-08-10 14:33:45,043][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023160] [Batch 01008/03692] [00:08:52/00:23:37, 0.528s/it]: train_loss_raw=1.6182, running_loss=1.4973, LR=0.000100
[2025-08-10 14:33:51,461][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023172] [Batch 01020/03692] [00:08:58/00:23:31, 0.528s/it]: train_loss_raw=1.4472, running_loss=1.4973, LR=0.000100
[2025-08-10 14:33:57,996][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023184] [Batch 01032/03692] [00:09:05/00:23:25, 0.528s/it]: train_loss_raw=1.5170, running_loss=1.4974, LR=0.000100
[2025-08-10 14:34:04,561][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023196] [Batch 01044/03692] [00:09:11/00:23:19, 0.529s/it]: train_loss_raw=1.4448, running_loss=1.4957, LR=0.000100
[2025-08-10 14:34:10,883][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023208] [Batch 01056/03692] [00:09:18/00:23:13, 0.529s/it]: train_loss_raw=1.4866, running_loss=1.4941, LR=0.000100
[2025-08-10 14:34:16,920][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023220] [Batch 01068/03692] [00:09:24/00:23:06, 0.528s/it]: train_loss_raw=1.3945, running_loss=1.4921, LR=0.000100
[2025-08-10 14:34:22,983][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023232] [Batch 01080/03692] [00:09:30/00:22:59, 0.528s/it]: train_loss_raw=1.4808, running_loss=1.4905, LR=0.000100
[2025-08-10 14:34:28,996][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023244] [Batch 01092/03692] [00:09:36/00:22:52, 0.528s/it]: train_loss_raw=1.5034, running_loss=1.4886, LR=0.000100
[2025-08-10 14:34:35,047][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023256] [Batch 01104/03692] [00:09:42/00:22:45, 0.528s/it]: train_loss_raw=1.4966, running_loss=1.4930, LR=0.000100
[2025-08-10 14:34:41,370][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023268] [Batch 01116/03692] [00:09:48/00:22:38, 0.528s/it]: train_loss_raw=1.4508, running_loss=1.4919, LR=0.000100
[2025-08-10 14:34:47,597][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023280] [Batch 01128/03692] [00:09:54/00:22:32, 0.527s/it]: train_loss_raw=1.5170, running_loss=1.4882, LR=0.000100
[2025-08-10 14:34:53,857][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023292] [Batch 01140/03692] [00:10:01/00:22:25, 0.527s/it]: train_loss_raw=1.5412, running_loss=1.4867, LR=0.000100
[2025-08-10 14:34:59,985][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023304] [Batch 01152/03692] [00:10:07/00:22:19, 0.527s/it]: train_loss_raw=1.5255, running_loss=1.4826, LR=0.000100
[2025-08-10 14:35:06,055][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023316] [Batch 01164/03692] [00:10:13/00:22:12, 0.527s/it]: train_loss_raw=1.4961, running_loss=1.4884, LR=0.000100
[2025-08-10 14:35:12,088][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023328] [Batch 01176/03692] [00:10:19/00:22:05, 0.527s/it]: train_loss_raw=1.4737, running_loss=1.4879, LR=0.000100
[2025-08-10 14:35:18,230][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023340] [Batch 01188/03692] [00:10:25/00:21:58, 0.527s/it]: train_loss_raw=1.4602, running_loss=1.4884, LR=0.000100
[2025-08-10 14:35:24,588][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023352] [Batch 01200/03692] [00:10:31/00:21:52, 0.527s/it]: train_loss_raw=1.4895, running_loss=1.4936, LR=0.000100
[2025-08-10 14:35:31,133][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023364] [Batch 01212/03692] [00:10:38/00:21:46, 0.527s/it]: train_loss_raw=1.4662, running_loss=1.4955, LR=0.000100
[2025-08-10 14:35:37,665][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023376] [Batch 01224/03692] [00:10:45/00:21:40, 0.527s/it]: train_loss_raw=1.5089, running_loss=1.4928, LR=0.000100
[2025-08-10 14:35:44,041][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023388] [Batch 01236/03692] [00:10:51/00:21:34, 0.527s/it]: train_loss_raw=1.4366, running_loss=1.4903, LR=0.000100
[2025-08-10 14:35:50,462][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023400] [Batch 01248/03692] [00:10:57/00:21:28, 0.527s/it]: train_loss_raw=1.5930, running_loss=1.4904, LR=0.000100
[2025-08-10 14:35:57,012][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023412] [Batch 01260/03692] [00:11:04/00:21:22, 0.527s/it]: train_loss_raw=1.5223, running_loss=1.4895, LR=0.000100
[2025-08-10 14:36:03,551][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023424] [Batch 01272/03692] [00:11:10/00:21:16, 0.527s/it]: train_loss_raw=1.5449, running_loss=1.4905, LR=0.000100
[2025-08-10 14:36:10,084][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023436] [Batch 01284/03692] [00:11:17/00:21:10, 0.528s/it]: train_loss_raw=1.4737, running_loss=1.4882, LR=0.000100
[2025-08-10 14:36:16,082][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023448] [Batch 01296/03692] [00:11:23/00:21:03, 0.527s/it]: train_loss_raw=1.4281, running_loss=1.4859, LR=0.000100
[2025-08-10 14:36:22,459][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023460] [Batch 01308/03692] [00:11:29/00:20:57, 0.527s/it]: train_loss_raw=1.5392, running_loss=1.4865, LR=0.000100
[2025-08-10 14:36:28,978][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023472] [Batch 01320/03692] [00:11:36/00:20:51, 0.528s/it]: train_loss_raw=1.5736, running_loss=1.4871, LR=0.000100
[2025-08-10 14:36:35,494][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023484] [Batch 01332/03692] [00:11:42/00:20:45, 0.528s/it]: train_loss_raw=1.5399, running_loss=1.4873, LR=0.000100
[2025-08-10 14:36:42,055][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023496] [Batch 01344/03692] [00:11:49/00:20:39, 0.528s/it]: train_loss_raw=1.4063, running_loss=1.4883, LR=0.000100
[2025-08-10 14:36:48,547][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023508] [Batch 01356/03692] [00:11:55/00:20:33, 0.528s/it]: train_loss_raw=1.3630, running_loss=1.4837, LR=0.000100
[2025-08-10 14:36:54,985][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023520] [Batch 01368/03692] [00:12:02/00:20:27, 0.528s/it]: train_loss_raw=1.4693, running_loss=1.4831, LR=0.000100
[2025-08-10 14:37:01,520][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023532] [Batch 01380/03692] [00:12:08/00:20:21, 0.528s/it]: train_loss_raw=1.5732, running_loss=1.4812, LR=0.000100
[2025-08-10 14:37:08,119][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023544] [Batch 01392/03692] [00:12:15/00:20:15, 0.528s/it]: train_loss_raw=1.3570, running_loss=1.4794, LR=0.000100
[2025-08-10 14:37:14,717][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023556] [Batch 01404/03692] [00:12:22/00:20:09, 0.529s/it]: train_loss_raw=1.5391, running_loss=1.4772, LR=0.000100
[2025-08-10 14:37:21,322][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023568] [Batch 01416/03692] [00:12:28/00:20:03, 0.529s/it]: train_loss_raw=1.4006, running_loss=1.4768, LR=0.000100
[2025-08-10 14:37:27,795][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023580] [Batch 01428/03692] [00:12:35/00:19:57, 0.529s/it]: train_loss_raw=1.5393, running_loss=1.4744, LR=0.000100
[2025-08-10 14:37:34,328][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023592] [Batch 01440/03692] [00:12:41/00:19:51, 0.529s/it]: train_loss_raw=1.3372, running_loss=1.4719, LR=0.000100
[2025-08-10 14:37:40,878][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023604] [Batch 01452/03692] [00:12:48/00:19:45, 0.529s/it]: train_loss_raw=1.4724, running_loss=1.4700, LR=0.000100
[2025-08-10 14:37:47,422][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023616] [Batch 01464/03692] [00:12:54/00:19:39, 0.529s/it]: train_loss_raw=1.4748, running_loss=1.4731, LR=0.000100
[2025-08-10 14:37:54,039][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023628] [Batch 01476/03692] [00:13:01/00:19:33, 0.529s/it]: train_loss_raw=1.5294, running_loss=1.4705, LR=0.000100
[2025-08-10 14:38:00,590][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023640] [Batch 01488/03692] [00:13:07/00:19:27, 0.530s/it]: train_loss_raw=1.3901, running_loss=1.4718, LR=0.000100
[2025-08-10 14:38:07,200][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023652] [Batch 01500/03692] [00:13:14/00:19:21, 0.530s/it]: train_loss_raw=1.5133, running_loss=1.4739, LR=0.000100
[2025-08-10 14:38:13,346][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023664] [Batch 01512/03692] [00:13:20/00:19:14, 0.530s/it]: train_loss_raw=1.3168, running_loss=1.4734, LR=0.000100
[2025-08-10 14:38:19,790][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023676] [Batch 01524/03692] [00:13:27/00:19:08, 0.530s/it]: train_loss_raw=1.4800, running_loss=1.4748, LR=0.000100
[2025-08-10 14:38:50,258][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023688] [Batch 01536/03692] [00:13:57/00:19:35, 0.545s/it]: train_loss_raw=1.5744, running_loss=1.4768, LR=0.000100
[2025-08-10 14:38:56,607][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023700] [Batch 01548/03692] [00:14:03/00:19:28, 0.545s/it]: train_loss_raw=1.4892, running_loss=1.4752, LR=0.000100
[2025-08-10 14:39:02,944][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023712] [Batch 01560/03692] [00:14:10/00:19:22, 0.545s/it]: train_loss_raw=1.5541, running_loss=1.4793, LR=0.000100
[2025-08-10 14:39:09,018][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023724] [Batch 01572/03692] [00:14:16/00:19:14, 0.545s/it]: train_loss_raw=1.4430, running_loss=1.4782, LR=0.000100
[2025-08-10 14:39:15,104][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023736] [Batch 01584/03692] [00:14:22/00:19:07, 0.544s/it]: train_loss_raw=1.4574, running_loss=1.4782, LR=0.000100
[2025-08-10 14:39:21,159][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023748] [Batch 01596/03692] [00:14:28/00:19:00, 0.544s/it]: train_loss_raw=1.5479, running_loss=1.4750, LR=0.000100
[2025-08-10 14:39:27,257][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023760] [Batch 01608/03692] [00:14:34/00:18:53, 0.544s/it]: train_loss_raw=1.5079, running_loss=1.4824, LR=0.000100
[2025-08-10 14:39:33,329][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023772] [Batch 01620/03692] [00:14:40/00:18:46, 0.544s/it]: train_loss_raw=1.4057, running_loss=1.4777, LR=0.000100
[2025-08-10 14:39:39,460][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023784] [Batch 01632/03692] [00:14:46/00:18:39, 0.543s/it]: train_loss_raw=1.4125, running_loss=1.4749, LR=0.000100
[2025-08-10 14:39:45,581][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023796] [Batch 01644/03692] [00:14:52/00:18:32, 0.543s/it]: train_loss_raw=1.5672, running_loss=1.4755, LR=0.000100
[2025-08-10 14:39:51,821][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023808] [Batch 01656/03692] [00:14:59/00:18:25, 0.543s/it]: train_loss_raw=1.6009, running_loss=1.4769, LR=0.000100
[2025-08-10 14:39:58,340][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023820] [Batch 01668/03692] [00:15:05/00:18:19, 0.543s/it]: train_loss_raw=1.4077, running_loss=1.4758, LR=0.000100
[2025-08-10 14:40:04,891][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023832] [Batch 01680/03692] [00:15:12/00:18:12, 0.543s/it]: train_loss_raw=1.4713, running_loss=1.4770, LR=0.000100
[2025-08-10 14:40:11,003][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023844] [Batch 01692/03692] [00:15:18/00:18:05, 0.543s/it]: train_loss_raw=1.5208, running_loss=1.4772, LR=0.000100
[2025-08-10 14:40:17,299][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023856] [Batch 01704/03692] [00:15:24/00:17:58, 0.543s/it]: train_loss_raw=1.5357, running_loss=1.4747, LR=0.000100
[2025-08-10 14:40:23,582][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023868] [Batch 01716/03692] [00:15:30/00:17:52, 0.543s/it]: train_loss_raw=1.5375, running_loss=1.4721, LR=0.000100
[2025-08-10 14:40:29,601][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023880] [Batch 01728/03692] [00:15:36/00:17:44, 0.542s/it]: train_loss_raw=1.3450, running_loss=1.4711, LR=0.000100
[2025-08-10 14:40:35,649][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023892] [Batch 01740/03692] [00:15:43/00:17:37, 0.542s/it]: train_loss_raw=1.4052, running_loss=1.4696, LR=0.000100
[2025-08-10 14:40:41,911][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023904] [Batch 01752/03692] [00:15:49/00:17:31, 0.542s/it]: train_loss_raw=1.3731, running_loss=1.4696, LR=0.000100
[2025-08-10 14:40:48,456][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023916] [Batch 01764/03692] [00:15:55/00:17:24, 0.542s/it]: train_loss_raw=1.5969, running_loss=1.4731, LR=0.000100
[2025-08-10 14:40:54,923][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023928] [Batch 01776/03692] [00:16:02/00:17:18, 0.542s/it]: train_loss_raw=1.5757, running_loss=1.4739, LR=0.000100
[2025-08-10 14:41:01,608][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023940] [Batch 01788/03692] [00:16:08/00:17:11, 0.542s/it]: train_loss_raw=1.4411, running_loss=1.4711, LR=0.000100
[2025-08-10 14:41:08,160][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023952] [Batch 01800/03692] [00:16:15/00:17:05, 0.542s/it]: train_loss_raw=1.5001, running_loss=1.4699, LR=0.000100
[2025-08-10 14:41:14,345][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023964] [Batch 01812/03692] [00:16:21/00:16:58, 0.542s/it]: train_loss_raw=1.4863, running_loss=1.4715, LR=0.000100
[2025-08-10 14:41:20,566][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023976] [Batch 01824/03692] [00:16:27/00:16:51, 0.542s/it]: train_loss_raw=1.4396, running_loss=1.4689, LR=0.000100
[2025-08-10 14:41:26,911][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023988] [Batch 01836/03692] [00:16:34/00:16:45, 0.542s/it]: train_loss_raw=1.5789, running_loss=1.4718, LR=0.000100
[2025-08-10 14:41:32,963][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024000] [Batch 01848/03692] [00:16:40/00:16:38, 0.541s/it]: train_loss_raw=1.6147, running_loss=1.4720, LR=0.000100
[2025-08-10 14:41:43,302][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024012] [Batch 01860/03692] [00:16:50/00:16:35, 0.543s/it]: train_loss_raw=1.6057, running_loss=1.4747, LR=0.000100
[2025-08-10 14:41:49,743][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024024] [Batch 01872/03692] [00:16:57/00:16:28, 0.543s/it]: train_loss_raw=1.4052, running_loss=1.4693, LR=0.000100
[2025-08-10 14:41:56,283][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024036] [Batch 01884/03692] [00:17:03/00:16:22, 0.543s/it]: train_loss_raw=1.4929, running_loss=1.4684, LR=0.000100
[2025-08-10 14:42:02,828][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024048] [Batch 01896/03692] [00:17:10/00:16:15, 0.543s/it]: train_loss_raw=1.5058, running_loss=1.4721, LR=0.000100
[2025-08-10 14:42:09,400][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024060] [Batch 01908/03692] [00:17:16/00:16:09, 0.543s/it]: train_loss_raw=1.3858, running_loss=1.4687, LR=0.000100
[2025-08-10 14:42:15,797][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024072] [Batch 01920/03692] [00:17:23/00:16:02, 0.543s/it]: train_loss_raw=1.3182, running_loss=1.4698, LR=0.000100
[2025-08-10 14:42:22,392][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024084] [Batch 01932/03692] [00:17:29/00:15:56, 0.543s/it]: train_loss_raw=1.4738, running_loss=1.4740, LR=0.000100
[2025-08-10 14:42:28,892][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024096] [Batch 01944/03692] [00:17:36/00:15:49, 0.543s/it]: train_loss_raw=1.2986, running_loss=1.4669, LR=0.000100
[2025-08-10 14:42:35,475][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024108] [Batch 01956/03692] [00:17:42/00:15:43, 0.543s/it]: train_loss_raw=1.5348, running_loss=1.4690, LR=0.000100
[2025-08-10 14:42:42,026][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024120] [Batch 01968/03692] [00:17:49/00:15:36, 0.543s/it]: train_loss_raw=1.4110, running_loss=1.4659, LR=0.000100
[2025-08-10 14:42:47,991][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024132] [Batch 01980/03692] [00:17:55/00:15:29, 0.543s/it]: train_loss_raw=1.4636, running_loss=1.4608, LR=0.000100
[2025-08-10 14:42:53,942][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024144] [Batch 01992/03692] [00:18:01/00:15:22, 0.543s/it]: train_loss_raw=1.5606, running_loss=1.4582, LR=0.000100
[2025-08-10 14:43:00,019][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024156] [Batch 02004/03692] [00:18:07/00:15:15, 0.543s/it]: train_loss_raw=1.3975, running_loss=1.4565, LR=0.000100
[2025-08-10 14:43:06,086][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024168] [Batch 02016/03692] [00:18:13/00:15:09, 0.542s/it]: train_loss_raw=1.4777, running_loss=1.4527, LR=0.000100
[2025-08-10 14:43:12,163][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024180] [Batch 02028/03692] [00:18:19/00:15:02, 0.542s/it]: train_loss_raw=1.3822, running_loss=1.4531, LR=0.000100
[2025-08-10 14:43:18,245][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024192] [Batch 02040/03692] [00:18:25/00:14:55, 0.542s/it]: train_loss_raw=1.6145, running_loss=1.4580, LR=0.000100
[2025-08-10 14:43:24,297][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024204] [Batch 02052/03692] [00:18:31/00:14:48, 0.542s/it]: train_loss_raw=1.4953, running_loss=1.4574, LR=0.000100
[2025-08-10 14:43:30,473][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024216] [Batch 02064/03692] [00:18:37/00:14:41, 0.542s/it]: train_loss_raw=1.5136, running_loss=1.4603, LR=0.000100
[2025-08-10 14:43:36,582][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024228] [Batch 02076/03692] [00:18:43/00:14:34, 0.541s/it]: train_loss_raw=1.5194, running_loss=1.4573, LR=0.000100
[2025-08-10 14:43:42,604][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024240] [Batch 02088/03692] [00:18:49/00:14:28, 0.541s/it]: train_loss_raw=1.3285, running_loss=1.4600, LR=0.000100
[2025-08-10 14:43:48,690][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024252] [Batch 02100/03692] [00:18:56/00:14:21, 0.541s/it]: train_loss_raw=1.5314, running_loss=1.4599, LR=0.000100
[2025-08-10 14:43:54,745][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024264] [Batch 02112/03692] [00:19:02/00:14:14, 0.541s/it]: train_loss_raw=1.4333, running_loss=1.4592, LR=0.000100
[2025-08-10 14:44:01,148][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024276] [Batch 02124/03692] [00:19:08/00:14:07, 0.541s/it]: train_loss_raw=1.4640, running_loss=1.4572, LR=0.000100
[2025-08-10 14:44:07,708][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024288] [Batch 02136/03692] [00:19:15/00:14:01, 0.541s/it]: train_loss_raw=1.4900, running_loss=1.4595, LR=0.000100
[2025-08-10 14:44:14,280][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024300] [Batch 02148/03692] [00:19:21/00:13:55, 0.541s/it]: train_loss_raw=1.4292, running_loss=1.4620, LR=0.000100
[2025-08-10 14:44:20,769][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024312] [Batch 02160/03692] [00:19:28/00:13:48, 0.541s/it]: train_loss_raw=1.2744, running_loss=1.4530, LR=0.000100
[2025-08-10 14:44:27,300][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024324] [Batch 02172/03692] [00:19:34/00:13:42, 0.541s/it]: train_loss_raw=1.5114, running_loss=1.4508, LR=0.000100
[2025-08-10 14:44:33,925][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024336] [Batch 02184/03692] [00:19:41/00:13:35, 0.541s/it]: train_loss_raw=1.5282, running_loss=1.4538, LR=0.000100
[2025-08-10 14:44:40,417][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024348] [Batch 02196/03692] [00:19:47/00:13:29, 0.541s/it]: train_loss_raw=1.3428, running_loss=1.4542, LR=0.000100
[2025-08-10 14:44:46,660][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024360] [Batch 02208/03692] [00:19:54/00:13:22, 0.541s/it]: train_loss_raw=1.3419, running_loss=1.4535, LR=0.000100
[2025-08-10 14:44:53,188][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024372] [Batch 02220/03692] [00:20:00/00:13:16, 0.541s/it]: train_loss_raw=1.5801, running_loss=1.4597, LR=0.000100
[2025-08-10 14:44:59,674][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024384] [Batch 02232/03692] [00:20:07/00:13:09, 0.541s/it]: train_loss_raw=1.4801, running_loss=1.4563, LR=0.000100
[2025-08-10 14:45:06,169][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024396] [Batch 02244/03692] [00:20:13/00:13:03, 0.541s/it]: train_loss_raw=1.5327, running_loss=1.4622, LR=0.000100
[2025-08-10 14:45:12,682][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024408] [Batch 02256/03692] [00:20:20/00:12:56, 0.541s/it]: train_loss_raw=1.3749, running_loss=1.4567, LR=0.000100
[2025-08-10 14:45:19,142][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024420] [Batch 02268/03692] [00:20:26/00:12:50, 0.541s/it]: train_loss_raw=1.5093, running_loss=1.4553, LR=0.000100
[2025-08-10 14:45:25,285][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024432] [Batch 02280/03692] [00:20:32/00:12:43, 0.541s/it]: train_loss_raw=1.2755, running_loss=1.4592, LR=0.000100
[2025-08-10 14:45:31,818][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024444] [Batch 02292/03692] [00:20:39/00:12:36, 0.541s/it]: train_loss_raw=1.4949, running_loss=1.4553, LR=0.000100
[2025-08-10 14:45:38,459][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024456] [Batch 02304/03692] [00:20:45/00:12:30, 0.541s/it]: train_loss_raw=1.4288, running_loss=1.4525, LR=0.000100
[2025-08-10 14:45:44,995][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024468] [Batch 02316/03692] [00:20:52/00:12:24, 0.541s/it]: train_loss_raw=1.4260, running_loss=1.4471, LR=0.000100
[2025-08-10 14:45:51,578][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024480] [Batch 02328/03692] [00:20:58/00:12:17, 0.541s/it]: train_loss_raw=1.5193, running_loss=1.4498, LR=0.000100
[2025-08-10 14:45:58,150][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024492] [Batch 02340/03692] [00:21:05/00:12:11, 0.541s/it]: train_loss_raw=1.4581, running_loss=1.4470, LR=0.000100
[2025-08-10 14:46:04,690][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024504] [Batch 02352/03692] [00:21:12/00:12:04, 0.541s/it]: train_loss_raw=1.4298, running_loss=1.4521, LR=0.000100
[2025-08-10 14:46:11,225][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024516] [Batch 02364/03692] [00:21:18/00:11:58, 0.541s/it]: train_loss_raw=1.4144, running_loss=1.4558, LR=0.000100
[2025-08-10 14:46:17,380][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024528] [Batch 02376/03692] [00:21:24/00:11:51, 0.541s/it]: train_loss_raw=1.3782, running_loss=1.4529, LR=0.000100
[2025-08-10 14:46:23,813][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024540] [Batch 02388/03692] [00:21:31/00:11:45, 0.541s/it]: train_loss_raw=1.3975, running_loss=1.4522, LR=0.000100
[2025-08-10 14:46:30,135][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024552] [Batch 02400/03692] [00:21:37/00:11:38, 0.541s/it]: train_loss_raw=1.5342, running_loss=1.4561, LR=0.000100
[2025-08-10 14:46:36,240][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024564] [Batch 02412/03692] [00:21:43/00:11:31, 0.540s/it]: train_loss_raw=1.3704, running_loss=1.4536, LR=0.000100
[2025-08-10 14:46:42,309][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024576] [Batch 02424/03692] [00:21:49/00:11:25, 0.540s/it]: train_loss_raw=1.4514, running_loss=1.4610, LR=0.000100
[2025-08-10 14:46:48,350][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024588] [Batch 02436/03692] [00:21:55/00:11:18, 0.540s/it]: train_loss_raw=1.3598, running_loss=1.4587, LR=0.000100
[2025-08-10 14:46:54,430][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024600] [Batch 02448/03692] [00:22:01/00:11:11, 0.540s/it]: train_loss_raw=1.3753, running_loss=1.4565, LR=0.000100
[2025-08-10 14:47:00,548][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024612] [Batch 02460/03692] [00:22:07/00:11:05, 0.540s/it]: train_loss_raw=1.5201, running_loss=1.4572, LR=0.000100
[2025-08-10 14:47:06,685][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024624] [Batch 02472/03692] [00:22:14/00:10:58, 0.540s/it]: train_loss_raw=1.4307, running_loss=1.4589, LR=0.000100
[2025-08-10 14:47:13,293][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024636] [Batch 02484/03692] [00:22:20/00:10:51, 0.540s/it]: train_loss_raw=1.3954, running_loss=1.4558, LR=0.000100
[2025-08-10 14:47:19,360][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024648] [Batch 02496/03692] [00:22:26/00:10:45, 0.540s/it]: train_loss_raw=1.4333, running_loss=1.4575, LR=0.000100
[2025-08-10 14:47:25,567][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024660] [Batch 02508/03692] [00:22:32/00:10:38, 0.539s/it]: train_loss_raw=1.3991, running_loss=1.4570, LR=0.000100
[2025-08-10 14:47:31,563][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024672] [Batch 02520/03692] [00:22:38/00:10:32, 0.539s/it]: train_loss_raw=1.4407, running_loss=1.4554, LR=0.000100
[2025-08-10 14:47:37,826][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024684] [Batch 02532/03692] [00:22:45/00:10:25, 0.539s/it]: train_loss_raw=1.3808, running_loss=1.4555, LR=0.000100
[2025-08-10 14:47:43,945][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024696] [Batch 02544/03692] [00:22:51/00:10:18, 0.539s/it]: train_loss_raw=1.4037, running_loss=1.4553, LR=0.000100
[2025-08-10 14:47:49,986][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024708] [Batch 02556/03692] [00:22:57/00:10:12, 0.539s/it]: train_loss_raw=1.5222, running_loss=1.4527, LR=0.000100
[2025-08-10 14:47:56,128][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024720] [Batch 02568/03692] [00:23:03/00:10:05, 0.539s/it]: train_loss_raw=1.4449, running_loss=1.4538, LR=0.000100
[2025-08-10 14:48:02,702][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024732] [Batch 02580/03692] [00:23:10/00:09:59, 0.539s/it]: train_loss_raw=1.3529, running_loss=1.4552, LR=0.000100
[2025-08-10 14:48:09,278][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024744] [Batch 02592/03692] [00:23:16/00:09:52, 0.539s/it]: train_loss_raw=1.5214, running_loss=1.4566, LR=0.000100
[2025-08-10 14:48:15,873][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024756] [Batch 02604/03692] [00:23:23/00:09:46, 0.539s/it]: train_loss_raw=1.5910, running_loss=1.4574, LR=0.000100
[2025-08-10 14:48:22,427][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024768] [Batch 02616/03692] [00:23:29/00:09:39, 0.539s/it]: train_loss_raw=1.5308, running_loss=1.4577, LR=0.000100
[2025-08-10 14:48:28,722][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024780] [Batch 02628/03692] [00:23:36/00:09:33, 0.539s/it]: train_loss_raw=1.5121, running_loss=1.4573, LR=0.000100
[2025-08-10 14:48:34,880][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024792] [Batch 02640/03692] [00:23:42/00:09:26, 0.539s/it]: train_loss_raw=1.2955, running_loss=1.4547, LR=0.000100
[2025-08-10 14:48:41,118][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024804] [Batch 02652/03692] [00:23:48/00:09:20, 0.539s/it]: train_loss_raw=1.6260, running_loss=1.4552, LR=0.000100
[2025-08-10 14:48:47,296][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024816] [Batch 02664/03692] [00:23:54/00:09:13, 0.539s/it]: train_loss_raw=1.4111, running_loss=1.4517, LR=0.000100
[2025-08-10 14:48:53,565][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024828] [Batch 02676/03692] [00:24:00/00:09:07, 0.538s/it]: train_loss_raw=1.4450, running_loss=1.4506, LR=0.000100
[2025-08-10 14:48:59,873][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024840] [Batch 02688/03692] [00:24:07/00:09:00, 0.538s/it]: train_loss_raw=1.3577, running_loss=1.4503, LR=0.000100
[2025-08-10 14:49:06,212][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024852] [Batch 02700/03692] [00:24:13/00:08:54, 0.538s/it]: train_loss_raw=1.6075, running_loss=1.4521, LR=0.000100
[2025-08-10 14:49:12,269][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024864] [Batch 02712/03692] [00:24:19/00:08:47, 0.538s/it]: train_loss_raw=1.5813, running_loss=1.4526, LR=0.000100
[2025-08-10 14:49:18,303][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024876] [Batch 02724/03692] [00:24:25/00:08:40, 0.538s/it]: train_loss_raw=1.5239, running_loss=1.4543, LR=0.000100
[2025-08-10 14:49:24,379][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024888] [Batch 02736/03692] [00:24:31/00:08:34, 0.538s/it]: train_loss_raw=1.4398, running_loss=1.4486, LR=0.000100
[2025-08-10 14:49:30,387][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024900] [Batch 02748/03692] [00:24:37/00:08:27, 0.538s/it]: train_loss_raw=1.4725, running_loss=1.4508, LR=0.000100
[2025-08-10 14:49:36,696][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024912] [Batch 02760/03692] [00:24:44/00:08:21, 0.538s/it]: train_loss_raw=1.4093, running_loss=1.4509, LR=0.000100
[2025-08-10 14:49:43,127][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024924] [Batch 02772/03692] [00:24:50/00:08:14, 0.538s/it]: train_loss_raw=1.4261, running_loss=1.4530, LR=0.000100
[2025-08-10 14:49:49,489][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024936] [Batch 02784/03692] [00:24:56/00:08:08, 0.538s/it]: train_loss_raw=1.3481, running_loss=1.4516, LR=0.000100
[2025-08-10 14:49:55,702][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024948] [Batch 02796/03692] [00:25:03/00:08:01, 0.538s/it]: train_loss_raw=1.4718, running_loss=1.4505, LR=0.000100
[2025-08-10 14:50:01,769][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024960] [Batch 02808/03692] [00:25:09/00:07:55, 0.537s/it]: train_loss_raw=1.4423, running_loss=1.4517, LR=0.000100
[2025-08-10 14:50:07,827][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024972] [Batch 02820/03692] [00:25:15/00:07:48, 0.537s/it]: train_loss_raw=1.4675, running_loss=1.4524, LR=0.000100
[2025-08-10 14:50:14,098][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024984] [Batch 02832/03692] [00:25:21/00:07:42, 0.537s/it]: train_loss_raw=1.4902, running_loss=1.4504, LR=0.000100
[2025-08-10 14:50:20,418][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024996] [Batch 02844/03692] [00:25:27/00:07:35, 0.537s/it]: train_loss_raw=1.4434, running_loss=1.4487, LR=0.000100
[2025-08-10 14:50:26,495][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025008] [Batch 02856/03692] [00:25:33/00:07:28, 0.537s/it]: train_loss_raw=1.4976, running_loss=1.4449, LR=0.000100
[2025-08-10 14:50:32,526][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025020] [Batch 02868/03692] [00:25:39/00:07:22, 0.537s/it]: train_loss_raw=1.2295, running_loss=1.4447, LR=0.000100
[2025-08-10 14:50:38,610][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025032] [Batch 02880/03692] [00:25:45/00:07:15, 0.537s/it]: train_loss_raw=1.3956, running_loss=1.4437, LR=0.000100
[2025-08-10 14:50:44,629][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025044] [Batch 02892/03692] [00:25:52/00:07:09, 0.537s/it]: train_loss_raw=1.4238, running_loss=1.4437, LR=0.000100
[2025-08-10 14:50:50,662][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025056] [Batch 02904/03692] [00:25:58/00:07:02, 0.537s/it]: train_loss_raw=1.5140, running_loss=1.4419, LR=0.000100
[2025-08-10 14:50:56,747][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025068] [Batch 02916/03692] [00:26:04/00:06:56, 0.536s/it]: train_loss_raw=1.4464, running_loss=1.4387, LR=0.000100
[2025-08-10 14:51:03,193][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025080] [Batch 02928/03692] [00:26:10/00:06:49, 0.536s/it]: train_loss_raw=1.3630, running_loss=1.4368, LR=0.000100
[2025-08-10 14:51:09,713][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025092] [Batch 02940/03692] [00:26:17/00:06:43, 0.536s/it]: train_loss_raw=1.3832, running_loss=1.4371, LR=0.000100
[2025-08-10 14:51:16,245][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025104] [Batch 02952/03692] [00:26:23/00:06:36, 0.536s/it]: train_loss_raw=1.4015, running_loss=1.4346, LR=0.000100
[2025-08-10 14:51:22,836][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025116] [Batch 02964/03692] [00:26:30/00:06:30, 0.537s/it]: train_loss_raw=1.4399, running_loss=1.4322, LR=0.000100
[2025-08-10 14:51:29,450][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025128] [Batch 02976/03692] [00:26:36/00:06:24, 0.537s/it]: train_loss_raw=1.3541, running_loss=1.4354, LR=0.000100
[2025-08-10 14:51:35,825][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025140] [Batch 02988/03692] [00:26:43/00:06:17, 0.537s/it]: train_loss_raw=1.6085, running_loss=1.4423, LR=0.000100
[2025-08-10 14:51:41,889][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025152] [Batch 03000/03692] [00:26:49/00:06:11, 0.536s/it]: train_loss_raw=1.4440, running_loss=1.4381, LR=0.000100
[2025-08-10 14:51:47,950][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025164] [Batch 03012/03692] [00:26:55/00:06:04, 0.536s/it]: train_loss_raw=1.3667, running_loss=1.4345, LR=0.000100
[2025-08-10 14:51:54,153][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025176] [Batch 03024/03692] [00:27:01/00:05:58, 0.536s/it]: train_loss_raw=1.3431, running_loss=1.4313, LR=0.000100
[2025-08-10 14:52:00,520][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025188] [Batch 03036/03692] [00:27:07/00:05:51, 0.536s/it]: train_loss_raw=1.4101, running_loss=1.4363, LR=0.000100
[2025-08-10 14:52:06,538][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025200] [Batch 03048/03692] [00:27:13/00:05:45, 0.536s/it]: train_loss_raw=1.5670, running_loss=1.4404, LR=0.000100
[2025-08-10 14:52:12,916][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025212] [Batch 03060/03692] [00:27:20/00:05:38, 0.536s/it]: train_loss_raw=1.3969, running_loss=1.4430, LR=0.000100
[2025-08-10 14:52:19,526][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025224] [Batch 03072/03692] [00:27:26/00:05:32, 0.536s/it]: train_loss_raw=1.3558, running_loss=1.4403, LR=0.000100
[2025-08-10 14:52:25,864][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025236] [Batch 03084/03692] [00:27:33/00:05:25, 0.536s/it]: train_loss_raw=1.3560, running_loss=1.4369, LR=0.000100
[2025-08-10 14:52:32,060][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025248] [Batch 03096/03692] [00:27:39/00:05:19, 0.536s/it]: train_loss_raw=1.4708, running_loss=1.4374, LR=0.000100
[2025-08-10 14:52:38,617][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025260] [Batch 03108/03692] [00:27:45/00:05:13, 0.536s/it]: train_loss_raw=1.4199, running_loss=1.4362, LR=0.000100
[2025-08-10 14:52:45,132][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025272] [Batch 03120/03692] [00:27:52/00:05:06, 0.536s/it]: train_loss_raw=1.4687, running_loss=1.4391, LR=0.000100
[2025-08-10 14:52:51,189][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025284] [Batch 03132/03692] [00:27:58/00:05:00, 0.536s/it]: train_loss_raw=1.3949, running_loss=1.4368, LR=0.000100
[2025-08-10 14:52:57,329][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025296] [Batch 03144/03692] [00:28:04/00:04:53, 0.536s/it]: train_loss_raw=1.4272, running_loss=1.4348, LR=0.000100
[2025-08-10 14:53:03,860][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025308] [Batch 03156/03692] [00:28:11/00:04:47, 0.536s/it]: train_loss_raw=1.3897, running_loss=1.4363, LR=0.000100
[2025-08-10 14:53:10,356][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025320] [Batch 03168/03692] [00:28:17/00:04:40, 0.536s/it]: train_loss_raw=1.5013, running_loss=1.4382, LR=0.000100
[2025-08-10 14:53:16,880][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025332] [Batch 03180/03692] [00:28:24/00:04:34, 0.536s/it]: train_loss_raw=1.3793, running_loss=1.4356, LR=0.000100
[2025-08-10 14:53:23,466][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025344] [Batch 03192/03692] [00:28:30/00:04:27, 0.536s/it]: train_loss_raw=1.4495, running_loss=1.4353, LR=0.000100
[2025-08-10 14:53:30,061][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025356] [Batch 03204/03692] [00:28:37/00:04:21, 0.536s/it]: train_loss_raw=1.4410, running_loss=1.4380, LR=0.000100
[2025-08-10 14:53:36,295][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025368] [Batch 03216/03692] [00:28:43/00:04:15, 0.536s/it]: train_loss_raw=1.5787, running_loss=1.4370, LR=0.000100
[2025-08-10 14:53:42,446][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025380] [Batch 03228/03692] [00:28:49/00:04:08, 0.536s/it]: train_loss_raw=1.4612, running_loss=1.4385, LR=0.000100
[2025-08-10 14:53:48,585][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025392] [Batch 03240/03692] [00:28:55/00:04:02, 0.536s/it]: train_loss_raw=1.3438, running_loss=1.4343, LR=0.000100
[2025-08-10 14:53:54,977][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025404] [Batch 03252/03692] [00:29:02/00:03:55, 0.536s/it]: train_loss_raw=1.5180, running_loss=1.4350, LR=0.000100
[2025-08-10 14:54:01,174][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025416] [Batch 03264/03692] [00:29:08/00:03:49, 0.536s/it]: train_loss_raw=1.3517, running_loss=1.4320, LR=0.000100
[2025-08-10 14:54:07,256][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025428] [Batch 03276/03692] [00:29:14/00:03:42, 0.536s/it]: train_loss_raw=1.3774, running_loss=1.4299, LR=0.000100
[2025-08-10 14:54:13,346][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025440] [Batch 03288/03692] [00:29:20/00:03:36, 0.535s/it]: train_loss_raw=1.5473, running_loss=1.4282, LR=0.000100
[2025-08-10 14:54:19,404][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025452] [Batch 03300/03692] [00:29:26/00:03:29, 0.535s/it]: train_loss_raw=1.5442, running_loss=1.4299, LR=0.000100
[2025-08-10 14:54:25,575][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025464] [Batch 03312/03692] [00:29:32/00:03:23, 0.535s/it]: train_loss_raw=1.3733, running_loss=1.4281, LR=0.000100
[2025-08-10 14:54:31,660][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025476] [Batch 03324/03692] [00:29:39/00:03:16, 0.535s/it]: train_loss_raw=1.4041, running_loss=1.4267, LR=0.000100
[2025-08-10 14:54:37,732][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025488] [Batch 03336/03692] [00:29:45/00:03:10, 0.535s/it]: train_loss_raw=1.3485, running_loss=1.4257, LR=0.000100
[2025-08-10 14:54:44,047][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025500] [Batch 03348/03692] [00:29:51/00:03:04, 0.535s/it]: train_loss_raw=1.3537, running_loss=1.4275, LR=0.000100
[2025-08-10 14:54:50,552][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025512] [Batch 03360/03692] [00:29:57/00:02:57, 0.535s/it]: train_loss_raw=1.3998, running_loss=1.4281, LR=0.000100
[2025-08-10 14:54:57,198][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025524] [Batch 03372/03692] [00:30:04/00:02:51, 0.535s/it]: train_loss_raw=1.4860, running_loss=1.4306, LR=0.000100
[2025-08-10 14:55:03,730][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025536] [Batch 03384/03692] [00:30:11/00:02:44, 0.535s/it]: train_loss_raw=1.4756, running_loss=1.4322, LR=0.000100
[2025-08-10 14:55:10,272][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025548] [Batch 03396/03692] [00:30:17/00:02:38, 0.535s/it]: train_loss_raw=1.2887, running_loss=1.4295, LR=0.000100
[2025-08-10 14:55:16,808][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025560] [Batch 03408/03692] [00:30:24/00:02:32, 0.535s/it]: train_loss_raw=1.4852, running_loss=1.4279, LR=0.000100
[2025-08-10 14:55:23,360][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025572] [Batch 03420/03692] [00:30:30/00:02:25, 0.535s/it]: train_loss_raw=1.3952, running_loss=1.4253, LR=0.000100
[2025-08-10 14:55:29,931][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025584] [Batch 03432/03692] [00:30:37/00:02:19, 0.535s/it]: train_loss_raw=1.3658, running_loss=1.4261, LR=0.000100
[2025-08-10 14:55:36,660][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025596] [Batch 03444/03692] [00:30:44/00:02:12, 0.535s/it]: train_loss_raw=1.4478, running_loss=1.4291, LR=0.000100
[2025-08-10 14:55:43,206][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025608] [Batch 03456/03692] [00:30:50/00:02:06, 0.535s/it]: train_loss_raw=1.5400, running_loss=1.4262, LR=0.000100
[2025-08-10 14:55:49,330][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025620] [Batch 03468/03692] [00:30:56/00:01:59, 0.535s/it]: train_loss_raw=1.5467, running_loss=1.4261, LR=0.000100
[2025-08-10 14:55:55,404][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025632] [Batch 03480/03692] [00:31:02/00:01:53, 0.535s/it]: train_loss_raw=1.4715, running_loss=1.4253, LR=0.000100
[2025-08-10 14:56:01,857][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025644] [Batch 03492/03692] [00:31:09/00:01:47, 0.535s/it]: train_loss_raw=1.3461, running_loss=1.4248, LR=0.000100
[2025-08-10 14:56:08,361][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025656] [Batch 03504/03692] [00:31:15/00:01:40, 0.535s/it]: train_loss_raw=1.4210, running_loss=1.4213, LR=0.000100
[2025-08-10 14:56:14,630][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025668] [Batch 03516/03692] [00:31:22/00:01:34, 0.535s/it]: train_loss_raw=1.3622, running_loss=1.4208, LR=0.000100
[2025-08-10 14:56:20,953][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025680] [Batch 03528/03692] [00:31:28/00:01:27, 0.535s/it]: train_loss_raw=1.3059, running_loss=1.4209, LR=0.000100
[2025-08-10 14:56:27,136][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025692] [Batch 03540/03692] [00:31:34/00:01:21, 0.535s/it]: train_loss_raw=1.4352, running_loss=1.4209, LR=0.000100
[2025-08-10 14:56:33,569][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025704] [Batch 03552/03692] [00:31:40/00:01:14, 0.535s/it]: train_loss_raw=1.5120, running_loss=1.4236, LR=0.000100
[2025-08-10 14:56:39,597][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025716] [Batch 03564/03692] [00:31:46/00:01:08, 0.535s/it]: train_loss_raw=1.3996, running_loss=1.4232, LR=0.000100
[2025-08-10 14:56:45,773][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025728] [Batch 03576/03692] [00:31:53/00:01:02, 0.535s/it]: train_loss_raw=1.4523, running_loss=1.4252, LR=0.000100
[2025-08-10 14:56:52,329][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025740] [Batch 03588/03692] [00:31:59/00:00:55, 0.535s/it]: train_loss_raw=1.2859, running_loss=1.4261, LR=0.000100
[2025-08-10 14:56:58,890][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025752] [Batch 03600/03692] [00:32:06/00:00:49, 0.535s/it]: train_loss_raw=1.4787, running_loss=1.4274, LR=0.000100
[2025-08-10 14:57:05,409][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025764] [Batch 03612/03692] [00:32:12/00:00:42, 0.535s/it]: train_loss_raw=1.4136, running_loss=1.4279, LR=0.000100
[2025-08-10 14:57:11,916][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025776] [Batch 03624/03692] [00:32:19/00:00:36, 0.535s/it]: train_loss_raw=1.3880, running_loss=1.4327, LR=0.000100
[2025-08-10 14:57:18,501][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025788] [Batch 03636/03692] [00:32:25/00:00:29, 0.535s/it]: train_loss_raw=1.3660, running_loss=1.4326, LR=0.000100
[2025-08-10 14:57:24,821][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025800] [Batch 03648/03692] [00:32:32/00:00:23, 0.535s/it]: train_loss_raw=1.3619, running_loss=1.4269, LR=0.000100
[2025-08-10 14:57:30,831][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025812] [Batch 03660/03692] [00:32:38/00:00:17, 0.535s/it]: train_loss_raw=1.3202, running_loss=1.4274, LR=0.000100
[2025-08-10 14:57:36,880][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025824] [Batch 03672/03692] [00:32:44/00:00:10, 0.535s/it]: train_loss_raw=1.5765, running_loss=1.4274, LR=0.000100
[2025-08-10 14:57:43,025][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025836] [Batch 03684/03692] [00:32:50/00:00:04, 0.535s/it]: train_loss_raw=1.4368, running_loss=1.4252, LR=0.000100
[2025-08-10 14:57:52,452][__main__][INFO] - [VALIDATION] [Epoch 06/29] Starting validation.
[2025-08-10 14:58:27,304][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 025845] [Batch 00011/00025] [00:00:34/00:00:37, 2.904s/it]
[2025-08-10 14:58:44,886][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 025845] [Batch 00023/00025] [00:00:52/00:00:02, 2.185s/it]
[2025-08-10 14:58:46,144][__main__][INFO] - [VALIDATION] [Epoch 06/29] train_loss=1.42532, valid_loss=1.32480
[2025-08-10 14:58:46,145][__main__][INFO] - [VALIDATION] [Epoch 06/29] Metrics:
[2025-08-10 14:58:46,145][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_er      0.569
[2025-08-10 14:58:46,145][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_prec    0.162
[2025-08-10 14:58:46,145][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_recall  0.167
[2025-08-10 14:58:46,145][__main__][INFO] - [VALIDATION] [Epoch 06/29] - pep_recall 0.126
[2025-08-10 14:58:46,149][__main__][INFO] - [TRAIN] [Epoch 06/29] Epoch complete, total time 04:02:45, remaining time 13:17:37, 00:34:40 per epoch
[2025-08-10 14:58:48,118][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025848] [Batch 00004/03692] [00:00:01/00:26:05, 0.425s/it]: train_loss_raw=1.4226, running_loss=1.4727, LR=0.000100
[2025-08-10 14:58:54,672][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025860] [Batch 00016/03692] [00:00:08/00:31:35, 0.516s/it]: train_loss_raw=1.4361, running_loss=1.4670, LR=0.000100
[2025-08-10 14:59:01,293][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025872] [Batch 00028/03692] [00:00:14/00:32:26, 0.531s/it]: train_loss_raw=1.4248, running_loss=1.4619, LR=0.000100
[2025-08-10 14:59:07,810][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025884] [Batch 00040/03692] [00:00:21/00:32:32, 0.535s/it]: train_loss_raw=1.3877, running_loss=1.4591, LR=0.000100
[2025-08-10 14:59:14,362][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025896] [Batch 00052/03692] [00:00:27/00:32:35, 0.537s/it]: train_loss_raw=1.4319, running_loss=1.4516, LR=0.000100
[2025-08-10 14:59:20,579][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025908] [Batch 00064/03692] [00:00:34/00:32:16, 0.534s/it]: train_loss_raw=1.5662, running_loss=1.4499, LR=0.000100
[2025-08-10 14:59:26,682][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025920] [Batch 00076/03692] [00:00:40/00:31:55, 0.530s/it]: train_loss_raw=1.5482, running_loss=1.4463, LR=0.000100
[2025-08-10 14:59:32,921][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025932] [Batch 00088/03692] [00:00:46/00:31:44, 0.528s/it]: train_loss_raw=1.4440, running_loss=1.4421, LR=0.000100
[2025-08-10 14:59:39,497][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025944] [Batch 00100/03692] [00:00:53/00:31:46, 0.531s/it]: train_loss_raw=1.3920, running_loss=1.4379, LR=0.000100
[2025-08-10 14:59:45,948][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025956] [Batch 00112/03692] [00:00:59/00:31:42, 0.532s/it]: train_loss_raw=1.3993, running_loss=1.4391, LR=0.000100
[2025-08-10 14:59:52,006][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025968] [Batch 00124/03692] [00:01:05/00:31:27, 0.529s/it]: train_loss_raw=1.3545, running_loss=1.4351, LR=0.000100
[2025-08-10 14:59:58,055][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025980] [Batch 00136/03692] [00:01:11/00:31:13, 0.527s/it]: train_loss_raw=1.3750, running_loss=1.4339, LR=0.000100
[2025-08-10 15:00:04,263][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025992] [Batch 00148/03692] [00:01:17/00:31:04, 0.526s/it]: train_loss_raw=1.4510, running_loss=1.4321, LR=0.000100
[2025-08-10 15:00:15,899][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026004] [Batch 00160/03692] [00:01:29/00:32:55, 0.559s/it]: train_loss_raw=1.3265, running_loss=1.4310, LR=0.000100
[2025-08-10 15:00:21,950][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026016] [Batch 00172/03692] [00:01:35/00:32:35, 0.555s/it]: train_loss_raw=1.4888, running_loss=1.4275, LR=0.000100
[2025-08-10 15:00:28,288][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026028] [Batch 00184/03692] [00:01:41/00:32:22, 0.554s/it]: train_loss_raw=1.4545, running_loss=1.4284, LR=0.000100
[2025-08-10 15:00:34,839][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026040] [Batch 00196/03692] [00:01:48/00:32:13, 0.553s/it]: train_loss_raw=1.3262, running_loss=1.4247, LR=0.000100
[2025-08-10 15:00:41,384][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026052] [Batch 00208/03692] [00:01:54/00:32:05, 0.553s/it]: train_loss_raw=1.3682, running_loss=1.4242, LR=0.000100
[2025-08-10 15:00:47,904][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026064] [Batch 00220/03692] [00:02:01/00:31:57, 0.552s/it]: train_loss_raw=1.3292, running_loss=1.4226, LR=0.000100
[2025-08-10 15:00:54,160][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026076] [Batch 00232/03692] [00:02:07/00:31:45, 0.551s/it]: train_loss_raw=1.3826, running_loss=1.4194, LR=0.000100
[2025-08-10 15:01:00,268][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026088] [Batch 00244/03692] [00:02:13/00:31:31, 0.549s/it]: train_loss_raw=1.2634, running_loss=1.4180, LR=0.000100
[2025-08-10 15:01:06,327][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026100] [Batch 00256/03692] [00:02:19/00:31:17, 0.547s/it]: train_loss_raw=1.4896, running_loss=1.4149, LR=0.000100
[2025-08-10 15:01:12,772][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026112] [Batch 00268/03692] [00:02:26/00:31:09, 0.546s/it]: train_loss_raw=1.2845, running_loss=1.4113, LR=0.000100
[2025-08-10 15:01:19,340][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026124] [Batch 00280/03692] [00:02:32/00:31:03, 0.546s/it]: train_loss_raw=1.4987, running_loss=1.4113, LR=0.000100
[2025-08-10 15:01:26,010][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026136] [Batch 00292/03692] [00:02:39/00:30:58, 0.547s/it]: train_loss_raw=1.4449, running_loss=1.4080, LR=0.000100
[2025-08-10 15:01:32,494][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026148] [Batch 00304/03692] [00:02:46/00:30:50, 0.546s/it]: train_loss_raw=1.3943, running_loss=1.4104, LR=0.000100
[2025-08-10 15:01:38,673][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026160] [Batch 00316/03692] [00:02:52/00:30:40, 0.545s/it]: train_loss_raw=1.4782, running_loss=1.4070, LR=0.000100
[2025-08-10 15:01:45,091][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026172] [Batch 00328/03692] [00:02:58/00:30:32, 0.545s/it]: train_loss_raw=1.2684, running_loss=1.4047, LR=0.000100
[2025-08-10 15:01:51,312][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026184] [Batch 00340/03692] [00:03:04/00:30:22, 0.544s/it]: train_loss_raw=1.4382, running_loss=1.4074, LR=0.000100
[2025-08-10 15:01:57,359][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026196] [Batch 00352/03692] [00:03:10/00:30:11, 0.542s/it]: train_loss_raw=1.4707, running_loss=1.4107, LR=0.000100
[2025-08-10 15:02:03,429][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026208] [Batch 00364/03692] [00:03:17/00:30:01, 0.541s/it]: train_loss_raw=1.5604, running_loss=1.4138, LR=0.000100
[2025-08-10 15:02:09,500][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026220] [Batch 00376/03692] [00:03:23/00:29:50, 0.540s/it]: train_loss_raw=1.4072, running_loss=1.4150, LR=0.000100
[2025-08-10 15:02:15,541][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026232] [Batch 00388/03692] [00:03:29/00:29:40, 0.539s/it]: train_loss_raw=1.3572, running_loss=1.4156, LR=0.000100
[2025-08-10 15:02:21,652][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026244] [Batch 00400/03692] [00:03:35/00:29:31, 0.538s/it]: train_loss_raw=1.3989, running_loss=1.4121, LR=0.000100
[2025-08-10 15:02:28,082][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026256] [Batch 00412/03692] [00:03:41/00:29:24, 0.538s/it]: train_loss_raw=1.3792, running_loss=1.4092, LR=0.000100
[2025-08-10 15:02:34,623][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026268] [Batch 00424/03692] [00:03:48/00:29:18, 0.538s/it]: train_loss_raw=1.4023, running_loss=1.4076, LR=0.000100
[2025-08-10 15:02:40,901][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026280] [Batch 00436/03692] [00:03:54/00:29:11, 0.538s/it]: train_loss_raw=1.4996, running_loss=1.4089, LR=0.000100
[2025-08-10 15:02:47,414][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026292] [Batch 00448/03692] [00:04:00/00:29:05, 0.538s/it]: train_loss_raw=1.4272, running_loss=1.4069, LR=0.000100
[2025-08-10 15:02:53,641][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026304] [Batch 00460/03692] [00:04:07/00:28:56, 0.537s/it]: train_loss_raw=1.3084, running_loss=1.4068, LR=0.000100
[2025-08-10 15:02:59,709][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026316] [Batch 00472/03692] [00:04:13/00:28:47, 0.537s/it]: train_loss_raw=1.3604, running_loss=1.4056, LR=0.000100
[2025-08-10 15:03:05,782][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026328] [Batch 00484/03692] [00:04:19/00:28:39, 0.536s/it]: train_loss_raw=1.4229, running_loss=1.4080, LR=0.000100
[2025-08-10 15:03:11,870][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026340] [Batch 00496/03692] [00:04:25/00:28:30, 0.535s/it]: train_loss_raw=1.4578, running_loss=1.4096, LR=0.000100
[2025-08-10 15:03:17,960][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026352] [Batch 00508/03692] [00:04:31/00:28:21, 0.535s/it]: train_loss_raw=1.4846, running_loss=1.4106, LR=0.000100
[2025-08-10 15:03:24,031][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026364] [Batch 00520/03692] [00:04:37/00:28:13, 0.534s/it]: train_loss_raw=1.2766, running_loss=1.4075, LR=0.000100
[2025-08-10 15:03:30,321][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026376] [Batch 00532/03692] [00:04:43/00:28:06, 0.534s/it]: train_loss_raw=1.5014, running_loss=1.4078, LR=0.000100
[2025-08-10 15:03:36,966][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026388] [Batch 00544/03692] [00:04:50/00:28:01, 0.534s/it]: train_loss_raw=1.3624, running_loss=1.4072, LR=0.000100
[2025-08-10 15:03:43,520][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026400] [Batch 00556/03692] [00:04:57/00:27:55, 0.534s/it]: train_loss_raw=1.3828, running_loss=1.4094, LR=0.000100
[2025-08-10 15:03:50,137][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026412] [Batch 00568/03692] [00:05:03/00:27:50, 0.535s/it]: train_loss_raw=1.5603, running_loss=1.4143, LR=0.000100
[2025-08-10 15:03:56,709][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026424] [Batch 00580/03692] [00:05:10/00:27:44, 0.535s/it]: train_loss_raw=1.3179, running_loss=1.4112, LR=0.000100
[2025-08-10 15:04:02,778][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026436] [Batch 00592/03692] [00:05:16/00:27:36, 0.534s/it]: train_loss_raw=1.3813, running_loss=1.4064, LR=0.000100
[2025-08-10 15:04:08,845][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026448] [Batch 00604/03692] [00:05:22/00:27:28, 0.534s/it]: train_loss_raw=1.5309, running_loss=1.4081, LR=0.000100
[2025-08-10 15:04:14,898][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026460] [Batch 00616/03692] [00:05:28/00:27:20, 0.533s/it]: train_loss_raw=1.4706, running_loss=1.4066, LR=0.000100
[2025-08-10 15:04:21,140][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026472] [Batch 00628/03692] [00:05:34/00:27:13, 0.533s/it]: train_loss_raw=1.3045, running_loss=1.4016, LR=0.000100
[2025-08-10 15:04:27,618][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026484] [Batch 00640/03692] [00:05:41/00:27:07, 0.533s/it]: train_loss_raw=1.4308, running_loss=1.4075, LR=0.000100
[2025-08-10 15:04:33,829][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026496] [Batch 00652/03692] [00:05:47/00:26:59, 0.533s/it]: train_loss_raw=1.4043, running_loss=1.4069, LR=0.000100
[2025-08-10 15:04:40,296][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026508] [Batch 00664/03692] [00:05:53/00:26:53, 0.533s/it]: train_loss_raw=1.4041, running_loss=1.4055, LR=0.000100
[2025-08-10 15:04:46,581][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026520] [Batch 00676/03692] [00:06:00/00:26:46, 0.533s/it]: train_loss_raw=1.5058, running_loss=1.4088, LR=0.000100
[2025-08-10 15:04:52,640][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026532] [Batch 00688/03692] [00:06:06/00:26:39, 0.532s/it]: train_loss_raw=1.3280, running_loss=1.4097, LR=0.000100
[2025-08-10 15:04:58,689][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026544] [Batch 00700/03692] [00:06:12/00:26:31, 0.532s/it]: train_loss_raw=1.3374, running_loss=1.4087, LR=0.000100
[2025-08-10 15:05:04,713][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026556] [Batch 00712/03692] [00:06:18/00:26:23, 0.531s/it]: train_loss_raw=1.6302, running_loss=1.4105, LR=0.000100
[2025-08-10 15:05:10,743][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026568] [Batch 00724/03692] [00:06:24/00:26:15, 0.531s/it]: train_loss_raw=1.4515, running_loss=1.4121, LR=0.000100
[2025-08-10 15:05:17,157][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026580] [Batch 00736/03692] [00:06:30/00:26:09, 0.531s/it]: train_loss_raw=1.4448, running_loss=1.4096, LR=0.000100
[2025-08-10 15:05:23,798][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026592] [Batch 00748/03692] [00:06:37/00:26:04, 0.531s/it]: train_loss_raw=1.4081, running_loss=1.4044, LR=0.000100
[2025-08-10 15:05:30,336][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026604] [Batch 00760/03692] [00:06:43/00:25:58, 0.531s/it]: train_loss_raw=1.3754, running_loss=1.4018, LR=0.000100
[2025-08-10 15:05:36,393][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026616] [Batch 00772/03692] [00:06:49/00:25:50, 0.531s/it]: train_loss_raw=1.4052, running_loss=1.4036, LR=0.000100
[2025-08-10 15:05:42,871][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026628] [Batch 00784/03692] [00:06:56/00:25:44, 0.531s/it]: train_loss_raw=1.4884, running_loss=1.4055, LR=0.000100
[2025-08-10 15:05:49,476][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026640] [Batch 00796/03692] [00:07:03/00:25:39, 0.531s/it]: train_loss_raw=1.2498, running_loss=1.3983, LR=0.000100
[2025-08-10 15:05:55,798][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026652] [Batch 00808/03692] [00:07:09/00:25:32, 0.531s/it]: train_loss_raw=1.4840, running_loss=1.3967, LR=0.000100
[2025-08-10 15:06:02,381][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026664] [Batch 00820/03692] [00:07:15/00:25:26, 0.532s/it]: train_loss_raw=1.4199, running_loss=1.3996, LR=0.000100
[2025-08-10 15:06:08,416][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026676] [Batch 00832/03692] [00:07:21/00:25:19, 0.531s/it]: train_loss_raw=1.3790, running_loss=1.3989, LR=0.000100
[2025-08-10 15:06:14,880][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026688] [Batch 00844/03692] [00:07:28/00:25:13, 0.531s/it]: train_loss_raw=1.3052, running_loss=1.4009, LR=0.000100
[2025-08-10 15:06:21,515][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026700] [Batch 00856/03692] [00:07:35/00:25:07, 0.532s/it]: train_loss_raw=1.5012, running_loss=1.4008, LR=0.000100
[2025-08-10 15:06:27,936][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026712] [Batch 00868/03692] [00:07:41/00:25:01, 0.532s/it]: train_loss_raw=1.4657, running_loss=1.4033, LR=0.000100
[2025-08-10 15:06:33,923][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026724] [Batch 00880/03692] [00:07:47/00:24:53, 0.531s/it]: train_loss_raw=1.3953, running_loss=1.4019, LR=0.000100
[2025-08-10 15:06:40,055][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026736] [Batch 00892/03692] [00:07:53/00:24:46, 0.531s/it]: train_loss_raw=1.3400, running_loss=1.4018, LR=0.000100
[2025-08-10 15:06:46,197][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026748] [Batch 00904/03692] [00:07:59/00:24:39, 0.531s/it]: train_loss_raw=1.4233, running_loss=1.3996, LR=0.000100
[2025-08-10 15:06:52,477][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026760] [Batch 00916/03692] [00:08:06/00:24:33, 0.531s/it]: train_loss_raw=1.3918, running_loss=1.3954, LR=0.000100
[2025-08-10 15:06:58,996][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026772] [Batch 00928/03692] [00:08:12/00:24:27, 0.531s/it]: train_loss_raw=1.4124, running_loss=1.3927, LR=0.000100
[2025-08-10 15:07:05,557][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026784] [Batch 00940/03692] [00:08:19/00:24:21, 0.531s/it]: train_loss_raw=1.5164, running_loss=1.3942, LR=0.000100
[2025-08-10 15:07:12,158][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026796] [Batch 00952/03692] [00:08:25/00:24:15, 0.531s/it]: train_loss_raw=1.2650, running_loss=1.3892, LR=0.000100
[2025-08-10 15:07:18,792][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026808] [Batch 00964/03692] [00:08:32/00:24:09, 0.532s/it]: train_loss_raw=1.3556, running_loss=1.3879, LR=0.000100
[2025-08-10 15:07:25,382][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026820] [Batch 00976/03692] [00:08:38/00:24:04, 0.532s/it]: train_loss_raw=1.3923, running_loss=1.3893, LR=0.000100
[2025-08-10 15:07:31,951][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026832] [Batch 00988/03692] [00:08:45/00:23:58, 0.532s/it]: train_loss_raw=1.4083, running_loss=1.3909, LR=0.000100
[2025-08-10 15:07:38,466][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026844] [Batch 01000/03692] [00:08:52/00:23:52, 0.532s/it]: train_loss_raw=1.4309, running_loss=1.3912, LR=0.000100
[2025-08-10 15:07:44,989][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026856] [Batch 01012/03692] [00:08:58/00:23:46, 0.532s/it]: train_loss_raw=1.3736, running_loss=1.3940, LR=0.000100
[2025-08-10 15:07:51,162][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026868] [Batch 01024/03692] [00:09:04/00:23:39, 0.532s/it]: train_loss_raw=1.3234, running_loss=1.3924, LR=0.000100
[2025-08-10 15:07:57,310][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026880] [Batch 01036/03692] [00:09:10/00:23:32, 0.532s/it]: train_loss_raw=1.3859, running_loss=1.3937, LR=0.000100
[2025-08-10 15:08:03,389][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026892] [Batch 01048/03692] [00:09:16/00:23:25, 0.531s/it]: train_loss_raw=1.3438, running_loss=1.4009, LR=0.000100
[2025-08-10 15:08:09,512][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026904] [Batch 01060/03692] [00:09:23/00:23:18, 0.531s/it]: train_loss_raw=1.4238, running_loss=1.3983, LR=0.000100
[2025-08-10 15:08:15,718][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026916] [Batch 01072/03692] [00:09:29/00:23:11, 0.531s/it]: train_loss_raw=1.2540, running_loss=1.3975, LR=0.000100
[2025-08-10 15:08:21,878][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026928] [Batch 01084/03692] [00:09:35/00:23:04, 0.531s/it]: train_loss_raw=1.4555, running_loss=1.4011, LR=0.000100
[2025-08-10 15:08:27,956][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026940] [Batch 01096/03692] [00:09:41/00:22:57, 0.531s/it]: train_loss_raw=1.2861, running_loss=1.4010, LR=0.000100
[2025-08-10 15:08:34,074][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026952] [Batch 01108/03692] [00:09:47/00:22:50, 0.530s/it]: train_loss_raw=1.2909, running_loss=1.3968, LR=0.000100
[2025-08-10 15:08:40,136][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026964] [Batch 01120/03692] [00:09:53/00:22:43, 0.530s/it]: train_loss_raw=1.3631, running_loss=1.3993, LR=0.000100
[2025-08-10 15:08:46,290][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026976] [Batch 01132/03692] [00:09:59/00:22:36, 0.530s/it]: train_loss_raw=1.4003, running_loss=1.3998, LR=0.000100
[2025-08-10 15:08:52,741][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026988] [Batch 01144/03692] [00:10:06/00:22:30, 0.530s/it]: train_loss_raw=1.5531, running_loss=1.4014, LR=0.000100
[2025-08-10 15:08:59,317][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027000] [Batch 01156/03692] [00:10:12/00:22:24, 0.530s/it]: train_loss_raw=1.3152, running_loss=1.4012, LR=0.000100
[2025-08-10 15:09:05,635][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027012] [Batch 01168/03692] [00:10:19/00:22:18, 0.530s/it]: train_loss_raw=1.4572, running_loss=1.3943, LR=0.000100
[2025-08-10 15:09:11,821][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027024] [Batch 01180/03692] [00:10:25/00:22:11, 0.530s/it]: train_loss_raw=1.4475, running_loss=1.3945, LR=0.000100
[2025-08-10 15:09:17,863][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027036] [Batch 01192/03692] [00:10:31/00:22:04, 0.530s/it]: train_loss_raw=1.3711, running_loss=1.3934, LR=0.000100
[2025-08-10 15:09:24,251][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027048] [Batch 01204/03692] [00:10:37/00:21:58, 0.530s/it]: train_loss_raw=1.2605, running_loss=1.3902, LR=0.000100
[2025-08-10 15:09:30,784][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027060] [Batch 01216/03692] [00:10:44/00:21:52, 0.530s/it]: train_loss_raw=1.4852, running_loss=1.3911, LR=0.000100
[2025-08-10 15:09:37,368][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027072] [Batch 01228/03692] [00:10:50/00:21:46, 0.530s/it]: train_loss_raw=1.3383, running_loss=1.3864, LR=0.000100
[2025-08-10 15:09:43,997][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027084] [Batch 01240/03692] [00:10:57/00:21:40, 0.530s/it]: train_loss_raw=1.4510, running_loss=1.3893, LR=0.000100
[2025-08-10 15:09:50,529][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027096] [Batch 01252/03692] [00:11:04/00:21:34, 0.530s/it]: train_loss_raw=1.4066, running_loss=1.3906, LR=0.000100
[2025-08-10 15:09:57,061][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027108] [Batch 01264/03692] [00:11:10/00:21:28, 0.531s/it]: train_loss_raw=1.2635, running_loss=1.3894, LR=0.000100
[2025-08-10 15:10:03,102][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027120] [Batch 01276/03692] [00:11:16/00:21:21, 0.530s/it]: train_loss_raw=1.4106, running_loss=1.3915, LR=0.000100
[2025-08-10 15:10:09,099][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027132] [Batch 01288/03692] [00:11:22/00:21:14, 0.530s/it]: train_loss_raw=1.4099, running_loss=1.3947, LR=0.000100
[2025-08-10 15:10:15,125][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027144] [Batch 01300/03692] [00:11:28/00:21:07, 0.530s/it]: train_loss_raw=1.3709, running_loss=1.3955, LR=0.000100
[2025-08-10 15:10:21,543][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027156] [Batch 01312/03692] [00:11:35/00:21:00, 0.530s/it]: train_loss_raw=1.4018, running_loss=1.3963, LR=0.000100
[2025-08-10 15:10:27,767][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027168] [Batch 01324/03692] [00:11:41/00:20:54, 0.530s/it]: train_loss_raw=1.4714, running_loss=1.3979, LR=0.000100
[2025-08-10 15:10:33,819][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027180] [Batch 01336/03692] [00:11:47/00:20:47, 0.529s/it]: train_loss_raw=1.4778, running_loss=1.3966, LR=0.000100
[2025-08-10 15:10:40,387][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027192] [Batch 01348/03692] [00:11:53/00:20:41, 0.530s/it]: train_loss_raw=1.4625, running_loss=1.3954, LR=0.000100
[2025-08-10 15:10:46,602][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027204] [Batch 01360/03692] [00:12:00/00:20:34, 0.530s/it]: train_loss_raw=1.4136, running_loss=1.3935, LR=0.000100
[2025-08-10 15:10:52,881][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027216] [Batch 01372/03692] [00:12:06/00:20:28, 0.529s/it]: train_loss_raw=1.3294, running_loss=1.3915, LR=0.000100
[2025-08-10 15:10:59,405][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027228] [Batch 01384/03692] [00:12:12/00:20:22, 0.530s/it]: train_loss_raw=1.5566, running_loss=1.3962, LR=0.000100
[2025-08-10 15:11:06,041][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027240] [Batch 01396/03692] [00:12:19/00:20:16, 0.530s/it]: train_loss_raw=1.3084, running_loss=1.3913, LR=0.000100
[2025-08-10 15:11:12,421][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027252] [Batch 01408/03692] [00:12:26/00:20:10, 0.530s/it]: train_loss_raw=1.4846, running_loss=1.3909, LR=0.000100
[2025-08-10 15:11:18,561][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027264] [Batch 01420/03692] [00:12:32/00:20:03, 0.530s/it]: train_loss_raw=1.3998, running_loss=1.3906, LR=0.000100
[2025-08-10 15:11:24,564][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027276] [Batch 01432/03692] [00:12:38/00:19:56, 0.529s/it]: train_loss_raw=1.4195, running_loss=1.3945, LR=0.000100
[2025-08-10 15:11:30,695][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027288] [Batch 01444/03692] [00:12:44/00:19:49, 0.529s/it]: train_loss_raw=1.3279, running_loss=1.3880, LR=0.000100
[2025-08-10 15:11:37,032][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027300] [Batch 01456/03692] [00:12:50/00:19:43, 0.529s/it]: train_loss_raw=1.3965, running_loss=1.3878, LR=0.000100
[2025-08-10 15:11:43,326][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027312] [Batch 01468/03692] [00:12:56/00:19:37, 0.529s/it]: train_loss_raw=1.3466, running_loss=1.3870, LR=0.000100
[2025-08-10 15:11:49,535][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027324] [Batch 01480/03692] [00:13:03/00:19:30, 0.529s/it]: train_loss_raw=1.3506, running_loss=1.3897, LR=0.000100
[2025-08-10 15:11:55,601][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027336] [Batch 01492/03692] [00:13:09/00:19:23, 0.529s/it]: train_loss_raw=1.3108, running_loss=1.3840, LR=0.000100
[2025-08-10 15:12:01,790][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027348] [Batch 01504/03692] [00:13:15/00:19:17, 0.529s/it]: train_loss_raw=1.3221, running_loss=1.3815, LR=0.000100
[2025-08-10 15:12:08,041][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027360] [Batch 01516/03692] [00:13:21/00:19:10, 0.529s/it]: train_loss_raw=1.4376, running_loss=1.3828, LR=0.000100
[2025-08-10 15:12:14,473][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027372] [Batch 01528/03692] [00:13:28/00:19:04, 0.529s/it]: train_loss_raw=1.4267, running_loss=1.3808, LR=0.000100
[2025-08-10 15:12:21,079][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027384] [Batch 01540/03692] [00:13:34/00:18:58, 0.529s/it]: train_loss_raw=1.3981, running_loss=1.3832, LR=0.000100
[2025-08-10 15:12:27,685][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027396] [Batch 01552/03692] [00:13:41/00:18:52, 0.529s/it]: train_loss_raw=1.4430, running_loss=1.3865, LR=0.000100
[2025-08-10 15:12:34,011][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027408] [Batch 01564/03692] [00:13:47/00:18:46, 0.529s/it]: train_loss_raw=1.3736, running_loss=1.3824, LR=0.000100
[2025-08-10 15:12:40,051][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027420] [Batch 01576/03692] [00:13:53/00:18:39, 0.529s/it]: train_loss_raw=1.4657, running_loss=1.3826, LR=0.000100
[2025-08-10 15:12:46,411][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027432] [Batch 01588/03692] [00:13:59/00:18:32, 0.529s/it]: train_loss_raw=1.4512, running_loss=1.3827, LR=0.000100
[2025-08-10 15:12:52,911][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027444] [Batch 01600/03692] [00:14:06/00:18:26, 0.529s/it]: train_loss_raw=1.3507, running_loss=1.3834, LR=0.000100
[2025-08-10 15:12:59,536][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027456] [Batch 01612/03692] [00:14:13/00:18:20, 0.529s/it]: train_loss_raw=1.2898, running_loss=1.3858, LR=0.000100
[2025-08-10 15:13:06,194][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027468] [Batch 01624/03692] [00:14:19/00:18:14, 0.529s/it]: train_loss_raw=1.3228, running_loss=1.3813, LR=0.000100
[2025-08-10 15:13:12,216][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027480] [Batch 01636/03692] [00:14:25/00:18:08, 0.529s/it]: train_loss_raw=1.3664, running_loss=1.3832, LR=0.000100
[2025-08-10 15:13:18,295][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027492] [Batch 01648/03692] [00:14:31/00:18:01, 0.529s/it]: train_loss_raw=1.3743, running_loss=1.3823, LR=0.000100
[2025-08-10 15:13:24,356][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027504] [Batch 01660/03692] [00:14:37/00:17:54, 0.529s/it]: train_loss_raw=1.4648, running_loss=1.3816, LR=0.000100
[2025-08-10 15:13:30,410][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027516] [Batch 01672/03692] [00:14:43/00:17:47, 0.529s/it]: train_loss_raw=1.4186, running_loss=1.3794, LR=0.000100
[2025-08-10 15:13:36,446][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027528] [Batch 01684/03692] [00:14:50/00:17:41, 0.529s/it]: train_loss_raw=1.2219, running_loss=1.3757, LR=0.000100
[2025-08-10 15:13:42,494][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027540] [Batch 01696/03692] [00:14:56/00:17:34, 0.528s/it]: train_loss_raw=1.3469, running_loss=1.3787, LR=0.000100
[2025-08-10 15:13:48,964][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027552] [Batch 01708/03692] [00:15:02/00:17:28, 0.528s/it]: train_loss_raw=1.2972, running_loss=1.3770, LR=0.000100
[2025-08-10 15:13:55,470][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027564] [Batch 01720/03692] [00:15:09/00:17:22, 0.529s/it]: train_loss_raw=1.3843, running_loss=1.3774, LR=0.000100
[2025-08-10 15:14:01,540][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027576] [Batch 01732/03692] [00:15:15/00:17:15, 0.528s/it]: train_loss_raw=1.2964, running_loss=1.3762, LR=0.000100
[2025-08-10 15:14:07,602][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027588] [Batch 01744/03692] [00:15:21/00:17:08, 0.528s/it]: train_loss_raw=1.4387, running_loss=1.3765, LR=0.000100
[2025-08-10 15:14:13,745][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027600] [Batch 01756/03692] [00:15:27/00:17:02, 0.528s/it]: train_loss_raw=1.3958, running_loss=1.3783, LR=0.000100
[2025-08-10 15:14:19,733][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027612] [Batch 01768/03692] [00:15:33/00:16:55, 0.528s/it]: train_loss_raw=1.3644, running_loss=1.3738, LR=0.000100
[2025-08-10 15:14:25,856][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027624] [Batch 01780/03692] [00:15:39/00:16:49, 0.528s/it]: train_loss_raw=1.4897, running_loss=1.3747, LR=0.000100
[2025-08-10 15:14:31,985][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027636] [Batch 01792/03692] [00:15:45/00:16:42, 0.528s/it]: train_loss_raw=1.2926, running_loss=1.3741, LR=0.000100
[2025-08-10 15:14:38,091][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027648] [Batch 01804/03692] [00:15:51/00:16:35, 0.528s/it]: train_loss_raw=1.4036, running_loss=1.3740, LR=0.000100
[2025-08-10 15:14:44,087][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027660] [Batch 01816/03692] [00:15:57/00:16:29, 0.527s/it]: train_loss_raw=1.3692, running_loss=1.3730, LR=0.000100
[2025-08-10 15:14:50,249][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027672] [Batch 01828/03692] [00:16:03/00:16:22, 0.527s/it]: train_loss_raw=1.2554, running_loss=1.3711, LR=0.000100
[2025-08-10 15:14:56,324][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027684] [Batch 01840/03692] [00:16:09/00:16:16, 0.527s/it]: train_loss_raw=1.3056, running_loss=1.3738, LR=0.000100
[2025-08-10 15:15:02,731][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027696] [Batch 01852/03692] [00:16:16/00:16:09, 0.527s/it]: train_loss_raw=1.3871, running_loss=1.3729, LR=0.000100
[2025-08-10 15:15:09,274][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027708] [Batch 01864/03692] [00:16:22/00:16:03, 0.527s/it]: train_loss_raw=1.4703, running_loss=1.3738, LR=0.000100
[2025-08-10 15:15:15,801][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027720] [Batch 01876/03692] [00:16:29/00:15:57, 0.527s/it]: train_loss_raw=1.4332, running_loss=1.3762, LR=0.000100
[2025-08-10 15:15:21,801][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027732] [Batch 01888/03692] [00:16:35/00:15:51, 0.527s/it]: train_loss_raw=1.3014, running_loss=1.3716, LR=0.000100
[2025-08-10 15:15:27,795][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027744] [Batch 01900/03692] [00:16:41/00:15:44, 0.527s/it]: train_loss_raw=1.5036, running_loss=1.3721, LR=0.000100
[2025-08-10 15:15:34,097][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027756] [Batch 01912/03692] [00:16:47/00:15:38, 0.527s/it]: train_loss_raw=1.2650, running_loss=1.3686, LR=0.000100
[2025-08-10 15:15:40,184][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027768] [Batch 01924/03692] [00:16:53/00:15:31, 0.527s/it]: train_loss_raw=1.3613, running_loss=1.3646, LR=0.000100
[2025-08-10 15:15:46,280][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027780] [Batch 01936/03692] [00:16:59/00:15:25, 0.527s/it]: train_loss_raw=1.3378, running_loss=1.3609, LR=0.000100
[2025-08-10 15:15:52,359][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027792] [Batch 01948/03692] [00:17:05/00:15:18, 0.527s/it]: train_loss_raw=1.2911, running_loss=1.3643, LR=0.000100
[2025-08-10 15:15:58,562][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027804] [Batch 01960/03692] [00:17:12/00:15:12, 0.527s/it]: train_loss_raw=1.3840, running_loss=1.3633, LR=0.000100
[2025-08-10 15:16:04,704][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027816] [Batch 01972/03692] [00:17:18/00:15:05, 0.527s/it]: train_loss_raw=1.3562, running_loss=1.3692, LR=0.000100
[2025-08-10 15:16:11,262][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027828] [Batch 01984/03692] [00:17:24/00:14:59, 0.527s/it]: train_loss_raw=1.2798, running_loss=1.3675, LR=0.000100
[2025-08-10 15:16:17,803][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027840] [Batch 01996/03692] [00:17:31/00:14:53, 0.527s/it]: train_loss_raw=1.2595, running_loss=1.3688, LR=0.000100
[2025-08-10 15:16:24,391][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027852] [Batch 02008/03692] [00:17:37/00:14:47, 0.527s/it]: train_loss_raw=1.3866, running_loss=1.3698, LR=0.000100
[2025-08-10 15:16:30,914][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027864] [Batch 02020/03692] [00:17:44/00:14:41, 0.527s/it]: train_loss_raw=1.2406, running_loss=1.3716, LR=0.000100
[2025-08-10 15:16:37,145][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027876] [Batch 02032/03692] [00:17:50/00:14:34, 0.527s/it]: train_loss_raw=1.3686, running_loss=1.3710, LR=0.000100
[2025-08-10 15:16:43,759][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027888] [Batch 02044/03692] [00:17:57/00:14:28, 0.527s/it]: train_loss_raw=1.2624, running_loss=1.3682, LR=0.000100
[2025-08-10 15:16:49,946][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027900] [Batch 02056/03692] [00:18:03/00:14:22, 0.527s/it]: train_loss_raw=1.2890, running_loss=1.3694, LR=0.000100
[2025-08-10 15:16:55,960][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027912] [Batch 02068/03692] [00:18:09/00:14:15, 0.527s/it]: train_loss_raw=1.3516, running_loss=1.3698, LR=0.000100
[2025-08-10 15:17:02,053][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027924] [Batch 02080/03692] [00:18:15/00:14:09, 0.527s/it]: train_loss_raw=1.3488, running_loss=1.3676, LR=0.000100
[2025-08-10 15:17:08,148][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027936] [Batch 02092/03692] [00:18:21/00:14:02, 0.527s/it]: train_loss_raw=1.4300, running_loss=1.3710, LR=0.000100
[2025-08-10 15:17:14,165][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027948] [Batch 02104/03692] [00:18:27/00:13:56, 0.526s/it]: train_loss_raw=1.4046, running_loss=1.3738, LR=0.000100
[2025-08-10 15:17:20,242][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027960] [Batch 02116/03692] [00:18:33/00:13:49, 0.526s/it]: train_loss_raw=1.2863, running_loss=1.3701, LR=0.000100
[2025-08-10 15:17:26,524][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027972] [Batch 02128/03692] [00:18:40/00:13:43, 0.526s/it]: train_loss_raw=1.2299, running_loss=1.3727, LR=0.000100
[2025-08-10 15:17:32,697][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027984] [Batch 02140/03692] [00:18:46/00:13:36, 0.526s/it]: train_loss_raw=1.2997, running_loss=1.3698, LR=0.000100
[2025-08-10 15:17:38,765][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027996] [Batch 02152/03692] [00:18:52/00:13:30, 0.526s/it]: train_loss_raw=1.3327, running_loss=1.3674, LR=0.000100
[2025-08-10 15:17:57,134][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028008] [Batch 02164/03692] [00:19:10/00:13:32, 0.532s/it]: train_loss_raw=1.3923, running_loss=1.3711, LR=0.000100
[2025-08-10 15:18:03,388][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028020] [Batch 02176/03692] [00:19:16/00:13:26, 0.532s/it]: train_loss_raw=1.4041, running_loss=1.3726, LR=0.000100
[2025-08-10 15:18:10,018][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028032] [Batch 02188/03692] [00:19:23/00:13:19, 0.532s/it]: train_loss_raw=1.4875, running_loss=1.3694, LR=0.000100
[2025-08-10 15:18:16,544][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028044] [Batch 02200/03692] [00:19:30/00:13:13, 0.532s/it]: train_loss_raw=1.3617, running_loss=1.3662, LR=0.000100
[2025-08-10 15:18:23,117][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028056] [Batch 02212/03692] [00:19:36/00:13:07, 0.532s/it]: train_loss_raw=1.4179, running_loss=1.3658, LR=0.000100
[2025-08-10 15:18:29,697][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028068] [Batch 02224/03692] [00:19:43/00:13:01, 0.532s/it]: train_loss_raw=1.4491, running_loss=1.3666, LR=0.000100
[2025-08-10 15:18:36,248][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028080] [Batch 02236/03692] [00:19:49/00:12:54, 0.532s/it]: train_loss_raw=1.3938, running_loss=1.3677, LR=0.000100
[2025-08-10 15:18:42,769][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028092] [Batch 02248/03692] [00:19:56/00:12:48, 0.532s/it]: train_loss_raw=1.2190, running_loss=1.3659, LR=0.000100
[2025-08-10 15:18:49,407][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028104] [Batch 02260/03692] [00:20:02/00:12:42, 0.532s/it]: train_loss_raw=1.3485, running_loss=1.3675, LR=0.000100
[2025-08-10 15:18:55,875][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028116] [Batch 02272/03692] [00:20:09/00:12:35, 0.532s/it]: train_loss_raw=1.2628, running_loss=1.3685, LR=0.000100
[2025-08-10 15:19:02,095][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028128] [Batch 02284/03692] [00:20:15/00:12:29, 0.532s/it]: train_loss_raw=1.4867, running_loss=1.3684, LR=0.000100
[2025-08-10 15:19:08,264][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028140] [Batch 02296/03692] [00:20:21/00:12:22, 0.532s/it]: train_loss_raw=1.3229, running_loss=1.3675, LR=0.000100
[2025-08-10 15:19:14,605][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028152] [Batch 02308/03692] [00:20:28/00:12:16, 0.532s/it]: train_loss_raw=1.2458, running_loss=1.3640, LR=0.000100
[2025-08-10 15:19:21,190][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028164] [Batch 02320/03692] [00:20:34/00:12:10, 0.532s/it]: train_loss_raw=1.2897, running_loss=1.3659, LR=0.000100
[2025-08-10 15:19:27,464][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028176] [Batch 02332/03692] [00:20:41/00:12:03, 0.532s/it]: train_loss_raw=1.2143, running_loss=1.3650, LR=0.000100
[2025-08-10 15:19:33,703][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028188] [Batch 02344/03692] [00:20:47/00:11:57, 0.532s/it]: train_loss_raw=1.3383, running_loss=1.3611, LR=0.000100
[2025-08-10 15:19:40,215][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028200] [Batch 02356/03692] [00:20:53/00:11:50, 0.532s/it]: train_loss_raw=1.2342, running_loss=1.3566, LR=0.000100
[2025-08-10 15:19:46,658][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028212] [Batch 02368/03692] [00:21:00/00:11:44, 0.532s/it]: train_loss_raw=1.3907, running_loss=1.3572, LR=0.000100
[2025-08-10 15:19:52,755][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028224] [Batch 02380/03692] [00:21:06/00:11:38, 0.532s/it]: train_loss_raw=1.4283, running_loss=1.3559, LR=0.000100
[2025-08-10 15:19:58,937][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028236] [Batch 02392/03692] [00:21:12/00:11:31, 0.532s/it]: train_loss_raw=1.2371, running_loss=1.3542, LR=0.000100
[2025-08-10 15:20:05,166][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028248] [Batch 02404/03692] [00:21:18/00:11:25, 0.532s/it]: train_loss_raw=1.3975, running_loss=1.3590, LR=0.000100
[2025-08-10 15:20:11,513][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028260] [Batch 02416/03692] [00:21:25/00:11:18, 0.532s/it]: train_loss_raw=1.3161, running_loss=1.3577, LR=0.000100
[2025-08-10 15:20:17,693][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028272] [Batch 02428/03692] [00:21:31/00:11:12, 0.532s/it]: train_loss_raw=1.3859, running_loss=1.3574, LR=0.000100
[2025-08-10 15:20:24,101][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028284] [Batch 02440/03692] [00:21:37/00:11:05, 0.532s/it]: train_loss_raw=1.2657, running_loss=1.3551, LR=0.000100
[2025-08-10 15:20:30,584][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028296] [Batch 02452/03692] [00:21:44/00:10:59, 0.532s/it]: train_loss_raw=1.4055, running_loss=1.3569, LR=0.000100
[2025-08-10 15:20:37,110][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028308] [Batch 02464/03692] [00:21:50/00:10:53, 0.532s/it]: train_loss_raw=1.2855, running_loss=1.3533, LR=0.000100
[2025-08-10 15:20:43,742][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028320] [Batch 02476/03692] [00:21:57/00:10:46, 0.532s/it]: train_loss_raw=1.1823, running_loss=1.3532, LR=0.000100
[2025-08-10 15:20:49,957][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028332] [Batch 02488/03692] [00:22:03/00:10:40, 0.532s/it]: train_loss_raw=1.2428, running_loss=1.3536, LR=0.000100
[2025-08-10 15:20:56,178][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028344] [Batch 02500/03692] [00:22:09/00:10:34, 0.532s/it]: train_loss_raw=1.4270, running_loss=1.3527, LR=0.000100
[2025-08-10 15:21:02,460][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028356] [Batch 02512/03692] [00:22:16/00:10:27, 0.532s/it]: train_loss_raw=1.3310, running_loss=1.3539, LR=0.000100
[2025-08-10 15:21:08,713][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028368] [Batch 02524/03692] [00:22:22/00:10:21, 0.532s/it]: train_loss_raw=1.2752, running_loss=1.3530, LR=0.000100
[2025-08-10 15:21:14,790][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028380] [Batch 02536/03692] [00:22:28/00:10:14, 0.532s/it]: train_loss_raw=1.4416, running_loss=1.3565, LR=0.000100
[2025-08-10 15:21:21,180][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028392] [Batch 02548/03692] [00:22:34/00:10:08, 0.532s/it]: train_loss_raw=1.3328, running_loss=1.3580, LR=0.000100
[2025-08-10 15:21:27,838][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028404] [Batch 02560/03692] [00:22:41/00:10:02, 0.532s/it]: train_loss_raw=1.3515, running_loss=1.3540, LR=0.000100
[2025-08-10 15:21:34,450][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028416] [Batch 02572/03692] [00:22:48/00:09:55, 0.532s/it]: train_loss_raw=1.3087, running_loss=1.3526, LR=0.000100
[2025-08-10 15:21:41,028][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028428] [Batch 02584/03692] [00:22:54/00:09:49, 0.532s/it]: train_loss_raw=1.3380, running_loss=1.3526, LR=0.000100
[2025-08-10 15:21:47,202][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028440] [Batch 02596/03692] [00:23:00/00:09:42, 0.532s/it]: train_loss_raw=1.1953, running_loss=1.3514, LR=0.000100
[2025-08-10 15:21:53,280][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028452] [Batch 02608/03692] [00:23:06/00:09:36, 0.532s/it]: train_loss_raw=1.3056, running_loss=1.3524, LR=0.000100
[2025-08-10 15:21:59,401][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028464] [Batch 02620/03692] [00:23:12/00:09:29, 0.532s/it]: train_loss_raw=1.3448, running_loss=1.3524, LR=0.000100
[2025-08-10 15:22:05,458][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028476] [Batch 02632/03692] [00:23:19/00:09:23, 0.532s/it]: train_loss_raw=1.4427, running_loss=1.3530, LR=0.000100
[2025-08-10 15:22:11,567][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028488] [Batch 02644/03692] [00:23:25/00:09:16, 0.531s/it]: train_loss_raw=1.4739, running_loss=1.3559, LR=0.000100
[2025-08-10 15:22:17,903][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028500] [Batch 02656/03692] [00:23:31/00:09:10, 0.531s/it]: train_loss_raw=1.3045, running_loss=1.3548, LR=0.000100
[2025-08-10 15:22:24,189][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028512] [Batch 02668/03692] [00:23:37/00:09:04, 0.531s/it]: train_loss_raw=1.3451, running_loss=1.3544, LR=0.000100
[2025-08-10 15:22:30,404][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028524] [Batch 02680/03692] [00:23:43/00:08:57, 0.531s/it]: train_loss_raw=1.2877, running_loss=1.3529, LR=0.000100
[2025-08-10 15:22:36,977][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028536] [Batch 02692/03692] [00:23:50/00:08:51, 0.531s/it]: train_loss_raw=1.4731, running_loss=1.3520, LR=0.000100
[2025-08-10 15:22:43,618][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028548] [Batch 02704/03692] [00:23:57/00:08:45, 0.532s/it]: train_loss_raw=1.3896, running_loss=1.3524, LR=0.000100
[2025-08-10 15:22:50,267][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028560] [Batch 02716/03692] [00:24:03/00:08:38, 0.532s/it]: train_loss_raw=1.4435, running_loss=1.3578, LR=0.000100
[2025-08-10 15:22:56,689][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028572] [Batch 02728/03692] [00:24:10/00:08:32, 0.532s/it]: train_loss_raw=1.5889, running_loss=1.3631, LR=0.000100
[2025-08-10 15:23:02,778][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028584] [Batch 02740/03692] [00:24:16/00:08:26, 0.532s/it]: train_loss_raw=1.4135, running_loss=1.3651, LR=0.000100
[2025-08-10 15:23:08,981][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028596] [Batch 02752/03692] [00:24:22/00:08:19, 0.531s/it]: train_loss_raw=1.3917, running_loss=1.3635, LR=0.000100
[2025-08-10 15:23:15,192][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028608] [Batch 02764/03692] [00:24:28/00:08:13, 0.531s/it]: train_loss_raw=1.4023, running_loss=1.3601, LR=0.000100
[2025-08-10 15:23:21,280][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028620] [Batch 02776/03692] [00:24:34/00:08:06, 0.531s/it]: train_loss_raw=1.2868, running_loss=1.3576, LR=0.000100
[2025-08-10 15:23:27,393][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028632] [Batch 02788/03692] [00:24:40/00:08:00, 0.531s/it]: train_loss_raw=1.2873, running_loss=1.3535, LR=0.000100
[2025-08-10 15:23:33,605][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028644] [Batch 02800/03692] [00:24:47/00:07:53, 0.531s/it]: train_loss_raw=1.2635, running_loss=1.3518, LR=0.000100
[2025-08-10 15:23:39,827][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028656] [Batch 02812/03692] [00:24:53/00:07:47, 0.531s/it]: train_loss_raw=1.3651, running_loss=1.3560, LR=0.000100
[2025-08-10 15:23:46,062][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028668] [Batch 02824/03692] [00:24:59/00:07:40, 0.531s/it]: train_loss_raw=1.2440, running_loss=1.3585, LR=0.000100
[2025-08-10 15:23:52,110][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028680] [Batch 02836/03692] [00:25:05/00:07:34, 0.531s/it]: train_loss_raw=1.4076, running_loss=1.3547, LR=0.000100
[2025-08-10 15:23:58,157][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028692] [Batch 02848/03692] [00:25:11/00:07:28, 0.531s/it]: train_loss_raw=1.3013, running_loss=1.3507, LR=0.000100
[2025-08-10 15:24:04,263][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028704] [Batch 02860/03692] [00:25:17/00:07:21, 0.531s/it]: train_loss_raw=1.2043, running_loss=1.3495, LR=0.000100
[2025-08-10 15:24:10,365][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028716] [Batch 02872/03692] [00:25:23/00:07:15, 0.531s/it]: train_loss_raw=1.4020, running_loss=1.3519, LR=0.000100
[2025-08-10 15:24:16,477][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028728] [Batch 02884/03692] [00:25:30/00:07:08, 0.531s/it]: train_loss_raw=1.3887, running_loss=1.3520, LR=0.000100
[2025-08-10 15:24:22,625][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028740] [Batch 02896/03692] [00:25:36/00:07:02, 0.530s/it]: train_loss_raw=1.3689, running_loss=1.3513, LR=0.000100
[2025-08-10 15:24:28,849][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028752] [Batch 02908/03692] [00:25:42/00:06:55, 0.530s/it]: train_loss_raw=1.2535, running_loss=1.3510, LR=0.000100
[2025-08-10 15:24:34,969][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028764] [Batch 02920/03692] [00:25:48/00:06:49, 0.530s/it]: train_loss_raw=1.4030, running_loss=1.3525, LR=0.000100
[2025-08-10 15:24:41,121][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028776] [Batch 02932/03692] [00:25:54/00:06:42, 0.530s/it]: train_loss_raw=1.3291, running_loss=1.3572, LR=0.000100
[2025-08-10 15:24:47,387][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028788] [Batch 02944/03692] [00:26:00/00:06:36, 0.530s/it]: train_loss_raw=1.3688, running_loss=1.3566, LR=0.000100
[2025-08-10 15:24:53,591][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028800] [Batch 02956/03692] [00:26:07/00:06:30, 0.530s/it]: train_loss_raw=1.2712, running_loss=1.3545, LR=0.000100
[2025-08-10 15:24:59,790][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028812] [Batch 02968/03692] [00:26:13/00:06:23, 0.530s/it]: train_loss_raw=1.3491, running_loss=1.3575, LR=0.000100
[2025-08-10 15:25:06,041][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028824] [Batch 02980/03692] [00:26:19/00:06:17, 0.530s/it]: train_loss_raw=1.2150, running_loss=1.3532, LR=0.000100
[2025-08-10 15:25:12,290][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028836] [Batch 02992/03692] [00:26:25/00:06:11, 0.530s/it]: train_loss_raw=1.2734, running_loss=1.3514, LR=0.000100
[2025-08-10 15:25:18,647][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028848] [Batch 03004/03692] [00:26:32/00:06:04, 0.530s/it]: train_loss_raw=1.3469, running_loss=1.3466, LR=0.000100
[2025-08-10 15:25:24,889][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028860] [Batch 03016/03692] [00:26:38/00:05:58, 0.530s/it]: train_loss_raw=1.2057, running_loss=1.3457, LR=0.000100
[2025-08-10 15:25:31,125][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028872] [Batch 03028/03692] [00:26:44/00:05:51, 0.530s/it]: train_loss_raw=1.4730, running_loss=1.3446, LR=0.000100
[2025-08-10 15:25:37,384][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028884] [Batch 03040/03692] [00:26:50/00:05:45, 0.530s/it]: train_loss_raw=1.2346, running_loss=1.3461, LR=0.000100
[2025-08-10 15:25:43,550][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028896] [Batch 03052/03692] [00:26:57/00:05:39, 0.530s/it]: train_loss_raw=1.4676, running_loss=1.3476, LR=0.000100
[2025-08-10 15:25:49,620][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028908] [Batch 03064/03692] [00:27:03/00:05:32, 0.530s/it]: train_loss_raw=1.3044, running_loss=1.3492, LR=0.000100
[2025-08-10 15:25:55,904][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028920] [Batch 03076/03692] [00:27:09/00:05:26, 0.530s/it]: train_loss_raw=1.3164, running_loss=1.3503, LR=0.000100
[2025-08-10 15:26:02,263][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028932] [Batch 03088/03692] [00:27:15/00:05:19, 0.530s/it]: train_loss_raw=1.2363, running_loss=1.3484, LR=0.000100
[2025-08-10 15:26:08,511][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028944] [Batch 03100/03692] [00:27:22/00:05:13, 0.530s/it]: train_loss_raw=1.4509, running_loss=1.3522, LR=0.000100
[2025-08-10 15:26:14,781][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028956] [Batch 03112/03692] [00:27:28/00:05:07, 0.530s/it]: train_loss_raw=1.3598, running_loss=1.3501, LR=0.000100
[2025-08-10 15:26:21,034][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028968] [Batch 03124/03692] [00:27:34/00:05:00, 0.530s/it]: train_loss_raw=1.2597, running_loss=1.3466, LR=0.000100
[2025-08-10 15:26:27,466][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028980] [Batch 03136/03692] [00:27:41/00:04:54, 0.530s/it]: train_loss_raw=1.4554, running_loss=1.3444, LR=0.000100
[2025-08-10 15:26:34,120][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028992] [Batch 03148/03692] [00:27:47/00:04:48, 0.530s/it]: train_loss_raw=1.4832, running_loss=1.3470, LR=0.000100
[2025-08-10 15:26:40,661][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029004] [Batch 03160/03692] [00:27:54/00:04:41, 0.530s/it]: train_loss_raw=1.5575, running_loss=1.3510, LR=0.000100
[2025-08-10 15:26:47,271][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029016] [Batch 03172/03692] [00:28:00/00:04:35, 0.530s/it]: train_loss_raw=1.2233, running_loss=1.3479, LR=0.000100
[2025-08-10 15:26:53,964][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029028] [Batch 03184/03692] [00:28:07/00:04:29, 0.530s/it]: train_loss_raw=1.3321, running_loss=1.3498, LR=0.000100
[2025-08-10 15:27:00,457][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029040] [Batch 03196/03692] [00:28:14/00:04:22, 0.530s/it]: train_loss_raw=1.4028, running_loss=1.3495, LR=0.000100
[2025-08-10 15:27:06,785][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029052] [Batch 03208/03692] [00:28:20/00:04:16, 0.530s/it]: train_loss_raw=1.2965, running_loss=1.3437, LR=0.000100
[2025-08-10 15:27:12,999][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029064] [Batch 03220/03692] [00:28:26/00:04:10, 0.530s/it]: train_loss_raw=1.2903, running_loss=1.3459, LR=0.000100
[2025-08-10 15:27:19,412][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029076] [Batch 03232/03692] [00:28:32/00:04:03, 0.530s/it]: train_loss_raw=1.4138, running_loss=1.3499, LR=0.000100
[2025-08-10 15:27:25,666][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029088] [Batch 03244/03692] [00:28:39/00:03:57, 0.530s/it]: train_loss_raw=1.2484, running_loss=1.3478, LR=0.000100
[2025-08-10 15:27:31,941][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029100] [Batch 03256/03692] [00:28:45/00:03:51, 0.530s/it]: train_loss_raw=1.4343, running_loss=1.3484, LR=0.000100
[2025-08-10 15:27:37,992][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029112] [Batch 03268/03692] [00:28:51/00:03:44, 0.530s/it]: train_loss_raw=1.2537, running_loss=1.3451, LR=0.000100
[2025-08-10 15:27:44,062][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029124] [Batch 03280/03692] [00:28:57/00:03:38, 0.530s/it]: train_loss_raw=1.3926, running_loss=1.3443, LR=0.000100
[2025-08-10 15:27:50,176][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029136] [Batch 03292/03692] [00:29:03/00:03:31, 0.530s/it]: train_loss_raw=1.2400, running_loss=1.3412, LR=0.000100
[2025-08-10 15:27:56,507][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029148] [Batch 03304/03692] [00:29:10/00:03:25, 0.530s/it]: train_loss_raw=1.3071, running_loss=1.3347, LR=0.000100
[2025-08-10 15:28:03,157][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029160] [Batch 03316/03692] [00:29:16/00:03:19, 0.530s/it]: train_loss_raw=1.4305, running_loss=1.3375, LR=0.000100
[2025-08-10 15:28:09,747][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029172] [Batch 03328/03692] [00:29:23/00:03:12, 0.530s/it]: train_loss_raw=1.2552, running_loss=1.3351, LR=0.000100
[2025-08-10 15:28:16,252][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029184] [Batch 03340/03692] [00:29:29/00:03:06, 0.530s/it]: train_loss_raw=1.1826, running_loss=1.3320, LR=0.000100
[2025-08-10 15:28:22,728][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029196] [Batch 03352/03692] [00:29:36/00:03:00, 0.530s/it]: train_loss_raw=1.3346, running_loss=1.3311, LR=0.000100
[2025-08-10 15:28:29,280][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029208] [Batch 03364/03692] [00:29:42/00:02:53, 0.530s/it]: train_loss_raw=1.4634, running_loss=1.3328, LR=0.000100
[2025-08-10 15:28:35,849][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029220] [Batch 03376/03692] [00:29:49/00:02:47, 0.530s/it]: train_loss_raw=1.3444, running_loss=1.3340, LR=0.000100
[2025-08-10 15:28:42,394][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029232] [Batch 03388/03692] [00:29:55/00:02:41, 0.530s/it]: train_loss_raw=1.2781, running_loss=1.3319, LR=0.000100
[2025-08-10 15:28:49,025][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029244] [Batch 03400/03692] [00:30:02/00:02:34, 0.530s/it]: train_loss_raw=1.3350, running_loss=1.3319, LR=0.000100
[2025-08-10 15:28:55,233][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029256] [Batch 03412/03692] [00:30:08/00:02:28, 0.530s/it]: train_loss_raw=1.1866, running_loss=1.3282, LR=0.000100
[2025-08-10 15:29:01,302][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029268] [Batch 03424/03692] [00:30:14/00:02:22, 0.530s/it]: train_loss_raw=1.3631, running_loss=1.3264, LR=0.000100
[2025-08-10 15:29:07,811][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029280] [Batch 03436/03692] [00:30:21/00:02:15, 0.530s/it]: train_loss_raw=1.4767, running_loss=1.3277, LR=0.000100
[2025-08-10 15:29:14,385][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029292] [Batch 03448/03692] [00:30:27/00:02:09, 0.530s/it]: train_loss_raw=1.2674, running_loss=1.3310, LR=0.000100
[2025-08-10 15:29:20,709][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029304] [Batch 03460/03692] [00:30:34/00:02:02, 0.530s/it]: train_loss_raw=1.3209, running_loss=1.3332, LR=0.000100
[2025-08-10 15:29:26,963][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029316] [Batch 03472/03692] [00:30:40/00:01:56, 0.530s/it]: train_loss_raw=1.3697, running_loss=1.3296, LR=0.000100
[2025-08-10 15:29:33,424][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029328] [Batch 03484/03692] [00:30:47/00:01:50, 0.530s/it]: train_loss_raw=1.4049, running_loss=1.3333, LR=0.000100
[2025-08-10 15:29:39,529][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029340] [Batch 03496/03692] [00:30:53/00:01:43, 0.530s/it]: train_loss_raw=1.3199, running_loss=1.3336, LR=0.000100
[2025-08-10 15:29:45,560][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029352] [Batch 03508/03692] [00:30:59/00:01:37, 0.530s/it]: train_loss_raw=1.4333, running_loss=1.3372, LR=0.000100
[2025-08-10 15:29:51,760][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029364] [Batch 03520/03692] [00:31:05/00:01:31, 0.530s/it]: train_loss_raw=1.2388, running_loss=1.3392, LR=0.000100
[2025-08-10 15:29:58,294][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029376] [Batch 03532/03692] [00:31:11/00:01:24, 0.530s/it]: train_loss_raw=1.2265, running_loss=1.3359, LR=0.000100
[2025-08-10 15:30:04,651][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029388] [Batch 03544/03692] [00:31:18/00:01:18, 0.530s/it]: train_loss_raw=1.3099, running_loss=1.3350, LR=0.000100
[2025-08-10 15:30:11,245][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029400] [Batch 03556/03692] [00:31:24/00:01:12, 0.530s/it]: train_loss_raw=1.2180, running_loss=1.3381, LR=0.000100
[2025-08-10 15:30:17,837][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029412] [Batch 03568/03692] [00:31:31/00:01:05, 0.530s/it]: train_loss_raw=1.4417, running_loss=1.3425, LR=0.000100
[2025-08-10 15:30:24,384][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029424] [Batch 03580/03692] [00:31:37/00:00:59, 0.530s/it]: train_loss_raw=1.3602, running_loss=1.3431, LR=0.000100
[2025-08-10 15:30:30,892][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029436] [Batch 03592/03692] [00:31:44/00:00:53, 0.530s/it]: train_loss_raw=1.5417, running_loss=1.3436, LR=0.000100
[2025-08-10 15:30:37,414][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029448] [Batch 03604/03692] [00:31:50/00:00:46, 0.530s/it]: train_loss_raw=1.2692, running_loss=1.3427, LR=0.000100
[2025-08-10 15:30:43,718][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029460] [Batch 03616/03692] [00:31:57/00:00:40, 0.530s/it]: train_loss_raw=1.5180, running_loss=1.3453, LR=0.000100
[2025-08-10 15:30:49,981][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029472] [Batch 03628/03692] [00:32:03/00:00:33, 0.530s/it]: train_loss_raw=1.4586, running_loss=1.3435, LR=0.000100
[2025-08-10 15:30:56,417][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029484] [Batch 03640/03692] [00:32:09/00:00:27, 0.530s/it]: train_loss_raw=1.4542, running_loss=1.3421, LR=0.000100
[2025-08-10 15:31:02,874][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029496] [Batch 03652/03692] [00:32:16/00:00:21, 0.530s/it]: train_loss_raw=1.4977, running_loss=1.3418, LR=0.000100
[2025-08-10 15:31:09,434][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029508] [Batch 03664/03692] [00:32:23/00:00:14, 0.530s/it]: train_loss_raw=1.3249, running_loss=1.3400, LR=0.000100
[2025-08-10 15:31:16,092][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029520] [Batch 03676/03692] [00:32:29/00:00:08, 0.530s/it]: train_loss_raw=1.1968, running_loss=1.3400, LR=0.000100
[2025-08-10 15:31:22,617][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029532] [Batch 03688/03692] [00:32:36/00:00:02, 0.530s/it]: train_loss_raw=1.3720, running_loss=1.3399, LR=0.000100
[2025-08-10 15:31:58,495][__main__][INFO] - [VALIDATION] [Epoch 07/29] Starting validation.
[2025-08-10 15:32:36,212][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 029537] [Batch 00011/00025] [00:00:37/00:00:40, 3.143s/it]
[2025-08-10 15:32:54,336][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 029537] [Batch 00023/00025] [00:00:55/00:00:02, 2.327s/it]
[2025-08-10 15:32:55,542][__main__][INFO] - [VALIDATION] [Epoch 07/29] train_loss=1.34014, valid_loss=1.26208
[2025-08-10 15:32:55,542][__main__][INFO] - [VALIDATION] [Epoch 07/29] Metrics:
[2025-08-10 15:32:55,542][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_er      0.557
[2025-08-10 15:32:55,542][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_prec    0.159
[2025-08-10 15:32:55,542][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_recall  0.166
[2025-08-10 15:32:55,544][__main__][INFO] - [VALIDATION] [Epoch 07/29] - pep_recall 0.123
[2025-08-10 15:32:55,547][__main__][INFO] - [TRAIN] [Epoch 07/29] Epoch complete, total time 04:36:54, remaining time 12:41:30, 00:34:36 per epoch
[2025-08-10 15:32:59,756][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029544] [Batch 00008/03692] [00:00:03/00:30:08, 0.491s/it]: train_loss_raw=1.2689, running_loss=1.4035, LR=0.000100
[2025-08-10 15:33:06,194][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029556] [Batch 00020/03692] [00:00:10/00:31:42, 0.518s/it]: train_loss_raw=1.3234, running_loss=1.3938, LR=0.000100
[2025-08-10 15:33:12,681][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029568] [Batch 00032/03692] [00:00:16/00:32:07, 0.527s/it]: train_loss_raw=1.3905, running_loss=1.3865, LR=0.000100
[2025-08-10 15:33:19,245][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029580] [Batch 00044/03692] [00:00:23/00:32:21, 0.532s/it]: train_loss_raw=1.2023, running_loss=1.3794, LR=0.000100
[2025-08-10 15:33:25,799][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029592] [Batch 00056/03692] [00:00:29/00:32:25, 0.535s/it]: train_loss_raw=1.4345, running_loss=1.3747, LR=0.000100
[2025-08-10 15:33:32,306][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029604] [Batch 00068/03692] [00:00:36/00:32:23, 0.536s/it]: train_loss_raw=1.2565, running_loss=1.3658, LR=0.000100
[2025-08-10 15:33:38,871][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029616] [Batch 00080/03692] [00:00:43/00:32:23, 0.538s/it]: train_loss_raw=1.2694, running_loss=1.3601, LR=0.000100
[2025-08-10 15:33:45,495][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029628] [Batch 00092/03692] [00:00:49/00:32:23, 0.540s/it]: train_loss_raw=1.3281, running_loss=1.3555, LR=0.000100
[2025-08-10 15:33:52,026][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029640] [Batch 00104/03692] [00:00:56/00:32:18, 0.540s/it]: train_loss_raw=1.3174, running_loss=1.3495, LR=0.000100
[2025-08-10 15:33:58,165][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029652] [Batch 00116/03692] [00:01:02/00:32:01, 0.537s/it]: train_loss_raw=1.2739, running_loss=1.3421, LR=0.000100
[2025-08-10 15:34:04,209][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029664] [Batch 00128/03692] [00:01:08/00:31:43, 0.534s/it]: train_loss_raw=1.4437, running_loss=1.3409, LR=0.000100
[2025-08-10 15:34:10,657][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029676] [Batch 00140/03692] [00:01:14/00:31:38, 0.534s/it]: train_loss_raw=1.3545, running_loss=1.3410, LR=0.000100
[2025-08-10 15:34:17,209][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029688] [Batch 00152/03692] [00:01:21/00:31:35, 0.535s/it]: train_loss_raw=1.4814, running_loss=1.3408, LR=0.000100
[2025-08-10 15:34:23,705][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029700] [Batch 00164/03692] [00:01:27/00:31:30, 0.536s/it]: train_loss_raw=1.2217, running_loss=1.3345, LR=0.000100
[2025-08-10 15:34:29,817][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029712] [Batch 00176/03692] [00:01:33/00:31:17, 0.534s/it]: train_loss_raw=1.2693, running_loss=1.3349, LR=0.000100
[2025-08-10 15:34:35,957][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029724] [Batch 00188/03692] [00:01:40/00:31:06, 0.533s/it]: train_loss_raw=1.3164, running_loss=1.3318, LR=0.000100
[2025-08-10 15:34:42,187][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029736] [Batch 00200/03692] [00:01:46/00:30:57, 0.532s/it]: train_loss_raw=1.2543, running_loss=1.3237, LR=0.000100
[2025-08-10 15:34:48,827][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029748] [Batch 00212/03692] [00:01:52/00:30:54, 0.533s/it]: train_loss_raw=1.3733, running_loss=1.3216, LR=0.000100
[2025-08-10 15:34:55,449][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029760] [Batch 00224/03692] [00:01:59/00:30:51, 0.534s/it]: train_loss_raw=1.4018, running_loss=1.3236, LR=0.000100
[2025-08-10 15:35:01,753][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029772] [Batch 00236/03692] [00:02:05/00:30:44, 0.534s/it]: train_loss_raw=1.4257, running_loss=1.3212, LR=0.000100
[2025-08-10 15:35:08,189][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029784] [Batch 00248/03692] [00:02:12/00:30:38, 0.534s/it]: train_loss_raw=1.2669, running_loss=1.3239, LR=0.000100
[2025-08-10 15:35:14,812][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029796] [Batch 00260/03692] [00:02:18/00:30:34, 0.535s/it]: train_loss_raw=1.4060, running_loss=1.3284, LR=0.000100
[2025-08-10 15:35:21,464][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029808] [Batch 00272/03692] [00:02:25/00:30:31, 0.535s/it]: train_loss_raw=1.3575, running_loss=1.3324, LR=0.000100
[2025-08-10 15:35:28,066][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029820] [Batch 00284/03692] [00:02:32/00:30:26, 0.536s/it]: train_loss_raw=1.3784, running_loss=1.3288, LR=0.000100
[2025-08-10 15:35:34,657][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029832] [Batch 00296/03692] [00:02:38/00:30:22, 0.537s/it]: train_loss_raw=1.3684, running_loss=1.3293, LR=0.000100
[2025-08-10 15:35:40,998][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029844] [Batch 00308/03692] [00:02:45/00:30:14, 0.536s/it]: train_loss_raw=1.3766, running_loss=1.3319, LR=0.000100
[2025-08-10 15:35:47,293][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029856] [Batch 00320/03692] [00:02:51/00:30:06, 0.536s/it]: train_loss_raw=1.3774, running_loss=1.3317, LR=0.000100
[2025-08-10 15:35:53,377][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029868] [Batch 00332/03692] [00:02:57/00:29:56, 0.535s/it]: train_loss_raw=1.4349, running_loss=1.3305, LR=0.000100
[2025-08-10 15:35:59,501][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029880] [Batch 00344/03692] [00:03:03/00:29:47, 0.534s/it]: train_loss_raw=1.4404, running_loss=1.3335, LR=0.000100
[2025-08-10 15:36:05,538][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029892] [Batch 00356/03692] [00:03:09/00:29:37, 0.533s/it]: train_loss_raw=1.3133, running_loss=1.3323, LR=0.000100
[2025-08-10 15:36:11,609][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029904] [Batch 00368/03692] [00:03:15/00:29:28, 0.532s/it]: train_loss_raw=1.3723, running_loss=1.3296, LR=0.000100
[2025-08-10 15:36:17,782][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029916] [Batch 00380/03692] [00:03:21/00:29:20, 0.531s/it]: train_loss_raw=1.3552, running_loss=1.3303, LR=0.000100
[2025-08-10 15:36:23,905][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029928] [Batch 00392/03692] [00:03:28/00:29:11, 0.531s/it]: train_loss_raw=1.4148, running_loss=1.3270, LR=0.000100
[2025-08-10 15:36:30,035][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029940] [Batch 00404/03692] [00:03:34/00:29:03, 0.530s/it]: train_loss_raw=1.3466, running_loss=1.3274, LR=0.000100
[2025-08-10 15:36:36,064][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029952] [Batch 00416/03692] [00:03:40/00:28:54, 0.529s/it]: train_loss_raw=1.2035, running_loss=1.3248, LR=0.000100
[2025-08-10 15:36:42,260][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029964] [Batch 00428/03692] [00:03:46/00:28:46, 0.529s/it]: train_loss_raw=1.3510, running_loss=1.3279, LR=0.000100
[2025-08-10 15:36:48,347][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029976] [Batch 00440/03692] [00:03:52/00:28:38, 0.528s/it]: train_loss_raw=1.2304, running_loss=1.3235, LR=0.000100
[2025-08-10 15:36:54,417][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029988] [Batch 00452/03692] [00:03:58/00:28:30, 0.528s/it]: train_loss_raw=1.3899, running_loss=1.3251, LR=0.000100
[2025-08-10 15:37:00,476][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030000] [Batch 00464/03692] [00:04:04/00:28:21, 0.527s/it]: train_loss_raw=1.3114, running_loss=1.3239, LR=0.000100
[2025-08-10 15:37:12,581][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030012] [Batch 00476/03692] [00:04:16/00:28:54, 0.539s/it]: train_loss_raw=1.3969, running_loss=1.3188, LR=0.000100
[2025-08-10 15:37:19,111][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030024] [Batch 00488/03692] [00:04:23/00:28:48, 0.540s/it]: train_loss_raw=1.4580, running_loss=1.3214, LR=0.000100
[2025-08-10 15:37:25,635][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030036] [Batch 00500/03692] [00:04:29/00:28:42, 0.540s/it]: train_loss_raw=1.3725, running_loss=1.3250, LR=0.000100
[2025-08-10 15:37:32,269][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030048] [Batch 00512/03692] [00:04:36/00:28:36, 0.540s/it]: train_loss_raw=1.3105, running_loss=1.3252, LR=0.000100
[2025-08-10 15:37:38,808][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030060] [Batch 00524/03692] [00:04:42/00:28:30, 0.540s/it]: train_loss_raw=1.2801, running_loss=1.3242, LR=0.000100
[2025-08-10 15:37:45,109][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030072] [Batch 00536/03692] [00:04:49/00:28:23, 0.540s/it]: train_loss_raw=1.3763, running_loss=1.3235, LR=0.000100
[2025-08-10 15:37:51,203][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030084] [Batch 00548/03692] [00:04:55/00:28:14, 0.539s/it]: train_loss_raw=1.3068, running_loss=1.3212, LR=0.000100
[2025-08-10 15:37:57,680][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030096] [Batch 00560/03692] [00:05:01/00:28:08, 0.539s/it]: train_loss_raw=1.3185, running_loss=1.3239, LR=0.000100
[2025-08-10 15:38:04,325][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030108] [Batch 00572/03692] [00:05:08/00:28:02, 0.539s/it]: train_loss_raw=1.2267, running_loss=1.3253, LR=0.000100
[2025-08-10 15:38:10,373][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030120] [Batch 00584/03692] [00:05:14/00:27:53, 0.539s/it]: train_loss_raw=1.3383, running_loss=1.3227, LR=0.000100
[2025-08-10 15:38:16,570][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030132] [Batch 00596/03692] [00:05:20/00:27:46, 0.538s/it]: train_loss_raw=1.2352, running_loss=1.3202, LR=0.000100
[2025-08-10 15:38:23,186][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030144] [Batch 00608/03692] [00:05:27/00:27:40, 0.538s/it]: train_loss_raw=1.3601, running_loss=1.3225, LR=0.000100
[2025-08-10 15:38:29,548][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030156] [Batch 00620/03692] [00:05:33/00:27:33, 0.538s/it]: train_loss_raw=1.4455, running_loss=1.3208, LR=0.000100
[2025-08-10 15:38:35,958][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030168] [Batch 00632/03692] [00:05:40/00:27:26, 0.538s/it]: train_loss_raw=1.2940, running_loss=1.3228, LR=0.000100
[2025-08-10 15:38:42,097][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030180] [Batch 00644/03692] [00:05:46/00:27:18, 0.538s/it]: train_loss_raw=1.3779, running_loss=1.3207, LR=0.000100
[2025-08-10 15:38:48,607][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030192] [Batch 00656/03692] [00:05:52/00:27:12, 0.538s/it]: train_loss_raw=1.3485, running_loss=1.3190, LR=0.000100
[2025-08-10 15:38:55,177][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030204] [Batch 00668/03692] [00:05:59/00:27:06, 0.538s/it]: train_loss_raw=1.4549, running_loss=1.3235, LR=0.000100
[2025-08-10 15:39:01,791][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030216] [Batch 00680/03692] [00:06:05/00:27:00, 0.538s/it]: train_loss_raw=1.4797, running_loss=1.3243, LR=0.000100
[2025-08-10 15:39:08,093][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030228] [Batch 00692/03692] [00:06:12/00:26:53, 0.538s/it]: train_loss_raw=1.1915, running_loss=1.3195, LR=0.000100
[2025-08-10 15:39:14,179][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030240] [Batch 00704/03692] [00:06:18/00:26:45, 0.537s/it]: train_loss_raw=1.1815, running_loss=1.3204, LR=0.000100
[2025-08-10 15:39:20,359][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030252] [Batch 00716/03692] [00:06:24/00:26:38, 0.537s/it]: train_loss_raw=1.3165, running_loss=1.3176, LR=0.000100
[2025-08-10 15:39:26,530][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030264] [Batch 00728/03692] [00:06:30/00:26:30, 0.537s/it]: train_loss_raw=1.4281, running_loss=1.3156, LR=0.000100
[2025-08-10 15:39:32,606][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030276] [Batch 00740/03692] [00:06:36/00:26:22, 0.536s/it]: train_loss_raw=1.3177, running_loss=1.3108, LR=0.000100
[2025-08-10 15:39:38,808][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030288] [Batch 00752/03692] [00:06:42/00:26:15, 0.536s/it]: train_loss_raw=1.2796, running_loss=1.3131, LR=0.000100
[2025-08-10 15:39:45,063][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030300] [Batch 00764/03692] [00:06:49/00:26:08, 0.536s/it]: train_loss_raw=1.3167, running_loss=1.3054, LR=0.000100
[2025-08-10 15:39:51,189][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030312] [Batch 00776/03692] [00:06:55/00:26:00, 0.535s/it]: train_loss_raw=1.2994, running_loss=1.3028, LR=0.000100
[2025-08-10 15:39:57,518][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030324] [Batch 00788/03692] [00:07:01/00:25:54, 0.535s/it]: train_loss_raw=1.2902, running_loss=1.3038, LR=0.000100
[2025-08-10 15:40:04,057][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030336] [Batch 00800/03692] [00:07:08/00:25:48, 0.535s/it]: train_loss_raw=1.3190, running_loss=1.3007, LR=0.000100
[2025-08-10 15:40:10,661][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030348] [Batch 00812/03692] [00:07:14/00:25:42, 0.536s/it]: train_loss_raw=1.3172, running_loss=1.3024, LR=0.000100
[2025-08-10 15:40:17,205][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030360] [Batch 00824/03692] [00:07:21/00:25:36, 0.536s/it]: train_loss_raw=1.4301, running_loss=1.3046, LR=0.000100
[2025-08-10 15:40:23,774][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030372] [Batch 00836/03692] [00:07:27/00:25:30, 0.536s/it]: train_loss_raw=1.3306, running_loss=1.3067, LR=0.000100
[2025-08-10 15:40:30,353][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030384] [Batch 00848/03692] [00:07:34/00:25:24, 0.536s/it]: train_loss_raw=1.4169, running_loss=1.3033, LR=0.000100
[2025-08-10 15:40:36,935][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030396] [Batch 00860/03692] [00:07:41/00:25:18, 0.536s/it]: train_loss_raw=1.2814, running_loss=1.3031, LR=0.000100
[2025-08-10 15:40:43,572][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030408] [Batch 00872/03692] [00:07:47/00:25:12, 0.536s/it]: train_loss_raw=1.2569, running_loss=1.3053, LR=0.000100
[2025-08-10 15:40:50,118][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030420] [Batch 00884/03692] [00:07:54/00:25:06, 0.537s/it]: train_loss_raw=1.2985, running_loss=1.3073, LR=0.000100
[2025-08-10 15:40:56,675][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030432] [Batch 00896/03692] [00:08:00/00:25:00, 0.537s/it]: train_loss_raw=1.2292, running_loss=1.3036, LR=0.000100
[2025-08-10 15:41:02,709][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030444] [Batch 00908/03692] [00:08:06/00:24:52, 0.536s/it]: train_loss_raw=1.3815, running_loss=1.2997, LR=0.000100
[2025-08-10 15:41:08,788][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030456] [Batch 00920/03692] [00:08:12/00:24:45, 0.536s/it]: train_loss_raw=1.3174, running_loss=1.3051, LR=0.000100
[2025-08-10 15:41:15,269][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030468] [Batch 00932/03692] [00:08:19/00:24:39, 0.536s/it]: train_loss_raw=1.4823, running_loss=1.3078, LR=0.000100
[2025-08-10 15:41:21,688][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030480] [Batch 00944/03692] [00:08:25/00:24:32, 0.536s/it]: train_loss_raw=1.4045, running_loss=1.3050, LR=0.000100
[2025-08-10 15:41:28,109][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030492] [Batch 00956/03692] [00:08:32/00:24:26, 0.536s/it]: train_loss_raw=1.3557, running_loss=1.3001, LR=0.000100
[2025-08-10 15:41:34,480][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030504] [Batch 00968/03692] [00:08:38/00:24:19, 0.536s/it]: train_loss_raw=1.3211, running_loss=1.3039, LR=0.000100
[2025-08-10 15:41:40,922][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030516] [Batch 00980/03692] [00:08:45/00:24:13, 0.536s/it]: train_loss_raw=1.4432, running_loss=1.3036, LR=0.000100
[2025-08-10 15:41:47,038][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030528] [Batch 00992/03692] [00:08:51/00:24:05, 0.535s/it]: train_loss_raw=1.3096, running_loss=1.3051, LR=0.000100
[2025-08-10 15:41:53,181][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030540] [Batch 01004/03692] [00:08:57/00:23:58, 0.535s/it]: train_loss_raw=1.3004, running_loss=1.3049, LR=0.000100
[2025-08-10 15:41:59,727][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030552] [Batch 01016/03692] [00:09:03/00:23:52, 0.535s/it]: train_loss_raw=1.3549, running_loss=1.3063, LR=0.000100
[2025-08-10 15:42:06,214][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030564] [Batch 01028/03692] [00:09:10/00:23:46, 0.535s/it]: train_loss_raw=1.4048, running_loss=1.3056, LR=0.000100
[2025-08-10 15:42:12,797][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030576] [Batch 01040/03692] [00:09:16/00:23:40, 0.536s/it]: train_loss_raw=1.3790, running_loss=1.3052, LR=0.000100
[2025-08-10 15:42:19,347][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030588] [Batch 01052/03692] [00:09:23/00:23:34, 0.536s/it]: train_loss_raw=1.2391, running_loss=1.3015, LR=0.000100
[2025-08-10 15:42:25,996][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030600] [Batch 01064/03692] [00:09:30/00:23:28, 0.536s/it]: train_loss_raw=1.2352, running_loss=1.3056, LR=0.000100
[2025-08-10 15:42:32,120][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030612] [Batch 01076/03692] [00:09:36/00:23:21, 0.536s/it]: train_loss_raw=1.2058, running_loss=1.3041, LR=0.000100
[2025-08-10 15:42:38,341][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030624] [Batch 01088/03692] [00:09:42/00:23:14, 0.535s/it]: train_loss_raw=1.1465, running_loss=1.3004, LR=0.000100
[2025-08-10 15:42:44,588][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030636] [Batch 01100/03692] [00:09:48/00:23:07, 0.535s/it]: train_loss_raw=1.3152, running_loss=1.2973, LR=0.000100
[2025-08-10 15:42:50,735][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030648] [Batch 01112/03692] [00:09:54/00:23:00, 0.535s/it]: train_loss_raw=1.3933, running_loss=1.3020, LR=0.000100
[2025-08-10 15:42:57,078][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030660] [Batch 01124/03692] [00:10:01/00:22:53, 0.535s/it]: train_loss_raw=1.3530, running_loss=1.3024, LR=0.000100
[2025-08-10 15:43:03,609][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030672] [Batch 01136/03692] [00:10:07/00:22:47, 0.535s/it]: train_loss_raw=1.1796, running_loss=1.3029, LR=0.000100
[2025-08-10 15:43:10,163][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030684] [Batch 01148/03692] [00:10:14/00:22:41, 0.535s/it]: train_loss_raw=1.2412, running_loss=1.3036, LR=0.000100
[2025-08-10 15:43:16,684][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030696] [Batch 01160/03692] [00:10:20/00:22:35, 0.535s/it]: train_loss_raw=1.2722, running_loss=1.2991, LR=0.000100
[2025-08-10 15:43:22,969][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030708] [Batch 01172/03692] [00:10:27/00:22:28, 0.535s/it]: train_loss_raw=1.4134, running_loss=1.2992, LR=0.000100
[2025-08-10 15:43:28,993][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030720] [Batch 01184/03692] [00:10:33/00:22:21, 0.535s/it]: train_loss_raw=1.2986, running_loss=1.2997, LR=0.000100
[2025-08-10 15:43:35,099][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030732] [Batch 01196/03692] [00:10:39/00:22:14, 0.535s/it]: train_loss_raw=1.2213, running_loss=1.3017, LR=0.000100
[2025-08-10 15:43:41,162][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030744] [Batch 01208/03692] [00:10:45/00:22:06, 0.534s/it]: train_loss_raw=1.3219, running_loss=1.3003, LR=0.000100
[2025-08-10 15:43:47,492][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030756] [Batch 01220/03692] [00:10:51/00:22:00, 0.534s/it]: train_loss_raw=1.3320, running_loss=1.3055, LR=0.000100
[2025-08-10 15:43:53,811][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030768] [Batch 01232/03692] [00:10:57/00:21:53, 0.534s/it]: train_loss_raw=1.1654, running_loss=1.3035, LR=0.000100
[2025-08-10 15:44:00,325][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030780] [Batch 01244/03692] [00:11:04/00:21:47, 0.534s/it]: train_loss_raw=1.3778, running_loss=1.3073, LR=0.000100
[2025-08-10 15:44:06,969][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030792] [Batch 01256/03692] [00:11:11/00:21:41, 0.534s/it]: train_loss_raw=1.2679, running_loss=1.3066, LR=0.000100
[2025-08-10 15:44:13,510][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030804] [Batch 01268/03692] [00:11:17/00:21:35, 0.534s/it]: train_loss_raw=1.2602, running_loss=1.3050, LR=0.000100
[2025-08-10 15:44:20,121][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030816] [Batch 01280/03692] [00:11:24/00:21:29, 0.535s/it]: train_loss_raw=1.2545, running_loss=1.3050, LR=0.000100
[2025-08-10 15:44:26,826][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030828] [Batch 01292/03692] [00:11:30/00:21:23, 0.535s/it]: train_loss_raw=1.4098, running_loss=1.3087, LR=0.000100
[2025-08-10 15:44:33,199][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030840] [Batch 01304/03692] [00:11:37/00:21:17, 0.535s/it]: train_loss_raw=1.4484, running_loss=1.3053, LR=0.000100
[2025-08-10 15:44:39,405][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030852] [Batch 01316/03692] [00:11:43/00:21:10, 0.535s/it]: train_loss_raw=1.3508, running_loss=1.3055, LR=0.000100
[2025-08-10 15:44:45,929][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030864] [Batch 01328/03692] [00:11:50/00:21:04, 0.535s/it]: train_loss_raw=1.2614, running_loss=1.3045, LR=0.000100
[2025-08-10 15:44:52,448][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030876] [Batch 01340/03692] [00:11:56/00:20:57, 0.535s/it]: train_loss_raw=1.2882, running_loss=1.3031, LR=0.000100
[2025-08-10 15:44:59,046][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030888] [Batch 01352/03692] [00:12:03/00:20:51, 0.535s/it]: train_loss_raw=1.2553, running_loss=1.3018, LR=0.000100
[2025-08-10 15:45:05,583][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030900] [Batch 01364/03692] [00:12:09/00:20:45, 0.535s/it]: train_loss_raw=1.3615, running_loss=1.2987, LR=0.000100
[2025-08-10 15:45:12,101][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030912] [Batch 01376/03692] [00:12:16/00:20:39, 0.535s/it]: train_loss_raw=1.2507, running_loss=1.2981, LR=0.000100
[2025-08-10 15:45:18,295][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030924] [Batch 01388/03692] [00:12:22/00:20:32, 0.535s/it]: train_loss_raw=1.2768, running_loss=1.2992, LR=0.000100
[2025-08-10 15:45:24,399][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030936] [Batch 01400/03692] [00:12:28/00:20:25, 0.535s/it]: train_loss_raw=1.4242, running_loss=1.3031, LR=0.000100
[2025-08-10 15:45:30,585][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030948] [Batch 01412/03692] [00:12:34/00:20:18, 0.535s/it]: train_loss_raw=1.3534, running_loss=1.3014, LR=0.000100
[2025-08-10 15:45:36,704][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030960] [Batch 01424/03692] [00:12:40/00:20:11, 0.534s/it]: train_loss_raw=1.4223, running_loss=1.2981, LR=0.000100
[2025-08-10 15:45:42,902][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030972] [Batch 01436/03692] [00:12:47/00:20:05, 0.534s/it]: train_loss_raw=1.2504, running_loss=1.3007, LR=0.000100
[2025-08-10 15:45:49,074][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030984] [Batch 01448/03692] [00:12:53/00:19:58, 0.534s/it]: train_loss_raw=1.3312, running_loss=1.2975, LR=0.000100
[2025-08-10 15:45:55,603][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030996] [Batch 01460/03692] [00:12:59/00:19:52, 0.534s/it]: train_loss_raw=1.3172, running_loss=1.2998, LR=0.000100
[2025-08-10 15:46:01,677][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031008] [Batch 01472/03692] [00:13:05/00:19:45, 0.534s/it]: train_loss_raw=1.2216, running_loss=1.2950, LR=0.000100
[2025-08-10 15:46:07,816][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031020] [Batch 01484/03692] [00:13:11/00:19:38, 0.534s/it]: train_loss_raw=1.2764, running_loss=1.2928, LR=0.000100
[2025-08-10 15:46:13,941][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031032] [Batch 01496/03692] [00:13:18/00:19:31, 0.533s/it]: train_loss_raw=1.3141, running_loss=1.2928, LR=0.000100
[2025-08-10 15:46:20,045][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031044] [Batch 01508/03692] [00:13:24/00:19:24, 0.533s/it]: train_loss_raw=1.2639, running_loss=1.2891, LR=0.000100
[2025-08-10 15:46:26,174][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031056] [Batch 01520/03692] [00:13:30/00:19:17, 0.533s/it]: train_loss_raw=1.4129, running_loss=1.2944, LR=0.000100
[2025-08-10 15:46:32,240][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031068] [Batch 01532/03692] [00:13:36/00:19:11, 0.533s/it]: train_loss_raw=1.3312, running_loss=1.2957, LR=0.000100
[2025-08-10 15:46:38,304][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031080] [Batch 01544/03692] [00:13:42/00:19:04, 0.533s/it]: train_loss_raw=1.2308, running_loss=1.2947, LR=0.000100
[2025-08-10 15:46:44,395][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031092] [Batch 01556/03692] [00:13:48/00:18:57, 0.532s/it]: train_loss_raw=1.3951, running_loss=1.2963, LR=0.000100
[2025-08-10 15:46:50,418][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031104] [Batch 01568/03692] [00:13:54/00:18:50, 0.532s/it]: train_loss_raw=1.1997, running_loss=1.2929, LR=0.000100
[2025-08-10 15:46:56,447][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031116] [Batch 01580/03692] [00:14:00/00:18:43, 0.532s/it]: train_loss_raw=1.3431, running_loss=1.2919, LR=0.000100
[2025-08-10 15:47:02,507][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031128] [Batch 01592/03692] [00:14:06/00:18:36, 0.532s/it]: train_loss_raw=1.3655, running_loss=1.2938, LR=0.000100
[2025-08-10 15:47:08,863][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031140] [Batch 01604/03692] [00:14:13/00:18:30, 0.532s/it]: train_loss_raw=1.3233, running_loss=1.2997, LR=0.000100
[2025-08-10 15:47:15,450][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031152] [Batch 01616/03692] [00:14:19/00:18:24, 0.532s/it]: train_loss_raw=1.3176, running_loss=1.3020, LR=0.000100
[2025-08-10 15:47:22,042][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031164] [Batch 01628/03692] [00:14:26/00:18:18, 0.532s/it]: train_loss_raw=1.3070, running_loss=1.3012, LR=0.000100
[2025-08-10 15:47:28,609][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031176] [Batch 01640/03692] [00:14:32/00:18:12, 0.532s/it]: train_loss_raw=1.3098, running_loss=1.2973, LR=0.000100
[2025-08-10 15:47:35,223][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031188] [Batch 01652/03692] [00:14:39/00:18:05, 0.532s/it]: train_loss_raw=1.2128, running_loss=1.2969, LR=0.000100
[2025-08-10 15:47:41,778][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031200] [Batch 01664/03692] [00:14:45/00:17:59, 0.532s/it]: train_loss_raw=1.2960, running_loss=1.3008, LR=0.000100
[2025-08-10 15:47:48,429][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031212] [Batch 01676/03692] [00:14:52/00:17:53, 0.533s/it]: train_loss_raw=1.2234, running_loss=1.3023, LR=0.000100
[2025-08-10 15:47:54,975][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031224] [Batch 01688/03692] [00:14:59/00:17:47, 0.533s/it]: train_loss_raw=1.1297, running_loss=1.2998, LR=0.000100
[2025-08-10 15:48:01,599][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031236] [Batch 01700/03692] [00:15:05/00:17:41, 0.533s/it]: train_loss_raw=1.4450, running_loss=1.3033, LR=0.000100
[2025-08-10 15:48:08,247][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031248] [Batch 01712/03692] [00:15:12/00:17:35, 0.533s/it]: train_loss_raw=1.2934, running_loss=1.3009, LR=0.000100
[2025-08-10 15:48:14,824][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031260] [Batch 01724/03692] [00:15:18/00:17:29, 0.533s/it]: train_loss_raw=1.2437, running_loss=1.3000, LR=0.000100
[2025-08-10 15:48:21,220][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031272] [Batch 01736/03692] [00:15:25/00:17:22, 0.533s/it]: train_loss_raw=1.2114, running_loss=1.3002, LR=0.000100
[2025-08-10 15:48:27,272][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031284] [Batch 01748/03692] [00:15:31/00:17:15, 0.533s/it]: train_loss_raw=1.4181, running_loss=1.3029, LR=0.000100
[2025-08-10 15:48:33,338][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031296] [Batch 01760/03692] [00:15:37/00:17:09, 0.533s/it]: train_loss_raw=1.3612, running_loss=1.3014, LR=0.000100
[2025-08-10 15:48:39,444][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031308] [Batch 01772/03692] [00:15:43/00:17:02, 0.533s/it]: train_loss_raw=1.3327, running_loss=1.3036, LR=0.000100
[2025-08-10 15:48:45,556][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031320] [Batch 01784/03692] [00:15:49/00:16:55, 0.532s/it]: train_loss_raw=1.3199, running_loss=1.2962, LR=0.000100
[2025-08-10 15:48:51,584][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031332] [Batch 01796/03692] [00:15:55/00:16:48, 0.532s/it]: train_loss_raw=1.3511, running_loss=1.2964, LR=0.000100
[2025-08-10 15:48:57,664][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031344] [Batch 01808/03692] [00:16:01/00:16:42, 0.532s/it]: train_loss_raw=1.3409, running_loss=1.2943, LR=0.000100
[2025-08-10 15:49:03,784][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031356] [Batch 01820/03692] [00:16:07/00:16:35, 0.532s/it]: train_loss_raw=1.2925, running_loss=1.2911, LR=0.000100
[2025-08-10 15:49:09,834][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031368] [Batch 01832/03692] [00:16:14/00:16:28, 0.532s/it]: train_loss_raw=1.2577, running_loss=1.2930, LR=0.000100
[2025-08-10 15:49:15,892][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031380] [Batch 01844/03692] [00:16:20/00:16:22, 0.531s/it]: train_loss_raw=1.3268, running_loss=1.2918, LR=0.000100
[2025-08-10 15:49:22,010][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031392] [Batch 01856/03692] [00:16:26/00:16:15, 0.531s/it]: train_loss_raw=1.3588, running_loss=1.2943, LR=0.000100
[2025-08-10 15:49:28,180][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031404] [Batch 01868/03692] [00:16:32/00:16:08, 0.531s/it]: train_loss_raw=1.3610, running_loss=1.2998, LR=0.000100
[2025-08-10 15:49:34,633][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031416] [Batch 01880/03692] [00:16:38/00:16:02, 0.531s/it]: train_loss_raw=1.2955, running_loss=1.3006, LR=0.000100
[2025-08-10 15:49:40,695][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031428] [Batch 01892/03692] [00:16:44/00:15:56, 0.531s/it]: train_loss_raw=1.4256, running_loss=1.2983, LR=0.000100
[2025-08-10 15:49:47,039][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031440] [Batch 01904/03692] [00:16:51/00:15:49, 0.531s/it]: train_loss_raw=1.2856, running_loss=1.2955, LR=0.000100
[2025-08-10 15:49:53,689][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031452] [Batch 01916/03692] [00:16:57/00:15:43, 0.531s/it]: train_loss_raw=1.2455, running_loss=1.2938, LR=0.000100
[2025-08-10 15:50:00,177][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031464] [Batch 01928/03692] [00:17:04/00:15:37, 0.531s/it]: train_loss_raw=1.3028, running_loss=1.2961, LR=0.000100
[2025-08-10 15:50:06,674][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031476] [Batch 01940/03692] [00:17:10/00:15:30, 0.531s/it]: train_loss_raw=1.2965, running_loss=1.2935, LR=0.000100
[2025-08-10 15:50:13,247][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031488] [Batch 01952/03692] [00:17:17/00:15:24, 0.531s/it]: train_loss_raw=1.1825, running_loss=1.2873, LR=0.000100
[2025-08-10 15:50:19,832][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031500] [Batch 01964/03692] [00:17:24/00:15:18, 0.532s/it]: train_loss_raw=1.3394, running_loss=1.2876, LR=0.000100
[2025-08-10 15:50:26,398][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031512] [Batch 01976/03692] [00:17:30/00:15:12, 0.532s/it]: train_loss_raw=1.3547, running_loss=1.2877, LR=0.000100
[2025-08-10 15:50:32,904][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031524] [Batch 01988/03692] [00:17:37/00:15:06, 0.532s/it]: train_loss_raw=1.3239, running_loss=1.2869, LR=0.000100
[2025-08-10 15:50:39,348][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031536] [Batch 02000/03692] [00:17:43/00:14:59, 0.532s/it]: train_loss_raw=1.1579, running_loss=1.2853, LR=0.000100
[2025-08-10 15:50:45,859][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031548] [Batch 02012/03692] [00:17:50/00:14:53, 0.532s/it]: train_loss_raw=1.2609, running_loss=1.2865, LR=0.000100
[2025-08-10 15:50:52,451][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031560] [Batch 02024/03692] [00:17:56/00:14:47, 0.532s/it]: train_loss_raw=1.2457, running_loss=1.2856, LR=0.000100
[2025-08-10 15:50:58,997][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031572] [Batch 02036/03692] [00:18:03/00:14:41, 0.532s/it]: train_loss_raw=1.2132, running_loss=1.2846, LR=0.000100
[2025-08-10 15:51:05,669][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031584] [Batch 02048/03692] [00:18:09/00:14:34, 0.532s/it]: train_loss_raw=1.2872, running_loss=1.2853, LR=0.000100
[2025-08-10 15:51:12,260][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031596] [Batch 02060/03692] [00:18:16/00:14:28, 0.532s/it]: train_loss_raw=1.1739, running_loss=1.2830, LR=0.000100
[2025-08-10 15:51:18,570][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031608] [Batch 02072/03692] [00:18:22/00:14:22, 0.532s/it]: train_loss_raw=1.3634, running_loss=1.2826, LR=0.000100
[2025-08-10 15:51:24,774][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031620] [Batch 02084/03692] [00:18:28/00:14:15, 0.532s/it]: train_loss_raw=1.2151, running_loss=1.2860, LR=0.000100
[2025-08-10 15:51:30,920][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031632] [Batch 02096/03692] [00:18:35/00:14:09, 0.532s/it]: train_loss_raw=1.2864, running_loss=1.2869, LR=0.000100
[2025-08-10 15:51:37,078][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031644] [Batch 02108/03692] [00:18:41/00:14:02, 0.532s/it]: train_loss_raw=1.3304, running_loss=1.2825, LR=0.000100
[2025-08-10 15:51:43,601][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031656] [Batch 02120/03692] [00:18:47/00:13:56, 0.532s/it]: train_loss_raw=1.2822, running_loss=1.2857, LR=0.000100
[2025-08-10 15:51:50,150][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031668] [Batch 02132/03692] [00:18:54/00:13:49, 0.532s/it]: train_loss_raw=1.2136, running_loss=1.2844, LR=0.000100
[2025-08-10 15:51:56,457][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031680] [Batch 02144/03692] [00:19:00/00:13:43, 0.532s/it]: train_loss_raw=1.2852, running_loss=1.2850, LR=0.000100
[2025-08-10 15:52:02,636][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031692] [Batch 02156/03692] [00:19:06/00:13:37, 0.532s/it]: train_loss_raw=1.2029, running_loss=1.2888, LR=0.000100
[2025-08-10 15:52:09,060][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031704] [Batch 02168/03692] [00:19:13/00:13:30, 0.532s/it]: train_loss_raw=1.2756, running_loss=1.2858, LR=0.000100
[2025-08-10 15:52:15,617][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031716] [Batch 02180/03692] [00:19:19/00:13:24, 0.532s/it]: train_loss_raw=1.1328, running_loss=1.2810, LR=0.000100
[2025-08-10 15:52:22,137][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031728] [Batch 02192/03692] [00:19:26/00:13:18, 0.532s/it]: train_loss_raw=1.2941, running_loss=1.2797, LR=0.000100
[2025-08-10 15:52:28,688][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031740] [Batch 02204/03692] [00:19:32/00:13:11, 0.532s/it]: train_loss_raw=1.3454, running_loss=1.2776, LR=0.000100
[2025-08-10 15:52:34,847][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031752] [Batch 02216/03692] [00:19:39/00:13:05, 0.532s/it]: train_loss_raw=1.1962, running_loss=1.2768, LR=0.000100
[2025-08-10 15:52:41,384][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031764] [Batch 02228/03692] [00:19:45/00:12:59, 0.532s/it]: train_loss_raw=1.2077, running_loss=1.2736, LR=0.000100
[2025-08-10 15:52:47,922][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031776] [Batch 02240/03692] [00:19:52/00:12:52, 0.532s/it]: train_loss_raw=1.3251, running_loss=1.2765, LR=0.000100
[2025-08-10 15:52:54,510][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031788] [Batch 02252/03692] [00:19:58/00:12:46, 0.532s/it]: train_loss_raw=1.2043, running_loss=1.2762, LR=0.000100
[2025-08-10 15:53:01,033][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031800] [Batch 02264/03692] [00:20:05/00:12:40, 0.532s/it]: train_loss_raw=1.2772, running_loss=1.2821, LR=0.000100
[2025-08-10 15:53:07,564][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031812] [Batch 02276/03692] [00:20:11/00:12:33, 0.532s/it]: train_loss_raw=1.3027, running_loss=1.2809, LR=0.000100
[2025-08-10 15:53:14,300][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031824] [Batch 02288/03692] [00:20:18/00:12:27, 0.533s/it]: train_loss_raw=1.3690, running_loss=1.2852, LR=0.000100
[2025-08-10 15:53:20,834][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031836] [Batch 02300/03692] [00:20:25/00:12:21, 0.533s/it]: train_loss_raw=1.0485, running_loss=1.2799, LR=0.000100
[2025-08-10 15:53:27,523][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031848] [Batch 02312/03692] [00:20:31/00:12:15, 0.533s/it]: train_loss_raw=1.2515, running_loss=1.2794, LR=0.000100
[2025-08-10 15:53:34,093][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031860] [Batch 02324/03692] [00:20:38/00:12:08, 0.533s/it]: train_loss_raw=1.2161, running_loss=1.2775, LR=0.000100
[2025-08-10 15:53:40,663][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031872] [Batch 02336/03692] [00:20:44/00:12:02, 0.533s/it]: train_loss_raw=1.2250, running_loss=1.2804, LR=0.000100
[2025-08-10 15:53:47,231][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031884] [Batch 02348/03692] [00:20:51/00:11:56, 0.533s/it]: train_loss_raw=1.2578, running_loss=1.2812, LR=0.000100
[2025-08-10 15:53:53,912][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031896] [Batch 02360/03692] [00:20:58/00:11:50, 0.533s/it]: train_loss_raw=1.2870, running_loss=1.2808, LR=0.000100
[2025-08-10 15:54:00,493][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031908] [Batch 02372/03692] [00:21:04/00:11:43, 0.533s/it]: train_loss_raw=1.2007, running_loss=1.2811, LR=0.000100
[2025-08-10 15:54:07,093][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031920] [Batch 02384/03692] [00:21:11/00:11:37, 0.533s/it]: train_loss_raw=1.2331, running_loss=1.2741, LR=0.000100
[2025-08-10 15:54:13,507][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031932] [Batch 02396/03692] [00:21:17/00:11:31, 0.533s/it]: train_loss_raw=1.2097, running_loss=1.2737, LR=0.000100
[2025-08-10 15:54:19,825][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031944] [Batch 02408/03692] [00:21:23/00:11:24, 0.533s/it]: train_loss_raw=1.3310, running_loss=1.2719, LR=0.000100
[2025-08-10 15:54:26,234][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031956] [Batch 02420/03692] [00:21:30/00:11:18, 0.533s/it]: train_loss_raw=1.1309, running_loss=1.2735, LR=0.000100
[2025-08-10 15:54:32,722][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031968] [Batch 02432/03692] [00:21:36/00:11:11, 0.533s/it]: train_loss_raw=1.2913, running_loss=1.2721, LR=0.000100
[2025-08-10 15:54:38,975][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031980] [Batch 02444/03692] [00:21:43/00:11:05, 0.533s/it]: train_loss_raw=1.2017, running_loss=1.2722, LR=0.000100
[2025-08-10 15:54:45,086][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031992] [Batch 02456/03692] [00:21:49/00:10:58, 0.533s/it]: train_loss_raw=1.2659, running_loss=1.2726, LR=0.000100
[2025-08-10 15:54:55,581][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032004] [Batch 02468/03692] [00:21:59/00:10:54, 0.535s/it]: train_loss_raw=1.1647, running_loss=1.2746, LR=0.000100
[2025-08-10 15:55:01,715][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032016] [Batch 02480/03692] [00:22:05/00:10:47, 0.535s/it]: train_loss_raw=1.1856, running_loss=1.2746, LR=0.000100
[2025-08-10 15:55:07,865][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032028] [Batch 02492/03692] [00:22:12/00:10:41, 0.535s/it]: train_loss_raw=1.1959, running_loss=1.2713, LR=0.000100
[2025-08-10 15:55:14,288][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032040] [Batch 02504/03692] [00:22:18/00:10:35, 0.535s/it]: train_loss_raw=1.2749, running_loss=1.2691, LR=0.000100
[2025-08-10 15:55:20,826][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032052] [Batch 02516/03692] [00:22:24/00:10:28, 0.535s/it]: train_loss_raw=1.2519, running_loss=1.2720, LR=0.000100
[2025-08-10 15:55:27,407][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032064] [Batch 02528/03692] [00:22:31/00:10:22, 0.535s/it]: train_loss_raw=1.2640, running_loss=1.2745, LR=0.000100
[2025-08-10 15:55:33,989][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032076] [Batch 02540/03692] [00:22:38/00:10:15, 0.535s/it]: train_loss_raw=1.1998, running_loss=1.2762, LR=0.000100
[2025-08-10 15:55:40,520][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032088] [Batch 02552/03692] [00:22:44/00:10:09, 0.535s/it]: train_loss_raw=1.2763, running_loss=1.2729, LR=0.000100
[2025-08-10 15:55:46,913][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032100] [Batch 02564/03692] [00:22:51/00:10:03, 0.535s/it]: train_loss_raw=1.2008, running_loss=1.2728, LR=0.000100
[2025-08-10 15:55:52,946][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032112] [Batch 02576/03692] [00:22:57/00:09:56, 0.535s/it]: train_loss_raw=1.4414, running_loss=1.2740, LR=0.000100
[2025-08-10 15:55:59,341][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032124] [Batch 02588/03692] [00:23:03/00:09:50, 0.535s/it]: train_loss_raw=1.2395, running_loss=1.2729, LR=0.000100
[2025-08-10 15:56:05,765][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032136] [Batch 02600/03692] [00:23:09/00:09:43, 0.535s/it]: train_loss_raw=1.2250, running_loss=1.2774, LR=0.000100
[2025-08-10 15:56:12,087][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032148] [Batch 02612/03692] [00:23:16/00:09:37, 0.535s/it]: train_loss_raw=1.2041, running_loss=1.2770, LR=0.000100
[2025-08-10 15:56:18,646][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032160] [Batch 02624/03692] [00:23:22/00:09:30, 0.535s/it]: train_loss_raw=1.4125, running_loss=1.2800, LR=0.000100
[2025-08-10 15:56:25,213][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032172] [Batch 02636/03692] [00:23:29/00:09:24, 0.535s/it]: train_loss_raw=1.2563, running_loss=1.2801, LR=0.000100
[2025-08-10 15:56:31,772][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032184] [Batch 02648/03692] [00:23:35/00:09:18, 0.535s/it]: train_loss_raw=1.1236, running_loss=1.2810, LR=0.000100
[2025-08-10 15:56:38,181][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032196] [Batch 02660/03692] [00:23:42/00:09:11, 0.535s/it]: train_loss_raw=1.0996, running_loss=1.2735, LR=0.000100
[2025-08-10 15:56:44,175][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032208] [Batch 02672/03692] [00:23:48/00:09:05, 0.535s/it]: train_loss_raw=1.2230, running_loss=1.2711, LR=0.000100
[2025-08-10 15:56:50,253][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032220] [Batch 02684/03692] [00:23:54/00:08:58, 0.534s/it]: train_loss_raw=1.2829, running_loss=1.2761, LR=0.000100
[2025-08-10 15:56:56,389][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032232] [Batch 02696/03692] [00:24:00/00:08:52, 0.534s/it]: train_loss_raw=1.0793, running_loss=1.2738, LR=0.000100
[2025-08-10 15:57:02,517][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032244] [Batch 02708/03692] [00:24:06/00:08:45, 0.534s/it]: train_loss_raw=1.2551, running_loss=1.2712, LR=0.000100
[2025-08-10 15:57:08,596][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032256] [Batch 02720/03692] [00:24:12/00:08:39, 0.534s/it]: train_loss_raw=1.2062, running_loss=1.2726, LR=0.000100
[2025-08-10 15:57:14,731][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032268] [Batch 02732/03692] [00:24:18/00:08:32, 0.534s/it]: train_loss_raw=1.3314, running_loss=1.2735, LR=0.000100
[2025-08-10 15:57:20,772][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032280] [Batch 02744/03692] [00:24:24/00:08:26, 0.534s/it]: train_loss_raw=1.2753, running_loss=1.2708, LR=0.000100
[2025-08-10 15:57:26,845][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032292] [Batch 02756/03692] [00:24:31/00:08:19, 0.534s/it]: train_loss_raw=1.3199, running_loss=1.2739, LR=0.000100
[2025-08-10 15:57:32,973][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032304] [Batch 02768/03692] [00:24:37/00:08:13, 0.534s/it]: train_loss_raw=1.3934, running_loss=1.2732, LR=0.000100
[2025-08-10 15:57:39,156][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032316] [Batch 02780/03692] [00:24:43/00:08:06, 0.534s/it]: train_loss_raw=1.4148, running_loss=1.2745, LR=0.000100
[2025-08-10 15:57:45,296][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032328] [Batch 02792/03692] [00:24:49/00:08:00, 0.533s/it]: train_loss_raw=1.2436, running_loss=1.2705, LR=0.000100
[2025-08-10 15:57:51,461][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032340] [Batch 02804/03692] [00:24:55/00:07:53, 0.533s/it]: train_loss_raw=1.2954, running_loss=1.2727, LR=0.000100
[2025-08-10 15:57:57,646][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032352] [Batch 02816/03692] [00:25:01/00:07:47, 0.533s/it]: train_loss_raw=1.2266, running_loss=1.2749, LR=0.000100
[2025-08-10 15:58:03,793][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032364] [Batch 02828/03692] [00:25:07/00:07:40, 0.533s/it]: train_loss_raw=1.1627, running_loss=1.2778, LR=0.000100
[2025-08-10 15:58:09,965][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032376] [Batch 02840/03692] [00:25:14/00:07:34, 0.533s/it]: train_loss_raw=1.3397, running_loss=1.2798, LR=0.000100
[2025-08-10 15:58:16,022][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032388] [Batch 02852/03692] [00:25:20/00:07:27, 0.533s/it]: train_loss_raw=1.1630, running_loss=1.2810, LR=0.000100
[2025-08-10 15:58:22,066][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032400] [Batch 02864/03692] [00:25:26/00:07:21, 0.533s/it]: train_loss_raw=1.3608, running_loss=1.2793, LR=0.000100
[2025-08-10 15:58:28,115][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032412] [Batch 02876/03692] [00:25:32/00:07:14, 0.533s/it]: train_loss_raw=1.3456, running_loss=1.2798, LR=0.000100
[2025-08-10 15:58:34,242][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032424] [Batch 02888/03692] [00:25:38/00:07:08, 0.533s/it]: train_loss_raw=1.2199, running_loss=1.2812, LR=0.000100
[2025-08-10 15:58:40,298][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032436] [Batch 02900/03692] [00:25:44/00:07:01, 0.533s/it]: train_loss_raw=1.3683, running_loss=1.2786, LR=0.000100
[2025-08-10 15:58:46,447][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032448] [Batch 02912/03692] [00:25:50/00:06:55, 0.532s/it]: train_loss_raw=1.3454, running_loss=1.2793, LR=0.000100
[2025-08-10 15:58:52,538][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032460] [Batch 02924/03692] [00:25:56/00:06:48, 0.532s/it]: train_loss_raw=1.3965, running_loss=1.2793, LR=0.000100
[2025-08-10 15:58:58,812][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032472] [Batch 02936/03692] [00:26:02/00:06:42, 0.532s/it]: train_loss_raw=1.2228, running_loss=1.2800, LR=0.000100
[2025-08-10 15:59:05,010][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032484] [Batch 02948/03692] [00:26:09/00:06:36, 0.532s/it]: train_loss_raw=1.4185, running_loss=1.2803, LR=0.000100
[2025-08-10 15:59:11,127][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032496] [Batch 02960/03692] [00:26:15/00:06:29, 0.532s/it]: train_loss_raw=1.2508, running_loss=1.2796, LR=0.000100
[2025-08-10 15:59:17,322][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032508] [Batch 02972/03692] [00:26:21/00:06:23, 0.532s/it]: train_loss_raw=1.2093, running_loss=1.2798, LR=0.000100
[2025-08-10 15:59:23,424][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032520] [Batch 02984/03692] [00:26:27/00:06:16, 0.532s/it]: train_loss_raw=1.2764, running_loss=1.2769, LR=0.000100
[2025-08-10 15:59:29,721][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032532] [Batch 02996/03692] [00:26:33/00:06:10, 0.532s/it]: train_loss_raw=1.1908, running_loss=1.2732, LR=0.000100
[2025-08-10 15:59:36,212][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032544] [Batch 03008/03692] [00:26:40/00:06:03, 0.532s/it]: train_loss_raw=1.1873, running_loss=1.2670, LR=0.000100
[2025-08-10 15:59:42,873][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032556] [Batch 03020/03692] [00:26:47/00:05:57, 0.532s/it]: train_loss_raw=1.0997, running_loss=1.2632, LR=0.000100
[2025-08-10 15:59:49,560][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032568] [Batch 03032/03692] [00:26:53/00:05:51, 0.532s/it]: train_loss_raw=1.1872, running_loss=1.2638, LR=0.000100
[2025-08-10 15:59:55,928][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032580] [Batch 03044/03692] [00:27:00/00:05:44, 0.532s/it]: train_loss_raw=1.2482, running_loss=1.2649, LR=0.000100
[2025-08-10 16:00:02,057][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032592] [Batch 03056/03692] [00:27:06/00:05:38, 0.532s/it]: train_loss_raw=1.2620, running_loss=1.2642, LR=0.000100
[2025-08-10 16:00:08,403][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032604] [Batch 03068/03692] [00:27:12/00:05:32, 0.532s/it]: train_loss_raw=1.3534, running_loss=1.2664, LR=0.000100
[2025-08-10 16:00:14,764][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032616] [Batch 03080/03692] [00:27:18/00:05:25, 0.532s/it]: train_loss_raw=1.1251, running_loss=1.2649, LR=0.000100
[2025-08-10 16:00:20,933][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032628] [Batch 03092/03692] [00:27:25/00:05:19, 0.532s/it]: train_loss_raw=1.2858, running_loss=1.2627, LR=0.000100
[2025-08-10 16:00:26,963][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032640] [Batch 03104/03692] [00:27:31/00:05:12, 0.532s/it]: train_loss_raw=1.4085, running_loss=1.2632, LR=0.000100
[2025-08-10 16:00:33,081][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032652] [Batch 03116/03692] [00:27:37/00:05:06, 0.532s/it]: train_loss_raw=1.1093, running_loss=1.2606, LR=0.000100
[2025-08-10 16:00:39,275][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032664] [Batch 03128/03692] [00:27:43/00:04:59, 0.532s/it]: train_loss_raw=1.2175, running_loss=1.2606, LR=0.000100
[2025-08-10 16:00:45,399][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032676] [Batch 03140/03692] [00:27:49/00:04:53, 0.532s/it]: train_loss_raw=1.2873, running_loss=1.2594, LR=0.000100
[2025-08-10 16:00:51,553][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032688] [Batch 03152/03692] [00:27:55/00:04:47, 0.532s/it]: train_loss_raw=1.3377, running_loss=1.2616, LR=0.000100
[2025-08-10 16:00:57,824][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032700] [Batch 03164/03692] [00:28:01/00:04:40, 0.532s/it]: train_loss_raw=1.1050, running_loss=1.2617, LR=0.000100
[2025-08-10 16:01:03,917][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032712] [Batch 03176/03692] [00:28:08/00:04:34, 0.532s/it]: train_loss_raw=1.2232, running_loss=1.2621, LR=0.000100
[2025-08-10 16:01:10,020][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032724] [Batch 03188/03692] [00:28:14/00:04:27, 0.531s/it]: train_loss_raw=1.3129, running_loss=1.2645, LR=0.000100
[2025-08-10 16:01:16,092][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032736] [Batch 03200/03692] [00:28:20/00:04:21, 0.531s/it]: train_loss_raw=1.1516, running_loss=1.2627, LR=0.000100
[2025-08-10 16:01:22,144][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032748] [Batch 03212/03692] [00:28:26/00:04:14, 0.531s/it]: train_loss_raw=1.3290, running_loss=1.2635, LR=0.000100
[2025-08-10 16:01:28,244][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032760] [Batch 03224/03692] [00:28:32/00:04:08, 0.531s/it]: train_loss_raw=1.2205, running_loss=1.2651, LR=0.000100
[2025-08-10 16:01:34,269][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032772] [Batch 03236/03692] [00:28:38/00:04:02, 0.531s/it]: train_loss_raw=1.2496, running_loss=1.2655, LR=0.000100
[2025-08-10 16:01:40,465][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032784] [Batch 03248/03692] [00:28:44/00:03:55, 0.531s/it]: train_loss_raw=1.3292, running_loss=1.2625, LR=0.000100
[2025-08-10 16:01:46,712][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032796] [Batch 03260/03692] [00:28:50/00:03:49, 0.531s/it]: train_loss_raw=1.1979, running_loss=1.2592, LR=0.000100
[2025-08-10 16:01:52,822][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032808] [Batch 03272/03692] [00:28:56/00:03:42, 0.531s/it]: train_loss_raw=1.2101, running_loss=1.2574, LR=0.000100
[2025-08-10 16:01:58,882][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032820] [Batch 03284/03692] [00:29:03/00:03:36, 0.531s/it]: train_loss_raw=1.2858, running_loss=1.2585, LR=0.000100
[2025-08-10 16:02:05,417][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032832] [Batch 03296/03692] [00:29:09/00:03:30, 0.531s/it]: train_loss_raw=1.2830, running_loss=1.2600, LR=0.000100
[2025-08-10 16:02:12,041][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032844] [Batch 03308/03692] [00:29:16/00:03:23, 0.531s/it]: train_loss_raw=1.2159, running_loss=1.2574, LR=0.000100
[2025-08-10 16:02:18,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032856] [Batch 03320/03692] [00:29:22/00:03:17, 0.531s/it]: train_loss_raw=1.2864, running_loss=1.2583, LR=0.000100
[2025-08-10 16:02:25,108][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032868] [Batch 03332/03692] [00:29:29/00:03:11, 0.531s/it]: train_loss_raw=1.3058, running_loss=1.2541, LR=0.000100
[2025-08-10 16:02:31,536][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032880] [Batch 03344/03692] [00:29:35/00:03:04, 0.531s/it]: train_loss_raw=1.2341, running_loss=1.2506, LR=0.000100
[2025-08-10 16:02:37,742][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032892] [Batch 03356/03692] [00:29:41/00:02:58, 0.531s/it]: train_loss_raw=1.2786, running_loss=1.2539, LR=0.000100
[2025-08-10 16:02:43,878][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032904] [Batch 03368/03692] [00:29:48/00:02:52, 0.531s/it]: train_loss_raw=1.4034, running_loss=1.2556, LR=0.000100
[2025-08-10 16:02:49,997][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032916] [Batch 03380/03692] [00:29:54/00:02:45, 0.531s/it]: train_loss_raw=1.3262, running_loss=1.2604, LR=0.000100
[2025-08-10 16:02:56,070][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032928] [Batch 03392/03692] [00:30:00/00:02:39, 0.531s/it]: train_loss_raw=1.2460, running_loss=1.2604, LR=0.000100
[2025-08-10 16:03:02,176][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032940] [Batch 03404/03692] [00:30:06/00:02:32, 0.531s/it]: train_loss_raw=1.2477, running_loss=1.2624, LR=0.000100
[2025-08-10 16:03:08,177][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032952] [Batch 03416/03692] [00:30:12/00:02:26, 0.531s/it]: train_loss_raw=1.2769, running_loss=1.2634, LR=0.000100
[2025-08-10 16:03:14,181][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032964] [Batch 03428/03692] [00:30:18/00:02:20, 0.530s/it]: train_loss_raw=1.1390, running_loss=1.2613, LR=0.000100
[2025-08-10 16:03:20,240][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032976] [Batch 03440/03692] [00:30:24/00:02:13, 0.530s/it]: train_loss_raw=1.2494, running_loss=1.2607, LR=0.000100
[2025-08-10 16:03:26,306][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032988] [Batch 03452/03692] [00:30:30/00:02:07, 0.530s/it]: train_loss_raw=1.0774, running_loss=1.2583, LR=0.000100
[2025-08-10 16:03:32,521][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033000] [Batch 03464/03692] [00:30:36/00:02:00, 0.530s/it]: train_loss_raw=1.3080, running_loss=1.2630, LR=0.000100
[2025-08-10 16:03:38,584][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033012] [Batch 03476/03692] [00:30:42/00:01:54, 0.530s/it]: train_loss_raw=1.2100, running_loss=1.2614, LR=0.000100
[2025-08-10 16:03:44,687][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033024] [Batch 03488/03692] [00:30:48/00:01:48, 0.530s/it]: train_loss_raw=1.2021, running_loss=1.2621, LR=0.000100
[2025-08-10 16:03:50,768][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033036] [Batch 03500/03692] [00:30:54/00:01:41, 0.530s/it]: train_loss_raw=1.2549, running_loss=1.2587, LR=0.000100
[2025-08-10 16:03:56,863][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033048] [Batch 03512/03692] [00:31:01/00:01:35, 0.530s/it]: train_loss_raw=1.2655, running_loss=1.2579, LR=0.000100
[2025-08-10 16:04:03,234][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033060] [Batch 03524/03692] [00:31:07/00:01:29, 0.530s/it]: train_loss_raw=1.3848, running_loss=1.2624, LR=0.000100
[2025-08-10 16:04:09,796][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033072] [Batch 03536/03692] [00:31:13/00:01:22, 0.530s/it]: train_loss_raw=1.3666, running_loss=1.2590, LR=0.000100
[2025-08-10 16:04:16,437][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033084] [Batch 03548/03692] [00:31:20/00:01:16, 0.530s/it]: train_loss_raw=1.3845, running_loss=1.2600, LR=0.000100
[2025-08-10 16:04:22,752][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033096] [Batch 03560/03692] [00:31:26/00:01:09, 0.530s/it]: train_loss_raw=1.4797, running_loss=1.2617, LR=0.000100
[2025-08-10 16:04:29,259][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033108] [Batch 03572/03692] [00:31:33/00:01:03, 0.530s/it]: train_loss_raw=1.2303, running_loss=1.2603, LR=0.000100
[2025-08-10 16:04:35,872][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033120] [Batch 03584/03692] [00:31:40/00:00:57, 0.530s/it]: train_loss_raw=1.2273, running_loss=1.2625, LR=0.000100
[2025-08-10 16:04:42,489][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033132] [Batch 03596/03692] [00:31:46/00:00:50, 0.530s/it]: train_loss_raw=1.3100, running_loss=1.2595, LR=0.000100
[2025-08-10 16:04:48,821][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033144] [Batch 03608/03692] [00:31:52/00:00:44, 0.530s/it]: train_loss_raw=1.4284, running_loss=1.2601, LR=0.000100
[2025-08-10 16:04:54,944][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033156] [Batch 03620/03692] [00:31:59/00:00:38, 0.530s/it]: train_loss_raw=1.2280, running_loss=1.2612, LR=0.000100
[2025-08-10 16:05:01,266][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033168] [Batch 03632/03692] [00:32:05/00:00:31, 0.530s/it]: train_loss_raw=1.3239, running_loss=1.2644, LR=0.000100
[2025-08-10 16:05:07,514][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033180] [Batch 03644/03692] [00:32:11/00:00:25, 0.530s/it]: train_loss_raw=1.1588, running_loss=1.2614, LR=0.000100
[2025-08-10 16:05:13,729][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033192] [Batch 03656/03692] [00:32:17/00:00:19, 0.530s/it]: train_loss_raw=1.1416, running_loss=1.2609, LR=0.000100
[2025-08-10 16:05:19,802][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033204] [Batch 03668/03692] [00:32:23/00:00:12, 0.530s/it]: train_loss_raw=1.2280, running_loss=1.2571, LR=0.000100
[2025-08-10 16:05:26,121][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033216] [Batch 03680/03692] [00:32:30/00:00:06, 0.530s/it]: train_loss_raw=1.3236, running_loss=1.2618, LR=0.000100
[2025-08-10 16:05:32,660][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033228] [Batch 03692/03692] [00:32:36/00:00:00, 0.530s/it]: train_loss_raw=1.2237, running_loss=1.2613, LR=0.000100
[2025-08-10 16:05:37,709][__main__][INFO] - [VALIDATION] [Epoch 08/29] Starting validation.
[2025-08-10 16:06:12,073][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 033229] [Batch 00011/00025] [00:00:34/00:00:37, 2.864s/it]
[2025-08-10 16:06:29,459][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 033229] [Batch 00023/00025] [00:00:51/00:00:02, 2.156s/it]
[2025-08-10 16:06:30,466][__main__][INFO] - [VALIDATION] [Epoch 08/29] train_loss=1.26131, valid_loss=1.21149
[2025-08-10 16:06:30,467][__main__][INFO] - [VALIDATION] [Epoch 08/29] Metrics:
[2025-08-10 16:06:30,467][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_er      0.518
[2025-08-10 16:06:30,467][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_prec    0.207
[2025-08-10 16:06:30,467][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_recall  0.213
[2025-08-10 16:06:30,467][__main__][INFO] - [VALIDATION] [Epoch 08/29] - pep_recall 0.167
[2025-08-10 16:06:30,470][__main__][INFO] - [TRAIN] [Epoch 08/29] Epoch complete, total time 05:10:29, remaining time 12:04:29, 00:34:29 per epoch
[2025-08-10 16:06:36,400][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033240] [Batch 00012/03692] [00:00:05/00:29:15, 0.477s/it]: train_loss_raw=1.2148, running_loss=1.2833, LR=0.000100
[2025-08-10 16:06:42,444][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033252] [Batch 00024/03692] [00:00:11/00:29:58, 0.490s/it]: train_loss_raw=1.2575, running_loss=1.2761, LR=0.000100
[2025-08-10 16:06:48,477][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033264] [Batch 00036/03692] [00:00:17/00:30:07, 0.494s/it]: train_loss_raw=1.2380, running_loss=1.2751, LR=0.000100
[2025-08-10 16:06:54,539][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033276] [Batch 00048/03692] [00:00:23/00:30:11, 0.497s/it]: train_loss_raw=1.2876, running_loss=1.2771, LR=0.000100
[2025-08-10 16:07:00,572][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033288] [Batch 00060/03692] [00:00:29/00:30:09, 0.498s/it]: train_loss_raw=1.2593, running_loss=1.2786, LR=0.000100
[2025-08-10 16:07:06,769][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033300] [Batch 00072/03692] [00:00:36/00:30:14, 0.501s/it]: train_loss_raw=1.2821, running_loss=1.2753, LR=0.000100
[2025-08-10 16:07:13,364][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033312] [Batch 00084/03692] [00:00:42/00:30:33, 0.508s/it]: train_loss_raw=1.2897, running_loss=1.2764, LR=0.000100
[2025-08-10 16:07:19,979][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033324] [Batch 00096/03692] [00:00:49/00:30:46, 0.514s/it]: train_loss_raw=1.1833, running_loss=1.2736, LR=0.000100
[2025-08-10 16:07:26,375][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033336] [Batch 00108/03692] [00:00:55/00:30:48, 0.516s/it]: train_loss_raw=1.2245, running_loss=1.2722, LR=0.000100
[2025-08-10 16:07:32,476][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033348] [Batch 00120/03692] [00:01:01/00:30:39, 0.515s/it]: train_loss_raw=1.4524, running_loss=1.2731, LR=0.000100
[2025-08-10 16:07:38,569][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033360] [Batch 00132/03692] [00:01:07/00:30:31, 0.514s/it]: train_loss_raw=1.2455, running_loss=1.2688, LR=0.000100
[2025-08-10 16:07:44,639][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033372] [Batch 00144/03692] [00:01:13/00:30:22, 0.514s/it]: train_loss_raw=1.2372, running_loss=1.2650, LR=0.000100
[2025-08-10 16:07:50,747][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033384] [Batch 00156/03692] [00:01:20/00:30:14, 0.513s/it]: train_loss_raw=1.2505, running_loss=1.2681, LR=0.000100
[2025-08-10 16:07:56,701][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033396] [Batch 00168/03692] [00:01:26/00:30:04, 0.512s/it]: train_loss_raw=1.2199, running_loss=1.2663, LR=0.000100
[2025-08-10 16:08:03,013][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033408] [Batch 00180/03692] [00:01:32/00:30:01, 0.513s/it]: train_loss_raw=1.2721, running_loss=1.2638, LR=0.000100
[2025-08-10 16:08:09,362][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033420] [Batch 00192/03692] [00:01:38/00:29:58, 0.514s/it]: train_loss_raw=1.3313, running_loss=1.2666, LR=0.000100
[2025-08-10 16:08:15,634][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033432] [Batch 00204/03692] [00:01:44/00:29:54, 0.515s/it]: train_loss_raw=1.2335, running_loss=1.2657, LR=0.000100
[2025-08-10 16:08:22,234][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033444] [Batch 00216/03692] [00:01:51/00:29:55, 0.516s/it]: train_loss_raw=1.2351, running_loss=1.2639, LR=0.000100
[2025-08-10 16:08:28,651][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033456] [Batch 00228/03692] [00:01:57/00:29:52, 0.517s/it]: train_loss_raw=1.2081, running_loss=1.2647, LR=0.000100
[2025-08-10 16:08:35,171][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033468] [Batch 00240/03692] [00:02:04/00:29:50, 0.519s/it]: train_loss_raw=1.2650, running_loss=1.2652, LR=0.000100
[2025-08-10 16:08:41,400][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033480] [Batch 00252/03692] [00:02:10/00:29:44, 0.519s/it]: train_loss_raw=1.2645, running_loss=1.2648, LR=0.000100
[2025-08-10 16:08:47,431][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033492] [Batch 00264/03692] [00:02:16/00:29:35, 0.518s/it]: train_loss_raw=1.3852, running_loss=1.2646, LR=0.000100
[2025-08-10 16:08:53,842][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033504] [Batch 00276/03692] [00:02:23/00:29:31, 0.519s/it]: train_loss_raw=1.1445, running_loss=1.2630, LR=0.000100
[2025-08-10 16:09:00,346][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033516] [Batch 00288/03692] [00:02:29/00:29:29, 0.520s/it]: train_loss_raw=1.1098, running_loss=1.2611, LR=0.000100
[2025-08-10 16:09:06,858][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033528] [Batch 00300/03692] [00:02:36/00:29:25, 0.521s/it]: train_loss_raw=1.1827, running_loss=1.2579, LR=0.000100
[2025-08-10 16:09:13,169][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033540] [Batch 00312/03692] [00:02:42/00:29:20, 0.521s/it]: train_loss_raw=1.3702, running_loss=1.2617, LR=0.000100
[2025-08-10 16:09:19,309][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033552] [Batch 00324/03692] [00:02:48/00:29:12, 0.520s/it]: train_loss_raw=1.1799, running_loss=1.2633, LR=0.000100
[2025-08-10 16:09:25,393][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033564] [Batch 00336/03692] [00:02:54/00:29:05, 0.520s/it]: train_loss_raw=1.2003, running_loss=1.2645, LR=0.000100
[2025-08-10 16:09:31,518][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033576] [Batch 00348/03692] [00:03:00/00:28:57, 0.520s/it]: train_loss_raw=1.2498, running_loss=1.2597, LR=0.000100
[2025-08-10 16:09:37,718][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033588] [Batch 00360/03692] [00:03:07/00:28:51, 0.520s/it]: train_loss_raw=1.4307, running_loss=1.2659, LR=0.000100
[2025-08-10 16:09:43,770][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033600] [Batch 00372/03692] [00:03:13/00:28:43, 0.519s/it]: train_loss_raw=1.2070, running_loss=1.2679, LR=0.000100
[2025-08-10 16:09:49,864][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033612] [Batch 00384/03692] [00:03:19/00:28:35, 0.519s/it]: train_loss_raw=1.1525, running_loss=1.2667, LR=0.000100
[2025-08-10 16:09:55,937][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033624] [Batch 00396/03692] [00:03:25/00:28:28, 0.518s/it]: train_loss_raw=1.4159, running_loss=1.2642, LR=0.000100
[2025-08-10 16:10:02,003][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033636] [Batch 00408/03692] [00:03:31/00:28:20, 0.518s/it]: train_loss_raw=1.2093, running_loss=1.2634, LR=0.000100
[2025-08-10 16:10:08,111][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033648] [Batch 00420/03692] [00:03:37/00:28:13, 0.518s/it]: train_loss_raw=1.3386, running_loss=1.2585, LR=0.000100
[2025-08-10 16:10:14,197][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033660] [Batch 00432/03692] [00:03:43/00:28:06, 0.517s/it]: train_loss_raw=1.1174, running_loss=1.2546, LR=0.000100
[2025-08-10 16:10:20,269][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033672] [Batch 00444/03692] [00:03:49/00:27:59, 0.517s/it]: train_loss_raw=1.2511, running_loss=1.2502, LR=0.000100
[2025-08-10 16:10:26,408][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033684] [Batch 00456/03692] [00:03:55/00:27:52, 0.517s/it]: train_loss_raw=1.2897, running_loss=1.2543, LR=0.000100
[2025-08-10 16:10:32,662][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033696] [Batch 00468/03692] [00:04:01/00:27:47, 0.517s/it]: train_loss_raw=1.3298, running_loss=1.2519, LR=0.000100
[2025-08-10 16:10:38,831][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033708] [Batch 00480/03692] [00:04:08/00:27:40, 0.517s/it]: train_loss_raw=1.2703, running_loss=1.2471, LR=0.000100
[2025-08-10 16:10:45,107][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033720] [Batch 00492/03692] [00:04:14/00:27:34, 0.517s/it]: train_loss_raw=1.2451, running_loss=1.2461, LR=0.000100
[2025-08-10 16:10:51,217][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033732] [Batch 00504/03692] [00:04:20/00:27:28, 0.517s/it]: train_loss_raw=1.2552, running_loss=1.2510, LR=0.000100
[2025-08-10 16:10:57,493][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033744] [Batch 00516/03692] [00:04:26/00:27:22, 0.517s/it]: train_loss_raw=1.3016, running_loss=1.2524, LR=0.000100
[2025-08-10 16:11:03,821][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033756] [Batch 00528/03692] [00:04:33/00:27:16, 0.517s/it]: train_loss_raw=1.2764, running_loss=1.2496, LR=0.000100
[2025-08-10 16:11:09,847][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033768] [Batch 00540/03692] [00:04:39/00:27:09, 0.517s/it]: train_loss_raw=1.1898, running_loss=1.2492, LR=0.000100
[2025-08-10 16:11:16,073][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033780] [Batch 00552/03692] [00:04:45/00:27:03, 0.517s/it]: train_loss_raw=1.1558, running_loss=1.2502, LR=0.000100
[2025-08-10 16:11:22,127][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033792] [Batch 00564/03692] [00:04:51/00:26:56, 0.517s/it]: train_loss_raw=1.3542, running_loss=1.2519, LR=0.000100
[2025-08-10 16:11:28,191][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033804] [Batch 00576/03692] [00:04:57/00:26:49, 0.517s/it]: train_loss_raw=1.3214, running_loss=1.2514, LR=0.000100
[2025-08-10 16:11:34,353][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033816] [Batch 00588/03692] [00:05:03/00:26:43, 0.516s/it]: train_loss_raw=1.2929, running_loss=1.2522, LR=0.000100
[2025-08-10 16:11:40,490][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033828] [Batch 00600/03692] [00:05:09/00:26:36, 0.516s/it]: train_loss_raw=1.2657, running_loss=1.2532, LR=0.000100
[2025-08-10 16:11:46,568][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033840] [Batch 00612/03692] [00:05:15/00:26:29, 0.516s/it]: train_loss_raw=1.2098, running_loss=1.2558, LR=0.000100
[2025-08-10 16:11:52,572][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033852] [Batch 00624/03692] [00:05:21/00:26:22, 0.516s/it]: train_loss_raw=1.2646, running_loss=1.2543, LR=0.000100
[2025-08-10 16:11:58,601][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033864] [Batch 00636/03692] [00:05:27/00:26:15, 0.516s/it]: train_loss_raw=1.2997, running_loss=1.2561, LR=0.000100
[2025-08-10 16:12:04,794][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033876] [Batch 00648/03692] [00:05:34/00:26:09, 0.516s/it]: train_loss_raw=1.2264, running_loss=1.2540, LR=0.000100
[2025-08-10 16:12:10,916][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033888] [Batch 00660/03692] [00:05:40/00:26:03, 0.516s/it]: train_loss_raw=1.1928, running_loss=1.2511, LR=0.000100
[2025-08-10 16:12:17,405][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033900] [Batch 00672/03692] [00:05:46/00:25:58, 0.516s/it]: train_loss_raw=1.3259, running_loss=1.2519, LR=0.000100
[2025-08-10 16:12:24,039][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033912] [Batch 00684/03692] [00:05:53/00:25:53, 0.517s/it]: train_loss_raw=1.2700, running_loss=1.2511, LR=0.000100
[2025-08-10 16:12:30,622][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033924] [Batch 00696/03692] [00:05:59/00:25:49, 0.517s/it]: train_loss_raw=1.1874, running_loss=1.2537, LR=0.000100
[2025-08-10 16:12:36,786][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033936] [Batch 00708/03692] [00:06:06/00:25:43, 0.517s/it]: train_loss_raw=1.1115, running_loss=1.2550, LR=0.000100
[2025-08-10 16:12:43,063][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033948] [Batch 00720/03692] [00:06:12/00:25:37, 0.517s/it]: train_loss_raw=1.2344, running_loss=1.2517, LR=0.000100
[2025-08-10 16:12:49,410][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033960] [Batch 00732/03692] [00:06:18/00:25:31, 0.517s/it]: train_loss_raw=1.2551, running_loss=1.2513, LR=0.000100
[2025-08-10 16:12:55,961][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033972] [Batch 00744/03692] [00:06:25/00:25:26, 0.518s/it]: train_loss_raw=1.3746, running_loss=1.2529, LR=0.000100
[2025-08-10 16:13:02,496][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033984] [Batch 00756/03692] [00:06:31/00:25:21, 0.518s/it]: train_loss_raw=1.2779, running_loss=1.2539, LR=0.000100
[2025-08-10 16:13:09,202][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033996] [Batch 00768/03692] [00:06:38/00:25:17, 0.519s/it]: train_loss_raw=1.2068, running_loss=1.2523, LR=0.000100
[2025-08-10 16:13:21,254][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034008] [Batch 00780/03692] [00:06:50/00:25:32, 0.526s/it]: train_loss_raw=1.1586, running_loss=1.2522, LR=0.000100
[2025-08-10 16:13:27,857][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034020] [Batch 00792/03692] [00:06:57/00:25:27, 0.527s/it]: train_loss_raw=1.1867, running_loss=1.2507, LR=0.000100
[2025-08-10 16:13:34,454][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034032] [Batch 00804/03692] [00:07:03/00:25:22, 0.527s/it]: train_loss_raw=1.1611, running_loss=1.2510, LR=0.000100
[2025-08-10 16:13:41,043][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034044] [Batch 00816/03692] [00:07:10/00:25:16, 0.527s/it]: train_loss_raw=1.2818, running_loss=1.2543, LR=0.000100
[2025-08-10 16:13:47,514][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034056] [Batch 00828/03692] [00:07:16/00:25:10, 0.528s/it]: train_loss_raw=1.1994, running_loss=1.2519, LR=0.000100
[2025-08-10 16:13:54,087][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034068] [Batch 00840/03692] [00:07:23/00:25:05, 0.528s/it]: train_loss_raw=1.2631, running_loss=1.2483, LR=0.000100
[2025-08-10 16:14:00,585][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034080] [Batch 00852/03692] [00:07:29/00:24:59, 0.528s/it]: train_loss_raw=1.1833, running_loss=1.2466, LR=0.000100
[2025-08-10 16:14:07,119][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034092] [Batch 00864/03692] [00:07:36/00:24:54, 0.528s/it]: train_loss_raw=1.2402, running_loss=1.2461, LR=0.000100
[2025-08-10 16:14:13,666][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034104] [Batch 00876/03692] [00:07:42/00:24:48, 0.529s/it]: train_loss_raw=1.1701, running_loss=1.2473, LR=0.000100
[2025-08-10 16:14:20,022][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034116] [Batch 00888/03692] [00:07:49/00:24:42, 0.529s/it]: train_loss_raw=1.2996, running_loss=1.2419, LR=0.000100
[2025-08-10 16:14:26,076][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034128] [Batch 00900/03692] [00:07:55/00:24:34, 0.528s/it]: train_loss_raw=1.3048, running_loss=1.2431, LR=0.000100
[2025-08-10 16:14:32,263][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034140] [Batch 00912/03692] [00:08:01/00:24:27, 0.528s/it]: train_loss_raw=1.1024, running_loss=1.2388, LR=0.000100
[2025-08-10 16:14:38,483][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034152] [Batch 00924/03692] [00:08:07/00:24:21, 0.528s/it]: train_loss_raw=1.1481, running_loss=1.2371, LR=0.000100
[2025-08-10 16:14:44,539][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034164] [Batch 00936/03692] [00:08:13/00:24:14, 0.528s/it]: train_loss_raw=1.2510, running_loss=1.2371, LR=0.000100
[2025-08-10 16:14:50,736][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034176] [Batch 00948/03692] [00:08:20/00:24:07, 0.527s/it]: train_loss_raw=1.3153, running_loss=1.2370, LR=0.000100
[2025-08-10 16:14:56,849][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034188] [Batch 00960/03692] [00:08:26/00:24:00, 0.527s/it]: train_loss_raw=1.3955, running_loss=1.2408, LR=0.000100
[2025-08-10 16:15:02,854][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034200] [Batch 00972/03692] [00:08:32/00:23:53, 0.527s/it]: train_loss_raw=1.2470, running_loss=1.2404, LR=0.000100
[2025-08-10 16:15:08,951][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034212] [Batch 00984/03692] [00:08:38/00:23:46, 0.527s/it]: train_loss_raw=1.2452, running_loss=1.2406, LR=0.000100
[2025-08-10 16:15:14,990][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034224] [Batch 00996/03692] [00:08:44/00:23:39, 0.526s/it]: train_loss_raw=1.2350, running_loss=1.2467, LR=0.000100
[2025-08-10 16:15:21,191][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034236] [Batch 01008/03692] [00:08:50/00:23:32, 0.526s/it]: train_loss_raw=1.2750, running_loss=1.2428, LR=0.000100
[2025-08-10 16:15:27,359][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034248] [Batch 01020/03692] [00:08:56/00:23:25, 0.526s/it]: train_loss_raw=1.3858, running_loss=1.2475, LR=0.000100
[2025-08-10 16:15:33,669][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034260] [Batch 01032/03692] [00:09:02/00:23:19, 0.526s/it]: train_loss_raw=1.2869, running_loss=1.2471, LR=0.000100
[2025-08-10 16:15:40,249][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034272] [Batch 01044/03692] [00:09:09/00:23:13, 0.526s/it]: train_loss_raw=1.2544, running_loss=1.2501, LR=0.000100
[2025-08-10 16:15:46,714][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034284] [Batch 01056/03692] [00:09:16/00:23:07, 0.527s/it]: train_loss_raw=1.3108, running_loss=1.2479, LR=0.000100
[2025-08-10 16:15:53,305][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034296] [Batch 01068/03692] [00:09:22/00:23:02, 0.527s/it]: train_loss_raw=1.1290, running_loss=1.2467, LR=0.000100
[2025-08-10 16:15:59,795][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034308] [Batch 01080/03692] [00:09:29/00:22:56, 0.527s/it]: train_loss_raw=1.3584, running_loss=1.2461, LR=0.000100
[2025-08-10 16:16:06,360][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034320] [Batch 01092/03692] [00:09:35/00:22:50, 0.527s/it]: train_loss_raw=1.1659, running_loss=1.2456, LR=0.000100
[2025-08-10 16:16:12,996][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034332] [Batch 01104/03692] [00:09:42/00:22:45, 0.527s/it]: train_loss_raw=1.3087, running_loss=1.2476, LR=0.000100
[2025-08-10 16:16:19,544][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034344] [Batch 01116/03692] [00:09:48/00:22:39, 0.528s/it]: train_loss_raw=1.1076, running_loss=1.2493, LR=0.000100
[2025-08-10 16:16:25,593][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034356] [Batch 01128/03692] [00:09:54/00:22:32, 0.527s/it]: train_loss_raw=1.2707, running_loss=1.2497, LR=0.000100
[2025-08-10 16:16:31,640][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034368] [Batch 01140/03692] [00:10:00/00:22:25, 0.527s/it]: train_loss_raw=1.2424, running_loss=1.2502, LR=0.000100
[2025-08-10 16:16:37,739][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034380] [Batch 01152/03692] [00:10:07/00:22:18, 0.527s/it]: train_loss_raw=1.2441, running_loss=1.2508, LR=0.000100
[2025-08-10 16:16:43,784][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034392] [Batch 01164/03692] [00:10:13/00:22:11, 0.527s/it]: train_loss_raw=1.3449, running_loss=1.2508, LR=0.000100
[2025-08-10 16:16:49,945][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034404] [Batch 01176/03692] [00:10:19/00:22:04, 0.527s/it]: train_loss_raw=1.2354, running_loss=1.2498, LR=0.000100
[2025-08-10 16:16:56,034][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034416] [Batch 01188/03692] [00:10:25/00:21:58, 0.526s/it]: train_loss_raw=1.1158, running_loss=1.2522, LR=0.000100
[2025-08-10 16:17:02,310][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034428] [Batch 01200/03692] [00:10:31/00:21:51, 0.526s/it]: train_loss_raw=1.3421, running_loss=1.2475, LR=0.000100
[2025-08-10 16:17:08,446][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034440] [Batch 01212/03692] [00:10:37/00:21:45, 0.526s/it]: train_loss_raw=1.2203, running_loss=1.2471, LR=0.000100
[2025-08-10 16:17:14,610][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034452] [Batch 01224/03692] [00:10:43/00:21:38, 0.526s/it]: train_loss_raw=1.2451, running_loss=1.2440, LR=0.000100
[2025-08-10 16:17:20,736][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034464] [Batch 01236/03692] [00:10:50/00:21:31, 0.526s/it]: train_loss_raw=1.2278, running_loss=1.2431, LR=0.000100
[2025-08-10 16:17:26,868][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034476] [Batch 01248/03692] [00:10:56/00:21:25, 0.526s/it]: train_loss_raw=1.3120, running_loss=1.2431, LR=0.000100
[2025-08-10 16:17:33,104][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034488] [Batch 01260/03692] [00:11:02/00:21:18, 0.526s/it]: train_loss_raw=1.2935, running_loss=1.2425, LR=0.000100
[2025-08-10 16:17:39,208][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034500] [Batch 01272/03692] [00:11:08/00:21:11, 0.526s/it]: train_loss_raw=1.2021, running_loss=1.2392, LR=0.000100
[2025-08-10 16:17:45,315][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034512] [Batch 01284/03692] [00:11:14/00:21:05, 0.525s/it]: train_loss_raw=1.3635, running_loss=1.2344, LR=0.000100
[2025-08-10 16:17:51,437][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034524] [Batch 01296/03692] [00:11:20/00:20:58, 0.525s/it]: train_loss_raw=1.1656, running_loss=1.2314, LR=0.000100
[2025-08-10 16:17:57,688][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034536] [Batch 01308/03692] [00:11:27/00:20:52, 0.525s/it]: train_loss_raw=1.2053, running_loss=1.2295, LR=0.000100
[2025-08-10 16:18:03,765][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034548] [Batch 01320/03692] [00:11:33/00:20:45, 0.525s/it]: train_loss_raw=1.2464, running_loss=1.2277, LR=0.000100
[2025-08-10 16:18:10,029][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034560] [Batch 01332/03692] [00:11:39/00:20:39, 0.525s/it]: train_loss_raw=1.2893, running_loss=1.2279, LR=0.000100
[2025-08-10 16:18:16,231][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034572] [Batch 01344/03692] [00:11:45/00:20:32, 0.525s/it]: train_loss_raw=1.2860, running_loss=1.2320, LR=0.000100
[2025-08-10 16:18:22,413][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034584] [Batch 01356/03692] [00:11:51/00:20:26, 0.525s/it]: train_loss_raw=1.1267, running_loss=1.2313, LR=0.000100
[2025-08-10 16:18:28,754][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034596] [Batch 01368/03692] [00:11:58/00:20:19, 0.525s/it]: train_loss_raw=1.2486, running_loss=1.2309, LR=0.000100
[2025-08-10 16:18:35,171][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034608] [Batch 01380/03692] [00:12:04/00:20:13, 0.525s/it]: train_loss_raw=1.2620, running_loss=1.2340, LR=0.000100
[2025-08-10 16:18:41,236][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034620] [Batch 01392/03692] [00:12:10/00:20:07, 0.525s/it]: train_loss_raw=1.2849, running_loss=1.2323, LR=0.000100
[2025-08-10 16:18:47,328][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034632] [Batch 01404/03692] [00:12:16/00:20:00, 0.525s/it]: train_loss_raw=1.3260, running_loss=1.2335, LR=0.000100
[2025-08-10 16:18:53,395][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034644] [Batch 01416/03692] [00:12:22/00:19:53, 0.525s/it]: train_loss_raw=1.1989, running_loss=1.2357, LR=0.000100
[2025-08-10 16:18:59,926][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034656] [Batch 01428/03692] [00:12:29/00:19:47, 0.525s/it]: train_loss_raw=1.2884, running_loss=1.2369, LR=0.000100
[2025-08-10 16:19:06,433][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034668] [Batch 01440/03692] [00:12:35/00:19:41, 0.525s/it]: train_loss_raw=1.3388, running_loss=1.2396, LR=0.000100
[2025-08-10 16:19:12,925][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034680] [Batch 01452/03692] [00:12:42/00:19:35, 0.525s/it]: train_loss_raw=1.2249, running_loss=1.2351, LR=0.000100
[2025-08-10 16:19:19,515][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034692] [Batch 01464/03692] [00:12:48/00:19:30, 0.525s/it]: train_loss_raw=1.2698, running_loss=1.2357, LR=0.000100
[2025-08-10 16:19:26,091][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034704] [Batch 01476/03692] [00:12:55/00:19:24, 0.525s/it]: train_loss_raw=1.1963, running_loss=1.2367, LR=0.000100
[2025-08-10 16:19:32,732][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034716] [Batch 01488/03692] [00:13:02/00:19:18, 0.526s/it]: train_loss_raw=1.1483, running_loss=1.2368, LR=0.000100
[2025-08-10 16:19:39,310][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034728] [Batch 01500/03692] [00:13:08/00:19:12, 0.526s/it]: train_loss_raw=1.2281, running_loss=1.2403, LR=0.000100
[2025-08-10 16:19:45,929][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034740] [Batch 01512/03692] [00:13:15/00:19:06, 0.526s/it]: train_loss_raw=1.2048, running_loss=1.2422, LR=0.000100
[2025-08-10 16:19:52,532][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034752] [Batch 01524/03692] [00:13:21/00:19:00, 0.526s/it]: train_loss_raw=1.2672, running_loss=1.2378, LR=0.000100
[2025-08-10 16:19:59,158][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034764] [Batch 01536/03692] [00:13:28/00:18:54, 0.526s/it]: train_loss_raw=1.1948, running_loss=1.2375, LR=0.000100
[2025-08-10 16:20:05,802][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034776] [Batch 01548/03692] [00:13:35/00:18:48, 0.527s/it]: train_loss_raw=1.1734, running_loss=1.2323, LR=0.000100
[2025-08-10 16:20:12,059][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034788] [Batch 01560/03692] [00:13:41/00:18:42, 0.527s/it]: train_loss_raw=1.2059, running_loss=1.2296, LR=0.000100
[2025-08-10 16:20:18,114][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034800] [Batch 01572/03692] [00:13:47/00:18:35, 0.526s/it]: train_loss_raw=1.1797, running_loss=1.2294, LR=0.000100
[2025-08-10 16:20:24,205][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034812] [Batch 01584/03692] [00:13:53/00:18:29, 0.526s/it]: train_loss_raw=1.1790, running_loss=1.2270, LR=0.000100
[2025-08-10 16:20:30,673][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034824] [Batch 01596/03692] [00:13:59/00:18:23, 0.526s/it]: train_loss_raw=1.2402, running_loss=1.2210, LR=0.000100
[2025-08-10 16:20:45,124][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034836] [Batch 01608/03692] [00:14:14/00:18:27, 0.531s/it]: train_loss_raw=1.1942, running_loss=1.2219, LR=0.000100
[2025-08-10 16:21:03,065][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034848] [Batch 01620/03692] [00:14:32/00:18:35, 0.539s/it]: train_loss_raw=1.2543, running_loss=1.2224, LR=0.000100
[2025-08-10 16:21:20,717][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034860] [Batch 01632/03692] [00:14:50/00:18:43, 0.545s/it]: train_loss_raw=1.2084, running_loss=1.2210, LR=0.000100
[2025-08-10 16:21:26,710][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034872] [Batch 01644/03692] [00:14:56/00:18:36, 0.545s/it]: train_loss_raw=1.1500, running_loss=1.2202, LR=0.000100
[2025-08-10 16:21:32,823][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034884] [Batch 01656/03692] [00:15:02/00:18:29, 0.545s/it]: train_loss_raw=1.1533, running_loss=1.2190, LR=0.000100
[2025-08-10 16:21:38,905][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034896] [Batch 01668/03692] [00:15:08/00:18:22, 0.545s/it]: train_loss_raw=1.2435, running_loss=1.2209, LR=0.000100
[2025-08-10 16:21:45,063][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034908] [Batch 01680/03692] [00:15:14/00:18:15, 0.544s/it]: train_loss_raw=1.1464, running_loss=1.2234, LR=0.000100
[2025-08-10 16:21:51,189][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034920] [Batch 01692/03692] [00:15:20/00:18:08, 0.544s/it]: train_loss_raw=1.1762, running_loss=1.2209, LR=0.000100
[2025-08-10 16:21:57,187][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034932] [Batch 01704/03692] [00:15:26/00:18:00, 0.544s/it]: train_loss_raw=1.3031, running_loss=1.2223, LR=0.000100
[2025-08-10 16:22:03,305][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034944] [Batch 01716/03692] [00:15:32/00:17:53, 0.543s/it]: train_loss_raw=1.2657, running_loss=1.2210, LR=0.000100
[2025-08-10 16:22:09,357][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034956] [Batch 01728/03692] [00:15:38/00:17:46, 0.543s/it]: train_loss_raw=1.2872, running_loss=1.2193, LR=0.000100
[2025-08-10 16:22:15,383][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034968] [Batch 01740/03692] [00:15:44/00:17:39, 0.543s/it]: train_loss_raw=1.2512, running_loss=1.2196, LR=0.000100
[2025-08-10 16:22:21,440][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034980] [Batch 01752/03692] [00:15:50/00:17:32, 0.543s/it]: train_loss_raw=1.2999, running_loss=1.2219, LR=0.000100
[2025-08-10 16:22:27,525][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034992] [Batch 01764/03692] [00:15:56/00:17:25, 0.542s/it]: train_loss_raw=1.3263, running_loss=1.2216, LR=0.000100
[2025-08-10 16:22:33,669][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035004] [Batch 01776/03692] [00:16:02/00:17:18, 0.542s/it]: train_loss_raw=1.2062, running_loss=1.2250, LR=0.000100
[2025-08-10 16:22:39,881][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035016] [Batch 01788/03692] [00:16:09/00:17:12, 0.542s/it]: train_loss_raw=1.1815, running_loss=1.2239, LR=0.000100
[2025-08-10 16:22:46,462][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035028] [Batch 01800/03692] [00:16:15/00:17:05, 0.542s/it]: train_loss_raw=1.3283, running_loss=1.2251, LR=0.000100
[2025-08-10 16:22:53,185][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035040] [Batch 01812/03692] [00:16:22/00:16:59, 0.542s/it]: train_loss_raw=1.2382, running_loss=1.2287, LR=0.000100
[2025-08-10 16:22:59,682][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035052] [Batch 01824/03692] [00:16:29/00:16:52, 0.542s/it]: train_loss_raw=1.2969, running_loss=1.2302, LR=0.000100
[2025-08-10 16:23:06,299][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035064] [Batch 01836/03692] [00:16:35/00:16:46, 0.542s/it]: train_loss_raw=1.2643, running_loss=1.2299, LR=0.000100
[2025-08-10 16:23:12,894][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035076] [Batch 01848/03692] [00:16:42/00:16:40, 0.542s/it]: train_loss_raw=1.2673, running_loss=1.2324, LR=0.000100
[2025-08-10 16:23:19,183][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035088] [Batch 01860/03692] [00:16:48/00:16:33, 0.542s/it]: train_loss_raw=1.0625, running_loss=1.2325, LR=0.000100
[2025-08-10 16:23:25,564][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035100] [Batch 01872/03692] [00:16:54/00:16:26, 0.542s/it]: train_loss_raw=1.2038, running_loss=1.2296, LR=0.000100
[2025-08-10 16:23:32,120][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035112] [Batch 01884/03692] [00:17:01/00:16:20, 0.542s/it]: train_loss_raw=1.2076, running_loss=1.2319, LR=0.000100
[2025-08-10 16:23:40,218][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035124] [Batch 01896/03692] [00:17:09/00:16:15, 0.543s/it]: train_loss_raw=1.2699, running_loss=1.2296, LR=0.000100
[2025-08-10 16:23:49,842][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035136] [Batch 01908/03692] [00:17:19/00:16:11, 0.545s/it]: train_loss_raw=1.2500, running_loss=1.2331, LR=0.000100
[2025-08-10 16:23:56,572][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035148] [Batch 01920/03692] [00:17:25/00:16:05, 0.545s/it]: train_loss_raw=1.3003, running_loss=1.2308, LR=0.000100
[2025-08-10 16:24:03,219][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035160] [Batch 01932/03692] [00:17:32/00:15:58, 0.545s/it]: train_loss_raw=1.3206, running_loss=1.2364, LR=0.000100
[2025-08-10 16:24:09,936][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035172] [Batch 01944/03692] [00:17:39/00:15:52, 0.545s/it]: train_loss_raw=1.2494, running_loss=1.2376, LR=0.000100
[2025-08-10 16:24:16,792][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035184] [Batch 01956/03692] [00:17:46/00:15:46, 0.545s/it]: train_loss_raw=1.1503, running_loss=1.2315, LR=0.000100
[2025-08-10 16:24:23,788][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035196] [Batch 01968/03692] [00:17:53/00:15:40, 0.545s/it]: train_loss_raw=1.2091, running_loss=1.2302, LR=0.000100
[2025-08-10 16:24:30,613][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035208] [Batch 01980/03692] [00:17:59/00:15:33, 0.545s/it]: train_loss_raw=1.3060, running_loss=1.2339, LR=0.000100
[2025-08-10 16:24:37,231][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035220] [Batch 01992/03692] [00:18:06/00:15:27, 0.545s/it]: train_loss_raw=1.2482, running_loss=1.2353, LR=0.000100
[2025-08-10 16:24:43,812][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035232] [Batch 02004/03692] [00:18:13/00:15:20, 0.545s/it]: train_loss_raw=1.1805, running_loss=1.2319, LR=0.000100
[2025-08-10 16:24:50,413][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035244] [Batch 02016/03692] [00:18:19/00:15:14, 0.546s/it]: train_loss_raw=1.2833, running_loss=1.2354, LR=0.000100
[2025-08-10 16:24:56,855][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035256] [Batch 02028/03692] [00:18:26/00:15:07, 0.545s/it]: train_loss_raw=1.0832, running_loss=1.2360, LR=0.000100
[2025-08-10 16:25:03,015][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035268] [Batch 02040/03692] [00:18:32/00:15:00, 0.545s/it]: train_loss_raw=1.2523, running_loss=1.2323, LR=0.000100
[2025-08-10 16:25:09,085][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035280] [Batch 02052/03692] [00:18:38/00:14:53, 0.545s/it]: train_loss_raw=1.1969, running_loss=1.2280, LR=0.000100
[2025-08-10 16:25:15,148][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035292] [Batch 02064/03692] [00:18:44/00:14:46, 0.545s/it]: train_loss_raw=1.1062, running_loss=1.2245, LR=0.000100
[2025-08-10 16:25:21,201][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035304] [Batch 02076/03692] [00:18:50/00:14:40, 0.545s/it]: train_loss_raw=1.1723, running_loss=1.2277, LR=0.000100
[2025-08-10 16:25:27,212][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035316] [Batch 02088/03692] [00:18:56/00:14:33, 0.544s/it]: train_loss_raw=1.2145, running_loss=1.2244, LR=0.000100
[2025-08-10 16:25:33,291][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035328] [Batch 02100/03692] [00:19:02/00:14:26, 0.544s/it]: train_loss_raw=1.2161, running_loss=1.2231, LR=0.000100
[2025-08-10 16:25:39,321][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035340] [Batch 02112/03692] [00:19:08/00:14:19, 0.544s/it]: train_loss_raw=1.2450, running_loss=1.2253, LR=0.000100
[2025-08-10 16:25:45,585][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035352] [Batch 02124/03692] [00:19:14/00:14:12, 0.544s/it]: train_loss_raw=1.2300, running_loss=1.2274, LR=0.000100
[2025-08-10 16:25:52,072][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035364] [Batch 02136/03692] [00:19:21/00:14:06, 0.544s/it]: train_loss_raw=1.2077, running_loss=1.2322, LR=0.000100
[2025-08-10 16:25:58,581][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035376] [Batch 02148/03692] [00:19:27/00:13:59, 0.544s/it]: train_loss_raw=1.2465, running_loss=1.2299, LR=0.000100
[2025-08-10 16:26:17,770][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035388] [Batch 02160/03692] [00:19:47/00:14:01, 0.550s/it]: train_loss_raw=1.2184, running_loss=1.2293, LR=0.000100
[2025-08-10 16:26:23,763][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035400] [Batch 02172/03692] [00:19:53/00:13:54, 0.549s/it]: train_loss_raw=1.2459, running_loss=1.2329, LR=0.000100
[2025-08-10 16:26:29,859][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035412] [Batch 02184/03692] [00:19:59/00:13:48, 0.549s/it]: train_loss_raw=1.1318, running_loss=1.2284, LR=0.000100
[2025-08-10 16:26:35,926][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035424] [Batch 02196/03692] [00:20:05/00:13:41, 0.549s/it]: train_loss_raw=1.1514, running_loss=1.2276, LR=0.000100
[2025-08-10 16:26:41,968][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035436] [Batch 02208/03692] [00:20:11/00:13:34, 0.549s/it]: train_loss_raw=1.1708, running_loss=1.2271, LR=0.000100
[2025-08-10 16:26:47,974][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035448] [Batch 02220/03692] [00:20:17/00:13:27, 0.548s/it]: train_loss_raw=1.1834, running_loss=1.2278, LR=0.000100
[2025-08-10 16:26:54,289][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035460] [Batch 02232/03692] [00:20:23/00:13:20, 0.548s/it]: train_loss_raw=1.2676, running_loss=1.2246, LR=0.000100
[2025-08-10 16:27:00,561][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035472] [Batch 02244/03692] [00:20:29/00:13:13, 0.548s/it]: train_loss_raw=1.1660, running_loss=1.2216, LR=0.000100
[2025-08-10 16:27:06,892][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035484] [Batch 02256/03692] [00:20:36/00:13:06, 0.548s/it]: train_loss_raw=1.3145, running_loss=1.2234, LR=0.000100
[2025-08-10 16:27:13,026][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035496] [Batch 02268/03692] [00:20:42/00:13:00, 0.548s/it]: train_loss_raw=1.2202, running_loss=1.2209, LR=0.000100
[2025-08-10 16:27:19,184][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035508] [Batch 02280/03692] [00:20:48/00:12:53, 0.548s/it]: train_loss_raw=1.2191, running_loss=1.2195, LR=0.000100
[2025-08-10 16:27:25,380][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035520] [Batch 02292/03692] [00:20:54/00:12:46, 0.547s/it]: train_loss_raw=1.1954, running_loss=1.2205, LR=0.000100
[2025-08-10 16:27:31,497][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035532] [Batch 02304/03692] [00:21:00/00:12:39, 0.547s/it]: train_loss_raw=1.2521, running_loss=1.2211, LR=0.000100
[2025-08-10 16:27:37,656][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035544] [Batch 02316/03692] [00:21:06/00:12:32, 0.547s/it]: train_loss_raw=1.2611, running_loss=1.2183, LR=0.000100
[2025-08-10 16:27:44,122][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035556] [Batch 02328/03692] [00:21:13/00:12:26, 0.547s/it]: train_loss_raw=1.1385, running_loss=1.2161, LR=0.000100
[2025-08-10 16:27:50,678][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035568] [Batch 02340/03692] [00:21:20/00:12:19, 0.547s/it]: train_loss_raw=1.2443, running_loss=1.2194, LR=0.000100
[2025-08-10 16:27:57,005][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035580] [Batch 02352/03692] [00:21:26/00:12:12, 0.547s/it]: train_loss_raw=1.3093, running_loss=1.2197, LR=0.000100
[2025-08-10 16:28:03,434][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035592] [Batch 02364/03692] [00:21:32/00:12:06, 0.547s/it]: train_loss_raw=1.1761, running_loss=1.2225, LR=0.000100
[2025-08-10 16:28:09,588][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035604] [Batch 02376/03692] [00:21:38/00:11:59, 0.547s/it]: train_loss_raw=1.2802, running_loss=1.2199, LR=0.000100
[2025-08-10 16:28:16,002][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035616] [Batch 02388/03692] [00:21:45/00:11:52, 0.547s/it]: train_loss_raw=1.1880, running_loss=1.2196, LR=0.000100
[2025-08-10 16:28:22,291][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035628] [Batch 02400/03692] [00:21:51/00:11:46, 0.547s/it]: train_loss_raw=1.1906, running_loss=1.2205, LR=0.000100
[2025-08-10 16:28:28,501][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035640] [Batch 02412/03692] [00:21:57/00:11:39, 0.546s/it]: train_loss_raw=1.1784, running_loss=1.2206, LR=0.000100
[2025-08-10 16:28:34,682][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035652] [Batch 02424/03692] [00:22:04/00:11:32, 0.546s/it]: train_loss_raw=1.1149, running_loss=1.2224, LR=0.000100
[2025-08-10 16:28:41,010][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035664] [Batch 02436/03692] [00:22:10/00:11:25, 0.546s/it]: train_loss_raw=1.1166, running_loss=1.2187, LR=0.000100
[2025-08-10 16:28:47,592][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035676] [Batch 02448/03692] [00:22:16/00:11:19, 0.546s/it]: train_loss_raw=1.1753, running_loss=1.2191, LR=0.000100
[2025-08-10 16:28:54,118][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035688] [Batch 02460/03692] [00:22:23/00:11:12, 0.546s/it]: train_loss_raw=1.1168, running_loss=1.2162, LR=0.000100
[2025-08-10 16:29:00,631][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035700] [Batch 02472/03692] [00:22:29/00:11:06, 0.546s/it]: train_loss_raw=1.1636, running_loss=1.2197, LR=0.000100
[2025-08-10 16:29:07,237][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035712] [Batch 02484/03692] [00:22:36/00:10:59, 0.546s/it]: train_loss_raw=1.1794, running_loss=1.2179, LR=0.000100
[2025-08-10 16:29:13,740][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035724] [Batch 02496/03692] [00:22:43/00:10:53, 0.546s/it]: train_loss_raw=1.2123, running_loss=1.2150, LR=0.000100
[2025-08-10 16:29:19,882][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035736] [Batch 02508/03692] [00:22:49/00:10:46, 0.546s/it]: train_loss_raw=1.1846, running_loss=1.2182, LR=0.000100
[2025-08-10 16:29:26,025][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035748] [Batch 02520/03692] [00:22:55/00:10:39, 0.546s/it]: train_loss_raw=1.1735, running_loss=1.2175, LR=0.000100
[2025-08-10 16:29:32,070][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035760] [Batch 02532/03692] [00:23:01/00:10:32, 0.546s/it]: train_loss_raw=1.2082, running_loss=1.2166, LR=0.000100
[2025-08-10 16:29:38,367][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035772] [Batch 02544/03692] [00:23:07/00:10:26, 0.545s/it]: train_loss_raw=1.1456, running_loss=1.2171, LR=0.000100
[2025-08-10 16:29:44,944][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035784] [Batch 02556/03692] [00:23:14/00:10:19, 0.545s/it]: train_loss_raw=1.1514, running_loss=1.2101, LR=0.000100
[2025-08-10 16:29:51,636][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035796] [Batch 02568/03692] [00:23:20/00:10:13, 0.546s/it]: train_loss_raw=1.0264, running_loss=1.2070, LR=0.000100
[2025-08-10 16:29:57,931][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035808] [Batch 02580/03692] [00:23:27/00:10:06, 0.545s/it]: train_loss_raw=1.1232, running_loss=1.2046, LR=0.000100
[2025-08-10 16:30:04,397][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035820] [Batch 02592/03692] [00:23:33/00:09:59, 0.545s/it]: train_loss_raw=1.2655, running_loss=1.2046, LR=0.000100
[2025-08-10 16:30:10,788][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035832] [Batch 02604/03692] [00:23:40/00:09:53, 0.545s/it]: train_loss_raw=1.1513, running_loss=1.2033, LR=0.000100
[2025-08-10 16:30:17,294][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035844] [Batch 02616/03692] [00:23:46/00:09:46, 0.545s/it]: train_loss_raw=1.2884, running_loss=1.2038, LR=0.000100
[2025-08-10 16:30:23,894][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035856] [Batch 02628/03692] [00:23:53/00:09:40, 0.545s/it]: train_loss_raw=1.1474, running_loss=1.2070, LR=0.000100
[2025-08-10 16:30:30,546][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035868] [Batch 02640/03692] [00:23:59/00:09:33, 0.545s/it]: train_loss_raw=1.1353, running_loss=1.2066, LR=0.000100
[2025-08-10 16:30:37,165][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035880] [Batch 02652/03692] [00:24:06/00:09:27, 0.545s/it]: train_loss_raw=1.3117, running_loss=1.2084, LR=0.000100
[2025-08-10 16:30:43,743][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035892] [Batch 02664/03692] [00:24:13/00:09:20, 0.545s/it]: train_loss_raw=1.2856, running_loss=1.2097, LR=0.000100
[2025-08-10 16:30:49,912][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035904] [Batch 02676/03692] [00:24:19/00:09:14, 0.545s/it]: train_loss_raw=1.2039, running_loss=1.2063, LR=0.000100
[2025-08-10 16:30:56,067][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035916] [Batch 02688/03692] [00:24:25/00:09:07, 0.545s/it]: train_loss_raw=1.2181, running_loss=1.2096, LR=0.000100
[2025-08-10 16:31:02,497][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035928] [Batch 02700/03692] [00:24:31/00:09:00, 0.545s/it]: train_loss_raw=1.2204, running_loss=1.2140, LR=0.000100
[2025-08-10 16:31:08,609][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035940] [Batch 02712/03692] [00:24:37/00:08:54, 0.545s/it]: train_loss_raw=1.2232, running_loss=1.2128, LR=0.000100
[2025-08-10 16:31:14,844][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035952] [Batch 02724/03692] [00:24:44/00:08:47, 0.545s/it]: train_loss_raw=1.1742, running_loss=1.2111, LR=0.000100
[2025-08-10 16:31:20,871][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035964] [Batch 02736/03692] [00:24:50/00:08:40, 0.545s/it]: train_loss_raw=1.2193, running_loss=1.2099, LR=0.000100
[2025-08-10 16:31:27,078][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035976] [Batch 02748/03692] [00:24:56/00:08:34, 0.545s/it]: train_loss_raw=1.2157, running_loss=1.2132, LR=0.000100
[2025-08-10 16:31:33,419][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035988] [Batch 02760/03692] [00:25:02/00:08:27, 0.544s/it]: train_loss_raw=1.2997, running_loss=1.2157, LR=0.000100
[2025-08-10 16:31:39,645][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036000] [Batch 02772/03692] [00:25:08/00:08:20, 0.544s/it]: train_loss_raw=1.1207, running_loss=1.2108, LR=0.000100
[2025-08-10 16:31:51,198][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036012] [Batch 02784/03692] [00:25:20/00:08:15, 0.546s/it]: train_loss_raw=1.1683, running_loss=1.2094, LR=0.000100
[2025-08-10 16:31:57,441][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036024] [Batch 02796/03692] [00:25:26/00:08:09, 0.546s/it]: train_loss_raw=1.0397, running_loss=1.2065, LR=0.000100
[2025-08-10 16:32:03,918][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036036] [Batch 02808/03692] [00:25:33/00:08:02, 0.546s/it]: train_loss_raw=1.2480, running_loss=1.2046, LR=0.000100
[2025-08-10 16:32:10,488][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036048] [Batch 02820/03692] [00:25:39/00:07:56, 0.546s/it]: train_loss_raw=1.2874, running_loss=1.2073, LR=0.000100
[2025-08-10 16:32:17,197][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036060] [Batch 02832/03692] [00:25:46/00:07:49, 0.546s/it]: train_loss_raw=1.0963, running_loss=1.2052, LR=0.000100
[2025-08-10 16:32:23,790][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036072] [Batch 02844/03692] [00:25:53/00:07:43, 0.546s/it]: train_loss_raw=1.2701, running_loss=1.2045, LR=0.000100
[2025-08-10 16:32:30,360][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036084] [Batch 02856/03692] [00:25:59/00:07:36, 0.546s/it]: train_loss_raw=1.1506, running_loss=1.2075, LR=0.000100
[2025-08-10 16:32:36,782][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036096] [Batch 02868/03692] [00:26:06/00:07:29, 0.546s/it]: train_loss_raw=1.1616, running_loss=1.2094, LR=0.000100
[2025-08-10 16:32:43,435][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036108] [Batch 02880/03692] [00:26:12/00:07:23, 0.546s/it]: train_loss_raw=1.1935, running_loss=1.2066, LR=0.000100
[2025-08-10 16:32:50,137][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036120] [Batch 02892/03692] [00:26:19/00:07:16, 0.546s/it]: train_loss_raw=1.2626, running_loss=1.2096, LR=0.000100
[2025-08-10 16:32:56,717][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036132] [Batch 02904/03692] [00:26:26/00:07:10, 0.546s/it]: train_loss_raw=1.1417, running_loss=1.2056, LR=0.000100
[2025-08-10 16:33:03,075][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036144] [Batch 02916/03692] [00:26:32/00:07:03, 0.546s/it]: train_loss_raw=1.1530, running_loss=1.2033, LR=0.000100
[2025-08-10 16:33:09,187][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036156] [Batch 02928/03692] [00:26:38/00:06:57, 0.546s/it]: train_loss_raw=1.2746, running_loss=1.2032, LR=0.000100
[2025-08-10 16:33:15,540][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036168] [Batch 02940/03692] [00:26:44/00:06:50, 0.546s/it]: train_loss_raw=1.2657, running_loss=1.1999, LR=0.000100
[2025-08-10 16:33:21,959][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036180] [Batch 02952/03692] [00:26:51/00:06:43, 0.546s/it]: train_loss_raw=1.1338, running_loss=1.2009, LR=0.000100
[2025-08-10 16:33:28,247][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036192] [Batch 02964/03692] [00:26:57/00:06:37, 0.546s/it]: train_loss_raw=1.2980, running_loss=1.2009, LR=0.000100
[2025-08-10 16:33:34,448][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036204] [Batch 02976/03692] [00:27:03/00:06:30, 0.546s/it]: train_loss_raw=1.1449, running_loss=1.1980, LR=0.000100
[2025-08-10 16:33:40,518][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036216] [Batch 02988/03692] [00:27:09/00:06:24, 0.545s/it]: train_loss_raw=1.1045, running_loss=1.1973, LR=0.000100
[2025-08-10 16:33:46,741][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036228] [Batch 03000/03692] [00:27:16/00:06:17, 0.545s/it]: train_loss_raw=1.2896, running_loss=1.2007, LR=0.000100
[2025-08-10 16:33:52,789][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036240] [Batch 03012/03692] [00:27:22/00:06:10, 0.545s/it]: train_loss_raw=1.3284, running_loss=1.2027, LR=0.000100
[2025-08-10 16:33:58,949][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036252] [Batch 03024/03692] [00:27:28/00:06:04, 0.545s/it]: train_loss_raw=1.1519, running_loss=1.2020, LR=0.000100
[2025-08-10 16:34:05,341][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036264] [Batch 03036/03692] [00:27:34/00:05:57, 0.545s/it]: train_loss_raw=1.1836, running_loss=1.2030, LR=0.000100
[2025-08-10 16:34:11,824][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036276] [Batch 03048/03692] [00:27:41/00:05:50, 0.545s/it]: train_loss_raw=1.2316, running_loss=1.2014, LR=0.000100
[2025-08-10 16:34:18,465][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036288] [Batch 03060/03692] [00:27:47/00:05:44, 0.545s/it]: train_loss_raw=1.1762, running_loss=1.2034, LR=0.000100
[2025-08-10 16:34:25,252][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036300] [Batch 03072/03692] [00:27:54/00:05:37, 0.545s/it]: train_loss_raw=1.0659, running_loss=1.2069, LR=0.000100
[2025-08-10 16:34:31,835][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036312] [Batch 03084/03692] [00:28:01/00:05:31, 0.545s/it]: train_loss_raw=1.3013, running_loss=1.2084, LR=0.000100
[2025-08-10 16:34:38,181][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036324] [Batch 03096/03692] [00:28:07/00:05:24, 0.545s/it]: train_loss_raw=1.3169, running_loss=1.2088, LR=0.000100
[2025-08-10 16:34:44,317][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036336] [Batch 03108/03692] [00:28:13/00:05:18, 0.545s/it]: train_loss_raw=1.2677, running_loss=1.2059, LR=0.000100
[2025-08-10 16:34:50,570][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036348] [Batch 03120/03692] [00:28:19/00:05:11, 0.545s/it]: train_loss_raw=1.1589, running_loss=1.2064, LR=0.000100
[2025-08-10 16:34:56,827][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036360] [Batch 03132/03692] [00:28:26/00:05:05, 0.545s/it]: train_loss_raw=1.2133, running_loss=1.2055, LR=0.000100
[2025-08-10 16:35:03,249][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036372] [Batch 03144/03692] [00:28:32/00:04:58, 0.545s/it]: train_loss_raw=1.1184, running_loss=1.2019, LR=0.000100
[2025-08-10 16:35:09,389][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036384] [Batch 03156/03692] [00:28:38/00:04:51, 0.545s/it]: train_loss_raw=1.2939, running_loss=1.2050, LR=0.000100
[2025-08-10 16:35:15,390][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036396] [Batch 03168/03692] [00:28:44/00:04:45, 0.544s/it]: train_loss_raw=1.1202, running_loss=1.2062, LR=0.000100
[2025-08-10 16:35:21,656][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036408] [Batch 03180/03692] [00:28:50/00:04:38, 0.544s/it]: train_loss_raw=1.3874, running_loss=1.2107, LR=0.000100
[2025-08-10 16:35:27,654][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036420] [Batch 03192/03692] [00:28:56/00:04:32, 0.544s/it]: train_loss_raw=1.1458, running_loss=1.2072, LR=0.000100
[2025-08-10 16:35:33,711][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036432] [Batch 03204/03692] [00:29:03/00:04:25, 0.544s/it]: train_loss_raw=1.2675, running_loss=1.2059, LR=0.000100
[2025-08-10 16:35:39,934][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036444] [Batch 03216/03692] [00:29:09/00:04:18, 0.544s/it]: train_loss_raw=1.1336, running_loss=1.2082, LR=0.000100
[2025-08-10 16:35:46,088][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036456] [Batch 03228/03692] [00:29:15/00:04:12, 0.544s/it]: train_loss_raw=1.1991, running_loss=1.2091, LR=0.000100
[2025-08-10 16:35:52,596][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036468] [Batch 03240/03692] [00:29:21/00:04:05, 0.544s/it]: train_loss_raw=1.1584, running_loss=1.2079, LR=0.000100
[2025-08-10 16:35:58,834][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036480] [Batch 03252/03692] [00:29:28/00:03:59, 0.544s/it]: train_loss_raw=1.2396, running_loss=1.2063, LR=0.000100
[2025-08-10 16:36:05,560][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036492] [Batch 03264/03692] [00:29:34/00:03:52, 0.544s/it]: train_loss_raw=1.1642, running_loss=1.2033, LR=0.000100
[2025-08-10 16:36:12,136][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036504] [Batch 03276/03692] [00:29:41/00:03:46, 0.544s/it]: train_loss_raw=1.3018, running_loss=1.2037, LR=0.000100
[2025-08-10 16:36:18,782][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036516] [Batch 03288/03692] [00:29:48/00:03:39, 0.544s/it]: train_loss_raw=1.2006, running_loss=1.2045, LR=0.000100
[2025-08-10 16:36:25,411][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036528] [Batch 03300/03692] [00:29:54/00:03:33, 0.544s/it]: train_loss_raw=1.0986, running_loss=1.2074, LR=0.000100
[2025-08-10 16:36:31,914][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036540] [Batch 03312/03692] [00:30:01/00:03:26, 0.544s/it]: train_loss_raw=1.2385, running_loss=1.2038, LR=0.000100
[2025-08-10 16:36:38,617][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036552] [Batch 03324/03692] [00:30:07/00:03:20, 0.544s/it]: train_loss_raw=1.0929, running_loss=1.1974, LR=0.000100
[2025-08-10 16:36:44,942][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036564] [Batch 03336/03692] [00:30:14/00:03:13, 0.544s/it]: train_loss_raw=1.1252, running_loss=1.1992, LR=0.000100
[2025-08-10 16:36:51,054][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036576] [Batch 03348/03692] [00:30:20/00:03:07, 0.544s/it]: train_loss_raw=1.1446, running_loss=1.1971, LR=0.000100
[2025-08-10 16:36:57,036][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036588] [Batch 03360/03692] [00:30:26/00:03:00, 0.544s/it]: train_loss_raw=1.1577, running_loss=1.1951, LR=0.000100
[2025-08-10 16:37:03,130][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036600] [Batch 03372/03692] [00:30:32/00:02:53, 0.543s/it]: train_loss_raw=1.1847, running_loss=1.1986, LR=0.000100
[2025-08-10 16:37:09,477][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036612] [Batch 03384/03692] [00:30:38/00:02:47, 0.543s/it]: train_loss_raw=1.1938, running_loss=1.2014, LR=0.000100
[2025-08-10 16:37:15,987][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036624] [Batch 03396/03692] [00:30:45/00:02:40, 0.543s/it]: train_loss_raw=1.1029, running_loss=1.2005, LR=0.000100
[2025-08-10 16:37:22,676][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036636] [Batch 03408/03692] [00:30:51/00:02:34, 0.543s/it]: train_loss_raw=1.2303, running_loss=1.2017, LR=0.000100
[2025-08-10 16:37:28,812][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036648] [Batch 03420/03692] [00:30:58/00:02:27, 0.543s/it]: train_loss_raw=1.0828, running_loss=1.2006, LR=0.000100
[2025-08-10 16:37:35,052][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036660] [Batch 03432/03692] [00:31:04/00:02:21, 0.543s/it]: train_loss_raw=1.3631, running_loss=1.2044, LR=0.000100
[2025-08-10 16:37:41,065][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036672] [Batch 03444/03692] [00:31:10/00:02:14, 0.543s/it]: train_loss_raw=1.2321, running_loss=1.2057, LR=0.000100
[2025-08-10 16:37:47,146][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036684] [Batch 03456/03692] [00:31:16/00:02:08, 0.543s/it]: train_loss_raw=1.2805, running_loss=1.2041, LR=0.000100
[2025-08-10 16:37:53,420][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036696] [Batch 03468/03692] [00:31:22/00:02:01, 0.543s/it]: train_loss_raw=1.0255, running_loss=1.2033, LR=0.000100
[2025-08-10 16:37:59,461][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036708] [Batch 03480/03692] [00:31:28/00:01:55, 0.543s/it]: train_loss_raw=1.1278, running_loss=1.2017, LR=0.000100
[2025-08-10 16:38:05,873][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036720] [Batch 03492/03692] [00:31:35/00:01:48, 0.543s/it]: train_loss_raw=1.1899, running_loss=1.1997, LR=0.000100
[2025-08-10 16:38:12,119][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036732] [Batch 03504/03692] [00:31:41/00:01:42, 0.543s/it]: train_loss_raw=1.1606, running_loss=1.1975, LR=0.000100
[2025-08-10 16:38:18,415][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036744] [Batch 03516/03692] [00:31:47/00:01:35, 0.543s/it]: train_loss_raw=1.1760, running_loss=1.1955, LR=0.000100
[2025-08-10 16:38:24,787][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036756] [Batch 03528/03692] [00:31:54/00:01:28, 0.543s/it]: train_loss_raw=1.1174, running_loss=1.1956, LR=0.000100
[2025-08-10 16:38:30,985][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036768] [Batch 03540/03692] [00:32:00/00:01:22, 0.542s/it]: train_loss_raw=1.2756, running_loss=1.1987, LR=0.000100
[2025-08-10 16:38:37,131][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036780] [Batch 03552/03692] [00:32:06/00:01:15, 0.542s/it]: train_loss_raw=1.2409, running_loss=1.2015, LR=0.000100
[2025-08-10 16:38:43,328][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036792] [Batch 03564/03692] [00:32:12/00:01:09, 0.542s/it]: train_loss_raw=1.1773, running_loss=1.2047, LR=0.000100
[2025-08-10 16:38:49,541][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036804] [Batch 03576/03692] [00:32:18/00:01:02, 0.542s/it]: train_loss_raw=1.1974, running_loss=1.2040, LR=0.000100
[2025-08-10 16:38:55,687][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036816] [Batch 03588/03692] [00:32:25/00:00:56, 0.542s/it]: train_loss_raw=1.2272, running_loss=1.1980, LR=0.000100
[2025-08-10 16:39:01,748][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036828] [Batch 03600/03692] [00:32:31/00:00:49, 0.542s/it]: train_loss_raw=1.2704, running_loss=1.1972, LR=0.000100
[2025-08-10 16:39:07,728][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036840] [Batch 03612/03692] [00:32:37/00:00:43, 0.542s/it]: train_loss_raw=1.1935, running_loss=1.1955, LR=0.000100
[2025-08-10 16:39:13,800][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036852] [Batch 03624/03692] [00:32:43/00:00:36, 0.542s/it]: train_loss_raw=1.3214, running_loss=1.1962, LR=0.000100
[2025-08-10 16:39:19,774][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036864] [Batch 03636/03692] [00:32:49/00:00:30, 0.542s/it]: train_loss_raw=1.1333, running_loss=1.1978, LR=0.000100
[2025-08-10 16:39:25,805][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036876] [Batch 03648/03692] [00:32:55/00:00:23, 0.541s/it]: train_loss_raw=1.1483, running_loss=1.1975, LR=0.000100
[2025-08-10 16:39:31,844][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036888] [Batch 03660/03692] [00:33:01/00:00:17, 0.541s/it]: train_loss_raw=1.2820, running_loss=1.1967, LR=0.000100
[2025-08-10 16:39:37,998][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036900] [Batch 03672/03692] [00:33:07/00:00:10, 0.541s/it]: train_loss_raw=1.2166, running_loss=1.1947, LR=0.000100
[2025-08-10 16:39:44,356][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036912] [Batch 03684/03692] [00:33:13/00:00:04, 0.541s/it]: train_loss_raw=1.1263, running_loss=1.1981, LR=0.000100
[2025-08-10 16:40:01,382][__main__][INFO] - [VALIDATION] [Epoch 09/29] Starting validation.
[2025-08-10 16:40:36,713][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 036921] [Batch 00011/00025] [00:00:35/00:00:38, 2.944s/it]
[2025-08-10 16:40:53,890][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 036921] [Batch 00023/00025] [00:00:52/00:00:02, 2.188s/it]
[2025-08-10 16:40:55,110][__main__][INFO] - [VALIDATION] [Epoch 09/29] train_loss=1.19850, valid_loss=1.16919
[2025-08-10 16:40:55,111][__main__][INFO] - [VALIDATION] [Epoch 09/29] Metrics:
[2025-08-10 16:40:55,111][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_er      0.506
[2025-08-10 16:40:55,111][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_prec    0.224
[2025-08-10 16:40:55,111][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_recall  0.229
[2025-08-10 16:40:55,111][__main__][INFO] - [VALIDATION] [Epoch 09/29] - pep_recall 0.185
[2025-08-10 16:40:55,115][__main__][INFO] - [TRAIN] [Epoch 09/29] Epoch complete, total time 05:44:54, remaining time 11:29:48, 00:34:29 per epoch
[2025-08-10 16:40:57,060][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036924] [Batch 00004/03692] [00:00:01/00:25:36, 0.417s/it]: train_loss_raw=1.0882, running_loss=1.1268, LR=0.000100
[2025-08-10 16:41:03,107][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036936] [Batch 00016/03692] [00:00:07/00:29:32, 0.482s/it]: train_loss_raw=1.2069, running_loss=1.1275, LR=0.000100
[2025-08-10 16:41:09,378][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036948] [Batch 00028/03692] [00:00:13/00:30:29, 0.499s/it]: train_loss_raw=1.1444, running_loss=1.1292, LR=0.000100
[2025-08-10 16:41:15,376][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036960] [Batch 00040/03692] [00:00:19/00:30:24, 0.500s/it]: train_loss_raw=0.9979, running_loss=1.1271, LR=0.000100
[2025-08-10 16:41:21,396][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036972] [Batch 00052/03692] [00:00:26/00:30:20, 0.500s/it]: train_loss_raw=1.1509, running_loss=1.1316, LR=0.000100
[2025-08-10 16:41:27,513][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036984] [Batch 00064/03692] [00:00:32/00:30:20, 0.502s/it]: train_loss_raw=1.1842, running_loss=1.1332, LR=0.000100
[2025-08-10 16:41:33,569][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036996] [Batch 00076/03692] [00:00:38/00:30:16, 0.502s/it]: train_loss_raw=1.0651, running_loss=1.1352, LR=0.000100
[2025-08-10 16:41:39,805][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037008] [Batch 00088/03692] [00:00:44/00:30:18, 0.505s/it]: train_loss_raw=1.0499, running_loss=1.1336, LR=0.000100
[2025-08-10 16:41:46,374][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037020] [Batch 00100/03692] [00:00:50/00:30:31, 0.510s/it]: train_loss_raw=1.1387, running_loss=1.1385, LR=0.000100
[2025-08-10 16:41:52,659][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037032] [Batch 00112/03692] [00:00:57/00:30:30, 0.511s/it]: train_loss_raw=1.1370, running_loss=1.1369, LR=0.000100
[2025-08-10 16:41:58,656][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037044] [Batch 00124/03692] [00:01:03/00:30:20, 0.510s/it]: train_loss_raw=1.2264, running_loss=1.1388, LR=0.000100
[2025-08-10 16:42:04,766][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037056] [Batch 00136/03692] [00:01:09/00:30:13, 0.510s/it]: train_loss_raw=1.2115, running_loss=1.1394, LR=0.000100
[2025-08-10 16:42:10,833][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037068] [Batch 00148/03692] [00:01:15/00:30:06, 0.510s/it]: train_loss_raw=1.1120, running_loss=1.1436, LR=0.000100
[2025-08-10 16:42:16,893][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037080] [Batch 00160/03692] [00:01:21/00:29:59, 0.509s/it]: train_loss_raw=1.1369, running_loss=1.1387, LR=0.000100
[2025-08-10 16:42:22,888][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037092] [Batch 00172/03692] [00:01:27/00:29:50, 0.509s/it]: train_loss_raw=1.0617, running_loss=1.1377, LR=0.000100
[2025-08-10 16:42:28,977][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037104] [Batch 00184/03692] [00:01:33/00:29:44, 0.509s/it]: train_loss_raw=1.1089, running_loss=1.1399, LR=0.000100
[2025-08-10 16:42:35,000][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037116] [Batch 00196/03692] [00:01:39/00:29:36, 0.508s/it]: train_loss_raw=1.2390, running_loss=1.1436, LR=0.000100
[2025-08-10 16:42:41,275][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037128] [Batch 00208/03692] [00:01:45/00:29:33, 0.509s/it]: train_loss_raw=1.0361, running_loss=1.1414, LR=0.000100
[2025-08-10 16:42:47,731][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037140] [Batch 00220/03692] [00:01:52/00:29:32, 0.511s/it]: train_loss_raw=1.1106, running_loss=1.1438, LR=0.000100
[2025-08-10 16:42:53,873][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037152] [Batch 00232/03692] [00:01:58/00:29:26, 0.511s/it]: train_loss_raw=1.2931, running_loss=1.1517, LR=0.000100
[2025-08-10 16:43:00,400][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037164] [Batch 00244/03692] [00:02:05/00:29:26, 0.512s/it]: train_loss_raw=1.1899, running_loss=1.1517, LR=0.000100
[2025-08-10 16:43:06,866][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037176] [Batch 00256/03692] [00:02:11/00:29:24, 0.514s/it]: train_loss_raw=0.9808, running_loss=1.1507, LR=0.000100
[2025-08-10 16:43:13,324][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037188] [Batch 00268/03692] [00:02:17/00:29:22, 0.515s/it]: train_loss_raw=1.2608, running_loss=1.1522, LR=0.000100
[2025-08-10 16:43:19,377][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037200] [Batch 00280/03692] [00:02:23/00:29:14, 0.514s/it]: train_loss_raw=1.2509, running_loss=1.1483, LR=0.000100
[2025-08-10 16:43:25,536][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037212] [Batch 00292/03692] [00:02:30/00:29:08, 0.514s/it]: train_loss_raw=1.0447, running_loss=1.1478, LR=0.000100
[2025-08-10 16:43:31,654][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037224] [Batch 00304/03692] [00:02:36/00:29:01, 0.514s/it]: train_loss_raw=1.2371, running_loss=1.1472, LR=0.000100
[2025-08-10 16:43:37,896][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037236] [Batch 00316/03692] [00:02:42/00:28:56, 0.514s/it]: train_loss_raw=1.1575, running_loss=1.1497, LR=0.000100
[2025-08-10 16:43:44,198][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037248] [Batch 00328/03692] [00:02:48/00:28:51, 0.515s/it]: train_loss_raw=1.1744, running_loss=1.1497, LR=0.000100
[2025-08-10 16:43:50,499][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037260] [Batch 00340/03692] [00:02:55/00:28:46, 0.515s/it]: train_loss_raw=1.0147, running_loss=1.1513, LR=0.000100
[2025-08-10 16:43:57,124][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037272] [Batch 00352/03692] [00:03:01/00:28:44, 0.516s/it]: train_loss_raw=1.1894, running_loss=1.1459, LR=0.000100
[2025-08-10 16:44:03,750][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037284] [Batch 00364/03692] [00:03:08/00:28:42, 0.517s/it]: train_loss_raw=1.2728, running_loss=1.1481, LR=0.000100
[2025-08-10 16:44:10,110][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037296] [Batch 00376/03692] [00:03:14/00:28:37, 0.518s/it]: train_loss_raw=1.2500, running_loss=1.1479, LR=0.000100
[2025-08-10 16:44:16,486][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037308] [Batch 00388/03692] [00:03:21/00:28:32, 0.518s/it]: train_loss_raw=1.1374, running_loss=1.1475, LR=0.000100
[2025-08-10 16:44:22,462][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037320] [Batch 00400/03692] [00:03:27/00:28:24, 0.518s/it]: train_loss_raw=1.0602, running_loss=1.1455, LR=0.000100
[2025-08-10 16:44:28,516][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037332] [Batch 00412/03692] [00:03:33/00:28:16, 0.517s/it]: train_loss_raw=1.1262, running_loss=1.1480, LR=0.000100
[2025-08-10 16:44:34,583][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037344] [Batch 00424/03692] [00:03:39/00:28:09, 0.517s/it]: train_loss_raw=1.2030, running_loss=1.1457, LR=0.000100
[2025-08-10 16:44:40,631][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037356] [Batch 00436/03692] [00:03:45/00:28:02, 0.517s/it]: train_loss_raw=1.1034, running_loss=1.1462, LR=0.000100
[2025-08-10 16:44:46,683][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037368] [Batch 00448/03692] [00:03:51/00:27:54, 0.516s/it]: train_loss_raw=1.0473, running_loss=1.1505, LR=0.000100
[2025-08-10 16:44:52,744][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037380] [Batch 00460/03692] [00:03:57/00:27:47, 0.516s/it]: train_loss_raw=0.9991, running_loss=1.1453, LR=0.000100
[2025-08-10 16:44:58,822][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037392] [Batch 00472/03692] [00:04:03/00:27:40, 0.516s/it]: train_loss_raw=1.2296, running_loss=1.1501, LR=0.000100
[2025-08-10 16:45:04,942][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037404] [Batch 00484/03692] [00:04:09/00:27:34, 0.516s/it]: train_loss_raw=1.1068, running_loss=1.1521, LR=0.000100
[2025-08-10 16:45:11,003][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037416] [Batch 00496/03692] [00:04:15/00:27:27, 0.515s/it]: train_loss_raw=1.1327, running_loss=1.1480, LR=0.000100
[2025-08-10 16:45:17,035][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037428] [Batch 00508/03692] [00:04:21/00:27:19, 0.515s/it]: train_loss_raw=1.0337, running_loss=1.1493, LR=0.000100
[2025-08-10 16:45:23,161][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037440] [Batch 00520/03692] [00:04:27/00:27:13, 0.515s/it]: train_loss_raw=1.1211, running_loss=1.1507, LR=0.000100
[2025-08-10 16:45:29,177][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037452] [Batch 00532/03692] [00:04:33/00:27:06, 0.515s/it]: train_loss_raw=1.0743, running_loss=1.1489, LR=0.000100
[2025-08-10 16:45:35,233][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037464] [Batch 00544/03692] [00:04:39/00:26:59, 0.514s/it]: train_loss_raw=1.1875, running_loss=1.1522, LR=0.000100
[2025-08-10 16:45:41,259][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037476] [Batch 00556/03692] [00:04:45/00:26:52, 0.514s/it]: train_loss_raw=1.0546, running_loss=1.1507, LR=0.000100
[2025-08-10 16:45:47,324][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037488] [Batch 00568/03692] [00:04:51/00:26:45, 0.514s/it]: train_loss_raw=1.1587, running_loss=1.1475, LR=0.000100
[2025-08-10 16:45:53,426][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037500] [Batch 00580/03692] [00:04:58/00:26:39, 0.514s/it]: train_loss_raw=1.2037, running_loss=1.1473, LR=0.000100
[2025-08-10 16:45:59,391][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037512] [Batch 00592/03692] [00:05:03/00:26:31, 0.514s/it]: train_loss_raw=1.1583, running_loss=1.1484, LR=0.000100
[2025-08-10 16:46:05,518][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037524] [Batch 00604/03692] [00:05:10/00:26:25, 0.513s/it]: train_loss_raw=1.1819, running_loss=1.1403, LR=0.000100
[2025-08-10 16:46:11,581][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037536] [Batch 00616/03692] [00:05:16/00:26:18, 0.513s/it]: train_loss_raw=1.1614, running_loss=1.1377, LR=0.000100
[2025-08-10 16:46:17,624][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037548] [Batch 00628/03692] [00:05:22/00:26:12, 0.513s/it]: train_loss_raw=1.2368, running_loss=1.1391, LR=0.000100
[2025-08-10 16:46:23,612][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037560] [Batch 00640/03692] [00:05:28/00:26:05, 0.513s/it]: train_loss_raw=1.2307, running_loss=1.1402, LR=0.000100
[2025-08-10 16:46:29,576][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037572] [Batch 00652/03692] [00:05:34/00:25:58, 0.513s/it]: train_loss_raw=1.0783, running_loss=1.1380, LR=0.000100
[2025-08-10 16:46:35,682][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037584] [Batch 00664/03692] [00:05:40/00:25:51, 0.512s/it]: train_loss_raw=1.2576, running_loss=1.1399, LR=0.000100
[2025-08-10 16:46:42,253][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037596] [Batch 00676/03692] [00:05:46/00:25:47, 0.513s/it]: train_loss_raw=1.1409, running_loss=1.1394, LR=0.000100
[2025-08-10 16:46:48,813][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037608] [Batch 00688/03692] [00:05:53/00:25:43, 0.514s/it]: train_loss_raw=1.1798, running_loss=1.1400, LR=0.000100
[2025-08-10 16:46:55,430][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037620] [Batch 00700/03692] [00:06:00/00:25:38, 0.514s/it]: train_loss_raw=1.0002, running_loss=1.1412, LR=0.000100
[2025-08-10 16:47:01,984][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037632] [Batch 00712/03692] [00:06:06/00:25:34, 0.515s/it]: train_loss_raw=1.1261, running_loss=1.1417, LR=0.000100
[2025-08-10 16:47:08,590][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037644] [Batch 00724/03692] [00:06:13/00:25:29, 0.515s/it]: train_loss_raw=1.2128, running_loss=1.1412, LR=0.000100
[2025-08-10 16:47:15,191][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037656] [Batch 00736/03692] [00:06:19/00:25:25, 0.516s/it]: train_loss_raw=1.1960, running_loss=1.1415, LR=0.000100
[2025-08-10 16:47:21,770][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037668] [Batch 00748/03692] [00:06:26/00:25:20, 0.517s/it]: train_loss_raw=1.0956, running_loss=1.1403, LR=0.000100
[2025-08-10 16:47:28,326][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037680] [Batch 00760/03692] [00:06:32/00:25:15, 0.517s/it]: train_loss_raw=0.9717, running_loss=1.1412, LR=0.000100
[2025-08-10 16:47:34,506][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037692] [Batch 00772/03692] [00:06:39/00:25:09, 0.517s/it]: train_loss_raw=1.1119, running_loss=1.1428, LR=0.000100
[2025-08-10 16:47:40,505][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037704] [Batch 00784/03692] [00:06:45/00:25:02, 0.517s/it]: train_loss_raw=1.1412, running_loss=1.1401, LR=0.000100
[2025-08-10 16:47:46,559][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037716] [Batch 00796/03692] [00:06:51/00:24:55, 0.517s/it]: train_loss_raw=1.1968, running_loss=1.1408, LR=0.000100
[2025-08-10 16:47:52,858][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037728] [Batch 00808/03692] [00:06:57/00:24:50, 0.517s/it]: train_loss_raw=1.1608, running_loss=1.1453, LR=0.000100
[2025-08-10 16:47:59,041][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037740] [Batch 00820/03692] [00:07:03/00:24:43, 0.517s/it]: train_loss_raw=1.1766, running_loss=1.1470, LR=0.000100
[2025-08-10 16:48:05,088][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037752] [Batch 00832/03692] [00:07:09/00:24:37, 0.516s/it]: train_loss_raw=1.1274, running_loss=1.1458, LR=0.000100
[2025-08-10 16:48:11,112][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037764] [Batch 00844/03692] [00:07:15/00:24:30, 0.516s/it]: train_loss_raw=1.1084, running_loss=1.1430, LR=0.000100
[2025-08-10 16:48:17,150][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037776] [Batch 00856/03692] [00:07:21/00:24:23, 0.516s/it]: train_loss_raw=1.0967, running_loss=1.1425, LR=0.000100
[2025-08-10 16:48:23,292][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037788] [Batch 00868/03692] [00:07:27/00:24:17, 0.516s/it]: train_loss_raw=1.3338, running_loss=1.1456, LR=0.000100
[2025-08-10 16:48:29,453][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037800] [Batch 00880/03692] [00:07:34/00:24:10, 0.516s/it]: train_loss_raw=1.1062, running_loss=1.1464, LR=0.000100
[2025-08-10 16:48:35,673][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037812] [Batch 00892/03692] [00:07:40/00:24:04, 0.516s/it]: train_loss_raw=1.2044, running_loss=1.1506, LR=0.000100
[2025-08-10 16:48:41,721][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037824] [Batch 00904/03692] [00:07:46/00:23:58, 0.516s/it]: train_loss_raw=1.0070, running_loss=1.1501, LR=0.000100
[2025-08-10 16:48:47,886][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037836] [Batch 00916/03692] [00:07:52/00:23:51, 0.516s/it]: train_loss_raw=1.1034, running_loss=1.1493, LR=0.000100
[2025-08-10 16:48:54,010][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037848] [Batch 00928/03692] [00:07:58/00:23:45, 0.516s/it]: train_loss_raw=1.1893, running_loss=1.1465, LR=0.000100
[2025-08-10 16:49:00,177][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037860] [Batch 00940/03692] [00:08:04/00:23:39, 0.516s/it]: train_loss_raw=1.1898, running_loss=1.1478, LR=0.000100
[2025-08-10 16:49:06,147][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037872] [Batch 00952/03692] [00:08:10/00:23:32, 0.515s/it]: train_loss_raw=0.9730, running_loss=1.1461, LR=0.000100
[2025-08-10 16:49:12,213][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037884] [Batch 00964/03692] [00:08:16/00:23:25, 0.515s/it]: train_loss_raw=1.1966, running_loss=1.1470, LR=0.000100
[2025-08-10 16:49:18,618][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037896] [Batch 00976/03692] [00:08:23/00:23:20, 0.516s/it]: train_loss_raw=1.1081, running_loss=1.1459, LR=0.000100
[2025-08-10 16:49:24,664][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037908] [Batch 00988/03692] [00:08:29/00:23:13, 0.515s/it]: train_loss_raw=1.1924, running_loss=1.1456, LR=0.000100
[2025-08-10 16:49:30,804][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037920] [Batch 01000/03692] [00:08:35/00:23:07, 0.515s/it]: train_loss_raw=1.2114, running_loss=1.1490, LR=0.000100
[2025-08-10 16:49:36,969][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037932] [Batch 01012/03692] [00:08:41/00:23:01, 0.515s/it]: train_loss_raw=1.2135, running_loss=1.1479, LR=0.000100
[2025-08-10 16:49:43,246][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037944] [Batch 01024/03692] [00:08:47/00:22:55, 0.515s/it]: train_loss_raw=1.3244, running_loss=1.1498, LR=0.000100
[2025-08-10 16:49:49,453][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037956] [Batch 01036/03692] [00:08:54/00:22:49, 0.516s/it]: train_loss_raw=1.1730, running_loss=1.1527, LR=0.000100
[2025-08-10 16:49:55,779][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037968] [Batch 01048/03692] [00:09:00/00:22:43, 0.516s/it]: train_loss_raw=1.1529, running_loss=1.1572, LR=0.000100
[2025-08-10 16:50:02,013][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037980] [Batch 01060/03692] [00:09:06/00:22:37, 0.516s/it]: train_loss_raw=1.1563, running_loss=1.1552, LR=0.000100
[2025-08-10 16:50:08,384][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037992] [Batch 01072/03692] [00:09:12/00:22:31, 0.516s/it]: train_loss_raw=1.1480, running_loss=1.1560, LR=0.000100
[2025-08-10 16:50:20,373][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038004] [Batch 01084/03692] [00:09:24/00:22:39, 0.521s/it]: train_loss_raw=1.0644, running_loss=1.1537, LR=0.000100
[2025-08-10 16:50:26,930][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038016] [Batch 01096/03692] [00:09:31/00:22:33, 0.521s/it]: train_loss_raw=1.1543, running_loss=1.1539, LR=0.000100
[2025-08-10 16:50:33,465][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038028] [Batch 01108/03692] [00:09:38/00:22:28, 0.522s/it]: train_loss_raw=1.2505, running_loss=1.1523, LR=0.000100
[2025-08-10 16:50:40,142][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038040] [Batch 01120/03692] [00:09:44/00:22:22, 0.522s/it]: train_loss_raw=1.0863, running_loss=1.1517, LR=0.000100
[2025-08-10 16:50:46,652][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038052] [Batch 01132/03692] [00:09:51/00:22:17, 0.522s/it]: train_loss_raw=1.1024, running_loss=1.1502, LR=0.000100
[2025-08-10 16:50:53,438][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038064] [Batch 01144/03692] [00:09:58/00:22:12, 0.523s/it]: train_loss_raw=1.0141, running_loss=1.1485, LR=0.000100
[2025-08-10 16:51:00,276][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038076] [Batch 01156/03692] [00:10:04/00:22:06, 0.523s/it]: train_loss_raw=1.0024, running_loss=1.1451, LR=0.000100
[2025-08-10 16:51:06,890][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038088] [Batch 01168/03692] [00:10:11/00:22:01, 0.524s/it]: train_loss_raw=1.2843, running_loss=1.1491, LR=0.000100
[2025-08-10 16:51:13,468][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038100] [Batch 01180/03692] [00:10:18/00:21:55, 0.524s/it]: train_loss_raw=1.2379, running_loss=1.1474, LR=0.000100
[2025-08-10 16:51:20,189][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038112] [Batch 01192/03692] [00:10:24/00:21:50, 0.524s/it]: train_loss_raw=1.0071, running_loss=1.1495, LR=0.000100
[2025-08-10 16:51:26,776][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038124] [Batch 01204/03692] [00:10:31/00:21:44, 0.524s/it]: train_loss_raw=1.0855, running_loss=1.1460, LR=0.000100
[2025-08-10 16:51:33,552][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038136] [Batch 01216/03692] [00:10:38/00:21:39, 0.525s/it]: train_loss_raw=1.0289, running_loss=1.1465, LR=0.000100
[2025-08-10 16:51:40,071][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038148] [Batch 01228/03692] [00:10:44/00:21:33, 0.525s/it]: train_loss_raw=1.1698, running_loss=1.1487, LR=0.000100
[2025-08-10 16:51:46,767][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038160] [Batch 01240/03692] [00:10:51/00:21:28, 0.525s/it]: train_loss_raw=1.0783, running_loss=1.1449, LR=0.000100
[2025-08-10 16:51:53,350][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038172] [Batch 01252/03692] [00:10:57/00:21:22, 0.526s/it]: train_loss_raw=1.2104, running_loss=1.1468, LR=0.000100
[2025-08-10 16:51:59,896][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038184] [Batch 01264/03692] [00:11:04/00:21:16, 0.526s/it]: train_loss_raw=1.0660, running_loss=1.1449, LR=0.000100
[2025-08-10 16:52:06,623][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038196] [Batch 01276/03692] [00:11:11/00:21:10, 0.526s/it]: train_loss_raw=1.1705, running_loss=1.1431, LR=0.000100
[2025-08-10 16:52:13,250][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038208] [Batch 01288/03692] [00:11:17/00:21:05, 0.526s/it]: train_loss_raw=1.1887, running_loss=1.1456, LR=0.000100
[2025-08-10 16:52:19,931][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038220] [Batch 01300/03692] [00:11:24/00:20:59, 0.527s/it]: train_loss_raw=1.0994, running_loss=1.1472, LR=0.000100
[2025-08-10 16:52:26,285][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038232] [Batch 01312/03692] [00:11:30/00:20:53, 0.527s/it]: train_loss_raw=1.2600, running_loss=1.1451, LR=0.000100
[2025-08-10 16:52:32,390][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038244] [Batch 01324/03692] [00:11:36/00:20:46, 0.526s/it]: train_loss_raw=1.1849, running_loss=1.1435, LR=0.000100
[2025-08-10 16:52:38,471][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038256] [Batch 01336/03692] [00:11:43/00:20:39, 0.526s/it]: train_loss_raw=1.0899, running_loss=1.1436, LR=0.000100
[2025-08-10 16:52:44,621][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038268] [Batch 01348/03692] [00:11:49/00:20:33, 0.526s/it]: train_loss_raw=0.9997, running_loss=1.1410, LR=0.000100
[2025-08-10 16:52:50,799][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038280] [Batch 01360/03692] [00:11:55/00:20:26, 0.526s/it]: train_loss_raw=1.1166, running_loss=1.1405, LR=0.000100
[2025-08-10 16:52:56,860][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038292] [Batch 01372/03692] [00:12:01/00:20:19, 0.526s/it]: train_loss_raw=1.0683, running_loss=1.1417, LR=0.000100
[2025-08-10 16:53:03,249][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038304] [Batch 01384/03692] [00:12:07/00:20:13, 0.526s/it]: train_loss_raw=1.0243, running_loss=1.1397, LR=0.000100
[2025-08-10 16:53:09,403][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038316] [Batch 01396/03692] [00:12:14/00:20:07, 0.526s/it]: train_loss_raw=1.1246, running_loss=1.1387, LR=0.000100
[2025-08-10 16:53:15,749][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038328] [Batch 01408/03692] [00:12:20/00:20:00, 0.526s/it]: train_loss_raw=1.1838, running_loss=1.1387, LR=0.000100
[2025-08-10 16:53:21,802][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038340] [Batch 01420/03692] [00:12:26/00:19:54, 0.526s/it]: train_loss_raw=1.1752, running_loss=1.1417, LR=0.000100
[2025-08-10 16:53:27,917][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038352] [Batch 01432/03692] [00:12:32/00:19:47, 0.526s/it]: train_loss_raw=1.2291, running_loss=1.1422, LR=0.000100
[2025-08-10 16:53:34,406][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038364] [Batch 01444/03692] [00:12:39/00:19:41, 0.526s/it]: train_loss_raw=1.1541, running_loss=1.1420, LR=0.000100
[2025-08-10 16:53:40,974][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038376] [Batch 01456/03692] [00:12:45/00:19:35, 0.526s/it]: train_loss_raw=0.9714, running_loss=1.1406, LR=0.000100
[2025-08-10 16:53:47,547][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038388] [Batch 01468/03692] [00:12:52/00:19:29, 0.526s/it]: train_loss_raw=1.1797, running_loss=1.1423, LR=0.000100
[2025-08-10 16:53:53,658][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038400] [Batch 01480/03692] [00:12:58/00:19:23, 0.526s/it]: train_loss_raw=1.0695, running_loss=1.1430, LR=0.000100
[2025-08-10 16:54:00,088][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038412] [Batch 01492/03692] [00:13:04/00:19:17, 0.526s/it]: train_loss_raw=1.1997, running_loss=1.1425, LR=0.000100
[2025-08-10 16:54:06,444][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038424] [Batch 01504/03692] [00:13:11/00:19:10, 0.526s/it]: train_loss_raw=1.1360, running_loss=1.1453, LR=0.000100
[2025-08-10 16:54:12,965][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038436] [Batch 01516/03692] [00:13:17/00:19:04, 0.526s/it]: train_loss_raw=1.1530, running_loss=1.1410, LR=0.000100
[2025-08-10 16:54:19,762][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038448] [Batch 01528/03692] [00:13:24/00:18:59, 0.526s/it]: train_loss_raw=1.1552, running_loss=1.1424, LR=0.000100
[2025-08-10 16:55:14,928][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038460] [Batch 01540/03692] [00:14:19/00:20:01, 0.558s/it]: train_loss_raw=1.1134, running_loss=1.1444, LR=0.000100
[2025-08-10 16:55:20,936][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038472] [Batch 01552/03692] [00:14:25/00:19:53, 0.558s/it]: train_loss_raw=1.0883, running_loss=1.1382, LR=0.000100
[2025-08-10 16:55:27,058][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038484] [Batch 01564/03692] [00:14:31/00:19:45, 0.557s/it]: train_loss_raw=1.1633, running_loss=1.1455, LR=0.000100
[2025-08-10 16:55:33,232][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038496] [Batch 01576/03692] [00:14:37/00:19:38, 0.557s/it]: train_loss_raw=1.1218, running_loss=1.1460, LR=0.000100
[2025-08-10 16:55:39,554][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038508] [Batch 01588/03692] [00:14:44/00:19:31, 0.557s/it]: train_loss_raw=1.1582, running_loss=1.1507, LR=0.000100
[2025-08-10 16:55:45,877][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038520] [Batch 01600/03692] [00:14:50/00:19:24, 0.557s/it]: train_loss_raw=1.2205, running_loss=1.1511, LR=0.000100
[2025-08-10 16:55:52,271][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038532] [Batch 01612/03692] [00:14:56/00:19:17, 0.556s/it]: train_loss_raw=1.1444, running_loss=1.1550, LR=0.000100
[2025-08-10 16:55:58,389][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038544] [Batch 01624/03692] [00:15:02/00:19:09, 0.556s/it]: train_loss_raw=1.2285, running_loss=1.1560, LR=0.000100
[2025-08-10 16:56:04,722][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038556] [Batch 01636/03692] [00:15:09/00:19:02, 0.556s/it]: train_loss_raw=1.1273, running_loss=1.1574, LR=0.000100
[2025-08-10 16:56:10,958][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038568] [Batch 01648/03692] [00:15:15/00:18:55, 0.556s/it]: train_loss_raw=1.1996, running_loss=1.1589, LR=0.000100
[2025-08-10 16:56:17,040][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038580] [Batch 01660/03692] [00:15:21/00:18:48, 0.555s/it]: train_loss_raw=1.1959, running_loss=1.1581, LR=0.000100
[2025-08-10 16:56:23,218][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038592] [Batch 01672/03692] [00:15:27/00:18:40, 0.555s/it]: train_loss_raw=1.1258, running_loss=1.1610, LR=0.000100
[2025-08-10 16:56:29,288][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038604] [Batch 01684/03692] [00:15:33/00:18:33, 0.555s/it]: train_loss_raw=1.1842, running_loss=1.1601, LR=0.000100
[2025-08-10 16:56:36,044][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038616] [Batch 01696/03692] [00:15:40/00:18:27, 0.555s/it]: train_loss_raw=1.1956, running_loss=1.1598, LR=0.000100
[2025-08-10 16:56:42,682][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038628] [Batch 01708/03692] [00:15:47/00:18:20, 0.555s/it]: train_loss_raw=1.2725, running_loss=1.1601, LR=0.000100
[2025-08-10 16:56:49,277][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038640] [Batch 01720/03692] [00:15:53/00:18:13, 0.555s/it]: train_loss_raw=1.1579, running_loss=1.1594, LR=0.000100
[2025-08-10 16:56:55,763][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038652] [Batch 01732/03692] [00:16:00/00:18:06, 0.554s/it]: train_loss_raw=1.1477, running_loss=1.1576, LR=0.000100
[2025-08-10 16:57:02,564][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038664] [Batch 01744/03692] [00:16:07/00:18:00, 0.555s/it]: train_loss_raw=1.2003, running_loss=1.1580, LR=0.000100
[2025-08-10 16:57:09,127][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038676] [Batch 01756/03692] [00:16:13/00:17:53, 0.555s/it]: train_loss_raw=1.2468, running_loss=1.1587, LR=0.000100
[2025-08-10 16:57:15,649][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038688] [Batch 01768/03692] [00:16:20/00:17:46, 0.554s/it]: train_loss_raw=1.2566, running_loss=1.1571, LR=0.000100
[2025-08-10 16:57:21,994][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038700] [Batch 01780/03692] [00:16:26/00:17:39, 0.554s/it]: train_loss_raw=1.0672, running_loss=1.1565, LR=0.000100
[2025-08-10 16:57:28,283][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038712] [Batch 01792/03692] [00:16:32/00:17:32, 0.554s/it]: train_loss_raw=1.2706, running_loss=1.1527, LR=0.000100
[2025-08-10 16:57:35,057][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038724] [Batch 01804/03692] [00:16:39/00:17:26, 0.554s/it]: train_loss_raw=1.2530, running_loss=1.1545, LR=0.000100
[2025-08-10 16:57:41,640][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038736] [Batch 01816/03692] [00:16:46/00:17:19, 0.554s/it]: train_loss_raw=1.0404, running_loss=1.1554, LR=0.000100
[2025-08-10 16:57:48,039][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038748] [Batch 01828/03692] [00:16:52/00:17:12, 0.554s/it]: train_loss_raw=1.1376, running_loss=1.1583, LR=0.000100
[2025-08-10 16:57:54,331][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038760] [Batch 01840/03692] [00:16:58/00:17:05, 0.554s/it]: train_loss_raw=1.1801, running_loss=1.1590, LR=0.000100
[2025-08-10 16:58:00,335][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038772] [Batch 01852/03692] [00:17:04/00:16:58, 0.553s/it]: train_loss_raw=1.0674, running_loss=1.1597, LR=0.000100
[2025-08-10 16:58:06,747][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038784] [Batch 01864/03692] [00:17:11/00:16:51, 0.553s/it]: train_loss_raw=1.1003, running_loss=1.1574, LR=0.000100
[2025-08-10 16:58:13,074][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038796] [Batch 01876/03692] [00:17:17/00:16:44, 0.553s/it]: train_loss_raw=1.1450, running_loss=1.1583, LR=0.000100
[2025-08-10 16:58:19,361][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038808] [Batch 01888/03692] [00:17:23/00:16:37, 0.553s/it]: train_loss_raw=1.1389, running_loss=1.1598, LR=0.000100
[2025-08-10 16:58:25,465][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038820] [Batch 01900/03692] [00:17:30/00:16:30, 0.553s/it]: train_loss_raw=1.1084, running_loss=1.1608, LR=0.000100
[2025-08-10 16:58:31,473][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038832] [Batch 01912/03692] [00:17:36/00:16:23, 0.552s/it]: train_loss_raw=1.1559, running_loss=1.1587, LR=0.000100
[2025-08-10 16:58:37,885][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038844] [Batch 01924/03692] [00:17:42/00:16:16, 0.552s/it]: train_loss_raw=1.0384, running_loss=1.1563, LR=0.000100
[2025-08-10 16:58:44,031][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038856] [Batch 01936/03692] [00:17:48/00:16:09, 0.552s/it]: train_loss_raw=1.2580, running_loss=1.1524, LR=0.000100
[2025-08-10 16:58:50,457][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038868] [Batch 01948/03692] [00:17:55/00:16:02, 0.552s/it]: train_loss_raw=1.2350, running_loss=1.1495, LR=0.000100
[2025-08-10 16:58:56,493][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038880] [Batch 01960/03692] [00:18:01/00:15:55, 0.552s/it]: train_loss_raw=1.1924, running_loss=1.1505, LR=0.000100
[2025-08-10 16:59:02,578][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038892] [Batch 01972/03692] [00:18:07/00:15:48, 0.551s/it]: train_loss_raw=1.1052, running_loss=1.1488, LR=0.000100
[2025-08-10 16:59:09,013][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038904] [Batch 01984/03692] [00:18:13/00:15:41, 0.551s/it]: train_loss_raw=1.1861, running_loss=1.1453, LR=0.000100
[2025-08-10 16:59:15,457][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038916] [Batch 01996/03692] [00:18:20/00:15:34, 0.551s/it]: train_loss_raw=1.1961, running_loss=1.1517, LR=0.000100
[2025-08-10 16:59:21,958][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038928] [Batch 02008/03692] [00:18:26/00:15:28, 0.551s/it]: train_loss_raw=1.3336, running_loss=1.1555, LR=0.000100
[2025-08-10 16:59:28,490][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038940] [Batch 02020/03692] [00:18:33/00:15:21, 0.551s/it]: train_loss_raw=1.1580, running_loss=1.1535, LR=0.000100
[2025-08-10 16:59:35,158][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038952] [Batch 02032/03692] [00:18:39/00:15:14, 0.551s/it]: train_loss_raw=1.0683, running_loss=1.1550, LR=0.000100
[2025-08-10 16:59:41,790][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038964] [Batch 02044/03692] [00:18:46/00:15:08, 0.551s/it]: train_loss_raw=1.1227, running_loss=1.1558, LR=0.000100
[2025-08-10 16:59:48,400][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038976] [Batch 02056/03692] [00:18:53/00:15:01, 0.551s/it]: train_loss_raw=1.0053, running_loss=1.1575, LR=0.000100
[2025-08-10 16:59:55,059][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038988] [Batch 02068/03692] [00:18:59/00:14:54, 0.551s/it]: train_loss_raw=1.1794, running_loss=1.1612, LR=0.000100
[2025-08-10 17:00:01,711][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039000] [Batch 02080/03692] [00:19:06/00:14:48, 0.551s/it]: train_loss_raw=1.1492, running_loss=1.1618, LR=0.000100
[2025-08-10 17:00:08,325][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039012] [Batch 02092/03692] [00:19:12/00:14:41, 0.551s/it]: train_loss_raw=1.1114, running_loss=1.1564, LR=0.000100
[2025-08-10 17:00:14,826][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039024] [Batch 02104/03692] [00:19:19/00:14:35, 0.551s/it]: train_loss_raw=1.0635, running_loss=1.1535, LR=0.000100
[2025-08-10 17:00:21,587][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039036] [Batch 02116/03692] [00:19:26/00:14:28, 0.551s/it]: train_loss_raw=1.1578, running_loss=1.1530, LR=0.000100
[2025-08-10 17:00:28,186][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039048] [Batch 02128/03692] [00:19:32/00:14:21, 0.551s/it]: train_loss_raw=1.1702, running_loss=1.1558, LR=0.000100
[2025-08-10 17:00:34,873][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039060] [Batch 02140/03692] [00:19:39/00:14:15, 0.551s/it]: train_loss_raw=1.2464, running_loss=1.1539, LR=0.000100
[2025-08-10 17:00:41,393][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039072] [Batch 02152/03692] [00:19:45/00:14:08, 0.551s/it]: train_loss_raw=0.9406, running_loss=1.1538, LR=0.000100
[2025-08-10 17:00:47,772][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039084] [Batch 02164/03692] [00:19:52/00:14:01, 0.551s/it]: train_loss_raw=1.2016, running_loss=1.1530, LR=0.000100
[2025-08-10 17:00:53,958][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039096] [Batch 02176/03692] [00:19:58/00:13:55, 0.551s/it]: train_loss_raw=1.3000, running_loss=1.1563, LR=0.000100
[2025-08-10 17:01:00,011][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039108] [Batch 02188/03692] [00:20:04/00:13:48, 0.551s/it]: train_loss_raw=1.0594, running_loss=1.1570, LR=0.000100
[2025-08-10 17:01:06,263][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039120] [Batch 02200/03692] [00:20:10/00:13:41, 0.550s/it]: train_loss_raw=1.1105, running_loss=1.1565, LR=0.000100
[2025-08-10 17:01:12,403][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039132] [Batch 02212/03692] [00:20:17/00:13:34, 0.550s/it]: train_loss_raw=1.0843, running_loss=1.1557, LR=0.000100
[2025-08-10 17:01:18,812][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039144] [Batch 02224/03692] [00:20:23/00:13:27, 0.550s/it]: train_loss_raw=1.0666, running_loss=1.1593, LR=0.000100
[2025-08-10 17:01:25,432][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039156] [Batch 02236/03692] [00:20:30/00:13:20, 0.550s/it]: train_loss_raw=1.0088, running_loss=1.1590, LR=0.000100
[2025-08-10 17:01:32,050][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039168] [Batch 02248/03692] [00:20:36/00:13:14, 0.550s/it]: train_loss_raw=1.1179, running_loss=1.1606, LR=0.000100
[2025-08-10 17:01:38,770][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039180] [Batch 02260/03692] [00:20:43/00:13:07, 0.550s/it]: train_loss_raw=1.1983, running_loss=1.1609, LR=0.000100
[2025-08-10 17:01:45,283][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039192] [Batch 02272/03692] [00:20:49/00:13:01, 0.550s/it]: train_loss_raw=1.1202, running_loss=1.1601, LR=0.000100
[2025-08-10 17:01:52,086][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039204] [Batch 02284/03692] [00:20:56/00:12:54, 0.550s/it]: train_loss_raw=1.1957, running_loss=1.1607, LR=0.000100
[2025-08-10 17:01:58,622][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039216] [Batch 02296/03692] [00:21:03/00:12:48, 0.550s/it]: train_loss_raw=1.3139, running_loss=1.1599, LR=0.000100
[2025-08-10 17:02:04,959][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039228] [Batch 02308/03692] [00:21:09/00:12:41, 0.550s/it]: train_loss_raw=1.1984, running_loss=1.1570, LR=0.000100
[2025-08-10 17:02:11,058][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039240] [Batch 02320/03692] [00:21:15/00:12:34, 0.550s/it]: train_loss_raw=1.0556, running_loss=1.1612, LR=0.000100
[2025-08-10 17:02:17,121][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039252] [Batch 02332/03692] [00:21:21/00:12:27, 0.550s/it]: train_loss_raw=1.1758, running_loss=1.1634, LR=0.000100
[2025-08-10 17:02:23,324][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039264] [Batch 02344/03692] [00:21:27/00:12:20, 0.549s/it]: train_loss_raw=1.2794, running_loss=1.1647, LR=0.000100
[2025-08-10 17:02:29,556][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039276] [Batch 02356/03692] [00:21:34/00:12:13, 0.549s/it]: train_loss_raw=1.0752, running_loss=1.1644, LR=0.000100
[2025-08-10 17:02:35,960][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039288] [Batch 02368/03692] [00:21:40/00:12:07, 0.549s/it]: train_loss_raw=1.0571, running_loss=1.1664, LR=0.000100
[2025-08-10 17:02:42,125][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039300] [Batch 02380/03692] [00:21:46/00:12:00, 0.549s/it]: train_loss_raw=1.0875, running_loss=1.1679, LR=0.000100
[2025-08-10 17:02:48,254][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039312] [Batch 02392/03692] [00:21:52/00:11:53, 0.549s/it]: train_loss_raw=1.2826, running_loss=1.1697, LR=0.000100
[2025-08-10 17:02:54,766][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039324] [Batch 02404/03692] [00:21:59/00:11:46, 0.549s/it]: train_loss_raw=1.2942, running_loss=1.1715, LR=0.000100
[2025-08-10 17:03:01,166][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039336] [Batch 02416/03692] [00:22:05/00:11:40, 0.549s/it]: train_loss_raw=1.2519, running_loss=1.1733, LR=0.000100
[2025-08-10 17:03:07,516][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039348] [Batch 02428/03692] [00:22:12/00:11:33, 0.549s/it]: train_loss_raw=1.2129, running_loss=1.1756, LR=0.000100
[2025-08-10 17:03:13,758][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039360] [Batch 02440/03692] [00:22:18/00:11:26, 0.549s/it]: train_loss_raw=1.2301, running_loss=1.1723, LR=0.000100
[2025-08-10 17:03:20,024][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039372] [Batch 02452/03692] [00:22:24/00:11:19, 0.548s/it]: train_loss_raw=1.1051, running_loss=1.1644, LR=0.000100
[2025-08-10 17:03:26,263][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039384] [Batch 02464/03692] [00:22:30/00:11:13, 0.548s/it]: train_loss_raw=1.1761, running_loss=1.1658, LR=0.000100
[2025-08-10 17:03:32,683][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039396] [Batch 02476/03692] [00:22:37/00:11:06, 0.548s/it]: train_loss_raw=1.0785, running_loss=1.1605, LR=0.000100
[2025-08-10 17:03:39,156][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039408] [Batch 02488/03692] [00:22:43/00:10:59, 0.548s/it]: train_loss_raw=1.3126, running_loss=1.1622, LR=0.000100
[2025-08-10 17:03:45,423][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039420] [Batch 02500/03692] [00:22:50/00:10:53, 0.548s/it]: train_loss_raw=1.0722, running_loss=1.1574, LR=0.000100
[2025-08-10 17:03:51,777][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039432] [Batch 02512/03692] [00:22:56/00:10:46, 0.548s/it]: train_loss_raw=1.1138, running_loss=1.1554, LR=0.000100
[2025-08-10 17:03:57,881][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039444] [Batch 02524/03692] [00:23:02/00:10:39, 0.548s/it]: train_loss_raw=1.0870, running_loss=1.1545, LR=0.000100
[2025-08-10 17:04:04,062][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039456] [Batch 02536/03692] [00:23:08/00:10:33, 0.548s/it]: train_loss_raw=1.1490, running_loss=1.1476, LR=0.000100
[2025-08-10 17:04:10,469][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039468] [Batch 02548/03692] [00:23:15/00:10:26, 0.548s/it]: train_loss_raw=1.2171, running_loss=1.1491, LR=0.000100
[2025-08-10 17:04:16,594][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039480] [Batch 02560/03692] [00:23:21/00:10:19, 0.547s/it]: train_loss_raw=1.1270, running_loss=1.1452, LR=0.000100
[2025-08-10 17:04:23,102][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039492] [Batch 02572/03692] [00:23:27/00:10:12, 0.547s/it]: train_loss_raw=1.2463, running_loss=1.1457, LR=0.000100
[2025-08-10 17:04:29,250][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039504] [Batch 02584/03692] [00:23:33/00:10:06, 0.547s/it]: train_loss_raw=1.1505, running_loss=1.1448, LR=0.000100
[2025-08-10 17:04:35,665][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039516] [Batch 02596/03692] [00:23:40/00:09:59, 0.547s/it]: train_loss_raw=1.0459, running_loss=1.1429, LR=0.000100
[2025-08-10 17:04:42,129][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039528] [Batch 02608/03692] [00:23:46/00:09:53, 0.547s/it]: train_loss_raw=0.9655, running_loss=1.1404, LR=0.000100
[2025-08-10 17:04:48,608][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039540] [Batch 02620/03692] [00:23:53/00:09:46, 0.547s/it]: train_loss_raw=1.2333, running_loss=1.1456, LR=0.000100
[2025-08-10 17:04:54,878][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039552] [Batch 02632/03692] [00:23:59/00:09:39, 0.547s/it]: train_loss_raw=1.1526, running_loss=1.1433, LR=0.000100
[2025-08-10 17:05:01,461][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039564] [Batch 02644/03692] [00:24:06/00:09:33, 0.547s/it]: train_loss_raw=1.1744, running_loss=1.1424, LR=0.000100
[2025-08-10 17:05:07,993][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039576] [Batch 02656/03692] [00:24:12/00:09:26, 0.547s/it]: train_loss_raw=1.0394, running_loss=1.1430, LR=0.000100
[2025-08-10 17:05:14,493][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039588] [Batch 02668/03692] [00:24:19/00:09:20, 0.547s/it]: train_loss_raw=1.1030, running_loss=1.1451, LR=0.000100
[2025-08-10 17:05:21,005][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039600] [Batch 02680/03692] [00:24:25/00:09:13, 0.547s/it]: train_loss_raw=1.1596, running_loss=1.1475, LR=0.000100
[2025-08-10 17:05:27,182][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039612] [Batch 02692/03692] [00:24:31/00:09:06, 0.547s/it]: train_loss_raw=1.2650, running_loss=1.1497, LR=0.000100
[2025-08-10 17:05:33,427][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039624] [Batch 02704/03692] [00:24:38/00:09:00, 0.547s/it]: train_loss_raw=1.2204, running_loss=1.1499, LR=0.000100
[2025-08-10 17:05:39,533][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039636] [Batch 02716/03692] [00:24:44/00:08:53, 0.546s/it]: train_loss_raw=1.2172, running_loss=1.1487, LR=0.000100
[2025-08-10 17:05:45,746][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039648] [Batch 02728/03692] [00:24:50/00:08:46, 0.546s/it]: train_loss_raw=1.1244, running_loss=1.1437, LR=0.000100
[2025-08-10 17:05:51,989][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039660] [Batch 02740/03692] [00:24:56/00:08:39, 0.546s/it]: train_loss_raw=1.1522, running_loss=1.1419, LR=0.000100
[2025-08-10 17:05:58,222][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039672] [Batch 02752/03692] [00:25:02/00:08:33, 0.546s/it]: train_loss_raw=1.0825, running_loss=1.1385, LR=0.000100
[2025-08-10 17:06:04,605][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039684] [Batch 02764/03692] [00:25:09/00:08:26, 0.546s/it]: train_loss_raw=1.1001, running_loss=1.1402, LR=0.000100
[2025-08-10 17:06:10,945][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039696] [Batch 02776/03692] [00:25:15/00:08:20, 0.546s/it]: train_loss_raw=1.1020, running_loss=1.1394, LR=0.000100
[2025-08-10 17:06:17,393][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039708] [Batch 02788/03692] [00:25:21/00:08:13, 0.546s/it]: train_loss_raw=1.4018, running_loss=1.1433, LR=0.000100
[2025-08-10 17:06:23,844][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039720] [Batch 02800/03692] [00:25:28/00:08:06, 0.546s/it]: train_loss_raw=1.1870, running_loss=1.1438, LR=0.000100
[2025-08-10 17:06:30,220][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039732] [Batch 02812/03692] [00:25:34/00:08:00, 0.546s/it]: train_loss_raw=1.0677, running_loss=1.1428, LR=0.000100
[2025-08-10 17:06:36,690][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039744] [Batch 02824/03692] [00:25:41/00:07:53, 0.546s/it]: train_loss_raw=1.2163, running_loss=1.1452, LR=0.000100
[2025-08-10 17:06:43,082][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039756] [Batch 02836/03692] [00:25:47/00:07:47, 0.546s/it]: train_loss_raw=1.2245, running_loss=1.1442, LR=0.000100
[2025-08-10 17:06:49,297][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039768] [Batch 02848/03692] [00:25:53/00:07:40, 0.546s/it]: train_loss_raw=1.1067, running_loss=1.1451, LR=0.000100
[2025-08-10 17:06:55,306][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039780] [Batch 02860/03692] [00:25:59/00:07:33, 0.545s/it]: train_loss_raw=1.0970, running_loss=1.1452, LR=0.000100
[2025-08-10 17:07:01,281][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039792] [Batch 02872/03692] [00:26:05/00:07:27, 0.545s/it]: train_loss_raw=1.1895, running_loss=1.1446, LR=0.000100
[2025-08-10 17:07:07,471][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039804] [Batch 02884/03692] [00:26:12/00:07:20, 0.545s/it]: train_loss_raw=1.1126, running_loss=1.1420, LR=0.000100
[2025-08-10 17:07:13,605][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039816] [Batch 02896/03692] [00:26:18/00:07:13, 0.545s/it]: train_loss_raw=1.2540, running_loss=1.1452, LR=0.000100
[2025-08-10 17:07:19,780][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039828] [Batch 02908/03692] [00:26:24/00:07:07, 0.545s/it]: train_loss_raw=1.0881, running_loss=1.1439, LR=0.000100
[2025-08-10 17:07:26,030][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039840] [Batch 02920/03692] [00:26:30/00:07:00, 0.545s/it]: train_loss_raw=1.2371, running_loss=1.1431, LR=0.000100
[2025-08-10 17:07:32,522][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039852] [Batch 02932/03692] [00:26:37/00:06:53, 0.545s/it]: train_loss_raw=1.0748, running_loss=1.1403, LR=0.000100
[2025-08-10 17:07:38,683][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039864] [Batch 02944/03692] [00:26:43/00:06:47, 0.545s/it]: train_loss_raw=1.1005, running_loss=1.1396, LR=0.000100
[2025-08-10 17:07:44,843][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039876] [Batch 02956/03692] [00:26:49/00:06:40, 0.544s/it]: train_loss_raw=1.1852, running_loss=1.1406, LR=0.000100
[2025-08-10 17:07:51,021][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039888] [Batch 02968/03692] [00:26:55/00:06:34, 0.544s/it]: train_loss_raw=1.2131, running_loss=1.1451, LR=0.000100
[2025-08-10 17:07:57,054][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039900] [Batch 02980/03692] [00:27:01/00:06:27, 0.544s/it]: train_loss_raw=1.0666, running_loss=1.1472, LR=0.000100
[2025-08-10 17:08:03,152][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039912] [Batch 02992/03692] [00:27:07/00:06:20, 0.544s/it]: train_loss_raw=1.2083, running_loss=1.1494, LR=0.000100
[2025-08-10 17:08:09,216][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039924] [Batch 03004/03692] [00:27:13/00:06:14, 0.544s/it]: train_loss_raw=1.2451, running_loss=1.1512, LR=0.000100
[2025-08-10 17:08:15,231][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039936] [Batch 03016/03692] [00:27:19/00:06:07, 0.544s/it]: train_loss_raw=1.1895, running_loss=1.1464, LR=0.000100
[2025-08-10 17:08:21,380][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039948] [Batch 03028/03692] [00:27:25/00:06:00, 0.544s/it]: train_loss_raw=1.2839, running_loss=1.1478, LR=0.000100
[2025-08-10 17:08:27,445][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039960] [Batch 03040/03692] [00:27:32/00:05:54, 0.543s/it]: train_loss_raw=1.2092, running_loss=1.1467, LR=0.000100
[2025-08-10 17:08:33,587][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039972] [Batch 03052/03692] [00:27:38/00:05:47, 0.543s/it]: train_loss_raw=1.0939, running_loss=1.1465, LR=0.000100
[2025-08-10 17:08:40,144][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039984] [Batch 03064/03692] [00:27:44/00:05:41, 0.543s/it]: train_loss_raw=1.1747, running_loss=1.1516, LR=0.000100
[2025-08-10 17:08:46,743][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039996] [Batch 03076/03692] [00:27:51/00:05:34, 0.543s/it]: train_loss_raw=1.0007, running_loss=1.1519, LR=0.000100
[2025-08-10 17:08:58,699][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040008] [Batch 03088/03692] [00:28:03/00:05:29, 0.545s/it]: train_loss_raw=1.1088, running_loss=1.1502, LR=0.000100
[2025-08-10 17:09:05,292][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040020] [Batch 03100/03692] [00:28:09/00:05:22, 0.545s/it]: train_loss_raw=1.3198, running_loss=1.1505, LR=0.000100
[2025-08-10 17:09:11,798][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040032] [Batch 03112/03692] [00:28:16/00:05:16, 0.545s/it]: train_loss_raw=1.1849, running_loss=1.1475, LR=0.000100
[2025-08-10 17:09:18,492][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040044] [Batch 03124/03692] [00:28:23/00:05:09, 0.545s/it]: train_loss_raw=1.2028, running_loss=1.1473, LR=0.000100
[2025-08-10 17:09:25,083][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040056] [Batch 03136/03692] [00:28:29/00:05:03, 0.545s/it]: train_loss_raw=1.1413, running_loss=1.1499, LR=0.000100
[2025-08-10 17:09:31,605][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040068] [Batch 03148/03692] [00:28:36/00:04:56, 0.545s/it]: train_loss_raw=1.1804, running_loss=1.1548, LR=0.000100
[2025-08-10 17:09:38,102][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040080] [Batch 03160/03692] [00:28:42/00:04:50, 0.545s/it]: train_loss_raw=1.1977, running_loss=1.1556, LR=0.000100
[2025-08-10 17:09:44,658][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040092] [Batch 03172/03692] [00:28:49/00:04:43, 0.545s/it]: train_loss_raw=1.2004, running_loss=1.1547, LR=0.000100
[2025-08-10 17:09:51,257][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040104] [Batch 03184/03692] [00:28:55/00:04:36, 0.545s/it]: train_loss_raw=1.0794, running_loss=1.1492, LR=0.000100
[2025-08-10 17:09:57,621][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040116] [Batch 03196/03692] [00:29:02/00:04:30, 0.545s/it]: train_loss_raw=1.1875, running_loss=1.1516, LR=0.000100
[2025-08-10 17:10:03,793][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040128] [Batch 03208/03692] [00:29:08/00:04:23, 0.545s/it]: train_loss_raw=1.1966, running_loss=1.1514, LR=0.000100
[2025-08-10 17:10:09,792][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040140] [Batch 03220/03692] [00:29:14/00:04:17, 0.545s/it]: train_loss_raw=1.1449, running_loss=1.1523, LR=0.000100
[2025-08-10 17:10:15,850][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040152] [Batch 03232/03692] [00:29:20/00:04:10, 0.545s/it]: train_loss_raw=1.3321, running_loss=1.1522, LR=0.000100
[2025-08-10 17:10:21,981][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040164] [Batch 03244/03692] [00:29:26/00:04:03, 0.545s/it]: train_loss_raw=1.0966, running_loss=1.1496, LR=0.000100
[2025-08-10 17:10:28,145][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040176] [Batch 03256/03692] [00:29:32/00:03:57, 0.544s/it]: train_loss_raw=1.1358, running_loss=1.1475, LR=0.000100
[2025-08-10 17:10:34,280][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040188] [Batch 03268/03692] [00:29:38/00:03:50, 0.544s/it]: train_loss_raw=1.2415, running_loss=1.1520, LR=0.000100
[2025-08-10 17:10:40,331][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040200] [Batch 03280/03692] [00:29:44/00:03:44, 0.544s/it]: train_loss_raw=1.0166, running_loss=1.1513, LR=0.000100
[2025-08-10 17:10:46,418][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040212] [Batch 03292/03692] [00:29:51/00:03:37, 0.544s/it]: train_loss_raw=1.2945, running_loss=1.1504, LR=0.000100
[2025-08-10 17:10:52,509][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040224] [Batch 03304/03692] [00:29:57/00:03:31, 0.544s/it]: train_loss_raw=1.1678, running_loss=1.1472, LR=0.000100
[2025-08-10 17:10:58,670][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040236] [Batch 03316/03692] [00:30:03/00:03:24, 0.544s/it]: train_loss_raw=1.0325, running_loss=1.1450, LR=0.000100
[2025-08-10 17:11:04,893][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040248] [Batch 03328/03692] [00:30:09/00:03:17, 0.544s/it]: train_loss_raw=1.2144, running_loss=1.1444, LR=0.000100
[2025-08-10 17:11:11,084][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040260] [Batch 03340/03692] [00:30:15/00:03:11, 0.544s/it]: train_loss_raw=1.1228, running_loss=1.1454, LR=0.000100
[2025-08-10 17:11:17,093][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040272] [Batch 03352/03692] [00:30:21/00:03:04, 0.543s/it]: train_loss_raw=1.2121, running_loss=1.1474, LR=0.000100
[2025-08-10 17:11:23,227][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040284] [Batch 03364/03692] [00:30:27/00:02:58, 0.543s/it]: train_loss_raw=1.1388, running_loss=1.1488, LR=0.000100
[2025-08-10 17:11:29,316][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040296] [Batch 03376/03692] [00:30:33/00:02:51, 0.543s/it]: train_loss_raw=1.2044, running_loss=1.1477, LR=0.000100
[2025-08-10 17:11:35,749][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040308] [Batch 03388/03692] [00:30:40/00:02:45, 0.543s/it]: train_loss_raw=1.0303, running_loss=1.1431, LR=0.000100
[2025-08-10 17:11:42,042][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040320] [Batch 03400/03692] [00:30:46/00:02:38, 0.543s/it]: train_loss_raw=1.0374, running_loss=1.1359, LR=0.000100
[2025-08-10 17:11:48,231][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040332] [Batch 03412/03692] [00:30:52/00:02:32, 0.543s/it]: train_loss_raw=1.0140, running_loss=1.1327, LR=0.000100
[2025-08-10 17:11:54,309][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040344] [Batch 03424/03692] [00:30:58/00:02:25, 0.543s/it]: train_loss_raw=1.0903, running_loss=1.1361, LR=0.000100
[2025-08-10 17:12:00,351][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040356] [Batch 03436/03692] [00:31:04/00:02:18, 0.543s/it]: train_loss_raw=1.1413, running_loss=1.1379, LR=0.000100
[2025-08-10 17:12:06,503][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040368] [Batch 03448/03692] [00:31:11/00:02:12, 0.543s/it]: train_loss_raw=1.1168, running_loss=1.1398, LR=0.000100
[2025-08-10 17:12:12,618][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040380] [Batch 03460/03692] [00:31:17/00:02:05, 0.543s/it]: train_loss_raw=1.0899, running_loss=1.1448, LR=0.000100
[2025-08-10 17:12:18,718][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040392] [Batch 03472/03692] [00:31:23/00:01:59, 0.542s/it]: train_loss_raw=1.1643, running_loss=1.1454, LR=0.000100
[2025-08-10 17:12:24,840][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040404] [Batch 03484/03692] [00:31:29/00:01:52, 0.542s/it]: train_loss_raw=1.1055, running_loss=1.1457, LR=0.000100
[2025-08-10 17:12:31,296][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040416] [Batch 03496/03692] [00:31:35/00:01:46, 0.542s/it]: train_loss_raw=1.1605, running_loss=1.1475, LR=0.000100
[2025-08-10 17:12:37,864][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040428] [Batch 03508/03692] [00:31:42/00:01:39, 0.542s/it]: train_loss_raw=1.2374, running_loss=1.1457, LR=0.000100
[2025-08-10 17:12:44,124][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040440] [Batch 03520/03692] [00:31:48/00:01:33, 0.542s/it]: train_loss_raw=1.1331, running_loss=1.1475, LR=0.000100
[2025-08-10 17:12:50,642][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040452] [Batch 03532/03692] [00:31:55/00:01:26, 0.542s/it]: train_loss_raw=1.0906, running_loss=1.1487, LR=0.000100
[2025-08-10 17:12:57,061][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040464] [Batch 03544/03692] [00:32:01/00:01:20, 0.542s/it]: train_loss_raw=1.1473, running_loss=1.1417, LR=0.000100
[2025-08-10 17:13:03,417][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040476] [Batch 03556/03692] [00:32:08/00:01:13, 0.542s/it]: train_loss_raw=1.1162, running_loss=1.1413, LR=0.000100
[2025-08-10 17:13:09,805][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040488] [Batch 03568/03692] [00:32:14/00:01:07, 0.542s/it]: train_loss_raw=1.0380, running_loss=1.1407, LR=0.000100
[2025-08-10 17:13:16,218][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040500] [Batch 03580/03692] [00:32:20/00:01:00, 0.542s/it]: train_loss_raw=1.2000, running_loss=1.1409, LR=0.000100
[2025-08-10 17:13:22,688][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040512] [Batch 03592/03692] [00:32:27/00:00:54, 0.542s/it]: train_loss_raw=1.0959, running_loss=1.1408, LR=0.000100
[2025-08-10 17:13:29,051][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040524] [Batch 03604/03692] [00:32:33/00:00:47, 0.542s/it]: train_loss_raw=1.0725, running_loss=1.1391, LR=0.000100
[2025-08-10 17:13:35,441][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040536] [Batch 03616/03692] [00:32:40/00:00:41, 0.542s/it]: train_loss_raw=1.1283, running_loss=1.1337, LR=0.000100
[2025-08-10 17:13:42,008][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040548] [Batch 03628/03692] [00:32:46/00:00:34, 0.542s/it]: train_loss_raw=1.1027, running_loss=1.1387, LR=0.000100
[2025-08-10 17:13:48,371][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040560] [Batch 03640/03692] [00:32:52/00:00:28, 0.542s/it]: train_loss_raw=1.1706, running_loss=1.1385, LR=0.000100
[2025-08-10 17:13:54,768][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040572] [Batch 03652/03692] [00:32:59/00:00:21, 0.542s/it]: train_loss_raw=1.1492, running_loss=1.1383, LR=0.000100
[2025-08-10 17:14:01,143][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040584] [Batch 03664/03692] [00:33:05/00:00:15, 0.542s/it]: train_loss_raw=1.1239, running_loss=1.1365, LR=0.000100
[2025-08-10 17:14:07,452][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040596] [Batch 03676/03692] [00:33:12/00:00:08, 0.542s/it]: train_loss_raw=1.0859, running_loss=1.1376, LR=0.000100
[2025-08-10 17:14:14,109][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040608] [Batch 03688/03692] [00:33:18/00:00:02, 0.542s/it]: train_loss_raw=1.0975, running_loss=1.1355, LR=0.000100
[2025-08-10 17:14:23,052][__main__][INFO] - [VALIDATION] [Epoch 10/29] Starting validation.
[2025-08-10 17:14:58,111][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 040613] [Batch 00011/00025] [00:00:35/00:00:37, 2.922s/it]
[2025-08-10 17:15:15,951][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 040613] [Batch 00023/00025] [00:00:52/00:00:02, 2.204s/it]
[2025-08-10 17:15:17,056][__main__][INFO] - [VALIDATION] [Epoch 10/29] train_loss=1.13549, valid_loss=1.13287
[2025-08-10 17:15:17,057][__main__][INFO] - [VALIDATION] [Epoch 10/29] Metrics:
[2025-08-10 17:15:17,058][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_er      0.488
[2025-08-10 17:15:17,058][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_prec    0.249
[2025-08-10 17:15:17,058][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_recall  0.257
[2025-08-10 17:15:17,058][__main__][INFO] - [VALIDATION] [Epoch 10/29] - pep_recall 0.222
[2025-08-10 17:15:17,061][__main__][INFO] - [TRAIN] [Epoch 10/29] Epoch complete, total time 06:19:16, remaining time 10:55:06, 00:34:28 per epoch
[2025-08-10 17:15:21,173][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040620] [Batch 00008/03692] [00:00:03/00:29:45, 0.485s/it]: train_loss_raw=1.1545, running_loss=1.1895, LR=0.000100
[2025-08-10 17:15:27,748][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040632] [Batch 00020/03692] [00:00:10/00:31:58, 0.523s/it]: train_loss_raw=1.1862, running_loss=1.1849, LR=0.000100
[2025-08-10 17:15:34,145][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040644] [Batch 00032/03692] [00:00:16/00:32:07, 0.527s/it]: train_loss_raw=1.0685, running_loss=1.1762, LR=0.000100
[2025-08-10 17:15:40,621][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040656] [Batch 00044/03692] [00:00:23/00:32:13, 0.530s/it]: train_loss_raw=1.1844, running_loss=1.1704, LR=0.000100
[2025-08-10 17:15:47,140][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040668] [Batch 00056/03692] [00:00:29/00:32:17, 0.533s/it]: train_loss_raw=1.1679, running_loss=1.1684, LR=0.000100
[2025-08-10 17:15:53,445][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040680] [Batch 00068/03692] [00:00:36/00:32:06, 0.532s/it]: train_loss_raw=1.1046, running_loss=1.1622, LR=0.000100
[2025-08-10 17:15:59,731][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040692] [Batch 00080/03692] [00:00:42/00:31:55, 0.530s/it]: train_loss_raw=1.1340, running_loss=1.1600, LR=0.000100
[2025-08-10 17:16:05,904][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040704] [Batch 00092/03692] [00:00:48/00:31:42, 0.528s/it]: train_loss_raw=1.1715, running_loss=1.1587, LR=0.000100
[2025-08-10 17:16:12,186][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040716] [Batch 00104/03692] [00:00:54/00:31:33, 0.528s/it]: train_loss_raw=1.1234, running_loss=1.1568, LR=0.000100
[2025-08-10 17:16:18,398][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040728] [Batch 00116/03692] [00:01:01/00:31:23, 0.527s/it]: train_loss_raw=1.1721, running_loss=1.1609, LR=0.000100
[2025-08-10 17:16:24,697][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040740] [Batch 00128/03692] [00:01:07/00:31:16, 0.527s/it]: train_loss_raw=1.0819, running_loss=1.1596, LR=0.000100
[2025-08-10 17:16:30,943][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040752] [Batch 00140/03692] [00:01:13/00:31:08, 0.526s/it]: train_loss_raw=1.1311, running_loss=1.1594, LR=0.000100
[2025-08-10 17:16:37,356][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040764] [Batch 00152/03692] [00:01:20/00:31:04, 0.527s/it]: train_loss_raw=1.2756, running_loss=1.1539, LR=0.000100
[2025-08-10 17:16:43,813][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040776] [Batch 00164/03692] [00:01:26/00:31:01, 0.528s/it]: train_loss_raw=1.0809, running_loss=1.1524, LR=0.000100
[2025-08-10 17:16:50,088][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040788] [Batch 00176/03692] [00:01:32/00:30:53, 0.527s/it]: train_loss_raw=1.1460, running_loss=1.1517, LR=0.000100
[2025-08-10 17:16:56,249][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040800] [Batch 00188/03692] [00:01:38/00:30:44, 0.526s/it]: train_loss_raw=1.2026, running_loss=1.1510, LR=0.000100
[2025-08-10 17:17:02,560][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040812] [Batch 00200/03692] [00:01:45/00:30:37, 0.526s/it]: train_loss_raw=1.1538, running_loss=1.1473, LR=0.000100
[2025-08-10 17:17:09,240][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040824] [Batch 00212/03692] [00:01:51/00:30:37, 0.528s/it]: train_loss_raw=1.1338, running_loss=1.1478, LR=0.000100
[2025-08-10 17:17:15,762][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040836] [Batch 00224/03692] [00:01:58/00:30:34, 0.529s/it]: train_loss_raw=1.1999, running_loss=1.1434, LR=0.000100
[2025-08-10 17:17:22,129][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040848] [Batch 00236/03692] [00:02:04/00:30:28, 0.529s/it]: train_loss_raw=0.9941, running_loss=1.1413, LR=0.000100
[2025-08-10 17:17:28,323][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040860] [Batch 00248/03692] [00:02:11/00:30:19, 0.528s/it]: train_loss_raw=1.1128, running_loss=1.1410, LR=0.000100
[2025-08-10 17:17:34,370][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040872] [Batch 00260/03692] [00:02:17/00:30:09, 0.527s/it]: train_loss_raw=1.1716, running_loss=1.1404, LR=0.000100
[2025-08-10 17:17:40,892][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040884] [Batch 00272/03692] [00:02:23/00:30:05, 0.528s/it]: train_loss_raw=1.0831, running_loss=1.1423, LR=0.000100
[2025-08-10 17:17:47,407][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040896] [Batch 00284/03692] [00:02:30/00:30:01, 0.529s/it]: train_loss_raw=1.1388, running_loss=1.1384, LR=0.000100
[2025-08-10 17:17:54,035][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040908] [Batch 00296/03692] [00:02:36/00:29:58, 0.530s/it]: train_loss_raw=1.0887, running_loss=1.1384, LR=0.000100
[2025-08-10 17:18:00,293][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040920] [Batch 00308/03692] [00:02:42/00:29:50, 0.529s/it]: train_loss_raw=1.0761, running_loss=1.1380, LR=0.000100
[2025-08-10 17:18:06,599][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040932] [Batch 00320/03692] [00:02:49/00:29:44, 0.529s/it]: train_loss_raw=1.1520, running_loss=1.1408, LR=0.000100
[2025-08-10 17:18:12,764][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040944] [Batch 00332/03692] [00:02:55/00:29:35, 0.529s/it]: train_loss_raw=1.1326, running_loss=1.1398, LR=0.000100
[2025-08-10 17:18:18,902][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040956] [Batch 00344/03692] [00:03:01/00:29:27, 0.528s/it]: train_loss_raw=1.1829, running_loss=1.1413, LR=0.000100
[2025-08-10 17:18:25,041][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040968] [Batch 00356/03692] [00:03:07/00:29:19, 0.527s/it]: train_loss_raw=1.1436, running_loss=1.1433, LR=0.000100
[2025-08-10 17:18:31,176][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040980] [Batch 00368/03692] [00:03:13/00:29:11, 0.527s/it]: train_loss_raw=1.1534, running_loss=1.1416, LR=0.000100
[2025-08-10 17:18:37,283][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040992] [Batch 00380/03692] [00:03:19/00:29:03, 0.526s/it]: train_loss_raw=1.1531, running_loss=1.1410, LR=0.000100
[2025-08-10 17:18:43,456][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041004] [Batch 00392/03692] [00:03:26/00:28:55, 0.526s/it]: train_loss_raw=0.9236, running_loss=1.1383, LR=0.000100
[2025-08-10 17:18:49,664][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041016] [Batch 00404/03692] [00:03:32/00:28:48, 0.526s/it]: train_loss_raw=1.1287, running_loss=1.1389, LR=0.000100
[2025-08-10 17:18:56,093][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041028] [Batch 00416/03692] [00:03:38/00:28:43, 0.526s/it]: train_loss_raw=1.0599, running_loss=1.1432, LR=0.000100
[2025-08-10 17:19:02,476][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041040] [Batch 00428/03692] [00:03:45/00:28:37, 0.526s/it]: train_loss_raw=1.0440, running_loss=1.1395, LR=0.000100
[2025-08-10 17:19:08,954][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041052] [Batch 00440/03692] [00:03:51/00:28:32, 0.526s/it]: train_loss_raw=1.2332, running_loss=1.1352, LR=0.000100
[2025-08-10 17:19:15,402][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041064] [Batch 00452/03692] [00:03:58/00:28:26, 0.527s/it]: train_loss_raw=0.9490, running_loss=1.1367, LR=0.000100
[2025-08-10 17:19:21,985][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041076] [Batch 00464/03692] [00:04:04/00:28:22, 0.527s/it]: train_loss_raw=1.0420, running_loss=1.1363, LR=0.000100
[2025-08-10 17:19:28,499][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041088] [Batch 00476/03692] [00:04:11/00:28:17, 0.528s/it]: train_loss_raw=1.2073, running_loss=1.1342, LR=0.000100
[2025-08-10 17:19:34,559][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041100] [Batch 00488/03692] [00:04:17/00:28:09, 0.527s/it]: train_loss_raw=1.0676, running_loss=1.1319, LR=0.000100
[2025-08-10 17:19:40,552][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041112] [Batch 00500/03692] [00:04:23/00:28:00, 0.527s/it]: train_loss_raw=1.1566, running_loss=1.1338, LR=0.000100
[2025-08-10 17:19:46,804][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041124] [Batch 00512/03692] [00:04:29/00:27:53, 0.526s/it]: train_loss_raw=1.1096, running_loss=1.1300, LR=0.000100
[2025-08-10 17:19:52,949][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041136] [Batch 00524/03692] [00:04:35/00:27:46, 0.526s/it]: train_loss_raw=1.1103, running_loss=1.1243, LR=0.000100
[2025-08-10 17:19:59,293][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041148] [Batch 00536/03692] [00:04:41/00:27:40, 0.526s/it]: train_loss_raw=1.1694, running_loss=1.1253, LR=0.000100
[2025-08-10 17:20:05,541][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041160] [Batch 00548/03692] [00:04:48/00:27:33, 0.526s/it]: train_loss_raw=1.1077, running_loss=1.1244, LR=0.000100
[2025-08-10 17:20:11,709][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041172] [Batch 00560/03692] [00:04:54/00:27:26, 0.526s/it]: train_loss_raw=1.0932, running_loss=1.1210, LR=0.000100
[2025-08-10 17:20:17,757][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041184] [Batch 00572/03692] [00:05:00/00:27:18, 0.525s/it]: train_loss_raw=1.1362, running_loss=1.1210, LR=0.000100
[2025-08-10 17:20:23,806][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041196] [Batch 00584/03692] [00:05:06/00:27:11, 0.525s/it]: train_loss_raw=1.1031, running_loss=1.1260, LR=0.000100
[2025-08-10 17:20:29,983][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041208] [Batch 00596/03692] [00:05:12/00:27:04, 0.525s/it]: train_loss_raw=1.1666, running_loss=1.1231, LR=0.000100
[2025-08-10 17:20:36,568][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041220] [Batch 00608/03692] [00:05:19/00:26:59, 0.525s/it]: train_loss_raw=1.0880, running_loss=1.1217, LR=0.000100
[2025-08-10 17:20:43,118][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041232] [Batch 00620/03692] [00:05:25/00:26:54, 0.526s/it]: train_loss_raw=0.9836, running_loss=1.1186, LR=0.000100
[2025-08-10 17:20:49,680][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041244] [Batch 00632/03692] [00:05:32/00:26:49, 0.526s/it]: train_loss_raw=1.1369, running_loss=1.1170, LR=0.000100
[2025-08-10 17:20:56,144][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041256] [Batch 00644/03692] [00:05:38/00:26:43, 0.526s/it]: train_loss_raw=1.1942, running_loss=1.1195, LR=0.000100
[2025-08-10 17:21:02,288][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041268] [Batch 00656/03692] [00:05:44/00:26:36, 0.526s/it]: train_loss_raw=0.9907, running_loss=1.1156, LR=0.000100
[2025-08-10 17:21:08,463][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041280] [Batch 00668/03692] [00:05:51/00:26:29, 0.526s/it]: train_loss_raw=1.2195, running_loss=1.1164, LR=0.000100
[2025-08-10 17:21:14,882][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041292] [Batch 00680/03692] [00:05:57/00:26:23, 0.526s/it]: train_loss_raw=1.1193, running_loss=1.1148, LR=0.000100
[2025-08-10 17:21:21,357][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041304] [Batch 00692/03692] [00:06:04/00:26:18, 0.526s/it]: train_loss_raw=1.0980, running_loss=1.1146, LR=0.000100
[2025-08-10 17:21:27,386][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041316] [Batch 00704/03692] [00:06:10/00:26:10, 0.526s/it]: train_loss_raw=1.1145, running_loss=1.1182, LR=0.000100
[2025-08-10 17:21:33,494][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041328] [Batch 00716/03692] [00:06:16/00:26:03, 0.525s/it]: train_loss_raw=1.0552, running_loss=1.1199, LR=0.000100
[2025-08-10 17:21:39,676][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041340] [Batch 00728/03692] [00:06:22/00:25:56, 0.525s/it]: train_loss_raw=1.0808, running_loss=1.1226, LR=0.000100
[2025-08-10 17:21:46,232][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041352] [Batch 00740/03692] [00:06:28/00:25:51, 0.526s/it]: train_loss_raw=1.1405, running_loss=1.1237, LR=0.000100
[2025-08-10 17:21:52,911][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041364] [Batch 00752/03692] [00:06:35/00:25:46, 0.526s/it]: train_loss_raw=1.0493, running_loss=1.1230, LR=0.000100
[2025-08-10 17:21:59,542][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041376] [Batch 00764/03692] [00:06:42/00:25:41, 0.526s/it]: train_loss_raw=1.2145, running_loss=1.1246, LR=0.000100
[2025-08-10 17:22:05,770][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041388] [Batch 00776/03692] [00:06:48/00:25:34, 0.526s/it]: train_loss_raw=1.0768, running_loss=1.1226, LR=0.000100
[2025-08-10 17:22:11,943][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041400] [Batch 00788/03692] [00:06:54/00:25:28, 0.526s/it]: train_loss_raw=1.2628, running_loss=1.1247, LR=0.000100
[2025-08-10 17:22:18,348][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041412] [Batch 00800/03692] [00:07:01/00:25:22, 0.526s/it]: train_loss_raw=1.1468, running_loss=1.1251, LR=0.000100
[2025-08-10 17:22:24,662][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041424] [Batch 00812/03692] [00:07:07/00:25:15, 0.526s/it]: train_loss_raw=1.1546, running_loss=1.1276, LR=0.000100
[2025-08-10 17:22:30,860][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041436] [Batch 00824/03692] [00:07:13/00:25:09, 0.526s/it]: train_loss_raw=1.1835, running_loss=1.1277, LR=0.000100
[2025-08-10 17:22:37,125][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041448] [Batch 00836/03692] [00:07:19/00:25:02, 0.526s/it]: train_loss_raw=1.0524, running_loss=1.1269, LR=0.000100
[2025-08-10 17:22:43,353][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041460] [Batch 00848/03692] [00:07:26/00:24:55, 0.526s/it]: train_loss_raw=1.0746, running_loss=1.1272, LR=0.000100
[2025-08-10 17:22:49,818][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041472] [Batch 00860/03692] [00:07:32/00:24:50, 0.526s/it]: train_loss_raw=1.1779, running_loss=1.1303, LR=0.000100
[2025-08-10 17:22:56,205][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041484] [Batch 00872/03692] [00:07:38/00:24:44, 0.526s/it]: train_loss_raw=1.1707, running_loss=1.1347, LR=0.000100
[2025-08-10 17:23:02,464][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041496] [Batch 00884/03692] [00:07:45/00:24:37, 0.526s/it]: train_loss_raw=1.0267, running_loss=1.1328, LR=0.000100
[2025-08-10 17:23:09,081][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041508] [Batch 00896/03692] [00:07:51/00:24:32, 0.527s/it]: train_loss_raw=1.2261, running_loss=1.1304, LR=0.000100
[2025-08-10 17:23:15,646][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041520] [Batch 00908/03692] [00:07:58/00:24:26, 0.527s/it]: train_loss_raw=1.2551, running_loss=1.1269, LR=0.000100
[2025-08-10 17:23:21,961][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041532] [Batch 00920/03692] [00:08:04/00:24:20, 0.527s/it]: train_loss_raw=1.2143, running_loss=1.1301, LR=0.000100
[2025-08-10 17:23:28,091][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041544] [Batch 00932/03692] [00:08:10/00:24:13, 0.527s/it]: train_loss_raw=1.0800, running_loss=1.1276, LR=0.000100
[2025-08-10 17:23:34,370][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041556] [Batch 00944/03692] [00:08:17/00:24:06, 0.527s/it]: train_loss_raw=0.9889, running_loss=1.1241, LR=0.000100
[2025-08-10 17:23:40,416][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041568] [Batch 00956/03692] [00:08:23/00:23:59, 0.526s/it]: train_loss_raw=1.1291, running_loss=1.1229, LR=0.000100
[2025-08-10 17:23:46,397][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041580] [Batch 00968/03692] [00:08:29/00:23:52, 0.526s/it]: train_loss_raw=1.1235, running_loss=1.1241, LR=0.000100
[2025-08-10 17:23:52,450][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041592] [Batch 00980/03692] [00:08:35/00:23:45, 0.526s/it]: train_loss_raw=1.0105, running_loss=1.1207, LR=0.000100
[2025-08-10 17:23:58,597][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041604] [Batch 00992/03692] [00:08:41/00:23:38, 0.526s/it]: train_loss_raw=1.0226, running_loss=1.1219, LR=0.000100
[2025-08-10 17:24:04,736][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041616] [Batch 01004/03692] [00:08:47/00:23:32, 0.525s/it]: train_loss_raw=1.0672, running_loss=1.1222, LR=0.000100
[2025-08-10 17:24:10,827][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041628] [Batch 01016/03692] [00:08:53/00:23:25, 0.525s/it]: train_loss_raw=0.9617, running_loss=1.1194, LR=0.000100
[2025-08-10 17:24:16,857][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041640] [Batch 01028/03692] [00:08:59/00:23:18, 0.525s/it]: train_loss_raw=1.1487, running_loss=1.1202, LR=0.000100
[2025-08-10 17:24:22,899][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041652] [Batch 01040/03692] [00:09:05/00:23:11, 0.525s/it]: train_loss_raw=1.1714, running_loss=1.1168, LR=0.000100
[2025-08-10 17:24:29,281][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041664] [Batch 01052/03692] [00:09:11/00:23:05, 0.525s/it]: train_loss_raw=0.9358, running_loss=1.1165, LR=0.000100
[2025-08-10 17:24:35,768][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041676] [Batch 01064/03692] [00:09:18/00:22:59, 0.525s/it]: train_loss_raw=1.2536, running_loss=1.1122, LR=0.000100
[2025-08-10 17:24:41,949][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041688] [Batch 01076/03692] [00:09:24/00:22:52, 0.525s/it]: train_loss_raw=0.9776, running_loss=1.1081, LR=0.000100
[2025-08-10 17:24:48,354][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041700] [Batch 01088/03692] [00:09:31/00:22:46, 0.525s/it]: train_loss_raw=1.0617, running_loss=1.1096, LR=0.000100
[2025-08-10 17:24:54,553][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041712] [Batch 01100/03692] [00:09:37/00:22:40, 0.525s/it]: train_loss_raw=1.0115, running_loss=1.1053, LR=0.000100
[2025-08-10 17:25:00,772][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041724] [Batch 01112/03692] [00:09:43/00:22:33, 0.525s/it]: train_loss_raw=1.1686, running_loss=1.1038, LR=0.000100
[2025-08-10 17:25:07,330][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041736] [Batch 01124/03692] [00:09:50/00:22:28, 0.525s/it]: train_loss_raw=1.1076, running_loss=1.0987, LR=0.000100
[2025-08-10 17:25:13,811][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041748] [Batch 01136/03692] [00:09:56/00:22:22, 0.525s/it]: train_loss_raw=1.1303, running_loss=1.0995, LR=0.000100
[2025-08-10 17:25:20,157][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041760] [Batch 01148/03692] [00:10:02/00:22:15, 0.525s/it]: train_loss_raw=1.2466, running_loss=1.1029, LR=0.000100
[2025-08-10 17:25:26,163][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041772] [Batch 01160/03692] [00:10:08/00:22:09, 0.525s/it]: train_loss_raw=1.0117, running_loss=1.1072, LR=0.000100
[2025-08-10 17:25:32,489][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041784] [Batch 01172/03692] [00:10:15/00:22:02, 0.525s/it]: train_loss_raw=1.0270, running_loss=1.1079, LR=0.000100
[2025-08-10 17:25:38,926][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041796] [Batch 01184/03692] [00:10:21/00:21:56, 0.525s/it]: train_loss_raw=1.1700, running_loss=1.1089, LR=0.000100
[2025-08-10 17:25:45,337][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041808] [Batch 01196/03692] [00:10:28/00:21:50, 0.525s/it]: train_loss_raw=1.1707, running_loss=1.1076, LR=0.000100
[2025-08-10 17:25:51,892][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041820] [Batch 01208/03692] [00:10:34/00:21:44, 0.525s/it]: train_loss_raw=1.0610, running_loss=1.1088, LR=0.000100
[2025-08-10 17:25:58,493][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041832] [Batch 01220/03692] [00:10:41/00:21:39, 0.526s/it]: train_loss_raw=1.1406, running_loss=1.1100, LR=0.000100
[2025-08-10 17:26:04,986][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041844] [Batch 01232/03692] [00:10:47/00:21:33, 0.526s/it]: train_loss_raw=1.0428, running_loss=1.1101, LR=0.000100
[2025-08-10 17:26:11,540][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041856] [Batch 01244/03692] [00:10:54/00:21:27, 0.526s/it]: train_loss_raw=1.0331, running_loss=1.1073, LR=0.000100
[2025-08-10 17:26:17,873][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041868] [Batch 01256/03692] [00:11:00/00:21:21, 0.526s/it]: train_loss_raw=0.9699, running_loss=1.1046, LR=0.000100
[2025-08-10 17:26:24,226][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041880] [Batch 01268/03692] [00:11:06/00:21:14, 0.526s/it]: train_loss_raw=1.1318, running_loss=1.1034, LR=0.000100
[2025-08-10 17:26:30,601][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041892] [Batch 01280/03692] [00:11:13/00:21:08, 0.526s/it]: train_loss_raw=1.1034, running_loss=1.1045, LR=0.000100
[2025-08-10 17:26:36,797][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041904] [Batch 01292/03692] [00:11:19/00:21:02, 0.526s/it]: train_loss_raw=1.0953, running_loss=1.1053, LR=0.000100
[2025-08-10 17:26:42,957][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041916] [Batch 01304/03692] [00:11:25/00:20:55, 0.526s/it]: train_loss_raw=1.0633, running_loss=1.1035, LR=0.000100
[2025-08-10 17:26:49,534][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041928] [Batch 01316/03692] [00:11:32/00:20:49, 0.526s/it]: train_loss_raw=1.1183, running_loss=1.1019, LR=0.000100
[2025-08-10 17:26:55,765][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041940] [Batch 01328/03692] [00:11:38/00:20:43, 0.526s/it]: train_loss_raw=1.2431, running_loss=1.0999, LR=0.000100
[2025-08-10 17:27:02,279][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041952] [Batch 01340/03692] [00:11:44/00:20:37, 0.526s/it]: train_loss_raw=1.1094, running_loss=1.1046, LR=0.000100
[2025-08-10 17:27:08,775][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041964] [Batch 01352/03692] [00:11:51/00:20:31, 0.526s/it]: train_loss_raw=1.0949, running_loss=1.1060, LR=0.000100
[2025-08-10 17:27:15,239][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041976] [Batch 01364/03692] [00:11:57/00:20:25, 0.526s/it]: train_loss_raw=1.1116, running_loss=1.1085, LR=0.000100
[2025-08-10 17:27:21,652][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041988] [Batch 01376/03692] [00:12:04/00:20:19, 0.526s/it]: train_loss_raw=1.1230, running_loss=1.1049, LR=0.000100
[2025-08-10 17:27:28,174][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042000] [Batch 01388/03692] [00:12:10/00:20:13, 0.527s/it]: train_loss_raw=0.9950, running_loss=1.1032, LR=0.000100
[2025-08-10 17:27:40,731][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042012] [Batch 01400/03692] [00:12:23/00:20:17, 0.531s/it]: train_loss_raw=1.1539, running_loss=1.1027, LR=0.000100
[2025-08-10 17:27:47,185][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042024] [Batch 01412/03692] [00:12:29/00:20:10, 0.531s/it]: train_loss_raw=1.0358, running_loss=1.1031, LR=0.000100
[2025-08-10 17:27:53,561][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042036] [Batch 01424/03692] [00:12:36/00:20:04, 0.531s/it]: train_loss_raw=1.2613, running_loss=1.1022, LR=0.000100
[2025-08-10 17:27:59,989][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042048] [Batch 01436/03692] [00:12:42/00:19:58, 0.531s/it]: train_loss_raw=1.1417, running_loss=1.1043, LR=0.000100
[2025-08-10 17:28:06,233][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042060] [Batch 01448/03692] [00:12:48/00:19:51, 0.531s/it]: train_loss_raw=1.1463, running_loss=1.1026, LR=0.000100
[2025-08-10 17:28:12,595][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042072] [Batch 01460/03692] [00:12:55/00:19:45, 0.531s/it]: train_loss_raw=1.1706, running_loss=1.1068, LR=0.000100
[2025-08-10 17:28:18,907][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042084] [Batch 01472/03692] [00:13:01/00:19:38, 0.531s/it]: train_loss_raw=1.1784, running_loss=1.1059, LR=0.000100
[2025-08-10 17:28:25,349][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042096] [Batch 01484/03692] [00:13:08/00:19:32, 0.531s/it]: train_loss_raw=1.2161, running_loss=1.1093, LR=0.000100
[2025-08-10 17:28:31,797][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042108] [Batch 01496/03692] [00:13:14/00:19:26, 0.531s/it]: train_loss_raw=1.1607, running_loss=1.1107, LR=0.000100
[2025-08-10 17:28:38,167][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042120] [Batch 01508/03692] [00:13:20/00:19:19, 0.531s/it]: train_loss_raw=1.1659, running_loss=1.1131, LR=0.000100
[2025-08-10 17:28:44,726][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042132] [Batch 01520/03692] [00:13:27/00:19:13, 0.531s/it]: train_loss_raw=1.2180, running_loss=1.1170, LR=0.000100
[2025-08-10 17:28:51,245][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042144] [Batch 01532/03692] [00:13:33/00:19:07, 0.531s/it]: train_loss_raw=1.0461, running_loss=1.1144, LR=0.000100
[2025-08-10 17:28:57,826][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042156] [Batch 01544/03692] [00:13:40/00:19:01, 0.531s/it]: train_loss_raw=1.0602, running_loss=1.1139, LR=0.000100
[2025-08-10 17:29:03,955][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042168] [Batch 01556/03692] [00:13:46/00:18:54, 0.531s/it]: train_loss_raw=1.2679, running_loss=1.1113, LR=0.000100
[2025-08-10 17:29:10,121][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042180] [Batch 01568/03692] [00:13:52/00:18:48, 0.531s/it]: train_loss_raw=1.0844, running_loss=1.1110, LR=0.000100
[2025-08-10 17:29:16,228][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042192] [Batch 01580/03692] [00:13:58/00:18:41, 0.531s/it]: train_loss_raw=1.0686, running_loss=1.1127, LR=0.000100
[2025-08-10 17:29:22,363][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042204] [Batch 01592/03692] [00:14:05/00:18:34, 0.531s/it]: train_loss_raw=1.0503, running_loss=1.1118, LR=0.000100
[2025-08-10 17:29:28,996][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042216] [Batch 01604/03692] [00:14:11/00:18:28, 0.531s/it]: train_loss_raw=1.0642, running_loss=1.1120, LR=0.000100
[2025-08-10 17:29:35,463][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042228] [Batch 01616/03692] [00:14:18/00:18:22, 0.531s/it]: train_loss_raw=1.0645, running_loss=1.1153, LR=0.000100
[2025-08-10 17:29:41,797][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042240] [Batch 01628/03692] [00:14:24/00:18:16, 0.531s/it]: train_loss_raw=1.1732, running_loss=1.1180, LR=0.000100
[2025-08-10 17:29:47,832][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042252] [Batch 01640/03692] [00:14:30/00:18:09, 0.531s/it]: train_loss_raw=1.1282, running_loss=1.1181, LR=0.000100
[2025-08-10 17:29:54,138][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042264] [Batch 01652/03692] [00:14:36/00:18:02, 0.531s/it]: train_loss_raw=1.0776, running_loss=1.1201, LR=0.000100
[2025-08-10 17:30:00,531][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042276] [Batch 01664/03692] [00:14:43/00:17:56, 0.531s/it]: train_loss_raw=1.2761, running_loss=1.1267, LR=0.000100
[2025-08-10 17:30:07,042][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042288] [Batch 01676/03692] [00:14:49/00:17:50, 0.531s/it]: train_loss_raw=0.9811, running_loss=1.1198, LR=0.000100
[2025-08-10 17:30:13,233][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042300] [Batch 01688/03692] [00:14:55/00:17:43, 0.531s/it]: train_loss_raw=1.0479, running_loss=1.1168, LR=0.000100
[2025-08-10 17:30:19,411][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042312] [Batch 01700/03692] [00:15:02/00:17:37, 0.531s/it]: train_loss_raw=1.2533, running_loss=1.1151, LR=0.000100
[2025-08-10 17:30:25,474][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042324] [Batch 01712/03692] [00:15:08/00:17:30, 0.530s/it]: train_loss_raw=1.1211, running_loss=1.1167, LR=0.000100
[2025-08-10 17:30:31,604][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042336] [Batch 01724/03692] [00:15:14/00:17:23, 0.530s/it]: train_loss_raw=1.1464, running_loss=1.1142, LR=0.000100
[2025-08-10 17:30:38,015][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042348] [Batch 01736/03692] [00:15:20/00:17:17, 0.530s/it]: train_loss_raw=0.9217, running_loss=1.1096, LR=0.000100
[2025-08-10 17:30:44,198][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042360] [Batch 01748/03692] [00:15:26/00:17:10, 0.530s/it]: train_loss_raw=1.0605, running_loss=1.1105, LR=0.000100
[2025-08-10 17:30:50,346][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042372] [Batch 01760/03692] [00:15:33/00:17:04, 0.530s/it]: train_loss_raw=1.2127, running_loss=1.1108, LR=0.000100
[2025-08-10 17:30:56,515][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042384] [Batch 01772/03692] [00:15:39/00:16:57, 0.530s/it]: train_loss_raw=1.0538, running_loss=1.1141, LR=0.000100
[2025-08-10 17:31:02,833][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042396] [Batch 01784/03692] [00:15:45/00:16:51, 0.530s/it]: train_loss_raw=1.0130, running_loss=1.1085, LR=0.000100
[2025-08-10 17:31:09,387][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042408] [Batch 01796/03692] [00:15:52/00:16:45, 0.530s/it]: train_loss_raw=1.1290, running_loss=1.1099, LR=0.000100
[2025-08-10 17:31:15,694][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042420] [Batch 01808/03692] [00:15:58/00:16:38, 0.530s/it]: train_loss_raw=1.0360, running_loss=1.1086, LR=0.000100
[2025-08-10 17:31:21,915][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042432] [Batch 01820/03692] [00:16:04/00:16:32, 0.530s/it]: train_loss_raw=1.0766, running_loss=1.1097, LR=0.000100
[2025-08-10 17:31:28,462][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042444] [Batch 01832/03692] [00:16:11/00:16:26, 0.530s/it]: train_loss_raw=0.9776, running_loss=1.1092, LR=0.000100
[2025-08-10 17:31:34,863][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042456] [Batch 01844/03692] [00:16:17/00:16:19, 0.530s/it]: train_loss_raw=1.0812, running_loss=1.1085, LR=0.000100
[2025-08-10 17:31:41,249][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042468] [Batch 01856/03692] [00:16:23/00:16:13, 0.530s/it]: train_loss_raw=1.1417, running_loss=1.1112, LR=0.000100
[2025-08-10 17:31:47,614][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042480] [Batch 01868/03692] [00:16:30/00:16:06, 0.530s/it]: train_loss_raw=1.1270, running_loss=1.1085, LR=0.000100
[2025-08-10 17:31:54,017][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042492] [Batch 01880/03692] [00:16:36/00:16:00, 0.530s/it]: train_loss_raw=1.0646, running_loss=1.1074, LR=0.000100
[2025-08-10 17:32:00,465][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042504] [Batch 01892/03692] [00:16:43/00:15:54, 0.530s/it]: train_loss_raw=1.1625, running_loss=1.1089, LR=0.000100
[2025-08-10 17:32:06,998][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042516] [Batch 01904/03692] [00:16:49/00:15:48, 0.530s/it]: train_loss_raw=1.1006, running_loss=1.1092, LR=0.000100
[2025-08-10 17:32:13,461][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042528] [Batch 01916/03692] [00:16:56/00:15:41, 0.530s/it]: train_loss_raw=1.0387, running_loss=1.1083, LR=0.000100
[2025-08-10 17:32:19,839][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042540] [Batch 01928/03692] [00:17:02/00:15:35, 0.530s/it]: train_loss_raw=1.1422, running_loss=1.1077, LR=0.000100
[2025-08-10 17:32:25,953][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042552] [Batch 01940/03692] [00:17:08/00:15:28, 0.530s/it]: train_loss_raw=1.0889, running_loss=1.1068, LR=0.000100
[2025-08-10 17:32:32,027][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042564] [Batch 01952/03692] [00:17:14/00:15:22, 0.530s/it]: train_loss_raw=1.0243, running_loss=1.1049, LR=0.000100
[2025-08-10 17:32:38,586][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042576] [Batch 01964/03692] [00:17:21/00:15:16, 0.530s/it]: train_loss_raw=1.1598, running_loss=1.1092, LR=0.000100
[2025-08-10 17:32:44,973][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042588] [Batch 01976/03692] [00:17:27/00:15:09, 0.530s/it]: train_loss_raw=1.1253, running_loss=1.1066, LR=0.000100
[2025-08-10 17:32:51,249][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042600] [Batch 01988/03692] [00:17:33/00:15:03, 0.530s/it]: train_loss_raw=1.0486, running_loss=1.1060, LR=0.000100
[2025-08-10 17:32:57,441][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042612] [Batch 02000/03692] [00:17:40/00:14:56, 0.530s/it]: train_loss_raw=1.1573, running_loss=1.1068, LR=0.000100
[2025-08-10 17:33:03,874][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042624] [Batch 02012/03692] [00:17:46/00:14:50, 0.530s/it]: train_loss_raw=1.1604, running_loss=1.1083, LR=0.000100
[2025-08-10 17:33:10,583][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042636] [Batch 02024/03692] [00:17:53/00:14:44, 0.530s/it]: train_loss_raw=1.1503, running_loss=1.1090, LR=0.000100
[2025-08-10 17:33:17,147][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042648] [Batch 02036/03692] [00:17:59/00:14:38, 0.530s/it]: train_loss_raw=1.1387, running_loss=1.1115, LR=0.000100
[2025-08-10 17:33:23,429][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042660] [Batch 02048/03692] [00:18:06/00:14:31, 0.530s/it]: train_loss_raw=0.9832, running_loss=1.1114, LR=0.000100
[2025-08-10 17:33:29,620][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042672] [Batch 02060/03692] [00:18:12/00:14:25, 0.530s/it]: train_loss_raw=1.0440, running_loss=1.1090, LR=0.000100
[2025-08-10 17:33:35,955][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042684] [Batch 02072/03692] [00:18:18/00:14:18, 0.530s/it]: train_loss_raw=1.1580, running_loss=1.1113, LR=0.000100
[2025-08-10 17:33:41,980][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042696] [Batch 02084/03692] [00:18:24/00:14:12, 0.530s/it]: train_loss_raw=1.1137, running_loss=1.1119, LR=0.000100
[2025-08-10 17:33:48,058][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042708] [Batch 02096/03692] [00:18:30/00:14:05, 0.530s/it]: train_loss_raw=1.1087, running_loss=1.1113, LR=0.000100
[2025-08-10 17:33:54,038][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042720] [Batch 02108/03692] [00:18:36/00:13:59, 0.530s/it]: train_loss_raw=1.1406, running_loss=1.1126, LR=0.000100
[2025-08-10 17:34:00,079][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042732] [Batch 02120/03692] [00:18:42/00:13:52, 0.530s/it]: train_loss_raw=1.0151, running_loss=1.1064, LR=0.000100
[2025-08-10 17:34:06,359][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042744] [Batch 02132/03692] [00:18:49/00:13:46, 0.530s/it]: train_loss_raw=1.0635, running_loss=1.1049, LR=0.000100
[2025-08-10 17:34:12,631][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042756] [Batch 02144/03692] [00:18:55/00:13:39, 0.530s/it]: train_loss_raw=1.0012, running_loss=1.1016, LR=0.000100
[2025-08-10 17:34:19,102][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042768] [Batch 02156/03692] [00:19:01/00:13:33, 0.530s/it]: train_loss_raw=1.2188, running_loss=1.1009, LR=0.000100
[2025-08-10 17:34:25,294][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042780] [Batch 02168/03692] [00:19:07/00:13:26, 0.530s/it]: train_loss_raw=1.1642, running_loss=1.0988, LR=0.000100
[2025-08-10 17:34:31,479][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042792] [Batch 02180/03692] [00:19:14/00:13:20, 0.529s/it]: train_loss_raw=1.1247, running_loss=1.1008, LR=0.000100
[2025-08-10 17:34:38,013][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042804] [Batch 02192/03692] [00:19:20/00:13:14, 0.530s/it]: train_loss_raw=1.2470, running_loss=1.1043, LR=0.000100
[2025-08-10 17:34:44,174][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042816] [Batch 02204/03692] [00:19:26/00:13:07, 0.529s/it]: train_loss_raw=1.1573, running_loss=1.1033, LR=0.000100
[2025-08-10 17:34:50,333][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042828] [Batch 02216/03692] [00:19:33/00:13:01, 0.529s/it]: train_loss_raw=1.0426, running_loss=1.1046, LR=0.000100
[2025-08-10 17:34:56,505][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042840] [Batch 02228/03692] [00:19:39/00:12:54, 0.529s/it]: train_loss_raw=1.0488, running_loss=1.1048, LR=0.000100
[2025-08-10 17:35:02,645][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042852] [Batch 02240/03692] [00:19:45/00:12:48, 0.529s/it]: train_loss_raw=1.0606, running_loss=1.1100, LR=0.000100
[2025-08-10 17:35:08,734][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042864] [Batch 02252/03692] [00:19:51/00:12:41, 0.529s/it]: train_loss_raw=1.1436, running_loss=1.1066, LR=0.000100
[2025-08-10 17:35:14,933][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042876] [Batch 02264/03692] [00:19:57/00:12:35, 0.529s/it]: train_loss_raw=1.1888, running_loss=1.1049, LR=0.000100
[2025-08-10 17:35:21,090][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042888] [Batch 02276/03692] [00:20:03/00:12:28, 0.529s/it]: train_loss_raw=1.2030, running_loss=1.1043, LR=0.000100
[2025-08-10 17:35:27,148][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042900] [Batch 02288/03692] [00:20:09/00:12:22, 0.529s/it]: train_loss_raw=1.1208, running_loss=1.1028, LR=0.000100
[2025-08-10 17:35:33,297][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042912] [Batch 02300/03692] [00:20:16/00:12:15, 0.529s/it]: train_loss_raw=1.0043, running_loss=1.1025, LR=0.000100
[2025-08-10 17:35:39,349][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042924] [Batch 02312/03692] [00:20:22/00:12:09, 0.529s/it]: train_loss_raw=1.1346, running_loss=1.1048, LR=0.000100
[2025-08-10 17:35:45,369][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042936] [Batch 02324/03692] [00:20:28/00:12:02, 0.528s/it]: train_loss_raw=1.0226, running_loss=1.1017, LR=0.000100
[2025-08-10 17:35:51,434][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042948] [Batch 02336/03692] [00:20:34/00:11:56, 0.528s/it]: train_loss_raw=1.1905, running_loss=1.1024, LR=0.000100
[2025-08-10 17:35:57,530][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042960] [Batch 02348/03692] [00:20:40/00:11:49, 0.528s/it]: train_loss_raw=1.1275, running_loss=1.1060, LR=0.000100
[2025-08-10 17:36:03,532][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042972] [Batch 02360/03692] [00:20:46/00:11:43, 0.528s/it]: train_loss_raw=0.9587, running_loss=1.1001, LR=0.000100
[2025-08-10 17:36:09,594][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042984] [Batch 02372/03692] [00:20:52/00:11:36, 0.528s/it]: train_loss_raw=1.0432, running_loss=1.1026, LR=0.000100
[2025-08-10 17:36:15,686][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042996] [Batch 02384/03692] [00:20:58/00:11:30, 0.528s/it]: train_loss_raw=1.0891, running_loss=1.1021, LR=0.000100
[2025-08-10 17:36:21,788][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043008] [Batch 02396/03692] [00:21:04/00:11:23, 0.528s/it]: train_loss_raw=1.1081, running_loss=1.1082, LR=0.000100
[2025-08-10 17:36:27,834][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043020] [Batch 02408/03692] [00:21:10/00:11:17, 0.528s/it]: train_loss_raw=1.2478, running_loss=1.1052, LR=0.000100
[2025-08-10 17:36:33,824][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043032] [Batch 02420/03692] [00:21:16/00:11:10, 0.527s/it]: train_loss_raw=1.0506, running_loss=1.1064, LR=0.000100
[2025-08-10 17:36:39,873][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043044] [Batch 02432/03692] [00:21:22/00:11:04, 0.527s/it]: train_loss_raw=1.0918, running_loss=1.1031, LR=0.000100
[2025-08-10 17:36:45,935][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043056] [Batch 02444/03692] [00:21:28/00:10:58, 0.527s/it]: train_loss_raw=1.1139, running_loss=1.1040, LR=0.000100
[2025-08-10 17:36:51,941][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043068] [Batch 02456/03692] [00:21:34/00:10:51, 0.527s/it]: train_loss_raw=0.9622, running_loss=1.0986, LR=0.000100
[2025-08-10 17:36:58,019][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043080] [Batch 02468/03692] [00:21:40/00:10:45, 0.527s/it]: train_loss_raw=1.2264, running_loss=1.0999, LR=0.000100
[2025-08-10 17:37:04,201][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043092] [Batch 02480/03692] [00:21:46/00:10:38, 0.527s/it]: train_loss_raw=1.0906, running_loss=1.0947, LR=0.000100
[2025-08-10 17:37:10,329][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043104] [Batch 02492/03692] [00:21:53/00:10:32, 0.527s/it]: train_loss_raw=1.1112, running_loss=1.0926, LR=0.000100
[2025-08-10 17:37:16,315][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043116] [Batch 02504/03692] [00:21:59/00:10:25, 0.527s/it]: train_loss_raw=1.1749, running_loss=1.0929, LR=0.000100
[2025-08-10 17:37:22,406][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043128] [Batch 02516/03692] [00:22:05/00:10:19, 0.527s/it]: train_loss_raw=1.0785, running_loss=1.0943, LR=0.000100
[2025-08-10 17:37:28,492][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043140] [Batch 02528/03692] [00:22:11/00:10:12, 0.527s/it]: train_loss_raw=1.0743, running_loss=1.0982, LR=0.000100
[2025-08-10 17:37:34,546][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043152] [Batch 02540/03692] [00:22:17/00:10:06, 0.526s/it]: train_loss_raw=1.1147, running_loss=1.1000, LR=0.000100
[2025-08-10 17:37:40,829][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043164] [Batch 02552/03692] [00:22:23/00:10:00, 0.526s/it]: train_loss_raw=1.1690, running_loss=1.1019, LR=0.000100
[2025-08-10 17:37:47,067][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043176] [Batch 02564/03692] [00:22:29/00:09:53, 0.526s/it]: train_loss_raw=1.1420, running_loss=1.0998, LR=0.000100
[2025-08-10 17:37:53,122][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043188] [Batch 02576/03692] [00:22:35/00:09:47, 0.526s/it]: train_loss_raw=1.1470, running_loss=1.1043, LR=0.000100
[2025-08-10 17:37:59,124][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043200] [Batch 02588/03692] [00:22:41/00:09:40, 0.526s/it]: train_loss_raw=1.0297, running_loss=1.1031, LR=0.000100
[2025-08-10 17:38:05,175][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043212] [Batch 02600/03692] [00:22:47/00:09:34, 0.526s/it]: train_loss_raw=1.1001, running_loss=1.1026, LR=0.000100
[2025-08-10 17:38:11,268][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043224] [Batch 02612/03692] [00:22:53/00:09:28, 0.526s/it]: train_loss_raw=1.0565, running_loss=1.1028, LR=0.000100
[2025-08-10 17:38:17,313][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043236] [Batch 02624/03692] [00:23:00/00:09:21, 0.526s/it]: train_loss_raw=1.0765, running_loss=1.0975, LR=0.000100
[2025-08-10 17:38:23,369][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043248] [Batch 02636/03692] [00:23:06/00:09:15, 0.526s/it]: train_loss_raw=0.9096, running_loss=1.0960, LR=0.000100
[2025-08-10 17:38:29,426][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043260] [Batch 02648/03692] [00:23:12/00:09:08, 0.526s/it]: train_loss_raw=1.0008, running_loss=1.0951, LR=0.000100
[2025-08-10 17:38:35,499][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043272] [Batch 02660/03692] [00:23:18/00:09:02, 0.526s/it]: train_loss_raw=1.1842, running_loss=1.0941, LR=0.000100
[2025-08-10 17:38:41,480][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043284] [Batch 02672/03692] [00:23:24/00:08:56, 0.526s/it]: train_loss_raw=1.1202, running_loss=1.0956, LR=0.000100
[2025-08-10 17:38:47,571][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043296] [Batch 02684/03692] [00:23:30/00:08:49, 0.525s/it]: train_loss_raw=1.0507, running_loss=1.0942, LR=0.000100
[2025-08-10 17:38:53,642][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043308] [Batch 02696/03692] [00:23:36/00:08:43, 0.525s/it]: train_loss_raw=1.0754, running_loss=1.0963, LR=0.000100
[2025-08-10 17:38:59,716][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043320] [Batch 02708/03692] [00:23:42/00:08:36, 0.525s/it]: train_loss_raw=1.0804, running_loss=1.0978, LR=0.000100
[2025-08-10 17:39:05,748][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043332] [Batch 02720/03692] [00:23:48/00:08:30, 0.525s/it]: train_loss_raw=1.2218, running_loss=1.1017, LR=0.000100
[2025-08-10 17:39:11,756][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043344] [Batch 02732/03692] [00:23:54/00:08:24, 0.525s/it]: train_loss_raw=1.0524, running_loss=1.1059, LR=0.000100
[2025-08-10 17:39:17,789][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043356] [Batch 02744/03692] [00:24:00/00:08:17, 0.525s/it]: train_loss_raw=1.2147, running_loss=1.1092, LR=0.000100
[2025-08-10 17:39:23,815][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043368] [Batch 02756/03692] [00:24:06/00:08:11, 0.525s/it]: train_loss_raw=1.0570, running_loss=1.1051, LR=0.000100
[2025-08-10 17:39:29,938][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043380] [Batch 02768/03692] [00:24:12/00:08:04, 0.525s/it]: train_loss_raw=1.1531, running_loss=1.1046, LR=0.000100
[2025-08-10 17:39:36,034][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043392] [Batch 02780/03692] [00:24:18/00:07:58, 0.525s/it]: train_loss_raw=1.1911, running_loss=1.1080, LR=0.000100
[2025-08-10 17:39:42,142][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043404] [Batch 02792/03692] [00:24:24/00:07:52, 0.525s/it]: train_loss_raw=0.9790, running_loss=1.1048, LR=0.000100
[2025-08-10 17:39:48,164][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043416] [Batch 02804/03692] [00:24:30/00:07:45, 0.525s/it]: train_loss_raw=0.9168, running_loss=1.1001, LR=0.000100
[2025-08-10 17:39:54,269][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043428] [Batch 02816/03692] [00:24:36/00:07:39, 0.524s/it]: train_loss_raw=1.1273, running_loss=1.0994, LR=0.000100
[2025-08-10 17:40:00,335][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043440] [Batch 02828/03692] [00:24:43/00:07:33, 0.524s/it]: train_loss_raw=0.9691, running_loss=1.0973, LR=0.000100
[2025-08-10 17:40:06,452][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043452] [Batch 02840/03692] [00:24:49/00:07:26, 0.524s/it]: train_loss_raw=1.1353, running_loss=1.0931, LR=0.000100
[2025-08-10 17:40:12,492][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043464] [Batch 02852/03692] [00:24:55/00:07:20, 0.524s/it]: train_loss_raw=1.0072, running_loss=1.0911, LR=0.000100
[2025-08-10 17:40:18,556][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043476] [Batch 02864/03692] [00:25:01/00:07:14, 0.524s/it]: train_loss_raw=1.1105, running_loss=1.0884, LR=0.000100
[2025-08-10 17:40:25,018][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043488] [Batch 02876/03692] [00:25:07/00:07:07, 0.524s/it]: train_loss_raw=1.0269, running_loss=1.0873, LR=0.000100
[2025-08-10 17:40:31,609][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043500] [Batch 02888/03692] [00:25:14/00:07:01, 0.524s/it]: train_loss_raw=1.1423, running_loss=1.0883, LR=0.000100
[2025-08-10 17:40:38,170][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043512] [Batch 02900/03692] [00:25:20/00:06:55, 0.524s/it]: train_loss_raw=1.1653, running_loss=1.0867, LR=0.000100
[2025-08-10 17:40:44,451][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043524] [Batch 02912/03692] [00:25:27/00:06:49, 0.524s/it]: train_loss_raw=1.0203, running_loss=1.0843, LR=0.000100
[2025-08-10 17:40:50,681][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043536] [Batch 02924/03692] [00:25:33/00:06:42, 0.524s/it]: train_loss_raw=1.0069, running_loss=1.0850, LR=0.000100
[2025-08-10 17:40:56,897][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043548] [Batch 02936/03692] [00:25:39/00:06:36, 0.524s/it]: train_loss_raw=0.9656, running_loss=1.0853, LR=0.000100
[2025-08-10 17:41:03,111][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043560] [Batch 02948/03692] [00:25:45/00:06:30, 0.524s/it]: train_loss_raw=1.0197, running_loss=1.0876, LR=0.000100
[2025-08-10 17:41:09,192][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043572] [Batch 02960/03692] [00:25:51/00:06:23, 0.524s/it]: train_loss_raw=1.1280, running_loss=1.0894, LR=0.000100
[2025-08-10 17:41:15,229][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043584] [Batch 02972/03692] [00:25:57/00:06:17, 0.524s/it]: train_loss_raw=0.9813, running_loss=1.0905, LR=0.000100
[2025-08-10 17:41:21,397][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043596] [Batch 02984/03692] [00:26:04/00:06:11, 0.524s/it]: train_loss_raw=1.2463, running_loss=1.0928, LR=0.000100
[2025-08-10 17:41:27,469][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043608] [Batch 02996/03692] [00:26:10/00:06:04, 0.524s/it]: train_loss_raw=1.0478, running_loss=1.0935, LR=0.000100
[2025-08-10 17:41:33,509][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043620] [Batch 03008/03692] [00:26:16/00:05:58, 0.524s/it]: train_loss_raw=1.0592, running_loss=1.0909, LR=0.000100
[2025-08-10 17:41:39,585][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043632] [Batch 03020/03692] [00:26:22/00:05:52, 0.524s/it]: train_loss_raw=1.0298, running_loss=1.0885, LR=0.000100
[2025-08-10 17:41:45,632][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043644] [Batch 03032/03692] [00:26:28/00:05:45, 0.524s/it]: train_loss_raw=0.9647, running_loss=1.0882, LR=0.000100
[2025-08-10 17:41:51,674][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043656] [Batch 03044/03692] [00:26:34/00:05:39, 0.524s/it]: train_loss_raw=1.1375, running_loss=1.0889, LR=0.000100
[2025-08-10 17:41:57,651][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043668] [Batch 03056/03692] [00:26:40/00:05:33, 0.524s/it]: train_loss_raw=1.1272, running_loss=1.0852, LR=0.000100
[2025-08-10 17:42:03,687][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043680] [Batch 03068/03692] [00:26:46/00:05:26, 0.524s/it]: train_loss_raw=1.0783, running_loss=1.0854, LR=0.000100
[2025-08-10 17:42:09,770][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043692] [Batch 03080/03692] [00:26:52/00:05:20, 0.524s/it]: train_loss_raw=1.0776, running_loss=1.0893, LR=0.000100
[2025-08-10 17:42:15,771][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043704] [Batch 03092/03692] [00:26:58/00:05:14, 0.523s/it]: train_loss_raw=1.0266, running_loss=1.0854, LR=0.000100
[2025-08-10 17:42:21,842][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043716] [Batch 03104/03692] [00:27:04/00:05:07, 0.523s/it]: train_loss_raw=1.1129, running_loss=1.0894, LR=0.000100
[2025-08-10 17:42:27,827][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043728] [Batch 03116/03692] [00:27:10/00:05:01, 0.523s/it]: train_loss_raw=1.1187, running_loss=1.0933, LR=0.000100
[2025-08-10 17:42:33,829][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043740] [Batch 03128/03692] [00:27:16/00:04:55, 0.523s/it]: train_loss_raw=1.1163, running_loss=1.0915, LR=0.000100
[2025-08-10 17:42:39,877][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043752] [Batch 03140/03692] [00:27:22/00:04:48, 0.523s/it]: train_loss_raw=1.0559, running_loss=1.0897, LR=0.000100
[2025-08-10 17:42:45,858][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043764] [Batch 03152/03692] [00:27:28/00:04:42, 0.523s/it]: train_loss_raw=1.0698, running_loss=1.0893, LR=0.000100
[2025-08-10 17:42:51,907][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043776] [Batch 03164/03692] [00:27:34/00:04:36, 0.523s/it]: train_loss_raw=1.0153, running_loss=1.0876, LR=0.000100
[2025-08-10 17:42:57,973][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043788] [Batch 03176/03692] [00:27:40/00:04:29, 0.523s/it]: train_loss_raw=1.0605, running_loss=1.0887, LR=0.000100
[2025-08-10 17:43:04,087][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043800] [Batch 03188/03692] [00:27:46/00:04:23, 0.523s/it]: train_loss_raw=1.1234, running_loss=1.0926, LR=0.000100
[2025-08-10 17:43:10,103][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043812] [Batch 03200/03692] [00:27:52/00:04:17, 0.523s/it]: train_loss_raw=1.2547, running_loss=1.0899, LR=0.000100
[2025-08-10 17:43:16,147][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043824] [Batch 03212/03692] [00:27:58/00:04:10, 0.523s/it]: train_loss_raw=1.0005, running_loss=1.0911, LR=0.000100
[2025-08-10 17:43:22,272][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043836] [Batch 03224/03692] [00:28:04/00:04:04, 0.523s/it]: train_loss_raw=1.0849, running_loss=1.0946, LR=0.000100
[2025-08-10 17:43:28,757][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043848] [Batch 03236/03692] [00:28:11/00:03:58, 0.523s/it]: train_loss_raw=1.0560, running_loss=1.0967, LR=0.000100
[2025-08-10 17:43:34,727][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043860] [Batch 03248/03692] [00:28:17/00:03:52, 0.523s/it]: train_loss_raw=1.1129, running_loss=1.0967, LR=0.000100
[2025-08-10 17:43:40,974][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043872] [Batch 03260/03692] [00:28:23/00:03:45, 0.523s/it]: train_loss_raw=1.0371, running_loss=1.0926, LR=0.000100
[2025-08-10 17:43:47,515][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043884] [Batch 03272/03692] [00:28:30/00:03:39, 0.523s/it]: train_loss_raw=0.9843, running_loss=1.0899, LR=0.000100
[2025-08-10 17:43:53,899][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043896] [Batch 03284/03692] [00:28:36/00:03:33, 0.523s/it]: train_loss_raw=1.1342, running_loss=1.0879, LR=0.000100
[2025-08-10 17:44:00,424][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043908] [Batch 03296/03692] [00:28:43/00:03:27, 0.523s/it]: train_loss_raw=0.9967, running_loss=1.0863, LR=0.000100
[2025-08-10 17:44:06,978][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043920] [Batch 03308/03692] [00:28:49/00:03:20, 0.523s/it]: train_loss_raw=1.1620, running_loss=1.0850, LR=0.000100
[2025-08-10 17:44:13,213][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043932] [Batch 03320/03692] [00:28:55/00:03:14, 0.523s/it]: train_loss_raw=1.0829, running_loss=1.0861, LR=0.000100
[2025-08-10 17:44:19,621][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043944] [Batch 03332/03692] [00:29:02/00:03:08, 0.523s/it]: train_loss_raw=1.0360, running_loss=1.0830, LR=0.000100
[2025-08-10 17:44:26,117][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043956] [Batch 03344/03692] [00:29:08/00:03:01, 0.523s/it]: train_loss_raw=1.0632, running_loss=1.0860, LR=0.000100
[2025-08-10 17:44:32,654][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043968] [Batch 03356/03692] [00:29:15/00:02:55, 0.523s/it]: train_loss_raw=1.2465, running_loss=1.0859, LR=0.000100
[2025-08-10 17:44:39,094][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043980] [Batch 03368/03692] [00:29:21/00:02:49, 0.523s/it]: train_loss_raw=1.0600, running_loss=1.0822, LR=0.000100
[2025-08-10 17:44:45,615][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043992] [Batch 03380/03692] [00:29:28/00:02:43, 0.523s/it]: train_loss_raw=1.0073, running_loss=1.0854, LR=0.000100
[2025-08-10 17:44:57,426][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044004] [Batch 03392/03692] [00:29:40/00:02:37, 0.525s/it]: train_loss_raw=1.1077, running_loss=1.0847, LR=0.000100
[2025-08-10 17:45:03,963][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044016] [Batch 03404/03692] [00:29:46/00:02:31, 0.525s/it]: train_loss_raw=0.9518, running_loss=1.0820, LR=0.000100
[2025-08-10 17:45:10,465][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044028] [Batch 03416/03692] [00:29:53/00:02:24, 0.525s/it]: train_loss_raw=1.0188, running_loss=1.0804, LR=0.000100
[2025-08-10 17:45:16,959][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044040] [Batch 03428/03692] [00:29:59/00:02:18, 0.525s/it]: train_loss_raw=1.1500, running_loss=1.0792, LR=0.000100
[2025-08-10 17:45:23,077][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044052] [Batch 03440/03692] [00:30:05/00:02:12, 0.525s/it]: train_loss_raw=1.0255, running_loss=1.0825, LR=0.000100
[2025-08-10 17:45:29,137][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044064] [Batch 03452/03692] [00:30:11/00:02:05, 0.525s/it]: train_loss_raw=1.1429, running_loss=1.0887, LR=0.000100
[2025-08-10 17:45:35,207][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044076] [Batch 03464/03692] [00:30:17/00:01:59, 0.525s/it]: train_loss_raw=1.1959, running_loss=1.0906, LR=0.000100
[2025-08-10 17:45:41,219][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044088] [Batch 03476/03692] [00:30:23/00:01:53, 0.525s/it]: train_loss_raw=1.0672, running_loss=1.0919, LR=0.000100
[2025-08-10 17:45:47,338][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044100] [Batch 03488/03692] [00:30:30/00:01:47, 0.525s/it]: train_loss_raw=1.0410, running_loss=1.0911, LR=0.000100
[2025-08-10 17:45:53,477][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044112] [Batch 03500/03692] [00:30:36/00:01:40, 0.525s/it]: train_loss_raw=0.9823, running_loss=1.0869, LR=0.000100
[2025-08-10 17:45:59,711][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044124] [Batch 03512/03692] [00:30:42/00:01:34, 0.525s/it]: train_loss_raw=0.9705, running_loss=1.0855, LR=0.000100
[2025-08-10 17:46:05,813][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044136] [Batch 03524/03692] [00:30:48/00:01:28, 0.525s/it]: train_loss_raw=1.1487, running_loss=1.0825, LR=0.000100
[2025-08-10 17:46:11,828][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044148] [Batch 03536/03692] [00:30:54/00:01:21, 0.524s/it]: train_loss_raw=1.0336, running_loss=1.0823, LR=0.000100
[2025-08-10 17:46:17,842][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044160] [Batch 03548/03692] [00:31:00/00:01:15, 0.524s/it]: train_loss_raw=1.0286, running_loss=1.0820, LR=0.000100
[2025-08-10 17:46:23,909][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044172] [Batch 03560/03692] [00:31:06/00:01:09, 0.524s/it]: train_loss_raw=0.9427, running_loss=1.0787, LR=0.000100
[2025-08-10 17:46:29,954][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044184] [Batch 03572/03692] [00:31:12/00:01:02, 0.524s/it]: train_loss_raw=1.1602, running_loss=1.0829, LR=0.000100
[2025-08-10 17:46:36,033][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044196] [Batch 03584/03692] [00:31:18/00:00:56, 0.524s/it]: train_loss_raw=1.0124, running_loss=1.0792, LR=0.000100
[2025-08-10 17:46:42,264][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044208] [Batch 03596/03692] [00:31:24/00:00:50, 0.524s/it]: train_loss_raw=1.1634, running_loss=1.0807, LR=0.000100
[2025-08-10 17:46:48,379][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044220] [Batch 03608/03692] [00:31:31/00:00:44, 0.524s/it]: train_loss_raw=1.0882, running_loss=1.0779, LR=0.000100
[2025-08-10 17:46:54,384][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044232] [Batch 03620/03692] [00:31:37/00:00:37, 0.524s/it]: train_loss_raw=1.1578, running_loss=1.0808, LR=0.000100
[2025-08-10 17:47:00,731][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044244] [Batch 03632/03692] [00:31:43/00:00:31, 0.524s/it]: train_loss_raw=1.0652, running_loss=1.0792, LR=0.000100
[2025-08-10 17:47:07,323][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044256] [Batch 03644/03692] [00:31:50/00:00:25, 0.524s/it]: train_loss_raw=1.0891, running_loss=1.0774, LR=0.000100
[2025-08-10 17:47:13,818][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044268] [Batch 03656/03692] [00:31:56/00:00:18, 0.524s/it]: train_loss_raw=0.9795, running_loss=1.0751, LR=0.000100
[2025-08-10 17:47:20,426][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044280] [Batch 03668/03692] [00:32:03/00:00:12, 0.524s/it]: train_loss_raw=0.9701, running_loss=1.0723, LR=0.000100
[2025-08-10 17:47:27,026][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044292] [Batch 03680/03692] [00:32:09/00:00:06, 0.524s/it]: train_loss_raw=1.0075, running_loss=1.0683, LR=0.000100
[2025-08-10 17:48:04,203][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044304] [Batch 03692/03692] [00:32:46/00:00:00, 0.533s/it]: train_loss_raw=1.1031, running_loss=1.0631, LR=0.000100
[2025-08-10 17:48:09,520][__main__][INFO] - [VALIDATION] [Epoch 11/29] Starting validation.
[2025-08-10 17:48:42,863][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 044305] [Batch 00011/00025] [00:00:33/00:00:36, 2.779s/it]
[2025-08-10 17:49:00,308][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 044305] [Batch 00023/00025] [00:00:50/00:00:02, 2.116s/it]
[2025-08-10 17:49:01,398][__main__][INFO] - [VALIDATION] [Epoch 11/29] train_loss=1.06314, valid_loss=1.07345
[2025-08-10 17:49:01,398][__main__][INFO] - [VALIDATION] [Epoch 11/29] Metrics:
[2025-08-10 17:49:01,398][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_er      0.468
[2025-08-10 17:49:01,398][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_prec    0.268
[2025-08-10 17:49:01,398][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_recall  0.277
[2025-08-10 17:49:01,398][__main__][INFO] - [VALIDATION] [Epoch 11/29] - pep_recall 0.240
[2025-08-10 17:49:01,402][__main__][INFO] - [TRAIN] [Epoch 11/29] Epoch complete, total time 06:53:00, remaining time 10:19:30, 00:34:25 per epoch
[2025-08-10 17:49:07,967][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044316] [Batch 00012/03692] [00:00:06/00:32:14, 0.526s/it]: train_loss_raw=1.0219, running_loss=1.0290, LR=0.000100
[2025-08-10 17:49:14,464][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044328] [Batch 00024/03692] [00:00:12/00:32:37, 0.534s/it]: train_loss_raw=1.0185, running_loss=1.0352, LR=0.000100
[2025-08-10 17:49:21,017][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044340] [Batch 00036/03692] [00:00:19/00:32:46, 0.538s/it]: train_loss_raw=0.9794, running_loss=1.0311, LR=0.000100
[2025-08-10 17:49:27,538][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044352] [Batch 00048/03692] [00:00:25/00:32:44, 0.539s/it]: train_loss_raw=0.9658, running_loss=1.0302, LR=0.000100
[2025-08-10 17:49:34,009][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044364] [Batch 00060/03692] [00:00:32/00:32:38, 0.539s/it]: train_loss_raw=1.0551, running_loss=1.0348, LR=0.000100
[2025-08-10 17:49:40,586][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044376] [Batch 00072/03692] [00:00:38/00:32:37, 0.541s/it]: train_loss_raw=0.9727, running_loss=1.0343, LR=0.000100
[2025-08-10 17:49:47,036][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044388] [Batch 00084/03692] [00:00:45/00:32:29, 0.540s/it]: train_loss_raw=1.1168, running_loss=1.0383, LR=0.000100
[2025-08-10 17:49:53,526][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044400] [Batch 00096/03692] [00:00:51/00:32:22, 0.540s/it]: train_loss_raw=1.0904, running_loss=1.0417, LR=0.000100
[2025-08-10 17:49:59,914][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044412] [Batch 00108/03692] [00:00:58/00:32:13, 0.539s/it]: train_loss_raw=1.1110, running_loss=1.0440, LR=0.000100
[2025-08-10 17:50:06,393][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044424] [Batch 00120/03692] [00:01:04/00:32:06, 0.539s/it]: train_loss_raw=1.0414, running_loss=1.0461, LR=0.000100
[2025-08-10 17:50:12,986][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044436] [Batch 00132/03692] [00:01:11/00:32:03, 0.540s/it]: train_loss_raw=1.1413, running_loss=1.0475, LR=0.000100
[2025-08-10 17:50:19,467][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044448] [Batch 00144/03692] [00:01:17/00:31:57, 0.540s/it]: train_loss_raw=1.0370, running_loss=1.0492, LR=0.000100
[2025-08-10 17:50:25,829][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044460] [Batch 00156/03692] [00:01:24/00:31:47, 0.540s/it]: train_loss_raw=1.0911, running_loss=1.0484, LR=0.000100
[2025-08-10 17:50:32,274][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044472] [Batch 00168/03692] [00:01:30/00:31:40, 0.539s/it]: train_loss_raw=1.0680, running_loss=1.0460, LR=0.000100
[2025-08-10 17:50:38,618][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044484] [Batch 00180/03692] [00:01:36/00:31:31, 0.539s/it]: train_loss_raw=0.9460, running_loss=1.0457, LR=0.000100
[2025-08-10 17:50:44,882][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044496] [Batch 00192/03692] [00:01:43/00:31:21, 0.538s/it]: train_loss_raw=1.0078, running_loss=1.0418, LR=0.000100
[2025-08-10 17:50:51,230][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044508] [Batch 00204/03692] [00:01:49/00:31:13, 0.537s/it]: train_loss_raw=0.9587, running_loss=1.0388, LR=0.000100
[2025-08-10 17:50:57,699][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044520] [Batch 00216/03692] [00:01:56/00:31:07, 0.537s/it]: train_loss_raw=0.9560, running_loss=1.0352, LR=0.000100
[2025-08-10 17:51:04,136][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044532] [Batch 00228/03692] [00:02:02/00:31:00, 0.537s/it]: train_loss_raw=1.0606, running_loss=1.0365, LR=0.000100
[2025-08-10 17:51:10,526][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044544] [Batch 00240/03692] [00:02:08/00:30:53, 0.537s/it]: train_loss_raw=1.1184, running_loss=1.0339, LR=0.000100
[2025-08-10 17:51:16,935][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044556] [Batch 00252/03692] [00:02:15/00:30:46, 0.537s/it]: train_loss_raw=1.1248, running_loss=1.0306, LR=0.000100
[2025-08-10 17:51:23,469][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044568] [Batch 00264/03692] [00:02:21/00:30:41, 0.537s/it]: train_loss_raw=1.1021, running_loss=1.0322, LR=0.000100
[2025-08-10 17:51:29,968][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044580] [Batch 00276/03692] [00:02:28/00:30:35, 0.537s/it]: train_loss_raw=1.1583, running_loss=1.0348, LR=0.000100
[2025-08-10 17:51:36,549][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044592] [Batch 00288/03692] [00:02:34/00:30:30, 0.538s/it]: train_loss_raw=0.9828, running_loss=1.0334, LR=0.000100
[2025-08-10 17:51:43,017][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044604] [Batch 00300/03692] [00:02:41/00:30:24, 0.538s/it]: train_loss_raw=1.0956, running_loss=1.0375, LR=0.000100
[2025-08-10 17:51:49,661][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044616] [Batch 00312/03692] [00:02:48/00:30:20, 0.538s/it]: train_loss_raw=1.0086, running_loss=1.0391, LR=0.000100
[2025-08-10 17:51:56,210][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044628] [Batch 00324/03692] [00:02:54/00:30:14, 0.539s/it]: train_loss_raw=0.9551, running_loss=1.0371, LR=0.000100
[2025-08-10 17:52:02,471][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044640] [Batch 00336/03692] [00:03:00/00:30:05, 0.538s/it]: train_loss_raw=1.0130, running_loss=1.0323, LR=0.000100
[2025-08-10 17:52:08,918][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044652] [Batch 00348/03692] [00:03:07/00:29:59, 0.538s/it]: train_loss_raw=1.0794, running_loss=1.0357, LR=0.000100
[2025-08-10 17:52:15,359][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044664] [Batch 00360/03692] [00:03:13/00:29:52, 0.538s/it]: train_loss_raw=1.0933, running_loss=1.0350, LR=0.000100
[2025-08-10 17:52:21,846][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044676] [Batch 00372/03692] [00:03:20/00:29:46, 0.538s/it]: train_loss_raw=1.1232, running_loss=1.0385, LR=0.000100
[2025-08-10 17:52:28,430][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044688] [Batch 00384/03692] [00:03:26/00:29:41, 0.538s/it]: train_loss_raw=1.0184, running_loss=1.0399, LR=0.000100
[2025-08-10 17:52:34,847][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044700] [Batch 00396/03692] [00:03:33/00:29:34, 0.538s/it]: train_loss_raw=1.0897, running_loss=1.0367, LR=0.000100
[2025-08-10 17:52:41,315][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044712] [Batch 00408/03692] [00:03:39/00:29:28, 0.538s/it]: train_loss_raw=1.0203, running_loss=1.0341, LR=0.000100
[2025-08-10 17:52:47,882][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044724] [Batch 00420/03692] [00:03:46/00:29:22, 0.539s/it]: train_loss_raw=1.1516, running_loss=1.0379, LR=0.000100
[2025-08-10 17:52:54,315][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044736] [Batch 00432/03692] [00:03:52/00:29:15, 0.539s/it]: train_loss_raw=1.0034, running_loss=1.0394, LR=0.000100
[2025-08-10 17:53:00,599][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044748] [Batch 00444/03692] [00:03:58/00:29:07, 0.538s/it]: train_loss_raw=0.9701, running_loss=1.0388, LR=0.000100
[2025-08-10 17:53:07,187][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044760] [Batch 00456/03692] [00:04:05/00:29:02, 0.538s/it]: train_loss_raw=1.1922, running_loss=1.0383, LR=0.000100
[2025-08-10 17:53:13,720][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044772] [Batch 00468/03692] [00:04:12/00:28:56, 0.539s/it]: train_loss_raw=1.0658, running_loss=1.0416, LR=0.000100
[2025-08-10 17:53:20,056][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044784] [Batch 00480/03692] [00:04:18/00:28:49, 0.538s/it]: train_loss_raw=0.9579, running_loss=1.0432, LR=0.000100
[2025-08-10 17:53:26,585][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044796] [Batch 00492/03692] [00:04:24/00:28:43, 0.538s/it]: train_loss_raw=0.9607, running_loss=1.0443, LR=0.000100
[2025-08-10 17:53:33,182][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044808] [Batch 00504/03692] [00:04:31/00:28:37, 0.539s/it]: train_loss_raw=0.9970, running_loss=1.0439, LR=0.000100
[2025-08-10 17:53:39,707][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044820] [Batch 00516/03692] [00:04:38/00:28:31, 0.539s/it]: train_loss_raw=0.8876, running_loss=1.0433, LR=0.000100
[2025-08-10 17:53:46,326][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044832] [Batch 00528/03692] [00:04:44/00:28:25, 0.539s/it]: train_loss_raw=1.0351, running_loss=1.0437, LR=0.000100
[2025-08-10 17:53:52,944][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044844] [Batch 00540/03692] [00:04:51/00:28:20, 0.539s/it]: train_loss_raw=1.0872, running_loss=1.0428, LR=0.000100
[2025-08-10 17:53:59,576][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044856] [Batch 00552/03692] [00:04:57/00:28:14, 0.540s/it]: train_loss_raw=1.1035, running_loss=1.0428, LR=0.000100
[2025-08-10 17:54:05,820][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044868] [Batch 00564/03692] [00:05:04/00:28:06, 0.539s/it]: train_loss_raw=0.9998, running_loss=1.0399, LR=0.000100
[2025-08-10 17:54:11,922][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044880] [Batch 00576/03692] [00:05:10/00:27:58, 0.539s/it]: train_loss_raw=1.0033, running_loss=1.0364, LR=0.000100
[2025-08-10 17:54:18,281][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044892] [Batch 00588/03692] [00:05:16/00:27:51, 0.538s/it]: train_loss_raw=1.1076, running_loss=1.0399, LR=0.000100
[2025-08-10 17:54:24,542][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044904] [Batch 00600/03692] [00:05:22/00:27:43, 0.538s/it]: train_loss_raw=1.0274, running_loss=1.0355, LR=0.000100
[2025-08-10 17:54:30,719][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044916] [Batch 00612/03692] [00:05:29/00:27:36, 0.538s/it]: train_loss_raw=0.9289, running_loss=1.0364, LR=0.000100
[2025-08-10 17:54:37,166][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044928] [Batch 00624/03692] [00:05:35/00:27:29, 0.538s/it]: train_loss_raw=1.0250, running_loss=1.0342, LR=0.000100
[2025-08-10 17:54:43,590][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044940] [Batch 00636/03692] [00:05:41/00:27:22, 0.538s/it]: train_loss_raw=1.0238, running_loss=1.0351, LR=0.000100
[2025-08-10 17:54:50,013][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044952] [Batch 00648/03692] [00:05:48/00:27:16, 0.538s/it]: train_loss_raw=0.9393, running_loss=1.0339, LR=0.000100
[2025-08-10 17:54:56,256][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044964] [Batch 00660/03692] [00:05:54/00:27:09, 0.537s/it]: train_loss_raw=1.0223, running_loss=1.0365, LR=0.000100
[2025-08-10 17:55:02,537][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044976] [Batch 00672/03692] [00:06:00/00:27:01, 0.537s/it]: train_loss_raw=0.9667, running_loss=1.0338, LR=0.000100
[2025-08-10 17:55:08,575][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044988] [Batch 00684/03692] [00:06:06/00:26:53, 0.536s/it]: train_loss_raw=1.0303, running_loss=1.0319, LR=0.000100
[2025-08-10 17:55:14,650][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045000] [Batch 00696/03692] [00:06:12/00:26:45, 0.536s/it]: train_loss_raw=1.1004, running_loss=1.0292, LR=0.000100
[2025-08-10 17:55:21,151][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045012] [Batch 00708/03692] [00:06:19/00:26:39, 0.536s/it]: train_loss_raw=1.0345, running_loss=1.0313, LR=0.000100
[2025-08-10 17:55:27,540][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045024] [Batch 00720/03692] [00:06:25/00:26:32, 0.536s/it]: train_loss_raw=0.9829, running_loss=1.0369, LR=0.000100
[2025-08-10 17:55:33,805][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045036] [Batch 00732/03692] [00:06:32/00:26:25, 0.536s/it]: train_loss_raw=1.0114, running_loss=1.0378, LR=0.000100
[2025-08-10 17:55:40,340][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045048] [Batch 00744/03692] [00:06:38/00:26:19, 0.536s/it]: train_loss_raw=1.0300, running_loss=1.0327, LR=0.000100
[2025-08-10 17:55:46,794][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045060] [Batch 00756/03692] [00:06:45/00:26:13, 0.536s/it]: train_loss_raw=1.1336, running_loss=1.0309, LR=0.000100
[2025-08-10 17:55:53,313][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045072] [Batch 00768/03692] [00:06:51/00:26:07, 0.536s/it]: train_loss_raw=1.0677, running_loss=1.0330, LR=0.000100
[2025-08-10 17:55:59,814][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045084] [Batch 00780/03692] [00:06:58/00:26:01, 0.536s/it]: train_loss_raw=1.0830, running_loss=1.0327, LR=0.000100
[2025-08-10 17:56:06,300][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045096] [Batch 00792/03692] [00:07:04/00:25:54, 0.536s/it]: train_loss_raw=0.9829, running_loss=1.0350, LR=0.000100
[2025-08-10 17:56:12,720][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045108] [Batch 00804/03692] [00:07:11/00:25:48, 0.536s/it]: train_loss_raw=0.9612, running_loss=1.0350, LR=0.000100
[2025-08-10 17:56:19,103][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045120] [Batch 00816/03692] [00:07:17/00:25:41, 0.536s/it]: train_loss_raw=0.9523, running_loss=1.0327, LR=0.000100
[2025-08-10 17:56:25,355][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045132] [Batch 00828/03692] [00:07:23/00:25:34, 0.536s/it]: train_loss_raw=1.0899, running_loss=1.0329, LR=0.000100
[2025-08-10 17:56:31,750][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045144] [Batch 00840/03692] [00:07:30/00:25:28, 0.536s/it]: train_loss_raw=1.0092, running_loss=1.0266, LR=0.000100
[2025-08-10 17:56:38,166][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045156] [Batch 00852/03692] [00:07:36/00:25:21, 0.536s/it]: train_loss_raw=1.0047, running_loss=1.0292, LR=0.000100
[2025-08-10 17:56:44,677][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045168] [Batch 00864/03692] [00:07:43/00:25:15, 0.536s/it]: train_loss_raw=1.1450, running_loss=1.0327, LR=0.000100
[2025-08-10 17:56:51,225][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045180] [Batch 00876/03692] [00:07:49/00:25:09, 0.536s/it]: train_loss_raw=1.0192, running_loss=1.0286, LR=0.000100
[2025-08-10 17:56:57,574][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045192] [Batch 00888/03692] [00:07:55/00:25:02, 0.536s/it]: train_loss_raw=1.0638, running_loss=1.0302, LR=0.000100
[2025-08-10 17:57:03,842][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045204] [Batch 00900/03692] [00:08:02/00:24:55, 0.536s/it]: train_loss_raw=0.9371, running_loss=1.0314, LR=0.000100
[2025-08-10 17:57:10,297][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045216] [Batch 00912/03692] [00:08:08/00:24:49, 0.536s/it]: train_loss_raw=1.0652, running_loss=1.0285, LR=0.000100
[2025-08-10 17:57:16,711][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045228] [Batch 00924/03692] [00:08:15/00:24:43, 0.536s/it]: train_loss_raw=1.0720, running_loss=1.0300, LR=0.000100
[2025-08-10 17:57:23,081][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045240] [Batch 00936/03692] [00:08:21/00:24:36, 0.536s/it]: train_loss_raw=1.0395, running_loss=1.0303, LR=0.000100
[2025-08-10 17:57:29,545][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045252] [Batch 00948/03692] [00:08:27/00:24:30, 0.536s/it]: train_loss_raw=1.0546, running_loss=1.0311, LR=0.000100
[2025-08-10 17:57:36,101][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045264] [Batch 00960/03692] [00:08:34/00:24:24, 0.536s/it]: train_loss_raw=1.0083, running_loss=1.0270, LR=0.000100
[2025-08-10 17:57:42,575][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045276] [Batch 00972/03692] [00:08:40/00:24:17, 0.536s/it]: train_loss_raw=1.0845, running_loss=1.0267, LR=0.000100
[2025-08-10 17:57:48,970][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045288] [Batch 00984/03692] [00:08:47/00:24:11, 0.536s/it]: train_loss_raw=1.0268, running_loss=1.0284, LR=0.000100
[2025-08-10 17:57:55,384][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045300] [Batch 00996/03692] [00:08:53/00:24:04, 0.536s/it]: train_loss_raw=0.9741, running_loss=1.0253, LR=0.000100
[2025-08-10 17:58:01,857][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045312] [Batch 01008/03692] [00:09:00/00:23:58, 0.536s/it]: train_loss_raw=0.9204, running_loss=1.0224, LR=0.000100
[2025-08-10 17:58:08,281][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045324] [Batch 01020/03692] [00:09:06/00:23:51, 0.536s/it]: train_loss_raw=1.0928, running_loss=1.0237, LR=0.000100
[2025-08-10 17:58:14,695][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045336] [Batch 01032/03692] [00:09:13/00:23:45, 0.536s/it]: train_loss_raw=0.9431, running_loss=1.0226, LR=0.000100
[2025-08-10 17:58:21,225][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045348] [Batch 01044/03692] [00:09:19/00:23:39, 0.536s/it]: train_loss_raw=1.0509, running_loss=1.0223, LR=0.000100
[2025-08-10 17:58:27,667][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045360] [Batch 01056/03692] [00:09:26/00:23:32, 0.536s/it]: train_loss_raw=1.0278, running_loss=1.0221, LR=0.000100
[2025-08-10 17:58:34,045][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045372] [Batch 01068/03692] [00:09:32/00:23:26, 0.536s/it]: train_loss_raw=1.0872, running_loss=1.0196, LR=0.000100
[2025-08-10 17:58:40,464][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045384] [Batch 01080/03692] [00:09:38/00:23:19, 0.536s/it]: train_loss_raw=0.9838, running_loss=1.0166, LR=0.000100
[2025-08-10 17:58:46,790][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045396] [Batch 01092/03692] [00:09:45/00:23:13, 0.536s/it]: train_loss_raw=1.0145, running_loss=1.0175, LR=0.000100
[2025-08-10 17:58:53,129][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045408] [Batch 01104/03692] [00:09:51/00:23:06, 0.536s/it]: train_loss_raw=1.0695, running_loss=1.0178, LR=0.000100
[2025-08-10 17:58:59,545][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045420] [Batch 01116/03692] [00:09:57/00:23:00, 0.536s/it]: train_loss_raw=1.0029, running_loss=1.0196, LR=0.000100
[2025-08-10 17:59:05,940][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045432] [Batch 01128/03692] [00:10:04/00:22:53, 0.536s/it]: train_loss_raw=0.8938, running_loss=1.0191, LR=0.000100
[2025-08-10 17:59:12,262][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045444] [Batch 01140/03692] [00:10:10/00:22:46, 0.536s/it]: train_loss_raw=1.0573, running_loss=1.0172, LR=0.000100
[2025-08-10 17:59:18,519][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045456] [Batch 01152/03692] [00:10:16/00:22:40, 0.535s/it]: train_loss_raw=0.9121, running_loss=1.0174, LR=0.000100
[2025-08-10 17:59:24,901][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045468] [Batch 01164/03692] [00:10:23/00:22:33, 0.535s/it]: train_loss_raw=1.0501, running_loss=1.0168, LR=0.000100
[2025-08-10 17:59:31,277][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045480] [Batch 01176/03692] [00:10:29/00:22:27, 0.535s/it]: train_loss_raw=1.1264, running_loss=1.0244, LR=0.000100
[2025-08-10 17:59:37,501][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045492] [Batch 01188/03692] [00:10:35/00:22:20, 0.535s/it]: train_loss_raw=0.9914, running_loss=1.0206, LR=0.000100
[2025-08-10 17:59:43,748][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045504] [Batch 01200/03692] [00:10:42/00:22:13, 0.535s/it]: train_loss_raw=1.1250, running_loss=1.0210, LR=0.000100
[2025-08-10 17:59:50,187][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045516] [Batch 01212/03692] [00:10:48/00:22:07, 0.535s/it]: train_loss_raw=1.0476, running_loss=1.0241, LR=0.000100
[2025-08-10 17:59:56,680][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045528] [Batch 01224/03692] [00:10:55/00:22:00, 0.535s/it]: train_loss_raw=1.0060, running_loss=1.0243, LR=0.000100
[2025-08-10 18:00:03,184][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045540] [Batch 01236/03692] [00:11:01/00:21:54, 0.535s/it]: train_loss_raw=1.1209, running_loss=1.0273, LR=0.000100
[2025-08-10 18:00:09,612][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045552] [Batch 01248/03692] [00:11:07/00:21:48, 0.535s/it]: train_loss_raw=0.9681, running_loss=1.0295, LR=0.000100
[2025-08-10 18:00:16,031][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045564] [Batch 01260/03692] [00:11:14/00:21:41, 0.535s/it]: train_loss_raw=1.1500, running_loss=1.0365, LR=0.000100
[2025-08-10 18:00:22,450][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045576] [Batch 01272/03692] [00:11:20/00:21:35, 0.535s/it]: train_loss_raw=1.0754, running_loss=1.0321, LR=0.000100
[2025-08-10 18:00:28,835][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045588] [Batch 01284/03692] [00:11:27/00:21:28, 0.535s/it]: train_loss_raw=1.1303, running_loss=1.0334, LR=0.000100
[2025-08-10 18:00:35,253][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045600] [Batch 01296/03692] [00:11:33/00:21:22, 0.535s/it]: train_loss_raw=1.0195, running_loss=1.0338, LR=0.000100
[2025-08-10 18:00:41,713][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045612] [Batch 01308/03692] [00:11:40/00:21:15, 0.535s/it]: train_loss_raw=0.9543, running_loss=1.0343, LR=0.000100
[2025-08-10 18:00:48,156][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045624] [Batch 01320/03692] [00:11:46/00:21:09, 0.535s/it]: train_loss_raw=0.9542, running_loss=1.0348, LR=0.000100
[2025-08-10 18:00:54,558][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045636] [Batch 01332/03692] [00:11:52/00:21:03, 0.535s/it]: train_loss_raw=1.0582, running_loss=1.0356, LR=0.000100
[2025-08-10 18:01:00,942][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045648] [Batch 01344/03692] [00:11:59/00:20:56, 0.535s/it]: train_loss_raw=0.9190, running_loss=1.0335, LR=0.000100
[2025-08-10 18:01:07,441][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045660] [Batch 01356/03692] [00:12:05/00:20:50, 0.535s/it]: train_loss_raw=1.0357, running_loss=1.0306, LR=0.000100
[2025-08-10 18:01:14,064][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045672] [Batch 01368/03692] [00:12:12/00:20:44, 0.535s/it]: train_loss_raw=1.0200, running_loss=1.0268, LR=0.000100
[2025-08-10 18:01:20,609][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045684] [Batch 01380/03692] [00:12:18/00:20:38, 0.535s/it]: train_loss_raw=0.9648, running_loss=1.0249, LR=0.000100
[2025-08-10 18:01:27,242][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045696] [Batch 01392/03692] [00:12:25/00:20:31, 0.536s/it]: train_loss_raw=1.0080, running_loss=1.0229, LR=0.000100
[2025-08-10 18:01:33,348][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045708] [Batch 01404/03692] [00:12:31/00:20:24, 0.535s/it]: train_loss_raw=1.0542, running_loss=1.0237, LR=0.000100
[2025-08-10 18:01:39,872][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045720] [Batch 01416/03692] [00:12:38/00:20:18, 0.535s/it]: train_loss_raw=0.9514, running_loss=1.0268, LR=0.000100
[2025-08-10 18:01:46,476][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045732] [Batch 01428/03692] [00:12:44/00:20:12, 0.536s/it]: train_loss_raw=0.9603, running_loss=1.0267, LR=0.000100
[2025-08-10 18:01:52,977][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045744] [Batch 01440/03692] [00:12:51/00:20:06, 0.536s/it]: train_loss_raw=1.0069, running_loss=1.0285, LR=0.000100
[2025-08-10 18:01:59,405][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045756] [Batch 01452/03692] [00:12:57/00:19:59, 0.536s/it]: train_loss_raw=1.1034, running_loss=1.0293, LR=0.000100
[2025-08-10 18:02:05,837][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045768] [Batch 01464/03692] [00:13:04/00:19:53, 0.536s/it]: train_loss_raw=0.9639, running_loss=1.0298, LR=0.000100
[2025-08-10 18:02:12,283][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045780] [Batch 01476/03692] [00:13:10/00:19:47, 0.536s/it]: train_loss_raw=0.9922, running_loss=1.0279, LR=0.000100
[2025-08-10 18:02:18,741][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045792] [Batch 01488/03692] [00:13:17/00:19:40, 0.536s/it]: train_loss_raw=1.1100, running_loss=1.0301, LR=0.000100
[2025-08-10 18:02:25,374][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045804] [Batch 01500/03692] [00:13:23/00:19:34, 0.536s/it]: train_loss_raw=1.1773, running_loss=1.0318, LR=0.000100
[2025-08-10 18:02:31,987][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045816] [Batch 01512/03692] [00:13:30/00:19:28, 0.536s/it]: train_loss_raw=1.0365, running_loss=1.0315, LR=0.000100
[2025-08-10 18:02:38,521][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045828] [Batch 01524/03692] [00:13:36/00:19:22, 0.536s/it]: train_loss_raw=1.0691, running_loss=1.0294, LR=0.000100
[2025-08-10 18:02:45,023][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045840] [Batch 01536/03692] [00:13:43/00:19:15, 0.536s/it]: train_loss_raw=1.0235, running_loss=1.0284, LR=0.000100
[2025-08-10 18:02:51,412][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045852] [Batch 01548/03692] [00:13:49/00:19:09, 0.536s/it]: train_loss_raw=0.9452, running_loss=1.0262, LR=0.000100
[2025-08-10 18:02:57,813][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045864] [Batch 01560/03692] [00:13:56/00:19:02, 0.536s/it]: train_loss_raw=0.9634, running_loss=1.0250, LR=0.000100
[2025-08-10 18:03:04,239][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045876] [Batch 01572/03692] [00:14:02/00:18:56, 0.536s/it]: train_loss_raw=1.0718, running_loss=1.0267, LR=0.000100
[2025-08-10 18:03:10,681][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045888] [Batch 01584/03692] [00:14:09/00:18:49, 0.536s/it]: train_loss_raw=1.0646, running_loss=1.0308, LR=0.000100
[2025-08-10 18:03:17,061][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045900] [Batch 01596/03692] [00:14:15/00:18:43, 0.536s/it]: train_loss_raw=1.0131, running_loss=1.0298, LR=0.000100
[2025-08-10 18:03:23,548][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045912] [Batch 01608/03692] [00:14:21/00:18:37, 0.536s/it]: train_loss_raw=0.9965, running_loss=1.0252, LR=0.000100
[2025-08-10 18:03:30,002][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045924] [Batch 01620/03692] [00:14:28/00:18:30, 0.536s/it]: train_loss_raw=1.0432, running_loss=1.0261, LR=0.000100
[2025-08-10 18:03:36,453][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045936] [Batch 01632/03692] [00:14:34/00:18:24, 0.536s/it]: train_loss_raw=1.0414, running_loss=1.0220, LR=0.000100
[2025-08-10 18:03:42,804][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045948] [Batch 01644/03692] [00:14:41/00:18:17, 0.536s/it]: train_loss_raw=1.1154, running_loss=1.0202, LR=0.000100
[2025-08-10 18:03:49,181][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045960] [Batch 01656/03692] [00:14:47/00:18:11, 0.536s/it]: train_loss_raw=1.0409, running_loss=1.0234, LR=0.000100
[2025-08-10 18:03:55,631][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045972] [Batch 01668/03692] [00:14:53/00:18:04, 0.536s/it]: train_loss_raw=1.0566, running_loss=1.0199, LR=0.000100
[2025-08-10 18:04:01,973][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045984] [Batch 01680/03692] [00:15:00/00:17:58, 0.536s/it]: train_loss_raw=1.0724, running_loss=1.0200, LR=0.000100
[2025-08-10 18:04:08,231][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045996] [Batch 01692/03692] [00:15:06/00:17:51, 0.536s/it]: train_loss_raw=1.0343, running_loss=1.0225, LR=0.000100
[2025-08-10 18:04:19,373][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046008] [Batch 01704/03692] [00:15:17/00:17:50, 0.539s/it]: train_loss_raw=0.9718, running_loss=1.0254, LR=0.000100
[2025-08-10 18:04:25,898][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046020] [Batch 01716/03692] [00:15:24/00:17:44, 0.539s/it]: train_loss_raw=1.0899, running_loss=1.0264, LR=0.000100
[2025-08-10 18:04:32,357][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046032] [Batch 01728/03692] [00:15:30/00:17:37, 0.539s/it]: train_loss_raw=1.0340, running_loss=1.0306, LR=0.000100
[2025-08-10 18:04:38,725][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046044] [Batch 01740/03692] [00:15:37/00:17:31, 0.539s/it]: train_loss_raw=1.1046, running_loss=1.0284, LR=0.000100
[2025-08-10 18:04:45,189][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046056] [Batch 01752/03692] [00:15:43/00:17:24, 0.539s/it]: train_loss_raw=0.9216, running_loss=1.0252, LR=0.000100
[2025-08-10 18:04:51,580][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046068] [Batch 01764/03692] [00:15:49/00:17:18, 0.539s/it]: train_loss_raw=0.9775, running_loss=1.0235, LR=0.000100
[2025-08-10 18:04:58,001][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046080] [Batch 01776/03692] [00:15:56/00:17:11, 0.538s/it]: train_loss_raw=1.0079, running_loss=1.0262, LR=0.000100
[2025-08-10 18:05:04,495][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046092] [Batch 01788/03692] [00:16:02/00:17:05, 0.538s/it]: train_loss_raw=1.0089, running_loss=1.0279, LR=0.000100
[2025-08-10 18:05:11,062][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046104] [Batch 01800/03692] [00:16:09/00:16:58, 0.539s/it]: train_loss_raw=1.0347, running_loss=1.0264, LR=0.000100
[2025-08-10 18:05:17,424][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046116] [Batch 01812/03692] [00:16:15/00:16:52, 0.539s/it]: train_loss_raw=1.1967, running_loss=1.0293, LR=0.000100
[2025-08-10 18:05:23,982][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046128] [Batch 01824/03692] [00:16:22/00:16:46, 0.539s/it]: train_loss_raw=0.8546, running_loss=1.0214, LR=0.000100
[2025-08-10 18:05:30,603][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046140] [Batch 01836/03692] [00:16:28/00:16:39, 0.539s/it]: train_loss_raw=1.0390, running_loss=1.0218, LR=0.000100
[2025-08-10 18:05:37,087][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046152] [Batch 01848/03692] [00:16:35/00:16:33, 0.539s/it]: train_loss_raw=1.0670, running_loss=1.0234, LR=0.000100
[2025-08-10 18:05:43,518][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046164] [Batch 01860/03692] [00:16:41/00:16:26, 0.539s/it]: train_loss_raw=1.0041, running_loss=1.0246, LR=0.000100
[2025-08-10 18:05:49,986][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046176] [Batch 01872/03692] [00:16:48/00:16:20, 0.539s/it]: train_loss_raw=1.0164, running_loss=1.0240, LR=0.000100
[2025-08-10 18:05:56,403][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046188] [Batch 01884/03692] [00:16:54/00:16:13, 0.539s/it]: train_loss_raw=1.0025, running_loss=1.0230, LR=0.000100
[2025-08-10 18:06:02,755][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046200] [Batch 01896/03692] [00:17:01/00:16:07, 0.539s/it]: train_loss_raw=1.0019, running_loss=1.0188, LR=0.000100
[2025-08-10 18:06:09,160][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046212] [Batch 01908/03692] [00:17:07/00:16:00, 0.539s/it]: train_loss_raw=1.0162, running_loss=1.0210, LR=0.000100
[2025-08-10 18:06:15,572][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046224] [Batch 01920/03692] [00:17:13/00:15:54, 0.538s/it]: train_loss_raw=1.0424, running_loss=1.0197, LR=0.000100
[2025-08-10 18:06:21,999][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046236] [Batch 01932/03692] [00:17:20/00:15:47, 0.538s/it]: train_loss_raw=1.0631, running_loss=1.0208, LR=0.000100
[2025-08-10 18:06:28,416][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046248] [Batch 01944/03692] [00:17:26/00:15:41, 0.538s/it]: train_loss_raw=1.1343, running_loss=1.0172, LR=0.000100
[2025-08-10 18:06:34,664][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046260] [Batch 01956/03692] [00:17:33/00:15:34, 0.538s/it]: train_loss_raw=1.0553, running_loss=1.0200, LR=0.000100
[2025-08-10 18:06:40,975][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046272] [Batch 01968/03692] [00:17:39/00:15:27, 0.538s/it]: train_loss_raw=0.9793, running_loss=1.0240, LR=0.000100
[2025-08-10 18:06:47,273][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046284] [Batch 01980/03692] [00:17:45/00:15:21, 0.538s/it]: train_loss_raw=0.9499, running_loss=1.0228, LR=0.000100
[2025-08-10 18:06:53,665][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046296] [Batch 01992/03692] [00:17:52/00:15:14, 0.538s/it]: train_loss_raw=1.0033, running_loss=1.0240, LR=0.000100
[2025-08-10 18:07:00,106][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046308] [Batch 02004/03692] [00:17:58/00:15:08, 0.538s/it]: train_loss_raw=1.0862, running_loss=1.0222, LR=0.000100
[2025-08-10 18:07:06,497][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046320] [Batch 02016/03692] [00:18:04/00:15:01, 0.538s/it]: train_loss_raw=0.9185, running_loss=1.0184, LR=0.000100
[2025-08-10 18:07:12,961][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046332] [Batch 02028/03692] [00:18:11/00:14:55, 0.538s/it]: train_loss_raw=1.0179, running_loss=1.0157, LR=0.000100
[2025-08-10 18:07:19,559][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046344] [Batch 02040/03692] [00:18:17/00:14:49, 0.538s/it]: train_loss_raw=0.9735, running_loss=1.0170, LR=0.000100
[2025-08-10 18:07:25,998][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046356] [Batch 02052/03692] [00:18:24/00:14:42, 0.538s/it]: train_loss_raw=1.0424, running_loss=1.0194, LR=0.000100
[2025-08-10 18:07:32,291][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046368] [Batch 02064/03692] [00:18:30/00:14:36, 0.538s/it]: train_loss_raw=0.9785, running_loss=1.0204, LR=0.000100
[2025-08-10 18:07:38,822][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046380] [Batch 02076/03692] [00:18:37/00:14:29, 0.538s/it]: train_loss_raw=1.0334, running_loss=1.0209, LR=0.000100
[2025-08-10 18:07:45,346][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046392] [Batch 02088/03692] [00:18:43/00:14:23, 0.538s/it]: train_loss_raw=1.1322, running_loss=1.0239, LR=0.000100
[2025-08-10 18:07:51,761][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046404] [Batch 02100/03692] [00:18:50/00:14:16, 0.538s/it]: train_loss_raw=1.0781, running_loss=1.0227, LR=0.000100
[2025-08-10 18:07:58,187][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046416] [Batch 02112/03692] [00:18:56/00:14:10, 0.538s/it]: train_loss_raw=0.9496, running_loss=1.0203, LR=0.000100
[2025-08-10 18:08:04,671][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046428] [Batch 02124/03692] [00:19:03/00:14:03, 0.538s/it]: train_loss_raw=0.9734, running_loss=1.0209, LR=0.000100
[2025-08-10 18:08:11,031][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046440] [Batch 02136/03692] [00:19:09/00:13:57, 0.538s/it]: train_loss_raw=1.0816, running_loss=1.0163, LR=0.000100
[2025-08-10 18:08:17,372][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046452] [Batch 02148/03692] [00:19:15/00:13:50, 0.538s/it]: train_loss_raw=0.8781, running_loss=1.0161, LR=0.000100
[2025-08-10 18:08:23,796][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046464] [Batch 02160/03692] [00:19:22/00:13:44, 0.538s/it]: train_loss_raw=0.9963, running_loss=1.0146, LR=0.000100
[2025-08-10 18:08:30,102][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046476] [Batch 02172/03692] [00:19:28/00:13:37, 0.538s/it]: train_loss_raw=1.0271, running_loss=1.0087, LR=0.000100
[2025-08-10 18:08:36,459][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046488] [Batch 02184/03692] [00:19:34/00:13:31, 0.538s/it]: train_loss_raw=1.0391, running_loss=1.0141, LR=0.000100
[2025-08-10 18:08:42,959][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046500] [Batch 02196/03692] [00:19:41/00:13:24, 0.538s/it]: train_loss_raw=0.9914, running_loss=1.0161, LR=0.000100
[2025-08-10 18:08:49,220][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046512] [Batch 02208/03692] [00:19:47/00:13:18, 0.538s/it]: train_loss_raw=1.0803, running_loss=1.0164, LR=0.000100
[2025-08-10 18:08:55,599][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046524] [Batch 02220/03692] [00:19:53/00:13:11, 0.538s/it]: train_loss_raw=0.9174, running_loss=1.0151, LR=0.000100
[2025-08-10 18:09:01,949][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046536] [Batch 02232/03692] [00:20:00/00:13:05, 0.538s/it]: train_loss_raw=0.9761, running_loss=1.0150, LR=0.000100
[2025-08-10 18:09:08,326][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046548] [Batch 02244/03692] [00:20:06/00:12:58, 0.538s/it]: train_loss_raw=0.9064, running_loss=1.0143, LR=0.000100
[2025-08-10 18:09:14,731][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046560] [Batch 02256/03692] [00:20:13/00:12:52, 0.538s/it]: train_loss_raw=1.0660, running_loss=1.0168, LR=0.000100
[2025-08-10 18:09:21,209][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046572] [Batch 02268/03692] [00:20:19/00:12:45, 0.538s/it]: train_loss_raw=1.1653, running_loss=1.0197, LR=0.000100
[2025-08-10 18:09:27,638][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046584] [Batch 02280/03692] [00:20:25/00:12:39, 0.538s/it]: train_loss_raw=1.0039, running_loss=1.0182, LR=0.000100
[2025-08-10 18:09:34,101][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046596] [Batch 02292/03692] [00:20:32/00:12:32, 0.538s/it]: train_loss_raw=1.0192, running_loss=1.0177, LR=0.000100
[2025-08-10 18:09:40,476][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046608] [Batch 02304/03692] [00:20:38/00:12:26, 0.538s/it]: train_loss_raw=0.8590, running_loss=1.0161, LR=0.000100
[2025-08-10 18:09:47,080][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046620] [Batch 02316/03692] [00:20:45/00:12:19, 0.538s/it]: train_loss_raw=0.8826, running_loss=1.0130, LR=0.000100
[2025-08-10 18:09:53,586][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046632] [Batch 02328/03692] [00:20:51/00:12:13, 0.538s/it]: train_loss_raw=1.1166, running_loss=1.0144, LR=0.000100
[2025-08-10 18:10:00,162][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046644] [Batch 02340/03692] [00:20:58/00:12:07, 0.538s/it]: train_loss_raw=0.9973, running_loss=1.0158, LR=0.000100
[2025-08-10 18:10:06,622][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046656] [Batch 02352/03692] [00:21:04/00:12:00, 0.538s/it]: train_loss_raw=0.9394, running_loss=1.0166, LR=0.000100
[2025-08-10 18:10:13,115][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046668] [Batch 02364/03692] [00:21:11/00:11:54, 0.538s/it]: train_loss_raw=0.7691, running_loss=1.0148, LR=0.000100
[2025-08-10 18:10:19,661][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046680] [Batch 02376/03692] [00:21:18/00:11:47, 0.538s/it]: train_loss_raw=0.9406, running_loss=1.0160, LR=0.000100
[2025-08-10 18:10:26,178][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046692] [Batch 02388/03692] [00:21:24/00:11:41, 0.538s/it]: train_loss_raw=1.0001, running_loss=1.0109, LR=0.000100
[2025-08-10 18:10:32,810][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046704] [Batch 02400/03692] [00:21:31/00:11:35, 0.538s/it]: train_loss_raw=1.1023, running_loss=1.0127, LR=0.000100
[2025-08-10 18:10:39,393][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046716] [Batch 02412/03692] [00:21:37/00:11:28, 0.538s/it]: train_loss_raw=0.9970, running_loss=1.0149, LR=0.000100
[2025-08-10 18:10:45,938][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046728] [Batch 02424/03692] [00:21:44/00:11:22, 0.538s/it]: train_loss_raw=1.0363, running_loss=1.0140, LR=0.000100
[2025-08-10 18:10:52,556][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046740] [Batch 02436/03692] [00:21:50/00:11:15, 0.538s/it]: train_loss_raw=0.9853, running_loss=1.0118, LR=0.000100
[2025-08-10 18:10:59,103][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046752] [Batch 02448/03692] [00:21:57/00:11:09, 0.538s/it]: train_loss_raw=1.0212, running_loss=1.0137, LR=0.000100
[2025-08-10 18:11:05,630][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046764] [Batch 02460/03692] [00:22:03/00:11:03, 0.538s/it]: train_loss_raw=0.9216, running_loss=1.0131, LR=0.000100
[2025-08-10 18:11:12,135][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046776] [Batch 02472/03692] [00:22:10/00:10:56, 0.538s/it]: train_loss_raw=1.0232, running_loss=1.0140, LR=0.000100
[2025-08-10 18:11:18,626][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046788] [Batch 02484/03692] [00:22:16/00:10:50, 0.538s/it]: train_loss_raw=1.0016, running_loss=1.0134, LR=0.000100
[2025-08-10 18:11:25,188][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046800] [Batch 02496/03692] [00:22:23/00:10:43, 0.538s/it]: train_loss_raw=1.1137, running_loss=1.0136, LR=0.000100
[2025-08-10 18:11:31,754][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046812] [Batch 02508/03692] [00:22:30/00:10:37, 0.538s/it]: train_loss_raw=0.8605, running_loss=1.0155, LR=0.000100
[2025-08-10 18:11:38,255][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046824] [Batch 02520/03692] [00:22:36/00:10:30, 0.538s/it]: train_loss_raw=1.1198, running_loss=1.0158, LR=0.000100
[2025-08-10 18:11:44,788][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046836] [Batch 02532/03692] [00:22:43/00:10:24, 0.538s/it]: train_loss_raw=0.9702, running_loss=1.0158, LR=0.000100
[2025-08-10 18:11:51,227][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046848] [Batch 02544/03692] [00:22:49/00:10:18, 0.538s/it]: train_loss_raw=1.0279, running_loss=1.0163, LR=0.000100
[2025-08-10 18:11:57,635][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046860] [Batch 02556/03692] [00:22:55/00:10:11, 0.538s/it]: train_loss_raw=1.0139, running_loss=1.0183, LR=0.000100
[2025-08-10 18:12:04,206][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046872] [Batch 02568/03692] [00:23:02/00:10:05, 0.538s/it]: train_loss_raw=1.0032, running_loss=1.0197, LR=0.000100
[2025-08-10 18:12:10,542][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046884] [Batch 02580/03692] [00:23:08/00:09:58, 0.538s/it]: train_loss_raw=1.0976, running_loss=1.0193, LR=0.000100
[2025-08-10 18:12:16,941][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046896] [Batch 02592/03692] [00:23:15/00:09:52, 0.538s/it]: train_loss_raw=0.9716, running_loss=1.0181, LR=0.000100
[2025-08-10 18:12:23,356][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046908] [Batch 02604/03692] [00:23:21/00:09:45, 0.538s/it]: train_loss_raw=1.0120, running_loss=1.0183, LR=0.000100
[2025-08-10 18:12:29,642][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046920] [Batch 02616/03692] [00:23:27/00:09:39, 0.538s/it]: train_loss_raw=1.0501, running_loss=1.0157, LR=0.000100
[2025-08-10 18:12:36,039][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046932] [Batch 02628/03692] [00:23:34/00:09:32, 0.538s/it]: train_loss_raw=1.0188, running_loss=1.0159, LR=0.000100
[2025-08-10 18:12:42,435][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046944] [Batch 02640/03692] [00:23:40/00:09:26, 0.538s/it]: train_loss_raw=0.9468, running_loss=1.0171, LR=0.000100
[2025-08-10 18:12:48,966][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046956] [Batch 02652/03692] [00:23:47/00:09:19, 0.538s/it]: train_loss_raw=0.9041, running_loss=1.0174, LR=0.000100
[2025-08-10 18:12:55,432][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046968] [Batch 02664/03692] [00:23:53/00:09:13, 0.538s/it]: train_loss_raw=1.1054, running_loss=1.0160, LR=0.000100
[2025-08-10 18:13:01,910][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046980] [Batch 02676/03692] [00:24:00/00:09:06, 0.538s/it]: train_loss_raw=0.9913, running_loss=1.0165, LR=0.000100
[2025-08-10 18:13:08,376][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046992] [Batch 02688/03692] [00:24:06/00:09:00, 0.538s/it]: train_loss_raw=0.9621, running_loss=1.0144, LR=0.000100
[2025-08-10 18:13:14,884][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047004] [Batch 02700/03692] [00:24:13/00:08:53, 0.538s/it]: train_loss_raw=0.9594, running_loss=1.0117, LR=0.000100
[2025-08-10 18:13:21,486][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047016] [Batch 02712/03692] [00:24:19/00:08:47, 0.538s/it]: train_loss_raw=0.8645, running_loss=1.0108, LR=0.000100
[2025-08-10 18:13:27,886][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047028] [Batch 02724/03692] [00:24:26/00:08:41, 0.538s/it]: train_loss_raw=1.0446, running_loss=1.0129, LR=0.000100
[2025-08-10 18:13:34,360][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047040] [Batch 02736/03692] [00:24:32/00:08:34, 0.538s/it]: train_loss_raw=0.9694, running_loss=1.0122, LR=0.000100
[2025-08-10 18:13:40,600][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047052] [Batch 02748/03692] [00:24:38/00:08:28, 0.538s/it]: train_loss_raw=0.8886, running_loss=1.0055, LR=0.000100
[2025-08-10 18:13:47,123][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047064] [Batch 02760/03692] [00:24:45/00:08:21, 0.538s/it]: train_loss_raw=1.1341, running_loss=1.0043, LR=0.000100
[2025-08-10 18:13:53,511][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047076] [Batch 02772/03692] [00:24:51/00:08:15, 0.538s/it]: train_loss_raw=0.9788, running_loss=1.0017, LR=0.000100
[2025-08-10 18:13:59,497][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047088] [Batch 02784/03692] [00:24:57/00:08:08, 0.538s/it]: train_loss_raw=1.1235, running_loss=1.0044, LR=0.000100
[2025-08-10 18:14:05,589][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047100] [Batch 02796/03692] [00:25:03/00:08:01, 0.538s/it]: train_loss_raw=1.0686, running_loss=1.0037, LR=0.000100
[2025-08-10 18:14:12,037][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047112] [Batch 02808/03692] [00:25:10/00:07:55, 0.538s/it]: train_loss_raw=1.1654, running_loss=1.0056, LR=0.000100
[2025-08-10 18:14:18,571][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047124] [Batch 02820/03692] [00:25:16/00:07:49, 0.538s/it]: train_loss_raw=0.9338, running_loss=1.0038, LR=0.000100
[2025-08-10 18:14:25,153][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047136] [Batch 02832/03692] [00:25:23/00:07:42, 0.538s/it]: train_loss_raw=1.0025, running_loss=1.0050, LR=0.000100
[2025-08-10 18:14:31,580][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047148] [Batch 02844/03692] [00:25:29/00:07:36, 0.538s/it]: train_loss_raw=1.0754, running_loss=1.0041, LR=0.000100
[2025-08-10 18:14:38,052][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047160] [Batch 02856/03692] [00:25:36/00:07:29, 0.538s/it]: train_loss_raw=0.9171, running_loss=1.0089, LR=0.000100
[2025-08-10 18:14:44,634][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047172] [Batch 02868/03692] [00:25:42/00:07:23, 0.538s/it]: train_loss_raw=0.9608, running_loss=1.0112, LR=0.000100
[2025-08-10 18:14:51,234][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047184] [Batch 02880/03692] [00:25:49/00:07:16, 0.538s/it]: train_loss_raw=1.0110, running_loss=1.0088, LR=0.000100
[2025-08-10 18:14:57,774][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047196] [Batch 02892/03692] [00:25:56/00:07:10, 0.538s/it]: train_loss_raw=1.0678, running_loss=1.0117, LR=0.000100
[2025-08-10 18:15:04,142][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047208] [Batch 02904/03692] [00:26:02/00:07:03, 0.538s/it]: train_loss_raw=0.9580, running_loss=1.0155, LR=0.000100
[2025-08-10 18:15:10,457][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047220] [Batch 02916/03692] [00:26:08/00:06:57, 0.538s/it]: train_loss_raw=1.0548, running_loss=1.0168, LR=0.000100
[2025-08-10 18:15:17,014][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047232] [Batch 02928/03692] [00:26:15/00:06:51, 0.538s/it]: train_loss_raw=1.0169, running_loss=1.0161, LR=0.000100
[2025-08-10 18:15:23,559][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047244] [Batch 02940/03692] [00:26:21/00:06:44, 0.538s/it]: train_loss_raw=1.1548, running_loss=1.0205, LR=0.000100
[2025-08-10 18:15:30,132][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047256] [Batch 02952/03692] [00:26:28/00:06:38, 0.538s/it]: train_loss_raw=1.0008, running_loss=1.0213, LR=0.000100
[2025-08-10 18:15:36,340][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047268] [Batch 02964/03692] [00:26:34/00:06:31, 0.538s/it]: train_loss_raw=0.9240, running_loss=1.0200, LR=0.000100
[2025-08-10 18:15:42,338][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047280] [Batch 02976/03692] [00:26:40/00:06:25, 0.538s/it]: train_loss_raw=0.9431, running_loss=1.0194, LR=0.000100
[2025-08-10 18:15:48,430][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047292] [Batch 02988/03692] [00:26:46/00:06:18, 0.538s/it]: train_loss_raw=1.0283, running_loss=1.0198, LR=0.000100
[2025-08-10 18:15:54,713][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047304] [Batch 03000/03692] [00:26:53/00:06:12, 0.538s/it]: train_loss_raw=1.0390, running_loss=1.0171, LR=0.000100
[2025-08-10 18:16:00,885][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047316] [Batch 03012/03692] [00:26:59/00:06:05, 0.538s/it]: train_loss_raw=1.0086, running_loss=1.0204, LR=0.000100
[2025-08-10 18:16:06,977][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047328] [Batch 03024/03692] [00:27:05/00:05:59, 0.537s/it]: train_loss_raw=1.1410, running_loss=1.0195, LR=0.000100
[2025-08-10 18:16:13,315][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047340] [Batch 03036/03692] [00:27:11/00:05:52, 0.537s/it]: train_loss_raw=1.0790, running_loss=1.0197, LR=0.000100
[2025-08-10 18:16:19,503][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047352] [Batch 03048/03692] [00:27:17/00:05:46, 0.537s/it]: train_loss_raw=0.9074, running_loss=1.0157, LR=0.000100
[2025-08-10 18:16:25,840][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047364] [Batch 03060/03692] [00:27:24/00:05:39, 0.537s/it]: train_loss_raw=1.0286, running_loss=1.0129, LR=0.000100
[2025-08-10 18:16:32,066][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047376] [Batch 03072/03692] [00:27:30/00:05:33, 0.537s/it]: train_loss_raw=1.0221, running_loss=1.0126, LR=0.000100
[2025-08-10 18:16:38,333][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047388] [Batch 03084/03692] [00:27:36/00:05:26, 0.537s/it]: train_loss_raw=0.8858, running_loss=1.0093, LR=0.000100
[2025-08-10 18:16:44,729][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047400] [Batch 03096/03692] [00:27:43/00:05:20, 0.537s/it]: train_loss_raw=1.0352, running_loss=1.0090, LR=0.000100
[2025-08-10 18:16:51,224][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047412] [Batch 03108/03692] [00:27:49/00:05:13, 0.537s/it]: train_loss_raw=0.9614, running_loss=1.0102, LR=0.000100
[2025-08-10 18:16:57,679][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047424] [Batch 03120/03692] [00:27:56/00:05:07, 0.537s/it]: train_loss_raw=0.9981, running_loss=1.0071, LR=0.000100
[2025-08-10 18:17:04,228][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047436] [Batch 03132/03692] [00:28:02/00:05:00, 0.537s/it]: train_loss_raw=1.0222, running_loss=1.0066, LR=0.000100
[2025-08-10 18:17:10,677][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047448] [Batch 03144/03692] [00:28:09/00:04:54, 0.537s/it]: train_loss_raw=1.0911, running_loss=1.0089, LR=0.000100
[2025-08-10 18:17:17,134][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047460] [Batch 03156/03692] [00:28:15/00:04:47, 0.537s/it]: train_loss_raw=0.9174, running_loss=1.0095, LR=0.000100
[2025-08-10 18:17:23,615][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047472] [Batch 03168/03692] [00:28:21/00:04:41, 0.537s/it]: train_loss_raw=1.1005, running_loss=1.0134, LR=0.000100
[2025-08-10 18:17:30,195][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047484] [Batch 03180/03692] [00:28:28/00:04:35, 0.537s/it]: train_loss_raw=0.9302, running_loss=1.0103, LR=0.000100
[2025-08-10 18:17:36,305][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047496] [Batch 03192/03692] [00:28:34/00:04:28, 0.537s/it]: train_loss_raw=1.0773, running_loss=1.0079, LR=0.000100
[2025-08-10 18:17:42,393][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047508] [Batch 03204/03692] [00:28:40/00:04:22, 0.537s/it]: train_loss_raw=0.9561, running_loss=1.0114, LR=0.000100
[2025-08-10 18:17:48,669][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047520] [Batch 03216/03692] [00:28:47/00:04:15, 0.537s/it]: train_loss_raw=1.1455, running_loss=1.0119, LR=0.000100
[2025-08-10 18:17:55,207][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047532] [Batch 03228/03692] [00:28:53/00:04:09, 0.537s/it]: train_loss_raw=1.0647, running_loss=1.0133, LR=0.000100
[2025-08-10 18:18:01,763][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047544] [Batch 03240/03692] [00:29:00/00:04:02, 0.537s/it]: train_loss_raw=1.0069, running_loss=1.0140, LR=0.000100
[2025-08-10 18:18:08,313][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047556] [Batch 03252/03692] [00:29:06/00:03:56, 0.537s/it]: train_loss_raw=0.9743, running_loss=1.0096, LR=0.000100
[2025-08-10 18:18:15,010][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047568] [Batch 03264/03692] [00:29:13/00:03:49, 0.537s/it]: train_loss_raw=0.9509, running_loss=1.0064, LR=0.000100
[2025-08-10 18:18:21,575][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047580] [Batch 03276/03692] [00:29:19/00:03:43, 0.537s/it]: train_loss_raw=1.0511, running_loss=1.0082, LR=0.000100
[2025-08-10 18:18:28,122][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047592] [Batch 03288/03692] [00:29:26/00:03:37, 0.537s/it]: train_loss_raw=0.8686, running_loss=1.0058, LR=0.000100
[2025-08-10 18:18:34,418][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047604] [Batch 03300/03692] [00:29:32/00:03:30, 0.537s/it]: train_loss_raw=1.0255, running_loss=1.0065, LR=0.000100
[2025-08-10 18:18:40,898][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047616] [Batch 03312/03692] [00:29:39/00:03:24, 0.537s/it]: train_loss_raw=0.9809, running_loss=1.0045, LR=0.000100
[2025-08-10 18:18:47,266][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047628] [Batch 03324/03692] [00:29:45/00:03:17, 0.537s/it]: train_loss_raw=0.9654, running_loss=1.0054, LR=0.000100
[2025-08-10 18:18:53,561][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047640] [Batch 03336/03692] [00:29:51/00:03:11, 0.537s/it]: train_loss_raw=0.9892, running_loss=1.0023, LR=0.000100
[2025-08-10 18:18:59,978][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047652] [Batch 03348/03692] [00:29:58/00:03:04, 0.537s/it]: train_loss_raw=1.0311, running_loss=1.0042, LR=0.000100
[2025-08-10 18:19:06,512][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047664] [Batch 03360/03692] [00:30:04/00:02:58, 0.537s/it]: train_loss_raw=0.9830, running_loss=1.0039, LR=0.000100
[2025-08-10 18:19:12,682][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047676] [Batch 03372/03692] [00:30:11/00:02:51, 0.537s/it]: train_loss_raw=1.0170, running_loss=1.0041, LR=0.000100
[2025-08-10 18:19:18,746][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047688] [Batch 03384/03692] [00:30:17/00:02:45, 0.537s/it]: train_loss_raw=0.9247, running_loss=1.0010, LR=0.000100
[2025-08-10 18:19:24,789][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047700] [Batch 03396/03692] [00:30:23/00:02:38, 0.537s/it]: train_loss_raw=0.8467, running_loss=0.9989, LR=0.000100
[2025-08-10 18:19:31,172][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047712] [Batch 03408/03692] [00:30:29/00:02:32, 0.537s/it]: train_loss_raw=0.8669, running_loss=0.9953, LR=0.000100
[2025-08-10 18:19:37,289][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047724] [Batch 03420/03692] [00:30:35/00:02:25, 0.537s/it]: train_loss_raw=1.0852, running_loss=0.9981, LR=0.000100
[2025-08-10 18:19:43,799][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047736] [Batch 03432/03692] [00:30:42/00:02:19, 0.537s/it]: train_loss_raw=1.0958, running_loss=0.9983, LR=0.000100
[2025-08-10 18:19:50,351][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047748] [Batch 03444/03692] [00:30:48/00:02:13, 0.537s/it]: train_loss_raw=0.8787, running_loss=0.9994, LR=0.000100
[2025-08-10 18:19:56,868][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047760] [Batch 03456/03692] [00:30:55/00:02:06, 0.537s/it]: train_loss_raw=1.0598, running_loss=1.0023, LR=0.000100
[2025-08-10 18:20:03,045][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047772] [Batch 03468/03692] [00:31:01/00:02:00, 0.537s/it]: train_loss_raw=0.9952, running_loss=1.0011, LR=0.000100
[2025-08-10 18:20:09,513][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047784] [Batch 03480/03692] [00:31:07/00:01:53, 0.537s/it]: train_loss_raw=1.0496, running_loss=1.0027, LR=0.000100
[2025-08-10 18:20:16,138][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047796] [Batch 03492/03692] [00:31:14/00:01:47, 0.537s/it]: train_loss_raw=1.0236, running_loss=0.9992, LR=0.000100
[2025-08-10 18:20:22,628][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047808] [Batch 03504/03692] [00:31:20/00:01:40, 0.537s/it]: train_loss_raw=1.0177, running_loss=0.9961, LR=0.000100
[2025-08-10 18:20:28,860][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047820] [Batch 03516/03692] [00:31:27/00:01:34, 0.537s/it]: train_loss_raw=0.9125, running_loss=0.9956, LR=0.000100
[2025-08-10 18:20:35,152][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047832] [Batch 03528/03692] [00:31:33/00:01:28, 0.537s/it]: train_loss_raw=1.1098, running_loss=0.9968, LR=0.000100
[2025-08-10 18:20:41,617][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047844] [Batch 03540/03692] [00:31:39/00:01:21, 0.537s/it]: train_loss_raw=0.9827, running_loss=0.9945, LR=0.000100
[2025-08-10 18:20:48,200][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047856] [Batch 03552/03692] [00:31:46/00:01:15, 0.537s/it]: train_loss_raw=1.0292, running_loss=0.9928, LR=0.000100
[2025-08-10 18:20:54,636][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047868] [Batch 03564/03692] [00:31:52/00:01:08, 0.537s/it]: train_loss_raw=0.9208, running_loss=0.9900, LR=0.000100
[2025-08-10 18:21:01,097][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047880] [Batch 03576/03692] [00:31:59/00:01:02, 0.537s/it]: train_loss_raw=0.9966, running_loss=0.9864, LR=0.000100
[2025-08-10 18:21:07,219][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047892] [Batch 03588/03692] [00:32:05/00:00:55, 0.537s/it]: train_loss_raw=0.8441, running_loss=0.9877, LR=0.000100
[2025-08-10 18:21:13,395][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047904] [Batch 03600/03692] [00:32:11/00:00:49, 0.537s/it]: train_loss_raw=1.0660, running_loss=0.9891, LR=0.000100
[2025-08-10 18:21:19,655][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047916] [Batch 03612/03692] [00:32:17/00:00:42, 0.537s/it]: train_loss_raw=0.8423, running_loss=0.9841, LR=0.000100
[2025-08-10 18:21:26,048][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047928] [Batch 03624/03692] [00:32:24/00:00:36, 0.537s/it]: train_loss_raw=0.9677, running_loss=0.9873, LR=0.000100
[2025-08-10 18:21:32,655][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047940] [Batch 03636/03692] [00:32:30/00:00:30, 0.537s/it]: train_loss_raw=0.9510, running_loss=0.9838, LR=0.000100
[2025-08-10 18:21:39,230][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047952] [Batch 03648/03692] [00:32:37/00:00:23, 0.537s/it]: train_loss_raw=1.0030, running_loss=0.9848, LR=0.000100
[2025-08-10 18:21:45,771][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047964] [Batch 03660/03692] [00:32:44/00:00:17, 0.537s/it]: train_loss_raw=0.8621, running_loss=0.9829, LR=0.000100
[2025-08-10 18:21:52,388][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047976] [Batch 03672/03692] [00:32:50/00:00:10, 0.537s/it]: train_loss_raw=1.0749, running_loss=0.9855, LR=0.000100
[2025-08-10 18:21:58,899][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047988] [Batch 03684/03692] [00:32:57/00:00:04, 0.537s/it]: train_loss_raw=1.0436, running_loss=0.9850, LR=0.000100
[2025-08-10 18:22:08,393][__main__][INFO] - [VALIDATION] [Epoch 12/29] Starting validation.
[2025-08-10 18:22:43,304][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 047997] [Batch 00011/00025] [00:00:34/00:00:37, 2.909s/it]
[2025-08-10 18:22:59,683][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 047997] [Batch 00023/00025] [00:00:51/00:00:02, 2.137s/it]
[2025-08-10 18:23:00,768][__main__][INFO] - [VALIDATION] [Epoch 12/29] train_loss=0.98475, valid_loss=1.02010
[2025-08-10 18:23:00,769][__main__][INFO] - [VALIDATION] [Epoch 12/29] Metrics:
[2025-08-10 18:23:00,769][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_er      0.443
[2025-08-10 18:23:00,770][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_prec    0.295
[2025-08-10 18:23:00,770][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_recall  0.303
[2025-08-10 18:23:00,770][__main__][INFO] - [VALIDATION] [Epoch 12/29] - pep_recall 0.261
[2025-08-10 18:23:00,774][__main__][INFO] - [TRAIN] [Epoch 12/29] Epoch complete, total time 07:27:00, remaining time 09:44:32, 00:34:23 per epoch
[2025-08-10 18:23:02,777][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048000] [Batch 00004/03692] [00:00:01/00:26:48, 0.436s/it]: train_loss_raw=1.0603, running_loss=0.8919, LR=0.000100
[2025-08-10 18:23:15,048][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048012] [Batch 00016/03692] [00:00:14/00:53:39, 0.876s/it]: train_loss_raw=0.8965, running_loss=0.9039, LR=0.000100
[2025-08-10 18:23:21,542][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048024] [Batch 00028/03692] [00:00:20/00:44:43, 0.732s/it]: train_loss_raw=1.0127, running_loss=0.9141, LR=0.000100
[2025-08-10 18:23:28,009][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048036] [Batch 00040/03692] [00:00:26/00:41:02, 0.674s/it]: train_loss_raw=0.9652, running_loss=0.9188, LR=0.000100
[2025-08-10 18:23:34,360][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048048] [Batch 00052/03692] [00:00:33/00:38:52, 0.641s/it]: train_loss_raw=0.9726, running_loss=0.9271, LR=0.000100
[2025-08-10 18:23:40,674][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048060] [Batch 00064/03692] [00:00:39/00:37:27, 0.619s/it]: train_loss_raw=1.0541, running_loss=0.9344, LR=0.000100
[2025-08-10 18:23:47,015][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048072] [Batch 00076/03692] [00:00:45/00:36:27, 0.605s/it]: train_loss_raw=0.9658, running_loss=0.9377, LR=0.000100
[2025-08-10 18:23:53,269][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048084] [Batch 00088/03692] [00:00:52/00:35:39, 0.594s/it]: train_loss_raw=1.0793, running_loss=0.9472, LR=0.000100
[2025-08-10 18:23:59,624][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048096] [Batch 00100/03692] [00:00:58/00:35:04, 0.586s/it]: train_loss_raw=0.9392, running_loss=0.9494, LR=0.000100
[2025-08-10 18:24:06,050][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048108] [Batch 00112/03692] [00:01:05/00:34:38, 0.581s/it]: train_loss_raw=0.9909, running_loss=0.9549, LR=0.000100
[2025-08-10 18:24:12,308][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048120] [Batch 00124/03692] [00:01:11/00:34:10, 0.575s/it]: train_loss_raw=1.0811, running_loss=0.9596, LR=0.000100
[2025-08-10 18:24:18,610][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048132] [Batch 00136/03692] [00:01:17/00:33:48, 0.570s/it]: train_loss_raw=1.0574, running_loss=0.9646, LR=0.000100
[2025-08-10 18:24:25,163][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048144] [Batch 00148/03692] [00:01:24/00:33:34, 0.568s/it]: train_loss_raw=0.9783, running_loss=0.9651, LR=0.000100
[2025-08-10 18:24:31,736][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048156] [Batch 00160/03692] [00:01:30/00:33:22, 0.567s/it]: train_loss_raw=1.0998, running_loss=0.9709, LR=0.000100
[2025-08-10 18:24:38,294][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048168] [Batch 00172/03692] [00:01:37/00:33:10, 0.565s/it]: train_loss_raw=0.9418, running_loss=0.9711, LR=0.000100
[2025-08-10 18:24:44,901][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048180] [Batch 00184/03692] [00:01:43/00:33:00, 0.565s/it]: train_loss_raw=0.8790, running_loss=0.9701, LR=0.000100
[2025-08-10 18:24:51,401][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048192] [Batch 00196/03692] [00:01:50/00:32:48, 0.563s/it]: train_loss_raw=0.9759, running_loss=0.9748, LR=0.000100
[2025-08-10 18:24:57,869][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048204] [Batch 00208/03692] [00:01:56/00:32:37, 0.562s/it]: train_loss_raw=1.0733, running_loss=0.9804, LR=0.000100
[2025-08-10 18:25:04,330][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048216] [Batch 00220/03692] [00:02:03/00:32:25, 0.560s/it]: train_loss_raw=0.8626, running_loss=0.9791, LR=0.000100
[2025-08-10 18:25:10,841][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048228] [Batch 00232/03692] [00:02:09/00:32:15, 0.560s/it]: train_loss_raw=0.9408, running_loss=0.9805, LR=0.000100
[2025-08-10 18:25:17,196][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048240] [Batch 00244/03692] [00:02:16/00:32:04, 0.558s/it]: train_loss_raw=0.8335, running_loss=0.9751, LR=0.000100
[2025-08-10 18:25:23,751][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048252] [Batch 00256/03692] [00:02:22/00:31:55, 0.557s/it]: train_loss_raw=1.0162, running_loss=0.9784, LR=0.000100
[2025-08-10 18:25:30,333][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048264] [Batch 00268/03692] [00:02:29/00:31:47, 0.557s/it]: train_loss_raw=1.0487, running_loss=0.9850, LR=0.000100
[2025-08-10 18:25:36,764][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048276] [Batch 00280/03692] [00:02:35/00:31:37, 0.556s/it]: train_loss_raw=1.0213, running_loss=0.9896, LR=0.000100
[2025-08-10 18:25:43,191][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048288] [Batch 00292/03692] [00:02:42/00:31:28, 0.555s/it]: train_loss_raw=0.9721, running_loss=0.9892, LR=0.000100
[2025-08-10 18:25:49,736][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048300] [Batch 00304/03692] [00:02:48/00:31:20, 0.555s/it]: train_loss_raw=0.9399, running_loss=0.9854, LR=0.000100
[2025-08-10 18:25:56,290][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048312] [Batch 00316/03692] [00:02:55/00:31:12, 0.555s/it]: train_loss_raw=1.0080, running_loss=0.9889, LR=0.000100
[2025-08-10 18:26:02,676][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048324] [Batch 00328/03692] [00:03:01/00:31:02, 0.554s/it]: train_loss_raw=1.0068, running_loss=0.9928, LR=0.000100
[2025-08-10 18:26:09,140][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048336] [Batch 00340/03692] [00:03:08/00:30:54, 0.553s/it]: train_loss_raw=1.0249, running_loss=0.9914, LR=0.000100
[2025-08-10 18:26:15,608][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048348] [Batch 00352/03692] [00:03:14/00:30:46, 0.553s/it]: train_loss_raw=1.0739, running_loss=0.9895, LR=0.000100
[2025-08-10 18:26:22,075][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048360] [Batch 00364/03692] [00:03:21/00:30:38, 0.552s/it]: train_loss_raw=1.0195, running_loss=0.9905, LR=0.000100
[2025-08-10 18:26:28,351][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048372] [Batch 00376/03692] [00:03:27/00:30:28, 0.551s/it]: train_loss_raw=0.9669, running_loss=0.9913, LR=0.000100
[2025-08-10 18:26:34,581][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048384] [Batch 00388/03692] [00:03:33/00:30:18, 0.550s/it]: train_loss_raw=1.0332, running_loss=0.9894, LR=0.000100
[2025-08-10 18:26:40,997][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048396] [Batch 00400/03692] [00:03:39/00:30:10, 0.550s/it]: train_loss_raw=1.0657, running_loss=0.9896, LR=0.000100
[2025-08-10 18:26:47,264][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048408] [Batch 00412/03692] [00:03:46/00:30:01, 0.549s/it]: train_loss_raw=0.9721, running_loss=0.9852, LR=0.000100
[2025-08-10 18:26:53,640][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048420] [Batch 00424/03692] [00:03:52/00:29:52, 0.549s/it]: train_loss_raw=0.9670, running_loss=0.9834, LR=0.000100
[2025-08-10 18:27:00,125][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048432] [Batch 00436/03692] [00:03:59/00:29:45, 0.548s/it]: train_loss_raw=0.9962, running_loss=0.9813, LR=0.000100
[2025-08-10 18:27:06,629][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048444] [Batch 00448/03692] [00:04:05/00:29:38, 0.548s/it]: train_loss_raw=0.9973, running_loss=0.9796, LR=0.000100
[2025-08-10 18:27:13,132][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048456] [Batch 00460/03692] [00:04:12/00:29:31, 0.548s/it]: train_loss_raw=0.9347, running_loss=0.9796, LR=0.000100
[2025-08-10 18:27:19,578][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048468] [Batch 00472/03692] [00:04:18/00:29:23, 0.548s/it]: train_loss_raw=1.0462, running_loss=0.9816, LR=0.000100
[2025-08-10 18:27:25,697][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048480] [Batch 00484/03692] [00:04:24/00:29:14, 0.547s/it]: train_loss_raw=1.1935, running_loss=0.9862, LR=0.000100
[2025-08-10 18:27:31,948][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048492] [Batch 00496/03692] [00:04:30/00:29:05, 0.546s/it]: train_loss_raw=0.8770, running_loss=0.9852, LR=0.000100
[2025-08-10 18:27:38,321][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048504] [Batch 00508/03692] [00:04:37/00:28:57, 0.546s/it]: train_loss_raw=0.9123, running_loss=0.9835, LR=0.000100
[2025-08-10 18:27:44,723][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048516] [Batch 00520/03692] [00:04:43/00:28:50, 0.546s/it]: train_loss_raw=0.8487, running_loss=0.9821, LR=0.000100
[2025-08-10 18:27:51,049][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048528] [Batch 00532/03692] [00:04:50/00:28:42, 0.545s/it]: train_loss_raw=1.1095, running_loss=0.9812, LR=0.000100
[2025-08-10 18:27:57,285][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048540] [Batch 00544/03692] [00:04:56/00:28:34, 0.545s/it]: train_loss_raw=1.0718, running_loss=0.9891, LR=0.000100
[2025-08-10 18:28:03,604][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048552] [Batch 00556/03692] [00:05:02/00:28:26, 0.544s/it]: train_loss_raw=0.9760, running_loss=0.9931, LR=0.000100
[2025-08-10 18:28:09,996][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048564] [Batch 00568/03692] [00:05:08/00:28:19, 0.544s/it]: train_loss_raw=1.1469, running_loss=0.9943, LR=0.000100
[2025-08-10 18:28:16,429][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048576] [Batch 00580/03692] [00:05:15/00:28:12, 0.544s/it]: train_loss_raw=1.1130, running_loss=0.9939, LR=0.000100
[2025-08-10 18:28:22,838][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048588] [Batch 00592/03692] [00:05:21/00:28:05, 0.544s/it]: train_loss_raw=0.9437, running_loss=0.9955, LR=0.000100
[2025-08-10 18:28:29,327][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048600] [Batch 00604/03692] [00:05:28/00:27:58, 0.544s/it]: train_loss_raw=1.0621, running_loss=0.9942, LR=0.000100
[2025-08-10 18:28:35,389][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048612] [Batch 00616/03692] [00:05:34/00:27:49, 0.543s/it]: train_loss_raw=0.9765, running_loss=0.9901, LR=0.000100
[2025-08-10 18:28:41,712][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048624] [Batch 00628/03692] [00:05:40/00:27:42, 0.542s/it]: train_loss_raw=0.9758, running_loss=0.9903, LR=0.000100
[2025-08-10 18:28:48,226][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048636] [Batch 00640/03692] [00:05:47/00:27:35, 0.542s/it]: train_loss_raw=0.9511, running_loss=0.9921, LR=0.000100
[2025-08-10 18:28:54,740][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048648] [Batch 00652/03692] [00:05:53/00:27:29, 0.542s/it]: train_loss_raw=0.9271, running_loss=0.9901, LR=0.000100
[2025-08-10 18:29:01,100][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048660] [Batch 00664/03692] [00:06:00/00:27:21, 0.542s/it]: train_loss_raw=1.0528, running_loss=0.9895, LR=0.000100
[2025-08-10 18:29:07,572][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048672] [Batch 00676/03692] [00:06:06/00:27:15, 0.542s/it]: train_loss_raw=0.9378, running_loss=0.9864, LR=0.000100
[2025-08-10 18:29:14,041][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048684] [Batch 00688/03692] [00:06:13/00:27:08, 0.542s/it]: train_loss_raw=1.0052, running_loss=0.9900, LR=0.000100
[2025-08-10 18:29:20,441][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048696] [Batch 00700/03692] [00:06:19/00:27:01, 0.542s/it]: train_loss_raw=1.0587, running_loss=0.9900, LR=0.000100
[2025-08-10 18:29:26,952][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048708] [Batch 00712/03692] [00:06:25/00:26:55, 0.542s/it]: train_loss_raw=0.9780, running_loss=0.9913, LR=0.000100
[2025-08-10 18:29:33,393][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048720] [Batch 00724/03692] [00:06:32/00:26:48, 0.542s/it]: train_loss_raw=0.9590, running_loss=0.9879, LR=0.000100
[2025-08-10 18:29:39,821][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048732] [Batch 00736/03692] [00:06:38/00:26:41, 0.542s/it]: train_loss_raw=0.9954, running_loss=0.9873, LR=0.000100
[2025-08-10 18:29:46,231][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048744] [Batch 00748/03692] [00:06:45/00:26:34, 0.542s/it]: train_loss_raw=0.9688, running_loss=0.9880, LR=0.000100
[2025-08-10 18:29:52,696][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048756] [Batch 00760/03692] [00:06:51/00:26:28, 0.542s/it]: train_loss_raw=0.9763, running_loss=0.9880, LR=0.000100
[2025-08-10 18:29:59,254][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048768] [Batch 00772/03692] [00:06:58/00:26:21, 0.542s/it]: train_loss_raw=1.0326, running_loss=0.9850, LR=0.000100
[2025-08-10 18:30:05,751][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048780] [Batch 00784/03692] [00:07:04/00:26:15, 0.542s/it]: train_loss_raw=1.0615, running_loss=0.9789, LR=0.000100
[2025-08-10 18:30:12,206][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048792] [Batch 00796/03692] [00:07:11/00:26:08, 0.542s/it]: train_loss_raw=1.0437, running_loss=0.9823, LR=0.000100
[2025-08-10 18:30:18,649][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048804] [Batch 00808/03692] [00:07:17/00:26:01, 0.542s/it]: train_loss_raw=1.0056, running_loss=0.9829, LR=0.000100
[2025-08-10 18:30:25,193][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048816] [Batch 00820/03692] [00:07:24/00:25:55, 0.542s/it]: train_loss_raw=0.9069, running_loss=0.9812, LR=0.000100
[2025-08-10 18:30:31,726][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048828] [Batch 00832/03692] [00:07:30/00:25:49, 0.542s/it]: train_loss_raw=0.9644, running_loss=0.9787, LR=0.000100
[2025-08-10 18:30:38,112][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048840] [Batch 00844/03692] [00:07:37/00:25:42, 0.542s/it]: train_loss_raw=0.9099, running_loss=0.9790, LR=0.000100
[2025-08-10 18:30:44,513][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048852] [Batch 00856/03692] [00:07:43/00:25:35, 0.541s/it]: train_loss_raw=0.9137, running_loss=0.9774, LR=0.000100
[2025-08-10 18:30:50,892][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048864] [Batch 00868/03692] [00:07:49/00:25:28, 0.541s/it]: train_loss_raw=0.9620, running_loss=0.9773, LR=0.000100
[2025-08-10 18:30:56,929][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048876] [Batch 00880/03692] [00:07:55/00:25:20, 0.541s/it]: train_loss_raw=0.9578, running_loss=0.9805, LR=0.000100
[2025-08-10 18:31:03,402][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048888] [Batch 00892/03692] [00:08:02/00:25:14, 0.541s/it]: train_loss_raw=1.0740, running_loss=0.9800, LR=0.000100
[2025-08-10 18:31:09,899][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048900] [Batch 00904/03692] [00:08:08/00:25:07, 0.541s/it]: train_loss_raw=1.1152, running_loss=0.9805, LR=0.000100
[2025-08-10 18:31:16,223][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048912] [Batch 00916/03692] [00:08:15/00:25:00, 0.541s/it]: train_loss_raw=0.7710, running_loss=0.9813, LR=0.000100
[2025-08-10 18:31:22,681][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048924] [Batch 00928/03692] [00:08:21/00:24:54, 0.541s/it]: train_loss_raw=0.9352, running_loss=0.9827, LR=0.000100
[2025-08-10 18:31:29,112][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048936] [Batch 00940/03692] [00:08:28/00:24:47, 0.541s/it]: train_loss_raw=0.8729, running_loss=0.9830, LR=0.000100
[2025-08-10 18:31:35,637][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048948] [Batch 00952/03692] [00:08:34/00:24:41, 0.541s/it]: train_loss_raw=0.9754, running_loss=0.9837, LR=0.000100
[2025-08-10 18:31:42,012][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048960] [Batch 00964/03692] [00:08:40/00:24:34, 0.540s/it]: train_loss_raw=1.0145, running_loss=0.9859, LR=0.000100
[2025-08-10 18:31:48,167][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048972] [Batch 00976/03692] [00:08:47/00:24:26, 0.540s/it]: train_loss_raw=0.9815, running_loss=0.9879, LR=0.000100
[2025-08-10 18:31:54,397][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048984] [Batch 00988/03692] [00:08:53/00:24:19, 0.540s/it]: train_loss_raw=1.1005, running_loss=0.9893, LR=0.000100
[2025-08-10 18:32:00,520][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048996] [Batch 01000/03692] [00:08:59/00:24:12, 0.539s/it]: train_loss_raw=1.0111, running_loss=0.9921, LR=0.000100
[2025-08-10 18:32:07,060][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049008] [Batch 01012/03692] [00:09:06/00:24:06, 0.540s/it]: train_loss_raw=0.9783, running_loss=0.9940, LR=0.000100
[2025-08-10 18:32:13,649][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049020] [Batch 01024/03692] [00:09:12/00:23:59, 0.540s/it]: train_loss_raw=0.9185, running_loss=0.9923, LR=0.000100
[2025-08-10 18:32:19,831][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049032] [Batch 01036/03692] [00:09:18/00:23:52, 0.539s/it]: train_loss_raw=0.8713, running_loss=0.9923, LR=0.000100
[2025-08-10 18:32:26,077][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049044] [Batch 01048/03692] [00:09:25/00:23:45, 0.539s/it]: train_loss_raw=0.8544, running_loss=0.9914, LR=0.000100
[2025-08-10 18:32:32,365][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049056] [Batch 01060/03692] [00:09:31/00:23:38, 0.539s/it]: train_loss_raw=1.0484, running_loss=0.9884, LR=0.000100
[2025-08-10 18:32:38,732][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049068] [Batch 01072/03692] [00:09:37/00:23:31, 0.539s/it]: train_loss_raw=0.9918, running_loss=0.9912, LR=0.000100
[2025-08-10 18:32:44,908][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049080] [Batch 01084/03692] [00:09:43/00:23:24, 0.539s/it]: train_loss_raw=1.0274, running_loss=0.9921, LR=0.000100
[2025-08-10 18:32:51,289][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049092] [Batch 01096/03692] [00:09:50/00:23:18, 0.539s/it]: train_loss_raw=1.0127, running_loss=0.9927, LR=0.000100
[2025-08-10 18:32:57,771][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049104] [Batch 01108/03692] [00:09:56/00:23:11, 0.539s/it]: train_loss_raw=1.0916, running_loss=0.9901, LR=0.000100
[2025-08-10 18:33:04,357][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049116] [Batch 01120/03692] [00:10:03/00:23:05, 0.539s/it]: train_loss_raw=0.9481, running_loss=0.9880, LR=0.000100
[2025-08-10 18:33:10,936][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049128] [Batch 01132/03692] [00:10:09/00:22:59, 0.539s/it]: train_loss_raw=1.0392, running_loss=0.9857, LR=0.000100
[2025-08-10 18:33:17,396][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049140] [Batch 01144/03692] [00:10:16/00:22:52, 0.539s/it]: train_loss_raw=0.9561, running_loss=0.9854, LR=0.000100
[2025-08-10 18:33:23,878][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049152] [Batch 01156/03692] [00:10:22/00:22:46, 0.539s/it]: train_loss_raw=1.0409, running_loss=0.9838, LR=0.000100
[2025-08-10 18:33:30,301][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049164] [Batch 01168/03692] [00:10:29/00:22:39, 0.539s/it]: train_loss_raw=0.9274, running_loss=0.9804, LR=0.000100
[2025-08-10 18:33:36,775][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049176] [Batch 01180/03692] [00:10:35/00:22:33, 0.539s/it]: train_loss_raw=1.0563, running_loss=0.9788, LR=0.000100
[2025-08-10 18:33:43,279][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049188] [Batch 01192/03692] [00:10:42/00:22:26, 0.539s/it]: train_loss_raw=0.9537, running_loss=0.9822, LR=0.000100
[2025-08-10 18:33:49,725][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049200] [Batch 01204/03692] [00:10:48/00:22:20, 0.539s/it]: train_loss_raw=1.0307, running_loss=0.9822, LR=0.000100
[2025-08-10 18:33:56,189][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049212] [Batch 01216/03692] [00:10:55/00:22:14, 0.539s/it]: train_loss_raw=0.9919, running_loss=0.9845, LR=0.000100
[2025-08-10 18:34:02,597][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049224] [Batch 01228/03692] [00:11:01/00:22:07, 0.539s/it]: train_loss_raw=1.1633, running_loss=0.9869, LR=0.000100
[2025-08-10 18:34:08,989][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049236] [Batch 01240/03692] [00:11:07/00:22:00, 0.539s/it]: train_loss_raw=0.9509, running_loss=0.9826, LR=0.000100
[2025-08-10 18:34:15,198][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049248] [Batch 01252/03692] [00:11:14/00:21:53, 0.538s/it]: train_loss_raw=0.8438, running_loss=0.9775, LR=0.000100
[2025-08-10 18:34:21,232][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049260] [Batch 01264/03692] [00:11:20/00:21:46, 0.538s/it]: train_loss_raw=0.9101, running_loss=0.9749, LR=0.000100
[2025-08-10 18:34:27,245][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049272] [Batch 01276/03692] [00:11:26/00:21:39, 0.538s/it]: train_loss_raw=1.0344, running_loss=0.9774, LR=0.000100
[2025-08-10 18:34:33,652][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049284] [Batch 01288/03692] [00:11:32/00:21:32, 0.538s/it]: train_loss_raw=1.1276, running_loss=0.9790, LR=0.000100
[2025-08-10 18:34:40,181][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049296] [Batch 01300/03692] [00:11:39/00:21:26, 0.538s/it]: train_loss_raw=0.9363, running_loss=0.9813, LR=0.000100
[2025-08-10 18:34:46,661][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049308] [Batch 01312/03692] [00:11:45/00:21:20, 0.538s/it]: train_loss_raw=0.8550, running_loss=0.9776, LR=0.000100
[2025-08-10 18:34:53,033][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049320] [Batch 01324/03692] [00:11:52/00:21:13, 0.538s/it]: train_loss_raw=1.0186, running_loss=0.9760, LR=0.000100
[2025-08-10 18:34:59,209][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049332] [Batch 01336/03692] [00:11:58/00:21:06, 0.538s/it]: train_loss_raw=1.0075, running_loss=0.9767, LR=0.000100
[2025-08-10 18:35:05,445][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049344] [Batch 01348/03692] [00:12:04/00:20:59, 0.537s/it]: train_loss_raw=0.9557, running_loss=0.9768, LR=0.000100
[2025-08-10 18:35:11,744][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049356] [Batch 01360/03692] [00:12:10/00:20:52, 0.537s/it]: train_loss_raw=1.0876, running_loss=0.9782, LR=0.000100
[2025-08-10 18:35:18,147][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049368] [Batch 01372/03692] [00:12:17/00:20:46, 0.537s/it]: train_loss_raw=0.9929, running_loss=0.9781, LR=0.000100
[2025-08-10 18:35:24,272][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049380] [Batch 01384/03692] [00:12:23/00:20:39, 0.537s/it]: train_loss_raw=0.9228, running_loss=0.9749, LR=0.000100
[2025-08-10 18:35:30,412][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049392] [Batch 01396/03692] [00:12:29/00:20:32, 0.537s/it]: train_loss_raw=0.9347, running_loss=0.9771, LR=0.000100
[2025-08-10 18:35:36,471][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049404] [Batch 01408/03692] [00:12:35/00:20:25, 0.537s/it]: train_loss_raw=1.0614, running_loss=0.9774, LR=0.000100
[2025-08-10 18:35:42,820][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049416] [Batch 01420/03692] [00:12:41/00:20:18, 0.536s/it]: train_loss_raw=1.0801, running_loss=0.9784, LR=0.000100
[2025-08-10 18:35:49,265][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049428] [Batch 01432/03692] [00:12:48/00:20:12, 0.536s/it]: train_loss_raw=0.9381, running_loss=0.9789, LR=0.000100
[2025-08-10 18:35:55,440][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049440] [Batch 01444/03692] [00:12:54/00:20:05, 0.536s/it]: train_loss_raw=1.1202, running_loss=0.9802, LR=0.000100
[2025-08-10 18:36:01,534][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049452] [Batch 01456/03692] [00:13:00/00:19:58, 0.536s/it]: train_loss_raw=1.0127, running_loss=0.9806, LR=0.000100
[2025-08-10 18:36:07,649][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049464] [Batch 01468/03692] [00:13:06/00:19:51, 0.536s/it]: train_loss_raw=0.9831, running_loss=0.9821, LR=0.000100
[2025-08-10 18:36:13,802][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049476] [Batch 01480/03692] [00:13:12/00:19:44, 0.536s/it]: train_loss_raw=0.8778, running_loss=0.9834, LR=0.000100
[2025-08-10 18:36:19,971][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049488] [Batch 01492/03692] [00:13:18/00:19:38, 0.535s/it]: train_loss_raw=1.1680, running_loss=0.9806, LR=0.000100
[2025-08-10 18:36:26,543][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049500] [Batch 01504/03692] [00:13:25/00:19:31, 0.536s/it]: train_loss_raw=0.9209, running_loss=0.9812, LR=0.000100
[2025-08-10 18:36:33,081][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049512] [Batch 01516/03692] [00:13:32/00:19:25, 0.536s/it]: train_loss_raw=0.9322, running_loss=0.9806, LR=0.000100
[2025-08-10 18:36:39,646][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049524] [Batch 01528/03692] [00:13:38/00:19:19, 0.536s/it]: train_loss_raw=1.0189, running_loss=0.9794, LR=0.000100
[2025-08-10 18:36:46,325][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049536] [Batch 01540/03692] [00:13:45/00:19:13, 0.536s/it]: train_loss_raw=1.0851, running_loss=0.9786, LR=0.000100
[2025-08-10 18:36:52,837][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049548] [Batch 01552/03692] [00:13:51/00:19:06, 0.536s/it]: train_loss_raw=0.9653, running_loss=0.9734, LR=0.000100
[2025-08-10 18:36:59,388][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049560] [Batch 01564/03692] [00:13:58/00:19:00, 0.536s/it]: train_loss_raw=0.8329, running_loss=0.9666, LR=0.000100
[2025-08-10 18:37:05,619][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049572] [Batch 01576/03692] [00:14:04/00:18:53, 0.536s/it]: train_loss_raw=1.0022, running_loss=0.9673, LR=0.000100
[2025-08-10 18:37:11,825][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049584] [Batch 01588/03692] [00:14:10/00:18:47, 0.536s/it]: train_loss_raw=0.9995, running_loss=0.9658, LR=0.000100
[2025-08-10 18:37:18,374][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049596] [Batch 01600/03692] [00:14:17/00:18:40, 0.536s/it]: train_loss_raw=0.9837, running_loss=0.9637, LR=0.000100
[2025-08-10 18:37:24,911][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049608] [Batch 01612/03692] [00:14:23/00:18:34, 0.536s/it]: train_loss_raw=0.8618, running_loss=0.9618, LR=0.000100
[2025-08-10 18:37:31,132][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049620] [Batch 01624/03692] [00:14:30/00:18:27, 0.536s/it]: train_loss_raw=0.9392, running_loss=0.9673, LR=0.000100
[2025-08-10 18:37:37,507][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049632] [Batch 01636/03692] [00:14:36/00:18:21, 0.536s/it]: train_loss_raw=0.8989, running_loss=0.9691, LR=0.000100
[2025-08-10 18:37:44,065][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049644] [Batch 01648/03692] [00:14:43/00:18:15, 0.536s/it]: train_loss_raw=1.0521, running_loss=0.9704, LR=0.000100
[2025-08-10 18:37:50,609][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049656] [Batch 01660/03692] [00:14:49/00:18:08, 0.536s/it]: train_loss_raw=0.9395, running_loss=0.9701, LR=0.000100
[2025-08-10 18:37:57,081][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049668] [Batch 01672/03692] [00:14:56/00:18:02, 0.536s/it]: train_loss_raw=1.0630, running_loss=0.9695, LR=0.000100
[2025-08-10 18:38:03,425][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049680] [Batch 01684/03692] [00:15:02/00:17:56, 0.536s/it]: train_loss_raw=1.0445, running_loss=0.9685, LR=0.000100
[2025-08-10 18:38:09,865][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049692] [Batch 01696/03692] [00:15:08/00:17:49, 0.536s/it]: train_loss_raw=0.9952, running_loss=0.9743, LR=0.000100
[2025-08-10 18:38:16,338][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049704] [Batch 01708/03692] [00:15:15/00:17:43, 0.536s/it]: train_loss_raw=1.0422, running_loss=0.9755, LR=0.000100
[2025-08-10 18:38:22,789][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049716] [Batch 01720/03692] [00:15:21/00:17:36, 0.536s/it]: train_loss_raw=1.1192, running_loss=0.9777, LR=0.000100
[2025-08-10 18:38:28,976][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049728] [Batch 01732/03692] [00:15:27/00:17:30, 0.536s/it]: train_loss_raw=0.8946, running_loss=0.9739, LR=0.000100
[2025-08-10 18:38:35,238][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049740] [Batch 01744/03692] [00:15:34/00:17:23, 0.536s/it]: train_loss_raw=0.8285, running_loss=0.9750, LR=0.000100
[2025-08-10 18:38:41,476][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049752] [Batch 01756/03692] [00:15:40/00:17:16, 0.536s/it]: train_loss_raw=1.0547, running_loss=0.9775, LR=0.000100
[2025-08-10 18:38:47,789][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049764] [Batch 01768/03692] [00:15:46/00:17:10, 0.535s/it]: train_loss_raw=1.0467, running_loss=0.9745, LR=0.000100
[2025-08-10 18:38:54,008][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049776] [Batch 01780/03692] [00:15:52/00:17:03, 0.535s/it]: train_loss_raw=1.1101, running_loss=0.9740, LR=0.000100
[2025-08-10 18:39:00,293][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049788] [Batch 01792/03692] [00:15:59/00:16:57, 0.535s/it]: train_loss_raw=0.9638, running_loss=0.9737, LR=0.000100
[2025-08-10 18:39:06,603][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049800] [Batch 01804/03692] [00:16:05/00:16:50, 0.535s/it]: train_loss_raw=0.9252, running_loss=0.9734, LR=0.000100
[2025-08-10 18:39:12,797][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049812] [Batch 01816/03692] [00:16:11/00:16:43, 0.535s/it]: train_loss_raw=0.9762, running_loss=0.9737, LR=0.000100
[2025-08-10 18:39:19,078][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049824] [Batch 01828/03692] [00:16:18/00:16:37, 0.535s/it]: train_loss_raw=0.8979, running_loss=0.9697, LR=0.000100
[2025-08-10 18:39:25,305][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049836] [Batch 01840/03692] [00:16:24/00:16:30, 0.535s/it]: train_loss_raw=0.9301, running_loss=0.9702, LR=0.000100
[2025-08-10 18:39:31,646][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049848] [Batch 01852/03692] [00:16:30/00:16:24, 0.535s/it]: train_loss_raw=1.0402, running_loss=0.9675, LR=0.000100
[2025-08-10 18:39:37,924][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049860] [Batch 01864/03692] [00:16:36/00:16:17, 0.535s/it]: train_loss_raw=1.0696, running_loss=0.9653, LR=0.000100
[2025-08-10 18:39:44,133][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049872] [Batch 01876/03692] [00:16:43/00:16:11, 0.535s/it]: train_loss_raw=0.9397, running_loss=0.9644, LR=0.000100
[2025-08-10 18:39:50,264][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049884] [Batch 01888/03692] [00:16:49/00:16:04, 0.535s/it]: train_loss_raw=0.8185, running_loss=0.9611, LR=0.000100
[2025-08-10 18:39:56,553][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049896] [Batch 01900/03692] [00:16:55/00:15:57, 0.534s/it]: train_loss_raw=0.9777, running_loss=0.9597, LR=0.000100
[2025-08-10 18:40:02,790][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049908] [Batch 01912/03692] [00:17:01/00:15:51, 0.534s/it]: train_loss_raw=0.8951, running_loss=0.9588, LR=0.000100
[2025-08-10 18:40:09,198][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049920] [Batch 01924/03692] [00:17:08/00:15:44, 0.534s/it]: train_loss_raw=0.9078, running_loss=0.9586, LR=0.000100
[2025-08-10 18:40:15,607][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049932] [Batch 01936/03692] [00:17:14/00:15:38, 0.534s/it]: train_loss_raw=0.9188, running_loss=0.9557, LR=0.000100
[2025-08-10 18:40:22,049][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049944] [Batch 01948/03692] [00:17:21/00:15:31, 0.534s/it]: train_loss_raw=1.0446, running_loss=0.9579, LR=0.000100
[2025-08-10 18:40:28,567][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049956] [Batch 01960/03692] [00:17:27/00:15:25, 0.534s/it]: train_loss_raw=1.0713, running_loss=0.9594, LR=0.000100
[2025-08-10 18:40:35,044][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049968] [Batch 01972/03692] [00:17:34/00:15:19, 0.534s/it]: train_loss_raw=0.9293, running_loss=0.9635, LR=0.000100
[2025-08-10 18:40:41,578][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049980] [Batch 01984/03692] [00:17:40/00:15:13, 0.535s/it]: train_loss_raw=0.9401, running_loss=0.9614, LR=0.000100
[2025-08-10 18:40:48,077][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049992] [Batch 01996/03692] [00:17:47/00:15:06, 0.535s/it]: train_loss_raw=1.0120, running_loss=0.9635, LR=0.000100
[2025-08-10 18:40:59,829][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050004] [Batch 02008/03692] [00:17:58/00:15:04, 0.537s/it]: train_loss_raw=0.8850, running_loss=0.9596, LR=0.000100
[2025-08-10 18:41:06,405][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050016] [Batch 02020/03692] [00:18:05/00:14:58, 0.537s/it]: train_loss_raw=1.0478, running_loss=0.9586, LR=0.000100
[2025-08-10 18:41:13,006][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050028] [Batch 02032/03692] [00:18:11/00:14:52, 0.537s/it]: train_loss_raw=0.9207, running_loss=0.9537, LR=0.000100
[2025-08-10 18:41:19,546][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050040] [Batch 02044/03692] [00:18:18/00:14:45, 0.537s/it]: train_loss_raw=1.0542, running_loss=0.9536, LR=0.000100
[2025-08-10 18:41:25,870][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050052] [Batch 02056/03692] [00:18:24/00:14:39, 0.537s/it]: train_loss_raw=1.0825, running_loss=0.9574, LR=0.000100
[2025-08-10 18:41:32,193][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050064] [Batch 02068/03692] [00:18:31/00:14:32, 0.537s/it]: train_loss_raw=0.9903, running_loss=0.9596, LR=0.000100
[2025-08-10 18:41:38,548][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050076] [Batch 02080/03692] [00:18:37/00:14:26, 0.537s/it]: train_loss_raw=0.9556, running_loss=0.9589, LR=0.000100
[2025-08-10 18:41:44,851][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050088] [Batch 02092/03692] [00:18:43/00:14:19, 0.537s/it]: train_loss_raw=0.9236, running_loss=0.9592, LR=0.000100
[2025-08-10 18:41:51,104][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050100] [Batch 02104/03692] [00:18:50/00:14:12, 0.537s/it]: train_loss_raw=0.9191, running_loss=0.9619, LR=0.000100
[2025-08-10 18:41:57,311][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050112] [Batch 02116/03692] [00:18:56/00:14:06, 0.537s/it]: train_loss_raw=1.0258, running_loss=0.9605, LR=0.000100
[2025-08-10 18:42:03,590][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050124] [Batch 02128/03692] [00:19:02/00:13:59, 0.537s/it]: train_loss_raw=0.9585, running_loss=0.9615, LR=0.000100
[2025-08-10 18:42:10,119][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050136] [Batch 02140/03692] [00:19:09/00:13:53, 0.537s/it]: train_loss_raw=0.9667, running_loss=0.9585, LR=0.000100
[2025-08-10 18:42:16,699][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050148] [Batch 02152/03692] [00:19:15/00:13:47, 0.537s/it]: train_loss_raw=1.0507, running_loss=0.9581, LR=0.000100
[2025-08-10 18:42:36,449][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050160] [Batch 02164/03692] [00:19:35/00:13:49, 0.543s/it]: train_loss_raw=0.9028, running_loss=0.9581, LR=0.000100
[2025-08-10 18:42:42,785][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050172] [Batch 02176/03692] [00:19:41/00:13:43, 0.543s/it]: train_loss_raw=1.0508, running_loss=0.9560, LR=0.000100
[2025-08-10 18:42:48,876][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050184] [Batch 02188/03692] [00:19:47/00:13:36, 0.543s/it]: train_loss_raw=1.0350, running_loss=0.9572, LR=0.000100
[2025-08-10 18:42:55,198][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050196] [Batch 02200/03692] [00:19:54/00:13:29, 0.543s/it]: train_loss_raw=1.0013, running_loss=0.9548, LR=0.000100
[2025-08-10 18:43:01,436][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050208] [Batch 02212/03692] [00:20:00/00:13:23, 0.543s/it]: train_loss_raw=0.9523, running_loss=0.9573, LR=0.000100
[2025-08-10 18:43:07,901][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050220] [Batch 02224/03692] [00:20:06/00:13:16, 0.543s/it]: train_loss_raw=0.8945, running_loss=0.9576, LR=0.000100
[2025-08-10 18:43:14,563][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050232] [Batch 02236/03692] [00:20:13/00:13:10, 0.543s/it]: train_loss_raw=0.9827, running_loss=0.9579, LR=0.000100
[2025-08-10 18:43:21,144][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050244] [Batch 02248/03692] [00:20:20/00:13:03, 0.543s/it]: train_loss_raw=0.9991, running_loss=0.9581, LR=0.000100
[2025-08-10 18:43:27,681][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050256] [Batch 02260/03692] [00:20:26/00:12:57, 0.543s/it]: train_loss_raw=0.8639, running_loss=0.9589, LR=0.000100
[2025-08-10 18:43:34,319][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050268] [Batch 02272/03692] [00:20:33/00:12:50, 0.543s/it]: train_loss_raw=1.0500, running_loss=0.9584, LR=0.000100
[2025-08-10 18:43:40,863][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050280] [Batch 02284/03692] [00:20:39/00:12:44, 0.543s/it]: train_loss_raw=1.0554, running_loss=0.9611, LR=0.000100
[2025-08-10 18:43:47,425][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050292] [Batch 02296/03692] [00:20:46/00:12:37, 0.543s/it]: train_loss_raw=0.9801, running_loss=0.9604, LR=0.000100
[2025-08-10 18:43:54,032][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050304] [Batch 02308/03692] [00:20:52/00:12:31, 0.543s/it]: train_loss_raw=0.9640, running_loss=0.9596, LR=0.000100
[2025-08-10 18:44:00,148][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050316] [Batch 02320/03692] [00:20:59/00:12:24, 0.543s/it]: train_loss_raw=0.9942, running_loss=0.9635, LR=0.000100
[2025-08-10 18:44:06,423][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050328] [Batch 02332/03692] [00:21:05/00:12:17, 0.543s/it]: train_loss_raw=0.9786, running_loss=0.9606, LR=0.000100
[2025-08-10 18:44:12,487][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050340] [Batch 02344/03692] [00:21:11/00:12:11, 0.542s/it]: train_loss_raw=1.0413, running_loss=0.9595, LR=0.000100
[2025-08-10 18:44:18,522][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050352] [Batch 02356/03692] [00:21:17/00:12:04, 0.542s/it]: train_loss_raw=0.9711, running_loss=0.9571, LR=0.000100
[2025-08-10 18:44:24,540][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050364] [Batch 02368/03692] [00:21:23/00:11:57, 0.542s/it]: train_loss_raw=1.0461, running_loss=0.9585, LR=0.000100
[2025-08-10 18:44:30,617][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050376] [Batch 02380/03692] [00:21:29/00:11:50, 0.542s/it]: train_loss_raw=1.0179, running_loss=0.9582, LR=0.000100
[2025-08-10 18:44:36,774][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050388] [Batch 02392/03692] [00:21:35/00:11:44, 0.542s/it]: train_loss_raw=1.1782, running_loss=0.9572, LR=0.000100
[2025-08-10 18:44:42,797][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050400] [Batch 02404/03692] [00:21:41/00:11:37, 0.541s/it]: train_loss_raw=1.0429, running_loss=0.9547, LR=0.000100
[2025-08-10 18:44:48,834][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050412] [Batch 02416/03692] [00:21:47/00:11:30, 0.541s/it]: train_loss_raw=0.9128, running_loss=0.9515, LR=0.000100
[2025-08-10 18:44:54,854][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050424] [Batch 02428/03692] [00:21:53/00:11:23, 0.541s/it]: train_loss_raw=1.0944, running_loss=0.9529, LR=0.000100
[2025-08-10 18:45:00,961][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050436] [Batch 02440/03692] [00:21:59/00:11:17, 0.541s/it]: train_loss_raw=0.9766, running_loss=0.9541, LR=0.000100
[2025-08-10 18:45:06,991][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050448] [Batch 02452/03692] [00:22:05/00:11:10, 0.541s/it]: train_loss_raw=1.0709, running_loss=0.9592, LR=0.000100
[2025-08-10 18:45:12,976][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050460] [Batch 02464/03692] [00:22:11/00:11:03, 0.541s/it]: train_loss_raw=0.9267, running_loss=0.9572, LR=0.000100
[2025-08-10 18:45:19,154][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050472] [Batch 02476/03692] [00:22:18/00:10:57, 0.540s/it]: train_loss_raw=0.8895, running_loss=0.9588, LR=0.000100
[2025-08-10 18:45:25,436][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050484] [Batch 02488/03692] [00:22:24/00:10:50, 0.540s/it]: train_loss_raw=0.9627, running_loss=0.9603, LR=0.000100
[2025-08-10 18:45:31,791][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050496] [Batch 02500/03692] [00:22:30/00:10:44, 0.540s/it]: train_loss_raw=0.9155, running_loss=0.9554, LR=0.000100
[2025-08-10 18:45:38,279][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050508] [Batch 02512/03692] [00:22:37/00:10:37, 0.540s/it]: train_loss_raw=0.9016, running_loss=0.9522, LR=0.000100
[2025-08-10 18:45:44,787][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050520] [Batch 02524/03692] [00:22:43/00:10:31, 0.540s/it]: train_loss_raw=0.8982, running_loss=0.9561, LR=0.000100
[2025-08-10 18:45:51,327][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050532] [Batch 02536/03692] [00:22:50/00:10:24, 0.540s/it]: train_loss_raw=0.9418, running_loss=0.9576, LR=0.000100
[2025-08-10 18:45:57,739][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050544] [Batch 02548/03692] [00:22:56/00:10:18, 0.540s/it]: train_loss_raw=0.9088, running_loss=0.9569, LR=0.000100
[2025-08-10 18:46:04,155][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050556] [Batch 02560/03692] [00:23:03/00:10:11, 0.540s/it]: train_loss_raw=1.0060, running_loss=0.9563, LR=0.000100
[2025-08-10 18:46:10,690][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050568] [Batch 02572/03692] [00:23:09/00:10:05, 0.540s/it]: train_loss_raw=0.8998, running_loss=0.9560, LR=0.000100
[2025-08-10 18:46:17,210][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050580] [Batch 02584/03692] [00:23:16/00:09:58, 0.540s/it]: train_loss_raw=0.8565, running_loss=0.9555, LR=0.000100
[2025-08-10 18:46:23,713][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050592] [Batch 02596/03692] [00:23:22/00:09:52, 0.540s/it]: train_loss_raw=0.9895, running_loss=0.9574, LR=0.000100
[2025-08-10 18:46:30,125][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050604] [Batch 02608/03692] [00:23:29/00:09:45, 0.540s/it]: train_loss_raw=1.0605, running_loss=0.9583, LR=0.000100
[2025-08-10 18:46:36,539][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050616] [Batch 02620/03692] [00:23:35/00:09:39, 0.540s/it]: train_loss_raw=0.9102, running_loss=0.9574, LR=0.000100
[2025-08-10 18:46:42,946][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050628] [Batch 02632/03692] [00:23:41/00:09:32, 0.540s/it]: train_loss_raw=0.8693, running_loss=0.9573, LR=0.000100
[2025-08-10 18:46:49,298][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050640] [Batch 02644/03692] [00:23:48/00:09:26, 0.540s/it]: train_loss_raw=1.0078, running_loss=0.9563, LR=0.000100
[2025-08-10 18:46:55,693][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050652] [Batch 02656/03692] [00:23:54/00:09:19, 0.540s/it]: train_loss_raw=0.8823, running_loss=0.9543, LR=0.000100
[2025-08-10 18:47:02,052][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050664] [Batch 02668/03692] [00:24:01/00:09:13, 0.540s/it]: train_loss_raw=1.0529, running_loss=0.9592, LR=0.000100
[2025-08-10 18:47:08,464][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050676] [Batch 02680/03692] [00:24:07/00:09:06, 0.540s/it]: train_loss_raw=0.9979, running_loss=0.9586, LR=0.000100
[2025-08-10 18:47:14,891][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050688] [Batch 02692/03692] [00:24:13/00:09:00, 0.540s/it]: train_loss_raw=0.9222, running_loss=0.9594, LR=0.000100
[2025-08-10 18:47:21,328][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050700] [Batch 02704/03692] [00:24:20/00:08:53, 0.540s/it]: train_loss_raw=0.9742, running_loss=0.9599, LR=0.000100
[2025-08-10 18:47:27,717][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050712] [Batch 02716/03692] [00:24:26/00:08:47, 0.540s/it]: train_loss_raw=0.8346, running_loss=0.9567, LR=0.000100
[2025-08-10 18:47:34,092][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050724] [Batch 02728/03692] [00:24:33/00:08:40, 0.540s/it]: train_loss_raw=0.9345, running_loss=0.9513, LR=0.000100
[2025-08-10 18:47:40,413][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050736] [Batch 02740/03692] [00:24:39/00:08:34, 0.540s/it]: train_loss_raw=0.9090, running_loss=0.9496, LR=0.000100
[2025-08-10 18:47:46,982][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050748] [Batch 02752/03692] [00:24:45/00:08:27, 0.540s/it]: train_loss_raw=0.9721, running_loss=0.9495, LR=0.000100
[2025-08-10 18:47:53,448][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050760] [Batch 02764/03692] [00:24:52/00:08:21, 0.540s/it]: train_loss_raw=0.9917, running_loss=0.9478, LR=0.000100
[2025-08-10 18:48:00,054][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050772] [Batch 02776/03692] [00:24:59/00:08:14, 0.540s/it]: train_loss_raw=0.9276, running_loss=0.9478, LR=0.000100
[2025-08-10 18:48:06,508][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050784] [Batch 02788/03692] [00:25:05/00:08:08, 0.540s/it]: train_loss_raw=0.9969, running_loss=0.9496, LR=0.000100
[2025-08-10 18:48:12,779][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050796] [Batch 02800/03692] [00:25:11/00:08:01, 0.540s/it]: train_loss_raw=0.9918, running_loss=0.9470, LR=0.000100
[2025-08-10 18:48:19,174][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050808] [Batch 02812/03692] [00:25:18/00:07:55, 0.540s/it]: train_loss_raw=1.0267, running_loss=0.9428, LR=0.000100
[2025-08-10 18:48:25,681][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050820] [Batch 02824/03692] [00:25:24/00:07:48, 0.540s/it]: train_loss_raw=0.8987, running_loss=0.9421, LR=0.000100
[2025-08-10 18:48:32,195][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050832] [Batch 02836/03692] [00:25:31/00:07:42, 0.540s/it]: train_loss_raw=0.8559, running_loss=0.9386, LR=0.000100
[2025-08-10 18:48:38,772][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050844] [Batch 02848/03692] [00:25:37/00:07:35, 0.540s/it]: train_loss_raw=1.1469, running_loss=0.9435, LR=0.000100
[2025-08-10 18:48:44,955][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050856] [Batch 02860/03692] [00:25:43/00:07:29, 0.540s/it]: train_loss_raw=0.9188, running_loss=0.9411, LR=0.000100
[2025-08-10 18:48:51,237][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050868] [Batch 02872/03692] [00:25:50/00:07:22, 0.540s/it]: train_loss_raw=0.9277, running_loss=0.9400, LR=0.000100
[2025-08-10 18:48:57,839][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050880] [Batch 02884/03692] [00:25:56/00:07:16, 0.540s/it]: train_loss_raw=1.0325, running_loss=0.9415, LR=0.000100
[2025-08-10 18:49:04,341][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050892] [Batch 02896/03692] [00:26:03/00:07:09, 0.540s/it]: train_loss_raw=0.9964, running_loss=0.9434, LR=0.000100
[2025-08-10 18:49:10,881][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050904] [Batch 02908/03692] [00:26:09/00:07:03, 0.540s/it]: train_loss_raw=0.9739, running_loss=0.9420, LR=0.000100
[2025-08-10 18:49:17,458][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050916] [Batch 02920/03692] [00:26:16/00:06:56, 0.540s/it]: train_loss_raw=0.9022, running_loss=0.9422, LR=0.000100
[2025-08-10 18:49:23,897][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050928] [Batch 02932/03692] [00:26:22/00:06:50, 0.540s/it]: train_loss_raw=1.0076, running_loss=0.9435, LR=0.000100
[2025-08-10 18:49:30,297][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050940] [Batch 02944/03692] [00:26:29/00:06:43, 0.540s/it]: train_loss_raw=0.8840, running_loss=0.9415, LR=0.000100
[2025-08-10 18:49:36,565][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050952] [Batch 02956/03692] [00:26:35/00:06:37, 0.540s/it]: train_loss_raw=1.1440, running_loss=0.9419, LR=0.000100
[2025-08-10 18:49:42,883][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050964] [Batch 02968/03692] [00:26:41/00:06:30, 0.540s/it]: train_loss_raw=1.1158, running_loss=0.9433, LR=0.000100
[2025-08-10 18:49:49,319][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050976] [Batch 02980/03692] [00:26:48/00:06:24, 0.540s/it]: train_loss_raw=1.0081, running_loss=0.9446, LR=0.000100
[2025-08-10 18:49:55,793][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050988] [Batch 02992/03692] [00:26:54/00:06:17, 0.540s/it]: train_loss_raw=0.8745, running_loss=0.9463, LR=0.000100
[2025-08-10 18:50:02,205][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051000] [Batch 03004/03692] [00:27:01/00:06:11, 0.540s/it]: train_loss_raw=1.0121, running_loss=0.9471, LR=0.000100
[2025-08-10 18:50:08,528][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051012] [Batch 03016/03692] [00:27:07/00:06:04, 0.540s/it]: train_loss_raw=0.8191, running_loss=0.9454, LR=0.000100
[2025-08-10 18:50:14,940][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051024] [Batch 03028/03692] [00:27:13/00:05:58, 0.540s/it]: train_loss_raw=0.9349, running_loss=0.9462, LR=0.000100
[2025-08-10 18:50:21,533][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051036] [Batch 03040/03692] [00:27:20/00:05:51, 0.540s/it]: train_loss_raw=0.8668, running_loss=0.9407, LR=0.000100
[2025-08-10 18:50:28,074][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051048] [Batch 03052/03692] [00:27:27/00:05:45, 0.540s/it]: train_loss_raw=0.9933, running_loss=0.9401, LR=0.000100
[2025-08-10 18:50:34,505][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051060] [Batch 03064/03692] [00:27:33/00:05:38, 0.540s/it]: train_loss_raw=0.8442, running_loss=0.9366, LR=0.000100
[2025-08-10 18:50:40,895][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051072] [Batch 03076/03692] [00:27:39/00:05:32, 0.540s/it]: train_loss_raw=0.9378, running_loss=0.9312, LR=0.000100
[2025-08-10 18:50:47,266][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051084] [Batch 03088/03692] [00:27:46/00:05:25, 0.540s/it]: train_loss_raw=0.8864, running_loss=0.9329, LR=0.000100
[2025-08-10 18:50:53,745][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051096] [Batch 03100/03692] [00:27:52/00:05:19, 0.540s/it]: train_loss_raw=0.9597, running_loss=0.9328, LR=0.000100
[2025-08-10 18:51:00,247][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051108] [Batch 03112/03692] [00:27:59/00:05:12, 0.540s/it]: train_loss_raw=0.9441, running_loss=0.9375, LR=0.000100
[2025-08-10 18:51:06,657][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051120] [Batch 03124/03692] [00:28:05/00:05:06, 0.540s/it]: train_loss_raw=0.8150, running_loss=0.9393, LR=0.000100
[2025-08-10 18:51:13,137][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051132] [Batch 03136/03692] [00:28:12/00:05:00, 0.540s/it]: train_loss_raw=0.9717, running_loss=0.9412, LR=0.000100
[2025-08-10 18:51:19,556][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051144] [Batch 03148/03692] [00:28:18/00:04:53, 0.540s/it]: train_loss_raw=1.0399, running_loss=0.9390, LR=0.000100
[2025-08-10 18:51:25,978][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051156] [Batch 03160/03692] [00:28:24/00:04:47, 0.540s/it]: train_loss_raw=0.8973, running_loss=0.9345, LR=0.000100
[2025-08-10 18:51:32,459][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051168] [Batch 03172/03692] [00:28:31/00:04:40, 0.540s/it]: train_loss_raw=0.9302, running_loss=0.9412, LR=0.000100
[2025-08-10 18:51:38,870][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051180] [Batch 03184/03692] [00:28:37/00:04:34, 0.540s/it]: train_loss_raw=0.8762, running_loss=0.9402, LR=0.000100
[2025-08-10 18:51:45,336][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051192] [Batch 03196/03692] [00:28:44/00:04:27, 0.540s/it]: train_loss_raw=1.0943, running_loss=0.9404, LR=0.000100
[2025-08-10 18:51:51,689][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051204] [Batch 03208/03692] [00:28:50/00:04:21, 0.539s/it]: train_loss_raw=1.0013, running_loss=0.9426, LR=0.000100
[2025-08-10 18:51:58,117][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051216] [Batch 03220/03692] [00:28:57/00:04:14, 0.539s/it]: train_loss_raw=0.9233, running_loss=0.9448, LR=0.000100
[2025-08-10 18:52:04,399][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051228] [Batch 03232/03692] [00:29:03/00:04:08, 0.539s/it]: train_loss_raw=0.9432, running_loss=0.9461, LR=0.000100
[2025-08-10 18:52:10,766][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051240] [Batch 03244/03692] [00:29:09/00:04:01, 0.539s/it]: train_loss_raw=0.9395, running_loss=0.9420, LR=0.000100
[2025-08-10 18:52:17,189][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051252] [Batch 03256/03692] [00:29:16/00:03:55, 0.539s/it]: train_loss_raw=0.9649, running_loss=0.9385, LR=0.000100
[2025-08-10 18:52:23,579][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051264] [Batch 03268/03692] [00:29:22/00:03:48, 0.539s/it]: train_loss_raw=1.0126, running_loss=0.9416, LR=0.000100
[2025-08-10 18:52:30,038][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051276] [Batch 03280/03692] [00:29:29/00:03:42, 0.539s/it]: train_loss_raw=0.8840, running_loss=0.9385, LR=0.000100
[2025-08-10 18:52:36,453][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051288] [Batch 03292/03692] [00:29:35/00:03:35, 0.539s/it]: train_loss_raw=0.9149, running_loss=0.9376, LR=0.000100
[2025-08-10 18:52:43,058][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051300] [Batch 03304/03692] [00:29:42/00:03:29, 0.539s/it]: train_loss_raw=0.9603, running_loss=0.9384, LR=0.000100
[2025-08-10 18:52:49,631][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051312] [Batch 03316/03692] [00:29:48/00:03:22, 0.539s/it]: train_loss_raw=0.8602, running_loss=0.9375, LR=0.000100
[2025-08-10 18:52:56,164][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051324] [Batch 03328/03692] [00:29:55/00:03:16, 0.539s/it]: train_loss_raw=0.9390, running_loss=0.9402, LR=0.000100
[2025-08-10 18:53:02,748][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051336] [Batch 03340/03692] [00:30:01/00:03:09, 0.539s/it]: train_loss_raw=0.9848, running_loss=0.9444, LR=0.000100
[2025-08-10 18:53:09,158][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051348] [Batch 03352/03692] [00:30:08/00:03:03, 0.539s/it]: train_loss_raw=0.8640, running_loss=0.9443, LR=0.000100
[2025-08-10 18:53:15,526][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051360] [Batch 03364/03692] [00:30:14/00:02:56, 0.539s/it]: train_loss_raw=0.9415, running_loss=0.9452, LR=0.000100
[2025-08-10 18:53:21,942][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051372] [Batch 03376/03692] [00:30:20/00:02:50, 0.539s/it]: train_loss_raw=0.8800, running_loss=0.9489, LR=0.000100
[2025-08-10 18:53:28,333][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051384] [Batch 03388/03692] [00:30:27/00:02:43, 0.539s/it]: train_loss_raw=0.8947, running_loss=0.9492, LR=0.000100
[2025-08-10 18:53:34,718][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051396] [Batch 03400/03692] [00:30:33/00:02:37, 0.539s/it]: train_loss_raw=0.9665, running_loss=0.9471, LR=0.000100
[2025-08-10 18:53:41,124][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051408] [Batch 03412/03692] [00:30:40/00:02:31, 0.539s/it]: train_loss_raw=0.9534, running_loss=0.9439, LR=0.000100
[2025-08-10 18:53:47,642][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051420] [Batch 03424/03692] [00:30:46/00:02:24, 0.539s/it]: train_loss_raw=1.0622, running_loss=0.9418, LR=0.000100
[2025-08-10 18:53:54,187][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051432] [Batch 03436/03692] [00:30:53/00:02:18, 0.539s/it]: train_loss_raw=0.8829, running_loss=0.9441, LR=0.000100
[2025-08-10 18:54:00,702][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051444] [Batch 03448/03692] [00:30:59/00:02:11, 0.539s/it]: train_loss_raw=0.8926, running_loss=0.9395, LR=0.000100
[2025-08-10 18:54:07,202][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051456] [Batch 03460/03692] [00:31:06/00:02:05, 0.539s/it]: train_loss_raw=1.0288, running_loss=0.9403, LR=0.000100
[2025-08-10 18:54:13,750][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051468] [Batch 03472/03692] [00:31:12/00:01:58, 0.539s/it]: train_loss_raw=1.0091, running_loss=0.9433, LR=0.000100
[2025-08-10 18:54:20,149][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051480] [Batch 03484/03692] [00:31:19/00:01:52, 0.539s/it]: train_loss_raw=0.9793, running_loss=0.9423, LR=0.000100
[2025-08-10 18:54:26,505][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051492] [Batch 03496/03692] [00:31:25/00:01:45, 0.539s/it]: train_loss_raw=0.9871, running_loss=0.9427, LR=0.000100
[2025-08-10 18:54:32,978][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051504] [Batch 03508/03692] [00:31:31/00:01:39, 0.539s/it]: train_loss_raw=0.7766, running_loss=0.9396, LR=0.000100
[2025-08-10 18:54:39,495][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051516] [Batch 03520/03692] [00:31:38/00:01:32, 0.539s/it]: train_loss_raw=0.9030, running_loss=0.9402, LR=0.000100
[2025-08-10 18:54:45,989][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051528] [Batch 03532/03692] [00:31:44/00:01:26, 0.539s/it]: train_loss_raw=0.8660, running_loss=0.9388, LR=0.000100
[2025-08-10 18:54:52,363][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051540] [Batch 03544/03692] [00:31:51/00:01:19, 0.539s/it]: train_loss_raw=0.9561, running_loss=0.9387, LR=0.000100
[2025-08-10 18:54:58,880][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051552] [Batch 03556/03692] [00:31:57/00:01:13, 0.539s/it]: train_loss_raw=0.8626, running_loss=0.9424, LR=0.000100
[2025-08-10 18:55:05,410][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051564] [Batch 03568/03692] [00:32:04/00:01:06, 0.539s/it]: train_loss_raw=0.8144, running_loss=0.9426, LR=0.000100
[2025-08-10 18:55:11,961][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051576] [Batch 03580/03692] [00:32:10/00:01:00, 0.539s/it]: train_loss_raw=0.9425, running_loss=0.9388, LR=0.000100
[2025-08-10 18:55:18,474][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051588] [Batch 03592/03692] [00:32:17/00:00:53, 0.539s/it]: train_loss_raw=0.8557, running_loss=0.9375, LR=0.000100
[2025-08-10 18:55:24,960][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051600] [Batch 03604/03692] [00:32:23/00:00:47, 0.539s/it]: train_loss_raw=0.8963, running_loss=0.9353, LR=0.000100
[2025-08-10 18:55:31,377][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051612] [Batch 03616/03692] [00:32:30/00:00:40, 0.539s/it]: train_loss_raw=0.9259, running_loss=0.9327, LR=0.000100
[2025-08-10 18:55:37,754][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051624] [Batch 03628/03692] [00:32:36/00:00:34, 0.539s/it]: train_loss_raw=0.9006, running_loss=0.9330, LR=0.000100
[2025-08-10 18:55:44,093][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051636] [Batch 03640/03692] [00:32:43/00:00:28, 0.539s/it]: train_loss_raw=0.8271, running_loss=0.9342, LR=0.000100
[2025-08-10 18:55:50,450][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051648] [Batch 03652/03692] [00:32:49/00:00:21, 0.539s/it]: train_loss_raw=0.9317, running_loss=0.9348, LR=0.000100
[2025-08-10 18:55:56,847][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051660] [Batch 03664/03692] [00:32:55/00:00:15, 0.539s/it]: train_loss_raw=0.9543, running_loss=0.9375, LR=0.000100
[2025-08-10 18:56:03,147][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051672] [Batch 03676/03692] [00:33:02/00:00:08, 0.539s/it]: train_loss_raw=0.7939, running_loss=0.9352, LR=0.000100
[2025-08-10 18:56:09,509][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051684] [Batch 03688/03692] [00:33:08/00:00:02, 0.539s/it]: train_loss_raw=0.8300, running_loss=0.9302, LR=0.000100
[2025-08-10 18:56:40,478][__main__][INFO] - [VALIDATION] [Epoch 13/29] Starting validation.
[2025-08-10 18:57:14,816][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 051689] [Batch 00011/00025] [00:00:34/00:00:37, 2.861s/it]
[2025-08-10 18:57:30,826][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 051689] [Batch 00023/00025] [00:00:50/00:00:02, 2.098s/it]
[2025-08-10 18:57:31,809][__main__][INFO] - [VALIDATION] [Epoch 13/29] train_loss=0.93188, valid_loss=0.95767
[2025-08-10 18:57:31,809][__main__][INFO] - [VALIDATION] [Epoch 13/29] Metrics:
[2025-08-10 18:57:31,809][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_er      0.426
[2025-08-10 18:57:31,809][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_prec    0.313
[2025-08-10 18:57:31,809][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_recall  0.319
[2025-08-10 18:57:31,809][__main__][INFO] - [VALIDATION] [Epoch 13/29] - pep_recall 0.276
[2025-08-10 18:57:31,813][__main__][INFO] - [TRAIN] [Epoch 13/29] Epoch complete, total time 08:01:31, remaining time 09:10:18, 00:34:23 per epoch
[2025-08-10 18:57:35,826][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051696] [Batch 00008/03692] [00:00:03/00:28:58, 0.472s/it]: train_loss_raw=0.7601, running_loss=0.9490, LR=0.000100
[2025-08-10 18:57:42,291][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051708] [Batch 00020/03692] [00:00:10/00:31:19, 0.512s/it]: train_loss_raw=0.8575, running_loss=0.9413, LR=0.000100
[2025-08-10 18:57:48,744][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051720] [Batch 00032/03692] [00:00:16/00:31:49, 0.522s/it]: train_loss_raw=0.9230, running_loss=0.9300, LR=0.000100
[2025-08-10 18:57:55,268][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051732] [Batch 00044/03692] [00:00:23/00:32:04, 0.528s/it]: train_loss_raw=0.7687, running_loss=0.9219, LR=0.000100
[2025-08-10 18:58:01,740][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051744] [Batch 00056/03692] [00:00:29/00:32:07, 0.530s/it]: train_loss_raw=0.8713, running_loss=0.9141, LR=0.000100
[2025-08-10 18:58:08,252][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051756] [Batch 00068/03692] [00:00:36/00:32:09, 0.532s/it]: train_loss_raw=0.9078, running_loss=0.9099, LR=0.000100
[2025-08-10 18:58:14,801][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051768] [Batch 00080/03692] [00:00:42/00:32:10, 0.534s/it]: train_loss_raw=0.8483, running_loss=0.9077, LR=0.000100
[2025-08-10 18:58:21,343][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051780] [Batch 00092/03692] [00:00:49/00:32:08, 0.536s/it]: train_loss_raw=0.8464, running_loss=0.9001, LR=0.000100
[2025-08-10 18:58:27,897][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051792] [Batch 00104/03692] [00:00:55/00:32:06, 0.537s/it]: train_loss_raw=0.7953, running_loss=0.8931, LR=0.000100
[2025-08-10 18:58:34,520][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051804] [Batch 00116/03692] [00:01:02/00:32:05, 0.539s/it]: train_loss_raw=0.8595, running_loss=0.8875, LR=0.000100
[2025-08-10 18:58:41,012][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051816] [Batch 00128/03692] [00:01:08/00:32:00, 0.539s/it]: train_loss_raw=0.8649, running_loss=0.8875, LR=0.000100
[2025-08-10 18:58:47,437][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051828] [Batch 00140/03692] [00:01:15/00:31:52, 0.538s/it]: train_loss_raw=0.9170, running_loss=0.8881, LR=0.000100
[2025-08-10 18:58:53,808][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051840] [Batch 00152/03692] [00:01:21/00:31:44, 0.538s/it]: train_loss_raw=0.9000, running_loss=0.8846, LR=0.000100
[2025-08-10 18:59:00,265][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051852] [Batch 00164/03692] [00:01:28/00:31:37, 0.538s/it]: train_loss_raw=0.9937, running_loss=0.8813, LR=0.000100
[2025-08-10 18:59:06,585][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051864] [Batch 00176/03692] [00:01:34/00:31:28, 0.537s/it]: train_loss_raw=0.8400, running_loss=0.8812, LR=0.000100
[2025-08-10 18:59:12,947][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051876] [Batch 00188/03692] [00:01:40/00:31:20, 0.537s/it]: train_loss_raw=0.9481, running_loss=0.8808, LR=0.000100
[2025-08-10 18:59:19,360][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051888] [Batch 00200/03692] [00:01:47/00:31:13, 0.537s/it]: train_loss_raw=0.9235, running_loss=0.8802, LR=0.000100
[2025-08-10 18:59:25,882][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051900] [Batch 00212/03692] [00:01:53/00:31:08, 0.537s/it]: train_loss_raw=0.9492, running_loss=0.8812, LR=0.000100
[2025-08-10 18:59:32,269][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051912] [Batch 00224/03692] [00:02:00/00:31:01, 0.537s/it]: train_loss_raw=0.8717, running_loss=0.8818, LR=0.000100
[2025-08-10 18:59:38,672][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051924] [Batch 00236/03692] [00:02:06/00:30:54, 0.537s/it]: train_loss_raw=0.8992, running_loss=0.8789, LR=0.000100
[2025-08-10 18:59:45,071][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051936] [Batch 00248/03692] [00:02:13/00:30:47, 0.536s/it]: train_loss_raw=0.8210, running_loss=0.8804, LR=0.000100
[2025-08-10 18:59:51,421][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051948] [Batch 00260/03692] [00:02:19/00:30:39, 0.536s/it]: train_loss_raw=0.9513, running_loss=0.8816, LR=0.000100
[2025-08-10 18:59:57,905][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051960] [Batch 00272/03692] [00:02:25/00:30:33, 0.536s/it]: train_loss_raw=0.8928, running_loss=0.8841, LR=0.000100
[2025-08-10 19:00:04,400][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051972] [Batch 00284/03692] [00:02:32/00:30:28, 0.536s/it]: train_loss_raw=0.9013, running_loss=0.8802, LR=0.000100
[2025-08-10 19:00:10,982][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051984] [Batch 00296/03692] [00:02:38/00:30:23, 0.537s/it]: train_loss_raw=0.8648, running_loss=0.8764, LR=0.000100
[2025-08-10 19:00:17,591][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051996] [Batch 00308/03692] [00:02:45/00:30:18, 0.537s/it]: train_loss_raw=0.9010, running_loss=0.8725, LR=0.000100
[2025-08-10 19:00:28,527][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052008] [Batch 00320/03692] [00:02:56/00:30:59, 0.551s/it]: train_loss_raw=0.9598, running_loss=0.8726, LR=0.000100
[2025-08-10 19:00:34,847][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052020] [Batch 00332/03692] [00:03:02/00:30:49, 0.551s/it]: train_loss_raw=0.9185, running_loss=0.8747, LR=0.000100
[2025-08-10 19:00:41,258][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052032] [Batch 00344/03692] [00:03:09/00:30:41, 0.550s/it]: train_loss_raw=0.8929, running_loss=0.8765, LR=0.000100
[2025-08-10 19:00:47,754][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052044] [Batch 00356/03692] [00:03:15/00:30:33, 0.550s/it]: train_loss_raw=0.7687, running_loss=0.8726, LR=0.000100
[2025-08-10 19:00:54,304][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052056] [Batch 00368/03692] [00:03:22/00:30:26, 0.550s/it]: train_loss_raw=0.9200, running_loss=0.8725, LR=0.000100
[2025-08-10 19:01:00,797][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052068] [Batch 00380/03692] [00:03:28/00:30:19, 0.549s/it]: train_loss_raw=0.7350, running_loss=0.8725, LR=0.000100
[2025-08-10 19:01:07,250][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052080] [Batch 00392/03692] [00:03:35/00:30:11, 0.549s/it]: train_loss_raw=0.8513, running_loss=0.8751, LR=0.000100
[2025-08-10 19:01:13,727][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052092] [Batch 00404/03692] [00:03:41/00:30:04, 0.549s/it]: train_loss_raw=0.9255, running_loss=0.8792, LR=0.000100
[2025-08-10 19:01:20,140][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052104] [Batch 00416/03692] [00:03:48/00:29:56, 0.548s/it]: train_loss_raw=0.8884, running_loss=0.8797, LR=0.000100
[2025-08-10 19:01:26,660][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052116] [Batch 00428/03692] [00:03:54/00:29:49, 0.548s/it]: train_loss_raw=0.8773, running_loss=0.8773, LR=0.000100
[2025-08-10 19:01:33,214][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052128] [Batch 00440/03692] [00:04:01/00:29:42, 0.548s/it]: train_loss_raw=0.8658, running_loss=0.8766, LR=0.000100
[2025-08-10 19:01:39,737][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052140] [Batch 00452/03692] [00:04:07/00:29:35, 0.548s/it]: train_loss_raw=0.8940, running_loss=0.8746, LR=0.000100
[2025-08-10 19:01:46,224][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052152] [Batch 00464/03692] [00:04:14/00:29:28, 0.548s/it]: train_loss_raw=0.8653, running_loss=0.8702, LR=0.000100
[2025-08-10 19:01:52,685][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052164] [Batch 00476/03692] [00:04:20/00:29:20, 0.548s/it]: train_loss_raw=0.8204, running_loss=0.8679, LR=0.000100
[2025-08-10 19:01:59,166][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052176] [Batch 00488/03692] [00:04:27/00:29:13, 0.547s/it]: train_loss_raw=0.8823, running_loss=0.8692, LR=0.000100
[2025-08-10 19:02:05,805][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052188] [Batch 00500/03692] [00:04:33/00:29:07, 0.548s/it]: train_loss_raw=0.8913, running_loss=0.8686, LR=0.000100
[2025-08-10 19:02:12,320][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052200] [Batch 00512/03692] [00:04:40/00:29:00, 0.547s/it]: train_loss_raw=1.0417, running_loss=0.8709, LR=0.000100
[2025-08-10 19:02:18,804][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052212] [Batch 00524/03692] [00:04:46/00:28:53, 0.547s/it]: train_loss_raw=0.7873, running_loss=0.8711, LR=0.000100
[2025-08-10 19:02:25,162][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052224] [Batch 00536/03692] [00:04:53/00:28:45, 0.547s/it]: train_loss_raw=0.9028, running_loss=0.8721, LR=0.000100
[2025-08-10 19:02:31,478][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052236] [Batch 00548/03692] [00:04:59/00:28:37, 0.546s/it]: train_loss_raw=0.8205, running_loss=0.8748, LR=0.000100
[2025-08-10 19:02:37,735][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052248] [Batch 00560/03692] [00:05:05/00:28:29, 0.546s/it]: train_loss_raw=0.9506, running_loss=0.8783, LR=0.000100
[2025-08-10 19:02:43,922][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052260] [Batch 00572/03692] [00:05:11/00:28:21, 0.545s/it]: train_loss_raw=0.9064, running_loss=0.8774, LR=0.000100
[2025-08-10 19:02:50,320][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052272] [Batch 00584/03692] [00:05:18/00:28:13, 0.545s/it]: train_loss_raw=0.8185, running_loss=0.8799, LR=0.000100
[2025-08-10 19:02:56,584][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052284] [Batch 00596/03692] [00:05:24/00:28:05, 0.545s/it]: train_loss_raw=0.9776, running_loss=0.8803, LR=0.000100
[2025-08-10 19:03:02,965][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052296] [Batch 00608/03692] [00:05:30/00:27:58, 0.544s/it]: train_loss_raw=0.8538, running_loss=0.8774, LR=0.000100
[2025-08-10 19:03:09,414][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052308] [Batch 00620/03692] [00:05:37/00:27:51, 0.544s/it]: train_loss_raw=0.8117, running_loss=0.8794, LR=0.000100
[2025-08-10 19:03:15,782][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052320] [Batch 00632/03692] [00:05:43/00:27:44, 0.544s/it]: train_loss_raw=0.8649, running_loss=0.8840, LR=0.000100
[2025-08-10 19:03:22,147][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052332] [Batch 00644/03692] [00:05:50/00:27:36, 0.544s/it]: train_loss_raw=0.8365, running_loss=0.8798, LR=0.000100
[2025-08-10 19:03:28,668][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052344] [Batch 00656/03692] [00:05:56/00:27:30, 0.544s/it]: train_loss_raw=0.9219, running_loss=0.8851, LR=0.000100
[2025-08-10 19:03:35,136][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052356] [Batch 00668/03692] [00:06:03/00:27:23, 0.544s/it]: train_loss_raw=0.9320, running_loss=0.8824, LR=0.000100
[2025-08-10 19:03:41,681][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052368] [Batch 00680/03692] [00:06:09/00:27:17, 0.544s/it]: train_loss_raw=0.9234, running_loss=0.8820, LR=0.000100
[2025-08-10 19:03:48,273][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052380] [Batch 00692/03692] [00:06:16/00:27:11, 0.544s/it]: train_loss_raw=0.8251, running_loss=0.8796, LR=0.000100
[2025-08-10 19:03:54,752][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052392] [Batch 00704/03692] [00:06:22/00:27:04, 0.544s/it]: train_loss_raw=0.9780, running_loss=0.8804, LR=0.000100
[2025-08-10 19:04:01,182][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052404] [Batch 00716/03692] [00:06:29/00:26:57, 0.543s/it]: train_loss_raw=0.7829, running_loss=0.8821, LR=0.000100
[2025-08-10 19:04:07,582][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052416] [Batch 00728/03692] [00:06:35/00:26:50, 0.543s/it]: train_loss_raw=0.9009, running_loss=0.8830, LR=0.000100
[2025-08-10 19:04:13,965][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052428] [Batch 00740/03692] [00:06:41/00:26:43, 0.543s/it]: train_loss_raw=0.9444, running_loss=0.8848, LR=0.000100
[2025-08-10 19:04:20,367][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052440] [Batch 00752/03692] [00:06:48/00:26:36, 0.543s/it]: train_loss_raw=0.8486, running_loss=0.8834, LR=0.000100
[2025-08-10 19:04:26,785][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052452] [Batch 00764/03692] [00:06:54/00:26:29, 0.543s/it]: train_loss_raw=0.9672, running_loss=0.8828, LR=0.000100
[2025-08-10 19:04:33,256][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052464] [Batch 00776/03692] [00:07:01/00:26:22, 0.543s/it]: train_loss_raw=1.0812, running_loss=0.8831, LR=0.000100
[2025-08-10 19:04:39,681][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052476] [Batch 00788/03692] [00:07:07/00:26:15, 0.543s/it]: train_loss_raw=0.8653, running_loss=0.8865, LR=0.000100
[2025-08-10 19:04:46,280][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052488] [Batch 00800/03692] [00:07:14/00:26:09, 0.543s/it]: train_loss_raw=0.8668, running_loss=0.8872, LR=0.000100
[2025-08-10 19:04:52,735][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052500] [Batch 00812/03692] [00:07:20/00:26:03, 0.543s/it]: train_loss_raw=0.8643, running_loss=0.8858, LR=0.000100
[2025-08-10 19:04:59,226][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052512] [Batch 00824/03692] [00:07:27/00:25:56, 0.543s/it]: train_loss_raw=0.7404, running_loss=0.8876, LR=0.000100
[2025-08-10 19:05:05,648][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052524] [Batch 00836/03692] [00:07:33/00:25:49, 0.543s/it]: train_loss_raw=0.7355, running_loss=0.8880, LR=0.000100
[2025-08-10 19:05:11,997][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052536] [Batch 00848/03692] [00:07:39/00:25:42, 0.542s/it]: train_loss_raw=0.9855, running_loss=0.8895, LR=0.000100
[2025-08-10 19:05:18,397][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052548] [Batch 00860/03692] [00:07:46/00:25:35, 0.542s/it]: train_loss_raw=0.9023, running_loss=0.8892, LR=0.000100
[2025-08-10 19:05:24,799][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052560] [Batch 00872/03692] [00:07:52/00:25:28, 0.542s/it]: train_loss_raw=0.9631, running_loss=0.8927, LR=0.000100
[2025-08-10 19:05:31,171][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052572] [Batch 00884/03692] [00:07:59/00:25:21, 0.542s/it]: train_loss_raw=0.8999, running_loss=0.8880, LR=0.000100
[2025-08-10 19:05:37,469][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052584] [Batch 00896/03692] [00:08:05/00:25:14, 0.542s/it]: train_loss_raw=0.9312, running_loss=0.8846, LR=0.000100
[2025-08-10 19:05:43,905][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052596] [Batch 00908/03692] [00:08:11/00:25:08, 0.542s/it]: train_loss_raw=0.7487, running_loss=0.8841, LR=0.000100
[2025-08-10 19:05:50,334][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052608] [Batch 00920/03692] [00:08:18/00:25:01, 0.542s/it]: train_loss_raw=0.8254, running_loss=0.8830, LR=0.000100
[2025-08-10 19:05:56,766][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052620] [Batch 00932/03692] [00:08:24/00:24:54, 0.542s/it]: train_loss_raw=0.8989, running_loss=0.8835, LR=0.000100
[2025-08-10 19:06:03,291][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052632] [Batch 00944/03692] [00:08:31/00:24:48, 0.542s/it]: train_loss_raw=0.7736, running_loss=0.8803, LR=0.000100
[2025-08-10 19:06:09,809][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052644] [Batch 00956/03692] [00:08:37/00:24:41, 0.542s/it]: train_loss_raw=0.9333, running_loss=0.8807, LR=0.000100
[2025-08-10 19:06:16,438][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052656] [Batch 00968/03692] [00:08:44/00:24:35, 0.542s/it]: train_loss_raw=0.9363, running_loss=0.8782, LR=0.000100
[2025-08-10 19:06:23,034][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052668] [Batch 00980/03692] [00:08:50/00:24:29, 0.542s/it]: train_loss_raw=0.8662, running_loss=0.8763, LR=0.000100
[2025-08-10 19:06:29,505][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052680] [Batch 00992/03692] [00:08:57/00:24:22, 0.542s/it]: train_loss_raw=0.8377, running_loss=0.8765, LR=0.000100
[2025-08-10 19:06:35,910][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052692] [Batch 01004/03692] [00:09:03/00:24:16, 0.542s/it]: train_loss_raw=0.8677, running_loss=0.8809, LR=0.000100
[2025-08-10 19:06:42,232][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052704] [Batch 01016/03692] [00:09:10/00:24:09, 0.542s/it]: train_loss_raw=0.7760, running_loss=0.8770, LR=0.000100
[2025-08-10 19:06:48,661][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052716] [Batch 01028/03692] [00:09:16/00:24:02, 0.541s/it]: train_loss_raw=0.7470, running_loss=0.8786, LR=0.000100
[2025-08-10 19:06:55,094][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052728] [Batch 01040/03692] [00:09:23/00:23:55, 0.541s/it]: train_loss_raw=0.9412, running_loss=0.8810, LR=0.000100
[2025-08-10 19:07:01,384][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052740] [Batch 01052/03692] [00:09:29/00:23:48, 0.541s/it]: train_loss_raw=0.8805, running_loss=0.8838, LR=0.000100
[2025-08-10 19:07:07,805][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052752] [Batch 01064/03692] [00:09:35/00:23:42, 0.541s/it]: train_loss_raw=0.8989, running_loss=0.8841, LR=0.000100
[2025-08-10 19:07:14,301][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052764] [Batch 01076/03692] [00:09:42/00:23:35, 0.541s/it]: train_loss_raw=0.9047, running_loss=0.8848, LR=0.000100
[2025-08-10 19:07:20,833][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052776] [Batch 01088/03692] [00:09:48/00:23:29, 0.541s/it]: train_loss_raw=0.8724, running_loss=0.8872, LR=0.000100
[2025-08-10 19:07:27,444][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052788] [Batch 01100/03692] [00:09:55/00:23:22, 0.541s/it]: train_loss_raw=0.8821, running_loss=0.8886, LR=0.000100
[2025-08-10 19:07:33,962][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052800] [Batch 01112/03692] [00:10:01/00:23:16, 0.541s/it]: train_loss_raw=0.8452, running_loss=0.8869, LR=0.000100
[2025-08-10 19:07:40,592][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052812] [Batch 01124/03692] [00:10:08/00:23:10, 0.541s/it]: train_loss_raw=0.8821, running_loss=0.8861, LR=0.000100
[2025-08-10 19:07:46,985][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052824] [Batch 01136/03692] [00:10:14/00:23:03, 0.541s/it]: train_loss_raw=0.8695, running_loss=0.8822, LR=0.000100
[2025-08-10 19:07:53,422][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052836] [Batch 01148/03692] [00:10:21/00:22:56, 0.541s/it]: train_loss_raw=0.9926, running_loss=0.8769, LR=0.000100
[2025-08-10 19:07:59,885][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052848] [Batch 01160/03692] [00:10:27/00:22:50, 0.541s/it]: train_loss_raw=0.8209, running_loss=0.8777, LR=0.000100
[2025-08-10 19:08:06,384][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052860] [Batch 01172/03692] [00:10:34/00:22:43, 0.541s/it]: train_loss_raw=0.9440, running_loss=0.8762, LR=0.000100
[2025-08-10 19:08:12,925][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052872] [Batch 01184/03692] [00:10:40/00:22:37, 0.541s/it]: train_loss_raw=0.8462, running_loss=0.8736, LR=0.000100
[2025-08-10 19:08:19,485][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052884] [Batch 01196/03692] [00:10:47/00:22:31, 0.541s/it]: train_loss_raw=0.8698, running_loss=0.8709, LR=0.000100
[2025-08-10 19:08:25,866][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052896] [Batch 01208/03692] [00:10:53/00:22:24, 0.541s/it]: train_loss_raw=0.7862, running_loss=0.8729, LR=0.000100
[2025-08-10 19:08:32,412][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052908] [Batch 01220/03692] [00:11:00/00:22:18, 0.541s/it]: train_loss_raw=0.9216, running_loss=0.8711, LR=0.000100
[2025-08-10 19:08:39,006][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052920] [Batch 01232/03692] [00:11:06/00:22:11, 0.541s/it]: train_loss_raw=0.8646, running_loss=0.8711, LR=0.000100
[2025-08-10 19:08:45,367][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052932] [Batch 01244/03692] [00:11:13/00:22:04, 0.541s/it]: train_loss_raw=0.8834, running_loss=0.8702, LR=0.000100
[2025-08-10 19:08:51,783][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052944] [Batch 01256/03692] [00:11:19/00:21:58, 0.541s/it]: train_loss_raw=0.9099, running_loss=0.8712, LR=0.000100
[2025-08-10 19:08:58,199][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052956] [Batch 01268/03692] [00:11:26/00:21:51, 0.541s/it]: train_loss_raw=0.8165, running_loss=0.8697, LR=0.000100
[2025-08-10 19:09:04,634][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052968] [Batch 01280/03692] [00:11:32/00:21:45, 0.541s/it]: train_loss_raw=0.8853, running_loss=0.8703, LR=0.000100
[2025-08-10 19:09:11,119][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052980] [Batch 01292/03692] [00:11:39/00:21:38, 0.541s/it]: train_loss_raw=0.7508, running_loss=0.8693, LR=0.000100
[2025-08-10 19:09:17,513][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052992] [Batch 01304/03692] [00:11:45/00:21:31, 0.541s/it]: train_loss_raw=0.9347, running_loss=0.8700, LR=0.000100
[2025-08-10 19:09:23,890][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053004] [Batch 01316/03692] [00:11:51/00:21:25, 0.541s/it]: train_loss_raw=0.8918, running_loss=0.8696, LR=0.000100
[2025-08-10 19:09:30,305][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053016] [Batch 01328/03692] [00:11:58/00:21:18, 0.541s/it]: train_loss_raw=0.9329, running_loss=0.8700, LR=0.000100
[2025-08-10 19:09:36,683][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053028] [Batch 01340/03692] [00:12:04/00:21:11, 0.541s/it]: train_loss_raw=0.8822, running_loss=0.8657, LR=0.000100
[2025-08-10 19:09:42,937][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053040] [Batch 01352/03692] [00:12:10/00:21:04, 0.541s/it]: train_loss_raw=0.7290, running_loss=0.8687, LR=0.000100
[2025-08-10 19:09:49,275][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053052] [Batch 01364/03692] [00:12:17/00:20:58, 0.540s/it]: train_loss_raw=0.8197, running_loss=0.8675, LR=0.000100
[2025-08-10 19:09:55,686][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053064] [Batch 01376/03692] [00:12:23/00:20:51, 0.540s/it]: train_loss_raw=0.9361, running_loss=0.8669, LR=0.000100
[2025-08-10 19:10:02,102][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053076] [Batch 01388/03692] [00:12:30/00:20:45, 0.540s/it]: train_loss_raw=0.9676, running_loss=0.8678, LR=0.000100
[2025-08-10 19:10:08,596][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053088] [Batch 01400/03692] [00:12:36/00:20:38, 0.540s/it]: train_loss_raw=0.8752, running_loss=0.8687, LR=0.000100
[2025-08-10 19:10:14,975][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053100] [Batch 01412/03692] [00:12:42/00:20:31, 0.540s/it]: train_loss_raw=0.7394, running_loss=0.8693, LR=0.000100
[2025-08-10 19:10:21,373][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053112] [Batch 01424/03692] [00:12:49/00:20:25, 0.540s/it]: train_loss_raw=0.8501, running_loss=0.8684, LR=0.000100
[2025-08-10 19:10:27,720][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053124] [Batch 01436/03692] [00:12:55/00:20:18, 0.540s/it]: train_loss_raw=0.8381, running_loss=0.8638, LR=0.000100
[2025-08-10 19:10:34,049][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053136] [Batch 01448/03692] [00:13:01/00:20:11, 0.540s/it]: train_loss_raw=0.8588, running_loss=0.8584, LR=0.000100
[2025-08-10 19:10:40,352][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053148] [Batch 01460/03692] [00:13:08/00:20:05, 0.540s/it]: train_loss_raw=0.8371, running_loss=0.8563, LR=0.000100
[2025-08-10 19:10:46,745][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053160] [Batch 01472/03692] [00:13:14/00:19:58, 0.540s/it]: train_loss_raw=0.8044, running_loss=0.8565, LR=0.000100
[2025-08-10 19:10:53,307][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053172] [Batch 01484/03692] [00:13:21/00:19:52, 0.540s/it]: train_loss_raw=0.8317, running_loss=0.8585, LR=0.000100
[2025-08-10 19:10:59,859][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053184] [Batch 01496/03692] [00:13:27/00:19:45, 0.540s/it]: train_loss_raw=0.9249, running_loss=0.8606, LR=0.000100
[2025-08-10 19:11:06,387][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053196] [Batch 01508/03692] [00:13:34/00:19:39, 0.540s/it]: train_loss_raw=0.8499, running_loss=0.8667, LR=0.000100
[2025-08-10 19:11:13,053][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053208] [Batch 01520/03692] [00:13:41/00:19:33, 0.540s/it]: train_loss_raw=0.8767, running_loss=0.8681, LR=0.000100
[2025-08-10 19:11:19,513][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053220] [Batch 01532/03692] [00:13:47/00:19:26, 0.540s/it]: train_loss_raw=0.8959, running_loss=0.8701, LR=0.000100
[2025-08-10 19:11:49,033][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053232] [Batch 01544/03692] [00:14:16/00:19:52, 0.555s/it]: train_loss_raw=0.8473, running_loss=0.8715, LR=0.000100
[2025-08-10 19:11:55,447][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053244] [Batch 01556/03692] [00:14:23/00:19:45, 0.555s/it]: train_loss_raw=0.8420, running_loss=0.8709, LR=0.000100
[2025-08-10 19:12:01,965][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053256] [Batch 01568/03692] [00:14:29/00:19:38, 0.555s/it]: train_loss_raw=0.8870, running_loss=0.8730, LR=0.000100
[2025-08-10 19:12:08,526][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053268] [Batch 01580/03692] [00:14:36/00:19:31, 0.555s/it]: train_loss_raw=0.8412, running_loss=0.8747, LR=0.000100
[2025-08-10 19:12:15,091][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053280] [Batch 01592/03692] [00:14:43/00:19:24, 0.555s/it]: train_loss_raw=0.8986, running_loss=0.8722, LR=0.000100
[2025-08-10 19:12:21,654][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053292] [Batch 01604/03692] [00:14:49/00:19:18, 0.555s/it]: train_loss_raw=0.7873, running_loss=0.8785, LR=0.000100
[2025-08-10 19:12:28,177][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053304] [Batch 01616/03692] [00:14:56/00:19:11, 0.555s/it]: train_loss_raw=0.8815, running_loss=0.8819, LR=0.000100
[2025-08-10 19:12:34,470][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053316] [Batch 01628/03692] [00:15:02/00:19:04, 0.554s/it]: train_loss_raw=0.9233, running_loss=0.8883, LR=0.000100
[2025-08-10 19:12:40,855][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053328] [Batch 01640/03692] [00:15:08/00:18:57, 0.554s/it]: train_loss_raw=0.9219, running_loss=0.8901, LR=0.000100
[2025-08-10 19:12:47,233][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053340] [Batch 01652/03692] [00:15:15/00:18:50, 0.554s/it]: train_loss_raw=0.8010, running_loss=0.8910, LR=0.000100
[2025-08-10 19:12:53,718][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053352] [Batch 01664/03692] [00:15:21/00:18:43, 0.554s/it]: train_loss_raw=0.9011, running_loss=0.8921, LR=0.000100
[2025-08-10 19:13:00,151][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053364] [Batch 01676/03692] [00:15:28/00:18:36, 0.554s/it]: train_loss_raw=0.8162, running_loss=0.8911, LR=0.000100
[2025-08-10 19:13:06,685][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053376] [Batch 01688/03692] [00:15:34/00:18:29, 0.554s/it]: train_loss_raw=0.8747, running_loss=0.8847, LR=0.000100
[2025-08-10 19:13:13,208][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053388] [Batch 01700/03692] [00:15:41/00:18:22, 0.554s/it]: train_loss_raw=0.9302, running_loss=0.8851, LR=0.000100
[2025-08-10 19:13:19,733][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053400] [Batch 01712/03692] [00:15:47/00:18:16, 0.554s/it]: train_loss_raw=0.9311, running_loss=0.8851, LR=0.000100
[2025-08-10 19:13:26,270][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053412] [Batch 01724/03692] [00:15:54/00:18:09, 0.553s/it]: train_loss_raw=0.8767, running_loss=0.8846, LR=0.000100
[2025-08-10 19:13:32,707][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053424] [Batch 01736/03692] [00:16:00/00:18:02, 0.553s/it]: train_loss_raw=0.9066, running_loss=0.8865, LR=0.000100
[2025-08-10 19:13:39,073][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053436] [Batch 01748/03692] [00:16:07/00:17:55, 0.553s/it]: train_loss_raw=0.9498, running_loss=0.8886, LR=0.000100
[2025-08-10 19:13:45,345][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053448] [Batch 01760/03692] [00:16:13/00:17:48, 0.553s/it]: train_loss_raw=0.8077, running_loss=0.8805, LR=0.000100
[2025-08-10 19:13:51,885][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053460] [Batch 01772/03692] [00:16:19/00:17:41, 0.553s/it]: train_loss_raw=0.9335, running_loss=0.8802, LR=0.000100
[2025-08-10 19:13:58,346][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053472] [Batch 01784/03692] [00:16:26/00:17:34, 0.553s/it]: train_loss_raw=0.9183, running_loss=0.8842, LR=0.000100
[2025-08-10 19:14:04,870][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053484] [Batch 01796/03692] [00:16:32/00:17:28, 0.553s/it]: train_loss_raw=0.9020, running_loss=0.8862, LR=0.000100
[2025-08-10 19:14:11,429][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053496] [Batch 01808/03692] [00:16:39/00:17:21, 0.553s/it]: train_loss_raw=0.9087, running_loss=0.8853, LR=0.000100
[2025-08-10 19:14:17,986][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053508] [Batch 01820/03692] [00:16:45/00:17:14, 0.553s/it]: train_loss_raw=0.8841, running_loss=0.8874, LR=0.000100
[2025-08-10 19:14:24,407][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053520] [Batch 01832/03692] [00:16:52/00:17:07, 0.553s/it]: train_loss_raw=0.9790, running_loss=0.8909, LR=0.000100
[2025-08-10 19:14:30,888][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053532] [Batch 01844/03692] [00:16:58/00:17:01, 0.553s/it]: train_loss_raw=0.9841, running_loss=0.8917, LR=0.000100
[2025-08-10 19:14:37,372][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053544] [Batch 01856/03692] [00:17:05/00:16:54, 0.552s/it]: train_loss_raw=0.8226, running_loss=0.8899, LR=0.000100
[2025-08-10 19:14:43,827][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053556] [Batch 01868/03692] [00:17:11/00:16:47, 0.552s/it]: train_loss_raw=0.7196, running_loss=0.8903, LR=0.000100
[2025-08-10 19:14:50,334][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053568] [Batch 01880/03692] [00:17:18/00:16:40, 0.552s/it]: train_loss_raw=0.8756, running_loss=0.8877, LR=0.000100
[2025-08-10 19:14:56,875][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053580] [Batch 01892/03692] [00:17:24/00:16:34, 0.552s/it]: train_loss_raw=1.0327, running_loss=0.8866, LR=0.000100
[2025-08-10 19:15:03,376][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053592] [Batch 01904/03692] [00:17:31/00:16:27, 0.552s/it]: train_loss_raw=1.0748, running_loss=0.8894, LR=0.000100
[2025-08-10 19:15:09,863][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053604] [Batch 01916/03692] [00:17:37/00:16:20, 0.552s/it]: train_loss_raw=0.8985, running_loss=0.8851, LR=0.000100
[2025-08-10 19:15:16,424][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053616] [Batch 01928/03692] [00:17:44/00:16:13, 0.552s/it]: train_loss_raw=0.8265, running_loss=0.8854, LR=0.000100
[2025-08-10 19:15:22,784][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053628] [Batch 01940/03692] [00:17:50/00:16:06, 0.552s/it]: train_loss_raw=0.8152, running_loss=0.8873, LR=0.000100
[2025-08-10 19:15:29,283][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053640] [Batch 01952/03692] [00:17:57/00:16:00, 0.552s/it]: train_loss_raw=0.8831, running_loss=0.8923, LR=0.000100
[2025-08-10 19:15:35,808][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053652] [Batch 01964/03692] [00:18:03/00:15:53, 0.552s/it]: train_loss_raw=0.8633, running_loss=0.8899, LR=0.000100
[2025-08-10 19:15:42,266][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053664] [Batch 01976/03692] [00:18:10/00:15:46, 0.552s/it]: train_loss_raw=0.8787, running_loss=0.8876, LR=0.000100
[2025-08-10 19:15:48,695][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053676] [Batch 01988/03692] [00:18:16/00:15:39, 0.552s/it]: train_loss_raw=0.8805, running_loss=0.8888, LR=0.000100
[2025-08-10 19:15:55,162][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053688] [Batch 02000/03692] [00:18:23/00:15:33, 0.552s/it]: train_loss_raw=0.8713, running_loss=0.8870, LR=0.000100
[2025-08-10 19:16:01,531][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053700] [Batch 02012/03692] [00:18:29/00:15:26, 0.551s/it]: train_loss_raw=0.7838, running_loss=0.8893, LR=0.000100
[2025-08-10 19:16:08,007][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053712] [Batch 02024/03692] [00:18:35/00:15:19, 0.551s/it]: train_loss_raw=0.9886, running_loss=0.8923, LR=0.000100
[2025-08-10 19:16:14,551][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053724] [Batch 02036/03692] [00:18:42/00:15:12, 0.551s/it]: train_loss_raw=0.8570, running_loss=0.8955, LR=0.000100
[2025-08-10 19:16:20,911][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053736] [Batch 02048/03692] [00:18:48/00:15:06, 0.551s/it]: train_loss_raw=0.8197, running_loss=0.8921, LR=0.000100
[2025-08-10 19:16:27,306][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053748] [Batch 02060/03692] [00:18:55/00:14:59, 0.551s/it]: train_loss_raw=0.9710, running_loss=0.8964, LR=0.000100
[2025-08-10 19:16:33,766][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053760] [Batch 02072/03692] [00:19:01/00:14:52, 0.551s/it]: train_loss_raw=0.9354, running_loss=0.8957, LR=0.000100
[2025-08-10 19:16:40,171][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053772] [Batch 02084/03692] [00:19:08/00:14:45, 0.551s/it]: train_loss_raw=1.0596, running_loss=0.8937, LR=0.000100
[2025-08-10 19:16:46,642][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053784] [Batch 02096/03692] [00:19:14/00:14:39, 0.551s/it]: train_loss_raw=0.8048, running_loss=0.8924, LR=0.000100
[2025-08-10 19:16:53,079][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053796] [Batch 02108/03692] [00:19:21/00:14:32, 0.551s/it]: train_loss_raw=1.0461, running_loss=0.8948, LR=0.000100
[2025-08-10 19:16:59,422][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053808] [Batch 02120/03692] [00:19:27/00:14:25, 0.551s/it]: train_loss_raw=0.9945, running_loss=0.8960, LR=0.000100
[2025-08-10 19:17:05,808][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053820] [Batch 02132/03692] [00:19:33/00:14:18, 0.551s/it]: train_loss_raw=0.9628, running_loss=0.8971, LR=0.000100
[2025-08-10 19:17:12,208][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053832] [Batch 02144/03692] [00:19:40/00:14:12, 0.550s/it]: train_loss_raw=0.9308, running_loss=0.8930, LR=0.000100
[2025-08-10 19:17:18,626][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053844] [Batch 02156/03692] [00:19:46/00:14:05, 0.550s/it]: train_loss_raw=0.9334, running_loss=0.8876, LR=0.000100
[2025-08-10 19:17:25,030][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053856] [Batch 02168/03692] [00:19:52/00:13:58, 0.550s/it]: train_loss_raw=0.8491, running_loss=0.8874, LR=0.000100
[2025-08-10 19:17:31,434][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053868] [Batch 02180/03692] [00:19:59/00:13:51, 0.550s/it]: train_loss_raw=0.8746, running_loss=0.8919, LR=0.000100
[2025-08-10 19:17:37,886][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053880] [Batch 02192/03692] [00:20:05/00:13:45, 0.550s/it]: train_loss_raw=0.9127, running_loss=0.8927, LR=0.000100
[2025-08-10 19:17:44,262][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053892] [Batch 02204/03692] [00:20:12/00:13:38, 0.550s/it]: train_loss_raw=1.0288, running_loss=0.8905, LR=0.000100
[2025-08-10 19:17:50,661][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053904] [Batch 02216/03692] [00:20:18/00:13:31, 0.550s/it]: train_loss_raw=0.8260, running_loss=0.8886, LR=0.000100
[2025-08-10 19:17:57,109][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053916] [Batch 02228/03692] [00:20:25/00:13:24, 0.550s/it]: train_loss_raw=0.8037, running_loss=0.8899, LR=0.000100
[2025-08-10 19:18:03,543][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053928] [Batch 02240/03692] [00:20:31/00:13:18, 0.550s/it]: train_loss_raw=0.9348, running_loss=0.8914, LR=0.000100
[2025-08-10 19:18:09,948][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053940] [Batch 02252/03692] [00:20:37/00:13:11, 0.550s/it]: train_loss_raw=0.8118, running_loss=0.8897, LR=0.000100
[2025-08-10 19:18:16,424][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053952] [Batch 02264/03692] [00:20:44/00:13:04, 0.550s/it]: train_loss_raw=0.8930, running_loss=0.8905, LR=0.000100
[2025-08-10 19:18:22,915][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053964] [Batch 02276/03692] [00:20:50/00:12:58, 0.550s/it]: train_loss_raw=0.8674, running_loss=0.8869, LR=0.000100
[2025-08-10 19:18:29,435][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053976] [Batch 02288/03692] [00:20:57/00:12:51, 0.550s/it]: train_loss_raw=0.9622, running_loss=0.8903, LR=0.000100
[2025-08-10 19:18:35,850][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053988] [Batch 02300/03692] [00:21:03/00:12:44, 0.549s/it]: train_loss_raw=0.8669, running_loss=0.8857, LR=0.000100
[2025-08-10 19:18:42,204][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054000] [Batch 02312/03692] [00:21:10/00:12:38, 0.549s/it]: train_loss_raw=0.8916, running_loss=0.8870, LR=0.000100
[2025-08-10 19:18:53,075][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054012] [Batch 02324/03692] [00:21:21/00:12:34, 0.551s/it]: train_loss_raw=0.9058, running_loss=0.8838, LR=0.000100
[2025-08-10 19:18:59,537][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054024] [Batch 02336/03692] [00:21:27/00:12:27, 0.551s/it]: train_loss_raw=0.9806, running_loss=0.8843, LR=0.000100
[2025-08-10 19:19:06,059][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054036] [Batch 02348/03692] [00:21:34/00:12:20, 0.551s/it]: train_loss_raw=0.9667, running_loss=0.8842, LR=0.000100
[2025-08-10 19:19:12,536][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054048] [Batch 02360/03692] [00:21:40/00:12:14, 0.551s/it]: train_loss_raw=0.8176, running_loss=0.8834, LR=0.000100
[2025-08-10 19:19:19,093][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054060] [Batch 02372/03692] [00:21:47/00:12:07, 0.551s/it]: train_loss_raw=0.7998, running_loss=0.8838, LR=0.000100
[2025-08-10 19:19:25,625][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054072] [Batch 02384/03692] [00:21:53/00:12:00, 0.551s/it]: train_loss_raw=0.7685, running_loss=0.8818, LR=0.000100
[2025-08-10 19:19:32,129][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054084] [Batch 02396/03692] [00:22:00/00:11:54, 0.551s/it]: train_loss_raw=0.9228, running_loss=0.8848, LR=0.000100
[2025-08-10 19:19:38,545][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054096] [Batch 02408/03692] [00:22:06/00:11:47, 0.551s/it]: train_loss_raw=0.9693, running_loss=0.8877, LR=0.000100
[2025-08-10 19:19:45,035][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054108] [Batch 02420/03692] [00:22:12/00:11:40, 0.551s/it]: train_loss_raw=0.9053, running_loss=0.8871, LR=0.000100
[2025-08-10 19:19:51,430][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054120] [Batch 02432/03692] [00:22:19/00:11:33, 0.551s/it]: train_loss_raw=0.8479, running_loss=0.8835, LR=0.000100
[2025-08-10 19:19:57,824][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054132] [Batch 02444/03692] [00:22:25/00:11:27, 0.551s/it]: train_loss_raw=0.7766, running_loss=0.8844, LR=0.000100
[2025-08-10 19:20:04,258][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054144] [Batch 02456/03692] [00:22:32/00:11:20, 0.551s/it]: train_loss_raw=0.8983, running_loss=0.8831, LR=0.000100
[2025-08-10 19:20:10,729][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054156] [Batch 02468/03692] [00:22:38/00:11:13, 0.551s/it]: train_loss_raw=0.8153, running_loss=0.8845, LR=0.000100
[2025-08-10 19:20:17,236][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054168] [Batch 02480/03692] [00:22:45/00:11:07, 0.550s/it]: train_loss_raw=0.8258, running_loss=0.8800, LR=0.000100
[2025-08-10 19:20:23,733][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054180] [Batch 02492/03692] [00:22:51/00:11:00, 0.550s/it]: train_loss_raw=0.9908, running_loss=0.8814, LR=0.000100
[2025-08-10 19:20:30,194][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054192] [Batch 02504/03692] [00:22:58/00:10:53, 0.550s/it]: train_loss_raw=0.9333, running_loss=0.8814, LR=0.000100
[2025-08-10 19:20:36,770][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054204] [Batch 02516/03692] [00:23:04/00:10:47, 0.550s/it]: train_loss_raw=0.9176, running_loss=0.8809, LR=0.000100
[2025-08-10 19:20:43,311][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054216] [Batch 02528/03692] [00:23:11/00:10:40, 0.550s/it]: train_loss_raw=0.8959, running_loss=0.8793, LR=0.000100
[2025-08-10 19:20:49,819][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054228] [Batch 02540/03692] [00:23:17/00:10:33, 0.550s/it]: train_loss_raw=0.9450, running_loss=0.8837, LR=0.000100
[2025-08-10 19:20:56,374][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054240] [Batch 02552/03692] [00:23:24/00:10:27, 0.550s/it]: train_loss_raw=0.9104, running_loss=0.8834, LR=0.000100
[2025-08-10 19:21:02,797][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054252] [Batch 02564/03692] [00:23:30/00:10:20, 0.550s/it]: train_loss_raw=0.7293, running_loss=0.8811, LR=0.000100
[2025-08-10 19:21:09,261][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054264] [Batch 02576/03692] [00:23:37/00:10:13, 0.550s/it]: train_loss_raw=0.8471, running_loss=0.8795, LR=0.000100
[2025-08-10 19:21:15,656][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054276] [Batch 02588/03692] [00:23:43/00:10:07, 0.550s/it]: train_loss_raw=0.8462, running_loss=0.8761, LR=0.000100
[2025-08-10 19:21:22,088][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054288] [Batch 02600/03692] [00:23:50/00:10:00, 0.550s/it]: train_loss_raw=0.9018, running_loss=0.8767, LR=0.000100
[2025-08-10 19:21:28,541][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054300] [Batch 02612/03692] [00:23:56/00:09:53, 0.550s/it]: train_loss_raw=0.8902, running_loss=0.8777, LR=0.000100
[2025-08-10 19:21:34,934][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054312] [Batch 02624/03692] [00:24:02/00:09:47, 0.550s/it]: train_loss_raw=0.7842, running_loss=0.8760, LR=0.000100
[2025-08-10 19:21:41,337][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054324] [Batch 02636/03692] [00:24:09/00:09:40, 0.550s/it]: train_loss_raw=0.9576, running_loss=0.8761, LR=0.000100
[2025-08-10 19:21:47,813][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054336] [Batch 02648/03692] [00:24:15/00:09:33, 0.550s/it]: train_loss_raw=0.8499, running_loss=0.8755, LR=0.000100
[2025-08-10 19:21:54,224][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054348] [Batch 02660/03692] [00:24:22/00:09:27, 0.550s/it]: train_loss_raw=0.9208, running_loss=0.8784, LR=0.000100
[2025-08-10 19:22:00,641][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054360] [Batch 02672/03692] [00:24:28/00:09:20, 0.550s/it]: train_loss_raw=0.8431, running_loss=0.8775, LR=0.000100
[2025-08-10 19:22:07,146][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054372] [Batch 02684/03692] [00:24:35/00:09:13, 0.550s/it]: train_loss_raw=0.9459, running_loss=0.8780, LR=0.000100
[2025-08-10 19:22:13,593][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054384] [Batch 02696/03692] [00:24:41/00:09:07, 0.550s/it]: train_loss_raw=0.8735, running_loss=0.8780, LR=0.000100
[2025-08-10 19:22:19,990][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054396] [Batch 02708/03692] [00:24:47/00:09:00, 0.549s/it]: train_loss_raw=0.8068, running_loss=0.8801, LR=0.000100
[2025-08-10 19:22:26,347][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054408] [Batch 02720/03692] [00:24:54/00:08:53, 0.549s/it]: train_loss_raw=0.9097, running_loss=0.8772, LR=0.000100
[2025-08-10 19:22:32,697][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054420] [Batch 02732/03692] [00:25:00/00:08:47, 0.549s/it]: train_loss_raw=0.8979, running_loss=0.8721, LR=0.000100
[2025-08-10 19:22:39,133][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054432] [Batch 02744/03692] [00:25:07/00:08:40, 0.549s/it]: train_loss_raw=0.8826, running_loss=0.8766, LR=0.000100
[2025-08-10 19:22:45,575][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054444] [Batch 02756/03692] [00:25:13/00:08:34, 0.549s/it]: train_loss_raw=0.9222, running_loss=0.8779, LR=0.000100
[2025-08-10 19:22:51,945][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054456] [Batch 02768/03692] [00:25:19/00:08:27, 0.549s/it]: train_loss_raw=0.9020, running_loss=0.8797, LR=0.000100
[2025-08-10 19:22:58,418][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054468] [Batch 02780/03692] [00:25:26/00:08:20, 0.549s/it]: train_loss_raw=0.9863, running_loss=0.8817, LR=0.000100
[2025-08-10 19:23:04,766][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054480] [Batch 02792/03692] [00:25:32/00:08:14, 0.549s/it]: train_loss_raw=0.8395, running_loss=0.8770, LR=0.000100
[2025-08-10 19:23:11,171][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054492] [Batch 02804/03692] [00:25:39/00:08:07, 0.549s/it]: train_loss_raw=0.8215, running_loss=0.8743, LR=0.000100
[2025-08-10 19:23:17,569][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054504] [Batch 02816/03692] [00:25:45/00:08:00, 0.549s/it]: train_loss_raw=0.8576, running_loss=0.8770, LR=0.000100
[2025-08-10 19:23:23,956][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054516] [Batch 02828/03692] [00:25:51/00:07:54, 0.549s/it]: train_loss_raw=0.8638, running_loss=0.8786, LR=0.000100
[2025-08-10 19:23:30,364][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054528] [Batch 02840/03692] [00:25:58/00:07:47, 0.549s/it]: train_loss_raw=0.8345, running_loss=0.8777, LR=0.000100
[2025-08-10 19:23:36,825][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054540] [Batch 02852/03692] [00:26:04/00:07:40, 0.549s/it]: train_loss_raw=0.8969, running_loss=0.8779, LR=0.000100
[2025-08-10 19:23:43,181][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054552] [Batch 02864/03692] [00:26:11/00:07:34, 0.549s/it]: train_loss_raw=0.7856, running_loss=0.8771, LR=0.000100
[2025-08-10 19:23:49,600][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054564] [Batch 02876/03692] [00:26:17/00:07:27, 0.549s/it]: train_loss_raw=0.7985, running_loss=0.8782, LR=0.000100
[2025-08-10 19:23:56,010][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054576] [Batch 02888/03692] [00:26:23/00:07:20, 0.548s/it]: train_loss_raw=0.7962, running_loss=0.8750, LR=0.000100
[2025-08-10 19:24:02,435][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054588] [Batch 02900/03692] [00:26:30/00:07:14, 0.548s/it]: train_loss_raw=0.9696, running_loss=0.8783, LR=0.000100
[2025-08-10 19:24:08,839][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054600] [Batch 02912/03692] [00:26:36/00:07:07, 0.548s/it]: train_loss_raw=0.8408, running_loss=0.8785, LR=0.000100
[2025-08-10 19:24:15,198][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054612] [Batch 02924/03692] [00:26:43/00:07:01, 0.548s/it]: train_loss_raw=0.8384, running_loss=0.8770, LR=0.000100
[2025-08-10 19:24:21,657][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054624] [Batch 02936/03692] [00:26:49/00:06:54, 0.548s/it]: train_loss_raw=0.8956, running_loss=0.8702, LR=0.000100
[2025-08-10 19:24:28,265][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054636] [Batch 02948/03692] [00:26:56/00:06:47, 0.548s/it]: train_loss_raw=0.9072, running_loss=0.8659, LR=0.000100
[2025-08-10 19:24:34,717][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054648] [Batch 02960/03692] [00:27:02/00:06:41, 0.548s/it]: train_loss_raw=0.8675, running_loss=0.8679, LR=0.000100
[2025-08-10 19:24:41,215][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054660] [Batch 02972/03692] [00:27:09/00:06:34, 0.548s/it]: train_loss_raw=0.9631, running_loss=0.8684, LR=0.000100
[2025-08-10 19:24:47,529][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054672] [Batch 02984/03692] [00:27:15/00:06:28, 0.548s/it]: train_loss_raw=0.9266, running_loss=0.8696, LR=0.000100
[2025-08-10 19:24:54,022][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054684] [Batch 02996/03692] [00:27:21/00:06:21, 0.548s/it]: train_loss_raw=0.8896, running_loss=0.8675, LR=0.000100
[2025-08-10 19:25:00,450][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054696] [Batch 03008/03692] [00:27:28/00:06:14, 0.548s/it]: train_loss_raw=0.9077, running_loss=0.8668, LR=0.000100
[2025-08-10 19:25:06,858][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054708] [Batch 03020/03692] [00:27:34/00:06:08, 0.548s/it]: train_loss_raw=0.9887, running_loss=0.8682, LR=0.000100
[2025-08-10 19:25:13,262][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054720] [Batch 03032/03692] [00:27:41/00:06:01, 0.548s/it]: train_loss_raw=0.8183, running_loss=0.8656, LR=0.000100
[2025-08-10 19:25:19,633][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054732] [Batch 03044/03692] [00:27:47/00:05:54, 0.548s/it]: train_loss_raw=0.8511, running_loss=0.8648, LR=0.000100
[2025-08-10 19:25:26,065][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054744] [Batch 03056/03692] [00:27:54/00:05:48, 0.548s/it]: train_loss_raw=0.7664, running_loss=0.8642, LR=0.000100
[2025-08-10 19:25:32,504][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054756] [Batch 03068/03692] [00:28:00/00:05:41, 0.548s/it]: train_loss_raw=0.8298, running_loss=0.8627, LR=0.000100
[2025-08-10 19:25:38,953][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054768] [Batch 03080/03692] [00:28:06/00:05:35, 0.548s/it]: train_loss_raw=0.9096, running_loss=0.8634, LR=0.000100
[2025-08-10 19:25:45,416][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054780] [Batch 03092/03692] [00:28:13/00:05:28, 0.548s/it]: train_loss_raw=1.0955, running_loss=0.8684, LR=0.000100
[2025-08-10 19:25:51,851][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054792] [Batch 03104/03692] [00:28:19/00:05:21, 0.548s/it]: train_loss_raw=0.8449, running_loss=0.8699, LR=0.000100
[2025-08-10 19:25:58,336][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054804] [Batch 03116/03692] [00:28:26/00:05:15, 0.548s/it]: train_loss_raw=0.8780, running_loss=0.8698, LR=0.000100
[2025-08-10 19:26:04,869][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054816] [Batch 03128/03692] [00:28:32/00:05:08, 0.548s/it]: train_loss_raw=0.8377, running_loss=0.8675, LR=0.000100
[2025-08-10 19:26:11,345][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054828] [Batch 03140/03692] [00:28:39/00:05:02, 0.548s/it]: train_loss_raw=0.8994, running_loss=0.8670, LR=0.000100
[2025-08-10 19:26:17,759][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054840] [Batch 03152/03692] [00:28:45/00:04:55, 0.547s/it]: train_loss_raw=0.9394, running_loss=0.8705, LR=0.000100
[2025-08-10 19:26:24,167][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054852] [Batch 03164/03692] [00:28:52/00:04:49, 0.547s/it]: train_loss_raw=1.0232, running_loss=0.8715, LR=0.000100
[2025-08-10 19:26:30,571][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054864] [Batch 03176/03692] [00:28:58/00:04:42, 0.547s/it]: train_loss_raw=0.9000, running_loss=0.8706, LR=0.000100
[2025-08-10 19:26:36,948][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054876] [Batch 03188/03692] [00:29:04/00:04:35, 0.547s/it]: train_loss_raw=0.8719, running_loss=0.8717, LR=0.000100
[2025-08-10 19:26:43,378][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054888] [Batch 03200/03692] [00:29:11/00:04:29, 0.547s/it]: train_loss_raw=0.8400, running_loss=0.8724, LR=0.000100
[2025-08-10 19:26:49,742][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054900] [Batch 03212/03692] [00:29:17/00:04:22, 0.547s/it]: train_loss_raw=0.8561, running_loss=0.8725, LR=0.000100
[2025-08-10 19:26:56,165][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054912] [Batch 03224/03692] [00:29:24/00:04:16, 0.547s/it]: train_loss_raw=0.8449, running_loss=0.8731, LR=0.000100
[2025-08-10 19:27:02,846][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054924] [Batch 03236/03692] [00:29:30/00:04:09, 0.547s/it]: train_loss_raw=0.7513, running_loss=0.8737, LR=0.000100
[2025-08-10 19:27:09,262][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054936] [Batch 03248/03692] [00:29:37/00:04:02, 0.547s/it]: train_loss_raw=0.8113, running_loss=0.8721, LR=0.000100
[2025-08-10 19:27:15,799][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054948] [Batch 03260/03692] [00:29:43/00:03:56, 0.547s/it]: train_loss_raw=0.8526, running_loss=0.8705, LR=0.000100
[2025-08-10 19:27:22,336][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054960] [Batch 03272/03692] [00:29:50/00:03:49, 0.547s/it]: train_loss_raw=0.8482, running_loss=0.8749, LR=0.000100
[2025-08-10 19:27:28,833][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054972] [Batch 03284/03692] [00:29:56/00:03:43, 0.547s/it]: train_loss_raw=0.8421, running_loss=0.8749, LR=0.000100
[2025-08-10 19:27:35,244][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054984] [Batch 03296/03692] [00:30:03/00:03:36, 0.547s/it]: train_loss_raw=0.7988, running_loss=0.8760, LR=0.000100
[2025-08-10 19:27:41,630][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054996] [Batch 03308/03692] [00:30:09/00:03:30, 0.547s/it]: train_loss_raw=0.7783, running_loss=0.8743, LR=0.000100
[2025-08-10 19:27:48,010][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055008] [Batch 03320/03692] [00:30:15/00:03:23, 0.547s/it]: train_loss_raw=0.8890, running_loss=0.8709, LR=0.000100
[2025-08-10 19:27:54,378][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055020] [Batch 03332/03692] [00:30:22/00:03:16, 0.547s/it]: train_loss_raw=0.8287, running_loss=0.8681, LR=0.000100
[2025-08-10 19:28:00,824][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055032] [Batch 03344/03692] [00:30:28/00:03:10, 0.547s/it]: train_loss_raw=0.6607, running_loss=0.8670, LR=0.000100
[2025-08-10 19:28:07,231][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055044] [Batch 03356/03692] [00:30:35/00:03:03, 0.547s/it]: train_loss_raw=0.8826, running_loss=0.8654, LR=0.000100
[2025-08-10 19:28:13,685][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055056] [Batch 03368/03692] [00:30:41/00:02:57, 0.547s/it]: train_loss_raw=0.9017, running_loss=0.8699, LR=0.000100
[2025-08-10 19:28:20,016][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055068] [Batch 03380/03692] [00:30:47/00:02:50, 0.547s/it]: train_loss_raw=0.8802, running_loss=0.8701, LR=0.000100
[2025-08-10 19:28:26,461][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055080] [Batch 03392/03692] [00:30:54/00:02:44, 0.547s/it]: train_loss_raw=0.8477, running_loss=0.8714, LR=0.000100
[2025-08-10 19:28:32,817][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055092] [Batch 03404/03692] [00:31:00/00:02:37, 0.547s/it]: train_loss_raw=0.7618, running_loss=0.8636, LR=0.000100
[2025-08-10 19:28:39,245][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055104] [Batch 03416/03692] [00:31:07/00:02:30, 0.547s/it]: train_loss_raw=0.8702, running_loss=0.8634, LR=0.000100
[2025-08-10 19:28:45,822][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055116] [Batch 03428/03692] [00:31:13/00:02:24, 0.547s/it]: train_loss_raw=0.8297, running_loss=0.8622, LR=0.000100
[2025-08-10 19:28:52,332][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055128] [Batch 03440/03692] [00:31:20/00:02:17, 0.547s/it]: train_loss_raw=0.8505, running_loss=0.8614, LR=0.000100
[2025-08-10 19:28:58,891][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055140] [Batch 03452/03692] [00:31:26/00:02:11, 0.547s/it]: train_loss_raw=0.8424, running_loss=0.8580, LR=0.000100
[2025-08-10 19:29:05,354][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055152] [Batch 03464/03692] [00:31:33/00:02:04, 0.547s/it]: train_loss_raw=0.8404, running_loss=0.8610, LR=0.000100
[2025-08-10 19:29:11,863][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055164] [Batch 03476/03692] [00:31:39/00:01:58, 0.547s/it]: train_loss_raw=1.0912, running_loss=0.8643, LR=0.000100
[2025-08-10 19:29:18,298][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055176] [Batch 03488/03692] [00:31:46/00:01:51, 0.547s/it]: train_loss_raw=0.8642, running_loss=0.8664, LR=0.000100
[2025-08-10 19:29:24,772][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055188] [Batch 03500/03692] [00:31:52/00:01:44, 0.546s/it]: train_loss_raw=0.7381, running_loss=0.8657, LR=0.000100
[2025-08-10 19:29:31,217][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055200] [Batch 03512/03692] [00:31:59/00:01:38, 0.546s/it]: train_loss_raw=0.9632, running_loss=0.8678, LR=0.000100
[2025-08-10 19:29:37,641][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055212] [Batch 03524/03692] [00:32:05/00:01:31, 0.546s/it]: train_loss_raw=0.8023, running_loss=0.8656, LR=0.000100
[2025-08-10 19:29:44,059][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055224] [Batch 03536/03692] [00:32:12/00:01:25, 0.546s/it]: train_loss_raw=0.7044, running_loss=0.8681, LR=0.000100
[2025-08-10 19:29:50,517][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055236] [Batch 03548/03692] [00:32:18/00:01:18, 0.546s/it]: train_loss_raw=0.8397, running_loss=0.8701, LR=0.000100
[2025-08-10 19:29:56,880][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055248] [Batch 03560/03692] [00:32:24/00:01:12, 0.546s/it]: train_loss_raw=0.8775, running_loss=0.8663, LR=0.000100
[2025-08-10 19:30:03,312][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055260] [Batch 03572/03692] [00:32:31/00:01:05, 0.546s/it]: train_loss_raw=0.8343, running_loss=0.8676, LR=0.000100
[2025-08-10 19:30:09,725][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055272] [Batch 03584/03692] [00:32:37/00:00:58, 0.546s/it]: train_loss_raw=0.8093, running_loss=0.8664, LR=0.000100
[2025-08-10 19:30:16,217][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055284] [Batch 03596/03692] [00:32:44/00:00:52, 0.546s/it]: train_loss_raw=0.8667, running_loss=0.8673, LR=0.000100
[2025-08-10 19:30:22,719][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055296] [Batch 03608/03692] [00:32:50/00:00:45, 0.546s/it]: train_loss_raw=0.9120, running_loss=0.8687, LR=0.000100
[2025-08-10 19:30:29,128][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055308] [Batch 03620/03692] [00:32:57/00:00:39, 0.546s/it]: train_loss_raw=0.7846, running_loss=0.8684, LR=0.000100
[2025-08-10 19:30:35,495][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055320] [Batch 03632/03692] [00:33:03/00:00:32, 0.546s/it]: train_loss_raw=0.8300, running_loss=0.8630, LR=0.000100
[2025-08-10 19:30:41,965][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055332] [Batch 03644/03692] [00:33:09/00:00:26, 0.546s/it]: train_loss_raw=0.8918, running_loss=0.8664, LR=0.000100
[2025-08-10 19:30:48,396][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055344] [Batch 03656/03692] [00:33:16/00:00:19, 0.546s/it]: train_loss_raw=0.8420, running_loss=0.8692, LR=0.000100
[2025-08-10 19:30:54,748][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055356] [Batch 03668/03692] [00:33:22/00:00:13, 0.546s/it]: train_loss_raw=0.6685, running_loss=0.8709, LR=0.000100
[2025-08-10 19:31:01,176][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055368] [Batch 03680/03692] [00:33:29/00:00:06, 0.546s/it]: train_loss_raw=0.8033, running_loss=0.8686, LR=0.000100
[2025-08-10 19:31:07,565][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055380] [Batch 03692/03692] [00:33:35/00:00:00, 0.546s/it]: train_loss_raw=0.7285, running_loss=0.8670, LR=0.000100
[2025-08-10 19:31:12,524][__main__][INFO] - [VALIDATION] [Epoch 14/29] Starting validation.
[2025-08-10 19:31:47,196][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 055381] [Batch 00011/00025] [00:00:34/00:00:37, 2.889s/it]
[2025-08-10 19:32:03,284][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 055381] [Batch 00023/00025] [00:00:50/00:00:02, 2.115s/it]
[2025-08-10 19:32:04,258][__main__][INFO] - [VALIDATION] [Epoch 14/29] train_loss=0.86695, valid_loss=0.88851
[2025-08-10 19:32:04,259][__main__][INFO] - [VALIDATION] [Epoch 14/29] Metrics:
[2025-08-10 19:32:04,259][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_er      0.394
[2025-08-10 19:32:04,259][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_prec    0.349
[2025-08-10 19:32:04,259][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_recall  0.356
[2025-08-10 19:32:04,259][__main__][INFO] - [VALIDATION] [Epoch 14/29] - pep_recall 0.322
[2025-08-10 19:32:04,261][__main__][INFO] - [TRAIN] [Epoch 14/29] Epoch complete, total time 08:36:03, remaining time 08:36:03, 00:34:24 per epoch
[2025-08-10 19:32:10,423][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055392] [Batch 00012/03692] [00:00:05/00:30:20, 0.495s/it]: train_loss_raw=0.8454, running_loss=1.0027, LR=0.000100
[2025-08-10 19:32:16,925][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055404] [Batch 00024/03692] [00:00:12/00:31:41, 0.518s/it]: train_loss_raw=0.8529, running_loss=0.9868, LR=0.000100
[2025-08-10 19:32:23,406][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055416] [Batch 00036/03692] [00:00:18/00:32:01, 0.526s/it]: train_loss_raw=0.8113, running_loss=0.9722, LR=0.000100
[2025-08-10 19:32:29,797][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055428] [Batch 00048/03692] [00:00:25/00:32:01, 0.527s/it]: train_loss_raw=0.9302, running_loss=0.9583, LR=0.000100
[2025-08-10 19:32:36,158][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055440] [Batch 00060/03692] [00:00:31/00:31:57, 0.528s/it]: train_loss_raw=0.8639, running_loss=0.9439, LR=0.000100
[2025-08-10 19:32:42,608][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055452] [Batch 00072/03692] [00:00:38/00:31:56, 0.529s/it]: train_loss_raw=0.8757, running_loss=0.9337, LR=0.000100
[2025-08-10 19:32:48,963][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055464] [Batch 00084/03692] [00:00:44/00:31:50, 0.529s/it]: train_loss_raw=0.9971, running_loss=0.9264, LR=0.000100
[2025-08-10 19:32:55,350][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055476] [Batch 00096/03692] [00:00:50/00:31:45, 0.530s/it]: train_loss_raw=0.9305, running_loss=0.9173, LR=0.000100
[2025-08-10 19:33:01,832][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055488] [Batch 00108/03692] [00:00:57/00:31:43, 0.531s/it]: train_loss_raw=0.9752, running_loss=0.9162, LR=0.000100
[2025-08-10 19:33:08,183][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055500] [Batch 00120/03692] [00:01:03/00:31:36, 0.531s/it]: train_loss_raw=0.8526, running_loss=0.9119, LR=0.000100
[2025-08-10 19:33:14,605][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055512] [Batch 00132/03692] [00:01:10/00:31:31, 0.531s/it]: train_loss_raw=0.8815, running_loss=0.9034, LR=0.000100
[2025-08-10 19:33:21,068][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055524] [Batch 00144/03692] [00:01:16/00:31:26, 0.532s/it]: train_loss_raw=0.9774, running_loss=0.9012, LR=0.000100
[2025-08-10 19:33:27,561][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055536] [Batch 00156/03692] [00:01:23/00:31:23, 0.533s/it]: train_loss_raw=0.9167, running_loss=0.8959, LR=0.000100
[2025-08-10 19:33:34,046][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055548] [Batch 00168/03692] [00:01:29/00:31:18, 0.533s/it]: train_loss_raw=0.8387, running_loss=0.8895, LR=0.000100
[2025-08-10 19:33:40,443][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055560] [Batch 00180/03692] [00:01:35/00:31:12, 0.533s/it]: train_loss_raw=0.8130, running_loss=0.8857, LR=0.000100
[2025-08-10 19:33:46,881][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055572] [Batch 00192/03692] [00:01:42/00:31:06, 0.533s/it]: train_loss_raw=0.9220, running_loss=0.8859, LR=0.000100
[2025-08-10 19:33:53,301][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055584] [Batch 00204/03692] [00:01:48/00:31:00, 0.533s/it]: train_loss_raw=0.8394, running_loss=0.8812, LR=0.000100
[2025-08-10 19:33:59,667][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055596] [Batch 00216/03692] [00:01:55/00:30:53, 0.533s/it]: train_loss_raw=0.7675, running_loss=0.8807, LR=0.000100
[2025-08-10 19:34:06,175][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055608] [Batch 00228/03692] [00:02:01/00:30:48, 0.534s/it]: train_loss_raw=0.7981, running_loss=0.8780, LR=0.000100
[2025-08-10 19:34:12,710][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055620] [Batch 00240/03692] [00:02:08/00:30:44, 0.534s/it]: train_loss_raw=0.8354, running_loss=0.8780, LR=0.000100
[2025-08-10 19:34:19,136][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055632] [Batch 00252/03692] [00:02:14/00:30:38, 0.534s/it]: train_loss_raw=0.9510, running_loss=0.8747, LR=0.000100
[2025-08-10 19:34:25,556][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055644] [Batch 00264/03692] [00:02:21/00:30:31, 0.534s/it]: train_loss_raw=0.8504, running_loss=0.8717, LR=0.000100
[2025-08-10 19:34:32,059][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055656] [Batch 00276/03692] [00:02:27/00:30:26, 0.535s/it]: train_loss_raw=0.8331, running_loss=0.8657, LR=0.000100
[2025-08-10 19:34:38,592][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055668] [Batch 00288/03692] [00:02:34/00:30:21, 0.535s/it]: train_loss_raw=0.7657, running_loss=0.8648, LR=0.000100
[2025-08-10 19:34:45,099][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055680] [Batch 00300/03692] [00:02:40/00:30:15, 0.535s/it]: train_loss_raw=0.7892, running_loss=0.8620, LR=0.000100
[2025-08-10 19:34:51,649][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055692] [Batch 00312/03692] [00:02:47/00:30:10, 0.536s/it]: train_loss_raw=0.9280, running_loss=0.8609, LR=0.000100
[2025-08-10 19:34:58,262][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055704] [Batch 00324/03692] [00:02:53/00:30:06, 0.536s/it]: train_loss_raw=0.7813, running_loss=0.8647, LR=0.000100
[2025-08-10 19:35:04,811][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055716] [Batch 00336/03692] [00:03:00/00:30:01, 0.537s/it]: train_loss_raw=0.8392, running_loss=0.8611, LR=0.000100
[2025-08-10 19:35:11,251][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055728] [Batch 00348/03692] [00:03:06/00:29:54, 0.537s/it]: train_loss_raw=0.9159, running_loss=0.8630, LR=0.000100
[2025-08-10 19:35:17,804][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055740] [Batch 00360/03692] [00:03:13/00:29:49, 0.537s/it]: train_loss_raw=0.8946, running_loss=0.8669, LR=0.000100
[2025-08-10 19:35:23,830][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055752] [Batch 00372/03692] [00:03:19/00:29:39, 0.536s/it]: train_loss_raw=0.9592, running_loss=0.8670, LR=0.000100
[2025-08-10 19:35:29,833][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055764] [Batch 00384/03692] [00:03:25/00:29:28, 0.535s/it]: train_loss_raw=0.8135, running_loss=0.8658, LR=0.000100
[2025-08-10 19:35:35,840][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055776] [Batch 00396/03692] [00:03:31/00:29:19, 0.534s/it]: train_loss_raw=0.8033, running_loss=0.8613, LR=0.000100
[2025-08-10 19:35:41,842][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055788] [Batch 00408/03692] [00:03:37/00:29:09, 0.533s/it]: train_loss_raw=0.8705, running_loss=0.8619, LR=0.000100
[2025-08-10 19:35:47,928][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055800] [Batch 00420/03692] [00:03:43/00:29:00, 0.532s/it]: train_loss_raw=0.8853, running_loss=0.8657, LR=0.000100
[2025-08-10 19:35:53,938][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055812] [Batch 00432/03692] [00:03:49/00:28:51, 0.531s/it]: train_loss_raw=0.8750, running_loss=0.8655, LR=0.000100
[2025-08-10 19:36:00,352][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055824] [Batch 00444/03692] [00:03:55/00:28:45, 0.531s/it]: train_loss_raw=0.6780, running_loss=0.8650, LR=0.000100
[2025-08-10 19:36:06,756][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055836] [Batch 00456/03692] [00:04:02/00:28:39, 0.531s/it]: train_loss_raw=0.9603, running_loss=0.8652, LR=0.000100
[2025-08-10 19:36:13,215][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055848] [Batch 00468/03692] [00:04:08/00:28:33, 0.531s/it]: train_loss_raw=0.9690, running_loss=0.8658, LR=0.000100
[2025-08-10 19:36:19,697][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055860] [Batch 00480/03692] [00:04:15/00:28:27, 0.532s/it]: train_loss_raw=0.9443, running_loss=0.8645, LR=0.000100
[2025-08-10 19:36:26,149][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055872] [Batch 00492/03692] [00:04:21/00:28:21, 0.532s/it]: train_loss_raw=0.8220, running_loss=0.8615, LR=0.000100
[2025-08-10 19:36:32,717][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055884] [Batch 00504/03692] [00:04:28/00:28:16, 0.532s/it]: train_loss_raw=0.8037, running_loss=0.8599, LR=0.000100
[2025-08-10 19:36:39,138][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055896] [Batch 00516/03692] [00:04:34/00:28:10, 0.532s/it]: train_loss_raw=0.9019, running_loss=0.8609, LR=0.000100
[2025-08-10 19:36:45,720][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055908] [Batch 00528/03692] [00:04:41/00:28:05, 0.533s/it]: train_loss_raw=0.7391, running_loss=0.8608, LR=0.000100
[2025-08-10 19:36:52,240][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055920] [Batch 00540/03692] [00:04:47/00:27:59, 0.533s/it]: train_loss_raw=0.8782, running_loss=0.8603, LR=0.000100
[2025-08-10 19:36:58,714][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055932] [Batch 00552/03692] [00:04:54/00:27:53, 0.533s/it]: train_loss_raw=0.9687, running_loss=0.8587, LR=0.000100
[2025-08-10 19:37:05,198][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055944] [Batch 00564/03692] [00:05:00/00:27:47, 0.533s/it]: train_loss_raw=0.8935, running_loss=0.8552, LR=0.000100
[2025-08-10 19:37:11,700][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055956] [Batch 00576/03692] [00:05:07/00:27:41, 0.533s/it]: train_loss_raw=0.8843, running_loss=0.8570, LR=0.000100
[2025-08-10 19:37:18,271][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055968] [Batch 00588/03692] [00:05:13/00:27:36, 0.534s/it]: train_loss_raw=0.7361, running_loss=0.8556, LR=0.000100
[2025-08-10 19:37:24,789][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055980] [Batch 00600/03692] [00:05:20/00:27:30, 0.534s/it]: train_loss_raw=0.8587, running_loss=0.8551, LR=0.000100
[2025-08-10 19:37:31,365][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055992] [Batch 00612/03692] [00:05:26/00:27:25, 0.534s/it]: train_loss_raw=0.7592, running_loss=0.8521, LR=0.000100
[2025-08-10 19:37:42,518][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056004] [Batch 00624/03692] [00:05:38/00:27:41, 0.542s/it]: train_loss_raw=0.8507, running_loss=0.8542, LR=0.000100
[2025-08-10 19:37:48,932][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056016] [Batch 00636/03692] [00:05:44/00:27:35, 0.542s/it]: train_loss_raw=0.8335, running_loss=0.8513, LR=0.000100
[2025-08-10 19:37:55,372][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056028] [Batch 00648/03692] [00:05:50/00:27:28, 0.541s/it]: train_loss_raw=0.8884, running_loss=0.8531, LR=0.000100
[2025-08-10 19:38:01,929][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056040] [Batch 00660/03692] [00:05:57/00:27:22, 0.542s/it]: train_loss_raw=0.8138, running_loss=0.8492, LR=0.000100
[2025-08-10 19:38:08,493][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056052] [Batch 00672/03692] [00:06:04/00:27:15, 0.542s/it]: train_loss_raw=0.8186, running_loss=0.8481, LR=0.000100
[2025-08-10 19:38:14,878][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056064] [Batch 00684/03692] [00:06:10/00:27:08, 0.542s/it]: train_loss_raw=0.7612, running_loss=0.8485, LR=0.000100
[2025-08-10 19:38:21,413][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056076] [Batch 00696/03692] [00:06:16/00:27:02, 0.542s/it]: train_loss_raw=0.8302, running_loss=0.8513, LR=0.000100
[2025-08-10 19:38:27,929][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056088] [Batch 00708/03692] [00:06:23/00:26:56, 0.542s/it]: train_loss_raw=0.9753, running_loss=0.8562, LR=0.000100
[2025-08-10 19:38:34,304][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056100] [Batch 00720/03692] [00:06:29/00:26:49, 0.541s/it]: train_loss_raw=0.9295, running_loss=0.8600, LR=0.000100
[2025-08-10 19:38:40,793][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056112] [Batch 00732/03692] [00:06:36/00:26:42, 0.541s/it]: train_loss_raw=0.7781, running_loss=0.8582, LR=0.000100
[2025-08-10 19:38:47,204][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056124] [Batch 00744/03692] [00:06:42/00:26:35, 0.541s/it]: train_loss_raw=0.7898, running_loss=0.8555, LR=0.000100
[2025-08-10 19:38:53,575][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056136] [Batch 00756/03692] [00:06:49/00:26:28, 0.541s/it]: train_loss_raw=0.8871, running_loss=0.8547, LR=0.000100
[2025-08-10 19:39:00,033][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056148] [Batch 00768/03692] [00:06:55/00:26:22, 0.541s/it]: train_loss_raw=0.7307, running_loss=0.8535, LR=0.000100
[2025-08-10 19:39:06,463][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056160] [Batch 00780/03692] [00:07:01/00:26:15, 0.541s/it]: train_loss_raw=0.7508, running_loss=0.8508, LR=0.000100
[2025-08-10 19:39:12,873][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056172] [Batch 00792/03692] [00:07:08/00:26:08, 0.541s/it]: train_loss_raw=0.8924, running_loss=0.8521, LR=0.000100
[2025-08-10 19:39:19,429][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056184] [Batch 00804/03692] [00:07:14/00:26:02, 0.541s/it]: train_loss_raw=0.9140, running_loss=0.8499, LR=0.000100
[2025-08-10 19:39:26,003][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056196] [Batch 00816/03692] [00:07:21/00:25:56, 0.541s/it]: train_loss_raw=0.9453, running_loss=0.8534, LR=0.000100
[2025-08-10 19:39:32,645][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056208] [Batch 00828/03692] [00:07:28/00:25:50, 0.541s/it]: train_loss_raw=0.8320, running_loss=0.8528, LR=0.000100
[2025-08-10 19:39:39,118][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056220] [Batch 00840/03692] [00:07:34/00:25:43, 0.541s/it]: train_loss_raw=0.8379, running_loss=0.8507, LR=0.000100
[2025-08-10 19:39:45,497][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056232] [Batch 00852/03692] [00:07:41/00:25:36, 0.541s/it]: train_loss_raw=0.8916, running_loss=0.8491, LR=0.000100
[2025-08-10 19:39:51,953][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056244] [Batch 00864/03692] [00:07:47/00:25:30, 0.541s/it]: train_loss_raw=0.8861, running_loss=0.8522, LR=0.000100
[2025-08-10 19:39:58,386][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056256] [Batch 00876/03692] [00:07:53/00:25:23, 0.541s/it]: train_loss_raw=0.9947, running_loss=0.8499, LR=0.000100
[2025-08-10 19:40:04,726][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056268] [Batch 00888/03692] [00:08:00/00:25:16, 0.541s/it]: train_loss_raw=0.9045, running_loss=0.8498, LR=0.000100
[2025-08-10 19:40:10,839][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056280] [Batch 00900/03692] [00:08:06/00:25:08, 0.540s/it]: train_loss_raw=0.8448, running_loss=0.8475, LR=0.000100
[2025-08-10 19:40:17,166][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056292] [Batch 00912/03692] [00:08:12/00:25:01, 0.540s/it]: train_loss_raw=0.7720, running_loss=0.8461, LR=0.000100
[2025-08-10 19:40:23,597][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056304] [Batch 00924/03692] [00:08:19/00:24:55, 0.540s/it]: train_loss_raw=0.9668, running_loss=0.8450, LR=0.000100
[2025-08-10 19:40:29,651][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056316] [Batch 00936/03692] [00:08:25/00:24:47, 0.540s/it]: train_loss_raw=0.7167, running_loss=0.8424, LR=0.000100
[2025-08-10 19:40:35,719][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056328] [Batch 00948/03692] [00:08:31/00:24:39, 0.539s/it]: train_loss_raw=0.8978, running_loss=0.8415, LR=0.000100
[2025-08-10 19:40:41,796][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056340] [Batch 00960/03692] [00:08:37/00:24:32, 0.539s/it]: train_loss_raw=0.8256, running_loss=0.8414, LR=0.000100
[2025-08-10 19:40:47,977][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056352] [Batch 00972/03692] [00:08:43/00:24:24, 0.539s/it]: train_loss_raw=0.8574, running_loss=0.8451, LR=0.000100
[2025-08-10 19:40:54,136][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056364] [Batch 00984/03692] [00:08:49/00:24:17, 0.538s/it]: train_loss_raw=0.9403, running_loss=0.8486, LR=0.000100
[2025-08-10 19:41:00,273][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056376] [Batch 00996/03692] [00:08:55/00:24:10, 0.538s/it]: train_loss_raw=0.7776, running_loss=0.8482, LR=0.000100
[2025-08-10 19:41:06,427][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056388] [Batch 01008/03692] [00:09:01/00:24:03, 0.538s/it]: train_loss_raw=0.8741, running_loss=0.8482, LR=0.000100
[2025-08-10 19:41:12,535][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056400] [Batch 01020/03692] [00:09:08/00:23:55, 0.537s/it]: train_loss_raw=0.8580, running_loss=0.8494, LR=0.000100
[2025-08-10 19:41:18,742][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056412] [Batch 01032/03692] [00:09:14/00:23:48, 0.537s/it]: train_loss_raw=0.8271, running_loss=0.8477, LR=0.000100
[2025-08-10 19:41:25,278][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056424] [Batch 01044/03692] [00:09:20/00:23:42, 0.537s/it]: train_loss_raw=0.8291, running_loss=0.8480, LR=0.000100
[2025-08-10 19:41:31,865][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056436] [Batch 01056/03692] [00:09:27/00:23:36, 0.537s/it]: train_loss_raw=0.7947, running_loss=0.8469, LR=0.000100
[2025-08-10 19:41:38,443][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056448] [Batch 01068/03692] [00:09:33/00:23:30, 0.537s/it]: train_loss_raw=0.7912, running_loss=0.8473, LR=0.000100
[2025-08-10 19:41:44,929][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056460] [Batch 01080/03692] [00:09:40/00:23:23, 0.537s/it]: train_loss_raw=0.8657, running_loss=0.8475, LR=0.000100
[2025-08-10 19:41:51,546][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056472] [Batch 01092/03692] [00:09:47/00:23:17, 0.538s/it]: train_loss_raw=0.6704, running_loss=0.8466, LR=0.000100
[2025-08-10 19:41:58,053][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056484] [Batch 01104/03692] [00:09:53/00:23:11, 0.538s/it]: train_loss_raw=0.7768, running_loss=0.8444, LR=0.000100
[2025-08-10 19:42:04,580][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056496] [Batch 01116/03692] [00:10:00/00:23:05, 0.538s/it]: train_loss_raw=0.9882, running_loss=0.8464, LR=0.000100
[2025-08-10 19:42:11,062][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056508] [Batch 01128/03692] [00:10:06/00:22:58, 0.538s/it]: train_loss_raw=0.8564, running_loss=0.8481, LR=0.000100
[2025-08-10 19:42:17,547][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056520] [Batch 01140/03692] [00:10:13/00:22:52, 0.538s/it]: train_loss_raw=0.9253, running_loss=0.8499, LR=0.000100
[2025-08-10 19:42:24,125][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056532] [Batch 01152/03692] [00:10:19/00:22:46, 0.538s/it]: train_loss_raw=0.8226, running_loss=0.8507, LR=0.000100
[2025-08-10 19:42:30,497][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056544] [Batch 01164/03692] [00:10:26/00:22:39, 0.538s/it]: train_loss_raw=0.7321, running_loss=0.8463, LR=0.000100
[2025-08-10 19:42:36,953][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056556] [Batch 01176/03692] [00:10:32/00:22:33, 0.538s/it]: train_loss_raw=0.8910, running_loss=0.8456, LR=0.000100
[2025-08-10 19:42:42,990][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056568] [Batch 01188/03692] [00:10:38/00:22:25, 0.537s/it]: train_loss_raw=0.7449, running_loss=0.8426, LR=0.000100
[2025-08-10 19:42:49,107][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056580] [Batch 01200/03692] [00:10:44/00:22:18, 0.537s/it]: train_loss_raw=0.9586, running_loss=0.8459, LR=0.000100
[2025-08-10 19:42:55,308][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056592] [Batch 01212/03692] [00:10:50/00:22:11, 0.537s/it]: train_loss_raw=0.8235, running_loss=0.8475, LR=0.000100
[2025-08-10 19:43:01,354][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056604] [Batch 01224/03692] [00:10:56/00:22:04, 0.537s/it]: train_loss_raw=0.8018, running_loss=0.8452, LR=0.000100
[2025-08-10 19:43:07,393][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056616] [Batch 01236/03692] [00:11:02/00:21:57, 0.536s/it]: train_loss_raw=0.7530, running_loss=0.8468, LR=0.000100
[2025-08-10 19:43:13,806][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056628] [Batch 01248/03692] [00:11:09/00:21:50, 0.536s/it]: train_loss_raw=0.7636, running_loss=0.8478, LR=0.000100
[2025-08-10 19:43:20,267][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056640] [Batch 01260/03692] [00:11:15/00:21:44, 0.536s/it]: train_loss_raw=0.7706, running_loss=0.8450, LR=0.000100
[2025-08-10 19:43:26,293][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056652] [Batch 01272/03692] [00:11:21/00:21:37, 0.536s/it]: train_loss_raw=0.8151, running_loss=0.8424, LR=0.000100
[2025-08-10 19:43:32,364][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056664] [Batch 01284/03692] [00:11:27/00:21:30, 0.536s/it]: train_loss_raw=0.7665, running_loss=0.8426, LR=0.000100
[2025-08-10 19:43:38,411][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056676] [Batch 01296/03692] [00:11:33/00:21:22, 0.535s/it]: train_loss_raw=0.8700, running_loss=0.8443, LR=0.000100
[2025-08-10 19:43:44,474][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056688] [Batch 01308/03692] [00:11:39/00:21:15, 0.535s/it]: train_loss_raw=0.6831, running_loss=0.8417, LR=0.000100
[2025-08-10 19:43:50,561][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056700] [Batch 01320/03692] [00:11:46/00:21:08, 0.535s/it]: train_loss_raw=0.8417, running_loss=0.8451, LR=0.000100
[2025-08-10 19:43:56,847][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056712] [Batch 01332/03692] [00:11:52/00:21:02, 0.535s/it]: train_loss_raw=0.9345, running_loss=0.8443, LR=0.000100
[2025-08-10 19:44:03,132][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056724] [Batch 01344/03692] [00:11:58/00:20:55, 0.535s/it]: train_loss_raw=0.8129, running_loss=0.8445, LR=0.000100
[2025-08-10 19:44:09,305][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056736] [Batch 01356/03692] [00:12:04/00:20:48, 0.535s/it]: train_loss_raw=0.7859, running_loss=0.8433, LR=0.000100
[2025-08-10 19:44:15,416][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056748] [Batch 01368/03692] [00:12:10/00:20:41, 0.534s/it]: train_loss_raw=0.8052, running_loss=0.8377, LR=0.000100
[2025-08-10 19:44:21,494][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056760] [Batch 01380/03692] [00:12:17/00:20:34, 0.534s/it]: train_loss_raw=0.8704, running_loss=0.8373, LR=0.000100
[2025-08-10 19:44:27,830][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056772] [Batch 01392/03692] [00:12:23/00:20:28, 0.534s/it]: train_loss_raw=0.8741, running_loss=0.8417, LR=0.000100
[2025-08-10 19:44:34,333][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056784] [Batch 01404/03692] [00:12:29/00:20:21, 0.534s/it]: train_loss_raw=0.8146, running_loss=0.8391, LR=0.000100
[2025-08-10 19:44:40,852][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056796] [Batch 01416/03692] [00:12:36/00:20:15, 0.534s/it]: train_loss_raw=0.8199, running_loss=0.8390, LR=0.000100
[2025-08-10 19:44:47,380][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056808] [Batch 01428/03692] [00:12:42/00:20:09, 0.534s/it]: train_loss_raw=0.8263, running_loss=0.8360, LR=0.000100
[2025-08-10 19:44:53,597][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056820] [Batch 01440/03692] [00:12:49/00:20:02, 0.534s/it]: train_loss_raw=0.9362, running_loss=0.8356, LR=0.000100
[2025-08-10 19:45:00,164][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056832] [Batch 01452/03692] [00:12:55/00:19:56, 0.534s/it]: train_loss_raw=0.9093, running_loss=0.8403, LR=0.000100
[2025-08-10 19:45:06,676][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056844] [Batch 01464/03692] [00:13:02/00:19:50, 0.534s/it]: train_loss_raw=0.8253, running_loss=0.8455, LR=0.000100
[2025-08-10 19:45:13,086][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056856] [Batch 01476/03692] [00:13:08/00:19:43, 0.534s/it]: train_loss_raw=0.8111, running_loss=0.8416, LR=0.000100
[2025-08-10 19:45:19,137][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056868] [Batch 01488/03692] [00:13:14/00:19:37, 0.534s/it]: train_loss_raw=0.8134, running_loss=0.8393, LR=0.000100
[2025-08-10 19:45:25,159][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056880] [Batch 01500/03692] [00:13:20/00:19:30, 0.534s/it]: train_loss_raw=0.7680, running_loss=0.8374, LR=0.000100
[2025-08-10 19:45:31,189][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056892] [Batch 01512/03692] [00:13:26/00:19:23, 0.534s/it]: train_loss_raw=0.7811, running_loss=0.8320, LR=0.000100
[2025-08-10 19:45:37,461][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056904] [Batch 01524/03692] [00:13:32/00:19:16, 0.533s/it]: train_loss_raw=0.8424, running_loss=0.8332, LR=0.000100
[2025-08-10 19:45:43,937][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056916] [Batch 01536/03692] [00:13:39/00:19:10, 0.533s/it]: train_loss_raw=1.0446, running_loss=0.8378, LR=0.000100
[2025-08-10 19:45:50,037][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056928] [Batch 01548/03692] [00:13:45/00:19:03, 0.533s/it]: train_loss_raw=0.8926, running_loss=0.8392, LR=0.000100
[2025-08-10 19:45:56,058][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056940] [Batch 01560/03692] [00:13:51/00:18:56, 0.533s/it]: train_loss_raw=0.9667, running_loss=0.8409, LR=0.000100
[2025-08-10 19:46:02,131][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056952] [Batch 01572/03692] [00:13:57/00:18:49, 0.533s/it]: train_loss_raw=0.7858, running_loss=0.8423, LR=0.000100
[2025-08-10 19:46:08,289][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056964] [Batch 01584/03692] [00:14:03/00:18:42, 0.533s/it]: train_loss_raw=0.9301, running_loss=0.8445, LR=0.000100
[2025-08-10 19:46:14,363][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056976] [Batch 01596/03692] [00:14:09/00:18:36, 0.533s/it]: train_loss_raw=0.7855, running_loss=0.8416, LR=0.000100
[2025-08-10 19:46:20,838][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056988] [Batch 01608/03692] [00:14:16/00:18:29, 0.533s/it]: train_loss_raw=0.8827, running_loss=0.8449, LR=0.000100
[2025-08-10 19:46:27,042][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057000] [Batch 01620/03692] [00:14:22/00:18:23, 0.532s/it]: train_loss_raw=0.7229, running_loss=0.8429, LR=0.000100
[2025-08-10 19:46:33,319][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057012] [Batch 01632/03692] [00:14:28/00:18:16, 0.532s/it]: train_loss_raw=0.9283, running_loss=0.8445, LR=0.000100
[2025-08-10 19:46:39,900][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057024] [Batch 01644/03692] [00:14:35/00:18:10, 0.532s/it]: train_loss_raw=0.8759, running_loss=0.8489, LR=0.000100
[2025-08-10 19:46:46,471][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057036] [Batch 01656/03692] [00:14:41/00:18:04, 0.533s/it]: train_loss_raw=0.9274, running_loss=0.8445, LR=0.000100
[2025-08-10 19:46:52,953][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057048] [Batch 01668/03692] [00:14:48/00:17:58, 0.533s/it]: train_loss_raw=0.7558, running_loss=0.8411, LR=0.000100
[2025-08-10 19:46:59,392][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057060] [Batch 01680/03692] [00:14:54/00:17:51, 0.533s/it]: train_loss_raw=0.7973, running_loss=0.8375, LR=0.000100
[2025-08-10 19:47:05,726][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057072] [Batch 01692/03692] [00:15:01/00:17:45, 0.533s/it]: train_loss_raw=0.8289, running_loss=0.8380, LR=0.000100
[2025-08-10 19:47:12,225][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057084] [Batch 01704/03692] [00:15:07/00:17:39, 0.533s/it]: train_loss_raw=0.8998, running_loss=0.8359, LR=0.000100
[2025-08-10 19:47:18,536][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057096] [Batch 01716/03692] [00:15:14/00:17:32, 0.533s/it]: train_loss_raw=0.8210, running_loss=0.8351, LR=0.000100
[2025-08-10 19:47:24,943][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057108] [Batch 01728/03692] [00:15:20/00:17:26, 0.533s/it]: train_loss_raw=1.0101, running_loss=0.8383, LR=0.000100
[2025-08-10 19:47:31,508][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057120] [Batch 01740/03692] [00:15:27/00:17:19, 0.533s/it]: train_loss_raw=0.9953, running_loss=0.8394, LR=0.000100
[2025-08-10 19:47:37,995][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057132] [Batch 01752/03692] [00:15:33/00:17:13, 0.533s/it]: train_loss_raw=0.7607, running_loss=0.8343, LR=0.000100
[2025-08-10 19:47:44,494][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057144] [Batch 01764/03692] [00:15:40/00:17:07, 0.533s/it]: train_loss_raw=0.7764, running_loss=0.8337, LR=0.000100
[2025-08-10 19:47:51,014][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057156] [Batch 01776/03692] [00:15:46/00:17:01, 0.533s/it]: train_loss_raw=0.8651, running_loss=0.8341, LR=0.000100
[2025-08-10 19:47:57,492][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057168] [Batch 01788/03692] [00:15:53/00:16:54, 0.533s/it]: train_loss_raw=0.7730, running_loss=0.8333, LR=0.000100
[2025-08-10 19:48:04,026][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057180] [Batch 01800/03692] [00:15:59/00:16:48, 0.533s/it]: train_loss_raw=0.8634, running_loss=0.8329, LR=0.000100
[2025-08-10 19:48:10,549][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057192] [Batch 01812/03692] [00:16:06/00:16:42, 0.533s/it]: train_loss_raw=0.8237, running_loss=0.8325, LR=0.000100
[2025-08-10 19:48:17,108][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057204] [Batch 01824/03692] [00:16:12/00:16:36, 0.533s/it]: train_loss_raw=0.8120, running_loss=0.8329, LR=0.000100
[2025-08-10 19:48:23,395][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057216] [Batch 01836/03692] [00:16:18/00:16:29, 0.533s/it]: train_loss_raw=0.9210, running_loss=0.8334, LR=0.000100
[2025-08-10 19:48:29,885][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057228] [Batch 01848/03692] [00:16:25/00:16:23, 0.533s/it]: train_loss_raw=0.9832, running_loss=0.8350, LR=0.000100
[2025-08-10 19:48:36,145][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057240] [Batch 01860/03692] [00:16:31/00:16:16, 0.533s/it]: train_loss_raw=0.7298, running_loss=0.8363, LR=0.000100
[2025-08-10 19:48:42,171][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057252] [Batch 01872/03692] [00:16:37/00:16:09, 0.533s/it]: train_loss_raw=0.7570, running_loss=0.8366, LR=0.000100
[2025-08-10 19:48:48,227][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057264] [Batch 01884/03692] [00:16:43/00:16:03, 0.533s/it]: train_loss_raw=0.7622, running_loss=0.8348, LR=0.000100
[2025-08-10 19:48:54,670][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057276] [Batch 01896/03692] [00:16:50/00:15:56, 0.533s/it]: train_loss_raw=0.7694, running_loss=0.8344, LR=0.000100
[2025-08-10 19:49:01,289][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057288] [Batch 01908/03692] [00:16:56/00:15:50, 0.533s/it]: train_loss_raw=0.9161, running_loss=0.8316, LR=0.000100
[2025-08-10 19:49:07,515][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057300] [Batch 01920/03692] [00:17:03/00:15:44, 0.533s/it]: train_loss_raw=0.8925, running_loss=0.8309, LR=0.000100
[2025-08-10 19:49:14,075][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057312] [Batch 01932/03692] [00:17:09/00:15:37, 0.533s/it]: train_loss_raw=0.6651, running_loss=0.8260, LR=0.000100
[2025-08-10 19:49:20,629][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057324] [Batch 01944/03692] [00:17:16/00:15:31, 0.533s/it]: train_loss_raw=0.7038, running_loss=0.8226, LR=0.000100
[2025-08-10 19:49:27,225][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057336] [Batch 01956/03692] [00:17:22/00:15:25, 0.533s/it]: train_loss_raw=0.8565, running_loss=0.8216, LR=0.000100
[2025-08-10 19:49:33,261][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057348] [Batch 01968/03692] [00:17:28/00:15:18, 0.533s/it]: train_loss_raw=0.8003, running_loss=0.8261, LR=0.000100
[2025-08-10 19:49:39,349][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057360] [Batch 01980/03692] [00:17:34/00:15:12, 0.533s/it]: train_loss_raw=0.8778, running_loss=0.8284, LR=0.000100
[2025-08-10 19:49:45,367][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057372] [Batch 01992/03692] [00:17:40/00:15:05, 0.533s/it]: train_loss_raw=0.7872, running_loss=0.8298, LR=0.000100
[2025-08-10 19:49:51,356][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057384] [Batch 02004/03692] [00:17:46/00:14:58, 0.532s/it]: train_loss_raw=0.8677, running_loss=0.8334, LR=0.000100
[2025-08-10 19:49:57,414][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057396] [Batch 02016/03692] [00:17:52/00:14:51, 0.532s/it]: train_loss_raw=0.8026, running_loss=0.8305, LR=0.000100
[2025-08-10 19:50:03,686][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057408] [Batch 02028/03692] [00:17:59/00:14:45, 0.532s/it]: train_loss_raw=0.8268, running_loss=0.8319, LR=0.000100
[2025-08-10 19:50:10,257][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057420] [Batch 02040/03692] [00:18:05/00:14:39, 0.532s/it]: train_loss_raw=0.8944, running_loss=0.8320, LR=0.000100
[2025-08-10 19:50:16,733][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057432] [Batch 02052/03692] [00:18:12/00:14:32, 0.532s/it]: train_loss_raw=0.8332, running_loss=0.8341, LR=0.000100
[2025-08-10 19:50:23,458][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057444] [Batch 02064/03692] [00:18:18/00:14:26, 0.532s/it]: train_loss_raw=0.8044, running_loss=0.8359, LR=0.000100
[2025-08-10 19:50:30,025][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057456] [Batch 02076/03692] [00:18:25/00:14:20, 0.533s/it]: train_loss_raw=0.7407, running_loss=0.8376, LR=0.000100
[2025-08-10 19:50:36,488][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057468] [Batch 02088/03692] [00:18:32/00:14:14, 0.533s/it]: train_loss_raw=1.0322, running_loss=0.8359, LR=0.000100
[2025-08-10 19:50:42,481][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057480] [Batch 02100/03692] [00:18:37/00:14:07, 0.532s/it]: train_loss_raw=0.8306, running_loss=0.8405, LR=0.000100
[2025-08-10 19:50:48,569][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057492] [Batch 02112/03692] [00:18:44/00:14:00, 0.532s/it]: train_loss_raw=0.7919, running_loss=0.8383, LR=0.000100
[2025-08-10 19:50:54,667][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057504] [Batch 02124/03692] [00:18:50/00:13:54, 0.532s/it]: train_loss_raw=0.7573, running_loss=0.8384, LR=0.000100
[2025-08-10 19:51:01,186][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057516] [Batch 02136/03692] [00:18:56/00:13:48, 0.532s/it]: train_loss_raw=0.9116, running_loss=0.8362, LR=0.000100
[2025-08-10 19:51:07,598][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057528] [Batch 02148/03692] [00:19:03/00:13:41, 0.532s/it]: train_loss_raw=0.6925, running_loss=0.8365, LR=0.000100
[2025-08-10 19:51:20,646][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057540] [Batch 02160/03692] [00:19:16/00:13:40, 0.535s/it]: train_loss_raw=0.8063, running_loss=0.8350, LR=0.000100
[2025-08-10 19:51:26,715][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057552] [Batch 02172/03692] [00:19:22/00:13:33, 0.535s/it]: train_loss_raw=0.7673, running_loss=0.8293, LR=0.000100
[2025-08-10 19:51:33,124][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057564] [Batch 02184/03692] [00:19:28/00:13:26, 0.535s/it]: train_loss_raw=0.8916, running_loss=0.8293, LR=0.000100
[2025-08-10 19:51:39,698][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057576] [Batch 02196/03692] [00:19:35/00:13:20, 0.535s/it]: train_loss_raw=0.7863, running_loss=0.8268, LR=0.000100
[2025-08-10 19:51:46,245][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057588] [Batch 02208/03692] [00:19:41/00:13:14, 0.535s/it]: train_loss_raw=0.8015, running_loss=0.8239, LR=0.000100
[2025-08-10 19:51:52,349][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057600] [Batch 02220/03692] [00:19:47/00:13:07, 0.535s/it]: train_loss_raw=0.6892, running_loss=0.8205, LR=0.000100
[2025-08-10 19:51:58,464][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057612] [Batch 02232/03692] [00:19:53/00:13:01, 0.535s/it]: train_loss_raw=0.8261, running_loss=0.8218, LR=0.000100
[2025-08-10 19:52:04,477][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057624] [Batch 02244/03692] [00:19:59/00:12:54, 0.535s/it]: train_loss_raw=0.7877, running_loss=0.8229, LR=0.000100
[2025-08-10 19:52:10,515][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057636] [Batch 02256/03692] [00:20:06/00:12:47, 0.535s/it]: train_loss_raw=0.8509, running_loss=0.8229, LR=0.000100
[2025-08-10 19:52:16,619][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057648] [Batch 02268/03692] [00:20:12/00:12:41, 0.534s/it]: train_loss_raw=0.8281, running_loss=0.8241, LR=0.000100
[2025-08-10 19:52:22,872][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057660] [Batch 02280/03692] [00:20:18/00:12:34, 0.534s/it]: train_loss_raw=0.8294, running_loss=0.8279, LR=0.000100
[2025-08-10 19:52:28,908][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057672] [Batch 02292/03692] [00:20:24/00:12:27, 0.534s/it]: train_loss_raw=0.7558, running_loss=0.8230, LR=0.000100
[2025-08-10 19:52:35,108][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057684] [Batch 02304/03692] [00:20:30/00:12:21, 0.534s/it]: train_loss_raw=0.7498, running_loss=0.8212, LR=0.000100
[2025-08-10 19:52:41,409][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057696] [Batch 02316/03692] [00:20:36/00:12:14, 0.534s/it]: train_loss_raw=0.6960, running_loss=0.8234, LR=0.000100
[2025-08-10 19:52:47,603][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057708] [Batch 02328/03692] [00:20:43/00:12:08, 0.534s/it]: train_loss_raw=0.7461, running_loss=0.8226, LR=0.000100
[2025-08-10 19:52:53,788][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057720] [Batch 02340/03692] [00:20:49/00:12:01, 0.534s/it]: train_loss_raw=0.7872, running_loss=0.8226, LR=0.000100
[2025-08-10 19:52:59,850][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057732] [Batch 02352/03692] [00:20:55/00:11:55, 0.534s/it]: train_loss_raw=0.7933, running_loss=0.8249, LR=0.000100
[2025-08-10 19:53:05,932][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057744] [Batch 02364/03692] [00:21:01/00:11:48, 0.534s/it]: train_loss_raw=0.8677, running_loss=0.8226, LR=0.000100
[2025-08-10 19:53:11,946][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057756] [Batch 02376/03692] [00:21:07/00:11:42, 0.533s/it]: train_loss_raw=0.7844, running_loss=0.8213, LR=0.000100
[2025-08-10 19:53:18,057][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057768] [Batch 02388/03692] [00:21:13/00:11:35, 0.533s/it]: train_loss_raw=0.8666, running_loss=0.8198, LR=0.000100
[2025-08-10 19:53:24,116][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057780] [Batch 02400/03692] [00:21:19/00:11:28, 0.533s/it]: train_loss_raw=0.7746, running_loss=0.8225, LR=0.000100
[2025-08-10 19:53:30,191][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057792] [Batch 02412/03692] [00:21:25/00:11:22, 0.533s/it]: train_loss_raw=0.7542, running_loss=0.8201, LR=0.000100
[2025-08-10 19:53:36,425][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057804] [Batch 02424/03692] [00:21:31/00:11:15, 0.533s/it]: train_loss_raw=0.8840, running_loss=0.8206, LR=0.000100
[2025-08-10 19:53:42,391][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057816] [Batch 02436/03692] [00:21:37/00:11:09, 0.533s/it]: train_loss_raw=0.6949, running_loss=0.8221, LR=0.000100
[2025-08-10 19:53:48,440][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057828] [Batch 02448/03692] [00:21:43/00:11:02, 0.533s/it]: train_loss_raw=0.7840, running_loss=0.8225, LR=0.000100
[2025-08-10 19:53:54,610][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057840] [Batch 02460/03692] [00:21:50/00:10:56, 0.533s/it]: train_loss_raw=0.8195, running_loss=0.8254, LR=0.000100
[2025-08-10 19:54:01,050][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057852] [Batch 02472/03692] [00:21:56/00:10:49, 0.533s/it]: train_loss_raw=0.8209, running_loss=0.8215, LR=0.000100
[2025-08-10 19:54:07,688][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057864] [Batch 02484/03692] [00:22:03/00:10:43, 0.533s/it]: train_loss_raw=0.8444, running_loss=0.8254, LR=0.000100
[2025-08-10 19:54:14,274][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057876] [Batch 02496/03692] [00:22:09/00:10:37, 0.533s/it]: train_loss_raw=0.8139, running_loss=0.8285, LR=0.000100
[2025-08-10 19:54:20,714][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057888] [Batch 02508/03692] [00:22:16/00:10:30, 0.533s/it]: train_loss_raw=0.8527, running_loss=0.8301, LR=0.000100
[2025-08-10 19:54:26,927][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057900] [Batch 02520/03692] [00:22:22/00:10:24, 0.533s/it]: train_loss_raw=0.7683, running_loss=0.8259, LR=0.000100
[2025-08-10 19:54:33,168][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057912] [Batch 02532/03692] [00:22:28/00:10:17, 0.533s/it]: train_loss_raw=0.7765, running_loss=0.8268, LR=0.000100
[2025-08-10 19:54:39,354][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057924] [Batch 02544/03692] [00:22:34/00:10:11, 0.533s/it]: train_loss_raw=0.8314, running_loss=0.8238, LR=0.000100
[2025-08-10 19:54:45,823][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057936] [Batch 02556/03692] [00:22:41/00:10:05, 0.533s/it]: train_loss_raw=0.7846, running_loss=0.8221, LR=0.000100
[2025-08-10 19:54:52,366][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057948] [Batch 02568/03692] [00:22:47/00:09:58, 0.533s/it]: train_loss_raw=0.8308, running_loss=0.8183, LR=0.000100
[2025-08-10 19:54:58,938][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057960] [Batch 02580/03692] [00:22:54/00:09:52, 0.533s/it]: train_loss_raw=0.7774, running_loss=0.8205, LR=0.000100
[2025-08-10 19:55:05,443][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057972] [Batch 02592/03692] [00:23:00/00:09:46, 0.533s/it]: train_loss_raw=0.8703, running_loss=0.8218, LR=0.000100
[2025-08-10 19:55:11,865][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057984] [Batch 02604/03692] [00:23:07/00:09:39, 0.533s/it]: train_loss_raw=0.7518, running_loss=0.8166, LR=0.000100
[2025-08-10 19:55:18,394][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057996] [Batch 02616/03692] [00:23:13/00:09:33, 0.533s/it]: train_loss_raw=0.8913, running_loss=0.8199, LR=0.000100
[2025-08-10 19:55:30,285][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058008] [Batch 02628/03692] [00:23:25/00:09:29, 0.535s/it]: train_loss_raw=0.7889, running_loss=0.8211, LR=0.000100
[2025-08-10 19:55:36,820][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058020] [Batch 02640/03692] [00:23:32/00:09:22, 0.535s/it]: train_loss_raw=0.7086, running_loss=0.8179, LR=0.000100
[2025-08-10 19:55:43,413][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058032] [Batch 02652/03692] [00:23:38/00:09:16, 0.535s/it]: train_loss_raw=0.9074, running_loss=0.8205, LR=0.000100
[2025-08-10 19:55:49,976][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058044] [Batch 02664/03692] [00:23:45/00:09:10, 0.535s/it]: train_loss_raw=0.8196, running_loss=0.8248, LR=0.000100
[2025-08-10 19:55:56,552][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058056] [Batch 02676/03692] [00:23:52/00:09:03, 0.535s/it]: train_loss_raw=0.8430, running_loss=0.8256, LR=0.000100
[2025-08-10 19:56:03,069][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058068] [Batch 02688/03692] [00:23:58/00:08:57, 0.535s/it]: train_loss_raw=0.7476, running_loss=0.8227, LR=0.000100
[2025-08-10 19:56:09,602][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058080] [Batch 02700/03692] [00:24:05/00:08:50, 0.535s/it]: train_loss_raw=0.8561, running_loss=0.8217, LR=0.000100
[2025-08-10 19:56:16,181][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058092] [Batch 02712/03692] [00:24:11/00:08:44, 0.535s/it]: train_loss_raw=0.8193, running_loss=0.8211, LR=0.000100
[2025-08-10 19:56:22,781][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058104] [Batch 02724/03692] [00:24:18/00:08:38, 0.535s/it]: train_loss_raw=0.8622, running_loss=0.8243, LR=0.000100
[2025-08-10 19:56:29,189][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058116] [Batch 02736/03692] [00:24:24/00:08:31, 0.535s/it]: train_loss_raw=0.7756, running_loss=0.8253, LR=0.000100
[2025-08-10 19:56:35,782][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058128] [Batch 02748/03692] [00:24:31/00:08:25, 0.535s/it]: train_loss_raw=0.7600, running_loss=0.8238, LR=0.000100
[2025-08-10 19:56:42,240][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058140] [Batch 02760/03692] [00:24:37/00:08:19, 0.535s/it]: train_loss_raw=0.7557, running_loss=0.8198, LR=0.000100
[2025-08-10 19:56:48,637][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058152] [Batch 02772/03692] [00:24:44/00:08:12, 0.535s/it]: train_loss_raw=0.8039, running_loss=0.8205, LR=0.000100
[2025-08-10 19:56:54,712][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058164] [Batch 02784/03692] [00:24:50/00:08:06, 0.535s/it]: train_loss_raw=0.7290, running_loss=0.8161, LR=0.000100
[2025-08-10 19:57:00,785][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058176] [Batch 02796/03692] [00:24:56/00:07:59, 0.535s/it]: train_loss_raw=0.8128, running_loss=0.8141, LR=0.000100
[2025-08-10 19:57:06,912][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058188] [Batch 02808/03692] [00:25:02/00:07:52, 0.535s/it]: train_loss_raw=0.8750, running_loss=0.8160, LR=0.000100
[2025-08-10 19:57:13,278][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058200] [Batch 02820/03692] [00:25:08/00:07:46, 0.535s/it]: train_loss_raw=0.8001, running_loss=0.8155, LR=0.000100
[2025-08-10 19:57:19,441][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058212] [Batch 02832/03692] [00:25:14/00:07:40, 0.535s/it]: train_loss_raw=0.7607, running_loss=0.8147, LR=0.000100
[2025-08-10 19:57:25,590][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058224] [Batch 02844/03692] [00:25:21/00:07:33, 0.535s/it]: train_loss_raw=0.7456, running_loss=0.8160, LR=0.000100
[2025-08-10 19:57:31,620][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058236] [Batch 02856/03692] [00:25:27/00:07:27, 0.535s/it]: train_loss_raw=0.8381, running_loss=0.8185, LR=0.000100
[2025-08-10 19:57:37,669][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058248] [Batch 02868/03692] [00:25:33/00:07:20, 0.535s/it]: train_loss_raw=0.8263, running_loss=0.8160, LR=0.000100
[2025-08-10 19:57:43,976][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058260] [Batch 02880/03692] [00:25:39/00:07:14, 0.535s/it]: train_loss_raw=0.7743, running_loss=0.8132, LR=0.000100
[2025-08-10 19:57:50,420][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058272] [Batch 02892/03692] [00:25:45/00:07:07, 0.535s/it]: train_loss_raw=0.7718, running_loss=0.8133, LR=0.000100
[2025-08-10 19:57:56,932][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058284] [Batch 02904/03692] [00:25:52/00:07:01, 0.535s/it]: train_loss_raw=0.7351, running_loss=0.8120, LR=0.000100
[2025-08-10 19:58:03,515][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058296] [Batch 02916/03692] [00:25:59/00:06:54, 0.535s/it]: train_loss_raw=0.8426, running_loss=0.8101, LR=0.000100
[2025-08-10 19:58:10,056][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058308] [Batch 02928/03692] [00:26:05/00:06:48, 0.535s/it]: train_loss_raw=0.8056, running_loss=0.8100, LR=0.000100
[2025-08-10 19:58:16,568][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058320] [Batch 02940/03692] [00:26:12/00:06:42, 0.535s/it]: train_loss_raw=0.7141, running_loss=0.8081, LR=0.000100
[2025-08-10 19:58:23,145][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058332] [Batch 02952/03692] [00:26:18/00:06:35, 0.535s/it]: train_loss_raw=0.7951, running_loss=0.8069, LR=0.000100
[2025-08-10 19:58:29,490][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058344] [Batch 02964/03692] [00:26:25/00:06:29, 0.535s/it]: train_loss_raw=0.8485, running_loss=0.8110, LR=0.000100
[2025-08-10 19:58:35,499][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058356] [Batch 02976/03692] [00:26:31/00:06:22, 0.535s/it]: train_loss_raw=0.7771, running_loss=0.8078, LR=0.000100
[2025-08-10 19:58:41,541][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058368] [Batch 02988/03692] [00:26:37/00:06:16, 0.534s/it]: train_loss_raw=0.8094, running_loss=0.8092, LR=0.000100
[2025-08-10 19:58:47,947][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058380] [Batch 03000/03692] [00:26:43/00:06:09, 0.534s/it]: train_loss_raw=0.8153, running_loss=0.8064, LR=0.000100
[2025-08-10 19:58:54,499][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058392] [Batch 03012/03692] [00:26:50/00:06:03, 0.535s/it]: train_loss_raw=0.8275, running_loss=0.8096, LR=0.000100
[2025-08-10 19:59:00,974][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058404] [Batch 03024/03692] [00:26:56/00:05:57, 0.535s/it]: train_loss_raw=0.6810, running_loss=0.8063, LR=0.000100
[2025-08-10 19:59:07,404][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058416] [Batch 03036/03692] [00:27:02/00:05:50, 0.535s/it]: train_loss_raw=0.7714, running_loss=0.8074, LR=0.000100
[2025-08-10 19:59:13,935][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058428] [Batch 03048/03692] [00:27:09/00:05:44, 0.535s/it]: train_loss_raw=0.9627, running_loss=0.8096, LR=0.000100
[2025-08-10 19:59:20,033][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058440] [Batch 03060/03692] [00:27:15/00:05:37, 0.534s/it]: train_loss_raw=0.7000, running_loss=0.8075, LR=0.000100
[2025-08-10 19:59:26,168][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058452] [Batch 03072/03692] [00:27:21/00:05:31, 0.534s/it]: train_loss_raw=0.8605, running_loss=0.8113, LR=0.000100
[2025-08-10 19:59:32,385][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058464] [Batch 03084/03692] [00:27:27/00:05:24, 0.534s/it]: train_loss_raw=0.9140, running_loss=0.8128, LR=0.000100
[2025-08-10 19:59:38,962][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058476] [Batch 03096/03692] [00:27:34/00:05:18, 0.534s/it]: train_loss_raw=0.9811, running_loss=0.8136, LR=0.000100
[2025-08-10 19:59:45,547][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058488] [Batch 03108/03692] [00:27:41/00:05:12, 0.534s/it]: train_loss_raw=0.8457, running_loss=0.8105, LR=0.000100
[2025-08-10 19:59:51,737][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058500] [Batch 03120/03692] [00:27:47/00:05:05, 0.534s/it]: train_loss_raw=0.7280, running_loss=0.8129, LR=0.000100
[2025-08-10 19:59:58,290][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058512] [Batch 03132/03692] [00:27:53/00:04:59, 0.534s/it]: train_loss_raw=0.7868, running_loss=0.8094, LR=0.000100
[2025-08-10 20:00:04,861][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058524] [Batch 03144/03692] [00:28:00/00:04:52, 0.534s/it]: train_loss_raw=0.8898, running_loss=0.8128, LR=0.000100
[2025-08-10 20:00:11,450][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058536] [Batch 03156/03692] [00:28:06/00:04:46, 0.535s/it]: train_loss_raw=0.7644, running_loss=0.8123, LR=0.000100
[2025-08-10 20:00:18,020][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058548] [Batch 03168/03692] [00:28:13/00:04:40, 0.535s/it]: train_loss_raw=0.7030, running_loss=0.8093, LR=0.000100
[2025-08-10 20:00:24,543][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058560] [Batch 03180/03692] [00:28:20/00:04:33, 0.535s/it]: train_loss_raw=0.8406, running_loss=0.8112, LR=0.000100
[2025-08-10 20:00:30,908][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058572] [Batch 03192/03692] [00:28:26/00:04:27, 0.535s/it]: train_loss_raw=0.8744, running_loss=0.8105, LR=0.000100
[2025-08-10 20:00:37,424][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058584] [Batch 03204/03692] [00:28:32/00:04:20, 0.535s/it]: train_loss_raw=0.7635, running_loss=0.8118, LR=0.000100
[2025-08-10 20:00:43,439][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058596] [Batch 03216/03692] [00:28:38/00:04:14, 0.535s/it]: train_loss_raw=0.8038, running_loss=0.8144, LR=0.000100
[2025-08-10 20:00:49,537][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058608] [Batch 03228/03692] [00:28:45/00:04:07, 0.534s/it]: train_loss_raw=0.8774, running_loss=0.8139, LR=0.000100
[2025-08-10 20:00:55,605][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058620] [Batch 03240/03692] [00:28:51/00:04:01, 0.534s/it]: train_loss_raw=0.8539, running_loss=0.8119, LR=0.000100
[2025-08-10 20:01:02,018][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058632] [Batch 03252/03692] [00:28:57/00:03:55, 0.534s/it]: train_loss_raw=0.7679, running_loss=0.8129, LR=0.000100
[2025-08-10 20:01:08,559][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058644] [Batch 03264/03692] [00:29:04/00:03:48, 0.534s/it]: train_loss_raw=0.8252, running_loss=0.8139, LR=0.000100
[2025-08-10 20:01:15,182][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058656] [Batch 03276/03692] [00:29:10/00:03:42, 0.534s/it]: train_loss_raw=0.9792, running_loss=0.8140, LR=0.000100
[2025-08-10 20:01:21,830][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058668] [Batch 03288/03692] [00:29:17/00:03:35, 0.534s/it]: train_loss_raw=0.7348, running_loss=0.8129, LR=0.000100
[2025-08-10 20:01:28,381][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058680] [Batch 03300/03692] [00:29:23/00:03:29, 0.535s/it]: train_loss_raw=0.8746, running_loss=0.8127, LR=0.000100
[2025-08-10 20:01:34,928][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058692] [Batch 03312/03692] [00:29:30/00:03:23, 0.535s/it]: train_loss_raw=0.8692, running_loss=0.8132, LR=0.000100
[2025-08-10 20:01:41,322][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058704] [Batch 03324/03692] [00:29:36/00:03:16, 0.535s/it]: train_loss_raw=0.9282, running_loss=0.8174, LR=0.000100
[2025-08-10 20:01:47,721][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058716] [Batch 03336/03692] [00:29:43/00:03:10, 0.535s/it]: train_loss_raw=0.7130, running_loss=0.8134, LR=0.000100
[2025-08-10 20:01:54,187][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058728] [Batch 03348/03692] [00:29:49/00:03:03, 0.535s/it]: train_loss_raw=0.8042, running_loss=0.8125, LR=0.000100
[2025-08-10 20:02:00,641][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058740] [Batch 03360/03692] [00:29:56/00:02:57, 0.535s/it]: train_loss_raw=0.8478, running_loss=0.8143, LR=0.000100
[2025-08-10 20:02:07,195][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058752] [Batch 03372/03692] [00:30:02/00:02:51, 0.535s/it]: train_loss_raw=0.8004, running_loss=0.8129, LR=0.000100
[2025-08-10 20:02:13,753][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058764] [Batch 03384/03692] [00:30:09/00:02:44, 0.535s/it]: train_loss_raw=0.7481, running_loss=0.8118, LR=0.000100
[2025-08-10 20:02:20,198][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058776] [Batch 03396/03692] [00:30:15/00:02:38, 0.535s/it]: train_loss_raw=0.7987, running_loss=0.8100, LR=0.000100
[2025-08-10 20:02:26,734][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058788] [Batch 03408/03692] [00:30:22/00:02:31, 0.535s/it]: train_loss_raw=0.8640, running_loss=0.8110, LR=0.000100
[2025-08-10 20:02:33,199][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058800] [Batch 03420/03692] [00:30:28/00:02:25, 0.535s/it]: train_loss_raw=0.8731, running_loss=0.8122, LR=0.000100
[2025-08-10 20:02:39,742][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058812] [Batch 03432/03692] [00:30:35/00:02:19, 0.535s/it]: train_loss_raw=0.8559, running_loss=0.8136, LR=0.000100
[2025-08-10 20:02:46,187][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058824] [Batch 03444/03692] [00:30:41/00:02:12, 0.535s/it]: train_loss_raw=0.8387, running_loss=0.8121, LR=0.000100
[2025-08-10 20:02:52,744][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058836] [Batch 03456/03692] [00:30:48/00:02:06, 0.535s/it]: train_loss_raw=0.7388, running_loss=0.8115, LR=0.000100
[2025-08-10 20:02:59,199][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058848] [Batch 03468/03692] [00:30:54/00:01:59, 0.535s/it]: train_loss_raw=0.7217, running_loss=0.8102, LR=0.000100
[2025-08-10 20:03:05,632][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058860] [Batch 03480/03692] [00:31:01/00:01:53, 0.535s/it]: train_loss_raw=0.8239, running_loss=0.8091, LR=0.000100
[2025-08-10 20:03:11,944][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058872] [Batch 03492/03692] [00:31:07/00:01:46, 0.535s/it]: train_loss_raw=0.8524, running_loss=0.8070, LR=0.000100
[2025-08-10 20:03:17,944][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058884] [Batch 03504/03692] [00:31:13/00:01:40, 0.535s/it]: train_loss_raw=0.8485, running_loss=0.8041, LR=0.000100
[2025-08-10 20:03:24,016][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058896] [Batch 03516/03692] [00:31:19/00:01:34, 0.535s/it]: train_loss_raw=0.7796, running_loss=0.8077, LR=0.000100
[2025-08-10 20:03:30,009][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058908] [Batch 03528/03692] [00:31:25/00:01:27, 0.534s/it]: train_loss_raw=0.6974, running_loss=0.8071, LR=0.000100
[2025-08-10 20:03:36,002][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058920] [Batch 03540/03692] [00:31:31/00:01:21, 0.534s/it]: train_loss_raw=0.7491, running_loss=0.8079, LR=0.000100
[2025-08-10 20:03:42,093][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058932] [Batch 03552/03692] [00:31:37/00:01:14, 0.534s/it]: train_loss_raw=0.7005, running_loss=0.8051, LR=0.000100
[2025-08-10 20:03:48,110][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058944] [Batch 03564/03692] [00:31:43/00:01:08, 0.534s/it]: train_loss_raw=0.7581, running_loss=0.8028, LR=0.000100
[2025-08-10 20:03:54,150][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058956] [Batch 03576/03692] [00:31:49/00:01:01, 0.534s/it]: train_loss_raw=0.7756, running_loss=0.8020, LR=0.000100
[2025-08-10 20:04:00,156][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058968] [Batch 03588/03692] [00:31:55/00:00:55, 0.534s/it]: train_loss_raw=0.7543, running_loss=0.7991, LR=0.000100
[2025-08-10 20:04:06,201][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058980] [Batch 03600/03692] [00:32:01/00:00:49, 0.534s/it]: train_loss_raw=0.8103, running_loss=0.7981, LR=0.000100
[2025-08-10 20:04:12,265][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058992] [Batch 03612/03692] [00:32:07/00:00:42, 0.534s/it]: train_loss_raw=0.8029, running_loss=0.7973, LR=0.000100
[2025-08-10 20:04:18,392][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059004] [Batch 03624/03692] [00:32:13/00:00:36, 0.534s/it]: train_loss_raw=0.8449, running_loss=0.8011, LR=0.000100
[2025-08-10 20:04:24,414][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059016] [Batch 03636/03692] [00:32:19/00:00:29, 0.534s/it]: train_loss_raw=0.8078, running_loss=0.8007, LR=0.000100
[2025-08-10 20:04:30,875][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059028] [Batch 03648/03692] [00:32:26/00:00:23, 0.534s/it]: train_loss_raw=0.8126, running_loss=0.8013, LR=0.000100
[2025-08-10 20:04:37,338][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059040] [Batch 03660/03692] [00:32:32/00:00:17, 0.534s/it]: train_loss_raw=0.8712, running_loss=0.8022, LR=0.000100
[2025-08-10 20:04:43,792][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059052] [Batch 03672/03692] [00:32:39/00:00:10, 0.534s/it]: train_loss_raw=0.7753, running_loss=0.7998, LR=0.000100
[2025-08-10 20:04:50,356][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059064] [Batch 03684/03692] [00:32:45/00:00:04, 0.534s/it]: train_loss_raw=0.7731, running_loss=0.8006, LR=0.000100
[2025-08-10 20:05:25,233][__main__][INFO] - [VALIDATION] [Epoch 15/29] Starting validation.
[2025-08-10 20:05:57,911][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 059073] [Batch 00011/00025] [00:00:32/00:00:35, 2.723s/it]
[2025-08-10 20:06:12,804][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 059073] [Batch 00023/00025] [00:00:47/00:00:01, 1.982s/it]
[2025-08-10 20:06:13,774][__main__][INFO] - [VALIDATION] [Epoch 15/29] train_loss=0.80166, valid_loss=0.82003
[2025-08-10 20:06:13,775][__main__][INFO] - [VALIDATION] [Epoch 15/29] Metrics:
[2025-08-10 20:06:13,775][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_er      0.365
[2025-08-10 20:06:13,775][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_prec    0.377
[2025-08-10 20:06:13,775][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_recall  0.382
[2025-08-10 20:06:13,775][__main__][INFO] - [VALIDATION] [Epoch 15/29] - pep_recall 0.336
[2025-08-10 20:06:13,778][__main__][INFO] - [TRAIN] [Epoch 15/29] Epoch complete, total time 09:10:13, remaining time 08:01:26, 00:34:23 per epoch
[2025-08-10 20:06:15,555][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059076] [Batch 00004/03692] [00:00:01/00:24:28, 0.398s/it]: train_loss_raw=0.6799, running_loss=0.7407, LR=0.000100
[2025-08-10 20:06:22,006][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059088] [Batch 00016/03692] [00:00:08/00:30:48, 0.503s/it]: train_loss_raw=0.8413, running_loss=0.7394, LR=0.000100
[2025-08-10 20:06:28,561][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059100] [Batch 00028/03692] [00:00:14/00:31:50, 0.521s/it]: train_loss_raw=0.7661, running_loss=0.7451, LR=0.000100
[2025-08-10 20:06:35,028][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059112] [Batch 00040/03692] [00:00:21/00:32:03, 0.527s/it]: train_loss_raw=0.7262, running_loss=0.7460, LR=0.000100
[2025-08-10 20:06:41,561][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059124] [Batch 00052/03692] [00:00:27/00:32:11, 0.531s/it]: train_loss_raw=0.7904, running_loss=0.7498, LR=0.000100
[2025-08-10 20:06:48,098][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059136] [Batch 00064/03692] [00:00:34/00:32:15, 0.533s/it]: train_loss_raw=0.6941, running_loss=0.7489, LR=0.000100
[2025-08-10 20:06:54,509][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059148] [Batch 00076/03692] [00:00:40/00:32:09, 0.534s/it]: train_loss_raw=0.8264, running_loss=0.7503, LR=0.000100
[2025-08-10 20:07:00,938][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059160] [Batch 00088/03692] [00:00:46/00:32:03, 0.534s/it]: train_loss_raw=0.8408, running_loss=0.7524, LR=0.000100
[2025-08-10 20:07:07,357][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059172] [Batch 00100/03692] [00:00:53/00:31:57, 0.534s/it]: train_loss_raw=0.8043, running_loss=0.7477, LR=0.000100
[2025-08-10 20:07:13,753][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059184] [Batch 00112/03692] [00:00:59/00:31:51, 0.534s/it]: train_loss_raw=0.7228, running_loss=0.7486, LR=0.000100
[2025-08-10 20:07:20,317][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059196] [Batch 00124/03692] [00:01:06/00:31:49, 0.535s/it]: train_loss_raw=0.7287, running_loss=0.7519, LR=0.000100
[2025-08-10 20:07:26,664][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059208] [Batch 00136/03692] [00:01:12/00:31:40, 0.535s/it]: train_loss_raw=0.7481, running_loss=0.7528, LR=0.000100
[2025-08-10 20:07:33,060][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059220] [Batch 00148/03692] [00:01:19/00:31:34, 0.534s/it]: train_loss_raw=0.7378, running_loss=0.7486, LR=0.000100
[2025-08-10 20:07:39,356][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059232] [Batch 00160/03692] [00:01:25/00:31:25, 0.534s/it]: train_loss_raw=0.7485, running_loss=0.7502, LR=0.000100
[2025-08-10 20:07:45,741][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059244] [Batch 00172/03692] [00:01:31/00:31:18, 0.534s/it]: train_loss_raw=0.7833, running_loss=0.7491, LR=0.000100
[2025-08-10 20:07:52,083][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059256] [Batch 00184/03692] [00:01:38/00:31:10, 0.533s/it]: train_loss_raw=0.6740, running_loss=0.7480, LR=0.000100
[2025-08-10 20:07:58,563][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059268] [Batch 00196/03692] [00:01:44/00:31:05, 0.534s/it]: train_loss_raw=0.7921, running_loss=0.7491, LR=0.000100
[2025-08-10 20:08:05,157][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059280] [Batch 00208/03692] [00:01:51/00:31:02, 0.535s/it]: train_loss_raw=0.7595, running_loss=0.7547, LR=0.000100
[2025-08-10 20:08:11,605][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059292] [Batch 00220/03692] [00:01:57/00:30:56, 0.535s/it]: train_loss_raw=0.8084, running_loss=0.7555, LR=0.000100
[2025-08-10 20:08:18,093][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059304] [Batch 00232/03692] [00:02:04/00:30:51, 0.535s/it]: train_loss_raw=0.7809, running_loss=0.7555, LR=0.000100
[2025-08-10 20:08:24,625][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059316] [Batch 00244/03692] [00:02:10/00:30:46, 0.536s/it]: train_loss_raw=0.8405, running_loss=0.7576, LR=0.000100
[2025-08-10 20:08:31,168][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059328] [Batch 00256/03692] [00:02:17/00:30:41, 0.536s/it]: train_loss_raw=0.6528, running_loss=0.7587, LR=0.000100
[2025-08-10 20:08:37,604][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059340] [Batch 00268/03692] [00:02:23/00:30:35, 0.536s/it]: train_loss_raw=0.6971, running_loss=0.7595, LR=0.000100
[2025-08-10 20:08:44,047][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059352] [Batch 00280/03692] [00:02:30/00:30:28, 0.536s/it]: train_loss_raw=0.7786, running_loss=0.7604, LR=0.000100
[2025-08-10 20:08:50,472][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059364] [Batch 00292/03692] [00:02:36/00:30:22, 0.536s/it]: train_loss_raw=0.8150, running_loss=0.7625, LR=0.000100
[2025-08-10 20:08:56,856][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059376] [Batch 00304/03692] [00:02:42/00:30:15, 0.536s/it]: train_loss_raw=0.6548, running_loss=0.7630, LR=0.000100
[2025-08-10 20:09:03,386][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059388] [Batch 00316/03692] [00:02:49/00:30:10, 0.536s/it]: train_loss_raw=0.7201, running_loss=0.7629, LR=0.000100
[2025-08-10 20:09:09,814][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059400] [Batch 00328/03692] [00:02:55/00:30:03, 0.536s/it]: train_loss_raw=0.9230, running_loss=0.7640, LR=0.000100
[2025-08-10 20:09:16,263][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059412] [Batch 00340/03692] [00:03:02/00:29:57, 0.536s/it]: train_loss_raw=0.7535, running_loss=0.7638, LR=0.000100
[2025-08-10 20:09:22,742][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059424] [Batch 00352/03692] [00:03:08/00:29:51, 0.536s/it]: train_loss_raw=0.7725, running_loss=0.7645, LR=0.000100
[2025-08-10 20:09:29,149][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059436] [Batch 00364/03692] [00:03:15/00:29:44, 0.536s/it]: train_loss_raw=0.7777, running_loss=0.7628, LR=0.000100
[2025-08-10 20:09:35,668][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059448] [Batch 00376/03692] [00:03:21/00:29:38, 0.536s/it]: train_loss_raw=0.7305, running_loss=0.7609, LR=0.000100
[2025-08-10 20:09:42,155][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059460] [Batch 00388/03692] [00:03:28/00:29:32, 0.537s/it]: train_loss_raw=0.6538, running_loss=0.7640, LR=0.000100
[2025-08-10 20:09:48,559][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059472] [Batch 00400/03692] [00:03:34/00:29:26, 0.536s/it]: train_loss_raw=0.6870, running_loss=0.7628, LR=0.000100
[2025-08-10 20:09:54,938][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059484] [Batch 00412/03692] [00:03:40/00:29:19, 0.536s/it]: train_loss_raw=0.7682, running_loss=0.7619, LR=0.000100
[2025-08-10 20:10:01,322][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059496] [Batch 00424/03692] [00:03:47/00:29:12, 0.536s/it]: train_loss_raw=0.8912, running_loss=0.7615, LR=0.000100
[2025-08-10 20:10:07,802][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059508] [Batch 00436/03692] [00:03:53/00:29:06, 0.536s/it]: train_loss_raw=0.6585, running_loss=0.7588, LR=0.000100
[2025-08-10 20:10:14,339][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059520] [Batch 00448/03692] [00:04:00/00:29:00, 0.537s/it]: train_loss_raw=0.6840, running_loss=0.7574, LR=0.000100
[2025-08-10 20:10:20,766][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059532] [Batch 00460/03692] [00:04:06/00:28:54, 0.537s/it]: train_loss_raw=0.8470, running_loss=0.7550, LR=0.000100
[2025-08-10 20:10:27,216][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059544] [Batch 00472/03692] [00:04:13/00:28:47, 0.537s/it]: train_loss_raw=0.6282, running_loss=0.7532, LR=0.000100
[2025-08-10 20:10:33,677][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059556] [Batch 00484/03692] [00:04:19/00:28:41, 0.537s/it]: train_loss_raw=0.7674, running_loss=0.7525, LR=0.000100
[2025-08-10 20:10:40,087][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059568] [Batch 00496/03692] [00:04:26/00:28:34, 0.537s/it]: train_loss_raw=0.7331, running_loss=0.7545, LR=0.000100
[2025-08-10 20:10:46,562][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059580] [Batch 00508/03692] [00:04:32/00:28:28, 0.537s/it]: train_loss_raw=0.6594, running_loss=0.7489, LR=0.000100
[2025-08-10 20:10:52,947][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059592] [Batch 00520/03692] [00:04:38/00:28:21, 0.537s/it]: train_loss_raw=0.8215, running_loss=0.7500, LR=0.000100
[2025-08-10 20:10:59,289][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059604] [Batch 00532/03692] [00:04:45/00:28:14, 0.536s/it]: train_loss_raw=0.6844, running_loss=0.7503, LR=0.000100
[2025-08-10 20:11:05,709][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059616] [Batch 00544/03692] [00:04:51/00:28:08, 0.536s/it]: train_loss_raw=0.6788, running_loss=0.7521, LR=0.000100
[2025-08-10 20:11:12,100][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059628] [Batch 00556/03692] [00:04:58/00:28:01, 0.536s/it]: train_loss_raw=0.7531, running_loss=0.7560, LR=0.000100
[2025-08-10 20:11:18,503][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059640] [Batch 00568/03692] [00:05:04/00:27:54, 0.536s/it]: train_loss_raw=0.8523, running_loss=0.7571, LR=0.000100
[2025-08-10 20:11:24,897][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059652] [Batch 00580/03692] [00:05:10/00:27:48, 0.536s/it]: train_loss_raw=0.8184, running_loss=0.7532, LR=0.000100
[2025-08-10 20:11:31,380][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059664] [Batch 00592/03692] [00:05:17/00:27:42, 0.536s/it]: train_loss_raw=0.7181, running_loss=0.7511, LR=0.000100
[2025-08-10 20:11:37,811][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059676] [Batch 00604/03692] [00:05:23/00:27:35, 0.536s/it]: train_loss_raw=0.6744, running_loss=0.7515, LR=0.000100
[2025-08-10 20:11:44,197][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059688] [Batch 00616/03692] [00:05:30/00:27:29, 0.536s/it]: train_loss_raw=0.7478, running_loss=0.7529, LR=0.000100
[2025-08-10 20:11:50,695][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059700] [Batch 00628/03692] [00:05:36/00:27:22, 0.536s/it]: train_loss_raw=0.7850, running_loss=0.7539, LR=0.000100
[2025-08-10 20:11:57,170][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059712] [Batch 00640/03692] [00:05:43/00:27:16, 0.536s/it]: train_loss_raw=0.6964, running_loss=0.7554, LR=0.000100
[2025-08-10 20:12:03,570][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059724] [Batch 00652/03692] [00:05:49/00:27:10, 0.536s/it]: train_loss_raw=0.7621, running_loss=0.7520, LR=0.000100
[2025-08-10 20:12:09,981][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059736] [Batch 00664/03692] [00:05:56/00:27:03, 0.536s/it]: train_loss_raw=0.8833, running_loss=0.7540, LR=0.000100
[2025-08-10 20:12:16,381][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059748] [Batch 00676/03692] [00:06:02/00:26:56, 0.536s/it]: train_loss_raw=0.8036, running_loss=0.7539, LR=0.000100
[2025-08-10 20:12:22,763][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059760] [Batch 00688/03692] [00:06:08/00:26:50, 0.536s/it]: train_loss_raw=0.7136, running_loss=0.7561, LR=0.000100
[2025-08-10 20:12:29,316][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059772] [Batch 00700/03692] [00:06:15/00:26:44, 0.536s/it]: train_loss_raw=0.7082, running_loss=0.7562, LR=0.000100
[2025-08-10 20:12:35,854][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059784] [Batch 00712/03692] [00:06:21/00:26:38, 0.536s/it]: train_loss_raw=0.8066, running_loss=0.7561, LR=0.000100
[2025-08-10 20:12:42,299][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059796] [Batch 00724/03692] [00:06:28/00:26:31, 0.536s/it]: train_loss_raw=0.7487, running_loss=0.7559, LR=0.000100
[2025-08-10 20:12:48,733][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059808] [Batch 00736/03692] [00:06:34/00:26:25, 0.536s/it]: train_loss_raw=0.7990, running_loss=0.7571, LR=0.000100
[2025-08-10 20:12:55,093][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059820] [Batch 00748/03692] [00:06:41/00:26:18, 0.536s/it]: train_loss_raw=0.7969, running_loss=0.7566, LR=0.000100
[2025-08-10 20:13:01,512][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059832] [Batch 00760/03692] [00:06:47/00:26:12, 0.536s/it]: train_loss_raw=0.8055, running_loss=0.7562, LR=0.000100
[2025-08-10 20:13:07,969][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059844] [Batch 00772/03692] [00:06:54/00:26:05, 0.536s/it]: train_loss_raw=0.6602, running_loss=0.7563, LR=0.000100
[2025-08-10 20:13:14,398][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059856] [Batch 00784/03692] [00:07:00/00:25:59, 0.536s/it]: train_loss_raw=0.8222, running_loss=0.7558, LR=0.000100
[2025-08-10 20:13:20,874][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059868] [Batch 00796/03692] [00:07:06/00:25:53, 0.536s/it]: train_loss_raw=0.6176, running_loss=0.7524, LR=0.000100
[2025-08-10 20:13:27,278][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059880] [Batch 00808/03692] [00:07:13/00:25:46, 0.536s/it]: train_loss_raw=0.6992, running_loss=0.7540, LR=0.000100
[2025-08-10 20:13:33,597][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059892] [Batch 00820/03692] [00:07:19/00:25:39, 0.536s/it]: train_loss_raw=0.8391, running_loss=0.7549, LR=0.000100
[2025-08-10 20:13:39,979][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059904] [Batch 00832/03692] [00:07:26/00:25:33, 0.536s/it]: train_loss_raw=0.8500, running_loss=0.7576, LR=0.000100
[2025-08-10 20:13:46,442][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059916] [Batch 00844/03692] [00:07:32/00:25:26, 0.536s/it]: train_loss_raw=0.8761, running_loss=0.7576, LR=0.000100
[2025-08-10 20:13:52,839][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059928] [Batch 00856/03692] [00:07:38/00:25:20, 0.536s/it]: train_loss_raw=0.8533, running_loss=0.7599, LR=0.000100
[2025-08-10 20:13:59,088][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059940] [Batch 00868/03692] [00:07:45/00:25:13, 0.536s/it]: train_loss_raw=0.7806, running_loss=0.7588, LR=0.000100
[2025-08-10 20:14:05,326][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059952] [Batch 00880/03692] [00:07:51/00:25:06, 0.536s/it]: train_loss_raw=0.8851, running_loss=0.7585, LR=0.000100
[2025-08-10 20:14:11,652][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059964] [Batch 00892/03692] [00:07:57/00:24:59, 0.536s/it]: train_loss_raw=0.6813, running_loss=0.7583, LR=0.000100
[2025-08-10 20:14:18,106][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059976] [Batch 00904/03692] [00:08:04/00:24:53, 0.536s/it]: train_loss_raw=0.7873, running_loss=0.7583, LR=0.000100
[2025-08-10 20:14:24,652][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059988] [Batch 00916/03692] [00:08:10/00:24:47, 0.536s/it]: train_loss_raw=0.7637, running_loss=0.7600, LR=0.000100
[2025-08-10 20:14:31,190][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060000] [Batch 00928/03692] [00:08:17/00:24:40, 0.536s/it]: train_loss_raw=0.7858, running_loss=0.7573, LR=0.000100
[2025-08-10 20:14:42,659][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060012] [Batch 00940/03692] [00:08:28/00:24:49, 0.541s/it]: train_loss_raw=0.8080, running_loss=0.7553, LR=0.000100
[2025-08-10 20:14:49,368][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060024] [Batch 00952/03692] [00:08:35/00:24:43, 0.541s/it]: train_loss_raw=0.6961, running_loss=0.7536, LR=0.000100
[2025-08-10 20:14:56,022][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060036] [Batch 00964/03692] [00:08:42/00:24:37, 0.542s/it]: train_loss_raw=0.8157, running_loss=0.7542, LR=0.000100
[2025-08-10 20:15:02,484][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060048] [Batch 00976/03692] [00:08:48/00:24:30, 0.542s/it]: train_loss_raw=0.7251, running_loss=0.7551, LR=0.000100
[2025-08-10 20:15:09,026][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060060] [Batch 00988/03692] [00:08:55/00:24:24, 0.542s/it]: train_loss_raw=0.6303, running_loss=0.7548, LR=0.000100
[2025-08-10 20:15:15,507][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060072] [Batch 01000/03692] [00:09:01/00:24:17, 0.542s/it]: train_loss_raw=0.7381, running_loss=0.7534, LR=0.000100
[2025-08-10 20:15:22,017][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060084] [Batch 01012/03692] [00:09:08/00:24:11, 0.542s/it]: train_loss_raw=0.6857, running_loss=0.7557, LR=0.000100
[2025-08-10 20:15:28,551][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060096] [Batch 01024/03692] [00:09:14/00:24:04, 0.542s/it]: train_loss_raw=0.6719, running_loss=0.7547, LR=0.000100
[2025-08-10 20:15:35,118][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060108] [Batch 01036/03692] [00:09:21/00:23:58, 0.542s/it]: train_loss_raw=0.8203, running_loss=0.7563, LR=0.000100
[2025-08-10 20:15:41,563][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060120] [Batch 01048/03692] [00:09:27/00:23:52, 0.542s/it]: train_loss_raw=0.7198, running_loss=0.7548, LR=0.000100
[2025-08-10 20:15:47,955][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060132] [Batch 01060/03692] [00:09:33/00:23:45, 0.542s/it]: train_loss_raw=0.7137, running_loss=0.7513, LR=0.000100
[2025-08-10 20:15:54,296][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060144] [Batch 01072/03692] [00:09:40/00:23:38, 0.541s/it]: train_loss_raw=0.7154, running_loss=0.7500, LR=0.000100
[2025-08-10 20:16:00,657][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060156] [Batch 01084/03692] [00:09:46/00:23:31, 0.541s/it]: train_loss_raw=0.6117, running_loss=0.7506, LR=0.000100
[2025-08-10 20:16:07,109][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060168] [Batch 01096/03692] [00:09:53/00:23:24, 0.541s/it]: train_loss_raw=0.8052, running_loss=0.7502, LR=0.000100
[2025-08-10 20:16:13,615][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060180] [Batch 01108/03692] [00:09:59/00:23:18, 0.541s/it]: train_loss_raw=0.8217, running_loss=0.7530, LR=0.000100
[2025-08-10 20:16:19,963][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060192] [Batch 01120/03692] [00:10:06/00:23:11, 0.541s/it]: train_loss_raw=0.8990, running_loss=0.7543, LR=0.000100
[2025-08-10 20:16:26,387][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060204] [Batch 01132/03692] [00:10:12/00:23:04, 0.541s/it]: train_loss_raw=0.6554, running_loss=0.7532, LR=0.000100
[2025-08-10 20:16:32,732][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060216] [Batch 01144/03692] [00:10:18/00:22:58, 0.541s/it]: train_loss_raw=0.7473, running_loss=0.7503, LR=0.000100
[2025-08-10 20:16:39,130][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060228] [Batch 01156/03692] [00:10:25/00:22:51, 0.541s/it]: train_loss_raw=0.6497, running_loss=0.7477, LR=0.000100
[2025-08-10 20:16:45,531][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060240] [Batch 01168/03692] [00:10:31/00:22:44, 0.541s/it]: train_loss_raw=0.8321, running_loss=0.7466, LR=0.000100
[2025-08-10 20:16:51,936][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060252] [Batch 01180/03692] [00:10:37/00:22:38, 0.541s/it]: train_loss_raw=0.6642, running_loss=0.7483, LR=0.000100
[2025-08-10 20:16:58,409][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060264] [Batch 01192/03692] [00:10:44/00:22:31, 0.541s/it]: train_loss_raw=0.6921, running_loss=0.7530, LR=0.000100
[2025-08-10 20:17:04,785][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060276] [Batch 01204/03692] [00:10:50/00:22:24, 0.541s/it]: train_loss_raw=0.7813, running_loss=0.7541, LR=0.000100
[2025-08-10 20:17:11,182][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060288] [Batch 01216/03692] [00:10:57/00:22:18, 0.540s/it]: train_loss_raw=0.8420, running_loss=0.7517, LR=0.000100
[2025-08-10 20:17:17,568][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060300] [Batch 01228/03692] [00:11:03/00:22:11, 0.540s/it]: train_loss_raw=0.7570, running_loss=0.7507, LR=0.000100
[2025-08-10 20:17:24,007][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060312] [Batch 01240/03692] [00:11:10/00:22:04, 0.540s/it]: train_loss_raw=0.7348, running_loss=0.7528, LR=0.000100
[2025-08-10 20:17:30,468][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060324] [Batch 01252/03692] [00:11:16/00:21:58, 0.540s/it]: train_loss_raw=0.9473, running_loss=0.7551, LR=0.000100
[2025-08-10 20:17:36,931][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060336] [Batch 01264/03692] [00:11:22/00:21:51, 0.540s/it]: train_loss_raw=0.7762, running_loss=0.7518, LR=0.000100
[2025-08-10 20:17:43,310][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060348] [Batch 01276/03692] [00:11:29/00:21:45, 0.540s/it]: train_loss_raw=0.9045, running_loss=0.7564, LR=0.000100
[2025-08-10 20:17:49,707][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060360] [Batch 01288/03692] [00:11:35/00:21:38, 0.540s/it]: train_loss_raw=0.7068, running_loss=0.7561, LR=0.000100
[2025-08-10 20:17:56,122][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060372] [Batch 01300/03692] [00:11:42/00:21:31, 0.540s/it]: train_loss_raw=0.8192, running_loss=0.7543, LR=0.000100
[2025-08-10 20:18:02,492][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060384] [Batch 01312/03692] [00:11:48/00:21:25, 0.540s/it]: train_loss_raw=0.7639, running_loss=0.7570, LR=0.000100
[2025-08-10 20:18:08,873][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060396] [Batch 01324/03692] [00:11:54/00:21:18, 0.540s/it]: train_loss_raw=0.8207, running_loss=0.7571, LR=0.000100
[2025-08-10 20:18:15,230][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060408] [Batch 01336/03692] [00:12:01/00:21:11, 0.540s/it]: train_loss_raw=0.7340, running_loss=0.7608, LR=0.000100
[2025-08-10 20:18:21,564][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060420] [Batch 01348/03692] [00:12:07/00:21:05, 0.540s/it]: train_loss_raw=0.7392, running_loss=0.7608, LR=0.000100
[2025-08-10 20:18:27,978][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060432] [Batch 01360/03692] [00:12:14/00:20:58, 0.540s/it]: train_loss_raw=0.8424, running_loss=0.7580, LR=0.000100
[2025-08-10 20:18:34,388][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060444] [Batch 01372/03692] [00:12:20/00:20:52, 0.540s/it]: train_loss_raw=0.8205, running_loss=0.7597, LR=0.000100
[2025-08-10 20:18:40,775][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060456] [Batch 01384/03692] [00:12:26/00:20:45, 0.540s/it]: train_loss_raw=0.7903, running_loss=0.7598, LR=0.000100
[2025-08-10 20:18:47,139][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060468] [Batch 01396/03692] [00:12:33/00:20:38, 0.540s/it]: train_loss_raw=0.7033, running_loss=0.7571, LR=0.000100
[2025-08-10 20:18:53,596][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060480] [Batch 01408/03692] [00:12:39/00:20:32, 0.540s/it]: train_loss_raw=0.8087, running_loss=0.7577, LR=0.000100
[2025-08-10 20:18:59,943][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060492] [Batch 01420/03692] [00:12:45/00:20:25, 0.539s/it]: train_loss_raw=0.7781, running_loss=0.7582, LR=0.000100
[2025-08-10 20:19:06,257][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060504] [Batch 01432/03692] [00:12:52/00:20:18, 0.539s/it]: train_loss_raw=0.6532, running_loss=0.7550, LR=0.000100
[2025-08-10 20:19:12,595][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060516] [Batch 01444/03692] [00:12:58/00:20:12, 0.539s/it]: train_loss_raw=0.7455, running_loss=0.7517, LR=0.000100
[2025-08-10 20:19:19,035][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060528] [Batch 01456/03692] [00:13:05/00:20:05, 0.539s/it]: train_loss_raw=0.7177, running_loss=0.7502, LR=0.000100
[2025-08-10 20:19:25,396][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060540] [Batch 01468/03692] [00:13:11/00:19:59, 0.539s/it]: train_loss_raw=0.7145, running_loss=0.7456, LR=0.000100
[2025-08-10 20:19:31,804][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060552] [Batch 01480/03692] [00:13:17/00:19:52, 0.539s/it]: train_loss_raw=0.6762, running_loss=0.7440, LR=0.000100
[2025-08-10 20:19:38,173][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060564] [Batch 01492/03692] [00:13:24/00:19:45, 0.539s/it]: train_loss_raw=0.8216, running_loss=0.7447, LR=0.000100
[2025-08-10 20:19:44,589][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060576] [Batch 01504/03692] [00:13:30/00:19:39, 0.539s/it]: train_loss_raw=0.7988, running_loss=0.7406, LR=0.000100
[2025-08-10 20:19:50,951][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060588] [Batch 01516/03692] [00:13:36/00:19:32, 0.539s/it]: train_loss_raw=0.7047, running_loss=0.7442, LR=0.000100
[2025-08-10 20:19:57,375][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060600] [Batch 01528/03692] [00:13:43/00:19:26, 0.539s/it]: train_loss_raw=0.7310, running_loss=0.7462, LR=0.000100
[2025-08-10 20:20:03,759][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060612] [Batch 01540/03692] [00:13:49/00:19:19, 0.539s/it]: train_loss_raw=0.7020, running_loss=0.7471, LR=0.000100
[2025-08-10 20:20:10,145][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060624] [Batch 01552/03692] [00:13:56/00:19:12, 0.539s/it]: train_loss_raw=0.7153, running_loss=0.7487, LR=0.000100
[2025-08-10 20:20:16,572][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060636] [Batch 01564/03692] [00:14:02/00:19:06, 0.539s/it]: train_loss_raw=0.7787, running_loss=0.7511, LR=0.000100
[2025-08-10 20:20:23,060][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060648] [Batch 01576/03692] [00:14:09/00:19:00, 0.539s/it]: train_loss_raw=0.7152, running_loss=0.7509, LR=0.000100
[2025-08-10 20:20:29,677][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060660] [Batch 01588/03692] [00:14:15/00:18:53, 0.539s/it]: train_loss_raw=0.8695, running_loss=0.7518, LR=0.000100
[2025-08-10 20:20:36,148][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060672] [Batch 01600/03692] [00:14:22/00:18:47, 0.539s/it]: train_loss_raw=0.6604, running_loss=0.7547, LR=0.000100
[2025-08-10 20:20:42,560][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060684] [Batch 01612/03692] [00:14:28/00:18:40, 0.539s/it]: train_loss_raw=0.8299, running_loss=0.7549, LR=0.000100
[2025-08-10 20:20:49,073][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060696] [Batch 01624/03692] [00:14:35/00:18:34, 0.539s/it]: train_loss_raw=0.7072, running_loss=0.7508, LR=0.000100
[2025-08-10 20:20:55,734][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060708] [Batch 01636/03692] [00:14:41/00:18:28, 0.539s/it]: train_loss_raw=0.7898, running_loss=0.7506, LR=0.000100
[2025-08-10 20:21:02,164][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060720] [Batch 01648/03692] [00:14:48/00:18:21, 0.539s/it]: train_loss_raw=0.7288, running_loss=0.7516, LR=0.000100
[2025-08-10 20:21:08,157][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060732] [Batch 01660/03692] [00:14:54/00:18:14, 0.539s/it]: train_loss_raw=0.6264, running_loss=0.7497, LR=0.000100
[2025-08-10 20:21:14,197][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060744] [Batch 01672/03692] [00:15:00/00:18:07, 0.538s/it]: train_loss_raw=0.7781, running_loss=0.7530, LR=0.000100
[2025-08-10 20:21:20,453][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060756] [Batch 01684/03692] [00:15:06/00:18:00, 0.538s/it]: train_loss_raw=0.6782, running_loss=0.7546, LR=0.000100
[2025-08-10 20:21:26,968][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060768] [Batch 01696/03692] [00:15:13/00:17:54, 0.538s/it]: train_loss_raw=0.6655, running_loss=0.7534, LR=0.000100
[2025-08-10 20:21:33,469][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060780] [Batch 01708/03692] [00:15:19/00:17:48, 0.538s/it]: train_loss_raw=0.7246, running_loss=0.7489, LR=0.000100
[2025-08-10 20:21:40,022][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060792] [Batch 01720/03692] [00:15:26/00:17:41, 0.538s/it]: train_loss_raw=0.8146, running_loss=0.7512, LR=0.000100
[2025-08-10 20:21:46,510][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060804] [Batch 01732/03692] [00:15:32/00:17:35, 0.538s/it]: train_loss_raw=0.7049, running_loss=0.7505, LR=0.000100
[2025-08-10 20:21:53,110][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060816] [Batch 01744/03692] [00:15:39/00:17:29, 0.539s/it]: train_loss_raw=0.8081, running_loss=0.7484, LR=0.000100
[2025-08-10 20:21:59,601][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060828] [Batch 01756/03692] [00:15:45/00:17:22, 0.539s/it]: train_loss_raw=0.8325, running_loss=0.7461, LR=0.000100
[2025-08-10 20:22:06,071][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060840] [Batch 01768/03692] [00:15:52/00:17:16, 0.539s/it]: train_loss_raw=0.7152, running_loss=0.7454, LR=0.000100
[2025-08-10 20:22:12,583][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060852] [Batch 01780/03692] [00:15:58/00:17:09, 0.539s/it]: train_loss_raw=0.6748, running_loss=0.7416, LR=0.000100
[2025-08-10 20:22:19,097][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060864] [Batch 01792/03692] [00:16:05/00:17:03, 0.539s/it]: train_loss_raw=0.8868, running_loss=0.7404, LR=0.000100
[2025-08-10 20:22:25,601][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060876] [Batch 01804/03692] [00:16:11/00:16:56, 0.539s/it]: train_loss_raw=0.7181, running_loss=0.7418, LR=0.000100
[2025-08-10 20:22:32,093][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060888] [Batch 01816/03692] [00:16:18/00:16:50, 0.539s/it]: train_loss_raw=0.6841, running_loss=0.7416, LR=0.000100
[2025-08-10 20:22:38,614][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060900] [Batch 01828/03692] [00:16:24/00:16:44, 0.539s/it]: train_loss_raw=0.7623, running_loss=0.7397, LR=0.000100
[2025-08-10 20:22:45,117][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060912] [Batch 01840/03692] [00:16:31/00:16:37, 0.539s/it]: train_loss_raw=0.6595, running_loss=0.7394, LR=0.000100
[2025-08-10 20:22:51,596][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060924] [Batch 01852/03692] [00:16:37/00:16:31, 0.539s/it]: train_loss_raw=0.7181, running_loss=0.7413, LR=0.000100
[2025-08-10 20:22:58,107][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060936] [Batch 01864/03692] [00:16:44/00:16:24, 0.539s/it]: train_loss_raw=0.7525, running_loss=0.7429, LR=0.000100
[2025-08-10 20:23:04,151][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060948] [Batch 01876/03692] [00:16:50/00:16:17, 0.538s/it]: train_loss_raw=0.6661, running_loss=0.7392, LR=0.000100
[2025-08-10 20:23:10,132][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060960] [Batch 01888/03692] [00:16:56/00:16:10, 0.538s/it]: train_loss_raw=0.7317, running_loss=0.7356, LR=0.000100
[2025-08-10 20:23:16,346][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060972] [Batch 01900/03692] [00:17:02/00:16:04, 0.538s/it]: train_loss_raw=0.7566, running_loss=0.7382, LR=0.000100
[2025-08-10 20:23:22,522][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060984] [Batch 01912/03692] [00:17:08/00:15:57, 0.538s/it]: train_loss_raw=0.7322, running_loss=0.7361, LR=0.000100
[2025-08-10 20:23:28,807][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060996] [Batch 01924/03692] [00:17:14/00:15:50, 0.538s/it]: train_loss_raw=0.7193, running_loss=0.7395, LR=0.000100
[2025-08-10 20:23:35,263][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061008] [Batch 01936/03692] [00:17:21/00:15:44, 0.538s/it]: train_loss_raw=0.5853, running_loss=0.7371, LR=0.000100
[2025-08-10 20:23:41,722][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061020] [Batch 01948/03692] [00:17:27/00:15:38, 0.538s/it]: train_loss_raw=0.6333, running_loss=0.7390, LR=0.000100
[2025-08-10 20:23:48,032][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061032] [Batch 01960/03692] [00:17:34/00:15:31, 0.538s/it]: train_loss_raw=0.7080, running_loss=0.7387, LR=0.000100
[2025-08-10 20:23:54,330][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061044] [Batch 01972/03692] [00:17:40/00:15:24, 0.538s/it]: train_loss_raw=0.7494, running_loss=0.7386, LR=0.000100
[2025-08-10 20:24:00,804][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061056] [Batch 01984/03692] [00:17:46/00:15:18, 0.538s/it]: train_loss_raw=0.6645, running_loss=0.7431, LR=0.000100
[2025-08-10 20:24:07,375][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061068] [Batch 01996/03692] [00:17:53/00:15:12, 0.538s/it]: train_loss_raw=0.8881, running_loss=0.7433, LR=0.000100
[2025-08-10 20:24:13,889][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061080] [Batch 02008/03692] [00:17:59/00:15:05, 0.538s/it]: train_loss_raw=0.7460, running_loss=0.7435, LR=0.000100
[2025-08-10 20:24:20,307][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061092] [Batch 02020/03692] [00:18:06/00:14:59, 0.538s/it]: train_loss_raw=0.6882, running_loss=0.7397, LR=0.000100
[2025-08-10 20:24:26,444][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061104] [Batch 02032/03692] [00:18:12/00:14:52, 0.538s/it]: train_loss_raw=0.7834, running_loss=0.7376, LR=0.000100
[2025-08-10 20:24:32,622][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061116] [Batch 02044/03692] [00:18:18/00:14:45, 0.538s/it]: train_loss_raw=0.6659, running_loss=0.7344, LR=0.000100
[2025-08-10 20:24:38,786][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061128] [Batch 02056/03692] [00:18:24/00:14:39, 0.537s/it]: train_loss_raw=0.8072, running_loss=0.7337, LR=0.000100
[2025-08-10 20:24:44,826][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061140] [Batch 02068/03692] [00:18:30/00:14:32, 0.537s/it]: train_loss_raw=0.7647, running_loss=0.7361, LR=0.000100
[2025-08-10 20:24:50,967][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061152] [Batch 02080/03692] [00:18:37/00:14:25, 0.537s/it]: train_loss_raw=0.8011, running_loss=0.7387, LR=0.000100
[2025-08-10 20:24:57,406][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061164] [Batch 02092/03692] [00:18:43/00:14:19, 0.537s/it]: train_loss_raw=0.7340, running_loss=0.7371, LR=0.000100
[2025-08-10 20:25:03,913][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061176] [Batch 02104/03692] [00:18:49/00:14:12, 0.537s/it]: train_loss_raw=0.5615, running_loss=0.7369, LR=0.000100
[2025-08-10 20:25:10,122][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061188] [Batch 02116/03692] [00:18:56/00:14:06, 0.537s/it]: train_loss_raw=0.7480, running_loss=0.7353, LR=0.000100
[2025-08-10 20:25:16,340][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061200] [Batch 02128/03692] [00:19:02/00:13:59, 0.537s/it]: train_loss_raw=0.8028, running_loss=0.7344, LR=0.000100
[2025-08-10 20:25:22,498][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061212] [Batch 02140/03692] [00:19:08/00:13:52, 0.537s/it]: train_loss_raw=0.7378, running_loss=0.7338, LR=0.000100
[2025-08-10 20:25:28,670][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061224] [Batch 02152/03692] [00:19:14/00:13:46, 0.537s/it]: train_loss_raw=0.7088, running_loss=0.7353, LR=0.000100
[2025-08-10 20:25:34,616][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061236] [Batch 02164/03692] [00:19:20/00:13:39, 0.536s/it]: train_loss_raw=0.6213, running_loss=0.7349, LR=0.000100
[2025-08-10 20:25:40,766][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061248] [Batch 02176/03692] [00:19:26/00:13:32, 0.536s/it]: train_loss_raw=0.7387, running_loss=0.7372, LR=0.000100
[2025-08-10 20:25:46,909][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061260] [Batch 02188/03692] [00:19:32/00:13:26, 0.536s/it]: train_loss_raw=0.7776, running_loss=0.7337, LR=0.000100
[2025-08-10 20:25:52,984][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061272] [Batch 02200/03692] [00:19:39/00:13:19, 0.536s/it]: train_loss_raw=0.7554, running_loss=0.7300, LR=0.000100
[2025-08-10 20:25:59,106][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061284] [Batch 02212/03692] [00:19:45/00:13:12, 0.536s/it]: train_loss_raw=0.7534, running_loss=0.7302, LR=0.000100
[2025-08-10 20:26:05,605][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061296] [Batch 02224/03692] [00:19:51/00:13:06, 0.536s/it]: train_loss_raw=0.5960, running_loss=0.7314, LR=0.000100
[2025-08-10 20:26:12,028][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061308] [Batch 02236/03692] [00:19:58/00:13:00, 0.536s/it]: train_loss_raw=0.6096, running_loss=0.7270, LR=0.000100
[2025-08-10 20:26:18,398][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061320] [Batch 02248/03692] [00:20:04/00:12:53, 0.536s/it]: train_loss_raw=0.5941, running_loss=0.7283, LR=0.000100
[2025-08-10 20:26:24,824][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061332] [Batch 02260/03692] [00:20:10/00:12:47, 0.536s/it]: train_loss_raw=0.7745, running_loss=0.7318, LR=0.000100
[2025-08-10 20:26:31,257][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061344] [Batch 02272/03692] [00:20:17/00:12:40, 0.536s/it]: train_loss_raw=0.7247, running_loss=0.7311, LR=0.000100
[2025-08-10 20:26:37,444][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061356] [Batch 02284/03692] [00:20:23/00:12:34, 0.536s/it]: train_loss_raw=0.7661, running_loss=0.7311, LR=0.000100
[2025-08-10 20:26:43,457][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061368] [Batch 02296/03692] [00:20:29/00:12:27, 0.535s/it]: train_loss_raw=0.6825, running_loss=0.7282, LR=0.000100
[2025-08-10 20:26:49,544][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061380] [Batch 02308/03692] [00:20:35/00:12:20, 0.535s/it]: train_loss_raw=0.7753, running_loss=0.7270, LR=0.000100
[2025-08-10 20:26:55,965][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061392] [Batch 02320/03692] [00:20:42/00:12:14, 0.535s/it]: train_loss_raw=0.6703, running_loss=0.7266, LR=0.000100
[2025-08-10 20:27:02,541][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061404] [Batch 02332/03692] [00:20:48/00:12:08, 0.535s/it]: train_loss_raw=0.6810, running_loss=0.7272, LR=0.000100
[2025-08-10 20:27:09,079][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061416] [Batch 02344/03692] [00:20:55/00:12:01, 0.535s/it]: train_loss_raw=0.7754, running_loss=0.7308, LR=0.000100
[2025-08-10 20:27:15,147][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061428] [Batch 02356/03692] [00:21:01/00:11:55, 0.535s/it]: train_loss_raw=0.7590, running_loss=0.7314, LR=0.000100
[2025-08-10 20:27:21,611][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061440] [Batch 02368/03692] [00:21:07/00:11:48, 0.535s/it]: train_loss_raw=0.8064, running_loss=0.7306, LR=0.000100
[2025-08-10 20:27:28,131][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061452] [Batch 02380/03692] [00:21:14/00:11:42, 0.535s/it]: train_loss_raw=0.7787, running_loss=0.7305, LR=0.000100
[2025-08-10 20:27:34,606][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061464] [Batch 02392/03692] [00:21:20/00:11:36, 0.535s/it]: train_loss_raw=0.6590, running_loss=0.7298, LR=0.000100
[2025-08-10 20:27:41,156][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061476] [Batch 02404/03692] [00:21:27/00:11:29, 0.535s/it]: train_loss_raw=0.8682, running_loss=0.7311, LR=0.000100
[2025-08-10 20:27:47,471][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061488] [Batch 02416/03692] [00:21:33/00:11:23, 0.535s/it]: train_loss_raw=0.7036, running_loss=0.7310, LR=0.000100
[2025-08-10 20:27:53,566][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061500] [Batch 02428/03692] [00:21:39/00:11:16, 0.535s/it]: train_loss_raw=0.7797, running_loss=0.7288, LR=0.000100
[2025-08-10 20:27:59,663][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061512] [Batch 02440/03692] [00:21:45/00:11:09, 0.535s/it]: train_loss_raw=0.8709, running_loss=0.7304, LR=0.000100
[2025-08-10 20:28:05,761][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061524] [Batch 02452/03692] [00:21:51/00:11:03, 0.535s/it]: train_loss_raw=0.7364, running_loss=0.7285, LR=0.000100
[2025-08-10 20:28:11,720][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061536] [Batch 02464/03692] [00:21:57/00:10:56, 0.535s/it]: train_loss_raw=0.7384, running_loss=0.7281, LR=0.000100
[2025-08-10 20:28:17,732][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061548] [Batch 02476/03692] [00:22:03/00:10:50, 0.535s/it]: train_loss_raw=0.7363, running_loss=0.7288, LR=0.000100
[2025-08-10 20:28:24,172][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061560] [Batch 02488/03692] [00:22:10/00:10:43, 0.535s/it]: train_loss_raw=0.7075, running_loss=0.7256, LR=0.000100
[2025-08-10 20:28:30,708][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061572] [Batch 02500/03692] [00:22:16/00:10:37, 0.535s/it]: train_loss_raw=0.6269, running_loss=0.7259, LR=0.000100
[2025-08-10 20:28:36,738][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061584] [Batch 02512/03692] [00:22:22/00:10:30, 0.535s/it]: train_loss_raw=0.7877, running_loss=0.7264, LR=0.000100
[2025-08-10 20:28:42,752][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061596] [Batch 02524/03692] [00:22:28/00:10:24, 0.534s/it]: train_loss_raw=0.7971, running_loss=0.7269, LR=0.000100
[2025-08-10 20:28:48,783][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061608] [Batch 02536/03692] [00:22:34/00:10:17, 0.534s/it]: train_loss_raw=0.6570, running_loss=0.7241, LR=0.000100
[2025-08-10 20:28:54,975][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061620] [Batch 02548/03692] [00:22:41/00:10:11, 0.534s/it]: train_loss_raw=0.7815, running_loss=0.7244, LR=0.000100
[2025-08-10 20:29:01,555][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061632] [Batch 02560/03692] [00:22:47/00:10:04, 0.534s/it]: train_loss_raw=0.7030, running_loss=0.7254, LR=0.000100
[2025-08-10 20:29:07,723][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061644] [Batch 02572/03692] [00:22:53/00:09:58, 0.534s/it]: train_loss_raw=0.6303, running_loss=0.7248, LR=0.000100
[2025-08-10 20:29:13,704][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061656] [Batch 02584/03692] [00:22:59/00:09:51, 0.534s/it]: train_loss_raw=0.7636, running_loss=0.7256, LR=0.000100
[2025-08-10 20:29:19,774][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061668] [Batch 02596/03692] [00:23:05/00:09:45, 0.534s/it]: train_loss_raw=0.7532, running_loss=0.7270, LR=0.000100
[2025-08-10 20:29:25,865][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061680] [Batch 02608/03692] [00:23:11/00:09:38, 0.534s/it]: train_loss_raw=0.6887, running_loss=0.7283, LR=0.000100
[2025-08-10 20:29:32,101][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061692] [Batch 02620/03692] [00:23:18/00:09:32, 0.534s/it]: train_loss_raw=0.6594, running_loss=0.7268, LR=0.000100
[2025-08-10 20:29:38,475][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061704] [Batch 02632/03692] [00:23:24/00:09:25, 0.534s/it]: train_loss_raw=0.8934, running_loss=0.7319, LR=0.000100
[2025-08-10 20:29:44,939][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061716] [Batch 02644/03692] [00:23:30/00:09:19, 0.534s/it]: train_loss_raw=0.7890, running_loss=0.7300, LR=0.000100
[2025-08-10 20:29:51,482][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061728] [Batch 02656/03692] [00:23:37/00:09:12, 0.534s/it]: train_loss_raw=0.8327, running_loss=0.7319, LR=0.000100
[2025-08-10 20:29:57,930][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061740] [Batch 02668/03692] [00:23:43/00:09:06, 0.534s/it]: train_loss_raw=0.7057, running_loss=0.7323, LR=0.000100
[2025-08-10 20:30:04,179][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061752] [Batch 02680/03692] [00:23:50/00:09:00, 0.534s/it]: train_loss_raw=0.6829, running_loss=0.7334, LR=0.000100
[2025-08-10 20:30:10,301][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061764] [Batch 02692/03692] [00:23:56/00:08:53, 0.534s/it]: train_loss_raw=0.7106, running_loss=0.7297, LR=0.000100
[2025-08-10 20:30:16,453][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061776] [Batch 02704/03692] [00:24:02/00:08:47, 0.533s/it]: train_loss_raw=0.6667, running_loss=0.7325, LR=0.000100
[2025-08-10 20:30:22,945][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061788] [Batch 02716/03692] [00:24:08/00:08:40, 0.533s/it]: train_loss_raw=0.6869, running_loss=0.7316, LR=0.000100
[2025-08-10 20:30:29,141][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061800] [Batch 02728/03692] [00:24:15/00:08:34, 0.533s/it]: train_loss_raw=0.6624, running_loss=0.7312, LR=0.000100
[2025-08-10 20:30:35,204][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061812] [Batch 02740/03692] [00:24:21/00:08:27, 0.533s/it]: train_loss_raw=0.8042, running_loss=0.7303, LR=0.000100
[2025-08-10 20:30:41,287][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061824] [Batch 02752/03692] [00:24:27/00:08:21, 0.533s/it]: train_loss_raw=0.6566, running_loss=0.7269, LR=0.000100
[2025-08-10 20:30:47,501][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061836] [Batch 02764/03692] [00:24:33/00:08:14, 0.533s/it]: train_loss_raw=0.6866, running_loss=0.7260, LR=0.000100
[2025-08-10 20:30:54,093][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061848] [Batch 02776/03692] [00:24:40/00:08:08, 0.533s/it]: train_loss_raw=0.6682, running_loss=0.7248, LR=0.000100
[2025-08-10 20:31:00,152][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061860] [Batch 02788/03692] [00:24:46/00:08:01, 0.533s/it]: train_loss_raw=0.6885, running_loss=0.7251, LR=0.000100
[2025-08-10 20:31:06,262][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061872] [Batch 02800/03692] [00:24:52/00:07:55, 0.533s/it]: train_loss_raw=0.8674, running_loss=0.7233, LR=0.000100
[2025-08-10 20:31:12,300][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061884] [Batch 02812/03692] [00:24:58/00:07:48, 0.533s/it]: train_loss_raw=0.6702, running_loss=0.7214, LR=0.000100
[2025-08-10 20:31:18,401][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061896] [Batch 02824/03692] [00:25:04/00:07:42, 0.533s/it]: train_loss_raw=0.8294, running_loss=0.7233, LR=0.000100
[2025-08-10 20:31:24,514][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061908] [Batch 02836/03692] [00:25:10/00:07:35, 0.533s/it]: train_loss_raw=0.7107, running_loss=0.7222, LR=0.000100
[2025-08-10 20:31:30,861][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061920] [Batch 02848/03692] [00:25:16/00:07:29, 0.533s/it]: train_loss_raw=0.7048, running_loss=0.7214, LR=0.000100
[2025-08-10 20:31:36,934][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061932] [Batch 02860/03692] [00:25:22/00:07:23, 0.533s/it]: train_loss_raw=0.6509, running_loss=0.7223, LR=0.000100
[2025-08-10 20:31:43,158][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061944] [Batch 02872/03692] [00:25:29/00:07:16, 0.532s/it]: train_loss_raw=0.7847, running_loss=0.7216, LR=0.000100
[2025-08-10 20:31:49,391][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061956] [Batch 02884/03692] [00:25:35/00:07:10, 0.532s/it]: train_loss_raw=0.6317, running_loss=0.7185, LR=0.000100
[2025-08-10 20:31:55,478][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061968] [Batch 02896/03692] [00:25:41/00:07:03, 0.532s/it]: train_loss_raw=0.6144, running_loss=0.7188, LR=0.000100
[2025-08-10 20:32:01,532][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061980] [Batch 02908/03692] [00:25:47/00:06:57, 0.532s/it]: train_loss_raw=0.7219, running_loss=0.7238, LR=0.000100
[2025-08-10 20:32:07,872][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061992] [Batch 02920/03692] [00:25:53/00:06:50, 0.532s/it]: train_loss_raw=0.8300, running_loss=0.7228, LR=0.000100
[2025-08-10 20:32:18,805][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062004] [Batch 02932/03692] [00:26:04/00:06:45, 0.534s/it]: train_loss_raw=0.7262, running_loss=0.7267, LR=0.000100
[2025-08-10 20:32:25,609][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062016] [Batch 02944/03692] [00:26:11/00:06:39, 0.534s/it]: train_loss_raw=0.7423, running_loss=0.7282, LR=0.000100
[2025-08-10 20:32:31,855][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062028] [Batch 02956/03692] [00:26:17/00:06:32, 0.534s/it]: train_loss_raw=0.6740, running_loss=0.7240, LR=0.000100
[2025-08-10 20:32:37,930][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062040] [Batch 02968/03692] [00:26:23/00:06:26, 0.534s/it]: train_loss_raw=0.7269, running_loss=0.7271, LR=0.000100
[2025-08-10 20:32:44,382][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062052] [Batch 02980/03692] [00:26:30/00:06:19, 0.534s/it]: train_loss_raw=0.6217, running_loss=0.7233, LR=0.000100
[2025-08-10 20:32:50,805][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062064] [Batch 02992/03692] [00:26:36/00:06:13, 0.534s/it]: train_loss_raw=0.6684, running_loss=0.7235, LR=0.000100
[2025-08-10 20:32:56,957][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062076] [Batch 03004/03692] [00:26:42/00:06:07, 0.534s/it]: train_loss_raw=0.7394, running_loss=0.7178, LR=0.000100
[2025-08-10 20:33:03,345][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062088] [Batch 03016/03692] [00:26:49/00:06:00, 0.534s/it]: train_loss_raw=0.6811, running_loss=0.7202, LR=0.000100
[2025-08-10 20:33:09,490][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062100] [Batch 03028/03692] [00:26:55/00:05:54, 0.534s/it]: train_loss_raw=0.7654, running_loss=0.7192, LR=0.000100
[2025-08-10 20:33:15,810][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062112] [Batch 03040/03692] [00:27:01/00:05:47, 0.534s/it]: train_loss_raw=0.6543, running_loss=0.7166, LR=0.000100
[2025-08-10 20:33:22,413][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062124] [Batch 03052/03692] [00:27:08/00:05:41, 0.534s/it]: train_loss_raw=0.7303, running_loss=0.7151, LR=0.000100
[2025-08-10 20:33:28,994][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062136] [Batch 03064/03692] [00:27:15/00:05:35, 0.534s/it]: train_loss_raw=0.6097, running_loss=0.7163, LR=0.000100
[2025-08-10 20:33:35,801][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062148] [Batch 03076/03692] [00:27:21/00:05:28, 0.534s/it]: train_loss_raw=0.8019, running_loss=0.7179, LR=0.000100
[2025-08-10 20:33:42,403][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062160] [Batch 03088/03692] [00:27:28/00:05:22, 0.534s/it]: train_loss_raw=0.7125, running_loss=0.7220, LR=0.000100
[2025-08-10 20:33:49,093][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062172] [Batch 03100/03692] [00:27:35/00:05:16, 0.534s/it]: train_loss_raw=0.7252, running_loss=0.7251, LR=0.000100
[2025-08-10 20:33:55,766][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062184] [Batch 03112/03692] [00:27:41/00:05:09, 0.534s/it]: train_loss_raw=0.6687, running_loss=0.7255, LR=0.000100
[2025-08-10 20:34:02,508][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062196] [Batch 03124/03692] [00:27:48/00:05:03, 0.534s/it]: train_loss_raw=0.6303, running_loss=0.7215, LR=0.000100
[2025-08-10 20:34:08,597][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062208] [Batch 03136/03692] [00:27:54/00:04:56, 0.534s/it]: train_loss_raw=0.7512, running_loss=0.7185, LR=0.000100
[2025-08-10 20:34:14,985][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062220] [Batch 03148/03692] [00:28:01/00:04:50, 0.534s/it]: train_loss_raw=0.7259, running_loss=0.7215, LR=0.000100
[2025-08-10 20:34:21,037][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062232] [Batch 03160/03692] [00:28:07/00:04:44, 0.534s/it]: train_loss_raw=0.6886, running_loss=0.7226, LR=0.000100
[2025-08-10 20:34:27,329][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062244] [Batch 03172/03692] [00:28:13/00:04:37, 0.534s/it]: train_loss_raw=0.5545, running_loss=0.7224, LR=0.000100
[2025-08-10 20:34:33,517][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062256] [Batch 03184/03692] [00:28:19/00:04:31, 0.534s/it]: train_loss_raw=0.5828, running_loss=0.7204, LR=0.000100
[2025-08-10 20:34:39,874][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062268] [Batch 03196/03692] [00:28:25/00:04:24, 0.534s/it]: train_loss_raw=0.7000, running_loss=0.7228, LR=0.000100
[2025-08-10 20:34:46,731][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062280] [Batch 03208/03692] [00:28:32/00:04:18, 0.534s/it]: train_loss_raw=0.7393, running_loss=0.7210, LR=0.000100
[2025-08-10 20:34:53,562][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062292] [Batch 03220/03692] [00:28:39/00:04:12, 0.534s/it]: train_loss_raw=0.7111, running_loss=0.7238, LR=0.000100
[2025-08-10 20:34:59,916][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062304] [Batch 03232/03692] [00:28:45/00:04:05, 0.534s/it]: train_loss_raw=0.6740, running_loss=0.7245, LR=0.000100
[2025-08-10 20:35:06,054][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062316] [Batch 03244/03692] [00:28:52/00:03:59, 0.534s/it]: train_loss_raw=0.8036, running_loss=0.7268, LR=0.000100
[2025-08-10 20:35:12,376][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062328] [Batch 03256/03692] [00:28:58/00:03:52, 0.534s/it]: train_loss_raw=0.6943, running_loss=0.7295, LR=0.000100
[2025-08-10 20:35:18,722][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062340] [Batch 03268/03692] [00:29:04/00:03:46, 0.534s/it]: train_loss_raw=0.6886, running_loss=0.7272, LR=0.000100
[2025-08-10 20:35:25,087][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062352] [Batch 03280/03692] [00:29:11/00:03:39, 0.534s/it]: train_loss_raw=0.7268, running_loss=0.7238, LR=0.000100
[2025-08-10 20:35:31,570][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062364] [Batch 03292/03692] [00:29:17/00:03:33, 0.534s/it]: train_loss_raw=0.5835, running_loss=0.7242, LR=0.000100
[2025-08-10 20:35:37,973][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062376] [Batch 03304/03692] [00:29:24/00:03:27, 0.534s/it]: train_loss_raw=0.6597, running_loss=0.7203, LR=0.000100
[2025-08-10 20:35:44,481][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062388] [Batch 03316/03692] [00:29:30/00:03:20, 0.534s/it]: train_loss_raw=0.6878, running_loss=0.7210, LR=0.000100
[2025-08-10 20:35:51,038][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062400] [Batch 03328/03692] [00:29:37/00:03:14, 0.534s/it]: train_loss_raw=0.7113, running_loss=0.7207, LR=0.000100
[2025-08-10 20:35:57,514][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062412] [Batch 03340/03692] [00:29:43/00:03:07, 0.534s/it]: train_loss_raw=0.6840, running_loss=0.7196, LR=0.000100
[2025-08-10 20:36:04,041][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062424] [Batch 03352/03692] [00:29:50/00:03:01, 0.534s/it]: train_loss_raw=0.7458, running_loss=0.7197, LR=0.000100
[2025-08-10 20:36:10,389][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062436] [Batch 03364/03692] [00:29:56/00:02:55, 0.534s/it]: train_loss_raw=0.7615, running_loss=0.7209, LR=0.000100
[2025-08-10 20:36:16,560][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062448] [Batch 03376/03692] [00:30:02/00:02:48, 0.534s/it]: train_loss_raw=0.8057, running_loss=0.7205, LR=0.000100
[2025-08-10 20:36:22,949][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062460] [Batch 03388/03692] [00:30:08/00:02:42, 0.534s/it]: train_loss_raw=0.7581, running_loss=0.7146, LR=0.000100
[2025-08-10 20:36:29,466][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062472] [Batch 03400/03692] [00:30:15/00:02:35, 0.534s/it]: train_loss_raw=0.6959, running_loss=0.7070, LR=0.000100
[2025-08-10 20:36:36,076][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062484] [Batch 03412/03692] [00:30:22/00:02:29, 0.534s/it]: train_loss_raw=0.7269, running_loss=0.7050, LR=0.000100
[2025-08-10 20:36:42,589][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062496] [Batch 03424/03692] [00:30:28/00:02:23, 0.534s/it]: train_loss_raw=0.6850, running_loss=0.7060, LR=0.000100
[2025-08-10 20:36:48,976][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062508] [Batch 03436/03692] [00:30:35/00:02:16, 0.534s/it]: train_loss_raw=0.6274, running_loss=0.7069, LR=0.000100
[2025-08-10 20:36:55,502][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062520] [Batch 03448/03692] [00:30:41/00:02:10, 0.534s/it]: train_loss_raw=0.6446, running_loss=0.7061, LR=0.000100
[2025-08-10 20:37:02,055][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062532] [Batch 03460/03692] [00:30:48/00:02:03, 0.534s/it]: train_loss_raw=0.6951, running_loss=0.7040, LR=0.000100
[2025-08-10 20:37:08,649][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062544] [Batch 03472/03692] [00:30:54/00:01:57, 0.534s/it]: train_loss_raw=0.7029, running_loss=0.7039, LR=0.000100
[2025-08-10 20:37:14,933][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062556] [Batch 03484/03692] [00:31:00/00:01:51, 0.534s/it]: train_loss_raw=0.6048, running_loss=0.7029, LR=0.000100
[2025-08-10 20:37:21,387][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062568] [Batch 03496/03692] [00:31:07/00:01:44, 0.534s/it]: train_loss_raw=0.7402, running_loss=0.7009, LR=0.000100
[2025-08-10 20:37:27,572][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062580] [Batch 03508/03692] [00:31:13/00:01:38, 0.534s/it]: train_loss_raw=0.6938, running_loss=0.6989, LR=0.000100
[2025-08-10 20:37:33,582][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062592] [Batch 03520/03692] [00:31:19/00:01:31, 0.534s/it]: train_loss_raw=0.8114, running_loss=0.7031, LR=0.000100
[2025-08-10 20:37:39,688][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062604] [Batch 03532/03692] [00:31:25/00:01:25, 0.534s/it]: train_loss_raw=0.5872, running_loss=0.7065, LR=0.000100
[2025-08-10 20:37:45,707][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062616] [Batch 03544/03692] [00:31:31/00:01:19, 0.534s/it]: train_loss_raw=0.8716, running_loss=0.7034, LR=0.000100
[2025-08-10 20:37:51,716][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062628] [Batch 03556/03692] [00:31:37/00:01:12, 0.534s/it]: train_loss_raw=0.6718, running_loss=0.7024, LR=0.000100
[2025-08-10 20:37:57,937][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062640] [Batch 03568/03692] [00:31:43/00:01:06, 0.534s/it]: train_loss_raw=0.7034, running_loss=0.7029, LR=0.000100
[2025-08-10 20:38:04,423][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062652] [Batch 03580/03692] [00:31:50/00:00:59, 0.534s/it]: train_loss_raw=0.6671, running_loss=0.7060, LR=0.000100
[2025-08-10 20:38:10,919][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062664] [Batch 03592/03692] [00:31:56/00:00:53, 0.534s/it]: train_loss_raw=0.7422, running_loss=0.7086, LR=0.000100
[2025-08-10 20:38:17,473][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062676] [Batch 03604/03692] [00:32:03/00:00:46, 0.534s/it]: train_loss_raw=0.8079, running_loss=0.7114, LR=0.000100
[2025-08-10 20:38:23,970][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062688] [Batch 03616/03692] [00:32:10/00:00:40, 0.534s/it]: train_loss_raw=0.6686, running_loss=0.7122, LR=0.000100
[2025-08-10 20:38:30,579][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062700] [Batch 03628/03692] [00:32:16/00:00:34, 0.534s/it]: train_loss_raw=0.7263, running_loss=0.7149, LR=0.000100
[2025-08-10 20:38:37,160][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062712] [Batch 03640/03692] [00:32:23/00:00:27, 0.534s/it]: train_loss_raw=0.7217, running_loss=0.7117, LR=0.000100
[2025-08-10 20:38:43,541][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062724] [Batch 03652/03692] [00:32:29/00:00:21, 0.534s/it]: train_loss_raw=0.8305, running_loss=0.7147, LR=0.000100
[2025-08-10 20:38:50,089][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062736] [Batch 03664/03692] [00:32:36/00:00:14, 0.534s/it]: train_loss_raw=0.8079, running_loss=0.7157, LR=0.000100
[2025-08-10 20:38:56,618][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062748] [Batch 03676/03692] [00:32:42/00:00:08, 0.534s/it]: train_loss_raw=0.8603, running_loss=0.7177, LR=0.000100
[2025-08-10 20:39:03,017][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062760] [Batch 03688/03692] [00:32:49/00:00:02, 0.534s/it]: train_loss_raw=0.6500, running_loss=0.7151, LR=0.000100
[2025-08-10 20:39:09,974][__main__][INFO] - [VALIDATION] [Epoch 16/29] Starting validation.
[2025-08-10 20:39:42,471][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 062765] [Batch 00011/00025] [00:00:32/00:00:35, 2.708s/it]
[2025-08-10 20:39:57,112][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 062765] [Batch 00023/00025] [00:00:47/00:00:01, 1.964s/it]
[2025-08-10 20:39:58,066][__main__][INFO] - [VALIDATION] [Epoch 16/29] train_loss=0.71354, valid_loss=0.75909
[2025-08-10 20:39:58,067][__main__][INFO] - [VALIDATION] [Epoch 16/29] Metrics:
[2025-08-10 20:39:58,067][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_er      0.335
[2025-08-10 20:39:58,067][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_prec    0.423
[2025-08-10 20:39:58,067][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_recall  0.429
[2025-08-10 20:39:58,067][__main__][INFO] - [VALIDATION] [Epoch 16/29] - pep_recall 0.396
[2025-08-10 20:39:58,070][__main__][INFO] - [TRAIN] [Epoch 16/29] Epoch complete, total time 09:43:57, remaining time 07:26:33, 00:34:21 per epoch
[2025-08-10 20:40:01,924][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062772] [Batch 00008/03692] [00:00:03/00:28:09, 0.459s/it]: train_loss_raw=0.7794, running_loss=0.7038, LR=0.000100
[2025-08-10 20:40:07,984][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062784] [Batch 00020/03692] [00:00:09/00:29:46, 0.486s/it]: train_loss_raw=0.6112, running_loss=0.7045, LR=0.000100
[2025-08-10 20:40:14,209][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062796] [Batch 00032/03692] [00:00:15/00:30:24, 0.499s/it]: train_loss_raw=0.7231, running_loss=0.7028, LR=0.000100
[2025-08-10 20:40:20,255][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062808] [Batch 00044/03692] [00:00:21/00:30:23, 0.500s/it]: train_loss_raw=0.6757, running_loss=0.7060, LR=0.000100
[2025-08-10 20:40:26,293][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062820] [Batch 00056/03692] [00:00:28/00:30:20, 0.501s/it]: train_loss_raw=0.7034, running_loss=0.7087, LR=0.000100
[2025-08-10 20:40:32,510][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062832] [Batch 00068/03692] [00:00:34/00:30:25, 0.504s/it]: train_loss_raw=0.6653, running_loss=0.7049, LR=0.000100
[2025-08-10 20:40:38,789][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062844] [Batch 00080/03692] [00:00:40/00:30:30, 0.507s/it]: train_loss_raw=0.7175, running_loss=0.7053, LR=0.000100
[2025-08-10 20:40:44,805][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062856] [Batch 00092/03692] [00:00:46/00:30:21, 0.506s/it]: train_loss_raw=0.6825, running_loss=0.7043, LR=0.000100
[2025-08-10 20:40:50,780][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062868] [Batch 00104/03692] [00:00:52/00:30:12, 0.505s/it]: train_loss_raw=0.6833, running_loss=0.7010, LR=0.000100
[2025-08-10 20:40:56,824][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062880] [Batch 00116/03692] [00:00:58/00:30:05, 0.505s/it]: train_loss_raw=0.6943, running_loss=0.7016, LR=0.000100
[2025-08-10 20:41:02,969][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062892] [Batch 00128/03692] [00:01:04/00:30:01, 0.506s/it]: train_loss_raw=0.6540, running_loss=0.7016, LR=0.000100
[2025-08-10 20:41:09,292][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062904] [Batch 00140/03692] [00:01:11/00:30:02, 0.507s/it]: train_loss_raw=0.6649, running_loss=0.7016, LR=0.000100
[2025-08-10 20:41:15,486][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062916] [Batch 00152/03692] [00:01:17/00:29:58, 0.508s/it]: train_loss_raw=0.7170, running_loss=0.7047, LR=0.000100
[2025-08-10 20:41:21,764][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062928] [Batch 00164/03692] [00:01:23/00:29:56, 0.509s/it]: train_loss_raw=0.7404, running_loss=0.7058, LR=0.000100
[2025-08-10 20:41:28,069][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062940] [Batch 00176/03692] [00:01:29/00:29:54, 0.510s/it]: train_loss_raw=0.7080, running_loss=0.7040, LR=0.000100
[2025-08-10 20:41:34,111][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062952] [Batch 00188/03692] [00:01:35/00:29:46, 0.510s/it]: train_loss_raw=0.6430, running_loss=0.7041, LR=0.000100
[2025-08-10 20:41:40,201][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062964] [Batch 00200/03692] [00:01:41/00:29:39, 0.510s/it]: train_loss_raw=0.8296, running_loss=0.7038, LR=0.000100
[2025-08-10 20:41:46,456][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062976] [Batch 00212/03692] [00:01:48/00:29:36, 0.510s/it]: train_loss_raw=0.7859, running_loss=0.7026, LR=0.000100
[2025-08-10 20:41:52,647][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062988] [Batch 00224/03692] [00:01:54/00:29:31, 0.511s/it]: train_loss_raw=0.7186, running_loss=0.7045, LR=0.000100
[2025-08-10 20:41:59,098][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063000] [Batch 00236/03692] [00:02:00/00:29:29, 0.512s/it]: train_loss_raw=0.7349, running_loss=0.7005, LR=0.000100
[2025-08-10 20:42:05,590][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063012] [Batch 00248/03692] [00:02:07/00:29:28, 0.513s/it]: train_loss_raw=0.7984, running_loss=0.6948, LR=0.000100
[2025-08-10 20:42:11,882][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063024] [Batch 00260/03692] [00:02:13/00:29:23, 0.514s/it]: train_loss_raw=0.7255, running_loss=0.6959, LR=0.000100
[2025-08-10 20:42:17,970][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063036] [Batch 00272/03692] [00:02:19/00:29:16, 0.514s/it]: train_loss_raw=0.6749, running_loss=0.6938, LR=0.000100
[2025-08-10 20:42:24,461][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063048] [Batch 00284/03692] [00:02:26/00:29:14, 0.515s/it]: train_loss_raw=0.7281, running_loss=0.6983, LR=0.000100
[2025-08-10 20:42:31,006][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063060] [Batch 00296/03692] [00:02:32/00:29:12, 0.516s/it]: train_loss_raw=0.6277, running_loss=0.7007, LR=0.000100
[2025-08-10 20:42:37,424][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063072] [Batch 00308/03692] [00:02:39/00:29:08, 0.517s/it]: train_loss_raw=0.7086, running_loss=0.7015, LR=0.000100
[2025-08-10 20:42:43,532][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063084] [Batch 00320/03692] [00:02:45/00:29:01, 0.516s/it]: train_loss_raw=0.6354, running_loss=0.6989, LR=0.000100
[2025-08-10 20:42:49,646][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063096] [Batch 00332/03692] [00:02:51/00:28:54, 0.516s/it]: train_loss_raw=0.6508, running_loss=0.6984, LR=0.000100
[2025-08-10 20:42:55,784][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063108] [Batch 00344/03692] [00:02:57/00:28:47, 0.516s/it]: train_loss_raw=0.8039, running_loss=0.6994, LR=0.000100
[2025-08-10 20:43:02,256][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063120] [Batch 00356/03692] [00:03:04/00:28:44, 0.517s/it]: train_loss_raw=0.6159, running_loss=0.6938, LR=0.000100
[2025-08-10 20:43:08,772][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063132] [Batch 00368/03692] [00:03:10/00:28:40, 0.518s/it]: train_loss_raw=0.5902, running_loss=0.6904, LR=0.000100
[2025-08-10 20:43:15,328][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063144] [Batch 00380/03692] [00:03:17/00:28:37, 0.519s/it]: train_loss_raw=0.7819, running_loss=0.6929, LR=0.000100
[2025-08-10 20:43:21,805][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063156] [Batch 00392/03692] [00:03:23/00:28:33, 0.519s/it]: train_loss_raw=0.6099, running_loss=0.6946, LR=0.000100
[2025-08-10 20:43:28,294][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063168] [Batch 00404/03692] [00:03:30/00:28:29, 0.520s/it]: train_loss_raw=0.6378, running_loss=0.6929, LR=0.000100
[2025-08-10 20:43:34,797][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063180] [Batch 00416/03692] [00:03:36/00:28:25, 0.521s/it]: train_loss_raw=0.7038, running_loss=0.6958, LR=0.000100
[2025-08-10 20:43:41,186][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063192] [Batch 00428/03692] [00:03:42/00:28:20, 0.521s/it]: train_loss_raw=0.5694, running_loss=0.6960, LR=0.000100
[2025-08-10 20:43:47,558][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063204] [Batch 00440/03692] [00:03:49/00:28:14, 0.521s/it]: train_loss_raw=0.7146, running_loss=0.6968, LR=0.000100
[2025-08-10 20:43:54,074][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063216] [Batch 00452/03692] [00:03:55/00:28:10, 0.522s/it]: train_loss_raw=0.6991, running_loss=0.6997, LR=0.000100
[2025-08-10 20:44:00,362][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063228] [Batch 00464/03692] [00:04:02/00:28:04, 0.522s/it]: train_loss_raw=0.6852, running_loss=0.7023, LR=0.000100
[2025-08-10 20:44:06,344][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063240] [Batch 00476/03692] [00:04:08/00:27:56, 0.521s/it]: train_loss_raw=0.7622, running_loss=0.7035, LR=0.000100
[2025-08-10 20:44:12,460][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063252] [Batch 00488/03692] [00:04:14/00:27:48, 0.521s/it]: train_loss_raw=0.6430, running_loss=0.7005, LR=0.000100
[2025-08-10 20:44:18,514][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063264] [Batch 00500/03692] [00:04:20/00:27:41, 0.521s/it]: train_loss_raw=0.7781, running_loss=0.7030, LR=0.000100
[2025-08-10 20:44:24,533][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063276] [Batch 00512/03692] [00:04:26/00:27:33, 0.520s/it]: train_loss_raw=0.6723, running_loss=0.7020, LR=0.000100
[2025-08-10 20:44:30,540][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063288] [Batch 00524/03692] [00:04:32/00:27:26, 0.520s/it]: train_loss_raw=0.6076, running_loss=0.6993, LR=0.000100
[2025-08-10 20:44:36,528][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063300] [Batch 00536/03692] [00:04:38/00:27:18, 0.519s/it]: train_loss_raw=0.7874, running_loss=0.6971, LR=0.000100
[2025-08-10 20:44:42,540][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063312] [Batch 00548/03692] [00:04:44/00:27:11, 0.519s/it]: train_loss_raw=0.7401, running_loss=0.7028, LR=0.000100
[2025-08-10 20:44:48,619][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063324] [Batch 00560/03692] [00:04:50/00:27:03, 0.519s/it]: train_loss_raw=0.5961, running_loss=0.7025, LR=0.000100
[2025-08-10 20:44:54,702][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063336] [Batch 00572/03692] [00:04:56/00:26:56, 0.518s/it]: train_loss_raw=0.6575, running_loss=0.7047, LR=0.000100
[2025-08-10 20:45:01,056][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063348] [Batch 00584/03692] [00:05:02/00:26:51, 0.518s/it]: train_loss_raw=0.6420, running_loss=0.7046, LR=0.000100
[2025-08-10 20:45:07,177][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063360] [Batch 00596/03692] [00:05:08/00:26:44, 0.518s/it]: train_loss_raw=0.6282, running_loss=0.7040, LR=0.000100
[2025-08-10 20:45:13,409][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063372] [Batch 00608/03692] [00:05:15/00:26:38, 0.518s/it]: train_loss_raw=0.7387, running_loss=0.7030, LR=0.000100
[2025-08-10 20:45:19,470][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063384] [Batch 00620/03692] [00:05:21/00:26:31, 0.518s/it]: train_loss_raw=0.6921, running_loss=0.7054, LR=0.000100
[2025-08-10 20:45:25,525][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063396] [Batch 00632/03692] [00:05:27/00:26:24, 0.518s/it]: train_loss_raw=0.7964, running_loss=0.7064, LR=0.000100
[2025-08-10 20:45:31,602][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063408] [Batch 00644/03692] [00:05:33/00:26:17, 0.518s/it]: train_loss_raw=0.7405, running_loss=0.7077, LR=0.000100
[2025-08-10 20:45:38,015][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063420] [Batch 00656/03692] [00:05:39/00:26:12, 0.518s/it]: train_loss_raw=0.7193, running_loss=0.7045, LR=0.000100
[2025-08-10 20:45:44,543][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063432] [Batch 00668/03692] [00:05:46/00:26:07, 0.518s/it]: train_loss_raw=0.7785, running_loss=0.7052, LR=0.000100
[2025-08-10 20:45:51,057][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063444] [Batch 00680/03692] [00:05:52/00:26:02, 0.519s/it]: train_loss_raw=0.6205, running_loss=0.7013, LR=0.000100
[2025-08-10 20:45:57,536][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063456] [Batch 00692/03692] [00:05:59/00:25:57, 0.519s/it]: train_loss_raw=0.7298, running_loss=0.7019, LR=0.000100
[2025-08-10 20:46:03,986][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063468] [Batch 00704/03692] [00:06:05/00:25:52, 0.520s/it]: train_loss_raw=0.6449, running_loss=0.6971, LR=0.000100
[2025-08-10 20:46:10,536][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063480] [Batch 00716/03692] [00:06:12/00:25:47, 0.520s/it]: train_loss_raw=0.6279, running_loss=0.6962, LR=0.000100
[2025-08-10 20:46:16,515][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063492] [Batch 00728/03692] [00:06:18/00:25:40, 0.520s/it]: train_loss_raw=0.6997, running_loss=0.6931, LR=0.000100
[2025-08-10 20:46:22,751][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063504] [Batch 00740/03692] [00:06:24/00:25:33, 0.520s/it]: train_loss_raw=0.7470, running_loss=0.6944, LR=0.000100
[2025-08-10 20:46:28,885][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063516] [Batch 00752/03692] [00:06:30/00:25:27, 0.519s/it]: train_loss_raw=0.6819, running_loss=0.6961, LR=0.000100
[2025-08-10 20:46:34,940][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063528] [Batch 00764/03692] [00:06:36/00:25:20, 0.519s/it]: train_loss_raw=0.5998, running_loss=0.6934, LR=0.000100
[2025-08-10 20:46:41,102][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063540] [Batch 00776/03692] [00:06:42/00:25:13, 0.519s/it]: train_loss_raw=0.7296, running_loss=0.6992, LR=0.000100
[2025-08-10 20:46:47,459][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063552] [Batch 00788/03692] [00:06:49/00:25:08, 0.519s/it]: train_loss_raw=0.5947, running_loss=0.6990, LR=0.000100
[2025-08-10 20:46:53,965][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063564] [Batch 00800/03692] [00:06:55/00:25:02, 0.520s/it]: train_loss_raw=0.7272, running_loss=0.7011, LR=0.000100
[2025-08-10 20:47:00,451][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063576] [Batch 00812/03692] [00:07:02/00:24:57, 0.520s/it]: train_loss_raw=0.7213, running_loss=0.7018, LR=0.000100
[2025-08-10 20:47:07,040][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063588] [Batch 00824/03692] [00:07:08/00:24:52, 0.520s/it]: train_loss_raw=0.7066, running_loss=0.7018, LR=0.000100
[2025-08-10 20:47:13,583][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063600] [Batch 00836/03692] [00:07:15/00:24:47, 0.521s/it]: train_loss_raw=0.7984, running_loss=0.7053, LR=0.000100
[2025-08-10 20:47:20,101][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063612] [Batch 00848/03692] [00:07:21/00:24:41, 0.521s/it]: train_loss_raw=0.6532, running_loss=0.7013, LR=0.000100
[2025-08-10 20:47:26,280][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063624] [Batch 00860/03692] [00:07:28/00:24:35, 0.521s/it]: train_loss_raw=0.7761, running_loss=0.7015, LR=0.000100
[2025-08-10 20:47:32,746][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063636] [Batch 00872/03692] [00:07:34/00:24:29, 0.521s/it]: train_loss_raw=0.6922, running_loss=0.6991, LR=0.000100
[2025-08-10 20:47:39,252][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063648] [Batch 00884/03692] [00:07:40/00:24:24, 0.521s/it]: train_loss_raw=0.7116, running_loss=0.6984, LR=0.000100
[2025-08-10 20:47:45,819][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063660] [Batch 00896/03692] [00:07:47/00:24:19, 0.522s/it]: train_loss_raw=0.6702, running_loss=0.6972, LR=0.000100
[2025-08-10 20:47:52,392][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063672] [Batch 00908/03692] [00:07:54/00:24:13, 0.522s/it]: train_loss_raw=0.7263, running_loss=0.6981, LR=0.000100
[2025-08-10 20:47:58,919][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063684] [Batch 00920/03692] [00:08:00/00:24:08, 0.522s/it]: train_loss_raw=0.7997, running_loss=0.6983, LR=0.000100
[2025-08-10 20:48:05,025][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063696] [Batch 00932/03692] [00:08:06/00:24:01, 0.522s/it]: train_loss_raw=0.5275, running_loss=0.6953, LR=0.000100
[2025-08-10 20:48:11,073][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063708] [Batch 00944/03692] [00:08:12/00:23:54, 0.522s/it]: train_loss_raw=0.6921, running_loss=0.6976, LR=0.000100
[2025-08-10 20:48:17,142][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063720] [Batch 00956/03692] [00:08:18/00:23:47, 0.522s/it]: train_loss_raw=0.6004, running_loss=0.6932, LR=0.000100
[2025-08-10 20:48:23,200][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063732] [Batch 00968/03692] [00:08:24/00:23:40, 0.522s/it]: train_loss_raw=0.6826, running_loss=0.6906, LR=0.000100
[2025-08-10 20:48:29,245][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063744] [Batch 00980/03692] [00:08:30/00:23:34, 0.521s/it]: train_loss_raw=0.6877, running_loss=0.6899, LR=0.000100
[2025-08-10 20:48:35,284][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063756] [Batch 00992/03692] [00:08:37/00:23:27, 0.521s/it]: train_loss_raw=0.6487, running_loss=0.6911, LR=0.000100
[2025-08-10 20:48:41,356][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063768] [Batch 01004/03692] [00:08:43/00:23:20, 0.521s/it]: train_loss_raw=0.6516, running_loss=0.6894, LR=0.000100
[2025-08-10 20:48:47,381][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063780] [Batch 01016/03692] [00:08:49/00:23:13, 0.521s/it]: train_loss_raw=0.6177, running_loss=0.6886, LR=0.000100
[2025-08-10 20:48:53,450][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063792] [Batch 01028/03692] [00:08:55/00:23:06, 0.521s/it]: train_loss_raw=0.6825, running_loss=0.6883, LR=0.000100
[2025-08-10 20:48:59,493][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063804] [Batch 01040/03692] [00:09:01/00:23:00, 0.520s/it]: train_loss_raw=0.8150, running_loss=0.6884, LR=0.000100
[2025-08-10 20:49:05,817][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063816] [Batch 01052/03692] [00:09:07/00:22:54, 0.520s/it]: train_loss_raw=0.6833, running_loss=0.6877, LR=0.000100
[2025-08-10 20:49:11,976][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063828] [Batch 01064/03692] [00:09:13/00:22:47, 0.520s/it]: train_loss_raw=0.6557, running_loss=0.6886, LR=0.000100
[2025-08-10 20:49:18,532][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063840] [Batch 01076/03692] [00:09:20/00:22:42, 0.521s/it]: train_loss_raw=0.8119, running_loss=0.6911, LR=0.000100
[2025-08-10 20:49:25,098][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063852] [Batch 01088/03692] [00:09:26/00:22:36, 0.521s/it]: train_loss_raw=0.7166, running_loss=0.6923, LR=0.000100
[2025-08-10 20:49:31,655][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063864] [Batch 01100/03692] [00:09:33/00:22:31, 0.521s/it]: train_loss_raw=0.6351, running_loss=0.6936, LR=0.000100
[2025-08-10 20:49:37,973][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063876] [Batch 01112/03692] [00:09:39/00:22:25, 0.521s/it]: train_loss_raw=0.5797, running_loss=0.6933, LR=0.000100
[2025-08-10 20:49:43,985][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063888] [Batch 01124/03692] [00:09:45/00:22:18, 0.521s/it]: train_loss_raw=0.6563, running_loss=0.6896, LR=0.000100
[2025-08-10 20:49:50,006][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063900] [Batch 01136/03692] [00:09:51/00:22:11, 0.521s/it]: train_loss_raw=0.6062, running_loss=0.6912, LR=0.000100
[2025-08-10 20:49:56,089][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063912] [Batch 01148/03692] [00:09:57/00:22:04, 0.521s/it]: train_loss_raw=0.7105, running_loss=0.6860, LR=0.000100
[2025-08-10 20:50:02,234][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063924] [Batch 01160/03692] [00:10:03/00:21:58, 0.521s/it]: train_loss_raw=0.6819, running_loss=0.6859, LR=0.000100
[2025-08-10 20:50:08,281][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063936] [Batch 01172/03692] [00:10:10/00:21:51, 0.520s/it]: train_loss_raw=0.5849, running_loss=0.6827, LR=0.000100
[2025-08-10 20:50:14,352][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063948] [Batch 01184/03692] [00:10:16/00:21:45, 0.520s/it]: train_loss_raw=0.8132, running_loss=0.6880, LR=0.000100
[2025-08-10 20:50:20,432][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063960] [Batch 01196/03692] [00:10:22/00:21:38, 0.520s/it]: train_loss_raw=0.7037, running_loss=0.6909, LR=0.000100
[2025-08-10 20:50:26,449][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063972] [Batch 01208/03692] [00:10:28/00:21:31, 0.520s/it]: train_loss_raw=0.7449, running_loss=0.6922, LR=0.000100
[2025-08-10 20:50:32,434][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063984] [Batch 01220/03692] [00:10:34/00:21:24, 0.520s/it]: train_loss_raw=0.6258, running_loss=0.6929, LR=0.000100
[2025-08-10 20:50:38,503][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063996] [Batch 01232/03692] [00:10:40/00:21:18, 0.520s/it]: train_loss_raw=0.6570, running_loss=0.6917, LR=0.000100
[2025-08-10 20:50:49,101][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064008] [Batch 01244/03692] [00:10:50/00:21:20, 0.523s/it]: train_loss_raw=0.7969, running_loss=0.6907, LR=0.000100
[2025-08-10 20:50:55,676][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064020] [Batch 01256/03692] [00:10:57/00:21:15, 0.523s/it]: train_loss_raw=0.6665, running_loss=0.6890, LR=0.000100
[2025-08-10 20:51:02,235][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064032] [Batch 01268/03692] [00:11:03/00:21:09, 0.524s/it]: train_loss_raw=0.6112, running_loss=0.6880, LR=0.000100
[2025-08-10 20:51:08,805][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064044] [Batch 01280/03692] [00:11:10/00:21:03, 0.524s/it]: train_loss_raw=0.6874, running_loss=0.6869, LR=0.000100
[2025-08-10 20:51:15,342][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064056] [Batch 01292/03692] [00:11:17/00:20:57, 0.524s/it]: train_loss_raw=0.7029, running_loss=0.6862, LR=0.000100
[2025-08-10 20:51:21,834][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064068] [Batch 01304/03692] [00:11:23/00:20:51, 0.524s/it]: train_loss_raw=0.6065, running_loss=0.6839, LR=0.000100
[2025-08-10 20:51:28,405][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064080] [Batch 01316/03692] [00:11:30/00:20:46, 0.524s/it]: train_loss_raw=0.7892, running_loss=0.6878, LR=0.000100
[2025-08-10 20:51:35,031][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064092] [Batch 01328/03692] [00:11:36/00:20:40, 0.525s/it]: train_loss_raw=0.7122, running_loss=0.6853, LR=0.000100
[2025-08-10 20:51:41,144][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064104] [Batch 01340/03692] [00:11:42/00:20:33, 0.525s/it]: train_loss_raw=0.7223, running_loss=0.6856, LR=0.000100
[2025-08-10 20:51:47,259][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064116] [Batch 01352/03692] [00:11:49/00:20:27, 0.524s/it]: train_loss_raw=0.7140, running_loss=0.6855, LR=0.000100
[2025-08-10 20:51:53,251][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064128] [Batch 01364/03692] [00:11:54/00:20:20, 0.524s/it]: train_loss_raw=0.7348, running_loss=0.6867, LR=0.000100
[2025-08-10 20:51:59,314][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064140] [Batch 01376/03692] [00:12:01/00:20:13, 0.524s/it]: train_loss_raw=0.7028, running_loss=0.6879, LR=0.000100
[2025-08-10 20:52:05,398][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064152] [Batch 01388/03692] [00:12:07/00:20:07, 0.524s/it]: train_loss_raw=0.6637, running_loss=0.6908, LR=0.000100
[2025-08-10 20:52:11,664][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064164] [Batch 01400/03692] [00:12:13/00:20:00, 0.524s/it]: train_loss_raw=0.6807, running_loss=0.6943, LR=0.000100
[2025-08-10 20:52:18,150][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064176] [Batch 01412/03692] [00:12:19/00:19:54, 0.524s/it]: train_loss_raw=0.6018, running_loss=0.6895, LR=0.000100
[2025-08-10 20:52:24,711][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064188] [Batch 01424/03692] [00:12:26/00:19:48, 0.524s/it]: train_loss_raw=0.6225, running_loss=0.6870, LR=0.000100
[2025-08-10 20:52:31,187][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064200] [Batch 01436/03692] [00:12:32/00:19:42, 0.524s/it]: train_loss_raw=0.6851, running_loss=0.6869, LR=0.000100
[2025-08-10 20:52:37,499][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064212] [Batch 01448/03692] [00:12:39/00:19:36, 0.524s/it]: train_loss_raw=0.5617, running_loss=0.6847, LR=0.000100
[2025-08-10 20:52:43,577][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064224] [Batch 01460/03692] [00:12:45/00:19:29, 0.524s/it]: train_loss_raw=0.6692, running_loss=0.6815, LR=0.000100
[2025-08-10 20:52:49,928][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064236] [Batch 01472/03692] [00:12:51/00:19:23, 0.524s/it]: train_loss_raw=0.5943, running_loss=0.6861, LR=0.000100
[2025-08-10 20:52:55,970][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064248] [Batch 01484/03692] [00:12:57/00:19:17, 0.524s/it]: train_loss_raw=0.6529, running_loss=0.6897, LR=0.000100
[2025-08-10 20:53:01,992][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064260] [Batch 01496/03692] [00:13:03/00:19:10, 0.524s/it]: train_loss_raw=0.6751, running_loss=0.6894, LR=0.000100
[2025-08-10 20:53:07,983][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064272] [Batch 01508/03692] [00:13:09/00:19:03, 0.524s/it]: train_loss_raw=0.7682, running_loss=0.6875, LR=0.000100
[2025-08-10 20:53:13,983][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064284] [Batch 01520/03692] [00:13:15/00:18:57, 0.524s/it]: train_loss_raw=0.4981, running_loss=0.6887, LR=0.000100
[2025-08-10 20:53:20,003][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064296] [Batch 01532/03692] [00:13:21/00:18:50, 0.523s/it]: train_loss_raw=0.6089, running_loss=0.6892, LR=0.000100
[2025-08-10 20:53:26,234][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064308] [Batch 01544/03692] [00:13:27/00:18:44, 0.523s/it]: train_loss_raw=0.6973, running_loss=0.6877, LR=0.000100
[2025-08-10 20:53:32,906][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064320] [Batch 01556/03692] [00:13:34/00:18:38, 0.524s/it]: train_loss_raw=0.5317, running_loss=0.6859, LR=0.000100
[2025-08-10 20:53:39,508][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064332] [Batch 01568/03692] [00:13:41/00:18:32, 0.524s/it]: train_loss_raw=0.7548, running_loss=0.6911, LR=0.000100
[2025-08-10 20:53:46,064][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064344] [Batch 01580/03692] [00:13:47/00:18:26, 0.524s/it]: train_loss_raw=0.6148, running_loss=0.6916, LR=0.000100
[2025-08-10 20:53:52,617][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064356] [Batch 01592/03692] [00:13:54/00:18:20, 0.524s/it]: train_loss_raw=0.6102, running_loss=0.6897, LR=0.000100
[2025-08-10 20:53:59,038][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064368] [Batch 01604/03692] [00:14:00/00:18:14, 0.524s/it]: train_loss_raw=0.7358, running_loss=0.6909, LR=0.000100
[2025-08-10 20:54:05,412][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064380] [Batch 01616/03692] [00:14:07/00:18:08, 0.524s/it]: train_loss_raw=0.6864, running_loss=0.6952, LR=0.000100
[2025-08-10 20:54:11,391][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064392] [Batch 01628/03692] [00:14:13/00:18:01, 0.524s/it]: train_loss_raw=0.6235, running_loss=0.6928, LR=0.000100
[2025-08-10 20:54:17,444][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064404] [Batch 01640/03692] [00:14:19/00:17:55, 0.524s/it]: train_loss_raw=0.5501, running_loss=0.6929, LR=0.000100
[2025-08-10 20:54:23,508][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064416] [Batch 01652/03692] [00:14:25/00:17:48, 0.524s/it]: train_loss_raw=0.6930, running_loss=0.6926, LR=0.000100
[2025-08-10 20:54:29,745][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064428] [Batch 01664/03692] [00:14:31/00:17:42, 0.524s/it]: train_loss_raw=0.8293, running_loss=0.6902, LR=0.000100
[2025-08-10 20:54:35,899][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064440] [Batch 01676/03692] [00:14:37/00:17:35, 0.524s/it]: train_loss_raw=0.5741, running_loss=0.6854, LR=0.000100
[2025-08-10 20:54:41,959][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064452] [Batch 01688/03692] [00:14:43/00:17:29, 0.524s/it]: train_loss_raw=0.6290, running_loss=0.6857, LR=0.000100
[2025-08-10 20:54:48,069][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064464] [Batch 01700/03692] [00:14:49/00:17:22, 0.523s/it]: train_loss_raw=0.6947, running_loss=0.6847, LR=0.000100
[2025-08-10 20:54:54,332][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064476] [Batch 01712/03692] [00:14:56/00:17:16, 0.523s/it]: train_loss_raw=0.6978, running_loss=0.6795, LR=0.000100
[2025-08-10 20:55:00,916][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064488] [Batch 01724/03692] [00:15:02/00:17:10, 0.524s/it]: train_loss_raw=0.6055, running_loss=0.6810, LR=0.000100
[2025-08-10 20:55:07,415][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064500] [Batch 01736/03692] [00:15:09/00:17:04, 0.524s/it]: train_loss_raw=0.8080, running_loss=0.6799, LR=0.000100
[2025-08-10 20:55:13,981][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064512] [Batch 01748/03692] [00:15:15/00:16:58, 0.524s/it]: train_loss_raw=0.6311, running_loss=0.6799, LR=0.000100
[2025-08-10 20:55:20,378][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064524] [Batch 01760/03692] [00:15:22/00:16:52, 0.524s/it]: train_loss_raw=0.6002, running_loss=0.6785, LR=0.000100
[2025-08-10 20:55:26,606][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064536] [Batch 01772/03692] [00:15:28/00:16:45, 0.524s/it]: train_loss_raw=0.7433, running_loss=0.6804, LR=0.000100
[2025-08-10 20:55:32,990][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064548] [Batch 01784/03692] [00:15:34/00:16:39, 0.524s/it]: train_loss_raw=0.6929, running_loss=0.6809, LR=0.000100
[2025-08-10 20:55:39,308][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064560] [Batch 01796/03692] [00:15:41/00:16:33, 0.524s/it]: train_loss_raw=0.6131, running_loss=0.6797, LR=0.000100
[2025-08-10 20:55:45,678][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064572] [Batch 01808/03692] [00:15:47/00:16:27, 0.524s/it]: train_loss_raw=0.6654, running_loss=0.6800, LR=0.000100
[2025-08-10 20:55:52,024][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064584] [Batch 01820/03692] [00:15:53/00:16:21, 0.524s/it]: train_loss_raw=0.7550, running_loss=0.6825, LR=0.000100
[2025-08-10 20:55:58,430][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064596] [Batch 01832/03692] [00:16:00/00:16:14, 0.524s/it]: train_loss_raw=0.6597, running_loss=0.6818, LR=0.000100
[2025-08-10 20:56:04,958][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064608] [Batch 01844/03692] [00:16:06/00:16:08, 0.524s/it]: train_loss_raw=0.7346, running_loss=0.6826, LR=0.000100
[2025-08-10 20:56:11,433][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064620] [Batch 01856/03692] [00:16:13/00:16:02, 0.524s/it]: train_loss_raw=0.6986, running_loss=0.6849, LR=0.000100
[2025-08-10 20:56:17,973][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064632] [Batch 01868/03692] [00:16:19/00:15:56, 0.524s/it]: train_loss_raw=0.6772, running_loss=0.6853, LR=0.000100
[2025-08-10 20:56:24,318][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064644] [Batch 01880/03692] [00:16:26/00:15:50, 0.525s/it]: train_loss_raw=0.7274, running_loss=0.6848, LR=0.000100
[2025-08-10 20:56:30,521][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064656] [Batch 01892/03692] [00:16:32/00:15:44, 0.524s/it]: train_loss_raw=0.8153, running_loss=0.6863, LR=0.000100
[2025-08-10 20:56:36,669][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064668] [Batch 01904/03692] [00:16:38/00:15:37, 0.524s/it]: train_loss_raw=0.6555, running_loss=0.6847, LR=0.000100
[2025-08-10 20:56:43,018][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064680] [Batch 01916/03692] [00:16:44/00:15:31, 0.524s/it]: train_loss_raw=0.6022, running_loss=0.6833, LR=0.000100
[2025-08-10 20:56:49,392][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064692] [Batch 01928/03692] [00:16:51/00:15:25, 0.524s/it]: train_loss_raw=0.6333, running_loss=0.6829, LR=0.000100
[2025-08-10 20:56:55,769][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064704] [Batch 01940/03692] [00:16:57/00:15:18, 0.524s/it]: train_loss_raw=0.6205, running_loss=0.6811, LR=0.000100
[2025-08-10 20:57:01,778][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064716] [Batch 01952/03692] [00:17:03/00:15:12, 0.524s/it]: train_loss_raw=0.6642, running_loss=0.6792, LR=0.000100
[2025-08-10 20:57:07,974][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064728] [Batch 01964/03692] [00:17:09/00:15:05, 0.524s/it]: train_loss_raw=0.7082, running_loss=0.6806, LR=0.000100
[2025-08-10 20:57:14,471][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064740] [Batch 01976/03692] [00:17:16/00:14:59, 0.524s/it]: train_loss_raw=0.7038, running_loss=0.6860, LR=0.000100
[2025-08-10 20:57:21,021][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064752] [Batch 01988/03692] [00:17:22/00:14:53, 0.525s/it]: train_loss_raw=0.7330, running_loss=0.6854, LR=0.000100
[2025-08-10 20:57:27,593][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064764] [Batch 02000/03692] [00:17:29/00:14:47, 0.525s/it]: train_loss_raw=0.8028, running_loss=0.6838, LR=0.000100
[2025-08-10 20:57:34,142][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064776] [Batch 02012/03692] [00:17:35/00:14:41, 0.525s/it]: train_loss_raw=0.7388, running_loss=0.6804, LR=0.000100
[2025-08-10 20:57:40,430][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064788] [Batch 02024/03692] [00:17:42/00:14:35, 0.525s/it]: train_loss_raw=0.7498, running_loss=0.6838, LR=0.000100
[2025-08-10 20:57:46,456][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064800] [Batch 02036/03692] [00:17:48/00:14:28, 0.525s/it]: train_loss_raw=0.6463, running_loss=0.6842, LR=0.000100
[2025-08-10 20:57:52,692][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064812] [Batch 02048/03692] [00:17:54/00:14:22, 0.525s/it]: train_loss_raw=0.6416, running_loss=0.6824, LR=0.000100
[2025-08-10 20:57:59,107][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064824] [Batch 02060/03692] [00:18:00/00:14:16, 0.525s/it]: train_loss_raw=0.6643, running_loss=0.6770, LR=0.000100
[2025-08-10 20:58:05,599][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064836] [Batch 02072/03692] [00:18:07/00:14:10, 0.525s/it]: train_loss_raw=0.6248, running_loss=0.6773, LR=0.000100
[2025-08-10 20:58:12,163][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064848] [Batch 02084/03692] [00:18:13/00:14:04, 0.525s/it]: train_loss_raw=0.5995, running_loss=0.6750, LR=0.000100
[2025-08-10 20:58:18,734][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064860] [Batch 02096/03692] [00:18:20/00:13:57, 0.525s/it]: train_loss_raw=0.6942, running_loss=0.6769, LR=0.000100
[2025-08-10 20:58:25,226][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064872] [Batch 02108/03692] [00:18:26/00:13:51, 0.525s/it]: train_loss_raw=0.7152, running_loss=0.6789, LR=0.000100
[2025-08-10 20:58:31,538][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064884] [Batch 02120/03692] [00:18:33/00:13:45, 0.525s/it]: train_loss_raw=0.7216, running_loss=0.6784, LR=0.000100
[2025-08-10 20:58:37,949][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064896] [Batch 02132/03692] [00:18:39/00:13:39, 0.525s/it]: train_loss_raw=0.6078, running_loss=0.6786, LR=0.000100
[2025-08-10 20:58:44,027][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064908] [Batch 02144/03692] [00:18:45/00:13:32, 0.525s/it]: train_loss_raw=0.6635, running_loss=0.6793, LR=0.000100
[2025-08-10 20:58:50,196][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064920] [Batch 02156/03692] [00:18:51/00:13:26, 0.525s/it]: train_loss_raw=0.7483, running_loss=0.6753, LR=0.000100
[2025-08-10 20:59:10,326][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064932] [Batch 02168/03692] [00:19:12/00:13:29, 0.531s/it]: train_loss_raw=0.6866, running_loss=0.6742, LR=0.000100
[2025-08-10 20:59:16,851][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064944] [Batch 02180/03692] [00:19:18/00:13:23, 0.531s/it]: train_loss_raw=0.6775, running_loss=0.6743, LR=0.000100
[2025-08-10 20:59:23,382][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064956] [Batch 02192/03692] [00:19:25/00:13:17, 0.532s/it]: train_loss_raw=0.6225, running_loss=0.6754, LR=0.000100
[2025-08-10 20:59:29,827][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064968] [Batch 02204/03692] [00:19:31/00:13:10, 0.532s/it]: train_loss_raw=0.6550, running_loss=0.6716, LR=0.000100
[2025-08-10 20:59:35,876][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064980] [Batch 02216/03692] [00:19:37/00:13:04, 0.531s/it]: train_loss_raw=0.6016, running_loss=0.6682, LR=0.000100
[2025-08-10 20:59:42,021][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064992] [Batch 02228/03692] [00:19:43/00:12:57, 0.531s/it]: train_loss_raw=0.6109, running_loss=0.6701, LR=0.000100
[2025-08-10 20:59:48,501][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065004] [Batch 02240/03692] [00:19:50/00:12:51, 0.531s/it]: train_loss_raw=0.6693, running_loss=0.6715, LR=0.000100
[2025-08-10 20:59:54,856][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065016] [Batch 02252/03692] [00:19:56/00:12:45, 0.531s/it]: train_loss_raw=0.7073, running_loss=0.6744, LR=0.000100
[2025-08-10 21:00:00,893][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065028] [Batch 02264/03692] [00:20:02/00:12:38, 0.531s/it]: train_loss_raw=0.7354, running_loss=0.6776, LR=0.000100
[2025-08-10 21:00:07,136][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065040] [Batch 02276/03692] [00:20:08/00:12:32, 0.531s/it]: train_loss_raw=0.7445, running_loss=0.6770, LR=0.000100
[2025-08-10 21:00:13,515][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065052] [Batch 02288/03692] [00:20:15/00:12:25, 0.531s/it]: train_loss_raw=0.6486, running_loss=0.6757, LR=0.000100
[2025-08-10 21:00:19,779][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065064] [Batch 02300/03692] [00:20:21/00:12:19, 0.531s/it]: train_loss_raw=0.6453, running_loss=0.6740, LR=0.000100
[2025-08-10 21:00:26,137][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065076] [Batch 02312/03692] [00:20:27/00:12:12, 0.531s/it]: train_loss_raw=0.7410, running_loss=0.6738, LR=0.000100
[2025-08-10 21:00:32,380][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065088] [Batch 02324/03692] [00:20:34/00:12:06, 0.531s/it]: train_loss_raw=0.6762, running_loss=0.6747, LR=0.000100
[2025-08-10 21:00:38,603][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065100] [Batch 02336/03692] [00:20:40/00:11:59, 0.531s/it]: train_loss_raw=0.7899, running_loss=0.6764, LR=0.000100
[2025-08-10 21:00:44,761][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065112] [Batch 02348/03692] [00:20:46/00:11:53, 0.531s/it]: train_loss_raw=0.6133, running_loss=0.6765, LR=0.000100
[2025-08-10 21:00:50,832][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065124] [Batch 02360/03692] [00:20:52/00:11:46, 0.531s/it]: train_loss_raw=0.6706, running_loss=0.6762, LR=0.000100
[2025-08-10 21:00:56,905][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065136] [Batch 02372/03692] [00:20:58/00:11:40, 0.531s/it]: train_loss_raw=0.6409, running_loss=0.6782, LR=0.000100
[2025-08-10 21:01:02,934][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065148] [Batch 02384/03692] [00:21:04/00:11:33, 0.530s/it]: train_loss_raw=0.7640, running_loss=0.6752, LR=0.000100
[2025-08-10 21:01:09,037][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065160] [Batch 02396/03692] [00:21:10/00:11:27, 0.530s/it]: train_loss_raw=0.7341, running_loss=0.6774, LR=0.000100
[2025-08-10 21:01:15,039][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065172] [Batch 02408/03692] [00:21:16/00:11:20, 0.530s/it]: train_loss_raw=0.6037, running_loss=0.6759, LR=0.000100
[2025-08-10 21:01:21,544][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065184] [Batch 02420/03692] [00:21:23/00:11:14, 0.530s/it]: train_loss_raw=0.6766, running_loss=0.6765, LR=0.000100
[2025-08-10 21:01:28,000][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065196] [Batch 02432/03692] [00:21:29/00:11:08, 0.530s/it]: train_loss_raw=0.6869, running_loss=0.6764, LR=0.000100
[2025-08-10 21:01:34,555][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065208] [Batch 02444/03692] [00:21:36/00:11:01, 0.530s/it]: train_loss_raw=0.6137, running_loss=0.6744, LR=0.000100
[2025-08-10 21:01:41,141][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065220] [Batch 02456/03692] [00:21:42/00:10:55, 0.530s/it]: train_loss_raw=0.7224, running_loss=0.6724, LR=0.000100
[2025-08-10 21:01:47,447][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065232] [Batch 02468/03692] [00:21:49/00:10:49, 0.530s/it]: train_loss_raw=0.6792, running_loss=0.6710, LR=0.000100
[2025-08-10 21:01:54,132][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065244] [Batch 02480/03692] [00:21:55/00:10:43, 0.531s/it]: train_loss_raw=0.6900, running_loss=0.6689, LR=0.000100
[2025-08-10 21:02:00,297][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065256] [Batch 02492/03692] [00:22:02/00:10:36, 0.531s/it]: train_loss_raw=0.7067, running_loss=0.6717, LR=0.000100
[2025-08-10 21:02:06,461][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065268] [Batch 02504/03692] [00:22:08/00:10:30, 0.530s/it]: train_loss_raw=0.6367, running_loss=0.6708, LR=0.000100
[2025-08-10 21:02:12,766][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065280] [Batch 02516/03692] [00:22:14/00:10:23, 0.530s/it]: train_loss_raw=0.6497, running_loss=0.6688, LR=0.000100
[2025-08-10 21:02:19,066][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065292] [Batch 02528/03692] [00:22:20/00:10:17, 0.530s/it]: train_loss_raw=0.7005, running_loss=0.6692, LR=0.000100
[2025-08-10 21:02:25,415][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065304] [Batch 02540/03692] [00:22:27/00:10:10, 0.530s/it]: train_loss_raw=0.6311, running_loss=0.6671, LR=0.000100
[2025-08-10 21:02:31,904][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065316] [Batch 02552/03692] [00:22:33/00:10:04, 0.530s/it]: train_loss_raw=0.6671, running_loss=0.6662, LR=0.000100
[2025-08-10 21:02:38,449][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065328] [Batch 02564/03692] [00:22:40/00:09:58, 0.530s/it]: train_loss_raw=0.7313, running_loss=0.6662, LR=0.000100
[2025-08-10 21:02:44,956][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065340] [Batch 02576/03692] [00:22:46/00:09:52, 0.531s/it]: train_loss_raw=0.7407, running_loss=0.6677, LR=0.000100
[2025-08-10 21:02:51,571][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065352] [Batch 02588/03692] [00:22:53/00:09:45, 0.531s/it]: train_loss_raw=0.7516, running_loss=0.6703, LR=0.000100
[2025-08-10 21:02:57,887][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065364] [Batch 02600/03692] [00:22:59/00:09:39, 0.531s/it]: train_loss_raw=0.6293, running_loss=0.6707, LR=0.000100
[2025-08-10 21:03:04,117][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065376] [Batch 02612/03692] [00:23:05/00:09:33, 0.531s/it]: train_loss_raw=0.5808, running_loss=0.6652, LR=0.000100
[2025-08-10 21:03:10,278][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065388] [Batch 02624/03692] [00:23:12/00:09:26, 0.530s/it]: train_loss_raw=0.5684, running_loss=0.6651, LR=0.000100
[2025-08-10 21:03:16,397][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065400] [Batch 02636/03692] [00:23:18/00:09:20, 0.530s/it]: train_loss_raw=0.7480, running_loss=0.6611, LR=0.000100
[2025-08-10 21:03:22,603][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065412] [Batch 02648/03692] [00:23:24/00:09:13, 0.530s/it]: train_loss_raw=0.6454, running_loss=0.6640, LR=0.000100
[2025-08-10 21:03:29,069][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065424] [Batch 02660/03692] [00:23:30/00:09:07, 0.530s/it]: train_loss_raw=0.6019, running_loss=0.6612, LR=0.000100
[2025-08-10 21:03:35,309][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065436] [Batch 02672/03692] [00:23:37/00:09:00, 0.530s/it]: train_loss_raw=0.7045, running_loss=0.6617, LR=0.000100
[2025-08-10 21:03:41,613][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065448] [Batch 02684/03692] [00:23:43/00:08:54, 0.530s/it]: train_loss_raw=0.6349, running_loss=0.6609, LR=0.000100
[2025-08-10 21:03:48,049][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065460] [Batch 02696/03692] [00:23:49/00:08:48, 0.530s/it]: train_loss_raw=0.6760, running_loss=0.6629, LR=0.000100
[2025-08-10 21:03:54,320][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065472] [Batch 02708/03692] [00:23:56/00:08:41, 0.530s/it]: train_loss_raw=0.6748, running_loss=0.6626, LR=0.000100
[2025-08-10 21:04:00,515][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065484] [Batch 02720/03692] [00:24:02/00:08:35, 0.530s/it]: train_loss_raw=0.7883, running_loss=0.6638, LR=0.000100
[2025-08-10 21:04:06,726][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065496] [Batch 02732/03692] [00:24:08/00:08:28, 0.530s/it]: train_loss_raw=0.7305, running_loss=0.6652, LR=0.000100
[2025-08-10 21:04:12,892][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065508] [Batch 02744/03692] [00:24:14/00:08:22, 0.530s/it]: train_loss_raw=0.7837, running_loss=0.6633, LR=0.000100
[2025-08-10 21:04:19,036][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065520] [Batch 02756/03692] [00:24:20/00:08:16, 0.530s/it]: train_loss_raw=0.5992, running_loss=0.6644, LR=0.000100
[2025-08-10 21:04:25,096][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065532] [Batch 02768/03692] [00:24:26/00:08:09, 0.530s/it]: train_loss_raw=0.5634, running_loss=0.6648, LR=0.000100
[2025-08-10 21:04:31,180][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065544] [Batch 02780/03692] [00:24:32/00:08:03, 0.530s/it]: train_loss_raw=0.7400, running_loss=0.6670, LR=0.000100
[2025-08-10 21:04:37,706][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065556] [Batch 02792/03692] [00:24:39/00:07:56, 0.530s/it]: train_loss_raw=0.6024, running_loss=0.6659, LR=0.000100
[2025-08-10 21:04:44,206][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065568] [Batch 02804/03692] [00:24:45/00:07:50, 0.530s/it]: train_loss_raw=0.6686, running_loss=0.6646, LR=0.000100
[2025-08-10 21:04:50,530][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065580] [Batch 02816/03692] [00:24:52/00:07:44, 0.530s/it]: train_loss_raw=0.6551, running_loss=0.6649, LR=0.000100
[2025-08-10 21:04:56,580][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065592] [Batch 02828/03692] [00:24:58/00:07:37, 0.530s/it]: train_loss_raw=0.6637, running_loss=0.6650, LR=0.000100
[2025-08-10 21:05:02,636][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065604] [Batch 02840/03692] [00:25:04/00:07:31, 0.530s/it]: train_loss_raw=0.7828, running_loss=0.6680, LR=0.000100
[2025-08-10 21:05:08,662][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065616] [Batch 02852/03692] [00:25:10/00:07:24, 0.530s/it]: train_loss_raw=0.5765, running_loss=0.6668, LR=0.000100
[2025-08-10 21:05:14,715][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065628] [Batch 02864/03692] [00:25:16/00:07:18, 0.529s/it]: train_loss_raw=0.6123, running_loss=0.6665, LR=0.000100
[2025-08-10 21:05:20,709][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065640] [Batch 02876/03692] [00:25:22/00:07:11, 0.529s/it]: train_loss_raw=0.6318, running_loss=0.6626, LR=0.000100
[2025-08-10 21:05:26,940][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065652] [Batch 02888/03692] [00:25:28/00:07:05, 0.529s/it]: train_loss_raw=0.6876, running_loss=0.6612, LR=0.000100
[2025-08-10 21:05:33,240][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065664] [Batch 02900/03692] [00:25:34/00:06:59, 0.529s/it]: train_loss_raw=0.6947, running_loss=0.6605, LR=0.000100
[2025-08-10 21:05:39,252][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065676] [Batch 02912/03692] [00:25:40/00:06:52, 0.529s/it]: train_loss_raw=0.7255, running_loss=0.6648, LR=0.000100
[2025-08-10 21:05:45,618][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065688] [Batch 02924/03692] [00:25:47/00:06:46, 0.529s/it]: train_loss_raw=0.6957, running_loss=0.6687, LR=0.000100
[2025-08-10 21:05:52,041][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065700] [Batch 02936/03692] [00:25:53/00:06:40, 0.529s/it]: train_loss_raw=0.6957, running_loss=0.6668, LR=0.000100
[2025-08-10 21:05:58,103][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065712] [Batch 02948/03692] [00:25:59/00:06:33, 0.529s/it]: train_loss_raw=0.6875, running_loss=0.6636, LR=0.000100
[2025-08-10 21:06:04,305][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065724] [Batch 02960/03692] [00:26:06/00:06:27, 0.529s/it]: train_loss_raw=0.7370, running_loss=0.6661, LR=0.000100
[2025-08-10 21:06:10,827][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065736] [Batch 02972/03692] [00:26:12/00:06:20, 0.529s/it]: train_loss_raw=0.5722, running_loss=0.6658, LR=0.000100
[2025-08-10 21:06:17,418][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065748] [Batch 02984/03692] [00:26:19/00:06:14, 0.529s/it]: train_loss_raw=0.6660, running_loss=0.6653, LR=0.000100
[2025-08-10 21:06:23,904][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065760] [Batch 02996/03692] [00:26:25/00:06:08, 0.529s/it]: train_loss_raw=0.6912, running_loss=0.6687, LR=0.000100
[2025-08-10 21:06:30,016][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065772] [Batch 03008/03692] [00:26:31/00:06:01, 0.529s/it]: train_loss_raw=0.7634, running_loss=0.6658, LR=0.000100
[2025-08-10 21:06:36,099][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065784] [Batch 03020/03692] [00:26:37/00:05:55, 0.529s/it]: train_loss_raw=0.6520, running_loss=0.6634, LR=0.000100
[2025-08-10 21:06:42,101][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065796] [Batch 03032/03692] [00:26:43/00:05:49, 0.529s/it]: train_loss_raw=0.5603, running_loss=0.6629, LR=0.000100
[2025-08-10 21:06:48,207][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065808] [Batch 03044/03692] [00:26:49/00:05:42, 0.529s/it]: train_loss_raw=0.7466, running_loss=0.6652, LR=0.000100
[2025-08-10 21:06:54,277][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065820] [Batch 03056/03692] [00:26:56/00:05:36, 0.529s/it]: train_loss_raw=0.5094, running_loss=0.6657, LR=0.000100
[2025-08-10 21:07:00,301][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065832] [Batch 03068/03692] [00:27:02/00:05:29, 0.529s/it]: train_loss_raw=0.6299, running_loss=0.6640, LR=0.000100
[2025-08-10 21:07:06,264][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065844] [Batch 03080/03692] [00:27:08/00:05:23, 0.529s/it]: train_loss_raw=0.5938, running_loss=0.6633, LR=0.000100
[2025-08-10 21:07:12,338][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065856] [Batch 03092/03692] [00:27:14/00:05:17, 0.528s/it]: train_loss_raw=0.6302, running_loss=0.6630, LR=0.000100
[2025-08-10 21:07:18,469][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065868] [Batch 03104/03692] [00:27:20/00:05:10, 0.528s/it]: train_loss_raw=0.7445, running_loss=0.6634, LR=0.000100
[2025-08-10 21:07:24,662][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065880] [Batch 03116/03692] [00:27:26/00:05:04, 0.528s/it]: train_loss_raw=0.7261, running_loss=0.6656, LR=0.000100
[2025-08-10 21:07:30,771][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065892] [Batch 03128/03692] [00:27:32/00:04:57, 0.528s/it]: train_loss_raw=0.7201, running_loss=0.6667, LR=0.000100
[2025-08-10 21:07:36,784][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065904] [Batch 03140/03692] [00:27:38/00:04:51, 0.528s/it]: train_loss_raw=0.7356, running_loss=0.6663, LR=0.000100
[2025-08-10 21:07:42,868][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065916] [Batch 03152/03692] [00:27:44/00:04:45, 0.528s/it]: train_loss_raw=0.6956, running_loss=0.6640, LR=0.000100
[2025-08-10 21:07:48,916][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065928] [Batch 03164/03692] [00:27:50/00:04:38, 0.528s/it]: train_loss_raw=0.6474, running_loss=0.6623, LR=0.000100
[2025-08-10 21:07:55,061][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065940] [Batch 03176/03692] [00:27:56/00:04:32, 0.528s/it]: train_loss_raw=0.5587, running_loss=0.6640, LR=0.000100
[2025-08-10 21:08:01,140][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065952] [Batch 03188/03692] [00:28:02/00:04:26, 0.528s/it]: train_loss_raw=0.7285, running_loss=0.6635, LR=0.000100
[2025-08-10 21:08:07,208][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065964] [Batch 03200/03692] [00:28:08/00:04:19, 0.528s/it]: train_loss_raw=0.6263, running_loss=0.6666, LR=0.000100
[2025-08-10 21:08:13,368][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065976] [Batch 03212/03692] [00:28:15/00:04:13, 0.528s/it]: train_loss_raw=0.6012, running_loss=0.6673, LR=0.000100
[2025-08-10 21:08:19,381][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065988] [Batch 03224/03692] [00:28:21/00:04:06, 0.528s/it]: train_loss_raw=0.7658, running_loss=0.6647, LR=0.000100
[2025-08-10 21:08:25,624][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066000] [Batch 03236/03692] [00:28:27/00:04:00, 0.528s/it]: train_loss_raw=0.6761, running_loss=0.6661, LR=0.000100
[2025-08-10 21:08:37,363][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066012] [Batch 03248/03692] [00:28:39/00:03:55, 0.529s/it]: train_loss_raw=0.6203, running_loss=0.6649, LR=0.000100
[2025-08-10 21:08:43,704][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066024] [Batch 03260/03692] [00:28:45/00:03:48, 0.529s/it]: train_loss_raw=0.6582, running_loss=0.6662, LR=0.000100
[2025-08-10 21:08:49,889][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066036] [Batch 03272/03692] [00:28:51/00:03:42, 0.529s/it]: train_loss_raw=0.6739, running_loss=0.6659, LR=0.000100
[2025-08-10 21:08:55,869][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066048] [Batch 03284/03692] [00:28:57/00:03:35, 0.529s/it]: train_loss_raw=0.6328, running_loss=0.6681, LR=0.000100
[2025-08-10 21:09:01,921][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066060] [Batch 03296/03692] [00:29:03/00:03:29, 0.529s/it]: train_loss_raw=0.7275, running_loss=0.6693, LR=0.000100
[2025-08-10 21:09:07,924][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066072] [Batch 03308/03692] [00:29:09/00:03:23, 0.529s/it]: train_loss_raw=0.7888, running_loss=0.6699, LR=0.000100
[2025-08-10 21:09:13,982][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066084] [Batch 03320/03692] [00:29:15/00:03:16, 0.529s/it]: train_loss_raw=0.6225, running_loss=0.6650, LR=0.000100
[2025-08-10 21:09:20,065][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066096] [Batch 03332/03692] [00:29:21/00:03:10, 0.529s/it]: train_loss_raw=0.6451, running_loss=0.6684, LR=0.000100
[2025-08-10 21:09:26,066][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066108] [Batch 03344/03692] [00:29:27/00:03:03, 0.529s/it]: train_loss_raw=0.5980, running_loss=0.6673, LR=0.000100
[2025-08-10 21:09:32,070][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066120] [Batch 03356/03692] [00:29:33/00:02:57, 0.529s/it]: train_loss_raw=0.6946, running_loss=0.6680, LR=0.000100
[2025-08-10 21:09:38,152][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066132] [Batch 03368/03692] [00:29:39/00:02:51, 0.528s/it]: train_loss_raw=0.5153, running_loss=0.6662, LR=0.000100
[2025-08-10 21:09:44,248][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066144] [Batch 03380/03692] [00:29:45/00:02:44, 0.528s/it]: train_loss_raw=0.8400, running_loss=0.6678, LR=0.000100
[2025-08-10 21:09:50,557][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066156] [Batch 03392/03692] [00:29:52/00:02:38, 0.528s/it]: train_loss_raw=0.6003, running_loss=0.6647, LR=0.000100
[2025-08-10 21:09:56,793][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066168] [Batch 03404/03692] [00:29:58/00:02:32, 0.528s/it]: train_loss_raw=0.6981, running_loss=0.6645, LR=0.000100
[2025-08-10 21:10:03,264][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066180] [Batch 03416/03692] [00:30:05/00:02:25, 0.528s/it]: train_loss_raw=0.6830, running_loss=0.6629, LR=0.000100
[2025-08-10 21:10:09,861][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066192] [Batch 03428/03692] [00:30:11/00:02:19, 0.528s/it]: train_loss_raw=0.6859, running_loss=0.6604, LR=0.000100
[2025-08-10 21:10:16,250][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066204] [Batch 03440/03692] [00:30:17/00:02:13, 0.528s/it]: train_loss_raw=0.7334, running_loss=0.6570, LR=0.000100
[2025-08-10 21:10:22,721][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066216] [Batch 03452/03692] [00:30:24/00:02:06, 0.529s/it]: train_loss_raw=0.6551, running_loss=0.6572, LR=0.000100
[2025-08-10 21:10:29,254][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066228] [Batch 03464/03692] [00:30:30/00:02:00, 0.529s/it]: train_loss_raw=0.6598, running_loss=0.6565, LR=0.000100
[2025-08-10 21:10:35,764][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066240] [Batch 03476/03692] [00:30:37/00:01:54, 0.529s/it]: train_loss_raw=0.7982, running_loss=0.6609, LR=0.000100
[2025-08-10 21:10:42,022][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066252] [Batch 03488/03692] [00:30:43/00:01:47, 0.529s/it]: train_loss_raw=0.5376, running_loss=0.6661, LR=0.000100
[2025-08-10 21:10:48,310][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066264] [Batch 03500/03692] [00:30:50/00:01:41, 0.529s/it]: train_loss_raw=0.7949, running_loss=0.6672, LR=0.000100
[2025-08-10 21:10:54,534][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066276] [Batch 03512/03692] [00:30:56/00:01:35, 0.529s/it]: train_loss_raw=0.6583, running_loss=0.6668, LR=0.000100
[2025-08-10 21:11:00,647][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066288] [Batch 03524/03692] [00:31:02/00:01:28, 0.528s/it]: train_loss_raw=0.6566, running_loss=0.6629, LR=0.000100
[2025-08-10 21:11:06,674][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066300] [Batch 03536/03692] [00:31:08/00:01:22, 0.528s/it]: train_loss_raw=0.6762, running_loss=0.6593, LR=0.000100
[2025-08-10 21:11:12,725][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066312] [Batch 03548/03692] [00:31:14/00:01:16, 0.528s/it]: train_loss_raw=0.6677, running_loss=0.6586, LR=0.000100
[2025-08-10 21:11:18,863][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066324] [Batch 03560/03692] [00:31:20/00:01:09, 0.528s/it]: train_loss_raw=0.5532, running_loss=0.6573, LR=0.000100
[2025-08-10 21:11:24,941][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066336] [Batch 03572/03692] [00:31:26/00:01:03, 0.528s/it]: train_loss_raw=0.5714, running_loss=0.6540, LR=0.000100
[2025-08-10 21:11:31,375][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066348] [Batch 03584/03692] [00:31:33/00:00:57, 0.528s/it]: train_loss_raw=0.7378, running_loss=0.6549, LR=0.000100
[2025-08-10 21:11:37,579][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066360] [Batch 03596/03692] [00:31:39/00:00:50, 0.528s/it]: train_loss_raw=0.5433, running_loss=0.6546, LR=0.000100
[2025-08-10 21:11:44,157][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066372] [Batch 03608/03692] [00:31:45/00:00:44, 0.528s/it]: train_loss_raw=0.5863, running_loss=0.6517, LR=0.000100
[2025-08-10 21:11:50,372][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066384] [Batch 03620/03692] [00:31:52/00:00:38, 0.528s/it]: train_loss_raw=0.6864, running_loss=0.6512, LR=0.000100
[2025-08-10 21:11:56,702][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066396] [Batch 03632/03692] [00:31:58/00:00:31, 0.528s/it]: train_loss_raw=0.6609, running_loss=0.6498, LR=0.000100
[2025-08-10 21:12:02,734][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066408] [Batch 03644/03692] [00:32:04/00:00:25, 0.528s/it]: train_loss_raw=0.5851, running_loss=0.6478, LR=0.000100
[2025-08-10 21:12:08,868][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066420] [Batch 03656/03692] [00:32:10/00:00:19, 0.528s/it]: train_loss_raw=0.7866, running_loss=0.6515, LR=0.000100
[2025-08-10 21:12:15,368][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066432] [Batch 03668/03692] [00:32:17/00:00:12, 0.528s/it]: train_loss_raw=0.6138, running_loss=0.6549, LR=0.000100
[2025-08-10 21:12:21,812][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066444] [Batch 03680/03692] [00:32:23/00:00:06, 0.528s/it]: train_loss_raw=0.7028, running_loss=0.6557, LR=0.000100
[2025-08-10 21:12:53,286][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066456] [Batch 03692/03692] [00:32:55/00:00:00, 0.535s/it]: train_loss_raw=0.5457, running_loss=0.6543, LR=0.000100
[2025-08-10 21:12:58,247][__main__][INFO] - [VALIDATION] [Epoch 17/29] Starting validation.
[2025-08-10 21:13:29,450][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 066457] [Batch 00011/00025] [00:00:31/00:00:33, 2.600s/it]
[2025-08-10 21:13:45,749][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 066457] [Batch 00023/00025] [00:00:47/00:00:01, 1.979s/it]
[2025-08-10 21:13:46,950][__main__][INFO] - [VALIDATION] [Epoch 17/29] train_loss=0.65431, valid_loss=0.69970
[2025-08-10 21:13:46,950][__main__][INFO] - [VALIDATION] [Epoch 17/29] Metrics:
[2025-08-10 21:13:46,950][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_er      0.304
[2025-08-10 21:13:46,950][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_prec    0.464
[2025-08-10 21:13:46,950][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_recall  0.468
[2025-08-10 21:13:46,950][__main__][INFO] - [VALIDATION] [Epoch 17/29] - pep_recall 0.437
[2025-08-10 21:13:46,953][__main__][INFO] - [TRAIN] [Epoch 17/29] Epoch complete, total time 10:17:46, remaining time 06:51:50, 00:34:19 per epoch
[2025-08-10 21:13:54,302][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066468] [Batch 00012/03692] [00:00:07/00:36:18, 0.592s/it]: train_loss_raw=0.6049, running_loss=0.5954, LR=0.000100
[2025-08-10 21:14:00,645][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066480] [Batch 00024/03692] [00:00:13/00:34:15, 0.560s/it]: train_loss_raw=0.6331, running_loss=0.6010, LR=0.000100
[2025-08-10 21:14:07,092][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066492] [Batch 00036/03692] [00:00:19/00:33:40, 0.553s/it]: train_loss_raw=0.7034, running_loss=0.6098, LR=0.000100
[2025-08-10 21:14:13,513][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066504] [Batch 00048/03692] [00:00:26/00:33:17, 0.548s/it]: train_loss_raw=0.5918, running_loss=0.6111, LR=0.000100
[2025-08-10 21:14:19,553][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066516] [Batch 00060/03692] [00:00:32/00:32:38, 0.539s/it]: train_loss_raw=0.5800, running_loss=0.6151, LR=0.000100
[2025-08-10 21:14:25,925][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066528] [Batch 00072/03692] [00:00:38/00:32:27, 0.538s/it]: train_loss_raw=0.7493, running_loss=0.6172, LR=0.000100
[2025-08-10 21:14:32,397][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066540] [Batch 00084/03692] [00:00:45/00:32:21, 0.538s/it]: train_loss_raw=0.5708, running_loss=0.6208, LR=0.000100
[2025-08-10 21:14:38,941][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066552] [Batch 00096/03692] [00:00:51/00:32:18, 0.539s/it]: train_loss_raw=0.5891, running_loss=0.6205, LR=0.000100
[2025-08-10 21:14:45,547][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066564] [Batch 00108/03692] [00:00:58/00:32:16, 0.540s/it]: train_loss_raw=0.6434, running_loss=0.6215, LR=0.000100
[2025-08-10 21:14:52,036][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066576] [Batch 00120/03692] [00:01:04/00:32:09, 0.540s/it]: train_loss_raw=0.7283, running_loss=0.6232, LR=0.000100
[2025-08-10 21:14:58,578][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066588] [Batch 00132/03692] [00:01:11/00:32:05, 0.541s/it]: train_loss_raw=0.5998, running_loss=0.6229, LR=0.000100
[2025-08-10 21:15:05,193][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066600] [Batch 00144/03692] [00:01:17/00:32:01, 0.542s/it]: train_loss_raw=0.5205, running_loss=0.6219, LR=0.000100
[2025-08-10 21:15:11,536][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066612] [Batch 00156/03692] [00:01:24/00:31:51, 0.541s/it]: train_loss_raw=0.7500, running_loss=0.6192, LR=0.000100
[2025-08-10 21:15:18,092][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066624] [Batch 00168/03692] [00:01:30/00:31:46, 0.541s/it]: train_loss_raw=0.6004, running_loss=0.6196, LR=0.000100
[2025-08-10 21:15:24,585][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066636] [Batch 00180/03692] [00:01:37/00:31:40, 0.541s/it]: train_loss_raw=0.7429, running_loss=0.6224, LR=0.000100
[2025-08-10 21:15:30,849][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066648] [Batch 00192/03692] [00:01:43/00:31:29, 0.540s/it]: train_loss_raw=0.7747, running_loss=0.6225, LR=0.000100
[2025-08-10 21:15:36,871][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066660] [Batch 00204/03692] [00:01:49/00:31:15, 0.538s/it]: train_loss_raw=0.5534, running_loss=0.6235, LR=0.000100
[2025-08-10 21:15:43,367][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066672] [Batch 00216/03692] [00:01:56/00:31:09, 0.538s/it]: train_loss_raw=0.6017, running_loss=0.6224, LR=0.000100
[2025-08-10 21:15:49,516][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066684] [Batch 00228/03692] [00:02:02/00:30:58, 0.536s/it]: train_loss_raw=0.6621, running_loss=0.6199, LR=0.000100
[2025-08-10 21:15:55,533][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066696] [Batch 00240/03692] [00:02:08/00:30:45, 0.535s/it]: train_loss_raw=0.6073, running_loss=0.6241, LR=0.000100
[2025-08-10 21:16:01,697][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066708] [Batch 00252/03692] [00:02:14/00:30:36, 0.534s/it]: train_loss_raw=0.6972, running_loss=0.6252, LR=0.000100
[2025-08-10 21:16:07,673][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066720] [Batch 00264/03692] [00:02:20/00:30:24, 0.532s/it]: train_loss_raw=0.5794, running_loss=0.6274, LR=0.000100
[2025-08-10 21:16:13,699][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066732] [Batch 00276/03692] [00:02:26/00:30:13, 0.531s/it]: train_loss_raw=0.5611, running_loss=0.6256, LR=0.000100
[2025-08-10 21:16:19,736][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066744] [Batch 00288/03692] [00:02:32/00:30:02, 0.530s/it]: train_loss_raw=0.6099, running_loss=0.6233, LR=0.000100
[2025-08-10 21:16:25,846][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066756] [Batch 00300/03692] [00:02:38/00:29:53, 0.529s/it]: train_loss_raw=0.6206, running_loss=0.6209, LR=0.000100
[2025-08-10 21:16:32,067][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066768] [Batch 00312/03692] [00:02:44/00:29:46, 0.528s/it]: train_loss_raw=0.6113, running_loss=0.6205, LR=0.000100
[2025-08-10 21:16:38,362][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066780] [Batch 00324/03692] [00:02:51/00:29:39, 0.528s/it]: train_loss_raw=0.5994, running_loss=0.6227, LR=0.000100
[2025-08-10 21:16:44,908][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066792] [Batch 00336/03692] [00:02:57/00:29:34, 0.529s/it]: train_loss_raw=0.6668, running_loss=0.6251, LR=0.000100
[2025-08-10 21:16:50,937][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066804] [Batch 00348/03692] [00:03:03/00:29:25, 0.528s/it]: train_loss_raw=0.5790, running_loss=0.6265, LR=0.000100
[2025-08-10 21:16:56,953][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066816] [Batch 00360/03692] [00:03:09/00:29:16, 0.527s/it]: train_loss_raw=0.6037, running_loss=0.6265, LR=0.000100
[2025-08-10 21:17:02,896][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066828] [Batch 00372/03692] [00:03:15/00:29:06, 0.526s/it]: train_loss_raw=0.6539, running_loss=0.6249, LR=0.000100
[2025-08-10 21:17:09,105][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066840] [Batch 00384/03692] [00:03:21/00:28:59, 0.526s/it]: train_loss_raw=0.6561, running_loss=0.6260, LR=0.000100
[2025-08-10 21:17:15,427][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066852] [Batch 00396/03692] [00:03:28/00:28:53, 0.526s/it]: train_loss_raw=0.5571, running_loss=0.6256, LR=0.000100
[2025-08-10 21:17:21,936][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066864] [Batch 00408/03692] [00:03:34/00:28:48, 0.526s/it]: train_loss_raw=0.6211, running_loss=0.6228, LR=0.000100
[2025-08-10 21:17:28,543][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066876] [Batch 00420/03692] [00:03:41/00:28:44, 0.527s/it]: train_loss_raw=0.6180, running_loss=0.6214, LR=0.000100
[2025-08-10 21:17:34,995][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066888] [Batch 00432/03692] [00:03:47/00:28:39, 0.527s/it]: train_loss_raw=0.5459, running_loss=0.6189, LR=0.000100
[2025-08-10 21:17:41,105][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066900] [Batch 00444/03692] [00:03:53/00:28:31, 0.527s/it]: train_loss_raw=0.6329, running_loss=0.6209, LR=0.000100
[2025-08-10 21:17:47,181][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066912] [Batch 00456/03692] [00:03:59/00:28:23, 0.526s/it]: train_loss_raw=0.6118, running_loss=0.6201, LR=0.000100
[2025-08-10 21:17:53,184][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066924] [Batch 00468/03692] [00:04:05/00:28:14, 0.526s/it]: train_loss_raw=0.5451, running_loss=0.6184, LR=0.000100
[2025-08-10 21:17:59,218][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066936] [Batch 00480/03692] [00:04:12/00:28:06, 0.525s/it]: train_loss_raw=0.6566, running_loss=0.6158, LR=0.000100
[2025-08-10 21:18:05,271][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066948] [Batch 00492/03692] [00:04:18/00:27:58, 0.525s/it]: train_loss_raw=0.5704, running_loss=0.6131, LR=0.000100
[2025-08-10 21:18:11,295][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066960] [Batch 00504/03692] [00:04:24/00:27:50, 0.524s/it]: train_loss_raw=0.6350, running_loss=0.6150, LR=0.000100
[2025-08-10 21:18:17,463][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066972] [Batch 00516/03692] [00:04:30/00:27:43, 0.524s/it]: train_loss_raw=0.6152, running_loss=0.6166, LR=0.000100
[2025-08-10 21:18:23,769][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066984] [Batch 00528/03692] [00:04:36/00:27:37, 0.524s/it]: train_loss_raw=0.6032, running_loss=0.6186, LR=0.000100
[2025-08-10 21:18:30,009][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066996] [Batch 00540/03692] [00:04:42/00:27:30, 0.524s/it]: train_loss_raw=0.6808, running_loss=0.6223, LR=0.000100
[2025-08-10 21:18:36,041][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067008] [Batch 00552/03692] [00:04:48/00:27:23, 0.523s/it]: train_loss_raw=0.7220, running_loss=0.6247, LR=0.000100
[2025-08-10 21:18:42,237][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067020] [Batch 00564/03692] [00:04:55/00:27:16, 0.523s/it]: train_loss_raw=0.6232, running_loss=0.6240, LR=0.000100
[2025-08-10 21:18:48,823][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067032] [Batch 00576/03692] [00:05:01/00:27:11, 0.524s/it]: train_loss_raw=0.6670, running_loss=0.6241, LR=0.000100
[2025-08-10 21:18:55,172][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067044] [Batch 00588/03692] [00:05:07/00:27:05, 0.524s/it]: train_loss_raw=0.6253, running_loss=0.6268, LR=0.000100
[2025-08-10 21:19:01,350][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067056] [Batch 00600/03692] [00:05:14/00:26:58, 0.524s/it]: train_loss_raw=0.5395, running_loss=0.6276, LR=0.000100
[2025-08-10 21:19:07,697][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067068] [Batch 00612/03692] [00:05:20/00:26:52, 0.524s/it]: train_loss_raw=0.5932, running_loss=0.6280, LR=0.000100
[2025-08-10 21:19:14,249][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067080] [Batch 00624/03692] [00:05:27/00:26:47, 0.524s/it]: train_loss_raw=0.6080, running_loss=0.6240, LR=0.000100
[2025-08-10 21:19:20,668][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067092] [Batch 00636/03692] [00:05:33/00:26:42, 0.524s/it]: train_loss_raw=0.5503, running_loss=0.6268, LR=0.000100
[2025-08-10 21:19:26,680][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067104] [Batch 00648/03692] [00:05:39/00:26:34, 0.524s/it]: train_loss_raw=0.4656, running_loss=0.6230, LR=0.000100
[2025-08-10 21:19:32,981][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067116] [Batch 00660/03692] [00:05:45/00:26:28, 0.524s/it]: train_loss_raw=0.6787, running_loss=0.6295, LR=0.000100
[2025-08-10 21:19:39,048][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067128] [Batch 00672/03692] [00:05:51/00:26:21, 0.524s/it]: train_loss_raw=0.7840, running_loss=0.6352, LR=0.000100
[2025-08-10 21:19:45,058][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067140] [Batch 00684/03692] [00:05:57/00:26:13, 0.523s/it]: train_loss_raw=0.6971, running_loss=0.6334, LR=0.000100
[2025-08-10 21:19:51,345][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067152] [Batch 00696/03692] [00:06:04/00:26:07, 0.523s/it]: train_loss_raw=0.7088, running_loss=0.6345, LR=0.000100
[2025-08-10 21:19:57,889][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067164] [Batch 00708/03692] [00:06:10/00:26:02, 0.524s/it]: train_loss_raw=0.5013, running_loss=0.6320, LR=0.000100
[2025-08-10 21:20:04,429][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067176] [Batch 00720/03692] [00:06:17/00:25:57, 0.524s/it]: train_loss_raw=0.6196, running_loss=0.6349, LR=0.000100
[2025-08-10 21:20:10,463][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067188] [Batch 00732/03692] [00:06:23/00:25:49, 0.524s/it]: train_loss_raw=0.5492, running_loss=0.6333, LR=0.000100
[2025-08-10 21:20:16,475][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067200] [Batch 00744/03692] [00:06:29/00:25:42, 0.523s/it]: train_loss_raw=0.5791, running_loss=0.6328, LR=0.000100
[2025-08-10 21:20:22,542][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067212] [Batch 00756/03692] [00:06:35/00:25:35, 0.523s/it]: train_loss_raw=0.6150, running_loss=0.6303, LR=0.000100
[2025-08-10 21:20:28,589][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067224] [Batch 00768/03692] [00:06:41/00:25:28, 0.523s/it]: train_loss_raw=0.7367, running_loss=0.6310, LR=0.000100
[2025-08-10 21:20:34,685][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067236] [Batch 00780/03692] [00:06:47/00:25:21, 0.522s/it]: train_loss_raw=0.6841, running_loss=0.6297, LR=0.000100
[2025-08-10 21:20:40,952][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067248] [Batch 00792/03692] [00:06:53/00:25:15, 0.522s/it]: train_loss_raw=0.6486, running_loss=0.6274, LR=0.000100
[2025-08-10 21:20:47,281][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067260] [Batch 00804/03692] [00:07:00/00:25:08, 0.522s/it]: train_loss_raw=0.6320, running_loss=0.6242, LR=0.000100
[2025-08-10 21:20:53,778][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067272] [Batch 00816/03692] [00:07:06/00:25:03, 0.523s/it]: train_loss_raw=0.6771, running_loss=0.6235, LR=0.000100
[2025-08-10 21:21:00,258][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067284] [Batch 00828/03692] [00:07:13/00:24:57, 0.523s/it]: train_loss_raw=0.6779, running_loss=0.6223, LR=0.000100
[2025-08-10 21:21:06,769][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067296] [Batch 00840/03692] [00:07:19/00:24:52, 0.523s/it]: train_loss_raw=0.7251, running_loss=0.6225, LR=0.000100
[2025-08-10 21:21:13,009][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067308] [Batch 00852/03692] [00:07:25/00:24:46, 0.523s/it]: train_loss_raw=0.6343, running_loss=0.6212, LR=0.000100
[2025-08-10 21:21:18,982][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067320] [Batch 00864/03692] [00:07:31/00:24:38, 0.523s/it]: train_loss_raw=0.6284, running_loss=0.6191, LR=0.000100
[2025-08-10 21:21:25,004][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067332] [Batch 00876/03692] [00:07:37/00:24:31, 0.523s/it]: train_loss_raw=0.6802, running_loss=0.6215, LR=0.000100
[2025-08-10 21:21:31,089][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067344] [Batch 00888/03692] [00:07:43/00:24:24, 0.522s/it]: train_loss_raw=0.5704, running_loss=0.6184, LR=0.000100
[2025-08-10 21:21:37,337][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067356] [Batch 00900/03692] [00:07:50/00:24:18, 0.522s/it]: train_loss_raw=0.6724, running_loss=0.6227, LR=0.000100
[2025-08-10 21:21:43,354][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067368] [Batch 00912/03692] [00:07:56/00:24:11, 0.522s/it]: train_loss_raw=0.5777, running_loss=0.6236, LR=0.000100
[2025-08-10 21:21:49,356][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067380] [Batch 00924/03692] [00:08:02/00:24:04, 0.522s/it]: train_loss_raw=0.5604, running_loss=0.6236, LR=0.000100
[2025-08-10 21:21:55,554][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067392] [Batch 00936/03692] [00:08:08/00:23:57, 0.522s/it]: train_loss_raw=0.5871, running_loss=0.6236, LR=0.000100
[2025-08-10 21:22:01,881][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067404] [Batch 00948/03692] [00:08:14/00:23:51, 0.522s/it]: train_loss_raw=0.6224, running_loss=0.6264, LR=0.000100
[2025-08-10 21:22:08,468][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067416] [Batch 00960/03692] [00:08:21/00:23:46, 0.522s/it]: train_loss_raw=0.5587, running_loss=0.6217, LR=0.000100
[2025-08-10 21:22:15,069][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067428] [Batch 00972/03692] [00:08:27/00:23:41, 0.522s/it]: train_loss_raw=0.6373, running_loss=0.6212, LR=0.000100
[2025-08-10 21:22:21,408][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067440] [Batch 00984/03692] [00:08:34/00:23:35, 0.523s/it]: train_loss_raw=0.7725, running_loss=0.6242, LR=0.000100
[2025-08-10 21:22:27,439][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067452] [Batch 00996/03692] [00:08:40/00:23:28, 0.522s/it]: train_loss_raw=0.6527, running_loss=0.6242, LR=0.000100
[2025-08-10 21:22:33,583][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067464] [Batch 01008/03692] [00:08:46/00:23:21, 0.522s/it]: train_loss_raw=0.5476, running_loss=0.6253, LR=0.000100
[2025-08-10 21:22:39,780][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067476] [Batch 01020/03692] [00:08:52/00:23:15, 0.522s/it]: train_loss_raw=0.6188, running_loss=0.6267, LR=0.000100
[2025-08-10 21:22:45,914][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067488] [Batch 01032/03692] [00:08:58/00:23:08, 0.522s/it]: train_loss_raw=0.6553, running_loss=0.6251, LR=0.000100
[2025-08-10 21:22:52,070][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067500] [Batch 01044/03692] [00:09:04/00:23:02, 0.522s/it]: train_loss_raw=0.7715, running_loss=0.6255, LR=0.000100
[2025-08-10 21:22:58,412][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067512] [Batch 01056/03692] [00:09:11/00:22:55, 0.522s/it]: train_loss_raw=0.4912, running_loss=0.6250, LR=0.000100
[2025-08-10 21:23:04,835][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067524] [Batch 01068/03692] [00:09:17/00:22:50, 0.522s/it]: train_loss_raw=0.5432, running_loss=0.6249, LR=0.000100
[2025-08-10 21:23:10,926][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067536] [Batch 01080/03692] [00:09:23/00:22:43, 0.522s/it]: train_loss_raw=0.6711, running_loss=0.6214, LR=0.000100
[2025-08-10 21:23:16,969][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067548] [Batch 01092/03692] [00:09:29/00:22:36, 0.522s/it]: train_loss_raw=0.6032, running_loss=0.6249, LR=0.000100
[2025-08-10 21:23:23,357][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067560] [Batch 01104/03692] [00:09:36/00:22:30, 0.522s/it]: train_loss_raw=0.5030, running_loss=0.6261, LR=0.000100
[2025-08-10 21:23:29,838][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067572] [Batch 01116/03692] [00:09:42/00:22:24, 0.522s/it]: train_loss_raw=0.6594, running_loss=0.6309, LR=0.000100
[2025-08-10 21:23:36,168][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067584] [Batch 01128/03692] [00:09:48/00:22:18, 0.522s/it]: train_loss_raw=0.5351, running_loss=0.6301, LR=0.000100
[2025-08-10 21:23:42,603][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067596] [Batch 01140/03692] [00:09:55/00:22:12, 0.522s/it]: train_loss_raw=0.6851, running_loss=0.6319, LR=0.000100
[2025-08-10 21:23:49,057][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067608] [Batch 01152/03692] [00:10:01/00:22:07, 0.522s/it]: train_loss_raw=0.5547, running_loss=0.6302, LR=0.000100
[2025-08-10 21:23:55,018][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067620] [Batch 01164/03692] [00:10:07/00:22:00, 0.522s/it]: train_loss_raw=0.5676, running_loss=0.6272, LR=0.000100
[2025-08-10 21:24:01,069][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067632] [Batch 01176/03692] [00:10:13/00:21:53, 0.522s/it]: train_loss_raw=0.6205, running_loss=0.6309, LR=0.000100
[2025-08-10 21:24:07,118][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067644] [Batch 01188/03692] [00:10:19/00:21:46, 0.522s/it]: train_loss_raw=0.5312, running_loss=0.6296, LR=0.000100
[2025-08-10 21:24:13,529][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067656] [Batch 01200/03692] [00:10:26/00:21:40, 0.522s/it]: train_loss_raw=0.6291, running_loss=0.6259, LR=0.000100
[2025-08-10 21:24:20,026][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067668] [Batch 01212/03692] [00:10:32/00:21:34, 0.522s/it]: train_loss_raw=0.6438, running_loss=0.6249, LR=0.000100
[2025-08-10 21:24:26,083][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067680] [Batch 01224/03692] [00:10:38/00:21:28, 0.522s/it]: train_loss_raw=0.5401, running_loss=0.6233, LR=0.000100
[2025-08-10 21:24:32,166][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067692] [Batch 01236/03692] [00:10:44/00:21:21, 0.522s/it]: train_loss_raw=0.5351, running_loss=0.6258, LR=0.000100
[2025-08-10 21:24:38,206][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067704] [Batch 01248/03692] [00:10:51/00:21:14, 0.522s/it]: train_loss_raw=0.5903, running_loss=0.6270, LR=0.000100
[2025-08-10 21:24:44,304][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067716] [Batch 01260/03692] [00:10:57/00:21:08, 0.522s/it]: train_loss_raw=0.6468, running_loss=0.6257, LR=0.000100
[2025-08-10 21:24:50,448][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067728] [Batch 01272/03692] [00:11:03/00:21:01, 0.521s/it]: train_loss_raw=0.5182, running_loss=0.6239, LR=0.000100
[2025-08-10 21:24:56,466][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067740] [Batch 01284/03692] [00:11:09/00:20:55, 0.521s/it]: train_loss_raw=0.5247, running_loss=0.6218, LR=0.000100
[2025-08-10 21:25:02,499][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067752] [Batch 01296/03692] [00:11:15/00:20:48, 0.521s/it]: train_loss_raw=0.5134, running_loss=0.6214, LR=0.000100
[2025-08-10 21:25:08,603][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067764] [Batch 01308/03692] [00:11:21/00:20:41, 0.521s/it]: train_loss_raw=0.6074, running_loss=0.6196, LR=0.000100
[2025-08-10 21:25:14,584][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067776] [Batch 01320/03692] [00:11:27/00:20:35, 0.521s/it]: train_loss_raw=0.6471, running_loss=0.6237, LR=0.000100
[2025-08-10 21:25:20,593][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067788] [Batch 01332/03692] [00:11:33/00:20:28, 0.521s/it]: train_loss_raw=0.5541, running_loss=0.6211, LR=0.000100
[2025-08-10 21:25:26,754][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067800] [Batch 01344/03692] [00:11:39/00:20:22, 0.521s/it]: train_loss_raw=0.4552, running_loss=0.6168, LR=0.000100
[2025-08-10 21:25:33,211][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067812] [Batch 01356/03692] [00:11:46/00:20:16, 0.521s/it]: train_loss_raw=0.5956, running_loss=0.6192, LR=0.000100
[2025-08-10 21:25:39,415][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067824] [Batch 01368/03692] [00:11:52/00:20:09, 0.521s/it]: train_loss_raw=0.6792, running_loss=0.6185, LR=0.000100
[2025-08-10 21:25:45,586][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067836] [Batch 01380/03692] [00:11:58/00:20:03, 0.521s/it]: train_loss_raw=0.6040, running_loss=0.6193, LR=0.000100
[2025-08-10 21:25:51,755][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067848] [Batch 01392/03692] [00:12:04/00:19:57, 0.521s/it]: train_loss_raw=0.6014, running_loss=0.6167, LR=0.000100
[2025-08-10 21:25:57,793][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067860] [Batch 01404/03692] [00:12:10/00:19:50, 0.520s/it]: train_loss_raw=0.6381, running_loss=0.6192, LR=0.000100
[2025-08-10 21:26:03,916][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067872] [Batch 01416/03692] [00:12:16/00:19:44, 0.520s/it]: train_loss_raw=0.6413, running_loss=0.6228, LR=0.000100
[2025-08-10 21:26:09,969][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067884] [Batch 01428/03692] [00:12:22/00:19:37, 0.520s/it]: train_loss_raw=0.6695, running_loss=0.6263, LR=0.000100
[2025-08-10 21:26:16,044][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067896] [Batch 01440/03692] [00:12:28/00:19:31, 0.520s/it]: train_loss_raw=0.5564, running_loss=0.6291, LR=0.000100
[2025-08-10 21:26:22,037][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067908] [Batch 01452/03692] [00:12:34/00:19:24, 0.520s/it]: train_loss_raw=0.7563, running_loss=0.6295, LR=0.000100
[2025-08-10 21:26:28,118][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067920] [Batch 01464/03692] [00:12:40/00:19:18, 0.520s/it]: train_loss_raw=0.6421, running_loss=0.6289, LR=0.000100
[2025-08-10 21:26:34,499][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067932] [Batch 01476/03692] [00:12:47/00:19:11, 0.520s/it]: train_loss_raw=0.6171, running_loss=0.6270, LR=0.000100
[2025-08-10 21:26:41,134][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067944] [Batch 01488/03692] [00:12:53/00:19:06, 0.520s/it]: train_loss_raw=0.5461, running_loss=0.6292, LR=0.000100
[2025-08-10 21:26:47,615][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067956] [Batch 01500/03692] [00:13:00/00:19:00, 0.520s/it]: train_loss_raw=0.6740, running_loss=0.6327, LR=0.000100
[2025-08-10 21:26:54,110][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067968] [Batch 01512/03692] [00:13:06/00:18:54, 0.520s/it]: train_loss_raw=0.5942, running_loss=0.6326, LR=0.000100
[2025-08-10 21:27:00,677][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067980] [Batch 01524/03692] [00:13:13/00:18:48, 0.521s/it]: train_loss_raw=0.5318, running_loss=0.6298, LR=0.000100
[2025-08-10 21:27:30,481][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067992] [Batch 01536/03692] [00:13:43/00:19:15, 0.536s/it]: train_loss_raw=0.5830, running_loss=0.6291, LR=0.000100
[2025-08-10 21:27:42,406][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068004] [Batch 01548/03692] [00:13:55/00:19:16, 0.540s/it]: train_loss_raw=0.7075, running_loss=0.6301, LR=0.000100
[2025-08-10 21:27:48,630][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068016] [Batch 01560/03692] [00:14:01/00:19:09, 0.539s/it]: train_loss_raw=0.5972, running_loss=0.6303, LR=0.000100
[2025-08-10 21:27:54,899][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068028] [Batch 01572/03692] [00:14:07/00:19:03, 0.539s/it]: train_loss_raw=0.6848, running_loss=0.6303, LR=0.000100
[2025-08-10 21:28:01,433][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068040] [Batch 01584/03692] [00:14:14/00:18:56, 0.539s/it]: train_loss_raw=0.6593, running_loss=0.6293, LR=0.000100
[2025-08-10 21:28:07,476][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068052] [Batch 01596/03692] [00:14:20/00:18:49, 0.539s/it]: train_loss_raw=0.5443, running_loss=0.6289, LR=0.000100
[2025-08-10 21:28:13,569][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068064] [Batch 01608/03692] [00:14:26/00:18:42, 0.539s/it]: train_loss_raw=0.5991, running_loss=0.6261, LR=0.000100
[2025-08-10 21:28:19,618][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068076] [Batch 01620/03692] [00:14:32/00:18:35, 0.539s/it]: train_loss_raw=0.6214, running_loss=0.6230, LR=0.000100
[2025-08-10 21:28:25,596][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068088] [Batch 01632/03692] [00:14:38/00:18:28, 0.538s/it]: train_loss_raw=0.6059, running_loss=0.6222, LR=0.000100
[2025-08-10 21:28:31,631][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068100] [Batch 01644/03692] [00:14:44/00:18:21, 0.538s/it]: train_loss_raw=0.6446, running_loss=0.6228, LR=0.000100
[2025-08-10 21:28:37,714][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068112] [Batch 01656/03692] [00:14:50/00:18:14, 0.538s/it]: train_loss_raw=0.6422, running_loss=0.6264, LR=0.000100
[2025-08-10 21:28:43,865][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068124] [Batch 01668/03692] [00:14:56/00:18:08, 0.538s/it]: train_loss_raw=0.5655, running_loss=0.6276, LR=0.000100
[2025-08-10 21:28:50,380][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068136] [Batch 01680/03692] [00:15:03/00:18:01, 0.538s/it]: train_loss_raw=0.6257, running_loss=0.6231, LR=0.000100
[2025-08-10 21:28:56,572][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068148] [Batch 01692/03692] [00:15:09/00:17:54, 0.537s/it]: train_loss_raw=0.6480, running_loss=0.6226, LR=0.000100
[2025-08-10 21:29:02,820][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068160] [Batch 01704/03692] [00:15:15/00:17:48, 0.537s/it]: train_loss_raw=0.6897, running_loss=0.6245, LR=0.000100
[2025-08-10 21:29:08,888][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068172] [Batch 01716/03692] [00:15:21/00:17:41, 0.537s/it]: train_loss_raw=0.6462, running_loss=0.6213, LR=0.000100
[2025-08-10 21:29:14,908][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068184] [Batch 01728/03692] [00:15:27/00:17:34, 0.537s/it]: train_loss_raw=0.6440, running_loss=0.6190, LR=0.000100
[2025-08-10 21:29:20,936][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068196] [Batch 01740/03692] [00:15:33/00:17:27, 0.537s/it]: train_loss_raw=0.6380, running_loss=0.6234, LR=0.000100
[2025-08-10 21:29:27,429][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068208] [Batch 01752/03692] [00:15:40/00:17:21, 0.537s/it]: train_loss_raw=0.5477, running_loss=0.6234, LR=0.000100
[2025-08-10 21:29:33,599][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068220] [Batch 01764/03692] [00:15:46/00:17:14, 0.537s/it]: train_loss_raw=0.6832, running_loss=0.6222, LR=0.000100
[2025-08-10 21:29:39,842][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068232] [Batch 01776/03692] [00:15:52/00:17:07, 0.536s/it]: train_loss_raw=0.6187, running_loss=0.6224, LR=0.000100
[2025-08-10 21:29:46,307][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068244] [Batch 01788/03692] [00:15:59/00:17:01, 0.536s/it]: train_loss_raw=0.6063, running_loss=0.6251, LR=0.000100
[2025-08-10 21:29:52,865][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068256] [Batch 01800/03692] [00:16:05/00:16:55, 0.536s/it]: train_loss_raw=0.5115, running_loss=0.6234, LR=0.000100
[2025-08-10 21:29:59,074][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068268] [Batch 01812/03692] [00:16:11/00:16:48, 0.536s/it]: train_loss_raw=0.4842, running_loss=0.6258, LR=0.000100
[2025-08-10 21:30:05,228][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068280] [Batch 01824/03692] [00:16:18/00:16:41, 0.536s/it]: train_loss_raw=0.5449, running_loss=0.6233, LR=0.000100
[2025-08-10 21:30:11,703][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068292] [Batch 01836/03692] [00:16:24/00:16:35, 0.536s/it]: train_loss_raw=0.6594, running_loss=0.6209, LR=0.000100
[2025-08-10 21:30:18,185][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068304] [Batch 01848/03692] [00:16:30/00:16:28, 0.536s/it]: train_loss_raw=0.5667, running_loss=0.6211, LR=0.000100
[2025-08-10 21:30:24,761][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068316] [Batch 01860/03692] [00:16:37/00:16:22, 0.536s/it]: train_loss_raw=0.5494, running_loss=0.6202, LR=0.000100
[2025-08-10 21:30:31,244][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068328] [Batch 01872/03692] [00:16:44/00:16:16, 0.536s/it]: train_loss_raw=0.7116, running_loss=0.6165, LR=0.000100
[2025-08-10 21:30:37,873][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068340] [Batch 01884/03692] [00:16:50/00:16:09, 0.536s/it]: train_loss_raw=0.6013, running_loss=0.6152, LR=0.000100
[2025-08-10 21:30:44,416][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068352] [Batch 01896/03692] [00:16:57/00:16:03, 0.537s/it]: train_loss_raw=0.5753, running_loss=0.6124, LR=0.000100
[2025-08-10 21:30:50,962][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068364] [Batch 01908/03692] [00:17:03/00:15:57, 0.537s/it]: train_loss_raw=0.6738, running_loss=0.6121, LR=0.000100
[2025-08-10 21:30:57,297][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068376] [Batch 01920/03692] [00:17:10/00:15:50, 0.537s/it]: train_loss_raw=0.5482, running_loss=0.6080, LR=0.000100
[2025-08-10 21:31:03,765][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068388] [Batch 01932/03692] [00:17:16/00:15:44, 0.537s/it]: train_loss_raw=0.6374, running_loss=0.6108, LR=0.000100
[2025-08-10 21:31:09,864][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068400] [Batch 01944/03692] [00:17:22/00:15:37, 0.536s/it]: train_loss_raw=0.6191, running_loss=0.6135, LR=0.000100
[2025-08-10 21:31:16,009][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068412] [Batch 01956/03692] [00:17:28/00:15:30, 0.536s/it]: train_loss_raw=0.6343, running_loss=0.6122, LR=0.000100
[2025-08-10 21:31:22,030][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068424] [Batch 01968/03692] [00:17:34/00:15:24, 0.536s/it]: train_loss_raw=0.6390, running_loss=0.6153, LR=0.000100
[2025-08-10 21:31:27,994][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068436] [Batch 01980/03692] [00:17:40/00:15:17, 0.536s/it]: train_loss_raw=0.6869, running_loss=0.6170, LR=0.000100
[2025-08-10 21:31:34,080][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068448] [Batch 01992/03692] [00:17:46/00:15:10, 0.536s/it]: train_loss_raw=0.6695, running_loss=0.6176, LR=0.000100
[2025-08-10 21:31:40,166][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068460] [Batch 02004/03692] [00:17:52/00:15:03, 0.535s/it]: train_loss_raw=0.6835, running_loss=0.6151, LR=0.000100
[2025-08-10 21:31:46,175][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068472] [Batch 02016/03692] [00:17:58/00:14:57, 0.535s/it]: train_loss_raw=0.6110, running_loss=0.6160, LR=0.000100
[2025-08-10 21:31:52,222][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068484] [Batch 02028/03692] [00:18:05/00:14:50, 0.535s/it]: train_loss_raw=0.5908, running_loss=0.6158, LR=0.000100
[2025-08-10 21:31:58,304][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068496] [Batch 02040/03692] [00:18:11/00:14:43, 0.535s/it]: train_loss_raw=0.5881, running_loss=0.6148, LR=0.000100
[2025-08-10 21:32:04,408][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068508] [Batch 02052/03692] [00:18:17/00:14:36, 0.535s/it]: train_loss_raw=0.5814, running_loss=0.6183, LR=0.000100
[2025-08-10 21:32:10,578][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068520] [Batch 02064/03692] [00:18:23/00:14:30, 0.535s/it]: train_loss_raw=0.6187, running_loss=0.6164, LR=0.000100
[2025-08-10 21:32:16,715][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068532] [Batch 02076/03692] [00:18:29/00:14:23, 0.534s/it]: train_loss_raw=0.5573, running_loss=0.6163, LR=0.000100
[2025-08-10 21:32:22,918][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068544] [Batch 02088/03692] [00:18:35/00:14:17, 0.534s/it]: train_loss_raw=0.6551, running_loss=0.6179, LR=0.000100
[2025-08-10 21:32:29,197][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068556] [Batch 02100/03692] [00:18:41/00:14:10, 0.534s/it]: train_loss_raw=0.6598, running_loss=0.6156, LR=0.000100
[2025-08-10 21:32:35,513][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068568] [Batch 02112/03692] [00:18:48/00:14:04, 0.534s/it]: train_loss_raw=0.6047, running_loss=0.6141, LR=0.000100
[2025-08-10 21:32:41,520][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068580] [Batch 02124/03692] [00:18:54/00:13:57, 0.534s/it]: train_loss_raw=0.6680, running_loss=0.6139, LR=0.000100
[2025-08-10 21:32:47,834][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068592] [Batch 02136/03692] [00:19:00/00:13:50, 0.534s/it]: train_loss_raw=0.5988, running_loss=0.6123, LR=0.000100
[2025-08-10 21:32:54,371][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068604] [Batch 02148/03692] [00:19:07/00:13:44, 0.534s/it]: train_loss_raw=0.5006, running_loss=0.6136, LR=0.000100
[2025-08-10 21:33:00,798][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068616] [Batch 02160/03692] [00:19:13/00:13:38, 0.534s/it]: train_loss_raw=0.5797, running_loss=0.6123, LR=0.000100
[2025-08-10 21:33:07,425][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068628] [Batch 02172/03692] [00:19:20/00:13:31, 0.534s/it]: train_loss_raw=0.5540, running_loss=0.6090, LR=0.000100
[2025-08-10 21:33:13,903][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068640] [Batch 02184/03692] [00:19:26/00:13:25, 0.534s/it]: train_loss_raw=0.5947, running_loss=0.6115, LR=0.000100
[2025-08-10 21:33:20,377][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068652] [Batch 02196/03692] [00:19:33/00:13:19, 0.534s/it]: train_loss_raw=0.5909, running_loss=0.6116, LR=0.000100
[2025-08-10 21:33:26,846][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068664] [Batch 02208/03692] [00:19:39/00:13:12, 0.534s/it]: train_loss_raw=0.5237, running_loss=0.6112, LR=0.000100
[2025-08-10 21:33:32,862][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068676] [Batch 02220/03692] [00:19:45/00:13:06, 0.534s/it]: train_loss_raw=0.5875, running_loss=0.6109, LR=0.000100
[2025-08-10 21:33:38,846][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068688] [Batch 02232/03692] [00:19:51/00:12:59, 0.534s/it]: train_loss_raw=0.6243, running_loss=0.6105, LR=0.000100
[2025-08-10 21:33:45,112][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068700] [Batch 02244/03692] [00:19:57/00:12:52, 0.534s/it]: train_loss_raw=0.6909, running_loss=0.6121, LR=0.000100
[2025-08-10 21:33:51,224][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068712] [Batch 02256/03692] [00:20:04/00:12:46, 0.534s/it]: train_loss_raw=0.5266, running_loss=0.6157, LR=0.000100
[2025-08-10 21:33:57,633][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068724] [Batch 02268/03692] [00:20:10/00:12:39, 0.534s/it]: train_loss_raw=0.6562, running_loss=0.6141, LR=0.000100
[2025-08-10 21:34:04,037][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068736] [Batch 02280/03692] [00:20:16/00:12:33, 0.534s/it]: train_loss_raw=0.7101, running_loss=0.6146, LR=0.000100
[2025-08-10 21:34:10,052][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068748] [Batch 02292/03692] [00:20:22/00:12:26, 0.534s/it]: train_loss_raw=0.6051, running_loss=0.6137, LR=0.000100
[2025-08-10 21:34:16,114][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068760] [Batch 02304/03692] [00:20:28/00:12:20, 0.533s/it]: train_loss_raw=0.7864, running_loss=0.6163, LR=0.000100
[2025-08-10 21:34:22,079][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068772] [Batch 02316/03692] [00:20:34/00:12:13, 0.533s/it]: train_loss_raw=0.5153, running_loss=0.6154, LR=0.000100
[2025-08-10 21:34:28,160][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068784] [Batch 02328/03692] [00:20:40/00:12:07, 0.533s/it]: train_loss_raw=0.6926, running_loss=0.6159, LR=0.000100
[2025-08-10 21:34:34,233][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068796] [Batch 02340/03692] [00:20:47/00:12:00, 0.533s/it]: train_loss_raw=0.6179, running_loss=0.6167, LR=0.000100
[2025-08-10 21:34:40,253][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068808] [Batch 02352/03692] [00:20:53/00:11:53, 0.533s/it]: train_loss_raw=0.6095, running_loss=0.6150, LR=0.000100
[2025-08-10 21:34:46,360][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068820] [Batch 02364/03692] [00:20:59/00:11:47, 0.533s/it]: train_loss_raw=0.5960, running_loss=0.6114, LR=0.000100
[2025-08-10 21:34:52,865][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068832] [Batch 02376/03692] [00:21:05/00:11:41, 0.533s/it]: train_loss_raw=0.5875, running_loss=0.6111, LR=0.000100
[2025-08-10 21:34:59,187][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068844] [Batch 02388/03692] [00:21:11/00:11:34, 0.533s/it]: train_loss_raw=0.6548, running_loss=0.6121, LR=0.000100
[2025-08-10 21:35:05,528][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068856] [Batch 02400/03692] [00:21:18/00:11:28, 0.533s/it]: train_loss_raw=0.5114, running_loss=0.6127, LR=0.000100
[2025-08-10 21:35:12,097][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068868] [Batch 02412/03692] [00:21:24/00:11:21, 0.533s/it]: train_loss_raw=0.5397, running_loss=0.6114, LR=0.000100
[2025-08-10 21:35:18,639][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068880] [Batch 02424/03692] [00:21:31/00:11:15, 0.533s/it]: train_loss_raw=0.6117, running_loss=0.6122, LR=0.000100
[2025-08-10 21:35:25,261][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068892] [Batch 02436/03692] [00:21:38/00:11:09, 0.533s/it]: train_loss_raw=0.6222, running_loss=0.6140, LR=0.000100
[2025-08-10 21:35:31,752][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068904] [Batch 02448/03692] [00:21:44/00:11:02, 0.533s/it]: train_loss_raw=0.6080, running_loss=0.6153, LR=0.000100
[2025-08-10 21:35:38,345][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068916] [Batch 02460/03692] [00:21:51/00:10:56, 0.533s/it]: train_loss_raw=0.5476, running_loss=0.6145, LR=0.000100
[2025-08-10 21:35:44,481][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068928] [Batch 02472/03692] [00:21:57/00:10:50, 0.533s/it]: train_loss_raw=0.5633, running_loss=0.6137, LR=0.000100
[2025-08-10 21:35:50,720][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068940] [Batch 02484/03692] [00:22:03/00:10:43, 0.533s/it]: train_loss_raw=0.6319, running_loss=0.6137, LR=0.000100
[2025-08-10 21:35:57,206][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068952] [Batch 02496/03692] [00:22:10/00:10:37, 0.533s/it]: train_loss_raw=0.5954, running_loss=0.6141, LR=0.000100
[2025-08-10 21:36:03,853][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068964] [Batch 02508/03692] [00:22:16/00:10:31, 0.533s/it]: train_loss_raw=0.7502, running_loss=0.6179, LR=0.000100
[2025-08-10 21:36:10,063][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068976] [Batch 02520/03692] [00:22:22/00:10:24, 0.533s/it]: train_loss_raw=0.7004, running_loss=0.6167, LR=0.000100
[2025-08-10 21:36:16,536][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068988] [Batch 02532/03692] [00:22:29/00:10:18, 0.533s/it]: train_loss_raw=0.6238, running_loss=0.6138, LR=0.000100
[2025-08-10 21:36:22,715][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069000] [Batch 02544/03692] [00:22:35/00:10:11, 0.533s/it]: train_loss_raw=0.5386, running_loss=0.6104, LR=0.000100
[2025-08-10 21:36:29,257][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069012] [Batch 02556/03692] [00:22:42/00:10:05, 0.533s/it]: train_loss_raw=0.5363, running_loss=0.6095, LR=0.000100
[2025-08-10 21:36:35,720][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069024] [Batch 02568/03692] [00:22:48/00:09:58, 0.533s/it]: train_loss_raw=0.6858, running_loss=0.6073, LR=0.000100
[2025-08-10 21:36:42,217][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069036] [Batch 02580/03692] [00:22:55/00:09:52, 0.533s/it]: train_loss_raw=0.5061, running_loss=0.6060, LR=0.000100
[2025-08-10 21:36:48,401][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069048] [Batch 02592/03692] [00:23:01/00:09:46, 0.533s/it]: train_loss_raw=0.5747, running_loss=0.6071, LR=0.000100
[2025-08-10 21:36:54,766][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069060] [Batch 02604/03692] [00:23:07/00:09:39, 0.533s/it]: train_loss_raw=0.4951, running_loss=0.6054, LR=0.000100
[2025-08-10 21:37:00,804][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069072] [Batch 02616/03692] [00:23:13/00:09:33, 0.533s/it]: train_loss_raw=0.6279, running_loss=0.6099, LR=0.000100
[2025-08-10 21:37:06,865][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069084] [Batch 02628/03692] [00:23:19/00:09:26, 0.533s/it]: train_loss_raw=0.6078, running_loss=0.6085, LR=0.000100
[2025-08-10 21:37:12,924][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069096] [Batch 02640/03692] [00:23:25/00:09:20, 0.532s/it]: train_loss_raw=0.6367, running_loss=0.6086, LR=0.000100
[2025-08-10 21:37:19,255][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069108] [Batch 02652/03692] [00:23:32/00:09:13, 0.532s/it]: train_loss_raw=0.6281, running_loss=0.6089, LR=0.000100
[2025-08-10 21:37:25,769][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069120] [Batch 02664/03692] [00:23:38/00:09:07, 0.532s/it]: train_loss_raw=0.6917, running_loss=0.6163, LR=0.000100
[2025-08-10 21:37:31,967][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069132] [Batch 02676/03692] [00:23:44/00:09:00, 0.532s/it]: train_loss_raw=0.5678, running_loss=0.6135, LR=0.000100
[2025-08-10 21:37:38,035][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069144] [Batch 02688/03692] [00:23:50/00:08:54, 0.532s/it]: train_loss_raw=0.6461, running_loss=0.6142, LR=0.000100
[2025-08-10 21:37:44,080][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069156] [Batch 02700/03692] [00:23:56/00:08:47, 0.532s/it]: train_loss_raw=0.5828, running_loss=0.6156, LR=0.000100
[2025-08-10 21:37:50,062][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069168] [Batch 02712/03692] [00:24:02/00:08:41, 0.532s/it]: train_loss_raw=0.5528, running_loss=0.6141, LR=0.000100
[2025-08-10 21:37:56,329][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069180] [Batch 02724/03692] [00:24:09/00:08:34, 0.532s/it]: train_loss_raw=0.5848, running_loss=0.6149, LR=0.000100
[2025-08-10 21:38:02,861][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069192] [Batch 02736/03692] [00:24:15/00:08:28, 0.532s/it]: train_loss_raw=0.6429, running_loss=0.6096, LR=0.000100
[2025-08-10 21:38:09,419][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069204] [Batch 02748/03692] [00:24:22/00:08:22, 0.532s/it]: train_loss_raw=0.5652, running_loss=0.6107, LR=0.000100
[2025-08-10 21:38:15,902][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069216] [Batch 02760/03692] [00:24:28/00:08:15, 0.532s/it]: train_loss_raw=0.6223, running_loss=0.6091, LR=0.000100
[2025-08-10 21:38:22,146][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069228] [Batch 02772/03692] [00:24:34/00:08:09, 0.532s/it]: train_loss_raw=0.5829, running_loss=0.6069, LR=0.000100
[2025-08-10 21:38:28,126][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069240] [Batch 02784/03692] [00:24:40/00:08:03, 0.532s/it]: train_loss_raw=0.8169, running_loss=0.6054, LR=0.000100
[2025-08-10 21:38:34,201][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069252] [Batch 02796/03692] [00:24:47/00:07:56, 0.532s/it]: train_loss_raw=0.6116, running_loss=0.6050, LR=0.000100
[2025-08-10 21:38:40,219][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069264] [Batch 02808/03692] [00:24:53/00:07:50, 0.532s/it]: train_loss_raw=0.5980, running_loss=0.6062, LR=0.000100
[2025-08-10 21:38:46,229][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069276] [Batch 02820/03692] [00:24:59/00:07:43, 0.532s/it]: train_loss_raw=0.6180, running_loss=0.6029, LR=0.000100
[2025-08-10 21:38:52,265][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069288] [Batch 02832/03692] [00:25:05/00:07:37, 0.531s/it]: train_loss_raw=0.5758, running_loss=0.6003, LR=0.000100
[2025-08-10 21:38:58,442][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069300] [Batch 02844/03692] [00:25:11/00:07:30, 0.531s/it]: train_loss_raw=0.5208, running_loss=0.6001, LR=0.000100
[2025-08-10 21:39:04,806][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069312] [Batch 02856/03692] [00:25:17/00:07:24, 0.531s/it]: train_loss_raw=0.6768, running_loss=0.6010, LR=0.000100
[2025-08-10 21:39:11,357][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069324] [Batch 02868/03692] [00:25:24/00:07:17, 0.531s/it]: train_loss_raw=0.5657, running_loss=0.6002, LR=0.000100
[2025-08-10 21:39:17,520][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069336] [Batch 02880/03692] [00:25:30/00:07:11, 0.531s/it]: train_loss_raw=0.5678, running_loss=0.6033, LR=0.000100
[2025-08-10 21:39:23,498][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069348] [Batch 02892/03692] [00:25:36/00:07:04, 0.531s/it]: train_loss_raw=0.4867, running_loss=0.6048, LR=0.000100
[2025-08-10 21:39:29,447][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069360] [Batch 02904/03692] [00:25:42/00:06:58, 0.531s/it]: train_loss_raw=0.6272, running_loss=0.6025, LR=0.000100
[2025-08-10 21:39:35,470][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069372] [Batch 02916/03692] [00:25:48/00:06:52, 0.531s/it]: train_loss_raw=0.6181, running_loss=0.6045, LR=0.000100
[2025-08-10 21:39:41,506][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069384] [Batch 02928/03692] [00:25:54/00:06:45, 0.531s/it]: train_loss_raw=0.6098, running_loss=0.6020, LR=0.000100
[2025-08-10 21:39:47,559][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069396] [Batch 02940/03692] [00:26:00/00:06:39, 0.531s/it]: train_loss_raw=0.6311, running_loss=0.6059, LR=0.000100
[2025-08-10 21:39:53,576][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069408] [Batch 02952/03692] [00:26:06/00:06:32, 0.531s/it]: train_loss_raw=0.6753, running_loss=0.6076, LR=0.000100
[2025-08-10 21:39:59,654][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069420] [Batch 02964/03692] [00:26:12/00:06:26, 0.531s/it]: train_loss_raw=0.6044, running_loss=0.6086, LR=0.000100
[2025-08-10 21:40:05,684][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069432] [Batch 02976/03692] [00:26:18/00:06:19, 0.530s/it]: train_loss_raw=0.6567, running_loss=0.6068, LR=0.000100
[2025-08-10 21:40:11,770][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069444] [Batch 02988/03692] [00:26:24/00:06:13, 0.530s/it]: train_loss_raw=0.6305, running_loss=0.6059, LR=0.000100
[2025-08-10 21:40:17,885][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069456] [Batch 03000/03692] [00:26:30/00:06:06, 0.530s/it]: train_loss_raw=0.5900, running_loss=0.6051, LR=0.000100
[2025-08-10 21:40:23,884][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069468] [Batch 03012/03692] [00:26:36/00:06:00, 0.530s/it]: train_loss_raw=0.5580, running_loss=0.6036, LR=0.000100
[2025-08-10 21:40:30,337][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069480] [Batch 03024/03692] [00:26:43/00:05:54, 0.530s/it]: train_loss_raw=0.5396, running_loss=0.6015, LR=0.000100
[2025-08-10 21:40:36,878][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069492] [Batch 03036/03692] [00:26:49/00:05:47, 0.530s/it]: train_loss_raw=0.5012, running_loss=0.5994, LR=0.000100
[2025-08-10 21:40:43,308][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069504] [Batch 03048/03692] [00:26:56/00:05:41, 0.530s/it]: train_loss_raw=0.6365, running_loss=0.5979, LR=0.000100
[2025-08-10 21:40:49,677][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069516] [Batch 03060/03692] [00:27:02/00:05:35, 0.530s/it]: train_loss_raw=0.6122, running_loss=0.5956, LR=0.000100
[2025-08-10 21:40:56,063][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069528] [Batch 03072/03692] [00:27:08/00:05:28, 0.530s/it]: train_loss_raw=0.5375, running_loss=0.5962, LR=0.000100
[2025-08-10 21:41:02,490][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069540] [Batch 03084/03692] [00:27:15/00:05:22, 0.530s/it]: train_loss_raw=0.5140, running_loss=0.5961, LR=0.000100
[2025-08-10 21:41:08,900][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069552] [Batch 03096/03692] [00:27:21/00:05:16, 0.530s/it]: train_loss_raw=0.6142, running_loss=0.5963, LR=0.000100
[2025-08-10 21:41:15,368][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069564] [Batch 03108/03692] [00:27:28/00:05:09, 0.530s/it]: train_loss_raw=0.6477, running_loss=0.5932, LR=0.000100
[2025-08-10 21:41:21,797][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069576] [Batch 03120/03692] [00:27:34/00:05:03, 0.530s/it]: train_loss_raw=0.6610, running_loss=0.5965, LR=0.000100
[2025-08-10 21:41:27,976][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069588] [Batch 03132/03692] [00:27:40/00:04:56, 0.530s/it]: train_loss_raw=0.6523, running_loss=0.5943, LR=0.000100
[2025-08-10 21:41:34,206][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069600] [Batch 03144/03692] [00:27:47/00:04:50, 0.530s/it]: train_loss_raw=0.5278, running_loss=0.5954, LR=0.000100
[2025-08-10 21:41:40,618][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069612] [Batch 03156/03692] [00:27:53/00:04:44, 0.530s/it]: train_loss_raw=0.5914, running_loss=0.5926, LR=0.000100
[2025-08-10 21:41:47,062][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069624] [Batch 03168/03692] [00:27:59/00:04:37, 0.530s/it]: train_loss_raw=0.5666, running_loss=0.5955, LR=0.000100
[2025-08-10 21:41:53,628][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069636] [Batch 03180/03692] [00:28:06/00:04:31, 0.530s/it]: train_loss_raw=0.5565, running_loss=0.5940, LR=0.000100
[2025-08-10 21:42:00,011][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069648] [Batch 03192/03692] [00:28:12/00:04:25, 0.530s/it]: train_loss_raw=0.4933, running_loss=0.5943, LR=0.000100
[2025-08-10 21:42:06,065][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069660] [Batch 03204/03692] [00:28:18/00:04:18, 0.530s/it]: train_loss_raw=0.5828, running_loss=0.5950, LR=0.000100
[2025-08-10 21:42:12,085][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069672] [Batch 03216/03692] [00:28:24/00:04:12, 0.530s/it]: train_loss_raw=0.5335, running_loss=0.5944, LR=0.000100
[2025-08-10 21:42:18,107][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069684] [Batch 03228/03692] [00:28:30/00:04:05, 0.530s/it]: train_loss_raw=0.5515, running_loss=0.5925, LR=0.000100
[2025-08-10 21:42:24,153][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069696] [Batch 03240/03692] [00:28:36/00:03:59, 0.530s/it]: train_loss_raw=0.5780, running_loss=0.5908, LR=0.000100
[2025-08-10 21:42:30,322][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069708] [Batch 03252/03692] [00:28:43/00:03:53, 0.530s/it]: train_loss_raw=0.7235, running_loss=0.5965, LR=0.000100
[2025-08-10 21:42:36,416][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069720] [Batch 03264/03692] [00:28:49/00:03:46, 0.530s/it]: train_loss_raw=0.5052, running_loss=0.5976, LR=0.000100
[2025-08-10 21:42:42,429][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069732] [Batch 03276/03692] [00:28:55/00:03:40, 0.530s/it]: train_loss_raw=0.6446, running_loss=0.5986, LR=0.000100
[2025-08-10 21:42:48,758][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069744] [Batch 03288/03692] [00:29:01/00:03:33, 0.530s/it]: train_loss_raw=0.5967, running_loss=0.6006, LR=0.000100
[2025-08-10 21:42:54,975][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069756] [Batch 03300/03692] [00:29:07/00:03:27, 0.530s/it]: train_loss_raw=0.5589, running_loss=0.5985, LR=0.000100
[2025-08-10 21:43:01,313][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069768] [Batch 03312/03692] [00:29:14/00:03:21, 0.530s/it]: train_loss_raw=0.5887, running_loss=0.5989, LR=0.000100
[2025-08-10 21:43:07,667][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069780] [Batch 03324/03692] [00:29:20/00:03:14, 0.530s/it]: train_loss_raw=0.6390, running_loss=0.6028, LR=0.000100
[2025-08-10 21:43:14,067][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069792] [Batch 03336/03692] [00:29:26/00:03:08, 0.530s/it]: train_loss_raw=0.6018, running_loss=0.6030, LR=0.000100
[2025-08-10 21:43:20,546][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069804] [Batch 03348/03692] [00:29:33/00:03:02, 0.530s/it]: train_loss_raw=0.6576, running_loss=0.6035, LR=0.000100
[2025-08-10 21:43:27,092][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069816] [Batch 03360/03692] [00:29:39/00:02:55, 0.530s/it]: train_loss_raw=0.6745, running_loss=0.6066, LR=0.000100
[2025-08-10 21:43:33,608][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069828] [Batch 03372/03692] [00:29:46/00:02:49, 0.530s/it]: train_loss_raw=0.5117, running_loss=0.6053, LR=0.000100
[2025-08-10 21:43:40,141][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069840] [Batch 03384/03692] [00:29:52/00:02:43, 0.530s/it]: train_loss_raw=0.5956, running_loss=0.6035, LR=0.000100
[2025-08-10 21:43:46,634][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069852] [Batch 03396/03692] [00:29:59/00:02:36, 0.530s/it]: train_loss_raw=0.5215, running_loss=0.6008, LR=0.000100
[2025-08-10 21:43:52,929][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069864] [Batch 03408/03692] [00:30:05/00:02:30, 0.530s/it]: train_loss_raw=0.5149, running_loss=0.6012, LR=0.000100
[2025-08-10 21:43:59,404][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069876] [Batch 03420/03692] [00:30:12/00:02:24, 0.530s/it]: train_loss_raw=0.5739, running_loss=0.6003, LR=0.000100
[2025-08-10 21:44:05,975][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069888] [Batch 03432/03692] [00:30:18/00:02:17, 0.530s/it]: train_loss_raw=0.5112, running_loss=0.5985, LR=0.000100
[2025-08-10 21:44:12,537][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069900] [Batch 03444/03692] [00:30:25/00:02:11, 0.530s/it]: train_loss_raw=0.6565, running_loss=0.5967, LR=0.000100
[2025-08-10 21:44:19,103][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069912] [Batch 03456/03692] [00:30:31/00:02:05, 0.530s/it]: train_loss_raw=0.6238, running_loss=0.6000, LR=0.000100
[2025-08-10 21:44:25,425][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069924] [Batch 03468/03692] [00:30:38/00:01:58, 0.530s/it]: train_loss_raw=0.5479, running_loss=0.5980, LR=0.000100
[2025-08-10 21:44:31,421][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069936] [Batch 03480/03692] [00:30:44/00:01:52, 0.530s/it]: train_loss_raw=0.6653, running_loss=0.5969, LR=0.000100
[2025-08-10 21:44:37,425][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069948] [Batch 03492/03692] [00:30:50/00:01:45, 0.530s/it]: train_loss_raw=0.6540, running_loss=0.5934, LR=0.000100
[2025-08-10 21:44:43,609][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069960] [Batch 03504/03692] [00:30:56/00:01:39, 0.530s/it]: train_loss_raw=0.5893, running_loss=0.5948, LR=0.000100
[2025-08-10 21:44:50,002][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069972] [Batch 03516/03692] [00:31:02/00:01:33, 0.530s/it]: train_loss_raw=0.5501, running_loss=0.5978, LR=0.000100
[2025-08-10 21:44:56,063][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069984] [Batch 03528/03692] [00:31:08/00:01:26, 0.530s/it]: train_loss_raw=0.6547, running_loss=0.5968, LR=0.000100
[2025-08-10 21:45:02,089][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069996] [Batch 03540/03692] [00:31:14/00:01:20, 0.530s/it]: train_loss_raw=0.6193, running_loss=0.5970, LR=0.000100
[2025-08-10 21:45:12,599][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070008] [Batch 03552/03692] [00:31:25/00:01:14, 0.531s/it]: train_loss_raw=0.6476, running_loss=0.5988, LR=0.000100
[2025-08-10 21:45:18,718][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070020] [Batch 03564/03692] [00:31:31/00:01:07, 0.531s/it]: train_loss_raw=0.5476, running_loss=0.5955, LR=0.000100
[2025-08-10 21:45:25,023][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070032] [Batch 03576/03692] [00:31:37/00:01:01, 0.531s/it]: train_loss_raw=0.5476, running_loss=0.5959, LR=0.000100
[2025-08-10 21:45:31,553][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070044] [Batch 03588/03692] [00:31:44/00:00:55, 0.531s/it]: train_loss_raw=0.6232, running_loss=0.5952, LR=0.000100
[2025-08-10 21:45:38,101][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070056] [Batch 03600/03692] [00:31:50/00:00:48, 0.531s/it]: train_loss_raw=0.4137, running_loss=0.5916, LR=0.000100
[2025-08-10 21:45:44,357][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070068] [Batch 03612/03692] [00:31:57/00:00:42, 0.531s/it]: train_loss_raw=0.5935, running_loss=0.5900, LR=0.000100
[2025-08-10 21:45:50,718][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070080] [Batch 03624/03692] [00:32:03/00:00:36, 0.531s/it]: train_loss_raw=0.6903, running_loss=0.5917, LR=0.000100
[2025-08-10 21:45:57,285][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070092] [Batch 03636/03692] [00:32:10/00:00:29, 0.531s/it]: train_loss_raw=0.6674, running_loss=0.5920, LR=0.000100
[2025-08-10 21:46:03,869][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070104] [Batch 03648/03692] [00:32:16/00:00:23, 0.531s/it]: train_loss_raw=0.7467, running_loss=0.5968, LR=0.000100
[2025-08-10 21:46:10,515][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070116] [Batch 03660/03692] [00:32:23/00:00:16, 0.531s/it]: train_loss_raw=0.5809, running_loss=0.5935, LR=0.000100
[2025-08-10 21:46:17,028][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070128] [Batch 03672/03692] [00:32:29/00:00:10, 0.531s/it]: train_loss_raw=0.6414, running_loss=0.5945, LR=0.000100
[2025-08-10 21:46:23,545][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070140] [Batch 03684/03692] [00:32:36/00:00:04, 0.531s/it]: train_loss_raw=0.5709, running_loss=0.5920, LR=0.000100
[2025-08-10 21:46:32,896][__main__][INFO] - [VALIDATION] [Epoch 18/29] Starting validation.
[2025-08-10 21:47:06,237][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 070149] [Batch 00011/00025] [00:00:33/00:00:36, 2.778s/it]
[2025-08-10 21:47:21,779][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 070149] [Batch 00023/00025] [00:00:48/00:00:02, 2.037s/it]
[2025-08-10 21:47:23,023][__main__][INFO] - [VALIDATION] [Epoch 18/29] train_loss=0.59286, valid_loss=0.65654
[2025-08-10 21:47:23,023][__main__][INFO] - [VALIDATION] [Epoch 18/29] Metrics:
[2025-08-10 21:47:23,023][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_er      0.285
[2025-08-10 21:47:23,023][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_prec    0.480
[2025-08-10 21:47:23,023][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_recall  0.485
[2025-08-10 21:47:23,023][__main__][INFO] - [VALIDATION] [Epoch 18/29] - pep_recall 0.464
[2025-08-10 21:47:23,026][__main__][INFO] - [TRAIN] [Epoch 18/29] Epoch complete, total time 10:51:22, remaining time 06:17:06, 00:34:16 per epoch
[2025-08-10 21:47:25,103][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070152] [Batch 00004/03692] [00:00:01/00:26:22, 0.429s/it]: train_loss_raw=0.6296, running_loss=0.6812, LR=0.000100
[2025-08-10 21:47:31,584][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070164] [Batch 00016/03692] [00:00:08/00:31:23, 0.512s/it]: train_loss_raw=0.6927, running_loss=0.6757, LR=0.000100
[2025-08-10 21:47:37,994][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070176] [Batch 00028/03692] [00:00:14/00:31:51, 0.522s/it]: train_loss_raw=0.6531, running_loss=0.6695, LR=0.000100
[2025-08-10 21:47:44,474][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070188] [Batch 00040/03692] [00:00:21/00:32:05, 0.527s/it]: train_loss_raw=0.5210, running_loss=0.6622, LR=0.000100
[2025-08-10 21:47:50,795][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070200] [Batch 00052/03692] [00:00:27/00:31:58, 0.527s/it]: train_loss_raw=0.6708, running_loss=0.6590, LR=0.000100
[2025-08-10 21:47:57,277][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070212] [Batch 00064/03692] [00:00:33/00:32:01, 0.530s/it]: train_loss_raw=0.4879, running_loss=0.6506, LR=0.000100
[2025-08-10 21:48:03,647][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070224] [Batch 00076/03692] [00:00:40/00:31:55, 0.530s/it]: train_loss_raw=0.4314, running_loss=0.6423, LR=0.000100
[2025-08-10 21:48:10,005][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070236] [Batch 00088/03692] [00:00:46/00:31:49, 0.530s/it]: train_loss_raw=0.5675, running_loss=0.6346, LR=0.000100
[2025-08-10 21:48:16,403][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070248] [Batch 00100/03692] [00:00:53/00:31:44, 0.530s/it]: train_loss_raw=0.5632, running_loss=0.6309, LR=0.000100
[2025-08-10 21:48:22,876][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070260] [Batch 00112/03692] [00:00:59/00:31:41, 0.531s/it]: train_loss_raw=0.5844, running_loss=0.6284, LR=0.000100
[2025-08-10 21:48:29,227][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070272] [Batch 00124/03692] [00:01:05/00:31:34, 0.531s/it]: train_loss_raw=0.5866, running_loss=0.6187, LR=0.000100
[2025-08-10 21:48:35,636][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070284] [Batch 00136/03692] [00:01:12/00:31:29, 0.531s/it]: train_loss_raw=0.5680, running_loss=0.6180, LR=0.000100
[2025-08-10 21:48:42,002][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070296] [Batch 00148/03692] [00:01:18/00:31:22, 0.531s/it]: train_loss_raw=0.6728, running_loss=0.6129, LR=0.000100
[2025-08-10 21:48:48,334][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070308] [Batch 00160/03692] [00:01:24/00:31:15, 0.531s/it]: train_loss_raw=0.6514, running_loss=0.6125, LR=0.000100
[2025-08-10 21:48:54,705][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070320] [Batch 00172/03692] [00:01:31/00:31:08, 0.531s/it]: train_loss_raw=0.6581, running_loss=0.6126, LR=0.000100
[2025-08-10 21:49:01,105][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070332] [Batch 00184/03692] [00:01:37/00:31:03, 0.531s/it]: train_loss_raw=0.5647, running_loss=0.6060, LR=0.000100
[2025-08-10 21:49:07,277][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070344] [Batch 00196/03692] [00:01:43/00:30:53, 0.530s/it]: train_loss_raw=0.5819, running_loss=0.6034, LR=0.000100
[2025-08-10 21:49:13,601][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070356] [Batch 00208/03692] [00:01:50/00:30:46, 0.530s/it]: train_loss_raw=0.6156, running_loss=0.6014, LR=0.000100
[2025-08-10 21:49:19,956][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070368] [Batch 00220/03692] [00:01:56/00:30:39, 0.530s/it]: train_loss_raw=0.6639, running_loss=0.6025, LR=0.000100
[2025-08-10 21:49:26,312][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070380] [Batch 00232/03692] [00:02:02/00:30:33, 0.530s/it]: train_loss_raw=0.5751, running_loss=0.6015, LR=0.000100
[2025-08-10 21:49:32,687][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070392] [Batch 00244/03692] [00:02:09/00:30:27, 0.530s/it]: train_loss_raw=0.5413, running_loss=0.6004, LR=0.000100
[2025-08-10 21:49:39,090][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070404] [Batch 00256/03692] [00:02:15/00:30:21, 0.530s/it]: train_loss_raw=0.5907, running_loss=0.6001, LR=0.000100
[2025-08-10 21:49:45,537][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070416] [Batch 00268/03692] [00:02:22/00:30:16, 0.530s/it]: train_loss_raw=0.6989, running_loss=0.6016, LR=0.000100
[2025-08-10 21:49:51,944][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070428] [Batch 00280/03692] [00:02:28/00:30:10, 0.531s/it]: train_loss_raw=0.6152, running_loss=0.6004, LR=0.000100
[2025-08-10 21:49:58,361][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070440] [Batch 00292/03692] [00:02:34/00:30:04, 0.531s/it]: train_loss_raw=0.7068, running_loss=0.6029, LR=0.000100
[2025-08-10 21:50:04,733][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070452] [Batch 00304/03692] [00:02:41/00:29:58, 0.531s/it]: train_loss_raw=0.5877, running_loss=0.5993, LR=0.000100
[2025-08-10 21:50:11,101][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070464] [Batch 00316/03692] [00:02:47/00:29:51, 0.531s/it]: train_loss_raw=0.5752, running_loss=0.5991, LR=0.000100
[2025-08-10 21:50:17,491][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070476] [Batch 00328/03692] [00:02:54/00:29:45, 0.531s/it]: train_loss_raw=0.5715, running_loss=0.5935, LR=0.000100
[2025-08-10 21:50:24,056][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070488] [Batch 00340/03692] [00:03:00/00:29:41, 0.531s/it]: train_loss_raw=0.5825, running_loss=0.5919, LR=0.000100
[2025-08-10 21:50:30,645][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070500] [Batch 00352/03692] [00:03:07/00:29:36, 0.532s/it]: train_loss_raw=0.6452, running_loss=0.5907, LR=0.000100
[2025-08-10 21:50:36,848][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070512] [Batch 00364/03692] [00:03:13/00:29:28, 0.531s/it]: train_loss_raw=0.6880, running_loss=0.5936, LR=0.000100
[2025-08-10 21:50:43,205][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070524] [Batch 00376/03692] [00:03:19/00:29:22, 0.531s/it]: train_loss_raw=0.5668, running_loss=0.5935, LR=0.000100
[2025-08-10 21:50:49,667][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070536] [Batch 00388/03692] [00:03:26/00:29:16, 0.532s/it]: train_loss_raw=0.6143, running_loss=0.5937, LR=0.000100
[2025-08-10 21:50:55,991][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070548] [Batch 00400/03692] [00:03:32/00:29:09, 0.532s/it]: train_loss_raw=0.5661, running_loss=0.5935, LR=0.000100
[2025-08-10 21:51:02,531][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070560] [Batch 00412/03692] [00:03:39/00:29:04, 0.532s/it]: train_loss_raw=0.5404, running_loss=0.5893, LR=0.000100
[2025-08-10 21:51:08,932][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070572] [Batch 00424/03692] [00:03:45/00:28:58, 0.532s/it]: train_loss_raw=0.6355, running_loss=0.5930, LR=0.000100
[2025-08-10 21:51:15,259][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070584] [Batch 00436/03692] [00:03:51/00:28:51, 0.532s/it]: train_loss_raw=0.5239, running_loss=0.5939, LR=0.000100
[2025-08-10 21:51:21,661][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070596] [Batch 00448/03692] [00:03:58/00:28:45, 0.532s/it]: train_loss_raw=0.5669, running_loss=0.5950, LR=0.000100
[2025-08-10 21:51:27,936][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070608] [Batch 00460/03692] [00:04:04/00:28:38, 0.532s/it]: train_loss_raw=0.6708, running_loss=0.5973, LR=0.000100
[2025-08-10 21:51:33,959][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070620] [Batch 00472/03692] [00:04:10/00:28:29, 0.531s/it]: train_loss_raw=0.6308, running_loss=0.6031, LR=0.000100
[2025-08-10 21:51:40,007][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070632] [Batch 00484/03692] [00:04:16/00:28:20, 0.530s/it]: train_loss_raw=0.6057, running_loss=0.6039, LR=0.000100
[2025-08-10 21:51:46,156][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070644] [Batch 00496/03692] [00:04:22/00:28:13, 0.530s/it]: train_loss_raw=0.5929, running_loss=0.6041, LR=0.000100
[2025-08-10 21:51:52,208][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070656] [Batch 00508/03692] [00:04:28/00:28:04, 0.529s/it]: train_loss_raw=0.6028, running_loss=0.6015, LR=0.000100
[2025-08-10 21:51:58,712][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070668] [Batch 00520/03692] [00:04:35/00:27:59, 0.529s/it]: train_loss_raw=0.5955, running_loss=0.5990, LR=0.000100
[2025-08-10 21:52:05,246][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070680] [Batch 00532/03692] [00:04:41/00:27:54, 0.530s/it]: train_loss_raw=0.5219, running_loss=0.5981, LR=0.000100
[2025-08-10 21:52:11,684][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070692] [Batch 00544/03692] [00:04:48/00:27:48, 0.530s/it]: train_loss_raw=0.5535, running_loss=0.5978, LR=0.000100
[2025-08-10 21:52:18,186][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070704] [Batch 00556/03692] [00:04:54/00:27:42, 0.530s/it]: train_loss_raw=0.5696, running_loss=0.5967, LR=0.000100
[2025-08-10 21:52:24,653][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070716] [Batch 00568/03692] [00:05:01/00:27:36, 0.530s/it]: train_loss_raw=0.6703, running_loss=0.5954, LR=0.000100
[2025-08-10 21:52:30,866][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070728] [Batch 00580/03692] [00:05:07/00:27:29, 0.530s/it]: train_loss_raw=0.6395, running_loss=0.5964, LR=0.000100
[2025-08-10 21:52:36,959][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070740] [Batch 00592/03692] [00:05:13/00:27:22, 0.530s/it]: train_loss_raw=0.6288, running_loss=0.5970, LR=0.000100
[2025-08-10 21:52:42,984][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070752] [Batch 00604/03692] [00:05:19/00:27:13, 0.529s/it]: train_loss_raw=0.7290, running_loss=0.5975, LR=0.000100
[2025-08-10 21:52:48,989][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070764] [Batch 00616/03692] [00:05:25/00:27:05, 0.529s/it]: train_loss_raw=0.6113, running_loss=0.5966, LR=0.000100
[2025-08-10 21:52:55,233][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070776] [Batch 00628/03692] [00:05:31/00:26:59, 0.528s/it]: train_loss_raw=0.4975, running_loss=0.5938, LR=0.000100
[2025-08-10 21:53:01,606][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070788] [Batch 00640/03692] [00:05:38/00:26:52, 0.528s/it]: train_loss_raw=0.5737, running_loss=0.5939, LR=0.000100
[2025-08-10 21:53:08,089][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070800] [Batch 00652/03692] [00:05:44/00:26:47, 0.529s/it]: train_loss_raw=0.5332, running_loss=0.5935, LR=0.000100
[2025-08-10 21:53:14,235][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070812] [Batch 00664/03692] [00:05:50/00:26:39, 0.528s/it]: train_loss_raw=0.5759, running_loss=0.5925, LR=0.000100
[2025-08-10 21:53:20,762][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070824] [Batch 00676/03692] [00:05:57/00:26:34, 0.529s/it]: train_loss_raw=0.5768, running_loss=0.5889, LR=0.000100
[2025-08-10 21:53:27,232][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070836] [Batch 00688/03692] [00:06:03/00:26:28, 0.529s/it]: train_loss_raw=0.4951, running_loss=0.5881, LR=0.000100
[2025-08-10 21:53:33,825][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070848] [Batch 00700/03692] [00:06:10/00:26:23, 0.529s/it]: train_loss_raw=0.6236, running_loss=0.5898, LR=0.000100
[2025-08-10 21:53:40,441][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070860] [Batch 00712/03692] [00:06:17/00:26:18, 0.530s/it]: train_loss_raw=0.6294, running_loss=0.5913, LR=0.000100
[2025-08-10 21:53:46,999][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070872] [Batch 00724/03692] [00:06:23/00:26:12, 0.530s/it]: train_loss_raw=0.6384, running_loss=0.5920, LR=0.000100
[2025-08-10 21:53:53,459][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070884] [Batch 00736/03692] [00:06:30/00:26:06, 0.530s/it]: train_loss_raw=0.6627, running_loss=0.5941, LR=0.000100
[2025-08-10 21:54:00,058][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070896] [Batch 00748/03692] [00:06:36/00:26:01, 0.530s/it]: train_loss_raw=0.7119, running_loss=0.5936, LR=0.000100
[2025-08-10 21:54:06,548][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070908] [Batch 00760/03692] [00:06:43/00:25:55, 0.530s/it]: train_loss_raw=0.6025, running_loss=0.5925, LR=0.000100
[2025-08-10 21:54:12,993][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070920] [Batch 00772/03692] [00:06:49/00:25:49, 0.531s/it]: train_loss_raw=0.5174, running_loss=0.5893, LR=0.000100
[2025-08-10 21:54:19,493][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070932] [Batch 00784/03692] [00:06:56/00:25:43, 0.531s/it]: train_loss_raw=0.5644, running_loss=0.5893, LR=0.000100
[2025-08-10 21:54:25,949][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070944] [Batch 00796/03692] [00:07:02/00:25:37, 0.531s/it]: train_loss_raw=0.5547, running_loss=0.5892, LR=0.000100
[2025-08-10 21:54:32,365][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070956] [Batch 00808/03692] [00:07:08/00:25:31, 0.531s/it]: train_loss_raw=0.6606, running_loss=0.5908, LR=0.000100
[2025-08-10 21:54:38,872][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070968] [Batch 00820/03692] [00:07:15/00:25:25, 0.531s/it]: train_loss_raw=0.5938, running_loss=0.5925, LR=0.000100
[2025-08-10 21:54:45,345][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070980] [Batch 00832/03692] [00:07:21/00:25:19, 0.531s/it]: train_loss_raw=0.5768, running_loss=0.5927, LR=0.000100
[2025-08-10 21:54:51,793][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070992] [Batch 00844/03692] [00:07:28/00:25:13, 0.531s/it]: train_loss_raw=0.4634, running_loss=0.5914, LR=0.000100
[2025-08-10 21:54:58,123][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071004] [Batch 00856/03692] [00:07:34/00:25:06, 0.531s/it]: train_loss_raw=0.6441, running_loss=0.5940, LR=0.000100
[2025-08-10 21:55:04,486][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071016] [Batch 00868/03692] [00:07:41/00:25:00, 0.531s/it]: train_loss_raw=0.5727, running_loss=0.5923, LR=0.000100
[2025-08-10 21:55:10,956][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071028] [Batch 00880/03692] [00:07:47/00:24:54, 0.531s/it]: train_loss_raw=0.5164, running_loss=0.5913, LR=0.000100
[2025-08-10 21:55:17,498][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071040] [Batch 00892/03692] [00:07:54/00:24:48, 0.532s/it]: train_loss_raw=0.6767, running_loss=0.5896, LR=0.000100
[2025-08-10 21:55:23,670][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071052] [Batch 00904/03692] [00:08:00/00:24:41, 0.531s/it]: train_loss_raw=0.4993, running_loss=0.5914, LR=0.000100
[2025-08-10 21:55:29,796][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071064] [Batch 00916/03692] [00:08:06/00:24:34, 0.531s/it]: train_loss_raw=0.7048, running_loss=0.5897, LR=0.000100
[2025-08-10 21:55:36,065][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071076] [Batch 00928/03692] [00:08:12/00:24:27, 0.531s/it]: train_loss_raw=0.5816, running_loss=0.5892, LR=0.000100
[2025-08-10 21:55:42,481][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071088] [Batch 00940/03692] [00:08:19/00:24:21, 0.531s/it]: train_loss_raw=0.6978, running_loss=0.5871, LR=0.000100
[2025-08-10 21:55:49,097][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071100] [Batch 00952/03692] [00:08:25/00:24:15, 0.531s/it]: train_loss_raw=0.6733, running_loss=0.5887, LR=0.000100
[2025-08-10 21:55:55,701][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071112] [Batch 00964/03692] [00:08:32/00:24:09, 0.531s/it]: train_loss_raw=0.5706, running_loss=0.5874, LR=0.000100
[2025-08-10 21:56:02,037][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071124] [Batch 00976/03692] [00:08:38/00:24:03, 0.531s/it]: train_loss_raw=0.5790, running_loss=0.5893, LR=0.000100
[2025-08-10 21:56:08,549][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071136] [Batch 00988/03692] [00:08:45/00:23:57, 0.532s/it]: train_loss_raw=0.5826, running_loss=0.5887, LR=0.000100
[2025-08-10 21:56:15,023][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071148] [Batch 01000/03692] [00:08:51/00:23:51, 0.532s/it]: train_loss_raw=0.4992, running_loss=0.5847, LR=0.000100
[2025-08-10 21:56:21,345][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071160] [Batch 01012/03692] [00:08:57/00:23:44, 0.532s/it]: train_loss_raw=0.6381, running_loss=0.5842, LR=0.000100
[2025-08-10 21:56:27,785][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071172] [Batch 01024/03692] [00:09:04/00:23:38, 0.532s/it]: train_loss_raw=0.5557, running_loss=0.5837, LR=0.000100
[2025-08-10 21:56:34,319][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071184] [Batch 01036/03692] [00:09:10/00:23:32, 0.532s/it]: train_loss_raw=0.5578, running_loss=0.5844, LR=0.000100
[2025-08-10 21:56:40,908][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071196] [Batch 01048/03692] [00:09:17/00:23:26, 0.532s/it]: train_loss_raw=0.5372, running_loss=0.5849, LR=0.000100
[2025-08-10 21:56:47,205][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071208] [Batch 01060/03692] [00:09:23/00:23:19, 0.532s/it]: train_loss_raw=0.6090, running_loss=0.5826, LR=0.000100
[2025-08-10 21:56:53,592][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071220] [Batch 01072/03692] [00:09:30/00:23:13, 0.532s/it]: train_loss_raw=0.6135, running_loss=0.5828, LR=0.000100
[2025-08-10 21:57:00,006][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071232] [Batch 01084/03692] [00:09:36/00:23:07, 0.532s/it]: train_loss_raw=0.6696, running_loss=0.5854, LR=0.000100
[2025-08-10 21:57:06,347][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071244] [Batch 01096/03692] [00:09:42/00:23:00, 0.532s/it]: train_loss_raw=0.5330, running_loss=0.5810, LR=0.000100
[2025-08-10 21:57:12,758][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071256] [Batch 01108/03692] [00:09:49/00:22:54, 0.532s/it]: train_loss_raw=0.6260, running_loss=0.5800, LR=0.000100
[2025-08-10 21:57:19,160][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071268] [Batch 01120/03692] [00:09:55/00:22:48, 0.532s/it]: train_loss_raw=0.5593, running_loss=0.5808, LR=0.000100
[2025-08-10 21:57:25,561][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071280] [Batch 01132/03692] [00:10:02/00:22:41, 0.532s/it]: train_loss_raw=0.6541, running_loss=0.5804, LR=0.000100
[2025-08-10 21:57:31,939][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071292] [Batch 01144/03692] [00:10:08/00:22:35, 0.532s/it]: train_loss_raw=0.6151, running_loss=0.5815, LR=0.000100
[2025-08-10 21:57:38,349][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071304] [Batch 01156/03692] [00:10:14/00:22:29, 0.532s/it]: train_loss_raw=0.6629, running_loss=0.5831, LR=0.000100
[2025-08-10 21:57:44,737][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071316] [Batch 01168/03692] [00:10:21/00:22:22, 0.532s/it]: train_loss_raw=0.6025, running_loss=0.5827, LR=0.000100
[2025-08-10 21:57:51,102][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071328] [Batch 01180/03692] [00:10:27/00:22:16, 0.532s/it]: train_loss_raw=0.4854, running_loss=0.5795, LR=0.000100
[2025-08-10 21:57:57,515][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071340] [Batch 01192/03692] [00:10:34/00:22:09, 0.532s/it]: train_loss_raw=0.6234, running_loss=0.5835, LR=0.000100
[2025-08-10 21:58:03,975][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071352] [Batch 01204/03692] [00:10:40/00:22:03, 0.532s/it]: train_loss_raw=0.5520, running_loss=0.5853, LR=0.000100
[2025-08-10 21:58:10,538][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071364] [Batch 01216/03692] [00:10:47/00:21:57, 0.532s/it]: train_loss_raw=0.6280, running_loss=0.5869, LR=0.000100
[2025-08-10 21:58:16,966][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071376] [Batch 01228/03692] [00:10:53/00:21:51, 0.532s/it]: train_loss_raw=0.7285, running_loss=0.5875, LR=0.000100
[2025-08-10 21:58:23,435][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071388] [Batch 01240/03692] [00:11:00/00:21:45, 0.532s/it]: train_loss_raw=0.5960, running_loss=0.5880, LR=0.000100
[2025-08-10 21:58:29,805][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071400] [Batch 01252/03692] [00:11:06/00:21:38, 0.532s/it]: train_loss_raw=0.6716, running_loss=0.5879, LR=0.000100
[2025-08-10 21:58:36,254][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071412] [Batch 01264/03692] [00:11:12/00:21:32, 0.532s/it]: train_loss_raw=0.4802, running_loss=0.5853, LR=0.000100
[2025-08-10 21:58:42,646][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071424] [Batch 01276/03692] [00:11:19/00:21:26, 0.532s/it]: train_loss_raw=0.6726, running_loss=0.5900, LR=0.000100
[2025-08-10 21:58:49,030][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071436] [Batch 01288/03692] [00:11:25/00:21:19, 0.532s/it]: train_loss_raw=0.5134, running_loss=0.5887, LR=0.000100
[2025-08-10 21:58:55,515][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071448] [Batch 01300/03692] [00:11:32/00:21:13, 0.532s/it]: train_loss_raw=0.6070, running_loss=0.5888, LR=0.000100
[2025-08-10 21:59:02,077][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071460] [Batch 01312/03692] [00:11:38/00:21:07, 0.533s/it]: train_loss_raw=0.6535, running_loss=0.5886, LR=0.000100
[2025-08-10 21:59:08,486][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071472] [Batch 01324/03692] [00:11:45/00:21:01, 0.533s/it]: train_loss_raw=0.4541, running_loss=0.5867, LR=0.000100
[2025-08-10 21:59:14,962][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071484] [Batch 01336/03692] [00:11:51/00:20:54, 0.533s/it]: train_loss_raw=0.6517, running_loss=0.5908, LR=0.000100
[2025-08-10 21:59:21,448][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071496] [Batch 01348/03692] [00:11:58/00:20:48, 0.533s/it]: train_loss_raw=0.4705, running_loss=0.5866, LR=0.000100
[2025-08-10 21:59:28,017][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071508] [Batch 01360/03692] [00:12:04/00:20:42, 0.533s/it]: train_loss_raw=0.6787, running_loss=0.5894, LR=0.000100
[2025-08-10 21:59:34,499][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071520] [Batch 01372/03692] [00:12:11/00:20:36, 0.533s/it]: train_loss_raw=0.4442, running_loss=0.5892, LR=0.000100
[2025-08-10 21:59:40,956][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071532] [Batch 01384/03692] [00:12:17/00:20:29, 0.533s/it]: train_loss_raw=0.6006, running_loss=0.5905, LR=0.000100
[2025-08-10 21:59:47,338][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071544] [Batch 01396/03692] [00:12:23/00:20:23, 0.533s/it]: train_loss_raw=0.5765, running_loss=0.5867, LR=0.000100
[2025-08-10 21:59:53,715][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071556] [Batch 01408/03692] [00:12:30/00:20:17, 0.533s/it]: train_loss_raw=0.5595, running_loss=0.5867, LR=0.000100
[2025-08-10 22:00:00,075][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071568] [Batch 01420/03692] [00:12:36/00:20:10, 0.533s/it]: train_loss_raw=0.6540, running_loss=0.5870, LR=0.000100
[2025-08-10 22:00:06,435][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071580] [Batch 01432/03692] [00:12:43/00:20:04, 0.533s/it]: train_loss_raw=0.6010, running_loss=0.5890, LR=0.000100
[2025-08-10 22:00:12,896][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071592] [Batch 01444/03692] [00:12:49/00:19:57, 0.533s/it]: train_loss_raw=0.6914, running_loss=0.5899, LR=0.000100
[2025-08-10 22:00:19,485][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071604] [Batch 01456/03692] [00:12:56/00:19:51, 0.533s/it]: train_loss_raw=0.6372, running_loss=0.5903, LR=0.000100
[2025-08-10 22:00:25,821][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071616] [Batch 01468/03692] [00:13:02/00:19:45, 0.533s/it]: train_loss_raw=0.5010, running_loss=0.5864, LR=0.000100
[2025-08-10 22:00:32,389][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071628] [Batch 01480/03692] [00:13:09/00:19:39, 0.533s/it]: train_loss_raw=0.6041, running_loss=0.5889, LR=0.000100
[2025-08-10 22:00:38,829][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071640] [Batch 01492/03692] [00:13:15/00:19:32, 0.533s/it]: train_loss_raw=0.7007, running_loss=0.5882, LR=0.000100
[2025-08-10 22:00:45,402][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071652] [Batch 01504/03692] [00:13:22/00:19:26, 0.533s/it]: train_loss_raw=0.6676, running_loss=0.5879, LR=0.000100
[2025-08-10 22:00:51,982][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071664] [Batch 01516/03692] [00:13:28/00:19:20, 0.533s/it]: train_loss_raw=0.5230, running_loss=0.5851, LR=0.000100
[2025-08-10 22:00:58,661][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071676] [Batch 01528/03692] [00:13:35/00:19:14, 0.534s/it]: train_loss_raw=0.6721, running_loss=0.5850, LR=0.000100
[2025-08-10 22:01:05,577][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071688] [Batch 01540/03692] [00:13:42/00:19:08, 0.534s/it]: train_loss_raw=0.5841, running_loss=0.5838, LR=0.000100
[2025-08-10 22:01:12,073][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071700] [Batch 01552/03692] [00:13:48/00:19:02, 0.534s/it]: train_loss_raw=0.6307, running_loss=0.5845, LR=0.000100
[2025-08-10 22:01:18,354][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071712] [Batch 01564/03692] [00:13:54/00:18:56, 0.534s/it]: train_loss_raw=0.6203, running_loss=0.5816, LR=0.000100
[2025-08-10 22:01:24,788][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071724] [Batch 01576/03692] [00:14:01/00:18:49, 0.534s/it]: train_loss_raw=0.5666, running_loss=0.5808, LR=0.000100
[2025-08-10 22:01:31,528][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071736] [Batch 01588/03692] [00:14:08/00:18:43, 0.534s/it]: train_loss_raw=0.5903, running_loss=0.5830, LR=0.000100
[2025-08-10 22:01:38,316][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071748] [Batch 01600/03692] [00:14:14/00:18:37, 0.534s/it]: train_loss_raw=0.5509, running_loss=0.5781, LR=0.000100
[2025-08-10 22:01:45,013][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071760] [Batch 01612/03692] [00:14:21/00:18:31, 0.535s/it]: train_loss_raw=0.4999, running_loss=0.5767, LR=0.000100
[2025-08-10 22:01:51,088][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071772] [Batch 01624/03692] [00:14:27/00:18:24, 0.534s/it]: train_loss_raw=0.5881, running_loss=0.5748, LR=0.000100
[2025-08-10 22:01:57,153][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071784] [Batch 01636/03692] [00:14:33/00:18:18, 0.534s/it]: train_loss_raw=0.5580, running_loss=0.5800, LR=0.000100
[2025-08-10 22:02:03,181][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071796] [Batch 01648/03692] [00:14:39/00:18:11, 0.534s/it]: train_loss_raw=0.5480, running_loss=0.5793, LR=0.000100
[2025-08-10 22:02:09,297][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071808] [Batch 01660/03692] [00:14:45/00:18:04, 0.534s/it]: train_loss_raw=0.5818, running_loss=0.5758, LR=0.000100
[2025-08-10 22:02:15,329][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071820] [Batch 01672/03692] [00:14:51/00:17:57, 0.533s/it]: train_loss_raw=0.6560, running_loss=0.5782, LR=0.000100
[2025-08-10 22:02:21,408][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071832] [Batch 01684/03692] [00:14:58/00:17:50, 0.533s/it]: train_loss_raw=0.6480, running_loss=0.5778, LR=0.000100
[2025-08-10 22:02:27,515][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071844] [Batch 01696/03692] [00:15:04/00:17:44, 0.533s/it]: train_loss_raw=0.5283, running_loss=0.5781, LR=0.000100
[2025-08-10 22:02:33,505][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071856] [Batch 01708/03692] [00:15:10/00:17:37, 0.533s/it]: train_loss_raw=0.5241, running_loss=0.5796, LR=0.000100
[2025-08-10 22:02:39,664][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071868] [Batch 01720/03692] [00:15:16/00:17:30, 0.533s/it]: train_loss_raw=0.6643, running_loss=0.5829, LR=0.000100
[2025-08-10 22:02:45,629][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071880] [Batch 01732/03692] [00:15:22/00:17:23, 0.532s/it]: train_loss_raw=0.6487, running_loss=0.5838, LR=0.000100
[2025-08-10 22:02:52,067][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071892] [Batch 01744/03692] [00:15:28/00:17:17, 0.533s/it]: train_loss_raw=0.6856, running_loss=0.5858, LR=0.000100
[2025-08-10 22:02:58,552][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071904] [Batch 01756/03692] [00:15:35/00:17:11, 0.533s/it]: train_loss_raw=0.5906, running_loss=0.5841, LR=0.000100
[2025-08-10 22:03:04,631][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071916] [Batch 01768/03692] [00:15:41/00:17:04, 0.532s/it]: train_loss_raw=0.6627, running_loss=0.5845, LR=0.000100
[2025-08-10 22:03:10,663][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071928] [Batch 01780/03692] [00:15:47/00:16:57, 0.532s/it]: train_loss_raw=0.6112, running_loss=0.5824, LR=0.000100
[2025-08-10 22:03:16,834][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071940] [Batch 01792/03692] [00:15:53/00:16:50, 0.532s/it]: train_loss_raw=0.6928, running_loss=0.5855, LR=0.000100
[2025-08-10 22:03:22,882][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071952] [Batch 01804/03692] [00:15:59/00:16:44, 0.532s/it]: train_loss_raw=0.6635, running_loss=0.5869, LR=0.000100
[2025-08-10 22:03:28,969][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071964] [Batch 01816/03692] [00:16:05/00:16:37, 0.532s/it]: train_loss_raw=0.4998, running_loss=0.5831, LR=0.000100
[2025-08-10 22:03:35,091][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071976] [Batch 01828/03692] [00:16:11/00:16:30, 0.532s/it]: train_loss_raw=0.6264, running_loss=0.5813, LR=0.000100
[2025-08-10 22:03:41,105][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071988] [Batch 01840/03692] [00:16:17/00:16:24, 0.531s/it]: train_loss_raw=0.6354, running_loss=0.5793, LR=0.000100
[2025-08-10 22:03:47,134][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072000] [Batch 01852/03692] [00:16:23/00:16:17, 0.531s/it]: train_loss_raw=0.5091, running_loss=0.5784, LR=0.000100
[2025-08-10 22:03:57,624][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072012] [Batch 01864/03692] [00:16:34/00:16:15, 0.533s/it]: train_loss_raw=0.5788, running_loss=0.5785, LR=0.000100
[2025-08-10 22:04:03,967][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072024] [Batch 01876/03692] [00:16:40/00:16:08, 0.533s/it]: train_loss_raw=0.6197, running_loss=0.5753, LR=0.000100
[2025-08-10 22:04:10,026][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072036] [Batch 01888/03692] [00:16:46/00:16:01, 0.533s/it]: train_loss_raw=0.6316, running_loss=0.5767, LR=0.000100
[2025-08-10 22:04:16,227][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072048] [Batch 01900/03692] [00:16:52/00:15:55, 0.533s/it]: train_loss_raw=0.6075, running_loss=0.5774, LR=0.000100
[2025-08-10 22:04:22,269][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072060] [Batch 01912/03692] [00:16:58/00:15:48, 0.533s/it]: train_loss_raw=0.5122, running_loss=0.5747, LR=0.000100
[2025-08-10 22:04:28,374][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072072] [Batch 01924/03692] [00:17:04/00:15:41, 0.533s/it]: train_loss_raw=0.5105, running_loss=0.5750, LR=0.000100
[2025-08-10 22:04:34,494][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072084] [Batch 01936/03692] [00:17:11/00:15:35, 0.533s/it]: train_loss_raw=0.5782, running_loss=0.5707, LR=0.000100
[2025-08-10 22:04:40,600][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072096] [Batch 01948/03692] [00:17:17/00:15:28, 0.532s/it]: train_loss_raw=0.5619, running_loss=0.5704, LR=0.000100
[2025-08-10 22:04:46,669][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072108] [Batch 01960/03692] [00:17:23/00:15:21, 0.532s/it]: train_loss_raw=0.6385, running_loss=0.5701, LR=0.000100
[2025-08-10 22:04:52,811][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072120] [Batch 01972/03692] [00:17:29/00:15:15, 0.532s/it]: train_loss_raw=0.6416, running_loss=0.5741, LR=0.000100
[2025-08-10 22:04:58,909][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072132] [Batch 01984/03692] [00:17:35/00:15:08, 0.532s/it]: train_loss_raw=0.6212, running_loss=0.5711, LR=0.000100
[2025-08-10 22:05:04,977][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072144] [Batch 01996/03692] [00:17:41/00:15:02, 0.532s/it]: train_loss_raw=0.5795, running_loss=0.5710, LR=0.000100
[2025-08-10 22:05:11,014][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072156] [Batch 02008/03692] [00:17:47/00:14:55, 0.532s/it]: train_loss_raw=0.6167, running_loss=0.5737, LR=0.000100
[2025-08-10 22:05:17,305][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072168] [Batch 02020/03692] [00:17:53/00:14:48, 0.532s/it]: train_loss_raw=0.6521, running_loss=0.5715, LR=0.000100
[2025-08-10 22:05:23,827][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072180] [Batch 02032/03692] [00:18:00/00:14:42, 0.532s/it]: train_loss_raw=0.6168, running_loss=0.5739, LR=0.000100
[2025-08-10 22:05:30,351][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072192] [Batch 02044/03692] [00:18:06/00:14:36, 0.532s/it]: train_loss_raw=0.5531, running_loss=0.5726, LR=0.000100
[2025-08-10 22:05:36,514][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072204] [Batch 02056/03692] [00:18:13/00:14:29, 0.532s/it]: train_loss_raw=0.6576, running_loss=0.5760, LR=0.000100
[2025-08-10 22:05:42,615][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072216] [Batch 02068/03692] [00:18:19/00:14:23, 0.532s/it]: train_loss_raw=0.5133, running_loss=0.5745, LR=0.000100
[2025-08-10 22:05:48,979][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072228] [Batch 02080/03692] [00:18:25/00:14:16, 0.532s/it]: train_loss_raw=0.5996, running_loss=0.5713, LR=0.000100
[2025-08-10 22:05:55,542][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072240] [Batch 02092/03692] [00:18:32/00:14:10, 0.532s/it]: train_loss_raw=0.4345, running_loss=0.5668, LR=0.000100
[2025-08-10 22:06:02,114][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072252] [Batch 02104/03692] [00:18:38/00:14:04, 0.532s/it]: train_loss_raw=0.5664, running_loss=0.5675, LR=0.000100
[2025-08-10 22:06:08,518][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072264] [Batch 02116/03692] [00:18:45/00:13:57, 0.532s/it]: train_loss_raw=0.4350, running_loss=0.5665, LR=0.000100
[2025-08-10 22:06:14,980][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072276] [Batch 02128/03692] [00:18:51/00:13:51, 0.532s/it]: train_loss_raw=0.6353, running_loss=0.5720, LR=0.000100
[2025-08-10 22:06:21,535][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072288] [Batch 02140/03692] [00:18:58/00:13:45, 0.532s/it]: train_loss_raw=0.6332, running_loss=0.5758, LR=0.000100
[2025-08-10 22:06:27,979][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072300] [Batch 02152/03692] [00:19:04/00:13:39, 0.532s/it]: train_loss_raw=0.5422, running_loss=0.5777, LR=0.000100
[2025-08-10 22:06:41,028][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072312] [Batch 02164/03692] [00:19:17/00:13:37, 0.535s/it]: train_loss_raw=0.5949, running_loss=0.5755, LR=0.000100
[2025-08-10 22:06:47,461][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072324] [Batch 02176/03692] [00:19:24/00:13:31, 0.535s/it]: train_loss_raw=0.5105, running_loss=0.5761, LR=0.000100
[2025-08-10 22:06:53,867][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072336] [Batch 02188/03692] [00:19:30/00:13:24, 0.535s/it]: train_loss_raw=0.5517, running_loss=0.5782, LR=0.000100
[2025-08-10 22:07:00,250][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072348] [Batch 02200/03692] [00:19:36/00:13:18, 0.535s/it]: train_loss_raw=0.5227, running_loss=0.5733, LR=0.000100
[2025-08-10 22:07:06,700][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072360] [Batch 02212/03692] [00:19:43/00:13:11, 0.535s/it]: train_loss_raw=0.6165, running_loss=0.5723, LR=0.000100
[2025-08-10 22:07:13,399][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072372] [Batch 02224/03692] [00:19:50/00:13:05, 0.535s/it]: train_loss_raw=0.6348, running_loss=0.5693, LR=0.000100
[2025-08-10 22:07:19,998][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072384] [Batch 02236/03692] [00:19:56/00:12:59, 0.535s/it]: train_loss_raw=0.5115, running_loss=0.5721, LR=0.000100
[2025-08-10 22:07:26,399][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072396] [Batch 02248/03692] [00:20:03/00:12:52, 0.535s/it]: train_loss_raw=0.5282, running_loss=0.5707, LR=0.000100
[2025-08-10 22:07:32,968][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072408] [Batch 02260/03692] [00:20:09/00:12:46, 0.535s/it]: train_loss_raw=0.5002, running_loss=0.5711, LR=0.000100
[2025-08-10 22:07:39,386][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072420] [Batch 02272/03692] [00:20:15/00:12:39, 0.535s/it]: train_loss_raw=0.6420, running_loss=0.5731, LR=0.000100
[2025-08-10 22:07:45,776][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072432] [Batch 02284/03692] [00:20:22/00:12:33, 0.535s/it]: train_loss_raw=0.4905, running_loss=0.5689, LR=0.000100
[2025-08-10 22:07:52,168][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072444] [Batch 02296/03692] [00:20:28/00:12:27, 0.535s/it]: train_loss_raw=0.6016, running_loss=0.5708, LR=0.000100
[2025-08-10 22:07:58,423][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072456] [Batch 02308/03692] [00:20:35/00:12:20, 0.535s/it]: train_loss_raw=0.6117, running_loss=0.5728, LR=0.000100
[2025-08-10 22:08:04,690][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072468] [Batch 02320/03692] [00:20:41/00:12:14, 0.535s/it]: train_loss_raw=0.6555, running_loss=0.5701, LR=0.000100
[2025-08-10 22:08:11,120][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072480] [Batch 02332/03692] [00:20:47/00:12:07, 0.535s/it]: train_loss_raw=0.5600, running_loss=0.5686, LR=0.000100
[2025-08-10 22:08:17,499][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072492] [Batch 02344/03692] [00:20:54/00:12:01, 0.535s/it]: train_loss_raw=0.5794, running_loss=0.5661, LR=0.000100
[2025-08-10 22:08:23,920][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072504] [Batch 02356/03692] [00:21:00/00:11:54, 0.535s/it]: train_loss_raw=0.4843, running_loss=0.5663, LR=0.000100
[2025-08-10 22:08:30,373][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072516] [Batch 02368/03692] [00:21:06/00:11:48, 0.535s/it]: train_loss_raw=0.6620, running_loss=0.5639, LR=0.000100
[2025-08-10 22:08:36,810][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072528] [Batch 02380/03692] [00:21:13/00:11:41, 0.535s/it]: train_loss_raw=0.6782, running_loss=0.5645, LR=0.000100
[2025-08-10 22:08:43,301][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072540] [Batch 02392/03692] [00:21:19/00:11:35, 0.535s/it]: train_loss_raw=0.4761, running_loss=0.5633, LR=0.000100
[2025-08-10 22:08:49,573][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072552] [Batch 02404/03692] [00:21:26/00:11:29, 0.535s/it]: train_loss_raw=0.4956, running_loss=0.5603, LR=0.000100
[2025-08-10 22:08:55,624][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072564] [Batch 02416/03692] [00:21:32/00:11:22, 0.535s/it]: train_loss_raw=0.5112, running_loss=0.5590, LR=0.000100
[2025-08-10 22:09:01,719][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072576] [Batch 02428/03692] [00:21:38/00:11:15, 0.535s/it]: train_loss_raw=0.5008, running_loss=0.5612, LR=0.000100
[2025-08-10 22:09:07,809][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072588] [Batch 02440/03692] [00:21:44/00:11:09, 0.535s/it]: train_loss_raw=0.5212, running_loss=0.5593, LR=0.000100
[2025-08-10 22:09:14,039][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072600] [Batch 02452/03692] [00:21:50/00:11:02, 0.535s/it]: train_loss_raw=0.5613, running_loss=0.5586, LR=0.000100
[2025-08-10 22:09:20,449][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072612] [Batch 02464/03692] [00:21:57/00:10:56, 0.535s/it]: train_loss_raw=0.4537, running_loss=0.5582, LR=0.000100
[2025-08-10 22:09:27,042][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072624] [Batch 02476/03692] [00:22:03/00:10:50, 0.535s/it]: train_loss_raw=0.6922, running_loss=0.5612, LR=0.000100
[2025-08-10 22:09:33,720][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072636] [Batch 02488/03692] [00:22:10/00:10:43, 0.535s/it]: train_loss_raw=0.6536, running_loss=0.5657, LR=0.000100
[2025-08-10 22:09:40,391][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072648] [Batch 02500/03692] [00:22:17/00:10:37, 0.535s/it]: train_loss_raw=0.4334, running_loss=0.5644, LR=0.000100
[2025-08-10 22:09:46,802][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072660] [Batch 02512/03692] [00:22:23/00:10:31, 0.535s/it]: train_loss_raw=0.6193, running_loss=0.5659, LR=0.000100
[2025-08-10 22:09:53,143][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072672] [Batch 02524/03692] [00:22:29/00:10:24, 0.535s/it]: train_loss_raw=0.6385, running_loss=0.5651, LR=0.000100
[2025-08-10 22:09:59,759][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072684] [Batch 02536/03692] [00:22:36/00:10:18, 0.535s/it]: train_loss_raw=0.5153, running_loss=0.5659, LR=0.000100
[2025-08-10 22:10:06,339][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072696] [Batch 02548/03692] [00:22:42/00:10:11, 0.535s/it]: train_loss_raw=0.6615, running_loss=0.5650, LR=0.000100
[2025-08-10 22:10:13,038][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072708] [Batch 02560/03692] [00:22:49/00:10:05, 0.535s/it]: train_loss_raw=0.5509, running_loss=0.5632, LR=0.000100
[2025-08-10 22:10:19,703][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072720] [Batch 02572/03692] [00:22:56/00:09:59, 0.535s/it]: train_loss_raw=0.6842, running_loss=0.5682, LR=0.000100
[2025-08-10 22:10:26,283][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072732] [Batch 02584/03692] [00:23:02/00:09:52, 0.535s/it]: train_loss_raw=0.4655, running_loss=0.5689, LR=0.000100
[2025-08-10 22:10:32,818][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072744] [Batch 02596/03692] [00:23:09/00:09:46, 0.535s/it]: train_loss_raw=0.5307, running_loss=0.5668, LR=0.000100
[2025-08-10 22:10:39,364][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072756] [Batch 02608/03692] [00:23:15/00:09:40, 0.535s/it]: train_loss_raw=0.5343, running_loss=0.5656, LR=0.000100
[2025-08-10 22:10:46,022][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072768] [Batch 02620/03692] [00:23:22/00:09:33, 0.535s/it]: train_loss_raw=0.6803, running_loss=0.5658, LR=0.000100
[2025-08-10 22:10:52,112][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072780] [Batch 02632/03692] [00:23:28/00:09:27, 0.535s/it]: train_loss_raw=0.5192, running_loss=0.5641, LR=0.000100
[2025-08-10 22:10:58,426][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072792] [Batch 02644/03692] [00:23:35/00:09:20, 0.535s/it]: train_loss_raw=0.5795, running_loss=0.5657, LR=0.000100
[2025-08-10 22:11:05,068][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072804] [Batch 02656/03692] [00:23:41/00:09:14, 0.535s/it]: train_loss_raw=0.5376, running_loss=0.5648, LR=0.000100
[2025-08-10 22:11:11,794][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072816] [Batch 02668/03692] [00:23:48/00:09:08, 0.535s/it]: train_loss_raw=0.4641, running_loss=0.5618, LR=0.000100
[2025-08-10 22:11:18,518][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072828] [Batch 02680/03692] [00:23:55/00:09:01, 0.535s/it]: train_loss_raw=0.6510, running_loss=0.5643, LR=0.000100
[2025-08-10 22:11:25,183][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072840] [Batch 02692/03692] [00:24:01/00:08:55, 0.536s/it]: train_loss_raw=0.5351, running_loss=0.5649, LR=0.000100
[2025-08-10 22:11:31,675][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072852] [Batch 02704/03692] [00:24:08/00:08:49, 0.536s/it]: train_loss_raw=0.5584, running_loss=0.5645, LR=0.000100
[2025-08-10 22:11:38,222][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072864] [Batch 02716/03692] [00:24:14/00:08:42, 0.536s/it]: train_loss_raw=0.4588, running_loss=0.5608, LR=0.000100
[2025-08-10 22:11:44,582][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072876] [Batch 02728/03692] [00:24:21/00:08:36, 0.536s/it]: train_loss_raw=0.5451, running_loss=0.5623, LR=0.000100
[2025-08-10 22:11:50,985][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072888] [Batch 02740/03692] [00:24:27/00:08:29, 0.536s/it]: train_loss_raw=0.6293, running_loss=0.5605, LR=0.000100
[2025-08-10 22:11:57,380][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072900] [Batch 02752/03692] [00:24:33/00:08:23, 0.536s/it]: train_loss_raw=0.5272, running_loss=0.5624, LR=0.000100
[2025-08-10 22:12:04,035][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072912] [Batch 02764/03692] [00:24:40/00:08:17, 0.536s/it]: train_loss_raw=0.6277, running_loss=0.5652, LR=0.000100
[2025-08-10 22:12:10,258][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072924] [Batch 02776/03692] [00:24:46/00:08:10, 0.536s/it]: train_loss_raw=0.6280, running_loss=0.5651, LR=0.000100
[2025-08-10 22:12:16,445][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072936] [Batch 02788/03692] [00:24:53/00:08:04, 0.536s/it]: train_loss_raw=0.5739, running_loss=0.5655, LR=0.000100
[2025-08-10 22:12:22,613][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072948] [Batch 02800/03692] [00:24:59/00:07:57, 0.535s/it]: train_loss_raw=0.5344, running_loss=0.5661, LR=0.000100
[2025-08-10 22:12:28,812][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072960] [Batch 02812/03692] [00:25:05/00:07:51, 0.535s/it]: train_loss_raw=0.4756, running_loss=0.5635, LR=0.000100
[2025-08-10 22:12:35,125][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072972] [Batch 02824/03692] [00:25:11/00:07:44, 0.535s/it]: train_loss_raw=0.6452, running_loss=0.5676, LR=0.000100
[2025-08-10 22:12:41,383][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072984] [Batch 02836/03692] [00:25:17/00:07:38, 0.535s/it]: train_loss_raw=0.6122, running_loss=0.5687, LR=0.000100
[2025-08-10 22:12:47,849][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072996] [Batch 02848/03692] [00:25:24/00:07:31, 0.535s/it]: train_loss_raw=0.5316, running_loss=0.5666, LR=0.000100
[2025-08-10 22:12:54,518][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073008] [Batch 02860/03692] [00:25:31/00:07:25, 0.535s/it]: train_loss_raw=0.5494, running_loss=0.5664, LR=0.000100
[2025-08-10 22:13:00,815][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073020] [Batch 02872/03692] [00:25:37/00:07:18, 0.535s/it]: train_loss_raw=0.5584, running_loss=0.5659, LR=0.000100
[2025-08-10 22:13:07,018][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073032] [Batch 02884/03692] [00:25:43/00:07:12, 0.535s/it]: train_loss_raw=0.5241, running_loss=0.5629, LR=0.000100
[2025-08-10 22:13:13,266][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073044] [Batch 02896/03692] [00:25:49/00:07:06, 0.535s/it]: train_loss_raw=0.5661, running_loss=0.5649, LR=0.000100
[2025-08-10 22:13:19,715][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073056] [Batch 02908/03692] [00:25:56/00:06:59, 0.535s/it]: train_loss_raw=0.4221, running_loss=0.5695, LR=0.000100
[2025-08-10 22:13:26,053][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073068] [Batch 02920/03692] [00:26:02/00:06:53, 0.535s/it]: train_loss_raw=0.5263, running_loss=0.5676, LR=0.000100
[2025-08-10 22:13:32,523][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073080] [Batch 02932/03692] [00:26:09/00:06:46, 0.535s/it]: train_loss_raw=0.5974, running_loss=0.5656, LR=0.000100
[2025-08-10 22:13:39,064][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073092] [Batch 02944/03692] [00:26:15/00:06:40, 0.535s/it]: train_loss_raw=0.6032, running_loss=0.5683, LR=0.000100
[2025-08-10 22:13:45,574][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073104] [Batch 02956/03692] [00:26:22/00:06:33, 0.535s/it]: train_loss_raw=0.6948, running_loss=0.5681, LR=0.000100
[2025-08-10 22:13:52,024][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073116] [Batch 02968/03692] [00:26:28/00:06:27, 0.535s/it]: train_loss_raw=0.4702, running_loss=0.5676, LR=0.000100
[2025-08-10 22:13:58,464][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073128] [Batch 02980/03692] [00:26:35/00:06:21, 0.535s/it]: train_loss_raw=0.5356, running_loss=0.5646, LR=0.000100
[2025-08-10 22:14:04,884][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073140] [Batch 02992/03692] [00:26:41/00:06:14, 0.535s/it]: train_loss_raw=0.5904, running_loss=0.5629, LR=0.000100
[2025-08-10 22:14:11,331][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073152] [Batch 03004/03692] [00:26:47/00:06:08, 0.535s/it]: train_loss_raw=0.6179, running_loss=0.5621, LR=0.000100
[2025-08-10 22:14:17,881][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073164] [Batch 03016/03692] [00:26:54/00:06:01, 0.535s/it]: train_loss_raw=0.4627, running_loss=0.5606, LR=0.000100
[2025-08-10 22:14:24,458][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073176] [Batch 03028/03692] [00:27:01/00:05:55, 0.535s/it]: train_loss_raw=0.7182, running_loss=0.5651, LR=0.000100
[2025-08-10 22:14:30,834][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073188] [Batch 03040/03692] [00:27:07/00:05:49, 0.535s/it]: train_loss_raw=0.6151, running_loss=0.5637, LR=0.000100
[2025-08-10 22:14:37,248][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073200] [Batch 03052/03692] [00:27:13/00:05:42, 0.535s/it]: train_loss_raw=0.6161, running_loss=0.5648, LR=0.000100
[2025-08-10 22:14:43,693][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073212] [Batch 03064/03692] [00:27:20/00:05:36, 0.535s/it]: train_loss_raw=0.5498, running_loss=0.5658, LR=0.000100
[2025-08-10 22:14:50,132][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073224] [Batch 03076/03692] [00:27:26/00:05:29, 0.535s/it]: train_loss_raw=0.5236, running_loss=0.5622, LR=0.000100
[2025-08-10 22:14:56,568][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073236] [Batch 03088/03692] [00:27:33/00:05:23, 0.535s/it]: train_loss_raw=0.5718, running_loss=0.5610, LR=0.000100
[2025-08-10 22:15:03,039][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073248] [Batch 03100/03692] [00:27:39/00:05:16, 0.535s/it]: train_loss_raw=0.4560, running_loss=0.5607, LR=0.000100
[2025-08-10 22:15:09,532][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073260] [Batch 03112/03692] [00:27:46/00:05:10, 0.535s/it]: train_loss_raw=0.5716, running_loss=0.5597, LR=0.000100
[2025-08-10 22:15:15,931][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073272] [Batch 03124/03692] [00:27:52/00:05:04, 0.535s/it]: train_loss_raw=0.5363, running_loss=0.5595, LR=0.000100
[2025-08-10 22:15:22,245][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073284] [Batch 03136/03692] [00:27:58/00:04:57, 0.535s/it]: train_loss_raw=0.5309, running_loss=0.5626, LR=0.000100
[2025-08-10 22:15:28,630][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073296] [Batch 03148/03692] [00:28:05/00:04:51, 0.535s/it]: train_loss_raw=0.5679, running_loss=0.5646, LR=0.000100
[2025-08-10 22:15:35,072][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073308] [Batch 03160/03692] [00:28:11/00:04:44, 0.535s/it]: train_loss_raw=0.5679, running_loss=0.5655, LR=0.000100
[2025-08-10 22:15:41,479][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073320] [Batch 03172/03692] [00:28:18/00:04:38, 0.535s/it]: train_loss_raw=0.6126, running_loss=0.5635, LR=0.000100
[2025-08-10 22:15:47,820][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073332] [Batch 03184/03692] [00:28:24/00:04:31, 0.535s/it]: train_loss_raw=0.4902, running_loss=0.5633, LR=0.000100
[2025-08-10 22:15:54,242][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073344] [Batch 03196/03692] [00:28:30/00:04:25, 0.535s/it]: train_loss_raw=0.5760, running_loss=0.5586, LR=0.000100
[2025-08-10 22:16:00,744][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073356] [Batch 03208/03692] [00:28:37/00:04:19, 0.535s/it]: train_loss_raw=0.4900, running_loss=0.5583, LR=0.000100
[2025-08-10 22:16:07,057][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073368] [Batch 03220/03692] [00:28:43/00:04:12, 0.535s/it]: train_loss_raw=0.5886, running_loss=0.5578, LR=0.000100
[2025-08-10 22:16:13,537][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073380] [Batch 03232/03692] [00:28:50/00:04:06, 0.535s/it]: train_loss_raw=0.5958, running_loss=0.5580, LR=0.000100
[2025-08-10 22:16:19,915][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073392] [Batch 03244/03692] [00:28:56/00:03:59, 0.535s/it]: train_loss_raw=0.5386, running_loss=0.5583, LR=0.000100
[2025-08-10 22:16:26,452][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073404] [Batch 03256/03692] [00:29:03/00:03:53, 0.535s/it]: train_loss_raw=0.4837, running_loss=0.5586, LR=0.000100
[2025-08-10 22:16:32,980][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073416] [Batch 03268/03692] [00:29:09/00:03:46, 0.535s/it]: train_loss_raw=0.5251, running_loss=0.5589, LR=0.000100
[2025-08-10 22:16:39,554][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073428] [Batch 03280/03692] [00:29:16/00:03:40, 0.535s/it]: train_loss_raw=0.5369, running_loss=0.5629, LR=0.000100
[2025-08-10 22:16:46,131][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073440] [Batch 03292/03692] [00:29:22/00:03:34, 0.535s/it]: train_loss_raw=0.6080, running_loss=0.5642, LR=0.000100
[2025-08-10 22:16:52,655][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073452] [Batch 03304/03692] [00:29:29/00:03:27, 0.535s/it]: train_loss_raw=0.5934, running_loss=0.5630, LR=0.000100
[2025-08-10 22:16:59,190][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073464] [Batch 03316/03692] [00:29:35/00:03:21, 0.536s/it]: train_loss_raw=0.5275, running_loss=0.5644, LR=0.000100
[2025-08-10 22:17:05,264][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073476] [Batch 03328/03692] [00:29:41/00:03:14, 0.535s/it]: train_loss_raw=0.5244, running_loss=0.5636, LR=0.000100
[2025-08-10 22:17:11,625][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073488] [Batch 03340/03692] [00:29:48/00:03:08, 0.535s/it]: train_loss_raw=0.4759, running_loss=0.5622, LR=0.000100
[2025-08-10 22:17:18,006][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073500] [Batch 03352/03692] [00:29:54/00:03:02, 0.535s/it]: train_loss_raw=0.5753, running_loss=0.5656, LR=0.000100
[2025-08-10 22:17:24,361][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073512] [Batch 03364/03692] [00:30:00/00:02:55, 0.535s/it]: train_loss_raw=0.5644, running_loss=0.5646, LR=0.000100
[2025-08-10 22:17:30,937][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073524] [Batch 03376/03692] [00:30:07/00:02:49, 0.535s/it]: train_loss_raw=0.5732, running_loss=0.5634, LR=0.000100
[2025-08-10 22:17:37,316][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073536] [Batch 03388/03692] [00:30:13/00:02:42, 0.535s/it]: train_loss_raw=0.4827, running_loss=0.5631, LR=0.000100
[2025-08-10 22:17:43,904][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073548] [Batch 03400/03692] [00:30:20/00:02:36, 0.535s/it]: train_loss_raw=0.6169, running_loss=0.5611, LR=0.000100
[2025-08-10 22:17:50,430][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073560] [Batch 03412/03692] [00:30:27/00:02:29, 0.535s/it]: train_loss_raw=0.5615, running_loss=0.5604, LR=0.000100
[2025-08-10 22:17:56,960][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073572] [Batch 03424/03692] [00:30:33/00:02:23, 0.536s/it]: train_loss_raw=0.5642, running_loss=0.5579, LR=0.000100
[2025-08-10 22:18:03,364][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073584] [Batch 03436/03692] [00:30:39/00:02:17, 0.535s/it]: train_loss_raw=0.6463, running_loss=0.5583, LR=0.000100
[2025-08-10 22:18:09,800][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073596] [Batch 03448/03692] [00:30:46/00:02:10, 0.536s/it]: train_loss_raw=0.4958, running_loss=0.5577, LR=0.000100
[2025-08-10 22:18:16,298][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073608] [Batch 03460/03692] [00:30:52/00:02:04, 0.536s/it]: train_loss_raw=0.4566, running_loss=0.5575, LR=0.000100
[2025-08-10 22:18:22,591][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073620] [Batch 03472/03692] [00:30:59/00:01:57, 0.535s/it]: train_loss_raw=0.5130, running_loss=0.5554, LR=0.000100
[2025-08-10 22:18:28,693][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073632] [Batch 03484/03692] [00:31:05/00:01:51, 0.535s/it]: train_loss_raw=0.5436, running_loss=0.5523, LR=0.000100
[2025-08-10 22:18:34,827][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073644] [Batch 03496/03692] [00:31:11/00:01:44, 0.535s/it]: train_loss_raw=0.6107, running_loss=0.5523, LR=0.000100
[2025-08-10 22:18:41,272][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073656] [Batch 03508/03692] [00:31:17/00:01:38, 0.535s/it]: train_loss_raw=0.6865, running_loss=0.5573, LR=0.000100
[2025-08-10 22:18:47,511][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073668] [Batch 03520/03692] [00:31:24/00:01:32, 0.535s/it]: train_loss_raw=0.5720, running_loss=0.5611, LR=0.000100
[2025-08-10 22:18:53,616][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073680] [Batch 03532/03692] [00:31:30/00:01:25, 0.535s/it]: train_loss_raw=0.5548, running_loss=0.5613, LR=0.000100
[2025-08-10 22:18:59,670][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073692] [Batch 03544/03692] [00:31:36/00:01:19, 0.535s/it]: train_loss_raw=0.5973, running_loss=0.5567, LR=0.000100
[2025-08-10 22:19:05,960][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073704] [Batch 03556/03692] [00:31:42/00:01:12, 0.535s/it]: train_loss_raw=0.7122, running_loss=0.5548, LR=0.000100
[2025-08-10 22:19:12,160][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073716] [Batch 03568/03692] [00:31:48/00:01:06, 0.535s/it]: train_loss_raw=0.5774, running_loss=0.5576, LR=0.000100
[2025-08-10 22:19:18,210][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073728] [Batch 03580/03692] [00:31:54/00:00:59, 0.535s/it]: train_loss_raw=0.6539, running_loss=0.5565, LR=0.000100
[2025-08-10 22:19:24,238][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073740] [Batch 03592/03692] [00:32:00/00:00:53, 0.535s/it]: train_loss_raw=0.5997, running_loss=0.5580, LR=0.000100
[2025-08-10 22:19:30,298][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073752] [Batch 03604/03692] [00:32:06/00:00:47, 0.535s/it]: train_loss_raw=0.5775, running_loss=0.5589, LR=0.000100
[2025-08-10 22:19:36,418][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073764] [Batch 03616/03692] [00:32:13/00:00:40, 0.535s/it]: train_loss_raw=0.6090, running_loss=0.5594, LR=0.000100
[2025-08-10 22:19:42,381][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073776] [Batch 03628/03692] [00:32:18/00:00:34, 0.534s/it]: train_loss_raw=0.5110, running_loss=0.5585, LR=0.000100
[2025-08-10 22:19:48,492][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073788] [Batch 03640/03692] [00:32:25/00:00:27, 0.534s/it]: train_loss_raw=0.5219, running_loss=0.5557, LR=0.000100
[2025-08-10 22:19:54,490][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073800] [Batch 03652/03692] [00:32:31/00:00:21, 0.534s/it]: train_loss_raw=0.6050, running_loss=0.5524, LR=0.000100
[2025-08-10 22:20:00,569][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073812] [Batch 03664/03692] [00:32:37/00:00:14, 0.534s/it]: train_loss_raw=0.5445, running_loss=0.5515, LR=0.000100
[2025-08-10 22:20:06,788][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073824] [Batch 03676/03692] [00:32:43/00:00:08, 0.534s/it]: train_loss_raw=0.4908, running_loss=0.5504, LR=0.000100
[2025-08-10 22:20:13,361][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073836] [Batch 03688/03692] [00:32:49/00:00:02, 0.534s/it]: train_loss_raw=0.5003, running_loss=0.5510, LR=0.000100
[2025-08-10 22:20:44,536][__main__][INFO] - [VALIDATION] [Epoch 19/29] Starting validation.
[2025-08-10 22:21:17,616][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 073841] [Batch 00011/00025] [00:00:33/00:00:35, 2.757s/it]
[2025-08-10 22:21:31,721][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 073841] [Batch 00023/00025] [00:00:47/00:00:01, 1.966s/it]
[2025-08-10 22:21:32,705][__main__][INFO] - [VALIDATION] [Epoch 19/29] train_loss=0.54972, valid_loss=0.61917
[2025-08-10 22:21:32,705][__main__][INFO] - [VALIDATION] [Epoch 19/29] Metrics:
[2025-08-10 22:21:32,706][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_er      0.263
[2025-08-10 22:21:32,706][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_prec    0.513
[2025-08-10 22:21:32,706][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_recall  0.517
[2025-08-10 22:21:32,706][__main__][INFO] - [VALIDATION] [Epoch 19/29] - pep_recall 0.498
[2025-08-10 22:21:32,708][__main__][INFO] - [TRAIN] [Epoch 19/29] Epoch complete, total time 11:25:31, remaining time 05:42:45, 00:34:16 per epoch
[2025-08-10 22:21:36,550][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073848] [Batch 00008/03692] [00:00:03/00:28:05, 0.458s/it]: train_loss_raw=0.5356, running_loss=0.5367, LR=0.000100
[2025-08-10 22:21:42,993][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073860] [Batch 00020/03692] [00:00:10/00:30:55, 0.505s/it]: train_loss_raw=0.5604, running_loss=0.5379, LR=0.000100
[2025-08-10 22:21:49,397][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073872] [Batch 00032/03692] [00:00:16/00:31:28, 0.516s/it]: train_loss_raw=0.6292, running_loss=0.5405, LR=0.000100
[2025-08-10 22:21:55,424][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073884] [Batch 00044/03692] [00:00:22/00:31:08, 0.512s/it]: train_loss_raw=0.5088, running_loss=0.5394, LR=0.000100
[2025-08-10 22:22:01,557][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073896] [Batch 00056/03692] [00:00:28/00:31:01, 0.512s/it]: train_loss_raw=0.4940, running_loss=0.5407, LR=0.000100
[2025-08-10 22:22:07,793][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073908] [Batch 00068/03692] [00:00:34/00:31:00, 0.513s/it]: train_loss_raw=0.5601, running_loss=0.5388, LR=0.000100
[2025-08-10 22:22:14,077][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073920] [Batch 00080/03692] [00:00:41/00:30:59, 0.515s/it]: train_loss_raw=0.4788, running_loss=0.5372, LR=0.000100
[2025-08-10 22:22:20,281][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073932] [Batch 00092/03692] [00:00:47/00:30:54, 0.515s/it]: train_loss_raw=0.4632, running_loss=0.5371, LR=0.000100
[2025-08-10 22:22:26,726][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073944] [Batch 00104/03692] [00:00:53/00:30:57, 0.518s/it]: train_loss_raw=0.5590, running_loss=0.5354, LR=0.000100
[2025-08-10 22:22:33,311][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073956] [Batch 00116/03692] [00:01:00/00:31:02, 0.521s/it]: train_loss_raw=0.4714, running_loss=0.5378, LR=0.000100
[2025-08-10 22:22:39,922][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073968] [Batch 00128/03692] [00:01:07/00:31:06, 0.524s/it]: train_loss_raw=0.6180, running_loss=0.5388, LR=0.000100
[2025-08-10 22:22:46,554][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073980] [Batch 00140/03692] [00:01:13/00:31:08, 0.526s/it]: train_loss_raw=0.5201, running_loss=0.5375, LR=0.000100
[2025-08-10 22:22:53,140][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073992] [Batch 00152/03692] [00:01:20/00:31:09, 0.528s/it]: train_loss_raw=0.5133, running_loss=0.5358, LR=0.000100
[2025-08-10 22:23:05,206][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074004] [Batch 00164/03692] [00:01:32/00:33:05, 0.563s/it]: train_loss_raw=0.4344, running_loss=0.5343, LR=0.000100
[2025-08-10 22:23:11,634][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074016] [Batch 00176/03692] [00:01:38/00:32:52, 0.561s/it]: train_loss_raw=0.5602, running_loss=0.5321, LR=0.000100
[2025-08-10 22:23:18,178][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074028] [Batch 00188/03692] [00:01:45/00:32:42, 0.560s/it]: train_loss_raw=0.4966, running_loss=0.5283, LR=0.000100
[2025-08-10 22:23:24,710][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074040] [Batch 00200/03692] [00:01:51/00:32:32, 0.559s/it]: train_loss_raw=0.4593, running_loss=0.5302, LR=0.000100
[2025-08-10 22:23:31,324][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074052] [Batch 00212/03692] [00:01:58/00:32:24, 0.559s/it]: train_loss_raw=0.4866, running_loss=0.5284, LR=0.000100
[2025-08-10 22:23:37,775][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074064] [Batch 00224/03692] [00:02:04/00:32:13, 0.558s/it]: train_loss_raw=0.6291, running_loss=0.5301, LR=0.000100
[2025-08-10 22:23:44,329][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074076] [Batch 00236/03692] [00:02:11/00:32:04, 0.557s/it]: train_loss_raw=0.5481, running_loss=0.5313, LR=0.000100
[2025-08-10 22:23:51,045][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074088] [Batch 00248/03692] [00:02:18/00:31:58, 0.557s/it]: train_loss_raw=0.4244, running_loss=0.5297, LR=0.000100
[2025-08-10 22:23:57,602][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074100] [Batch 00260/03692] [00:02:24/00:31:50, 0.557s/it]: train_loss_raw=0.4554, running_loss=0.5322, LR=0.000100
[2025-08-10 22:24:04,364][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074112] [Batch 00272/03692] [00:02:31/00:31:44, 0.557s/it]: train_loss_raw=0.3916, running_loss=0.5287, LR=0.000100
[2025-08-10 22:24:10,945][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074124] [Batch 00284/03692] [00:02:38/00:31:36, 0.557s/it]: train_loss_raw=0.4799, running_loss=0.5295, LR=0.000100
[2025-08-10 22:24:17,541][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074136] [Batch 00296/03692] [00:02:44/00:31:29, 0.556s/it]: train_loss_raw=0.6031, running_loss=0.5300, LR=0.000100
[2025-08-10 22:24:24,029][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074148] [Batch 00308/03692] [00:02:51/00:31:20, 0.556s/it]: train_loss_raw=0.5822, running_loss=0.5299, LR=0.000100
[2025-08-10 22:24:30,561][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074160] [Batch 00320/03692] [00:02:57/00:31:12, 0.555s/it]: train_loss_raw=0.7237, running_loss=0.5343, LR=0.000100
[2025-08-10 22:24:37,192][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074172] [Batch 00332/03692] [00:03:04/00:31:05, 0.555s/it]: train_loss_raw=0.5198, running_loss=0.5341, LR=0.000100
[2025-08-10 22:24:43,732][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074184] [Batch 00344/03692] [00:03:10/00:30:57, 0.555s/it]: train_loss_raw=0.5842, running_loss=0.5362, LR=0.000100
[2025-08-10 22:24:50,501][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074196] [Batch 00356/03692] [00:03:17/00:30:51, 0.555s/it]: train_loss_raw=0.4405, running_loss=0.5362, LR=0.000100
[2025-08-10 22:24:57,195][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074208] [Batch 00368/03692] [00:03:24/00:30:45, 0.555s/it]: train_loss_raw=0.5678, running_loss=0.5396, LR=0.000100
[2025-08-10 22:25:03,612][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074220] [Batch 00380/03692] [00:03:30/00:30:36, 0.555s/it]: train_loss_raw=0.4559, running_loss=0.5367, LR=0.000100
[2025-08-10 22:25:09,923][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074232] [Batch 00392/03692] [00:03:37/00:30:27, 0.554s/it]: train_loss_raw=0.4708, running_loss=0.5360, LR=0.000100
[2025-08-10 22:25:16,425][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074244] [Batch 00404/03692] [00:03:43/00:30:19, 0.553s/it]: train_loss_raw=0.6807, running_loss=0.5358, LR=0.000100
[2025-08-10 22:25:22,947][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074256] [Batch 00416/03692] [00:03:50/00:30:11, 0.553s/it]: train_loss_raw=0.4697, running_loss=0.5350, LR=0.000100
[2025-08-10 22:25:29,376][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074268] [Batch 00428/03692] [00:03:56/00:30:03, 0.553s/it]: train_loss_raw=0.6190, running_loss=0.5375, LR=0.000100
[2025-08-10 22:25:35,946][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074280] [Batch 00440/03692] [00:04:03/00:29:56, 0.552s/it]: train_loss_raw=0.4730, running_loss=0.5347, LR=0.000100
[2025-08-10 22:25:42,468][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074292] [Batch 00452/03692] [00:04:09/00:29:49, 0.552s/it]: train_loss_raw=0.5041, running_loss=0.5332, LR=0.000100
[2025-08-10 22:25:48,932][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074304] [Batch 00464/03692] [00:04:16/00:29:41, 0.552s/it]: train_loss_raw=0.4468, running_loss=0.5316, LR=0.000100
[2025-08-10 22:25:55,457][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074316] [Batch 00476/03692] [00:04:22/00:29:33, 0.552s/it]: train_loss_raw=0.5877, running_loss=0.5275, LR=0.000100
[2025-08-10 22:26:02,031][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074328] [Batch 00488/03692] [00:04:29/00:29:27, 0.552s/it]: train_loss_raw=0.5294, running_loss=0.5299, LR=0.000100
[2025-08-10 22:26:08,523][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074340] [Batch 00500/03692] [00:04:35/00:29:19, 0.551s/it]: train_loss_raw=0.4912, running_loss=0.5338, LR=0.000100
[2025-08-10 22:26:15,046][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074352] [Batch 00512/03692] [00:04:42/00:29:12, 0.551s/it]: train_loss_raw=0.5855, running_loss=0.5333, LR=0.000100
[2025-08-10 22:26:21,477][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074364] [Batch 00524/03692] [00:04:48/00:29:04, 0.551s/it]: train_loss_raw=0.5233, running_loss=0.5352, LR=0.000100
[2025-08-10 22:26:27,892][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074376] [Batch 00536/03692] [00:04:55/00:28:56, 0.550s/it]: train_loss_raw=0.4481, running_loss=0.5327, LR=0.000100
[2025-08-10 22:26:34,127][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074388] [Batch 00548/03692] [00:05:01/00:28:48, 0.550s/it]: train_loss_raw=0.5454, running_loss=0.5375, LR=0.000100
[2025-08-10 22:26:40,249][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074400] [Batch 00560/03692] [00:05:07/00:28:39, 0.549s/it]: train_loss_raw=0.4655, running_loss=0.5357, LR=0.000100
[2025-08-10 22:26:46,580][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074412] [Batch 00572/03692] [00:05:13/00:28:31, 0.548s/it]: train_loss_raw=0.4802, running_loss=0.5340, LR=0.000100
[2025-08-10 22:26:53,022][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074424] [Batch 00584/03692] [00:05:20/00:28:23, 0.548s/it]: train_loss_raw=0.5827, running_loss=0.5357, LR=0.000100
[2025-08-10 22:26:59,501][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074436] [Batch 00596/03692] [00:05:26/00:28:16, 0.548s/it]: train_loss_raw=0.5896, running_loss=0.5370, LR=0.000100
[2025-08-10 22:27:05,923][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074448] [Batch 00608/03692] [00:05:33/00:28:09, 0.548s/it]: train_loss_raw=0.4917, running_loss=0.5343, LR=0.000100
[2025-08-10 22:27:12,361][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074460] [Batch 00620/03692] [00:05:39/00:28:02, 0.548s/it]: train_loss_raw=0.3702, running_loss=0.5275, LR=0.000100
[2025-08-10 22:27:18,516][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074472] [Batch 00632/03692] [00:05:45/00:27:53, 0.547s/it]: train_loss_raw=0.7370, running_loss=0.5290, LR=0.000100
[2025-08-10 22:27:24,905][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074484] [Batch 00644/03692] [00:05:52/00:27:46, 0.547s/it]: train_loss_raw=0.6369, running_loss=0.5289, LR=0.000100
[2025-08-10 22:27:31,369][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074496] [Batch 00656/03692] [00:05:58/00:27:39, 0.546s/it]: train_loss_raw=0.4435, running_loss=0.5294, LR=0.000100
[2025-08-10 22:27:37,893][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074508] [Batch 00668/03692] [00:06:05/00:27:32, 0.546s/it]: train_loss_raw=0.4803, running_loss=0.5283, LR=0.000100
[2025-08-10 22:27:44,270][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074520] [Batch 00680/03692] [00:06:11/00:27:24, 0.546s/it]: train_loss_raw=0.5651, running_loss=0.5333, LR=0.000100
[2025-08-10 22:27:50,759][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074532] [Batch 00692/03692] [00:06:17/00:27:18, 0.546s/it]: train_loss_raw=0.4579, running_loss=0.5321, LR=0.000100
[2025-08-10 22:27:57,292][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074544] [Batch 00704/03692] [00:06:24/00:27:11, 0.546s/it]: train_loss_raw=0.5985, running_loss=0.5289, LR=0.000100
[2025-08-10 22:28:03,773][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074556] [Batch 00716/03692] [00:06:30/00:27:04, 0.546s/it]: train_loss_raw=0.5248, running_loss=0.5296, LR=0.000100
[2025-08-10 22:28:10,150][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074568] [Batch 00728/03692] [00:06:37/00:26:57, 0.546s/it]: train_loss_raw=0.4806, running_loss=0.5285, LR=0.000100
[2025-08-10 22:28:16,473][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074580] [Batch 00740/03692] [00:06:43/00:26:49, 0.545s/it]: train_loss_raw=0.4755, running_loss=0.5290, LR=0.000100
[2025-08-10 22:28:22,915][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074592] [Batch 00752/03692] [00:06:50/00:26:43, 0.545s/it]: train_loss_raw=0.5610, running_loss=0.5295, LR=0.000100
[2025-08-10 22:28:29,227][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074604] [Batch 00764/03692] [00:06:56/00:26:35, 0.545s/it]: train_loss_raw=0.5003, running_loss=0.5298, LR=0.000100
[2025-08-10 22:28:35,656][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074616] [Batch 00776/03692] [00:07:02/00:26:28, 0.545s/it]: train_loss_raw=0.5362, running_loss=0.5313, LR=0.000100
[2025-08-10 22:28:42,005][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074628] [Batch 00788/03692] [00:07:09/00:26:21, 0.545s/it]: train_loss_raw=0.6714, running_loss=0.5325, LR=0.000100
[2025-08-10 22:28:48,478][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074640] [Batch 00800/03692] [00:07:15/00:26:14, 0.544s/it]: train_loss_raw=0.5782, running_loss=0.5315, LR=0.000100
[2025-08-10 22:28:54,960][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074652] [Batch 00812/03692] [00:07:22/00:26:07, 0.544s/it]: train_loss_raw=0.4773, running_loss=0.5312, LR=0.000100
[2025-08-10 22:29:01,422][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074664] [Batch 00824/03692] [00:07:28/00:26:01, 0.544s/it]: train_loss_raw=0.3791, running_loss=0.5300, LR=0.000100
[2025-08-10 22:29:07,931][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074676] [Batch 00836/03692] [00:07:35/00:25:54, 0.544s/it]: train_loss_raw=0.6175, running_loss=0.5346, LR=0.000100
[2025-08-10 22:29:14,535][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074688] [Batch 00848/03692] [00:07:41/00:25:48, 0.544s/it]: train_loss_raw=0.5044, running_loss=0.5302, LR=0.000100
[2025-08-10 22:29:21,185][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074700] [Batch 00860/03692] [00:07:48/00:25:42, 0.545s/it]: train_loss_raw=0.5287, running_loss=0.5308, LR=0.000100
[2025-08-10 22:29:27,548][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074712] [Batch 00872/03692] [00:07:54/00:25:35, 0.544s/it]: train_loss_raw=0.6252, running_loss=0.5293, LR=0.000100
[2025-08-10 22:29:33,933][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074724] [Batch 00884/03692] [00:08:01/00:25:28, 0.544s/it]: train_loss_raw=0.4598, running_loss=0.5273, LR=0.000100
[2025-08-10 22:29:40,255][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074736] [Batch 00896/03692] [00:08:07/00:25:20, 0.544s/it]: train_loss_raw=0.5982, running_loss=0.5287, LR=0.000100
[2025-08-10 22:29:46,644][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074748] [Batch 00908/03692] [00:08:13/00:25:13, 0.544s/it]: train_loss_raw=0.6010, running_loss=0.5322, LR=0.000100
[2025-08-10 22:29:53,071][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074760] [Batch 00920/03692] [00:08:20/00:25:07, 0.544s/it]: train_loss_raw=0.4710, running_loss=0.5323, LR=0.000100
[2025-08-10 22:29:59,447][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074772] [Batch 00932/03692] [00:08:26/00:25:00, 0.544s/it]: train_loss_raw=0.6498, running_loss=0.5298, LR=0.000100
[2025-08-10 22:30:05,948][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074784] [Batch 00944/03692] [00:08:33/00:24:53, 0.543s/it]: train_loss_raw=0.6338, running_loss=0.5294, LR=0.000100
[2025-08-10 22:30:12,328][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074796] [Batch 00956/03692] [00:08:39/00:24:46, 0.543s/it]: train_loss_raw=0.5647, running_loss=0.5295, LR=0.000100
[2025-08-10 22:30:18,755][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074808] [Batch 00968/03692] [00:08:45/00:24:39, 0.543s/it]: train_loss_raw=0.5378, running_loss=0.5277, LR=0.000100
[2025-08-10 22:30:25,114][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074820] [Batch 00980/03692] [00:08:52/00:24:32, 0.543s/it]: train_loss_raw=0.5054, running_loss=0.5297, LR=0.000100
[2025-08-10 22:30:31,583][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074832] [Batch 00992/03692] [00:08:58/00:24:26, 0.543s/it]: train_loss_raw=0.5904, running_loss=0.5286, LR=0.000100
[2025-08-10 22:30:37,944][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074844] [Batch 01004/03692] [00:09:05/00:24:19, 0.543s/it]: train_loss_raw=0.5038, running_loss=0.5272, LR=0.000100
[2025-08-10 22:30:44,325][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074856] [Batch 01016/03692] [00:09:11/00:24:12, 0.543s/it]: train_loss_raw=0.4964, running_loss=0.5262, LR=0.000100
[2025-08-10 22:30:50,715][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074868] [Batch 01028/03692] [00:09:17/00:24:05, 0.543s/it]: train_loss_raw=0.6041, running_loss=0.5250, LR=0.000100
[2025-08-10 22:30:57,185][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074880] [Batch 01040/03692] [00:09:24/00:23:58, 0.543s/it]: train_loss_raw=0.5980, running_loss=0.5210, LR=0.000100
[2025-08-10 22:31:03,577][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074892] [Batch 01052/03692] [00:09:30/00:23:52, 0.542s/it]: train_loss_raw=0.5113, running_loss=0.5252, LR=0.000100
[2025-08-10 22:31:10,116][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074904] [Batch 01064/03692] [00:09:37/00:23:45, 0.543s/it]: train_loss_raw=0.5617, running_loss=0.5276, LR=0.000100
[2025-08-10 22:31:16,604][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074916] [Batch 01076/03692] [00:09:43/00:23:39, 0.542s/it]: train_loss_raw=0.4505, running_loss=0.5256, LR=0.000100
[2025-08-10 22:31:23,012][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074928] [Batch 01088/03692] [00:09:50/00:23:32, 0.542s/it]: train_loss_raw=0.6207, running_loss=0.5250, LR=0.000100
[2025-08-10 22:31:29,588][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074940] [Batch 01100/03692] [00:09:56/00:23:26, 0.542s/it]: train_loss_raw=0.5731, running_loss=0.5273, LR=0.000100
[2025-08-10 22:31:36,090][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074952] [Batch 01112/03692] [00:10:03/00:23:19, 0.542s/it]: train_loss_raw=0.5023, running_loss=0.5278, LR=0.000100
[2025-08-10 22:31:42,602][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074964] [Batch 01124/03692] [00:10:09/00:23:13, 0.542s/it]: train_loss_raw=0.5490, running_loss=0.5272, LR=0.000100
[2025-08-10 22:31:49,016][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074976] [Batch 01136/03692] [00:10:16/00:23:06, 0.542s/it]: train_loss_raw=0.5549, running_loss=0.5251, LR=0.000100
[2025-08-10 22:31:55,521][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074988] [Batch 01148/03692] [00:10:22/00:22:59, 0.542s/it]: train_loss_raw=0.5545, running_loss=0.5282, LR=0.000100
[2025-08-10 22:32:02,053][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075000] [Batch 01160/03692] [00:10:29/00:22:53, 0.542s/it]: train_loss_raw=0.5555, running_loss=0.5251, LR=0.000100
[2025-08-10 22:32:08,570][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075012] [Batch 01172/03692] [00:10:35/00:22:46, 0.542s/it]: train_loss_raw=0.3933, running_loss=0.5267, LR=0.000100
[2025-08-10 22:32:14,996][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075024] [Batch 01184/03692] [00:10:42/00:22:40, 0.542s/it]: train_loss_raw=0.4286, running_loss=0.5254, LR=0.000100
[2025-08-10 22:32:21,436][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075036] [Batch 01196/03692] [00:10:48/00:22:33, 0.542s/it]: train_loss_raw=0.4588, running_loss=0.5253, LR=0.000100
[2025-08-10 22:32:27,858][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075048] [Batch 01208/03692] [00:10:54/00:22:26, 0.542s/it]: train_loss_raw=0.4950, running_loss=0.5249, LR=0.000100
[2025-08-10 22:32:34,272][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075060] [Batch 01220/03692] [00:11:01/00:22:20, 0.542s/it]: train_loss_raw=0.5787, running_loss=0.5294, LR=0.000100
[2025-08-10 22:32:40,731][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075072] [Batch 01232/03692] [00:11:07/00:22:13, 0.542s/it]: train_loss_raw=0.5143, running_loss=0.5336, LR=0.000100
[2025-08-10 22:32:47,104][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075084] [Batch 01244/03692] [00:11:14/00:22:06, 0.542s/it]: train_loss_raw=0.5250, running_loss=0.5341, LR=0.000100
[2025-08-10 22:32:53,629][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075096] [Batch 01256/03692] [00:11:20/00:22:00, 0.542s/it]: train_loss_raw=0.4918, running_loss=0.5371, LR=0.000100
[2025-08-10 22:33:00,086][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075108] [Batch 01268/03692] [00:11:27/00:21:53, 0.542s/it]: train_loss_raw=0.5548, running_loss=0.5351, LR=0.000100
[2025-08-10 22:33:06,352][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075120] [Batch 01280/03692] [00:11:33/00:21:46, 0.542s/it]: train_loss_raw=0.4748, running_loss=0.5329, LR=0.000100
[2025-08-10 22:33:12,637][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075132] [Batch 01292/03692] [00:11:39/00:21:39, 0.542s/it]: train_loss_raw=0.5485, running_loss=0.5336, LR=0.000100
[2025-08-10 22:33:19,271][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075144] [Batch 01304/03692] [00:11:46/00:21:33, 0.542s/it]: train_loss_raw=0.4753, running_loss=0.5346, LR=0.000100
[2025-08-10 22:33:25,569][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075156] [Batch 01316/03692] [00:11:52/00:21:26, 0.542s/it]: train_loss_raw=0.5074, running_loss=0.5350, LR=0.000100
[2025-08-10 22:33:32,006][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075168] [Batch 01328/03692] [00:11:59/00:21:20, 0.542s/it]: train_loss_raw=0.5157, running_loss=0.5344, LR=0.000100
[2025-08-10 22:33:38,538][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075180] [Batch 01340/03692] [00:12:05/00:21:13, 0.542s/it]: train_loss_raw=0.5453, running_loss=0.5347, LR=0.000100
[2025-08-10 22:33:45,199][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075192] [Batch 01352/03692] [00:12:12/00:21:07, 0.542s/it]: train_loss_raw=0.5964, running_loss=0.5363, LR=0.000100
[2025-08-10 22:33:51,771][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075204] [Batch 01364/03692] [00:12:18/00:21:01, 0.542s/it]: train_loss_raw=0.4773, running_loss=0.5314, LR=0.000100
[2025-08-10 22:33:58,417][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075216] [Batch 01376/03692] [00:12:25/00:20:54, 0.542s/it]: train_loss_raw=0.5346, running_loss=0.5291, LR=0.000100
[2025-08-10 22:34:05,079][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075228] [Batch 01388/03692] [00:12:32/00:20:48, 0.542s/it]: train_loss_raw=0.5140, running_loss=0.5280, LR=0.000100
[2025-08-10 22:34:11,653][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075240] [Batch 01400/03692] [00:12:38/00:20:42, 0.542s/it]: train_loss_raw=0.5141, running_loss=0.5304, LR=0.000100
[2025-08-10 22:34:18,116][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075252] [Batch 01412/03692] [00:12:45/00:20:35, 0.542s/it]: train_loss_raw=0.6326, running_loss=0.5294, LR=0.000100
[2025-08-10 22:34:24,628][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075264] [Batch 01424/03692] [00:12:51/00:20:29, 0.542s/it]: train_loss_raw=0.4878, running_loss=0.5304, LR=0.000100
[2025-08-10 22:34:31,154][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075276] [Batch 01436/03692] [00:12:58/00:20:22, 0.542s/it]: train_loss_raw=0.5123, running_loss=0.5278, LR=0.000100
[2025-08-10 22:34:37,655][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075288] [Batch 01448/03692] [00:13:04/00:20:16, 0.542s/it]: train_loss_raw=0.5099, running_loss=0.5286, LR=0.000100
[2025-08-10 22:34:44,117][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075300] [Batch 01460/03692] [00:13:11/00:20:09, 0.542s/it]: train_loss_raw=0.5917, running_loss=0.5306, LR=0.000100
[2025-08-10 22:34:50,486][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075312] [Batch 01472/03692] [00:13:17/00:20:02, 0.542s/it]: train_loss_raw=0.4982, running_loss=0.5313, LR=0.000100
[2025-08-10 22:34:56,778][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075324] [Batch 01484/03692] [00:13:23/00:19:56, 0.542s/it]: train_loss_raw=0.5725, running_loss=0.5325, LR=0.000100
[2025-08-10 22:35:03,154][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075336] [Batch 01496/03692] [00:13:30/00:19:49, 0.542s/it]: train_loss_raw=0.4177, running_loss=0.5294, LR=0.000100
[2025-08-10 22:35:09,646][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075348] [Batch 01508/03692] [00:13:36/00:19:42, 0.542s/it]: train_loss_raw=0.6517, running_loss=0.5323, LR=0.000100
[2025-08-10 22:35:16,343][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075360] [Batch 01520/03692] [00:13:43/00:19:36, 0.542s/it]: train_loss_raw=0.4990, running_loss=0.5352, LR=0.000100
[2025-08-10 22:35:22,743][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075372] [Batch 01532/03692] [00:13:49/00:19:30, 0.542s/it]: train_loss_raw=0.6055, running_loss=0.5335, LR=0.000100
[2025-08-10 22:35:52,738][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075384] [Batch 01544/03692] [00:14:19/00:19:56, 0.557s/it]: train_loss_raw=0.4736, running_loss=0.5329, LR=0.000100
[2025-08-10 22:35:59,225][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075396] [Batch 01556/03692] [00:14:26/00:19:49, 0.557s/it]: train_loss_raw=0.5034, running_loss=0.5310, LR=0.000100
[2025-08-10 22:36:05,747][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075408] [Batch 01568/03692] [00:14:32/00:19:42, 0.557s/it]: train_loss_raw=0.5610, running_loss=0.5337, LR=0.000100
[2025-08-10 22:36:12,264][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075420] [Batch 01580/03692] [00:14:39/00:19:35, 0.557s/it]: train_loss_raw=0.4553, running_loss=0.5328, LR=0.000100
[2025-08-10 22:36:18,712][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075432] [Batch 01592/03692] [00:14:45/00:19:28, 0.556s/it]: train_loss_raw=0.4972, running_loss=0.5295, LR=0.000100
[2025-08-10 22:36:25,255][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075444] [Batch 01604/03692] [00:14:52/00:19:21, 0.556s/it]: train_loss_raw=0.5058, running_loss=0.5265, LR=0.000100
[2025-08-10 22:36:31,741][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075456] [Batch 01616/03692] [00:14:58/00:19:14, 0.556s/it]: train_loss_raw=0.5579, running_loss=0.5272, LR=0.000100
[2025-08-10 22:36:38,289][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075468] [Batch 01628/03692] [00:15:05/00:19:07, 0.556s/it]: train_loss_raw=0.6596, running_loss=0.5300, LR=0.000100
[2025-08-10 22:36:44,612][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075480] [Batch 01640/03692] [00:15:11/00:19:00, 0.556s/it]: train_loss_raw=0.4919, running_loss=0.5278, LR=0.000100
[2025-08-10 22:36:50,667][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075492] [Batch 01652/03692] [00:15:17/00:18:53, 0.556s/it]: train_loss_raw=0.6085, running_loss=0.5270, LR=0.000100
[2025-08-10 22:36:57,121][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075504] [Batch 01664/03692] [00:15:24/00:18:46, 0.555s/it]: train_loss_raw=0.5625, running_loss=0.5298, LR=0.000100
[2025-08-10 22:37:03,572][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075516] [Batch 01676/03692] [00:15:30/00:18:39, 0.555s/it]: train_loss_raw=0.5579, running_loss=0.5349, LR=0.000100
[2025-08-10 22:37:09,840][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075528] [Batch 01688/03692] [00:15:36/00:18:32, 0.555s/it]: train_loss_raw=0.4737, running_loss=0.5350, LR=0.000100
[2025-08-10 22:37:15,817][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075540] [Batch 01700/03692] [00:15:42/00:18:24, 0.555s/it]: train_loss_raw=0.5772, running_loss=0.5331, LR=0.000100
[2025-08-10 22:37:21,866][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075552] [Batch 01712/03692] [00:15:48/00:18:17, 0.554s/it]: train_loss_raw=0.5602, running_loss=0.5286, LR=0.000100
[2025-08-10 22:37:27,880][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075564] [Batch 01724/03692] [00:15:54/00:18:10, 0.554s/it]: train_loss_raw=0.6270, running_loss=0.5275, LR=0.000100
[2025-08-10 22:37:33,978][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075576] [Batch 01736/03692] [00:16:01/00:18:02, 0.554s/it]: train_loss_raw=0.5805, running_loss=0.5268, LR=0.000100
[2025-08-10 22:37:40,150][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075588] [Batch 01748/03692] [00:16:07/00:17:55, 0.553s/it]: train_loss_raw=0.4756, running_loss=0.5251, LR=0.000100
[2025-08-10 22:37:46,650][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075600] [Batch 01760/03692] [00:16:13/00:17:48, 0.553s/it]: train_loss_raw=0.4709, running_loss=0.5227, LR=0.000100
[2025-08-10 22:37:53,061][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075612] [Batch 01772/03692] [00:16:20/00:17:42, 0.553s/it]: train_loss_raw=0.4324, running_loss=0.5216, LR=0.000100
[2025-08-10 22:37:59,487][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075624] [Batch 01784/03692] [00:16:26/00:17:35, 0.553s/it]: train_loss_raw=0.6730, running_loss=0.5224, LR=0.000100
[2025-08-10 22:38:05,825][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075636] [Batch 01796/03692] [00:16:32/00:17:28, 0.553s/it]: train_loss_raw=0.5086, running_loss=0.5255, LR=0.000100
[2025-08-10 22:38:12,164][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075648] [Batch 01808/03692] [00:16:39/00:17:21, 0.553s/it]: train_loss_raw=0.4718, running_loss=0.5269, LR=0.000100
[2025-08-10 22:38:18,604][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075660] [Batch 01820/03692] [00:16:45/00:17:14, 0.553s/it]: train_loss_raw=0.5243, running_loss=0.5223, LR=0.000100
[2025-08-10 22:38:25,138][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075672] [Batch 01832/03692] [00:16:52/00:17:07, 0.553s/it]: train_loss_raw=0.4772, running_loss=0.5209, LR=0.000100
[2025-08-10 22:38:31,678][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075684] [Batch 01844/03692] [00:16:58/00:17:00, 0.552s/it]: train_loss_raw=0.6119, running_loss=0.5251, LR=0.000100
[2025-08-10 22:38:38,087][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075696] [Batch 01856/03692] [00:17:05/00:16:54, 0.552s/it]: train_loss_raw=0.4566, running_loss=0.5265, LR=0.000100
[2025-08-10 22:38:44,533][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075708] [Batch 01868/03692] [00:17:11/00:16:47, 0.552s/it]: train_loss_raw=0.5276, running_loss=0.5278, LR=0.000100
[2025-08-10 22:38:51,057][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075720] [Batch 01880/03692] [00:17:18/00:16:40, 0.552s/it]: train_loss_raw=0.4595, running_loss=0.5287, LR=0.000100
[2025-08-10 22:38:57,513][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075732] [Batch 01892/03692] [00:17:24/00:16:33, 0.552s/it]: train_loss_raw=0.5256, running_loss=0.5283, LR=0.000100
[2025-08-10 22:39:03,933][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075744] [Batch 01904/03692] [00:17:31/00:16:27, 0.552s/it]: train_loss_raw=0.4692, running_loss=0.5289, LR=0.000100
[2025-08-10 22:39:10,379][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075756] [Batch 01916/03692] [00:17:37/00:16:20, 0.552s/it]: train_loss_raw=0.5076, running_loss=0.5269, LR=0.000100
[2025-08-10 22:39:16,897][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075768] [Batch 01928/03692] [00:17:44/00:16:13, 0.552s/it]: train_loss_raw=0.5390, running_loss=0.5298, LR=0.000100
[2025-08-10 22:39:23,306][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075780] [Batch 01940/03692] [00:17:50/00:16:06, 0.552s/it]: train_loss_raw=0.4956, running_loss=0.5302, LR=0.000100
[2025-08-10 22:39:29,733][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075792] [Batch 01952/03692] [00:17:56/00:15:59, 0.552s/it]: train_loss_raw=0.5409, running_loss=0.5295, LR=0.000100
[2025-08-10 22:39:36,165][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075804] [Batch 01964/03692] [00:18:03/00:15:53, 0.552s/it]: train_loss_raw=0.5313, running_loss=0.5288, LR=0.000100
[2025-08-10 22:39:42,565][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075816] [Batch 01976/03692] [00:18:09/00:15:46, 0.551s/it]: train_loss_raw=0.4725, running_loss=0.5294, LR=0.000100
[2025-08-10 22:39:48,933][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075828] [Batch 01988/03692] [00:18:16/00:15:39, 0.551s/it]: train_loss_raw=0.3957, running_loss=0.5269, LR=0.000100
[2025-08-10 22:39:55,303][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075840] [Batch 02000/03692] [00:18:22/00:15:32, 0.551s/it]: train_loss_raw=0.5064, running_loss=0.5269, LR=0.000100
[2025-08-10 22:40:01,691][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075852] [Batch 02012/03692] [00:18:28/00:15:25, 0.551s/it]: train_loss_raw=0.5038, running_loss=0.5287, LR=0.000100
[2025-08-10 22:40:08,073][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075864] [Batch 02024/03692] [00:18:35/00:15:19, 0.551s/it]: train_loss_raw=0.5177, running_loss=0.5287, LR=0.000100
[2025-08-10 22:40:14,459][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075876] [Batch 02036/03692] [00:18:41/00:15:12, 0.551s/it]: train_loss_raw=0.6479, running_loss=0.5284, LR=0.000100
[2025-08-10 22:40:20,835][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075888] [Batch 02048/03692] [00:18:47/00:15:05, 0.551s/it]: train_loss_raw=0.4479, running_loss=0.5259, LR=0.000100
[2025-08-10 22:40:27,238][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075900] [Batch 02060/03692] [00:18:54/00:14:58, 0.551s/it]: train_loss_raw=0.4622, running_loss=0.5228, LR=0.000100
[2025-08-10 22:40:33,644][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075912] [Batch 02072/03692] [00:19:00/00:14:51, 0.551s/it]: train_loss_raw=0.5463, running_loss=0.5239, LR=0.000100
[2025-08-10 22:40:40,055][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075924] [Batch 02084/03692] [00:19:07/00:14:45, 0.550s/it]: train_loss_raw=0.4709, running_loss=0.5196, LR=0.000100
[2025-08-10 22:40:46,429][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075936] [Batch 02096/03692] [00:19:13/00:14:38, 0.550s/it]: train_loss_raw=0.4552, running_loss=0.5228, LR=0.000100
[2025-08-10 22:40:52,875][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075948] [Batch 02108/03692] [00:19:19/00:14:31, 0.550s/it]: train_loss_raw=0.5063, running_loss=0.5265, LR=0.000100
[2025-08-10 22:40:59,254][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075960] [Batch 02120/03692] [00:19:26/00:14:24, 0.550s/it]: train_loss_raw=0.5436, running_loss=0.5277, LR=0.000100
[2025-08-10 22:41:05,643][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075972] [Batch 02132/03692] [00:19:32/00:14:18, 0.550s/it]: train_loss_raw=0.5812, running_loss=0.5282, LR=0.000100
[2025-08-10 22:41:12,070][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075984] [Batch 02144/03692] [00:19:39/00:14:11, 0.550s/it]: train_loss_raw=0.5329, running_loss=0.5278, LR=0.000100
[2025-08-10 22:41:18,420][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075996] [Batch 02156/03692] [00:19:45/00:14:04, 0.550s/it]: train_loss_raw=0.4739, running_loss=0.5272, LR=0.000100
[2025-08-10 22:41:29,337][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076008] [Batch 02168/03692] [00:19:56/00:14:01, 0.552s/it]: train_loss_raw=0.5194, running_loss=0.5242, LR=0.000100
[2025-08-10 22:41:35,706][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076020] [Batch 02180/03692] [00:20:02/00:13:54, 0.552s/it]: train_loss_raw=0.4918, running_loss=0.5241, LR=0.000100
[2025-08-10 22:41:42,052][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076032] [Batch 02192/03692] [00:20:09/00:13:47, 0.552s/it]: train_loss_raw=0.5826, running_loss=0.5249, LR=0.000100
[2025-08-10 22:41:48,433][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076044] [Batch 02204/03692] [00:20:15/00:13:40, 0.552s/it]: train_loss_raw=0.6461, running_loss=0.5315, LR=0.000100
[2025-08-10 22:41:54,846][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076056] [Batch 02216/03692] [00:20:21/00:13:33, 0.551s/it]: train_loss_raw=0.5551, running_loss=0.5327, LR=0.000100
[2025-08-10 22:42:01,225][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076068] [Batch 02228/03692] [00:20:28/00:13:27, 0.551s/it]: train_loss_raw=0.5858, running_loss=0.5336, LR=0.000100
[2025-08-10 22:42:07,587][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076080] [Batch 02240/03692] [00:20:34/00:13:20, 0.551s/it]: train_loss_raw=0.6221, running_loss=0.5312, LR=0.000100
[2025-08-10 22:42:13,999][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076092] [Batch 02252/03692] [00:20:41/00:13:13, 0.551s/it]: train_loss_raw=0.5344, running_loss=0.5328, LR=0.000100
[2025-08-10 22:42:20,463][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076104] [Batch 02264/03692] [00:20:47/00:13:06, 0.551s/it]: train_loss_raw=0.5769, running_loss=0.5344, LR=0.000100
[2025-08-10 22:42:26,850][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076116] [Batch 02276/03692] [00:20:53/00:13:00, 0.551s/it]: train_loss_raw=0.4712, running_loss=0.5340, LR=0.000100
[2025-08-10 22:42:33,299][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076128] [Batch 02288/03692] [00:21:00/00:12:53, 0.551s/it]: train_loss_raw=0.4880, running_loss=0.5314, LR=0.000100
[2025-08-10 22:42:39,653][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076140] [Batch 02300/03692] [00:21:06/00:12:46, 0.551s/it]: train_loss_raw=0.4537, running_loss=0.5278, LR=0.000100
[2025-08-10 22:42:46,030][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076152] [Batch 02312/03692] [00:21:13/00:12:39, 0.551s/it]: train_loss_raw=0.5144, running_loss=0.5280, LR=0.000100
[2025-08-10 22:42:52,549][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076164] [Batch 02324/03692] [00:21:19/00:12:33, 0.551s/it]: train_loss_raw=0.4982, running_loss=0.5256, LR=0.000100
[2025-08-10 22:42:59,026][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076176] [Batch 02336/03692] [00:21:26/00:12:26, 0.551s/it]: train_loss_raw=0.5443, running_loss=0.5271, LR=0.000100
[2025-08-10 22:43:05,489][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076188] [Batch 02348/03692] [00:21:32/00:12:19, 0.551s/it]: train_loss_raw=0.5690, running_loss=0.5279, LR=0.000100
[2025-08-10 22:43:12,020][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076200] [Batch 02360/03692] [00:21:39/00:12:13, 0.550s/it]: train_loss_raw=0.4063, running_loss=0.5210, LR=0.000100
[2025-08-10 22:43:18,456][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076212] [Batch 02372/03692] [00:21:45/00:12:06, 0.550s/it]: train_loss_raw=0.5170, running_loss=0.5231, LR=0.000100
[2025-08-10 22:43:24,997][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076224] [Batch 02384/03692] [00:21:52/00:11:59, 0.550s/it]: train_loss_raw=0.5107, running_loss=0.5260, LR=0.000100
[2025-08-10 22:43:31,556][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076236] [Batch 02396/03692] [00:21:58/00:11:53, 0.550s/it]: train_loss_raw=0.5319, running_loss=0.5272, LR=0.000100
[2025-08-10 22:43:37,982][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076248] [Batch 02408/03692] [00:22:05/00:11:46, 0.550s/it]: train_loss_raw=0.4780, running_loss=0.5251, LR=0.000100
[2025-08-10 22:43:44,452][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076260] [Batch 02420/03692] [00:22:11/00:11:39, 0.550s/it]: train_loss_raw=0.4165, running_loss=0.5224, LR=0.000100
[2025-08-10 22:43:51,119][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076272] [Batch 02432/03692] [00:22:18/00:11:33, 0.550s/it]: train_loss_raw=0.5367, running_loss=0.5250, LR=0.000100
[2025-08-10 22:43:57,506][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076284] [Batch 02444/03692] [00:22:24/00:11:26, 0.550s/it]: train_loss_raw=0.5750, running_loss=0.5239, LR=0.000100
[2025-08-10 22:44:03,599][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076296] [Batch 02456/03692] [00:22:30/00:11:19, 0.550s/it]: train_loss_raw=0.5236, running_loss=0.5238, LR=0.000100
[2025-08-10 22:44:10,047][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076308] [Batch 02468/03692] [00:22:37/00:11:13, 0.550s/it]: train_loss_raw=0.4216, running_loss=0.5239, LR=0.000100
[2025-08-10 22:44:16,507][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076320] [Batch 02480/03692] [00:22:43/00:11:06, 0.550s/it]: train_loss_raw=0.6059, running_loss=0.5223, LR=0.000100
[2025-08-10 22:44:23,100][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076332] [Batch 02492/03692] [00:22:50/00:10:59, 0.550s/it]: train_loss_raw=0.4926, running_loss=0.5232, LR=0.000100
[2025-08-10 22:44:29,540][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076344] [Batch 02504/03692] [00:22:56/00:10:53, 0.550s/it]: train_loss_raw=0.4110, running_loss=0.5241, LR=0.000100
[2025-08-10 22:44:35,978][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076356] [Batch 02516/03692] [00:23:03/00:10:46, 0.550s/it]: train_loss_raw=0.5664, running_loss=0.5261, LR=0.000100
[2025-08-10 22:44:42,513][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076368] [Batch 02528/03692] [00:23:09/00:10:39, 0.550s/it]: train_loss_raw=0.4915, running_loss=0.5274, LR=0.000100
[2025-08-10 22:44:48,980][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076380] [Batch 02540/03692] [00:23:16/00:10:33, 0.550s/it]: train_loss_raw=0.5763, running_loss=0.5245, LR=0.000100
[2025-08-10 22:44:55,568][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076392] [Batch 02552/03692] [00:23:22/00:10:26, 0.550s/it]: train_loss_raw=0.4771, running_loss=0.5247, LR=0.000100
[2025-08-10 22:45:02,102][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076404] [Batch 02564/03692] [00:23:29/00:10:19, 0.550s/it]: train_loss_raw=0.5116, running_loss=0.5233, LR=0.000100
[2025-08-10 22:45:08,581][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076416] [Batch 02576/03692] [00:23:35/00:10:13, 0.550s/it]: train_loss_raw=0.5292, running_loss=0.5241, LR=0.000100
[2025-08-10 22:45:14,785][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076428] [Batch 02588/03692] [00:23:41/00:10:06, 0.549s/it]: train_loss_raw=0.5607, running_loss=0.5252, LR=0.000100
[2025-08-10 22:45:20,981][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076440] [Batch 02600/03692] [00:23:48/00:09:59, 0.549s/it]: train_loss_raw=0.4777, running_loss=0.5234, LR=0.000100
[2025-08-10 22:45:27,325][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076452] [Batch 02612/03692] [00:23:54/00:09:53, 0.549s/it]: train_loss_raw=0.4255, running_loss=0.5227, LR=0.000100
[2025-08-10 22:45:33,554][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076464] [Batch 02624/03692] [00:24:00/00:09:46, 0.549s/it]: train_loss_raw=0.6539, running_loss=0.5218, LR=0.000100
[2025-08-10 22:45:39,803][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076476] [Batch 02636/03692] [00:24:06/00:09:39, 0.549s/it]: train_loss_raw=0.5480, running_loss=0.5229, LR=0.000100
[2025-08-10 22:45:46,037][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076488] [Batch 02648/03692] [00:24:13/00:09:32, 0.549s/it]: train_loss_raw=0.4989, running_loss=0.5233, LR=0.000100
[2025-08-10 22:45:52,569][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076500] [Batch 02660/03692] [00:24:19/00:09:26, 0.549s/it]: train_loss_raw=0.5624, running_loss=0.5247, LR=0.000100
[2025-08-10 22:45:58,994][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076512] [Batch 02672/03692] [00:24:26/00:09:19, 0.549s/it]: train_loss_raw=0.5096, running_loss=0.5212, LR=0.000100
[2025-08-10 22:46:05,420][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076524] [Batch 02684/03692] [00:24:32/00:09:13, 0.549s/it]: train_loss_raw=0.6405, running_loss=0.5230, LR=0.000100
[2025-08-10 22:46:11,798][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076536] [Batch 02696/03692] [00:24:38/00:09:06, 0.549s/it]: train_loss_raw=0.6394, running_loss=0.5247, LR=0.000100
[2025-08-10 22:46:18,303][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076548] [Batch 02708/03692] [00:24:45/00:08:59, 0.549s/it]: train_loss_raw=0.5678, running_loss=0.5256, LR=0.000100
[2025-08-10 22:46:24,792][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076560] [Batch 02720/03692] [00:24:51/00:08:53, 0.548s/it]: train_loss_raw=0.4898, running_loss=0.5256, LR=0.000100
[2025-08-10 22:46:31,244][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076572] [Batch 02732/03692] [00:24:58/00:08:46, 0.548s/it]: train_loss_raw=0.4111, running_loss=0.5225, LR=0.000100
[2025-08-10 22:46:37,761][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076584] [Batch 02744/03692] [00:25:04/00:08:39, 0.548s/it]: train_loss_raw=0.5975, running_loss=0.5213, LR=0.000100
[2025-08-10 22:46:44,276][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076596] [Batch 02756/03692] [00:25:11/00:08:33, 0.548s/it]: train_loss_raw=0.5012, running_loss=0.5233, LR=0.000100
[2025-08-10 22:46:50,753][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076608] [Batch 02768/03692] [00:25:17/00:08:26, 0.548s/it]: train_loss_raw=0.5558, running_loss=0.5228, LR=0.000100
[2025-08-10 22:46:57,246][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076620] [Batch 02780/03692] [00:25:24/00:08:20, 0.548s/it]: train_loss_raw=0.4571, running_loss=0.5247, LR=0.000100
[2025-08-10 22:47:03,701][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076632] [Batch 02792/03692] [00:25:30/00:08:13, 0.548s/it]: train_loss_raw=0.5343, running_loss=0.5223, LR=0.000100
[2025-08-10 22:47:09,929][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076644] [Batch 02804/03692] [00:25:37/00:08:06, 0.548s/it]: train_loss_raw=0.5093, running_loss=0.5228, LR=0.000100
[2025-08-10 22:47:15,893][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076656] [Batch 02816/03692] [00:25:43/00:07:59, 0.548s/it]: train_loss_raw=0.4711, running_loss=0.5233, LR=0.000100
[2025-08-10 22:47:22,059][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076668] [Batch 02828/03692] [00:25:49/00:07:53, 0.548s/it]: train_loss_raw=0.5832, running_loss=0.5296, LR=0.000100
[2025-08-10 22:47:28,179][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076680] [Batch 02840/03692] [00:25:55/00:07:46, 0.548s/it]: train_loss_raw=0.5278, running_loss=0.5285, LR=0.000100
[2025-08-10 22:47:34,440][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076692] [Batch 02852/03692] [00:26:01/00:07:39, 0.548s/it]: train_loss_raw=0.4819, running_loss=0.5272, LR=0.000100
[2025-08-10 22:47:40,897][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076704] [Batch 02864/03692] [00:26:08/00:07:33, 0.547s/it]: train_loss_raw=0.4648, running_loss=0.5244, LR=0.000100
[2025-08-10 22:47:47,405][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076716] [Batch 02876/03692] [00:26:14/00:07:26, 0.547s/it]: train_loss_raw=0.6439, running_loss=0.5247, LR=0.000100
[2025-08-10 22:47:53,546][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076728] [Batch 02888/03692] [00:26:20/00:07:20, 0.547s/it]: train_loss_raw=0.5089, running_loss=0.5231, LR=0.000100
[2025-08-10 22:47:59,895][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076740] [Batch 02900/03692] [00:26:27/00:07:13, 0.547s/it]: train_loss_raw=0.4691, running_loss=0.5244, LR=0.000100
[2025-08-10 22:48:05,968][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076752] [Batch 02912/03692] [00:26:33/00:07:06, 0.547s/it]: train_loss_raw=0.5059, running_loss=0.5239, LR=0.000100
[2025-08-10 22:48:11,998][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076764] [Batch 02924/03692] [00:26:39/00:07:00, 0.547s/it]: train_loss_raw=0.5854, running_loss=0.5209, LR=0.000100
[2025-08-10 22:48:18,042][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076776] [Batch 02936/03692] [00:26:45/00:06:53, 0.547s/it]: train_loss_raw=0.4995, running_loss=0.5207, LR=0.000100
[2025-08-10 22:48:24,122][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076788] [Batch 02948/03692] [00:26:51/00:06:46, 0.547s/it]: train_loss_raw=0.6324, running_loss=0.5205, LR=0.000100
[2025-08-10 22:48:30,615][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076800] [Batch 02960/03692] [00:26:57/00:06:40, 0.547s/it]: train_loss_raw=0.5473, running_loss=0.5207, LR=0.000100
[2025-08-10 22:48:37,058][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076812] [Batch 02972/03692] [00:27:04/00:06:33, 0.546s/it]: train_loss_raw=0.5197, running_loss=0.5208, LR=0.000100
[2025-08-10 22:48:43,603][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076824] [Batch 02984/03692] [00:27:10/00:06:26, 0.546s/it]: train_loss_raw=0.5860, running_loss=0.5221, LR=0.000100
[2025-08-10 22:48:50,046][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076836] [Batch 02996/03692] [00:27:17/00:06:20, 0.546s/it]: train_loss_raw=0.5408, running_loss=0.5225, LR=0.000100
[2025-08-10 22:48:56,512][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076848] [Batch 03008/03692] [00:27:23/00:06:13, 0.546s/it]: train_loss_raw=0.5048, running_loss=0.5250, LR=0.000100
[2025-08-10 22:49:02,953][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076860] [Batch 03020/03692] [00:27:30/00:06:07, 0.546s/it]: train_loss_raw=0.6450, running_loss=0.5259, LR=0.000100
[2025-08-10 22:49:09,428][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076872] [Batch 03032/03692] [00:27:36/00:06:00, 0.546s/it]: train_loss_raw=0.6777, running_loss=0.5260, LR=0.000100
[2025-08-10 22:49:15,889][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076884] [Batch 03044/03692] [00:27:42/00:05:54, 0.546s/it]: train_loss_raw=0.4971, running_loss=0.5273, LR=0.000100
[2025-08-10 22:49:22,257][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076896] [Batch 03056/03692] [00:27:49/00:05:47, 0.546s/it]: train_loss_raw=0.6092, running_loss=0.5257, LR=0.000100
[2025-08-10 22:49:28,587][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076908] [Batch 03068/03692] [00:27:55/00:05:40, 0.546s/it]: train_loss_raw=0.5913, running_loss=0.5271, LR=0.000100
[2025-08-10 22:49:34,988][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076920] [Batch 03080/03692] [00:28:02/00:05:34, 0.546s/it]: train_loss_raw=0.4588, running_loss=0.5258, LR=0.000100
[2025-08-10 22:49:41,437][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076932] [Batch 03092/03692] [00:28:08/00:05:27, 0.546s/it]: train_loss_raw=0.4706, running_loss=0.5253, LR=0.000100
[2025-08-10 22:49:47,826][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076944] [Batch 03104/03692] [00:28:14/00:05:21, 0.546s/it]: train_loss_raw=0.4891, running_loss=0.5222, LR=0.000100
[2025-08-10 22:49:54,137][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076956] [Batch 03116/03692] [00:28:21/00:05:14, 0.546s/it]: train_loss_raw=0.6132, running_loss=0.5259, LR=0.000100
[2025-08-10 22:50:00,547][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076968] [Batch 03128/03692] [00:28:27/00:05:07, 0.546s/it]: train_loss_raw=0.5500, running_loss=0.5264, LR=0.000100
[2025-08-10 22:50:06,937][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076980] [Batch 03140/03692] [00:28:34/00:05:01, 0.546s/it]: train_loss_raw=0.5786, running_loss=0.5264, LR=0.000100
[2025-08-10 22:50:13,369][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076992] [Batch 03152/03692] [00:28:40/00:04:54, 0.546s/it]: train_loss_raw=0.6535, running_loss=0.5264, LR=0.000100
[2025-08-10 22:50:19,721][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077004] [Batch 03164/03692] [00:28:46/00:04:48, 0.546s/it]: train_loss_raw=0.4806, running_loss=0.5261, LR=0.000100
[2025-08-10 22:50:26,113][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077016] [Batch 03176/03692] [00:28:53/00:04:41, 0.546s/it]: train_loss_raw=0.4704, running_loss=0.5252, LR=0.000100
[2025-08-10 22:50:32,665][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077028] [Batch 03188/03692] [00:28:59/00:04:35, 0.546s/it]: train_loss_raw=0.5314, running_loss=0.5260, LR=0.000100
[2025-08-10 22:50:39,105][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077040] [Batch 03200/03692] [00:29:06/00:04:28, 0.546s/it]: train_loss_raw=0.5288, running_loss=0.5269, LR=0.000100
[2025-08-10 22:50:45,700][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077052] [Batch 03212/03692] [00:29:12/00:04:21, 0.546s/it]: train_loss_raw=0.5590, running_loss=0.5257, LR=0.000100
[2025-08-10 22:50:52,180][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077064] [Batch 03224/03692] [00:29:19/00:04:15, 0.546s/it]: train_loss_raw=0.4461, running_loss=0.5257, LR=0.000100
[2025-08-10 22:50:58,687][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077076] [Batch 03236/03692] [00:29:25/00:04:08, 0.546s/it]: train_loss_raw=0.5801, running_loss=0.5285, LR=0.000100
[2025-08-10 22:51:05,281][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077088] [Batch 03248/03692] [00:29:32/00:04:02, 0.546s/it]: train_loss_raw=0.5579, running_loss=0.5297, LR=0.000100
[2025-08-10 22:51:11,831][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077100] [Batch 03260/03692] [00:29:38/00:03:55, 0.546s/it]: train_loss_raw=0.4005, running_loss=0.5303, LR=0.000100
[2025-08-10 22:51:18,350][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077112] [Batch 03272/03692] [00:29:45/00:03:49, 0.546s/it]: train_loss_raw=0.5641, running_loss=0.5293, LR=0.000100
[2025-08-10 22:51:24,915][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077124] [Batch 03284/03692] [00:29:52/00:03:42, 0.546s/it]: train_loss_raw=0.4848, running_loss=0.5297, LR=0.000100
[2025-08-10 22:51:31,315][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077136] [Batch 03296/03692] [00:29:58/00:03:36, 0.546s/it]: train_loss_raw=0.4957, running_loss=0.5298, LR=0.000100
[2025-08-10 22:51:37,741][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077148] [Batch 03308/03692] [00:30:04/00:03:29, 0.546s/it]: train_loss_raw=0.5028, running_loss=0.5289, LR=0.000100
[2025-08-10 22:51:44,131][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077160] [Batch 03320/03692] [00:30:11/00:03:22, 0.546s/it]: train_loss_raw=0.4882, running_loss=0.5275, LR=0.000100
[2025-08-10 22:51:50,472][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077172] [Batch 03332/03692] [00:30:17/00:03:16, 0.545s/it]: train_loss_raw=0.5148, running_loss=0.5228, LR=0.000100
[2025-08-10 22:51:56,986][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077184] [Batch 03344/03692] [00:30:24/00:03:09, 0.545s/it]: train_loss_raw=0.5022, running_loss=0.5218, LR=0.000100
[2025-08-10 22:52:03,453][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077196] [Batch 03356/03692] [00:30:30/00:03:03, 0.545s/it]: train_loss_raw=0.5476, running_loss=0.5219, LR=0.000100
[2025-08-10 22:52:09,924][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077208] [Batch 03368/03692] [00:30:37/00:02:56, 0.545s/it]: train_loss_raw=0.5490, running_loss=0.5214, LR=0.000100
[2025-08-10 22:52:16,269][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077220] [Batch 03380/03692] [00:30:43/00:02:50, 0.545s/it]: train_loss_raw=0.5186, running_loss=0.5214, LR=0.000100
[2025-08-10 22:52:22,645][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077232] [Batch 03392/03692] [00:30:49/00:02:43, 0.545s/it]: train_loss_raw=0.4274, running_loss=0.5191, LR=0.000100
[2025-08-10 22:52:28,971][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077244] [Batch 03404/03692] [00:30:56/00:02:37, 0.545s/it]: train_loss_raw=0.5107, running_loss=0.5215, LR=0.000100
[2025-08-10 22:52:35,521][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077256] [Batch 03416/03692] [00:31:02/00:02:30, 0.545s/it]: train_loss_raw=0.4777, running_loss=0.5213, LR=0.000100
[2025-08-10 22:52:42,048][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077268] [Batch 03428/03692] [00:31:09/00:02:23, 0.545s/it]: train_loss_raw=0.5887, running_loss=0.5237, LR=0.000100
[2025-08-10 22:52:48,507][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077280] [Batch 03440/03692] [00:31:15/00:02:17, 0.545s/it]: train_loss_raw=0.4502, running_loss=0.5237, LR=0.000100
[2025-08-10 22:52:54,940][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077292] [Batch 03452/03692] [00:31:22/00:02:10, 0.545s/it]: train_loss_raw=0.5171, running_loss=0.5229, LR=0.000100
[2025-08-10 22:53:01,380][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077304] [Batch 03464/03692] [00:31:28/00:02:04, 0.545s/it]: train_loss_raw=0.5089, running_loss=0.5224, LR=0.000100
[2025-08-10 22:53:07,824][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077316] [Batch 03476/03692] [00:31:34/00:01:57, 0.545s/it]: train_loss_raw=0.5766, running_loss=0.5227, LR=0.000100
[2025-08-10 22:53:14,206][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077328] [Batch 03488/03692] [00:31:41/00:01:51, 0.545s/it]: train_loss_raw=0.5553, running_loss=0.5225, LR=0.000100
[2025-08-10 22:53:20,581][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077340] [Batch 03500/03692] [00:31:47/00:01:44, 0.545s/it]: train_loss_raw=0.5513, running_loss=0.5212, LR=0.000100
[2025-08-10 22:53:27,094][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077352] [Batch 03512/03692] [00:31:54/00:01:38, 0.545s/it]: train_loss_raw=0.5495, running_loss=0.5253, LR=0.000100
[2025-08-10 22:53:33,681][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077364] [Batch 03524/03692] [00:32:00/00:01:31, 0.545s/it]: train_loss_raw=0.4932, running_loss=0.5240, LR=0.000100
[2025-08-10 22:53:40,022][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077376] [Batch 03536/03692] [00:32:07/00:01:25, 0.545s/it]: train_loss_raw=0.6030, running_loss=0.5204, LR=0.000100
[2025-08-10 22:53:46,417][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077388] [Batch 03548/03692] [00:32:13/00:01:18, 0.545s/it]: train_loss_raw=0.4764, running_loss=0.5194, LR=0.000100
[2025-08-10 22:53:52,782][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077400] [Batch 03560/03692] [00:32:19/00:01:11, 0.545s/it]: train_loss_raw=0.4882, running_loss=0.5145, LR=0.000100
[2025-08-10 22:53:59,180][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077412] [Batch 03572/03692] [00:32:26/00:01:05, 0.545s/it]: train_loss_raw=0.5360, running_loss=0.5178, LR=0.000100
[2025-08-10 22:54:05,639][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077424] [Batch 03584/03692] [00:32:32/00:00:58, 0.545s/it]: train_loss_raw=0.5026, running_loss=0.5171, LR=0.000100
[2025-08-10 22:54:11,958][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077436] [Batch 03596/03692] [00:32:39/00:00:52, 0.545s/it]: train_loss_raw=0.6081, running_loss=0.5172, LR=0.000100
[2025-08-10 22:54:18,433][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077448] [Batch 03608/03692] [00:32:45/00:00:45, 0.545s/it]: train_loss_raw=0.4822, running_loss=0.5186, LR=0.000100
[2025-08-10 22:54:24,996][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077460] [Batch 03620/03692] [00:32:52/00:00:39, 0.545s/it]: train_loss_raw=0.7715, running_loss=0.5233, LR=0.000100
[2025-08-10 22:54:31,541][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077472] [Batch 03632/03692] [00:32:58/00:00:32, 0.545s/it]: train_loss_raw=0.4966, running_loss=0.5205, LR=0.000100
[2025-08-10 22:54:38,045][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077484] [Batch 03644/03692] [00:33:05/00:00:26, 0.545s/it]: train_loss_raw=0.4701, running_loss=0.5182, LR=0.000100
[2025-08-10 22:54:44,525][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077496] [Batch 03656/03692] [00:33:11/00:00:19, 0.545s/it]: train_loss_raw=0.5316, running_loss=0.5176, LR=0.000100
[2025-08-10 22:54:51,052][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077508] [Batch 03668/03692] [00:33:18/00:00:13, 0.545s/it]: train_loss_raw=0.5703, running_loss=0.5164, LR=0.000100
[2025-08-10 22:54:57,524][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077520] [Batch 03680/03692] [00:33:24/00:00:06, 0.545s/it]: train_loss_raw=0.4743, running_loss=0.5189, LR=0.000100
[2025-08-10 22:55:03,860][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077532] [Batch 03692/03692] [00:33:30/00:00:00, 0.545s/it]: train_loss_raw=0.6126, running_loss=0.5197, LR=0.000100
[2025-08-10 22:55:09,092][__main__][INFO] - [VALIDATION] [Epoch 20/29] Starting validation.
[2025-08-10 22:55:42,274][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 077533] [Batch 00011/00025] [00:00:33/00:00:35, 2.765s/it]
[2025-08-10 22:55:56,855][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 077533] [Batch 00023/00025] [00:00:47/00:00:01, 1.990s/it]
[2025-08-10 22:55:57,850][__main__][INFO] - [VALIDATION] [Epoch 20/29] train_loss=0.51966, valid_loss=0.60788
[2025-08-10 22:55:57,850][__main__][INFO] - [VALIDATION] [Epoch 20/29] Metrics:
[2025-08-10 22:55:57,851][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_er      0.255
[2025-08-10 22:55:57,851][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_prec    0.515
[2025-08-10 22:55:57,851][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_recall  0.517
[2025-08-10 22:55:57,851][__main__][INFO] - [VALIDATION] [Epoch 20/29] - pep_recall 0.499
[2025-08-10 22:55:57,854][__main__][INFO] - [TRAIN] [Epoch 20/29] Epoch complete, total time 11:59:57, remaining time 05:08:33, 00:34:17 per epoch
[2025-08-10 22:56:04,100][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077544] [Batch 00012/03692] [00:00:06/00:30:50, 0.503s/it]: train_loss_raw=0.5064, running_loss=0.4188, LR=0.000100
[2025-08-10 22:56:10,590][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077556] [Batch 00024/03692] [00:00:12/00:31:54, 0.522s/it]: train_loss_raw=0.4276, running_loss=0.4291, LR=0.000100
[2025-08-10 22:56:17,041][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077568] [Batch 00036/03692] [00:00:18/00:32:07, 0.527s/it]: train_loss_raw=0.4945, running_loss=0.4422, LR=0.000100
[2025-08-10 22:56:23,449][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077580] [Batch 00048/03692] [00:00:25/00:32:07, 0.529s/it]: train_loss_raw=0.6356, running_loss=0.4483, LR=0.000100
[2025-08-10 22:56:29,473][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077592] [Batch 00060/03692] [00:00:31/00:31:41, 0.523s/it]: train_loss_raw=0.5414, running_loss=0.4566, LR=0.000100
[2025-08-10 22:56:35,852][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077604] [Batch 00072/03692] [00:00:37/00:31:39, 0.525s/it]: train_loss_raw=0.5548, running_loss=0.4642, LR=0.000100
[2025-08-10 22:56:42,401][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077616] [Batch 00084/03692] [00:00:44/00:31:44, 0.528s/it]: train_loss_raw=0.4768, running_loss=0.4692, LR=0.000100
[2025-08-10 22:56:48,928][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077628] [Batch 00096/03692] [00:00:50/00:31:45, 0.530s/it]: train_loss_raw=0.4505, running_loss=0.4753, LR=0.000100
[2025-08-10 22:56:55,424][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077640] [Batch 00108/03692] [00:00:57/00:31:43, 0.531s/it]: train_loss_raw=0.5218, running_loss=0.4782, LR=0.000100
[2025-08-10 22:57:01,936][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077652] [Batch 00120/03692] [00:01:03/00:31:41, 0.532s/it]: train_loss_raw=0.4896, running_loss=0.4838, LR=0.000100
[2025-08-10 22:57:08,437][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077664] [Batch 00132/03692] [00:01:10/00:31:37, 0.533s/it]: train_loss_raw=0.5666, running_loss=0.4865, LR=0.000100
[2025-08-10 22:57:14,909][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077676] [Batch 00144/03692] [00:01:16/00:31:33, 0.534s/it]: train_loss_raw=0.4264, running_loss=0.4900, LR=0.000100
[2025-08-10 22:57:21,311][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077688] [Batch 00156/03692] [00:01:23/00:31:26, 0.534s/it]: train_loss_raw=0.5001, running_loss=0.4932, LR=0.000100
[2025-08-10 22:57:27,696][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077700] [Batch 00168/03692] [00:01:29/00:31:20, 0.534s/it]: train_loss_raw=0.5469, running_loss=0.4943, LR=0.000100
[2025-08-10 22:57:34,075][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077712] [Batch 00180/03692] [00:01:36/00:31:13, 0.533s/it]: train_loss_raw=0.4107, running_loss=0.4958, LR=0.000100
[2025-08-10 22:57:40,625][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077724] [Batch 00192/03692] [00:01:42/00:31:09, 0.534s/it]: train_loss_raw=0.4552, running_loss=0.4973, LR=0.000100
[2025-08-10 22:57:47,045][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077736] [Batch 00204/03692] [00:01:48/00:31:03, 0.534s/it]: train_loss_raw=0.4521, running_loss=0.5014, LR=0.000100
[2025-08-10 22:57:53,466][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077748] [Batch 00216/03692] [00:01:55/00:30:57, 0.534s/it]: train_loss_raw=0.4946, running_loss=0.5033, LR=0.000100
[2025-08-10 22:57:59,791][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077760] [Batch 00228/03692] [00:02:01/00:30:49, 0.534s/it]: train_loss_raw=0.4516, running_loss=0.5042, LR=0.000100
[2025-08-10 22:58:06,290][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077772] [Batch 00240/03692] [00:02:08/00:30:44, 0.534s/it]: train_loss_raw=0.5043, running_loss=0.5077, LR=0.000100
[2025-08-10 22:58:12,650][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077784] [Batch 00252/03692] [00:02:14/00:30:37, 0.534s/it]: train_loss_raw=0.5843, running_loss=0.5111, LR=0.000100
[2025-08-10 22:58:19,113][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077796] [Batch 00264/03692] [00:02:21/00:30:31, 0.534s/it]: train_loss_raw=0.5385, running_loss=0.5116, LR=0.000100
[2025-08-10 22:58:25,681][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077808] [Batch 00276/03692] [00:02:27/00:30:27, 0.535s/it]: train_loss_raw=0.4892, running_loss=0.5095, LR=0.000100
[2025-08-10 22:58:32,333][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077820] [Batch 00288/03692] [00:02:34/00:30:23, 0.536s/it]: train_loss_raw=0.5960, running_loss=0.5145, LR=0.000100
[2025-08-10 22:58:38,882][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077832] [Batch 00300/03692] [00:02:40/00:30:18, 0.536s/it]: train_loss_raw=0.4820, running_loss=0.5108, LR=0.000100
[2025-08-10 22:58:45,353][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077844] [Batch 00312/03692] [00:02:47/00:30:12, 0.536s/it]: train_loss_raw=0.5786, running_loss=0.5127, LR=0.000100
[2025-08-10 22:58:51,525][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077856] [Batch 00324/03692] [00:02:53/00:30:03, 0.535s/it]: train_loss_raw=0.4581, running_loss=0.5119, LR=0.000100
[2025-08-10 22:58:58,093][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077868] [Batch 00336/03692] [00:03:00/00:29:58, 0.536s/it]: train_loss_raw=0.4182, running_loss=0.5153, LR=0.000100
[2025-08-10 22:59:04,675][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077880] [Batch 00348/03692] [00:03:06/00:29:53, 0.536s/it]: train_loss_raw=0.5485, running_loss=0.5163, LR=0.000100
[2025-08-10 22:59:11,201][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077892] [Batch 00360/03692] [00:03:13/00:29:47, 0.536s/it]: train_loss_raw=0.5639, running_loss=0.5164, LR=0.000100
[2025-08-10 22:59:17,770][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077904] [Batch 00372/03692] [00:03:19/00:29:42, 0.537s/it]: train_loss_raw=0.6329, running_loss=0.5179, LR=0.000100
[2025-08-10 22:59:24,278][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077916] [Batch 00384/03692] [00:03:26/00:29:36, 0.537s/it]: train_loss_raw=0.4708, running_loss=0.5151, LR=0.000100
[2025-08-10 22:59:30,821][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077928] [Batch 00396/03692] [00:03:32/00:29:30, 0.537s/it]: train_loss_raw=0.5072, running_loss=0.5158, LR=0.000100
[2025-08-10 22:59:37,320][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077940] [Batch 00408/03692] [00:03:39/00:29:24, 0.537s/it]: train_loss_raw=0.5722, running_loss=0.5133, LR=0.000100
[2025-08-10 22:59:43,753][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077952] [Batch 00420/03692] [00:03:45/00:29:18, 0.537s/it]: train_loss_raw=0.5852, running_loss=0.5132, LR=0.000100
[2025-08-10 22:59:50,284][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077964] [Batch 00432/03692] [00:03:52/00:29:12, 0.538s/it]: train_loss_raw=0.4903, running_loss=0.5130, LR=0.000100
[2025-08-10 22:59:56,675][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077976] [Batch 00444/03692] [00:03:58/00:29:05, 0.537s/it]: train_loss_raw=0.5836, running_loss=0.5126, LR=0.000100
[2025-08-10 23:00:03,038][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077988] [Batch 00456/03692] [00:04:04/00:28:58, 0.537s/it]: train_loss_raw=0.5185, running_loss=0.5157, LR=0.000100
[2025-08-10 23:00:09,402][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078000] [Batch 00468/03692] [00:04:11/00:28:51, 0.537s/it]: train_loss_raw=0.5317, running_loss=0.5181, LR=0.000100
[2025-08-10 23:00:20,309][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078012] [Batch 00480/03692] [00:04:22/00:29:14, 0.546s/it]: train_loss_raw=0.5038, running_loss=0.5179, LR=0.000100
[2025-08-10 23:00:26,745][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078024] [Batch 00492/03692] [00:04:28/00:29:07, 0.546s/it]: train_loss_raw=0.5138, running_loss=0.5148, LR=0.000100
[2025-08-10 23:00:33,218][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078036] [Batch 00504/03692] [00:04:35/00:29:00, 0.546s/it]: train_loss_raw=0.4941, running_loss=0.5157, LR=0.000100
[2025-08-10 23:00:39,581][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078048] [Batch 00516/03692] [00:04:41/00:28:52, 0.546s/it]: train_loss_raw=0.4122, running_loss=0.5142, LR=0.000100
[2025-08-10 23:00:46,002][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078060] [Batch 00528/03692] [00:04:47/00:28:45, 0.545s/it]: train_loss_raw=0.5501, running_loss=0.5155, LR=0.000100
[2025-08-10 23:00:52,482][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078072] [Batch 00540/03692] [00:04:54/00:28:38, 0.545s/it]: train_loss_raw=0.5281, running_loss=0.5137, LR=0.000100
[2025-08-10 23:00:58,818][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078084] [Batch 00552/03692] [00:05:00/00:28:30, 0.545s/it]: train_loss_raw=0.5727, running_loss=0.5105, LR=0.000100
[2025-08-10 23:01:05,230][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078096] [Batch 00564/03692] [00:05:07/00:28:23, 0.545s/it]: train_loss_raw=0.5867, running_loss=0.5117, LR=0.000100
[2025-08-10 23:01:11,674][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078108] [Batch 00576/03692] [00:05:13/00:28:16, 0.544s/it]: train_loss_raw=0.6564, running_loss=0.5125, LR=0.000100
[2025-08-10 23:01:17,997][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078120] [Batch 00588/03692] [00:05:19/00:28:08, 0.544s/it]: train_loss_raw=0.5224, running_loss=0.5134, LR=0.000100
[2025-08-10 23:01:24,416][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078132] [Batch 00600/03692] [00:05:26/00:28:01, 0.544s/it]: train_loss_raw=0.4434, running_loss=0.5120, LR=0.000100
[2025-08-10 23:01:30,808][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078144] [Batch 00612/03692] [00:05:32/00:27:54, 0.544s/it]: train_loss_raw=0.5958, running_loss=0.5101, LR=0.000100
[2025-08-10 23:01:37,360][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078156] [Batch 00624/03692] [00:05:39/00:27:48, 0.544s/it]: train_loss_raw=0.6188, running_loss=0.5105, LR=0.000100
[2025-08-10 23:01:43,897][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078168] [Batch 00636/03692] [00:05:45/00:27:41, 0.544s/it]: train_loss_raw=0.4970, running_loss=0.5112, LR=0.000100
[2025-08-10 23:01:50,382][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078180] [Batch 00648/03692] [00:05:52/00:27:35, 0.544s/it]: train_loss_raw=0.5014, running_loss=0.5155, LR=0.000100
[2025-08-10 23:01:56,843][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078192] [Batch 00660/03692] [00:05:58/00:27:28, 0.544s/it]: train_loss_raw=0.4766, running_loss=0.5162, LR=0.000100
[2025-08-10 23:02:03,265][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078204] [Batch 00672/03692] [00:06:05/00:27:21, 0.543s/it]: train_loss_raw=0.4482, running_loss=0.5172, LR=0.000100
[2025-08-10 23:02:09,636][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078216] [Batch 00684/03692] [00:06:11/00:27:14, 0.543s/it]: train_loss_raw=0.6072, running_loss=0.5154, LR=0.000100
[2025-08-10 23:02:16,053][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078228] [Batch 00696/03692] [00:06:17/00:27:07, 0.543s/it]: train_loss_raw=0.5484, running_loss=0.5192, LR=0.000100
[2025-08-10 23:02:22,447][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078240] [Batch 00708/03692] [00:06:24/00:27:00, 0.543s/it]: train_loss_raw=0.4539, running_loss=0.5187, LR=0.000100
[2025-08-10 23:02:28,938][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078252] [Batch 00720/03692] [00:06:30/00:26:53, 0.543s/it]: train_loss_raw=0.4624, running_loss=0.5153, LR=0.000100
[2025-08-10 23:02:35,397][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078264] [Batch 00732/03692] [00:06:37/00:26:46, 0.543s/it]: train_loss_raw=0.4557, running_loss=0.5129, LR=0.000100
[2025-08-10 23:02:41,782][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078276] [Batch 00744/03692] [00:06:43/00:26:39, 0.543s/it]: train_loss_raw=0.5265, running_loss=0.5139, LR=0.000100
[2025-08-10 23:02:48,319][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078288] [Batch 00756/03692] [00:06:50/00:26:33, 0.543s/it]: train_loss_raw=0.4775, running_loss=0.5134, LR=0.000100
[2025-08-10 23:02:54,851][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078300] [Batch 00768/03692] [00:06:56/00:26:26, 0.543s/it]: train_loss_raw=0.4891, running_loss=0.5135, LR=0.000100
[2025-08-10 23:03:01,229][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078312] [Batch 00780/03692] [00:07:03/00:26:19, 0.543s/it]: train_loss_raw=0.5493, running_loss=0.5132, LR=0.000100
[2025-08-10 23:03:07,622][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078324] [Batch 00792/03692] [00:07:09/00:26:12, 0.542s/it]: train_loss_raw=0.4957, running_loss=0.5164, LR=0.000100
[2025-08-10 23:03:13,964][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078336] [Batch 00804/03692] [00:07:15/00:26:05, 0.542s/it]: train_loss_raw=0.5437, running_loss=0.5154, LR=0.000100
[2025-08-10 23:03:20,344][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078348] [Batch 00816/03692] [00:07:22/00:25:58, 0.542s/it]: train_loss_raw=0.5460, running_loss=0.5146, LR=0.000100
[2025-08-10 23:03:26,770][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078360] [Batch 00828/03692] [00:07:28/00:25:52, 0.542s/it]: train_loss_raw=0.5261, running_loss=0.5122, LR=0.000100
[2025-08-10 23:03:33,258][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078372] [Batch 00840/03692] [00:07:35/00:25:45, 0.542s/it]: train_loss_raw=0.4808, running_loss=0.5101, LR=0.000100
[2025-08-10 23:03:39,511][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078384] [Batch 00852/03692] [00:07:41/00:25:38, 0.542s/it]: train_loss_raw=0.3858, running_loss=0.5100, LR=0.000100
[2025-08-10 23:03:45,864][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078396] [Batch 00864/03692] [00:07:47/00:25:31, 0.541s/it]: train_loss_raw=0.5679, running_loss=0.5094, LR=0.000100
[2025-08-10 23:03:52,232][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078408] [Batch 00876/03692] [00:07:54/00:25:24, 0.541s/it]: train_loss_raw=0.4679, running_loss=0.5085, LR=0.000100
[2025-08-10 23:03:58,560][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078420] [Batch 00888/03692] [00:08:00/00:25:17, 0.541s/it]: train_loss_raw=0.6005, running_loss=0.5108, LR=0.000100
[2025-08-10 23:04:04,938][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078432] [Batch 00900/03692] [00:08:06/00:25:10, 0.541s/it]: train_loss_raw=0.5820, running_loss=0.5120, LR=0.000100
[2025-08-10 23:04:11,279][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078444] [Batch 00912/03692] [00:08:13/00:25:03, 0.541s/it]: train_loss_raw=0.5172, running_loss=0.5142, LR=0.000100
[2025-08-10 23:04:17,612][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078456] [Batch 00924/03692] [00:08:19/00:24:56, 0.541s/it]: train_loss_raw=0.4349, running_loss=0.5119, LR=0.000100
[2025-08-10 23:04:24,042][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078468] [Batch 00936/03692] [00:08:25/00:24:49, 0.541s/it]: train_loss_raw=0.4325, running_loss=0.5105, LR=0.000100
[2025-08-10 23:04:30,479][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078480] [Batch 00948/03692] [00:08:32/00:24:43, 0.541s/it]: train_loss_raw=0.6707, running_loss=0.5130, LR=0.000100
[2025-08-10 23:04:36,886][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078492] [Batch 00960/03692] [00:08:38/00:24:36, 0.540s/it]: train_loss_raw=0.4400, running_loss=0.5106, LR=0.000100
[2025-08-10 23:04:43,290][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078504] [Batch 00972/03692] [00:08:45/00:24:29, 0.540s/it]: train_loss_raw=0.6116, running_loss=0.5101, LR=0.000100
[2025-08-10 23:04:49,662][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078516] [Batch 00984/03692] [00:08:51/00:24:22, 0.540s/it]: train_loss_raw=0.5270, running_loss=0.5089, LR=0.000100
[2025-08-10 23:04:55,994][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078528] [Batch 00996/03692] [00:08:57/00:24:16, 0.540s/it]: train_loss_raw=0.5876, running_loss=0.5075, LR=0.000100
[2025-08-10 23:05:02,407][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078540] [Batch 01008/03692] [00:09:04/00:24:09, 0.540s/it]: train_loss_raw=0.5013, running_loss=0.5095, LR=0.000100
[2025-08-10 23:05:09,007][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078552] [Batch 01020/03692] [00:09:10/00:24:03, 0.540s/it]: train_loss_raw=0.6046, running_loss=0.5088, LR=0.000100
[2025-08-10 23:05:15,539][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078564] [Batch 01032/03692] [00:09:17/00:23:56, 0.540s/it]: train_loss_raw=0.5823, running_loss=0.5079, LR=0.000100
[2025-08-10 23:05:21,940][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078576] [Batch 01044/03692] [00:09:23/00:23:50, 0.540s/it]: train_loss_raw=0.5949, running_loss=0.5092, LR=0.000100
[2025-08-10 23:05:28,331][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078588] [Batch 01056/03692] [00:09:30/00:23:43, 0.540s/it]: train_loss_raw=0.4490, running_loss=0.5088, LR=0.000100
[2025-08-10 23:05:34,586][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078600] [Batch 01068/03692] [00:09:36/00:23:36, 0.540s/it]: train_loss_raw=0.5404, running_loss=0.5084, LR=0.000100
[2025-08-10 23:05:40,962][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078612] [Batch 01080/03692] [00:09:42/00:23:29, 0.540s/it]: train_loss_raw=0.5439, running_loss=0.5078, LR=0.000100
[2025-08-10 23:05:47,409][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078624] [Batch 01092/03692] [00:09:49/00:23:23, 0.540s/it]: train_loss_raw=0.4468, running_loss=0.5090, LR=0.000100
[2025-08-10 23:05:53,762][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078636] [Batch 01104/03692] [00:09:55/00:23:16, 0.540s/it]: train_loss_raw=0.6469, running_loss=0.5079, LR=0.000100
[2025-08-10 23:06:00,094][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078648] [Batch 01116/03692] [00:10:02/00:23:09, 0.539s/it]: train_loss_raw=0.4142, running_loss=0.5071, LR=0.000100
[2025-08-10 23:06:06,533][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078660] [Batch 01128/03692] [00:10:08/00:23:03, 0.539s/it]: train_loss_raw=0.6665, running_loss=0.5073, LR=0.000100
[2025-08-10 23:06:13,060][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078672] [Batch 01140/03692] [00:10:14/00:22:56, 0.539s/it]: train_loss_raw=0.5001, running_loss=0.5082, LR=0.000100
[2025-08-10 23:06:19,568][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078684] [Batch 01152/03692] [00:10:21/00:22:50, 0.539s/it]: train_loss_raw=0.5000, running_loss=0.5118, LR=0.000100
[2025-08-10 23:06:26,026][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078696] [Batch 01164/03692] [00:10:27/00:22:43, 0.539s/it]: train_loss_raw=0.5273, running_loss=0.5099, LR=0.000100
[2025-08-10 23:06:32,529][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078708] [Batch 01176/03692] [00:10:34/00:22:37, 0.540s/it]: train_loss_raw=0.5515, running_loss=0.5120, LR=0.000100
[2025-08-10 23:06:38,921][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078720] [Batch 01188/03692] [00:10:40/00:22:30, 0.539s/it]: train_loss_raw=0.5915, running_loss=0.5135, LR=0.000100
[2025-08-10 23:06:45,408][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078732] [Batch 01200/03692] [00:10:47/00:22:24, 0.539s/it]: train_loss_raw=0.4569, running_loss=0.5112, LR=0.000100
[2025-08-10 23:06:51,814][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078744] [Batch 01212/03692] [00:10:53/00:22:17, 0.539s/it]: train_loss_raw=0.4043, running_loss=0.5085, LR=0.000100
[2025-08-10 23:06:58,234][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078756] [Batch 01224/03692] [00:11:00/00:22:11, 0.539s/it]: train_loss_raw=0.4497, running_loss=0.5075, LR=0.000100
[2025-08-10 23:07:04,620][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078768] [Batch 01236/03692] [00:11:06/00:22:04, 0.539s/it]: train_loss_raw=0.5791, running_loss=0.5070, LR=0.000100
[2025-08-10 23:07:11,022][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078780] [Batch 01248/03692] [00:11:12/00:21:57, 0.539s/it]: train_loss_raw=0.5067, running_loss=0.5054, LR=0.000100
[2025-08-10 23:07:17,412][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078792] [Batch 01260/03692] [00:11:19/00:21:51, 0.539s/it]: train_loss_raw=0.5476, running_loss=0.5050, LR=0.000100
[2025-08-10 23:07:23,766][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078804] [Batch 01272/03692] [00:11:25/00:21:44, 0.539s/it]: train_loss_raw=0.5581, running_loss=0.5056, LR=0.000100
[2025-08-10 23:07:30,297][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078816] [Batch 01284/03692] [00:11:32/00:21:38, 0.539s/it]: train_loss_raw=0.4519, running_loss=0.5058, LR=0.000100
[2025-08-10 23:07:36,849][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078828] [Batch 01296/03692] [00:11:38/00:21:31, 0.539s/it]: train_loss_raw=0.5759, running_loss=0.5041, LR=0.000100
[2025-08-10 23:07:43,303][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078840] [Batch 01308/03692] [00:11:45/00:21:25, 0.539s/it]: train_loss_raw=0.4918, running_loss=0.5068, LR=0.000100
[2025-08-10 23:07:49,849][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078852] [Batch 01320/03692] [00:11:51/00:21:19, 0.539s/it]: train_loss_raw=0.5169, running_loss=0.5061, LR=0.000100
[2025-08-10 23:07:56,443][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078864] [Batch 01332/03692] [00:11:58/00:21:12, 0.539s/it]: train_loss_raw=0.5824, running_loss=0.5066, LR=0.000100
[2025-08-10 23:08:02,964][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078876] [Batch 01344/03692] [00:12:04/00:21:06, 0.539s/it]: train_loss_raw=0.5429, running_loss=0.5084, LR=0.000100
[2025-08-10 23:08:09,155][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078888] [Batch 01356/03692] [00:12:11/00:20:59, 0.539s/it]: train_loss_raw=0.5079, running_loss=0.5066, LR=0.000100
[2025-08-10 23:08:15,555][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078900] [Batch 01368/03692] [00:12:17/00:20:52, 0.539s/it]: train_loss_raw=0.5682, running_loss=0.5063, LR=0.000100
[2025-08-10 23:08:22,010][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078912] [Batch 01380/03692] [00:12:23/00:20:46, 0.539s/it]: train_loss_raw=0.5867, running_loss=0.5061, LR=0.000100
[2025-08-10 23:08:28,491][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078924] [Batch 01392/03692] [00:12:30/00:20:39, 0.539s/it]: train_loss_raw=0.4618, running_loss=0.5047, LR=0.000100
[2025-08-10 23:08:35,084][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078936] [Batch 01404/03692] [00:12:37/00:20:33, 0.539s/it]: train_loss_raw=0.4497, running_loss=0.5087, LR=0.000100
[2025-08-10 23:08:41,552][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078948] [Batch 01416/03692] [00:12:43/00:20:27, 0.539s/it]: train_loss_raw=0.4491, running_loss=0.5088, LR=0.000100
[2025-08-10 23:08:48,055][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078960] [Batch 01428/03692] [00:12:49/00:20:20, 0.539s/it]: train_loss_raw=0.5721, running_loss=0.5051, LR=0.000100
[2025-08-10 23:08:54,526][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078972] [Batch 01440/03692] [00:12:56/00:20:14, 0.539s/it]: train_loss_raw=0.5255, running_loss=0.5054, LR=0.000100
[2025-08-10 23:09:00,871][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078984] [Batch 01452/03692] [00:13:02/00:20:07, 0.539s/it]: train_loss_raw=0.4392, running_loss=0.5065, LR=0.000100
[2025-08-10 23:09:07,233][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078996] [Batch 01464/03692] [00:13:09/00:20:01, 0.539s/it]: train_loss_raw=0.5397, running_loss=0.5080, LR=0.000100
[2025-08-10 23:09:13,592][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079008] [Batch 01476/03692] [00:13:15/00:19:54, 0.539s/it]: train_loss_raw=0.5202, running_loss=0.5099, LR=0.000100
[2025-08-10 23:09:19,936][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079020] [Batch 01488/03692] [00:13:21/00:19:47, 0.539s/it]: train_loss_raw=0.5239, running_loss=0.5074, LR=0.000100
[2025-08-10 23:09:26,338][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079032] [Batch 01500/03692] [00:13:28/00:19:41, 0.539s/it]: train_loss_raw=0.4635, running_loss=0.5048, LR=0.000100
[2025-08-10 23:09:32,876][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079044] [Batch 01512/03692] [00:13:34/00:19:34, 0.539s/it]: train_loss_raw=0.5038, running_loss=0.5075, LR=0.000100
[2025-08-10 23:09:39,269][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079056] [Batch 01524/03692] [00:13:41/00:19:28, 0.539s/it]: train_loss_raw=0.5150, running_loss=0.5056, LR=0.000100
[2025-08-10 23:09:45,695][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079068] [Batch 01536/03692] [00:13:47/00:19:21, 0.539s/it]: train_loss_raw=0.5081, running_loss=0.5059, LR=0.000100
[2025-08-10 23:09:52,029][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079080] [Batch 01548/03692] [00:13:53/00:19:15, 0.539s/it]: train_loss_raw=0.4616, running_loss=0.5067, LR=0.000100
[2025-08-10 23:09:58,385][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079092] [Batch 01560/03692] [00:14:00/00:19:08, 0.539s/it]: train_loss_raw=0.5702, running_loss=0.5106, LR=0.000100
[2025-08-10 23:10:04,773][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079104] [Batch 01572/03692] [00:14:06/00:19:01, 0.539s/it]: train_loss_raw=0.5593, running_loss=0.5107, LR=0.000100
[2025-08-10 23:10:11,077][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079116] [Batch 01584/03692] [00:14:13/00:18:55, 0.539s/it]: train_loss_raw=0.5567, running_loss=0.5134, LR=0.000100
[2025-08-10 23:10:17,440][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079128] [Batch 01596/03692] [00:14:19/00:18:48, 0.538s/it]: train_loss_raw=0.4227, running_loss=0.5147, LR=0.000100
[2025-08-10 23:10:23,703][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079140] [Batch 01608/03692] [00:14:25/00:18:41, 0.538s/it]: train_loss_raw=0.4740, running_loss=0.5125, LR=0.000100
[2025-08-10 23:10:30,157][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079152] [Batch 01620/03692] [00:14:32/00:18:35, 0.538s/it]: train_loss_raw=0.5633, running_loss=0.5146, LR=0.000100
[2025-08-10 23:10:36,468][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079164] [Batch 01632/03692] [00:14:38/00:18:28, 0.538s/it]: train_loss_raw=0.5473, running_loss=0.5153, LR=0.000100
[2025-08-10 23:10:42,989][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079176] [Batch 01644/03692] [00:14:44/00:18:22, 0.538s/it]: train_loss_raw=0.4611, running_loss=0.5142, LR=0.000100
[2025-08-10 23:10:49,477][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079188] [Batch 01656/03692] [00:14:51/00:18:15, 0.538s/it]: train_loss_raw=0.5133, running_loss=0.5140, LR=0.000100
[2025-08-10 23:10:55,950][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079200] [Batch 01668/03692] [00:14:57/00:18:09, 0.538s/it]: train_loss_raw=0.5125, running_loss=0.5111, LR=0.000100
[2025-08-10 23:11:02,394][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079212] [Batch 01680/03692] [00:15:04/00:18:03, 0.538s/it]: train_loss_raw=0.5776, running_loss=0.5091, LR=0.000100
[2025-08-10 23:11:08,832][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079224] [Batch 01692/03692] [00:15:10/00:17:56, 0.538s/it]: train_loss_raw=0.4960, running_loss=0.5098, LR=0.000100
[2025-08-10 23:11:15,228][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079236] [Batch 01704/03692] [00:15:17/00:17:50, 0.538s/it]: train_loss_raw=0.4814, running_loss=0.5087, LR=0.000100
[2025-08-10 23:11:21,698][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079248] [Batch 01716/03692] [00:15:23/00:17:43, 0.538s/it]: train_loss_raw=0.5588, running_loss=0.5124, LR=0.000100
[2025-08-10 23:11:28,090][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079260] [Batch 01728/03692] [00:15:30/00:17:37, 0.538s/it]: train_loss_raw=0.4277, running_loss=0.5120, LR=0.000100
[2025-08-10 23:11:34,496][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079272] [Batch 01740/03692] [00:15:36/00:17:30, 0.538s/it]: train_loss_raw=0.5263, running_loss=0.5152, LR=0.000100
[2025-08-10 23:11:41,000][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079284] [Batch 01752/03692] [00:15:42/00:17:24, 0.538s/it]: train_loss_raw=0.5206, running_loss=0.5092, LR=0.000100
[2025-08-10 23:11:47,545][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079296] [Batch 01764/03692] [00:15:49/00:17:17, 0.538s/it]: train_loss_raw=0.5020, running_loss=0.5084, LR=0.000100
[2025-08-10 23:11:54,094][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079308] [Batch 01776/03692] [00:15:56/00:17:11, 0.538s/it]: train_loss_raw=0.5898, running_loss=0.5085, LR=0.000100
[2025-08-10 23:12:00,546][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079320] [Batch 01788/03692] [00:16:02/00:17:04, 0.538s/it]: train_loss_raw=0.6506, running_loss=0.5145, LR=0.000100
[2025-08-10 23:12:06,902][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079332] [Batch 01800/03692] [00:16:08/00:16:58, 0.538s/it]: train_loss_raw=0.5164, running_loss=0.5129, LR=0.000100
[2025-08-10 23:12:13,571][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079344] [Batch 01812/03692] [00:16:15/00:16:52, 0.538s/it]: train_loss_raw=0.4574, running_loss=0.5123, LR=0.000100
[2025-08-10 23:12:20,129][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079356] [Batch 01824/03692] [00:16:22/00:16:45, 0.538s/it]: train_loss_raw=0.5649, running_loss=0.5126, LR=0.000100
[2025-08-10 23:12:26,615][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079368] [Batch 01836/03692] [00:16:28/00:16:39, 0.538s/it]: train_loss_raw=0.5021, running_loss=0.5131, LR=0.000100
[2025-08-10 23:12:33,191][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079380] [Batch 01848/03692] [00:16:35/00:16:32, 0.538s/it]: train_loss_raw=0.5637, running_loss=0.5162, LR=0.000100
[2025-08-10 23:12:39,708][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079392] [Batch 01860/03692] [00:16:41/00:16:26, 0.539s/it]: train_loss_raw=0.4518, running_loss=0.5175, LR=0.000100
[2025-08-10 23:12:46,071][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079404] [Batch 01872/03692] [00:16:48/00:16:20, 0.538s/it]: train_loss_raw=0.5032, running_loss=0.5157, LR=0.000100
[2025-08-10 23:12:52,514][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079416] [Batch 01884/03692] [00:16:54/00:16:13, 0.538s/it]: train_loss_raw=0.5108, running_loss=0.5166, LR=0.000100
[2025-08-10 23:12:59,038][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079428] [Batch 01896/03692] [00:17:00/00:16:07, 0.538s/it]: train_loss_raw=0.4891, running_loss=0.5155, LR=0.000100
[2025-08-10 23:13:05,448][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079440] [Batch 01908/03692] [00:17:07/00:16:00, 0.538s/it]: train_loss_raw=0.5008, running_loss=0.5128, LR=0.000100
[2025-08-10 23:13:11,885][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079452] [Batch 01920/03692] [00:17:13/00:15:54, 0.538s/it]: train_loss_raw=0.4826, running_loss=0.5128, LR=0.000100
[2025-08-10 23:13:18,356][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079464] [Batch 01932/03692] [00:17:20/00:15:47, 0.538s/it]: train_loss_raw=0.5665, running_loss=0.5108, LR=0.000100
[2025-08-10 23:13:24,752][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079476] [Batch 01944/03692] [00:17:26/00:15:41, 0.538s/it]: train_loss_raw=0.6178, running_loss=0.5109, LR=0.000100
[2025-08-10 23:13:31,126][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079488] [Batch 01956/03692] [00:17:33/00:15:34, 0.538s/it]: train_loss_raw=0.5203, running_loss=0.5098, LR=0.000100
[2025-08-10 23:13:37,574][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079500] [Batch 01968/03692] [00:17:39/00:15:28, 0.538s/it]: train_loss_raw=0.5142, running_loss=0.5081, LR=0.000100
[2025-08-10 23:13:43,952][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079512] [Batch 01980/03692] [00:17:45/00:15:21, 0.538s/it]: train_loss_raw=0.5674, running_loss=0.5038, LR=0.000100
[2025-08-10 23:13:50,358][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079524] [Batch 01992/03692] [00:17:52/00:15:15, 0.538s/it]: train_loss_raw=0.4812, running_loss=0.5030, LR=0.000100
[2025-08-10 23:13:56,744][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079536] [Batch 02004/03692] [00:17:58/00:15:08, 0.538s/it]: train_loss_raw=0.4670, running_loss=0.5062, LR=0.000100
[2025-08-10 23:14:03,171][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079548] [Batch 02016/03692] [00:18:05/00:15:02, 0.538s/it]: train_loss_raw=0.5148, running_loss=0.5060, LR=0.000100
[2025-08-10 23:14:09,684][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079560] [Batch 02028/03692] [00:18:11/00:14:55, 0.538s/it]: train_loss_raw=0.5039, running_loss=0.5059, LR=0.000100
[2025-08-10 23:14:16,278][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079572] [Batch 02040/03692] [00:18:18/00:14:49, 0.538s/it]: train_loss_raw=0.4399, running_loss=0.5063, LR=0.000100
[2025-08-10 23:14:22,740][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079584] [Batch 02052/03692] [00:18:24/00:14:42, 0.538s/it]: train_loss_raw=0.5879, running_loss=0.5081, LR=0.000100
[2025-08-10 23:14:29,183][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079596] [Batch 02064/03692] [00:18:31/00:14:36, 0.538s/it]: train_loss_raw=0.5291, running_loss=0.5076, LR=0.000100
[2025-08-10 23:14:35,279][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079608] [Batch 02076/03692] [00:18:37/00:14:29, 0.538s/it]: train_loss_raw=0.5487, running_loss=0.5087, LR=0.000100
[2025-08-10 23:14:41,190][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079620] [Batch 02088/03692] [00:18:43/00:14:22, 0.538s/it]: train_loss_raw=0.5543, running_loss=0.5098, LR=0.000100
[2025-08-10 23:14:47,588][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079632] [Batch 02100/03692] [00:18:49/00:14:16, 0.538s/it]: train_loss_raw=0.4974, running_loss=0.5086, LR=0.000100
[2025-08-10 23:14:54,126][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079644] [Batch 02112/03692] [00:18:56/00:14:09, 0.538s/it]: train_loss_raw=0.4444, running_loss=0.5078, LR=0.000100
[2025-08-10 23:15:00,668][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079656] [Batch 02124/03692] [00:19:02/00:14:03, 0.538s/it]: train_loss_raw=0.4848, running_loss=0.5092, LR=0.000100
[2025-08-10 23:15:07,230][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079668] [Batch 02136/03692] [00:19:09/00:13:57, 0.538s/it]: train_loss_raw=0.4717, running_loss=0.5126, LR=0.000100
[2025-08-10 23:15:13,747][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079680] [Batch 02148/03692] [00:19:15/00:13:50, 0.538s/it]: train_loss_raw=0.4832, running_loss=0.5140, LR=0.000100
[2025-08-10 23:15:26,865][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079692] [Batch 02160/03692] [00:19:28/00:13:48, 0.541s/it]: train_loss_raw=0.5416, running_loss=0.5156, LR=0.000100
[2025-08-10 23:15:33,165][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079704] [Batch 02172/03692] [00:19:35/00:13:42, 0.541s/it]: train_loss_raw=0.4277, running_loss=0.5131, LR=0.000100
[2025-08-10 23:15:39,726][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079716] [Batch 02184/03692] [00:19:41/00:13:35, 0.541s/it]: train_loss_raw=0.4076, running_loss=0.5159, LR=0.000100
[2025-08-10 23:15:46,218][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079728] [Batch 02196/03692] [00:19:48/00:13:29, 0.541s/it]: train_loss_raw=0.4295, running_loss=0.5092, LR=0.000100
[2025-08-10 23:15:52,718][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079740] [Batch 02208/03692] [00:19:54/00:13:22, 0.541s/it]: train_loss_raw=0.5404, running_loss=0.5086, LR=0.000100
[2025-08-10 23:15:59,047][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079752] [Batch 02220/03692] [00:20:00/00:13:16, 0.541s/it]: train_loss_raw=0.4999, running_loss=0.5065, LR=0.000100
[2025-08-10 23:16:05,681][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079764] [Batch 02232/03692] [00:20:07/00:13:09, 0.541s/it]: train_loss_raw=0.4676, running_loss=0.5035, LR=0.000100
[2025-08-10 23:16:11,797][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079776] [Batch 02244/03692] [00:20:13/00:13:03, 0.541s/it]: train_loss_raw=0.5154, running_loss=0.5030, LR=0.000100
[2025-08-10 23:16:17,948][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079788] [Batch 02256/03692] [00:20:19/00:12:56, 0.541s/it]: train_loss_raw=0.5025, running_loss=0.5047, LR=0.000100
[2025-08-10 23:16:24,421][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079800] [Batch 02268/03692] [00:20:26/00:12:49, 0.541s/it]: train_loss_raw=0.5222, running_loss=0.5042, LR=0.000100
[2025-08-10 23:16:30,890][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079812] [Batch 02280/03692] [00:20:32/00:12:43, 0.541s/it]: train_loss_raw=0.5418, running_loss=0.5015, LR=0.000100
[2025-08-10 23:16:37,367][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079824] [Batch 02292/03692] [00:20:39/00:12:36, 0.541s/it]: train_loss_raw=0.5508, running_loss=0.5001, LR=0.000100
[2025-08-10 23:16:43,880][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079836] [Batch 02304/03692] [00:20:45/00:12:30, 0.541s/it]: train_loss_raw=0.5403, running_loss=0.5013, LR=0.000100
[2025-08-10 23:16:50,312][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079848] [Batch 02316/03692] [00:20:52/00:12:23, 0.541s/it]: train_loss_raw=0.5344, running_loss=0.4995, LR=0.000100
[2025-08-10 23:16:56,490][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079860] [Batch 02328/03692] [00:20:58/00:12:17, 0.541s/it]: train_loss_raw=0.5256, running_loss=0.5022, LR=0.000100
[2025-08-10 23:17:02,947][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079872] [Batch 02340/03692] [00:21:04/00:12:10, 0.541s/it]: train_loss_raw=0.6266, running_loss=0.5049, LR=0.000100
[2025-08-10 23:17:09,416][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079884] [Batch 02352/03692] [00:21:11/00:12:04, 0.541s/it]: train_loss_raw=0.4949, running_loss=0.5065, LR=0.000100
[2025-08-10 23:17:15,830][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079896] [Batch 02364/03692] [00:21:17/00:11:57, 0.541s/it]: train_loss_raw=0.5128, running_loss=0.5039, LR=0.000100
[2025-08-10 23:17:22,381][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079908] [Batch 02376/03692] [00:21:24/00:11:51, 0.541s/it]: train_loss_raw=0.4982, running_loss=0.5005, LR=0.000100
[2025-08-10 23:17:28,907][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079920] [Batch 02388/03692] [00:21:30/00:11:44, 0.541s/it]: train_loss_raw=0.5170, running_loss=0.5026, LR=0.000100
[2025-08-10 23:17:35,399][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079932] [Batch 02400/03692] [00:21:37/00:11:38, 0.541s/it]: train_loss_raw=0.5284, running_loss=0.5047, LR=0.000100
[2025-08-10 23:17:41,825][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079944] [Batch 02412/03692] [00:21:43/00:11:31, 0.541s/it]: train_loss_raw=0.5658, running_loss=0.5076, LR=0.000100
[2025-08-10 23:17:48,283][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079956] [Batch 02424/03692] [00:21:50/00:11:25, 0.541s/it]: train_loss_raw=0.6467, running_loss=0.5068, LR=0.000100
[2025-08-10 23:17:54,778][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079968] [Batch 02436/03692] [00:21:56/00:11:18, 0.541s/it]: train_loss_raw=0.3671, running_loss=0.5056, LR=0.000100
[2025-08-10 23:18:01,353][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079980] [Batch 02448/03692] [00:22:03/00:11:12, 0.541s/it]: train_loss_raw=0.5077, running_loss=0.5080, LR=0.000100
[2025-08-10 23:18:07,845][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079992] [Batch 02460/03692] [00:22:09/00:11:05, 0.541s/it]: train_loss_raw=0.5731, running_loss=0.5061, LR=0.000100
[2025-08-10 23:18:18,742][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080004] [Batch 02472/03692] [00:22:20/00:11:01, 0.542s/it]: train_loss_raw=0.5134, running_loss=0.5062, LR=0.000100
[2025-08-10 23:18:25,186][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080016] [Batch 02484/03692] [00:22:27/00:10:55, 0.542s/it]: train_loss_raw=0.4230, running_loss=0.5009, LR=0.000100
[2025-08-10 23:18:31,576][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080028] [Batch 02496/03692] [00:22:33/00:10:48, 0.542s/it]: train_loss_raw=0.5696, running_loss=0.4991, LR=0.000100
[2025-08-10 23:18:38,051][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080040] [Batch 02508/03692] [00:22:39/00:10:42, 0.542s/it]: train_loss_raw=0.5404, running_loss=0.4978, LR=0.000100
[2025-08-10 23:18:44,525][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080052] [Batch 02520/03692] [00:22:46/00:10:35, 0.542s/it]: train_loss_raw=0.4511, running_loss=0.4987, LR=0.000100
[2025-08-10 23:18:50,960][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080064] [Batch 02532/03692] [00:22:52/00:10:28, 0.542s/it]: train_loss_raw=0.5134, running_loss=0.4987, LR=0.000100
[2025-08-10 23:18:57,478][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080076] [Batch 02544/03692] [00:22:59/00:10:22, 0.542s/it]: train_loss_raw=0.5057, running_loss=0.4960, LR=0.000100
[2025-08-10 23:19:04,133][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080088] [Batch 02556/03692] [00:23:06/00:10:16, 0.542s/it]: train_loss_raw=0.4260, running_loss=0.4958, LR=0.000100
[2025-08-10 23:19:10,455][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080100] [Batch 02568/03692] [00:23:12/00:10:09, 0.542s/it]: train_loss_raw=0.5786, running_loss=0.4954, LR=0.000100
[2025-08-10 23:19:16,857][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080112] [Batch 02580/03692] [00:23:18/00:10:02, 0.542s/it]: train_loss_raw=0.5288, running_loss=0.4951, LR=0.000100
[2025-08-10 23:19:23,071][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080124] [Batch 02592/03692] [00:23:25/00:09:56, 0.542s/it]: train_loss_raw=0.4934, running_loss=0.4981, LR=0.000100
[2025-08-10 23:19:29,474][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080136] [Batch 02604/03692] [00:23:31/00:09:49, 0.542s/it]: train_loss_raw=0.5222, running_loss=0.4993, LR=0.000100
[2025-08-10 23:19:35,984][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080148] [Batch 02616/03692] [00:23:37/00:09:43, 0.542s/it]: train_loss_raw=0.5700, running_loss=0.4992, LR=0.000100
[2025-08-10 23:19:42,426][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080160] [Batch 02628/03692] [00:23:44/00:09:36, 0.542s/it]: train_loss_raw=0.6046, running_loss=0.4983, LR=0.000100
[2025-08-10 23:19:48,889][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080172] [Batch 02640/03692] [00:23:50/00:09:30, 0.542s/it]: train_loss_raw=0.5467, running_loss=0.4991, LR=0.000100
[2025-08-10 23:19:55,379][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080184] [Batch 02652/03692] [00:23:57/00:09:23, 0.542s/it]: train_loss_raw=0.5795, running_loss=0.5003, LR=0.000100
[2025-08-10 23:20:01,905][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080196] [Batch 02664/03692] [00:24:03/00:09:17, 0.542s/it]: train_loss_raw=0.4894, running_loss=0.4998, LR=0.000100
[2025-08-10 23:20:08,432][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080208] [Batch 02676/03692] [00:24:10/00:09:10, 0.542s/it]: train_loss_raw=0.4964, running_loss=0.5011, LR=0.000100
[2025-08-10 23:20:14,964][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080220] [Batch 02688/03692] [00:24:16/00:09:04, 0.542s/it]: train_loss_raw=0.5155, running_loss=0.4993, LR=0.000100
[2025-08-10 23:20:21,419][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080232] [Batch 02700/03692] [00:24:23/00:08:57, 0.542s/it]: train_loss_raw=0.3936, running_loss=0.4986, LR=0.000100
[2025-08-10 23:20:27,915][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080244] [Batch 02712/03692] [00:24:29/00:08:51, 0.542s/it]: train_loss_raw=0.5469, running_loss=0.4998, LR=0.000100
[2025-08-10 23:20:34,428][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080256] [Batch 02724/03692] [00:24:36/00:08:44, 0.542s/it]: train_loss_raw=0.4747, running_loss=0.4996, LR=0.000100
[2025-08-10 23:20:40,836][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080268] [Batch 02736/03692] [00:24:42/00:08:38, 0.542s/it]: train_loss_raw=0.4384, running_loss=0.4999, LR=0.000100
[2025-08-10 23:20:47,256][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080280] [Batch 02748/03692] [00:24:49/00:08:31, 0.542s/it]: train_loss_raw=0.5150, running_loss=0.4982, LR=0.000100
[2025-08-10 23:20:53,738][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080292] [Batch 02760/03692] [00:24:55/00:08:25, 0.542s/it]: train_loss_raw=0.4587, running_loss=0.4988, LR=0.000100
[2025-08-10 23:21:00,125][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080304] [Batch 02772/03692] [00:25:02/00:08:18, 0.542s/it]: train_loss_raw=0.4311, running_loss=0.5006, LR=0.000100
[2025-08-10 23:21:06,481][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080316] [Batch 02784/03692] [00:25:08/00:08:11, 0.542s/it]: train_loss_raw=0.5052, running_loss=0.5014, LR=0.000100
[2025-08-10 23:21:12,929][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080328] [Batch 02796/03692] [00:25:14/00:08:05, 0.542s/it]: train_loss_raw=0.5475, running_loss=0.5030, LR=0.000100
[2025-08-10 23:21:19,263][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080340] [Batch 02808/03692] [00:25:21/00:07:58, 0.542s/it]: train_loss_raw=0.4725, running_loss=0.4984, LR=0.000100
[2025-08-10 23:21:25,709][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080352] [Batch 02820/03692] [00:25:27/00:07:52, 0.542s/it]: train_loss_raw=0.5493, running_loss=0.4942, LR=0.000100
[2025-08-10 23:21:32,102][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080364] [Batch 02832/03692] [00:25:34/00:07:45, 0.542s/it]: train_loss_raw=0.5419, running_loss=0.4960, LR=0.000100
[2025-08-10 23:21:38,638][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080376] [Batch 02844/03692] [00:25:40/00:07:39, 0.542s/it]: train_loss_raw=0.5397, running_loss=0.4940, LR=0.000100
[2025-08-10 23:21:45,171][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080388] [Batch 02856/03692] [00:25:47/00:07:32, 0.542s/it]: train_loss_raw=0.4703, running_loss=0.4930, LR=0.000100
[2025-08-10 23:21:51,606][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080400] [Batch 02868/03692] [00:25:53/00:07:26, 0.542s/it]: train_loss_raw=0.4278, running_loss=0.4906, LR=0.000100
[2025-08-10 23:21:58,023][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080412] [Batch 02880/03692] [00:25:59/00:07:19, 0.542s/it]: train_loss_raw=0.4949, running_loss=0.4884, LR=0.000100
[2025-08-10 23:22:04,447][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080424] [Batch 02892/03692] [00:26:06/00:07:13, 0.542s/it]: train_loss_raw=0.5095, running_loss=0.4875, LR=0.000100
[2025-08-10 23:22:10,827][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080436] [Batch 02904/03692] [00:26:12/00:07:06, 0.542s/it]: train_loss_raw=0.5403, running_loss=0.4873, LR=0.000100
[2025-08-10 23:22:17,231][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080448] [Batch 02916/03692] [00:26:19/00:07:00, 0.542s/it]: train_loss_raw=0.5764, running_loss=0.4908, LR=0.000100
[2025-08-10 23:22:23,644][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080460] [Batch 02928/03692] [00:26:25/00:06:53, 0.542s/it]: train_loss_raw=0.5617, running_loss=0.4918, LR=0.000100
[2025-08-10 23:22:30,017][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080472] [Batch 02940/03692] [00:26:31/00:06:47, 0.541s/it]: train_loss_raw=0.5079, running_loss=0.4895, LR=0.000100
[2025-08-10 23:22:36,429][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080484] [Batch 02952/03692] [00:26:38/00:06:40, 0.541s/it]: train_loss_raw=0.5770, running_loss=0.4912, LR=0.000100
[2025-08-10 23:22:42,828][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080496] [Batch 02964/03692] [00:26:44/00:06:34, 0.541s/it]: train_loss_raw=0.3893, running_loss=0.4928, LR=0.000100
[2025-08-10 23:22:49,226][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080508] [Batch 02976/03692] [00:26:51/00:06:27, 0.541s/it]: train_loss_raw=0.5213, running_loss=0.4919, LR=0.000100
[2025-08-10 23:22:55,615][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080520] [Batch 02988/03692] [00:26:57/00:06:21, 0.541s/it]: train_loss_raw=0.5308, running_loss=0.4895, LR=0.000100
[2025-08-10 23:23:02,005][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080532] [Batch 03000/03692] [00:27:03/00:06:14, 0.541s/it]: train_loss_raw=0.4737, running_loss=0.4922, LR=0.000100
[2025-08-10 23:23:08,369][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080544] [Batch 03012/03692] [00:27:10/00:06:08, 0.541s/it]: train_loss_raw=0.5060, running_loss=0.4924, LR=0.000100
[2025-08-10 23:23:14,771][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080556] [Batch 03024/03692] [00:27:16/00:06:01, 0.541s/it]: train_loss_raw=0.5375, running_loss=0.4913, LR=0.000100
[2025-08-10 23:23:21,183][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080568] [Batch 03036/03692] [00:27:23/00:05:55, 0.541s/it]: train_loss_raw=0.4764, running_loss=0.4878, LR=0.000100
[2025-08-10 23:23:27,613][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080580] [Batch 03048/03692] [00:27:29/00:05:48, 0.541s/it]: train_loss_raw=0.4307, running_loss=0.4877, LR=0.000100
[2025-08-10 23:23:33,957][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080592] [Batch 03060/03692] [00:27:35/00:05:42, 0.541s/it]: train_loss_raw=0.5511, running_loss=0.4896, LR=0.000100
[2025-08-10 23:23:40,398][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080604] [Batch 03072/03692] [00:27:42/00:05:35, 0.541s/it]: train_loss_raw=0.5703, running_loss=0.4901, LR=0.000100
[2025-08-10 23:23:46,792][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080616] [Batch 03084/03692] [00:27:48/00:05:28, 0.541s/it]: train_loss_raw=0.4813, running_loss=0.4933, LR=0.000100
[2025-08-10 23:23:53,105][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080628] [Batch 03096/03692] [00:27:55/00:05:22, 0.541s/it]: train_loss_raw=0.5187, running_loss=0.4945, LR=0.000100
[2025-08-10 23:23:59,518][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080640] [Batch 03108/03692] [00:28:01/00:05:15, 0.541s/it]: train_loss_raw=0.4063, running_loss=0.4908, LR=0.000100
[2025-08-10 23:24:05,985][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080652] [Batch 03120/03692] [00:28:07/00:05:09, 0.541s/it]: train_loss_raw=0.6295, running_loss=0.4918, LR=0.000100
[2025-08-10 23:24:12,360][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080664] [Batch 03132/03692] [00:28:14/00:05:02, 0.541s/it]: train_loss_raw=0.5423, running_loss=0.4926, LR=0.000100
[2025-08-10 23:24:18,771][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080676] [Batch 03144/03692] [00:28:20/00:04:56, 0.541s/it]: train_loss_raw=0.3470, running_loss=0.4927, LR=0.000100
[2025-08-10 23:24:25,144][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080688] [Batch 03156/03692] [00:28:27/00:04:49, 0.541s/it]: train_loss_raw=0.5361, running_loss=0.4918, LR=0.000100
[2025-08-10 23:24:31,455][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080700] [Batch 03168/03692] [00:28:33/00:04:43, 0.541s/it]: train_loss_raw=0.5078, running_loss=0.4927, LR=0.000100
[2025-08-10 23:24:37,800][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080712] [Batch 03180/03692] [00:28:39/00:04:36, 0.541s/it]: train_loss_raw=0.4645, running_loss=0.4916, LR=0.000100
[2025-08-10 23:24:44,160][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080724] [Batch 03192/03692] [00:28:46/00:04:30, 0.541s/it]: train_loss_raw=0.4871, running_loss=0.4899, LR=0.000100
[2025-08-10 23:24:50,570][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080736] [Batch 03204/03692] [00:28:52/00:04:23, 0.541s/it]: train_loss_raw=0.3693, running_loss=0.4901, LR=0.000100
[2025-08-10 23:24:56,942][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080748] [Batch 03216/03692] [00:28:58/00:04:17, 0.541s/it]: train_loss_raw=0.4930, running_loss=0.4871, LR=0.000100
[2025-08-10 23:25:03,285][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080760] [Batch 03228/03692] [00:29:05/00:04:10, 0.541s/it]: train_loss_raw=0.5018, running_loss=0.4882, LR=0.000100
[2025-08-10 23:25:09,682][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080772] [Batch 03240/03692] [00:29:11/00:04:04, 0.541s/it]: train_loss_raw=0.5103, running_loss=0.4875, LR=0.000100
[2025-08-10 23:25:16,168][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080784] [Batch 03252/03692] [00:29:18/00:03:57, 0.541s/it]: train_loss_raw=0.4141, running_loss=0.4859, LR=0.000100
[2025-08-10 23:25:22,567][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080796] [Batch 03264/03692] [00:29:24/00:03:51, 0.541s/it]: train_loss_raw=0.3966, running_loss=0.4858, LR=0.000100
[2025-08-10 23:25:28,903][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080808] [Batch 03276/03692] [00:29:30/00:03:44, 0.541s/it]: train_loss_raw=0.4811, running_loss=0.4896, LR=0.000100
[2025-08-10 23:25:35,283][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080820] [Batch 03288/03692] [00:29:37/00:03:38, 0.541s/it]: train_loss_raw=0.4592, running_loss=0.4905, LR=0.000100
[2025-08-10 23:25:41,709][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080832] [Batch 03300/03692] [00:29:43/00:03:31, 0.540s/it]: train_loss_raw=0.6079, running_loss=0.4909, LR=0.000100
[2025-08-10 23:25:48,077][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080844] [Batch 03312/03692] [00:29:50/00:03:25, 0.540s/it]: train_loss_raw=0.5337, running_loss=0.4914, LR=0.000100
[2025-08-10 23:25:54,473][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080856] [Batch 03324/03692] [00:29:56/00:03:18, 0.540s/it]: train_loss_raw=0.4011, running_loss=0.4923, LR=0.000100
[2025-08-10 23:26:01,021][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080868] [Batch 03336/03692] [00:30:02/00:03:12, 0.540s/it]: train_loss_raw=0.5583, running_loss=0.4944, LR=0.000100
[2025-08-10 23:26:07,658][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080880] [Batch 03348/03692] [00:30:09/00:03:05, 0.540s/it]: train_loss_raw=0.4534, running_loss=0.4961, LR=0.000100
[2025-08-10 23:26:14,100][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080892] [Batch 03360/03692] [00:30:16/00:02:59, 0.540s/it]: train_loss_raw=0.5165, running_loss=0.4961, LR=0.000100
[2025-08-10 23:26:20,576][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080904] [Batch 03372/03692] [00:30:22/00:02:52, 0.540s/it]: train_loss_raw=0.4217, running_loss=0.4955, LR=0.000100
[2025-08-10 23:26:26,993][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080916] [Batch 03384/03692] [00:30:28/00:02:46, 0.540s/it]: train_loss_raw=0.4793, running_loss=0.4931, LR=0.000100
[2025-08-10 23:26:33,602][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080928] [Batch 03396/03692] [00:30:35/00:02:39, 0.540s/it]: train_loss_raw=0.4253, running_loss=0.4914, LR=0.000100
[2025-08-10 23:26:40,034][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080940] [Batch 03408/03692] [00:30:41/00:02:33, 0.540s/it]: train_loss_raw=0.5966, running_loss=0.4893, LR=0.000100
[2025-08-10 23:26:46,549][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080952] [Batch 03420/03692] [00:30:48/00:02:27, 0.540s/it]: train_loss_raw=0.6251, running_loss=0.4895, LR=0.000100
[2025-08-10 23:26:52,996][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080964] [Batch 03432/03692] [00:30:54/00:02:20, 0.540s/it]: train_loss_raw=0.4414, running_loss=0.4870, LR=0.000100
[2025-08-10 23:26:59,504][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080976] [Batch 03444/03692] [00:31:01/00:02:14, 0.540s/it]: train_loss_raw=0.5980, running_loss=0.4880, LR=0.000100
[2025-08-10 23:27:05,965][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080988] [Batch 03456/03692] [00:31:07/00:02:07, 0.540s/it]: train_loss_raw=0.4892, running_loss=0.4882, LR=0.000100
[2025-08-10 23:27:12,349][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081000] [Batch 03468/03692] [00:31:14/00:02:01, 0.540s/it]: train_loss_raw=0.5537, running_loss=0.4889, LR=0.000100
[2025-08-10 23:27:18,710][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081012] [Batch 03480/03692] [00:31:20/00:01:54, 0.540s/it]: train_loss_raw=0.5350, running_loss=0.4886, LR=0.000100
[2025-08-10 23:27:25,125][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081024] [Batch 03492/03692] [00:31:27/00:01:48, 0.540s/it]: train_loss_raw=0.4880, running_loss=0.4901, LR=0.000100
[2025-08-10 23:27:31,528][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081036] [Batch 03504/03692] [00:31:33/00:01:41, 0.540s/it]: train_loss_raw=0.5222, running_loss=0.4901, LR=0.000100
[2025-08-10 23:27:37,910][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081048] [Batch 03516/03692] [00:31:39/00:01:35, 0.540s/it]: train_loss_raw=0.4196, running_loss=0.4902, LR=0.000100
[2025-08-10 23:27:44,354][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081060] [Batch 03528/03692] [00:31:46/00:01:28, 0.540s/it]: train_loss_raw=0.4592, running_loss=0.4904, LR=0.000100
[2025-08-10 23:27:50,843][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081072] [Batch 03540/03692] [00:31:52/00:01:22, 0.540s/it]: train_loss_raw=0.4620, running_loss=0.4900, LR=0.000100
[2025-08-10 23:27:57,284][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081084] [Batch 03552/03692] [00:31:59/00:01:15, 0.540s/it]: train_loss_raw=0.5600, running_loss=0.4929, LR=0.000100
[2025-08-10 23:28:03,602][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081096] [Batch 03564/03692] [00:32:05/00:01:09, 0.540s/it]: train_loss_raw=0.4156, running_loss=0.4945, LR=0.000100
[2025-08-10 23:28:10,102][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081108] [Batch 03576/03692] [00:32:12/00:01:02, 0.540s/it]: train_loss_raw=0.4661, running_loss=0.4940, LR=0.000100
[2025-08-10 23:28:16,523][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081120] [Batch 03588/03692] [00:32:18/00:00:56, 0.540s/it]: train_loss_raw=0.3648, running_loss=0.4927, LR=0.000100
[2025-08-10 23:28:22,959][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081132] [Batch 03600/03692] [00:32:24/00:00:49, 0.540s/it]: train_loss_raw=0.4936, running_loss=0.4918, LR=0.000100
[2025-08-10 23:28:29,468][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081144] [Batch 03612/03692] [00:32:31/00:00:43, 0.540s/it]: train_loss_raw=0.5223, running_loss=0.4930, LR=0.000100
[2025-08-10 23:28:35,994][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081156] [Batch 03624/03692] [00:32:37/00:00:36, 0.540s/it]: train_loss_raw=0.5756, running_loss=0.4897, LR=0.000100
[2025-08-10 23:28:42,473][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081168] [Batch 03636/03692] [00:32:44/00:00:30, 0.540s/it]: train_loss_raw=0.5315, running_loss=0.4926, LR=0.000100
[2025-08-10 23:28:48,958][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081180] [Batch 03648/03692] [00:32:50/00:00:23, 0.540s/it]: train_loss_raw=0.4088, running_loss=0.4923, LR=0.000100
[2025-08-10 23:28:55,284][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081192] [Batch 03660/03692] [00:32:57/00:00:17, 0.540s/it]: train_loss_raw=0.5322, running_loss=0.4934, LR=0.000100
[2025-08-10 23:29:01,533][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081204] [Batch 03672/03692] [00:33:03/00:00:10, 0.540s/it]: train_loss_raw=0.5537, running_loss=0.4962, LR=0.000100
[2025-08-10 23:29:08,032][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081216] [Batch 03684/03692] [00:33:09/00:00:04, 0.540s/it]: train_loss_raw=0.4641, running_loss=0.4939, LR=0.000100
[2025-08-10 23:29:25,262][__main__][INFO] - [VALIDATION] [Epoch 21/29] Starting validation.
[2025-08-10 23:29:57,427][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 081225] [Batch 00011/00025] [00:00:32/00:00:34, 2.680s/it]
[2025-08-10 23:30:11,098][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 081225] [Batch 00023/00025] [00:00:45/00:00:01, 1.910s/it]
[2025-08-10 23:30:12,059][__main__][INFO] - [VALIDATION] [Epoch 21/29] train_loss=0.49201, valid_loss=0.58859
[2025-08-10 23:30:12,059][__main__][INFO] - [VALIDATION] [Epoch 21/29] Metrics:
[2025-08-10 23:30:12,060][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_er      0.245
[2025-08-10 23:30:12,060][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_prec    0.546
[2025-08-10 23:30:12,060][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_recall  0.551
[2025-08-10 23:30:12,060][__main__][INFO] - [VALIDATION] [Epoch 21/29] - pep_recall 0.543
[2025-08-10 23:30:12,062][__main__][INFO] - [TRAIN] [Epoch 21/29] Epoch complete, total time 12:34:11, remaining time 04:34:15, 00:34:16 per epoch
[2025-08-10 23:30:14,075][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081228] [Batch 00004/03692] [00:00:01/00:27:09, 0.442s/it]: train_loss_raw=0.3874, running_loss=0.4162, LR=0.000100
[2025-08-10 23:30:20,730][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081240] [Batch 00016/03692] [00:00:08/00:32:14, 0.526s/it]: train_loss_raw=0.5077, running_loss=0.4158, LR=0.000100
[2025-08-10 23:30:27,324][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081252] [Batch 00028/03692] [00:00:15/00:32:44, 0.536s/it]: train_loss_raw=0.3599, running_loss=0.4195, LR=0.000100
[2025-08-10 23:30:33,869][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081264] [Batch 00040/03692] [00:00:21/00:32:48, 0.539s/it]: train_loss_raw=0.4565, running_loss=0.4225, LR=0.000100
[2025-08-10 23:30:40,438][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081276] [Batch 00052/03692] [00:00:28/00:32:49, 0.541s/it]: train_loss_raw=0.4633, running_loss=0.4248, LR=0.000100
[2025-08-10 23:30:47,000][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081288] [Batch 00064/03692] [00:00:34/00:32:46, 0.542s/it]: train_loss_raw=0.4514, running_loss=0.4245, LR=0.000100
[2025-08-10 23:30:53,484][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081300] [Batch 00076/03692] [00:00:41/00:32:39, 0.542s/it]: train_loss_raw=0.4251, running_loss=0.4284, LR=0.000100
[2025-08-10 23:30:59,829][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081312] [Batch 00088/03692] [00:00:47/00:32:26, 0.540s/it]: train_loss_raw=0.4310, running_loss=0.4288, LR=0.000100
[2025-08-10 23:31:06,287][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081324] [Batch 00100/03692] [00:00:53/00:32:18, 0.540s/it]: train_loss_raw=0.5724, running_loss=0.4279, LR=0.000100
[2025-08-10 23:31:12,643][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081336] [Batch 00112/03692] [00:01:00/00:32:08, 0.539s/it]: train_loss_raw=0.4038, running_loss=0.4311, LR=0.000100
[2025-08-10 23:31:19,092][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081348] [Batch 00124/03692] [00:01:06/00:32:01, 0.539s/it]: train_loss_raw=0.4795, running_loss=0.4288, LR=0.000100
[2025-08-10 23:31:25,369][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081360] [Batch 00136/03692] [00:01:13/00:31:50, 0.537s/it]: train_loss_raw=0.4185, running_loss=0.4292, LR=0.000100
[2025-08-10 23:31:31,525][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081372] [Batch 00148/03692] [00:01:19/00:31:36, 0.535s/it]: train_loss_raw=0.4217, running_loss=0.4307, LR=0.000100
[2025-08-10 23:31:37,736][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081384] [Batch 00160/03692] [00:01:25/00:31:25, 0.534s/it]: train_loss_raw=0.4418, running_loss=0.4316, LR=0.000100
[2025-08-10 23:31:44,285][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081396] [Batch 00172/03692] [00:01:31/00:31:22, 0.535s/it]: train_loss_raw=0.4185, running_loss=0.4334, LR=0.000100
[2025-08-10 23:31:50,667][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081408] [Batch 00184/03692] [00:01:38/00:31:15, 0.535s/it]: train_loss_raw=0.4453, running_loss=0.4336, LR=0.000100
[2025-08-10 23:31:56,671][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081420] [Batch 00196/03692] [00:01:44/00:31:01, 0.532s/it]: train_loss_raw=0.5139, running_loss=0.4336, LR=0.000100
[2025-08-10 23:32:02,755][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081432] [Batch 00208/03692] [00:01:50/00:30:49, 0.531s/it]: train_loss_raw=0.3171, running_loss=0.4317, LR=0.000100
[2025-08-10 23:32:08,961][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081444] [Batch 00220/03692] [00:01:56/00:30:40, 0.530s/it]: train_loss_raw=0.5418, running_loss=0.4290, LR=0.000100
[2025-08-10 23:32:15,154][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081456] [Batch 00232/03692] [00:02:02/00:30:32, 0.530s/it]: train_loss_raw=0.4379, running_loss=0.4329, LR=0.000100
[2025-08-10 23:32:21,398][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081468] [Batch 00244/03692] [00:02:09/00:30:24, 0.529s/it]: train_loss_raw=0.4449, running_loss=0.4330, LR=0.000100
[2025-08-10 23:32:27,754][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081480] [Batch 00256/03692] [00:02:15/00:30:17, 0.529s/it]: train_loss_raw=0.4756, running_loss=0.4330, LR=0.000100
[2025-08-10 23:32:34,263][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081492] [Batch 00268/03692] [00:02:21/00:30:13, 0.530s/it]: train_loss_raw=0.4089, running_loss=0.4328, LR=0.000100
[2025-08-10 23:32:40,731][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081504] [Batch 00280/03692] [00:02:28/00:30:08, 0.530s/it]: train_loss_raw=0.4263, running_loss=0.4344, LR=0.000100
[2025-08-10 23:32:47,219][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081516] [Batch 00292/03692] [00:02:34/00:30:03, 0.531s/it]: train_loss_raw=0.5710, running_loss=0.4387, LR=0.000100
[2025-08-10 23:32:53,521][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081528] [Batch 00304/03692] [00:02:41/00:29:56, 0.530s/it]: train_loss_raw=0.4349, running_loss=0.4379, LR=0.000100
[2025-08-10 23:32:59,935][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081540] [Batch 00316/03692] [00:02:47/00:29:50, 0.530s/it]: train_loss_raw=0.4556, running_loss=0.4367, LR=0.000100
[2025-08-10 23:33:06,439][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081552] [Batch 00328/03692] [00:02:54/00:29:45, 0.531s/it]: train_loss_raw=0.5696, running_loss=0.4365, LR=0.000100
[2025-08-10 23:33:12,969][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081564] [Batch 00340/03692] [00:03:00/00:29:41, 0.531s/it]: train_loss_raw=0.5238, running_loss=0.4391, LR=0.000100
[2025-08-10 23:33:19,540][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081576] [Batch 00352/03692] [00:03:07/00:29:36, 0.532s/it]: train_loss_raw=0.4707, running_loss=0.4347, LR=0.000100
[2025-08-10 23:33:26,111][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081588] [Batch 00364/03692] [00:03:13/00:29:31, 0.532s/it]: train_loss_raw=0.4262, running_loss=0.4347, LR=0.000100
[2025-08-10 23:33:32,493][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081600] [Batch 00376/03692] [00:03:20/00:29:25, 0.532s/it]: train_loss_raw=0.4894, running_loss=0.4395, LR=0.000100
[2025-08-10 23:33:38,738][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081612] [Batch 00388/03692] [00:03:26/00:29:17, 0.532s/it]: train_loss_raw=0.4653, running_loss=0.4412, LR=0.000100
[2025-08-10 23:33:44,989][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081624] [Batch 00400/03692] [00:03:32/00:29:10, 0.532s/it]: train_loss_raw=0.5224, running_loss=0.4383, LR=0.000100
[2025-08-10 23:33:51,169][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081636] [Batch 00412/03692] [00:03:38/00:29:02, 0.531s/it]: train_loss_raw=0.3758, running_loss=0.4384, LR=0.000100
[2025-08-10 23:33:57,213][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081648] [Batch 00424/03692] [00:03:44/00:28:53, 0.530s/it]: train_loss_raw=0.3276, running_loss=0.4366, LR=0.000100
[2025-08-10 23:34:03,258][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081660] [Batch 00436/03692] [00:03:50/00:28:44, 0.530s/it]: train_loss_raw=0.4037, running_loss=0.4393, LR=0.000100
[2025-08-10 23:34:09,326][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081672] [Batch 00448/03692] [00:03:57/00:28:36, 0.529s/it]: train_loss_raw=0.5113, running_loss=0.4381, LR=0.000100
[2025-08-10 23:34:15,676][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081684] [Batch 00460/03692] [00:04:03/00:28:29, 0.529s/it]: train_loss_raw=0.4549, running_loss=0.4395, LR=0.000100
[2025-08-10 23:34:22,051][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081696] [Batch 00472/03692] [00:04:09/00:28:23, 0.529s/it]: train_loss_raw=0.4570, running_loss=0.4413, LR=0.000100
[2025-08-10 23:34:28,123][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081708] [Batch 00484/03692] [00:04:15/00:28:15, 0.529s/it]: train_loss_raw=0.4177, running_loss=0.4428, LR=0.000100
[2025-08-10 23:34:34,610][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081720] [Batch 00496/03692] [00:04:22/00:28:10, 0.529s/it]: train_loss_raw=0.4947, running_loss=0.4431, LR=0.000100
[2025-08-10 23:34:41,077][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081732] [Batch 00508/03692] [00:04:28/00:28:04, 0.529s/it]: train_loss_raw=0.3582, running_loss=0.4424, LR=0.000100
[2025-08-10 23:34:47,457][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081744] [Batch 00520/03692] [00:04:35/00:27:58, 0.529s/it]: train_loss_raw=0.5150, running_loss=0.4430, LR=0.000100
[2025-08-10 23:34:53,828][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081756] [Batch 00532/03692] [00:04:41/00:27:52, 0.529s/it]: train_loss_raw=0.3974, running_loss=0.4403, LR=0.000100
[2025-08-10 23:35:00,225][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081768] [Batch 00544/03692] [00:04:47/00:27:46, 0.529s/it]: train_loss_raw=0.5594, running_loss=0.4416, LR=0.000100
[2025-08-10 23:35:06,706][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081780] [Batch 00556/03692] [00:04:54/00:27:40, 0.529s/it]: train_loss_raw=0.4797, running_loss=0.4418, LR=0.000100
[2025-08-10 23:35:13,220][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081792] [Batch 00568/03692] [00:05:00/00:27:35, 0.530s/it]: train_loss_raw=0.4167, running_loss=0.4407, LR=0.000100
[2025-08-10 23:35:19,714][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081804] [Batch 00580/03692] [00:05:07/00:27:29, 0.530s/it]: train_loss_raw=0.4542, running_loss=0.4423, LR=0.000100
[2025-08-10 23:35:26,171][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081816] [Batch 00592/03692] [00:05:13/00:27:23, 0.530s/it]: train_loss_raw=0.3939, running_loss=0.4410, LR=0.000100
[2025-08-10 23:35:32,532][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081828] [Batch 00604/03692] [00:05:20/00:27:17, 0.530s/it]: train_loss_raw=0.5141, running_loss=0.4372, LR=0.000100
[2025-08-10 23:35:38,934][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081840] [Batch 00616/03692] [00:05:26/00:27:11, 0.530s/it]: train_loss_raw=0.4945, running_loss=0.4408, LR=0.000100
[2025-08-10 23:35:45,386][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081852] [Batch 00628/03692] [00:05:33/00:27:05, 0.530s/it]: train_loss_raw=0.4901, running_loss=0.4415, LR=0.000100
[2025-08-10 23:35:51,692][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081864] [Batch 00640/03692] [00:05:39/00:26:58, 0.530s/it]: train_loss_raw=0.5049, running_loss=0.4431, LR=0.000100
[2025-08-10 23:35:58,087][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081876] [Batch 00652/03692] [00:05:45/00:26:52, 0.530s/it]: train_loss_raw=0.4731, running_loss=0.4452, LR=0.000100
[2025-08-10 23:36:04,605][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081888] [Batch 00664/03692] [00:05:52/00:26:46, 0.531s/it]: train_loss_raw=0.4964, running_loss=0.4483, LR=0.000100
[2025-08-10 23:36:11,212][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081900] [Batch 00676/03692] [00:05:58/00:26:41, 0.531s/it]: train_loss_raw=0.4237, running_loss=0.4478, LR=0.000100
[2025-08-10 23:36:17,453][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081912] [Batch 00688/03692] [00:06:05/00:26:34, 0.531s/it]: train_loss_raw=0.4851, running_loss=0.4448, LR=0.000100
[2025-08-10 23:36:23,683][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081924] [Batch 00700/03692] [00:06:11/00:26:27, 0.531s/it]: train_loss_raw=0.4147, running_loss=0.4467, LR=0.000100
[2025-08-10 23:36:30,003][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081936] [Batch 00712/03692] [00:06:17/00:26:20, 0.530s/it]: train_loss_raw=0.4502, running_loss=0.4462, LR=0.000100
[2025-08-10 23:36:36,529][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081948] [Batch 00724/03692] [00:06:24/00:26:15, 0.531s/it]: train_loss_raw=0.5065, running_loss=0.4458, LR=0.000100
[2025-08-10 23:36:43,080][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081960] [Batch 00736/03692] [00:06:30/00:26:09, 0.531s/it]: train_loss_raw=0.4722, running_loss=0.4480, LR=0.000100
[2025-08-10 23:36:49,621][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081972] [Batch 00748/03692] [00:06:37/00:26:03, 0.531s/it]: train_loss_raw=0.4341, running_loss=0.4477, LR=0.000100
[2025-08-10 23:36:56,112][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081984] [Batch 00760/03692] [00:06:43/00:25:57, 0.531s/it]: train_loss_raw=0.3733, running_loss=0.4502, LR=0.000100
[2025-08-10 23:37:02,574][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081996] [Batch 00772/03692] [00:06:50/00:25:51, 0.531s/it]: train_loss_raw=0.5336, running_loss=0.4501, LR=0.000100
[2025-08-10 23:37:14,430][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082008] [Batch 00784/03692] [00:07:02/00:26:05, 0.538s/it]: train_loss_raw=0.4302, running_loss=0.4496, LR=0.000100
[2025-08-10 23:37:20,782][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082020] [Batch 00796/03692] [00:07:08/00:25:58, 0.538s/it]: train_loss_raw=0.3752, running_loss=0.4538, LR=0.000100
[2025-08-10 23:37:27,220][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082032] [Batch 00808/03692] [00:07:14/00:25:52, 0.538s/it]: train_loss_raw=0.4651, running_loss=0.4490, LR=0.000100
[2025-08-10 23:37:33,437][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082044] [Batch 00820/03692] [00:07:21/00:25:45, 0.538s/it]: train_loss_raw=0.4155, running_loss=0.4474, LR=0.000100
[2025-08-10 23:37:39,767][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082056] [Batch 00832/03692] [00:07:27/00:25:38, 0.538s/it]: train_loss_raw=0.3880, running_loss=0.4466, LR=0.000100
[2025-08-10 23:37:46,181][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082068] [Batch 00844/03692] [00:07:33/00:25:31, 0.538s/it]: train_loss_raw=0.5378, running_loss=0.4504, LR=0.000100
[2025-08-10 23:37:52,519][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082080] [Batch 00856/03692] [00:07:40/00:25:24, 0.538s/it]: train_loss_raw=0.4667, running_loss=0.4525, LR=0.000100
[2025-08-10 23:37:58,849][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082092] [Batch 00868/03692] [00:07:46/00:25:17, 0.537s/it]: train_loss_raw=0.3894, running_loss=0.4498, LR=0.000100
[2025-08-10 23:38:05,204][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082104] [Batch 00880/03692] [00:07:52/00:25:11, 0.537s/it]: train_loss_raw=0.3648, running_loss=0.4486, LR=0.000100
[2025-08-10 23:38:11,603][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082116] [Batch 00892/03692] [00:07:59/00:25:04, 0.537s/it]: train_loss_raw=0.5300, running_loss=0.4508, LR=0.000100
[2025-08-10 23:38:18,016][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082128] [Batch 00904/03692] [00:08:05/00:24:57, 0.537s/it]: train_loss_raw=0.4480, running_loss=0.4529, LR=0.000100
[2025-08-10 23:38:24,353][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082140] [Batch 00916/03692] [00:08:12/00:24:51, 0.537s/it]: train_loss_raw=0.3881, running_loss=0.4533, LR=0.000100
[2025-08-10 23:38:30,780][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082152] [Batch 00928/03692] [00:08:18/00:24:44, 0.537s/it]: train_loss_raw=0.3952, running_loss=0.4540, LR=0.000100
[2025-08-10 23:38:37,155][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082164] [Batch 00940/03692] [00:08:24/00:24:38, 0.537s/it]: train_loss_raw=0.5502, running_loss=0.4530, LR=0.000100
[2025-08-10 23:38:43,563][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082176] [Batch 00952/03692] [00:08:31/00:24:31, 0.537s/it]: train_loss_raw=0.4158, running_loss=0.4547, LR=0.000100
[2025-08-10 23:38:49,940][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082188] [Batch 00964/03692] [00:08:37/00:24:24, 0.537s/it]: train_loss_raw=0.5063, running_loss=0.4568, LR=0.000100
[2025-08-10 23:38:56,470][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082200] [Batch 00976/03692] [00:08:44/00:24:18, 0.537s/it]: train_loss_raw=0.4310, running_loss=0.4543, LR=0.000100
[2025-08-10 23:39:03,016][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082212] [Batch 00988/03692] [00:08:50/00:24:12, 0.537s/it]: train_loss_raw=0.3845, running_loss=0.4527, LR=0.000100
[2025-08-10 23:39:09,472][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082224] [Batch 01000/03692] [00:08:57/00:24:06, 0.537s/it]: train_loss_raw=0.4200, running_loss=0.4532, LR=0.000100
[2025-08-10 23:39:15,801][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082236] [Batch 01012/03692] [00:09:03/00:23:59, 0.537s/it]: train_loss_raw=0.3845, running_loss=0.4521, LR=0.000100
[2025-08-10 23:39:22,224][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082248] [Batch 01024/03692] [00:09:09/00:23:52, 0.537s/it]: train_loss_raw=0.4182, running_loss=0.4489, LR=0.000100
[2025-08-10 23:39:28,658][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082260] [Batch 01036/03692] [00:09:16/00:23:46, 0.537s/it]: train_loss_raw=0.4907, running_loss=0.4499, LR=0.000100
[2025-08-10 23:39:35,131][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082272] [Batch 01048/03692] [00:09:22/00:23:39, 0.537s/it]: train_loss_raw=0.5287, running_loss=0.4504, LR=0.000100
[2025-08-10 23:39:41,491][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082284] [Batch 01060/03692] [00:09:29/00:23:33, 0.537s/it]: train_loss_raw=0.4661, running_loss=0.4516, LR=0.000100
[2025-08-10 23:39:47,848][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082296] [Batch 01072/03692] [00:09:35/00:23:26, 0.537s/it]: train_loss_raw=0.3521, running_loss=0.4522, LR=0.000100
[2025-08-10 23:39:54,173][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082308] [Batch 01084/03692] [00:09:41/00:23:19, 0.537s/it]: train_loss_raw=0.4866, running_loss=0.4506, LR=0.000100
[2025-08-10 23:40:00,547][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082320] [Batch 01096/03692] [00:09:48/00:23:13, 0.537s/it]: train_loss_raw=0.5122, running_loss=0.4507, LR=0.000100
[2025-08-10 23:40:06,903][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082332] [Batch 01108/03692] [00:09:54/00:23:06, 0.537s/it]: train_loss_raw=0.3983, running_loss=0.4468, LR=0.000100
[2025-08-10 23:40:13,299][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082344] [Batch 01120/03692] [00:10:00/00:23:00, 0.537s/it]: train_loss_raw=0.5218, running_loss=0.4495, LR=0.000100
[2025-08-10 23:40:19,777][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082356] [Batch 01132/03692] [00:10:07/00:22:53, 0.537s/it]: train_loss_raw=0.5034, running_loss=0.4505, LR=0.000100
[2025-08-10 23:40:26,307][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082368] [Batch 01144/03692] [00:10:13/00:22:47, 0.537s/it]: train_loss_raw=0.3147, running_loss=0.4500, LR=0.000100
[2025-08-10 23:40:32,670][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082380] [Batch 01156/03692] [00:10:20/00:22:40, 0.537s/it]: train_loss_raw=0.4092, running_loss=0.4485, LR=0.000100
[2025-08-10 23:40:39,051][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082392] [Batch 01168/03692] [00:10:26/00:22:34, 0.537s/it]: train_loss_raw=0.5035, running_loss=0.4504, LR=0.000100
[2025-08-10 23:40:45,525][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082404] [Batch 01180/03692] [00:10:33/00:22:28, 0.537s/it]: train_loss_raw=0.4276, running_loss=0.4475, LR=0.000100
[2025-08-10 23:40:51,515][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082416] [Batch 01192/03692] [00:10:39/00:22:20, 0.536s/it]: train_loss_raw=0.4325, running_loss=0.4451, LR=0.000100
[2025-08-10 23:40:57,803][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082428] [Batch 01204/03692] [00:10:45/00:22:13, 0.536s/it]: train_loss_raw=0.4055, running_loss=0.4470, LR=0.000100
[2025-08-10 23:41:04,316][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082440] [Batch 01216/03692] [00:10:52/00:22:07, 0.536s/it]: train_loss_raw=0.4194, running_loss=0.4451, LR=0.000100
[2025-08-10 23:41:10,416][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082452] [Batch 01228/03692] [00:10:58/00:22:00, 0.536s/it]: train_loss_raw=0.4176, running_loss=0.4445, LR=0.000100
[2025-08-10 23:41:16,704][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082464] [Batch 01240/03692] [00:11:04/00:21:53, 0.536s/it]: train_loss_raw=0.4248, running_loss=0.4456, LR=0.000100
[2025-08-10 23:41:23,208][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082476] [Batch 01252/03692] [00:11:10/00:21:47, 0.536s/it]: train_loss_raw=0.4193, running_loss=0.4470, LR=0.000100
[2025-08-10 23:41:29,713][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082488] [Batch 01264/03692] [00:11:17/00:21:41, 0.536s/it]: train_loss_raw=0.4458, running_loss=0.4478, LR=0.000100
[2025-08-10 23:41:36,225][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082500] [Batch 01276/03692] [00:11:23/00:21:34, 0.536s/it]: train_loss_raw=0.5703, running_loss=0.4464, LR=0.000100
[2025-08-10 23:41:42,730][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082512] [Batch 01288/03692] [00:11:30/00:21:28, 0.536s/it]: train_loss_raw=0.4316, running_loss=0.4441, LR=0.000100
[2025-08-10 23:41:49,200][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082524] [Batch 01300/03692] [00:11:36/00:21:22, 0.536s/it]: train_loss_raw=0.4448, running_loss=0.4452, LR=0.000100
[2025-08-10 23:41:55,630][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082536] [Batch 01312/03692] [00:11:43/00:21:15, 0.536s/it]: train_loss_raw=0.4283, running_loss=0.4452, LR=0.000100
[2025-08-10 23:42:01,984][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082548] [Batch 01324/03692] [00:11:49/00:21:09, 0.536s/it]: train_loss_raw=0.4836, running_loss=0.4464, LR=0.000100
[2025-08-10 23:42:08,354][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082560] [Batch 01336/03692] [00:11:56/00:21:02, 0.536s/it]: train_loss_raw=0.4176, running_loss=0.4464, LR=0.000100
[2025-08-10 23:42:14,719][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082572] [Batch 01348/03692] [00:12:02/00:20:56, 0.536s/it]: train_loss_raw=0.3875, running_loss=0.4430, LR=0.000100
[2025-08-10 23:42:21,067][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082584] [Batch 01360/03692] [00:12:08/00:20:49, 0.536s/it]: train_loss_raw=0.4357, running_loss=0.4410, LR=0.000100
[2025-08-10 23:42:27,433][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082596] [Batch 01372/03692] [00:12:15/00:20:43, 0.536s/it]: train_loss_raw=0.3857, running_loss=0.4420, LR=0.000100
[2025-08-10 23:42:33,884][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082608] [Batch 01384/03692] [00:12:21/00:20:36, 0.536s/it]: train_loss_raw=0.5346, running_loss=0.4435, LR=0.000100
[2025-08-10 23:42:40,367][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082620] [Batch 01396/03692] [00:12:28/00:20:30, 0.536s/it]: train_loss_raw=0.4856, running_loss=0.4431, LR=0.000100
[2025-08-10 23:42:46,864][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082632] [Batch 01408/03692] [00:12:34/00:20:24, 0.536s/it]: train_loss_raw=0.5084, running_loss=0.4456, LR=0.000100
[2025-08-10 23:42:53,283][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082644] [Batch 01420/03692] [00:12:40/00:20:17, 0.536s/it]: train_loss_raw=0.3550, running_loss=0.4444, LR=0.000100
[2025-08-10 23:42:59,633][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082656] [Batch 01432/03692] [00:12:47/00:20:11, 0.536s/it]: train_loss_raw=0.4025, running_loss=0.4453, LR=0.000100
[2025-08-10 23:43:06,182][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082668] [Batch 01444/03692] [00:12:53/00:20:04, 0.536s/it]: train_loss_raw=0.4311, running_loss=0.4447, LR=0.000100
[2025-08-10 23:43:12,762][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082680] [Batch 01456/03692] [00:13:00/00:19:58, 0.536s/it]: train_loss_raw=0.4178, running_loss=0.4425, LR=0.000100
[2025-08-10 23:43:19,127][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082692] [Batch 01468/03692] [00:13:06/00:19:52, 0.536s/it]: train_loss_raw=0.4430, running_loss=0.4449, LR=0.000100
[2025-08-10 23:43:25,521][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082704] [Batch 01480/03692] [00:13:13/00:19:45, 0.536s/it]: train_loss_raw=0.4487, running_loss=0.4453, LR=0.000100
[2025-08-10 23:43:31,835][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082716] [Batch 01492/03692] [00:13:19/00:19:38, 0.536s/it]: train_loss_raw=0.3826, running_loss=0.4427, LR=0.000100
[2025-08-10 23:43:38,141][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082728] [Batch 01504/03692] [00:13:25/00:19:32, 0.536s/it]: train_loss_raw=0.4889, running_loss=0.4456, LR=0.000100
[2025-08-10 23:43:44,444][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082740] [Batch 01516/03692] [00:13:32/00:19:25, 0.536s/it]: train_loss_raw=0.4730, running_loss=0.4423, LR=0.000100
[2025-08-10 23:43:50,782][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082752] [Batch 01528/03692] [00:13:38/00:19:19, 0.536s/it]: train_loss_raw=0.5103, running_loss=0.4449, LR=0.000100
[2025-08-10 23:44:43,494][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082764] [Batch 01540/03692] [00:14:31/00:20:17, 0.566s/it]: train_loss_raw=0.4253, running_loss=0.4457, LR=0.000100
[2025-08-10 23:44:49,904][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082776] [Batch 01552/03692] [00:14:37/00:20:10, 0.565s/it]: train_loss_raw=0.4720, running_loss=0.4470, LR=0.000100
[2025-08-10 23:44:56,373][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082788] [Batch 01564/03692] [00:14:44/00:20:02, 0.565s/it]: train_loss_raw=0.4674, running_loss=0.4533, LR=0.000100
[2025-08-10 23:45:02,717][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082800] [Batch 01576/03692] [00:14:50/00:19:55, 0.565s/it]: train_loss_raw=0.4665, running_loss=0.4527, LR=0.000100
[2025-08-10 23:45:09,048][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082812] [Batch 01588/03692] [00:14:56/00:19:48, 0.565s/it]: train_loss_raw=0.5627, running_loss=0.4568, LR=0.000100
[2025-08-10 23:45:15,542][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082824] [Batch 01600/03692] [00:15:03/00:19:40, 0.565s/it]: train_loss_raw=0.4201, running_loss=0.4587, LR=0.000100
[2025-08-10 23:45:22,054][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082836] [Batch 01612/03692] [00:15:09/00:19:33, 0.564s/it]: train_loss_raw=0.4632, running_loss=0.4616, LR=0.000100
[2025-08-10 23:45:28,573][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082848] [Batch 01624/03692] [00:15:16/00:19:26, 0.564s/it]: train_loss_raw=0.4803, running_loss=0.4650, LR=0.000100
[2025-08-10 23:45:34,947][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082860] [Batch 01636/03692] [00:15:22/00:19:19, 0.564s/it]: train_loss_raw=0.5227, running_loss=0.4646, LR=0.000100
[2025-08-10 23:45:41,346][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082872] [Batch 01648/03692] [00:15:29/00:19:12, 0.564s/it]: train_loss_raw=0.5273, running_loss=0.4689, LR=0.000100
[2025-08-10 23:45:47,826][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082884] [Batch 01660/03692] [00:15:35/00:19:05, 0.564s/it]: train_loss_raw=0.4664, running_loss=0.4699, LR=0.000100
[2025-08-10 23:45:54,291][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082896] [Batch 01672/03692] [00:15:41/00:18:58, 0.563s/it]: train_loss_raw=0.4212, running_loss=0.4691, LR=0.000100
[2025-08-10 23:46:00,672][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082908] [Batch 01684/03692] [00:15:48/00:18:50, 0.563s/it]: train_loss_raw=0.4340, running_loss=0.4686, LR=0.000100
[2025-08-10 23:46:07,032][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082920] [Batch 01696/03692] [00:15:54/00:18:43, 0.563s/it]: train_loss_raw=0.5033, running_loss=0.4703, LR=0.000100
[2025-08-10 23:46:13,382][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082932] [Batch 01708/03692] [00:16:01/00:18:36, 0.563s/it]: train_loss_raw=0.4475, running_loss=0.4708, LR=0.000100
[2025-08-10 23:46:19,782][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082944] [Batch 01720/03692] [00:16:07/00:18:29, 0.562s/it]: train_loss_raw=0.4022, running_loss=0.4681, LR=0.000100
[2025-08-10 23:46:26,216][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082956] [Batch 01732/03692] [00:16:13/00:18:22, 0.562s/it]: train_loss_raw=0.4919, running_loss=0.4701, LR=0.000100
[2025-08-10 23:46:32,746][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082968] [Batch 01744/03692] [00:16:20/00:18:15, 0.562s/it]: train_loss_raw=0.5033, running_loss=0.4690, LR=0.000100
[2025-08-10 23:46:39,311][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082980] [Batch 01756/03692] [00:16:27/00:18:08, 0.562s/it]: train_loss_raw=0.5128, running_loss=0.4722, LR=0.000100
[2025-08-10 23:46:45,846][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082992] [Batch 01768/03692] [00:16:33/00:18:01, 0.562s/it]: train_loss_raw=0.4528, running_loss=0.4725, LR=0.000100
[2025-08-10 23:46:52,304][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083004] [Batch 01780/03692] [00:16:39/00:17:54, 0.562s/it]: train_loss_raw=0.4687, running_loss=0.4707, LR=0.000100
[2025-08-10 23:46:58,685][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083016] [Batch 01792/03692] [00:16:46/00:17:47, 0.562s/it]: train_loss_raw=0.4998, running_loss=0.4725, LR=0.000100
[2025-08-10 23:47:05,112][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083028] [Batch 01804/03692] [00:16:52/00:17:39, 0.561s/it]: train_loss_raw=0.5144, running_loss=0.4757, LR=0.000100
[2025-08-10 23:47:11,551][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083040] [Batch 01816/03692] [00:16:59/00:17:32, 0.561s/it]: train_loss_raw=0.4298, running_loss=0.4760, LR=0.000100
[2025-08-10 23:47:18,050][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083052] [Batch 01828/03692] [00:17:05/00:17:25, 0.561s/it]: train_loss_raw=0.3641, running_loss=0.4725, LR=0.000100
[2025-08-10 23:47:24,533][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083064] [Batch 01840/03692] [00:17:12/00:17:18, 0.561s/it]: train_loss_raw=0.5424, running_loss=0.4750, LR=0.000100
[2025-08-10 23:47:30,802][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083076] [Batch 01852/03692] [00:17:18/00:17:11, 0.561s/it]: train_loss_raw=0.4387, running_loss=0.4775, LR=0.000100
[2025-08-10 23:47:36,930][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083088] [Batch 01864/03692] [00:17:24/00:17:04, 0.560s/it]: train_loss_raw=0.5695, running_loss=0.4791, LR=0.000100
[2025-08-10 23:47:43,131][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083100] [Batch 01876/03692] [00:17:30/00:16:57, 0.560s/it]: train_loss_raw=0.5068, running_loss=0.4772, LR=0.000100
[2025-08-10 23:47:49,479][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083112] [Batch 01888/03692] [00:17:37/00:16:50, 0.560s/it]: train_loss_raw=0.4385, running_loss=0.4744, LR=0.000100
[2025-08-10 23:47:55,689][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083124] [Batch 01900/03692] [00:17:43/00:16:42, 0.560s/it]: train_loss_raw=0.4455, running_loss=0.4739, LR=0.000100
[2025-08-10 23:48:01,849][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083136] [Batch 01912/03692] [00:17:49/00:16:35, 0.559s/it]: train_loss_raw=0.4628, running_loss=0.4738, LR=0.000100
[2025-08-10 23:48:07,889][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083148] [Batch 01924/03692] [00:17:55/00:16:28, 0.559s/it]: train_loss_raw=0.6315, running_loss=0.4765, LR=0.000100
[2025-08-10 23:48:13,925][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083160] [Batch 01936/03692] [00:18:01/00:16:21, 0.559s/it]: train_loss_raw=0.4227, running_loss=0.4727, LR=0.000100
[2025-08-10 23:48:20,003][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083172] [Batch 01948/03692] [00:18:07/00:16:13, 0.558s/it]: train_loss_raw=0.5206, running_loss=0.4750, LR=0.000100
[2025-08-10 23:48:26,057][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083184] [Batch 01960/03692] [00:18:13/00:16:06, 0.558s/it]: train_loss_raw=0.4247, running_loss=0.4739, LR=0.000100
[2025-08-10 23:48:32,158][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083196] [Batch 01972/03692] [00:18:19/00:15:59, 0.558s/it]: train_loss_raw=0.4487, running_loss=0.4708, LR=0.000100
[2025-08-10 23:48:38,222][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083208] [Batch 01984/03692] [00:18:25/00:15:52, 0.557s/it]: train_loss_raw=0.5325, running_loss=0.4712, LR=0.000100
[2025-08-10 23:48:44,267][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083220] [Batch 01996/03692] [00:18:31/00:15:44, 0.557s/it]: train_loss_raw=0.4603, running_loss=0.4729, LR=0.000100
[2025-08-10 23:48:50,291][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083232] [Batch 02008/03692] [00:18:37/00:15:37, 0.557s/it]: train_loss_raw=0.4892, running_loss=0.4691, LR=0.000100
[2025-08-10 23:48:56,287][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083244] [Batch 02020/03692] [00:18:43/00:15:30, 0.556s/it]: train_loss_raw=0.4801, running_loss=0.4717, LR=0.000100
[2025-08-10 23:49:02,314][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083256] [Batch 02032/03692] [00:18:50/00:15:23, 0.556s/it]: train_loss_raw=0.4443, running_loss=0.4719, LR=0.000100
[2025-08-10 23:49:08,446][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083268] [Batch 02044/03692] [00:18:56/00:15:16, 0.556s/it]: train_loss_raw=0.4520, running_loss=0.4718, LR=0.000100
[2025-08-10 23:49:14,488][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083280] [Batch 02056/03692] [00:19:02/00:15:08, 0.556s/it]: train_loss_raw=0.3233, running_loss=0.4689, LR=0.000100
[2025-08-10 23:49:20,605][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083292] [Batch 02068/03692] [00:19:08/00:15:01, 0.555s/it]: train_loss_raw=0.4323, running_loss=0.4692, LR=0.000100
[2025-08-10 23:49:26,622][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083304] [Batch 02080/03692] [00:19:14/00:14:54, 0.555s/it]: train_loss_raw=0.5490, running_loss=0.4690, LR=0.000100
[2025-08-10 23:49:32,686][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083316] [Batch 02092/03692] [00:19:20/00:14:47, 0.555s/it]: train_loss_raw=0.4961, running_loss=0.4729, LR=0.000100
[2025-08-10 23:49:38,704][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083328] [Batch 02104/03692] [00:19:26/00:14:40, 0.554s/it]: train_loss_raw=0.5103, running_loss=0.4735, LR=0.000100
[2025-08-10 23:49:45,013][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083340] [Batch 02116/03692] [00:19:32/00:14:33, 0.554s/it]: train_loss_raw=0.3802, running_loss=0.4776, LR=0.000100
[2025-08-10 23:49:51,253][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083352] [Batch 02128/03692] [00:19:38/00:14:26, 0.554s/it]: train_loss_raw=0.4320, running_loss=0.4744, LR=0.000100
[2025-08-10 23:49:57,368][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083364] [Batch 02140/03692] [00:19:45/00:14:19, 0.554s/it]: train_loss_raw=0.5545, running_loss=0.4724, LR=0.000100
[2025-08-10 23:50:03,428][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083376] [Batch 02152/03692] [00:19:51/00:14:12, 0.553s/it]: train_loss_raw=0.4329, running_loss=0.4739, LR=0.000100
[2025-08-10 23:50:09,451][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083388] [Batch 02164/03692] [00:19:57/00:14:05, 0.553s/it]: train_loss_raw=0.4815, running_loss=0.4724, LR=0.000100
[2025-08-10 23:50:15,799][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083400] [Batch 02176/03692] [00:20:03/00:13:58, 0.553s/it]: train_loss_raw=0.5167, running_loss=0.4700, LR=0.000100
[2025-08-10 23:50:22,178][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083412] [Batch 02188/03692] [00:20:09/00:13:51, 0.553s/it]: train_loss_raw=0.4836, running_loss=0.4667, LR=0.000100
[2025-08-10 23:50:28,603][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083424] [Batch 02200/03692] [00:20:16/00:13:44, 0.553s/it]: train_loss_raw=0.3859, running_loss=0.4644, LR=0.000100
[2025-08-10 23:50:35,013][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083436] [Batch 02212/03692] [00:20:22/00:13:38, 0.553s/it]: train_loss_raw=0.3632, running_loss=0.4649, LR=0.000100
[2025-08-10 23:50:41,555][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083448] [Batch 02224/03692] [00:20:29/00:13:31, 0.553s/it]: train_loss_raw=0.5321, running_loss=0.4642, LR=0.000100
[2025-08-10 23:50:47,942][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083460] [Batch 02236/03692] [00:20:35/00:13:24, 0.553s/it]: train_loss_raw=0.5136, running_loss=0.4659, LR=0.000100
[2025-08-10 23:50:54,358][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083472] [Batch 02248/03692] [00:20:42/00:13:17, 0.553s/it]: train_loss_raw=0.5195, running_loss=0.4677, LR=0.000100
[2025-08-10 23:51:00,705][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083484] [Batch 02260/03692] [00:20:48/00:13:11, 0.552s/it]: train_loss_raw=0.3453, running_loss=0.4650, LR=0.000100
[2025-08-10 23:51:07,018][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083496] [Batch 02272/03692] [00:20:54/00:13:04, 0.552s/it]: train_loss_raw=0.3596, running_loss=0.4604, LR=0.000100
[2025-08-10 23:51:13,430][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083508] [Batch 02284/03692] [00:21:01/00:12:57, 0.552s/it]: train_loss_raw=0.4724, running_loss=0.4601, LR=0.000100
[2025-08-10 23:51:19,972][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083520] [Batch 02296/03692] [00:21:07/00:12:50, 0.552s/it]: train_loss_raw=0.5022, running_loss=0.4645, LR=0.000100
[2025-08-10 23:51:26,394][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083532] [Batch 02308/03692] [00:21:14/00:12:44, 0.552s/it]: train_loss_raw=0.5114, running_loss=0.4637, LR=0.000100
[2025-08-10 23:51:32,707][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083544] [Batch 02320/03692] [00:21:20/00:12:37, 0.552s/it]: train_loss_raw=0.4108, running_loss=0.4604, LR=0.000100
[2025-08-10 23:51:39,053][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083556] [Batch 02332/03692] [00:21:26/00:12:30, 0.552s/it]: train_loss_raw=0.4197, running_loss=0.4641, LR=0.000100
[2025-08-10 23:51:45,520][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083568] [Batch 02344/03692] [00:21:33/00:12:23, 0.552s/it]: train_loss_raw=0.4999, running_loss=0.4640, LR=0.000100
[2025-08-10 23:51:51,981][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083580] [Batch 02356/03692] [00:21:39/00:12:16, 0.552s/it]: train_loss_raw=0.5077, running_loss=0.4651, LR=0.000100
[2025-08-10 23:51:58,530][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083592] [Batch 02368/03692] [00:21:46/00:12:10, 0.552s/it]: train_loss_raw=0.4613, running_loss=0.4646, LR=0.000100
[2025-08-10 23:52:04,986][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083604] [Batch 02380/03692] [00:21:52/00:12:03, 0.552s/it]: train_loss_raw=0.4808, running_loss=0.4656, LR=0.000100
[2025-08-10 23:52:11,347][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083616] [Batch 02392/03692] [00:21:59/00:11:56, 0.551s/it]: train_loss_raw=0.4186, running_loss=0.4634, LR=0.000100
[2025-08-10 23:52:17,742][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083628] [Batch 02404/03692] [00:22:05/00:11:50, 0.551s/it]: train_loss_raw=0.5976, running_loss=0.4656, LR=0.000100
[2025-08-10 23:52:24,161][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083640] [Batch 02416/03692] [00:22:11/00:11:43, 0.551s/it]: train_loss_raw=0.4984, running_loss=0.4678, LR=0.000100
[2025-08-10 23:52:30,506][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083652] [Batch 02428/03692] [00:22:18/00:11:36, 0.551s/it]: train_loss_raw=0.3636, running_loss=0.4707, LR=0.000100
[2025-08-10 23:52:36,805][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083664] [Batch 02440/03692] [00:22:24/00:11:29, 0.551s/it]: train_loss_raw=0.4501, running_loss=0.4714, LR=0.000100
[2025-08-10 23:52:43,338][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083676] [Batch 02452/03692] [00:22:31/00:11:23, 0.551s/it]: train_loss_raw=0.4497, running_loss=0.4738, LR=0.000100
[2025-08-10 23:52:49,817][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083688] [Batch 02464/03692] [00:22:37/00:11:16, 0.551s/it]: train_loss_raw=0.4086, running_loss=0.4735, LR=0.000100
[2025-08-10 23:52:56,336][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083700] [Batch 02476/03692] [00:22:44/00:11:09, 0.551s/it]: train_loss_raw=0.5618, running_loss=0.4746, LR=0.000100
[2025-08-10 23:53:02,776][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083712] [Batch 02488/03692] [00:22:50/00:11:03, 0.551s/it]: train_loss_raw=0.5027, running_loss=0.4745, LR=0.000100
[2025-08-10 23:53:09,297][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083724] [Batch 02500/03692] [00:22:56/00:10:56, 0.551s/it]: train_loss_raw=0.5022, running_loss=0.4744, LR=0.000100
[2025-08-10 23:53:15,463][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083736] [Batch 02512/03692] [00:23:03/00:10:49, 0.551s/it]: train_loss_raw=0.5286, running_loss=0.4728, LR=0.000100
[2025-08-10 23:53:21,818][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083748] [Batch 02524/03692] [00:23:09/00:10:43, 0.551s/it]: train_loss_raw=0.4800, running_loss=0.4743, LR=0.000100
[2025-08-10 23:53:28,037][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083760] [Batch 02536/03692] [00:23:15/00:10:36, 0.550s/it]: train_loss_raw=0.4548, running_loss=0.4721, LR=0.000100
[2025-08-10 23:53:34,257][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083772] [Batch 02548/03692] [00:23:21/00:10:29, 0.550s/it]: train_loss_raw=0.6076, running_loss=0.4731, LR=0.000100
[2025-08-10 23:53:40,725][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083784] [Batch 02560/03692] [00:23:28/00:10:22, 0.550s/it]: train_loss_raw=0.3656, running_loss=0.4693, LR=0.000100
[2025-08-10 23:53:47,314][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083796] [Batch 02572/03692] [00:23:35/00:10:16, 0.550s/it]: train_loss_raw=0.3957, running_loss=0.4656, LR=0.000100
[2025-08-10 23:53:53,808][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083808] [Batch 02584/03692] [00:23:41/00:10:09, 0.550s/it]: train_loss_raw=0.5198, running_loss=0.4676, LR=0.000100
[2025-08-10 23:54:00,263][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083820] [Batch 02596/03692] [00:23:47/00:10:02, 0.550s/it]: train_loss_raw=0.4613, running_loss=0.4681, LR=0.000100
[2025-08-10 23:54:06,678][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083832] [Batch 02608/03692] [00:23:54/00:09:56, 0.550s/it]: train_loss_raw=0.4783, running_loss=0.4690, LR=0.000100
[2025-08-10 23:54:13,070][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083844] [Batch 02620/03692] [00:24:00/00:09:49, 0.550s/it]: train_loss_raw=0.4451, running_loss=0.4681, LR=0.000100
[2025-08-10 23:54:19,452][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083856] [Batch 02632/03692] [00:24:07/00:09:42, 0.550s/it]: train_loss_raw=0.5924, running_loss=0.4664, LR=0.000100
[2025-08-10 23:54:25,837][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083868] [Batch 02644/03692] [00:24:13/00:09:36, 0.550s/it]: train_loss_raw=0.4603, running_loss=0.4662, LR=0.000100
[2025-08-10 23:54:32,215][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083880] [Batch 02656/03692] [00:24:19/00:09:29, 0.550s/it]: train_loss_raw=0.5492, running_loss=0.4700, LR=0.000100
[2025-08-10 23:54:38,632][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083892] [Batch 02668/03692] [00:24:26/00:09:22, 0.550s/it]: train_loss_raw=0.4721, running_loss=0.4708, LR=0.000100
[2025-08-10 23:54:45,128][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083904] [Batch 02680/03692] [00:24:32/00:09:16, 0.550s/it]: train_loss_raw=0.5217, running_loss=0.4721, LR=0.000100
[2025-08-10 23:54:51,482][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083916] [Batch 02692/03692] [00:24:39/00:09:09, 0.549s/it]: train_loss_raw=0.4756, running_loss=0.4720, LR=0.000100
[2025-08-10 23:54:57,896][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083928] [Batch 02704/03692] [00:24:45/00:09:02, 0.549s/it]: train_loss_raw=0.5276, running_loss=0.4754, LR=0.000100
[2025-08-10 23:55:04,256][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083940] [Batch 02716/03692] [00:24:51/00:08:56, 0.549s/it]: train_loss_raw=0.5685, running_loss=0.4748, LR=0.000100
[2025-08-10 23:55:10,598][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083952] [Batch 02728/03692] [00:24:58/00:08:49, 0.549s/it]: train_loss_raw=0.5317, running_loss=0.4750, LR=0.000100
[2025-08-10 23:55:17,054][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083964] [Batch 02740/03692] [00:25:04/00:08:42, 0.549s/it]: train_loss_raw=0.3368, running_loss=0.4701, LR=0.000100
[2025-08-10 23:55:23,442][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083976] [Batch 02752/03692] [00:25:11/00:08:36, 0.549s/it]: train_loss_raw=0.4293, running_loss=0.4701, LR=0.000100
[2025-08-10 23:55:29,807][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083988] [Batch 02764/03692] [00:25:17/00:08:29, 0.549s/it]: train_loss_raw=0.5439, running_loss=0.4704, LR=0.000100
[2025-08-10 23:55:36,215][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084000] [Batch 02776/03692] [00:25:23/00:08:22, 0.549s/it]: train_loss_raw=0.3954, running_loss=0.4661, LR=0.000100
[2025-08-10 23:55:47,273][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084012] [Batch 02788/03692] [00:25:34/00:08:17, 0.551s/it]: train_loss_raw=0.4048, running_loss=0.4661, LR=0.000100
[2025-08-10 23:55:53,670][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084024] [Batch 02800/03692] [00:25:41/00:08:11, 0.550s/it]: train_loss_raw=0.4976, running_loss=0.4659, LR=0.000100
[2025-08-10 23:56:00,047][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084036] [Batch 02812/03692] [00:25:47/00:08:04, 0.550s/it]: train_loss_raw=0.4805, running_loss=0.4661, LR=0.000100
[2025-08-10 23:56:06,314][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084048] [Batch 02824/03692] [00:25:54/00:07:57, 0.550s/it]: train_loss_raw=0.4496, running_loss=0.4679, LR=0.000100
[2025-08-10 23:56:12,659][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084060] [Batch 02836/03692] [00:26:00/00:07:50, 0.550s/it]: train_loss_raw=0.4834, running_loss=0.4685, LR=0.000100
[2025-08-10 23:56:18,910][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084072] [Batch 02848/03692] [00:26:06/00:07:44, 0.550s/it]: train_loss_raw=0.5222, running_loss=0.4700, LR=0.000100
[2025-08-10 23:56:25,150][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084084] [Batch 02860/03692] [00:26:12/00:07:37, 0.550s/it]: train_loss_raw=0.6185, running_loss=0.4683, LR=0.000100
[2025-08-10 23:56:31,558][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084096] [Batch 02872/03692] [00:26:19/00:07:30, 0.550s/it]: train_loss_raw=0.3907, running_loss=0.4677, LR=0.000100
[2025-08-10 23:56:37,942][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084108] [Batch 02884/03692] [00:26:25/00:07:24, 0.550s/it]: train_loss_raw=0.4411, running_loss=0.4687, LR=0.000100
[2025-08-10 23:56:44,350][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084120] [Batch 02896/03692] [00:26:32/00:07:17, 0.550s/it]: train_loss_raw=0.5325, running_loss=0.4669, LR=0.000100
[2025-08-10 23:56:50,724][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084132] [Batch 02908/03692] [00:26:38/00:07:10, 0.550s/it]: train_loss_raw=0.5051, running_loss=0.4683, LR=0.000100
[2025-08-10 23:56:57,111][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084144] [Batch 02920/03692] [00:26:44/00:07:04, 0.550s/it]: train_loss_raw=0.4354, running_loss=0.4698, LR=0.000100
[2025-08-10 23:57:03,577][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084156] [Batch 02932/03692] [00:26:51/00:06:57, 0.550s/it]: train_loss_raw=0.4789, running_loss=0.4673, LR=0.000100
[2025-08-10 23:57:10,019][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084168] [Batch 02944/03692] [00:26:57/00:06:51, 0.549s/it]: train_loss_raw=0.3681, running_loss=0.4685, LR=0.000100
[2025-08-10 23:57:16,449][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084180] [Batch 02956/03692] [00:27:04/00:06:44, 0.549s/it]: train_loss_raw=0.5819, running_loss=0.4686, LR=0.000100
[2025-08-10 23:57:22,845][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084192] [Batch 02968/03692] [00:27:10/00:06:37, 0.549s/it]: train_loss_raw=0.5005, running_loss=0.4699, LR=0.000100
[2025-08-10 23:57:29,137][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084204] [Batch 02980/03692] [00:27:16/00:06:31, 0.549s/it]: train_loss_raw=0.5263, running_loss=0.4723, LR=0.000100
[2025-08-10 23:57:35,518][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084216] [Batch 02992/03692] [00:27:23/00:06:24, 0.549s/it]: train_loss_raw=0.5371, running_loss=0.4725, LR=0.000100
[2025-08-10 23:57:41,861][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084228] [Batch 03004/03692] [00:27:29/00:06:17, 0.549s/it]: train_loss_raw=0.3954, running_loss=0.4723, LR=0.000100
[2025-08-10 23:57:48,343][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084240] [Batch 03016/03692] [00:27:36/00:06:11, 0.549s/it]: train_loss_raw=0.5433, running_loss=0.4724, LR=0.000100
[2025-08-10 23:57:54,766][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084252] [Batch 03028/03692] [00:27:42/00:06:04, 0.549s/it]: train_loss_raw=0.4614, running_loss=0.4682, LR=0.000100
[2025-08-10 23:58:01,251][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084264] [Batch 03040/03692] [00:27:48/00:05:57, 0.549s/it]: train_loss_raw=0.4503, running_loss=0.4707, LR=0.000100
[2025-08-10 23:58:07,669][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084276] [Batch 03052/03692] [00:27:55/00:05:51, 0.549s/it]: train_loss_raw=0.4636, running_loss=0.4708, LR=0.000100
[2025-08-10 23:58:14,071][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084288] [Batch 03064/03692] [00:28:01/00:05:44, 0.549s/it]: train_loss_raw=0.4877, running_loss=0.4698, LR=0.000100
[2025-08-10 23:58:20,529][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084300] [Batch 03076/03692] [00:28:08/00:05:38, 0.549s/it]: train_loss_raw=0.4709, running_loss=0.4679, LR=0.000100
[2025-08-10 23:58:26,971][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084312] [Batch 03088/03692] [00:28:14/00:05:31, 0.549s/it]: train_loss_raw=0.4746, running_loss=0.4646, LR=0.000100
[2025-08-10 23:58:33,400][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084324] [Batch 03100/03692] [00:28:21/00:05:24, 0.549s/it]: train_loss_raw=0.3670, running_loss=0.4632, LR=0.000100
[2025-08-10 23:58:39,758][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084336] [Batch 03112/03692] [00:28:27/00:05:18, 0.549s/it]: train_loss_raw=0.5161, running_loss=0.4651, LR=0.000100
[2025-08-10 23:58:46,115][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084348] [Batch 03124/03692] [00:28:33/00:05:11, 0.549s/it]: train_loss_raw=0.4889, running_loss=0.4656, LR=0.000100
[2025-08-10 23:58:52,559][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084360] [Batch 03136/03692] [00:28:40/00:05:04, 0.549s/it]: train_loss_raw=0.4979, running_loss=0.4672, LR=0.000100
[2025-08-10 23:58:58,863][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084372] [Batch 03148/03692] [00:28:46/00:04:58, 0.548s/it]: train_loss_raw=0.3949, running_loss=0.4686, LR=0.000100
[2025-08-10 23:59:05,174][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084384] [Batch 03160/03692] [00:28:52/00:04:51, 0.548s/it]: train_loss_raw=0.3924, running_loss=0.4681, LR=0.000100
[2025-08-10 23:59:11,553][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084396] [Batch 03172/03692] [00:28:59/00:04:45, 0.548s/it]: train_loss_raw=0.4416, running_loss=0.4666, LR=0.000100
[2025-08-10 23:59:17,895][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084408] [Batch 03184/03692] [00:29:05/00:04:38, 0.548s/it]: train_loss_raw=0.4167, running_loss=0.4648, LR=0.000100
[2025-08-10 23:59:24,247][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084420] [Batch 03196/03692] [00:29:11/00:04:31, 0.548s/it]: train_loss_raw=0.5223, running_loss=0.4661, LR=0.000100
[2025-08-10 23:59:30,553][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084432] [Batch 03208/03692] [00:29:18/00:04:25, 0.548s/it]: train_loss_raw=0.6020, running_loss=0.4686, LR=0.000100
[2025-08-10 23:59:36,970][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084444] [Batch 03220/03692] [00:29:24/00:04:18, 0.548s/it]: train_loss_raw=0.4952, running_loss=0.4696, LR=0.000100
[2025-08-10 23:59:43,343][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084456] [Batch 03232/03692] [00:29:31/00:04:12, 0.548s/it]: train_loss_raw=0.5229, running_loss=0.4707, LR=0.000100
[2025-08-10 23:59:49,763][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084468] [Batch 03244/03692] [00:29:37/00:04:05, 0.548s/it]: train_loss_raw=0.5181, running_loss=0.4691, LR=0.000100
[2025-08-10 23:59:56,152][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084480] [Batch 03256/03692] [00:29:43/00:03:58, 0.548s/it]: train_loss_raw=0.4795, running_loss=0.4733, LR=0.000100
[2025-08-11 00:00:02,514][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084492] [Batch 03268/03692] [00:29:50/00:03:52, 0.548s/it]: train_loss_raw=0.4850, running_loss=0.4716, LR=0.000100
[2025-08-11 00:00:09,036][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084504] [Batch 03280/03692] [00:29:56/00:03:45, 0.548s/it]: train_loss_raw=0.4315, running_loss=0.4707, LR=0.000100
[2025-08-11 00:00:15,595][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084516] [Batch 03292/03692] [00:30:03/00:03:39, 0.548s/it]: train_loss_raw=0.5398, running_loss=0.4708, LR=0.000100
[2025-08-11 00:00:21,945][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084528] [Batch 03304/03692] [00:30:09/00:03:32, 0.548s/it]: train_loss_raw=0.4193, running_loss=0.4710, LR=0.000100
[2025-08-11 00:00:28,207][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084540] [Batch 03316/03692] [00:30:15/00:03:25, 0.548s/it]: train_loss_raw=0.5020, running_loss=0.4731, LR=0.000100
[2025-08-11 00:00:34,625][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084552] [Batch 03328/03692] [00:30:22/00:03:19, 0.548s/it]: train_loss_raw=0.6531, running_loss=0.4731, LR=0.000100
[2025-08-11 00:00:41,061][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084564] [Batch 03340/03692] [00:30:28/00:03:12, 0.548s/it]: train_loss_raw=0.5256, running_loss=0.4758, LR=0.000100
[2025-08-11 00:00:47,632][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084576] [Batch 03352/03692] [00:30:35/00:03:06, 0.548s/it]: train_loss_raw=0.4828, running_loss=0.4743, LR=0.000100
[2025-08-11 00:00:54,146][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084588] [Batch 03364/03692] [00:30:41/00:02:59, 0.548s/it]: train_loss_raw=0.4492, running_loss=0.4731, LR=0.000100
[2025-08-11 00:01:00,558][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084600] [Batch 03376/03692] [00:30:48/00:02:52, 0.547s/it]: train_loss_raw=0.5222, running_loss=0.4725, LR=0.000100
[2025-08-11 00:01:06,983][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084612] [Batch 03388/03692] [00:30:54/00:02:46, 0.547s/it]: train_loss_raw=0.3689, running_loss=0.4722, LR=0.000100
[2025-08-11 00:01:13,500][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084624] [Batch 03400/03692] [00:31:01/00:02:39, 0.547s/it]: train_loss_raw=0.4502, running_loss=0.4702, LR=0.000100
[2025-08-11 00:01:20,057][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084636] [Batch 03412/03692] [00:31:07/00:02:33, 0.547s/it]: train_loss_raw=0.4395, running_loss=0.4707, LR=0.000100
[2025-08-11 00:01:26,553][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084648] [Batch 03424/03692] [00:31:14/00:02:26, 0.547s/it]: train_loss_raw=0.5179, running_loss=0.4717, LR=0.000100
[2025-08-11 00:01:33,015][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084660] [Batch 03436/03692] [00:31:20/00:02:20, 0.547s/it]: train_loss_raw=0.3813, running_loss=0.4730, LR=0.000100
[2025-08-11 00:01:39,517][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084672] [Batch 03448/03692] [00:31:27/00:02:13, 0.547s/it]: train_loss_raw=0.4896, running_loss=0.4722, LR=0.000100
[2025-08-11 00:01:46,000][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084684] [Batch 03460/03692] [00:31:33/00:02:06, 0.547s/it]: train_loss_raw=0.4932, running_loss=0.4736, LR=0.000100
[2025-08-11 00:01:52,544][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084696] [Batch 03472/03692] [00:31:40/00:02:00, 0.547s/it]: train_loss_raw=0.5603, running_loss=0.4736, LR=0.000100
[2025-08-11 00:01:58,831][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084708] [Batch 03484/03692] [00:31:46/00:01:53, 0.547s/it]: train_loss_raw=0.4362, running_loss=0.4718, LR=0.000100
[2025-08-11 00:02:05,153][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084720] [Batch 03496/03692] [00:31:52/00:01:47, 0.547s/it]: train_loss_raw=0.3448, running_loss=0.4673, LR=0.000100
[2025-08-11 00:02:11,589][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084732] [Batch 03508/03692] [00:31:59/00:01:40, 0.547s/it]: train_loss_raw=0.4218, running_loss=0.4638, LR=0.000100
[2025-08-11 00:02:18,157][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084744] [Batch 03520/03692] [00:32:05/00:01:34, 0.547s/it]: train_loss_raw=0.5163, running_loss=0.4651, LR=0.000100
[2025-08-11 00:02:24,586][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084756] [Batch 03532/03692] [00:32:12/00:01:27, 0.547s/it]: train_loss_raw=0.5359, running_loss=0.4647, LR=0.000100
[2025-08-11 00:02:31,088][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084768] [Batch 03544/03692] [00:32:18/00:01:20, 0.547s/it]: train_loss_raw=0.4516, running_loss=0.4656, LR=0.000100
[2025-08-11 00:02:37,272][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084780] [Batch 03556/03692] [00:32:24/00:01:14, 0.547s/it]: train_loss_raw=0.6155, running_loss=0.4667, LR=0.000100
[2025-08-11 00:02:43,811][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084792] [Batch 03568/03692] [00:32:31/00:01:07, 0.547s/it]: train_loss_raw=0.4668, running_loss=0.4641, LR=0.000100
[2025-08-11 00:02:50,362][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084804] [Batch 03580/03692] [00:32:38/00:01:01, 0.547s/it]: train_loss_raw=0.5095, running_loss=0.4654, LR=0.000100
[2025-08-11 00:02:56,874][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084816] [Batch 03592/03692] [00:32:44/00:00:54, 0.547s/it]: train_loss_raw=0.4515, running_loss=0.4667, LR=0.000100
[2025-08-11 00:03:03,432][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084828] [Batch 03604/03692] [00:32:51/00:00:48, 0.547s/it]: train_loss_raw=0.4973, running_loss=0.4679, LR=0.000100
[2025-08-11 00:03:09,922][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084840] [Batch 03616/03692] [00:32:57/00:00:41, 0.547s/it]: train_loss_raw=0.3677, running_loss=0.4671, LR=0.000100
[2025-08-11 00:03:16,477][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084852] [Batch 03628/03692] [00:33:04/00:00:35, 0.547s/it]: train_loss_raw=0.4978, running_loss=0.4687, LR=0.000100
[2025-08-11 00:03:22,696][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084864] [Batch 03640/03692] [00:33:10/00:00:28, 0.547s/it]: train_loss_raw=0.3631, running_loss=0.4671, LR=0.000100
[2025-08-11 00:03:28,781][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084876] [Batch 03652/03692] [00:33:16/00:00:21, 0.547s/it]: train_loss_raw=0.5104, running_loss=0.4674, LR=0.000100
[2025-08-11 00:03:34,945][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084888] [Batch 03664/03692] [00:33:22/00:00:15, 0.547s/it]: train_loss_raw=0.5379, running_loss=0.4625, LR=0.000100
[2025-08-11 00:03:41,424][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084900] [Batch 03676/03692] [00:33:29/00:00:08, 0.547s/it]: train_loss_raw=0.5300, running_loss=0.4604, LR=0.000100
[2025-08-11 00:03:47,883][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084912] [Batch 03688/03692] [00:33:35/00:00:02, 0.547s/it]: train_loss_raw=0.3948, running_loss=0.4589, LR=0.000100
[2025-08-11 00:03:54,933][__main__][INFO] - [VALIDATION] [Epoch 22/29] Starting validation.
[2025-08-11 00:04:27,140][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 084917] [Batch 00011/00025] [00:00:32/00:00:34, 2.684s/it]
[2025-08-11 00:04:42,844][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 084917] [Batch 00023/00025] [00:00:47/00:00:01, 1.996s/it]
[2025-08-11 00:04:43,946][__main__][INFO] - [VALIDATION] [Epoch 22/29] train_loss=0.45844, valid_loss=0.58366
[2025-08-11 00:04:43,946][__main__][INFO] - [VALIDATION] [Epoch 22/29] Metrics:
[2025-08-11 00:04:43,947][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_er      0.235
[2025-08-11 00:04:43,947][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_prec    0.543
[2025-08-11 00:04:43,947][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_recall  0.549
[2025-08-11 00:04:43,947][__main__][INFO] - [VALIDATION] [Epoch 22/29] - pep_recall 0.542
[2025-08-11 00:04:43,951][__main__][INFO] - [TRAIN] [Epoch 22/29] Epoch complete, total time 13:08:43, remaining time 04:00:02, 00:34:17 per epoch
[2025-08-11 00:04:48,059][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084924] [Batch 00008/03692] [00:00:03/00:29:13, 0.476s/it]: train_loss_raw=0.4414, running_loss=0.4530, LR=0.000100
[2025-08-11 00:04:54,326][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084936] [Batch 00020/03692] [00:00:10/00:30:49, 0.504s/it]: train_loss_raw=0.4024, running_loss=0.4544, LR=0.000100
[2025-08-11 00:05:00,522][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084948] [Batch 00032/03692] [00:00:16/00:31:01, 0.508s/it]: train_loss_raw=0.5123, running_loss=0.4581, LR=0.000100
[2025-08-11 00:05:06,749][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084960] [Batch 00044/03692] [00:00:22/00:31:05, 0.511s/it]: train_loss_raw=0.5366, running_loss=0.4606, LR=0.000100
[2025-08-11 00:05:12,849][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084972] [Batch 00056/03692] [00:00:28/00:30:56, 0.511s/it]: train_loss_raw=0.3734, running_loss=0.4630, LR=0.000100
[2025-08-11 00:05:19,002][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084984] [Batch 00068/03692] [00:00:34/00:30:52, 0.511s/it]: train_loss_raw=0.4085, running_loss=0.4630, LR=0.000100
[2025-08-11 00:05:25,505][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084996] [Batch 00080/03692] [00:00:41/00:31:02, 0.516s/it]: train_loss_raw=0.3898, running_loss=0.4627, LR=0.000100
[2025-08-11 00:05:31,876][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085008] [Batch 00092/03692] [00:00:47/00:31:03, 0.518s/it]: train_loss_raw=0.4788, running_loss=0.4637, LR=0.000100
[2025-08-11 00:05:38,380][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085020] [Batch 00104/03692] [00:00:54/00:31:07, 0.520s/it]: train_loss_raw=0.3607, running_loss=0.4649, LR=0.000100
[2025-08-11 00:05:44,846][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085032] [Batch 00116/03692] [00:01:00/00:31:08, 0.522s/it]: train_loss_raw=0.5260, running_loss=0.4635, LR=0.000100
[2025-08-11 00:05:51,307][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085044] [Batch 00128/03692] [00:01:07/00:31:07, 0.524s/it]: train_loss_raw=0.4339, running_loss=0.4622, LR=0.000100
[2025-08-11 00:05:57,873][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085056] [Batch 00140/03692] [00:01:13/00:31:07, 0.526s/it]: train_loss_raw=0.3804, running_loss=0.4627, LR=0.000100
[2025-08-11 00:06:04,264][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085068] [Batch 00152/03692] [00:01:20/00:31:03, 0.526s/it]: train_loss_raw=0.4136, running_loss=0.4616, LR=0.000100
[2025-08-11 00:06:10,760][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085080] [Batch 00164/03692] [00:01:26/00:31:01, 0.527s/it]: train_loss_raw=0.4489, running_loss=0.4619, LR=0.000100
[2025-08-11 00:06:17,235][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085092] [Batch 00176/03692] [00:01:32/00:30:57, 0.528s/it]: train_loss_raw=0.4069, running_loss=0.4584, LR=0.000100
[2025-08-11 00:06:23,656][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085104] [Batch 00188/03692] [00:01:39/00:30:52, 0.529s/it]: train_loss_raw=0.4864, running_loss=0.4603, LR=0.000100
[2025-08-11 00:06:30,153][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085116] [Batch 00200/03692] [00:01:45/00:30:49, 0.530s/it]: train_loss_raw=0.4973, running_loss=0.4593, LR=0.000100
[2025-08-11 00:06:36,704][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085128] [Batch 00212/03692] [00:01:52/00:30:45, 0.530s/it]: train_loss_raw=0.4763, running_loss=0.4586, LR=0.000100
[2025-08-11 00:06:43,026][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085140] [Batch 00224/03692] [00:01:58/00:30:38, 0.530s/it]: train_loss_raw=0.5494, running_loss=0.4598, LR=0.000100
[2025-08-11 00:06:49,338][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085152] [Batch 00236/03692] [00:02:05/00:30:31, 0.530s/it]: train_loss_raw=0.4467, running_loss=0.4599, LR=0.000100
[2025-08-11 00:06:55,805][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085164] [Batch 00248/03692] [00:02:11/00:30:26, 0.530s/it]: train_loss_raw=0.5263, running_loss=0.4623, LR=0.000100
[2025-08-11 00:07:02,235][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085176] [Batch 00260/03692] [00:02:17/00:30:21, 0.531s/it]: train_loss_raw=0.4528, running_loss=0.4590, LR=0.000100
[2025-08-11 00:07:08,685][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085188] [Batch 00272/03692] [00:02:24/00:30:16, 0.531s/it]: train_loss_raw=0.4088, running_loss=0.4620, LR=0.000100
[2025-08-11 00:07:15,139][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085200] [Batch 00284/03692] [00:02:30/00:30:10, 0.531s/it]: train_loss_raw=0.5904, running_loss=0.4635, LR=0.000100
[2025-08-11 00:07:21,531][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085212] [Batch 00296/03692] [00:02:37/00:30:04, 0.531s/it]: train_loss_raw=0.3910, running_loss=0.4631, LR=0.000100
[2025-08-11 00:07:27,941][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085224] [Batch 00308/03692] [00:02:43/00:29:58, 0.531s/it]: train_loss_raw=0.5421, running_loss=0.4672, LR=0.000100
[2025-08-11 00:07:34,367][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085236] [Batch 00320/03692] [00:02:50/00:29:52, 0.532s/it]: train_loss_raw=0.4687, running_loss=0.4681, LR=0.000100
[2025-08-11 00:07:40,825][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085248] [Batch 00332/03692] [00:02:56/00:29:47, 0.532s/it]: train_loss_raw=0.4090, running_loss=0.4684, LR=0.000100
[2025-08-11 00:07:47,339][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085260] [Batch 00344/03692] [00:03:03/00:29:41, 0.532s/it]: train_loss_raw=0.4623, running_loss=0.4669, LR=0.000100
[2025-08-11 00:07:53,813][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085272] [Batch 00356/03692] [00:03:09/00:29:36, 0.532s/it]: train_loss_raw=0.4410, running_loss=0.4689, LR=0.000100
[2025-08-11 00:08:00,282][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085284] [Batch 00368/03692] [00:03:16/00:29:30, 0.533s/it]: train_loss_raw=0.3863, running_loss=0.4651, LR=0.000100
[2025-08-11 00:08:06,747][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085296] [Batch 00380/03692] [00:03:22/00:29:24, 0.533s/it]: train_loss_raw=0.5204, running_loss=0.4684, LR=0.000100
[2025-08-11 00:08:13,294][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085308] [Batch 00392/03692] [00:03:29/00:29:19, 0.533s/it]: train_loss_raw=0.4645, running_loss=0.4652, LR=0.000100
[2025-08-11 00:08:19,830][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085320] [Batch 00404/03692] [00:03:35/00:29:14, 0.534s/it]: train_loss_raw=0.3913, running_loss=0.4658, LR=0.000100
[2025-08-11 00:08:26,321][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085332] [Batch 00416/03692] [00:03:42/00:29:08, 0.534s/it]: train_loss_raw=0.4512, running_loss=0.4685, LR=0.000100
[2025-08-11 00:08:32,763][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085344] [Batch 00428/03692] [00:03:48/00:29:02, 0.534s/it]: train_loss_raw=0.4119, running_loss=0.4673, LR=0.000100
[2025-08-11 00:08:39,327][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085356] [Batch 00440/03692] [00:03:55/00:28:57, 0.534s/it]: train_loss_raw=0.5088, running_loss=0.4678, LR=0.000100
[2025-08-11 00:08:45,457][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085368] [Batch 00452/03692] [00:04:01/00:28:49, 0.534s/it]: train_loss_raw=0.4585, running_loss=0.4668, LR=0.000100
[2025-08-11 00:08:51,809][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085380] [Batch 00464/03692] [00:04:07/00:28:42, 0.534s/it]: train_loss_raw=0.4578, running_loss=0.4657, LR=0.000100
[2025-08-11 00:08:58,292][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085392] [Batch 00476/03692] [00:04:14/00:28:36, 0.534s/it]: train_loss_raw=0.3746, running_loss=0.4645, LR=0.000100
[2025-08-11 00:09:04,693][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085404] [Batch 00488/03692] [00:04:20/00:28:29, 0.534s/it]: train_loss_raw=0.4707, running_loss=0.4679, LR=0.000100
[2025-08-11 00:09:10,915][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085416] [Batch 00500/03692] [00:04:26/00:28:22, 0.533s/it]: train_loss_raw=0.4594, running_loss=0.4655, LR=0.000100
[2025-08-11 00:09:17,025][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085428] [Batch 00512/03692] [00:04:32/00:28:14, 0.533s/it]: train_loss_raw=0.4041, running_loss=0.4646, LR=0.000100
[2025-08-11 00:09:23,009][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085440] [Batch 00524/03692] [00:04:38/00:28:05, 0.532s/it]: train_loss_raw=0.3507, running_loss=0.4643, LR=0.000100
[2025-08-11 00:09:29,077][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085452] [Batch 00536/03692] [00:04:44/00:27:57, 0.531s/it]: train_loss_raw=0.4122, running_loss=0.4650, LR=0.000100
[2025-08-11 00:09:35,405][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085464] [Batch 00548/03692] [00:04:51/00:27:50, 0.531s/it]: train_loss_raw=0.3411, running_loss=0.4663, LR=0.000100
[2025-08-11 00:09:42,040][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085476] [Batch 00560/03692] [00:04:57/00:27:45, 0.532s/it]: train_loss_raw=0.4716, running_loss=0.4695, LR=0.000100
[2025-08-11 00:09:48,508][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085488] [Batch 00572/03692] [00:05:04/00:27:39, 0.532s/it]: train_loss_raw=0.3506, running_loss=0.4675, LR=0.000100
[2025-08-11 00:09:55,106][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085500] [Batch 00584/03692] [00:05:10/00:27:34, 0.532s/it]: train_loss_raw=0.4719, running_loss=0.4687, LR=0.000100
[2025-08-11 00:10:01,615][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085512] [Batch 00596/03692] [00:05:17/00:27:28, 0.532s/it]: train_loss_raw=0.4054, running_loss=0.4681, LR=0.000100
[2025-08-11 00:10:08,207][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085524] [Batch 00608/03692] [00:05:23/00:27:23, 0.533s/it]: train_loss_raw=0.4265, running_loss=0.4677, LR=0.000100
[2025-08-11 00:10:14,631][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085536] [Batch 00620/03692] [00:05:30/00:27:16, 0.533s/it]: train_loss_raw=0.3836, running_loss=0.4669, LR=0.000100
[2025-08-11 00:10:21,082][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085548] [Batch 00632/03692] [00:05:36/00:27:10, 0.533s/it]: train_loss_raw=0.5674, running_loss=0.4709, LR=0.000100
[2025-08-11 00:10:27,509][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085560] [Batch 00644/03692] [00:05:43/00:27:04, 0.533s/it]: train_loss_raw=0.5436, running_loss=0.4713, LR=0.000100
[2025-08-11 00:10:33,938][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085572] [Batch 00656/03692] [00:05:49/00:26:58, 0.533s/it]: train_loss_raw=0.4996, running_loss=0.4702, LR=0.000100
[2025-08-11 00:10:40,270][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085584] [Batch 00668/03692] [00:05:56/00:26:51, 0.533s/it]: train_loss_raw=0.4759, running_loss=0.4729, LR=0.000100
[2025-08-11 00:10:46,632][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085596] [Batch 00680/03692] [00:06:02/00:26:45, 0.533s/it]: train_loss_raw=0.3841, running_loss=0.4686, LR=0.000100
[2025-08-11 00:10:53,133][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085608] [Batch 00692/03692] [00:06:08/00:26:39, 0.533s/it]: train_loss_raw=0.3787, running_loss=0.4680, LR=0.000100
[2025-08-11 00:10:59,653][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085620] [Batch 00704/03692] [00:06:15/00:26:33, 0.533s/it]: train_loss_raw=0.4405, running_loss=0.4665, LR=0.000100
[2025-08-11 00:11:06,169][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085632] [Batch 00716/03692] [00:06:21/00:26:27, 0.533s/it]: train_loss_raw=0.4715, running_loss=0.4651, LR=0.000100
[2025-08-11 00:11:12,723][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085644] [Batch 00728/03692] [00:06:28/00:26:21, 0.534s/it]: train_loss_raw=0.4230, running_loss=0.4651, LR=0.000100
[2025-08-11 00:11:19,278][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085656] [Batch 00740/03692] [00:06:35/00:26:15, 0.534s/it]: train_loss_raw=0.3757, running_loss=0.4619, LR=0.000100
[2025-08-11 00:11:25,805][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085668] [Batch 00752/03692] [00:06:41/00:26:09, 0.534s/it]: train_loss_raw=0.4786, running_loss=0.4605, LR=0.000100
[2025-08-11 00:11:32,272][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085680] [Batch 00764/03692] [00:06:48/00:26:03, 0.534s/it]: train_loss_raw=0.3691, running_loss=0.4607, LR=0.000100
[2025-08-11 00:11:38,474][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085692] [Batch 00776/03692] [00:06:54/00:25:56, 0.534s/it]: train_loss_raw=0.5178, running_loss=0.4625, LR=0.000100
[2025-08-11 00:11:44,952][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085704] [Batch 00788/03692] [00:07:00/00:25:50, 0.534s/it]: train_loss_raw=0.4848, running_loss=0.4631, LR=0.000100
[2025-08-11 00:11:51,536][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085716] [Batch 00800/03692] [00:07:07/00:25:44, 0.534s/it]: train_loss_raw=0.4584, running_loss=0.4633, LR=0.000100
[2025-08-11 00:11:58,041][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085728] [Batch 00812/03692] [00:07:13/00:25:38, 0.534s/it]: train_loss_raw=0.5434, running_loss=0.4652, LR=0.000100
[2025-08-11 00:12:04,547][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085740] [Batch 00824/03692] [00:07:20/00:25:32, 0.534s/it]: train_loss_raw=0.4787, running_loss=0.4668, LR=0.000100
[2025-08-11 00:12:10,972][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085752] [Batch 00836/03692] [00:07:26/00:25:26, 0.534s/it]: train_loss_raw=0.4580, running_loss=0.4641, LR=0.000100
[2025-08-11 00:12:17,380][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085764] [Batch 00848/03692] [00:07:33/00:25:19, 0.534s/it]: train_loss_raw=0.4282, running_loss=0.4603, LR=0.000100
[2025-08-11 00:12:23,807][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085776] [Batch 00860/03692] [00:07:39/00:25:13, 0.534s/it]: train_loss_raw=0.4328, running_loss=0.4588, LR=0.000100
[2025-08-11 00:12:30,207][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085788] [Batch 00872/03692] [00:07:45/00:25:06, 0.534s/it]: train_loss_raw=0.4175, running_loss=0.4572, LR=0.000100
[2025-08-11 00:12:36,579][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085800] [Batch 00884/03692] [00:07:52/00:25:00, 0.534s/it]: train_loss_raw=0.3624, running_loss=0.4591, LR=0.000100
[2025-08-11 00:12:42,800][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085812] [Batch 00896/03692] [00:07:58/00:24:53, 0.534s/it]: train_loss_raw=0.4190, running_loss=0.4551, LR=0.000100
[2025-08-11 00:12:49,064][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085824] [Batch 00908/03692] [00:08:04/00:24:46, 0.534s/it]: train_loss_raw=0.4767, running_loss=0.4558, LR=0.000100
[2025-08-11 00:12:55,463][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085836] [Batch 00920/03692] [00:08:11/00:24:40, 0.534s/it]: train_loss_raw=0.3880, running_loss=0.4574, LR=0.000100
[2025-08-11 00:13:01,880][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085848] [Batch 00932/03692] [00:08:17/00:24:33, 0.534s/it]: train_loss_raw=0.4050, running_loss=0.4557, LR=0.000100
[2025-08-11 00:13:08,340][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085860] [Batch 00944/03692] [00:08:24/00:24:27, 0.534s/it]: train_loss_raw=0.5624, running_loss=0.4562, LR=0.000100
[2025-08-11 00:13:14,881][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085872] [Batch 00956/03692] [00:08:30/00:24:21, 0.534s/it]: train_loss_raw=0.5780, running_loss=0.4566, LR=0.000100
[2025-08-11 00:13:21,331][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085884] [Batch 00968/03692] [00:08:37/00:24:15, 0.534s/it]: train_loss_raw=0.4441, running_loss=0.4564, LR=0.000100
[2025-08-11 00:13:27,725][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085896] [Batch 00980/03692] [00:08:43/00:24:08, 0.534s/it]: train_loss_raw=0.4738, running_loss=0.4557, LR=0.000100
[2025-08-11 00:13:34,161][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085908] [Batch 00992/03692] [00:08:49/00:24:02, 0.534s/it]: train_loss_raw=0.5017, running_loss=0.4580, LR=0.000100
[2025-08-11 00:13:40,707][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085920] [Batch 01004/03692] [00:08:56/00:23:56, 0.534s/it]: train_loss_raw=0.5541, running_loss=0.4604, LR=0.000100
[2025-08-11 00:13:47,102][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085932] [Batch 01016/03692] [00:09:02/00:23:49, 0.534s/it]: train_loss_raw=0.4569, running_loss=0.4603, LR=0.000100
[2025-08-11 00:13:53,596][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085944] [Batch 01028/03692] [00:09:09/00:23:43, 0.534s/it]: train_loss_raw=0.3301, running_loss=0.4567, LR=0.000100
[2025-08-11 00:14:00,190][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085956] [Batch 01040/03692] [00:09:15/00:23:37, 0.535s/it]: train_loss_raw=0.3645, running_loss=0.4542, LR=0.000100
[2025-08-11 00:14:06,605][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085968] [Batch 01052/03692] [00:09:22/00:23:31, 0.535s/it]: train_loss_raw=0.3902, running_loss=0.4566, LR=0.000100
[2025-08-11 00:14:13,088][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085980] [Batch 01064/03692] [00:09:28/00:23:24, 0.535s/it]: train_loss_raw=0.4478, running_loss=0.4536, LR=0.000100
[2025-08-11 00:14:19,440][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085992] [Batch 01076/03692] [00:09:35/00:23:18, 0.535s/it]: train_loss_raw=0.4527, running_loss=0.4521, LR=0.000100
[2025-08-11 00:14:30,631][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086004] [Batch 01088/03692] [00:09:46/00:23:23, 0.539s/it]: train_loss_raw=0.6697, running_loss=0.4533, LR=0.000100
[2025-08-11 00:14:36,785][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086016] [Batch 01100/03692] [00:09:52/00:23:16, 0.539s/it]: train_loss_raw=0.4579, running_loss=0.4540, LR=0.000100
[2025-08-11 00:14:43,298][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086028] [Batch 01112/03692] [00:09:59/00:23:09, 0.539s/it]: train_loss_raw=0.4747, running_loss=0.4533, LR=0.000100
[2025-08-11 00:14:49,825][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086040] [Batch 01124/03692] [00:10:05/00:23:03, 0.539s/it]: train_loss_raw=0.4127, running_loss=0.4524, LR=0.000100
[2025-08-11 00:14:56,419][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086052] [Batch 01136/03692] [00:10:12/00:22:57, 0.539s/it]: train_loss_raw=0.4547, running_loss=0.4537, LR=0.000100
[2025-08-11 00:15:02,931][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086064] [Batch 01148/03692] [00:10:18/00:22:51, 0.539s/it]: train_loss_raw=0.4991, running_loss=0.4538, LR=0.000100
[2025-08-11 00:15:09,437][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086076] [Batch 01160/03692] [00:10:25/00:22:44, 0.539s/it]: train_loss_raw=0.4069, running_loss=0.4570, LR=0.000100
[2025-08-11 00:15:15,816][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086088] [Batch 01172/03692] [00:10:31/00:22:37, 0.539s/it]: train_loss_raw=0.4330, running_loss=0.4536, LR=0.000100
[2025-08-11 00:15:22,294][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086100] [Batch 01184/03692] [00:10:38/00:22:31, 0.539s/it]: train_loss_raw=0.4955, running_loss=0.4561, LR=0.000100
[2025-08-11 00:15:28,584][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086112] [Batch 01196/03692] [00:10:44/00:22:24, 0.539s/it]: train_loss_raw=0.4081, running_loss=0.4607, LR=0.000100
[2025-08-11 00:15:35,065][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086124] [Batch 01208/03692] [00:10:50/00:22:18, 0.539s/it]: train_loss_raw=0.3470, running_loss=0.4559, LR=0.000100
[2025-08-11 00:15:41,570][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086136] [Batch 01220/03692] [00:10:57/00:22:11, 0.539s/it]: train_loss_raw=0.4791, running_loss=0.4543, LR=0.000100
[2025-08-11 00:15:48,036][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086148] [Batch 01232/03692] [00:11:03/00:22:05, 0.539s/it]: train_loss_raw=0.4802, running_loss=0.4501, LR=0.000100
[2025-08-11 00:15:54,420][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086160] [Batch 01244/03692] [00:11:10/00:21:58, 0.539s/it]: train_loss_raw=0.5275, running_loss=0.4537, LR=0.000100
[2025-08-11 00:16:00,747][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086172] [Batch 01256/03692] [00:11:16/00:21:52, 0.539s/it]: train_loss_raw=0.4716, running_loss=0.4530, LR=0.000100
[2025-08-11 00:16:07,080][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086184] [Batch 01268/03692] [00:11:22/00:21:45, 0.539s/it]: train_loss_raw=0.5086, running_loss=0.4531, LR=0.000100
[2025-08-11 00:16:13,491][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086196] [Batch 01280/03692] [00:11:29/00:21:38, 0.538s/it]: train_loss_raw=0.4437, running_loss=0.4549, LR=0.000100
[2025-08-11 00:16:19,842][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086208] [Batch 01292/03692] [00:11:35/00:21:32, 0.538s/it]: train_loss_raw=0.4921, running_loss=0.4555, LR=0.000100
[2025-08-11 00:16:26,178][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086220] [Batch 01304/03692] [00:11:41/00:21:25, 0.538s/it]: train_loss_raw=0.3940, running_loss=0.4540, LR=0.000100
[2025-08-11 00:16:32,544][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086232] [Batch 01316/03692] [00:11:48/00:21:18, 0.538s/it]: train_loss_raw=0.5112, running_loss=0.4544, LR=0.000100
[2025-08-11 00:16:38,956][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086244] [Batch 01328/03692] [00:11:54/00:21:12, 0.538s/it]: train_loss_raw=0.5055, running_loss=0.4546, LR=0.000100
[2025-08-11 00:16:45,359][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086256] [Batch 01340/03692] [00:12:01/00:21:05, 0.538s/it]: train_loss_raw=0.4394, running_loss=0.4526, LR=0.000100
[2025-08-11 00:16:51,977][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086268] [Batch 01352/03692] [00:12:07/00:20:59, 0.538s/it]: train_loss_raw=0.4823, running_loss=0.4542, LR=0.000100
[2025-08-11 00:16:58,415][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086280] [Batch 01364/03692] [00:12:14/00:20:53, 0.538s/it]: train_loss_raw=0.4581, running_loss=0.4548, LR=0.000100
[2025-08-11 00:17:04,754][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086292] [Batch 01376/03692] [00:12:20/00:20:46, 0.538s/it]: train_loss_raw=0.4356, running_loss=0.4547, LR=0.000100
[2025-08-11 00:17:11,058][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086304] [Batch 01388/03692] [00:12:26/00:20:39, 0.538s/it]: train_loss_raw=0.4941, running_loss=0.4537, LR=0.000100
[2025-08-11 00:17:17,440][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086316] [Batch 01400/03692] [00:12:33/00:20:33, 0.538s/it]: train_loss_raw=0.4831, running_loss=0.4542, LR=0.000100
[2025-08-11 00:17:23,917][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086328] [Batch 01412/03692] [00:12:39/00:20:26, 0.538s/it]: train_loss_raw=0.3810, running_loss=0.4512, LR=0.000100
[2025-08-11 00:17:30,322][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086340] [Batch 01424/03692] [00:12:46/00:20:20, 0.538s/it]: train_loss_raw=0.4961, running_loss=0.4510, LR=0.000100
[2025-08-11 00:17:36,708][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086352] [Batch 01436/03692] [00:12:52/00:20:13, 0.538s/it]: train_loss_raw=0.4840, running_loss=0.4505, LR=0.000100
[2025-08-11 00:17:43,167][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086364] [Batch 01448/03692] [00:12:58/00:20:07, 0.538s/it]: train_loss_raw=0.5375, running_loss=0.4530, LR=0.000100
[2025-08-11 00:17:49,660][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086376] [Batch 01460/03692] [00:13:05/00:20:00, 0.538s/it]: train_loss_raw=0.5153, running_loss=0.4538, LR=0.000100
[2025-08-11 00:17:56,021][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086388] [Batch 01472/03692] [00:13:11/00:19:54, 0.538s/it]: train_loss_raw=0.4702, running_loss=0.4556, LR=0.000100
[2025-08-11 00:18:02,413][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086400] [Batch 01484/03692] [00:13:18/00:19:47, 0.538s/it]: train_loss_raw=0.4702, running_loss=0.4575, LR=0.000100
[2025-08-11 00:18:08,874][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086412] [Batch 01496/03692] [00:13:24/00:19:41, 0.538s/it]: train_loss_raw=0.4245, running_loss=0.4565, LR=0.000100
[2025-08-11 00:18:15,155][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086424] [Batch 01508/03692] [00:13:30/00:19:34, 0.538s/it]: train_loss_raw=0.5836, running_loss=0.4572, LR=0.000100
[2025-08-11 00:18:21,234][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086436] [Batch 01520/03692] [00:13:36/00:19:27, 0.537s/it]: train_loss_raw=0.5163, running_loss=0.4571, LR=0.000100
[2025-08-11 00:18:27,741][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086448] [Batch 01532/03692] [00:13:43/00:19:21, 0.538s/it]: train_loss_raw=0.3788, running_loss=0.4589, LR=0.000100
[2025-08-11 00:18:34,252][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086460] [Batch 01544/03692] [00:13:50/00:19:14, 0.538s/it]: train_loss_raw=0.4168, running_loss=0.4571, LR=0.000100
[2025-08-11 00:18:40,748][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086472] [Batch 01556/03692] [00:13:56/00:19:08, 0.538s/it]: train_loss_raw=0.4493, running_loss=0.4556, LR=0.000100
[2025-08-11 00:18:47,094][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086484] [Batch 01568/03692] [00:14:02/00:19:01, 0.538s/it]: train_loss_raw=0.4944, running_loss=0.4558, LR=0.000100
[2025-08-11 00:18:53,156][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086496] [Batch 01580/03692] [00:14:08/00:18:54, 0.537s/it]: train_loss_raw=0.4713, running_loss=0.4541, LR=0.000100
[2025-08-11 00:18:59,458][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086508] [Batch 01592/03692] [00:14:15/00:18:48, 0.537s/it]: train_loss_raw=0.4918, running_loss=0.4554, LR=0.000100
[2025-08-11 00:19:05,810][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086520] [Batch 01604/03692] [00:14:21/00:18:41, 0.537s/it]: train_loss_raw=0.4536, running_loss=0.4577, LR=0.000100
[2025-08-11 00:19:11,882][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086532] [Batch 01616/03692] [00:14:27/00:18:34, 0.537s/it]: train_loss_raw=0.4018, running_loss=0.4556, LR=0.000100
[2025-08-11 00:19:17,995][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086544] [Batch 01628/03692] [00:14:33/00:18:27, 0.537s/it]: train_loss_raw=0.4704, running_loss=0.4566, LR=0.000100
[2025-08-11 00:19:24,144][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086556] [Batch 01640/03692] [00:14:39/00:18:20, 0.537s/it]: train_loss_raw=0.3817, running_loss=0.4573, LR=0.000100
[2025-08-11 00:19:30,360][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086568] [Batch 01652/03692] [00:14:46/00:18:14, 0.536s/it]: train_loss_raw=0.4994, running_loss=0.4566, LR=0.000100
[2025-08-11 00:19:36,534][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086580] [Batch 01664/03692] [00:14:52/00:18:07, 0.536s/it]: train_loss_raw=0.5412, running_loss=0.4585, LR=0.000100
[2025-08-11 00:19:42,858][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086592] [Batch 01676/03692] [00:14:58/00:18:00, 0.536s/it]: train_loss_raw=0.4735, running_loss=0.4591, LR=0.000100
[2025-08-11 00:19:49,225][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086604] [Batch 01688/03692] [00:15:04/00:17:54, 0.536s/it]: train_loss_raw=0.4738, running_loss=0.4605, LR=0.000100
[2025-08-11 00:19:55,287][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086616] [Batch 01700/03692] [00:15:11/00:17:47, 0.536s/it]: train_loss_raw=0.5673, running_loss=0.4584, LR=0.000100
[2025-08-11 00:20:01,349][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086628] [Batch 01712/03692] [00:15:17/00:17:40, 0.536s/it]: train_loss_raw=0.4105, running_loss=0.4574, LR=0.000100
[2025-08-11 00:20:07,380][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086640] [Batch 01724/03692] [00:15:23/00:17:33, 0.535s/it]: train_loss_raw=0.4252, running_loss=0.4571, LR=0.000100
[2025-08-11 00:20:13,931][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086652] [Batch 01736/03692] [00:15:29/00:17:27, 0.536s/it]: train_loss_raw=0.4552, running_loss=0.4553, LR=0.000100
[2025-08-11 00:20:20,441][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086664] [Batch 01748/03692] [00:15:36/00:17:21, 0.536s/it]: train_loss_raw=0.3237, running_loss=0.4549, LR=0.000100
[2025-08-11 00:20:26,640][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086676] [Batch 01760/03692] [00:15:42/00:17:14, 0.535s/it]: train_loss_raw=0.3802, running_loss=0.4538, LR=0.000100
[2025-08-11 00:20:32,814][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086688] [Batch 01772/03692] [00:15:48/00:17:07, 0.535s/it]: train_loss_raw=0.5147, running_loss=0.4548, LR=0.000100
[2025-08-11 00:20:38,981][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086700] [Batch 01784/03692] [00:15:54/00:17:01, 0.535s/it]: train_loss_raw=0.4399, running_loss=0.4557, LR=0.000100
[2025-08-11 00:20:45,197][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086712] [Batch 01796/03692] [00:16:00/00:16:54, 0.535s/it]: train_loss_raw=0.4962, running_loss=0.4570, LR=0.000100
[2025-08-11 00:20:51,398][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086724] [Batch 01808/03692] [00:16:07/00:16:47, 0.535s/it]: train_loss_raw=0.3608, running_loss=0.4589, LR=0.000100
[2025-08-11 00:20:57,517][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086736] [Batch 01820/03692] [00:16:13/00:16:41, 0.535s/it]: train_loss_raw=0.4837, running_loss=0.4633, LR=0.000100
[2025-08-11 00:21:03,605][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086748] [Batch 01832/03692] [00:16:19/00:16:34, 0.535s/it]: train_loss_raw=0.4083, running_loss=0.4603, LR=0.000100
[2025-08-11 00:21:09,848][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086760] [Batch 01844/03692] [00:16:25/00:16:27, 0.534s/it]: train_loss_raw=0.5024, running_loss=0.4625, LR=0.000100
[2025-08-11 00:21:16,263][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086772] [Batch 01856/03692] [00:16:32/00:16:21, 0.534s/it]: train_loss_raw=0.4623, running_loss=0.4622, LR=0.000100
[2025-08-11 00:21:22,598][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086784] [Batch 01868/03692] [00:16:38/00:16:14, 0.534s/it]: train_loss_raw=0.4697, running_loss=0.4615, LR=0.000100
[2025-08-11 00:21:28,730][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086796] [Batch 01880/03692] [00:16:44/00:16:08, 0.534s/it]: train_loss_raw=0.4415, running_loss=0.4616, LR=0.000100
[2025-08-11 00:21:35,083][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086808] [Batch 01892/03692] [00:16:50/00:16:01, 0.534s/it]: train_loss_raw=0.4707, running_loss=0.4579, LR=0.000100
[2025-08-11 00:21:41,486][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086820] [Batch 01904/03692] [00:16:57/00:15:55, 0.534s/it]: train_loss_raw=0.4337, running_loss=0.4569, LR=0.000100
[2025-08-11 00:21:47,913][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086832] [Batch 01916/03692] [00:17:03/00:15:48, 0.534s/it]: train_loss_raw=0.3636, running_loss=0.4553, LR=0.000100
[2025-08-11 00:21:54,369][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086844] [Batch 01928/03692] [00:17:10/00:15:42, 0.534s/it]: train_loss_raw=0.5596, running_loss=0.4569, LR=0.000100
[2025-08-11 00:22:00,786][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086856] [Batch 01940/03692] [00:17:16/00:15:36, 0.534s/it]: train_loss_raw=0.4855, running_loss=0.4566, LR=0.000100
[2025-08-11 00:22:07,186][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086868] [Batch 01952/03692] [00:17:22/00:15:29, 0.534s/it]: train_loss_raw=0.5023, running_loss=0.4553, LR=0.000100
[2025-08-11 00:22:13,491][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086880] [Batch 01964/03692] [00:17:29/00:15:23, 0.534s/it]: train_loss_raw=0.5438, running_loss=0.4560, LR=0.000100
[2025-08-11 00:22:19,746][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086892] [Batch 01976/03692] [00:17:35/00:15:16, 0.534s/it]: train_loss_raw=0.4095, running_loss=0.4563, LR=0.000100
[2025-08-11 00:22:26,118][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086904] [Batch 01988/03692] [00:17:41/00:15:10, 0.534s/it]: train_loss_raw=0.5464, running_loss=0.4541, LR=0.000100
[2025-08-11 00:22:32,805][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086916] [Batch 02000/03692] [00:17:48/00:15:03, 0.534s/it]: train_loss_raw=0.4272, running_loss=0.4520, LR=0.000100
[2025-08-11 00:22:39,099][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086928] [Batch 02012/03692] [00:17:54/00:14:57, 0.534s/it]: train_loss_raw=0.4639, running_loss=0.4521, LR=0.000100
[2025-08-11 00:22:45,556][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086940] [Batch 02024/03692] [00:18:01/00:14:51, 0.534s/it]: train_loss_raw=0.3186, running_loss=0.4474, LR=0.000100
[2025-08-11 00:22:52,020][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086952] [Batch 02036/03692] [00:18:07/00:14:44, 0.534s/it]: train_loss_raw=0.3878, running_loss=0.4477, LR=0.000100
[2025-08-11 00:22:58,365][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086964] [Batch 02048/03692] [00:18:14/00:14:38, 0.534s/it]: train_loss_raw=0.4801, running_loss=0.4497, LR=0.000100
[2025-08-11 00:23:04,881][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086976] [Batch 02060/03692] [00:18:20/00:14:31, 0.534s/it]: train_loss_raw=0.4642, running_loss=0.4458, LR=0.000100
[2025-08-11 00:23:11,213][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086988] [Batch 02072/03692] [00:18:26/00:14:25, 0.534s/it]: train_loss_raw=0.3318, running_loss=0.4455, LR=0.000100
[2025-08-11 00:23:17,441][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087000] [Batch 02084/03692] [00:18:33/00:14:18, 0.534s/it]: train_loss_raw=0.4684, running_loss=0.4467, LR=0.000100
[2025-08-11 00:23:23,965][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087012] [Batch 02096/03692] [00:18:39/00:14:12, 0.534s/it]: train_loss_raw=0.4719, running_loss=0.4445, LR=0.000100
[2025-08-11 00:23:30,403][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087024] [Batch 02108/03692] [00:18:46/00:14:06, 0.534s/it]: train_loss_raw=0.4782, running_loss=0.4449, LR=0.000100
[2025-08-11 00:23:36,896][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087036] [Batch 02120/03692] [00:18:52/00:13:59, 0.534s/it]: train_loss_raw=0.3762, running_loss=0.4444, LR=0.000100
[2025-08-11 00:23:43,438][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087048] [Batch 02132/03692] [00:18:59/00:13:53, 0.534s/it]: train_loss_raw=0.5115, running_loss=0.4452, LR=0.000100
[2025-08-11 00:23:49,905][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087060] [Batch 02144/03692] [00:19:05/00:13:47, 0.534s/it]: train_loss_raw=0.4649, running_loss=0.4469, LR=0.000100
[2025-08-11 00:23:56,209][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087072] [Batch 02156/03692] [00:19:11/00:13:40, 0.534s/it]: train_loss_raw=0.5671, running_loss=0.4500, LR=0.000100
[2025-08-11 00:24:02,741][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087084] [Batch 02168/03692] [00:19:18/00:13:34, 0.534s/it]: train_loss_raw=0.4617, running_loss=0.4509, LR=0.000100
[2025-08-11 00:24:09,403][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087096] [Batch 02180/03692] [00:19:25/00:13:28, 0.534s/it]: train_loss_raw=0.3363, running_loss=0.4517, LR=0.000100
[2025-08-11 00:24:15,765][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087108] [Batch 02192/03692] [00:19:31/00:13:21, 0.534s/it]: train_loss_raw=0.4170, running_loss=0.4530, LR=0.000100
[2025-08-11 00:24:21,857][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087120] [Batch 02204/03692] [00:19:37/00:13:15, 0.534s/it]: train_loss_raw=0.6347, running_loss=0.4541, LR=0.000100
[2025-08-11 00:24:27,854][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087132] [Batch 02216/03692] [00:19:43/00:13:08, 0.534s/it]: train_loss_raw=0.5656, running_loss=0.4533, LR=0.000100
[2025-08-11 00:24:34,354][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087144] [Batch 02228/03692] [00:19:50/00:13:02, 0.534s/it]: train_loss_raw=0.4123, running_loss=0.4516, LR=0.000100
[2025-08-11 00:24:40,859][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087156] [Batch 02240/03692] [00:19:56/00:12:55, 0.534s/it]: train_loss_raw=0.4757, running_loss=0.4545, LR=0.000100
[2025-08-11 00:24:47,109][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087168] [Batch 02252/03692] [00:20:02/00:12:49, 0.534s/it]: train_loss_raw=0.4255, running_loss=0.4524, LR=0.000100
[2025-08-11 00:24:53,153][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087180] [Batch 02264/03692] [00:20:08/00:12:42, 0.534s/it]: train_loss_raw=0.3525, running_loss=0.4512, LR=0.000100
[2025-08-11 00:24:59,225][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087192] [Batch 02276/03692] [00:20:14/00:12:35, 0.534s/it]: train_loss_raw=0.4527, running_loss=0.4508, LR=0.000100
[2025-08-11 00:25:05,229][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087204] [Batch 02288/03692] [00:20:20/00:12:29, 0.534s/it]: train_loss_raw=0.4419, running_loss=0.4537, LR=0.000100
[2025-08-11 00:25:11,246][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087216] [Batch 02300/03692] [00:20:26/00:12:22, 0.533s/it]: train_loss_raw=0.4664, running_loss=0.4552, LR=0.000100
[2025-08-11 00:25:17,307][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087228] [Batch 02312/03692] [00:20:33/00:12:15, 0.533s/it]: train_loss_raw=0.4303, running_loss=0.4561, LR=0.000100
[2025-08-11 00:25:23,525][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087240] [Batch 02324/03692] [00:20:39/00:12:09, 0.533s/it]: train_loss_raw=0.4741, running_loss=0.4596, LR=0.000100
[2025-08-11 00:25:29,672][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087252] [Batch 02336/03692] [00:20:45/00:12:02, 0.533s/it]: train_loss_raw=0.4089, running_loss=0.4560, LR=0.000100
[2025-08-11 00:25:35,990][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087264] [Batch 02348/03692] [00:20:51/00:11:56, 0.533s/it]: train_loss_raw=0.4498, running_loss=0.4555, LR=0.000100
[2025-08-11 00:25:42,537][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087276] [Batch 02360/03692] [00:20:58/00:11:50, 0.533s/it]: train_loss_raw=0.4469, running_loss=0.4541, LR=0.000100
[2025-08-11 00:25:48,758][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087288] [Batch 02372/03692] [00:21:04/00:11:43, 0.533s/it]: train_loss_raw=0.4935, running_loss=0.4568, LR=0.000100
[2025-08-11 00:25:54,880][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087300] [Batch 02384/03692] [00:21:10/00:11:37, 0.533s/it]: train_loss_raw=0.4222, running_loss=0.4571, LR=0.000100
[2025-08-11 00:26:01,031][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087312] [Batch 02396/03692] [00:21:16/00:11:30, 0.533s/it]: train_loss_raw=0.4141, running_loss=0.4554, LR=0.000100
[2025-08-11 00:26:07,241][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087324] [Batch 02408/03692] [00:21:22/00:11:24, 0.533s/it]: train_loss_raw=0.5239, running_loss=0.4573, LR=0.000100
[2025-08-11 00:26:13,542][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087336] [Batch 02420/03692] [00:21:29/00:11:17, 0.533s/it]: train_loss_raw=0.3341, running_loss=0.4553, LR=0.000100
[2025-08-11 00:26:19,932][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087348] [Batch 02432/03692] [00:21:35/00:11:11, 0.533s/it]: train_loss_raw=0.6193, running_loss=0.4591, LR=0.000100
[2025-08-11 00:26:26,484][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087360] [Batch 02444/03692] [00:21:42/00:11:04, 0.533s/it]: train_loss_raw=0.4153, running_loss=0.4591, LR=0.000100
[2025-08-11 00:26:33,053][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087372] [Batch 02456/03692] [00:21:48/00:10:58, 0.533s/it]: train_loss_raw=0.4284, running_loss=0.4602, LR=0.000100
[2025-08-11 00:26:39,670][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087384] [Batch 02468/03692] [00:21:55/00:10:52, 0.533s/it]: train_loss_raw=0.4166, running_loss=0.4584, LR=0.000100
[2025-08-11 00:26:46,107][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087396] [Batch 02480/03692] [00:22:01/00:10:46, 0.533s/it]: train_loss_raw=0.4348, running_loss=0.4573, LR=0.000100
[2025-08-11 00:26:52,630][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087408] [Batch 02492/03692] [00:22:08/00:10:39, 0.533s/it]: train_loss_raw=0.4729, running_loss=0.4548, LR=0.000100
[2025-08-11 00:26:59,125][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087420] [Batch 02504/03692] [00:22:14/00:10:33, 0.533s/it]: train_loss_raw=0.3954, running_loss=0.4547, LR=0.000100
[2025-08-11 00:27:05,581][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087432] [Batch 02516/03692] [00:22:21/00:10:26, 0.533s/it]: train_loss_raw=0.4066, running_loss=0.4554, LR=0.000100
[2025-08-11 00:27:11,989][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087444] [Batch 02528/03692] [00:22:27/00:10:20, 0.533s/it]: train_loss_raw=0.3986, running_loss=0.4527, LR=0.000100
[2025-08-11 00:27:18,405][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087456] [Batch 02540/03692] [00:22:34/00:10:14, 0.533s/it]: train_loss_raw=0.5374, running_loss=0.4545, LR=0.000100
[2025-08-11 00:27:24,775][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087468] [Batch 02552/03692] [00:22:40/00:10:07, 0.533s/it]: train_loss_raw=0.4664, running_loss=0.4570, LR=0.000100
[2025-08-11 00:27:30,897][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087480] [Batch 02564/03692] [00:22:46/00:10:01, 0.533s/it]: train_loss_raw=0.4513, running_loss=0.4547, LR=0.000100
[2025-08-11 00:27:37,046][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087492] [Batch 02576/03692] [00:22:52/00:09:54, 0.533s/it]: train_loss_raw=0.4981, running_loss=0.4569, LR=0.000100
[2025-08-11 00:27:43,219][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087504] [Batch 02588/03692] [00:22:58/00:09:48, 0.533s/it]: train_loss_raw=0.4249, running_loss=0.4567, LR=0.000100
[2025-08-11 00:27:49,546][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087516] [Batch 02600/03692] [00:23:05/00:09:41, 0.533s/it]: train_loss_raw=0.4655, running_loss=0.4563, LR=0.000100
[2025-08-11 00:27:55,596][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087528] [Batch 02612/03692] [00:23:11/00:09:35, 0.533s/it]: train_loss_raw=0.4409, running_loss=0.4557, LR=0.000100
[2025-08-11 00:28:01,986][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087540] [Batch 02624/03692] [00:23:17/00:09:28, 0.533s/it]: train_loss_raw=0.4709, running_loss=0.4558, LR=0.000100
[2025-08-11 00:28:08,209][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087552] [Batch 02636/03692] [00:23:23/00:09:22, 0.533s/it]: train_loss_raw=0.4785, running_loss=0.4565, LR=0.000100
[2025-08-11 00:28:14,685][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087564] [Batch 02648/03692] [00:23:30/00:09:16, 0.533s/it]: train_loss_raw=0.4449, running_loss=0.4591, LR=0.000100
[2025-08-11 00:28:21,066][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087576] [Batch 02660/03692] [00:23:36/00:09:09, 0.533s/it]: train_loss_raw=0.5197, running_loss=0.4589, LR=0.000100
[2025-08-11 00:28:27,581][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087588] [Batch 02672/03692] [00:23:43/00:09:03, 0.533s/it]: train_loss_raw=0.4787, running_loss=0.4582, LR=0.000100
[2025-08-11 00:28:34,166][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087600] [Batch 02684/03692] [00:23:49/00:08:57, 0.533s/it]: train_loss_raw=0.5251, running_loss=0.4579, LR=0.000100
[2025-08-11 00:28:40,763][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087612] [Batch 02696/03692] [00:23:56/00:08:50, 0.533s/it]: train_loss_raw=0.4547, running_loss=0.4617, LR=0.000100
[2025-08-11 00:28:47,117][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087624] [Batch 02708/03692] [00:24:02/00:08:44, 0.533s/it]: train_loss_raw=0.4709, running_loss=0.4612, LR=0.000100
[2025-08-11 00:28:53,244][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087636] [Batch 02720/03692] [00:24:08/00:08:37, 0.533s/it]: train_loss_raw=0.3671, running_loss=0.4543, LR=0.000100
[2025-08-11 00:28:59,450][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087648] [Batch 02732/03692] [00:24:15/00:08:31, 0.533s/it]: train_loss_raw=0.4124, running_loss=0.4519, LR=0.000100
[2025-08-11 00:29:05,637][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087660] [Batch 02744/03692] [00:24:21/00:08:24, 0.533s/it]: train_loss_raw=0.4107, running_loss=0.4501, LR=0.000100
[2025-08-11 00:29:11,770][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087672] [Batch 02756/03692] [00:24:27/00:08:18, 0.532s/it]: train_loss_raw=0.5618, running_loss=0.4509, LR=0.000100
[2025-08-11 00:29:17,977][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087684] [Batch 02768/03692] [00:24:33/00:08:11, 0.532s/it]: train_loss_raw=0.3181, running_loss=0.4510, LR=0.000100
[2025-08-11 00:29:24,376][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087696] [Batch 02780/03692] [00:24:40/00:08:05, 0.532s/it]: train_loss_raw=0.4277, running_loss=0.4512, LR=0.000100
[2025-08-11 00:29:30,809][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087708] [Batch 02792/03692] [00:24:46/00:07:59, 0.532s/it]: train_loss_raw=0.5434, running_loss=0.4496, LR=0.000100
[2025-08-11 00:29:37,218][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087720] [Batch 02804/03692] [00:24:52/00:07:52, 0.532s/it]: train_loss_raw=0.4528, running_loss=0.4501, LR=0.000100
[2025-08-11 00:29:43,629][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087732] [Batch 02816/03692] [00:24:59/00:07:46, 0.532s/it]: train_loss_raw=0.3512, running_loss=0.4491, LR=0.000100
[2025-08-11 00:29:49,753][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087744] [Batch 02828/03692] [00:25:05/00:07:39, 0.532s/it]: train_loss_raw=0.4614, running_loss=0.4475, LR=0.000100
[2025-08-11 00:29:55,985][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087756] [Batch 02840/03692] [00:25:11/00:07:33, 0.532s/it]: train_loss_raw=0.4264, running_loss=0.4494, LR=0.000100
[2025-08-11 00:30:02,298][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087768] [Batch 02852/03692] [00:25:18/00:07:27, 0.532s/it]: train_loss_raw=0.5071, running_loss=0.4511, LR=0.000100
[2025-08-11 00:30:08,815][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087780] [Batch 02864/03692] [00:25:24/00:07:20, 0.532s/it]: train_loss_raw=0.4844, running_loss=0.4542, LR=0.000100
[2025-08-11 00:30:15,179][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087792] [Batch 02876/03692] [00:25:30/00:07:14, 0.532s/it]: train_loss_raw=0.3990, running_loss=0.4544, LR=0.000100
[2025-08-11 00:30:21,489][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087804] [Batch 02888/03692] [00:25:37/00:07:07, 0.532s/it]: train_loss_raw=0.4546, running_loss=0.4512, LR=0.000100
[2025-08-11 00:30:27,697][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087816] [Batch 02900/03692] [00:25:43/00:07:01, 0.532s/it]: train_loss_raw=0.3575, running_loss=0.4490, LR=0.000100
[2025-08-11 00:30:33,873][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087828] [Batch 02912/03692] [00:25:49/00:06:55, 0.532s/it]: train_loss_raw=0.3958, running_loss=0.4485, LR=0.000100
[2025-08-11 00:30:39,971][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087840] [Batch 02924/03692] [00:25:55/00:06:48, 0.532s/it]: train_loss_raw=0.4757, running_loss=0.4526, LR=0.000100
[2025-08-11 00:30:46,157][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087852] [Batch 02936/03692] [00:26:01/00:06:42, 0.532s/it]: train_loss_raw=0.5332, running_loss=0.4542, LR=0.000100
[2025-08-11 00:30:52,371][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087864] [Batch 02948/03692] [00:26:08/00:06:35, 0.532s/it]: train_loss_raw=0.5294, running_loss=0.4560, LR=0.000100
[2025-08-11 00:30:58,818][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087876] [Batch 02960/03692] [00:26:14/00:06:29, 0.532s/it]: train_loss_raw=0.3822, running_loss=0.4572, LR=0.000100
[2025-08-11 00:31:05,305][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087888] [Batch 02972/03692] [00:26:21/00:06:23, 0.532s/it]: train_loss_raw=0.6102, running_loss=0.4579, LR=0.000100
[2025-08-11 00:31:11,819][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087900] [Batch 02984/03692] [00:26:27/00:06:16, 0.532s/it]: train_loss_raw=0.4606, running_loss=0.4616, LR=0.000100
[2025-08-11 00:31:18,291][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087912] [Batch 02996/03692] [00:26:34/00:06:10, 0.532s/it]: train_loss_raw=0.3991, running_loss=0.4591, LR=0.000100
[2025-08-11 00:31:24,741][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087924] [Batch 03008/03692] [00:26:40/00:06:03, 0.532s/it]: train_loss_raw=0.4870, running_loss=0.4597, LR=0.000100
[2025-08-11 00:31:31,196][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087936] [Batch 03020/03692] [00:26:46/00:05:57, 0.532s/it]: train_loss_raw=0.4539, running_loss=0.4567, LR=0.000100
[2025-08-11 00:31:37,468][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087948] [Batch 03032/03692] [00:26:53/00:05:51, 0.532s/it]: train_loss_raw=0.4174, running_loss=0.4556, LR=0.000100
[2025-08-11 00:31:43,767][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087960] [Batch 03044/03692] [00:26:59/00:05:44, 0.532s/it]: train_loss_raw=0.4022, running_loss=0.4532, LR=0.000100
[2025-08-11 00:31:50,150][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087972] [Batch 03056/03692] [00:27:05/00:05:38, 0.532s/it]: train_loss_raw=0.4303, running_loss=0.4522, LR=0.000100
[2025-08-11 00:31:56,189][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087984] [Batch 03068/03692] [00:27:11/00:05:31, 0.532s/it]: train_loss_raw=0.3988, running_loss=0.4548, LR=0.000100
[2025-08-11 00:32:02,262][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087996] [Batch 03080/03692] [00:27:18/00:05:25, 0.532s/it]: train_loss_raw=0.5216, running_loss=0.4534, LR=0.000100
[2025-08-11 00:32:12,980][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088008] [Batch 03092/03692] [00:27:28/00:05:19, 0.533s/it]: train_loss_raw=0.3066, running_loss=0.4493, LR=0.000100
[2025-08-11 00:32:19,012][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088020] [Batch 03104/03692] [00:27:34/00:05:13, 0.533s/it]: train_loss_raw=0.4721, running_loss=0.4520, LR=0.000100
[2025-08-11 00:32:25,033][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088032] [Batch 03116/03692] [00:27:40/00:05:06, 0.533s/it]: train_loss_raw=0.4795, running_loss=0.4533, LR=0.000100
[2025-08-11 00:32:31,100][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088044] [Batch 03128/03692] [00:27:46/00:05:00, 0.533s/it]: train_loss_raw=0.5307, running_loss=0.4540, LR=0.000100
[2025-08-11 00:32:37,625][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088056] [Batch 03140/03692] [00:27:53/00:04:54, 0.533s/it]: train_loss_raw=0.3409, running_loss=0.4523, LR=0.000100
[2025-08-11 00:32:43,846][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088068] [Batch 03152/03692] [00:27:59/00:04:47, 0.533s/it]: train_loss_raw=0.3546, running_loss=0.4519, LR=0.000100
[2025-08-11 00:32:49,927][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088080] [Batch 03164/03692] [00:28:05/00:04:41, 0.533s/it]: train_loss_raw=0.4290, running_loss=0.4506, LR=0.000100
[2025-08-11 00:32:55,989][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088092] [Batch 03176/03692] [00:28:11/00:04:34, 0.533s/it]: train_loss_raw=0.5073, running_loss=0.4522, LR=0.000100
[2025-08-11 00:33:01,912][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088104] [Batch 03188/03692] [00:28:17/00:04:28, 0.533s/it]: train_loss_raw=0.4502, running_loss=0.4529, LR=0.000100
[2025-08-11 00:33:07,994][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088116] [Batch 03200/03692] [00:28:23/00:04:21, 0.532s/it]: train_loss_raw=0.3841, running_loss=0.4506, LR=0.000100
[2025-08-11 00:33:14,223][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088128] [Batch 03212/03692] [00:28:29/00:04:15, 0.532s/it]: train_loss_raw=0.6009, running_loss=0.4522, LR=0.000100
[2025-08-11 00:33:20,345][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088140] [Batch 03224/03692] [00:28:36/00:04:09, 0.532s/it]: train_loss_raw=0.4898, running_loss=0.4530, LR=0.000100
[2025-08-11 00:33:26,433][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088152] [Batch 03236/03692] [00:28:42/00:04:02, 0.532s/it]: train_loss_raw=0.3886, running_loss=0.4515, LR=0.000100
[2025-08-11 00:33:32,540][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088164] [Batch 03248/03692] [00:28:48/00:03:56, 0.532s/it]: train_loss_raw=0.4008, running_loss=0.4510, LR=0.000100
[2025-08-11 00:33:38,761][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088176] [Batch 03260/03692] [00:28:54/00:03:49, 0.532s/it]: train_loss_raw=0.3116, running_loss=0.4522, LR=0.000100
[2025-08-11 00:33:44,977][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088188] [Batch 03272/03692] [00:29:00/00:03:43, 0.532s/it]: train_loss_raw=0.4481, running_loss=0.4537, LR=0.000100
[2025-08-11 00:33:51,156][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088200] [Batch 03284/03692] [00:29:06/00:03:37, 0.532s/it]: train_loss_raw=0.5099, running_loss=0.4554, LR=0.000100
[2025-08-11 00:33:57,409][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088212] [Batch 03296/03692] [00:29:13/00:03:30, 0.532s/it]: train_loss_raw=0.4024, running_loss=0.4556, LR=0.000100
[2025-08-11 00:34:03,656][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088224] [Batch 03308/03692] [00:29:19/00:03:24, 0.532s/it]: train_loss_raw=0.3950, running_loss=0.4572, LR=0.000100
[2025-08-11 00:34:09,878][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088236] [Batch 03320/03692] [00:29:25/00:03:17, 0.532s/it]: train_loss_raw=0.4198, running_loss=0.4579, LR=0.000100
[2025-08-11 00:34:15,888][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088248] [Batch 03332/03692] [00:29:31/00:03:11, 0.532s/it]: train_loss_raw=0.6176, running_loss=0.4590, LR=0.000100
[2025-08-11 00:34:21,882][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088260] [Batch 03344/03692] [00:29:37/00:03:04, 0.532s/it]: train_loss_raw=0.4518, running_loss=0.4579, LR=0.000100
[2025-08-11 00:34:27,883][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088272] [Batch 03356/03692] [00:29:43/00:02:58, 0.531s/it]: train_loss_raw=0.4402, running_loss=0.4569, LR=0.000100
[2025-08-11 00:34:34,118][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088284] [Batch 03368/03692] [00:29:49/00:02:52, 0.531s/it]: train_loss_raw=0.5541, running_loss=0.4582, LR=0.000100
[2025-08-11 00:34:40,527][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088296] [Batch 03380/03692] [00:29:56/00:02:45, 0.531s/it]: train_loss_raw=0.3887, running_loss=0.4586, LR=0.000100
[2025-08-11 00:34:47,005][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088308] [Batch 03392/03692] [00:30:02/00:02:39, 0.531s/it]: train_loss_raw=0.4529, running_loss=0.4595, LR=0.000100
[2025-08-11 00:34:53,132][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088320] [Batch 03404/03692] [00:30:08/00:02:33, 0.531s/it]: train_loss_raw=0.4039, running_loss=0.4560, LR=0.000100
[2025-08-11 00:34:59,155][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088332] [Batch 03416/03692] [00:30:14/00:02:26, 0.531s/it]: train_loss_raw=0.4068, running_loss=0.4557, LR=0.000100
[2025-08-11 00:35:05,295][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088344] [Batch 03428/03692] [00:30:21/00:02:20, 0.531s/it]: train_loss_raw=0.5908, running_loss=0.4582, LR=0.000100
[2025-08-11 00:35:11,325][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088356] [Batch 03440/03692] [00:30:27/00:02:13, 0.531s/it]: train_loss_raw=0.4514, running_loss=0.4602, LR=0.000100
[2025-08-11 00:35:17,347][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088368] [Batch 03452/03692] [00:30:33/00:02:07, 0.531s/it]: train_loss_raw=0.4572, running_loss=0.4609, LR=0.000100
[2025-08-11 00:35:23,405][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088380] [Batch 03464/03692] [00:30:39/00:02:01, 0.531s/it]: train_loss_raw=0.3857, running_loss=0.4627, LR=0.000100
[2025-08-11 00:35:29,393][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088392] [Batch 03476/03692] [00:30:45/00:01:54, 0.531s/it]: train_loss_raw=0.4826, running_loss=0.4612, LR=0.000100
[2025-08-11 00:35:35,533][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088404] [Batch 03488/03692] [00:30:51/00:01:48, 0.531s/it]: train_loss_raw=0.5615, running_loss=0.4612, LR=0.000100
[2025-08-11 00:35:41,642][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088416] [Batch 03500/03692] [00:30:57/00:01:41, 0.531s/it]: train_loss_raw=0.4907, running_loss=0.4621, LR=0.000100
[2025-08-11 00:35:47,718][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088428] [Batch 03512/03692] [00:31:03/00:01:35, 0.531s/it]: train_loss_raw=0.4987, running_loss=0.4650, LR=0.000100
[2025-08-11 00:35:53,847][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088440] [Batch 03524/03692] [00:31:09/00:01:29, 0.531s/it]: train_loss_raw=0.4692, running_loss=0.4583, LR=0.000100
[2025-08-11 00:36:00,356][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088452] [Batch 03536/03692] [00:31:16/00:01:22, 0.531s/it]: train_loss_raw=0.4666, running_loss=0.4571, LR=0.000100
[2025-08-11 00:36:06,506][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088464] [Batch 03548/03692] [00:31:22/00:01:16, 0.531s/it]: train_loss_raw=0.6781, running_loss=0.4553, LR=0.000100
[2025-08-11 00:36:12,555][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088476] [Batch 03560/03692] [00:31:28/00:01:10, 0.530s/it]: train_loss_raw=0.6460, running_loss=0.4575, LR=0.000100
[2025-08-11 00:36:18,630][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088488] [Batch 03572/03692] [00:31:34/00:01:03, 0.530s/it]: train_loss_raw=0.4671, running_loss=0.4563, LR=0.000100
[2025-08-11 00:36:24,974][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088500] [Batch 03584/03692] [00:31:40/00:00:57, 0.530s/it]: train_loss_raw=0.4532, running_loss=0.4536, LR=0.000100
[2025-08-11 00:36:31,301][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088512] [Batch 03596/03692] [00:31:47/00:00:50, 0.530s/it]: train_loss_raw=0.4939, running_loss=0.4560, LR=0.000100
[2025-08-11 00:36:37,449][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088524] [Batch 03608/03692] [00:31:53/00:00:44, 0.530s/it]: train_loss_raw=0.4046, running_loss=0.4548, LR=0.000100
[2025-08-11 00:36:43,998][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088536] [Batch 03620/03692] [00:31:59/00:00:38, 0.530s/it]: train_loss_raw=0.4008, running_loss=0.4530, LR=0.000100
[2025-08-11 00:36:50,449][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088548] [Batch 03632/03692] [00:32:06/00:00:31, 0.530s/it]: train_loss_raw=0.4546, running_loss=0.4539, LR=0.000100
[2025-08-11 00:36:56,875][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088560] [Batch 03644/03692] [00:32:12/00:00:25, 0.530s/it]: train_loss_raw=0.3808, running_loss=0.4533, LR=0.000100
[2025-08-11 00:37:03,256][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088572] [Batch 03656/03692] [00:32:19/00:00:19, 0.530s/it]: train_loss_raw=0.4769, running_loss=0.4567, LR=0.000100
[2025-08-11 00:37:09,658][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088584] [Batch 03668/03692] [00:32:25/00:00:12, 0.530s/it]: train_loss_raw=0.5208, running_loss=0.4552, LR=0.000100
[2025-08-11 00:37:16,116][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088596] [Batch 03680/03692] [00:32:31/00:00:06, 0.530s/it]: train_loss_raw=0.3616, running_loss=0.4528, LR=0.000100
[2025-08-11 00:37:46,515][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088608] [Batch 03692/03692] [00:33:02/00:00:00, 0.537s/it]: train_loss_raw=0.3816, running_loss=0.4514, LR=0.000100
[2025-08-11 00:37:51,530][__main__][INFO] - [VALIDATION] [Epoch 23/29] Starting validation.
[2025-08-11 00:38:23,421][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 088609] [Batch 00011/00025] [00:00:31/00:00:34, 2.657s/it]
[2025-08-11 00:38:37,446][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 088609] [Batch 00023/00025] [00:00:45/00:00:01, 1.913s/it]
[2025-08-11 00:38:38,450][__main__][INFO] - [VALIDATION] [Epoch 23/29] train_loss=0.45142, valid_loss=0.56150
[2025-08-11 00:38:38,450][__main__][INFO] - [VALIDATION] [Epoch 23/29] Metrics:
[2025-08-11 00:38:38,450][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_er      0.236
[2025-08-11 00:38:38,450][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_prec    0.563
[2025-08-11 00:38:38,450][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_recall  0.569
[2025-08-11 00:38:38,450][__main__][INFO] - [VALIDATION] [Epoch 23/29] - pep_recall 0.558
[2025-08-11 00:38:38,453][__main__][INFO] - [TRAIN] [Epoch 23/29] Epoch complete, total time 13:42:37, remaining time 03:25:39, 00:34:16 per epoch
[2025-08-11 00:38:44,765][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088620] [Batch 00012/03692] [00:00:06/00:31:01, 0.506s/it]: train_loss_raw=0.4278, running_loss=0.4244, LR=0.000100
[2025-08-11 00:38:51,297][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088632] [Batch 00024/03692] [00:00:12/00:32:06, 0.525s/it]: train_loss_raw=0.3577, running_loss=0.4243, LR=0.000100
[2025-08-11 00:38:57,667][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088644] [Batch 00036/03692] [00:00:18/00:32:06, 0.527s/it]: train_loss_raw=0.4484, running_loss=0.4259, LR=0.000100
[2025-08-11 00:39:04,135][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088656] [Batch 00048/03692] [00:00:25/00:32:11, 0.530s/it]: train_loss_raw=0.4631, running_loss=0.4216, LR=0.000100
[2025-08-11 00:39:10,662][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088668] [Batch 00060/03692] [00:00:31/00:32:15, 0.533s/it]: train_loss_raw=0.4577, running_loss=0.4226, LR=0.000100
[2025-08-11 00:39:17,136][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088680] [Batch 00072/03692] [00:00:38/00:32:12, 0.534s/it]: train_loss_raw=0.5103, running_loss=0.4225, LR=0.000100
[2025-08-11 00:39:23,385][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088692] [Batch 00084/03692] [00:00:44/00:31:59, 0.532s/it]: train_loss_raw=0.4091, running_loss=0.4234, LR=0.000100
[2025-08-11 00:39:29,594][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088704] [Batch 00096/03692] [00:00:50/00:31:46, 0.530s/it]: train_loss_raw=0.4280, running_loss=0.4273, LR=0.000100
[2025-08-11 00:39:35,843][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088716] [Batch 00108/03692] [00:00:57/00:31:36, 0.529s/it]: train_loss_raw=0.3920, running_loss=0.4275, LR=0.000100
[2025-08-11 00:39:42,140][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088728] [Batch 00120/03692] [00:01:03/00:31:28, 0.529s/it]: train_loss_raw=0.4005, running_loss=0.4266, LR=0.000100
[2025-08-11 00:39:48,634][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088740] [Batch 00132/03692] [00:01:09/00:31:26, 0.530s/it]: train_loss_raw=0.4026, running_loss=0.4278, LR=0.000100
[2025-08-11 00:39:55,210][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088752] [Batch 00144/03692] [00:01:16/00:31:25, 0.531s/it]: train_loss_raw=0.3193, running_loss=0.4291, LR=0.000100
[2025-08-11 00:40:01,533][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088764] [Batch 00156/03692] [00:01:22/00:31:17, 0.531s/it]: train_loss_raw=0.5129, running_loss=0.4271, LR=0.000100
[2025-08-11 00:40:07,759][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088776] [Batch 00168/03692] [00:01:29/00:31:08, 0.530s/it]: train_loss_raw=0.4568, running_loss=0.4261, LR=0.000100
[2025-08-11 00:40:14,092][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088788] [Batch 00180/03692] [00:01:35/00:31:01, 0.530s/it]: train_loss_raw=0.4076, running_loss=0.4251, LR=0.000100
[2025-08-11 00:40:20,541][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088800] [Batch 00192/03692] [00:01:41/00:30:56, 0.530s/it]: train_loss_raw=0.3432, running_loss=0.4270, LR=0.000100
[2025-08-11 00:40:26,926][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088812] [Batch 00204/03692] [00:01:48/00:30:50, 0.531s/it]: train_loss_raw=0.4643, running_loss=0.4238, LR=0.000100
[2025-08-11 00:40:33,367][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088824] [Batch 00216/03692] [00:01:54/00:30:45, 0.531s/it]: train_loss_raw=0.4387, running_loss=0.4236, LR=0.000100
[2025-08-11 00:40:39,711][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088836] [Batch 00228/03692] [00:02:01/00:30:38, 0.531s/it]: train_loss_raw=0.4560, running_loss=0.4222, LR=0.000100
[2025-08-11 00:40:46,085][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088848] [Batch 00240/03692] [00:02:07/00:30:32, 0.531s/it]: train_loss_raw=0.4699, running_loss=0.4244, LR=0.000100
[2025-08-11 00:40:52,511][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088860] [Batch 00252/03692] [00:02:13/00:30:26, 0.531s/it]: train_loss_raw=0.4656, running_loss=0.4245, LR=0.000100
[2025-08-11 00:40:59,023][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088872] [Batch 00264/03692] [00:02:20/00:30:22, 0.532s/it]: train_loss_raw=0.3513, running_loss=0.4205, LR=0.000100
[2025-08-11 00:41:05,533][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088884] [Batch 00276/03692] [00:02:26/00:30:17, 0.532s/it]: train_loss_raw=0.3871, running_loss=0.4208, LR=0.000100
[2025-08-11 00:41:12,001][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088896] [Batch 00288/03692] [00:02:33/00:30:12, 0.532s/it]: train_loss_raw=0.4661, running_loss=0.4202, LR=0.000100
[2025-08-11 00:41:18,418][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088908] [Batch 00300/03692] [00:02:39/00:30:05, 0.532s/it]: train_loss_raw=0.3709, running_loss=0.4206, LR=0.000100
[2025-08-11 00:41:24,925][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088920] [Batch 00312/03692] [00:02:46/00:30:00, 0.533s/it]: train_loss_raw=0.4107, running_loss=0.4234, LR=0.000100
[2025-08-11 00:41:31,285][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088932] [Batch 00324/03692] [00:02:52/00:29:54, 0.533s/it]: train_loss_raw=0.4064, running_loss=0.4260, LR=0.000100
[2025-08-11 00:41:37,792][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088944] [Batch 00336/03692] [00:02:59/00:29:48, 0.533s/it]: train_loss_raw=0.4470, running_loss=0.4254, LR=0.000100
[2025-08-11 00:41:44,355][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088956] [Batch 00348/03692] [00:03:05/00:29:44, 0.534s/it]: train_loss_raw=0.3682, running_loss=0.4225, LR=0.000100
[2025-08-11 00:41:50,838][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088968] [Batch 00360/03692] [00:03:12/00:29:38, 0.534s/it]: train_loss_raw=0.4527, running_loss=0.4284, LR=0.000100
[2025-08-11 00:41:57,372][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088980] [Batch 00372/03692] [00:03:18/00:29:33, 0.534s/it]: train_loss_raw=0.4723, running_loss=0.4310, LR=0.000100
[2025-08-11 00:42:03,619][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088992] [Batch 00384/03692] [00:03:24/00:29:25, 0.534s/it]: train_loss_raw=0.3927, running_loss=0.4319, LR=0.000100
[2025-08-11 00:42:10,007][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089004] [Batch 00396/03692] [00:03:31/00:29:18, 0.534s/it]: train_loss_raw=0.4260, running_loss=0.4317, LR=0.000100
[2025-08-11 00:42:16,272][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089016] [Batch 00408/03692] [00:03:37/00:29:11, 0.533s/it]: train_loss_raw=0.4593, running_loss=0.4293, LR=0.000100
[2025-08-11 00:42:22,378][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089028] [Batch 00420/03692] [00:03:43/00:29:02, 0.533s/it]: train_loss_raw=0.5106, running_loss=0.4301, LR=0.000100
[2025-08-11 00:42:28,622][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089040] [Batch 00432/03692] [00:03:49/00:28:55, 0.532s/it]: train_loss_raw=0.4250, running_loss=0.4302, LR=0.000100
[2025-08-11 00:42:34,817][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089052] [Batch 00444/03692] [00:03:56/00:28:47, 0.532s/it]: train_loss_raw=0.4354, running_loss=0.4287, LR=0.000100
[2025-08-11 00:42:40,988][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089064] [Batch 00456/03692] [00:04:02/00:28:39, 0.531s/it]: train_loss_raw=0.4112, running_loss=0.4345, LR=0.000100
[2025-08-11 00:42:47,081][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089076] [Batch 00468/03692] [00:04:08/00:28:31, 0.531s/it]: train_loss_raw=0.4158, running_loss=0.4352, LR=0.000100
[2025-08-11 00:42:53,233][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089088] [Batch 00480/03692] [00:04:14/00:28:23, 0.530s/it]: train_loss_raw=0.3909, running_loss=0.4305, LR=0.000100
[2025-08-11 00:42:59,617][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089100] [Batch 00492/03692] [00:04:20/00:28:17, 0.530s/it]: train_loss_raw=0.4680, running_loss=0.4298, LR=0.000100
[2025-08-11 00:43:06,147][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089112] [Batch 00504/03692] [00:04:27/00:28:11, 0.531s/it]: train_loss_raw=0.4155, running_loss=0.4352, LR=0.000100
[2025-08-11 00:43:12,637][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089124] [Batch 00516/03692] [00:04:33/00:28:06, 0.531s/it]: train_loss_raw=0.3935, running_loss=0.4277, LR=0.000100
[2025-08-11 00:43:18,934][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089136] [Batch 00528/03692] [00:04:40/00:27:59, 0.531s/it]: train_loss_raw=0.3829, running_loss=0.4247, LR=0.000100
[2025-08-11 00:43:25,325][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089148] [Batch 00540/03692] [00:04:46/00:27:53, 0.531s/it]: train_loss_raw=0.5059, running_loss=0.4276, LR=0.000100
[2025-08-11 00:43:31,661][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089160] [Batch 00552/03692] [00:04:52/00:27:46, 0.531s/it]: train_loss_raw=0.4423, running_loss=0.4326, LR=0.000100
[2025-08-11 00:43:38,065][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089172] [Batch 00564/03692] [00:04:59/00:27:40, 0.531s/it]: train_loss_raw=0.4072, running_loss=0.4328, LR=0.000100
[2025-08-11 00:43:44,490][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089184] [Batch 00576/03692] [00:05:05/00:27:34, 0.531s/it]: train_loss_raw=0.4494, running_loss=0.4317, LR=0.000100
[2025-08-11 00:43:51,009][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089196] [Batch 00588/03692] [00:05:12/00:27:28, 0.531s/it]: train_loss_raw=0.3650, running_loss=0.4307, LR=0.000100
[2025-08-11 00:43:57,608][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089208] [Batch 00600/03692] [00:05:18/00:27:23, 0.532s/it]: train_loss_raw=0.4404, running_loss=0.4316, LR=0.000100
[2025-08-11 00:44:04,015][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089220] [Batch 00612/03692] [00:05:25/00:27:17, 0.532s/it]: train_loss_raw=0.4361, running_loss=0.4313, LR=0.000100
[2025-08-11 00:44:10,298][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089232] [Batch 00624/03692] [00:05:31/00:27:10, 0.531s/it]: train_loss_raw=0.3483, running_loss=0.4290, LR=0.000100
[2025-08-11 00:44:16,749][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089244] [Batch 00636/03692] [00:05:38/00:27:04, 0.532s/it]: train_loss_raw=0.5109, running_loss=0.4289, LR=0.000100
[2025-08-11 00:44:23,125][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089256] [Batch 00648/03692] [00:05:44/00:26:57, 0.532s/it]: train_loss_raw=0.4152, running_loss=0.4294, LR=0.000100
[2025-08-11 00:44:29,556][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089268] [Batch 00660/03692] [00:05:50/00:26:51, 0.532s/it]: train_loss_raw=0.5075, running_loss=0.4329, LR=0.000100
[2025-08-11 00:44:36,010][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089280] [Batch 00672/03692] [00:05:57/00:26:45, 0.532s/it]: train_loss_raw=0.5366, running_loss=0.4296, LR=0.000100
[2025-08-11 00:44:42,505][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089292] [Batch 00684/03692] [00:06:03/00:26:39, 0.532s/it]: train_loss_raw=0.3692, running_loss=0.4274, LR=0.000100
[2025-08-11 00:44:48,893][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089304] [Batch 00696/03692] [00:06:10/00:26:33, 0.532s/it]: train_loss_raw=0.4052, running_loss=0.4275, LR=0.000100
[2025-08-11 00:44:55,364][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089316] [Batch 00708/03692] [00:06:16/00:26:27, 0.532s/it]: train_loss_raw=0.3720, running_loss=0.4278, LR=0.000100
[2025-08-11 00:45:01,743][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089328] [Batch 00720/03692] [00:06:23/00:26:21, 0.532s/it]: train_loss_raw=0.4888, running_loss=0.4285, LR=0.000100
[2025-08-11 00:45:08,146][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089340] [Batch 00732/03692] [00:06:29/00:26:14, 0.532s/it]: train_loss_raw=0.4339, running_loss=0.4284, LR=0.000100
[2025-08-11 00:45:14,510][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089352] [Batch 00744/03692] [00:06:35/00:26:08, 0.532s/it]: train_loss_raw=0.4643, running_loss=0.4293, LR=0.000100
[2025-08-11 00:45:21,052][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089364] [Batch 00756/03692] [00:06:42/00:26:02, 0.532s/it]: train_loss_raw=0.4601, running_loss=0.4315, LR=0.000100
[2025-08-11 00:45:27,501][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089376] [Batch 00768/03692] [00:06:48/00:25:56, 0.532s/it]: train_loss_raw=0.3775, running_loss=0.4278, LR=0.000100
[2025-08-11 00:45:33,868][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089388] [Batch 00780/03692] [00:06:55/00:25:49, 0.532s/it]: train_loss_raw=0.4215, running_loss=0.4261, LR=0.000100
[2025-08-11 00:45:40,236][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089400] [Batch 00792/03692] [00:07:01/00:25:43, 0.532s/it]: train_loss_raw=0.5428, running_loss=0.4324, LR=0.000100
[2025-08-11 00:45:46,636][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089412] [Batch 00804/03692] [00:07:07/00:25:37, 0.532s/it]: train_loss_raw=0.3876, running_loss=0.4343, LR=0.000100
[2025-08-11 00:45:53,114][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089424] [Batch 00816/03692] [00:07:14/00:25:31, 0.532s/it]: train_loss_raw=0.4057, running_loss=0.4330, LR=0.000100
[2025-08-11 00:45:59,515][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089436] [Batch 00828/03692] [00:07:20/00:25:24, 0.532s/it]: train_loss_raw=0.3653, running_loss=0.4319, LR=0.000100
[2025-08-11 00:46:05,979][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089448] [Batch 00840/03692] [00:07:27/00:25:18, 0.532s/it]: train_loss_raw=0.5075, running_loss=0.4311, LR=0.000100
[2025-08-11 00:46:12,354][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089460] [Batch 00852/03692] [00:07:33/00:25:12, 0.532s/it]: train_loss_raw=0.4596, running_loss=0.4312, LR=0.000100
[2025-08-11 00:46:18,716][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089472] [Batch 00864/03692] [00:07:40/00:25:05, 0.532s/it]: train_loss_raw=0.5024, running_loss=0.4283, LR=0.000100
[2025-08-11 00:46:25,214][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089484] [Batch 00876/03692] [00:07:46/00:24:59, 0.533s/it]: train_loss_raw=0.4660, running_loss=0.4274, LR=0.000100
[2025-08-11 00:46:31,621][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089496] [Batch 00888/03692] [00:07:52/00:24:53, 0.533s/it]: train_loss_raw=0.3273, running_loss=0.4255, LR=0.000100
[2025-08-11 00:46:38,150][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089508] [Batch 00900/03692] [00:07:59/00:24:47, 0.533s/it]: train_loss_raw=0.3689, running_loss=0.4269, LR=0.000100
[2025-08-11 00:46:44,557][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089520] [Batch 00912/03692] [00:08:05/00:24:41, 0.533s/it]: train_loss_raw=0.3632, running_loss=0.4238, LR=0.000100
[2025-08-11 00:46:50,967][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089532] [Batch 00924/03692] [00:08:12/00:24:34, 0.533s/it]: train_loss_raw=0.5494, running_loss=0.4284, LR=0.000100
[2025-08-11 00:46:57,456][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089544] [Batch 00936/03692] [00:08:18/00:24:28, 0.533s/it]: train_loss_raw=0.3553, running_loss=0.4244, LR=0.000100
[2025-08-11 00:47:03,838][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089556] [Batch 00948/03692] [00:08:25/00:24:22, 0.533s/it]: train_loss_raw=0.4404, running_loss=0.4236, LR=0.000100
[2025-08-11 00:47:10,301][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089568] [Batch 00960/03692] [00:08:31/00:24:15, 0.533s/it]: train_loss_raw=0.5326, running_loss=0.4233, LR=0.000100
[2025-08-11 00:47:16,870][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089580] [Batch 00972/03692] [00:08:38/00:24:10, 0.533s/it]: train_loss_raw=0.4315, running_loss=0.4250, LR=0.000100
[2025-08-11 00:47:23,291][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089592] [Batch 00984/03692] [00:08:44/00:24:03, 0.533s/it]: train_loss_raw=0.5182, running_loss=0.4279, LR=0.000100
[2025-08-11 00:47:29,851][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089604] [Batch 00996/03692] [00:08:51/00:23:57, 0.533s/it]: train_loss_raw=0.4053, running_loss=0.4270, LR=0.000100
[2025-08-11 00:47:36,278][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089616] [Batch 01008/03692] [00:08:57/00:23:51, 0.533s/it]: train_loss_raw=0.4369, running_loss=0.4251, LR=0.000100
[2025-08-11 00:47:42,675][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089628] [Batch 01020/03692] [00:09:03/00:23:45, 0.533s/it]: train_loss_raw=0.5572, running_loss=0.4270, LR=0.000100
[2025-08-11 00:47:49,181][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089640] [Batch 01032/03692] [00:09:10/00:23:38, 0.533s/it]: train_loss_raw=0.4514, running_loss=0.4267, LR=0.000100
[2025-08-11 00:47:55,680][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089652] [Batch 01044/03692] [00:09:16/00:23:32, 0.534s/it]: train_loss_raw=0.4225, running_loss=0.4250, LR=0.000100
[2025-08-11 00:48:02,197][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089664] [Batch 01056/03692] [00:09:23/00:23:26, 0.534s/it]: train_loss_raw=0.3890, running_loss=0.4228, LR=0.000100
[2025-08-11 00:48:08,678][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089676] [Batch 01068/03692] [00:09:29/00:23:20, 0.534s/it]: train_loss_raw=0.4045, running_loss=0.4224, LR=0.000100
[2025-08-11 00:48:14,979][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089688] [Batch 01080/03692] [00:09:36/00:23:13, 0.534s/it]: train_loss_raw=0.4293, running_loss=0.4240, LR=0.000100
[2025-08-11 00:48:21,301][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089700] [Batch 01092/03692] [00:09:42/00:23:07, 0.534s/it]: train_loss_raw=0.4519, running_loss=0.4226, LR=0.000100
[2025-08-11 00:48:27,670][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089712] [Batch 01104/03692] [00:09:48/00:23:00, 0.533s/it]: train_loss_raw=0.3963, running_loss=0.4194, LR=0.000100
[2025-08-11 00:48:34,065][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089724] [Batch 01116/03692] [00:09:55/00:22:54, 0.533s/it]: train_loss_raw=0.4394, running_loss=0.4181, LR=0.000100
[2025-08-11 00:48:40,535][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089736] [Batch 01128/03692] [00:10:01/00:22:48, 0.534s/it]: train_loss_raw=0.3228, running_loss=0.4160, LR=0.000100
[2025-08-11 00:48:47,013][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089748] [Batch 01140/03692] [00:10:08/00:22:41, 0.534s/it]: train_loss_raw=0.4403, running_loss=0.4201, LR=0.000100
[2025-08-11 00:48:53,397][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089760] [Batch 01152/03692] [00:10:14/00:22:35, 0.534s/it]: train_loss_raw=0.3733, running_loss=0.4234, LR=0.000100
[2025-08-11 00:48:59,843][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089772] [Batch 01164/03692] [00:10:21/00:22:29, 0.534s/it]: train_loss_raw=0.4994, running_loss=0.4227, LR=0.000100
[2025-08-11 00:49:06,246][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089784] [Batch 01176/03692] [00:10:27/00:22:22, 0.534s/it]: train_loss_raw=0.3943, running_loss=0.4239, LR=0.000100
[2025-08-11 00:49:12,628][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089796] [Batch 01188/03692] [00:10:33/00:22:16, 0.534s/it]: train_loss_raw=0.3961, running_loss=0.4204, LR=0.000100
[2025-08-11 00:49:19,046][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089808] [Batch 01200/03692] [00:10:40/00:22:09, 0.534s/it]: train_loss_raw=0.4338, running_loss=0.4234, LR=0.000100
[2025-08-11 00:49:25,602][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089820] [Batch 01212/03692] [00:10:46/00:22:03, 0.534s/it]: train_loss_raw=0.3318, running_loss=0.4216, LR=0.000100
[2025-08-11 00:49:32,050][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089832] [Batch 01224/03692] [00:10:53/00:21:57, 0.534s/it]: train_loss_raw=0.4390, running_loss=0.4210, LR=0.000100
[2025-08-11 00:49:38,163][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089844] [Batch 01236/03692] [00:10:59/00:21:50, 0.534s/it]: train_loss_raw=0.3027, running_loss=0.4222, LR=0.000100
[2025-08-11 00:49:44,318][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089856] [Batch 01248/03692] [00:11:05/00:21:43, 0.533s/it]: train_loss_raw=0.4319, running_loss=0.4206, LR=0.000100
[2025-08-11 00:49:50,516][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089868] [Batch 01260/03692] [00:11:11/00:21:36, 0.533s/it]: train_loss_raw=0.3908, running_loss=0.4190, LR=0.000100
[2025-08-11 00:49:56,815][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089880] [Batch 01272/03692] [00:11:18/00:21:30, 0.533s/it]: train_loss_raw=0.5873, running_loss=0.4188, LR=0.000100
[2025-08-11 00:50:03,147][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089892] [Batch 01284/03692] [00:11:24/00:21:23, 0.533s/it]: train_loss_raw=0.4478, running_loss=0.4196, LR=0.000100
[2025-08-11 00:50:09,542][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089904] [Batch 01296/03692] [00:11:30/00:21:17, 0.533s/it]: train_loss_raw=0.3133, running_loss=0.4188, LR=0.000100
[2025-08-11 00:50:15,761][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089916] [Batch 01308/03692] [00:11:37/00:21:10, 0.533s/it]: train_loss_raw=0.4559, running_loss=0.4212, LR=0.000100
[2025-08-11 00:50:21,912][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089928] [Batch 01320/03692] [00:11:43/00:21:03, 0.533s/it]: train_loss_raw=0.3512, running_loss=0.4193, LR=0.000100
[2025-08-11 00:50:28,169][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089940] [Batch 01332/03692] [00:11:49/00:20:57, 0.533s/it]: train_loss_raw=0.3774, running_loss=0.4204, LR=0.000100
[2025-08-11 00:50:34,276][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089952] [Batch 01344/03692] [00:11:55/00:20:50, 0.532s/it]: train_loss_raw=0.3967, running_loss=0.4224, LR=0.000100
[2025-08-11 00:50:40,327][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089964] [Batch 01356/03692] [00:12:01/00:20:43, 0.532s/it]: train_loss_raw=0.3967, running_loss=0.4228, LR=0.000100
[2025-08-11 00:50:46,396][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089976] [Batch 01368/03692] [00:12:07/00:20:36, 0.532s/it]: train_loss_raw=0.5188, running_loss=0.4218, LR=0.000100
[2025-08-11 00:50:52,507][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089988] [Batch 01380/03692] [00:12:13/00:20:29, 0.532s/it]: train_loss_raw=0.3506, running_loss=0.4209, LR=0.000100
[2025-08-11 00:50:58,844][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090000] [Batch 01392/03692] [00:12:20/00:20:22, 0.532s/it]: train_loss_raw=0.4943, running_loss=0.4197, LR=0.000100
[2025-08-11 00:51:10,876][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090012] [Batch 01404/03692] [00:12:32/00:20:25, 0.536s/it]: train_loss_raw=0.3630, running_loss=0.4186, LR=0.000100
[2025-08-11 00:51:17,231][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090024] [Batch 01416/03692] [00:12:38/00:20:19, 0.536s/it]: train_loss_raw=0.3887, running_loss=0.4164, LR=0.000100
[2025-08-11 00:51:23,440][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090036] [Batch 01428/03692] [00:12:44/00:20:12, 0.536s/it]: train_loss_raw=0.4753, running_loss=0.4236, LR=0.000100
[2025-08-11 00:51:29,705][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090048] [Batch 01440/03692] [00:12:51/00:20:05, 0.535s/it]: train_loss_raw=0.4607, running_loss=0.4240, LR=0.000100
[2025-08-11 00:51:36,196][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090060] [Batch 01452/03692] [00:12:57/00:19:59, 0.535s/it]: train_loss_raw=0.4222, running_loss=0.4246, LR=0.000100
[2025-08-11 00:51:42,631][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090072] [Batch 01464/03692] [00:13:03/00:19:53, 0.535s/it]: train_loss_raw=0.3840, running_loss=0.4213, LR=0.000100
[2025-08-11 00:51:49,075][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090084] [Batch 01476/03692] [00:13:10/00:19:46, 0.535s/it]: train_loss_raw=0.4210, running_loss=0.4202, LR=0.000100
[2025-08-11 00:51:55,445][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090096] [Batch 01488/03692] [00:13:16/00:19:40, 0.535s/it]: train_loss_raw=0.4701, running_loss=0.4217, LR=0.000100
[2025-08-11 00:52:01,842][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090108] [Batch 01500/03692] [00:13:23/00:19:33, 0.535s/it]: train_loss_raw=0.3101, running_loss=0.4220, LR=0.000100
[2025-08-11 00:52:08,268][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090120] [Batch 01512/03692] [00:13:29/00:19:27, 0.535s/it]: train_loss_raw=0.5333, running_loss=0.4200, LR=0.000100
[2025-08-11 00:52:14,767][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090132] [Batch 01524/03692] [00:13:36/00:19:20, 0.535s/it]: train_loss_raw=0.3545, running_loss=0.4179, LR=0.000100
[2025-08-11 00:52:45,089][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090144] [Batch 01536/03692] [00:14:06/00:19:48, 0.551s/it]: train_loss_raw=0.3651, running_loss=0.4183, LR=0.000100
[2025-08-11 00:52:51,376][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090156] [Batch 01548/03692] [00:14:12/00:19:40, 0.551s/it]: train_loss_raw=0.3845, running_loss=0.4164, LR=0.000100
[2025-08-11 00:52:57,705][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090168] [Batch 01560/03692] [00:14:19/00:19:33, 0.551s/it]: train_loss_raw=0.3993, running_loss=0.4161, LR=0.000100
[2025-08-11 00:53:04,160][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090180] [Batch 01572/03692] [00:14:25/00:19:27, 0.551s/it]: train_loss_raw=0.4805, running_loss=0.4169, LR=0.000100
[2025-08-11 00:53:10,602][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090192] [Batch 01584/03692] [00:14:31/00:19:20, 0.550s/it]: train_loss_raw=0.3845, running_loss=0.4146, LR=0.000100
[2025-08-11 00:53:17,119][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090204] [Batch 01596/03692] [00:14:38/00:19:13, 0.550s/it]: train_loss_raw=0.4002, running_loss=0.4184, LR=0.000100
[2025-08-11 00:53:23,619][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090216] [Batch 01608/03692] [00:14:44/00:19:06, 0.550s/it]: train_loss_raw=0.4823, running_loss=0.4174, LR=0.000100
[2025-08-11 00:53:30,129][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090228] [Batch 01620/03692] [00:14:51/00:19:00, 0.550s/it]: train_loss_raw=0.4506, running_loss=0.4173, LR=0.000100
[2025-08-11 00:53:36,636][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090240] [Batch 01632/03692] [00:14:57/00:18:53, 0.550s/it]: train_loss_raw=0.4037, running_loss=0.4125, LR=0.000100
[2025-08-11 00:53:42,923][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090252] [Batch 01644/03692] [00:15:04/00:18:46, 0.550s/it]: train_loss_raw=0.4944, running_loss=0.4127, LR=0.000100
[2025-08-11 00:53:49,314][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090264] [Batch 01656/03692] [00:15:10/00:18:39, 0.550s/it]: train_loss_raw=0.4954, running_loss=0.4128, LR=0.000100
[2025-08-11 00:53:55,781][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090276] [Batch 01668/03692] [00:15:17/00:18:32, 0.550s/it]: train_loss_raw=0.5350, running_loss=0.4160, LR=0.000100
[2025-08-11 00:54:02,215][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090288] [Batch 01680/03692] [00:15:23/00:18:26, 0.550s/it]: train_loss_raw=0.4400, running_loss=0.4162, LR=0.000100
[2025-08-11 00:54:08,628][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090300] [Batch 01692/03692] [00:15:29/00:18:19, 0.550s/it]: train_loss_raw=0.3624, running_loss=0.4165, LR=0.000100
[2025-08-11 00:54:14,946][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090312] [Batch 01704/03692] [00:15:36/00:18:12, 0.549s/it]: train_loss_raw=0.3579, running_loss=0.4162, LR=0.000100
[2025-08-11 00:54:21,329][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090324] [Batch 01716/03692] [00:15:42/00:18:05, 0.549s/it]: train_loss_raw=0.3818, running_loss=0.4180, LR=0.000100
[2025-08-11 00:54:27,694][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090336] [Batch 01728/03692] [00:15:49/00:17:58, 0.549s/it]: train_loss_raw=0.5128, running_loss=0.4226, LR=0.000100
[2025-08-11 00:54:34,113][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090348] [Batch 01740/03692] [00:15:55/00:17:51, 0.549s/it]: train_loss_raw=0.3984, running_loss=0.4235, LR=0.000100
[2025-08-11 00:54:40,494][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090360] [Batch 01752/03692] [00:16:01/00:17:45, 0.549s/it]: train_loss_raw=0.4256, running_loss=0.4248, LR=0.000100
[2025-08-11 00:54:46,956][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090372] [Batch 01764/03692] [00:16:08/00:17:38, 0.549s/it]: train_loss_raw=0.4497, running_loss=0.4238, LR=0.000100
[2025-08-11 00:54:53,414][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090384] [Batch 01776/03692] [00:16:14/00:17:31, 0.549s/it]: train_loss_raw=0.3865, running_loss=0.4247, LR=0.000100
[2025-08-11 00:54:59,852][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090396] [Batch 01788/03692] [00:16:21/00:17:24, 0.549s/it]: train_loss_raw=0.3841, running_loss=0.4237, LR=0.000100
[2025-08-11 00:55:06,291][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090408] [Batch 01800/03692] [00:16:27/00:17:18, 0.549s/it]: train_loss_raw=0.3004, running_loss=0.4238, LR=0.000100
[2025-08-11 00:55:12,721][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090420] [Batch 01812/03692] [00:16:34/00:17:11, 0.549s/it]: train_loss_raw=0.4761, running_loss=0.4236, LR=0.000100
[2025-08-11 00:55:18,791][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090432] [Batch 01824/03692] [00:16:40/00:17:04, 0.548s/it]: train_loss_raw=0.4110, running_loss=0.4240, LR=0.000100
[2025-08-11 00:55:24,853][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090444] [Batch 01836/03692] [00:16:46/00:16:57, 0.548s/it]: train_loss_raw=0.4292, running_loss=0.4218, LR=0.000100
[2025-08-11 00:55:30,913][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090456] [Batch 01848/03692] [00:16:52/00:16:50, 0.548s/it]: train_loss_raw=0.3886, running_loss=0.4234, LR=0.000100
[2025-08-11 00:55:36,961][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090468] [Batch 01860/03692] [00:16:58/00:16:42, 0.547s/it]: train_loss_raw=0.3994, running_loss=0.4238, LR=0.000100
[2025-08-11 00:55:42,934][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090480] [Batch 01872/03692] [00:17:04/00:16:35, 0.547s/it]: train_loss_raw=0.4251, running_loss=0.4244, LR=0.000100
[2025-08-11 00:55:48,965][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090492] [Batch 01884/03692] [00:17:10/00:16:28, 0.547s/it]: train_loss_raw=0.3880, running_loss=0.4217, LR=0.000100
[2025-08-11 00:55:55,036][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090504] [Batch 01896/03692] [00:17:16/00:16:21, 0.547s/it]: train_loss_raw=0.2751, running_loss=0.4176, LR=0.000100
[2025-08-11 00:56:01,093][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090516] [Batch 01908/03692] [00:17:22/00:16:14, 0.546s/it]: train_loss_raw=0.3930, running_loss=0.4169, LR=0.000100
[2025-08-11 00:56:07,294][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090528] [Batch 01920/03692] [00:17:28/00:16:07, 0.546s/it]: train_loss_raw=0.3103, running_loss=0.4163, LR=0.000100
[2025-08-11 00:56:13,756][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090540] [Batch 01932/03692] [00:17:35/00:16:01, 0.546s/it]: train_loss_raw=0.4264, running_loss=0.4163, LR=0.000100
[2025-08-11 00:56:20,269][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090552] [Batch 01944/03692] [00:17:41/00:15:54, 0.546s/it]: train_loss_raw=0.4352, running_loss=0.4194, LR=0.000100
[2025-08-11 00:56:26,805][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090564] [Batch 01956/03692] [00:17:48/00:15:47, 0.546s/it]: train_loss_raw=0.3554, running_loss=0.4226, LR=0.000100
[2025-08-11 00:56:32,950][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090576] [Batch 01968/03692] [00:17:54/00:15:41, 0.546s/it]: train_loss_raw=0.3379, running_loss=0.4228, LR=0.000100
[2025-08-11 00:56:39,014][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090588] [Batch 01980/03692] [00:18:00/00:15:34, 0.546s/it]: train_loss_raw=0.4220, running_loss=0.4247, LR=0.000100
[2025-08-11 00:56:45,065][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090600] [Batch 01992/03692] [00:18:06/00:15:27, 0.545s/it]: train_loss_raw=0.3837, running_loss=0.4241, LR=0.000100
[2025-08-11 00:56:51,053][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090612] [Batch 02004/03692] [00:18:12/00:15:20, 0.545s/it]: train_loss_raw=0.3663, running_loss=0.4237, LR=0.000100
[2025-08-11 00:56:57,060][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090624] [Batch 02016/03692] [00:18:18/00:15:13, 0.545s/it]: train_loss_raw=0.4426, running_loss=0.4244, LR=0.000100
[2025-08-11 00:57:03,101][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090636] [Batch 02028/03692] [00:18:24/00:15:06, 0.545s/it]: train_loss_raw=0.3140, running_loss=0.4264, LR=0.000100
[2025-08-11 00:57:09,145][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090648] [Batch 02040/03692] [00:18:30/00:14:59, 0.544s/it]: train_loss_raw=0.3851, running_loss=0.4266, LR=0.000100
[2025-08-11 00:57:15,198][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090660] [Batch 02052/03692] [00:18:36/00:14:52, 0.544s/it]: train_loss_raw=0.4440, running_loss=0.4256, LR=0.000100
[2025-08-11 00:57:21,145][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090672] [Batch 02064/03692] [00:18:42/00:14:45, 0.544s/it]: train_loss_raw=0.3894, running_loss=0.4233, LR=0.000100
[2025-08-11 00:57:27,205][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090684] [Batch 02076/03692] [00:18:48/00:14:38, 0.544s/it]: train_loss_raw=0.3372, running_loss=0.4243, LR=0.000100
[2025-08-11 00:57:33,235][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090696] [Batch 02088/03692] [00:18:54/00:14:31, 0.543s/it]: train_loss_raw=0.5205, running_loss=0.4260, LR=0.000100
[2025-08-11 00:57:39,304][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090708] [Batch 02100/03692] [00:19:00/00:14:24, 0.543s/it]: train_loss_raw=0.4611, running_loss=0.4256, LR=0.000100
[2025-08-11 00:57:45,296][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090720] [Batch 02112/03692] [00:19:06/00:14:17, 0.543s/it]: train_loss_raw=0.5073, running_loss=0.4241, LR=0.000100
[2025-08-11 00:57:51,329][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090732] [Batch 02124/03692] [00:19:12/00:14:10, 0.543s/it]: train_loss_raw=0.4399, running_loss=0.4236, LR=0.000100
[2025-08-11 00:57:57,413][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090744] [Batch 02136/03692] [00:19:18/00:14:04, 0.542s/it]: train_loss_raw=0.4230, running_loss=0.4234, LR=0.000100
[2025-08-11 00:58:03,469][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090756] [Batch 02148/03692] [00:19:24/00:13:57, 0.542s/it]: train_loss_raw=0.4552, running_loss=0.4248, LR=0.000100
[2025-08-11 00:58:09,689][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090768] [Batch 02160/03692] [00:19:30/00:13:50, 0.542s/it]: train_loss_raw=0.4157, running_loss=0.4236, LR=0.000100
[2025-08-11 00:58:16,157][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090780] [Batch 02172/03692] [00:19:37/00:13:44, 0.542s/it]: train_loss_raw=0.3591, running_loss=0.4265, LR=0.000100
[2025-08-11 00:58:22,699][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090792] [Batch 02184/03692] [00:19:44/00:13:37, 0.542s/it]: train_loss_raw=0.4334, running_loss=0.4256, LR=0.000100
[2025-08-11 00:58:28,760][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090804] [Batch 02196/03692] [00:19:50/00:13:30, 0.542s/it]: train_loss_raw=0.4110, running_loss=0.4246, LR=0.000100
[2025-08-11 00:58:34,781][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090816] [Batch 02208/03692] [00:19:56/00:13:23, 0.542s/it]: train_loss_raw=0.4263, running_loss=0.4242, LR=0.000100
[2025-08-11 00:58:40,820][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090828] [Batch 02220/03692] [00:20:02/00:13:17, 0.541s/it]: train_loss_raw=0.3760, running_loss=0.4234, LR=0.000100
[2025-08-11 00:58:46,850][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090840] [Batch 02232/03692] [00:20:08/00:13:10, 0.541s/it]: train_loss_raw=0.4260, running_loss=0.4232, LR=0.000100
[2025-08-11 00:58:52,910][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090852] [Batch 02244/03692] [00:20:14/00:13:03, 0.541s/it]: train_loss_raw=0.4250, running_loss=0.4238, LR=0.000100
[2025-08-11 00:58:58,912][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090864] [Batch 02256/03692] [00:20:20/00:12:56, 0.541s/it]: train_loss_raw=0.4038, running_loss=0.4236, LR=0.000100
[2025-08-11 00:59:04,939][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090876] [Batch 02268/03692] [00:20:26/00:12:49, 0.541s/it]: train_loss_raw=0.4242, running_loss=0.4200, LR=0.000100
[2025-08-11 00:59:11,002][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090888] [Batch 02280/03692] [00:20:32/00:12:43, 0.540s/it]: train_loss_raw=0.3697, running_loss=0.4204, LR=0.000100
[2025-08-11 00:59:17,095][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090900] [Batch 02292/03692] [00:20:38/00:12:36, 0.540s/it]: train_loss_raw=0.3836, running_loss=0.4227, LR=0.000100
[2025-08-11 00:59:23,144][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090912] [Batch 02304/03692] [00:20:44/00:12:29, 0.540s/it]: train_loss_raw=0.4419, running_loss=0.4217, LR=0.000100
[2025-08-11 00:59:29,232][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090924] [Batch 02316/03692] [00:20:50/00:12:22, 0.540s/it]: train_loss_raw=0.3841, running_loss=0.4192, LR=0.000100
[2025-08-11 00:59:35,248][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090936] [Batch 02328/03692] [00:20:56/00:12:16, 0.540s/it]: train_loss_raw=0.3639, running_loss=0.4199, LR=0.000100
[2025-08-11 00:59:41,324][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090948] [Batch 02340/03692] [00:21:02/00:12:09, 0.540s/it]: train_loss_raw=0.3990, running_loss=0.4179, LR=0.000100
[2025-08-11 00:59:47,311][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090960] [Batch 02352/03692] [00:21:08/00:12:02, 0.539s/it]: train_loss_raw=0.4594, running_loss=0.4185, LR=0.000100
[2025-08-11 00:59:53,345][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090972] [Batch 02364/03692] [00:21:14/00:11:56, 0.539s/it]: train_loss_raw=0.3467, running_loss=0.4196, LR=0.000100
[2025-08-11 00:59:59,639][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090984] [Batch 02376/03692] [00:21:20/00:11:49, 0.539s/it]: train_loss_raw=0.4176, running_loss=0.4243, LR=0.000100
[2025-08-11 01:00:06,140][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090996] [Batch 02388/03692] [00:21:27/00:11:43, 0.539s/it]: train_loss_raw=0.4926, running_loss=0.4239, LR=0.000100
[2025-08-11 01:00:12,220][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091008] [Batch 02400/03692] [00:21:33/00:11:36, 0.539s/it]: train_loss_raw=0.4428, running_loss=0.4244, LR=0.000100
[2025-08-11 01:00:18,258][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091020] [Batch 02412/03692] [00:21:39/00:11:29, 0.539s/it]: train_loss_raw=0.5383, running_loss=0.4272, LR=0.000100
[2025-08-11 01:00:24,307][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091032] [Batch 02424/03692] [00:21:45/00:11:22, 0.539s/it]: train_loss_raw=0.4437, running_loss=0.4273, LR=0.000100
[2025-08-11 01:00:30,347][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091044] [Batch 02436/03692] [00:21:51/00:11:16, 0.538s/it]: train_loss_raw=0.3799, running_loss=0.4300, LR=0.000100
[2025-08-11 01:00:36,698][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091056] [Batch 02448/03692] [00:21:58/00:11:09, 0.538s/it]: train_loss_raw=0.4829, running_loss=0.4270, LR=0.000100
[2025-08-11 01:00:42,945][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091068] [Batch 02460/03692] [00:22:04/00:11:03, 0.538s/it]: train_loss_raw=0.3461, running_loss=0.4250, LR=0.000100
[2025-08-11 01:00:49,010][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091080] [Batch 02472/03692] [00:22:10/00:10:56, 0.538s/it]: train_loss_raw=0.5226, running_loss=0.4236, LR=0.000100
[2025-08-11 01:00:55,047][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091092] [Batch 02484/03692] [00:22:16/00:10:49, 0.538s/it]: train_loss_raw=0.4003, running_loss=0.4239, LR=0.000100
[2025-08-11 01:01:01,211][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091104] [Batch 02496/03692] [00:22:22/00:10:43, 0.538s/it]: train_loss_raw=0.5344, running_loss=0.4269, LR=0.000100
[2025-08-11 01:01:07,559][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091116] [Batch 02508/03692] [00:22:28/00:10:36, 0.538s/it]: train_loss_raw=0.3817, running_loss=0.4235, LR=0.000100
[2025-08-11 01:01:13,580][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091128] [Batch 02520/03692] [00:22:34/00:10:30, 0.538s/it]: train_loss_raw=0.4453, running_loss=0.4229, LR=0.000100
[2025-08-11 01:01:19,594][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091140] [Batch 02532/03692] [00:22:40/00:10:23, 0.537s/it]: train_loss_raw=0.4041, running_loss=0.4233, LR=0.000100
[2025-08-11 01:01:25,625][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091152] [Batch 02544/03692] [00:22:46/00:10:16, 0.537s/it]: train_loss_raw=0.4413, running_loss=0.4240, LR=0.000100
[2025-08-11 01:01:31,658][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091164] [Batch 02556/03692] [00:22:52/00:10:10, 0.537s/it]: train_loss_raw=0.5121, running_loss=0.4248, LR=0.000100
[2025-08-11 01:01:37,867][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091176] [Batch 02568/03692] [00:22:59/00:10:03, 0.537s/it]: train_loss_raw=0.4001, running_loss=0.4253, LR=0.000100
[2025-08-11 01:01:44,012][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091188] [Batch 02580/03692] [00:23:05/00:09:57, 0.537s/it]: train_loss_raw=0.3924, running_loss=0.4214, LR=0.000100
[2025-08-11 01:01:50,061][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091200] [Batch 02592/03692] [00:23:11/00:09:50, 0.537s/it]: train_loss_raw=0.4522, running_loss=0.4217, LR=0.000100
[2025-08-11 01:01:56,081][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091212] [Batch 02604/03692] [00:23:17/00:09:43, 0.537s/it]: train_loss_raw=0.4154, running_loss=0.4218, LR=0.000100
[2025-08-11 01:02:02,147][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091224] [Batch 02616/03692] [00:23:23/00:09:37, 0.536s/it]: train_loss_raw=0.3384, running_loss=0.4219, LR=0.000100
[2025-08-11 01:02:08,367][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091236] [Batch 02628/03692] [00:23:29/00:09:30, 0.536s/it]: train_loss_raw=0.4879, running_loss=0.4221, LR=0.000100
[2025-08-11 01:02:14,978][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091248] [Batch 02640/03692] [00:23:36/00:09:24, 0.536s/it]: train_loss_raw=0.3742, running_loss=0.4239, LR=0.000100
[2025-08-11 01:02:21,315][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091260] [Batch 02652/03692] [00:23:42/00:09:17, 0.536s/it]: train_loss_raw=0.4125, running_loss=0.4230, LR=0.000100
[2025-08-11 01:02:27,845][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091272] [Batch 02664/03692] [00:23:49/00:09:11, 0.536s/it]: train_loss_raw=0.3928, running_loss=0.4211, LR=0.000100
[2025-08-11 01:02:34,352][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091284] [Batch 02676/03692] [00:23:55/00:09:05, 0.536s/it]: train_loss_raw=0.4924, running_loss=0.4215, LR=0.000100
[2025-08-11 01:02:40,906][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091296] [Batch 02688/03692] [00:24:02/00:08:58, 0.537s/it]: train_loss_raw=0.3949, running_loss=0.4215, LR=0.000100
[2025-08-11 01:02:47,354][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091308] [Batch 02700/03692] [00:24:08/00:08:52, 0.537s/it]: train_loss_raw=0.3566, running_loss=0.4234, LR=0.000100
[2025-08-11 01:02:53,885][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091320] [Batch 02712/03692] [00:24:15/00:08:45, 0.537s/it]: train_loss_raw=0.3727, running_loss=0.4221, LR=0.000100
[2025-08-11 01:03:00,277][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091332] [Batch 02724/03692] [00:24:21/00:08:39, 0.537s/it]: train_loss_raw=0.4803, running_loss=0.4244, LR=0.000100
[2025-08-11 01:03:06,769][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091344] [Batch 02736/03692] [00:24:28/00:08:32, 0.537s/it]: train_loss_raw=0.3750, running_loss=0.4240, LR=0.000100
[2025-08-11 01:03:13,272][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091356] [Batch 02748/03692] [00:24:34/00:08:26, 0.537s/it]: train_loss_raw=0.4814, running_loss=0.4245, LR=0.000100
[2025-08-11 01:03:19,683][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091368] [Batch 02760/03692] [00:24:40/00:08:20, 0.537s/it]: train_loss_raw=0.4455, running_loss=0.4220, LR=0.000100
[2025-08-11 01:03:26,141][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091380] [Batch 02772/03692] [00:24:47/00:08:13, 0.537s/it]: train_loss_raw=0.4381, running_loss=0.4198, LR=0.000100
[2025-08-11 01:03:32,480][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091392] [Batch 02784/03692] [00:24:53/00:08:07, 0.537s/it]: train_loss_raw=0.4917, running_loss=0.4165, LR=0.000100
[2025-08-11 01:03:38,871][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091404] [Batch 02796/03692] [00:25:00/00:08:00, 0.537s/it]: train_loss_raw=0.3164, running_loss=0.4169, LR=0.000100
[2025-08-11 01:03:45,227][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091416] [Batch 02808/03692] [00:25:06/00:07:54, 0.537s/it]: train_loss_raw=0.3720, running_loss=0.4175, LR=0.000100
[2025-08-11 01:03:51,571][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091428] [Batch 02820/03692] [00:25:12/00:07:47, 0.536s/it]: train_loss_raw=0.4285, running_loss=0.4196, LR=0.000100
[2025-08-11 01:03:57,973][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091440] [Batch 02832/03692] [00:25:19/00:07:41, 0.536s/it]: train_loss_raw=0.4938, running_loss=0.4228, LR=0.000100
[2025-08-11 01:04:04,396][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091452] [Batch 02844/03692] [00:25:25/00:07:34, 0.536s/it]: train_loss_raw=0.3676, running_loss=0.4206, LR=0.000100
[2025-08-11 01:04:10,776][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091464] [Batch 02856/03692] [00:25:32/00:07:28, 0.536s/it]: train_loss_raw=0.4023, running_loss=0.4186, LR=0.000100
[2025-08-11 01:04:17,205][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091476] [Batch 02868/03692] [00:25:38/00:07:22, 0.536s/it]: train_loss_raw=0.3899, running_loss=0.4222, LR=0.000100
[2025-08-11 01:04:23,581][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091488] [Batch 02880/03692] [00:25:44/00:07:15, 0.536s/it]: train_loss_raw=0.5718, running_loss=0.4223, LR=0.000100
[2025-08-11 01:04:29,969][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091500] [Batch 02892/03692] [00:25:51/00:07:09, 0.536s/it]: train_loss_raw=0.4286, running_loss=0.4219, LR=0.000100
[2025-08-11 01:04:36,418][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091512] [Batch 02904/03692] [00:25:57/00:07:02, 0.536s/it]: train_loss_raw=0.3795, running_loss=0.4209, LR=0.000100
[2025-08-11 01:04:42,789][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091524] [Batch 02916/03692] [00:26:04/00:06:56, 0.536s/it]: train_loss_raw=0.4475, running_loss=0.4228, LR=0.000100
[2025-08-11 01:04:49,230][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091536] [Batch 02928/03692] [00:26:10/00:06:49, 0.536s/it]: train_loss_raw=0.5448, running_loss=0.4250, LR=0.000100
[2025-08-11 01:04:55,586][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091548] [Batch 02940/03692] [00:26:16/00:06:43, 0.536s/it]: train_loss_raw=0.3823, running_loss=0.4239, LR=0.000100
[2025-08-11 01:05:02,120][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091560] [Batch 02952/03692] [00:26:23/00:06:36, 0.536s/it]: train_loss_raw=0.4034, running_loss=0.4239, LR=0.000100
[2025-08-11 01:05:08,255][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091572] [Batch 02964/03692] [00:26:29/00:06:30, 0.536s/it]: train_loss_raw=0.4832, running_loss=0.4248, LR=0.000100
[2025-08-11 01:05:14,783][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091584] [Batch 02976/03692] [00:26:36/00:06:24, 0.536s/it]: train_loss_raw=0.2786, running_loss=0.4219, LR=0.000100
[2025-08-11 01:05:21,304][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091596] [Batch 02988/03692] [00:26:42/00:06:17, 0.536s/it]: train_loss_raw=0.4776, running_loss=0.4203, LR=0.000100
[2025-08-11 01:05:27,689][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091608] [Batch 03000/03692] [00:26:48/00:06:11, 0.536s/it]: train_loss_raw=0.5311, running_loss=0.4194, LR=0.000100
[2025-08-11 01:05:34,067][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091620] [Batch 03012/03692] [00:26:55/00:06:04, 0.536s/it]: train_loss_raw=0.3838, running_loss=0.4194, LR=0.000100
[2025-08-11 01:05:40,411][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091632] [Batch 03024/03692] [00:27:01/00:05:58, 0.536s/it]: train_loss_raw=0.2737, running_loss=0.4173, LR=0.000100
[2025-08-11 01:05:46,819][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091644] [Batch 03036/03692] [00:27:08/00:05:51, 0.536s/it]: train_loss_raw=0.4162, running_loss=0.4185, LR=0.000100
[2025-08-11 01:05:53,296][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091656] [Batch 03048/03692] [00:27:14/00:05:45, 0.536s/it]: train_loss_raw=0.5435, running_loss=0.4181, LR=0.000100
[2025-08-11 01:05:59,689][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091668] [Batch 03060/03692] [00:27:20/00:05:38, 0.536s/it]: train_loss_raw=0.5339, running_loss=0.4197, LR=0.000100
[2025-08-11 01:06:06,066][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091680] [Batch 03072/03692] [00:27:27/00:05:32, 0.536s/it]: train_loss_raw=0.4223, running_loss=0.4192, LR=0.000100
[2025-08-11 01:06:12,510][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091692] [Batch 03084/03692] [00:27:33/00:05:26, 0.536s/it]: train_loss_raw=0.4346, running_loss=0.4197, LR=0.000100
[2025-08-11 01:06:18,877][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091704] [Batch 03096/03692] [00:27:40/00:05:19, 0.536s/it]: train_loss_raw=0.3310, running_loss=0.4170, LR=0.000100
[2025-08-11 01:06:25,292][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091716] [Batch 03108/03692] [00:27:46/00:05:13, 0.536s/it]: train_loss_raw=0.4422, running_loss=0.4187, LR=0.000100
[2025-08-11 01:06:31,889][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091728] [Batch 03120/03692] [00:27:53/00:05:06, 0.536s/it]: train_loss_raw=0.4701, running_loss=0.4208, LR=0.000100
[2025-08-11 01:06:38,444][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091740] [Batch 03132/03692] [00:27:59/00:05:00, 0.536s/it]: train_loss_raw=0.4651, running_loss=0.4190, LR=0.000100
[2025-08-11 01:06:44,990][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091752] [Batch 03144/03692] [00:28:06/00:04:53, 0.536s/it]: train_loss_raw=0.4683, running_loss=0.4202, LR=0.000100
[2025-08-11 01:06:51,394][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091764] [Batch 03156/03692] [00:28:12/00:04:47, 0.536s/it]: train_loss_raw=0.4808, running_loss=0.4207, LR=0.000100
[2025-08-11 01:06:57,746][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091776] [Batch 03168/03692] [00:28:19/00:04:41, 0.536s/it]: train_loss_raw=0.3406, running_loss=0.4195, LR=0.000100
[2025-08-11 01:07:04,188][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091788] [Batch 03180/03692] [00:28:25/00:04:34, 0.536s/it]: train_loss_raw=0.3429, running_loss=0.4177, LR=0.000100
[2025-08-11 01:07:10,597][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091800] [Batch 03192/03692] [00:28:31/00:04:28, 0.536s/it]: train_loss_raw=0.3890, running_loss=0.4174, LR=0.000100
[2025-08-11 01:07:17,238][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091812] [Batch 03204/03692] [00:28:38/00:04:21, 0.536s/it]: train_loss_raw=0.4542, running_loss=0.4150, LR=0.000100
[2025-08-11 01:07:23,639][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091824] [Batch 03216/03692] [00:28:44/00:04:15, 0.536s/it]: train_loss_raw=0.5659, running_loss=0.4152, LR=0.000100
[2025-08-11 01:07:30,069][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091836] [Batch 03228/03692] [00:28:51/00:04:08, 0.536s/it]: train_loss_raw=0.5038, running_loss=0.4203, LR=0.000100
[2025-08-11 01:07:36,457][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091848] [Batch 03240/03692] [00:28:57/00:04:02, 0.536s/it]: train_loss_raw=0.4001, running_loss=0.4202, LR=0.000100
[2025-08-11 01:07:42,767][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091860] [Batch 03252/03692] [00:29:04/00:03:55, 0.536s/it]: train_loss_raw=0.4441, running_loss=0.4200, LR=0.000100
[2025-08-11 01:07:49,231][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091872] [Batch 03264/03692] [00:29:10/00:03:49, 0.536s/it]: train_loss_raw=0.4445, running_loss=0.4222, LR=0.000100
[2025-08-11 01:07:55,593][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091884] [Batch 03276/03692] [00:29:16/00:03:43, 0.536s/it]: train_loss_raw=0.3869, running_loss=0.4201, LR=0.000100
[2025-08-11 01:08:01,742][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091896] [Batch 03288/03692] [00:29:23/00:03:36, 0.536s/it]: train_loss_raw=0.2738, running_loss=0.4207, LR=0.000100
[2025-08-11 01:08:08,268][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091908] [Batch 03300/03692] [00:29:29/00:03:30, 0.536s/it]: train_loss_raw=0.3379, running_loss=0.4206, LR=0.000100
[2025-08-11 01:08:14,762][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091920] [Batch 03312/03692] [00:29:36/00:03:23, 0.536s/it]: train_loss_raw=0.4235, running_loss=0.4207, LR=0.000100
[2025-08-11 01:08:21,217][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091932] [Batch 03324/03692] [00:29:42/00:03:17, 0.536s/it]: train_loss_raw=0.4118, running_loss=0.4203, LR=0.000100
[2025-08-11 01:08:27,617][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091944] [Batch 03336/03692] [00:29:48/00:03:10, 0.536s/it]: train_loss_raw=0.4558, running_loss=0.4246, LR=0.000100
[2025-08-11 01:08:34,027][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091956] [Batch 03348/03692] [00:29:55/00:03:04, 0.536s/it]: train_loss_raw=0.3760, running_loss=0.4248, LR=0.000100
[2025-08-11 01:08:40,320][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091968] [Batch 03360/03692] [00:30:01/00:02:58, 0.536s/it]: train_loss_raw=0.4513, running_loss=0.4283, LR=0.000100
[2025-08-11 01:08:46,697][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091980] [Batch 03372/03692] [00:30:08/00:02:51, 0.536s/it]: train_loss_raw=0.5251, running_loss=0.4278, LR=0.000100
[2025-08-11 01:08:53,172][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091992] [Batch 03384/03692] [00:30:14/00:02:45, 0.536s/it]: train_loss_raw=0.4822, running_loss=0.4300, LR=0.000100
[2025-08-11 01:09:04,271][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092004] [Batch 03396/03692] [00:30:25/00:02:39, 0.538s/it]: train_loss_raw=0.4767, running_loss=0.4271, LR=0.000100
[2025-08-11 01:09:10,438][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092016] [Batch 03408/03692] [00:30:31/00:02:32, 0.537s/it]: train_loss_raw=0.4506, running_loss=0.4236, LR=0.000100
[2025-08-11 01:09:16,964][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092028] [Batch 03420/03692] [00:30:38/00:02:26, 0.538s/it]: train_loss_raw=0.3641, running_loss=0.4237, LR=0.000100
[2025-08-11 01:09:23,456][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092040] [Batch 03432/03692] [00:30:44/00:02:19, 0.538s/it]: train_loss_raw=0.3998, running_loss=0.4201, LR=0.000100
[2025-08-11 01:09:29,847][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092052] [Batch 03444/03692] [00:30:51/00:02:13, 0.538s/it]: train_loss_raw=0.4204, running_loss=0.4177, LR=0.000100
[2025-08-11 01:09:35,958][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092064] [Batch 03456/03692] [00:30:57/00:02:06, 0.537s/it]: train_loss_raw=0.4472, running_loss=0.4171, LR=0.000100
[2025-08-11 01:09:42,467][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092076] [Batch 03468/03692] [00:31:03/00:02:00, 0.537s/it]: train_loss_raw=0.4108, running_loss=0.4164, LR=0.000100
[2025-08-11 01:09:48,919][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092088] [Batch 03480/03692] [00:31:10/00:01:53, 0.537s/it]: train_loss_raw=0.4699, running_loss=0.4162, LR=0.000100
[2025-08-11 01:09:55,501][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092100] [Batch 03492/03692] [00:31:16/00:01:47, 0.537s/it]: train_loss_raw=0.4174, running_loss=0.4192, LR=0.000100
[2025-08-11 01:10:01,837][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092112] [Batch 03504/03692] [00:31:23/00:01:41, 0.537s/it]: train_loss_raw=0.3820, running_loss=0.4186, LR=0.000100
[2025-08-11 01:10:08,138][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092124] [Batch 03516/03692] [00:31:29/00:01:34, 0.537s/it]: train_loss_raw=0.4023, running_loss=0.4178, LR=0.000100
[2025-08-11 01:10:14,140][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092136] [Batch 03528/03692] [00:31:35/00:01:28, 0.537s/it]: train_loss_raw=0.4694, running_loss=0.4219, LR=0.000100
[2025-08-11 01:10:20,188][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092148] [Batch 03540/03692] [00:31:41/00:01:21, 0.537s/it]: train_loss_raw=0.3254, running_loss=0.4199, LR=0.000100
[2025-08-11 01:10:26,226][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092160] [Batch 03552/03692] [00:31:47/00:01:15, 0.537s/it]: train_loss_raw=0.4388, running_loss=0.4221, LR=0.000100
[2025-08-11 01:10:32,682][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092172] [Batch 03564/03692] [00:31:53/00:01:08, 0.537s/it]: train_loss_raw=0.3967, running_loss=0.4217, LR=0.000100
[2025-08-11 01:10:38,779][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092184] [Batch 03576/03692] [00:32:00/00:01:02, 0.537s/it]: train_loss_raw=0.3192, running_loss=0.4218, LR=0.000100
[2025-08-11 01:10:45,209][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092196] [Batch 03588/03692] [00:32:06/00:00:55, 0.537s/it]: train_loss_raw=0.4731, running_loss=0.4245, LR=0.000100
[2025-08-11 01:10:51,626][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092208] [Batch 03600/03692] [00:32:12/00:00:49, 0.537s/it]: train_loss_raw=0.3773, running_loss=0.4252, LR=0.000100
[2025-08-11 01:10:58,166][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092220] [Batch 03612/03692] [00:32:19/00:00:42, 0.537s/it]: train_loss_raw=0.4484, running_loss=0.4256, LR=0.000100
[2025-08-11 01:11:04,702][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092232] [Batch 03624/03692] [00:32:26/00:00:36, 0.537s/it]: train_loss_raw=0.5181, running_loss=0.4248, LR=0.000100
[2025-08-11 01:11:11,241][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092244] [Batch 03636/03692] [00:32:32/00:00:30, 0.537s/it]: train_loss_raw=0.6013, running_loss=0.4204, LR=0.000100
[2025-08-11 01:11:17,781][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092256] [Batch 03648/03692] [00:32:39/00:00:23, 0.537s/it]: train_loss_raw=0.3182, running_loss=0.4199, LR=0.000100
[2025-08-11 01:11:24,168][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092268] [Batch 03660/03692] [00:32:45/00:00:17, 0.537s/it]: train_loss_raw=0.4711, running_loss=0.4202, LR=0.000100
[2025-08-11 01:11:30,555][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092280] [Batch 03672/03692] [00:32:51/00:00:10, 0.537s/it]: train_loss_raw=0.3175, running_loss=0.4178, LR=0.000100
[2025-08-11 01:11:36,966][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092292] [Batch 03684/03692] [00:32:58/00:00:04, 0.537s/it]: train_loss_raw=0.3414, running_loss=0.4198, LR=0.000100
[2025-08-11 01:11:46,297][__main__][INFO] - [VALIDATION] [Epoch 24/29] Starting validation.
[2025-08-11 01:12:19,491][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 092301] [Batch 00011/00025] [00:00:33/00:00:35, 2.766s/it]
[2025-08-11 01:12:35,456][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 092301] [Batch 00023/00025] [00:00:49/00:00:02, 2.048s/it]
[2025-08-11 01:12:36,584][__main__][INFO] - [VALIDATION] [Epoch 24/29] train_loss=0.41864, valid_loss=0.56616
[2025-08-11 01:12:36,585][__main__][INFO] - [VALIDATION] [Epoch 24/29] Metrics:
[2025-08-11 01:12:36,585][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_er      0.224
[2025-08-11 01:12:36,585][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_prec    0.580
[2025-08-11 01:12:36,586][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_recall  0.585
[2025-08-11 01:12:36,586][__main__][INFO] - [VALIDATION] [Epoch 24/29] - pep_recall 0.568
[2025-08-11 01:12:36,589][__main__][INFO] - [TRAIN] [Epoch 24/29] Epoch complete, total time 14:16:35, remaining time 02:51:19, 00:34:15 per epoch
[2025-08-11 01:12:38,560][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092304] [Batch 00004/03692] [00:00:01/00:26:14, 0.427s/it]: train_loss_raw=0.3988, running_loss=0.4434, LR=0.000100
[2025-08-11 01:12:45,220][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092316] [Batch 00016/03692] [00:00:08/00:32:02, 0.523s/it]: train_loss_raw=0.3640, running_loss=0.4398, LR=0.000100
[2025-08-11 01:12:51,674][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092328] [Batch 00028/03692] [00:00:14/00:32:19, 0.529s/it]: train_loss_raw=0.3399, running_loss=0.4353, LR=0.000100
[2025-08-11 01:12:58,185][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092340] [Batch 00040/03692] [00:00:21/00:32:27, 0.533s/it]: train_loss_raw=0.4818, running_loss=0.4308, LR=0.000100
[2025-08-11 01:13:04,588][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092352] [Batch 00052/03692] [00:00:27/00:32:21, 0.533s/it]: train_loss_raw=0.4395, running_loss=0.4297, LR=0.000100
[2025-08-11 01:13:10,768][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092364] [Batch 00064/03692] [00:00:33/00:32:02, 0.530s/it]: train_loss_raw=0.4291, running_loss=0.4295, LR=0.000100
[2025-08-11 01:13:17,006][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092376] [Batch 00076/03692] [00:00:40/00:31:50, 0.528s/it]: train_loss_raw=0.5958, running_loss=0.4291, LR=0.000100
[2025-08-11 01:13:23,048][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092388] [Batch 00088/03692] [00:00:46/00:31:31, 0.525s/it]: train_loss_raw=0.4208, running_loss=0.4293, LR=0.000100
[2025-08-11 01:13:29,079][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092400] [Batch 00100/03692] [00:00:52/00:31:15, 0.522s/it]: train_loss_raw=0.3857, running_loss=0.4295, LR=0.000100
[2025-08-11 01:13:35,130][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092412] [Batch 00112/03692] [00:00:58/00:31:02, 0.520s/it]: train_loss_raw=0.3862, running_loss=0.4264, LR=0.000100
[2025-08-11 01:13:41,192][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092424] [Batch 00124/03692] [00:01:04/00:30:51, 0.519s/it]: train_loss_raw=0.4782, running_loss=0.4274, LR=0.000100
[2025-08-11 01:13:47,193][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092436] [Batch 00136/03692] [00:01:10/00:30:39, 0.517s/it]: train_loss_raw=0.4336, running_loss=0.4267, LR=0.000100
[2025-08-11 01:13:53,398][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092448] [Batch 00148/03692] [00:01:16/00:30:32, 0.517s/it]: train_loss_raw=0.3721, running_loss=0.4226, LR=0.000100
[2025-08-11 01:13:59,521][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092460] [Batch 00160/03692] [00:01:22/00:30:24, 0.517s/it]: train_loss_raw=0.3761, running_loss=0.4188, LR=0.000100
[2025-08-11 01:14:05,497][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092472] [Batch 00172/03692] [00:01:28/00:30:14, 0.515s/it]: train_loss_raw=0.3675, running_loss=0.4196, LR=0.000100
[2025-08-11 01:14:11,457][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092484] [Batch 00184/03692] [00:01:34/00:30:03, 0.514s/it]: train_loss_raw=0.4382, running_loss=0.4185, LR=0.000100
[2025-08-11 01:14:17,468][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092496] [Batch 00196/03692] [00:01:40/00:29:54, 0.513s/it]: train_loss_raw=0.4011, running_loss=0.4203, LR=0.000100
[2025-08-11 01:14:23,500][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092508] [Batch 00208/03692] [00:01:46/00:29:46, 0.513s/it]: train_loss_raw=0.4110, running_loss=0.4195, LR=0.000100
[2025-08-11 01:14:29,658][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092520] [Batch 00220/03692] [00:01:52/00:29:40, 0.513s/it]: train_loss_raw=0.3642, running_loss=0.4185, LR=0.000100
[2025-08-11 01:14:35,702][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092532] [Batch 00232/03692] [00:01:58/00:29:32, 0.512s/it]: train_loss_raw=0.5006, running_loss=0.4214, LR=0.000100
[2025-08-11 01:14:41,797][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092544] [Batch 00244/03692] [00:02:04/00:29:25, 0.512s/it]: train_loss_raw=0.5324, running_loss=0.4233, LR=0.000100
[2025-08-11 01:14:48,113][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092556] [Batch 00256/03692] [00:02:11/00:29:21, 0.513s/it]: train_loss_raw=0.3531, running_loss=0.4222, LR=0.000100
[2025-08-11 01:14:54,316][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092568] [Batch 00268/03692] [00:02:17/00:29:16, 0.513s/it]: train_loss_raw=0.5093, running_loss=0.4225, LR=0.000100
[2025-08-11 01:15:00,722][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092580] [Batch 00280/03692] [00:02:23/00:29:13, 0.514s/it]: train_loss_raw=0.4716, running_loss=0.4209, LR=0.000100
[2025-08-11 01:15:06,914][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092592] [Batch 00292/03692] [00:02:30/00:29:07, 0.514s/it]: train_loss_raw=0.4267, running_loss=0.4215, LR=0.000100
[2025-08-11 01:15:13,342][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092604] [Batch 00304/03692] [00:02:36/00:29:04, 0.515s/it]: train_loss_raw=0.4073, running_loss=0.4205, LR=0.000100
[2025-08-11 01:15:19,513][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092616] [Batch 00316/03692] [00:02:42/00:28:57, 0.515s/it]: train_loss_raw=0.4927, running_loss=0.4233, LR=0.000100
[2025-08-11 01:15:25,563][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092628] [Batch 00328/03692] [00:02:48/00:28:50, 0.514s/it]: train_loss_raw=0.5068, running_loss=0.4237, LR=0.000100
[2025-08-11 01:15:31,628][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092640] [Batch 00340/03692] [00:02:54/00:28:43, 0.514s/it]: train_loss_raw=0.4481, running_loss=0.4237, LR=0.000100
[2025-08-11 01:15:37,615][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092652] [Batch 00352/03692] [00:03:00/00:28:35, 0.514s/it]: train_loss_raw=0.4982, running_loss=0.4261, LR=0.000100
[2025-08-11 01:15:43,636][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092664] [Batch 00364/03692] [00:03:06/00:28:27, 0.513s/it]: train_loss_raw=0.3646, running_loss=0.4324, LR=0.000100
[2025-08-11 01:15:49,789][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092676] [Batch 00376/03692] [00:03:12/00:28:21, 0.513s/it]: train_loss_raw=0.3660, running_loss=0.4316, LR=0.000100
[2025-08-11 01:15:56,191][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092688] [Batch 00388/03692] [00:03:19/00:28:17, 0.514s/it]: train_loss_raw=0.4382, running_loss=0.4281, LR=0.000100
[2025-08-11 01:16:02,617][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092700] [Batch 00400/03692] [00:03:25/00:28:13, 0.514s/it]: train_loss_raw=0.5028, running_loss=0.4260, LR=0.000100
[2025-08-11 01:16:09,142][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092712] [Batch 00412/03692] [00:03:32/00:28:10, 0.515s/it]: train_loss_raw=0.3788, running_loss=0.4277, LR=0.000100
[2025-08-11 01:16:15,536][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092724] [Batch 00424/03692] [00:03:38/00:28:05, 0.516s/it]: train_loss_raw=0.4041, running_loss=0.4257, LR=0.000100
[2025-08-11 01:16:21,948][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092736] [Batch 00436/03692] [00:03:45/00:28:00, 0.516s/it]: train_loss_raw=0.3200, running_loss=0.4209, LR=0.000100
[2025-08-11 01:16:28,426][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092748] [Batch 00448/03692] [00:03:51/00:27:56, 0.517s/it]: train_loss_raw=0.5272, running_loss=0.4241, LR=0.000100
[2025-08-11 01:16:34,806][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092760] [Batch 00460/03692] [00:03:57/00:27:51, 0.517s/it]: train_loss_raw=0.3885, running_loss=0.4237, LR=0.000100
[2025-08-11 01:16:41,149][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092772] [Batch 00472/03692] [00:04:04/00:27:46, 0.518s/it]: train_loss_raw=0.4963, running_loss=0.4262, LR=0.000100
[2025-08-11 01:16:47,589][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092784] [Batch 00484/03692] [00:04:10/00:27:41, 0.518s/it]: train_loss_raw=0.4264, running_loss=0.4214, LR=0.000100
[2025-08-11 01:16:53,983][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092796] [Batch 00496/03692] [00:04:17/00:27:36, 0.518s/it]: train_loss_raw=0.3802, running_loss=0.4182, LR=0.000100
[2025-08-11 01:17:00,385][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092808] [Batch 00508/03692] [00:04:23/00:27:31, 0.519s/it]: train_loss_raw=0.3553, running_loss=0.4200, LR=0.000100
[2025-08-11 01:17:06,633][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092820] [Batch 00520/03692] [00:04:29/00:27:25, 0.519s/it]: train_loss_raw=0.3953, running_loss=0.4170, LR=0.000100
[2025-08-11 01:17:13,005][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092832] [Batch 00532/03692] [00:04:36/00:27:20, 0.519s/it]: train_loss_raw=0.3719, running_loss=0.4182, LR=0.000100
[2025-08-11 01:17:19,386][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092844] [Batch 00544/03692] [00:04:42/00:27:14, 0.519s/it]: train_loss_raw=0.4326, running_loss=0.4179, LR=0.000100
[2025-08-11 01:17:25,789][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092856] [Batch 00556/03692] [00:04:48/00:27:09, 0.520s/it]: train_loss_raw=0.3899, running_loss=0.4200, LR=0.000100
[2025-08-11 01:17:32,198][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092868] [Batch 00568/03692] [00:04:55/00:27:04, 0.520s/it]: train_loss_raw=0.3753, running_loss=0.4200, LR=0.000100
[2025-08-11 01:17:38,548][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092880] [Batch 00580/03692] [00:05:01/00:26:58, 0.520s/it]: train_loss_raw=0.4476, running_loss=0.4209, LR=0.000100
[2025-08-11 01:17:44,976][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092892] [Batch 00592/03692] [00:05:08/00:26:53, 0.520s/it]: train_loss_raw=0.4689, running_loss=0.4203, LR=0.000100
[2025-08-11 01:17:51,389][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092904] [Batch 00604/03692] [00:05:14/00:26:48, 0.521s/it]: train_loss_raw=0.5263, running_loss=0.4236, LR=0.000100
[2025-08-11 01:17:57,757][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092916] [Batch 00616/03692] [00:05:20/00:26:42, 0.521s/it]: train_loss_raw=0.3880, running_loss=0.4232, LR=0.000100
[2025-08-11 01:18:04,246][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092928] [Batch 00628/03692] [00:05:27/00:26:37, 0.521s/it]: train_loss_raw=0.4481, running_loss=0.4205, LR=0.000100
[2025-08-11 01:18:10,495][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092940] [Batch 00640/03692] [00:05:33/00:26:31, 0.521s/it]: train_loss_raw=0.4534, running_loss=0.4232, LR=0.000100
[2025-08-11 01:18:16,964][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092952] [Batch 00652/03692] [00:05:40/00:26:25, 0.522s/it]: train_loss_raw=0.4174, running_loss=0.4218, LR=0.000100
[2025-08-11 01:18:23,281][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092964] [Batch 00664/03692] [00:05:46/00:26:19, 0.522s/it]: train_loss_raw=0.4413, running_loss=0.4222, LR=0.000100
[2025-08-11 01:18:29,664][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092976] [Batch 00676/03692] [00:05:52/00:26:14, 0.522s/it]: train_loss_raw=0.5543, running_loss=0.4220, LR=0.000100
[2025-08-11 01:18:36,130][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092988] [Batch 00688/03692] [00:05:59/00:26:08, 0.522s/it]: train_loss_raw=0.3836, running_loss=0.4239, LR=0.000100
[2025-08-11 01:18:42,490][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093000] [Batch 00700/03692] [00:06:05/00:26:02, 0.522s/it]: train_loss_raw=0.4853, running_loss=0.4227, LR=0.000100
[2025-08-11 01:18:48,896][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093012] [Batch 00712/03692] [00:06:12/00:25:57, 0.523s/it]: train_loss_raw=0.3382, running_loss=0.4192, LR=0.000100
[2025-08-11 01:18:55,335][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093024] [Batch 00724/03692] [00:06:18/00:25:51, 0.523s/it]: train_loss_raw=0.3385, running_loss=0.4204, LR=0.000100
[2025-08-11 01:19:01,789][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093036] [Batch 00736/03692] [00:06:24/00:25:46, 0.523s/it]: train_loss_raw=0.4566, running_loss=0.4210, LR=0.000100
[2025-08-11 01:19:08,193][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093048] [Batch 00748/03692] [00:06:31/00:25:40, 0.523s/it]: train_loss_raw=0.3328, running_loss=0.4198, LR=0.000100
[2025-08-11 01:19:14,581][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093060] [Batch 00760/03692] [00:06:37/00:25:34, 0.523s/it]: train_loss_raw=0.3438, running_loss=0.4191, LR=0.000100
[2025-08-11 01:19:20,962][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093072] [Batch 00772/03692] [00:06:44/00:25:28, 0.523s/it]: train_loss_raw=0.4543, running_loss=0.4155, LR=0.000100
[2025-08-11 01:19:27,295][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093084] [Batch 00784/03692] [00:06:50/00:25:22, 0.524s/it]: train_loss_raw=0.3701, running_loss=0.4171, LR=0.000100
[2025-08-11 01:19:33,677][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093096] [Batch 00796/03692] [00:06:56/00:25:16, 0.524s/it]: train_loss_raw=0.3988, running_loss=0.4162, LR=0.000100
[2025-08-11 01:19:40,067][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093108] [Batch 00808/03692] [00:07:03/00:25:10, 0.524s/it]: train_loss_raw=0.4071, running_loss=0.4207, LR=0.000100
[2025-08-11 01:19:46,443][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093120] [Batch 00820/03692] [00:07:09/00:25:04, 0.524s/it]: train_loss_raw=0.4936, running_loss=0.4222, LR=0.000100
[2025-08-11 01:19:52,977][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093132] [Batch 00832/03692] [00:07:16/00:24:59, 0.524s/it]: train_loss_raw=0.3713, running_loss=0.4211, LR=0.000100
[2025-08-11 01:19:59,371][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093144] [Batch 00844/03692] [00:07:22/00:24:53, 0.524s/it]: train_loss_raw=0.3658, running_loss=0.4214, LR=0.000100
[2025-08-11 01:20:05,742][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093156] [Batch 00856/03692] [00:07:28/00:24:47, 0.524s/it]: train_loss_raw=0.4063, running_loss=0.4223, LR=0.000100
[2025-08-11 01:20:12,093][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093168] [Batch 00868/03692] [00:07:35/00:24:41, 0.524s/it]: train_loss_raw=0.4991, running_loss=0.4216, LR=0.000100
[2025-08-11 01:20:18,480][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093180] [Batch 00880/03692] [00:07:41/00:24:35, 0.525s/it]: train_loss_raw=0.3718, running_loss=0.4212, LR=0.000100
[2025-08-11 01:20:24,942][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093192] [Batch 00892/03692] [00:07:48/00:24:29, 0.525s/it]: train_loss_raw=0.4426, running_loss=0.4192, LR=0.000100
[2025-08-11 01:20:31,514][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093204] [Batch 00904/03692] [00:07:54/00:24:23, 0.525s/it]: train_loss_raw=0.4344, running_loss=0.4183, LR=0.000100
[2025-08-11 01:20:38,018][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093216] [Batch 00916/03692] [00:08:01/00:24:18, 0.525s/it]: train_loss_raw=0.5148, running_loss=0.4193, LR=0.000100
[2025-08-11 01:20:44,502][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093228] [Batch 00928/03692] [00:08:07/00:24:12, 0.525s/it]: train_loss_raw=0.4643, running_loss=0.4184, LR=0.000100
[2025-08-11 01:20:50,889][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093240] [Batch 00940/03692] [00:08:14/00:24:06, 0.526s/it]: train_loss_raw=0.4307, running_loss=0.4171, LR=0.000100
[2025-08-11 01:20:57,260][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093252] [Batch 00952/03692] [00:08:20/00:24:00, 0.526s/it]: train_loss_raw=0.3656, running_loss=0.4172, LR=0.000100
[2025-08-11 01:21:03,583][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093264] [Batch 00964/03692] [00:08:26/00:23:53, 0.526s/it]: train_loss_raw=0.3726, running_loss=0.4160, LR=0.000100
[2025-08-11 01:21:09,949][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093276] [Batch 00976/03692] [00:08:33/00:23:47, 0.526s/it]: train_loss_raw=0.2926, running_loss=0.4159, LR=0.000100
[2025-08-11 01:21:16,278][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093288] [Batch 00988/03692] [00:08:39/00:23:41, 0.526s/it]: train_loss_raw=0.4396, running_loss=0.4158, LR=0.000100
[2025-08-11 01:21:22,695][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093300] [Batch 01000/03692] [00:08:45/00:23:35, 0.526s/it]: train_loss_raw=0.4367, running_loss=0.4188, LR=0.000100
[2025-08-11 01:21:29,076][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093312] [Batch 01012/03692] [00:08:52/00:23:29, 0.526s/it]: train_loss_raw=0.4479, running_loss=0.4210, LR=0.000100
[2025-08-11 01:21:35,530][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093324] [Batch 01024/03692] [00:08:58/00:23:23, 0.526s/it]: train_loss_raw=0.3600, running_loss=0.4173, LR=0.000100
[2025-08-11 01:21:42,036][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093336] [Batch 01036/03692] [00:09:05/00:23:17, 0.526s/it]: train_loss_raw=0.4471, running_loss=0.4205, LR=0.000100
[2025-08-11 01:21:48,485][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093348] [Batch 01048/03692] [00:09:11/00:23:11, 0.526s/it]: train_loss_raw=0.4049, running_loss=0.4189, LR=0.000100
[2025-08-11 01:21:54,984][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093360] [Batch 01060/03692] [00:09:18/00:23:05, 0.527s/it]: train_loss_raw=0.3461, running_loss=0.4195, LR=0.000100
[2025-08-11 01:22:01,337][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093372] [Batch 01072/03692] [00:09:24/00:22:59, 0.527s/it]: train_loss_raw=0.4649, running_loss=0.4190, LR=0.000100
[2025-08-11 01:22:07,819][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093384] [Batch 01084/03692] [00:09:30/00:22:53, 0.527s/it]: train_loss_raw=0.3990, running_loss=0.4157, LR=0.000100
[2025-08-11 01:22:14,367][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093396] [Batch 01096/03692] [00:09:37/00:22:47, 0.527s/it]: train_loss_raw=0.3845, running_loss=0.4182, LR=0.000100
[2025-08-11 01:22:20,700][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093408] [Batch 01108/03692] [00:09:43/00:22:41, 0.527s/it]: train_loss_raw=0.3859, running_loss=0.4157, LR=0.000100
[2025-08-11 01:22:27,163][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093420] [Batch 01120/03692] [00:09:50/00:22:35, 0.527s/it]: train_loss_raw=0.3179, running_loss=0.4160, LR=0.000100
[2025-08-11 01:22:33,586][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093432] [Batch 01132/03692] [00:09:56/00:22:29, 0.527s/it]: train_loss_raw=0.3516, running_loss=0.4163, LR=0.000100
[2025-08-11 01:22:40,068][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093444] [Batch 01144/03692] [00:10:03/00:22:23, 0.527s/it]: train_loss_raw=0.4392, running_loss=0.4157, LR=0.000100
[2025-08-11 01:22:46,120][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093456] [Batch 01156/03692] [00:10:09/00:22:16, 0.527s/it]: train_loss_raw=0.3732, running_loss=0.4158, LR=0.000100
[2025-08-11 01:22:52,505][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093468] [Batch 01168/03692] [00:10:15/00:22:10, 0.527s/it]: train_loss_raw=0.3501, running_loss=0.4186, LR=0.000100
[2025-08-11 01:22:59,006][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093480] [Batch 01180/03692] [00:10:22/00:22:04, 0.527s/it]: train_loss_raw=0.3721, running_loss=0.4172, LR=0.000100
[2025-08-11 01:23:05,259][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093492] [Batch 01192/03692] [00:10:28/00:21:57, 0.527s/it]: train_loss_raw=0.4200, running_loss=0.4161, LR=0.000100
[2025-08-11 01:23:11,364][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093504] [Batch 01204/03692] [00:10:34/00:21:51, 0.527s/it]: train_loss_raw=0.4308, running_loss=0.4188, LR=0.000100
[2025-08-11 01:23:17,909][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093516] [Batch 01216/03692] [00:10:41/00:21:45, 0.527s/it]: train_loss_raw=0.5061, running_loss=0.4163, LR=0.000100
[2025-08-11 01:23:24,145][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093528] [Batch 01228/03692] [00:10:47/00:21:38, 0.527s/it]: train_loss_raw=0.3817, running_loss=0.4151, LR=0.000100
[2025-08-11 01:23:30,165][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093540] [Batch 01240/03692] [00:10:53/00:21:31, 0.527s/it]: train_loss_raw=0.4647, running_loss=0.4148, LR=0.000100
[2025-08-11 01:23:36,186][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093552] [Batch 01252/03692] [00:10:59/00:21:24, 0.527s/it]: train_loss_raw=0.3541, running_loss=0.4161, LR=0.000100
[2025-08-11 01:23:42,150][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093564] [Batch 01264/03692] [00:11:05/00:21:17, 0.526s/it]: train_loss_raw=0.3596, running_loss=0.4137, LR=0.000100
[2025-08-11 01:23:48,202][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093576] [Batch 01276/03692] [00:11:11/00:21:11, 0.526s/it]: train_loss_raw=0.3408, running_loss=0.4140, LR=0.000100
[2025-08-11 01:23:54,268][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093588] [Batch 01288/03692] [00:11:17/00:21:04, 0.526s/it]: train_loss_raw=0.4992, running_loss=0.4143, LR=0.000100
[2025-08-11 01:24:00,333][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093600] [Batch 01300/03692] [00:11:23/00:20:57, 0.526s/it]: train_loss_raw=0.3060, running_loss=0.4150, LR=0.000100
[2025-08-11 01:24:06,367][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093612] [Batch 01312/03692] [00:11:29/00:20:50, 0.526s/it]: train_loss_raw=0.4344, running_loss=0.4154, LR=0.000100
[2025-08-11 01:24:12,485][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093624] [Batch 01324/03692] [00:11:35/00:20:44, 0.525s/it]: train_loss_raw=0.4637, running_loss=0.4146, LR=0.000100
[2025-08-11 01:24:18,540][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093636] [Batch 01336/03692] [00:11:41/00:20:37, 0.525s/it]: train_loss_raw=0.4221, running_loss=0.4162, LR=0.000100
[2025-08-11 01:24:24,634][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093648] [Batch 01348/03692] [00:11:47/00:20:30, 0.525s/it]: train_loss_raw=0.5500, running_loss=0.4172, LR=0.000100
[2025-08-11 01:24:30,948][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093660] [Batch 01360/03692] [00:11:54/00:20:24, 0.525s/it]: train_loss_raw=0.3364, running_loss=0.4128, LR=0.000100
[2025-08-11 01:24:36,964][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093672] [Batch 01372/03692] [00:12:00/00:20:17, 0.525s/it]: train_loss_raw=0.4638, running_loss=0.4125, LR=0.000100
[2025-08-11 01:24:43,022][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093684] [Batch 01384/03692] [00:12:06/00:20:10, 0.525s/it]: train_loss_raw=0.4411, running_loss=0.4153, LR=0.000100
[2025-08-11 01:24:49,385][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093696] [Batch 01396/03692] [00:12:12/00:20:04, 0.525s/it]: train_loss_raw=0.3761, running_loss=0.4151, LR=0.000100
[2025-08-11 01:24:55,401][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093708] [Batch 01408/03692] [00:12:18/00:19:58, 0.525s/it]: train_loss_raw=0.4339, running_loss=0.4162, LR=0.000100
[2025-08-11 01:25:01,464][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093720] [Batch 01420/03692] [00:12:24/00:19:51, 0.524s/it]: train_loss_raw=0.3690, running_loss=0.4173, LR=0.000100
[2025-08-11 01:25:07,828][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093732] [Batch 01432/03692] [00:12:30/00:19:45, 0.524s/it]: train_loss_raw=0.3980, running_loss=0.4209, LR=0.000100
[2025-08-11 01:25:14,344][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093744] [Batch 01444/03692] [00:12:37/00:19:39, 0.525s/it]: train_loss_raw=0.3979, running_loss=0.4205, LR=0.000100
[2025-08-11 01:25:20,865][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093756] [Batch 01456/03692] [00:12:44/00:19:33, 0.525s/it]: train_loss_raw=0.4935, running_loss=0.4213, LR=0.000100
[2025-08-11 01:25:27,375][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093768] [Batch 01468/03692] [00:12:50/00:19:27, 0.525s/it]: train_loss_raw=0.3964, running_loss=0.4193, LR=0.000100
[2025-08-11 01:25:33,443][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093780] [Batch 01480/03692] [00:12:56/00:19:20, 0.525s/it]: train_loss_raw=0.3960, running_loss=0.4197, LR=0.000100
[2025-08-11 01:25:39,480][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093792] [Batch 01492/03692] [00:13:02/00:19:14, 0.525s/it]: train_loss_raw=0.4740, running_loss=0.4213, LR=0.000100
[2025-08-11 01:25:45,531][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093804] [Batch 01504/03692] [00:13:08/00:19:07, 0.524s/it]: train_loss_raw=0.4230, running_loss=0.4199, LR=0.000100
[2025-08-11 01:25:51,542][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093816] [Batch 01516/03692] [00:13:14/00:19:00, 0.524s/it]: train_loss_raw=0.4290, running_loss=0.4170, LR=0.000100
[2025-08-11 01:25:57,605][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093828] [Batch 01528/03692] [00:13:20/00:18:54, 0.524s/it]: train_loss_raw=0.3959, running_loss=0.4167, LR=0.000100
[2025-08-11 01:26:03,694][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093840] [Batch 01540/03692] [00:13:26/00:18:47, 0.524s/it]: train_loss_raw=0.4117, running_loss=0.4169, LR=0.000100
[2025-08-11 01:26:09,782][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093852] [Batch 01552/03692] [00:13:32/00:18:40, 0.524s/it]: train_loss_raw=0.4821, running_loss=0.4162, LR=0.000100
[2025-08-11 01:26:15,893][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093864] [Batch 01564/03692] [00:13:39/00:18:34, 0.524s/it]: train_loss_raw=0.4245, running_loss=0.4175, LR=0.000100
[2025-08-11 01:26:21,953][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093876] [Batch 01576/03692] [00:13:45/00:18:27, 0.524s/it]: train_loss_raw=0.3637, running_loss=0.4191, LR=0.000100
[2025-08-11 01:26:27,977][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093888] [Batch 01588/03692] [00:13:51/00:18:21, 0.523s/it]: train_loss_raw=0.4489, running_loss=0.4212, LR=0.000100
[2025-08-11 01:26:34,011][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093900] [Batch 01600/03692] [00:13:57/00:18:14, 0.523s/it]: train_loss_raw=0.3762, running_loss=0.4183, LR=0.000100
[2025-08-11 01:26:40,046][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093912] [Batch 01612/03692] [00:14:03/00:18:07, 0.523s/it]: train_loss_raw=0.4269, running_loss=0.4182, LR=0.000100
[2025-08-11 01:26:46,073][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093924] [Batch 01624/03692] [00:14:09/00:18:01, 0.523s/it]: train_loss_raw=0.4151, running_loss=0.4170, LR=0.000100
[2025-08-11 01:26:52,106][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093936] [Batch 01636/03692] [00:14:15/00:17:54, 0.523s/it]: train_loss_raw=0.4870, running_loss=0.4190, LR=0.000100
[2025-08-11 01:26:58,359][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093948] [Batch 01648/03692] [00:14:21/00:17:48, 0.523s/it]: train_loss_raw=0.3960, running_loss=0.4194, LR=0.000100
[2025-08-11 01:27:04,416][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093960] [Batch 01660/03692] [00:14:27/00:17:41, 0.523s/it]: train_loss_raw=0.4255, running_loss=0.4196, LR=0.000100
[2025-08-11 01:27:10,424][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093972] [Batch 01672/03692] [00:14:33/00:17:35, 0.522s/it]: train_loss_raw=0.3121, running_loss=0.4190, LR=0.000100
[2025-08-11 01:27:16,465][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093984] [Batch 01684/03692] [00:14:39/00:17:28, 0.522s/it]: train_loss_raw=0.4829, running_loss=0.4202, LR=0.000100
[2025-08-11 01:27:22,452][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093996] [Batch 01696/03692] [00:14:45/00:17:22, 0.522s/it]: train_loss_raw=0.4349, running_loss=0.4244, LR=0.000100
[2025-08-11 01:27:32,931][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094008] [Batch 01708/03692] [00:14:56/00:17:20, 0.525s/it]: train_loss_raw=0.4175, running_loss=0.4224, LR=0.000100
[2025-08-11 01:27:38,900][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094020] [Batch 01720/03692] [00:15:02/00:17:14, 0.524s/it]: train_loss_raw=0.4347, running_loss=0.4264, LR=0.000100
[2025-08-11 01:27:44,916][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094032] [Batch 01732/03692] [00:15:08/00:17:07, 0.524s/it]: train_loss_raw=0.4064, running_loss=0.4270, LR=0.000100
[2025-08-11 01:27:50,916][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094044] [Batch 01744/03692] [00:15:14/00:17:00, 0.524s/it]: train_loss_raw=0.5024, running_loss=0.4265, LR=0.000100
[2025-08-11 01:27:57,102][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094056] [Batch 01756/03692] [00:15:20/00:16:54, 0.524s/it]: train_loss_raw=0.3037, running_loss=0.4245, LR=0.000100
[2025-08-11 01:28:03,637][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094068] [Batch 01768/03692] [00:15:26/00:16:48, 0.524s/it]: train_loss_raw=0.5418, running_loss=0.4249, LR=0.000100
[2025-08-11 01:28:10,132][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094080] [Batch 01780/03692] [00:15:33/00:16:42, 0.524s/it]: train_loss_raw=0.3512, running_loss=0.4293, LR=0.000100
[2025-08-11 01:28:16,466][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094092] [Batch 01792/03692] [00:15:39/00:16:36, 0.524s/it]: train_loss_raw=0.3326, running_loss=0.4280, LR=0.000100
[2025-08-11 01:28:22,718][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094104] [Batch 01804/03692] [00:15:45/00:16:29, 0.524s/it]: train_loss_raw=0.4163, running_loss=0.4249, LR=0.000100
[2025-08-11 01:28:29,002][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094116] [Batch 01816/03692] [00:15:52/00:16:23, 0.524s/it]: train_loss_raw=0.4499, running_loss=0.4234, LR=0.000100
[2025-08-11 01:28:35,142][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094128] [Batch 01828/03692] [00:15:58/00:16:17, 0.524s/it]: train_loss_raw=0.3126, running_loss=0.4234, LR=0.000100
[2025-08-11 01:28:41,249][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094140] [Batch 01840/03692] [00:16:04/00:16:10, 0.524s/it]: train_loss_raw=0.4203, running_loss=0.4241, LR=0.000100
[2025-08-11 01:28:47,490][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094152] [Batch 01852/03692] [00:16:10/00:16:04, 0.524s/it]: train_loss_raw=0.3466, running_loss=0.4217, LR=0.000100
[2025-08-11 01:28:53,790][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094164] [Batch 01864/03692] [00:16:16/00:15:58, 0.524s/it]: train_loss_raw=0.3523, running_loss=0.4181, LR=0.000100
[2025-08-11 01:28:59,879][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094176] [Batch 01876/03692] [00:16:23/00:15:51, 0.524s/it]: train_loss_raw=0.4981, running_loss=0.4172, LR=0.000100
[2025-08-11 01:29:05,976][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094188] [Batch 01888/03692] [00:16:29/00:15:45, 0.524s/it]: train_loss_raw=0.3937, running_loss=0.4121, LR=0.000100
[2025-08-11 01:29:12,061][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094200] [Batch 01900/03692] [00:16:35/00:15:38, 0.524s/it]: train_loss_raw=0.4544, running_loss=0.4127, LR=0.000100
[2025-08-11 01:29:18,163][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094212] [Batch 01912/03692] [00:16:41/00:15:32, 0.524s/it]: train_loss_raw=0.3335, running_loss=0.4117, LR=0.000100
[2025-08-11 01:29:24,287][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094224] [Batch 01924/03692] [00:16:47/00:15:25, 0.524s/it]: train_loss_raw=0.3796, running_loss=0.4119, LR=0.000100
[2025-08-11 01:29:30,394][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094236] [Batch 01936/03692] [00:16:53/00:15:19, 0.524s/it]: train_loss_raw=0.3503, running_loss=0.4140, LR=0.000100
[2025-08-11 01:29:36,437][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094248] [Batch 01948/03692] [00:16:59/00:15:12, 0.523s/it]: train_loss_raw=0.4464, running_loss=0.4157, LR=0.000100
[2025-08-11 01:29:42,565][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094260] [Batch 01960/03692] [00:17:05/00:15:06, 0.523s/it]: train_loss_raw=0.3639, running_loss=0.4129, LR=0.000100
[2025-08-11 01:29:48,678][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094272] [Batch 01972/03692] [00:17:11/00:14:59, 0.523s/it]: train_loss_raw=0.3651, running_loss=0.4122, LR=0.000100
[2025-08-11 01:29:54,969][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094284] [Batch 01984/03692] [00:17:18/00:14:53, 0.523s/it]: train_loss_raw=0.4218, running_loss=0.4125, LR=0.000100
[2025-08-11 01:30:01,201][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094296] [Batch 01996/03692] [00:17:24/00:14:47, 0.523s/it]: train_loss_raw=0.4280, running_loss=0.4167, LR=0.000100
[2025-08-11 01:30:07,449][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094308] [Batch 02008/03692] [00:17:30/00:14:41, 0.523s/it]: train_loss_raw=0.4162, running_loss=0.4186, LR=0.000100
[2025-08-11 01:30:13,612][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094320] [Batch 02020/03692] [00:17:36/00:14:34, 0.523s/it]: train_loss_raw=0.3771, running_loss=0.4180, LR=0.000100
[2025-08-11 01:30:19,754][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094332] [Batch 02032/03692] [00:17:42/00:14:28, 0.523s/it]: train_loss_raw=0.4445, running_loss=0.4208, LR=0.000100
[2025-08-11 01:30:26,238][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094344] [Batch 02044/03692] [00:17:49/00:14:22, 0.523s/it]: train_loss_raw=0.3632, running_loss=0.4223, LR=0.000100
[2025-08-11 01:30:32,675][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094356] [Batch 02056/03692] [00:17:55/00:14:16, 0.523s/it]: train_loss_raw=0.5560, running_loss=0.4235, LR=0.000100
[2025-08-11 01:30:39,016][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094368] [Batch 02068/03692] [00:18:02/00:14:09, 0.523s/it]: train_loss_raw=0.5133, running_loss=0.4235, LR=0.000100
[2025-08-11 01:30:45,249][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094380] [Batch 02080/03692] [00:18:08/00:14:03, 0.523s/it]: train_loss_raw=0.5428, running_loss=0.4206, LR=0.000100
[2025-08-11 01:30:51,485][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094392] [Batch 02092/03692] [00:18:14/00:13:57, 0.523s/it]: train_loss_raw=0.4136, running_loss=0.4203, LR=0.000100
[2025-08-11 01:30:57,725][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094404] [Batch 02104/03692] [00:18:20/00:13:50, 0.523s/it]: train_loss_raw=0.4576, running_loss=0.4187, LR=0.000100
[2025-08-11 01:31:03,922][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094416] [Batch 02116/03692] [00:18:27/00:13:44, 0.523s/it]: train_loss_raw=0.3950, running_loss=0.4157, LR=0.000100
[2025-08-11 01:31:10,113][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094428] [Batch 02128/03692] [00:18:33/00:13:38, 0.523s/it]: train_loss_raw=0.4494, running_loss=0.4196, LR=0.000100
[2025-08-11 01:31:16,282][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094440] [Batch 02140/03692] [00:18:39/00:13:31, 0.523s/it]: train_loss_raw=0.5072, running_loss=0.4193, LR=0.000100
[2025-08-11 01:31:22,377][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094452] [Batch 02152/03692] [00:18:45/00:13:25, 0.523s/it]: train_loss_raw=0.4049, running_loss=0.4202, LR=0.000100
[2025-08-11 01:31:35,588][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094464] [Batch 02164/03692] [00:18:58/00:13:24, 0.526s/it]: train_loss_raw=0.4288, running_loss=0.4183, LR=0.000100
[2025-08-11 01:31:41,700][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094476] [Batch 02176/03692] [00:19:04/00:13:17, 0.526s/it]: train_loss_raw=0.3961, running_loss=0.4140, LR=0.000100
[2025-08-11 01:31:47,806][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094488] [Batch 02188/03692] [00:19:10/00:13:11, 0.526s/it]: train_loss_raw=0.4271, running_loss=0.4138, LR=0.000100
[2025-08-11 01:31:53,862][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094500] [Batch 02200/03692] [00:19:17/00:13:04, 0.526s/it]: train_loss_raw=0.4757, running_loss=0.4140, LR=0.000100
[2025-08-11 01:32:00,082][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094512] [Batch 02212/03692] [00:19:23/00:12:58, 0.526s/it]: train_loss_raw=0.4235, running_loss=0.4122, LR=0.000100
[2025-08-11 01:32:06,407][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094524] [Batch 02224/03692] [00:19:29/00:12:51, 0.526s/it]: train_loss_raw=0.3899, running_loss=0.4126, LR=0.000100
[2025-08-11 01:32:12,613][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094536] [Batch 02236/03692] [00:19:35/00:12:45, 0.526s/it]: train_loss_raw=0.4276, running_loss=0.4114, LR=0.000100
[2025-08-11 01:32:18,690][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094548] [Batch 02248/03692] [00:19:41/00:12:39, 0.526s/it]: train_loss_raw=0.3314, running_loss=0.4103, LR=0.000100
[2025-08-11 01:32:24,717][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094560] [Batch 02260/03692] [00:19:47/00:12:32, 0.526s/it]: train_loss_raw=0.3783, running_loss=0.4075, LR=0.000100
[2025-08-11 01:32:30,744][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094572] [Batch 02272/03692] [00:19:53/00:12:26, 0.525s/it]: train_loss_raw=0.5677, running_loss=0.4078, LR=0.000100
[2025-08-11 01:32:36,777][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094584] [Batch 02284/03692] [00:19:59/00:12:19, 0.525s/it]: train_loss_raw=0.3364, running_loss=0.4055, LR=0.000100
[2025-08-11 01:32:42,782][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094596] [Batch 02296/03692] [00:20:05/00:12:13, 0.525s/it]: train_loss_raw=0.4035, running_loss=0.4060, LR=0.000100
[2025-08-11 01:32:48,871][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094608] [Batch 02308/03692] [00:20:12/00:12:06, 0.525s/it]: train_loss_raw=0.4480, running_loss=0.4070, LR=0.000100
[2025-08-11 01:32:55,006][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094620] [Batch 02320/03692] [00:20:18/00:12:00, 0.525s/it]: train_loss_raw=0.3466, running_loss=0.4066, LR=0.000100
[2025-08-11 01:33:01,182][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094632] [Batch 02332/03692] [00:20:24/00:11:54, 0.525s/it]: train_loss_raw=0.4187, running_loss=0.4083, LR=0.000100
[2025-08-11 01:33:07,284][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094644] [Batch 02344/03692] [00:20:30/00:11:47, 0.525s/it]: train_loss_raw=0.3482, running_loss=0.4101, LR=0.000100
[2025-08-11 01:33:13,383][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094656] [Batch 02356/03692] [00:20:36/00:11:41, 0.525s/it]: train_loss_raw=0.3112, running_loss=0.4077, LR=0.000100
[2025-08-11 01:33:19,745][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094668] [Batch 02368/03692] [00:20:42/00:11:34, 0.525s/it]: train_loss_raw=0.3763, running_loss=0.4079, LR=0.000100
[2025-08-11 01:33:26,078][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094680] [Batch 02380/03692] [00:20:49/00:11:28, 0.525s/it]: train_loss_raw=0.4992, running_loss=0.4091, LR=0.000100
[2025-08-11 01:33:32,152][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094692] [Batch 02392/03692] [00:20:55/00:11:22, 0.525s/it]: train_loss_raw=0.4336, running_loss=0.4095, LR=0.000100
[2025-08-11 01:33:38,256][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094704] [Batch 02404/03692] [00:21:01/00:11:15, 0.525s/it]: train_loss_raw=0.5084, running_loss=0.4129, LR=0.000100
[2025-08-11 01:33:44,578][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094716] [Batch 02416/03692] [00:21:07/00:11:09, 0.525s/it]: train_loss_raw=0.4347, running_loss=0.4129, LR=0.000100
[2025-08-11 01:33:50,969][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094728] [Batch 02428/03692] [00:21:14/00:11:03, 0.525s/it]: train_loss_raw=0.3279, running_loss=0.4122, LR=0.000100
[2025-08-11 01:33:57,343][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094740] [Batch 02440/03692] [00:21:20/00:10:57, 0.525s/it]: train_loss_raw=0.3964, running_loss=0.4131, LR=0.000100
[2025-08-11 01:34:03,374][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094752] [Batch 02452/03692] [00:21:26/00:10:50, 0.525s/it]: train_loss_raw=0.4767, running_loss=0.4120, LR=0.000100
[2025-08-11 01:34:09,374][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094764] [Batch 02464/03692] [00:21:32/00:10:44, 0.525s/it]: train_loss_raw=0.4811, running_loss=0.4153, LR=0.000100
[2025-08-11 01:34:15,346][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094776] [Batch 02476/03692] [00:21:38/00:10:37, 0.524s/it]: train_loss_raw=0.4227, running_loss=0.4148, LR=0.000100
[2025-08-11 01:34:21,349][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094788] [Batch 02488/03692] [00:21:44/00:10:31, 0.524s/it]: train_loss_raw=0.3215, running_loss=0.4122, LR=0.000100
[2025-08-11 01:34:27,336][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094800] [Batch 02500/03692] [00:21:50/00:10:24, 0.524s/it]: train_loss_raw=0.3400, running_loss=0.4106, LR=0.000100
[2025-08-11 01:34:33,384][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094812] [Batch 02512/03692] [00:21:56/00:10:18, 0.524s/it]: train_loss_raw=0.3639, running_loss=0.4090, LR=0.000100
[2025-08-11 01:34:39,449][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094824] [Batch 02524/03692] [00:22:02/00:10:12, 0.524s/it]: train_loss_raw=0.3671, running_loss=0.4111, LR=0.000100
[2025-08-11 01:34:45,464][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094836] [Batch 02536/03692] [00:22:08/00:10:05, 0.524s/it]: train_loss_raw=0.4265, running_loss=0.4132, LR=0.000100
[2025-08-11 01:34:51,863][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094848] [Batch 02548/03692] [00:22:15/00:09:59, 0.524s/it]: train_loss_raw=0.4107, running_loss=0.4143, LR=0.000100
[2025-08-11 01:34:57,989][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094860] [Batch 02560/03692] [00:22:21/00:09:53, 0.524s/it]: train_loss_raw=0.4316, running_loss=0.4126, LR=0.000100
[2025-08-11 01:35:04,074][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094872] [Batch 02572/03692] [00:22:27/00:09:46, 0.524s/it]: train_loss_raw=0.3459, running_loss=0.4104, LR=0.000100
[2025-08-11 01:35:10,141][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094884] [Batch 02584/03692] [00:22:33/00:09:40, 0.524s/it]: train_loss_raw=0.3608, running_loss=0.4103, LR=0.000100
[2025-08-11 01:35:16,175][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094896] [Batch 02596/03692] [00:22:39/00:09:33, 0.524s/it]: train_loss_raw=0.3086, running_loss=0.4082, LR=0.000100
[2025-08-11 01:35:22,738][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094908] [Batch 02608/03692] [00:22:45/00:09:27, 0.524s/it]: train_loss_raw=0.4459, running_loss=0.4118, LR=0.000100
[2025-08-11 01:35:29,208][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094920] [Batch 02620/03692] [00:22:52/00:09:21, 0.524s/it]: train_loss_raw=0.4663, running_loss=0.4126, LR=0.000100
[2025-08-11 01:35:35,721][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094932] [Batch 02632/03692] [00:22:58/00:09:15, 0.524s/it]: train_loss_raw=0.3443, running_loss=0.4111, LR=0.000100
[2025-08-11 01:35:42,177][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094944] [Batch 02644/03692] [00:23:05/00:09:09, 0.524s/it]: train_loss_raw=0.3875, running_loss=0.4147, LR=0.000100
[2025-08-11 01:35:48,635][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094956] [Batch 02656/03692] [00:23:11/00:09:02, 0.524s/it]: train_loss_raw=0.4673, running_loss=0.4150, LR=0.000100
[2025-08-11 01:35:55,145][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094968] [Batch 02668/03692] [00:23:18/00:08:56, 0.524s/it]: train_loss_raw=0.4664, running_loss=0.4157, LR=0.000100
[2025-08-11 01:36:01,694][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094980] [Batch 02680/03692] [00:23:24/00:08:50, 0.524s/it]: train_loss_raw=0.4127, running_loss=0.4166, LR=0.000100
[2025-08-11 01:36:08,204][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094992] [Batch 02692/03692] [00:23:31/00:08:44, 0.524s/it]: train_loss_raw=0.3135, running_loss=0.4170, LR=0.000100
[2025-08-11 01:36:14,742][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095004] [Batch 02704/03692] [00:23:37/00:08:38, 0.524s/it]: train_loss_raw=0.3961, running_loss=0.4179, LR=0.000100
[2025-08-11 01:36:21,041][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095016] [Batch 02716/03692] [00:23:44/00:08:31, 0.524s/it]: train_loss_raw=0.4085, running_loss=0.4156, LR=0.000100
[2025-08-11 01:36:27,404][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095028] [Batch 02728/03692] [00:23:50/00:08:25, 0.524s/it]: train_loss_raw=0.3894, running_loss=0.4183, LR=0.000100
[2025-08-11 01:36:33,691][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095040] [Batch 02740/03692] [00:23:56/00:08:19, 0.524s/it]: train_loss_raw=0.3556, running_loss=0.4156, LR=0.000100
[2025-08-11 01:36:40,125][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095052] [Batch 02752/03692] [00:24:03/00:08:12, 0.524s/it]: train_loss_raw=0.4594, running_loss=0.4155, LR=0.000100
[2025-08-11 01:36:46,325][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095064] [Batch 02764/03692] [00:24:09/00:08:06, 0.524s/it]: train_loss_raw=0.4228, running_loss=0.4137, LR=0.000100
[2025-08-11 01:36:52,402][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095076] [Batch 02776/03692] [00:24:15/00:08:00, 0.524s/it]: train_loss_raw=0.5552, running_loss=0.4137, LR=0.000100
[2025-08-11 01:36:58,837][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095088] [Batch 02788/03692] [00:24:21/00:07:54, 0.524s/it]: train_loss_raw=0.4696, running_loss=0.4132, LR=0.000100
[2025-08-11 01:37:05,141][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095100] [Batch 02800/03692] [00:24:28/00:07:47, 0.524s/it]: train_loss_raw=0.3913, running_loss=0.4137, LR=0.000100
[2025-08-11 01:37:11,162][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095112] [Batch 02812/03692] [00:24:34/00:07:41, 0.524s/it]: train_loss_raw=0.2740, running_loss=0.4112, LR=0.000100
[2025-08-11 01:37:17,227][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095124] [Batch 02824/03692] [00:24:40/00:07:35, 0.524s/it]: train_loss_raw=0.4470, running_loss=0.4105, LR=0.000100
[2025-08-11 01:37:23,775][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095136] [Batch 02836/03692] [00:24:46/00:07:28, 0.524s/it]: train_loss_raw=0.3815, running_loss=0.4118, LR=0.000100
[2025-08-11 01:37:30,332][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095148] [Batch 02848/03692] [00:24:53/00:07:22, 0.524s/it]: train_loss_raw=0.4463, running_loss=0.4122, LR=0.000100
[2025-08-11 01:37:36,891][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095160] [Batch 02860/03692] [00:25:00/00:07:16, 0.524s/it]: train_loss_raw=0.4288, running_loss=0.4134, LR=0.000100
[2025-08-11 01:37:43,199][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095172] [Batch 02872/03692] [00:25:06/00:07:10, 0.524s/it]: train_loss_raw=0.3821, running_loss=0.4130, LR=0.000100
[2025-08-11 01:37:49,592][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095184] [Batch 02884/03692] [00:25:12/00:07:03, 0.525s/it]: train_loss_raw=0.3535, running_loss=0.4157, LR=0.000100
[2025-08-11 01:37:56,109][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095196] [Batch 02896/03692] [00:25:19/00:06:57, 0.525s/it]: train_loss_raw=0.4075, running_loss=0.4150, LR=0.000100
[2025-08-11 01:38:02,298][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095208] [Batch 02908/03692] [00:25:25/00:06:51, 0.525s/it]: train_loss_raw=0.4994, running_loss=0.4142, LR=0.000100
[2025-08-11 01:38:08,355][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095220] [Batch 02920/03692] [00:25:31/00:06:44, 0.524s/it]: train_loss_raw=0.5129, running_loss=0.4158, LR=0.000100
[2025-08-11 01:38:14,420][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095232] [Batch 02932/03692] [00:25:37/00:06:38, 0.524s/it]: train_loss_raw=0.4584, running_loss=0.4132, LR=0.000100
[2025-08-11 01:38:20,425][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095244] [Batch 02944/03692] [00:25:43/00:06:32, 0.524s/it]: train_loss_raw=0.3583, running_loss=0.4123, LR=0.000100
[2025-08-11 01:38:26,465][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095256] [Batch 02956/03692] [00:25:49/00:06:25, 0.524s/it]: train_loss_raw=0.4134, running_loss=0.4139, LR=0.000100
[2025-08-11 01:38:32,479][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095268] [Batch 02968/03692] [00:25:55/00:06:19, 0.524s/it]: train_loss_raw=0.3482, running_loss=0.4140, LR=0.000100
[2025-08-11 01:38:38,587][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095280] [Batch 02980/03692] [00:26:01/00:06:13, 0.524s/it]: train_loss_raw=0.4584, running_loss=0.4117, LR=0.000100
[2025-08-11 01:38:44,749][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095292] [Batch 02992/03692] [00:26:07/00:06:06, 0.524s/it]: train_loss_raw=0.3848, running_loss=0.4117, LR=0.000100
[2025-08-11 01:38:50,953][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095304] [Batch 03004/03692] [00:26:14/00:06:00, 0.524s/it]: train_loss_raw=0.4476, running_loss=0.4123, LR=0.000100
[2025-08-11 01:38:57,042][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095316] [Batch 03016/03692] [00:26:20/00:05:54, 0.524s/it]: train_loss_raw=0.3301, running_loss=0.4082, LR=0.000100
[2025-08-11 01:39:03,096][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095328] [Batch 03028/03692] [00:26:26/00:05:47, 0.524s/it]: train_loss_raw=0.3395, running_loss=0.4084, LR=0.000100
[2025-08-11 01:39:09,156][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095340] [Batch 03040/03692] [00:26:32/00:05:41, 0.524s/it]: train_loss_raw=0.3311, running_loss=0.4072, LR=0.000100
[2025-08-11 01:39:15,233][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095352] [Batch 03052/03692] [00:26:38/00:05:35, 0.524s/it]: train_loss_raw=0.4456, running_loss=0.4066, LR=0.000100
[2025-08-11 01:39:21,392][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095364] [Batch 03064/03692] [00:26:44/00:05:28, 0.524s/it]: train_loss_raw=0.3904, running_loss=0.4050, LR=0.000100
[2025-08-11 01:39:27,603][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095376] [Batch 03076/03692] [00:26:50/00:05:22, 0.524s/it]: train_loss_raw=0.4506, running_loss=0.4038, LR=0.000100
[2025-08-11 01:39:33,751][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095388] [Batch 03088/03692] [00:26:56/00:05:16, 0.524s/it]: train_loss_raw=0.4013, running_loss=0.4048, LR=0.000100
[2025-08-11 01:39:39,892][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095400] [Batch 03100/03692] [00:27:03/00:05:09, 0.524s/it]: train_loss_raw=0.4414, running_loss=0.4075, LR=0.000100
[2025-08-11 01:39:46,021][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095412] [Batch 03112/03692] [00:27:09/00:05:03, 0.524s/it]: train_loss_raw=0.3904, running_loss=0.4072, LR=0.000100
[2025-08-11 01:39:52,100][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095424] [Batch 03124/03692] [00:27:15/00:04:57, 0.523s/it]: train_loss_raw=0.4250, running_loss=0.4083, LR=0.000100
[2025-08-11 01:39:58,534][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095436] [Batch 03136/03692] [00:27:21/00:04:51, 0.523s/it]: train_loss_raw=0.4408, running_loss=0.4101, LR=0.000100
[2025-08-11 01:40:04,673][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095448] [Batch 03148/03692] [00:27:27/00:04:44, 0.523s/it]: train_loss_raw=0.3462, running_loss=0.4092, LR=0.000100
[2025-08-11 01:40:10,744][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095460] [Batch 03160/03692] [00:27:33/00:04:38, 0.523s/it]: train_loss_raw=0.4797, running_loss=0.4104, LR=0.000100
[2025-08-11 01:40:16,794][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095472] [Batch 03172/03692] [00:27:39/00:04:32, 0.523s/it]: train_loss_raw=0.3656, running_loss=0.4092, LR=0.000100
[2025-08-11 01:40:22,978][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095484] [Batch 03184/03692] [00:27:46/00:04:25, 0.523s/it]: train_loss_raw=0.4254, running_loss=0.4118, LR=0.000100
[2025-08-11 01:40:29,249][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095496] [Batch 03196/03692] [00:27:52/00:04:19, 0.523s/it]: train_loss_raw=0.4142, running_loss=0.4108, LR=0.000100
[2025-08-11 01:40:35,475][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095508] [Batch 03208/03692] [00:27:58/00:04:13, 0.523s/it]: train_loss_raw=0.5320, running_loss=0.4126, LR=0.000100
[2025-08-11 01:40:41,766][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095520] [Batch 03220/03692] [00:28:04/00:04:06, 0.523s/it]: train_loss_raw=0.4137, running_loss=0.4129, LR=0.000100
[2025-08-11 01:40:47,886][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095532] [Batch 03232/03692] [00:28:11/00:04:00, 0.523s/it]: train_loss_raw=0.4494, running_loss=0.4158, LR=0.000100
[2025-08-11 01:40:53,993][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095544] [Batch 03244/03692] [00:28:17/00:03:54, 0.523s/it]: train_loss_raw=0.3049, running_loss=0.4124, LR=0.000100
[2025-08-11 01:41:00,089][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095556] [Batch 03256/03692] [00:28:23/00:03:48, 0.523s/it]: train_loss_raw=0.5029, running_loss=0.4156, LR=0.000100
[2025-08-11 01:41:06,151][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095568] [Batch 03268/03692] [00:28:29/00:03:41, 0.523s/it]: train_loss_raw=0.3804, running_loss=0.4131, LR=0.000100
[2025-08-11 01:41:12,276][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095580] [Batch 03280/03692] [00:28:35/00:03:35, 0.523s/it]: train_loss_raw=0.2970, running_loss=0.4114, LR=0.000100
[2025-08-11 01:41:18,416][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095592] [Batch 03292/03692] [00:28:41/00:03:29, 0.523s/it]: train_loss_raw=0.3331, running_loss=0.4100, LR=0.000100
[2025-08-11 01:41:24,477][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095604] [Batch 03304/03692] [00:28:47/00:03:22, 0.523s/it]: train_loss_raw=0.3747, running_loss=0.4080, LR=0.000100
[2025-08-11 01:41:30,591][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095616] [Batch 03316/03692] [00:28:53/00:03:16, 0.523s/it]: train_loss_raw=0.4393, running_loss=0.4095, LR=0.000100
[2025-08-11 01:41:36,627][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095628] [Batch 03328/03692] [00:28:59/00:03:10, 0.523s/it]: train_loss_raw=0.3707, running_loss=0.4083, LR=0.000100
[2025-08-11 01:41:42,673][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095640] [Batch 03340/03692] [00:29:05/00:03:03, 0.523s/it]: train_loss_raw=0.4107, running_loss=0.4093, LR=0.000100
[2025-08-11 01:41:48,778][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095652] [Batch 03352/03692] [00:29:11/00:02:57, 0.523s/it]: train_loss_raw=0.4595, running_loss=0.4133, LR=0.000100
[2025-08-11 01:41:54,958][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095664] [Batch 03364/03692] [00:29:18/00:02:51, 0.523s/it]: train_loss_raw=0.3820, running_loss=0.4146, LR=0.000100
[2025-08-11 01:42:00,990][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095676] [Batch 03376/03692] [00:29:24/00:02:45, 0.523s/it]: train_loss_raw=0.3816, running_loss=0.4117, LR=0.000100
[2025-08-11 01:42:07,113][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095688] [Batch 03388/03692] [00:29:30/00:02:38, 0.523s/it]: train_loss_raw=0.4205, running_loss=0.4132, LR=0.000100
[2025-08-11 01:42:13,177][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095700] [Batch 03400/03692] [00:29:36/00:02:32, 0.522s/it]: train_loss_raw=0.3453, running_loss=0.4130, LR=0.000100
[2025-08-11 01:42:19,157][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095712] [Batch 03412/03692] [00:29:42/00:02:26, 0.522s/it]: train_loss_raw=0.3663, running_loss=0.4177, LR=0.000100
[2025-08-11 01:42:25,274][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095724] [Batch 03424/03692] [00:29:48/00:02:19, 0.522s/it]: train_loss_raw=0.5630, running_loss=0.4174, LR=0.000100
[2025-08-11 01:42:31,496][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095736] [Batch 03436/03692] [00:29:54/00:02:13, 0.522s/it]: train_loss_raw=0.3822, running_loss=0.4142, LR=0.000100
[2025-08-11 01:42:37,565][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095748] [Batch 03448/03692] [00:30:00/00:02:07, 0.522s/it]: train_loss_raw=0.4221, running_loss=0.4167, LR=0.000100
[2025-08-11 01:42:43,606][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095760] [Batch 03460/03692] [00:30:06/00:02:01, 0.522s/it]: train_loss_raw=0.4633, running_loss=0.4170, LR=0.000100
[2025-08-11 01:42:49,645][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095772] [Batch 03472/03692] [00:30:12/00:01:54, 0.522s/it]: train_loss_raw=0.3597, running_loss=0.4159, LR=0.000100
[2025-08-11 01:42:56,107][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095784] [Batch 03484/03692] [00:30:19/00:01:48, 0.522s/it]: train_loss_raw=0.3923, running_loss=0.4159, LR=0.000100
[2025-08-11 01:43:02,581][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095796] [Batch 03496/03692] [00:30:25/00:01:42, 0.522s/it]: train_loss_raw=0.4789, running_loss=0.4160, LR=0.000100
[2025-08-11 01:43:08,989][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095808] [Batch 03508/03692] [00:30:32/00:01:36, 0.522s/it]: train_loss_raw=0.3616, running_loss=0.4165, LR=0.000100
[2025-08-11 01:43:15,544][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095820] [Batch 03520/03692] [00:30:38/00:01:29, 0.522s/it]: train_loss_raw=0.3573, running_loss=0.4138, LR=0.000100
[2025-08-11 01:43:21,742][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095832] [Batch 03532/03692] [00:30:44/00:01:23, 0.522s/it]: train_loss_raw=0.3309, running_loss=0.4113, LR=0.000100
[2025-08-11 01:43:27,737][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095844] [Batch 03544/03692] [00:30:50/00:01:17, 0.522s/it]: train_loss_raw=0.4260, running_loss=0.4111, LR=0.000100
[2025-08-11 01:43:33,758][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095856] [Batch 03556/03692] [00:30:56/00:01:11, 0.522s/it]: train_loss_raw=0.4940, running_loss=0.4122, LR=0.000100
[2025-08-11 01:43:40,050][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095868] [Batch 03568/03692] [00:31:03/00:01:04, 0.522s/it]: train_loss_raw=0.5094, running_loss=0.4128, LR=0.000100
[2025-08-11 01:43:46,155][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095880] [Batch 03580/03692] [00:31:09/00:00:58, 0.522s/it]: train_loss_raw=0.4181, running_loss=0.4152, LR=0.000100
[2025-08-11 01:43:52,195][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095892] [Batch 03592/03692] [00:31:15/00:00:52, 0.522s/it]: train_loss_raw=0.5956, running_loss=0.4173, LR=0.000100
[2025-08-11 01:43:58,405][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095904] [Batch 03604/03692] [00:31:21/00:00:45, 0.522s/it]: train_loss_raw=0.4444, running_loss=0.4191, LR=0.000100
[2025-08-11 01:44:04,564][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095916] [Batch 03616/03692] [00:31:27/00:00:39, 0.522s/it]: train_loss_raw=0.4122, running_loss=0.4168, LR=0.000100
[2025-08-11 01:44:10,629][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095928] [Batch 03628/03692] [00:31:33/00:00:33, 0.522s/it]: train_loss_raw=0.3850, running_loss=0.4169, LR=0.000100
[2025-08-11 01:44:16,672][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095940] [Batch 03640/03692] [00:31:39/00:00:27, 0.522s/it]: train_loss_raw=0.3865, running_loss=0.4169, LR=0.000100
[2025-08-11 01:44:22,766][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095952] [Batch 03652/03692] [00:31:45/00:00:20, 0.522s/it]: train_loss_raw=0.3141, running_loss=0.4159, LR=0.000100
[2025-08-11 01:44:29,038][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095964] [Batch 03664/03692] [00:31:52/00:00:14, 0.522s/it]: train_loss_raw=0.3608, running_loss=0.4184, LR=0.000100
[2025-08-11 01:44:35,584][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095976] [Batch 03676/03692] [00:31:58/00:00:08, 0.522s/it]: train_loss_raw=0.4877, running_loss=0.4163, LR=0.000100
[2025-08-11 01:44:41,755][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095988] [Batch 03688/03692] [00:32:04/00:00:02, 0.522s/it]: train_loss_raw=0.3272, running_loss=0.4164, LR=0.000100
[2025-08-11 01:45:13,745][__main__][INFO] - [VALIDATION] [Epoch 25/29] Starting validation.
[2025-08-11 01:45:47,945][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 095993] [Batch 00011/00025] [00:00:34/00:00:37, 2.850s/it]
[2025-08-11 01:46:03,333][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 095993] [Batch 00023/00025] [00:00:49/00:00:02, 2.066s/it]
[2025-08-11 01:46:04,278][__main__][INFO] - [VALIDATION] [Epoch 25/29] train_loss=0.41519, valid_loss=0.54735
[2025-08-11 01:46:04,278][__main__][INFO] - [VALIDATION] [Epoch 25/29] Metrics:
[2025-08-11 01:46:04,278][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_er      0.221
[2025-08-11 01:46:04,278][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_prec    0.581
[2025-08-11 01:46:04,278][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_recall  0.585
[2025-08-11 01:46:04,279][__main__][INFO] - [VALIDATION] [Epoch 25/29] - pep_recall 0.577
[2025-08-11 01:46:04,281][__main__][INFO] - [TRAIN] [Epoch 25/29] Epoch complete, total time 14:50:03, remaining time 02:16:55, 00:34:13 per epoch
[2025-08-11 01:46:08,342][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096000] [Batch 00008/03692] [00:00:03/00:29:32, 0.481s/it]: train_loss_raw=0.5216, running_loss=0.4743, LR=0.000100
[2025-08-11 01:46:19,241][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096012] [Batch 00020/03692] [00:00:14/00:45:07, 0.737s/it]: train_loss_raw=0.3068, running_loss=0.4644, LR=0.000100
[2025-08-11 01:46:25,575][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096024] [Batch 00032/03692] [00:00:21/00:40:11, 0.659s/it]: train_loss_raw=0.3438, running_loss=0.4546, LR=0.000100
[2025-08-11 01:46:31,953][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096036] [Batch 00044/03692] [00:00:27/00:37:56, 0.624s/it]: train_loss_raw=0.3704, running_loss=0.4435, LR=0.000100
[2025-08-11 01:46:38,396][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096048] [Batch 00056/03692] [00:00:33/00:36:41, 0.605s/it]: train_loss_raw=0.3942, running_loss=0.4377, LR=0.000100
[2025-08-11 01:46:44,879][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096060] [Batch 00068/03692] [00:00:40/00:35:52, 0.594s/it]: train_loss_raw=0.3800, running_loss=0.4288, LR=0.000100
[2025-08-11 01:46:51,353][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096072] [Batch 00080/03692] [00:00:46/00:35:15, 0.586s/it]: train_loss_raw=0.3719, running_loss=0.4212, LR=0.000100
[2025-08-11 01:46:57,766][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096084] [Batch 00092/03692] [00:00:53/00:34:44, 0.579s/it]: train_loss_raw=0.2978, running_loss=0.4138, LR=0.000100
[2025-08-11 01:47:04,129][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096096] [Batch 00104/03692] [00:00:59/00:34:17, 0.573s/it]: train_loss_raw=0.3770, running_loss=0.4094, LR=0.000100
[2025-08-11 01:47:10,604][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096108] [Batch 00116/03692] [00:01:06/00:33:58, 0.570s/it]: train_loss_raw=0.3915, running_loss=0.4064, LR=0.000100
[2025-08-11 01:47:16,943][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096120] [Batch 00128/03692] [00:01:12/00:33:37, 0.566s/it]: train_loss_raw=0.3568, running_loss=0.4043, LR=0.000100
[2025-08-11 01:47:23,266][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096132] [Batch 00140/03692] [00:01:18/00:33:18, 0.563s/it]: train_loss_raw=0.3305, running_loss=0.3998, LR=0.000100
[2025-08-11 01:47:29,779][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096144] [Batch 00152/03692] [00:01:25/00:33:06, 0.561s/it]: train_loss_raw=0.4500, running_loss=0.3981, LR=0.000100
[2025-08-11 01:47:36,273][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096156] [Batch 00164/03692] [00:01:31/00:32:54, 0.560s/it]: train_loss_raw=0.3275, running_loss=0.3947, LR=0.000100
[2025-08-11 01:47:42,780][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096168] [Batch 00176/03692] [00:01:38/00:32:43, 0.558s/it]: train_loss_raw=0.3162, running_loss=0.3920, LR=0.000100
[2025-08-11 01:47:49,182][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096180] [Batch 00188/03692] [00:01:44/00:32:31, 0.557s/it]: train_loss_raw=0.2971, running_loss=0.3901, LR=0.000100
[2025-08-11 01:47:55,523][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096192] [Batch 00200/03692] [00:01:51/00:32:18, 0.555s/it]: train_loss_raw=0.3106, running_loss=0.3869, LR=0.000100
[2025-08-11 01:48:01,889][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096204] [Batch 00212/03692] [00:01:57/00:32:07, 0.554s/it]: train_loss_raw=0.4161, running_loss=0.3873, LR=0.000100
[2025-08-11 01:48:08,251][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096216] [Batch 00224/03692] [00:02:03/00:31:56, 0.552s/it]: train_loss_raw=0.3918, running_loss=0.3861, LR=0.000100
[2025-08-11 01:48:14,607][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096228] [Batch 00236/03692] [00:02:10/00:31:45, 0.551s/it]: train_loss_raw=0.2987, running_loss=0.3830, LR=0.000100
[2025-08-11 01:48:20,988][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096240] [Batch 00248/03692] [00:02:16/00:31:35, 0.550s/it]: train_loss_raw=0.5787, running_loss=0.3863, LR=0.000100
[2025-08-11 01:48:27,374][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096252] [Batch 00260/03692] [00:02:22/00:31:26, 0.550s/it]: train_loss_raw=0.3724, running_loss=0.3871, LR=0.000100
[2025-08-11 01:48:33,788][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096264] [Batch 00272/03692] [00:02:29/00:31:17, 0.549s/it]: train_loss_raw=0.3907, running_loss=0.3868, LR=0.000100
[2025-08-11 01:48:40,169][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096276] [Batch 00284/03692] [00:02:35/00:31:08, 0.548s/it]: train_loss_raw=0.3930, running_loss=0.3863, LR=0.000100
[2025-08-11 01:48:46,565][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096288] [Batch 00296/03692] [00:02:42/00:30:59, 0.548s/it]: train_loss_raw=0.3119, running_loss=0.3864, LR=0.000100
[2025-08-11 01:48:52,962][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096300] [Batch 00308/03692] [00:02:48/00:30:50, 0.547s/it]: train_loss_raw=0.3793, running_loss=0.3884, LR=0.000100
[2025-08-11 01:48:59,406][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096312] [Batch 00320/03692] [00:02:54/00:30:43, 0.547s/it]: train_loss_raw=0.4545, running_loss=0.3902, LR=0.000100
[2025-08-11 01:49:05,837][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096324] [Batch 00332/03692] [00:03:01/00:30:35, 0.546s/it]: train_loss_raw=0.4875, running_loss=0.3918, LR=0.000100
[2025-08-11 01:49:12,193][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096336] [Batch 00344/03692] [00:03:07/00:30:26, 0.546s/it]: train_loss_raw=0.3891, running_loss=0.3911, LR=0.000100
[2025-08-11 01:49:18,614][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096348] [Batch 00356/03692] [00:03:14/00:30:19, 0.545s/it]: train_loss_raw=0.3365, running_loss=0.3908, LR=0.000100
[2025-08-11 01:49:25,025][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096360] [Batch 00368/03692] [00:03:20/00:30:11, 0.545s/it]: train_loss_raw=0.4524, running_loss=0.3918, LR=0.000100
[2025-08-11 01:49:31,380][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096372] [Batch 00380/03692] [00:03:26/00:30:03, 0.544s/it]: train_loss_raw=0.3573, running_loss=0.3880, LR=0.000100
[2025-08-11 01:49:37,780][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096384] [Batch 00392/03692] [00:03:33/00:29:55, 0.544s/it]: train_loss_raw=0.4147, running_loss=0.3882, LR=0.000100
[2025-08-11 01:49:44,261][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096396] [Batch 00404/03692] [00:03:39/00:29:48, 0.544s/it]: train_loss_raw=0.3504, running_loss=0.3877, LR=0.000100
[2025-08-11 01:49:50,727][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096408] [Batch 00416/03692] [00:03:46/00:29:41, 0.544s/it]: train_loss_raw=0.4743, running_loss=0.3865, LR=0.000100
[2025-08-11 01:49:57,089][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096420] [Batch 00428/03692] [00:03:52/00:29:33, 0.543s/it]: train_loss_raw=0.3627, running_loss=0.3848, LR=0.000100
[2025-08-11 01:50:03,591][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096432] [Batch 00440/03692] [00:03:59/00:29:27, 0.543s/it]: train_loss_raw=0.3566, running_loss=0.3879, LR=0.000100
[2025-08-11 01:50:10,121][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096444] [Batch 00452/03692] [00:04:05/00:29:20, 0.543s/it]: train_loss_raw=0.3137, running_loss=0.3884, LR=0.000100
[2025-08-11 01:50:16,520][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096456] [Batch 00464/03692] [00:04:12/00:29:13, 0.543s/it]: train_loss_raw=0.4157, running_loss=0.3875, LR=0.000100
[2025-08-11 01:50:22,860][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096468] [Batch 00476/03692] [00:04:18/00:29:05, 0.543s/it]: train_loss_raw=0.3479, running_loss=0.3888, LR=0.000100
[2025-08-11 01:50:29,355][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096480] [Batch 00488/03692] [00:04:24/00:28:58, 0.543s/it]: train_loss_raw=0.3529, running_loss=0.3888, LR=0.000100
[2025-08-11 01:50:35,718][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096492] [Batch 00500/03692] [00:04:31/00:28:51, 0.542s/it]: train_loss_raw=0.5214, running_loss=0.3898, LR=0.000100
[2025-08-11 01:50:42,108][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096504] [Batch 00512/03692] [00:04:37/00:28:44, 0.542s/it]: train_loss_raw=0.3735, running_loss=0.3884, LR=0.000100
[2025-08-11 01:50:48,589][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096516] [Batch 00524/03692] [00:04:44/00:28:37, 0.542s/it]: train_loss_raw=0.4229, running_loss=0.3869, LR=0.000100
[2025-08-11 01:50:54,918][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096528] [Batch 00536/03692] [00:04:50/00:28:30, 0.542s/it]: train_loss_raw=0.2857, running_loss=0.3835, LR=0.000100
[2025-08-11 01:51:01,387][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096540] [Batch 00548/03692] [00:04:56/00:28:23, 0.542s/it]: train_loss_raw=0.3793, running_loss=0.3845, LR=0.000100
[2025-08-11 01:51:07,808][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096552] [Batch 00560/03692] [00:05:03/00:28:16, 0.542s/it]: train_loss_raw=0.3503, running_loss=0.3813, LR=0.000100
[2025-08-11 01:51:14,202][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096564] [Batch 00572/03692] [00:05:09/00:28:09, 0.541s/it]: train_loss_raw=0.3806, running_loss=0.3843, LR=0.000100
[2025-08-11 01:51:20,576][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096576] [Batch 00584/03692] [00:05:16/00:28:02, 0.541s/it]: train_loss_raw=0.3218, running_loss=0.3834, LR=0.000100
[2025-08-11 01:51:26,909][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096588] [Batch 00596/03692] [00:05:22/00:27:54, 0.541s/it]: train_loss_raw=0.3329, running_loss=0.3810, LR=0.000100
[2025-08-11 01:51:33,492][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096600] [Batch 00608/03692] [00:05:28/00:27:48, 0.541s/it]: train_loss_raw=0.3860, running_loss=0.3786, LR=0.000100
[2025-08-11 01:51:39,894][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096612] [Batch 00620/03692] [00:05:35/00:27:41, 0.541s/it]: train_loss_raw=0.4096, running_loss=0.3826, LR=0.000100
[2025-08-11 01:51:46,217][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096624] [Batch 00632/03692] [00:05:41/00:27:34, 0.541s/it]: train_loss_raw=0.3167, running_loss=0.3805, LR=0.000100
[2025-08-11 01:51:52,627][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096636] [Batch 00644/03692] [00:05:48/00:27:27, 0.541s/it]: train_loss_raw=0.4360, running_loss=0.3795, LR=0.000100
[2025-08-11 01:51:59,041][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096648] [Batch 00656/03692] [00:05:54/00:27:20, 0.540s/it]: train_loss_raw=0.4222, running_loss=0.3798, LR=0.000100
[2025-08-11 01:52:05,465][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096660] [Batch 00668/03692] [00:06:00/00:27:14, 0.540s/it]: train_loss_raw=0.4158, running_loss=0.3803, LR=0.000100
[2025-08-11 01:52:11,809][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096672] [Batch 00680/03692] [00:06:07/00:27:06, 0.540s/it]: train_loss_raw=0.2978, running_loss=0.3787, LR=0.000100
[2025-08-11 01:52:18,138][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096684] [Batch 00692/03692] [00:06:13/00:26:59, 0.540s/it]: train_loss_raw=0.3915, running_loss=0.3786, LR=0.000100
[2025-08-11 01:52:24,508][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096696] [Batch 00704/03692] [00:06:20/00:26:52, 0.540s/it]: train_loss_raw=0.4724, running_loss=0.3799, LR=0.000100
[2025-08-11 01:52:30,896][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096708] [Batch 00716/03692] [00:06:26/00:26:46, 0.540s/it]: train_loss_raw=0.3485, running_loss=0.3812, LR=0.000100
[2025-08-11 01:52:37,283][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096720] [Batch 00728/03692] [00:06:32/00:26:39, 0.540s/it]: train_loss_raw=0.2883, running_loss=0.3812, LR=0.000100
[2025-08-11 01:52:43,681][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096732] [Batch 00740/03692] [00:06:39/00:26:32, 0.539s/it]: train_loss_raw=0.4476, running_loss=0.3858, LR=0.000100
[2025-08-11 01:52:50,050][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096744] [Batch 00752/03692] [00:06:45/00:26:25, 0.539s/it]: train_loss_raw=0.4544, running_loss=0.3854, LR=0.000100
[2025-08-11 01:52:56,429][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096756] [Batch 00764/03692] [00:06:51/00:26:18, 0.539s/it]: train_loss_raw=0.4091, running_loss=0.3847, LR=0.000100
[2025-08-11 01:53:02,789][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096768] [Batch 00776/03692] [00:06:58/00:26:11, 0.539s/it]: train_loss_raw=0.3534, running_loss=0.3832, LR=0.000100
[2025-08-11 01:53:09,123][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096780] [Batch 00788/03692] [00:07:04/00:26:04, 0.539s/it]: train_loss_raw=0.3916, running_loss=0.3835, LR=0.000100
[2025-08-11 01:53:15,508][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096792] [Batch 00800/03692] [00:07:11/00:25:58, 0.539s/it]: train_loss_raw=0.3670, running_loss=0.3842, LR=0.000100
[2025-08-11 01:53:21,905][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096804] [Batch 00812/03692] [00:07:17/00:25:51, 0.539s/it]: train_loss_raw=0.4346, running_loss=0.3829, LR=0.000100
[2025-08-11 01:53:28,284][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096816] [Batch 00824/03692] [00:07:23/00:25:44, 0.539s/it]: train_loss_raw=0.3798, running_loss=0.3845, LR=0.000100
[2025-08-11 01:53:34,645][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096828] [Batch 00836/03692] [00:07:30/00:25:37, 0.538s/it]: train_loss_raw=0.3609, running_loss=0.3850, LR=0.000100
[2025-08-11 01:53:41,057][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096840] [Batch 00848/03692] [00:07:36/00:25:31, 0.538s/it]: train_loss_raw=0.4687, running_loss=0.3843, LR=0.000100
[2025-08-11 01:53:47,408][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096852] [Batch 00860/03692] [00:07:42/00:25:24, 0.538s/it]: train_loss_raw=0.3126, running_loss=0.3816, LR=0.000100
[2025-08-11 01:53:53,913][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096864] [Batch 00872/03692] [00:07:49/00:25:18, 0.538s/it]: train_loss_raw=0.4604, running_loss=0.3840, LR=0.000100
[2025-08-11 01:54:00,289][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096876] [Batch 00884/03692] [00:07:55/00:25:11, 0.538s/it]: train_loss_raw=0.3666, running_loss=0.3828, LR=0.000100
[2025-08-11 01:54:06,671][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096888] [Batch 00896/03692] [00:08:02/00:25:04, 0.538s/it]: train_loss_raw=0.4314, running_loss=0.3852, LR=0.000100
[2025-08-11 01:54:13,173][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096900] [Batch 00908/03692] [00:08:08/00:24:58, 0.538s/it]: train_loss_raw=0.3481, running_loss=0.3821, LR=0.000100
[2025-08-11 01:54:19,578][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096912] [Batch 00920/03692] [00:08:15/00:24:51, 0.538s/it]: train_loss_raw=0.5104, running_loss=0.3834, LR=0.000100
[2025-08-11 01:54:25,972][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096924] [Batch 00932/03692] [00:08:21/00:24:45, 0.538s/it]: train_loss_raw=0.4077, running_loss=0.3851, LR=0.000100
[2025-08-11 01:54:32,342][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096936] [Batch 00944/03692] [00:08:27/00:24:38, 0.538s/it]: train_loss_raw=0.3766, running_loss=0.3873, LR=0.000100
[2025-08-11 01:54:38,791][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096948] [Batch 00956/03692] [00:08:34/00:24:31, 0.538s/it]: train_loss_raw=0.3358, running_loss=0.3842, LR=0.000100
[2025-08-11 01:54:45,191][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096960] [Batch 00968/03692] [00:08:40/00:24:25, 0.538s/it]: train_loss_raw=0.4162, running_loss=0.3863, LR=0.000100
[2025-08-11 01:54:51,757][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096972] [Batch 00980/03692] [00:08:47/00:24:19, 0.538s/it]: train_loss_raw=0.4705, running_loss=0.3881, LR=0.000100
[2025-08-11 01:54:58,209][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096984] [Batch 00992/03692] [00:08:53/00:24:12, 0.538s/it]: train_loss_raw=0.4082, running_loss=0.3902, LR=0.000100
[2025-08-11 01:55:04,672][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096996] [Batch 01004/03692] [00:09:00/00:24:06, 0.538s/it]: train_loss_raw=0.5206, running_loss=0.3917, LR=0.000100
[2025-08-11 01:55:11,168][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097008] [Batch 01016/03692] [00:09:06/00:23:59, 0.538s/it]: train_loss_raw=0.4575, running_loss=0.3930, LR=0.000100
[2025-08-11 01:55:17,692][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097020] [Batch 01028/03692] [00:09:13/00:23:53, 0.538s/it]: train_loss_raw=0.4440, running_loss=0.3931, LR=0.000100
[2025-08-11 01:55:24,074][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097032] [Batch 01040/03692] [00:09:19/00:23:46, 0.538s/it]: train_loss_raw=0.2953, running_loss=0.3924, LR=0.000100
[2025-08-11 01:55:30,441][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097044] [Batch 01052/03692] [00:09:25/00:23:40, 0.538s/it]: train_loss_raw=0.4186, running_loss=0.3949, LR=0.000100
[2025-08-11 01:55:36,868][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097056] [Batch 01064/03692] [00:09:32/00:23:33, 0.538s/it]: train_loss_raw=0.3894, running_loss=0.3912, LR=0.000100
[2025-08-11 01:55:43,214][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097068] [Batch 01076/03692] [00:09:38/00:23:27, 0.538s/it]: train_loss_raw=0.4194, running_loss=0.3922, LR=0.000100
[2025-08-11 01:55:49,633][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097080] [Batch 01088/03692] [00:09:45/00:23:20, 0.538s/it]: train_loss_raw=0.3044, running_loss=0.3919, LR=0.000100
[2025-08-11 01:55:56,044][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097092] [Batch 01100/03692] [00:09:51/00:23:13, 0.538s/it]: train_loss_raw=0.3742, running_loss=0.3945, LR=0.000100
[2025-08-11 01:56:02,352][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097104] [Batch 01112/03692] [00:09:57/00:23:07, 0.538s/it]: train_loss_raw=0.2610, running_loss=0.3922, LR=0.000100
[2025-08-11 01:56:08,749][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097116] [Batch 01124/03692] [00:10:04/00:23:00, 0.538s/it]: train_loss_raw=0.3983, running_loss=0.3917, LR=0.000100
[2025-08-11 01:56:15,194][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097128] [Batch 01136/03692] [00:10:10/00:22:54, 0.538s/it]: train_loss_raw=0.4017, running_loss=0.3900, LR=0.000100
[2025-08-11 01:56:21,567][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097140] [Batch 01148/03692] [00:10:17/00:22:47, 0.538s/it]: train_loss_raw=0.3894, running_loss=0.3936, LR=0.000100
[2025-08-11 01:56:27,918][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097152] [Batch 01160/03692] [00:10:23/00:22:40, 0.537s/it]: train_loss_raw=0.3764, running_loss=0.3936, LR=0.000100
[2025-08-11 01:56:34,323][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097164] [Batch 01172/03692] [00:10:29/00:22:34, 0.537s/it]: train_loss_raw=0.3905, running_loss=0.3925, LR=0.000100
[2025-08-11 01:56:40,657][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097176] [Batch 01184/03692] [00:10:36/00:22:27, 0.537s/it]: train_loss_raw=0.3443, running_loss=0.3908, LR=0.000100
[2025-08-11 01:56:47,010][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097188] [Batch 01196/03692] [00:10:42/00:22:20, 0.537s/it]: train_loss_raw=0.4593, running_loss=0.3934, LR=0.000100
[2025-08-11 01:56:53,385][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097200] [Batch 01208/03692] [00:10:48/00:22:14, 0.537s/it]: train_loss_raw=0.3180, running_loss=0.3913, LR=0.000100
[2025-08-11 01:56:59,844][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097212] [Batch 01220/03692] [00:10:55/00:22:07, 0.537s/it]: train_loss_raw=0.2939, running_loss=0.3889, LR=0.000100
[2025-08-11 01:57:06,445][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097224] [Batch 01232/03692] [00:11:01/00:22:01, 0.537s/it]: train_loss_raw=0.4237, running_loss=0.3868, LR=0.000100
[2025-08-11 01:57:12,827][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097236] [Batch 01244/03692] [00:11:08/00:21:55, 0.537s/it]: train_loss_raw=0.4461, running_loss=0.3840, LR=0.000100
[2025-08-11 01:57:19,195][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097248] [Batch 01256/03692] [00:11:14/00:21:48, 0.537s/it]: train_loss_raw=0.4188, running_loss=0.3832, LR=0.000100
[2025-08-11 01:57:25,701][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097260] [Batch 01268/03692] [00:11:21/00:21:42, 0.537s/it]: train_loss_raw=0.2681, running_loss=0.3824, LR=0.000100
[2025-08-11 01:57:32,181][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097272] [Batch 01280/03692] [00:11:27/00:21:35, 0.537s/it]: train_loss_raw=0.4585, running_loss=0.3884, LR=0.000100
[2025-08-11 01:57:38,558][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097284] [Batch 01292/03692] [00:11:34/00:21:29, 0.537s/it]: train_loss_raw=0.3663, running_loss=0.3865, LR=0.000100
[2025-08-11 01:57:44,909][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097296] [Batch 01304/03692] [00:11:40/00:21:22, 0.537s/it]: train_loss_raw=0.4745, running_loss=0.3891, LR=0.000100
[2025-08-11 01:57:51,330][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097308] [Batch 01316/03692] [00:11:46/00:21:16, 0.537s/it]: train_loss_raw=0.3833, running_loss=0.3878, LR=0.000100
[2025-08-11 01:57:57,727][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097320] [Batch 01328/03692] [00:11:53/00:21:09, 0.537s/it]: train_loss_raw=0.3249, running_loss=0.3838, LR=0.000100
[2025-08-11 01:58:04,124][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097332] [Batch 01340/03692] [00:11:59/00:21:03, 0.537s/it]: train_loss_raw=0.4088, running_loss=0.3843, LR=0.000100
[2025-08-11 01:58:10,591][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097344] [Batch 01352/03692] [00:12:06/00:20:56, 0.537s/it]: train_loss_raw=0.4449, running_loss=0.3838, LR=0.000100
[2025-08-11 01:58:16,981][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097356] [Batch 01364/03692] [00:12:12/00:20:50, 0.537s/it]: train_loss_raw=0.4576, running_loss=0.3866, LR=0.000100
[2025-08-11 01:58:23,333][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097368] [Batch 01376/03692] [00:12:18/00:20:43, 0.537s/it]: train_loss_raw=0.4399, running_loss=0.3864, LR=0.000100
[2025-08-11 01:58:29,755][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097380] [Batch 01388/03692] [00:12:25/00:20:37, 0.537s/it]: train_loss_raw=0.3449, running_loss=0.3866, LR=0.000100
[2025-08-11 01:58:36,101][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097392] [Batch 01400/03692] [00:12:31/00:20:30, 0.537s/it]: train_loss_raw=0.3794, running_loss=0.3824, LR=0.000100
[2025-08-11 01:58:42,577][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097404] [Batch 01412/03692] [00:12:38/00:20:24, 0.537s/it]: train_loss_raw=0.4312, running_loss=0.3836, LR=0.000100
[2025-08-11 01:58:48,996][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097416] [Batch 01424/03692] [00:12:44/00:20:17, 0.537s/it]: train_loss_raw=0.3252, running_loss=0.3835, LR=0.000100
[2025-08-11 01:58:55,379][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097428] [Batch 01436/03692] [00:12:50/00:20:11, 0.537s/it]: train_loss_raw=0.4368, running_loss=0.3869, LR=0.000100
[2025-08-11 01:59:01,679][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097440] [Batch 01448/03692] [00:12:57/00:20:04, 0.537s/it]: train_loss_raw=0.3666, running_loss=0.3863, LR=0.000100
[2025-08-11 01:59:08,051][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097452] [Batch 01460/03692] [00:13:03/00:19:57, 0.537s/it]: train_loss_raw=0.4430, running_loss=0.3844, LR=0.000100
[2025-08-11 01:59:14,484][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097464] [Batch 01472/03692] [00:13:09/00:19:51, 0.537s/it]: train_loss_raw=0.3748, running_loss=0.3845, LR=0.000100
[2025-08-11 01:59:20,910][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097476] [Batch 01484/03692] [00:13:16/00:19:44, 0.537s/it]: train_loss_raw=0.3992, running_loss=0.3855, LR=0.000100
[2025-08-11 01:59:27,270][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097488] [Batch 01496/03692] [00:13:22/00:19:38, 0.537s/it]: train_loss_raw=0.4240, running_loss=0.3895, LR=0.000100
[2025-08-11 01:59:33,670][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097500] [Batch 01508/03692] [00:13:29/00:19:31, 0.537s/it]: train_loss_raw=0.3813, running_loss=0.3880, LR=0.000100
[2025-08-11 01:59:40,112][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097512] [Batch 01520/03692] [00:13:35/00:19:25, 0.537s/it]: train_loss_raw=0.4367, running_loss=0.3883, LR=0.000100
[2025-08-11 01:59:46,525][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097524] [Batch 01532/03692] [00:13:42/00:19:19, 0.537s/it]: train_loss_raw=0.4771, running_loss=0.3900, LR=0.000100
[2025-08-11 02:00:16,465][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097536] [Batch 01544/03692] [00:14:11/00:19:45, 0.552s/it]: train_loss_raw=0.3279, running_loss=0.3898, LR=0.000100
[2025-08-11 02:00:22,840][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097548] [Batch 01556/03692] [00:14:18/00:19:38, 0.552s/it]: train_loss_raw=0.3482, running_loss=0.3918, LR=0.000100
[2025-08-11 02:00:29,223][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097560] [Batch 01568/03692] [00:14:24/00:19:31, 0.551s/it]: train_loss_raw=0.5741, running_loss=0.3970, LR=0.000100
[2025-08-11 02:00:35,495][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097572] [Batch 01580/03692] [00:14:31/00:19:24, 0.551s/it]: train_loss_raw=0.4250, running_loss=0.3951, LR=0.000100
[2025-08-11 02:00:41,874][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097584] [Batch 01592/03692] [00:14:37/00:19:17, 0.551s/it]: train_loss_raw=0.3872, running_loss=0.3917, LR=0.000100
[2025-08-11 02:00:48,316][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097596] [Batch 01604/03692] [00:14:43/00:19:10, 0.551s/it]: train_loss_raw=0.3325, running_loss=0.3901, LR=0.000100
[2025-08-11 02:00:54,693][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097608] [Batch 01616/03692] [00:14:50/00:19:03, 0.551s/it]: train_loss_raw=0.4064, running_loss=0.3917, LR=0.000100
[2025-08-11 02:01:01,148][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097620] [Batch 01628/03692] [00:14:56/00:18:56, 0.551s/it]: train_loss_raw=0.3553, running_loss=0.3918, LR=0.000100
[2025-08-11 02:01:07,545][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097632] [Batch 01640/03692] [00:15:03/00:18:49, 0.551s/it]: train_loss_raw=0.4602, running_loss=0.3927, LR=0.000100
[2025-08-11 02:01:13,778][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097644] [Batch 01652/03692] [00:15:09/00:18:42, 0.550s/it]: train_loss_raw=0.4576, running_loss=0.3917, LR=0.000100
[2025-08-11 02:01:19,992][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097656] [Batch 01664/03692] [00:15:15/00:18:35, 0.550s/it]: train_loss_raw=0.3548, running_loss=0.3901, LR=0.000100
[2025-08-11 02:01:26,187][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097668] [Batch 01676/03692] [00:15:21/00:18:28, 0.550s/it]: train_loss_raw=0.4241, running_loss=0.3878, LR=0.000100
[2025-08-11 02:01:32,334][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097680] [Batch 01688/03692] [00:15:27/00:18:21, 0.550s/it]: train_loss_raw=0.3770, running_loss=0.3877, LR=0.000100
[2025-08-11 02:01:38,680][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097692] [Batch 01700/03692] [00:15:34/00:18:14, 0.550s/it]: train_loss_raw=0.4075, running_loss=0.3912, LR=0.000100
[2025-08-11 02:01:44,700][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097704] [Batch 01712/03692] [00:15:40/00:18:07, 0.549s/it]: train_loss_raw=0.4044, running_loss=0.3904, LR=0.000100
[2025-08-11 02:01:50,787][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097716] [Batch 01724/03692] [00:15:46/00:18:00, 0.549s/it]: train_loss_raw=0.3187, running_loss=0.3934, LR=0.000100
[2025-08-11 02:01:57,192][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097728] [Batch 01736/03692] [00:15:52/00:17:53, 0.549s/it]: train_loss_raw=0.3998, running_loss=0.3947, LR=0.000100
[2025-08-11 02:02:03,576][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097740] [Batch 01748/03692] [00:15:59/00:17:46, 0.549s/it]: train_loss_raw=0.4625, running_loss=0.3947, LR=0.000100
[2025-08-11 02:02:09,763][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097752] [Batch 01760/03692] [00:16:05/00:17:39, 0.548s/it]: train_loss_raw=0.4565, running_loss=0.3945, LR=0.000100
[2025-08-11 02:02:15,904][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097764] [Batch 01772/03692] [00:16:11/00:17:32, 0.548s/it]: train_loss_raw=0.4575, running_loss=0.3915, LR=0.000100
[2025-08-11 02:02:22,087][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097776] [Batch 01784/03692] [00:16:17/00:17:25, 0.548s/it]: train_loss_raw=0.3391, running_loss=0.3932, LR=0.000100
[2025-08-11 02:02:28,122][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097788] [Batch 01796/03692] [00:16:23/00:17:18, 0.548s/it]: train_loss_raw=0.3551, running_loss=0.3882, LR=0.000100
[2025-08-11 02:02:34,216][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097800] [Batch 01808/03692] [00:16:29/00:17:11, 0.547s/it]: train_loss_raw=0.4181, running_loss=0.3883, LR=0.000100
[2025-08-11 02:02:40,269][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097812] [Batch 01820/03692] [00:16:35/00:17:04, 0.547s/it]: train_loss_raw=0.4240, running_loss=0.3884, LR=0.000100
[2025-08-11 02:02:46,296][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097824] [Batch 01832/03692] [00:16:41/00:16:57, 0.547s/it]: train_loss_raw=0.3064, running_loss=0.3856, LR=0.000100
[2025-08-11 02:02:52,380][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097836] [Batch 01844/03692] [00:16:47/00:16:50, 0.547s/it]: train_loss_raw=0.3521, running_loss=0.3855, LR=0.000100
[2025-08-11 02:02:58,544][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097848] [Batch 01856/03692] [00:16:54/00:16:43, 0.546s/it]: train_loss_raw=0.4149, running_loss=0.3871, LR=0.000100
[2025-08-11 02:03:04,709][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097860] [Batch 01868/03692] [00:17:00/00:16:36, 0.546s/it]: train_loss_raw=0.3688, running_loss=0.3869, LR=0.000100
[2025-08-11 02:03:10,965][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097872] [Batch 01880/03692] [00:17:06/00:16:29, 0.546s/it]: train_loss_raw=0.3601, running_loss=0.3870, LR=0.000100
[2025-08-11 02:03:17,139][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097884] [Batch 01892/03692] [00:17:12/00:16:22, 0.546s/it]: train_loss_raw=0.2968, running_loss=0.3861, LR=0.000100
[2025-08-11 02:03:23,330][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097896] [Batch 01904/03692] [00:17:18/00:16:15, 0.546s/it]: train_loss_raw=0.3914, running_loss=0.3848, LR=0.000100
[2025-08-11 02:03:29,488][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097908] [Batch 01916/03692] [00:17:24/00:16:08, 0.545s/it]: train_loss_raw=0.3389, running_loss=0.3826, LR=0.000100
[2025-08-11 02:03:35,685][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097920] [Batch 01928/03692] [00:17:31/00:16:01, 0.545s/it]: train_loss_raw=0.3002, running_loss=0.3855, LR=0.000100
[2025-08-11 02:03:41,821][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097932] [Batch 01940/03692] [00:17:37/00:15:54, 0.545s/it]: train_loss_raw=0.3506, running_loss=0.3867, LR=0.000100
[2025-08-11 02:03:47,890][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097944] [Batch 01952/03692] [00:17:43/00:15:47, 0.545s/it]: train_loss_raw=0.4255, running_loss=0.3895, LR=0.000100
[2025-08-11 02:03:54,151][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097956] [Batch 01964/03692] [00:17:49/00:15:41, 0.545s/it]: train_loss_raw=0.3214, running_loss=0.3890, LR=0.000100
[2025-08-11 02:04:00,457][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097968] [Batch 01976/03692] [00:17:55/00:15:34, 0.545s/it]: train_loss_raw=0.3356, running_loss=0.3874, LR=0.000100
[2025-08-11 02:04:06,875][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097980] [Batch 01988/03692] [00:18:02/00:15:27, 0.544s/it]: train_loss_raw=0.3323, running_loss=0.3876, LR=0.000100
[2025-08-11 02:04:12,968][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097992] [Batch 02000/03692] [00:18:08/00:15:20, 0.544s/it]: train_loss_raw=0.3246, running_loss=0.3911, LR=0.000100
[2025-08-11 02:04:23,500][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098004] [Batch 02012/03692] [00:18:19/00:15:17, 0.546s/it]: train_loss_raw=0.3758, running_loss=0.3899, LR=0.000100
[2025-08-11 02:04:29,553][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098016] [Batch 02024/03692] [00:18:25/00:15:10, 0.546s/it]: train_loss_raw=0.3697, running_loss=0.3893, LR=0.000100
[2025-08-11 02:04:35,733][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098028] [Batch 02036/03692] [00:18:31/00:15:03, 0.546s/it]: train_loss_raw=0.4136, running_loss=0.3908, LR=0.000100
[2025-08-11 02:04:41,900][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098040] [Batch 02048/03692] [00:18:37/00:14:56, 0.546s/it]: train_loss_raw=0.3566, running_loss=0.3886, LR=0.000100
[2025-08-11 02:04:48,117][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098052] [Batch 02060/03692] [00:18:43/00:14:50, 0.545s/it]: train_loss_raw=0.4191, running_loss=0.3900, LR=0.000100
[2025-08-11 02:04:54,501][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098064] [Batch 02072/03692] [00:18:50/00:14:43, 0.545s/it]: train_loss_raw=0.4438, running_loss=0.3924, LR=0.000100
[2025-08-11 02:05:00,708][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098076] [Batch 02084/03692] [00:18:56/00:14:36, 0.545s/it]: train_loss_raw=0.3613, running_loss=0.3874, LR=0.000100
[2025-08-11 02:05:06,947][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098088] [Batch 02096/03692] [00:19:02/00:14:29, 0.545s/it]: train_loss_raw=0.3757, running_loss=0.3871, LR=0.000100
[2025-08-11 02:05:13,140][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098100] [Batch 02108/03692] [00:19:08/00:14:23, 0.545s/it]: train_loss_raw=0.4261, running_loss=0.3861, LR=0.000100
[2025-08-11 02:05:19,395][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098112] [Batch 02120/03692] [00:19:14/00:14:16, 0.545s/it]: train_loss_raw=0.5115, running_loss=0.3864, LR=0.000100
[2025-08-11 02:05:25,865][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098124] [Batch 02132/03692] [00:19:21/00:14:09, 0.545s/it]: train_loss_raw=0.4199, running_loss=0.3845, LR=0.000100
[2025-08-11 02:05:32,015][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098136] [Batch 02144/03692] [00:19:27/00:14:02, 0.545s/it]: train_loss_raw=0.3928, running_loss=0.3832, LR=0.000100
[2025-08-11 02:05:38,450][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098148] [Batch 02156/03692] [00:19:33/00:13:56, 0.545s/it]: train_loss_raw=0.3248, running_loss=0.3823, LR=0.000100
[2025-08-11 02:05:45,049][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098160] [Batch 02168/03692] [00:19:40/00:13:49, 0.545s/it]: train_loss_raw=0.4127, running_loss=0.3865, LR=0.000100
[2025-08-11 02:05:51,452][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098172] [Batch 02180/03692] [00:19:46/00:13:43, 0.544s/it]: train_loss_raw=0.3463, running_loss=0.3839, LR=0.000100
[2025-08-11 02:05:57,456][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098184] [Batch 02192/03692] [00:19:52/00:13:36, 0.544s/it]: train_loss_raw=0.3867, running_loss=0.3855, LR=0.000100
[2025-08-11 02:06:03,619][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098196] [Batch 02204/03692] [00:19:59/00:13:29, 0.544s/it]: train_loss_raw=0.3177, running_loss=0.3887, LR=0.000100
[2025-08-11 02:06:09,706][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098208] [Batch 02216/03692] [00:20:05/00:13:22, 0.544s/it]: train_loss_raw=0.4839, running_loss=0.3894, LR=0.000100
[2025-08-11 02:06:16,289][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098220] [Batch 02228/03692] [00:20:11/00:13:16, 0.544s/it]: train_loss_raw=0.3226, running_loss=0.3879, LR=0.000100
[2025-08-11 02:06:22,325][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098232] [Batch 02240/03692] [00:20:17/00:13:09, 0.544s/it]: train_loss_raw=0.3680, running_loss=0.3867, LR=0.000100
[2025-08-11 02:06:28,364][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098244] [Batch 02252/03692] [00:20:23/00:13:02, 0.543s/it]: train_loss_raw=0.3801, running_loss=0.3836, LR=0.000100
[2025-08-11 02:06:34,453][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098256] [Batch 02264/03692] [00:20:29/00:12:55, 0.543s/it]: train_loss_raw=0.3472, running_loss=0.3877, LR=0.000100
[2025-08-11 02:06:40,458][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098268] [Batch 02276/03692] [00:20:35/00:12:48, 0.543s/it]: train_loss_raw=0.3738, running_loss=0.3859, LR=0.000100
[2025-08-11 02:06:46,445][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098280] [Batch 02288/03692] [00:20:41/00:12:42, 0.543s/it]: train_loss_raw=0.5017, running_loss=0.3876, LR=0.000100
[2025-08-11 02:06:52,533][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098292] [Batch 02300/03692] [00:20:48/00:12:35, 0.543s/it]: train_loss_raw=0.3983, running_loss=0.3877, LR=0.000100
[2025-08-11 02:06:58,539][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098304] [Batch 02312/03692] [00:20:54/00:12:28, 0.542s/it]: train_loss_raw=0.4625, running_loss=0.3880, LR=0.000100
[2025-08-11 02:07:04,553][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098316] [Batch 02324/03692] [00:21:00/00:12:21, 0.542s/it]: train_loss_raw=0.3667, running_loss=0.3883, LR=0.000100
[2025-08-11 02:07:10,595][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098328] [Batch 02336/03692] [00:21:06/00:12:14, 0.542s/it]: train_loss_raw=0.4271, running_loss=0.3885, LR=0.000100
[2025-08-11 02:07:16,684][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098340] [Batch 02348/03692] [00:21:12/00:12:08, 0.542s/it]: train_loss_raw=0.4609, running_loss=0.3897, LR=0.000100
[2025-08-11 02:07:22,928][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098352] [Batch 02360/03692] [00:21:18/00:12:01, 0.542s/it]: train_loss_raw=0.4479, running_loss=0.3895, LR=0.000100
[2025-08-11 02:07:29,062][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098364] [Batch 02372/03692] [00:21:24/00:11:54, 0.542s/it]: train_loss_raw=0.4102, running_loss=0.3874, LR=0.000100
[2025-08-11 02:07:35,094][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098376] [Batch 02384/03692] [00:21:30/00:11:48, 0.541s/it]: train_loss_raw=0.4115, running_loss=0.3867, LR=0.000100
[2025-08-11 02:07:41,487][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098388] [Batch 02396/03692] [00:21:36/00:11:41, 0.541s/it]: train_loss_raw=0.2504, running_loss=0.3850, LR=0.000100
[2025-08-11 02:07:47,692][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098400] [Batch 02408/03692] [00:21:43/00:11:34, 0.541s/it]: train_loss_raw=0.3914, running_loss=0.3858, LR=0.000100
[2025-08-11 02:07:53,707][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098412] [Batch 02420/03692] [00:21:49/00:11:28, 0.541s/it]: train_loss_raw=0.4527, running_loss=0.3893, LR=0.000100
[2025-08-11 02:07:59,921][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098424] [Batch 02432/03692] [00:21:55/00:11:21, 0.541s/it]: train_loss_raw=0.3476, running_loss=0.3902, LR=0.000100
[2025-08-11 02:08:06,176][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098436] [Batch 02444/03692] [00:22:01/00:11:14, 0.541s/it]: train_loss_raw=0.3653, running_loss=0.3933, LR=0.000100
[2025-08-11 02:08:12,347][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098448] [Batch 02456/03692] [00:22:07/00:11:08, 0.541s/it]: train_loss_raw=0.3365, running_loss=0.3893, LR=0.000100
[2025-08-11 02:08:18,883][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098460] [Batch 02468/03692] [00:22:14/00:11:01, 0.541s/it]: train_loss_raw=0.4602, running_loss=0.3914, LR=0.000100
[2025-08-11 02:08:25,367][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098472] [Batch 02480/03692] [00:22:20/00:10:55, 0.541s/it]: train_loss_raw=0.4725, running_loss=0.3900, LR=0.000100
[2025-08-11 02:08:31,730][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098484] [Batch 02492/03692] [00:22:27/00:10:48, 0.541s/it]: train_loss_raw=0.3839, running_loss=0.3907, LR=0.000100
[2025-08-11 02:08:38,219][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098496] [Batch 02504/03692] [00:22:33/00:10:42, 0.541s/it]: train_loss_raw=0.2971, running_loss=0.3909, LR=0.000100
[2025-08-11 02:08:44,666][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098508] [Batch 02516/03692] [00:22:40/00:10:35, 0.541s/it]: train_loss_raw=0.4153, running_loss=0.3942, LR=0.000100
[2025-08-11 02:08:51,095][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098520] [Batch 02528/03692] [00:22:46/00:10:29, 0.541s/it]: train_loss_raw=0.3601, running_loss=0.3938, LR=0.000100
[2025-08-11 02:08:57,610][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098532] [Batch 02540/03692] [00:22:53/00:10:22, 0.541s/it]: train_loss_raw=0.3679, running_loss=0.3938, LR=0.000100
[2025-08-11 02:09:03,969][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098544] [Batch 02552/03692] [00:22:59/00:10:16, 0.541s/it]: train_loss_raw=0.4111, running_loss=0.3916, LR=0.000100
[2025-08-11 02:09:10,325][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098556] [Batch 02564/03692] [00:23:05/00:10:09, 0.540s/it]: train_loss_raw=0.3210, running_loss=0.3895, LR=0.000100
[2025-08-11 02:09:16,854][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098568] [Batch 02576/03692] [00:23:12/00:10:03, 0.541s/it]: train_loss_raw=0.3304, running_loss=0.3884, LR=0.000100
[2025-08-11 02:09:23,234][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098580] [Batch 02588/03692] [00:23:18/00:09:56, 0.540s/it]: train_loss_raw=0.3592, running_loss=0.3889, LR=0.000100
[2025-08-11 02:09:29,535][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098592] [Batch 02600/03692] [00:23:25/00:09:50, 0.540s/it]: train_loss_raw=0.4368, running_loss=0.3901, LR=0.000100
[2025-08-11 02:09:35,932][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098604] [Batch 02612/03692] [00:23:31/00:09:43, 0.540s/it]: train_loss_raw=0.3343, running_loss=0.3858, LR=0.000100
[2025-08-11 02:09:42,374][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098616] [Batch 02624/03692] [00:23:37/00:09:37, 0.540s/it]: train_loss_raw=0.3686, running_loss=0.3859, LR=0.000100
[2025-08-11 02:09:48,825][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098628] [Batch 02636/03692] [00:23:44/00:09:30, 0.540s/it]: train_loss_raw=0.3628, running_loss=0.3865, LR=0.000100
[2025-08-11 02:09:55,471][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098640] [Batch 02648/03692] [00:23:50/00:09:24, 0.540s/it]: train_loss_raw=0.4122, running_loss=0.3876, LR=0.000100
[2025-08-11 02:10:01,938][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098652] [Batch 02660/03692] [00:23:57/00:09:17, 0.540s/it]: train_loss_raw=0.3758, running_loss=0.3867, LR=0.000100
[2025-08-11 02:10:08,404][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098664] [Batch 02672/03692] [00:24:03/00:09:11, 0.540s/it]: train_loss_raw=0.4207, running_loss=0.3908, LR=0.000100
[2025-08-11 02:10:14,899][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098676] [Batch 02684/03692] [00:24:10/00:09:04, 0.540s/it]: train_loss_raw=0.3946, running_loss=0.3892, LR=0.000100
[2025-08-11 02:10:21,362][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098688] [Batch 02696/03692] [00:24:16/00:08:58, 0.540s/it]: train_loss_raw=0.3604, running_loss=0.3920, LR=0.000100
[2025-08-11 02:10:27,749][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098700] [Batch 02708/03692] [00:24:23/00:08:51, 0.540s/it]: train_loss_raw=0.3839, running_loss=0.3934, LR=0.000100
[2025-08-11 02:10:34,160][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098712] [Batch 02720/03692] [00:24:29/00:08:45, 0.540s/it]: train_loss_raw=0.3566, running_loss=0.3924, LR=0.000100
[2025-08-11 02:10:40,649][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098724] [Batch 02732/03692] [00:24:36/00:08:38, 0.540s/it]: train_loss_raw=0.3460, running_loss=0.3909, LR=0.000100
[2025-08-11 02:10:47,136][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098736] [Batch 02744/03692] [00:24:42/00:08:32, 0.540s/it]: train_loss_raw=0.3943, running_loss=0.3895, LR=0.000100
[2025-08-11 02:10:53,548][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098748] [Batch 02756/03692] [00:24:49/00:08:25, 0.540s/it]: train_loss_raw=0.4294, running_loss=0.3911, LR=0.000100
[2025-08-11 02:10:59,594][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098760] [Batch 02768/03692] [00:24:55/00:08:19, 0.540s/it]: train_loss_raw=0.3467, running_loss=0.3904, LR=0.000100
[2025-08-11 02:11:05,654][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098772] [Batch 02780/03692] [00:25:01/00:08:12, 0.540s/it]: train_loss_raw=0.4012, running_loss=0.3865, LR=0.000100
[2025-08-11 02:11:11,712][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098784] [Batch 02792/03692] [00:25:07/00:08:05, 0.540s/it]: train_loss_raw=0.2803, running_loss=0.3835, LR=0.000100
[2025-08-11 02:11:18,305][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098796] [Batch 02804/03692] [00:25:13/00:07:59, 0.540s/it]: train_loss_raw=0.3922, running_loss=0.3818, LR=0.000100
[2025-08-11 02:11:24,854][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098808] [Batch 02816/03692] [00:25:20/00:07:52, 0.540s/it]: train_loss_raw=0.4627, running_loss=0.3847, LR=0.000100
[2025-08-11 02:11:31,343][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098820] [Batch 02828/03692] [00:25:26/00:07:46, 0.540s/it]: train_loss_raw=0.3926, running_loss=0.3871, LR=0.000100
[2025-08-11 02:11:37,825][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098832] [Batch 02840/03692] [00:25:33/00:07:39, 0.540s/it]: train_loss_raw=0.4616, running_loss=0.3867, LR=0.000100
[2025-08-11 02:11:44,304][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098844] [Batch 02852/03692] [00:25:39/00:07:33, 0.540s/it]: train_loss_raw=0.4088, running_loss=0.3859, LR=0.000100
[2025-08-11 02:11:50,762][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098856] [Batch 02864/03692] [00:25:46/00:07:27, 0.540s/it]: train_loss_raw=0.3048, running_loss=0.3853, LR=0.000100
[2025-08-11 02:11:57,157][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098868] [Batch 02876/03692] [00:25:52/00:07:20, 0.540s/it]: train_loss_raw=0.4292, running_loss=0.3830, LR=0.000100
[2025-08-11 02:12:03,441][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098880] [Batch 02888/03692] [00:25:58/00:07:14, 0.540s/it]: train_loss_raw=0.3998, running_loss=0.3847, LR=0.000100
[2025-08-11 02:12:09,672][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098892] [Batch 02900/03692] [00:26:05/00:07:07, 0.540s/it]: train_loss_raw=0.3767, running_loss=0.3849, LR=0.000100
[2025-08-11 02:12:16,311][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098904] [Batch 02912/03692] [00:26:11/00:07:01, 0.540s/it]: train_loss_raw=0.3696, running_loss=0.3861, LR=0.000100
[2025-08-11 02:12:22,375][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098916] [Batch 02924/03692] [00:26:17/00:06:54, 0.540s/it]: train_loss_raw=0.3805, running_loss=0.3887, LR=0.000100
[2025-08-11 02:12:28,781][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098928] [Batch 02936/03692] [00:26:24/00:06:47, 0.540s/it]: train_loss_raw=0.3374, running_loss=0.3855, LR=0.000100
[2025-08-11 02:12:35,297][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098940] [Batch 02948/03692] [00:26:30/00:06:41, 0.540s/it]: train_loss_raw=0.4396, running_loss=0.3864, LR=0.000100
[2025-08-11 02:12:41,628][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098952] [Batch 02960/03692] [00:26:37/00:06:34, 0.540s/it]: train_loss_raw=0.3674, running_loss=0.3837, LR=0.000100
[2025-08-11 02:12:47,916][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098964] [Batch 02972/03692] [00:26:43/00:06:28, 0.540s/it]: train_loss_raw=0.4051, running_loss=0.3843, LR=0.000100
[2025-08-11 02:12:53,941][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098976] [Batch 02984/03692] [00:26:49/00:06:21, 0.539s/it]: train_loss_raw=0.5069, running_loss=0.3852, LR=0.000100
[2025-08-11 02:12:59,929][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098988] [Batch 02996/03692] [00:26:55/00:06:15, 0.539s/it]: train_loss_raw=0.3883, running_loss=0.3864, LR=0.000100
[2025-08-11 02:13:05,935][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099000] [Batch 03008/03692] [00:27:01/00:06:08, 0.539s/it]: train_loss_raw=0.3717, running_loss=0.3846, LR=0.000100
[2025-08-11 02:13:11,989][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099012] [Batch 03020/03692] [00:27:07/00:06:02, 0.539s/it]: train_loss_raw=0.4285, running_loss=0.3864, LR=0.000100
[2025-08-11 02:13:18,021][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099024] [Batch 03032/03692] [00:27:13/00:05:55, 0.539s/it]: train_loss_raw=0.3027, running_loss=0.3872, LR=0.000100
[2025-08-11 02:13:24,086][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099036] [Batch 03044/03692] [00:27:19/00:05:49, 0.539s/it]: train_loss_raw=0.4555, running_loss=0.3869, LR=0.000100
[2025-08-11 02:13:30,471][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099048] [Batch 03056/03692] [00:27:25/00:05:42, 0.539s/it]: train_loss_raw=0.3872, running_loss=0.3904, LR=0.000100
[2025-08-11 02:13:36,994][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099060] [Batch 03068/03692] [00:27:32/00:05:36, 0.539s/it]: train_loss_raw=0.3979, running_loss=0.3902, LR=0.000100
[2025-08-11 02:13:43,375][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099072] [Batch 03080/03692] [00:27:38/00:05:29, 0.539s/it]: train_loss_raw=0.3574, running_loss=0.3924, LR=0.000100
[2025-08-11 02:13:49,880][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099084] [Batch 03092/03692] [00:27:45/00:05:23, 0.539s/it]: train_loss_raw=0.4175, running_loss=0.3941, LR=0.000100
[2025-08-11 02:13:56,379][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099096] [Batch 03104/03692] [00:27:51/00:05:16, 0.539s/it]: train_loss_raw=0.3703, running_loss=0.3926, LR=0.000100
[2025-08-11 02:14:02,804][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099108] [Batch 03116/03692] [00:27:58/00:05:10, 0.539s/it]: train_loss_raw=0.3452, running_loss=0.3891, LR=0.000100
[2025-08-11 02:14:09,122][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099120] [Batch 03128/03692] [00:28:04/00:05:03, 0.539s/it]: train_loss_raw=0.3357, running_loss=0.3896, LR=0.000100
[2025-08-11 02:14:15,492][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099132] [Batch 03140/03692] [00:28:11/00:04:57, 0.539s/it]: train_loss_raw=0.3846, running_loss=0.3920, LR=0.000100
[2025-08-11 02:14:21,895][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099144] [Batch 03152/03692] [00:28:17/00:04:50, 0.539s/it]: train_loss_raw=0.3640, running_loss=0.3924, LR=0.000100
[2025-08-11 02:14:28,321][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099156] [Batch 03164/03692] [00:28:23/00:04:44, 0.539s/it]: train_loss_raw=0.4340, running_loss=0.3915, LR=0.000100
[2025-08-11 02:14:34,765][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099168] [Batch 03176/03692] [00:28:30/00:04:37, 0.538s/it]: train_loss_raw=0.4975, running_loss=0.3903, LR=0.000100
[2025-08-11 02:14:41,143][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099180] [Batch 03188/03692] [00:28:36/00:04:31, 0.538s/it]: train_loss_raw=0.3060, running_loss=0.3925, LR=0.000100
[2025-08-11 02:14:47,618][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099192] [Batch 03200/03692] [00:28:43/00:04:24, 0.538s/it]: train_loss_raw=0.3798, running_loss=0.3923, LR=0.000100
[2025-08-11 02:14:54,175][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099204] [Batch 03212/03692] [00:28:49/00:04:18, 0.539s/it]: train_loss_raw=0.3421, running_loss=0.3911, LR=0.000100
[2025-08-11 02:15:00,627][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099216] [Batch 03224/03692] [00:28:56/00:04:12, 0.539s/it]: train_loss_raw=0.3496, running_loss=0.3922, LR=0.000100
[2025-08-11 02:15:06,658][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099228] [Batch 03236/03692] [00:29:02/00:04:05, 0.538s/it]: train_loss_raw=0.4190, running_loss=0.3947, LR=0.000100
[2025-08-11 02:15:12,843][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099240] [Batch 03248/03692] [00:29:08/00:03:58, 0.538s/it]: train_loss_raw=0.3385, running_loss=0.3928, LR=0.000100
[2025-08-11 02:15:19,258][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099252] [Batch 03260/03692] [00:29:14/00:03:52, 0.538s/it]: train_loss_raw=0.4830, running_loss=0.3914, LR=0.000100
[2025-08-11 02:15:25,674][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099264] [Batch 03272/03692] [00:29:21/00:03:46, 0.538s/it]: train_loss_raw=0.3125, running_loss=0.3918, LR=0.000100
[2025-08-11 02:15:32,161][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099276] [Batch 03284/03692] [00:29:27/00:03:39, 0.538s/it]: train_loss_raw=0.4155, running_loss=0.3880, LR=0.000100
[2025-08-11 02:15:38,651][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099288] [Batch 03296/03692] [00:29:34/00:03:33, 0.538s/it]: train_loss_raw=0.4159, running_loss=0.3872, LR=0.000100
[2025-08-11 02:15:45,139][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099300] [Batch 03308/03692] [00:29:40/00:03:26, 0.538s/it]: train_loss_raw=0.4542, running_loss=0.3871, LR=0.000100
[2025-08-11 02:15:51,582][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099312] [Batch 03320/03692] [00:29:47/00:03:20, 0.538s/it]: train_loss_raw=0.3110, running_loss=0.3895, LR=0.000100
[2025-08-11 02:15:57,882][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099324] [Batch 03332/03692] [00:29:53/00:03:13, 0.538s/it]: train_loss_raw=0.3798, running_loss=0.3902, LR=0.000100
[2025-08-11 02:16:04,293][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099336] [Batch 03344/03692] [00:29:59/00:03:07, 0.538s/it]: train_loss_raw=0.4667, running_loss=0.3883, LR=0.000100
[2025-08-11 02:16:10,668][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099348] [Batch 03356/03692] [00:30:06/00:03:00, 0.538s/it]: train_loss_raw=0.4664, running_loss=0.3880, LR=0.000100
[2025-08-11 02:16:17,077][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099360] [Batch 03368/03692] [00:30:12/00:02:54, 0.538s/it]: train_loss_raw=0.4164, running_loss=0.3892, LR=0.000100
[2025-08-11 02:16:23,493][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099372] [Batch 03380/03692] [00:30:19/00:02:47, 0.538s/it]: train_loss_raw=0.3859, running_loss=0.3886, LR=0.000100
[2025-08-11 02:16:29,878][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099384] [Batch 03392/03692] [00:30:25/00:02:41, 0.538s/it]: train_loss_raw=0.3326, running_loss=0.3868, LR=0.000100
[2025-08-11 02:16:36,214][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099396] [Batch 03404/03692] [00:30:31/00:02:34, 0.538s/it]: train_loss_raw=0.4068, running_loss=0.3882, LR=0.000100
[2025-08-11 02:16:42,526][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099408] [Batch 03416/03692] [00:30:38/00:02:28, 0.538s/it]: train_loss_raw=0.3917, running_loss=0.3870, LR=0.000100
[2025-08-11 02:16:48,902][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099420] [Batch 03428/03692] [00:30:44/00:02:22, 0.538s/it]: train_loss_raw=0.4180, running_loss=0.3871, LR=0.000100
[2025-08-11 02:16:55,283][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099432] [Batch 03440/03692] [00:30:50/00:02:15, 0.538s/it]: train_loss_raw=0.3325, running_loss=0.3881, LR=0.000100
[2025-08-11 02:17:01,698][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099444] [Batch 03452/03692] [00:30:57/00:02:09, 0.538s/it]: train_loss_raw=0.3711, running_loss=0.3876, LR=0.000100
[2025-08-11 02:17:08,133][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099456] [Batch 03464/03692] [00:31:03/00:02:02, 0.538s/it]: train_loss_raw=0.3708, running_loss=0.3878, LR=0.000100
[2025-08-11 02:17:14,487][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099468] [Batch 03476/03692] [00:31:09/00:01:56, 0.538s/it]: train_loss_raw=0.3489, running_loss=0.3877, LR=0.000100
[2025-08-11 02:17:20,982][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099480] [Batch 03488/03692] [00:31:16/00:01:49, 0.538s/it]: train_loss_raw=0.4020, running_loss=0.3875, LR=0.000100
[2025-08-11 02:17:27,342][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099492] [Batch 03500/03692] [00:31:22/00:01:43, 0.538s/it]: train_loss_raw=0.4140, running_loss=0.3906, LR=0.000100
[2025-08-11 02:17:33,719][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099504] [Batch 03512/03692] [00:31:29/00:01:36, 0.538s/it]: train_loss_raw=0.4185, running_loss=0.3892, LR=0.000100
[2025-08-11 02:17:40,225][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099516] [Batch 03524/03692] [00:31:35/00:01:30, 0.538s/it]: train_loss_raw=0.4956, running_loss=0.3908, LR=0.000100
[2025-08-11 02:17:46,752][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099528] [Batch 03536/03692] [00:31:42/00:01:23, 0.538s/it]: train_loss_raw=0.3546, running_loss=0.3905, LR=0.000100
[2025-08-11 02:17:53,157][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099540] [Batch 03548/03692] [00:31:48/00:01:17, 0.538s/it]: train_loss_raw=0.3672, running_loss=0.3914, LR=0.000100
[2025-08-11 02:17:59,566][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099552] [Batch 03560/03692] [00:31:55/00:01:11, 0.538s/it]: train_loss_raw=0.3087, running_loss=0.3893, LR=0.000100
[2025-08-11 02:18:05,959][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099564] [Batch 03572/03692] [00:32:01/00:01:04, 0.538s/it]: train_loss_raw=0.3403, running_loss=0.3875, LR=0.000100
[2025-08-11 02:18:12,458][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099576] [Batch 03584/03692] [00:32:07/00:00:58, 0.538s/it]: train_loss_raw=0.4662, running_loss=0.3874, LR=0.000100
[2025-08-11 02:18:19,048][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099588] [Batch 03596/03692] [00:32:14/00:00:51, 0.538s/it]: train_loss_raw=0.4945, running_loss=0.3868, LR=0.000100
[2025-08-11 02:18:25,521][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099600] [Batch 03608/03692] [00:32:21/00:00:45, 0.538s/it]: train_loss_raw=0.3662, running_loss=0.3829, LR=0.000100
[2025-08-11 02:18:31,914][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099612] [Batch 03620/03692] [00:32:27/00:00:38, 0.538s/it]: train_loss_raw=0.3118, running_loss=0.3808, LR=0.000100
[2025-08-11 02:18:38,322][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099624] [Batch 03632/03692] [00:32:33/00:00:32, 0.538s/it]: train_loss_raw=0.3168, running_loss=0.3826, LR=0.000100
[2025-08-11 02:18:44,833][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099636] [Batch 03644/03692] [00:32:40/00:00:25, 0.538s/it]: train_loss_raw=0.3397, running_loss=0.3831, LR=0.000100
[2025-08-11 02:18:51,317][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099648] [Batch 03656/03692] [00:32:46/00:00:19, 0.538s/it]: train_loss_raw=0.3662, running_loss=0.3834, LR=0.000100
[2025-08-11 02:18:57,856][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099660] [Batch 03668/03692] [00:32:53/00:00:12, 0.538s/it]: train_loss_raw=0.4107, running_loss=0.3838, LR=0.000100
[2025-08-11 02:19:04,205][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099672] [Batch 03680/03692] [00:32:59/00:00:06, 0.538s/it]: train_loss_raw=0.4406, running_loss=0.3847, LR=0.000100
[2025-08-11 02:19:10,626][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099684] [Batch 03692/03692] [00:33:06/00:00:00, 0.538s/it]: train_loss_raw=0.4881, running_loss=0.3856, LR=0.000100
[2025-08-11 02:19:15,933][__main__][INFO] - [VALIDATION] [Epoch 26/29] Starting validation.
[2025-08-11 02:19:50,062][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 099685] [Batch 00011/00025] [00:00:34/00:00:36, 2.844s/it]
[2025-08-11 02:20:07,573][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 099685] [Batch 00023/00025] [00:00:51/00:00:02, 2.152s/it]
[2025-08-11 02:20:08,720][__main__][INFO] - [VALIDATION] [Epoch 26/29] train_loss=0.38556, valid_loss=0.55375
[2025-08-11 02:20:08,721][__main__][INFO] - [VALIDATION] [Epoch 26/29] Metrics:
[2025-08-11 02:20:08,721][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_er      0.227
[2025-08-11 02:20:08,721][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_prec    0.578
[2025-08-11 02:20:08,721][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_recall  0.586
[2025-08-11 02:20:08,721][__main__][INFO] - [VALIDATION] [Epoch 26/29] - pep_recall 0.574
[2025-08-11 02:20:08,724][__main__][INFO] - [TRAIN] [Epoch 26/29] Epoch complete, total time 15:24:07, remaining time 01:42:40, 00:34:13 per epoch
[2025-08-11 02:20:15,090][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099696] [Batch 00012/03692] [00:00:06/00:31:10, 0.508s/it]: train_loss_raw=0.4264, running_loss=0.3103, LR=0.000100
[2025-08-11 02:20:21,553][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099708] [Batch 00024/03692] [00:00:12/00:31:59, 0.523s/it]: train_loss_raw=0.4845, running_loss=0.3210, LR=0.000100
[2025-08-11 02:20:28,017][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099720] [Batch 00036/03692] [00:00:19/00:32:12, 0.529s/it]: train_loss_raw=0.3806, running_loss=0.3284, LR=0.000100
[2025-08-11 02:20:34,449][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099732] [Batch 00048/03692] [00:00:25/00:32:12, 0.530s/it]: train_loss_raw=0.3915, running_loss=0.3365, LR=0.000100
[2025-08-11 02:20:40,804][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099744] [Batch 00060/03692] [00:00:31/00:32:05, 0.530s/it]: train_loss_raw=0.4295, running_loss=0.3443, LR=0.000100
[2025-08-11 02:20:47,361][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099756] [Batch 00072/03692] [00:00:38/00:32:09, 0.533s/it]: train_loss_raw=0.2750, running_loss=0.3456, LR=0.000100
[2025-08-11 02:20:53,926][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099768] [Batch 00084/03692] [00:00:44/00:32:10, 0.535s/it]: train_loss_raw=0.4761, running_loss=0.3477, LR=0.000100
[2025-08-11 02:21:00,239][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099780] [Batch 00096/03692] [00:00:51/00:31:59, 0.534s/it]: train_loss_raw=0.3228, running_loss=0.3532, LR=0.000100
[2025-08-11 02:21:06,769][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099792] [Batch 00108/03692] [00:00:57/00:31:57, 0.535s/it]: train_loss_raw=0.5247, running_loss=0.3571, LR=0.000100
[2025-08-11 02:21:13,300][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099804] [Batch 00120/03692] [00:01:04/00:31:54, 0.536s/it]: train_loss_raw=0.3697, running_loss=0.3602, LR=0.000100
[2025-08-11 02:21:19,763][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099816] [Batch 00132/03692] [00:01:10/00:31:48, 0.536s/it]: train_loss_raw=0.3935, running_loss=0.3631, LR=0.000100
[2025-08-11 02:21:26,256][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099828] [Batch 00144/03692] [00:01:17/00:31:43, 0.537s/it]: train_loss_raw=0.4101, running_loss=0.3637, LR=0.000100
[2025-08-11 02:21:32,407][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099840] [Batch 00156/03692] [00:01:23/00:31:30, 0.535s/it]: train_loss_raw=0.3600, running_loss=0.3687, LR=0.000100
[2025-08-11 02:21:38,450][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099852] [Batch 00168/03692] [00:01:29/00:31:16, 0.532s/it]: train_loss_raw=0.3268, running_loss=0.3674, LR=0.000100
[2025-08-11 02:21:44,940][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099864] [Batch 00180/03692] [00:01:35/00:31:12, 0.533s/it]: train_loss_raw=0.4282, running_loss=0.3694, LR=0.000100
[2025-08-11 02:21:51,399][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099876] [Batch 00192/03692] [00:01:42/00:31:06, 0.533s/it]: train_loss_raw=0.3576, running_loss=0.3752, LR=0.000100
[2025-08-11 02:21:57,893][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099888] [Batch 00204/03692] [00:01:48/00:31:02, 0.534s/it]: train_loss_raw=0.3136, running_loss=0.3754, LR=0.000100
[2025-08-11 02:22:04,105][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099900] [Batch 00216/03692] [00:01:55/00:30:52, 0.533s/it]: train_loss_raw=0.3247, running_loss=0.3774, LR=0.000100
[2025-08-11 02:22:10,080][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099912] [Batch 00228/03692] [00:02:01/00:30:39, 0.531s/it]: train_loss_raw=0.2674, running_loss=0.3774, LR=0.000100
[2025-08-11 02:22:16,561][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099924] [Batch 00240/03692] [00:02:07/00:30:34, 0.532s/it]: train_loss_raw=0.3776, running_loss=0.3773, LR=0.000100
[2025-08-11 02:22:22,548][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099936] [Batch 00252/03692] [00:02:13/00:30:23, 0.530s/it]: train_loss_raw=0.3127, running_loss=0.3764, LR=0.000100
[2025-08-11 02:22:28,596][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099948] [Batch 00264/03692] [00:02:19/00:30:12, 0.529s/it]: train_loss_raw=0.3708, running_loss=0.3789, LR=0.000100
[2025-08-11 02:22:34,643][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099960] [Batch 00276/03692] [00:02:25/00:30:02, 0.528s/it]: train_loss_raw=0.3590, running_loss=0.3805, LR=0.000100
[2025-08-11 02:22:40,946][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099972] [Batch 00288/03692] [00:02:31/00:29:56, 0.528s/it]: train_loss_raw=0.4081, running_loss=0.3800, LR=0.000100
[2025-08-11 02:22:47,353][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099984] [Batch 00300/03692] [00:02:38/00:29:50, 0.528s/it]: train_loss_raw=0.4239, running_loss=0.3818, LR=0.000100
[2025-08-11 02:22:53,711][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099996] [Batch 00312/03692] [00:02:44/00:29:44, 0.528s/it]: train_loss_raw=0.3786, running_loss=0.3817, LR=0.000100
[2025-08-11 02:23:05,230][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100008] [Batch 00324/03692] [00:02:56/00:30:32, 0.544s/it]: train_loss_raw=0.4256, running_loss=0.3835, LR=0.000100
[2025-08-11 02:23:11,755][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100020] [Batch 00336/03692] [00:03:02/00:30:25, 0.544s/it]: train_loss_raw=0.3294, running_loss=0.3823, LR=0.000100
[2025-08-11 02:23:18,296][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100032] [Batch 00348/03692] [00:03:09/00:30:19, 0.544s/it]: train_loss_raw=0.3512, running_loss=0.3836, LR=0.000100
[2025-08-11 02:23:24,799][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100044] [Batch 00360/03692] [00:03:15/00:30:12, 0.544s/it]: train_loss_raw=0.3086, running_loss=0.3823, LR=0.000100
[2025-08-11 02:23:31,218][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100056] [Batch 00372/03692] [00:03:22/00:30:04, 0.544s/it]: train_loss_raw=0.2616, running_loss=0.3829, LR=0.000100
[2025-08-11 02:23:37,663][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100068] [Batch 00384/03692] [00:03:28/00:29:57, 0.543s/it]: train_loss_raw=0.3986, running_loss=0.3806, LR=0.000100
[2025-08-11 02:23:44,137][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100080] [Batch 00396/03692] [00:03:35/00:29:50, 0.543s/it]: train_loss_raw=0.4564, running_loss=0.3834, LR=0.000100
[2025-08-11 02:23:50,382][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100092] [Batch 00408/03692] [00:03:41/00:29:41, 0.543s/it]: train_loss_raw=0.4269, running_loss=0.3824, LR=0.000100
[2025-08-11 02:23:56,648][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100104] [Batch 00420/03692] [00:03:47/00:29:33, 0.542s/it]: train_loss_raw=0.3696, running_loss=0.3798, LR=0.000100
[2025-08-11 02:24:03,132][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100116] [Batch 00432/03692] [00:03:54/00:29:26, 0.542s/it]: train_loss_raw=0.3884, running_loss=0.3804, LR=0.000100
[2025-08-11 02:24:09,578][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100128] [Batch 00444/03692] [00:04:00/00:29:19, 0.542s/it]: train_loss_raw=0.3834, running_loss=0.3861, LR=0.000100
[2025-08-11 02:24:16,076][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100140] [Batch 00456/03692] [00:04:07/00:29:13, 0.542s/it]: train_loss_raw=0.4447, running_loss=0.3896, LR=0.000100
[2025-08-11 02:24:22,441][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100152] [Batch 00468/03692] [00:04:13/00:29:05, 0.542s/it]: train_loss_raw=0.3473, running_loss=0.3894, LR=0.000100
[2025-08-11 02:24:28,759][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100164] [Batch 00480/03692] [00:04:19/00:28:58, 0.541s/it]: train_loss_raw=0.3787, running_loss=0.3862, LR=0.000100
[2025-08-11 02:24:35,134][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100176] [Batch 00492/03692] [00:04:26/00:28:51, 0.541s/it]: train_loss_raw=0.3439, running_loss=0.3855, LR=0.000100
[2025-08-11 02:24:41,521][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100188] [Batch 00504/03692] [00:04:32/00:28:43, 0.541s/it]: train_loss_raw=0.3488, running_loss=0.3872, LR=0.000100
[2025-08-11 02:24:47,845][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100200] [Batch 00516/03692] [00:04:38/00:28:36, 0.540s/it]: train_loss_raw=0.3123, running_loss=0.3852, LR=0.000100
[2025-08-11 02:24:54,217][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100212] [Batch 00528/03692] [00:04:45/00:28:29, 0.540s/it]: train_loss_raw=0.3292, running_loss=0.3871, LR=0.000100
[2025-08-11 02:25:00,694][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100224] [Batch 00540/03692] [00:04:51/00:28:22, 0.540s/it]: train_loss_raw=0.4041, running_loss=0.3893, LR=0.000100
[2025-08-11 02:25:07,223][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100236] [Batch 00552/03692] [00:04:58/00:28:16, 0.540s/it]: train_loss_raw=0.3646, running_loss=0.3874, LR=0.000100
[2025-08-11 02:25:13,689][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100248] [Batch 00564/03692] [00:05:04/00:28:09, 0.540s/it]: train_loss_raw=0.3976, running_loss=0.3872, LR=0.000100
[2025-08-11 02:25:20,190][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100260] [Batch 00576/03692] [00:05:11/00:28:03, 0.540s/it]: train_loss_raw=0.4066, running_loss=0.3872, LR=0.000100
[2025-08-11 02:25:26,530][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100272] [Batch 00588/03692] [00:05:17/00:27:56, 0.540s/it]: train_loss_raw=0.4524, running_loss=0.3858, LR=0.000100
[2025-08-11 02:25:32,902][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100284] [Batch 00600/03692] [00:05:23/00:27:49, 0.540s/it]: train_loss_raw=0.3833, running_loss=0.3828, LR=0.000100
[2025-08-11 02:25:39,203][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100296] [Batch 00612/03692] [00:05:30/00:27:41, 0.540s/it]: train_loss_raw=0.3459, running_loss=0.3841, LR=0.000100
[2025-08-11 02:25:45,636][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100308] [Batch 00624/03692] [00:05:36/00:27:35, 0.539s/it]: train_loss_raw=0.3815, running_loss=0.3867, LR=0.000100
[2025-08-11 02:25:52,046][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100320] [Batch 00636/03692] [00:05:43/00:27:28, 0.539s/it]: train_loss_raw=0.3537, running_loss=0.3895, LR=0.000100
[2025-08-11 02:25:58,445][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100332] [Batch 00648/03692] [00:05:49/00:27:21, 0.539s/it]: train_loss_raw=0.2720, running_loss=0.3889, LR=0.000100
[2025-08-11 02:26:04,919][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100344] [Batch 00660/03692] [00:05:55/00:27:15, 0.539s/it]: train_loss_raw=0.3950, running_loss=0.3858, LR=0.000100
[2025-08-11 02:26:11,335][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100356] [Batch 00672/03692] [00:06:02/00:27:08, 0.539s/it]: train_loss_raw=0.4216, running_loss=0.3836, LR=0.000100
[2025-08-11 02:26:17,697][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100368] [Batch 00684/03692] [00:06:08/00:27:01, 0.539s/it]: train_loss_raw=0.4136, running_loss=0.3818, LR=0.000100
[2025-08-11 02:26:24,077][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100380] [Batch 00696/03692] [00:06:15/00:26:54, 0.539s/it]: train_loss_raw=0.5009, running_loss=0.3834, LR=0.000100
[2025-08-11 02:26:30,479][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100392] [Batch 00708/03692] [00:06:21/00:26:47, 0.539s/it]: train_loss_raw=0.3836, running_loss=0.3847, LR=0.000100
[2025-08-11 02:26:36,871][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100404] [Batch 00720/03692] [00:06:27/00:26:41, 0.539s/it]: train_loss_raw=0.3936, running_loss=0.3874, LR=0.000100
[2025-08-11 02:26:43,228][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100416] [Batch 00732/03692] [00:06:34/00:26:34, 0.539s/it]: train_loss_raw=0.4057, running_loss=0.3893, LR=0.000100
[2025-08-11 02:26:49,576][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100428] [Batch 00744/03692] [00:06:40/00:26:27, 0.538s/it]: train_loss_raw=0.3234, running_loss=0.3897, LR=0.000100
[2025-08-11 02:26:55,925][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100440] [Batch 00756/03692] [00:06:46/00:26:20, 0.538s/it]: train_loss_raw=0.2988, running_loss=0.3886, LR=0.000100
[2025-08-11 02:27:02,248][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100452] [Batch 00768/03692] [00:06:53/00:26:13, 0.538s/it]: train_loss_raw=0.3313, running_loss=0.3864, LR=0.000100
[2025-08-11 02:27:08,668][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100464] [Batch 00780/03692] [00:06:59/00:26:06, 0.538s/it]: train_loss_raw=0.4591, running_loss=0.3908, LR=0.000100
[2025-08-11 02:27:15,147][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100476] [Batch 00792/03692] [00:07:06/00:26:00, 0.538s/it]: train_loss_raw=0.3011, running_loss=0.3913, LR=0.000100
[2025-08-11 02:27:21,512][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100488] [Batch 00804/03692] [00:07:12/00:25:53, 0.538s/it]: train_loss_raw=0.3383, running_loss=0.3904, LR=0.000100
[2025-08-11 02:27:27,955][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100500] [Batch 00816/03692] [00:07:18/00:25:47, 0.538s/it]: train_loss_raw=0.3899, running_loss=0.3878, LR=0.000100
[2025-08-11 02:27:34,404][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100512] [Batch 00828/03692] [00:07:25/00:25:40, 0.538s/it]: train_loss_raw=0.3439, running_loss=0.3853, LR=0.000100
[2025-08-11 02:27:40,900][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100524] [Batch 00840/03692] [00:07:31/00:25:34, 0.538s/it]: train_loss_raw=0.4077, running_loss=0.3871, LR=0.000100
[2025-08-11 02:27:47,248][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100536] [Batch 00852/03692] [00:07:38/00:25:27, 0.538s/it]: train_loss_raw=0.3823, running_loss=0.3828, LR=0.000100
[2025-08-11 02:27:53,593][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100548] [Batch 00864/03692] [00:07:44/00:25:20, 0.538s/it]: train_loss_raw=0.3597, running_loss=0.3851, LR=0.000100
[2025-08-11 02:28:00,085][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100560] [Batch 00876/03692] [00:07:51/00:25:14, 0.538s/it]: train_loss_raw=0.4216, running_loss=0.3857, LR=0.000100
[2025-08-11 02:28:06,571][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100572] [Batch 00888/03692] [00:07:57/00:25:08, 0.538s/it]: train_loss_raw=0.3174, running_loss=0.3867, LR=0.000100
[2025-08-11 02:28:12,988][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100584] [Batch 00900/03692] [00:08:03/00:25:01, 0.538s/it]: train_loss_raw=0.3628, running_loss=0.3863, LR=0.000100
[2025-08-11 02:28:19,327][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100596] [Batch 00912/03692] [00:08:10/00:24:54, 0.538s/it]: train_loss_raw=0.3963, running_loss=0.3894, LR=0.000100
[2025-08-11 02:28:25,697][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100608] [Batch 00924/03692] [00:08:16/00:24:47, 0.538s/it]: train_loss_raw=0.3267, running_loss=0.3875, LR=0.000100
[2025-08-11 02:28:32,081][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100620] [Batch 00936/03692] [00:08:23/00:24:41, 0.537s/it]: train_loss_raw=0.4526, running_loss=0.3909, LR=0.000100
[2025-08-11 02:28:38,368][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100632] [Batch 00948/03692] [00:08:29/00:24:34, 0.537s/it]: train_loss_raw=0.3956, running_loss=0.3889, LR=0.000100
[2025-08-11 02:28:44,705][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100644] [Batch 00960/03692] [00:08:35/00:24:27, 0.537s/it]: train_loss_raw=0.3797, running_loss=0.3889, LR=0.000100
[2025-08-11 02:28:51,234][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100656] [Batch 00972/03692] [00:08:42/00:24:21, 0.537s/it]: train_loss_raw=0.3326, running_loss=0.3909, LR=0.000100
[2025-08-11 02:28:57,772][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100668] [Batch 00984/03692] [00:08:48/00:24:15, 0.537s/it]: train_loss_raw=0.3857, running_loss=0.3906, LR=0.000100
[2025-08-11 02:29:04,214][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100680] [Batch 00996/03692] [00:08:55/00:24:08, 0.537s/it]: train_loss_raw=0.2443, running_loss=0.3875, LR=0.000100
[2025-08-11 02:29:10,636][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100692] [Batch 01008/03692] [00:09:01/00:24:02, 0.537s/it]: train_loss_raw=0.3201, running_loss=0.3846, LR=0.000100
[2025-08-11 02:29:17,024][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100704] [Batch 01020/03692] [00:09:08/00:23:55, 0.537s/it]: train_loss_raw=0.3002, running_loss=0.3851, LR=0.000100
[2025-08-11 02:29:23,549][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100716] [Batch 01032/03692] [00:09:14/00:23:49, 0.537s/it]: train_loss_raw=0.4341, running_loss=0.3873, LR=0.000100
[2025-08-11 02:29:30,096][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100728] [Batch 01044/03692] [00:09:21/00:23:43, 0.537s/it]: train_loss_raw=0.2969, running_loss=0.3838, LR=0.000100
[2025-08-11 02:29:36,470][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100740] [Batch 01056/03692] [00:09:27/00:23:36, 0.537s/it]: train_loss_raw=0.3899, running_loss=0.3837, LR=0.000100
[2025-08-11 02:29:42,788][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100752] [Batch 01068/03692] [00:09:33/00:23:29, 0.537s/it]: train_loss_raw=0.4155, running_loss=0.3843, LR=0.000100
[2025-08-11 02:29:49,236][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100764] [Batch 01080/03692] [00:09:40/00:23:23, 0.537s/it]: train_loss_raw=0.3795, running_loss=0.3857, LR=0.000100
[2025-08-11 02:29:55,621][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100776] [Batch 01092/03692] [00:09:46/00:23:16, 0.537s/it]: train_loss_raw=0.4231, running_loss=0.3893, LR=0.000100
[2025-08-11 02:30:02,140][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100788] [Batch 01104/03692] [00:09:53/00:23:10, 0.537s/it]: train_loss_raw=0.4830, running_loss=0.3905, LR=0.000100
[2025-08-11 02:30:08,601][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100800] [Batch 01116/03692] [00:09:59/00:23:04, 0.537s/it]: train_loss_raw=0.4201, running_loss=0.3882, LR=0.000100
[2025-08-11 02:30:14,983][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100812] [Batch 01128/03692] [00:10:05/00:22:57, 0.537s/it]: train_loss_raw=0.3893, running_loss=0.3871, LR=0.000100
[2025-08-11 02:30:21,436][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100824] [Batch 01140/03692] [00:10:12/00:22:51, 0.537s/it]: train_loss_raw=0.3580, running_loss=0.3876, LR=0.000100
[2025-08-11 02:30:27,952][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100836] [Batch 01152/03692] [00:10:18/00:22:44, 0.537s/it]: train_loss_raw=0.4713, running_loss=0.3896, LR=0.000100
[2025-08-11 02:30:34,334][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100848] [Batch 01164/03692] [00:10:25/00:22:38, 0.537s/it]: train_loss_raw=0.2974, running_loss=0.3875, LR=0.000100
[2025-08-11 02:30:40,612][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100860] [Batch 01176/03692] [00:10:31/00:22:31, 0.537s/it]: train_loss_raw=0.3812, running_loss=0.3855, LR=0.000100
[2025-08-11 02:30:46,855][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100872] [Batch 01188/03692] [00:10:37/00:22:24, 0.537s/it]: train_loss_raw=0.3892, running_loss=0.3839, LR=0.000100
[2025-08-11 02:30:53,188][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100884] [Batch 01200/03692] [00:10:44/00:22:17, 0.537s/it]: train_loss_raw=0.4421, running_loss=0.3840, LR=0.000100
[2025-08-11 02:30:59,613][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100896] [Batch 01212/03692] [00:10:50/00:22:11, 0.537s/it]: train_loss_raw=0.4118, running_loss=0.3842, LR=0.000100
[2025-08-11 02:31:06,095][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100908] [Batch 01224/03692] [00:10:57/00:22:04, 0.537s/it]: train_loss_raw=0.3863, running_loss=0.3819, LR=0.000100
[2025-08-11 02:31:12,612][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100920] [Batch 01236/03692] [00:11:03/00:21:58, 0.537s/it]: train_loss_raw=0.3412, running_loss=0.3820, LR=0.000100
[2025-08-11 02:31:18,736][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100932] [Batch 01248/03692] [00:11:09/00:21:51, 0.537s/it]: train_loss_raw=0.3654, running_loss=0.3821, LR=0.000100
[2025-08-11 02:31:24,811][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100944] [Batch 01260/03692] [00:11:15/00:21:44, 0.536s/it]: train_loss_raw=0.3222, running_loss=0.3814, LR=0.000100
[2025-08-11 02:31:30,987][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100956] [Batch 01272/03692] [00:11:21/00:21:37, 0.536s/it]: train_loss_raw=0.3866, running_loss=0.3839, LR=0.000100
[2025-08-11 02:31:37,202][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100968] [Batch 01284/03692] [00:11:28/00:21:30, 0.536s/it]: train_loss_raw=0.4053, running_loss=0.3856, LR=0.000100
[2025-08-11 02:31:43,167][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100980] [Batch 01296/03692] [00:11:34/00:21:23, 0.536s/it]: train_loss_raw=0.3883, running_loss=0.3843, LR=0.000100
[2025-08-11 02:31:49,442][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100992] [Batch 01308/03692] [00:11:40/00:21:16, 0.536s/it]: train_loss_raw=0.3505, running_loss=0.3814, LR=0.000100
[2025-08-11 02:31:55,970][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101004] [Batch 01320/03692] [00:11:46/00:21:10, 0.536s/it]: train_loss_raw=0.3348, running_loss=0.3821, LR=0.000100
[2025-08-11 02:32:02,091][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101016] [Batch 01332/03692] [00:11:53/00:21:03, 0.535s/it]: train_loss_raw=0.5136, running_loss=0.3855, LR=0.000100
[2025-08-11 02:32:08,567][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101028] [Batch 01344/03692] [00:11:59/00:20:57, 0.535s/it]: train_loss_raw=0.4641, running_loss=0.3861, LR=0.000100
[2025-08-11 02:32:15,068][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101040] [Batch 01356/03692] [00:12:06/00:20:50, 0.535s/it]: train_loss_raw=0.3223, running_loss=0.3856, LR=0.000100
[2025-08-11 02:32:21,169][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101052] [Batch 01368/03692] [00:12:12/00:20:43, 0.535s/it]: train_loss_raw=0.4182, running_loss=0.3814, LR=0.000100
[2025-08-11 02:32:27,268][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101064] [Batch 01380/03692] [00:12:18/00:20:36, 0.535s/it]: train_loss_raw=0.3429, running_loss=0.3806, LR=0.000100
[2025-08-11 02:32:33,475][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101076] [Batch 01392/03692] [00:12:24/00:20:30, 0.535s/it]: train_loss_raw=0.4413, running_loss=0.3809, LR=0.000100
[2025-08-11 02:32:39,548][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101088] [Batch 01404/03692] [00:12:30/00:20:23, 0.535s/it]: train_loss_raw=0.4459, running_loss=0.3821, LR=0.000100
[2025-08-11 02:32:46,029][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101100] [Batch 01416/03692] [00:12:37/00:20:16, 0.535s/it]: train_loss_raw=0.3241, running_loss=0.3820, LR=0.000100
[2025-08-11 02:32:52,597][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101112] [Batch 01428/03692] [00:12:43/00:20:10, 0.535s/it]: train_loss_raw=0.5523, running_loss=0.3827, LR=0.000100
[2025-08-11 02:32:59,147][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101124] [Batch 01440/03692] [00:12:50/00:20:04, 0.535s/it]: train_loss_raw=0.3498, running_loss=0.3811, LR=0.000100
[2025-08-11 02:33:05,677][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101136] [Batch 01452/03692] [00:12:56/00:19:58, 0.535s/it]: train_loss_raw=0.3115, running_loss=0.3824, LR=0.000100
[2025-08-11 02:33:12,094][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101148] [Batch 01464/03692] [00:13:03/00:19:51, 0.535s/it]: train_loss_raw=0.3718, running_loss=0.3800, LR=0.000100
[2025-08-11 02:33:18,426][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101160] [Batch 01476/03692] [00:13:09/00:19:45, 0.535s/it]: train_loss_raw=0.4479, running_loss=0.3814, LR=0.000100
[2025-08-11 02:33:24,968][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101172] [Batch 01488/03692] [00:13:15/00:19:38, 0.535s/it]: train_loss_raw=0.4527, running_loss=0.3835, LR=0.000100
[2025-08-11 02:33:31,531][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101184] [Batch 01500/03692] [00:13:22/00:19:32, 0.535s/it]: train_loss_raw=0.5361, running_loss=0.3835, LR=0.000100
[2025-08-11 02:33:37,786][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101196] [Batch 01512/03692] [00:13:28/00:19:26, 0.535s/it]: train_loss_raw=0.4189, running_loss=0.3824, LR=0.000100
[2025-08-11 02:33:43,940][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101208] [Batch 01524/03692] [00:13:34/00:19:19, 0.535s/it]: train_loss_raw=0.4231, running_loss=0.3822, LR=0.000100
[2025-08-11 02:33:50,048][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101220] [Batch 01536/03692] [00:13:41/00:19:12, 0.535s/it]: train_loss_raw=0.3038, running_loss=0.3835, LR=0.000100
[2025-08-11 02:33:56,148][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101232] [Batch 01548/03692] [00:13:47/00:19:05, 0.534s/it]: train_loss_raw=0.3365, running_loss=0.3826, LR=0.000100
[2025-08-11 02:34:02,231][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101244] [Batch 01560/03692] [00:13:53/00:18:58, 0.534s/it]: train_loss_raw=0.4177, running_loss=0.3819, LR=0.000100
[2025-08-11 02:34:08,289][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101256] [Batch 01572/03692] [00:13:59/00:18:51, 0.534s/it]: train_loss_raw=0.3175, running_loss=0.3792, LR=0.000100
[2025-08-11 02:34:14,283][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101268] [Batch 01584/03692] [00:14:05/00:18:44, 0.534s/it]: train_loss_raw=0.3219, running_loss=0.3766, LR=0.000100
[2025-08-11 02:34:20,372][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101280] [Batch 01596/03692] [00:14:11/00:18:38, 0.533s/it]: train_loss_raw=0.3665, running_loss=0.3738, LR=0.000100
[2025-08-11 02:34:26,680][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101292] [Batch 01608/03692] [00:14:17/00:18:31, 0.533s/it]: train_loss_raw=0.3605, running_loss=0.3780, LR=0.000100
[2025-08-11 02:34:32,851][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101304] [Batch 01620/03692] [00:14:23/00:18:24, 0.533s/it]: train_loss_raw=0.4763, running_loss=0.3793, LR=0.000100
[2025-08-11 02:34:39,052][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101316] [Batch 01632/03692] [00:14:30/00:18:18, 0.533s/it]: train_loss_raw=0.4693, running_loss=0.3813, LR=0.000100
[2025-08-11 02:34:45,188][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101328] [Batch 01644/03692] [00:14:36/00:18:11, 0.533s/it]: train_loss_raw=0.3785, running_loss=0.3829, LR=0.000100
[2025-08-11 02:34:51,239][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101340] [Batch 01656/03692] [00:14:42/00:18:04, 0.533s/it]: train_loss_raw=0.3166, running_loss=0.3838, LR=0.000100
[2025-08-11 02:34:57,460][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101352] [Batch 01668/03692] [00:14:48/00:17:58, 0.533s/it]: train_loss_raw=0.3002, running_loss=0.3841, LR=0.000100
[2025-08-11 02:35:03,780][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101364] [Batch 01680/03692] [00:14:54/00:17:51, 0.533s/it]: train_loss_raw=0.4409, running_loss=0.3808, LR=0.000100
[2025-08-11 02:35:10,022][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101376] [Batch 01692/03692] [00:15:01/00:17:45, 0.533s/it]: train_loss_raw=0.2867, running_loss=0.3786, LR=0.000100
[2025-08-11 02:35:16,369][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101388] [Batch 01704/03692] [00:15:07/00:17:38, 0.532s/it]: train_loss_raw=0.4228, running_loss=0.3774, LR=0.000100
[2025-08-11 02:35:22,851][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101400] [Batch 01716/03692] [00:15:13/00:17:32, 0.533s/it]: train_loss_raw=0.3028, running_loss=0.3772, LR=0.000100
[2025-08-11 02:35:29,117][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101412] [Batch 01728/03692] [00:15:20/00:17:25, 0.532s/it]: train_loss_raw=0.4422, running_loss=0.3764, LR=0.000100
[2025-08-11 02:35:35,329][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101424] [Batch 01740/03692] [00:15:26/00:17:19, 0.532s/it]: train_loss_raw=0.4286, running_loss=0.3795, LR=0.000100
[2025-08-11 02:35:41,559][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101436] [Batch 01752/03692] [00:15:32/00:17:12, 0.532s/it]: train_loss_raw=0.3690, running_loss=0.3787, LR=0.000100
[2025-08-11 02:35:47,582][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101448] [Batch 01764/03692] [00:15:38/00:17:05, 0.532s/it]: train_loss_raw=0.3365, running_loss=0.3762, LR=0.000100
[2025-08-11 02:35:53,608][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101460] [Batch 01776/03692] [00:15:44/00:16:59, 0.532s/it]: train_loss_raw=0.3048, running_loss=0.3731, LR=0.000100
[2025-08-11 02:35:59,684][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101472] [Batch 01788/03692] [00:15:50/00:16:52, 0.532s/it]: train_loss_raw=0.4087, running_loss=0.3756, LR=0.000100
[2025-08-11 02:36:06,130][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101484] [Batch 01800/03692] [00:15:57/00:16:46, 0.532s/it]: train_loss_raw=0.3570, running_loss=0.3755, LR=0.000100
[2025-08-11 02:36:12,259][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101496] [Batch 01812/03692] [00:16:03/00:16:39, 0.532s/it]: train_loss_raw=0.3789, running_loss=0.3781, LR=0.000100
[2025-08-11 02:36:18,470][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101508] [Batch 01824/03692] [00:16:09/00:16:32, 0.532s/it]: train_loss_raw=0.4399, running_loss=0.3766, LR=0.000100
[2025-08-11 02:36:24,929][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101520] [Batch 01836/03692] [00:16:15/00:16:26, 0.532s/it]: train_loss_raw=0.3649, running_loss=0.3767, LR=0.000100
[2025-08-11 02:36:31,416][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101532] [Batch 01848/03692] [00:16:22/00:16:20, 0.532s/it]: train_loss_raw=0.4615, running_loss=0.3772, LR=0.000100
[2025-08-11 02:36:37,613][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101544] [Batch 01860/03692] [00:16:28/00:16:13, 0.532s/it]: train_loss_raw=0.3081, running_loss=0.3772, LR=0.000100
[2025-08-11 02:36:43,641][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101556] [Batch 01872/03692] [00:16:34/00:16:07, 0.531s/it]: train_loss_raw=0.3040, running_loss=0.3810, LR=0.000100
[2025-08-11 02:36:49,613][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101568] [Batch 01884/03692] [00:16:40/00:16:00, 0.531s/it]: train_loss_raw=0.3625, running_loss=0.3808, LR=0.000100
[2025-08-11 02:36:55,692][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101580] [Batch 01896/03692] [00:16:46/00:15:53, 0.531s/it]: train_loss_raw=0.3354, running_loss=0.3801, LR=0.000100
[2025-08-11 02:37:01,696][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101592] [Batch 01908/03692] [00:16:52/00:15:46, 0.531s/it]: train_loss_raw=0.3177, running_loss=0.3786, LR=0.000100
[2025-08-11 02:37:07,838][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101604] [Batch 01920/03692] [00:16:58/00:15:40, 0.531s/it]: train_loss_raw=0.4043, running_loss=0.3820, LR=0.000100
[2025-08-11 02:37:14,084][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101616] [Batch 01932/03692] [00:17:05/00:15:33, 0.531s/it]: train_loss_raw=0.2299, running_loss=0.3809, LR=0.000100
[2025-08-11 02:37:20,650][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101628] [Batch 01944/03692] [00:17:11/00:15:27, 0.531s/it]: train_loss_raw=0.3962, running_loss=0.3804, LR=0.000100
[2025-08-11 02:37:26,836][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101640] [Batch 01956/03692] [00:17:17/00:15:21, 0.531s/it]: train_loss_raw=0.4152, running_loss=0.3797, LR=0.000100
[2025-08-11 02:37:32,973][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101652] [Batch 01968/03692] [00:17:23/00:15:14, 0.530s/it]: train_loss_raw=0.4806, running_loss=0.3814, LR=0.000100
[2025-08-11 02:37:39,236][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101664] [Batch 01980/03692] [00:17:30/00:15:08, 0.530s/it]: train_loss_raw=0.3779, running_loss=0.3792, LR=0.000100
[2025-08-11 02:37:45,789][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101676] [Batch 01992/03692] [00:17:36/00:15:01, 0.531s/it]: train_loss_raw=0.4434, running_loss=0.3829, LR=0.000100
[2025-08-11 02:37:52,346][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101688] [Batch 02004/03692] [00:17:43/00:14:55, 0.531s/it]: train_loss_raw=0.3409, running_loss=0.3815, LR=0.000100
[2025-08-11 02:37:58,694][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101700] [Batch 02016/03692] [00:17:49/00:14:49, 0.531s/it]: train_loss_raw=0.3815, running_loss=0.3862, LR=0.000100
[2025-08-11 02:38:04,917][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101712] [Batch 02028/03692] [00:17:55/00:14:42, 0.531s/it]: train_loss_raw=0.3310, running_loss=0.3877, LR=0.000100
[2025-08-11 02:38:11,020][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101724] [Batch 02040/03692] [00:18:02/00:14:36, 0.530s/it]: train_loss_raw=0.4598, running_loss=0.3897, LR=0.000100
[2025-08-11 02:38:16,979][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101736] [Batch 02052/03692] [00:18:07/00:14:29, 0.530s/it]: train_loss_raw=0.3142, running_loss=0.3886, LR=0.000100
[2025-08-11 02:38:23,182][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101748] [Batch 02064/03692] [00:18:14/00:14:23, 0.530s/it]: train_loss_raw=0.3463, running_loss=0.3881, LR=0.000100
[2025-08-11 02:38:29,256][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101760] [Batch 02076/03692] [00:18:20/00:14:16, 0.530s/it]: train_loss_raw=0.3303, running_loss=0.3855, LR=0.000100
[2025-08-11 02:38:35,465][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101772] [Batch 02088/03692] [00:18:26/00:14:09, 0.530s/it]: train_loss_raw=0.4159, running_loss=0.3854, LR=0.000100
[2025-08-11 02:38:41,846][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101784] [Batch 02100/03692] [00:18:32/00:14:03, 0.530s/it]: train_loss_raw=0.3599, running_loss=0.3861, LR=0.000100
[2025-08-11 02:38:47,851][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101796] [Batch 02112/03692] [00:18:38/00:13:57, 0.530s/it]: train_loss_raw=0.4643, running_loss=0.3876, LR=0.000100
[2025-08-11 02:38:53,896][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101808] [Batch 02124/03692] [00:18:44/00:13:50, 0.530s/it]: train_loss_raw=0.4208, running_loss=0.3874, LR=0.000100
[2025-08-11 02:39:00,348][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101820] [Batch 02136/03692] [00:18:51/00:13:44, 0.530s/it]: train_loss_raw=0.3377, running_loss=0.3822, LR=0.000100
[2025-08-11 02:39:06,852][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101832] [Batch 02148/03692] [00:18:57/00:13:37, 0.530s/it]: train_loss_raw=0.3247, running_loss=0.3805, LR=0.000100
[2025-08-11 02:39:20,133][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101844] [Batch 02160/03692] [00:19:11/00:13:36, 0.533s/it]: train_loss_raw=0.3364, running_loss=0.3807, LR=0.000100
[2025-08-11 02:39:26,432][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101856] [Batch 02172/03692] [00:19:17/00:13:29, 0.533s/it]: train_loss_raw=0.3390, running_loss=0.3804, LR=0.000100
[2025-08-11 02:39:32,430][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101868] [Batch 02184/03692] [00:19:23/00:13:23, 0.533s/it]: train_loss_raw=0.3755, running_loss=0.3814, LR=0.000100
[2025-08-11 02:39:38,427][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101880] [Batch 02196/03692] [00:19:29/00:13:16, 0.533s/it]: train_loss_raw=0.3945, running_loss=0.3843, LR=0.000100
[2025-08-11 02:39:44,386][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101892] [Batch 02208/03692] [00:19:35/00:13:09, 0.532s/it]: train_loss_raw=0.2965, running_loss=0.3832, LR=0.000100
[2025-08-11 02:39:50,451][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101904] [Batch 02220/03692] [00:19:41/00:13:03, 0.532s/it]: train_loss_raw=0.3099, running_loss=0.3817, LR=0.000100
[2025-08-11 02:39:56,651][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101916] [Batch 02232/03692] [00:19:47/00:12:56, 0.532s/it]: train_loss_raw=0.4892, running_loss=0.3833, LR=0.000100
[2025-08-11 02:40:02,878][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101928] [Batch 02244/03692] [00:19:53/00:12:50, 0.532s/it]: train_loss_raw=0.3999, running_loss=0.3858, LR=0.000100
[2025-08-11 02:40:09,300][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101940] [Batch 02256/03692] [00:20:00/00:12:44, 0.532s/it]: train_loss_raw=0.3751, running_loss=0.3855, LR=0.000100
[2025-08-11 02:40:15,768][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101952] [Batch 02268/03692] [00:20:06/00:12:37, 0.532s/it]: train_loss_raw=0.4486, running_loss=0.3870, LR=0.000100
[2025-08-11 02:40:22,366][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101964] [Batch 02280/03692] [00:20:13/00:12:31, 0.532s/it]: train_loss_raw=0.4192, running_loss=0.3858, LR=0.000100
[2025-08-11 02:40:28,502][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101976] [Batch 02292/03692] [00:20:19/00:12:24, 0.532s/it]: train_loss_raw=0.4016, running_loss=0.3880, LR=0.000100
[2025-08-11 02:40:34,670][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101988] [Batch 02304/03692] [00:20:25/00:12:18, 0.532s/it]: train_loss_raw=0.3559, running_loss=0.3880, LR=0.000100
[2025-08-11 02:40:40,725][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102000] [Batch 02316/03692] [00:20:31/00:12:11, 0.532s/it]: train_loss_raw=0.3343, running_loss=0.3866, LR=0.000100
[2025-08-11 02:40:51,322][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102012] [Batch 02328/03692] [00:20:42/00:12:07, 0.534s/it]: train_loss_raw=0.3849, running_loss=0.3868, LR=0.000100
[2025-08-11 02:40:57,365][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102024] [Batch 02340/03692] [00:20:48/00:12:01, 0.533s/it]: train_loss_raw=0.3121, running_loss=0.3861, LR=0.000100
[2025-08-11 02:41:03,614][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102036] [Batch 02352/03692] [00:20:54/00:11:54, 0.533s/it]: train_loss_raw=0.3175, running_loss=0.3862, LR=0.000100
[2025-08-11 02:41:10,090][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102048] [Batch 02364/03692] [00:21:01/00:11:48, 0.533s/it]: train_loss_raw=0.3488, running_loss=0.3868, LR=0.000100
[2025-08-11 02:41:16,594][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102060] [Batch 02376/03692] [00:21:07/00:11:42, 0.534s/it]: train_loss_raw=0.4396, running_loss=0.3882, LR=0.000100
[2025-08-11 02:41:23,084][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102072] [Batch 02388/03692] [00:21:14/00:11:35, 0.534s/it]: train_loss_raw=0.4040, running_loss=0.3888, LR=0.000100
[2025-08-11 02:41:29,266][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102084] [Batch 02400/03692] [00:21:20/00:11:29, 0.533s/it]: train_loss_raw=0.3725, running_loss=0.3891, LR=0.000100
[2025-08-11 02:41:35,616][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102096] [Batch 02412/03692] [00:21:26/00:11:22, 0.533s/it]: train_loss_raw=0.3759, running_loss=0.3874, LR=0.000100
[2025-08-11 02:41:42,073][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102108] [Batch 02424/03692] [00:21:33/00:11:16, 0.533s/it]: train_loss_raw=0.3720, running_loss=0.3863, LR=0.000100
[2025-08-11 02:41:48,561][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102120] [Batch 02436/03692] [00:21:39/00:11:10, 0.533s/it]: train_loss_raw=0.3634, running_loss=0.3858, LR=0.000100
[2025-08-11 02:41:55,015][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102132] [Batch 02448/03692] [00:21:46/00:11:03, 0.534s/it]: train_loss_raw=0.4012, running_loss=0.3833, LR=0.000100
[2025-08-11 02:42:01,473][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102144] [Batch 02460/03692] [00:21:52/00:10:57, 0.534s/it]: train_loss_raw=0.3842, running_loss=0.3814, LR=0.000100
[2025-08-11 02:42:07,981][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102156] [Batch 02472/03692] [00:21:58/00:10:50, 0.534s/it]: train_loss_raw=0.4250, running_loss=0.3812, LR=0.000100
[2025-08-11 02:42:14,424][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102168] [Batch 02484/03692] [00:22:05/00:10:44, 0.534s/it]: train_loss_raw=0.3920, running_loss=0.3809, LR=0.000100
[2025-08-11 02:42:20,638][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102180] [Batch 02496/03692] [00:22:11/00:10:38, 0.534s/it]: train_loss_raw=0.3695, running_loss=0.3803, LR=0.000100
[2025-08-11 02:42:26,677][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102192] [Batch 02508/03692] [00:22:17/00:10:31, 0.533s/it]: train_loss_raw=0.3912, running_loss=0.3796, LR=0.000100
[2025-08-11 02:42:33,014][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102204] [Batch 02520/03692] [00:22:24/00:10:25, 0.533s/it]: train_loss_raw=0.3800, running_loss=0.3791, LR=0.000100
[2025-08-11 02:42:39,425][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102216] [Batch 02532/03692] [00:22:30/00:10:18, 0.533s/it]: train_loss_raw=0.4032, running_loss=0.3761, LR=0.000100
[2025-08-11 02:42:45,598][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102228] [Batch 02544/03692] [00:22:36/00:10:12, 0.533s/it]: train_loss_raw=0.3085, running_loss=0.3757, LR=0.000100
[2025-08-11 02:42:51,669][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102240] [Batch 02556/03692] [00:22:42/00:10:05, 0.533s/it]: train_loss_raw=0.3831, running_loss=0.3776, LR=0.000100
[2025-08-11 02:42:58,001][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102252] [Batch 02568/03692] [00:22:49/00:09:59, 0.533s/it]: train_loss_raw=0.3576, running_loss=0.3792, LR=0.000100
[2025-08-11 02:43:04,435][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102264] [Batch 02580/03692] [00:22:55/00:09:52, 0.533s/it]: train_loss_raw=0.4381, running_loss=0.3832, LR=0.000100
[2025-08-11 02:43:10,738][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102276] [Batch 02592/03692] [00:23:01/00:09:46, 0.533s/it]: train_loss_raw=0.4472, running_loss=0.3829, LR=0.000100
[2025-08-11 02:43:16,991][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102288] [Batch 02604/03692] [00:23:07/00:09:39, 0.533s/it]: train_loss_raw=0.3730, running_loss=0.3819, LR=0.000100
[2025-08-11 02:43:23,168][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102300] [Batch 02616/03692] [00:23:14/00:09:33, 0.533s/it]: train_loss_raw=0.3595, running_loss=0.3844, LR=0.000100
[2025-08-11 02:43:29,324][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102312] [Batch 02628/03692] [00:23:20/00:09:26, 0.533s/it]: train_loss_raw=0.3270, running_loss=0.3856, LR=0.000100
[2025-08-11 02:43:35,497][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102324] [Batch 02640/03692] [00:23:26/00:09:20, 0.533s/it]: train_loss_raw=0.4186, running_loss=0.3874, LR=0.000100
[2025-08-11 02:43:41,685][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102336] [Batch 02652/03692] [00:23:32/00:09:13, 0.533s/it]: train_loss_raw=0.3655, running_loss=0.3890, LR=0.000100
[2025-08-11 02:43:47,826][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102348] [Batch 02664/03692] [00:23:38/00:09:07, 0.533s/it]: train_loss_raw=0.2968, running_loss=0.3875, LR=0.000100
[2025-08-11 02:43:54,306][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102360] [Batch 02676/03692] [00:23:45/00:09:01, 0.533s/it]: train_loss_raw=0.3949, running_loss=0.3853, LR=0.000100
[2025-08-11 02:44:00,817][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102372] [Batch 02688/03692] [00:23:51/00:08:54, 0.533s/it]: train_loss_raw=0.3198, running_loss=0.3828, LR=0.000100
[2025-08-11 02:44:07,174][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102384] [Batch 02700/03692] [00:23:58/00:08:48, 0.533s/it]: train_loss_raw=0.3432, running_loss=0.3837, LR=0.000100
[2025-08-11 02:44:13,609][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102396] [Batch 02712/03692] [00:24:04/00:08:42, 0.533s/it]: train_loss_raw=0.3521, running_loss=0.3835, LR=0.000100
[2025-08-11 02:44:20,144][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102408] [Batch 02724/03692] [00:24:11/00:08:35, 0.533s/it]: train_loss_raw=0.3882, running_loss=0.3879, LR=0.000100
[2025-08-11 02:44:26,512][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102420] [Batch 02736/03692] [00:24:17/00:08:29, 0.533s/it]: train_loss_raw=0.3802, running_loss=0.3861, LR=0.000100
[2025-08-11 02:44:32,921][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102432] [Batch 02748/03692] [00:24:23/00:08:22, 0.533s/it]: train_loss_raw=0.4540, running_loss=0.3846, LR=0.000100
[2025-08-11 02:44:39,365][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102444] [Batch 02760/03692] [00:24:30/00:08:16, 0.533s/it]: train_loss_raw=0.2832, running_loss=0.3862, LR=0.000100
[2025-08-11 02:44:45,824][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102456] [Batch 02772/03692] [00:24:36/00:08:10, 0.533s/it]: train_loss_raw=0.4048, running_loss=0.3889, LR=0.000100
[2025-08-11 02:44:52,290][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102468] [Batch 02784/03692] [00:24:43/00:08:03, 0.533s/it]: train_loss_raw=0.4130, running_loss=0.3869, LR=0.000100
[2025-08-11 02:44:58,844][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102480] [Batch 02796/03692] [00:24:49/00:07:57, 0.533s/it]: train_loss_raw=0.3890, running_loss=0.3871, LR=0.000100
[2025-08-11 02:45:05,266][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102492] [Batch 02808/03692] [00:24:56/00:07:51, 0.533s/it]: train_loss_raw=0.3373, running_loss=0.3870, LR=0.000100
[2025-08-11 02:45:11,725][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102504] [Batch 02820/03692] [00:25:02/00:07:44, 0.533s/it]: train_loss_raw=0.4596, running_loss=0.3877, LR=0.000100
[2025-08-11 02:45:18,144][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102516] [Batch 02832/03692] [00:25:09/00:07:38, 0.533s/it]: train_loss_raw=0.3627, running_loss=0.3890, LR=0.000100
[2025-08-11 02:45:24,481][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102528] [Batch 02844/03692] [00:25:15/00:07:31, 0.533s/it]: train_loss_raw=0.4359, running_loss=0.3898, LR=0.000100
[2025-08-11 02:45:30,827][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102540] [Batch 02856/03692] [00:25:21/00:07:25, 0.533s/it]: train_loss_raw=0.4545, running_loss=0.3893, LR=0.000100
[2025-08-11 02:45:37,221][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102552] [Batch 02868/03692] [00:25:28/00:07:19, 0.533s/it]: train_loss_raw=0.3408, running_loss=0.3882, LR=0.000100
[2025-08-11 02:45:43,623][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102564] [Batch 02880/03692] [00:25:34/00:07:12, 0.533s/it]: train_loss_raw=0.4241, running_loss=0.3877, LR=0.000100
[2025-08-11 02:45:50,015][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102576] [Batch 02892/03692] [00:25:41/00:07:06, 0.533s/it]: train_loss_raw=0.3661, running_loss=0.3897, LR=0.000100
[2025-08-11 02:45:56,487][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102588] [Batch 02904/03692] [00:25:47/00:06:59, 0.533s/it]: train_loss_raw=0.3877, running_loss=0.3876, LR=0.000100
[2025-08-11 02:46:02,825][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102600] [Batch 02916/03692] [00:25:53/00:06:53, 0.533s/it]: train_loss_raw=0.4075, running_loss=0.3869, LR=0.000100
[2025-08-11 02:46:08,923][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102612] [Batch 02928/03692] [00:25:59/00:06:47, 0.533s/it]: train_loss_raw=0.4972, running_loss=0.3904, LR=0.000100
[2025-08-11 02:46:15,288][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102624] [Batch 02940/03692] [00:26:06/00:06:40, 0.533s/it]: train_loss_raw=0.4117, running_loss=0.3896, LR=0.000100
[2025-08-11 02:46:21,693][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102636] [Batch 02952/03692] [00:26:12/00:06:34, 0.533s/it]: train_loss_raw=0.4053, running_loss=0.3869, LR=0.000100
[2025-08-11 02:46:28,097][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102648] [Batch 02964/03692] [00:26:19/00:06:27, 0.533s/it]: train_loss_raw=0.4565, running_loss=0.3864, LR=0.000100
[2025-08-11 02:46:34,473][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102660] [Batch 02976/03692] [00:26:25/00:06:21, 0.533s/it]: train_loss_raw=0.3522, running_loss=0.3852, LR=0.000100
[2025-08-11 02:46:40,812][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102672] [Batch 02988/03692] [00:26:31/00:06:15, 0.533s/it]: train_loss_raw=0.4585, running_loss=0.3837, LR=0.000100
[2025-08-11 02:46:47,162][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102684] [Batch 03000/03692] [00:26:38/00:06:08, 0.533s/it]: train_loss_raw=0.4080, running_loss=0.3803, LR=0.000100
[2025-08-11 02:46:53,609][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102696] [Batch 03012/03692] [00:26:44/00:06:02, 0.533s/it]: train_loss_raw=0.4462, running_loss=0.3847, LR=0.000100
[2025-08-11 02:46:59,989][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102708] [Batch 03024/03692] [00:26:50/00:05:55, 0.533s/it]: train_loss_raw=0.4374, running_loss=0.3847, LR=0.000100
[2025-08-11 02:47:06,374][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102720] [Batch 03036/03692] [00:26:57/00:05:49, 0.533s/it]: train_loss_raw=0.3255, running_loss=0.3824, LR=0.000100
[2025-08-11 02:47:12,731][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102732] [Batch 03048/03692] [00:27:03/00:05:43, 0.533s/it]: train_loss_raw=0.3250, running_loss=0.3832, LR=0.000100
[2025-08-11 02:47:19,139][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102744] [Batch 03060/03692] [00:27:10/00:05:36, 0.533s/it]: train_loss_raw=0.4591, running_loss=0.3818, LR=0.000100
[2025-08-11 02:47:25,443][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102756] [Batch 03072/03692] [00:27:16/00:05:30, 0.533s/it]: train_loss_raw=0.3143, running_loss=0.3850, LR=0.000100
[2025-08-11 02:47:31,539][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102768] [Batch 03084/03692] [00:27:22/00:05:23, 0.533s/it]: train_loss_raw=0.3498, running_loss=0.3842, LR=0.000100
[2025-08-11 02:47:37,593][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102780] [Batch 03096/03692] [00:27:28/00:05:17, 0.532s/it]: train_loss_raw=0.4566, running_loss=0.3825, LR=0.000100
[2025-08-11 02:47:43,746][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102792] [Batch 03108/03692] [00:27:34/00:05:10, 0.532s/it]: train_loss_raw=0.4840, running_loss=0.3828, LR=0.000100
[2025-08-11 02:47:50,206][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102804] [Batch 03120/03692] [00:27:41/00:05:04, 0.532s/it]: train_loss_raw=0.3939, running_loss=0.3865, LR=0.000100
[2025-08-11 02:47:56,561][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102816] [Batch 03132/03692] [00:27:47/00:04:58, 0.532s/it]: train_loss_raw=0.3844, running_loss=0.3861, LR=0.000100
[2025-08-11 02:48:02,864][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102828] [Batch 03144/03692] [00:27:53/00:04:51, 0.532s/it]: train_loss_raw=0.4320, running_loss=0.3865, LR=0.000100
[2025-08-11 02:48:09,092][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102840] [Batch 03156/03692] [00:28:00/00:04:45, 0.532s/it]: train_loss_raw=0.3580, running_loss=0.3851, LR=0.000100
[2025-08-11 02:48:15,418][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102852] [Batch 03168/03692] [00:28:06/00:04:38, 0.532s/it]: train_loss_raw=0.3459, running_loss=0.3868, LR=0.000100
[2025-08-11 02:48:21,901][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102864] [Batch 03180/03692] [00:28:12/00:04:32, 0.532s/it]: train_loss_raw=0.4215, running_loss=0.3884, LR=0.000100
[2025-08-11 02:48:28,358][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102876] [Batch 03192/03692] [00:28:19/00:04:26, 0.532s/it]: train_loss_raw=0.3652, running_loss=0.3883, LR=0.000100
[2025-08-11 02:48:34,761][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102888] [Batch 03204/03692] [00:28:25/00:04:19, 0.532s/it]: train_loss_raw=0.3781, running_loss=0.3879, LR=0.000100
[2025-08-11 02:48:41,173][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102900] [Batch 03216/03692] [00:28:32/00:04:13, 0.532s/it]: train_loss_raw=0.3284, running_loss=0.3893, LR=0.000100
[2025-08-11 02:48:47,731][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102912] [Batch 03228/03692] [00:28:38/00:04:07, 0.532s/it]: train_loss_raw=0.4002, running_loss=0.3874, LR=0.000100
[2025-08-11 02:48:54,141][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102924] [Batch 03240/03692] [00:28:45/00:04:00, 0.532s/it]: train_loss_raw=0.4251, running_loss=0.3883, LR=0.000100
[2025-08-11 02:49:00,513][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102936] [Batch 03252/03692] [00:28:51/00:03:54, 0.532s/it]: train_loss_raw=0.3683, running_loss=0.3870, LR=0.000100
[2025-08-11 02:49:06,860][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102948] [Batch 03264/03692] [00:28:57/00:03:47, 0.532s/it]: train_loss_raw=0.4174, running_loss=0.3844, LR=0.000100
[2025-08-11 02:49:13,200][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102960] [Batch 03276/03692] [00:29:04/00:03:41, 0.532s/it]: train_loss_raw=0.5116, running_loss=0.3851, LR=0.000100
[2025-08-11 02:49:19,578][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102972] [Batch 03288/03692] [00:29:10/00:03:35, 0.532s/it]: train_loss_raw=0.3535, running_loss=0.3832, LR=0.000100
[2025-08-11 02:49:26,017][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102984] [Batch 03300/03692] [00:29:17/00:03:28, 0.532s/it]: train_loss_raw=0.4334, running_loss=0.3853, LR=0.000100
[2025-08-11 02:49:32,599][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102996] [Batch 03312/03692] [00:29:23/00:03:22, 0.532s/it]: train_loss_raw=0.3180, running_loss=0.3850, LR=0.000100
[2025-08-11 02:49:38,943][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103008] [Batch 03324/03692] [00:29:29/00:03:15, 0.532s/it]: train_loss_raw=0.3787, running_loss=0.3863, LR=0.000100
[2025-08-11 02:49:45,363][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103020] [Batch 03336/03692] [00:29:36/00:03:09, 0.532s/it]: train_loss_raw=0.3076, running_loss=0.3855, LR=0.000100
[2025-08-11 02:49:51,798][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103032] [Batch 03348/03692] [00:29:42/00:03:03, 0.532s/it]: train_loss_raw=0.4629, running_loss=0.3877, LR=0.000100
[2025-08-11 02:49:58,304][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103044] [Batch 03360/03692] [00:29:49/00:02:56, 0.533s/it]: train_loss_raw=0.3669, running_loss=0.3865, LR=0.000100
[2025-08-11 02:50:04,871][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103056] [Batch 03372/03692] [00:29:55/00:02:50, 0.533s/it]: train_loss_raw=0.4063, running_loss=0.3846, LR=0.000100
[2025-08-11 02:50:11,332][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103068] [Batch 03384/03692] [00:30:02/00:02:44, 0.533s/it]: train_loss_raw=0.3169, running_loss=0.3824, LR=0.000100
[2025-08-11 02:50:17,735][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103080] [Batch 03396/03692] [00:30:08/00:02:37, 0.533s/it]: train_loss_raw=0.3921, running_loss=0.3788, LR=0.000100
[2025-08-11 02:50:24,138][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103092] [Batch 03408/03692] [00:30:15/00:02:31, 0.533s/it]: train_loss_raw=0.3631, running_loss=0.3790, LR=0.000100
[2025-08-11 02:50:30,530][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103104] [Batch 03420/03692] [00:30:21/00:02:24, 0.533s/it]: train_loss_raw=0.3823, running_loss=0.3804, LR=0.000100
[2025-08-11 02:50:36,895][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103116] [Batch 03432/03692] [00:30:27/00:02:18, 0.533s/it]: train_loss_raw=0.4690, running_loss=0.3820, LR=0.000100
[2025-08-11 02:50:43,324][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103128] [Batch 03444/03692] [00:30:34/00:02:12, 0.533s/it]: train_loss_raw=0.3693, running_loss=0.3816, LR=0.000100
[2025-08-11 02:50:49,788][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103140] [Batch 03456/03692] [00:30:40/00:02:05, 0.533s/it]: train_loss_raw=0.4087, running_loss=0.3847, LR=0.000100
[2025-08-11 02:50:56,288][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103152] [Batch 03468/03692] [00:30:47/00:01:59, 0.533s/it]: train_loss_raw=0.4723, running_loss=0.3842, LR=0.000100
[2025-08-11 02:51:02,758][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103164] [Batch 03480/03692] [00:30:53/00:01:52, 0.533s/it]: train_loss_raw=0.3632, running_loss=0.3861, LR=0.000100
[2025-08-11 02:51:09,239][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103176] [Batch 03492/03692] [00:31:00/00:01:46, 0.533s/it]: train_loss_raw=0.3202, running_loss=0.3863, LR=0.000100
[2025-08-11 02:51:15,660][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103188] [Batch 03504/03692] [00:31:06/00:01:40, 0.533s/it]: train_loss_raw=0.3940, running_loss=0.3894, LR=0.000100
[2025-08-11 02:51:22,152][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103200] [Batch 03516/03692] [00:31:13/00:01:33, 0.533s/it]: train_loss_raw=0.3087, running_loss=0.3877, LR=0.000100
[2025-08-11 02:51:28,645][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103212] [Batch 03528/03692] [00:31:19/00:01:27, 0.533s/it]: train_loss_raw=0.4190, running_loss=0.3885, LR=0.000100
[2025-08-11 02:51:35,109][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103224] [Batch 03540/03692] [00:31:26/00:01:20, 0.533s/it]: train_loss_raw=0.2663, running_loss=0.3867, LR=0.000100
[2025-08-11 02:51:41,203][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103236] [Batch 03552/03692] [00:31:32/00:01:14, 0.533s/it]: train_loss_raw=0.3778, running_loss=0.3861, LR=0.000100
[2025-08-11 02:51:47,729][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103248] [Batch 03564/03692] [00:31:38/00:01:08, 0.533s/it]: train_loss_raw=0.3874, running_loss=0.3857, LR=0.000100
[2025-08-11 02:51:54,223][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103260] [Batch 03576/03692] [00:31:45/00:01:01, 0.533s/it]: train_loss_raw=0.3501, running_loss=0.3831, LR=0.000100
[2025-08-11 02:52:00,508][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103272] [Batch 03588/03692] [00:31:51/00:00:55, 0.533s/it]: train_loss_raw=0.4937, running_loss=0.3841, LR=0.000100
[2025-08-11 02:52:06,742][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103284] [Batch 03600/03692] [00:31:57/00:00:49, 0.533s/it]: train_loss_raw=0.3963, running_loss=0.3834, LR=0.000100
[2025-08-11 02:52:13,242][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103296] [Batch 03612/03692] [00:32:04/00:00:42, 0.533s/it]: train_loss_raw=0.3508, running_loss=0.3821, LR=0.000100
[2025-08-11 02:52:19,625][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103308] [Batch 03624/03692] [00:32:10/00:00:36, 0.533s/it]: train_loss_raw=0.3597, running_loss=0.3855, LR=0.000100
[2025-08-11 02:52:26,045][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103320] [Batch 03636/03692] [00:32:17/00:00:29, 0.533s/it]: train_loss_raw=0.4771, running_loss=0.3836, LR=0.000100
[2025-08-11 02:52:32,449][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103332] [Batch 03648/03692] [00:32:23/00:00:23, 0.533s/it]: train_loss_raw=0.4296, running_loss=0.3837, LR=0.000100
[2025-08-11 02:52:39,006][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103344] [Batch 03660/03692] [00:32:30/00:00:17, 0.533s/it]: train_loss_raw=0.3422, running_loss=0.3808, LR=0.000100
[2025-08-11 02:52:45,362][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103356] [Batch 03672/03692] [00:32:36/00:00:10, 0.533s/it]: train_loss_raw=0.4966, running_loss=0.3851, LR=0.000100
[2025-08-11 02:52:51,765][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103368] [Batch 03684/03692] [00:32:42/00:00:04, 0.533s/it]: train_loss_raw=0.3384, running_loss=0.3828, LR=0.000100
[2025-08-11 02:53:09,092][__main__][INFO] - [VALIDATION] [Epoch 27/29] Starting validation.
[2025-08-11 02:53:41,545][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 103377] [Batch 00011/00025] [00:00:32/00:00:35, 2.704s/it]
[2025-08-11 02:53:57,511][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 103377] [Batch 00023/00025] [00:00:48/00:00:02, 2.017s/it]
[2025-08-11 02:53:58,654][__main__][INFO] - [VALIDATION] [Epoch 27/29] train_loss=0.38182, valid_loss=0.54465
[2025-08-11 02:53:58,654][__main__][INFO] - [VALIDATION] [Epoch 27/29] Metrics:
[2025-08-11 02:53:58,655][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_er      0.221
[2025-08-11 02:53:58,655][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_prec    0.568
[2025-08-11 02:53:58,655][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_recall  0.574
[2025-08-11 02:53:58,655][__main__][INFO] - [VALIDATION] [Epoch 27/29] - pep_recall 0.565
[2025-08-11 02:53:58,658][__main__][INFO] - [TRAIN] [Epoch 27/29] Epoch complete, total time 15:57:57, remaining time 01:08:25, 00:34:12 per epoch
[2025-08-11 02:54:00,639][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103380] [Batch 00004/03692] [00:00:01/00:26:09, 0.425s/it]: train_loss_raw=0.3360, running_loss=0.3049, LR=0.000100
[2025-08-11 02:54:07,128][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103392] [Batch 00016/03692] [00:00:08/00:31:21, 0.512s/it]: train_loss_raw=0.3155, running_loss=0.3045, LR=0.000100
[2025-08-11 02:54:13,569][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103404] [Batch 00028/03692] [00:00:14/00:31:54, 0.523s/it]: train_loss_raw=0.4388, running_loss=0.3062, LR=0.000100
[2025-08-11 02:54:19,982][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103416] [Batch 00040/03692] [00:00:21/00:32:01, 0.526s/it]: train_loss_raw=0.2922, running_loss=0.3097, LR=0.000100
[2025-08-11 02:54:26,230][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103428] [Batch 00052/03692] [00:00:27/00:31:50, 0.525s/it]: train_loss_raw=0.2714, running_loss=0.3084, LR=0.000100
[2025-08-11 02:54:32,512][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103440] [Batch 00064/03692] [00:00:33/00:31:43, 0.525s/it]: train_loss_raw=0.2644, running_loss=0.3123, LR=0.000100
[2025-08-11 02:54:38,890][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103452] [Batch 00076/03692] [00:00:39/00:31:40, 0.526s/it]: train_loss_raw=0.2283, running_loss=0.3123, LR=0.000100
[2025-08-11 02:54:45,398][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103464] [Batch 00088/03692] [00:00:46/00:31:42, 0.528s/it]: train_loss_raw=0.3599, running_loss=0.3137, LR=0.000100
[2025-08-11 02:54:51,980][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103476] [Batch 00100/03692] [00:00:53/00:31:45, 0.530s/it]: train_loss_raw=0.2883, running_loss=0.3144, LR=0.000100
[2025-08-11 02:54:58,435][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103488] [Batch 00112/03692] [00:00:59/00:31:41, 0.531s/it]: train_loss_raw=0.3258, running_loss=0.3152, LR=0.000100
[2025-08-11 02:55:04,921][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103500] [Batch 00124/03692] [00:01:05/00:31:38, 0.532s/it]: train_loss_raw=0.2978, running_loss=0.3153, LR=0.000100
[2025-08-11 02:55:11,364][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103512] [Batch 00136/03692] [00:01:12/00:31:33, 0.533s/it]: train_loss_raw=0.2716, running_loss=0.3150, LR=0.000100
[2025-08-11 02:55:17,827][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103524] [Batch 00148/03692] [00:01:18/00:31:29, 0.533s/it]: train_loss_raw=0.3896, running_loss=0.3176, LR=0.000100
[2025-08-11 02:55:24,206][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103536] [Batch 00160/03692] [00:01:25/00:31:22, 0.533s/it]: train_loss_raw=0.2551, running_loss=0.3193, LR=0.000100
[2025-08-11 02:55:30,552][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103548] [Batch 00172/03692] [00:01:31/00:31:14, 0.533s/it]: train_loss_raw=0.3170, running_loss=0.3193, LR=0.000100
[2025-08-11 02:55:37,045][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103560] [Batch 00184/03692] [00:01:38/00:31:10, 0.533s/it]: train_loss_raw=0.2883, running_loss=0.3225, LR=0.000100
[2025-08-11 02:55:43,386][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103572] [Batch 00196/03692] [00:01:44/00:31:03, 0.533s/it]: train_loss_raw=0.2628, running_loss=0.3244, LR=0.000100
[2025-08-11 02:55:49,772][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103584] [Batch 00208/03692] [00:01:50/00:30:56, 0.533s/it]: train_loss_raw=0.3602, running_loss=0.3264, LR=0.000100
[2025-08-11 02:55:56,226][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103596] [Batch 00220/03692] [00:01:57/00:30:51, 0.533s/it]: train_loss_raw=0.3864, running_loss=0.3285, LR=0.000100
[2025-08-11 02:56:02,807][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103608] [Batch 00232/03692] [00:02:03/00:30:47, 0.534s/it]: train_loss_raw=0.3018, running_loss=0.3319, LR=0.000100
[2025-08-11 02:56:09,280][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103620] [Batch 00244/03692] [00:02:10/00:30:41, 0.534s/it]: train_loss_raw=0.2992, running_loss=0.3300, LR=0.000100
[2025-08-11 02:56:15,659][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103632] [Batch 00256/03692] [00:02:16/00:30:35, 0.534s/it]: train_loss_raw=0.3071, running_loss=0.3293, LR=0.000100
[2025-08-11 02:56:22,013][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103644] [Batch 00268/03692] [00:02:23/00:30:27, 0.534s/it]: train_loss_raw=0.3070, running_loss=0.3276, LR=0.000100
[2025-08-11 02:56:28,494][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103656] [Batch 00280/03692] [00:02:29/00:30:22, 0.534s/it]: train_loss_raw=0.3634, running_loss=0.3308, LR=0.000100
[2025-08-11 02:56:34,917][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103668] [Batch 00292/03692] [00:02:35/00:30:16, 0.534s/it]: train_loss_raw=0.3225, running_loss=0.3320, LR=0.000100
[2025-08-11 02:56:41,321][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103680] [Batch 00304/03692] [00:02:42/00:30:09, 0.534s/it]: train_loss_raw=0.4020, running_loss=0.3316, LR=0.000100
[2025-08-11 02:56:47,737][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103692] [Batch 00316/03692] [00:02:48/00:30:03, 0.534s/it]: train_loss_raw=0.2960, running_loss=0.3320, LR=0.000100
[2025-08-11 02:56:54,277][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103704] [Batch 00328/03692] [00:02:55/00:29:58, 0.535s/it]: train_loss_raw=0.3256, running_loss=0.3313, LR=0.000100
[2025-08-11 02:57:00,711][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103716] [Batch 00340/03692] [00:03:01/00:29:52, 0.535s/it]: train_loss_raw=0.3683, running_loss=0.3324, LR=0.000100
[2025-08-11 02:57:07,070][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103728] [Batch 00352/03692] [00:03:08/00:29:45, 0.534s/it]: train_loss_raw=0.3238, running_loss=0.3326, LR=0.000100
[2025-08-11 02:57:13,452][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103740] [Batch 00364/03692] [00:03:14/00:29:38, 0.534s/it]: train_loss_raw=0.3299, running_loss=0.3322, LR=0.000100
[2025-08-11 02:57:19,818][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103752] [Batch 00376/03692] [00:03:20/00:29:31, 0.534s/it]: train_loss_raw=0.3210, running_loss=0.3337, LR=0.000100
[2025-08-11 02:57:26,246][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103764] [Batch 00388/03692] [00:03:27/00:29:25, 0.534s/it]: train_loss_raw=0.3671, running_loss=0.3330, LR=0.000100
[2025-08-11 02:57:32,649][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103776] [Batch 00400/03692] [00:03:33/00:29:18, 0.534s/it]: train_loss_raw=0.2892, running_loss=0.3315, LR=0.000100
[2025-08-11 02:57:39,033][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103788] [Batch 00412/03692] [00:03:40/00:29:12, 0.534s/it]: train_loss_raw=0.4375, running_loss=0.3336, LR=0.000100
[2025-08-11 02:57:45,331][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103800] [Batch 00424/03692] [00:03:46/00:29:04, 0.534s/it]: train_loss_raw=0.3171, running_loss=0.3312, LR=0.000100
[2025-08-11 02:57:51,675][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103812] [Batch 00436/03692] [00:03:52/00:28:58, 0.534s/it]: train_loss_raw=0.3379, running_loss=0.3299, LR=0.000100
[2025-08-11 02:57:58,044][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103824] [Batch 00448/03692] [00:03:59/00:28:51, 0.534s/it]: train_loss_raw=0.4073, running_loss=0.3320, LR=0.000100
[2025-08-11 02:58:04,392][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103836] [Batch 00460/03692] [00:04:05/00:28:44, 0.534s/it]: train_loss_raw=0.3823, running_loss=0.3336, LR=0.000100
[2025-08-11 02:58:10,754][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103848] [Batch 00472/03692] [00:04:11/00:28:37, 0.534s/it]: train_loss_raw=0.3496, running_loss=0.3353, LR=0.000100
[2025-08-11 02:58:17,231][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103860] [Batch 00484/03692] [00:04:18/00:28:31, 0.534s/it]: train_loss_raw=0.3147, running_loss=0.3334, LR=0.000100
[2025-08-11 02:58:23,622][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103872] [Batch 00496/03692] [00:04:24/00:28:25, 0.534s/it]: train_loss_raw=0.4116, running_loss=0.3336, LR=0.000100
[2025-08-11 02:58:29,964][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103884] [Batch 00508/03692] [00:04:31/00:28:18, 0.534s/it]: train_loss_raw=0.3359, running_loss=0.3325, LR=0.000100
[2025-08-11 02:58:36,280][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103896] [Batch 00520/03692] [00:04:37/00:28:11, 0.533s/it]: train_loss_raw=0.3182, running_loss=0.3305, LR=0.000100
[2025-08-11 02:58:42,713][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103908] [Batch 00532/03692] [00:04:43/00:28:05, 0.533s/it]: train_loss_raw=0.3241, running_loss=0.3286, LR=0.000100
[2025-08-11 02:58:49,132][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103920] [Batch 00544/03692] [00:04:50/00:27:59, 0.533s/it]: train_loss_raw=0.3335, running_loss=0.3279, LR=0.000100
[2025-08-11 02:58:55,588][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103932] [Batch 00556/03692] [00:04:56/00:27:53, 0.534s/it]: train_loss_raw=0.4041, running_loss=0.3320, LR=0.000100
[2025-08-11 02:59:02,024][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103944] [Batch 00568/03692] [00:05:03/00:27:46, 0.534s/it]: train_loss_raw=0.3586, running_loss=0.3328, LR=0.000100
[2025-08-11 02:59:08,273][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103956] [Batch 00580/03692] [00:05:09/00:27:39, 0.533s/it]: train_loss_raw=0.3997, running_loss=0.3360, LR=0.000100
[2025-08-11 02:59:14,683][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103968] [Batch 00592/03692] [00:05:15/00:27:33, 0.533s/it]: train_loss_raw=0.3748, running_loss=0.3347, LR=0.000100
[2025-08-11 02:59:21,108][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103980] [Batch 00604/03692] [00:05:22/00:27:27, 0.533s/it]: train_loss_raw=0.3842, running_loss=0.3358, LR=0.000100
[2025-08-11 02:59:27,512][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103992] [Batch 00616/03692] [00:05:28/00:27:20, 0.533s/it]: train_loss_raw=0.2744, running_loss=0.3366, LR=0.000100
[2025-08-11 02:59:39,614][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104004] [Batch 00628/03692] [00:05:40/00:27:42, 0.542s/it]: train_loss_raw=0.4483, running_loss=0.3367, LR=0.000100
[2025-08-11 02:59:45,974][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104016] [Batch 00640/03692] [00:05:47/00:27:34, 0.542s/it]: train_loss_raw=0.3524, running_loss=0.3364, LR=0.000100
[2025-08-11 02:59:52,339][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104028] [Batch 00652/03692] [00:05:53/00:27:27, 0.542s/it]: train_loss_raw=0.3077, running_loss=0.3361, LR=0.000100
[2025-08-11 02:59:58,691][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104040] [Batch 00664/03692] [00:05:59/00:27:20, 0.542s/it]: train_loss_raw=0.3304, running_loss=0.3373, LR=0.000100
[2025-08-11 03:00:05,142][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104052] [Batch 00676/03692] [00:06:06/00:27:13, 0.542s/it]: train_loss_raw=0.3653, running_loss=0.3369, LR=0.000100
[2025-08-11 03:00:11,475][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104064] [Batch 00688/03692] [00:06:12/00:27:06, 0.541s/it]: train_loss_raw=0.3386, running_loss=0.3373, LR=0.000100
[2025-08-11 03:00:17,972][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104076] [Batch 00700/03692] [00:06:19/00:27:00, 0.541s/it]: train_loss_raw=0.2996, running_loss=0.3383, LR=0.000100
[2025-08-11 03:00:24,313][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104088] [Batch 00712/03692] [00:06:25/00:26:52, 0.541s/it]: train_loss_raw=0.3455, running_loss=0.3375, LR=0.000100
[2025-08-11 03:00:30,694][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104100] [Batch 00724/03692] [00:06:31/00:26:45, 0.541s/it]: train_loss_raw=0.3347, running_loss=0.3352, LR=0.000100
[2025-08-11 03:00:37,155][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104112] [Batch 00736/03692] [00:06:38/00:26:39, 0.541s/it]: train_loss_raw=0.4021, running_loss=0.3368, LR=0.000100
[2025-08-11 03:00:43,540][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104124] [Batch 00748/03692] [00:06:44/00:26:32, 0.541s/it]: train_loss_raw=0.3305, running_loss=0.3365, LR=0.000100
[2025-08-11 03:00:50,009][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104136] [Batch 00760/03692] [00:06:51/00:26:25, 0.541s/it]: train_loss_raw=0.3032, running_loss=0.3356, LR=0.000100
[2025-08-11 03:00:56,558][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104148] [Batch 00772/03692] [00:06:57/00:26:19, 0.541s/it]: train_loss_raw=0.3182, running_loss=0.3368, LR=0.000100
[2025-08-11 03:01:03,084][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104160] [Batch 00784/03692] [00:07:04/00:26:13, 0.541s/it]: train_loss_raw=0.3428, running_loss=0.3383, LR=0.000100
[2025-08-11 03:01:09,482][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104172] [Batch 00796/03692] [00:07:10/00:26:06, 0.541s/it]: train_loss_raw=0.3863, running_loss=0.3381, LR=0.000100
[2025-08-11 03:01:15,957][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104184] [Batch 00808/03692] [00:07:17/00:25:59, 0.541s/it]: train_loss_raw=0.3582, running_loss=0.3375, LR=0.000100
[2025-08-11 03:01:22,406][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104196] [Batch 00820/03692] [00:07:23/00:25:53, 0.541s/it]: train_loss_raw=0.2639, running_loss=0.3379, LR=0.000100
[2025-08-11 03:01:28,863][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104208] [Batch 00832/03692] [00:07:29/00:25:46, 0.541s/it]: train_loss_raw=0.4274, running_loss=0.3381, LR=0.000100
[2025-08-11 03:01:35,338][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104220] [Batch 00844/03692] [00:07:36/00:25:40, 0.541s/it]: train_loss_raw=0.3507, running_loss=0.3391, LR=0.000100
[2025-08-11 03:01:41,811][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104232] [Batch 00856/03692] [00:07:42/00:25:33, 0.541s/it]: train_loss_raw=0.2716, running_loss=0.3365, LR=0.000100
[2025-08-11 03:01:48,315][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104244] [Batch 00868/03692] [00:07:49/00:25:27, 0.541s/it]: train_loss_raw=0.3491, running_loss=0.3364, LR=0.000100
[2025-08-11 03:01:54,743][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104256] [Batch 00880/03692] [00:07:55/00:25:20, 0.541s/it]: train_loss_raw=0.3831, running_loss=0.3374, LR=0.000100
[2025-08-11 03:02:01,115][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104268] [Batch 00892/03692] [00:08:02/00:25:13, 0.541s/it]: train_loss_raw=0.3158, running_loss=0.3368, LR=0.000100
[2025-08-11 03:02:07,481][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104280] [Batch 00904/03692] [00:08:08/00:25:06, 0.540s/it]: train_loss_raw=0.3114, running_loss=0.3418, LR=0.000100
[2025-08-11 03:02:13,957][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104292] [Batch 00916/03692] [00:08:15/00:25:00, 0.540s/it]: train_loss_raw=0.3648, running_loss=0.3412, LR=0.000100
[2025-08-11 03:02:20,479][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104304] [Batch 00928/03692] [00:08:21/00:24:53, 0.540s/it]: train_loss_raw=0.3572, running_loss=0.3435, LR=0.000100
[2025-08-11 03:02:26,907][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104316] [Batch 00940/03692] [00:08:27/00:24:47, 0.540s/it]: train_loss_raw=0.4153, running_loss=0.3428, LR=0.000100
[2025-08-11 03:02:33,292][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104328] [Batch 00952/03692] [00:08:34/00:24:40, 0.540s/it]: train_loss_raw=0.3179, running_loss=0.3431, LR=0.000100
[2025-08-11 03:02:39,612][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104340] [Batch 00964/03692] [00:08:40/00:24:33, 0.540s/it]: train_loss_raw=0.2884, running_loss=0.3414, LR=0.000100
[2025-08-11 03:02:46,070][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104352] [Batch 00976/03692] [00:08:47/00:24:26, 0.540s/it]: train_loss_raw=0.2646, running_loss=0.3429, LR=0.000100
[2025-08-11 03:02:52,468][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104364] [Batch 00988/03692] [00:08:53/00:24:20, 0.540s/it]: train_loss_raw=0.3207, running_loss=0.3427, LR=0.000100
[2025-08-11 03:02:58,924][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104376] [Batch 01000/03692] [00:08:59/00:24:13, 0.540s/it]: train_loss_raw=0.3270, running_loss=0.3437, LR=0.000100
[2025-08-11 03:03:05,306][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104388] [Batch 01012/03692] [00:09:06/00:24:06, 0.540s/it]: train_loss_raw=0.3810, running_loss=0.3438, LR=0.000100
[2025-08-11 03:03:11,672][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104400] [Batch 01024/03692] [00:09:12/00:24:00, 0.540s/it]: train_loss_raw=0.3444, running_loss=0.3474, LR=0.000100
[2025-08-11 03:03:18,051][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104412] [Batch 01036/03692] [00:09:19/00:23:53, 0.540s/it]: train_loss_raw=0.3951, running_loss=0.3470, LR=0.000100
[2025-08-11 03:03:24,503][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104424] [Batch 01048/03692] [00:09:25/00:23:46, 0.540s/it]: train_loss_raw=0.3526, running_loss=0.3449, LR=0.000100
[2025-08-11 03:03:30,877][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104436] [Batch 01060/03692] [00:09:31/00:23:40, 0.540s/it]: train_loss_raw=0.3942, running_loss=0.3457, LR=0.000100
[2025-08-11 03:03:37,310][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104448] [Batch 01072/03692] [00:09:38/00:23:33, 0.540s/it]: train_loss_raw=0.3414, running_loss=0.3485, LR=0.000100
[2025-08-11 03:03:43,637][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104460] [Batch 01084/03692] [00:09:44/00:23:26, 0.539s/it]: train_loss_raw=0.3399, running_loss=0.3470, LR=0.000100
[2025-08-11 03:03:49,944][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104472] [Batch 01096/03692] [00:09:51/00:23:19, 0.539s/it]: train_loss_raw=0.3312, running_loss=0.3495, LR=0.000100
[2025-08-11 03:03:56,416][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104484] [Batch 01108/03692] [00:09:57/00:23:13, 0.539s/it]: train_loss_raw=0.3989, running_loss=0.3501, LR=0.000100
[2025-08-11 03:04:02,936][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104496] [Batch 01120/03692] [00:10:03/00:23:07, 0.539s/it]: train_loss_raw=0.4648, running_loss=0.3523, LR=0.000100
[2025-08-11 03:04:09,279][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104508] [Batch 01132/03692] [00:10:10/00:23:00, 0.539s/it]: train_loss_raw=0.3398, running_loss=0.3523, LR=0.000100
[2025-08-11 03:04:15,695][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104520] [Batch 01144/03692] [00:10:16/00:22:53, 0.539s/it]: train_loss_raw=0.4012, running_loss=0.3504, LR=0.000100
[2025-08-11 03:04:22,255][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104532] [Batch 01156/03692] [00:10:23/00:22:47, 0.539s/it]: train_loss_raw=0.3419, running_loss=0.3513, LR=0.000100
[2025-08-11 03:04:28,717][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104544] [Batch 01168/03692] [00:10:29/00:22:40, 0.539s/it]: train_loss_raw=0.4291, running_loss=0.3507, LR=0.000100
[2025-08-11 03:04:35,109][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104556] [Batch 01180/03692] [00:10:36/00:22:34, 0.539s/it]: train_loss_raw=0.3409, running_loss=0.3515, LR=0.000100
[2025-08-11 03:04:41,487][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104568] [Batch 01192/03692] [00:10:42/00:22:27, 0.539s/it]: train_loss_raw=0.3578, running_loss=0.3487, LR=0.000100
[2025-08-11 03:04:47,976][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104580] [Batch 01204/03692] [00:10:49/00:22:21, 0.539s/it]: train_loss_raw=0.3479, running_loss=0.3481, LR=0.000100
[2025-08-11 03:04:54,457][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104592] [Batch 01216/03692] [00:10:55/00:22:14, 0.539s/it]: train_loss_raw=0.3041, running_loss=0.3507, LR=0.000100
[2025-08-11 03:05:00,929][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104604] [Batch 01228/03692] [00:11:01/00:22:08, 0.539s/it]: train_loss_raw=0.3936, running_loss=0.3534, LR=0.000100
[2025-08-11 03:05:07,468][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104616] [Batch 01240/03692] [00:11:08/00:22:01, 0.539s/it]: train_loss_raw=0.3056, running_loss=0.3525, LR=0.000100
[2025-08-11 03:05:14,011][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104628] [Batch 01252/03692] [00:11:15/00:21:55, 0.539s/it]: train_loss_raw=0.3716, running_loss=0.3520, LR=0.000100
[2025-08-11 03:05:20,527][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104640] [Batch 01264/03692] [00:11:21/00:21:49, 0.539s/it]: train_loss_raw=0.3957, running_loss=0.3493, LR=0.000100
[2025-08-11 03:05:26,941][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104652] [Batch 01276/03692] [00:11:28/00:21:42, 0.539s/it]: train_loss_raw=0.3889, running_loss=0.3510, LR=0.000100
[2025-08-11 03:05:33,452][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104664] [Batch 01288/03692] [00:11:34/00:21:36, 0.539s/it]: train_loss_raw=0.3498, running_loss=0.3481, LR=0.000100
[2025-08-11 03:05:39,892][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104676] [Batch 01300/03692] [00:11:40/00:21:29, 0.539s/it]: train_loss_raw=0.2860, running_loss=0.3480, LR=0.000100
[2025-08-11 03:05:46,265][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104688] [Batch 01312/03692] [00:11:47/00:21:23, 0.539s/it]: train_loss_raw=0.3136, running_loss=0.3457, LR=0.000100
[2025-08-11 03:05:52,742][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104700] [Batch 01324/03692] [00:11:53/00:21:16, 0.539s/it]: train_loss_raw=0.3590, running_loss=0.3453, LR=0.000100
[2025-08-11 03:05:59,060][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104712] [Batch 01336/03692] [00:12:00/00:21:09, 0.539s/it]: train_loss_raw=0.3519, running_loss=0.3474, LR=0.000100
[2025-08-11 03:06:05,433][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104724] [Batch 01348/03692] [00:12:06/00:21:03, 0.539s/it]: train_loss_raw=0.3594, running_loss=0.3511, LR=0.000100
[2025-08-11 03:06:11,828][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104736] [Batch 01360/03692] [00:12:12/00:20:56, 0.539s/it]: train_loss_raw=0.3368, running_loss=0.3510, LR=0.000100
[2025-08-11 03:06:18,209][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104748] [Batch 01372/03692] [00:12:19/00:20:50, 0.539s/it]: train_loss_raw=0.3228, running_loss=0.3508, LR=0.000100
[2025-08-11 03:06:24,536][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104760] [Batch 01384/03692] [00:12:25/00:20:43, 0.539s/it]: train_loss_raw=0.3845, running_loss=0.3500, LR=0.000100
[2025-08-11 03:06:30,948][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104772] [Batch 01396/03692] [00:12:32/00:20:36, 0.539s/it]: train_loss_raw=0.3653, running_loss=0.3486, LR=0.000100
[2025-08-11 03:06:37,451][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104784] [Batch 01408/03692] [00:12:38/00:20:30, 0.539s/it]: train_loss_raw=0.3545, running_loss=0.3471, LR=0.000100
[2025-08-11 03:06:43,891][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104796] [Batch 01420/03692] [00:12:44/00:20:23, 0.539s/it]: train_loss_raw=0.3213, running_loss=0.3490, LR=0.000100
[2025-08-11 03:06:50,374][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104808] [Batch 01432/03692] [00:12:51/00:20:17, 0.539s/it]: train_loss_raw=0.3530, running_loss=0.3462, LR=0.000100
[2025-08-11 03:06:56,758][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104820] [Batch 01444/03692] [00:12:57/00:20:10, 0.539s/it]: train_loss_raw=0.2967, running_loss=0.3456, LR=0.000100
[2025-08-11 03:07:03,137][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104832] [Batch 01456/03692] [00:13:04/00:20:04, 0.539s/it]: train_loss_raw=0.3668, running_loss=0.3463, LR=0.000100
[2025-08-11 03:07:09,433][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104844] [Batch 01468/03692] [00:13:10/00:19:57, 0.538s/it]: train_loss_raw=0.3398, running_loss=0.3462, LR=0.000100
[2025-08-11 03:07:15,802][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104856] [Batch 01480/03692] [00:13:16/00:19:50, 0.538s/it]: train_loss_raw=0.2842, running_loss=0.3453, LR=0.000100
[2025-08-11 03:07:22,174][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104868] [Batch 01492/03692] [00:13:23/00:19:44, 0.538s/it]: train_loss_raw=0.2827, running_loss=0.3452, LR=0.000100
[2025-08-11 03:07:28,590][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104880] [Batch 01504/03692] [00:13:29/00:19:37, 0.538s/it]: train_loss_raw=0.3867, running_loss=0.3472, LR=0.000100
[2025-08-11 03:07:34,937][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104892] [Batch 01516/03692] [00:13:36/00:19:31, 0.538s/it]: train_loss_raw=0.2943, running_loss=0.3468, LR=0.000100
[2025-08-11 03:07:41,340][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104904] [Batch 01528/03692] [00:13:42/00:19:24, 0.538s/it]: train_loss_raw=0.3276, running_loss=0.3456, LR=0.000100
[2025-08-11 03:08:32,663][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104916] [Batch 01540/03692] [00:14:33/00:20:20, 0.567s/it]: train_loss_raw=0.4098, running_loss=0.3478, LR=0.000100
[2025-08-11 03:08:38,971][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104928] [Batch 01552/03692] [00:14:40/00:20:13, 0.567s/it]: train_loss_raw=0.3381, running_loss=0.3498, LR=0.000100
[2025-08-11 03:08:45,332][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104940] [Batch 01564/03692] [00:14:46/00:20:06, 0.567s/it]: train_loss_raw=0.3827, running_loss=0.3518, LR=0.000100
[2025-08-11 03:08:51,691][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104952] [Batch 01576/03692] [00:14:52/00:19:58, 0.566s/it]: train_loss_raw=0.3990, running_loss=0.3541, LR=0.000100
[2025-08-11 03:08:58,009][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104964] [Batch 01588/03692] [00:14:59/00:19:51, 0.566s/it]: train_loss_raw=0.4449, running_loss=0.3552, LR=0.000100
[2025-08-11 03:09:04,317][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104976] [Batch 01600/03692] [00:15:05/00:19:43, 0.566s/it]: train_loss_raw=0.4165, running_loss=0.3561, LR=0.000100
[2025-08-11 03:09:10,737][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104988] [Batch 01612/03692] [00:15:11/00:19:36, 0.566s/it]: train_loss_raw=0.3897, running_loss=0.3581, LR=0.000100
[2025-08-11 03:09:17,328][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105000] [Batch 01624/03692] [00:15:18/00:19:29, 0.566s/it]: train_loss_raw=0.3821, running_loss=0.3589, LR=0.000100
[2025-08-11 03:09:23,869][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105012] [Batch 01636/03692] [00:15:24/00:19:22, 0.565s/it]: train_loss_raw=0.3024, running_loss=0.3599, LR=0.000100
[2025-08-11 03:09:30,287][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105024] [Batch 01648/03692] [00:15:31/00:19:15, 0.565s/it]: train_loss_raw=0.3332, running_loss=0.3593, LR=0.000100
[2025-08-11 03:09:36,641][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105036] [Batch 01660/03692] [00:15:37/00:19:07, 0.565s/it]: train_loss_raw=0.4736, running_loss=0.3612, LR=0.000100
[2025-08-11 03:09:42,945][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105048] [Batch 01672/03692] [00:15:44/00:19:00, 0.565s/it]: train_loss_raw=0.4180, running_loss=0.3609, LR=0.000100
[2025-08-11 03:09:49,391][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105060] [Batch 01684/03692] [00:15:50/00:18:53, 0.564s/it]: train_loss_raw=0.3499, running_loss=0.3606, LR=0.000100
[2025-08-11 03:09:55,867][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105072] [Batch 01696/03692] [00:15:56/00:18:46, 0.564s/it]: train_loss_raw=0.3320, running_loss=0.3607, LR=0.000100
[2025-08-11 03:10:02,218][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105084] [Batch 01708/03692] [00:16:03/00:18:38, 0.564s/it]: train_loss_raw=0.4268, running_loss=0.3606, LR=0.000100
[2025-08-11 03:10:08,698][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105096] [Batch 01720/03692] [00:16:09/00:18:31, 0.564s/it]: train_loss_raw=0.4316, running_loss=0.3614, LR=0.000100
[2025-08-11 03:10:15,071][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105108] [Batch 01732/03692] [00:16:16/00:18:24, 0.564s/it]: train_loss_raw=0.3691, running_loss=0.3624, LR=0.000100
[2025-08-11 03:10:21,397][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105120] [Batch 01744/03692] [00:16:22/00:18:17, 0.563s/it]: train_loss_raw=0.3755, running_loss=0.3645, LR=0.000100
[2025-08-11 03:10:27,755][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105132] [Batch 01756/03692] [00:16:28/00:18:10, 0.563s/it]: train_loss_raw=0.4234, running_loss=0.3637, LR=0.000100
[2025-08-11 03:10:34,009][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105144] [Batch 01768/03692] [00:16:35/00:18:02, 0.563s/it]: train_loss_raw=0.2925, running_loss=0.3622, LR=0.000100
[2025-08-11 03:10:40,249][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105156] [Batch 01780/03692] [00:16:41/00:17:55, 0.563s/it]: train_loss_raw=0.3507, running_loss=0.3612, LR=0.000100
[2025-08-11 03:10:46,462][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105168] [Batch 01792/03692] [00:16:47/00:17:48, 0.562s/it]: train_loss_raw=0.3096, running_loss=0.3621, LR=0.000100
[2025-08-11 03:10:52,710][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105180] [Batch 01804/03692] [00:16:53/00:17:40, 0.562s/it]: train_loss_raw=0.3215, running_loss=0.3589, LR=0.000100
[2025-08-11 03:10:58,992][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105192] [Batch 01816/03692] [00:17:00/00:17:33, 0.562s/it]: train_loss_raw=0.3246, running_loss=0.3605, LR=0.000100
[2025-08-11 03:11:05,526][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105204] [Batch 01828/03692] [00:17:06/00:17:26, 0.562s/it]: train_loss_raw=0.4026, running_loss=0.3631, LR=0.000100
[2025-08-11 03:11:11,940][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105216] [Batch 01840/03692] [00:17:13/00:17:19, 0.561s/it]: train_loss_raw=0.3683, running_loss=0.3611, LR=0.000100
[2025-08-11 03:11:18,397][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105228] [Batch 01852/03692] [00:17:19/00:17:12, 0.561s/it]: train_loss_raw=0.2752, running_loss=0.3599, LR=0.000100
[2025-08-11 03:11:24,930][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105240] [Batch 01864/03692] [00:17:25/00:17:05, 0.561s/it]: train_loss_raw=0.4147, running_loss=0.3626, LR=0.000100
[2025-08-11 03:11:31,458][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105252] [Batch 01876/03692] [00:17:32/00:16:58, 0.561s/it]: train_loss_raw=0.3183, running_loss=0.3617, LR=0.000100
[2025-08-11 03:11:37,832][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105264] [Batch 01888/03692] [00:17:38/00:16:51, 0.561s/it]: train_loss_raw=0.4045, running_loss=0.3610, LR=0.000100
[2025-08-11 03:11:44,268][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105276] [Batch 01900/03692] [00:17:45/00:16:44, 0.561s/it]: train_loss_raw=0.2884, running_loss=0.3606, LR=0.000100
[2025-08-11 03:11:50,712][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105288] [Batch 01912/03692] [00:17:51/00:16:37, 0.561s/it]: train_loss_raw=0.3829, running_loss=0.3595, LR=0.000100
[2025-08-11 03:11:57,153][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105300] [Batch 01924/03692] [00:17:58/00:16:30, 0.560s/it]: train_loss_raw=0.3727, running_loss=0.3594, LR=0.000100
[2025-08-11 03:12:03,651][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105312] [Batch 01936/03692] [00:18:04/00:16:23, 0.560s/it]: train_loss_raw=0.3250, running_loss=0.3607, LR=0.000100
[2025-08-11 03:12:10,048][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105324] [Batch 01948/03692] [00:18:11/00:16:16, 0.560s/it]: train_loss_raw=0.4077, running_loss=0.3613, LR=0.000100
[2025-08-11 03:12:16,417][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105336] [Batch 01960/03692] [00:18:17/00:16:09, 0.560s/it]: train_loss_raw=0.3040, running_loss=0.3610, LR=0.000100
[2025-08-11 03:12:22,798][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105348] [Batch 01972/03692] [00:18:23/00:16:02, 0.560s/it]: train_loss_raw=0.3054, running_loss=0.3606, LR=0.000100
[2025-08-11 03:12:29,197][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105360] [Batch 01984/03692] [00:18:30/00:15:55, 0.560s/it]: train_loss_raw=0.4212, running_loss=0.3607, LR=0.000100
[2025-08-11 03:12:35,626][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105372] [Batch 01996/03692] [00:18:36/00:15:48, 0.559s/it]: train_loss_raw=0.5107, running_loss=0.3638, LR=0.000100
[2025-08-11 03:12:42,008][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105384] [Batch 02008/03692] [00:18:43/00:15:41, 0.559s/it]: train_loss_raw=0.3099, running_loss=0.3636, LR=0.000100
[2025-08-11 03:12:48,429][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105396] [Batch 02020/03692] [00:18:49/00:15:34, 0.559s/it]: train_loss_raw=0.3721, running_loss=0.3638, LR=0.000100
[2025-08-11 03:12:54,769][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105408] [Batch 02032/03692] [00:18:55/00:15:27, 0.559s/it]: train_loss_raw=0.3776, running_loss=0.3623, LR=0.000100
[2025-08-11 03:13:01,146][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105420] [Batch 02044/03692] [00:19:02/00:15:20, 0.559s/it]: train_loss_raw=0.3104, running_loss=0.3638, LR=0.000100
[2025-08-11 03:13:07,529][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105432] [Batch 02056/03692] [00:19:08/00:15:13, 0.559s/it]: train_loss_raw=0.3597, running_loss=0.3644, LR=0.000100
[2025-08-11 03:13:13,891][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105444] [Batch 02068/03692] [00:19:14/00:15:06, 0.558s/it]: train_loss_raw=0.3464, running_loss=0.3651, LR=0.000100
[2025-08-11 03:13:20,256][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105456] [Batch 02080/03692] [00:19:21/00:15:00, 0.558s/it]: train_loss_raw=0.3924, running_loss=0.3679, LR=0.000100
[2025-08-11 03:13:26,552][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105468] [Batch 02092/03692] [00:19:27/00:14:53, 0.558s/it]: train_loss_raw=0.3536, running_loss=0.3662, LR=0.000100
[2025-08-11 03:13:32,907][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105480] [Batch 02104/03692] [00:19:33/00:14:46, 0.558s/it]: train_loss_raw=0.3735, running_loss=0.3686, LR=0.000100
[2025-08-11 03:13:39,279][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105492] [Batch 02116/03692] [00:19:40/00:14:39, 0.558s/it]: train_loss_raw=0.4299, running_loss=0.3680, LR=0.000100
[2025-08-11 03:13:45,687][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105504] [Batch 02128/03692] [00:19:46/00:14:32, 0.558s/it]: train_loss_raw=0.2798, running_loss=0.3665, LR=0.000100
[2025-08-11 03:13:52,237][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105516] [Batch 02140/03692] [00:19:53/00:14:25, 0.558s/it]: train_loss_raw=0.3232, running_loss=0.3634, LR=0.000100
[2025-08-11 03:13:58,580][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105528] [Batch 02152/03692] [00:19:59/00:14:18, 0.557s/it]: train_loss_raw=0.3086, running_loss=0.3610, LR=0.000100
[2025-08-11 03:14:04,937][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105540] [Batch 02164/03692] [00:20:06/00:14:11, 0.557s/it]: train_loss_raw=0.4261, running_loss=0.3603, LR=0.000100
[2025-08-11 03:14:11,367][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105552] [Batch 02176/03692] [00:20:12/00:14:04, 0.557s/it]: train_loss_raw=0.3027, running_loss=0.3578, LR=0.000100
[2025-08-11 03:14:17,741][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105564] [Batch 02188/03692] [00:20:18/00:13:57, 0.557s/it]: train_loss_raw=0.3757, running_loss=0.3611, LR=0.000100
[2025-08-11 03:14:24,081][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105576] [Batch 02200/03692] [00:20:25/00:13:50, 0.557s/it]: train_loss_raw=0.4251, running_loss=0.3583, LR=0.000100
[2025-08-11 03:14:30,494][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105588] [Batch 02212/03692] [00:20:31/00:13:44, 0.557s/it]: train_loss_raw=0.3804, running_loss=0.3595, LR=0.000100
[2025-08-11 03:14:36,873][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105600] [Batch 02224/03692] [00:20:37/00:13:37, 0.557s/it]: train_loss_raw=0.4062, running_loss=0.3583, LR=0.000100
[2025-08-11 03:14:43,223][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105612] [Batch 02236/03692] [00:20:44/00:13:30, 0.556s/it]: train_loss_raw=0.4785, running_loss=0.3599, LR=0.000100
[2025-08-11 03:14:49,578][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105624] [Batch 02248/03692] [00:20:50/00:13:23, 0.556s/it]: train_loss_raw=0.3637, running_loss=0.3601, LR=0.000100
[2025-08-11 03:14:55,971][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105636] [Batch 02260/03692] [00:20:57/00:13:16, 0.556s/it]: train_loss_raw=0.3270, running_loss=0.3585, LR=0.000100
[2025-08-11 03:15:02,355][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105648] [Batch 02272/03692] [00:21:03/00:13:09, 0.556s/it]: train_loss_raw=0.3738, running_loss=0.3601, LR=0.000100
[2025-08-11 03:15:08,769][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105660] [Batch 02284/03692] [00:21:09/00:13:02, 0.556s/it]: train_loss_raw=0.4431, running_loss=0.3610, LR=0.000100
[2025-08-11 03:15:15,120][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105672] [Batch 02296/03692] [00:21:16/00:12:55, 0.556s/it]: train_loss_raw=0.3875, running_loss=0.3618, LR=0.000100
[2025-08-11 03:15:21,532][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105684] [Batch 02308/03692] [00:21:22/00:12:49, 0.556s/it]: train_loss_raw=0.4157, running_loss=0.3606, LR=0.000100
[2025-08-11 03:15:27,915][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105696] [Batch 02320/03692] [00:21:28/00:12:42, 0.556s/it]: train_loss_raw=0.3943, running_loss=0.3614, LR=0.000100
[2025-08-11 03:15:34,269][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105708] [Batch 02332/03692] [00:21:35/00:12:35, 0.555s/it]: train_loss_raw=0.3535, running_loss=0.3624, LR=0.000100
[2025-08-11 03:15:40,668][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105720] [Batch 02344/03692] [00:21:41/00:12:28, 0.555s/it]: train_loss_raw=0.2998, running_loss=0.3650, LR=0.000100
[2025-08-11 03:15:46,943][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105732] [Batch 02356/03692] [00:21:48/00:12:21, 0.555s/it]: train_loss_raw=0.1846, running_loss=0.3660, LR=0.000100
[2025-08-11 03:15:53,310][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105744] [Batch 02368/03692] [00:21:54/00:12:14, 0.555s/it]: train_loss_raw=0.3742, running_loss=0.3642, LR=0.000100
[2025-08-11 03:15:59,813][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105756] [Batch 02380/03692] [00:22:00/00:12:08, 0.555s/it]: train_loss_raw=0.3468, running_loss=0.3642, LR=0.000100
[2025-08-11 03:16:06,255][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105768] [Batch 02392/03692] [00:22:07/00:12:01, 0.555s/it]: train_loss_raw=0.3661, running_loss=0.3640, LR=0.000100
[2025-08-11 03:16:12,761][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105780] [Batch 02404/03692] [00:22:13/00:11:54, 0.555s/it]: train_loss_raw=0.4153, running_loss=0.3651, LR=0.000100
[2025-08-11 03:16:19,139][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105792] [Batch 02416/03692] [00:22:20/00:11:47, 0.555s/it]: train_loss_raw=0.3664, running_loss=0.3654, LR=0.000100
[2025-08-11 03:16:25,526][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105804] [Batch 02428/03692] [00:22:26/00:11:41, 0.555s/it]: train_loss_raw=0.3077, running_loss=0.3633, LR=0.000100
[2025-08-11 03:16:31,899][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105816] [Batch 02440/03692] [00:22:32/00:11:34, 0.554s/it]: train_loss_raw=0.3291, running_loss=0.3623, LR=0.000100
[2025-08-11 03:16:38,279][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105828] [Batch 02452/03692] [00:22:39/00:11:27, 0.554s/it]: train_loss_raw=0.3196, running_loss=0.3612, LR=0.000100
[2025-08-11 03:16:44,670][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105840] [Batch 02464/03692] [00:22:45/00:11:20, 0.554s/it]: train_loss_raw=0.3313, running_loss=0.3590, LR=0.000100
[2025-08-11 03:16:51,042][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105852] [Batch 02476/03692] [00:22:52/00:11:13, 0.554s/it]: train_loss_raw=0.2964, running_loss=0.3587, LR=0.000100
[2025-08-11 03:16:57,413][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105864] [Batch 02488/03692] [00:22:58/00:11:07, 0.554s/it]: train_loss_raw=0.3332, running_loss=0.3593, LR=0.000100
[2025-08-11 03:17:03,822][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105876] [Batch 02500/03692] [00:23:04/00:11:00, 0.554s/it]: train_loss_raw=0.3700, running_loss=0.3612, LR=0.000100
[2025-08-11 03:17:10,393][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105888] [Batch 02512/03692] [00:23:11/00:10:53, 0.554s/it]: train_loss_raw=0.3192, running_loss=0.3617, LR=0.000100
[2025-08-11 03:17:16,965][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105900] [Batch 02524/03692] [00:23:18/00:10:46, 0.554s/it]: train_loss_raw=0.3827, running_loss=0.3611, LR=0.000100
[2025-08-11 03:17:23,581][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105912] [Batch 02536/03692] [00:23:24/00:10:40, 0.554s/it]: train_loss_raw=0.3773, running_loss=0.3603, LR=0.000100
[2025-08-11 03:17:30,030][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105924] [Batch 02548/03692] [00:23:31/00:10:33, 0.554s/it]: train_loss_raw=0.4716, running_loss=0.3576, LR=0.000100
[2025-08-11 03:17:36,390][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105936] [Batch 02560/03692] [00:23:37/00:10:26, 0.554s/it]: train_loss_raw=0.4260, running_loss=0.3582, LR=0.000100
[2025-08-11 03:17:42,744][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105948] [Batch 02572/03692] [00:23:43/00:10:20, 0.554s/it]: train_loss_raw=0.4840, running_loss=0.3598, LR=0.000100
[2025-08-11 03:17:49,112][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105960] [Batch 02584/03692] [00:23:50/00:10:13, 0.553s/it]: train_loss_raw=0.3338, running_loss=0.3583, LR=0.000100
[2025-08-11 03:17:55,507][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105972] [Batch 02596/03692] [00:23:56/00:10:06, 0.553s/it]: train_loss_raw=0.3753, running_loss=0.3587, LR=0.000100
[2025-08-11 03:18:01,969][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105984] [Batch 02608/03692] [00:24:03/00:09:59, 0.553s/it]: train_loss_raw=0.3871, running_loss=0.3576, LR=0.000100
[2025-08-11 03:18:08,298][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105996] [Batch 02620/03692] [00:24:09/00:09:53, 0.553s/it]: train_loss_raw=0.3442, running_loss=0.3591, LR=0.000100
[2025-08-11 03:18:19,263][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106008] [Batch 02632/03692] [00:24:20/00:09:48, 0.555s/it]: train_loss_raw=0.3069, running_loss=0.3605, LR=0.000100
[2025-08-11 03:18:25,602][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106020] [Batch 02644/03692] [00:24:26/00:09:41, 0.555s/it]: train_loss_raw=0.3686, running_loss=0.3579, LR=0.000100
[2025-08-11 03:18:32,006][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106032] [Batch 02656/03692] [00:24:33/00:09:34, 0.555s/it]: train_loss_raw=0.3642, running_loss=0.3586, LR=0.000100
[2025-08-11 03:18:38,438][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106044] [Batch 02668/03692] [00:24:39/00:09:27, 0.555s/it]: train_loss_raw=0.4082, running_loss=0.3585, LR=0.000100
[2025-08-11 03:18:45,026][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106056] [Batch 02680/03692] [00:24:46/00:09:21, 0.555s/it]: train_loss_raw=0.2663, running_loss=0.3562, LR=0.000100
[2025-08-11 03:18:51,494][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106068] [Batch 02692/03692] [00:24:52/00:09:14, 0.554s/it]: train_loss_raw=0.3684, running_loss=0.3580, LR=0.000100
[2025-08-11 03:18:57,969][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106080] [Batch 02704/03692] [00:24:59/00:09:07, 0.554s/it]: train_loss_raw=0.4105, running_loss=0.3570, LR=0.000100
[2025-08-11 03:19:04,563][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106092] [Batch 02716/03692] [00:25:05/00:09:01, 0.554s/it]: train_loss_raw=0.3722, running_loss=0.3564, LR=0.000100
[2025-08-11 03:19:10,992][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106104] [Batch 02728/03692] [00:25:12/00:08:54, 0.554s/it]: train_loss_raw=0.3279, running_loss=0.3598, LR=0.000100
[2025-08-11 03:19:17,415][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106116] [Batch 02740/03692] [00:25:18/00:08:47, 0.554s/it]: train_loss_raw=0.3366, running_loss=0.3614, LR=0.000100
[2025-08-11 03:19:23,743][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106128] [Batch 02752/03692] [00:25:24/00:08:40, 0.554s/it]: train_loss_raw=0.3492, running_loss=0.3605, LR=0.000100
[2025-08-11 03:19:30,243][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106140] [Batch 02764/03692] [00:25:31/00:08:34, 0.554s/it]: train_loss_raw=0.3039, running_loss=0.3579, LR=0.000100
[2025-08-11 03:19:36,863][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106152] [Batch 02776/03692] [00:25:37/00:08:27, 0.554s/it]: train_loss_raw=0.3291, running_loss=0.3587, LR=0.000100
[2025-08-11 03:19:43,439][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106164] [Batch 02788/03692] [00:25:44/00:08:20, 0.554s/it]: train_loss_raw=0.4732, running_loss=0.3633, LR=0.000100
[2025-08-11 03:19:49,971][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106176] [Batch 02800/03692] [00:25:51/00:08:14, 0.554s/it]: train_loss_raw=0.3016, running_loss=0.3613, LR=0.000100
[2025-08-11 03:19:56,563][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106188] [Batch 02812/03692] [00:25:57/00:08:07, 0.554s/it]: train_loss_raw=0.3493, running_loss=0.3632, LR=0.000100
[2025-08-11 03:20:03,115][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106200] [Batch 02824/03692] [00:26:04/00:08:00, 0.554s/it]: train_loss_raw=0.2712, running_loss=0.3634, LR=0.000100
[2025-08-11 03:20:09,666][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106212] [Batch 02836/03692] [00:26:10/00:07:54, 0.554s/it]: train_loss_raw=0.3889, running_loss=0.3622, LR=0.000100
[2025-08-11 03:20:16,108][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106224] [Batch 02848/03692] [00:26:17/00:07:47, 0.554s/it]: train_loss_raw=0.3595, running_loss=0.3636, LR=0.000100
[2025-08-11 03:20:22,537][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106236] [Batch 02860/03692] [00:26:23/00:07:40, 0.554s/it]: train_loss_raw=0.3508, running_loss=0.3646, LR=0.000100
[2025-08-11 03:20:28,943][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106248] [Batch 02872/03692] [00:26:30/00:07:33, 0.554s/it]: train_loss_raw=0.3290, running_loss=0.3643, LR=0.000100
[2025-08-11 03:20:35,274][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106260] [Batch 02884/03692] [00:26:36/00:07:27, 0.554s/it]: train_loss_raw=0.3266, running_loss=0.3620, LR=0.000100
[2025-08-11 03:20:41,810][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106272] [Batch 02896/03692] [00:26:42/00:07:20, 0.553s/it]: train_loss_raw=0.3445, running_loss=0.3602, LR=0.000100
[2025-08-11 03:20:48,161][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106284] [Batch 02908/03692] [00:26:49/00:07:13, 0.553s/it]: train_loss_raw=0.2976, running_loss=0.3617, LR=0.000100
[2025-08-11 03:20:54,539][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106296] [Batch 02920/03692] [00:26:55/00:07:07, 0.553s/it]: train_loss_raw=0.4332, running_loss=0.3617, LR=0.000100
[2025-08-11 03:21:00,980][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106308] [Batch 02932/03692] [00:27:02/00:07:00, 0.553s/it]: train_loss_raw=0.3629, running_loss=0.3605, LR=0.000100
[2025-08-11 03:21:07,403][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106320] [Batch 02944/03692] [00:27:08/00:06:53, 0.553s/it]: train_loss_raw=0.3501, running_loss=0.3582, LR=0.000100
[2025-08-11 03:21:13,615][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106332] [Batch 02956/03692] [00:27:14/00:06:47, 0.553s/it]: train_loss_raw=0.3790, running_loss=0.3561, LR=0.000100
[2025-08-11 03:21:19,949][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106344] [Batch 02968/03692] [00:27:21/00:06:40, 0.553s/it]: train_loss_raw=0.4739, running_loss=0.3604, LR=0.000100
[2025-08-11 03:21:26,353][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106356] [Batch 02980/03692] [00:27:27/00:06:33, 0.553s/it]: train_loss_raw=0.4072, running_loss=0.3609, LR=0.000100
[2025-08-11 03:21:32,709][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106368] [Batch 02992/03692] [00:27:33/00:06:26, 0.553s/it]: train_loss_raw=0.4213, running_loss=0.3615, LR=0.000100
[2025-08-11 03:21:39,238][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106380] [Batch 03004/03692] [00:27:40/00:06:20, 0.553s/it]: train_loss_raw=0.3246, running_loss=0.3610, LR=0.000100
[2025-08-11 03:21:45,751][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106392] [Batch 03016/03692] [00:27:46/00:06:13, 0.553s/it]: train_loss_raw=0.2822, running_loss=0.3602, LR=0.000100
[2025-08-11 03:21:52,214][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106404] [Batch 03028/03692] [00:27:53/00:06:06, 0.553s/it]: train_loss_raw=0.2752, running_loss=0.3585, LR=0.000100
[2025-08-11 03:21:58,670][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106416] [Batch 03040/03692] [00:27:59/00:06:00, 0.553s/it]: train_loss_raw=0.4227, running_loss=0.3625, LR=0.000100
[2025-08-11 03:22:05,114][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106428] [Batch 03052/03692] [00:28:06/00:05:53, 0.552s/it]: train_loss_raw=0.4370, running_loss=0.3638, LR=0.000100
[2025-08-11 03:22:11,590][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106440] [Batch 03064/03692] [00:28:12/00:05:46, 0.552s/it]: train_loss_raw=0.3591, running_loss=0.3638, LR=0.000100
[2025-08-11 03:22:18,071][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106452] [Batch 03076/03692] [00:28:19/00:05:40, 0.552s/it]: train_loss_raw=0.3168, running_loss=0.3653, LR=0.000100
[2025-08-11 03:22:24,493][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106464] [Batch 03088/03692] [00:28:25/00:05:33, 0.552s/it]: train_loss_raw=0.2794, running_loss=0.3635, LR=0.000100
[2025-08-11 03:22:30,892][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106476] [Batch 03100/03692] [00:28:31/00:05:26, 0.552s/it]: train_loss_raw=0.3554, running_loss=0.3652, LR=0.000100
[2025-08-11 03:22:37,357][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106488] [Batch 03112/03692] [00:28:38/00:05:20, 0.552s/it]: train_loss_raw=0.3667, running_loss=0.3649, LR=0.000100
[2025-08-11 03:22:43,681][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106500] [Batch 03124/03692] [00:28:44/00:05:13, 0.552s/it]: train_loss_raw=0.4514, running_loss=0.3646, LR=0.000100
[2025-08-11 03:22:50,033][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106512] [Batch 03136/03692] [00:28:51/00:05:06, 0.552s/it]: train_loss_raw=0.3190, running_loss=0.3660, LR=0.000100
[2025-08-11 03:22:56,424][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106524] [Batch 03148/03692] [00:28:57/00:05:00, 0.552s/it]: train_loss_raw=0.3430, running_loss=0.3638, LR=0.000100
[2025-08-11 03:23:02,961][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106536] [Batch 03160/03692] [00:29:04/00:04:53, 0.552s/it]: train_loss_raw=0.3109, running_loss=0.3642, LR=0.000100
[2025-08-11 03:23:09,388][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106548] [Batch 03172/03692] [00:29:10/00:04:46, 0.552s/it]: train_loss_raw=0.3426, running_loss=0.3628, LR=0.000100
[2025-08-11 03:23:15,705][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106560] [Batch 03184/03692] [00:29:16/00:04:40, 0.552s/it]: train_loss_raw=0.2922, running_loss=0.3621, LR=0.000100
[2025-08-11 03:23:22,098][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106572] [Batch 03196/03692] [00:29:23/00:04:33, 0.552s/it]: train_loss_raw=0.3638, running_loss=0.3598, LR=0.000100
[2025-08-11 03:23:28,491][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106584] [Batch 03208/03692] [00:29:29/00:04:26, 0.552s/it]: train_loss_raw=0.3368, running_loss=0.3614, LR=0.000100
[2025-08-11 03:23:34,748][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106596] [Batch 03220/03692] [00:29:35/00:04:20, 0.551s/it]: train_loss_raw=0.2841, running_loss=0.3601, LR=0.000100
[2025-08-11 03:23:41,167][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106608] [Batch 03232/03692] [00:29:42/00:04:13, 0.551s/it]: train_loss_raw=0.3332, running_loss=0.3625, LR=0.000100
[2025-08-11 03:23:47,555][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106620] [Batch 03244/03692] [00:29:48/00:04:07, 0.551s/it]: train_loss_raw=0.4054, running_loss=0.3623, LR=0.000100
[2025-08-11 03:23:53,943][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106632] [Batch 03256/03692] [00:29:55/00:04:00, 0.551s/it]: train_loss_raw=0.3238, running_loss=0.3601, LR=0.000100
[2025-08-11 03:24:00,347][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106644] [Batch 03268/03692] [00:30:01/00:03:53, 0.551s/it]: train_loss_raw=0.4142, running_loss=0.3598, LR=0.000100
[2025-08-11 03:24:06,710][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106656] [Batch 03280/03692] [00:30:07/00:03:47, 0.551s/it]: train_loss_raw=0.4948, running_loss=0.3611, LR=0.000100
[2025-08-11 03:24:13,100][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106668] [Batch 03292/03692] [00:30:14/00:03:40, 0.551s/it]: train_loss_raw=0.3575, running_loss=0.3608, LR=0.000100
[2025-08-11 03:24:19,621][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106680] [Batch 03304/03692] [00:30:20/00:03:33, 0.551s/it]: train_loss_raw=0.4134, running_loss=0.3618, LR=0.000100
[2025-08-11 03:24:26,180][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106692] [Batch 03316/03692] [00:30:27/00:03:27, 0.551s/it]: train_loss_raw=0.3002, running_loss=0.3591, LR=0.000100
[2025-08-11 03:24:32,499][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106704] [Batch 03328/03692] [00:30:33/00:03:20, 0.551s/it]: train_loss_raw=0.2920, running_loss=0.3596, LR=0.000100
[2025-08-11 03:24:38,944][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106716] [Batch 03340/03692] [00:30:40/00:03:13, 0.551s/it]: train_loss_raw=0.3381, running_loss=0.3558, LR=0.000100
[2025-08-11 03:24:45,309][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106728] [Batch 03352/03692] [00:30:46/00:03:07, 0.551s/it]: train_loss_raw=0.3928, running_loss=0.3588, LR=0.000100
[2025-08-11 03:24:51,749][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106740] [Batch 03364/03692] [00:30:52/00:03:00, 0.551s/it]: train_loss_raw=0.3700, running_loss=0.3581, LR=0.000100
[2025-08-11 03:24:58,112][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106752] [Batch 03376/03692] [00:30:59/00:02:54, 0.551s/it]: train_loss_raw=0.3253, running_loss=0.3578, LR=0.000100
[2025-08-11 03:25:04,466][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106764] [Batch 03388/03692] [00:31:05/00:02:47, 0.551s/it]: train_loss_raw=0.3972, running_loss=0.3592, LR=0.000100
[2025-08-11 03:25:10,830][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106776] [Batch 03400/03692] [00:31:11/00:02:40, 0.551s/it]: train_loss_raw=0.3005, running_loss=0.3575, LR=0.000100
[2025-08-11 03:25:17,251][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106788] [Batch 03412/03692] [00:31:18/00:02:34, 0.551s/it]: train_loss_raw=0.3923, running_loss=0.3545, LR=0.000100
[2025-08-11 03:25:23,706][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106800] [Batch 03424/03692] [00:31:24/00:02:27, 0.550s/it]: train_loss_raw=0.3625, running_loss=0.3558, LR=0.000100
[2025-08-11 03:25:30,196][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106812] [Batch 03436/03692] [00:31:31/00:02:20, 0.550s/it]: train_loss_raw=0.3842, running_loss=0.3542, LR=0.000100
[2025-08-11 03:25:36,592][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106824] [Batch 03448/03692] [00:31:37/00:02:14, 0.550s/it]: train_loss_raw=0.4298, running_loss=0.3548, LR=0.000100
[2025-08-11 03:25:42,979][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106836] [Batch 03460/03692] [00:31:44/00:02:07, 0.550s/it]: train_loss_raw=0.3689, running_loss=0.3567, LR=0.000100
[2025-08-11 03:25:49,339][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106848] [Batch 03472/03692] [00:31:50/00:02:01, 0.550s/it]: train_loss_raw=0.2668, running_loss=0.3559, LR=0.000100
[2025-08-11 03:25:55,803][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106860] [Batch 03484/03692] [00:31:56/00:01:54, 0.550s/it]: train_loss_raw=0.3693, running_loss=0.3563, LR=0.000100
[2025-08-11 03:26:02,332][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106872] [Batch 03496/03692] [00:32:03/00:01:47, 0.550s/it]: train_loss_raw=0.3417, running_loss=0.3567, LR=0.000100
[2025-08-11 03:26:08,669][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106884] [Batch 03508/03692] [00:32:09/00:01:41, 0.550s/it]: train_loss_raw=0.3380, running_loss=0.3561, LR=0.000100
[2025-08-11 03:26:15,062][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106896] [Batch 03520/03692] [00:32:16/00:01:34, 0.550s/it]: train_loss_raw=0.4245, running_loss=0.3601, LR=0.000100
[2025-08-11 03:26:21,494][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106908] [Batch 03532/03692] [00:32:22/00:01:27, 0.550s/it]: train_loss_raw=0.3545, running_loss=0.3592, LR=0.000100
[2025-08-11 03:26:28,151][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106920] [Batch 03544/03692] [00:32:29/00:01:21, 0.550s/it]: train_loss_raw=0.3463, running_loss=0.3592, LR=0.000100
[2025-08-11 03:26:34,686][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106932] [Batch 03556/03692] [00:32:35/00:01:14, 0.550s/it]: train_loss_raw=0.4153, running_loss=0.3606, LR=0.000100
[2025-08-11 03:26:41,138][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106944] [Batch 03568/03692] [00:32:42/00:01:08, 0.550s/it]: train_loss_raw=0.4408, running_loss=0.3634, LR=0.000100
[2025-08-11 03:26:47,581][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106956] [Batch 03580/03692] [00:32:48/00:01:01, 0.550s/it]: train_loss_raw=0.4666, running_loss=0.3631, LR=0.000100
[2025-08-11 03:26:54,049][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106968] [Batch 03592/03692] [00:32:55/00:00:54, 0.550s/it]: train_loss_raw=0.3492, running_loss=0.3649, LR=0.000100
[2025-08-11 03:27:00,527][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106980] [Batch 03604/03692] [00:33:01/00:00:48, 0.550s/it]: train_loss_raw=0.3648, running_loss=0.3642, LR=0.000100
[2025-08-11 03:27:06,949][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106992] [Batch 03616/03692] [00:33:08/00:00:41, 0.550s/it]: train_loss_raw=0.2145, running_loss=0.3622, LR=0.000100
[2025-08-11 03:27:13,295][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107004] [Batch 03628/03692] [00:33:14/00:00:35, 0.550s/it]: train_loss_raw=0.3071, running_loss=0.3608, LR=0.000100
[2025-08-11 03:27:19,660][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107016] [Batch 03640/03692] [00:33:20/00:00:28, 0.550s/it]: train_loss_raw=0.3291, running_loss=0.3597, LR=0.000100
[2025-08-11 03:27:26,054][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107028] [Batch 03652/03692] [00:33:27/00:00:21, 0.550s/it]: train_loss_raw=0.4068, running_loss=0.3600, LR=0.000100
[2025-08-11 03:27:32,538][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107040] [Batch 03664/03692] [00:33:33/00:00:15, 0.550s/it]: train_loss_raw=0.3170, running_loss=0.3595, LR=0.000100
[2025-08-11 03:27:39,024][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107052] [Batch 03676/03692] [00:33:40/00:00:08, 0.550s/it]: train_loss_raw=0.4348, running_loss=0.3578, LR=0.000100
[2025-08-11 03:27:45,519][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107064] [Batch 03688/03692] [00:33:46/00:00:02, 0.550s/it]: train_loss_raw=0.3949, running_loss=0.3584, LR=0.000100
[2025-08-11 03:27:53,010][__main__][INFO] - [VALIDATION] [Epoch 28/29] Starting validation.
[2025-08-11 03:28:26,253][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 107069] [Batch 00011/00025] [00:00:33/00:00:36, 2.770s/it]
[2025-08-11 03:28:41,675][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 107069] [Batch 00023/00025] [00:00:48/00:00:02, 2.028s/it]
[2025-08-11 03:28:42,812][__main__][INFO] - [VALIDATION] [Epoch 28/29] train_loss=0.35874, valid_loss=0.55003
[2025-08-11 03:28:42,812][__main__][INFO] - [VALIDATION] [Epoch 28/29] Metrics:
[2025-08-11 03:28:42,812][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_er      0.212
[2025-08-11 03:28:42,813][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_prec    0.585
[2025-08-11 03:28:42,813][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_recall  0.590
[2025-08-11 03:28:42,813][__main__][INFO] - [VALIDATION] [Epoch 28/29] - pep_recall 0.585
[2025-08-11 03:28:42,817][__main__][INFO] - [TRAIN] [Epoch 28/29] Epoch complete, total time 16:32:42, remaining time 00:34:13, 00:34:13 per epoch
[2025-08-11 03:28:46,922][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107076] [Batch 00008/03692] [00:00:03/00:29:31, 0.481s/it]: train_loss_raw=0.4122, running_loss=0.2831, LR=0.000100
[2025-08-11 03:28:53,410][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107088] [Batch 00020/03692] [00:00:10/00:31:37, 0.517s/it]: train_loss_raw=0.2938, running_loss=0.2887, LR=0.000100
[2025-08-11 03:28:59,819][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107100] [Batch 00032/03692] [00:00:16/00:31:55, 0.523s/it]: train_loss_raw=0.4253, running_loss=0.2970, LR=0.000100
[2025-08-11 03:29:06,187][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107112] [Batch 00044/03692] [00:00:23/00:31:56, 0.525s/it]: train_loss_raw=0.4715, running_loss=0.3041, LR=0.000100
[2025-08-11 03:29:12,669][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107124] [Batch 00056/03692] [00:00:29/00:32:01, 0.528s/it]: train_loss_raw=0.2710, running_loss=0.3106, LR=0.000100
[2025-08-11 03:29:19,121][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107136] [Batch 00068/03692] [00:00:36/00:32:01, 0.530s/it]: train_loss_raw=0.3344, running_loss=0.3138, LR=0.000100
[2025-08-11 03:29:25,480][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107148] [Batch 00080/03692] [00:00:42/00:31:54, 0.530s/it]: train_loss_raw=0.3910, running_loss=0.3197, LR=0.000100
[2025-08-11 03:29:31,915][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107160] [Batch 00092/03692] [00:00:48/00:31:51, 0.531s/it]: train_loss_raw=0.4121, running_loss=0.3227, LR=0.000100
[2025-08-11 03:29:38,289][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107172] [Batch 00104/03692] [00:00:55/00:31:44, 0.531s/it]: train_loss_raw=0.3426, running_loss=0.3260, LR=0.000100
[2025-08-11 03:29:44,674][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107184] [Batch 00116/03692] [00:01:01/00:31:38, 0.531s/it]: train_loss_raw=0.3409, running_loss=0.3294, LR=0.000100
[2025-08-11 03:29:51,055][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107196] [Batch 00128/03692] [00:01:07/00:31:32, 0.531s/it]: train_loss_raw=0.2989, running_loss=0.3332, LR=0.000100
[2025-08-11 03:29:57,456][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107208] [Batch 00140/03692] [00:01:14/00:31:27, 0.531s/it]: train_loss_raw=0.3999, running_loss=0.3375, LR=0.000100
[2025-08-11 03:30:03,855][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107220] [Batch 00152/03692] [00:01:20/00:31:21, 0.531s/it]: train_loss_raw=0.3171, running_loss=0.3389, LR=0.000100
[2025-08-11 03:30:10,302][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107232] [Batch 00164/03692] [00:01:27/00:31:16, 0.532s/it]: train_loss_raw=0.3862, running_loss=0.3449, LR=0.000100
[2025-08-11 03:30:16,662][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107244] [Batch 00176/03692] [00:01:33/00:31:09, 0.532s/it]: train_loss_raw=0.4272, running_loss=0.3465, LR=0.000100
[2025-08-11 03:30:23,040][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107256] [Batch 00188/03692] [00:01:39/00:31:03, 0.532s/it]: train_loss_raw=0.4000, running_loss=0.3465, LR=0.000100
[2025-08-11 03:30:29,446][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107268] [Batch 00200/03692] [00:01:46/00:30:57, 0.532s/it]: train_loss_raw=0.3279, running_loss=0.3479, LR=0.000100
[2025-08-11 03:30:35,811][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107280] [Batch 00212/03692] [00:01:52/00:30:50, 0.532s/it]: train_loss_raw=0.3569, running_loss=0.3474, LR=0.000100
[2025-08-11 03:30:42,199][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107292] [Batch 00224/03692] [00:01:59/00:30:44, 0.532s/it]: train_loss_raw=0.3169, running_loss=0.3503, LR=0.000100
[2025-08-11 03:30:48,671][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107304] [Batch 00236/03692] [00:02:05/00:30:39, 0.532s/it]: train_loss_raw=0.4665, running_loss=0.3502, LR=0.000100
[2025-08-11 03:30:55,177][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107316] [Batch 00248/03692] [00:02:12/00:30:34, 0.533s/it]: train_loss_raw=0.3287, running_loss=0.3531, LR=0.000100
[2025-08-11 03:31:01,613][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107328] [Batch 00260/03692] [00:02:18/00:30:28, 0.533s/it]: train_loss_raw=0.4719, running_loss=0.3553, LR=0.000100
[2025-08-11 03:31:07,941][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107340] [Batch 00272/03692] [00:02:24/00:30:21, 0.533s/it]: train_loss_raw=0.3438, running_loss=0.3547, LR=0.000100
[2025-08-11 03:31:14,293][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107352] [Batch 00284/03692] [00:02:31/00:30:14, 0.532s/it]: train_loss_raw=0.3602, running_loss=0.3567, LR=0.000100
[2025-08-11 03:31:20,643][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107364] [Batch 00296/03692] [00:02:37/00:30:07, 0.532s/it]: train_loss_raw=0.3513, running_loss=0.3573, LR=0.000100
[2025-08-11 03:31:26,986][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107376] [Batch 00308/03692] [00:02:43/00:30:00, 0.532s/it]: train_loss_raw=0.4931, running_loss=0.3592, LR=0.000100
[2025-08-11 03:31:33,426][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107388] [Batch 00320/03692] [00:02:50/00:29:55, 0.532s/it]: train_loss_raw=0.4407, running_loss=0.3621, LR=0.000100
[2025-08-11 03:31:39,806][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107400] [Batch 00332/03692] [00:02:56/00:29:48, 0.532s/it]: train_loss_raw=0.3227, running_loss=0.3611, LR=0.000100
[2025-08-11 03:31:46,307][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107412] [Batch 00344/03692] [00:03:03/00:29:43, 0.533s/it]: train_loss_raw=0.3954, running_loss=0.3615, LR=0.000100
[2025-08-11 03:31:52,711][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107424] [Batch 00356/03692] [00:03:09/00:29:37, 0.533s/it]: train_loss_raw=0.4064, running_loss=0.3644, LR=0.000100
[2025-08-11 03:31:59,139][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107436] [Batch 00368/03692] [00:03:16/00:29:30, 0.533s/it]: train_loss_raw=0.3232, running_loss=0.3623, LR=0.000100
[2025-08-11 03:32:05,551][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107448] [Batch 00380/03692] [00:03:22/00:29:24, 0.533s/it]: train_loss_raw=0.2961, running_loss=0.3583, LR=0.000100
[2025-08-11 03:32:11,903][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107460] [Batch 00392/03692] [00:03:28/00:29:17, 0.533s/it]: train_loss_raw=0.3240, running_loss=0.3591, LR=0.000100
[2025-08-11 03:32:18,237][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107472] [Batch 00404/03692] [00:03:35/00:29:11, 0.533s/it]: train_loss_raw=0.3280, running_loss=0.3608, LR=0.000100
[2025-08-11 03:32:24,645][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107484] [Batch 00416/03692] [00:03:41/00:29:04, 0.533s/it]: train_loss_raw=0.3140, running_loss=0.3615, LR=0.000100
[2025-08-11 03:32:30,919][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107496] [Batch 00428/03692] [00:03:47/00:28:57, 0.532s/it]: train_loss_raw=0.3977, running_loss=0.3647, LR=0.000100
[2025-08-11 03:32:37,262][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107508] [Batch 00440/03692] [00:03:54/00:28:50, 0.532s/it]: train_loss_raw=0.3295, running_loss=0.3649, LR=0.000100
[2025-08-11 03:32:43,645][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107520] [Batch 00452/03692] [00:04:00/00:28:44, 0.532s/it]: train_loss_raw=0.4491, running_loss=0.3650, LR=0.000100
[2025-08-11 03:32:49,990][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107532] [Batch 00464/03692] [00:04:06/00:28:37, 0.532s/it]: train_loss_raw=0.2588, running_loss=0.3624, LR=0.000100
[2025-08-11 03:32:56,370][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107544] [Batch 00476/03692] [00:04:13/00:28:31, 0.532s/it]: train_loss_raw=0.3284, running_loss=0.3639, LR=0.000100
[2025-08-11 03:33:02,714][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107556] [Batch 00488/03692] [00:04:19/00:28:24, 0.532s/it]: train_loss_raw=0.3284, running_loss=0.3598, LR=0.000100
[2025-08-11 03:33:09,098][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107568] [Batch 00500/03692] [00:04:26/00:28:18, 0.532s/it]: train_loss_raw=0.3777, running_loss=0.3614, LR=0.000100
[2025-08-11 03:33:15,405][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107580] [Batch 00512/03692] [00:04:32/00:28:11, 0.532s/it]: train_loss_raw=0.4115, running_loss=0.3605, LR=0.000100
[2025-08-11 03:33:21,694][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107592] [Batch 00524/03692] [00:04:38/00:28:04, 0.532s/it]: train_loss_raw=0.4056, running_loss=0.3602, LR=0.000100
[2025-08-11 03:33:28,036][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107604] [Batch 00536/03692] [00:04:44/00:27:57, 0.532s/it]: train_loss_raw=0.3249, running_loss=0.3622, LR=0.000100
[2025-08-11 03:33:34,358][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107616] [Batch 00548/03692] [00:04:51/00:27:51, 0.532s/it]: train_loss_raw=0.3344, running_loss=0.3602, LR=0.000100
[2025-08-11 03:33:40,803][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107628] [Batch 00560/03692] [00:04:57/00:27:45, 0.532s/it]: train_loss_raw=0.4053, running_loss=0.3592, LR=0.000100
[2025-08-11 03:33:47,165][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107640] [Batch 00572/03692] [00:05:04/00:27:38, 0.532s/it]: train_loss_raw=0.3544, running_loss=0.3596, LR=0.000100
[2025-08-11 03:33:53,469][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107652] [Batch 00584/03692] [00:05:10/00:27:31, 0.531s/it]: train_loss_raw=0.3450, running_loss=0.3568, LR=0.000100
[2025-08-11 03:33:59,833][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107664] [Batch 00596/03692] [00:05:16/00:27:25, 0.531s/it]: train_loss_raw=0.3349, running_loss=0.3583, LR=0.000100
[2025-08-11 03:34:06,245][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107676] [Batch 00608/03692] [00:05:23/00:27:19, 0.532s/it]: train_loss_raw=0.3937, running_loss=0.3606, LR=0.000100
[2025-08-11 03:34:12,689][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107688] [Batch 00620/03692] [00:05:29/00:27:13, 0.532s/it]: train_loss_raw=0.3881, running_loss=0.3618, LR=0.000100
[2025-08-11 03:34:19,036][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107700] [Batch 00632/03692] [00:05:35/00:27:06, 0.532s/it]: train_loss_raw=0.3383, running_loss=0.3602, LR=0.000100
[2025-08-11 03:34:25,442][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107712] [Batch 00644/03692] [00:05:42/00:27:00, 0.532s/it]: train_loss_raw=0.3751, running_loss=0.3609, LR=0.000100
[2025-08-11 03:34:31,787][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107724] [Batch 00656/03692] [00:05:48/00:26:53, 0.532s/it]: train_loss_raw=0.4190, running_loss=0.3616, LR=0.000100
[2025-08-11 03:34:38,157][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107736] [Batch 00668/03692] [00:05:55/00:26:47, 0.532s/it]: train_loss_raw=0.3719, running_loss=0.3610, LR=0.000100
[2025-08-11 03:34:44,648][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107748] [Batch 00680/03692] [00:06:01/00:26:41, 0.532s/it]: train_loss_raw=0.3647, running_loss=0.3643, LR=0.000100
[2025-08-11 03:34:51,129][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107760] [Batch 00692/03692] [00:06:08/00:26:35, 0.532s/it]: train_loss_raw=0.3596, running_loss=0.3658, LR=0.000100
[2025-08-11 03:34:57,549][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107772] [Batch 00704/03692] [00:06:14/00:26:29, 0.532s/it]: train_loss_raw=0.3258, running_loss=0.3637, LR=0.000100
[2025-08-11 03:35:03,921][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107784] [Batch 00716/03692] [00:06:20/00:26:22, 0.532s/it]: train_loss_raw=0.3861, running_loss=0.3598, LR=0.000100
[2025-08-11 03:35:10,247][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107796] [Batch 00728/03692] [00:06:27/00:26:16, 0.532s/it]: train_loss_raw=0.2946, running_loss=0.3584, LR=0.000100
[2025-08-11 03:35:16,758][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107808] [Batch 00740/03692] [00:06:33/00:26:10, 0.532s/it]: train_loss_raw=0.2899, running_loss=0.3600, LR=0.000100
[2025-08-11 03:35:23,169][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107820] [Batch 00752/03692] [00:06:40/00:26:04, 0.532s/it]: train_loss_raw=0.3568, running_loss=0.3601, LR=0.000100
[2025-08-11 03:35:29,517][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107832] [Batch 00764/03692] [00:06:46/00:25:57, 0.532s/it]: train_loss_raw=0.3347, running_loss=0.3597, LR=0.000100
[2025-08-11 03:35:35,848][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107844] [Batch 00776/03692] [00:06:52/00:25:51, 0.532s/it]: train_loss_raw=0.3502, running_loss=0.3629, LR=0.000100
[2025-08-11 03:35:42,280][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107856] [Batch 00788/03692] [00:06:59/00:25:44, 0.532s/it]: train_loss_raw=0.3692, running_loss=0.3631, LR=0.000100
[2025-08-11 03:35:48,734][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107868] [Batch 00800/03692] [00:07:05/00:25:38, 0.532s/it]: train_loss_raw=0.3326, running_loss=0.3637, LR=0.000100
[2025-08-11 03:35:55,094][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107880] [Batch 00812/03692] [00:07:12/00:25:32, 0.532s/it]: train_loss_raw=0.3165, running_loss=0.3635, LR=0.000100
[2025-08-11 03:36:01,443][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107892] [Batch 00824/03692] [00:07:18/00:25:25, 0.532s/it]: train_loss_raw=0.4153, running_loss=0.3648, LR=0.000100
[2025-08-11 03:36:07,815][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107904] [Batch 00836/03692] [00:07:24/00:25:19, 0.532s/it]: train_loss_raw=0.3568, running_loss=0.3662, LR=0.000100
[2025-08-11 03:36:14,198][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107916] [Batch 00848/03692] [00:07:31/00:25:12, 0.532s/it]: train_loss_raw=0.3102, running_loss=0.3646, LR=0.000100
[2025-08-11 03:36:20,606][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107928] [Batch 00860/03692] [00:07:37/00:25:06, 0.532s/it]: train_loss_raw=0.2978, running_loss=0.3618, LR=0.000100
[2025-08-11 03:36:26,966][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107940] [Batch 00872/03692] [00:07:43/00:25:00, 0.532s/it]: train_loss_raw=0.2755, running_loss=0.3625, LR=0.000100
[2025-08-11 03:36:33,316][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107952] [Batch 00884/03692] [00:07:50/00:24:53, 0.532s/it]: train_loss_raw=0.4181, running_loss=0.3645, LR=0.000100
[2025-08-11 03:36:39,700][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107964] [Batch 00896/03692] [00:07:56/00:24:47, 0.532s/it]: train_loss_raw=0.4113, running_loss=0.3642, LR=0.000100
[2025-08-11 03:36:46,140][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107976] [Batch 00908/03692] [00:08:03/00:24:41, 0.532s/it]: train_loss_raw=0.3171, running_loss=0.3674, LR=0.000100
[2025-08-11 03:36:52,495][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107988] [Batch 00920/03692] [00:08:09/00:24:34, 0.532s/it]: train_loss_raw=0.3898, running_loss=0.3671, LR=0.000100
[2025-08-11 03:36:58,874][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108000] [Batch 00932/03692] [00:08:15/00:24:28, 0.532s/it]: train_loss_raw=0.3586, running_loss=0.3678, LR=0.000100
[2025-08-11 03:37:10,507][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108012] [Batch 00944/03692] [00:08:27/00:24:37, 0.538s/it]: train_loss_raw=0.3587, running_loss=0.3649, LR=0.000100
[2025-08-11 03:37:17,034][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108024] [Batch 00956/03692] [00:08:33/00:24:30, 0.538s/it]: train_loss_raw=0.4212, running_loss=0.3625, LR=0.000100
[2025-08-11 03:37:23,437][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108036] [Batch 00968/03692] [00:08:40/00:24:24, 0.538s/it]: train_loss_raw=0.3501, running_loss=0.3619, LR=0.000100
[2025-08-11 03:37:29,837][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108048] [Batch 00980/03692] [00:08:46/00:24:17, 0.538s/it]: train_loss_raw=0.3718, running_loss=0.3614, LR=0.000100
[2025-08-11 03:37:36,263][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108060] [Batch 00992/03692] [00:08:53/00:24:11, 0.537s/it]: train_loss_raw=0.3816, running_loss=0.3609, LR=0.000100
[2025-08-11 03:37:42,681][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108072] [Batch 01004/03692] [00:08:59/00:24:04, 0.537s/it]: train_loss_raw=0.2995, running_loss=0.3610, LR=0.000100
[2025-08-11 03:37:49,117][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108084] [Batch 01016/03692] [00:09:06/00:23:58, 0.537s/it]: train_loss_raw=0.5173, running_loss=0.3639, LR=0.000100
[2025-08-11 03:37:55,476][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108096] [Batch 01028/03692] [00:09:12/00:23:51, 0.537s/it]: train_loss_raw=0.3457, running_loss=0.3639, LR=0.000100
[2025-08-11 03:38:01,825][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108108] [Batch 01040/03692] [00:09:18/00:23:44, 0.537s/it]: train_loss_raw=0.4563, running_loss=0.3664, LR=0.000100
[2025-08-11 03:38:08,177][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108120] [Batch 01052/03692] [00:09:25/00:23:38, 0.537s/it]: train_loss_raw=0.3929, running_loss=0.3643, LR=0.000100
[2025-08-11 03:38:14,573][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108132] [Batch 01064/03692] [00:09:31/00:23:31, 0.537s/it]: train_loss_raw=0.3902, running_loss=0.3636, LR=0.000100
[2025-08-11 03:38:20,912][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108144] [Batch 01076/03692] [00:09:37/00:23:24, 0.537s/it]: train_loss_raw=0.4504, running_loss=0.3635, LR=0.000100
[2025-08-11 03:38:27,270][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108156] [Batch 01088/03692] [00:09:44/00:23:18, 0.537s/it]: train_loss_raw=0.4363, running_loss=0.3620, LR=0.000100
[2025-08-11 03:38:33,652][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108168] [Batch 01100/03692] [00:09:50/00:23:11, 0.537s/it]: train_loss_raw=0.3932, running_loss=0.3626, LR=0.000100
[2025-08-11 03:38:40,056][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108180] [Batch 01112/03692] [00:09:56/00:23:05, 0.537s/it]: train_loss_raw=0.3325, running_loss=0.3630, LR=0.000100
[2025-08-11 03:38:46,641][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108192] [Batch 01124/03692] [00:10:03/00:22:58, 0.537s/it]: train_loss_raw=0.3389, running_loss=0.3589, LR=0.000100
[2025-08-11 03:38:53,105][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108204] [Batch 01136/03692] [00:10:10/00:22:52, 0.537s/it]: train_loss_raw=0.2875, running_loss=0.3551, LR=0.000100
[2025-08-11 03:38:59,586][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108216] [Batch 01148/03692] [00:10:16/00:22:46, 0.537s/it]: train_loss_raw=0.3472, running_loss=0.3566, LR=0.000100
[2025-08-11 03:39:06,179][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108228] [Batch 01160/03692] [00:10:23/00:22:40, 0.537s/it]: train_loss_raw=0.4102, running_loss=0.3586, LR=0.000100
[2025-08-11 03:39:12,626][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108240] [Batch 01172/03692] [00:10:29/00:22:33, 0.537s/it]: train_loss_raw=0.3337, running_loss=0.3601, LR=0.000100
[2025-08-11 03:39:19,157][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108252] [Batch 01184/03692] [00:10:36/00:22:27, 0.537s/it]: train_loss_raw=0.3396, running_loss=0.3605, LR=0.000100
[2025-08-11 03:39:25,650][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108264] [Batch 01196/03692] [00:10:42/00:22:21, 0.537s/it]: train_loss_raw=0.3194, running_loss=0.3602, LR=0.000100
[2025-08-11 03:39:32,142][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108276] [Batch 01208/03692] [00:10:49/00:22:14, 0.537s/it]: train_loss_raw=0.4807, running_loss=0.3642, LR=0.000100
[2025-08-11 03:39:38,631][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108288] [Batch 01220/03692] [00:10:55/00:22:08, 0.537s/it]: train_loss_raw=0.3290, running_loss=0.3659, LR=0.000100
[2025-08-11 03:39:45,129][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108300] [Batch 01232/03692] [00:11:02/00:22:01, 0.537s/it]: train_loss_raw=0.3870, running_loss=0.3646, LR=0.000100
[2025-08-11 03:39:51,606][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108312] [Batch 01244/03692] [00:11:08/00:21:55, 0.537s/it]: train_loss_raw=0.2729, running_loss=0.3641, LR=0.000100
[2025-08-11 03:39:58,066][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108324] [Batch 01256/03692] [00:11:14/00:21:49, 0.537s/it]: train_loss_raw=0.3011, running_loss=0.3655, LR=0.000100
[2025-08-11 03:40:04,577][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108336] [Batch 01268/03692] [00:11:21/00:21:42, 0.537s/it]: train_loss_raw=0.4422, running_loss=0.3639, LR=0.000100
[2025-08-11 03:40:11,077][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108348] [Batch 01280/03692] [00:11:28/00:21:36, 0.538s/it]: train_loss_raw=0.3655, running_loss=0.3625, LR=0.000100
[2025-08-11 03:40:17,333][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108360] [Batch 01292/03692] [00:11:34/00:21:29, 0.537s/it]: train_loss_raw=0.2972, running_loss=0.3619, LR=0.000100
[2025-08-11 03:40:23,789][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108372] [Batch 01304/03692] [00:11:40/00:21:23, 0.537s/it]: train_loss_raw=0.4223, running_loss=0.3565, LR=0.000100
[2025-08-11 03:40:30,236][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108384] [Batch 01316/03692] [00:11:47/00:21:16, 0.537s/it]: train_loss_raw=0.3582, running_loss=0.3589, LR=0.000100
[2025-08-11 03:40:36,732][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108396] [Batch 01328/03692] [00:11:53/00:21:10, 0.537s/it]: train_loss_raw=0.4756, running_loss=0.3615, LR=0.000100
[2025-08-11 03:40:43,278][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108408] [Batch 01340/03692] [00:12:00/00:21:04, 0.537s/it]: train_loss_raw=0.3363, running_loss=0.3614, LR=0.000100
[2025-08-11 03:40:49,743][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108420] [Batch 01352/03692] [00:12:06/00:20:57, 0.537s/it]: train_loss_raw=0.3914, running_loss=0.3624, LR=0.000100
[2025-08-11 03:40:56,297][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108432] [Batch 01364/03692] [00:12:13/00:20:51, 0.538s/it]: train_loss_raw=0.3863, running_loss=0.3608, LR=0.000100
[2025-08-11 03:41:02,796][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108444] [Batch 01376/03692] [00:12:19/00:20:45, 0.538s/it]: train_loss_raw=0.3434, running_loss=0.3598, LR=0.000100
[2025-08-11 03:41:09,290][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108456] [Batch 01388/03692] [00:12:26/00:20:38, 0.538s/it]: train_loss_raw=0.4823, running_loss=0.3616, LR=0.000100
[2025-08-11 03:41:15,660][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108468] [Batch 01400/03692] [00:12:32/00:20:32, 0.538s/it]: train_loss_raw=0.4351, running_loss=0.3609, LR=0.000100
[2025-08-11 03:41:22,132][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108480] [Batch 01412/03692] [00:12:39/00:20:25, 0.538s/it]: train_loss_raw=0.3660, running_loss=0.3584, LR=0.000100
[2025-08-11 03:41:28,742][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108492] [Batch 01424/03692] [00:12:45/00:20:19, 0.538s/it]: train_loss_raw=0.3262, running_loss=0.3599, LR=0.000100
[2025-08-11 03:41:35,259][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108504] [Batch 01436/03692] [00:12:52/00:20:13, 0.538s/it]: train_loss_raw=0.3022, running_loss=0.3582, LR=0.000100
[2025-08-11 03:41:41,789][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108516] [Batch 01448/03692] [00:12:58/00:20:06, 0.538s/it]: train_loss_raw=0.2989, running_loss=0.3582, LR=0.000100
[2025-08-11 03:41:48,280][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108528] [Batch 01460/03692] [00:13:05/00:20:00, 0.538s/it]: train_loss_raw=0.3539, running_loss=0.3592, LR=0.000100
[2025-08-11 03:41:54,750][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108540] [Batch 01472/03692] [00:13:11/00:19:53, 0.538s/it]: train_loss_raw=0.3206, running_loss=0.3599, LR=0.000100
[2025-08-11 03:42:01,257][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108552] [Batch 01484/03692] [00:13:18/00:19:47, 0.538s/it]: train_loss_raw=0.3183, running_loss=0.3597, LR=0.000100
[2025-08-11 03:42:07,541][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108564] [Batch 01496/03692] [00:13:24/00:19:40, 0.538s/it]: train_loss_raw=0.3821, running_loss=0.3586, LR=0.000100
[2025-08-11 03:42:13,924][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108576] [Batch 01508/03692] [00:13:30/00:19:34, 0.538s/it]: train_loss_raw=0.3403, running_loss=0.3559, LR=0.000100
[2025-08-11 03:42:20,253][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108588] [Batch 01520/03692] [00:13:37/00:19:27, 0.538s/it]: train_loss_raw=0.3489, running_loss=0.3557, LR=0.000100
[2025-08-11 03:42:26,678][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108600] [Batch 01532/03692] [00:13:43/00:19:21, 0.538s/it]: train_loss_raw=0.3290, running_loss=0.3576, LR=0.000100
[2025-08-11 03:42:33,250][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108612] [Batch 01544/03692] [00:13:50/00:19:14, 0.538s/it]: train_loss_raw=0.4104, running_loss=0.3589, LR=0.000100
[2025-08-11 03:42:39,624][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108624] [Batch 01556/03692] [00:13:56/00:19:08, 0.538s/it]: train_loss_raw=0.3984, running_loss=0.3594, LR=0.000100
[2025-08-11 03:42:46,022][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108636] [Batch 01568/03692] [00:14:02/00:19:01, 0.538s/it]: train_loss_raw=0.3470, running_loss=0.3569, LR=0.000100
[2025-08-11 03:42:52,411][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108648] [Batch 01580/03692] [00:14:09/00:18:55, 0.538s/it]: train_loss_raw=0.3806, running_loss=0.3568, LR=0.000100
[2025-08-11 03:42:58,870][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108660] [Batch 01592/03692] [00:14:15/00:18:48, 0.538s/it]: train_loss_raw=0.3770, running_loss=0.3598, LR=0.000100
[2025-08-11 03:43:05,186][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108672] [Batch 01604/03692] [00:14:22/00:18:42, 0.537s/it]: train_loss_raw=0.4220, running_loss=0.3614, LR=0.000100
[2025-08-11 03:43:11,549][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108684] [Batch 01616/03692] [00:14:28/00:18:35, 0.537s/it]: train_loss_raw=0.3197, running_loss=0.3578, LR=0.000100
[2025-08-11 03:43:17,992][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108696] [Batch 01628/03692] [00:14:34/00:18:29, 0.537s/it]: train_loss_raw=0.3881, running_loss=0.3593, LR=0.000100
[2025-08-11 03:43:24,366][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108708] [Batch 01640/03692] [00:14:41/00:18:22, 0.537s/it]: train_loss_raw=0.3133, running_loss=0.3578, LR=0.000100
[2025-08-11 03:43:30,763][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108720] [Batch 01652/03692] [00:14:47/00:18:16, 0.537s/it]: train_loss_raw=0.3953, running_loss=0.3586, LR=0.000100
[2025-08-11 03:43:37,133][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108732] [Batch 01664/03692] [00:14:54/00:18:09, 0.537s/it]: train_loss_raw=0.3634, running_loss=0.3576, LR=0.000100
[2025-08-11 03:43:43,517][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108744] [Batch 01676/03692] [00:15:00/00:18:03, 0.537s/it]: train_loss_raw=0.3103, running_loss=0.3566, LR=0.000100
[2025-08-11 03:43:49,827][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108756] [Batch 01688/03692] [00:15:06/00:17:56, 0.537s/it]: train_loss_raw=0.4353, running_loss=0.3603, LR=0.000100
[2025-08-11 03:43:56,173][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108768] [Batch 01700/03692] [00:15:13/00:17:49, 0.537s/it]: train_loss_raw=0.3988, running_loss=0.3583, LR=0.000100
[2025-08-11 03:44:02,573][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108780] [Batch 01712/03692] [00:15:19/00:17:43, 0.537s/it]: train_loss_raw=0.3327, running_loss=0.3561, LR=0.000100
[2025-08-11 03:44:08,927][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108792] [Batch 01724/03692] [00:15:25/00:17:36, 0.537s/it]: train_loss_raw=0.3753, running_loss=0.3561, LR=0.000100
[2025-08-11 03:44:15,267][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108804] [Batch 01736/03692] [00:15:32/00:17:30, 0.537s/it]: train_loss_raw=0.3479, running_loss=0.3549, LR=0.000100
[2025-08-11 03:44:21,613][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108816] [Batch 01748/03692] [00:15:38/00:17:23, 0.537s/it]: train_loss_raw=0.3073, running_loss=0.3574, LR=0.000100
[2025-08-11 03:44:28,004][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108828] [Batch 01760/03692] [00:15:44/00:17:17, 0.537s/it]: train_loss_raw=0.3948, running_loss=0.3560, LR=0.000100
[2025-08-11 03:44:34,411][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108840] [Batch 01772/03692] [00:15:51/00:17:10, 0.537s/it]: train_loss_raw=0.4112, running_loss=0.3575, LR=0.000100
[2025-08-11 03:44:40,938][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108852] [Batch 01784/03692] [00:15:57/00:17:04, 0.537s/it]: train_loss_raw=0.3709, running_loss=0.3577, LR=0.000100
[2025-08-11 03:44:47,381][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108864] [Batch 01796/03692] [00:16:04/00:16:57, 0.537s/it]: train_loss_raw=0.3017, running_loss=0.3590, LR=0.000100
[2025-08-11 03:44:53,796][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108876] [Batch 01808/03692] [00:16:10/00:16:51, 0.537s/it]: train_loss_raw=0.3925, running_loss=0.3573, LR=0.000100
[2025-08-11 03:45:00,176][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108888] [Batch 01820/03692] [00:16:17/00:16:45, 0.537s/it]: train_loss_raw=0.3297, running_loss=0.3586, LR=0.000100
[2025-08-11 03:45:06,650][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108900] [Batch 01832/03692] [00:16:23/00:16:38, 0.537s/it]: train_loss_raw=0.2813, running_loss=0.3587, LR=0.000100
[2025-08-11 03:45:12,988][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108912] [Batch 01844/03692] [00:16:29/00:16:32, 0.537s/it]: train_loss_raw=0.3341, running_loss=0.3564, LR=0.000100
[2025-08-11 03:45:19,268][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108924] [Batch 01856/03692] [00:16:36/00:16:25, 0.537s/it]: train_loss_raw=0.3955, running_loss=0.3569, LR=0.000100
[2025-08-11 03:45:25,506][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108936] [Batch 01868/03692] [00:16:42/00:16:18, 0.537s/it]: train_loss_raw=0.3842, running_loss=0.3564, LR=0.000100
[2025-08-11 03:45:31,746][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108948] [Batch 01880/03692] [00:16:48/00:16:12, 0.537s/it]: train_loss_raw=0.4345, running_loss=0.3541, LR=0.000100
[2025-08-11 03:45:37,949][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108960] [Batch 01892/03692] [00:16:54/00:16:05, 0.536s/it]: train_loss_raw=0.4036, running_loss=0.3538, LR=0.000100
[2025-08-11 03:45:44,292][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108972] [Batch 01904/03692] [00:17:01/00:15:58, 0.536s/it]: train_loss_raw=0.3208, running_loss=0.3516, LR=0.000100
[2025-08-11 03:45:50,800][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108984] [Batch 01916/03692] [00:17:07/00:15:52, 0.536s/it]: train_loss_raw=0.2811, running_loss=0.3557, LR=0.000100
[2025-08-11 03:45:57,201][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108996] [Batch 01928/03692] [00:17:14/00:15:46, 0.536s/it]: train_loss_raw=0.2570, running_loss=0.3542, LR=0.000100
[2025-08-11 03:46:03,594][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109008] [Batch 01940/03692] [00:17:20/00:15:39, 0.536s/it]: train_loss_raw=0.3711, running_loss=0.3547, LR=0.000100
[2025-08-11 03:46:10,000][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109020] [Batch 01952/03692] [00:17:26/00:15:33, 0.536s/it]: train_loss_raw=0.4110, running_loss=0.3568, LR=0.000100
[2025-08-11 03:46:16,445][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109032] [Batch 01964/03692] [00:17:33/00:15:26, 0.536s/it]: train_loss_raw=0.3922, running_loss=0.3577, LR=0.000100
[2025-08-11 03:46:22,910][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109044] [Batch 01976/03692] [00:17:39/00:15:20, 0.536s/it]: train_loss_raw=0.3560, running_loss=0.3595, LR=0.000100
[2025-08-11 03:46:29,397][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109056] [Batch 01988/03692] [00:17:46/00:15:13, 0.536s/it]: train_loss_raw=0.4273, running_loss=0.3621, LR=0.000100
[2025-08-11 03:46:35,858][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109068] [Batch 02000/03692] [00:17:52/00:15:07, 0.536s/it]: train_loss_raw=0.3226, running_loss=0.3621, LR=0.000100
[2025-08-11 03:46:42,406][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109080] [Batch 02012/03692] [00:17:59/00:15:01, 0.536s/it]: train_loss_raw=0.4504, running_loss=0.3633, LR=0.000100
[2025-08-11 03:46:48,856][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109092] [Batch 02024/03692] [00:18:05/00:14:54, 0.536s/it]: train_loss_raw=0.3481, running_loss=0.3638, LR=0.000100
[2025-08-11 03:46:55,226][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109104] [Batch 02036/03692] [00:18:12/00:14:48, 0.536s/it]: train_loss_raw=0.3388, running_loss=0.3633, LR=0.000100
[2025-08-11 03:47:01,589][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109116] [Batch 02048/03692] [00:18:18/00:14:41, 0.536s/it]: train_loss_raw=0.4813, running_loss=0.3650, LR=0.000100
[2025-08-11 03:47:08,053][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109128] [Batch 02060/03692] [00:18:24/00:14:35, 0.536s/it]: train_loss_raw=0.3893, running_loss=0.3628, LR=0.000100
[2025-08-11 03:47:14,417][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109140] [Batch 02072/03692] [00:18:31/00:14:28, 0.536s/it]: train_loss_raw=0.3557, running_loss=0.3623, LR=0.000100
[2025-08-11 03:47:20,793][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109152] [Batch 02084/03692] [00:18:37/00:14:22, 0.536s/it]: train_loss_raw=0.4598, running_loss=0.3649, LR=0.000100
[2025-08-11 03:47:27,166][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109164] [Batch 02096/03692] [00:18:44/00:14:15, 0.536s/it]: train_loss_raw=0.3787, running_loss=0.3626, LR=0.000100
[2025-08-11 03:47:33,567][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109176] [Batch 02108/03692] [00:18:50/00:14:09, 0.536s/it]: train_loss_raw=0.3773, running_loss=0.3638, LR=0.000100
[2025-08-11 03:47:39,919][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109188] [Batch 02120/03692] [00:18:56/00:14:02, 0.536s/it]: train_loss_raw=0.3332, running_loss=0.3623, LR=0.000100
[2025-08-11 03:47:46,387][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109200] [Batch 02132/03692] [00:19:03/00:13:56, 0.536s/it]: train_loss_raw=0.4419, running_loss=0.3606, LR=0.000100
[2025-08-11 03:47:52,795][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109212] [Batch 02144/03692] [00:19:09/00:13:50, 0.536s/it]: train_loss_raw=0.4203, running_loss=0.3616, LR=0.000100
[2025-08-11 03:47:59,160][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109224] [Batch 02156/03692] [00:19:16/00:13:43, 0.536s/it]: train_loss_raw=0.3861, running_loss=0.3603, LR=0.000100
[2025-08-11 03:48:05,593][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109236] [Batch 02168/03692] [00:19:22/00:13:37, 0.536s/it]: train_loss_raw=0.4279, running_loss=0.3597, LR=0.000100
[2025-08-11 03:48:11,987][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109248] [Batch 02180/03692] [00:19:28/00:13:30, 0.536s/it]: train_loss_raw=0.3433, running_loss=0.3592, LR=0.000100
[2025-08-11 03:48:18,354][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109260] [Batch 02192/03692] [00:19:35/00:13:24, 0.536s/it]: train_loss_raw=0.2364, running_loss=0.3579, LR=0.000100
[2025-08-11 03:48:24,805][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109272] [Batch 02204/03692] [00:19:41/00:13:17, 0.536s/it]: train_loss_raw=0.4645, running_loss=0.3591, LR=0.000100
[2025-08-11 03:48:31,360][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109284] [Batch 02216/03692] [00:19:48/00:13:11, 0.536s/it]: train_loss_raw=0.3150, running_loss=0.3613, LR=0.000100
[2025-08-11 03:48:37,849][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109296] [Batch 02228/03692] [00:19:54/00:13:05, 0.536s/it]: train_loss_raw=0.3481, running_loss=0.3587, LR=0.000100
[2025-08-11 03:48:44,251][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109308] [Batch 02240/03692] [00:20:01/00:12:58, 0.536s/it]: train_loss_raw=0.2685, running_loss=0.3577, LR=0.000100
[2025-08-11 03:48:50,644][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109320] [Batch 02252/03692] [00:20:07/00:12:52, 0.536s/it]: train_loss_raw=0.3179, running_loss=0.3575, LR=0.000100
[2025-08-11 03:48:56,922][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109332] [Batch 02264/03692] [00:20:13/00:12:45, 0.536s/it]: train_loss_raw=0.3469, running_loss=0.3588, LR=0.000100
[2025-08-11 03:49:03,325][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109344] [Batch 02276/03692] [00:20:20/00:12:39, 0.536s/it]: train_loss_raw=0.3472, running_loss=0.3592, LR=0.000100
[2025-08-11 03:49:09,718][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109356] [Batch 02288/03692] [00:20:26/00:12:32, 0.536s/it]: train_loss_raw=0.3250, running_loss=0.3608, LR=0.000100
[2025-08-11 03:49:16,105][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109368] [Batch 02300/03692] [00:20:33/00:12:26, 0.536s/it]: train_loss_raw=0.4253, running_loss=0.3623, LR=0.000100
[2025-08-11 03:49:22,501][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109380] [Batch 02312/03692] [00:20:39/00:12:19, 0.536s/it]: train_loss_raw=0.3941, running_loss=0.3611, LR=0.000100
[2025-08-11 03:49:28,895][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109392] [Batch 02324/03692] [00:20:45/00:12:13, 0.536s/it]: train_loss_raw=0.3478, running_loss=0.3577, LR=0.000100
[2025-08-11 03:49:35,371][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109404] [Batch 02336/03692] [00:20:52/00:12:06, 0.536s/it]: train_loss_raw=0.3064, running_loss=0.3606, LR=0.000100
[2025-08-11 03:49:41,839][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109416] [Batch 02348/03692] [00:20:58/00:12:00, 0.536s/it]: train_loss_raw=0.3084, running_loss=0.3600, LR=0.000100
[2025-08-11 03:49:48,228][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109428] [Batch 02360/03692] [00:21:05/00:11:54, 0.536s/it]: train_loss_raw=0.2773, running_loss=0.3619, LR=0.000100
[2025-08-11 03:49:54,677][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109440] [Batch 02372/03692] [00:21:11/00:11:47, 0.536s/it]: train_loss_raw=0.3043, running_loss=0.3625, LR=0.000100
[2025-08-11 03:50:01,100][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109452] [Batch 02384/03692] [00:21:18/00:11:41, 0.536s/it]: train_loss_raw=0.3402, running_loss=0.3642, LR=0.000100
[2025-08-11 03:50:07,577][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109464] [Batch 02396/03692] [00:21:24/00:11:34, 0.536s/it]: train_loss_raw=0.3585, running_loss=0.3628, LR=0.000100
[2025-08-11 03:50:13,958][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109476] [Batch 02408/03692] [00:21:30/00:11:28, 0.536s/it]: train_loss_raw=0.3927, running_loss=0.3622, LR=0.000100
[2025-08-11 03:50:20,336][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109488] [Batch 02420/03692] [00:21:37/00:11:21, 0.536s/it]: train_loss_raw=0.3769, running_loss=0.3621, LR=0.000100
[2025-08-11 03:50:26,634][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109500] [Batch 02432/03692] [00:21:43/00:11:15, 0.536s/it]: train_loss_raw=0.3071, running_loss=0.3621, LR=0.000100
[2025-08-11 03:50:33,079][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109512] [Batch 02444/03692] [00:21:50/00:11:08, 0.536s/it]: train_loss_raw=0.4145, running_loss=0.3615, LR=0.000100
[2025-08-11 03:50:39,541][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109524] [Batch 02456/03692] [00:21:56/00:11:02, 0.536s/it]: train_loss_raw=0.3797, running_loss=0.3606, LR=0.000100
[2025-08-11 03:50:45,866][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109536] [Batch 02468/03692] [00:22:02/00:10:56, 0.536s/it]: train_loss_raw=0.4472, running_loss=0.3566, LR=0.000100
[2025-08-11 03:50:52,266][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109548] [Batch 02480/03692] [00:22:09/00:10:49, 0.536s/it]: train_loss_raw=0.4963, running_loss=0.3581, LR=0.000100
[2025-08-11 03:50:58,680][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109560] [Batch 02492/03692] [00:22:15/00:10:43, 0.536s/it]: train_loss_raw=0.3395, running_loss=0.3609, LR=0.000100
[2025-08-11 03:51:05,144][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109572] [Batch 02504/03692] [00:22:22/00:10:36, 0.536s/it]: train_loss_raw=0.3502, running_loss=0.3592, LR=0.000100
[2025-08-11 03:51:11,545][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109584] [Batch 02516/03692] [00:22:28/00:10:30, 0.536s/it]: train_loss_raw=0.4519, running_loss=0.3625, LR=0.000100
[2025-08-11 03:51:17,856][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109596] [Batch 02528/03692] [00:22:34/00:10:23, 0.536s/it]: train_loss_raw=0.3854, running_loss=0.3643, LR=0.000100
[2025-08-11 03:51:24,234][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109608] [Batch 02540/03692] [00:22:41/00:10:17, 0.536s/it]: train_loss_raw=0.3557, running_loss=0.3630, LR=0.000100
[2025-08-11 03:51:30,733][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109620] [Batch 02552/03692] [00:22:47/00:10:10, 0.536s/it]: train_loss_raw=0.3897, running_loss=0.3654, LR=0.000100
[2025-08-11 03:51:37,081][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109632] [Batch 02564/03692] [00:22:54/00:10:04, 0.536s/it]: train_loss_raw=0.3966, running_loss=0.3633, LR=0.000100
[2025-08-11 03:51:43,426][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109644] [Batch 02576/03692] [00:23:00/00:09:58, 0.536s/it]: train_loss_raw=0.3814, running_loss=0.3636, LR=0.000100
[2025-08-11 03:51:49,783][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109656] [Batch 02588/03692] [00:23:06/00:09:51, 0.536s/it]: train_loss_raw=0.3353, running_loss=0.3625, LR=0.000100
[2025-08-11 03:51:56,183][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109668] [Batch 02600/03692] [00:23:13/00:09:45, 0.536s/it]: train_loss_raw=0.3441, running_loss=0.3610, LR=0.000100
[2025-08-11 03:52:02,482][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109680] [Batch 02612/03692] [00:23:19/00:09:38, 0.536s/it]: train_loss_raw=0.4102, running_loss=0.3591, LR=0.000100
[2025-08-11 03:52:08,839][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109692] [Batch 02624/03692] [00:23:25/00:09:32, 0.536s/it]: train_loss_raw=0.3782, running_loss=0.3590, LR=0.000100
[2025-08-11 03:52:15,191][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109704] [Batch 02636/03692] [00:23:32/00:09:25, 0.536s/it]: train_loss_raw=0.3586, running_loss=0.3587, LR=0.000100
[2025-08-11 03:52:21,560][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109716] [Batch 02648/03692] [00:23:38/00:09:19, 0.536s/it]: train_loss_raw=0.3688, running_loss=0.3591, LR=0.000100
[2025-08-11 03:52:27,913][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109728] [Batch 02660/03692] [00:23:44/00:09:12, 0.536s/it]: train_loss_raw=0.2910, running_loss=0.3602, LR=0.000100
[2025-08-11 03:52:34,312][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109740] [Batch 02672/03692] [00:23:51/00:09:06, 0.536s/it]: train_loss_raw=0.3167, running_loss=0.3612, LR=0.000100
[2025-08-11 03:52:40,724][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109752] [Batch 02684/03692] [00:23:57/00:08:59, 0.536s/it]: train_loss_raw=0.5176, running_loss=0.3647, LR=0.000100
[2025-08-11 03:52:47,176][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109764] [Batch 02696/03692] [00:24:04/00:08:53, 0.536s/it]: train_loss_raw=0.3682, running_loss=0.3667, LR=0.000100
[2025-08-11 03:52:53,529][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109776] [Batch 02708/03692] [00:24:10/00:08:47, 0.536s/it]: train_loss_raw=0.3319, running_loss=0.3651, LR=0.000100
[2025-08-11 03:52:59,900][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109788] [Batch 02720/03692] [00:24:16/00:08:40, 0.536s/it]: train_loss_raw=0.3234, running_loss=0.3651, LR=0.000100
[2025-08-11 03:53:06,222][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109800] [Batch 02732/03692] [00:24:23/00:08:34, 0.536s/it]: train_loss_raw=0.3052, running_loss=0.3636, LR=0.000100
[2025-08-11 03:53:12,653][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109812] [Batch 02744/03692] [00:24:29/00:08:27, 0.536s/it]: train_loss_raw=0.3752, running_loss=0.3615, LR=0.000100
[2025-08-11 03:53:19,013][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109824] [Batch 02756/03692] [00:24:35/00:08:21, 0.536s/it]: train_loss_raw=0.3751, running_loss=0.3613, LR=0.000100
[2025-08-11 03:53:25,529][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109836] [Batch 02768/03692] [00:24:42/00:08:14, 0.536s/it]: train_loss_raw=0.3111, running_loss=0.3608, LR=0.000100
[2025-08-11 03:53:32,006][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109848] [Batch 02780/03692] [00:24:48/00:08:08, 0.536s/it]: train_loss_raw=0.4042, running_loss=0.3603, LR=0.000100
[2025-08-11 03:53:38,589][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109860] [Batch 02792/03692] [00:24:55/00:08:02, 0.536s/it]: train_loss_raw=0.3160, running_loss=0.3601, LR=0.000100
[2025-08-11 03:53:44,822][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109872] [Batch 02804/03692] [00:25:01/00:07:55, 0.536s/it]: train_loss_raw=0.4308, running_loss=0.3584, LR=0.000100
[2025-08-11 03:53:50,926][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109884] [Batch 02816/03692] [00:25:07/00:07:49, 0.535s/it]: train_loss_raw=0.4409, running_loss=0.3586, LR=0.000100
[2025-08-11 03:53:57,435][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109896] [Batch 02828/03692] [00:25:14/00:07:42, 0.535s/it]: train_loss_raw=0.4542, running_loss=0.3629, LR=0.000100
[2025-08-11 03:54:03,884][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109908] [Batch 02840/03692] [00:25:20/00:07:36, 0.535s/it]: train_loss_raw=0.3137, running_loss=0.3624, LR=0.000100
[2025-08-11 03:54:10,422][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109920] [Batch 02852/03692] [00:25:27/00:07:29, 0.536s/it]: train_loss_raw=0.2983, running_loss=0.3616, LR=0.000100
[2025-08-11 03:54:16,921][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109932] [Batch 02864/03692] [00:25:33/00:07:23, 0.536s/it]: train_loss_raw=0.3510, running_loss=0.3621, LR=0.000100
[2025-08-11 03:54:23,341][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109944] [Batch 02876/03692] [00:25:40/00:07:17, 0.536s/it]: train_loss_raw=0.3401, running_loss=0.3602, LR=0.000100
[2025-08-11 03:54:29,847][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109956] [Batch 02888/03692] [00:25:46/00:07:10, 0.536s/it]: train_loss_raw=0.5018, running_loss=0.3576, LR=0.000100
[2025-08-11 03:54:36,295][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109968] [Batch 02900/03692] [00:25:53/00:07:04, 0.536s/it]: train_loss_raw=0.3803, running_loss=0.3566, LR=0.000100
[2025-08-11 03:54:42,582][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109980] [Batch 02912/03692] [00:25:59/00:06:57, 0.536s/it]: train_loss_raw=0.3688, running_loss=0.3565, LR=0.000100
[2025-08-11 03:54:48,853][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109992] [Batch 02924/03692] [00:26:05/00:06:51, 0.535s/it]: train_loss_raw=0.4017, running_loss=0.3567, LR=0.000100
[2025-08-11 03:54:59,787][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110004] [Batch 02936/03692] [00:26:16/00:06:45, 0.537s/it]: train_loss_raw=0.3015, running_loss=0.3539, LR=0.000100
[2025-08-11 03:55:06,221][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110016] [Batch 02948/03692] [00:26:23/00:06:39, 0.537s/it]: train_loss_raw=0.2908, running_loss=0.3514, LR=0.000100
[2025-08-11 03:55:12,671][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110028] [Batch 02960/03692] [00:26:29/00:06:33, 0.537s/it]: train_loss_raw=0.4248, running_loss=0.3526, LR=0.000100
[2025-08-11 03:55:19,105][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110040] [Batch 02972/03692] [00:26:36/00:06:26, 0.537s/it]: train_loss_raw=0.3575, running_loss=0.3564, LR=0.000100
[2025-08-11 03:55:25,605][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110052] [Batch 02984/03692] [00:26:42/00:06:20, 0.537s/it]: train_loss_raw=0.4308, running_loss=0.3574, LR=0.000100
[2025-08-11 03:55:32,170][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110064] [Batch 02996/03692] [00:26:49/00:06:13, 0.537s/it]: train_loss_raw=0.3390, running_loss=0.3577, LR=0.000100
[2025-08-11 03:55:38,536][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110076] [Batch 03008/03692] [00:26:55/00:06:07, 0.537s/it]: train_loss_raw=0.2346, running_loss=0.3536, LR=0.000100
[2025-08-11 03:55:44,929][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110088] [Batch 03020/03692] [00:27:01/00:06:00, 0.537s/it]: train_loss_raw=0.3244, running_loss=0.3536, LR=0.000100
[2025-08-11 03:55:51,517][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110100] [Batch 03032/03692] [00:27:08/00:05:54, 0.537s/it]: train_loss_raw=0.4617, running_loss=0.3557, LR=0.000100
[2025-08-11 03:55:58,129][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110112] [Batch 03044/03692] [00:27:15/00:05:48, 0.537s/it]: train_loss_raw=0.3552, running_loss=0.3567, LR=0.000100
[2025-08-11 03:56:04,340][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110124] [Batch 03056/03692] [00:27:21/00:05:41, 0.537s/it]: train_loss_raw=0.3578, running_loss=0.3559, LR=0.000100
[2025-08-11 03:56:10,656][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110136] [Batch 03068/03692] [00:27:27/00:05:35, 0.537s/it]: train_loss_raw=0.3537, running_loss=0.3573, LR=0.000100
[2025-08-11 03:56:17,078][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110148] [Batch 03080/03692] [00:27:34/00:05:28, 0.537s/it]: train_loss_raw=0.2894, running_loss=0.3573, LR=0.000100
[2025-08-11 03:56:23,407][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110160] [Batch 03092/03692] [00:27:40/00:05:22, 0.537s/it]: train_loss_raw=0.4105, running_loss=0.3588, LR=0.000100
[2025-08-11 03:56:29,788][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110172] [Batch 03104/03692] [00:27:46/00:05:15, 0.537s/it]: train_loss_raw=0.3357, running_loss=0.3580, LR=0.000100
[2025-08-11 03:56:36,205][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110184] [Batch 03116/03692] [00:27:53/00:05:09, 0.537s/it]: train_loss_raw=0.4639, running_loss=0.3590, LR=0.000100
[2025-08-11 03:56:42,589][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110196] [Batch 03128/03692] [00:27:59/00:05:02, 0.537s/it]: train_loss_raw=0.4178, running_loss=0.3582, LR=0.000100
[2025-08-11 03:56:48,998][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110208] [Batch 03140/03692] [00:28:05/00:04:56, 0.537s/it]: train_loss_raw=0.3694, running_loss=0.3585, LR=0.000100
[2025-08-11 03:56:55,533][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110220] [Batch 03152/03692] [00:28:12/00:04:49, 0.537s/it]: train_loss_raw=0.4046, running_loss=0.3601, LR=0.000100
[2025-08-11 03:57:02,125][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110232] [Batch 03164/03692] [00:28:19/00:04:43, 0.537s/it]: train_loss_raw=0.3694, running_loss=0.3586, LR=0.000100
[2025-08-11 03:57:08,687][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110244] [Batch 03176/03692] [00:28:25/00:04:37, 0.537s/it]: train_loss_raw=0.3737, running_loss=0.3576, LR=0.000100
[2025-08-11 03:57:15,199][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110256] [Batch 03188/03692] [00:28:32/00:04:30, 0.537s/it]: train_loss_raw=0.4491, running_loss=0.3591, LR=0.000100
[2025-08-11 03:57:21,660][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110268] [Batch 03200/03692] [00:28:38/00:04:24, 0.537s/it]: train_loss_raw=0.2585, running_loss=0.3569, LR=0.000100
[2025-08-11 03:57:27,995][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110280] [Batch 03212/03692] [00:28:44/00:04:17, 0.537s/it]: train_loss_raw=0.3748, running_loss=0.3582, LR=0.000100
[2025-08-11 03:57:34,348][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110292] [Batch 03224/03692] [00:28:51/00:04:11, 0.537s/it]: train_loss_raw=0.2954, running_loss=0.3607, LR=0.000100
[2025-08-11 03:57:40,832][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110304] [Batch 03236/03692] [00:28:57/00:04:04, 0.537s/it]: train_loss_raw=0.4075, running_loss=0.3624, LR=0.000100
[2025-08-11 03:57:47,346][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110316] [Batch 03248/03692] [00:29:04/00:03:58, 0.537s/it]: train_loss_raw=0.3513, running_loss=0.3602, LR=0.000100
[2025-08-11 03:57:53,803][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110328] [Batch 03260/03692] [00:29:10/00:03:51, 0.537s/it]: train_loss_raw=0.3657, running_loss=0.3604, LR=0.000100
[2025-08-11 03:58:00,330][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110340] [Batch 03272/03692] [00:29:17/00:03:45, 0.537s/it]: train_loss_raw=0.3826, running_loss=0.3600, LR=0.000100
[2025-08-11 03:58:06,709][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110352] [Batch 03284/03692] [00:29:23/00:03:39, 0.537s/it]: train_loss_raw=0.3737, running_loss=0.3572, LR=0.000100
[2025-08-11 03:58:13,069][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110364] [Batch 03296/03692] [00:29:29/00:03:32, 0.537s/it]: train_loss_raw=0.3142, running_loss=0.3561, LR=0.000100
[2025-08-11 03:58:19,421][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110376] [Batch 03308/03692] [00:29:36/00:03:26, 0.537s/it]: train_loss_raw=0.3605, running_loss=0.3566, LR=0.000100
[2025-08-11 03:58:25,819][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110388] [Batch 03320/03692] [00:29:42/00:03:19, 0.537s/it]: train_loss_raw=0.4063, running_loss=0.3560, LR=0.000100
[2025-08-11 03:58:32,256][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110400] [Batch 03332/03692] [00:29:49/00:03:13, 0.537s/it]: train_loss_raw=0.3810, running_loss=0.3570, LR=0.000100
[2025-08-11 03:58:38,696][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110412] [Batch 03344/03692] [00:29:55/00:03:06, 0.537s/it]: train_loss_raw=0.3426, running_loss=0.3554, LR=0.000100
[2025-08-11 03:58:45,089][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110424] [Batch 03356/03692] [00:30:02/00:03:00, 0.537s/it]: train_loss_raw=0.4275, running_loss=0.3558, LR=0.000100
[2025-08-11 03:58:51,442][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110436] [Batch 03368/03692] [00:30:08/00:02:53, 0.537s/it]: train_loss_raw=0.3049, running_loss=0.3569, LR=0.000100
[2025-08-11 03:58:57,883][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110448] [Batch 03380/03692] [00:30:14/00:02:47, 0.537s/it]: train_loss_raw=0.3079, running_loss=0.3585, LR=0.000100
[2025-08-11 03:59:04,347][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110460] [Batch 03392/03692] [00:30:21/00:02:41, 0.537s/it]: train_loss_raw=0.3503, running_loss=0.3573, LR=0.000100
[2025-08-11 03:59:10,807][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110472] [Batch 03404/03692] [00:30:27/00:02:34, 0.537s/it]: train_loss_raw=0.3618, running_loss=0.3598, LR=0.000100
[2025-08-11 03:59:17,168][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110484] [Batch 03416/03692] [00:30:34/00:02:28, 0.537s/it]: train_loss_raw=0.4063, running_loss=0.3599, LR=0.000100
[2025-08-11 03:59:23,629][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110496] [Batch 03428/03692] [00:30:40/00:02:21, 0.537s/it]: train_loss_raw=0.4561, running_loss=0.3618, LR=0.000100
[2025-08-11 03:59:30,058][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110508] [Batch 03440/03692] [00:30:46/00:02:15, 0.537s/it]: train_loss_raw=0.2937, running_loss=0.3638, LR=0.000100
[2025-08-11 03:59:36,410][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110520] [Batch 03452/03692] [00:30:53/00:02:08, 0.537s/it]: train_loss_raw=0.4130, running_loss=0.3652, LR=0.000100
[2025-08-11 03:59:42,797][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110532] [Batch 03464/03692] [00:30:59/00:02:02, 0.537s/it]: train_loss_raw=0.3848, running_loss=0.3640, LR=0.000100
[2025-08-11 03:59:49,162][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110544] [Batch 03476/03692] [00:31:06/00:01:55, 0.537s/it]: train_loss_raw=0.3002, running_loss=0.3655, LR=0.000100
[2025-08-11 03:59:55,511][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110556] [Batch 03488/03692] [00:31:12/00:01:49, 0.537s/it]: train_loss_raw=0.3541, running_loss=0.3674, LR=0.000100
[2025-08-11 04:00:01,982][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110568] [Batch 03500/03692] [00:31:18/00:01:43, 0.537s/it]: train_loss_raw=0.2968, running_loss=0.3670, LR=0.000100
[2025-08-11 04:00:08,285][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110580] [Batch 03512/03692] [00:31:25/00:01:36, 0.537s/it]: train_loss_raw=0.3603, running_loss=0.3648, LR=0.000100
[2025-08-11 04:00:14,623][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110592] [Batch 03524/03692] [00:31:31/00:01:30, 0.537s/it]: train_loss_raw=0.3752, running_loss=0.3674, LR=0.000100
[2025-08-11 04:00:21,051][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110604] [Batch 03536/03692] [00:31:37/00:01:23, 0.537s/it]: train_loss_raw=0.4474, running_loss=0.3665, LR=0.000100
[2025-08-11 04:00:27,354][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110616] [Batch 03548/03692] [00:31:44/00:01:17, 0.537s/it]: train_loss_raw=0.4037, running_loss=0.3659, LR=0.000100
[2025-08-11 04:00:33,678][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110628] [Batch 03560/03692] [00:31:50/00:01:10, 0.537s/it]: train_loss_raw=0.3671, running_loss=0.3630, LR=0.000100
[2025-08-11 04:00:40,017][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110640] [Batch 03572/03692] [00:31:56/00:01:04, 0.537s/it]: train_loss_raw=0.3579, running_loss=0.3644, LR=0.000100
[2025-08-11 04:00:46,301][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110652] [Batch 03584/03692] [00:32:03/00:00:57, 0.537s/it]: train_loss_raw=0.3580, running_loss=0.3605, LR=0.000100
[2025-08-11 04:00:52,643][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110664] [Batch 03596/03692] [00:32:09/00:00:51, 0.537s/it]: train_loss_raw=0.3083, running_loss=0.3576, LR=0.000100
[2025-08-11 04:00:59,144][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110676] [Batch 03608/03692] [00:32:16/00:00:45, 0.537s/it]: train_loss_raw=0.2748, running_loss=0.3573, LR=0.000100
[2025-08-11 04:01:05,583][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110688] [Batch 03620/03692] [00:32:22/00:00:38, 0.537s/it]: train_loss_raw=0.3694, running_loss=0.3548, LR=0.000100
[2025-08-11 04:01:11,933][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110700] [Batch 03632/03692] [00:32:28/00:00:32, 0.537s/it]: train_loss_raw=0.3581, running_loss=0.3558, LR=0.000100
[2025-08-11 04:01:18,322][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110712] [Batch 03644/03692] [00:32:35/00:00:25, 0.537s/it]: train_loss_raw=0.4498, running_loss=0.3575, LR=0.000100
[2025-08-11 04:01:24,652][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110724] [Batch 03656/03692] [00:32:41/00:00:19, 0.537s/it]: train_loss_raw=0.3014, running_loss=0.3588, LR=0.000100
[2025-08-11 04:01:31,121][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110736] [Batch 03668/03692] [00:32:48/00:00:12, 0.537s/it]: train_loss_raw=0.3731, running_loss=0.3594, LR=0.000100
[2025-08-11 04:01:37,605][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110748] [Batch 03680/03692] [00:32:54/00:00:06, 0.537s/it]: train_loss_raw=0.3720, running_loss=0.3621, LR=0.000100
[2025-08-11 04:02:07,500][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110760] [Batch 03692/03692] [00:33:24/00:00:00, 0.543s/it]: train_loss_raw=0.2230, running_loss=0.3608, LR=0.000100
[2025-08-11 04:02:12,443][__main__][INFO] - [VALIDATION] [Epoch 29/29] Starting validation.
[2025-08-11 04:02:43,992][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 110761] [Batch 00011/00025] [00:00:31/00:00:34, 2.629s/it]
[2025-08-11 04:02:58,326][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 110761] [Batch 00023/00025] [00:00:45/00:00:01, 1.912s/it]
[2025-08-11 04:02:59,478][__main__][INFO] - [VALIDATION] [Epoch 29/29] train_loss=0.36077, valid_loss=0.53856
[2025-08-11 04:02:59,479][__main__][INFO] - [VALIDATION] [Epoch 29/29] Metrics:
[2025-08-11 04:02:59,479][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_er      0.215
[2025-08-11 04:02:59,479][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_prec    0.592
[2025-08-11 04:02:59,479][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_recall  0.596
[2025-08-11 04:02:59,479][__main__][INFO] - [VALIDATION] [Epoch 29/29] - pep_recall 0.574
[2025-08-11 04:02:59,483][__main__][INFO] - [TRAIN] [Epoch 29/29] Epoch complete, total time 17:06:58, remaining time 00:00:00, 00:34:13 per epoch
[2025-08-11 04:03:00,777][__main__][INFO] - InstaNovo training finished.
