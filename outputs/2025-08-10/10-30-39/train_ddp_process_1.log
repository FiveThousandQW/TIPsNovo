[2025-08-10 10:43:03,926][__main__][INFO] - Initializing training.
[2025-08-10 10:43:03,927][__main__][INFO] - Python version: 3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:24:24) [GCC 13.3.0]
[2025-08-10 10:43:03,927][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-10 10:43:03,927][__main__][INFO] - CUDA version: 12.1
[2025-08-10 10:43:03,933][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/1461_high/*.parquet
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 128
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: instanovo_300raw_high
train_subset: 1.0
valid_subset: 0.02
val_check_interval: 1.0
lazy_loading: true
max_shard_size: 1000000
preshuffle_shards: true
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-10 10:43:03,940][__main__][INFO] - Starting transformer training
[2025-08-10 10:43:03,940][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-10 10:43:03,940][__main__][INFO] - Loading data
[2025-08-10 10:43:26,738][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-10 10:43:26,787][instanovo.utils.data_handler][INFO] - Pre-shuffling across 002 shards. This may take a while...
[2025-08-10 10:43:26,787][instanovo.utils.data_handler][INFO] - Computing new mapping per original shard
[2025-08-10 10:43:26,833][instanovo.utils.data_handler][INFO] - Extracting rows to create shuffled shards
[2025-08-10 10:44:09,042][instanovo.utils.data_handler][INFO] - Writing shuffled shard 000/002 to /tmp/tmprmj4ef7a/temp_881cd4b9dbe741c5aa5dab2477836d4a.parquet [00:00:42/00:00:42, 42.209s/it]
[2025-08-10 10:45:48,373][instanovo.utils.data_handler][INFO] - Writing shuffled shard 001/002 to /tmp/tmprmj4ef7a/temp_f1a841ecc19f4ab3bb51adccd64aa407.parquet [00:02:21/00:00:00, 70.770s/it]
[2025-08-10 10:45:48,373][instanovo.utils.data_handler][INFO] - Removing unshuffled shards
[2025-08-10 10:46:10,700][instanovo.utils.data_handler][INFO] - Pre-shuffle complete
[2025-08-10 10:46:33,511][__main__][INFO] - Validation path not specified, generating from training set.
[2025-08-10 10:48:52,221][__main__][INFO] - Data splits saved to /data/48/wuqian/fast/TipsNovo/model_save/splits.csv
[2025-08-10 10:48:52,222][__main__][INFO] - Checking for unknown residues in 1,262,032 rows.
[2025-08-10 10:48:56,835][__main__][WARNING] - Unsupported residues found in evaluation set! These rows will be dropped.
[2025-08-10 10:48:56,835][__main__][INFO] - New residues found: 
{'O'}
[2025-08-10 10:48:56,835][__main__][INFO] - Residues supported: 
{'L', 'R', 'N', 'K', 'Y', 'S', '[UNIMOD:5]', '[PAD]', 'I', 'Q[UNIMOD:7]', 'Y[UNIMOD:21]', '[EOS]', 'P', 'C', 'D', 'A', 'H', 'Q', 'C[UNIMOD:4]', 'F', 'G', '[UNIMOD:1]', 'T[UNIMOD:21]', 'M[UNIMOD:35]', '[SOS]', 'T', 'E', 'S[UNIMOD:21]', '[UNIMOD:385]', 'N[UNIMOD:7]', 'M', 'W', 'V'}
[2025-08-10 10:51:41,774][__main__][WARNING] - 1 (0.00%) training rows dropped.
[2025-08-10 10:51:41,775][__main__][WARNING] - 0 (0.00%) validation rows dropped.
[2025-08-10 10:54:29,611][__main__][INFO] - Data loaded: 945,150 training samples; 6,292 validation samples
[2025-08-10 10:54:30,058][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-10 10:54:30,078][__main__][INFO] - No data leakage!
[2025-08-10 10:54:30,078][__main__][INFO] - Model checkpointing every 0.27 epochs.
[2025-08-10 10:54:30,079][__main__][INFO] - Updates per epoch: 7,384, step_scale=0.25
[2025-08-10 10:55:11,307][__main__][INFO] - Sample batch:
[2025-08-10 10:55:11,308][__main__][INFO] -  - spectra.shape=torch.Size([128, 200, 2])
[2025-08-10 10:55:11,308][__main__][INFO] -  - precursors.shape=torch.Size([128, 3])
[2025-08-10 10:55:11,308][__main__][INFO] -  - spectra_mask.shape=torch.Size([128, 200])
[2025-08-10 10:55:11,308][__main__][INFO] -  - peptides.shape=torch.Size([128, 41])
[2025-08-10 10:55:11,308][__main__][INFO] -  - peptides_mask.shape=torch.Size([128, 41])
[2025-08-10 10:55:11,487][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-10 10:55:11,488][__main__][INFO] - Test forward pass:
[2025-08-10 10:55:19,820][__main__][INFO] -  - y.shape=torch.Size([128, 42, 33])
[2025-08-10 10:55:20,956][__main__][INFO] - Model saving enabled
[2025-08-10 10:55:20,957][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save
[2025-08-10 10:55:20,957][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-10 10:55:20,968][__main__][INFO] - InstaNovo training started.
[2025-08-10 10:55:26,249][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-10 10:56:07,170][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000012] [Batch 00012/03692] [00:00:06/00:32:31, 0.530s/it]: train_loss_raw=3.3522, running_loss=3.6024, LR=0.000002
[2025-08-10 10:56:13,690][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/03692] [00:00:12/00:32:48, 0.537s/it]: train_loss_raw=3.0502, running_loss=3.5512, LR=0.000005
[2025-08-10 10:56:20,302][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000036] [Batch 00036/03692] [00:00:19/00:32:59, 0.542s/it]: train_loss_raw=2.9854, running_loss=3.4905, LR=0.000007
[2025-08-10 10:56:26,907][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/03692] [00:00:26/00:33:01, 0.544s/it]: train_loss_raw=2.9394, running_loss=3.4303, LR=0.000010
[2025-08-10 10:56:33,512][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000060] [Batch 00060/03692] [00:00:32/00:32:59, 0.545s/it]: train_loss_raw=2.8731, running_loss=3.3719, LR=0.000012
[2025-08-10 10:56:40,059][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/03692] [00:00:39/00:32:53, 0.545s/it]: train_loss_raw=2.8038, running_loss=3.3089, LR=0.000015
[2025-08-10 10:56:46,568][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000084] [Batch 00084/03692] [00:00:45/00:32:45, 0.545s/it]: train_loss_raw=2.7649, running_loss=3.2473, LR=0.000017
[2025-08-10 10:56:53,025][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/03692] [00:00:52/00:32:35, 0.544s/it]: train_loss_raw=2.7534, running_loss=3.1909, LR=0.000020
[2025-08-10 10:56:59,579][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000108] [Batch 00108/03692] [00:00:58/00:32:30, 0.544s/it]: train_loss_raw=2.7124, running_loss=3.1383, LR=0.000022
[2025-08-10 10:57:06,075][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/03692] [00:01:05/00:32:22, 0.544s/it]: train_loss_raw=2.7143, running_loss=3.0920, LR=0.000025
[2025-08-10 10:57:12,503][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000132] [Batch 00132/03692] [00:01:11/00:32:13, 0.543s/it]: train_loss_raw=2.6921, running_loss=3.0494, LR=0.000027
[2025-08-10 10:57:18,948][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/03692] [00:01:18/00:32:05, 0.543s/it]: train_loss_raw=2.7371, running_loss=3.0115, LR=0.000030
[2025-08-10 10:57:25,372][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000156] [Batch 00156/03692] [00:01:24/00:31:56, 0.542s/it]: train_loss_raw=2.7001, running_loss=2.9770, LR=0.000032
[2025-08-10 10:57:31,792][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/03692] [00:01:30/00:31:48, 0.542s/it]: train_loss_raw=2.7099, running_loss=2.9461, LR=0.000035
[2025-08-10 10:57:38,222][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000180] [Batch 00180/03692] [00:01:37/00:31:40, 0.541s/it]: train_loss_raw=2.7091, running_loss=2.9186, LR=0.000037
[2025-08-10 10:57:44,755][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/03692] [00:01:43/00:31:34, 0.541s/it]: train_loss_raw=2.7018, running_loss=2.8937, LR=0.000040
[2025-08-10 10:57:51,417][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000204] [Batch 00204/03692] [00:01:50/00:31:31, 0.542s/it]: train_loss_raw=2.7139, running_loss=2.8713, LR=0.000042
[2025-08-10 10:57:57,976][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/03692] [00:01:57/00:31:25, 0.542s/it]: train_loss_raw=2.7188, running_loss=2.8507, LR=0.000045
[2025-08-10 10:58:04,606][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000228] [Batch 00228/03692] [00:02:03/00:31:20, 0.543s/it]: train_loss_raw=2.7001, running_loss=2.8338, LR=0.000047
[2025-08-10 10:58:11,090][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/03692] [00:02:10/00:31:13, 0.543s/it]: train_loss_raw=2.6825, running_loss=2.8174, LR=0.000050
[2025-08-10 10:58:17,664][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000252] [Batch 00252/03692] [00:02:16/00:31:08, 0.543s/it]: train_loss_raw=2.6966, running_loss=2.8025, LR=0.000052
[2025-08-10 10:58:24,161][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/03692] [00:02:23/00:31:01, 0.543s/it]: train_loss_raw=2.6884, running_loss=2.7896, LR=0.000055
[2025-08-10 10:58:30,671][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000276] [Batch 00276/03692] [00:02:29/00:30:54, 0.543s/it]: train_loss_raw=2.6695, running_loss=2.7768, LR=0.000057
[2025-08-10 10:58:37,261][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/03692] [00:02:36/00:30:49, 0.543s/it]: train_loss_raw=2.7061, running_loss=2.7659, LR=0.000060
[2025-08-10 10:58:43,763][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000300] [Batch 00300/03692] [00:02:42/00:30:42, 0.543s/it]: train_loss_raw=2.6682, running_loss=2.7547, LR=0.000062
[2025-08-10 10:58:50,252][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/03692] [00:02:49/00:30:35, 0.543s/it]: train_loss_raw=2.6785, running_loss=2.7454, LR=0.000065
[2025-08-10 10:58:56,754][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000324] [Batch 00324/03692] [00:02:55/00:30:28, 0.543s/it]: train_loss_raw=2.6836, running_loss=2.7370, LR=0.000067
[2025-08-10 10:59:03,195][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/03692] [00:03:02/00:30:21, 0.543s/it]: train_loss_raw=2.6608, running_loss=2.7290, LR=0.000070
[2025-08-10 10:59:09,824][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000348] [Batch 00348/03692] [00:03:09/00:30:16, 0.543s/it]: train_loss_raw=2.6692, running_loss=2.7235, LR=0.000072
[2025-08-10 10:59:16,414][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/03692] [00:03:15/00:30:10, 0.543s/it]: train_loss_raw=2.6778, running_loss=2.7177, LR=0.000075
[2025-08-10 10:59:23,039][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000372] [Batch 00372/03692] [00:03:22/00:30:04, 0.544s/it]: train_loss_raw=2.6561, running_loss=2.7121, LR=0.000077
[2025-08-10 10:59:29,589][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/03692] [00:03:28/00:29:58, 0.544s/it]: train_loss_raw=2.6969, running_loss=2.7065, LR=0.000080
[2025-08-10 10:59:36,156][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000396] [Batch 00396/03692] [00:03:35/00:29:52, 0.544s/it]: train_loss_raw=2.6900, running_loss=2.7021, LR=0.000082
[2025-08-10 10:59:42,673][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/03692] [00:03:41/00:29:45, 0.544s/it]: train_loss_raw=2.6473, running_loss=2.6975, LR=0.000085
[2025-08-10 10:59:49,257][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000420] [Batch 00420/03692] [00:03:48/00:29:39, 0.544s/it]: train_loss_raw=2.6573, running_loss=2.6926, LR=0.000087
[2025-08-10 10:59:55,865][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/03692] [00:03:55/00:29:33, 0.544s/it]: train_loss_raw=2.6507, running_loss=2.6886, LR=0.000090
[2025-08-10 11:00:02,509][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000444] [Batch 00444/03692] [00:04:01/00:29:28, 0.544s/it]: train_loss_raw=2.6870, running_loss=2.6836, LR=0.000092
[2025-08-10 11:00:09,077][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/03692] [00:04:08/00:29:21, 0.544s/it]: train_loss_raw=2.6402, running_loss=2.6790, LR=0.000095
[2025-08-10 11:00:15,538][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000468] [Batch 00468/03692] [00:04:14/00:29:14, 0.544s/it]: train_loss_raw=2.6177, running_loss=2.6750, LR=0.000097
[2025-08-10 11:00:22,003][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/03692] [00:04:21/00:29:07, 0.544s/it]: train_loss_raw=2.6240, running_loss=2.6708, LR=0.000100
[2025-08-10 11:00:28,434][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000492] [Batch 00492/03692] [00:04:27/00:29:00, 0.544s/it]: train_loss_raw=2.6065, running_loss=2.6680, LR=0.000100
[2025-08-10 11:00:34,996][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/03692] [00:04:34/00:28:54, 0.544s/it]: train_loss_raw=2.6391, running_loss=2.6657, LR=0.000100
[2025-08-10 11:00:41,575][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000516] [Batch 00516/03692] [00:04:40/00:28:48, 0.544s/it]: train_loss_raw=2.6628, running_loss=2.6620, LR=0.000100
[2025-08-10 11:00:48,146][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/03692] [00:04:47/00:28:41, 0.544s/it]: train_loss_raw=2.6838, running_loss=2.6587, LR=0.000100
[2025-08-10 11:00:54,728][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000540] [Batch 00540/03692] [00:04:53/00:28:35, 0.544s/it]: train_loss_raw=2.6060, running_loss=2.6558, LR=0.000100
[2025-08-10 11:01:01,366][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/03692] [00:05:00/00:28:29, 0.544s/it]: train_loss_raw=2.5866, running_loss=2.6508, LR=0.000100
[2025-08-10 11:01:07,954][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000564] [Batch 00564/03692] [00:05:07/00:28:23, 0.545s/it]: train_loss_raw=2.6794, running_loss=2.6472, LR=0.000100
[2025-08-10 11:01:14,545][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/03692] [00:05:13/00:28:17, 0.545s/it]: train_loss_raw=2.6330, running_loss=2.6422, LR=0.000100
[2025-08-10 11:01:21,129][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000588] [Batch 00588/03692] [00:05:20/00:28:10, 0.545s/it]: train_loss_raw=2.5668, running_loss=2.6368, LR=0.000100
[2025-08-10 11:01:27,665][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/03692] [00:05:26/00:28:04, 0.545s/it]: train_loss_raw=2.6182, running_loss=2.6328, LR=0.000100
[2025-08-10 11:01:34,190][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000612] [Batch 00612/03692] [00:05:33/00:27:57, 0.545s/it]: train_loss_raw=2.5170, running_loss=2.6288, LR=0.000100
[2025-08-10 11:01:40,757][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/03692] [00:05:39/00:27:51, 0.545s/it]: train_loss_raw=2.5528, running_loss=2.6261, LR=0.000100
[2025-08-10 11:01:47,274][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000636] [Batch 00636/03692] [00:05:46/00:27:44, 0.545s/it]: train_loss_raw=2.5465, running_loss=2.6192, LR=0.000100
[2025-08-10 11:01:53,786][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/03692] [00:05:52/00:27:38, 0.545s/it]: train_loss_raw=2.5940, running_loss=2.6158, LR=0.000100
[2025-08-10 11:02:00,215][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000660] [Batch 00660/03692] [00:05:59/00:27:31, 0.545s/it]: train_loss_raw=2.5991, running_loss=2.6112, LR=0.000100
[2025-08-10 11:02:06,667][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/03692] [00:06:05/00:27:24, 0.544s/it]: train_loss_raw=2.6129, running_loss=2.6090, LR=0.000100
[2025-08-10 11:02:13,095][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000684] [Batch 00684/03692] [00:06:12/00:27:17, 0.544s/it]: train_loss_raw=2.5770, running_loss=2.6035, LR=0.000100
[2025-08-10 11:02:19,625][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/03692] [00:06:18/00:27:10, 0.544s/it]: train_loss_raw=2.6077, running_loss=2.6009, LR=0.000100
[2025-08-10 11:02:26,161][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000708] [Batch 00708/03692] [00:06:25/00:27:04, 0.544s/it]: train_loss_raw=2.5449, running_loss=2.5983, LR=0.000100
[2025-08-10 11:02:32,683][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/03692] [00:06:31/00:26:57, 0.544s/it]: train_loss_raw=2.5277, running_loss=2.5955, LR=0.000100
[2025-08-10 11:02:39,141][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000732] [Batch 00732/03692] [00:06:38/00:26:50, 0.544s/it]: train_loss_raw=2.5414, running_loss=2.5916, LR=0.000100
[2025-08-10 11:02:45,693][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/03692] [00:06:44/00:26:44, 0.544s/it]: train_loss_raw=2.5543, running_loss=2.5909, LR=0.000100
[2025-08-10 11:02:52,330][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000756] [Batch 00756/03692] [00:06:51/00:26:38, 0.544s/it]: train_loss_raw=2.6165, running_loss=2.5903, LR=0.000100
[2025-08-10 11:02:58,838][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/03692] [00:06:58/00:26:31, 0.544s/it]: train_loss_raw=2.6038, running_loss=2.5871, LR=0.000100
[2025-08-10 11:03:05,295][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000780] [Batch 00780/03692] [00:07:04/00:26:24, 0.544s/it]: train_loss_raw=2.5766, running_loss=2.5863, LR=0.000100
[2025-08-10 11:03:11,774][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/03692] [00:07:10/00:26:18, 0.544s/it]: train_loss_raw=2.5110, running_loss=2.5815, LR=0.000100
[2025-08-10 11:03:18,278][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000804] [Batch 00804/03692] [00:07:17/00:26:11, 0.544s/it]: train_loss_raw=2.5898, running_loss=2.5802, LR=0.000100
[2025-08-10 11:03:24,751][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/03692] [00:07:23/00:26:04, 0.544s/it]: train_loss_raw=2.5733, running_loss=2.5783, LR=0.000100
[2025-08-10 11:03:31,300][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000828] [Batch 00828/03692] [00:07:30/00:25:58, 0.544s/it]: train_loss_raw=2.5291, running_loss=2.5755, LR=0.000100
[2025-08-10 11:03:37,829][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000840] [Batch 00840/03692] [00:07:37/00:25:51, 0.544s/it]: train_loss_raw=2.4338, running_loss=2.5702, LR=0.000100
[2025-08-10 11:03:44,446][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000852] [Batch 00852/03692] [00:07:43/00:25:45, 0.544s/it]: train_loss_raw=2.5903, running_loss=2.5669, LR=0.000100
[2025-08-10 11:03:50,851][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000864] [Batch 00864/03692] [00:07:50/00:25:38, 0.544s/it]: train_loss_raw=2.5931, running_loss=2.5629, LR=0.000100
[2025-08-10 11:03:57,287][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000876] [Batch 00876/03692] [00:07:56/00:25:31, 0.544s/it]: train_loss_raw=2.5855, running_loss=2.5608, LR=0.000100
[2025-08-10 11:04:03,832][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000888] [Batch 00888/03692] [00:08:03/00:25:25, 0.544s/it]: train_loss_raw=2.5255, running_loss=2.5589, LR=0.000100
[2025-08-10 11:04:10,458][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000900] [Batch 00900/03692] [00:08:09/00:25:19, 0.544s/it]: train_loss_raw=2.4961, running_loss=2.5574, LR=0.000100
[2025-08-10 11:04:16,912][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000912] [Batch 00912/03692] [00:08:16/00:25:12, 0.544s/it]: train_loss_raw=2.5337, running_loss=2.5530, LR=0.000100
[2025-08-10 11:04:23,392][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000924] [Batch 00924/03692] [00:08:22/00:25:05, 0.544s/it]: train_loss_raw=2.4935, running_loss=2.5500, LR=0.000100
[2025-08-10 11:04:29,855][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000936] [Batch 00936/03692] [00:08:29/00:24:58, 0.544s/it]: train_loss_raw=2.5747, running_loss=2.5447, LR=0.000100
[2025-08-10 11:04:36,343][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000948] [Batch 00948/03692] [00:08:35/00:24:52, 0.544s/it]: train_loss_raw=2.5347, running_loss=2.5411, LR=0.000100
[2025-08-10 11:04:42,902][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000960] [Batch 00960/03692] [00:08:42/00:24:45, 0.544s/it]: train_loss_raw=2.5094, running_loss=2.5389, LR=0.000100
[2025-08-10 11:04:49,540][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000972] [Batch 00972/03692] [00:08:48/00:24:39, 0.544s/it]: train_loss_raw=2.5558, running_loss=2.5399, LR=0.000100
[2025-08-10 11:04:56,066][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000984] [Batch 00984/03692] [00:08:55/00:24:33, 0.544s/it]: train_loss_raw=2.4952, running_loss=2.5386, LR=0.000100
[2025-08-10 11:05:02,573][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000996] [Batch 00996/03692] [00:09:01/00:24:26, 0.544s/it]: train_loss_raw=2.4864, running_loss=2.5367, LR=0.000100
[2025-08-10 11:05:09,167][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001008] [Batch 01008/03692] [00:09:08/00:24:20, 0.544s/it]: train_loss_raw=2.5082, running_loss=2.5352, LR=0.000100
[2025-08-10 11:05:15,734][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001020] [Batch 01020/03692] [00:09:14/00:24:13, 0.544s/it]: train_loss_raw=2.5612, running_loss=2.5319, LR=0.000100
[2025-08-10 11:05:22,277][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001032] [Batch 01032/03692] [00:09:21/00:24:07, 0.544s/it]: train_loss_raw=2.4791, running_loss=2.5293, LR=0.000100
[2025-08-10 11:05:28,837][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001044] [Batch 01044/03692] [00:09:28/00:24:00, 0.544s/it]: train_loss_raw=2.5368, running_loss=2.5276, LR=0.000100
[2025-08-10 11:05:35,488][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001056] [Batch 01056/03692] [00:09:34/00:23:54, 0.544s/it]: train_loss_raw=2.5024, running_loss=2.5281, LR=0.000100
[2025-08-10 11:05:42,052][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001068] [Batch 01068/03692] [00:09:41/00:23:48, 0.544s/it]: train_loss_raw=2.5750, running_loss=2.5273, LR=0.000100
[2025-08-10 11:05:48,679][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001080] [Batch 01080/03692] [00:09:47/00:23:41, 0.544s/it]: train_loss_raw=2.4945, running_loss=2.5269, LR=0.000100
[2025-08-10 11:05:55,362][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001092] [Batch 01092/03692] [00:09:54/00:23:35, 0.544s/it]: train_loss_raw=2.4944, running_loss=2.5221, LR=0.000100
[2025-08-10 11:06:01,970][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001104] [Batch 01104/03692] [00:10:01/00:23:29, 0.545s/it]: train_loss_raw=2.5277, running_loss=2.5214, LR=0.000100
[2025-08-10 11:06:08,329][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001116] [Batch 01116/03692] [00:10:07/00:23:22, 0.544s/it]: train_loss_raw=2.5323, running_loss=2.5182, LR=0.000100
[2025-08-10 11:06:14,758][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001128] [Batch 01128/03692] [00:10:13/00:23:15, 0.544s/it]: train_loss_raw=2.4842, running_loss=2.5143, LR=0.000100
[2025-08-10 11:06:21,217][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001140] [Batch 01140/03692] [00:10:20/00:23:08, 0.544s/it]: train_loss_raw=2.4010, running_loss=2.5105, LR=0.000100
[2025-08-10 11:06:27,537][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001152] [Batch 01152/03692] [00:10:26/00:23:01, 0.544s/it]: train_loss_raw=2.4418, running_loss=2.5078, LR=0.000100
[2025-08-10 11:06:33,857][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001164] [Batch 01164/03692] [00:10:33/00:22:54, 0.544s/it]: train_loss_raw=2.5152, running_loss=2.5066, LR=0.000100
[2025-08-10 11:06:40,495][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001176] [Batch 01176/03692] [00:10:39/00:22:48, 0.544s/it]: train_loss_raw=2.5144, running_loss=2.5056, LR=0.000100
[2025-08-10 11:06:47,132][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001188] [Batch 01188/03692] [00:10:46/00:22:42, 0.544s/it]: train_loss_raw=2.5142, running_loss=2.5071, LR=0.000100
[2025-08-10 11:06:53,701][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001200] [Batch 01200/03692] [00:10:52/00:22:35, 0.544s/it]: train_loss_raw=2.4707, running_loss=2.5070, LR=0.000100
[2025-08-10 11:07:00,242][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001212] [Batch 01212/03692] [00:10:59/00:22:29, 0.544s/it]: train_loss_raw=2.5031, running_loss=2.5033, LR=0.000100
[2025-08-10 11:07:06,865][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001224] [Batch 01224/03692] [00:11:06/00:22:22, 0.544s/it]: train_loss_raw=2.4798, running_loss=2.5028, LR=0.000100
[2025-08-10 11:07:13,538][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001236] [Batch 01236/03692] [00:11:12/00:22:16, 0.544s/it]: train_loss_raw=2.4807, running_loss=2.5015, LR=0.000100
[2025-08-10 11:07:20,129][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001248] [Batch 01248/03692] [00:11:19/00:22:10, 0.544s/it]: train_loss_raw=2.4705, running_loss=2.4994, LR=0.000100
[2025-08-10 11:07:26,616][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001260] [Batch 01260/03692] [00:11:25/00:22:03, 0.544s/it]: train_loss_raw=2.4899, running_loss=2.5000, LR=0.000100
[2025-08-10 11:07:33,119][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001272] [Batch 01272/03692] [00:11:32/00:21:57, 0.544s/it]: train_loss_raw=2.4613, running_loss=2.4994, LR=0.000100
[2025-08-10 11:07:39,805][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001284] [Batch 01284/03692] [00:11:38/00:21:50, 0.544s/it]: train_loss_raw=2.4973, running_loss=2.4980, LR=0.000100
[2025-08-10 11:07:46,128][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001296] [Batch 01296/03692] [00:11:45/00:21:43, 0.544s/it]: train_loss_raw=2.4895, running_loss=2.4946, LR=0.000100
[2025-08-10 11:07:52,640][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001308] [Batch 01308/03692] [00:11:51/00:21:37, 0.544s/it]: train_loss_raw=2.3837, running_loss=2.4897, LR=0.000100
[2025-08-10 11:07:59,252][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001320] [Batch 01320/03692] [00:11:58/00:21:31, 0.544s/it]: train_loss_raw=2.5472, running_loss=2.4870, LR=0.000100
[2025-08-10 11:08:05,497][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001332] [Batch 01332/03692] [00:12:04/00:21:23, 0.544s/it]: train_loss_raw=2.5147, running_loss=2.4866, LR=0.000100
[2025-08-10 11:08:11,842][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001344] [Batch 01344/03692] [00:12:11/00:21:17, 0.544s/it]: train_loss_raw=2.4096, running_loss=2.4869, LR=0.000100
[2025-08-10 11:08:18,402][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001356] [Batch 01356/03692] [00:12:17/00:21:10, 0.544s/it]: train_loss_raw=2.4586, running_loss=2.4836, LR=0.000100
[2025-08-10 11:08:25,064][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001368] [Batch 01368/03692] [00:12:24/00:21:04, 0.544s/it]: train_loss_raw=2.4101, running_loss=2.4821, LR=0.000100
[2025-08-10 11:08:31,627][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001380] [Batch 01380/03692] [00:12:30/00:20:57, 0.544s/it]: train_loss_raw=2.4647, running_loss=2.4830, LR=0.000100
[2025-08-10 11:08:38,242][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001392] [Batch 01392/03692] [00:12:37/00:20:51, 0.544s/it]: train_loss_raw=2.4970, running_loss=2.4838, LR=0.000100
[2025-08-10 11:08:44,742][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001404] [Batch 01404/03692] [00:12:43/00:20:44, 0.544s/it]: train_loss_raw=2.5204, running_loss=2.4828, LR=0.000100
[2025-08-10 11:08:51,373][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001416] [Batch 01416/03692] [00:12:50/00:20:38, 0.544s/it]: train_loss_raw=2.4622, running_loss=2.4771, LR=0.000100
[2025-08-10 11:08:57,950][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001428] [Batch 01428/03692] [00:12:57/00:20:32, 0.544s/it]: train_loss_raw=2.4884, running_loss=2.4770, LR=0.000100
[2025-08-10 11:09:04,497][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001440] [Batch 01440/03692] [00:13:03/00:20:25, 0.544s/it]: train_loss_raw=2.4544, running_loss=2.4735, LR=0.000100
[2025-08-10 11:09:11,130][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001452] [Batch 01452/03692] [00:13:10/00:20:19, 0.544s/it]: train_loss_raw=2.5488, running_loss=2.4744, LR=0.000100
[2025-08-10 11:09:17,742][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001464] [Batch 01464/03692] [00:13:16/00:20:12, 0.544s/it]: train_loss_raw=2.4969, running_loss=2.4750, LR=0.000100
[2025-08-10 11:09:24,344][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001476] [Batch 01476/03692] [00:13:23/00:20:06, 0.544s/it]: train_loss_raw=2.4584, running_loss=2.4737, LR=0.000100
[2025-08-10 11:09:30,972][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001488] [Batch 01488/03692] [00:13:30/00:20:00, 0.544s/it]: train_loss_raw=2.4842, running_loss=2.4722, LR=0.000100
[2025-08-10 11:09:37,599][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001500] [Batch 01500/03692] [00:13:36/00:19:53, 0.545s/it]: train_loss_raw=2.4400, running_loss=2.4691, LR=0.000100
[2025-08-10 11:09:44,265][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001512] [Batch 01512/03692] [00:13:43/00:19:47, 0.545s/it]: train_loss_raw=2.4345, running_loss=2.4661, LR=0.000100
[2025-08-10 11:09:50,960][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001524] [Batch 01524/03692] [00:13:50/00:19:40, 0.545s/it]: train_loss_raw=2.4847, running_loss=2.4634, LR=0.000100
[2025-08-10 11:10:26,610][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001536] [Batch 01536/03692] [00:14:25/00:20:15, 0.564s/it]: train_loss_raw=2.5185, running_loss=2.4639, LR=0.000100
[2025-08-10 11:10:33,265][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001548] [Batch 01548/03692] [00:14:32/00:20:08, 0.564s/it]: train_loss_raw=2.4657, running_loss=2.4646, LR=0.000100
[2025-08-10 11:10:39,775][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001560] [Batch 01560/03692] [00:14:38/00:20:01, 0.563s/it]: train_loss_raw=2.4599, running_loss=2.4643, LR=0.000100
[2025-08-10 11:10:46,372][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001572] [Batch 01572/03692] [00:14:45/00:19:54, 0.563s/it]: train_loss_raw=2.4477, running_loss=2.4638, LR=0.000100
[2025-08-10 11:10:53,000][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001584] [Batch 01584/03692] [00:14:52/00:19:47, 0.563s/it]: train_loss_raw=2.4786, running_loss=2.4618, LR=0.000100
[2025-08-10 11:10:59,607][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001596] [Batch 01596/03692] [00:14:58/00:19:40, 0.563s/it]: train_loss_raw=2.3347, running_loss=2.4574, LR=0.000100
[2025-08-10 11:11:06,192][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001608] [Batch 01608/03692] [00:15:05/00:19:33, 0.563s/it]: train_loss_raw=2.4333, running_loss=2.4539, LR=0.000100
[2025-08-10 11:11:12,680][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001620] [Batch 01620/03692] [00:15:11/00:19:26, 0.563s/it]: train_loss_raw=2.4477, running_loss=2.4532, LR=0.000100
[2025-08-10 11:11:19,050][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001632] [Batch 01632/03692] [00:15:18/00:19:19, 0.563s/it]: train_loss_raw=2.5128, running_loss=2.4519, LR=0.000100
[2025-08-10 11:11:25,608][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001644] [Batch 01644/03692] [00:15:24/00:19:12, 0.563s/it]: train_loss_raw=2.4820, running_loss=2.4504, LR=0.000100
[2025-08-10 11:11:32,157][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001656] [Batch 01656/03692] [00:15:31/00:19:05, 0.562s/it]: train_loss_raw=2.4354, running_loss=2.4496, LR=0.000100
[2025-08-10 11:11:38,763][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001668] [Batch 01668/03692] [00:15:37/00:18:58, 0.562s/it]: train_loss_raw=2.4726, running_loss=2.4497, LR=0.000100
[2025-08-10 11:11:45,492][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001680] [Batch 01680/03692] [00:15:44/00:18:51, 0.562s/it]: train_loss_raw=2.3593, running_loss=2.4441, LR=0.000100
[2025-08-10 11:11:52,018][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001692] [Batch 01692/03692] [00:15:51/00:18:44, 0.562s/it]: train_loss_raw=2.4088, running_loss=2.4438, LR=0.000100
[2025-08-10 11:11:58,639][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001704] [Batch 01704/03692] [00:15:57/00:18:37, 0.562s/it]: train_loss_raw=2.4259, running_loss=2.4396, LR=0.000100
[2025-08-10 11:12:05,291][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001716] [Batch 01716/03692] [00:16:04/00:18:30, 0.562s/it]: train_loss_raw=2.3685, running_loss=2.4393, LR=0.000100
[2025-08-10 11:12:11,863][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001728] [Batch 01728/03692] [00:16:11/00:18:23, 0.562s/it]: train_loss_raw=2.4818, running_loss=2.4409, LR=0.000100
[2025-08-10 11:12:18,620][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001740] [Batch 01740/03692] [00:16:17/00:18:16, 0.562s/it]: train_loss_raw=2.4165, running_loss=2.4387, LR=0.000100
[2025-08-10 11:12:25,211][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001752] [Batch 01752/03692] [00:16:24/00:18:10, 0.562s/it]: train_loss_raw=2.3738, running_loss=2.4344, LR=0.000100
[2025-08-10 11:12:31,905][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001764] [Batch 01764/03692] [00:16:31/00:18:03, 0.562s/it]: train_loss_raw=2.5084, running_loss=2.4370, LR=0.000100
[2025-08-10 11:12:38,523][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001776] [Batch 01776/03692] [00:16:37/00:17:56, 0.562s/it]: train_loss_raw=2.3800, running_loss=2.4345, LR=0.000100
[2025-08-10 11:12:45,031][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001788] [Batch 01788/03692] [00:16:44/00:17:49, 0.562s/it]: train_loss_raw=2.4618, running_loss=2.4327, LR=0.000100
[2025-08-10 11:12:51,632][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001800] [Batch 01800/03692] [00:16:50/00:17:42, 0.562s/it]: train_loss_raw=2.4224, running_loss=2.4320, LR=0.000100
[2025-08-10 11:12:58,219][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001812] [Batch 01812/03692] [00:16:57/00:17:35, 0.561s/it]: train_loss_raw=2.4048, running_loss=2.4317, LR=0.000100
[2025-08-10 11:13:04,772][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001824] [Batch 01824/03692] [00:17:03/00:17:28, 0.561s/it]: train_loss_raw=2.4514, running_loss=2.4326, LR=0.000100
[2025-08-10 11:13:11,391][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001836] [Batch 01836/03692] [00:17:10/00:17:21, 0.561s/it]: train_loss_raw=2.4779, running_loss=2.4325, LR=0.000100
[2025-08-10 11:13:17,867][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001848] [Batch 01848/03692] [00:17:17/00:17:14, 0.561s/it]: train_loss_raw=2.4510, running_loss=2.4319, LR=0.000100
[2025-08-10 11:13:24,483][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001860] [Batch 01860/03692] [00:17:23/00:17:07, 0.561s/it]: train_loss_raw=2.4387, running_loss=2.4289, LR=0.000100
[2025-08-10 11:13:31,113][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001872] [Batch 01872/03692] [00:17:30/00:17:01, 0.561s/it]: train_loss_raw=2.3928, running_loss=2.4269, LR=0.000100
[2025-08-10 11:13:37,699][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001884] [Batch 01884/03692] [00:17:36/00:16:54, 0.561s/it]: train_loss_raw=2.4444, running_loss=2.4246, LR=0.000100
[2025-08-10 11:13:44,206][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001896] [Batch 01896/03692] [00:17:43/00:16:47, 0.561s/it]: train_loss_raw=2.4737, running_loss=2.4214, LR=0.000100
[2025-08-10 11:13:50,673][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001908] [Batch 01908/03692] [00:17:49/00:16:40, 0.561s/it]: train_loss_raw=2.4740, running_loss=2.4220, LR=0.000100
[2025-08-10 11:13:57,293][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001920] [Batch 01920/03692] [00:17:56/00:16:33, 0.561s/it]: train_loss_raw=2.4135, running_loss=2.4178, LR=0.000100
[2025-08-10 11:14:03,910][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001932] [Batch 01932/03692] [00:18:03/00:16:26, 0.561s/it]: train_loss_raw=2.3758, running_loss=2.4190, LR=0.000100
[2025-08-10 11:14:10,517][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001944] [Batch 01944/03692] [00:18:09/00:16:19, 0.561s/it]: train_loss_raw=2.3680, running_loss=2.4166, LR=0.000100
[2025-08-10 11:14:17,121][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001956] [Batch 01956/03692] [00:18:16/00:16:13, 0.560s/it]: train_loss_raw=2.3945, running_loss=2.4186, LR=0.000100
[2025-08-10 11:14:23,632][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001968] [Batch 01968/03692] [00:18:22/00:16:06, 0.560s/it]: train_loss_raw=2.3769, running_loss=2.4166, LR=0.000100
[2025-08-10 11:14:30,281][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001980] [Batch 01980/03692] [00:18:29/00:15:59, 0.560s/it]: train_loss_raw=2.4578, running_loss=2.4161, LR=0.000100
[2025-08-10 11:14:36,882][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001992] [Batch 01992/03692] [00:18:36/00:15:52, 0.560s/it]: train_loss_raw=2.2429, running_loss=2.4099, LR=0.000100
[2025-08-10 11:14:47,619][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002004] [Batch 02004/03692] [00:18:46/00:15:49, 0.562s/it]: train_loss_raw=2.4226, running_loss=2.4079, LR=0.000100
[2025-08-10 11:14:54,199][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002016] [Batch 02016/03692] [00:18:53/00:15:42, 0.562s/it]: train_loss_raw=2.3867, running_loss=2.4053, LR=0.000100
[2025-08-10 11:15:00,659][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002028] [Batch 02028/03692] [00:18:59/00:15:35, 0.562s/it]: train_loss_raw=2.4175, running_loss=2.4046, LR=0.000100
[2025-08-10 11:15:07,118][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002040] [Batch 02040/03692] [00:19:06/00:15:28, 0.562s/it]: train_loss_raw=2.2075, running_loss=2.4031, LR=0.000100
[2025-08-10 11:15:13,770][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002052] [Batch 02052/03692] [00:19:12/00:15:21, 0.562s/it]: train_loss_raw=2.3054, running_loss=2.4017, LR=0.000100
[2025-08-10 11:15:20,365][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002064] [Batch 02064/03692] [00:19:19/00:15:14, 0.562s/it]: train_loss_raw=2.3919, running_loss=2.4011, LR=0.000100
[2025-08-10 11:15:26,895][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002076] [Batch 02076/03692] [00:19:26/00:15:07, 0.562s/it]: train_loss_raw=2.4262, running_loss=2.4001, LR=0.000100
[2025-08-10 11:15:33,560][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002088] [Batch 02088/03692] [00:19:32/00:15:00, 0.562s/it]: train_loss_raw=2.3335, running_loss=2.4012, LR=0.000100
[2025-08-10 11:15:40,145][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002100] [Batch 02100/03692] [00:19:39/00:14:54, 0.562s/it]: train_loss_raw=2.4007, running_loss=2.3976, LR=0.000100
[2025-08-10 11:15:46,790][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002112] [Batch 02112/03692] [00:19:45/00:14:47, 0.562s/it]: train_loss_raw=2.3481, running_loss=2.3986, LR=0.000100
[2025-08-10 11:15:53,398][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002124] [Batch 02124/03692] [00:19:52/00:14:40, 0.561s/it]: train_loss_raw=2.4072, running_loss=2.3978, LR=0.000100
[2025-08-10 11:15:59,944][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002136] [Batch 02136/03692] [00:19:59/00:14:33, 0.561s/it]: train_loss_raw=2.2925, running_loss=2.3942, LR=0.000100
[2025-08-10 11:16:06,541][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002148] [Batch 02148/03692] [00:20:05/00:14:26, 0.561s/it]: train_loss_raw=2.4763, running_loss=2.3945, LR=0.000100
[2025-08-10 11:16:13,086][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002160] [Batch 02160/03692] [00:20:12/00:14:19, 0.561s/it]: train_loss_raw=2.4114, running_loss=2.3949, LR=0.000100
[2025-08-10 11:16:19,692][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002172] [Batch 02172/03692] [00:20:18/00:14:12, 0.561s/it]: train_loss_raw=2.3575, running_loss=2.3935, LR=0.000100
[2025-08-10 11:16:26,309][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002184] [Batch 02184/03692] [00:20:25/00:14:06, 0.561s/it]: train_loss_raw=2.4276, running_loss=2.3916, LR=0.000100
[2025-08-10 11:16:32,924][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002196] [Batch 02196/03692] [00:20:32/00:13:59, 0.561s/it]: train_loss_raw=2.4023, running_loss=2.3880, LR=0.000100
[2025-08-10 11:16:39,598][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002208] [Batch 02208/03692] [00:20:38/00:13:52, 0.561s/it]: train_loss_raw=2.2981, running_loss=2.3861, LR=0.000100
[2025-08-10 11:16:45,980][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002220] [Batch 02220/03692] [00:20:45/00:13:45, 0.561s/it]: train_loss_raw=2.3363, running_loss=2.3827, LR=0.000100
[2025-08-10 11:16:52,428][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002232] [Batch 02232/03692] [00:20:51/00:13:38, 0.561s/it]: train_loss_raw=2.3026, running_loss=2.3797, LR=0.000100
[2025-08-10 11:16:58,944][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002244] [Batch 02244/03692] [00:20:58/00:13:31, 0.561s/it]: train_loss_raw=2.3750, running_loss=2.3772, LR=0.000100
[2025-08-10 11:17:05,292][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002256] [Batch 02256/03692] [00:21:04/00:13:24, 0.560s/it]: train_loss_raw=2.3217, running_loss=2.3760, LR=0.000100
[2025-08-10 11:17:11,664][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002268] [Batch 02268/03692] [00:21:10/00:13:17, 0.560s/it]: train_loss_raw=2.3379, running_loss=2.3733, LR=0.000100
[2025-08-10 11:17:18,166][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002280] [Batch 02280/03692] [00:21:17/00:13:11, 0.560s/it]: train_loss_raw=2.3532, running_loss=2.3758, LR=0.000100
[2025-08-10 11:17:24,617][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002292] [Batch 02292/03692] [00:21:23/00:13:04, 0.560s/it]: train_loss_raw=2.4242, running_loss=2.3728, LR=0.000100
[2025-08-10 11:17:31,190][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002304] [Batch 02304/03692] [00:21:30/00:12:57, 0.560s/it]: train_loss_raw=2.3554, running_loss=2.3739, LR=0.000100
[2025-08-10 11:17:37,769][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002316] [Batch 02316/03692] [00:21:36/00:12:50, 0.560s/it]: train_loss_raw=2.4810, running_loss=2.3754, LR=0.000100
[2025-08-10 11:17:44,286][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002328] [Batch 02328/03692] [00:21:43/00:12:43, 0.560s/it]: train_loss_raw=2.4094, running_loss=2.3747, LR=0.000100
[2025-08-10 11:17:50,841][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002340] [Batch 02340/03692] [00:21:50/00:12:36, 0.560s/it]: train_loss_raw=2.3453, running_loss=2.3718, LR=0.000100
[2025-08-10 11:17:57,472][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002352] [Batch 02352/03692] [00:21:56/00:12:30, 0.560s/it]: train_loss_raw=2.2707, running_loss=2.3673, LR=0.000100
[2025-08-10 11:18:04,062][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002364] [Batch 02364/03692] [00:22:03/00:12:23, 0.560s/it]: train_loss_raw=2.3091, running_loss=2.3690, LR=0.000100
[2025-08-10 11:18:10,589][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002376] [Batch 02376/03692] [00:22:09/00:12:16, 0.560s/it]: train_loss_raw=2.3580, running_loss=2.3686, LR=0.000100
[2025-08-10 11:18:17,142][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002388] [Batch 02388/03692] [00:22:16/00:12:09, 0.560s/it]: train_loss_raw=2.3828, running_loss=2.3681, LR=0.000100
[2025-08-10 11:18:23,624][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002400] [Batch 02400/03692] [00:22:22/00:12:02, 0.560s/it]: train_loss_raw=2.3769, running_loss=2.3676, LR=0.000100
[2025-08-10 11:18:30,205][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002412] [Batch 02412/03692] [00:22:29/00:11:56, 0.559s/it]: train_loss_raw=2.3493, running_loss=2.3676, LR=0.000100
[2025-08-10 11:18:36,707][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002424] [Batch 02424/03692] [00:22:35/00:11:49, 0.559s/it]: train_loss_raw=2.3095, running_loss=2.3614, LR=0.000100
[2025-08-10 11:18:43,337][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002436] [Batch 02436/03692] [00:22:42/00:11:42, 0.559s/it]: train_loss_raw=2.4188, running_loss=2.3659, LR=0.000100
[2025-08-10 11:18:49,906][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002448] [Batch 02448/03692] [00:22:49/00:11:35, 0.559s/it]: train_loss_raw=2.3393, running_loss=2.3659, LR=0.000100
[2025-08-10 11:18:56,563][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002460] [Batch 02460/03692] [00:22:55/00:11:28, 0.559s/it]: train_loss_raw=2.2984, running_loss=2.3632, LR=0.000100
[2025-08-10 11:19:03,099][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002472] [Batch 02472/03692] [00:23:02/00:11:22, 0.559s/it]: train_loss_raw=2.3463, running_loss=2.3618, LR=0.000100
[2025-08-10 11:19:09,706][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002484] [Batch 02484/03692] [00:23:08/00:11:15, 0.559s/it]: train_loss_raw=2.3306, running_loss=2.3627, LR=0.000100
[2025-08-10 11:19:16,323][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002496] [Batch 02496/03692] [00:23:15/00:11:08, 0.559s/it]: train_loss_raw=2.3141, running_loss=2.3614, LR=0.000100
[2025-08-10 11:19:22,795][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002508] [Batch 02508/03692] [00:23:21/00:11:01, 0.559s/it]: train_loss_raw=2.3203, running_loss=2.3599, LR=0.000100
[2025-08-10 11:19:29,272][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002520] [Batch 02520/03692] [00:23:28/00:10:55, 0.559s/it]: train_loss_raw=2.2422, running_loss=2.3581, LR=0.000100
[2025-08-10 11:19:35,891][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002532] [Batch 02532/03692] [00:23:35/00:10:48, 0.559s/it]: train_loss_raw=2.2900, running_loss=2.3561, LR=0.000100
[2025-08-10 11:19:42,405][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002544] [Batch 02544/03692] [00:23:41/00:10:41, 0.559s/it]: train_loss_raw=2.3652, running_loss=2.3582, LR=0.000100
[2025-08-10 11:19:48,859][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002556] [Batch 02556/03692] [00:23:48/00:10:34, 0.559s/it]: train_loss_raw=2.4261, running_loss=2.3584, LR=0.000100
[2025-08-10 11:19:55,400][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002568] [Batch 02568/03692] [00:23:54/00:10:27, 0.559s/it]: train_loss_raw=2.3753, running_loss=2.3572, LR=0.000100
[2025-08-10 11:20:01,894][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002580] [Batch 02580/03692] [00:24:01/00:10:21, 0.559s/it]: train_loss_raw=2.3768, running_loss=2.3560, LR=0.000100
[2025-08-10 11:20:08,396][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002592] [Batch 02592/03692] [00:24:07/00:10:14, 0.558s/it]: train_loss_raw=2.3903, running_loss=2.3543, LR=0.000100
[2025-08-10 11:20:15,007][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002604] [Batch 02604/03692] [00:24:14/00:10:07, 0.558s/it]: train_loss_raw=2.3333, running_loss=2.3491, LR=0.000100
[2025-08-10 11:20:21,625][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002616] [Batch 02616/03692] [00:24:20/00:10:00, 0.558s/it]: train_loss_raw=2.3487, running_loss=2.3454, LR=0.000100
[2025-08-10 11:20:28,270][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002628] [Batch 02628/03692] [00:24:27/00:09:54, 0.558s/it]: train_loss_raw=2.2851, running_loss=2.3445, LR=0.000100
[2025-08-10 11:20:34,896][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002640] [Batch 02640/03692] [00:24:34/00:09:47, 0.558s/it]: train_loss_raw=2.3642, running_loss=2.3447, LR=0.000100
[2025-08-10 11:20:41,439][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002652] [Batch 02652/03692] [00:24:40/00:09:40, 0.558s/it]: train_loss_raw=2.3338, running_loss=2.3455, LR=0.000100
[2025-08-10 11:20:48,064][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002664] [Batch 02664/03692] [00:24:47/00:09:33, 0.558s/it]: train_loss_raw=2.3606, running_loss=2.3484, LR=0.000100
[2025-08-10 11:20:54,576][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002676] [Batch 02676/03692] [00:24:53/00:09:27, 0.558s/it]: train_loss_raw=2.4195, running_loss=2.3480, LR=0.000100
[2025-08-10 11:21:01,011][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002688] [Batch 02688/03692] [00:25:00/00:09:20, 0.558s/it]: train_loss_raw=2.3509, running_loss=2.3453, LR=0.000100
[2025-08-10 11:21:07,528][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002700] [Batch 02700/03692] [00:25:06/00:09:13, 0.558s/it]: train_loss_raw=2.3115, running_loss=2.3465, LR=0.000100
[2025-08-10 11:21:14,051][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002712] [Batch 02712/03692] [00:25:13/00:09:06, 0.558s/it]: train_loss_raw=2.2890, running_loss=2.3468, LR=0.000100
[2025-08-10 11:21:20,736][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002724] [Batch 02724/03692] [00:25:19/00:09:00, 0.558s/it]: train_loss_raw=2.2476, running_loss=2.3430, LR=0.000100
[2025-08-10 11:21:27,211][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002736] [Batch 02736/03692] [00:25:26/00:08:53, 0.558s/it]: train_loss_raw=2.2346, running_loss=2.3406, LR=0.000100
[2025-08-10 11:21:33,639][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002748] [Batch 02748/03692] [00:25:32/00:08:46, 0.558s/it]: train_loss_raw=2.3668, running_loss=2.3405, LR=0.000100
[2025-08-10 11:21:40,138][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002760] [Batch 02760/03692] [00:25:39/00:08:39, 0.558s/it]: train_loss_raw=2.3289, running_loss=2.3395, LR=0.000100
[2025-08-10 11:21:46,685][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002772] [Batch 02772/03692] [00:25:45/00:08:33, 0.558s/it]: train_loss_raw=2.2599, running_loss=2.3386, LR=0.000100
[2025-08-10 11:21:53,167][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002784] [Batch 02784/03692] [00:25:52/00:08:26, 0.558s/it]: train_loss_raw=2.3280, running_loss=2.3379, LR=0.000100
[2025-08-10 11:21:59,729][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002796] [Batch 02796/03692] [00:25:58/00:08:19, 0.558s/it]: train_loss_raw=2.3374, running_loss=2.3351, LR=0.000100
[2025-08-10 11:22:06,273][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002808] [Batch 02808/03692] [00:26:05/00:08:12, 0.558s/it]: train_loss_raw=2.3915, running_loss=2.3314, LR=0.000100
[2025-08-10 11:22:12,788][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002820] [Batch 02820/03692] [00:26:11/00:08:06, 0.557s/it]: train_loss_raw=2.3199, running_loss=2.3299, LR=0.000100
[2025-08-10 11:22:19,472][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002832] [Batch 02832/03692] [00:26:18/00:07:59, 0.557s/it]: train_loss_raw=2.3817, running_loss=2.3274, LR=0.000100
[2025-08-10 11:22:26,110][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002844] [Batch 02844/03692] [00:26:25/00:07:52, 0.557s/it]: train_loss_raw=2.2035, running_loss=2.3259, LR=0.000100
[2025-08-10 11:22:32,741][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002856] [Batch 02856/03692] [00:26:31/00:07:45, 0.557s/it]: train_loss_raw=2.2867, running_loss=2.3276, LR=0.000100
[2025-08-10 11:22:39,193][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002868] [Batch 02868/03692] [00:26:38/00:07:39, 0.557s/it]: train_loss_raw=2.3717, running_loss=2.3289, LR=0.000100
[2025-08-10 11:22:45,759][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002880] [Batch 02880/03692] [00:26:44/00:07:32, 0.557s/it]: train_loss_raw=2.3047, running_loss=2.3282, LR=0.000100
[2025-08-10 11:22:52,317][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002892] [Batch 02892/03692] [00:26:51/00:07:25, 0.557s/it]: train_loss_raw=2.2632, running_loss=2.3282, LR=0.000100
[2025-08-10 11:22:58,733][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002904] [Batch 02904/03692] [00:26:57/00:07:19, 0.557s/it]: train_loss_raw=2.2714, running_loss=2.3275, LR=0.000100
[2025-08-10 11:23:05,216][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002916] [Batch 02916/03692] [00:27:04/00:07:12, 0.557s/it]: train_loss_raw=2.3274, running_loss=2.3249, LR=0.000100
[2025-08-10 11:23:11,725][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002928] [Batch 02928/03692] [00:27:10/00:07:05, 0.557s/it]: train_loss_raw=2.3142, running_loss=2.3257, LR=0.000100
[2025-08-10 11:23:18,102][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002940] [Batch 02940/03692] [00:27:17/00:06:58, 0.557s/it]: train_loss_raw=2.2769, running_loss=2.3221, LR=0.000100
[2025-08-10 11:23:24,694][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002952] [Batch 02952/03692] [00:27:23/00:06:52, 0.557s/it]: train_loss_raw=2.3121, running_loss=2.3198, LR=0.000100
[2025-08-10 11:23:31,355][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002964] [Batch 02964/03692] [00:27:30/00:06:45, 0.557s/it]: train_loss_raw=2.3016, running_loss=2.3204, LR=0.000100
[2025-08-10 11:23:37,968][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002976] [Batch 02976/03692] [00:27:37/00:06:38, 0.557s/it]: train_loss_raw=2.3411, running_loss=2.3203, LR=0.000100
[2025-08-10 11:23:44,232][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002988] [Batch 02988/03692] [00:27:43/00:06:31, 0.557s/it]: train_loss_raw=2.2975, running_loss=2.3166, LR=0.000100
[2025-08-10 11:23:50,636][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003000] [Batch 03000/03692] [00:27:49/00:06:25, 0.557s/it]: train_loss_raw=2.2716, running_loss=2.3147, LR=0.000100
[2025-08-10 11:23:57,255][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003012] [Batch 03012/03692] [00:27:56/00:06:18, 0.557s/it]: train_loss_raw=2.2858, running_loss=2.3096, LR=0.000100
[2025-08-10 11:24:03,933][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003024] [Batch 03024/03692] [00:28:03/00:06:11, 0.557s/it]: train_loss_raw=2.3988, running_loss=2.3092, LR=0.000100
[2025-08-10 11:24:10,586][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003036] [Batch 03036/03692] [00:28:09/00:06:05, 0.557s/it]: train_loss_raw=2.3442, running_loss=2.3107, LR=0.000100
[2025-08-10 11:24:17,203][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003048] [Batch 03048/03692] [00:28:16/00:05:58, 0.557s/it]: train_loss_raw=2.2776, running_loss=2.3087, LR=0.000100
[2025-08-10 11:24:23,780][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003060] [Batch 03060/03692] [00:28:22/00:05:51, 0.557s/it]: train_loss_raw=2.2490, running_loss=2.3104, LR=0.000100
[2025-08-10 11:24:30,396][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003072] [Batch 03072/03692] [00:28:29/00:05:45, 0.557s/it]: train_loss_raw=2.2454, running_loss=2.3075, LR=0.000100
[2025-08-10 11:24:37,049][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003084] [Batch 03084/03692] [00:28:36/00:05:38, 0.556s/it]: train_loss_raw=2.1650, running_loss=2.3032, LR=0.000100
[2025-08-10 11:24:43,448][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003096] [Batch 03096/03692] [00:28:42/00:05:31, 0.556s/it]: train_loss_raw=2.4160, running_loss=2.3028, LR=0.000100
[2025-08-10 11:24:49,730][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003108] [Batch 03108/03692] [00:28:48/00:05:24, 0.556s/it]: train_loss_raw=2.3553, running_loss=2.3038, LR=0.000100
[2025-08-10 11:24:55,980][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003120] [Batch 03120/03692] [00:28:55/00:05:18, 0.556s/it]: train_loss_raw=2.2205, running_loss=2.3023, LR=0.000100
[2025-08-10 11:25:02,561][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003132] [Batch 03132/03692] [00:29:01/00:05:11, 0.556s/it]: train_loss_raw=2.2395, running_loss=2.3002, LR=0.000100
[2025-08-10 11:25:09,097][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003144] [Batch 03144/03692] [00:29:08/00:05:04, 0.556s/it]: train_loss_raw=2.2987, running_loss=2.3023, LR=0.000100
[2025-08-10 11:25:15,615][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003156] [Batch 03156/03692] [00:29:14/00:04:58, 0.556s/it]: train_loss_raw=2.3224, running_loss=2.3036, LR=0.000100
[2025-08-10 11:25:21,994][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003168] [Batch 03168/03692] [00:29:21/00:04:51, 0.556s/it]: train_loss_raw=2.2725, running_loss=2.3000, LR=0.000100
[2025-08-10 11:25:28,477][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003180] [Batch 03180/03692] [00:29:27/00:04:44, 0.556s/it]: train_loss_raw=2.3335, running_loss=2.2988, LR=0.000100
[2025-08-10 11:25:34,933][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003192] [Batch 03192/03692] [00:29:34/00:04:37, 0.556s/it]: train_loss_raw=2.2622, running_loss=2.2952, LR=0.000100
[2025-08-10 11:25:41,268][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003204] [Batch 03204/03692] [00:29:40/00:04:31, 0.556s/it]: train_loss_raw=2.3185, running_loss=2.2936, LR=0.000100
[2025-08-10 11:25:47,498][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003216] [Batch 03216/03692] [00:29:46/00:04:24, 0.556s/it]: train_loss_raw=2.2508, running_loss=2.2898, LR=0.000100
[2025-08-10 11:25:53,810][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003228] [Batch 03228/03692] [00:29:53/00:04:17, 0.555s/it]: train_loss_raw=2.1484, running_loss=2.2894, LR=0.000100
[2025-08-10 11:26:00,011][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003240] [Batch 03240/03692] [00:29:59/00:04:11, 0.555s/it]: train_loss_raw=2.2873, running_loss=2.2873, LR=0.000100
[2025-08-10 11:26:06,398][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003252] [Batch 03252/03692] [00:30:05/00:04:04, 0.555s/it]: train_loss_raw=2.2477, running_loss=2.2877, LR=0.000100
[2025-08-10 11:26:13,007][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003264] [Batch 03264/03692] [00:30:12/00:03:57, 0.555s/it]: train_loss_raw=2.2267, running_loss=2.2868, LR=0.000100
[2025-08-10 11:26:19,624][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003276] [Batch 03276/03692] [00:30:18/00:03:50, 0.555s/it]: train_loss_raw=2.3691, running_loss=2.2902, LR=0.000100
[2025-08-10 11:26:26,256][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003288] [Batch 03288/03692] [00:30:25/00:03:44, 0.555s/it]: train_loss_raw=2.2869, running_loss=2.2890, LR=0.000100
[2025-08-10 11:26:32,874][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003300] [Batch 03300/03692] [00:30:32/00:03:37, 0.555s/it]: train_loss_raw=2.2604, running_loss=2.2845, LR=0.000100
[2025-08-10 11:26:39,353][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003312] [Batch 03312/03692] [00:30:38/00:03:30, 0.555s/it]: train_loss_raw=2.2913, running_loss=2.2836, LR=0.000100
[2025-08-10 11:26:45,832][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003324] [Batch 03324/03692] [00:30:45/00:03:24, 0.555s/it]: train_loss_raw=2.2371, running_loss=2.2820, LR=0.000100
[2025-08-10 11:26:52,326][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003336] [Batch 03336/03692] [00:30:51/00:03:17, 0.555s/it]: train_loss_raw=2.2045, running_loss=2.2784, LR=0.000100
[2025-08-10 11:26:58,740][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003348] [Batch 03348/03692] [00:30:57/00:03:10, 0.555s/it]: train_loss_raw=2.3533, running_loss=2.2801, LR=0.000100
[2025-08-10 11:27:05,268][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003360] [Batch 03360/03692] [00:31:04/00:03:04, 0.555s/it]: train_loss_raw=2.3612, running_loss=2.2835, LR=0.000100
[2025-08-10 11:27:11,823][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003372] [Batch 03372/03692] [00:31:11/00:02:57, 0.555s/it]: train_loss_raw=2.3129, running_loss=2.2812, LR=0.000100
[2025-08-10 11:27:18,323][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003384] [Batch 03384/03692] [00:31:17/00:02:50, 0.555s/it]: train_loss_raw=2.3036, running_loss=2.2818, LR=0.000100
[2025-08-10 11:27:24,879][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003396] [Batch 03396/03692] [00:31:24/00:02:44, 0.555s/it]: train_loss_raw=2.2543, running_loss=2.2797, LR=0.000100
[2025-08-10 11:27:31,320][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003408] [Batch 03408/03692] [00:31:30/00:02:37, 0.555s/it]: train_loss_raw=2.3025, running_loss=2.2771, LR=0.000100
[2025-08-10 11:27:37,791][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003420] [Batch 03420/03692] [00:31:36/00:02:30, 0.555s/it]: train_loss_raw=2.2533, running_loss=2.2739, LR=0.000100
[2025-08-10 11:27:44,256][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003432] [Batch 03432/03692] [00:31:43/00:02:24, 0.555s/it]: train_loss_raw=2.1917, running_loss=2.2704, LR=0.000100
[2025-08-10 11:27:50,685][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003444] [Batch 03444/03692] [00:31:49/00:02:17, 0.555s/it]: train_loss_raw=2.2757, running_loss=2.2679, LR=0.000100
[2025-08-10 11:27:57,249][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003456] [Batch 03456/03692] [00:31:56/00:02:10, 0.555s/it]: train_loss_raw=2.2555, running_loss=2.2678, LR=0.000100
[2025-08-10 11:28:03,851][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003468] [Batch 03468/03692] [00:32:03/00:02:04, 0.555s/it]: train_loss_raw=2.2321, running_loss=2.2657, LR=0.000100
[2025-08-10 11:28:10,507][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003480] [Batch 03480/03692] [00:32:09/00:01:57, 0.555s/it]: train_loss_raw=2.2462, running_loss=2.2682, LR=0.000100
[2025-08-10 11:28:17,139][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003492] [Batch 03492/03692] [00:32:16/00:01:50, 0.555s/it]: train_loss_raw=2.2429, running_loss=2.2708, LR=0.000100
[2025-08-10 11:28:23,756][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003504] [Batch 03504/03692] [00:32:22/00:01:44, 0.554s/it]: train_loss_raw=2.2499, running_loss=2.2715, LR=0.000100
[2025-08-10 11:28:30,355][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003516] [Batch 03516/03692] [00:32:29/00:01:37, 0.554s/it]: train_loss_raw=2.2152, running_loss=2.2719, LR=0.000100
[2025-08-10 11:28:36,863][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003528] [Batch 03528/03692] [00:32:36/00:01:30, 0.554s/it]: train_loss_raw=2.3055, running_loss=2.2701, LR=0.000100
[2025-08-10 11:28:43,370][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003540] [Batch 03540/03692] [00:32:42/00:01:24, 0.554s/it]: train_loss_raw=2.3523, running_loss=2.2692, LR=0.000100
[2025-08-10 11:28:49,998][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003552] [Batch 03552/03692] [00:32:49/00:01:17, 0.554s/it]: train_loss_raw=2.3082, running_loss=2.2699, LR=0.000100
[2025-08-10 11:28:56,567][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003564] [Batch 03564/03692] [00:32:55/00:01:10, 0.554s/it]: train_loss_raw=2.3535, running_loss=2.2723, LR=0.000100
[2025-08-10 11:29:03,145][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003576] [Batch 03576/03692] [00:33:02/00:01:04, 0.554s/it]: train_loss_raw=2.1710, running_loss=2.2650, LR=0.000100
[2025-08-10 11:29:09,719][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003588] [Batch 03588/03692] [00:33:08/00:00:57, 0.554s/it]: train_loss_raw=2.3228, running_loss=2.2639, LR=0.000100
[2025-08-10 11:29:16,296][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003600] [Batch 03600/03692] [00:33:15/00:00:50, 0.554s/it]: train_loss_raw=2.2612, running_loss=2.2655, LR=0.000100
[2025-08-10 11:29:22,778][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003612] [Batch 03612/03692] [00:33:21/00:00:44, 0.554s/it]: train_loss_raw=2.3111, running_loss=2.2651, LR=0.000100
[2025-08-10 11:29:29,354][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003624] [Batch 03624/03692] [00:33:28/00:00:37, 0.554s/it]: train_loss_raw=2.3689, running_loss=2.2651, LR=0.000100
[2025-08-10 11:29:35,954][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003636] [Batch 03636/03692] [00:33:35/00:00:31, 0.554s/it]: train_loss_raw=2.2453, running_loss=2.2619, LR=0.000100
[2025-08-10 11:29:42,554][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003648] [Batch 03648/03692] [00:33:41/00:00:24, 0.554s/it]: train_loss_raw=2.2433, running_loss=2.2611, LR=0.000100
[2025-08-10 11:29:49,015][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003660] [Batch 03660/03692] [00:33:48/00:00:17, 0.554s/it]: train_loss_raw=2.2997, running_loss=2.2609, LR=0.000100
[2025-08-10 11:29:55,582][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003672] [Batch 03672/03692] [00:33:54/00:00:11, 0.554s/it]: train_loss_raw=2.2485, running_loss=2.2583, LR=0.000100
[2025-08-10 11:30:02,176][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003684] [Batch 03684/03692] [00:34:01/00:00:04, 0.554s/it]: train_loss_raw=2.1232, running_loss=2.2549, LR=0.000100
[2025-08-10 11:30:12,029][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-10 11:30:15,008][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003693] [Batch 00011/00025] [00:00:02/00:00:03, 0.248s/it]
[2025-08-10 11:30:52,543][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 003693] [Batch 00023/00025] [00:00:40/00:00:01, 1.688s/it]
[2025-08-10 11:31:09,746][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=2.25647, valid_loss=2.23328
[2025-08-10 11:31:09,747][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-10 11:31:09,747][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.863
[2025-08-10 11:31:09,747][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.017
[2025-08-10 11:31:09,747][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.019
[2025-08-10 11:31:09,747][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.000
[2025-08-10 11:31:09,750][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:35:08, remaining time 16:59:19, 00:35:08 per epoch
[2025-08-10 11:31:12,557][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003696] [Batch 00004/03692] [00:00:01/00:27:18, 0.444s/it]: train_loss_raw=2.2133, running_loss=2.2537, LR=0.000100
[2025-08-10 11:31:19,073][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003708] [Batch 00016/03692] [00:00:08/00:31:45, 0.518s/it]: train_loss_raw=2.2056, running_loss=2.2533, LR=0.000100
[2025-08-10 11:31:25,596][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003720] [Batch 00028/03692] [00:00:14/00:32:18, 0.529s/it]: train_loss_raw=2.3262, running_loss=2.2544, LR=0.000100
[2025-08-10 11:31:32,083][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003732] [Batch 00040/03692] [00:00:21/00:32:25, 0.533s/it]: train_loss_raw=2.3564, running_loss=2.2557, LR=0.000100
[2025-08-10 11:31:38,551][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003744] [Batch 00052/03692] [00:00:27/00:32:23, 0.534s/it]: train_loss_raw=2.2765, running_loss=2.2556, LR=0.000100
[2025-08-10 11:31:44,992][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003756] [Batch 00064/03692] [00:00:34/00:32:19, 0.535s/it]: train_loss_raw=2.2402, running_loss=2.2549, LR=0.000100
[2025-08-10 11:31:51,432][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003768] [Batch 00076/03692] [00:00:40/00:32:14, 0.535s/it]: train_loss_raw=2.2567, running_loss=2.2523, LR=0.000100
[2025-08-10 11:31:57,974][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003780] [Batch 00088/03692] [00:00:47/00:32:12, 0.536s/it]: train_loss_raw=2.2236, running_loss=2.2494, LR=0.000100
[2025-08-10 11:32:04,575][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003792] [Batch 00100/03692] [00:00:53/00:32:12, 0.538s/it]: train_loss_raw=2.2010, running_loss=2.2466, LR=0.000100
[2025-08-10 11:32:11,149][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003804] [Batch 00112/03692] [00:01:00/00:32:09, 0.539s/it]: train_loss_raw=2.1991, running_loss=2.2449, LR=0.000100
[2025-08-10 11:32:17,765][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003816] [Batch 00124/03692] [00:01:06/00:32:07, 0.540s/it]: train_loss_raw=2.2115, running_loss=2.2412, LR=0.000100
[2025-08-10 11:32:24,287][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003828] [Batch 00136/03692] [00:01:13/00:32:02, 0.540s/it]: train_loss_raw=2.2719, running_loss=2.2423, LR=0.000100
[2025-08-10 11:32:30,689][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003840] [Batch 00148/03692] [00:01:19/00:31:53, 0.540s/it]: train_loss_raw=2.1222, running_loss=2.2412, LR=0.000100
[2025-08-10 11:32:37,049][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003852] [Batch 00160/03692] [00:01:26/00:31:44, 0.539s/it]: train_loss_raw=2.2715, running_loss=2.2389, LR=0.000100
[2025-08-10 11:32:43,434][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003864] [Batch 00172/03692] [00:01:32/00:31:36, 0.539s/it]: train_loss_raw=2.1613, running_loss=2.2378, LR=0.000100
[2025-08-10 11:32:49,731][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003876] [Batch 00184/03692] [00:01:38/00:31:26, 0.538s/it]: train_loss_raw=2.2480, running_loss=2.2389, LR=0.000100
[2025-08-10 11:32:55,968][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003888] [Batch 00196/03692] [00:01:45/00:31:16, 0.537s/it]: train_loss_raw=2.2493, running_loss=2.2399, LR=0.000100
[2025-08-10 11:33:02,396][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003900] [Batch 00208/03692] [00:01:51/00:31:09, 0.537s/it]: train_loss_raw=2.1644, running_loss=2.2391, LR=0.000100
[2025-08-10 11:33:09,026][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003912] [Batch 00220/03692] [00:01:58/00:31:06, 0.537s/it]: train_loss_raw=2.1976, running_loss=2.2364, LR=0.000100
[2025-08-10 11:33:15,680][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003924] [Batch 00232/03692] [00:02:04/00:31:02, 0.538s/it]: train_loss_raw=2.1788, running_loss=2.2350, LR=0.000100
[2025-08-10 11:33:22,242][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003936] [Batch 00244/03692] [00:02:11/00:30:57, 0.539s/it]: train_loss_raw=2.2650, running_loss=2.2345, LR=0.000100
[2025-08-10 11:33:28,807][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003948] [Batch 00256/03692] [00:02:18/00:30:52, 0.539s/it]: train_loss_raw=2.3276, running_loss=2.2346, LR=0.000100
[2025-08-10 11:33:35,485][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003960] [Batch 00268/03692] [00:02:24/00:30:48, 0.540s/it]: train_loss_raw=2.2058, running_loss=2.2352, LR=0.000100
[2025-08-10 11:33:42,107][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003972] [Batch 00280/03692] [00:02:31/00:30:44, 0.540s/it]: train_loss_raw=2.2033, running_loss=2.2342, LR=0.000100
[2025-08-10 11:33:48,721][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003984] [Batch 00292/03692] [00:02:37/00:30:39, 0.541s/it]: train_loss_raw=2.1658, running_loss=2.2343, LR=0.000100
[2025-08-10 11:33:55,343][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 003996] [Batch 00304/03692] [00:02:44/00:30:34, 0.541s/it]: train_loss_raw=2.2236, running_loss=2.2333, LR=0.000100
[2025-08-10 11:34:06,502][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004008] [Batch 00316/03692] [00:02:55/00:31:17, 0.556s/it]: train_loss_raw=2.1407, running_loss=2.2304, LR=0.000100
[2025-08-10 11:34:13,038][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004020] [Batch 00328/03692] [00:03:02/00:31:09, 0.556s/it]: train_loss_raw=2.1055, running_loss=2.2313, LR=0.000100
[2025-08-10 11:34:19,636][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004032] [Batch 00340/03692] [00:03:08/00:31:01, 0.555s/it]: train_loss_raw=2.2511, running_loss=2.2329, LR=0.000100
[2025-08-10 11:34:26,161][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004044] [Batch 00352/03692] [00:03:15/00:30:53, 0.555s/it]: train_loss_raw=2.2601, running_loss=2.2291, LR=0.000100
[2025-08-10 11:34:32,678][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004056] [Batch 00364/03692] [00:03:21/00:30:45, 0.555s/it]: train_loss_raw=2.2533, running_loss=2.2281, LR=0.000100
[2025-08-10 11:34:39,207][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004068] [Batch 00376/03692] [00:03:28/00:30:38, 0.554s/it]: train_loss_raw=2.1421, running_loss=2.2281, LR=0.000100
[2025-08-10 11:34:45,843][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004080] [Batch 00388/03692] [00:03:35/00:30:31, 0.554s/it]: train_loss_raw=2.1896, running_loss=2.2284, LR=0.000100
[2025-08-10 11:34:52,412][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004092] [Batch 00400/03692] [00:03:41/00:30:24, 0.554s/it]: train_loss_raw=2.1058, running_loss=2.2257, LR=0.000100
[2025-08-10 11:34:58,861][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004104] [Batch 00412/03692] [00:03:48/00:30:15, 0.554s/it]: train_loss_raw=2.1677, running_loss=2.2262, LR=0.000100
[2025-08-10 11:35:05,289][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004116] [Batch 00424/03692] [00:03:54/00:30:07, 0.553s/it]: train_loss_raw=2.2484, running_loss=2.2259, LR=0.000100
[2025-08-10 11:35:11,740][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004128] [Batch 00436/03692] [00:04:00/00:29:59, 0.553s/it]: train_loss_raw=2.2530, running_loss=2.2238, LR=0.000100
[2025-08-10 11:35:18,222][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004140] [Batch 00448/03692] [00:04:07/00:29:51, 0.552s/it]: train_loss_raw=2.2288, running_loss=2.2214, LR=0.000100
[2025-08-10 11:35:24,854][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004152] [Batch 00460/03692] [00:04:14/00:29:45, 0.552s/it]: train_loss_raw=2.2248, running_loss=2.2211, LR=0.000100
[2025-08-10 11:35:31,447][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004164] [Batch 00472/03692] [00:04:20/00:29:38, 0.552s/it]: train_loss_raw=2.2513, running_loss=2.2218, LR=0.000100
[2025-08-10 11:35:38,060][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004176] [Batch 00484/03692] [00:04:27/00:29:31, 0.552s/it]: train_loss_raw=2.1959, running_loss=2.2208, LR=0.000100
[2025-08-10 11:35:44,582][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004188] [Batch 00496/03692] [00:04:33/00:29:24, 0.552s/it]: train_loss_raw=2.2003, running_loss=2.2212, LR=0.000100
[2025-08-10 11:35:51,053][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004200] [Batch 00508/03692] [00:04:40/00:29:16, 0.552s/it]: train_loss_raw=2.2687, running_loss=2.2176, LR=0.000100
[2025-08-10 11:35:57,449][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004212] [Batch 00520/03692] [00:04:46/00:29:08, 0.551s/it]: train_loss_raw=2.2439, running_loss=2.2169, LR=0.000100
[2025-08-10 11:36:03,971][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004224] [Batch 00532/03692] [00:04:53/00:29:01, 0.551s/it]: train_loss_raw=2.1684, running_loss=2.2124, LR=0.000100
[2025-08-10 11:36:10,527][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004236] [Batch 00544/03692] [00:04:59/00:28:54, 0.551s/it]: train_loss_raw=2.1484, running_loss=2.2095, LR=0.000100
[2025-08-10 11:36:16,971][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004248] [Batch 00556/03692] [00:05:06/00:28:47, 0.551s/it]: train_loss_raw=2.1580, running_loss=2.2118, LR=0.000100
[2025-08-10 11:36:23,455][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004260] [Batch 00568/03692] [00:05:12/00:28:39, 0.550s/it]: train_loss_raw=2.3021, running_loss=2.2116, LR=0.000100
[2025-08-10 11:36:30,094][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004272] [Batch 00580/03692] [00:05:19/00:28:33, 0.551s/it]: train_loss_raw=2.2412, running_loss=2.2088, LR=0.000100
[2025-08-10 11:36:36,554][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004284] [Batch 00592/03692] [00:05:25/00:28:25, 0.550s/it]: train_loss_raw=2.1971, running_loss=2.2100, LR=0.000100
[2025-08-10 11:36:43,004][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004296] [Batch 00604/03692] [00:05:32/00:28:18, 0.550s/it]: train_loss_raw=2.1762, running_loss=2.2090, LR=0.000100
[2025-08-10 11:36:49,457][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004308] [Batch 00616/03692] [00:05:38/00:28:11, 0.550s/it]: train_loss_raw=2.1656, running_loss=2.2049, LR=0.000100
[2025-08-10 11:36:55,805][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004320] [Batch 00628/03692] [00:05:45/00:28:03, 0.549s/it]: train_loss_raw=2.2483, running_loss=2.2049, LR=0.000100
[2025-08-10 11:37:02,261][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004332] [Batch 00640/03692] [00:05:51/00:27:56, 0.549s/it]: train_loss_raw=2.1914, running_loss=2.2046, LR=0.000100
[2025-08-10 11:37:08,797][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004344] [Batch 00652/03692] [00:05:58/00:27:49, 0.549s/it]: train_loss_raw=2.2307, running_loss=2.2046, LR=0.000100
[2025-08-10 11:37:15,395][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004356] [Batch 00664/03692] [00:06:04/00:27:42, 0.549s/it]: train_loss_raw=2.0742, running_loss=2.2036, LR=0.000100
[2025-08-10 11:37:22,024][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004368] [Batch 00676/03692] [00:06:11/00:27:36, 0.549s/it]: train_loss_raw=2.2160, running_loss=2.2039, LR=0.000100
[2025-08-10 11:37:28,677][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004380] [Batch 00688/03692] [00:06:17/00:27:30, 0.549s/it]: train_loss_raw=2.2731, running_loss=2.2026, LR=0.000100
[2025-08-10 11:37:35,154][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004392] [Batch 00700/03692] [00:06:24/00:27:22, 0.549s/it]: train_loss_raw=2.1835, running_loss=2.2021, LR=0.000100
[2025-08-10 11:37:41,394][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004404] [Batch 00712/03692] [00:06:30/00:27:14, 0.549s/it]: train_loss_raw=2.1002, running_loss=2.1988, LR=0.000100
[2025-08-10 11:37:47,659][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004416] [Batch 00724/03692] [00:06:36/00:27:06, 0.548s/it]: train_loss_raw=2.1402, running_loss=2.1999, LR=0.000100
[2025-08-10 11:37:53,969][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004428] [Batch 00736/03692] [00:06:43/00:26:59, 0.548s/it]: train_loss_raw=2.1705, running_loss=2.1987, LR=0.000100
[2025-08-10 11:38:00,566][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004440] [Batch 00748/03692] [00:06:49/00:26:52, 0.548s/it]: train_loss_raw=2.2766, running_loss=2.1985, LR=0.000100
[2025-08-10 11:38:07,200][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004452] [Batch 00760/03692] [00:06:56/00:26:46, 0.548s/it]: train_loss_raw=2.2711, running_loss=2.2007, LR=0.000100
[2025-08-10 11:38:13,762][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004464] [Batch 00772/03692] [00:07:02/00:26:39, 0.548s/it]: train_loss_raw=2.2582, running_loss=2.2008, LR=0.000100
[2025-08-10 11:38:20,329][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004476] [Batch 00784/03692] [00:07:09/00:26:33, 0.548s/it]: train_loss_raw=2.1546, running_loss=2.1995, LR=0.000100
[2025-08-10 11:38:26,929][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004488] [Batch 00796/03692] [00:07:16/00:26:26, 0.548s/it]: train_loss_raw=2.2195, running_loss=2.1943, LR=0.000100
[2025-08-10 11:38:33,511][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004500] [Batch 00808/03692] [00:07:22/00:26:20, 0.548s/it]: train_loss_raw=2.2084, running_loss=2.1946, LR=0.000100
[2025-08-10 11:38:40,018][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004512] [Batch 00820/03692] [00:07:29/00:26:13, 0.548s/it]: train_loss_raw=2.2414, running_loss=2.1979, LR=0.000100
[2025-08-10 11:38:46,560][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004524] [Batch 00832/03692] [00:07:35/00:26:06, 0.548s/it]: train_loss_raw=2.1115, running_loss=2.1987, LR=0.000100
[2025-08-10 11:38:53,034][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004536] [Batch 00844/03692] [00:07:42/00:25:59, 0.548s/it]: train_loss_raw=2.2515, running_loss=2.1966, LR=0.000100
[2025-08-10 11:38:59,641][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004548] [Batch 00856/03692] [00:07:48/00:25:53, 0.548s/it]: train_loss_raw=2.2056, running_loss=2.1963, LR=0.000100
[2025-08-10 11:39:06,227][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004560] [Batch 00868/03692] [00:07:55/00:25:46, 0.548s/it]: train_loss_raw=2.3192, running_loss=2.2000, LR=0.000100
[2025-08-10 11:39:12,660][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004572] [Batch 00880/03692] [00:08:01/00:25:39, 0.548s/it]: train_loss_raw=2.1521, running_loss=2.1973, LR=0.000100
[2025-08-10 11:39:19,257][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004584] [Batch 00892/03692] [00:08:08/00:25:33, 0.548s/it]: train_loss_raw=2.1484, running_loss=2.1966, LR=0.000100
[2025-08-10 11:39:25,885][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004596] [Batch 00904/03692] [00:08:15/00:25:26, 0.548s/it]: train_loss_raw=2.2239, running_loss=2.1944, LR=0.000100
[2025-08-10 11:39:32,426][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004608] [Batch 00916/03692] [00:08:21/00:25:20, 0.548s/it]: train_loss_raw=2.0953, running_loss=2.1927, LR=0.000100
[2025-08-10 11:39:38,798][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004620] [Batch 00928/03692] [00:08:28/00:25:13, 0.547s/it]: train_loss_raw=2.1822, running_loss=2.1936, LR=0.000100
[2025-08-10 11:39:45,335][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004632] [Batch 00940/03692] [00:08:34/00:25:06, 0.547s/it]: train_loss_raw=2.2977, running_loss=2.1964, LR=0.000100
[2025-08-10 11:39:51,919][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004644] [Batch 00952/03692] [00:08:41/00:24:59, 0.547s/it]: train_loss_raw=2.1718, running_loss=2.1973, LR=0.000100
[2025-08-10 11:39:58,332][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004656] [Batch 00964/03692] [00:08:47/00:24:52, 0.547s/it]: train_loss_raw=2.2190, running_loss=2.1924, LR=0.000100
[2025-08-10 11:40:04,986][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004668] [Batch 00976/03692] [00:08:54/00:24:46, 0.547s/it]: train_loss_raw=2.0929, running_loss=2.1880, LR=0.000100
[2025-08-10 11:40:11,544][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004680] [Batch 00988/03692] [00:09:00/00:24:39, 0.547s/it]: train_loss_raw=2.1549, running_loss=2.1867, LR=0.000100
[2025-08-10 11:40:18,079][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004692] [Batch 01000/03692] [00:09:07/00:24:33, 0.547s/it]: train_loss_raw=2.0841, running_loss=2.1859, LR=0.000100
[2025-08-10 11:40:24,575][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004704] [Batch 01012/03692] [00:09:13/00:24:26, 0.547s/it]: train_loss_raw=2.1312, running_loss=2.1867, LR=0.000100
[2025-08-10 11:40:31,031][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004716] [Batch 01024/03692] [00:09:20/00:24:19, 0.547s/it]: train_loss_raw=2.1578, running_loss=2.1864, LR=0.000100
[2025-08-10 11:40:37,564][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004728] [Batch 01036/03692] [00:09:26/00:24:13, 0.547s/it]: train_loss_raw=2.2199, running_loss=2.1866, LR=0.000100
[2025-08-10 11:40:44,153][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004740] [Batch 01048/03692] [00:09:33/00:24:06, 0.547s/it]: train_loss_raw=2.1643, running_loss=2.1854, LR=0.000100
[2025-08-10 11:40:50,605][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004752] [Batch 01060/03692] [00:09:39/00:23:59, 0.547s/it]: train_loss_raw=2.1227, running_loss=2.1853, LR=0.000100
[2025-08-10 11:40:57,243][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004764] [Batch 01072/03692] [00:09:46/00:23:53, 0.547s/it]: train_loss_raw=2.1907, running_loss=2.1881, LR=0.000100
[2025-08-10 11:41:03,787][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004776] [Batch 01084/03692] [00:09:53/00:23:46, 0.547s/it]: train_loss_raw=2.2062, running_loss=2.1894, LR=0.000100
[2025-08-10 11:41:10,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004788] [Batch 01096/03692] [00:09:59/00:23:39, 0.547s/it]: train_loss_raw=2.1675, running_loss=2.1877, LR=0.000100
[2025-08-10 11:41:16,427][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004800] [Batch 01108/03692] [00:10:05/00:23:32, 0.547s/it]: train_loss_raw=2.0686, running_loss=2.1877, LR=0.000100
[2025-08-10 11:41:22,873][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004812] [Batch 01120/03692] [00:10:12/00:23:25, 0.547s/it]: train_loss_raw=2.2700, running_loss=2.1884, LR=0.000100
[2025-08-10 11:41:29,334][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004824] [Batch 01132/03692] [00:10:18/00:23:18, 0.546s/it]: train_loss_raw=2.1471, running_loss=2.1903, LR=0.000100
[2025-08-10 11:41:35,904][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004836] [Batch 01144/03692] [00:10:25/00:23:12, 0.546s/it]: train_loss_raw=2.1926, running_loss=2.1925, LR=0.000100
[2025-08-10 11:41:42,383][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004848] [Batch 01156/03692] [00:10:31/00:23:05, 0.546s/it]: train_loss_raw=2.0894, running_loss=2.1893, LR=0.000100
[2025-08-10 11:41:48,995][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004860] [Batch 01168/03692] [00:10:38/00:22:59, 0.546s/it]: train_loss_raw=2.1793, running_loss=2.1927, LR=0.000100
[2025-08-10 11:41:55,550][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004872] [Batch 01180/03692] [00:10:44/00:22:52, 0.546s/it]: train_loss_raw=2.1117, running_loss=2.1875, LR=0.000100
[2025-08-10 11:42:02,115][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004884] [Batch 01192/03692] [00:10:51/00:22:46, 0.546s/it]: train_loss_raw=2.1713, running_loss=2.1844, LR=0.000100
[2025-08-10 11:42:08,558][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004896] [Batch 01204/03692] [00:10:57/00:22:39, 0.546s/it]: train_loss_raw=2.2740, running_loss=2.1836, LR=0.000100
[2025-08-10 11:42:15,150][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004908] [Batch 01216/03692] [00:11:04/00:22:32, 0.546s/it]: train_loss_raw=2.1478, running_loss=2.1825, LR=0.000100
[2025-08-10 11:42:21,635][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004920] [Batch 01228/03692] [00:11:10/00:22:26, 0.546s/it]: train_loss_raw=2.1948, running_loss=2.1833, LR=0.000100
[2025-08-10 11:42:27,842][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004932] [Batch 01240/03692] [00:11:17/00:22:18, 0.546s/it]: train_loss_raw=2.2168, running_loss=2.1853, LR=0.000100
[2025-08-10 11:42:34,228][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004944] [Batch 01252/03692] [00:11:23/00:22:11, 0.546s/it]: train_loss_raw=2.1393, running_loss=2.1855, LR=0.000100
[2025-08-10 11:42:40,784][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004956] [Batch 01264/03692] [00:11:30/00:22:05, 0.546s/it]: train_loss_raw=2.1081, running_loss=2.1837, LR=0.000100
[2025-08-10 11:42:47,380][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004968] [Batch 01276/03692] [00:11:36/00:21:58, 0.546s/it]: train_loss_raw=2.2643, running_loss=2.1822, LR=0.000100
[2025-08-10 11:42:53,997][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004980] [Batch 01288/03692] [00:11:43/00:21:52, 0.546s/it]: train_loss_raw=2.1302, running_loss=2.1823, LR=0.000100
[2025-08-10 11:43:00,500][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004992] [Batch 01300/03692] [00:11:49/00:21:45, 0.546s/it]: train_loss_raw=2.1665, running_loss=2.1810, LR=0.000100
[2025-08-10 11:43:06,714][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005004] [Batch 01312/03692] [00:11:55/00:21:38, 0.546s/it]: train_loss_raw=2.2322, running_loss=2.1775, LR=0.000100
[2025-08-10 11:43:12,989][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005016] [Batch 01324/03692] [00:12:02/00:21:31, 0.545s/it]: train_loss_raw=2.1001, running_loss=2.1767, LR=0.000100
[2025-08-10 11:43:19,270][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005028] [Batch 01336/03692] [00:12:08/00:21:24, 0.545s/it]: train_loss_raw=2.1489, running_loss=2.1757, LR=0.000100
[2025-08-10 11:43:25,478][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005040] [Batch 01348/03692] [00:12:14/00:21:17, 0.545s/it]: train_loss_raw=2.1134, running_loss=2.1728, LR=0.000100
[2025-08-10 11:43:31,709][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005052] [Batch 01360/03692] [00:12:20/00:21:10, 0.545s/it]: train_loss_raw=2.0956, running_loss=2.1723, LR=0.000100
[2025-08-10 11:43:37,975][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005064] [Batch 01372/03692] [00:12:27/00:21:03, 0.545s/it]: train_loss_raw=2.0989, running_loss=2.1717, LR=0.000100
[2025-08-10 11:43:44,166][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005076] [Batch 01384/03692] [00:12:33/00:20:56, 0.544s/it]: train_loss_raw=2.0509, running_loss=2.1676, LR=0.000100
[2025-08-10 11:43:50,405][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005088] [Batch 01396/03692] [00:12:39/00:20:49, 0.544s/it]: train_loss_raw=2.2907, running_loss=2.1676, LR=0.000100
[2025-08-10 11:43:56,660][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005100] [Batch 01408/03692] [00:12:45/00:20:42, 0.544s/it]: train_loss_raw=2.0545, running_loss=2.1679, LR=0.000100
[2025-08-10 11:44:02,885][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005112] [Batch 01420/03692] [00:12:52/00:20:35, 0.544s/it]: train_loss_raw=2.1597, running_loss=2.1656, LR=0.000100
[2025-08-10 11:44:09,184][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005124] [Batch 01432/03692] [00:12:58/00:20:28, 0.544s/it]: train_loss_raw=2.1639, running_loss=2.1670, LR=0.000100
[2025-08-10 11:44:15,528][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005136] [Batch 01444/03692] [00:13:04/00:20:21, 0.543s/it]: train_loss_raw=2.1900, running_loss=2.1646, LR=0.000100
[2025-08-10 11:44:21,751][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005148] [Batch 01456/03692] [00:13:10/00:20:14, 0.543s/it]: train_loss_raw=2.2742, running_loss=2.1636, LR=0.000100
[2025-08-10 11:44:28,175][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005160] [Batch 01468/03692] [00:13:17/00:20:08, 0.543s/it]: train_loss_raw=2.0972, running_loss=2.1622, LR=0.000100
[2025-08-10 11:44:34,690][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005172] [Batch 01480/03692] [00:13:23/00:20:01, 0.543s/it]: train_loss_raw=2.0924, running_loss=2.1610, LR=0.000100
[2025-08-10 11:44:41,250][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005184] [Batch 01492/03692] [00:13:30/00:19:55, 0.543s/it]: train_loss_raw=2.0973, running_loss=2.1624, LR=0.000100
[2025-08-10 11:44:47,824][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005196] [Batch 01504/03692] [00:13:37/00:19:48, 0.543s/it]: train_loss_raw=2.0454, running_loss=2.1610, LR=0.000100
[2025-08-10 11:44:54,275][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005208] [Batch 01516/03692] [00:13:43/00:19:42, 0.543s/it]: train_loss_raw=2.1426, running_loss=2.1582, LR=0.000100
[2025-08-10 11:45:00,878][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005220] [Batch 01528/03692] [00:13:50/00:19:35, 0.543s/it]: train_loss_raw=2.1392, running_loss=2.1580, LR=0.000100
[2025-08-10 11:45:07,483][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005232] [Batch 01540/03692] [00:13:56/00:19:29, 0.543s/it]: train_loss_raw=1.9961, running_loss=2.1562, LR=0.000100
[2025-08-10 11:45:14,115][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005244] [Batch 01552/03692] [00:14:03/00:19:22, 0.543s/it]: train_loss_raw=2.1231, running_loss=2.1576, LR=0.000100
[2025-08-10 11:45:20,710][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005256] [Batch 01564/03692] [00:14:09/00:19:16, 0.543s/it]: train_loss_raw=2.1768, running_loss=2.1585, LR=0.000100
[2025-08-10 11:45:27,155][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005268] [Batch 01576/03692] [00:14:16/00:19:09, 0.543s/it]: train_loss_raw=2.2068, running_loss=2.1561, LR=0.000100
[2025-08-10 11:45:33,632][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005280] [Batch 01588/03692] [00:14:22/00:19:03, 0.543s/it]: train_loss_raw=2.0321, running_loss=2.1533, LR=0.000100
[2025-08-10 11:45:40,210][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005292] [Batch 01600/03692] [00:14:29/00:18:56, 0.543s/it]: train_loss_raw=2.0734, running_loss=2.1514, LR=0.000100
[2025-08-10 11:45:46,783][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005304] [Batch 01612/03692] [00:14:36/00:18:50, 0.543s/it]: train_loss_raw=1.9999, running_loss=2.1485, LR=0.000100
[2025-08-10 11:45:53,341][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005316] [Batch 01624/03692] [00:14:42/00:18:43, 0.543s/it]: train_loss_raw=2.0959, running_loss=2.1515, LR=0.000100
[2025-08-10 11:45:59,938][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005328] [Batch 01636/03692] [00:14:49/00:18:37, 0.543s/it]: train_loss_raw=2.2729, running_loss=2.1505, LR=0.000100
[2025-08-10 11:46:06,607][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005340] [Batch 01648/03692] [00:14:55/00:18:31, 0.544s/it]: train_loss_raw=2.1383, running_loss=2.1485, LR=0.000100
[2025-08-10 11:46:13,179][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005352] [Batch 01660/03692] [00:15:02/00:18:24, 0.544s/it]: train_loss_raw=2.1743, running_loss=2.1501, LR=0.000100
[2025-08-10 11:46:19,815][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005364] [Batch 01672/03692] [00:15:09/00:18:18, 0.544s/it]: train_loss_raw=2.1434, running_loss=2.1521, LR=0.000100
[2025-08-10 11:46:26,306][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005376] [Batch 01684/03692] [00:15:15/00:18:11, 0.544s/it]: train_loss_raw=2.1284, running_loss=2.1517, LR=0.000100
[2025-08-10 11:46:32,755][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005388] [Batch 01696/03692] [00:15:21/00:18:05, 0.544s/it]: train_loss_raw=2.1549, running_loss=2.1498, LR=0.000100
[2025-08-10 11:46:39,254][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005400] [Batch 01708/03692] [00:15:28/00:17:58, 0.544s/it]: train_loss_raw=2.1351, running_loss=2.1469, LR=0.000100
[2025-08-10 11:46:45,697][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005412] [Batch 01720/03692] [00:15:34/00:17:51, 0.544s/it]: train_loss_raw=2.1056, running_loss=2.1441, LR=0.000100
[2025-08-10 11:46:52,229][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005424] [Batch 01732/03692] [00:15:41/00:17:45, 0.544s/it]: train_loss_raw=2.0555, running_loss=2.1416, LR=0.000100
[2025-08-10 11:46:58,602][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005436] [Batch 01744/03692] [00:15:47/00:17:38, 0.543s/it]: train_loss_raw=2.0940, running_loss=2.1407, LR=0.000100
[2025-08-10 11:47:05,157][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005448] [Batch 01756/03692] [00:15:54/00:17:32, 0.543s/it]: train_loss_raw=2.2548, running_loss=2.1432, LR=0.000100
[2025-08-10 11:47:11,637][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005460] [Batch 01768/03692] [00:16:00/00:17:25, 0.543s/it]: train_loss_raw=2.1318, running_loss=2.1404, LR=0.000100
[2025-08-10 11:47:18,124][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005472] [Batch 01780/03692] [00:16:07/00:17:19, 0.543s/it]: train_loss_raw=2.1343, running_loss=2.1396, LR=0.000100
[2025-08-10 11:47:24,630][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005484] [Batch 01792/03692] [00:16:13/00:17:12, 0.543s/it]: train_loss_raw=2.2083, running_loss=2.1406, LR=0.000100
[2025-08-10 11:47:31,226][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005496] [Batch 01804/03692] [00:16:20/00:17:06, 0.543s/it]: train_loss_raw=2.1331, running_loss=2.1411, LR=0.000100
[2025-08-10 11:47:37,859][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005508] [Batch 01816/03692] [00:16:27/00:16:59, 0.544s/it]: train_loss_raw=2.1090, running_loss=2.1377, LR=0.000100
[2025-08-10 11:47:44,495][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005520] [Batch 01828/03692] [00:16:33/00:16:53, 0.544s/it]: train_loss_raw=2.2146, running_loss=2.1393, LR=0.000100
[2025-08-10 11:47:51,071][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005532] [Batch 01840/03692] [00:16:40/00:16:46, 0.544s/it]: train_loss_raw=2.1774, running_loss=2.1423, LR=0.000100
[2025-08-10 11:47:57,652][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005544] [Batch 01852/03692] [00:16:46/00:16:40, 0.544s/it]: train_loss_raw=2.0803, running_loss=2.1376, LR=0.000100
[2025-08-10 11:48:04,258][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005556] [Batch 01864/03692] [00:16:53/00:16:33, 0.544s/it]: train_loss_raw=2.0908, running_loss=2.1380, LR=0.000100
[2025-08-10 11:48:10,789][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005568] [Batch 01876/03692] [00:17:00/00:16:27, 0.544s/it]: train_loss_raw=1.9811, running_loss=2.1350, LR=0.000100
[2025-08-10 11:48:17,343][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005580] [Batch 01888/03692] [00:17:06/00:16:20, 0.544s/it]: train_loss_raw=1.9976, running_loss=2.1327, LR=0.000100
[2025-08-10 11:48:23,668][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005592] [Batch 01900/03692] [00:17:12/00:16:14, 0.544s/it]: train_loss_raw=2.1494, running_loss=2.1385, LR=0.000100
[2025-08-10 11:48:30,289][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005604] [Batch 01912/03692] [00:17:19/00:16:07, 0.544s/it]: train_loss_raw=2.1203, running_loss=2.1374, LR=0.000100
[2025-08-10 11:48:36,933][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005616] [Batch 01924/03692] [00:17:26/00:16:01, 0.544s/it]: train_loss_raw=2.0887, running_loss=2.1369, LR=0.000100
[2025-08-10 11:48:43,622][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005628] [Batch 01936/03692] [00:17:32/00:15:54, 0.544s/it]: train_loss_raw=2.1986, running_loss=2.1385, LR=0.000100
[2025-08-10 11:48:50,192][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005640] [Batch 01948/03692] [00:17:39/00:15:48, 0.544s/it]: train_loss_raw=2.1025, running_loss=2.1368, LR=0.000100
[2025-08-10 11:48:56,672][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005652] [Batch 01960/03692] [00:17:45/00:15:41, 0.544s/it]: train_loss_raw=2.2509, running_loss=2.1372, LR=0.000100
[2025-08-10 11:49:03,310][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005664] [Batch 01972/03692] [00:17:52/00:15:35, 0.544s/it]: train_loss_raw=2.1244, running_loss=2.1383, LR=0.000100
[2025-08-10 11:49:09,929][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005676] [Batch 01984/03692] [00:17:59/00:15:29, 0.544s/it]: train_loss_raw=2.0109, running_loss=2.1387, LR=0.000100
[2025-08-10 11:49:16,598][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005688] [Batch 01996/03692] [00:18:05/00:15:22, 0.544s/it]: train_loss_raw=2.0854, running_loss=2.1357, LR=0.000100
[2025-08-10 11:49:23,137][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005700] [Batch 02008/03692] [00:18:12/00:15:16, 0.544s/it]: train_loss_raw=2.1526, running_loss=2.1374, LR=0.000100
[2025-08-10 11:49:29,704][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005712] [Batch 02020/03692] [00:18:18/00:15:09, 0.544s/it]: train_loss_raw=2.0840, running_loss=2.1372, LR=0.000100
[2025-08-10 11:49:36,288][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005724] [Batch 02032/03692] [00:18:25/00:15:03, 0.544s/it]: train_loss_raw=2.0947, running_loss=2.1355, LR=0.000100
[2025-08-10 11:49:42,759][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005736] [Batch 02044/03692] [00:18:31/00:14:56, 0.544s/it]: train_loss_raw=2.0952, running_loss=2.1347, LR=0.000100
[2025-08-10 11:49:49,201][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005748] [Batch 02056/03692] [00:18:38/00:14:49, 0.544s/it]: train_loss_raw=2.0866, running_loss=2.1312, LR=0.000100
[2025-08-10 11:49:55,632][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005760] [Batch 02068/03692] [00:18:44/00:14:43, 0.544s/it]: train_loss_raw=2.0654, running_loss=2.1279, LR=0.000100
[2025-08-10 11:50:02,071][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005772] [Batch 02080/03692] [00:18:51/00:14:36, 0.544s/it]: train_loss_raw=2.0863, running_loss=2.1270, LR=0.000100
[2025-08-10 11:50:08,517][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005784] [Batch 02092/03692] [00:18:57/00:14:30, 0.544s/it]: train_loss_raw=2.0723, running_loss=2.1246, LR=0.000100
[2025-08-10 11:50:14,945][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005796] [Batch 02104/03692] [00:19:04/00:14:23, 0.544s/it]: train_loss_raw=2.1995, running_loss=2.1274, LR=0.000100
[2025-08-10 11:50:21,583][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005808] [Batch 02116/03692] [00:19:10/00:14:17, 0.544s/it]: train_loss_raw=2.0884, running_loss=2.1280, LR=0.000100
[2025-08-10 11:50:28,183][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005820] [Batch 02128/03692] [00:19:17/00:14:10, 0.544s/it]: train_loss_raw=1.9796, running_loss=2.1254, LR=0.000100
[2025-08-10 11:50:34,755][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005832] [Batch 02140/03692] [00:19:23/00:14:04, 0.544s/it]: train_loss_raw=2.1008, running_loss=2.1238, LR=0.000100
[2025-08-10 11:50:41,246][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005844] [Batch 02152/03692] [00:19:30/00:13:57, 0.544s/it]: train_loss_raw=2.1808, running_loss=2.1247, LR=0.000100
[2025-08-10 11:50:54,646][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005856] [Batch 02164/03692] [00:19:43/00:13:55, 0.547s/it]: train_loss_raw=2.1925, running_loss=2.1252, LR=0.000100
[2025-08-10 11:51:00,894][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005868] [Batch 02176/03692] [00:19:50/00:13:49, 0.547s/it]: train_loss_raw=2.0723, running_loss=2.1212, LR=0.000100
[2025-08-10 11:51:07,193][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005880] [Batch 02188/03692] [00:19:56/00:13:42, 0.547s/it]: train_loss_raw=2.1586, running_loss=2.1195, LR=0.000100
[2025-08-10 11:51:13,643][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005892] [Batch 02200/03692] [00:20:02/00:13:35, 0.547s/it]: train_loss_raw=2.1320, running_loss=2.1162, LR=0.000100
[2025-08-10 11:51:20,258][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005904] [Batch 02212/03692] [00:20:09/00:13:29, 0.547s/it]: train_loss_raw=2.2011, running_loss=2.1163, LR=0.000100
[2025-08-10 11:51:26,749][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005916] [Batch 02224/03692] [00:20:15/00:13:22, 0.547s/it]: train_loss_raw=2.1763, running_loss=2.1157, LR=0.000100
[2025-08-10 11:51:33,363][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005928] [Batch 02236/03692] [00:20:22/00:13:16, 0.547s/it]: train_loss_raw=2.1753, running_loss=2.1170, LR=0.000100
[2025-08-10 11:51:39,960][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005940] [Batch 02248/03692] [00:20:29/00:13:09, 0.547s/it]: train_loss_raw=2.0531, running_loss=2.1167, LR=0.000100
[2025-08-10 11:51:46,592][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005952] [Batch 02260/03692] [00:20:35/00:13:03, 0.547s/it]: train_loss_raw=2.1258, running_loss=2.1150, LR=0.000100
[2025-08-10 11:51:53,208][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005964] [Batch 02272/03692] [00:20:42/00:12:56, 0.547s/it]: train_loss_raw=2.0930, running_loss=2.1169, LR=0.000100
[2025-08-10 11:51:59,776][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005976] [Batch 02284/03692] [00:20:48/00:12:49, 0.547s/it]: train_loss_raw=2.0447, running_loss=2.1133, LR=0.000100
[2025-08-10 11:52:06,392][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005988] [Batch 02296/03692] [00:20:55/00:12:43, 0.547s/it]: train_loss_raw=1.9861, running_loss=2.1115, LR=0.000100
[2025-08-10 11:52:12,996][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006000] [Batch 02308/03692] [00:21:02/00:12:36, 0.547s/it]: train_loss_raw=2.0973, running_loss=2.1097, LR=0.000100
[2025-08-10 11:52:25,009][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006012] [Batch 02320/03692] [00:21:14/00:12:33, 0.549s/it]: train_loss_raw=2.1658, running_loss=2.1083, LR=0.000100
[2025-08-10 11:52:31,654][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006024] [Batch 02332/03692] [00:21:20/00:12:26, 0.549s/it]: train_loss_raw=2.1899, running_loss=2.1068, LR=0.000100
[2025-08-10 11:52:38,234][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006036] [Batch 02344/03692] [00:21:27/00:12:20, 0.549s/it]: train_loss_raw=1.9563, running_loss=2.1038, LR=0.000100
[2025-08-10 11:52:44,903][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006048] [Batch 02356/03692] [00:21:34/00:12:13, 0.549s/it]: train_loss_raw=2.0676, running_loss=2.1039, LR=0.000100
[2025-08-10 11:52:51,465][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006060] [Batch 02368/03692] [00:21:40/00:12:07, 0.549s/it]: train_loss_raw=2.1608, running_loss=2.1048, LR=0.000100
[2025-08-10 11:52:58,087][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006072] [Batch 02380/03692] [00:21:47/00:12:00, 0.549s/it]: train_loss_raw=2.0698, running_loss=2.1033, LR=0.000100
[2025-08-10 11:53:04,717][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006084] [Batch 02392/03692] [00:21:53/00:11:54, 0.549s/it]: train_loss_raw=2.1716, running_loss=2.1025, LR=0.000100
[2025-08-10 11:53:11,311][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006096] [Batch 02404/03692] [00:22:00/00:11:47, 0.549s/it]: train_loss_raw=2.1306, running_loss=2.1023, LR=0.000100
[2025-08-10 11:53:17,829][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006108] [Batch 02416/03692] [00:22:07/00:11:40, 0.549s/it]: train_loss_raw=2.0745, running_loss=2.0981, LR=0.000100
[2025-08-10 11:53:24,337][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006120] [Batch 02428/03692] [00:22:13/00:11:34, 0.549s/it]: train_loss_raw=2.0632, running_loss=2.0963, LR=0.000100
[2025-08-10 11:53:30,775][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006132] [Batch 02440/03692] [00:22:19/00:11:27, 0.549s/it]: train_loss_raw=2.1246, running_loss=2.0976, LR=0.000100
[2025-08-10 11:53:37,321][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006144] [Batch 02452/03692] [00:22:26/00:11:20, 0.549s/it]: train_loss_raw=1.9618, running_loss=2.0977, LR=0.000100
[2025-08-10 11:53:43,887][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006156] [Batch 02464/03692] [00:22:33/00:11:14, 0.549s/it]: train_loss_raw=2.0640, running_loss=2.1003, LR=0.000100
[2025-08-10 11:53:50,544][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006168] [Batch 02476/03692] [00:22:39/00:11:07, 0.549s/it]: train_loss_raw=2.1315, running_loss=2.0957, LR=0.000100
[2025-08-10 11:53:57,020][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006180] [Batch 02488/03692] [00:22:46/00:11:01, 0.549s/it]: train_loss_raw=2.0711, running_loss=2.0948, LR=0.000100
[2025-08-10 11:54:03,451][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006192] [Batch 02500/03692] [00:22:52/00:10:54, 0.549s/it]: train_loss_raw=2.1916, running_loss=2.0963, LR=0.000100
[2025-08-10 11:54:09,950][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006204] [Batch 02512/03692] [00:22:59/00:10:47, 0.549s/it]: train_loss_raw=2.1444, running_loss=2.0974, LR=0.000100
[2025-08-10 11:54:16,388][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006216] [Batch 02524/03692] [00:23:05/00:10:41, 0.549s/it]: train_loss_raw=2.0335, running_loss=2.0977, LR=0.000100
[2025-08-10 11:54:22,862][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006228] [Batch 02536/03692] [00:23:12/00:10:34, 0.549s/it]: train_loss_raw=2.0138, running_loss=2.0995, LR=0.000100
[2025-08-10 11:54:29,385][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006240] [Batch 02548/03692] [00:23:18/00:10:27, 0.549s/it]: train_loss_raw=2.1077, running_loss=2.0984, LR=0.000100
[2025-08-10 11:54:36,055][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006252] [Batch 02560/03692] [00:23:25/00:10:21, 0.549s/it]: train_loss_raw=2.1262, running_loss=2.0972, LR=0.000100
[2025-08-10 11:54:42,672][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006264] [Batch 02572/03692] [00:23:31/00:10:14, 0.549s/it]: train_loss_raw=2.0586, running_loss=2.0934, LR=0.000100
[2025-08-10 11:54:49,367][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006276] [Batch 02584/03692] [00:23:38/00:10:08, 0.549s/it]: train_loss_raw=2.0388, running_loss=2.0897, LR=0.000100
[2025-08-10 11:54:55,944][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006288] [Batch 02596/03692] [00:23:45/00:10:01, 0.549s/it]: train_loss_raw=2.0370, running_loss=2.0870, LR=0.000100
[2025-08-10 11:55:02,592][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006300] [Batch 02608/03692] [00:23:51/00:09:55, 0.549s/it]: train_loss_raw=2.0618, running_loss=2.0864, LR=0.000100
[2025-08-10 11:55:09,292][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006312] [Batch 02620/03692] [00:23:58/00:09:48, 0.549s/it]: train_loss_raw=2.1631, running_loss=2.0874, LR=0.000100
[2025-08-10 11:55:15,987][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006324] [Batch 02632/03692] [00:24:05/00:09:42, 0.549s/it]: train_loss_raw=2.0311, running_loss=2.0846, LR=0.000100
[2025-08-10 11:55:22,671][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006336] [Batch 02644/03692] [00:24:11/00:09:35, 0.549s/it]: train_loss_raw=2.0502, running_loss=2.0843, LR=0.000100
[2025-08-10 11:55:29,226][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006348] [Batch 02656/03692] [00:24:18/00:09:28, 0.549s/it]: train_loss_raw=2.0227, running_loss=2.0824, LR=0.000100
[2025-08-10 11:55:35,527][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006360] [Batch 02668/03692] [00:24:24/00:09:22, 0.549s/it]: train_loss_raw=2.0663, running_loss=2.0836, LR=0.000100
[2025-08-10 11:55:41,942][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006372] [Batch 02680/03692] [00:24:31/00:09:15, 0.549s/it]: train_loss_raw=2.1080, running_loss=2.0851, LR=0.000100
[2025-08-10 11:55:48,089][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006384] [Batch 02692/03692] [00:24:37/00:09:08, 0.549s/it]: train_loss_raw=2.0843, running_loss=2.0842, LR=0.000100
[2025-08-10 11:55:54,504][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006396] [Batch 02704/03692] [00:24:43/00:09:02, 0.549s/it]: train_loss_raw=2.0971, running_loss=2.0831, LR=0.000100
[2025-08-10 11:56:01,047][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006408] [Batch 02716/03692] [00:24:50/00:08:55, 0.549s/it]: train_loss_raw=2.0362, running_loss=2.0822, LR=0.000100
[2025-08-10 11:56:07,698][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006420] [Batch 02728/03692] [00:24:56/00:08:48, 0.549s/it]: train_loss_raw=2.0801, running_loss=2.0849, LR=0.000100
[2025-08-10 11:56:14,347][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006432] [Batch 02740/03692] [00:25:03/00:08:42, 0.549s/it]: train_loss_raw=1.9970, running_loss=2.0830, LR=0.000100
[2025-08-10 11:56:20,971][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006444] [Batch 02752/03692] [00:25:10/00:08:35, 0.549s/it]: train_loss_raw=2.0256, running_loss=2.0836, LR=0.000100
[2025-08-10 11:56:27,621][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006456] [Batch 02764/03692] [00:25:16/00:08:29, 0.549s/it]: train_loss_raw=2.1038, running_loss=2.0852, LR=0.000100
[2025-08-10 11:56:34,204][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006468] [Batch 02776/03692] [00:25:23/00:08:22, 0.549s/it]: train_loss_raw=2.0485, running_loss=2.0845, LR=0.000100
[2025-08-10 11:56:40,824][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006480] [Batch 02788/03692] [00:25:30/00:08:16, 0.549s/it]: train_loss_raw=2.0226, running_loss=2.0826, LR=0.000100
[2025-08-10 11:56:47,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006492] [Batch 02800/03692] [00:25:36/00:08:09, 0.549s/it]: train_loss_raw=2.0626, running_loss=2.0800, LR=0.000100
[2025-08-10 11:56:53,863][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006504] [Batch 02812/03692] [00:25:43/00:08:02, 0.549s/it]: train_loss_raw=2.1051, running_loss=2.0822, LR=0.000100
[2025-08-10 11:57:00,452][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006516] [Batch 02824/03692] [00:25:49/00:07:56, 0.549s/it]: train_loss_raw=2.1224, running_loss=2.0815, LR=0.000100
[2025-08-10 11:57:07,068][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006528] [Batch 02836/03692] [00:25:56/00:07:49, 0.549s/it]: train_loss_raw=2.1544, running_loss=2.0867, LR=0.000100
[2025-08-10 11:57:13,687][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006540] [Batch 02848/03692] [00:26:02/00:07:43, 0.549s/it]: train_loss_raw=2.0490, running_loss=2.0877, LR=0.000100
[2025-08-10 11:57:20,300][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006552] [Batch 02860/03692] [00:26:09/00:07:36, 0.549s/it]: train_loss_raw=2.1425, running_loss=2.0897, LR=0.000100
[2025-08-10 11:57:26,897][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006564] [Batch 02872/03692] [00:26:16/00:07:30, 0.549s/it]: train_loss_raw=2.0508, running_loss=2.0885, LR=0.000100
[2025-08-10 11:57:33,509][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006576] [Batch 02884/03692] [00:26:22/00:07:23, 0.549s/it]: train_loss_raw=2.0440, running_loss=2.0870, LR=0.000100
[2025-08-10 11:57:40,164][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006588] [Batch 02896/03692] [00:26:29/00:07:16, 0.549s/it]: train_loss_raw=2.0298, running_loss=2.0854, LR=0.000100
[2025-08-10 11:57:46,753][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006600] [Batch 02908/03692] [00:26:35/00:07:10, 0.549s/it]: train_loss_raw=2.0336, running_loss=2.0832, LR=0.000100
[2025-08-10 11:57:53,383][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006612] [Batch 02920/03692] [00:26:42/00:07:03, 0.549s/it]: train_loss_raw=1.9977, running_loss=2.0826, LR=0.000100
[2025-08-10 11:57:59,978][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006624] [Batch 02932/03692] [00:26:49/00:06:57, 0.549s/it]: train_loss_raw=2.0461, running_loss=2.0804, LR=0.000100
[2025-08-10 11:58:06,567][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006636] [Batch 02944/03692] [00:26:55/00:06:50, 0.549s/it]: train_loss_raw=2.0765, running_loss=2.0824, LR=0.000100
[2025-08-10 11:58:13,081][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006648] [Batch 02956/03692] [00:27:02/00:06:43, 0.549s/it]: train_loss_raw=2.1012, running_loss=2.0808, LR=0.000100
[2025-08-10 11:58:19,523][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006660] [Batch 02968/03692] [00:27:08/00:06:37, 0.549s/it]: train_loss_raw=1.9974, running_loss=2.0806, LR=0.000100
[2025-08-10 11:58:26,042][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006672] [Batch 02980/03692] [00:27:15/00:06:30, 0.549s/it]: train_loss_raw=2.0524, running_loss=2.0834, LR=0.000100
[2025-08-10 11:58:32,592][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006684] [Batch 02992/03692] [00:27:21/00:06:24, 0.549s/it]: train_loss_raw=2.0780, running_loss=2.0809, LR=0.000100
[2025-08-10 11:58:39,023][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006696] [Batch 03004/03692] [00:27:28/00:06:17, 0.549s/it]: train_loss_raw=2.0360, running_loss=2.0783, LR=0.000100
[2025-08-10 11:58:45,467][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006708] [Batch 03016/03692] [00:27:34/00:06:10, 0.549s/it]: train_loss_raw=2.0088, running_loss=2.0739, LR=0.000100
[2025-08-10 11:58:51,790][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006720] [Batch 03028/03692] [00:27:41/00:06:04, 0.549s/it]: train_loss_raw=2.1241, running_loss=2.0714, LR=0.000100
[2025-08-10 11:58:58,142][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006732] [Batch 03040/03692] [00:27:47/00:05:57, 0.548s/it]: train_loss_raw=2.1015, running_loss=2.0676, LR=0.000100
[2025-08-10 11:59:04,668][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006744] [Batch 03052/03692] [00:27:53/00:05:51, 0.548s/it]: train_loss_raw=2.0207, running_loss=2.0699, LR=0.000100
[2025-08-10 11:59:11,209][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006756] [Batch 03064/03692] [00:28:00/00:05:44, 0.548s/it]: train_loss_raw=2.0793, running_loss=2.0687, LR=0.000100
[2025-08-10 11:59:17,782][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006768] [Batch 03076/03692] [00:28:07/00:05:37, 0.548s/it]: train_loss_raw=2.0586, running_loss=2.0720, LR=0.000100
[2025-08-10 11:59:24,369][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006780] [Batch 03088/03692] [00:28:13/00:05:31, 0.548s/it]: train_loss_raw=2.0025, running_loss=2.0731, LR=0.000100
[2025-08-10 11:59:30,986][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006792] [Batch 03100/03692] [00:28:20/00:05:24, 0.548s/it]: train_loss_raw=2.0873, running_loss=2.0730, LR=0.000100
[2025-08-10 11:59:37,630][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006804] [Batch 03112/03692] [00:28:26/00:05:18, 0.548s/it]: train_loss_raw=2.0482, running_loss=2.0760, LR=0.000100
[2025-08-10 11:59:44,192][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006816] [Batch 03124/03692] [00:28:33/00:05:11, 0.548s/it]: train_loss_raw=2.0195, running_loss=2.0761, LR=0.000100
[2025-08-10 11:59:50,835][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006828] [Batch 03136/03692] [00:28:40/00:05:04, 0.548s/it]: train_loss_raw=1.9606, running_loss=2.0717, LR=0.000100
[2025-08-10 11:59:57,445][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006840] [Batch 03148/03692] [00:28:46/00:04:58, 0.548s/it]: train_loss_raw=2.0678, running_loss=2.0705, LR=0.000100
[2025-08-10 12:00:04,061][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006852] [Batch 03160/03692] [00:28:53/00:04:51, 0.549s/it]: train_loss_raw=1.9569, running_loss=2.0702, LR=0.000100
[2025-08-10 12:00:10,671][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006864] [Batch 03172/03692] [00:28:59/00:04:45, 0.549s/it]: train_loss_raw=2.1292, running_loss=2.0714, LR=0.000100
[2025-08-10 12:00:17,400][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006876] [Batch 03184/03692] [00:29:06/00:04:38, 0.549s/it]: train_loss_raw=2.0461, running_loss=2.0715, LR=0.000100
[2025-08-10 12:00:24,114][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006888] [Batch 03196/03692] [00:29:13/00:04:32, 0.549s/it]: train_loss_raw=2.0311, running_loss=2.0717, LR=0.000100
[2025-08-10 12:00:30,824][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006900] [Batch 03208/03692] [00:29:20/00:04:25, 0.549s/it]: train_loss_raw=2.1934, running_loss=2.0726, LR=0.000100
[2025-08-10 12:00:37,263][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006912] [Batch 03220/03692] [00:29:26/00:04:18, 0.549s/it]: train_loss_raw=2.0930, running_loss=2.0709, LR=0.000100
[2025-08-10 12:00:43,535][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006924] [Batch 03232/03692] [00:29:32/00:04:12, 0.549s/it]: train_loss_raw=2.1746, running_loss=2.0735, LR=0.000100
[2025-08-10 12:00:49,898][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006936] [Batch 03244/03692] [00:29:39/00:04:05, 0.548s/it]: train_loss_raw=2.0328, running_loss=2.0769, LR=0.000100
[2025-08-10 12:00:56,467][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006948] [Batch 03256/03692] [00:29:45/00:03:59, 0.548s/it]: train_loss_raw=2.1470, running_loss=2.0745, LR=0.000100
[2025-08-10 12:01:03,028][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006960] [Batch 03268/03692] [00:29:52/00:03:52, 0.548s/it]: train_loss_raw=2.2224, running_loss=2.0733, LR=0.000100
[2025-08-10 12:01:09,729][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006972] [Batch 03280/03692] [00:29:58/00:03:45, 0.548s/it]: train_loss_raw=2.1731, running_loss=2.0690, LR=0.000100
[2025-08-10 12:01:16,368][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006984] [Batch 03292/03692] [00:30:05/00:03:39, 0.548s/it]: train_loss_raw=2.0809, running_loss=2.0688, LR=0.000100
[2025-08-10 12:01:22,950][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006996] [Batch 03304/03692] [00:30:12/00:03:32, 0.548s/it]: train_loss_raw=1.9694, running_loss=2.0649, LR=0.000100
[2025-08-10 12:01:29,612][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007008] [Batch 03316/03692] [00:30:18/00:03:26, 0.549s/it]: train_loss_raw=2.0033, running_loss=2.0604, LR=0.000100
[2025-08-10 12:01:36,144][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007020] [Batch 03328/03692] [00:30:25/00:03:19, 0.548s/it]: train_loss_raw=2.1132, running_loss=2.0596, LR=0.000100
[2025-08-10 12:01:42,697][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007032] [Batch 03340/03692] [00:30:31/00:03:13, 0.548s/it]: train_loss_raw=2.0190, running_loss=2.0574, LR=0.000100
[2025-08-10 12:01:49,222][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007044] [Batch 03352/03692] [00:30:38/00:03:06, 0.548s/it]: train_loss_raw=2.1397, running_loss=2.0586, LR=0.000100
[2025-08-10 12:01:55,788][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007056] [Batch 03364/03692] [00:30:45/00:02:59, 0.548s/it]: train_loss_raw=2.0348, running_loss=2.0567, LR=0.000100
[2025-08-10 12:02:02,365][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007068] [Batch 03376/03692] [00:30:51/00:02:53, 0.548s/it]: train_loss_raw=2.0314, running_loss=2.0580, LR=0.000100
[2025-08-10 12:02:08,946][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007080] [Batch 03388/03692] [00:30:58/00:02:46, 0.548s/it]: train_loss_raw=2.1123, running_loss=2.0585, LR=0.000100
[2025-08-10 12:02:15,447][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007092] [Batch 03400/03692] [00:31:04/00:02:40, 0.548s/it]: train_loss_raw=2.0534, running_loss=2.0582, LR=0.000100
[2025-08-10 12:02:21,999][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007104] [Batch 03412/03692] [00:31:11/00:02:33, 0.548s/it]: train_loss_raw=2.1112, running_loss=2.0584, LR=0.000100
[2025-08-10 12:02:28,634][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007116] [Batch 03424/03692] [00:31:17/00:02:26, 0.548s/it]: train_loss_raw=1.9293, running_loss=2.0578, LR=0.000100
[2025-08-10 12:02:35,195][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007128] [Batch 03436/03692] [00:31:24/00:02:20, 0.548s/it]: train_loss_raw=2.0859, running_loss=2.0581, LR=0.000100
[2025-08-10 12:02:41,614][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007140] [Batch 03448/03692] [00:31:30/00:02:13, 0.548s/it]: train_loss_raw=2.1160, running_loss=2.0611, LR=0.000100
[2025-08-10 12:02:48,301][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007152] [Batch 03460/03692] [00:31:37/00:02:07, 0.548s/it]: train_loss_raw=2.0310, running_loss=2.0578, LR=0.000100
[2025-08-10 12:02:54,912][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007164] [Batch 03472/03692] [00:31:44/00:02:00, 0.548s/it]: train_loss_raw=2.0949, running_loss=2.0594, LR=0.000100
[2025-08-10 12:03:01,399][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007176] [Batch 03484/03692] [00:31:50/00:01:54, 0.548s/it]: train_loss_raw=1.9795, running_loss=2.0599, LR=0.000100
[2025-08-10 12:03:07,875][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007188] [Batch 03496/03692] [00:31:57/00:01:47, 0.548s/it]: train_loss_raw=2.0505, running_loss=2.0631, LR=0.000100
[2025-08-10 12:03:14,393][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007200] [Batch 03508/03692] [00:32:03/00:01:40, 0.548s/it]: train_loss_raw=2.1040, running_loss=2.0649, LR=0.000100
[2025-08-10 12:03:21,012][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007212] [Batch 03520/03692] [00:32:10/00:01:34, 0.548s/it]: train_loss_raw=2.0168, running_loss=2.0651, LR=0.000100
[2025-08-10 12:03:27,554][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007224] [Batch 03532/03692] [00:32:16/00:01:27, 0.548s/it]: train_loss_raw=2.0497, running_loss=2.0667, LR=0.000100
[2025-08-10 12:03:33,968][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007236] [Batch 03544/03692] [00:32:23/00:01:21, 0.548s/it]: train_loss_raw=2.0290, running_loss=2.0671, LR=0.000100
[2025-08-10 12:03:40,458][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007248] [Batch 03556/03692] [00:32:29/00:01:14, 0.548s/it]: train_loss_raw=2.0697, running_loss=2.0638, LR=0.000100
[2025-08-10 12:03:47,004][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007260] [Batch 03568/03692] [00:32:36/00:01:07, 0.548s/it]: train_loss_raw=2.0147, running_loss=2.0617, LR=0.000100
[2025-08-10 12:03:53,588][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007272] [Batch 03580/03692] [00:32:42/00:01:01, 0.548s/it]: train_loss_raw=2.1407, running_loss=2.0664, LR=0.000100
[2025-08-10 12:04:00,251][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007284] [Batch 03592/03692] [00:32:49/00:00:54, 0.548s/it]: train_loss_raw=1.9329, running_loss=2.0630, LR=0.000100
[2025-08-10 12:04:06,719][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007296] [Batch 03604/03692] [00:32:55/00:00:48, 0.548s/it]: train_loss_raw=2.0118, running_loss=2.0596, LR=0.000100
[2025-08-10 12:04:13,228][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007308] [Batch 03616/03692] [00:33:02/00:00:41, 0.548s/it]: train_loss_raw=2.1177, running_loss=2.0593, LR=0.000100
[2025-08-10 12:04:19,839][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007320] [Batch 03628/03692] [00:33:09/00:00:35, 0.548s/it]: train_loss_raw=2.0708, running_loss=2.0572, LR=0.000100
[2025-08-10 12:04:26,447][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007332] [Batch 03640/03692] [00:33:15/00:00:28, 0.548s/it]: train_loss_raw=2.0972, running_loss=2.0597, LR=0.000100
[2025-08-10 12:04:33,079][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007344] [Batch 03652/03692] [00:33:22/00:00:21, 0.548s/it]: train_loss_raw=2.0464, running_loss=2.0610, LR=0.000100
[2025-08-10 12:04:39,652][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007356] [Batch 03664/03692] [00:33:28/00:00:15, 0.548s/it]: train_loss_raw=1.9411, running_loss=2.0621, LR=0.000100
[2025-08-10 12:04:46,058][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007368] [Batch 03676/03692] [00:33:35/00:00:08, 0.548s/it]: train_loss_raw=2.0658, running_loss=2.0592, LR=0.000100
[2025-08-10 12:04:52,587][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007380] [Batch 03688/03692] [00:33:41/00:00:02, 0.548s/it]: train_loss_raw=2.0442, running_loss=2.0552, LR=0.000100
[2025-08-10 12:05:29,993][__main__][INFO] - [VALIDATION] [Epoch 01/29] Starting validation.
[2025-08-10 12:06:06,212][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 007385] [Batch 00011/00025] [00:00:36/00:00:39, 3.018s/it]
[2025-08-10 12:06:24,994][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 007385] [Batch 00023/00025] [00:00:54/00:00:02, 2.292s/it]
[2025-08-10 12:06:26,181][__main__][INFO] - [VALIDATION] [Epoch 01/29] train_loss=2.05375, valid_loss=2.00863
[2025-08-10 12:06:26,181][__main__][INFO] - [VALIDATION] [Epoch 01/29] Metrics:
[2025-08-10 12:06:26,181][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_er      0.766
[2025-08-10 12:06:26,181][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_prec    0.025
[2025-08-10 12:06:26,181][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_recall  0.025
[2025-08-10 12:06:26,182][__main__][INFO] - [VALIDATION] [Epoch 01/29] - pep_recall 0.000
[2025-08-10 12:06:26,184][__main__][INFO] - [TRAIN] [Epoch 01/29] Epoch complete, total time 01:10:25, remaining time 16:25:55, 00:35:12 per epoch
[2025-08-10 12:06:31,366][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007392] [Batch 00008/03692] [00:00:04/00:30:44, 0.501s/it]: train_loss_raw=2.0491, running_loss=2.0888, LR=0.000100
[2025-08-10 12:06:38,002][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007404] [Batch 00020/03692] [00:00:10/00:32:33, 0.532s/it]: train_loss_raw=1.9665, running_loss=2.0795, LR=0.000100
[2025-08-10 12:06:44,634][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007416] [Batch 00032/03692] [00:00:17/00:32:55, 0.540s/it]: train_loss_raw=2.0322, running_loss=2.0740, LR=0.000100
[2025-08-10 12:06:51,282][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007428] [Batch 00044/03692] [00:00:23/00:33:03, 0.544s/it]: train_loss_raw=2.0311, running_loss=2.0720, LR=0.000100
[2025-08-10 12:06:57,981][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007440] [Batch 00056/03692] [00:00:30/00:33:08, 0.547s/it]: train_loss_raw=2.0324, running_loss=2.0674, LR=0.000100
[2025-08-10 12:07:04,601][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007452] [Batch 00068/03692] [00:00:37/00:33:04, 0.548s/it]: train_loss_raw=2.1161, running_loss=2.0621, LR=0.000100
[2025-08-10 12:07:10,884][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007464] [Batch 00080/03692] [00:00:43/00:32:45, 0.544s/it]: train_loss_raw=2.0939, running_loss=2.0576, LR=0.000100
[2025-08-10 12:07:17,369][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007476] [Batch 00092/03692] [00:00:50/00:32:36, 0.544s/it]: train_loss_raw=2.0567, running_loss=2.0537, LR=0.000100
[2025-08-10 12:07:23,930][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007488] [Batch 00104/03692] [00:00:56/00:32:31, 0.544s/it]: train_loss_raw=2.0200, running_loss=2.0465, LR=0.000100
[2025-08-10 12:07:30,544][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007500] [Batch 00116/03692] [00:01:03/00:32:27, 0.545s/it]: train_loss_raw=2.0086, running_loss=2.0434, LR=0.000100
[2025-08-10 12:07:37,173][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007512] [Batch 00128/03692] [00:01:09/00:32:23, 0.545s/it]: train_loss_raw=1.9943, running_loss=2.0416, LR=0.000100
[2025-08-10 12:07:43,806][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007524] [Batch 00140/03692] [00:01:16/00:32:19, 0.546s/it]: train_loss_raw=2.1383, running_loss=2.0394, LR=0.000100
[2025-08-10 12:07:50,471][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007536] [Batch 00152/03692] [00:01:23/00:32:15, 0.547s/it]: train_loss_raw=2.0972, running_loss=2.0404, LR=0.000100
[2025-08-10 12:07:57,073][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007548] [Batch 00164/03692] [00:01:29/00:32:09, 0.547s/it]: train_loss_raw=2.0528, running_loss=2.0364, LR=0.000100
[2025-08-10 12:08:03,659][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007560] [Batch 00176/03692] [00:01:36/00:32:03, 0.547s/it]: train_loss_raw=2.0955, running_loss=2.0353, LR=0.000100
[2025-08-10 12:08:10,177][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007572] [Batch 00188/03692] [00:01:42/00:31:56, 0.547s/it]: train_loss_raw=1.9126, running_loss=2.0304, LR=0.000100
[2025-08-10 12:08:16,800][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007584] [Batch 00200/03692] [00:01:49/00:31:50, 0.547s/it]: train_loss_raw=1.9532, running_loss=2.0288, LR=0.000100
[2025-08-10 12:08:23,282][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007596] [Batch 00212/03692] [00:01:55/00:31:42, 0.547s/it]: train_loss_raw=2.0935, running_loss=2.0266, LR=0.000100
[2025-08-10 12:08:29,847][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007608] [Batch 00224/03692] [00:02:02/00:31:36, 0.547s/it]: train_loss_raw=2.0225, running_loss=2.0251, LR=0.000100
[2025-08-10 12:08:36,313][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007620] [Batch 00236/03692] [00:02:08/00:31:28, 0.546s/it]: train_loss_raw=2.1717, running_loss=2.0299, LR=0.000100
[2025-08-10 12:08:42,847][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007632] [Batch 00248/03692] [00:02:15/00:31:21, 0.546s/it]: train_loss_raw=2.0309, running_loss=2.0288, LR=0.000100
[2025-08-10 12:08:49,466][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007644] [Batch 00260/03692] [00:02:22/00:31:15, 0.547s/it]: train_loss_raw=2.0560, running_loss=2.0306, LR=0.000100
[2025-08-10 12:08:55,972][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007656] [Batch 00272/03692] [00:02:28/00:31:08, 0.546s/it]: train_loss_raw=1.9360, running_loss=2.0290, LR=0.000100
[2025-08-10 12:09:02,442][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007668] [Batch 00284/03692] [00:02:35/00:31:00, 0.546s/it]: train_loss_raw=2.0260, running_loss=2.0279, LR=0.000100
[2025-08-10 12:09:09,013][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007680] [Batch 00296/03692] [00:02:41/00:30:54, 0.546s/it]: train_loss_raw=2.0601, running_loss=2.0275, LR=0.000100
[2025-08-10 12:09:15,598][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007692] [Batch 00308/03692] [00:02:48/00:30:48, 0.546s/it]: train_loss_raw=2.0211, running_loss=2.0285, LR=0.000100
[2025-08-10 12:09:22,175][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007704] [Batch 00320/03692] [00:02:54/00:30:42, 0.546s/it]: train_loss_raw=2.0633, running_loss=2.0288, LR=0.000100
[2025-08-10 12:09:28,837][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007716] [Batch 00332/03692] [00:03:01/00:30:36, 0.547s/it]: train_loss_raw=1.9447, running_loss=2.0264, LR=0.000100
[2025-08-10 12:09:35,471][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007728] [Batch 00344/03692] [00:03:08/00:30:30, 0.547s/it]: train_loss_raw=1.9980, running_loss=2.0252, LR=0.000100
[2025-08-10 12:09:41,739][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007740] [Batch 00356/03692] [00:03:14/00:30:21, 0.546s/it]: train_loss_raw=2.0211, running_loss=2.0215, LR=0.000100
[2025-08-10 12:09:48,056][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007752] [Batch 00368/03692] [00:03:20/00:30:12, 0.545s/it]: train_loss_raw=2.0678, running_loss=2.0194, LR=0.000100
[2025-08-10 12:09:54,363][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007764] [Batch 00380/03692] [00:03:27/00:30:04, 0.545s/it]: train_loss_raw=2.1267, running_loss=2.0176, LR=0.000100
[2025-08-10 12:10:00,802][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007776] [Batch 00392/03692] [00:03:33/00:29:56, 0.544s/it]: train_loss_raw=2.0630, running_loss=2.0154, LR=0.000100
[2025-08-10 12:10:07,392][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007788] [Batch 00404/03692] [00:03:40/00:29:50, 0.545s/it]: train_loss_raw=1.9641, running_loss=2.0141, LR=0.000100
[2025-08-10 12:10:14,015][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007800] [Batch 00416/03692] [00:03:46/00:29:44, 0.545s/it]: train_loss_raw=1.9635, running_loss=2.0120, LR=0.000100
[2025-08-10 12:10:20,569][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007812] [Batch 00428/03692] [00:03:53/00:29:38, 0.545s/it]: train_loss_raw=2.0721, running_loss=2.0137, LR=0.000100
[2025-08-10 12:10:27,155][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007824] [Batch 00440/03692] [00:03:59/00:29:32, 0.545s/it]: train_loss_raw=1.9774, running_loss=2.0163, LR=0.000100
[2025-08-10 12:10:33,700][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007836] [Batch 00452/03692] [00:04:06/00:29:25, 0.545s/it]: train_loss_raw=1.8559, running_loss=2.0146, LR=0.000100
[2025-08-10 12:10:40,278][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007848] [Batch 00464/03692] [00:04:12/00:29:19, 0.545s/it]: train_loss_raw=1.9943, running_loss=2.0097, LR=0.000100
[2025-08-10 12:10:46,915][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007860] [Batch 00476/03692] [00:04:19/00:29:13, 0.545s/it]: train_loss_raw=2.0609, running_loss=2.0094, LR=0.000100
[2025-08-10 12:10:53,181][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007872] [Batch 00488/03692] [00:04:25/00:29:05, 0.545s/it]: train_loss_raw=2.0457, running_loss=2.0116, LR=0.000100
[2025-08-10 12:10:59,414][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007884] [Batch 00500/03692] [00:04:32/00:28:56, 0.544s/it]: train_loss_raw=1.9669, running_loss=2.0124, LR=0.000100
[2025-08-10 12:11:05,639][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007896] [Batch 00512/03692] [00:04:38/00:28:48, 0.544s/it]: train_loss_raw=1.9926, running_loss=2.0122, LR=0.000100
[2025-08-10 12:11:11,849][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007908] [Batch 00524/03692] [00:04:44/00:28:39, 0.543s/it]: train_loss_raw=2.0287, running_loss=2.0115, LR=0.000100
[2025-08-10 12:11:18,035][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007920] [Batch 00536/03692] [00:04:50/00:28:31, 0.542s/it]: train_loss_raw=1.9475, running_loss=2.0131, LR=0.000100
[2025-08-10 12:11:24,281][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007932] [Batch 00548/03692] [00:04:56/00:28:23, 0.542s/it]: train_loss_raw=2.0524, running_loss=2.0124, LR=0.000100
[2025-08-10 12:11:30,498][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007944] [Batch 00560/03692] [00:05:03/00:28:15, 0.541s/it]: train_loss_raw=2.0830, running_loss=2.0113, LR=0.000100
[2025-08-10 12:11:36,726][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007956] [Batch 00572/03692] [00:05:09/00:28:07, 0.541s/it]: train_loss_raw=1.9740, running_loss=2.0103, LR=0.000100
[2025-08-10 12:11:42,995][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007968] [Batch 00584/03692] [00:05:15/00:27:59, 0.540s/it]: train_loss_raw=1.9443, running_loss=2.0097, LR=0.000100
[2025-08-10 12:11:49,251][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007980] [Batch 00596/03692] [00:05:21/00:27:52, 0.540s/it]: train_loss_raw=2.0395, running_loss=2.0121, LR=0.000100
[2025-08-10 12:11:55,626][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 007992] [Batch 00608/03692] [00:05:28/00:27:45, 0.540s/it]: train_loss_raw=1.9544, running_loss=2.0094, LR=0.000100
[2025-08-10 12:12:06,965][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008004] [Batch 00620/03692] [00:05:39/00:28:02, 0.548s/it]: train_loss_raw=2.0528, running_loss=2.0105, LR=0.000100
[2025-08-10 12:12:13,447][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008016] [Batch 00632/03692] [00:05:46/00:27:55, 0.548s/it]: train_loss_raw=1.9997, running_loss=2.0113, LR=0.000100
[2025-08-10 12:12:20,061][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008028] [Batch 00644/03692] [00:05:52/00:27:49, 0.548s/it]: train_loss_raw=2.0864, running_loss=2.0092, LR=0.000100
[2025-08-10 12:12:26,653][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008040] [Batch 00656/03692] [00:05:59/00:27:42, 0.548s/it]: train_loss_raw=2.1540, running_loss=2.0115, LR=0.000100
[2025-08-10 12:12:33,010][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008052] [Batch 00668/03692] [00:06:05/00:27:35, 0.547s/it]: train_loss_raw=1.9745, running_loss=2.0099, LR=0.000100
[2025-08-10 12:12:39,517][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008064] [Batch 00680/03692] [00:06:12/00:27:28, 0.547s/it]: train_loss_raw=2.0494, running_loss=2.0104, LR=0.000100
[2025-08-10 12:12:46,047][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008076] [Batch 00692/03692] [00:06:18/00:27:21, 0.547s/it]: train_loss_raw=2.0483, running_loss=2.0122, LR=0.000100
[2025-08-10 12:12:52,658][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008088] [Batch 00704/03692] [00:06:25/00:27:15, 0.547s/it]: train_loss_raw=1.9934, running_loss=2.0107, LR=0.000100
[2025-08-10 12:12:59,230][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008100] [Batch 00716/03692] [00:06:31/00:27:08, 0.547s/it]: train_loss_raw=2.0073, running_loss=2.0129, LR=0.000100
[2025-08-10 12:13:05,527][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008112] [Batch 00728/03692] [00:06:38/00:27:01, 0.547s/it]: train_loss_raw=2.0845, running_loss=2.0151, LR=0.000100
[2025-08-10 12:13:11,715][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008124] [Batch 00740/03692] [00:06:44/00:26:53, 0.546s/it]: train_loss_raw=2.0530, running_loss=2.0158, LR=0.000100
[2025-08-10 12:13:17,948][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008136] [Batch 00752/03692] [00:06:50/00:26:45, 0.546s/it]: train_loss_raw=2.1592, running_loss=2.0159, LR=0.000100
[2025-08-10 12:13:24,531][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008148] [Batch 00764/03692] [00:06:57/00:26:38, 0.546s/it]: train_loss_raw=1.9646, running_loss=2.0146, LR=0.000100
[2025-08-10 12:13:31,131][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008160] [Batch 00776/03692] [00:07:03/00:26:32, 0.546s/it]: train_loss_raw=1.9931, running_loss=2.0117, LR=0.000100
[2025-08-10 12:13:37,624][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008172] [Batch 00788/03692] [00:07:10/00:26:25, 0.546s/it]: train_loss_raw=2.0210, running_loss=2.0139, LR=0.000100
[2025-08-10 12:13:44,142][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008184] [Batch 00800/03692] [00:07:16/00:26:18, 0.546s/it]: train_loss_raw=2.0774, running_loss=2.0124, LR=0.000100
[2025-08-10 12:13:50,685][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008196] [Batch 00812/03692] [00:07:23/00:26:12, 0.546s/it]: train_loss_raw=2.0687, running_loss=2.0132, LR=0.000100
[2025-08-10 12:13:57,231][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008208] [Batch 00824/03692] [00:07:29/00:26:05, 0.546s/it]: train_loss_raw=1.9638, running_loss=2.0118, LR=0.000100
[2025-08-10 12:14:03,736][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008220] [Batch 00836/03692] [00:07:36/00:25:59, 0.546s/it]: train_loss_raw=1.9920, running_loss=2.0111, LR=0.000100
[2025-08-10 12:14:10,296][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008232] [Batch 00848/03692] [00:07:42/00:25:52, 0.546s/it]: train_loss_raw=2.0213, running_loss=2.0128, LR=0.000100
[2025-08-10 12:14:16,888][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008244] [Batch 00860/03692] [00:07:49/00:25:46, 0.546s/it]: train_loss_raw=1.8284, running_loss=2.0077, LR=0.000100
[2025-08-10 12:14:23,564][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008256] [Batch 00872/03692] [00:07:56/00:25:40, 0.546s/it]: train_loss_raw=1.9789, running_loss=2.0098, LR=0.000100
[2025-08-10 12:14:30,096][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008268] [Batch 00884/03692] [00:08:02/00:25:33, 0.546s/it]: train_loss_raw=2.0487, running_loss=2.0065, LR=0.000100
[2025-08-10 12:14:36,596][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008280] [Batch 00896/03692] [00:08:09/00:25:26, 0.546s/it]: train_loss_raw=2.0755, running_loss=2.0070, LR=0.000100
[2025-08-10 12:14:43,114][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008292] [Batch 00908/03692] [00:08:15/00:25:20, 0.546s/it]: train_loss_raw=1.9931, running_loss=2.0073, LR=0.000100
[2025-08-10 12:14:49,631][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008304] [Batch 00920/03692] [00:08:22/00:25:13, 0.546s/it]: train_loss_raw=1.9564, running_loss=2.0104, LR=0.000100
[2025-08-10 12:14:56,244][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008316] [Batch 00932/03692] [00:08:28/00:25:06, 0.546s/it]: train_loss_raw=2.0349, running_loss=2.0079, LR=0.000100
[2025-08-10 12:15:02,808][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008328] [Batch 00944/03692] [00:08:35/00:25:00, 0.546s/it]: train_loss_raw=2.0902, running_loss=2.0047, LR=0.000100
[2025-08-10 12:15:09,352][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008340] [Batch 00956/03692] [00:08:41/00:24:53, 0.546s/it]: train_loss_raw=2.0485, running_loss=2.0062, LR=0.000100
[2025-08-10 12:15:16,031][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008352] [Batch 00968/03692] [00:08:48/00:24:47, 0.546s/it]: train_loss_raw=2.0284, running_loss=2.0067, LR=0.000100
[2025-08-10 12:15:22,588][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008364] [Batch 00980/03692] [00:08:55/00:24:41, 0.546s/it]: train_loss_raw=1.8797, running_loss=2.0060, LR=0.000100
[2025-08-10 12:15:28,990][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008376] [Batch 00992/03692] [00:09:01/00:24:34, 0.546s/it]: train_loss_raw=2.0547, running_loss=2.0056, LR=0.000100
[2025-08-10 12:15:35,481][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008388] [Batch 01004/03692] [00:09:08/00:24:27, 0.546s/it]: train_loss_raw=1.9182, running_loss=2.0047, LR=0.000100
[2025-08-10 12:15:41,922][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008400] [Batch 01016/03692] [00:09:14/00:24:20, 0.546s/it]: train_loss_raw=2.0103, running_loss=2.0015, LR=0.000100
[2025-08-10 12:15:48,404][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008412] [Batch 01028/03692] [00:09:21/00:24:13, 0.546s/it]: train_loss_raw=1.9854, running_loss=2.0001, LR=0.000100
[2025-08-10 12:15:54,969][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008424] [Batch 01040/03692] [00:09:27/00:24:07, 0.546s/it]: train_loss_raw=2.0205, running_loss=1.9992, LR=0.000100
[2025-08-10 12:16:01,418][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008436] [Batch 01052/03692] [00:09:34/00:24:00, 0.546s/it]: train_loss_raw=1.8944, running_loss=1.9964, LR=0.000100
[2025-08-10 12:16:07,878][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008448] [Batch 01064/03692] [00:09:40/00:23:53, 0.546s/it]: train_loss_raw=2.0689, running_loss=1.9968, LR=0.000100
[2025-08-10 12:16:14,313][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008460] [Batch 01076/03692] [00:09:46/00:23:47, 0.545s/it]: train_loss_raw=2.0457, running_loss=1.9999, LR=0.000100
[2025-08-10 12:16:20,783][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008472] [Batch 01088/03692] [00:09:53/00:23:40, 0.545s/it]: train_loss_raw=2.0036, running_loss=1.9973, LR=0.000100
[2025-08-10 12:16:27,211][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008484] [Batch 01100/03692] [00:09:59/00:23:33, 0.545s/it]: train_loss_raw=1.9717, running_loss=1.9998, LR=0.000100
[2025-08-10 12:16:33,625][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008496] [Batch 01112/03692] [00:10:06/00:23:26, 0.545s/it]: train_loss_raw=1.9279, running_loss=1.9979, LR=0.000100
[2025-08-10 12:16:40,114][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008508] [Batch 01124/03692] [00:10:12/00:23:19, 0.545s/it]: train_loss_raw=1.9099, running_loss=1.9968, LR=0.000100
[2025-08-10 12:16:46,576][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008520] [Batch 01136/03692] [00:10:19/00:23:13, 0.545s/it]: train_loss_raw=1.9541, running_loss=1.9944, LR=0.000100
[2025-08-10 12:16:53,027][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008532] [Batch 01148/03692] [00:10:25/00:23:06, 0.545s/it]: train_loss_raw=2.1236, running_loss=1.9979, LR=0.000100
[2025-08-10 12:16:59,473][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008544] [Batch 01160/03692] [00:10:32/00:22:59, 0.545s/it]: train_loss_raw=1.9856, running_loss=1.9979, LR=0.000100
[2025-08-10 12:17:05,874][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008556] [Batch 01172/03692] [00:10:38/00:22:52, 0.545s/it]: train_loss_raw=1.9608, running_loss=1.9991, LR=0.000100
[2025-08-10 12:17:12,359][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008568] [Batch 01184/03692] [00:10:44/00:22:46, 0.545s/it]: train_loss_raw=2.0423, running_loss=2.0004, LR=0.000100
[2025-08-10 12:17:18,811][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008580] [Batch 01196/03692] [00:10:51/00:22:39, 0.545s/it]: train_loss_raw=1.9039, running_loss=1.9963, LR=0.000100
[2025-08-10 12:17:25,265][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008592] [Batch 01208/03692] [00:10:57/00:22:32, 0.545s/it]: train_loss_raw=2.0114, running_loss=1.9922, LR=0.000100
[2025-08-10 12:17:31,632][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008604] [Batch 01220/03692] [00:11:04/00:22:25, 0.544s/it]: train_loss_raw=1.8901, running_loss=1.9903, LR=0.000100
[2025-08-10 12:17:38,114][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008616] [Batch 01232/03692] [00:11:10/00:22:19, 0.544s/it]: train_loss_raw=1.9447, running_loss=1.9910, LR=0.000100
[2025-08-10 12:17:44,664][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008628] [Batch 01244/03692] [00:11:17/00:22:12, 0.544s/it]: train_loss_raw=1.9030, running_loss=1.9905, LR=0.000100
[2025-08-10 12:17:51,237][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008640] [Batch 01256/03692] [00:11:23/00:22:06, 0.544s/it]: train_loss_raw=1.9879, running_loss=1.9933, LR=0.000100
[2025-08-10 12:17:57,850][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008652] [Batch 01268/03692] [00:11:30/00:21:59, 0.545s/it]: train_loss_raw=2.0758, running_loss=1.9951, LR=0.000100
[2025-08-10 12:18:04,294][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008664] [Batch 01280/03692] [00:11:36/00:21:53, 0.544s/it]: train_loss_raw=1.9588, running_loss=1.9948, LR=0.000100
[2025-08-10 12:18:10,803][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008676] [Batch 01292/03692] [00:11:43/00:21:46, 0.544s/it]: train_loss_raw=2.0062, running_loss=1.9961, LR=0.000100
[2025-08-10 12:18:17,402][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008688] [Batch 01304/03692] [00:11:50/00:21:40, 0.545s/it]: train_loss_raw=2.0483, running_loss=1.9972, LR=0.000100
[2025-08-10 12:18:23,982][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008700] [Batch 01316/03692] [00:11:56/00:21:33, 0.545s/it]: train_loss_raw=1.9295, running_loss=1.9956, LR=0.000100
[2025-08-10 12:18:30,583][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008712] [Batch 01328/03692] [00:12:03/00:21:27, 0.545s/it]: train_loss_raw=1.9774, running_loss=1.9943, LR=0.000100
[2025-08-10 12:18:37,171][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008724] [Batch 01340/03692] [00:12:09/00:21:20, 0.545s/it]: train_loss_raw=2.1231, running_loss=1.9947, LR=0.000100
[2025-08-10 12:18:43,700][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008736] [Batch 01352/03692] [00:12:16/00:21:14, 0.545s/it]: train_loss_raw=1.9922, running_loss=1.9988, LR=0.000100
[2025-08-10 12:18:50,268][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008748] [Batch 01364/03692] [00:12:22/00:21:07, 0.545s/it]: train_loss_raw=2.0351, running_loss=2.0009, LR=0.000100
[2025-08-10 12:18:56,763][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008760] [Batch 01376/03692] [00:12:29/00:21:01, 0.545s/it]: train_loss_raw=2.0036, running_loss=1.9996, LR=0.000100
[2025-08-10 12:19:03,098][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008772] [Batch 01388/03692] [00:12:35/00:20:54, 0.544s/it]: train_loss_raw=1.9640, running_loss=1.9991, LR=0.000100
[2025-08-10 12:19:09,659][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008784] [Batch 01400/03692] [00:12:42/00:20:47, 0.544s/it]: train_loss_raw=2.1370, running_loss=1.9979, LR=0.000100
[2025-08-10 12:19:16,260][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008796] [Batch 01412/03692] [00:12:48/00:20:41, 0.545s/it]: train_loss_raw=1.9291, running_loss=1.9950, LR=0.000100
[2025-08-10 12:19:22,841][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008808] [Batch 01424/03692] [00:12:55/00:20:35, 0.545s/it]: train_loss_raw=1.9891, running_loss=1.9939, LR=0.000100
[2025-08-10 12:19:29,472][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008820] [Batch 01436/03692] [00:13:02/00:20:28, 0.545s/it]: train_loss_raw=1.8919, running_loss=1.9964, LR=0.000100
[2025-08-10 12:19:35,995][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008832] [Batch 01448/03692] [00:13:08/00:20:22, 0.545s/it]: train_loss_raw=2.0455, running_loss=1.9958, LR=0.000100
[2025-08-10 12:19:42,532][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008844] [Batch 01460/03692] [00:13:15/00:20:15, 0.545s/it]: train_loss_raw=2.0355, running_loss=1.9949, LR=0.000100
[2025-08-10 12:19:49,182][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008856] [Batch 01472/03692] [00:13:21/00:20:09, 0.545s/it]: train_loss_raw=2.0739, running_loss=1.9955, LR=0.000100
[2025-08-10 12:19:55,760][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008868] [Batch 01484/03692] [00:13:28/00:20:02, 0.545s/it]: train_loss_raw=1.9327, running_loss=1.9958, LR=0.000100
[2025-08-10 12:20:02,257][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008880] [Batch 01496/03692] [00:13:34/00:19:56, 0.545s/it]: train_loss_raw=1.9368, running_loss=1.9943, LR=0.000100
[2025-08-10 12:20:08,861][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008892] [Batch 01508/03692] [00:13:41/00:19:49, 0.545s/it]: train_loss_raw=1.9201, running_loss=1.9924, LR=0.000100
[2025-08-10 12:20:15,290][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008904] [Batch 01520/03692] [00:13:47/00:19:43, 0.545s/it]: train_loss_raw=2.0976, running_loss=1.9899, LR=0.000100
[2025-08-10 12:20:21,719][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008916] [Batch 01532/03692] [00:13:54/00:19:36, 0.545s/it]: train_loss_raw=2.0380, running_loss=1.9901, LR=0.000100
[2025-08-10 12:20:51,458][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008928] [Batch 01544/03692] [00:14:24/00:20:02, 0.560s/it]: train_loss_raw=1.9569, running_loss=1.9868, LR=0.000100
[2025-08-10 12:20:58,114][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008940] [Batch 01556/03692] [00:14:30/00:19:55, 0.560s/it]: train_loss_raw=1.9196, running_loss=1.9894, LR=0.000100
[2025-08-10 12:21:04,606][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008952] [Batch 01568/03692] [00:14:37/00:19:48, 0.559s/it]: train_loss_raw=1.9896, running_loss=1.9904, LR=0.000100
[2025-08-10 12:21:11,095][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008964] [Batch 01580/03692] [00:14:43/00:19:41, 0.559s/it]: train_loss_raw=1.9339, running_loss=1.9931, LR=0.000100
[2025-08-10 12:21:17,666][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008976] [Batch 01592/03692] [00:14:50/00:19:34, 0.559s/it]: train_loss_raw=1.8656, running_loss=1.9931, LR=0.000100
[2025-08-10 12:21:24,241][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 008988] [Batch 01604/03692] [00:14:56/00:19:27, 0.559s/it]: train_loss_raw=1.9619, running_loss=1.9939, LR=0.000100
[2025-08-10 12:21:30,817][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009000] [Batch 01616/03692] [00:15:03/00:19:20, 0.559s/it]: train_loss_raw=1.9777, running_loss=1.9965, LR=0.000100
[2025-08-10 12:21:37,438][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009012] [Batch 01628/03692] [00:15:10/00:19:13, 0.559s/it]: train_loss_raw=1.8479, running_loss=1.9890, LR=0.000100
[2025-08-10 12:21:44,068][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009024] [Batch 01640/03692] [00:15:16/00:19:07, 0.559s/it]: train_loss_raw=1.9411, running_loss=1.9906, LR=0.000100
[2025-08-10 12:21:50,615][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009036] [Batch 01652/03692] [00:15:23/00:19:00, 0.559s/it]: train_loss_raw=1.9515, running_loss=1.9922, LR=0.000100
[2025-08-10 12:21:57,230][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009048] [Batch 01664/03692] [00:15:29/00:18:53, 0.559s/it]: train_loss_raw=1.9523, running_loss=1.9924, LR=0.000100
[2025-08-10 12:22:03,718][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009060] [Batch 01676/03692] [00:15:36/00:18:46, 0.559s/it]: train_loss_raw=1.9350, running_loss=1.9910, LR=0.000100
[2025-08-10 12:22:10,208][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009072] [Batch 01688/03692] [00:15:42/00:18:39, 0.559s/it]: train_loss_raw=2.0571, running_loss=1.9929, LR=0.000100
[2025-08-10 12:22:16,610][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009084] [Batch 01700/03692] [00:15:49/00:18:32, 0.558s/it]: train_loss_raw=2.0756, running_loss=1.9901, LR=0.000100
[2025-08-10 12:22:23,015][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009096] [Batch 01712/03692] [00:15:55/00:18:25, 0.558s/it]: train_loss_raw=1.9437, running_loss=1.9888, LR=0.000100
[2025-08-10 12:22:29,518][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009108] [Batch 01724/03692] [00:16:02/00:18:18, 0.558s/it]: train_loss_raw=2.0463, running_loss=1.9928, LR=0.000100
[2025-08-10 12:22:36,009][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009120] [Batch 01736/03692] [00:16:08/00:18:11, 0.558s/it]: train_loss_raw=2.0085, running_loss=1.9932, LR=0.000100
[2025-08-10 12:22:42,444][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009132] [Batch 01748/03692] [00:16:15/00:18:04, 0.558s/it]: train_loss_raw=2.0601, running_loss=1.9924, LR=0.000100
[2025-08-10 12:22:48,862][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009144] [Batch 01760/03692] [00:16:21/00:17:57, 0.558s/it]: train_loss_raw=1.9652, running_loss=1.9910, LR=0.000100
[2025-08-10 12:22:55,435][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009156] [Batch 01772/03692] [00:16:28/00:17:50, 0.558s/it]: train_loss_raw=1.8923, running_loss=1.9873, LR=0.000100
[2025-08-10 12:23:02,117][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009168] [Batch 01784/03692] [00:16:34/00:17:43, 0.558s/it]: train_loss_raw=1.9565, running_loss=1.9866, LR=0.000100
[2025-08-10 12:23:08,557][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009180] [Batch 01796/03692] [00:16:41/00:17:36, 0.557s/it]: train_loss_raw=2.0044, running_loss=1.9867, LR=0.000100
[2025-08-10 12:23:15,044][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009192] [Batch 01808/03692] [00:16:47/00:17:30, 0.557s/it]: train_loss_raw=1.9051, running_loss=1.9857, LR=0.000100
[2025-08-10 12:23:21,488][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009204] [Batch 01820/03692] [00:16:54/00:17:23, 0.557s/it]: train_loss_raw=1.9069, running_loss=1.9839, LR=0.000100
[2025-08-10 12:23:28,022][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009216] [Batch 01832/03692] [00:17:00/00:17:16, 0.557s/it]: train_loss_raw=2.0677, running_loss=1.9861, LR=0.000100
[2025-08-10 12:23:34,669][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009228] [Batch 01844/03692] [00:17:07/00:17:09, 0.557s/it]: train_loss_raw=1.9312, running_loss=1.9857, LR=0.000100
[2025-08-10 12:23:41,152][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009240] [Batch 01856/03692] [00:17:13/00:17:02, 0.557s/it]: train_loss_raw=1.9994, running_loss=1.9846, LR=0.000100
[2025-08-10 12:23:47,619][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009252] [Batch 01868/03692] [00:17:20/00:16:55, 0.557s/it]: train_loss_raw=2.0080, running_loss=1.9870, LR=0.000100
[2025-08-10 12:23:54,128][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009264] [Batch 01880/03692] [00:17:26/00:16:48, 0.557s/it]: train_loss_raw=1.9807, running_loss=1.9885, LR=0.000100
[2025-08-10 12:24:00,551][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009276] [Batch 01892/03692] [00:17:33/00:16:41, 0.557s/it]: train_loss_raw=1.9729, running_loss=1.9881, LR=0.000100
[2025-08-10 12:24:07,102][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009288] [Batch 01904/03692] [00:17:39/00:16:35, 0.557s/it]: train_loss_raw=1.9211, running_loss=1.9856, LR=0.000100
[2025-08-10 12:24:13,631][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009300] [Batch 01916/03692] [00:17:46/00:16:28, 0.557s/it]: train_loss_raw=2.1047, running_loss=1.9853, LR=0.000100
[2025-08-10 12:24:20,144][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009312] [Batch 01928/03692] [00:17:52/00:16:21, 0.556s/it]: train_loss_raw=1.9986, running_loss=1.9828, LR=0.000100
[2025-08-10 12:24:26,652][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009324] [Batch 01940/03692] [00:17:59/00:16:14, 0.556s/it]: train_loss_raw=1.9792, running_loss=1.9841, LR=0.000100
[2025-08-10 12:24:33,164][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009336] [Batch 01952/03692] [00:18:05/00:16:07, 0.556s/it]: train_loss_raw=1.8564, running_loss=1.9831, LR=0.000100
[2025-08-10 12:24:39,671][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009348] [Batch 01964/03692] [00:18:12/00:16:01, 0.556s/it]: train_loss_raw=1.9965, running_loss=1.9871, LR=0.000100
[2025-08-10 12:24:46,016][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009360] [Batch 01976/03692] [00:18:18/00:15:54, 0.556s/it]: train_loss_raw=2.0237, running_loss=1.9831, LR=0.000100
[2025-08-10 12:24:52,592][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009372] [Batch 01988/03692] [00:18:25/00:15:47, 0.556s/it]: train_loss_raw=2.0235, running_loss=1.9830, LR=0.000100
[2025-08-10 12:24:59,181][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009384] [Batch 02000/03692] [00:18:31/00:15:40, 0.556s/it]: train_loss_raw=1.9604, running_loss=1.9800, LR=0.000100
[2025-08-10 12:25:05,773][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009396] [Batch 02012/03692] [00:18:38/00:15:33, 0.556s/it]: train_loss_raw=1.9196, running_loss=1.9809, LR=0.000100
[2025-08-10 12:25:12,288][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009408] [Batch 02024/03692] [00:18:44/00:15:27, 0.556s/it]: train_loss_raw=1.9959, running_loss=1.9818, LR=0.000100
[2025-08-10 12:25:18,755][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009420] [Batch 02036/03692] [00:18:51/00:15:20, 0.556s/it]: train_loss_raw=2.1036, running_loss=1.9813, LR=0.000100
[2025-08-10 12:25:25,201][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009432] [Batch 02048/03692] [00:18:57/00:15:13, 0.556s/it]: train_loss_raw=1.9641, running_loss=1.9805, LR=0.000100
[2025-08-10 12:25:31,678][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009444] [Batch 02060/03692] [00:19:04/00:15:06, 0.555s/it]: train_loss_raw=1.9846, running_loss=1.9788, LR=0.000100
[2025-08-10 12:25:38,155][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009456] [Batch 02072/03692] [00:19:10/00:14:59, 0.555s/it]: train_loss_raw=1.9130, running_loss=1.9768, LR=0.000100
[2025-08-10 12:25:44,658][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009468] [Batch 02084/03692] [00:19:17/00:14:52, 0.555s/it]: train_loss_raw=1.9716, running_loss=1.9762, LR=0.000100
[2025-08-10 12:25:51,134][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009480] [Batch 02096/03692] [00:19:23/00:14:46, 0.555s/it]: train_loss_raw=2.0556, running_loss=1.9782, LR=0.000100
[2025-08-10 12:25:57,627][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009492] [Batch 02108/03692] [00:19:30/00:14:39, 0.555s/it]: train_loss_raw=1.9908, running_loss=1.9735, LR=0.000100
[2025-08-10 12:26:04,042][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009504] [Batch 02120/03692] [00:19:36/00:14:32, 0.555s/it]: train_loss_raw=1.9544, running_loss=1.9713, LR=0.000100
[2025-08-10 12:26:10,489][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009516] [Batch 02132/03692] [00:19:43/00:14:25, 0.555s/it]: train_loss_raw=1.9803, running_loss=1.9714, LR=0.000100
[2025-08-10 12:26:16,905][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009528] [Batch 02144/03692] [00:19:49/00:14:18, 0.555s/it]: train_loss_raw=2.0540, running_loss=1.9722, LR=0.000100
[2025-08-10 12:26:23,296][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009540] [Batch 02156/03692] [00:19:55/00:14:12, 0.555s/it]: train_loss_raw=1.9549, running_loss=1.9723, LR=0.000100
[2025-08-10 12:26:29,667][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009552] [Batch 02168/03692] [00:20:02/00:14:05, 0.555s/it]: train_loss_raw=1.8839, running_loss=1.9750, LR=0.000100
[2025-08-10 12:26:36,107][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009564] [Batch 02180/03692] [00:20:08/00:13:58, 0.554s/it]: train_loss_raw=1.8793, running_loss=1.9735, LR=0.000100
[2025-08-10 12:26:42,538][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009576] [Batch 02192/03692] [00:20:15/00:13:51, 0.554s/it]: train_loss_raw=2.0174, running_loss=1.9791, LR=0.000100
[2025-08-10 12:26:48,961][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009588] [Batch 02204/03692] [00:20:21/00:13:44, 0.554s/it]: train_loss_raw=1.9571, running_loss=1.9784, LR=0.000100
[2025-08-10 12:26:55,481][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009600] [Batch 02216/03692] [00:20:28/00:13:38, 0.554s/it]: train_loss_raw=2.0226, running_loss=1.9773, LR=0.000100
[2025-08-10 12:27:02,069][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009612] [Batch 02228/03692] [00:20:34/00:13:31, 0.554s/it]: train_loss_raw=1.9629, running_loss=1.9740, LR=0.000100
[2025-08-10 12:27:08,620][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009624] [Batch 02240/03692] [00:20:41/00:13:24, 0.554s/it]: train_loss_raw=1.9111, running_loss=1.9764, LR=0.000100
[2025-08-10 12:27:15,041][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009636] [Batch 02252/03692] [00:20:47/00:13:17, 0.554s/it]: train_loss_raw=1.9726, running_loss=1.9759, LR=0.000100
[2025-08-10 12:27:21,460][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009648] [Batch 02264/03692] [00:20:54/00:13:11, 0.554s/it]: train_loss_raw=1.9761, running_loss=1.9717, LR=0.000100
[2025-08-10 12:27:27,958][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009660] [Batch 02276/03692] [00:21:00/00:13:04, 0.554s/it]: train_loss_raw=1.9506, running_loss=1.9742, LR=0.000100
[2025-08-10 12:27:34,535][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009672] [Batch 02288/03692] [00:21:07/00:12:57, 0.554s/it]: train_loss_raw=2.0377, running_loss=1.9725, LR=0.000100
[2025-08-10 12:27:41,221][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009684] [Batch 02300/03692] [00:21:13/00:12:50, 0.554s/it]: train_loss_raw=2.0053, running_loss=1.9750, LR=0.000100
[2025-08-10 12:27:47,801][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009696] [Batch 02312/03692] [00:21:20/00:12:44, 0.554s/it]: train_loss_raw=1.9842, running_loss=1.9760, LR=0.000100
[2025-08-10 12:27:54,360][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009708] [Batch 02324/03692] [00:21:26/00:12:37, 0.554s/it]: train_loss_raw=1.9416, running_loss=1.9752, LR=0.000100
[2025-08-10 12:28:00,982][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009720] [Batch 02336/03692] [00:21:33/00:12:30, 0.554s/it]: train_loss_raw=1.9696, running_loss=1.9764, LR=0.000100
[2025-08-10 12:28:07,512][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009732] [Batch 02348/03692] [00:21:40/00:12:24, 0.554s/it]: train_loss_raw=1.9249, running_loss=1.9761, LR=0.000100
[2025-08-10 12:28:13,831][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009744] [Batch 02360/03692] [00:21:46/00:12:17, 0.554s/it]: train_loss_raw=2.0051, running_loss=1.9776, LR=0.000100
[2025-08-10 12:28:20,219][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009756] [Batch 02372/03692] [00:21:52/00:12:10, 0.553s/it]: train_loss_raw=1.9120, running_loss=1.9759, LR=0.000100
[2025-08-10 12:28:26,775][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009768] [Batch 02384/03692] [00:21:59/00:12:03, 0.553s/it]: train_loss_raw=2.0037, running_loss=1.9759, LR=0.000100
[2025-08-10 12:28:33,322][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009780] [Batch 02396/03692] [00:22:05/00:11:57, 0.553s/it]: train_loss_raw=2.0028, running_loss=1.9783, LR=0.000100
[2025-08-10 12:28:39,739][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009792] [Batch 02408/03692] [00:22:12/00:11:50, 0.553s/it]: train_loss_raw=2.0296, running_loss=1.9791, LR=0.000100
[2025-08-10 12:28:46,233][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009804] [Batch 02420/03692] [00:22:18/00:11:43, 0.553s/it]: train_loss_raw=2.0117, running_loss=1.9762, LR=0.000100
[2025-08-10 12:28:52,753][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009816] [Batch 02432/03692] [00:22:25/00:11:37, 0.553s/it]: train_loss_raw=1.9532, running_loss=1.9731, LR=0.000100
[2025-08-10 12:28:59,344][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009828] [Batch 02444/03692] [00:22:31/00:11:30, 0.553s/it]: train_loss_raw=2.0385, running_loss=1.9717, LR=0.000100
[2025-08-10 12:29:05,865][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009840] [Batch 02456/03692] [00:22:38/00:11:23, 0.553s/it]: train_loss_raw=1.7750, running_loss=1.9694, LR=0.000100
[2025-08-10 12:29:12,326][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009852] [Batch 02468/03692] [00:22:44/00:11:16, 0.553s/it]: train_loss_raw=1.8362, running_loss=1.9655, LR=0.000100
[2025-08-10 12:29:18,533][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009864] [Batch 02480/03692] [00:22:51/00:11:10, 0.553s/it]: train_loss_raw=1.9162, running_loss=1.9636, LR=0.000100
[2025-08-10 12:29:24,805][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009876] [Batch 02492/03692] [00:22:57/00:11:03, 0.553s/it]: train_loss_raw=2.0556, running_loss=1.9636, LR=0.000100
[2025-08-10 12:29:31,023][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009888] [Batch 02504/03692] [00:23:03/00:10:56, 0.553s/it]: train_loss_raw=1.9586, running_loss=1.9635, LR=0.000100
[2025-08-10 12:29:37,317][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009900] [Batch 02516/03692] [00:23:09/00:10:49, 0.552s/it]: train_loss_raw=1.9994, running_loss=1.9648, LR=0.000100
[2025-08-10 12:29:43,575][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009912] [Batch 02528/03692] [00:23:16/00:10:42, 0.552s/it]: train_loss_raw=1.9190, running_loss=1.9663, LR=0.000100
[2025-08-10 12:29:49,816][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009924] [Batch 02540/03692] [00:23:22/00:10:36, 0.552s/it]: train_loss_raw=1.7722, running_loss=1.9639, LR=0.000100
[2025-08-10 12:29:56,162][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009936] [Batch 02552/03692] [00:23:28/00:10:29, 0.552s/it]: train_loss_raw=1.8637, running_loss=1.9601, LR=0.000100
[2025-08-10 12:30:02,723][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009948] [Batch 02564/03692] [00:23:35/00:10:22, 0.552s/it]: train_loss_raw=1.9927, running_loss=1.9633, LR=0.000100
[2025-08-10 12:30:08,966][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009960] [Batch 02576/03692] [00:23:41/00:10:15, 0.552s/it]: train_loss_raw=1.9553, running_loss=1.9638, LR=0.000100
[2025-08-10 12:30:15,342][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009972] [Batch 02588/03692] [00:23:47/00:10:09, 0.552s/it]: train_loss_raw=1.9832, running_loss=1.9640, LR=0.000100
[2025-08-10 12:30:21,907][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009984] [Batch 02600/03692] [00:23:54/00:10:02, 0.552s/it]: train_loss_raw=1.9574, running_loss=1.9629, LR=0.000100
[2025-08-10 12:30:28,487][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009996] [Batch 02612/03692] [00:24:01/00:09:55, 0.552s/it]: train_loss_raw=1.9108, running_loss=1.9611, LR=0.000100
[2025-08-10 12:30:39,843][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010008] [Batch 02624/03692] [00:24:12/00:09:51, 0.554s/it]: train_loss_raw=1.9068, running_loss=1.9620, LR=0.000100
[2025-08-10 12:30:46,447][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010020] [Batch 02636/03692] [00:24:19/00:09:44, 0.554s/it]: train_loss_raw=1.9987, running_loss=1.9616, LR=0.000100
[2025-08-10 12:30:52,980][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010032] [Batch 02648/03692] [00:24:25/00:09:37, 0.553s/it]: train_loss_raw=1.9615, running_loss=1.9633, LR=0.000100
[2025-08-10 12:30:59,567][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010044] [Batch 02660/03692] [00:24:32/00:09:31, 0.553s/it]: train_loss_raw=2.0764, running_loss=1.9628, LR=0.000100
[2025-08-10 12:31:06,125][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010056] [Batch 02672/03692] [00:24:38/00:09:24, 0.553s/it]: train_loss_raw=1.9313, running_loss=1.9628, LR=0.000100
[2025-08-10 12:31:12,664][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010068] [Batch 02684/03692] [00:24:45/00:09:17, 0.553s/it]: train_loss_raw=1.9722, running_loss=1.9627, LR=0.000100
[2025-08-10 12:31:19,206][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010080] [Batch 02696/03692] [00:24:51/00:09:11, 0.553s/it]: train_loss_raw=1.9061, running_loss=1.9630, LR=0.000100
[2025-08-10 12:31:25,663][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010092] [Batch 02708/03692] [00:24:58/00:09:04, 0.553s/it]: train_loss_raw=1.9807, running_loss=1.9612, LR=0.000100
[2025-08-10 12:31:32,234][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010104] [Batch 02720/03692] [00:25:04/00:08:57, 0.553s/it]: train_loss_raw=1.9633, running_loss=1.9635, LR=0.000100
[2025-08-10 12:31:38,828][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010116] [Batch 02732/03692] [00:25:11/00:08:51, 0.553s/it]: train_loss_raw=1.9187, running_loss=1.9651, LR=0.000100
[2025-08-10 12:31:45,391][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010128] [Batch 02744/03692] [00:25:18/00:08:44, 0.553s/it]: train_loss_raw=2.0069, running_loss=1.9631, LR=0.000100
[2025-08-10 12:31:51,826][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010140] [Batch 02756/03692] [00:25:24/00:08:37, 0.553s/it]: train_loss_raw=2.0326, running_loss=1.9698, LR=0.000100
[2025-08-10 12:31:58,306][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010152] [Batch 02768/03692] [00:25:30/00:08:31, 0.553s/it]: train_loss_raw=2.0225, running_loss=1.9718, LR=0.000100
[2025-08-10 12:32:04,880][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010164] [Batch 02780/03692] [00:25:37/00:08:24, 0.553s/it]: train_loss_raw=2.0393, running_loss=1.9726, LR=0.000100
[2025-08-10 12:32:11,386][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010176] [Batch 02792/03692] [00:25:44/00:08:17, 0.553s/it]: train_loss_raw=2.0129, running_loss=1.9698, LR=0.000100
[2025-08-10 12:32:17,962][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010188] [Batch 02804/03692] [00:25:50/00:08:11, 0.553s/it]: train_loss_raw=1.9429, running_loss=1.9673, LR=0.000100
[2025-08-10 12:32:24,391][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010200] [Batch 02816/03692] [00:25:57/00:08:04, 0.553s/it]: train_loss_raw=1.9713, running_loss=1.9693, LR=0.000100
[2025-08-10 12:32:30,915][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010212] [Batch 02828/03692] [00:26:03/00:07:57, 0.553s/it]: train_loss_raw=1.8726, running_loss=1.9692, LR=0.000100
[2025-08-10 12:32:37,567][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010224] [Batch 02840/03692] [00:26:10/00:07:51, 0.553s/it]: train_loss_raw=1.9514, running_loss=1.9677, LR=0.000100
[2025-08-10 12:32:44,145][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010236] [Batch 02852/03692] [00:26:16/00:07:44, 0.553s/it]: train_loss_raw=1.8540, running_loss=1.9635, LR=0.000100
[2025-08-10 12:32:50,659][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010248] [Batch 02864/03692] [00:26:23/00:07:37, 0.553s/it]: train_loss_raw=2.0228, running_loss=1.9623, LR=0.000100
[2025-08-10 12:32:57,187][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010260] [Batch 02876/03692] [00:26:29/00:07:31, 0.553s/it]: train_loss_raw=1.9658, running_loss=1.9639, LR=0.000100
[2025-08-10 12:33:03,653][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010272] [Batch 02888/03692] [00:26:36/00:07:24, 0.553s/it]: train_loss_raw=1.9364, running_loss=1.9626, LR=0.000100
[2025-08-10 12:33:10,065][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010284] [Batch 02900/03692] [00:26:42/00:07:17, 0.553s/it]: train_loss_raw=1.9078, running_loss=1.9625, LR=0.000100
[2025-08-10 12:33:16,496][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010296] [Batch 02912/03692] [00:26:49/00:07:11, 0.553s/it]: train_loss_raw=1.9028, running_loss=1.9618, LR=0.000100
[2025-08-10 12:33:22,874][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010308] [Batch 02924/03692] [00:26:55/00:07:04, 0.553s/it]: train_loss_raw=2.0490, running_loss=1.9624, LR=0.000100
[2025-08-10 12:33:29,467][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010320] [Batch 02936/03692] [00:27:02/00:06:57, 0.552s/it]: train_loss_raw=2.0128, running_loss=1.9593, LR=0.000100
[2025-08-10 12:33:36,090][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010332] [Batch 02948/03692] [00:27:08/00:06:51, 0.552s/it]: train_loss_raw=1.9882, running_loss=1.9597, LR=0.000100
[2025-08-10 12:33:42,633][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010344] [Batch 02960/03692] [00:27:15/00:06:44, 0.552s/it]: train_loss_raw=2.0717, running_loss=1.9587, LR=0.000100
[2025-08-10 12:33:49,119][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010356] [Batch 02972/03692] [00:27:21/00:06:37, 0.552s/it]: train_loss_raw=2.0439, running_loss=1.9545, LR=0.000100
[2025-08-10 12:33:55,489][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010368] [Batch 02984/03692] [00:27:28/00:06:31, 0.552s/it]: train_loss_raw=1.9853, running_loss=1.9594, LR=0.000100
[2025-08-10 12:34:01,929][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010380] [Batch 02996/03692] [00:27:34/00:06:24, 0.552s/it]: train_loss_raw=1.9878, running_loss=1.9573, LR=0.000100
[2025-08-10 12:34:08,281][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010392] [Batch 03008/03692] [00:27:40/00:06:17, 0.552s/it]: train_loss_raw=1.9602, running_loss=1.9533, LR=0.000100
[2025-08-10 12:34:14,693][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010404] [Batch 03020/03692] [00:27:47/00:06:11, 0.552s/it]: train_loss_raw=1.9305, running_loss=1.9500, LR=0.000100
[2025-08-10 12:34:20,999][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010416] [Batch 03032/03692] [00:27:53/00:06:04, 0.552s/it]: train_loss_raw=1.9571, running_loss=1.9538, LR=0.000100
[2025-08-10 12:34:27,547][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010428] [Batch 03044/03692] [00:28:00/00:05:57, 0.552s/it]: train_loss_raw=1.9598, running_loss=1.9520, LR=0.000100
[2025-08-10 12:34:34,021][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010440] [Batch 03056/03692] [00:28:06/00:05:51, 0.552s/it]: train_loss_raw=1.8937, running_loss=1.9571, LR=0.000100
[2025-08-10 12:34:40,496][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010452] [Batch 03068/03692] [00:28:13/00:05:44, 0.552s/it]: train_loss_raw=1.9136, running_loss=1.9566, LR=0.000100
[2025-08-10 12:34:47,049][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010464] [Batch 03080/03692] [00:28:19/00:05:37, 0.552s/it]: train_loss_raw=1.9608, running_loss=1.9553, LR=0.000100
[2025-08-10 12:34:53,536][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010476] [Batch 03092/03692] [00:28:26/00:05:31, 0.552s/it]: train_loss_raw=1.9277, running_loss=1.9562, LR=0.000100
[2025-08-10 12:35:00,063][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010488] [Batch 03104/03692] [00:28:32/00:05:24, 0.552s/it]: train_loss_raw=1.8916, running_loss=1.9502, LR=0.000100
[2025-08-10 12:35:06,651][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010500] [Batch 03116/03692] [00:28:39/00:05:17, 0.552s/it]: train_loss_raw=1.9736, running_loss=1.9468, LR=0.000100
[2025-08-10 12:35:13,233][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010512] [Batch 03128/03692] [00:28:45/00:05:11, 0.552s/it]: train_loss_raw=1.8580, running_loss=1.9475, LR=0.000100
[2025-08-10 12:35:19,716][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010524] [Batch 03140/03692] [00:28:52/00:05:04, 0.552s/it]: train_loss_raw=2.0356, running_loss=1.9468, LR=0.000100
[2025-08-10 12:35:26,153][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010536] [Batch 03152/03692] [00:28:58/00:04:57, 0.552s/it]: train_loss_raw=1.9032, running_loss=1.9473, LR=0.000100
[2025-08-10 12:35:32,623][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010548] [Batch 03164/03692] [00:29:05/00:04:51, 0.552s/it]: train_loss_raw=1.9278, running_loss=1.9487, LR=0.000100
[2025-08-10 12:35:39,106][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010560] [Batch 03176/03692] [00:29:11/00:04:44, 0.552s/it]: train_loss_raw=2.0216, running_loss=1.9470, LR=0.000100
[2025-08-10 12:35:45,559][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010572] [Batch 03188/03692] [00:29:18/00:04:37, 0.552s/it]: train_loss_raw=1.9415, running_loss=1.9463, LR=0.000100
[2025-08-10 12:35:52,023][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010584] [Batch 03200/03692] [00:29:24/00:04:31, 0.551s/it]: train_loss_raw=1.8670, running_loss=1.9455, LR=0.000100
[2025-08-10 12:35:58,506][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010596] [Batch 03212/03692] [00:29:31/00:04:24, 0.551s/it]: train_loss_raw=1.9537, running_loss=1.9501, LR=0.000100
[2025-08-10 12:36:05,002][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010608] [Batch 03224/03692] [00:29:37/00:04:18, 0.551s/it]: train_loss_raw=1.9239, running_loss=1.9514, LR=0.000100
[2025-08-10 12:36:11,539][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010620] [Batch 03236/03692] [00:29:44/00:04:11, 0.551s/it]: train_loss_raw=2.0024, running_loss=1.9531, LR=0.000100
[2025-08-10 12:36:18,050][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010632] [Batch 03248/03692] [00:29:50/00:04:04, 0.551s/it]: train_loss_raw=1.9452, running_loss=1.9555, LR=0.000100
[2025-08-10 12:36:24,524][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010644] [Batch 03260/03692] [00:29:57/00:03:58, 0.551s/it]: train_loss_raw=1.9177, running_loss=1.9566, LR=0.000100
[2025-08-10 12:36:31,140][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010656] [Batch 03272/03692] [00:30:03/00:03:51, 0.551s/it]: train_loss_raw=1.8554, running_loss=1.9517, LR=0.000100
[2025-08-10 12:36:37,735][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010668] [Batch 03284/03692] [00:30:10/00:03:44, 0.551s/it]: train_loss_raw=1.9785, running_loss=1.9511, LR=0.000100
[2025-08-10 12:36:44,290][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010680] [Batch 03296/03692] [00:30:16/00:03:38, 0.551s/it]: train_loss_raw=1.8895, running_loss=1.9481, LR=0.000100
[2025-08-10 12:36:50,960][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010692] [Batch 03308/03692] [00:30:23/00:03:31, 0.551s/it]: train_loss_raw=1.8993, running_loss=1.9432, LR=0.000100
[2025-08-10 12:36:57,582][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010704] [Batch 03320/03692] [00:30:30/00:03:25, 0.551s/it]: train_loss_raw=1.9207, running_loss=1.9440, LR=0.000100
[2025-08-10 12:37:04,060][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010716] [Batch 03332/03692] [00:30:36/00:03:18, 0.551s/it]: train_loss_raw=1.9672, running_loss=1.9419, LR=0.000100
[2025-08-10 12:37:10,628][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010728] [Batch 03344/03692] [00:30:43/00:03:11, 0.551s/it]: train_loss_raw=2.0556, running_loss=1.9420, LR=0.000100
[2025-08-10 12:37:17,205][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010740] [Batch 03356/03692] [00:30:49/00:03:05, 0.551s/it]: train_loss_raw=1.9833, running_loss=1.9427, LR=0.000100
[2025-08-10 12:37:23,709][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010752] [Batch 03368/03692] [00:30:56/00:02:58, 0.551s/it]: train_loss_raw=1.8961, running_loss=1.9414, LR=0.000100
[2025-08-10 12:37:30,260][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010764] [Batch 03380/03692] [00:31:02/00:02:51, 0.551s/it]: train_loss_raw=1.9223, running_loss=1.9387, LR=0.000100
[2025-08-10 12:37:36,805][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010776] [Batch 03392/03692] [00:31:09/00:02:45, 0.551s/it]: train_loss_raw=1.9499, running_loss=1.9402, LR=0.000100
[2025-08-10 12:37:43,362][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010788] [Batch 03404/03692] [00:31:16/00:02:38, 0.551s/it]: train_loss_raw=1.9684, running_loss=1.9399, LR=0.000100
[2025-08-10 12:37:49,918][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010800] [Batch 03416/03692] [00:31:22/00:02:32, 0.551s/it]: train_loss_raw=1.8876, running_loss=1.9382, LR=0.000100
[2025-08-10 12:37:56,484][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010812] [Batch 03428/03692] [00:31:29/00:02:25, 0.551s/it]: train_loss_raw=1.9938, running_loss=1.9390, LR=0.000100
[2025-08-10 12:38:03,088][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010824] [Batch 03440/03692] [00:31:35/00:02:18, 0.551s/it]: train_loss_raw=1.8805, running_loss=1.9408, LR=0.000100
[2025-08-10 12:38:09,565][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010836] [Batch 03452/03692] [00:31:42/00:02:12, 0.551s/it]: train_loss_raw=1.8872, running_loss=1.9420, LR=0.000100
[2025-08-10 12:38:16,010][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010848] [Batch 03464/03692] [00:31:48/00:02:05, 0.551s/it]: train_loss_raw=1.9509, running_loss=1.9407, LR=0.000100
[2025-08-10 12:38:22,413][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010860] [Batch 03476/03692] [00:31:55/00:01:59, 0.551s/it]: train_loss_raw=1.9756, running_loss=1.9422, LR=0.000100
[2025-08-10 12:38:28,912][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010872] [Batch 03488/03692] [00:32:01/00:01:52, 0.551s/it]: train_loss_raw=1.9336, running_loss=1.9416, LR=0.000100
[2025-08-10 12:38:35,427][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010884] [Batch 03500/03692] [00:32:08/00:01:45, 0.551s/it]: train_loss_raw=1.9773, running_loss=1.9422, LR=0.000100
[2025-08-10 12:38:41,914][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010896] [Batch 03512/03692] [00:32:14/00:01:39, 0.551s/it]: train_loss_raw=1.8755, running_loss=1.9408, LR=0.000100
[2025-08-10 12:38:48,374][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010908] [Batch 03524/03692] [00:32:21/00:01:32, 0.551s/it]: train_loss_raw=1.9354, running_loss=1.9411, LR=0.000100
[2025-08-10 12:38:54,788][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010920] [Batch 03536/03692] [00:32:27/00:01:25, 0.551s/it]: train_loss_raw=1.9100, running_loss=1.9429, LR=0.000100
[2025-08-10 12:39:01,231][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010932] [Batch 03548/03692] [00:32:33/00:01:19, 0.551s/it]: train_loss_raw=1.8442, running_loss=1.9447, LR=0.000100
[2025-08-10 12:39:07,843][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010944] [Batch 03560/03692] [00:32:40/00:01:12, 0.551s/it]: train_loss_raw=1.8551, running_loss=1.9442, LR=0.000100
[2025-08-10 12:39:14,270][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010956] [Batch 03572/03692] [00:32:46/00:01:06, 0.551s/it]: train_loss_raw=1.9851, running_loss=1.9415, LR=0.000100
[2025-08-10 12:39:20,658][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010968] [Batch 03584/03692] [00:32:53/00:00:59, 0.551s/it]: train_loss_raw=1.7934, running_loss=1.9409, LR=0.000100
[2025-08-10 12:39:27,082][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010980] [Batch 03596/03692] [00:32:59/00:00:52, 0.551s/it]: train_loss_raw=1.9031, running_loss=1.9389, LR=0.000100
[2025-08-10 12:39:33,565][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010992] [Batch 03608/03692] [00:33:06/00:00:46, 0.550s/it]: train_loss_raw=1.9111, running_loss=1.9367, LR=0.000100
[2025-08-10 12:39:40,111][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011004] [Batch 03620/03692] [00:33:12/00:00:39, 0.550s/it]: train_loss_raw=1.9386, running_loss=1.9354, LR=0.000100
[2025-08-10 12:39:46,611][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011016] [Batch 03632/03692] [00:33:19/00:00:33, 0.550s/it]: train_loss_raw=1.8755, running_loss=1.9322, LR=0.000100
[2025-08-10 12:39:53,207][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011028] [Batch 03644/03692] [00:33:25/00:00:26, 0.550s/it]: train_loss_raw=1.8288, running_loss=1.9290, LR=0.000100
[2025-08-10 12:39:59,751][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011040] [Batch 03656/03692] [00:33:32/00:00:19, 0.550s/it]: train_loss_raw=1.9663, running_loss=1.9313, LR=0.000100
[2025-08-10 12:40:06,298][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011052] [Batch 03668/03692] [00:33:38/00:00:13, 0.550s/it]: train_loss_raw=1.9896, running_loss=1.9324, LR=0.000100
[2025-08-10 12:40:12,844][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011064] [Batch 03680/03692] [00:33:45/00:00:06, 0.550s/it]: train_loss_raw=1.9345, running_loss=1.9293, LR=0.000100
[2025-08-10 12:40:19,428][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011076] [Batch 03692/03692] [00:33:52/00:00:00, 0.550s/it]: train_loss_raw=1.8957, running_loss=1.9312, LR=0.000100
[2025-08-10 12:40:24,839][__main__][INFO] - [VALIDATION] [Epoch 02/29] Starting validation.
[2025-08-10 12:41:01,199][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 011077] [Batch 00011/00025] [00:00:36/00:00:39, 3.030s/it]
[2025-08-10 12:41:18,423][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 011077] [Batch 00023/00025] [00:00:53/00:00:02, 2.233s/it]
[2025-08-10 12:41:19,607][__main__][INFO] - [VALIDATION] [Epoch 02/29] train_loss=1.93116, valid_loss=1.88446
[2025-08-10 12:41:19,607][__main__][INFO] - [VALIDATION] [Epoch 02/29] Metrics:
[2025-08-10 12:41:19,607][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_er      0.735
[2025-08-10 12:41:19,607][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_prec    0.030
[2025-08-10 12:41:19,607][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_recall  0.030
[2025-08-10 12:41:19,607][__main__][INFO] - [VALIDATION] [Epoch 02/29] - pep_recall 0.002
[2025-08-10 12:41:19,611][__main__][INFO] - [TRAIN] [Epoch 02/29] Epoch complete, total time 01:45:18, remaining time 15:47:49, 00:35:06 per epoch
[2025-08-10 12:41:28,261][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011088] [Batch 00012/03692] [00:00:06/00:31:15, 0.510s/it]: train_loss_raw=1.9259, running_loss=1.8813, LR=0.000100
[2025-08-10 12:41:34,819][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011100] [Batch 00024/03692] [00:00:12/00:32:16, 0.528s/it]: train_loss_raw=1.9488, running_loss=1.8820, LR=0.000100
[2025-08-10 12:41:41,124][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011112] [Batch 00036/03692] [00:00:18/00:32:07, 0.527s/it]: train_loss_raw=1.9432, running_loss=1.8862, LR=0.000100
[2025-08-10 12:41:47,403][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011124] [Batch 00048/03692] [00:00:25/00:31:57, 0.526s/it]: train_loss_raw=1.9038, running_loss=1.8958, LR=0.000100
[2025-08-10 12:41:53,962][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011136] [Batch 00060/03692] [00:00:31/00:32:05, 0.530s/it]: train_loss_raw=1.9284, running_loss=1.9032, LR=0.000100
[2025-08-10 12:42:00,508][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011148] [Batch 00072/03692] [00:00:38/00:32:08, 0.533s/it]: train_loss_raw=2.0345, running_loss=1.9086, LR=0.000100
[2025-08-10 12:42:06,849][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011160] [Batch 00084/03692] [00:00:44/00:32:00, 0.532s/it]: train_loss_raw=1.8962, running_loss=1.9143, LR=0.000100
[2025-08-10 12:42:13,062][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011172] [Batch 00096/03692] [00:00:50/00:31:47, 0.530s/it]: train_loss_raw=1.9083, running_loss=1.9137, LR=0.000100
[2025-08-10 12:42:19,297][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011184] [Batch 00108/03692] [00:00:57/00:31:36, 0.529s/it]: train_loss_raw=1.9269, running_loss=1.9121, LR=0.000100
[2025-08-10 12:42:25,616][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011196] [Batch 00120/03692] [00:01:03/00:31:29, 0.529s/it]: train_loss_raw=1.9833, running_loss=1.9150, LR=0.000100
[2025-08-10 12:42:31,890][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011208] [Batch 00132/03692] [00:01:09/00:31:20, 0.528s/it]: train_loss_raw=2.0284, running_loss=1.9142, LR=0.000100
[2025-08-10 12:42:38,160][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011220] [Batch 00144/03692] [00:01:16/00:31:12, 0.528s/it]: train_loss_raw=1.7778, running_loss=1.9141, LR=0.000100
[2025-08-10 12:42:44,396][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011232] [Batch 00156/03692] [00:01:22/00:31:04, 0.527s/it]: train_loss_raw=2.0789, running_loss=1.9190, LR=0.000100
[2025-08-10 12:42:50,646][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011244] [Batch 00168/03692] [00:01:28/00:30:56, 0.527s/it]: train_loss_raw=1.8846, running_loss=1.9190, LR=0.000100
[2025-08-10 12:42:56,945][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011256] [Batch 00180/03692] [00:01:34/00:30:49, 0.527s/it]: train_loss_raw=1.8984, running_loss=1.9185, LR=0.000100
[2025-08-10 12:43:03,239][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011268] [Batch 00192/03692] [00:01:41/00:30:42, 0.527s/it]: train_loss_raw=1.9388, running_loss=1.9209, LR=0.000100
[2025-08-10 12:43:09,629][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011280] [Batch 00204/03692] [00:01:47/00:30:37, 0.527s/it]: train_loss_raw=1.9589, running_loss=1.9227, LR=0.000100
[2025-08-10 12:43:16,052][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011292] [Batch 00216/03692] [00:01:53/00:30:33, 0.527s/it]: train_loss_raw=2.0289, running_loss=1.9254, LR=0.000100
[2025-08-10 12:43:22,309][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011304] [Batch 00228/03692] [00:02:00/00:30:25, 0.527s/it]: train_loss_raw=1.8829, running_loss=1.9228, LR=0.000100
[2025-08-10 12:43:28,633][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011316] [Batch 00240/03692] [00:02:06/00:30:19, 0.527s/it]: train_loss_raw=1.9971, running_loss=1.9249, LR=0.000100
[2025-08-10 12:43:34,960][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011328] [Batch 00252/03692] [00:02:12/00:30:13, 0.527s/it]: train_loss_raw=1.8761, running_loss=1.9225, LR=0.000100
[2025-08-10 12:43:41,254][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011340] [Batch 00264/03692] [00:02:19/00:30:06, 0.527s/it]: train_loss_raw=1.8930, running_loss=1.9221, LR=0.000100
[2025-08-10 12:43:47,675][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011352] [Batch 00276/03692] [00:02:25/00:30:01, 0.527s/it]: train_loss_raw=1.9633, running_loss=1.9186, LR=0.000100
[2025-08-10 12:43:53,988][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011364] [Batch 00288/03692] [00:02:31/00:29:54, 0.527s/it]: train_loss_raw=1.9069, running_loss=1.9211, LR=0.000100
[2025-08-10 12:44:00,335][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011376] [Batch 00300/03692] [00:02:38/00:29:48, 0.527s/it]: train_loss_raw=1.8296, running_loss=1.9194, LR=0.000100
[2025-08-10 12:44:06,601][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011388] [Batch 00312/03692] [00:02:44/00:29:41, 0.527s/it]: train_loss_raw=1.9473, running_loss=1.9198, LR=0.000100
[2025-08-10 12:44:12,900][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011400] [Batch 00324/03692] [00:02:50/00:29:35, 0.527s/it]: train_loss_raw=1.9083, running_loss=1.9191, LR=0.000100
[2025-08-10 12:44:19,402][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011412] [Batch 00336/03692] [00:02:57/00:29:30, 0.528s/it]: train_loss_raw=1.8915, running_loss=1.9194, LR=0.000100
[2025-08-10 12:44:25,803][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011424] [Batch 00348/03692] [00:03:03/00:29:24, 0.528s/it]: train_loss_raw=1.7455, running_loss=1.9203, LR=0.000100
[2025-08-10 12:44:32,268][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011436] [Batch 00360/03692] [00:03:10/00:29:19, 0.528s/it]: train_loss_raw=1.8694, running_loss=1.9190, LR=0.000100
[2025-08-10 12:44:38,760][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011448] [Batch 00372/03692] [00:03:16/00:29:14, 0.529s/it]: train_loss_raw=1.8857, running_loss=1.9171, LR=0.000100
[2025-08-10 12:44:45,374][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011460] [Batch 00384/03692] [00:03:23/00:29:10, 0.529s/it]: train_loss_raw=1.9322, running_loss=1.9174, LR=0.000100
[2025-08-10 12:44:52,018][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011472] [Batch 00396/03692] [00:03:29/00:29:06, 0.530s/it]: train_loss_raw=1.9952, running_loss=1.9192, LR=0.000100
[2025-08-10 12:44:58,444][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011484] [Batch 00408/03692] [00:03:36/00:29:00, 0.530s/it]: train_loss_raw=2.0063, running_loss=1.9179, LR=0.000100
[2025-08-10 12:45:04,810][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011496] [Batch 00420/03692] [00:03:42/00:28:54, 0.530s/it]: train_loss_raw=2.0062, running_loss=1.9209, LR=0.000100
[2025-08-10 12:45:11,201][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011508] [Batch 00432/03692] [00:03:49/00:28:48, 0.530s/it]: train_loss_raw=1.8873, running_loss=1.9197, LR=0.000100
[2025-08-10 12:45:17,451][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011520] [Batch 00444/03692] [00:03:55/00:28:41, 0.530s/it]: train_loss_raw=1.8929, running_loss=1.9158, LR=0.000100
[2025-08-10 12:45:23,835][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011532] [Batch 00456/03692] [00:04:01/00:28:35, 0.530s/it]: train_loss_raw=2.0003, running_loss=1.9178, LR=0.000100
[2025-08-10 12:45:30,185][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011544] [Batch 00468/03692] [00:04:08/00:28:28, 0.530s/it]: train_loss_raw=1.9074, running_loss=1.9162, LR=0.000100
[2025-08-10 12:45:36,456][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011556] [Batch 00480/03692] [00:04:14/00:28:21, 0.530s/it]: train_loss_raw=1.9419, running_loss=1.9128, LR=0.000100
[2025-08-10 12:45:42,898][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011568] [Batch 00492/03692] [00:04:20/00:28:15, 0.530s/it]: train_loss_raw=1.7872, running_loss=1.9127, LR=0.000100
[2025-08-10 12:45:49,440][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011580] [Batch 00504/03692] [00:04:27/00:28:10, 0.530s/it]: train_loss_raw=1.8998, running_loss=1.9109, LR=0.000100
[2025-08-10 12:45:55,970][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011592] [Batch 00516/03692] [00:04:33/00:28:05, 0.531s/it]: train_loss_raw=1.8271, running_loss=1.9102, LR=0.000100
[2025-08-10 12:46:02,464][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011604] [Batch 00528/03692] [00:04:40/00:27:59, 0.531s/it]: train_loss_raw=2.0021, running_loss=1.9107, LR=0.000100
[2025-08-10 12:46:08,839][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011616] [Batch 00540/03692] [00:04:46/00:27:53, 0.531s/it]: train_loss_raw=1.9767, running_loss=1.9124, LR=0.000100
[2025-08-10 12:46:15,299][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011628] [Batch 00552/03692] [00:04:53/00:27:47, 0.531s/it]: train_loss_raw=1.8914, running_loss=1.9137, LR=0.000100
[2025-08-10 12:46:21,833][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011640] [Batch 00564/03692] [00:04:59/00:27:42, 0.531s/it]: train_loss_raw=2.0249, running_loss=1.9163, LR=0.000100
[2025-08-10 12:46:28,415][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011652] [Batch 00576/03692] [00:05:06/00:27:36, 0.532s/it]: train_loss_raw=1.8520, running_loss=1.9167, LR=0.000100
[2025-08-10 12:46:34,595][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011664] [Batch 00588/03692] [00:05:12/00:27:29, 0.531s/it]: train_loss_raw=1.9980, running_loss=1.9169, LR=0.000100
[2025-08-10 12:46:40,969][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011676] [Batch 00600/03692] [00:05:18/00:27:23, 0.531s/it]: train_loss_raw=1.9192, running_loss=1.9131, LR=0.000100
[2025-08-10 12:46:47,233][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011688] [Batch 00612/03692] [00:05:25/00:27:16, 0.531s/it]: train_loss_raw=1.9644, running_loss=1.9161, LR=0.000100
[2025-08-10 12:46:53,434][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011700] [Batch 00624/03692] [00:05:31/00:27:08, 0.531s/it]: train_loss_raw=1.8846, running_loss=1.9144, LR=0.000100
[2025-08-10 12:46:59,649][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011712] [Batch 00636/03692] [00:05:37/00:27:01, 0.531s/it]: train_loss_raw=1.7861, running_loss=1.9087, LR=0.000100
[2025-08-10 12:47:05,918][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011724] [Batch 00648/03692] [00:05:43/00:26:54, 0.531s/it]: train_loss_raw=1.8716, running_loss=1.9093, LR=0.000100
[2025-08-10 12:47:12,256][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011736] [Batch 00660/03692] [00:05:50/00:26:48, 0.530s/it]: train_loss_raw=1.8867, running_loss=1.9060, LR=0.000100
[2025-08-10 12:47:18,749][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011748] [Batch 00672/03692] [00:05:56/00:26:42, 0.531s/it]: train_loss_raw=1.9247, running_loss=1.9067, LR=0.000100
[2025-08-10 12:47:25,363][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011760] [Batch 00684/03692] [00:06:03/00:26:37, 0.531s/it]: train_loss_raw=1.9517, running_loss=1.9066, LR=0.000100
[2025-08-10 12:47:31,768][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011772] [Batch 00696/03692] [00:06:09/00:26:31, 0.531s/it]: train_loss_raw=1.9279, running_loss=1.9090, LR=0.000100
[2025-08-10 12:47:38,257][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011784] [Batch 00708/03692] [00:06:16/00:26:25, 0.531s/it]: train_loss_raw=1.9174, running_loss=1.9076, LR=0.000100
[2025-08-10 12:47:44,841][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011796] [Batch 00720/03692] [00:06:22/00:26:19, 0.532s/it]: train_loss_raw=1.9689, running_loss=1.9082, LR=0.000100
[2025-08-10 12:47:51,443][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011808] [Batch 00732/03692] [00:06:29/00:26:14, 0.532s/it]: train_loss_raw=1.9051, running_loss=1.9078, LR=0.000100
[2025-08-10 12:47:57,897][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011820] [Batch 00744/03692] [00:06:35/00:26:08, 0.532s/it]: train_loss_raw=1.7305, running_loss=1.9029, LR=0.000100
[2025-08-10 12:48:04,262][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011832] [Batch 00756/03692] [00:06:42/00:26:01, 0.532s/it]: train_loss_raw=2.0142, running_loss=1.9029, LR=0.000100
[2025-08-10 12:48:10,694][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011844] [Batch 00768/03692] [00:06:48/00:25:55, 0.532s/it]: train_loss_raw=2.0085, running_loss=1.9030, LR=0.000100
[2025-08-10 12:48:17,161][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011856] [Batch 00780/03692] [00:06:55/00:25:49, 0.532s/it]: train_loss_raw=1.9351, running_loss=1.9056, LR=0.000100
[2025-08-10 12:48:23,435][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011868] [Batch 00792/03692] [00:07:01/00:25:42, 0.532s/it]: train_loss_raw=1.8584, running_loss=1.9057, LR=0.000100
[2025-08-10 12:48:29,726][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011880] [Batch 00804/03692] [00:07:07/00:25:35, 0.532s/it]: train_loss_raw=2.0049, running_loss=1.9101, LR=0.000100
[2025-08-10 12:48:36,195][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011892] [Batch 00816/03692] [00:07:14/00:25:29, 0.532s/it]: train_loss_raw=1.7814, running_loss=1.9098, LR=0.000100
[2025-08-10 12:48:42,696][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011904] [Batch 00828/03692] [00:07:20/00:25:23, 0.532s/it]: train_loss_raw=1.9897, running_loss=1.9098, LR=0.000100
[2025-08-10 12:48:49,141][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011916] [Batch 00840/03692] [00:07:26/00:25:17, 0.532s/it]: train_loss_raw=2.0084, running_loss=1.9109, LR=0.000100
[2025-08-10 12:48:55,611][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011928] [Batch 00852/03692] [00:07:33/00:25:11, 0.532s/it]: train_loss_raw=1.9772, running_loss=1.9095, LR=0.000100
[2025-08-10 12:49:01,820][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011940] [Batch 00864/03692] [00:07:39/00:25:04, 0.532s/it]: train_loss_raw=1.9424, running_loss=1.9059, LR=0.000100
[2025-08-10 12:49:08,255][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011952] [Batch 00876/03692] [00:07:46/00:24:58, 0.532s/it]: train_loss_raw=1.9367, running_loss=1.9093, LR=0.000100
[2025-08-10 12:49:14,843][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011964] [Batch 00888/03692] [00:07:52/00:24:52, 0.532s/it]: train_loss_raw=1.8208, running_loss=1.9086, LR=0.000100
[2025-08-10 12:49:21,344][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011976] [Batch 00900/03692] [00:07:59/00:24:46, 0.532s/it]: train_loss_raw=1.9076, running_loss=1.9097, LR=0.000100
[2025-08-10 12:49:27,729][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 011988] [Batch 00912/03692] [00:08:05/00:24:40, 0.532s/it]: train_loss_raw=1.8844, running_loss=1.9099, LR=0.000100
[2025-08-10 12:49:34,173][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012000] [Batch 00924/03692] [00:08:12/00:24:33, 0.532s/it]: train_loss_raw=1.9099, running_loss=1.9076, LR=0.000100
[2025-08-10 12:49:45,178][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012012] [Batch 00936/03692] [00:08:23/00:24:41, 0.537s/it]: train_loss_raw=1.9283, running_loss=1.9071, LR=0.000100
[2025-08-10 12:49:51,694][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012024] [Batch 00948/03692] [00:08:29/00:24:34, 0.537s/it]: train_loss_raw=1.9303, running_loss=1.9046, LR=0.000100
[2025-08-10 12:49:58,117][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012036] [Batch 00960/03692] [00:08:35/00:24:28, 0.537s/it]: train_loss_raw=2.0117, running_loss=1.9040, LR=0.000100
[2025-08-10 12:50:04,563][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012048] [Batch 00972/03692] [00:08:42/00:24:21, 0.537s/it]: train_loss_raw=1.9012, running_loss=1.9048, LR=0.000100
[2025-08-10 12:50:11,186][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012060] [Batch 00984/03692] [00:08:49/00:24:15, 0.538s/it]: train_loss_raw=1.8425, running_loss=1.9036, LR=0.000100
[2025-08-10 12:50:17,705][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012072] [Batch 00996/03692] [00:08:55/00:24:09, 0.538s/it]: train_loss_raw=1.8853, running_loss=1.9033, LR=0.000100
[2025-08-10 12:50:24,312][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012084] [Batch 01008/03692] [00:09:02/00:24:03, 0.538s/it]: train_loss_raw=1.9442, running_loss=1.9032, LR=0.000100
[2025-08-10 12:50:30,877][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012096] [Batch 01020/03692] [00:09:08/00:23:57, 0.538s/it]: train_loss_raw=1.9321, running_loss=1.9019, LR=0.000100
[2025-08-10 12:50:37,497][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012108] [Batch 01032/03692] [00:09:15/00:23:51, 0.538s/it]: train_loss_raw=1.7964, running_loss=1.9018, LR=0.000100
[2025-08-10 12:50:44,178][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012120] [Batch 01044/03692] [00:09:22/00:23:45, 0.538s/it]: train_loss_raw=1.9935, running_loss=1.9034, LR=0.000100
[2025-08-10 12:50:50,833][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012132] [Batch 01056/03692] [00:09:28/00:23:39, 0.539s/it]: train_loss_raw=1.8359, running_loss=1.9042, LR=0.000100
[2025-08-10 12:50:57,380][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012144] [Batch 01068/03692] [00:09:35/00:23:33, 0.539s/it]: train_loss_raw=1.8422, running_loss=1.9022, LR=0.000100
[2025-08-10 12:51:03,935][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012156] [Batch 01080/03692] [00:09:41/00:23:27, 0.539s/it]: train_loss_raw=1.9515, running_loss=1.8998, LR=0.000100
[2025-08-10 12:51:10,377][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012168] [Batch 01092/03692] [00:09:48/00:23:20, 0.539s/it]: train_loss_raw=1.9133, running_loss=1.8998, LR=0.000100
[2025-08-10 12:51:16,834][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012180] [Batch 01104/03692] [00:09:54/00:23:14, 0.539s/it]: train_loss_raw=1.9129, running_loss=1.8996, LR=0.000100
[2025-08-10 12:51:23,263][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012192] [Batch 01116/03692] [00:10:01/00:23:07, 0.539s/it]: train_loss_raw=1.8859, running_loss=1.8966, LR=0.000100
[2025-08-10 12:51:29,584][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012204] [Batch 01128/03692] [00:10:07/00:23:00, 0.539s/it]: train_loss_raw=1.8086, running_loss=1.8947, LR=0.000100
[2025-08-10 12:51:35,979][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012216] [Batch 01140/03692] [00:10:13/00:22:54, 0.538s/it]: train_loss_raw=1.8199, running_loss=1.8943, LR=0.000100
[2025-08-10 12:51:42,598][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012228] [Batch 01152/03692] [00:10:20/00:22:48, 0.539s/it]: train_loss_raw=1.9084, running_loss=1.8947, LR=0.000100
[2025-08-10 12:51:49,212][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012240] [Batch 01164/03692] [00:10:27/00:22:41, 0.539s/it]: train_loss_raw=1.9428, running_loss=1.8967, LR=0.000100
[2025-08-10 12:51:55,853][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012252] [Batch 01176/03692] [00:10:33/00:22:35, 0.539s/it]: train_loss_raw=1.9706, running_loss=1.8987, LR=0.000100
[2025-08-10 12:52:02,471][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012264] [Batch 01188/03692] [00:10:40/00:22:29, 0.539s/it]: train_loss_raw=1.8578, running_loss=1.9010, LR=0.000100
[2025-08-10 12:52:09,108][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012276] [Batch 01200/03692] [00:10:46/00:22:23, 0.539s/it]: train_loss_raw=1.9250, running_loss=1.8980, LR=0.000100
[2025-08-10 12:52:15,466][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012288] [Batch 01212/03692] [00:10:53/00:22:16, 0.539s/it]: train_loss_raw=1.9220, running_loss=1.8948, LR=0.000100
[2025-08-10 12:52:21,608][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012300] [Batch 01224/03692] [00:10:59/00:22:09, 0.539s/it]: train_loss_raw=1.8287, running_loss=1.8905, LR=0.000100
[2025-08-10 12:52:27,829][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012312] [Batch 01236/03692] [00:11:05/00:22:02, 0.539s/it]: train_loss_raw=1.9834, running_loss=1.8931, LR=0.000100
[2025-08-10 12:52:34,072][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012324] [Batch 01248/03692] [00:11:11/00:21:55, 0.538s/it]: train_loss_raw=1.8998, running_loss=1.8923, LR=0.000100
[2025-08-10 12:52:40,353][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012336] [Batch 01260/03692] [00:11:18/00:21:49, 0.538s/it]: train_loss_raw=1.8654, running_loss=1.8927, LR=0.000100
[2025-08-10 12:52:46,654][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012348] [Batch 01272/03692] [00:11:24/00:21:42, 0.538s/it]: train_loss_raw=1.9735, running_loss=1.8922, LR=0.000100
[2025-08-10 12:52:52,920][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012360] [Batch 01284/03692] [00:11:30/00:21:35, 0.538s/it]: train_loss_raw=1.9176, running_loss=1.8880, LR=0.000100
[2025-08-10 12:52:59,141][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012372] [Batch 01296/03692] [00:11:36/00:21:28, 0.538s/it]: train_loss_raw=1.8275, running_loss=1.8877, LR=0.000100
[2025-08-10 12:53:05,616][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012384] [Batch 01308/03692] [00:11:43/00:21:22, 0.538s/it]: train_loss_raw=1.9553, running_loss=1.8872, LR=0.000100
[2025-08-10 12:53:12,071][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012396] [Batch 01320/03692] [00:11:49/00:21:15, 0.538s/it]: train_loss_raw=1.8579, running_loss=1.8859, LR=0.000100
[2025-08-10 12:53:18,714][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012408] [Batch 01332/03692] [00:11:56/00:21:09, 0.538s/it]: train_loss_raw=1.8855, running_loss=1.8878, LR=0.000100
[2025-08-10 12:53:25,218][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012420] [Batch 01344/03692] [00:12:03/00:21:03, 0.538s/it]: train_loss_raw=1.8124, running_loss=1.8877, LR=0.000100
[2025-08-10 12:53:31,682][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012432] [Batch 01356/03692] [00:12:09/00:20:56, 0.538s/it]: train_loss_raw=1.8166, running_loss=1.8876, LR=0.000100
[2025-08-10 12:53:38,184][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012444] [Batch 01368/03692] [00:12:16/00:20:50, 0.538s/it]: train_loss_raw=1.8788, running_loss=1.8864, LR=0.000100
[2025-08-10 12:53:44,694][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012456] [Batch 01380/03692] [00:12:22/00:20:44, 0.538s/it]: train_loss_raw=1.8711, running_loss=1.8855, LR=0.000100
[2025-08-10 12:53:51,178][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012468] [Batch 01392/03692] [00:12:29/00:20:37, 0.538s/it]: train_loss_raw=1.9115, running_loss=1.8811, LR=0.000100
[2025-08-10 12:53:57,546][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012480] [Batch 01404/03692] [00:12:35/00:20:31, 0.538s/it]: train_loss_raw=1.8278, running_loss=1.8817, LR=0.000100
[2025-08-10 12:54:03,972][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012492] [Batch 01416/03692] [00:12:41/00:20:24, 0.538s/it]: train_loss_raw=1.8971, running_loss=1.8818, LR=0.000100
[2025-08-10 12:54:10,364][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012504] [Batch 01428/03692] [00:12:48/00:20:17, 0.538s/it]: train_loss_raw=1.8945, running_loss=1.8826, LR=0.000100
[2025-08-10 12:54:16,739][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012516] [Batch 01440/03692] [00:12:54/00:20:11, 0.538s/it]: train_loss_raw=1.8828, running_loss=1.8806, LR=0.000100
[2025-08-10 12:54:23,094][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012528] [Batch 01452/03692] [00:13:00/00:20:04, 0.538s/it]: train_loss_raw=1.8662, running_loss=1.8805, LR=0.000100
[2025-08-10 12:54:29,559][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012540] [Batch 01464/03692] [00:13:07/00:19:58, 0.538s/it]: train_loss_raw=1.7893, running_loss=1.8793, LR=0.000100
[2025-08-10 12:54:36,143][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012552] [Batch 01476/03692] [00:13:13/00:19:52, 0.538s/it]: train_loss_raw=1.8321, running_loss=1.8786, LR=0.000100
[2025-08-10 12:54:42,607][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012564] [Batch 01488/03692] [00:13:20/00:19:45, 0.538s/it]: train_loss_raw=1.8786, running_loss=1.8780, LR=0.000100
[2025-08-10 12:54:49,021][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012576] [Batch 01500/03692] [00:13:26/00:19:39, 0.538s/it]: train_loss_raw=1.9792, running_loss=1.8753, LR=0.000100
[2025-08-10 12:54:55,490][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012588] [Batch 01512/03692] [00:13:33/00:19:32, 0.538s/it]: train_loss_raw=1.9576, running_loss=1.8769, LR=0.000100
[2025-08-10 12:55:01,925][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012600] [Batch 01524/03692] [00:13:39/00:19:26, 0.538s/it]: train_loss_raw=1.8798, running_loss=1.8762, LR=0.000100
[2025-08-10 12:55:08,385][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012612] [Batch 01536/03692] [00:13:46/00:19:19, 0.538s/it]: train_loss_raw=1.9383, running_loss=1.8765, LR=0.000100
[2025-08-10 12:55:14,997][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012624] [Batch 01548/03692] [00:13:52/00:19:13, 0.538s/it]: train_loss_raw=1.8318, running_loss=1.8726, LR=0.000100
[2025-08-10 12:55:21,622][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012636] [Batch 01560/03692] [00:13:59/00:19:07, 0.538s/it]: train_loss_raw=1.8048, running_loss=1.8753, LR=0.000100
[2025-08-10 12:55:28,094][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012648] [Batch 01572/03692] [00:14:05/00:19:00, 0.538s/it]: train_loss_raw=1.9020, running_loss=1.8733, LR=0.000100
[2025-08-10 12:55:34,599][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012660] [Batch 01584/03692] [00:14:12/00:18:54, 0.538s/it]: train_loss_raw=1.9708, running_loss=1.8723, LR=0.000100
[2025-08-10 12:55:41,176][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012672] [Batch 01596/03692] [00:14:19/00:18:48, 0.538s/it]: train_loss_raw=1.8499, running_loss=1.8729, LR=0.000100
[2025-08-10 12:55:47,684][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012684] [Batch 01608/03692] [00:14:25/00:18:41, 0.538s/it]: train_loss_raw=1.7987, running_loss=1.8706, LR=0.000100
[2025-08-10 12:55:54,084][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012696] [Batch 01620/03692] [00:14:31/00:18:35, 0.538s/it]: train_loss_raw=1.8845, running_loss=1.8712, LR=0.000100
[2025-08-10 12:56:00,453][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012708] [Batch 01632/03692] [00:14:38/00:18:28, 0.538s/it]: train_loss_raw=1.9080, running_loss=1.8721, LR=0.000100
[2025-08-10 12:56:07,094][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012720] [Batch 01644/03692] [00:14:44/00:18:22, 0.538s/it]: train_loss_raw=1.8108, running_loss=1.8736, LR=0.000100
[2025-08-10 12:56:13,629][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012732] [Batch 01656/03692] [00:14:51/00:18:16, 0.538s/it]: train_loss_raw=1.8989, running_loss=1.8725, LR=0.000100
[2025-08-10 12:56:20,097][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012744] [Batch 01668/03692] [00:14:57/00:18:09, 0.538s/it]: train_loss_raw=1.9998, running_loss=1.8709, LR=0.000100
[2025-08-10 12:56:26,571][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012756] [Batch 01680/03692] [00:15:04/00:18:03, 0.538s/it]: train_loss_raw=1.7568, running_loss=1.8720, LR=0.000100
[2025-08-10 12:56:33,002][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012768] [Batch 01692/03692] [00:15:10/00:17:56, 0.538s/it]: train_loss_raw=1.8479, running_loss=1.8693, LR=0.000100
[2025-08-10 12:56:39,401][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012780] [Batch 01704/03692] [00:15:17/00:17:50, 0.538s/it]: train_loss_raw=1.9663, running_loss=1.8714, LR=0.000100
[2025-08-10 12:56:45,918][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012792] [Batch 01716/03692] [00:15:23/00:17:43, 0.538s/it]: train_loss_raw=1.9601, running_loss=1.8734, LR=0.000100
[2025-08-10 12:56:52,402][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012804] [Batch 01728/03692] [00:15:30/00:17:37, 0.538s/it]: train_loss_raw=1.9874, running_loss=1.8759, LR=0.000100
[2025-08-10 12:56:59,080][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012816] [Batch 01740/03692] [00:15:36/00:17:31, 0.538s/it]: train_loss_raw=2.0062, running_loss=1.8753, LR=0.000100
[2025-08-10 12:57:05,579][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012828] [Batch 01752/03692] [00:15:43/00:17:24, 0.538s/it]: train_loss_raw=1.9423, running_loss=1.8737, LR=0.000100
[2025-08-10 12:57:12,062][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012840] [Batch 01764/03692] [00:15:49/00:17:18, 0.539s/it]: train_loss_raw=1.9255, running_loss=1.8728, LR=0.000100
[2025-08-10 12:57:18,648][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012852] [Batch 01776/03692] [00:15:56/00:17:11, 0.539s/it]: train_loss_raw=1.8886, running_loss=1.8722, LR=0.000100
[2025-08-10 12:57:25,290][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012864] [Batch 01788/03692] [00:16:03/00:17:05, 0.539s/it]: train_loss_raw=1.8993, running_loss=1.8696, LR=0.000100
[2025-08-10 12:57:31,816][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012876] [Batch 01800/03692] [00:16:09/00:16:59, 0.539s/it]: train_loss_raw=1.8343, running_loss=1.8708, LR=0.000100
[2025-08-10 12:57:38,314][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012888] [Batch 01812/03692] [00:16:16/00:16:52, 0.539s/it]: train_loss_raw=1.7555, running_loss=1.8673, LR=0.000100
[2025-08-10 12:57:44,876][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012900] [Batch 01824/03692] [00:16:22/00:16:46, 0.539s/it]: train_loss_raw=1.9044, running_loss=1.8670, LR=0.000100
[2025-08-10 12:57:51,403][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012912] [Batch 01836/03692] [00:16:29/00:16:40, 0.539s/it]: train_loss_raw=1.8059, running_loss=1.8645, LR=0.000100
[2025-08-10 12:57:57,906][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012924] [Batch 01848/03692] [00:16:35/00:16:33, 0.539s/it]: train_loss_raw=1.8566, running_loss=1.8665, LR=0.000100
[2025-08-10 12:58:04,507][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012936] [Batch 01860/03692] [00:16:42/00:16:27, 0.539s/it]: train_loss_raw=1.9607, running_loss=1.8646, LR=0.000100
[2025-08-10 12:58:10,974][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012948] [Batch 01872/03692] [00:16:48/00:16:20, 0.539s/it]: train_loss_raw=1.7715, running_loss=1.8597, LR=0.000100
[2025-08-10 12:58:17,496][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012960] [Batch 01884/03692] [00:16:55/00:16:14, 0.539s/it]: train_loss_raw=1.9870, running_loss=1.8605, LR=0.000100
[2025-08-10 12:58:24,047][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012972] [Batch 01896/03692] [00:17:01/00:16:08, 0.539s/it]: train_loss_raw=1.7765, running_loss=1.8582, LR=0.000100
[2025-08-10 12:58:30,635][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012984] [Batch 01908/03692] [00:17:08/00:16:01, 0.539s/it]: train_loss_raw=1.8682, running_loss=1.8589, LR=0.000100
[2025-08-10 12:58:37,079][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 012996] [Batch 01920/03692] [00:17:14/00:15:55, 0.539s/it]: train_loss_raw=1.8161, running_loss=1.8560, LR=0.000100
[2025-08-10 12:58:43,397][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013008] [Batch 01932/03692] [00:17:21/00:15:48, 0.539s/it]: train_loss_raw=1.8715, running_loss=1.8587, LR=0.000100
[2025-08-10 12:58:49,912][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013020] [Batch 01944/03692] [00:17:27/00:15:42, 0.539s/it]: train_loss_raw=1.9286, running_loss=1.8588, LR=0.000100
[2025-08-10 12:58:56,466][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013032] [Batch 01956/03692] [00:17:34/00:15:35, 0.539s/it]: train_loss_raw=1.7818, running_loss=1.8583, LR=0.000100
[2025-08-10 12:59:03,044][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013044] [Batch 01968/03692] [00:17:40/00:15:29, 0.539s/it]: train_loss_raw=1.8217, running_loss=1.8562, LR=0.000100
[2025-08-10 12:59:09,678][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013056] [Batch 01980/03692] [00:17:47/00:15:23, 0.539s/it]: train_loss_raw=1.7652, running_loss=1.8573, LR=0.000100
[2025-08-10 12:59:16,266][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013068] [Batch 01992/03692] [00:17:54/00:15:16, 0.539s/it]: train_loss_raw=1.7848, running_loss=1.8569, LR=0.000100
[2025-08-10 12:59:22,819][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013080] [Batch 02004/03692] [00:18:00/00:15:10, 0.539s/it]: train_loss_raw=1.8300, running_loss=1.8566, LR=0.000100
[2025-08-10 12:59:29,395][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013092] [Batch 02016/03692] [00:18:07/00:15:03, 0.539s/it]: train_loss_raw=1.7007, running_loss=1.8559, LR=0.000100
[2025-08-10 12:59:35,896][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013104] [Batch 02028/03692] [00:18:13/00:14:57, 0.539s/it]: train_loss_raw=1.7789, running_loss=1.8549, LR=0.000100
[2025-08-10 12:59:42,422][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013116] [Batch 02040/03692] [00:18:20/00:14:51, 0.539s/it]: train_loss_raw=1.8554, running_loss=1.8589, LR=0.000100
[2025-08-10 12:59:48,992][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013128] [Batch 02052/03692] [00:18:26/00:14:44, 0.539s/it]: train_loss_raw=1.8661, running_loss=1.8598, LR=0.000100
[2025-08-10 12:59:55,565][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013140] [Batch 02064/03692] [00:18:33/00:14:38, 0.539s/it]: train_loss_raw=1.9353, running_loss=1.8625, LR=0.000100
[2025-08-10 13:00:02,137][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013152] [Batch 02076/03692] [00:18:39/00:14:31, 0.539s/it]: train_loss_raw=1.8094, running_loss=1.8626, LR=0.000100
[2025-08-10 13:00:08,673][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013164] [Batch 02088/03692] [00:18:46/00:14:25, 0.540s/it]: train_loss_raw=1.8295, running_loss=1.8614, LR=0.000100
[2025-08-10 13:00:15,339][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013176] [Batch 02100/03692] [00:18:53/00:14:19, 0.540s/it]: train_loss_raw=1.7705, running_loss=1.8589, LR=0.000100
[2025-08-10 13:00:21,957][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013188] [Batch 02112/03692] [00:18:59/00:14:12, 0.540s/it]: train_loss_raw=1.8420, running_loss=1.8610, LR=0.000100
[2025-08-10 13:00:28,491][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013200] [Batch 02124/03692] [00:19:06/00:14:06, 0.540s/it]: train_loss_raw=1.8453, running_loss=1.8601, LR=0.000100
[2025-08-10 13:00:34,949][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013212] [Batch 02136/03692] [00:19:12/00:13:59, 0.540s/it]: train_loss_raw=1.8575, running_loss=1.8602, LR=0.000100
[2025-08-10 13:00:41,457][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013224] [Batch 02148/03692] [00:19:19/00:13:53, 0.540s/it]: train_loss_raw=1.8078, running_loss=1.8565, LR=0.000100
[2025-08-10 13:00:55,161][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013236] [Batch 02160/03692] [00:19:33/00:13:51, 0.543s/it]: train_loss_raw=1.8917, running_loss=1.8593, LR=0.000100
[2025-08-10 13:01:01,582][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013248] [Batch 02172/03692] [00:19:39/00:13:45, 0.543s/it]: train_loss_raw=1.8575, running_loss=1.8577, LR=0.000100
[2025-08-10 13:01:08,101][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013260] [Batch 02184/03692] [00:19:45/00:13:38, 0.543s/it]: train_loss_raw=1.9092, running_loss=1.8547, LR=0.000100
[2025-08-10 13:01:14,577][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013272] [Batch 02196/03692] [00:19:52/00:13:32, 0.543s/it]: train_loss_raw=1.7258, running_loss=1.8535, LR=0.000100
[2025-08-10 13:01:21,093][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013284] [Batch 02208/03692] [00:19:58/00:13:25, 0.543s/it]: train_loss_raw=1.7994, running_loss=1.8498, LR=0.000100
[2025-08-10 13:01:27,688][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013296] [Batch 02220/03692] [00:20:05/00:13:19, 0.543s/it]: train_loss_raw=1.8533, running_loss=1.8502, LR=0.000100
[2025-08-10 13:01:34,307][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013308] [Batch 02232/03692] [00:20:12/00:13:12, 0.543s/it]: train_loss_raw=1.7934, running_loss=1.8484, LR=0.000100
[2025-08-10 13:01:40,743][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013320] [Batch 02244/03692] [00:20:18/00:13:06, 0.543s/it]: train_loss_raw=1.7925, running_loss=1.8484, LR=0.000100
[2025-08-10 13:01:47,255][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013332] [Batch 02256/03692] [00:20:25/00:12:59, 0.543s/it]: train_loss_raw=1.8047, running_loss=1.8486, LR=0.000100
[2025-08-10 13:01:53,695][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013344] [Batch 02268/03692] [00:20:31/00:12:53, 0.543s/it]: train_loss_raw=1.8711, running_loss=1.8448, LR=0.000100
[2025-08-10 13:02:00,186][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013356] [Batch 02280/03692] [00:20:38/00:12:46, 0.543s/it]: train_loss_raw=1.9416, running_loss=1.8429, LR=0.000100
[2025-08-10 13:02:06,653][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013368] [Batch 02292/03692] [00:20:44/00:12:40, 0.543s/it]: train_loss_raw=1.8930, running_loss=1.8470, LR=0.000100
[2025-08-10 13:02:13,077][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013380] [Batch 02304/03692] [00:20:50/00:12:33, 0.543s/it]: train_loss_raw=1.7753, running_loss=1.8457, LR=0.000100
[2025-08-10 13:02:19,482][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013392] [Batch 02316/03692] [00:20:57/00:12:27, 0.543s/it]: train_loss_raw=1.7648, running_loss=1.8475, LR=0.000100
[2025-08-10 13:02:25,936][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013404] [Batch 02328/03692] [00:21:03/00:12:20, 0.543s/it]: train_loss_raw=1.7696, running_loss=1.8459, LR=0.000100
[2025-08-10 13:02:32,360][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013416] [Batch 02340/03692] [00:21:10/00:12:13, 0.543s/it]: train_loss_raw=1.7683, running_loss=1.8410, LR=0.000100
[2025-08-10 13:02:38,877][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013428] [Batch 02352/03692] [00:21:16/00:12:07, 0.543s/it]: train_loss_raw=1.8720, running_loss=1.8438, LR=0.000100
[2025-08-10 13:02:45,489][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013440] [Batch 02364/03692] [00:21:23/00:12:00, 0.543s/it]: train_loss_raw=1.7464, running_loss=1.8430, LR=0.000100
[2025-08-10 13:02:51,925][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013452] [Batch 02376/03692] [00:21:29/00:11:54, 0.543s/it]: train_loss_raw=1.8353, running_loss=1.8420, LR=0.000100
[2025-08-10 13:02:58,368][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013464] [Batch 02388/03692] [00:21:36/00:11:47, 0.543s/it]: train_loss_raw=1.8212, running_loss=1.8441, LR=0.000100
[2025-08-10 13:03:04,973][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013476] [Batch 02400/03692] [00:21:42/00:11:41, 0.543s/it]: train_loss_raw=1.8518, running_loss=1.8446, LR=0.000100
[2025-08-10 13:03:11,545][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013488] [Batch 02412/03692] [00:21:49/00:11:34, 0.543s/it]: train_loss_raw=1.7887, running_loss=1.8397, LR=0.000100
[2025-08-10 13:03:18,016][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013500] [Batch 02424/03692] [00:21:55/00:11:28, 0.543s/it]: train_loss_raw=1.9524, running_loss=1.8453, LR=0.000100
[2025-08-10 13:03:24,433][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013512] [Batch 02436/03692] [00:22:02/00:11:21, 0.543s/it]: train_loss_raw=1.8139, running_loss=1.8445, LR=0.000100
[2025-08-10 13:03:30,876][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013524] [Batch 02448/03692] [00:22:08/00:11:15, 0.543s/it]: train_loss_raw=1.8077, running_loss=1.8442, LR=0.000100
[2025-08-10 13:03:37,324][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013536] [Batch 02460/03692] [00:22:15/00:11:08, 0.543s/it]: train_loss_raw=1.8515, running_loss=1.8405, LR=0.000100
[2025-08-10 13:03:43,890][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013548] [Batch 02472/03692] [00:22:21/00:11:02, 0.543s/it]: train_loss_raw=1.8049, running_loss=1.8443, LR=0.000100
[2025-08-10 13:03:50,372][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013560] [Batch 02484/03692] [00:22:28/00:10:55, 0.543s/it]: train_loss_raw=1.7734, running_loss=1.8433, LR=0.000100
[2025-08-10 13:03:56,800][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013572] [Batch 02496/03692] [00:22:34/00:10:49, 0.543s/it]: train_loss_raw=1.9104, running_loss=1.8439, LR=0.000100
[2025-08-10 13:04:03,443][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013584] [Batch 02508/03692] [00:22:41/00:10:42, 0.543s/it]: train_loss_raw=1.8376, running_loss=1.8431, LR=0.000100
[2025-08-10 13:04:10,090][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013596] [Batch 02520/03692] [00:22:47/00:10:36, 0.543s/it]: train_loss_raw=1.8730, running_loss=1.8396, LR=0.000100
[2025-08-10 13:04:16,549][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013608] [Batch 02532/03692] [00:22:54/00:10:29, 0.543s/it]: train_loss_raw=1.7971, running_loss=1.8326, LR=0.000100
[2025-08-10 13:04:23,080][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013620] [Batch 02544/03692] [00:23:00/00:10:23, 0.543s/it]: train_loss_raw=1.9132, running_loss=1.8323, LR=0.000100
[2025-08-10 13:04:29,523][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013632] [Batch 02556/03692] [00:23:07/00:10:16, 0.543s/it]: train_loss_raw=1.8068, running_loss=1.8288, LR=0.000100
[2025-08-10 13:04:35,956][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013644] [Batch 02568/03692] [00:23:13/00:10:10, 0.543s/it]: train_loss_raw=1.9294, running_loss=1.8323, LR=0.000100
[2025-08-10 13:04:42,380][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013656] [Batch 02580/03692] [00:23:20/00:10:03, 0.543s/it]: train_loss_raw=1.8589, running_loss=1.8351, LR=0.000100
[2025-08-10 13:04:48,847][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013668] [Batch 02592/03692] [00:23:26/00:09:56, 0.543s/it]: train_loss_raw=1.8894, running_loss=1.8372, LR=0.000100
[2025-08-10 13:04:55,302][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013680] [Batch 02604/03692] [00:23:33/00:09:50, 0.543s/it]: train_loss_raw=1.8036, running_loss=1.8353, LR=0.000100
[2025-08-10 13:05:01,804][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013692] [Batch 02616/03692] [00:23:39/00:09:43, 0.543s/it]: train_loss_raw=1.7249, running_loss=1.8319, LR=0.000100
[2025-08-10 13:05:08,267][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013704] [Batch 02628/03692] [00:23:46/00:09:37, 0.543s/it]: train_loss_raw=1.7808, running_loss=1.8303, LR=0.000100
[2025-08-10 13:05:14,777][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013716] [Batch 02640/03692] [00:23:52/00:09:30, 0.543s/it]: train_loss_raw=1.7837, running_loss=1.8293, LR=0.000100
[2025-08-10 13:05:21,338][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013728] [Batch 02652/03692] [00:23:59/00:09:24, 0.543s/it]: train_loss_raw=1.7592, running_loss=1.8283, LR=0.000100
[2025-08-10 13:05:27,868][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013740] [Batch 02664/03692] [00:24:05/00:09:17, 0.543s/it]: train_loss_raw=1.8480, running_loss=1.8273, LR=0.000100
[2025-08-10 13:05:34,459][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013752] [Batch 02676/03692] [00:24:12/00:09:11, 0.543s/it]: train_loss_raw=1.8813, running_loss=1.8269, LR=0.000100
[2025-08-10 13:05:40,922][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013764] [Batch 02688/03692] [00:24:18/00:09:04, 0.543s/it]: train_loss_raw=1.8858, running_loss=1.8266, LR=0.000100
[2025-08-10 13:05:47,480][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013776] [Batch 02700/03692] [00:24:25/00:08:58, 0.543s/it]: train_loss_raw=1.8032, running_loss=1.8292, LR=0.000100
[2025-08-10 13:05:54,044][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013788] [Batch 02712/03692] [00:24:31/00:08:51, 0.543s/it]: train_loss_raw=1.8917, running_loss=1.8296, LR=0.000100
[2025-08-10 13:06:00,563][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013800] [Batch 02724/03692] [00:24:38/00:08:45, 0.543s/it]: train_loss_raw=1.8886, running_loss=1.8335, LR=0.000100
[2025-08-10 13:06:06,989][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013812] [Batch 02736/03692] [00:24:44/00:08:38, 0.543s/it]: train_loss_raw=1.8625, running_loss=1.8365, LR=0.000100
[2025-08-10 13:06:13,386][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013824] [Batch 02748/03692] [00:24:51/00:08:32, 0.543s/it]: train_loss_raw=1.8268, running_loss=1.8331, LR=0.000100
[2025-08-10 13:06:19,789][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013836] [Batch 02760/03692] [00:24:57/00:08:25, 0.543s/it]: train_loss_raw=1.8896, running_loss=1.8303, LR=0.000100
[2025-08-10 13:06:26,152][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013848] [Batch 02772/03692] [00:25:04/00:08:19, 0.543s/it]: train_loss_raw=1.9039, running_loss=1.8311, LR=0.000100
[2025-08-10 13:06:32,623][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013860] [Batch 02784/03692] [00:25:10/00:08:12, 0.543s/it]: train_loss_raw=1.7554, running_loss=1.8259, LR=0.000100
[2025-08-10 13:06:39,086][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013872] [Batch 02796/03692] [00:25:16/00:08:06, 0.543s/it]: train_loss_raw=1.9020, running_loss=1.8244, LR=0.000100
[2025-08-10 13:06:45,536][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013884] [Batch 02808/03692] [00:25:23/00:07:59, 0.543s/it]: train_loss_raw=1.7308, running_loss=1.8226, LR=0.000100
[2025-08-10 13:06:52,069][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013896] [Batch 02820/03692] [00:25:29/00:07:53, 0.543s/it]: train_loss_raw=1.8601, running_loss=1.8228, LR=0.000100
[2025-08-10 13:06:58,552][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013908] [Batch 02832/03692] [00:25:36/00:07:46, 0.543s/it]: train_loss_raw=1.8420, running_loss=1.8226, LR=0.000100
[2025-08-10 13:07:04,896][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013920] [Batch 02844/03692] [00:25:42/00:07:40, 0.542s/it]: train_loss_raw=1.7526, running_loss=1.8208, LR=0.000100
[2025-08-10 13:07:11,072][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013932] [Batch 02856/03692] [00:25:48/00:07:33, 0.542s/it]: train_loss_raw=1.9512, running_loss=1.8219, LR=0.000100
[2025-08-10 13:07:17,326][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013944] [Batch 02868/03692] [00:25:55/00:07:26, 0.542s/it]: train_loss_raw=1.8639, running_loss=1.8275, LR=0.000100
[2025-08-10 13:07:23,569][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013956] [Batch 02880/03692] [00:26:01/00:07:20, 0.542s/it]: train_loss_raw=1.8298, running_loss=1.8268, LR=0.000100
[2025-08-10 13:07:29,938][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013968] [Batch 02892/03692] [00:26:07/00:07:13, 0.542s/it]: train_loss_raw=1.7809, running_loss=1.8243, LR=0.000100
[2025-08-10 13:07:36,462][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013980] [Batch 02904/03692] [00:26:14/00:07:07, 0.542s/it]: train_loss_raw=1.7798, running_loss=1.8212, LR=0.000100
[2025-08-10 13:07:42,828][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 013992] [Batch 02916/03692] [00:26:20/00:07:00, 0.542s/it]: train_loss_raw=1.8093, running_loss=1.8215, LR=0.000100
[2025-08-10 13:07:53,317][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014004] [Batch 02928/03692] [00:26:31/00:06:55, 0.543s/it]: train_loss_raw=1.8678, running_loss=1.8170, LR=0.000100
[2025-08-10 13:07:59,741][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014016] [Batch 02940/03692] [00:26:37/00:06:48, 0.543s/it]: train_loss_raw=1.7802, running_loss=1.8184, LR=0.000100
[2025-08-10 13:08:06,013][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014028] [Batch 02952/03692] [00:26:43/00:06:42, 0.543s/it]: train_loss_raw=1.8240, running_loss=1.8192, LR=0.000100
[2025-08-10 13:08:12,213][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014040] [Batch 02964/03692] [00:26:50/00:06:35, 0.543s/it]: train_loss_raw=1.9008, running_loss=1.8188, LR=0.000100
[2025-08-10 13:08:18,488][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014052] [Batch 02976/03692] [00:26:56/00:06:28, 0.543s/it]: train_loss_raw=1.8316, running_loss=1.8192, LR=0.000100
[2025-08-10 13:08:24,881][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014064] [Batch 02988/03692] [00:27:02/00:06:22, 0.543s/it]: train_loss_raw=1.8193, running_loss=1.8202, LR=0.000100
[2025-08-10 13:08:31,210][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014076] [Batch 03000/03692] [00:27:09/00:06:15, 0.543s/it]: train_loss_raw=1.7680, running_loss=1.8178, LR=0.000100
[2025-08-10 13:08:37,603][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014088] [Batch 03012/03692] [00:27:15/00:06:09, 0.543s/it]: train_loss_raw=1.6575, running_loss=1.8119, LR=0.000100
[2025-08-10 13:08:44,001][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014100] [Batch 03024/03692] [00:27:21/00:06:02, 0.543s/it]: train_loss_raw=1.7922, running_loss=1.8156, LR=0.000100
[2025-08-10 13:08:50,485][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014112] [Batch 03036/03692] [00:27:28/00:05:56, 0.543s/it]: train_loss_raw=1.8996, running_loss=1.8146, LR=0.000100
[2025-08-10 13:08:56,930][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014124] [Batch 03048/03692] [00:27:34/00:05:49, 0.543s/it]: train_loss_raw=1.7500, running_loss=1.8147, LR=0.000100
[2025-08-10 13:09:03,392][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014136] [Batch 03060/03692] [00:27:41/00:05:43, 0.543s/it]: train_loss_raw=1.8841, running_loss=1.8143, LR=0.000100
[2025-08-10 13:09:10,023][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014148] [Batch 03072/03692] [00:27:47/00:05:36, 0.543s/it]: train_loss_raw=1.8925, running_loss=1.8171, LR=0.000100
[2025-08-10 13:09:16,670][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014160] [Batch 03084/03692] [00:27:54/00:05:30, 0.543s/it]: train_loss_raw=1.8528, running_loss=1.8164, LR=0.000100
[2025-08-10 13:09:23,256][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014172] [Batch 03096/03692] [00:28:01/00:05:23, 0.543s/it]: train_loss_raw=1.6809, running_loss=1.8145, LR=0.000100
[2025-08-10 13:09:29,769][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014184] [Batch 03108/03692] [00:28:07/00:05:17, 0.543s/it]: train_loss_raw=1.7741, running_loss=1.8106, LR=0.000100
[2025-08-10 13:09:37,154][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014196] [Batch 03120/03692] [00:28:15/00:05:10, 0.543s/it]: train_loss_raw=1.8061, running_loss=1.8079, LR=0.000100
[2025-08-10 13:09:44,047][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014208] [Batch 03132/03692] [00:28:21/00:05:04, 0.543s/it]: train_loss_raw=1.9133, running_loss=1.8075, LR=0.000100
[2025-08-10 13:09:50,828][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014220] [Batch 03144/03692] [00:28:28/00:04:57, 0.543s/it]: train_loss_raw=1.8216, running_loss=1.8081, LR=0.000100
[2025-08-10 13:09:57,581][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014232] [Batch 03156/03692] [00:28:35/00:04:51, 0.544s/it]: train_loss_raw=1.8918, running_loss=1.8062, LR=0.000100
[2025-08-10 13:10:04,153][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014244] [Batch 03168/03692] [00:28:42/00:04:44, 0.544s/it]: train_loss_raw=1.8922, running_loss=1.8078, LR=0.000100
[2025-08-10 13:10:10,775][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014256] [Batch 03180/03692] [00:28:48/00:04:38, 0.544s/it]: train_loss_raw=1.8783, running_loss=1.8114, LR=0.000100
[2025-08-10 13:10:17,424][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014268] [Batch 03192/03692] [00:28:55/00:04:31, 0.544s/it]: train_loss_raw=1.7604, running_loss=1.8105, LR=0.000100
[2025-08-10 13:10:24,061][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014280] [Batch 03204/03692] [00:29:01/00:04:25, 0.544s/it]: train_loss_raw=1.6615, running_loss=1.8096, LR=0.000100
[2025-08-10 13:10:30,720][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014292] [Batch 03216/03692] [00:29:08/00:04:18, 0.544s/it]: train_loss_raw=1.8071, running_loss=1.8095, LR=0.000100
[2025-08-10 13:10:37,092][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014304] [Batch 03228/03692] [00:29:14/00:04:12, 0.544s/it]: train_loss_raw=1.7525, running_loss=1.8081, LR=0.000100
[2025-08-10 13:10:43,536][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014316] [Batch 03240/03692] [00:29:21/00:04:05, 0.544s/it]: train_loss_raw=1.7989, running_loss=1.8097, LR=0.000100
[2025-08-10 13:10:49,910][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014328] [Batch 03252/03692] [00:29:27/00:03:59, 0.544s/it]: train_loss_raw=1.7429, running_loss=1.8072, LR=0.000100
[2025-08-10 13:10:56,395][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014340] [Batch 03264/03692] [00:29:34/00:03:52, 0.544s/it]: train_loss_raw=1.8790, running_loss=1.8077, LR=0.000100
[2025-08-10 13:11:02,806][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014352] [Batch 03276/03692] [00:29:40/00:03:46, 0.544s/it]: train_loss_raw=1.8659, running_loss=1.8102, LR=0.000100
[2025-08-10 13:11:09,112][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014364] [Batch 03288/03692] [00:29:46/00:03:39, 0.543s/it]: train_loss_raw=1.8635, running_loss=1.8118, LR=0.000100
[2025-08-10 13:11:15,561][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014376] [Batch 03300/03692] [00:29:53/00:03:33, 0.543s/it]: train_loss_raw=1.8723, running_loss=1.8121, LR=0.000100
[2025-08-10 13:11:22,177][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014388] [Batch 03312/03692] [00:30:00/00:03:26, 0.543s/it]: train_loss_raw=1.9669, running_loss=1.8075, LR=0.000100
[2025-08-10 13:11:28,839][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014400] [Batch 03324/03692] [00:30:06/00:03:20, 0.544s/it]: train_loss_raw=1.8213, running_loss=1.8056, LR=0.000100
[2025-08-10 13:11:35,403][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014412] [Batch 03336/03692] [00:30:13/00:03:13, 0.544s/it]: train_loss_raw=1.7459, running_loss=1.8059, LR=0.000100
[2025-08-10 13:11:42,040][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014424] [Batch 03348/03692] [00:30:19/00:03:06, 0.544s/it]: train_loss_raw=1.7114, running_loss=1.8064, LR=0.000100
[2025-08-10 13:11:48,558][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014436] [Batch 03360/03692] [00:30:26/00:03:00, 0.544s/it]: train_loss_raw=1.9037, running_loss=1.8033, LR=0.000100
[2025-08-10 13:11:55,175][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014448] [Batch 03372/03692] [00:30:33/00:02:53, 0.544s/it]: train_loss_raw=1.8438, running_loss=1.8014, LR=0.000100
[2025-08-10 13:12:01,804][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014460] [Batch 03384/03692] [00:30:39/00:02:47, 0.544s/it]: train_loss_raw=1.8214, running_loss=1.8036, LR=0.000100
[2025-08-10 13:12:08,325][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014472] [Batch 03396/03692] [00:30:46/00:02:40, 0.544s/it]: train_loss_raw=1.8166, running_loss=1.8035, LR=0.000100
[2025-08-10 13:12:14,933][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014484] [Batch 03408/03692] [00:30:52/00:02:34, 0.544s/it]: train_loss_raw=1.7773, running_loss=1.7987, LR=0.000100
[2025-08-10 13:12:21,562][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014496] [Batch 03420/03692] [00:30:59/00:02:27, 0.544s/it]: train_loss_raw=1.8792, running_loss=1.7993, LR=0.000100
[2025-08-10 13:12:28,275][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014508] [Batch 03432/03692] [00:31:06/00:02:21, 0.544s/it]: train_loss_raw=1.8035, running_loss=1.7946, LR=0.000100
[2025-08-10 13:12:34,887][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014520] [Batch 03444/03692] [00:31:12/00:02:14, 0.544s/it]: train_loss_raw=1.8154, running_loss=1.7918, LR=0.000100
[2025-08-10 13:12:41,399][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014532] [Batch 03456/03692] [00:31:19/00:02:08, 0.544s/it]: train_loss_raw=1.7535, running_loss=1.7894, LR=0.000100
[2025-08-10 13:12:47,941][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014544] [Batch 03468/03692] [00:31:25/00:02:01, 0.544s/it]: train_loss_raw=1.7308, running_loss=1.7938, LR=0.000100
[2025-08-10 13:12:54,571][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014556] [Batch 03480/03692] [00:31:32/00:01:55, 0.544s/it]: train_loss_raw=1.8374, running_loss=1.7930, LR=0.000100
[2025-08-10 13:13:01,006][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014568] [Batch 03492/03692] [00:31:38/00:01:48, 0.544s/it]: train_loss_raw=1.8428, running_loss=1.7934, LR=0.000100
[2025-08-10 13:13:07,298][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014580] [Batch 03504/03692] [00:31:45/00:01:42, 0.544s/it]: train_loss_raw=1.7860, running_loss=1.7956, LR=0.000100
[2025-08-10 13:13:13,608][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014592] [Batch 03516/03692] [00:31:51/00:01:35, 0.544s/it]: train_loss_raw=1.8094, running_loss=1.7982, LR=0.000100
[2025-08-10 13:13:19,933][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014604] [Batch 03528/03692] [00:31:57/00:01:29, 0.544s/it]: train_loss_raw=1.9379, running_loss=1.7998, LR=0.000100
[2025-08-10 13:13:26,234][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014616] [Batch 03540/03692] [00:32:04/00:01:22, 0.544s/it]: train_loss_raw=1.8107, running_loss=1.8015, LR=0.000100
[2025-08-10 13:13:32,565][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014628] [Batch 03552/03692] [00:32:10/00:01:16, 0.543s/it]: train_loss_raw=1.6650, running_loss=1.7976, LR=0.000100
[2025-08-10 13:13:38,977][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014640] [Batch 03564/03692] [00:32:16/00:01:09, 0.543s/it]: train_loss_raw=1.7842, running_loss=1.7957, LR=0.000100
[2025-08-10 13:13:45,446][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014652] [Batch 03576/03692] [00:32:23/00:01:03, 0.543s/it]: train_loss_raw=1.7182, running_loss=1.7958, LR=0.000100
[2025-08-10 13:13:52,024][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014664] [Batch 03588/03692] [00:32:29/00:00:56, 0.543s/it]: train_loss_raw=1.6982, running_loss=1.7959, LR=0.000100
[2025-08-10 13:13:58,627][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014676] [Batch 03600/03692] [00:32:36/00:00:49, 0.543s/it]: train_loss_raw=1.8196, running_loss=1.7977, LR=0.000100
[2025-08-10 13:14:05,239][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014688] [Batch 03612/03692] [00:32:43/00:00:43, 0.543s/it]: train_loss_raw=1.7519, running_loss=1.7988, LR=0.000100
[2025-08-10 13:14:11,797][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014700] [Batch 03624/03692] [00:32:49/00:00:36, 0.544s/it]: train_loss_raw=1.7891, running_loss=1.7988, LR=0.000100
[2025-08-10 13:14:18,563][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014712] [Batch 03636/03692] [00:32:56/00:00:30, 0.544s/it]: train_loss_raw=1.8587, running_loss=1.7974, LR=0.000100
[2025-08-10 13:14:25,172][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014724] [Batch 03648/03692] [00:33:03/00:00:23, 0.544s/it]: train_loss_raw=1.6198, running_loss=1.7935, LR=0.000100
[2025-08-10 13:14:31,560][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014736] [Batch 03660/03692] [00:33:09/00:00:17, 0.544s/it]: train_loss_raw=1.7623, running_loss=1.7972, LR=0.000100
[2025-08-10 13:14:37,890][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014748] [Batch 03672/03692] [00:33:15/00:00:10, 0.544s/it]: train_loss_raw=1.8278, running_loss=1.7979, LR=0.000100
[2025-08-10 13:14:44,243][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014760] [Batch 03684/03692] [00:33:22/00:00:04, 0.543s/it]: train_loss_raw=1.7724, running_loss=1.7954, LR=0.000100
[2025-08-10 13:15:25,390][__main__][INFO] - [VALIDATION] [Epoch 03/29] Starting validation.
[2025-08-10 13:15:59,993][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 014769] [Batch 00011/00025] [00:00:34/00:00:37, 2.884s/it]
[2025-08-10 13:16:17,716][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 014769] [Batch 00023/00025] [00:00:52/00:00:02, 2.180s/it]
[2025-08-10 13:16:18,834][__main__][INFO] - [VALIDATION] [Epoch 03/29] train_loss=1.79419, valid_loss=1.71588
[2025-08-10 13:16:18,835][__main__][INFO] - [VALIDATION] [Epoch 03/29] Metrics:
[2025-08-10 13:16:18,835][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_er      0.711
[2025-08-10 13:16:18,835][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_prec    0.052
[2025-08-10 13:16:18,835][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_recall  0.053
[2025-08-10 13:16:18,836][__main__][INFO] - [VALIDATION] [Epoch 03/29] - pep_recall 0.010
[2025-08-10 13:16:18,838][__main__][INFO] - [TRAIN] [Epoch 03/29] Epoch complete, total time 02:20:18, remaining time 15:11:57, 00:35:04 per epoch
[2025-08-10 13:16:21,717][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014772] [Batch 00004/03692] [00:00:01/00:27:28, 0.447s/it]: train_loss_raw=1.7536, running_loss=1.7814, LR=0.000100
[2025-08-10 13:16:28,388][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014784] [Batch 00016/03692] [00:00:08/00:32:23, 0.529s/it]: train_loss_raw=1.9286, running_loss=1.7796, LR=0.000100
[2025-08-10 13:16:34,737][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014796] [Batch 00028/03692] [00:00:14/00:32:17, 0.529s/it]: train_loss_raw=1.7674, running_loss=1.7796, LR=0.000100
[2025-08-10 13:16:41,210][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014808] [Batch 00040/03692] [00:00:21/00:32:22, 0.532s/it]: train_loss_raw=1.8414, running_loss=1.7791, LR=0.000100
[2025-08-10 13:16:47,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014820] [Batch 00052/03692] [00:00:27/00:32:23, 0.534s/it]: train_loss_raw=1.6723, running_loss=1.7776, LR=0.000100
[2025-08-10 13:16:54,038][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014832] [Batch 00064/03692] [00:00:34/00:32:13, 0.533s/it]: train_loss_raw=1.6487, running_loss=1.7744, LR=0.000100
[2025-08-10 13:17:00,112][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014844] [Batch 00076/03692] [00:00:40/00:31:51, 0.529s/it]: train_loss_raw=1.6978, running_loss=1.7752, LR=0.000100
[2025-08-10 13:17:06,540][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014856] [Batch 00088/03692] [00:00:46/00:31:48, 0.530s/it]: train_loss_raw=1.6630, running_loss=1.7692, LR=0.000100
[2025-08-10 13:17:13,094][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014868] [Batch 00100/03692] [00:00:53/00:31:49, 0.532s/it]: train_loss_raw=1.6682, running_loss=1.7611, LR=0.000100
[2025-08-10 13:17:19,657][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014880] [Batch 00112/03692] [00:00:59/00:31:49, 0.533s/it]: train_loss_raw=1.7622, running_loss=1.7639, LR=0.000100
[2025-08-10 13:17:26,183][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014892] [Batch 00124/03692] [00:01:06/00:31:46, 0.534s/it]: train_loss_raw=1.7190, running_loss=1.7637, LR=0.000100
[2025-08-10 13:17:32,430][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014904] [Batch 00136/03692] [00:01:12/00:31:35, 0.533s/it]: train_loss_raw=1.7227, running_loss=1.7652, LR=0.000100
[2025-08-10 13:17:38,733][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014916] [Batch 00148/03692] [00:01:18/00:31:27, 0.532s/it]: train_loss_raw=1.7530, running_loss=1.7675, LR=0.000100
[2025-08-10 13:17:45,286][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014928] [Batch 00160/03692] [00:01:25/00:31:24, 0.533s/it]: train_loss_raw=1.7736, running_loss=1.7682, LR=0.000100
[2025-08-10 13:17:51,829][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014940] [Batch 00172/03692] [00:01:31/00:31:20, 0.534s/it]: train_loss_raw=1.6890, running_loss=1.7686, LR=0.000100
[2025-08-10 13:17:58,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014952] [Batch 00184/03692] [00:01:38/00:31:16, 0.535s/it]: train_loss_raw=1.6543, running_loss=1.7659, LR=0.000100
[2025-08-10 13:18:04,896][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014964] [Batch 00196/03692] [00:01:44/00:31:12, 0.536s/it]: train_loss_raw=1.7240, running_loss=1.7658, LR=0.000100
[2025-08-10 13:18:11,230][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014976] [Batch 00208/03692] [00:01:51/00:31:04, 0.535s/it]: train_loss_raw=1.8387, running_loss=1.7675, LR=0.000100
[2025-08-10 13:18:17,523][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 014988] [Batch 00220/03692] [00:01:57/00:30:55, 0.535s/it]: train_loss_raw=1.7269, running_loss=1.7681, LR=0.000100
[2025-08-10 13:18:23,707][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015000] [Batch 00232/03692] [00:02:03/00:30:45, 0.534s/it]: train_loss_raw=1.8370, running_loss=1.7686, LR=0.000100
[2025-08-10 13:18:29,822][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015012] [Batch 00244/03692] [00:02:09/00:30:35, 0.532s/it]: train_loss_raw=1.7851, running_loss=1.7650, LR=0.000100
[2025-08-10 13:18:36,157][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015024] [Batch 00256/03692] [00:02:16/00:30:28, 0.532s/it]: train_loss_raw=1.6583, running_loss=1.7631, LR=0.000100
[2025-08-10 13:18:42,587][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015036] [Batch 00268/03692] [00:02:22/00:30:22, 0.532s/it]: train_loss_raw=1.7342, running_loss=1.7595, LR=0.000100
[2025-08-10 13:18:49,130][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015048] [Batch 00280/03692] [00:02:29/00:30:18, 0.533s/it]: train_loss_raw=1.6642, running_loss=1.7552, LR=0.000100
[2025-08-10 13:18:55,608][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015060] [Batch 00292/03692] [00:02:35/00:30:12, 0.533s/it]: train_loss_raw=1.6817, running_loss=1.7564, LR=0.000100
[2025-08-10 13:19:02,140][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015072] [Batch 00304/03692] [00:02:42/00:30:07, 0.534s/it]: train_loss_raw=1.7698, running_loss=1.7605, LR=0.000100
[2025-08-10 13:19:08,669][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015084] [Batch 00316/03692] [00:02:48/00:30:02, 0.534s/it]: train_loss_raw=1.6603, running_loss=1.7621, LR=0.000100
[2025-08-10 13:19:15,193][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015096] [Batch 00328/03692] [00:02:55/00:29:57, 0.534s/it]: train_loss_raw=1.7045, running_loss=1.7631, LR=0.000100
[2025-08-10 13:19:21,883][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015108] [Batch 00340/03692] [00:03:01/00:29:53, 0.535s/it]: train_loss_raw=1.7577, running_loss=1.7589, LR=0.000100
[2025-08-10 13:19:28,498][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015120] [Batch 00352/03692] [00:03:08/00:29:49, 0.536s/it]: train_loss_raw=1.8057, running_loss=1.7611, LR=0.000100
[2025-08-10 13:19:35,061][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015132] [Batch 00364/03692] [00:03:15/00:29:44, 0.536s/it]: train_loss_raw=1.7093, running_loss=1.7579, LR=0.000100
[2025-08-10 13:19:41,646][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015144] [Batch 00376/03692] [00:03:21/00:29:38, 0.536s/it]: train_loss_raw=1.8112, running_loss=1.7551, LR=0.000100
[2025-08-10 13:19:48,227][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015156] [Batch 00388/03692] [00:03:28/00:29:33, 0.537s/it]: train_loss_raw=1.6968, running_loss=1.7521, LR=0.000100
[2025-08-10 13:19:54,802][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015168] [Batch 00400/03692] [00:03:34/00:29:28, 0.537s/it]: train_loss_raw=1.7791, running_loss=1.7536, LR=0.000100
[2025-08-10 13:20:01,379][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015180] [Batch 00412/03692] [00:03:41/00:29:22, 0.537s/it]: train_loss_raw=1.7015, running_loss=1.7540, LR=0.000100
[2025-08-10 13:20:07,945][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015192] [Batch 00424/03692] [00:03:48/00:29:17, 0.538s/it]: train_loss_raw=1.6605, running_loss=1.7475, LR=0.000100
[2025-08-10 13:20:14,560][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015204] [Batch 00436/03692] [00:03:54/00:29:12, 0.538s/it]: train_loss_raw=1.8609, running_loss=1.7489, LR=0.000100
[2025-08-10 13:20:21,159][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015216] [Batch 00448/03692] [00:04:01/00:29:06, 0.538s/it]: train_loss_raw=1.8662, running_loss=1.7484, LR=0.000100
[2025-08-10 13:20:27,732][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015228] [Batch 00460/03692] [00:04:07/00:29:01, 0.539s/it]: train_loss_raw=1.8668, running_loss=1.7509, LR=0.000100
[2025-08-10 13:20:34,079][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015240] [Batch 00472/03692] [00:04:14/00:28:53, 0.538s/it]: train_loss_raw=1.7448, running_loss=1.7525, LR=0.000100
[2025-08-10 13:20:40,612][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015252] [Batch 00484/03692] [00:04:20/00:28:47, 0.539s/it]: train_loss_raw=1.9000, running_loss=1.7533, LR=0.000100
[2025-08-10 13:20:46,856][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015264] [Batch 00496/03692] [00:04:26/00:28:39, 0.538s/it]: train_loss_raw=1.7703, running_loss=1.7559, LR=0.000100
[2025-08-10 13:20:53,157][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015276] [Batch 00508/03692] [00:04:33/00:28:32, 0.538s/it]: train_loss_raw=1.7599, running_loss=1.7557, LR=0.000100
[2025-08-10 13:20:59,397][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015288] [Batch 00520/03692] [00:04:39/00:28:24, 0.537s/it]: train_loss_raw=1.8352, running_loss=1.7585, LR=0.000100
[2025-08-10 13:21:05,802][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015300] [Batch 00532/03692] [00:04:45/00:28:18, 0.537s/it]: train_loss_raw=1.8063, running_loss=1.7610, LR=0.000100
[2025-08-10 13:21:12,294][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015312] [Batch 00544/03692] [00:04:52/00:28:11, 0.537s/it]: train_loss_raw=1.7604, running_loss=1.7592, LR=0.000100
[2025-08-10 13:21:18,869][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015324] [Batch 00556/03692] [00:04:58/00:28:06, 0.538s/it]: train_loss_raw=1.7911, running_loss=1.7586, LR=0.000100
[2025-08-10 13:21:25,335][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015336] [Batch 00568/03692] [00:05:05/00:27:59, 0.538s/it]: train_loss_raw=1.7627, running_loss=1.7578, LR=0.000100
[2025-08-10 13:21:31,583][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015348] [Batch 00580/03692] [00:05:11/00:27:52, 0.537s/it]: train_loss_raw=1.8162, running_loss=1.7552, LR=0.000100
[2025-08-10 13:21:37,813][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015360] [Batch 00592/03692] [00:05:17/00:27:44, 0.537s/it]: train_loss_raw=1.8278, running_loss=1.7542, LR=0.000100
[2025-08-10 13:21:43,908][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015372] [Batch 00604/03692] [00:05:23/00:27:36, 0.536s/it]: train_loss_raw=1.7154, running_loss=1.7509, LR=0.000100
[2025-08-10 13:21:50,424][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015384] [Batch 00616/03692] [00:05:30/00:27:30, 0.537s/it]: train_loss_raw=1.6208, running_loss=1.7501, LR=0.000100
[2025-08-10 13:21:57,026][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015396] [Batch 00628/03692] [00:05:37/00:27:24, 0.537s/it]: train_loss_raw=1.7153, running_loss=1.7493, LR=0.000100
[2025-08-10 13:22:03,618][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015408] [Batch 00640/03692] [00:05:43/00:27:18, 0.537s/it]: train_loss_raw=1.8300, running_loss=1.7490, LR=0.000100
[2025-08-10 13:22:10,204][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015420] [Batch 00652/03692] [00:05:50/00:27:13, 0.537s/it]: train_loss_raw=1.8450, running_loss=1.7522, LR=0.000100
[2025-08-10 13:22:16,756][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015432] [Batch 00664/03692] [00:05:56/00:27:07, 0.537s/it]: train_loss_raw=1.8089, running_loss=1.7550, LR=0.000100
[2025-08-10 13:22:23,228][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015444] [Batch 00676/03692] [00:06:03/00:27:00, 0.537s/it]: train_loss_raw=1.6232, running_loss=1.7512, LR=0.000100
[2025-08-10 13:22:29,495][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015456] [Batch 00688/03692] [00:06:09/00:26:53, 0.537s/it]: train_loss_raw=1.6393, running_loss=1.7491, LR=0.000100
[2025-08-10 13:22:35,741][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015468] [Batch 00700/03692] [00:06:15/00:26:46, 0.537s/it]: train_loss_raw=1.7962, running_loss=1.7495, LR=0.000100
[2025-08-10 13:22:42,009][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015480] [Batch 00712/03692] [00:06:22/00:26:39, 0.537s/it]: train_loss_raw=1.6572, running_loss=1.7480, LR=0.000100
[2025-08-10 13:22:48,496][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015492] [Batch 00724/03692] [00:06:28/00:26:32, 0.537s/it]: train_loss_raw=1.7254, running_loss=1.7447, LR=0.000100
[2025-08-10 13:22:54,882][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015504] [Batch 00736/03692] [00:06:34/00:26:26, 0.537s/it]: train_loss_raw=1.6336, running_loss=1.7440, LR=0.000100
[2025-08-10 13:23:01,349][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015516] [Batch 00748/03692] [00:06:41/00:26:19, 0.537s/it]: train_loss_raw=1.5296, running_loss=1.7417, LR=0.000100
[2025-08-10 13:23:07,697][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015528] [Batch 00760/03692] [00:06:47/00:26:13, 0.537s/it]: train_loss_raw=1.6152, running_loss=1.7420, LR=0.000100
[2025-08-10 13:23:14,147][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015540] [Batch 00772/03692] [00:06:54/00:26:06, 0.537s/it]: train_loss_raw=1.7141, running_loss=1.7453, LR=0.000100
[2025-08-10 13:23:20,671][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015552] [Batch 00784/03692] [00:07:00/00:26:00, 0.537s/it]: train_loss_raw=1.7244, running_loss=1.7448, LR=0.000100
[2025-08-10 13:23:27,174][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015564] [Batch 00796/03692] [00:07:07/00:25:54, 0.537s/it]: train_loss_raw=1.7748, running_loss=1.7461, LR=0.000100
[2025-08-10 13:23:33,429][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015576] [Batch 00808/03692] [00:07:13/00:25:47, 0.537s/it]: train_loss_raw=1.6421, running_loss=1.7460, LR=0.000100
[2025-08-10 13:23:39,881][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015588] [Batch 00820/03692] [00:07:19/00:25:40, 0.537s/it]: train_loss_raw=1.7428, running_loss=1.7467, LR=0.000100
[2025-08-10 13:23:46,495][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015600] [Batch 00832/03692] [00:07:26/00:25:35, 0.537s/it]: train_loss_raw=1.7914, running_loss=1.7451, LR=0.000100
[2025-08-10 13:23:53,171][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015612] [Batch 00844/03692] [00:07:33/00:25:29, 0.537s/it]: train_loss_raw=1.8102, running_loss=1.7415, LR=0.000100
[2025-08-10 13:23:59,759][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015624] [Batch 00856/03692] [00:07:39/00:25:23, 0.537s/it]: train_loss_raw=1.7893, running_loss=1.7418, LR=0.000100
[2025-08-10 13:24:06,365][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015636] [Batch 00868/03692] [00:07:46/00:25:17, 0.537s/it]: train_loss_raw=1.6828, running_loss=1.7410, LR=0.000100
[2025-08-10 13:24:12,975][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015648] [Batch 00880/03692] [00:07:53/00:25:11, 0.538s/it]: train_loss_raw=1.6500, running_loss=1.7388, LR=0.000100
[2025-08-10 13:24:19,500][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015660] [Batch 00892/03692] [00:07:59/00:25:05, 0.538s/it]: train_loss_raw=1.6023, running_loss=1.7381, LR=0.000100
[2025-08-10 13:24:26,047][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015672] [Batch 00904/03692] [00:08:06/00:24:59, 0.538s/it]: train_loss_raw=1.8507, running_loss=1.7418, LR=0.000100
[2025-08-10 13:24:32,348][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015684] [Batch 00916/03692] [00:08:12/00:24:52, 0.538s/it]: train_loss_raw=1.5569, running_loss=1.7392, LR=0.000100
[2025-08-10 13:24:38,614][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015696] [Batch 00928/03692] [00:08:18/00:24:45, 0.537s/it]: train_loss_raw=1.7433, running_loss=1.7403, LR=0.000100
[2025-08-10 13:24:44,867][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015708] [Batch 00940/03692] [00:08:24/00:24:38, 0.537s/it]: train_loss_raw=1.7724, running_loss=1.7428, LR=0.000100
[2025-08-10 13:24:51,088][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015720] [Batch 00952/03692] [00:08:31/00:24:31, 0.537s/it]: train_loss_raw=1.7339, running_loss=1.7428, LR=0.000100
[2025-08-10 13:24:57,296][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015732] [Batch 00964/03692] [00:08:37/00:24:24, 0.537s/it]: train_loss_raw=1.8324, running_loss=1.7425, LR=0.000100
[2025-08-10 13:25:03,580][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015744] [Batch 00976/03692] [00:08:43/00:24:17, 0.537s/it]: train_loss_raw=1.7382, running_loss=1.7423, LR=0.000100
[2025-08-10 13:25:09,639][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015756] [Batch 00988/03692] [00:08:49/00:24:09, 0.536s/it]: train_loss_raw=1.7674, running_loss=1.7368, LR=0.000100
[2025-08-10 13:25:15,796][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015768] [Batch 01000/03692] [00:08:55/00:24:02, 0.536s/it]: train_loss_raw=1.8035, running_loss=1.7384, LR=0.000100
[2025-08-10 13:25:22,025][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015780] [Batch 01012/03692] [00:09:02/00:23:55, 0.536s/it]: train_loss_raw=1.6282, running_loss=1.7399, LR=0.000100
[2025-08-10 13:25:28,578][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015792] [Batch 01024/03692] [00:09:08/00:23:49, 0.536s/it]: train_loss_raw=1.7209, running_loss=1.7394, LR=0.000100
[2025-08-10 13:25:35,124][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015804] [Batch 01036/03692] [00:09:15/00:23:43, 0.536s/it]: train_loss_raw=1.6094, running_loss=1.7331, LR=0.000100
[2025-08-10 13:25:41,497][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015816] [Batch 01048/03692] [00:09:21/00:23:36, 0.536s/it]: train_loss_raw=1.6010, running_loss=1.7358, LR=0.000100
[2025-08-10 13:25:48,063][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015828] [Batch 01060/03692] [00:09:28/00:23:30, 0.536s/it]: train_loss_raw=1.7435, running_loss=1.7359, LR=0.000100
[2025-08-10 13:25:54,569][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015840] [Batch 01072/03692] [00:09:34/00:23:24, 0.536s/it]: train_loss_raw=1.7602, running_loss=1.7379, LR=0.000100
[2025-08-10 13:26:01,042][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015852] [Batch 01084/03692] [00:09:41/00:23:18, 0.536s/it]: train_loss_raw=1.6883, running_loss=1.7387, LR=0.000100
[2025-08-10 13:26:07,400][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015864] [Batch 01096/03692] [00:09:47/00:23:11, 0.536s/it]: train_loss_raw=1.6106, running_loss=1.7403, LR=0.000100
[2025-08-10 13:26:13,938][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015876] [Batch 01108/03692] [00:09:54/00:23:05, 0.536s/it]: train_loss_raw=1.6923, running_loss=1.7383, LR=0.000100
[2025-08-10 13:26:20,580][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015888] [Batch 01120/03692] [00:10:00/00:22:59, 0.536s/it]: train_loss_raw=1.8256, running_loss=1.7414, LR=0.000100
[2025-08-10 13:26:27,171][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015900] [Batch 01132/03692] [00:10:07/00:22:53, 0.536s/it]: train_loss_raw=1.6847, running_loss=1.7377, LR=0.000100
[2025-08-10 13:26:33,783][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015912] [Batch 01144/03692] [00:10:13/00:22:47, 0.537s/it]: train_loss_raw=1.6890, running_loss=1.7394, LR=0.000100
[2025-08-10 13:26:40,354][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015924] [Batch 01156/03692] [00:10:20/00:22:41, 0.537s/it]: train_loss_raw=1.7258, running_loss=1.7384, LR=0.000100
[2025-08-10 13:26:46,973][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015936] [Batch 01168/03692] [00:10:27/00:22:35, 0.537s/it]: train_loss_raw=1.7463, running_loss=1.7399, LR=0.000100
[2025-08-10 13:26:53,556][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015948] [Batch 01180/03692] [00:10:33/00:22:28, 0.537s/it]: train_loss_raw=1.7008, running_loss=1.7364, LR=0.000100
[2025-08-10 13:27:00,157][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015960] [Batch 01192/03692] [00:10:40/00:22:22, 0.537s/it]: train_loss_raw=1.7369, running_loss=1.7385, LR=0.000100
[2025-08-10 13:27:06,739][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015972] [Batch 01204/03692] [00:10:46/00:22:16, 0.537s/it]: train_loss_raw=1.7737, running_loss=1.7409, LR=0.000100
[2025-08-10 13:27:13,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015984] [Batch 01216/03692] [00:10:53/00:22:10, 0.537s/it]: train_loss_raw=1.6036, running_loss=1.7357, LR=0.000100
[2025-08-10 13:27:19,698][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 015996] [Batch 01228/03692] [00:10:59/00:22:03, 0.537s/it]: train_loss_raw=1.6943, running_loss=1.7361, LR=0.000100
[2025-08-10 13:27:31,344][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016008] [Batch 01240/03692] [00:11:11/00:22:07, 0.541s/it]: train_loss_raw=1.6876, running_loss=1.7346, LR=0.000100
[2025-08-10 13:27:37,568][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016020] [Batch 01252/03692] [00:11:17/00:22:00, 0.541s/it]: train_loss_raw=1.6736, running_loss=1.7322, LR=0.000100
[2025-08-10 13:27:43,908][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016032] [Batch 01264/03692] [00:11:23/00:21:53, 0.541s/it]: train_loss_raw=1.7370, running_loss=1.7332, LR=0.000100
[2025-08-10 13:27:50,108][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016044] [Batch 01276/03692] [00:11:30/00:21:46, 0.541s/it]: train_loss_raw=1.7900, running_loss=1.7309, LR=0.000100
[2025-08-10 13:27:56,312][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016056] [Batch 01288/03692] [00:11:36/00:21:39, 0.541s/it]: train_loss_raw=1.7169, running_loss=1.7313, LR=0.000100
[2025-08-10 13:28:02,576][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016068] [Batch 01300/03692] [00:11:42/00:21:32, 0.540s/it]: train_loss_raw=1.6763, running_loss=1.7327, LR=0.000100
[2025-08-10 13:28:09,156][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016080] [Batch 01312/03692] [00:11:49/00:21:26, 0.541s/it]: train_loss_raw=1.7023, running_loss=1.7326, LR=0.000100
[2025-08-10 13:28:15,453][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016092] [Batch 01324/03692] [00:11:55/00:21:19, 0.540s/it]: train_loss_raw=1.7797, running_loss=1.7344, LR=0.000100
[2025-08-10 13:28:21,845][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016104] [Batch 01336/03692] [00:12:01/00:21:13, 0.540s/it]: train_loss_raw=1.7805, running_loss=1.7310, LR=0.000100
[2025-08-10 13:28:28,423][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016116] [Batch 01348/03692] [00:12:08/00:21:06, 0.540s/it]: train_loss_raw=1.6634, running_loss=1.7325, LR=0.000100
[2025-08-10 13:28:35,012][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016128] [Batch 01360/03692] [00:12:15/00:21:00, 0.541s/it]: train_loss_raw=1.7052, running_loss=1.7323, LR=0.000100
[2025-08-10 13:28:41,224][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016140] [Batch 01372/03692] [00:12:21/00:20:53, 0.540s/it]: train_loss_raw=1.7081, running_loss=1.7332, LR=0.000100
[2025-08-10 13:28:47,446][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016152] [Batch 01384/03692] [00:12:27/00:20:46, 0.540s/it]: train_loss_raw=1.7524, running_loss=1.7334, LR=0.000100
[2025-08-10 13:28:53,664][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016164] [Batch 01396/03692] [00:12:33/00:20:39, 0.540s/it]: train_loss_raw=1.6508, running_loss=1.7304, LR=0.000100
[2025-08-10 13:28:59,962][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016176] [Batch 01408/03692] [00:12:40/00:20:32, 0.540s/it]: train_loss_raw=1.7722, running_loss=1.7286, LR=0.000100
[2025-08-10 13:29:06,628][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016188] [Batch 01420/03692] [00:12:46/00:20:26, 0.540s/it]: train_loss_raw=1.7821, running_loss=1.7273, LR=0.000100
[2025-08-10 13:29:13,245][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016200] [Batch 01432/03692] [00:12:53/00:20:20, 0.540s/it]: train_loss_raw=1.6800, running_loss=1.7300, LR=0.000100
[2025-08-10 13:29:19,717][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016212] [Batch 01444/03692] [00:12:59/00:20:13, 0.540s/it]: train_loss_raw=1.8955, running_loss=1.7308, LR=0.000100
[2025-08-10 13:29:25,744][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016224] [Batch 01456/03692] [00:13:05/00:20:06, 0.540s/it]: train_loss_raw=1.7180, running_loss=1.7282, LR=0.000100
[2025-08-10 13:29:31,946][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016236] [Batch 01468/03692] [00:13:12/00:19:59, 0.540s/it]: train_loss_raw=1.6683, running_loss=1.7271, LR=0.000100
[2025-08-10 13:29:38,438][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016248] [Batch 01480/03692] [00:13:18/00:19:53, 0.540s/it]: train_loss_raw=1.7820, running_loss=1.7254, LR=0.000100
[2025-08-10 13:29:45,010][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016260] [Batch 01492/03692] [00:13:25/00:19:47, 0.540s/it]: train_loss_raw=1.6511, running_loss=1.7234, LR=0.000100
[2025-08-10 13:29:51,479][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016272] [Batch 01504/03692] [00:13:31/00:19:40, 0.540s/it]: train_loss_raw=1.7129, running_loss=1.7229, LR=0.000100
[2025-08-10 13:29:58,052][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016284] [Batch 01516/03692] [00:13:38/00:19:34, 0.540s/it]: train_loss_raw=1.7871, running_loss=1.7224, LR=0.000100
[2025-08-10 13:30:04,571][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016296] [Batch 01528/03692] [00:13:44/00:19:27, 0.540s/it]: train_loss_raw=1.8586, running_loss=1.7242, LR=0.000100
[2025-08-10 13:30:11,092][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016308] [Batch 01540/03692] [00:13:51/00:19:21, 0.540s/it]: train_loss_raw=1.5605, running_loss=1.7221, LR=0.000100
[2025-08-10 13:30:17,541][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016320] [Batch 01552/03692] [00:13:57/00:19:14, 0.540s/it]: train_loss_raw=1.8013, running_loss=1.7235, LR=0.000100
[2025-08-10 13:30:24,136][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016332] [Batch 01564/03692] [00:14:04/00:19:08, 0.540s/it]: train_loss_raw=1.7592, running_loss=1.7243, LR=0.000100
[2025-08-10 13:30:30,708][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016344] [Batch 01576/03692] [00:14:10/00:19:02, 0.540s/it]: train_loss_raw=1.7494, running_loss=1.7224, LR=0.000100
[2025-08-10 13:30:37,297][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016356] [Batch 01588/03692] [00:14:17/00:18:55, 0.540s/it]: train_loss_raw=1.7573, running_loss=1.7251, LR=0.000100
[2025-08-10 13:30:43,922][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016368] [Batch 01600/03692] [00:14:23/00:18:49, 0.540s/it]: train_loss_raw=1.7222, running_loss=1.7250, LR=0.000100
[2025-08-10 13:30:50,541][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016380] [Batch 01612/03692] [00:14:30/00:18:43, 0.540s/it]: train_loss_raw=1.7663, running_loss=1.7256, LR=0.000100
[2025-08-10 13:30:56,744][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016392] [Batch 01624/03692] [00:14:36/00:18:36, 0.540s/it]: train_loss_raw=1.7312, running_loss=1.7243, LR=0.000100
[2025-08-10 13:31:02,905][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016404] [Batch 01636/03692] [00:14:42/00:18:29, 0.540s/it]: train_loss_raw=1.6158, running_loss=1.7244, LR=0.000100
[2025-08-10 13:31:09,312][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016416] [Batch 01648/03692] [00:14:49/00:18:23, 0.540s/it]: train_loss_raw=1.7247, running_loss=1.7231, LR=0.000100
[2025-08-10 13:31:15,711][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016428] [Batch 01660/03692] [00:14:55/00:18:16, 0.540s/it]: train_loss_raw=1.6664, running_loss=1.7243, LR=0.000100
[2025-08-10 13:31:21,792][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016440] [Batch 01672/03692] [00:15:01/00:18:09, 0.539s/it]: train_loss_raw=1.6805, running_loss=1.7229, LR=0.000100
[2025-08-10 13:31:28,043][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016452] [Batch 01684/03692] [00:15:08/00:18:02, 0.539s/it]: train_loss_raw=1.8845, running_loss=1.7260, LR=0.000100
[2025-08-10 13:31:34,294][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016464] [Batch 01696/03692] [00:15:14/00:17:56, 0.539s/it]: train_loss_raw=1.6386, running_loss=1.7215, LR=0.000100
[2025-08-10 13:31:40,639][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016476] [Batch 01708/03692] [00:15:20/00:17:49, 0.539s/it]: train_loss_raw=1.7672, running_loss=1.7245, LR=0.000100
[2025-08-10 13:31:46,834][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016488] [Batch 01720/03692] [00:15:26/00:17:42, 0.539s/it]: train_loss_raw=1.6804, running_loss=1.7246, LR=0.000100
[2025-08-10 13:31:53,405][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016500] [Batch 01732/03692] [00:15:33/00:17:36, 0.539s/it]: train_loss_raw=1.6840, running_loss=1.7232, LR=0.000100
[2025-08-10 13:31:59,902][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016512] [Batch 01744/03692] [00:15:39/00:17:29, 0.539s/it]: train_loss_raw=1.6997, running_loss=1.7194, LR=0.000100
[2025-08-10 13:32:06,240][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016524] [Batch 01756/03692] [00:15:46/00:17:23, 0.539s/it]: train_loss_raw=1.7715, running_loss=1.7210, LR=0.000100
[2025-08-10 13:32:12,714][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016536] [Batch 01768/03692] [00:15:52/00:17:16, 0.539s/it]: train_loss_raw=1.7691, running_loss=1.7195, LR=0.000100
[2025-08-10 13:32:18,863][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016548] [Batch 01780/03692] [00:15:58/00:17:10, 0.539s/it]: train_loss_raw=1.6118, running_loss=1.7187, LR=0.000100
[2025-08-10 13:32:25,219][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016560] [Batch 01792/03692] [00:16:05/00:17:03, 0.539s/it]: train_loss_raw=1.7148, running_loss=1.7138, LR=0.000100
[2025-08-10 13:32:31,373][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016572] [Batch 01804/03692] [00:16:11/00:16:56, 0.538s/it]: train_loss_raw=1.6823, running_loss=1.7132, LR=0.000100
[2025-08-10 13:32:37,399][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016584] [Batch 01816/03692] [00:16:17/00:16:49, 0.538s/it]: train_loss_raw=1.6690, running_loss=1.7114, LR=0.000100
[2025-08-10 13:32:43,540][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016596] [Batch 01828/03692] [00:16:23/00:16:42, 0.538s/it]: train_loss_raw=1.7003, running_loss=1.7100, LR=0.000100
[2025-08-10 13:32:49,612][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016608] [Batch 01840/03692] [00:16:29/00:16:36, 0.538s/it]: train_loss_raw=1.6666, running_loss=1.7129, LR=0.000100
[2025-08-10 13:32:56,121][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016620] [Batch 01852/03692] [00:16:36/00:16:29, 0.538s/it]: train_loss_raw=1.6492, running_loss=1.7110, LR=0.000100
[2025-08-10 13:33:02,601][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016632] [Batch 01864/03692] [00:16:42/00:16:23, 0.538s/it]: train_loss_raw=1.8074, running_loss=1.7101, LR=0.000100
[2025-08-10 13:33:09,203][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016644] [Batch 01876/03692] [00:16:49/00:16:16, 0.538s/it]: train_loss_raw=1.6931, running_loss=1.7084, LR=0.000100
[2025-08-10 13:33:15,686][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016656] [Batch 01888/03692] [00:16:55/00:16:10, 0.538s/it]: train_loss_raw=1.5799, running_loss=1.7090, LR=0.000100
[2025-08-10 13:33:22,081][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016668] [Batch 01900/03692] [00:17:02/00:16:04, 0.538s/it]: train_loss_raw=1.6532, running_loss=1.7096, LR=0.000100
[2025-08-10 13:33:28,635][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016680] [Batch 01912/03692] [00:17:08/00:15:57, 0.538s/it]: train_loss_raw=1.7373, running_loss=1.7069, LR=0.000100
[2025-08-10 13:33:35,190][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016692] [Batch 01924/03692] [00:17:15/00:15:51, 0.538s/it]: train_loss_raw=1.7489, running_loss=1.7088, LR=0.000100
[2025-08-10 13:33:41,799][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016704] [Batch 01936/03692] [00:17:21/00:15:45, 0.538s/it]: train_loss_raw=1.6903, running_loss=1.7069, LR=0.000100
[2025-08-10 13:33:48,347][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016716] [Batch 01948/03692] [00:17:28/00:15:38, 0.538s/it]: train_loss_raw=1.6451, running_loss=1.7080, LR=0.000100
[2025-08-10 13:33:54,992][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016728] [Batch 01960/03692] [00:17:35/00:15:32, 0.538s/it]: train_loss_raw=1.6850, running_loss=1.7030, LR=0.000100
[2025-08-10 13:34:01,603][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016740] [Batch 01972/03692] [00:17:41/00:15:26, 0.538s/it]: train_loss_raw=1.6112, running_loss=1.7032, LR=0.000100
[2025-08-10 13:34:08,150][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016752] [Batch 01984/03692] [00:17:48/00:15:19, 0.538s/it]: train_loss_raw=1.6606, running_loss=1.7045, LR=0.000100
[2025-08-10 13:34:14,820][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016764] [Batch 01996/03692] [00:17:54/00:15:13, 0.539s/it]: train_loss_raw=1.7301, running_loss=1.7073, LR=0.000100
[2025-08-10 13:34:21,426][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016776] [Batch 02008/03692] [00:18:01/00:15:06, 0.539s/it]: train_loss_raw=1.7376, running_loss=1.7083, LR=0.000100
[2025-08-10 13:34:27,914][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016788] [Batch 02020/03692] [00:18:07/00:15:00, 0.539s/it]: train_loss_raw=1.7420, running_loss=1.7064, LR=0.000100
[2025-08-10 13:34:34,423][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016800] [Batch 02032/03692] [00:18:14/00:14:54, 0.539s/it]: train_loss_raw=1.7947, running_loss=1.7043, LR=0.000100
[2025-08-10 13:34:40,949][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016812] [Batch 02044/03692] [00:18:21/00:14:47, 0.539s/it]: train_loss_raw=1.6687, running_loss=1.7099, LR=0.000100
[2025-08-10 13:34:47,478][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016824] [Batch 02056/03692] [00:18:27/00:14:41, 0.539s/it]: train_loss_raw=1.8103, running_loss=1.7108, LR=0.000100
[2025-08-10 13:34:54,056][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016836] [Batch 02068/03692] [00:18:34/00:14:34, 0.539s/it]: train_loss_raw=1.6221, running_loss=1.7072, LR=0.000100
[2025-08-10 13:35:00,620][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016848] [Batch 02080/03692] [00:18:40/00:14:28, 0.539s/it]: train_loss_raw=1.7204, running_loss=1.7058, LR=0.000100
[2025-08-10 13:35:07,186][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016860] [Batch 02092/03692] [00:18:47/00:14:22, 0.539s/it]: train_loss_raw=1.7041, running_loss=1.7068, LR=0.000100
[2025-08-10 13:35:13,774][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016872] [Batch 02104/03692] [00:18:53/00:14:15, 0.539s/it]: train_loss_raw=1.8337, running_loss=1.7089, LR=0.000100
[2025-08-10 13:35:20,223][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016884] [Batch 02116/03692] [00:19:00/00:14:09, 0.539s/it]: train_loss_raw=1.6533, running_loss=1.7077, LR=0.000100
[2025-08-10 13:35:26,835][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016896] [Batch 02128/03692] [00:19:06/00:14:02, 0.539s/it]: train_loss_raw=1.6622, running_loss=1.7041, LR=0.000100
[2025-08-10 13:35:33,395][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016908] [Batch 02140/03692] [00:19:13/00:13:56, 0.539s/it]: train_loss_raw=1.7809, running_loss=1.7019, LR=0.000100
[2025-08-10 13:35:39,961][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016920] [Batch 02152/03692] [00:19:20/00:13:50, 0.539s/it]: train_loss_raw=1.7653, running_loss=1.7018, LR=0.000100
[2025-08-10 13:35:46,505][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016932] [Batch 02164/03692] [00:19:26/00:13:43, 0.539s/it]: train_loss_raw=1.5876, running_loss=1.7010, LR=0.000100
[2025-08-10 13:35:53,080][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016944] [Batch 02176/03692] [00:19:33/00:13:37, 0.539s/it]: train_loss_raw=1.7357, running_loss=1.7035, LR=0.000100
[2025-08-10 13:35:59,703][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016956] [Batch 02188/03692] [00:19:39/00:13:30, 0.539s/it]: train_loss_raw=1.7060, running_loss=1.7017, LR=0.000100
[2025-08-10 13:36:06,213][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016968] [Batch 02200/03692] [00:19:46/00:13:24, 0.539s/it]: train_loss_raw=1.6472, running_loss=1.6974, LR=0.000100
[2025-08-10 13:36:12,737][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016980] [Batch 02212/03692] [00:19:52/00:13:18, 0.539s/it]: train_loss_raw=1.6911, running_loss=1.6977, LR=0.000100
[2025-08-10 13:36:18,933][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 016992] [Batch 02224/03692] [00:19:59/00:13:11, 0.539s/it]: train_loss_raw=1.7464, running_loss=1.6999, LR=0.000100
[2025-08-10 13:36:25,314][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017004] [Batch 02236/03692] [00:20:05/00:13:04, 0.539s/it]: train_loss_raw=1.6909, running_loss=1.6992, LR=0.000100
[2025-08-10 13:36:31,913][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017016] [Batch 02248/03692] [00:20:11/00:12:58, 0.539s/it]: train_loss_raw=1.6740, running_loss=1.6984, LR=0.000100
[2025-08-10 13:36:38,482][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017028] [Batch 02260/03692] [00:20:18/00:12:52, 0.539s/it]: train_loss_raw=1.7095, running_loss=1.6998, LR=0.000100
[2025-08-10 13:36:44,860][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017040] [Batch 02272/03692] [00:20:24/00:12:45, 0.539s/it]: train_loss_raw=1.6975, running_loss=1.6995, LR=0.000100
[2025-08-10 13:36:51,025][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017052] [Batch 02284/03692] [00:20:31/00:12:38, 0.539s/it]: train_loss_raw=1.7000, running_loss=1.6991, LR=0.000100
[2025-08-10 13:36:57,517][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017064] [Batch 02296/03692] [00:20:37/00:12:32, 0.539s/it]: train_loss_raw=1.6973, running_loss=1.6987, LR=0.000100
[2025-08-10 13:37:04,106][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017076] [Batch 02308/03692] [00:20:44/00:12:26, 0.539s/it]: train_loss_raw=1.7696, running_loss=1.6970, LR=0.000100
[2025-08-10 13:37:10,666][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017088] [Batch 02320/03692] [00:20:50/00:12:19, 0.539s/it]: train_loss_raw=1.6201, running_loss=1.6968, LR=0.000100
[2025-08-10 13:37:16,831][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017100] [Batch 02332/03692] [00:20:56/00:12:13, 0.539s/it]: train_loss_raw=1.6371, running_loss=1.6971, LR=0.000100
[2025-08-10 13:37:23,095][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017112] [Batch 02344/03692] [00:21:03/00:12:06, 0.539s/it]: train_loss_raw=1.6976, running_loss=1.6963, LR=0.000100
[2025-08-10 13:37:29,462][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017124] [Batch 02356/03692] [00:21:09/00:11:59, 0.539s/it]: train_loss_raw=1.7265, running_loss=1.6988, LR=0.000100
[2025-08-10 13:37:35,756][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017136] [Batch 02368/03692] [00:21:15/00:11:53, 0.539s/it]: train_loss_raw=1.6601, running_loss=1.7003, LR=0.000100
[2025-08-10 13:37:42,088][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017148] [Batch 02380/03692] [00:21:22/00:11:46, 0.539s/it]: train_loss_raw=1.7584, running_loss=1.6989, LR=0.000100
[2025-08-10 13:37:48,735][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017160] [Batch 02392/03692] [00:21:28/00:11:40, 0.539s/it]: train_loss_raw=1.8030, running_loss=1.6976, LR=0.000100
[2025-08-10 13:37:55,110][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017172] [Batch 02404/03692] [00:21:35/00:11:33, 0.539s/it]: train_loss_raw=1.7258, running_loss=1.6961, LR=0.000100
[2025-08-10 13:38:01,405][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017184] [Batch 02416/03692] [00:21:41/00:11:27, 0.539s/it]: train_loss_raw=1.6674, running_loss=1.6972, LR=0.000100
[2025-08-10 13:38:07,866][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017196] [Batch 02428/03692] [00:21:47/00:11:20, 0.539s/it]: train_loss_raw=1.6582, running_loss=1.6989, LR=0.000100
[2025-08-10 13:38:14,234][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017208] [Batch 02440/03692] [00:21:54/00:11:14, 0.539s/it]: train_loss_raw=1.6881, running_loss=1.6940, LR=0.000100
[2025-08-10 13:38:20,876][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017220] [Batch 02452/03692] [00:22:00/00:11:08, 0.539s/it]: train_loss_raw=1.6003, running_loss=1.6921, LR=0.000100
[2025-08-10 13:38:27,523][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017232] [Batch 02464/03692] [00:22:07/00:11:01, 0.539s/it]: train_loss_raw=1.6742, running_loss=1.6897, LR=0.000100
[2025-08-10 13:38:34,102][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017244] [Batch 02476/03692] [00:22:14/00:10:55, 0.539s/it]: train_loss_raw=1.7478, running_loss=1.6873, LR=0.000100
[2025-08-10 13:38:40,667][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017256] [Batch 02488/03692] [00:22:20/00:10:48, 0.539s/it]: train_loss_raw=1.7524, running_loss=1.6895, LR=0.000100
[2025-08-10 13:38:47,128][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017268] [Batch 02500/03692] [00:22:27/00:10:42, 0.539s/it]: train_loss_raw=1.6402, running_loss=1.6891, LR=0.000100
[2025-08-10 13:38:53,392][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017280] [Batch 02512/03692] [00:22:33/00:10:35, 0.539s/it]: train_loss_raw=1.7195, running_loss=1.6903, LR=0.000100
[2025-08-10 13:38:59,691][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017292] [Batch 02524/03692] [00:22:39/00:10:29, 0.539s/it]: train_loss_raw=1.7080, running_loss=1.6885, LR=0.000100
[2025-08-10 13:39:05,847][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017304] [Batch 02536/03692] [00:22:45/00:10:22, 0.539s/it]: train_loss_raw=1.6631, running_loss=1.6887, LR=0.000100
[2025-08-10 13:39:12,010][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017316] [Batch 02548/03692] [00:22:52/00:10:16, 0.538s/it]: train_loss_raw=1.6888, running_loss=1.6862, LR=0.000100
[2025-08-10 13:39:18,316][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017328] [Batch 02560/03692] [00:22:58/00:10:09, 0.538s/it]: train_loss_raw=1.6270, running_loss=1.6853, LR=0.000100
[2025-08-10 13:39:24,619][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017340] [Batch 02572/03692] [00:23:04/00:10:02, 0.538s/it]: train_loss_raw=1.6524, running_loss=1.6845, LR=0.000100
[2025-08-10 13:39:30,804][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017352] [Batch 02584/03692] [00:23:10/00:09:56, 0.538s/it]: train_loss_raw=1.7149, running_loss=1.6831, LR=0.000100
[2025-08-10 13:39:37,029][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017364] [Batch 02596/03692] [00:23:17/00:09:49, 0.538s/it]: train_loss_raw=1.6300, running_loss=1.6845, LR=0.000100
[2025-08-10 13:39:43,301][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017376] [Batch 02608/03692] [00:23:23/00:09:43, 0.538s/it]: train_loss_raw=1.6709, running_loss=1.6818, LR=0.000100
[2025-08-10 13:39:49,514][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017388] [Batch 02620/03692] [00:23:29/00:09:36, 0.538s/it]: train_loss_raw=1.6454, running_loss=1.6809, LR=0.000100
[2025-08-10 13:39:55,802][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017400] [Batch 02632/03692] [00:23:35/00:09:30, 0.538s/it]: train_loss_raw=1.6228, running_loss=1.6797, LR=0.000100
[2025-08-10 13:40:02,100][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017412] [Batch 02644/03692] [00:23:42/00:09:23, 0.538s/it]: train_loss_raw=1.7058, running_loss=1.6787, LR=0.000100
[2025-08-10 13:40:08,372][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017424] [Batch 02656/03692] [00:23:48/00:09:17, 0.538s/it]: train_loss_raw=1.5841, running_loss=1.6767, LR=0.000100
[2025-08-10 13:40:14,752][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017436] [Batch 02668/03692] [00:23:54/00:09:10, 0.538s/it]: train_loss_raw=1.7809, running_loss=1.6781, LR=0.000100
[2025-08-10 13:40:21,302][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017448] [Batch 02680/03692] [00:24:01/00:09:04, 0.538s/it]: train_loss_raw=1.6061, running_loss=1.6785, LR=0.000100
[2025-08-10 13:40:27,767][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017460] [Batch 02692/03692] [00:24:07/00:08:57, 0.538s/it]: train_loss_raw=1.7449, running_loss=1.6798, LR=0.000100
[2025-08-10 13:40:34,311][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017472] [Batch 02704/03692] [00:24:14/00:08:51, 0.538s/it]: train_loss_raw=1.5825, running_loss=1.6817, LR=0.000100
[2025-08-10 13:40:40,547][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017484] [Batch 02716/03692] [00:24:20/00:08:44, 0.538s/it]: train_loss_raw=1.6721, running_loss=1.6803, LR=0.000100
[2025-08-10 13:40:46,664][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017496] [Batch 02728/03692] [00:24:26/00:08:38, 0.538s/it]: train_loss_raw=1.7430, running_loss=1.6856, LR=0.000100
[2025-08-10 13:40:53,071][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017508] [Batch 02740/03692] [00:24:33/00:08:31, 0.538s/it]: train_loss_raw=1.6153, running_loss=1.6852, LR=0.000100
[2025-08-10 13:40:59,291][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017520] [Batch 02752/03692] [00:24:39/00:08:25, 0.538s/it]: train_loss_raw=1.6671, running_loss=1.6836, LR=0.000100
[2025-08-10 13:41:05,878][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017532] [Batch 02764/03692] [00:24:45/00:08:18, 0.538s/it]: train_loss_raw=1.6593, running_loss=1.6837, LR=0.000100
[2025-08-10 13:41:12,456][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017544] [Batch 02776/03692] [00:24:52/00:08:12, 0.538s/it]: train_loss_raw=1.6102, running_loss=1.6815, LR=0.000100
[2025-08-10 13:41:19,082][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017556] [Batch 02788/03692] [00:24:59/00:08:06, 0.538s/it]: train_loss_raw=1.7113, running_loss=1.6832, LR=0.000100
[2025-08-10 13:41:25,620][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017568] [Batch 02800/03692] [00:25:05/00:07:59, 0.538s/it]: train_loss_raw=1.5374, running_loss=1.6823, LR=0.000100
[2025-08-10 13:41:32,182][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017580] [Batch 02812/03692] [00:25:12/00:07:53, 0.538s/it]: train_loss_raw=1.7492, running_loss=1.6826, LR=0.000100
[2025-08-10 13:41:38,749][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017592] [Batch 02824/03692] [00:25:18/00:07:46, 0.538s/it]: train_loss_raw=1.7089, running_loss=1.6816, LR=0.000100
[2025-08-10 13:41:45,300][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017604] [Batch 02836/03692] [00:25:25/00:07:40, 0.538s/it]: train_loss_raw=1.6031, running_loss=1.6775, LR=0.000100
[2025-08-10 13:41:51,963][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017616] [Batch 02848/03692] [00:25:32/00:07:34, 0.538s/it]: train_loss_raw=1.6828, running_loss=1.6786, LR=0.000100
[2025-08-10 13:41:58,456][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017628] [Batch 02860/03692] [00:25:38/00:07:27, 0.538s/it]: train_loss_raw=1.8073, running_loss=1.6839, LR=0.000100
[2025-08-10 13:42:04,844][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017640] [Batch 02872/03692] [00:25:44/00:07:21, 0.538s/it]: train_loss_raw=1.6838, running_loss=1.6806, LR=0.000100
[2025-08-10 13:42:11,390][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017652] [Batch 02884/03692] [00:25:51/00:07:14, 0.538s/it]: train_loss_raw=1.5810, running_loss=1.6788, LR=0.000100
[2025-08-10 13:42:18,029][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017664] [Batch 02896/03692] [00:25:58/00:07:08, 0.538s/it]: train_loss_raw=1.7523, running_loss=1.6774, LR=0.000100
[2025-08-10 13:42:24,589][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017676] [Batch 02908/03692] [00:26:04/00:07:01, 0.538s/it]: train_loss_raw=1.6998, running_loss=1.6758, LR=0.000100
[2025-08-10 13:42:30,928][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017688] [Batch 02920/03692] [00:26:10/00:06:55, 0.538s/it]: train_loss_raw=1.6640, running_loss=1.6715, LR=0.000100
[2025-08-10 13:42:37,022][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017700] [Batch 02932/03692] [00:26:17/00:06:48, 0.538s/it]: train_loss_raw=1.5899, running_loss=1.6745, LR=0.000100
[2025-08-10 13:42:43,261][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017712] [Batch 02944/03692] [00:26:23/00:06:42, 0.538s/it]: train_loss_raw=1.5370, running_loss=1.6745, LR=0.000100
[2025-08-10 13:42:49,561][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017724] [Batch 02956/03692] [00:26:29/00:06:35, 0.538s/it]: train_loss_raw=1.5941, running_loss=1.6770, LR=0.000100
[2025-08-10 13:42:55,613][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017736] [Batch 02968/03692] [00:26:35/00:06:29, 0.538s/it]: train_loss_raw=1.6655, running_loss=1.6791, LR=0.000100
[2025-08-10 13:43:01,658][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017748] [Batch 02980/03692] [00:26:41/00:06:22, 0.537s/it]: train_loss_raw=1.6489, running_loss=1.6767, LR=0.000100
[2025-08-10 13:43:07,737][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017760] [Batch 02992/03692] [00:26:47/00:06:16, 0.537s/it]: train_loss_raw=1.7048, running_loss=1.6723, LR=0.000100
[2025-08-10 13:43:13,887][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017772] [Batch 03004/03692] [00:26:53/00:06:09, 0.537s/it]: train_loss_raw=1.7767, running_loss=1.6774, LR=0.000100
[2025-08-10 13:43:19,929][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017784] [Batch 03016/03692] [00:27:00/00:06:03, 0.537s/it]: train_loss_raw=1.6613, running_loss=1.6736, LR=0.000100
[2025-08-10 13:43:26,037][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017796] [Batch 03028/03692] [00:27:06/00:05:56, 0.537s/it]: train_loss_raw=1.7537, running_loss=1.6767, LR=0.000100
[2025-08-10 13:43:32,320][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017808] [Batch 03040/03692] [00:27:12/00:05:50, 0.537s/it]: train_loss_raw=1.7182, running_loss=1.6738, LR=0.000100
[2025-08-10 13:43:38,916][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017820] [Batch 03052/03692] [00:27:18/00:05:43, 0.537s/it]: train_loss_raw=1.7004, running_loss=1.6789, LR=0.000100
[2025-08-10 13:43:45,177][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017832] [Batch 03064/03692] [00:27:25/00:05:37, 0.537s/it]: train_loss_raw=1.5825, running_loss=1.6785, LR=0.000100
[2025-08-10 13:43:51,318][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017844] [Batch 03076/03692] [00:27:31/00:05:30, 0.537s/it]: train_loss_raw=1.5658, running_loss=1.6793, LR=0.000100
[2025-08-10 13:43:57,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017856] [Batch 03088/03692] [00:27:37/00:05:24, 0.537s/it]: train_loss_raw=1.5964, running_loss=1.6765, LR=0.000100
[2025-08-10 13:44:04,187][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017868] [Batch 03100/03692] [00:27:44/00:05:17, 0.537s/it]: train_loss_raw=1.5821, running_loss=1.6736, LR=0.000100
[2025-08-10 13:44:10,786][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017880] [Batch 03112/03692] [00:27:50/00:05:11, 0.537s/it]: train_loss_raw=1.6738, running_loss=1.6711, LR=0.000100
[2025-08-10 13:44:17,345][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017892] [Batch 03124/03692] [00:27:57/00:05:04, 0.537s/it]: train_loss_raw=1.5588, running_loss=1.6676, LR=0.000100
[2025-08-10 13:44:23,967][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017904] [Batch 03136/03692] [00:28:04/00:04:58, 0.537s/it]: train_loss_raw=1.8185, running_loss=1.6677, LR=0.000100
[2025-08-10 13:44:30,128][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017916] [Batch 03148/03692] [00:28:10/00:04:52, 0.537s/it]: train_loss_raw=1.7038, running_loss=1.6658, LR=0.000100
[2025-08-10 13:44:36,385][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017928] [Batch 03160/03692] [00:28:16/00:04:45, 0.537s/it]: train_loss_raw=1.5996, running_loss=1.6643, LR=0.000100
[2025-08-10 13:44:42,715][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017940] [Batch 03172/03692] [00:28:22/00:04:39, 0.537s/it]: train_loss_raw=1.5835, running_loss=1.6626, LR=0.000100
[2025-08-10 13:44:48,920][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017952] [Batch 03184/03692] [00:28:28/00:04:32, 0.537s/it]: train_loss_raw=1.5434, running_loss=1.6597, LR=0.000100
[2025-08-10 13:44:55,134][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017964] [Batch 03196/03692] [00:28:35/00:04:26, 0.537s/it]: train_loss_raw=1.7246, running_loss=1.6604, LR=0.000100
[2025-08-10 13:45:01,729][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017976] [Batch 03208/03692] [00:28:41/00:04:19, 0.537s/it]: train_loss_raw=1.7307, running_loss=1.6638, LR=0.000100
[2025-08-10 13:45:08,083][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 017988] [Batch 03220/03692] [00:28:48/00:04:13, 0.537s/it]: train_loss_raw=1.7082, running_loss=1.6662, LR=0.000100
[2025-08-10 13:45:14,321][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018000] [Batch 03232/03692] [00:28:54/00:04:06, 0.537s/it]: train_loss_raw=1.6464, running_loss=1.6670, LR=0.000100
[2025-08-10 13:45:25,296][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018012] [Batch 03244/03692] [00:29:05/00:04:01, 0.538s/it]: train_loss_raw=1.6769, running_loss=1.6656, LR=0.000100
[2025-08-10 13:45:31,578][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018024] [Batch 03256/03692] [00:29:11/00:03:54, 0.538s/it]: train_loss_raw=1.6265, running_loss=1.6617, LR=0.000100
[2025-08-10 13:45:37,874][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018036] [Batch 03268/03692] [00:29:17/00:03:48, 0.538s/it]: train_loss_raw=1.5739, running_loss=1.6606, LR=0.000100
[2025-08-10 13:45:44,343][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018048] [Batch 03280/03692] [00:29:24/00:03:41, 0.538s/it]: train_loss_raw=1.6929, running_loss=1.6580, LR=0.000100
[2025-08-10 13:45:50,811][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018060] [Batch 03292/03692] [00:29:30/00:03:35, 0.538s/it]: train_loss_raw=1.6056, running_loss=1.6579, LR=0.000100
[2025-08-10 13:45:57,238][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018072] [Batch 03304/03692] [00:29:37/00:03:28, 0.538s/it]: train_loss_raw=1.7407, running_loss=1.6592, LR=0.000100
[2025-08-10 13:46:03,766][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018084] [Batch 03316/03692] [00:29:43/00:03:22, 0.538s/it]: train_loss_raw=1.6785, running_loss=1.6578, LR=0.000100
[2025-08-10 13:46:10,365][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018096] [Batch 03328/03692] [00:29:50/00:03:15, 0.538s/it]: train_loss_raw=1.6227, running_loss=1.6554, LR=0.000100
[2025-08-10 13:46:16,939][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018108] [Batch 03340/03692] [00:29:57/00:03:09, 0.538s/it]: train_loss_raw=1.6906, running_loss=1.6560, LR=0.000100
[2025-08-10 13:46:23,612][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018120] [Batch 03352/03692] [00:30:03/00:03:02, 0.538s/it]: train_loss_raw=1.7187, running_loss=1.6542, LR=0.000100
[2025-08-10 13:46:30,203][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018132] [Batch 03364/03692] [00:30:10/00:02:56, 0.538s/it]: train_loss_raw=1.7227, running_loss=1.6535, LR=0.000100
[2025-08-10 13:46:36,503][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018144] [Batch 03376/03692] [00:30:16/00:02:50, 0.538s/it]: train_loss_raw=1.7408, running_loss=1.6514, LR=0.000100
[2025-08-10 13:46:42,508][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018156] [Batch 03388/03692] [00:30:22/00:02:43, 0.538s/it]: train_loss_raw=1.6790, running_loss=1.6500, LR=0.000100
[2025-08-10 13:46:48,597][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018168] [Batch 03400/03692] [00:30:28/00:02:37, 0.538s/it]: train_loss_raw=1.5398, running_loss=1.6513, LR=0.000100
[2025-08-10 13:46:54,637][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018180] [Batch 03412/03692] [00:30:34/00:02:30, 0.538s/it]: train_loss_raw=1.6719, running_loss=1.6499, LR=0.000100
[2025-08-10 13:47:00,820][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018192] [Batch 03424/03692] [00:30:40/00:02:24, 0.538s/it]: train_loss_raw=1.6603, running_loss=1.6502, LR=0.000100
[2025-08-10 13:47:07,079][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018204] [Batch 03436/03692] [00:30:47/00:02:17, 0.538s/it]: train_loss_raw=1.6120, running_loss=1.6490, LR=0.000100
[2025-08-10 13:47:13,252][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018216] [Batch 03448/03692] [00:30:53/00:02:11, 0.538s/it]: train_loss_raw=1.7994, running_loss=1.6534, LR=0.000100
[2025-08-10 13:47:19,496][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018228] [Batch 03460/03692] [00:30:59/00:02:04, 0.537s/it]: train_loss_raw=1.7036, running_loss=1.6532, LR=0.000100
[2025-08-10 13:47:25,545][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018240] [Batch 03472/03692] [00:31:05/00:01:58, 0.537s/it]: train_loss_raw=1.5747, running_loss=1.6534, LR=0.000100
[2025-08-10 13:47:31,629][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018252] [Batch 03484/03692] [00:31:11/00:01:51, 0.537s/it]: train_loss_raw=1.5989, running_loss=1.6531, LR=0.000100
[2025-08-10 13:47:37,630][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018264] [Batch 03496/03692] [00:31:17/00:01:45, 0.537s/it]: train_loss_raw=1.5084, running_loss=1.6511, LR=0.000100
[2025-08-10 13:47:44,092][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018276] [Batch 03508/03692] [00:31:24/00:01:38, 0.537s/it]: train_loss_raw=1.6790, running_loss=1.6554, LR=0.000100
[2025-08-10 13:47:50,572][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018288] [Batch 03520/03692] [00:31:30/00:01:32, 0.537s/it]: train_loss_raw=1.5791, running_loss=1.6553, LR=0.000100
[2025-08-10 13:47:57,100][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018300] [Batch 03532/03692] [00:31:37/00:01:25, 0.537s/it]: train_loss_raw=1.5894, running_loss=1.6542, LR=0.000100
[2025-08-10 13:48:03,563][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018312] [Batch 03544/03692] [00:31:43/00:01:19, 0.537s/it]: train_loss_raw=1.6809, running_loss=1.6540, LR=0.000100
[2025-08-10 13:48:09,570][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018324] [Batch 03556/03692] [00:31:49/00:01:13, 0.537s/it]: train_loss_raw=1.5371, running_loss=1.6538, LR=0.000100
[2025-08-10 13:48:15,686][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018336] [Batch 03568/03692] [00:31:55/00:01:06, 0.537s/it]: train_loss_raw=1.7152, running_loss=1.6541, LR=0.000100
[2025-08-10 13:48:21,715][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018348] [Batch 03580/03692] [00:32:01/00:01:00, 0.537s/it]: train_loss_raw=1.6531, running_loss=1.6557, LR=0.000100
[2025-08-10 13:48:27,887][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018360] [Batch 03592/03692] [00:32:07/00:00:53, 0.537s/it]: train_loss_raw=1.6833, running_loss=1.6575, LR=0.000100
[2025-08-10 13:48:34,092][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018372] [Batch 03604/03692] [00:32:14/00:00:47, 0.537s/it]: train_loss_raw=1.6445, running_loss=1.6572, LR=0.000100
[2025-08-10 13:48:40,279][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018384] [Batch 03616/03692] [00:32:20/00:00:40, 0.537s/it]: train_loss_raw=1.5315, running_loss=1.6532, LR=0.000100
[2025-08-10 13:48:46,351][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018396] [Batch 03628/03692] [00:32:26/00:00:34, 0.536s/it]: train_loss_raw=1.5591, running_loss=1.6534, LR=0.000100
[2025-08-10 13:48:52,361][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018408] [Batch 03640/03692] [00:32:32/00:00:27, 0.536s/it]: train_loss_raw=1.7330, running_loss=1.6534, LR=0.000100
[2025-08-10 13:48:58,414][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018420] [Batch 03652/03692] [00:32:38/00:00:21, 0.536s/it]: train_loss_raw=1.6804, running_loss=1.6514, LR=0.000100
[2025-08-10 13:49:04,488][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018432] [Batch 03664/03692] [00:32:44/00:00:15, 0.536s/it]: train_loss_raw=1.5731, running_loss=1.6476, LR=0.000100
[2025-08-10 13:49:10,568][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018444] [Batch 03676/03692] [00:32:50/00:00:08, 0.536s/it]: train_loss_raw=1.5913, running_loss=1.6474, LR=0.000100
[2025-08-10 13:49:16,569][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 018456] [Batch 03688/03692] [00:32:56/00:00:02, 0.536s/it]: train_loss_raw=1.6390, running_loss=1.6500, LR=0.000100
[2025-08-10 13:49:24,055][__main__][INFO] - [VALIDATION] [Epoch 04/29] Starting validation.
[2025-08-10 13:49:59,898][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 018461] [Batch 00011/00025] [00:00:35/00:00:38, 2.987s/it]
[2025-08-10 13:50:18,007][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 018461] [Batch 00023/00025] [00:00:53/00:00:02, 2.248s/it]
[2025-08-10 13:50:19,084][__main__][INFO] - [VALIDATION] [Epoch 04/29] train_loss=1.65119, valid_loss=1.54139
[2025-08-10 13:50:19,084][__main__][INFO] - [VALIDATION] [Epoch 04/29] Metrics:
[2025-08-10 13:50:19,084][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_er      0.663
[2025-08-10 13:50:19,084][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_prec    0.073
[2025-08-10 13:50:19,084][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_recall  0.076
[2025-08-10 13:50:19,084][__main__][INFO] - [VALIDATION] [Epoch 04/29] - pep_recall 0.034
[2025-08-10 13:50:19,087][__main__][INFO] - [TRAIN] [Epoch 04/29] Epoch complete, total time 02:54:18, remaining time 14:31:31, 00:34:51 per epoch
[2025-08-10 13:50:23,163][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018468] [Batch 00008/03692] [00:00:03/00:29:17, 0.477s/it]: train_loss_raw=1.7007, running_loss=1.6503, LR=0.000100
[2025-08-10 13:50:29,249][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018480] [Batch 00020/03692] [00:00:09/00:30:18, 0.495s/it]: train_loss_raw=1.6497, running_loss=1.6506, LR=0.000100
[2025-08-10 13:50:35,634][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018492] [Batch 00032/03692] [00:00:16/00:31:02, 0.509s/it]: train_loss_raw=1.6229, running_loss=1.6521, LR=0.000100
[2025-08-10 13:50:42,123][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018504] [Batch 00044/03692] [00:00:22/00:31:28, 0.518s/it]: train_loss_raw=1.5157, running_loss=1.6519, LR=0.000100
[2025-08-10 13:50:48,733][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018516] [Batch 00056/03692] [00:00:29/00:31:48, 0.525s/it]: train_loss_raw=1.5018, running_loss=1.6450, LR=0.000100
[2025-08-10 13:50:55,272][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018528] [Batch 00068/03692] [00:00:35/00:31:54, 0.528s/it]: train_loss_raw=1.7535, running_loss=1.6453, LR=0.000100
[2025-08-10 13:51:01,813][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018540] [Batch 00080/03692] [00:00:42/00:31:57, 0.531s/it]: train_loss_raw=1.5802, running_loss=1.6498, LR=0.000100
[2025-08-10 13:51:08,228][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018552] [Batch 00092/03692] [00:00:48/00:31:52, 0.531s/it]: train_loss_raw=1.6353, running_loss=1.6454, LR=0.000100
[2025-08-10 13:51:14,288][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018564] [Batch 00104/03692] [00:00:54/00:31:35, 0.528s/it]: train_loss_raw=1.5851, running_loss=1.6391, LR=0.000100
[2025-08-10 13:51:20,350][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018576] [Batch 00116/03692] [00:01:01/00:31:20, 0.526s/it]: train_loss_raw=1.5241, running_loss=1.6390, LR=0.000100
[2025-08-10 13:51:26,360][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018588] [Batch 00128/03692] [00:01:07/00:31:05, 0.524s/it]: train_loss_raw=1.7695, running_loss=1.6438, LR=0.000100
[2025-08-10 13:51:32,403][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018600] [Batch 00140/03692] [00:01:13/00:30:53, 0.522s/it]: train_loss_raw=1.6686, running_loss=1.6475, LR=0.000100
[2025-08-10 13:51:38,529][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018612] [Batch 00152/03692] [00:01:19/00:30:44, 0.521s/it]: train_loss_raw=1.6354, running_loss=1.6436, LR=0.000100
[2025-08-10 13:51:44,619][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018624] [Batch 00164/03692] [00:01:25/00:30:34, 0.520s/it]: train_loss_raw=1.6457, running_loss=1.6426, LR=0.000100
[2025-08-10 13:51:50,673][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018636] [Batch 00176/03692] [00:01:31/00:30:24, 0.519s/it]: train_loss_raw=1.7196, running_loss=1.6400, LR=0.000100
[2025-08-10 13:51:56,737][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018648] [Batch 00188/03692] [00:01:37/00:30:15, 0.518s/it]: train_loss_raw=1.6452, running_loss=1.6393, LR=0.000100
[2025-08-10 13:52:02,769][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018660] [Batch 00200/03692] [00:01:43/00:30:05, 0.517s/it]: train_loss_raw=1.7278, running_loss=1.6350, LR=0.000100
[2025-08-10 13:52:08,742][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018672] [Batch 00212/03692] [00:01:49/00:29:55, 0.516s/it]: train_loss_raw=1.8476, running_loss=1.6355, LR=0.000100
[2025-08-10 13:52:15,034][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018684] [Batch 00224/03692] [00:01:55/00:29:51, 0.516s/it]: train_loss_raw=1.6387, running_loss=1.6318, LR=0.000100
[2025-08-10 13:52:21,573][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018696] [Batch 00236/03692] [00:02:02/00:29:49, 0.518s/it]: train_loss_raw=1.7067, running_loss=1.6344, LR=0.000100
[2025-08-10 13:52:28,075][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018708] [Batch 00248/03692] [00:02:08/00:29:47, 0.519s/it]: train_loss_raw=1.6849, running_loss=1.6362, LR=0.000100
[2025-08-10 13:52:34,723][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018720] [Batch 00260/03692] [00:02:15/00:29:46, 0.521s/it]: train_loss_raw=1.6868, running_loss=1.6373, LR=0.000100
[2025-08-10 13:52:41,357][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018732] [Batch 00272/03692] [00:02:22/00:29:45, 0.522s/it]: train_loss_raw=1.4548, running_loss=1.6349, LR=0.000100
[2025-08-10 13:52:47,893][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018744] [Batch 00284/03692] [00:02:28/00:29:42, 0.523s/it]: train_loss_raw=1.7076, running_loss=1.6359, LR=0.000100
[2025-08-10 13:52:54,423][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018756] [Batch 00296/03692] [00:02:35/00:29:39, 0.524s/it]: train_loss_raw=1.6097, running_loss=1.6325, LR=0.000100
[2025-08-10 13:53:00,987][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018768] [Batch 00308/03692] [00:02:41/00:29:35, 0.525s/it]: train_loss_raw=1.5416, running_loss=1.6349, LR=0.000100
[2025-08-10 13:53:07,554][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018780] [Batch 00320/03692] [00:02:48/00:29:32, 0.526s/it]: train_loss_raw=1.6076, running_loss=1.6337, LR=0.000100
[2025-08-10 13:53:14,149][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018792] [Batch 00332/03692] [00:02:54/00:29:29, 0.527s/it]: train_loss_raw=1.7712, running_loss=1.6355, LR=0.000100
[2025-08-10 13:53:20,748][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018804] [Batch 00344/03692] [00:03:01/00:29:25, 0.527s/it]: train_loss_raw=1.5706, running_loss=1.6350, LR=0.000100
[2025-08-10 13:53:27,247][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018816] [Batch 00356/03692] [00:03:07/00:29:20, 0.528s/it]: train_loss_raw=1.6271, running_loss=1.6362, LR=0.000100
[2025-08-10 13:53:33,817][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018828] [Batch 00368/03692] [00:03:14/00:29:16, 0.528s/it]: train_loss_raw=1.5741, running_loss=1.6406, LR=0.000100
[2025-08-10 13:53:40,506][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018840] [Batch 00380/03692] [00:03:21/00:29:13, 0.529s/it]: train_loss_raw=1.6063, running_loss=1.6404, LR=0.000100
[2025-08-10 13:53:46,667][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018852] [Batch 00392/03692] [00:03:27/00:29:05, 0.529s/it]: train_loss_raw=1.7069, running_loss=1.6352, LR=0.000100
[2025-08-10 13:53:52,771][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018864] [Batch 00404/03692] [00:03:33/00:28:56, 0.528s/it]: train_loss_raw=1.6738, running_loss=1.6344, LR=0.000100
[2025-08-10 13:53:58,809][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018876] [Batch 00416/03692] [00:03:39/00:28:48, 0.528s/it]: train_loss_raw=1.6081, running_loss=1.6345, LR=0.000100
[2025-08-10 13:54:04,838][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018888] [Batch 00428/03692] [00:03:45/00:28:39, 0.527s/it]: train_loss_raw=1.5914, running_loss=1.6323, LR=0.000100
[2025-08-10 13:54:10,993][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018900] [Batch 00440/03692] [00:03:51/00:28:32, 0.526s/it]: train_loss_raw=1.5760, running_loss=1.6315, LR=0.000100
[2025-08-10 13:54:17,177][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018912] [Batch 00452/03692] [00:03:57/00:28:24, 0.526s/it]: train_loss_raw=1.5972, running_loss=1.6329, LR=0.000100
[2025-08-10 13:54:23,320][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018924] [Batch 00464/03692] [00:04:03/00:28:17, 0.526s/it]: train_loss_raw=1.5791, running_loss=1.6328, LR=0.000100
[2025-08-10 13:54:29,405][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018936] [Batch 00476/03692] [00:04:10/00:28:09, 0.525s/it]: train_loss_raw=1.7129, running_loss=1.6331, LR=0.000100
[2025-08-10 13:54:35,625][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018948] [Batch 00488/03692] [00:04:16/00:28:02, 0.525s/it]: train_loss_raw=1.6112, running_loss=1.6300, LR=0.000100
[2025-08-10 13:54:42,130][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018960] [Batch 00500/03692] [00:04:22/00:27:57, 0.526s/it]: train_loss_raw=1.5462, running_loss=1.6279, LR=0.000100
[2025-08-10 13:54:48,710][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018972] [Batch 00512/03692] [00:04:29/00:27:53, 0.526s/it]: train_loss_raw=1.6194, running_loss=1.6264, LR=0.000100
[2025-08-10 13:54:55,162][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018984] [Batch 00524/03692] [00:04:35/00:27:47, 0.526s/it]: train_loss_raw=1.5849, running_loss=1.6246, LR=0.000100
[2025-08-10 13:55:01,605][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 018996] [Batch 00536/03692] [00:04:42/00:27:41, 0.527s/it]: train_loss_raw=1.7617, running_loss=1.6255, LR=0.000100
[2025-08-10 13:55:08,030][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019008] [Batch 00548/03692] [00:04:48/00:27:36, 0.527s/it]: train_loss_raw=1.5131, running_loss=1.6245, LR=0.000100
[2025-08-10 13:55:14,554][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019020] [Batch 00560/03692] [00:04:55/00:27:31, 0.527s/it]: train_loss_raw=1.6450, running_loss=1.6280, LR=0.000100
[2025-08-10 13:55:21,131][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019032] [Batch 00572/03692] [00:05:01/00:27:26, 0.528s/it]: train_loss_raw=1.6832, running_loss=1.6291, LR=0.000100
[2025-08-10 13:55:27,716][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019044] [Batch 00584/03692] [00:05:08/00:27:21, 0.528s/it]: train_loss_raw=1.6062, running_loss=1.6271, LR=0.000100
[2025-08-10 13:55:33,877][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019056] [Batch 00596/03692] [00:05:14/00:27:13, 0.528s/it]: train_loss_raw=1.6303, running_loss=1.6281, LR=0.000100
[2025-08-10 13:55:39,928][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019068] [Batch 00608/03692] [00:05:20/00:27:06, 0.527s/it]: train_loss_raw=1.5139, running_loss=1.6299, LR=0.000100
[2025-08-10 13:55:46,123][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019080] [Batch 00620/03692] [00:05:26/00:26:59, 0.527s/it]: train_loss_raw=1.6937, running_loss=1.6295, LR=0.000100
[2025-08-10 13:55:52,688][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019092] [Batch 00632/03692] [00:05:33/00:26:53, 0.527s/it]: train_loss_raw=1.7024, running_loss=1.6272, LR=0.000100
[2025-08-10 13:55:59,051][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019104] [Batch 00644/03692] [00:05:39/00:26:47, 0.527s/it]: train_loss_raw=1.5762, running_loss=1.6262, LR=0.000100
[2025-08-10 13:56:05,206][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019116] [Batch 00656/03692] [00:05:45/00:26:40, 0.527s/it]: train_loss_raw=1.6137, running_loss=1.6219, LR=0.000100
[2025-08-10 13:56:11,776][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019128] [Batch 00668/03692] [00:05:52/00:26:35, 0.528s/it]: train_loss_raw=1.6189, running_loss=1.6217, LR=0.000100
[2025-08-10 13:56:18,418][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019140] [Batch 00680/03692] [00:05:59/00:26:30, 0.528s/it]: train_loss_raw=1.4443, running_loss=1.6214, LR=0.000100
[2025-08-10 13:56:25,088][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019152] [Batch 00692/03692] [00:06:05/00:26:25, 0.529s/it]: train_loss_raw=1.6533, running_loss=1.6237, LR=0.000100
[2025-08-10 13:56:31,646][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019164] [Batch 00704/03692] [00:06:12/00:26:20, 0.529s/it]: train_loss_raw=1.5405, running_loss=1.6238, LR=0.000100
[2025-08-10 13:56:38,159][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019176] [Batch 00716/03692] [00:06:18/00:26:14, 0.529s/it]: train_loss_raw=1.6393, running_loss=1.6254, LR=0.000100
[2025-08-10 13:56:44,776][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019188] [Batch 00728/03692] [00:06:25/00:26:09, 0.529s/it]: train_loss_raw=1.5531, running_loss=1.6207, LR=0.000100
[2025-08-10 13:56:51,423][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019200] [Batch 00740/03692] [00:06:32/00:26:04, 0.530s/it]: train_loss_raw=1.7173, running_loss=1.6233, LR=0.000100
[2025-08-10 13:56:57,970][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019212] [Batch 00752/03692] [00:06:38/00:25:58, 0.530s/it]: train_loss_raw=1.5906, running_loss=1.6199, LR=0.000100
[2025-08-10 13:57:04,525][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019224] [Batch 00764/03692] [00:06:45/00:25:52, 0.530s/it]: train_loss_raw=1.7919, running_loss=1.6240, LR=0.000100
[2025-08-10 13:57:11,044][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019236] [Batch 00776/03692] [00:06:51/00:25:47, 0.531s/it]: train_loss_raw=1.7522, running_loss=1.6287, LR=0.000100
[2025-08-10 13:57:17,662][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019248] [Batch 00788/03692] [00:06:58/00:25:41, 0.531s/it]: train_loss_raw=1.5371, running_loss=1.6278, LR=0.000100
[2025-08-10 13:57:24,236][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019260] [Batch 00800/03692] [00:07:04/00:25:35, 0.531s/it]: train_loss_raw=1.5292, running_loss=1.6293, LR=0.000100
[2025-08-10 13:57:30,815][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019272] [Batch 00812/03692] [00:07:11/00:25:30, 0.531s/it]: train_loss_raw=1.5389, running_loss=1.6258, LR=0.000100
[2025-08-10 13:57:37,368][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019284] [Batch 00824/03692] [00:07:18/00:25:24, 0.532s/it]: train_loss_raw=1.7371, running_loss=1.6255, LR=0.000100
[2025-08-10 13:57:43,919][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019296] [Batch 00836/03692] [00:07:24/00:25:18, 0.532s/it]: train_loss_raw=1.7740, running_loss=1.6294, LR=0.000100
[2025-08-10 13:57:50,090][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019308] [Batch 00848/03692] [00:07:30/00:25:11, 0.532s/it]: train_loss_raw=1.6933, running_loss=1.6330, LR=0.000100
[2025-08-10 13:57:56,138][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019320] [Batch 00860/03692] [00:07:36/00:25:04, 0.531s/it]: train_loss_raw=1.6263, running_loss=1.6321, LR=0.000100
[2025-08-10 13:58:02,160][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019332] [Batch 00872/03692] [00:07:42/00:24:56, 0.531s/it]: train_loss_raw=1.6669, running_loss=1.6302, LR=0.000100
[2025-08-10 13:58:08,178][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019344] [Batch 00884/03692] [00:07:48/00:24:49, 0.530s/it]: train_loss_raw=1.7097, running_loss=1.6306, LR=0.000100
[2025-08-10 13:58:14,219][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019356] [Batch 00896/03692] [00:07:54/00:24:41, 0.530s/it]: train_loss_raw=1.6315, running_loss=1.6319, LR=0.000100
[2025-08-10 13:58:20,342][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019368] [Batch 00908/03692] [00:08:00/00:24:34, 0.530s/it]: train_loss_raw=1.6119, running_loss=1.6290, LR=0.000100
[2025-08-10 13:58:26,378][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019380] [Batch 00920/03692] [00:08:07/00:24:27, 0.529s/it]: train_loss_raw=1.6276, running_loss=1.6261, LR=0.000100
[2025-08-10 13:58:32,471][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019392] [Batch 00932/03692] [00:08:13/00:24:20, 0.529s/it]: train_loss_raw=1.5871, running_loss=1.6251, LR=0.000100
[2025-08-10 13:58:38,598][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019404] [Batch 00944/03692] [00:08:19/00:24:13, 0.529s/it]: train_loss_raw=1.6441, running_loss=1.6251, LR=0.000100
[2025-08-10 13:58:44,614][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019416] [Batch 00956/03692] [00:08:25/00:24:06, 0.529s/it]: train_loss_raw=1.6880, running_loss=1.6268, LR=0.000100
[2025-08-10 13:58:50,662][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019428] [Batch 00968/03692] [00:08:31/00:23:58, 0.528s/it]: train_loss_raw=1.5333, running_loss=1.6239, LR=0.000100
[2025-08-10 13:58:56,708][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019440] [Batch 00980/03692] [00:08:37/00:23:51, 0.528s/it]: train_loss_raw=1.6494, running_loss=1.6254, LR=0.000100
[2025-08-10 13:59:02,806][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019452] [Batch 00992/03692] [00:08:43/00:23:44, 0.528s/it]: train_loss_raw=1.6233, running_loss=1.6225, LR=0.000100
[2025-08-10 13:59:09,006][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019464] [Batch 01004/03692] [00:08:49/00:23:38, 0.528s/it]: train_loss_raw=1.6245, running_loss=1.6187, LR=0.000100
[2025-08-10 13:59:15,235][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019476] [Batch 01016/03692] [00:08:55/00:23:31, 0.527s/it]: train_loss_raw=1.5400, running_loss=1.6141, LR=0.000100
[2025-08-10 13:59:21,733][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019488] [Batch 01028/03692] [00:09:02/00:23:25, 0.528s/it]: train_loss_raw=1.5273, running_loss=1.6077, LR=0.000100
[2025-08-10 13:59:28,276][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019500] [Batch 01040/03692] [00:09:08/00:23:19, 0.528s/it]: train_loss_raw=1.6933, running_loss=1.6125, LR=0.000100
[2025-08-10 13:59:34,827][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019512] [Batch 01052/03692] [00:09:15/00:23:13, 0.528s/it]: train_loss_raw=1.6962, running_loss=1.6139, LR=0.000100
[2025-08-10 13:59:41,360][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019524] [Batch 01064/03692] [00:09:22/00:23:08, 0.528s/it]: train_loss_raw=1.5557, running_loss=1.6134, LR=0.000100
[2025-08-10 13:59:47,855][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019536] [Batch 01076/03692] [00:09:28/00:23:02, 0.528s/it]: train_loss_raw=1.5701, running_loss=1.6127, LR=0.000100
[2025-08-10 13:59:54,401][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019548] [Batch 01088/03692] [00:09:35/00:22:56, 0.529s/it]: train_loss_raw=1.4638, running_loss=1.6137, LR=0.000100
[2025-08-10 14:00:00,951][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019560] [Batch 01100/03692] [00:09:41/00:22:50, 0.529s/it]: train_loss_raw=1.7277, running_loss=1.6145, LR=0.000100
[2025-08-10 14:00:07,314][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019572] [Batch 01112/03692] [00:09:47/00:22:44, 0.529s/it]: train_loss_raw=1.6715, running_loss=1.6142, LR=0.000100
[2025-08-10 14:00:13,351][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019584] [Batch 01124/03692] [00:09:54/00:22:37, 0.528s/it]: train_loss_raw=1.6855, running_loss=1.6137, LR=0.000100
[2025-08-10 14:00:19,370][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019596] [Batch 01136/03692] [00:10:00/00:22:30, 0.528s/it]: train_loss_raw=1.6032, running_loss=1.6087, LR=0.000100
[2025-08-10 14:00:25,445][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019608] [Batch 01148/03692] [00:10:06/00:22:23, 0.528s/it]: train_loss_raw=1.6512, running_loss=1.6068, LR=0.000100
[2025-08-10 14:00:31,564][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019620] [Batch 01160/03692] [00:10:12/00:22:16, 0.528s/it]: train_loss_raw=1.5458, running_loss=1.6074, LR=0.000100
[2025-08-10 14:00:37,674][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019632] [Batch 01172/03692] [00:10:18/00:22:09, 0.528s/it]: train_loss_raw=1.6586, running_loss=1.6065, LR=0.000100
[2025-08-10 14:00:43,772][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019644] [Batch 01184/03692] [00:10:24/00:22:02, 0.527s/it]: train_loss_raw=1.5418, running_loss=1.6049, LR=0.000100
[2025-08-10 14:00:49,880][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019656] [Batch 01196/03692] [00:10:30/00:21:55, 0.527s/it]: train_loss_raw=1.6241, running_loss=1.6072, LR=0.000100
[2025-08-10 14:00:56,114][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019668] [Batch 01208/03692] [00:10:36/00:21:49, 0.527s/it]: train_loss_raw=1.5256, running_loss=1.6069, LR=0.000100
[2025-08-10 14:01:02,334][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019680] [Batch 01220/03692] [00:10:42/00:21:42, 0.527s/it]: train_loss_raw=1.5830, running_loss=1.6092, LR=0.000100
[2025-08-10 14:01:08,486][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019692] [Batch 01232/03692] [00:10:49/00:21:36, 0.527s/it]: train_loss_raw=1.6119, running_loss=1.6085, LR=0.000100
[2025-08-10 14:01:14,507][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019704] [Batch 01244/03692] [00:10:55/00:21:29, 0.527s/it]: train_loss_raw=1.5980, running_loss=1.6094, LR=0.000100
[2025-08-10 14:01:20,588][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019716] [Batch 01256/03692] [00:11:01/00:21:22, 0.526s/it]: train_loss_raw=1.6482, running_loss=1.6081, LR=0.000100
[2025-08-10 14:01:27,185][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019728] [Batch 01268/03692] [00:11:07/00:21:16, 0.527s/it]: train_loss_raw=1.7201, running_loss=1.6099, LR=0.000100
[2025-08-10 14:01:33,839][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019740] [Batch 01280/03692] [00:11:14/00:21:10, 0.527s/it]: train_loss_raw=1.6055, running_loss=1.6097, LR=0.000100
[2025-08-10 14:01:40,393][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019752] [Batch 01292/03692] [00:11:21/00:21:05, 0.527s/it]: train_loss_raw=1.6996, running_loss=1.6104, LR=0.000100
[2025-08-10 14:01:46,883][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019764] [Batch 01304/03692] [00:11:27/00:20:59, 0.527s/it]: train_loss_raw=1.5866, running_loss=1.6096, LR=0.000100
[2025-08-10 14:01:53,270][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019776] [Batch 01316/03692] [00:11:33/00:20:52, 0.527s/it]: train_loss_raw=1.6411, running_loss=1.6108, LR=0.000100
[2025-08-10 14:01:59,397][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019788] [Batch 01328/03692] [00:11:40/00:20:46, 0.527s/it]: train_loss_raw=1.5918, running_loss=1.6114, LR=0.000100
[2025-08-10 14:02:05,595][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019800] [Batch 01340/03692] [00:11:46/00:20:39, 0.527s/it]: train_loss_raw=1.6544, running_loss=1.6112, LR=0.000100
[2025-08-10 14:02:12,016][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019812] [Batch 01352/03692] [00:11:52/00:20:33, 0.527s/it]: train_loss_raw=1.6075, running_loss=1.6088, LR=0.000100
[2025-08-10 14:02:18,617][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019824] [Batch 01364/03692] [00:11:59/00:20:27, 0.527s/it]: train_loss_raw=1.5001, running_loss=1.6100, LR=0.000100
[2025-08-10 14:02:25,096][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019836] [Batch 01376/03692] [00:12:05/00:20:21, 0.527s/it]: train_loss_raw=1.6353, running_loss=1.6070, LR=0.000100
[2025-08-10 14:02:31,677][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019848] [Batch 01388/03692] [00:12:12/00:20:15, 0.528s/it]: train_loss_raw=1.7042, running_loss=1.6065, LR=0.000100
[2025-08-10 14:02:38,013][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019860] [Batch 01400/03692] [00:12:18/00:20:09, 0.528s/it]: train_loss_raw=1.7388, running_loss=1.6049, LR=0.000100
[2025-08-10 14:02:44,023][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019872] [Batch 01412/03692] [00:12:24/00:20:02, 0.527s/it]: train_loss_raw=1.5450, running_loss=1.6026, LR=0.000100
[2025-08-10 14:02:50,072][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019884] [Batch 01424/03692] [00:12:30/00:19:55, 0.527s/it]: train_loss_raw=1.6210, running_loss=1.6023, LR=0.000100
[2025-08-10 14:02:56,068][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019896] [Batch 01436/03692] [00:12:36/00:19:48, 0.527s/it]: train_loss_raw=1.5424, running_loss=1.6053, LR=0.000100
[2025-08-10 14:03:02,130][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019908] [Batch 01448/03692] [00:12:42/00:19:42, 0.527s/it]: train_loss_raw=1.5799, running_loss=1.6048, LR=0.000100
[2025-08-10 14:03:08,435][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019920] [Batch 01460/03692] [00:12:49/00:19:35, 0.527s/it]: train_loss_raw=1.5177, running_loss=1.6049, LR=0.000100
[2025-08-10 14:03:14,471][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019932] [Batch 01472/03692] [00:12:55/00:19:29, 0.527s/it]: train_loss_raw=1.6198, running_loss=1.6041, LR=0.000100
[2025-08-10 14:03:20,619][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019944] [Batch 01484/03692] [00:13:01/00:19:22, 0.526s/it]: train_loss_raw=1.6177, running_loss=1.6032, LR=0.000100
[2025-08-10 14:03:26,947][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019956] [Batch 01496/03692] [00:13:07/00:19:16, 0.526s/it]: train_loss_raw=1.5251, running_loss=1.6003, LR=0.000100
[2025-08-10 14:03:33,478][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019968] [Batch 01508/03692] [00:13:14/00:19:10, 0.527s/it]: train_loss_raw=1.6107, running_loss=1.5986, LR=0.000100
[2025-08-10 14:03:39,857][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019980] [Batch 01520/03692] [00:13:20/00:19:03, 0.527s/it]: train_loss_raw=1.6529, running_loss=1.6019, LR=0.000100
[2025-08-10 14:03:46,138][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 019992] [Batch 01532/03692] [00:13:26/00:18:57, 0.527s/it]: train_loss_raw=1.5635, running_loss=1.5960, LR=0.000100
[2025-08-10 14:03:56,483][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020004] [Batch 01544/03692] [00:13:37/00:18:56, 0.529s/it]: train_loss_raw=1.5550, running_loss=1.5952, LR=0.000100
[2025-08-10 14:04:02,530][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020016] [Batch 01556/03692] [00:13:43/00:18:50, 0.529s/it]: train_loss_raw=1.6865, running_loss=1.5990, LR=0.000100
[2025-08-10 14:04:08,561][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020028] [Batch 01568/03692] [00:13:49/00:18:43, 0.529s/it]: train_loss_raw=1.6706, running_loss=1.5978, LR=0.000100
[2025-08-10 14:04:14,609][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020040] [Batch 01580/03692] [00:13:55/00:18:36, 0.529s/it]: train_loss_raw=1.5858, running_loss=1.5987, LR=0.000100
[2025-08-10 14:04:20,699][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020052] [Batch 01592/03692] [00:14:01/00:18:29, 0.528s/it]: train_loss_raw=1.7004, running_loss=1.5973, LR=0.000100
[2025-08-10 14:04:26,775][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020064] [Batch 01604/03692] [00:14:07/00:18:23, 0.528s/it]: train_loss_raw=1.6012, running_loss=1.5992, LR=0.000100
[2025-08-10 14:04:32,905][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020076] [Batch 01616/03692] [00:14:13/00:18:16, 0.528s/it]: train_loss_raw=1.6885, running_loss=1.5968, LR=0.000100
[2025-08-10 14:04:39,476][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020088] [Batch 01628/03692] [00:14:20/00:18:10, 0.528s/it]: train_loss_raw=1.5614, running_loss=1.5973, LR=0.000100
[2025-08-10 14:04:46,032][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020100] [Batch 01640/03692] [00:14:26/00:18:04, 0.528s/it]: train_loss_raw=1.6295, running_loss=1.5959, LR=0.000100
[2025-08-10 14:04:52,551][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020112] [Batch 01652/03692] [00:14:33/00:17:58, 0.529s/it]: train_loss_raw=1.4565, running_loss=1.5892, LR=0.000100
[2025-08-10 14:04:59,102][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020124] [Batch 01664/03692] [00:14:39/00:17:52, 0.529s/it]: train_loss_raw=1.4679, running_loss=1.5898, LR=0.000100
[2025-08-10 14:05:05,668][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020136] [Batch 01676/03692] [00:14:46/00:17:46, 0.529s/it]: train_loss_raw=1.5938, running_loss=1.5889, LR=0.000100
[2025-08-10 14:05:12,300][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020148] [Batch 01688/03692] [00:14:52/00:17:40, 0.529s/it]: train_loss_raw=1.6089, running_loss=1.5839, LR=0.000100
[2025-08-10 14:05:18,842][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020160] [Batch 01700/03692] [00:14:59/00:17:33, 0.529s/it]: train_loss_raw=1.6847, running_loss=1.5825, LR=0.000100
[2025-08-10 14:05:25,405][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020172] [Batch 01712/03692] [00:15:06/00:17:27, 0.529s/it]: train_loss_raw=1.5755, running_loss=1.5828, LR=0.000100
[2025-08-10 14:05:32,031][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020184] [Batch 01724/03692] [00:15:12/00:17:21, 0.529s/it]: train_loss_raw=1.5268, running_loss=1.5833, LR=0.000100
[2025-08-10 14:05:38,466][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020196] [Batch 01736/03692] [00:15:19/00:17:15, 0.529s/it]: train_loss_raw=1.5844, running_loss=1.5845, LR=0.000100
[2025-08-10 14:05:44,552][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020208] [Batch 01748/03692] [00:15:25/00:17:08, 0.529s/it]: train_loss_raw=1.5801, running_loss=1.5856, LR=0.000100
[2025-08-10 14:05:50,651][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020220] [Batch 01760/03692] [00:15:31/00:17:02, 0.529s/it]: train_loss_raw=1.7026, running_loss=1.5857, LR=0.000100
[2025-08-10 14:05:56,725][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020232] [Batch 01772/03692] [00:15:37/00:16:55, 0.529s/it]: train_loss_raw=1.5916, running_loss=1.5866, LR=0.000100
[2025-08-10 14:06:02,907][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020244] [Batch 01784/03692] [00:15:43/00:16:49, 0.529s/it]: train_loss_raw=1.6020, running_loss=1.5851, LR=0.000100
[2025-08-10 14:06:09,092][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020256] [Batch 01796/03692] [00:15:49/00:16:42, 0.529s/it]: train_loss_raw=1.5560, running_loss=1.5872, LR=0.000100
[2025-08-10 14:06:15,390][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020268] [Batch 01808/03692] [00:15:56/00:16:36, 0.529s/it]: train_loss_raw=1.6064, running_loss=1.5879, LR=0.000100
[2025-08-10 14:06:21,971][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020280] [Batch 01820/03692] [00:16:02/00:16:30, 0.529s/it]: train_loss_raw=1.6269, running_loss=1.5930, LR=0.000100
[2025-08-10 14:06:28,349][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020292] [Batch 01832/03692] [00:16:09/00:16:23, 0.529s/it]: train_loss_raw=1.4948, running_loss=1.5903, LR=0.000100
[2025-08-10 14:06:34,662][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020304] [Batch 01844/03692] [00:16:15/00:16:17, 0.529s/it]: train_loss_raw=1.6619, running_loss=1.5921, LR=0.000100
[2025-08-10 14:06:41,196][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020316] [Batch 01856/03692] [00:16:21/00:16:11, 0.529s/it]: train_loss_raw=1.6416, running_loss=1.5905, LR=0.000100
[2025-08-10 14:06:47,478][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020328] [Batch 01868/03692] [00:16:28/00:16:04, 0.529s/it]: train_loss_raw=1.5686, running_loss=1.5922, LR=0.000100
[2025-08-10 14:06:53,535][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020340] [Batch 01880/03692] [00:16:34/00:15:58, 0.529s/it]: train_loss_raw=1.5261, running_loss=1.5925, LR=0.000100
[2025-08-10 14:06:59,617][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020352] [Batch 01892/03692] [00:16:40/00:15:51, 0.529s/it]: train_loss_raw=1.6123, running_loss=1.5885, LR=0.000100
[2025-08-10 14:07:05,791][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020364] [Batch 01904/03692] [00:16:46/00:15:45, 0.529s/it]: train_loss_raw=1.6185, running_loss=1.5864, LR=0.000100
[2025-08-10 14:07:11,871][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020376] [Batch 01916/03692] [00:16:52/00:15:38, 0.528s/it]: train_loss_raw=1.5769, running_loss=1.5859, LR=0.000100
[2025-08-10 14:07:18,041][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020388] [Batch 01928/03692] [00:16:58/00:15:32, 0.528s/it]: train_loss_raw=1.5456, running_loss=1.5848, LR=0.000100
[2025-08-10 14:07:24,171][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020400] [Batch 01940/03692] [00:17:04/00:15:25, 0.528s/it]: train_loss_raw=1.5726, running_loss=1.5865, LR=0.000100
[2025-08-10 14:07:30,588][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020412] [Batch 01952/03692] [00:17:11/00:15:19, 0.528s/it]: train_loss_raw=1.6631, running_loss=1.5844, LR=0.000100
[2025-08-10 14:07:37,015][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020424] [Batch 01964/03692] [00:17:17/00:15:12, 0.528s/it]: train_loss_raw=1.4957, running_loss=1.5828, LR=0.000100
[2025-08-10 14:07:43,317][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020436] [Batch 01976/03692] [00:17:23/00:15:06, 0.528s/it]: train_loss_raw=1.5388, running_loss=1.5874, LR=0.000100
[2025-08-10 14:07:49,860][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020448] [Batch 01988/03692] [00:17:30/00:15:00, 0.528s/it]: train_loss_raw=1.6326, running_loss=1.5843, LR=0.000100
[2025-08-10 14:07:56,425][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020460] [Batch 02000/03692] [00:17:37/00:14:54, 0.529s/it]: train_loss_raw=1.7338, running_loss=1.5893, LR=0.000100
[2025-08-10 14:08:02,964][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020472] [Batch 02012/03692] [00:17:43/00:14:48, 0.529s/it]: train_loss_raw=1.4857, running_loss=1.5863, LR=0.000100
[2025-08-10 14:08:09,354][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020484] [Batch 02024/03692] [00:17:50/00:14:41, 0.529s/it]: train_loss_raw=1.5042, running_loss=1.5846, LR=0.000100
[2025-08-10 14:08:15,866][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020496] [Batch 02036/03692] [00:17:56/00:14:35, 0.529s/it]: train_loss_raw=1.4751, running_loss=1.5854, LR=0.000100
[2025-08-10 14:08:22,322][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020508] [Batch 02048/03692] [00:18:02/00:14:29, 0.529s/it]: train_loss_raw=1.4778, running_loss=1.5827, LR=0.000100
[2025-08-10 14:08:28,571][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020520] [Batch 02060/03692] [00:18:09/00:14:22, 0.529s/it]: train_loss_raw=1.6090, running_loss=1.5842, LR=0.000100
[2025-08-10 14:08:34,843][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020532] [Batch 02072/03692] [00:18:15/00:14:16, 0.529s/it]: train_loss_raw=1.5558, running_loss=1.5836, LR=0.000100
[2025-08-10 14:08:41,044][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020544] [Batch 02084/03692] [00:18:21/00:14:10, 0.529s/it]: train_loss_raw=1.5979, running_loss=1.5828, LR=0.000100
[2025-08-10 14:08:47,426][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020556] [Batch 02096/03692] [00:18:28/00:14:03, 0.529s/it]: train_loss_raw=1.5945, running_loss=1.5794, LR=0.000100
[2025-08-10 14:08:54,045][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020568] [Batch 02108/03692] [00:18:34/00:13:57, 0.529s/it]: train_loss_raw=1.5451, running_loss=1.5786, LR=0.000100
[2025-08-10 14:09:00,631][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020580] [Batch 02120/03692] [00:18:41/00:13:51, 0.529s/it]: train_loss_raw=1.5930, running_loss=1.5838, LR=0.000100
[2025-08-10 14:09:07,221][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020592] [Batch 02132/03692] [00:18:47/00:13:45, 0.529s/it]: train_loss_raw=1.4501, running_loss=1.5796, LR=0.000100
[2025-08-10 14:09:13,605][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020604] [Batch 02144/03692] [00:18:54/00:13:38, 0.529s/it]: train_loss_raw=1.4317, running_loss=1.5777, LR=0.000100
[2025-08-10 14:09:19,861][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020616] [Batch 02156/03692] [00:19:00/00:13:32, 0.529s/it]: train_loss_raw=1.6884, running_loss=1.5823, LR=0.000100
[2025-08-10 14:09:39,269][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020628] [Batch 02168/03692] [00:19:19/00:13:35, 0.535s/it]: train_loss_raw=1.6280, running_loss=1.5799, LR=0.000100
[2025-08-10 14:09:45,342][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020640] [Batch 02180/03692] [00:19:25/00:13:28, 0.535s/it]: train_loss_raw=1.4829, running_loss=1.5791, LR=0.000100
[2025-08-10 14:09:51,409][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020652] [Batch 02192/03692] [00:19:32/00:13:22, 0.535s/it]: train_loss_raw=1.4971, running_loss=1.5752, LR=0.000100
[2025-08-10 14:09:57,418][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020664] [Batch 02204/03692] [00:19:38/00:13:15, 0.535s/it]: train_loss_raw=1.5570, running_loss=1.5749, LR=0.000100
[2025-08-10 14:10:03,473][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020676] [Batch 02216/03692] [00:19:44/00:13:08, 0.534s/it]: train_loss_raw=1.6184, running_loss=1.5762, LR=0.000100
[2025-08-10 14:10:09,568][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020688] [Batch 02228/03692] [00:19:50/00:13:02, 0.534s/it]: train_loss_raw=1.5457, running_loss=1.5722, LR=0.000100
[2025-08-10 14:10:15,610][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020700] [Batch 02240/03692] [00:19:56/00:12:55, 0.534s/it]: train_loss_raw=1.6633, running_loss=1.5730, LR=0.000100
[2025-08-10 14:10:21,783][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020712] [Batch 02252/03692] [00:20:02/00:12:48, 0.534s/it]: train_loss_raw=1.5312, running_loss=1.5725, LR=0.000100
[2025-08-10 14:10:28,197][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020724] [Batch 02264/03692] [00:20:08/00:12:42, 0.534s/it]: train_loss_raw=1.5800, running_loss=1.5705, LR=0.000100
[2025-08-10 14:10:34,675][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020736] [Batch 02276/03692] [00:20:15/00:12:36, 0.534s/it]: train_loss_raw=1.4729, running_loss=1.5670, LR=0.000100
[2025-08-10 14:10:41,103][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020748] [Batch 02288/03692] [00:20:21/00:12:29, 0.534s/it]: train_loss_raw=1.5580, running_loss=1.5693, LR=0.000100
[2025-08-10 14:10:47,531][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020760] [Batch 02300/03692] [00:20:28/00:12:23, 0.534s/it]: train_loss_raw=1.5837, running_loss=1.5706, LR=0.000100
[2025-08-10 14:10:53,997][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020772] [Batch 02312/03692] [00:20:34/00:12:16, 0.534s/it]: train_loss_raw=1.6558, running_loss=1.5700, LR=0.000100
[2025-08-10 14:11:00,459][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020784] [Batch 02324/03692] [00:20:41/00:12:10, 0.534s/it]: train_loss_raw=1.5171, running_loss=1.5683, LR=0.000100
[2025-08-10 14:11:07,035][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020796] [Batch 02336/03692] [00:20:47/00:12:04, 0.534s/it]: train_loss_raw=1.7138, running_loss=1.5630, LR=0.000100
[2025-08-10 14:11:13,596][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020808] [Batch 02348/03692] [00:20:54/00:11:57, 0.534s/it]: train_loss_raw=1.6947, running_loss=1.5637, LR=0.000100
[2025-08-10 14:11:20,170][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020820] [Batch 02360/03692] [00:21:00/00:11:51, 0.534s/it]: train_loss_raw=1.6882, running_loss=1.5642, LR=0.000100
[2025-08-10 14:11:26,709][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020832] [Batch 02372/03692] [00:21:07/00:11:45, 0.534s/it]: train_loss_raw=1.4579, running_loss=1.5634, LR=0.000100
[2025-08-10 14:11:33,220][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020844] [Batch 02384/03692] [00:21:13/00:11:38, 0.534s/it]: train_loss_raw=1.6100, running_loss=1.5646, LR=0.000100
[2025-08-10 14:11:39,750][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020856] [Batch 02396/03692] [00:21:20/00:11:32, 0.534s/it]: train_loss_raw=1.5365, running_loss=1.5634, LR=0.000100
[2025-08-10 14:11:46,312][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020868] [Batch 02408/03692] [00:21:26/00:11:26, 0.534s/it]: train_loss_raw=1.4385, running_loss=1.5621, LR=0.000100
[2025-08-10 14:11:52,758][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020880] [Batch 02420/03692] [00:21:33/00:11:19, 0.534s/it]: train_loss_raw=1.5532, running_loss=1.5596, LR=0.000100
[2025-08-10 14:11:59,170][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020892] [Batch 02432/03692] [00:21:39/00:11:13, 0.534s/it]: train_loss_raw=1.5185, running_loss=1.5615, LR=0.000100
[2025-08-10 14:12:05,623][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020904] [Batch 02444/03692] [00:21:46/00:11:07, 0.534s/it]: train_loss_raw=1.5162, running_loss=1.5625, LR=0.000100
[2025-08-10 14:12:12,093][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020916] [Batch 02456/03692] [00:21:52/00:11:00, 0.535s/it]: train_loss_raw=1.5601, running_loss=1.5614, LR=0.000100
[2025-08-10 14:12:18,520][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020928] [Batch 02468/03692] [00:21:59/00:10:54, 0.535s/it]: train_loss_raw=1.5371, running_loss=1.5587, LR=0.000100
[2025-08-10 14:12:24,893][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020940] [Batch 02480/03692] [00:22:05/00:10:47, 0.534s/it]: train_loss_raw=1.3491, running_loss=1.5581, LR=0.000100
[2025-08-10 14:12:31,412][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020952] [Batch 02492/03692] [00:22:12/00:10:41, 0.535s/it]: train_loss_raw=1.6348, running_loss=1.5558, LR=0.000100
[2025-08-10 14:12:37,968][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020964] [Batch 02504/03692] [00:22:18/00:10:35, 0.535s/it]: train_loss_raw=1.4465, running_loss=1.5549, LR=0.000100
[2025-08-10 14:12:44,588][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020976] [Batch 02516/03692] [00:22:25/00:10:28, 0.535s/it]: train_loss_raw=1.4503, running_loss=1.5541, LR=0.000100
[2025-08-10 14:12:51,201][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 020988] [Batch 02528/03692] [00:22:31/00:10:22, 0.535s/it]: train_loss_raw=1.5782, running_loss=1.5555, LR=0.000100
[2025-08-10 14:12:57,710][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021000] [Batch 02540/03692] [00:22:38/00:10:16, 0.535s/it]: train_loss_raw=1.5418, running_loss=1.5557, LR=0.000100
[2025-08-10 14:13:04,188][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021012] [Batch 02552/03692] [00:22:44/00:10:09, 0.535s/it]: train_loss_raw=1.6419, running_loss=1.5567, LR=0.000100
[2025-08-10 14:13:10,653][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021024] [Batch 02564/03692] [00:22:51/00:10:03, 0.535s/it]: train_loss_raw=1.5245, running_loss=1.5596, LR=0.000100
[2025-08-10 14:13:17,170][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021036] [Batch 02576/03692] [00:22:57/00:09:56, 0.535s/it]: train_loss_raw=1.4960, running_loss=1.5615, LR=0.000100
[2025-08-10 14:13:23,612][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021048] [Batch 02588/03692] [00:23:04/00:09:50, 0.535s/it]: train_loss_raw=1.5473, running_loss=1.5613, LR=0.000100
[2025-08-10 14:13:30,091][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021060] [Batch 02600/03692] [00:23:10/00:09:44, 0.535s/it]: train_loss_raw=1.6999, running_loss=1.5663, LR=0.000100
[2025-08-10 14:13:36,573][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021072] [Batch 02612/03692] [00:23:17/00:09:37, 0.535s/it]: train_loss_raw=1.5754, running_loss=1.5635, LR=0.000100
[2025-08-10 14:13:42,930][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021084] [Batch 02624/03692] [00:23:23/00:09:31, 0.535s/it]: train_loss_raw=1.5113, running_loss=1.5629, LR=0.000100
[2025-08-10 14:13:49,433][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021096] [Batch 02636/03692] [00:23:30/00:09:24, 0.535s/it]: train_loss_raw=1.5583, running_loss=1.5628, LR=0.000100
[2025-08-10 14:13:55,842][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021108] [Batch 02648/03692] [00:23:36/00:09:18, 0.535s/it]: train_loss_raw=1.4867, running_loss=1.5605, LR=0.000100
[2025-08-10 14:14:02,373][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021120] [Batch 02660/03692] [00:23:43/00:09:12, 0.535s/it]: train_loss_raw=1.6279, running_loss=1.5614, LR=0.000100
[2025-08-10 14:14:08,966][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021132] [Batch 02672/03692] [00:23:49/00:09:05, 0.535s/it]: train_loss_raw=1.5346, running_loss=1.5599, LR=0.000100
[2025-08-10 14:14:15,584][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021144] [Batch 02684/03692] [00:23:56/00:08:59, 0.535s/it]: train_loss_raw=1.5461, running_loss=1.5563, LR=0.000100
[2025-08-10 14:14:22,231][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021156] [Batch 02696/03692] [00:24:02/00:08:53, 0.535s/it]: train_loss_raw=1.3987, running_loss=1.5553, LR=0.000100
[2025-08-10 14:14:28,822][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021168] [Batch 02708/03692] [00:24:09/00:08:46, 0.535s/it]: train_loss_raw=1.6032, running_loss=1.5560, LR=0.000100
[2025-08-10 14:14:35,338][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021180] [Batch 02720/03692] [00:24:15/00:08:40, 0.535s/it]: train_loss_raw=1.5204, running_loss=1.5591, LR=0.000100
[2025-08-10 14:14:41,813][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021192] [Batch 02732/03692] [00:24:22/00:08:33, 0.535s/it]: train_loss_raw=1.4846, running_loss=1.5622, LR=0.000100
[2025-08-10 14:14:48,175][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021204] [Batch 02744/03692] [00:24:28/00:08:27, 0.535s/it]: train_loss_raw=1.5130, running_loss=1.5622, LR=0.000100
[2025-08-10 14:14:54,577][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021216] [Batch 02756/03692] [00:24:35/00:08:21, 0.535s/it]: train_loss_raw=1.6274, running_loss=1.5623, LR=0.000100
[2025-08-10 14:15:01,112][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021228] [Batch 02768/03692] [00:24:41/00:08:14, 0.535s/it]: train_loss_raw=1.6702, running_loss=1.5612, LR=0.000100
[2025-08-10 14:15:07,713][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021240] [Batch 02780/03692] [00:24:48/00:08:08, 0.535s/it]: train_loss_raw=1.4001, running_loss=1.5576, LR=0.000100
[2025-08-10 14:15:14,270][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021252] [Batch 02792/03692] [00:24:54/00:08:01, 0.535s/it]: train_loss_raw=1.5098, running_loss=1.5566, LR=0.000100
[2025-08-10 14:15:20,941][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021264] [Batch 02804/03692] [00:25:01/00:07:55, 0.536s/it]: train_loss_raw=1.5434, running_loss=1.5559, LR=0.000100
[2025-08-10 14:15:27,279][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021276] [Batch 02816/03692] [00:25:07/00:07:49, 0.535s/it]: train_loss_raw=1.4926, running_loss=1.5575, LR=0.000100
[2025-08-10 14:15:33,702][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021288] [Batch 02828/03692] [00:25:14/00:07:42, 0.535s/it]: train_loss_raw=1.6421, running_loss=1.5568, LR=0.000100
[2025-08-10 14:15:40,199][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021300] [Batch 02840/03692] [00:25:20/00:07:36, 0.536s/it]: train_loss_raw=1.7777, running_loss=1.5618, LR=0.000100
[2025-08-10 14:15:46,754][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021312] [Batch 02852/03692] [00:25:27/00:07:29, 0.536s/it]: train_loss_raw=1.6323, running_loss=1.5605, LR=0.000100
[2025-08-10 14:15:53,187][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021324] [Batch 02864/03692] [00:25:33/00:07:23, 0.536s/it]: train_loss_raw=1.5807, running_loss=1.5593, LR=0.000100
[2025-08-10 14:15:59,676][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021336] [Batch 02876/03692] [00:25:40/00:07:17, 0.536s/it]: train_loss_raw=1.5695, running_loss=1.5561, LR=0.000100
[2025-08-10 14:16:06,163][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021348] [Batch 02888/03692] [00:25:46/00:07:10, 0.536s/it]: train_loss_raw=1.4499, running_loss=1.5546, LR=0.000100
[2025-08-10 14:16:12,622][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021360] [Batch 02900/03692] [00:25:53/00:07:04, 0.536s/it]: train_loss_raw=1.5621, running_loss=1.5560, LR=0.000100
[2025-08-10 14:16:19,211][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021372] [Batch 02912/03692] [00:25:59/00:06:57, 0.536s/it]: train_loss_raw=1.5527, running_loss=1.5587, LR=0.000100
[2025-08-10 14:16:25,791][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021384] [Batch 02924/03692] [00:26:06/00:06:51, 0.536s/it]: train_loss_raw=1.5016, running_loss=1.5584, LR=0.000100
[2025-08-10 14:16:32,340][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021396] [Batch 02936/03692] [00:26:12/00:06:45, 0.536s/it]: train_loss_raw=1.3943, running_loss=1.5581, LR=0.000100
[2025-08-10 14:16:38,781][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021408] [Batch 02948/03692] [00:26:19/00:06:38, 0.536s/it]: train_loss_raw=1.5361, running_loss=1.5586, LR=0.000100
[2025-08-10 14:16:45,177][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021420] [Batch 02960/03692] [00:26:25/00:06:32, 0.536s/it]: train_loss_raw=1.4745, running_loss=1.5598, LR=0.000100
[2025-08-10 14:16:51,555][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021432] [Batch 02972/03692] [00:26:32/00:06:25, 0.536s/it]: train_loss_raw=1.5060, running_loss=1.5587, LR=0.000100
[2025-08-10 14:16:58,020][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021444] [Batch 02984/03692] [00:26:38/00:06:19, 0.536s/it]: train_loss_raw=1.5935, running_loss=1.5597, LR=0.000100
[2025-08-10 14:17:04,536][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021456] [Batch 02996/03692] [00:26:45/00:06:12, 0.536s/it]: train_loss_raw=1.6245, running_loss=1.5556, LR=0.000100
[2025-08-10 14:17:10,959][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021468] [Batch 03008/03692] [00:26:51/00:06:06, 0.536s/it]: train_loss_raw=1.6017, running_loss=1.5553, LR=0.000100
[2025-08-10 14:17:17,478][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021480] [Batch 03020/03692] [00:26:58/00:06:00, 0.536s/it]: train_loss_raw=1.5480, running_loss=1.5538, LR=0.000100
[2025-08-10 14:17:23,897][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021492] [Batch 03032/03692] [00:27:04/00:05:53, 0.536s/it]: train_loss_raw=1.5145, running_loss=1.5529, LR=0.000100
[2025-08-10 14:17:30,309][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021504] [Batch 03044/03692] [00:27:10/00:05:47, 0.536s/it]: train_loss_raw=1.6704, running_loss=1.5526, LR=0.000100
[2025-08-10 14:17:36,769][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021516] [Batch 03056/03692] [00:27:17/00:05:40, 0.536s/it]: train_loss_raw=1.6644, running_loss=1.5566, LR=0.000100
[2025-08-10 14:17:43,130][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021528] [Batch 03068/03692] [00:27:23/00:05:34, 0.536s/it]: train_loss_raw=1.5710, running_loss=1.5553, LR=0.000100
[2025-08-10 14:17:49,628][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021540] [Batch 03080/03692] [00:27:30/00:05:27, 0.536s/it]: train_loss_raw=1.6542, running_loss=1.5520, LR=0.000100
[2025-08-10 14:17:56,014][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021552] [Batch 03092/03692] [00:27:36/00:05:21, 0.536s/it]: train_loss_raw=1.7024, running_loss=1.5517, LR=0.000100
[2025-08-10 14:18:02,444][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021564] [Batch 03104/03692] [00:27:43/00:05:15, 0.536s/it]: train_loss_raw=1.5341, running_loss=1.5485, LR=0.000100
[2025-08-10 14:18:08,879][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021576] [Batch 03116/03692] [00:27:49/00:05:08, 0.536s/it]: train_loss_raw=1.5855, running_loss=1.5472, LR=0.000100
[2025-08-10 14:18:15,361][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021588] [Batch 03128/03692] [00:27:56/00:05:02, 0.536s/it]: train_loss_raw=1.4985, running_loss=1.5430, LR=0.000100
[2025-08-10 14:18:21,915][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021600] [Batch 03140/03692] [00:28:02/00:04:55, 0.536s/it]: train_loss_raw=1.6106, running_loss=1.5401, LR=0.000100
[2025-08-10 14:18:28,505][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021612] [Batch 03152/03692] [00:28:09/00:04:49, 0.536s/it]: train_loss_raw=1.5685, running_loss=1.5421, LR=0.000100
[2025-08-10 14:18:35,028][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021624] [Batch 03164/03692] [00:28:15/00:04:42, 0.536s/it]: train_loss_raw=1.5848, running_loss=1.5389, LR=0.000100
[2025-08-10 14:18:41,528][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021636] [Batch 03176/03692] [00:28:22/00:04:36, 0.536s/it]: train_loss_raw=1.6216, running_loss=1.5382, LR=0.000100
[2025-08-10 14:18:47,968][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021648] [Batch 03188/03692] [00:28:28/00:04:30, 0.536s/it]: train_loss_raw=1.6226, running_loss=1.5349, LR=0.000100
[2025-08-10 14:18:54,572][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021660] [Batch 03200/03692] [00:28:35/00:04:23, 0.536s/it]: train_loss_raw=1.4598, running_loss=1.5331, LR=0.000100
[2025-08-10 14:19:01,112][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021672] [Batch 03212/03692] [00:28:41/00:04:17, 0.536s/it]: train_loss_raw=1.5242, running_loss=1.5303, LR=0.000100
[2025-08-10 14:19:07,744][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021684] [Batch 03224/03692] [00:28:48/00:04:10, 0.536s/it]: train_loss_raw=1.5085, running_loss=1.5316, LR=0.000100
[2025-08-10 14:19:14,364][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021696] [Batch 03236/03692] [00:28:55/00:04:04, 0.536s/it]: train_loss_raw=1.4283, running_loss=1.5295, LR=0.000100
[2025-08-10 14:19:20,910][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021708] [Batch 03248/03692] [00:29:01/00:03:58, 0.536s/it]: train_loss_raw=1.6559, running_loss=1.5310, LR=0.000100
[2025-08-10 14:19:27,421][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021720] [Batch 03260/03692] [00:29:08/00:03:51, 0.536s/it]: train_loss_raw=1.7272, running_loss=1.5319, LR=0.000100
[2025-08-10 14:19:33,850][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021732] [Batch 03272/03692] [00:29:14/00:03:45, 0.536s/it]: train_loss_raw=1.5522, running_loss=1.5334, LR=0.000100
[2025-08-10 14:19:40,291][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021744] [Batch 03284/03692] [00:29:20/00:03:38, 0.536s/it]: train_loss_raw=1.5496, running_loss=1.5328, LR=0.000100
[2025-08-10 14:19:46,776][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021756] [Batch 03296/03692] [00:29:27/00:03:32, 0.536s/it]: train_loss_raw=1.6389, running_loss=1.5382, LR=0.000100
[2025-08-10 14:19:53,246][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021768] [Batch 03308/03692] [00:29:33/00:03:25, 0.536s/it]: train_loss_raw=1.5862, running_loss=1.5385, LR=0.000100
[2025-08-10 14:19:59,662][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021780] [Batch 03320/03692] [00:29:40/00:03:19, 0.536s/it]: train_loss_raw=1.5659, running_loss=1.5364, LR=0.000100
[2025-08-10 14:20:06,279][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021792] [Batch 03332/03692] [00:29:46/00:03:13, 0.536s/it]: train_loss_raw=1.4395, running_loss=1.5354, LR=0.000100
[2025-08-10 14:20:12,767][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021804] [Batch 03344/03692] [00:29:53/00:03:06, 0.536s/it]: train_loss_raw=1.5341, running_loss=1.5371, LR=0.000100
[2025-08-10 14:20:19,223][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021816] [Batch 03356/03692] [00:29:59/00:03:00, 0.536s/it]: train_loss_raw=1.5163, running_loss=1.5349, LR=0.000100
[2025-08-10 14:20:25,680][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021828] [Batch 03368/03692] [00:30:06/00:02:53, 0.536s/it]: train_loss_raw=1.4171, running_loss=1.5356, LR=0.000100
[2025-08-10 14:20:32,076][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021840] [Batch 03380/03692] [00:30:12/00:02:47, 0.536s/it]: train_loss_raw=1.4994, running_loss=1.5363, LR=0.000100
[2025-08-10 14:20:38,424][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021852] [Batch 03392/03692] [00:30:19/00:02:40, 0.536s/it]: train_loss_raw=1.5049, running_loss=1.5340, LR=0.000100
[2025-08-10 14:20:44,889][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021864] [Batch 03404/03692] [00:30:25/00:02:34, 0.536s/it]: train_loss_raw=1.5234, running_loss=1.5334, LR=0.000100
[2025-08-10 14:20:51,309][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021876] [Batch 03416/03692] [00:30:31/00:02:28, 0.536s/it]: train_loss_raw=1.5336, running_loss=1.5331, LR=0.000100
[2025-08-10 14:20:57,729][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021888] [Batch 03428/03692] [00:30:38/00:02:21, 0.536s/it]: train_loss_raw=1.6075, running_loss=1.5337, LR=0.000100
[2025-08-10 14:21:04,141][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021900] [Batch 03440/03692] [00:30:44/00:02:15, 0.536s/it]: train_loss_raw=1.6690, running_loss=1.5358, LR=0.000100
[2025-08-10 14:21:10,763][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021912] [Batch 03452/03692] [00:30:51/00:02:08, 0.536s/it]: train_loss_raw=1.4308, running_loss=1.5342, LR=0.000100
[2025-08-10 14:21:17,188][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021924] [Batch 03464/03692] [00:30:57/00:02:02, 0.536s/it]: train_loss_raw=1.6609, running_loss=1.5363, LR=0.000100
[2025-08-10 14:21:23,620][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021936] [Batch 03476/03692] [00:31:04/00:01:55, 0.536s/it]: train_loss_raw=1.4417, running_loss=1.5324, LR=0.000100
[2025-08-10 14:21:30,036][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021948] [Batch 03488/03692] [00:31:10/00:01:49, 0.536s/it]: train_loss_raw=1.5400, running_loss=1.5340, LR=0.000100
[2025-08-10 14:21:36,531][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021960] [Batch 03500/03692] [00:31:17/00:01:42, 0.536s/it]: train_loss_raw=1.5565, running_loss=1.5322, LR=0.000100
[2025-08-10 14:21:43,104][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021972] [Batch 03512/03692] [00:31:23/00:01:36, 0.536s/it]: train_loss_raw=1.3665, running_loss=1.5285, LR=0.000100
[2025-08-10 14:21:49,691][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021984] [Batch 03524/03692] [00:31:30/00:01:30, 0.536s/it]: train_loss_raw=1.5558, running_loss=1.5269, LR=0.000100
[2025-08-10 14:21:56,202][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 021996] [Batch 03536/03692] [00:31:36/00:01:23, 0.536s/it]: train_loss_raw=1.5393, running_loss=1.5297, LR=0.000100
[2025-08-10 14:22:06,992][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022008] [Batch 03548/03692] [00:31:47/00:01:17, 0.538s/it]: train_loss_raw=1.5708, running_loss=1.5304, LR=0.000100
[2025-08-10 14:22:13,439][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022020] [Batch 03560/03692] [00:31:54/00:01:10, 0.538s/it]: train_loss_raw=1.5955, running_loss=1.5303, LR=0.000100
[2025-08-10 14:22:20,066][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022032] [Batch 03572/03692] [00:32:00/00:01:04, 0.538s/it]: train_loss_raw=1.5008, running_loss=1.5273, LR=0.000100
[2025-08-10 14:22:26,640][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022044] [Batch 03584/03692] [00:32:07/00:00:58, 0.538s/it]: train_loss_raw=1.5174, running_loss=1.5287, LR=0.000100
[2025-08-10 14:22:33,063][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022056] [Batch 03596/03692] [00:32:13/00:00:51, 0.538s/it]: train_loss_raw=1.6863, running_loss=1.5290, LR=0.000100
[2025-08-10 14:22:39,452][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022068] [Batch 03608/03692] [00:32:20/00:00:45, 0.538s/it]: train_loss_raw=1.5904, running_loss=1.5279, LR=0.000100
[2025-08-10 14:22:45,931][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022080] [Batch 03620/03692] [00:32:26/00:00:38, 0.538s/it]: train_loss_raw=1.5343, running_loss=1.5276, LR=0.000100
[2025-08-10 14:22:52,487][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022092] [Batch 03632/03692] [00:32:33/00:00:32, 0.538s/it]: train_loss_raw=1.4941, running_loss=1.5261, LR=0.000100
[2025-08-10 14:22:59,000][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022104] [Batch 03644/03692] [00:32:39/00:00:25, 0.538s/it]: train_loss_raw=1.5359, running_loss=1.5223, LR=0.000100
[2025-08-10 14:23:05,432][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022116] [Batch 03656/03692] [00:32:46/00:00:19, 0.538s/it]: train_loss_raw=1.4895, running_loss=1.5281, LR=0.000100
[2025-08-10 14:23:11,793][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022128] [Batch 03668/03692] [00:32:52/00:00:12, 0.538s/it]: train_loss_raw=1.4892, running_loss=1.5270, LR=0.000100
[2025-08-10 14:23:18,208][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022140] [Batch 03680/03692] [00:32:58/00:00:06, 0.538s/it]: train_loss_raw=1.4791, running_loss=1.5271, LR=0.000100
[2025-08-10 14:23:51,338][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 022152] [Batch 03692/03692] [00:33:31/00:00:00, 0.545s/it]: train_loss_raw=1.4019, running_loss=1.5215, LR=0.000100
[2025-08-10 14:23:56,394][__main__][INFO] - [VALIDATION] [Epoch 05/29] Starting validation.
[2025-08-10 14:24:31,690][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 022153] [Batch 00011/00025] [00:00:35/00:00:38, 2.941s/it]
[2025-08-10 14:24:50,255][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 022153] [Batch 00023/00025] [00:00:53/00:00:02, 2.244s/it]
[2025-08-10 14:24:51,489][__main__][INFO] - [VALIDATION] [Epoch 05/29] train_loss=1.52148, valid_loss=1.40185
[2025-08-10 14:24:51,490][__main__][INFO] - [VALIDATION] [Epoch 05/29] Metrics:
[2025-08-10 14:24:51,490][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_er      0.614
[2025-08-10 14:24:51,490][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_prec    0.114
[2025-08-10 14:24:51,490][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_recall  0.120
[2025-08-10 14:24:51,490][__main__][INFO] - [VALIDATION] [Epoch 05/29] - pep_recall 0.071
[2025-08-10 14:24:51,494][__main__][INFO] - [TRAIN] [Epoch 05/29] Epoch complete, total time 03:28:50, remaining time 13:55:22, 00:34:48 per epoch
[2025-08-10 14:24:58,657][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022164] [Batch 00012/03692] [00:00:06/00:30:47, 0.502s/it]: train_loss_raw=1.5096, running_loss=1.5519, LR=0.000100
[2025-08-10 14:25:05,133][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022176] [Batch 00024/03692] [00:00:12/00:31:50, 0.521s/it]: train_loss_raw=1.3241, running_loss=1.5409, LR=0.000100
[2025-08-10 14:25:11,694][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022188] [Batch 00036/03692] [00:00:19/00:32:15, 0.529s/it]: train_loss_raw=1.4221, running_loss=1.5293, LR=0.000100
[2025-08-10 14:25:18,199][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022200] [Batch 00048/03692] [00:00:25/00:32:20, 0.533s/it]: train_loss_raw=1.4727, running_loss=1.5239, LR=0.000100
[2025-08-10 14:25:24,765][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022212] [Batch 00060/03692] [00:00:32/00:32:25, 0.536s/it]: train_loss_raw=1.5991, running_loss=1.5162, LR=0.000100
[2025-08-10 14:25:31,317][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022224] [Batch 00072/03692] [00:00:38/00:32:24, 0.537s/it]: train_loss_raw=1.5074, running_loss=1.5129, LR=0.000100
[2025-08-10 14:25:37,912][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022236] [Batch 00084/03692] [00:00:45/00:32:24, 0.539s/it]: train_loss_raw=1.4793, running_loss=1.5087, LR=0.000100
[2025-08-10 14:25:44,403][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022248] [Batch 00096/03692] [00:00:51/00:32:19, 0.539s/it]: train_loss_raw=1.4650, running_loss=1.5028, LR=0.000100
[2025-08-10 14:25:50,853][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022260] [Batch 00108/03692] [00:00:58/00:32:12, 0.539s/it]: train_loss_raw=1.5086, running_loss=1.4997, LR=0.000100
[2025-08-10 14:25:56,902][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022272] [Batch 00120/03692] [00:01:04/00:31:53, 0.536s/it]: train_loss_raw=1.4987, running_loss=1.4922, LR=0.000100
[2025-08-10 14:26:03,054][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022284] [Batch 00132/03692] [00:01:10/00:31:39, 0.533s/it]: train_loss_raw=1.4435, running_loss=1.4903, LR=0.000100
[2025-08-10 14:26:09,520][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022296] [Batch 00144/03692] [00:01:16/00:31:34, 0.534s/it]: train_loss_raw=1.5692, running_loss=1.4958, LR=0.000100
[2025-08-10 14:26:16,084][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022308] [Batch 00156/03692] [00:01:23/00:31:31, 0.535s/it]: train_loss_raw=1.4759, running_loss=1.4940, LR=0.000100
[2025-08-10 14:26:22,615][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022320] [Batch 00168/03692] [00:01:29/00:31:27, 0.536s/it]: train_loss_raw=1.4270, running_loss=1.4917, LR=0.000100
[2025-08-10 14:26:29,007][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022332] [Batch 00180/03692] [00:01:36/00:31:20, 0.535s/it]: train_loss_raw=1.5263, running_loss=1.4922, LR=0.000100
[2025-08-10 14:26:35,074][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022344] [Batch 00192/03692] [00:01:42/00:31:07, 0.534s/it]: train_loss_raw=1.3594, running_loss=1.4931, LR=0.000100
[2025-08-10 14:26:41,421][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022356] [Batch 00204/03692] [00:01:48/00:31:00, 0.533s/it]: train_loss_raw=1.5937, running_loss=1.4957, LR=0.000100
[2025-08-10 14:26:47,540][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022368] [Batch 00216/03692] [00:01:54/00:30:49, 0.532s/it]: train_loss_raw=1.4928, running_loss=1.4924, LR=0.000100
[2025-08-10 14:26:53,985][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022380] [Batch 00228/03692] [00:02:01/00:30:43, 0.532s/it]: train_loss_raw=1.4857, running_loss=1.4926, LR=0.000100
[2025-08-10 14:27:00,549][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022392] [Batch 00240/03692] [00:02:07/00:30:39, 0.533s/it]: train_loss_raw=1.5265, running_loss=1.4868, LR=0.000100
[2025-08-10 14:27:06,616][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022404] [Batch 00252/03692] [00:02:13/00:30:28, 0.532s/it]: train_loss_raw=1.5592, running_loss=1.4859, LR=0.000100
[2025-08-10 14:27:12,899][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022416] [Batch 00264/03692] [00:02:20/00:30:21, 0.531s/it]: train_loss_raw=1.5647, running_loss=1.4841, LR=0.000100
[2025-08-10 14:27:19,369][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022428] [Batch 00276/03692] [00:02:26/00:30:16, 0.532s/it]: train_loss_raw=1.5525, running_loss=1.4800, LR=0.000100
[2025-08-10 14:27:25,909][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022440] [Batch 00288/03692] [00:02:33/00:30:11, 0.532s/it]: train_loss_raw=1.5092, running_loss=1.4824, LR=0.000100
[2025-08-10 14:27:32,474][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022452] [Batch 00300/03692] [00:02:39/00:30:07, 0.533s/it]: train_loss_raw=1.4319, running_loss=1.4806, LR=0.000100
[2025-08-10 14:27:39,036][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022464] [Batch 00312/03692] [00:02:46/00:30:02, 0.533s/it]: train_loss_raw=1.4794, running_loss=1.4844, LR=0.000100
[2025-08-10 14:27:45,138][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022476] [Batch 00324/03692] [00:02:52/00:29:53, 0.532s/it]: train_loss_raw=1.5238, running_loss=1.4825, LR=0.000100
[2025-08-10 14:27:51,152][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022488] [Batch 00336/03692] [00:02:58/00:29:43, 0.531s/it]: train_loss_raw=1.4412, running_loss=1.4811, LR=0.000100
[2025-08-10 14:27:57,488][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022500] [Batch 00348/03692] [00:03:04/00:29:36, 0.531s/it]: train_loss_raw=1.5517, running_loss=1.4785, LR=0.000100
[2025-08-10 14:28:04,011][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022512] [Batch 00360/03692] [00:03:11/00:29:31, 0.532s/it]: train_loss_raw=1.5471, running_loss=1.4798, LR=0.000100
[2025-08-10 14:28:10,374][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022524] [Batch 00372/03692] [00:03:17/00:29:24, 0.532s/it]: train_loss_raw=1.4741, running_loss=1.4789, LR=0.000100
[2025-08-10 14:28:16,926][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022536] [Batch 00384/03692] [00:03:24/00:29:19, 0.532s/it]: train_loss_raw=1.5009, running_loss=1.4824, LR=0.000100
[2025-08-10 14:28:23,154][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022548] [Batch 00396/03692] [00:03:30/00:29:12, 0.532s/it]: train_loss_raw=1.5283, running_loss=1.4839, LR=0.000100
[2025-08-10 14:28:29,212][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022560] [Batch 00408/03692] [00:03:36/00:29:03, 0.531s/it]: train_loss_raw=1.4721, running_loss=1.4840, LR=0.000100
[2025-08-10 14:28:35,357][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022572] [Batch 00420/03692] [00:03:42/00:28:55, 0.530s/it]: train_loss_raw=1.5341, running_loss=1.4801, LR=0.000100
[2025-08-10 14:28:41,473][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022584] [Batch 00432/03692] [00:03:48/00:28:46, 0.530s/it]: train_loss_raw=1.6243, running_loss=1.4824, LR=0.000100
[2025-08-10 14:28:47,950][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022596] [Batch 00444/03692] [00:03:55/00:28:41, 0.530s/it]: train_loss_raw=1.3624, running_loss=1.4777, LR=0.000100
[2025-08-10 14:28:54,494][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022608] [Batch 00456/03692] [00:04:01/00:28:36, 0.530s/it]: train_loss_raw=1.5297, running_loss=1.4809, LR=0.000100
[2025-08-10 14:29:00,604][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022620] [Batch 00468/03692] [00:04:07/00:28:28, 0.530s/it]: train_loss_raw=1.3976, running_loss=1.4790, LR=0.000100
[2025-08-10 14:29:06,596][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022632] [Batch 00480/03692] [00:04:13/00:28:19, 0.529s/it]: train_loss_raw=1.5526, running_loss=1.4818, LR=0.000100
[2025-08-10 14:29:12,650][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022644] [Batch 00492/03692] [00:04:20/00:28:11, 0.528s/it]: train_loss_raw=1.4518, running_loss=1.4787, LR=0.000100
[2025-08-10 14:29:18,767][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022656] [Batch 00504/03692] [00:04:26/00:28:03, 0.528s/it]: train_loss_raw=1.4369, running_loss=1.4852, LR=0.000100
[2025-08-10 14:29:24,844][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022668] [Batch 00516/03692] [00:04:32/00:27:55, 0.528s/it]: train_loss_raw=1.5210, running_loss=1.4863, LR=0.000100
[2025-08-10 14:29:30,824][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022680] [Batch 00528/03692] [00:04:38/00:27:47, 0.527s/it]: train_loss_raw=1.5408, running_loss=1.4860, LR=0.000100
[2025-08-10 14:29:37,340][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022692] [Batch 00540/03692] [00:04:44/00:27:41, 0.527s/it]: train_loss_raw=1.4849, running_loss=1.4814, LR=0.000100
[2025-08-10 14:29:43,648][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022704] [Batch 00552/03692] [00:04:51/00:27:35, 0.527s/it]: train_loss_raw=1.4700, running_loss=1.4844, LR=0.000100
[2025-08-10 14:29:49,668][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022716] [Batch 00564/03692] [00:04:57/00:27:27, 0.527s/it]: train_loss_raw=1.5141, running_loss=1.4857, LR=0.000100
[2025-08-10 14:29:55,759][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022728] [Batch 00576/03692] [00:05:03/00:27:19, 0.526s/it]: train_loss_raw=1.4387, running_loss=1.4838, LR=0.000100
[2025-08-10 14:30:01,993][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022740] [Batch 00588/03692] [00:05:09/00:27:13, 0.526s/it]: train_loss_raw=1.5803, running_loss=1.4839, LR=0.000100
[2025-08-10 14:30:08,539][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022752] [Batch 00600/03692] [00:05:15/00:27:07, 0.527s/it]: train_loss_raw=1.5716, running_loss=1.4868, LR=0.000100
[2025-08-10 14:30:15,053][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022764] [Batch 00612/03692] [00:05:22/00:27:02, 0.527s/it]: train_loss_raw=1.6253, running_loss=1.4878, LR=0.000100
[2025-08-10 14:30:21,588][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022776] [Batch 00624/03692] [00:05:28/00:26:57, 0.527s/it]: train_loss_raw=1.4177, running_loss=1.4852, LR=0.000100
[2025-08-10 14:30:28,155][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022788] [Batch 00636/03692] [00:05:35/00:26:52, 0.528s/it]: train_loss_raw=1.4617, running_loss=1.4850, LR=0.000100
[2025-08-10 14:30:34,675][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022800] [Batch 00648/03692] [00:05:42/00:26:46, 0.528s/it]: train_loss_raw=1.5377, running_loss=1.4886, LR=0.000100
[2025-08-10 14:30:41,296][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022812] [Batch 00660/03692] [00:05:48/00:26:41, 0.528s/it]: train_loss_raw=1.5309, running_loss=1.4874, LR=0.000100
[2025-08-10 14:30:48,066][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022824] [Batch 00672/03692] [00:05:55/00:26:37, 0.529s/it]: train_loss_raw=1.5395, running_loss=1.4875, LR=0.000100
[2025-08-10 14:30:54,660][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022836] [Batch 00684/03692] [00:06:02/00:26:32, 0.529s/it]: train_loss_raw=1.5222, running_loss=1.4872, LR=0.000100
[2025-08-10 14:31:01,210][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022848] [Batch 00696/03692] [00:06:08/00:26:26, 0.530s/it]: train_loss_raw=1.5173, running_loss=1.4873, LR=0.000100
[2025-08-10 14:31:07,802][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022860] [Batch 00708/03692] [00:06:15/00:26:21, 0.530s/it]: train_loss_raw=1.4067, running_loss=1.4886, LR=0.000100
[2025-08-10 14:31:14,170][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022872] [Batch 00720/03692] [00:06:21/00:26:14, 0.530s/it]: train_loss_raw=1.5463, running_loss=1.4851, LR=0.000100
[2025-08-10 14:31:20,250][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022884] [Batch 00732/03692] [00:06:27/00:26:07, 0.530s/it]: train_loss_raw=1.6132, running_loss=1.4820, LR=0.000100
[2025-08-10 14:31:26,749][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022896] [Batch 00744/03692] [00:06:34/00:26:01, 0.530s/it]: train_loss_raw=1.3929, running_loss=1.4821, LR=0.000100
[2025-08-10 14:31:33,211][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022908] [Batch 00756/03692] [00:06:40/00:25:55, 0.530s/it]: train_loss_raw=1.4379, running_loss=1.4820, LR=0.000100
[2025-08-10 14:31:39,299][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022920] [Batch 00768/03692] [00:06:46/00:25:48, 0.530s/it]: train_loss_raw=1.5157, running_loss=1.4818, LR=0.000100
[2025-08-10 14:31:45,825][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022932] [Batch 00780/03692] [00:06:53/00:25:42, 0.530s/it]: train_loss_raw=1.4889, running_loss=1.4821, LR=0.000100
[2025-08-10 14:31:52,244][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022944] [Batch 00792/03692] [00:06:59/00:25:36, 0.530s/it]: train_loss_raw=1.4695, running_loss=1.4848, LR=0.000100
[2025-08-10 14:31:58,505][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022956] [Batch 00804/03692] [00:07:05/00:25:29, 0.530s/it]: train_loss_raw=1.4717, running_loss=1.4863, LR=0.000100
[2025-08-10 14:32:04,904][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022968] [Batch 00816/03692] [00:07:12/00:25:23, 0.530s/it]: train_loss_raw=1.5829, running_loss=1.4761, LR=0.000100
[2025-08-10 14:32:10,952][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022980] [Batch 00828/03692] [00:07:18/00:25:16, 0.529s/it]: train_loss_raw=1.4714, running_loss=1.4771, LR=0.000100
[2025-08-10 14:32:17,066][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 022992] [Batch 00840/03692] [00:07:24/00:25:08, 0.529s/it]: train_loss_raw=1.3080, running_loss=1.4778, LR=0.000100
[2025-08-10 14:32:23,164][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023004] [Batch 00852/03692] [00:07:30/00:25:01, 0.529s/it]: train_loss_raw=1.4991, running_loss=1.4778, LR=0.000100
[2025-08-10 14:32:29,644][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023016] [Batch 00864/03692] [00:07:37/00:24:55, 0.529s/it]: train_loss_raw=1.4196, running_loss=1.4749, LR=0.000100
[2025-08-10 14:32:36,211][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023028] [Batch 00876/03692] [00:07:43/00:24:50, 0.529s/it]: train_loss_raw=1.4494, running_loss=1.4752, LR=0.000100
[2025-08-10 14:32:42,710][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023040] [Batch 00888/03692] [00:07:50/00:24:44, 0.529s/it]: train_loss_raw=1.4776, running_loss=1.4730, LR=0.000100
[2025-08-10 14:32:49,059][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023052] [Batch 00900/03692] [00:07:56/00:24:37, 0.529s/it]: train_loss_raw=1.4517, running_loss=1.4726, LR=0.000100
[2025-08-10 14:32:55,087][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023064] [Batch 00912/03692] [00:08:02/00:24:30, 0.529s/it]: train_loss_raw=1.5811, running_loss=1.4783, LR=0.000100
[2025-08-10 14:33:01,384][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023076] [Batch 00924/03692] [00:08:08/00:24:24, 0.529s/it]: train_loss_raw=1.3743, running_loss=1.4773, LR=0.000100
[2025-08-10 14:33:07,639][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023088] [Batch 00936/03692] [00:08:15/00:24:17, 0.529s/it]: train_loss_raw=1.4663, running_loss=1.4810, LR=0.000100
[2025-08-10 14:33:13,700][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023100] [Batch 00948/03692] [00:08:21/00:24:10, 0.529s/it]: train_loss_raw=1.4789, running_loss=1.4808, LR=0.000100
[2025-08-10 14:33:19,743][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023112] [Batch 00960/03692] [00:08:27/00:24:03, 0.528s/it]: train_loss_raw=1.3615, running_loss=1.4821, LR=0.000100
[2025-08-10 14:33:25,864][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023124] [Batch 00972/03692] [00:08:33/00:23:56, 0.528s/it]: train_loss_raw=1.3533, running_loss=1.4794, LR=0.000100
[2025-08-10 14:33:32,093][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023136] [Batch 00984/03692] [00:08:39/00:23:49, 0.528s/it]: train_loss_raw=1.5368, running_loss=1.4789, LR=0.000100
[2025-08-10 14:33:38,532][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023148] [Batch 00996/03692] [00:08:45/00:23:43, 0.528s/it]: train_loss_raw=1.4425, running_loss=1.4773, LR=0.000100
[2025-08-10 14:33:45,033][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023160] [Batch 01008/03692] [00:08:52/00:23:37, 0.528s/it]: train_loss_raw=1.5365, running_loss=1.4830, LR=0.000100
[2025-08-10 14:33:51,474][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023172] [Batch 01020/03692] [00:08:58/00:23:31, 0.528s/it]: train_loss_raw=1.4346, running_loss=1.4846, LR=0.000100
[2025-08-10 14:33:57,986][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023184] [Batch 01032/03692] [00:09:05/00:23:25, 0.528s/it]: train_loss_raw=1.2640, running_loss=1.4792, LR=0.000100
[2025-08-10 14:34:04,548][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023196] [Batch 01044/03692] [00:09:11/00:23:19, 0.529s/it]: train_loss_raw=1.4272, running_loss=1.4757, LR=0.000100
[2025-08-10 14:34:10,892][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023208] [Batch 01056/03692] [00:09:18/00:23:13, 0.529s/it]: train_loss_raw=1.5386, running_loss=1.4747, LR=0.000100
[2025-08-10 14:34:16,933][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023220] [Batch 01068/03692] [00:09:24/00:23:06, 0.528s/it]: train_loss_raw=1.5033, running_loss=1.4734, LR=0.000100
[2025-08-10 14:34:22,976][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023232] [Batch 01080/03692] [00:09:30/00:22:59, 0.528s/it]: train_loss_raw=1.4488, running_loss=1.4727, LR=0.000100
[2025-08-10 14:34:28,987][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023244] [Batch 01092/03692] [00:09:36/00:22:52, 0.528s/it]: train_loss_raw=1.3883, running_loss=1.4657, LR=0.000100
[2025-08-10 14:34:35,037][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023256] [Batch 01104/03692] [00:09:42/00:22:45, 0.528s/it]: train_loss_raw=1.5126, running_loss=1.4607, LR=0.000100
[2025-08-10 14:34:41,386][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023268] [Batch 01116/03692] [00:09:48/00:22:38, 0.528s/it]: train_loss_raw=1.3734, running_loss=1.4545, LR=0.000100
[2025-08-10 14:34:47,591][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023280] [Batch 01128/03692] [00:09:54/00:22:32, 0.527s/it]: train_loss_raw=1.5846, running_loss=1.4567, LR=0.000100
[2025-08-10 14:34:53,848][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023292] [Batch 01140/03692] [00:10:01/00:22:25, 0.527s/it]: train_loss_raw=1.4754, running_loss=1.4610, LR=0.000100
[2025-08-10 14:34:59,978][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023304] [Batch 01152/03692] [00:10:07/00:22:19, 0.527s/it]: train_loss_raw=1.3578, running_loss=1.4622, LR=0.000100
[2025-08-10 14:35:06,056][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023316] [Batch 01164/03692] [00:10:13/00:22:12, 0.527s/it]: train_loss_raw=1.5505, running_loss=1.4654, LR=0.000100
[2025-08-10 14:35:12,098][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023328] [Batch 01176/03692] [00:10:19/00:22:05, 0.527s/it]: train_loss_raw=1.4806, running_loss=1.4663, LR=0.000100
[2025-08-10 14:35:18,216][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023340] [Batch 01188/03692] [00:10:25/00:21:58, 0.527s/it]: train_loss_raw=1.5598, running_loss=1.4672, LR=0.000100
[2025-08-10 14:35:24,579][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023352] [Batch 01200/03692] [00:10:31/00:21:52, 0.527s/it]: train_loss_raw=1.4650, running_loss=1.4680, LR=0.000100
[2025-08-10 14:35:31,121][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023364] [Batch 01212/03692] [00:10:38/00:21:46, 0.527s/it]: train_loss_raw=1.5336, running_loss=1.4723, LR=0.000100
[2025-08-10 14:35:37,656][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023376] [Batch 01224/03692] [00:10:45/00:21:40, 0.527s/it]: train_loss_raw=1.4356, running_loss=1.4684, LR=0.000100
[2025-08-10 14:35:44,049][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023388] [Batch 01236/03692] [00:10:51/00:21:34, 0.527s/it]: train_loss_raw=1.4086, running_loss=1.4672, LR=0.000100
[2025-08-10 14:35:50,475][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023400] [Batch 01248/03692] [00:10:57/00:21:28, 0.527s/it]: train_loss_raw=1.3283, running_loss=1.4626, LR=0.000100
[2025-08-10 14:35:57,023][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023412] [Batch 01260/03692] [00:11:04/00:21:22, 0.527s/it]: train_loss_raw=1.4159, running_loss=1.4607, LR=0.000100
[2025-08-10 14:36:03,567][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023424] [Batch 01272/03692] [00:11:10/00:21:16, 0.527s/it]: train_loss_raw=1.4719, running_loss=1.4542, LR=0.000100
[2025-08-10 14:36:10,070][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023436] [Batch 01284/03692] [00:11:17/00:21:10, 0.528s/it]: train_loss_raw=1.4000, running_loss=1.4593, LR=0.000100
[2025-08-10 14:36:16,090][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023448] [Batch 01296/03692] [00:11:23/00:21:03, 0.527s/it]: train_loss_raw=1.4279, running_loss=1.4642, LR=0.000100
[2025-08-10 14:36:22,449][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023460] [Batch 01308/03692] [00:11:29/00:20:57, 0.527s/it]: train_loss_raw=1.3324, running_loss=1.4648, LR=0.000100
[2025-08-10 14:36:28,972][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023472] [Batch 01320/03692] [00:11:36/00:20:51, 0.528s/it]: train_loss_raw=1.4884, running_loss=1.4659, LR=0.000100
[2025-08-10 14:36:35,509][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023484] [Batch 01332/03692] [00:11:42/00:20:45, 0.528s/it]: train_loss_raw=1.5225, running_loss=1.4659, LR=0.000100
[2025-08-10 14:36:42,065][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023496] [Batch 01344/03692] [00:11:49/00:20:39, 0.528s/it]: train_loss_raw=1.4164, running_loss=1.4622, LR=0.000100
[2025-08-10 14:36:48,561][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023508] [Batch 01356/03692] [00:11:55/00:20:33, 0.528s/it]: train_loss_raw=1.5139, running_loss=1.4621, LR=0.000100
[2025-08-10 14:36:54,997][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023520] [Batch 01368/03692] [00:12:02/00:20:27, 0.528s/it]: train_loss_raw=1.4833, running_loss=1.4669, LR=0.000100
[2025-08-10 14:37:01,505][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023532] [Batch 01380/03692] [00:12:08/00:20:21, 0.528s/it]: train_loss_raw=1.5368, running_loss=1.4724, LR=0.000100
[2025-08-10 14:37:08,111][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023544] [Batch 01392/03692] [00:12:15/00:20:15, 0.528s/it]: train_loss_raw=1.4311, running_loss=1.4686, LR=0.000100
[2025-08-10 14:37:14,707][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023556] [Batch 01404/03692] [00:12:22/00:20:09, 0.529s/it]: train_loss_raw=1.4023, running_loss=1.4654, LR=0.000100
[2025-08-10 14:37:21,318][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023568] [Batch 01416/03692] [00:12:28/00:20:03, 0.529s/it]: train_loss_raw=1.5555, running_loss=1.4635, LR=0.000100
[2025-08-10 14:37:27,823][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023580] [Batch 01428/03692] [00:12:35/00:19:57, 0.529s/it]: train_loss_raw=1.4499, running_loss=1.4635, LR=0.000100
[2025-08-10 14:37:34,341][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023592] [Batch 01440/03692] [00:12:41/00:19:51, 0.529s/it]: train_loss_raw=1.4578, running_loss=1.4638, LR=0.000100
[2025-08-10 14:37:40,867][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023604] [Batch 01452/03692] [00:12:48/00:19:45, 0.529s/it]: train_loss_raw=1.4239, running_loss=1.4651, LR=0.000100
[2025-08-10 14:37:47,437][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023616] [Batch 01464/03692] [00:12:54/00:19:39, 0.529s/it]: train_loss_raw=1.3783, running_loss=1.4629, LR=0.000100
[2025-08-10 14:37:54,048][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023628] [Batch 01476/03692] [00:13:01/00:19:33, 0.529s/it]: train_loss_raw=1.4485, running_loss=1.4627, LR=0.000100
[2025-08-10 14:38:00,598][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023640] [Batch 01488/03692] [00:13:07/00:19:27, 0.530s/it]: train_loss_raw=1.4868, running_loss=1.4633, LR=0.000100
[2025-08-10 14:38:07,186][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023652] [Batch 01500/03692] [00:13:14/00:19:21, 0.530s/it]: train_loss_raw=1.5437, running_loss=1.4665, LR=0.000100
[2025-08-10 14:38:13,338][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023664] [Batch 01512/03692] [00:13:20/00:19:14, 0.530s/it]: train_loss_raw=1.5504, running_loss=1.4637, LR=0.000100
[2025-08-10 14:38:19,778][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023676] [Batch 01524/03692] [00:13:27/00:19:08, 0.530s/it]: train_loss_raw=1.4181, running_loss=1.4613, LR=0.000100
[2025-08-10 14:38:50,248][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023688] [Batch 01536/03692] [00:13:57/00:19:35, 0.545s/it]: train_loss_raw=1.4663, running_loss=1.4611, LR=0.000100
[2025-08-10 14:38:56,597][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023700] [Batch 01548/03692] [00:14:03/00:19:28, 0.545s/it]: train_loss_raw=1.4702, running_loss=1.4613, LR=0.000100
[2025-08-10 14:39:02,934][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023712] [Batch 01560/03692] [00:14:10/00:19:22, 0.545s/it]: train_loss_raw=1.3708, running_loss=1.4650, LR=0.000100
[2025-08-10 14:39:09,007][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023724] [Batch 01572/03692] [00:14:16/00:19:14, 0.545s/it]: train_loss_raw=1.4724, running_loss=1.4637, LR=0.000100
[2025-08-10 14:39:15,116][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023736] [Batch 01584/03692] [00:14:22/00:19:07, 0.544s/it]: train_loss_raw=1.5146, running_loss=1.4642, LR=0.000100
[2025-08-10 14:39:21,168][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023748] [Batch 01596/03692] [00:14:28/00:19:00, 0.544s/it]: train_loss_raw=1.5013, running_loss=1.4613, LR=0.000100
[2025-08-10 14:39:27,248][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023760] [Batch 01608/03692] [00:14:34/00:18:53, 0.544s/it]: train_loss_raw=1.4738, running_loss=1.4611, LR=0.000100
[2025-08-10 14:39:33,341][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023772] [Batch 01620/03692] [00:14:40/00:18:46, 0.544s/it]: train_loss_raw=1.4196, running_loss=1.4576, LR=0.000100
[2025-08-10 14:39:39,451][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023784] [Batch 01632/03692] [00:14:46/00:18:39, 0.543s/it]: train_loss_raw=1.4375, running_loss=1.4581, LR=0.000100
[2025-08-10 14:39:45,571][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023796] [Batch 01644/03692] [00:14:52/00:18:32, 0.543s/it]: train_loss_raw=1.4485, running_loss=1.4574, LR=0.000100
[2025-08-10 14:39:51,830][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023808] [Batch 01656/03692] [00:14:59/00:18:25, 0.543s/it]: train_loss_raw=1.5863, running_loss=1.4662, LR=0.000100
[2025-08-10 14:39:58,349][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023820] [Batch 01668/03692] [00:15:05/00:18:19, 0.543s/it]: train_loss_raw=1.3637, running_loss=1.4666, LR=0.000100
[2025-08-10 14:40:04,900][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023832] [Batch 01680/03692] [00:15:12/00:18:12, 0.543s/it]: train_loss_raw=1.4635, running_loss=1.4730, LR=0.000100
[2025-08-10 14:40:10,994][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023844] [Batch 01692/03692] [00:15:18/00:18:05, 0.543s/it]: train_loss_raw=1.4252, running_loss=1.4724, LR=0.000100
[2025-08-10 14:40:17,294][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023856] [Batch 01704/03692] [00:15:24/00:17:58, 0.543s/it]: train_loss_raw=1.5045, running_loss=1.4743, LR=0.000100
[2025-08-10 14:40:23,574][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023868] [Batch 01716/03692] [00:15:30/00:17:51, 0.543s/it]: train_loss_raw=1.5230, running_loss=1.4749, LR=0.000100
[2025-08-10 14:40:29,592][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023880] [Batch 01728/03692] [00:15:36/00:17:44, 0.542s/it]: train_loss_raw=1.4278, running_loss=1.4759, LR=0.000100
[2025-08-10 14:40:35,661][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023892] [Batch 01740/03692] [00:15:43/00:17:37, 0.542s/it]: train_loss_raw=1.3940, running_loss=1.4755, LR=0.000100
[2025-08-10 14:40:41,901][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023904] [Batch 01752/03692] [00:15:49/00:17:31, 0.542s/it]: train_loss_raw=1.3932, running_loss=1.4746, LR=0.000100
[2025-08-10 14:40:48,443][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023916] [Batch 01764/03692] [00:15:55/00:17:24, 0.542s/it]: train_loss_raw=1.4839, running_loss=1.4717, LR=0.000100
[2025-08-10 14:40:54,938][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023928] [Batch 01776/03692] [00:16:02/00:17:18, 0.542s/it]: train_loss_raw=1.4499, running_loss=1.4732, LR=0.000100
[2025-08-10 14:41:01,598][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023940] [Batch 01788/03692] [00:16:08/00:17:11, 0.542s/it]: train_loss_raw=1.4939, running_loss=1.4714, LR=0.000100
[2025-08-10 14:41:08,154][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023952] [Batch 01800/03692] [00:16:15/00:17:05, 0.542s/it]: train_loss_raw=1.4378, running_loss=1.4689, LR=0.000100
[2025-08-10 14:41:14,353][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023964] [Batch 01812/03692] [00:16:21/00:16:58, 0.542s/it]: train_loss_raw=1.4625, running_loss=1.4698, LR=0.000100
[2025-08-10 14:41:20,559][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023976] [Batch 01824/03692] [00:16:27/00:16:51, 0.542s/it]: train_loss_raw=1.3622, running_loss=1.4672, LR=0.000100
[2025-08-10 14:41:26,902][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 023988] [Batch 01836/03692] [00:16:34/00:16:45, 0.542s/it]: train_loss_raw=1.4344, running_loss=1.4688, LR=0.000100
[2025-08-10 14:41:32,953][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024000] [Batch 01848/03692] [00:16:40/00:16:38, 0.541s/it]: train_loss_raw=1.3399, running_loss=1.4665, LR=0.000100
[2025-08-10 14:41:43,294][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024012] [Batch 01860/03692] [00:16:50/00:16:35, 0.543s/it]: train_loss_raw=1.3403, running_loss=1.4652, LR=0.000100
[2025-08-10 14:41:49,767][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024024] [Batch 01872/03692] [00:16:57/00:16:28, 0.543s/it]: train_loss_raw=1.5243, running_loss=1.4665, LR=0.000100
[2025-08-10 14:41:56,292][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024036] [Batch 01884/03692] [00:17:03/00:16:22, 0.543s/it]: train_loss_raw=1.4671, running_loss=1.4696, LR=0.000100
[2025-08-10 14:42:02,838][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024048] [Batch 01896/03692] [00:17:10/00:16:15, 0.543s/it]: train_loss_raw=1.3910, running_loss=1.4686, LR=0.000100
[2025-08-10 14:42:09,391][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024060] [Batch 01908/03692] [00:17:16/00:16:09, 0.543s/it]: train_loss_raw=1.4137, running_loss=1.4688, LR=0.000100
[2025-08-10 14:42:15,808][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024072] [Batch 01920/03692] [00:17:23/00:16:02, 0.543s/it]: train_loss_raw=1.4139, running_loss=1.4684, LR=0.000100
[2025-08-10 14:42:22,384][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024084] [Batch 01932/03692] [00:17:29/00:15:56, 0.543s/it]: train_loss_raw=1.4065, running_loss=1.4677, LR=0.000100
[2025-08-10 14:42:28,903][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024096] [Batch 01944/03692] [00:17:36/00:15:49, 0.543s/it]: train_loss_raw=1.3978, running_loss=1.4684, LR=0.000100
[2025-08-10 14:42:35,464][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024108] [Batch 01956/03692] [00:17:42/00:15:43, 0.543s/it]: train_loss_raw=1.5372, running_loss=1.4660, LR=0.000100
[2025-08-10 14:42:42,015][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024120] [Batch 01968/03692] [00:17:49/00:15:36, 0.543s/it]: train_loss_raw=1.5086, running_loss=1.4657, LR=0.000100
[2025-08-10 14:42:47,979][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024132] [Batch 01980/03692] [00:17:55/00:15:29, 0.543s/it]: train_loss_raw=1.3765, running_loss=1.4632, LR=0.000100
[2025-08-10 14:42:53,965][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024144] [Batch 01992/03692] [00:18:01/00:15:22, 0.543s/it]: train_loss_raw=1.4952, running_loss=1.4684, LR=0.000100
[2025-08-10 14:43:00,010][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024156] [Batch 02004/03692] [00:18:07/00:15:15, 0.543s/it]: train_loss_raw=1.4350, running_loss=1.4658, LR=0.000100
[2025-08-10 14:43:06,094][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024168] [Batch 02016/03692] [00:18:13/00:15:09, 0.542s/it]: train_loss_raw=1.4643, running_loss=1.4613, LR=0.000100
[2025-08-10 14:43:12,153][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024180] [Batch 02028/03692] [00:18:19/00:15:02, 0.542s/it]: train_loss_raw=1.4545, running_loss=1.4625, LR=0.000100
[2025-08-10 14:43:18,236][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024192] [Batch 02040/03692] [00:18:25/00:14:55, 0.542s/it]: train_loss_raw=1.4123, running_loss=1.4580, LR=0.000100
[2025-08-10 14:43:24,288][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024204] [Batch 02052/03692] [00:18:31/00:14:48, 0.542s/it]: train_loss_raw=1.5270, running_loss=1.4585, LR=0.000100
[2025-08-10 14:43:30,470][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024216] [Batch 02064/03692] [00:18:37/00:14:41, 0.542s/it]: train_loss_raw=1.4855, running_loss=1.4575, LR=0.000100
[2025-08-10 14:43:36,572][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024228] [Batch 02076/03692] [00:18:43/00:14:34, 0.541s/it]: train_loss_raw=1.3981, running_loss=1.4560, LR=0.000100
[2025-08-10 14:43:42,613][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024240] [Batch 02088/03692] [00:18:49/00:14:28, 0.541s/it]: train_loss_raw=1.3549, running_loss=1.4547, LR=0.000100
[2025-08-10 14:43:48,700][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024252] [Batch 02100/03692] [00:18:56/00:14:21, 0.541s/it]: train_loss_raw=1.4795, running_loss=1.4564, LR=0.000100
[2025-08-10 14:43:54,751][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024264] [Batch 02112/03692] [00:19:02/00:14:14, 0.541s/it]: train_loss_raw=1.4865, running_loss=1.4542, LR=0.000100
[2025-08-10 14:44:01,138][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024276] [Batch 02124/03692] [00:19:08/00:14:07, 0.541s/it]: train_loss_raw=1.5485, running_loss=1.4544, LR=0.000100
[2025-08-10 14:44:07,718][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024288] [Batch 02136/03692] [00:19:15/00:14:01, 0.541s/it]: train_loss_raw=1.4636, running_loss=1.4559, LR=0.000100
[2025-08-10 14:44:14,289][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024300] [Batch 02148/03692] [00:19:21/00:13:55, 0.541s/it]: train_loss_raw=1.4964, running_loss=1.4567, LR=0.000100
[2025-08-10 14:44:20,782][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024312] [Batch 02160/03692] [00:19:28/00:13:48, 0.541s/it]: train_loss_raw=1.3785, running_loss=1.4533, LR=0.000100
[2025-08-10 14:44:27,309][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024324] [Batch 02172/03692] [00:19:34/00:13:42, 0.541s/it]: train_loss_raw=1.4760, running_loss=1.4614, LR=0.000100
[2025-08-10 14:44:33,916][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024336] [Batch 02184/03692] [00:19:41/00:13:35, 0.541s/it]: train_loss_raw=1.3772, running_loss=1.4596, LR=0.000100
[2025-08-10 14:44:40,428][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024348] [Batch 02196/03692] [00:19:47/00:13:29, 0.541s/it]: train_loss_raw=1.5062, running_loss=1.4594, LR=0.000100
[2025-08-10 14:44:46,670][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024360] [Batch 02208/03692] [00:19:54/00:13:22, 0.541s/it]: train_loss_raw=1.4919, running_loss=1.4564, LR=0.000100
[2025-08-10 14:44:53,180][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024372] [Batch 02220/03692] [00:20:00/00:13:16, 0.541s/it]: train_loss_raw=1.3563, running_loss=1.4557, LR=0.000100
[2025-08-10 14:44:59,683][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024384] [Batch 02232/03692] [00:20:07/00:13:09, 0.541s/it]: train_loss_raw=1.4419, running_loss=1.4505, LR=0.000100
[2025-08-10 14:45:06,179][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024396] [Batch 02244/03692] [00:20:13/00:13:03, 0.541s/it]: train_loss_raw=1.4256, running_loss=1.4498, LR=0.000100
[2025-08-10 14:45:12,695][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024408] [Batch 02256/03692] [00:20:20/00:12:56, 0.541s/it]: train_loss_raw=1.3718, running_loss=1.4488, LR=0.000100
[2025-08-10 14:45:19,154][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024420] [Batch 02268/03692] [00:20:26/00:12:50, 0.541s/it]: train_loss_raw=1.6342, running_loss=1.4512, LR=0.000100
[2025-08-10 14:45:25,315][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024432] [Batch 02280/03692] [00:20:32/00:12:43, 0.541s/it]: train_loss_raw=1.4788, running_loss=1.4553, LR=0.000100
[2025-08-10 14:45:31,826][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024444] [Batch 02292/03692] [00:20:39/00:12:36, 0.541s/it]: train_loss_raw=1.4256, running_loss=1.4542, LR=0.000100
[2025-08-10 14:45:38,450][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024456] [Batch 02304/03692] [00:20:45/00:12:30, 0.541s/it]: train_loss_raw=1.4649, running_loss=1.4503, LR=0.000100
[2025-08-10 14:45:44,985][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024468] [Batch 02316/03692] [00:20:52/00:12:24, 0.541s/it]: train_loss_raw=1.4463, running_loss=1.4447, LR=0.000100
[2025-08-10 14:45:51,601][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024480] [Batch 02328/03692] [00:20:58/00:12:17, 0.541s/it]: train_loss_raw=1.6069, running_loss=1.4448, LR=0.000100
[2025-08-10 14:45:58,140][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024492] [Batch 02340/03692] [00:21:05/00:12:11, 0.541s/it]: train_loss_raw=1.5049, running_loss=1.4456, LR=0.000100
[2025-08-10 14:46:04,679][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024504] [Batch 02352/03692] [00:21:12/00:12:04, 0.541s/it]: train_loss_raw=1.5409, running_loss=1.4461, LR=0.000100
[2025-08-10 14:46:11,240][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024516] [Batch 02364/03692] [00:21:18/00:11:58, 0.541s/it]: train_loss_raw=1.5164, running_loss=1.4494, LR=0.000100
[2025-08-10 14:46:17,371][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024528] [Batch 02376/03692] [00:21:24/00:11:51, 0.541s/it]: train_loss_raw=1.5001, running_loss=1.4526, LR=0.000100
[2025-08-10 14:46:23,801][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024540] [Batch 02388/03692] [00:21:31/00:11:45, 0.541s/it]: train_loss_raw=1.5137, running_loss=1.4531, LR=0.000100
[2025-08-10 14:46:30,144][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024552] [Batch 02400/03692] [00:21:37/00:11:38, 0.541s/it]: train_loss_raw=1.4170, running_loss=1.4502, LR=0.000100
[2025-08-10 14:46:36,228][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024564] [Batch 02412/03692] [00:21:43/00:11:31, 0.540s/it]: train_loss_raw=1.2834, running_loss=1.4467, LR=0.000100
[2025-08-10 14:46:42,315][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024576] [Batch 02424/03692] [00:21:49/00:11:25, 0.540s/it]: train_loss_raw=1.5011, running_loss=1.4460, LR=0.000100
[2025-08-10 14:46:48,359][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024588] [Batch 02436/03692] [00:21:55/00:11:18, 0.540s/it]: train_loss_raw=1.5566, running_loss=1.4488, LR=0.000100
[2025-08-10 14:46:54,421][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024600] [Batch 02448/03692] [00:22:01/00:11:11, 0.540s/it]: train_loss_raw=1.4642, running_loss=1.4493, LR=0.000100
[2025-08-10 14:47:00,539][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024612] [Batch 02460/03692] [00:22:07/00:11:05, 0.540s/it]: train_loss_raw=1.4604, running_loss=1.4511, LR=0.000100
[2025-08-10 14:47:06,677][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024624] [Batch 02472/03692] [00:22:14/00:10:58, 0.540s/it]: train_loss_raw=1.3272, running_loss=1.4505, LR=0.000100
[2025-08-10 14:47:13,284][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024636] [Batch 02484/03692] [00:22:20/00:10:51, 0.540s/it]: train_loss_raw=1.3743, running_loss=1.4505, LR=0.000100
[2025-08-10 14:47:19,369][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024648] [Batch 02496/03692] [00:22:26/00:10:45, 0.540s/it]: train_loss_raw=1.4807, running_loss=1.4510, LR=0.000100
[2025-08-10 14:47:25,575][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024660] [Batch 02508/03692] [00:22:32/00:10:38, 0.539s/it]: train_loss_raw=1.4808, running_loss=1.4552, LR=0.000100
[2025-08-10 14:47:31,570][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024672] [Batch 02520/03692] [00:22:38/00:10:32, 0.539s/it]: train_loss_raw=1.4433, running_loss=1.4534, LR=0.000100
[2025-08-10 14:47:37,816][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024684] [Batch 02532/03692] [00:22:45/00:10:25, 0.539s/it]: train_loss_raw=1.5355, running_loss=1.4548, LR=0.000100
[2025-08-10 14:47:43,951][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024696] [Batch 02544/03692] [00:22:51/00:10:18, 0.539s/it]: train_loss_raw=1.3574, running_loss=1.4503, LR=0.000100
[2025-08-10 14:47:49,994][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024708] [Batch 02556/03692] [00:22:57/00:10:12, 0.539s/it]: train_loss_raw=1.4336, running_loss=1.4466, LR=0.000100
[2025-08-10 14:47:56,118][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024720] [Batch 02568/03692] [00:23:03/00:10:05, 0.539s/it]: train_loss_raw=1.3350, running_loss=1.4466, LR=0.000100
[2025-08-10 14:48:02,693][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024732] [Batch 02580/03692] [00:23:10/00:09:59, 0.539s/it]: train_loss_raw=1.4655, running_loss=1.4497, LR=0.000100
[2025-08-10 14:48:09,269][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024744] [Batch 02592/03692] [00:23:16/00:09:52, 0.539s/it]: train_loss_raw=1.4332, running_loss=1.4519, LR=0.000100
[2025-08-10 14:48:15,885][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024756] [Batch 02604/03692] [00:23:23/00:09:46, 0.539s/it]: train_loss_raw=1.4157, running_loss=1.4524, LR=0.000100
[2025-08-10 14:48:22,434][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024768] [Batch 02616/03692] [00:23:29/00:09:39, 0.539s/it]: train_loss_raw=1.4392, running_loss=1.4574, LR=0.000100
[2025-08-10 14:48:28,713][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024780] [Batch 02628/03692] [00:23:36/00:09:33, 0.539s/it]: train_loss_raw=1.4564, running_loss=1.4527, LR=0.000100
[2025-08-10 14:48:34,870][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024792] [Batch 02640/03692] [00:23:42/00:09:26, 0.539s/it]: train_loss_raw=1.4279, running_loss=1.4508, LR=0.000100
[2025-08-10 14:48:41,109][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024804] [Batch 02652/03692] [00:23:48/00:09:20, 0.539s/it]: train_loss_raw=1.5082, running_loss=1.4548, LR=0.000100
[2025-08-10 14:48:47,289][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024816] [Batch 02664/03692] [00:23:54/00:09:13, 0.539s/it]: train_loss_raw=1.5406, running_loss=1.4543, LR=0.000100
[2025-08-10 14:48:53,586][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024828] [Batch 02676/03692] [00:24:00/00:09:07, 0.538s/it]: train_loss_raw=1.4451, running_loss=1.4498, LR=0.000100
[2025-08-10 14:48:59,894][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024840] [Batch 02688/03692] [00:24:07/00:09:00, 0.538s/it]: train_loss_raw=1.4257, running_loss=1.4491, LR=0.000100
[2025-08-10 14:49:06,202][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024852] [Batch 02700/03692] [00:24:13/00:08:54, 0.538s/it]: train_loss_raw=1.4880, running_loss=1.4509, LR=0.000100
[2025-08-10 14:49:12,263][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024864] [Batch 02712/03692] [00:24:19/00:08:47, 0.538s/it]: train_loss_raw=1.5279, running_loss=1.4470, LR=0.000100
[2025-08-10 14:49:18,293][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024876] [Batch 02724/03692] [00:24:25/00:08:40, 0.538s/it]: train_loss_raw=1.5123, running_loss=1.4478, LR=0.000100
[2025-08-10 14:49:24,388][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024888] [Batch 02736/03692] [00:24:31/00:08:34, 0.538s/it]: train_loss_raw=1.5402, running_loss=1.4479, LR=0.000100
[2025-08-10 14:49:30,375][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024900] [Batch 02748/03692] [00:24:37/00:08:27, 0.538s/it]: train_loss_raw=1.3747, running_loss=1.4442, LR=0.000100
[2025-08-10 14:49:36,687][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024912] [Batch 02760/03692] [00:24:44/00:08:21, 0.538s/it]: train_loss_raw=1.3676, running_loss=1.4412, LR=0.000100
[2025-08-10 14:49:43,117][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024924] [Batch 02772/03692] [00:24:50/00:08:14, 0.538s/it]: train_loss_raw=1.4148, running_loss=1.4438, LR=0.000100
[2025-08-10 14:49:49,487][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024936] [Batch 02784/03692] [00:24:56/00:08:08, 0.538s/it]: train_loss_raw=1.4531, running_loss=1.4453, LR=0.000100
[2025-08-10 14:49:55,711][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024948] [Batch 02796/03692] [00:25:03/00:08:01, 0.538s/it]: train_loss_raw=1.4311, running_loss=1.4430, LR=0.000100
[2025-08-10 14:50:01,781][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024960] [Batch 02808/03692] [00:25:09/00:07:55, 0.537s/it]: train_loss_raw=1.3073, running_loss=1.4423, LR=0.000100
[2025-08-10 14:50:07,817][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024972] [Batch 02820/03692] [00:25:15/00:07:48, 0.537s/it]: train_loss_raw=1.3979, running_loss=1.4448, LR=0.000100
[2025-08-10 14:50:14,089][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024984] [Batch 02832/03692] [00:25:21/00:07:42, 0.537s/it]: train_loss_raw=1.3386, running_loss=1.4435, LR=0.000100
[2025-08-10 14:50:20,406][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 024996] [Batch 02844/03692] [00:25:27/00:07:35, 0.537s/it]: train_loss_raw=1.3936, running_loss=1.4448, LR=0.000100
[2025-08-10 14:50:26,504][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025008] [Batch 02856/03692] [00:25:33/00:07:28, 0.537s/it]: train_loss_raw=1.5607, running_loss=1.4477, LR=0.000100
[2025-08-10 14:50:32,539][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025020] [Batch 02868/03692] [00:25:39/00:07:22, 0.537s/it]: train_loss_raw=1.3923, running_loss=1.4453, LR=0.000100
[2025-08-10 14:50:38,601][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025032] [Batch 02880/03692] [00:25:45/00:07:15, 0.537s/it]: train_loss_raw=1.5261, running_loss=1.4495, LR=0.000100
[2025-08-10 14:50:44,623][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025044] [Batch 02892/03692] [00:25:51/00:07:09, 0.537s/it]: train_loss_raw=1.3773, running_loss=1.4458, LR=0.000100
[2025-08-10 14:50:50,671][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025056] [Batch 02904/03692] [00:25:58/00:07:02, 0.537s/it]: train_loss_raw=1.5670, running_loss=1.4499, LR=0.000100
[2025-08-10 14:50:56,738][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025068] [Batch 02916/03692] [00:26:04/00:06:56, 0.536s/it]: train_loss_raw=1.5100, running_loss=1.4497, LR=0.000100
[2025-08-10 14:51:03,183][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025080] [Batch 02928/03692] [00:26:10/00:06:49, 0.536s/it]: train_loss_raw=1.5033, running_loss=1.4479, LR=0.000100
[2025-08-10 14:51:09,719][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025092] [Batch 02940/03692] [00:26:17/00:06:43, 0.536s/it]: train_loss_raw=1.5096, running_loss=1.4461, LR=0.000100
[2025-08-10 14:51:16,235][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025104] [Batch 02952/03692] [00:26:23/00:06:36, 0.536s/it]: train_loss_raw=1.4763, running_loss=1.4406, LR=0.000100
[2025-08-10 14:51:22,869][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025116] [Batch 02964/03692] [00:26:30/00:06:30, 0.537s/it]: train_loss_raw=1.3961, running_loss=1.4416, LR=0.000100
[2025-08-10 14:51:29,458][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025128] [Batch 02976/03692] [00:26:36/00:06:24, 0.537s/it]: train_loss_raw=1.3152, running_loss=1.4402, LR=0.000100
[2025-08-10 14:51:35,817][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025140] [Batch 02988/03692] [00:26:43/00:06:17, 0.537s/it]: train_loss_raw=1.5686, running_loss=1.4420, LR=0.000100
[2025-08-10 14:51:41,881][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025152] [Batch 03000/03692] [00:26:49/00:06:11, 0.536s/it]: train_loss_raw=1.4386, running_loss=1.4412, LR=0.000100
[2025-08-10 14:51:47,976][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025164] [Batch 03012/03692] [00:26:55/00:06:04, 0.536s/it]: train_loss_raw=1.4988, running_loss=1.4361, LR=0.000100
[2025-08-10 14:51:54,166][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025176] [Batch 03024/03692] [00:27:01/00:05:58, 0.536s/it]: train_loss_raw=1.4208, running_loss=1.4378, LR=0.000100
[2025-08-10 14:52:00,508][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025188] [Batch 03036/03692] [00:27:07/00:05:51, 0.536s/it]: train_loss_raw=1.4029, running_loss=1.4383, LR=0.000100
[2025-08-10 14:52:06,550][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025200] [Batch 03048/03692] [00:27:13/00:05:45, 0.536s/it]: train_loss_raw=1.3454, running_loss=1.4390, LR=0.000100
[2025-08-10 14:52:12,930][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025212] [Batch 03060/03692] [00:27:20/00:05:38, 0.536s/it]: train_loss_raw=1.2973, running_loss=1.4373, LR=0.000100
[2025-08-10 14:52:19,535][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025224] [Batch 03072/03692] [00:27:26/00:05:32, 0.536s/it]: train_loss_raw=1.4859, running_loss=1.4370, LR=0.000100
[2025-08-10 14:52:25,855][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025236] [Batch 03084/03692] [00:27:33/00:05:25, 0.536s/it]: train_loss_raw=1.3570, running_loss=1.4355, LR=0.000100
[2025-08-10 14:52:32,071][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025248] [Batch 03096/03692] [00:27:39/00:05:19, 0.536s/it]: train_loss_raw=1.3415, running_loss=1.4309, LR=0.000100
[2025-08-10 14:52:38,607][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025260] [Batch 03108/03692] [00:27:45/00:05:13, 0.536s/it]: train_loss_raw=1.4100, running_loss=1.4313, LR=0.000100
[2025-08-10 14:52:45,143][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025272] [Batch 03120/03692] [00:27:52/00:05:06, 0.536s/it]: train_loss_raw=1.4231, running_loss=1.4313, LR=0.000100
[2025-08-10 14:52:51,197][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025284] [Batch 03132/03692] [00:27:58/00:05:00, 0.536s/it]: train_loss_raw=1.3670, running_loss=1.4336, LR=0.000100
[2025-08-10 14:52:57,320][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025296] [Batch 03144/03692] [00:28:04/00:04:53, 0.536s/it]: train_loss_raw=1.4362, running_loss=1.4353, LR=0.000100
[2025-08-10 14:53:03,869][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025308] [Batch 03156/03692] [00:28:11/00:04:47, 0.536s/it]: train_loss_raw=1.4575, running_loss=1.4365, LR=0.000100
[2025-08-10 14:53:10,364][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025320] [Batch 03168/03692] [00:28:17/00:04:40, 0.536s/it]: train_loss_raw=1.5920, running_loss=1.4358, LR=0.000100
[2025-08-10 14:53:16,894][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025332] [Batch 03180/03692] [00:28:24/00:04:34, 0.536s/it]: train_loss_raw=1.3729, running_loss=1.4326, LR=0.000100
[2025-08-10 14:53:23,457][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025344] [Batch 03192/03692] [00:28:30/00:04:27, 0.536s/it]: train_loss_raw=1.4512, running_loss=1.4340, LR=0.000100
[2025-08-10 14:53:30,071][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025356] [Batch 03204/03692] [00:28:37/00:04:21, 0.536s/it]: train_loss_raw=1.5067, running_loss=1.4355, LR=0.000100
[2025-08-10 14:53:36,285][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025368] [Batch 03216/03692] [00:28:43/00:04:15, 0.536s/it]: train_loss_raw=1.4423, running_loss=1.4354, LR=0.000100
[2025-08-10 14:53:42,456][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025380] [Batch 03228/03692] [00:28:49/00:04:08, 0.536s/it]: train_loss_raw=1.5149, running_loss=1.4399, LR=0.000100
[2025-08-10 14:53:48,594][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025392] [Batch 03240/03692] [00:28:55/00:04:02, 0.536s/it]: train_loss_raw=1.4605, running_loss=1.4380, LR=0.000100
[2025-08-10 14:53:54,970][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025404] [Batch 03252/03692] [00:29:02/00:03:55, 0.536s/it]: train_loss_raw=1.4706, running_loss=1.4348, LR=0.000100
[2025-08-10 14:54:01,164][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025416] [Batch 03264/03692] [00:29:08/00:03:49, 0.536s/it]: train_loss_raw=1.4054, running_loss=1.4364, LR=0.000100
[2025-08-10 14:54:07,269][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025428] [Batch 03276/03692] [00:29:14/00:03:42, 0.536s/it]: train_loss_raw=1.4935, running_loss=1.4388, LR=0.000100
[2025-08-10 14:54:13,353][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025440] [Batch 03288/03692] [00:29:20/00:03:36, 0.535s/it]: train_loss_raw=1.4989, running_loss=1.4369, LR=0.000100
[2025-08-10 14:54:19,415][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025452] [Batch 03300/03692] [00:29:26/00:03:29, 0.535s/it]: train_loss_raw=1.4576, running_loss=1.4383, LR=0.000100
[2025-08-10 14:54:25,565][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025464] [Batch 03312/03692] [00:29:32/00:03:23, 0.535s/it]: train_loss_raw=1.3635, running_loss=1.4373, LR=0.000100
[2025-08-10 14:54:31,676][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025476] [Batch 03324/03692] [00:29:39/00:03:16, 0.535s/it]: train_loss_raw=1.5065, running_loss=1.4332, LR=0.000100
[2025-08-10 14:54:37,741][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025488] [Batch 03336/03692] [00:29:45/00:03:10, 0.535s/it]: train_loss_raw=1.1994, running_loss=1.4362, LR=0.000100
[2025-08-10 14:54:44,057][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025500] [Batch 03348/03692] [00:29:51/00:03:04, 0.535s/it]: train_loss_raw=1.5109, running_loss=1.4443, LR=0.000100
[2025-08-10 14:54:50,585][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025512] [Batch 03360/03692] [00:29:57/00:02:57, 0.535s/it]: train_loss_raw=1.3988, running_loss=1.4419, LR=0.000100
[2025-08-10 14:54:57,190][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025524] [Batch 03372/03692] [00:30:04/00:02:51, 0.535s/it]: train_loss_raw=1.4243, running_loss=1.4399, LR=0.000100
[2025-08-10 14:55:03,741][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025536] [Batch 03384/03692] [00:30:11/00:02:44, 0.535s/it]: train_loss_raw=1.5092, running_loss=1.4429, LR=0.000100
[2025-08-10 14:55:10,281][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025548] [Batch 03396/03692] [00:30:17/00:02:38, 0.535s/it]: train_loss_raw=1.4827, running_loss=1.4432, LR=0.000100
[2025-08-10 14:55:16,830][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025560] [Batch 03408/03692] [00:30:24/00:02:32, 0.535s/it]: train_loss_raw=1.4761, running_loss=1.4390, LR=0.000100
[2025-08-10 14:55:23,371][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025572] [Batch 03420/03692] [00:30:30/00:02:25, 0.535s/it]: train_loss_raw=1.5408, running_loss=1.4384, LR=0.000100
[2025-08-10 14:55:29,922][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025584] [Batch 03432/03692] [00:30:37/00:02:19, 0.535s/it]: train_loss_raw=1.3446, running_loss=1.4398, LR=0.000100
[2025-08-10 14:55:36,651][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025596] [Batch 03444/03692] [00:30:44/00:02:12, 0.535s/it]: train_loss_raw=1.4790, running_loss=1.4423, LR=0.000100
[2025-08-10 14:55:43,216][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025608] [Batch 03456/03692] [00:30:50/00:02:06, 0.535s/it]: train_loss_raw=1.4569, running_loss=1.4438, LR=0.000100
[2025-08-10 14:55:49,320][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025620] [Batch 03468/03692] [00:30:56/00:01:59, 0.535s/it]: train_loss_raw=1.4187, running_loss=1.4440, LR=0.000100
[2025-08-10 14:55:55,414][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025632] [Batch 03480/03692] [00:31:02/00:01:53, 0.535s/it]: train_loss_raw=1.4572, running_loss=1.4378, LR=0.000100
[2025-08-10 14:56:01,886][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025644] [Batch 03492/03692] [00:31:09/00:01:47, 0.535s/it]: train_loss_raw=1.3272, running_loss=1.4354, LR=0.000100
[2025-08-10 14:56:08,351][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025656] [Batch 03504/03692] [00:31:15/00:01:40, 0.535s/it]: train_loss_raw=1.4608, running_loss=1.4370, LR=0.000100
[2025-08-10 14:56:14,620][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025668] [Batch 03516/03692] [00:31:21/00:01:34, 0.535s/it]: train_loss_raw=1.4326, running_loss=1.4356, LR=0.000100
[2025-08-10 14:56:20,942][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025680] [Batch 03528/03692] [00:31:28/00:01:27, 0.535s/it]: train_loss_raw=1.4824, running_loss=1.4330, LR=0.000100
[2025-08-10 14:56:27,127][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025692] [Batch 03540/03692] [00:31:34/00:01:21, 0.535s/it]: train_loss_raw=1.5460, running_loss=1.4368, LR=0.000100
[2025-08-10 14:56:33,559][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025704] [Batch 03552/03692] [00:31:40/00:01:14, 0.535s/it]: train_loss_raw=1.3779, running_loss=1.4334, LR=0.000100
[2025-08-10 14:56:39,604][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025716] [Batch 03564/03692] [00:31:46/00:01:08, 0.535s/it]: train_loss_raw=1.3883, running_loss=1.4292, LR=0.000100
[2025-08-10 14:56:45,785][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025728] [Batch 03576/03692] [00:31:53/00:01:02, 0.535s/it]: train_loss_raw=1.4269, running_loss=1.4251, LR=0.000100
[2025-08-10 14:56:52,338][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025740] [Batch 03588/03692] [00:31:59/00:00:55, 0.535s/it]: train_loss_raw=1.4920, running_loss=1.4236, LR=0.000100
[2025-08-10 14:56:58,902][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025752] [Batch 03600/03692] [00:32:06/00:00:49, 0.535s/it]: train_loss_raw=1.3784, running_loss=1.4235, LR=0.000100
[2025-08-10 14:57:05,401][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025764] [Batch 03612/03692] [00:32:12/00:00:42, 0.535s/it]: train_loss_raw=1.4897, running_loss=1.4247, LR=0.000100
[2025-08-10 14:57:11,928][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025776] [Batch 03624/03692] [00:32:19/00:00:36, 0.535s/it]: train_loss_raw=1.3880, running_loss=1.4217, LR=0.000100
[2025-08-10 14:57:18,491][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025788] [Batch 03636/03692] [00:32:25/00:00:29, 0.535s/it]: train_loss_raw=1.4043, running_loss=1.4223, LR=0.000100
[2025-08-10 14:57:24,831][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025800] [Batch 03648/03692] [00:32:32/00:00:23, 0.535s/it]: train_loss_raw=1.5156, running_loss=1.4245, LR=0.000100
[2025-08-10 14:57:30,841][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025812] [Batch 03660/03692] [00:32:38/00:00:17, 0.535s/it]: train_loss_raw=1.3831, running_loss=1.4237, LR=0.000100
[2025-08-10 14:57:36,900][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025824] [Batch 03672/03692] [00:32:44/00:00:10, 0.535s/it]: train_loss_raw=1.4616, running_loss=1.4240, LR=0.000100
[2025-08-10 14:57:43,016][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 025836] [Batch 03684/03692] [00:32:50/00:00:04, 0.535s/it]: train_loss_raw=1.3787, running_loss=1.4196, LR=0.000100
[2025-08-10 14:57:52,471][__main__][INFO] - [VALIDATION] [Epoch 06/29] Starting validation.
[2025-08-10 14:58:26,633][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 025845] [Batch 00011/00025] [00:00:34/00:00:37, 2.847s/it]
[2025-08-10 14:58:43,856][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 025845] [Batch 00023/00025] [00:00:51/00:00:02, 2.141s/it]
[2025-08-10 14:58:45,152][__main__][INFO] - [VALIDATION] [Epoch 06/29] train_loss=1.41881, valid_loss=1.31724
[2025-08-10 14:58:45,153][__main__][INFO] - [VALIDATION] [Epoch 06/29] Metrics:
[2025-08-10 14:58:45,153][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_er      0.569
[2025-08-10 14:58:45,154][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_prec    0.156
[2025-08-10 14:58:45,154][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_recall  0.161
[2025-08-10 14:58:45,154][__main__][INFO] - [VALIDATION] [Epoch 06/29] - pep_recall 0.113
[2025-08-10 14:58:45,157][__main__][INFO] - [TRAIN] [Epoch 06/29] Epoch complete, total time 04:02:44, remaining time 13:17:34, 00:34:40 per epoch
[2025-08-10 14:58:48,130][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025848] [Batch 00004/03692] [00:00:01/00:26:28, 0.431s/it]: train_loss_raw=1.5163, running_loss=1.3906, LR=0.000100
[2025-08-10 14:58:54,695][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025860] [Batch 00016/03692] [00:00:08/00:31:44, 0.518s/it]: train_loss_raw=1.4571, running_loss=1.3956, LR=0.000100
[2025-08-10 14:59:01,284][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025872] [Batch 00028/03692] [00:00:14/00:32:26, 0.531s/it]: train_loss_raw=1.4037, running_loss=1.4034, LR=0.000100
[2025-08-10 14:59:07,820][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025884] [Batch 00040/03692] [00:00:21/00:32:35, 0.535s/it]: train_loss_raw=1.4128, running_loss=1.4031, LR=0.000100
[2025-08-10 14:59:14,382][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025896] [Batch 00052/03692] [00:00:27/00:32:38, 0.538s/it]: train_loss_raw=1.4078, running_loss=1.3990, LR=0.000100
[2025-08-10 14:59:20,590][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025908] [Batch 00064/03692] [00:00:34/00:32:17, 0.534s/it]: train_loss_raw=1.4850, running_loss=1.3972, LR=0.000100
[2025-08-10 14:59:26,689][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025920] [Batch 00076/03692] [00:00:40/00:31:56, 0.530s/it]: train_loss_raw=1.3752, running_loss=1.3975, LR=0.000100
[2025-08-10 14:59:32,943][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025932] [Batch 00088/03692] [00:00:46/00:31:45, 0.529s/it]: train_loss_raw=1.4346, running_loss=1.4003, LR=0.000100
[2025-08-10 14:59:39,507][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025944] [Batch 00100/03692] [00:00:53/00:31:47, 0.531s/it]: train_loss_raw=1.5909, running_loss=1.4040, LR=0.000100
[2025-08-10 14:59:45,956][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025956] [Batch 00112/03692] [00:00:59/00:31:43, 0.532s/it]: train_loss_raw=1.4433, running_loss=1.4078, LR=0.000100
[2025-08-10 14:59:51,996][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025968] [Batch 00124/03692] [00:01:05/00:31:27, 0.529s/it]: train_loss_raw=1.3461, running_loss=1.4107, LR=0.000100
[2025-08-10 14:59:58,045][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025980] [Batch 00136/03692] [00:01:11/00:31:13, 0.527s/it]: train_loss_raw=1.5093, running_loss=1.4120, LR=0.000100
[2025-08-10 15:00:04,277][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 025992] [Batch 00148/03692] [00:01:17/00:31:04, 0.526s/it]: train_loss_raw=1.3474, running_loss=1.4086, LR=0.000100
[2025-08-10 15:00:15,904][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026004] [Batch 00160/03692] [00:01:29/00:32:55, 0.559s/it]: train_loss_raw=1.4408, running_loss=1.4152, LR=0.000100
[2025-08-10 15:00:21,941][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026016] [Batch 00172/03692] [00:01:35/00:32:35, 0.555s/it]: train_loss_raw=1.3775, running_loss=1.4141, LR=0.000100
[2025-08-10 15:00:28,299][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026028] [Batch 00184/03692] [00:01:41/00:32:22, 0.554s/it]: train_loss_raw=1.3067, running_loss=1.4143, LR=0.000100
[2025-08-10 15:00:34,845][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026040] [Batch 00196/03692] [00:01:48/00:32:14, 0.553s/it]: train_loss_raw=1.4301, running_loss=1.4131, LR=0.000100
[2025-08-10 15:00:41,375][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026052] [Batch 00208/03692] [00:01:54/00:32:05, 0.553s/it]: train_loss_raw=1.3608, running_loss=1.4157, LR=0.000100
[2025-08-10 15:00:47,895][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026064] [Batch 00220/03692] [00:02:01/00:31:57, 0.552s/it]: train_loss_raw=1.4333, running_loss=1.4130, LR=0.000100
[2025-08-10 15:00:54,149][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026076] [Batch 00232/03692] [00:02:07/00:31:45, 0.551s/it]: train_loss_raw=1.4515, running_loss=1.4101, LR=0.000100
[2025-08-10 15:01:00,277][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026088] [Batch 00244/03692] [00:02:13/00:31:31, 0.549s/it]: train_loss_raw=1.3697, running_loss=1.4123, LR=0.000100
[2025-08-10 15:01:06,337][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026100] [Batch 00256/03692] [00:02:19/00:31:18, 0.547s/it]: train_loss_raw=1.5438, running_loss=1.4147, LR=0.000100
[2025-08-10 15:01:12,763][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026112] [Batch 00268/03692] [00:02:26/00:31:09, 0.546s/it]: train_loss_raw=1.4544, running_loss=1.4139, LR=0.000100
[2025-08-10 15:01:19,329][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026124] [Batch 00280/03692] [00:02:32/00:31:03, 0.546s/it]: train_loss_raw=1.4399, running_loss=1.4131, LR=0.000100
[2025-08-10 15:01:26,001][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026136] [Batch 00292/03692] [00:02:39/00:30:58, 0.547s/it]: train_loss_raw=1.3143, running_loss=1.4124, LR=0.000100
[2025-08-10 15:01:32,513][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026148] [Batch 00304/03692] [00:02:46/00:30:51, 0.546s/it]: train_loss_raw=1.4096, running_loss=1.4112, LR=0.000100
[2025-08-10 15:01:38,668][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026160] [Batch 00316/03692] [00:02:52/00:30:40, 0.545s/it]: train_loss_raw=1.3081, running_loss=1.4060, LR=0.000100
[2025-08-10 15:01:45,102][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026172] [Batch 00328/03692] [00:02:58/00:30:32, 0.545s/it]: train_loss_raw=1.3014, running_loss=1.4056, LR=0.000100
[2025-08-10 15:01:51,323][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026184] [Batch 00340/03692] [00:03:04/00:30:23, 0.544s/it]: train_loss_raw=1.5479, running_loss=1.4078, LR=0.000100
[2025-08-10 15:01:57,351][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026196] [Batch 00352/03692] [00:03:10/00:30:11, 0.542s/it]: train_loss_raw=1.3956, running_loss=1.4067, LR=0.000100
[2025-08-10 15:02:03,419][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026208] [Batch 00364/03692] [00:03:17/00:30:01, 0.541s/it]: train_loss_raw=1.4427, running_loss=1.4088, LR=0.000100
[2025-08-10 15:02:09,491][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026220] [Batch 00376/03692] [00:03:23/00:29:51, 0.540s/it]: train_loss_raw=1.4063, running_loss=1.4062, LR=0.000100
[2025-08-10 15:02:15,550][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026232] [Batch 00388/03692] [00:03:29/00:29:40, 0.539s/it]: train_loss_raw=1.2234, running_loss=1.4078, LR=0.000100
[2025-08-10 15:02:21,661][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026244] [Batch 00400/03692] [00:03:35/00:29:31, 0.538s/it]: train_loss_raw=1.4680, running_loss=1.4083, LR=0.000100
[2025-08-10 15:02:28,071][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026256] [Batch 00412/03692] [00:03:41/00:29:24, 0.538s/it]: train_loss_raw=1.3475, running_loss=1.4102, LR=0.000100
[2025-08-10 15:02:34,614][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026268] [Batch 00424/03692] [00:03:48/00:29:18, 0.538s/it]: train_loss_raw=1.3712, running_loss=1.4066, LR=0.000100
[2025-08-10 15:02:40,890][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026280] [Batch 00436/03692] [00:03:54/00:29:11, 0.538s/it]: train_loss_raw=1.3690, running_loss=1.4078, LR=0.000100
[2025-08-10 15:02:47,427][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026292] [Batch 00448/03692] [00:04:01/00:29:05, 0.538s/it]: train_loss_raw=1.3252, running_loss=1.4060, LR=0.000100
[2025-08-10 15:02:53,633][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026304] [Batch 00460/03692] [00:04:07/00:28:57, 0.537s/it]: train_loss_raw=1.4098, running_loss=1.4057, LR=0.000100
[2025-08-10 15:02:59,701][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026316] [Batch 00472/03692] [00:04:13/00:28:47, 0.537s/it]: train_loss_raw=1.3511, running_loss=1.4009, LR=0.000100
[2025-08-10 15:03:05,772][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026328] [Batch 00484/03692] [00:04:19/00:28:39, 0.536s/it]: train_loss_raw=1.3534, running_loss=1.4014, LR=0.000100
[2025-08-10 15:03:11,861][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026340] [Batch 00496/03692] [00:04:25/00:28:30, 0.535s/it]: train_loss_raw=1.3236, running_loss=1.3993, LR=0.000100
[2025-08-10 15:03:17,968][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026352] [Batch 00508/03692] [00:04:31/00:28:22, 0.535s/it]: train_loss_raw=1.3568, running_loss=1.3961, LR=0.000100
[2025-08-10 15:03:24,039][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026364] [Batch 00520/03692] [00:04:37/00:28:13, 0.534s/it]: train_loss_raw=1.2338, running_loss=1.3927, LR=0.000100
[2025-08-10 15:03:30,309][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026376] [Batch 00532/03692] [00:04:43/00:28:06, 0.534s/it]: train_loss_raw=1.5632, running_loss=1.3947, LR=0.000100
[2025-08-10 15:03:36,975][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026388] [Batch 00544/03692] [00:04:50/00:28:01, 0.534s/it]: train_loss_raw=1.4465, running_loss=1.3912, LR=0.000100
[2025-08-10 15:03:43,530][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026400] [Batch 00556/03692] [00:04:57/00:27:55, 0.534s/it]: train_loss_raw=1.2919, running_loss=1.3931, LR=0.000100
[2025-08-10 15:03:50,126][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026412] [Batch 00568/03692] [00:05:03/00:27:50, 0.535s/it]: train_loss_raw=1.3951, running_loss=1.3968, LR=0.000100
[2025-08-10 15:03:56,697][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026424] [Batch 00580/03692] [00:05:10/00:27:44, 0.535s/it]: train_loss_raw=1.4899, running_loss=1.3974, LR=0.000100
[2025-08-10 15:04:02,788][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026436] [Batch 00592/03692] [00:05:16/00:27:36, 0.534s/it]: train_loss_raw=1.3839, running_loss=1.3963, LR=0.000100
[2025-08-10 15:04:08,835][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026448] [Batch 00604/03692] [00:05:22/00:27:28, 0.534s/it]: train_loss_raw=1.4767, running_loss=1.3936, LR=0.000100
[2025-08-10 15:04:14,927][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026460] [Batch 00616/03692] [00:05:28/00:27:20, 0.533s/it]: train_loss_raw=1.5307, running_loss=1.3945, LR=0.000100
[2025-08-10 15:04:21,131][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026472] [Batch 00628/03692] [00:05:34/00:27:13, 0.533s/it]: train_loss_raw=1.3732, running_loss=1.3952, LR=0.000100
[2025-08-10 15:04:27,609][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026484] [Batch 00640/03692] [00:05:41/00:27:07, 0.533s/it]: train_loss_raw=1.4266, running_loss=1.3973, LR=0.000100
[2025-08-10 15:04:33,820][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026496] [Batch 00652/03692] [00:05:47/00:26:59, 0.533s/it]: train_loss_raw=1.3268, running_loss=1.4006, LR=0.000100
[2025-08-10 15:04:40,285][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026508] [Batch 00664/03692] [00:05:53/00:26:53, 0.533s/it]: train_loss_raw=1.4113, running_loss=1.4011, LR=0.000100
[2025-08-10 15:04:46,572][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026520] [Batch 00676/03692] [00:06:00/00:26:46, 0.533s/it]: train_loss_raw=1.4442, running_loss=1.3966, LR=0.000100
[2025-08-10 15:04:52,647][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026532] [Batch 00688/03692] [00:06:06/00:26:39, 0.532s/it]: train_loss_raw=1.3527, running_loss=1.3956, LR=0.000100
[2025-08-10 15:04:58,680][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026544] [Batch 00700/03692] [00:06:12/00:26:31, 0.532s/it]: train_loss_raw=1.2778, running_loss=1.3951, LR=0.000100
[2025-08-10 15:05:04,703][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026556] [Batch 00712/03692] [00:06:18/00:26:23, 0.531s/it]: train_loss_raw=1.4333, running_loss=1.3974, LR=0.000100
[2025-08-10 15:05:10,730][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026568] [Batch 00724/03692] [00:06:24/00:26:15, 0.531s/it]: train_loss_raw=1.3524, running_loss=1.3947, LR=0.000100
[2025-08-10 15:05:17,148][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026580] [Batch 00736/03692] [00:06:30/00:26:09, 0.531s/it]: train_loss_raw=1.3156, running_loss=1.4011, LR=0.000100
[2025-08-10 15:05:23,788][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026592] [Batch 00748/03692] [00:06:37/00:26:04, 0.531s/it]: train_loss_raw=1.4880, running_loss=1.4004, LR=0.000100
[2025-08-10 15:05:30,346][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026604] [Batch 00760/03692] [00:06:43/00:25:58, 0.532s/it]: train_loss_raw=1.4112, running_loss=1.3959, LR=0.000100
[2025-08-10 15:05:36,384][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026616] [Batch 00772/03692] [00:06:49/00:25:50, 0.531s/it]: train_loss_raw=1.5144, running_loss=1.3933, LR=0.000100
[2025-08-10 15:05:42,862][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026628] [Batch 00784/03692] [00:06:56/00:25:44, 0.531s/it]: train_loss_raw=1.3469, running_loss=1.3971, LR=0.000100
[2025-08-10 15:05:49,486][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026640] [Batch 00796/03692] [00:07:03/00:25:39, 0.532s/it]: train_loss_raw=1.4752, running_loss=1.4000, LR=0.000100
[2025-08-10 15:05:55,811][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026652] [Batch 00808/03692] [00:07:09/00:25:32, 0.531s/it]: train_loss_raw=1.4920, running_loss=1.4018, LR=0.000100
[2025-08-10 15:06:02,392][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026664] [Batch 00820/03692] [00:07:15/00:25:27, 0.532s/it]: train_loss_raw=1.4473, running_loss=1.4041, LR=0.000100
[2025-08-10 15:06:08,407][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026676] [Batch 00832/03692] [00:07:22/00:25:19, 0.531s/it]: train_loss_raw=1.2528, running_loss=1.3990, LR=0.000100
[2025-08-10 15:06:14,893][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026688] [Batch 00844/03692] [00:07:28/00:25:13, 0.531s/it]: train_loss_raw=1.3418, running_loss=1.3974, LR=0.000100
[2025-08-10 15:06:21,505][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026700] [Batch 00856/03692] [00:07:35/00:25:07, 0.532s/it]: train_loss_raw=1.2359, running_loss=1.3978, LR=0.000100
[2025-08-10 15:06:27,946][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026712] [Batch 00868/03692] [00:07:41/00:25:01, 0.532s/it]: train_loss_raw=1.5385, running_loss=1.4047, LR=0.000100
[2025-08-10 15:06:33,932][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026724] [Batch 00880/03692] [00:07:47/00:24:53, 0.531s/it]: train_loss_raw=1.5410, running_loss=1.4064, LR=0.000100
[2025-08-10 15:06:40,089][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026736] [Batch 00892/03692] [00:07:53/00:24:46, 0.531s/it]: train_loss_raw=1.3590, running_loss=1.4067, LR=0.000100
[2025-08-10 15:06:46,185][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026748] [Batch 00904/03692] [00:07:59/00:24:39, 0.531s/it]: train_loss_raw=1.4405, running_loss=1.4071, LR=0.000100
[2025-08-10 15:06:52,468][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026760] [Batch 00916/03692] [00:08:06/00:24:33, 0.531s/it]: train_loss_raw=1.4919, running_loss=1.4053, LR=0.000100
[2025-08-10 15:06:58,985][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026772] [Batch 00928/03692] [00:08:12/00:24:27, 0.531s/it]: train_loss_raw=1.4243, running_loss=1.4028, LR=0.000100
[2025-08-10 15:07:05,574][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026784] [Batch 00940/03692] [00:08:19/00:24:21, 0.531s/it]: train_loss_raw=1.4399, running_loss=1.4040, LR=0.000100
[2025-08-10 15:07:12,160][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026796] [Batch 00952/03692] [00:08:25/00:24:15, 0.531s/it]: train_loss_raw=1.3896, running_loss=1.4055, LR=0.000100
[2025-08-10 15:07:18,783][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026808] [Batch 00964/03692] [00:08:32/00:24:09, 0.532s/it]: train_loss_raw=1.1535, running_loss=1.3996, LR=0.000100
[2025-08-10 15:07:25,371][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026820] [Batch 00976/03692] [00:08:38/00:24:04, 0.532s/it]: train_loss_raw=1.4530, running_loss=1.3953, LR=0.000100
[2025-08-10 15:07:31,938][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026832] [Batch 00988/03692] [00:08:45/00:23:58, 0.532s/it]: train_loss_raw=1.1941, running_loss=1.3935, LR=0.000100
[2025-08-10 15:07:38,505][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026844] [Batch 01000/03692] [00:08:52/00:23:52, 0.532s/it]: train_loss_raw=1.3827, running_loss=1.3915, LR=0.000100
[2025-08-10 15:07:44,981][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026856] [Batch 01012/03692] [00:08:58/00:23:46, 0.532s/it]: train_loss_raw=1.4165, running_loss=1.3947, LR=0.000100
[2025-08-10 15:07:51,152][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026868] [Batch 01024/03692] [00:09:04/00:23:39, 0.532s/it]: train_loss_raw=1.4743, running_loss=1.3938, LR=0.000100
[2025-08-10 15:07:57,321][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026880] [Batch 01036/03692] [00:09:10/00:23:32, 0.532s/it]: train_loss_raw=1.2450, running_loss=1.3937, LR=0.000100
[2025-08-10 15:08:03,384][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026892] [Batch 01048/03692] [00:09:16/00:23:25, 0.531s/it]: train_loss_raw=1.4045, running_loss=1.3894, LR=0.000100
[2025-08-10 15:08:09,520][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026904] [Batch 01060/03692] [00:09:23/00:23:18, 0.531s/it]: train_loss_raw=1.4549, running_loss=1.3914, LR=0.000100
[2025-08-10 15:08:15,707][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026916] [Batch 01072/03692] [00:09:29/00:23:11, 0.531s/it]: train_loss_raw=1.4333, running_loss=1.3920, LR=0.000100
[2025-08-10 15:08:21,867][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026928] [Batch 01084/03692] [00:09:35/00:23:04, 0.531s/it]: train_loss_raw=1.3801, running_loss=1.3940, LR=0.000100
[2025-08-10 15:08:27,989][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026940] [Batch 01096/03692] [00:09:41/00:22:57, 0.531s/it]: train_loss_raw=1.4178, running_loss=1.3985, LR=0.000100
[2025-08-10 15:08:34,085][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026952] [Batch 01108/03692] [00:09:47/00:22:50, 0.530s/it]: train_loss_raw=1.3697, running_loss=1.3974, LR=0.000100
[2025-08-10 15:08:40,144][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026964] [Batch 01120/03692] [00:09:53/00:22:43, 0.530s/it]: train_loss_raw=1.4257, running_loss=1.3961, LR=0.000100
[2025-08-10 15:08:46,281][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026976] [Batch 01132/03692] [00:09:59/00:22:36, 0.530s/it]: train_loss_raw=1.3956, running_loss=1.3949, LR=0.000100
[2025-08-10 15:08:52,750][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 026988] [Batch 01144/03692] [00:10:06/00:22:30, 0.530s/it]: train_loss_raw=1.3157, running_loss=1.3930, LR=0.000100
[2025-08-10 15:08:59,308][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027000] [Batch 01156/03692] [00:10:12/00:22:24, 0.530s/it]: train_loss_raw=1.4066, running_loss=1.3937, LR=0.000100
[2025-08-10 15:09:05,625][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027012] [Batch 01168/03692] [00:10:19/00:22:18, 0.530s/it]: train_loss_raw=1.3583, running_loss=1.3928, LR=0.000100
[2025-08-10 15:09:11,811][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027024] [Batch 01180/03692] [00:10:25/00:22:11, 0.530s/it]: train_loss_raw=1.4338, running_loss=1.3957, LR=0.000100
[2025-08-10 15:09:17,851][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027036] [Batch 01192/03692] [00:10:31/00:22:04, 0.530s/it]: train_loss_raw=1.3509, running_loss=1.4000, LR=0.000100
[2025-08-10 15:09:24,243][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027048] [Batch 01204/03692] [00:10:37/00:21:58, 0.530s/it]: train_loss_raw=1.4588, running_loss=1.4012, LR=0.000100
[2025-08-10 15:09:30,795][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027060] [Batch 01216/03692] [00:10:44/00:21:52, 0.530s/it]: train_loss_raw=1.5339, running_loss=1.4043, LR=0.000100
[2025-08-10 15:09:37,358][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027072] [Batch 01228/03692] [00:10:50/00:21:46, 0.530s/it]: train_loss_raw=1.4384, running_loss=1.4025, LR=0.000100
[2025-08-10 15:09:44,008][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027084] [Batch 01240/03692] [00:10:57/00:21:40, 0.530s/it]: train_loss_raw=1.4713, running_loss=1.4030, LR=0.000100
[2025-08-10 15:09:50,521][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027096] [Batch 01252/03692] [00:11:04/00:21:34, 0.530s/it]: train_loss_raw=1.4599, running_loss=1.4000, LR=0.000100
[2025-08-10 15:09:57,050][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027108] [Batch 01264/03692] [00:11:10/00:21:28, 0.531s/it]: train_loss_raw=1.3981, running_loss=1.4012, LR=0.000100
[2025-08-10 15:10:03,116][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027120] [Batch 01276/03692] [00:11:16/00:21:21, 0.530s/it]: train_loss_raw=1.4835, running_loss=1.4005, LR=0.000100
[2025-08-10 15:10:09,110][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027132] [Batch 01288/03692] [00:11:22/00:21:14, 0.530s/it]: train_loss_raw=1.4368, running_loss=1.4045, LR=0.000100
[2025-08-10 15:10:15,135][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027144] [Batch 01300/03692] [00:11:28/00:21:07, 0.530s/it]: train_loss_raw=1.4243, running_loss=1.3979, LR=0.000100
[2025-08-10 15:10:21,533][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027156] [Batch 01312/03692] [00:11:35/00:21:00, 0.530s/it]: train_loss_raw=1.3794, running_loss=1.3987, LR=0.000100
[2025-08-10 15:10:27,777][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027168] [Batch 01324/03692] [00:11:41/00:20:54, 0.530s/it]: train_loss_raw=1.4074, running_loss=1.3965, LR=0.000100
[2025-08-10 15:10:33,828][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027180] [Batch 01336/03692] [00:11:47/00:20:47, 0.530s/it]: train_loss_raw=1.4060, running_loss=1.3985, LR=0.000100
[2025-08-10 15:10:40,393][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027192] [Batch 01348/03692] [00:11:53/00:20:41, 0.530s/it]: train_loss_raw=1.3972, running_loss=1.3965, LR=0.000100
[2025-08-10 15:10:46,623][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027204] [Batch 01360/03692] [00:12:00/00:20:34, 0.530s/it]: train_loss_raw=1.3158, running_loss=1.3937, LR=0.000100
[2025-08-10 15:10:52,874][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027216] [Batch 01372/03692] [00:12:06/00:20:28, 0.529s/it]: train_loss_raw=1.3185, running_loss=1.3886, LR=0.000100
[2025-08-10 15:10:59,394][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027228] [Batch 01384/03692] [00:12:12/00:20:22, 0.530s/it]: train_loss_raw=1.2643, running_loss=1.3908, LR=0.000100
[2025-08-10 15:11:06,036][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027240] [Batch 01396/03692] [00:12:19/00:20:16, 0.530s/it]: train_loss_raw=1.4163, running_loss=1.3888, LR=0.000100
[2025-08-10 15:11:12,412][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027252] [Batch 01408/03692] [00:12:26/00:20:10, 0.530s/it]: train_loss_raw=1.2419, running_loss=1.3858, LR=0.000100
[2025-08-10 15:11:18,552][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027264] [Batch 01420/03692] [00:12:32/00:20:03, 0.530s/it]: train_loss_raw=1.5079, running_loss=1.3841, LR=0.000100
[2025-08-10 15:11:24,575][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027276] [Batch 01432/03692] [00:12:38/00:19:56, 0.529s/it]: train_loss_raw=1.4656, running_loss=1.3873, LR=0.000100
[2025-08-10 15:11:30,704][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027288] [Batch 01444/03692] [00:12:44/00:19:49, 0.529s/it]: train_loss_raw=1.3692, running_loss=1.3838, LR=0.000100
[2025-08-10 15:11:37,044][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027300] [Batch 01456/03692] [00:12:50/00:19:43, 0.529s/it]: train_loss_raw=1.4223, running_loss=1.3852, LR=0.000100
[2025-08-10 15:11:43,322][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027312] [Batch 01468/03692] [00:12:56/00:19:37, 0.529s/it]: train_loss_raw=1.3615, running_loss=1.3836, LR=0.000100
[2025-08-10 15:11:49,552][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027324] [Batch 01480/03692] [00:13:03/00:19:30, 0.529s/it]: train_loss_raw=1.2426, running_loss=1.3826, LR=0.000100
[2025-08-10 15:11:55,592][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027336] [Batch 01492/03692] [00:13:09/00:19:23, 0.529s/it]: train_loss_raw=1.3792, running_loss=1.3850, LR=0.000100
[2025-08-10 15:12:01,781][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027348] [Batch 01504/03692] [00:13:15/00:19:17, 0.529s/it]: train_loss_raw=1.4089, running_loss=1.3843, LR=0.000100
[2025-08-10 15:12:08,032][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027360] [Batch 01516/03692] [00:13:21/00:19:10, 0.529s/it]: train_loss_raw=1.4240, running_loss=1.3844, LR=0.000100
[2025-08-10 15:12:14,487][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027372] [Batch 01528/03692] [00:13:28/00:19:04, 0.529s/it]: train_loss_raw=1.3659, running_loss=1.3863, LR=0.000100
[2025-08-10 15:12:21,068][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027384] [Batch 01540/03692] [00:13:34/00:18:58, 0.529s/it]: train_loss_raw=1.4071, running_loss=1.3860, LR=0.000100
[2025-08-10 15:12:27,674][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027396] [Batch 01552/03692] [00:13:41/00:18:52, 0.529s/it]: train_loss_raw=1.3731, running_loss=1.3816, LR=0.000100
[2025-08-10 15:12:34,018][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027408] [Batch 01564/03692] [00:13:47/00:18:46, 0.529s/it]: train_loss_raw=1.3333, running_loss=1.3826, LR=0.000100
[2025-08-10 15:12:40,060][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027420] [Batch 01576/03692] [00:13:53/00:18:39, 0.529s/it]: train_loss_raw=1.4023, running_loss=1.3825, LR=0.000100
[2025-08-10 15:12:46,420][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027432] [Batch 01588/03692] [00:14:00/00:18:32, 0.529s/it]: train_loss_raw=1.3383, running_loss=1.3796, LR=0.000100
[2025-08-10 15:12:52,921][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027444] [Batch 01600/03692] [00:14:06/00:18:26, 0.529s/it]: train_loss_raw=1.3360, running_loss=1.3781, LR=0.000100
[2025-08-10 15:12:59,526][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027456] [Batch 01612/03692] [00:14:13/00:18:20, 0.529s/it]: train_loss_raw=1.4486, running_loss=1.3806, LR=0.000100
[2025-08-10 15:13:06,184][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027468] [Batch 01624/03692] [00:14:19/00:18:14, 0.529s/it]: train_loss_raw=1.2911, running_loss=1.3789, LR=0.000100
[2025-08-10 15:13:12,225][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027480] [Batch 01636/03692] [00:14:25/00:18:08, 0.529s/it]: train_loss_raw=1.4572, running_loss=1.3775, LR=0.000100
[2025-08-10 15:13:18,286][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027492] [Batch 01648/03692] [00:14:31/00:18:01, 0.529s/it]: train_loss_raw=1.4745, running_loss=1.3760, LR=0.000100
[2025-08-10 15:13:24,363][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027504] [Batch 01660/03692] [00:14:37/00:17:54, 0.529s/it]: train_loss_raw=1.5616, running_loss=1.3793, LR=0.000100
[2025-08-10 15:13:30,402][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027516] [Batch 01672/03692] [00:14:43/00:17:47, 0.529s/it]: train_loss_raw=1.4174, running_loss=1.3803, LR=0.000100
[2025-08-10 15:13:36,460][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027528] [Batch 01684/03692] [00:14:50/00:17:41, 0.529s/it]: train_loss_raw=1.3719, running_loss=1.3817, LR=0.000100
[2025-08-10 15:13:42,485][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027540] [Batch 01696/03692] [00:14:56/00:17:34, 0.528s/it]: train_loss_raw=1.4558, running_loss=1.3752, LR=0.000100
[2025-08-10 15:13:48,973][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027552] [Batch 01708/03692] [00:15:02/00:17:28, 0.528s/it]: train_loss_raw=1.4507, running_loss=1.3754, LR=0.000100
[2025-08-10 15:13:55,485][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027564] [Batch 01720/03692] [00:15:09/00:17:22, 0.529s/it]: train_loss_raw=1.3824, running_loss=1.3777, LR=0.000100
[2025-08-10 15:14:01,553][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027576] [Batch 01732/03692] [00:15:15/00:17:15, 0.528s/it]: train_loss_raw=1.3523, running_loss=1.3761, LR=0.000100
[2025-08-10 15:14:07,612][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027588] [Batch 01744/03692] [00:15:21/00:17:08, 0.528s/it]: train_loss_raw=1.3784, running_loss=1.3792, LR=0.000100
[2025-08-10 15:14:13,740][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027600] [Batch 01756/03692] [00:15:27/00:17:02, 0.528s/it]: train_loss_raw=1.3084, running_loss=1.3819, LR=0.000100
[2025-08-10 15:14:19,742][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027612] [Batch 01768/03692] [00:15:33/00:16:55, 0.528s/it]: train_loss_raw=1.3942, running_loss=1.3811, LR=0.000100
[2025-08-10 15:14:25,843][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027624] [Batch 01780/03692] [00:15:39/00:16:49, 0.528s/it]: train_loss_raw=1.2705, running_loss=1.3763, LR=0.000100
[2025-08-10 15:14:31,974][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027636] [Batch 01792/03692] [00:15:45/00:16:42, 0.528s/it]: train_loss_raw=1.4611, running_loss=1.3785, LR=0.000100
[2025-08-10 15:14:38,081][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027648] [Batch 01804/03692] [00:15:51/00:16:35, 0.528s/it]: train_loss_raw=1.4956, running_loss=1.3820, LR=0.000100
[2025-08-10 15:14:44,103][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027660] [Batch 01816/03692] [00:15:57/00:16:29, 0.527s/it]: train_loss_raw=1.3555, running_loss=1.3831, LR=0.000100
[2025-08-10 15:14:50,291][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027672] [Batch 01828/03692] [00:16:03/00:16:22, 0.527s/it]: train_loss_raw=1.3513, running_loss=1.3832, LR=0.000100
[2025-08-10 15:14:56,341][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027684] [Batch 01840/03692] [00:16:09/00:16:16, 0.527s/it]: train_loss_raw=1.4456, running_loss=1.3818, LR=0.000100
[2025-08-10 15:15:02,740][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027696] [Batch 01852/03692] [00:16:16/00:16:10, 0.527s/it]: train_loss_raw=1.5234, running_loss=1.3828, LR=0.000100
[2025-08-10 15:15:09,263][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027708] [Batch 01864/03692] [00:16:22/00:16:03, 0.527s/it]: train_loss_raw=1.2452, running_loss=1.3823, LR=0.000100
[2025-08-10 15:15:15,792][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027720] [Batch 01876/03692] [00:16:29/00:15:57, 0.527s/it]: train_loss_raw=1.4206, running_loss=1.3793, LR=0.000100
[2025-08-10 15:15:21,792][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027732] [Batch 01888/03692] [00:16:35/00:15:51, 0.527s/it]: train_loss_raw=1.2799, running_loss=1.3816, LR=0.000100
[2025-08-10 15:15:27,803][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027744] [Batch 01900/03692] [00:16:41/00:15:44, 0.527s/it]: train_loss_raw=1.2635, running_loss=1.3820, LR=0.000100
[2025-08-10 15:15:34,094][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027756] [Batch 01912/03692] [00:16:47/00:15:38, 0.527s/it]: train_loss_raw=1.2472, running_loss=1.3815, LR=0.000100
[2025-08-10 15:15:40,174][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027768] [Batch 01924/03692] [00:16:53/00:15:31, 0.527s/it]: train_loss_raw=1.3203, running_loss=1.3786, LR=0.000100
[2025-08-10 15:15:46,268][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027780] [Batch 01936/03692] [00:16:59/00:15:25, 0.527s/it]: train_loss_raw=1.3298, running_loss=1.3774, LR=0.000100
[2025-08-10 15:15:52,368][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027792] [Batch 01948/03692] [00:17:05/00:15:18, 0.527s/it]: train_loss_raw=1.4365, running_loss=1.3807, LR=0.000100
[2025-08-10 15:15:58,550][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027804] [Batch 01960/03692] [00:17:12/00:15:12, 0.527s/it]: train_loss_raw=1.2992, running_loss=1.3791, LR=0.000100
[2025-08-10 15:16:04,716][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027816] [Batch 01972/03692] [00:17:18/00:15:05, 0.527s/it]: train_loss_raw=1.3858, running_loss=1.3751, LR=0.000100
[2025-08-10 15:16:11,271][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027828] [Batch 01984/03692] [00:17:24/00:14:59, 0.527s/it]: train_loss_raw=1.3228, running_loss=1.3749, LR=0.000100
[2025-08-10 15:16:17,793][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027840] [Batch 01996/03692] [00:17:31/00:14:53, 0.527s/it]: train_loss_raw=1.4031, running_loss=1.3758, LR=0.000100
[2025-08-10 15:16:24,401][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027852] [Batch 02008/03692] [00:17:37/00:14:47, 0.527s/it]: train_loss_raw=1.3362, running_loss=1.3749, LR=0.000100
[2025-08-10 15:16:30,906][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027864] [Batch 02020/03692] [00:17:44/00:14:41, 0.527s/it]: train_loss_raw=1.3905, running_loss=1.3739, LR=0.000100
[2025-08-10 15:16:37,170][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027876] [Batch 02032/03692] [00:17:50/00:14:34, 0.527s/it]: train_loss_raw=1.3547, running_loss=1.3738, LR=0.000100
[2025-08-10 15:16:43,780][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027888] [Batch 02044/03692] [00:17:57/00:14:28, 0.527s/it]: train_loss_raw=1.5204, running_loss=1.3737, LR=0.000100
[2025-08-10 15:16:49,938][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027900] [Batch 02056/03692] [00:18:03/00:14:22, 0.527s/it]: train_loss_raw=1.1259, running_loss=1.3684, LR=0.000100
[2025-08-10 15:16:55,951][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027912] [Batch 02068/03692] [00:18:09/00:14:15, 0.527s/it]: train_loss_raw=1.4837, running_loss=1.3694, LR=0.000100
[2025-08-10 15:17:02,062][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027924] [Batch 02080/03692] [00:18:15/00:14:09, 0.527s/it]: train_loss_raw=1.4143, running_loss=1.3674, LR=0.000100
[2025-08-10 15:17:08,156][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027936] [Batch 02092/03692] [00:18:21/00:14:02, 0.527s/it]: train_loss_raw=1.3245, running_loss=1.3667, LR=0.000100
[2025-08-10 15:17:14,175][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027948] [Batch 02104/03692] [00:18:27/00:13:56, 0.527s/it]: train_loss_raw=1.3611, running_loss=1.3703, LR=0.000100
[2025-08-10 15:17:20,251][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027960] [Batch 02116/03692] [00:18:33/00:13:49, 0.526s/it]: train_loss_raw=1.3323, running_loss=1.3690, LR=0.000100
[2025-08-10 15:17:26,520][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027972] [Batch 02128/03692] [00:18:40/00:13:43, 0.526s/it]: train_loss_raw=1.4122, running_loss=1.3640, LR=0.000100
[2025-08-10 15:17:32,704][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027984] [Batch 02140/03692] [00:18:46/00:13:36, 0.526s/it]: train_loss_raw=1.3216, running_loss=1.3594, LR=0.000100
[2025-08-10 15:17:38,760][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 027996] [Batch 02152/03692] [00:18:52/00:13:30, 0.526s/it]: train_loss_raw=1.3265, running_loss=1.3660, LR=0.000100
[2025-08-10 15:17:57,123][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028008] [Batch 02164/03692] [00:19:10/00:13:32, 0.532s/it]: train_loss_raw=1.3285, running_loss=1.3675, LR=0.000100
[2025-08-10 15:18:03,377][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028020] [Batch 02176/03692] [00:19:16/00:13:26, 0.532s/it]: train_loss_raw=1.4512, running_loss=1.3757, LR=0.000100
[2025-08-10 15:18:10,026][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028032] [Batch 02188/03692] [00:19:23/00:13:19, 0.532s/it]: train_loss_raw=1.3836, running_loss=1.3767, LR=0.000100
[2025-08-10 15:18:16,555][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028044] [Batch 02200/03692] [00:19:30/00:13:13, 0.532s/it]: train_loss_raw=1.4858, running_loss=1.3774, LR=0.000100
[2025-08-10 15:18:23,128][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028056] [Batch 02212/03692] [00:19:36/00:13:07, 0.532s/it]: train_loss_raw=1.3787, running_loss=1.3729, LR=0.000100
[2025-08-10 15:18:29,692][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028068] [Batch 02224/03692] [00:19:43/00:13:01, 0.532s/it]: train_loss_raw=1.4458, running_loss=1.3761, LR=0.000100
[2025-08-10 15:18:36,258][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028080] [Batch 02236/03692] [00:19:49/00:12:54, 0.532s/it]: train_loss_raw=1.4542, running_loss=1.3791, LR=0.000100
[2025-08-10 15:18:42,762][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028092] [Batch 02248/03692] [00:19:56/00:12:48, 0.532s/it]: train_loss_raw=1.3177, running_loss=1.3778, LR=0.000100
[2025-08-10 15:18:49,417][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028104] [Batch 02260/03692] [00:20:03/00:12:42, 0.532s/it]: train_loss_raw=1.3214, running_loss=1.3749, LR=0.000100
[2025-08-10 15:18:55,884][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028116] [Batch 02272/03692] [00:20:09/00:12:35, 0.532s/it]: train_loss_raw=1.2846, running_loss=1.3742, LR=0.000100
[2025-08-10 15:19:02,086][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028128] [Batch 02284/03692] [00:20:15/00:12:29, 0.532s/it]: train_loss_raw=1.3645, running_loss=1.3754, LR=0.000100
[2025-08-10 15:19:08,261][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028140] [Batch 02296/03692] [00:20:21/00:12:22, 0.532s/it]: train_loss_raw=1.3546, running_loss=1.3742, LR=0.000100
[2025-08-10 15:19:14,593][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028152] [Batch 02308/03692] [00:20:28/00:12:16, 0.532s/it]: train_loss_raw=1.3932, running_loss=1.3744, LR=0.000100
[2025-08-10 15:19:21,206][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028164] [Batch 02320/03692] [00:20:34/00:12:10, 0.532s/it]: train_loss_raw=1.2915, running_loss=1.3716, LR=0.000100
[2025-08-10 15:19:27,473][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028176] [Batch 02332/03692] [00:20:41/00:12:03, 0.532s/it]: train_loss_raw=1.2915, running_loss=1.3650, LR=0.000100
[2025-08-10 15:19:33,717][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028188] [Batch 02344/03692] [00:20:47/00:11:57, 0.532s/it]: train_loss_raw=1.3440, running_loss=1.3620, LR=0.000100
[2025-08-10 15:19:40,250][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028200] [Batch 02356/03692] [00:20:53/00:11:51, 0.532s/it]: train_loss_raw=1.4345, running_loss=1.3627, LR=0.000100
[2025-08-10 15:19:46,650][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028212] [Batch 02368/03692] [00:21:00/00:11:44, 0.532s/it]: train_loss_raw=1.4439, running_loss=1.3615, LR=0.000100
[2025-08-10 15:19:52,746][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028224] [Batch 02380/03692] [00:21:06/00:11:38, 0.532s/it]: train_loss_raw=1.1880, running_loss=1.3623, LR=0.000100
[2025-08-10 15:19:58,933][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028236] [Batch 02392/03692] [00:21:12/00:11:31, 0.532s/it]: train_loss_raw=1.3213, running_loss=1.3650, LR=0.000100
[2025-08-10 15:20:05,157][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028248] [Batch 02404/03692] [00:21:18/00:11:25, 0.532s/it]: train_loss_raw=1.4257, running_loss=1.3630, LR=0.000100
[2025-08-10 15:20:11,502][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028260] [Batch 02416/03692] [00:21:25/00:11:18, 0.532s/it]: train_loss_raw=1.2877, running_loss=1.3553, LR=0.000100
[2025-08-10 15:20:17,683][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028272] [Batch 02428/03692] [00:21:31/00:11:12, 0.532s/it]: train_loss_raw=1.4287, running_loss=1.3554, LR=0.000100
[2025-08-10 15:20:24,090][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028284] [Batch 02440/03692] [00:21:37/00:11:05, 0.532s/it]: train_loss_raw=1.2695, running_loss=1.3546, LR=0.000100
[2025-08-10 15:20:30,575][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028296] [Batch 02452/03692] [00:21:44/00:10:59, 0.532s/it]: train_loss_raw=1.3735, running_loss=1.3569, LR=0.000100
[2025-08-10 15:20:37,117][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028308] [Batch 02464/03692] [00:21:50/00:10:53, 0.532s/it]: train_loss_raw=1.4679, running_loss=1.3564, LR=0.000100
[2025-08-10 15:20:43,733][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028320] [Batch 02476/03692] [00:21:57/00:10:46, 0.532s/it]: train_loss_raw=1.3701, running_loss=1.3550, LR=0.000100
[2025-08-10 15:20:49,946][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028332] [Batch 02488/03692] [00:22:03/00:10:40, 0.532s/it]: train_loss_raw=1.5027, running_loss=1.3571, LR=0.000100
[2025-08-10 15:20:56,166][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028344] [Batch 02500/03692] [00:22:09/00:10:34, 0.532s/it]: train_loss_raw=1.2931, running_loss=1.3598, LR=0.000100
[2025-08-10 15:21:02,450][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028356] [Batch 02512/03692] [00:22:16/00:10:27, 0.532s/it]: train_loss_raw=1.4309, running_loss=1.3562, LR=0.000100
[2025-08-10 15:21:08,703][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028368] [Batch 02524/03692] [00:22:22/00:10:21, 0.532s/it]: train_loss_raw=1.3892, running_loss=1.3593, LR=0.000100
[2025-08-10 15:21:14,781][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028380] [Batch 02536/03692] [00:22:28/00:10:14, 0.532s/it]: train_loss_raw=1.4483, running_loss=1.3599, LR=0.000100
[2025-08-10 15:21:21,200][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028392] [Batch 02548/03692] [00:22:34/00:10:08, 0.532s/it]: train_loss_raw=1.3264, running_loss=1.3592, LR=0.000100
[2025-08-10 15:21:27,830][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028404] [Batch 02560/03692] [00:22:41/00:10:02, 0.532s/it]: train_loss_raw=1.2731, running_loss=1.3594, LR=0.000100
[2025-08-10 15:21:34,442][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028416] [Batch 02572/03692] [00:22:48/00:09:55, 0.532s/it]: train_loss_raw=1.4793, running_loss=1.3599, LR=0.000100
[2025-08-10 15:21:41,038][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028428] [Batch 02584/03692] [00:22:54/00:09:49, 0.532s/it]: train_loss_raw=1.4201, running_loss=1.3587, LR=0.000100
[2025-08-10 15:21:47,213][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028440] [Batch 02596/03692] [00:23:00/00:09:42, 0.532s/it]: train_loss_raw=1.3026, running_loss=1.3598, LR=0.000100
[2025-08-10 15:21:53,270][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028452] [Batch 02608/03692] [00:23:06/00:09:36, 0.532s/it]: train_loss_raw=1.3643, running_loss=1.3607, LR=0.000100
[2025-08-10 15:21:59,391][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028464] [Batch 02620/03692] [00:23:12/00:09:29, 0.532s/it]: train_loss_raw=1.3975, running_loss=1.3605, LR=0.000100
[2025-08-10 15:22:05,449][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028476] [Batch 02632/03692] [00:23:19/00:09:23, 0.532s/it]: train_loss_raw=1.3882, running_loss=1.3650, LR=0.000100
[2025-08-10 15:22:11,557][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028488] [Batch 02644/03692] [00:23:25/00:09:16, 0.531s/it]: train_loss_raw=1.4361, running_loss=1.3636, LR=0.000100
[2025-08-10 15:22:17,919][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028500] [Batch 02656/03692] [00:23:31/00:09:10, 0.531s/it]: train_loss_raw=1.1486, running_loss=1.3610, LR=0.000100
[2025-08-10 15:22:24,179][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028512] [Batch 02668/03692] [00:23:37/00:09:04, 0.531s/it]: train_loss_raw=1.2746, running_loss=1.3587, LR=0.000100
[2025-08-10 15:22:30,393][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028524] [Batch 02680/03692] [00:23:43/00:08:57, 0.531s/it]: train_loss_raw=1.3781, running_loss=1.3611, LR=0.000100
[2025-08-10 15:22:36,985][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028536] [Batch 02692/03692] [00:23:50/00:08:51, 0.531s/it]: train_loss_raw=1.4359, running_loss=1.3622, LR=0.000100
[2025-08-10 15:22:43,610][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028548] [Batch 02704/03692] [00:23:57/00:08:45, 0.532s/it]: train_loss_raw=1.1121, running_loss=1.3575, LR=0.000100
[2025-08-10 15:22:50,258][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028560] [Batch 02716/03692] [00:24:03/00:08:38, 0.532s/it]: train_loss_raw=1.1416, running_loss=1.3515, LR=0.000100
[2025-08-10 15:22:56,678][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028572] [Batch 02728/03692] [00:24:10/00:08:32, 0.532s/it]: train_loss_raw=1.4780, running_loss=1.3556, LR=0.000100
[2025-08-10 15:23:02,787][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028584] [Batch 02740/03692] [00:24:16/00:08:26, 0.532s/it]: train_loss_raw=1.5136, running_loss=1.3553, LR=0.000100
[2025-08-10 15:23:08,979][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028596] [Batch 02752/03692] [00:24:22/00:08:19, 0.531s/it]: train_loss_raw=1.4208, running_loss=1.3578, LR=0.000100
[2025-08-10 15:23:15,200][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028608] [Batch 02764/03692] [00:24:28/00:08:13, 0.531s/it]: train_loss_raw=1.5063, running_loss=1.3615, LR=0.000100
[2025-08-10 15:23:21,290][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028620] [Batch 02776/03692] [00:24:34/00:08:06, 0.531s/it]: train_loss_raw=1.3204, running_loss=1.3597, LR=0.000100
[2025-08-10 15:23:27,385][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028632] [Batch 02788/03692] [00:24:40/00:08:00, 0.531s/it]: train_loss_raw=1.4510, running_loss=1.3595, LR=0.000100
[2025-08-10 15:23:33,611][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028644] [Batch 02800/03692] [00:24:47/00:07:53, 0.531s/it]: train_loss_raw=1.4077, running_loss=1.3632, LR=0.000100
[2025-08-10 15:23:39,817][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028656] [Batch 02812/03692] [00:24:53/00:07:47, 0.531s/it]: train_loss_raw=1.3218, running_loss=1.3627, LR=0.000100
[2025-08-10 15:23:46,055][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028668] [Batch 02824/03692] [00:24:59/00:07:40, 0.531s/it]: train_loss_raw=1.3554, running_loss=1.3629, LR=0.000100
[2025-08-10 15:23:52,098][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028680] [Batch 02836/03692] [00:25:05/00:07:34, 0.531s/it]: train_loss_raw=1.4079, running_loss=1.3605, LR=0.000100
[2025-08-10 15:23:58,148][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028692] [Batch 02848/03692] [00:25:11/00:07:28, 0.531s/it]: train_loss_raw=1.3829, running_loss=1.3584, LR=0.000100
[2025-08-10 15:24:04,295][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028704] [Batch 02860/03692] [00:25:17/00:07:21, 0.531s/it]: train_loss_raw=1.3457, running_loss=1.3594, LR=0.000100
[2025-08-10 15:24:10,355][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028716] [Batch 02872/03692] [00:25:23/00:07:15, 0.531s/it]: train_loss_raw=1.3973, running_loss=1.3574, LR=0.000100
[2025-08-10 15:24:16,484][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028728] [Batch 02884/03692] [00:25:30/00:07:08, 0.531s/it]: train_loss_raw=1.4295, running_loss=1.3578, LR=0.000100
[2025-08-10 15:24:22,613][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028740] [Batch 02896/03692] [00:25:36/00:07:02, 0.530s/it]: train_loss_raw=1.1758, running_loss=1.3565, LR=0.000100
[2025-08-10 15:24:28,840][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028752] [Batch 02908/03692] [00:25:42/00:06:55, 0.530s/it]: train_loss_raw=1.2949, running_loss=1.3500, LR=0.000100
[2025-08-10 15:24:34,958][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028764] [Batch 02920/03692] [00:25:48/00:06:49, 0.530s/it]: train_loss_raw=1.2436, running_loss=1.3491, LR=0.000100
[2025-08-10 15:24:41,112][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028776] [Batch 02932/03692] [00:25:54/00:06:42, 0.530s/it]: train_loss_raw=1.3570, running_loss=1.3476, LR=0.000100
[2025-08-10 15:24:47,379][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028788] [Batch 02944/03692] [00:26:00/00:06:36, 0.530s/it]: train_loss_raw=1.2788, running_loss=1.3480, LR=0.000100
[2025-08-10 15:24:53,600][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028800] [Batch 02956/03692] [00:26:07/00:06:30, 0.530s/it]: train_loss_raw=1.4269, running_loss=1.3505, LR=0.000100
[2025-08-10 15:24:59,780][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028812] [Batch 02968/03692] [00:26:13/00:06:23, 0.530s/it]: train_loss_raw=1.4703, running_loss=1.3465, LR=0.000100
[2025-08-10 15:25:06,032][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028824] [Batch 02980/03692] [00:26:19/00:06:17, 0.530s/it]: train_loss_raw=1.3779, running_loss=1.3437, LR=0.000100
[2025-08-10 15:25:12,283][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028836] [Batch 02992/03692] [00:26:25/00:06:11, 0.530s/it]: train_loss_raw=1.3408, running_loss=1.3431, LR=0.000100
[2025-08-10 15:25:18,638][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028848] [Batch 03004/03692] [00:26:32/00:06:04, 0.530s/it]: train_loss_raw=1.2982, running_loss=1.3413, LR=0.000100
[2025-08-10 15:25:24,880][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028860] [Batch 03016/03692] [00:26:38/00:05:58, 0.530s/it]: train_loss_raw=1.3079, running_loss=1.3403, LR=0.000100
[2025-08-10 15:25:31,136][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028872] [Batch 03028/03692] [00:26:44/00:05:51, 0.530s/it]: train_loss_raw=1.3050, running_loss=1.3421, LR=0.000100
[2025-08-10 15:25:37,376][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028884] [Batch 03040/03692] [00:26:50/00:05:45, 0.530s/it]: train_loss_raw=1.3563, running_loss=1.3449, LR=0.000100
[2025-08-10 15:25:43,540][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028896] [Batch 03052/03692] [00:26:57/00:05:39, 0.530s/it]: train_loss_raw=1.2944, running_loss=1.3454, LR=0.000100
[2025-08-10 15:25:49,611][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028908] [Batch 03064/03692] [00:27:03/00:05:32, 0.530s/it]: train_loss_raw=1.4238, running_loss=1.3478, LR=0.000100
[2025-08-10 15:25:55,915][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028920] [Batch 03076/03692] [00:27:09/00:05:26, 0.530s/it]: train_loss_raw=1.4116, running_loss=1.3503, LR=0.000100
[2025-08-10 15:26:02,252][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028932] [Batch 03088/03692] [00:27:15/00:05:19, 0.530s/it]: train_loss_raw=1.4241, running_loss=1.3490, LR=0.000100
[2025-08-10 15:26:08,500][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028944] [Batch 03100/03692] [00:27:22/00:05:13, 0.530s/it]: train_loss_raw=1.3688, running_loss=1.3516, LR=0.000100
[2025-08-10 15:26:14,796][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028956] [Batch 03112/03692] [00:27:28/00:05:07, 0.530s/it]: train_loss_raw=1.3208, running_loss=1.3487, LR=0.000100
[2025-08-10 15:26:21,023][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028968] [Batch 03124/03692] [00:27:34/00:05:00, 0.530s/it]: train_loss_raw=1.3313, running_loss=1.3541, LR=0.000100
[2025-08-10 15:26:27,460][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028980] [Batch 03136/03692] [00:27:41/00:04:54, 0.530s/it]: train_loss_raw=1.3264, running_loss=1.3499, LR=0.000100
[2025-08-10 15:26:34,110][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 028992] [Batch 03148/03692] [00:27:47/00:04:48, 0.530s/it]: train_loss_raw=1.3266, running_loss=1.3486, LR=0.000100
[2025-08-10 15:26:40,649][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029004] [Batch 03160/03692] [00:27:54/00:04:41, 0.530s/it]: train_loss_raw=1.2623, running_loss=1.3457, LR=0.000100
[2025-08-10 15:26:47,268][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029016] [Batch 03172/03692] [00:28:00/00:04:35, 0.530s/it]: train_loss_raw=1.2244, running_loss=1.3441, LR=0.000100
[2025-08-10 15:26:53,955][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029028] [Batch 03184/03692] [00:28:07/00:04:29, 0.530s/it]: train_loss_raw=1.3036, running_loss=1.3397, LR=0.000100
[2025-08-10 15:27:00,447][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029040] [Batch 03196/03692] [00:28:14/00:04:22, 0.530s/it]: train_loss_raw=1.2640, running_loss=1.3406, LR=0.000100
[2025-08-10 15:27:06,778][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029052] [Batch 03208/03692] [00:28:20/00:04:16, 0.530s/it]: train_loss_raw=1.4089, running_loss=1.3433, LR=0.000100
[2025-08-10 15:27:12,993][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029064] [Batch 03220/03692] [00:28:26/00:04:10, 0.530s/it]: train_loss_raw=1.5566, running_loss=1.3462, LR=0.000100
[2025-08-10 15:27:19,423][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029076] [Batch 03232/03692] [00:28:33/00:04:03, 0.530s/it]: train_loss_raw=1.2779, running_loss=1.3478, LR=0.000100
[2025-08-10 15:27:25,656][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029088] [Batch 03244/03692] [00:28:39/00:03:57, 0.530s/it]: train_loss_raw=1.3325, running_loss=1.3479, LR=0.000100
[2025-08-10 15:27:31,956][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029100] [Batch 03256/03692] [00:28:45/00:03:51, 0.530s/it]: train_loss_raw=1.3444, running_loss=1.3497, LR=0.000100
[2025-08-10 15:27:38,003][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029112] [Batch 03268/03692] [00:28:51/00:03:44, 0.530s/it]: train_loss_raw=1.3760, running_loss=1.3491, LR=0.000100
[2025-08-10 15:27:44,070][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029124] [Batch 03280/03692] [00:28:57/00:03:38, 0.530s/it]: train_loss_raw=1.4878, running_loss=1.3519, LR=0.000100
[2025-08-10 15:27:50,167][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029136] [Batch 03292/03692] [00:29:03/00:03:31, 0.530s/it]: train_loss_raw=1.5248, running_loss=1.3565, LR=0.000100
[2025-08-10 15:27:56,497][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029148] [Batch 03304/03692] [00:29:10/00:03:25, 0.530s/it]: train_loss_raw=1.4039, running_loss=1.3596, LR=0.000100
[2025-08-10 15:28:03,144][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029160] [Batch 03316/03692] [00:29:16/00:03:19, 0.530s/it]: train_loss_raw=1.3760, running_loss=1.3566, LR=0.000100
[2025-08-10 15:28:09,758][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029172] [Batch 03328/03692] [00:29:23/00:03:12, 0.530s/it]: train_loss_raw=1.4965, running_loss=1.3597, LR=0.000100
[2025-08-10 15:28:16,244][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029184] [Batch 03340/03692] [00:29:29/00:03:06, 0.530s/it]: train_loss_raw=1.3768, running_loss=1.3520, LR=0.000100
[2025-08-10 15:28:22,737][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029196] [Batch 03352/03692] [00:29:36/00:03:00, 0.530s/it]: train_loss_raw=1.3268, running_loss=1.3526, LR=0.000100
[2025-08-10 15:28:29,271][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029208] [Batch 03364/03692] [00:29:42/00:02:53, 0.530s/it]: train_loss_raw=1.4035, running_loss=1.3561, LR=0.000100
[2025-08-10 15:28:35,842][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029220] [Batch 03376/03692] [00:29:49/00:02:47, 0.530s/it]: train_loss_raw=1.2537, running_loss=1.3510, LR=0.000100
[2025-08-10 15:28:42,404][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029232] [Batch 03388/03692] [00:29:55/00:02:41, 0.530s/it]: train_loss_raw=1.3606, running_loss=1.3472, LR=0.000100
[2025-08-10 15:28:49,035][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029244] [Batch 03400/03692] [00:30:02/00:02:34, 0.530s/it]: train_loss_raw=1.3912, running_loss=1.3477, LR=0.000100
[2025-08-10 15:28:55,242][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029256] [Batch 03412/03692] [00:30:08/00:02:28, 0.530s/it]: train_loss_raw=1.3736, running_loss=1.3454, LR=0.000100
[2025-08-10 15:29:01,293][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029268] [Batch 03424/03692] [00:30:14/00:02:22, 0.530s/it]: train_loss_raw=1.4870, running_loss=1.3457, LR=0.000100
[2025-08-10 15:29:07,802][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029280] [Batch 03436/03692] [00:30:21/00:02:15, 0.530s/it]: train_loss_raw=1.4245, running_loss=1.3518, LR=0.000100
[2025-08-10 15:29:14,375][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029292] [Batch 03448/03692] [00:30:27/00:02:09, 0.530s/it]: train_loss_raw=1.4134, running_loss=1.3518, LR=0.000100
[2025-08-10 15:29:20,699][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029304] [Batch 03460/03692] [00:30:34/00:02:02, 0.530s/it]: train_loss_raw=1.4027, running_loss=1.3523, LR=0.000100
[2025-08-10 15:29:26,955][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029316] [Batch 03472/03692] [00:30:40/00:01:56, 0.530s/it]: train_loss_raw=1.3302, running_loss=1.3533, LR=0.000100
[2025-08-10 15:29:33,415][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029328] [Batch 03484/03692] [00:30:47/00:01:50, 0.530s/it]: train_loss_raw=1.3687, running_loss=1.3548, LR=0.000100
[2025-08-10 15:29:39,540][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029340] [Batch 03496/03692] [00:30:53/00:01:43, 0.530s/it]: train_loss_raw=1.4034, running_loss=1.3498, LR=0.000100
[2025-08-10 15:29:45,571][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029352] [Batch 03508/03692] [00:30:59/00:01:37, 0.530s/it]: train_loss_raw=1.4480, running_loss=1.3499, LR=0.000100
[2025-08-10 15:29:51,772][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029364] [Batch 03520/03692] [00:31:05/00:01:31, 0.530s/it]: train_loss_raw=1.3267, running_loss=1.3468, LR=0.000100
[2025-08-10 15:29:58,311][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029376] [Batch 03532/03692] [00:31:11/00:01:24, 0.530s/it]: train_loss_raw=1.3637, running_loss=1.3483, LR=0.000100
[2025-08-10 15:30:04,642][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029388] [Batch 03544/03692] [00:31:18/00:01:18, 0.530s/it]: train_loss_raw=1.3953, running_loss=1.3472, LR=0.000100
[2025-08-10 15:30:11,235][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029400] [Batch 03556/03692] [00:31:24/00:01:12, 0.530s/it]: train_loss_raw=1.1640, running_loss=1.3487, LR=0.000100
[2025-08-10 15:30:17,828][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029412] [Batch 03568/03692] [00:31:31/00:01:05, 0.530s/it]: train_loss_raw=1.3424, running_loss=1.3502, LR=0.000100
[2025-08-10 15:30:24,391][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029424] [Batch 03580/03692] [00:31:37/00:00:59, 0.530s/it]: train_loss_raw=1.3626, running_loss=1.3498, LR=0.000100
[2025-08-10 15:30:30,881][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029436] [Batch 03592/03692] [00:31:44/00:00:53, 0.530s/it]: train_loss_raw=1.3912, running_loss=1.3540, LR=0.000100
[2025-08-10 15:30:37,425][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029448] [Batch 03604/03692] [00:31:51/00:00:46, 0.530s/it]: train_loss_raw=1.2423, running_loss=1.3539, LR=0.000100
[2025-08-10 15:30:43,709][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029460] [Batch 03616/03692] [00:31:57/00:00:40, 0.530s/it]: train_loss_raw=1.2709, running_loss=1.3496, LR=0.000100
[2025-08-10 15:30:49,973][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029472] [Batch 03628/03692] [00:32:03/00:00:33, 0.530s/it]: train_loss_raw=1.2709, running_loss=1.3504, LR=0.000100
[2025-08-10 15:30:56,408][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029484] [Batch 03640/03692] [00:32:10/00:00:27, 0.530s/it]: train_loss_raw=1.2715, running_loss=1.3461, LR=0.000100
[2025-08-10 15:31:02,865][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029496] [Batch 03652/03692] [00:32:16/00:00:21, 0.530s/it]: train_loss_raw=1.3606, running_loss=1.3476, LR=0.000100
[2025-08-10 15:31:09,423][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029508] [Batch 03664/03692] [00:32:23/00:00:14, 0.530s/it]: train_loss_raw=1.3549, running_loss=1.3473, LR=0.000100
[2025-08-10 15:31:16,103][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029520] [Batch 03676/03692] [00:32:29/00:00:08, 0.530s/it]: train_loss_raw=1.3571, running_loss=1.3447, LR=0.000100
[2025-08-10 15:31:22,627][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 029532] [Batch 03688/03692] [00:32:36/00:00:02, 0.530s/it]: train_loss_raw=1.5186, running_loss=1.3456, LR=0.000100
[2025-08-10 15:31:58,480][__main__][INFO] - [VALIDATION] [Epoch 07/29] Starting validation.
[2025-08-10 15:32:33,827][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 029537] [Batch 00011/00025] [00:00:35/00:00:38, 2.945s/it]
[2025-08-10 15:32:51,862][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 029537] [Batch 00023/00025] [00:00:53/00:00:02, 2.224s/it]
[2025-08-10 15:32:53,135][__main__][INFO] - [VALIDATION] [Epoch 07/29] train_loss=1.34484, valid_loss=1.23675
[2025-08-10 15:32:53,135][__main__][INFO] - [VALIDATION] [Epoch 07/29] Metrics:
[2025-08-10 15:32:53,135][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_er      0.556
[2025-08-10 15:32:53,135][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_prec    0.171
[2025-08-10 15:32:53,135][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_recall  0.178
[2025-08-10 15:32:53,136][__main__][INFO] - [VALIDATION] [Epoch 07/29] - pep_recall 0.128
[2025-08-10 15:32:53,139][__main__][INFO] - [TRAIN] [Epoch 07/29] Epoch complete, total time 04:36:52, remaining time 12:41:23, 00:34:36 per epoch
[2025-08-10 15:32:59,771][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029544] [Batch 00008/03692] [00:00:03/00:30:20, 0.494s/it]: train_loss_raw=1.1914, running_loss=1.3064, LR=0.000100
[2025-08-10 15:33:06,183][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029556] [Batch 00020/03692] [00:00:10/00:31:43, 0.518s/it]: train_loss_raw=1.4272, running_loss=1.3099, LR=0.000100
[2025-08-10 15:33:12,689][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029568] [Batch 00032/03692] [00:00:16/00:32:09, 0.527s/it]: train_loss_raw=1.2596, running_loss=1.3061, LR=0.000100
[2025-08-10 15:33:19,235][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029580] [Batch 00044/03692] [00:00:23/00:32:21, 0.532s/it]: train_loss_raw=1.2633, running_loss=1.3033, LR=0.000100
[2025-08-10 15:33:25,790][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029592] [Batch 00056/03692] [00:00:29/00:32:26, 0.535s/it]: train_loss_raw=1.3054, running_loss=1.3068, LR=0.000100
[2025-08-10 15:33:32,297][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029604] [Batch 00068/03692] [00:00:36/00:32:24, 0.536s/it]: train_loss_raw=1.2540, running_loss=1.3081, LR=0.000100
[2025-08-10 15:33:38,882][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029616] [Batch 00080/03692] [00:00:43/00:32:24, 0.538s/it]: train_loss_raw=1.1959, running_loss=1.3098, LR=0.000100
[2025-08-10 15:33:45,503][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029628] [Batch 00092/03692] [00:00:49/00:32:24, 0.540s/it]: train_loss_raw=1.3252, running_loss=1.3050, LR=0.000100
[2025-08-10 15:33:52,015][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029640] [Batch 00104/03692] [00:00:56/00:32:18, 0.540s/it]: train_loss_raw=1.1872, running_loss=1.3048, LR=0.000100
[2025-08-10 15:33:58,158][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029652] [Batch 00116/03692] [00:01:02/00:32:01, 0.537s/it]: train_loss_raw=1.3489, running_loss=1.3087, LR=0.000100
[2025-08-10 15:34:04,218][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029664] [Batch 00128/03692] [00:01:08/00:31:44, 0.534s/it]: train_loss_raw=1.2039, running_loss=1.3104, LR=0.000100
[2025-08-10 15:34:10,652][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029676] [Batch 00140/03692] [00:01:14/00:31:38, 0.535s/it]: train_loss_raw=1.3061, running_loss=1.3149, LR=0.000100
[2025-08-10 15:34:17,199][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029688] [Batch 00152/03692] [00:01:21/00:31:35, 0.535s/it]: train_loss_raw=1.4216, running_loss=1.3189, LR=0.000100
[2025-08-10 15:34:23,695][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029700] [Batch 00164/03692] [00:01:27/00:31:30, 0.536s/it]: train_loss_raw=1.5000, running_loss=1.3156, LR=0.000100
[2025-08-10 15:34:29,827][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029712] [Batch 00176/03692] [00:01:34/00:31:18, 0.534s/it]: train_loss_raw=1.3297, running_loss=1.3161, LR=0.000100
[2025-08-10 15:34:35,948][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029724] [Batch 00188/03692] [00:01:40/00:31:06, 0.533s/it]: train_loss_raw=1.1870, running_loss=1.3144, LR=0.000100
[2025-08-10 15:34:42,177][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029736] [Batch 00200/03692] [00:01:46/00:30:57, 0.532s/it]: train_loss_raw=1.2940, running_loss=1.3128, LR=0.000100
[2025-08-10 15:34:48,822][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029748] [Batch 00212/03692] [00:01:53/00:30:54, 0.533s/it]: train_loss_raw=1.2555, running_loss=1.3154, LR=0.000100
[2025-08-10 15:34:55,440][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029760] [Batch 00224/03692] [00:01:59/00:30:52, 0.534s/it]: train_loss_raw=1.3092, running_loss=1.3140, LR=0.000100
[2025-08-10 15:35:01,761][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029772] [Batch 00236/03692] [00:02:05/00:30:44, 0.534s/it]: train_loss_raw=1.3342, running_loss=1.3131, LR=0.000100
[2025-08-10 15:35:08,183][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029784] [Batch 00248/03692] [00:02:12/00:30:38, 0.534s/it]: train_loss_raw=1.3024, running_loss=1.3135, LR=0.000100
[2025-08-10 15:35:14,821][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029796] [Batch 00260/03692] [00:02:19/00:30:34, 0.535s/it]: train_loss_raw=1.2084, running_loss=1.3113, LR=0.000100
[2025-08-10 15:35:21,451][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029808] [Batch 00272/03692] [00:02:25/00:30:31, 0.535s/it]: train_loss_raw=1.3583, running_loss=1.3159, LR=0.000100
[2025-08-10 15:35:28,076][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029820] [Batch 00284/03692] [00:02:32/00:30:27, 0.536s/it]: train_loss_raw=1.2530, running_loss=1.3118, LR=0.000100
[2025-08-10 15:35:34,649][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029832] [Batch 00296/03692] [00:02:38/00:30:22, 0.537s/it]: train_loss_raw=1.2343, running_loss=1.3117, LR=0.000100
[2025-08-10 15:35:41,004][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029844] [Batch 00308/03692] [00:02:45/00:30:14, 0.536s/it]: train_loss_raw=1.3619, running_loss=1.3169, LR=0.000100
[2025-08-10 15:35:47,284][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029856] [Batch 00320/03692] [00:02:51/00:30:06, 0.536s/it]: train_loss_raw=1.2266, running_loss=1.3166, LR=0.000100
[2025-08-10 15:35:53,368][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029868] [Batch 00332/03692] [00:02:57/00:29:56, 0.535s/it]: train_loss_raw=1.2419, running_loss=1.3143, LR=0.000100
[2025-08-10 15:35:59,513][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029880] [Batch 00344/03692] [00:03:03/00:29:47, 0.534s/it]: train_loss_raw=1.3431, running_loss=1.3199, LR=0.000100
[2025-08-10 15:36:05,548][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029892] [Batch 00356/03692] [00:03:09/00:29:37, 0.533s/it]: train_loss_raw=1.3217, running_loss=1.3230, LR=0.000100
[2025-08-10 15:36:11,598][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029904] [Batch 00368/03692] [00:03:15/00:29:28, 0.532s/it]: train_loss_raw=1.4270, running_loss=1.3246, LR=0.000100
[2025-08-10 15:36:17,778][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029916] [Batch 00380/03692] [00:03:21/00:29:20, 0.531s/it]: train_loss_raw=1.3903, running_loss=1.3281, LR=0.000100
[2025-08-10 15:36:23,894][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029928] [Batch 00392/03692] [00:03:28/00:29:11, 0.531s/it]: train_loss_raw=1.3413, running_loss=1.3293, LR=0.000100
[2025-08-10 15:36:30,026][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029940] [Batch 00404/03692] [00:03:34/00:29:03, 0.530s/it]: train_loss_raw=1.3840, running_loss=1.3280, LR=0.000100
[2025-08-10 15:36:36,054][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029952] [Batch 00416/03692] [00:03:40/00:28:54, 0.529s/it]: train_loss_raw=1.2710, running_loss=1.3270, LR=0.000100
[2025-08-10 15:36:42,281][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029964] [Batch 00428/03692] [00:03:46/00:28:47, 0.529s/it]: train_loss_raw=1.3188, running_loss=1.3204, LR=0.000100
[2025-08-10 15:36:48,338][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029976] [Batch 00440/03692] [00:03:52/00:28:38, 0.528s/it]: train_loss_raw=1.3526, running_loss=1.3216, LR=0.000100
[2025-08-10 15:36:54,408][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 029988] [Batch 00452/03692] [00:03:58/00:28:30, 0.528s/it]: train_loss_raw=1.3140, running_loss=1.3180, LR=0.000100
[2025-08-10 15:37:00,468][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030000] [Batch 00464/03692] [00:04:04/00:28:22, 0.527s/it]: train_loss_raw=1.3185, running_loss=1.3131, LR=0.000100
[2025-08-10 15:37:12,570][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030012] [Batch 00476/03692] [00:04:16/00:28:54, 0.539s/it]: train_loss_raw=1.3356, running_loss=1.3113, LR=0.000100
[2025-08-10 15:37:19,124][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030024] [Batch 00488/03692] [00:04:23/00:28:48, 0.540s/it]: train_loss_raw=1.2678, running_loss=1.3119, LR=0.000100
[2025-08-10 15:37:25,625][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030036] [Batch 00500/03692] [00:04:29/00:28:42, 0.540s/it]: train_loss_raw=1.1823, running_loss=1.3086, LR=0.000100
[2025-08-10 15:37:32,281][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030048] [Batch 00512/03692] [00:04:36/00:28:37, 0.540s/it]: train_loss_raw=1.4375, running_loss=1.3097, LR=0.000100
[2025-08-10 15:37:38,819][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030060] [Batch 00524/03692] [00:04:43/00:28:30, 0.540s/it]: train_loss_raw=1.2892, running_loss=1.3098, LR=0.000100
[2025-08-10 15:37:45,098][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030072] [Batch 00536/03692] [00:04:49/00:28:23, 0.540s/it]: train_loss_raw=1.2389, running_loss=1.3100, LR=0.000100
[2025-08-10 15:37:51,192][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030084] [Batch 00548/03692] [00:04:55/00:28:14, 0.539s/it]: train_loss_raw=1.2960, running_loss=1.3101, LR=0.000100
[2025-08-10 15:37:57,689][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030096] [Batch 00560/03692] [00:05:01/00:28:08, 0.539s/it]: train_loss_raw=1.3701, running_loss=1.3173, LR=0.000100
[2025-08-10 15:38:04,331][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030108] [Batch 00572/03692] [00:05:08/00:28:02, 0.539s/it]: train_loss_raw=1.1971, running_loss=1.3180, LR=0.000100
[2025-08-10 15:38:10,363][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030120] [Batch 00584/03692] [00:05:14/00:27:53, 0.539s/it]: train_loss_raw=1.3252, running_loss=1.3150, LR=0.000100
[2025-08-10 15:38:16,578][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030132] [Batch 00596/03692] [00:05:20/00:27:46, 0.538s/it]: train_loss_raw=1.3853, running_loss=1.3055, LR=0.000100
[2025-08-10 15:38:23,173][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030144] [Batch 00608/03692] [00:05:27/00:27:40, 0.538s/it]: train_loss_raw=1.3512, running_loss=1.3023, LR=0.000100
[2025-08-10 15:38:29,535][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030156] [Batch 00620/03692] [00:05:33/00:27:33, 0.538s/it]: train_loss_raw=1.4273, running_loss=1.3073, LR=0.000100
[2025-08-10 15:38:35,949][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030168] [Batch 00632/03692] [00:05:40/00:27:26, 0.538s/it]: train_loss_raw=1.3680, running_loss=1.3060, LR=0.000100
[2025-08-10 15:38:42,088][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030180] [Batch 00644/03692] [00:05:46/00:27:18, 0.538s/it]: train_loss_raw=1.3475, running_loss=1.3018, LR=0.000100
[2025-08-10 15:38:48,617][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030192] [Batch 00656/03692] [00:05:52/00:27:12, 0.538s/it]: train_loss_raw=1.3080, running_loss=1.3044, LR=0.000100
[2025-08-10 15:38:55,168][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030204] [Batch 00668/03692] [00:05:59/00:27:06, 0.538s/it]: train_loss_raw=1.2918, running_loss=1.3082, LR=0.000100
[2025-08-10 15:39:01,800][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030216] [Batch 00680/03692] [00:06:05/00:27:01, 0.538s/it]: train_loss_raw=1.3625, running_loss=1.3094, LR=0.000100
[2025-08-10 15:39:08,086][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030228] [Batch 00692/03692] [00:06:12/00:26:53, 0.538s/it]: train_loss_raw=1.4236, running_loss=1.3092, LR=0.000100
[2025-08-10 15:39:14,167][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030240] [Batch 00704/03692] [00:06:18/00:26:45, 0.537s/it]: train_loss_raw=1.4434, running_loss=1.3042, LR=0.000100
[2025-08-10 15:39:20,368][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030252] [Batch 00716/03692] [00:06:24/00:26:38, 0.537s/it]: train_loss_raw=1.4062, running_loss=1.3037, LR=0.000100
[2025-08-10 15:39:26,541][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030264] [Batch 00728/03692] [00:06:30/00:26:30, 0.537s/it]: train_loss_raw=1.3412, running_loss=1.3056, LR=0.000100
[2025-08-10 15:39:32,615][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030276] [Batch 00740/03692] [00:06:36/00:26:22, 0.536s/it]: train_loss_raw=1.3650, running_loss=1.3073, LR=0.000100
[2025-08-10 15:39:38,818][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030288] [Batch 00752/03692] [00:06:43/00:26:15, 0.536s/it]: train_loss_raw=1.2274, running_loss=1.3069, LR=0.000100
[2025-08-10 15:39:45,072][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030300] [Batch 00764/03692] [00:06:49/00:26:08, 0.536s/it]: train_loss_raw=1.4240, running_loss=1.3021, LR=0.000100
[2025-08-10 15:39:51,184][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030312] [Batch 00776/03692] [00:06:55/00:26:00, 0.535s/it]: train_loss_raw=1.2725, running_loss=1.3022, LR=0.000100
[2025-08-10 15:39:57,510][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030324] [Batch 00788/03692] [00:07:01/00:25:54, 0.535s/it]: train_loss_raw=1.2897, running_loss=1.3002, LR=0.000100
[2025-08-10 15:40:04,066][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030336] [Batch 00800/03692] [00:07:08/00:25:48, 0.535s/it]: train_loss_raw=1.3227, running_loss=1.2954, LR=0.000100
[2025-08-10 15:40:10,651][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030348] [Batch 00812/03692] [00:07:14/00:25:42, 0.536s/it]: train_loss_raw=1.1492, running_loss=1.2925, LR=0.000100
[2025-08-10 15:40:17,202][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030360] [Batch 00824/03692] [00:07:21/00:25:36, 0.536s/it]: train_loss_raw=1.4094, running_loss=1.2964, LR=0.000100
[2025-08-10 15:40:23,764][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030372] [Batch 00836/03692] [00:07:27/00:25:30, 0.536s/it]: train_loss_raw=1.3464, running_loss=1.2987, LR=0.000100
[2025-08-10 15:40:30,361][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030384] [Batch 00848/03692] [00:07:34/00:25:24, 0.536s/it]: train_loss_raw=1.2710, running_loss=1.2969, LR=0.000100
[2025-08-10 15:40:36,944][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030396] [Batch 00860/03692] [00:07:41/00:25:18, 0.536s/it]: train_loss_raw=1.3419, running_loss=1.3012, LR=0.000100
[2025-08-10 15:40:43,573][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030408] [Batch 00872/03692] [00:07:47/00:25:12, 0.536s/it]: train_loss_raw=1.2773, running_loss=1.3049, LR=0.000100
[2025-08-10 15:40:50,109][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030420] [Batch 00884/03692] [00:07:54/00:25:06, 0.537s/it]: train_loss_raw=1.2092, running_loss=1.3067, LR=0.000100
[2025-08-10 15:40:56,664][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030432] [Batch 00896/03692] [00:08:00/00:25:00, 0.537s/it]: train_loss_raw=1.2582, running_loss=1.3072, LR=0.000100
[2025-08-10 15:41:02,719][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030444] [Batch 00908/03692] [00:08:06/00:24:52, 0.536s/it]: train_loss_raw=1.1773, running_loss=1.3074, LR=0.000100
[2025-08-10 15:41:08,779][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030456] [Batch 00920/03692] [00:08:12/00:24:45, 0.536s/it]: train_loss_raw=1.1993, running_loss=1.3077, LR=0.000100
[2025-08-10 15:41:15,261][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030468] [Batch 00932/03692] [00:08:19/00:24:39, 0.536s/it]: train_loss_raw=1.3460, running_loss=1.3022, LR=0.000100
[2025-08-10 15:41:21,698][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030480] [Batch 00944/03692] [00:08:25/00:24:32, 0.536s/it]: train_loss_raw=1.4439, running_loss=1.3055, LR=0.000100
[2025-08-10 15:41:28,099][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030492] [Batch 00956/03692] [00:08:32/00:24:26, 0.536s/it]: train_loss_raw=1.3637, running_loss=1.3039, LR=0.000100
[2025-08-10 15:41:34,492][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030504] [Batch 00968/03692] [00:08:38/00:24:19, 0.536s/it]: train_loss_raw=1.1754, running_loss=1.3027, LR=0.000100
[2025-08-10 15:41:40,912][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030516] [Batch 00980/03692] [00:08:45/00:24:13, 0.536s/it]: train_loss_raw=1.4140, running_loss=1.3043, LR=0.000100
[2025-08-10 15:41:47,029][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030528] [Batch 00992/03692] [00:08:51/00:24:05, 0.535s/it]: train_loss_raw=1.2095, running_loss=1.3007, LR=0.000100
[2025-08-10 15:41:53,191][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030540] [Batch 01004/03692] [00:08:57/00:23:58, 0.535s/it]: train_loss_raw=1.4294, running_loss=1.2995, LR=0.000100
[2025-08-10 15:41:59,738][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030552] [Batch 01016/03692] [00:09:03/00:23:52, 0.535s/it]: train_loss_raw=1.2745, running_loss=1.2951, LR=0.000100
[2025-08-10 15:42:06,224][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030564] [Batch 01028/03692] [00:09:10/00:23:46, 0.535s/it]: train_loss_raw=1.3895, running_loss=1.2949, LR=0.000100
[2025-08-10 15:42:12,789][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030576] [Batch 01040/03692] [00:09:16/00:23:40, 0.536s/it]: train_loss_raw=1.3247, running_loss=1.2949, LR=0.000100
[2025-08-10 15:42:19,356][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030588] [Batch 01052/03692] [00:09:23/00:23:34, 0.536s/it]: train_loss_raw=1.3181, running_loss=1.2959, LR=0.000100
[2025-08-10 15:42:25,984][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030600] [Batch 01064/03692] [00:09:30/00:23:28, 0.536s/it]: train_loss_raw=1.2829, running_loss=1.2980, LR=0.000100
[2025-08-10 15:42:32,111][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030612] [Batch 01076/03692] [00:09:36/00:23:21, 0.536s/it]: train_loss_raw=1.3122, running_loss=1.3003, LR=0.000100
[2025-08-10 15:42:38,333][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030624] [Batch 01088/03692] [00:09:42/00:23:14, 0.535s/it]: train_loss_raw=1.3316, running_loss=1.3019, LR=0.000100
[2025-08-10 15:42:44,577][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030636] [Batch 01100/03692] [00:09:48/00:23:07, 0.535s/it]: train_loss_raw=1.2858, running_loss=1.3002, LR=0.000100
[2025-08-10 15:42:50,743][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030648] [Batch 01112/03692] [00:09:54/00:23:00, 0.535s/it]: train_loss_raw=1.2359, running_loss=1.2933, LR=0.000100
[2025-08-10 15:42:57,088][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030660] [Batch 01124/03692] [00:10:01/00:22:53, 0.535s/it]: train_loss_raw=1.1298, running_loss=1.2913, LR=0.000100
[2025-08-10 15:43:03,603][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030672] [Batch 01136/03692] [00:10:07/00:22:47, 0.535s/it]: train_loss_raw=1.3805, running_loss=1.2943, LR=0.000100
[2025-08-10 15:43:10,152][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030684] [Batch 01148/03692] [00:10:14/00:22:41, 0.535s/it]: train_loss_raw=1.3188, running_loss=1.2973, LR=0.000100
[2025-08-10 15:43:16,673][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030696] [Batch 01160/03692] [00:10:20/00:22:35, 0.535s/it]: train_loss_raw=1.2289, running_loss=1.2988, LR=0.000100
[2025-08-10 15:43:22,979][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030708] [Batch 01172/03692] [00:10:27/00:22:28, 0.535s/it]: train_loss_raw=1.3250, running_loss=1.3002, LR=0.000100
[2025-08-10 15:43:29,002][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030720] [Batch 01184/03692] [00:10:33/00:22:21, 0.535s/it]: train_loss_raw=1.2229, running_loss=1.2968, LR=0.000100
[2025-08-10 15:43:35,087][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030732] [Batch 01196/03692] [00:10:39/00:22:14, 0.535s/it]: train_loss_raw=1.2648, running_loss=1.2986, LR=0.000100
[2025-08-10 15:43:41,170][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030744] [Batch 01208/03692] [00:10:45/00:22:07, 0.534s/it]: train_loss_raw=1.2944, running_loss=1.2961, LR=0.000100
[2025-08-10 15:43:47,502][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030756] [Batch 01220/03692] [00:10:51/00:22:00, 0.534s/it]: train_loss_raw=1.2081, running_loss=1.2938, LR=0.000100
[2025-08-10 15:43:53,800][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030768] [Batch 01232/03692] [00:10:57/00:21:53, 0.534s/it]: train_loss_raw=1.1291, running_loss=1.2925, LR=0.000100
[2025-08-10 15:44:00,317][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030780] [Batch 01244/03692] [00:11:04/00:21:47, 0.534s/it]: train_loss_raw=1.3905, running_loss=1.2912, LR=0.000100
[2025-08-10 15:44:06,960][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030792] [Batch 01256/03692] [00:11:11/00:21:41, 0.534s/it]: train_loss_raw=1.2713, running_loss=1.2914, LR=0.000100
[2025-08-10 15:44:13,518][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030804] [Batch 01268/03692] [00:11:17/00:21:35, 0.534s/it]: train_loss_raw=1.2455, running_loss=1.2923, LR=0.000100
[2025-08-10 15:44:20,132][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030816] [Batch 01280/03692] [00:11:24/00:21:29, 0.535s/it]: train_loss_raw=1.2549, running_loss=1.2946, LR=0.000100
[2025-08-10 15:44:26,817][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030828] [Batch 01292/03692] [00:11:30/00:21:23, 0.535s/it]: train_loss_raw=1.3266, running_loss=1.2971, LR=0.000100
[2025-08-10 15:44:33,208][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030840] [Batch 01304/03692] [00:11:37/00:21:17, 0.535s/it]: train_loss_raw=1.3696, running_loss=1.2948, LR=0.000100
[2025-08-10 15:44:39,422][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030852] [Batch 01316/03692] [00:11:43/00:21:10, 0.535s/it]: train_loss_raw=1.2274, running_loss=1.2941, LR=0.000100
[2025-08-10 15:44:45,919][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030864] [Batch 01328/03692] [00:11:50/00:21:04, 0.535s/it]: train_loss_raw=1.3379, running_loss=1.2966, LR=0.000100
[2025-08-10 15:44:52,437][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030876] [Batch 01340/03692] [00:11:56/00:20:57, 0.535s/it]: train_loss_raw=1.3158, running_loss=1.2949, LR=0.000100
[2025-08-10 15:44:59,035][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030888] [Batch 01352/03692] [00:12:03/00:20:51, 0.535s/it]: train_loss_raw=1.3450, running_loss=1.2901, LR=0.000100
[2025-08-10 15:45:05,574][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030900] [Batch 01364/03692] [00:12:09/00:20:45, 0.535s/it]: train_loss_raw=1.3732, running_loss=1.2914, LR=0.000100
[2025-08-10 15:45:12,093][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030912] [Batch 01376/03692] [00:12:16/00:20:39, 0.535s/it]: train_loss_raw=1.3772, running_loss=1.2912, LR=0.000100
[2025-08-10 15:45:18,309][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030924] [Batch 01388/03692] [00:12:22/00:20:32, 0.535s/it]: train_loss_raw=1.3439, running_loss=1.2887, LR=0.000100
[2025-08-10 15:45:24,387][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030936] [Batch 01400/03692] [00:12:28/00:20:25, 0.535s/it]: train_loss_raw=1.3116, running_loss=1.2913, LR=0.000100
[2025-08-10 15:45:30,574][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030948] [Batch 01412/03692] [00:12:34/00:20:18, 0.535s/it]: train_loss_raw=1.3023, running_loss=1.2919, LR=0.000100
[2025-08-10 15:45:36,695][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030960] [Batch 01424/03692] [00:12:40/00:20:11, 0.534s/it]: train_loss_raw=1.3301, running_loss=1.2937, LR=0.000100
[2025-08-10 15:45:42,899][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030972] [Batch 01436/03692] [00:12:47/00:20:05, 0.534s/it]: train_loss_raw=1.3386, running_loss=1.2975, LR=0.000100
[2025-08-10 15:45:49,083][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030984] [Batch 01448/03692] [00:12:53/00:19:58, 0.534s/it]: train_loss_raw=1.3132, running_loss=1.2971, LR=0.000100
[2025-08-10 15:45:55,615][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 030996] [Batch 01460/03692] [00:12:59/00:19:52, 0.534s/it]: train_loss_raw=1.2685, running_loss=1.2944, LR=0.000100
[2025-08-10 15:46:01,666][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031008] [Batch 01472/03692] [00:13:05/00:19:45, 0.534s/it]: train_loss_raw=1.2043, running_loss=1.2938, LR=0.000100
[2025-08-10 15:46:07,828][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031020] [Batch 01484/03692] [00:13:12/00:19:38, 0.534s/it]: train_loss_raw=1.3730, running_loss=1.2970, LR=0.000100
[2025-08-10 15:46:13,932][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031032] [Batch 01496/03692] [00:13:18/00:19:31, 0.533s/it]: train_loss_raw=1.2403, running_loss=1.2932, LR=0.000100
[2025-08-10 15:46:20,039][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031044] [Batch 01508/03692] [00:13:24/00:19:24, 0.533s/it]: train_loss_raw=1.2486, running_loss=1.2892, LR=0.000100
[2025-08-10 15:46:26,182][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031056] [Batch 01520/03692] [00:13:30/00:19:17, 0.533s/it]: train_loss_raw=1.2625, running_loss=1.2968, LR=0.000100
[2025-08-10 15:46:32,253][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031068] [Batch 01532/03692] [00:13:36/00:19:11, 0.533s/it]: train_loss_raw=1.3376, running_loss=1.2965, LR=0.000100
[2025-08-10 15:46:38,295][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031080] [Batch 01544/03692] [00:13:42/00:19:04, 0.533s/it]: train_loss_raw=1.2984, running_loss=1.2963, LR=0.000100
[2025-08-10 15:46:44,384][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031092] [Batch 01556/03692] [00:13:48/00:18:57, 0.532s/it]: train_loss_raw=1.2756, running_loss=1.2958, LR=0.000100
[2025-08-10 15:46:50,427][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031104] [Batch 01568/03692] [00:13:54/00:18:50, 0.532s/it]: train_loss_raw=1.2582, running_loss=1.2933, LR=0.000100
[2025-08-10 15:46:56,438][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031116] [Batch 01580/03692] [00:14:00/00:18:43, 0.532s/it]: train_loss_raw=1.2192, running_loss=1.2892, LR=0.000100
[2025-08-10 15:47:02,517][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031128] [Batch 01592/03692] [00:14:06/00:18:36, 0.532s/it]: train_loss_raw=1.3571, running_loss=1.2898, LR=0.000100
[2025-08-10 15:47:08,875][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031140] [Batch 01604/03692] [00:14:13/00:18:30, 0.532s/it]: train_loss_raw=1.4011, running_loss=1.2895, LR=0.000100
[2025-08-10 15:47:15,460][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031152] [Batch 01616/03692] [00:14:19/00:18:24, 0.532s/it]: train_loss_raw=1.2111, running_loss=1.2891, LR=0.000100
[2025-08-10 15:47:22,030][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031164] [Batch 01628/03692] [00:14:26/00:18:18, 0.532s/it]: train_loss_raw=1.1882, running_loss=1.2925, LR=0.000100
[2025-08-10 15:47:28,601][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031176] [Batch 01640/03692] [00:14:32/00:18:12, 0.532s/it]: train_loss_raw=1.3064, running_loss=1.2954, LR=0.000100
[2025-08-10 15:47:35,210][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031188] [Batch 01652/03692] [00:14:39/00:18:05, 0.532s/it]: train_loss_raw=1.1214, running_loss=1.2912, LR=0.000100
[2025-08-10 15:47:41,795][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031200] [Batch 01664/03692] [00:14:45/00:17:59, 0.532s/it]: train_loss_raw=1.3813, running_loss=1.2924, LR=0.000100
[2025-08-10 15:47:48,464][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031212] [Batch 01676/03692] [00:14:52/00:17:53, 0.533s/it]: train_loss_raw=1.3374, running_loss=1.2912, LR=0.000100
[2025-08-10 15:47:54,963][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031224] [Batch 01688/03692] [00:14:59/00:17:47, 0.533s/it]: train_loss_raw=1.3101, running_loss=1.2881, LR=0.000100
[2025-08-10 15:48:01,589][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031236] [Batch 01700/03692] [00:15:05/00:17:41, 0.533s/it]: train_loss_raw=1.2349, running_loss=1.2851, LR=0.000100
[2025-08-10 15:48:08,236][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031248] [Batch 01712/03692] [00:15:12/00:17:35, 0.533s/it]: train_loss_raw=1.3270, running_loss=1.2860, LR=0.000100
[2025-08-10 15:48:14,854][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031260] [Batch 01724/03692] [00:15:19/00:17:29, 0.533s/it]: train_loss_raw=1.3135, running_loss=1.2871, LR=0.000100
[2025-08-10 15:48:21,230][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031272] [Batch 01736/03692] [00:15:25/00:17:22, 0.533s/it]: train_loss_raw=1.3394, running_loss=1.2907, LR=0.000100
[2025-08-10 15:48:27,280][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031284] [Batch 01748/03692] [00:15:31/00:17:15, 0.533s/it]: train_loss_raw=1.2751, running_loss=1.2912, LR=0.000100
[2025-08-10 15:48:33,329][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031296] [Batch 01760/03692] [00:15:37/00:17:09, 0.533s/it]: train_loss_raw=1.2645, running_loss=1.2910, LR=0.000100
[2025-08-10 15:48:39,435][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031308] [Batch 01772/03692] [00:15:43/00:17:02, 0.533s/it]: train_loss_raw=1.1604, running_loss=1.2898, LR=0.000100
[2025-08-10 15:48:45,564][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031320] [Batch 01784/03692] [00:15:49/00:16:55, 0.532s/it]: train_loss_raw=1.4033, running_loss=1.2892, LR=0.000100
[2025-08-10 15:48:51,594][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031332] [Batch 01796/03692] [00:15:55/00:16:48, 0.532s/it]: train_loss_raw=1.2541, running_loss=1.2881, LR=0.000100
[2025-08-10 15:48:57,672][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031344] [Batch 01808/03692] [00:16:01/00:16:42, 0.532s/it]: train_loss_raw=1.2754, running_loss=1.2854, LR=0.000100
[2025-08-10 15:49:03,771][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031356] [Batch 01820/03692] [00:16:07/00:16:35, 0.532s/it]: train_loss_raw=1.3259, running_loss=1.2880, LR=0.000100
[2025-08-10 15:49:09,844][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031368] [Batch 01832/03692] [00:16:14/00:16:28, 0.532s/it]: train_loss_raw=1.2697, running_loss=1.2863, LR=0.000100
[2025-08-10 15:49:15,901][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031380] [Batch 01844/03692] [00:16:20/00:16:22, 0.531s/it]: train_loss_raw=1.1700, running_loss=1.2864, LR=0.000100
[2025-08-10 15:49:22,001][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031392] [Batch 01856/03692] [00:16:26/00:16:15, 0.531s/it]: train_loss_raw=1.1211, running_loss=1.2870, LR=0.000100
[2025-08-10 15:49:28,167][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031404] [Batch 01868/03692] [00:16:32/00:16:08, 0.531s/it]: train_loss_raw=1.3244, running_loss=1.2907, LR=0.000100
[2025-08-10 15:49:34,623][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031416] [Batch 01880/03692] [00:16:38/00:16:02, 0.531s/it]: train_loss_raw=1.2174, running_loss=1.2865, LR=0.000100
[2025-08-10 15:49:40,691][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031428] [Batch 01892/03692] [00:16:44/00:15:56, 0.531s/it]: train_loss_raw=1.1748, running_loss=1.2837, LR=0.000100
[2025-08-10 15:49:47,046][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031440] [Batch 01904/03692] [00:16:51/00:15:49, 0.531s/it]: train_loss_raw=1.0832, running_loss=1.2812, LR=0.000100
[2025-08-10 15:49:53,677][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031452] [Batch 01916/03692] [00:16:57/00:15:43, 0.531s/it]: train_loss_raw=1.3443, running_loss=1.2839, LR=0.000100
[2025-08-10 15:50:00,165][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031464] [Batch 01928/03692] [00:17:04/00:15:37, 0.531s/it]: train_loss_raw=1.4457, running_loss=1.2864, LR=0.000100
[2025-08-10 15:50:06,662][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031476] [Batch 01940/03692] [00:17:10/00:15:30, 0.531s/it]: train_loss_raw=1.2878, running_loss=1.2849, LR=0.000100
[2025-08-10 15:50:13,256][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031488] [Batch 01952/03692] [00:17:17/00:15:24, 0.531s/it]: train_loss_raw=1.2935, running_loss=1.2842, LR=0.000100
[2025-08-10 15:50:19,823][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031500] [Batch 01964/03692] [00:17:24/00:15:18, 0.532s/it]: train_loss_raw=1.2695, running_loss=1.2802, LR=0.000100
[2025-08-10 15:50:26,388][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031512] [Batch 01976/03692] [00:17:30/00:15:12, 0.532s/it]: train_loss_raw=1.2715, running_loss=1.2796, LR=0.000100
[2025-08-10 15:50:32,912][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031524] [Batch 01988/03692] [00:17:37/00:15:06, 0.532s/it]: train_loss_raw=1.1946, running_loss=1.2782, LR=0.000100
[2025-08-10 15:50:39,356][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031536] [Batch 02000/03692] [00:17:43/00:14:59, 0.532s/it]: train_loss_raw=1.1308, running_loss=1.2791, LR=0.000100
[2025-08-10 15:50:45,871][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031548] [Batch 02012/03692] [00:17:50/00:14:53, 0.532s/it]: train_loss_raw=1.4014, running_loss=1.2828, LR=0.000100
[2025-08-10 15:50:52,439][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031560] [Batch 02024/03692] [00:17:56/00:14:47, 0.532s/it]: train_loss_raw=1.2362, running_loss=1.2868, LR=0.000100
[2025-08-10 15:50:59,012][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031572] [Batch 02036/03692] [00:18:03/00:14:41, 0.532s/it]: train_loss_raw=1.3093, running_loss=1.2863, LR=0.000100
[2025-08-10 15:51:05,658][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031584] [Batch 02048/03692] [00:18:09/00:14:34, 0.532s/it]: train_loss_raw=1.3746, running_loss=1.2892, LR=0.000100
[2025-08-10 15:51:12,249][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031596] [Batch 02060/03692] [00:18:16/00:14:28, 0.532s/it]: train_loss_raw=1.2565, running_loss=1.2841, LR=0.000100
[2025-08-10 15:51:18,558][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031608] [Batch 02072/03692] [00:18:22/00:14:22, 0.532s/it]: train_loss_raw=1.1397, running_loss=1.2818, LR=0.000100
[2025-08-10 15:51:24,785][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031620] [Batch 02084/03692] [00:18:28/00:14:15, 0.532s/it]: train_loss_raw=1.1614, running_loss=1.2822, LR=0.000100
[2025-08-10 15:51:30,912][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031632] [Batch 02096/03692] [00:18:35/00:14:09, 0.532s/it]: train_loss_raw=1.3062, running_loss=1.2847, LR=0.000100
[2025-08-10 15:51:37,089][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031644] [Batch 02108/03692] [00:18:41/00:14:02, 0.532s/it]: train_loss_raw=1.2298, running_loss=1.2788, LR=0.000100
[2025-08-10 15:51:43,613][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031656] [Batch 02120/03692] [00:18:47/00:13:56, 0.532s/it]: train_loss_raw=1.1223, running_loss=1.2799, LR=0.000100
[2025-08-10 15:51:50,138][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031668] [Batch 02132/03692] [00:18:54/00:13:49, 0.532s/it]: train_loss_raw=1.2307, running_loss=1.2852, LR=0.000100
[2025-08-10 15:51:56,444][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031680] [Batch 02144/03692] [00:19:00/00:13:43, 0.532s/it]: train_loss_raw=1.2715, running_loss=1.2851, LR=0.000100
[2025-08-10 15:52:02,624][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031692] [Batch 02156/03692] [00:19:06/00:13:37, 0.532s/it]: train_loss_raw=1.2925, running_loss=1.2837, LR=0.000100
[2025-08-10 15:52:09,046][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031704] [Batch 02168/03692] [00:19:13/00:13:30, 0.532s/it]: train_loss_raw=1.2515, running_loss=1.2821, LR=0.000100
[2025-08-10 15:52:15,624][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031716] [Batch 02180/03692] [00:19:19/00:13:24, 0.532s/it]: train_loss_raw=1.3670, running_loss=1.2849, LR=0.000100
[2025-08-10 15:52:22,128][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031728] [Batch 02192/03692] [00:19:26/00:13:18, 0.532s/it]: train_loss_raw=1.4122, running_loss=1.2905, LR=0.000100
[2025-08-10 15:52:28,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031740] [Batch 02204/03692] [00:19:32/00:13:11, 0.532s/it]: train_loss_raw=1.3037, running_loss=1.2897, LR=0.000100
[2025-08-10 15:52:34,857][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031752] [Batch 02216/03692] [00:19:39/00:13:05, 0.532s/it]: train_loss_raw=1.2267, running_loss=1.2894, LR=0.000100
[2025-08-10 15:52:41,401][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031764] [Batch 02228/03692] [00:19:45/00:12:59, 0.532s/it]: train_loss_raw=1.0847, running_loss=1.2880, LR=0.000100
[2025-08-10 15:52:47,909][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031776] [Batch 02240/03692] [00:19:52/00:12:52, 0.532s/it]: train_loss_raw=1.4086, running_loss=1.2867, LR=0.000100
[2025-08-10 15:52:54,501][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031788] [Batch 02252/03692] [00:19:58/00:12:46, 0.532s/it]: train_loss_raw=1.3479, running_loss=1.2874, LR=0.000100
[2025-08-10 15:53:01,054][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031800] [Batch 02264/03692] [00:20:05/00:12:40, 0.532s/it]: train_loss_raw=1.3402, running_loss=1.2887, LR=0.000100
[2025-08-10 15:53:07,551][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031812] [Batch 02276/03692] [00:20:11/00:12:33, 0.532s/it]: train_loss_raw=1.3645, running_loss=1.2879, LR=0.000100
[2025-08-10 15:53:14,289][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031824] [Batch 02288/03692] [00:20:18/00:12:27, 0.533s/it]: train_loss_raw=1.2334, running_loss=1.2860, LR=0.000100
[2025-08-10 15:53:20,844][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031836] [Batch 02300/03692] [00:20:25/00:12:21, 0.533s/it]: train_loss_raw=1.3369, running_loss=1.2844, LR=0.000100
[2025-08-10 15:53:27,520][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031848] [Batch 02312/03692] [00:20:31/00:12:15, 0.533s/it]: train_loss_raw=1.1786, running_loss=1.2830, LR=0.000100
[2025-08-10 15:53:34,103][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031860] [Batch 02324/03692] [00:20:38/00:12:08, 0.533s/it]: train_loss_raw=1.1708, running_loss=1.2804, LR=0.000100
[2025-08-10 15:53:40,672][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031872] [Batch 02336/03692] [00:20:44/00:12:02, 0.533s/it]: train_loss_raw=1.2563, running_loss=1.2799, LR=0.000100
[2025-08-10 15:53:47,240][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031884] [Batch 02348/03692] [00:20:51/00:11:56, 0.533s/it]: train_loss_raw=1.3417, running_loss=1.2746, LR=0.000100
[2025-08-10 15:53:53,901][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031896] [Batch 02360/03692] [00:20:58/00:11:50, 0.533s/it]: train_loss_raw=1.2493, running_loss=1.2697, LR=0.000100
[2025-08-10 15:54:00,482][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031908] [Batch 02372/03692] [00:21:04/00:11:43, 0.533s/it]: train_loss_raw=1.3624, running_loss=1.2711, LR=0.000100
[2025-08-10 15:54:07,102][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031920] [Batch 02384/03692] [00:21:11/00:11:37, 0.533s/it]: train_loss_raw=1.3696, running_loss=1.2745, LR=0.000100
[2025-08-10 15:54:13,504][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031932] [Batch 02396/03692] [00:21:17/00:11:31, 0.533s/it]: train_loss_raw=1.3243, running_loss=1.2764, LR=0.000100
[2025-08-10 15:54:19,815][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031944] [Batch 02408/03692] [00:21:23/00:11:24, 0.533s/it]: train_loss_raw=1.3391, running_loss=1.2759, LR=0.000100
[2025-08-10 15:54:26,243][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031956] [Batch 02420/03692] [00:21:30/00:11:18, 0.533s/it]: train_loss_raw=1.2970, running_loss=1.2759, LR=0.000100
[2025-08-10 15:54:32,747][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031968] [Batch 02432/03692] [00:21:36/00:11:11, 0.533s/it]: train_loss_raw=1.1550, running_loss=1.2725, LR=0.000100
[2025-08-10 15:54:39,003][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031980] [Batch 02444/03692] [00:21:43/00:11:05, 0.533s/it]: train_loss_raw=1.3162, running_loss=1.2727, LR=0.000100
[2025-08-10 15:54:45,072][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 031992] [Batch 02456/03692] [00:21:49/00:10:58, 0.533s/it]: train_loss_raw=1.3818, running_loss=1.2768, LR=0.000100
[2025-08-10 15:54:55,591][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032004] [Batch 02468/03692] [00:21:59/00:10:54, 0.535s/it]: train_loss_raw=1.2979, running_loss=1.2769, LR=0.000100
[2025-08-10 15:55:01,704][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032016] [Batch 02480/03692] [00:22:05/00:10:47, 0.535s/it]: train_loss_raw=1.2258, running_loss=1.2752, LR=0.000100
[2025-08-10 15:55:07,854][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032028] [Batch 02492/03692] [00:22:12/00:10:41, 0.535s/it]: train_loss_raw=1.2142, running_loss=1.2737, LR=0.000100
[2025-08-10 15:55:14,277][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032040] [Batch 02504/03692] [00:22:18/00:10:35, 0.535s/it]: train_loss_raw=1.2181, running_loss=1.2743, LR=0.000100
[2025-08-10 15:55:20,836][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032052] [Batch 02516/03692] [00:22:25/00:10:28, 0.535s/it]: train_loss_raw=1.2928, running_loss=1.2722, LR=0.000100
[2025-08-10 15:55:27,395][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032064] [Batch 02528/03692] [00:22:31/00:10:22, 0.535s/it]: train_loss_raw=1.3456, running_loss=1.2703, LR=0.000100
[2025-08-10 15:55:33,980][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032076] [Batch 02540/03692] [00:22:38/00:10:15, 0.535s/it]: train_loss_raw=1.2140, running_loss=1.2687, LR=0.000100
[2025-08-10 15:55:40,511][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032088] [Batch 02552/03692] [00:22:44/00:10:09, 0.535s/it]: train_loss_raw=1.3320, running_loss=1.2705, LR=0.000100
[2025-08-10 15:55:46,920][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032100] [Batch 02564/03692] [00:22:51/00:10:03, 0.535s/it]: train_loss_raw=1.3323, running_loss=1.2660, LR=0.000100
[2025-08-10 15:55:52,935][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032112] [Batch 02576/03692] [00:22:57/00:09:56, 0.535s/it]: train_loss_raw=1.3079, running_loss=1.2672, LR=0.000100
[2025-08-10 15:55:59,363][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032124] [Batch 02588/03692] [00:23:03/00:09:50, 0.535s/it]: train_loss_raw=1.2333, running_loss=1.2684, LR=0.000100
[2025-08-10 15:56:05,755][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032136] [Batch 02600/03692] [00:23:09/00:09:43, 0.535s/it]: train_loss_raw=1.2438, running_loss=1.2679, LR=0.000100
[2025-08-10 15:56:12,078][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032148] [Batch 02612/03692] [00:23:16/00:09:37, 0.535s/it]: train_loss_raw=1.2926, running_loss=1.2704, LR=0.000100
[2025-08-10 15:56:18,637][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032160] [Batch 02624/03692] [00:23:22/00:09:30, 0.535s/it]: train_loss_raw=1.2489, running_loss=1.2728, LR=0.000100
[2025-08-10 15:56:25,222][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032172] [Batch 02636/03692] [00:23:29/00:09:24, 0.535s/it]: train_loss_raw=1.2430, running_loss=1.2681, LR=0.000100
[2025-08-10 15:56:31,763][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032184] [Batch 02648/03692] [00:23:35/00:09:18, 0.535s/it]: train_loss_raw=1.2791, running_loss=1.2706, LR=0.000100
[2025-08-10 15:56:38,173][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032196] [Batch 02660/03692] [00:23:42/00:09:11, 0.535s/it]: train_loss_raw=1.1408, running_loss=1.2690, LR=0.000100
[2025-08-10 15:56:44,162][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032208] [Batch 02672/03692] [00:23:48/00:09:05, 0.535s/it]: train_loss_raw=1.2410, running_loss=1.2697, LR=0.000100
[2025-08-10 15:56:50,246][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032220] [Batch 02684/03692] [00:23:54/00:08:58, 0.534s/it]: train_loss_raw=1.1450, running_loss=1.2661, LR=0.000100
[2025-08-10 15:56:56,378][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032232] [Batch 02696/03692] [00:24:00/00:08:52, 0.534s/it]: train_loss_raw=1.2948, running_loss=1.2712, LR=0.000100
[2025-08-10 15:57:02,508][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032244] [Batch 02708/03692] [00:24:06/00:08:45, 0.534s/it]: train_loss_raw=1.2133, running_loss=1.2700, LR=0.000100
[2025-08-10 15:57:08,607][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032256] [Batch 02720/03692] [00:24:12/00:08:39, 0.534s/it]: train_loss_raw=1.2453, running_loss=1.2660, LR=0.000100
[2025-08-10 15:57:14,720][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032268] [Batch 02732/03692] [00:24:18/00:08:32, 0.534s/it]: train_loss_raw=1.3568, running_loss=1.2675, LR=0.000100
[2025-08-10 15:57:20,764][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032280] [Batch 02744/03692] [00:24:24/00:08:26, 0.534s/it]: train_loss_raw=1.2298, running_loss=1.2670, LR=0.000100
[2025-08-10 15:57:26,833][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032292] [Batch 02756/03692] [00:24:31/00:08:19, 0.534s/it]: train_loss_raw=1.2912, running_loss=1.2699, LR=0.000100
[2025-08-10 15:57:32,962][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032304] [Batch 02768/03692] [00:24:37/00:08:13, 0.534s/it]: train_loss_raw=1.2234, running_loss=1.2719, LR=0.000100
[2025-08-10 15:57:39,165][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032316] [Batch 02780/03692] [00:24:43/00:08:06, 0.534s/it]: train_loss_raw=1.3796, running_loss=1.2727, LR=0.000100
[2025-08-10 15:57:45,304][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032328] [Batch 02792/03692] [00:24:49/00:08:00, 0.533s/it]: train_loss_raw=1.2771, running_loss=1.2717, LR=0.000100
[2025-08-10 15:57:51,451][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032340] [Batch 02804/03692] [00:24:55/00:07:53, 0.533s/it]: train_loss_raw=1.3456, running_loss=1.2697, LR=0.000100
[2025-08-10 15:57:57,657][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032352] [Batch 02816/03692] [00:25:01/00:07:47, 0.533s/it]: train_loss_raw=1.3338, running_loss=1.2765, LR=0.000100
[2025-08-10 15:58:03,784][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032364] [Batch 02828/03692] [00:25:07/00:07:40, 0.533s/it]: train_loss_raw=1.3624, running_loss=1.2797, LR=0.000100
[2025-08-10 15:58:09,955][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032376] [Batch 02840/03692] [00:25:14/00:07:34, 0.533s/it]: train_loss_raw=1.3849, running_loss=1.2778, LR=0.000100
[2025-08-10 15:58:16,010][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032388] [Batch 02852/03692] [00:25:20/00:07:27, 0.533s/it]: train_loss_raw=1.2972, running_loss=1.2745, LR=0.000100
[2025-08-10 15:58:22,077][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032400] [Batch 02864/03692] [00:25:26/00:07:21, 0.533s/it]: train_loss_raw=1.4335, running_loss=1.2779, LR=0.000100
[2025-08-10 15:58:28,121][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032412] [Batch 02876/03692] [00:25:32/00:07:14, 0.533s/it]: train_loss_raw=1.3810, running_loss=1.2761, LR=0.000100
[2025-08-10 15:58:34,233][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032424] [Batch 02888/03692] [00:25:38/00:07:08, 0.533s/it]: train_loss_raw=1.3201, running_loss=1.2727, LR=0.000100
[2025-08-10 15:58:40,289][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032436] [Batch 02900/03692] [00:25:44/00:07:01, 0.533s/it]: train_loss_raw=1.2119, running_loss=1.2681, LR=0.000100
[2025-08-10 15:58:46,438][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032448] [Batch 02912/03692] [00:25:50/00:06:55, 0.532s/it]: train_loss_raw=1.4396, running_loss=1.2704, LR=0.000100
[2025-08-10 15:58:52,545][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032460] [Batch 02924/03692] [00:25:56/00:06:48, 0.532s/it]: train_loss_raw=1.3066, running_loss=1.2702, LR=0.000100
[2025-08-10 15:58:58,800][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032472] [Batch 02936/03692] [00:26:02/00:06:42, 0.532s/it]: train_loss_raw=1.2057, running_loss=1.2666, LR=0.000100
[2025-08-10 15:59:05,017][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032484] [Batch 02948/03692] [00:26:09/00:06:36, 0.532s/it]: train_loss_raw=1.4306, running_loss=1.2712, LR=0.000100
[2025-08-10 15:59:11,140][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032496] [Batch 02960/03692] [00:26:15/00:06:29, 0.532s/it]: train_loss_raw=1.3079, running_loss=1.2753, LR=0.000100
[2025-08-10 15:59:17,313][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032508] [Batch 02972/03692] [00:26:21/00:06:23, 0.532s/it]: train_loss_raw=1.3431, running_loss=1.2720, LR=0.000100
[2025-08-10 15:59:23,437][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032520] [Batch 02984/03692] [00:26:27/00:06:16, 0.532s/it]: train_loss_raw=1.2495, running_loss=1.2727, LR=0.000100
[2025-08-10 15:59:29,711][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032532] [Batch 02996/03692] [00:26:33/00:06:10, 0.532s/it]: train_loss_raw=1.2165, running_loss=1.2753, LR=0.000100
[2025-08-10 15:59:36,222][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032544] [Batch 03008/03692] [00:26:40/00:06:03, 0.532s/it]: train_loss_raw=1.3571, running_loss=1.2737, LR=0.000100
[2025-08-10 15:59:42,911][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032556] [Batch 03020/03692] [00:26:47/00:05:57, 0.532s/it]: train_loss_raw=1.1894, running_loss=1.2680, LR=0.000100
[2025-08-10 15:59:49,550][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032568] [Batch 03032/03692] [00:26:53/00:05:51, 0.532s/it]: train_loss_raw=1.2548, running_loss=1.2695, LR=0.000100
[2025-08-10 15:59:55,919][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032580] [Batch 03044/03692] [00:27:00/00:05:44, 0.532s/it]: train_loss_raw=1.4105, running_loss=1.2715, LR=0.000100
[2025-08-10 16:00:02,047][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032592] [Batch 03056/03692] [00:27:06/00:05:38, 0.532s/it]: train_loss_raw=1.3570, running_loss=1.2685, LR=0.000100
[2025-08-10 16:00:08,413][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032604] [Batch 03068/03692] [00:27:12/00:05:32, 0.532s/it]: train_loss_raw=1.2666, running_loss=1.2691, LR=0.000100
[2025-08-10 16:00:14,755][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032616] [Batch 03080/03692] [00:27:18/00:05:25, 0.532s/it]: train_loss_raw=1.4035, running_loss=1.2714, LR=0.000100
[2025-08-10 16:00:20,924][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032628] [Batch 03092/03692] [00:27:25/00:05:19, 0.532s/it]: train_loss_raw=1.2412, running_loss=1.2694, LR=0.000100
[2025-08-10 16:00:26,973][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032640] [Batch 03104/03692] [00:27:31/00:05:12, 0.532s/it]: train_loss_raw=1.3370, running_loss=1.2684, LR=0.000100
[2025-08-10 16:00:33,071][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032652] [Batch 03116/03692] [00:27:37/00:05:06, 0.532s/it]: train_loss_raw=1.2531, running_loss=1.2662, LR=0.000100
[2025-08-10 16:00:39,265][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032664] [Batch 03128/03692] [00:27:43/00:04:59, 0.532s/it]: train_loss_raw=1.3497, running_loss=1.2678, LR=0.000100
[2025-08-10 16:00:45,409][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032676] [Batch 03140/03692] [00:27:49/00:04:53, 0.532s/it]: train_loss_raw=1.3570, running_loss=1.2700, LR=0.000100
[2025-08-10 16:00:51,545][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032688] [Batch 03152/03692] [00:27:55/00:04:47, 0.532s/it]: train_loss_raw=1.1473, running_loss=1.2673, LR=0.000100
[2025-08-10 16:00:57,815][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032700] [Batch 03164/03692] [00:28:01/00:04:40, 0.532s/it]: train_loss_raw=1.2617, running_loss=1.2673, LR=0.000100
[2025-08-10 16:01:03,946][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032712] [Batch 03176/03692] [00:28:08/00:04:34, 0.532s/it]: train_loss_raw=1.2959, running_loss=1.2629, LR=0.000100
[2025-08-10 16:01:10,010][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032724] [Batch 03188/03692] [00:28:14/00:04:27, 0.531s/it]: train_loss_raw=1.2893, running_loss=1.2654, LR=0.000100
[2025-08-10 16:01:16,109][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032736] [Batch 03200/03692] [00:28:20/00:04:21, 0.531s/it]: train_loss_raw=1.2911, running_loss=1.2641, LR=0.000100
[2025-08-10 16:01:22,132][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032748] [Batch 03212/03692] [00:28:26/00:04:14, 0.531s/it]: train_loss_raw=1.2999, running_loss=1.2696, LR=0.000100
[2025-08-10 16:01:28,255][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032760] [Batch 03224/03692] [00:28:32/00:04:08, 0.531s/it]: train_loss_raw=1.2110, running_loss=1.2647, LR=0.000100
[2025-08-10 16:01:34,284][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032772] [Batch 03236/03692] [00:28:38/00:04:02, 0.531s/it]: train_loss_raw=1.1634, running_loss=1.2623, LR=0.000100
[2025-08-10 16:01:40,455][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032784] [Batch 03248/03692] [00:28:44/00:03:55, 0.531s/it]: train_loss_raw=1.2771, running_loss=1.2583, LR=0.000100
[2025-08-10 16:01:46,719][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032796] [Batch 03260/03692] [00:28:50/00:03:49, 0.531s/it]: train_loss_raw=1.1983, running_loss=1.2538, LR=0.000100
[2025-08-10 16:01:52,831][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032808] [Batch 03272/03692] [00:28:57/00:03:42, 0.531s/it]: train_loss_raw=1.2187, running_loss=1.2551, LR=0.000100
[2025-08-10 16:01:58,873][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032820] [Batch 03284/03692] [00:29:03/00:03:36, 0.531s/it]: train_loss_raw=1.1455, running_loss=1.2592, LR=0.000100
[2025-08-10 16:02:05,406][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032832] [Batch 03296/03692] [00:29:09/00:03:30, 0.531s/it]: train_loss_raw=1.2770, running_loss=1.2593, LR=0.000100
[2025-08-10 16:02:12,060][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032844] [Batch 03308/03692] [00:29:16/00:03:23, 0.531s/it]: train_loss_raw=1.2875, running_loss=1.2576, LR=0.000100
[2025-08-10 16:02:18,569][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032856] [Batch 03320/03692] [00:29:22/00:03:17, 0.531s/it]: train_loss_raw=1.3934, running_loss=1.2561, LR=0.000100
[2025-08-10 16:02:25,119][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032868] [Batch 03332/03692] [00:29:29/00:03:11, 0.531s/it]: train_loss_raw=1.2545, running_loss=1.2558, LR=0.000100
[2025-08-10 16:02:31,528][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032880] [Batch 03344/03692] [00:29:35/00:03:04, 0.531s/it]: train_loss_raw=1.3182, running_loss=1.2571, LR=0.000100
[2025-08-10 16:02:37,751][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032892] [Batch 03356/03692] [00:29:41/00:02:58, 0.531s/it]: train_loss_raw=1.1342, running_loss=1.2591, LR=0.000100
[2025-08-10 16:02:43,886][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032904] [Batch 03368/03692] [00:29:48/00:02:52, 0.531s/it]: train_loss_raw=1.3411, running_loss=1.2574, LR=0.000100
[2025-08-10 16:02:49,986][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032916] [Batch 03380/03692] [00:29:54/00:02:45, 0.531s/it]: train_loss_raw=1.1997, running_loss=1.2586, LR=0.000100
[2025-08-10 16:02:56,061][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032928] [Batch 03392/03692] [00:30:00/00:02:39, 0.531s/it]: train_loss_raw=1.0800, running_loss=1.2594, LR=0.000100
[2025-08-10 16:03:02,164][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032940] [Batch 03404/03692] [00:30:06/00:02:32, 0.531s/it]: train_loss_raw=1.3323, running_loss=1.2600, LR=0.000100
[2025-08-10 16:03:08,190][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032952] [Batch 03416/03692] [00:30:12/00:02:26, 0.531s/it]: train_loss_raw=1.3265, running_loss=1.2592, LR=0.000100
[2025-08-10 16:03:14,190][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032964] [Batch 03428/03692] [00:30:18/00:02:20, 0.530s/it]: train_loss_raw=1.2606, running_loss=1.2603, LR=0.000100
[2025-08-10 16:03:20,251][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032976] [Batch 03440/03692] [00:30:24/00:02:13, 0.530s/it]: train_loss_raw=1.3177, running_loss=1.2599, LR=0.000100
[2025-08-10 16:03:26,297][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 032988] [Batch 03452/03692] [00:30:30/00:02:07, 0.530s/it]: train_loss_raw=1.2450, running_loss=1.2617, LR=0.000100
[2025-08-10 16:03:32,511][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033000] [Batch 03464/03692] [00:30:36/00:02:00, 0.530s/it]: train_loss_raw=1.2296, running_loss=1.2600, LR=0.000100
[2025-08-10 16:03:38,593][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033012] [Batch 03476/03692] [00:30:42/00:01:54, 0.530s/it]: train_loss_raw=1.3351, running_loss=1.2608, LR=0.000100
[2025-08-10 16:03:44,704][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033024] [Batch 03488/03692] [00:30:48/00:01:48, 0.530s/it]: train_loss_raw=1.2503, running_loss=1.2574, LR=0.000100
[2025-08-10 16:03:50,776][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033036] [Batch 03500/03692] [00:30:54/00:01:41, 0.530s/it]: train_loss_raw=1.2151, running_loss=1.2564, LR=0.000100
[2025-08-10 16:03:56,874][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033048] [Batch 03512/03692] [00:31:01/00:01:35, 0.530s/it]: train_loss_raw=1.2952, running_loss=1.2602, LR=0.000100
[2025-08-10 16:04:03,246][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033060] [Batch 03524/03692] [00:31:07/00:01:29, 0.530s/it]: train_loss_raw=1.3142, running_loss=1.2596, LR=0.000100
[2025-08-10 16:04:09,787][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033072] [Batch 03536/03692] [00:31:13/00:01:22, 0.530s/it]: train_loss_raw=1.3088, running_loss=1.2588, LR=0.000100
[2025-08-10 16:04:16,436][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033084] [Batch 03548/03692] [00:31:20/00:01:16, 0.530s/it]: train_loss_raw=1.1414, running_loss=1.2598, LR=0.000100
[2025-08-10 16:04:22,764][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033096] [Batch 03560/03692] [00:31:26/00:01:09, 0.530s/it]: train_loss_raw=1.1245, running_loss=1.2609, LR=0.000100
[2025-08-10 16:04:29,270][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033108] [Batch 03572/03692] [00:31:33/00:01:03, 0.530s/it]: train_loss_raw=1.3037, running_loss=1.2605, LR=0.000100
[2025-08-10 16:04:35,861][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033120] [Batch 03584/03692] [00:31:40/00:00:57, 0.530s/it]: train_loss_raw=1.2941, running_loss=1.2580, LR=0.000100
[2025-08-10 16:04:42,523][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033132] [Batch 03596/03692] [00:31:46/00:00:50, 0.530s/it]: train_loss_raw=1.1332, running_loss=1.2590, LR=0.000100
[2025-08-10 16:04:48,811][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033144] [Batch 03608/03692] [00:31:52/00:00:44, 0.530s/it]: train_loss_raw=1.0998, running_loss=1.2592, LR=0.000100
[2025-08-10 16:04:54,934][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033156] [Batch 03620/03692] [00:31:59/00:00:38, 0.530s/it]: train_loss_raw=1.1946, running_loss=1.2585, LR=0.000100
[2025-08-10 16:05:01,255][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033168] [Batch 03632/03692] [00:32:05/00:00:31, 0.530s/it]: train_loss_raw=1.4977, running_loss=1.2612, LR=0.000100
[2025-08-10 16:05:07,502][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033180] [Batch 03644/03692] [00:32:11/00:00:25, 0.530s/it]: train_loss_raw=1.1215, running_loss=1.2543, LR=0.000100
[2025-08-10 16:05:13,738][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033192] [Batch 03656/03692] [00:32:17/00:00:19, 0.530s/it]: train_loss_raw=1.2283, running_loss=1.2534, LR=0.000100
[2025-08-10 16:05:19,792][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033204] [Batch 03668/03692] [00:32:23/00:00:12, 0.530s/it]: train_loss_raw=1.1942, running_loss=1.2513, LR=0.000100
[2025-08-10 16:05:26,138][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033216] [Batch 03680/03692] [00:32:30/00:00:06, 0.530s/it]: train_loss_raw=1.3082, running_loss=1.2530, LR=0.000100
[2025-08-10 16:05:32,668][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 033228] [Batch 03692/03692] [00:32:36/00:00:00, 0.530s/it]: train_loss_raw=1.2013, running_loss=1.2521, LR=0.000100
[2025-08-10 16:05:37,694][__main__][INFO] - [VALIDATION] [Epoch 08/29] Starting validation.
[2025-08-10 16:06:11,357][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 033229] [Batch 00011/00025] [00:00:33/00:00:36, 2.805s/it]
[2025-08-10 16:06:28,532][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 033229] [Batch 00023/00025] [00:00:50/00:00:02, 2.118s/it]
[2025-08-10 16:06:29,615][__main__][INFO] - [VALIDATION] [Epoch 08/29] train_loss=1.25209, valid_loss=1.18430
[2025-08-10 16:06:29,615][__main__][INFO] - [VALIDATION] [Epoch 08/29] Metrics:
[2025-08-10 16:06:29,615][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_er      0.512
[2025-08-10 16:06:29,615][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_prec    0.211
[2025-08-10 16:06:29,615][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_recall  0.216
[2025-08-10 16:06:29,615][__main__][INFO] - [VALIDATION] [Epoch 08/29] - pep_recall 0.175
[2025-08-10 16:06:29,618][__main__][INFO] - [TRAIN] [Epoch 08/29] Epoch complete, total time 05:10:28, remaining time 12:04:27, 00:34:29 per epoch
[2025-08-10 16:06:36,391][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033240] [Batch 00012/03692] [00:00:05/00:29:17, 0.478s/it]: train_loss_raw=1.2375, running_loss=1.2472, LR=0.000100
[2025-08-10 16:06:42,433][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033252] [Batch 00024/03692] [00:00:11/00:29:59, 0.491s/it]: train_loss_raw=1.2081, running_loss=1.2483, LR=0.000100
[2025-08-10 16:06:48,469][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033264] [Batch 00036/03692] [00:00:17/00:30:08, 0.495s/it]: train_loss_raw=1.2572, running_loss=1.2496, LR=0.000100
[2025-08-10 16:06:54,548][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033276] [Batch 00048/03692] [00:00:23/00:30:13, 0.498s/it]: train_loss_raw=1.2514, running_loss=1.2528, LR=0.000100
[2025-08-10 16:07:00,563][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033288] [Batch 00060/03692] [00:00:29/00:30:10, 0.498s/it]: train_loss_raw=1.2437, running_loss=1.2546, LR=0.000100
[2025-08-10 16:07:06,761][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033300] [Batch 00072/03692] [00:00:36/00:30:15, 0.501s/it]: train_loss_raw=1.3223, running_loss=1.2586, LR=0.000100
[2025-08-10 16:07:13,351][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033312] [Batch 00084/03692] [00:00:42/00:30:33, 0.508s/it]: train_loss_raw=1.1627, running_loss=1.2585, LR=0.000100
[2025-08-10 16:07:19,997][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033324] [Batch 00096/03692] [00:00:49/00:30:48, 0.514s/it]: train_loss_raw=1.1870, running_loss=1.2594, LR=0.000100
[2025-08-10 16:07:26,385][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033336] [Batch 00108/03692] [00:00:55/00:30:49, 0.516s/it]: train_loss_raw=1.0078, running_loss=1.2541, LR=0.000100
[2025-08-10 16:07:32,489][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033348] [Batch 00120/03692] [00:01:01/00:30:40, 0.515s/it]: train_loss_raw=1.3228, running_loss=1.2539, LR=0.000100
[2025-08-10 16:07:38,582][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033360] [Batch 00132/03692] [00:01:07/00:30:31, 0.515s/it]: train_loss_raw=1.2886, running_loss=1.2529, LR=0.000100
[2025-08-10 16:07:44,656][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033372] [Batch 00144/03692] [00:01:13/00:30:23, 0.514s/it]: train_loss_raw=1.1842, running_loss=1.2505, LR=0.000100
[2025-08-10 16:07:50,738][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033384] [Batch 00156/03692] [00:01:20/00:30:15, 0.513s/it]: train_loss_raw=1.1947, running_loss=1.2493, LR=0.000100
[2025-08-10 16:07:56,713][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033396] [Batch 00168/03692] [00:01:26/00:30:05, 0.512s/it]: train_loss_raw=1.3019, running_loss=1.2510, LR=0.000100
[2025-08-10 16:08:03,022][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033408] [Batch 00180/03692] [00:01:32/00:30:02, 0.513s/it]: train_loss_raw=1.2111, running_loss=1.2529, LR=0.000100
[2025-08-10 16:08:09,352][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033420] [Batch 00192/03692] [00:01:38/00:29:59, 0.514s/it]: train_loss_raw=1.2624, running_loss=1.2498, LR=0.000100
[2025-08-10 16:08:15,644][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033432] [Batch 00204/03692] [00:01:44/00:29:55, 0.515s/it]: train_loss_raw=1.2165, running_loss=1.2523, LR=0.000100
[2025-08-10 16:08:22,247][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033444] [Batch 00216/03692] [00:01:51/00:29:55, 0.517s/it]: train_loss_raw=1.3402, running_loss=1.2539, LR=0.000100
[2025-08-10 16:08:28,643][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033456] [Batch 00228/03692] [00:01:57/00:29:52, 0.517s/it]: train_loss_raw=1.2702, running_loss=1.2557, LR=0.000100
[2025-08-10 16:08:35,201][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033468] [Batch 00240/03692] [00:02:04/00:29:51, 0.519s/it]: train_loss_raw=1.4278, running_loss=1.2553, LR=0.000100
[2025-08-10 16:08:41,391][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033480] [Batch 00252/03692] [00:02:10/00:29:44, 0.519s/it]: train_loss_raw=1.1053, running_loss=1.2523, LR=0.000100
[2025-08-10 16:08:47,446][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033492] [Batch 00264/03692] [00:02:16/00:29:36, 0.518s/it]: train_loss_raw=1.2774, running_loss=1.2535, LR=0.000100
[2025-08-10 16:08:53,831][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033504] [Batch 00276/03692] [00:02:23/00:29:32, 0.519s/it]: train_loss_raw=1.2023, running_loss=1.2538, LR=0.000100
[2025-08-10 16:09:00,337][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033516] [Batch 00288/03692] [00:02:29/00:29:29, 0.520s/it]: train_loss_raw=1.1140, running_loss=1.2543, LR=0.000100
[2025-08-10 16:09:06,868][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033528] [Batch 00300/03692] [00:02:36/00:29:26, 0.521s/it]: train_loss_raw=1.3475, running_loss=1.2544, LR=0.000100
[2025-08-10 16:09:13,158][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033540] [Batch 00312/03692] [00:02:42/00:29:20, 0.521s/it]: train_loss_raw=1.2703, running_loss=1.2549, LR=0.000100
[2025-08-10 16:09:19,311][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033552] [Batch 00324/03692] [00:02:48/00:29:13, 0.521s/it]: train_loss_raw=1.2954, running_loss=1.2516, LR=0.000100
[2025-08-10 16:09:25,402][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033564] [Batch 00336/03692] [00:02:54/00:29:05, 0.520s/it]: train_loss_raw=1.1923, running_loss=1.2490, LR=0.000100
[2025-08-10 16:09:31,540][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033576] [Batch 00348/03692] [00:03:00/00:28:58, 0.520s/it]: train_loss_raw=1.2464, running_loss=1.2504, LR=0.000100
[2025-08-10 16:09:37,727][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033588] [Batch 00360/03692] [00:03:07/00:28:51, 0.520s/it]: train_loss_raw=1.2299, running_loss=1.2472, LR=0.000100
[2025-08-10 16:09:43,779][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033600] [Batch 00372/03692] [00:03:13/00:28:43, 0.519s/it]: train_loss_raw=1.2007, running_loss=1.2453, LR=0.000100
[2025-08-10 16:09:49,854][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033612] [Batch 00384/03692] [00:03:19/00:28:35, 0.519s/it]: train_loss_raw=1.2670, running_loss=1.2422, LR=0.000100
[2025-08-10 16:09:55,928][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033624] [Batch 00396/03692] [00:03:25/00:28:28, 0.518s/it]: train_loss_raw=1.4189, running_loss=1.2462, LR=0.000100
[2025-08-10 16:10:02,016][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033636] [Batch 00408/03692] [00:03:31/00:28:21, 0.518s/it]: train_loss_raw=1.2300, running_loss=1.2440, LR=0.000100
[2025-08-10 16:10:08,106][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033648] [Batch 00420/03692] [00:03:37/00:28:14, 0.518s/it]: train_loss_raw=1.2818, running_loss=1.2419, LR=0.000100
[2025-08-10 16:10:14,185][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033660] [Batch 00432/03692] [00:03:43/00:28:06, 0.517s/it]: train_loss_raw=1.1881, running_loss=1.2416, LR=0.000100
[2025-08-10 16:10:20,279][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033672] [Batch 00444/03692] [00:03:49/00:27:59, 0.517s/it]: train_loss_raw=1.0897, running_loss=1.2420, LR=0.000100
[2025-08-10 16:10:26,399][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033684] [Batch 00456/03692] [00:03:55/00:27:52, 0.517s/it]: train_loss_raw=1.3977, running_loss=1.2442, LR=0.000100
[2025-08-10 16:10:32,675][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033696] [Batch 00468/03692] [00:04:02/00:27:47, 0.517s/it]: train_loss_raw=1.1742, running_loss=1.2435, LR=0.000100
[2025-08-10 16:10:38,845][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033708] [Batch 00480/03692] [00:04:08/00:27:40, 0.517s/it]: train_loss_raw=1.2857, running_loss=1.2453, LR=0.000100
[2025-08-10 16:10:45,119][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033720] [Batch 00492/03692] [00:04:14/00:27:35, 0.517s/it]: train_loss_raw=1.4231, running_loss=1.2469, LR=0.000100
[2025-08-10 16:10:51,208][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033732] [Batch 00504/03692] [00:04:20/00:27:28, 0.517s/it]: train_loss_raw=1.3425, running_loss=1.2444, LR=0.000100
[2025-08-10 16:10:57,514][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033744] [Batch 00516/03692] [00:04:26/00:27:22, 0.517s/it]: train_loss_raw=1.2154, running_loss=1.2421, LR=0.000100
[2025-08-10 16:11:03,812][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033756] [Batch 00528/03692] [00:04:33/00:27:16, 0.517s/it]: train_loss_raw=1.3271, running_loss=1.2423, LR=0.000100
[2025-08-10 16:11:09,855][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033768] [Batch 00540/03692] [00:04:39/00:27:09, 0.517s/it]: train_loss_raw=1.2863, running_loss=1.2395, LR=0.000100
[2025-08-10 16:11:16,062][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033780] [Batch 00552/03692] [00:04:45/00:27:03, 0.517s/it]: train_loss_raw=1.1928, running_loss=1.2388, LR=0.000100
[2025-08-10 16:11:22,135][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033792] [Batch 00564/03692] [00:04:51/00:26:56, 0.517s/it]: train_loss_raw=1.3368, running_loss=1.2418, LR=0.000100
[2025-08-10 16:11:28,182][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033804] [Batch 00576/03692] [00:04:57/00:26:49, 0.517s/it]: train_loss_raw=1.2388, running_loss=1.2451, LR=0.000100
[2025-08-10 16:11:34,347][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033816] [Batch 00588/03692] [00:05:03/00:26:43, 0.516s/it]: train_loss_raw=1.1003, running_loss=1.2472, LR=0.000100
[2025-08-10 16:11:40,481][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033828] [Batch 00600/03692] [00:05:09/00:26:36, 0.516s/it]: train_loss_raw=1.2543, running_loss=1.2488, LR=0.000100
[2025-08-10 16:11:46,574][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033840] [Batch 00612/03692] [00:05:15/00:26:29, 0.516s/it]: train_loss_raw=1.2443, running_loss=1.2506, LR=0.000100
[2025-08-10 16:11:52,583][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033852] [Batch 00624/03692] [00:05:21/00:26:22, 0.516s/it]: train_loss_raw=1.1910, running_loss=1.2433, LR=0.000100
[2025-08-10 16:11:58,591][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033864] [Batch 00636/03692] [00:05:27/00:26:15, 0.516s/it]: train_loss_raw=1.2945, running_loss=1.2434, LR=0.000100
[2025-08-10 16:12:04,785][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033876] [Batch 00648/03692] [00:05:34/00:26:09, 0.516s/it]: train_loss_raw=1.3402, running_loss=1.2437, LR=0.000100
[2025-08-10 16:12:10,907][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033888] [Batch 00660/03692] [00:05:40/00:26:03, 0.516s/it]: train_loss_raw=1.2290, running_loss=1.2465, LR=0.000100
[2025-08-10 16:12:17,396][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033900] [Batch 00672/03692] [00:05:46/00:25:58, 0.516s/it]: train_loss_raw=1.1678, running_loss=1.2437, LR=0.000100
[2025-08-10 16:12:24,028][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033912] [Batch 00684/03692] [00:05:53/00:25:53, 0.517s/it]: train_loss_raw=1.1527, running_loss=1.2469, LR=0.000100
[2025-08-10 16:12:30,636][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033924] [Batch 00696/03692] [00:05:59/00:25:49, 0.517s/it]: train_loss_raw=1.3197, running_loss=1.2495, LR=0.000100
[2025-08-10 16:12:36,799][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033936] [Batch 00708/03692] [00:06:06/00:25:43, 0.517s/it]: train_loss_raw=1.3265, running_loss=1.2524, LR=0.000100
[2025-08-10 16:12:43,084][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033948] [Batch 00720/03692] [00:06:12/00:25:37, 0.517s/it]: train_loss_raw=1.3048, running_loss=1.2523, LR=0.000100
[2025-08-10 16:12:49,400][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033960] [Batch 00732/03692] [00:06:18/00:25:31, 0.517s/it]: train_loss_raw=1.2737, running_loss=1.2480, LR=0.000100
[2025-08-10 16:12:55,989][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033972] [Batch 00744/03692] [00:06:25/00:25:26, 0.518s/it]: train_loss_raw=1.3312, running_loss=1.2450, LR=0.000100
[2025-08-10 16:13:02,509][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033984] [Batch 00756/03692] [00:06:31/00:25:21, 0.518s/it]: train_loss_raw=1.1279, running_loss=1.2437, LR=0.000100
[2025-08-10 16:13:09,191][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 033996] [Batch 00768/03692] [00:06:38/00:25:17, 0.519s/it]: train_loss_raw=1.2225, running_loss=1.2424, LR=0.000100
[2025-08-10 16:13:21,270][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034008] [Batch 00780/03692] [00:06:50/00:25:32, 0.526s/it]: train_loss_raw=1.3191, running_loss=1.2452, LR=0.000100
[2025-08-10 16:13:27,870][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034020] [Batch 00792/03692] [00:06:57/00:25:27, 0.527s/it]: train_loss_raw=1.2009, running_loss=1.2440, LR=0.000100
[2025-08-10 16:13:34,464][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034032] [Batch 00804/03692] [00:07:03/00:25:22, 0.527s/it]: train_loss_raw=1.2676, running_loss=1.2448, LR=0.000100
[2025-08-10 16:13:41,031][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034044] [Batch 00816/03692] [00:07:10/00:25:16, 0.527s/it]: train_loss_raw=1.2086, running_loss=1.2417, LR=0.000100
[2025-08-10 16:13:47,522][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034056] [Batch 00828/03692] [00:07:16/00:25:11, 0.528s/it]: train_loss_raw=1.4230, running_loss=1.2426, LR=0.000100
[2025-08-10 16:13:54,100][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034068] [Batch 00840/03692] [00:07:23/00:25:05, 0.528s/it]: train_loss_raw=1.0989, running_loss=1.2418, LR=0.000100
[2025-08-10 16:14:00,600][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034080] [Batch 00852/03692] [00:07:29/00:24:59, 0.528s/it]: train_loss_raw=1.1159, running_loss=1.2419, LR=0.000100
[2025-08-10 16:14:07,109][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034092] [Batch 00864/03692] [00:07:36/00:24:54, 0.528s/it]: train_loss_raw=1.3711, running_loss=1.2409, LR=0.000100
[2025-08-10 16:14:13,657][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034104] [Batch 00876/03692] [00:07:42/00:24:48, 0.529s/it]: train_loss_raw=1.2874, running_loss=1.2461, LR=0.000100
[2025-08-10 16:14:20,028][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034116] [Batch 00888/03692] [00:07:49/00:24:42, 0.529s/it]: train_loss_raw=1.2243, running_loss=1.2432, LR=0.000100
[2025-08-10 16:14:26,067][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034128] [Batch 00900/03692] [00:07:55/00:24:34, 0.528s/it]: train_loss_raw=1.2191, running_loss=1.2405, LR=0.000100
[2025-08-10 16:14:32,254][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034140] [Batch 00912/03692] [00:08:01/00:24:28, 0.528s/it]: train_loss_raw=1.1496, running_loss=1.2399, LR=0.000100
[2025-08-10 16:14:38,473][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034152] [Batch 00924/03692] [00:08:07/00:24:21, 0.528s/it]: train_loss_raw=1.1072, running_loss=1.2381, LR=0.000100
[2025-08-10 16:14:44,550][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034164] [Batch 00936/03692] [00:08:13/00:24:14, 0.528s/it]: train_loss_raw=1.2176, running_loss=1.2403, LR=0.000100
[2025-08-10 16:14:50,745][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034176] [Batch 00948/03692] [00:08:20/00:24:07, 0.528s/it]: train_loss_raw=1.2230, running_loss=1.2388, LR=0.000100
[2025-08-10 16:14:56,840][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034188] [Batch 00960/03692] [00:08:26/00:24:00, 0.527s/it]: train_loss_raw=1.2018, running_loss=1.2427, LR=0.000100
[2025-08-10 16:15:02,846][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034200] [Batch 00972/03692] [00:08:32/00:23:53, 0.527s/it]: train_loss_raw=1.1725, running_loss=1.2432, LR=0.000100
[2025-08-10 16:15:08,961][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034212] [Batch 00984/03692] [00:08:38/00:23:46, 0.527s/it]: train_loss_raw=1.3915, running_loss=1.2416, LR=0.000100
[2025-08-10 16:15:14,999][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034224] [Batch 00996/03692] [00:08:44/00:23:39, 0.526s/it]: train_loss_raw=1.3306, running_loss=1.2427, LR=0.000100
[2025-08-10 16:15:21,201][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034236] [Batch 01008/03692] [00:08:50/00:23:32, 0.526s/it]: train_loss_raw=1.2984, running_loss=1.2432, LR=0.000100
[2025-08-10 16:15:27,373][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034248] [Batch 01020/03692] [00:08:56/00:23:25, 0.526s/it]: train_loss_raw=1.3536, running_loss=1.2443, LR=0.000100
[2025-08-10 16:15:33,657][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034260] [Batch 01032/03692] [00:09:02/00:23:19, 0.526s/it]: train_loss_raw=1.3175, running_loss=1.2459, LR=0.000100
[2025-08-10 16:15:40,245][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034272] [Batch 01044/03692] [00:09:09/00:23:13, 0.526s/it]: train_loss_raw=1.2520, running_loss=1.2465, LR=0.000100
[2025-08-10 16:15:46,704][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034284] [Batch 01056/03692] [00:09:16/00:23:08, 0.527s/it]: train_loss_raw=1.1403, running_loss=1.2474, LR=0.000100
[2025-08-10 16:15:53,313][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034296] [Batch 01068/03692] [00:09:22/00:23:02, 0.527s/it]: train_loss_raw=1.1720, running_loss=1.2430, LR=0.000100
[2025-08-10 16:15:59,803][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034308] [Batch 01080/03692] [00:09:29/00:22:56, 0.527s/it]: train_loss_raw=1.1428, running_loss=1.2433, LR=0.000100
[2025-08-10 16:16:06,411][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034320] [Batch 01092/03692] [00:09:35/00:22:50, 0.527s/it]: train_loss_raw=1.3690, running_loss=1.2453, LR=0.000100
[2025-08-10 16:16:12,988][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034332] [Batch 01104/03692] [00:09:42/00:22:45, 0.527s/it]: train_loss_raw=1.2541, running_loss=1.2427, LR=0.000100
[2025-08-10 16:16:19,554][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034344] [Batch 01116/03692] [00:09:48/00:22:39, 0.528s/it]: train_loss_raw=1.1572, running_loss=1.2459, LR=0.000100
[2025-08-10 16:16:25,582][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034356] [Batch 01128/03692] [00:09:54/00:22:32, 0.527s/it]: train_loss_raw=1.1764, running_loss=1.2462, LR=0.000100
[2025-08-10 16:16:31,636][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034368] [Batch 01140/03692] [00:10:00/00:22:25, 0.527s/it]: train_loss_raw=1.1480, running_loss=1.2451, LR=0.000100
[2025-08-10 16:16:37,731][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034380] [Batch 01152/03692] [00:10:07/00:22:18, 0.527s/it]: train_loss_raw=1.1973, running_loss=1.2469, LR=0.000100
[2025-08-10 16:16:43,776][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034392] [Batch 01164/03692] [00:10:13/00:22:11, 0.527s/it]: train_loss_raw=1.0389, running_loss=1.2440, LR=0.000100
[2025-08-10 16:16:49,936][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034404] [Batch 01176/03692] [00:10:19/00:22:04, 0.527s/it]: train_loss_raw=1.3790, running_loss=1.2400, LR=0.000100
[2025-08-10 16:16:56,032][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034416] [Batch 01188/03692] [00:10:25/00:21:58, 0.526s/it]: train_loss_raw=1.1895, running_loss=1.2414, LR=0.000100
[2025-08-10 16:17:02,317][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034428] [Batch 01200/03692] [00:10:31/00:21:51, 0.526s/it]: train_loss_raw=1.1733, running_loss=1.2435, LR=0.000100
[2025-08-10 16:17:08,435][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034440] [Batch 01212/03692] [00:10:37/00:21:45, 0.526s/it]: train_loss_raw=1.2199, running_loss=1.2404, LR=0.000100
[2025-08-10 16:17:14,602][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034452] [Batch 01224/03692] [00:10:43/00:21:38, 0.526s/it]: train_loss_raw=1.2383, running_loss=1.2413, LR=0.000100
[2025-08-10 16:17:20,747][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034464] [Batch 01236/03692] [00:10:50/00:21:31, 0.526s/it]: train_loss_raw=1.2907, running_loss=1.2439, LR=0.000100
[2025-08-10 16:17:26,857][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034476] [Batch 01248/03692] [00:10:56/00:21:25, 0.526s/it]: train_loss_raw=1.2783, running_loss=1.2436, LR=0.000100
[2025-08-10 16:17:33,092][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034488] [Batch 01260/03692] [00:11:02/00:21:18, 0.526s/it]: train_loss_raw=1.4093, running_loss=1.2441, LR=0.000100
[2025-08-10 16:17:39,219][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034500] [Batch 01272/03692] [00:11:08/00:21:11, 0.526s/it]: train_loss_raw=1.2332, running_loss=1.2455, LR=0.000100
[2025-08-10 16:17:45,306][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034512] [Batch 01284/03692] [00:11:14/00:21:05, 0.525s/it]: train_loss_raw=1.2236, running_loss=1.2419, LR=0.000100
[2025-08-10 16:17:51,428][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034524] [Batch 01296/03692] [00:11:20/00:20:58, 0.525s/it]: train_loss_raw=1.3088, running_loss=1.2447, LR=0.000100
[2025-08-10 16:17:57,678][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034536] [Batch 01308/03692] [00:11:27/00:20:52, 0.525s/it]: train_loss_raw=1.1883, running_loss=1.2439, LR=0.000100
[2025-08-10 16:18:03,770][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034548] [Batch 01320/03692] [00:11:33/00:20:45, 0.525s/it]: train_loss_raw=1.2197, running_loss=1.2451, LR=0.000100
[2025-08-10 16:18:10,018][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034560] [Batch 01332/03692] [00:11:39/00:20:39, 0.525s/it]: train_loss_raw=1.3260, running_loss=1.2434, LR=0.000100
[2025-08-10 16:18:16,222][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034572] [Batch 01344/03692] [00:11:45/00:20:32, 0.525s/it]: train_loss_raw=1.2410, running_loss=1.2419, LR=0.000100
[2025-08-10 16:18:22,407][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034584] [Batch 01356/03692] [00:11:51/00:20:26, 0.525s/it]: train_loss_raw=1.2948, running_loss=1.2437, LR=0.000100
[2025-08-10 16:18:28,762][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034596] [Batch 01368/03692] [00:11:58/00:20:19, 0.525s/it]: train_loss_raw=1.1561, running_loss=1.2440, LR=0.000100
[2025-08-10 16:18:35,156][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034608] [Batch 01380/03692] [00:12:04/00:20:13, 0.525s/it]: train_loss_raw=1.2201, running_loss=1.2487, LR=0.000100
[2025-08-10 16:18:41,226][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034620] [Batch 01392/03692] [00:12:10/00:20:07, 0.525s/it]: train_loss_raw=1.2628, running_loss=1.2452, LR=0.000100
[2025-08-10 16:18:47,335][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034632] [Batch 01404/03692] [00:12:16/00:20:00, 0.525s/it]: train_loss_raw=1.2683, running_loss=1.2447, LR=0.000100
[2025-08-10 16:18:53,405][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034644] [Batch 01416/03692] [00:12:22/00:19:53, 0.525s/it]: train_loss_raw=1.2295, running_loss=1.2415, LR=0.000100
[2025-08-10 16:18:59,916][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034656] [Batch 01428/03692] [00:12:29/00:19:47, 0.525s/it]: train_loss_raw=1.2856, running_loss=1.2395, LR=0.000100
[2025-08-10 16:19:06,425][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034668] [Batch 01440/03692] [00:12:35/00:19:41, 0.525s/it]: train_loss_raw=1.1293, running_loss=1.2403, LR=0.000100
[2025-08-10 16:19:12,920][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034680] [Batch 01452/03692] [00:12:42/00:19:35, 0.525s/it]: train_loss_raw=1.1921, running_loss=1.2386, LR=0.000100
[2025-08-10 16:19:19,527][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034692] [Batch 01464/03692] [00:12:48/00:19:30, 0.525s/it]: train_loss_raw=1.1747, running_loss=1.2364, LR=0.000100
[2025-08-10 16:19:26,102][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034704] [Batch 01476/03692] [00:12:55/00:19:24, 0.525s/it]: train_loss_raw=1.2609, running_loss=1.2387, LR=0.000100
[2025-08-10 16:19:32,750][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034716] [Batch 01488/03692] [00:13:02/00:19:18, 0.526s/it]: train_loss_raw=1.2205, running_loss=1.2365, LR=0.000100
[2025-08-10 16:19:39,295][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034728] [Batch 01500/03692] [00:13:08/00:19:12, 0.526s/it]: train_loss_raw=1.2578, running_loss=1.2374, LR=0.000100
[2025-08-10 16:19:45,947][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034740] [Batch 01512/03692] [00:13:15/00:19:06, 0.526s/it]: train_loss_raw=1.2197, running_loss=1.2362, LR=0.000100
[2025-08-10 16:19:52,523][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034752] [Batch 01524/03692] [00:13:21/00:19:00, 0.526s/it]: train_loss_raw=1.2557, running_loss=1.2360, LR=0.000100
[2025-08-10 16:19:59,150][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034764] [Batch 01536/03692] [00:13:28/00:18:54, 0.526s/it]: train_loss_raw=1.1832, running_loss=1.2331, LR=0.000100
[2025-08-10 16:20:05,791][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034776] [Batch 01548/03692] [00:13:35/00:18:48, 0.527s/it]: train_loss_raw=1.2390, running_loss=1.2328, LR=0.000100
[2025-08-10 16:20:12,050][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034788] [Batch 01560/03692] [00:13:41/00:18:42, 0.527s/it]: train_loss_raw=1.1911, running_loss=1.2296, LR=0.000100
[2025-08-10 16:20:18,105][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034800] [Batch 01572/03692] [00:13:47/00:18:35, 0.526s/it]: train_loss_raw=1.3387, running_loss=1.2345, LR=0.000100
[2025-08-10 16:20:24,212][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034812] [Batch 01584/03692] [00:13:53/00:18:29, 0.526s/it]: train_loss_raw=1.1598, running_loss=1.2320, LR=0.000100
[2025-08-10 16:20:30,661][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034824] [Batch 01596/03692] [00:14:00/00:18:23, 0.526s/it]: train_loss_raw=1.1242, running_loss=1.2316, LR=0.000100
[2025-08-10 16:20:45,236][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034836] [Batch 01608/03692] [00:14:14/00:18:27, 0.531s/it]: train_loss_raw=1.2566, running_loss=1.2293, LR=0.000100
[2025-08-10 16:21:03,178][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034848] [Batch 01620/03692] [00:14:32/00:18:35, 0.539s/it]: train_loss_raw=1.3080, running_loss=1.2308, LR=0.000100
[2025-08-10 16:21:20,723][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034860] [Batch 01632/03692] [00:14:50/00:18:43, 0.545s/it]: train_loss_raw=1.0778, running_loss=1.2287, LR=0.000100
[2025-08-10 16:21:26,701][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034872] [Batch 01644/03692] [00:14:56/00:18:36, 0.545s/it]: train_loss_raw=1.2155, running_loss=1.2275, LR=0.000100
[2025-08-10 16:21:32,832][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034884] [Batch 01656/03692] [00:15:02/00:18:29, 0.545s/it]: train_loss_raw=1.0876, running_loss=1.2256, LR=0.000100
[2025-08-10 16:21:38,895][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034896] [Batch 01668/03692] [00:15:08/00:18:22, 0.545s/it]: train_loss_raw=1.2054, running_loss=1.2268, LR=0.000100
[2025-08-10 16:21:45,053][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034908] [Batch 01680/03692] [00:15:14/00:18:15, 0.544s/it]: train_loss_raw=1.2105, running_loss=1.2279, LR=0.000100
[2025-08-10 16:21:51,180][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034920] [Batch 01692/03692] [00:15:20/00:18:08, 0.544s/it]: train_loss_raw=1.2844, running_loss=1.2262, LR=0.000100
[2025-08-10 16:21:57,194][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034932] [Batch 01704/03692] [00:15:26/00:18:00, 0.544s/it]: train_loss_raw=1.2634, running_loss=1.2295, LR=0.000100
[2025-08-10 16:22:03,313][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034944] [Batch 01716/03692] [00:15:32/00:17:53, 0.544s/it]: train_loss_raw=1.1791, running_loss=1.2307, LR=0.000100
[2025-08-10 16:22:09,368][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034956] [Batch 01728/03692] [00:15:38/00:17:46, 0.543s/it]: train_loss_raw=1.1103, running_loss=1.2274, LR=0.000100
[2025-08-10 16:22:15,394][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034968] [Batch 01740/03692] [00:15:44/00:17:39, 0.543s/it]: train_loss_raw=1.2945, running_loss=1.2259, LR=0.000100
[2025-08-10 16:22:21,431][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034980] [Batch 01752/03692] [00:15:50/00:17:32, 0.543s/it]: train_loss_raw=1.2144, running_loss=1.2286, LR=0.000100
[2025-08-10 16:22:27,516][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 034992] [Batch 01764/03692] [00:15:56/00:17:25, 0.542s/it]: train_loss_raw=1.2440, running_loss=1.2289, LR=0.000100
[2025-08-10 16:22:33,660][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035004] [Batch 01776/03692] [00:16:03/00:17:18, 0.542s/it]: train_loss_raw=1.0839, running_loss=1.2307, LR=0.000100
[2025-08-10 16:22:39,878][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035016] [Batch 01788/03692] [00:16:09/00:17:12, 0.542s/it]: train_loss_raw=1.1937, running_loss=1.2300, LR=0.000100
[2025-08-10 16:22:46,482][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035028] [Batch 01800/03692] [00:16:15/00:17:05, 0.542s/it]: train_loss_raw=1.2741, running_loss=1.2301, LR=0.000100
[2025-08-10 16:22:53,176][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035040] [Batch 01812/03692] [00:16:22/00:16:59, 0.542s/it]: train_loss_raw=1.2543, running_loss=1.2275, LR=0.000100
[2025-08-10 16:22:59,675][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035052] [Batch 01824/03692] [00:16:29/00:16:52, 0.542s/it]: train_loss_raw=1.1300, running_loss=1.2264, LR=0.000100
[2025-08-10 16:23:06,288][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035064] [Batch 01836/03692] [00:16:35/00:16:46, 0.542s/it]: train_loss_raw=1.2514, running_loss=1.2280, LR=0.000100
[2025-08-10 16:23:12,881][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035076] [Batch 01848/03692] [00:16:42/00:16:40, 0.542s/it]: train_loss_raw=1.0651, running_loss=1.2258, LR=0.000100
[2025-08-10 16:23:19,193][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035088] [Batch 01860/03692] [00:16:48/00:16:33, 0.542s/it]: train_loss_raw=1.3351, running_loss=1.2240, LR=0.000100
[2025-08-10 16:23:25,572][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035100] [Batch 01872/03692] [00:16:54/00:16:26, 0.542s/it]: train_loss_raw=1.2506, running_loss=1.2223, LR=0.000100
[2025-08-10 16:23:32,117][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035112] [Batch 01884/03692] [00:17:01/00:16:20, 0.542s/it]: train_loss_raw=1.2522, running_loss=1.2199, LR=0.000100
[2025-08-10 16:23:40,332][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035124] [Batch 01896/03692] [00:17:09/00:16:15, 0.543s/it]: train_loss_raw=1.3093, running_loss=1.2190, LR=0.000100
[2025-08-10 16:23:49,859][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035136] [Batch 01908/03692] [00:17:19/00:16:11, 0.545s/it]: train_loss_raw=1.2719, running_loss=1.2196, LR=0.000100
[2025-08-10 16:23:56,561][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035148] [Batch 01920/03692] [00:17:25/00:16:05, 0.545s/it]: train_loss_raw=1.2440, running_loss=1.2234, LR=0.000100
[2025-08-10 16:24:03,242][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035160] [Batch 01932/03692] [00:17:32/00:15:58, 0.545s/it]: train_loss_raw=1.2913, running_loss=1.2229, LR=0.000100
[2025-08-10 16:24:09,953][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035172] [Batch 01944/03692] [00:17:39/00:15:52, 0.545s/it]: train_loss_raw=1.2183, running_loss=1.2247, LR=0.000100
[2025-08-10 16:24:16,781][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035184] [Batch 01956/03692] [00:17:46/00:15:46, 0.545s/it]: train_loss_raw=1.1087, running_loss=1.2257, LR=0.000100
[2025-08-10 16:24:23,824][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035196] [Batch 01968/03692] [00:17:53/00:15:40, 0.545s/it]: train_loss_raw=1.1614, running_loss=1.2274, LR=0.000100
[2025-08-10 16:24:30,603][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035208] [Batch 01980/03692] [00:17:59/00:15:33, 0.545s/it]: train_loss_raw=1.2001, running_loss=1.2247, LR=0.000100
[2025-08-10 16:24:37,221][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035220] [Batch 01992/03692] [00:18:06/00:15:27, 0.545s/it]: train_loss_raw=1.1886, running_loss=1.2286, LR=0.000100
[2025-08-10 16:24:43,823][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035232] [Batch 02004/03692] [00:18:13/00:15:20, 0.545s/it]: train_loss_raw=1.3482, running_loss=1.2286, LR=0.000100
[2025-08-10 16:24:50,401][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035244] [Batch 02016/03692] [00:18:19/00:15:14, 0.546s/it]: train_loss_raw=1.2177, running_loss=1.2302, LR=0.000100
[2025-08-10 16:24:56,866][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035256] [Batch 02028/03692] [00:18:26/00:15:07, 0.545s/it]: train_loss_raw=1.1424, running_loss=1.2320, LR=0.000100
[2025-08-10 16:25:03,006][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035268] [Batch 02040/03692] [00:18:32/00:15:00, 0.545s/it]: train_loss_raw=1.3364, running_loss=1.2331, LR=0.000100
[2025-08-10 16:25:09,076][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035280] [Batch 02052/03692] [00:18:38/00:14:53, 0.545s/it]: train_loss_raw=1.3078, running_loss=1.2296, LR=0.000100
[2025-08-10 16:25:15,143][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035292] [Batch 02064/03692] [00:18:44/00:14:46, 0.545s/it]: train_loss_raw=1.1929, running_loss=1.2307, LR=0.000100
[2025-08-10 16:25:21,211][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035304] [Batch 02076/03692] [00:18:50/00:14:40, 0.545s/it]: train_loss_raw=1.1722, running_loss=1.2321, LR=0.000100
[2025-08-10 16:25:27,204][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035316] [Batch 02088/03692] [00:18:56/00:14:33, 0.544s/it]: train_loss_raw=1.2907, running_loss=1.2375, LR=0.000100
[2025-08-10 16:25:33,278][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035328] [Batch 02100/03692] [00:19:02/00:14:26, 0.544s/it]: train_loss_raw=1.1475, running_loss=1.2404, LR=0.000100
[2025-08-10 16:25:39,311][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035340] [Batch 02112/03692] [00:19:08/00:14:19, 0.544s/it]: train_loss_raw=1.3235, running_loss=1.2394, LR=0.000100
[2025-08-10 16:25:45,576][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035352] [Batch 02124/03692] [00:19:14/00:14:12, 0.544s/it]: train_loss_raw=1.3283, running_loss=1.2396, LR=0.000100
[2025-08-10 16:25:52,082][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035364] [Batch 02136/03692] [00:19:21/00:14:06, 0.544s/it]: train_loss_raw=1.2041, running_loss=1.2354, LR=0.000100
[2025-08-10 16:25:58,571][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035376] [Batch 02148/03692] [00:19:27/00:13:59, 0.544s/it]: train_loss_raw=1.2781, running_loss=1.2343, LR=0.000100
[2025-08-10 16:26:17,762][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035388] [Batch 02160/03692] [00:19:47/00:14:01, 0.550s/it]: train_loss_raw=1.3243, running_loss=1.2306, LR=0.000100
[2025-08-10 16:26:23,770][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035400] [Batch 02172/03692] [00:19:53/00:13:54, 0.549s/it]: train_loss_raw=1.2441, running_loss=1.2327, LR=0.000100
[2025-08-10 16:26:29,866][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035412] [Batch 02184/03692] [00:19:59/00:13:48, 0.549s/it]: train_loss_raw=1.3582, running_loss=1.2344, LR=0.000100
[2025-08-10 16:26:35,934][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035424] [Batch 02196/03692] [00:20:05/00:13:41, 0.549s/it]: train_loss_raw=1.2481, running_loss=1.2304, LR=0.000100
[2025-08-10 16:26:41,977][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035436] [Batch 02208/03692] [00:20:11/00:13:34, 0.549s/it]: train_loss_raw=1.2046, running_loss=1.2338, LR=0.000100
[2025-08-10 16:26:47,984][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035448] [Batch 02220/03692] [00:20:17/00:13:27, 0.548s/it]: train_loss_raw=1.1224, running_loss=1.2311, LR=0.000100
[2025-08-10 16:26:54,280][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035460] [Batch 02232/03692] [00:20:23/00:13:20, 0.548s/it]: train_loss_raw=1.2824, running_loss=1.2306, LR=0.000100
[2025-08-10 16:27:00,552][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035472] [Batch 02244/03692] [00:20:29/00:13:13, 0.548s/it]: train_loss_raw=1.2307, running_loss=1.2301, LR=0.000100
[2025-08-10 16:27:06,881][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035484] [Batch 02256/03692] [00:20:36/00:13:06, 0.548s/it]: train_loss_raw=1.2943, running_loss=1.2299, LR=0.000100
[2025-08-10 16:27:13,016][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035496] [Batch 02268/03692] [00:20:42/00:13:00, 0.548s/it]: train_loss_raw=1.1362, running_loss=1.2316, LR=0.000100
[2025-08-10 16:27:19,175][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035508] [Batch 02280/03692] [00:20:48/00:12:53, 0.548s/it]: train_loss_raw=1.1461, running_loss=1.2289, LR=0.000100
[2025-08-10 16:27:25,370][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035520] [Batch 02292/03692] [00:20:54/00:12:46, 0.547s/it]: train_loss_raw=1.1525, running_loss=1.2281, LR=0.000100
[2025-08-10 16:27:31,504][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035532] [Batch 02304/03692] [00:21:00/00:12:39, 0.547s/it]: train_loss_raw=1.1429, running_loss=1.2284, LR=0.000100
[2025-08-10 16:27:37,669][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035544] [Batch 02316/03692] [00:21:07/00:12:32, 0.547s/it]: train_loss_raw=1.3003, running_loss=1.2340, LR=0.000100
[2025-08-10 16:27:44,130][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035556] [Batch 02328/03692] [00:21:13/00:12:26, 0.547s/it]: train_loss_raw=1.1600, running_loss=1.2345, LR=0.000100
[2025-08-10 16:27:50,668][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035568] [Batch 02340/03692] [00:21:20/00:12:19, 0.547s/it]: train_loss_raw=1.3297, running_loss=1.2345, LR=0.000100
[2025-08-10 16:27:56,996][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035580] [Batch 02352/03692] [00:21:26/00:12:12, 0.547s/it]: train_loss_raw=1.2286, running_loss=1.2329, LR=0.000100
[2025-08-10 16:28:03,424][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035592] [Batch 02364/03692] [00:21:32/00:12:06, 0.547s/it]: train_loss_raw=1.2423, running_loss=1.2323, LR=0.000100
[2025-08-10 16:28:09,579][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035604] [Batch 02376/03692] [00:21:38/00:11:59, 0.547s/it]: train_loss_raw=1.1568, running_loss=1.2282, LR=0.000100
[2025-08-10 16:28:16,011][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035616] [Batch 02388/03692] [00:21:45/00:11:52, 0.547s/it]: train_loss_raw=1.2272, running_loss=1.2277, LR=0.000100
[2025-08-10 16:28:22,279][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035628] [Batch 02400/03692] [00:21:51/00:11:46, 0.547s/it]: train_loss_raw=1.3027, running_loss=1.2240, LR=0.000100
[2025-08-10 16:28:28,509][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035640] [Batch 02412/03692] [00:21:57/00:11:39, 0.546s/it]: train_loss_raw=1.2180, running_loss=1.2199, LR=0.000100
[2025-08-10 16:28:34,673][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035652] [Batch 02424/03692] [00:22:04/00:11:32, 0.546s/it]: train_loss_raw=1.2687, running_loss=1.2226, LR=0.000100
[2025-08-10 16:28:41,018][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035664] [Batch 02436/03692] [00:22:10/00:11:25, 0.546s/it]: train_loss_raw=1.1083, running_loss=1.2198, LR=0.000100
[2025-08-10 16:28:47,583][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035676] [Batch 02448/03692] [00:22:16/00:11:19, 0.546s/it]: train_loss_raw=1.1358, running_loss=1.2188, LR=0.000100
[2025-08-10 16:28:54,139][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035688] [Batch 02460/03692] [00:22:23/00:11:12, 0.546s/it]: train_loss_raw=1.2567, running_loss=1.2205, LR=0.000100
[2025-08-10 16:29:00,642][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035700] [Batch 02472/03692] [00:22:29/00:11:06, 0.546s/it]: train_loss_raw=1.1013, running_loss=1.2159, LR=0.000100
[2025-08-10 16:29:07,226][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035712] [Batch 02484/03692] [00:22:36/00:10:59, 0.546s/it]: train_loss_raw=1.0449, running_loss=1.2144, LR=0.000100
[2025-08-10 16:29:13,731][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035724] [Batch 02496/03692] [00:22:43/00:10:53, 0.546s/it]: train_loss_raw=1.3146, running_loss=1.2186, LR=0.000100
[2025-08-10 16:29:19,872][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035736] [Batch 02508/03692] [00:22:49/00:10:46, 0.546s/it]: train_loss_raw=1.0840, running_loss=1.2199, LR=0.000100
[2025-08-10 16:29:26,034][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035748] [Batch 02520/03692] [00:22:55/00:10:39, 0.546s/it]: train_loss_raw=1.2134, running_loss=1.2210, LR=0.000100
[2025-08-10 16:29:32,062][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035760] [Batch 02532/03692] [00:23:01/00:10:32, 0.546s/it]: train_loss_raw=1.2259, running_loss=1.2180, LR=0.000100
[2025-08-10 16:29:38,374][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035772] [Batch 02544/03692] [00:23:07/00:10:26, 0.545s/it]: train_loss_raw=1.3376, running_loss=1.2190, LR=0.000100
[2025-08-10 16:29:44,954][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035784] [Batch 02556/03692] [00:23:14/00:10:19, 0.545s/it]: train_loss_raw=1.1703, running_loss=1.2197, LR=0.000100
[2025-08-10 16:29:51,626][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035796] [Batch 02568/03692] [00:23:20/00:10:13, 0.546s/it]: train_loss_raw=1.2480, running_loss=1.2170, LR=0.000100
[2025-08-10 16:29:57,940][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035808] [Batch 02580/03692] [00:23:27/00:10:06, 0.545s/it]: train_loss_raw=1.2442, running_loss=1.2173, LR=0.000100
[2025-08-10 16:30:04,408][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035820] [Batch 02592/03692] [00:23:33/00:09:59, 0.545s/it]: train_loss_raw=1.2690, running_loss=1.2175, LR=0.000100
[2025-08-10 16:30:10,778][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035832] [Batch 02604/03692] [00:23:40/00:09:53, 0.545s/it]: train_loss_raw=1.1361, running_loss=1.2212, LR=0.000100
[2025-08-10 16:30:17,285][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035844] [Batch 02616/03692] [00:23:46/00:09:46, 0.545s/it]: train_loss_raw=1.1571, running_loss=1.2186, LR=0.000100
[2025-08-10 16:30:23,907][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035856] [Batch 02628/03692] [00:23:53/00:09:40, 0.545s/it]: train_loss_raw=1.2882, running_loss=1.2182, LR=0.000100
[2025-08-10 16:30:30,536][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035868] [Batch 02640/03692] [00:23:59/00:09:33, 0.545s/it]: train_loss_raw=1.1680, running_loss=1.2239, LR=0.000100
[2025-08-10 16:30:37,157][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035880] [Batch 02652/03692] [00:24:06/00:09:27, 0.545s/it]: train_loss_raw=1.1952, running_loss=1.2240, LR=0.000100
[2025-08-10 16:30:43,731][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035892] [Batch 02664/03692] [00:24:13/00:09:20, 0.545s/it]: train_loss_raw=1.2107, running_loss=1.2225, LR=0.000100
[2025-08-10 16:30:49,908][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035904] [Batch 02676/03692] [00:24:19/00:09:14, 0.545s/it]: train_loss_raw=1.2150, running_loss=1.2236, LR=0.000100
[2025-08-10 16:30:56,075][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035916] [Batch 02688/03692] [00:24:25/00:09:07, 0.545s/it]: train_loss_raw=1.2408, running_loss=1.2209, LR=0.000100
[2025-08-10 16:31:02,487][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035928] [Batch 02700/03692] [00:24:31/00:09:00, 0.545s/it]: train_loss_raw=1.2933, running_loss=1.2197, LR=0.000100
[2025-08-10 16:31:08,599][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035940] [Batch 02712/03692] [00:24:37/00:08:54, 0.545s/it]: train_loss_raw=1.1616, running_loss=1.2181, LR=0.000100
[2025-08-10 16:31:14,854][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035952] [Batch 02724/03692] [00:24:44/00:08:47, 0.545s/it]: train_loss_raw=1.0508, running_loss=1.2144, LR=0.000100
[2025-08-10 16:31:20,889][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035964] [Batch 02736/03692] [00:24:50/00:08:40, 0.545s/it]: train_loss_raw=1.2252, running_loss=1.2097, LR=0.000100
[2025-08-10 16:31:27,077][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035976] [Batch 02748/03692] [00:24:56/00:08:34, 0.545s/it]: train_loss_raw=1.2709, running_loss=1.2128, LR=0.000100
[2025-08-10 16:31:33,410][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 035988] [Batch 02760/03692] [00:25:02/00:08:27, 0.544s/it]: train_loss_raw=1.1248, running_loss=1.2159, LR=0.000100
[2025-08-10 16:31:39,638][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036000] [Batch 02772/03692] [00:25:08/00:08:20, 0.544s/it]: train_loss_raw=1.1350, running_loss=1.2196, LR=0.000100
[2025-08-10 16:31:51,186][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036012] [Batch 02784/03692] [00:25:20/00:08:15, 0.546s/it]: train_loss_raw=1.1038, running_loss=1.2148, LR=0.000100
[2025-08-10 16:31:57,431][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036024] [Batch 02796/03692] [00:25:26/00:08:09, 0.546s/it]: train_loss_raw=1.1613, running_loss=1.2163, LR=0.000100
[2025-08-10 16:32:03,925][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036036] [Batch 02808/03692] [00:25:33/00:08:02, 0.546s/it]: train_loss_raw=1.1578, running_loss=1.2166, LR=0.000100
[2025-08-10 16:32:10,506][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036048] [Batch 02820/03692] [00:25:39/00:07:56, 0.546s/it]: train_loss_raw=1.1348, running_loss=1.2137, LR=0.000100
[2025-08-10 16:32:17,187][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036060] [Batch 02832/03692] [00:25:46/00:07:49, 0.546s/it]: train_loss_raw=1.2094, running_loss=1.2136, LR=0.000100
[2025-08-10 16:32:23,798][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036072] [Batch 02844/03692] [00:25:53/00:07:43, 0.546s/it]: train_loss_raw=1.3623, running_loss=1.2138, LR=0.000100
[2025-08-10 16:32:30,370][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036084] [Batch 02856/03692] [00:25:59/00:07:36, 0.546s/it]: train_loss_raw=1.2848, running_loss=1.2103, LR=0.000100
[2025-08-10 16:32:36,771][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036096] [Batch 02868/03692] [00:26:06/00:07:29, 0.546s/it]: train_loss_raw=1.2068, running_loss=1.2167, LR=0.000100
[2025-08-10 16:32:43,423][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036108] [Batch 02880/03692] [00:26:12/00:07:23, 0.546s/it]: train_loss_raw=1.2339, running_loss=1.2173, LR=0.000100
[2025-08-10 16:32:50,128][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036120] [Batch 02892/03692] [00:26:19/00:07:16, 0.546s/it]: train_loss_raw=1.0968, running_loss=1.2178, LR=0.000100
[2025-08-10 16:32:56,696][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036132] [Batch 02904/03692] [00:26:26/00:07:10, 0.546s/it]: train_loss_raw=1.1331, running_loss=1.2147, LR=0.000100
[2025-08-10 16:33:03,099][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036144] [Batch 02916/03692] [00:26:32/00:07:03, 0.546s/it]: train_loss_raw=1.2171, running_loss=1.2106, LR=0.000100
[2025-08-10 16:33:09,179][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036156] [Batch 02928/03692] [00:26:38/00:06:57, 0.546s/it]: train_loss_raw=1.2414, running_loss=1.2126, LR=0.000100
[2025-08-10 16:33:15,529][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036168] [Batch 02940/03692] [00:26:44/00:06:50, 0.546s/it]: train_loss_raw=1.2681, running_loss=1.2142, LR=0.000100
[2025-08-10 16:33:21,950][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036180] [Batch 02952/03692] [00:26:51/00:06:43, 0.546s/it]: train_loss_raw=1.2645, running_loss=1.2178, LR=0.000100
[2025-08-10 16:33:28,253][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036192] [Batch 02964/03692] [00:26:57/00:06:37, 0.546s/it]: train_loss_raw=1.1105, running_loss=1.2164, LR=0.000100
[2025-08-10 16:33:34,457][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036204] [Batch 02976/03692] [00:27:03/00:06:30, 0.546s/it]: train_loss_raw=1.1710, running_loss=1.2166, LR=0.000100
[2025-08-10 16:33:40,528][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036216] [Batch 02988/03692] [00:27:09/00:06:24, 0.545s/it]: train_loss_raw=1.2010, running_loss=1.2152, LR=0.000100
[2025-08-10 16:33:46,748][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036228] [Batch 03000/03692] [00:27:16/00:06:17, 0.545s/it]: train_loss_raw=1.2031, running_loss=1.2108, LR=0.000100
[2025-08-10 16:33:52,781][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036240] [Batch 03012/03692] [00:27:22/00:06:10, 0.545s/it]: train_loss_raw=1.1460, running_loss=1.2113, LR=0.000100
[2025-08-10 16:33:58,937][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036252] [Batch 03024/03692] [00:27:28/00:06:04, 0.545s/it]: train_loss_raw=1.1707, running_loss=1.2116, LR=0.000100
[2025-08-10 16:34:05,326][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036264] [Batch 03036/03692] [00:27:34/00:05:57, 0.545s/it]: train_loss_raw=1.0212, running_loss=1.2078, LR=0.000100
[2025-08-10 16:34:11,813][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036276] [Batch 03048/03692] [00:27:41/00:05:50, 0.545s/it]: train_loss_raw=1.1403, running_loss=1.2065, LR=0.000100
[2025-08-10 16:34:18,480][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036288] [Batch 03060/03692] [00:27:47/00:05:44, 0.545s/it]: train_loss_raw=1.1445, running_loss=1.2089, LR=0.000100
[2025-08-10 16:34:25,240][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036300] [Batch 03072/03692] [00:27:54/00:05:37, 0.545s/it]: train_loss_raw=1.3103, running_loss=1.2082, LR=0.000100
[2025-08-10 16:34:31,857][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036312] [Batch 03084/03692] [00:28:01/00:05:31, 0.545s/it]: train_loss_raw=1.1855, running_loss=1.2076, LR=0.000100
[2025-08-10 16:34:38,172][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036324] [Batch 03096/03692] [00:28:07/00:05:24, 0.545s/it]: train_loss_raw=1.0547, running_loss=1.2061, LR=0.000100
[2025-08-10 16:34:44,307][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036336] [Batch 03108/03692] [00:28:13/00:05:18, 0.545s/it]: train_loss_raw=1.2852, running_loss=1.2037, LR=0.000100
[2025-08-10 16:34:50,578][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036348] [Batch 03120/03692] [00:28:19/00:05:11, 0.545s/it]: train_loss_raw=1.2286, running_loss=1.2034, LR=0.000100
[2025-08-10 16:34:56,836][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036360] [Batch 03132/03692] [00:28:26/00:05:05, 0.545s/it]: train_loss_raw=1.2390, running_loss=1.2090, LR=0.000100
[2025-08-10 16:35:03,235][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036372] [Batch 03144/03692] [00:28:32/00:04:58, 0.545s/it]: train_loss_raw=1.0766, running_loss=1.2076, LR=0.000100
[2025-08-10 16:35:09,397][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036384] [Batch 03156/03692] [00:28:38/00:04:51, 0.545s/it]: train_loss_raw=1.3978, running_loss=1.2109, LR=0.000100
[2025-08-10 16:35:15,382][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036396] [Batch 03168/03692] [00:28:44/00:04:45, 0.544s/it]: train_loss_raw=1.1675, running_loss=1.2104, LR=0.000100
[2025-08-10 16:35:21,647][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036408] [Batch 03180/03692] [00:28:50/00:04:38, 0.544s/it]: train_loss_raw=1.1483, running_loss=1.2099, LR=0.000100
[2025-08-10 16:35:27,666][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036420] [Batch 03192/03692] [00:28:57/00:04:32, 0.544s/it]: train_loss_raw=1.2460, running_loss=1.2088, LR=0.000100
[2025-08-10 16:35:33,731][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036432] [Batch 03204/03692] [00:29:03/00:04:25, 0.544s/it]: train_loss_raw=1.1926, running_loss=1.2080, LR=0.000100
[2025-08-10 16:35:39,925][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036444] [Batch 03216/03692] [00:29:09/00:04:18, 0.544s/it]: train_loss_raw=1.0941, running_loss=1.2046, LR=0.000100
[2025-08-10 16:35:46,077][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036456] [Batch 03228/03692] [00:29:15/00:04:12, 0.544s/it]: train_loss_raw=1.0978, running_loss=1.2022, LR=0.000100
[2025-08-10 16:35:52,588][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036468] [Batch 03240/03692] [00:29:21/00:04:05, 0.544s/it]: train_loss_raw=1.0317, running_loss=1.1953, LR=0.000100
[2025-08-10 16:35:58,819][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036480] [Batch 03252/03692] [00:29:28/00:03:59, 0.544s/it]: train_loss_raw=1.2135, running_loss=1.1959, LR=0.000100
[2025-08-10 16:36:05,549][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036492] [Batch 03264/03692] [00:29:34/00:03:52, 0.544s/it]: train_loss_raw=1.2641, running_loss=1.1987, LR=0.000100
[2025-08-10 16:36:12,126][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036504] [Batch 03276/03692] [00:29:41/00:03:46, 0.544s/it]: train_loss_raw=1.2911, running_loss=1.1982, LR=0.000100
[2025-08-10 16:36:18,767][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036516] [Batch 03288/03692] [00:29:48/00:03:39, 0.544s/it]: train_loss_raw=1.1268, running_loss=1.1955, LR=0.000100
[2025-08-10 16:36:25,401][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036528] [Batch 03300/03692] [00:29:54/00:03:33, 0.544s/it]: train_loss_raw=1.0724, running_loss=1.1956, LR=0.000100
[2025-08-10 16:36:31,903][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036540] [Batch 03312/03692] [00:30:01/00:03:26, 0.544s/it]: train_loss_raw=1.1160, running_loss=1.1941, LR=0.000100
[2025-08-10 16:36:38,623][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036552] [Batch 03324/03692] [00:30:07/00:03:20, 0.544s/it]: train_loss_raw=1.2799, running_loss=1.1993, LR=0.000100
[2025-08-10 16:36:44,951][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036564] [Batch 03336/03692] [00:30:14/00:03:13, 0.544s/it]: train_loss_raw=1.0358, running_loss=1.1980, LR=0.000100
[2025-08-10 16:36:51,064][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036576] [Batch 03348/03692] [00:30:20/00:03:07, 0.544s/it]: train_loss_raw=1.2774, running_loss=1.2023, LR=0.000100
[2025-08-10 16:36:57,043][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036588] [Batch 03360/03692] [00:30:26/00:03:00, 0.544s/it]: train_loss_raw=1.2479, running_loss=1.2032, LR=0.000100
[2025-08-10 16:37:03,147][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036600] [Batch 03372/03692] [00:30:32/00:02:53, 0.543s/it]: train_loss_raw=1.1519, running_loss=1.2031, LR=0.000100
[2025-08-10 16:37:09,467][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036612] [Batch 03384/03692] [00:30:38/00:02:47, 0.543s/it]: train_loss_raw=1.1871, running_loss=1.2044, LR=0.000100
[2025-08-10 16:37:15,978][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036624] [Batch 03396/03692] [00:30:45/00:02:40, 0.543s/it]: train_loss_raw=1.1408, running_loss=1.2077, LR=0.000100
[2025-08-10 16:37:22,664][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036636] [Batch 03408/03692] [00:30:52/00:02:34, 0.543s/it]: train_loss_raw=1.0951, running_loss=1.2074, LR=0.000100
[2025-08-10 16:37:28,819][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036648] [Batch 03420/03692] [00:30:58/00:02:27, 0.543s/it]: train_loss_raw=1.1374, running_loss=1.2063, LR=0.000100
[2025-08-10 16:37:35,041][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036660] [Batch 03432/03692] [00:31:04/00:02:21, 0.543s/it]: train_loss_raw=1.1323, running_loss=1.2054, LR=0.000100
[2025-08-10 16:37:41,072][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036672] [Batch 03444/03692] [00:31:10/00:02:14, 0.543s/it]: train_loss_raw=1.2571, running_loss=1.2078, LR=0.000100
[2025-08-10 16:37:47,155][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036684] [Batch 03456/03692] [00:31:16/00:02:08, 0.543s/it]: train_loss_raw=1.2471, running_loss=1.2068, LR=0.000100
[2025-08-10 16:37:53,426][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036696] [Batch 03468/03692] [00:31:22/00:02:01, 0.543s/it]: train_loss_raw=1.1787, running_loss=1.2054, LR=0.000100
[2025-08-10 16:37:59,453][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036708] [Batch 03480/03692] [00:31:28/00:01:55, 0.543s/it]: train_loss_raw=1.1603, running_loss=1.2051, LR=0.000100
[2025-08-10 16:38:05,879][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036720] [Batch 03492/03692] [00:31:35/00:01:48, 0.543s/it]: train_loss_raw=1.1394, running_loss=1.2039, LR=0.000100
[2025-08-10 16:38:12,111][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036732] [Batch 03504/03692] [00:31:41/00:01:42, 0.543s/it]: train_loss_raw=1.2501, running_loss=1.2070, LR=0.000100
[2025-08-10 16:38:18,404][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036744] [Batch 03516/03692] [00:31:47/00:01:35, 0.543s/it]: train_loss_raw=1.2677, running_loss=1.2082, LR=0.000100
[2025-08-10 16:38:24,779][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036756] [Batch 03528/03692] [00:31:54/00:01:28, 0.543s/it]: train_loss_raw=1.2298, running_loss=1.2090, LR=0.000100
[2025-08-10 16:38:30,994][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036768] [Batch 03540/03692] [00:32:00/00:01:22, 0.542s/it]: train_loss_raw=1.1557, running_loss=1.2045, LR=0.000100
[2025-08-10 16:38:37,145][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036780] [Batch 03552/03692] [00:32:06/00:01:15, 0.542s/it]: train_loss_raw=1.3274, running_loss=1.2046, LR=0.000100
[2025-08-10 16:38:43,375][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036792] [Batch 03564/03692] [00:32:12/00:01:09, 0.542s/it]: train_loss_raw=1.0536, running_loss=1.2023, LR=0.000100
[2025-08-10 16:38:49,569][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036804] [Batch 03576/03692] [00:32:18/00:01:02, 0.542s/it]: train_loss_raw=1.1557, running_loss=1.2040, LR=0.000100
[2025-08-10 16:38:55,679][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036816] [Batch 03588/03692] [00:32:25/00:00:56, 0.542s/it]: train_loss_raw=1.2231, running_loss=1.2056, LR=0.000100
[2025-08-10 16:39:01,739][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036828] [Batch 03600/03692] [00:32:31/00:00:49, 0.542s/it]: train_loss_raw=1.3336, running_loss=1.2071, LR=0.000100
[2025-08-10 16:39:07,737][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036840] [Batch 03612/03692] [00:32:37/00:00:43, 0.542s/it]: train_loss_raw=1.2882, running_loss=1.2077, LR=0.000100
[2025-08-10 16:39:13,792][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036852] [Batch 03624/03692] [00:32:43/00:00:36, 0.542s/it]: train_loss_raw=1.2863, running_loss=1.2077, LR=0.000100
[2025-08-10 16:39:19,787][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036864] [Batch 03636/03692] [00:32:49/00:00:30, 0.542s/it]: train_loss_raw=1.3116, running_loss=1.2043, LR=0.000100
[2025-08-10 16:39:25,795][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036876] [Batch 03648/03692] [00:32:55/00:00:23, 0.541s/it]: train_loss_raw=1.2462, running_loss=1.2016, LR=0.000100
[2025-08-10 16:39:31,856][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036888] [Batch 03660/03692] [00:33:01/00:00:17, 0.541s/it]: train_loss_raw=1.1947, running_loss=1.1990, LR=0.000100
[2025-08-10 16:39:38,009][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036900] [Batch 03672/03692] [00:33:07/00:00:10, 0.541s/it]: train_loss_raw=1.1917, running_loss=1.1991, LR=0.000100
[2025-08-10 16:39:44,376][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 036912] [Batch 03684/03692] [00:33:13/00:00:04, 0.541s/it]: train_loss_raw=1.2169, running_loss=1.1972, LR=0.000100
[2025-08-10 16:40:01,435][__main__][INFO] - [VALIDATION] [Epoch 09/29] Starting validation.
[2025-08-10 16:40:36,293][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 036921] [Batch 00011/00025] [00:00:34/00:00:37, 2.905s/it]
[2025-08-10 16:40:53,006][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 036921] [Batch 00023/00025] [00:00:51/00:00:02, 2.149s/it]
[2025-08-10 16:40:54,324][__main__][INFO] - [VALIDATION] [Epoch 09/29] train_loss=1.19880, valid_loss=1.15322
[2025-08-10 16:40:54,324][__main__][INFO] - [VALIDATION] [Epoch 09/29] Metrics:
[2025-08-10 16:40:54,324][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_er      0.502
[2025-08-10 16:40:54,325][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_prec    0.217
[2025-08-10 16:40:54,325][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_recall  0.222
[2025-08-10 16:40:54,325][__main__][INFO] - [VALIDATION] [Epoch 09/29] - pep_recall 0.180
[2025-08-10 16:40:54,330][__main__][INFO] - [TRAIN] [Epoch 09/29] Epoch complete, total time 05:44:53, remaining time 11:29:47, 00:34:29 per epoch
[2025-08-10 16:40:57,071][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036924] [Batch 00004/03692] [00:00:01/00:25:33, 0.416s/it]: train_loss_raw=1.1078, running_loss=1.1287, LR=0.000100
[2025-08-10 16:41:03,116][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036936] [Batch 00016/03692] [00:00:07/00:29:31, 0.482s/it]: train_loss_raw=1.2342, running_loss=1.1288, LR=0.000100
[2025-08-10 16:41:09,370][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036948] [Batch 00028/03692] [00:00:13/00:30:27, 0.499s/it]: train_loss_raw=1.1757, running_loss=1.1335, LR=0.000100
[2025-08-10 16:41:15,367][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036960] [Batch 00040/03692] [00:00:19/00:30:22, 0.499s/it]: train_loss_raw=1.3265, running_loss=1.1343, LR=0.000100
[2025-08-10 16:41:21,386][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036972] [Batch 00052/03692] [00:00:25/00:30:18, 0.500s/it]: train_loss_raw=1.2578, running_loss=1.1335, LR=0.000100
[2025-08-10 16:41:27,504][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036984] [Batch 00064/03692] [00:00:32/00:30:19, 0.501s/it]: train_loss_raw=1.2116, running_loss=1.1371, LR=0.000100
[2025-08-10 16:41:33,558][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 036996] [Batch 00076/03692] [00:00:38/00:30:15, 0.502s/it]: train_loss_raw=1.2683, running_loss=1.1406, LR=0.000100
[2025-08-10 16:41:39,795][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037008] [Batch 00088/03692] [00:00:44/00:30:17, 0.504s/it]: train_loss_raw=1.0876, running_loss=1.1410, LR=0.000100
[2025-08-10 16:41:46,386][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037020] [Batch 00100/03692] [00:00:50/00:30:31, 0.510s/it]: train_loss_raw=1.0515, running_loss=1.1386, LR=0.000100
[2025-08-10 16:41:52,650][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037032] [Batch 00112/03692] [00:00:57/00:30:29, 0.511s/it]: train_loss_raw=1.0882, running_loss=1.1418, LR=0.000100
[2025-08-10 16:41:58,648][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037044] [Batch 00124/03692] [00:01:03/00:30:19, 0.510s/it]: train_loss_raw=1.0855, running_loss=1.1382, LR=0.000100
[2025-08-10 16:42:04,757][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037056] [Batch 00136/03692] [00:01:09/00:30:13, 0.510s/it]: train_loss_raw=1.1378, running_loss=1.1382, LR=0.000100
[2025-08-10 16:42:10,828][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037068] [Batch 00148/03692] [00:01:15/00:30:06, 0.510s/it]: train_loss_raw=1.1498, running_loss=1.1382, LR=0.000100
[2025-08-10 16:42:16,887][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037080] [Batch 00160/03692] [00:01:21/00:29:58, 0.509s/it]: train_loss_raw=1.1038, running_loss=1.1355, LR=0.000100
[2025-08-10 16:42:22,879][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037092] [Batch 00172/03692] [00:01:27/00:29:50, 0.509s/it]: train_loss_raw=1.1481, running_loss=1.1400, LR=0.000100
[2025-08-10 16:42:28,969][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037104] [Batch 00184/03692] [00:01:33/00:29:43, 0.508s/it]: train_loss_raw=1.1463, running_loss=1.1418, LR=0.000100
[2025-08-10 16:42:35,010][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037116] [Batch 00196/03692] [00:01:39/00:29:36, 0.508s/it]: train_loss_raw=1.2209, running_loss=1.1436, LR=0.000100
[2025-08-10 16:42:41,286][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037128] [Batch 00208/03692] [00:01:45/00:29:33, 0.509s/it]: train_loss_raw=1.1465, running_loss=1.1440, LR=0.000100
[2025-08-10 16:42:47,739][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037140] [Batch 00220/03692] [00:01:52/00:29:32, 0.511s/it]: train_loss_raw=1.1084, running_loss=1.1468, LR=0.000100
[2025-08-10 16:42:53,880][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037152] [Batch 00232/03692] [00:01:58/00:29:26, 0.511s/it]: train_loss_raw=1.2317, running_loss=1.1454, LR=0.000100
[2025-08-10 16:43:00,391][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037164] [Batch 00244/03692] [00:02:04/00:29:26, 0.512s/it]: train_loss_raw=1.2954, running_loss=1.1488, LR=0.000100
[2025-08-10 16:43:06,875][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037176] [Batch 00256/03692] [00:02:11/00:29:24, 0.514s/it]: train_loss_raw=1.0255, running_loss=1.1480, LR=0.000100
[2025-08-10 16:43:13,315][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037188] [Batch 00268/03692] [00:02:17/00:29:21, 0.515s/it]: train_loss_raw=1.0537, running_loss=1.1475, LR=0.000100
[2025-08-10 16:43:19,365][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037200] [Batch 00280/03692] [00:02:23/00:29:14, 0.514s/it]: train_loss_raw=1.1932, running_loss=1.1520, LR=0.000100
[2025-08-10 16:43:25,547][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037212] [Batch 00292/03692] [00:02:30/00:29:08, 0.514s/it]: train_loss_raw=1.2110, running_loss=1.1522, LR=0.000100
[2025-08-10 16:43:31,645][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037224] [Batch 00304/03692] [00:02:36/00:29:01, 0.514s/it]: train_loss_raw=1.0824, running_loss=1.1521, LR=0.000100
[2025-08-10 16:43:37,907][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037236] [Batch 00316/03692] [00:02:42/00:28:56, 0.514s/it]: train_loss_raw=1.1097, running_loss=1.1487, LR=0.000100
[2025-08-10 16:43:44,188][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037248] [Batch 00328/03692] [00:02:48/00:28:51, 0.515s/it]: train_loss_raw=1.2742, running_loss=1.1514, LR=0.000100
[2025-08-10 16:43:50,507][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037260] [Batch 00340/03692] [00:02:55/00:28:46, 0.515s/it]: train_loss_raw=1.0298, running_loss=1.1507, LR=0.000100
[2025-08-10 16:43:57,114][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037272] [Batch 00352/03692] [00:03:01/00:28:44, 0.516s/it]: train_loss_raw=1.1786, running_loss=1.1473, LR=0.000100
[2025-08-10 16:44:03,742][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037284] [Batch 00364/03692] [00:03:08/00:28:41, 0.517s/it]: train_loss_raw=1.0767, running_loss=1.1464, LR=0.000100
[2025-08-10 16:44:10,102][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037296] [Batch 00376/03692] [00:03:14/00:28:37, 0.518s/it]: train_loss_raw=1.2729, running_loss=1.1493, LR=0.000100
[2025-08-10 16:44:16,477][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037308] [Batch 00388/03692] [00:03:21/00:28:32, 0.518s/it]: train_loss_raw=1.1901, running_loss=1.1494, LR=0.000100
[2025-08-10 16:44:22,480][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037320] [Batch 00400/03692] [00:03:27/00:28:24, 0.518s/it]: train_loss_raw=1.2261, running_loss=1.1496, LR=0.000100
[2025-08-10 16:44:28,549][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037332] [Batch 00412/03692] [00:03:33/00:28:16, 0.517s/it]: train_loss_raw=1.0740, running_loss=1.1533, LR=0.000100
[2025-08-10 16:44:34,593][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037344] [Batch 00424/03692] [00:03:39/00:28:09, 0.517s/it]: train_loss_raw=1.1950, running_loss=1.1531, LR=0.000100
[2025-08-10 16:44:40,647][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037356] [Batch 00436/03692] [00:03:45/00:28:02, 0.517s/it]: train_loss_raw=1.0568, running_loss=1.1527, LR=0.000100
[2025-08-10 16:44:46,691][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037368] [Batch 00448/03692] [00:03:51/00:27:54, 0.516s/it]: train_loss_raw=1.0138, running_loss=1.1519, LR=0.000100
[2025-08-10 16:44:52,753][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037380] [Batch 00460/03692] [00:03:57/00:27:47, 0.516s/it]: train_loss_raw=1.1402, running_loss=1.1528, LR=0.000100
[2025-08-10 16:44:58,830][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037392] [Batch 00472/03692] [00:04:03/00:27:40, 0.516s/it]: train_loss_raw=1.0868, running_loss=1.1545, LR=0.000100
[2025-08-10 16:45:04,952][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037404] [Batch 00484/03692] [00:04:09/00:27:34, 0.516s/it]: train_loss_raw=1.1195, running_loss=1.1510, LR=0.000100
[2025-08-10 16:45:11,013][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037416] [Batch 00496/03692] [00:04:15/00:27:27, 0.515s/it]: train_loss_raw=1.1205, running_loss=1.1533, LR=0.000100
[2025-08-10 16:45:17,044][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037428] [Batch 00508/03692] [00:04:21/00:27:19, 0.515s/it]: train_loss_raw=1.1053, running_loss=1.1548, LR=0.000100
[2025-08-10 16:45:23,148][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037440] [Batch 00520/03692] [00:04:27/00:27:13, 0.515s/it]: train_loss_raw=1.1422, running_loss=1.1570, LR=0.000100
[2025-08-10 16:45:29,166][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037452] [Batch 00532/03692] [00:04:33/00:27:06, 0.515s/it]: train_loss_raw=1.3269, running_loss=1.1610, LR=0.000100
[2025-08-10 16:45:35,240][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037464] [Batch 00544/03692] [00:04:39/00:26:59, 0.514s/it]: train_loss_raw=1.0871, running_loss=1.1593, LR=0.000100
[2025-08-10 16:45:41,299][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037476] [Batch 00556/03692] [00:04:45/00:26:52, 0.514s/it]: train_loss_raw=1.2080, running_loss=1.1610, LR=0.000100
[2025-08-10 16:45:47,315][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037488] [Batch 00568/03692] [00:04:51/00:26:45, 0.514s/it]: train_loss_raw=1.1119, running_loss=1.1550, LR=0.000100
[2025-08-10 16:45:53,435][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037500] [Batch 00580/03692] [00:04:58/00:26:39, 0.514s/it]: train_loss_raw=1.2374, running_loss=1.1555, LR=0.000100
[2025-08-10 16:45:59,383][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037512] [Batch 00592/03692] [00:05:03/00:26:31, 0.513s/it]: train_loss_raw=1.1977, running_loss=1.1548, LR=0.000100
[2025-08-10 16:46:05,529][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037524] [Batch 00604/03692] [00:05:10/00:26:25, 0.513s/it]: train_loss_raw=1.2059, running_loss=1.1553, LR=0.000100
[2025-08-10 16:46:11,590][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037536] [Batch 00616/03692] [00:05:16/00:26:18, 0.513s/it]: train_loss_raw=1.1495, running_loss=1.1517, LR=0.000100
[2025-08-10 16:46:17,632][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037548] [Batch 00628/03692] [00:05:22/00:26:12, 0.513s/it]: train_loss_raw=1.3298, running_loss=1.1534, LR=0.000100
[2025-08-10 16:46:23,601][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037560] [Batch 00640/03692] [00:05:28/00:26:05, 0.513s/it]: train_loss_raw=1.0851, running_loss=1.1576, LR=0.000100
[2025-08-10 16:46:29,585][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037572] [Batch 00652/03692] [00:05:34/00:25:58, 0.513s/it]: train_loss_raw=1.2005, running_loss=1.1543, LR=0.000100
[2025-08-10 16:46:35,673][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037584] [Batch 00664/03692] [00:05:40/00:25:51, 0.512s/it]: train_loss_raw=1.3259, running_loss=1.1576, LR=0.000100
[2025-08-10 16:46:42,244][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037596] [Batch 00676/03692] [00:05:46/00:25:47, 0.513s/it]: train_loss_raw=1.1708, running_loss=1.1620, LR=0.000100
[2025-08-10 16:46:48,823][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037608] [Batch 00688/03692] [00:05:53/00:25:43, 0.514s/it]: train_loss_raw=1.1465, running_loss=1.1586, LR=0.000100
[2025-08-10 16:46:55,441][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037620] [Batch 00700/03692] [00:06:00/00:25:38, 0.514s/it]: train_loss_raw=1.2748, running_loss=1.1597, LR=0.000100
[2025-08-10 16:47:02,004][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037632] [Batch 00712/03692] [00:06:06/00:25:34, 0.515s/it]: train_loss_raw=1.1770, running_loss=1.1567, LR=0.000100
[2025-08-10 16:47:08,579][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037644] [Batch 00724/03692] [00:06:13/00:25:29, 0.515s/it]: train_loss_raw=1.1049, running_loss=1.1538, LR=0.000100
[2025-08-10 16:47:15,224][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037656] [Batch 00736/03692] [00:06:19/00:25:25, 0.516s/it]: train_loss_raw=1.2010, running_loss=1.1543, LR=0.000100
[2025-08-10 16:47:21,761][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037668] [Batch 00748/03692] [00:06:26/00:25:20, 0.517s/it]: train_loss_raw=1.1264, running_loss=1.1549, LR=0.000100
[2025-08-10 16:47:28,317][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037680] [Batch 00760/03692] [00:06:32/00:25:15, 0.517s/it]: train_loss_raw=1.2040, running_loss=1.1537, LR=0.000100
[2025-08-10 16:47:34,526][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037692] [Batch 00772/03692] [00:06:39/00:25:09, 0.517s/it]: train_loss_raw=1.2118, running_loss=1.1524, LR=0.000100
[2025-08-10 16:47:40,515][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037704] [Batch 00784/03692] [00:06:45/00:25:02, 0.517s/it]: train_loss_raw=1.1570, running_loss=1.1537, LR=0.000100
[2025-08-10 16:47:46,549][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037716] [Batch 00796/03692] [00:06:51/00:24:55, 0.517s/it]: train_loss_raw=1.0127, running_loss=1.1529, LR=0.000100
[2025-08-10 16:47:52,866][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037728] [Batch 00808/03692] [00:06:57/00:24:50, 0.517s/it]: train_loss_raw=1.1041, running_loss=1.1546, LR=0.000100
[2025-08-10 16:47:59,032][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037740] [Batch 00820/03692] [00:07:03/00:24:43, 0.517s/it]: train_loss_raw=1.0516, running_loss=1.1547, LR=0.000100
[2025-08-10 16:48:05,098][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037752] [Batch 00832/03692] [00:07:09/00:24:37, 0.516s/it]: train_loss_raw=1.2461, running_loss=1.1538, LR=0.000100
[2025-08-10 16:48:11,123][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037764] [Batch 00844/03692] [00:07:15/00:24:30, 0.516s/it]: train_loss_raw=1.1752, running_loss=1.1548, LR=0.000100
[2025-08-10 16:48:17,161][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037776] [Batch 00856/03692] [00:07:21/00:24:23, 0.516s/it]: train_loss_raw=1.1165, running_loss=1.1603, LR=0.000100
[2025-08-10 16:48:23,282][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037788] [Batch 00868/03692] [00:07:27/00:24:17, 0.516s/it]: train_loss_raw=1.0962, running_loss=1.1566, LR=0.000100
[2025-08-10 16:48:29,448][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037800] [Batch 00880/03692] [00:07:34/00:24:10, 0.516s/it]: train_loss_raw=1.1724, running_loss=1.1508, LR=0.000100
[2025-08-10 16:48:35,684][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037812] [Batch 00892/03692] [00:07:40/00:24:04, 0.516s/it]: train_loss_raw=1.1675, running_loss=1.1506, LR=0.000100
[2025-08-10 16:48:41,731][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037824] [Batch 00904/03692] [00:07:46/00:23:58, 0.516s/it]: train_loss_raw=1.2046, running_loss=1.1553, LR=0.000100
[2025-08-10 16:48:47,878][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037836] [Batch 00916/03692] [00:07:52/00:23:51, 0.516s/it]: train_loss_raw=1.1869, running_loss=1.1558, LR=0.000100
[2025-08-10 16:48:54,018][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037848] [Batch 00928/03692] [00:07:58/00:23:45, 0.516s/it]: train_loss_raw=1.1115, running_loss=1.1516, LR=0.000100
[2025-08-10 16:49:00,167][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037860] [Batch 00940/03692] [00:08:04/00:23:39, 0.516s/it]: train_loss_raw=1.0770, running_loss=1.1551, LR=0.000100
[2025-08-10 16:49:06,164][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037872] [Batch 00952/03692] [00:08:10/00:23:32, 0.516s/it]: train_loss_raw=1.1730, running_loss=1.1575, LR=0.000100
[2025-08-10 16:49:12,202][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037884] [Batch 00964/03692] [00:08:16/00:23:25, 0.515s/it]: train_loss_raw=1.2232, running_loss=1.1549, LR=0.000100
[2025-08-10 16:49:18,627][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037896] [Batch 00976/03692] [00:08:23/00:23:20, 0.516s/it]: train_loss_raw=1.0320, running_loss=1.1562, LR=0.000100
[2025-08-10 16:49:24,654][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037908] [Batch 00988/03692] [00:08:29/00:23:13, 0.515s/it]: train_loss_raw=1.2670, running_loss=1.1554, LR=0.000100
[2025-08-10 16:49:30,795][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037920] [Batch 01000/03692] [00:08:35/00:23:07, 0.515s/it]: train_loss_raw=1.1596, running_loss=1.1565, LR=0.000100
[2025-08-10 16:49:36,959][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037932] [Batch 01012/03692] [00:08:41/00:23:01, 0.515s/it]: train_loss_raw=1.1766, running_loss=1.1573, LR=0.000100
[2025-08-10 16:49:43,238][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037944] [Batch 01024/03692] [00:08:47/00:22:55, 0.515s/it]: train_loss_raw=1.1052, running_loss=1.1561, LR=0.000100
[2025-08-10 16:49:49,443][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037956] [Batch 01036/03692] [00:08:54/00:22:49, 0.515s/it]: train_loss_raw=1.0745, running_loss=1.1546, LR=0.000100
[2025-08-10 16:49:55,770][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037968] [Batch 01048/03692] [00:09:00/00:22:43, 0.516s/it]: train_loss_raw=1.1660, running_loss=1.1511, LR=0.000100
[2025-08-10 16:50:02,004][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037980] [Batch 01060/03692] [00:09:06/00:22:37, 0.516s/it]: train_loss_raw=1.1451, running_loss=1.1503, LR=0.000100
[2025-08-10 16:50:08,389][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 037992] [Batch 01072/03692] [00:09:12/00:22:31, 0.516s/it]: train_loss_raw=1.1874, running_loss=1.1478, LR=0.000100
[2025-08-10 16:50:20,370][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038004] [Batch 01084/03692] [00:09:24/00:22:39, 0.521s/it]: train_loss_raw=1.2553, running_loss=1.1490, LR=0.000100
[2025-08-10 16:50:26,941][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038016] [Batch 01096/03692] [00:09:31/00:22:33, 0.521s/it]: train_loss_raw=1.1009, running_loss=1.1496, LR=0.000100
[2025-08-10 16:50:33,454][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038028] [Batch 01108/03692] [00:09:38/00:22:28, 0.522s/it]: train_loss_raw=1.1357, running_loss=1.1469, LR=0.000100
[2025-08-10 16:50:40,148][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038040] [Batch 01120/03692] [00:09:44/00:22:22, 0.522s/it]: train_loss_raw=1.3030, running_loss=1.1479, LR=0.000100
[2025-08-10 16:50:46,668][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038052] [Batch 01132/03692] [00:09:51/00:22:17, 0.522s/it]: train_loss_raw=1.1045, running_loss=1.1439, LR=0.000100
[2025-08-10 16:50:53,448][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038064] [Batch 01144/03692] [00:09:58/00:22:11, 0.523s/it]: train_loss_raw=1.1963, running_loss=1.1411, LR=0.000100
[2025-08-10 16:51:00,262][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038076] [Batch 01156/03692] [00:10:04/00:22:06, 0.523s/it]: train_loss_raw=1.0890, running_loss=1.1375, LR=0.000100
[2025-08-10 16:51:06,883][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038088] [Batch 01168/03692] [00:10:11/00:22:01, 0.524s/it]: train_loss_raw=1.0243, running_loss=1.1396, LR=0.000100
[2025-08-10 16:51:13,486][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038100] [Batch 01180/03692] [00:10:18/00:21:55, 0.524s/it]: train_loss_raw=1.3195, running_loss=1.1437, LR=0.000100
[2025-08-10 16:51:20,181][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038112] [Batch 01192/03692] [00:10:24/00:21:50, 0.524s/it]: train_loss_raw=1.1676, running_loss=1.1448, LR=0.000100
[2025-08-10 16:51:26,763][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038124] [Batch 01204/03692] [00:10:31/00:21:44, 0.524s/it]: train_loss_raw=1.1236, running_loss=1.1461, LR=0.000100
[2025-08-10 16:51:33,561][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038136] [Batch 01216/03692] [00:10:38/00:21:39, 0.525s/it]: train_loss_raw=1.1947, running_loss=1.1431, LR=0.000100
[2025-08-10 16:51:40,097][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038148] [Batch 01228/03692] [00:10:44/00:21:33, 0.525s/it]: train_loss_raw=1.1957, running_loss=1.1473, LR=0.000100
[2025-08-10 16:51:46,797][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038160] [Batch 01240/03692] [00:10:51/00:21:28, 0.525s/it]: train_loss_raw=1.2278, running_loss=1.1525, LR=0.000100
[2025-08-10 16:51:53,359][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038172] [Batch 01252/03692] [00:10:57/00:21:22, 0.526s/it]: train_loss_raw=1.0764, running_loss=1.1527, LR=0.000100
[2025-08-10 16:51:59,883][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038184] [Batch 01264/03692] [00:11:04/00:21:16, 0.526s/it]: train_loss_raw=1.0732, running_loss=1.1503, LR=0.000100
[2025-08-10 16:52:06,632][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038196] [Batch 01276/03692] [00:11:11/00:21:10, 0.526s/it]: train_loss_raw=1.2987, running_loss=1.1503, LR=0.000100
[2025-08-10 16:52:13,262][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038208] [Batch 01288/03692] [00:11:17/00:21:05, 0.526s/it]: train_loss_raw=1.2445, running_loss=1.1544, LR=0.000100
[2025-08-10 16:52:19,953][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038220] [Batch 01300/03692] [00:11:24/00:20:59, 0.527s/it]: train_loss_raw=1.1021, running_loss=1.1511, LR=0.000100
[2025-08-10 16:52:26,279][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038232] [Batch 01312/03692] [00:11:30/00:20:53, 0.527s/it]: train_loss_raw=1.1535, running_loss=1.1526, LR=0.000100
[2025-08-10 16:52:32,401][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038244] [Batch 01324/03692] [00:11:36/00:20:46, 0.526s/it]: train_loss_raw=1.1079, running_loss=1.1530, LR=0.000100
[2025-08-10 16:52:38,491][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038256] [Batch 01336/03692] [00:11:43/00:20:39, 0.526s/it]: train_loss_raw=1.0647, running_loss=1.1507, LR=0.000100
[2025-08-10 16:52:44,610][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038268] [Batch 01348/03692] [00:11:49/00:20:33, 0.526s/it]: train_loss_raw=1.1692, running_loss=1.1481, LR=0.000100
[2025-08-10 16:52:50,811][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038280] [Batch 01360/03692] [00:11:55/00:20:26, 0.526s/it]: train_loss_raw=1.2335, running_loss=1.1514, LR=0.000100
[2025-08-10 16:52:56,875][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038292] [Batch 01372/03692] [00:12:01/00:20:19, 0.526s/it]: train_loss_raw=1.1140, running_loss=1.1471, LR=0.000100
[2025-08-10 16:53:03,240][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038304] [Batch 01384/03692] [00:12:07/00:20:13, 0.526s/it]: train_loss_raw=1.1582, running_loss=1.1470, LR=0.000100
[2025-08-10 16:53:09,394][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038316] [Batch 01396/03692] [00:12:13/00:20:07, 0.526s/it]: train_loss_raw=1.1428, running_loss=1.1479, LR=0.000100
[2025-08-10 16:53:15,740][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038328] [Batch 01408/03692] [00:12:20/00:20:00, 0.526s/it]: train_loss_raw=1.1594, running_loss=1.1505, LR=0.000100
[2025-08-10 16:53:21,792][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038340] [Batch 01420/03692] [00:12:26/00:19:54, 0.526s/it]: train_loss_raw=1.0544, running_loss=1.1496, LR=0.000100
[2025-08-10 16:53:27,907][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038352] [Batch 01432/03692] [00:12:32/00:19:47, 0.525s/it]: train_loss_raw=1.1013, running_loss=1.1445, LR=0.000100
[2025-08-10 16:53:34,419][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038364] [Batch 01444/03692] [00:12:39/00:19:41, 0.526s/it]: train_loss_raw=1.2079, running_loss=1.1480, LR=0.000100
[2025-08-10 16:53:40,985][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038376] [Batch 01456/03692] [00:12:45/00:19:35, 0.526s/it]: train_loss_raw=1.2225, running_loss=1.1484, LR=0.000100
[2025-08-10 16:53:47,538][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038388] [Batch 01468/03692] [00:12:52/00:19:29, 0.526s/it]: train_loss_raw=1.0617, running_loss=1.1462, LR=0.000100
[2025-08-10 16:53:53,649][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038400] [Batch 01480/03692] [00:12:58/00:19:23, 0.526s/it]: train_loss_raw=1.2013, running_loss=1.1481, LR=0.000100
[2025-08-10 16:54:00,104][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038412] [Batch 01492/03692] [00:13:04/00:19:17, 0.526s/it]: train_loss_raw=1.0287, running_loss=1.1465, LR=0.000100
[2025-08-10 16:54:06,453][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038424] [Batch 01504/03692] [00:13:11/00:19:10, 0.526s/it]: train_loss_raw=1.0211, running_loss=1.1423, LR=0.000100
[2025-08-10 16:54:12,974][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038436] [Batch 01516/03692] [00:13:17/00:19:04, 0.526s/it]: train_loss_raw=1.0530, running_loss=1.1441, LR=0.000100
[2025-08-10 16:54:19,751][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038448] [Batch 01528/03692] [00:13:24/00:18:59, 0.526s/it]: train_loss_raw=1.2831, running_loss=1.1463, LR=0.000100
[2025-08-10 16:55:14,919][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038460] [Batch 01540/03692] [00:14:19/00:20:01, 0.558s/it]: train_loss_raw=1.1727, running_loss=1.1474, LR=0.000100
[2025-08-10 16:55:20,927][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038472] [Batch 01552/03692] [00:14:25/00:19:53, 0.558s/it]: train_loss_raw=1.0361, running_loss=1.1459, LR=0.000100
[2025-08-10 16:55:27,049][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038484] [Batch 01564/03692] [00:14:31/00:19:45, 0.557s/it]: train_loss_raw=1.0434, running_loss=1.1474, LR=0.000100
[2025-08-10 16:55:33,241][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038496] [Batch 01576/03692] [00:14:37/00:19:38, 0.557s/it]: train_loss_raw=1.2533, running_loss=1.1503, LR=0.000100
[2025-08-10 16:55:39,544][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038508] [Batch 01588/03692] [00:14:44/00:19:31, 0.557s/it]: train_loss_raw=1.0939, running_loss=1.1540, LR=0.000100
[2025-08-10 16:55:45,872][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038520] [Batch 01600/03692] [00:14:50/00:19:24, 0.557s/it]: train_loss_raw=1.2753, running_loss=1.1539, LR=0.000100
[2025-08-10 16:55:52,282][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038532] [Batch 01612/03692] [00:14:56/00:19:17, 0.556s/it]: train_loss_raw=1.0800, running_loss=1.1495, LR=0.000100
[2025-08-10 16:55:58,380][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038544] [Batch 01624/03692] [00:15:02/00:19:09, 0.556s/it]: train_loss_raw=1.0908, running_loss=1.1520, LR=0.000100
[2025-08-10 16:56:04,741][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038556] [Batch 01636/03692] [00:15:09/00:19:02, 0.556s/it]: train_loss_raw=1.2054, running_loss=1.1518, LR=0.000100
[2025-08-10 16:56:10,967][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038568] [Batch 01648/03692] [00:15:15/00:18:55, 0.556s/it]: train_loss_raw=1.1744, running_loss=1.1481, LR=0.000100
[2025-08-10 16:56:17,031][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038580] [Batch 01660/03692] [00:15:21/00:18:48, 0.555s/it]: train_loss_raw=1.0860, running_loss=1.1497, LR=0.000100
[2025-08-10 16:56:23,208][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038592] [Batch 01672/03692] [00:15:27/00:18:40, 0.555s/it]: train_loss_raw=1.0450, running_loss=1.1491, LR=0.000100
[2025-08-10 16:56:29,275][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038604] [Batch 01684/03692] [00:15:33/00:18:33, 0.555s/it]: train_loss_raw=1.3187, running_loss=1.1521, LR=0.000100
[2025-08-10 16:56:36,032][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038616] [Batch 01696/03692] [00:15:40/00:18:27, 0.555s/it]: train_loss_raw=1.0461, running_loss=1.1489, LR=0.000100
[2025-08-10 16:56:42,677][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038628] [Batch 01708/03692] [00:15:47/00:18:20, 0.555s/it]: train_loss_raw=1.1749, running_loss=1.1496, LR=0.000100
[2025-08-10 16:56:49,268][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038640] [Batch 01720/03692] [00:15:53/00:18:13, 0.555s/it]: train_loss_raw=1.2138, running_loss=1.1516, LR=0.000100
[2025-08-10 16:56:55,772][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038652] [Batch 01732/03692] [00:16:00/00:18:06, 0.554s/it]: train_loss_raw=1.1392, running_loss=1.1501, LR=0.000100
[2025-08-10 16:57:02,574][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038664] [Batch 01744/03692] [00:16:07/00:18:00, 0.555s/it]: train_loss_raw=1.1031, running_loss=1.1529, LR=0.000100
[2025-08-10 16:57:09,138][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038676] [Batch 01756/03692] [00:16:13/00:17:53, 0.555s/it]: train_loss_raw=1.2278, running_loss=1.1552, LR=0.000100
[2025-08-10 16:57:15,640][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038688] [Batch 01768/03692] [00:16:20/00:17:46, 0.554s/it]: train_loss_raw=1.2227, running_loss=1.1588, LR=0.000100
[2025-08-10 16:57:22,016][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038700] [Batch 01780/03692] [00:16:26/00:17:39, 0.554s/it]: train_loss_raw=1.1947, running_loss=1.1584, LR=0.000100
[2025-08-10 16:57:28,305][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038712] [Batch 01792/03692] [00:16:32/00:17:32, 0.554s/it]: train_loss_raw=1.2128, running_loss=1.1601, LR=0.000100
[2025-08-10 16:57:35,077][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038724] [Batch 01804/03692] [00:16:39/00:17:26, 0.554s/it]: train_loss_raw=1.2222, running_loss=1.1590, LR=0.000100
[2025-08-10 16:57:41,634][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038736] [Batch 01816/03692] [00:16:46/00:17:19, 0.554s/it]: train_loss_raw=1.2340, running_loss=1.1630, LR=0.000100
[2025-08-10 16:57:48,057][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038748] [Batch 01828/03692] [00:16:52/00:17:12, 0.554s/it]: train_loss_raw=1.2662, running_loss=1.1634, LR=0.000100
[2025-08-10 16:57:54,343][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038760] [Batch 01840/03692] [00:16:58/00:17:05, 0.554s/it]: train_loss_raw=1.1578, running_loss=1.1638, LR=0.000100
[2025-08-10 16:58:00,346][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038772] [Batch 01852/03692] [00:17:04/00:16:58, 0.553s/it]: train_loss_raw=1.3029, running_loss=1.1616, LR=0.000100
[2025-08-10 16:58:06,759][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038784] [Batch 01864/03692] [00:17:11/00:16:51, 0.553s/it]: train_loss_raw=1.3231, running_loss=1.1608, LR=0.000100
[2025-08-10 16:58:13,083][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038796] [Batch 01876/03692] [00:17:17/00:16:44, 0.553s/it]: train_loss_raw=1.0591, running_loss=1.1581, LR=0.000100
[2025-08-10 16:58:19,350][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038808] [Batch 01888/03692] [00:17:23/00:16:37, 0.553s/it]: train_loss_raw=1.1722, running_loss=1.1571, LR=0.000100
[2025-08-10 16:58:25,456][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038820] [Batch 01900/03692] [00:17:30/00:16:30, 0.553s/it]: train_loss_raw=1.1248, running_loss=1.1567, LR=0.000100
[2025-08-10 16:58:31,483][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038832] [Batch 01912/03692] [00:17:36/00:16:23, 0.552s/it]: train_loss_raw=1.0890, running_loss=1.1605, LR=0.000100
[2025-08-10 16:58:37,876][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038844] [Batch 01924/03692] [00:17:42/00:16:16, 0.552s/it]: train_loss_raw=1.1877, running_loss=1.1590, LR=0.000100
[2025-08-10 16:58:44,022][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038856] [Batch 01936/03692] [00:17:48/00:16:09, 0.552s/it]: train_loss_raw=1.2430, running_loss=1.1588, LR=0.000100
[2025-08-10 16:58:50,449][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038868] [Batch 01948/03692] [00:17:55/00:16:02, 0.552s/it]: train_loss_raw=1.3864, running_loss=1.1628, LR=0.000100
[2025-08-10 16:58:56,505][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038880] [Batch 01960/03692] [00:18:01/00:15:55, 0.552s/it]: train_loss_raw=1.2033, running_loss=1.1639, LR=0.000100
[2025-08-10 16:59:02,588][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038892] [Batch 01972/03692] [00:18:07/00:15:48, 0.551s/it]: train_loss_raw=1.1595, running_loss=1.1673, LR=0.000100
[2025-08-10 16:59:09,030][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038904] [Batch 01984/03692] [00:18:13/00:15:41, 0.551s/it]: train_loss_raw=1.1992, running_loss=1.1712, LR=0.000100
[2025-08-10 16:59:15,448][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038916] [Batch 01996/03692] [00:18:20/00:15:34, 0.551s/it]: train_loss_raw=1.2183, running_loss=1.1741, LR=0.000100
[2025-08-10 16:59:21,979][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038928] [Batch 02008/03692] [00:18:26/00:15:28, 0.551s/it]: train_loss_raw=0.9904, running_loss=1.1684, LR=0.000100
[2025-08-10 16:59:28,480][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038940] [Batch 02020/03692] [00:18:33/00:15:21, 0.551s/it]: train_loss_raw=1.1428, running_loss=1.1664, LR=0.000100
[2025-08-10 16:59:35,188][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038952] [Batch 02032/03692] [00:18:39/00:15:14, 0.551s/it]: train_loss_raw=1.1297, running_loss=1.1631, LR=0.000100
[2025-08-10 16:59:41,781][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038964] [Batch 02044/03692] [00:18:46/00:15:08, 0.551s/it]: train_loss_raw=1.1912, running_loss=1.1647, LR=0.000100
[2025-08-10 16:59:48,423][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038976] [Batch 02056/03692] [00:18:53/00:15:01, 0.551s/it]: train_loss_raw=1.1212, running_loss=1.1667, LR=0.000100
[2025-08-10 16:59:55,049][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 038988] [Batch 02068/03692] [00:18:59/00:14:54, 0.551s/it]: train_loss_raw=1.0876, running_loss=1.1645, LR=0.000100
[2025-08-10 17:00:01,703][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039000] [Batch 02080/03692] [00:19:06/00:14:48, 0.551s/it]: train_loss_raw=0.9682, running_loss=1.1675, LR=0.000100
[2025-08-10 17:00:08,334][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039012] [Batch 02092/03692] [00:19:12/00:14:41, 0.551s/it]: train_loss_raw=1.1883, running_loss=1.1675, LR=0.000100
[2025-08-10 17:00:14,842][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039024] [Batch 02104/03692] [00:19:19/00:14:35, 0.551s/it]: train_loss_raw=1.2274, running_loss=1.1673, LR=0.000100
[2025-08-10 17:00:21,598][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039036] [Batch 02116/03692] [00:19:26/00:14:28, 0.551s/it]: train_loss_raw=1.1745, running_loss=1.1653, LR=0.000100
[2025-08-10 17:00:28,175][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039048] [Batch 02128/03692] [00:19:32/00:14:21, 0.551s/it]: train_loss_raw=1.1124, running_loss=1.1617, LR=0.000100
[2025-08-10 17:00:34,886][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039060] [Batch 02140/03692] [00:19:39/00:14:15, 0.551s/it]: train_loss_raw=1.1687, running_loss=1.1571, LR=0.000100
[2025-08-10 17:00:41,402][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039072] [Batch 02152/03692] [00:19:45/00:14:08, 0.551s/it]: train_loss_raw=1.2802, running_loss=1.1579, LR=0.000100
[2025-08-10 17:00:47,762][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039084] [Batch 02164/03692] [00:19:52/00:14:01, 0.551s/it]: train_loss_raw=1.1399, running_loss=1.1602, LR=0.000100
[2025-08-10 17:00:53,971][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039096] [Batch 02176/03692] [00:19:58/00:13:55, 0.551s/it]: train_loss_raw=1.1536, running_loss=1.1582, LR=0.000100
[2025-08-10 17:01:00,024][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039108] [Batch 02188/03692] [00:20:04/00:13:48, 0.551s/it]: train_loss_raw=1.1139, running_loss=1.1599, LR=0.000100
[2025-08-10 17:01:06,272][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039120] [Batch 02200/03692] [00:20:10/00:13:41, 0.550s/it]: train_loss_raw=1.2174, running_loss=1.1599, LR=0.000100
[2025-08-10 17:01:12,393][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039132] [Batch 02212/03692] [00:20:16/00:13:34, 0.550s/it]: train_loss_raw=1.1099, running_loss=1.1605, LR=0.000100
[2025-08-10 17:01:18,797][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039144] [Batch 02224/03692] [00:20:23/00:13:27, 0.550s/it]: train_loss_raw=0.9912, running_loss=1.1595, LR=0.000100
[2025-08-10 17:01:25,422][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039156] [Batch 02236/03692] [00:20:30/00:13:20, 0.550s/it]: train_loss_raw=1.2547, running_loss=1.1540, LR=0.000100
[2025-08-10 17:01:32,041][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039168] [Batch 02248/03692] [00:20:36/00:13:14, 0.550s/it]: train_loss_raw=1.2849, running_loss=1.1534, LR=0.000100
[2025-08-10 17:01:38,759][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039180] [Batch 02260/03692] [00:20:43/00:13:07, 0.550s/it]: train_loss_raw=1.2136, running_loss=1.1588, LR=0.000100
[2025-08-10 17:01:45,274][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039192] [Batch 02272/03692] [00:20:49/00:13:01, 0.550s/it]: train_loss_raw=1.2825, running_loss=1.1622, LR=0.000100
[2025-08-10 17:01:52,114][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039204] [Batch 02284/03692] [00:20:56/00:12:54, 0.550s/it]: train_loss_raw=1.1491, running_loss=1.1634, LR=0.000100
[2025-08-10 17:01:58,639][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039216] [Batch 02296/03692] [00:21:03/00:12:48, 0.550s/it]: train_loss_raw=1.2017, running_loss=1.1598, LR=0.000100
[2025-08-10 17:02:04,996][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039228] [Batch 02308/03692] [00:21:09/00:12:41, 0.550s/it]: train_loss_raw=1.0876, running_loss=1.1625, LR=0.000100
[2025-08-10 17:02:11,049][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039240] [Batch 02320/03692] [00:21:15/00:12:34, 0.550s/it]: train_loss_raw=1.1716, running_loss=1.1618, LR=0.000100
[2025-08-10 17:02:17,109][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039252] [Batch 02332/03692] [00:21:21/00:12:27, 0.550s/it]: train_loss_raw=1.1528, running_loss=1.1596, LR=0.000100
[2025-08-10 17:02:23,313][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039264] [Batch 02344/03692] [00:21:27/00:12:20, 0.549s/it]: train_loss_raw=1.0751, running_loss=1.1593, LR=0.000100
[2025-08-10 17:02:29,568][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039276] [Batch 02356/03692] [00:21:34/00:12:13, 0.549s/it]: train_loss_raw=1.2147, running_loss=1.1600, LR=0.000100
[2025-08-10 17:02:35,950][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039288] [Batch 02368/03692] [00:21:40/00:12:07, 0.549s/it]: train_loss_raw=1.1655, running_loss=1.1608, LR=0.000100
[2025-08-10 17:02:42,136][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039300] [Batch 02380/03692] [00:21:46/00:12:00, 0.549s/it]: train_loss_raw=1.1503, running_loss=1.1587, LR=0.000100
[2025-08-10 17:02:48,301][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039312] [Batch 02392/03692] [00:21:52/00:11:53, 0.549s/it]: train_loss_raw=1.0242, running_loss=1.1570, LR=0.000100
[2025-08-10 17:02:54,757][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039324] [Batch 02404/03692] [00:21:59/00:11:46, 0.549s/it]: train_loss_raw=1.1235, running_loss=1.1561, LR=0.000100
[2025-08-10 17:03:01,157][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039336] [Batch 02416/03692] [00:22:05/00:11:40, 0.549s/it]: train_loss_raw=1.2225, running_loss=1.1601, LR=0.000100
[2025-08-10 17:03:07,507][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039348] [Batch 02428/03692] [00:22:12/00:11:33, 0.549s/it]: train_loss_raw=1.0666, running_loss=1.1578, LR=0.000100
[2025-08-10 17:03:13,765][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039360] [Batch 02440/03692] [00:22:18/00:11:26, 0.549s/it]: train_loss_raw=1.1084, running_loss=1.1553, LR=0.000100
[2025-08-10 17:03:20,065][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039372] [Batch 02452/03692] [00:22:24/00:11:20, 0.548s/it]: train_loss_raw=1.2176, running_loss=1.1511, LR=0.000100
[2025-08-10 17:03:26,251][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039384] [Batch 02464/03692] [00:22:30/00:11:13, 0.548s/it]: train_loss_raw=1.0643, running_loss=1.1495, LR=0.000100
[2025-08-10 17:03:32,668][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039396] [Batch 02476/03692] [00:22:37/00:11:06, 0.548s/it]: train_loss_raw=1.1322, running_loss=1.1478, LR=0.000100
[2025-08-10 17:03:39,143][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039408] [Batch 02488/03692] [00:22:43/00:10:59, 0.548s/it]: train_loss_raw=1.1516, running_loss=1.1499, LR=0.000100
[2025-08-10 17:03:45,411][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039420] [Batch 02500/03692] [00:22:50/00:10:53, 0.548s/it]: train_loss_raw=1.0757, running_loss=1.1519, LR=0.000100
[2025-08-10 17:03:51,768][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039432] [Batch 02512/03692] [00:22:56/00:10:46, 0.548s/it]: train_loss_raw=1.1969, running_loss=1.1480, LR=0.000100
[2025-08-10 17:03:57,872][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039444] [Batch 02524/03692] [00:23:02/00:10:39, 0.548s/it]: train_loss_raw=1.1413, running_loss=1.1427, LR=0.000100
[2025-08-10 17:04:04,052][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039456] [Batch 02536/03692] [00:23:08/00:10:32, 0.548s/it]: train_loss_raw=1.1457, running_loss=1.1407, LR=0.000100
[2025-08-10 17:04:10,480][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039468] [Batch 02548/03692] [00:23:15/00:10:26, 0.548s/it]: train_loss_raw=1.1113, running_loss=1.1373, LR=0.000100
[2025-08-10 17:04:16,586][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039480] [Batch 02560/03692] [00:23:21/00:10:19, 0.547s/it]: train_loss_raw=1.0388, running_loss=1.1398, LR=0.000100
[2025-08-10 17:04:23,111][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039492] [Batch 02572/03692] [00:23:27/00:10:12, 0.547s/it]: train_loss_raw=1.0921, running_loss=1.1398, LR=0.000100
[2025-08-10 17:04:29,242][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039504] [Batch 02584/03692] [00:23:33/00:10:06, 0.547s/it]: train_loss_raw=1.0558, running_loss=1.1399, LR=0.000100
[2025-08-10 17:04:35,654][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039516] [Batch 02596/03692] [00:23:40/00:09:59, 0.547s/it]: train_loss_raw=1.1037, running_loss=1.1401, LR=0.000100
[2025-08-10 17:04:42,120][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039528] [Batch 02608/03692] [00:23:46/00:09:53, 0.547s/it]: train_loss_raw=1.1271, running_loss=1.1431, LR=0.000100
[2025-08-10 17:04:48,599][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039540] [Batch 02620/03692] [00:23:53/00:09:46, 0.547s/it]: train_loss_raw=1.0933, running_loss=1.1425, LR=0.000100
[2025-08-10 17:04:54,869][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039552] [Batch 02632/03692] [00:23:59/00:09:39, 0.547s/it]: train_loss_raw=1.2046, running_loss=1.1436, LR=0.000100
[2025-08-10 17:05:01,451][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039564] [Batch 02644/03692] [00:24:06/00:09:33, 0.547s/it]: train_loss_raw=1.2562, running_loss=1.1448, LR=0.000100
[2025-08-10 17:05:07,984][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039576] [Batch 02656/03692] [00:24:12/00:09:26, 0.547s/it]: train_loss_raw=1.0744, running_loss=1.1427, LR=0.000100
[2025-08-10 17:05:14,486][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039588] [Batch 02668/03692] [00:24:19/00:09:20, 0.547s/it]: train_loss_raw=1.0275, running_loss=1.1406, LR=0.000100
[2025-08-10 17:05:20,996][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039600] [Batch 02680/03692] [00:24:25/00:09:13, 0.547s/it]: train_loss_raw=1.0372, running_loss=1.1406, LR=0.000100
[2025-08-10 17:05:27,192][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039612] [Batch 02692/03692] [00:24:31/00:09:06, 0.547s/it]: train_loss_raw=1.1082, running_loss=1.1422, LR=0.000100
[2025-08-10 17:05:33,415][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039624] [Batch 02704/03692] [00:24:38/00:09:00, 0.547s/it]: train_loss_raw=1.2716, running_loss=1.1453, LR=0.000100
[2025-08-10 17:05:39,520][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039636] [Batch 02716/03692] [00:24:44/00:08:53, 0.546s/it]: train_loss_raw=1.1219, running_loss=1.1428, LR=0.000100
[2025-08-10 17:05:45,734][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039648] [Batch 02728/03692] [00:24:50/00:08:46, 0.546s/it]: train_loss_raw=1.1310, running_loss=1.1434, LR=0.000100
[2025-08-10 17:05:51,980][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039660] [Batch 02740/03692] [00:24:56/00:08:39, 0.546s/it]: train_loss_raw=1.0870, running_loss=1.1466, LR=0.000100
[2025-08-10 17:05:58,212][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039672] [Batch 02752/03692] [00:25:02/00:08:33, 0.546s/it]: train_loss_raw=1.0665, running_loss=1.1468, LR=0.000100
[2025-08-10 17:06:04,606][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039684] [Batch 02764/03692] [00:25:09/00:08:26, 0.546s/it]: train_loss_raw=1.1369, running_loss=1.1469, LR=0.000100
[2025-08-10 17:06:10,940][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039696] [Batch 02776/03692] [00:25:15/00:08:20, 0.546s/it]: train_loss_raw=1.0799, running_loss=1.1455, LR=0.000100
[2025-08-10 17:06:17,380][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039708] [Batch 02788/03692] [00:25:21/00:08:13, 0.546s/it]: train_loss_raw=1.2158, running_loss=1.1443, LR=0.000100
[2025-08-10 17:06:23,836][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039720] [Batch 02800/03692] [00:25:28/00:08:06, 0.546s/it]: train_loss_raw=1.0725, running_loss=1.1406, LR=0.000100
[2025-08-10 17:06:30,227][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039732] [Batch 02812/03692] [00:25:34/00:08:00, 0.546s/it]: train_loss_raw=1.1348, running_loss=1.1406, LR=0.000100
[2025-08-10 17:06:36,681][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039744] [Batch 02824/03692] [00:25:41/00:07:53, 0.546s/it]: train_loss_raw=1.1233, running_loss=1.1388, LR=0.000100
[2025-08-10 17:06:43,074][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039756] [Batch 02836/03692] [00:25:47/00:07:47, 0.546s/it]: train_loss_raw=1.1943, running_loss=1.1429, LR=0.000100
[2025-08-10 17:06:49,306][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039768] [Batch 02848/03692] [00:25:53/00:07:40, 0.546s/it]: train_loss_raw=1.1467, running_loss=1.1436, LR=0.000100
[2025-08-10 17:06:55,296][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039780] [Batch 02860/03692] [00:25:59/00:07:33, 0.545s/it]: train_loss_raw=1.0885, running_loss=1.1433, LR=0.000100
[2025-08-10 17:07:01,331][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039792] [Batch 02872/03692] [00:26:05/00:07:27, 0.545s/it]: train_loss_raw=1.2128, running_loss=1.1457, LR=0.000100
[2025-08-10 17:07:07,462][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039804] [Batch 02884/03692] [00:26:12/00:07:20, 0.545s/it]: train_loss_raw=1.1834, running_loss=1.1451, LR=0.000100
[2025-08-10 17:07:13,596][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039816] [Batch 02896/03692] [00:26:18/00:07:13, 0.545s/it]: train_loss_raw=1.1154, running_loss=1.1466, LR=0.000100
[2025-08-10 17:07:19,769][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039828] [Batch 02908/03692] [00:26:24/00:07:07, 0.545s/it]: train_loss_raw=1.1802, running_loss=1.1496, LR=0.000100
[2025-08-10 17:07:26,021][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039840] [Batch 02920/03692] [00:26:30/00:07:00, 0.545s/it]: train_loss_raw=1.1913, running_loss=1.1493, LR=0.000100
[2025-08-10 17:07:32,513][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039852] [Batch 02932/03692] [00:26:37/00:06:53, 0.545s/it]: train_loss_raw=1.1422, running_loss=1.1480, LR=0.000100
[2025-08-10 17:07:38,690][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039864] [Batch 02944/03692] [00:26:43/00:06:47, 0.545s/it]: train_loss_raw=1.2312, running_loss=1.1486, LR=0.000100
[2025-08-10 17:07:44,833][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039876] [Batch 02956/03692] [00:26:49/00:06:40, 0.544s/it]: train_loss_raw=1.2257, running_loss=1.1500, LR=0.000100
[2025-08-10 17:07:51,012][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039888] [Batch 02968/03692] [00:26:55/00:06:34, 0.544s/it]: train_loss_raw=1.0209, running_loss=1.1437, LR=0.000100
[2025-08-10 17:07:57,043][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039900] [Batch 02980/03692] [00:27:01/00:06:27, 0.544s/it]: train_loss_raw=1.1715, running_loss=1.1417, LR=0.000100
[2025-08-10 17:08:03,142][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039912] [Batch 02992/03692] [00:27:07/00:06:20, 0.544s/it]: train_loss_raw=1.0775, running_loss=1.1441, LR=0.000100
[2025-08-10 17:08:09,226][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039924] [Batch 03004/03692] [00:27:13/00:06:14, 0.544s/it]: train_loss_raw=1.1572, running_loss=1.1410, LR=0.000100
[2025-08-10 17:08:15,223][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039936] [Batch 03016/03692] [00:27:19/00:06:07, 0.544s/it]: train_loss_raw=1.2281, running_loss=1.1447, LR=0.000100
[2025-08-10 17:08:21,390][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039948] [Batch 03028/03692] [00:27:25/00:06:00, 0.544s/it]: train_loss_raw=1.1537, running_loss=1.1433, LR=0.000100
[2025-08-10 17:08:27,433][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039960] [Batch 03040/03692] [00:27:32/00:05:54, 0.543s/it]: train_loss_raw=1.3463, running_loss=1.1401, LR=0.000100
[2025-08-10 17:08:33,597][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039972] [Batch 03052/03692] [00:27:38/00:05:47, 0.543s/it]: train_loss_raw=1.1126, running_loss=1.1349, LR=0.000100
[2025-08-10 17:08:40,133][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039984] [Batch 03064/03692] [00:27:44/00:05:41, 0.543s/it]: train_loss_raw=1.1647, running_loss=1.1359, LR=0.000100
[2025-08-10 17:08:46,760][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 039996] [Batch 03076/03692] [00:27:51/00:05:34, 0.543s/it]: train_loss_raw=1.1236, running_loss=1.1347, LR=0.000100
[2025-08-10 17:08:58,736][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040008] [Batch 03088/03692] [00:28:03/00:05:29, 0.545s/it]: train_loss_raw=1.0674, running_loss=1.1333, LR=0.000100
[2025-08-10 17:09:05,301][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040020] [Batch 03100/03692] [00:28:09/00:05:22, 0.545s/it]: train_loss_raw=1.0298, running_loss=1.1322, LR=0.000100
[2025-08-10 17:09:11,807][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040032] [Batch 03112/03692] [00:28:16/00:05:16, 0.545s/it]: train_loss_raw=1.1797, running_loss=1.1328, LR=0.000100
[2025-08-10 17:09:18,483][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040044] [Batch 03124/03692] [00:28:23/00:05:09, 0.545s/it]: train_loss_raw=1.1610, running_loss=1.1340, LR=0.000100
[2025-08-10 17:09:25,092][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040056] [Batch 03136/03692] [00:28:29/00:05:03, 0.545s/it]: train_loss_raw=0.9801, running_loss=1.1358, LR=0.000100
[2025-08-10 17:09:31,596][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040068] [Batch 03148/03692] [00:28:36/00:04:56, 0.545s/it]: train_loss_raw=1.1034, running_loss=1.1404, LR=0.000100
[2025-08-10 17:09:38,093][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040080] [Batch 03160/03692] [00:28:42/00:04:50, 0.545s/it]: train_loss_raw=1.1958, running_loss=1.1408, LR=0.000100
[2025-08-10 17:09:44,666][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040092] [Batch 03172/03692] [00:28:49/00:04:43, 0.545s/it]: train_loss_raw=1.1199, running_loss=1.1425, LR=0.000100
[2025-08-10 17:09:51,267][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040104] [Batch 03184/03692] [00:28:55/00:04:36, 0.545s/it]: train_loss_raw=1.1495, running_loss=1.1440, LR=0.000100
[2025-08-10 17:09:57,637][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040116] [Batch 03196/03692] [00:29:02/00:04:30, 0.545s/it]: train_loss_raw=1.1082, running_loss=1.1424, LR=0.000100
[2025-08-10 17:10:03,784][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040128] [Batch 03208/03692] [00:29:08/00:04:23, 0.545s/it]: train_loss_raw=1.0968, running_loss=1.1420, LR=0.000100
[2025-08-10 17:10:09,780][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040140] [Batch 03220/03692] [00:29:14/00:04:17, 0.545s/it]: train_loss_raw=1.1219, running_loss=1.1422, LR=0.000100
[2025-08-10 17:10:15,841][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040152] [Batch 03232/03692] [00:29:20/00:04:10, 0.545s/it]: train_loss_raw=1.1392, running_loss=1.1453, LR=0.000100
[2025-08-10 17:10:21,970][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040164] [Batch 03244/03692] [00:29:26/00:04:03, 0.545s/it]: train_loss_raw=1.2787, running_loss=1.1478, LR=0.000100
[2025-08-10 17:10:28,136][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040176] [Batch 03256/03692] [00:29:32/00:03:57, 0.544s/it]: train_loss_raw=1.1908, running_loss=1.1474, LR=0.000100
[2025-08-10 17:10:34,292][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040188] [Batch 03268/03692] [00:29:38/00:03:50, 0.544s/it]: train_loss_raw=1.0985, running_loss=1.1493, LR=0.000100
[2025-08-10 17:10:40,342][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040200] [Batch 03280/03692] [00:29:44/00:03:44, 0.544s/it]: train_loss_raw=1.0580, running_loss=1.1462, LR=0.000100
[2025-08-10 17:10:46,427][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040212] [Batch 03292/03692] [00:29:51/00:03:37, 0.544s/it]: train_loss_raw=1.1883, running_loss=1.1481, LR=0.000100
[2025-08-10 17:10:52,503][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040224] [Batch 03304/03692] [00:29:57/00:03:31, 0.544s/it]: train_loss_raw=1.1979, running_loss=1.1489, LR=0.000100
[2025-08-10 17:10:58,663][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040236] [Batch 03316/03692] [00:30:03/00:03:24, 0.544s/it]: train_loss_raw=1.1036, running_loss=1.1490, LR=0.000100
[2025-08-10 17:11:04,885][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040248] [Batch 03328/03692] [00:30:09/00:03:17, 0.544s/it]: train_loss_raw=1.0635, running_loss=1.1495, LR=0.000100
[2025-08-10 17:11:11,075][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040260] [Batch 03340/03692] [00:30:15/00:03:11, 0.544s/it]: train_loss_raw=0.9718, running_loss=1.1487, LR=0.000100
[2025-08-10 17:11:17,084][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040272] [Batch 03352/03692] [00:30:21/00:03:04, 0.543s/it]: train_loss_raw=1.0697, running_loss=1.1451, LR=0.000100
[2025-08-10 17:11:23,239][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040284] [Batch 03364/03692] [00:30:27/00:02:58, 0.543s/it]: train_loss_raw=1.0178, running_loss=1.1437, LR=0.000100
[2025-08-10 17:11:29,312][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040296] [Batch 03376/03692] [00:30:33/00:02:51, 0.543s/it]: train_loss_raw=1.1439, running_loss=1.1389, LR=0.000100
[2025-08-10 17:11:35,741][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040308] [Batch 03388/03692] [00:30:40/00:02:45, 0.543s/it]: train_loss_raw=1.1702, running_loss=1.1390, LR=0.000100
[2025-08-10 17:11:42,050][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040320] [Batch 03400/03692] [00:30:46/00:02:38, 0.543s/it]: train_loss_raw=1.1357, running_loss=1.1415, LR=0.000100
[2025-08-10 17:11:48,253][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040332] [Batch 03412/03692] [00:30:52/00:02:32, 0.543s/it]: train_loss_raw=1.0674, running_loss=1.1424, LR=0.000100
[2025-08-10 17:11:54,300][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040344] [Batch 03424/03692] [00:30:58/00:02:25, 0.543s/it]: train_loss_raw=0.9859, running_loss=1.1407, LR=0.000100
[2025-08-10 17:12:00,342][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040356] [Batch 03436/03692] [00:31:04/00:02:18, 0.543s/it]: train_loss_raw=1.0990, running_loss=1.1388, LR=0.000100
[2025-08-10 17:12:06,529][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040368] [Batch 03448/03692] [00:31:11/00:02:12, 0.543s/it]: train_loss_raw=1.2498, running_loss=1.1390, LR=0.000100
[2025-08-10 17:12:12,627][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040380] [Batch 03460/03692] [00:31:17/00:02:05, 0.543s/it]: train_loss_raw=1.2763, running_loss=1.1382, LR=0.000100
[2025-08-10 17:12:18,709][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040392] [Batch 03472/03692] [00:31:23/00:01:59, 0.542s/it]: train_loss_raw=1.1111, running_loss=1.1356, LR=0.000100
[2025-08-10 17:12:24,850][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040404] [Batch 03484/03692] [00:31:29/00:01:52, 0.542s/it]: train_loss_raw=1.1617, running_loss=1.1387, LR=0.000100
[2025-08-10 17:12:31,279][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040416] [Batch 03496/03692] [00:31:35/00:01:46, 0.542s/it]: train_loss_raw=1.1907, running_loss=1.1359, LR=0.000100
[2025-08-10 17:12:37,855][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040428] [Batch 03508/03692] [00:31:42/00:01:39, 0.542s/it]: train_loss_raw=1.0446, running_loss=1.1353, LR=0.000100
[2025-08-10 17:12:44,117][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040440] [Batch 03520/03692] [00:31:48/00:01:33, 0.542s/it]: train_loss_raw=1.1300, running_loss=1.1341, LR=0.000100
[2025-08-10 17:12:50,634][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040452] [Batch 03532/03692] [00:31:55/00:01:26, 0.542s/it]: train_loss_raw=1.2031, running_loss=1.1378, LR=0.000100
[2025-08-10 17:12:57,050][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040464] [Batch 03544/03692] [00:32:01/00:01:20, 0.542s/it]: train_loss_raw=1.1040, running_loss=1.1404, LR=0.000100
[2025-08-10 17:13:03,407][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040476] [Batch 03556/03692] [00:32:07/00:01:13, 0.542s/it]: train_loss_raw=1.3053, running_loss=1.1424, LR=0.000100
[2025-08-10 17:13:09,795][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040488] [Batch 03568/03692] [00:32:14/00:01:07, 0.542s/it]: train_loss_raw=1.0450, running_loss=1.1429, LR=0.000100
[2025-08-10 17:13:16,209][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040500] [Batch 03580/03692] [00:32:20/00:01:00, 0.542s/it]: train_loss_raw=1.2147, running_loss=1.1441, LR=0.000100
[2025-08-10 17:13:22,676][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040512] [Batch 03592/03692] [00:32:27/00:00:54, 0.542s/it]: train_loss_raw=1.2299, running_loss=1.1423, LR=0.000100
[2025-08-10 17:13:29,041][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040524] [Batch 03604/03692] [00:32:33/00:00:47, 0.542s/it]: train_loss_raw=1.1543, running_loss=1.1472, LR=0.000100
[2025-08-10 17:13:35,431][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040536] [Batch 03616/03692] [00:32:40/00:00:41, 0.542s/it]: train_loss_raw=1.0860, running_loss=1.1472, LR=0.000100
[2025-08-10 17:13:41,997][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040548] [Batch 03628/03692] [00:32:46/00:00:34, 0.542s/it]: train_loss_raw=1.1983, running_loss=1.1478, LR=0.000100
[2025-08-10 17:13:48,361][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040560] [Batch 03640/03692] [00:32:52/00:00:28, 0.542s/it]: train_loss_raw=1.1227, running_loss=1.1436, LR=0.000100
[2025-08-10 17:13:54,753][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040572] [Batch 03652/03692] [00:32:59/00:00:21, 0.542s/it]: train_loss_raw=1.0846, running_loss=1.1405, LR=0.000100
[2025-08-10 17:14:01,157][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040584] [Batch 03664/03692] [00:33:05/00:00:15, 0.542s/it]: train_loss_raw=1.0859, running_loss=1.1352, LR=0.000100
[2025-08-10 17:14:07,462][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040596] [Batch 03676/03692] [00:33:12/00:00:08, 0.542s/it]: train_loss_raw=1.2143, running_loss=1.1358, LR=0.000100
[2025-08-10 17:14:14,102][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 040608] [Batch 03688/03692] [00:33:18/00:00:02, 0.542s/it]: train_loss_raw=1.1914, running_loss=1.1361, LR=0.000100
[2025-08-10 17:14:21,749][__main__][INFO] - [VALIDATION] [Epoch 10/29] Starting validation.
[2025-08-10 17:14:57,017][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 040613] [Batch 00011/00025] [00:00:35/00:00:38, 2.939s/it]
[2025-08-10 17:15:14,774][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 040613] [Batch 00023/00025] [00:00:53/00:00:02, 2.209s/it]
[2025-08-10 17:15:16,041][__main__][INFO] - [VALIDATION] [Epoch 10/29] train_loss=1.13640, valid_loss=1.12461
[2025-08-10 17:15:16,041][__main__][INFO] - [VALIDATION] [Epoch 10/29] Metrics:
[2025-08-10 17:15:16,041][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_er      0.484
[2025-08-10 17:15:16,041][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_prec    0.259
[2025-08-10 17:15:16,041][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_recall  0.267
[2025-08-10 17:15:16,042][__main__][INFO] - [VALIDATION] [Epoch 10/29] - pep_recall 0.234
[2025-08-10 17:15:16,045][__main__][INFO] - [TRAIN] [Epoch 10/29] Epoch complete, total time 06:19:15, remaining time 10:55:04, 00:34:28 per epoch
[2025-08-10 17:15:21,162][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040620] [Batch 00008/03692] [00:00:03/00:29:52, 0.487s/it]: train_loss_raw=1.2220, running_loss=1.1329, LR=0.000100
[2025-08-10 17:15:27,739][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040632] [Batch 00020/03692] [00:00:10/00:32:02, 0.524s/it]: train_loss_raw=1.2236, running_loss=1.1391, LR=0.000100
[2025-08-10 17:15:34,136][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040644] [Batch 00032/03692] [00:00:16/00:32:09, 0.527s/it]: train_loss_raw=1.2002, running_loss=1.1382, LR=0.000100
[2025-08-10 17:15:40,614][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040656] [Batch 00044/03692] [00:00:23/00:32:15, 0.531s/it]: train_loss_raw=1.1440, running_loss=1.1419, LR=0.000100
[2025-08-10 17:15:47,129][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040668] [Batch 00056/03692] [00:00:29/00:32:18, 0.533s/it]: train_loss_raw=1.1535, running_loss=1.1405, LR=0.000100
[2025-08-10 17:15:53,434][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040680] [Batch 00068/03692] [00:00:36/00:32:07, 0.532s/it]: train_loss_raw=1.1238, running_loss=1.1384, LR=0.000100
[2025-08-10 17:15:59,721][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040692] [Batch 00080/03692] [00:00:42/00:31:56, 0.531s/it]: train_loss_raw=1.1353, running_loss=1.1399, LR=0.000100
[2025-08-10 17:16:05,894][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040704] [Batch 00092/03692] [00:00:48/00:31:42, 0.529s/it]: train_loss_raw=1.1071, running_loss=1.1419, LR=0.000100
[2025-08-10 17:16:12,177][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040716] [Batch 00104/03692] [00:00:54/00:31:34, 0.528s/it]: train_loss_raw=1.2787, running_loss=1.1454, LR=0.000100
[2025-08-10 17:16:18,388][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040728] [Batch 00116/03692] [00:01:01/00:31:24, 0.527s/it]: train_loss_raw=1.1254, running_loss=1.1463, LR=0.000100
[2025-08-10 17:16:24,686][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040740] [Batch 00128/03692] [00:01:07/00:31:17, 0.527s/it]: train_loss_raw=1.3337, running_loss=1.1439, LR=0.000100
[2025-08-10 17:16:30,933][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040752] [Batch 00140/03692] [00:01:13/00:31:08, 0.526s/it]: train_loss_raw=1.0903, running_loss=1.1424, LR=0.000100
[2025-08-10 17:16:37,349][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040764] [Batch 00152/03692] [00:01:20/00:31:05, 0.527s/it]: train_loss_raw=1.1098, running_loss=1.1413, LR=0.000100
[2025-08-10 17:16:43,803][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040776] [Batch 00164/03692] [00:01:26/00:31:01, 0.528s/it]: train_loss_raw=1.1479, running_loss=1.1439, LR=0.000100
[2025-08-10 17:16:50,077][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040788] [Batch 00176/03692] [00:01:32/00:30:54, 0.527s/it]: train_loss_raw=1.2273, running_loss=1.1450, LR=0.000100
[2025-08-10 17:16:56,242][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040800] [Batch 00188/03692] [00:01:38/00:30:44, 0.526s/it]: train_loss_raw=1.1191, running_loss=1.1443, LR=0.000100
[2025-08-10 17:17:02,551][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040812] [Batch 00200/03692] [00:01:45/00:30:38, 0.526s/it]: train_loss_raw=1.2591, running_loss=1.1438, LR=0.000100
[2025-08-10 17:17:09,249][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040824] [Batch 00212/03692] [00:01:51/00:30:38, 0.528s/it]: train_loss_raw=1.1104, running_loss=1.1431, LR=0.000100
[2025-08-10 17:17:15,771][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040836] [Batch 00224/03692] [00:01:58/00:30:34, 0.529s/it]: train_loss_raw=1.1624, running_loss=1.1419, LR=0.000100
[2025-08-10 17:17:22,156][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040848] [Batch 00236/03692] [00:02:04/00:30:28, 0.529s/it]: train_loss_raw=1.0284, running_loss=1.1345, LR=0.000100
[2025-08-10 17:17:28,332][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040860] [Batch 00248/03692] [00:02:11/00:30:20, 0.528s/it]: train_loss_raw=1.2009, running_loss=1.1362, LR=0.000100
[2025-08-10 17:17:34,379][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040872] [Batch 00260/03692] [00:02:17/00:30:09, 0.527s/it]: train_loss_raw=1.1580, running_loss=1.1363, LR=0.000100
[2025-08-10 17:17:40,901][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040884] [Batch 00272/03692] [00:02:23/00:30:05, 0.528s/it]: train_loss_raw=1.0853, running_loss=1.1396, LR=0.000100
[2025-08-10 17:17:47,417][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040896] [Batch 00284/03692] [00:02:30/00:30:01, 0.529s/it]: train_loss_raw=1.1069, running_loss=1.1402, LR=0.000100
[2025-08-10 17:17:54,045][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040908] [Batch 00296/03692] [00:02:36/00:29:58, 0.530s/it]: train_loss_raw=1.2257, running_loss=1.1393, LR=0.000100
[2025-08-10 17:18:00,284][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040920] [Batch 00308/03692] [00:02:43/00:29:51, 0.529s/it]: train_loss_raw=1.0985, running_loss=1.1331, LR=0.000100
[2025-08-10 17:18:06,589][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040932] [Batch 00320/03692] [00:02:49/00:29:44, 0.529s/it]: train_loss_raw=1.1114, running_loss=1.1305, LR=0.000100
[2025-08-10 17:18:12,754][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040944] [Batch 00332/03692] [00:02:55/00:29:35, 0.529s/it]: train_loss_raw=1.0401, running_loss=1.1347, LR=0.000100
[2025-08-10 17:18:18,911][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040956] [Batch 00344/03692] [00:03:01/00:29:27, 0.528s/it]: train_loss_raw=1.1463, running_loss=1.1348, LR=0.000100
[2025-08-10 17:18:25,032][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040968] [Batch 00356/03692] [00:03:07/00:29:19, 0.527s/it]: train_loss_raw=1.1039, running_loss=1.1338, LR=0.000100
[2025-08-10 17:18:31,163][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040980] [Batch 00368/03692] [00:03:13/00:29:11, 0.527s/it]: train_loss_raw=1.0885, running_loss=1.1346, LR=0.000100
[2025-08-10 17:18:37,274][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 040992] [Batch 00380/03692] [00:03:20/00:29:03, 0.526s/it]: train_loss_raw=1.0953, running_loss=1.1330, LR=0.000100
[2025-08-10 17:18:43,463][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041004] [Batch 00392/03692] [00:03:26/00:28:55, 0.526s/it]: train_loss_raw=1.2078, running_loss=1.1331, LR=0.000100
[2025-08-10 17:18:49,679][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041016] [Batch 00404/03692] [00:03:32/00:28:48, 0.526s/it]: train_loss_raw=1.1086, running_loss=1.1334, LR=0.000100
[2025-08-10 17:18:56,081][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041028] [Batch 00416/03692] [00:03:38/00:28:43, 0.526s/it]: train_loss_raw=1.1632, running_loss=1.1354, LR=0.000100
[2025-08-10 17:19:02,484][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041040] [Batch 00428/03692] [00:03:45/00:28:37, 0.526s/it]: train_loss_raw=1.0217, running_loss=1.1342, LR=0.000100
[2025-08-10 17:19:08,942][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041052] [Batch 00440/03692] [00:03:51/00:28:32, 0.527s/it]: train_loss_raw=1.1448, running_loss=1.1311, LR=0.000100
[2025-08-10 17:19:15,412][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041064] [Batch 00452/03692] [00:03:58/00:28:27, 0.527s/it]: train_loss_raw=1.0993, running_loss=1.1287, LR=0.000100
[2025-08-10 17:19:21,976][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041076] [Batch 00464/03692] [00:04:04/00:28:22, 0.527s/it]: train_loss_raw=1.1682, running_loss=1.1271, LR=0.000100
[2025-08-10 17:19:28,508][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041088] [Batch 00476/03692] [00:04:11/00:28:17, 0.528s/it]: train_loss_raw=1.0781, running_loss=1.1235, LR=0.000100
[2025-08-10 17:19:34,550][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041100] [Batch 00488/03692] [00:04:17/00:28:09, 0.527s/it]: train_loss_raw=1.1950, running_loss=1.1261, LR=0.000100
[2025-08-10 17:19:40,562][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041112] [Batch 00500/03692] [00:04:23/00:28:00, 0.527s/it]: train_loss_raw=1.0899, running_loss=1.1236, LR=0.000100
[2025-08-10 17:19:46,793][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041124] [Batch 00512/03692] [00:04:29/00:27:53, 0.526s/it]: train_loss_raw=1.1029, running_loss=1.1240, LR=0.000100
[2025-08-10 17:19:52,939][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041136] [Batch 00524/03692] [00:04:35/00:27:46, 0.526s/it]: train_loss_raw=1.0280, running_loss=1.1205, LR=0.000100
[2025-08-10 17:19:59,286][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041148] [Batch 00536/03692] [00:04:42/00:27:40, 0.526s/it]: train_loss_raw=1.0342, running_loss=1.1211, LR=0.000100
[2025-08-10 17:20:05,532][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041160] [Batch 00548/03692] [00:04:48/00:27:33, 0.526s/it]: train_loss_raw=1.0526, running_loss=1.1208, LR=0.000100
[2025-08-10 17:20:11,699][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041172] [Batch 00560/03692] [00:04:54/00:27:26, 0.526s/it]: train_loss_raw=1.0875, running_loss=1.1191, LR=0.000100
[2025-08-10 17:20:17,749][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041184] [Batch 00572/03692] [00:05:00/00:27:18, 0.525s/it]: train_loss_raw=1.1414, running_loss=1.1178, LR=0.000100
[2025-08-10 17:20:23,813][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041196] [Batch 00584/03692] [00:05:06/00:27:11, 0.525s/it]: train_loss_raw=1.1187, running_loss=1.1179, LR=0.000100
[2025-08-10 17:20:29,991][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041208] [Batch 00596/03692] [00:05:12/00:27:04, 0.525s/it]: train_loss_raw=1.0021, running_loss=1.1200, LR=0.000100
[2025-08-10 17:20:36,559][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041220] [Batch 00608/03692] [00:05:19/00:26:59, 0.525s/it]: train_loss_raw=1.2284, running_loss=1.1217, LR=0.000100
[2025-08-10 17:20:43,129][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041232] [Batch 00620/03692] [00:05:25/00:26:54, 0.526s/it]: train_loss_raw=1.0860, running_loss=1.1182, LR=0.000100
[2025-08-10 17:20:49,690][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041244] [Batch 00632/03692] [00:05:32/00:26:49, 0.526s/it]: train_loss_raw=1.2061, running_loss=1.1185, LR=0.000100
[2025-08-10 17:20:56,135][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041256] [Batch 00644/03692] [00:05:38/00:26:43, 0.526s/it]: train_loss_raw=1.0815, running_loss=1.1210, LR=0.000100
[2025-08-10 17:21:02,278][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041268] [Batch 00656/03692] [00:05:45/00:26:36, 0.526s/it]: train_loss_raw=1.1202, running_loss=1.1183, LR=0.000100
[2025-08-10 17:21:08,453][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041280] [Batch 00668/03692] [00:05:51/00:26:29, 0.526s/it]: train_loss_raw=0.9233, running_loss=1.1167, LR=0.000100
[2025-08-10 17:21:14,872][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041292] [Batch 00680/03692] [00:05:57/00:26:23, 0.526s/it]: train_loss_raw=1.3177, running_loss=1.1215, LR=0.000100
[2025-08-10 17:21:21,347][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041304] [Batch 00692/03692] [00:06:04/00:26:18, 0.526s/it]: train_loss_raw=1.1565, running_loss=1.1233, LR=0.000100
[2025-08-10 17:21:27,397][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041316] [Batch 00704/03692] [00:06:10/00:26:10, 0.526s/it]: train_loss_raw=1.1453, running_loss=1.1203, LR=0.000100
[2025-08-10 17:21:33,502][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041328] [Batch 00716/03692] [00:06:16/00:26:03, 0.525s/it]: train_loss_raw=1.0399, running_loss=1.1174, LR=0.000100
[2025-08-10 17:21:39,685][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041340] [Batch 00728/03692] [00:06:22/00:25:56, 0.525s/it]: train_loss_raw=1.3081, running_loss=1.1177, LR=0.000100
[2025-08-10 17:21:46,221][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041352] [Batch 00740/03692] [00:06:28/00:25:51, 0.526s/it]: train_loss_raw=1.0547, running_loss=1.1174, LR=0.000100
[2025-08-10 17:21:52,929][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041364] [Batch 00752/03692] [00:06:35/00:25:46, 0.526s/it]: train_loss_raw=1.3316, running_loss=1.1164, LR=0.000100
[2025-08-10 17:21:59,529][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041376] [Batch 00764/03692] [00:06:42/00:25:41, 0.527s/it]: train_loss_raw=1.1433, running_loss=1.1175, LR=0.000100
[2025-08-10 17:22:05,780][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041388] [Batch 00776/03692] [00:06:48/00:25:35, 0.526s/it]: train_loss_raw=1.1263, running_loss=1.1192, LR=0.000100
[2025-08-10 17:22:11,934][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041400] [Batch 00788/03692] [00:06:54/00:25:28, 0.526s/it]: train_loss_raw=1.2016, running_loss=1.1137, LR=0.000100
[2025-08-10 17:22:18,337][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041412] [Batch 00800/03692] [00:07:01/00:25:22, 0.526s/it]: train_loss_raw=0.9938, running_loss=1.1115, LR=0.000100
[2025-08-10 17:22:24,653][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041424] [Batch 00812/03692] [00:07:07/00:25:15, 0.526s/it]: train_loss_raw=1.0932, running_loss=1.1123, LR=0.000100
[2025-08-10 17:22:30,850][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041436] [Batch 00824/03692] [00:07:13/00:25:09, 0.526s/it]: train_loss_raw=1.1094, running_loss=1.1168, LR=0.000100
[2025-08-10 17:22:37,133][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041448] [Batch 00836/03692] [00:07:19/00:25:02, 0.526s/it]: train_loss_raw=1.1387, running_loss=1.1141, LR=0.000100
[2025-08-10 17:22:43,344][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041460] [Batch 00848/03692] [00:07:26/00:24:56, 0.526s/it]: train_loss_raw=1.1685, running_loss=1.1167, LR=0.000100
[2025-08-10 17:22:49,828][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041472] [Batch 00860/03692] [00:07:32/00:24:50, 0.526s/it]: train_loss_raw=1.1045, running_loss=1.1169, LR=0.000100
[2025-08-10 17:22:56,221][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041484] [Batch 00872/03692] [00:07:38/00:24:44, 0.526s/it]: train_loss_raw=1.0124, running_loss=1.1165, LR=0.000100
[2025-08-10 17:23:02,473][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041496] [Batch 00884/03692] [00:07:45/00:24:37, 0.526s/it]: train_loss_raw=1.0223, running_loss=1.1151, LR=0.000100
[2025-08-10 17:23:09,091][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041508] [Batch 00896/03692] [00:07:51/00:24:32, 0.527s/it]: train_loss_raw=1.1078, running_loss=1.1192, LR=0.000100
[2025-08-10 17:23:15,636][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041520] [Batch 00908/03692] [00:07:58/00:24:26, 0.527s/it]: train_loss_raw=1.0017, running_loss=1.1182, LR=0.000100
[2025-08-10 17:23:21,969][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041532] [Batch 00920/03692] [00:08:04/00:24:20, 0.527s/it]: train_loss_raw=1.0853, running_loss=1.1220, LR=0.000100
[2025-08-10 17:23:28,082][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041544] [Batch 00932/03692] [00:08:10/00:24:13, 0.527s/it]: train_loss_raw=1.1615, running_loss=1.1234, LR=0.000100
[2025-08-10 17:23:34,361][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041556] [Batch 00944/03692] [00:08:17/00:24:07, 0.527s/it]: train_loss_raw=1.1488, running_loss=1.1202, LR=0.000100
[2025-08-10 17:23:40,428][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041568] [Batch 00956/03692] [00:08:23/00:24:00, 0.526s/it]: train_loss_raw=1.2280, running_loss=1.1187, LR=0.000100
[2025-08-10 17:23:46,408][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041580] [Batch 00968/03692] [00:08:29/00:23:52, 0.526s/it]: train_loss_raw=1.1845, running_loss=1.1213, LR=0.000100
[2025-08-10 17:23:52,459][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041592] [Batch 00980/03692] [00:08:35/00:23:45, 0.526s/it]: train_loss_raw=1.0520, running_loss=1.1179, LR=0.000100
[2025-08-10 17:23:58,588][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041604] [Batch 00992/03692] [00:08:41/00:23:38, 0.526s/it]: train_loss_raw=1.0909, running_loss=1.1202, LR=0.000100
[2025-08-10 17:24:04,748][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041616] [Batch 01004/03692] [00:08:47/00:23:32, 0.525s/it]: train_loss_raw=1.2125, running_loss=1.1215, LR=0.000100
[2025-08-10 17:24:10,818][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041628] [Batch 01016/03692] [00:08:53/00:23:25, 0.525s/it]: train_loss_raw=1.1489, running_loss=1.1240, LR=0.000100
[2025-08-10 17:24:16,865][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041640] [Batch 01028/03692] [00:08:59/00:23:18, 0.525s/it]: train_loss_raw=1.1338, running_loss=1.1232, LR=0.000100
[2025-08-10 17:24:22,907][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041652] [Batch 01040/03692] [00:09:05/00:23:11, 0.525s/it]: train_loss_raw=1.2155, running_loss=1.1213, LR=0.000100
[2025-08-10 17:24:29,289][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041664] [Batch 01052/03692] [00:09:12/00:23:05, 0.525s/it]: train_loss_raw=1.1521, running_loss=1.1262, LR=0.000100
[2025-08-10 17:24:35,759][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041676] [Batch 01064/03692] [00:09:18/00:22:59, 0.525s/it]: train_loss_raw=1.1094, running_loss=1.1254, LR=0.000100
[2025-08-10 17:24:41,940][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041688] [Batch 01076/03692] [00:09:24/00:22:52, 0.525s/it]: train_loss_raw=1.1244, running_loss=1.1247, LR=0.000100
[2025-08-10 17:24:48,373][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041700] [Batch 01088/03692] [00:09:31/00:22:46, 0.525s/it]: train_loss_raw=1.0901, running_loss=1.1239, LR=0.000100
[2025-08-10 17:24:54,543][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041712] [Batch 01100/03692] [00:09:37/00:22:40, 0.525s/it]: train_loss_raw=1.1692, running_loss=1.1213, LR=0.000100
[2025-08-10 17:25:00,779][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041724] [Batch 01112/03692] [00:09:43/00:22:33, 0.525s/it]: train_loss_raw=1.2567, running_loss=1.1186, LR=0.000100
[2025-08-10 17:25:07,319][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041736] [Batch 01124/03692] [00:09:50/00:22:28, 0.525s/it]: train_loss_raw=1.1416, running_loss=1.1201, LR=0.000100
[2025-08-10 17:25:13,827][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041748] [Batch 01136/03692] [00:09:56/00:22:22, 0.525s/it]: train_loss_raw=1.1439, running_loss=1.1235, LR=0.000100
[2025-08-10 17:25:20,148][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041760] [Batch 01148/03692] [00:10:02/00:22:15, 0.525s/it]: train_loss_raw=1.1258, running_loss=1.1268, LR=0.000100
[2025-08-10 17:25:26,173][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041772] [Batch 01160/03692] [00:10:08/00:22:09, 0.525s/it]: train_loss_raw=1.0300, running_loss=1.1262, LR=0.000100
[2025-08-10 17:25:32,479][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041784] [Batch 01172/03692] [00:10:15/00:22:02, 0.525s/it]: train_loss_raw=1.1489, running_loss=1.1221, LR=0.000100
[2025-08-10 17:25:38,916][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041796] [Batch 01184/03692] [00:10:21/00:21:56, 0.525s/it]: train_loss_raw=1.0546, running_loss=1.1177, LR=0.000100
[2025-08-10 17:25:45,348][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041808] [Batch 01196/03692] [00:10:28/00:21:50, 0.525s/it]: train_loss_raw=1.2723, running_loss=1.1172, LR=0.000100
[2025-08-10 17:25:51,881][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041820] [Batch 01208/03692] [00:10:34/00:21:44, 0.525s/it]: train_loss_raw=1.0269, running_loss=1.1202, LR=0.000100
[2025-08-10 17:25:58,482][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041832] [Batch 01220/03692] [00:10:41/00:21:39, 0.526s/it]: train_loss_raw=1.1236, running_loss=1.1142, LR=0.000100
[2025-08-10 17:26:04,996][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041844] [Batch 01232/03692] [00:10:47/00:21:33, 0.526s/it]: train_loss_raw=1.0553, running_loss=1.1151, LR=0.000100
[2025-08-10 17:26:11,530][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041856] [Batch 01244/03692] [00:10:54/00:21:27, 0.526s/it]: train_loss_raw=1.1087, running_loss=1.1161, LR=0.000100
[2025-08-10 17:26:17,881][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041868] [Batch 01256/03692] [00:11:00/00:21:21, 0.526s/it]: train_loss_raw=0.9525, running_loss=1.1140, LR=0.000100
[2025-08-10 17:26:24,216][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041880] [Batch 01268/03692] [00:11:06/00:21:14, 0.526s/it]: train_loss_raw=1.0970, running_loss=1.1136, LR=0.000100
[2025-08-10 17:26:30,593][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041892] [Batch 01280/03692] [00:11:13/00:21:08, 0.526s/it]: train_loss_raw=1.0904, running_loss=1.1121, LR=0.000100
[2025-08-10 17:26:36,788][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041904] [Batch 01292/03692] [00:11:19/00:21:02, 0.526s/it]: train_loss_raw=1.1125, running_loss=1.1089, LR=0.000100
[2025-08-10 17:26:42,948][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041916] [Batch 01304/03692] [00:11:25/00:20:55, 0.526s/it]: train_loss_raw=1.0095, running_loss=1.1051, LR=0.000100
[2025-08-10 17:26:49,523][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041928] [Batch 01316/03692] [00:11:32/00:20:49, 0.526s/it]: train_loss_raw=1.1462, running_loss=1.1037, LR=0.000100
[2025-08-10 17:26:55,777][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041940] [Batch 01328/03692] [00:11:38/00:20:43, 0.526s/it]: train_loss_raw=1.1438, running_loss=1.1037, LR=0.000100
[2025-08-10 17:27:02,275][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041952] [Batch 01340/03692] [00:11:45/00:20:37, 0.526s/it]: train_loss_raw=1.1355, running_loss=1.1066, LR=0.000100
[2025-08-10 17:27:08,763][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041964] [Batch 01352/03692] [00:11:51/00:20:31, 0.526s/it]: train_loss_raw=1.0539, running_loss=1.1065, LR=0.000100
[2025-08-10 17:27:15,246][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041976] [Batch 01364/03692] [00:11:57/00:20:25, 0.526s/it]: train_loss_raw=1.0154, running_loss=1.1021, LR=0.000100
[2025-08-10 17:27:21,669][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 041988] [Batch 01376/03692] [00:12:04/00:20:19, 0.526s/it]: train_loss_raw=1.0852, running_loss=1.1033, LR=0.000100
[2025-08-10 17:27:28,162][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042000] [Batch 01388/03692] [00:12:10/00:20:13, 0.527s/it]: train_loss_raw=1.1498, running_loss=1.1061, LR=0.000100
[2025-08-10 17:27:40,723][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042012] [Batch 01400/03692] [00:12:23/00:20:17, 0.531s/it]: train_loss_raw=1.1637, running_loss=1.1090, LR=0.000100
[2025-08-10 17:27:47,177][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042024] [Batch 01412/03692] [00:12:29/00:20:10, 0.531s/it]: train_loss_raw=1.0517, running_loss=1.1083, LR=0.000100
[2025-08-10 17:27:53,558][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042036] [Batch 01424/03692] [00:12:36/00:20:04, 0.531s/it]: train_loss_raw=1.2347, running_loss=1.1151, LR=0.000100
[2025-08-10 17:27:59,981][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042048] [Batch 01436/03692] [00:12:42/00:19:58, 0.531s/it]: train_loss_raw=1.0887, running_loss=1.1156, LR=0.000100
[2025-08-10 17:28:06,224][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042060] [Batch 01448/03692] [00:12:48/00:19:51, 0.531s/it]: train_loss_raw=1.1796, running_loss=1.1178, LR=0.000100
[2025-08-10 17:28:12,586][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042072] [Batch 01460/03692] [00:12:55/00:19:45, 0.531s/it]: train_loss_raw=1.0314, running_loss=1.1119, LR=0.000100
[2025-08-10 17:28:18,898][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042084] [Batch 01472/03692] [00:13:01/00:19:38, 0.531s/it]: train_loss_raw=1.0032, running_loss=1.1100, LR=0.000100
[2025-08-10 17:28:25,343][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042096] [Batch 01484/03692] [00:13:08/00:19:32, 0.531s/it]: train_loss_raw=1.0800, running_loss=1.1098, LR=0.000100
[2025-08-10 17:28:31,789][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042108] [Batch 01496/03692] [00:13:14/00:19:26, 0.531s/it]: train_loss_raw=1.1579, running_loss=1.1105, LR=0.000100
[2025-08-10 17:28:38,158][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042120] [Batch 01508/03692] [00:13:20/00:19:19, 0.531s/it]: train_loss_raw=1.0472, running_loss=1.1096, LR=0.000100
[2025-08-10 17:28:44,718][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042132] [Batch 01520/03692] [00:13:27/00:19:13, 0.531s/it]: train_loss_raw=1.1756, running_loss=1.1109, LR=0.000100
[2025-08-10 17:28:51,234][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042144] [Batch 01532/03692] [00:13:33/00:19:07, 0.531s/it]: train_loss_raw=1.1590, running_loss=1.1119, LR=0.000100
[2025-08-10 17:28:57,817][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042156] [Batch 01544/03692] [00:13:40/00:19:01, 0.531s/it]: train_loss_raw=1.1484, running_loss=1.1107, LR=0.000100
[2025-08-10 17:29:03,946][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042168] [Batch 01556/03692] [00:13:46/00:18:54, 0.531s/it]: train_loss_raw=1.1438, running_loss=1.1108, LR=0.000100
[2025-08-10 17:29:10,116][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042180] [Batch 01568/03692] [00:13:52/00:18:48, 0.531s/it]: train_loss_raw=1.0435, running_loss=1.1118, LR=0.000100
[2025-08-10 17:29:16,219][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042192] [Batch 01580/03692] [00:13:58/00:18:41, 0.531s/it]: train_loss_raw=1.0528, running_loss=1.1116, LR=0.000100
[2025-08-10 17:29:22,353][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042204] [Batch 01592/03692] [00:14:05/00:18:34, 0.531s/it]: train_loss_raw=1.1535, running_loss=1.1112, LR=0.000100
[2025-08-10 17:29:29,005][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042216] [Batch 01604/03692] [00:14:11/00:18:28, 0.531s/it]: train_loss_raw=1.1700, running_loss=1.1118, LR=0.000100
[2025-08-10 17:29:35,454][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042228] [Batch 01616/03692] [00:14:18/00:18:22, 0.531s/it]: train_loss_raw=1.0824, running_loss=1.1105, LR=0.000100
[2025-08-10 17:29:41,789][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042240] [Batch 01628/03692] [00:14:24/00:18:16, 0.531s/it]: train_loss_raw=1.1768, running_loss=1.1187, LR=0.000100
[2025-08-10 17:29:47,841][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042252] [Batch 01640/03692] [00:14:30/00:18:09, 0.531s/it]: train_loss_raw=1.1193, running_loss=1.1195, LR=0.000100
[2025-08-10 17:29:54,129][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042264] [Batch 01652/03692] [00:14:36/00:18:02, 0.531s/it]: train_loss_raw=1.1330, running_loss=1.1177, LR=0.000100
[2025-08-10 17:30:00,521][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042276] [Batch 01664/03692] [00:14:43/00:17:56, 0.531s/it]: train_loss_raw=1.1574, running_loss=1.1194, LR=0.000100
[2025-08-10 17:30:07,030][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042288] [Batch 01676/03692] [00:14:49/00:17:50, 0.531s/it]: train_loss_raw=1.1737, running_loss=1.1150, LR=0.000100
[2025-08-10 17:30:13,227][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042300] [Batch 01688/03692] [00:14:55/00:17:43, 0.531s/it]: train_loss_raw=1.0672, running_loss=1.1164, LR=0.000100
[2025-08-10 17:30:19,428][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042312] [Batch 01700/03692] [00:15:02/00:17:37, 0.531s/it]: train_loss_raw=1.1800, running_loss=1.1133, LR=0.000100
[2025-08-10 17:30:25,482][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042324] [Batch 01712/03692] [00:15:08/00:17:30, 0.530s/it]: train_loss_raw=1.1344, running_loss=1.1132, LR=0.000100
[2025-08-10 17:30:31,595][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042336] [Batch 01724/03692] [00:15:14/00:17:23, 0.530s/it]: train_loss_raw=1.1126, running_loss=1.1110, LR=0.000100
[2025-08-10 17:30:38,009][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042348] [Batch 01736/03692] [00:15:20/00:17:17, 0.530s/it]: train_loss_raw=1.0552, running_loss=1.1091, LR=0.000100
[2025-08-10 17:30:44,188][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042360] [Batch 01748/03692] [00:15:26/00:17:10, 0.530s/it]: train_loss_raw=1.0792, running_loss=1.1069, LR=0.000100
[2025-08-10 17:30:50,337][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042372] [Batch 01760/03692] [00:15:33/00:17:04, 0.530s/it]: train_loss_raw=1.0849, running_loss=1.1068, LR=0.000100
[2025-08-10 17:30:56,507][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042384] [Batch 01772/03692] [00:15:39/00:16:57, 0.530s/it]: train_loss_raw=1.0458, running_loss=1.1062, LR=0.000100
[2025-08-10 17:31:02,822][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042396] [Batch 01784/03692] [00:15:45/00:16:51, 0.530s/it]: train_loss_raw=1.1895, running_loss=1.1088, LR=0.000100
[2025-08-10 17:31:09,371][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042408] [Batch 01796/03692] [00:15:52/00:16:45, 0.530s/it]: train_loss_raw=1.1016, running_loss=1.1069, LR=0.000100
[2025-08-10 17:31:15,685][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042420] [Batch 01808/03692] [00:15:58/00:16:38, 0.530s/it]: train_loss_raw=1.0025, running_loss=1.1036, LR=0.000100
[2025-08-10 17:31:21,906][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042432] [Batch 01820/03692] [00:16:04/00:16:32, 0.530s/it]: train_loss_raw=1.0265, running_loss=1.1027, LR=0.000100
[2025-08-10 17:31:28,453][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042444] [Batch 01832/03692] [00:16:11/00:16:26, 0.530s/it]: train_loss_raw=1.1663, running_loss=1.1064, LR=0.000100
[2025-08-10 17:31:34,854][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042456] [Batch 01844/03692] [00:16:17/00:16:19, 0.530s/it]: train_loss_raw=1.1458, running_loss=1.1109, LR=0.000100
[2025-08-10 17:31:41,237][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042468] [Batch 01856/03692] [00:16:23/00:16:13, 0.530s/it]: train_loss_raw=1.0808, running_loss=1.1093, LR=0.000100
[2025-08-10 17:31:47,622][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042480] [Batch 01868/03692] [00:16:30/00:16:07, 0.530s/it]: train_loss_raw=0.9942, running_loss=1.1086, LR=0.000100
[2025-08-10 17:31:54,028][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042492] [Batch 01880/03692] [00:16:36/00:16:00, 0.530s/it]: train_loss_raw=1.0650, running_loss=1.1075, LR=0.000100
[2025-08-10 17:32:00,477][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042504] [Batch 01892/03692] [00:16:43/00:15:54, 0.530s/it]: train_loss_raw=1.1845, running_loss=1.1119, LR=0.000100
[2025-08-10 17:32:06,988][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042516] [Batch 01904/03692] [00:16:49/00:15:48, 0.530s/it]: train_loss_raw=1.1015, running_loss=1.1113, LR=0.000100
[2025-08-10 17:32:13,453][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042528] [Batch 01916/03692] [00:16:56/00:15:41, 0.530s/it]: train_loss_raw=1.1257, running_loss=1.1104, LR=0.000100
[2025-08-10 17:32:19,828][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042540] [Batch 01928/03692] [00:17:02/00:15:35, 0.530s/it]: train_loss_raw=1.1859, running_loss=1.1105, LR=0.000100
[2025-08-10 17:32:25,960][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042552] [Batch 01940/03692] [00:17:08/00:15:29, 0.530s/it]: train_loss_raw=1.0875, running_loss=1.1096, LR=0.000100
[2025-08-10 17:32:32,019][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042564] [Batch 01952/03692] [00:17:14/00:15:22, 0.530s/it]: train_loss_raw=1.1057, running_loss=1.1080, LR=0.000100
[2025-08-10 17:32:38,577][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042576] [Batch 01964/03692] [00:17:21/00:15:16, 0.530s/it]: train_loss_raw=1.1039, running_loss=1.1054, LR=0.000100
[2025-08-10 17:32:44,971][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042588] [Batch 01976/03692] [00:17:27/00:15:09, 0.530s/it]: train_loss_raw=1.1286, running_loss=1.1068, LR=0.000100
[2025-08-10 17:32:51,240][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042600] [Batch 01988/03692] [00:17:33/00:15:03, 0.530s/it]: train_loss_raw=1.1571, running_loss=1.1050, LR=0.000100
[2025-08-10 17:32:57,430][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042612] [Batch 02000/03692] [00:17:40/00:14:56, 0.530s/it]: train_loss_raw=1.1388, running_loss=1.1085, LR=0.000100
[2025-08-10 17:33:03,881][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042624] [Batch 02012/03692] [00:17:46/00:14:50, 0.530s/it]: train_loss_raw=1.2264, running_loss=1.1081, LR=0.000100
[2025-08-10 17:33:10,573][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042636] [Batch 02024/03692] [00:17:53/00:14:44, 0.530s/it]: train_loss_raw=0.9590, running_loss=1.1099, LR=0.000100
[2025-08-10 17:33:17,137][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042648] [Batch 02036/03692] [00:17:59/00:14:38, 0.530s/it]: train_loss_raw=1.1688, running_loss=1.1074, LR=0.000100
[2025-08-10 17:33:23,419][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042660] [Batch 02048/03692] [00:18:06/00:14:31, 0.530s/it]: train_loss_raw=1.1313, running_loss=1.1133, LR=0.000100
[2025-08-10 17:33:29,626][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042672] [Batch 02060/03692] [00:18:12/00:14:25, 0.530s/it]: train_loss_raw=1.1692, running_loss=1.1114, LR=0.000100
[2025-08-10 17:33:35,946][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042684] [Batch 02072/03692] [00:18:18/00:14:19, 0.530s/it]: train_loss_raw=1.0621, running_loss=1.1093, LR=0.000100
[2025-08-10 17:33:41,986][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042696] [Batch 02084/03692] [00:18:24/00:14:12, 0.530s/it]: train_loss_raw=1.0129, running_loss=1.1118, LR=0.000100
[2025-08-10 17:33:48,049][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042708] [Batch 02096/03692] [00:18:30/00:14:05, 0.530s/it]: train_loss_raw=1.2391, running_loss=1.1175, LR=0.000100
[2025-08-10 17:33:54,049][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042720] [Batch 02108/03692] [00:18:36/00:13:59, 0.530s/it]: train_loss_raw=1.0583, running_loss=1.1132, LR=0.000100
[2025-08-10 17:34:00,068][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042732] [Batch 02120/03692] [00:18:42/00:13:52, 0.530s/it]: train_loss_raw=1.0876, running_loss=1.1116, LR=0.000100
[2025-08-10 17:34:06,350][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042744] [Batch 02132/03692] [00:18:49/00:13:46, 0.530s/it]: train_loss_raw=1.0227, running_loss=1.1093, LR=0.000100
[2025-08-10 17:34:12,618][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042756] [Batch 02144/03692] [00:18:55/00:13:39, 0.530s/it]: train_loss_raw=1.0843, running_loss=1.1096, LR=0.000100
[2025-08-10 17:34:19,091][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042768] [Batch 02156/03692] [00:19:01/00:13:33, 0.530s/it]: train_loss_raw=1.2423, running_loss=1.1083, LR=0.000100
[2025-08-10 17:34:25,284][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042780] [Batch 02168/03692] [00:19:08/00:13:26, 0.530s/it]: train_loss_raw=1.0975, running_loss=1.1070, LR=0.000100
[2025-08-10 17:34:31,496][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042792] [Batch 02180/03692] [00:19:14/00:13:20, 0.529s/it]: train_loss_raw=1.0736, running_loss=1.1107, LR=0.000100
[2025-08-10 17:34:38,020][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042804] [Batch 02192/03692] [00:19:20/00:13:14, 0.530s/it]: train_loss_raw=1.0683, running_loss=1.1114, LR=0.000100
[2025-08-10 17:34:44,166][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042816] [Batch 02204/03692] [00:19:26/00:13:07, 0.529s/it]: train_loss_raw=1.1580, running_loss=1.1121, LR=0.000100
[2025-08-10 17:34:50,342][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042828] [Batch 02216/03692] [00:19:33/00:13:01, 0.529s/it]: train_loss_raw=1.1209, running_loss=1.1102, LR=0.000100
[2025-08-10 17:34:56,496][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042840] [Batch 02228/03692] [00:19:39/00:12:54, 0.529s/it]: train_loss_raw=1.1606, running_loss=1.1061, LR=0.000100
[2025-08-10 17:35:02,666][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042852] [Batch 02240/03692] [00:19:45/00:12:48, 0.529s/it]: train_loss_raw=1.1185, running_loss=1.1033, LR=0.000100
[2025-08-10 17:35:08,751][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042864] [Batch 02252/03692] [00:19:51/00:12:41, 0.529s/it]: train_loss_raw=1.1223, running_loss=1.1023, LR=0.000100
[2025-08-10 17:35:14,924][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042876] [Batch 02264/03692] [00:19:57/00:12:35, 0.529s/it]: train_loss_raw=1.0232, running_loss=1.0977, LR=0.000100
[2025-08-10 17:35:21,080][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042888] [Batch 02276/03692] [00:20:03/00:12:28, 0.529s/it]: train_loss_raw=1.1918, running_loss=1.0990, LR=0.000100
[2025-08-10 17:35:27,160][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042900] [Batch 02288/03692] [00:20:09/00:12:22, 0.529s/it]: train_loss_raw=1.1243, running_loss=1.1024, LR=0.000100
[2025-08-10 17:35:33,291][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042912] [Batch 02300/03692] [00:20:16/00:12:15, 0.529s/it]: train_loss_raw=1.0292, running_loss=1.1021, LR=0.000100
[2025-08-10 17:35:39,340][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042924] [Batch 02312/03692] [00:20:22/00:12:09, 0.529s/it]: train_loss_raw=0.9974, running_loss=1.1000, LR=0.000100
[2025-08-10 17:35:45,357][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042936] [Batch 02324/03692] [00:20:28/00:12:02, 0.528s/it]: train_loss_raw=1.0061, running_loss=1.0971, LR=0.000100
[2025-08-10 17:35:51,445][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042948] [Batch 02336/03692] [00:20:34/00:11:56, 0.528s/it]: train_loss_raw=1.2564, running_loss=1.0995, LR=0.000100
[2025-08-10 17:35:57,541][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042960] [Batch 02348/03692] [00:20:40/00:11:49, 0.528s/it]: train_loss_raw=1.2046, running_loss=1.1044, LR=0.000100
[2025-08-10 17:36:03,542][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042972] [Batch 02360/03692] [00:20:46/00:11:43, 0.528s/it]: train_loss_raw=1.1959, running_loss=1.1074, LR=0.000100
[2025-08-10 17:36:09,589][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042984] [Batch 02372/03692] [00:20:52/00:11:36, 0.528s/it]: train_loss_raw=0.9478, running_loss=1.1004, LR=0.000100
[2025-08-10 17:36:15,683][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 042996] [Batch 02384/03692] [00:20:58/00:11:30, 0.528s/it]: train_loss_raw=1.0944, running_loss=1.0977, LR=0.000100
[2025-08-10 17:36:21,803][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043008] [Batch 02396/03692] [00:21:04/00:11:23, 0.528s/it]: train_loss_raw=1.0304, running_loss=1.0957, LR=0.000100
[2025-08-10 17:36:27,822][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043020] [Batch 02408/03692] [00:21:10/00:11:17, 0.528s/it]: train_loss_raw=1.0843, running_loss=1.0958, LR=0.000100
[2025-08-10 17:36:33,832][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043032] [Batch 02420/03692] [00:21:16/00:11:10, 0.528s/it]: train_loss_raw=1.0682, running_loss=1.0973, LR=0.000100
[2025-08-10 17:36:39,881][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043044] [Batch 02432/03692] [00:21:22/00:11:04, 0.527s/it]: train_loss_raw=0.9710, running_loss=1.0956, LR=0.000100
[2025-08-10 17:36:45,943][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043056] [Batch 02444/03692] [00:21:28/00:10:58, 0.527s/it]: train_loss_raw=1.0003, running_loss=1.0964, LR=0.000100
[2025-08-10 17:36:51,971][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043068] [Batch 02456/03692] [00:21:34/00:10:51, 0.527s/it]: train_loss_raw=1.1692, running_loss=1.0938, LR=0.000100
[2025-08-10 17:36:58,030][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043080] [Batch 02468/03692] [00:21:40/00:10:45, 0.527s/it]: train_loss_raw=1.1220, running_loss=1.0966, LR=0.000100
[2025-08-10 17:37:04,224][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043092] [Batch 02480/03692] [00:21:46/00:10:38, 0.527s/it]: train_loss_raw=1.1562, running_loss=1.0963, LR=0.000100
[2025-08-10 17:37:10,339][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043104] [Batch 02492/03692] [00:21:53/00:10:32, 0.527s/it]: train_loss_raw=1.0212, running_loss=1.0974, LR=0.000100
[2025-08-10 17:37:16,306][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043116] [Batch 02504/03692] [00:21:59/00:10:25, 0.527s/it]: train_loss_raw=1.0434, running_loss=1.0978, LR=0.000100
[2025-08-10 17:37:22,397][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043128] [Batch 02516/03692] [00:22:05/00:10:19, 0.527s/it]: train_loss_raw=1.2420, running_loss=1.1017, LR=0.000100
[2025-08-10 17:37:28,491][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043140] [Batch 02528/03692] [00:22:11/00:10:12, 0.527s/it]: train_loss_raw=1.1075, running_loss=1.1046, LR=0.000100
[2025-08-10 17:37:34,536][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043152] [Batch 02540/03692] [00:22:17/00:10:06, 0.526s/it]: train_loss_raw=1.3081, running_loss=1.1105, LR=0.000100
[2025-08-10 17:37:40,824][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043164] [Batch 02552/03692] [00:22:23/00:10:00, 0.526s/it]: train_loss_raw=0.9377, running_loss=1.1088, LR=0.000100
[2025-08-10 17:37:47,053][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043176] [Batch 02564/03692] [00:22:29/00:09:53, 0.526s/it]: train_loss_raw=1.1017, running_loss=1.1066, LR=0.000100
[2025-08-10 17:37:53,136][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043188] [Batch 02576/03692] [00:22:35/00:09:47, 0.526s/it]: train_loss_raw=1.1960, running_loss=1.1061, LR=0.000100
[2025-08-10 17:37:59,115][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043200] [Batch 02588/03692] [00:22:41/00:09:40, 0.526s/it]: train_loss_raw=1.0736, running_loss=1.1068, LR=0.000100
[2025-08-10 17:38:05,167][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043212] [Batch 02600/03692] [00:22:47/00:09:34, 0.526s/it]: train_loss_raw=1.0634, running_loss=1.1063, LR=0.000100
[2025-08-10 17:38:11,278][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043224] [Batch 02612/03692] [00:22:54/00:09:28, 0.526s/it]: train_loss_raw=1.0899, running_loss=1.1054, LR=0.000100
[2025-08-10 17:38:17,339][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043236] [Batch 02624/03692] [00:23:00/00:09:21, 0.526s/it]: train_loss_raw=1.0982, running_loss=1.1013, LR=0.000100
[2025-08-10 17:38:23,380][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043248] [Batch 02636/03692] [00:23:06/00:09:15, 0.526s/it]: train_loss_raw=0.9283, running_loss=1.0990, LR=0.000100
[2025-08-10 17:38:29,444][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043260] [Batch 02648/03692] [00:23:12/00:09:08, 0.526s/it]: train_loss_raw=1.1414, running_loss=1.1003, LR=0.000100
[2025-08-10 17:38:35,490][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043272] [Batch 02660/03692] [00:23:18/00:09:02, 0.526s/it]: train_loss_raw=1.1283, running_loss=1.0994, LR=0.000100
[2025-08-10 17:38:41,491][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043284] [Batch 02672/03692] [00:23:24/00:08:56, 0.526s/it]: train_loss_raw=0.9838, running_loss=1.0960, LR=0.000100
[2025-08-10 17:38:47,580][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043296] [Batch 02684/03692] [00:23:30/00:08:49, 0.525s/it]: train_loss_raw=1.0886, running_loss=1.0940, LR=0.000100
[2025-08-10 17:38:53,670][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043308] [Batch 02696/03692] [00:23:36/00:08:43, 0.525s/it]: train_loss_raw=1.0872, running_loss=1.0885, LR=0.000100
[2025-08-10 17:38:59,727][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043320] [Batch 02708/03692] [00:23:42/00:08:36, 0.525s/it]: train_loss_raw=1.1041, running_loss=1.0923, LR=0.000100
[2025-08-10 17:39:05,768][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043332] [Batch 02720/03692] [00:23:48/00:08:30, 0.525s/it]: train_loss_raw=1.0619, running_loss=1.0912, LR=0.000100
[2025-08-10 17:39:11,767][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043344] [Batch 02732/03692] [00:23:54/00:08:24, 0.525s/it]: train_loss_raw=1.0430, running_loss=1.0960, LR=0.000100
[2025-08-10 17:39:17,782][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043356] [Batch 02744/03692] [00:24:00/00:08:17, 0.525s/it]: train_loss_raw=1.0520, running_loss=1.0984, LR=0.000100
[2025-08-10 17:39:23,824][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043368] [Batch 02756/03692] [00:24:06/00:08:11, 0.525s/it]: train_loss_raw=1.1790, running_loss=1.0988, LR=0.000100
[2025-08-10 17:39:29,958][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043380] [Batch 02768/03692] [00:24:12/00:08:04, 0.525s/it]: train_loss_raw=0.9916, running_loss=1.0959, LR=0.000100
[2025-08-10 17:39:36,024][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043392] [Batch 02780/03692] [00:24:18/00:07:58, 0.525s/it]: train_loss_raw=1.1801, running_loss=1.0918, LR=0.000100
[2025-08-10 17:39:42,164][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043404] [Batch 02792/03692] [00:24:24/00:07:52, 0.525s/it]: train_loss_raw=1.2107, running_loss=1.1003, LR=0.000100
[2025-08-10 17:39:48,163][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043416] [Batch 02804/03692] [00:24:30/00:07:45, 0.525s/it]: train_loss_raw=1.0998, running_loss=1.0979, LR=0.000100
[2025-08-10 17:39:54,279][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043428] [Batch 02816/03692] [00:24:37/00:07:39, 0.525s/it]: train_loss_raw=1.0353, running_loss=1.0985, LR=0.000100
[2025-08-10 17:40:00,353][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043440] [Batch 02828/03692] [00:24:43/00:07:33, 0.524s/it]: train_loss_raw=1.0950, running_loss=1.0982, LR=0.000100
[2025-08-10 17:40:06,443][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043452] [Batch 02840/03692] [00:24:49/00:07:26, 0.524s/it]: train_loss_raw=1.0339, running_loss=1.0988, LR=0.000100
[2025-08-10 17:40:12,501][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043464] [Batch 02852/03692] [00:24:55/00:07:20, 0.524s/it]: train_loss_raw=1.1175, running_loss=1.0986, LR=0.000100
[2025-08-10 17:40:18,564][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043476] [Batch 02864/03692] [00:25:01/00:07:14, 0.524s/it]: train_loss_raw=1.0265, running_loss=1.0976, LR=0.000100
[2025-08-10 17:40:25,014][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043488] [Batch 02876/03692] [00:25:07/00:07:07, 0.524s/it]: train_loss_raw=1.0975, running_loss=1.0949, LR=0.000100
[2025-08-10 17:40:31,598][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043500] [Batch 02888/03692] [00:25:14/00:07:01, 0.524s/it]: train_loss_raw=1.1140, running_loss=1.0985, LR=0.000100
[2025-08-10 17:40:38,162][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043512] [Batch 02900/03692] [00:25:20/00:06:55, 0.524s/it]: train_loss_raw=0.9486, running_loss=1.0976, LR=0.000100
[2025-08-10 17:40:44,442][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043524] [Batch 02912/03692] [00:25:27/00:06:49, 0.524s/it]: train_loss_raw=1.0494, running_loss=1.0944, LR=0.000100
[2025-08-10 17:40:50,673][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043536] [Batch 02924/03692] [00:25:33/00:06:42, 0.524s/it]: train_loss_raw=1.1062, running_loss=1.0926, LR=0.000100
[2025-08-10 17:40:56,933][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043548] [Batch 02936/03692] [00:25:39/00:06:36, 0.524s/it]: train_loss_raw=1.0903, running_loss=1.0915, LR=0.000100
[2025-08-10 17:41:03,127][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043560] [Batch 02948/03692] [00:25:45/00:06:30, 0.524s/it]: train_loss_raw=1.1763, running_loss=1.0924, LR=0.000100
[2025-08-10 17:41:09,211][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043572] [Batch 02960/03692] [00:25:51/00:06:23, 0.524s/it]: train_loss_raw=0.9839, running_loss=1.0908, LR=0.000100
[2025-08-10 17:41:15,241][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043584] [Batch 02972/03692] [00:25:57/00:06:17, 0.524s/it]: train_loss_raw=1.0619, running_loss=1.0915, LR=0.000100
[2025-08-10 17:41:21,388][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043596] [Batch 02984/03692] [00:26:04/00:06:11, 0.524s/it]: train_loss_raw=1.1727, running_loss=1.0968, LR=0.000100
[2025-08-10 17:41:27,478][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043608] [Batch 02996/03692] [00:26:10/00:06:04, 0.524s/it]: train_loss_raw=1.0985, running_loss=1.0967, LR=0.000100
[2025-08-10 17:41:33,522][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043620] [Batch 03008/03692] [00:26:16/00:05:58, 0.524s/it]: train_loss_raw=1.1621, running_loss=1.0928, LR=0.000100
[2025-08-10 17:41:39,604][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043632] [Batch 03020/03692] [00:26:22/00:05:52, 0.524s/it]: train_loss_raw=1.1466, running_loss=1.0917, LR=0.000100
[2025-08-10 17:41:45,620][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043644] [Batch 03032/03692] [00:26:28/00:05:45, 0.524s/it]: train_loss_raw=1.0442, running_loss=1.0939, LR=0.000100
[2025-08-10 17:41:51,683][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043656] [Batch 03044/03692] [00:26:34/00:05:39, 0.524s/it]: train_loss_raw=1.1173, running_loss=1.0951, LR=0.000100
[2025-08-10 17:41:57,661][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043668] [Batch 03056/03692] [00:26:40/00:05:33, 0.524s/it]: train_loss_raw=1.0331, running_loss=1.0900, LR=0.000100
[2025-08-10 17:42:03,675][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043680] [Batch 03068/03692] [00:26:46/00:05:26, 0.524s/it]: train_loss_raw=1.1315, running_loss=1.0962, LR=0.000100
[2025-08-10 17:42:09,757][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043692] [Batch 03080/03692] [00:26:52/00:05:20, 0.524s/it]: train_loss_raw=1.0375, running_loss=1.0919, LR=0.000100
[2025-08-10 17:42:15,788][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043704] [Batch 03092/03692] [00:26:58/00:05:14, 0.523s/it]: train_loss_raw=1.0617, running_loss=1.0937, LR=0.000100
[2025-08-10 17:42:21,850][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043716] [Batch 03104/03692] [00:27:04/00:05:07, 0.523s/it]: train_loss_raw=1.1634, running_loss=1.0917, LR=0.000100
[2025-08-10 17:42:27,837][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043728] [Batch 03116/03692] [00:27:10/00:05:01, 0.523s/it]: train_loss_raw=0.9767, running_loss=1.0926, LR=0.000100
[2025-08-10 17:42:33,837][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043740] [Batch 03128/03692] [00:27:16/00:04:55, 0.523s/it]: train_loss_raw=1.0991, running_loss=1.0867, LR=0.000100
[2025-08-10 17:42:39,868][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043752] [Batch 03140/03692] [00:27:22/00:04:48, 0.523s/it]: train_loss_raw=1.0025, running_loss=1.0836, LR=0.000100
[2025-08-10 17:42:45,849][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043764] [Batch 03152/03692] [00:27:28/00:04:42, 0.523s/it]: train_loss_raw=1.1200, running_loss=1.0831, LR=0.000100
[2025-08-10 17:42:51,896][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043776] [Batch 03164/03692] [00:27:34/00:04:36, 0.523s/it]: train_loss_raw=1.0460, running_loss=1.0790, LR=0.000100
[2025-08-10 17:42:57,982][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043788] [Batch 03176/03692] [00:27:40/00:04:29, 0.523s/it]: train_loss_raw=1.0733, running_loss=1.0793, LR=0.000100
[2025-08-10 17:43:04,097][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043800] [Batch 03188/03692] [00:27:46/00:04:23, 0.523s/it]: train_loss_raw=1.1236, running_loss=1.0812, LR=0.000100
[2025-08-10 17:43:10,113][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043812] [Batch 03200/03692] [00:27:52/00:04:17, 0.523s/it]: train_loss_raw=1.2225, running_loss=1.0831, LR=0.000100
[2025-08-10 17:43:16,138][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043824] [Batch 03212/03692] [00:27:58/00:04:10, 0.523s/it]: train_loss_raw=0.9920, running_loss=1.0878, LR=0.000100
[2025-08-10 17:43:22,283][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043836] [Batch 03224/03692] [00:28:05/00:04:04, 0.523s/it]: train_loss_raw=1.0802, running_loss=1.0842, LR=0.000100
[2025-08-10 17:43:28,747][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043848] [Batch 03236/03692] [00:28:11/00:03:58, 0.523s/it]: train_loss_raw=1.0881, running_loss=1.0835, LR=0.000100
[2025-08-10 17:43:34,740][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043860] [Batch 03248/03692] [00:28:17/00:03:52, 0.523s/it]: train_loss_raw=1.1821, running_loss=1.0892, LR=0.000100
[2025-08-10 17:43:40,983][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043872] [Batch 03260/03692] [00:28:23/00:03:45, 0.523s/it]: train_loss_raw=1.0690, running_loss=1.0864, LR=0.000100
[2025-08-10 17:43:47,526][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043884] [Batch 03272/03692] [00:28:30/00:03:39, 0.523s/it]: train_loss_raw=1.1325, running_loss=1.0843, LR=0.000100
[2025-08-10 17:43:53,920][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043896] [Batch 03284/03692] [00:28:36/00:03:33, 0.523s/it]: train_loss_raw=1.1094, running_loss=1.0851, LR=0.000100
[2025-08-10 17:44:00,414][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043908] [Batch 03296/03692] [00:28:43/00:03:27, 0.523s/it]: train_loss_raw=1.1339, running_loss=1.0835, LR=0.000100
[2025-08-10 17:44:06,968][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043920] [Batch 03308/03692] [00:28:49/00:03:20, 0.523s/it]: train_loss_raw=0.9799, running_loss=1.0836, LR=0.000100
[2025-08-10 17:44:13,223][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043932] [Batch 03320/03692] [00:28:55/00:03:14, 0.523s/it]: train_loss_raw=1.0991, running_loss=1.0847, LR=0.000100
[2025-08-10 17:44:19,630][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043944] [Batch 03332/03692] [00:29:02/00:03:08, 0.523s/it]: train_loss_raw=1.1029, running_loss=1.0836, LR=0.000100
[2025-08-10 17:44:26,135][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043956] [Batch 03344/03692] [00:29:08/00:03:01, 0.523s/it]: train_loss_raw=1.2290, running_loss=1.0806, LR=0.000100
[2025-08-10 17:44:32,662][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043968] [Batch 03356/03692] [00:29:15/00:02:55, 0.523s/it]: train_loss_raw=1.1238, running_loss=1.0792, LR=0.000100
[2025-08-10 17:44:39,112][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043980] [Batch 03368/03692] [00:29:21/00:02:49, 0.523s/it]: train_loss_raw=1.1413, running_loss=1.0794, LR=0.000100
[2025-08-10 17:44:45,628][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 043992] [Batch 03380/03692] [00:29:28/00:02:43, 0.523s/it]: train_loss_raw=1.0647, running_loss=1.0763, LR=0.000100
[2025-08-10 17:44:57,417][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044004] [Batch 03392/03692] [00:29:40/00:02:37, 0.525s/it]: train_loss_raw=1.0871, running_loss=1.0795, LR=0.000100
[2025-08-10 17:45:03,954][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044016] [Batch 03404/03692] [00:29:46/00:02:31, 0.525s/it]: train_loss_raw=1.0378, running_loss=1.0779, LR=0.000100
[2025-08-10 17:45:10,460][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044028] [Batch 03416/03692] [00:29:53/00:02:24, 0.525s/it]: train_loss_raw=1.1023, running_loss=1.0780, LR=0.000100
[2025-08-10 17:45:16,950][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044040] [Batch 03428/03692] [00:29:59/00:02:18, 0.525s/it]: train_loss_raw=1.0138, running_loss=1.0774, LR=0.000100
[2025-08-10 17:45:23,071][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044052] [Batch 03440/03692] [00:30:05/00:02:12, 0.525s/it]: train_loss_raw=1.1778, running_loss=1.0774, LR=0.000100
[2025-08-10 17:45:29,128][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044064] [Batch 03452/03692] [00:30:11/00:02:05, 0.525s/it]: train_loss_raw=1.0211, running_loss=1.0787, LR=0.000100
[2025-08-10 17:45:35,213][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044076] [Batch 03464/03692] [00:30:17/00:01:59, 0.525s/it]: train_loss_raw=1.2552, running_loss=1.0799, LR=0.000100
[2025-08-10 17:45:41,210][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044088] [Batch 03476/03692] [00:30:23/00:01:53, 0.525s/it]: train_loss_raw=0.9942, running_loss=1.0825, LR=0.000100
[2025-08-10 17:45:47,329][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044100] [Batch 03488/03692] [00:30:30/00:01:47, 0.525s/it]: train_loss_raw=1.1101, running_loss=1.0834, LR=0.000100
[2025-08-10 17:45:53,485][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044112] [Batch 03500/03692] [00:30:36/00:01:40, 0.525s/it]: train_loss_raw=1.1098, running_loss=1.0839, LR=0.000100
[2025-08-10 17:45:59,702][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044124] [Batch 03512/03692] [00:30:42/00:01:34, 0.525s/it]: train_loss_raw=1.0604, running_loss=1.0798, LR=0.000100
[2025-08-10 17:46:05,802][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044136] [Batch 03524/03692] [00:30:48/00:01:28, 0.525s/it]: train_loss_raw=0.9968, running_loss=1.0775, LR=0.000100
[2025-08-10 17:46:11,820][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044148] [Batch 03536/03692] [00:30:54/00:01:21, 0.524s/it]: train_loss_raw=1.0439, running_loss=1.0776, LR=0.000100
[2025-08-10 17:46:17,834][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044160] [Batch 03548/03692] [00:31:00/00:01:15, 0.524s/it]: train_loss_raw=1.0775, running_loss=1.0755, LR=0.000100
[2025-08-10 17:46:23,900][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044172] [Batch 03560/03692] [00:31:06/00:01:09, 0.524s/it]: train_loss_raw=1.0644, running_loss=1.0737, LR=0.000100
[2025-08-10 17:46:29,961][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044184] [Batch 03572/03692] [00:31:12/00:01:02, 0.524s/it]: train_loss_raw=1.1589, running_loss=1.0778, LR=0.000100
[2025-08-10 17:46:36,043][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044196] [Batch 03584/03692] [00:31:18/00:00:56, 0.524s/it]: train_loss_raw=1.0519, running_loss=1.0765, LR=0.000100
[2025-08-10 17:46:42,271][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044208] [Batch 03596/03692] [00:31:25/00:00:50, 0.524s/it]: train_loss_raw=1.1117, running_loss=1.0765, LR=0.000100
[2025-08-10 17:46:48,387][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044220] [Batch 03608/03692] [00:31:31/00:00:44, 0.524s/it]: train_loss_raw=1.1644, running_loss=1.0746, LR=0.000100
[2025-08-10 17:46:54,393][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044232] [Batch 03620/03692] [00:31:37/00:00:37, 0.524s/it]: train_loss_raw=1.0994, running_loss=1.0750, LR=0.000100
[2025-08-10 17:47:00,738][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044244] [Batch 03632/03692] [00:31:43/00:00:31, 0.524s/it]: train_loss_raw=1.0840, running_loss=1.0779, LR=0.000100
[2025-08-10 17:47:07,313][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044256] [Batch 03644/03692] [00:31:50/00:00:25, 0.524s/it]: train_loss_raw=1.1025, running_loss=1.0741, LR=0.000100
[2025-08-10 17:47:13,826][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044268] [Batch 03656/03692] [00:31:56/00:00:18, 0.524s/it]: train_loss_raw=1.1282, running_loss=1.0698, LR=0.000100
[2025-08-10 17:47:20,417][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044280] [Batch 03668/03692] [00:32:03/00:00:12, 0.524s/it]: train_loss_raw=0.9795, running_loss=1.0689, LR=0.000100
[2025-08-10 17:47:27,019][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044292] [Batch 03680/03692] [00:32:09/00:00:06, 0.524s/it]: train_loss_raw=1.2894, running_loss=1.0722, LR=0.000100
[2025-08-10 17:48:04,193][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 044304] [Batch 03692/03692] [00:32:46/00:00:00, 0.533s/it]: train_loss_raw=1.0956, running_loss=1.0751, LR=0.000100
[2025-08-10 17:48:09,192][__main__][INFO] - [VALIDATION] [Epoch 11/29] Starting validation.
[2025-08-10 17:48:43,318][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 044305] [Batch 00011/00025] [00:00:34/00:00:36, 2.844s/it]
[2025-08-10 17:49:00,680][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 044305] [Batch 00023/00025] [00:00:51/00:00:02, 2.145s/it]
[2025-08-10 17:49:01,704][__main__][INFO] - [VALIDATION] [Epoch 11/29] train_loss=1.07514, valid_loss=1.05955
[2025-08-10 17:49:01,705][__main__][INFO] - [VALIDATION] [Epoch 11/29] Metrics:
[2025-08-10 17:49:01,705][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_er      0.467
[2025-08-10 17:49:01,705][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_prec    0.264
[2025-08-10 17:49:01,705][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_recall  0.273
[2025-08-10 17:49:01,705][__main__][INFO] - [VALIDATION] [Epoch 11/29] - pep_recall 0.238
[2025-08-10 17:49:01,708][__main__][INFO] - [TRAIN] [Epoch 11/29] Epoch complete, total time 06:53:00, remaining time 10:19:31, 00:34:25 per epoch
[2025-08-10 17:49:07,979][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044316] [Batch 00012/03692] [00:00:06/00:30:48, 0.502s/it]: train_loss_raw=1.0638, running_loss=1.1339, LR=0.000100
[2025-08-10 17:49:14,475][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044328] [Batch 00024/03692] [00:00:12/00:31:54, 0.522s/it]: train_loss_raw=1.0865, running_loss=1.1226, LR=0.000100
[2025-08-10 17:49:21,008][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044340] [Batch 00036/03692] [00:00:19/00:32:15, 0.529s/it]: train_loss_raw=1.1468, running_loss=1.1151, LR=0.000100
[2025-08-10 17:49:27,526][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044352] [Batch 00048/03692] [00:00:25/00:32:21, 0.533s/it]: train_loss_raw=0.9160, running_loss=1.1054, LR=0.000100
[2025-08-10 17:49:34,000][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044364] [Batch 00060/03692] [00:00:32/00:32:20, 0.534s/it]: train_loss_raw=1.0155, running_loss=1.0942, LR=0.000100
[2025-08-10 17:49:40,576][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044376] [Batch 00072/03692] [00:00:38/00:32:22, 0.536s/it]: train_loss_raw=1.0940, running_loss=1.0870, LR=0.000100
[2025-08-10 17:49:47,047][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044388] [Batch 00084/03692] [00:00:45/00:32:17, 0.537s/it]: train_loss_raw=1.1176, running_loss=1.0782, LR=0.000100
[2025-08-10 17:49:53,515][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044400] [Batch 00096/03692] [00:00:51/00:32:11, 0.537s/it]: train_loss_raw=1.0023, running_loss=1.0767, LR=0.000100
[2025-08-10 17:49:59,903][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044412] [Batch 00108/03692] [00:00:57/00:32:03, 0.537s/it]: train_loss_raw=0.9551, running_loss=1.0720, LR=0.000100
[2025-08-10 17:50:06,380][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044424] [Batch 00120/03692] [00:01:04/00:31:57, 0.537s/it]: train_loss_raw=1.1839, running_loss=1.0728, LR=0.000100
[2025-08-10 17:50:12,974][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044436] [Batch 00132/03692] [00:01:11/00:31:55, 0.538s/it]: train_loss_raw=1.1929, running_loss=1.0723, LR=0.000100
[2025-08-10 17:50:19,474][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044448] [Batch 00144/03692] [00:01:17/00:31:50, 0.538s/it]: train_loss_raw=1.0290, running_loss=1.0647, LR=0.000100
[2025-08-10 17:50:25,823][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044460] [Batch 00156/03692] [00:01:23/00:31:41, 0.538s/it]: train_loss_raw=1.0073, running_loss=1.0621, LR=0.000100
[2025-08-10 17:50:32,285][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044472] [Batch 00168/03692] [00:01:30/00:31:34, 0.538s/it]: train_loss_raw=1.0035, running_loss=1.0596, LR=0.000100
[2025-08-10 17:50:38,642][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044484] [Batch 00180/03692] [00:01:36/00:31:26, 0.537s/it]: train_loss_raw=0.9709, running_loss=1.0524, LR=0.000100
[2025-08-10 17:50:44,904][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044496] [Batch 00192/03692] [00:01:42/00:31:16, 0.536s/it]: train_loss_raw=1.1168, running_loss=1.0500, LR=0.000100
[2025-08-10 17:50:51,241][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044508] [Batch 00204/03692] [00:01:49/00:31:08, 0.536s/it]: train_loss_raw=0.9505, running_loss=1.0466, LR=0.000100
[2025-08-10 17:50:57,709][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044520] [Batch 00216/03692] [00:01:55/00:31:02, 0.536s/it]: train_loss_raw=1.0328, running_loss=1.0471, LR=0.000100
[2025-08-10 17:51:04,147][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044532] [Batch 00228/03692] [00:02:02/00:30:56, 0.536s/it]: train_loss_raw=1.1640, running_loss=1.0461, LR=0.000100
[2025-08-10 17:51:10,537][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044544] [Batch 00240/03692] [00:02:08/00:30:49, 0.536s/it]: train_loss_raw=1.0799, running_loss=1.0439, LR=0.000100
[2025-08-10 17:51:16,942][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044556] [Batch 00252/03692] [00:02:14/00:30:42, 0.536s/it]: train_loss_raw=1.1288, running_loss=1.0433, LR=0.000100
[2025-08-10 17:51:23,459][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044568] [Batch 00264/03692] [00:02:21/00:30:37, 0.536s/it]: train_loss_raw=1.0941, running_loss=1.0467, LR=0.000100
[2025-08-10 17:51:29,957][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044580] [Batch 00276/03692] [00:02:28/00:30:31, 0.536s/it]: train_loss_raw=0.9139, running_loss=1.0483, LR=0.000100
[2025-08-10 17:51:36,543][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044592] [Batch 00288/03692] [00:02:34/00:30:27, 0.537s/it]: train_loss_raw=1.1655, running_loss=1.0485, LR=0.000100
[2025-08-10 17:51:43,031][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044604] [Batch 00300/03692] [00:02:41/00:30:21, 0.537s/it]: train_loss_raw=1.2116, running_loss=1.0464, LR=0.000100
[2025-08-10 17:51:49,650][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044616] [Batch 00312/03692] [00:02:47/00:30:16, 0.537s/it]: train_loss_raw=0.9786, running_loss=1.0440, LR=0.000100
[2025-08-10 17:51:56,227][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044628] [Batch 00324/03692] [00:02:54/00:30:11, 0.538s/it]: train_loss_raw=0.9754, running_loss=1.0445, LR=0.000100
[2025-08-10 17:52:02,482][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044640] [Batch 00336/03692] [00:03:00/00:30:03, 0.537s/it]: train_loss_raw=1.0235, running_loss=1.0400, LR=0.000100
[2025-08-10 17:52:08,931][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044652] [Batch 00348/03692] [00:03:06/00:29:56, 0.537s/it]: train_loss_raw=0.9976, running_loss=1.0339, LR=0.000100
[2025-08-10 17:52:15,366][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044664] [Batch 00360/03692] [00:03:13/00:29:50, 0.537s/it]: train_loss_raw=0.9887, running_loss=1.0389, LR=0.000100
[2025-08-10 17:52:21,854][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044676] [Batch 00372/03692] [00:03:19/00:29:44, 0.537s/it]: train_loss_raw=1.0081, running_loss=1.0388, LR=0.000100
[2025-08-10 17:52:28,422][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044688] [Batch 00384/03692] [00:03:26/00:29:38, 0.538s/it]: train_loss_raw=1.0630, running_loss=1.0374, LR=0.000100
[2025-08-10 17:52:34,856][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044700] [Batch 00396/03692] [00:03:32/00:29:32, 0.538s/it]: train_loss_raw=0.9802, running_loss=1.0369, LR=0.000100
[2025-08-10 17:52:41,306][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044712] [Batch 00408/03692] [00:03:39/00:29:25, 0.538s/it]: train_loss_raw=1.1265, running_loss=1.0389, LR=0.000100
[2025-08-10 17:52:47,872][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044724] [Batch 00420/03692] [00:03:45/00:29:20, 0.538s/it]: train_loss_raw=1.0120, running_loss=1.0366, LR=0.000100
[2025-08-10 17:52:54,332][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044736] [Batch 00432/03692] [00:03:52/00:29:13, 0.538s/it]: train_loss_raw=1.1488, running_loss=1.0416, LR=0.000100
[2025-08-10 17:53:00,585][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044748] [Batch 00444/03692] [00:03:58/00:29:05, 0.537s/it]: train_loss_raw=1.0197, running_loss=1.0412, LR=0.000100
[2025-08-10 17:53:07,173][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044760] [Batch 00456/03692] [00:04:05/00:29:00, 0.538s/it]: train_loss_raw=1.0351, running_loss=1.0425, LR=0.000100
[2025-08-10 17:53:13,706][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044772] [Batch 00468/03692] [00:04:11/00:28:54, 0.538s/it]: train_loss_raw=1.1456, running_loss=1.0448, LR=0.000100
[2025-08-10 17:53:20,080][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044784] [Batch 00480/03692] [00:04:18/00:28:47, 0.538s/it]: train_loss_raw=0.9070, running_loss=1.0427, LR=0.000100
[2025-08-10 17:53:26,598][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044796] [Batch 00492/03692] [00:04:24/00:28:41, 0.538s/it]: train_loss_raw=0.9543, running_loss=1.0379, LR=0.000100
[2025-08-10 17:53:33,170][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044808] [Batch 00504/03692] [00:04:31/00:28:35, 0.538s/it]: train_loss_raw=1.0942, running_loss=1.0401, LR=0.000100
[2025-08-10 17:53:39,717][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044820] [Batch 00516/03692] [00:04:37/00:28:29, 0.538s/it]: train_loss_raw=1.0172, running_loss=1.0407, LR=0.000100
[2025-08-10 17:53:46,317][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044832] [Batch 00528/03692] [00:04:44/00:28:24, 0.539s/it]: train_loss_raw=1.1011, running_loss=1.0388, LR=0.000100
[2025-08-10 17:53:52,934][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044844] [Batch 00540/03692] [00:04:50/00:28:18, 0.539s/it]: train_loss_raw=1.1797, running_loss=1.0378, LR=0.000100
[2025-08-10 17:53:59,571][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044856] [Batch 00552/03692] [00:04:57/00:28:12, 0.539s/it]: train_loss_raw=1.0429, running_loss=1.0430, LR=0.000100
[2025-08-10 17:54:05,809][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044868] [Batch 00564/03692] [00:05:03/00:28:05, 0.539s/it]: train_loss_raw=0.9053, running_loss=1.0413, LR=0.000100
[2025-08-10 17:54:11,947][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044880] [Batch 00576/03692] [00:05:09/00:27:56, 0.538s/it]: train_loss_raw=1.1546, running_loss=1.0409, LR=0.000100
[2025-08-10 17:54:18,272][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044892] [Batch 00588/03692] [00:05:16/00:27:49, 0.538s/it]: train_loss_raw=1.0617, running_loss=1.0419, LR=0.000100
[2025-08-10 17:54:24,553][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044904] [Batch 00600/03692] [00:05:22/00:27:42, 0.538s/it]: train_loss_raw=0.9764, running_loss=1.0405, LR=0.000100
[2025-08-10 17:54:30,734][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044916] [Batch 00612/03692] [00:05:28/00:27:34, 0.537s/it]: train_loss_raw=1.0026, running_loss=1.0368, LR=0.000100
[2025-08-10 17:54:37,156][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044928] [Batch 00624/03692] [00:05:35/00:27:28, 0.537s/it]: train_loss_raw=1.1728, running_loss=1.0383, LR=0.000100
[2025-08-10 17:54:43,614][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044940] [Batch 00636/03692] [00:05:41/00:27:21, 0.537s/it]: train_loss_raw=0.9645, running_loss=1.0347, LR=0.000100
[2025-08-10 17:54:50,003][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044952] [Batch 00648/03692] [00:05:48/00:27:14, 0.537s/it]: train_loss_raw=1.0776, running_loss=1.0349, LR=0.000100
[2025-08-10 17:54:56,247][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044964] [Batch 00660/03692] [00:05:54/00:27:07, 0.537s/it]: train_loss_raw=1.1138, running_loss=1.0369, LR=0.000100
[2025-08-10 17:55:02,530][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044976] [Batch 00672/03692] [00:06:00/00:27:00, 0.537s/it]: train_loss_raw=1.1190, running_loss=1.0373, LR=0.000100
[2025-08-10 17:55:08,564][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 044988] [Batch 00684/03692] [00:06:06/00:26:52, 0.536s/it]: train_loss_raw=0.9557, running_loss=1.0359, LR=0.000100
[2025-08-10 17:55:14,640][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045000] [Batch 00696/03692] [00:06:12/00:26:44, 0.535s/it]: train_loss_raw=0.9335, running_loss=1.0324, LR=0.000100
[2025-08-10 17:55:21,139][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045012] [Batch 00708/03692] [00:06:19/00:26:38, 0.536s/it]: train_loss_raw=1.0023, running_loss=1.0296, LR=0.000100
[2025-08-10 17:55:27,530][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045024] [Batch 00720/03692] [00:06:25/00:26:31, 0.536s/it]: train_loss_raw=0.8881, running_loss=1.0322, LR=0.000100
[2025-08-10 17:55:33,794][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045036] [Batch 00732/03692] [00:06:31/00:26:24, 0.535s/it]: train_loss_raw=0.9412, running_loss=1.0320, LR=0.000100
[2025-08-10 17:55:40,331][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045048] [Batch 00744/03692] [00:06:38/00:26:18, 0.535s/it]: train_loss_raw=1.1844, running_loss=1.0302, LR=0.000100
[2025-08-10 17:55:46,803][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045060] [Batch 00756/03692] [00:06:44/00:26:12, 0.536s/it]: train_loss_raw=1.0938, running_loss=1.0300, LR=0.000100
[2025-08-10 17:55:53,304][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045072] [Batch 00768/03692] [00:06:51/00:26:06, 0.536s/it]: train_loss_raw=0.9461, running_loss=1.0278, LR=0.000100
[2025-08-10 17:55:59,826][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045084] [Batch 00780/03692] [00:06:57/00:26:00, 0.536s/it]: train_loss_raw=1.1360, running_loss=1.0327, LR=0.000100
[2025-08-10 17:56:06,291][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045096] [Batch 00792/03692] [00:07:04/00:25:53, 0.536s/it]: train_loss_raw=0.9883, running_loss=1.0343, LR=0.000100
[2025-08-10 17:56:12,709][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045108] [Batch 00804/03692] [00:07:10/00:25:47, 0.536s/it]: train_loss_raw=0.9042, running_loss=1.0274, LR=0.000100
[2025-08-10 17:56:19,094][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045120] [Batch 00816/03692] [00:07:17/00:25:40, 0.536s/it]: train_loss_raw=1.0484, running_loss=1.0277, LR=0.000100
[2025-08-10 17:56:25,364][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045132] [Batch 00828/03692] [00:07:23/00:25:33, 0.536s/it]: train_loss_raw=1.1978, running_loss=1.0276, LR=0.000100
[2025-08-10 17:56:31,760][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045144] [Batch 00840/03692] [00:07:29/00:25:27, 0.535s/it]: train_loss_raw=1.0059, running_loss=1.0320, LR=0.000100
[2025-08-10 17:56:38,186][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045156] [Batch 00852/03692] [00:07:36/00:25:20, 0.535s/it]: train_loss_raw=1.0089, running_loss=1.0309, LR=0.000100
[2025-08-10 17:56:44,667][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045168] [Batch 00864/03692] [00:07:42/00:25:14, 0.536s/it]: train_loss_raw=1.0395, running_loss=1.0336, LR=0.000100
[2025-08-10 17:56:51,217][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045180] [Batch 00876/03692] [00:07:49/00:25:08, 0.536s/it]: train_loss_raw=1.0754, running_loss=1.0364, LR=0.000100
[2025-08-10 17:56:57,565][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045192] [Batch 00888/03692] [00:07:55/00:25:01, 0.536s/it]: train_loss_raw=1.0583, running_loss=1.0356, LR=0.000100
[2025-08-10 17:57:03,854][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045204] [Batch 00900/03692] [00:08:01/00:24:54, 0.535s/it]: train_loss_raw=0.9652, running_loss=1.0350, LR=0.000100
[2025-08-10 17:57:10,287][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045216] [Batch 00912/03692] [00:08:08/00:24:48, 0.535s/it]: train_loss_raw=0.9406, running_loss=1.0349, LR=0.000100
[2025-08-10 17:57:16,701][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045228] [Batch 00924/03692] [00:08:14/00:24:42, 0.535s/it]: train_loss_raw=1.0771, running_loss=1.0335, LR=0.000100
[2025-08-10 17:57:23,088][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045240] [Batch 00936/03692] [00:08:21/00:24:35, 0.535s/it]: train_loss_raw=1.0397, running_loss=1.0334, LR=0.000100
[2025-08-10 17:57:29,536][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045252] [Batch 00948/03692] [00:08:27/00:24:29, 0.535s/it]: train_loss_raw=0.9732, running_loss=1.0318, LR=0.000100
[2025-08-10 17:57:36,114][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045264] [Batch 00960/03692] [00:08:34/00:24:23, 0.536s/it]: train_loss_raw=1.1515, running_loss=1.0334, LR=0.000100
[2025-08-10 17:57:42,566][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045276] [Batch 00972/03692] [00:08:40/00:24:16, 0.536s/it]: train_loss_raw=1.0635, running_loss=1.0365, LR=0.000100
[2025-08-10 17:57:48,978][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045288] [Batch 00984/03692] [00:08:47/00:24:10, 0.536s/it]: train_loss_raw=1.1189, running_loss=1.0360, LR=0.000100
[2025-08-10 17:57:55,396][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045300] [Batch 00996/03692] [00:08:53/00:24:03, 0.536s/it]: train_loss_raw=1.0472, running_loss=1.0348, LR=0.000100
[2025-08-10 17:58:01,865][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045312] [Batch 01008/03692] [00:08:59/00:23:57, 0.536s/it]: train_loss_raw=1.1286, running_loss=1.0336, LR=0.000100
[2025-08-10 17:58:08,270][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045324] [Batch 01020/03692] [00:09:06/00:23:51, 0.536s/it]: train_loss_raw=0.9994, running_loss=1.0304, LR=0.000100
[2025-08-10 17:58:14,706][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045336] [Batch 01032/03692] [00:09:12/00:23:44, 0.536s/it]: train_loss_raw=1.0873, running_loss=1.0284, LR=0.000100
[2025-08-10 17:58:21,213][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045348] [Batch 01044/03692] [00:09:19/00:23:38, 0.536s/it]: train_loss_raw=1.0367, running_loss=1.0290, LR=0.000100
[2025-08-10 17:58:27,656][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045360] [Batch 01056/03692] [00:09:25/00:23:32, 0.536s/it]: train_loss_raw=1.0266, running_loss=1.0307, LR=0.000100
[2025-08-10 17:58:34,034][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045372] [Batch 01068/03692] [00:09:32/00:23:25, 0.536s/it]: train_loss_raw=1.0649, running_loss=1.0288, LR=0.000100
[2025-08-10 17:58:40,475][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045384] [Batch 01080/03692] [00:09:38/00:23:19, 0.536s/it]: train_loss_raw=0.9784, running_loss=1.0288, LR=0.000100
[2025-08-10 17:58:46,803][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045396] [Batch 01092/03692] [00:09:44/00:23:12, 0.536s/it]: train_loss_raw=0.9438, running_loss=1.0240, LR=0.000100
[2025-08-10 17:58:53,119][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045408] [Batch 01104/03692] [00:09:51/00:23:05, 0.535s/it]: train_loss_raw=1.0223, running_loss=1.0218, LR=0.000100
[2025-08-10 17:58:59,552][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045420] [Batch 01116/03692] [00:09:57/00:22:59, 0.535s/it]: train_loss_raw=1.0210, running_loss=1.0237, LR=0.000100
[2025-08-10 17:59:05,930][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045432] [Batch 01128/03692] [00:10:03/00:22:52, 0.535s/it]: train_loss_raw=1.0318, running_loss=1.0236, LR=0.000100
[2025-08-10 17:59:12,277][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045444] [Batch 01140/03692] [00:10:10/00:22:46, 0.535s/it]: train_loss_raw=1.0947, running_loss=1.0274, LR=0.000100
[2025-08-10 17:59:18,526][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045456] [Batch 01152/03692] [00:10:16/00:22:39, 0.535s/it]: train_loss_raw=1.1949, running_loss=1.0297, LR=0.000100
[2025-08-10 17:59:24,891][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045468] [Batch 01164/03692] [00:10:22/00:22:32, 0.535s/it]: train_loss_raw=0.9884, running_loss=1.0285, LR=0.000100
[2025-08-10 17:59:31,268][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045480] [Batch 01176/03692] [00:10:29/00:22:26, 0.535s/it]: train_loss_raw=1.0024, running_loss=1.0273, LR=0.000100
[2025-08-10 17:59:37,528][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045492] [Batch 01188/03692] [00:10:35/00:22:19, 0.535s/it]: train_loss_raw=0.9575, running_loss=1.0317, LR=0.000100
[2025-08-10 17:59:43,739][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045504] [Batch 01200/03692] [00:10:41/00:22:12, 0.535s/it]: train_loss_raw=1.1315, running_loss=1.0342, LR=0.000100
[2025-08-10 17:59:50,197][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045516] [Batch 01212/03692] [00:10:48/00:22:06, 0.535s/it]: train_loss_raw=0.9837, running_loss=1.0364, LR=0.000100
[2025-08-10 17:59:56,695][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045528] [Batch 01224/03692] [00:10:54/00:22:00, 0.535s/it]: train_loss_raw=1.0112, running_loss=1.0329, LR=0.000100
[2025-08-10 18:00:03,192][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045540] [Batch 01236/03692] [00:11:01/00:21:53, 0.535s/it]: train_loss_raw=1.1737, running_loss=1.0385, LR=0.000100
[2025-08-10 18:00:09,620][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045552] [Batch 01248/03692] [00:11:07/00:21:47, 0.535s/it]: train_loss_raw=1.2126, running_loss=1.0379, LR=0.000100
[2025-08-10 18:00:16,052][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045564] [Batch 01260/03692] [00:11:14/00:21:41, 0.535s/it]: train_loss_raw=1.1136, running_loss=1.0420, LR=0.000100
[2025-08-10 18:00:22,441][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045576] [Batch 01272/03692] [00:11:20/00:21:34, 0.535s/it]: train_loss_raw=0.9820, running_loss=1.0369, LR=0.000100
[2025-08-10 18:00:28,850][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045588] [Batch 01284/03692] [00:11:26/00:21:28, 0.535s/it]: train_loss_raw=1.0775, running_loss=1.0348, LR=0.000100
[2025-08-10 18:00:35,244][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045600] [Batch 01296/03692] [00:11:33/00:21:21, 0.535s/it]: train_loss_raw=0.9619, running_loss=1.0339, LR=0.000100
[2025-08-10 18:00:41,704][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045612] [Batch 01308/03692] [00:11:39/00:21:15, 0.535s/it]: train_loss_raw=1.1690, running_loss=1.0320, LR=0.000100
[2025-08-10 18:00:48,147][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045624] [Batch 01320/03692] [00:11:46/00:21:09, 0.535s/it]: train_loss_raw=1.1019, running_loss=1.0313, LR=0.000100
[2025-08-10 18:00:54,573][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045636] [Batch 01332/03692] [00:11:52/00:21:02, 0.535s/it]: train_loss_raw=0.9386, running_loss=1.0282, LR=0.000100
[2025-08-10 18:01:00,954][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045648] [Batch 01344/03692] [00:11:59/00:20:56, 0.535s/it]: train_loss_raw=1.1016, running_loss=1.0249, LR=0.000100
[2025-08-10 18:01:07,449][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045660] [Batch 01356/03692] [00:12:05/00:20:49, 0.535s/it]: train_loss_raw=0.9548, running_loss=1.0271, LR=0.000100
[2025-08-10 18:01:14,089][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045672] [Batch 01368/03692] [00:12:12/00:20:43, 0.535s/it]: train_loss_raw=0.9965, running_loss=1.0285, LR=0.000100
[2025-08-10 18:01:20,600][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045684] [Batch 01380/03692] [00:12:18/00:20:37, 0.535s/it]: train_loss_raw=1.0069, running_loss=1.0270, LR=0.000100
[2025-08-10 18:01:27,231][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045696] [Batch 01392/03692] [00:12:25/00:20:31, 0.535s/it]: train_loss_raw=1.0213, running_loss=1.0284, LR=0.000100
[2025-08-10 18:01:33,339][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045708] [Batch 01404/03692] [00:12:31/00:20:24, 0.535s/it]: train_loss_raw=0.9980, running_loss=1.0306, LR=0.000100
[2025-08-10 18:01:39,882][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045720] [Batch 01416/03692] [00:12:37/00:20:18, 0.535s/it]: train_loss_raw=1.1487, running_loss=1.0284, LR=0.000100
[2025-08-10 18:01:46,486][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045732] [Batch 01428/03692] [00:12:44/00:20:12, 0.535s/it]: train_loss_raw=1.1320, running_loss=1.0328, LR=0.000100
[2025-08-10 18:01:52,968][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045744] [Batch 01440/03692] [00:12:51/00:20:05, 0.535s/it]: train_loss_raw=0.9657, running_loss=1.0309, LR=0.000100
[2025-08-10 18:01:59,395][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045756] [Batch 01452/03692] [00:12:57/00:19:59, 0.535s/it]: train_loss_raw=1.1614, running_loss=1.0320, LR=0.000100
[2025-08-10 18:02:05,826][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045768] [Batch 01464/03692] [00:13:03/00:19:52, 0.535s/it]: train_loss_raw=1.0109, running_loss=1.0326, LR=0.000100
[2025-08-10 18:02:12,274][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045780] [Batch 01476/03692] [00:13:10/00:19:46, 0.535s/it]: train_loss_raw=1.1120, running_loss=1.0331, LR=0.000100
[2025-08-10 18:02:18,737][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045792] [Batch 01488/03692] [00:13:16/00:19:40, 0.535s/it]: train_loss_raw=1.0273, running_loss=1.0300, LR=0.000100
[2025-08-10 18:02:25,372][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045804] [Batch 01500/03692] [00:13:23/00:19:34, 0.536s/it]: train_loss_raw=1.0170, running_loss=1.0309, LR=0.000100
[2025-08-10 18:02:31,978][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045816] [Batch 01512/03692] [00:13:30/00:19:27, 0.536s/it]: train_loss_raw=0.9785, running_loss=1.0270, LR=0.000100
[2025-08-10 18:02:38,515][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045828] [Batch 01524/03692] [00:13:36/00:19:21, 0.536s/it]: train_loss_raw=0.9927, running_loss=1.0271, LR=0.000100
[2025-08-10 18:02:45,013][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045840] [Batch 01536/03692] [00:13:43/00:19:15, 0.536s/it]: train_loss_raw=0.9738, running_loss=1.0241, LR=0.000100
[2025-08-10 18:02:51,402][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045852] [Batch 01548/03692] [00:13:49/00:19:08, 0.536s/it]: train_loss_raw=1.0853, running_loss=1.0277, LR=0.000100
[2025-08-10 18:02:57,819][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045864] [Batch 01560/03692] [00:13:55/00:19:02, 0.536s/it]: train_loss_raw=1.0006, running_loss=1.0278, LR=0.000100
[2025-08-10 18:03:04,229][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045876] [Batch 01572/03692] [00:14:02/00:18:55, 0.536s/it]: train_loss_raw=0.9777, running_loss=1.0270, LR=0.000100
[2025-08-10 18:03:10,671][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045888] [Batch 01584/03692] [00:14:08/00:18:49, 0.536s/it]: train_loss_raw=1.1496, running_loss=1.0276, LR=0.000100
[2025-08-10 18:03:17,050][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045900] [Batch 01596/03692] [00:14:15/00:18:42, 0.536s/it]: train_loss_raw=1.0242, running_loss=1.0281, LR=0.000100
[2025-08-10 18:03:23,540][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045912] [Batch 01608/03692] [00:14:21/00:18:36, 0.536s/it]: train_loss_raw=1.0695, running_loss=1.0318, LR=0.000100
[2025-08-10 18:03:29,992][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045924] [Batch 01620/03692] [00:14:28/00:18:30, 0.536s/it]: train_loss_raw=0.9203, running_loss=1.0356, LR=0.000100
[2025-08-10 18:03:36,469][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045936] [Batch 01632/03692] [00:14:34/00:18:23, 0.536s/it]: train_loss_raw=1.0052, running_loss=1.0400, LR=0.000100
[2025-08-10 18:03:42,796][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045948] [Batch 01644/03692] [00:14:40/00:18:17, 0.536s/it]: train_loss_raw=0.9434, running_loss=1.0350, LR=0.000100
[2025-08-10 18:03:49,189][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045960] [Batch 01656/03692] [00:14:47/00:18:10, 0.536s/it]: train_loss_raw=0.9628, running_loss=1.0332, LR=0.000100
[2025-08-10 18:03:55,622][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045972] [Batch 01668/03692] [00:14:53/00:18:04, 0.536s/it]: train_loss_raw=1.0747, running_loss=1.0308, LR=0.000100
[2025-08-10 18:04:01,963][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045984] [Batch 01680/03692] [00:15:00/00:17:57, 0.536s/it]: train_loss_raw=0.9706, running_loss=1.0342, LR=0.000100
[2025-08-10 18:04:08,242][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 045996] [Batch 01692/03692] [00:15:06/00:17:51, 0.536s/it]: train_loss_raw=0.9203, running_loss=1.0297, LR=0.000100
[2025-08-10 18:04:19,365][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046008] [Batch 01704/03692] [00:15:17/00:17:50, 0.538s/it]: train_loss_raw=0.8859, running_loss=1.0270, LR=0.000100
[2025-08-10 18:04:25,886][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046020] [Batch 01716/03692] [00:15:23/00:17:43, 0.538s/it]: train_loss_raw=0.9420, running_loss=1.0300, LR=0.000100
[2025-08-10 18:04:32,347][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046032] [Batch 01728/03692] [00:15:30/00:17:37, 0.538s/it]: train_loss_raw=1.0144, running_loss=1.0284, LR=0.000100
[2025-08-10 18:04:38,713][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046044] [Batch 01740/03692] [00:15:36/00:17:30, 0.538s/it]: train_loss_raw=0.9091, running_loss=1.0254, LR=0.000100
[2025-08-10 18:04:45,182][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046056] [Batch 01752/03692] [00:15:43/00:17:24, 0.538s/it]: train_loss_raw=1.0619, running_loss=1.0230, LR=0.000100
[2025-08-10 18:04:51,597][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046068] [Batch 01764/03692] [00:15:49/00:17:17, 0.538s/it]: train_loss_raw=1.0533, running_loss=1.0246, LR=0.000100
[2025-08-10 18:04:57,995][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046080] [Batch 01776/03692] [00:15:56/00:17:11, 0.538s/it]: train_loss_raw=1.0570, running_loss=1.0233, LR=0.000100
[2025-08-10 18:05:04,504][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046092] [Batch 01788/03692] [00:16:02/00:17:05, 0.538s/it]: train_loss_raw=1.1182, running_loss=1.0241, LR=0.000100
[2025-08-10 18:05:11,047][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046104] [Batch 01800/03692] [00:16:09/00:16:58, 0.538s/it]: train_loss_raw=0.9445, running_loss=1.0241, LR=0.000100
[2025-08-10 18:05:17,437][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046116] [Batch 01812/03692] [00:16:15/00:16:52, 0.538s/it]: train_loss_raw=0.9614, running_loss=1.0210, LR=0.000100
[2025-08-10 18:05:23,970][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046128] [Batch 01824/03692] [00:16:22/00:16:45, 0.538s/it]: train_loss_raw=1.0461, running_loss=1.0189, LR=0.000100
[2025-08-10 18:05:30,590][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046140] [Batch 01836/03692] [00:16:28/00:16:39, 0.538s/it]: train_loss_raw=1.0354, running_loss=1.0164, LR=0.000100
[2025-08-10 18:05:37,116][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046152] [Batch 01848/03692] [00:16:35/00:16:33, 0.539s/it]: train_loss_raw=1.0181, running_loss=1.0181, LR=0.000100
[2025-08-10 18:05:43,527][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046164] [Batch 01860/03692] [00:16:41/00:16:26, 0.538s/it]: train_loss_raw=0.9482, running_loss=1.0200, LR=0.000100
[2025-08-10 18:05:49,975][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046176] [Batch 01872/03692] [00:16:48/00:16:20, 0.538s/it]: train_loss_raw=1.0546, running_loss=1.0160, LR=0.000100
[2025-08-10 18:05:56,424][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046188] [Batch 01884/03692] [00:16:54/00:16:13, 0.538s/it]: train_loss_raw=1.0996, running_loss=1.0199, LR=0.000100
[2025-08-10 18:06:02,763][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046200] [Batch 01896/03692] [00:17:00/00:16:06, 0.538s/it]: train_loss_raw=0.8951, running_loss=1.0203, LR=0.000100
[2025-08-10 18:06:09,170][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046212] [Batch 01908/03692] [00:17:07/00:16:00, 0.538s/it]: train_loss_raw=0.9705, running_loss=1.0185, LR=0.000100
[2025-08-10 18:06:15,565][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046224] [Batch 01920/03692] [00:17:13/00:15:53, 0.538s/it]: train_loss_raw=1.1840, running_loss=1.0198, LR=0.000100
[2025-08-10 18:06:21,988][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046236] [Batch 01932/03692] [00:17:20/00:15:47, 0.538s/it]: train_loss_raw=1.0156, running_loss=1.0200, LR=0.000100
[2025-08-10 18:06:28,404][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046248] [Batch 01944/03692] [00:17:26/00:15:40, 0.538s/it]: train_loss_raw=0.8784, running_loss=1.0186, LR=0.000100
[2025-08-10 18:06:34,694][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046260] [Batch 01956/03692] [00:17:32/00:15:34, 0.538s/it]: train_loss_raw=1.1371, running_loss=1.0173, LR=0.000100
[2025-08-10 18:06:40,999][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046272] [Batch 01968/03692] [00:17:39/00:15:27, 0.538s/it]: train_loss_raw=1.0341, running_loss=1.0178, LR=0.000100
[2025-08-10 18:06:47,284][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046284] [Batch 01980/03692] [00:17:45/00:15:21, 0.538s/it]: train_loss_raw=1.0324, running_loss=1.0212, LR=0.000100
[2025-08-10 18:06:53,675][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046296] [Batch 01992/03692] [00:17:51/00:15:14, 0.538s/it]: train_loss_raw=1.2221, running_loss=1.0236, LR=0.000100
[2025-08-10 18:07:00,097][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046308] [Batch 02004/03692] [00:17:58/00:15:08, 0.538s/it]: train_loss_raw=0.9329, running_loss=1.0219, LR=0.000100
[2025-08-10 18:07:06,508][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046320] [Batch 02016/03692] [00:18:04/00:15:01, 0.538s/it]: train_loss_raw=1.0541, running_loss=1.0232, LR=0.000100
[2025-08-10 18:07:12,951][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046332] [Batch 02028/03692] [00:18:11/00:14:55, 0.538s/it]: train_loss_raw=0.9576, running_loss=1.0230, LR=0.000100
[2025-08-10 18:07:19,564][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046344] [Batch 02040/03692] [00:18:17/00:14:48, 0.538s/it]: train_loss_raw=1.0368, running_loss=1.0238, LR=0.000100
[2025-08-10 18:07:25,990][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046356] [Batch 02052/03692] [00:18:24/00:14:42, 0.538s/it]: train_loss_raw=0.9676, running_loss=1.0225, LR=0.000100
[2025-08-10 18:07:32,312][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046368] [Batch 02064/03692] [00:18:30/00:14:35, 0.538s/it]: train_loss_raw=1.0211, running_loss=1.0232, LR=0.000100
[2025-08-10 18:07:38,812][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046380] [Batch 02076/03692] [00:18:36/00:14:29, 0.538s/it]: train_loss_raw=1.0667, running_loss=1.0245, LR=0.000100
[2025-08-10 18:07:45,359][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046392] [Batch 02088/03692] [00:18:43/00:14:23, 0.538s/it]: train_loss_raw=1.0869, running_loss=1.0216, LR=0.000100
[2025-08-10 18:07:51,752][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046404] [Batch 02100/03692] [00:18:49/00:14:16, 0.538s/it]: train_loss_raw=1.0626, running_loss=1.0188, LR=0.000100
[2025-08-10 18:07:58,204][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046416] [Batch 02112/03692] [00:18:56/00:14:10, 0.538s/it]: train_loss_raw=1.0516, running_loss=1.0252, LR=0.000100
[2025-08-10 18:08:04,681][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046428] [Batch 02124/03692] [00:19:02/00:14:03, 0.538s/it]: train_loss_raw=1.1190, running_loss=1.0268, LR=0.000100
[2025-08-10 18:08:11,021][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046440] [Batch 02136/03692] [00:19:09/00:13:57, 0.538s/it]: train_loss_raw=1.0877, running_loss=1.0207, LR=0.000100
[2025-08-10 18:08:17,364][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046452] [Batch 02148/03692] [00:19:15/00:13:50, 0.538s/it]: train_loss_raw=0.9994, running_loss=1.0226, LR=0.000100
[2025-08-10 18:08:23,818][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046464] [Batch 02160/03692] [00:19:21/00:13:44, 0.538s/it]: train_loss_raw=1.0435, running_loss=1.0209, LR=0.000100
[2025-08-10 18:08:30,092][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046476] [Batch 02172/03692] [00:19:28/00:13:37, 0.538s/it]: train_loss_raw=0.9274, running_loss=1.0225, LR=0.000100
[2025-08-10 18:08:36,474][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046488] [Batch 02184/03692] [00:19:34/00:13:30, 0.538s/it]: train_loss_raw=0.9218, running_loss=1.0238, LR=0.000100
[2025-08-10 18:08:42,945][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046500] [Batch 02196/03692] [00:19:40/00:13:24, 0.538s/it]: train_loss_raw=0.8848, running_loss=1.0206, LR=0.000100
[2025-08-10 18:08:49,232][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046512] [Batch 02208/03692] [00:19:47/00:13:17, 0.538s/it]: train_loss_raw=1.0341, running_loss=1.0218, LR=0.000100
[2025-08-10 18:08:55,606][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046524] [Batch 02220/03692] [00:19:53/00:13:11, 0.538s/it]: train_loss_raw=0.9937, running_loss=1.0211, LR=0.000100
[2025-08-10 18:09:01,965][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046536] [Batch 02232/03692] [00:20:00/00:13:04, 0.538s/it]: train_loss_raw=0.9589, running_loss=1.0200, LR=0.000100
[2025-08-10 18:09:08,335][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046548] [Batch 02244/03692] [00:20:06/00:12:58, 0.538s/it]: train_loss_raw=1.0450, running_loss=1.0212, LR=0.000100
[2025-08-10 18:09:14,722][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046560] [Batch 02256/03692] [00:20:12/00:12:51, 0.538s/it]: train_loss_raw=1.0272, running_loss=1.0208, LR=0.000100
[2025-08-10 18:09:21,218][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046572] [Batch 02268/03692] [00:20:19/00:12:45, 0.538s/it]: train_loss_raw=1.0887, running_loss=1.0206, LR=0.000100
[2025-08-10 18:09:27,646][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046584] [Batch 02280/03692] [00:20:25/00:12:39, 0.538s/it]: train_loss_raw=1.0614, running_loss=1.0250, LR=0.000100
[2025-08-10 18:09:34,092][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046596] [Batch 02292/03692] [00:20:32/00:12:32, 0.538s/it]: train_loss_raw=1.0704, running_loss=1.0267, LR=0.000100
[2025-08-10 18:09:40,485][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046608] [Batch 02304/03692] [00:20:38/00:12:26, 0.538s/it]: train_loss_raw=0.9932, running_loss=1.0306, LR=0.000100
[2025-08-10 18:09:47,090][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046620] [Batch 02316/03692] [00:20:45/00:12:19, 0.538s/it]: train_loss_raw=1.0827, running_loss=1.0258, LR=0.000100
[2025-08-10 18:09:53,597][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046632] [Batch 02328/03692] [00:20:51/00:12:13, 0.538s/it]: train_loss_raw=1.0152, running_loss=1.0222, LR=0.000100
[2025-08-10 18:10:00,152][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046644] [Batch 02340/03692] [00:20:58/00:12:06, 0.538s/it]: train_loss_raw=0.8500, running_loss=1.0181, LR=0.000100
[2025-08-10 18:10:06,629][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046656] [Batch 02352/03692] [00:21:04/00:12:00, 0.538s/it]: train_loss_raw=0.8571, running_loss=1.0128, LR=0.000100
[2025-08-10 18:10:13,104][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046668] [Batch 02364/03692] [00:21:11/00:11:54, 0.538s/it]: train_loss_raw=1.0916, running_loss=1.0196, LR=0.000100
[2025-08-10 18:10:19,655][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046680] [Batch 02376/03692] [00:21:17/00:11:47, 0.538s/it]: train_loss_raw=0.9034, running_loss=1.0185, LR=0.000100
[2025-08-10 18:10:26,165][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046692] [Batch 02388/03692] [00:21:24/00:11:41, 0.538s/it]: train_loss_raw=0.9919, running_loss=1.0196, LR=0.000100
[2025-08-10 18:10:32,801][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046704] [Batch 02400/03692] [00:21:30/00:11:34, 0.538s/it]: train_loss_raw=1.0245, running_loss=1.0161, LR=0.000100
[2025-08-10 18:10:39,402][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046716] [Batch 02412/03692] [00:21:37/00:11:28, 0.538s/it]: train_loss_raw=0.8706, running_loss=1.0162, LR=0.000100
[2025-08-10 18:10:45,929][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046728] [Batch 02424/03692] [00:21:43/00:11:22, 0.538s/it]: train_loss_raw=0.9918, running_loss=1.0137, LR=0.000100
[2025-08-10 18:10:52,566][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046740] [Batch 02436/03692] [00:21:50/00:11:15, 0.538s/it]: train_loss_raw=1.0987, running_loss=1.0151, LR=0.000100
[2025-08-10 18:10:59,094][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046752] [Batch 02448/03692] [00:21:57/00:11:09, 0.538s/it]: train_loss_raw=1.0390, running_loss=1.0134, LR=0.000100
[2025-08-10 18:11:05,648][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046764] [Batch 02460/03692] [00:22:03/00:11:02, 0.538s/it]: train_loss_raw=0.9047, running_loss=1.0098, LR=0.000100
[2025-08-10 18:11:12,141][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046776] [Batch 02472/03692] [00:22:10/00:10:56, 0.538s/it]: train_loss_raw=1.0405, running_loss=1.0158, LR=0.000100
[2025-08-10 18:11:18,615][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046788] [Batch 02484/03692] [00:22:16/00:10:50, 0.538s/it]: train_loss_raw=0.8508, running_loss=1.0138, LR=0.000100
[2025-08-10 18:11:25,177][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046800] [Batch 02496/03692] [00:22:23/00:10:43, 0.538s/it]: train_loss_raw=1.1124, running_loss=1.0142, LR=0.000100
[2025-08-10 18:11:31,768][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046812] [Batch 02508/03692] [00:22:29/00:10:37, 0.538s/it]: train_loss_raw=1.0386, running_loss=1.0131, LR=0.000100
[2025-08-10 18:11:38,242][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046824] [Batch 02520/03692] [00:22:36/00:10:30, 0.538s/it]: train_loss_raw=1.0422, running_loss=1.0166, LR=0.000100
[2025-08-10 18:11:44,810][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046836] [Batch 02532/03692] [00:22:42/00:10:24, 0.538s/it]: train_loss_raw=0.9691, running_loss=1.0134, LR=0.000100
[2025-08-10 18:11:51,242][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046848] [Batch 02544/03692] [00:22:49/00:10:17, 0.538s/it]: train_loss_raw=0.9773, running_loss=1.0104, LR=0.000100
[2025-08-10 18:11:57,623][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046860] [Batch 02556/03692] [00:22:55/00:10:11, 0.538s/it]: train_loss_raw=0.9987, running_loss=1.0103, LR=0.000100
[2025-08-10 18:12:04,196][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046872] [Batch 02568/03692] [00:23:02/00:10:05, 0.538s/it]: train_loss_raw=0.9241, running_loss=1.0077, LR=0.000100
[2025-08-10 18:12:10,561][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046884] [Batch 02580/03692] [00:23:08/00:09:58, 0.538s/it]: train_loss_raw=1.0129, running_loss=1.0065, LR=0.000100
[2025-08-10 18:12:16,929][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046896] [Batch 02592/03692] [00:23:14/00:09:52, 0.538s/it]: train_loss_raw=1.0277, running_loss=1.0103, LR=0.000100
[2025-08-10 18:12:23,381][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046908] [Batch 02604/03692] [00:23:21/00:09:45, 0.538s/it]: train_loss_raw=1.1055, running_loss=1.0111, LR=0.000100
[2025-08-10 18:12:29,657][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046920] [Batch 02616/03692] [00:23:27/00:09:39, 0.538s/it]: train_loss_raw=0.9458, running_loss=1.0101, LR=0.000100
[2025-08-10 18:12:36,029][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046932] [Batch 02628/03692] [00:23:34/00:09:32, 0.538s/it]: train_loss_raw=0.8824, running_loss=1.0091, LR=0.000100
[2025-08-10 18:12:42,445][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046944] [Batch 02640/03692] [00:23:40/00:09:26, 0.538s/it]: train_loss_raw=1.0191, running_loss=1.0079, LR=0.000100
[2025-08-10 18:12:48,976][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046956] [Batch 02652/03692] [00:23:47/00:09:19, 0.538s/it]: train_loss_raw=1.0446, running_loss=1.0098, LR=0.000100
[2025-08-10 18:12:55,454][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046968] [Batch 02664/03692] [00:23:53/00:09:13, 0.538s/it]: train_loss_raw=1.0601, running_loss=1.0130, LR=0.000100
[2025-08-10 18:13:01,900][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046980] [Batch 02676/03692] [00:23:59/00:09:06, 0.538s/it]: train_loss_raw=1.1010, running_loss=1.0110, LR=0.000100
[2025-08-10 18:13:08,366][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 046992] [Batch 02688/03692] [00:24:06/00:09:00, 0.538s/it]: train_loss_raw=0.9229, running_loss=1.0098, LR=0.000100
[2025-08-10 18:13:14,873][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047004] [Batch 02700/03692] [00:24:12/00:08:53, 0.538s/it]: train_loss_raw=1.0447, running_loss=1.0054, LR=0.000100
[2025-08-10 18:13:21,495][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047016] [Batch 02712/03692] [00:24:19/00:08:47, 0.538s/it]: train_loss_raw=1.0021, running_loss=1.0096, LR=0.000100
[2025-08-10 18:13:27,877][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047028] [Batch 02724/03692] [00:24:25/00:08:40, 0.538s/it]: train_loss_raw=1.0244, running_loss=1.0104, LR=0.000100
[2025-08-10 18:13:34,347][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047040] [Batch 02736/03692] [00:24:32/00:08:34, 0.538s/it]: train_loss_raw=0.9306, running_loss=1.0119, LR=0.000100
[2025-08-10 18:13:40,608][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047052] [Batch 02748/03692] [00:24:38/00:08:27, 0.538s/it]: train_loss_raw=0.9112, running_loss=1.0105, LR=0.000100
[2025-08-10 18:13:47,129][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047064] [Batch 02760/03692] [00:24:45/00:08:21, 0.538s/it]: train_loss_raw=0.8099, running_loss=1.0047, LR=0.000100
[2025-08-10 18:13:53,523][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047076] [Batch 02772/03692] [00:24:51/00:08:15, 0.538s/it]: train_loss_raw=1.0211, running_loss=1.0065, LR=0.000100
[2025-08-10 18:13:59,512][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047088] [Batch 02784/03692] [00:24:57/00:08:08, 0.538s/it]: train_loss_raw=0.8835, running_loss=1.0086, LR=0.000100
[2025-08-10 18:14:05,580][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047100] [Batch 02796/03692] [00:25:03/00:08:01, 0.538s/it]: train_loss_raw=1.0168, running_loss=1.0104, LR=0.000100
[2025-08-10 18:14:12,028][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047112] [Batch 02808/03692] [00:25:10/00:07:55, 0.538s/it]: train_loss_raw=1.1041, running_loss=1.0127, LR=0.000100
[2025-08-10 18:14:18,561][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047124] [Batch 02820/03692] [00:25:16/00:07:48, 0.538s/it]: train_loss_raw=0.9507, running_loss=1.0150, LR=0.000100
[2025-08-10 18:14:25,145][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047136] [Batch 02832/03692] [00:25:23/00:07:42, 0.538s/it]: train_loss_raw=1.1438, running_loss=1.0154, LR=0.000100
[2025-08-10 18:14:31,590][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047148] [Batch 02844/03692] [00:25:29/00:07:36, 0.538s/it]: train_loss_raw=1.0372, running_loss=1.0120, LR=0.000100
[2025-08-10 18:14:38,067][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047160] [Batch 02856/03692] [00:25:36/00:07:29, 0.538s/it]: train_loss_raw=0.9435, running_loss=1.0117, LR=0.000100
[2025-08-10 18:14:44,644][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047172] [Batch 02868/03692] [00:25:42/00:07:23, 0.538s/it]: train_loss_raw=1.0376, running_loss=1.0103, LR=0.000100
[2025-08-10 18:14:51,241][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047184] [Batch 02880/03692] [00:25:49/00:07:16, 0.538s/it]: train_loss_raw=1.2001, running_loss=1.0124, LR=0.000100
[2025-08-10 18:14:57,803][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047196] [Batch 02892/03692] [00:25:55/00:07:10, 0.538s/it]: train_loss_raw=0.9051, running_loss=1.0125, LR=0.000100
[2025-08-10 18:15:04,137][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047208] [Batch 02904/03692] [00:26:02/00:07:03, 0.538s/it]: train_loss_raw=1.0441, running_loss=1.0131, LR=0.000100
[2025-08-10 18:15:10,467][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047220] [Batch 02916/03692] [00:26:08/00:06:57, 0.538s/it]: train_loss_raw=1.0324, running_loss=1.0120, LR=0.000100
[2025-08-10 18:15:17,004][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047232] [Batch 02928/03692] [00:26:15/00:06:50, 0.538s/it]: train_loss_raw=0.9651, running_loss=1.0088, LR=0.000100
[2025-08-10 18:15:23,566][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047244] [Batch 02940/03692] [00:26:21/00:06:44, 0.538s/it]: train_loss_raw=0.9526, running_loss=1.0069, LR=0.000100
[2025-08-10 18:15:30,122][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047256] [Batch 02952/03692] [00:26:28/00:06:38, 0.538s/it]: train_loss_raw=0.9248, running_loss=1.0052, LR=0.000100
[2025-08-10 18:15:36,331][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047268] [Batch 02964/03692] [00:26:34/00:06:31, 0.538s/it]: train_loss_raw=1.0086, running_loss=1.0113, LR=0.000100
[2025-08-10 18:15:42,348][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047280] [Batch 02976/03692] [00:26:40/00:06:25, 0.538s/it]: train_loss_raw=0.9862, running_loss=1.0105, LR=0.000100
[2025-08-10 18:15:48,439][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047292] [Batch 02988/03692] [00:26:46/00:06:18, 0.538s/it]: train_loss_raw=0.9388, running_loss=1.0084, LR=0.000100
[2025-08-10 18:15:54,702][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047304] [Batch 03000/03692] [00:26:52/00:06:12, 0.538s/it]: train_loss_raw=0.9549, running_loss=1.0062, LR=0.000100
[2025-08-10 18:16:00,878][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047316] [Batch 03012/03692] [00:26:58/00:06:05, 0.537s/it]: train_loss_raw=1.0613, running_loss=1.0080, LR=0.000100
[2025-08-10 18:16:06,968][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047328] [Batch 03024/03692] [00:27:05/00:05:58, 0.537s/it]: train_loss_raw=1.0222, running_loss=1.0078, LR=0.000100
[2025-08-10 18:16:13,305][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047340] [Batch 03036/03692] [00:27:11/00:05:52, 0.537s/it]: train_loss_raw=1.1396, running_loss=1.0090, LR=0.000100
[2025-08-10 18:16:19,515][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047352] [Batch 03048/03692] [00:27:17/00:05:45, 0.537s/it]: train_loss_raw=1.1445, running_loss=1.0063, LR=0.000100
[2025-08-10 18:16:25,830][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047364] [Batch 03060/03692] [00:27:23/00:05:39, 0.537s/it]: train_loss_raw=0.8872, running_loss=0.9993, LR=0.000100
[2025-08-10 18:16:32,080][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047376] [Batch 03072/03692] [00:27:30/00:05:33, 0.537s/it]: train_loss_raw=1.1160, running_loss=0.9991, LR=0.000100
[2025-08-10 18:16:38,342][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047388] [Batch 03084/03692] [00:27:36/00:05:26, 0.537s/it]: train_loss_raw=1.1030, running_loss=1.0002, LR=0.000100
[2025-08-10 18:16:44,719][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047400] [Batch 03096/03692] [00:27:42/00:05:20, 0.537s/it]: train_loss_raw=1.0479, running_loss=1.0037, LR=0.000100
[2025-08-10 18:16:51,213][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047412] [Batch 03108/03692] [00:27:49/00:05:13, 0.537s/it]: train_loss_raw=1.0934, running_loss=1.0061, LR=0.000100
[2025-08-10 18:16:57,669][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047424] [Batch 03120/03692] [00:27:55/00:05:07, 0.537s/it]: train_loss_raw=0.9828, running_loss=1.0065, LR=0.000100
[2025-08-10 18:17:04,239][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047436] [Batch 03132/03692] [00:28:02/00:05:00, 0.537s/it]: train_loss_raw=1.0160, running_loss=1.0018, LR=0.000100
[2025-08-10 18:17:10,688][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047448] [Batch 03144/03692] [00:28:08/00:04:54, 0.537s/it]: train_loss_raw=1.0916, running_loss=1.0043, LR=0.000100
[2025-08-10 18:17:17,142][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047460] [Batch 03156/03692] [00:28:15/00:04:47, 0.537s/it]: train_loss_raw=0.9285, running_loss=0.9984, LR=0.000100
[2025-08-10 18:17:23,605][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047472] [Batch 03168/03692] [00:28:21/00:04:41, 0.537s/it]: train_loss_raw=1.0538, running_loss=1.0002, LR=0.000100
[2025-08-10 18:17:30,214][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047484] [Batch 03180/03692] [00:28:28/00:04:35, 0.537s/it]: train_loss_raw=0.9997, running_loss=1.0036, LR=0.000100
[2025-08-10 18:17:36,315][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047496] [Batch 03192/03692] [00:28:34/00:04:28, 0.537s/it]: train_loss_raw=0.9526, running_loss=1.0012, LR=0.000100
[2025-08-10 18:17:42,386][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047508] [Batch 03204/03692] [00:28:40/00:04:22, 0.537s/it]: train_loss_raw=0.9600, running_loss=1.0016, LR=0.000100
[2025-08-10 18:17:48,657][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047520] [Batch 03216/03692] [00:28:46/00:04:15, 0.537s/it]: train_loss_raw=0.9821, running_loss=1.0037, LR=0.000100
[2025-08-10 18:17:55,216][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047532] [Batch 03228/03692] [00:28:53/00:04:09, 0.537s/it]: train_loss_raw=1.0062, running_loss=1.0000, LR=0.000100
[2025-08-10 18:18:01,772][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047544] [Batch 03240/03692] [00:28:59/00:04:02, 0.537s/it]: train_loss_raw=0.9259, running_loss=0.9963, LR=0.000100
[2025-08-10 18:18:08,300][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047556] [Batch 03252/03692] [00:29:06/00:03:56, 0.537s/it]: train_loss_raw=0.9922, running_loss=0.9977, LR=0.000100
[2025-08-10 18:18:15,018][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047568] [Batch 03264/03692] [00:29:13/00:03:49, 0.537s/it]: train_loss_raw=0.9069, running_loss=0.9988, LR=0.000100
[2025-08-10 18:18:21,566][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047580] [Batch 03276/03692] [00:29:19/00:03:43, 0.537s/it]: train_loss_raw=1.0024, running_loss=0.9969, LR=0.000100
[2025-08-10 18:18:28,120][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047592] [Batch 03288/03692] [00:29:26/00:03:37, 0.537s/it]: train_loss_raw=0.9851, running_loss=0.9941, LR=0.000100
[2025-08-10 18:18:34,407][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047604] [Batch 03300/03692] [00:29:32/00:03:30, 0.537s/it]: train_loss_raw=0.8893, running_loss=0.9937, LR=0.000100
[2025-08-10 18:18:40,908][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047616] [Batch 03312/03692] [00:29:38/00:03:24, 0.537s/it]: train_loss_raw=1.0026, running_loss=0.9952, LR=0.000100
[2025-08-10 18:18:47,263][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047628] [Batch 03324/03692] [00:29:45/00:03:17, 0.537s/it]: train_loss_raw=0.9716, running_loss=0.9950, LR=0.000100
[2025-08-10 18:18:53,551][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047640] [Batch 03336/03692] [00:29:51/00:03:11, 0.537s/it]: train_loss_raw=0.8298, running_loss=0.9939, LR=0.000100
[2025-08-10 18:18:59,967][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047652] [Batch 03348/03692] [00:29:58/00:03:04, 0.537s/it]: train_loss_raw=0.9947, running_loss=0.9958, LR=0.000100
[2025-08-10 18:19:06,502][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047664] [Batch 03360/03692] [00:30:04/00:02:58, 0.537s/it]: train_loss_raw=1.0122, running_loss=0.9965, LR=0.000100
[2025-08-10 18:19:12,673][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047676] [Batch 03372/03692] [00:30:10/00:02:51, 0.537s/it]: train_loss_raw=0.9689, running_loss=0.9951, LR=0.000100
[2025-08-10 18:19:18,737][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047688] [Batch 03384/03692] [00:30:16/00:02:45, 0.537s/it]: train_loss_raw=1.0428, running_loss=0.9947, LR=0.000100
[2025-08-10 18:19:24,796][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047700] [Batch 03396/03692] [00:30:22/00:02:38, 0.537s/it]: train_loss_raw=0.9325, running_loss=0.9932, LR=0.000100
[2025-08-10 18:19:31,180][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047712] [Batch 03408/03692] [00:30:29/00:02:32, 0.537s/it]: train_loss_raw=0.9077, running_loss=0.9919, LR=0.000100
[2025-08-10 18:19:37,281][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047724] [Batch 03420/03692] [00:30:35/00:02:25, 0.537s/it]: train_loss_raw=0.8964, running_loss=0.9927, LR=0.000100
[2025-08-10 18:19:43,812][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047736] [Batch 03432/03692] [00:30:41/00:02:19, 0.537s/it]: train_loss_raw=1.0106, running_loss=0.9972, LR=0.000100
[2025-08-10 18:19:50,363][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047748] [Batch 03444/03692] [00:30:48/00:02:13, 0.537s/it]: train_loss_raw=0.9993, running_loss=0.9945, LR=0.000100
[2025-08-10 18:19:56,875][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047760] [Batch 03456/03692] [00:30:54/00:02:06, 0.537s/it]: train_loss_raw=0.9979, running_loss=0.9957, LR=0.000100
[2025-08-10 18:20:03,035][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047772] [Batch 03468/03692] [00:31:01/00:02:00, 0.537s/it]: train_loss_raw=1.0188, running_loss=0.9975, LR=0.000100
[2025-08-10 18:20:09,518][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047784] [Batch 03480/03692] [00:31:07/00:01:53, 0.537s/it]: train_loss_raw=1.0567, running_loss=0.9970, LR=0.000100
[2025-08-10 18:20:16,147][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047796] [Batch 03492/03692] [00:31:14/00:01:47, 0.537s/it]: train_loss_raw=0.9039, running_loss=0.9960, LR=0.000100
[2025-08-10 18:20:22,619][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047808] [Batch 03504/03692] [00:31:20/00:01:40, 0.537s/it]: train_loss_raw=1.0425, running_loss=0.9894, LR=0.000100
[2025-08-10 18:20:28,851][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047820] [Batch 03516/03692] [00:31:26/00:01:34, 0.537s/it]: train_loss_raw=0.9693, running_loss=0.9877, LR=0.000100
[2025-08-10 18:20:35,148][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047832] [Batch 03528/03692] [00:31:33/00:01:28, 0.537s/it]: train_loss_raw=1.1164, running_loss=0.9891, LR=0.000100
[2025-08-10 18:20:41,607][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047844] [Batch 03540/03692] [00:31:39/00:01:21, 0.537s/it]: train_loss_raw=0.8706, running_loss=0.9901, LR=0.000100
[2025-08-10 18:20:48,190][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047856] [Batch 03552/03692] [00:31:46/00:01:15, 0.537s/it]: train_loss_raw=1.0018, running_loss=0.9911, LR=0.000100
[2025-08-10 18:20:54,653][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047868] [Batch 03564/03692] [00:31:52/00:01:08, 0.537s/it]: train_loss_raw=0.9996, running_loss=0.9948, LR=0.000100
[2025-08-10 18:21:01,088][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047880] [Batch 03576/03692] [00:31:59/00:01:02, 0.537s/it]: train_loss_raw=0.9816, running_loss=0.9948, LR=0.000100
[2025-08-10 18:21:07,211][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047892] [Batch 03588/03692] [00:32:05/00:00:55, 0.537s/it]: train_loss_raw=1.1238, running_loss=0.9961, LR=0.000100
[2025-08-10 18:21:13,392][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047904] [Batch 03600/03692] [00:32:11/00:00:49, 0.537s/it]: train_loss_raw=0.9421, running_loss=0.9982, LR=0.000100
[2025-08-10 18:21:19,646][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047916] [Batch 03612/03692] [00:32:17/00:00:42, 0.536s/it]: train_loss_raw=0.8969, running_loss=0.9936, LR=0.000100
[2025-08-10 18:21:26,057][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047928] [Batch 03624/03692] [00:32:24/00:00:36, 0.536s/it]: train_loss_raw=1.0660, running_loss=0.9941, LR=0.000100
[2025-08-10 18:21:32,650][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047940] [Batch 03636/03692] [00:32:30/00:00:30, 0.536s/it]: train_loss_raw=0.9873, running_loss=0.9934, LR=0.000100
[2025-08-10 18:21:39,220][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047952] [Batch 03648/03692] [00:32:37/00:00:23, 0.537s/it]: train_loss_raw=0.9095, running_loss=0.9974, LR=0.000100
[2025-08-10 18:21:45,762][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047964] [Batch 03660/03692] [00:32:43/00:00:17, 0.537s/it]: train_loss_raw=0.9243, running_loss=0.9954, LR=0.000100
[2025-08-10 18:21:52,379][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047976] [Batch 03672/03692] [00:32:50/00:00:10, 0.537s/it]: train_loss_raw=1.0534, running_loss=0.9962, LR=0.000100
[2025-08-10 18:21:58,890][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 047988] [Batch 03684/03692] [00:32:56/00:00:04, 0.537s/it]: train_loss_raw=0.8818, running_loss=0.9973, LR=0.000100
[2025-08-10 18:22:08,293][__main__][INFO] - [VALIDATION] [Epoch 12/29] Starting validation.
[2025-08-10 18:22:42,285][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 047997] [Batch 00011/00025] [00:00:33/00:00:36, 2.833s/it]
[2025-08-10 18:22:58,587][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 047997] [Batch 00023/00025] [00:00:50/00:00:02, 2.096s/it]
[2025-08-10 18:22:59,733][__main__][INFO] - [VALIDATION] [Epoch 12/29] train_loss=0.99779, valid_loss=1.01735
[2025-08-10 18:22:59,734][__main__][INFO] - [VALIDATION] [Epoch 12/29] Metrics:
[2025-08-10 18:22:59,734][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_er      0.442
[2025-08-10 18:22:59,734][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_prec    0.279
[2025-08-10 18:22:59,734][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_recall  0.286
[2025-08-10 18:22:59,734][__main__][INFO] - [VALIDATION] [Epoch 12/29] - pep_recall 0.259
[2025-08-10 18:22:59,737][__main__][INFO] - [TRAIN] [Epoch 12/29] Epoch complete, total time 07:26:58, remaining time 09:44:30, 00:34:22 per epoch
[2025-08-10 18:23:02,766][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048000] [Batch 00004/03692] [00:00:01/00:26:23, 0.429s/it]: train_loss_raw=0.8471, running_loss=0.8997, LR=0.000100
[2025-08-10 18:23:15,039][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048012] [Batch 00016/03692] [00:00:13/00:53:34, 0.874s/it]: train_loss_raw=1.0614, running_loss=0.9097, LR=0.000100
[2025-08-10 18:23:21,531][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048024] [Batch 00028/03692] [00:00:20/00:44:40, 0.732s/it]: train_loss_raw=0.9450, running_loss=0.9222, LR=0.000100
[2025-08-10 18:23:27,998][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048036] [Batch 00040/03692] [00:00:26/00:41:00, 0.674s/it]: train_loss_raw=1.0421, running_loss=0.9318, LR=0.000100
[2025-08-10 18:23:34,351][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048048] [Batch 00052/03692] [00:00:33/00:38:51, 0.640s/it]: train_loss_raw=0.8702, running_loss=0.9348, LR=0.000100
[2025-08-10 18:23:40,681][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048060] [Batch 00064/03692] [00:00:39/00:37:26, 0.619s/it]: train_loss_raw=0.9952, running_loss=0.9387, LR=0.000100
[2025-08-10 18:23:47,007][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048072] [Batch 00076/03692] [00:00:45/00:36:26, 0.605s/it]: train_loss_raw=1.0877, running_loss=0.9453, LR=0.000100
[2025-08-10 18:23:53,280][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048084] [Batch 00088/03692] [00:00:52/00:35:39, 0.594s/it]: train_loss_raw=1.0408, running_loss=0.9484, LR=0.000100
[2025-08-10 18:23:59,615][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048096] [Batch 00100/03692] [00:00:58/00:35:03, 0.586s/it]: train_loss_raw=0.9857, running_loss=0.9538, LR=0.000100
[2025-08-10 18:24:06,041][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048108] [Batch 00112/03692] [00:01:04/00:34:37, 0.580s/it]: train_loss_raw=1.0886, running_loss=0.9593, LR=0.000100
[2025-08-10 18:24:12,299][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048120] [Batch 00124/03692] [00:01:11/00:34:10, 0.575s/it]: train_loss_raw=0.9063, running_loss=0.9633, LR=0.000100
[2025-08-10 18:24:18,600][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048132] [Batch 00136/03692] [00:01:17/00:33:47, 0.570s/it]: train_loss_raw=0.9820, running_loss=0.9703, LR=0.000100
[2025-08-10 18:24:25,156][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048144] [Batch 00148/03692] [00:01:24/00:33:34, 0.568s/it]: train_loss_raw=1.0290, running_loss=0.9680, LR=0.000100
[2025-08-10 18:24:31,755][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048156] [Batch 00160/03692] [00:01:30/00:33:22, 0.567s/it]: train_loss_raw=0.9332, running_loss=0.9685, LR=0.000100
[2025-08-10 18:24:38,300][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048168] [Batch 00172/03692] [00:01:37/00:33:10, 0.565s/it]: train_loss_raw=0.9918, running_loss=0.9718, LR=0.000100
[2025-08-10 18:24:44,892][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048180] [Batch 00184/03692] [00:01:43/00:32:59, 0.564s/it]: train_loss_raw=1.0021, running_loss=0.9714, LR=0.000100
[2025-08-10 18:24:51,391][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048192] [Batch 00196/03692] [00:01:50/00:32:48, 0.563s/it]: train_loss_raw=0.9863, running_loss=0.9739, LR=0.000100
[2025-08-10 18:24:57,860][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048204] [Batch 00208/03692] [00:01:56/00:32:36, 0.562s/it]: train_loss_raw=0.9243, running_loss=0.9731, LR=0.000100
[2025-08-10 18:25:04,366][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048216] [Batch 00220/03692] [00:02:03/00:32:26, 0.561s/it]: train_loss_raw=1.1130, running_loss=0.9781, LR=0.000100
[2025-08-10 18:25:10,832][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048228] [Batch 00232/03692] [00:02:09/00:32:15, 0.559s/it]: train_loss_raw=0.9815, running_loss=0.9821, LR=0.000100
[2025-08-10 18:25:17,185][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048240] [Batch 00244/03692] [00:02:16/00:32:03, 0.558s/it]: train_loss_raw=1.0160, running_loss=0.9833, LR=0.000100
[2025-08-10 18:25:23,764][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048252] [Batch 00256/03692] [00:02:22/00:31:55, 0.557s/it]: train_loss_raw=1.0656, running_loss=0.9860, LR=0.000100
[2025-08-10 18:25:30,323][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048264] [Batch 00268/03692] [00:02:29/00:31:47, 0.557s/it]: train_loss_raw=1.0767, running_loss=0.9874, LR=0.000100
[2025-08-10 18:25:36,755][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048276] [Batch 00280/03692] [00:02:35/00:31:37, 0.556s/it]: train_loss_raw=0.9939, running_loss=0.9863, LR=0.000100
[2025-08-10 18:25:43,183][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048288] [Batch 00292/03692] [00:02:42/00:31:27, 0.555s/it]: train_loss_raw=1.0321, running_loss=0.9863, LR=0.000100
[2025-08-10 18:25:49,744][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048300] [Batch 00304/03692] [00:02:48/00:31:20, 0.555s/it]: train_loss_raw=1.0752, running_loss=0.9893, LR=0.000100
[2025-08-10 18:25:56,288][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048312] [Batch 00316/03692] [00:02:55/00:31:12, 0.555s/it]: train_loss_raw=1.0654, running_loss=0.9895, LR=0.000100
[2025-08-10 18:26:02,667][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048324] [Batch 00328/03692] [00:03:01/00:31:02, 0.554s/it]: train_loss_raw=1.1453, running_loss=0.9893, LR=0.000100
[2025-08-10 18:26:09,131][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048336] [Batch 00340/03692] [00:03:08/00:30:54, 0.553s/it]: train_loss_raw=1.2221, running_loss=0.9924, LR=0.000100
[2025-08-10 18:26:15,595][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048348] [Batch 00352/03692] [00:03:14/00:30:45, 0.553s/it]: train_loss_raw=0.8954, running_loss=0.9953, LR=0.000100
[2025-08-10 18:26:22,066][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048360] [Batch 00364/03692] [00:03:21/00:30:37, 0.552s/it]: train_loss_raw=0.9970, running_loss=0.9943, LR=0.000100
[2025-08-10 18:26:28,340][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048372] [Batch 00376/03692] [00:03:27/00:30:28, 0.551s/it]: train_loss_raw=0.8809, running_loss=0.9948, LR=0.000100
[2025-08-10 18:26:34,572][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048384] [Batch 00388/03692] [00:03:33/00:30:18, 0.550s/it]: train_loss_raw=0.9709, running_loss=0.9937, LR=0.000100
[2025-08-10 18:26:40,988][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048396] [Batch 00400/03692] [00:03:39/00:30:10, 0.550s/it]: train_loss_raw=0.9497, running_loss=0.9887, LR=0.000100
[2025-08-10 18:26:47,255][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048408] [Batch 00412/03692] [00:03:46/00:30:00, 0.549s/it]: train_loss_raw=1.0397, running_loss=0.9876, LR=0.000100
[2025-08-10 18:26:53,631][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048420] [Batch 00424/03692] [00:03:52/00:29:52, 0.549s/it]: train_loss_raw=0.9337, running_loss=0.9887, LR=0.000100
[2025-08-10 18:27:00,115][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048432] [Batch 00436/03692] [00:03:59/00:29:45, 0.548s/it]: train_loss_raw=0.8978, running_loss=0.9872, LR=0.000100
[2025-08-10 18:27:06,620][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048444] [Batch 00448/03692] [00:04:05/00:29:38, 0.548s/it]: train_loss_raw=0.9492, running_loss=0.9871, LR=0.000100
[2025-08-10 18:27:13,120][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048456] [Batch 00460/03692] [00:04:12/00:29:31, 0.548s/it]: train_loss_raw=0.9766, running_loss=0.9899, LR=0.000100
[2025-08-10 18:27:19,585][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048468] [Batch 00472/03692] [00:04:18/00:29:23, 0.548s/it]: train_loss_raw=1.0686, running_loss=0.9908, LR=0.000100
[2025-08-10 18:27:25,689][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048480] [Batch 00484/03692] [00:04:24/00:29:14, 0.547s/it]: train_loss_raw=1.0366, running_loss=0.9886, LR=0.000100
[2025-08-10 18:27:31,939][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048492] [Batch 00496/03692] [00:04:30/00:29:05, 0.546s/it]: train_loss_raw=0.9951, running_loss=0.9872, LR=0.000100
[2025-08-10 18:27:38,311][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048504] [Batch 00508/03692] [00:04:37/00:28:57, 0.546s/it]: train_loss_raw=0.8842, running_loss=0.9892, LR=0.000100
[2025-08-10 18:27:44,713][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048516] [Batch 00520/03692] [00:04:43/00:28:50, 0.546s/it]: train_loss_raw=1.0181, running_loss=0.9871, LR=0.000100
[2025-08-10 18:27:51,039][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048528] [Batch 00532/03692] [00:04:49/00:28:42, 0.545s/it]: train_loss_raw=0.8778, running_loss=0.9824, LR=0.000100
[2025-08-10 18:27:57,274][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048540] [Batch 00544/03692] [00:04:56/00:28:34, 0.545s/it]: train_loss_raw=1.0447, running_loss=0.9829, LR=0.000100
[2025-08-10 18:28:03,591][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048552] [Batch 00556/03692] [00:05:02/00:28:26, 0.544s/it]: train_loss_raw=0.9523, running_loss=0.9807, LR=0.000100
[2025-08-10 18:28:09,985][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048564] [Batch 00568/03692] [00:05:08/00:28:19, 0.544s/it]: train_loss_raw=1.0511, running_loss=0.9787, LR=0.000100
[2025-08-10 18:28:16,424][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048576] [Batch 00580/03692] [00:05:15/00:28:12, 0.544s/it]: train_loss_raw=1.1147, running_loss=0.9841, LR=0.000100
[2025-08-10 18:28:22,829][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048588] [Batch 00592/03692] [00:05:21/00:28:05, 0.544s/it]: train_loss_raw=0.9645, running_loss=0.9854, LR=0.000100
[2025-08-10 18:28:29,318][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048600] [Batch 00604/03692] [00:05:28/00:27:58, 0.543s/it]: train_loss_raw=0.9854, running_loss=0.9850, LR=0.000100
[2025-08-10 18:28:35,397][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048612] [Batch 00616/03692] [00:05:34/00:27:49, 0.543s/it]: train_loss_raw=1.1152, running_loss=0.9833, LR=0.000100
[2025-08-10 18:28:41,703][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048624] [Batch 00628/03692] [00:05:40/00:27:42, 0.542s/it]: train_loss_raw=1.0984, running_loss=0.9871, LR=0.000100
[2025-08-10 18:28:48,217][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048636] [Batch 00640/03692] [00:05:47/00:27:35, 0.542s/it]: train_loss_raw=0.9223, running_loss=0.9911, LR=0.000100
[2025-08-10 18:28:54,731][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048648] [Batch 00652/03692] [00:05:53/00:27:29, 0.542s/it]: train_loss_raw=0.8590, running_loss=0.9901, LR=0.000100
[2025-08-10 18:29:01,091][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048660] [Batch 00664/03692] [00:06:00/00:27:21, 0.542s/it]: train_loss_raw=1.0330, running_loss=0.9896, LR=0.000100
[2025-08-10 18:29:07,560][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048672] [Batch 00676/03692] [00:06:06/00:27:15, 0.542s/it]: train_loss_raw=1.0950, running_loss=0.9935, LR=0.000100
[2025-08-10 18:29:14,032][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048684] [Batch 00688/03692] [00:06:12/00:27:08, 0.542s/it]: train_loss_raw=0.9592, running_loss=0.9902, LR=0.000100
[2025-08-10 18:29:20,432][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048696] [Batch 00700/03692] [00:06:19/00:27:01, 0.542s/it]: train_loss_raw=0.9864, running_loss=0.9890, LR=0.000100
[2025-08-10 18:29:26,940][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048708] [Batch 00712/03692] [00:06:25/00:26:55, 0.542s/it]: train_loss_raw=1.0474, running_loss=0.9888, LR=0.000100
[2025-08-10 18:29:33,385][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048720] [Batch 00724/03692] [00:06:32/00:26:48, 0.542s/it]: train_loss_raw=0.9739, running_loss=0.9860, LR=0.000100
[2025-08-10 18:29:39,812][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048732] [Batch 00736/03692] [00:06:38/00:26:41, 0.542s/it]: train_loss_raw=0.8648, running_loss=0.9831, LR=0.000100
[2025-08-10 18:29:46,222][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048744] [Batch 00748/03692] [00:06:45/00:26:34, 0.542s/it]: train_loss_raw=1.0167, running_loss=0.9823, LR=0.000100
[2025-08-10 18:29:52,705][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048756] [Batch 00760/03692] [00:06:51/00:26:28, 0.542s/it]: train_loss_raw=1.0126, running_loss=0.9824, LR=0.000100
[2025-08-10 18:29:59,244][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048768] [Batch 00772/03692] [00:06:58/00:26:21, 0.542s/it]: train_loss_raw=0.9671, running_loss=0.9820, LR=0.000100
[2025-08-10 18:30:05,743][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048780] [Batch 00784/03692] [00:07:04/00:26:15, 0.542s/it]: train_loss_raw=1.1087, running_loss=0.9844, LR=0.000100
[2025-08-10 18:30:12,196][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048792] [Batch 00796/03692] [00:07:11/00:26:08, 0.542s/it]: train_loss_raw=0.9115, running_loss=0.9782, LR=0.000100
[2025-08-10 18:30:18,639][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048804] [Batch 00808/03692] [00:07:17/00:26:01, 0.542s/it]: train_loss_raw=0.8746, running_loss=0.9765, LR=0.000100
[2025-08-10 18:30:25,184][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048816] [Batch 00820/03692] [00:07:24/00:25:55, 0.542s/it]: train_loss_raw=0.9883, running_loss=0.9799, LR=0.000100
[2025-08-10 18:30:31,717][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048828] [Batch 00832/03692] [00:07:30/00:25:49, 0.542s/it]: train_loss_raw=1.1483, running_loss=0.9798, LR=0.000100
[2025-08-10 18:30:38,102][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048840] [Batch 00844/03692] [00:07:37/00:25:42, 0.542s/it]: train_loss_raw=1.0945, running_loss=0.9779, LR=0.000100
[2025-08-10 18:30:44,504][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048852] [Batch 00856/03692] [00:07:43/00:25:35, 0.541s/it]: train_loss_raw=0.9216, running_loss=0.9776, LR=0.000100
[2025-08-10 18:30:50,901][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048864] [Batch 00868/03692] [00:07:49/00:25:28, 0.541s/it]: train_loss_raw=0.9673, running_loss=0.9741, LR=0.000100
[2025-08-10 18:30:56,940][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048876] [Batch 00880/03692] [00:07:55/00:25:20, 0.541s/it]: train_loss_raw=0.9724, running_loss=0.9769, LR=0.000100
[2025-08-10 18:31:03,412][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048888] [Batch 00892/03692] [00:08:02/00:25:14, 0.541s/it]: train_loss_raw=0.9511, running_loss=0.9769, LR=0.000100
[2025-08-10 18:31:09,890][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048900] [Batch 00904/03692] [00:08:08/00:25:07, 0.541s/it]: train_loss_raw=0.9230, running_loss=0.9790, LR=0.000100
[2025-08-10 18:31:16,211][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048912] [Batch 00916/03692] [00:08:15/00:25:00, 0.541s/it]: train_loss_raw=0.9552, running_loss=0.9803, LR=0.000100
[2025-08-10 18:31:22,672][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048924] [Batch 00928/03692] [00:08:21/00:24:54, 0.541s/it]: train_loss_raw=1.0135, running_loss=0.9822, LR=0.000100
[2025-08-10 18:31:29,103][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048936] [Batch 00940/03692] [00:08:28/00:24:47, 0.540s/it]: train_loss_raw=0.9806, running_loss=0.9790, LR=0.000100
[2025-08-10 18:31:35,630][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048948] [Batch 00952/03692] [00:08:34/00:24:41, 0.541s/it]: train_loss_raw=1.0109, running_loss=0.9801, LR=0.000100
[2025-08-10 18:31:42,004][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048960] [Batch 00964/03692] [00:08:40/00:24:34, 0.540s/it]: train_loss_raw=1.0038, running_loss=0.9856, LR=0.000100
[2025-08-10 18:31:48,179][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048972] [Batch 00976/03692] [00:08:47/00:24:26, 0.540s/it]: train_loss_raw=1.0881, running_loss=0.9896, LR=0.000100
[2025-08-10 18:31:54,388][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048984] [Batch 00988/03692] [00:08:53/00:24:19, 0.540s/it]: train_loss_raw=0.9927, running_loss=0.9922, LR=0.000100
[2025-08-10 18:32:00,508][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 048996] [Batch 01000/03692] [00:08:59/00:24:12, 0.539s/it]: train_loss_raw=1.0163, running_loss=0.9894, LR=0.000100
[2025-08-10 18:32:07,070][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049008] [Batch 01012/03692] [00:09:06/00:24:05, 0.540s/it]: train_loss_raw=0.9749, running_loss=0.9875, LR=0.000100
[2025-08-10 18:32:13,634][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049020] [Batch 01024/03692] [00:09:12/00:23:59, 0.540s/it]: train_loss_raw=1.0543, running_loss=0.9859, LR=0.000100
[2025-08-10 18:32:19,821][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049032] [Batch 01036/03692] [00:09:18/00:23:52, 0.539s/it]: train_loss_raw=1.0663, running_loss=0.9864, LR=0.000100
[2025-08-10 18:32:26,068][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049044] [Batch 01048/03692] [00:09:25/00:23:45, 0.539s/it]: train_loss_raw=0.8790, running_loss=0.9847, LR=0.000100
[2025-08-10 18:32:32,356][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049056] [Batch 01060/03692] [00:09:31/00:23:38, 0.539s/it]: train_loss_raw=1.0030, running_loss=0.9860, LR=0.000100
[2025-08-10 18:32:38,723][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049068] [Batch 01072/03692] [00:09:37/00:23:31, 0.539s/it]: train_loss_raw=1.0801, running_loss=0.9877, LR=0.000100
[2025-08-10 18:32:44,897][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049080] [Batch 01084/03692] [00:09:43/00:23:24, 0.539s/it]: train_loss_raw=0.9838, running_loss=0.9892, LR=0.000100
[2025-08-10 18:32:51,276][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049092] [Batch 01096/03692] [00:09:50/00:23:18, 0.539s/it]: train_loss_raw=0.9863, running_loss=0.9846, LR=0.000100
[2025-08-10 18:32:57,762][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049104] [Batch 01108/03692] [00:09:56/00:23:11, 0.539s/it]: train_loss_raw=0.9558, running_loss=0.9825, LR=0.000100
[2025-08-10 18:33:04,343][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049116] [Batch 01120/03692] [00:10:03/00:23:05, 0.539s/it]: train_loss_raw=0.9099, running_loss=0.9797, LR=0.000100
[2025-08-10 18:33:10,927][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049128] [Batch 01132/03692] [00:10:09/00:22:59, 0.539s/it]: train_loss_raw=0.9331, running_loss=0.9809, LR=0.000100
[2025-08-10 18:33:17,387][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049140] [Batch 01144/03692] [00:10:16/00:22:52, 0.539s/it]: train_loss_raw=0.9197, running_loss=0.9787, LR=0.000100
[2025-08-10 18:33:23,868][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049152] [Batch 01156/03692] [00:10:22/00:22:46, 0.539s/it]: train_loss_raw=0.8433, running_loss=0.9785, LR=0.000100
[2025-08-10 18:33:30,288][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049164] [Batch 01168/03692] [00:10:29/00:22:39, 0.539s/it]: train_loss_raw=1.0077, running_loss=0.9756, LR=0.000100
[2025-08-10 18:33:36,765][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049176] [Batch 01180/03692] [00:10:35/00:22:33, 0.539s/it]: train_loss_raw=1.0052, running_loss=0.9758, LR=0.000100
[2025-08-10 18:33:43,269][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049188] [Batch 01192/03692] [00:10:42/00:22:26, 0.539s/it]: train_loss_raw=1.0173, running_loss=0.9758, LR=0.000100
[2025-08-10 18:33:49,717][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049200] [Batch 01204/03692] [00:10:48/00:22:20, 0.539s/it]: train_loss_raw=0.8820, running_loss=0.9740, LR=0.000100
[2025-08-10 18:33:56,179][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049212] [Batch 01216/03692] [00:10:55/00:22:13, 0.539s/it]: train_loss_raw=0.8729, running_loss=0.9709, LR=0.000100
[2025-08-10 18:34:02,586][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049224] [Batch 01228/03692] [00:11:01/00:22:07, 0.539s/it]: train_loss_raw=0.8663, running_loss=0.9731, LR=0.000100
[2025-08-10 18:34:08,978][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049236] [Batch 01240/03692] [00:11:07/00:22:00, 0.539s/it]: train_loss_raw=0.9667, running_loss=0.9729, LR=0.000100
[2025-08-10 18:34:15,210][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049248] [Batch 01252/03692] [00:11:14/00:21:53, 0.538s/it]: train_loss_raw=0.9328, running_loss=0.9741, LR=0.000100
[2025-08-10 18:34:21,241][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049260] [Batch 01264/03692] [00:11:20/00:21:46, 0.538s/it]: train_loss_raw=0.8338, running_loss=0.9712, LR=0.000100
[2025-08-10 18:34:27,265][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049272] [Batch 01276/03692] [00:11:26/00:21:39, 0.538s/it]: train_loss_raw=0.9986, running_loss=0.9696, LR=0.000100
[2025-08-10 18:34:33,643][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049284] [Batch 01288/03692] [00:11:32/00:21:32, 0.538s/it]: train_loss_raw=0.9849, running_loss=0.9705, LR=0.000100
[2025-08-10 18:34:40,202][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049296] [Batch 01300/03692] [00:11:39/00:21:26, 0.538s/it]: train_loss_raw=0.9884, running_loss=0.9714, LR=0.000100
[2025-08-10 18:34:46,674][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049308] [Batch 01312/03692] [00:11:45/00:21:20, 0.538s/it]: train_loss_raw=1.0121, running_loss=0.9736, LR=0.000100
[2025-08-10 18:34:53,025][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049320] [Batch 01324/03692] [00:11:51/00:21:13, 0.538s/it]: train_loss_raw=0.9577, running_loss=0.9742, LR=0.000100
[2025-08-10 18:34:59,202][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049332] [Batch 01336/03692] [00:11:58/00:21:06, 0.538s/it]: train_loss_raw=0.9643, running_loss=0.9771, LR=0.000100
[2025-08-10 18:35:05,432][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049344] [Batch 01348/03692] [00:12:04/00:20:59, 0.537s/it]: train_loss_raw=1.0289, running_loss=0.9753, LR=0.000100
[2025-08-10 18:35:11,733][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049356] [Batch 01360/03692] [00:12:10/00:20:52, 0.537s/it]: train_loss_raw=0.9941, running_loss=0.9792, LR=0.000100
[2025-08-10 18:35:18,136][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049368] [Batch 01372/03692] [00:12:17/00:20:46, 0.537s/it]: train_loss_raw=0.8977, running_loss=0.9804, LR=0.000100
[2025-08-10 18:35:24,268][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049380] [Batch 01384/03692] [00:12:23/00:20:39, 0.537s/it]: train_loss_raw=0.9145, running_loss=0.9761, LR=0.000100
[2025-08-10 18:35:30,404][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049392] [Batch 01396/03692] [00:12:29/00:20:32, 0.537s/it]: train_loss_raw=0.9947, running_loss=0.9759, LR=0.000100
[2025-08-10 18:35:36,461][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049404] [Batch 01408/03692] [00:12:35/00:20:25, 0.537s/it]: train_loss_raw=0.8290, running_loss=0.9762, LR=0.000100
[2025-08-10 18:35:42,810][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049416] [Batch 01420/03692] [00:12:41/00:20:18, 0.536s/it]: train_loss_raw=0.8663, running_loss=0.9774, LR=0.000100
[2025-08-10 18:35:49,254][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049428] [Batch 01432/03692] [00:12:48/00:20:12, 0.536s/it]: train_loss_raw=0.9713, running_loss=0.9787, LR=0.000100
[2025-08-10 18:35:55,431][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049440] [Batch 01444/03692] [00:12:54/00:20:05, 0.536s/it]: train_loss_raw=0.8939, running_loss=0.9735, LR=0.000100
[2025-08-10 18:36:01,526][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049452] [Batch 01456/03692] [00:13:00/00:19:58, 0.536s/it]: train_loss_raw=0.9886, running_loss=0.9730, LR=0.000100
[2025-08-10 18:36:07,657][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049464] [Batch 01468/03692] [00:13:06/00:19:51, 0.536s/it]: train_loss_raw=0.9571, running_loss=0.9693, LR=0.000100
[2025-08-10 18:36:13,792][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049476] [Batch 01480/03692] [00:13:12/00:19:44, 0.536s/it]: train_loss_raw=1.1086, running_loss=0.9744, LR=0.000100
[2025-08-10 18:36:19,962][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049488] [Batch 01492/03692] [00:13:18/00:19:38, 0.535s/it]: train_loss_raw=0.8614, running_loss=0.9720, LR=0.000100
[2025-08-10 18:36:26,554][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049500] [Batch 01504/03692] [00:13:25/00:19:31, 0.536s/it]: train_loss_raw=0.9264, running_loss=0.9728, LR=0.000100
[2025-08-10 18:36:33,069][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049512] [Batch 01516/03692] [00:13:32/00:19:25, 0.536s/it]: train_loss_raw=0.8990, running_loss=0.9737, LR=0.000100
[2025-08-10 18:36:39,640][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049524] [Batch 01528/03692] [00:13:38/00:19:19, 0.536s/it]: train_loss_raw=1.0245, running_loss=0.9771, LR=0.000100
[2025-08-10 18:36:46,316][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049536] [Batch 01540/03692] [00:13:45/00:19:13, 0.536s/it]: train_loss_raw=0.9803, running_loss=0.9714, LR=0.000100
[2025-08-10 18:36:52,851][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049548] [Batch 01552/03692] [00:13:51/00:19:06, 0.536s/it]: train_loss_raw=0.9758, running_loss=0.9719, LR=0.000100
[2025-08-10 18:36:59,405][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049560] [Batch 01564/03692] [00:13:58/00:19:00, 0.536s/it]: train_loss_raw=0.9711, running_loss=0.9683, LR=0.000100
[2025-08-10 18:37:05,634][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049572] [Batch 01576/03692] [00:14:04/00:18:53, 0.536s/it]: train_loss_raw=1.0134, running_loss=0.9674, LR=0.000100
[2025-08-10 18:37:11,816][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049584] [Batch 01588/03692] [00:14:10/00:18:47, 0.536s/it]: train_loss_raw=0.8848, running_loss=0.9665, LR=0.000100
[2025-08-10 18:37:18,385][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049596] [Batch 01600/03692] [00:14:17/00:18:40, 0.536s/it]: train_loss_raw=0.8873, running_loss=0.9684, LR=0.000100
[2025-08-10 18:37:24,932][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049608] [Batch 01612/03692] [00:14:23/00:18:34, 0.536s/it]: train_loss_raw=1.0251, running_loss=0.9716, LR=0.000100
[2025-08-10 18:37:31,140][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049620] [Batch 01624/03692] [00:14:30/00:18:27, 0.536s/it]: train_loss_raw=0.9698, running_loss=0.9687, LR=0.000100
[2025-08-10 18:37:37,517][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049632] [Batch 01636/03692] [00:14:36/00:18:21, 0.536s/it]: train_loss_raw=0.9723, running_loss=0.9661, LR=0.000100
[2025-08-10 18:37:44,055][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049644] [Batch 01648/03692] [00:14:43/00:18:15, 0.536s/it]: train_loss_raw=0.9349, running_loss=0.9670, LR=0.000100
[2025-08-10 18:37:50,616][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049656] [Batch 01660/03692] [00:14:49/00:18:08, 0.536s/it]: train_loss_raw=1.0443, running_loss=0.9639, LR=0.000100
[2025-08-10 18:37:57,090][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049668] [Batch 01672/03692] [00:14:56/00:18:02, 0.536s/it]: train_loss_raw=1.0111, running_loss=0.9648, LR=0.000100
[2025-08-10 18:38:03,414][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049680] [Batch 01684/03692] [00:15:02/00:17:55, 0.536s/it]: train_loss_raw=0.9482, running_loss=0.9653, LR=0.000100
[2025-08-10 18:38:09,854][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049692] [Batch 01696/03692] [00:15:08/00:17:49, 0.536s/it]: train_loss_raw=0.9633, running_loss=0.9655, LR=0.000100
[2025-08-10 18:38:16,329][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049704] [Batch 01708/03692] [00:15:15/00:17:43, 0.536s/it]: train_loss_raw=1.1139, running_loss=0.9659, LR=0.000100
[2025-08-10 18:38:22,782][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049716] [Batch 01720/03692] [00:15:21/00:17:36, 0.536s/it]: train_loss_raw=1.0630, running_loss=0.9691, LR=0.000100
[2025-08-10 18:38:28,986][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049728] [Batch 01732/03692] [00:15:27/00:17:30, 0.536s/it]: train_loss_raw=0.9893, running_loss=0.9665, LR=0.000100
[2025-08-10 18:38:35,229][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049740] [Batch 01744/03692] [00:15:34/00:17:23, 0.536s/it]: train_loss_raw=1.0255, running_loss=0.9648, LR=0.000100
[2025-08-10 18:38:41,466][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049752] [Batch 01756/03692] [00:15:40/00:17:16, 0.536s/it]: train_loss_raw=0.9428, running_loss=0.9687, LR=0.000100
[2025-08-10 18:38:47,780][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049764] [Batch 01768/03692] [00:15:46/00:17:10, 0.535s/it]: train_loss_raw=1.0142, running_loss=0.9679, LR=0.000100
[2025-08-10 18:38:53,999][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049776] [Batch 01780/03692] [00:15:52/00:17:03, 0.535s/it]: train_loss_raw=0.9151, running_loss=0.9692, LR=0.000100
[2025-08-10 18:39:00,288][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049788] [Batch 01792/03692] [00:15:59/00:16:57, 0.535s/it]: train_loss_raw=0.9254, running_loss=0.9716, LR=0.000100
[2025-08-10 18:39:06,594][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049800] [Batch 01804/03692] [00:16:05/00:16:50, 0.535s/it]: train_loss_raw=0.8875, running_loss=0.9735, LR=0.000100
[2025-08-10 18:39:12,788][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049812] [Batch 01816/03692] [00:16:11/00:16:43, 0.535s/it]: train_loss_raw=0.9677, running_loss=0.9699, LR=0.000100
[2025-08-10 18:39:19,068][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049824] [Batch 01828/03692] [00:16:18/00:16:37, 0.535s/it]: train_loss_raw=0.9863, running_loss=0.9660, LR=0.000100
[2025-08-10 18:39:25,296][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049836] [Batch 01840/03692] [00:16:24/00:16:30, 0.535s/it]: train_loss_raw=1.0349, running_loss=0.9665, LR=0.000100
[2025-08-10 18:39:31,637][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049848] [Batch 01852/03692] [00:16:30/00:16:24, 0.535s/it]: train_loss_raw=0.9150, running_loss=0.9696, LR=0.000100
[2025-08-10 18:39:37,914][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049860] [Batch 01864/03692] [00:16:36/00:16:17, 0.535s/it]: train_loss_raw=0.9232, running_loss=0.9727, LR=0.000100
[2025-08-10 18:39:44,142][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049872] [Batch 01876/03692] [00:16:43/00:16:11, 0.535s/it]: train_loss_raw=0.9303, running_loss=0.9700, LR=0.000100
[2025-08-10 18:39:50,255][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049884] [Batch 01888/03692] [00:16:49/00:16:04, 0.535s/it]: train_loss_raw=0.8644, running_loss=0.9692, LR=0.000100
[2025-08-10 18:39:56,563][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049896] [Batch 01900/03692] [00:16:55/00:15:57, 0.534s/it]: train_loss_raw=0.9251, running_loss=0.9745, LR=0.000100
[2025-08-10 18:40:02,779][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049908] [Batch 01912/03692] [00:17:01/00:15:51, 0.534s/it]: train_loss_raw=0.8975, running_loss=0.9720, LR=0.000100
[2025-08-10 18:40:09,186][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049920] [Batch 01924/03692] [00:17:08/00:15:44, 0.534s/it]: train_loss_raw=0.9504, running_loss=0.9704, LR=0.000100
[2025-08-10 18:40:15,598][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049932] [Batch 01936/03692] [00:17:14/00:15:38, 0.534s/it]: train_loss_raw=0.8864, running_loss=0.9733, LR=0.000100
[2025-08-10 18:40:22,039][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049944] [Batch 01948/03692] [00:17:20/00:15:31, 0.534s/it]: train_loss_raw=0.9153, running_loss=0.9702, LR=0.000100
[2025-08-10 18:40:28,557][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049956] [Batch 01960/03692] [00:17:27/00:15:25, 0.534s/it]: train_loss_raw=0.9858, running_loss=0.9687, LR=0.000100
[2025-08-10 18:40:35,040][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049968] [Batch 01972/03692] [00:17:33/00:15:19, 0.534s/it]: train_loss_raw=0.8507, running_loss=0.9672, LR=0.000100
[2025-08-10 18:40:41,568][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049980] [Batch 01984/03692] [00:17:40/00:15:12, 0.535s/it]: train_loss_raw=0.9691, running_loss=0.9696, LR=0.000100
[2025-08-10 18:40:48,068][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 049992] [Batch 01996/03692] [00:17:47/00:15:06, 0.535s/it]: train_loss_raw=0.9067, running_loss=0.9711, LR=0.000100
[2025-08-10 18:40:59,821][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050004] [Batch 02008/03692] [00:17:58/00:15:04, 0.537s/it]: train_loss_raw=0.9656, running_loss=0.9730, LR=0.000100
[2025-08-10 18:41:06,397][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050016] [Batch 02020/03692] [00:18:05/00:14:58, 0.537s/it]: train_loss_raw=1.0037, running_loss=0.9705, LR=0.000100
[2025-08-10 18:41:13,016][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050028] [Batch 02032/03692] [00:18:11/00:14:52, 0.537s/it]: train_loss_raw=1.0129, running_loss=0.9724, LR=0.000100
[2025-08-10 18:41:19,542][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050040] [Batch 02044/03692] [00:18:18/00:14:45, 0.537s/it]: train_loss_raw=0.8606, running_loss=0.9675, LR=0.000100
[2025-08-10 18:41:25,862][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050052] [Batch 02056/03692] [00:18:24/00:14:39, 0.537s/it]: train_loss_raw=0.9906, running_loss=0.9697, LR=0.000100
[2025-08-10 18:41:32,181][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050064] [Batch 02068/03692] [00:18:31/00:14:32, 0.537s/it]: train_loss_raw=0.9027, running_loss=0.9691, LR=0.000100
[2025-08-10 18:41:38,537][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050076] [Batch 02080/03692] [00:18:37/00:14:26, 0.537s/it]: train_loss_raw=0.9762, running_loss=0.9694, LR=0.000100
[2025-08-10 18:41:44,842][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050088] [Batch 02092/03692] [00:18:43/00:14:19, 0.537s/it]: train_loss_raw=1.0064, running_loss=0.9706, LR=0.000100
[2025-08-10 18:41:51,096][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050100] [Batch 02104/03692] [00:18:50/00:14:12, 0.537s/it]: train_loss_raw=0.9004, running_loss=0.9686, LR=0.000100
[2025-08-10 18:41:57,358][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050112] [Batch 02116/03692] [00:18:56/00:14:06, 0.537s/it]: train_loss_raw=1.0109, running_loss=0.9680, LR=0.000100
[2025-08-10 18:42:03,581][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050124] [Batch 02128/03692] [00:19:02/00:13:59, 0.537s/it]: train_loss_raw=1.0057, running_loss=0.9660, LR=0.000100
[2025-08-10 18:42:10,110][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050136] [Batch 02140/03692] [00:19:09/00:13:53, 0.537s/it]: train_loss_raw=1.0000, running_loss=0.9630, LR=0.000100
[2025-08-10 18:42:16,691][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050148] [Batch 02152/03692] [00:19:15/00:13:46, 0.537s/it]: train_loss_raw=1.1210, running_loss=0.9596, LR=0.000100
[2025-08-10 18:42:36,436][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050160] [Batch 02164/03692] [00:19:35/00:13:49, 0.543s/it]: train_loss_raw=0.9497, running_loss=0.9600, LR=0.000100
[2025-08-10 18:42:42,775][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050172] [Batch 02176/03692] [00:19:41/00:13:43, 0.543s/it]: train_loss_raw=0.9396, running_loss=0.9581, LR=0.000100
[2025-08-10 18:42:48,887][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050184] [Batch 02188/03692] [00:19:47/00:13:36, 0.543s/it]: train_loss_raw=0.9909, running_loss=0.9540, LR=0.000100
[2025-08-10 18:42:55,212][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050196] [Batch 02200/03692] [00:19:54/00:13:29, 0.543s/it]: train_loss_raw=0.9100, running_loss=0.9557, LR=0.000100
[2025-08-10 18:43:01,424][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050208] [Batch 02212/03692] [00:20:00/00:13:23, 0.543s/it]: train_loss_raw=0.9793, running_loss=0.9540, LR=0.000100
[2025-08-10 18:43:07,886][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050220] [Batch 02224/03692] [00:20:06/00:13:16, 0.543s/it]: train_loss_raw=0.9210, running_loss=0.9560, LR=0.000100
[2025-08-10 18:43:14,573][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050232] [Batch 02236/03692] [00:20:13/00:13:10, 0.543s/it]: train_loss_raw=0.8871, running_loss=0.9563, LR=0.000100
[2025-08-10 18:43:21,152][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050244] [Batch 02248/03692] [00:20:20/00:13:03, 0.543s/it]: train_loss_raw=0.8937, running_loss=0.9575, LR=0.000100
[2025-08-10 18:43:27,692][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050256] [Batch 02260/03692] [00:20:26/00:12:57, 0.543s/it]: train_loss_raw=0.9177, running_loss=0.9580, LR=0.000100
[2025-08-10 18:43:34,333][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050268] [Batch 02272/03692] [00:20:33/00:12:50, 0.543s/it]: train_loss_raw=0.8933, running_loss=0.9610, LR=0.000100
[2025-08-10 18:43:40,878][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050280] [Batch 02284/03692] [00:20:39/00:12:44, 0.543s/it]: train_loss_raw=1.0047, running_loss=0.9624, LR=0.000100
[2025-08-10 18:43:47,416][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050292] [Batch 02296/03692] [00:20:46/00:12:37, 0.543s/it]: train_loss_raw=0.9813, running_loss=0.9593, LR=0.000100
[2025-08-10 18:43:54,047][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050304] [Batch 02308/03692] [00:20:52/00:12:31, 0.543s/it]: train_loss_raw=1.0316, running_loss=0.9622, LR=0.000100
[2025-08-10 18:44:00,159][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050316] [Batch 02320/03692] [00:20:59/00:12:24, 0.543s/it]: train_loss_raw=1.0532, running_loss=0.9608, LR=0.000100
[2025-08-10 18:44:06,413][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050328] [Batch 02332/03692] [00:21:05/00:12:17, 0.543s/it]: train_loss_raw=1.0388, running_loss=0.9630, LR=0.000100
[2025-08-10 18:44:12,478][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050340] [Batch 02344/03692] [00:21:11/00:12:11, 0.542s/it]: train_loss_raw=0.9572, running_loss=0.9634, LR=0.000100
[2025-08-10 18:44:18,532][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050352] [Batch 02356/03692] [00:21:17/00:12:04, 0.542s/it]: train_loss_raw=0.9555, running_loss=0.9628, LR=0.000100
[2025-08-10 18:44:24,548][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050364] [Batch 02368/03692] [00:21:23/00:11:57, 0.542s/it]: train_loss_raw=0.9330, running_loss=0.9611, LR=0.000100
[2025-08-10 18:44:30,608][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050376] [Batch 02380/03692] [00:21:29/00:11:50, 0.542s/it]: train_loss_raw=0.9342, running_loss=0.9631, LR=0.000100
[2025-08-10 18:44:36,766][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050388] [Batch 02392/03692] [00:21:35/00:11:44, 0.542s/it]: train_loss_raw=0.9306, running_loss=0.9638, LR=0.000100
[2025-08-10 18:44:42,813][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050400] [Batch 02404/03692] [00:21:41/00:11:37, 0.541s/it]: train_loss_raw=0.9181, running_loss=0.9582, LR=0.000100
[2025-08-10 18:44:48,822][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050412] [Batch 02416/03692] [00:21:47/00:11:30, 0.541s/it]: train_loss_raw=0.7619, running_loss=0.9556, LR=0.000100
[2025-08-10 18:44:54,862][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050424] [Batch 02428/03692] [00:21:53/00:11:23, 0.541s/it]: train_loss_raw=1.0592, running_loss=0.9569, LR=0.000100
[2025-08-10 18:45:00,953][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050436] [Batch 02440/03692] [00:21:59/00:11:17, 0.541s/it]: train_loss_raw=0.9364, running_loss=0.9566, LR=0.000100
[2025-08-10 18:45:07,001][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050448] [Batch 02452/03692] [00:22:05/00:11:10, 0.541s/it]: train_loss_raw=0.9524, running_loss=0.9542, LR=0.000100
[2025-08-10 18:45:12,987][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050460] [Batch 02464/03692] [00:22:11/00:11:03, 0.541s/it]: train_loss_raw=1.0201, running_loss=0.9539, LR=0.000100
[2025-08-10 18:45:19,141][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050472] [Batch 02476/03692] [00:22:18/00:10:57, 0.540s/it]: train_loss_raw=0.9005, running_loss=0.9573, LR=0.000100
[2025-08-10 18:45:25,422][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050484] [Batch 02488/03692] [00:22:24/00:10:50, 0.540s/it]: train_loss_raw=1.0081, running_loss=0.9626, LR=0.000100
[2025-08-10 18:45:31,814][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050496] [Batch 02500/03692] [00:22:30/00:10:44, 0.540s/it]: train_loss_raw=0.9534, running_loss=0.9624, LR=0.000100
[2025-08-10 18:45:38,266][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050508] [Batch 02512/03692] [00:22:37/00:10:37, 0.540s/it]: train_loss_raw=0.8544, running_loss=0.9594, LR=0.000100
[2025-08-10 18:45:44,796][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050520] [Batch 02524/03692] [00:22:43/00:10:31, 0.540s/it]: train_loss_raw=1.0864, running_loss=0.9611, LR=0.000100
[2025-08-10 18:45:51,318][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050532] [Batch 02536/03692] [00:22:50/00:10:24, 0.540s/it]: train_loss_raw=0.7896, running_loss=0.9626, LR=0.000100
[2025-08-10 18:45:57,730][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050544] [Batch 02548/03692] [00:22:56/00:10:18, 0.540s/it]: train_loss_raw=1.0054, running_loss=0.9635, LR=0.000100
[2025-08-10 18:46:04,171][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050556] [Batch 02560/03692] [00:23:03/00:10:11, 0.540s/it]: train_loss_raw=0.9343, running_loss=0.9611, LR=0.000100
[2025-08-10 18:46:10,682][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050568] [Batch 02572/03692] [00:23:09/00:10:05, 0.540s/it]: train_loss_raw=0.8882, running_loss=0.9618, LR=0.000100
[2025-08-10 18:46:17,218][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050580] [Batch 02584/03692] [00:23:16/00:09:58, 0.540s/it]: train_loss_raw=0.8182, running_loss=0.9607, LR=0.000100
[2025-08-10 18:46:23,704][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050592] [Batch 02596/03692] [00:23:22/00:09:52, 0.540s/it]: train_loss_raw=0.8525, running_loss=0.9567, LR=0.000100
[2025-08-10 18:46:30,115][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050604] [Batch 02608/03692] [00:23:29/00:09:45, 0.540s/it]: train_loss_raw=0.9875, running_loss=0.9563, LR=0.000100
[2025-08-10 18:46:36,562][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050616] [Batch 02620/03692] [00:23:35/00:09:39, 0.540s/it]: train_loss_raw=0.8654, running_loss=0.9588, LR=0.000100
[2025-08-10 18:46:42,955][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050628] [Batch 02632/03692] [00:23:41/00:09:32, 0.540s/it]: train_loss_raw=1.0032, running_loss=0.9585, LR=0.000100
[2025-08-10 18:46:49,286][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050640] [Batch 02644/03692] [00:23:48/00:09:26, 0.540s/it]: train_loss_raw=0.9775, running_loss=0.9615, LR=0.000100
[2025-08-10 18:46:55,702][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050652] [Batch 02656/03692] [00:23:54/00:09:19, 0.540s/it]: train_loss_raw=1.0951, running_loss=0.9620, LR=0.000100
[2025-08-10 18:47:02,067][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050664] [Batch 02668/03692] [00:24:01/00:09:13, 0.540s/it]: train_loss_raw=0.9886, running_loss=0.9594, LR=0.000100
[2025-08-10 18:47:08,454][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050676] [Batch 02680/03692] [00:24:07/00:09:06, 0.540s/it]: train_loss_raw=0.8941, running_loss=0.9581, LR=0.000100
[2025-08-10 18:47:14,881][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050688] [Batch 02692/03692] [00:24:13/00:09:00, 0.540s/it]: train_loss_raw=0.8828, running_loss=0.9575, LR=0.000100
[2025-08-10 18:47:21,318][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050700] [Batch 02704/03692] [00:24:20/00:08:53, 0.540s/it]: train_loss_raw=0.9359, running_loss=0.9621, LR=0.000100
[2025-08-10 18:47:27,709][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050712] [Batch 02716/03692] [00:24:26/00:08:47, 0.540s/it]: train_loss_raw=0.9285, running_loss=0.9628, LR=0.000100
[2025-08-10 18:47:34,101][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050724] [Batch 02728/03692] [00:24:33/00:08:40, 0.540s/it]: train_loss_raw=0.9693, running_loss=0.9651, LR=0.000100
[2025-08-10 18:47:40,424][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050736] [Batch 02740/03692] [00:24:39/00:08:34, 0.540s/it]: train_loss_raw=0.8882, running_loss=0.9611, LR=0.000100
[2025-08-10 18:47:46,971][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050748] [Batch 02752/03692] [00:24:45/00:08:27, 0.540s/it]: train_loss_raw=0.8558, running_loss=0.9549, LR=0.000100
[2025-08-10 18:47:53,458][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050760] [Batch 02764/03692] [00:24:52/00:08:21, 0.540s/it]: train_loss_raw=0.8826, running_loss=0.9524, LR=0.000100
[2025-08-10 18:48:00,045][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050772] [Batch 02776/03692] [00:24:58/00:08:14, 0.540s/it]: train_loss_raw=0.9300, running_loss=0.9495, LR=0.000100
[2025-08-10 18:48:06,524][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050784] [Batch 02788/03692] [00:25:05/00:08:08, 0.540s/it]: train_loss_raw=1.0709, running_loss=0.9447, LR=0.000100
[2025-08-10 18:48:12,788][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050796] [Batch 02800/03692] [00:25:11/00:08:01, 0.540s/it]: train_loss_raw=0.9491, running_loss=0.9489, LR=0.000100
[2025-08-10 18:48:19,184][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050808] [Batch 02812/03692] [00:25:18/00:07:55, 0.540s/it]: train_loss_raw=0.9395, running_loss=0.9442, LR=0.000100
[2025-08-10 18:48:25,689][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050820] [Batch 02824/03692] [00:25:24/00:07:48, 0.540s/it]: train_loss_raw=0.9508, running_loss=0.9408, LR=0.000100
[2025-08-10 18:48:32,205][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050832] [Batch 02836/03692] [00:25:31/00:07:42, 0.540s/it]: train_loss_raw=0.9454, running_loss=0.9400, LR=0.000100
[2025-08-10 18:48:38,763][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050844] [Batch 02848/03692] [00:25:37/00:07:35, 0.540s/it]: train_loss_raw=0.9323, running_loss=0.9374, LR=0.000100
[2025-08-10 18:48:44,944][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050856] [Batch 02860/03692] [00:25:43/00:07:29, 0.540s/it]: train_loss_raw=0.9157, running_loss=0.9412, LR=0.000100
[2025-08-10 18:48:51,232][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050868] [Batch 02872/03692] [00:25:50/00:07:22, 0.540s/it]: train_loss_raw=1.0398, running_loss=0.9389, LR=0.000100
[2025-08-10 18:48:57,830][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050880] [Batch 02884/03692] [00:25:56/00:07:16, 0.540s/it]: train_loss_raw=0.9985, running_loss=0.9390, LR=0.000100
[2025-08-10 18:49:04,330][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050892] [Batch 02896/03692] [00:26:03/00:07:09, 0.540s/it]: train_loss_raw=0.9595, running_loss=0.9389, LR=0.000100
[2025-08-10 18:49:10,889][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050904] [Batch 02908/03692] [00:26:09/00:07:03, 0.540s/it]: train_loss_raw=0.8858, running_loss=0.9392, LR=0.000100
[2025-08-10 18:49:17,449][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050916] [Batch 02920/03692] [00:26:16/00:06:56, 0.540s/it]: train_loss_raw=1.0541, running_loss=0.9425, LR=0.000100
[2025-08-10 18:49:23,886][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050928] [Batch 02932/03692] [00:26:22/00:06:50, 0.540s/it]: train_loss_raw=0.9384, running_loss=0.9452, LR=0.000100
[2025-08-10 18:49:30,315][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050940] [Batch 02944/03692] [00:26:29/00:06:43, 0.540s/it]: train_loss_raw=0.8838, running_loss=0.9424, LR=0.000100
[2025-08-10 18:49:36,577][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050952] [Batch 02956/03692] [00:26:35/00:06:37, 0.540s/it]: train_loss_raw=0.9328, running_loss=0.9430, LR=0.000100
[2025-08-10 18:49:42,892][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050964] [Batch 02968/03692] [00:26:41/00:06:30, 0.540s/it]: train_loss_raw=1.0283, running_loss=0.9450, LR=0.000100
[2025-08-10 18:49:49,361][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050976] [Batch 02980/03692] [00:26:48/00:06:24, 0.540s/it]: train_loss_raw=0.8357, running_loss=0.9431, LR=0.000100
[2025-08-10 18:49:55,782][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 050988] [Batch 02992/03692] [00:26:54/00:06:17, 0.540s/it]: train_loss_raw=0.9616, running_loss=0.9407, LR=0.000100
[2025-08-10 18:50:02,196][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051000] [Batch 03004/03692] [00:27:01/00:06:11, 0.540s/it]: train_loss_raw=0.9555, running_loss=0.9409, LR=0.000100
[2025-08-10 18:50:08,538][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051012] [Batch 03016/03692] [00:27:07/00:06:04, 0.540s/it]: train_loss_raw=0.9982, running_loss=0.9417, LR=0.000100
[2025-08-10 18:50:14,953][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051024] [Batch 03028/03692] [00:27:13/00:05:58, 0.540s/it]: train_loss_raw=1.0043, running_loss=0.9406, LR=0.000100
[2025-08-10 18:50:21,522][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051036] [Batch 03040/03692] [00:27:20/00:05:51, 0.540s/it]: train_loss_raw=0.9258, running_loss=0.9419, LR=0.000100
[2025-08-10 18:50:28,082][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051048] [Batch 03052/03692] [00:27:27/00:05:45, 0.540s/it]: train_loss_raw=1.0560, running_loss=0.9484, LR=0.000100
[2025-08-10 18:50:34,504][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051060] [Batch 03064/03692] [00:27:33/00:05:38, 0.540s/it]: train_loss_raw=0.8148, running_loss=0.9476, LR=0.000100
[2025-08-10 18:50:40,886][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051072] [Batch 03076/03692] [00:27:39/00:05:32, 0.540s/it]: train_loss_raw=0.9817, running_loss=0.9441, LR=0.000100
[2025-08-10 18:50:47,276][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051084] [Batch 03088/03692] [00:27:46/00:05:25, 0.540s/it]: train_loss_raw=0.7676, running_loss=0.9472, LR=0.000100
[2025-08-10 18:50:53,736][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051096] [Batch 03100/03692] [00:27:52/00:05:19, 0.540s/it]: train_loss_raw=0.7988, running_loss=0.9453, LR=0.000100
[2025-08-10 18:51:00,237][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051108] [Batch 03112/03692] [00:27:59/00:05:12, 0.540s/it]: train_loss_raw=1.0275, running_loss=0.9492, LR=0.000100
[2025-08-10 18:51:06,683][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051120] [Batch 03124/03692] [00:28:05/00:05:06, 0.540s/it]: train_loss_raw=0.9407, running_loss=0.9476, LR=0.000100
[2025-08-10 18:51:13,136][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051132] [Batch 03136/03692] [00:28:12/00:05:00, 0.540s/it]: train_loss_raw=0.9967, running_loss=0.9503, LR=0.000100
[2025-08-10 18:51:19,564][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051144] [Batch 03148/03692] [00:28:18/00:04:53, 0.540s/it]: train_loss_raw=0.9046, running_loss=0.9449, LR=0.000100
[2025-08-10 18:51:25,985][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051156] [Batch 03160/03692] [00:28:24/00:04:47, 0.540s/it]: train_loss_raw=0.9893, running_loss=0.9489, LR=0.000100
[2025-08-10 18:51:32,451][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051168] [Batch 03172/03692] [00:28:31/00:04:40, 0.540s/it]: train_loss_raw=1.0333, running_loss=0.9500, LR=0.000100
[2025-08-10 18:51:38,862][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051180] [Batch 03184/03692] [00:28:37/00:04:34, 0.540s/it]: train_loss_raw=0.9035, running_loss=0.9469, LR=0.000100
[2025-08-10 18:51:45,327][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051192] [Batch 03196/03692] [00:28:44/00:04:27, 0.540s/it]: train_loss_raw=0.9703, running_loss=0.9477, LR=0.000100
[2025-08-10 18:51:51,680][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051204] [Batch 03208/03692] [00:28:50/00:04:21, 0.539s/it]: train_loss_raw=0.9583, running_loss=0.9469, LR=0.000100
[2025-08-10 18:51:58,106][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051216] [Batch 03220/03692] [00:28:57/00:04:14, 0.539s/it]: train_loss_raw=0.9988, running_loss=0.9446, LR=0.000100
[2025-08-10 18:52:04,422][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051228] [Batch 03232/03692] [00:29:03/00:04:08, 0.539s/it]: train_loss_raw=0.9093, running_loss=0.9469, LR=0.000100
[2025-08-10 18:52:10,757][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051240] [Batch 03244/03692] [00:29:09/00:04:01, 0.539s/it]: train_loss_raw=0.9504, running_loss=0.9463, LR=0.000100
[2025-08-10 18:52:17,180][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051252] [Batch 03256/03692] [00:29:16/00:03:55, 0.539s/it]: train_loss_raw=0.8857, running_loss=0.9439, LR=0.000100
[2025-08-10 18:52:23,570][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051264] [Batch 03268/03692] [00:29:22/00:03:48, 0.539s/it]: train_loss_raw=0.8911, running_loss=0.9407, LR=0.000100
[2025-08-10 18:52:30,046][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051276] [Batch 03280/03692] [00:29:28/00:03:42, 0.539s/it]: train_loss_raw=0.8734, running_loss=0.9428, LR=0.000100
[2025-08-10 18:52:36,460][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051288] [Batch 03292/03692] [00:29:35/00:03:35, 0.539s/it]: train_loss_raw=0.9336, running_loss=0.9432, LR=0.000100
[2025-08-10 18:52:43,069][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051300] [Batch 03304/03692] [00:29:42/00:03:29, 0.539s/it]: train_loss_raw=0.9737, running_loss=0.9418, LR=0.000100
[2025-08-10 18:52:49,645][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051312] [Batch 03316/03692] [00:29:48/00:03:22, 0.539s/it]: train_loss_raw=0.9947, running_loss=0.9407, LR=0.000100
[2025-08-10 18:52:56,153][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051324] [Batch 03328/03692] [00:29:55/00:03:16, 0.539s/it]: train_loss_raw=0.8983, running_loss=0.9370, LR=0.000100
[2025-08-10 18:53:02,735][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051336] [Batch 03340/03692] [00:30:01/00:03:09, 0.539s/it]: train_loss_raw=0.9616, running_loss=0.9382, LR=0.000100
[2025-08-10 18:53:09,172][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051348] [Batch 03352/03692] [00:30:08/00:03:03, 0.539s/it]: train_loss_raw=0.8831, running_loss=0.9379, LR=0.000100
[2025-08-10 18:53:15,536][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051360] [Batch 03364/03692] [00:30:14/00:02:56, 0.539s/it]: train_loss_raw=0.7163, running_loss=0.9394, LR=0.000100
[2025-08-10 18:53:21,933][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051372] [Batch 03376/03692] [00:30:20/00:02:50, 0.539s/it]: train_loss_raw=0.9619, running_loss=0.9392, LR=0.000100
[2025-08-10 18:53:28,323][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051384] [Batch 03388/03692] [00:30:27/00:02:43, 0.539s/it]: train_loss_raw=1.0130, running_loss=0.9368, LR=0.000100
[2025-08-10 18:53:34,727][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051396] [Batch 03400/03692] [00:30:33/00:02:37, 0.539s/it]: train_loss_raw=1.0000, running_loss=0.9398, LR=0.000100
[2025-08-10 18:53:41,135][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051408] [Batch 03412/03692] [00:30:40/00:02:31, 0.539s/it]: train_loss_raw=0.9251, running_loss=0.9392, LR=0.000100
[2025-08-10 18:53:47,631][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051420] [Batch 03424/03692] [00:30:46/00:02:24, 0.539s/it]: train_loss_raw=0.9387, running_loss=0.9396, LR=0.000100
[2025-08-10 18:53:54,198][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051432] [Batch 03436/03692] [00:30:53/00:02:18, 0.539s/it]: train_loss_raw=0.9679, running_loss=0.9383, LR=0.000100
[2025-08-10 18:54:00,692][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051444] [Batch 03448/03692] [00:30:59/00:02:11, 0.539s/it]: train_loss_raw=0.9922, running_loss=0.9420, LR=0.000100
[2025-08-10 18:54:07,199][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051456] [Batch 03460/03692] [00:31:06/00:02:05, 0.539s/it]: train_loss_raw=0.8139, running_loss=0.9410, LR=0.000100
[2025-08-10 18:54:13,742][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051468] [Batch 03472/03692] [00:31:12/00:01:58, 0.539s/it]: train_loss_raw=0.9085, running_loss=0.9399, LR=0.000100
[2025-08-10 18:54:20,159][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051480] [Batch 03484/03692] [00:31:19/00:01:52, 0.539s/it]: train_loss_raw=1.0868, running_loss=0.9443, LR=0.000100
[2025-08-10 18:54:26,513][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051492] [Batch 03496/03692] [00:31:25/00:01:45, 0.539s/it]: train_loss_raw=1.0329, running_loss=0.9412, LR=0.000100
[2025-08-10 18:54:32,967][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051504] [Batch 03508/03692] [00:31:31/00:01:39, 0.539s/it]: train_loss_raw=0.9270, running_loss=0.9407, LR=0.000100
[2025-08-10 18:54:39,506][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051516] [Batch 03520/03692] [00:31:38/00:01:32, 0.539s/it]: train_loss_raw=0.8770, running_loss=0.9405, LR=0.000100
[2025-08-10 18:54:45,980][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051528] [Batch 03532/03692] [00:31:44/00:01:26, 0.539s/it]: train_loss_raw=1.1469, running_loss=0.9419, LR=0.000100
[2025-08-10 18:54:52,354][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051540] [Batch 03544/03692] [00:31:51/00:01:19, 0.539s/it]: train_loss_raw=0.9244, running_loss=0.9424, LR=0.000100
[2025-08-10 18:54:58,898][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051552] [Batch 03556/03692] [00:31:57/00:01:13, 0.539s/it]: train_loss_raw=0.9499, running_loss=0.9387, LR=0.000100
[2025-08-10 18:55:05,398][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051564] [Batch 03568/03692] [00:32:04/00:01:06, 0.539s/it]: train_loss_raw=0.8379, running_loss=0.9401, LR=0.000100
[2025-08-10 18:55:11,952][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051576] [Batch 03580/03692] [00:32:10/00:01:00, 0.539s/it]: train_loss_raw=0.9522, running_loss=0.9385, LR=0.000100
[2025-08-10 18:55:18,482][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051588] [Batch 03592/03692] [00:32:17/00:00:53, 0.539s/it]: train_loss_raw=0.9322, running_loss=0.9381, LR=0.000100
[2025-08-10 18:55:24,968][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051600] [Batch 03604/03692] [00:32:23/00:00:47, 0.539s/it]: train_loss_raw=0.9349, running_loss=0.9362, LR=0.000100
[2025-08-10 18:55:31,367][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051612] [Batch 03616/03692] [00:32:30/00:00:40, 0.539s/it]: train_loss_raw=0.8977, running_loss=0.9396, LR=0.000100
[2025-08-10 18:55:37,766][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051624] [Batch 03628/03692] [00:32:36/00:00:34, 0.539s/it]: train_loss_raw=0.9718, running_loss=0.9385, LR=0.000100
[2025-08-10 18:55:44,084][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051636] [Batch 03640/03692] [00:32:43/00:00:28, 0.539s/it]: train_loss_raw=0.8216, running_loss=0.9369, LR=0.000100
[2025-08-10 18:55:50,460][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051648] [Batch 03652/03692] [00:32:49/00:00:21, 0.539s/it]: train_loss_raw=1.0244, running_loss=0.9373, LR=0.000100
[2025-08-10 18:55:56,839][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051660] [Batch 03664/03692] [00:32:55/00:00:15, 0.539s/it]: train_loss_raw=1.0257, running_loss=0.9376, LR=0.000100
[2025-08-10 18:56:03,170][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051672] [Batch 03676/03692] [00:33:02/00:00:08, 0.539s/it]: train_loss_raw=0.9220, running_loss=0.9395, LR=0.000100
[2025-08-10 18:56:09,518][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 051684] [Batch 03688/03692] [00:33:08/00:00:02, 0.539s/it]: train_loss_raw=1.0710, running_loss=0.9385, LR=0.000100
[2025-08-10 18:56:40,766][__main__][INFO] - [VALIDATION] [Epoch 13/29] Starting validation.
[2025-08-10 18:57:14,270][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 051689] [Batch 00011/00025] [00:00:33/00:00:36, 2.792s/it]
[2025-08-10 18:57:29,705][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 051689] [Batch 00023/00025] [00:00:48/00:00:02, 2.039s/it]
[2025-08-10 18:57:30,831][__main__][INFO] - [VALIDATION] [Epoch 13/29] train_loss=0.93965, valid_loss=0.95567
[2025-08-10 18:57:30,831][__main__][INFO] - [VALIDATION] [Epoch 13/29] Metrics:
[2025-08-10 18:57:30,832][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_er      0.428
[2025-08-10 18:57:30,832][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_prec    0.320
[2025-08-10 18:57:30,832][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_recall  0.327
[2025-08-10 18:57:30,832][__main__][INFO] - [VALIDATION] [Epoch 13/29] - pep_recall 0.291
[2025-08-10 18:57:30,834][__main__][INFO] - [TRAIN] [Epoch 13/29] Epoch complete, total time 08:01:30, remaining time 09:10:17, 00:34:23 per epoch
[2025-08-10 18:57:35,838][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051696] [Batch 00008/03692] [00:00:03/00:29:16, 0.477s/it]: train_loss_raw=0.9047, running_loss=0.9056, LR=0.000100
[2025-08-10 18:57:42,282][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051708] [Batch 00020/03692] [00:00:10/00:31:23, 0.513s/it]: train_loss_raw=0.7681, running_loss=0.9036, LR=0.000100
[2025-08-10 18:57:48,758][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051720] [Batch 00032/03692] [00:00:16/00:31:54, 0.523s/it]: train_loss_raw=0.8679, running_loss=0.9063, LR=0.000100
[2025-08-10 18:57:55,280][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051732] [Batch 00044/03692] [00:00:23/00:32:08, 0.529s/it]: train_loss_raw=0.8909, running_loss=0.9069, LR=0.000100
[2025-08-10 18:58:01,730][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051744] [Batch 00056/03692] [00:00:29/00:32:08, 0.530s/it]: train_loss_raw=0.8909, running_loss=0.9073, LR=0.000100
[2025-08-10 18:58:08,243][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051756] [Batch 00068/03692] [00:00:36/00:32:10, 0.533s/it]: train_loss_raw=0.9303, running_loss=0.9047, LR=0.000100
[2025-08-10 18:58:14,791][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051768] [Batch 00080/03692] [00:00:42/00:32:10, 0.535s/it]: train_loss_raw=1.0085, running_loss=0.9038, LR=0.000100
[2025-08-10 18:58:21,349][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051780] [Batch 00092/03692] [00:00:49/00:32:10, 0.536s/it]: train_loss_raw=0.8876, running_loss=0.9051, LR=0.000100
[2025-08-10 18:58:27,902][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051792] [Batch 00104/03692] [00:00:55/00:32:07, 0.537s/it]: train_loss_raw=1.0226, running_loss=0.9070, LR=0.000100
[2025-08-10 18:58:34,511][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051804] [Batch 00116/03692] [00:01:02/00:32:06, 0.539s/it]: train_loss_raw=0.9780, running_loss=0.9070, LR=0.000100
[2025-08-10 18:58:41,020][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051816] [Batch 00128/03692] [00:01:08/00:32:01, 0.539s/it]: train_loss_raw=0.8544, running_loss=0.9067, LR=0.000100
[2025-08-10 18:58:47,432][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051828] [Batch 00140/03692] [00:01:15/00:31:53, 0.539s/it]: train_loss_raw=1.0718, running_loss=0.9077, LR=0.000100
[2025-08-10 18:58:53,816][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051840] [Batch 00152/03692] [00:01:21/00:31:44, 0.538s/it]: train_loss_raw=0.9165, running_loss=0.9089, LR=0.000100
[2025-08-10 18:59:00,258][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051852] [Batch 00164/03692] [00:01:28/00:31:38, 0.538s/it]: train_loss_raw=1.0384, running_loss=0.9096, LR=0.000100
[2025-08-10 18:59:06,596][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051864] [Batch 00176/03692] [00:01:34/00:31:29, 0.537s/it]: train_loss_raw=0.8439, running_loss=0.9073, LR=0.000100
[2025-08-10 18:59:12,960][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051876] [Batch 00188/03692] [00:01:40/00:31:21, 0.537s/it]: train_loss_raw=0.8975, running_loss=0.9041, LR=0.000100
[2025-08-10 18:59:19,349][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051888] [Batch 00200/03692] [00:01:47/00:31:13, 0.537s/it]: train_loss_raw=0.8218, running_loss=0.9053, LR=0.000100
[2025-08-10 18:59:25,873][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051900] [Batch 00212/03692] [00:01:53/00:31:08, 0.537s/it]: train_loss_raw=0.9211, running_loss=0.9066, LR=0.000100
[2025-08-10 18:59:32,278][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051912] [Batch 00224/03692] [00:02:00/00:31:01, 0.537s/it]: train_loss_raw=1.0393, running_loss=0.9045, LR=0.000100
[2025-08-10 18:59:38,679][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051924] [Batch 00236/03692] [00:02:06/00:30:54, 0.537s/it]: train_loss_raw=0.9569, running_loss=0.9055, LR=0.000100
[2025-08-10 18:59:45,062][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051936] [Batch 00248/03692] [00:02:13/00:30:47, 0.536s/it]: train_loss_raw=0.9432, running_loss=0.9095, LR=0.000100
[2025-08-10 18:59:51,409][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051948] [Batch 00260/03692] [00:02:19/00:30:39, 0.536s/it]: train_loss_raw=0.7480, running_loss=0.9073, LR=0.000100
[2025-08-10 18:59:57,911][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051960] [Batch 00272/03692] [00:02:25/00:30:34, 0.536s/it]: train_loss_raw=0.9058, running_loss=0.9077, LR=0.000100
[2025-08-10 19:00:04,413][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051972] [Batch 00284/03692] [00:02:32/00:30:28, 0.537s/it]: train_loss_raw=0.9273, running_loss=0.9094, LR=0.000100
[2025-08-10 19:00:10,974][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051984] [Batch 00296/03692] [00:02:38/00:30:23, 0.537s/it]: train_loss_raw=0.9178, running_loss=0.9098, LR=0.000100
[2025-08-10 19:00:17,583][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 051996] [Batch 00308/03692] [00:02:45/00:30:19, 0.538s/it]: train_loss_raw=1.0507, running_loss=0.9103, LR=0.000100
[2025-08-10 19:00:28,533][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052008] [Batch 00320/03692] [00:02:56/00:30:59, 0.552s/it]: train_loss_raw=0.8561, running_loss=0.9091, LR=0.000100
[2025-08-10 19:00:34,859][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052020] [Batch 00332/03692] [00:03:02/00:30:50, 0.551s/it]: train_loss_raw=0.9986, running_loss=0.9138, LR=0.000100
[2025-08-10 19:00:41,269][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052032] [Batch 00344/03692] [00:03:09/00:30:41, 0.550s/it]: train_loss_raw=0.7543, running_loss=0.9133, LR=0.000100
[2025-08-10 19:00:47,762][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052044] [Batch 00356/03692] [00:03:15/00:30:34, 0.550s/it]: train_loss_raw=0.9336, running_loss=0.9126, LR=0.000100
[2025-08-10 19:00:54,294][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052056] [Batch 00368/03692] [00:03:22/00:30:27, 0.550s/it]: train_loss_raw=0.8287, running_loss=0.9127, LR=0.000100
[2025-08-10 19:01:00,787][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052068] [Batch 00380/03692] [00:03:28/00:30:19, 0.549s/it]: train_loss_raw=0.9265, running_loss=0.9115, LR=0.000100
[2025-08-10 19:01:07,240][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052080] [Batch 00392/03692] [00:03:35/00:30:11, 0.549s/it]: train_loss_raw=0.9829, running_loss=0.9102, LR=0.000100
[2025-08-10 19:01:13,734][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052092] [Batch 00404/03692] [00:03:41/00:30:04, 0.549s/it]: train_loss_raw=0.9162, running_loss=0.9045, LR=0.000100
[2025-08-10 19:01:20,131][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052104] [Batch 00416/03692] [00:03:48/00:29:56, 0.548s/it]: train_loss_raw=0.9294, running_loss=0.9046, LR=0.000100
[2025-08-10 19:01:26,668][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052116] [Batch 00428/03692] [00:03:54/00:29:49, 0.548s/it]: train_loss_raw=0.9276, running_loss=0.9042, LR=0.000100
[2025-08-10 19:01:33,203][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052128] [Batch 00440/03692] [00:04:01/00:29:42, 0.548s/it]: train_loss_raw=0.8803, running_loss=0.9014, LR=0.000100
[2025-08-10 19:01:39,728][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052140] [Batch 00452/03692] [00:04:07/00:29:35, 0.548s/it]: train_loss_raw=0.8704, running_loss=0.9053, LR=0.000100
[2025-08-10 19:01:46,212][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052152] [Batch 00464/03692] [00:04:14/00:29:28, 0.548s/it]: train_loss_raw=0.9999, running_loss=0.9089, LR=0.000100
[2025-08-10 19:01:52,694][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052164] [Batch 00476/03692] [00:04:20/00:29:21, 0.548s/it]: train_loss_raw=0.8761, running_loss=0.9059, LR=0.000100
[2025-08-10 19:01:59,176][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052176] [Batch 00488/03692] [00:04:27/00:29:14, 0.547s/it]: train_loss_raw=0.9065, running_loss=0.9065, LR=0.000100
[2025-08-10 19:02:05,797][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052188] [Batch 00500/03692] [00:04:33/00:29:07, 0.548s/it]: train_loss_raw=1.0061, running_loss=0.9082, LR=0.000100
[2025-08-10 19:02:12,310][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052200] [Batch 00512/03692] [00:04:40/00:29:00, 0.547s/it]: train_loss_raw=0.8068, running_loss=0.9040, LR=0.000100
[2025-08-10 19:02:18,815][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052212] [Batch 00524/03692] [00:04:46/00:28:53, 0.547s/it]: train_loss_raw=0.9244, running_loss=0.9075, LR=0.000100
[2025-08-10 19:02:25,153][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052224] [Batch 00536/03692] [00:04:53/00:28:45, 0.547s/it]: train_loss_raw=0.8786, running_loss=0.9036, LR=0.000100
[2025-08-10 19:02:31,488][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052236] [Batch 00548/03692] [00:04:59/00:28:38, 0.546s/it]: train_loss_raw=1.0049, running_loss=0.9053, LR=0.000100
[2025-08-10 19:02:37,743][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052248] [Batch 00560/03692] [00:05:05/00:28:29, 0.546s/it]: train_loss_raw=1.0206, running_loss=0.9075, LR=0.000100
[2025-08-10 19:02:43,933][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052260] [Batch 00572/03692] [00:05:11/00:28:21, 0.545s/it]: train_loss_raw=0.8573, running_loss=0.9077, LR=0.000100
[2025-08-10 19:02:50,331][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052272] [Batch 00584/03692] [00:05:18/00:28:14, 0.545s/it]: train_loss_raw=0.9681, running_loss=0.9117, LR=0.000100
[2025-08-10 19:02:56,596][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052284] [Batch 00596/03692] [00:05:24/00:28:06, 0.545s/it]: train_loss_raw=0.9595, running_loss=0.9093, LR=0.000100
[2025-08-10 19:03:02,955][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052296] [Batch 00608/03692] [00:05:30/00:27:58, 0.544s/it]: train_loss_raw=0.8252, running_loss=0.9072, LR=0.000100
[2025-08-10 19:03:09,407][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052308] [Batch 00620/03692] [00:05:37/00:27:51, 0.544s/it]: train_loss_raw=0.9130, running_loss=0.9104, LR=0.000100
[2025-08-10 19:03:15,795][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052320] [Batch 00632/03692] [00:05:43/00:27:44, 0.544s/it]: train_loss_raw=0.9027, running_loss=0.9099, LR=0.000100
[2025-08-10 19:03:22,168][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052332] [Batch 00644/03692] [00:05:50/00:27:37, 0.544s/it]: train_loss_raw=0.9026, running_loss=0.9160, LR=0.000100
[2025-08-10 19:03:28,675][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052344] [Batch 00656/03692] [00:05:56/00:27:30, 0.544s/it]: train_loss_raw=0.9248, running_loss=0.9109, LR=0.000100
[2025-08-10 19:03:35,151][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052356] [Batch 00668/03692] [00:06:03/00:27:23, 0.544s/it]: train_loss_raw=0.8673, running_loss=0.9099, LR=0.000100
[2025-08-10 19:03:41,671][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052368] [Batch 00680/03692] [00:06:09/00:27:17, 0.544s/it]: train_loss_raw=0.8585, running_loss=0.9083, LR=0.000100
[2025-08-10 19:03:48,262][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052380] [Batch 00692/03692] [00:06:16/00:27:11, 0.544s/it]: train_loss_raw=0.9218, running_loss=0.9062, LR=0.000100
[2025-08-10 19:03:54,759][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052392] [Batch 00704/03692] [00:06:22/00:27:04, 0.544s/it]: train_loss_raw=0.9438, running_loss=0.9012, LR=0.000100
[2025-08-10 19:04:01,191][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052404] [Batch 00716/03692] [00:06:29/00:26:57, 0.544s/it]: train_loss_raw=0.9048, running_loss=0.9028, LR=0.000100
[2025-08-10 19:04:07,590][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052416] [Batch 00728/03692] [00:06:35/00:26:50, 0.543s/it]: train_loss_raw=0.9026, running_loss=0.9030, LR=0.000100
[2025-08-10 19:04:13,955][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052428] [Batch 00740/03692] [00:06:41/00:26:43, 0.543s/it]: train_loss_raw=0.9285, running_loss=0.9049, LR=0.000100
[2025-08-10 19:04:20,378][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052440] [Batch 00752/03692] [00:06:48/00:26:36, 0.543s/it]: train_loss_raw=0.8963, running_loss=0.9057, LR=0.000100
[2025-08-10 19:04:26,778][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052452] [Batch 00764/03692] [00:06:54/00:26:29, 0.543s/it]: train_loss_raw=0.9186, running_loss=0.9071, LR=0.000100
[2025-08-10 19:04:33,246][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052464] [Batch 00776/03692] [00:07:01/00:26:22, 0.543s/it]: train_loss_raw=0.8572, running_loss=0.9042, LR=0.000100
[2025-08-10 19:04:39,673][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052476] [Batch 00788/03692] [00:07:07/00:26:16, 0.543s/it]: train_loss_raw=0.8549, running_loss=0.9069, LR=0.000100
[2025-08-10 19:04:46,290][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052488] [Batch 00800/03692] [00:07:14/00:26:09, 0.543s/it]: train_loss_raw=0.7676, running_loss=0.9036, LR=0.000100
[2025-08-10 19:04:52,726][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052500] [Batch 00812/03692] [00:07:20/00:26:03, 0.543s/it]: train_loss_raw=0.9977, running_loss=0.9068, LR=0.000100
[2025-08-10 19:04:59,216][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052512] [Batch 00824/03692] [00:07:27/00:25:56, 0.543s/it]: train_loss_raw=0.8626, running_loss=0.9057, LR=0.000100
[2025-08-10 19:05:05,642][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052524] [Batch 00836/03692] [00:07:33/00:25:49, 0.543s/it]: train_loss_raw=1.0373, running_loss=0.9091, LR=0.000100
[2025-08-10 19:05:12,008][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052536] [Batch 00848/03692] [00:07:39/00:25:42, 0.542s/it]: train_loss_raw=0.9239, running_loss=0.9079, LR=0.000100
[2025-08-10 19:05:18,389][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052548] [Batch 00860/03692] [00:07:46/00:25:35, 0.542s/it]: train_loss_raw=1.0316, running_loss=0.9085, LR=0.000100
[2025-08-10 19:05:24,789][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052560] [Batch 00872/03692] [00:07:52/00:25:28, 0.542s/it]: train_loss_raw=0.7974, running_loss=0.9079, LR=0.000100
[2025-08-10 19:05:31,179][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052572] [Batch 00884/03692] [00:07:59/00:25:22, 0.542s/it]: train_loss_raw=0.9186, running_loss=0.9106, LR=0.000100
[2025-08-10 19:05:37,457][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052584] [Batch 00896/03692] [00:08:05/00:25:14, 0.542s/it]: train_loss_raw=0.8993, running_loss=0.9143, LR=0.000100
[2025-08-10 19:05:43,932][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052596] [Batch 00908/03692] [00:08:11/00:25:08, 0.542s/it]: train_loss_raw=0.9230, running_loss=0.9116, LR=0.000100
[2025-08-10 19:05:50,322][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052608] [Batch 00920/03692] [00:08:18/00:25:01, 0.542s/it]: train_loss_raw=0.9090, running_loss=0.9115, LR=0.000100
[2025-08-10 19:05:56,761][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052620] [Batch 00932/03692] [00:08:24/00:24:54, 0.542s/it]: train_loss_raw=0.9026, running_loss=0.9107, LR=0.000100
[2025-08-10 19:06:03,278][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052632] [Batch 00944/03692] [00:08:31/00:24:48, 0.542s/it]: train_loss_raw=0.9538, running_loss=0.9142, LR=0.000100
[2025-08-10 19:06:09,818][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052644] [Batch 00956/03692] [00:08:37/00:24:41, 0.542s/it]: train_loss_raw=0.8469, running_loss=0.9123, LR=0.000100
[2025-08-10 19:06:16,428][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052656] [Batch 00968/03692] [00:08:44/00:24:35, 0.542s/it]: train_loss_raw=0.9395, running_loss=0.9092, LR=0.000100
[2025-08-10 19:06:23,029][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052668] [Batch 00980/03692] [00:08:51/00:24:29, 0.542s/it]: train_loss_raw=0.9670, running_loss=0.9115, LR=0.000100
[2025-08-10 19:06:29,533][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052680] [Batch 00992/03692] [00:08:57/00:24:22, 0.542s/it]: train_loss_raw=0.8734, running_loss=0.9109, LR=0.000100
[2025-08-10 19:06:35,899][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052692] [Batch 01004/03692] [00:09:03/00:24:16, 0.542s/it]: train_loss_raw=0.9237, running_loss=0.9091, LR=0.000100
[2025-08-10 19:06:42,238][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052704] [Batch 01016/03692] [00:09:10/00:24:09, 0.542s/it]: train_loss_raw=0.8837, running_loss=0.9071, LR=0.000100
[2025-08-10 19:06:48,651][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052716] [Batch 01028/03692] [00:09:16/00:24:02, 0.541s/it]: train_loss_raw=0.9090, running_loss=0.9069, LR=0.000100
[2025-08-10 19:06:55,085][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052728] [Batch 01040/03692] [00:09:23/00:23:55, 0.541s/it]: train_loss_raw=0.9252, running_loss=0.9129, LR=0.000100
[2025-08-10 19:07:01,394][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052740] [Batch 01052/03692] [00:09:29/00:23:48, 0.541s/it]: train_loss_raw=0.8379, running_loss=0.9088, LR=0.000100
[2025-08-10 19:07:07,795][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052752] [Batch 01064/03692] [00:09:35/00:23:42, 0.541s/it]: train_loss_raw=0.8201, running_loss=0.9146, LR=0.000100
[2025-08-10 19:07:14,311][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052764] [Batch 01076/03692] [00:09:42/00:23:35, 0.541s/it]: train_loss_raw=0.9024, running_loss=0.9143, LR=0.000100
[2025-08-10 19:07:20,843][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052776] [Batch 01088/03692] [00:09:48/00:23:29, 0.541s/it]: train_loss_raw=0.9098, running_loss=0.9111, LR=0.000100
[2025-08-10 19:07:27,433][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052788] [Batch 01100/03692] [00:09:55/00:23:23, 0.541s/it]: train_loss_raw=0.9000, running_loss=0.9096, LR=0.000100
[2025-08-10 19:07:33,947][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052800] [Batch 01112/03692] [00:10:01/00:23:16, 0.541s/it]: train_loss_raw=0.8116, running_loss=0.9100, LR=0.000100
[2025-08-10 19:07:40,580][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052812] [Batch 01124/03692] [00:10:08/00:23:10, 0.541s/it]: train_loss_raw=0.8636, running_loss=0.9092, LR=0.000100
[2025-08-10 19:07:46,974][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052824] [Batch 01136/03692] [00:10:14/00:23:03, 0.541s/it]: train_loss_raw=0.8386, running_loss=0.9069, LR=0.000100
[2025-08-10 19:07:53,417][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052836] [Batch 01148/03692] [00:10:21/00:22:57, 0.541s/it]: train_loss_raw=0.8910, running_loss=0.9039, LR=0.000100
[2025-08-10 19:07:59,876][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052848] [Batch 01160/03692] [00:10:27/00:22:50, 0.541s/it]: train_loss_raw=0.8539, running_loss=0.9013, LR=0.000100
[2025-08-10 19:08:06,396][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052860] [Batch 01172/03692] [00:10:34/00:22:44, 0.541s/it]: train_loss_raw=1.0600, running_loss=0.9046, LR=0.000100
[2025-08-10 19:08:12,915][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052872] [Batch 01184/03692] [00:10:40/00:22:37, 0.541s/it]: train_loss_raw=1.0229, running_loss=0.9023, LR=0.000100
[2025-08-10 19:08:19,476][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052884] [Batch 01196/03692] [00:10:47/00:22:31, 0.541s/it]: train_loss_raw=0.8017, running_loss=0.9031, LR=0.000100
[2025-08-10 19:08:25,890][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052896] [Batch 01208/03692] [00:10:53/00:22:24, 0.541s/it]: train_loss_raw=0.8454, running_loss=0.9034, LR=0.000100
[2025-08-10 19:08:32,399][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052908] [Batch 01220/03692] [00:11:00/00:22:18, 0.541s/it]: train_loss_raw=0.8544, running_loss=0.8994, LR=0.000100
[2025-08-10 19:08:39,014][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052920] [Batch 01232/03692] [00:11:06/00:22:11, 0.541s/it]: train_loss_raw=0.7975, running_loss=0.9019, LR=0.000100
[2025-08-10 19:08:45,379][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052932] [Batch 01244/03692] [00:11:13/00:22:05, 0.541s/it]: train_loss_raw=0.9217, running_loss=0.9020, LR=0.000100
[2025-08-10 19:08:51,792][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052944] [Batch 01256/03692] [00:11:19/00:21:58, 0.541s/it]: train_loss_raw=0.8184, running_loss=0.8985, LR=0.000100
[2025-08-10 19:08:58,186][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052956] [Batch 01268/03692] [00:11:26/00:21:51, 0.541s/it]: train_loss_raw=0.9682, running_loss=0.8990, LR=0.000100
[2025-08-10 19:09:04,663][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052968] [Batch 01280/03692] [00:11:32/00:21:45, 0.541s/it]: train_loss_raw=0.8602, running_loss=0.8997, LR=0.000100
[2025-08-10 19:09:11,129][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052980] [Batch 01292/03692] [00:11:39/00:21:38, 0.541s/it]: train_loss_raw=0.9566, running_loss=0.9011, LR=0.000100
[2025-08-10 19:09:17,526][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 052992] [Batch 01304/03692] [00:11:45/00:21:31, 0.541s/it]: train_loss_raw=0.9015, running_loss=0.9003, LR=0.000100
[2025-08-10 19:09:23,881][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053004] [Batch 01316/03692] [00:11:51/00:21:25, 0.541s/it]: train_loss_raw=0.9659, running_loss=0.9022, LR=0.000100
[2025-08-10 19:09:30,322][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053016] [Batch 01328/03692] [00:11:58/00:21:18, 0.541s/it]: train_loss_raw=0.8508, running_loss=0.9033, LR=0.000100
[2025-08-10 19:09:36,689][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053028] [Batch 01340/03692] [00:12:04/00:21:11, 0.541s/it]: train_loss_raw=0.9862, running_loss=0.9002, LR=0.000100
[2025-08-10 19:09:42,944][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053040] [Batch 01352/03692] [00:12:10/00:21:05, 0.541s/it]: train_loss_raw=0.9750, running_loss=0.9019, LR=0.000100
[2025-08-10 19:09:49,282][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053052] [Batch 01364/03692] [00:12:17/00:20:58, 0.541s/it]: train_loss_raw=0.9046, running_loss=0.9092, LR=0.000100
[2025-08-10 19:09:55,676][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053064] [Batch 01376/03692] [00:12:23/00:20:51, 0.540s/it]: train_loss_raw=0.8464, running_loss=0.9013, LR=0.000100
[2025-08-10 19:10:02,093][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053076] [Batch 01388/03692] [00:12:30/00:20:45, 0.540s/it]: train_loss_raw=0.8792, running_loss=0.9011, LR=0.000100
[2025-08-10 19:10:08,607][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053088] [Batch 01400/03692] [00:12:36/00:20:38, 0.540s/it]: train_loss_raw=0.9808, running_loss=0.9041, LR=0.000100
[2025-08-10 19:10:14,987][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053100] [Batch 01412/03692] [00:12:42/00:20:31, 0.540s/it]: train_loss_raw=1.0153, running_loss=0.9017, LR=0.000100
[2025-08-10 19:10:21,364][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053112] [Batch 01424/03692] [00:12:49/00:20:25, 0.540s/it]: train_loss_raw=0.8209, running_loss=0.8998, LR=0.000100
[2025-08-10 19:10:27,751][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053124] [Batch 01436/03692] [00:12:55/00:20:18, 0.540s/it]: train_loss_raw=0.9983, running_loss=0.9037, LR=0.000100
[2025-08-10 19:10:34,059][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053136] [Batch 01448/03692] [00:13:02/00:20:11, 0.540s/it]: train_loss_raw=0.9303, running_loss=0.9035, LR=0.000100
[2025-08-10 19:10:40,362][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053148] [Batch 01460/03692] [00:13:08/00:20:05, 0.540s/it]: train_loss_raw=1.0001, running_loss=0.9013, LR=0.000100
[2025-08-10 19:10:46,758][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053160] [Batch 01472/03692] [00:13:14/00:19:58, 0.540s/it]: train_loss_raw=0.9907, running_loss=0.8990, LR=0.000100
[2025-08-10 19:10:53,296][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053172] [Batch 01484/03692] [00:13:21/00:19:52, 0.540s/it]: train_loss_raw=0.8776, running_loss=0.8968, LR=0.000100
[2025-08-10 19:10:59,847][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053184] [Batch 01496/03692] [00:13:27/00:19:45, 0.540s/it]: train_loss_raw=0.9339, running_loss=0.8962, LR=0.000100
[2025-08-10 19:11:06,377][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053196] [Batch 01508/03692] [00:13:34/00:19:39, 0.540s/it]: train_loss_raw=1.0122, running_loss=0.9003, LR=0.000100
[2025-08-10 19:11:13,041][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053208] [Batch 01520/03692] [00:13:41/00:19:33, 0.540s/it]: train_loss_raw=0.9592, running_loss=0.9024, LR=0.000100
[2025-08-10 19:11:19,503][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053220] [Batch 01532/03692] [00:13:47/00:19:26, 0.540s/it]: train_loss_raw=0.9161, running_loss=0.9007, LR=0.000100
[2025-08-10 19:11:49,024][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053232] [Batch 01544/03692] [00:14:17/00:19:52, 0.555s/it]: train_loss_raw=0.9732, running_loss=0.9007, LR=0.000100
[2025-08-10 19:11:55,454][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053244] [Batch 01556/03692] [00:14:23/00:19:45, 0.555s/it]: train_loss_raw=1.0434, running_loss=0.9003, LR=0.000100
[2025-08-10 19:12:01,954][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053256] [Batch 01568/03692] [00:14:29/00:19:38, 0.555s/it]: train_loss_raw=0.8940, running_loss=0.9025, LR=0.000100
[2025-08-10 19:12:08,517][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053268] [Batch 01580/03692] [00:14:36/00:19:31, 0.555s/it]: train_loss_raw=0.8009, running_loss=0.9006, LR=0.000100
[2025-08-10 19:12:15,080][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053280] [Batch 01592/03692] [00:14:43/00:19:24, 0.555s/it]: train_loss_raw=0.8093, running_loss=0.8993, LR=0.000100
[2025-08-10 19:12:21,641][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053292] [Batch 01604/03692] [00:14:49/00:19:18, 0.555s/it]: train_loss_raw=1.0441, running_loss=0.9055, LR=0.000100
[2025-08-10 19:12:28,203][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053304] [Batch 01616/03692] [00:14:56/00:19:11, 0.555s/it]: train_loss_raw=0.9379, running_loss=0.9073, LR=0.000100
[2025-08-10 19:12:34,484][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053316] [Batch 01628/03692] [00:15:02/00:19:04, 0.554s/it]: train_loss_raw=0.9595, running_loss=0.9097, LR=0.000100
[2025-08-10 19:12:40,846][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053328] [Batch 01640/03692] [00:15:08/00:18:57, 0.554s/it]: train_loss_raw=0.9128, running_loss=0.9061, LR=0.000100
[2025-08-10 19:12:47,248][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053340] [Batch 01652/03692] [00:15:15/00:18:50, 0.554s/it]: train_loss_raw=0.8642, running_loss=0.9037, LR=0.000100
[2025-08-10 19:12:53,724][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053352] [Batch 01664/03692] [00:15:21/00:18:43, 0.554s/it]: train_loss_raw=0.9257, running_loss=0.9050, LR=0.000100
[2025-08-10 19:13:00,162][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053364] [Batch 01676/03692] [00:15:28/00:18:36, 0.554s/it]: train_loss_raw=0.9343, running_loss=0.9048, LR=0.000100
[2025-08-10 19:13:06,673][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053376] [Batch 01688/03692] [00:15:34/00:18:29, 0.554s/it]: train_loss_raw=0.9056, running_loss=0.9048, LR=0.000100
[2025-08-10 19:13:13,217][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053388] [Batch 01700/03692] [00:15:41/00:18:22, 0.554s/it]: train_loss_raw=0.8818, running_loss=0.9052, LR=0.000100
[2025-08-10 19:13:19,725][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053400] [Batch 01712/03692] [00:15:47/00:18:16, 0.554s/it]: train_loss_raw=0.8494, running_loss=0.8988, LR=0.000100
[2025-08-10 19:13:26,261][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053412] [Batch 01724/03692] [00:15:54/00:18:09, 0.554s/it]: train_loss_raw=1.0029, running_loss=0.9006, LR=0.000100
[2025-08-10 19:13:32,723][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053424] [Batch 01736/03692] [00:16:00/00:18:02, 0.553s/it]: train_loss_raw=0.8984, running_loss=0.9020, LR=0.000100
[2025-08-10 19:13:39,064][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053436] [Batch 01748/03692] [00:16:07/00:17:55, 0.553s/it]: train_loss_raw=0.9993, running_loss=0.8992, LR=0.000100
[2025-08-10 19:13:45,351][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053448] [Batch 01760/03692] [00:16:13/00:17:48, 0.553s/it]: train_loss_raw=0.8361, running_loss=0.8980, LR=0.000100
[2025-08-10 19:13:51,896][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053460] [Batch 01772/03692] [00:16:19/00:17:41, 0.553s/it]: train_loss_raw=1.0442, running_loss=0.8964, LR=0.000100
[2025-08-10 19:13:58,333][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053472] [Batch 01784/03692] [00:16:26/00:17:34, 0.553s/it]: train_loss_raw=0.7119, running_loss=0.8942, LR=0.000100
[2025-08-10 19:14:04,879][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053484] [Batch 01796/03692] [00:16:32/00:17:28, 0.553s/it]: train_loss_raw=0.8307, running_loss=0.8911, LR=0.000100
[2025-08-10 19:14:11,416][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053496] [Batch 01808/03692] [00:16:39/00:17:21, 0.553s/it]: train_loss_raw=0.8889, running_loss=0.8923, LR=0.000100
[2025-08-10 19:14:17,996][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053508] [Batch 01820/03692] [00:16:45/00:17:14, 0.553s/it]: train_loss_raw=0.9621, running_loss=0.8918, LR=0.000100
[2025-08-10 19:14:24,417][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053520] [Batch 01832/03692] [00:16:52/00:17:07, 0.553s/it]: train_loss_raw=0.8354, running_loss=0.8902, LR=0.000100
[2025-08-10 19:14:30,904][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053532] [Batch 01844/03692] [00:16:58/00:17:01, 0.553s/it]: train_loss_raw=0.8229, running_loss=0.8910, LR=0.000100
[2025-08-10 19:14:37,362][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053544] [Batch 01856/03692] [00:17:05/00:16:54, 0.552s/it]: train_loss_raw=1.0005, running_loss=0.8920, LR=0.000100
[2025-08-10 19:14:43,835][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053556] [Batch 01868/03692] [00:17:11/00:16:47, 0.552s/it]: train_loss_raw=0.7618, running_loss=0.8870, LR=0.000100
[2025-08-10 19:14:50,322][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053568] [Batch 01880/03692] [00:17:18/00:16:40, 0.552s/it]: train_loss_raw=0.8088, running_loss=0.8842, LR=0.000100
[2025-08-10 19:14:56,885][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053580] [Batch 01892/03692] [00:17:24/00:16:34, 0.552s/it]: train_loss_raw=0.9843, running_loss=0.8868, LR=0.000100
[2025-08-10 19:15:03,383][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053592] [Batch 01904/03692] [00:17:31/00:16:27, 0.552s/it]: train_loss_raw=0.9438, running_loss=0.8851, LR=0.000100
[2025-08-10 19:15:09,877][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053604] [Batch 01916/03692] [00:17:37/00:16:20, 0.552s/it]: train_loss_raw=0.7678, running_loss=0.8858, LR=0.000100
[2025-08-10 19:15:16,413][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053616] [Batch 01928/03692] [00:17:44/00:16:13, 0.552s/it]: train_loss_raw=0.7983, running_loss=0.8842, LR=0.000100
[2025-08-10 19:15:22,801][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053628] [Batch 01940/03692] [00:17:50/00:16:07, 0.552s/it]: train_loss_raw=0.9123, running_loss=0.8846, LR=0.000100
[2025-08-10 19:15:29,274][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053640] [Batch 01952/03692] [00:17:57/00:16:00, 0.552s/it]: train_loss_raw=0.9515, running_loss=0.8894, LR=0.000100
[2025-08-10 19:15:35,827][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053652] [Batch 01964/03692] [00:18:03/00:15:53, 0.552s/it]: train_loss_raw=0.8217, running_loss=0.8885, LR=0.000100
[2025-08-10 19:15:42,255][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053664] [Batch 01976/03692] [00:18:10/00:15:46, 0.552s/it]: train_loss_raw=0.8869, running_loss=0.8869, LR=0.000100
[2025-08-10 19:15:48,715][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053676] [Batch 01988/03692] [00:18:16/00:15:40, 0.552s/it]: train_loss_raw=0.9206, running_loss=0.8815, LR=0.000100
[2025-08-10 19:15:55,154][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053688] [Batch 02000/03692] [00:18:23/00:15:33, 0.552s/it]: train_loss_raw=0.9441, running_loss=0.8869, LR=0.000100
[2025-08-10 19:16:01,542][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053700] [Batch 02012/03692] [00:18:29/00:15:26, 0.551s/it]: train_loss_raw=0.8164, running_loss=0.8891, LR=0.000100
[2025-08-10 19:16:07,995][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053712] [Batch 02024/03692] [00:18:35/00:15:19, 0.551s/it]: train_loss_raw=0.8311, running_loss=0.8914, LR=0.000100
[2025-08-10 19:16:14,559][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053724] [Batch 02036/03692] [00:18:42/00:15:13, 0.551s/it]: train_loss_raw=1.0019, running_loss=0.8934, LR=0.000100
[2025-08-10 19:16:20,900][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053736] [Batch 02048/03692] [00:18:48/00:15:06, 0.551s/it]: train_loss_raw=0.8748, running_loss=0.8903, LR=0.000100
[2025-08-10 19:16:27,330][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053748] [Batch 02060/03692] [00:18:55/00:14:59, 0.551s/it]: train_loss_raw=0.8596, running_loss=0.8919, LR=0.000100
[2025-08-10 19:16:33,782][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053760] [Batch 02072/03692] [00:19:01/00:14:52, 0.551s/it]: train_loss_raw=0.9640, running_loss=0.8905, LR=0.000100
[2025-08-10 19:16:40,183][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053772] [Batch 02084/03692] [00:19:08/00:14:45, 0.551s/it]: train_loss_raw=0.8278, running_loss=0.8858, LR=0.000100
[2025-08-10 19:16:46,628][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053784] [Batch 02096/03692] [00:19:14/00:14:39, 0.551s/it]: train_loss_raw=0.6973, running_loss=0.8791, LR=0.000100
[2025-08-10 19:16:53,068][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053796] [Batch 02108/03692] [00:19:21/00:14:32, 0.551s/it]: train_loss_raw=0.7459, running_loss=0.8784, LR=0.000100
[2025-08-10 19:16:59,433][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053808] [Batch 02120/03692] [00:19:27/00:14:25, 0.551s/it]: train_loss_raw=0.8776, running_loss=0.8797, LR=0.000100
[2025-08-10 19:17:05,822][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053820] [Batch 02132/03692] [00:19:33/00:14:18, 0.551s/it]: train_loss_raw=0.9022, running_loss=0.8825, LR=0.000100
[2025-08-10 19:17:12,219][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053832] [Batch 02144/03692] [00:19:40/00:14:12, 0.550s/it]: train_loss_raw=0.8279, running_loss=0.8801, LR=0.000100
[2025-08-10 19:17:18,633][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053844] [Batch 02156/03692] [00:19:46/00:14:05, 0.550s/it]: train_loss_raw=0.9166, running_loss=0.8861, LR=0.000100
[2025-08-10 19:17:25,038][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053856] [Batch 02168/03692] [00:19:53/00:13:58, 0.550s/it]: train_loss_raw=0.9547, running_loss=0.8892, LR=0.000100
[2025-08-10 19:17:31,421][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053868] [Batch 02180/03692] [00:19:59/00:13:51, 0.550s/it]: train_loss_raw=0.8184, running_loss=0.8883, LR=0.000100
[2025-08-10 19:17:37,899][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053880] [Batch 02192/03692] [00:20:05/00:13:45, 0.550s/it]: train_loss_raw=0.9110, running_loss=0.8868, LR=0.000100
[2025-08-10 19:17:44,271][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053892] [Batch 02204/03692] [00:20:12/00:13:38, 0.550s/it]: train_loss_raw=0.8681, running_loss=0.8867, LR=0.000100
[2025-08-10 19:17:50,650][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053904] [Batch 02216/03692] [00:20:18/00:13:31, 0.550s/it]: train_loss_raw=0.8542, running_loss=0.8852, LR=0.000100
[2025-08-10 19:17:57,118][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053916] [Batch 02228/03692] [00:20:25/00:13:24, 0.550s/it]: train_loss_raw=0.9103, running_loss=0.8871, LR=0.000100
[2025-08-10 19:18:03,532][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053928] [Batch 02240/03692] [00:20:31/00:13:18, 0.550s/it]: train_loss_raw=0.8539, running_loss=0.8855, LR=0.000100
[2025-08-10 19:18:09,938][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053940] [Batch 02252/03692] [00:20:37/00:13:11, 0.550s/it]: train_loss_raw=0.7290, running_loss=0.8817, LR=0.000100
[2025-08-10 19:18:16,410][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053952] [Batch 02264/03692] [00:20:44/00:13:04, 0.550s/it]: train_loss_raw=0.9042, running_loss=0.8826, LR=0.000100
[2025-08-10 19:18:22,903][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053964] [Batch 02276/03692] [00:20:50/00:12:58, 0.550s/it]: train_loss_raw=0.8876, running_loss=0.8816, LR=0.000100
[2025-08-10 19:18:29,424][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053976] [Batch 02288/03692] [00:20:57/00:12:51, 0.550s/it]: train_loss_raw=0.8863, running_loss=0.8778, LR=0.000100
[2025-08-10 19:18:35,857][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 053988] [Batch 02300/03692] [00:21:03/00:12:44, 0.549s/it]: train_loss_raw=0.9371, running_loss=0.8778, LR=0.000100
[2025-08-10 19:18:42,212][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054000] [Batch 02312/03692] [00:21:10/00:12:38, 0.549s/it]: train_loss_raw=0.9303, running_loss=0.8769, LR=0.000100
[2025-08-10 19:18:53,065][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054012] [Batch 02324/03692] [00:21:21/00:12:34, 0.551s/it]: train_loss_raw=0.8838, running_loss=0.8745, LR=0.000100
[2025-08-10 19:18:59,553][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054024] [Batch 02336/03692] [00:21:27/00:12:27, 0.551s/it]: train_loss_raw=0.8428, running_loss=0.8768, LR=0.000100
[2025-08-10 19:19:06,050][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054036] [Batch 02348/03692] [00:21:34/00:12:20, 0.551s/it]: train_loss_raw=0.9419, running_loss=0.8805, LR=0.000100
[2025-08-10 19:19:12,568][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054048] [Batch 02360/03692] [00:21:40/00:12:14, 0.551s/it]: train_loss_raw=0.9049, running_loss=0.8788, LR=0.000100
[2025-08-10 19:19:19,082][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054060] [Batch 02372/03692] [00:21:47/00:12:07, 0.551s/it]: train_loss_raw=0.8807, running_loss=0.8842, LR=0.000100
[2025-08-10 19:19:25,612][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054072] [Batch 02384/03692] [00:21:53/00:12:00, 0.551s/it]: train_loss_raw=0.8602, running_loss=0.8846, LR=0.000100
[2025-08-10 19:19:32,149][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054084] [Batch 02396/03692] [00:22:00/00:11:54, 0.551s/it]: train_loss_raw=0.8876, running_loss=0.8845, LR=0.000100
[2025-08-10 19:19:38,535][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054096] [Batch 02408/03692] [00:22:06/00:11:47, 0.551s/it]: train_loss_raw=0.8375, running_loss=0.8822, LR=0.000100
[2025-08-10 19:19:45,025][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054108] [Batch 02420/03692] [00:22:13/00:11:40, 0.551s/it]: train_loss_raw=0.8783, running_loss=0.8788, LR=0.000100
[2025-08-10 19:19:51,421][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054120] [Batch 02432/03692] [00:22:19/00:11:33, 0.551s/it]: train_loss_raw=0.8373, running_loss=0.8770, LR=0.000100
[2025-08-10 19:19:57,847][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054132] [Batch 02444/03692] [00:22:25/00:11:27, 0.551s/it]: train_loss_raw=0.8989, running_loss=0.8774, LR=0.000100
[2025-08-10 19:20:04,266][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054144] [Batch 02456/03692] [00:22:32/00:11:20, 0.551s/it]: train_loss_raw=0.9096, running_loss=0.8770, LR=0.000100
[2025-08-10 19:20:10,736][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054156] [Batch 02468/03692] [00:22:38/00:11:13, 0.551s/it]: train_loss_raw=0.8011, running_loss=0.8773, LR=0.000100
[2025-08-10 19:20:17,225][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054168] [Batch 02480/03692] [00:22:45/00:11:07, 0.550s/it]: train_loss_raw=0.7483, running_loss=0.8781, LR=0.000100
[2025-08-10 19:20:23,742][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054180] [Batch 02492/03692] [00:22:51/00:11:00, 0.550s/it]: train_loss_raw=0.9701, running_loss=0.8800, LR=0.000100
[2025-08-10 19:20:30,186][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054192] [Batch 02504/03692] [00:22:58/00:10:53, 0.550s/it]: train_loss_raw=0.9057, running_loss=0.8792, LR=0.000100
[2025-08-10 19:20:36,794][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054204] [Batch 02516/03692] [00:23:04/00:10:47, 0.550s/it]: train_loss_raw=0.8032, running_loss=0.8767, LR=0.000100
[2025-08-10 19:20:43,302][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054216] [Batch 02528/03692] [00:23:11/00:10:40, 0.550s/it]: train_loss_raw=0.8734, running_loss=0.8767, LR=0.000100
[2025-08-10 19:20:49,808][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054228] [Batch 02540/03692] [00:23:17/00:10:33, 0.550s/it]: train_loss_raw=0.9115, running_loss=0.8770, LR=0.000100
[2025-08-10 19:20:56,362][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054240] [Batch 02552/03692] [00:23:24/00:10:27, 0.550s/it]: train_loss_raw=0.8562, running_loss=0.8778, LR=0.000100
[2025-08-10 19:21:02,788][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054252] [Batch 02564/03692] [00:23:30/00:10:20, 0.550s/it]: train_loss_raw=0.8285, running_loss=0.8775, LR=0.000100
[2025-08-10 19:21:09,252][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054264] [Batch 02576/03692] [00:23:37/00:10:13, 0.550s/it]: train_loss_raw=0.9050, running_loss=0.8790, LR=0.000100
[2025-08-10 19:21:15,667][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054276] [Batch 02588/03692] [00:23:43/00:10:07, 0.550s/it]: train_loss_raw=0.8731, running_loss=0.8781, LR=0.000100
[2025-08-10 19:21:22,077][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054288] [Batch 02600/03692] [00:23:50/00:10:00, 0.550s/it]: train_loss_raw=0.8348, running_loss=0.8787, LR=0.000100
[2025-08-10 19:21:28,539][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054300] [Batch 02612/03692] [00:23:56/00:09:53, 0.550s/it]: train_loss_raw=0.8609, running_loss=0.8773, LR=0.000100
[2025-08-10 19:21:34,945][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054312] [Batch 02624/03692] [00:24:02/00:09:47, 0.550s/it]: train_loss_raw=0.9602, running_loss=0.8798, LR=0.000100
[2025-08-10 19:21:41,332][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054324] [Batch 02636/03692] [00:24:09/00:09:40, 0.550s/it]: train_loss_raw=0.9721, running_loss=0.8813, LR=0.000100
[2025-08-10 19:21:47,821][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054336] [Batch 02648/03692] [00:24:15/00:09:33, 0.550s/it]: train_loss_raw=1.0499, running_loss=0.8840, LR=0.000100
[2025-08-10 19:21:54,233][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054348] [Batch 02660/03692] [00:24:22/00:09:27, 0.550s/it]: train_loss_raw=0.9062, running_loss=0.8829, LR=0.000100
[2025-08-10 19:22:00,632][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054360] [Batch 02672/03692] [00:24:28/00:09:20, 0.550s/it]: train_loss_raw=0.9672, running_loss=0.8788, LR=0.000100
[2025-08-10 19:22:07,138][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054372] [Batch 02684/03692] [00:24:35/00:09:13, 0.550s/it]: train_loss_raw=0.9558, running_loss=0.8834, LR=0.000100
[2025-08-10 19:22:13,582][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054384] [Batch 02696/03692] [00:24:41/00:09:07, 0.550s/it]: train_loss_raw=0.9497, running_loss=0.8839, LR=0.000100
[2025-08-10 19:22:20,004][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054396] [Batch 02708/03692] [00:24:47/00:09:00, 0.549s/it]: train_loss_raw=0.9779, running_loss=0.8874, LR=0.000100
[2025-08-10 19:22:26,357][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054408] [Batch 02720/03692] [00:24:54/00:08:54, 0.549s/it]: train_loss_raw=0.8635, running_loss=0.8834, LR=0.000100
[2025-08-10 19:22:32,713][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054420] [Batch 02732/03692] [00:25:00/00:08:47, 0.549s/it]: train_loss_raw=0.8688, running_loss=0.8855, LR=0.000100
[2025-08-10 19:22:39,143][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054432] [Batch 02744/03692] [00:25:07/00:08:40, 0.549s/it]: train_loss_raw=0.8052, running_loss=0.8812, LR=0.000100
[2025-08-10 19:22:45,585][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054444] [Batch 02756/03692] [00:25:13/00:08:34, 0.549s/it]: train_loss_raw=0.7618, running_loss=0.8781, LR=0.000100
[2025-08-10 19:22:51,954][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054456] [Batch 02768/03692] [00:25:19/00:08:27, 0.549s/it]: train_loss_raw=0.9387, running_loss=0.8782, LR=0.000100
[2025-08-10 19:22:58,409][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054468] [Batch 02780/03692] [00:25:26/00:08:20, 0.549s/it]: train_loss_raw=0.9321, running_loss=0.8772, LR=0.000100
[2025-08-10 19:23:04,773][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054480] [Batch 02792/03692] [00:25:32/00:08:14, 0.549s/it]: train_loss_raw=0.9596, running_loss=0.8783, LR=0.000100
[2025-08-10 19:23:11,163][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054492] [Batch 02804/03692] [00:25:39/00:08:07, 0.549s/it]: train_loss_raw=0.7810, running_loss=0.8760, LR=0.000100
[2025-08-10 19:23:17,557][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054504] [Batch 02816/03692] [00:25:45/00:08:00, 0.549s/it]: train_loss_raw=0.8783, running_loss=0.8741, LR=0.000100
[2025-08-10 19:23:23,947][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054516] [Batch 02828/03692] [00:25:51/00:07:54, 0.549s/it]: train_loss_raw=0.9929, running_loss=0.8793, LR=0.000100
[2025-08-10 19:23:30,371][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054528] [Batch 02840/03692] [00:25:58/00:07:47, 0.549s/it]: train_loss_raw=0.9948, running_loss=0.8821, LR=0.000100
[2025-08-10 19:23:36,814][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054540] [Batch 02852/03692] [00:26:04/00:07:40, 0.549s/it]: train_loss_raw=0.7590, running_loss=0.8780, LR=0.000100
[2025-08-10 19:23:43,170][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054552] [Batch 02864/03692] [00:26:11/00:07:34, 0.549s/it]: train_loss_raw=0.9555, running_loss=0.8768, LR=0.000100
[2025-08-10 19:23:49,613][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054564] [Batch 02876/03692] [00:26:17/00:07:27, 0.549s/it]: train_loss_raw=0.9160, running_loss=0.8740, LR=0.000100
[2025-08-10 19:23:56,018][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054576] [Batch 02888/03692] [00:26:23/00:07:20, 0.548s/it]: train_loss_raw=0.8050, running_loss=0.8701, LR=0.000100
[2025-08-10 19:24:02,426][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054588] [Batch 02900/03692] [00:26:30/00:07:14, 0.548s/it]: train_loss_raw=0.9336, running_loss=0.8718, LR=0.000100
[2025-08-10 19:24:08,852][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054600] [Batch 02912/03692] [00:26:36/00:07:07, 0.548s/it]: train_loss_raw=0.9438, running_loss=0.8713, LR=0.000100
[2025-08-10 19:24:15,218][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054612] [Batch 02924/03692] [00:26:43/00:07:01, 0.548s/it]: train_loss_raw=0.8488, running_loss=0.8720, LR=0.000100
[2025-08-10 19:24:21,648][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054624] [Batch 02936/03692] [00:26:49/00:06:54, 0.548s/it]: train_loss_raw=0.8572, running_loss=0.8733, LR=0.000100
[2025-08-10 19:24:28,253][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054636] [Batch 02948/03692] [00:26:56/00:06:47, 0.548s/it]: train_loss_raw=0.8618, running_loss=0.8693, LR=0.000100
[2025-08-10 19:24:34,706][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054648] [Batch 02960/03692] [00:27:02/00:06:41, 0.548s/it]: train_loss_raw=0.9042, running_loss=0.8674, LR=0.000100
[2025-08-10 19:24:41,224][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054660] [Batch 02972/03692] [00:27:09/00:06:34, 0.548s/it]: train_loss_raw=0.8909, running_loss=0.8669, LR=0.000100
[2025-08-10 19:24:47,545][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054672] [Batch 02984/03692] [00:27:15/00:06:28, 0.548s/it]: train_loss_raw=0.8922, running_loss=0.8680, LR=0.000100
[2025-08-10 19:24:54,012][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054684] [Batch 02996/03692] [00:27:21/00:06:21, 0.548s/it]: train_loss_raw=0.8437, running_loss=0.8653, LR=0.000100
[2025-08-10 19:25:00,438][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054696] [Batch 03008/03692] [00:27:28/00:06:14, 0.548s/it]: train_loss_raw=0.8861, running_loss=0.8639, LR=0.000100
[2025-08-10 19:25:06,871][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054708] [Batch 03020/03692] [00:27:34/00:06:08, 0.548s/it]: train_loss_raw=0.8975, running_loss=0.8629, LR=0.000100
[2025-08-10 19:25:13,252][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054720] [Batch 03032/03692] [00:27:41/00:06:01, 0.548s/it]: train_loss_raw=0.7939, running_loss=0.8625, LR=0.000100
[2025-08-10 19:25:19,622][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054732] [Batch 03044/03692] [00:27:47/00:05:54, 0.548s/it]: train_loss_raw=0.7934, running_loss=0.8616, LR=0.000100
[2025-08-10 19:25:26,069][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054744] [Batch 03056/03692] [00:27:54/00:05:48, 0.548s/it]: train_loss_raw=0.7665, running_loss=0.8641, LR=0.000100
[2025-08-10 19:25:32,493][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054756] [Batch 03068/03692] [00:28:00/00:05:41, 0.548s/it]: train_loss_raw=0.8573, running_loss=0.8669, LR=0.000100
[2025-08-10 19:25:38,979][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054768] [Batch 03080/03692] [00:28:06/00:05:35, 0.548s/it]: train_loss_raw=0.8982, running_loss=0.8655, LR=0.000100
[2025-08-10 19:25:45,406][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054780] [Batch 03092/03692] [00:28:13/00:05:28, 0.548s/it]: train_loss_raw=0.9277, running_loss=0.8668, LR=0.000100
[2025-08-10 19:25:51,842][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054792] [Batch 03104/03692] [00:28:19/00:05:22, 0.548s/it]: train_loss_raw=0.9981, running_loss=0.8707, LR=0.000100
[2025-08-10 19:25:58,323][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054804] [Batch 03116/03692] [00:28:26/00:05:15, 0.548s/it]: train_loss_raw=0.8245, running_loss=0.8711, LR=0.000100
[2025-08-10 19:26:04,877][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054816] [Batch 03128/03692] [00:28:32/00:05:08, 0.548s/it]: train_loss_raw=0.8966, running_loss=0.8707, LR=0.000100
[2025-08-10 19:26:11,336][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054828] [Batch 03140/03692] [00:28:39/00:05:02, 0.548s/it]: train_loss_raw=1.0433, running_loss=0.8713, LR=0.000100
[2025-08-10 19:26:17,745][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054840] [Batch 03152/03692] [00:28:45/00:04:55, 0.548s/it]: train_loss_raw=0.9577, running_loss=0.8760, LR=0.000100
[2025-08-10 19:26:24,157][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054852] [Batch 03164/03692] [00:28:52/00:04:49, 0.547s/it]: train_loss_raw=0.9404, running_loss=0.8773, LR=0.000100
[2025-08-10 19:26:30,581][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054864] [Batch 03176/03692] [00:28:58/00:04:42, 0.547s/it]: train_loss_raw=1.0412, running_loss=0.8780, LR=0.000100
[2025-08-10 19:26:36,959][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054876] [Batch 03188/03692] [00:29:04/00:04:35, 0.547s/it]: train_loss_raw=0.8912, running_loss=0.8779, LR=0.000100
[2025-08-10 19:26:43,369][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054888] [Batch 03200/03692] [00:29:11/00:04:29, 0.547s/it]: train_loss_raw=0.8107, running_loss=0.8777, LR=0.000100
[2025-08-10 19:26:49,734][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054900] [Batch 03212/03692] [00:29:17/00:04:22, 0.547s/it]: train_loss_raw=1.0292, running_loss=0.8792, LR=0.000100
[2025-08-10 19:26:56,174][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054912] [Batch 03224/03692] [00:29:24/00:04:16, 0.547s/it]: train_loss_raw=0.9106, running_loss=0.8793, LR=0.000100
[2025-08-10 19:27:02,838][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054924] [Batch 03236/03692] [00:29:30/00:04:09, 0.547s/it]: train_loss_raw=0.8786, running_loss=0.8805, LR=0.000100
[2025-08-10 19:27:09,272][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054936] [Batch 03248/03692] [00:29:37/00:04:02, 0.547s/it]: train_loss_raw=0.9709, running_loss=0.8808, LR=0.000100
[2025-08-10 19:27:15,810][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054948] [Batch 03260/03692] [00:29:43/00:03:56, 0.547s/it]: train_loss_raw=0.9662, running_loss=0.8779, LR=0.000100
[2025-08-10 19:27:22,345][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054960] [Batch 03272/03692] [00:29:50/00:03:49, 0.547s/it]: train_loss_raw=0.8222, running_loss=0.8762, LR=0.000100
[2025-08-10 19:27:28,843][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054972] [Batch 03284/03692] [00:29:56/00:03:43, 0.547s/it]: train_loss_raw=0.8041, running_loss=0.8714, LR=0.000100
[2025-08-10 19:27:35,235][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054984] [Batch 03296/03692] [00:30:03/00:03:36, 0.547s/it]: train_loss_raw=0.8127, running_loss=0.8731, LR=0.000100
[2025-08-10 19:27:41,643][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 054996] [Batch 03308/03692] [00:30:09/00:03:30, 0.547s/it]: train_loss_raw=0.8924, running_loss=0.8728, LR=0.000100
[2025-08-10 19:27:48,021][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055008] [Batch 03320/03692] [00:30:15/00:03:23, 0.547s/it]: train_loss_raw=0.8951, running_loss=0.8701, LR=0.000100
[2025-08-10 19:27:54,369][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055020] [Batch 03332/03692] [00:30:22/00:03:16, 0.547s/it]: train_loss_raw=0.7532, running_loss=0.8689, LR=0.000100
[2025-08-10 19:28:00,831][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055032] [Batch 03344/03692] [00:30:28/00:03:10, 0.547s/it]: train_loss_raw=0.9689, running_loss=0.8711, LR=0.000100
[2025-08-10 19:28:07,221][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055044] [Batch 03356/03692] [00:30:35/00:03:03, 0.547s/it]: train_loss_raw=0.9184, running_loss=0.8693, LR=0.000100
[2025-08-10 19:28:13,676][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055056] [Batch 03368/03692] [00:30:41/00:02:57, 0.547s/it]: train_loss_raw=0.9313, running_loss=0.8718, LR=0.000100
[2025-08-10 19:28:20,033][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055068] [Batch 03380/03692] [00:30:48/00:02:50, 0.547s/it]: train_loss_raw=0.8114, running_loss=0.8677, LR=0.000100
[2025-08-10 19:28:26,450][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055080] [Batch 03392/03692] [00:30:54/00:02:44, 0.547s/it]: train_loss_raw=0.9063, running_loss=0.8686, LR=0.000100
[2025-08-10 19:28:32,826][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055092] [Batch 03404/03692] [00:31:00/00:02:37, 0.547s/it]: train_loss_raw=0.7699, running_loss=0.8692, LR=0.000100
[2025-08-10 19:28:39,260][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055104] [Batch 03416/03692] [00:31:07/00:02:30, 0.547s/it]: train_loss_raw=0.7797, running_loss=0.8709, LR=0.000100
[2025-08-10 19:28:45,811][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055116] [Batch 03428/03692] [00:31:13/00:02:24, 0.547s/it]: train_loss_raw=0.8860, running_loss=0.8725, LR=0.000100
[2025-08-10 19:28:52,341][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055128] [Batch 03440/03692] [00:31:20/00:02:17, 0.547s/it]: train_loss_raw=0.7840, running_loss=0.8692, LR=0.000100
[2025-08-10 19:28:58,902][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055140] [Batch 03452/03692] [00:31:26/00:02:11, 0.547s/it]: train_loss_raw=0.8490, running_loss=0.8668, LR=0.000100
[2025-08-10 19:29:05,384][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055152] [Batch 03464/03692] [00:31:33/00:02:04, 0.547s/it]: train_loss_raw=0.8557, running_loss=0.8678, LR=0.000100
[2025-08-10 19:29:11,851][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055164] [Batch 03476/03692] [00:31:39/00:01:58, 0.547s/it]: train_loss_raw=0.9467, running_loss=0.8679, LR=0.000100
[2025-08-10 19:29:18,315][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055176] [Batch 03488/03692] [00:31:46/00:01:51, 0.547s/it]: train_loss_raw=0.8564, running_loss=0.8660, LR=0.000100
[2025-08-10 19:29:24,781][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055188] [Batch 03500/03692] [00:31:52/00:01:44, 0.547s/it]: train_loss_raw=0.9255, running_loss=0.8702, LR=0.000100
[2025-08-10 19:29:31,206][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055200] [Batch 03512/03692] [00:31:59/00:01:38, 0.546s/it]: train_loss_raw=0.9814, running_loss=0.8698, LR=0.000100
[2025-08-10 19:29:37,651][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055212] [Batch 03524/03692] [00:32:05/00:01:31, 0.546s/it]: train_loss_raw=0.8272, running_loss=0.8711, LR=0.000100
[2025-08-10 19:29:44,051][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055224] [Batch 03536/03692] [00:32:12/00:01:25, 0.546s/it]: train_loss_raw=0.8179, running_loss=0.8670, LR=0.000100
[2025-08-10 19:29:50,525][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055236] [Batch 03548/03692] [00:32:18/00:01:18, 0.546s/it]: train_loss_raw=0.8191, running_loss=0.8661, LR=0.000100
[2025-08-10 19:29:56,890][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055248] [Batch 03560/03692] [00:32:24/00:01:12, 0.546s/it]: train_loss_raw=0.9008, running_loss=0.8641, LR=0.000100
[2025-08-10 19:30:03,303][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055260] [Batch 03572/03692] [00:32:31/00:01:05, 0.546s/it]: train_loss_raw=0.8238, running_loss=0.8649, LR=0.000100
[2025-08-10 19:30:09,749][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055272] [Batch 03584/03692] [00:32:37/00:00:58, 0.546s/it]: train_loss_raw=0.9112, running_loss=0.8612, LR=0.000100
[2025-08-10 19:30:16,229][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055284] [Batch 03596/03692] [00:32:44/00:00:52, 0.546s/it]: train_loss_raw=0.8526, running_loss=0.8575, LR=0.000100
[2025-08-10 19:30:22,708][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055296] [Batch 03608/03692] [00:32:50/00:00:45, 0.546s/it]: train_loss_raw=0.6961, running_loss=0.8574, LR=0.000100
[2025-08-10 19:30:29,120][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055308] [Batch 03620/03692] [00:32:57/00:00:39, 0.546s/it]: train_loss_raw=0.8474, running_loss=0.8565, LR=0.000100
[2025-08-10 19:30:35,485][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055320] [Batch 03632/03692] [00:33:03/00:00:32, 0.546s/it]: train_loss_raw=0.8863, running_loss=0.8562, LR=0.000100
[2025-08-10 19:30:41,974][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055332] [Batch 03644/03692] [00:33:09/00:00:26, 0.546s/it]: train_loss_raw=0.8335, running_loss=0.8524, LR=0.000100
[2025-08-10 19:30:48,406][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055344] [Batch 03656/03692] [00:33:16/00:00:19, 0.546s/it]: train_loss_raw=0.8740, running_loss=0.8548, LR=0.000100
[2025-08-10 19:30:54,759][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055356] [Batch 03668/03692] [00:33:22/00:00:13, 0.546s/it]: train_loss_raw=0.8977, running_loss=0.8592, LR=0.000100
[2025-08-10 19:31:01,184][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055368] [Batch 03680/03692] [00:33:29/00:00:06, 0.546s/it]: train_loss_raw=0.7938, running_loss=0.8577, LR=0.000100
[2025-08-10 19:31:07,556][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 055380] [Batch 03692/03692] [00:33:35/00:00:00, 0.546s/it]: train_loss_raw=0.8448, running_loss=0.8575, LR=0.000100
[2025-08-10 19:31:12,514][__main__][INFO] - [VALIDATION] [Epoch 14/29] Starting validation.
[2025-08-10 19:31:46,442][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 055381] [Batch 00011/00025] [00:00:33/00:00:36, 2.827s/it]
[2025-08-10 19:32:01,959][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 055381] [Batch 00023/00025] [00:00:49/00:00:02, 2.060s/it]
[2025-08-10 19:32:03,211][__main__][INFO] - [VALIDATION] [Epoch 14/29] train_loss=0.85753, valid_loss=0.88570
[2025-08-10 19:32:03,211][__main__][INFO] - [VALIDATION] [Epoch 14/29] Metrics:
[2025-08-10 19:32:03,211][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_er      0.392
[2025-08-10 19:32:03,211][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_prec    0.364
[2025-08-10 19:32:03,212][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_recall  0.370
[2025-08-10 19:32:03,212][__main__][INFO] - [VALIDATION] [Epoch 14/29] - pep_recall 0.329
[2025-08-10 19:32:03,216][__main__][INFO] - [TRAIN] [Epoch 14/29] Epoch complete, total time 08:36:02, remaining time 08:36:02, 00:34:24 per epoch
[2025-08-10 19:32:10,438][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055392] [Batch 00012/03692] [00:00:05/00:30:32, 0.498s/it]: train_loss_raw=0.8916, running_loss=0.8274, LR=0.000100
[2025-08-10 19:32:16,915][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055404] [Batch 00024/03692] [00:00:12/00:31:43, 0.519s/it]: train_loss_raw=0.9869, running_loss=0.8314, LR=0.000100
[2025-08-10 19:32:23,398][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055416] [Batch 00036/03692] [00:00:18/00:32:03, 0.526s/it]: train_loss_raw=0.9390, running_loss=0.8381, LR=0.000100
[2025-08-10 19:32:29,808][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055428] [Batch 00048/03692] [00:00:25/00:32:04, 0.528s/it]: train_loss_raw=0.8360, running_loss=0.8336, LR=0.000100
[2025-08-10 19:32:36,149][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055440] [Batch 00060/03692] [00:00:31/00:31:58, 0.528s/it]: train_loss_raw=0.8687, running_loss=0.8423, LR=0.000100
[2025-08-10 19:32:42,599][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055452] [Batch 00072/03692] [00:00:38/00:31:57, 0.530s/it]: train_loss_raw=0.8145, running_loss=0.8420, LR=0.000100
[2025-08-10 19:32:48,982][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055464] [Batch 00084/03692] [00:00:44/00:31:52, 0.530s/it]: train_loss_raw=0.8152, running_loss=0.8414, LR=0.000100
[2025-08-10 19:32:55,340][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055476] [Batch 00096/03692] [00:00:50/00:31:45, 0.530s/it]: train_loss_raw=0.8950, running_loss=0.8444, LR=0.000100
[2025-08-10 19:33:01,842][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055488] [Batch 00108/03692] [00:00:57/00:31:44, 0.531s/it]: train_loss_raw=0.7901, running_loss=0.8416, LR=0.000100
[2025-08-10 19:33:08,201][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055500] [Batch 00120/03692] [00:01:03/00:31:37, 0.531s/it]: train_loss_raw=0.8523, running_loss=0.8455, LR=0.000100
[2025-08-10 19:33:14,600][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055512] [Batch 00132/03692] [00:01:10/00:31:31, 0.531s/it]: train_loss_raw=0.8222, running_loss=0.8493, LR=0.000100
[2025-08-10 19:33:21,059][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055524] [Batch 00144/03692] [00:01:16/00:31:27, 0.532s/it]: train_loss_raw=0.6521, running_loss=0.8492, LR=0.000100
[2025-08-10 19:33:27,570][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055536] [Batch 00156/03692] [00:01:23/00:31:23, 0.533s/it]: train_loss_raw=1.0491, running_loss=0.8528, LR=0.000100
[2025-08-10 19:33:34,038][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055548] [Batch 00168/03692] [00:01:29/00:31:18, 0.533s/it]: train_loss_raw=0.8298, running_loss=0.8521, LR=0.000100
[2025-08-10 19:33:40,452][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055560] [Batch 00180/03692] [00:01:35/00:31:12, 0.533s/it]: train_loss_raw=0.8653, running_loss=0.8532, LR=0.000100
[2025-08-10 19:33:46,872][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055572] [Batch 00192/03692] [00:01:42/00:31:06, 0.533s/it]: train_loss_raw=0.8053, running_loss=0.8536, LR=0.000100
[2025-08-10 19:33:53,292][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055584] [Batch 00204/03692] [00:01:48/00:31:00, 0.533s/it]: train_loss_raw=0.9216, running_loss=0.8571, LR=0.000100
[2025-08-10 19:33:59,678][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055596] [Batch 00216/03692] [00:01:55/00:30:54, 0.533s/it]: train_loss_raw=0.8731, running_loss=0.8567, LR=0.000100
[2025-08-10 19:34:06,165][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055608] [Batch 00228/03692] [00:02:01/00:30:49, 0.534s/it]: train_loss_raw=0.8892, running_loss=0.8588, LR=0.000100
[2025-08-10 19:34:12,719][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055620] [Batch 00240/03692] [00:02:08/00:30:44, 0.534s/it]: train_loss_raw=0.9686, running_loss=0.8603, LR=0.000100
[2025-08-10 19:34:19,145][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055632] [Batch 00252/03692] [00:02:14/00:30:38, 0.534s/it]: train_loss_raw=0.9106, running_loss=0.8561, LR=0.000100
[2025-08-10 19:34:25,565][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055644] [Batch 00264/03692] [00:02:21/00:30:32, 0.534s/it]: train_loss_raw=0.8083, running_loss=0.8591, LR=0.000100
[2025-08-10 19:34:32,050][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055656] [Batch 00276/03692] [00:02:27/00:30:26, 0.535s/it]: train_loss_raw=0.9334, running_loss=0.8560, LR=0.000100
[2025-08-10 19:34:38,584][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055668] [Batch 00288/03692] [00:02:34/00:30:21, 0.535s/it]: train_loss_raw=0.8497, running_loss=0.8541, LR=0.000100
[2025-08-10 19:34:45,109][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055680] [Batch 00300/03692] [00:02:40/00:30:16, 0.535s/it]: train_loss_raw=0.7927, running_loss=0.8538, LR=0.000100
[2025-08-10 19:34:51,635][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055692] [Batch 00312/03692] [00:02:47/00:30:11, 0.536s/it]: train_loss_raw=0.8834, running_loss=0.8536, LR=0.000100
[2025-08-10 19:34:58,251][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055704] [Batch 00324/03692] [00:02:53/00:30:06, 0.536s/it]: train_loss_raw=0.8635, running_loss=0.8510, LR=0.000100
[2025-08-10 19:35:04,825][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055716] [Batch 00336/03692] [00:03:00/00:30:01, 0.537s/it]: train_loss_raw=0.9171, running_loss=0.8475, LR=0.000100
[2025-08-10 19:35:11,288][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055728] [Batch 00348/03692] [00:03:06/00:29:55, 0.537s/it]: train_loss_raw=0.9225, running_loss=0.8527, LR=0.000100
[2025-08-10 19:35:17,817][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055740] [Batch 00360/03692] [00:03:13/00:29:49, 0.537s/it]: train_loss_raw=0.9253, running_loss=0.8536, LR=0.000100
[2025-08-10 19:35:23,838][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055752] [Batch 00372/03692] [00:03:19/00:29:39, 0.536s/it]: train_loss_raw=0.7835, running_loss=0.8531, LR=0.000100
[2025-08-10 19:35:29,824][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055764] [Batch 00384/03692] [00:03:25/00:29:29, 0.535s/it]: train_loss_raw=0.7988, running_loss=0.8534, LR=0.000100
[2025-08-10 19:35:35,849][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055776] [Batch 00396/03692] [00:03:31/00:29:19, 0.534s/it]: train_loss_raw=0.8910, running_loss=0.8519, LR=0.000100
[2025-08-10 19:35:41,832][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055788] [Batch 00408/03692] [00:03:37/00:29:09, 0.533s/it]: train_loss_raw=0.7982, running_loss=0.8502, LR=0.000100
[2025-08-10 19:35:47,919][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055800] [Batch 00420/03692] [00:03:43/00:29:00, 0.532s/it]: train_loss_raw=0.9512, running_loss=0.8486, LR=0.000100
[2025-08-10 19:35:53,929][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055812] [Batch 00432/03692] [00:03:49/00:28:51, 0.531s/it]: train_loss_raw=0.8081, running_loss=0.8518, LR=0.000100
[2025-08-10 19:36:00,364][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055824] [Batch 00444/03692] [00:03:55/00:28:45, 0.531s/it]: train_loss_raw=0.9213, running_loss=0.8493, LR=0.000100
[2025-08-10 19:36:06,771][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055836] [Batch 00456/03692] [00:04:02/00:28:39, 0.531s/it]: train_loss_raw=0.8912, running_loss=0.8494, LR=0.000100
[2025-08-10 19:36:13,222][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055848] [Batch 00468/03692] [00:04:08/00:28:33, 0.532s/it]: train_loss_raw=0.8074, running_loss=0.8492, LR=0.000100
[2025-08-10 19:36:19,708][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055860] [Batch 00480/03692] [00:04:15/00:28:28, 0.532s/it]: train_loss_raw=0.8486, running_loss=0.8536, LR=0.000100
[2025-08-10 19:36:26,160][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055872] [Batch 00492/03692] [00:04:21/00:28:22, 0.532s/it]: train_loss_raw=0.9398, running_loss=0.8529, LR=0.000100
[2025-08-10 19:36:32,703][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055884] [Batch 00504/03692] [00:04:28/00:28:16, 0.532s/it]: train_loss_raw=0.9034, running_loss=0.8564, LR=0.000100
[2025-08-10 19:36:39,148][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055896] [Batch 00516/03692] [00:04:34/00:28:10, 0.532s/it]: train_loss_raw=0.7936, running_loss=0.8577, LR=0.000100
[2025-08-10 19:36:45,712][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055908] [Batch 00528/03692] [00:04:41/00:28:05, 0.533s/it]: train_loss_raw=0.8991, running_loss=0.8597, LR=0.000100
[2025-08-10 19:36:52,256][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055920] [Batch 00540/03692] [00:04:47/00:27:59, 0.533s/it]: train_loss_raw=0.8057, running_loss=0.8605, LR=0.000100
[2025-08-10 19:36:58,704][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055932] [Batch 00552/03692] [00:04:54/00:27:53, 0.533s/it]: train_loss_raw=0.9320, running_loss=0.8622, LR=0.000100
[2025-08-10 19:37:05,206][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055944] [Batch 00564/03692] [00:05:00/00:27:47, 0.533s/it]: train_loss_raw=0.8859, running_loss=0.8672, LR=0.000100
[2025-08-10 19:37:11,710][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055956] [Batch 00576/03692] [00:05:07/00:27:42, 0.533s/it]: train_loss_raw=0.8640, running_loss=0.8621, LR=0.000100
[2025-08-10 19:37:18,262][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055968] [Batch 00588/03692] [00:05:13/00:27:36, 0.534s/it]: train_loss_raw=0.8566, running_loss=0.8607, LR=0.000100
[2025-08-10 19:37:24,780][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055980] [Batch 00600/03692] [00:05:20/00:27:30, 0.534s/it]: train_loss_raw=0.8146, running_loss=0.8581, LR=0.000100
[2025-08-10 19:37:31,357][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 055992] [Batch 00612/03692] [00:05:26/00:27:25, 0.534s/it]: train_loss_raw=0.8563, running_loss=0.8574, LR=0.000100
[2025-08-10 19:37:42,549][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056004] [Batch 00624/03692] [00:05:38/00:27:42, 0.542s/it]: train_loss_raw=1.0067, running_loss=0.8544, LR=0.000100
[2025-08-10 19:37:48,950][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056016] [Batch 00636/03692] [00:05:44/00:27:35, 0.542s/it]: train_loss_raw=0.7596, running_loss=0.8553, LR=0.000100
[2025-08-10 19:37:55,360][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056028] [Batch 00648/03692] [00:05:50/00:27:28, 0.542s/it]: train_loss_raw=0.8221, running_loss=0.8540, LR=0.000100
[2025-08-10 19:38:01,918][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056040] [Batch 00660/03692] [00:05:57/00:27:22, 0.542s/it]: train_loss_raw=0.8865, running_loss=0.8540, LR=0.000100
[2025-08-10 19:38:08,503][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056052] [Batch 00672/03692] [00:06:04/00:27:16, 0.542s/it]: train_loss_raw=0.8850, running_loss=0.8562, LR=0.000100
[2025-08-10 19:38:14,892][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056064] [Batch 00684/03692] [00:06:10/00:27:09, 0.542s/it]: train_loss_raw=0.8886, running_loss=0.8600, LR=0.000100
[2025-08-10 19:38:21,403][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056076] [Batch 00696/03692] [00:06:16/00:27:02, 0.542s/it]: train_loss_raw=0.8863, running_loss=0.8593, LR=0.000100
[2025-08-10 19:38:27,937][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056088] [Batch 00708/03692] [00:06:23/00:26:56, 0.542s/it]: train_loss_raw=0.8540, running_loss=0.8587, LR=0.000100
[2025-08-10 19:38:34,320][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056100] [Batch 00720/03692] [00:06:29/00:26:49, 0.541s/it]: train_loss_raw=0.8082, running_loss=0.8617, LR=0.000100
[2025-08-10 19:38:40,800][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056112] [Batch 00732/03692] [00:06:36/00:26:42, 0.541s/it]: train_loss_raw=0.8392, running_loss=0.8586, LR=0.000100
[2025-08-10 19:38:47,195][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056124] [Batch 00744/03692] [00:06:42/00:26:35, 0.541s/it]: train_loss_raw=0.8127, running_loss=0.8555, LR=0.000100
[2025-08-10 19:38:53,564][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056136] [Batch 00756/03692] [00:06:49/00:26:28, 0.541s/it]: train_loss_raw=0.8034, running_loss=0.8569, LR=0.000100
[2025-08-10 19:39:00,041][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056148] [Batch 00768/03692] [00:06:55/00:26:22, 0.541s/it]: train_loss_raw=0.7283, running_loss=0.8569, LR=0.000100
[2025-08-10 19:39:06,471][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056160] [Batch 00780/03692] [00:07:02/00:26:15, 0.541s/it]: train_loss_raw=0.7483, running_loss=0.8551, LR=0.000100
[2025-08-10 19:39:12,861][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056172] [Batch 00792/03692] [00:07:08/00:26:08, 0.541s/it]: train_loss_raw=0.7600, running_loss=0.8528, LR=0.000100
[2025-08-10 19:39:19,420][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056184] [Batch 00804/03692] [00:07:14/00:26:02, 0.541s/it]: train_loss_raw=0.8148, running_loss=0.8500, LR=0.000100
[2025-08-10 19:39:26,012][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056196] [Batch 00816/03692] [00:07:21/00:25:56, 0.541s/it]: train_loss_raw=0.9445, running_loss=0.8520, LR=0.000100
[2025-08-10 19:39:32,636][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056208] [Batch 00828/03692] [00:07:28/00:25:50, 0.541s/it]: train_loss_raw=0.8615, running_loss=0.8521, LR=0.000100
[2025-08-10 19:39:39,130][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056220] [Batch 00840/03692] [00:07:34/00:25:43, 0.541s/it]: train_loss_raw=0.8234, running_loss=0.8523, LR=0.000100
[2025-08-10 19:39:45,519][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056232] [Batch 00852/03692] [00:07:41/00:25:36, 0.541s/it]: train_loss_raw=0.7354, running_loss=0.8515, LR=0.000100
[2025-08-10 19:39:51,965][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056244] [Batch 00864/03692] [00:07:47/00:25:30, 0.541s/it]: train_loss_raw=0.7929, running_loss=0.8551, LR=0.000100
[2025-08-10 19:39:58,397][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056256] [Batch 00876/03692] [00:07:53/00:25:23, 0.541s/it]: train_loss_raw=0.9676, running_loss=0.8534, LR=0.000100
[2025-08-10 19:40:04,718][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056268] [Batch 00888/03692] [00:08:00/00:25:16, 0.541s/it]: train_loss_raw=0.8078, running_loss=0.8539, LR=0.000100
[2025-08-10 19:40:10,831][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056280] [Batch 00900/03692] [00:08:06/00:25:08, 0.540s/it]: train_loss_raw=0.8319, running_loss=0.8519, LR=0.000100
[2025-08-10 19:40:17,176][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056292] [Batch 00912/03692] [00:08:12/00:25:01, 0.540s/it]: train_loss_raw=0.8124, running_loss=0.8539, LR=0.000100
[2025-08-10 19:40:23,588][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056304] [Batch 00924/03692] [00:08:19/00:24:55, 0.540s/it]: train_loss_raw=0.9293, running_loss=0.8511, LR=0.000100
[2025-08-10 19:40:29,642][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056316] [Batch 00936/03692] [00:08:25/00:24:47, 0.540s/it]: train_loss_raw=0.8607, running_loss=0.8517, LR=0.000100
[2025-08-10 19:40:35,710][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056328] [Batch 00948/03692] [00:08:31/00:24:39, 0.539s/it]: train_loss_raw=0.7934, running_loss=0.8545, LR=0.000100
[2025-08-10 19:40:41,803][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056340] [Batch 00960/03692] [00:08:37/00:24:32, 0.539s/it]: train_loss_raw=0.8753, running_loss=0.8543, LR=0.000100
[2025-08-10 19:40:47,984][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056352] [Batch 00972/03692] [00:08:43/00:24:25, 0.539s/it]: train_loss_raw=0.9186, running_loss=0.8552, LR=0.000100
[2025-08-10 19:40:54,128][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056364] [Batch 00984/03692] [00:08:49/00:24:17, 0.538s/it]: train_loss_raw=0.9065, running_loss=0.8539, LR=0.000100
[2025-08-10 19:41:00,270][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056376] [Batch 00996/03692] [00:08:55/00:24:10, 0.538s/it]: train_loss_raw=0.9366, running_loss=0.8514, LR=0.000100
[2025-08-10 19:41:06,416][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056388] [Batch 01008/03692] [00:09:01/00:24:03, 0.538s/it]: train_loss_raw=0.7880, running_loss=0.8459, LR=0.000100
[2025-08-10 19:41:12,526][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056400] [Batch 01020/03692] [00:09:08/00:23:55, 0.537s/it]: train_loss_raw=0.7560, running_loss=0.8443, LR=0.000100
[2025-08-10 19:41:18,754][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056412] [Batch 01032/03692] [00:09:14/00:23:48, 0.537s/it]: train_loss_raw=0.8509, running_loss=0.8424, LR=0.000100
[2025-08-10 19:41:25,287][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056424] [Batch 01044/03692] [00:09:20/00:23:42, 0.537s/it]: train_loss_raw=0.7913, running_loss=0.8412, LR=0.000100
[2025-08-10 19:41:31,862][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056436] [Batch 01056/03692] [00:09:27/00:23:36, 0.537s/it]: train_loss_raw=0.8464, running_loss=0.8394, LR=0.000100
[2025-08-10 19:41:38,452][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056448] [Batch 01068/03692] [00:09:33/00:23:30, 0.537s/it]: train_loss_raw=0.8222, running_loss=0.8393, LR=0.000100
[2025-08-10 19:41:44,938][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056460] [Batch 01080/03692] [00:09:40/00:23:23, 0.537s/it]: train_loss_raw=0.7389, running_loss=0.8431, LR=0.000100
[2025-08-10 19:41:51,536][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056472] [Batch 01092/03692] [00:09:47/00:23:17, 0.538s/it]: train_loss_raw=0.8379, running_loss=0.8398, LR=0.000100
[2025-08-10 19:41:58,063][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056484] [Batch 01104/03692] [00:09:53/00:23:11, 0.538s/it]: train_loss_raw=0.8580, running_loss=0.8444, LR=0.000100
[2025-08-10 19:42:04,571][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056496] [Batch 01116/03692] [00:10:00/00:23:05, 0.538s/it]: train_loss_raw=0.9303, running_loss=0.8476, LR=0.000100
[2025-08-10 19:42:11,072][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056508] [Batch 01128/03692] [00:10:06/00:22:58, 0.538s/it]: train_loss_raw=0.7976, running_loss=0.8450, LR=0.000100
[2025-08-10 19:42:17,564][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056520] [Batch 01140/03692] [00:10:13/00:22:52, 0.538s/it]: train_loss_raw=0.9344, running_loss=0.8440, LR=0.000100
[2025-08-10 19:42:24,115][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056532] [Batch 01152/03692] [00:10:19/00:22:46, 0.538s/it]: train_loss_raw=0.8558, running_loss=0.8411, LR=0.000100
[2025-08-10 19:42:30,485][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056544] [Batch 01164/03692] [00:10:26/00:22:39, 0.538s/it]: train_loss_raw=0.9215, running_loss=0.8360, LR=0.000100
[2025-08-10 19:42:36,944][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056556] [Batch 01176/03692] [00:10:32/00:22:33, 0.538s/it]: train_loss_raw=0.7857, running_loss=0.8320, LR=0.000100
[2025-08-10 19:42:43,001][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056568] [Batch 01188/03692] [00:10:38/00:22:25, 0.537s/it]: train_loss_raw=0.8882, running_loss=0.8356, LR=0.000100
[2025-08-10 19:42:49,116][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056580] [Batch 01200/03692] [00:10:44/00:22:18, 0.537s/it]: train_loss_raw=0.8997, running_loss=0.8404, LR=0.000100
[2025-08-10 19:42:55,299][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056592] [Batch 01212/03692] [00:10:50/00:22:11, 0.537s/it]: train_loss_raw=0.6467, running_loss=0.8363, LR=0.000100
[2025-08-10 19:43:01,363][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056604] [Batch 01224/03692] [00:10:56/00:22:04, 0.537s/it]: train_loss_raw=0.8776, running_loss=0.8377, LR=0.000100
[2025-08-10 19:43:07,401][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056616] [Batch 01236/03692] [00:11:02/00:21:57, 0.536s/it]: train_loss_raw=0.7979, running_loss=0.8374, LR=0.000100
[2025-08-10 19:43:13,814][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056628] [Batch 01248/03692] [00:11:09/00:21:50, 0.536s/it]: train_loss_raw=0.8636, running_loss=0.8376, LR=0.000100
[2025-08-10 19:43:20,259][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056640] [Batch 01260/03692] [00:11:15/00:21:44, 0.536s/it]: train_loss_raw=0.7634, running_loss=0.8357, LR=0.000100
[2025-08-10 19:43:26,301][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056652] [Batch 01272/03692] [00:11:21/00:21:37, 0.536s/it]: train_loss_raw=0.9125, running_loss=0.8401, LR=0.000100
[2025-08-10 19:43:32,352][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056664] [Batch 01284/03692] [00:11:27/00:21:30, 0.536s/it]: train_loss_raw=0.7396, running_loss=0.8378, LR=0.000100
[2025-08-10 19:43:38,431][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056676] [Batch 01296/03692] [00:11:33/00:21:22, 0.535s/it]: train_loss_raw=0.7120, running_loss=0.8357, LR=0.000100
[2025-08-10 19:43:44,501][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056688] [Batch 01308/03692] [00:11:40/00:21:15, 0.535s/it]: train_loss_raw=0.9055, running_loss=0.8353, LR=0.000100
[2025-08-10 19:43:50,579][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056700] [Batch 01320/03692] [00:11:46/00:21:08, 0.535s/it]: train_loss_raw=0.7885, running_loss=0.8354, LR=0.000100
[2025-08-10 19:43:56,838][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056712] [Batch 01332/03692] [00:11:52/00:21:02, 0.535s/it]: train_loss_raw=0.7785, running_loss=0.8352, LR=0.000100
[2025-08-10 19:44:03,123][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056724] [Batch 01344/03692] [00:11:58/00:20:55, 0.535s/it]: train_loss_raw=0.8202, running_loss=0.8327, LR=0.000100
[2025-08-10 19:44:09,311][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056736] [Batch 01356/03692] [00:12:04/00:20:48, 0.535s/it]: train_loss_raw=0.8299, running_loss=0.8356, LR=0.000100
[2025-08-10 19:44:15,424][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056748] [Batch 01368/03692] [00:12:10/00:20:41, 0.534s/it]: train_loss_raw=0.9067, running_loss=0.8387, LR=0.000100
[2025-08-10 19:44:21,485][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056760] [Batch 01380/03692] [00:12:17/00:20:34, 0.534s/it]: train_loss_raw=1.0221, running_loss=0.8349, LR=0.000100
[2025-08-10 19:44:27,841][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056772] [Batch 01392/03692] [00:12:23/00:20:28, 0.534s/it]: train_loss_raw=0.8973, running_loss=0.8365, LR=0.000100
[2025-08-10 19:44:34,322][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056784] [Batch 01404/03692] [00:12:29/00:20:21, 0.534s/it]: train_loss_raw=0.7769, running_loss=0.8384, LR=0.000100
[2025-08-10 19:44:40,863][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056796] [Batch 01416/03692] [00:12:36/00:20:15, 0.534s/it]: train_loss_raw=0.8733, running_loss=0.8388, LR=0.000100
[2025-08-10 19:44:47,370][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056808] [Batch 01428/03692] [00:12:42/00:20:09, 0.534s/it]: train_loss_raw=0.8296, running_loss=0.8379, LR=0.000100
[2025-08-10 19:44:53,588][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056820] [Batch 01440/03692] [00:12:49/00:20:02, 0.534s/it]: train_loss_raw=0.8365, running_loss=0.8341, LR=0.000100
[2025-08-10 19:45:00,153][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056832] [Batch 01452/03692] [00:12:55/00:19:56, 0.534s/it]: train_loss_raw=0.8277, running_loss=0.8292, LR=0.000100
[2025-08-10 19:45:06,666][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056844] [Batch 01464/03692] [00:13:02/00:19:50, 0.534s/it]: train_loss_raw=0.8206, running_loss=0.8332, LR=0.000100
[2025-08-10 19:45:13,076][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056856] [Batch 01476/03692] [00:13:08/00:19:43, 0.534s/it]: train_loss_raw=0.8339, running_loss=0.8340, LR=0.000100
[2025-08-10 19:45:19,128][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056868] [Batch 01488/03692] [00:13:14/00:19:37, 0.534s/it]: train_loss_raw=0.8684, running_loss=0.8335, LR=0.000100
[2025-08-10 19:45:25,148][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056880] [Batch 01500/03692] [00:13:20/00:19:30, 0.534s/it]: train_loss_raw=0.7830, running_loss=0.8320, LR=0.000100
[2025-08-10 19:45:31,207][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056892] [Batch 01512/03692] [00:13:26/00:19:23, 0.534s/it]: train_loss_raw=0.9782, running_loss=0.8358, LR=0.000100
[2025-08-10 19:45:37,449][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056904] [Batch 01524/03692] [00:13:32/00:19:16, 0.533s/it]: train_loss_raw=0.9620, running_loss=0.8337, LR=0.000100
[2025-08-10 19:45:43,927][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056916] [Batch 01536/03692] [00:13:39/00:19:10, 0.534s/it]: train_loss_raw=0.8608, running_loss=0.8358, LR=0.000100
[2025-08-10 19:45:50,026][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056928] [Batch 01548/03692] [00:13:45/00:19:03, 0.533s/it]: train_loss_raw=0.8562, running_loss=0.8358, LR=0.000100
[2025-08-10 19:45:56,066][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056940] [Batch 01560/03692] [00:13:51/00:18:56, 0.533s/it]: train_loss_raw=0.7347, running_loss=0.8417, LR=0.000100
[2025-08-10 19:46:02,121][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056952] [Batch 01572/03692] [00:13:57/00:18:49, 0.533s/it]: train_loss_raw=0.7558, running_loss=0.8421, LR=0.000100
[2025-08-10 19:46:08,299][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056964] [Batch 01584/03692] [00:14:03/00:18:42, 0.533s/it]: train_loss_raw=0.8277, running_loss=0.8457, LR=0.000100
[2025-08-10 19:46:14,374][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056976] [Batch 01596/03692] [00:14:09/00:18:36, 0.533s/it]: train_loss_raw=0.8496, running_loss=0.8433, LR=0.000100
[2025-08-10 19:46:20,828][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 056988] [Batch 01608/03692] [00:14:16/00:18:29, 0.533s/it]: train_loss_raw=0.8772, running_loss=0.8377, LR=0.000100
[2025-08-10 19:46:27,033][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057000] [Batch 01620/03692] [00:14:22/00:18:23, 0.532s/it]: train_loss_raw=0.9143, running_loss=0.8376, LR=0.000100
[2025-08-10 19:46:33,335][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057012] [Batch 01632/03692] [00:14:28/00:18:16, 0.532s/it]: train_loss_raw=0.8365, running_loss=0.8372, LR=0.000100
[2025-08-10 19:46:39,886][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057024] [Batch 01644/03692] [00:14:35/00:18:10, 0.532s/it]: train_loss_raw=0.8815, running_loss=0.8367, LR=0.000100
[2025-08-10 19:46:46,480][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057036] [Batch 01656/03692] [00:14:42/00:18:04, 0.533s/it]: train_loss_raw=0.8029, running_loss=0.8376, LR=0.000100
[2025-08-10 19:46:52,969][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057048] [Batch 01668/03692] [00:14:48/00:17:58, 0.533s/it]: train_loss_raw=0.9394, running_loss=0.8369, LR=0.000100
[2025-08-10 19:46:59,402][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057060] [Batch 01680/03692] [00:14:54/00:17:51, 0.533s/it]: train_loss_raw=0.8636, running_loss=0.8390, LR=0.000100
[2025-08-10 19:47:05,712][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057072] [Batch 01692/03692] [00:15:01/00:17:45, 0.533s/it]: train_loss_raw=0.9597, running_loss=0.8358, LR=0.000100
[2025-08-10 19:47:12,232][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057084] [Batch 01704/03692] [00:15:07/00:17:39, 0.533s/it]: train_loss_raw=0.8699, running_loss=0.8381, LR=0.000100
[2025-08-10 19:47:18,549][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057096] [Batch 01716/03692] [00:15:14/00:17:32, 0.533s/it]: train_loss_raw=0.8129, running_loss=0.8374, LR=0.000100
[2025-08-10 19:47:24,953][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057108] [Batch 01728/03692] [00:15:20/00:17:26, 0.533s/it]: train_loss_raw=0.8975, running_loss=0.8361, LR=0.000100
[2025-08-10 19:47:31,497][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057120] [Batch 01740/03692] [00:15:27/00:17:19, 0.533s/it]: train_loss_raw=0.8388, running_loss=0.8359, LR=0.000100
[2025-08-10 19:47:37,981][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057132] [Batch 01752/03692] [00:15:33/00:17:13, 0.533s/it]: train_loss_raw=0.8177, running_loss=0.8327, LR=0.000100
[2025-08-10 19:47:44,485][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057144] [Batch 01764/03692] [00:15:40/00:17:07, 0.533s/it]: train_loss_raw=0.8366, running_loss=0.8342, LR=0.000100
[2025-08-10 19:47:51,007][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057156] [Batch 01776/03692] [00:15:46/00:17:01, 0.533s/it]: train_loss_raw=0.7690, running_loss=0.8368, LR=0.000100
[2025-08-10 19:47:57,483][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057168] [Batch 01788/03692] [00:15:53/00:16:54, 0.533s/it]: train_loss_raw=0.7811, running_loss=0.8351, LR=0.000100
[2025-08-10 19:48:04,015][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057180] [Batch 01800/03692] [00:15:59/00:16:48, 0.533s/it]: train_loss_raw=0.8160, running_loss=0.8373, LR=0.000100
[2025-08-10 19:48:10,540][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057192] [Batch 01812/03692] [00:16:06/00:16:42, 0.533s/it]: train_loss_raw=0.9681, running_loss=0.8353, LR=0.000100
[2025-08-10 19:48:17,118][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057204] [Batch 01824/03692] [00:16:12/00:16:36, 0.533s/it]: train_loss_raw=0.8193, running_loss=0.8305, LR=0.000100
[2025-08-10 19:48:23,406][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057216] [Batch 01836/03692] [00:16:18/00:16:29, 0.533s/it]: train_loss_raw=0.8749, running_loss=0.8308, LR=0.000100
[2025-08-10 19:48:29,877][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057228] [Batch 01848/03692] [00:16:25/00:16:23, 0.533s/it]: train_loss_raw=0.9146, running_loss=0.8320, LR=0.000100
[2025-08-10 19:48:36,139][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057240] [Batch 01860/03692] [00:16:31/00:16:16, 0.533s/it]: train_loss_raw=0.8331, running_loss=0.8329, LR=0.000100
[2025-08-10 19:48:42,192][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057252] [Batch 01872/03692] [00:16:37/00:16:10, 0.533s/it]: train_loss_raw=0.7955, running_loss=0.8336, LR=0.000100
[2025-08-10 19:48:48,241][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057264] [Batch 01884/03692] [00:16:43/00:16:03, 0.533s/it]: train_loss_raw=0.8342, running_loss=0.8308, LR=0.000100
[2025-08-10 19:48:54,678][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057276] [Batch 01896/03692] [00:16:50/00:15:56, 0.533s/it]: train_loss_raw=0.7907, running_loss=0.8292, LR=0.000100
[2025-08-10 19:49:01,280][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057288] [Batch 01908/03692] [00:16:56/00:15:50, 0.533s/it]: train_loss_raw=0.8956, running_loss=0.8292, LR=0.000100
[2025-08-10 19:49:07,545][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057300] [Batch 01920/03692] [00:17:03/00:15:44, 0.533s/it]: train_loss_raw=0.8469, running_loss=0.8325, LR=0.000100
[2025-08-10 19:49:14,063][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057312] [Batch 01932/03692] [00:17:09/00:15:37, 0.533s/it]: train_loss_raw=0.8086, running_loss=0.8306, LR=0.000100
[2025-08-10 19:49:20,620][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057324] [Batch 01944/03692] [00:17:16/00:15:31, 0.533s/it]: train_loss_raw=0.7786, running_loss=0.8290, LR=0.000100
[2025-08-10 19:49:27,219][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057336] [Batch 01956/03692] [00:17:22/00:15:25, 0.533s/it]: train_loss_raw=0.8817, running_loss=0.8297, LR=0.000100
[2025-08-10 19:49:33,267][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057348] [Batch 01968/03692] [00:17:28/00:15:18, 0.533s/it]: train_loss_raw=0.8359, running_loss=0.8295, LR=0.000100
[2025-08-10 19:49:39,340][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057360] [Batch 01980/03692] [00:17:34/00:15:12, 0.533s/it]: train_loss_raw=0.8538, running_loss=0.8265, LR=0.000100
[2025-08-10 19:49:45,375][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057372] [Batch 01992/03692] [00:17:40/00:15:05, 0.533s/it]: train_loss_raw=0.7707, running_loss=0.8242, LR=0.000100
[2025-08-10 19:49:51,347][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057384] [Batch 02004/03692] [00:17:46/00:14:58, 0.532s/it]: train_loss_raw=0.8071, running_loss=0.8248, LR=0.000100
[2025-08-10 19:49:57,424][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057396] [Batch 02016/03692] [00:17:52/00:14:52, 0.532s/it]: train_loss_raw=0.7474, running_loss=0.8232, LR=0.000100
[2025-08-10 19:50:03,674][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057408] [Batch 02028/03692] [00:17:59/00:14:45, 0.532s/it]: train_loss_raw=0.8062, running_loss=0.8193, LR=0.000100
[2025-08-10 19:50:10,246][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057420] [Batch 02040/03692] [00:18:05/00:14:39, 0.532s/it]: train_loss_raw=0.9026, running_loss=0.8196, LR=0.000100
[2025-08-10 19:50:16,743][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057432] [Batch 02052/03692] [00:18:12/00:14:32, 0.532s/it]: train_loss_raw=0.9657, running_loss=0.8201, LR=0.000100
[2025-08-10 19:50:23,447][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057444] [Batch 02064/03692] [00:18:18/00:14:26, 0.532s/it]: train_loss_raw=0.7768, running_loss=0.8201, LR=0.000100
[2025-08-10 19:50:30,036][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057456] [Batch 02076/03692] [00:18:25/00:14:20, 0.533s/it]: train_loss_raw=0.7080, running_loss=0.8164, LR=0.000100
[2025-08-10 19:50:36,497][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057468] [Batch 02088/03692] [00:18:32/00:14:14, 0.533s/it]: train_loss_raw=0.8554, running_loss=0.8156, LR=0.000100
[2025-08-10 19:50:42,491][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057480] [Batch 02100/03692] [00:18:38/00:14:07, 0.532s/it]: train_loss_raw=0.8603, running_loss=0.8172, LR=0.000100
[2025-08-10 19:50:48,577][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057492] [Batch 02112/03692] [00:18:44/00:14:00, 0.532s/it]: train_loss_raw=0.8933, running_loss=0.8219, LR=0.000100
[2025-08-10 19:50:54,685][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057504] [Batch 02124/03692] [00:18:50/00:13:54, 0.532s/it]: train_loss_raw=0.7937, running_loss=0.8203, LR=0.000100
[2025-08-10 19:51:01,196][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057516] [Batch 02136/03692] [00:18:56/00:13:48, 0.532s/it]: train_loss_raw=0.8556, running_loss=0.8245, LR=0.000100
[2025-08-10 19:51:07,615][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057528] [Batch 02148/03692] [00:19:03/00:13:41, 0.532s/it]: train_loss_raw=0.6959, running_loss=0.8238, LR=0.000100
[2025-08-10 19:51:20,632][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057540] [Batch 02160/03692] [00:19:16/00:13:40, 0.535s/it]: train_loss_raw=0.7407, running_loss=0.8227, LR=0.000100
[2025-08-10 19:51:26,706][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057552] [Batch 02172/03692] [00:19:22/00:13:33, 0.535s/it]: train_loss_raw=0.8922, running_loss=0.8228, LR=0.000100
[2025-08-10 19:51:33,135][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057564] [Batch 02184/03692] [00:19:28/00:13:26, 0.535s/it]: train_loss_raw=0.8418, running_loss=0.8188, LR=0.000100
[2025-08-10 19:51:39,707][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057576] [Batch 02196/03692] [00:19:35/00:13:20, 0.535s/it]: train_loss_raw=0.8758, running_loss=0.8198, LR=0.000100
[2025-08-10 19:51:46,235][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057588] [Batch 02208/03692] [00:19:41/00:13:14, 0.535s/it]: train_loss_raw=0.6961, running_loss=0.8145, LR=0.000100
[2025-08-10 19:51:52,358][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057600] [Batch 02220/03692] [00:19:47/00:13:07, 0.535s/it]: train_loss_raw=0.7030, running_loss=0.8170, LR=0.000100
[2025-08-10 19:51:58,464][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057612] [Batch 02232/03692] [00:19:54/00:13:01, 0.535s/it]: train_loss_raw=0.8523, running_loss=0.8177, LR=0.000100
[2025-08-10 19:52:04,470][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057624] [Batch 02244/03692] [00:20:00/00:12:54, 0.535s/it]: train_loss_raw=0.8419, running_loss=0.8209, LR=0.000100
[2025-08-10 19:52:10,506][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057636] [Batch 02256/03692] [00:20:06/00:12:47, 0.535s/it]: train_loss_raw=0.8523, running_loss=0.8195, LR=0.000100
[2025-08-10 19:52:16,610][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057648] [Batch 02268/03692] [00:20:12/00:12:41, 0.534s/it]: train_loss_raw=0.7487, running_loss=0.8198, LR=0.000100
[2025-08-10 19:52:22,862][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057660] [Batch 02280/03692] [00:20:18/00:12:34, 0.534s/it]: train_loss_raw=0.7719, running_loss=0.8187, LR=0.000100
[2025-08-10 19:52:28,919][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057672] [Batch 02292/03692] [00:20:24/00:12:27, 0.534s/it]: train_loss_raw=0.9653, running_loss=0.8214, LR=0.000100
[2025-08-10 19:52:35,120][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057684] [Batch 02304/03692] [00:20:30/00:12:21, 0.534s/it]: train_loss_raw=0.7716, running_loss=0.8210, LR=0.000100
[2025-08-10 19:52:41,416][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057696] [Batch 02316/03692] [00:20:36/00:12:14, 0.534s/it]: train_loss_raw=0.8382, running_loss=0.8207, LR=0.000100
[2025-08-10 19:52:47,593][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057708] [Batch 02328/03692] [00:20:43/00:12:08, 0.534s/it]: train_loss_raw=0.7798, running_loss=0.8191, LR=0.000100
[2025-08-10 19:52:53,788][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057720] [Batch 02340/03692] [00:20:49/00:12:01, 0.534s/it]: train_loss_raw=0.9561, running_loss=0.8237, LR=0.000100
[2025-08-10 19:52:59,860][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057732] [Batch 02352/03692] [00:20:55/00:11:55, 0.534s/it]: train_loss_raw=0.7172, running_loss=0.8194, LR=0.000100
[2025-08-10 19:53:05,942][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057744] [Batch 02364/03692] [00:21:01/00:11:48, 0.534s/it]: train_loss_raw=0.8034, running_loss=0.8197, LR=0.000100
[2025-08-10 19:53:11,957][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057756] [Batch 02376/03692] [00:21:07/00:11:42, 0.533s/it]: train_loss_raw=0.8699, running_loss=0.8207, LR=0.000100
[2025-08-10 19:53:18,066][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057768] [Batch 02388/03692] [00:21:13/00:11:35, 0.533s/it]: train_loss_raw=0.8136, running_loss=0.8230, LR=0.000100
[2025-08-10 19:53:24,106][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057780] [Batch 02400/03692] [00:21:19/00:11:28, 0.533s/it]: train_loss_raw=0.8717, running_loss=0.8188, LR=0.000100
[2025-08-10 19:53:30,182][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057792] [Batch 02412/03692] [00:21:25/00:11:22, 0.533s/it]: train_loss_raw=0.8208, running_loss=0.8197, LR=0.000100
[2025-08-10 19:53:36,416][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057804] [Batch 02424/03692] [00:21:31/00:11:15, 0.533s/it]: train_loss_raw=0.9135, running_loss=0.8212, LR=0.000100
[2025-08-10 19:53:42,401][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057816] [Batch 02436/03692] [00:21:37/00:11:09, 0.533s/it]: train_loss_raw=0.8378, running_loss=0.8215, LR=0.000100
[2025-08-10 19:53:48,432][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057828] [Batch 02448/03692] [00:21:43/00:11:02, 0.533s/it]: train_loss_raw=0.7325, running_loss=0.8192, LR=0.000100
[2025-08-10 19:53:54,599][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057840] [Batch 02460/03692] [00:21:50/00:10:56, 0.533s/it]: train_loss_raw=0.8231, running_loss=0.8192, LR=0.000100
[2025-08-10 19:54:01,060][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057852] [Batch 02472/03692] [00:21:56/00:10:49, 0.533s/it]: train_loss_raw=0.8385, running_loss=0.8181, LR=0.000100
[2025-08-10 19:54:07,678][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057864] [Batch 02484/03692] [00:22:03/00:10:43, 0.533s/it]: train_loss_raw=0.8217, running_loss=0.8217, LR=0.000100
[2025-08-10 19:54:14,281][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057876] [Batch 02496/03692] [00:22:09/00:10:37, 0.533s/it]: train_loss_raw=0.8561, running_loss=0.8207, LR=0.000100
[2025-08-10 19:54:20,703][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057888] [Batch 02508/03692] [00:22:16/00:10:30, 0.533s/it]: train_loss_raw=0.8181, running_loss=0.8168, LR=0.000100
[2025-08-10 19:54:26,916][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057900] [Batch 02520/03692] [00:22:22/00:10:24, 0.533s/it]: train_loss_raw=0.8869, running_loss=0.8174, LR=0.000100
[2025-08-10 19:54:33,182][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057912] [Batch 02532/03692] [00:22:28/00:10:17, 0.533s/it]: train_loss_raw=0.9292, running_loss=0.8207, LR=0.000100
[2025-08-10 19:54:39,366][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057924] [Batch 02544/03692] [00:22:34/00:10:11, 0.533s/it]: train_loss_raw=0.7843, running_loss=0.8167, LR=0.000100
[2025-08-10 19:54:45,838][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057936] [Batch 02556/03692] [00:22:41/00:10:05, 0.533s/it]: train_loss_raw=0.8103, running_loss=0.8164, LR=0.000100
[2025-08-10 19:54:52,375][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057948] [Batch 02568/03692] [00:22:47/00:09:58, 0.533s/it]: train_loss_raw=0.7747, running_loss=0.8140, LR=0.000100
[2025-08-10 19:54:58,929][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057960] [Batch 02580/03692] [00:22:54/00:09:52, 0.533s/it]: train_loss_raw=0.7831, running_loss=0.8149, LR=0.000100
[2025-08-10 19:55:05,429][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057972] [Batch 02592/03692] [00:23:00/00:09:46, 0.533s/it]: train_loss_raw=0.8641, running_loss=0.8163, LR=0.000100
[2025-08-10 19:55:11,894][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057984] [Batch 02604/03692] [00:23:07/00:09:39, 0.533s/it]: train_loss_raw=1.0116, running_loss=0.8216, LR=0.000100
[2025-08-10 19:55:18,386][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 057996] [Batch 02616/03692] [00:23:13/00:09:33, 0.533s/it]: train_loss_raw=0.7557, running_loss=0.8188, LR=0.000100
[2025-08-10 19:55:30,276][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058008] [Batch 02628/03692] [00:23:25/00:09:29, 0.535s/it]: train_loss_raw=0.8040, running_loss=0.8210, LR=0.000100
[2025-08-10 19:55:36,832][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058020] [Batch 02640/03692] [00:23:32/00:09:22, 0.535s/it]: train_loss_raw=0.8060, running_loss=0.8165, LR=0.000100
[2025-08-10 19:55:43,421][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058032] [Batch 02652/03692] [00:23:38/00:09:16, 0.535s/it]: train_loss_raw=0.7787, running_loss=0.8174, LR=0.000100
[2025-08-10 19:55:49,967][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058044] [Batch 02664/03692] [00:23:45/00:09:10, 0.535s/it]: train_loss_raw=0.9274, running_loss=0.8163, LR=0.000100
[2025-08-10 19:55:56,570][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058056] [Batch 02676/03692] [00:23:52/00:09:03, 0.535s/it]: train_loss_raw=0.7766, running_loss=0.8150, LR=0.000100
[2025-08-10 19:56:03,061][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058068] [Batch 02688/03692] [00:23:58/00:08:57, 0.535s/it]: train_loss_raw=0.9009, running_loss=0.8148, LR=0.000100
[2025-08-10 19:56:09,591][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058080] [Batch 02700/03692] [00:24:05/00:08:50, 0.535s/it]: train_loss_raw=0.7568, running_loss=0.8134, LR=0.000100
[2025-08-10 19:56:16,192][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058092] [Batch 02712/03692] [00:24:11/00:08:44, 0.535s/it]: train_loss_raw=0.7700, running_loss=0.8098, LR=0.000100
[2025-08-10 19:56:22,769][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058104] [Batch 02724/03692] [00:24:18/00:08:38, 0.535s/it]: train_loss_raw=0.7452, running_loss=0.8123, LR=0.000100
[2025-08-10 19:56:29,180][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058116] [Batch 02736/03692] [00:24:24/00:08:31, 0.535s/it]: train_loss_raw=0.8257, running_loss=0.8145, LR=0.000100
[2025-08-10 19:56:35,772][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058128] [Batch 02748/03692] [00:24:31/00:08:25, 0.535s/it]: train_loss_raw=0.7729, running_loss=0.8177, LR=0.000100
[2025-08-10 19:56:42,267][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058140] [Batch 02760/03692] [00:24:37/00:08:19, 0.535s/it]: train_loss_raw=0.7716, running_loss=0.8193, LR=0.000100
[2025-08-10 19:56:48,648][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058152] [Batch 02772/03692] [00:24:44/00:08:12, 0.535s/it]: train_loss_raw=0.8409, running_loss=0.8189, LR=0.000100
[2025-08-10 19:56:54,718][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058164] [Batch 02784/03692] [00:24:50/00:08:06, 0.535s/it]: train_loss_raw=0.8414, running_loss=0.8145, LR=0.000100
[2025-08-10 19:57:00,794][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058176] [Batch 02796/03692] [00:24:56/00:07:59, 0.535s/it]: train_loss_raw=0.6307, running_loss=0.8113, LR=0.000100
[2025-08-10 19:57:06,919][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058188] [Batch 02808/03692] [00:25:02/00:07:52, 0.535s/it]: train_loss_raw=0.9201, running_loss=0.8092, LR=0.000100
[2025-08-10 19:57:13,265][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058200] [Batch 02820/03692] [00:25:08/00:07:46, 0.535s/it]: train_loss_raw=0.8094, running_loss=0.8076, LR=0.000100
[2025-08-10 19:57:19,432][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058212] [Batch 02832/03692] [00:25:14/00:07:40, 0.535s/it]: train_loss_raw=0.6914, running_loss=0.8044, LR=0.000100
[2025-08-10 19:57:25,598][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058224] [Batch 02844/03692] [00:25:21/00:07:33, 0.535s/it]: train_loss_raw=0.7928, running_loss=0.8083, LR=0.000100
[2025-08-10 19:57:31,611][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058236] [Batch 02856/03692] [00:25:27/00:07:27, 0.535s/it]: train_loss_raw=0.7155, running_loss=0.8067, LR=0.000100
[2025-08-10 19:57:37,676][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058248] [Batch 02868/03692] [00:25:33/00:07:20, 0.535s/it]: train_loss_raw=0.8976, running_loss=0.8085, LR=0.000100
[2025-08-10 19:57:43,967][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058260] [Batch 02880/03692] [00:25:39/00:07:14, 0.535s/it]: train_loss_raw=0.7695, running_loss=0.8073, LR=0.000100
[2025-08-10 19:57:50,436][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058272] [Batch 02892/03692] [00:25:45/00:07:07, 0.535s/it]: train_loss_raw=0.7123, running_loss=0.8029, LR=0.000100
[2025-08-10 19:57:56,918][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058284] [Batch 02904/03692] [00:25:52/00:07:01, 0.535s/it]: train_loss_raw=0.8266, running_loss=0.8026, LR=0.000100
[2025-08-10 19:58:03,502][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058296] [Batch 02916/03692] [00:25:59/00:06:54, 0.535s/it]: train_loss_raw=0.9307, running_loss=0.8062, LR=0.000100
[2025-08-10 19:58:10,064][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058308] [Batch 02928/03692] [00:26:05/00:06:48, 0.535s/it]: train_loss_raw=0.7892, running_loss=0.8062, LR=0.000100
[2025-08-10 19:58:16,579][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058320] [Batch 02940/03692] [00:26:12/00:06:42, 0.535s/it]: train_loss_raw=0.8768, running_loss=0.8081, LR=0.000100
[2025-08-10 19:58:23,139][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058332] [Batch 02952/03692] [00:26:18/00:06:35, 0.535s/it]: train_loss_raw=0.9015, running_loss=0.8095, LR=0.000100
[2025-08-10 19:58:29,504][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058344] [Batch 02964/03692] [00:26:25/00:06:29, 0.535s/it]: train_loss_raw=0.7726, running_loss=0.8048, LR=0.000100
[2025-08-10 19:58:35,515][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058356] [Batch 02976/03692] [00:26:31/00:06:22, 0.535s/it]: train_loss_raw=0.7791, running_loss=0.8046, LR=0.000100
[2025-08-10 19:58:41,551][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058368] [Batch 02988/03692] [00:26:37/00:06:16, 0.535s/it]: train_loss_raw=0.8448, running_loss=0.8060, LR=0.000100
[2025-08-10 19:58:47,938][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058380] [Batch 03000/03692] [00:26:43/00:06:09, 0.534s/it]: train_loss_raw=0.9107, running_loss=0.8068, LR=0.000100
[2025-08-10 19:58:54,490][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058392] [Batch 03012/03692] [00:26:50/00:06:03, 0.535s/it]: train_loss_raw=0.8958, running_loss=0.8054, LR=0.000100
[2025-08-10 19:59:00,966][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058404] [Batch 03024/03692] [00:26:56/00:05:57, 0.535s/it]: train_loss_raw=0.7541, running_loss=0.8044, LR=0.000100
[2025-08-10 19:59:07,393][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058416] [Batch 03036/03692] [00:27:02/00:05:50, 0.535s/it]: train_loss_raw=0.9188, running_loss=0.8029, LR=0.000100
[2025-08-10 19:59:13,947][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058428] [Batch 03048/03692] [00:27:09/00:05:44, 0.535s/it]: train_loss_raw=0.7759, running_loss=0.8004, LR=0.000100
[2025-08-10 19:59:20,053][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058440] [Batch 03060/03692] [00:27:15/00:05:37, 0.535s/it]: train_loss_raw=0.8357, running_loss=0.7993, LR=0.000100
[2025-08-10 19:59:26,159][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058452] [Batch 03072/03692] [00:27:21/00:05:31, 0.534s/it]: train_loss_raw=0.8248, running_loss=0.7978, LR=0.000100
[2025-08-10 19:59:32,375][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058464] [Batch 03084/03692] [00:27:27/00:05:24, 0.534s/it]: train_loss_raw=0.7325, running_loss=0.7980, LR=0.000100
[2025-08-10 19:59:38,957][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058476] [Batch 03096/03692] [00:27:34/00:05:18, 0.534s/it]: train_loss_raw=0.8046, running_loss=0.7971, LR=0.000100
[2025-08-10 19:59:45,535][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058488] [Batch 03108/03692] [00:27:41/00:05:12, 0.534s/it]: train_loss_raw=0.8451, running_loss=0.7978, LR=0.000100
[2025-08-10 19:59:51,755][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058500] [Batch 03120/03692] [00:27:47/00:05:05, 0.534s/it]: train_loss_raw=0.9175, running_loss=0.8024, LR=0.000100
[2025-08-10 19:59:58,303][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058512] [Batch 03132/03692] [00:27:53/00:04:59, 0.534s/it]: train_loss_raw=0.8612, running_loss=0.8060, LR=0.000100
[2025-08-10 20:00:04,850][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058524] [Batch 03144/03692] [00:28:00/00:04:52, 0.534s/it]: train_loss_raw=0.8335, running_loss=0.8096, LR=0.000100
[2025-08-10 20:00:11,459][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058536] [Batch 03156/03692] [00:28:06/00:04:46, 0.535s/it]: train_loss_raw=0.8503, running_loss=0.8109, LR=0.000100
[2025-08-10 20:00:18,008][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058548] [Batch 03168/03692] [00:28:13/00:04:40, 0.535s/it]: train_loss_raw=0.7648, running_loss=0.8132, LR=0.000100
[2025-08-10 20:00:24,551][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058560] [Batch 03180/03692] [00:28:20/00:04:33, 0.535s/it]: train_loss_raw=0.6799, running_loss=0.8080, LR=0.000100
[2025-08-10 20:00:30,929][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058572] [Batch 03192/03692] [00:28:26/00:04:27, 0.535s/it]: train_loss_raw=0.9429, running_loss=0.8093, LR=0.000100
[2025-08-10 20:00:37,418][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058584] [Batch 03204/03692] [00:28:32/00:04:20, 0.535s/it]: train_loss_raw=0.7095, running_loss=0.8078, LR=0.000100
[2025-08-10 20:00:43,427][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058596] [Batch 03216/03692] [00:28:38/00:04:14, 0.535s/it]: train_loss_raw=0.7505, running_loss=0.8071, LR=0.000100
[2025-08-10 20:00:49,526][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058608] [Batch 03228/03692] [00:28:45/00:04:07, 0.534s/it]: train_loss_raw=0.7058, running_loss=0.8088, LR=0.000100
[2025-08-10 20:00:55,616][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058620] [Batch 03240/03692] [00:28:51/00:04:01, 0.534s/it]: train_loss_raw=0.8868, running_loss=0.8094, LR=0.000100
[2025-08-10 20:01:02,008][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058632] [Batch 03252/03692] [00:28:57/00:03:55, 0.534s/it]: train_loss_raw=0.8020, running_loss=0.8083, LR=0.000100
[2025-08-10 20:01:08,546][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058644] [Batch 03264/03692] [00:29:04/00:03:48, 0.534s/it]: train_loss_raw=0.6940, running_loss=0.8046, LR=0.000100
[2025-08-10 20:01:15,207][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058656] [Batch 03276/03692] [00:29:10/00:03:42, 0.534s/it]: train_loss_raw=0.7228, running_loss=0.8005, LR=0.000100
[2025-08-10 20:01:21,852][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058668] [Batch 03288/03692] [00:29:17/00:03:35, 0.534s/it]: train_loss_raw=0.8288, running_loss=0.7973, LR=0.000100
[2025-08-10 20:01:28,391][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058680] [Batch 03300/03692] [00:29:23/00:03:29, 0.535s/it]: train_loss_raw=0.8438, running_loss=0.7977, LR=0.000100
[2025-08-10 20:01:34,940][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058692] [Batch 03312/03692] [00:29:30/00:03:23, 0.535s/it]: train_loss_raw=0.7911, running_loss=0.7991, LR=0.000100
[2025-08-10 20:01:41,337][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058704] [Batch 03324/03692] [00:29:36/00:03:16, 0.535s/it]: train_loss_raw=0.8464, running_loss=0.8017, LR=0.000100
[2025-08-10 20:01:47,728][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058716] [Batch 03336/03692] [00:29:43/00:03:10, 0.535s/it]: train_loss_raw=0.7773, running_loss=0.8016, LR=0.000100
[2025-08-10 20:01:54,194][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058728] [Batch 03348/03692] [00:29:49/00:03:03, 0.535s/it]: train_loss_raw=0.7433, running_loss=0.8024, LR=0.000100
[2025-08-10 20:02:00,653][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058740] [Batch 03360/03692] [00:29:56/00:02:57, 0.535s/it]: train_loss_raw=0.7235, running_loss=0.8044, LR=0.000100
[2025-08-10 20:02:07,185][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058752] [Batch 03372/03692] [00:30:02/00:02:51, 0.535s/it]: train_loss_raw=0.8868, running_loss=0.8080, LR=0.000100
[2025-08-10 20:02:13,741][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058764] [Batch 03384/03692] [00:30:09/00:02:44, 0.535s/it]: train_loss_raw=0.8104, running_loss=0.8044, LR=0.000100
[2025-08-10 20:02:20,208][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058776] [Batch 03396/03692] [00:30:15/00:02:38, 0.535s/it]: train_loss_raw=0.9059, running_loss=0.8053, LR=0.000100
[2025-08-10 20:02:26,727][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058788] [Batch 03408/03692] [00:30:22/00:02:31, 0.535s/it]: train_loss_raw=0.9458, running_loss=0.8038, LR=0.000100
[2025-08-10 20:02:33,218][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058800] [Batch 03420/03692] [00:30:28/00:02:25, 0.535s/it]: train_loss_raw=0.8626, running_loss=0.8040, LR=0.000100
[2025-08-10 20:02:39,732][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058812] [Batch 03432/03692] [00:30:35/00:02:19, 0.535s/it]: train_loss_raw=0.8399, running_loss=0.8030, LR=0.000100
[2025-08-10 20:02:46,178][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058824] [Batch 03444/03692] [00:30:41/00:02:12, 0.535s/it]: train_loss_raw=0.7659, running_loss=0.8022, LR=0.000100
[2025-08-10 20:02:52,731][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058836] [Batch 03456/03692] [00:30:48/00:02:06, 0.535s/it]: train_loss_raw=0.7669, running_loss=0.7996, LR=0.000100
[2025-08-10 20:02:59,209][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058848] [Batch 03468/03692] [00:30:54/00:01:59, 0.535s/it]: train_loss_raw=0.7888, running_loss=0.7995, LR=0.000100
[2025-08-10 20:03:05,621][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058860] [Batch 03480/03692] [00:31:01/00:01:53, 0.535s/it]: train_loss_raw=0.7924, running_loss=0.7995, LR=0.000100
[2025-08-10 20:03:11,954][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058872] [Batch 03492/03692] [00:31:07/00:01:46, 0.535s/it]: train_loss_raw=0.8721, running_loss=0.8016, LR=0.000100
[2025-08-10 20:03:17,959][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058884] [Batch 03504/03692] [00:31:13/00:01:40, 0.535s/it]: train_loss_raw=0.8634, running_loss=0.7987, LR=0.000100
[2025-08-10 20:03:24,007][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058896] [Batch 03516/03692] [00:31:19/00:01:34, 0.535s/it]: train_loss_raw=0.7952, running_loss=0.7987, LR=0.000100
[2025-08-10 20:03:30,000][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058908] [Batch 03528/03692] [00:31:25/00:01:27, 0.534s/it]: train_loss_raw=0.6832, running_loss=0.7973, LR=0.000100
[2025-08-10 20:03:36,009][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058920] [Batch 03540/03692] [00:31:31/00:01:21, 0.534s/it]: train_loss_raw=0.8866, running_loss=0.7960, LR=0.000100
[2025-08-10 20:03:42,100][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058932] [Batch 03552/03692] [00:31:37/00:01:14, 0.534s/it]: train_loss_raw=0.7914, running_loss=0.8005, LR=0.000100
[2025-08-10 20:03:48,123][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058944] [Batch 03564/03692] [00:31:43/00:01:08, 0.534s/it]: train_loss_raw=0.8079, running_loss=0.8041, LR=0.000100
[2025-08-10 20:03:54,161][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058956] [Batch 03576/03692] [00:31:49/00:01:01, 0.534s/it]: train_loss_raw=0.8478, running_loss=0.8030, LR=0.000100
[2025-08-10 20:04:00,145][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058968] [Batch 03588/03692] [00:31:55/00:00:55, 0.534s/it]: train_loss_raw=0.8575, running_loss=0.8051, LR=0.000100
[2025-08-10 20:04:06,213][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058980] [Batch 03600/03692] [00:32:01/00:00:49, 0.534s/it]: train_loss_raw=0.7989, running_loss=0.8078, LR=0.000100
[2025-08-10 20:04:12,256][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 058992] [Batch 03612/03692] [00:32:07/00:00:42, 0.534s/it]: train_loss_raw=0.9218, running_loss=0.8112, LR=0.000100
[2025-08-10 20:04:18,411][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059004] [Batch 03624/03692] [00:32:13/00:00:36, 0.534s/it]: train_loss_raw=0.6852, running_loss=0.8096, LR=0.000100
[2025-08-10 20:04:24,433][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059016] [Batch 03636/03692] [00:32:19/00:00:29, 0.534s/it]: train_loss_raw=0.8088, running_loss=0.8031, LR=0.000100
[2025-08-10 20:04:30,865][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059028] [Batch 03648/03692] [00:32:26/00:00:23, 0.534s/it]: train_loss_raw=0.7148, running_loss=0.8031, LR=0.000100
[2025-08-10 20:04:37,329][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059040] [Batch 03660/03692] [00:32:32/00:00:17, 0.534s/it]: train_loss_raw=0.6687, running_loss=0.7993, LR=0.000100
[2025-08-10 20:04:43,781][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059052] [Batch 03672/03692] [00:32:39/00:00:10, 0.534s/it]: train_loss_raw=0.8642, running_loss=0.7992, LR=0.000100
[2025-08-10 20:04:50,373][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 059064] [Batch 03684/03692] [00:32:45/00:00:04, 0.534s/it]: train_loss_raw=0.8465, running_loss=0.7974, LR=0.000100
[2025-08-10 20:05:25,225][__main__][INFO] - [VALIDATION] [Epoch 15/29] Starting validation.
[2025-08-10 20:05:56,802][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 059073] [Batch 00011/00025] [00:00:31/00:00:34, 2.631s/it]
[2025-08-10 20:06:11,575][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 059073] [Batch 00023/00025] [00:00:46/00:00:01, 1.931s/it]
[2025-08-10 20:06:12,697][__main__][INFO] - [VALIDATION] [Epoch 15/29] train_loss=0.79859, valid_loss=0.82390
[2025-08-10 20:06:12,697][__main__][INFO] - [VALIDATION] [Epoch 15/29] Metrics:
[2025-08-10 20:06:12,697][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_er      0.367
[2025-08-10 20:06:12,697][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_prec    0.364
[2025-08-10 20:06:12,697][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_recall  0.370
[2025-08-10 20:06:12,697][__main__][INFO] - [VALIDATION] [Epoch 15/29] - pep_recall 0.341
[2025-08-10 20:06:12,700][__main__][INFO] - [TRAIN] [Epoch 15/29] Epoch complete, total time 09:10:11, remaining time 08:01:25, 00:34:23 per epoch
[2025-08-10 20:06:15,566][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059076] [Batch 00004/03692] [00:00:01/00:24:31, 0.399s/it]: train_loss_raw=0.7178, running_loss=0.7019, LR=0.000100
[2025-08-10 20:06:22,018][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059088] [Batch 00016/03692] [00:00:08/00:30:49, 0.503s/it]: train_loss_raw=0.7938, running_loss=0.7125, LR=0.000100
[2025-08-10 20:06:28,551][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059100] [Batch 00028/03692] [00:00:14/00:31:47, 0.521s/it]: train_loss_raw=0.6567, running_loss=0.7181, LR=0.000100
[2025-08-10 20:06:35,047][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059112] [Batch 00040/03692] [00:00:21/00:32:04, 0.527s/it]: train_loss_raw=0.9563, running_loss=0.7269, LR=0.000100
[2025-08-10 20:06:41,544][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059124] [Batch 00052/03692] [00:00:27/00:32:10, 0.530s/it]: train_loss_raw=0.7236, running_loss=0.7293, LR=0.000100
[2025-08-10 20:06:48,108][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059136] [Batch 00064/03692] [00:00:34/00:32:15, 0.533s/it]: train_loss_raw=0.7147, running_loss=0.7304, LR=0.000100
[2025-08-10 20:06:54,518][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059148] [Batch 00076/03692] [00:00:40/00:32:09, 0.534s/it]: train_loss_raw=0.7862, running_loss=0.7356, LR=0.000100
[2025-08-10 20:07:00,926][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059160] [Batch 00088/03692] [00:00:46/00:32:03, 0.534s/it]: train_loss_raw=0.7263, running_loss=0.7351, LR=0.000100
[2025-08-10 20:07:07,348][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059172] [Batch 00100/03692] [00:00:53/00:31:57, 0.534s/it]: train_loss_raw=0.7310, running_loss=0.7372, LR=0.000100
[2025-08-10 20:07:13,744][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059184] [Batch 00112/03692] [00:00:59/00:31:50, 0.534s/it]: train_loss_raw=0.7186, running_loss=0.7387, LR=0.000100
[2025-08-10 20:07:20,308][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059196] [Batch 00124/03692] [00:01:06/00:31:48, 0.535s/it]: train_loss_raw=0.6258, running_loss=0.7439, LR=0.000100
[2025-08-10 20:07:26,672][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059208] [Batch 00136/03692] [00:01:12/00:31:40, 0.535s/it]: train_loss_raw=0.7980, running_loss=0.7506, LR=0.000100
[2025-08-10 20:07:33,050][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059220] [Batch 00148/03692] [00:01:19/00:31:33, 0.534s/it]: train_loss_raw=0.8685, running_loss=0.7496, LR=0.000100
[2025-08-10 20:07:39,363][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059232] [Batch 00160/03692] [00:01:25/00:31:25, 0.534s/it]: train_loss_raw=0.9380, running_loss=0.7535, LR=0.000100
[2025-08-10 20:07:45,730][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059244] [Batch 00172/03692] [00:01:31/00:31:17, 0.533s/it]: train_loss_raw=0.7817, running_loss=0.7533, LR=0.000100
[2025-08-10 20:07:52,108][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059256] [Batch 00184/03692] [00:01:38/00:31:11, 0.533s/it]: train_loss_raw=0.7095, running_loss=0.7554, LR=0.000100
[2025-08-10 20:07:58,579][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059268] [Batch 00196/03692] [00:01:44/00:31:05, 0.534s/it]: train_loss_raw=0.7932, running_loss=0.7571, LR=0.000100
[2025-08-10 20:08:05,142][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059280] [Batch 00208/03692] [00:01:51/00:31:02, 0.534s/it]: train_loss_raw=0.8325, running_loss=0.7640, LR=0.000100
[2025-08-10 20:08:11,613][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059292] [Batch 00220/03692] [00:01:57/00:30:56, 0.535s/it]: train_loss_raw=0.8999, running_loss=0.7667, LR=0.000100
[2025-08-10 20:08:18,085][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059304] [Batch 00232/03692] [00:02:04/00:30:51, 0.535s/it]: train_loss_raw=0.7787, running_loss=0.7662, LR=0.000100
[2025-08-10 20:08:24,615][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059316] [Batch 00244/03692] [00:02:10/00:30:46, 0.535s/it]: train_loss_raw=0.7622, running_loss=0.7631, LR=0.000100
[2025-08-10 20:08:31,154][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059328] [Batch 00256/03692] [00:02:17/00:30:41, 0.536s/it]: train_loss_raw=0.7730, running_loss=0.7669, LR=0.000100
[2025-08-10 20:08:37,617][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059340] [Batch 00268/03692] [00:02:23/00:30:35, 0.536s/it]: train_loss_raw=0.8334, running_loss=0.7655, LR=0.000100
[2025-08-10 20:08:44,038][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059352] [Batch 00280/03692] [00:02:30/00:30:28, 0.536s/it]: train_loss_raw=0.7835, running_loss=0.7659, LR=0.000100
[2025-08-10 20:08:50,463][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059364] [Batch 00292/03692] [00:02:36/00:30:22, 0.536s/it]: train_loss_raw=0.7614, running_loss=0.7662, LR=0.000100
[2025-08-10 20:08:56,847][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059376] [Batch 00304/03692] [00:02:42/00:30:15, 0.536s/it]: train_loss_raw=0.7518, running_loss=0.7702, LR=0.000100
[2025-08-10 20:09:03,381][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059388] [Batch 00316/03692] [00:02:49/00:30:09, 0.536s/it]: train_loss_raw=0.7757, running_loss=0.7705, LR=0.000100
[2025-08-10 20:09:09,822][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059400] [Batch 00328/03692] [00:02:55/00:30:03, 0.536s/it]: train_loss_raw=0.7605, running_loss=0.7672, LR=0.000100
[2025-08-10 20:09:16,278][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059412] [Batch 00340/03692] [00:03:02/00:29:57, 0.536s/it]: train_loss_raw=0.7433, running_loss=0.7659, LR=0.000100
[2025-08-10 20:09:22,733][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059424] [Batch 00352/03692] [00:03:08/00:29:51, 0.536s/it]: train_loss_raw=0.6267, running_loss=0.7612, LR=0.000100
[2025-08-10 20:09:29,161][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059436] [Batch 00364/03692] [00:03:15/00:29:44, 0.536s/it]: train_loss_raw=0.6956, running_loss=0.7634, LR=0.000100
[2025-08-10 20:09:35,693][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059448] [Batch 00376/03692] [00:03:21/00:29:39, 0.536s/it]: train_loss_raw=0.6961, running_loss=0.7634, LR=0.000100
[2025-08-10 20:09:42,147][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059460] [Batch 00388/03692] [00:03:28/00:29:32, 0.537s/it]: train_loss_raw=0.9468, running_loss=0.7629, LR=0.000100
[2025-08-10 20:09:48,567][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059472] [Batch 00400/03692] [00:03:34/00:29:26, 0.536s/it]: train_loss_raw=0.6895, running_loss=0.7633, LR=0.000100
[2025-08-10 20:09:54,927][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059484] [Batch 00412/03692] [00:03:40/00:29:19, 0.536s/it]: train_loss_raw=0.8448, running_loss=0.7657, LR=0.000100
[2025-08-10 20:10:01,335][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059496] [Batch 00424/03692] [00:03:47/00:29:12, 0.536s/it]: train_loss_raw=0.8031, running_loss=0.7667, LR=0.000100
[2025-08-10 20:10:07,813][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059508] [Batch 00436/03692] [00:03:53/00:29:06, 0.536s/it]: train_loss_raw=0.7329, running_loss=0.7691, LR=0.000100
[2025-08-10 20:10:14,329][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059520] [Batch 00448/03692] [00:04:00/00:29:00, 0.537s/it]: train_loss_raw=0.7071, running_loss=0.7671, LR=0.000100
[2025-08-10 20:10:20,753][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059532] [Batch 00460/03692] [00:04:06/00:28:53, 0.536s/it]: train_loss_raw=0.7239, running_loss=0.7660, LR=0.000100
[2025-08-10 20:10:27,229][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059544] [Batch 00472/03692] [00:04:13/00:28:47, 0.537s/it]: train_loss_raw=0.8114, running_loss=0.7643, LR=0.000100
[2025-08-10 20:10:33,667][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059556] [Batch 00484/03692] [00:04:19/00:28:41, 0.537s/it]: train_loss_raw=0.7119, running_loss=0.7667, LR=0.000100
[2025-08-10 20:10:40,096][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059568] [Batch 00496/03692] [00:04:26/00:28:34, 0.537s/it]: train_loss_raw=0.8427, running_loss=0.7653, LR=0.000100
[2025-08-10 20:10:46,586][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059580] [Batch 00508/03692] [00:04:32/00:28:28, 0.537s/it]: train_loss_raw=0.8189, running_loss=0.7720, LR=0.000100
[2025-08-10 20:10:52,955][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059592] [Batch 00520/03692] [00:04:38/00:28:21, 0.537s/it]: train_loss_raw=0.6681, running_loss=0.7701, LR=0.000100
[2025-08-10 20:10:59,280][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059604] [Batch 00532/03692] [00:04:45/00:28:14, 0.536s/it]: train_loss_raw=0.7611, running_loss=0.7741, LR=0.000100
[2025-08-10 20:11:05,700][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059616] [Batch 00544/03692] [00:04:51/00:28:08, 0.536s/it]: train_loss_raw=0.6860, running_loss=0.7735, LR=0.000100
[2025-08-10 20:11:12,088][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059628] [Batch 00556/03692] [00:04:58/00:28:01, 0.536s/it]: train_loss_raw=0.7855, running_loss=0.7692, LR=0.000100
[2025-08-10 20:11:18,494][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059640] [Batch 00568/03692] [00:05:04/00:27:54, 0.536s/it]: train_loss_raw=0.6927, running_loss=0.7672, LR=0.000100
[2025-08-10 20:11:24,906][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059652] [Batch 00580/03692] [00:05:10/00:27:48, 0.536s/it]: train_loss_raw=0.7636, running_loss=0.7663, LR=0.000100
[2025-08-10 20:11:31,371][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059664] [Batch 00592/03692] [00:05:17/00:27:42, 0.536s/it]: train_loss_raw=0.8385, running_loss=0.7673, LR=0.000100
[2025-08-10 20:11:37,801][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059676] [Batch 00604/03692] [00:05:23/00:27:35, 0.536s/it]: train_loss_raw=0.7951, running_loss=0.7672, LR=0.000100
[2025-08-10 20:11:44,206][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059688] [Batch 00616/03692] [00:05:30/00:27:29, 0.536s/it]: train_loss_raw=0.7362, running_loss=0.7655, LR=0.000100
[2025-08-10 20:11:50,686][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059700] [Batch 00628/03692] [00:05:36/00:27:22, 0.536s/it]: train_loss_raw=0.7238, running_loss=0.7650, LR=0.000100
[2025-08-10 20:11:57,160][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059712] [Batch 00640/03692] [00:05:43/00:27:16, 0.536s/it]: train_loss_raw=0.6736, running_loss=0.7618, LR=0.000100
[2025-08-10 20:12:03,581][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059724] [Batch 00652/03692] [00:05:49/00:27:10, 0.536s/it]: train_loss_raw=0.7508, running_loss=0.7590, LR=0.000100
[2025-08-10 20:12:09,992][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059736] [Batch 00664/03692] [00:05:56/00:27:03, 0.536s/it]: train_loss_raw=0.7996, running_loss=0.7584, LR=0.000100
[2025-08-10 20:12:16,372][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059748] [Batch 00676/03692] [00:06:02/00:26:56, 0.536s/it]: train_loss_raw=0.6576, running_loss=0.7545, LR=0.000100
[2025-08-10 20:12:22,772][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059760] [Batch 00688/03692] [00:06:08/00:26:50, 0.536s/it]: train_loss_raw=0.8767, running_loss=0.7581, LR=0.000100
[2025-08-10 20:12:29,325][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059772] [Batch 00700/03692] [00:06:15/00:26:44, 0.536s/it]: train_loss_raw=0.8383, running_loss=0.7578, LR=0.000100
[2025-08-10 20:12:35,864][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059784] [Batch 00712/03692] [00:06:21/00:26:38, 0.536s/it]: train_loss_raw=0.7286, running_loss=0.7552, LR=0.000100
[2025-08-10 20:12:42,310][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059796] [Batch 00724/03692] [00:06:28/00:26:31, 0.536s/it]: train_loss_raw=0.7709, running_loss=0.7583, LR=0.000100
[2025-08-10 20:12:48,728][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059808] [Batch 00736/03692] [00:06:34/00:26:25, 0.536s/it]: train_loss_raw=0.6786, running_loss=0.7579, LR=0.000100
[2025-08-10 20:12:55,104][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059820] [Batch 00748/03692] [00:06:41/00:26:18, 0.536s/it]: train_loss_raw=0.9269, running_loss=0.7603, LR=0.000100
[2025-08-10 20:13:01,521][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059832] [Batch 00760/03692] [00:06:47/00:26:12, 0.536s/it]: train_loss_raw=0.7804, running_loss=0.7608, LR=0.000100
[2025-08-10 20:13:07,959][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059844] [Batch 00772/03692] [00:06:53/00:26:05, 0.536s/it]: train_loss_raw=0.8325, running_loss=0.7644, LR=0.000100
[2025-08-10 20:13:14,406][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059856] [Batch 00784/03692] [00:07:00/00:25:59, 0.536s/it]: train_loss_raw=0.8258, running_loss=0.7650, LR=0.000100
[2025-08-10 20:13:20,893][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059868] [Batch 00796/03692] [00:07:06/00:25:53, 0.536s/it]: train_loss_raw=0.6868, running_loss=0.7626, LR=0.000100
[2025-08-10 20:13:27,291][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059880] [Batch 00808/03692] [00:07:13/00:25:46, 0.536s/it]: train_loss_raw=0.6765, running_loss=0.7638, LR=0.000100
[2025-08-10 20:13:33,620][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059892] [Batch 00820/03692] [00:07:19/00:25:39, 0.536s/it]: train_loss_raw=0.7695, running_loss=0.7622, LR=0.000100
[2025-08-10 20:13:39,970][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059904] [Batch 00832/03692] [00:07:25/00:25:33, 0.536s/it]: train_loss_raw=0.7560, running_loss=0.7630, LR=0.000100
[2025-08-10 20:13:46,434][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059916] [Batch 00844/03692] [00:07:32/00:25:26, 0.536s/it]: train_loss_raw=0.7276, running_loss=0.7664, LR=0.000100
[2025-08-10 20:13:52,848][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059928] [Batch 00856/03692] [00:07:38/00:25:20, 0.536s/it]: train_loss_raw=0.6373, running_loss=0.7634, LR=0.000100
[2025-08-10 20:13:59,105][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059940] [Batch 00868/03692] [00:07:45/00:25:13, 0.536s/it]: train_loss_raw=0.8376, running_loss=0.7643, LR=0.000100
[2025-08-10 20:14:05,345][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059952] [Batch 00880/03692] [00:07:51/00:25:06, 0.536s/it]: train_loss_raw=0.8063, running_loss=0.7652, LR=0.000100
[2025-08-10 20:14:11,663][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059964] [Batch 00892/03692] [00:07:57/00:24:59, 0.536s/it]: train_loss_raw=0.7480, running_loss=0.7698, LR=0.000100
[2025-08-10 20:14:18,116][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059976] [Batch 00904/03692] [00:08:04/00:24:53, 0.536s/it]: train_loss_raw=0.7679, running_loss=0.7657, LR=0.000100
[2025-08-10 20:14:24,643][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 059988] [Batch 00916/03692] [00:08:10/00:24:47, 0.536s/it]: train_loss_raw=0.8143, running_loss=0.7640, LR=0.000100
[2025-08-10 20:14:31,181][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060000] [Batch 00928/03692] [00:08:17/00:24:40, 0.536s/it]: train_loss_raw=0.7933, running_loss=0.7658, LR=0.000100
[2025-08-10 20:14:42,668][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060012] [Batch 00940/03692] [00:08:28/00:24:49, 0.541s/it]: train_loss_raw=0.7524, running_loss=0.7627, LR=0.000100
[2025-08-10 20:14:49,380][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060024] [Batch 00952/03692] [00:08:35/00:24:43, 0.541s/it]: train_loss_raw=0.6200, running_loss=0.7601, LR=0.000100
[2025-08-10 20:14:56,011][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060036] [Batch 00964/03692] [00:08:42/00:24:37, 0.542s/it]: train_loss_raw=0.6429, running_loss=0.7548, LR=0.000100
[2025-08-10 20:15:02,504][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060048] [Batch 00976/03692] [00:08:48/00:24:30, 0.542s/it]: train_loss_raw=0.7416, running_loss=0.7554, LR=0.000100
[2025-08-10 20:15:09,043][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060060] [Batch 00988/03692] [00:08:55/00:24:24, 0.542s/it]: train_loss_raw=0.7853, running_loss=0.7557, LR=0.000100
[2025-08-10 20:15:15,514][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060072] [Batch 01000/03692] [00:09:01/00:24:17, 0.542s/it]: train_loss_raw=0.6832, running_loss=0.7530, LR=0.000100
[2025-08-10 20:15:22,029][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060084] [Batch 01012/03692] [00:09:08/00:24:11, 0.542s/it]: train_loss_raw=0.6590, running_loss=0.7524, LR=0.000100
[2025-08-10 20:15:28,541][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060096] [Batch 01024/03692] [00:09:14/00:24:04, 0.542s/it]: train_loss_raw=0.7454, running_loss=0.7500, LR=0.000100
[2025-08-10 20:15:35,127][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060108] [Batch 01036/03692] [00:09:21/00:23:58, 0.542s/it]: train_loss_raw=0.9040, running_loss=0.7528, LR=0.000100
[2025-08-10 20:15:41,575][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060120] [Batch 01048/03692] [00:09:27/00:23:52, 0.542s/it]: train_loss_raw=0.7719, running_loss=0.7571, LR=0.000100
[2025-08-10 20:15:47,946][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060132] [Batch 01060/03692] [00:09:33/00:23:45, 0.541s/it]: train_loss_raw=0.6459, running_loss=0.7521, LR=0.000100
[2025-08-10 20:15:54,286][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060144] [Batch 01072/03692] [00:09:40/00:23:38, 0.541s/it]: train_loss_raw=0.7125, running_loss=0.7561, LR=0.000100
[2025-08-10 20:16:00,689][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060156] [Batch 01084/03692] [00:09:46/00:23:31, 0.541s/it]: train_loss_raw=0.8104, running_loss=0.7580, LR=0.000100
[2025-08-10 20:16:07,117][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060168] [Batch 01096/03692] [00:09:53/00:23:24, 0.541s/it]: train_loss_raw=0.7849, running_loss=0.7596, LR=0.000100
[2025-08-10 20:16:13,608][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060180] [Batch 01108/03692] [00:09:59/00:23:18, 0.541s/it]: train_loss_raw=0.7178, running_loss=0.7640, LR=0.000100
[2025-08-10 20:16:19,954][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060192] [Batch 01120/03692] [00:10:05/00:23:11, 0.541s/it]: train_loss_raw=0.7298, running_loss=0.7641, LR=0.000100
[2025-08-10 20:16:26,397][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060204] [Batch 01132/03692] [00:10:12/00:23:04, 0.541s/it]: train_loss_raw=0.8504, running_loss=0.7659, LR=0.000100
[2025-08-10 20:16:32,761][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060216] [Batch 01144/03692] [00:10:18/00:22:58, 0.541s/it]: train_loss_raw=0.7311, running_loss=0.7629, LR=0.000100
[2025-08-10 20:16:39,139][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060228] [Batch 01156/03692] [00:10:25/00:22:51, 0.541s/it]: train_loss_raw=0.7847, running_loss=0.7642, LR=0.000100
[2025-08-10 20:16:45,544][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060240] [Batch 01168/03692] [00:10:31/00:22:44, 0.541s/it]: train_loss_raw=0.6963, running_loss=0.7595, LR=0.000100
[2025-08-10 20:16:51,927][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060252] [Batch 01180/03692] [00:10:37/00:22:38, 0.541s/it]: train_loss_raw=0.7966, running_loss=0.7599, LR=0.000100
[2025-08-10 20:16:58,399][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060264] [Batch 01192/03692] [00:10:44/00:22:31, 0.541s/it]: train_loss_raw=0.7308, running_loss=0.7586, LR=0.000100
[2025-08-10 20:17:04,807][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060276] [Batch 01204/03692] [00:10:50/00:22:24, 0.541s/it]: train_loss_raw=0.8210, running_loss=0.7572, LR=0.000100
[2025-08-10 20:17:11,195][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060288] [Batch 01216/03692] [00:10:57/00:22:18, 0.540s/it]: train_loss_raw=0.9009, running_loss=0.7551, LR=0.000100
[2025-08-10 20:17:17,585][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060300] [Batch 01228/03692] [00:11:03/00:22:11, 0.540s/it]: train_loss_raw=0.9230, running_loss=0.7577, LR=0.000100
[2025-08-10 20:17:24,020][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060312] [Batch 01240/03692] [00:11:10/00:22:04, 0.540s/it]: train_loss_raw=0.7621, running_loss=0.7586, LR=0.000100
[2025-08-10 20:17:30,459][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060324] [Batch 01252/03692] [00:11:16/00:21:58, 0.540s/it]: train_loss_raw=0.7190, running_loss=0.7625, LR=0.000100
[2025-08-10 20:17:36,937][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060336] [Batch 01264/03692] [00:11:22/00:21:51, 0.540s/it]: train_loss_raw=0.7919, running_loss=0.7577, LR=0.000100
[2025-08-10 20:17:43,318][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060348] [Batch 01276/03692] [00:11:29/00:21:45, 0.540s/it]: train_loss_raw=0.7574, running_loss=0.7564, LR=0.000100
[2025-08-10 20:17:49,714][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060360] [Batch 01288/03692] [00:11:35/00:21:38, 0.540s/it]: train_loss_raw=0.8046, running_loss=0.7574, LR=0.000100
[2025-08-10 20:17:56,113][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060372] [Batch 01300/03692] [00:11:42/00:21:31, 0.540s/it]: train_loss_raw=0.6365, running_loss=0.7513, LR=0.000100
[2025-08-10 20:18:02,501][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060384] [Batch 01312/03692] [00:11:48/00:21:25, 0.540s/it]: train_loss_raw=0.6809, running_loss=0.7480, LR=0.000100
[2025-08-10 20:18:08,864][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060396] [Batch 01324/03692] [00:11:54/00:21:18, 0.540s/it]: train_loss_raw=0.8109, running_loss=0.7493, LR=0.000100
[2025-08-10 20:18:15,240][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060408] [Batch 01336/03692] [00:12:01/00:21:11, 0.540s/it]: train_loss_raw=0.8948, running_loss=0.7533, LR=0.000100
[2025-08-10 20:18:21,575][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060420] [Batch 01348/03692] [00:12:07/00:21:05, 0.540s/it]: train_loss_raw=0.7023, running_loss=0.7527, LR=0.000100
[2025-08-10 20:18:27,969][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060432] [Batch 01360/03692] [00:12:13/00:20:58, 0.540s/it]: train_loss_raw=0.7078, running_loss=0.7492, LR=0.000100
[2025-08-10 20:18:34,397][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060444] [Batch 01372/03692] [00:12:20/00:20:52, 0.540s/it]: train_loss_raw=0.7875, running_loss=0.7504, LR=0.000100
[2025-08-10 20:18:40,766][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060456] [Batch 01384/03692] [00:12:26/00:20:45, 0.540s/it]: train_loss_raw=0.7903, running_loss=0.7515, LR=0.000100
[2025-08-10 20:18:47,150][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060468] [Batch 01396/03692] [00:12:33/00:20:38, 0.540s/it]: train_loss_raw=0.7584, running_loss=0.7516, LR=0.000100
[2025-08-10 20:18:53,611][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060480] [Batch 01408/03692] [00:12:39/00:20:32, 0.540s/it]: train_loss_raw=0.7508, running_loss=0.7529, LR=0.000100
[2025-08-10 20:18:59,933][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060492] [Batch 01420/03692] [00:12:45/00:20:25, 0.539s/it]: train_loss_raw=0.6253, running_loss=0.7499, LR=0.000100
[2025-08-10 20:19:06,272][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060504] [Batch 01432/03692] [00:12:52/00:20:18, 0.539s/it]: train_loss_raw=0.7325, running_loss=0.7517, LR=0.000100
[2025-08-10 20:19:12,612][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060516] [Batch 01444/03692] [00:12:58/00:20:12, 0.539s/it]: train_loss_raw=0.7823, running_loss=0.7533, LR=0.000100
[2025-08-10 20:19:19,024][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060528] [Batch 01456/03692] [00:13:05/00:20:05, 0.539s/it]: train_loss_raw=0.7356, running_loss=0.7534, LR=0.000100
[2025-08-10 20:19:25,412][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060540] [Batch 01468/03692] [00:13:11/00:19:59, 0.539s/it]: train_loss_raw=0.8061, running_loss=0.7510, LR=0.000100
[2025-08-10 20:19:31,791][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060552] [Batch 01480/03692] [00:13:17/00:19:52, 0.539s/it]: train_loss_raw=0.7570, running_loss=0.7484, LR=0.000100
[2025-08-10 20:19:38,164][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060564] [Batch 01492/03692] [00:13:24/00:19:45, 0.539s/it]: train_loss_raw=0.7552, running_loss=0.7480, LR=0.000100
[2025-08-10 20:19:44,578][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060576] [Batch 01504/03692] [00:13:30/00:19:39, 0.539s/it]: train_loss_raw=0.7287, running_loss=0.7494, LR=0.000100
[2025-08-10 20:19:50,942][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060588] [Batch 01516/03692] [00:13:36/00:19:32, 0.539s/it]: train_loss_raw=0.6678, running_loss=0.7481, LR=0.000100
[2025-08-10 20:19:57,387][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060600] [Batch 01528/03692] [00:13:43/00:19:26, 0.539s/it]: train_loss_raw=0.7265, running_loss=0.7455, LR=0.000100
[2025-08-10 20:20:03,773][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060612] [Batch 01540/03692] [00:13:49/00:19:19, 0.539s/it]: train_loss_raw=0.8601, running_loss=0.7512, LR=0.000100
[2025-08-10 20:20:10,158][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060624] [Batch 01552/03692] [00:13:56/00:19:12, 0.539s/it]: train_loss_raw=0.6786, running_loss=0.7476, LR=0.000100
[2025-08-10 20:20:16,582][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060636] [Batch 01564/03692] [00:14:02/00:19:06, 0.539s/it]: train_loss_raw=0.5975, running_loss=0.7500, LR=0.000100
[2025-08-10 20:20:23,049][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060648] [Batch 01576/03692] [00:14:09/00:19:00, 0.539s/it]: train_loss_raw=0.7336, running_loss=0.7525, LR=0.000100
[2025-08-10 20:20:29,667][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060660] [Batch 01588/03692] [00:14:15/00:18:53, 0.539s/it]: train_loss_raw=0.8708, running_loss=0.7545, LR=0.000100
[2025-08-10 20:20:36,138][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060672] [Batch 01600/03692] [00:14:22/00:18:47, 0.539s/it]: train_loss_raw=0.7515, running_loss=0.7510, LR=0.000100
[2025-08-10 20:20:42,577][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060684] [Batch 01612/03692] [00:14:28/00:18:40, 0.539s/it]: train_loss_raw=0.7733, running_loss=0.7500, LR=0.000100
[2025-08-10 20:20:49,091][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060696] [Batch 01624/03692] [00:14:35/00:18:34, 0.539s/it]: train_loss_raw=0.6248, running_loss=0.7504, LR=0.000100
[2025-08-10 20:20:55,747][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060708] [Batch 01636/03692] [00:14:41/00:18:28, 0.539s/it]: train_loss_raw=0.7193, running_loss=0.7449, LR=0.000100
[2025-08-10 20:21:02,163][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060720] [Batch 01648/03692] [00:14:48/00:18:21, 0.539s/it]: train_loss_raw=0.8374, running_loss=0.7481, LR=0.000100
[2025-08-10 20:21:08,147][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060732] [Batch 01660/03692] [00:14:54/00:18:14, 0.539s/it]: train_loss_raw=0.7876, running_loss=0.7468, LR=0.000100
[2025-08-10 20:21:14,188][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060744] [Batch 01672/03692] [00:15:00/00:18:07, 0.538s/it]: train_loss_raw=0.7979, running_loss=0.7480, LR=0.000100
[2025-08-10 20:21:20,461][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060756] [Batch 01684/03692] [00:15:06/00:18:00, 0.538s/it]: train_loss_raw=0.6550, running_loss=0.7488, LR=0.000100
[2025-08-10 20:21:26,977][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060768] [Batch 01696/03692] [00:15:13/00:17:54, 0.538s/it]: train_loss_raw=0.7418, running_loss=0.7488, LR=0.000100
[2025-08-10 20:21:33,479][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060780] [Batch 01708/03692] [00:15:19/00:17:48, 0.538s/it]: train_loss_raw=0.7909, running_loss=0.7464, LR=0.000100
[2025-08-10 20:21:40,031][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060792] [Batch 01720/03692] [00:15:26/00:17:41, 0.538s/it]: train_loss_raw=0.8217, running_loss=0.7489, LR=0.000100
[2025-08-10 20:21:46,520][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060804] [Batch 01732/03692] [00:15:32/00:17:35, 0.538s/it]: train_loss_raw=0.7666, running_loss=0.7510, LR=0.000100
[2025-08-10 20:21:53,102][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060816] [Batch 01744/03692] [00:15:39/00:17:28, 0.538s/it]: train_loss_raw=0.7480, running_loss=0.7522, LR=0.000100
[2025-08-10 20:21:59,624][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060828] [Batch 01756/03692] [00:15:45/00:17:22, 0.539s/it]: train_loss_raw=0.8174, running_loss=0.7517, LR=0.000100
[2025-08-10 20:22:06,083][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060840] [Batch 01768/03692] [00:15:52/00:17:16, 0.539s/it]: train_loss_raw=0.7277, running_loss=0.7486, LR=0.000100
[2025-08-10 20:22:12,572][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060852] [Batch 01780/03692] [00:15:58/00:17:09, 0.539s/it]: train_loss_raw=0.7517, running_loss=0.7503, LR=0.000100
[2025-08-10 20:22:19,086][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060864] [Batch 01792/03692] [00:16:05/00:17:03, 0.539s/it]: train_loss_raw=0.8164, running_loss=0.7531, LR=0.000100
[2025-08-10 20:22:25,593][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060876] [Batch 01804/03692] [00:16:11/00:16:56, 0.539s/it]: train_loss_raw=0.7040, running_loss=0.7513, LR=0.000100
[2025-08-10 20:22:32,103][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060888] [Batch 01816/03692] [00:16:18/00:16:50, 0.539s/it]: train_loss_raw=0.7371, running_loss=0.7472, LR=0.000100
[2025-08-10 20:22:38,622][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060900] [Batch 01828/03692] [00:16:24/00:16:44, 0.539s/it]: train_loss_raw=0.6340, running_loss=0.7428, LR=0.000100
[2025-08-10 20:22:45,146][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060912] [Batch 01840/03692] [00:16:31/00:16:37, 0.539s/it]: train_loss_raw=0.8346, running_loss=0.7437, LR=0.000100
[2025-08-10 20:22:51,588][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060924] [Batch 01852/03692] [00:16:37/00:16:31, 0.539s/it]: train_loss_raw=0.8194, running_loss=0.7433, LR=0.000100
[2025-08-10 20:22:58,115][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060936] [Batch 01864/03692] [00:16:44/00:16:24, 0.539s/it]: train_loss_raw=0.7529, running_loss=0.7394, LR=0.000100
[2025-08-10 20:23:04,142][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060948] [Batch 01876/03692] [00:16:50/00:16:17, 0.538s/it]: train_loss_raw=0.6753, running_loss=0.7382, LR=0.000100
[2025-08-10 20:23:10,150][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060960] [Batch 01888/03692] [00:16:56/00:16:10, 0.538s/it]: train_loss_raw=0.8217, running_loss=0.7357, LR=0.000100
[2025-08-10 20:23:16,336][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060972] [Batch 01900/03692] [00:17:02/00:16:04, 0.538s/it]: train_loss_raw=0.8242, running_loss=0.7352, LR=0.000100
[2025-08-10 20:23:22,509][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060984] [Batch 01912/03692] [00:17:08/00:15:57, 0.538s/it]: train_loss_raw=0.7850, running_loss=0.7359, LR=0.000100
[2025-08-10 20:23:28,797][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 060996] [Batch 01924/03692] [00:17:14/00:15:50, 0.538s/it]: train_loss_raw=0.7474, running_loss=0.7372, LR=0.000100
[2025-08-10 20:23:35,254][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061008] [Batch 01936/03692] [00:17:21/00:15:44, 0.538s/it]: train_loss_raw=0.7065, running_loss=0.7374, LR=0.000100
[2025-08-10 20:23:41,710][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061020] [Batch 01948/03692] [00:17:27/00:15:38, 0.538s/it]: train_loss_raw=0.7412, running_loss=0.7358, LR=0.000100
[2025-08-10 20:23:48,040][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061032] [Batch 01960/03692] [00:17:34/00:15:31, 0.538s/it]: train_loss_raw=0.7386, running_loss=0.7330, LR=0.000100
[2025-08-10 20:23:54,347][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061044] [Batch 01972/03692] [00:17:40/00:15:24, 0.538s/it]: train_loss_raw=0.6192, running_loss=0.7292, LR=0.000100
[2025-08-10 20:24:00,788][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061056] [Batch 01984/03692] [00:17:46/00:15:18, 0.538s/it]: train_loss_raw=0.7312, running_loss=0.7262, LR=0.000100
[2025-08-10 20:24:07,364][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061068] [Batch 01996/03692] [00:17:53/00:15:12, 0.538s/it]: train_loss_raw=0.8226, running_loss=0.7317, LR=0.000100
[2025-08-10 20:24:13,882][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061080] [Batch 02008/03692] [00:17:59/00:15:05, 0.538s/it]: train_loss_raw=0.7148, running_loss=0.7330, LR=0.000100
[2025-08-10 20:24:20,321][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061092] [Batch 02020/03692] [00:18:06/00:14:59, 0.538s/it]: train_loss_raw=0.7335, running_loss=0.7360, LR=0.000100
[2025-08-10 20:24:26,436][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061104] [Batch 02032/03692] [00:18:12/00:14:52, 0.538s/it]: train_loss_raw=0.6982, running_loss=0.7365, LR=0.000100
[2025-08-10 20:24:32,630][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061116] [Batch 02044/03692] [00:18:18/00:14:45, 0.538s/it]: train_loss_raw=0.6928, running_loss=0.7374, LR=0.000100
[2025-08-10 20:24:38,776][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061128] [Batch 02056/03692] [00:18:24/00:14:39, 0.537s/it]: train_loss_raw=0.6695, running_loss=0.7373, LR=0.000100
[2025-08-10 20:24:44,817][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061140] [Batch 02068/03692] [00:18:30/00:14:32, 0.537s/it]: train_loss_raw=0.7106, running_loss=0.7354, LR=0.000100
[2025-08-10 20:24:50,955][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061152] [Batch 02080/03692] [00:18:36/00:14:25, 0.537s/it]: train_loss_raw=0.6918, running_loss=0.7360, LR=0.000100
[2025-08-10 20:24:57,415][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061164] [Batch 02092/03692] [00:18:43/00:14:19, 0.537s/it]: train_loss_raw=0.7598, running_loss=0.7396, LR=0.000100
[2025-08-10 20:25:03,921][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061176] [Batch 02104/03692] [00:18:49/00:14:12, 0.537s/it]: train_loss_raw=0.8181, running_loss=0.7412, LR=0.000100
[2025-08-10 20:25:10,113][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061188] [Batch 02116/03692] [00:18:56/00:14:06, 0.537s/it]: train_loss_raw=0.7626, running_loss=0.7391, LR=0.000100
[2025-08-10 20:25:16,331][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061200] [Batch 02128/03692] [00:19:02/00:13:59, 0.537s/it]: train_loss_raw=0.6849, running_loss=0.7381, LR=0.000100
[2025-08-10 20:25:22,489][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061212] [Batch 02140/03692] [00:19:08/00:13:52, 0.537s/it]: train_loss_raw=0.8265, running_loss=0.7403, LR=0.000100
[2025-08-10 20:25:28,677][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061224] [Batch 02152/03692] [00:19:14/00:13:46, 0.537s/it]: train_loss_raw=0.7939, running_loss=0.7414, LR=0.000100
[2025-08-10 20:25:34,607][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061236] [Batch 02164/03692] [00:19:20/00:13:39, 0.536s/it]: train_loss_raw=0.7533, running_loss=0.7398, LR=0.000100
[2025-08-10 20:25:40,757][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061248] [Batch 02176/03692] [00:19:26/00:13:32, 0.536s/it]: train_loss_raw=0.7437, running_loss=0.7367, LR=0.000100
[2025-08-10 20:25:46,900][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061260] [Batch 02188/03692] [00:19:32/00:13:26, 0.536s/it]: train_loss_raw=0.6984, running_loss=0.7369, LR=0.000100
[2025-08-10 20:25:52,994][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061272] [Batch 02200/03692] [00:19:39/00:13:19, 0.536s/it]: train_loss_raw=0.6746, running_loss=0.7341, LR=0.000100
[2025-08-10 20:25:59,116][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061284] [Batch 02212/03692] [00:19:45/00:13:12, 0.536s/it]: train_loss_raw=0.6305, running_loss=0.7330, LR=0.000100
[2025-08-10 20:26:05,594][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061296] [Batch 02224/03692] [00:19:51/00:13:06, 0.536s/it]: train_loss_raw=0.6275, running_loss=0.7328, LR=0.000100
[2025-08-10 20:26:12,016][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061308] [Batch 02236/03692] [00:19:58/00:13:00, 0.536s/it]: train_loss_raw=0.7572, running_loss=0.7294, LR=0.000100
[2025-08-10 20:26:18,417][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061320] [Batch 02248/03692] [00:20:04/00:12:53, 0.536s/it]: train_loss_raw=0.7932, running_loss=0.7317, LR=0.000100
[2025-08-10 20:26:24,812][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061332] [Batch 02260/03692] [00:20:10/00:12:47, 0.536s/it]: train_loss_raw=0.7629, running_loss=0.7294, LR=0.000100
[2025-08-10 20:26:31,268][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061344] [Batch 02272/03692] [00:20:17/00:12:40, 0.536s/it]: train_loss_raw=0.6306, running_loss=0.7281, LR=0.000100
[2025-08-10 20:26:37,454][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061356] [Batch 02284/03692] [00:20:23/00:12:34, 0.536s/it]: train_loss_raw=0.8326, running_loss=0.7282, LR=0.000100
[2025-08-10 20:26:43,448][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061368] [Batch 02296/03692] [00:20:29/00:12:27, 0.535s/it]: train_loss_raw=0.7442, running_loss=0.7290, LR=0.000100
[2025-08-10 20:26:49,534][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061380] [Batch 02308/03692] [00:20:35/00:12:20, 0.535s/it]: train_loss_raw=0.8903, running_loss=0.7321, LR=0.000100
[2025-08-10 20:26:55,974][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061392] [Batch 02320/03692] [00:20:42/00:12:14, 0.535s/it]: train_loss_raw=0.8659, running_loss=0.7337, LR=0.000100
[2025-08-10 20:27:02,529][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061404] [Batch 02332/03692] [00:20:48/00:12:08, 0.535s/it]: train_loss_raw=0.7185, running_loss=0.7335, LR=0.000100
[2025-08-10 20:27:09,088][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061416] [Batch 02344/03692] [00:20:55/00:12:01, 0.535s/it]: train_loss_raw=0.7309, running_loss=0.7370, LR=0.000100
[2025-08-10 20:27:15,158][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061428] [Batch 02356/03692] [00:21:01/00:11:55, 0.535s/it]: train_loss_raw=0.6557, running_loss=0.7362, LR=0.000100
[2025-08-10 20:27:21,621][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061440] [Batch 02368/03692] [00:21:07/00:11:48, 0.535s/it]: train_loss_raw=0.7586, running_loss=0.7373, LR=0.000100
[2025-08-10 20:27:28,139][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061452] [Batch 02380/03692] [00:21:14/00:11:42, 0.535s/it]: train_loss_raw=0.7054, running_loss=0.7370, LR=0.000100
[2025-08-10 20:27:34,596][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061464] [Batch 02392/03692] [00:21:20/00:11:35, 0.535s/it]: train_loss_raw=0.7005, running_loss=0.7354, LR=0.000100
[2025-08-10 20:27:41,162][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061476] [Batch 02404/03692] [00:21:27/00:11:29, 0.535s/it]: train_loss_raw=0.7424, running_loss=0.7352, LR=0.000100
[2025-08-10 20:27:47,463][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061488] [Batch 02416/03692] [00:21:33/00:11:23, 0.535s/it]: train_loss_raw=0.7307, running_loss=0.7401, LR=0.000100
[2025-08-10 20:27:53,575][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061500] [Batch 02428/03692] [00:21:39/00:11:16, 0.535s/it]: train_loss_raw=0.7058, running_loss=0.7363, LR=0.000100
[2025-08-10 20:27:59,652][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061512] [Batch 02440/03692] [00:21:45/00:11:09, 0.535s/it]: train_loss_raw=0.7136, running_loss=0.7376, LR=0.000100
[2025-08-10 20:28:05,768][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061524] [Batch 02452/03692] [00:21:51/00:11:03, 0.535s/it]: train_loss_raw=0.7155, running_loss=0.7383, LR=0.000100
[2025-08-10 20:28:11,729][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061536] [Batch 02464/03692] [00:21:57/00:10:56, 0.535s/it]: train_loss_raw=0.8252, running_loss=0.7368, LR=0.000100
[2025-08-10 20:28:17,723][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061548] [Batch 02476/03692] [00:22:03/00:10:50, 0.535s/it]: train_loss_raw=0.6481, running_loss=0.7367, LR=0.000100
[2025-08-10 20:28:24,160][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061560] [Batch 02488/03692] [00:22:10/00:10:43, 0.535s/it]: train_loss_raw=0.7159, running_loss=0.7365, LR=0.000100
[2025-08-10 20:28:30,717][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061572] [Batch 02500/03692] [00:22:16/00:10:37, 0.535s/it]: train_loss_raw=0.6493, running_loss=0.7363, LR=0.000100
[2025-08-10 20:28:36,748][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061584] [Batch 02512/03692] [00:22:22/00:10:30, 0.535s/it]: train_loss_raw=0.6584, running_loss=0.7349, LR=0.000100
[2025-08-10 20:28:42,743][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061596] [Batch 02524/03692] [00:22:28/00:10:24, 0.534s/it]: train_loss_raw=0.6437, running_loss=0.7350, LR=0.000100
[2025-08-10 20:28:48,774][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061608] [Batch 02536/03692] [00:22:34/00:10:17, 0.534s/it]: train_loss_raw=0.5884, running_loss=0.7334, LR=0.000100
[2025-08-10 20:28:54,966][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061620] [Batch 02548/03692] [00:22:40/00:10:11, 0.534s/it]: train_loss_raw=0.6849, running_loss=0.7335, LR=0.000100
[2025-08-10 20:29:01,543][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061632] [Batch 02560/03692] [00:22:47/00:10:04, 0.534s/it]: train_loss_raw=0.7337, running_loss=0.7319, LR=0.000100
[2025-08-10 20:29:07,733][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061644] [Batch 02572/03692] [00:22:53/00:09:58, 0.534s/it]: train_loss_raw=0.6466, running_loss=0.7309, LR=0.000100
[2025-08-10 20:29:13,715][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061656] [Batch 02584/03692] [00:22:59/00:09:51, 0.534s/it]: train_loss_raw=0.6874, running_loss=0.7321, LR=0.000100
[2025-08-10 20:29:19,785][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061668] [Batch 02596/03692] [00:23:05/00:09:45, 0.534s/it]: train_loss_raw=0.6598, running_loss=0.7314, LR=0.000100
[2025-08-10 20:29:25,873][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061680] [Batch 02608/03692] [00:23:11/00:09:38, 0.534s/it]: train_loss_raw=0.7058, running_loss=0.7347, LR=0.000100
[2025-08-10 20:29:32,100][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061692] [Batch 02620/03692] [00:23:18/00:09:32, 0.534s/it]: train_loss_raw=0.6383, running_loss=0.7333, LR=0.000100
[2025-08-10 20:29:38,467][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061704] [Batch 02632/03692] [00:23:24/00:09:25, 0.534s/it]: train_loss_raw=0.6962, running_loss=0.7342, LR=0.000100
[2025-08-10 20:29:44,950][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061716] [Batch 02644/03692] [00:23:30/00:09:19, 0.534s/it]: train_loss_raw=0.7020, running_loss=0.7344, LR=0.000100
[2025-08-10 20:29:51,491][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061728] [Batch 02656/03692] [00:23:37/00:09:12, 0.534s/it]: train_loss_raw=0.7029, running_loss=0.7345, LR=0.000100
[2025-08-10 20:29:57,922][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061740] [Batch 02668/03692] [00:23:43/00:09:06, 0.534s/it]: train_loss_raw=0.7159, running_loss=0.7330, LR=0.000100
[2025-08-10 20:30:04,171][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061752] [Batch 02680/03692] [00:23:50/00:09:00, 0.534s/it]: train_loss_raw=0.8345, running_loss=0.7326, LR=0.000100
[2025-08-10 20:30:10,294][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061764] [Batch 02692/03692] [00:23:56/00:08:53, 0.534s/it]: train_loss_raw=0.7872, running_loss=0.7342, LR=0.000100
[2025-08-10 20:30:16,450][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061776] [Batch 02704/03692] [00:24:02/00:08:47, 0.533s/it]: train_loss_raw=0.6556, running_loss=0.7330, LR=0.000100
[2025-08-10 20:30:22,935][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061788] [Batch 02716/03692] [00:24:08/00:08:40, 0.533s/it]: train_loss_raw=0.6692, running_loss=0.7332, LR=0.000100
[2025-08-10 20:30:29,135][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061800] [Batch 02728/03692] [00:24:15/00:08:34, 0.533s/it]: train_loss_raw=0.8528, running_loss=0.7351, LR=0.000100
[2025-08-10 20:30:35,191][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061812] [Batch 02740/03692] [00:24:21/00:08:27, 0.533s/it]: train_loss_raw=0.7546, running_loss=0.7353, LR=0.000100
[2025-08-10 20:30:41,278][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061824] [Batch 02752/03692] [00:24:27/00:08:21, 0.533s/it]: train_loss_raw=0.7735, running_loss=0.7361, LR=0.000100
[2025-08-10 20:30:47,511][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061836] [Batch 02764/03692] [00:24:33/00:08:14, 0.533s/it]: train_loss_raw=0.7200, running_loss=0.7376, LR=0.000100
[2025-08-10 20:30:54,082][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061848] [Batch 02776/03692] [00:24:40/00:08:08, 0.533s/it]: train_loss_raw=0.8675, running_loss=0.7382, LR=0.000100
[2025-08-10 20:31:00,160][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061860] [Batch 02788/03692] [00:24:46/00:08:01, 0.533s/it]: train_loss_raw=0.6931, running_loss=0.7368, LR=0.000100
[2025-08-10 20:31:06,271][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061872] [Batch 02800/03692] [00:24:52/00:07:55, 0.533s/it]: train_loss_raw=0.6685, running_loss=0.7344, LR=0.000100
[2025-08-10 20:31:12,301][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061884] [Batch 02812/03692] [00:24:58/00:07:48, 0.533s/it]: train_loss_raw=0.8269, running_loss=0.7350, LR=0.000100
[2025-08-10 20:31:18,390][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061896] [Batch 02824/03692] [00:25:04/00:07:42, 0.533s/it]: train_loss_raw=0.6677, running_loss=0.7353, LR=0.000100
[2025-08-10 20:31:24,502][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061908] [Batch 02836/03692] [00:25:10/00:07:35, 0.533s/it]: train_loss_raw=0.8497, running_loss=0.7397, LR=0.000100
[2025-08-10 20:31:30,851][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061920] [Batch 02848/03692] [00:25:16/00:07:29, 0.533s/it]: train_loss_raw=0.7324, running_loss=0.7361, LR=0.000100
[2025-08-10 20:31:36,942][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061932] [Batch 02860/03692] [00:25:22/00:07:23, 0.533s/it]: train_loss_raw=0.7383, running_loss=0.7363, LR=0.000100
[2025-08-10 20:31:43,149][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061944] [Batch 02872/03692] [00:25:29/00:07:16, 0.532s/it]: train_loss_raw=0.7256, running_loss=0.7351, LR=0.000100
[2025-08-10 20:31:49,401][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061956] [Batch 02884/03692] [00:25:35/00:07:10, 0.532s/it]: train_loss_raw=0.8141, running_loss=0.7331, LR=0.000100
[2025-08-10 20:31:55,467][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061968] [Batch 02896/03692] [00:25:41/00:07:03, 0.532s/it]: train_loss_raw=0.7636, running_loss=0.7303, LR=0.000100
[2025-08-10 20:32:01,540][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061980] [Batch 02908/03692] [00:25:47/00:06:57, 0.532s/it]: train_loss_raw=0.7346, running_loss=0.7290, LR=0.000100
[2025-08-10 20:32:07,881][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 061992] [Batch 02920/03692] [00:25:53/00:06:50, 0.532s/it]: train_loss_raw=0.6731, running_loss=0.7252, LR=0.000100
[2025-08-10 20:32:18,788][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062004] [Batch 02932/03692] [00:26:04/00:06:45, 0.534s/it]: train_loss_raw=0.7563, running_loss=0.7250, LR=0.000100
[2025-08-10 20:32:25,604][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062016] [Batch 02944/03692] [00:26:11/00:06:39, 0.534s/it]: train_loss_raw=0.7928, running_loss=0.7213, LR=0.000100
[2025-08-10 20:32:31,846][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062028] [Batch 02956/03692] [00:26:17/00:06:32, 0.534s/it]: train_loss_raw=0.7098, running_loss=0.7199, LR=0.000100
[2025-08-10 20:32:37,945][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062040] [Batch 02968/03692] [00:26:23/00:06:26, 0.534s/it]: train_loss_raw=0.7812, running_loss=0.7209, LR=0.000100
[2025-08-10 20:32:44,371][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062052] [Batch 02980/03692] [00:26:30/00:06:19, 0.534s/it]: train_loss_raw=0.7599, running_loss=0.7208, LR=0.000100
[2025-08-10 20:32:50,800][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062064] [Batch 02992/03692] [00:26:36/00:06:13, 0.534s/it]: train_loss_raw=0.7146, running_loss=0.7219, LR=0.000100
[2025-08-10 20:32:57,002][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062076] [Batch 03004/03692] [00:26:43/00:06:07, 0.534s/it]: train_loss_raw=0.7354, running_loss=0.7195, LR=0.000100
[2025-08-10 20:33:03,332][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062088] [Batch 03016/03692] [00:26:49/00:06:00, 0.534s/it]: train_loss_raw=0.7412, running_loss=0.7225, LR=0.000100
[2025-08-10 20:33:09,480][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062100] [Batch 03028/03692] [00:26:55/00:05:54, 0.534s/it]: train_loss_raw=0.6502, running_loss=0.7228, LR=0.000100
[2025-08-10 20:33:15,828][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062112] [Batch 03040/03692] [00:27:01/00:05:47, 0.534s/it]: train_loss_raw=0.7518, running_loss=0.7230, LR=0.000100
[2025-08-10 20:33:22,403][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062124] [Batch 03052/03692] [00:27:08/00:05:41, 0.534s/it]: train_loss_raw=0.6231, running_loss=0.7176, LR=0.000100
[2025-08-10 20:33:28,984][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062136] [Batch 03064/03692] [00:27:15/00:05:35, 0.534s/it]: train_loss_raw=0.6816, running_loss=0.7167, LR=0.000100
[2025-08-10 20:33:35,816][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062148] [Batch 03076/03692] [00:27:21/00:05:28, 0.534s/it]: train_loss_raw=0.6934, running_loss=0.7153, LR=0.000100
[2025-08-10 20:33:42,413][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062160] [Batch 03088/03692] [00:27:28/00:05:22, 0.534s/it]: train_loss_raw=0.6965, running_loss=0.7152, LR=0.000100
[2025-08-10 20:33:49,114][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062172] [Batch 03100/03692] [00:27:35/00:05:16, 0.534s/it]: train_loss_raw=0.6669, running_loss=0.7146, LR=0.000100
[2025-08-10 20:33:55,756][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062184] [Batch 03112/03692] [00:27:41/00:05:09, 0.534s/it]: train_loss_raw=0.8144, running_loss=0.7158, LR=0.000100
[2025-08-10 20:34:02,523][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062196] [Batch 03124/03692] [00:27:48/00:05:03, 0.534s/it]: train_loss_raw=0.7016, running_loss=0.7157, LR=0.000100
[2025-08-10 20:34:08,609][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062208] [Batch 03136/03692] [00:27:54/00:04:56, 0.534s/it]: train_loss_raw=0.7273, running_loss=0.7131, LR=0.000100
[2025-08-10 20:34:14,975][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062220] [Batch 03148/03692] [00:28:01/00:04:50, 0.534s/it]: train_loss_raw=0.7563, running_loss=0.7122, LR=0.000100
[2025-08-10 20:34:21,048][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062232] [Batch 03160/03692] [00:28:07/00:04:44, 0.534s/it]: train_loss_raw=0.6186, running_loss=0.7134, LR=0.000100
[2025-08-10 20:34:27,343][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062244] [Batch 03172/03692] [00:28:13/00:04:37, 0.534s/it]: train_loss_raw=0.7419, running_loss=0.7180, LR=0.000100
[2025-08-10 20:34:33,525][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062256] [Batch 03184/03692] [00:28:19/00:04:31, 0.534s/it]: train_loss_raw=0.7099, running_loss=0.7186, LR=0.000100
[2025-08-10 20:34:39,884][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062268] [Batch 03196/03692] [00:28:25/00:04:24, 0.534s/it]: train_loss_raw=0.8037, running_loss=0.7200, LR=0.000100
[2025-08-10 20:34:46,749][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062280] [Batch 03208/03692] [00:28:32/00:04:18, 0.534s/it]: train_loss_raw=0.6465, running_loss=0.7164, LR=0.000100
[2025-08-10 20:34:53,553][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062292] [Batch 03220/03692] [00:28:39/00:04:12, 0.534s/it]: train_loss_raw=0.7701, running_loss=0.7220, LR=0.000100
[2025-08-10 20:34:59,905][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062304] [Batch 03232/03692] [00:28:45/00:04:05, 0.534s/it]: train_loss_raw=0.7726, running_loss=0.7228, LR=0.000100
[2025-08-10 20:35:06,044][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062316] [Batch 03244/03692] [00:28:52/00:03:59, 0.534s/it]: train_loss_raw=0.7371, running_loss=0.7228, LR=0.000100
[2025-08-10 20:35:12,367][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062328] [Batch 03256/03692] [00:28:58/00:03:52, 0.534s/it]: train_loss_raw=0.6958, running_loss=0.7231, LR=0.000100
[2025-08-10 20:35:18,735][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062340] [Batch 03268/03692] [00:29:04/00:03:46, 0.534s/it]: train_loss_raw=0.7470, running_loss=0.7262, LR=0.000100
[2025-08-10 20:35:25,098][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062352] [Batch 03280/03692] [00:29:11/00:03:39, 0.534s/it]: train_loss_raw=0.8460, running_loss=0.7271, LR=0.000100
[2025-08-10 20:35:31,560][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062364] [Batch 03292/03692] [00:29:17/00:03:33, 0.534s/it]: train_loss_raw=0.8258, running_loss=0.7276, LR=0.000100
[2025-08-10 20:35:37,962][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062376] [Batch 03304/03692] [00:29:23/00:03:27, 0.534s/it]: train_loss_raw=0.6562, running_loss=0.7285, LR=0.000100
[2025-08-10 20:35:44,468][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062388] [Batch 03316/03692] [00:29:30/00:03:20, 0.534s/it]: train_loss_raw=0.7998, running_loss=0.7313, LR=0.000100
[2025-08-10 20:35:51,048][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062400] [Batch 03328/03692] [00:29:37/00:03:14, 0.534s/it]: train_loss_raw=0.7014, running_loss=0.7296, LR=0.000100
[2025-08-10 20:35:57,505][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062412] [Batch 03340/03692] [00:29:43/00:03:07, 0.534s/it]: train_loss_raw=0.6841, running_loss=0.7294, LR=0.000100
[2025-08-10 20:36:04,035][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062424] [Batch 03352/03692] [00:29:50/00:03:01, 0.534s/it]: train_loss_raw=0.7496, running_loss=0.7318, LR=0.000100
[2025-08-10 20:36:10,380][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062436] [Batch 03364/03692] [00:29:56/00:02:55, 0.534s/it]: train_loss_raw=0.6812, running_loss=0.7274, LR=0.000100
[2025-08-10 20:36:16,570][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062448] [Batch 03376/03692] [00:30:02/00:02:48, 0.534s/it]: train_loss_raw=0.7105, running_loss=0.7245, LR=0.000100
[2025-08-10 20:36:22,980][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062460] [Batch 03388/03692] [00:30:09/00:02:42, 0.534s/it]: train_loss_raw=0.6398, running_loss=0.7180, LR=0.000100
[2025-08-10 20:36:29,457][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062472] [Batch 03400/03692] [00:30:15/00:02:35, 0.534s/it]: train_loss_raw=0.8307, running_loss=0.7202, LR=0.000100
[2025-08-10 20:36:36,067][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062484] [Batch 03412/03692] [00:30:22/00:02:29, 0.534s/it]: train_loss_raw=0.7152, running_loss=0.7173, LR=0.000100
[2025-08-10 20:36:42,580][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062496] [Batch 03424/03692] [00:30:28/00:02:23, 0.534s/it]: train_loss_raw=0.5455, running_loss=0.7151, LR=0.000100
[2025-08-10 20:36:48,967][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062508] [Batch 03436/03692] [00:30:34/00:02:16, 0.534s/it]: train_loss_raw=0.8214, running_loss=0.7132, LR=0.000100
[2025-08-10 20:36:55,512][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062520] [Batch 03448/03692] [00:30:41/00:02:10, 0.534s/it]: train_loss_raw=0.6701, running_loss=0.7135, LR=0.000100
[2025-08-10 20:37:02,063][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062532] [Batch 03460/03692] [00:30:48/00:02:03, 0.534s/it]: train_loss_raw=0.7664, running_loss=0.7127, LR=0.000100
[2025-08-10 20:37:08,643][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062544] [Batch 03472/03692] [00:30:54/00:01:57, 0.534s/it]: train_loss_raw=0.7475, running_loss=0.7151, LR=0.000100
[2025-08-10 20:37:14,955][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062556] [Batch 03484/03692] [00:31:00/00:01:51, 0.534s/it]: train_loss_raw=0.6408, running_loss=0.7125, LR=0.000100
[2025-08-10 20:37:21,395][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062568] [Batch 03496/03692] [00:31:07/00:01:44, 0.534s/it]: train_loss_raw=0.6184, running_loss=0.7141, LR=0.000100
[2025-08-10 20:37:27,564][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062580] [Batch 03508/03692] [00:31:13/00:01:38, 0.534s/it]: train_loss_raw=0.7418, running_loss=0.7149, LR=0.000100
[2025-08-10 20:37:33,592][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062592] [Batch 03520/03692] [00:31:19/00:01:31, 0.534s/it]: train_loss_raw=0.6565, running_loss=0.7127, LR=0.000100
[2025-08-10 20:37:39,699][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062604] [Batch 03532/03692] [00:31:25/00:01:25, 0.534s/it]: train_loss_raw=0.7475, running_loss=0.7135, LR=0.000100
[2025-08-10 20:37:45,696][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062616] [Batch 03544/03692] [00:31:31/00:01:18, 0.534s/it]: train_loss_raw=0.7605, running_loss=0.7118, LR=0.000100
[2025-08-10 20:37:51,708][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062628] [Batch 03556/03692] [00:31:37/00:01:12, 0.534s/it]: train_loss_raw=0.8781, running_loss=0.7113, LR=0.000100
[2025-08-10 20:37:57,926][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062640] [Batch 03568/03692] [00:31:43/00:01:06, 0.534s/it]: train_loss_raw=0.7062, running_loss=0.7123, LR=0.000100
[2025-08-10 20:38:04,414][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062652] [Batch 03580/03692] [00:31:50/00:00:59, 0.534s/it]: train_loss_raw=0.8097, running_loss=0.7133, LR=0.000100
[2025-08-10 20:38:10,911][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062664] [Batch 03592/03692] [00:31:56/00:00:53, 0.534s/it]: train_loss_raw=0.5514, running_loss=0.7129, LR=0.000100
[2025-08-10 20:38:17,485][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062676] [Batch 03604/03692] [00:32:03/00:00:46, 0.534s/it]: train_loss_raw=0.6631, running_loss=0.7100, LR=0.000100
[2025-08-10 20:38:23,978][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062688] [Batch 03616/03692] [00:32:10/00:00:40, 0.534s/it]: train_loss_raw=0.8544, running_loss=0.7105, LR=0.000100
[2025-08-10 20:38:30,565][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062700] [Batch 03628/03692] [00:32:16/00:00:34, 0.534s/it]: train_loss_raw=0.6867, running_loss=0.7120, LR=0.000100
[2025-08-10 20:38:37,151][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062712] [Batch 03640/03692] [00:32:23/00:00:27, 0.534s/it]: train_loss_raw=0.7748, running_loss=0.7137, LR=0.000100
[2025-08-10 20:38:43,530][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062724] [Batch 03652/03692] [00:32:29/00:00:21, 0.534s/it]: train_loss_raw=0.6269, running_loss=0.7175, LR=0.000100
[2025-08-10 20:38:50,098][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062736] [Batch 03664/03692] [00:32:36/00:00:14, 0.534s/it]: train_loss_raw=0.7079, running_loss=0.7159, LR=0.000100
[2025-08-10 20:38:56,608][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062748] [Batch 03676/03692] [00:32:42/00:00:08, 0.534s/it]: train_loss_raw=0.6199, running_loss=0.7157, LR=0.000100
[2025-08-10 20:39:03,009][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 062760] [Batch 03688/03692] [00:32:49/00:00:02, 0.534s/it]: train_loss_raw=0.7386, running_loss=0.7171, LR=0.000100
[2025-08-10 20:39:10,001][__main__][INFO] - [VALIDATION] [Epoch 16/29] Starting validation.
[2025-08-10 20:39:41,288][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 062765] [Batch 00011/00025] [00:00:31/00:00:33, 2.607s/it]
[2025-08-10 20:39:55,845][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 062765] [Batch 00023/00025] [00:00:45/00:00:01, 1.910s/it]
[2025-08-10 20:39:56,916][__main__][INFO] - [VALIDATION] [Epoch 16/29] train_loss=0.71701, valid_loss=0.75668
[2025-08-10 20:39:56,917][__main__][INFO] - [VALIDATION] [Epoch 16/29] Metrics:
[2025-08-10 20:39:56,917][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_er      0.336
[2025-08-10 20:39:56,917][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_prec    0.423
[2025-08-10 20:39:56,917][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_recall  0.429
[2025-08-10 20:39:56,917][__main__][INFO] - [VALIDATION] [Epoch 16/29] - pep_recall 0.388
[2025-08-10 20:39:56,920][__main__][INFO] - [TRAIN] [Epoch 16/29] Epoch complete, total time 09:43:56, remaining time 07:26:32, 00:34:20 per epoch
[2025-08-10 20:40:01,912][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062772] [Batch 00008/03692] [00:00:03/00:27:55, 0.455s/it]: train_loss_raw=0.7188, running_loss=0.6134, LR=0.000100
[2025-08-10 20:40:07,993][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062784] [Batch 00020/03692] [00:00:09/00:29:44, 0.486s/it]: train_loss_raw=0.7543, running_loss=0.6273, LR=0.000100
[2025-08-10 20:40:14,216][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062796] [Batch 00032/03692] [00:00:15/00:30:23, 0.498s/it]: train_loss_raw=0.7996, running_loss=0.6384, LR=0.000100
[2025-08-10 20:40:20,265][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062808] [Batch 00044/03692] [00:00:21/00:30:23, 0.500s/it]: train_loss_raw=0.6897, running_loss=0.6461, LR=0.000100
[2025-08-10 20:40:26,282][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062820] [Batch 00056/03692] [00:00:28/00:30:18, 0.500s/it]: train_loss_raw=0.6916, running_loss=0.6556, LR=0.000100
[2025-08-10 20:40:32,529][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062832] [Batch 00068/03692] [00:00:34/00:30:25, 0.504s/it]: train_loss_raw=0.6693, running_loss=0.6597, LR=0.000100
[2025-08-10 20:40:38,798][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062844] [Batch 00080/03692] [00:00:40/00:30:29, 0.507s/it]: train_loss_raw=0.7739, running_loss=0.6645, LR=0.000100
[2025-08-10 20:40:44,800][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062856] [Batch 00092/03692] [00:00:46/00:30:20, 0.506s/it]: train_loss_raw=0.6347, running_loss=0.6687, LR=0.000100
[2025-08-10 20:40:50,790][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062868] [Batch 00104/03692] [00:00:52/00:30:11, 0.505s/it]: train_loss_raw=0.6215, running_loss=0.6701, LR=0.000100
[2025-08-10 20:40:56,845][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062880] [Batch 00116/03692] [00:00:58/00:30:05, 0.505s/it]: train_loss_raw=0.7300, running_loss=0.6729, LR=0.000100
[2025-08-10 20:41:03,008][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062892] [Batch 00128/03692] [00:01:04/00:30:02, 0.506s/it]: train_loss_raw=0.6208, running_loss=0.6791, LR=0.000100
[2025-08-10 20:41:09,319][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062904] [Batch 00140/03692] [00:01:11/00:30:02, 0.507s/it]: train_loss_raw=0.6984, running_loss=0.6822, LR=0.000100
[2025-08-10 20:41:15,518][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062916] [Batch 00152/03692] [00:01:17/00:29:58, 0.508s/it]: train_loss_raw=0.6978, running_loss=0.6865, LR=0.000100
[2025-08-10 20:41:21,800][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062928] [Batch 00164/03692] [00:01:23/00:29:56, 0.509s/it]: train_loss_raw=0.7355, running_loss=0.6895, LR=0.000100
[2025-08-10 20:41:28,079][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062940] [Batch 00176/03692] [00:01:29/00:29:54, 0.510s/it]: train_loss_raw=0.7320, running_loss=0.6933, LR=0.000100
[2025-08-10 20:41:34,104][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062952] [Batch 00188/03692] [00:01:35/00:29:46, 0.510s/it]: train_loss_raw=0.6528, running_loss=0.6947, LR=0.000100
[2025-08-10 20:41:40,211][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062964] [Batch 00200/03692] [00:01:41/00:29:39, 0.510s/it]: train_loss_raw=0.7060, running_loss=0.6981, LR=0.000100
[2025-08-10 20:41:46,465][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062976] [Batch 00212/03692] [00:01:48/00:29:35, 0.510s/it]: train_loss_raw=0.8623, running_loss=0.6975, LR=0.000100
[2025-08-10 20:41:52,655][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 062988] [Batch 00224/03692] [00:01:54/00:29:30, 0.511s/it]: train_loss_raw=0.8131, running_loss=0.6977, LR=0.000100
[2025-08-10 20:41:59,114][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063000] [Batch 00236/03692] [00:02:00/00:29:29, 0.512s/it]: train_loss_raw=0.7017, running_loss=0.6959, LR=0.000100
[2025-08-10 20:42:05,584][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063012] [Batch 00248/03692] [00:02:07/00:29:27, 0.513s/it]: train_loss_raw=0.6711, running_loss=0.6987, LR=0.000100
[2025-08-10 20:42:11,892][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063024] [Batch 00260/03692] [00:02:13/00:29:23, 0.514s/it]: train_loss_raw=0.7291, running_loss=0.7038, LR=0.000100
[2025-08-10 20:42:17,961][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063036] [Batch 00272/03692] [00:02:19/00:29:16, 0.514s/it]: train_loss_raw=0.8352, running_loss=0.6989, LR=0.000100
[2025-08-10 20:42:24,468][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063048] [Batch 00284/03692] [00:02:26/00:29:14, 0.515s/it]: train_loss_raw=0.6606, running_loss=0.7006, LR=0.000100
[2025-08-10 20:42:30,995][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063060] [Batch 00296/03692] [00:02:32/00:29:12, 0.516s/it]: train_loss_raw=0.7717, running_loss=0.7026, LR=0.000100
[2025-08-10 20:42:37,415][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063072] [Batch 00308/03692] [00:02:39/00:29:08, 0.517s/it]: train_loss_raw=0.7119, running_loss=0.7031, LR=0.000100
[2025-08-10 20:42:43,524][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063084] [Batch 00320/03692] [00:02:45/00:29:01, 0.516s/it]: train_loss_raw=0.5730, running_loss=0.7032, LR=0.000100
[2025-08-10 20:42:49,653][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063096] [Batch 00332/03692] [00:02:51/00:28:54, 0.516s/it]: train_loss_raw=0.5566, running_loss=0.6983, LR=0.000100
[2025-08-10 20:42:55,773][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063108] [Batch 00344/03692] [00:02:57/00:28:47, 0.516s/it]: train_loss_raw=0.7475, running_loss=0.7002, LR=0.000100
[2025-08-10 20:43:02,252][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063120] [Batch 00356/03692] [00:03:03/00:28:44, 0.517s/it]: train_loss_raw=0.6786, running_loss=0.6998, LR=0.000100
[2025-08-10 20:43:08,763][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063132] [Batch 00368/03692] [00:03:10/00:28:40, 0.518s/it]: train_loss_raw=0.6280, running_loss=0.6966, LR=0.000100
[2025-08-10 20:43:15,319][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063144] [Batch 00380/03692] [00:03:17/00:28:37, 0.519s/it]: train_loss_raw=0.8055, running_loss=0.7015, LR=0.000100
[2025-08-10 20:43:21,796][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063156] [Batch 00392/03692] [00:03:23/00:28:33, 0.519s/it]: train_loss_raw=0.7398, running_loss=0.7018, LR=0.000100
[2025-08-10 20:43:28,302][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063168] [Batch 00404/03692] [00:03:30/00:28:29, 0.520s/it]: train_loss_raw=0.6837, running_loss=0.7042, LR=0.000100
[2025-08-10 20:43:34,805][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063180] [Batch 00416/03692] [00:03:36/00:28:25, 0.521s/it]: train_loss_raw=0.7841, running_loss=0.7031, LR=0.000100
[2025-08-10 20:43:41,199][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063192] [Batch 00428/03692] [00:03:42/00:28:20, 0.521s/it]: train_loss_raw=0.6502, running_loss=0.7036, LR=0.000100
[2025-08-10 20:43:47,549][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063204] [Batch 00440/03692] [00:03:49/00:28:14, 0.521s/it]: train_loss_raw=0.6595, running_loss=0.7056, LR=0.000100
[2025-08-10 20:43:54,066][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063216] [Batch 00452/03692] [00:03:55/00:28:10, 0.522s/it]: train_loss_raw=0.6701, running_loss=0.7080, LR=0.000100
[2025-08-10 20:44:00,352][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063228] [Batch 00464/03692] [00:04:02/00:28:04, 0.522s/it]: train_loss_raw=0.7719, running_loss=0.7068, LR=0.000100
[2025-08-10 20:44:06,352][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063240] [Batch 00476/03692] [00:04:08/00:27:56, 0.521s/it]: train_loss_raw=0.6332, running_loss=0.7071, LR=0.000100
[2025-08-10 20:44:12,468][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063252] [Batch 00488/03692] [00:04:14/00:27:48, 0.521s/it]: train_loss_raw=0.8062, running_loss=0.7116, LR=0.000100
[2025-08-10 20:44:18,504][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063264] [Batch 00500/03692] [00:04:20/00:27:41, 0.520s/it]: train_loss_raw=0.7541, running_loss=0.7118, LR=0.000100
[2025-08-10 20:44:24,540][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063276] [Batch 00512/03692] [00:04:26/00:27:33, 0.520s/it]: train_loss_raw=0.7154, running_loss=0.7109, LR=0.000100
[2025-08-10 20:44:30,530][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063288] [Batch 00524/03692] [00:04:32/00:27:26, 0.520s/it]: train_loss_raw=0.7288, running_loss=0.7130, LR=0.000100
[2025-08-10 20:44:36,546][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063300] [Batch 00536/03692] [00:04:38/00:27:18, 0.519s/it]: train_loss_raw=0.7106, running_loss=0.7077, LR=0.000100
[2025-08-10 20:44:42,548][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063312] [Batch 00548/03692] [00:04:44/00:27:10, 0.519s/it]: train_loss_raw=0.6652, running_loss=0.7067, LR=0.000100
[2025-08-10 20:44:48,611][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063324] [Batch 00560/03692] [00:04:50/00:27:03, 0.518s/it]: train_loss_raw=0.6723, running_loss=0.7065, LR=0.000100
[2025-08-10 20:44:54,690][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063336] [Batch 00572/03692] [00:04:56/00:26:56, 0.518s/it]: train_loss_raw=0.8233, running_loss=0.7085, LR=0.000100
[2025-08-10 20:45:01,065][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063348] [Batch 00584/03692] [00:05:02/00:26:51, 0.518s/it]: train_loss_raw=0.8315, running_loss=0.7076, LR=0.000100
[2025-08-10 20:45:07,185][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063360] [Batch 00596/03692] [00:05:08/00:26:44, 0.518s/it]: train_loss_raw=0.6911, running_loss=0.7083, LR=0.000100
[2025-08-10 20:45:13,418][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063372] [Batch 00608/03692] [00:05:15/00:26:38, 0.518s/it]: train_loss_raw=0.7055, running_loss=0.7067, LR=0.000100
[2025-08-10 20:45:19,462][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063384] [Batch 00620/03692] [00:05:21/00:26:31, 0.518s/it]: train_loss_raw=0.7590, running_loss=0.7093, LR=0.000100
[2025-08-10 20:45:25,515][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063396] [Batch 00632/03692] [00:05:27/00:26:24, 0.518s/it]: train_loss_raw=0.6636, running_loss=0.7108, LR=0.000100
[2025-08-10 20:45:31,594][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063408] [Batch 00644/03692] [00:05:33/00:26:17, 0.518s/it]: train_loss_raw=0.7847, running_loss=0.7105, LR=0.000100
[2025-08-10 20:45:38,027][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063420] [Batch 00656/03692] [00:05:39/00:26:12, 0.518s/it]: train_loss_raw=0.7038, running_loss=0.7107, LR=0.000100
[2025-08-10 20:45:44,553][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063432] [Batch 00668/03692] [00:05:46/00:26:07, 0.518s/it]: train_loss_raw=0.6755, running_loss=0.7108, LR=0.000100
[2025-08-10 20:45:51,047][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063444] [Batch 00680/03692] [00:05:52/00:26:02, 0.519s/it]: train_loss_raw=0.7475, running_loss=0.7144, LR=0.000100
[2025-08-10 20:45:57,547][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063456] [Batch 00692/03692] [00:05:59/00:25:57, 0.519s/it]: train_loss_raw=0.7767, running_loss=0.7158, LR=0.000100
[2025-08-10 20:46:03,977][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063468] [Batch 00704/03692] [00:06:05/00:25:52, 0.519s/it]: train_loss_raw=0.8377, running_loss=0.7155, LR=0.000100
[2025-08-10 20:46:10,527][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063480] [Batch 00716/03692] [00:06:12/00:25:47, 0.520s/it]: train_loss_raw=0.6309, running_loss=0.7123, LR=0.000100
[2025-08-10 20:46:16,506][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063492] [Batch 00728/03692] [00:06:18/00:25:39, 0.520s/it]: train_loss_raw=0.6483, running_loss=0.7073, LR=0.000100
[2025-08-10 20:46:22,760][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063504] [Batch 00740/03692] [00:06:24/00:25:33, 0.520s/it]: train_loss_raw=0.6001, running_loss=0.7042, LR=0.000100
[2025-08-10 20:46:28,894][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063516] [Batch 00752/03692] [00:06:30/00:25:27, 0.519s/it]: train_loss_raw=0.7935, running_loss=0.7085, LR=0.000100
[2025-08-10 20:46:34,931][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063528] [Batch 00764/03692] [00:06:36/00:25:20, 0.519s/it]: train_loss_raw=0.6785, running_loss=0.7070, LR=0.000100
[2025-08-10 20:46:41,111][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063540] [Batch 00776/03692] [00:06:42/00:25:13, 0.519s/it]: train_loss_raw=0.6575, running_loss=0.7028, LR=0.000100
[2025-08-10 20:46:47,451][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063552] [Batch 00788/03692] [00:06:49/00:25:07, 0.519s/it]: train_loss_raw=0.6513, running_loss=0.7050, LR=0.000100
[2025-08-10 20:46:53,956][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063564] [Batch 00800/03692] [00:06:55/00:25:02, 0.520s/it]: train_loss_raw=0.8078, running_loss=0.7083, LR=0.000100
[2025-08-10 20:47:00,474][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063576] [Batch 00812/03692] [00:07:02/00:24:57, 0.520s/it]: train_loss_raw=0.8117, running_loss=0.7043, LR=0.000100
[2025-08-10 20:47:07,029][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063588] [Batch 00824/03692] [00:07:08/00:24:52, 0.520s/it]: train_loss_raw=0.6802, running_loss=0.7015, LR=0.000100
[2025-08-10 20:47:13,607][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063600] [Batch 00836/03692] [00:07:15/00:24:47, 0.521s/it]: train_loss_raw=0.7168, running_loss=0.7005, LR=0.000100
[2025-08-10 20:47:20,119][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063612] [Batch 00848/03692] [00:07:21/00:24:41, 0.521s/it]: train_loss_raw=0.7788, running_loss=0.6986, LR=0.000100
[2025-08-10 20:47:26,294][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063624] [Batch 00860/03692] [00:07:28/00:24:35, 0.521s/it]: train_loss_raw=0.6673, running_loss=0.6985, LR=0.000100
[2025-08-10 20:47:32,759][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063636] [Batch 00872/03692] [00:07:34/00:24:29, 0.521s/it]: train_loss_raw=0.6423, running_loss=0.6965, LR=0.000100
[2025-08-10 20:47:39,243][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063648] [Batch 00884/03692] [00:07:40/00:24:24, 0.521s/it]: train_loss_raw=0.6423, running_loss=0.6942, LR=0.000100
[2025-08-10 20:47:45,810][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063660] [Batch 00896/03692] [00:07:47/00:24:18, 0.522s/it]: train_loss_raw=0.5765, running_loss=0.6918, LR=0.000100
[2025-08-10 20:47:52,383][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063672] [Batch 00908/03692] [00:07:54/00:24:13, 0.522s/it]: train_loss_raw=0.7135, running_loss=0.6932, LR=0.000100
[2025-08-10 20:47:58,930][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063684] [Batch 00920/03692] [00:08:00/00:24:08, 0.522s/it]: train_loss_raw=0.7413, running_loss=0.6907, LR=0.000100
[2025-08-10 20:48:05,036][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063696] [Batch 00932/03692] [00:08:06/00:24:01, 0.522s/it]: train_loss_raw=0.7189, running_loss=0.6904, LR=0.000100
[2025-08-10 20:48:11,084][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063708] [Batch 00944/03692] [00:08:12/00:23:54, 0.522s/it]: train_loss_raw=0.7472, running_loss=0.6917, LR=0.000100
[2025-08-10 20:48:17,163][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063720] [Batch 00956/03692] [00:08:18/00:23:47, 0.522s/it]: train_loss_raw=0.7190, running_loss=0.6952, LR=0.000100
[2025-08-10 20:48:23,209][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063732] [Batch 00968/03692] [00:08:24/00:23:40, 0.522s/it]: train_loss_raw=0.6457, running_loss=0.6946, LR=0.000100
[2025-08-10 20:48:29,266][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063744] [Batch 00980/03692] [00:08:30/00:23:34, 0.521s/it]: train_loss_raw=0.6887, running_loss=0.6950, LR=0.000100
[2025-08-10 20:48:35,320][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063756] [Batch 00992/03692] [00:08:37/00:23:27, 0.521s/it]: train_loss_raw=0.7428, running_loss=0.6960, LR=0.000100
[2025-08-10 20:48:41,364][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063768] [Batch 01004/03692] [00:08:43/00:23:20, 0.521s/it]: train_loss_raw=0.7706, running_loss=0.6932, LR=0.000100
[2025-08-10 20:48:47,375][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063780] [Batch 01016/03692] [00:08:49/00:23:13, 0.521s/it]: train_loss_raw=0.6774, running_loss=0.6908, LR=0.000100
[2025-08-10 20:48:53,441][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063792] [Batch 01028/03692] [00:08:55/00:23:06, 0.521s/it]: train_loss_raw=0.8267, running_loss=0.6905, LR=0.000100
[2025-08-10 20:48:59,500][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063804] [Batch 01040/03692] [00:09:01/00:23:00, 0.520s/it]: train_loss_raw=0.6329, running_loss=0.6887, LR=0.000100
[2025-08-10 20:49:05,856][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063816] [Batch 01052/03692] [00:09:07/00:22:54, 0.521s/it]: train_loss_raw=0.7810, running_loss=0.6936, LR=0.000100
[2025-08-10 20:49:11,993][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063828] [Batch 01064/03692] [00:09:13/00:22:47, 0.520s/it]: train_loss_raw=0.5900, running_loss=0.6922, LR=0.000100
[2025-08-10 20:49:18,543][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063840] [Batch 01076/03692] [00:09:20/00:22:42, 0.521s/it]: train_loss_raw=0.6826, running_loss=0.6921, LR=0.000100
[2025-08-10 20:49:25,085][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063852] [Batch 01088/03692] [00:09:26/00:22:36, 0.521s/it]: train_loss_raw=0.6453, running_loss=0.6887, LR=0.000100
[2025-08-10 20:49:31,662][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063864] [Batch 01100/03692] [00:09:33/00:22:31, 0.521s/it]: train_loss_raw=0.6466, running_loss=0.6871, LR=0.000100
[2025-08-10 20:49:37,980][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063876] [Batch 01112/03692] [00:09:39/00:22:25, 0.521s/it]: train_loss_raw=0.6718, running_loss=0.6881, LR=0.000100
[2025-08-10 20:49:43,976][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063888] [Batch 01124/03692] [00:09:45/00:22:18, 0.521s/it]: train_loss_raw=0.6672, running_loss=0.6904, LR=0.000100
[2025-08-10 20:49:49,998][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063900] [Batch 01136/03692] [00:09:51/00:22:11, 0.521s/it]: train_loss_raw=0.5832, running_loss=0.6907, LR=0.000100
[2025-08-10 20:49:56,111][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063912] [Batch 01148/03692] [00:09:57/00:22:04, 0.521s/it]: train_loss_raw=0.6996, running_loss=0.6924, LR=0.000100
[2025-08-10 20:50:02,246][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063924] [Batch 01160/03692] [00:10:03/00:21:58, 0.521s/it]: train_loss_raw=0.6150, running_loss=0.6897, LR=0.000100
[2025-08-10 20:50:08,273][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063936] [Batch 01172/03692] [00:10:09/00:21:51, 0.520s/it]: train_loss_raw=0.7127, running_loss=0.6948, LR=0.000100
[2025-08-10 20:50:14,344][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063948] [Batch 01184/03692] [00:10:16/00:21:44, 0.520s/it]: train_loss_raw=0.5995, running_loss=0.6932, LR=0.000100
[2025-08-10 20:50:20,421][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063960] [Batch 01196/03692] [00:10:22/00:21:38, 0.520s/it]: train_loss_raw=0.6630, running_loss=0.6918, LR=0.000100
[2025-08-10 20:50:26,441][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063972] [Batch 01208/03692] [00:10:28/00:21:31, 0.520s/it]: train_loss_raw=0.7267, running_loss=0.6936, LR=0.000100
[2025-08-10 20:50:32,444][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063984] [Batch 01220/03692] [00:10:34/00:21:24, 0.520s/it]: train_loss_raw=0.6188, running_loss=0.6924, LR=0.000100
[2025-08-10 20:50:38,493][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 063996] [Batch 01232/03692] [00:10:40/00:21:18, 0.520s/it]: train_loss_raw=0.6911, running_loss=0.6900, LR=0.000100
[2025-08-10 20:50:49,112][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064008] [Batch 01244/03692] [00:10:50/00:21:20, 0.523s/it]: train_loss_raw=0.7221, running_loss=0.6882, LR=0.000100
[2025-08-10 20:50:55,662][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064020] [Batch 01256/03692] [00:10:57/00:21:14, 0.523s/it]: train_loss_raw=0.7828, running_loss=0.6892, LR=0.000100
[2025-08-10 20:51:02,227][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064032] [Batch 01268/03692] [00:11:03/00:21:09, 0.524s/it]: train_loss_raw=0.6879, running_loss=0.6899, LR=0.000100
[2025-08-10 20:51:08,813][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064044] [Batch 01280/03692] [00:11:10/00:21:03, 0.524s/it]: train_loss_raw=0.5908, running_loss=0.6866, LR=0.000100
[2025-08-10 20:51:15,332][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064056] [Batch 01292/03692] [00:11:17/00:20:57, 0.524s/it]: train_loss_raw=0.7938, running_loss=0.6851, LR=0.000100
[2025-08-10 20:51:21,824][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064068] [Batch 01304/03692] [00:11:23/00:20:51, 0.524s/it]: train_loss_raw=0.6892, running_loss=0.6876, LR=0.000100
[2025-08-10 20:51:28,395][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064080] [Batch 01316/03692] [00:11:30/00:20:45, 0.524s/it]: train_loss_raw=0.6759, running_loss=0.6861, LR=0.000100
[2025-08-10 20:51:35,019][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064092] [Batch 01328/03692] [00:11:36/00:20:40, 0.525s/it]: train_loss_raw=0.6314, running_loss=0.6847, LR=0.000100
[2025-08-10 20:51:41,158][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064104] [Batch 01340/03692] [00:11:42/00:20:33, 0.525s/it]: train_loss_raw=0.6873, running_loss=0.6885, LR=0.000100
[2025-08-10 20:51:47,268][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064116] [Batch 01352/03692] [00:11:48/00:20:27, 0.524s/it]: train_loss_raw=0.5927, running_loss=0.6887, LR=0.000100
[2025-08-10 20:51:53,261][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064128] [Batch 01364/03692] [00:11:54/00:20:20, 0.524s/it]: train_loss_raw=0.7005, running_loss=0.6860, LR=0.000100
[2025-08-10 20:51:59,305][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064140] [Batch 01376/03692] [00:12:01/00:20:13, 0.524s/it]: train_loss_raw=0.7436, running_loss=0.6890, LR=0.000100
[2025-08-10 20:52:05,389][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064152] [Batch 01388/03692] [00:12:07/00:20:06, 0.524s/it]: train_loss_raw=0.7242, running_loss=0.6885, LR=0.000100
[2025-08-10 20:52:11,653][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064164] [Batch 01400/03692] [00:12:13/00:20:00, 0.524s/it]: train_loss_raw=0.6146, running_loss=0.6893, LR=0.000100
[2025-08-10 20:52:18,159][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064176] [Batch 01412/03692] [00:12:19/00:19:54, 0.524s/it]: train_loss_raw=0.6497, running_loss=0.6908, LR=0.000100
[2025-08-10 20:52:24,701][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064188] [Batch 01424/03692] [00:12:26/00:19:48, 0.524s/it]: train_loss_raw=0.7665, running_loss=0.6919, LR=0.000100
[2025-08-10 20:52:31,197][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064200] [Batch 01436/03692] [00:12:32/00:19:42, 0.524s/it]: train_loss_raw=0.6026, running_loss=0.6954, LR=0.000100
[2025-08-10 20:52:37,509][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064212] [Batch 01448/03692] [00:12:39/00:19:36, 0.524s/it]: train_loss_raw=0.8020, running_loss=0.6933, LR=0.000100
[2025-08-10 20:52:43,565][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064224] [Batch 01460/03692] [00:12:45/00:19:29, 0.524s/it]: train_loss_raw=0.6528, running_loss=0.6926, LR=0.000100
[2025-08-10 20:52:49,943][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064236] [Batch 01472/03692] [00:12:51/00:19:23, 0.524s/it]: train_loss_raw=0.7268, running_loss=0.6913, LR=0.000100
[2025-08-10 20:52:55,961][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064248] [Batch 01484/03692] [00:12:57/00:19:17, 0.524s/it]: train_loss_raw=0.6679, running_loss=0.6928, LR=0.000100
[2025-08-10 20:53:02,002][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064260] [Batch 01496/03692] [00:13:03/00:19:10, 0.524s/it]: train_loss_raw=0.7762, running_loss=0.6941, LR=0.000100
[2025-08-10 20:53:07,973][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064272] [Batch 01508/03692] [00:13:09/00:19:03, 0.524s/it]: train_loss_raw=0.6777, running_loss=0.6931, LR=0.000100
[2025-08-10 20:53:13,975][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064284] [Batch 01520/03692] [00:13:15/00:18:57, 0.523s/it]: train_loss_raw=0.7247, running_loss=0.6924, LR=0.000100
[2025-08-10 20:53:20,014][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064296] [Batch 01532/03692] [00:13:21/00:18:50, 0.523s/it]: train_loss_raw=0.7190, running_loss=0.6910, LR=0.000100
[2025-08-10 20:53:26,242][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064308] [Batch 01544/03692] [00:13:27/00:18:44, 0.523s/it]: train_loss_raw=0.7708, running_loss=0.6900, LR=0.000100
[2025-08-10 20:53:32,898][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064320] [Batch 01556/03692] [00:13:34/00:18:38, 0.524s/it]: train_loss_raw=0.6739, running_loss=0.6931, LR=0.000100
[2025-08-10 20:53:39,522][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064332] [Batch 01568/03692] [00:13:41/00:18:32, 0.524s/it]: train_loss_raw=0.7900, running_loss=0.6934, LR=0.000100
[2025-08-10 20:53:46,052][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064344] [Batch 01580/03692] [00:13:47/00:18:26, 0.524s/it]: train_loss_raw=0.5786, running_loss=0.6882, LR=0.000100
[2025-08-10 20:53:52,644][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064356] [Batch 01592/03692] [00:13:54/00:18:20, 0.524s/it]: train_loss_raw=0.8428, running_loss=0.6924, LR=0.000100
[2025-08-10 20:53:59,047][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064368] [Batch 01604/03692] [00:14:00/00:18:14, 0.524s/it]: train_loss_raw=0.6777, running_loss=0.6896, LR=0.000100
[2025-08-10 20:54:05,402][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064380] [Batch 01616/03692] [00:14:07/00:18:08, 0.524s/it]: train_loss_raw=0.7836, running_loss=0.6919, LR=0.000100
[2025-08-10 20:54:11,397][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064392] [Batch 01628/03692] [00:14:13/00:18:01, 0.524s/it]: train_loss_raw=0.6406, running_loss=0.6913, LR=0.000100
[2025-08-10 20:54:17,440][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064404] [Batch 01640/03692] [00:14:19/00:17:55, 0.524s/it]: train_loss_raw=0.6522, running_loss=0.6928, LR=0.000100
[2025-08-10 20:54:23,516][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064416] [Batch 01652/03692] [00:14:25/00:17:48, 0.524s/it]: train_loss_raw=0.6780, running_loss=0.6907, LR=0.000100
[2025-08-10 20:54:29,736][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064428] [Batch 01664/03692] [00:14:31/00:17:42, 0.524s/it]: train_loss_raw=0.6635, running_loss=0.6853, LR=0.000100
[2025-08-10 20:54:35,890][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064440] [Batch 01676/03692] [00:14:37/00:17:35, 0.524s/it]: train_loss_raw=0.5196, running_loss=0.6877, LR=0.000100
[2025-08-10 20:54:41,950][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064452] [Batch 01688/03692] [00:14:43/00:17:29, 0.524s/it]: train_loss_raw=0.7753, running_loss=0.6880, LR=0.000100
[2025-08-10 20:54:48,059][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064464] [Batch 01700/03692] [00:14:49/00:17:22, 0.523s/it]: train_loss_raw=0.6693, running_loss=0.6904, LR=0.000100
[2025-08-10 20:54:54,341][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064476] [Batch 01712/03692] [00:14:56/00:17:16, 0.523s/it]: train_loss_raw=0.7567, running_loss=0.6896, LR=0.000100
[2025-08-10 20:55:00,907][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064488] [Batch 01724/03692] [00:15:02/00:17:10, 0.524s/it]: train_loss_raw=0.7033, running_loss=0.6860, LR=0.000100
[2025-08-10 20:55:07,402][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064500] [Batch 01736/03692] [00:15:09/00:17:04, 0.524s/it]: train_loss_raw=0.6313, running_loss=0.6864, LR=0.000100
[2025-08-10 20:55:13,973][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064512] [Batch 01748/03692] [00:15:15/00:16:58, 0.524s/it]: train_loss_raw=0.6504, running_loss=0.6840, LR=0.000100
[2025-08-10 20:55:20,385][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064524] [Batch 01760/03692] [00:15:22/00:16:52, 0.524s/it]: train_loss_raw=0.7145, running_loss=0.6809, LR=0.000100
[2025-08-10 20:55:26,626][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064536] [Batch 01772/03692] [00:15:28/00:16:45, 0.524s/it]: train_loss_raw=0.6435, running_loss=0.6823, LR=0.000100
[2025-08-10 20:55:32,997][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064548] [Batch 01784/03692] [00:15:34/00:16:39, 0.524s/it]: train_loss_raw=0.6572, running_loss=0.6831, LR=0.000100
[2025-08-10 20:55:39,335][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064560] [Batch 01796/03692] [00:15:41/00:16:33, 0.524s/it]: train_loss_raw=0.5963, running_loss=0.6793, LR=0.000100
[2025-08-10 20:55:45,696][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064572] [Batch 01808/03692] [00:15:47/00:16:27, 0.524s/it]: train_loss_raw=0.8099, running_loss=0.6828, LR=0.000100
[2025-08-10 20:55:52,015][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064584] [Batch 01820/03692] [00:15:53/00:16:20, 0.524s/it]: train_loss_raw=0.6327, running_loss=0.6847, LR=0.000100
[2025-08-10 20:55:58,442][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064596] [Batch 01832/03692] [00:16:00/00:16:14, 0.524s/it]: train_loss_raw=0.6725, running_loss=0.6857, LR=0.000100
[2025-08-10 20:56:04,977][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064608] [Batch 01844/03692] [00:16:06/00:16:08, 0.524s/it]: train_loss_raw=0.7841, running_loss=0.6899, LR=0.000100
[2025-08-10 20:56:11,424][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064620] [Batch 01856/03692] [00:16:13/00:16:02, 0.524s/it]: train_loss_raw=0.7858, running_loss=0.6893, LR=0.000100
[2025-08-10 20:56:17,982][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064632] [Batch 01868/03692] [00:16:19/00:15:56, 0.524s/it]: train_loss_raw=0.6151, running_loss=0.6872, LR=0.000100
[2025-08-10 20:56:24,326][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064644] [Batch 01880/03692] [00:16:26/00:15:50, 0.524s/it]: train_loss_raw=0.7382, running_loss=0.6881, LR=0.000100
[2025-08-10 20:56:30,529][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064656] [Batch 01892/03692] [00:16:32/00:15:44, 0.524s/it]: train_loss_raw=0.5710, running_loss=0.6835, LR=0.000100
[2025-08-10 20:56:36,677][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064668] [Batch 01904/03692] [00:16:38/00:15:37, 0.524s/it]: train_loss_raw=0.6210, running_loss=0.6799, LR=0.000100
[2025-08-10 20:56:43,027][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064680] [Batch 01916/03692] [00:16:44/00:15:31, 0.524s/it]: train_loss_raw=0.6103, running_loss=0.6786, LR=0.000100
[2025-08-10 20:56:49,402][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064692] [Batch 01928/03692] [00:16:51/00:15:25, 0.524s/it]: train_loss_raw=0.6252, running_loss=0.6799, LR=0.000100
[2025-08-10 20:56:55,777][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064704] [Batch 01940/03692] [00:16:57/00:15:18, 0.524s/it]: train_loss_raw=0.7144, running_loss=0.6799, LR=0.000100
[2025-08-10 20:57:01,785][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064716] [Batch 01952/03692] [00:17:03/00:15:12, 0.524s/it]: train_loss_raw=0.6090, running_loss=0.6824, LR=0.000100
[2025-08-10 20:57:07,965][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064728] [Batch 01964/03692] [00:17:09/00:15:05, 0.524s/it]: train_loss_raw=0.6174, running_loss=0.6822, LR=0.000100
[2025-08-10 20:57:14,486][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064740] [Batch 01976/03692] [00:17:16/00:14:59, 0.524s/it]: train_loss_raw=0.5785, running_loss=0.6815, LR=0.000100
[2025-08-10 20:57:21,029][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064752] [Batch 01988/03692] [00:17:22/00:14:53, 0.525s/it]: train_loss_raw=0.7344, running_loss=0.6789, LR=0.000100
[2025-08-10 20:57:27,584][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064764] [Batch 02000/03692] [00:17:29/00:14:47, 0.525s/it]: train_loss_raw=0.7437, running_loss=0.6827, LR=0.000100
[2025-08-10 20:57:34,149][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064776] [Batch 02012/03692] [00:17:35/00:14:41, 0.525s/it]: train_loss_raw=0.6478, running_loss=0.6831, LR=0.000100
[2025-08-10 20:57:40,438][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064788] [Batch 02024/03692] [00:17:42/00:14:35, 0.525s/it]: train_loss_raw=0.6333, running_loss=0.6829, LR=0.000100
[2025-08-10 20:57:46,464][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064800] [Batch 02036/03692] [00:17:48/00:14:28, 0.525s/it]: train_loss_raw=0.6644, running_loss=0.6810, LR=0.000100
[2025-08-10 20:57:52,681][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064812] [Batch 02048/03692] [00:17:54/00:14:22, 0.525s/it]: train_loss_raw=0.7383, running_loss=0.6823, LR=0.000100
[2025-08-10 20:57:59,098][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064824] [Batch 02060/03692] [00:18:00/00:14:16, 0.525s/it]: train_loss_raw=0.6988, running_loss=0.6832, LR=0.000100
[2025-08-10 20:58:05,625][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064836] [Batch 02072/03692] [00:18:07/00:14:10, 0.525s/it]: train_loss_raw=0.6943, running_loss=0.6843, LR=0.000100
[2025-08-10 20:58:12,155][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064848] [Batch 02084/03692] [00:18:13/00:14:04, 0.525s/it]: train_loss_raw=0.6355, running_loss=0.6849, LR=0.000100
[2025-08-10 20:58:18,728][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064860] [Batch 02096/03692] [00:18:20/00:13:57, 0.525s/it]: train_loss_raw=0.5554, running_loss=0.6832, LR=0.000100
[2025-08-10 20:58:25,217][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064872] [Batch 02108/03692] [00:18:26/00:13:51, 0.525s/it]: train_loss_raw=0.5723, running_loss=0.6835, LR=0.000100
[2025-08-10 20:58:31,548][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064884] [Batch 02120/03692] [00:18:33/00:13:45, 0.525s/it]: train_loss_raw=0.7107, running_loss=0.6823, LR=0.000100
[2025-08-10 20:58:37,959][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064896] [Batch 02132/03692] [00:18:39/00:13:39, 0.525s/it]: train_loss_raw=0.7121, running_loss=0.6811, LR=0.000100
[2025-08-10 20:58:44,061][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064908] [Batch 02144/03692] [00:18:45/00:13:32, 0.525s/it]: train_loss_raw=0.6606, running_loss=0.6821, LR=0.000100
[2025-08-10 20:58:50,192][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064920] [Batch 02156/03692] [00:18:51/00:13:26, 0.525s/it]: train_loss_raw=0.6482, running_loss=0.6826, LR=0.000100
[2025-08-10 20:59:10,314][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064932] [Batch 02168/03692] [00:19:12/00:13:29, 0.531s/it]: train_loss_raw=0.5749, running_loss=0.6804, LR=0.000100
[2025-08-10 20:59:16,859][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064944] [Batch 02180/03692] [00:19:18/00:13:23, 0.531s/it]: train_loss_raw=0.5361, running_loss=0.6809, LR=0.000100
[2025-08-10 20:59:23,371][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064956] [Batch 02192/03692] [00:19:25/00:13:17, 0.532s/it]: train_loss_raw=0.7791, running_loss=0.6812, LR=0.000100
[2025-08-10 20:59:29,838][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064968] [Batch 02204/03692] [00:19:31/00:13:10, 0.532s/it]: train_loss_raw=0.7120, running_loss=0.6788, LR=0.000100
[2025-08-10 20:59:35,888][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064980] [Batch 02216/03692] [00:19:37/00:13:04, 0.531s/it]: train_loss_raw=0.7375, running_loss=0.6796, LR=0.000100
[2025-08-10 20:59:42,017][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 064992] [Batch 02228/03692] [00:19:43/00:12:57, 0.531s/it]: train_loss_raw=0.7907, running_loss=0.6821, LR=0.000100
[2025-08-10 20:59:48,497][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065004] [Batch 02240/03692] [00:19:50/00:12:51, 0.531s/it]: train_loss_raw=0.7897, running_loss=0.6768, LR=0.000100
[2025-08-10 20:59:54,866][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065016] [Batch 02252/03692] [00:19:56/00:12:45, 0.531s/it]: train_loss_raw=0.7188, running_loss=0.6756, LR=0.000100
[2025-08-10 21:00:00,900][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065028] [Batch 02264/03692] [00:20:02/00:12:38, 0.531s/it]: train_loss_raw=0.5808, running_loss=0.6756, LR=0.000100
[2025-08-10 21:00:07,126][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065040] [Batch 02276/03692] [00:20:08/00:12:32, 0.531s/it]: train_loss_raw=0.6664, running_loss=0.6732, LR=0.000100
[2025-08-10 21:00:13,527][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065052] [Batch 02288/03692] [00:20:15/00:12:25, 0.531s/it]: train_loss_raw=0.5411, running_loss=0.6690, LR=0.000100
[2025-08-10 21:00:19,768][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065064] [Batch 02300/03692] [00:20:21/00:12:19, 0.531s/it]: train_loss_raw=0.6934, running_loss=0.6678, LR=0.000100
[2025-08-10 21:00:26,129][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065076] [Batch 02312/03692] [00:20:27/00:12:12, 0.531s/it]: train_loss_raw=0.5654, running_loss=0.6684, LR=0.000100
[2025-08-10 21:00:32,371][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065088] [Batch 02324/03692] [00:20:34/00:12:06, 0.531s/it]: train_loss_raw=0.6427, running_loss=0.6688, LR=0.000100
[2025-08-10 21:00:38,594][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065100] [Batch 02336/03692] [00:20:40/00:11:59, 0.531s/it]: train_loss_raw=0.5551, running_loss=0.6703, LR=0.000100
[2025-08-10 21:00:44,758][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065112] [Batch 02348/03692] [00:20:46/00:11:53, 0.531s/it]: train_loss_raw=0.6819, running_loss=0.6672, LR=0.000100
[2025-08-10 21:00:50,823][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065124] [Batch 02360/03692] [00:20:52/00:11:46, 0.531s/it]: train_loss_raw=0.7018, running_loss=0.6671, LR=0.000100
[2025-08-10 21:00:56,913][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065136] [Batch 02372/03692] [00:20:58/00:11:40, 0.531s/it]: train_loss_raw=0.5486, running_loss=0.6636, LR=0.000100
[2025-08-10 21:01:02,924][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065148] [Batch 02384/03692] [00:21:04/00:11:33, 0.530s/it]: train_loss_raw=0.6821, running_loss=0.6661, LR=0.000100
[2025-08-10 21:01:09,049][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065160] [Batch 02396/03692] [00:21:10/00:11:27, 0.530s/it]: train_loss_raw=0.6214, running_loss=0.6642, LR=0.000100
[2025-08-10 21:01:15,045][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065172] [Batch 02408/03692] [00:21:16/00:11:20, 0.530s/it]: train_loss_raw=0.6974, running_loss=0.6638, LR=0.000100
[2025-08-10 21:01:21,535][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065184] [Batch 02420/03692] [00:21:23/00:11:14, 0.530s/it]: train_loss_raw=0.6092, running_loss=0.6613, LR=0.000100
[2025-08-10 21:01:27,991][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065196] [Batch 02432/03692] [00:21:29/00:11:08, 0.530s/it]: train_loss_raw=0.6022, running_loss=0.6621, LR=0.000100
[2025-08-10 21:01:34,565][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065208] [Batch 02444/03692] [00:21:36/00:11:01, 0.530s/it]: train_loss_raw=0.9155, running_loss=0.6644, LR=0.000100
[2025-08-10 21:01:41,152][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065220] [Batch 02456/03692] [00:21:42/00:10:55, 0.530s/it]: train_loss_raw=0.6893, running_loss=0.6613, LR=0.000100
[2025-08-10 21:01:47,456][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065232] [Batch 02468/03692] [00:21:49/00:10:49, 0.530s/it]: train_loss_raw=0.6692, running_loss=0.6654, LR=0.000100
[2025-08-10 21:01:54,123][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065244] [Batch 02480/03692] [00:21:55/00:10:43, 0.531s/it]: train_loss_raw=0.7901, running_loss=0.6695, LR=0.000100
[2025-08-10 21:02:00,288][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065256] [Batch 02492/03692] [00:22:02/00:10:36, 0.531s/it]: train_loss_raw=0.6408, running_loss=0.6715, LR=0.000100
[2025-08-10 21:02:06,484][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065268] [Batch 02504/03692] [00:22:08/00:10:30, 0.530s/it]: train_loss_raw=0.6178, running_loss=0.6703, LR=0.000100
[2025-08-10 21:02:12,756][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065280] [Batch 02516/03692] [00:22:14/00:10:23, 0.530s/it]: train_loss_raw=0.6087, running_loss=0.6724, LR=0.000100
[2025-08-10 21:02:19,056][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065292] [Batch 02528/03692] [00:22:20/00:10:17, 0.530s/it]: train_loss_raw=0.7660, running_loss=0.6738, LR=0.000100
[2025-08-10 21:02:25,429][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065304] [Batch 02540/03692] [00:22:27/00:10:10, 0.530s/it]: train_loss_raw=0.6707, running_loss=0.6712, LR=0.000100
[2025-08-10 21:02:31,896][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065316] [Batch 02552/03692] [00:22:33/00:10:04, 0.530s/it]: train_loss_raw=0.7013, running_loss=0.6718, LR=0.000100
[2025-08-10 21:02:38,440][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065328] [Batch 02564/03692] [00:22:40/00:09:58, 0.530s/it]: train_loss_raw=0.5827, running_loss=0.6696, LR=0.000100
[2025-08-10 21:02:44,948][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065340] [Batch 02576/03692] [00:22:46/00:09:52, 0.531s/it]: train_loss_raw=0.6903, running_loss=0.6680, LR=0.000100
[2025-08-10 21:02:51,583][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065352] [Batch 02588/03692] [00:22:53/00:09:45, 0.531s/it]: train_loss_raw=0.6953, running_loss=0.6653, LR=0.000100
[2025-08-10 21:02:57,883][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065364] [Batch 02600/03692] [00:22:59/00:09:39, 0.531s/it]: train_loss_raw=0.6868, running_loss=0.6667, LR=0.000100
[2025-08-10 21:03:04,108][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065376] [Batch 02612/03692] [00:23:05/00:09:33, 0.531s/it]: train_loss_raw=0.6271, running_loss=0.6656, LR=0.000100
[2025-08-10 21:03:10,269][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065388] [Batch 02624/03692] [00:23:11/00:09:26, 0.530s/it]: train_loss_raw=0.6857, running_loss=0.6634, LR=0.000100
[2025-08-10 21:03:16,388][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065400] [Batch 02636/03692] [00:23:18/00:09:20, 0.530s/it]: train_loss_raw=0.6175, running_loss=0.6644, LR=0.000100
[2025-08-10 21:03:22,610][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065412] [Batch 02648/03692] [00:23:24/00:09:13, 0.530s/it]: train_loss_raw=0.6459, running_loss=0.6646, LR=0.000100
[2025-08-10 21:03:29,078][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065424] [Batch 02660/03692] [00:23:30/00:09:07, 0.530s/it]: train_loss_raw=0.6722, running_loss=0.6652, LR=0.000100
[2025-08-10 21:03:35,306][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065436] [Batch 02672/03692] [00:23:37/00:09:00, 0.530s/it]: train_loss_raw=0.5485, running_loss=0.6696, LR=0.000100
[2025-08-10 21:03:41,601][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065448] [Batch 02684/03692] [00:23:43/00:08:54, 0.530s/it]: train_loss_raw=0.6420, running_loss=0.6707, LR=0.000100
[2025-08-10 21:03:48,040][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065460] [Batch 02696/03692] [00:23:49/00:08:48, 0.530s/it]: train_loss_raw=0.7143, running_loss=0.6705, LR=0.000100
[2025-08-10 21:03:54,311][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065472] [Batch 02708/03692] [00:23:56/00:08:41, 0.530s/it]: train_loss_raw=0.6295, running_loss=0.6702, LR=0.000100
[2025-08-10 21:04:00,506][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065484] [Batch 02720/03692] [00:24:02/00:08:35, 0.530s/it]: train_loss_raw=0.7341, running_loss=0.6703, LR=0.000100
[2025-08-10 21:04:06,717][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065496] [Batch 02732/03692] [00:24:08/00:08:28, 0.530s/it]: train_loss_raw=0.7960, running_loss=0.6708, LR=0.000100
[2025-08-10 21:04:12,882][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065508] [Batch 02744/03692] [00:24:14/00:08:22, 0.530s/it]: train_loss_raw=0.6583, running_loss=0.6684, LR=0.000100
[2025-08-10 21:04:19,045][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065520] [Batch 02756/03692] [00:24:20/00:08:16, 0.530s/it]: train_loss_raw=0.7085, running_loss=0.6679, LR=0.000100
[2025-08-10 21:04:25,085][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065532] [Batch 02768/03692] [00:24:26/00:08:09, 0.530s/it]: train_loss_raw=0.7450, running_loss=0.6672, LR=0.000100
[2025-08-10 21:04:31,171][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065544] [Batch 02780/03692] [00:24:32/00:08:03, 0.530s/it]: train_loss_raw=0.6752, running_loss=0.6639, LR=0.000100
[2025-08-10 21:04:37,696][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065556] [Batch 02792/03692] [00:24:39/00:07:56, 0.530s/it]: train_loss_raw=0.5656, running_loss=0.6667, LR=0.000100
[2025-08-10 21:04:44,212][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065568] [Batch 02804/03692] [00:24:45/00:07:50, 0.530s/it]: train_loss_raw=0.6476, running_loss=0.6646, LR=0.000100
[2025-08-10 21:04:50,521][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065580] [Batch 02816/03692] [00:24:52/00:07:44, 0.530s/it]: train_loss_raw=0.6716, running_loss=0.6639, LR=0.000100
[2025-08-10 21:04:56,590][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065592] [Batch 02828/03692] [00:24:58/00:07:37, 0.530s/it]: train_loss_raw=0.5556, running_loss=0.6619, LR=0.000100
[2025-08-10 21:05:02,648][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065604] [Batch 02840/03692] [00:25:04/00:07:31, 0.530s/it]: train_loss_raw=0.7069, running_loss=0.6609, LR=0.000100
[2025-08-10 21:05:08,673][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065616] [Batch 02852/03692] [00:25:10/00:07:24, 0.530s/it]: train_loss_raw=0.5709, running_loss=0.6606, LR=0.000100
[2025-08-10 21:05:14,706][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065628] [Batch 02864/03692] [00:25:16/00:07:18, 0.529s/it]: train_loss_raw=0.7804, running_loss=0.6569, LR=0.000100
[2025-08-10 21:05:20,701][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065640] [Batch 02876/03692] [00:25:22/00:07:11, 0.529s/it]: train_loss_raw=0.6397, running_loss=0.6546, LR=0.000100
[2025-08-10 21:05:26,946][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065652] [Batch 02888/03692] [00:25:28/00:07:05, 0.529s/it]: train_loss_raw=0.7281, running_loss=0.6554, LR=0.000100
[2025-08-10 21:05:33,231][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065664] [Batch 02900/03692] [00:25:34/00:06:59, 0.529s/it]: train_loss_raw=0.6257, running_loss=0.6544, LR=0.000100
[2025-08-10 21:05:39,257][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065676] [Batch 02912/03692] [00:25:40/00:06:52, 0.529s/it]: train_loss_raw=0.6541, running_loss=0.6541, LR=0.000100
[2025-08-10 21:05:45,623][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065688] [Batch 02924/03692] [00:25:47/00:06:46, 0.529s/it]: train_loss_raw=0.6334, running_loss=0.6568, LR=0.000100
[2025-08-10 21:05:52,050][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065700] [Batch 02936/03692] [00:25:53/00:06:40, 0.529s/it]: train_loss_raw=0.6861, running_loss=0.6590, LR=0.000100
[2025-08-10 21:05:58,113][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065712] [Batch 02948/03692] [00:25:59/00:06:33, 0.529s/it]: train_loss_raw=0.6367, running_loss=0.6636, LR=0.000100
[2025-08-10 21:06:04,319][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065724] [Batch 02960/03692] [00:26:06/00:06:27, 0.529s/it]: train_loss_raw=0.6581, running_loss=0.6641, LR=0.000100
[2025-08-10 21:06:10,833][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065736] [Batch 02972/03692] [00:26:12/00:06:20, 0.529s/it]: train_loss_raw=0.5855, running_loss=0.6646, LR=0.000100
[2025-08-10 21:06:17,408][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065748] [Batch 02984/03692] [00:26:19/00:06:14, 0.529s/it]: train_loss_raw=0.6234, running_loss=0.6632, LR=0.000100
[2025-08-10 21:06:23,894][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065760] [Batch 02996/03692] [00:26:25/00:06:08, 0.529s/it]: train_loss_raw=0.5933, running_loss=0.6611, LR=0.000100
[2025-08-10 21:06:30,027][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065772] [Batch 03008/03692] [00:26:31/00:06:01, 0.529s/it]: train_loss_raw=0.5490, running_loss=0.6583, LR=0.000100
[2025-08-10 21:06:36,091][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065784] [Batch 03020/03692] [00:26:37/00:05:55, 0.529s/it]: train_loss_raw=0.5609, running_loss=0.6554, LR=0.000100
[2025-08-10 21:06:42,093][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065796] [Batch 03032/03692] [00:26:43/00:05:49, 0.529s/it]: train_loss_raw=0.6287, running_loss=0.6524, LR=0.000100
[2025-08-10 21:06:48,198][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065808] [Batch 03044/03692] [00:26:49/00:05:42, 0.529s/it]: train_loss_raw=0.5760, running_loss=0.6542, LR=0.000100
[2025-08-10 21:06:54,269][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065820] [Batch 03056/03692] [00:26:55/00:05:36, 0.529s/it]: train_loss_raw=0.7551, running_loss=0.6541, LR=0.000100
[2025-08-10 21:07:00,309][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065832] [Batch 03068/03692] [00:27:02/00:05:29, 0.529s/it]: train_loss_raw=0.7294, running_loss=0.6576, LR=0.000100
[2025-08-10 21:07:06,276][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065844] [Batch 03080/03692] [00:27:08/00:05:23, 0.529s/it]: train_loss_raw=0.5980, running_loss=0.6559, LR=0.000100
[2025-08-10 21:07:12,329][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065856] [Batch 03092/03692] [00:27:14/00:05:17, 0.528s/it]: train_loss_raw=0.6186, running_loss=0.6520, LR=0.000100
[2025-08-10 21:07:18,460][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065868] [Batch 03104/03692] [00:27:20/00:05:10, 0.528s/it]: train_loss_raw=0.7877, running_loss=0.6554, LR=0.000100
[2025-08-10 21:07:24,650][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065880] [Batch 03116/03692] [00:27:26/00:05:04, 0.528s/it]: train_loss_raw=0.6135, running_loss=0.6500, LR=0.000100
[2025-08-10 21:07:30,763][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065892] [Batch 03128/03692] [00:27:32/00:04:57, 0.528s/it]: train_loss_raw=0.7019, running_loss=0.6556, LR=0.000100
[2025-08-10 21:07:36,776][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065904] [Batch 03140/03692] [00:27:38/00:04:51, 0.528s/it]: train_loss_raw=0.6487, running_loss=0.6552, LR=0.000100
[2025-08-10 21:07:42,879][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065916] [Batch 03152/03692] [00:27:44/00:04:45, 0.528s/it]: train_loss_raw=0.5662, running_loss=0.6560, LR=0.000100
[2025-08-10 21:07:48,925][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065928] [Batch 03164/03692] [00:27:50/00:04:38, 0.528s/it]: train_loss_raw=0.6777, running_loss=0.6548, LR=0.000100
[2025-08-10 21:07:55,049][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065940] [Batch 03176/03692] [00:27:56/00:04:32, 0.528s/it]: train_loss_raw=0.6360, running_loss=0.6513, LR=0.000100
[2025-08-10 21:08:01,150][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065952] [Batch 03188/03692] [00:28:02/00:04:26, 0.528s/it]: train_loss_raw=0.5571, running_loss=0.6503, LR=0.000100
[2025-08-10 21:08:07,199][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065964] [Batch 03200/03692] [00:28:08/00:04:19, 0.528s/it]: train_loss_raw=0.6287, running_loss=0.6524, LR=0.000100
[2025-08-10 21:08:13,359][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065976] [Batch 03212/03692] [00:28:15/00:04:13, 0.528s/it]: train_loss_raw=0.6826, running_loss=0.6509, LR=0.000100
[2025-08-10 21:08:19,397][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 065988] [Batch 03224/03692] [00:28:21/00:04:06, 0.528s/it]: train_loss_raw=0.7002, running_loss=0.6532, LR=0.000100
[2025-08-10 21:08:25,615][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066000] [Batch 03236/03692] [00:28:27/00:04:00, 0.528s/it]: train_loss_raw=0.6764, running_loss=0.6510, LR=0.000100
[2025-08-10 21:08:37,376][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066012] [Batch 03248/03692] [00:28:39/00:03:55, 0.529s/it]: train_loss_raw=0.8334, running_loss=0.6546, LR=0.000100
[2025-08-10 21:08:43,696][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066024] [Batch 03260/03692] [00:28:45/00:03:48, 0.529s/it]: train_loss_raw=0.6140, running_loss=0.6507, LR=0.000100
[2025-08-10 21:08:49,880][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066036] [Batch 03272/03692] [00:28:51/00:03:42, 0.529s/it]: train_loss_raw=0.6714, running_loss=0.6531, LR=0.000100
[2025-08-10 21:08:55,880][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066048] [Batch 03284/03692] [00:28:57/00:03:35, 0.529s/it]: train_loss_raw=0.6158, running_loss=0.6518, LR=0.000100
[2025-08-10 21:09:01,929][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066060] [Batch 03296/03692] [00:29:03/00:03:29, 0.529s/it]: train_loss_raw=0.5352, running_loss=0.6507, LR=0.000100
[2025-08-10 21:09:07,915][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066072] [Batch 03308/03692] [00:29:09/00:03:23, 0.529s/it]: train_loss_raw=0.6848, running_loss=0.6492, LR=0.000100
[2025-08-10 21:09:13,972][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066084] [Batch 03320/03692] [00:29:15/00:03:16, 0.529s/it]: train_loss_raw=0.6210, running_loss=0.6472, LR=0.000100
[2025-08-10 21:09:20,054][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066096] [Batch 03332/03692] [00:29:21/00:03:10, 0.529s/it]: train_loss_raw=0.6886, running_loss=0.6506, LR=0.000100
[2025-08-10 21:09:26,057][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066108] [Batch 03344/03692] [00:29:27/00:03:03, 0.529s/it]: train_loss_raw=0.7137, running_loss=0.6482, LR=0.000100
[2025-08-10 21:09:32,080][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066120] [Batch 03356/03692] [00:29:33/00:02:57, 0.529s/it]: train_loss_raw=0.5902, running_loss=0.6490, LR=0.000100
[2025-08-10 21:09:38,142][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066132] [Batch 03368/03692] [00:29:39/00:02:51, 0.528s/it]: train_loss_raw=0.6693, running_loss=0.6533, LR=0.000100
[2025-08-10 21:09:44,239][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066144] [Batch 03380/03692] [00:29:45/00:02:44, 0.528s/it]: train_loss_raw=0.6212, running_loss=0.6583, LR=0.000100
[2025-08-10 21:09:50,548][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066156] [Batch 03392/03692] [00:29:52/00:02:38, 0.528s/it]: train_loss_raw=0.6754, running_loss=0.6581, LR=0.000100
[2025-08-10 21:09:56,808][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066168] [Batch 03404/03692] [00:29:58/00:02:32, 0.528s/it]: train_loss_raw=0.5703, running_loss=0.6587, LR=0.000100
[2025-08-10 21:10:03,253][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066180] [Batch 03416/03692] [00:30:04/00:02:25, 0.528s/it]: train_loss_raw=0.5559, running_loss=0.6570, LR=0.000100
[2025-08-10 21:10:09,852][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066192] [Batch 03428/03692] [00:30:11/00:02:19, 0.528s/it]: train_loss_raw=0.6591, running_loss=0.6565, LR=0.000100
[2025-08-10 21:10:16,243][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066204] [Batch 03440/03692] [00:30:17/00:02:13, 0.528s/it]: train_loss_raw=0.5746, running_loss=0.6562, LR=0.000100
[2025-08-10 21:10:22,744][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066216] [Batch 03452/03692] [00:30:24/00:02:06, 0.529s/it]: train_loss_raw=0.6411, running_loss=0.6555, LR=0.000100
[2025-08-10 21:10:29,245][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066228] [Batch 03464/03692] [00:30:30/00:02:00, 0.529s/it]: train_loss_raw=0.6916, running_loss=0.6545, LR=0.000100
[2025-08-10 21:10:35,753][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066240] [Batch 03476/03692] [00:30:37/00:01:54, 0.529s/it]: train_loss_raw=0.6086, running_loss=0.6501, LR=0.000100
[2025-08-10 21:10:42,014][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066252] [Batch 03488/03692] [00:30:43/00:01:47, 0.529s/it]: train_loss_raw=0.6889, running_loss=0.6527, LR=0.000100
[2025-08-10 21:10:48,301][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066264] [Batch 03500/03692] [00:30:50/00:01:41, 0.529s/it]: train_loss_raw=0.7382, running_loss=0.6565, LR=0.000100
[2025-08-10 21:10:54,523][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066276] [Batch 03512/03692] [00:30:56/00:01:35, 0.529s/it]: train_loss_raw=0.6577, running_loss=0.6599, LR=0.000100
[2025-08-10 21:11:00,639][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066288] [Batch 03524/03692] [00:31:02/00:01:28, 0.528s/it]: train_loss_raw=0.7243, running_loss=0.6619, LR=0.000100
[2025-08-10 21:11:06,683][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066300] [Batch 03536/03692] [00:31:08/00:01:22, 0.528s/it]: train_loss_raw=0.6839, running_loss=0.6610, LR=0.000100
[2025-08-10 21:11:12,716][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066312] [Batch 03548/03692] [00:31:14/00:01:16, 0.528s/it]: train_loss_raw=0.6666, running_loss=0.6620, LR=0.000100
[2025-08-10 21:11:18,854][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066324] [Batch 03560/03692] [00:31:20/00:01:09, 0.528s/it]: train_loss_raw=0.6138, running_loss=0.6602, LR=0.000100
[2025-08-10 21:11:24,958][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066336] [Batch 03572/03692] [00:31:26/00:01:03, 0.528s/it]: train_loss_raw=0.7195, running_loss=0.6620, LR=0.000100
[2025-08-10 21:11:31,399][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066348] [Batch 03584/03692] [00:31:33/00:00:57, 0.528s/it]: train_loss_raw=0.6646, running_loss=0.6638, LR=0.000100
[2025-08-10 21:11:37,592][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066360] [Batch 03596/03692] [00:31:39/00:00:50, 0.528s/it]: train_loss_raw=0.6468, running_loss=0.6609, LR=0.000100
[2025-08-10 21:11:44,165][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066372] [Batch 03608/03692] [00:31:45/00:00:44, 0.528s/it]: train_loss_raw=0.6231, running_loss=0.6597, LR=0.000100
[2025-08-10 21:11:50,379][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066384] [Batch 03620/03692] [00:31:52/00:00:38, 0.528s/it]: train_loss_raw=0.6676, running_loss=0.6558, LR=0.000100
[2025-08-10 21:11:56,691][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066396] [Batch 03632/03692] [00:31:58/00:00:31, 0.528s/it]: train_loss_raw=0.6455, running_loss=0.6558, LR=0.000100
[2025-08-10 21:12:02,745][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066408] [Batch 03644/03692] [00:32:04/00:00:25, 0.528s/it]: train_loss_raw=0.6901, running_loss=0.6557, LR=0.000100
[2025-08-10 21:12:08,856][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066420] [Batch 03656/03692] [00:32:10/00:00:19, 0.528s/it]: train_loss_raw=0.5953, running_loss=0.6512, LR=0.000100
[2025-08-10 21:12:15,382][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066432] [Batch 03668/03692] [00:32:17/00:00:12, 0.528s/it]: train_loss_raw=0.6809, running_loss=0.6476, LR=0.000100
[2025-08-10 21:12:21,824][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066444] [Batch 03680/03692] [00:32:23/00:00:06, 0.528s/it]: train_loss_raw=0.5882, running_loss=0.6524, LR=0.000100
[2025-08-10 21:12:53,293][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 066456] [Batch 03692/03692] [00:32:55/00:00:00, 0.535s/it]: train_loss_raw=0.5470, running_loss=0.6505, LR=0.000100
[2025-08-10 21:12:58,263][__main__][INFO] - [VALIDATION] [Epoch 17/29] Starting validation.
[2025-08-10 21:13:30,639][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 066457] [Batch 00011/00025] [00:00:32/00:00:35, 2.698s/it]
[2025-08-10 21:13:46,937][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 066457] [Batch 00023/00025] [00:00:48/00:00:02, 2.028s/it]
[2025-08-10 21:13:47,991][__main__][INFO] - [VALIDATION] [Epoch 17/29] train_loss=0.65046, valid_loss=0.70297
[2025-08-10 21:13:47,991][__main__][INFO] - [VALIDATION] [Epoch 17/29] Metrics:
[2025-08-10 21:13:47,991][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_er      0.312
[2025-08-10 21:13:47,991][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_prec    0.445
[2025-08-10 21:13:47,992][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_recall  0.451
[2025-08-10 21:13:47,992][__main__][INFO] - [VALIDATION] [Epoch 17/29] - pep_recall 0.435
[2025-08-10 21:13:47,995][__main__][INFO] - [TRAIN] [Epoch 17/29] Epoch complete, total time 10:17:47, remaining time 06:51:51, 00:34:19 per epoch
[2025-08-10 21:13:54,314][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066468] [Batch 00012/03692] [00:00:06/00:30:58, 0.505s/it]: train_loss_raw=0.6967, running_loss=0.5998, LR=0.000100
[2025-08-10 21:14:00,635][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066480] [Batch 00024/03692] [00:00:12/00:31:32, 0.516s/it]: train_loss_raw=0.5467, running_loss=0.5950, LR=0.000100
[2025-08-10 21:14:07,083][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066492] [Batch 00036/03692] [00:00:18/00:31:52, 0.523s/it]: train_loss_raw=0.4761, running_loss=0.5933, LR=0.000100
[2025-08-10 21:14:13,506][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066504] [Batch 00048/03692] [00:00:25/00:31:56, 0.526s/it]: train_loss_raw=0.5303, running_loss=0.5926, LR=0.000100
[2025-08-10 21:14:19,561][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066516] [Batch 00060/03692] [00:00:31/00:31:35, 0.522s/it]: train_loss_raw=0.6649, running_loss=0.5945, LR=0.000100
[2025-08-10 21:14:25,916][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066528] [Batch 00072/03692] [00:00:37/00:31:33, 0.523s/it]: train_loss_raw=0.5054, running_loss=0.5907, LR=0.000100
[2025-08-10 21:14:32,411][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066540] [Batch 00084/03692] [00:00:44/00:31:36, 0.526s/it]: train_loss_raw=0.5607, running_loss=0.5902, LR=0.000100
[2025-08-10 21:14:38,929][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066552] [Batch 00096/03692] [00:00:50/00:31:38, 0.528s/it]: train_loss_raw=0.6024, running_loss=0.5899, LR=0.000100
[2025-08-10 21:14:45,586][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066564] [Batch 00108/03692] [00:00:57/00:31:42, 0.531s/it]: train_loss_raw=0.5375, running_loss=0.5893, LR=0.000100
[2025-08-10 21:14:52,057][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066576] [Batch 00120/03692] [00:01:03/00:31:39, 0.532s/it]: train_loss_raw=0.4786, running_loss=0.5853, LR=0.000100
[2025-08-10 21:14:58,623][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066588] [Batch 00132/03692] [00:01:10/00:31:37, 0.533s/it]: train_loss_raw=0.5870, running_loss=0.5851, LR=0.000100
[2025-08-10 21:15:05,200][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066600] [Batch 00144/03692] [00:01:16/00:31:35, 0.534s/it]: train_loss_raw=0.6209, running_loss=0.5818, LR=0.000100
[2025-08-10 21:15:11,552][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066612] [Batch 00156/03692] [00:01:23/00:31:28, 0.534s/it]: train_loss_raw=0.6339, running_loss=0.5817, LR=0.000100
[2025-08-10 21:15:18,099][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066624] [Batch 00168/03692] [00:01:29/00:31:24, 0.535s/it]: train_loss_raw=0.6127, running_loss=0.5818, LR=0.000100
[2025-08-10 21:15:24,607][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066636] [Batch 00180/03692] [00:01:36/00:31:19, 0.535s/it]: train_loss_raw=0.5139, running_loss=0.5829, LR=0.000100
[2025-08-10 21:15:30,841][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066648] [Batch 00192/03692] [00:01:42/00:31:10, 0.534s/it]: train_loss_raw=0.4974, running_loss=0.5828, LR=0.000100
[2025-08-10 21:15:36,864][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066660] [Batch 00204/03692] [00:01:48/00:30:56, 0.532s/it]: train_loss_raw=0.5977, running_loss=0.5843, LR=0.000100
[2025-08-10 21:15:43,358][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066672] [Batch 00216/03692] [00:01:55/00:30:52, 0.533s/it]: train_loss_raw=0.6042, running_loss=0.5870, LR=0.000100
[2025-08-10 21:15:49,526][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066684] [Batch 00228/03692] [00:02:01/00:30:42, 0.532s/it]: train_loss_raw=0.7094, running_loss=0.5877, LR=0.000100
[2025-08-10 21:15:55,523][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066696] [Batch 00240/03692] [00:02:07/00:30:30, 0.530s/it]: train_loss_raw=0.5832, running_loss=0.5893, LR=0.000100
[2025-08-10 21:16:01,690][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066708] [Batch 00252/03692] [00:02:13/00:30:21, 0.530s/it]: train_loss_raw=0.5146, running_loss=0.5873, LR=0.000100
[2025-08-10 21:16:07,686][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066720] [Batch 00264/03692] [00:02:19/00:30:10, 0.528s/it]: train_loss_raw=0.6185, running_loss=0.5891, LR=0.000100
[2025-08-10 21:16:13,690][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066732] [Batch 00276/03692] [00:02:25/00:30:00, 0.527s/it]: train_loss_raw=0.5833, running_loss=0.5905, LR=0.000100
[2025-08-10 21:16:19,727][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066744] [Batch 00288/03692] [00:02:31/00:29:50, 0.526s/it]: train_loss_raw=0.5206, running_loss=0.5924, LR=0.000100
[2025-08-10 21:16:25,837][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066756] [Batch 00300/03692] [00:02:37/00:29:41, 0.525s/it]: train_loss_raw=0.5159, running_loss=0.5898, LR=0.000100
[2025-08-10 21:16:32,058][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066768] [Batch 00312/03692] [00:02:43/00:29:34, 0.525s/it]: train_loss_raw=0.5962, running_loss=0.5920, LR=0.000100
[2025-08-10 21:16:38,370][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066780] [Batch 00324/03692] [00:02:50/00:29:28, 0.525s/it]: train_loss_raw=0.5234, running_loss=0.5889, LR=0.000100
[2025-08-10 21:16:44,900][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066792] [Batch 00336/03692] [00:02:56/00:29:24, 0.526s/it]: train_loss_raw=0.7160, running_loss=0.5921, LR=0.000100
[2025-08-10 21:16:50,943][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066804] [Batch 00348/03692] [00:03:02/00:29:15, 0.525s/it]: train_loss_raw=0.5460, running_loss=0.5904, LR=0.000100
[2025-08-10 21:16:56,944][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066816] [Batch 00360/03692] [00:03:08/00:29:06, 0.524s/it]: train_loss_raw=0.5935, running_loss=0.5911, LR=0.000100
[2025-08-10 21:17:02,888][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066828] [Batch 00372/03692] [00:03:14/00:28:57, 0.523s/it]: train_loss_raw=0.6312, running_loss=0.5962, LR=0.000100
[2025-08-10 21:17:09,114][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066840] [Batch 00384/03692] [00:03:20/00:28:50, 0.523s/it]: train_loss_raw=0.5246, running_loss=0.5941, LR=0.000100
[2025-08-10 21:17:15,422][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066852] [Batch 00396/03692] [00:03:27/00:28:44, 0.523s/it]: train_loss_raw=0.5504, running_loss=0.5948, LR=0.000100
[2025-08-10 21:17:21,925][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066864] [Batch 00408/03692] [00:03:33/00:28:39, 0.524s/it]: train_loss_raw=0.6322, running_loss=0.5948, LR=0.000100
[2025-08-10 21:17:28,552][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066876] [Batch 00420/03692] [00:03:40/00:28:36, 0.525s/it]: train_loss_raw=0.5106, running_loss=0.5928, LR=0.000100
[2025-08-10 21:17:35,019][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066888] [Batch 00432/03692] [00:03:46/00:28:31, 0.525s/it]: train_loss_raw=0.6152, running_loss=0.5924, LR=0.000100
[2025-08-10 21:17:41,096][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066900] [Batch 00444/03692] [00:03:52/00:28:23, 0.524s/it]: train_loss_raw=0.6047, running_loss=0.5932, LR=0.000100
[2025-08-10 21:17:47,193][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066912] [Batch 00456/03692] [00:03:58/00:28:15, 0.524s/it]: train_loss_raw=0.6535, running_loss=0.5927, LR=0.000100
[2025-08-10 21:17:53,194][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066924] [Batch 00468/03692] [00:04:04/00:28:07, 0.523s/it]: train_loss_raw=0.5932, running_loss=0.5944, LR=0.000100
[2025-08-10 21:17:59,209][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066936] [Batch 00480/03692] [00:04:10/00:27:59, 0.523s/it]: train_loss_raw=0.6143, running_loss=0.5936, LR=0.000100
[2025-08-10 21:18:05,262][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066948] [Batch 00492/03692] [00:04:17/00:27:51, 0.522s/it]: train_loss_raw=0.4754, running_loss=0.5944, LR=0.000100
[2025-08-10 21:18:11,303][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066960] [Batch 00504/03692] [00:04:23/00:27:43, 0.522s/it]: train_loss_raw=0.6391, running_loss=0.5951, LR=0.000100
[2025-08-10 21:18:17,455][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066972] [Batch 00516/03692] [00:04:29/00:27:36, 0.522s/it]: train_loss_raw=0.5277, running_loss=0.5950, LR=0.000100
[2025-08-10 21:18:23,758][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066984] [Batch 00528/03692] [00:04:35/00:27:30, 0.522s/it]: train_loss_raw=0.6232, running_loss=0.5937, LR=0.000100
[2025-08-10 21:18:30,027][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 066996] [Batch 00540/03692] [00:04:41/00:27:24, 0.522s/it]: train_loss_raw=0.6289, running_loss=0.5968, LR=0.000100
[2025-08-10 21:18:36,057][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067008] [Batch 00552/03692] [00:04:47/00:27:17, 0.521s/it]: train_loss_raw=0.4937, running_loss=0.5928, LR=0.000100
[2025-08-10 21:18:42,255][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067020] [Batch 00564/03692] [00:04:53/00:27:10, 0.521s/it]: train_loss_raw=0.6122, running_loss=0.5914, LR=0.000100
[2025-08-10 21:18:48,814][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067032] [Batch 00576/03692] [00:05:00/00:27:05, 0.522s/it]: train_loss_raw=0.7149, running_loss=0.5983, LR=0.000100
[2025-08-10 21:18:55,182][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067044] [Batch 00588/03692] [00:05:06/00:27:00, 0.522s/it]: train_loss_raw=0.4769, running_loss=0.5967, LR=0.000100
[2025-08-10 21:19:01,359][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067056] [Batch 00600/03692] [00:05:13/00:26:53, 0.522s/it]: train_loss_raw=0.5390, running_loss=0.5984, LR=0.000100
[2025-08-10 21:19:07,685][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067068] [Batch 00612/03692] [00:05:19/00:26:47, 0.522s/it]: train_loss_raw=0.4626, running_loss=0.5953, LR=0.000100
[2025-08-10 21:19:14,259][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067080] [Batch 00624/03692] [00:05:26/00:26:42, 0.522s/it]: train_loss_raw=0.6062, running_loss=0.5954, LR=0.000100
[2025-08-10 21:19:20,658][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067092] [Batch 00636/03692] [00:05:32/00:26:37, 0.523s/it]: train_loss_raw=0.6354, running_loss=0.5945, LR=0.000100
[2025-08-10 21:19:26,671][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067104] [Batch 00648/03692] [00:05:38/00:26:29, 0.522s/it]: train_loss_raw=0.6168, running_loss=0.5961, LR=0.000100
[2025-08-10 21:19:32,971][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067116] [Batch 00660/03692] [00:05:44/00:26:23, 0.522s/it]: train_loss_raw=0.5545, running_loss=0.5922, LR=0.000100
[2025-08-10 21:19:39,057][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067128] [Batch 00672/03692] [00:05:50/00:26:16, 0.522s/it]: train_loss_raw=0.6104, running_loss=0.5926, LR=0.000100
[2025-08-10 21:19:45,077][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067140] [Batch 00684/03692] [00:05:56/00:26:09, 0.522s/it]: train_loss_raw=0.6927, running_loss=0.5942, LR=0.000100
[2025-08-10 21:19:51,336][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067152] [Batch 00696/03692] [00:06:03/00:26:02, 0.522s/it]: train_loss_raw=0.5159, running_loss=0.5950, LR=0.000100
[2025-08-10 21:19:57,913][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067164] [Batch 00708/03692] [00:06:09/00:25:57, 0.522s/it]: train_loss_raw=0.7648, running_loss=0.5996, LR=0.000100
[2025-08-10 21:20:04,420][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067176] [Batch 00720/03692] [00:06:16/00:25:52, 0.522s/it]: train_loss_raw=0.6584, running_loss=0.5990, LR=0.000100
[2025-08-10 21:20:10,475][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067188] [Batch 00732/03692] [00:06:22/00:25:45, 0.522s/it]: train_loss_raw=0.6551, running_loss=0.5977, LR=0.000100
[2025-08-10 21:20:16,498][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067200] [Batch 00744/03692] [00:06:28/00:25:38, 0.522s/it]: train_loss_raw=0.6259, running_loss=0.5992, LR=0.000100
[2025-08-10 21:20:22,562][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067212] [Batch 00756/03692] [00:06:34/00:25:31, 0.522s/it]: train_loss_raw=0.6644, running_loss=0.5976, LR=0.000100
[2025-08-10 21:20:28,598][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067224] [Batch 00768/03692] [00:06:40/00:25:24, 0.521s/it]: train_loss_raw=0.5570, running_loss=0.5975, LR=0.000100
[2025-08-10 21:20:34,678][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067236] [Batch 00780/03692] [00:06:46/00:25:17, 0.521s/it]: train_loss_raw=0.6193, running_loss=0.6007, LR=0.000100
[2025-08-10 21:20:40,943][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067248] [Batch 00792/03692] [00:06:52/00:25:11, 0.521s/it]: train_loss_raw=0.5924, running_loss=0.6017, LR=0.000100
[2025-08-10 21:20:47,275][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067260] [Batch 00804/03692] [00:06:59/00:25:05, 0.521s/it]: train_loss_raw=0.5960, running_loss=0.6019, LR=0.000100
[2025-08-10 21:20:53,785][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067272] [Batch 00816/03692] [00:07:05/00:24:59, 0.521s/it]: train_loss_raw=0.5929, running_loss=0.5969, LR=0.000100
[2025-08-10 21:21:00,249][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067284] [Batch 00828/03692] [00:07:11/00:24:54, 0.522s/it]: train_loss_raw=0.5260, running_loss=0.5974, LR=0.000100
[2025-08-10 21:21:06,780][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067296] [Batch 00840/03692] [00:07:18/00:24:48, 0.522s/it]: train_loss_raw=0.6386, running_loss=0.5951, LR=0.000100
[2025-08-10 21:21:13,000][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067308] [Batch 00852/03692] [00:07:24/00:24:42, 0.522s/it]: train_loss_raw=0.7013, running_loss=0.5922, LR=0.000100
[2025-08-10 21:21:19,000][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067320] [Batch 00864/03692] [00:07:30/00:24:35, 0.522s/it]: train_loss_raw=0.5667, running_loss=0.5922, LR=0.000100
[2025-08-10 21:21:24,995][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067332] [Batch 00876/03692] [00:07:36/00:24:28, 0.521s/it]: train_loss_raw=0.6165, running_loss=0.5939, LR=0.000100
[2025-08-10 21:21:31,108][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067344] [Batch 00888/03692] [00:07:42/00:24:21, 0.521s/it]: train_loss_raw=0.6181, running_loss=0.5922, LR=0.000100
[2025-08-10 21:21:37,346][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067356] [Batch 00900/03692] [00:07:49/00:24:15, 0.521s/it]: train_loss_raw=0.5446, running_loss=0.5933, LR=0.000100
[2025-08-10 21:21:43,345][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067368] [Batch 00912/03692] [00:07:55/00:24:08, 0.521s/it]: train_loss_raw=0.6103, running_loss=0.5933, LR=0.000100
[2025-08-10 21:21:49,367][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067380] [Batch 00924/03692] [00:08:01/00:24:01, 0.521s/it]: train_loss_raw=0.6064, running_loss=0.5929, LR=0.000100
[2025-08-10 21:21:55,543][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067392] [Batch 00936/03692] [00:08:07/00:23:54, 0.521s/it]: train_loss_raw=0.5173, running_loss=0.5937, LR=0.000100
[2025-08-10 21:22:01,873][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067404] [Batch 00948/03692] [00:08:13/00:23:48, 0.521s/it]: train_loss_raw=0.5834, running_loss=0.5987, LR=0.000100
[2025-08-10 21:22:08,463][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067416] [Batch 00960/03692] [00:08:20/00:23:43, 0.521s/it]: train_loss_raw=0.5662, running_loss=0.5951, LR=0.000100
[2025-08-10 21:22:15,059][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067428] [Batch 00972/03692] [00:08:26/00:23:38, 0.521s/it]: train_loss_raw=0.6872, running_loss=0.5972, LR=0.000100
[2025-08-10 21:22:21,399][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067440] [Batch 00984/03692] [00:08:33/00:23:32, 0.521s/it]: train_loss_raw=0.6810, running_loss=0.5970, LR=0.000100
[2025-08-10 21:22:27,430][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067452] [Batch 00996/03692] [00:08:39/00:23:25, 0.521s/it]: train_loss_raw=0.7129, running_loss=0.5990, LR=0.000100
[2025-08-10 21:22:33,590][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067464] [Batch 01008/03692] [00:08:45/00:23:18, 0.521s/it]: train_loss_raw=0.5884, running_loss=0.5997, LR=0.000100
[2025-08-10 21:22:39,771][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067476] [Batch 01020/03692] [00:08:51/00:23:12, 0.521s/it]: train_loss_raw=0.5759, running_loss=0.5996, LR=0.000100
[2025-08-10 21:22:45,905][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067488] [Batch 01032/03692] [00:08:57/00:23:05, 0.521s/it]: train_loss_raw=0.5264, running_loss=0.6011, LR=0.000100
[2025-08-10 21:22:52,061][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067500] [Batch 01044/03692] [00:09:03/00:22:59, 0.521s/it]: train_loss_raw=0.5680, running_loss=0.5993, LR=0.000100
[2025-08-10 21:22:58,402][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067512] [Batch 01056/03692] [00:09:10/00:22:53, 0.521s/it]: train_loss_raw=0.5760, running_loss=0.5976, LR=0.000100
[2025-08-10 21:23:04,826][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067524] [Batch 01068/03692] [00:09:16/00:22:47, 0.521s/it]: train_loss_raw=0.6269, running_loss=0.5979, LR=0.000100
[2025-08-10 21:23:10,935][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067536] [Batch 01080/03692] [00:09:22/00:22:40, 0.521s/it]: train_loss_raw=0.6024, running_loss=0.5923, LR=0.000100
[2025-08-10 21:23:16,977][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067548] [Batch 01092/03692] [00:09:28/00:22:34, 0.521s/it]: train_loss_raw=0.5752, running_loss=0.5899, LR=0.000100
[2025-08-10 21:23:23,346][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067560] [Batch 01104/03692] [00:09:35/00:22:28, 0.521s/it]: train_loss_raw=0.5686, running_loss=0.5909, LR=0.000100
[2025-08-10 21:23:29,848][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067572] [Batch 01116/03692] [00:09:41/00:22:22, 0.521s/it]: train_loss_raw=0.6433, running_loss=0.5917, LR=0.000100
[2025-08-10 21:23:36,196][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067584] [Batch 01128/03692] [00:09:47/00:22:16, 0.521s/it]: train_loss_raw=0.6371, running_loss=0.5900, LR=0.000100
[2025-08-10 21:23:42,611][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067596] [Batch 01140/03692] [00:09:54/00:22:10, 0.521s/it]: train_loss_raw=0.5291, running_loss=0.5929, LR=0.000100
[2025-08-10 21:23:49,063][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067608] [Batch 01152/03692] [00:10:00/00:22:04, 0.522s/it]: train_loss_raw=0.5706, running_loss=0.5938, LR=0.000100
[2025-08-10 21:23:55,026][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067620] [Batch 01164/03692] [00:10:06/00:21:57, 0.521s/it]: train_loss_raw=0.6967, running_loss=0.5955, LR=0.000100
[2025-08-10 21:24:01,078][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067632] [Batch 01176/03692] [00:10:12/00:21:51, 0.521s/it]: train_loss_raw=0.6768, running_loss=0.5956, LR=0.000100
[2025-08-10 21:24:07,108][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067644] [Batch 01188/03692] [00:10:18/00:21:44, 0.521s/it]: train_loss_raw=0.5807, running_loss=0.5979, LR=0.000100
[2025-08-10 21:24:13,520][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067656] [Batch 01200/03692] [00:10:25/00:21:38, 0.521s/it]: train_loss_raw=0.6577, running_loss=0.6011, LR=0.000100
[2025-08-10 21:24:20,018][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067668] [Batch 01212/03692] [00:10:31/00:21:32, 0.521s/it]: train_loss_raw=0.6299, running_loss=0.6023, LR=0.000100
[2025-08-10 21:24:26,074][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067680] [Batch 01224/03692] [00:10:37/00:21:26, 0.521s/it]: train_loss_raw=0.5660, running_loss=0.6027, LR=0.000100
[2025-08-10 21:24:32,157][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067692] [Batch 01236/03692] [00:10:43/00:21:19, 0.521s/it]: train_loss_raw=0.6312, running_loss=0.6039, LR=0.000100
[2025-08-10 21:24:38,198][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067704] [Batch 01248/03692] [00:10:49/00:21:12, 0.521s/it]: train_loss_raw=0.6191, running_loss=0.6034, LR=0.000100
[2025-08-10 21:24:44,315][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067716] [Batch 01260/03692] [00:10:56/00:21:06, 0.521s/it]: train_loss_raw=0.5083, running_loss=0.6033, LR=0.000100
[2025-08-10 21:24:50,458][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067728] [Batch 01272/03692] [00:11:02/00:20:59, 0.521s/it]: train_loss_raw=0.5264, running_loss=0.6018, LR=0.000100
[2025-08-10 21:24:56,476][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067740] [Batch 01284/03692] [00:11:08/00:20:53, 0.520s/it]: train_loss_raw=0.5216, running_loss=0.6041, LR=0.000100
[2025-08-10 21:25:02,491][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067752] [Batch 01296/03692] [00:11:14/00:20:46, 0.520s/it]: train_loss_raw=0.6002, running_loss=0.6057, LR=0.000100
[2025-08-10 21:25:08,591][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067764] [Batch 01308/03692] [00:11:20/00:20:40, 0.520s/it]: train_loss_raw=0.7105, running_loss=0.6047, LR=0.000100
[2025-08-10 21:25:14,590][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067776] [Batch 01320/03692] [00:11:26/00:20:33, 0.520s/it]: train_loss_raw=0.6173, running_loss=0.6057, LR=0.000100
[2025-08-10 21:25:20,585][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067788] [Batch 01332/03692] [00:11:32/00:20:26, 0.520s/it]: train_loss_raw=0.5512, running_loss=0.6075, LR=0.000100
[2025-08-10 21:25:26,763][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067800] [Batch 01344/03692] [00:11:38/00:20:20, 0.520s/it]: train_loss_raw=0.5659, running_loss=0.6065, LR=0.000100
[2025-08-10 21:25:33,202][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067812] [Batch 01356/03692] [00:11:44/00:20:14, 0.520s/it]: train_loss_raw=0.4994, running_loss=0.6026, LR=0.000100
[2025-08-10 21:25:39,424][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067824] [Batch 01368/03692] [00:11:51/00:20:08, 0.520s/it]: train_loss_raw=0.7078, running_loss=0.6048, LR=0.000100
[2025-08-10 21:25:45,576][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067836] [Batch 01380/03692] [00:11:57/00:20:01, 0.520s/it]: train_loss_raw=0.6636, running_loss=0.6043, LR=0.000100
[2025-08-10 21:25:51,762][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067848] [Batch 01392/03692] [00:12:03/00:19:55, 0.520s/it]: train_loss_raw=0.7231, running_loss=0.6036, LR=0.000100
[2025-08-10 21:25:57,806][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067860] [Batch 01404/03692] [00:12:09/00:19:48, 0.520s/it]: train_loss_raw=0.6005, running_loss=0.6037, LR=0.000100
[2025-08-10 21:26:03,907][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067872] [Batch 01416/03692] [00:12:15/00:19:42, 0.520s/it]: train_loss_raw=0.5090, running_loss=0.6018, LR=0.000100
[2025-08-10 21:26:09,975][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067884] [Batch 01428/03692] [00:12:21/00:19:35, 0.519s/it]: train_loss_raw=0.6145, running_loss=0.6026, LR=0.000100
[2025-08-10 21:26:16,057][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067896] [Batch 01440/03692] [00:12:27/00:19:29, 0.519s/it]: train_loss_raw=0.6770, running_loss=0.6037, LR=0.000100
[2025-08-10 21:26:22,047][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067908] [Batch 01452/03692] [00:12:33/00:19:22, 0.519s/it]: train_loss_raw=0.6837, running_loss=0.6011, LR=0.000100
[2025-08-10 21:26:28,130][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067920] [Batch 01464/03692] [00:12:39/00:19:16, 0.519s/it]: train_loss_raw=0.5359, running_loss=0.6044, LR=0.000100
[2025-08-10 21:26:34,508][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067932] [Batch 01476/03692] [00:12:46/00:19:10, 0.519s/it]: train_loss_raw=0.6365, running_loss=0.6035, LR=0.000100
[2025-08-10 21:26:41,124][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067944] [Batch 01488/03692] [00:12:52/00:19:04, 0.519s/it]: train_loss_raw=0.4819, running_loss=0.6036, LR=0.000100
[2025-08-10 21:26:47,620][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067956] [Batch 01500/03692] [00:12:59/00:18:58, 0.520s/it]: train_loss_raw=0.6372, running_loss=0.6041, LR=0.000100
[2025-08-10 21:26:54,121][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067968] [Batch 01512/03692] [00:13:05/00:18:53, 0.520s/it]: train_loss_raw=0.5350, running_loss=0.6020, LR=0.000100
[2025-08-10 21:27:00,666][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067980] [Batch 01524/03692] [00:13:12/00:18:47, 0.520s/it]: train_loss_raw=0.6469, running_loss=0.5982, LR=0.000100
[2025-08-10 21:27:30,475][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 067992] [Batch 01536/03692] [00:13:42/00:19:14, 0.535s/it]: train_loss_raw=0.7827, running_loss=0.6027, LR=0.000100
[2025-08-10 21:27:42,397][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068004] [Batch 01548/03692] [00:13:54/00:19:15, 0.539s/it]: train_loss_raw=0.5371, running_loss=0.6060, LR=0.000100
[2025-08-10 21:27:48,621][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068016] [Batch 01560/03692] [00:14:00/00:19:08, 0.539s/it]: train_loss_raw=0.5673, running_loss=0.6084, LR=0.000100
[2025-08-10 21:27:54,887][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068028] [Batch 01572/03692] [00:14:06/00:19:01, 0.539s/it]: train_loss_raw=0.7071, running_loss=0.6106, LR=0.000100
[2025-08-10 21:28:01,419][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068040] [Batch 01584/03692] [00:14:13/00:18:55, 0.539s/it]: train_loss_raw=0.5404, running_loss=0.6118, LR=0.000100
[2025-08-10 21:28:07,497][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068052] [Batch 01596/03692] [00:14:19/00:18:48, 0.538s/it]: train_loss_raw=0.6293, running_loss=0.6090, LR=0.000100
[2025-08-10 21:28:13,563][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068064] [Batch 01608/03692] [00:14:25/00:18:41, 0.538s/it]: train_loss_raw=0.6389, running_loss=0.6072, LR=0.000100
[2025-08-10 21:28:19,610][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068076] [Batch 01620/03692] [00:14:31/00:18:34, 0.538s/it]: train_loss_raw=0.6104, running_loss=0.6112, LR=0.000100
[2025-08-10 21:28:25,606][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068088] [Batch 01632/03692] [00:14:37/00:18:27, 0.538s/it]: train_loss_raw=0.5683, running_loss=0.6101, LR=0.000100
[2025-08-10 21:28:31,648][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068100] [Batch 01644/03692] [00:14:43/00:18:20, 0.537s/it]: train_loss_raw=0.6947, running_loss=0.6113, LR=0.000100
[2025-08-10 21:28:37,706][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068112] [Batch 01656/03692] [00:14:49/00:18:13, 0.537s/it]: train_loss_raw=0.5834, running_loss=0.6070, LR=0.000100
[2025-08-10 21:28:43,852][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068124] [Batch 01668/03692] [00:14:55/00:18:06, 0.537s/it]: train_loss_raw=0.5567, running_loss=0.6097, LR=0.000100
[2025-08-10 21:28:50,394][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068136] [Batch 01680/03692] [00:15:02/00:18:00, 0.537s/it]: train_loss_raw=0.5017, running_loss=0.6116, LR=0.000100
[2025-08-10 21:28:56,564][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068148] [Batch 01692/03692] [00:15:08/00:17:53, 0.537s/it]: train_loss_raw=0.6240, running_loss=0.6113, LR=0.000100
[2025-08-10 21:29:02,810][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068160] [Batch 01704/03692] [00:15:14/00:17:46, 0.537s/it]: train_loss_raw=0.6222, running_loss=0.6109, LR=0.000100
[2025-08-10 21:29:08,878][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068172] [Batch 01716/03692] [00:15:20/00:17:40, 0.536s/it]: train_loss_raw=0.5150, running_loss=0.6098, LR=0.000100
[2025-08-10 21:29:14,900][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068184] [Batch 01728/03692] [00:15:26/00:17:33, 0.536s/it]: train_loss_raw=0.6158, running_loss=0.6102, LR=0.000100
[2025-08-10 21:29:20,927][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068196] [Batch 01740/03692] [00:15:32/00:17:26, 0.536s/it]: train_loss_raw=0.6007, running_loss=0.6081, LR=0.000100
[2025-08-10 21:29:27,455][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068208] [Batch 01752/03692] [00:15:39/00:17:19, 0.536s/it]: train_loss_raw=0.5948, running_loss=0.6146, LR=0.000100
[2025-08-10 21:29:33,590][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068220] [Batch 01764/03692] [00:15:45/00:17:13, 0.536s/it]: train_loss_raw=0.5762, running_loss=0.6163, LR=0.000100
[2025-08-10 21:29:39,852][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068232] [Batch 01776/03692] [00:15:51/00:17:06, 0.536s/it]: train_loss_raw=0.6646, running_loss=0.6174, LR=0.000100
[2025-08-10 21:29:46,322][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068244] [Batch 01788/03692] [00:15:58/00:17:00, 0.536s/it]: train_loss_raw=0.6472, running_loss=0.6178, LR=0.000100
[2025-08-10 21:29:52,872][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068256] [Batch 01800/03692] [00:16:04/00:16:53, 0.536s/it]: train_loss_raw=0.5670, running_loss=0.6188, LR=0.000100
[2025-08-10 21:29:59,065][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068268] [Batch 01812/03692] [00:16:10/00:16:47, 0.536s/it]: train_loss_raw=0.5150, running_loss=0.6174, LR=0.000100
[2025-08-10 21:30:05,236][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068280] [Batch 01824/03692] [00:16:16/00:16:40, 0.536s/it]: train_loss_raw=0.5660, running_loss=0.6165, LR=0.000100
[2025-08-10 21:30:11,712][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068292] [Batch 01836/03692] [00:16:23/00:16:34, 0.536s/it]: train_loss_raw=0.4870, running_loss=0.6142, LR=0.000100
[2025-08-10 21:30:18,175][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068304] [Batch 01848/03692] [00:16:29/00:16:27, 0.536s/it]: train_loss_raw=0.6113, running_loss=0.6156, LR=0.000100
[2025-08-10 21:30:24,750][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068316] [Batch 01860/03692] [00:16:36/00:16:21, 0.536s/it]: train_loss_raw=0.4999, running_loss=0.6147, LR=0.000100
[2025-08-10 21:30:31,232][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068328] [Batch 01872/03692] [00:16:42/00:16:15, 0.536s/it]: train_loss_raw=0.7676, running_loss=0.6182, LR=0.000100
[2025-08-10 21:30:37,865][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068340] [Batch 01884/03692] [00:16:49/00:16:08, 0.536s/it]: train_loss_raw=0.5621, running_loss=0.6191, LR=0.000100
[2025-08-10 21:30:44,406][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068352] [Batch 01896/03692] [00:16:56/00:16:02, 0.536s/it]: train_loss_raw=0.5687, running_loss=0.6189, LR=0.000100
[2025-08-10 21:30:50,993][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068364] [Batch 01908/03692] [00:17:02/00:15:56, 0.536s/it]: train_loss_raw=0.5928, running_loss=0.6216, LR=0.000100
[2025-08-10 21:30:57,304][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068376] [Batch 01920/03692] [00:17:09/00:15:49, 0.536s/it]: train_loss_raw=0.4696, running_loss=0.6235, LR=0.000100
[2025-08-10 21:31:03,755][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068388] [Batch 01932/03692] [00:17:15/00:15:43, 0.536s/it]: train_loss_raw=0.5692, running_loss=0.6260, LR=0.000100
[2025-08-10 21:31:09,872][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068400] [Batch 01944/03692] [00:17:21/00:15:36, 0.536s/it]: train_loss_raw=0.6091, running_loss=0.6264, LR=0.000100
[2025-08-10 21:31:16,000][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068412] [Batch 01956/03692] [00:17:27/00:15:29, 0.536s/it]: train_loss_raw=0.5365, running_loss=0.6256, LR=0.000100
[2025-08-10 21:31:22,036][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068424] [Batch 01968/03692] [00:17:33/00:15:23, 0.535s/it]: train_loss_raw=0.7100, running_loss=0.6211, LR=0.000100
[2025-08-10 21:31:28,003][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068436] [Batch 01980/03692] [00:17:39/00:15:16, 0.535s/it]: train_loss_raw=0.5435, running_loss=0.6207, LR=0.000100
[2025-08-10 21:31:34,107][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068448] [Batch 01992/03692] [00:17:45/00:15:09, 0.535s/it]: train_loss_raw=0.7169, running_loss=0.6185, LR=0.000100
[2025-08-10 21:31:40,175][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068460] [Batch 02004/03692] [00:17:51/00:15:02, 0.535s/it]: train_loss_raw=0.5642, running_loss=0.6169, LR=0.000100
[2025-08-10 21:31:46,175][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068472] [Batch 02016/03692] [00:17:57/00:14:56, 0.535s/it]: train_loss_raw=0.6221, running_loss=0.6154, LR=0.000100
[2025-08-10 21:31:52,245][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068484] [Batch 02028/03692] [00:18:03/00:14:49, 0.535s/it]: train_loss_raw=0.6271, running_loss=0.6131, LR=0.000100
[2025-08-10 21:31:58,295][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068496] [Batch 02040/03692] [00:18:10/00:14:42, 0.534s/it]: train_loss_raw=0.5472, running_loss=0.6163, LR=0.000100
[2025-08-10 21:32:04,396][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068508] [Batch 02052/03692] [00:18:16/00:14:36, 0.534s/it]: train_loss_raw=0.6045, running_loss=0.6157, LR=0.000100
[2025-08-10 21:32:10,569][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068520] [Batch 02064/03692] [00:18:22/00:14:29, 0.534s/it]: train_loss_raw=0.6230, running_loss=0.6148, LR=0.000100
[2025-08-10 21:32:16,706][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068532] [Batch 02076/03692] [00:18:28/00:14:22, 0.534s/it]: train_loss_raw=0.6016, running_loss=0.6112, LR=0.000100
[2025-08-10 21:32:22,909][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068544] [Batch 02088/03692] [00:18:34/00:14:16, 0.534s/it]: train_loss_raw=0.6372, running_loss=0.6123, LR=0.000100
[2025-08-10 21:32:29,239][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068556] [Batch 02100/03692] [00:18:40/00:14:09, 0.534s/it]: train_loss_raw=0.7689, running_loss=0.6145, LR=0.000100
[2025-08-10 21:32:35,503][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068568] [Batch 02112/03692] [00:18:47/00:14:03, 0.534s/it]: train_loss_raw=0.6575, running_loss=0.6146, LR=0.000100
[2025-08-10 21:32:41,515][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068580] [Batch 02124/03692] [00:18:53/00:13:56, 0.534s/it]: train_loss_raw=0.6829, running_loss=0.6170, LR=0.000100
[2025-08-10 21:32:47,841][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068592] [Batch 02136/03692] [00:18:59/00:13:50, 0.534s/it]: train_loss_raw=0.4248, running_loss=0.6168, LR=0.000100
[2025-08-10 21:32:54,360][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068604] [Batch 02148/03692] [00:19:06/00:13:43, 0.534s/it]: train_loss_raw=0.7445, running_loss=0.6216, LR=0.000100
[2025-08-10 21:33:00,808][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068616] [Batch 02160/03692] [00:19:12/00:13:37, 0.534s/it]: train_loss_raw=0.6249, running_loss=0.6194, LR=0.000100
[2025-08-10 21:33:07,420][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068628] [Batch 02172/03692] [00:19:19/00:13:31, 0.534s/it]: train_loss_raw=0.5694, running_loss=0.6197, LR=0.000100
[2025-08-10 21:33:13,894][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068640] [Batch 02184/03692] [00:19:25/00:13:24, 0.534s/it]: train_loss_raw=0.6064, running_loss=0.6187, LR=0.000100
[2025-08-10 21:33:20,388][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068652] [Batch 02196/03692] [00:19:32/00:13:18, 0.534s/it]: train_loss_raw=0.6043, running_loss=0.6171, LR=0.000100
[2025-08-10 21:33:26,837][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068664] [Batch 02208/03692] [00:19:38/00:13:12, 0.534s/it]: train_loss_raw=0.6075, running_loss=0.6172, LR=0.000100
[2025-08-10 21:33:32,870][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068676] [Batch 02220/03692] [00:19:44/00:13:05, 0.534s/it]: train_loss_raw=0.5684, running_loss=0.6173, LR=0.000100
[2025-08-10 21:33:38,836][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068688] [Batch 02232/03692] [00:19:50/00:12:58, 0.533s/it]: train_loss_raw=0.6637, running_loss=0.6136, LR=0.000100
[2025-08-10 21:33:45,119][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068700] [Batch 02244/03692] [00:19:56/00:12:52, 0.533s/it]: train_loss_raw=0.5738, running_loss=0.6152, LR=0.000100
[2025-08-10 21:33:51,235][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068712] [Batch 02256/03692] [00:20:02/00:12:45, 0.533s/it]: train_loss_raw=0.6713, running_loss=0.6137, LR=0.000100
[2025-08-10 21:33:57,627][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068724] [Batch 02268/03692] [00:20:09/00:12:39, 0.533s/it]: train_loss_raw=0.5107, running_loss=0.6138, LR=0.000100
[2025-08-10 21:34:04,044][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068736] [Batch 02280/03692] [00:20:15/00:12:32, 0.533s/it]: train_loss_raw=0.7519, running_loss=0.6145, LR=0.000100
[2025-08-10 21:34:10,061][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068748] [Batch 02292/03692] [00:20:21/00:12:26, 0.533s/it]: train_loss_raw=0.5707, running_loss=0.6098, LR=0.000100
[2025-08-10 21:34:16,114][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068760] [Batch 02304/03692] [00:20:27/00:12:19, 0.533s/it]: train_loss_raw=0.6984, running_loss=0.6096, LR=0.000100
[2025-08-10 21:34:22,090][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068772] [Batch 02316/03692] [00:20:33/00:12:13, 0.533s/it]: train_loss_raw=0.6585, running_loss=0.6074, LR=0.000100
[2025-08-10 21:34:28,152][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068784] [Batch 02328/03692] [00:20:39/00:12:06, 0.533s/it]: train_loss_raw=0.5711, running_loss=0.6025, LR=0.000100
[2025-08-10 21:34:34,225][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068796] [Batch 02340/03692] [00:20:45/00:11:59, 0.532s/it]: train_loss_raw=0.5801, running_loss=0.6037, LR=0.000100
[2025-08-10 21:34:40,241][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068808] [Batch 02352/03692] [00:20:51/00:11:53, 0.532s/it]: train_loss_raw=0.5977, running_loss=0.6018, LR=0.000100
[2025-08-10 21:34:46,352][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068820] [Batch 02364/03692] [00:20:58/00:11:46, 0.532s/it]: train_loss_raw=0.5715, running_loss=0.6032, LR=0.000100
[2025-08-10 21:34:52,869][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068832] [Batch 02376/03692] [00:21:04/00:11:40, 0.532s/it]: train_loss_raw=0.6810, running_loss=0.6017, LR=0.000100
[2025-08-10 21:34:59,196][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068844] [Batch 02388/03692] [00:21:10/00:11:34, 0.532s/it]: train_loss_raw=0.6856, running_loss=0.6057, LR=0.000100
[2025-08-10 21:35:05,538][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068856] [Batch 02400/03692] [00:21:17/00:11:27, 0.532s/it]: train_loss_raw=0.5858, running_loss=0.6052, LR=0.000100
[2025-08-10 21:35:12,107][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068868] [Batch 02412/03692] [00:21:23/00:11:21, 0.532s/it]: train_loss_raw=0.6553, running_loss=0.6069, LR=0.000100
[2025-08-10 21:35:18,648][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068880] [Batch 02424/03692] [00:21:30/00:11:15, 0.532s/it]: train_loss_raw=0.5995, running_loss=0.6061, LR=0.000100
[2025-08-10 21:35:25,272][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068892] [Batch 02436/03692] [00:21:37/00:11:08, 0.532s/it]: train_loss_raw=0.6013, running_loss=0.6036, LR=0.000100
[2025-08-10 21:35:31,738][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068904] [Batch 02448/03692] [00:21:43/00:11:02, 0.532s/it]: train_loss_raw=0.6188, running_loss=0.6049, LR=0.000100
[2025-08-10 21:35:38,334][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068916] [Batch 02460/03692] [00:21:50/00:10:56, 0.533s/it]: train_loss_raw=0.6327, running_loss=0.6053, LR=0.000100
[2025-08-10 21:35:44,472][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068928] [Batch 02472/03692] [00:21:56/00:10:49, 0.532s/it]: train_loss_raw=0.7482, running_loss=0.6073, LR=0.000100
[2025-08-10 21:35:50,708][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068940] [Batch 02484/03692] [00:22:02/00:10:43, 0.532s/it]: train_loss_raw=0.5917, running_loss=0.6096, LR=0.000100
[2025-08-10 21:35:57,195][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068952] [Batch 02496/03692] [00:22:08/00:10:36, 0.532s/it]: train_loss_raw=0.6720, running_loss=0.6133, LR=0.000100
[2025-08-10 21:36:03,841][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068964] [Batch 02508/03692] [00:22:15/00:10:30, 0.533s/it]: train_loss_raw=0.5013, running_loss=0.6144, LR=0.000100
[2025-08-10 21:36:10,052][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068976] [Batch 02520/03692] [00:22:21/00:10:24, 0.532s/it]: train_loss_raw=0.5604, running_loss=0.6130, LR=0.000100
[2025-08-10 21:36:16,526][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 068988] [Batch 02532/03692] [00:22:28/00:10:17, 0.532s/it]: train_loss_raw=0.6804, running_loss=0.6159, LR=0.000100
[2025-08-10 21:36:22,722][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069000] [Batch 02544/03692] [00:22:34/00:10:11, 0.532s/it]: train_loss_raw=0.5731, running_loss=0.6127, LR=0.000100
[2025-08-10 21:36:29,247][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069012] [Batch 02556/03692] [00:22:40/00:10:04, 0.532s/it]: train_loss_raw=0.6719, running_loss=0.6109, LR=0.000100
[2025-08-10 21:36:35,711][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069024] [Batch 02568/03692] [00:22:47/00:09:58, 0.532s/it]: train_loss_raw=0.6466, running_loss=0.6075, LR=0.000100
[2025-08-10 21:36:42,226][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069036] [Batch 02580/03692] [00:22:53/00:09:52, 0.533s/it]: train_loss_raw=0.6120, running_loss=0.6051, LR=0.000100
[2025-08-10 21:36:48,392][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069048] [Batch 02592/03692] [00:23:00/00:09:45, 0.532s/it]: train_loss_raw=0.5359, running_loss=0.6079, LR=0.000100
[2025-08-10 21:36:54,775][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069060] [Batch 02604/03692] [00:23:06/00:09:39, 0.532s/it]: train_loss_raw=0.6250, running_loss=0.6053, LR=0.000100
[2025-08-10 21:37:00,813][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069072] [Batch 02616/03692] [00:23:12/00:09:32, 0.532s/it]: train_loss_raw=0.5514, running_loss=0.6003, LR=0.000100
[2025-08-10 21:37:06,856][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069084] [Batch 02628/03692] [00:23:18/00:09:26, 0.532s/it]: train_loss_raw=0.5658, running_loss=0.6020, LR=0.000100
[2025-08-10 21:37:12,933][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069096] [Batch 02640/03692] [00:23:24/00:09:19, 0.532s/it]: train_loss_raw=0.5978, running_loss=0.6052, LR=0.000100
[2025-08-10 21:37:19,244][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069108] [Batch 02652/03692] [00:23:30/00:09:13, 0.532s/it]: train_loss_raw=0.5804, running_loss=0.6066, LR=0.000100
[2025-08-10 21:37:25,778][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069120] [Batch 02664/03692] [00:23:37/00:09:07, 0.532s/it]: train_loss_raw=0.6458, running_loss=0.6054, LR=0.000100
[2025-08-10 21:37:31,976][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069132] [Batch 02676/03692] [00:23:43/00:09:00, 0.532s/it]: train_loss_raw=0.5109, running_loss=0.6021, LR=0.000100
[2025-08-10 21:37:38,027][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069144] [Batch 02688/03692] [00:23:49/00:08:54, 0.532s/it]: train_loss_raw=0.5034, running_loss=0.6034, LR=0.000100
[2025-08-10 21:37:44,071][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069156] [Batch 02700/03692] [00:23:55/00:08:47, 0.532s/it]: train_loss_raw=0.5967, running_loss=0.6016, LR=0.000100
[2025-08-10 21:37:50,055][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069168] [Batch 02712/03692] [00:24:01/00:08:41, 0.532s/it]: train_loss_raw=0.6568, running_loss=0.6043, LR=0.000100
[2025-08-10 21:37:56,337][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069180] [Batch 02724/03692] [00:24:08/00:08:34, 0.532s/it]: train_loss_raw=0.5847, running_loss=0.6065, LR=0.000100
[2025-08-10 21:38:02,883][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069192] [Batch 02736/03692] [00:24:14/00:08:28, 0.532s/it]: train_loss_raw=0.7113, running_loss=0.6063, LR=0.000100
[2025-08-10 21:38:09,408][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069204] [Batch 02748/03692] [00:24:21/00:08:21, 0.532s/it]: train_loss_raw=0.5085, running_loss=0.6031, LR=0.000100
[2025-08-10 21:38:15,910][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069216] [Batch 02760/03692] [00:24:27/00:08:15, 0.532s/it]: train_loss_raw=0.5122, running_loss=0.5961, LR=0.000100
[2025-08-10 21:38:22,153][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069228] [Batch 02772/03692] [00:24:33/00:08:09, 0.532s/it]: train_loss_raw=0.6787, running_loss=0.6014, LR=0.000100
[2025-08-10 21:38:28,135][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069240] [Batch 02784/03692] [00:24:39/00:08:02, 0.532s/it]: train_loss_raw=0.7331, running_loss=0.6010, LR=0.000100
[2025-08-10 21:38:34,192][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069252] [Batch 02796/03692] [00:24:45/00:07:56, 0.531s/it]: train_loss_raw=0.5945, running_loss=0.5999, LR=0.000100
[2025-08-10 21:38:40,210][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069264] [Batch 02808/03692] [00:24:51/00:07:49, 0.531s/it]: train_loss_raw=0.5561, running_loss=0.6011, LR=0.000100
[2025-08-10 21:38:46,220][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069276] [Batch 02820/03692] [00:24:57/00:07:43, 0.531s/it]: train_loss_raw=0.7215, running_loss=0.6014, LR=0.000100
[2025-08-10 21:38:52,272][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069288] [Batch 02832/03692] [00:25:04/00:07:36, 0.531s/it]: train_loss_raw=0.6751, running_loss=0.6033, LR=0.000100
[2025-08-10 21:38:58,449][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069300] [Batch 02844/03692] [00:25:10/00:07:30, 0.531s/it]: train_loss_raw=0.6807, running_loss=0.5995, LR=0.000100
[2025-08-10 21:39:04,796][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069312] [Batch 02856/03692] [00:25:16/00:07:23, 0.531s/it]: train_loss_raw=0.5718, running_loss=0.5964, LR=0.000100
[2025-08-10 21:39:11,365][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069324] [Batch 02868/03692] [00:25:23/00:07:17, 0.531s/it]: train_loss_raw=0.6284, running_loss=0.5997, LR=0.000100
[2025-08-10 21:39:17,528][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069336] [Batch 02880/03692] [00:25:29/00:07:11, 0.531s/it]: train_loss_raw=0.5933, running_loss=0.6006, LR=0.000100
[2025-08-10 21:39:23,507][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069348] [Batch 02892/03692] [00:25:35/00:07:04, 0.531s/it]: train_loss_raw=0.6152, running_loss=0.6025, LR=0.000100
[2025-08-10 21:39:29,439][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069360] [Batch 02904/03692] [00:25:41/00:06:58, 0.531s/it]: train_loss_raw=0.6118, running_loss=0.5987, LR=0.000100
[2025-08-10 21:39:35,479][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069372] [Batch 02916/03692] [00:25:47/00:06:51, 0.531s/it]: train_loss_raw=0.5868, running_loss=0.6005, LR=0.000100
[2025-08-10 21:39:41,514][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069384] [Batch 02928/03692] [00:25:53/00:06:45, 0.530s/it]: train_loss_raw=0.6534, running_loss=0.6050, LR=0.000100
[2025-08-10 21:39:47,568][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069396] [Batch 02940/03692] [00:25:59/00:06:38, 0.530s/it]: train_loss_raw=0.5176, running_loss=0.6059, LR=0.000100
[2025-08-10 21:39:53,592][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069408] [Batch 02952/03692] [00:26:05/00:06:32, 0.530s/it]: train_loss_raw=0.5509, running_loss=0.6092, LR=0.000100
[2025-08-10 21:39:59,666][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069420] [Batch 02964/03692] [00:26:11/00:06:25, 0.530s/it]: train_loss_raw=0.5993, running_loss=0.6150, LR=0.000100
[2025-08-10 21:40:05,674][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069432] [Batch 02976/03692] [00:26:17/00:06:19, 0.530s/it]: train_loss_raw=0.6284, running_loss=0.6140, LR=0.000100
[2025-08-10 21:40:11,778][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069444] [Batch 02988/03692] [00:26:23/00:06:13, 0.530s/it]: train_loss_raw=0.6315, running_loss=0.6139, LR=0.000100
[2025-08-10 21:40:17,876][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069456] [Batch 03000/03692] [00:26:29/00:06:06, 0.530s/it]: train_loss_raw=0.6712, running_loss=0.6124, LR=0.000100
[2025-08-10 21:40:23,893][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069468] [Batch 03012/03692] [00:26:35/00:06:00, 0.530s/it]: train_loss_raw=0.6633, running_loss=0.6120, LR=0.000100
[2025-08-10 21:40:30,328][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069480] [Batch 03024/03692] [00:26:42/00:05:53, 0.530s/it]: train_loss_raw=0.7490, running_loss=0.6126, LR=0.000100
[2025-08-10 21:40:36,867][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069492] [Batch 03036/03692] [00:26:48/00:05:47, 0.530s/it]: train_loss_raw=0.6232, running_loss=0.6100, LR=0.000100
[2025-08-10 21:40:43,296][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069504] [Batch 03048/03692] [00:26:55/00:05:41, 0.530s/it]: train_loss_raw=0.5663, running_loss=0.6073, LR=0.000100
[2025-08-10 21:40:49,696][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069516] [Batch 03060/03692] [00:27:01/00:05:34, 0.530s/it]: train_loss_raw=0.5524, running_loss=0.6079, LR=0.000100
[2025-08-10 21:40:56,076][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069528] [Batch 03072/03692] [00:27:07/00:05:28, 0.530s/it]: train_loss_raw=0.5417, running_loss=0.6048, LR=0.000100
[2025-08-10 21:41:02,480][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069540] [Batch 03084/03692] [00:27:14/00:05:22, 0.530s/it]: train_loss_raw=0.5893, running_loss=0.6029, LR=0.000100
[2025-08-10 21:41:08,910][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069552] [Batch 03096/03692] [00:27:20/00:05:15, 0.530s/it]: train_loss_raw=0.5852, running_loss=0.6033, LR=0.000100
[2025-08-10 21:41:15,353][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069564] [Batch 03108/03692] [00:27:27/00:05:09, 0.530s/it]: train_loss_raw=0.6182, running_loss=0.6005, LR=0.000100
[2025-08-10 21:41:21,788][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069576] [Batch 03120/03692] [00:27:33/00:05:03, 0.530s/it]: train_loss_raw=0.5921, running_loss=0.6010, LR=0.000100
[2025-08-10 21:41:27,982][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069588] [Batch 03132/03692] [00:27:39/00:04:56, 0.530s/it]: train_loss_raw=0.5933, running_loss=0.6019, LR=0.000100
[2025-08-10 21:41:34,196][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069600] [Batch 03144/03692] [00:27:45/00:04:50, 0.530s/it]: train_loss_raw=0.5938, running_loss=0.6004, LR=0.000100
[2025-08-10 21:41:40,609][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069612] [Batch 03156/03692] [00:27:52/00:04:44, 0.530s/it]: train_loss_raw=0.5833, running_loss=0.5999, LR=0.000100
[2025-08-10 21:41:47,053][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069624] [Batch 03168/03692] [00:27:58/00:04:37, 0.530s/it]: train_loss_raw=0.5302, running_loss=0.6027, LR=0.000100
[2025-08-10 21:41:53,637][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069636] [Batch 03180/03692] [00:28:05/00:04:31, 0.530s/it]: train_loss_raw=0.6145, running_loss=0.6015, LR=0.000100
[2025-08-10 21:42:00,018][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069648] [Batch 03192/03692] [00:28:11/00:04:25, 0.530s/it]: train_loss_raw=0.6106, running_loss=0.6058, LR=0.000100
[2025-08-10 21:42:06,072][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069660] [Batch 03204/03692] [00:28:17/00:04:18, 0.530s/it]: train_loss_raw=0.6267, running_loss=0.6057, LR=0.000100
[2025-08-10 21:42:12,108][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069672] [Batch 03216/03692] [00:28:23/00:04:12, 0.530s/it]: train_loss_raw=0.6656, running_loss=0.6105, LR=0.000100
[2025-08-10 21:42:18,116][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069684] [Batch 03228/03692] [00:28:29/00:04:05, 0.530s/it]: train_loss_raw=0.6209, running_loss=0.6075, LR=0.000100
[2025-08-10 21:42:24,145][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069696] [Batch 03240/03692] [00:28:35/00:03:59, 0.530s/it]: train_loss_raw=0.6266, running_loss=0.6086, LR=0.000100
[2025-08-10 21:42:30,329][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069708] [Batch 03252/03692] [00:28:42/00:03:52, 0.530s/it]: train_loss_raw=0.5580, running_loss=0.6083, LR=0.000100
[2025-08-10 21:42:36,431][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069720] [Batch 03264/03692] [00:28:48/00:03:46, 0.529s/it]: train_loss_raw=0.5781, running_loss=0.6094, LR=0.000100
[2025-08-10 21:42:42,437][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069732] [Batch 03276/03692] [00:28:54/00:03:40, 0.529s/it]: train_loss_raw=0.6146, running_loss=0.6061, LR=0.000100
[2025-08-10 21:42:48,765][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069744] [Batch 03288/03692] [00:29:00/00:03:33, 0.529s/it]: train_loss_raw=0.7504, running_loss=0.6104, LR=0.000100
[2025-08-10 21:42:54,981][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069756] [Batch 03300/03692] [00:29:06/00:03:27, 0.529s/it]: train_loss_raw=0.5498, running_loss=0.6093, LR=0.000100
[2025-08-10 21:43:01,347][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069768] [Batch 03312/03692] [00:29:13/00:03:21, 0.529s/it]: train_loss_raw=0.6604, running_loss=0.6101, LR=0.000100
[2025-08-10 21:43:07,676][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069780] [Batch 03324/03692] [00:29:19/00:03:14, 0.529s/it]: train_loss_raw=0.6147, running_loss=0.6105, LR=0.000100
[2025-08-10 21:43:14,083][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069792] [Batch 03336/03692] [00:29:25/00:03:08, 0.529s/it]: train_loss_raw=0.6770, running_loss=0.6085, LR=0.000100
[2025-08-10 21:43:20,555][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069804] [Batch 03348/03692] [00:29:32/00:03:02, 0.529s/it]: train_loss_raw=0.6026, running_loss=0.6090, LR=0.000100
[2025-08-10 21:43:27,082][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069816] [Batch 03360/03692] [00:29:38/00:02:55, 0.529s/it]: train_loss_raw=0.4971, running_loss=0.6051, LR=0.000100
[2025-08-10 21:43:33,598][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069828] [Batch 03372/03692] [00:29:45/00:02:49, 0.529s/it]: train_loss_raw=0.6502, running_loss=0.6057, LR=0.000100
[2025-08-10 21:43:40,131][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069840] [Batch 03384/03692] [00:29:51/00:02:43, 0.530s/it]: train_loss_raw=0.5612, running_loss=0.5995, LR=0.000100
[2025-08-10 21:43:46,645][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069852] [Batch 03396/03692] [00:29:58/00:02:36, 0.530s/it]: train_loss_raw=0.5836, running_loss=0.5993, LR=0.000100
[2025-08-10 21:43:52,954][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069864] [Batch 03408/03692] [00:30:04/00:02:30, 0.530s/it]: train_loss_raw=0.5457, running_loss=0.5977, LR=0.000100
[2025-08-10 21:43:59,413][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069876] [Batch 03420/03692] [00:30:11/00:02:24, 0.530s/it]: train_loss_raw=0.6157, running_loss=0.5962, LR=0.000100
[2025-08-10 21:44:05,964][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069888] [Batch 03432/03692] [00:30:17/00:02:17, 0.530s/it]: train_loss_raw=0.6153, running_loss=0.6021, LR=0.000100
[2025-08-10 21:44:12,549][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069900] [Batch 03444/03692] [00:30:24/00:02:11, 0.530s/it]: train_loss_raw=0.5865, running_loss=0.6002, LR=0.000100
[2025-08-10 21:44:19,094][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069912] [Batch 03456/03692] [00:30:30/00:02:05, 0.530s/it]: train_loss_raw=0.5321, running_loss=0.6018, LR=0.000100
[2025-08-10 21:44:25,416][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069924] [Batch 03468/03692] [00:30:37/00:01:58, 0.530s/it]: train_loss_raw=0.5941, running_loss=0.6012, LR=0.000100
[2025-08-10 21:44:31,414][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069936] [Batch 03480/03692] [00:30:43/00:01:52, 0.530s/it]: train_loss_raw=0.6620, running_loss=0.6048, LR=0.000100
[2025-08-10 21:44:37,434][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069948] [Batch 03492/03692] [00:30:49/00:01:45, 0.530s/it]: train_loss_raw=0.7005, running_loss=0.6061, LR=0.000100
[2025-08-10 21:44:43,600][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069960] [Batch 03504/03692] [00:30:55/00:01:39, 0.529s/it]: train_loss_raw=0.5410, running_loss=0.6071, LR=0.000100
[2025-08-10 21:44:50,014][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069972] [Batch 03516/03692] [00:31:01/00:01:33, 0.530s/it]: train_loss_raw=0.7178, running_loss=0.6054, LR=0.000100
[2025-08-10 21:44:56,054][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069984] [Batch 03528/03692] [00:31:07/00:01:26, 0.529s/it]: train_loss_raw=0.6653, running_loss=0.6048, LR=0.000100
[2025-08-10 21:45:02,079][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 069996] [Batch 03540/03692] [00:31:13/00:01:20, 0.529s/it]: train_loss_raw=0.6672, running_loss=0.6013, LR=0.000100
[2025-08-10 21:45:12,607][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070008] [Batch 03552/03692] [00:31:24/00:01:14, 0.531s/it]: train_loss_raw=0.5170, running_loss=0.6026, LR=0.000100
[2025-08-10 21:45:18,723][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070020] [Batch 03564/03692] [00:31:30/00:01:07, 0.530s/it]: train_loss_raw=0.6160, running_loss=0.6026, LR=0.000100
[2025-08-10 21:45:25,012][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070032] [Batch 03576/03692] [00:31:36/00:01:01, 0.530s/it]: train_loss_raw=0.5490, running_loss=0.6024, LR=0.000100
[2025-08-10 21:45:31,543][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070044] [Batch 03588/03692] [00:31:43/00:00:55, 0.530s/it]: train_loss_raw=0.5032, running_loss=0.6031, LR=0.000100
[2025-08-10 21:45:38,089][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070056] [Batch 03600/03692] [00:31:49/00:00:48, 0.531s/it]: train_loss_raw=0.6789, running_loss=0.6076, LR=0.000100
[2025-08-10 21:45:44,366][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070068] [Batch 03612/03692] [00:31:56/00:00:42, 0.530s/it]: train_loss_raw=0.6215, running_loss=0.6060, LR=0.000100
[2025-08-10 21:45:50,725][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070080] [Batch 03624/03692] [00:32:02/00:00:36, 0.530s/it]: train_loss_raw=0.6877, running_loss=0.6053, LR=0.000100
[2025-08-10 21:45:57,308][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070092] [Batch 03636/03692] [00:32:09/00:00:29, 0.531s/it]: train_loss_raw=0.6340, running_loss=0.6067, LR=0.000100
[2025-08-10 21:46:03,861][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070104] [Batch 03648/03692] [00:32:15/00:00:23, 0.531s/it]: train_loss_raw=0.6071, running_loss=0.6058, LR=0.000100
[2025-08-10 21:46:10,505][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070116] [Batch 03660/03692] [00:32:22/00:00:16, 0.531s/it]: train_loss_raw=0.5887, running_loss=0.6035, LR=0.000100
[2025-08-10 21:46:17,039][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070128] [Batch 03672/03692] [00:32:28/00:00:10, 0.531s/it]: train_loss_raw=0.6427, running_loss=0.6016, LR=0.000100
[2025-08-10 21:46:23,536][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 070140] [Batch 03684/03692] [00:32:35/00:00:04, 0.531s/it]: train_loss_raw=0.5720, running_loss=0.6023, LR=0.000100
[2025-08-10 21:46:32,861][__main__][INFO] - [VALIDATION] [Epoch 18/29] Starting validation.
[2025-08-10 21:47:05,929][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 070149] [Batch 00011/00025] [00:00:33/00:00:35, 2.756s/it]
[2025-08-10 21:47:21,206][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 070149] [Batch 00023/00025] [00:00:48/00:00:02, 2.014s/it]
[2025-08-10 21:47:22,353][__main__][INFO] - [VALIDATION] [Epoch 18/29] train_loss=0.60237, valid_loss=0.66421
[2025-08-10 21:47:22,354][__main__][INFO] - [VALIDATION] [Epoch 18/29] Metrics:
[2025-08-10 21:47:22,354][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_er      0.291
[2025-08-10 21:47:22,354][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_prec    0.460
[2025-08-10 21:47:22,354][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_recall  0.466
[2025-08-10 21:47:22,354][__main__][INFO] - [VALIDATION] [Epoch 18/29] - pep_recall 0.445
[2025-08-10 21:47:22,357][__main__][INFO] - [TRAIN] [Epoch 18/29] Epoch complete, total time 10:51:21, remaining time 06:17:06, 00:34:16 per epoch
[2025-08-10 21:47:25,115][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070152] [Batch 00004/03692] [00:00:01/00:26:41, 0.434s/it]: train_loss_raw=0.5383, running_loss=0.5710, LR=0.000100
[2025-08-10 21:47:31,576][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070164] [Batch 00016/03692] [00:00:08/00:31:23, 0.512s/it]: train_loss_raw=0.6082, running_loss=0.5750, LR=0.000100
[2025-08-10 21:47:38,004][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070176] [Batch 00028/03692] [00:00:14/00:31:53, 0.522s/it]: train_loss_raw=0.5006, running_loss=0.5761, LR=0.000100
[2025-08-10 21:47:44,465][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070188] [Batch 00040/03692] [00:00:21/00:32:05, 0.527s/it]: train_loss_raw=0.6267, running_loss=0.5794, LR=0.000100
[2025-08-10 21:47:50,806][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070200] [Batch 00052/03692] [00:00:27/00:31:59, 0.527s/it]: train_loss_raw=0.6341, running_loss=0.5786, LR=0.000100
[2025-08-10 21:47:57,268][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070212] [Batch 00064/03692] [00:00:33/00:32:01, 0.530s/it]: train_loss_raw=0.6025, running_loss=0.5841, LR=0.000100
[2025-08-10 21:48:03,637][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070224] [Batch 00076/03692] [00:00:40/00:31:55, 0.530s/it]: train_loss_raw=0.6400, running_loss=0.5833, LR=0.000100
[2025-08-10 21:48:09,994][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070236] [Batch 00088/03692] [00:00:46/00:31:49, 0.530s/it]: train_loss_raw=0.5785, running_loss=0.5851, LR=0.000100
[2025-08-10 21:48:16,410][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070248] [Batch 00100/03692] [00:00:53/00:31:44, 0.530s/it]: train_loss_raw=0.6183, running_loss=0.5907, LR=0.000100
[2025-08-10 21:48:22,864][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070260] [Batch 00112/03692] [00:00:59/00:31:41, 0.531s/it]: train_loss_raw=0.5396, running_loss=0.5893, LR=0.000100
[2025-08-10 21:48:29,246][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070272] [Batch 00124/03692] [00:01:05/00:31:35, 0.531s/it]: train_loss_raw=0.6433, running_loss=0.5885, LR=0.000100
[2025-08-10 21:48:35,661][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070284] [Batch 00136/03692] [00:01:12/00:31:29, 0.531s/it]: train_loss_raw=0.5646, running_loss=0.5893, LR=0.000100
[2025-08-10 21:48:42,014][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070296] [Batch 00148/03692] [00:01:18/00:31:23, 0.531s/it]: train_loss_raw=0.7028, running_loss=0.5914, LR=0.000100
[2025-08-10 21:48:48,344][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070308] [Batch 00160/03692] [00:01:24/00:31:15, 0.531s/it]: train_loss_raw=0.5132, running_loss=0.5894, LR=0.000100
[2025-08-10 21:48:54,695][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070320] [Batch 00172/03692] [00:01:31/00:31:08, 0.531s/it]: train_loss_raw=0.5803, running_loss=0.5908, LR=0.000100
[2025-08-10 21:49:01,116][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070332] [Batch 00184/03692] [00:01:37/00:31:03, 0.531s/it]: train_loss_raw=0.6883, running_loss=0.5907, LR=0.000100
[2025-08-10 21:49:07,288][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070344] [Batch 00196/03692] [00:01:43/00:30:53, 0.530s/it]: train_loss_raw=0.5245, running_loss=0.5901, LR=0.000100
[2025-08-10 21:49:13,608][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070356] [Batch 00208/03692] [00:01:50/00:30:46, 0.530s/it]: train_loss_raw=0.5522, running_loss=0.5911, LR=0.000100
[2025-08-10 21:49:19,974][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070368] [Batch 00220/03692] [00:01:56/00:30:40, 0.530s/it]: train_loss_raw=0.6271, running_loss=0.5883, LR=0.000100
[2025-08-10 21:49:26,321][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070380] [Batch 00232/03692] [00:02:02/00:30:33, 0.530s/it]: train_loss_raw=0.5543, running_loss=0.5913, LR=0.000100
[2025-08-10 21:49:32,678][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070392] [Batch 00244/03692] [00:02:09/00:30:27, 0.530s/it]: train_loss_raw=0.5768, running_loss=0.5917, LR=0.000100
[2025-08-10 21:49:39,108][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070404] [Batch 00256/03692] [00:02:15/00:30:21, 0.530s/it]: train_loss_raw=0.4327, running_loss=0.5886, LR=0.000100
[2025-08-10 21:49:45,546][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070416] [Batch 00268/03692] [00:02:22/00:30:16, 0.530s/it]: train_loss_raw=0.5743, running_loss=0.5869, LR=0.000100
[2025-08-10 21:49:51,935][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070428] [Batch 00280/03692] [00:02:28/00:30:10, 0.531s/it]: train_loss_raw=0.5573, running_loss=0.5851, LR=0.000100
[2025-08-10 21:49:58,351][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070440] [Batch 00292/03692] [00:02:34/00:30:04, 0.531s/it]: train_loss_raw=0.4941, running_loss=0.5880, LR=0.000100
[2025-08-10 21:50:04,724][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070452] [Batch 00304/03692] [00:02:41/00:29:58, 0.531s/it]: train_loss_raw=0.6459, running_loss=0.5856, LR=0.000100
[2025-08-10 21:50:11,093][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070464] [Batch 00316/03692] [00:02:47/00:29:51, 0.531s/it]: train_loss_raw=0.5286, running_loss=0.5855, LR=0.000100
[2025-08-10 21:50:17,500][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070476] [Batch 00328/03692] [00:02:54/00:29:45, 0.531s/it]: train_loss_raw=0.6647, running_loss=0.5836, LR=0.000100
[2025-08-10 21:50:24,045][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070488] [Batch 00340/03692] [00:03:00/00:29:41, 0.531s/it]: train_loss_raw=0.5503, running_loss=0.5858, LR=0.000100
[2025-08-10 21:50:30,663][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070500] [Batch 00352/03692] [00:03:07/00:29:37, 0.532s/it]: train_loss_raw=0.6461, running_loss=0.5842, LR=0.000100
[2025-08-10 21:50:36,879][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070512] [Batch 00364/03692] [00:03:13/00:29:29, 0.532s/it]: train_loss_raw=0.6655, running_loss=0.5852, LR=0.000100
[2025-08-10 21:50:43,196][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070524] [Batch 00376/03692] [00:03:19/00:29:22, 0.531s/it]: train_loss_raw=0.6616, running_loss=0.5826, LR=0.000100
[2025-08-10 21:50:49,676][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070536] [Batch 00388/03692] [00:03:26/00:29:16, 0.532s/it]: train_loss_raw=0.5622, running_loss=0.5840, LR=0.000100
[2025-08-10 21:50:55,999][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070548] [Batch 00400/03692] [00:03:32/00:29:09, 0.532s/it]: train_loss_raw=0.5543, running_loss=0.5846, LR=0.000100
[2025-08-10 21:51:02,519][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070560] [Batch 00412/03692] [00:03:39/00:29:04, 0.532s/it]: train_loss_raw=0.5913, running_loss=0.5869, LR=0.000100
[2025-08-10 21:51:08,943][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070572] [Batch 00424/03692] [00:03:45/00:28:58, 0.532s/it]: train_loss_raw=0.5609, running_loss=0.5893, LR=0.000100
[2025-08-10 21:51:15,270][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070584] [Batch 00436/03692] [00:03:51/00:28:51, 0.532s/it]: train_loss_raw=0.5633, running_loss=0.5892, LR=0.000100
[2025-08-10 21:51:21,669][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070596] [Batch 00448/03692] [00:03:58/00:28:45, 0.532s/it]: train_loss_raw=0.4968, running_loss=0.5890, LR=0.000100
[2025-08-10 21:51:27,947][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070608] [Batch 00460/03692] [00:04:04/00:28:38, 0.532s/it]: train_loss_raw=0.6494, running_loss=0.5872, LR=0.000100
[2025-08-10 21:51:33,950][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070620] [Batch 00472/03692] [00:04:10/00:28:29, 0.531s/it]: train_loss_raw=0.6079, running_loss=0.5890, LR=0.000100
[2025-08-10 21:51:39,998][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070632] [Batch 00484/03692] [00:04:16/00:28:20, 0.530s/it]: train_loss_raw=0.4758, running_loss=0.5879, LR=0.000100
[2025-08-10 21:51:46,166][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070644] [Batch 00496/03692] [00:04:22/00:28:13, 0.530s/it]: train_loss_raw=0.5589, running_loss=0.5862, LR=0.000100
[2025-08-10 21:51:52,215][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070656] [Batch 00508/03692] [00:04:28/00:28:04, 0.529s/it]: train_loss_raw=0.5866, running_loss=0.5914, LR=0.000100
[2025-08-10 21:51:58,704][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070668] [Batch 00520/03692] [00:04:35/00:27:59, 0.529s/it]: train_loss_raw=0.5649, running_loss=0.5901, LR=0.000100
[2025-08-10 21:52:05,254][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070680] [Batch 00532/03692] [00:04:41/00:27:54, 0.530s/it]: train_loss_raw=0.5359, running_loss=0.5885, LR=0.000100
[2025-08-10 21:52:11,692][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070692] [Batch 00544/03692] [00:04:48/00:27:48, 0.530s/it]: train_loss_raw=0.5471, running_loss=0.5844, LR=0.000100
[2025-08-10 21:52:18,177][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070704] [Batch 00556/03692] [00:04:54/00:27:42, 0.530s/it]: train_loss_raw=0.5982, running_loss=0.5865, LR=0.000100
[2025-08-10 21:52:24,661][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070716] [Batch 00568/03692] [00:05:01/00:27:37, 0.530s/it]: train_loss_raw=0.6267, running_loss=0.5886, LR=0.000100
[2025-08-10 21:52:30,855][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070728] [Batch 00580/03692] [00:05:07/00:27:29, 0.530s/it]: train_loss_raw=0.5787, running_loss=0.5891, LR=0.000100
[2025-08-10 21:52:36,952][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070740] [Batch 00592/03692] [00:05:13/00:27:22, 0.530s/it]: train_loss_raw=0.5703, running_loss=0.5881, LR=0.000100
[2025-08-10 21:52:42,993][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070752] [Batch 00604/03692] [00:05:19/00:27:14, 0.529s/it]: train_loss_raw=0.5871, running_loss=0.5842, LR=0.000100
[2025-08-10 21:52:48,995][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070764] [Batch 00616/03692] [00:05:25/00:27:05, 0.529s/it]: train_loss_raw=0.5641, running_loss=0.5842, LR=0.000100
[2025-08-10 21:52:55,222][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070776] [Batch 00628/03692] [00:05:31/00:26:59, 0.528s/it]: train_loss_raw=0.4800, running_loss=0.5849, LR=0.000100
[2025-08-10 21:53:01,615][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070788] [Batch 00640/03692] [00:05:38/00:26:52, 0.528s/it]: train_loss_raw=0.5989, running_loss=0.5879, LR=0.000100
[2025-08-10 21:53:08,080][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070800] [Batch 00652/03692] [00:05:44/00:26:47, 0.529s/it]: train_loss_raw=0.5249, running_loss=0.5875, LR=0.000100
[2025-08-10 21:53:14,243][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070812] [Batch 00664/03692] [00:05:50/00:26:40, 0.528s/it]: train_loss_raw=0.6401, running_loss=0.5881, LR=0.000100
[2025-08-10 21:53:20,753][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070824] [Batch 00676/03692] [00:05:57/00:26:34, 0.529s/it]: train_loss_raw=0.4673, running_loss=0.5873, LR=0.000100
[2025-08-10 21:53:27,220][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070836] [Batch 00688/03692] [00:06:03/00:26:28, 0.529s/it]: train_loss_raw=0.6208, running_loss=0.5860, LR=0.000100
[2025-08-10 21:53:33,816][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070848] [Batch 00700/03692] [00:06:10/00:26:23, 0.529s/it]: train_loss_raw=0.7120, running_loss=0.5912, LR=0.000100
[2025-08-10 21:53:40,431][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070860] [Batch 00712/03692] [00:06:17/00:26:18, 0.530s/it]: train_loss_raw=0.6154, running_loss=0.5913, LR=0.000100
[2025-08-10 21:53:47,008][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070872] [Batch 00724/03692] [00:06:23/00:26:12, 0.530s/it]: train_loss_raw=0.4701, running_loss=0.5893, LR=0.000100
[2025-08-10 21:53:53,449][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070884] [Batch 00736/03692] [00:06:30/00:26:06, 0.530s/it]: train_loss_raw=0.5638, running_loss=0.5919, LR=0.000100
[2025-08-10 21:54:00,049][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070896] [Batch 00748/03692] [00:06:36/00:26:01, 0.530s/it]: train_loss_raw=0.6059, running_loss=0.5921, LR=0.000100
[2025-08-10 21:54:06,579][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070908] [Batch 00760/03692] [00:06:43/00:25:55, 0.531s/it]: train_loss_raw=0.5954, running_loss=0.5940, LR=0.000100
[2025-08-10 21:54:12,986][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070920] [Batch 00772/03692] [00:06:49/00:25:49, 0.531s/it]: train_loss_raw=0.5733, running_loss=0.5893, LR=0.000100
[2025-08-10 21:54:19,484][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070932] [Batch 00784/03692] [00:06:56/00:25:43, 0.531s/it]: train_loss_raw=0.5009, running_loss=0.5895, LR=0.000100
[2025-08-10 21:54:25,938][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070944] [Batch 00796/03692] [00:07:02/00:25:37, 0.531s/it]: train_loss_raw=0.5399, running_loss=0.5900, LR=0.000100
[2025-08-10 21:54:32,362][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070956] [Batch 00808/03692] [00:07:08/00:25:31, 0.531s/it]: train_loss_raw=0.5131, running_loss=0.5879, LR=0.000100
[2025-08-10 21:54:38,863][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070968] [Batch 00820/03692] [00:07:15/00:25:25, 0.531s/it]: train_loss_raw=0.5897, running_loss=0.5922, LR=0.000100
[2025-08-10 21:54:45,335][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070980] [Batch 00832/03692] [00:07:21/00:25:19, 0.531s/it]: train_loss_raw=0.5396, running_loss=0.5894, LR=0.000100
[2025-08-10 21:54:51,780][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 070992] [Batch 00844/03692] [00:07:28/00:25:13, 0.531s/it]: train_loss_raw=0.5042, running_loss=0.5879, LR=0.000100
[2025-08-10 21:54:58,130][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071004] [Batch 00856/03692] [00:07:34/00:25:06, 0.531s/it]: train_loss_raw=0.5326, running_loss=0.5889, LR=0.000100
[2025-08-10 21:55:04,477][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071016] [Batch 00868/03692] [00:07:41/00:25:00, 0.531s/it]: train_loss_raw=0.6472, running_loss=0.5883, LR=0.000100
[2025-08-10 21:55:10,944][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071028] [Batch 00880/03692] [00:07:47/00:24:54, 0.531s/it]: train_loss_raw=0.6909, running_loss=0.5873, LR=0.000100
[2025-08-10 21:55:17,488][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071040] [Batch 00892/03692] [00:07:54/00:24:48, 0.532s/it]: train_loss_raw=0.4925, running_loss=0.5814, LR=0.000100
[2025-08-10 21:55:23,680][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071052] [Batch 00904/03692] [00:08:00/00:24:41, 0.531s/it]: train_loss_raw=0.5008, running_loss=0.5833, LR=0.000100
[2025-08-10 21:55:29,782][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071064] [Batch 00916/03692] [00:08:06/00:24:34, 0.531s/it]: train_loss_raw=0.5958, running_loss=0.5856, LR=0.000100
[2025-08-10 21:55:36,068][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071076] [Batch 00928/03692] [00:08:12/00:24:27, 0.531s/it]: train_loss_raw=0.5245, running_loss=0.5834, LR=0.000100
[2025-08-10 21:55:42,476][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071088] [Batch 00940/03692] [00:08:19/00:24:21, 0.531s/it]: train_loss_raw=0.5838, running_loss=0.5827, LR=0.000100
[2025-08-10 21:55:49,086][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071100] [Batch 00952/03692] [00:08:25/00:24:15, 0.531s/it]: train_loss_raw=0.4806, running_loss=0.5813, LR=0.000100
[2025-08-10 21:55:55,691][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071112] [Batch 00964/03692] [00:08:32/00:24:09, 0.531s/it]: train_loss_raw=0.6464, running_loss=0.5851, LR=0.000100
[2025-08-10 21:56:02,026][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071124] [Batch 00976/03692] [00:08:38/00:24:03, 0.531s/it]: train_loss_raw=0.6686, running_loss=0.5866, LR=0.000100
[2025-08-10 21:56:08,537][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071136] [Batch 00988/03692] [00:08:45/00:23:57, 0.532s/it]: train_loss_raw=0.5838, running_loss=0.5910, LR=0.000100
[2025-08-10 21:56:15,036][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071148] [Batch 01000/03692] [00:08:51/00:23:51, 0.532s/it]: train_loss_raw=0.6121, running_loss=0.5921, LR=0.000100
[2025-08-10 21:56:21,334][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071160] [Batch 01012/03692] [00:08:57/00:23:44, 0.532s/it]: train_loss_raw=0.5950, running_loss=0.5939, LR=0.000100
[2025-08-10 21:56:27,777][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071172] [Batch 01024/03692] [00:09:04/00:23:38, 0.532s/it]: train_loss_raw=0.5534, running_loss=0.5931, LR=0.000100
[2025-08-10 21:56:34,328][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071184] [Batch 01036/03692] [00:09:10/00:23:32, 0.532s/it]: train_loss_raw=0.4418, running_loss=0.5918, LR=0.000100
[2025-08-10 21:56:40,897][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071196] [Batch 01048/03692] [00:09:17/00:23:26, 0.532s/it]: train_loss_raw=0.5252, running_loss=0.5884, LR=0.000100
[2025-08-10 21:56:47,215][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071208] [Batch 01060/03692] [00:09:23/00:23:20, 0.532s/it]: train_loss_raw=0.5705, running_loss=0.5883, LR=0.000100
[2025-08-10 21:56:53,599][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071220] [Batch 01072/03692] [00:09:30/00:23:13, 0.532s/it]: train_loss_raw=0.6013, running_loss=0.5875, LR=0.000100
[2025-08-10 21:56:59,995][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071232] [Batch 01084/03692] [00:09:36/00:23:07, 0.532s/it]: train_loss_raw=0.4775, running_loss=0.5916, LR=0.000100
[2025-08-10 21:57:06,353][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071244] [Batch 01096/03692] [00:09:42/00:23:00, 0.532s/it]: train_loss_raw=0.6038, running_loss=0.5902, LR=0.000100
[2025-08-10 21:57:12,747][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071256] [Batch 01108/03692] [00:09:49/00:22:54, 0.532s/it]: train_loss_raw=0.5483, running_loss=0.5881, LR=0.000100
[2025-08-10 21:57:19,186][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071268] [Batch 01120/03692] [00:09:55/00:22:48, 0.532s/it]: train_loss_raw=0.5365, running_loss=0.5878, LR=0.000100
[2025-08-10 21:57:25,568][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071280] [Batch 01132/03692] [00:10:02/00:22:41, 0.532s/it]: train_loss_raw=0.5308, running_loss=0.5881, LR=0.000100
[2025-08-10 21:57:31,948][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071292] [Batch 01144/03692] [00:10:08/00:22:35, 0.532s/it]: train_loss_raw=0.6446, running_loss=0.5922, LR=0.000100
[2025-08-10 21:57:38,344][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071304] [Batch 01156/03692] [00:10:14/00:22:29, 0.532s/it]: train_loss_raw=0.5710, running_loss=0.5925, LR=0.000100
[2025-08-10 21:57:44,746][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071316] [Batch 01168/03692] [00:10:21/00:22:22, 0.532s/it]: train_loss_raw=0.6258, running_loss=0.5929, LR=0.000100
[2025-08-10 21:57:51,093][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071328] [Batch 01180/03692] [00:10:27/00:22:16, 0.532s/it]: train_loss_raw=0.5525, running_loss=0.5877, LR=0.000100
[2025-08-10 21:57:57,527][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071340] [Batch 01192/03692] [00:10:34/00:22:10, 0.532s/it]: train_loss_raw=0.6942, running_loss=0.5927, LR=0.000100
[2025-08-10 21:58:03,966][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071352] [Batch 01204/03692] [00:10:40/00:22:03, 0.532s/it]: train_loss_raw=0.6137, running_loss=0.5926, LR=0.000100
[2025-08-10 21:58:10,547][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071364] [Batch 01216/03692] [00:10:47/00:21:57, 0.532s/it]: train_loss_raw=0.6034, running_loss=0.5911, LR=0.000100
[2025-08-10 21:58:16,957][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071376] [Batch 01228/03692] [00:10:53/00:21:51, 0.532s/it]: train_loss_raw=0.5617, running_loss=0.5891, LR=0.000100
[2025-08-10 21:58:23,442][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071388] [Batch 01240/03692] [00:11:00/00:21:45, 0.532s/it]: train_loss_raw=0.5555, running_loss=0.5876, LR=0.000100
[2025-08-10 21:58:29,795][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071400] [Batch 01252/03692] [00:11:06/00:21:38, 0.532s/it]: train_loss_raw=0.6743, running_loss=0.5884, LR=0.000100
[2025-08-10 21:58:36,261][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071412] [Batch 01264/03692] [00:11:12/00:21:32, 0.532s/it]: train_loss_raw=0.7880, running_loss=0.5904, LR=0.000100
[2025-08-10 21:58:42,635][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071424] [Batch 01276/03692] [00:11:19/00:21:26, 0.532s/it]: train_loss_raw=0.6619, running_loss=0.5870, LR=0.000100
[2025-08-10 21:58:49,021][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071436] [Batch 01288/03692] [00:11:25/00:21:19, 0.532s/it]: train_loss_raw=0.6416, running_loss=0.5859, LR=0.000100
[2025-08-10 21:58:55,523][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071448] [Batch 01300/03692] [00:11:32/00:21:13, 0.532s/it]: train_loss_raw=0.6298, running_loss=0.5855, LR=0.000100
[2025-08-10 21:59:02,067][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071460] [Batch 01312/03692] [00:11:38/00:21:07, 0.533s/it]: train_loss_raw=0.5656, running_loss=0.5859, LR=0.000100
[2025-08-10 21:59:08,494][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071472] [Batch 01324/03692] [00:11:45/00:21:01, 0.533s/it]: train_loss_raw=0.6569, running_loss=0.5861, LR=0.000100
[2025-08-10 21:59:14,952][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071484] [Batch 01336/03692] [00:11:51/00:20:54, 0.533s/it]: train_loss_raw=0.6230, running_loss=0.5852, LR=0.000100
[2025-08-10 21:59:21,440][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071496] [Batch 01348/03692] [00:11:58/00:20:48, 0.533s/it]: train_loss_raw=0.5255, running_loss=0.5839, LR=0.000100
[2025-08-10 21:59:28,008][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071508] [Batch 01360/03692] [00:12:04/00:20:42, 0.533s/it]: train_loss_raw=0.5857, running_loss=0.5822, LR=0.000100
[2025-08-10 21:59:34,484][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071520] [Batch 01372/03692] [00:12:11/00:20:36, 0.533s/it]: train_loss_raw=0.6282, running_loss=0.5831, LR=0.000100
[2025-08-10 21:59:40,947][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071532] [Batch 01384/03692] [00:12:17/00:20:29, 0.533s/it]: train_loss_raw=0.6119, running_loss=0.5859, LR=0.000100
[2025-08-10 21:59:47,329][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071544] [Batch 01396/03692] [00:12:23/00:20:23, 0.533s/it]: train_loss_raw=0.6730, running_loss=0.5865, LR=0.000100
[2025-08-10 21:59:53,722][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071556] [Batch 01408/03692] [00:12:30/00:20:17, 0.533s/it]: train_loss_raw=0.6126, running_loss=0.5856, LR=0.000100
[2025-08-10 22:00:00,082][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071568] [Batch 01420/03692] [00:12:36/00:20:10, 0.533s/it]: train_loss_raw=0.4619, running_loss=0.5857, LR=0.000100
[2025-08-10 22:00:06,443][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071580] [Batch 01432/03692] [00:12:43/00:20:04, 0.533s/it]: train_loss_raw=0.5269, running_loss=0.5837, LR=0.000100
[2025-08-10 22:00:12,906][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071592] [Batch 01444/03692] [00:12:49/00:19:57, 0.533s/it]: train_loss_raw=0.5659, running_loss=0.5838, LR=0.000100
[2025-08-10 22:00:19,476][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071604] [Batch 01456/03692] [00:12:56/00:19:51, 0.533s/it]: train_loss_raw=0.5737, running_loss=0.5832, LR=0.000100
[2025-08-10 22:00:25,814][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071616] [Batch 01468/03692] [00:13:02/00:19:45, 0.533s/it]: train_loss_raw=0.5744, running_loss=0.5854, LR=0.000100
[2025-08-10 22:00:32,398][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071628] [Batch 01480/03692] [00:13:09/00:19:39, 0.533s/it]: train_loss_raw=0.5757, running_loss=0.5863, LR=0.000100
[2025-08-10 22:00:38,819][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071640] [Batch 01492/03692] [00:13:15/00:19:32, 0.533s/it]: train_loss_raw=0.4649, running_loss=0.5820, LR=0.000100
[2025-08-10 22:00:45,390][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071652] [Batch 01504/03692] [00:13:22/00:19:26, 0.533s/it]: train_loss_raw=0.4905, running_loss=0.5812, LR=0.000100
[2025-08-10 22:00:51,990][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071664] [Batch 01516/03692] [00:13:28/00:19:20, 0.533s/it]: train_loss_raw=0.5364, running_loss=0.5821, LR=0.000100
[2025-08-10 22:00:58,648][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071676] [Batch 01528/03692] [00:13:35/00:19:14, 0.534s/it]: train_loss_raw=0.6731, running_loss=0.5809, LR=0.000100
[2025-08-10 22:01:05,591][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071688] [Batch 01540/03692] [00:13:42/00:19:08, 0.534s/it]: train_loss_raw=0.5950, running_loss=0.5830, LR=0.000100
[2025-08-10 22:01:12,064][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071700] [Batch 01552/03692] [00:13:48/00:19:02, 0.534s/it]: train_loss_raw=0.4060, running_loss=0.5813, LR=0.000100
[2025-08-10 22:01:18,345][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071712] [Batch 01564/03692] [00:13:54/00:18:56, 0.534s/it]: train_loss_raw=0.5815, running_loss=0.5819, LR=0.000100
[2025-08-10 22:01:24,784][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071724] [Batch 01576/03692] [00:14:01/00:18:49, 0.534s/it]: train_loss_raw=0.6974, running_loss=0.5834, LR=0.000100
[2025-08-10 22:01:31,537][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071736] [Batch 01588/03692] [00:14:08/00:18:43, 0.534s/it]: train_loss_raw=0.5882, running_loss=0.5834, LR=0.000100
[2025-08-10 22:01:38,335][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071748] [Batch 01600/03692] [00:14:14/00:18:37, 0.534s/it]: train_loss_raw=0.6445, running_loss=0.5839, LR=0.000100
[2025-08-10 22:01:45,021][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071760] [Batch 01612/03692] [00:14:21/00:18:31, 0.535s/it]: train_loss_raw=0.6411, running_loss=0.5870, LR=0.000100
[2025-08-10 22:01:51,099][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071772] [Batch 01624/03692] [00:14:27/00:18:24, 0.534s/it]: train_loss_raw=0.6201, running_loss=0.5858, LR=0.000100
[2025-08-10 22:01:57,167][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071784] [Batch 01636/03692] [00:14:33/00:18:18, 0.534s/it]: train_loss_raw=0.4715, running_loss=0.5883, LR=0.000100
[2025-08-10 22:02:03,191][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071796] [Batch 01648/03692] [00:14:39/00:18:11, 0.534s/it]: train_loss_raw=0.5790, running_loss=0.5868, LR=0.000100
[2025-08-10 22:02:09,286][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071808] [Batch 01660/03692] [00:14:45/00:18:04, 0.534s/it]: train_loss_raw=0.6544, running_loss=0.5813, LR=0.000100
[2025-08-10 22:02:15,319][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071820] [Batch 01672/03692] [00:14:51/00:17:57, 0.533s/it]: train_loss_raw=0.4886, running_loss=0.5808, LR=0.000100
[2025-08-10 22:02:21,399][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071832] [Batch 01684/03692] [00:14:58/00:17:50, 0.533s/it]: train_loss_raw=0.5232, running_loss=0.5790, LR=0.000100
[2025-08-10 22:02:27,507][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071844] [Batch 01696/03692] [00:15:04/00:17:44, 0.533s/it]: train_loss_raw=0.7155, running_loss=0.5807, LR=0.000100
[2025-08-10 22:02:33,513][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071856] [Batch 01708/03692] [00:15:10/00:17:37, 0.533s/it]: train_loss_raw=0.4724, running_loss=0.5782, LR=0.000100
[2025-08-10 22:02:39,672][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071868] [Batch 01720/03692] [00:15:16/00:17:30, 0.533s/it]: train_loss_raw=0.5214, running_loss=0.5789, LR=0.000100
[2025-08-10 22:02:45,659][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071880] [Batch 01732/03692] [00:15:22/00:17:23, 0.532s/it]: train_loss_raw=0.6397, running_loss=0.5793, LR=0.000100
[2025-08-10 22:02:52,082][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071892] [Batch 01744/03692] [00:15:28/00:17:17, 0.533s/it]: train_loss_raw=0.5616, running_loss=0.5834, LR=0.000100
[2025-08-10 22:02:58,609][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071904] [Batch 01756/03692] [00:15:35/00:17:11, 0.533s/it]: train_loss_raw=0.6235, running_loss=0.5802, LR=0.000100
[2025-08-10 22:03:04,622][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071916] [Batch 01768/03692] [00:15:41/00:17:04, 0.532s/it]: train_loss_raw=0.4906, running_loss=0.5790, LR=0.000100
[2025-08-10 22:03:10,673][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071928] [Batch 01780/03692] [00:15:47/00:16:57, 0.532s/it]: train_loss_raw=0.5734, running_loss=0.5796, LR=0.000100
[2025-08-10 22:03:16,843][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071940] [Batch 01792/03692] [00:15:53/00:16:50, 0.532s/it]: train_loss_raw=0.6616, running_loss=0.5806, LR=0.000100
[2025-08-10 22:03:22,891][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071952] [Batch 01804/03692] [00:15:59/00:16:44, 0.532s/it]: train_loss_raw=0.4529, running_loss=0.5795, LR=0.000100
[2025-08-10 22:03:28,963][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071964] [Batch 01816/03692] [00:16:05/00:16:37, 0.532s/it]: train_loss_raw=0.5753, running_loss=0.5819, LR=0.000100
[2025-08-10 22:03:35,090][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071976] [Batch 01828/03692] [00:16:11/00:16:30, 0.532s/it]: train_loss_raw=0.5253, running_loss=0.5779, LR=0.000100
[2025-08-10 22:03:41,118][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 071988] [Batch 01840/03692] [00:16:17/00:16:24, 0.531s/it]: train_loss_raw=0.6907, running_loss=0.5803, LR=0.000100
[2025-08-10 22:03:47,143][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072000] [Batch 01852/03692] [00:16:23/00:16:17, 0.531s/it]: train_loss_raw=0.6119, running_loss=0.5776, LR=0.000100
[2025-08-10 22:03:57,614][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072012] [Batch 01864/03692] [00:16:34/00:16:15, 0.533s/it]: train_loss_raw=0.5821, running_loss=0.5805, LR=0.000100
[2025-08-10 22:04:03,975][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072024] [Batch 01876/03692] [00:16:40/00:16:08, 0.533s/it]: train_loss_raw=0.5905, running_loss=0.5806, LR=0.000100
[2025-08-10 22:04:10,034][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072036] [Batch 01888/03692] [00:16:46/00:16:01, 0.533s/it]: train_loss_raw=0.5354, running_loss=0.5776, LR=0.000100
[2025-08-10 22:04:16,219][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072048] [Batch 01900/03692] [00:16:52/00:15:55, 0.533s/it]: train_loss_raw=0.6059, running_loss=0.5744, LR=0.000100
[2025-08-10 22:04:22,258][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072060] [Batch 01912/03692] [00:16:58/00:15:48, 0.533s/it]: train_loss_raw=0.6089, running_loss=0.5771, LR=0.000100
[2025-08-10 22:04:28,385][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072072] [Batch 01924/03692] [00:17:05/00:15:41, 0.533s/it]: train_loss_raw=0.7539, running_loss=0.5817, LR=0.000100
[2025-08-10 22:04:34,505][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072084] [Batch 01936/03692] [00:17:11/00:15:35, 0.533s/it]: train_loss_raw=0.5930, running_loss=0.5828, LR=0.000100
[2025-08-10 22:04:40,591][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072096] [Batch 01948/03692] [00:17:17/00:15:28, 0.532s/it]: train_loss_raw=0.6168, running_loss=0.5830, LR=0.000100
[2025-08-10 22:04:46,709][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072108] [Batch 01960/03692] [00:17:23/00:15:21, 0.532s/it]: train_loss_raw=0.5351, running_loss=0.5830, LR=0.000100
[2025-08-10 22:04:52,820][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072120] [Batch 01972/03692] [00:17:29/00:15:15, 0.532s/it]: train_loss_raw=0.5834, running_loss=0.5861, LR=0.000100
[2025-08-10 22:04:58,898][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072132] [Batch 01984/03692] [00:17:35/00:15:08, 0.532s/it]: train_loss_raw=0.4544, running_loss=0.5874, LR=0.000100
[2025-08-10 22:05:04,986][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072144] [Batch 01996/03692] [00:17:41/00:15:02, 0.532s/it]: train_loss_raw=0.5727, running_loss=0.5857, LR=0.000100
[2025-08-10 22:05:11,026][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072156] [Batch 02008/03692] [00:17:47/00:14:55, 0.532s/it]: train_loss_raw=0.5605, running_loss=0.5831, LR=0.000100
[2025-08-10 22:05:17,296][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072168] [Batch 02020/03692] [00:17:53/00:14:48, 0.532s/it]: train_loss_raw=0.5660, running_loss=0.5804, LR=0.000100
[2025-08-10 22:05:23,818][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072180] [Batch 02032/03692] [00:18:00/00:14:42, 0.532s/it]: train_loss_raw=0.6523, running_loss=0.5802, LR=0.000100
[2025-08-10 22:05:30,376][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072192] [Batch 02044/03692] [00:18:06/00:14:36, 0.532s/it]: train_loss_raw=0.5877, running_loss=0.5811, LR=0.000100
[2025-08-10 22:05:36,525][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072204] [Batch 02056/03692] [00:18:13/00:14:29, 0.532s/it]: train_loss_raw=0.6094, running_loss=0.5820, LR=0.000100
[2025-08-10 22:05:42,622][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072216] [Batch 02068/03692] [00:18:19/00:14:23, 0.532s/it]: train_loss_raw=0.4903, running_loss=0.5835, LR=0.000100
[2025-08-10 22:05:48,989][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072228] [Batch 02080/03692] [00:18:25/00:14:16, 0.532s/it]: train_loss_raw=0.7339, running_loss=0.5846, LR=0.000100
[2025-08-10 22:05:55,560][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072240] [Batch 02092/03692] [00:18:32/00:14:10, 0.532s/it]: train_loss_raw=0.6027, running_loss=0.5829, LR=0.000100
[2025-08-10 22:06:02,105][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072252] [Batch 02104/03692] [00:18:38/00:14:04, 0.532s/it]: train_loss_raw=0.5562, running_loss=0.5823, LR=0.000100
[2025-08-10 22:06:08,528][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072264] [Batch 02116/03692] [00:18:45/00:13:58, 0.532s/it]: train_loss_raw=0.4866, running_loss=0.5808, LR=0.000100
[2025-08-10 22:06:14,970][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072276] [Batch 02128/03692] [00:18:51/00:13:51, 0.532s/it]: train_loss_raw=0.6764, running_loss=0.5799, LR=0.000100
[2025-08-10 22:06:21,526][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072288] [Batch 02140/03692] [00:18:58/00:13:45, 0.532s/it]: train_loss_raw=0.4257, running_loss=0.5784, LR=0.000100
[2025-08-10 22:06:27,997][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072300] [Batch 02152/03692] [00:19:04/00:13:39, 0.532s/it]: train_loss_raw=0.5486, running_loss=0.5773, LR=0.000100
[2025-08-10 22:06:41,019][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072312] [Batch 02164/03692] [00:19:17/00:13:37, 0.535s/it]: train_loss_raw=0.7186, running_loss=0.5803, LR=0.000100
[2025-08-10 22:06:47,479][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072324] [Batch 02176/03692] [00:19:24/00:13:31, 0.535s/it]: train_loss_raw=0.5625, running_loss=0.5796, LR=0.000100
[2025-08-10 22:06:53,857][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072336] [Batch 02188/03692] [00:19:30/00:13:24, 0.535s/it]: train_loss_raw=0.5565, running_loss=0.5758, LR=0.000100
[2025-08-10 22:07:00,260][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072348] [Batch 02200/03692] [00:19:36/00:13:18, 0.535s/it]: train_loss_raw=0.5866, running_loss=0.5772, LR=0.000100
[2025-08-10 22:07:06,710][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072360] [Batch 02212/03692] [00:19:43/00:13:11, 0.535s/it]: train_loss_raw=0.5568, running_loss=0.5758, LR=0.000100
[2025-08-10 22:07:13,441][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072372] [Batch 02224/03692] [00:19:50/00:13:05, 0.535s/it]: train_loss_raw=0.5421, running_loss=0.5775, LR=0.000100
[2025-08-10 22:07:19,984][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072384] [Batch 02236/03692] [00:19:56/00:12:59, 0.535s/it]: train_loss_raw=0.4562, running_loss=0.5759, LR=0.000100
[2025-08-10 22:07:26,407][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072396] [Batch 02248/03692] [00:20:03/00:12:52, 0.535s/it]: train_loss_raw=0.5490, running_loss=0.5739, LR=0.000100
[2025-08-10 22:07:32,958][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072408] [Batch 02260/03692] [00:20:09/00:12:46, 0.535s/it]: train_loss_raw=0.5630, running_loss=0.5705, LR=0.000100
[2025-08-10 22:07:39,377][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072420] [Batch 02272/03692] [00:20:15/00:12:39, 0.535s/it]: train_loss_raw=0.5377, running_loss=0.5690, LR=0.000100
[2025-08-10 22:07:45,772][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072432] [Batch 02284/03692] [00:20:22/00:12:33, 0.535s/it]: train_loss_raw=0.6221, running_loss=0.5699, LR=0.000100
[2025-08-10 22:07:52,179][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072444] [Batch 02296/03692] [00:20:28/00:12:27, 0.535s/it]: train_loss_raw=0.8319, running_loss=0.5715, LR=0.000100
[2025-08-10 22:07:58,414][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072456] [Batch 02308/03692] [00:20:35/00:12:20, 0.535s/it]: train_loss_raw=0.4072, running_loss=0.5695, LR=0.000100
[2025-08-10 22:08:04,681][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072468] [Batch 02320/03692] [00:20:41/00:12:14, 0.535s/it]: train_loss_raw=0.6069, running_loss=0.5720, LR=0.000100
[2025-08-10 22:08:11,110][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072480] [Batch 02332/03692] [00:20:47/00:12:07, 0.535s/it]: train_loss_raw=0.6232, running_loss=0.5734, LR=0.000100
[2025-08-10 22:08:17,510][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072492] [Batch 02344/03692] [00:20:54/00:12:01, 0.535s/it]: train_loss_raw=0.5628, running_loss=0.5677, LR=0.000100
[2025-08-10 22:08:23,909][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072504] [Batch 02356/03692] [00:21:00/00:11:54, 0.535s/it]: train_loss_raw=0.5740, running_loss=0.5637, LR=0.000100
[2025-08-10 22:08:30,362][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072516] [Batch 02368/03692] [00:21:06/00:11:48, 0.535s/it]: train_loss_raw=0.5435, running_loss=0.5643, LR=0.000100
[2025-08-10 22:08:36,821][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072528] [Batch 02380/03692] [00:21:13/00:11:41, 0.535s/it]: train_loss_raw=0.5891, running_loss=0.5648, LR=0.000100
[2025-08-10 22:08:43,292][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072540] [Batch 02392/03692] [00:21:19/00:11:35, 0.535s/it]: train_loss_raw=0.5838, running_loss=0.5648, LR=0.000100
[2025-08-10 22:08:49,564][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072552] [Batch 02404/03692] [00:21:26/00:11:29, 0.535s/it]: train_loss_raw=0.5797, running_loss=0.5683, LR=0.000100
[2025-08-10 22:08:55,636][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072564] [Batch 02416/03692] [00:21:32/00:11:22, 0.535s/it]: train_loss_raw=0.4934, running_loss=0.5673, LR=0.000100
[2025-08-10 22:09:01,726][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072576] [Batch 02428/03692] [00:21:38/00:11:15, 0.535s/it]: train_loss_raw=0.4426, running_loss=0.5646, LR=0.000100
[2025-08-10 22:09:07,816][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072588] [Batch 02440/03692] [00:21:44/00:11:09, 0.535s/it]: train_loss_raw=0.6261, running_loss=0.5662, LR=0.000100
[2025-08-10 22:09:14,029][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072600] [Batch 02452/03692] [00:21:50/00:11:02, 0.535s/it]: train_loss_raw=0.4461, running_loss=0.5657, LR=0.000100
[2025-08-10 22:09:20,435][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072612] [Batch 02464/03692] [00:21:57/00:10:56, 0.535s/it]: train_loss_raw=0.5398, running_loss=0.5664, LR=0.000100
[2025-08-10 22:09:27,060][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072624] [Batch 02476/03692] [00:22:03/00:10:50, 0.535s/it]: train_loss_raw=0.5040, running_loss=0.5658, LR=0.000100
[2025-08-10 22:09:33,743][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072636] [Batch 02488/03692] [00:22:10/00:10:43, 0.535s/it]: train_loss_raw=0.4727, running_loss=0.5647, LR=0.000100
[2025-08-10 22:09:40,431][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072648] [Batch 02500/03692] [00:22:17/00:10:37, 0.535s/it]: train_loss_raw=0.6223, running_loss=0.5663, LR=0.000100
[2025-08-10 22:09:46,839][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072660] [Batch 02512/03692] [00:22:23/00:10:31, 0.535s/it]: train_loss_raw=0.5247, running_loss=0.5715, LR=0.000100
[2025-08-10 22:09:53,184][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072672] [Batch 02524/03692] [00:22:29/00:10:24, 0.535s/it]: train_loss_raw=0.6879, running_loss=0.5757, LR=0.000100
[2025-08-10 22:09:59,769][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072684] [Batch 02536/03692] [00:22:36/00:10:18, 0.535s/it]: train_loss_raw=0.5345, running_loss=0.5730, LR=0.000100
[2025-08-10 22:10:06,328][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072696] [Batch 02548/03692] [00:22:42/00:10:11, 0.535s/it]: train_loss_raw=0.5347, running_loss=0.5715, LR=0.000100
[2025-08-10 22:10:13,028][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072708] [Batch 02560/03692] [00:22:49/00:10:05, 0.535s/it]: train_loss_raw=0.6734, running_loss=0.5742, LR=0.000100
[2025-08-10 22:10:19,712][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072720] [Batch 02572/03692] [00:22:56/00:09:59, 0.535s/it]: train_loss_raw=0.6335, running_loss=0.5740, LR=0.000100
[2025-08-10 22:10:26,272][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072732] [Batch 02584/03692] [00:23:02/00:09:52, 0.535s/it]: train_loss_raw=0.6248, running_loss=0.5748, LR=0.000100
[2025-08-10 22:10:32,828][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072744] [Batch 02596/03692] [00:23:09/00:09:46, 0.535s/it]: train_loss_raw=0.6733, running_loss=0.5764, LR=0.000100
[2025-08-10 22:10:39,355][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072756] [Batch 02608/03692] [00:23:15/00:09:40, 0.535s/it]: train_loss_raw=0.5305, running_loss=0.5769, LR=0.000100
[2025-08-10 22:10:46,011][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072768] [Batch 02620/03692] [00:23:22/00:09:33, 0.535s/it]: train_loss_raw=0.5829, running_loss=0.5746, LR=0.000100
[2025-08-10 22:10:52,122][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072780] [Batch 02632/03692] [00:23:28/00:09:27, 0.535s/it]: train_loss_raw=0.6573, running_loss=0.5751, LR=0.000100
[2025-08-10 22:10:58,428][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072792] [Batch 02644/03692] [00:23:35/00:09:20, 0.535s/it]: train_loss_raw=0.5250, running_loss=0.5745, LR=0.000100
[2025-08-10 22:11:05,067][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072804] [Batch 02656/03692] [00:23:41/00:09:14, 0.535s/it]: train_loss_raw=0.6120, running_loss=0.5746, LR=0.000100
[2025-08-10 22:11:11,779][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072816] [Batch 02668/03692] [00:23:48/00:09:08, 0.535s/it]: train_loss_raw=0.5937, running_loss=0.5741, LR=0.000100
[2025-08-10 22:11:18,526][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072828] [Batch 02680/03692] [00:23:55/00:09:01, 0.536s/it]: train_loss_raw=0.5451, running_loss=0.5746, LR=0.000100
[2025-08-10 22:11:25,195][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072840] [Batch 02692/03692] [00:24:01/00:08:55, 0.536s/it]: train_loss_raw=0.6126, running_loss=0.5752, LR=0.000100
[2025-08-10 22:11:31,683][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072852] [Batch 02704/03692] [00:24:08/00:08:49, 0.536s/it]: train_loss_raw=0.4644, running_loss=0.5711, LR=0.000100
[2025-08-10 22:11:38,211][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072864] [Batch 02716/03692] [00:24:14/00:08:42, 0.536s/it]: train_loss_raw=0.4805, running_loss=0.5670, LR=0.000100
[2025-08-10 22:11:44,568][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072876] [Batch 02728/03692] [00:24:21/00:08:36, 0.536s/it]: train_loss_raw=0.5855, running_loss=0.5669, LR=0.000100
[2025-08-10 22:11:50,994][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072888] [Batch 02740/03692] [00:24:27/00:08:29, 0.536s/it]: train_loss_raw=0.5686, running_loss=0.5647, LR=0.000100
[2025-08-10 22:11:57,371][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072900] [Batch 02752/03692] [00:24:33/00:08:23, 0.536s/it]: train_loss_raw=0.6525, running_loss=0.5669, LR=0.000100
[2025-08-10 22:12:04,026][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072912] [Batch 02764/03692] [00:24:40/00:08:17, 0.536s/it]: train_loss_raw=0.6851, running_loss=0.5708, LR=0.000100
[2025-08-10 22:12:10,265][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072924] [Batch 02776/03692] [00:24:46/00:08:10, 0.536s/it]: train_loss_raw=0.5691, running_loss=0.5705, LR=0.000100
[2025-08-10 22:12:16,435][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072936] [Batch 02788/03692] [00:24:53/00:08:04, 0.536s/it]: train_loss_raw=0.6092, running_loss=0.5738, LR=0.000100
[2025-08-10 22:12:22,604][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072948] [Batch 02800/03692] [00:24:59/00:07:57, 0.535s/it]: train_loss_raw=0.6026, running_loss=0.5722, LR=0.000100
[2025-08-10 22:12:28,803][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072960] [Batch 02812/03692] [00:25:05/00:07:51, 0.535s/it]: train_loss_raw=0.5586, running_loss=0.5692, LR=0.000100
[2025-08-10 22:12:35,136][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072972] [Batch 02824/03692] [00:25:11/00:07:44, 0.535s/it]: train_loss_raw=0.6479, running_loss=0.5691, LR=0.000100
[2025-08-10 22:12:41,370][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072984] [Batch 02836/03692] [00:25:17/00:07:38, 0.535s/it]: train_loss_raw=0.6201, running_loss=0.5704, LR=0.000100
[2025-08-10 22:12:47,840][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 072996] [Batch 02848/03692] [00:25:24/00:07:31, 0.535s/it]: train_loss_raw=0.6389, running_loss=0.5701, LR=0.000100
[2025-08-10 22:12:54,509][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073008] [Batch 02860/03692] [00:25:31/00:07:25, 0.535s/it]: train_loss_raw=0.6217, running_loss=0.5715, LR=0.000100
[2025-08-10 22:13:00,806][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073020] [Batch 02872/03692] [00:25:37/00:07:18, 0.535s/it]: train_loss_raw=0.6456, running_loss=0.5718, LR=0.000100
[2025-08-10 22:13:07,007][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073032] [Batch 02884/03692] [00:25:43/00:07:12, 0.535s/it]: train_loss_raw=0.5422, running_loss=0.5719, LR=0.000100
[2025-08-10 22:13:13,274][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073044] [Batch 02896/03692] [00:25:49/00:07:06, 0.535s/it]: train_loss_raw=0.6136, running_loss=0.5725, LR=0.000100
[2025-08-10 22:13:19,724][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073056] [Batch 02908/03692] [00:25:56/00:06:59, 0.535s/it]: train_loss_raw=0.6738, running_loss=0.5733, LR=0.000100
[2025-08-10 22:13:26,062][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073068] [Batch 02920/03692] [00:26:02/00:06:53, 0.535s/it]: train_loss_raw=0.5868, running_loss=0.5732, LR=0.000100
[2025-08-10 22:13:32,510][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073080] [Batch 02932/03692] [00:26:09/00:06:46, 0.535s/it]: train_loss_raw=0.5269, running_loss=0.5696, LR=0.000100
[2025-08-10 22:13:39,072][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073092] [Batch 02944/03692] [00:26:15/00:06:40, 0.535s/it]: train_loss_raw=0.5103, running_loss=0.5682, LR=0.000100
[2025-08-10 22:13:45,584][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073104] [Batch 02956/03692] [00:26:22/00:06:33, 0.535s/it]: train_loss_raw=0.5896, running_loss=0.5683, LR=0.000100
[2025-08-10 22:13:52,038][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073116] [Batch 02968/03692] [00:26:28/00:06:27, 0.535s/it]: train_loss_raw=0.6086, running_loss=0.5704, LR=0.000100
[2025-08-10 22:13:58,456][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073128] [Batch 02980/03692] [00:26:35/00:06:21, 0.535s/it]: train_loss_raw=0.5019, running_loss=0.5725, LR=0.000100
[2025-08-10 22:14:04,901][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073140] [Batch 02992/03692] [00:26:41/00:06:14, 0.535s/it]: train_loss_raw=0.5540, running_loss=0.5749, LR=0.000100
[2025-08-10 22:14:11,349][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073152] [Batch 03004/03692] [00:26:47/00:06:08, 0.535s/it]: train_loss_raw=0.5580, running_loss=0.5714, LR=0.000100
[2025-08-10 22:14:17,889][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073164] [Batch 03016/03692] [00:26:54/00:06:01, 0.535s/it]: train_loss_raw=0.6875, running_loss=0.5696, LR=0.000100
[2025-08-10 22:14:24,449][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073176] [Batch 03028/03692] [00:27:01/00:05:55, 0.535s/it]: train_loss_raw=0.6039, running_loss=0.5692, LR=0.000100
[2025-08-10 22:14:30,844][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073188] [Batch 03040/03692] [00:27:07/00:05:49, 0.535s/it]: train_loss_raw=0.5654, running_loss=0.5709, LR=0.000100
[2025-08-10 22:14:37,239][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073200] [Batch 03052/03692] [00:27:13/00:05:42, 0.535s/it]: train_loss_raw=0.6524, running_loss=0.5729, LR=0.000100
[2025-08-10 22:14:43,704][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073212] [Batch 03064/03692] [00:27:20/00:05:36, 0.535s/it]: train_loss_raw=0.5536, running_loss=0.5708, LR=0.000100
[2025-08-10 22:14:50,122][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073224] [Batch 03076/03692] [00:27:26/00:05:29, 0.535s/it]: train_loss_raw=0.4539, running_loss=0.5670, LR=0.000100
[2025-08-10 22:14:56,559][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073236] [Batch 03088/03692] [00:27:33/00:05:23, 0.535s/it]: train_loss_raw=0.6079, running_loss=0.5697, LR=0.000100
[2025-08-10 22:15:03,030][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073248] [Batch 03100/03692] [00:27:39/00:05:16, 0.535s/it]: train_loss_raw=0.4590, running_loss=0.5692, LR=0.000100
[2025-08-10 22:15:09,543][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073260] [Batch 03112/03692] [00:27:46/00:05:10, 0.535s/it]: train_loss_raw=0.5354, running_loss=0.5683, LR=0.000100
[2025-08-10 22:15:15,945][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073272] [Batch 03124/03692] [00:27:52/00:05:04, 0.535s/it]: train_loss_raw=0.6306, running_loss=0.5674, LR=0.000100
[2025-08-10 22:15:22,255][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073284] [Batch 03136/03692] [00:27:58/00:04:57, 0.535s/it]: train_loss_raw=0.5278, running_loss=0.5685, LR=0.000100
[2025-08-10 22:15:28,639][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073296] [Batch 03148/03692] [00:28:05/00:04:51, 0.535s/it]: train_loss_raw=0.5158, running_loss=0.5680, LR=0.000100
[2025-08-10 22:15:35,063][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073308] [Batch 03160/03692] [00:28:11/00:04:44, 0.535s/it]: train_loss_raw=0.5066, running_loss=0.5677, LR=0.000100
[2025-08-10 22:15:41,489][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073320] [Batch 03172/03692] [00:28:18/00:04:38, 0.535s/it]: train_loss_raw=0.5349, running_loss=0.5674, LR=0.000100
[2025-08-10 22:15:47,839][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073332] [Batch 03184/03692] [00:28:24/00:04:31, 0.535s/it]: train_loss_raw=0.6125, running_loss=0.5665, LR=0.000100
[2025-08-10 22:15:54,231][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073344] [Batch 03196/03692] [00:28:30/00:04:25, 0.535s/it]: train_loss_raw=0.5921, running_loss=0.5653, LR=0.000100
[2025-08-10 22:16:00,735][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073356] [Batch 03208/03692] [00:28:37/00:04:19, 0.535s/it]: train_loss_raw=0.5283, running_loss=0.5669, LR=0.000100
[2025-08-10 22:16:07,066][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073368] [Batch 03220/03692] [00:28:43/00:04:12, 0.535s/it]: train_loss_raw=0.5885, running_loss=0.5650, LR=0.000100
[2025-08-10 22:16:13,525][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073380] [Batch 03232/03692] [00:28:50/00:04:06, 0.535s/it]: train_loss_raw=0.6072, running_loss=0.5677, LR=0.000100
[2025-08-10 22:16:19,910][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073392] [Batch 03244/03692] [00:28:56/00:03:59, 0.535s/it]: train_loss_raw=0.5452, running_loss=0.5680, LR=0.000100
[2025-08-10 22:16:26,466][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073404] [Batch 03256/03692] [00:29:03/00:03:53, 0.535s/it]: train_loss_raw=0.4076, running_loss=0.5656, LR=0.000100
[2025-08-10 22:16:32,998][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073416] [Batch 03268/03692] [00:29:09/00:03:47, 0.535s/it]: train_loss_raw=0.5105, running_loss=0.5648, LR=0.000100
[2025-08-10 22:16:39,545][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073428] [Batch 03280/03692] [00:29:16/00:03:40, 0.535s/it]: train_loss_raw=0.5901, running_loss=0.5650, LR=0.000100
[2025-08-10 22:16:46,115][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073440] [Batch 03292/03692] [00:29:22/00:03:34, 0.535s/it]: train_loss_raw=0.5360, running_loss=0.5673, LR=0.000100
[2025-08-10 22:16:52,678][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073452] [Batch 03304/03692] [00:29:29/00:03:27, 0.536s/it]: train_loss_raw=0.4902, running_loss=0.5622, LR=0.000100
[2025-08-10 22:16:59,213][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073464] [Batch 03316/03692] [00:29:35/00:03:21, 0.536s/it]: train_loss_raw=0.5171, running_loss=0.5587, LR=0.000100
[2025-08-10 22:17:05,275][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073476] [Batch 03328/03692] [00:29:41/00:03:14, 0.535s/it]: train_loss_raw=0.6360, running_loss=0.5597, LR=0.000100
[2025-08-10 22:17:11,638][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073488] [Batch 03340/03692] [00:29:48/00:03:08, 0.535s/it]: train_loss_raw=0.6123, running_loss=0.5578, LR=0.000100
[2025-08-10 22:17:17,995][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073500] [Batch 03352/03692] [00:29:54/00:03:02, 0.535s/it]: train_loss_raw=0.5162, running_loss=0.5585, LR=0.000100
[2025-08-10 22:17:24,373][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073512] [Batch 03364/03692] [00:30:00/00:02:55, 0.535s/it]: train_loss_raw=0.5422, running_loss=0.5597, LR=0.000100
[2025-08-10 22:17:30,928][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073524] [Batch 03376/03692] [00:30:07/00:02:49, 0.535s/it]: train_loss_raw=0.4994, running_loss=0.5591, LR=0.000100
[2025-08-10 22:17:37,344][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073536] [Batch 03388/03692] [00:30:13/00:02:42, 0.535s/it]: train_loss_raw=0.6261, running_loss=0.5604, LR=0.000100
[2025-08-10 22:17:43,915][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073548] [Batch 03400/03692] [00:30:20/00:02:36, 0.535s/it]: train_loss_raw=0.5729, running_loss=0.5599, LR=0.000100
[2025-08-10 22:17:50,479][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073560] [Batch 03412/03692] [00:30:27/00:02:29, 0.535s/it]: train_loss_raw=0.5605, running_loss=0.5570, LR=0.000100
[2025-08-10 22:17:56,970][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073572] [Batch 03424/03692] [00:30:33/00:02:23, 0.536s/it]: train_loss_raw=0.4438, running_loss=0.5548, LR=0.000100
[2025-08-10 22:18:03,355][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073584] [Batch 03436/03692] [00:30:39/00:02:17, 0.535s/it]: train_loss_raw=0.6331, running_loss=0.5567, LR=0.000100
[2025-08-10 22:18:09,815][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073596] [Batch 03448/03692] [00:30:46/00:02:10, 0.536s/it]: train_loss_raw=0.5844, running_loss=0.5593, LR=0.000100
[2025-08-10 22:18:16,311][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073608] [Batch 03460/03692] [00:30:52/00:02:04, 0.536s/it]: train_loss_raw=0.5553, running_loss=0.5609, LR=0.000100
[2025-08-10 22:18:22,580][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073620] [Batch 03472/03692] [00:30:59/00:01:57, 0.535s/it]: train_loss_raw=0.5774, running_loss=0.5607, LR=0.000100
[2025-08-10 22:18:28,686][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073632] [Batch 03484/03692] [00:31:05/00:01:51, 0.535s/it]: train_loss_raw=0.5956, running_loss=0.5575, LR=0.000100
[2025-08-10 22:18:34,815][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073644] [Batch 03496/03692] [00:31:11/00:01:44, 0.535s/it]: train_loss_raw=0.7126, running_loss=0.5587, LR=0.000100
[2025-08-10 22:18:41,260][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073656] [Batch 03508/03692] [00:31:17/00:01:38, 0.535s/it]: train_loss_raw=0.4746, running_loss=0.5577, LR=0.000100
[2025-08-10 22:18:47,522][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073668] [Batch 03520/03692] [00:31:24/00:01:32, 0.535s/it]: train_loss_raw=0.5991, running_loss=0.5575, LR=0.000100
[2025-08-10 22:18:53,606][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073680] [Batch 03532/03692] [00:31:30/00:01:25, 0.535s/it]: train_loss_raw=0.6266, running_loss=0.5584, LR=0.000100
[2025-08-10 22:18:59,661][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073692] [Batch 03544/03692] [00:31:36/00:01:19, 0.535s/it]: train_loss_raw=0.6026, running_loss=0.5581, LR=0.000100
[2025-08-10 22:19:05,956][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073704] [Batch 03556/03692] [00:31:42/00:01:12, 0.535s/it]: train_loss_raw=0.5675, running_loss=0.5606, LR=0.000100
[2025-08-10 22:19:12,169][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073716] [Batch 03568/03692] [00:31:48/00:01:06, 0.535s/it]: train_loss_raw=0.6732, running_loss=0.5607, LR=0.000100
[2025-08-10 22:19:18,218][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073728] [Batch 03580/03692] [00:31:54/00:00:59, 0.535s/it]: train_loss_raw=0.5737, running_loss=0.5608, LR=0.000100
[2025-08-10 22:19:24,229][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073740] [Batch 03592/03692] [00:32:00/00:00:53, 0.535s/it]: train_loss_raw=0.5789, running_loss=0.5585, LR=0.000100
[2025-08-10 22:19:30,307][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073752] [Batch 03604/03692] [00:32:06/00:00:47, 0.535s/it]: train_loss_raw=0.5204, running_loss=0.5530, LR=0.000100
[2025-08-10 22:19:36,426][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073764] [Batch 03616/03692] [00:32:13/00:00:40, 0.535s/it]: train_loss_raw=0.5864, running_loss=0.5550, LR=0.000100
[2025-08-10 22:19:42,390][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073776] [Batch 03628/03692] [00:32:19/00:00:34, 0.534s/it]: train_loss_raw=0.5904, running_loss=0.5587, LR=0.000100
[2025-08-10 22:19:48,500][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073788] [Batch 03640/03692] [00:32:25/00:00:27, 0.534s/it]: train_loss_raw=0.5725, running_loss=0.5607, LR=0.000100
[2025-08-10 22:19:54,505][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073800] [Batch 03652/03692] [00:32:31/00:00:21, 0.534s/it]: train_loss_raw=0.5516, running_loss=0.5604, LR=0.000100
[2025-08-10 22:20:00,578][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073812] [Batch 03664/03692] [00:32:37/00:00:14, 0.534s/it]: train_loss_raw=0.6615, running_loss=0.5633, LR=0.000100
[2025-08-10 22:20:06,800][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073824] [Batch 03676/03692] [00:32:43/00:00:08, 0.534s/it]: train_loss_raw=0.5441, running_loss=0.5630, LR=0.000100
[2025-08-10 22:20:13,374][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 073836] [Batch 03688/03692] [00:32:49/00:00:02, 0.534s/it]: train_loss_raw=0.5155, running_loss=0.5624, LR=0.000100
[2025-08-10 22:20:44,449][__main__][INFO] - [VALIDATION] [Epoch 19/29] Starting validation.
[2025-08-10 22:21:17,808][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 073841] [Batch 00011/00025] [00:00:33/00:00:36, 2.780s/it]
[2025-08-10 22:21:31,763][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 073841] [Batch 00023/00025] [00:00:47/00:00:01, 1.971s/it]
[2025-08-10 22:21:32,772][__main__][INFO] - [VALIDATION] [Epoch 19/29] train_loss=0.56304, valid_loss=0.61964
[2025-08-10 22:21:32,773][__main__][INFO] - [VALIDATION] [Epoch 19/29] Metrics:
[2025-08-10 22:21:32,773][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_er      0.273
[2025-08-10 22:21:32,774][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_prec    0.497
[2025-08-10 22:21:32,774][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_recall  0.502
[2025-08-10 22:21:32,774][__main__][INFO] - [VALIDATION] [Epoch 19/29] - pep_recall 0.481
[2025-08-10 22:21:32,776][__main__][INFO] - [TRAIN] [Epoch 19/29] Epoch complete, total time 11:25:31, remaining time 05:42:45, 00:34:16 per epoch
[2025-08-10 22:21:36,557][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073848] [Batch 00008/03692] [00:00:03/00:27:31, 0.448s/it]: train_loss_raw=0.6027, running_loss=0.5276, LR=0.000100
[2025-08-10 22:21:43,034][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073860] [Batch 00020/03692] [00:00:10/00:30:47, 0.503s/it]: train_loss_raw=0.5074, running_loss=0.5284, LR=0.000100
[2025-08-10 22:21:49,413][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073872] [Batch 00032/03692] [00:00:16/00:31:20, 0.514s/it]: train_loss_raw=0.5700, running_loss=0.5287, LR=0.000100
[2025-08-10 22:21:55,433][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073884] [Batch 00044/03692] [00:00:22/00:31:02, 0.510s/it]: train_loss_raw=0.5327, running_loss=0.5310, LR=0.000100
[2025-08-10 22:22:01,546][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073896] [Batch 00056/03692] [00:00:28/00:30:55, 0.510s/it]: train_loss_raw=0.5377, running_loss=0.5323, LR=0.000100
[2025-08-10 22:22:07,781][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073908] [Batch 00068/03692] [00:00:34/00:30:55, 0.512s/it]: train_loss_raw=0.5663, running_loss=0.5326, LR=0.000100
[2025-08-10 22:22:14,068][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073920] [Batch 00080/03692] [00:00:41/00:30:55, 0.514s/it]: train_loss_raw=0.5212, running_loss=0.5320, LR=0.000100
[2025-08-10 22:22:20,272][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073932] [Batch 00092/03692] [00:00:47/00:30:50, 0.514s/it]: train_loss_raw=0.5241, running_loss=0.5321, LR=0.000100
[2025-08-10 22:22:26,739][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073944] [Batch 00104/03692] [00:00:53/00:30:54, 0.517s/it]: train_loss_raw=0.5279, running_loss=0.5339, LR=0.000100
[2025-08-10 22:22:33,297][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073956] [Batch 00116/03692] [00:01:00/00:30:59, 0.520s/it]: train_loss_raw=0.5749, running_loss=0.5370, LR=0.000100
[2025-08-10 22:22:39,903][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073968] [Batch 00128/03692] [00:01:06/00:31:03, 0.523s/it]: train_loss_raw=0.4866, running_loss=0.5364, LR=0.000100
[2025-08-10 22:22:46,564][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073980] [Batch 00140/03692] [00:01:13/00:31:07, 0.526s/it]: train_loss_raw=0.6050, running_loss=0.5343, LR=0.000100
[2025-08-10 22:22:53,131][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 073992] [Batch 00152/03692] [00:01:20/00:31:06, 0.527s/it]: train_loss_raw=0.5638, running_loss=0.5402, LR=0.000100
[2025-08-10 22:23:05,217][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074004] [Batch 00164/03692] [00:01:32/00:33:04, 0.562s/it]: train_loss_raw=0.5233, running_loss=0.5399, LR=0.000100
[2025-08-10 22:23:11,623][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074016] [Batch 00176/03692] [00:01:38/00:32:50, 0.561s/it]: train_loss_raw=0.5742, running_loss=0.5391, LR=0.000100
[2025-08-10 22:23:18,168][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074028] [Batch 00188/03692] [00:01:45/00:32:40, 0.560s/it]: train_loss_raw=0.5041, running_loss=0.5378, LR=0.000100
[2025-08-10 22:23:24,699][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074040] [Batch 00200/03692] [00:01:51/00:32:30, 0.559s/it]: train_loss_raw=0.5907, running_loss=0.5365, LR=0.000100
[2025-08-10 22:23:31,316][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074052] [Batch 00212/03692] [00:01:58/00:32:22, 0.558s/it]: train_loss_raw=0.5114, running_loss=0.5361, LR=0.000100
[2025-08-10 22:23:37,794][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074064] [Batch 00224/03692] [00:02:04/00:32:12, 0.557s/it]: train_loss_raw=0.5795, running_loss=0.5385, LR=0.000100
[2025-08-10 22:23:44,341][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074076] [Batch 00236/03692] [00:02:11/00:32:03, 0.557s/it]: train_loss_raw=0.6159, running_loss=0.5399, LR=0.000100
[2025-08-10 22:23:51,035][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074088] [Batch 00248/03692] [00:02:18/00:31:57, 0.557s/it]: train_loss_raw=0.5347, running_loss=0.5373, LR=0.000100
[2025-08-10 22:23:57,617][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074100] [Batch 00260/03692] [00:02:24/00:31:49, 0.556s/it]: train_loss_raw=0.6006, running_loss=0.5358, LR=0.000100
[2025-08-10 22:24:04,378][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074112] [Batch 00272/03692] [00:02:31/00:31:43, 0.557s/it]: train_loss_raw=0.4954, running_loss=0.5310, LR=0.000100
[2025-08-10 22:24:10,933][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074124] [Batch 00284/03692] [00:02:37/00:31:35, 0.556s/it]: train_loss_raw=0.5046, running_loss=0.5306, LR=0.000100
[2025-08-10 22:24:17,529][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074136] [Batch 00296/03692] [00:02:44/00:31:27, 0.556s/it]: train_loss_raw=0.5600, running_loss=0.5276, LR=0.000100
[2025-08-10 22:24:24,037][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074148] [Batch 00308/03692] [00:02:51/00:31:19, 0.555s/it]: train_loss_raw=0.4803, running_loss=0.5260, LR=0.000100
[2025-08-10 22:24:30,552][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074160] [Batch 00320/03692] [00:02:57/00:31:11, 0.555s/it]: train_loss_raw=0.4379, running_loss=0.5263, LR=0.000100
[2025-08-10 22:24:37,179][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074172] [Batch 00332/03692] [00:03:04/00:31:04, 0.555s/it]: train_loss_raw=0.4905, running_loss=0.5239, LR=0.000100
[2025-08-10 22:24:43,719][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074184] [Batch 00344/03692] [00:03:10/00:30:56, 0.554s/it]: train_loss_raw=0.4833, running_loss=0.5264, LR=0.000100
[2025-08-10 22:24:50,546][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074196] [Batch 00356/03692] [00:03:17/00:30:51, 0.555s/it]: train_loss_raw=0.5699, running_loss=0.5277, LR=0.000100
[2025-08-10 22:24:57,205][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074208] [Batch 00368/03692] [00:03:24/00:30:44, 0.555s/it]: train_loss_raw=0.5492, running_loss=0.5296, LR=0.000100
[2025-08-10 22:25:03,620][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074220] [Batch 00380/03692] [00:03:30/00:30:35, 0.554s/it]: train_loss_raw=0.5679, running_loss=0.5257, LR=0.000100
[2025-08-10 22:25:09,913][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074232] [Batch 00392/03692] [00:03:36/00:30:26, 0.553s/it]: train_loss_raw=0.5309, running_loss=0.5263, LR=0.000100
[2025-08-10 22:25:16,432][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074244] [Batch 00404/03692] [00:03:43/00:30:18, 0.553s/it]: train_loss_raw=0.4668, running_loss=0.5242, LR=0.000100
[2025-08-10 22:25:22,938][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074256] [Batch 00416/03692] [00:03:49/00:30:10, 0.553s/it]: train_loss_raw=0.5547, running_loss=0.5261, LR=0.000100
[2025-08-10 22:25:29,394][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074268] [Batch 00428/03692] [00:03:56/00:30:02, 0.552s/it]: train_loss_raw=0.5715, running_loss=0.5284, LR=0.000100
[2025-08-10 22:25:35,965][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074280] [Batch 00440/03692] [00:04:02/00:29:55, 0.552s/it]: train_loss_raw=0.5824, running_loss=0.5297, LR=0.000100
[2025-08-10 22:25:42,476][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074292] [Batch 00452/03692] [00:04:09/00:29:48, 0.552s/it]: train_loss_raw=0.5217, running_loss=0.5319, LR=0.000100
[2025-08-10 22:25:48,944][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074304] [Batch 00464/03692] [00:04:15/00:29:40, 0.552s/it]: train_loss_raw=0.5244, running_loss=0.5336, LR=0.000100
[2025-08-10 22:25:55,445][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074316] [Batch 00476/03692] [00:04:22/00:29:33, 0.551s/it]: train_loss_raw=0.4581, running_loss=0.5339, LR=0.000100
[2025-08-10 22:26:02,043][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074328] [Batch 00488/03692] [00:04:29/00:29:26, 0.551s/it]: train_loss_raw=0.5365, running_loss=0.5322, LR=0.000100
[2025-08-10 22:26:08,531][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074340] [Batch 00500/03692] [00:04:35/00:29:19, 0.551s/it]: train_loss_raw=0.4976, running_loss=0.5306, LR=0.000100
[2025-08-10 22:26:15,037][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074352] [Batch 00512/03692] [00:04:42/00:29:11, 0.551s/it]: train_loss_raw=0.4916, running_loss=0.5286, LR=0.000100
[2025-08-10 22:26:21,468][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074364] [Batch 00524/03692] [00:04:48/00:29:04, 0.551s/it]: train_loss_raw=0.6038, running_loss=0.5302, LR=0.000100
[2025-08-10 22:26:27,900][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074376] [Batch 00536/03692] [00:04:54/00:28:56, 0.550s/it]: train_loss_raw=0.5721, running_loss=0.5300, LR=0.000100
[2025-08-10 22:26:34,136][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074388] [Batch 00548/03692] [00:05:01/00:28:47, 0.550s/it]: train_loss_raw=0.4854, running_loss=0.5332, LR=0.000100
[2025-08-10 22:26:40,238][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074400] [Batch 00560/03692] [00:05:07/00:28:38, 0.549s/it]: train_loss_raw=0.6959, running_loss=0.5363, LR=0.000100
[2025-08-10 22:26:46,571][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074412] [Batch 00572/03692] [00:05:13/00:28:30, 0.548s/it]: train_loss_raw=0.4374, running_loss=0.5357, LR=0.000100
[2025-08-10 22:26:53,013][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074424] [Batch 00584/03692] [00:05:20/00:28:23, 0.548s/it]: train_loss_raw=0.4351, running_loss=0.5386, LR=0.000100
[2025-08-10 22:26:59,492][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074436] [Batch 00596/03692] [00:05:26/00:28:16, 0.548s/it]: train_loss_raw=0.5354, running_loss=0.5381, LR=0.000100
[2025-08-10 22:27:05,932][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074448] [Batch 00608/03692] [00:05:32/00:28:08, 0.548s/it]: train_loss_raw=0.4995, running_loss=0.5391, LR=0.000100
[2025-08-10 22:27:12,382][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074460] [Batch 00620/03692] [00:05:39/00:28:01, 0.547s/it]: train_loss_raw=0.4819, running_loss=0.5380, LR=0.000100
[2025-08-10 22:27:18,507][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074472] [Batch 00632/03692] [00:05:45/00:27:53, 0.547s/it]: train_loss_raw=0.4709, running_loss=0.5345, LR=0.000100
[2025-08-10 22:27:24,921][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074484] [Batch 00644/03692] [00:05:51/00:27:45, 0.547s/it]: train_loss_raw=0.5075, running_loss=0.5368, LR=0.000100
[2025-08-10 22:27:31,380][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074496] [Batch 00656/03692] [00:05:58/00:27:38, 0.546s/it]: train_loss_raw=0.4858, running_loss=0.5353, LR=0.000100
[2025-08-10 22:27:37,889][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074508] [Batch 00668/03692] [00:06:04/00:27:31, 0.546s/it]: train_loss_raw=0.5236, running_loss=0.5353, LR=0.000100
[2025-08-10 22:27:44,279][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074520] [Batch 00680/03692] [00:06:11/00:27:24, 0.546s/it]: train_loss_raw=0.5177, running_loss=0.5353, LR=0.000100
[2025-08-10 22:27:50,769][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074532] [Batch 00692/03692] [00:06:17/00:27:17, 0.546s/it]: train_loss_raw=0.4011, running_loss=0.5353, LR=0.000100
[2025-08-10 22:27:57,281][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074544] [Batch 00704/03692] [00:06:24/00:27:11, 0.546s/it]: train_loss_raw=0.5044, running_loss=0.5341, LR=0.000100
[2025-08-10 22:28:03,763][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074556] [Batch 00716/03692] [00:06:30/00:27:04, 0.546s/it]: train_loss_raw=0.5208, running_loss=0.5365, LR=0.000100
[2025-08-10 22:28:10,163][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074568] [Batch 00728/03692] [00:06:37/00:26:57, 0.546s/it]: train_loss_raw=0.6051, running_loss=0.5373, LR=0.000100
[2025-08-10 22:28:16,482][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074580] [Batch 00740/03692] [00:06:43/00:26:49, 0.545s/it]: train_loss_raw=0.4577, running_loss=0.5342, LR=0.000100
[2025-08-10 22:28:22,906][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074592] [Batch 00752/03692] [00:06:49/00:26:42, 0.545s/it]: train_loss_raw=0.5546, running_loss=0.5365, LR=0.000100
[2025-08-10 22:28:29,242][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074604] [Batch 00764/03692] [00:06:56/00:26:35, 0.545s/it]: train_loss_raw=0.5052, running_loss=0.5361, LR=0.000100
[2025-08-10 22:28:35,665][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074616] [Batch 00776/03692] [00:07:02/00:26:28, 0.545s/it]: train_loss_raw=0.5324, running_loss=0.5352, LR=0.000100
[2025-08-10 22:28:41,997][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074628] [Batch 00788/03692] [00:07:09/00:26:21, 0.544s/it]: train_loss_raw=0.4993, running_loss=0.5361, LR=0.000100
[2025-08-10 22:28:48,469][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074640] [Batch 00800/03692] [00:07:15/00:26:14, 0.544s/it]: train_loss_raw=0.4815, running_loss=0.5322, LR=0.000100
[2025-08-10 22:28:54,980][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074652] [Batch 00812/03692] [00:07:22/00:26:07, 0.544s/it]: train_loss_raw=0.5558, running_loss=0.5316, LR=0.000100
[2025-08-10 22:29:01,430][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074664] [Batch 00824/03692] [00:07:28/00:26:00, 0.544s/it]: train_loss_raw=0.5979, running_loss=0.5295, LR=0.000100
[2025-08-10 22:29:07,942][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074676] [Batch 00836/03692] [00:07:34/00:25:54, 0.544s/it]: train_loss_raw=0.5019, running_loss=0.5289, LR=0.000100
[2025-08-10 22:29:14,542][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074688] [Batch 00848/03692] [00:07:41/00:25:48, 0.544s/it]: train_loss_raw=0.5275, running_loss=0.5283, LR=0.000100
[2025-08-10 22:29:21,199][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074700] [Batch 00860/03692] [00:07:48/00:25:41, 0.544s/it]: train_loss_raw=0.5970, running_loss=0.5305, LR=0.000100
[2025-08-10 22:29:27,539][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074712] [Batch 00872/03692] [00:07:54/00:25:34, 0.544s/it]: train_loss_raw=0.5114, running_loss=0.5317, LR=0.000100
[2025-08-10 22:29:33,923][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074724] [Batch 00884/03692] [00:08:00/00:25:27, 0.544s/it]: train_loss_raw=0.3723, running_loss=0.5311, LR=0.000100
[2025-08-10 22:29:40,246][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074736] [Batch 00896/03692] [00:08:07/00:25:20, 0.544s/it]: train_loss_raw=0.5562, running_loss=0.5334, LR=0.000100
[2025-08-10 22:29:46,654][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074748] [Batch 00908/03692] [00:08:13/00:25:13, 0.544s/it]: train_loss_raw=0.4600, running_loss=0.5340, LR=0.000100
[2025-08-10 22:29:53,062][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074760] [Batch 00920/03692] [00:08:20/00:25:06, 0.544s/it]: train_loss_raw=0.5853, running_loss=0.5324, LR=0.000100
[2025-08-10 22:29:59,455][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074772] [Batch 00932/03692] [00:08:26/00:24:59, 0.543s/it]: train_loss_raw=0.6221, running_loss=0.5343, LR=0.000100
[2025-08-10 22:30:05,956][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074784] [Batch 00944/03692] [00:08:32/00:24:53, 0.543s/it]: train_loss_raw=0.4932, running_loss=0.5343, LR=0.000100
[2025-08-10 22:30:12,318][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074796] [Batch 00956/03692] [00:08:39/00:24:46, 0.543s/it]: train_loss_raw=0.5795, running_loss=0.5315, LR=0.000100
[2025-08-10 22:30:18,746][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074808] [Batch 00968/03692] [00:08:45/00:24:39, 0.543s/it]: train_loss_raw=0.5350, running_loss=0.5300, LR=0.000100
[2025-08-10 22:30:25,127][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074820] [Batch 00980/03692] [00:08:52/00:24:32, 0.543s/it]: train_loss_raw=0.4545, running_loss=0.5325, LR=0.000100
[2025-08-10 22:30:31,574][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074832] [Batch 00992/03692] [00:08:58/00:24:25, 0.543s/it]: train_loss_raw=0.6019, running_loss=0.5308, LR=0.000100
[2025-08-10 22:30:37,955][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074844] [Batch 01004/03692] [00:09:04/00:24:19, 0.543s/it]: train_loss_raw=0.5322, running_loss=0.5290, LR=0.000100
[2025-08-10 22:30:44,349][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074856] [Batch 01016/03692] [00:09:11/00:24:12, 0.543s/it]: train_loss_raw=0.5300, running_loss=0.5289, LR=0.000100
[2025-08-10 22:30:50,705][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074868] [Batch 01028/03692] [00:09:17/00:24:05, 0.543s/it]: train_loss_raw=0.5354, running_loss=0.5317, LR=0.000100
[2025-08-10 22:30:57,195][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074880] [Batch 01040/03692] [00:09:24/00:23:58, 0.543s/it]: train_loss_raw=0.5310, running_loss=0.5318, LR=0.000100
[2025-08-10 22:31:03,566][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074892] [Batch 01052/03692] [00:09:30/00:23:51, 0.542s/it]: train_loss_raw=0.4817, running_loss=0.5293, LR=0.000100
[2025-08-10 22:31:10,107][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074904] [Batch 01064/03692] [00:09:37/00:23:45, 0.542s/it]: train_loss_raw=0.5328, running_loss=0.5306, LR=0.000100
[2025-08-10 22:31:16,610][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074916] [Batch 01076/03692] [00:09:43/00:23:38, 0.542s/it]: train_loss_raw=0.5363, running_loss=0.5329, LR=0.000100
[2025-08-10 22:31:23,001][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074928] [Batch 01088/03692] [00:09:50/00:23:32, 0.542s/it]: train_loss_raw=0.4626, running_loss=0.5311, LR=0.000100
[2025-08-10 22:31:29,575][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074940] [Batch 01100/03692] [00:09:56/00:23:25, 0.542s/it]: train_loss_raw=0.5017, running_loss=0.5331, LR=0.000100
[2025-08-10 22:31:36,081][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074952] [Batch 01112/03692] [00:10:03/00:23:19, 0.542s/it]: train_loss_raw=0.4935, running_loss=0.5296, LR=0.000100
[2025-08-10 22:31:42,613][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074964] [Batch 01124/03692] [00:10:09/00:23:12, 0.542s/it]: train_loss_raw=0.5375, running_loss=0.5283, LR=0.000100
[2025-08-10 22:31:49,007][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074976] [Batch 01136/03692] [00:10:16/00:23:06, 0.542s/it]: train_loss_raw=0.4917, running_loss=0.5255, LR=0.000100
[2025-08-10 22:31:55,510][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 074988] [Batch 01148/03692] [00:10:22/00:22:59, 0.542s/it]: train_loss_raw=0.5146, running_loss=0.5269, LR=0.000100
[2025-08-10 22:32:02,045][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075000] [Batch 01160/03692] [00:10:29/00:22:53, 0.542s/it]: train_loss_raw=0.4525, running_loss=0.5241, LR=0.000100
[2025-08-10 22:32:08,581][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075012] [Batch 01172/03692] [00:10:35/00:22:46, 0.542s/it]: train_loss_raw=0.5145, running_loss=0.5268, LR=0.000100
[2025-08-10 22:32:14,984][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075024] [Batch 01184/03692] [00:10:42/00:22:39, 0.542s/it]: train_loss_raw=0.5474, running_loss=0.5292, LR=0.000100
[2025-08-10 22:32:21,427][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075036] [Batch 01196/03692] [00:10:48/00:22:33, 0.542s/it]: train_loss_raw=0.4753, running_loss=0.5277, LR=0.000100
[2025-08-10 22:32:27,849][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075048] [Batch 01208/03692] [00:10:54/00:22:26, 0.542s/it]: train_loss_raw=0.5202, running_loss=0.5278, LR=0.000100
[2025-08-10 22:32:34,262][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075060] [Batch 01220/03692] [00:11:01/00:22:19, 0.542s/it]: train_loss_raw=0.4953, running_loss=0.5273, LR=0.000100
[2025-08-10 22:32:40,721][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075072] [Batch 01232/03692] [00:11:07/00:22:13, 0.542s/it]: train_loss_raw=0.5024, running_loss=0.5274, LR=0.000100
[2025-08-10 22:32:47,113][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075084] [Batch 01244/03692] [00:11:14/00:22:06, 0.542s/it]: train_loss_raw=0.5035, running_loss=0.5298, LR=0.000100
[2025-08-10 22:32:53,636][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075096] [Batch 01256/03692] [00:11:20/00:22:00, 0.542s/it]: train_loss_raw=0.5063, running_loss=0.5289, LR=0.000100
[2025-08-10 22:33:00,106][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075108] [Batch 01268/03692] [00:11:27/00:21:53, 0.542s/it]: train_loss_raw=0.5223, running_loss=0.5313, LR=0.000100
[2025-08-10 22:33:06,359][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075120] [Batch 01280/03692] [00:11:33/00:21:46, 0.542s/it]: train_loss_raw=0.4778, running_loss=0.5314, LR=0.000100
[2025-08-10 22:33:12,649][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075132] [Batch 01292/03692] [00:11:39/00:21:39, 0.542s/it]: train_loss_raw=0.5635, running_loss=0.5310, LR=0.000100
[2025-08-10 22:33:19,257][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075144] [Batch 01304/03692] [00:11:46/00:21:33, 0.542s/it]: train_loss_raw=0.4656, running_loss=0.5291, LR=0.000100
[2025-08-10 22:33:25,582][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075156] [Batch 01316/03692] [00:11:52/00:21:26, 0.541s/it]: train_loss_raw=0.4104, running_loss=0.5288, LR=0.000100
[2025-08-10 22:33:31,996][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075168] [Batch 01328/03692] [00:11:59/00:21:19, 0.541s/it]: train_loss_raw=0.4247, running_loss=0.5230, LR=0.000100
[2025-08-10 22:33:38,525][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075180] [Batch 01340/03692] [00:12:05/00:21:13, 0.541s/it]: train_loss_raw=0.5686, running_loss=0.5225, LR=0.000100
[2025-08-10 22:33:45,209][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075192] [Batch 01352/03692] [00:12:12/00:21:07, 0.542s/it]: train_loss_raw=0.5385, running_loss=0.5257, LR=0.000100
[2025-08-10 22:33:51,760][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075204] [Batch 01364/03692] [00:12:18/00:21:00, 0.542s/it]: train_loss_raw=0.4422, running_loss=0.5250, LR=0.000100
[2025-08-10 22:33:58,410][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075216] [Batch 01376/03692] [00:12:25/00:20:54, 0.542s/it]: train_loss_raw=0.5158, running_loss=0.5271, LR=0.000100
[2025-08-10 22:34:05,091][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075228] [Batch 01388/03692] [00:12:32/00:20:48, 0.542s/it]: train_loss_raw=0.5225, running_loss=0.5267, LR=0.000100
[2025-08-10 22:34:11,644][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075240] [Batch 01400/03692] [00:12:38/00:20:42, 0.542s/it]: train_loss_raw=0.5177, running_loss=0.5299, LR=0.000100
[2025-08-10 22:34:18,128][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075252] [Batch 01412/03692] [00:12:45/00:20:35, 0.542s/it]: train_loss_raw=0.4492, running_loss=0.5300, LR=0.000100
[2025-08-10 22:34:24,657][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075264] [Batch 01424/03692] [00:12:51/00:20:29, 0.542s/it]: train_loss_raw=0.5502, running_loss=0.5275, LR=0.000100
[2025-08-10 22:34:31,144][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075276] [Batch 01436/03692] [00:12:58/00:20:22, 0.542s/it]: train_loss_raw=0.6366, running_loss=0.5307, LR=0.000100
[2025-08-10 22:34:37,668][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075288] [Batch 01448/03692] [00:13:04/00:20:16, 0.542s/it]: train_loss_raw=0.5296, running_loss=0.5305, LR=0.000100
[2025-08-10 22:34:44,105][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075300] [Batch 01460/03692] [00:13:11/00:20:09, 0.542s/it]: train_loss_raw=0.4557, running_loss=0.5285, LR=0.000100
[2025-08-10 22:34:50,477][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075312] [Batch 01472/03692] [00:13:17/00:20:02, 0.542s/it]: train_loss_raw=0.5267, running_loss=0.5278, LR=0.000100
[2025-08-10 22:34:56,768][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075324] [Batch 01484/03692] [00:13:23/00:19:55, 0.542s/it]: train_loss_raw=0.4663, running_loss=0.5255, LR=0.000100
[2025-08-10 22:35:03,173][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075336] [Batch 01496/03692] [00:13:30/00:19:49, 0.542s/it]: train_loss_raw=0.5274, running_loss=0.5277, LR=0.000100
[2025-08-10 22:35:09,634][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075348] [Batch 01508/03692] [00:13:36/00:19:42, 0.542s/it]: train_loss_raw=0.5089, running_loss=0.5283, LR=0.000100
[2025-08-10 22:35:16,338][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075360] [Batch 01520/03692] [00:13:43/00:19:36, 0.542s/it]: train_loss_raw=0.4209, running_loss=0.5267, LR=0.000100
[2025-08-10 22:35:22,734][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075372] [Batch 01532/03692] [00:13:49/00:19:29, 0.542s/it]: train_loss_raw=0.5489, running_loss=0.5296, LR=0.000100
[2025-08-10 22:35:52,745][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075384] [Batch 01544/03692] [00:14:19/00:19:56, 0.557s/it]: train_loss_raw=0.4541, running_loss=0.5283, LR=0.000100
[2025-08-10 22:35:59,239][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075396] [Batch 01556/03692] [00:14:26/00:19:49, 0.557s/it]: train_loss_raw=0.5058, running_loss=0.5294, LR=0.000100
[2025-08-10 22:36:05,735][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075408] [Batch 01568/03692] [00:14:32/00:19:42, 0.557s/it]: train_loss_raw=0.5885, running_loss=0.5304, LR=0.000100
[2025-08-10 22:36:12,273][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075420] [Batch 01580/03692] [00:14:39/00:19:35, 0.557s/it]: train_loss_raw=0.5309, running_loss=0.5260, LR=0.000100
[2025-08-10 22:36:18,721][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075432] [Batch 01592/03692] [00:14:45/00:19:28, 0.556s/it]: train_loss_raw=0.4230, running_loss=0.5228, LR=0.000100
[2025-08-10 22:36:25,246][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075444] [Batch 01604/03692] [00:14:52/00:19:21, 0.556s/it]: train_loss_raw=0.4618, running_loss=0.5220, LR=0.000100
[2025-08-10 22:36:31,730][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075456] [Batch 01616/03692] [00:14:58/00:19:14, 0.556s/it]: train_loss_raw=0.5871, running_loss=0.5240, LR=0.000100
[2025-08-10 22:36:38,280][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075468] [Batch 01628/03692] [00:15:05/00:19:07, 0.556s/it]: train_loss_raw=0.5009, running_loss=0.5220, LR=0.000100
[2025-08-10 22:36:44,622][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075480] [Batch 01640/03692] [00:15:11/00:19:00, 0.556s/it]: train_loss_raw=0.4979, running_loss=0.5219, LR=0.000100
[2025-08-10 22:36:50,655][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075492] [Batch 01652/03692] [00:15:17/00:18:53, 0.555s/it]: train_loss_raw=0.5268, running_loss=0.5218, LR=0.000100
[2025-08-10 22:36:57,130][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075504] [Batch 01664/03692] [00:15:24/00:18:46, 0.555s/it]: train_loss_raw=0.5959, running_loss=0.5232, LR=0.000100
[2025-08-10 22:37:03,594][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075516] [Batch 01676/03692] [00:15:30/00:18:39, 0.555s/it]: train_loss_raw=0.4317, running_loss=0.5204, LR=0.000100
[2025-08-10 22:37:09,831][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075528] [Batch 01688/03692] [00:15:36/00:18:32, 0.555s/it]: train_loss_raw=0.4764, running_loss=0.5205, LR=0.000100
[2025-08-10 22:37:15,811][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075540] [Batch 01700/03692] [00:15:42/00:18:24, 0.555s/it]: train_loss_raw=0.6053, running_loss=0.5222, LR=0.000100
[2025-08-10 22:37:21,858][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075552] [Batch 01712/03692] [00:15:48/00:18:17, 0.554s/it]: train_loss_raw=0.5769, running_loss=0.5223, LR=0.000100
[2025-08-10 22:37:27,869][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075564] [Batch 01724/03692] [00:15:54/00:18:10, 0.554s/it]: train_loss_raw=0.4842, running_loss=0.5232, LR=0.000100
[2025-08-10 22:37:33,969][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075576] [Batch 01736/03692] [00:16:00/00:18:02, 0.554s/it]: train_loss_raw=0.4960, running_loss=0.5219, LR=0.000100
[2025-08-10 22:37:40,160][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075588] [Batch 01748/03692] [00:16:07/00:17:55, 0.553s/it]: train_loss_raw=0.5891, running_loss=0.5195, LR=0.000100
[2025-08-10 22:37:46,639][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075600] [Batch 01760/03692] [00:16:13/00:17:48, 0.553s/it]: train_loss_raw=0.6170, running_loss=0.5213, LR=0.000100
[2025-08-10 22:37:53,052][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075612] [Batch 01772/03692] [00:16:20/00:17:41, 0.553s/it]: train_loss_raw=0.6131, running_loss=0.5224, LR=0.000100
[2025-08-10 22:37:59,478][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075624] [Batch 01784/03692] [00:16:26/00:17:35, 0.553s/it]: train_loss_raw=0.4992, running_loss=0.5219, LR=0.000100
[2025-08-10 22:38:05,839][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075636] [Batch 01796/03692] [00:16:32/00:17:28, 0.553s/it]: train_loss_raw=0.5196, running_loss=0.5179, LR=0.000100
[2025-08-10 22:38:12,175][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075648] [Batch 01808/03692] [00:16:39/00:17:21, 0.553s/it]: train_loss_raw=0.4882, running_loss=0.5173, LR=0.000100
[2025-08-10 22:38:18,615][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075660] [Batch 01820/03692] [00:16:45/00:17:14, 0.553s/it]: train_loss_raw=0.5787, running_loss=0.5186, LR=0.000100
[2025-08-10 22:38:25,146][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075672] [Batch 01832/03692] [00:16:52/00:17:07, 0.552s/it]: train_loss_raw=0.4061, running_loss=0.5165, LR=0.000100
[2025-08-10 22:38:31,670][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075684] [Batch 01844/03692] [00:16:58/00:17:00, 0.552s/it]: train_loss_raw=0.4362, running_loss=0.5161, LR=0.000100
[2025-08-10 22:38:38,101][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075696] [Batch 01856/03692] [00:17:05/00:16:54, 0.552s/it]: train_loss_raw=0.6475, running_loss=0.5197, LR=0.000100
[2025-08-10 22:38:44,525][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075708] [Batch 01868/03692] [00:17:11/00:16:47, 0.552s/it]: train_loss_raw=0.5922, running_loss=0.5226, LR=0.000100
[2025-08-10 22:38:51,065][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075720] [Batch 01880/03692] [00:17:18/00:16:40, 0.552s/it]: train_loss_raw=0.5573, running_loss=0.5174, LR=0.000100
[2025-08-10 22:38:57,522][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075732] [Batch 01892/03692] [00:17:24/00:16:33, 0.552s/it]: train_loss_raw=0.5240, running_loss=0.5172, LR=0.000100
[2025-08-10 22:39:03,946][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075744] [Batch 01904/03692] [00:17:30/00:16:26, 0.552s/it]: train_loss_raw=0.5129, running_loss=0.5146, LR=0.000100
[2025-08-10 22:39:10,365][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075756] [Batch 01916/03692] [00:17:37/00:16:20, 0.552s/it]: train_loss_raw=0.6165, running_loss=0.5170, LR=0.000100
[2025-08-10 22:39:16,889][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075768] [Batch 01928/03692] [00:17:43/00:16:13, 0.552s/it]: train_loss_raw=0.4324, running_loss=0.5171, LR=0.000100
[2025-08-10 22:39:23,295][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075780] [Batch 01940/03692] [00:17:50/00:16:06, 0.552s/it]: train_loss_raw=0.4772, running_loss=0.5183, LR=0.000100
[2025-08-10 22:39:29,724][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075792] [Batch 01952/03692] [00:17:56/00:15:59, 0.552s/it]: train_loss_raw=0.4316, running_loss=0.5182, LR=0.000100
[2025-08-10 22:39:36,156][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075804] [Batch 01964/03692] [00:18:03/00:15:53, 0.552s/it]: train_loss_raw=0.4650, running_loss=0.5198, LR=0.000100
[2025-08-10 22:39:42,560][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075816] [Batch 01976/03692] [00:18:09/00:15:46, 0.551s/it]: train_loss_raw=0.5493, running_loss=0.5227, LR=0.000100
[2025-08-10 22:39:48,924][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075828] [Batch 01988/03692] [00:18:15/00:15:39, 0.551s/it]: train_loss_raw=0.4634, running_loss=0.5205, LR=0.000100
[2025-08-10 22:39:55,294][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075840] [Batch 02000/03692] [00:18:22/00:15:32, 0.551s/it]: train_loss_raw=0.5058, running_loss=0.5213, LR=0.000100
[2025-08-10 22:40:01,682][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075852] [Batch 02012/03692] [00:18:28/00:15:25, 0.551s/it]: train_loss_raw=0.5503, running_loss=0.5246, LR=0.000100
[2025-08-10 22:40:08,064][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075864] [Batch 02024/03692] [00:18:35/00:15:18, 0.551s/it]: train_loss_raw=0.4467, running_loss=0.5224, LR=0.000100
[2025-08-10 22:40:14,448][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075876] [Batch 02036/03692] [00:18:41/00:15:12, 0.551s/it]: train_loss_raw=0.4763, running_loss=0.5231, LR=0.000100
[2025-08-10 22:40:20,827][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075888] [Batch 02048/03692] [00:18:47/00:15:05, 0.551s/it]: train_loss_raw=0.4372, running_loss=0.5182, LR=0.000100
[2025-08-10 22:40:27,228][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075900] [Batch 02060/03692] [00:18:54/00:14:58, 0.551s/it]: train_loss_raw=0.5677, running_loss=0.5178, LR=0.000100
[2025-08-10 22:40:33,654][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075912] [Batch 02072/03692] [00:19:00/00:14:51, 0.551s/it]: train_loss_raw=0.5082, running_loss=0.5227, LR=0.000100
[2025-08-10 22:40:40,046][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075924] [Batch 02084/03692] [00:19:07/00:14:45, 0.550s/it]: train_loss_raw=0.5055, running_loss=0.5225, LR=0.000100
[2025-08-10 22:40:46,444][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075936] [Batch 02096/03692] [00:19:13/00:14:38, 0.550s/it]: train_loss_raw=0.6028, running_loss=0.5231, LR=0.000100
[2025-08-10 22:40:52,866][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075948] [Batch 02108/03692] [00:19:19/00:14:31, 0.550s/it]: train_loss_raw=0.5759, running_loss=0.5247, LR=0.000100
[2025-08-10 22:40:59,263][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075960] [Batch 02120/03692] [00:19:26/00:14:24, 0.550s/it]: train_loss_raw=0.4008, running_loss=0.5214, LR=0.000100
[2025-08-10 22:41:05,652][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075972] [Batch 02132/03692] [00:19:32/00:14:18, 0.550s/it]: train_loss_raw=0.5277, running_loss=0.5206, LR=0.000100
[2025-08-10 22:41:12,079][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075984] [Batch 02144/03692] [00:19:39/00:14:11, 0.550s/it]: train_loss_raw=0.5261, running_loss=0.5215, LR=0.000100
[2025-08-10 22:41:18,431][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 075996] [Batch 02156/03692] [00:19:45/00:14:04, 0.550s/it]: train_loss_raw=0.5495, running_loss=0.5199, LR=0.000100
[2025-08-10 22:41:29,329][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076008] [Batch 02168/03692] [00:19:56/00:14:00, 0.552s/it]: train_loss_raw=0.6898, running_loss=0.5223, LR=0.000100
[2025-08-10 22:41:35,723][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076020] [Batch 02180/03692] [00:20:02/00:13:54, 0.552s/it]: train_loss_raw=0.5078, running_loss=0.5217, LR=0.000100
[2025-08-10 22:41:42,064][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076032] [Batch 02192/03692] [00:20:09/00:13:47, 0.552s/it]: train_loss_raw=0.6532, running_loss=0.5223, LR=0.000100
[2025-08-10 22:41:48,441][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076044] [Batch 02204/03692] [00:20:15/00:13:40, 0.551s/it]: train_loss_raw=0.6335, running_loss=0.5232, LR=0.000100
[2025-08-10 22:41:54,835][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076056] [Batch 02216/03692] [00:20:21/00:13:33, 0.551s/it]: train_loss_raw=0.5367, running_loss=0.5253, LR=0.000100
[2025-08-10 22:42:01,216][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076068] [Batch 02228/03692] [00:20:28/00:13:27, 0.551s/it]: train_loss_raw=0.5468, running_loss=0.5254, LR=0.000100
[2025-08-10 22:42:07,596][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076080] [Batch 02240/03692] [00:20:34/00:13:20, 0.551s/it]: train_loss_raw=0.3400, running_loss=0.5210, LR=0.000100
[2025-08-10 22:42:14,011][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076092] [Batch 02252/03692] [00:20:41/00:13:13, 0.551s/it]: train_loss_raw=0.5616, running_loss=0.5211, LR=0.000100
[2025-08-10 22:42:20,452][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076104] [Batch 02264/03692] [00:20:47/00:13:06, 0.551s/it]: train_loss_raw=0.4825, running_loss=0.5193, LR=0.000100
[2025-08-10 22:42:26,840][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076116] [Batch 02276/03692] [00:20:53/00:13:00, 0.551s/it]: train_loss_raw=0.5407, running_loss=0.5212, LR=0.000100
[2025-08-10 22:42:33,290][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076128] [Batch 02288/03692] [00:21:00/00:12:53, 0.551s/it]: train_loss_raw=0.6556, running_loss=0.5224, LR=0.000100
[2025-08-10 22:42:39,661][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076140] [Batch 02300/03692] [00:21:06/00:12:46, 0.551s/it]: train_loss_raw=0.4274, running_loss=0.5230, LR=0.000100
[2025-08-10 22:42:46,022][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076152] [Batch 02312/03692] [00:21:13/00:12:39, 0.551s/it]: train_loss_raw=0.5130, running_loss=0.5224, LR=0.000100
[2025-08-10 22:42:52,539][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076164] [Batch 02324/03692] [00:21:19/00:12:33, 0.551s/it]: train_loss_raw=0.5290, running_loss=0.5224, LR=0.000100
[2025-08-10 22:42:59,034][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076176] [Batch 02336/03692] [00:21:26/00:12:26, 0.551s/it]: train_loss_raw=0.5164, running_loss=0.5248, LR=0.000100
[2025-08-10 22:43:05,497][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076188] [Batch 02348/03692] [00:21:32/00:12:19, 0.550s/it]: train_loss_raw=0.5924, running_loss=0.5226, LR=0.000100
[2025-08-10 22:43:12,033][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076200] [Batch 02360/03692] [00:21:39/00:12:13, 0.550s/it]: train_loss_raw=0.3774, running_loss=0.5191, LR=0.000100
[2025-08-10 22:43:18,463][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076212] [Batch 02372/03692] [00:21:45/00:12:06, 0.550s/it]: train_loss_raw=0.5071, running_loss=0.5244, LR=0.000100
[2025-08-10 22:43:24,985][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076224] [Batch 02384/03692] [00:21:52/00:11:59, 0.550s/it]: train_loss_raw=0.5904, running_loss=0.5270, LR=0.000100
[2025-08-10 22:43:31,547][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076236] [Batch 02396/03692] [00:21:58/00:11:53, 0.550s/it]: train_loss_raw=0.6651, running_loss=0.5278, LR=0.000100
[2025-08-10 22:43:37,974][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076248] [Batch 02408/03692] [00:22:05/00:11:46, 0.550s/it]: train_loss_raw=0.5026, running_loss=0.5280, LR=0.000100
[2025-08-10 22:43:44,462][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076260] [Batch 02420/03692] [00:22:11/00:11:39, 0.550s/it]: train_loss_raw=0.4203, running_loss=0.5304, LR=0.000100
[2025-08-10 22:43:51,113][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076272] [Batch 02432/03692] [00:22:18/00:11:33, 0.550s/it]: train_loss_raw=0.4261, running_loss=0.5281, LR=0.000100
[2025-08-10 22:43:57,517][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076284] [Batch 02444/03692] [00:22:24/00:11:26, 0.550s/it]: train_loss_raw=0.5249, running_loss=0.5269, LR=0.000100
[2025-08-10 22:44:03,590][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076296] [Batch 02456/03692] [00:22:30/00:11:19, 0.550s/it]: train_loss_raw=0.4702, running_loss=0.5251, LR=0.000100
[2025-08-10 22:44:10,055][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076308] [Batch 02468/03692] [00:22:37/00:11:13, 0.550s/it]: train_loss_raw=0.5225, running_loss=0.5271, LR=0.000100
[2025-08-10 22:44:16,497][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076320] [Batch 02480/03692] [00:22:43/00:11:06, 0.550s/it]: train_loss_raw=0.6030, running_loss=0.5269, LR=0.000100
[2025-08-10 22:44:23,108][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076332] [Batch 02492/03692] [00:22:50/00:10:59, 0.550s/it]: train_loss_raw=0.5336, running_loss=0.5272, LR=0.000100
[2025-08-10 22:44:29,530][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076344] [Batch 02504/03692] [00:22:56/00:10:53, 0.550s/it]: train_loss_raw=0.5340, running_loss=0.5289, LR=0.000100
[2025-08-10 22:44:35,992][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076356] [Batch 02516/03692] [00:23:03/00:10:46, 0.550s/it]: train_loss_raw=0.5856, running_loss=0.5297, LR=0.000100
[2025-08-10 22:44:42,503][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076368] [Batch 02528/03692] [00:23:09/00:10:39, 0.550s/it]: train_loss_raw=0.5519, running_loss=0.5258, LR=0.000100
[2025-08-10 22:44:49,013][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076380] [Batch 02540/03692] [00:23:16/00:10:33, 0.550s/it]: train_loss_raw=0.6289, running_loss=0.5273, LR=0.000100
[2025-08-10 22:44:55,588][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076392] [Batch 02552/03692] [00:23:22/00:10:26, 0.550s/it]: train_loss_raw=0.4847, running_loss=0.5249, LR=0.000100
[2025-08-10 22:45:02,093][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076404] [Batch 02564/03692] [00:23:29/00:10:19, 0.550s/it]: train_loss_raw=0.5991, running_loss=0.5235, LR=0.000100
[2025-08-10 22:45:08,573][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076416] [Batch 02576/03692] [00:23:35/00:10:13, 0.550s/it]: train_loss_raw=0.4139, running_loss=0.5227, LR=0.000100
[2025-08-10 22:45:14,777][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076428] [Batch 02588/03692] [00:23:41/00:10:06, 0.549s/it]: train_loss_raw=0.4931, running_loss=0.5207, LR=0.000100
[2025-08-10 22:45:20,973][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076440] [Batch 02600/03692] [00:23:48/00:09:59, 0.549s/it]: train_loss_raw=0.5345, running_loss=0.5232, LR=0.000100
[2025-08-10 22:45:27,317][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076452] [Batch 02612/03692] [00:23:54/00:09:53, 0.549s/it]: train_loss_raw=0.5063, running_loss=0.5200, LR=0.000100
[2025-08-10 22:45:33,577][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076464] [Batch 02624/03692] [00:24:00/00:09:46, 0.549s/it]: train_loss_raw=0.5536, running_loss=0.5229, LR=0.000100
[2025-08-10 22:45:39,812][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076476] [Batch 02636/03692] [00:24:06/00:09:39, 0.549s/it]: train_loss_raw=0.5589, running_loss=0.5245, LR=0.000100
[2025-08-10 22:45:46,047][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076488] [Batch 02648/03692] [00:24:13/00:09:32, 0.549s/it]: train_loss_raw=0.5310, running_loss=0.5242, LR=0.000100
[2025-08-10 22:45:52,577][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076500] [Batch 02660/03692] [00:24:19/00:09:26, 0.549s/it]: train_loss_raw=0.5993, running_loss=0.5272, LR=0.000100
[2025-08-10 22:45:59,002][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076512] [Batch 02672/03692] [00:24:26/00:09:19, 0.549s/it]: train_loss_raw=0.4561, running_loss=0.5273, LR=0.000100
[2025-08-10 22:46:05,427][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076524] [Batch 02684/03692] [00:24:32/00:09:12, 0.549s/it]: train_loss_raw=0.5062, running_loss=0.5277, LR=0.000100
[2025-08-10 22:46:11,806][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076536] [Batch 02696/03692] [00:24:38/00:09:06, 0.549s/it]: train_loss_raw=0.5081, running_loss=0.5270, LR=0.000100
[2025-08-10 22:46:18,317][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076548] [Batch 02708/03692] [00:24:45/00:08:59, 0.549s/it]: train_loss_raw=0.5866, running_loss=0.5273, LR=0.000100
[2025-08-10 22:46:24,783][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076560] [Batch 02720/03692] [00:24:51/00:08:53, 0.548s/it]: train_loss_raw=0.5777, running_loss=0.5256, LR=0.000100
[2025-08-10 22:46:31,250][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076572] [Batch 02732/03692] [00:24:58/00:08:46, 0.548s/it]: train_loss_raw=0.5177, running_loss=0.5215, LR=0.000100
[2025-08-10 22:46:37,750][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076584] [Batch 02744/03692] [00:25:04/00:08:39, 0.548s/it]: train_loss_raw=0.4628, running_loss=0.5210, LR=0.000100
[2025-08-10 22:46:44,295][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076596] [Batch 02756/03692] [00:25:11/00:08:33, 0.548s/it]: train_loss_raw=0.5019, running_loss=0.5216, LR=0.000100
[2025-08-10 22:46:50,743][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076608] [Batch 02768/03692] [00:25:17/00:08:26, 0.548s/it]: train_loss_raw=0.4683, running_loss=0.5197, LR=0.000100
[2025-08-10 22:46:57,238][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076620] [Batch 02780/03692] [00:25:24/00:08:20, 0.548s/it]: train_loss_raw=0.4935, running_loss=0.5216, LR=0.000100
[2025-08-10 22:47:03,688][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076632] [Batch 02792/03692] [00:25:30/00:08:13, 0.548s/it]: train_loss_raw=0.4705, running_loss=0.5199, LR=0.000100
[2025-08-10 22:47:09,920][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076644] [Batch 02804/03692] [00:25:36/00:08:06, 0.548s/it]: train_loss_raw=0.5493, running_loss=0.5199, LR=0.000100
[2025-08-10 22:47:15,900][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076656] [Batch 02816/03692] [00:25:42/00:07:59, 0.548s/it]: train_loss_raw=0.6247, running_loss=0.5216, LR=0.000100
[2025-08-10 22:47:22,053][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076668] [Batch 02828/03692] [00:25:49/00:07:53, 0.548s/it]: train_loss_raw=0.5715, running_loss=0.5237, LR=0.000100
[2025-08-10 22:47:28,169][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076680] [Batch 02840/03692] [00:25:55/00:07:46, 0.548s/it]: train_loss_raw=0.5963, running_loss=0.5239, LR=0.000100
[2025-08-10 22:47:34,449][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076692] [Batch 02852/03692] [00:26:01/00:07:39, 0.548s/it]: train_loss_raw=0.5098, running_loss=0.5259, LR=0.000100
[2025-08-10 22:47:40,889][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076704] [Batch 02864/03692] [00:26:07/00:07:33, 0.547s/it]: train_loss_raw=0.6515, running_loss=0.5248, LR=0.000100
[2025-08-10 22:47:47,395][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076716] [Batch 02876/03692] [00:26:14/00:07:26, 0.547s/it]: train_loss_raw=0.6447, running_loss=0.5280, LR=0.000100
[2025-08-10 22:47:53,575][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076728] [Batch 02888/03692] [00:26:20/00:07:20, 0.547s/it]: train_loss_raw=0.5877, running_loss=0.5268, LR=0.000100
[2025-08-10 22:47:59,921][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076740] [Batch 02900/03692] [00:26:26/00:07:13, 0.547s/it]: train_loss_raw=0.4525, running_loss=0.5275, LR=0.000100
[2025-08-10 22:48:05,958][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076752] [Batch 02912/03692] [00:26:32/00:07:06, 0.547s/it]: train_loss_raw=0.5870, running_loss=0.5282, LR=0.000100
[2025-08-10 22:48:12,004][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076764] [Batch 02924/03692] [00:26:39/00:06:59, 0.547s/it]: train_loss_raw=0.4531, running_loss=0.5241, LR=0.000100
[2025-08-10 22:48:18,058][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076776] [Batch 02936/03692] [00:26:45/00:06:53, 0.547s/it]: train_loss_raw=0.5631, running_loss=0.5227, LR=0.000100
[2025-08-10 22:48:24,112][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076788] [Batch 02948/03692] [00:26:51/00:06:46, 0.547s/it]: train_loss_raw=0.4920, running_loss=0.5234, LR=0.000100
[2025-08-10 22:48:30,606][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076800] [Batch 02960/03692] [00:26:57/00:06:40, 0.546s/it]: train_loss_raw=0.4811, running_loss=0.5230, LR=0.000100
[2025-08-10 22:48:37,074][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076812] [Batch 02972/03692] [00:27:04/00:06:33, 0.546s/it]: train_loss_raw=0.6202, running_loss=0.5230, LR=0.000100
[2025-08-10 22:48:43,592][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076824] [Batch 02984/03692] [00:27:10/00:06:26, 0.546s/it]: train_loss_raw=0.5567, running_loss=0.5237, LR=0.000100
[2025-08-10 22:48:50,053][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076836] [Batch 02996/03692] [00:27:17/00:06:20, 0.546s/it]: train_loss_raw=0.4702, running_loss=0.5195, LR=0.000100
[2025-08-10 22:48:56,524][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076848] [Batch 03008/03692] [00:27:23/00:06:13, 0.546s/it]: train_loss_raw=0.4456, running_loss=0.5177, LR=0.000100
[2025-08-10 22:49:02,963][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076860] [Batch 03020/03692] [00:27:29/00:06:07, 0.546s/it]: train_loss_raw=0.5735, running_loss=0.5173, LR=0.000100
[2025-08-10 22:49:09,419][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076872] [Batch 03032/03692] [00:27:36/00:06:00, 0.546s/it]: train_loss_raw=0.4794, running_loss=0.5187, LR=0.000100
[2025-08-10 22:49:15,878][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076884] [Batch 03044/03692] [00:27:42/00:05:53, 0.546s/it]: train_loss_raw=0.5652, running_loss=0.5170, LR=0.000100
[2025-08-10 22:49:22,248][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076896] [Batch 03056/03692] [00:27:49/00:05:47, 0.546s/it]: train_loss_raw=0.3672, running_loss=0.5165, LR=0.000100
[2025-08-10 22:49:28,597][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076908] [Batch 03068/03692] [00:27:55/00:05:40, 0.546s/it]: train_loss_raw=0.4443, running_loss=0.5152, LR=0.000100
[2025-08-10 22:49:34,999][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076920] [Batch 03080/03692] [00:28:02/00:05:34, 0.546s/it]: train_loss_raw=0.5639, running_loss=0.5156, LR=0.000100
[2025-08-10 22:49:41,427][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076932] [Batch 03092/03692] [00:28:08/00:05:27, 0.546s/it]: train_loss_raw=0.5189, running_loss=0.5164, LR=0.000100
[2025-08-10 22:49:47,835][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076944] [Batch 03104/03692] [00:28:14/00:05:21, 0.546s/it]: train_loss_raw=0.4917, running_loss=0.5185, LR=0.000100
[2025-08-10 22:49:54,128][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076956] [Batch 03116/03692] [00:28:21/00:05:14, 0.546s/it]: train_loss_raw=0.5345, running_loss=0.5166, LR=0.000100
[2025-08-10 22:50:00,538][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076968] [Batch 03128/03692] [00:28:27/00:05:07, 0.546s/it]: train_loss_raw=0.4691, running_loss=0.5176, LR=0.000100
[2025-08-10 22:50:06,946][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076980] [Batch 03140/03692] [00:28:33/00:05:01, 0.546s/it]: train_loss_raw=0.4953, running_loss=0.5172, LR=0.000100
[2025-08-10 22:50:13,385][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 076992] [Batch 03152/03692] [00:28:40/00:04:54, 0.546s/it]: train_loss_raw=0.5629, running_loss=0.5197, LR=0.000100
[2025-08-10 22:50:19,734][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077004] [Batch 03164/03692] [00:28:46/00:04:48, 0.546s/it]: train_loss_raw=0.6273, running_loss=0.5205, LR=0.000100
[2025-08-10 22:50:26,105][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077016] [Batch 03176/03692] [00:28:53/00:04:41, 0.546s/it]: train_loss_raw=0.3929, running_loss=0.5184, LR=0.000100
[2025-08-10 22:50:32,655][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077028] [Batch 03188/03692] [00:28:59/00:04:35, 0.546s/it]: train_loss_raw=0.5721, running_loss=0.5219, LR=0.000100
[2025-08-10 22:50:39,112][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077040] [Batch 03200/03692] [00:29:06/00:04:28, 0.546s/it]: train_loss_raw=0.5315, running_loss=0.5229, LR=0.000100
[2025-08-10 22:50:45,691][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077052] [Batch 03212/03692] [00:29:12/00:04:21, 0.546s/it]: train_loss_raw=0.4703, running_loss=0.5221, LR=0.000100
[2025-08-10 22:50:52,190][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077064] [Batch 03224/03692] [00:29:19/00:04:15, 0.546s/it]: train_loss_raw=0.6300, running_loss=0.5220, LR=0.000100
[2025-08-10 22:50:58,711][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077076] [Batch 03236/03692] [00:29:25/00:04:08, 0.546s/it]: train_loss_raw=0.5020, running_loss=0.5194, LR=0.000100
[2025-08-10 22:51:05,274][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077088] [Batch 03248/03692] [00:29:32/00:04:02, 0.546s/it]: train_loss_raw=0.5047, running_loss=0.5175, LR=0.000100
[2025-08-10 22:51:11,821][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077100] [Batch 03260/03692] [00:29:38/00:03:55, 0.546s/it]: train_loss_raw=0.5362, running_loss=0.5173, LR=0.000100
[2025-08-10 22:51:18,358][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077112] [Batch 03272/03692] [00:29:45/00:03:49, 0.546s/it]: train_loss_raw=0.4863, running_loss=0.5175, LR=0.000100
[2025-08-10 22:51:24,904][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077124] [Batch 03284/03692] [00:29:51/00:03:42, 0.546s/it]: train_loss_raw=0.5738, running_loss=0.5177, LR=0.000100
[2025-08-10 22:51:31,305][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077136] [Batch 03296/03692] [00:29:58/00:03:36, 0.546s/it]: train_loss_raw=0.4921, running_loss=0.5198, LR=0.000100
[2025-08-10 22:51:37,751][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077148] [Batch 03308/03692] [00:30:04/00:03:29, 0.546s/it]: train_loss_raw=0.5546, running_loss=0.5195, LR=0.000100
[2025-08-10 22:51:44,140][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077160] [Batch 03320/03692] [00:30:11/00:03:22, 0.546s/it]: train_loss_raw=0.5806, running_loss=0.5223, LR=0.000100
[2025-08-10 22:51:50,485][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077172] [Batch 03332/03692] [00:30:17/00:03:16, 0.545s/it]: train_loss_raw=0.5066, running_loss=0.5208, LR=0.000100
[2025-08-10 22:51:56,994][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077184] [Batch 03344/03692] [00:30:24/00:03:09, 0.545s/it]: train_loss_raw=0.5122, running_loss=0.5160, LR=0.000100
[2025-08-10 22:52:03,462][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077196] [Batch 03356/03692] [00:30:30/00:03:03, 0.545s/it]: train_loss_raw=0.5461, running_loss=0.5158, LR=0.000100
[2025-08-10 22:52:09,930][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077208] [Batch 03368/03692] [00:30:36/00:02:56, 0.545s/it]: train_loss_raw=0.5464, running_loss=0.5191, LR=0.000100
[2025-08-10 22:52:16,278][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077220] [Batch 03380/03692] [00:30:43/00:02:50, 0.545s/it]: train_loss_raw=0.6060, running_loss=0.5206, LR=0.000100
[2025-08-10 22:52:22,637][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077232] [Batch 03392/03692] [00:30:49/00:02:43, 0.545s/it]: train_loss_raw=0.5548, running_loss=0.5189, LR=0.000100
[2025-08-10 22:52:28,962][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077244] [Batch 03404/03692] [00:30:55/00:02:37, 0.545s/it]: train_loss_raw=0.6259, running_loss=0.5212, LR=0.000100
[2025-08-10 22:52:35,512][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077256] [Batch 03416/03692] [00:31:02/00:02:30, 0.545s/it]: train_loss_raw=0.3625, running_loss=0.5199, LR=0.000100
[2025-08-10 22:52:42,059][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077268] [Batch 03428/03692] [00:31:09/00:02:23, 0.545s/it]: train_loss_raw=0.3867, running_loss=0.5157, LR=0.000100
[2025-08-10 22:52:48,521][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077280] [Batch 03440/03692] [00:31:15/00:02:17, 0.545s/it]: train_loss_raw=0.6021, running_loss=0.5164, LR=0.000100
[2025-08-10 22:52:54,930][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077292] [Batch 03452/03692] [00:31:21/00:02:10, 0.545s/it]: train_loss_raw=0.4837, running_loss=0.5167, LR=0.000100
[2025-08-10 22:53:01,389][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077304] [Batch 03464/03692] [00:31:28/00:02:04, 0.545s/it]: train_loss_raw=0.4919, running_loss=0.5185, LR=0.000100
[2025-08-10 22:53:07,815][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077316] [Batch 03476/03692] [00:31:34/00:01:57, 0.545s/it]: train_loss_raw=0.5355, running_loss=0.5184, LR=0.000100
[2025-08-10 22:53:14,220][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077328] [Batch 03488/03692] [00:31:41/00:01:51, 0.545s/it]: train_loss_raw=0.5073, running_loss=0.5163, LR=0.000100
[2025-08-10 22:53:20,589][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077340] [Batch 03500/03692] [00:31:47/00:01:44, 0.545s/it]: train_loss_raw=0.5636, running_loss=0.5200, LR=0.000100
[2025-08-10 22:53:27,110][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077352] [Batch 03512/03692] [00:31:54/00:01:38, 0.545s/it]: train_loss_raw=0.4415, running_loss=0.5200, LR=0.000100
[2025-08-10 22:53:33,671][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077364] [Batch 03524/03692] [00:32:00/00:01:31, 0.545s/it]: train_loss_raw=0.4331, running_loss=0.5168, LR=0.000100
[2025-08-10 22:53:40,032][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077376] [Batch 03536/03692] [00:32:07/00:01:25, 0.545s/it]: train_loss_raw=0.4301, running_loss=0.5166, LR=0.000100
[2025-08-10 22:53:46,437][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077388] [Batch 03548/03692] [00:32:13/00:01:18, 0.545s/it]: train_loss_raw=0.5621, running_loss=0.5170, LR=0.000100
[2025-08-10 22:53:52,795][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077400] [Batch 03560/03692] [00:32:19/00:01:11, 0.545s/it]: train_loss_raw=0.4374, running_loss=0.5148, LR=0.000100
[2025-08-10 22:53:59,191][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077412] [Batch 03572/03692] [00:32:26/00:01:05, 0.545s/it]: train_loss_raw=0.3684, running_loss=0.5125, LR=0.000100
[2025-08-10 22:54:05,629][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077424] [Batch 03584/03692] [00:32:32/00:00:58, 0.545s/it]: train_loss_raw=0.5083, running_loss=0.5123, LR=0.000100
[2025-08-10 22:54:11,983][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077436] [Batch 03596/03692] [00:32:39/00:00:52, 0.545s/it]: train_loss_raw=0.4743, running_loss=0.5131, LR=0.000100
[2025-08-10 22:54:18,422][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077448] [Batch 03608/03692] [00:32:45/00:00:45, 0.545s/it]: train_loss_raw=0.5199, running_loss=0.5163, LR=0.000100
[2025-08-10 22:54:24,984][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077460] [Batch 03620/03692] [00:32:52/00:00:39, 0.545s/it]: train_loss_raw=0.5645, running_loss=0.5164, LR=0.000100
[2025-08-10 22:54:31,531][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077472] [Batch 03632/03692] [00:32:58/00:00:32, 0.545s/it]: train_loss_raw=0.4779, running_loss=0.5158, LR=0.000100
[2025-08-10 22:54:38,036][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077484] [Batch 03644/03692] [00:33:05/00:00:26, 0.545s/it]: train_loss_raw=0.5851, running_loss=0.5126, LR=0.000100
[2025-08-10 22:54:44,535][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077496] [Batch 03656/03692] [00:33:11/00:00:19, 0.545s/it]: train_loss_raw=0.4535, running_loss=0.5108, LR=0.000100
[2025-08-10 22:54:51,060][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077508] [Batch 03668/03692] [00:33:18/00:00:13, 0.545s/it]: train_loss_raw=0.5384, running_loss=0.5103, LR=0.000100
[2025-08-10 22:54:57,539][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077520] [Batch 03680/03692] [00:33:24/00:00:06, 0.545s/it]: train_loss_raw=0.4653, running_loss=0.5128, LR=0.000100
[2025-08-10 22:55:03,868][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 077532] [Batch 03692/03692] [00:33:30/00:00:00, 0.545s/it]: train_loss_raw=0.6646, running_loss=0.5168, LR=0.000100
[2025-08-10 22:55:09,116][__main__][INFO] - [VALIDATION] [Epoch 20/29] Starting validation.
[2025-08-10 22:55:42,294][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 077533] [Batch 00011/00025] [00:00:33/00:00:35, 2.765s/it]
[2025-08-10 22:55:56,825][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 077533] [Batch 00023/00025] [00:00:47/00:00:01, 1.988s/it]
[2025-08-10 22:55:57,822][__main__][INFO] - [VALIDATION] [Epoch 20/29] train_loss=0.51683, valid_loss=0.62055
[2025-08-10 22:55:57,822][__main__][INFO] - [VALIDATION] [Epoch 20/29] Metrics:
[2025-08-10 22:55:57,822][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_er      0.266
[2025-08-10 22:55:57,822][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_prec    0.497
[2025-08-10 22:55:57,822][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_recall  0.501
[2025-08-10 22:55:57,822][__main__][INFO] - [VALIDATION] [Epoch 20/29] - pep_recall 0.479
[2025-08-10 22:55:57,825][__main__][INFO] - [TRAIN] [Epoch 20/29] Epoch complete, total time 11:59:57, remaining time 05:08:33, 00:34:17 per epoch
[2025-08-10 22:56:04,116][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077544] [Batch 00012/03692] [00:00:06/00:30:52, 0.503s/it]: train_loss_raw=0.4287, running_loss=0.4240, LR=0.000100
[2025-08-10 22:56:10,603][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077556] [Batch 00024/03692] [00:00:12/00:31:54, 0.522s/it]: train_loss_raw=0.6049, running_loss=0.4346, LR=0.000100
[2025-08-10 22:56:17,049][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077568] [Batch 00036/03692] [00:00:18/00:32:06, 0.527s/it]: train_loss_raw=0.5411, running_loss=0.4429, LR=0.000100
[2025-08-10 22:56:23,440][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077580] [Batch 00048/03692] [00:00:25/00:32:05, 0.528s/it]: train_loss_raw=0.6246, running_loss=0.4518, LR=0.000100
[2025-08-10 22:56:29,483][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077592] [Batch 00060/03692] [00:00:31/00:31:41, 0.523s/it]: train_loss_raw=0.5394, running_loss=0.4624, LR=0.000100
[2025-08-10 22:56:35,844][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077604] [Batch 00072/03692] [00:00:37/00:31:38, 0.525s/it]: train_loss_raw=0.3689, running_loss=0.4680, LR=0.000100
[2025-08-10 22:56:42,393][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077616] [Batch 00084/03692] [00:00:44/00:31:43, 0.528s/it]: train_loss_raw=0.5207, running_loss=0.4747, LR=0.000100
[2025-08-10 22:56:48,945][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077628] [Batch 00096/03692] [00:00:50/00:31:45, 0.530s/it]: train_loss_raw=0.4855, running_loss=0.4789, LR=0.000100
[2025-08-10 22:56:55,434][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077640] [Batch 00108/03692] [00:00:57/00:31:43, 0.531s/it]: train_loss_raw=0.5282, running_loss=0.4822, LR=0.000100
[2025-08-10 22:57:01,925][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077652] [Batch 00120/03692] [00:01:03/00:31:40, 0.532s/it]: train_loss_raw=0.5665, running_loss=0.4871, LR=0.000100
[2025-08-10 22:57:08,427][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077664] [Batch 00132/03692] [00:01:10/00:31:37, 0.533s/it]: train_loss_raw=0.4820, running_loss=0.4897, LR=0.000100
[2025-08-10 22:57:14,922][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077676] [Batch 00144/03692] [00:01:16/00:31:33, 0.534s/it]: train_loss_raw=0.5673, running_loss=0.4940, LR=0.000100
[2025-08-10 22:57:21,321][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077688] [Batch 00156/03692] [00:01:23/00:31:26, 0.534s/it]: train_loss_raw=0.4882, running_loss=0.4943, LR=0.000100
[2025-08-10 22:57:27,704][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077700] [Batch 00168/03692] [00:01:29/00:31:20, 0.533s/it]: train_loss_raw=0.5821, running_loss=0.4938, LR=0.000100
[2025-08-10 22:57:34,067][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077712] [Batch 00180/03692] [00:01:35/00:31:12, 0.533s/it]: train_loss_raw=0.5049, running_loss=0.4943, LR=0.000100
[2025-08-10 22:57:40,616][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077724] [Batch 00192/03692] [00:01:42/00:31:09, 0.534s/it]: train_loss_raw=0.5568, running_loss=0.4975, LR=0.000100
[2025-08-10 22:57:47,034][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077736] [Batch 00204/03692] [00:01:48/00:31:02, 0.534s/it]: train_loss_raw=0.5880, running_loss=0.5022, LR=0.000100
[2025-08-10 22:57:53,478][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077748] [Batch 00216/03692] [00:01:55/00:30:57, 0.534s/it]: train_loss_raw=0.4370, running_loss=0.4996, LR=0.000100
[2025-08-10 22:57:59,800][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077760] [Batch 00228/03692] [00:02:01/00:30:49, 0.534s/it]: train_loss_raw=0.5465, running_loss=0.4988, LR=0.000100
[2025-08-10 22:58:06,298][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077772] [Batch 00240/03692] [00:02:08/00:30:44, 0.534s/it]: train_loss_raw=0.5211, running_loss=0.4988, LR=0.000100
[2025-08-10 22:58:12,675][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077784] [Batch 00252/03692] [00:02:14/00:30:37, 0.534s/it]: train_loss_raw=0.4484, running_loss=0.4985, LR=0.000100
[2025-08-10 22:58:19,103][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077796] [Batch 00264/03692] [00:02:21/00:30:31, 0.534s/it]: train_loss_raw=0.5405, running_loss=0.5021, LR=0.000100
[2025-08-10 22:58:25,670][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077808] [Batch 00276/03692] [00:02:27/00:30:26, 0.535s/it]: train_loss_raw=0.5664, running_loss=0.5084, LR=0.000100
[2025-08-10 22:58:32,321][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077820] [Batch 00288/03692] [00:02:34/00:30:23, 0.536s/it]: train_loss_raw=0.5090, running_loss=0.5094, LR=0.000100
[2025-08-10 22:58:38,872][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077832] [Batch 00300/03692] [00:02:40/00:30:18, 0.536s/it]: train_loss_raw=0.4882, running_loss=0.5117, LR=0.000100
[2025-08-10 22:58:45,367][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077844] [Batch 00312/03692] [00:02:47/00:30:12, 0.536s/it]: train_loss_raw=0.5554, running_loss=0.5092, LR=0.000100
[2025-08-10 22:58:51,538][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077856] [Batch 00324/03692] [00:02:53/00:30:03, 0.535s/it]: train_loss_raw=0.5581, running_loss=0.5125, LR=0.000100
[2025-08-10 22:58:58,101][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077868] [Batch 00336/03692] [00:03:00/00:29:58, 0.536s/it]: train_loss_raw=0.4682, running_loss=0.5110, LR=0.000100
[2025-08-10 22:59:04,685][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077880] [Batch 00348/03692] [00:03:06/00:29:53, 0.536s/it]: train_loss_raw=0.5775, running_loss=0.5116, LR=0.000100
[2025-08-10 22:59:11,192][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077892] [Batch 00360/03692] [00:03:13/00:29:47, 0.536s/it]: train_loss_raw=0.4456, running_loss=0.5121, LR=0.000100
[2025-08-10 22:59:17,761][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077904] [Batch 00372/03692] [00:03:19/00:29:42, 0.537s/it]: train_loss_raw=0.4991, running_loss=0.5136, LR=0.000100
[2025-08-10 22:59:24,267][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077916] [Batch 00384/03692] [00:03:26/00:29:36, 0.537s/it]: train_loss_raw=0.4450, running_loss=0.5122, LR=0.000100
[2025-08-10 22:59:30,811][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077928] [Batch 00396/03692] [00:03:32/00:29:30, 0.537s/it]: train_loss_raw=0.4405, running_loss=0.5120, LR=0.000100
[2025-08-10 22:59:37,304][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077940] [Batch 00408/03692] [00:03:39/00:29:24, 0.537s/it]: train_loss_raw=0.4440, running_loss=0.5064, LR=0.000100
[2025-08-10 22:59:43,764][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077952] [Batch 00420/03692] [00:03:45/00:29:18, 0.537s/it]: train_loss_raw=0.5566, running_loss=0.5092, LR=0.000100
[2025-08-10 22:59:50,272][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077964] [Batch 00432/03692] [00:03:52/00:29:12, 0.537s/it]: train_loss_raw=0.5400, running_loss=0.5125, LR=0.000100
[2025-08-10 22:59:56,683][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077976] [Batch 00444/03692] [00:03:58/00:29:05, 0.537s/it]: train_loss_raw=0.4488, running_loss=0.5118, LR=0.000100
[2025-08-10 23:00:03,029][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 077988] [Batch 00456/03692] [00:04:04/00:28:58, 0.537s/it]: train_loss_raw=0.5042, running_loss=0.5127, LR=0.000100
[2025-08-10 23:00:09,420][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078000] [Batch 00468/03692] [00:04:11/00:28:51, 0.537s/it]: train_loss_raw=0.5142, running_loss=0.5135, LR=0.000100
[2025-08-10 23:00:20,321][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078012] [Batch 00480/03692] [00:04:22/00:29:14, 0.546s/it]: train_loss_raw=0.5014, running_loss=0.5118, LR=0.000100
[2025-08-10 23:00:26,736][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078024] [Batch 00492/03692] [00:04:28/00:29:07, 0.546s/it]: train_loss_raw=0.4701, running_loss=0.5117, LR=0.000100
[2025-08-10 23:00:33,209][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078036] [Batch 00504/03692] [00:04:35/00:29:00, 0.546s/it]: train_loss_raw=0.4535, running_loss=0.5104, LR=0.000100
[2025-08-10 23:00:39,595][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078048] [Batch 00516/03692] [00:04:41/00:28:52, 0.546s/it]: train_loss_raw=0.5117, running_loss=0.5089, LR=0.000100
[2025-08-10 23:00:46,018][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078060] [Batch 00528/03692] [00:04:47/00:28:45, 0.545s/it]: train_loss_raw=0.4148, running_loss=0.5062, LR=0.000100
[2025-08-10 23:00:52,473][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078072] [Batch 00540/03692] [00:04:54/00:28:38, 0.545s/it]: train_loss_raw=0.4315, running_loss=0.5064, LR=0.000100
[2025-08-10 23:00:58,846][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078084] [Batch 00552/03692] [00:05:00/00:28:30, 0.545s/it]: train_loss_raw=0.5013, running_loss=0.5082, LR=0.000100
[2025-08-10 23:01:05,252][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078096] [Batch 00564/03692] [00:05:07/00:28:23, 0.545s/it]: train_loss_raw=0.5247, running_loss=0.5104, LR=0.000100
[2025-08-10 23:01:11,665][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078108] [Batch 00576/03692] [00:05:13/00:28:16, 0.544s/it]: train_loss_raw=0.5806, running_loss=0.5074, LR=0.000100
[2025-08-10 23:01:18,009][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078120] [Batch 00588/03692] [00:05:19/00:28:08, 0.544s/it]: train_loss_raw=0.4329, running_loss=0.5057, LR=0.000100
[2025-08-10 23:01:24,444][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078132] [Batch 00600/03692] [00:05:26/00:28:01, 0.544s/it]: train_loss_raw=0.6483, running_loss=0.5108, LR=0.000100
[2025-08-10 23:01:30,817][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078144] [Batch 00612/03692] [00:05:32/00:27:54, 0.544s/it]: train_loss_raw=0.4685, running_loss=0.5123, LR=0.000100
[2025-08-10 23:01:37,357][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078156] [Batch 00624/03692] [00:05:39/00:27:48, 0.544s/it]: train_loss_raw=0.5152, running_loss=0.5111, LR=0.000100
[2025-08-10 23:01:43,889][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078168] [Batch 00636/03692] [00:05:45/00:27:41, 0.544s/it]: train_loss_raw=0.5068, running_loss=0.5117, LR=0.000100
[2025-08-10 23:01:50,390][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078180] [Batch 00648/03692] [00:05:52/00:27:35, 0.544s/it]: train_loss_raw=0.3910, running_loss=0.5081, LR=0.000100
[2025-08-10 23:01:56,834][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078192] [Batch 00660/03692] [00:05:58/00:27:28, 0.544s/it]: train_loss_raw=0.5222, running_loss=0.5071, LR=0.000100
[2025-08-10 23:02:03,256][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078204] [Batch 00672/03692] [00:06:05/00:27:21, 0.543s/it]: train_loss_raw=0.4949, running_loss=0.5074, LR=0.000100
[2025-08-10 23:02:09,645][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078216] [Batch 00684/03692] [00:06:11/00:27:14, 0.543s/it]: train_loss_raw=0.4377, running_loss=0.5086, LR=0.000100
[2025-08-10 23:02:16,049][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078228] [Batch 00696/03692] [00:06:17/00:27:07, 0.543s/it]: train_loss_raw=0.5187, running_loss=0.5089, LR=0.000100
[2025-08-10 23:02:22,454][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078240] [Batch 00708/03692] [00:06:24/00:27:00, 0.543s/it]: train_loss_raw=0.4124, running_loss=0.5047, LR=0.000100
[2025-08-10 23:02:28,929][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078252] [Batch 00720/03692] [00:06:30/00:26:53, 0.543s/it]: train_loss_raw=0.5129, running_loss=0.5037, LR=0.000100
[2025-08-10 23:02:35,411][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078264] [Batch 00732/03692] [00:06:37/00:26:46, 0.543s/it]: train_loss_raw=0.5063, running_loss=0.5019, LR=0.000100
[2025-08-10 23:02:41,772][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078276] [Batch 00744/03692] [00:06:43/00:26:39, 0.543s/it]: train_loss_raw=0.5045, running_loss=0.5049, LR=0.000100
[2025-08-10 23:02:48,310][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078288] [Batch 00756/03692] [00:06:50/00:26:33, 0.543s/it]: train_loss_raw=0.5434, running_loss=0.5045, LR=0.000100
[2025-08-10 23:02:54,867][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078300] [Batch 00768/03692] [00:06:56/00:26:26, 0.543s/it]: train_loss_raw=0.4881, running_loss=0.5031, LR=0.000100
[2025-08-10 23:03:01,219][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078312] [Batch 00780/03692] [00:07:03/00:26:19, 0.542s/it]: train_loss_raw=0.5130, running_loss=0.5049, LR=0.000100
[2025-08-10 23:03:07,631][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078324] [Batch 00792/03692] [00:07:09/00:26:12, 0.542s/it]: train_loss_raw=0.4293, running_loss=0.5040, LR=0.000100
[2025-08-10 23:03:13,972][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078336] [Batch 00804/03692] [00:07:15/00:26:05, 0.542s/it]: train_loss_raw=0.4844, running_loss=0.5035, LR=0.000100
[2025-08-10 23:03:20,335][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078348] [Batch 00816/03692] [00:07:22/00:25:58, 0.542s/it]: train_loss_raw=0.5795, running_loss=0.5058, LR=0.000100
[2025-08-10 23:03:26,761][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078360] [Batch 00828/03692] [00:07:28/00:25:51, 0.542s/it]: train_loss_raw=0.5531, running_loss=0.5064, LR=0.000100
[2025-08-10 23:03:33,276][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078372] [Batch 00840/03692] [00:07:35/00:25:45, 0.542s/it]: train_loss_raw=0.6041, running_loss=0.5067, LR=0.000100
[2025-08-10 23:03:39,518][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078384] [Batch 00852/03692] [00:07:41/00:25:38, 0.542s/it]: train_loss_raw=0.5290, running_loss=0.5067, LR=0.000100
[2025-08-10 23:03:45,855][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078396] [Batch 00864/03692] [00:07:47/00:25:31, 0.541s/it]: train_loss_raw=0.4288, running_loss=0.5077, LR=0.000100
[2025-08-10 23:03:52,222][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078408] [Batch 00876/03692] [00:07:54/00:25:24, 0.541s/it]: train_loss_raw=0.5904, running_loss=0.5121, LR=0.000100
[2025-08-10 23:03:58,551][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078420] [Batch 00888/03692] [00:08:00/00:25:17, 0.541s/it]: train_loss_raw=0.4312, running_loss=0.5096, LR=0.000100
[2025-08-10 23:04:04,929][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078432] [Batch 00900/03692] [00:08:06/00:25:10, 0.541s/it]: train_loss_raw=0.5717, running_loss=0.5113, LR=0.000100
[2025-08-10 23:04:11,288][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078444] [Batch 00912/03692] [00:08:13/00:25:03, 0.541s/it]: train_loss_raw=0.5056, running_loss=0.5097, LR=0.000100
[2025-08-10 23:04:17,624][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078456] [Batch 00924/03692] [00:08:19/00:24:56, 0.541s/it]: train_loss_raw=0.4588, running_loss=0.5073, LR=0.000100
[2025-08-10 23:04:24,032][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078468] [Batch 00936/03692] [00:08:25/00:24:49, 0.541s/it]: train_loss_raw=0.5478, running_loss=0.5066, LR=0.000100
[2025-08-10 23:04:30,470][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078480] [Batch 00948/03692] [00:08:32/00:24:43, 0.541s/it]: train_loss_raw=0.6659, running_loss=0.5093, LR=0.000100
[2025-08-10 23:04:36,875][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078492] [Batch 00960/03692] [00:08:38/00:24:36, 0.540s/it]: train_loss_raw=0.5438, running_loss=0.5099, LR=0.000100
[2025-08-10 23:04:43,282][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078504] [Batch 00972/03692] [00:08:45/00:24:29, 0.540s/it]: train_loss_raw=0.4793, running_loss=0.5092, LR=0.000100
[2025-08-10 23:04:49,653][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078516] [Batch 00984/03692] [00:08:51/00:24:22, 0.540s/it]: train_loss_raw=0.5303, running_loss=0.5095, LR=0.000100
[2025-08-10 23:04:55,983][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078528] [Batch 00996/03692] [00:08:57/00:24:16, 0.540s/it]: train_loss_raw=0.5127, running_loss=0.5101, LR=0.000100
[2025-08-10 23:05:02,431][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078540] [Batch 01008/03692] [00:09:04/00:24:09, 0.540s/it]: train_loss_raw=0.5987, running_loss=0.5107, LR=0.000100
[2025-08-10 23:05:09,018][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078552] [Batch 01020/03692] [00:09:10/00:24:03, 0.540s/it]: train_loss_raw=0.4762, running_loss=0.5100, LR=0.000100
[2025-08-10 23:05:15,529][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078564] [Batch 01032/03692] [00:09:17/00:23:56, 0.540s/it]: train_loss_raw=0.5047, running_loss=0.5099, LR=0.000100
[2025-08-10 23:05:21,948][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078576] [Batch 01044/03692] [00:09:23/00:23:50, 0.540s/it]: train_loss_raw=0.5132, running_loss=0.5086, LR=0.000100
[2025-08-10 23:05:28,322][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078588] [Batch 01056/03692] [00:09:30/00:23:43, 0.540s/it]: train_loss_raw=0.4986, running_loss=0.5072, LR=0.000100
[2025-08-10 23:05:34,596][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078600] [Batch 01068/03692] [00:09:36/00:23:36, 0.540s/it]: train_loss_raw=0.5682, running_loss=0.5066, LR=0.000100
[2025-08-10 23:05:40,953][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078612] [Batch 01080/03692] [00:09:42/00:23:29, 0.540s/it]: train_loss_raw=0.4403, running_loss=0.5044, LR=0.000100
[2025-08-10 23:05:47,423][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078624] [Batch 01092/03692] [00:09:49/00:23:23, 0.540s/it]: train_loss_raw=0.4574, running_loss=0.5022, LR=0.000100
[2025-08-10 23:05:53,751][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078636] [Batch 01104/03692] [00:09:55/00:23:16, 0.540s/it]: train_loss_raw=0.6123, running_loss=0.5021, LR=0.000100
[2025-08-10 23:06:00,084][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078648] [Batch 01116/03692] [00:10:02/00:23:09, 0.539s/it]: train_loss_raw=0.4622, running_loss=0.5047, LR=0.000100
[2025-08-10 23:06:06,523][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078660] [Batch 01128/03692] [00:10:08/00:23:03, 0.539s/it]: train_loss_raw=0.5248, running_loss=0.5011, LR=0.000100
[2025-08-10 23:06:13,087][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078672] [Batch 01140/03692] [00:10:15/00:22:56, 0.539s/it]: train_loss_raw=0.5509, running_loss=0.5001, LR=0.000100
[2025-08-10 23:06:19,558][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078684] [Batch 01152/03692] [00:10:21/00:22:50, 0.539s/it]: train_loss_raw=0.5520, running_loss=0.5000, LR=0.000100
[2025-08-10 23:06:26,018][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078696] [Batch 01164/03692] [00:10:27/00:22:43, 0.539s/it]: train_loss_raw=0.4419, running_loss=0.5019, LR=0.000100
[2025-08-10 23:06:32,520][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078708] [Batch 01176/03692] [00:10:34/00:22:37, 0.539s/it]: train_loss_raw=0.4629, running_loss=0.5021, LR=0.000100
[2025-08-10 23:06:38,909][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078720] [Batch 01188/03692] [00:10:40/00:22:30, 0.539s/it]: train_loss_raw=0.4386, running_loss=0.5073, LR=0.000100
[2025-08-10 23:06:45,418][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078732] [Batch 01200/03692] [00:10:47/00:22:24, 0.539s/it]: train_loss_raw=0.5567, running_loss=0.5075, LR=0.000100
[2025-08-10 23:06:51,806][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078744] [Batch 01212/03692] [00:10:53/00:22:17, 0.539s/it]: train_loss_raw=0.4951, running_loss=0.5102, LR=0.000100
[2025-08-10 23:06:58,245][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078756] [Batch 01224/03692] [00:11:00/00:22:11, 0.539s/it]: train_loss_raw=0.6449, running_loss=0.5126, LR=0.000100
[2025-08-10 23:07:04,636][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078768] [Batch 01236/03692] [00:11:06/00:22:04, 0.539s/it]: train_loss_raw=0.5515, running_loss=0.5140, LR=0.000100
[2025-08-10 23:07:11,012][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078780] [Batch 01248/03692] [00:11:12/00:21:57, 0.539s/it]: train_loss_raw=0.4585, running_loss=0.5095, LR=0.000100
[2025-08-10 23:07:17,401][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078792] [Batch 01260/03692] [00:11:19/00:21:51, 0.539s/it]: train_loss_raw=0.5509, running_loss=0.5082, LR=0.000100
[2025-08-10 23:07:23,773][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078804] [Batch 01272/03692] [00:11:25/00:21:44, 0.539s/it]: train_loss_raw=0.4326, running_loss=0.5051, LR=0.000100
[2025-08-10 23:07:30,291][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078816] [Batch 01284/03692] [00:11:32/00:21:38, 0.539s/it]: train_loss_raw=0.4915, running_loss=0.5044, LR=0.000100
[2025-08-10 23:07:36,840][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078828] [Batch 01296/03692] [00:11:38/00:21:31, 0.539s/it]: train_loss_raw=0.4257, running_loss=0.5002, LR=0.000100
[2025-08-10 23:07:43,318][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078840] [Batch 01308/03692] [00:11:45/00:21:25, 0.539s/it]: train_loss_raw=0.4018, running_loss=0.4952, LR=0.000100
[2025-08-10 23:07:49,841][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078852] [Batch 01320/03692] [00:11:51/00:21:19, 0.539s/it]: train_loss_raw=0.6245, running_loss=0.4991, LR=0.000100
[2025-08-10 23:07:56,432][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078864] [Batch 01332/03692] [00:11:58/00:21:12, 0.539s/it]: train_loss_raw=0.4678, running_loss=0.5009, LR=0.000100
[2025-08-10 23:08:02,954][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078876] [Batch 01344/03692] [00:12:04/00:21:06, 0.539s/it]: train_loss_raw=0.4058, running_loss=0.4955, LR=0.000100
[2025-08-10 23:08:09,146][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078888] [Batch 01356/03692] [00:12:11/00:20:59, 0.539s/it]: train_loss_raw=0.4782, running_loss=0.4971, LR=0.000100
[2025-08-10 23:08:15,564][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078900] [Batch 01368/03692] [00:12:17/00:20:52, 0.539s/it]: train_loss_raw=0.4797, running_loss=0.4967, LR=0.000100
[2025-08-10 23:08:21,999][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078912] [Batch 01380/03692] [00:12:23/00:20:46, 0.539s/it]: train_loss_raw=0.5225, running_loss=0.4981, LR=0.000100
[2025-08-10 23:08:28,480][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078924] [Batch 01392/03692] [00:12:30/00:20:39, 0.539s/it]: train_loss_raw=0.5801, running_loss=0.5046, LR=0.000100
[2025-08-10 23:08:35,071][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078936] [Batch 01404/03692] [00:12:36/00:20:33, 0.539s/it]: train_loss_raw=0.4074, running_loss=0.5034, LR=0.000100
[2025-08-10 23:08:41,570][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078948] [Batch 01416/03692] [00:12:43/00:20:27, 0.539s/it]: train_loss_raw=0.4776, running_loss=0.5035, LR=0.000100
[2025-08-10 23:08:48,065][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078960] [Batch 01428/03692] [00:12:49/00:20:20, 0.539s/it]: train_loss_raw=0.5566, running_loss=0.5060, LR=0.000100
[2025-08-10 23:08:54,515][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078972] [Batch 01440/03692] [00:12:56/00:20:14, 0.539s/it]: train_loss_raw=0.5156, running_loss=0.5079, LR=0.000100
[2025-08-10 23:09:00,862][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078984] [Batch 01452/03692] [00:13:02/00:20:07, 0.539s/it]: train_loss_raw=0.5829, running_loss=0.5096, LR=0.000100
[2025-08-10 23:09:07,242][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 078996] [Batch 01464/03692] [00:13:09/00:20:00, 0.539s/it]: train_loss_raw=0.4925, running_loss=0.5081, LR=0.000100
[2025-08-10 23:09:13,583][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079008] [Batch 01476/03692] [00:13:15/00:19:54, 0.539s/it]: train_loss_raw=0.5401, running_loss=0.5100, LR=0.000100
[2025-08-10 23:09:19,966][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079020] [Batch 01488/03692] [00:13:21/00:19:47, 0.539s/it]: train_loss_raw=0.5263, running_loss=0.5125, LR=0.000100
[2025-08-10 23:09:26,329][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079032] [Batch 01500/03692] [00:13:28/00:19:41, 0.539s/it]: train_loss_raw=0.5575, running_loss=0.5125, LR=0.000100
[2025-08-10 23:09:32,885][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079044] [Batch 01512/03692] [00:13:34/00:19:34, 0.539s/it]: train_loss_raw=0.5788, running_loss=0.5134, LR=0.000100
[2025-08-10 23:09:39,258][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079056] [Batch 01524/03692] [00:13:41/00:19:28, 0.539s/it]: train_loss_raw=0.4450, running_loss=0.5088, LR=0.000100
[2025-08-10 23:09:45,711][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079068] [Batch 01536/03692] [00:13:47/00:19:21, 0.539s/it]: train_loss_raw=0.6631, running_loss=0.5123, LR=0.000100
[2025-08-10 23:09:52,039][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079080] [Batch 01548/03692] [00:13:53/00:19:15, 0.539s/it]: train_loss_raw=0.4651, running_loss=0.5161, LR=0.000100
[2025-08-10 23:09:58,376][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079092] [Batch 01560/03692] [00:14:00/00:19:08, 0.539s/it]: train_loss_raw=0.5524, running_loss=0.5165, LR=0.000100
[2025-08-10 23:10:04,762][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079104] [Batch 01572/03692] [00:14:06/00:19:01, 0.539s/it]: train_loss_raw=0.5949, running_loss=0.5182, LR=0.000100
[2025-08-10 23:10:11,069][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079116] [Batch 01584/03692] [00:14:12/00:18:55, 0.539s/it]: train_loss_raw=0.4694, running_loss=0.5181, LR=0.000100
[2025-08-10 23:10:17,431][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079128] [Batch 01596/03692] [00:14:19/00:18:48, 0.538s/it]: train_loss_raw=0.5636, running_loss=0.5164, LR=0.000100
[2025-08-10 23:10:23,694][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079140] [Batch 01608/03692] [00:14:25/00:18:41, 0.538s/it]: train_loss_raw=0.4649, running_loss=0.5157, LR=0.000100
[2025-08-10 23:10:30,163][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079152] [Batch 01620/03692] [00:14:32/00:18:35, 0.538s/it]: train_loss_raw=0.5636, running_loss=0.5144, LR=0.000100
[2025-08-10 23:10:36,480][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079164] [Batch 01632/03692] [00:14:38/00:18:28, 0.538s/it]: train_loss_raw=0.4439, running_loss=0.5117, LR=0.000100
[2025-08-10 23:10:42,997][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079176] [Batch 01644/03692] [00:14:44/00:18:22, 0.538s/it]: train_loss_raw=0.5232, running_loss=0.5108, LR=0.000100
[2025-08-10 23:10:49,468][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079188] [Batch 01656/03692] [00:14:51/00:18:15, 0.538s/it]: train_loss_raw=0.5170, running_loss=0.5106, LR=0.000100
[2025-08-10 23:10:55,941][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079200] [Batch 01668/03692] [00:14:57/00:18:09, 0.538s/it]: train_loss_raw=0.3766, running_loss=0.5089, LR=0.000100
[2025-08-10 23:11:02,385][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079212] [Batch 01680/03692] [00:15:04/00:18:03, 0.538s/it]: train_loss_raw=0.4399, running_loss=0.5071, LR=0.000100
[2025-08-10 23:11:08,823][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079224] [Batch 01692/03692] [00:15:10/00:17:56, 0.538s/it]: train_loss_raw=0.4663, running_loss=0.5082, LR=0.000100
[2025-08-10 23:11:15,244][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079236] [Batch 01704/03692] [00:15:17/00:17:50, 0.538s/it]: train_loss_raw=0.5719, running_loss=0.5076, LR=0.000100
[2025-08-10 23:11:21,689][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079248] [Batch 01716/03692] [00:15:23/00:17:43, 0.538s/it]: train_loss_raw=0.4688, running_loss=0.5077, LR=0.000100
[2025-08-10 23:11:28,102][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079260] [Batch 01728/03692] [00:15:30/00:17:37, 0.538s/it]: train_loss_raw=0.4658, running_loss=0.5067, LR=0.000100
[2025-08-10 23:11:34,488][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079272] [Batch 01740/03692] [00:15:36/00:17:30, 0.538s/it]: train_loss_raw=0.4930, running_loss=0.5036, LR=0.000100
[2025-08-10 23:11:40,987][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079284] [Batch 01752/03692] [00:15:42/00:17:24, 0.538s/it]: train_loss_raw=0.5333, running_loss=0.5020, LR=0.000100
[2025-08-10 23:11:47,536][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079296] [Batch 01764/03692] [00:15:49/00:17:17, 0.538s/it]: train_loss_raw=0.4212, running_loss=0.5049, LR=0.000100
[2025-08-10 23:11:54,088][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079308] [Batch 01776/03692] [00:15:56/00:17:11, 0.538s/it]: train_loss_raw=0.4763, running_loss=0.4992, LR=0.000100
[2025-08-10 23:12:00,555][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079320] [Batch 01788/03692] [00:16:02/00:17:04, 0.538s/it]: train_loss_raw=0.6357, running_loss=0.4999, LR=0.000100
[2025-08-10 23:12:06,911][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079332] [Batch 01800/03692] [00:16:08/00:16:58, 0.538s/it]: train_loss_raw=0.4904, running_loss=0.4966, LR=0.000100
[2025-08-10 23:12:13,578][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079344] [Batch 01812/03692] [00:16:15/00:16:52, 0.538s/it]: train_loss_raw=0.5726, running_loss=0.5010, LR=0.000100
[2025-08-10 23:12:20,119][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079356] [Batch 01824/03692] [00:16:22/00:16:45, 0.538s/it]: train_loss_raw=0.5456, running_loss=0.5028, LR=0.000100
[2025-08-10 23:12:26,626][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079368] [Batch 01836/03692] [00:16:28/00:16:39, 0.538s/it]: train_loss_raw=0.4688, running_loss=0.5018, LR=0.000100
[2025-08-10 23:12:33,181][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079380] [Batch 01848/03692] [00:16:35/00:16:32, 0.538s/it]: train_loss_raw=0.4193, running_loss=0.5013, LR=0.000100
[2025-08-10 23:12:39,718][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079392] [Batch 01860/03692] [00:16:41/00:16:26, 0.539s/it]: train_loss_raw=0.5542, running_loss=0.5049, LR=0.000100
[2025-08-10 23:12:46,080][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079404] [Batch 01872/03692] [00:16:48/00:16:20, 0.538s/it]: train_loss_raw=0.5645, running_loss=0.5056, LR=0.000100
[2025-08-10 23:12:52,505][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079416] [Batch 01884/03692] [00:16:54/00:16:13, 0.538s/it]: train_loss_raw=0.5229, running_loss=0.5037, LR=0.000100
[2025-08-10 23:12:59,047][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079428] [Batch 01896/03692] [00:17:00/00:16:07, 0.538s/it]: train_loss_raw=0.5801, running_loss=0.5052, LR=0.000100
[2025-08-10 23:13:05,440][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079440] [Batch 01908/03692] [00:17:07/00:16:00, 0.538s/it]: train_loss_raw=0.5523, running_loss=0.5071, LR=0.000100
[2025-08-10 23:13:11,895][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079452] [Batch 01920/03692] [00:17:13/00:15:54, 0.538s/it]: train_loss_raw=0.5491, running_loss=0.5127, LR=0.000100
[2025-08-10 23:13:18,362][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079464] [Batch 01932/03692] [00:17:20/00:15:47, 0.538s/it]: train_loss_raw=0.5111, running_loss=0.5124, LR=0.000100
[2025-08-10 23:13:24,759][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079476] [Batch 01944/03692] [00:17:26/00:15:41, 0.538s/it]: train_loss_raw=0.5476, running_loss=0.5098, LR=0.000100
[2025-08-10 23:13:31,138][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079488] [Batch 01956/03692] [00:17:33/00:15:34, 0.538s/it]: train_loss_raw=0.4094, running_loss=0.5094, LR=0.000100
[2025-08-10 23:13:37,581][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079500] [Batch 01968/03692] [00:17:39/00:15:28, 0.538s/it]: train_loss_raw=0.5281, running_loss=0.5131, LR=0.000100
[2025-08-10 23:13:43,943][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079512] [Batch 01980/03692] [00:17:45/00:15:21, 0.538s/it]: train_loss_raw=0.5348, running_loss=0.5158, LR=0.000100
[2025-08-10 23:13:50,365][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079524] [Batch 01992/03692] [00:17:52/00:15:15, 0.538s/it]: train_loss_raw=0.5095, running_loss=0.5119, LR=0.000100
[2025-08-10 23:13:56,751][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079536] [Batch 02004/03692] [00:17:58/00:15:08, 0.538s/it]: train_loss_raw=0.4646, running_loss=0.5118, LR=0.000100
[2025-08-10 23:14:03,158][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079548] [Batch 02016/03692] [00:18:05/00:15:02, 0.538s/it]: train_loss_raw=0.5444, running_loss=0.5148, LR=0.000100
[2025-08-10 23:14:09,701][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079560] [Batch 02028/03692] [00:18:11/00:14:55, 0.538s/it]: train_loss_raw=0.5143, running_loss=0.5145, LR=0.000100
[2025-08-10 23:14:16,268][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079572] [Batch 02040/03692] [00:18:18/00:14:49, 0.538s/it]: train_loss_raw=0.5515, running_loss=0.5125, LR=0.000100
[2025-08-10 23:14:22,746][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079584] [Batch 02052/03692] [00:18:24/00:14:42, 0.538s/it]: train_loss_raw=0.5575, running_loss=0.5120, LR=0.000100
[2025-08-10 23:14:29,199][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079596] [Batch 02064/03692] [00:18:31/00:14:36, 0.538s/it]: train_loss_raw=0.4482, running_loss=0.5115, LR=0.000100
[2025-08-10 23:14:35,269][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079608] [Batch 02076/03692] [00:18:37/00:14:29, 0.538s/it]: train_loss_raw=0.4554, running_loss=0.5077, LR=0.000100
[2025-08-10 23:14:41,203][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079620] [Batch 02088/03692] [00:18:43/00:14:22, 0.538s/it]: train_loss_raw=0.5857, running_loss=0.5070, LR=0.000100
[2025-08-10 23:14:47,579][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079632] [Batch 02100/03692] [00:18:49/00:14:16, 0.538s/it]: train_loss_raw=0.6278, running_loss=0.5090, LR=0.000100
[2025-08-10 23:14:54,114][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079644] [Batch 02112/03692] [00:18:56/00:14:09, 0.538s/it]: train_loss_raw=0.4685, running_loss=0.5071, LR=0.000100
[2025-08-10 23:15:00,658][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079656] [Batch 02124/03692] [00:19:02/00:14:03, 0.538s/it]: train_loss_raw=0.4706, running_loss=0.5076, LR=0.000100
[2025-08-10 23:15:07,217][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079668] [Batch 02136/03692] [00:19:09/00:13:57, 0.538s/it]: train_loss_raw=0.4551, running_loss=0.5085, LR=0.000100
[2025-08-10 23:15:13,736][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079680] [Batch 02148/03692] [00:19:15/00:13:50, 0.538s/it]: train_loss_raw=0.4740, running_loss=0.5100, LR=0.000100
[2025-08-10 23:15:26,860][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079692] [Batch 02160/03692] [00:19:28/00:13:48, 0.541s/it]: train_loss_raw=0.4425, running_loss=0.5067, LR=0.000100
[2025-08-10 23:15:33,153][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079704] [Batch 02172/03692] [00:19:35/00:13:42, 0.541s/it]: train_loss_raw=0.4781, running_loss=0.5078, LR=0.000100
[2025-08-10 23:15:39,717][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079716] [Batch 02184/03692] [00:19:41/00:13:35, 0.541s/it]: train_loss_raw=0.4541, running_loss=0.5072, LR=0.000100
[2025-08-10 23:15:46,208][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079728] [Batch 02196/03692] [00:19:48/00:13:29, 0.541s/it]: train_loss_raw=0.5292, running_loss=0.5059, LR=0.000100
[2025-08-10 23:15:52,725][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079740] [Batch 02208/03692] [00:19:54/00:13:22, 0.541s/it]: train_loss_raw=0.6028, running_loss=0.5069, LR=0.000100
[2025-08-10 23:15:59,059][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079752] [Batch 02220/03692] [00:20:00/00:13:16, 0.541s/it]: train_loss_raw=0.5958, running_loss=0.5079, LR=0.000100
[2025-08-10 23:16:05,672][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079764] [Batch 02232/03692] [00:20:07/00:13:09, 0.541s/it]: train_loss_raw=0.4962, running_loss=0.5119, LR=0.000100
[2025-08-10 23:16:11,788][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079776] [Batch 02244/03692] [00:20:13/00:13:03, 0.541s/it]: train_loss_raw=0.4402, running_loss=0.5097, LR=0.000100
[2025-08-10 23:16:17,939][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079788] [Batch 02256/03692] [00:20:19/00:12:56, 0.541s/it]: train_loss_raw=0.5725, running_loss=0.5110, LR=0.000100
[2025-08-10 23:16:24,408][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079800] [Batch 02268/03692] [00:20:26/00:12:49, 0.541s/it]: train_loss_raw=0.5447, running_loss=0.5110, LR=0.000100
[2025-08-10 23:16:30,878][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079812] [Batch 02280/03692] [00:20:32/00:12:43, 0.541s/it]: train_loss_raw=0.5184, running_loss=0.5108, LR=0.000100
[2025-08-10 23:16:37,358][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079824] [Batch 02292/03692] [00:20:39/00:12:36, 0.541s/it]: train_loss_raw=0.5855, running_loss=0.5115, LR=0.000100
[2025-08-10 23:16:43,890][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079836] [Batch 02304/03692] [00:20:45/00:12:30, 0.541s/it]: train_loss_raw=0.6440, running_loss=0.5132, LR=0.000100
[2025-08-10 23:16:50,303][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079848] [Batch 02316/03692] [00:20:52/00:12:23, 0.541s/it]: train_loss_raw=0.4296, running_loss=0.5093, LR=0.000100
[2025-08-10 23:16:56,478][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079860] [Batch 02328/03692] [00:20:58/00:12:17, 0.541s/it]: train_loss_raw=0.4811, running_loss=0.5075, LR=0.000100
[2025-08-10 23:17:02,955][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079872] [Batch 02340/03692] [00:21:04/00:12:10, 0.541s/it]: train_loss_raw=0.5604, running_loss=0.5072, LR=0.000100
[2025-08-10 23:17:09,406][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079884] [Batch 02352/03692] [00:21:11/00:12:04, 0.541s/it]: train_loss_raw=0.4479, running_loss=0.5072, LR=0.000100
[2025-08-10 23:17:15,822][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079896] [Batch 02364/03692] [00:21:17/00:11:57, 0.541s/it]: train_loss_raw=0.4684, running_loss=0.5056, LR=0.000100
[2025-08-10 23:17:22,373][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079908] [Batch 02376/03692] [00:21:24/00:11:51, 0.541s/it]: train_loss_raw=0.5212, running_loss=0.5040, LR=0.000100
[2025-08-10 23:17:28,898][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079920] [Batch 02388/03692] [00:21:30/00:11:44, 0.541s/it]: train_loss_raw=0.5229, running_loss=0.5064, LR=0.000100
[2025-08-10 23:17:35,389][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079932] [Batch 02400/03692] [00:21:37/00:11:38, 0.541s/it]: train_loss_raw=0.5193, running_loss=0.5079, LR=0.000100
[2025-08-10 23:17:41,818][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079944] [Batch 02412/03692] [00:21:43/00:11:31, 0.541s/it]: train_loss_raw=0.5099, running_loss=0.5069, LR=0.000100
[2025-08-10 23:17:48,273][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079956] [Batch 02424/03692] [00:21:50/00:11:25, 0.541s/it]: train_loss_raw=0.5836, running_loss=0.5054, LR=0.000100
[2025-08-10 23:17:54,786][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079968] [Batch 02436/03692] [00:21:56/00:11:18, 0.541s/it]: train_loss_raw=0.6124, running_loss=0.5073, LR=0.000100
[2025-08-10 23:18:01,344][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079980] [Batch 02448/03692] [00:22:03/00:11:12, 0.541s/it]: train_loss_raw=0.5294, running_loss=0.5059, LR=0.000100
[2025-08-10 23:18:07,838][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 079992] [Batch 02460/03692] [00:22:09/00:11:05, 0.541s/it]: train_loss_raw=0.5203, running_loss=0.5062, LR=0.000100
[2025-08-10 23:18:18,758][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080004] [Batch 02472/03692] [00:22:20/00:11:01, 0.542s/it]: train_loss_raw=0.4281, running_loss=0.5042, LR=0.000100
[2025-08-10 23:18:25,177][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080016] [Batch 02484/03692] [00:22:27/00:10:55, 0.542s/it]: train_loss_raw=0.5091, running_loss=0.5033, LR=0.000100
[2025-08-10 23:18:31,584][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080028] [Batch 02496/03692] [00:22:33/00:10:48, 0.542s/it]: train_loss_raw=0.5732, running_loss=0.5020, LR=0.000100
[2025-08-10 23:18:38,041][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080040] [Batch 02508/03692] [00:22:39/00:10:42, 0.542s/it]: train_loss_raw=0.4120, running_loss=0.5038, LR=0.000100
[2025-08-10 23:18:44,533][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080052] [Batch 02520/03692] [00:22:46/00:10:35, 0.542s/it]: train_loss_raw=0.4708, running_loss=0.5039, LR=0.000100
[2025-08-10 23:18:50,970][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080064] [Batch 02532/03692] [00:22:52/00:10:28, 0.542s/it]: train_loss_raw=0.5135, running_loss=0.5036, LR=0.000100
[2025-08-10 23:18:57,496][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080076] [Batch 02544/03692] [00:22:59/00:10:22, 0.542s/it]: train_loss_raw=0.5956, running_loss=0.5019, LR=0.000100
[2025-08-10 23:19:04,151][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080088] [Batch 02556/03692] [00:23:06/00:10:16, 0.542s/it]: train_loss_raw=0.5527, running_loss=0.5040, LR=0.000100
[2025-08-10 23:19:10,443][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080100] [Batch 02568/03692] [00:23:12/00:10:09, 0.542s/it]: train_loss_raw=0.5334, running_loss=0.5032, LR=0.000100
[2025-08-10 23:19:16,863][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080112] [Batch 02580/03692] [00:23:18/00:10:02, 0.542s/it]: train_loss_raw=0.4804, running_loss=0.4991, LR=0.000100
[2025-08-10 23:19:23,059][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080124] [Batch 02592/03692] [00:23:24/00:09:56, 0.542s/it]: train_loss_raw=0.5319, running_loss=0.5016, LR=0.000100
[2025-08-10 23:19:29,487][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080136] [Batch 02604/03692] [00:23:31/00:09:49, 0.542s/it]: train_loss_raw=0.5129, running_loss=0.5012, LR=0.000100
[2025-08-10 23:19:36,000][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080148] [Batch 02616/03692] [00:23:37/00:09:43, 0.542s/it]: train_loss_raw=0.4643, running_loss=0.5037, LR=0.000100
[2025-08-10 23:19:42,439][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080160] [Batch 02628/03692] [00:23:44/00:09:36, 0.542s/it]: train_loss_raw=0.6123, running_loss=0.5067, LR=0.000100
[2025-08-10 23:19:48,880][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080172] [Batch 02640/03692] [00:23:50/00:09:30, 0.542s/it]: train_loss_raw=0.5801, running_loss=0.5057, LR=0.000100
[2025-08-10 23:19:55,366][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080184] [Batch 02652/03692] [00:23:57/00:09:23, 0.542s/it]: train_loss_raw=0.5353, running_loss=0.5077, LR=0.000100
[2025-08-10 23:20:01,893][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080196] [Batch 02664/03692] [00:24:03/00:09:17, 0.542s/it]: train_loss_raw=0.4476, running_loss=0.5092, LR=0.000100
[2025-08-10 23:20:08,423][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080208] [Batch 02676/03692] [00:24:10/00:09:10, 0.542s/it]: train_loss_raw=0.5551, running_loss=0.5060, LR=0.000100
[2025-08-10 23:20:14,956][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080220] [Batch 02688/03692] [00:24:16/00:09:04, 0.542s/it]: train_loss_raw=0.5276, running_loss=0.5063, LR=0.000100
[2025-08-10 23:20:21,426][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080232] [Batch 02700/03692] [00:24:23/00:08:57, 0.542s/it]: train_loss_raw=0.5689, running_loss=0.5044, LR=0.000100
[2025-08-10 23:20:27,923][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080244] [Batch 02712/03692] [00:24:29/00:08:51, 0.542s/it]: train_loss_raw=0.5051, running_loss=0.5014, LR=0.000100
[2025-08-10 23:20:34,416][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080256] [Batch 02724/03692] [00:24:36/00:08:44, 0.542s/it]: train_loss_raw=0.5228, running_loss=0.5022, LR=0.000100
[2025-08-10 23:20:40,826][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080268] [Batch 02736/03692] [00:24:42/00:08:38, 0.542s/it]: train_loss_raw=0.4328, running_loss=0.5002, LR=0.000100
[2025-08-10 23:20:47,246][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080280] [Batch 02748/03692] [00:24:49/00:08:31, 0.542s/it]: train_loss_raw=0.4865, running_loss=0.4972, LR=0.000100
[2025-08-10 23:20:53,749][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080292] [Batch 02760/03692] [00:24:55/00:08:25, 0.542s/it]: train_loss_raw=0.5315, running_loss=0.4989, LR=0.000100
[2025-08-10 23:21:00,116][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080304] [Batch 02772/03692] [00:25:02/00:08:18, 0.542s/it]: train_loss_raw=0.4076, running_loss=0.5013, LR=0.000100
[2025-08-10 23:21:06,472][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080316] [Batch 02784/03692] [00:25:08/00:08:11, 0.542s/it]: train_loss_raw=0.5975, running_loss=0.5018, LR=0.000100
[2025-08-10 23:21:12,918][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080328] [Batch 02796/03692] [00:25:14/00:08:05, 0.542s/it]: train_loss_raw=0.4225, running_loss=0.5024, LR=0.000100
[2025-08-10 23:21:19,273][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080340] [Batch 02808/03692] [00:25:21/00:07:58, 0.542s/it]: train_loss_raw=0.4523, running_loss=0.5026, LR=0.000100
[2025-08-10 23:21:25,725][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080352] [Batch 02820/03692] [00:25:27/00:07:52, 0.542s/it]: train_loss_raw=0.4681, running_loss=0.5023, LR=0.000100
[2025-08-10 23:21:32,091][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080364] [Batch 02832/03692] [00:25:34/00:07:45, 0.542s/it]: train_loss_raw=0.5184, running_loss=0.5013, LR=0.000100
[2025-08-10 23:21:38,647][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080376] [Batch 02844/03692] [00:25:40/00:07:39, 0.542s/it]: train_loss_raw=0.4789, running_loss=0.5026, LR=0.000100
[2025-08-10 23:21:45,159][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080388] [Batch 02856/03692] [00:25:47/00:07:32, 0.542s/it]: train_loss_raw=0.4950, running_loss=0.5042, LR=0.000100
[2025-08-10 23:21:51,597][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080400] [Batch 02868/03692] [00:25:53/00:07:26, 0.542s/it]: train_loss_raw=0.5188, running_loss=0.5041, LR=0.000100
[2025-08-10 23:21:58,034][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080412] [Batch 02880/03692] [00:25:59/00:07:19, 0.542s/it]: train_loss_raw=0.5512, running_loss=0.5051, LR=0.000100
[2025-08-10 23:22:04,434][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080424] [Batch 02892/03692] [00:26:06/00:07:13, 0.542s/it]: train_loss_raw=0.5605, running_loss=0.5044, LR=0.000100
[2025-08-10 23:22:10,845][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080436] [Batch 02904/03692] [00:26:12/00:07:06, 0.542s/it]: train_loss_raw=0.3762, running_loss=0.5019, LR=0.000100
[2025-08-10 23:22:17,222][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080448] [Batch 02916/03692] [00:26:19/00:07:00, 0.542s/it]: train_loss_raw=0.5307, running_loss=0.4991, LR=0.000100
[2025-08-10 23:22:23,655][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080460] [Batch 02928/03692] [00:26:25/00:06:53, 0.542s/it]: train_loss_raw=0.4444, running_loss=0.4953, LR=0.000100
[2025-08-10 23:22:30,031][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080472] [Batch 02940/03692] [00:26:31/00:06:47, 0.541s/it]: train_loss_raw=0.5680, running_loss=0.4998, LR=0.000100
[2025-08-10 23:22:36,420][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080484] [Batch 02952/03692] [00:26:38/00:06:40, 0.541s/it]: train_loss_raw=0.4695, running_loss=0.4963, LR=0.000100
[2025-08-10 23:22:42,838][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080496] [Batch 02964/03692] [00:26:44/00:06:34, 0.541s/it]: train_loss_raw=0.5474, running_loss=0.4961, LR=0.000100
[2025-08-10 23:22:49,243][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080508] [Batch 02976/03692] [00:26:51/00:06:27, 0.541s/it]: train_loss_raw=0.6199, running_loss=0.4980, LR=0.000100
[2025-08-10 23:22:55,605][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080520] [Batch 02988/03692] [00:26:57/00:06:21, 0.541s/it]: train_loss_raw=0.4424, running_loss=0.4992, LR=0.000100
[2025-08-10 23:23:01,992][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080532] [Batch 03000/03692] [00:27:03/00:06:14, 0.541s/it]: train_loss_raw=0.6129, running_loss=0.5021, LR=0.000100
[2025-08-10 23:23:08,390][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080544] [Batch 03012/03692] [00:27:10/00:06:08, 0.541s/it]: train_loss_raw=0.4861, running_loss=0.4985, LR=0.000100
[2025-08-10 23:23:14,758][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080556] [Batch 03024/03692] [00:27:16/00:06:01, 0.541s/it]: train_loss_raw=0.4552, running_loss=0.4976, LR=0.000100
[2025-08-10 23:23:21,189][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080568] [Batch 03036/03692] [00:27:23/00:05:55, 0.541s/it]: train_loss_raw=0.5688, running_loss=0.4986, LR=0.000100
[2025-08-10 23:23:27,621][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080580] [Batch 03048/03692] [00:27:29/00:05:48, 0.541s/it]: train_loss_raw=0.5351, running_loss=0.5013, LR=0.000100
[2025-08-10 23:23:33,974][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080592] [Batch 03060/03692] [00:27:35/00:05:42, 0.541s/it]: train_loss_raw=0.4411, running_loss=0.4998, LR=0.000100
[2025-08-10 23:23:40,389][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080604] [Batch 03072/03692] [00:27:42/00:05:35, 0.541s/it]: train_loss_raw=0.4179, running_loss=0.4990, LR=0.000100
[2025-08-10 23:23:46,784][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080616] [Batch 03084/03692] [00:27:48/00:05:28, 0.541s/it]: train_loss_raw=0.5811, running_loss=0.4995, LR=0.000100
[2025-08-10 23:23:53,112][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080628] [Batch 03096/03692] [00:27:55/00:05:22, 0.541s/it]: train_loss_raw=0.4166, running_loss=0.4991, LR=0.000100
[2025-08-10 23:23:59,509][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080640] [Batch 03108/03692] [00:28:01/00:05:15, 0.541s/it]: train_loss_raw=0.4988, running_loss=0.4972, LR=0.000100
[2025-08-10 23:24:05,975][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080652] [Batch 03120/03692] [00:28:07/00:05:09, 0.541s/it]: train_loss_raw=0.5034, running_loss=0.4948, LR=0.000100
[2025-08-10 23:24:12,375][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080664] [Batch 03132/03692] [00:28:14/00:05:02, 0.541s/it]: train_loss_raw=0.5647, running_loss=0.4976, LR=0.000100
[2025-08-10 23:24:18,784][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080676] [Batch 03144/03692] [00:28:20/00:04:56, 0.541s/it]: train_loss_raw=0.5701, running_loss=0.4968, LR=0.000100
[2025-08-10 23:24:25,133][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080688] [Batch 03156/03692] [00:28:27/00:04:49, 0.541s/it]: train_loss_raw=0.5094, running_loss=0.4985, LR=0.000100
[2025-08-10 23:24:31,465][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080700] [Batch 03168/03692] [00:28:33/00:04:43, 0.541s/it]: train_loss_raw=0.5936, running_loss=0.5026, LR=0.000100
[2025-08-10 23:24:37,792][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080712] [Batch 03180/03692] [00:28:39/00:04:36, 0.541s/it]: train_loss_raw=0.5199, running_loss=0.5014, LR=0.000100
[2025-08-10 23:24:44,188][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080724] [Batch 03192/03692] [00:28:46/00:04:30, 0.541s/it]: train_loss_raw=0.4929, running_loss=0.5003, LR=0.000100
[2025-08-10 23:24:50,561][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080736] [Batch 03204/03692] [00:28:52/00:04:23, 0.541s/it]: train_loss_raw=0.4427, running_loss=0.5018, LR=0.000100
[2025-08-10 23:24:56,949][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080748] [Batch 03216/03692] [00:28:58/00:04:17, 0.541s/it]: train_loss_raw=0.5085, running_loss=0.5017, LR=0.000100
[2025-08-10 23:25:03,276][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080760] [Batch 03228/03692] [00:29:05/00:04:10, 0.541s/it]: train_loss_raw=0.4598, running_loss=0.5014, LR=0.000100
[2025-08-10 23:25:09,670][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080772] [Batch 03240/03692] [00:29:11/00:04:04, 0.541s/it]: train_loss_raw=0.4318, running_loss=0.4996, LR=0.000100
[2025-08-10 23:25:16,159][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080784] [Batch 03252/03692] [00:29:18/00:03:57, 0.541s/it]: train_loss_raw=0.4835, running_loss=0.4993, LR=0.000100
[2025-08-10 23:25:22,558][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080796] [Batch 03264/03692] [00:29:24/00:03:51, 0.541s/it]: train_loss_raw=0.4636, running_loss=0.4964, LR=0.000100
[2025-08-10 23:25:28,926][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080808] [Batch 03276/03692] [00:29:30/00:03:44, 0.541s/it]: train_loss_raw=0.4243, running_loss=0.4985, LR=0.000100
[2025-08-10 23:25:35,274][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080820] [Batch 03288/03692] [00:29:37/00:03:38, 0.541s/it]: train_loss_raw=0.4971, running_loss=0.5002, LR=0.000100
[2025-08-10 23:25:41,703][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080832] [Batch 03300/03692] [00:29:43/00:03:31, 0.540s/it]: train_loss_raw=0.4346, running_loss=0.4999, LR=0.000100
[2025-08-10 23:25:48,070][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080844] [Batch 03312/03692] [00:29:49/00:03:25, 0.540s/it]: train_loss_raw=0.4050, running_loss=0.4986, LR=0.000100
[2025-08-10 23:25:54,483][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080856] [Batch 03324/03692] [00:29:56/00:03:18, 0.540s/it]: train_loss_raw=0.5084, running_loss=0.5012, LR=0.000100
[2025-08-10 23:26:01,010][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080868] [Batch 03336/03692] [00:30:02/00:03:12, 0.540s/it]: train_loss_raw=0.5156, running_loss=0.5024, LR=0.000100
[2025-08-10 23:26:07,650][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080880] [Batch 03348/03692] [00:30:09/00:03:05, 0.540s/it]: train_loss_raw=0.5597, running_loss=0.4997, LR=0.000100
[2025-08-10 23:26:14,121][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080892] [Batch 03360/03692] [00:30:16/00:02:59, 0.540s/it]: train_loss_raw=0.4848, running_loss=0.4976, LR=0.000100
[2025-08-10 23:26:20,587][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080904] [Batch 03372/03692] [00:30:22/00:02:52, 0.540s/it]: train_loss_raw=0.6578, running_loss=0.4996, LR=0.000100
[2025-08-10 23:26:26,981][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080916] [Batch 03384/03692] [00:30:28/00:02:46, 0.540s/it]: train_loss_raw=0.4063, running_loss=0.4989, LR=0.000100
[2025-08-10 23:26:33,611][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080928] [Batch 03396/03692] [00:30:35/00:02:39, 0.540s/it]: train_loss_raw=0.4884, running_loss=0.4999, LR=0.000100
[2025-08-10 23:26:40,025][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080940] [Batch 03408/03692] [00:30:41/00:02:33, 0.540s/it]: train_loss_raw=0.5357, running_loss=0.5008, LR=0.000100
[2025-08-10 23:26:46,541][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080952] [Batch 03420/03692] [00:30:48/00:02:27, 0.540s/it]: train_loss_raw=0.5419, running_loss=0.5023, LR=0.000100
[2025-08-10 23:26:52,986][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080964] [Batch 03432/03692] [00:30:54/00:02:20, 0.540s/it]: train_loss_raw=0.5297, running_loss=0.5022, LR=0.000100
[2025-08-10 23:26:59,494][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080976] [Batch 03444/03692] [00:31:01/00:02:14, 0.540s/it]: train_loss_raw=0.4490, running_loss=0.5009, LR=0.000100
[2025-08-10 23:27:05,955][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 080988] [Batch 03456/03692] [00:31:07/00:02:07, 0.540s/it]: train_loss_raw=0.4447, running_loss=0.4977, LR=0.000100
[2025-08-10 23:27:12,362][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081000] [Batch 03468/03692] [00:31:14/00:02:01, 0.540s/it]: train_loss_raw=0.5062, running_loss=0.4995, LR=0.000100
[2025-08-10 23:27:18,719][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081012] [Batch 03480/03692] [00:31:20/00:01:54, 0.540s/it]: train_loss_raw=0.4841, running_loss=0.4999, LR=0.000100
[2025-08-10 23:27:25,135][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081024] [Batch 03492/03692] [00:31:27/00:01:48, 0.540s/it]: train_loss_raw=0.5992, running_loss=0.5011, LR=0.000100
[2025-08-10 23:27:31,537][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081036] [Batch 03504/03692] [00:31:33/00:01:41, 0.540s/it]: train_loss_raw=0.5438, running_loss=0.5022, LR=0.000100
[2025-08-10 23:27:37,918][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081048] [Batch 03516/03692] [00:31:39/00:01:35, 0.540s/it]: train_loss_raw=0.4944, running_loss=0.4997, LR=0.000100
[2025-08-10 23:27:44,374][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081060] [Batch 03528/03692] [00:31:46/00:01:28, 0.540s/it]: train_loss_raw=0.4752, running_loss=0.4993, LR=0.000100
[2025-08-10 23:27:50,850][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081072] [Batch 03540/03692] [00:31:52/00:01:22, 0.540s/it]: train_loss_raw=0.4351, running_loss=0.4955, LR=0.000100
[2025-08-10 23:27:57,298][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081084] [Batch 03552/03692] [00:31:59/00:01:15, 0.540s/it]: train_loss_raw=0.4859, running_loss=0.4955, LR=0.000100
[2025-08-10 23:28:03,612][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081096] [Batch 03564/03692] [00:32:05/00:01:09, 0.540s/it]: train_loss_raw=0.5300, running_loss=0.4995, LR=0.000100
[2025-08-10 23:28:10,122][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081108] [Batch 03576/03692] [00:32:12/00:01:02, 0.540s/it]: train_loss_raw=0.4416, running_loss=0.5002, LR=0.000100
[2025-08-10 23:28:16,530][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081120] [Batch 03588/03692] [00:32:18/00:00:56, 0.540s/it]: train_loss_raw=0.4691, running_loss=0.5008, LR=0.000100
[2025-08-10 23:28:22,967][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081132] [Batch 03600/03692] [00:32:24/00:00:49, 0.540s/it]: train_loss_raw=0.6036, running_loss=0.4992, LR=0.000100
[2025-08-10 23:28:29,459][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081144] [Batch 03612/03692] [00:32:31/00:00:43, 0.540s/it]: train_loss_raw=0.4523, running_loss=0.4993, LR=0.000100
[2025-08-10 23:28:35,982][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081156] [Batch 03624/03692] [00:32:37/00:00:36, 0.540s/it]: train_loss_raw=0.5567, running_loss=0.4980, LR=0.000100
[2025-08-10 23:28:42,464][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081168] [Batch 03636/03692] [00:32:44/00:00:30, 0.540s/it]: train_loss_raw=0.4850, running_loss=0.4995, LR=0.000100
[2025-08-10 23:28:48,967][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081180] [Batch 03648/03692] [00:32:50/00:00:23, 0.540s/it]: train_loss_raw=0.5104, running_loss=0.4973, LR=0.000100
[2025-08-10 23:28:55,300][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081192] [Batch 03660/03692] [00:32:57/00:00:17, 0.540s/it]: train_loss_raw=0.4604, running_loss=0.4972, LR=0.000100
[2025-08-10 23:29:01,543][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081204] [Batch 03672/03692] [00:33:03/00:00:10, 0.540s/it]: train_loss_raw=0.6184, running_loss=0.4984, LR=0.000100
[2025-08-10 23:29:08,022][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 081216] [Batch 03684/03692] [00:33:09/00:00:04, 0.540s/it]: train_loss_raw=0.5552, running_loss=0.4991, LR=0.000100
[2025-08-10 23:29:25,096][__main__][INFO] - [VALIDATION] [Epoch 21/29] Starting validation.
[2025-08-10 23:29:57,324][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 081225] [Batch 00011/00025] [00:00:32/00:00:34, 2.686s/it]
[2025-08-10 23:30:11,022][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 081225] [Batch 00023/00025] [00:00:45/00:00:01, 1.914s/it]
[2025-08-10 23:30:11,991][__main__][INFO] - [VALIDATION] [Epoch 21/29] train_loss=0.50147, valid_loss=0.59256
[2025-08-10 23:30:11,991][__main__][INFO] - [VALIDATION] [Epoch 21/29] Metrics:
[2025-08-10 23:30:11,991][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_er      0.249
[2025-08-10 23:30:11,991][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_prec    0.534
[2025-08-10 23:30:11,991][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_recall  0.539
[2025-08-10 23:30:11,991][__main__][INFO] - [VALIDATION] [Epoch 21/29] - pep_recall 0.515
[2025-08-10 23:30:11,995][__main__][INFO] - [TRAIN] [Epoch 21/29] Epoch complete, total time 12:34:11, remaining time 04:34:14, 00:34:16 per epoch
[2025-08-10 23:30:14,070][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081228] [Batch 00004/03692] [00:00:01/00:27:15, 0.444s/it]: train_loss_raw=0.4169, running_loss=0.5098, LR=0.000100
[2025-08-10 23:30:20,718][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081240] [Batch 00016/03692] [00:00:08/00:32:14, 0.526s/it]: train_loss_raw=0.4724, running_loss=0.5071, LR=0.000100
[2025-08-10 23:30:27,314][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081252] [Batch 00028/03692] [00:00:15/00:32:45, 0.536s/it]: train_loss_raw=0.3631, running_loss=0.5035, LR=0.000100
[2025-08-10 23:30:33,860][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081264] [Batch 00040/03692] [00:00:21/00:32:48, 0.539s/it]: train_loss_raw=0.5407, running_loss=0.4997, LR=0.000100
[2025-08-10 23:30:40,428][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081276] [Batch 00052/03692] [00:00:28/00:32:49, 0.541s/it]: train_loss_raw=0.4892, running_loss=0.4963, LR=0.000100
[2025-08-10 23:30:46,989][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081288] [Batch 00064/03692] [00:00:34/00:32:46, 0.542s/it]: train_loss_raw=0.5060, running_loss=0.4965, LR=0.000100
[2025-08-10 23:30:53,473][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081300] [Batch 00076/03692] [00:00:41/00:32:39, 0.542s/it]: train_loss_raw=0.5649, running_loss=0.4981, LR=0.000100
[2025-08-10 23:30:59,836][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081312] [Batch 00088/03692] [00:00:47/00:32:27, 0.540s/it]: train_loss_raw=0.4484, running_loss=0.4938, LR=0.000100
[2025-08-10 23:31:06,312][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081324] [Batch 00100/03692] [00:00:54/00:32:20, 0.540s/it]: train_loss_raw=0.6098, running_loss=0.4932, LR=0.000100
[2025-08-10 23:31:12,634][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081336] [Batch 00112/03692] [00:01:00/00:32:08, 0.539s/it]: train_loss_raw=0.4365, running_loss=0.4911, LR=0.000100
[2025-08-10 23:31:19,100][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081348] [Batch 00124/03692] [00:01:06/00:32:02, 0.539s/it]: train_loss_raw=0.4522, running_loss=0.4906, LR=0.000100
[2025-08-10 23:31:25,376][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081360] [Batch 00136/03692] [00:01:13/00:31:50, 0.537s/it]: train_loss_raw=0.4980, running_loss=0.4903, LR=0.000100
[2025-08-10 23:31:31,519][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081372] [Batch 00148/03692] [00:01:19/00:31:37, 0.535s/it]: train_loss_raw=0.4901, running_loss=0.4920, LR=0.000100
[2025-08-10 23:31:37,744][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081384] [Batch 00160/03692] [00:01:25/00:31:26, 0.534s/it]: train_loss_raw=0.5129, running_loss=0.4910, LR=0.000100
[2025-08-10 23:31:44,293][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081396] [Batch 00172/03692] [00:01:31/00:31:22, 0.535s/it]: train_loss_raw=0.5876, running_loss=0.4905, LR=0.000100
[2025-08-10 23:31:50,662][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081408] [Batch 00184/03692] [00:01:38/00:31:15, 0.535s/it]: train_loss_raw=0.5614, running_loss=0.4887, LR=0.000100
[2025-08-10 23:31:56,664][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081420] [Batch 00196/03692] [00:01:44/00:31:01, 0.532s/it]: train_loss_raw=0.4753, running_loss=0.4853, LR=0.000100
[2025-08-10 23:32:02,746][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081432] [Batch 00208/03692] [00:01:50/00:30:50, 0.531s/it]: train_loss_raw=0.4643, running_loss=0.4859, LR=0.000100
[2025-08-10 23:32:08,951][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081444] [Batch 00220/03692] [00:01:56/00:30:41, 0.530s/it]: train_loss_raw=0.5394, running_loss=0.4865, LR=0.000100
[2025-08-10 23:32:15,165][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081456] [Batch 00232/03692] [00:02:02/00:30:32, 0.530s/it]: train_loss_raw=0.4151, running_loss=0.4835, LR=0.000100
[2025-08-10 23:32:21,387][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081468] [Batch 00244/03692] [00:02:09/00:30:24, 0.529s/it]: train_loss_raw=0.3908, running_loss=0.4808, LR=0.000100
[2025-08-10 23:32:27,767][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081480] [Batch 00256/03692] [00:02:15/00:30:18, 0.529s/it]: train_loss_raw=0.6535, running_loss=0.4799, LR=0.000100
[2025-08-10 23:32:34,273][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081492] [Batch 00268/03692] [00:02:21/00:30:13, 0.530s/it]: train_loss_raw=0.4379, running_loss=0.4780, LR=0.000100
[2025-08-10 23:32:40,754][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081504] [Batch 00280/03692] [00:02:28/00:30:09, 0.530s/it]: train_loss_raw=0.3863, running_loss=0.4783, LR=0.000100
[2025-08-10 23:32:47,207][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081516] [Batch 00292/03692] [00:02:34/00:30:03, 0.531s/it]: train_loss_raw=0.3807, running_loss=0.4769, LR=0.000100
[2025-08-10 23:32:53,512][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081528] [Batch 00304/03692] [00:02:41/00:29:56, 0.530s/it]: train_loss_raw=0.4591, running_loss=0.4762, LR=0.000100
[2025-08-10 23:32:59,944][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081540] [Batch 00316/03692] [00:02:47/00:29:51, 0.531s/it]: train_loss_raw=0.4553, running_loss=0.4768, LR=0.000100
[2025-08-10 23:33:06,429][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081552] [Batch 00328/03692] [00:02:54/00:29:45, 0.531s/it]: train_loss_raw=0.4362, running_loss=0.4773, LR=0.000100
[2025-08-10 23:33:12,977][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081564] [Batch 00340/03692] [00:03:00/00:29:41, 0.531s/it]: train_loss_raw=0.4519, running_loss=0.4750, LR=0.000100
[2025-08-10 23:33:19,531][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081576] [Batch 00352/03692] [00:03:07/00:29:36, 0.532s/it]: train_loss_raw=0.4932, running_loss=0.4775, LR=0.000100
[2025-08-10 23:33:26,099][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081588] [Batch 00364/03692] [00:03:13/00:29:31, 0.532s/it]: train_loss_raw=0.4403, running_loss=0.4791, LR=0.000100
[2025-08-10 23:33:32,482][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081600] [Batch 00376/03692] [00:03:20/00:29:25, 0.532s/it]: train_loss_raw=0.4535, running_loss=0.4788, LR=0.000100
[2025-08-10 23:33:38,729][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081612] [Batch 00388/03692] [00:03:26/00:29:17, 0.532s/it]: train_loss_raw=0.5157, running_loss=0.4790, LR=0.000100
[2025-08-10 23:33:44,980][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081624] [Batch 00400/03692] [00:03:32/00:29:10, 0.532s/it]: train_loss_raw=0.4874, running_loss=0.4799, LR=0.000100
[2025-08-10 23:33:51,159][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081636] [Batch 00412/03692] [00:03:38/00:29:02, 0.531s/it]: train_loss_raw=0.4933, running_loss=0.4792, LR=0.000100
[2025-08-10 23:33:57,223][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081648] [Batch 00424/03692] [00:03:44/00:28:53, 0.530s/it]: train_loss_raw=0.4247, running_loss=0.4818, LR=0.000100
[2025-08-10 23:34:03,270][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081660] [Batch 00436/03692] [00:03:50/00:28:44, 0.530s/it]: train_loss_raw=0.5231, running_loss=0.4807, LR=0.000100
[2025-08-10 23:34:09,337][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081672] [Batch 00448/03692] [00:03:57/00:28:36, 0.529s/it]: train_loss_raw=0.5655, running_loss=0.4819, LR=0.000100
[2025-08-10 23:34:15,667][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081684] [Batch 00460/03692] [00:04:03/00:28:29, 0.529s/it]: train_loss_raw=0.5838, running_loss=0.4824, LR=0.000100
[2025-08-10 23:34:22,042][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081696] [Batch 00472/03692] [00:04:09/00:28:23, 0.529s/it]: train_loss_raw=0.4830, running_loss=0.4811, LR=0.000100
[2025-08-10 23:34:28,113][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081708] [Batch 00484/03692] [00:04:15/00:28:15, 0.529s/it]: train_loss_raw=0.5028, running_loss=0.4774, LR=0.000100
[2025-08-10 23:34:34,617][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081720] [Batch 00496/03692] [00:04:22/00:28:10, 0.529s/it]: train_loss_raw=0.4079, running_loss=0.4783, LR=0.000100
[2025-08-10 23:34:41,069][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081732] [Batch 00508/03692] [00:04:28/00:28:04, 0.529s/it]: train_loss_raw=0.3371, running_loss=0.4761, LR=0.000100
[2025-08-10 23:34:47,464][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081744] [Batch 00520/03692] [00:04:35/00:27:58, 0.529s/it]: train_loss_raw=0.4500, running_loss=0.4763, LR=0.000100
[2025-08-10 23:34:53,836][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081756] [Batch 00532/03692] [00:04:41/00:27:52, 0.529s/it]: train_loss_raw=0.3689, running_loss=0.4737, LR=0.000100
[2025-08-10 23:35:00,219][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081768] [Batch 00544/03692] [00:04:47/00:27:46, 0.529s/it]: train_loss_raw=0.4458, running_loss=0.4717, LR=0.000100
[2025-08-10 23:35:06,697][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081780] [Batch 00556/03692] [00:04:54/00:27:40, 0.529s/it]: train_loss_raw=0.4843, running_loss=0.4719, LR=0.000100
[2025-08-10 23:35:13,209][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081792] [Batch 00568/03692] [00:05:00/00:27:35, 0.530s/it]: train_loss_raw=0.5366, running_loss=0.4724, LR=0.000100
[2025-08-10 23:35:19,722][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081804] [Batch 00580/03692] [00:05:07/00:27:29, 0.530s/it]: train_loss_raw=0.4110, running_loss=0.4699, LR=0.000100
[2025-08-10 23:35:26,178][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081816] [Batch 00592/03692] [00:05:13/00:27:23, 0.530s/it]: train_loss_raw=0.4455, running_loss=0.4683, LR=0.000100
[2025-08-10 23:35:32,541][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081828] [Batch 00604/03692] [00:05:20/00:27:17, 0.530s/it]: train_loss_raw=0.5339, running_loss=0.4699, LR=0.000100
[2025-08-10 23:35:38,941][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081840] [Batch 00616/03692] [00:05:26/00:27:11, 0.530s/it]: train_loss_raw=0.4221, running_loss=0.4692, LR=0.000100
[2025-08-10 23:35:45,378][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081852] [Batch 00628/03692] [00:05:33/00:27:05, 0.530s/it]: train_loss_raw=0.4896, running_loss=0.4705, LR=0.000100
[2025-08-10 23:35:51,701][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081864] [Batch 00640/03692] [00:05:39/00:26:58, 0.530s/it]: train_loss_raw=0.4595, running_loss=0.4724, LR=0.000100
[2025-08-10 23:35:58,079][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081876] [Batch 00652/03692] [00:05:45/00:26:52, 0.530s/it]: train_loss_raw=0.5583, running_loss=0.4753, LR=0.000100
[2025-08-10 23:36:04,599][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081888] [Batch 00664/03692] [00:05:52/00:26:46, 0.531s/it]: train_loss_raw=0.5959, running_loss=0.4785, LR=0.000100
[2025-08-10 23:36:11,202][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081900] [Batch 00676/03692] [00:05:58/00:26:41, 0.531s/it]: train_loss_raw=0.4482, running_loss=0.4759, LR=0.000100
[2025-08-10 23:36:17,462][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081912] [Batch 00688/03692] [00:06:05/00:26:34, 0.531s/it]: train_loss_raw=0.5363, running_loss=0.4762, LR=0.000100
[2025-08-10 23:36:23,690][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081924] [Batch 00700/03692] [00:06:11/00:26:27, 0.531s/it]: train_loss_raw=0.5106, running_loss=0.4768, LR=0.000100
[2025-08-10 23:36:29,995][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081936] [Batch 00712/03692] [00:06:17/00:26:20, 0.530s/it]: train_loss_raw=0.3708, running_loss=0.4744, LR=0.000100
[2025-08-10 23:36:36,519][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081948] [Batch 00724/03692] [00:06:24/00:26:15, 0.531s/it]: train_loss_raw=0.4557, running_loss=0.4735, LR=0.000100
[2025-08-10 23:36:43,091][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081960] [Batch 00736/03692] [00:06:30/00:26:09, 0.531s/it]: train_loss_raw=0.4004, running_loss=0.4725, LR=0.000100
[2025-08-10 23:36:49,630][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081972] [Batch 00748/03692] [00:06:37/00:26:03, 0.531s/it]: train_loss_raw=0.6011, running_loss=0.4727, LR=0.000100
[2025-08-10 23:36:56,103][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081984] [Batch 00760/03692] [00:06:43/00:25:57, 0.531s/it]: train_loss_raw=0.5208, running_loss=0.4764, LR=0.000100
[2025-08-10 23:37:02,565][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 081996] [Batch 00772/03692] [00:06:50/00:25:51, 0.531s/it]: train_loss_raw=0.4814, running_loss=0.4787, LR=0.000100
[2025-08-10 23:37:14,422][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082008] [Batch 00784/03692] [00:07:02/00:26:05, 0.538s/it]: train_loss_raw=0.6084, running_loss=0.4813, LR=0.000100
[2025-08-10 23:37:20,792][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082020] [Batch 00796/03692] [00:07:08/00:25:58, 0.538s/it]: train_loss_raw=0.4566, running_loss=0.4841, LR=0.000100
[2025-08-10 23:37:27,211][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082032] [Batch 00808/03692] [00:07:14/00:25:52, 0.538s/it]: train_loss_raw=0.4433, running_loss=0.4853, LR=0.000100
[2025-08-10 23:37:33,428][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082044] [Batch 00820/03692] [00:07:21/00:25:45, 0.538s/it]: train_loss_raw=0.5587, running_loss=0.4847, LR=0.000100
[2025-08-10 23:37:39,758][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082056] [Batch 00832/03692] [00:07:27/00:25:38, 0.538s/it]: train_loss_raw=0.4213, running_loss=0.4831, LR=0.000100
[2025-08-10 23:37:46,172][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082068] [Batch 00844/03692] [00:07:33/00:25:31, 0.538s/it]: train_loss_raw=0.3920, running_loss=0.4827, LR=0.000100
[2025-08-10 23:37:52,527][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082080] [Batch 00856/03692] [00:07:40/00:25:24, 0.538s/it]: train_loss_raw=0.5246, running_loss=0.4812, LR=0.000100
[2025-08-10 23:37:58,837][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082092] [Batch 00868/03692] [00:07:46/00:25:17, 0.537s/it]: train_loss_raw=0.5355, running_loss=0.4828, LR=0.000100
[2025-08-10 23:38:05,195][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082104] [Batch 00880/03692] [00:07:52/00:25:11, 0.537s/it]: train_loss_raw=0.4670, running_loss=0.4840, LR=0.000100
[2025-08-10 23:38:11,613][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082116] [Batch 00892/03692] [00:07:59/00:25:04, 0.537s/it]: train_loss_raw=0.4023, running_loss=0.4836, LR=0.000100
[2025-08-10 23:38:18,006][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082128] [Batch 00904/03692] [00:08:05/00:24:57, 0.537s/it]: train_loss_raw=0.4505, running_loss=0.4830, LR=0.000100
[2025-08-10 23:38:24,366][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082140] [Batch 00916/03692] [00:08:12/00:24:51, 0.537s/it]: train_loss_raw=0.5626, running_loss=0.4840, LR=0.000100
[2025-08-10 23:38:30,771][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082152] [Batch 00928/03692] [00:08:18/00:24:44, 0.537s/it]: train_loss_raw=0.3842, running_loss=0.4816, LR=0.000100
[2025-08-10 23:38:37,164][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082164] [Batch 00940/03692] [00:08:24/00:24:38, 0.537s/it]: train_loss_raw=0.5146, running_loss=0.4805, LR=0.000100
[2025-08-10 23:38:43,571][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082176] [Batch 00952/03692] [00:08:31/00:24:31, 0.537s/it]: train_loss_raw=0.4310, running_loss=0.4779, LR=0.000100
[2025-08-10 23:38:49,953][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082188] [Batch 00964/03692] [00:08:37/00:24:24, 0.537s/it]: train_loss_raw=0.4407, running_loss=0.4773, LR=0.000100
[2025-08-10 23:38:56,457][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082200] [Batch 00976/03692] [00:08:44/00:24:18, 0.537s/it]: train_loss_raw=0.4313, running_loss=0.4773, LR=0.000100
[2025-08-10 23:39:03,007][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082212] [Batch 00988/03692] [00:08:50/00:24:12, 0.537s/it]: train_loss_raw=0.4640, running_loss=0.4811, LR=0.000100
[2025-08-10 23:39:09,463][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082224] [Batch 01000/03692] [00:08:57/00:24:06, 0.537s/it]: train_loss_raw=0.4772, running_loss=0.4817, LR=0.000100
[2025-08-10 23:39:15,812][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082236] [Batch 01012/03692] [00:09:03/00:23:59, 0.537s/it]: train_loss_raw=0.4782, running_loss=0.4854, LR=0.000100
[2025-08-10 23:39:22,234][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082248] [Batch 01024/03692] [00:09:09/00:23:52, 0.537s/it]: train_loss_raw=0.4558, running_loss=0.4849, LR=0.000100
[2025-08-10 23:39:28,669][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082260] [Batch 01036/03692] [00:09:16/00:23:46, 0.537s/it]: train_loss_raw=0.4651, running_loss=0.4836, LR=0.000100
[2025-08-10 23:39:35,122][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082272] [Batch 01048/03692] [00:09:22/00:23:39, 0.537s/it]: train_loss_raw=0.3572, running_loss=0.4819, LR=0.000100
[2025-08-10 23:39:41,480][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082284] [Batch 01060/03692] [00:09:29/00:23:33, 0.537s/it]: train_loss_raw=0.5066, running_loss=0.4781, LR=0.000100
[2025-08-10 23:39:47,837][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082296] [Batch 01072/03692] [00:09:35/00:23:26, 0.537s/it]: train_loss_raw=0.4083, running_loss=0.4790, LR=0.000100
[2025-08-10 23:39:54,164][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082308] [Batch 01084/03692] [00:09:41/00:23:19, 0.537s/it]: train_loss_raw=0.4820, running_loss=0.4812, LR=0.000100
[2025-08-10 23:40:00,554][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082320] [Batch 01096/03692] [00:09:48/00:23:13, 0.537s/it]: train_loss_raw=0.5856, running_loss=0.4815, LR=0.000100
[2025-08-10 23:40:06,921][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082332] [Batch 01108/03692] [00:09:54/00:23:06, 0.537s/it]: train_loss_raw=0.4883, running_loss=0.4796, LR=0.000100
[2025-08-10 23:40:13,291][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082344] [Batch 01120/03692] [00:10:00/00:23:00, 0.537s/it]: train_loss_raw=0.4844, running_loss=0.4758, LR=0.000100
[2025-08-10 23:40:19,768][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082356] [Batch 01132/03692] [00:10:07/00:22:53, 0.537s/it]: train_loss_raw=0.5562, running_loss=0.4784, LR=0.000100
[2025-08-10 23:40:26,316][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082368] [Batch 01144/03692] [00:10:14/00:22:47, 0.537s/it]: train_loss_raw=0.4303, running_loss=0.4774, LR=0.000100
[2025-08-10 23:40:32,686][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082380] [Batch 01156/03692] [00:10:20/00:22:40, 0.537s/it]: train_loss_raw=0.4828, running_loss=0.4803, LR=0.000100
[2025-08-10 23:40:39,064][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082392] [Batch 01168/03692] [00:10:26/00:22:34, 0.537s/it]: train_loss_raw=0.4205, running_loss=0.4793, LR=0.000100
[2025-08-10 23:40:45,518][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082404] [Batch 01180/03692] [00:10:33/00:22:28, 0.537s/it]: train_loss_raw=0.4798, running_loss=0.4819, LR=0.000100
[2025-08-10 23:40:51,536][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082416] [Batch 01192/03692] [00:10:39/00:22:20, 0.536s/it]: train_loss_raw=0.5368, running_loss=0.4853, LR=0.000100
[2025-08-10 23:40:57,793][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082428] [Batch 01204/03692] [00:10:45/00:22:13, 0.536s/it]: train_loss_raw=0.4568, running_loss=0.4832, LR=0.000100
[2025-08-10 23:41:04,330][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082440] [Batch 01216/03692] [00:10:52/00:22:07, 0.536s/it]: train_loss_raw=0.5558, running_loss=0.4817, LR=0.000100
[2025-08-10 23:41:10,431][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082452] [Batch 01228/03692] [00:10:58/00:22:00, 0.536s/it]: train_loss_raw=0.5588, running_loss=0.4823, LR=0.000100
[2025-08-10 23:41:16,695][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082464] [Batch 01240/03692] [00:11:04/00:21:53, 0.536s/it]: train_loss_raw=0.5525, running_loss=0.4777, LR=0.000100
[2025-08-10 23:41:23,200][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082476] [Batch 01252/03692] [00:11:10/00:21:47, 0.536s/it]: train_loss_raw=0.5359, running_loss=0.4759, LR=0.000100
[2025-08-10 23:41:29,725][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082488] [Batch 01264/03692] [00:11:17/00:21:41, 0.536s/it]: train_loss_raw=0.5038, running_loss=0.4769, LR=0.000100
[2025-08-10 23:41:36,214][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082500] [Batch 01276/03692] [00:11:23/00:21:34, 0.536s/it]: train_loss_raw=0.3810, running_loss=0.4747, LR=0.000100
[2025-08-10 23:41:42,722][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082512] [Batch 01288/03692] [00:11:30/00:21:28, 0.536s/it]: train_loss_raw=0.3957, running_loss=0.4735, LR=0.000100
[2025-08-10 23:41:49,217][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082524] [Batch 01300/03692] [00:11:36/00:21:22, 0.536s/it]: train_loss_raw=0.4731, running_loss=0.4721, LR=0.000100
[2025-08-10 23:41:55,642][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082536] [Batch 01312/03692] [00:11:43/00:21:15, 0.536s/it]: train_loss_raw=0.5288, running_loss=0.4746, LR=0.000100
[2025-08-10 23:42:01,976][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082548] [Batch 01324/03692] [00:11:49/00:21:09, 0.536s/it]: train_loss_raw=0.4487, running_loss=0.4723, LR=0.000100
[2025-08-10 23:42:08,361][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082560] [Batch 01336/03692] [00:11:56/00:21:02, 0.536s/it]: train_loss_raw=0.4494, running_loss=0.4733, LR=0.000100
[2025-08-10 23:42:14,711][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082572] [Batch 01348/03692] [00:12:02/00:20:56, 0.536s/it]: train_loss_raw=0.4631, running_loss=0.4720, LR=0.000100
[2025-08-10 23:42:21,057][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082584] [Batch 01360/03692] [00:12:08/00:20:49, 0.536s/it]: train_loss_raw=0.5642, running_loss=0.4748, LR=0.000100
[2025-08-10 23:42:27,448][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082596] [Batch 01372/03692] [00:12:15/00:20:43, 0.536s/it]: train_loss_raw=0.4709, running_loss=0.4740, LR=0.000100
[2025-08-10 23:42:33,910][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082608] [Batch 01384/03692] [00:12:21/00:20:36, 0.536s/it]: train_loss_raw=0.4643, running_loss=0.4716, LR=0.000100
[2025-08-10 23:42:40,359][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082620] [Batch 01396/03692] [00:12:28/00:20:30, 0.536s/it]: train_loss_raw=0.5063, running_loss=0.4725, LR=0.000100
[2025-08-10 23:42:46,855][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082632] [Batch 01408/03692] [00:12:34/00:20:24, 0.536s/it]: train_loss_raw=0.5295, running_loss=0.4729, LR=0.000100
[2025-08-10 23:42:53,275][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082644] [Batch 01420/03692] [00:12:40/00:20:17, 0.536s/it]: train_loss_raw=0.4932, running_loss=0.4742, LR=0.000100
[2025-08-10 23:42:59,624][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082656] [Batch 01432/03692] [00:12:47/00:20:11, 0.536s/it]: train_loss_raw=0.4275, running_loss=0.4749, LR=0.000100
[2025-08-10 23:43:06,192][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082668] [Batch 01444/03692] [00:12:53/00:20:04, 0.536s/it]: train_loss_raw=0.4803, running_loss=0.4738, LR=0.000100
[2025-08-10 23:43:12,750][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082680] [Batch 01456/03692] [00:13:00/00:19:58, 0.536s/it]: train_loss_raw=0.5296, running_loss=0.4736, LR=0.000100
[2025-08-10 23:43:19,118][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082692] [Batch 01468/03692] [00:13:06/00:19:52, 0.536s/it]: train_loss_raw=0.4139, running_loss=0.4755, LR=0.000100
[2025-08-10 23:43:25,512][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082704] [Batch 01480/03692] [00:13:13/00:19:45, 0.536s/it]: train_loss_raw=0.4458, running_loss=0.4784, LR=0.000100
[2025-08-10 23:43:31,851][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082716] [Batch 01492/03692] [00:13:19/00:19:38, 0.536s/it]: train_loss_raw=0.4439, running_loss=0.4773, LR=0.000100
[2025-08-10 23:43:38,132][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082728] [Batch 01504/03692] [00:13:25/00:19:32, 0.536s/it]: train_loss_raw=0.4923, running_loss=0.4786, LR=0.000100
[2025-08-10 23:43:44,436][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082740] [Batch 01516/03692] [00:13:32/00:19:25, 0.536s/it]: train_loss_raw=0.5155, running_loss=0.4805, LR=0.000100
[2025-08-10 23:43:50,773][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082752] [Batch 01528/03692] [00:13:38/00:19:19, 0.536s/it]: train_loss_raw=0.5656, running_loss=0.4848, LR=0.000100
[2025-08-10 23:44:43,485][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082764] [Batch 01540/03692] [00:14:31/00:20:17, 0.566s/it]: train_loss_raw=0.3834, running_loss=0.4814, LR=0.000100
[2025-08-10 23:44:49,924][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082776] [Batch 01552/03692] [00:14:37/00:20:10, 0.565s/it]: train_loss_raw=0.5222, running_loss=0.4804, LR=0.000100
[2025-08-10 23:44:56,365][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082788] [Batch 01564/03692] [00:14:44/00:20:02, 0.565s/it]: train_loss_raw=0.5304, running_loss=0.4809, LR=0.000100
[2025-08-10 23:45:02,707][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082800] [Batch 01576/03692] [00:14:50/00:19:55, 0.565s/it]: train_loss_raw=0.5356, running_loss=0.4782, LR=0.000100
[2025-08-10 23:45:09,060][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082812] [Batch 01588/03692] [00:14:56/00:19:48, 0.565s/it]: train_loss_raw=0.4769, running_loss=0.4785, LR=0.000100
[2025-08-10 23:45:15,550][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082824] [Batch 01600/03692] [00:15:03/00:19:41, 0.565s/it]: train_loss_raw=0.4646, running_loss=0.4756, LR=0.000100
[2025-08-10 23:45:22,072][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082836] [Batch 01612/03692] [00:15:09/00:19:33, 0.564s/it]: train_loss_raw=0.5220, running_loss=0.4777, LR=0.000100
[2025-08-10 23:45:28,564][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082848] [Batch 01624/03692] [00:15:16/00:19:26, 0.564s/it]: train_loss_raw=0.4776, running_loss=0.4756, LR=0.000100
[2025-08-10 23:45:34,954][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082860] [Batch 01636/03692] [00:15:22/00:19:19, 0.564s/it]: train_loss_raw=0.5168, running_loss=0.4763, LR=0.000100
[2025-08-10 23:45:41,337][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082872] [Batch 01648/03692] [00:15:29/00:19:12, 0.564s/it]: train_loss_raw=0.4871, running_loss=0.4786, LR=0.000100
[2025-08-10 23:45:47,836][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082884] [Batch 01660/03692] [00:15:35/00:19:05, 0.564s/it]: train_loss_raw=0.4834, running_loss=0.4769, LR=0.000100
[2025-08-10 23:45:54,281][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082896] [Batch 01672/03692] [00:15:41/00:18:58, 0.563s/it]: train_loss_raw=0.4309, running_loss=0.4753, LR=0.000100
[2025-08-10 23:46:00,664][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082908] [Batch 01684/03692] [00:15:48/00:18:50, 0.563s/it]: train_loss_raw=0.4813, running_loss=0.4745, LR=0.000100
[2025-08-10 23:46:07,024][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082920] [Batch 01696/03692] [00:15:54/00:18:43, 0.563s/it]: train_loss_raw=0.3658, running_loss=0.4699, LR=0.000100
[2025-08-10 23:46:13,367][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082932] [Batch 01708/03692] [00:16:01/00:18:36, 0.563s/it]: train_loss_raw=0.4191, running_loss=0.4681, LR=0.000100
[2025-08-10 23:46:19,769][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082944] [Batch 01720/03692] [00:16:07/00:18:29, 0.562s/it]: train_loss_raw=0.4246, running_loss=0.4710, LR=0.000100
[2025-08-10 23:46:26,205][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082956] [Batch 01732/03692] [00:16:13/00:18:22, 0.562s/it]: train_loss_raw=0.5779, running_loss=0.4707, LR=0.000100
[2025-08-10 23:46:32,753][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082968] [Batch 01744/03692] [00:16:20/00:18:15, 0.562s/it]: train_loss_raw=0.5302, running_loss=0.4722, LR=0.000100
[2025-08-10 23:46:39,298][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082980] [Batch 01756/03692] [00:16:27/00:18:08, 0.562s/it]: train_loss_raw=0.5170, running_loss=0.4769, LR=0.000100
[2025-08-10 23:46:45,854][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 082992] [Batch 01768/03692] [00:16:33/00:18:01, 0.562s/it]: train_loss_raw=0.5202, running_loss=0.4775, LR=0.000100
[2025-08-10 23:46:52,322][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083004] [Batch 01780/03692] [00:16:40/00:17:54, 0.562s/it]: train_loss_raw=0.4938, running_loss=0.4776, LR=0.000100
[2025-08-10 23:46:58,677][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083016] [Batch 01792/03692] [00:16:46/00:17:47, 0.562s/it]: train_loss_raw=0.3859, running_loss=0.4767, LR=0.000100
[2025-08-10 23:47:05,103][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083028] [Batch 01804/03692] [00:16:52/00:17:39, 0.561s/it]: train_loss_raw=0.4679, running_loss=0.4766, LR=0.000100
[2025-08-10 23:47:11,561][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083040] [Batch 01816/03692] [00:16:59/00:17:32, 0.561s/it]: train_loss_raw=0.5159, running_loss=0.4740, LR=0.000100
[2025-08-10 23:47:18,040][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083052] [Batch 01828/03692] [00:17:05/00:17:25, 0.561s/it]: train_loss_raw=0.4511, running_loss=0.4706, LR=0.000100
[2025-08-10 23:47:24,522][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083064] [Batch 01840/03692] [00:17:12/00:17:18, 0.561s/it]: train_loss_raw=0.4598, running_loss=0.4720, LR=0.000100
[2025-08-10 23:47:30,817][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083076] [Batch 01852/03692] [00:17:18/00:17:11, 0.561s/it]: train_loss_raw=0.3775, running_loss=0.4743, LR=0.000100
[2025-08-10 23:47:36,921][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083088] [Batch 01864/03692] [00:17:24/00:17:04, 0.560s/it]: train_loss_raw=0.5344, running_loss=0.4710, LR=0.000100
[2025-08-10 23:47:43,120][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083100] [Batch 01876/03692] [00:17:30/00:16:57, 0.560s/it]: train_loss_raw=0.4194, running_loss=0.4685, LR=0.000100
[2025-08-10 23:47:49,474][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083112] [Batch 01888/03692] [00:17:37/00:16:50, 0.560s/it]: train_loss_raw=0.4999, running_loss=0.4702, LR=0.000100
[2025-08-10 23:47:55,696][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083124] [Batch 01900/03692] [00:17:43/00:16:42, 0.560s/it]: train_loss_raw=0.5190, running_loss=0.4717, LR=0.000100
[2025-08-10 23:48:01,863][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083136] [Batch 01912/03692] [00:17:49/00:16:35, 0.559s/it]: train_loss_raw=0.5207, running_loss=0.4746, LR=0.000100
[2025-08-10 23:48:07,883][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083148] [Batch 01924/03692] [00:17:55/00:16:28, 0.559s/it]: train_loss_raw=0.4477, running_loss=0.4728, LR=0.000100
[2025-08-10 23:48:13,938][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083160] [Batch 01936/03692] [00:18:01/00:16:21, 0.559s/it]: train_loss_raw=0.6046, running_loss=0.4731, LR=0.000100
[2025-08-10 23:48:20,015][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083172] [Batch 01948/03692] [00:18:07/00:16:13, 0.558s/it]: train_loss_raw=0.5360, running_loss=0.4722, LR=0.000100
[2025-08-10 23:48:26,071][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083184] [Batch 01960/03692] [00:18:13/00:16:06, 0.558s/it]: train_loss_raw=0.4332, running_loss=0.4740, LR=0.000100
[2025-08-10 23:48:32,149][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083196] [Batch 01972/03692] [00:18:19/00:15:59, 0.558s/it]: train_loss_raw=0.3984, running_loss=0.4711, LR=0.000100
[2025-08-10 23:48:38,235][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083208] [Batch 01984/03692] [00:18:25/00:15:52, 0.557s/it]: train_loss_raw=0.5682, running_loss=0.4742, LR=0.000100
[2025-08-10 23:48:44,277][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083220] [Batch 01996/03692] [00:18:31/00:15:44, 0.557s/it]: train_loss_raw=0.4187, running_loss=0.4756, LR=0.000100
[2025-08-10 23:48:50,300][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083232] [Batch 02008/03692] [00:18:38/00:15:37, 0.557s/it]: train_loss_raw=0.5898, running_loss=0.4757, LR=0.000100
[2025-08-10 23:48:56,296][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083244] [Batch 02020/03692] [00:18:44/00:15:30, 0.556s/it]: train_loss_raw=0.3857, running_loss=0.4737, LR=0.000100
[2025-08-10 23:49:02,306][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083256] [Batch 02032/03692] [00:18:50/00:15:23, 0.556s/it]: train_loss_raw=0.3999, running_loss=0.4714, LR=0.000100
[2025-08-10 23:49:08,438][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083268] [Batch 02044/03692] [00:18:56/00:15:16, 0.556s/it]: train_loss_raw=0.4031, running_loss=0.4696, LR=0.000100
[2025-08-10 23:49:14,496][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083280] [Batch 02056/03692] [00:19:02/00:15:08, 0.556s/it]: train_loss_raw=0.5271, running_loss=0.4685, LR=0.000100
[2025-08-10 23:49:20,596][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083292] [Batch 02068/03692] [00:19:08/00:15:01, 0.555s/it]: train_loss_raw=0.4652, running_loss=0.4661, LR=0.000100
[2025-08-10 23:49:26,630][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083304] [Batch 02080/03692] [00:19:14/00:14:54, 0.555s/it]: train_loss_raw=0.5110, running_loss=0.4661, LR=0.000100
[2025-08-10 23:49:32,698][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083316] [Batch 02092/03692] [00:19:20/00:14:47, 0.555s/it]: train_loss_raw=0.4985, running_loss=0.4669, LR=0.000100
[2025-08-10 23:49:38,712][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083328] [Batch 02104/03692] [00:19:26/00:14:40, 0.554s/it]: train_loss_raw=0.4698, running_loss=0.4665, LR=0.000100
[2025-08-10 23:49:45,001][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083340] [Batch 02116/03692] [00:19:32/00:14:33, 0.554s/it]: train_loss_raw=0.4413, running_loss=0.4673, LR=0.000100
[2025-08-10 23:49:51,245][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083352] [Batch 02128/03692] [00:19:38/00:14:26, 0.554s/it]: train_loss_raw=0.6204, running_loss=0.4651, LR=0.000100
[2025-08-10 23:49:57,377][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083364] [Batch 02140/03692] [00:19:45/00:14:19, 0.554s/it]: train_loss_raw=0.5162, running_loss=0.4654, LR=0.000100
[2025-08-10 23:50:03,439][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083376] [Batch 02152/03692] [00:19:51/00:14:12, 0.554s/it]: train_loss_raw=0.4992, running_loss=0.4682, LR=0.000100
[2025-08-10 23:50:09,442][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083388] [Batch 02164/03692] [00:19:57/00:14:05, 0.553s/it]: train_loss_raw=0.5020, running_loss=0.4637, LR=0.000100
[2025-08-10 23:50:15,791][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083400] [Batch 02176/03692] [00:20:03/00:13:58, 0.553s/it]: train_loss_raw=0.4211, running_loss=0.4623, LR=0.000100
[2025-08-10 23:50:22,186][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083412] [Batch 02188/03692] [00:20:09/00:13:51, 0.553s/it]: train_loss_raw=0.4692, running_loss=0.4612, LR=0.000100
[2025-08-10 23:50:28,615][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083424] [Batch 02200/03692] [00:20:16/00:13:44, 0.553s/it]: train_loss_raw=0.4347, running_loss=0.4601, LR=0.000100
[2025-08-10 23:50:35,012][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083436] [Batch 02212/03692] [00:20:22/00:13:38, 0.553s/it]: train_loss_raw=0.3532, running_loss=0.4595, LR=0.000100
[2025-08-10 23:50:41,552][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083448] [Batch 02224/03692] [00:20:29/00:13:31, 0.553s/it]: train_loss_raw=0.4535, running_loss=0.4582, LR=0.000100
[2025-08-10 23:50:47,950][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083460] [Batch 02236/03692] [00:20:35/00:13:24, 0.553s/it]: train_loss_raw=0.5506, running_loss=0.4610, LR=0.000100
[2025-08-10 23:50:54,349][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083472] [Batch 02248/03692] [00:20:42/00:13:17, 0.553s/it]: train_loss_raw=0.4577, running_loss=0.4640, LR=0.000100
[2025-08-10 23:51:00,711][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083484] [Batch 02260/03692] [00:20:48/00:13:11, 0.552s/it]: train_loss_raw=0.4744, running_loss=0.4650, LR=0.000100
[2025-08-10 23:51:07,010][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083496] [Batch 02272/03692] [00:20:54/00:13:04, 0.552s/it]: train_loss_raw=0.4172, running_loss=0.4643, LR=0.000100
[2025-08-10 23:51:13,437][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083508] [Batch 02284/03692] [00:21:01/00:12:57, 0.552s/it]: train_loss_raw=0.5278, running_loss=0.4623, LR=0.000100
[2025-08-10 23:51:19,984][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083520] [Batch 02296/03692] [00:21:07/00:12:50, 0.552s/it]: train_loss_raw=0.3705, running_loss=0.4603, LR=0.000100
[2025-08-10 23:51:26,402][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083532] [Batch 02308/03692] [00:21:14/00:12:44, 0.552s/it]: train_loss_raw=0.3639, running_loss=0.4642, LR=0.000100
[2025-08-10 23:51:32,716][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083544] [Batch 02320/03692] [00:21:20/00:12:37, 0.552s/it]: train_loss_raw=0.4899, running_loss=0.4622, LR=0.000100
[2025-08-10 23:51:39,065][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083556] [Batch 02332/03692] [00:21:26/00:12:30, 0.552s/it]: train_loss_raw=0.5570, running_loss=0.4657, LR=0.000100
[2025-08-10 23:51:45,529][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083568] [Batch 02344/03692] [00:21:33/00:12:23, 0.552s/it]: train_loss_raw=0.4205, running_loss=0.4659, LR=0.000100
[2025-08-10 23:51:51,973][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083580] [Batch 02356/03692] [00:21:39/00:12:16, 0.552s/it]: train_loss_raw=0.5090, running_loss=0.4662, LR=0.000100
[2025-08-10 23:51:58,549][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083592] [Batch 02368/03692] [00:21:46/00:12:10, 0.552s/it]: train_loss_raw=0.5064, running_loss=0.4682, LR=0.000100
[2025-08-10 23:52:04,977][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083604] [Batch 02380/03692] [00:21:52/00:12:03, 0.552s/it]: train_loss_raw=0.4444, running_loss=0.4685, LR=0.000100
[2025-08-10 23:52:11,355][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083616] [Batch 02392/03692] [00:21:59/00:11:56, 0.551s/it]: train_loss_raw=0.3803, running_loss=0.4648, LR=0.000100
[2025-08-10 23:52:17,753][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083628] [Batch 02404/03692] [00:22:05/00:11:50, 0.551s/it]: train_loss_raw=0.4495, running_loss=0.4657, LR=0.000100
[2025-08-10 23:52:24,169][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083640] [Batch 02416/03692] [00:22:11/00:11:43, 0.551s/it]: train_loss_raw=0.5334, running_loss=0.4665, LR=0.000100
[2025-08-10 23:52:30,517][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083652] [Batch 02428/03692] [00:22:18/00:11:36, 0.551s/it]: train_loss_raw=0.5451, running_loss=0.4698, LR=0.000100
[2025-08-10 23:52:36,796][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083664] [Batch 02440/03692] [00:22:24/00:11:29, 0.551s/it]: train_loss_raw=0.4572, running_loss=0.4713, LR=0.000100
[2025-08-10 23:52:43,329][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083676] [Batch 02452/03692] [00:22:31/00:11:23, 0.551s/it]: train_loss_raw=0.4194, running_loss=0.4696, LR=0.000100
[2025-08-10 23:52:49,810][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083688] [Batch 02464/03692] [00:22:37/00:11:16, 0.551s/it]: train_loss_raw=0.4677, running_loss=0.4708, LR=0.000100
[2025-08-10 23:52:56,328][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083700] [Batch 02476/03692] [00:22:44/00:11:09, 0.551s/it]: train_loss_raw=0.5188, running_loss=0.4743, LR=0.000100
[2025-08-10 23:53:02,789][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083712] [Batch 02488/03692] [00:22:50/00:11:03, 0.551s/it]: train_loss_raw=0.4534, running_loss=0.4714, LR=0.000100
[2025-08-10 23:53:09,307][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083724] [Batch 02500/03692] [00:22:57/00:10:56, 0.551s/it]: train_loss_raw=0.3808, running_loss=0.4704, LR=0.000100
[2025-08-10 23:53:15,471][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083736] [Batch 02512/03692] [00:23:03/00:10:49, 0.551s/it]: train_loss_raw=0.5183, running_loss=0.4698, LR=0.000100
[2025-08-10 23:53:21,809][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083748] [Batch 02524/03692] [00:23:09/00:10:43, 0.551s/it]: train_loss_raw=0.4045, running_loss=0.4707, LR=0.000100
[2025-08-10 23:53:28,027][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083760] [Batch 02536/03692] [00:23:15/00:10:36, 0.550s/it]: train_loss_raw=0.5587, running_loss=0.4693, LR=0.000100
[2025-08-10 23:53:34,304][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083772] [Batch 02548/03692] [00:23:22/00:10:29, 0.550s/it]: train_loss_raw=0.5362, running_loss=0.4694, LR=0.000100
[2025-08-10 23:53:40,716][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083784] [Batch 02560/03692] [00:23:28/00:10:22, 0.550s/it]: train_loss_raw=0.4137, running_loss=0.4697, LR=0.000100
[2025-08-10 23:53:47,322][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083796] [Batch 02572/03692] [00:23:35/00:10:16, 0.550s/it]: train_loss_raw=0.4605, running_loss=0.4695, LR=0.000100
[2025-08-10 23:53:53,799][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083808] [Batch 02584/03692] [00:23:41/00:10:09, 0.550s/it]: train_loss_raw=0.3996, running_loss=0.4676, LR=0.000100
[2025-08-10 23:54:00,271][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083820] [Batch 02596/03692] [00:23:47/00:10:02, 0.550s/it]: train_loss_raw=0.6119, running_loss=0.4701, LR=0.000100
[2025-08-10 23:54:06,669][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083832] [Batch 02608/03692] [00:23:54/00:09:56, 0.550s/it]: train_loss_raw=0.4534, running_loss=0.4691, LR=0.000100
[2025-08-10 23:54:13,079][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083844] [Batch 02620/03692] [00:24:00/00:09:49, 0.550s/it]: train_loss_raw=0.4021, running_loss=0.4652, LR=0.000100
[2025-08-10 23:54:19,442][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083856] [Batch 02632/03692] [00:24:07/00:09:42, 0.550s/it]: train_loss_raw=0.5278, running_loss=0.4656, LR=0.000100
[2025-08-10 23:54:25,828][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083868] [Batch 02644/03692] [00:24:13/00:09:36, 0.550s/it]: train_loss_raw=0.4233, running_loss=0.4647, LR=0.000100
[2025-08-10 23:54:32,223][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083880] [Batch 02656/03692] [00:24:19/00:09:29, 0.550s/it]: train_loss_raw=0.3775, running_loss=0.4622, LR=0.000100
[2025-08-10 23:54:38,623][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083892] [Batch 02668/03692] [00:24:26/00:09:22, 0.550s/it]: train_loss_raw=0.4528, running_loss=0.4632, LR=0.000100
[2025-08-10 23:54:45,118][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083904] [Batch 02680/03692] [00:24:32/00:09:16, 0.550s/it]: train_loss_raw=0.5102, running_loss=0.4634, LR=0.000100
[2025-08-10 23:54:51,473][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083916] [Batch 02692/03692] [00:24:39/00:09:09, 0.549s/it]: train_loss_raw=0.4930, running_loss=0.4629, LR=0.000100
[2025-08-10 23:54:57,887][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083928] [Batch 02704/03692] [00:24:45/00:09:02, 0.549s/it]: train_loss_raw=0.4835, running_loss=0.4626, LR=0.000100
[2025-08-10 23:55:04,264][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083940] [Batch 02716/03692] [00:24:51/00:08:56, 0.549s/it]: train_loss_raw=0.4479, running_loss=0.4588, LR=0.000100
[2025-08-10 23:55:10,612][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083952] [Batch 02728/03692] [00:24:58/00:08:49, 0.549s/it]: train_loss_raw=0.4750, running_loss=0.4598, LR=0.000100
[2025-08-10 23:55:17,045][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083964] [Batch 02740/03692] [00:25:04/00:08:42, 0.549s/it]: train_loss_raw=0.6560, running_loss=0.4622, LR=0.000100
[2025-08-10 23:55:23,432][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083976] [Batch 02752/03692] [00:25:11/00:08:36, 0.549s/it]: train_loss_raw=0.4281, running_loss=0.4613, LR=0.000100
[2025-08-10 23:55:29,835][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 083988] [Batch 02764/03692] [00:25:17/00:08:29, 0.549s/it]: train_loss_raw=0.4562, running_loss=0.4605, LR=0.000100
[2025-08-10 23:55:36,224][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084000] [Batch 02776/03692] [00:25:23/00:08:22, 0.549s/it]: train_loss_raw=0.3907, running_loss=0.4610, LR=0.000100
[2025-08-10 23:55:47,279][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084012] [Batch 02788/03692] [00:25:34/00:08:17, 0.551s/it]: train_loss_raw=0.4991, running_loss=0.4606, LR=0.000100
[2025-08-10 23:55:53,680][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084024] [Batch 02800/03692] [00:25:41/00:08:11, 0.550s/it]: train_loss_raw=0.4837, running_loss=0.4634, LR=0.000100
[2025-08-10 23:56:00,038][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084036] [Batch 02812/03692] [00:25:47/00:08:04, 0.550s/it]: train_loss_raw=0.4863, running_loss=0.4656, LR=0.000100
[2025-08-10 23:56:06,321][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084048] [Batch 02824/03692] [00:25:54/00:07:57, 0.550s/it]: train_loss_raw=0.5095, running_loss=0.4638, LR=0.000100
[2025-08-10 23:56:12,667][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084060] [Batch 02836/03692] [00:26:00/00:07:50, 0.550s/it]: train_loss_raw=0.4229, running_loss=0.4617, LR=0.000100
[2025-08-10 23:56:18,928][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084072] [Batch 02848/03692] [00:26:06/00:07:44, 0.550s/it]: train_loss_raw=0.5064, running_loss=0.4620, LR=0.000100
[2025-08-10 23:56:25,171][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084084] [Batch 02860/03692] [00:26:12/00:07:37, 0.550s/it]: train_loss_raw=0.5416, running_loss=0.4653, LR=0.000100
[2025-08-10 23:56:31,548][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084096] [Batch 02872/03692] [00:26:19/00:07:30, 0.550s/it]: train_loss_raw=0.6135, running_loss=0.4658, LR=0.000100
[2025-08-10 23:56:37,933][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084108] [Batch 02884/03692] [00:26:25/00:07:24, 0.550s/it]: train_loss_raw=0.4992, running_loss=0.4705, LR=0.000100
[2025-08-10 23:56:44,341][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084120] [Batch 02896/03692] [00:26:32/00:07:17, 0.550s/it]: train_loss_raw=0.4570, running_loss=0.4680, LR=0.000100
[2025-08-10 23:56:50,715][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084132] [Batch 02908/03692] [00:26:38/00:07:10, 0.550s/it]: train_loss_raw=0.5276, running_loss=0.4654, LR=0.000100
[2025-08-10 23:56:57,099][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084144] [Batch 02920/03692] [00:26:44/00:07:04, 0.550s/it]: train_loss_raw=0.4972, running_loss=0.4657, LR=0.000100
[2025-08-10 23:57:03,568][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084156] [Batch 02932/03692] [00:26:51/00:06:57, 0.550s/it]: train_loss_raw=0.4647, running_loss=0.4641, LR=0.000100
[2025-08-10 23:57:10,011][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084168] [Batch 02944/03692] [00:26:57/00:06:51, 0.549s/it]: train_loss_raw=0.4989, running_loss=0.4682, LR=0.000100
[2025-08-10 23:57:16,440][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084180] [Batch 02956/03692] [00:27:04/00:06:44, 0.549s/it]: train_loss_raw=0.5311, running_loss=0.4649, LR=0.000100
[2025-08-10 23:57:22,853][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084192] [Batch 02968/03692] [00:27:10/00:06:37, 0.549s/it]: train_loss_raw=0.4263, running_loss=0.4618, LR=0.000100
[2025-08-10 23:57:29,145][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084204] [Batch 02980/03692] [00:27:16/00:06:31, 0.549s/it]: train_loss_raw=0.4788, running_loss=0.4608, LR=0.000100
[2025-08-10 23:57:35,507][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084216] [Batch 02992/03692] [00:27:23/00:06:24, 0.549s/it]: train_loss_raw=0.4403, running_loss=0.4599, LR=0.000100
[2025-08-10 23:57:41,868][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084228] [Batch 03004/03692] [00:27:29/00:06:17, 0.549s/it]: train_loss_raw=0.5725, running_loss=0.4601, LR=0.000100
[2025-08-10 23:57:48,330][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084240] [Batch 03016/03692] [00:27:36/00:06:11, 0.549s/it]: train_loss_raw=0.4668, running_loss=0.4625, LR=0.000100
[2025-08-10 23:57:54,774][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084252] [Batch 03028/03692] [00:27:42/00:06:04, 0.549s/it]: train_loss_raw=0.4486, running_loss=0.4599, LR=0.000100
[2025-08-10 23:58:01,242][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084264] [Batch 03040/03692] [00:27:48/00:05:57, 0.549s/it]: train_loss_raw=0.4592, running_loss=0.4630, LR=0.000100
[2025-08-10 23:58:07,661][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084276] [Batch 03052/03692] [00:27:55/00:05:51, 0.549s/it]: train_loss_raw=0.3834, running_loss=0.4628, LR=0.000100
[2025-08-10 23:58:14,062][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084288] [Batch 03064/03692] [00:28:01/00:05:44, 0.549s/it]: train_loss_raw=0.4825, running_loss=0.4629, LR=0.000100
[2025-08-10 23:58:20,520][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084300] [Batch 03076/03692] [00:28:08/00:05:38, 0.549s/it]: train_loss_raw=0.5045, running_loss=0.4607, LR=0.000100
[2025-08-10 23:58:26,989][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084312] [Batch 03088/03692] [00:28:14/00:05:31, 0.549s/it]: train_loss_raw=0.4647, running_loss=0.4646, LR=0.000100
[2025-08-10 23:58:33,409][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084324] [Batch 03100/03692] [00:28:21/00:05:24, 0.549s/it]: train_loss_raw=0.4484, running_loss=0.4650, LR=0.000100
[2025-08-10 23:58:39,772][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084336] [Batch 03112/03692] [00:28:27/00:05:18, 0.549s/it]: train_loss_raw=0.4244, running_loss=0.4632, LR=0.000100
[2025-08-10 23:58:46,106][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084348] [Batch 03124/03692] [00:28:33/00:05:11, 0.549s/it]: train_loss_raw=0.5022, running_loss=0.4617, LR=0.000100
[2025-08-10 23:58:52,550][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084360] [Batch 03136/03692] [00:28:40/00:05:04, 0.549s/it]: train_loss_raw=0.4624, running_loss=0.4616, LR=0.000100
[2025-08-10 23:58:58,877][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084372] [Batch 03148/03692] [00:28:46/00:04:58, 0.548s/it]: train_loss_raw=0.4203, running_loss=0.4615, LR=0.000100
[2025-08-10 23:59:05,183][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084384] [Batch 03160/03692] [00:28:52/00:04:51, 0.548s/it]: train_loss_raw=0.5726, running_loss=0.4620, LR=0.000100
[2025-08-10 23:59:11,536][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084396] [Batch 03172/03692] [00:28:59/00:04:45, 0.548s/it]: train_loss_raw=0.4874, running_loss=0.4596, LR=0.000100
[2025-08-10 23:59:17,903][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084408] [Batch 03184/03692] [00:29:05/00:04:38, 0.548s/it]: train_loss_raw=0.5255, running_loss=0.4580, LR=0.000100
[2025-08-10 23:59:24,272][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084420] [Batch 03196/03692] [00:29:11/00:04:31, 0.548s/it]: train_loss_raw=0.4928, running_loss=0.4597, LR=0.000100
[2025-08-10 23:59:30,563][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084432] [Batch 03208/03692] [00:29:18/00:04:25, 0.548s/it]: train_loss_raw=0.4525, running_loss=0.4626, LR=0.000100
[2025-08-10 23:59:36,979][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084444] [Batch 03220/03692] [00:29:24/00:04:18, 0.548s/it]: train_loss_raw=0.4750, running_loss=0.4622, LR=0.000100
[2025-08-10 23:59:43,334][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084456] [Batch 03232/03692] [00:29:31/00:04:12, 0.548s/it]: train_loss_raw=0.4228, running_loss=0.4664, LR=0.000100
[2025-08-10 23:59:49,754][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084468] [Batch 03244/03692] [00:29:37/00:04:05, 0.548s/it]: train_loss_raw=0.4123, running_loss=0.4697, LR=0.000100
[2025-08-10 23:59:56,142][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084480] [Batch 03256/03692] [00:29:43/00:03:58, 0.548s/it]: train_loss_raw=0.4311, running_loss=0.4684, LR=0.000100
[2025-08-11 00:00:02,531][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084492] [Batch 03268/03692] [00:29:50/00:03:52, 0.548s/it]: train_loss_raw=0.5188, running_loss=0.4673, LR=0.000100
[2025-08-11 00:00:09,045][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084504] [Batch 03280/03692] [00:29:56/00:03:45, 0.548s/it]: train_loss_raw=0.4792, running_loss=0.4676, LR=0.000100
[2025-08-11 00:00:15,587][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084516] [Batch 03292/03692] [00:30:03/00:03:39, 0.548s/it]: train_loss_raw=0.4191, running_loss=0.4629, LR=0.000100
[2025-08-11 00:00:21,934][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084528] [Batch 03304/03692] [00:30:09/00:03:32, 0.548s/it]: train_loss_raw=0.3566, running_loss=0.4583, LR=0.000100
[2025-08-11 00:00:28,218][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084540] [Batch 03316/03692] [00:30:15/00:03:25, 0.548s/it]: train_loss_raw=0.4421, running_loss=0.4595, LR=0.000100
[2025-08-11 00:00:34,615][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084552] [Batch 03328/03692] [00:30:22/00:03:19, 0.548s/it]: train_loss_raw=0.5985, running_loss=0.4598, LR=0.000100
[2025-08-11 00:00:41,090][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084564] [Batch 03340/03692] [00:30:28/00:03:12, 0.548s/it]: train_loss_raw=0.4151, running_loss=0.4582, LR=0.000100
[2025-08-11 00:00:47,623][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084576] [Batch 03352/03692] [00:30:35/00:03:06, 0.548s/it]: train_loss_raw=0.4650, running_loss=0.4582, LR=0.000100
[2025-08-11 00:00:54,157][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084588] [Batch 03364/03692] [00:30:41/00:02:59, 0.548s/it]: train_loss_raw=0.4705, running_loss=0.4558, LR=0.000100
[2025-08-11 00:01:00,553][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084600] [Batch 03376/03692] [00:30:48/00:02:53, 0.547s/it]: train_loss_raw=0.5077, running_loss=0.4570, LR=0.000100
[2025-08-11 00:01:06,974][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084612] [Batch 03388/03692] [00:30:54/00:02:46, 0.547s/it]: train_loss_raw=0.4763, running_loss=0.4613, LR=0.000100
[2025-08-11 00:01:13,490][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084624] [Batch 03400/03692] [00:31:01/00:02:39, 0.547s/it]: train_loss_raw=0.5162, running_loss=0.4614, LR=0.000100
[2025-08-11 00:01:20,052][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084636] [Batch 03412/03692] [00:31:07/00:02:33, 0.547s/it]: train_loss_raw=0.4809, running_loss=0.4595, LR=0.000100
[2025-08-11 00:01:26,548][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084648] [Batch 03424/03692] [00:31:14/00:02:26, 0.547s/it]: train_loss_raw=0.5478, running_loss=0.4599, LR=0.000100
[2025-08-11 00:01:33,022][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084660] [Batch 03436/03692] [00:31:20/00:02:20, 0.547s/it]: train_loss_raw=0.3798, running_loss=0.4576, LR=0.000100
[2025-08-11 00:01:39,506][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084672] [Batch 03448/03692] [00:31:27/00:02:13, 0.547s/it]: train_loss_raw=0.4434, running_loss=0.4588, LR=0.000100
[2025-08-11 00:01:46,007][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084684] [Batch 03460/03692] [00:31:33/00:02:06, 0.547s/it]: train_loss_raw=0.5070, running_loss=0.4621, LR=0.000100
[2025-08-11 00:01:52,534][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084696] [Batch 03472/03692] [00:31:40/00:02:00, 0.547s/it]: train_loss_raw=0.3696, running_loss=0.4630, LR=0.000100
[2025-08-11 00:01:58,844][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084708] [Batch 03484/03692] [00:31:46/00:01:53, 0.547s/it]: train_loss_raw=0.4588, running_loss=0.4647, LR=0.000100
[2025-08-11 00:02:05,161][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084720] [Batch 03496/03692] [00:31:52/00:01:47, 0.547s/it]: train_loss_raw=0.3251, running_loss=0.4618, LR=0.000100
[2025-08-11 00:02:11,603][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084732] [Batch 03508/03692] [00:31:59/00:01:40, 0.547s/it]: train_loss_raw=0.4276, running_loss=0.4581, LR=0.000100
[2025-08-11 00:02:18,168][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084744] [Batch 03520/03692] [00:32:05/00:01:34, 0.547s/it]: train_loss_raw=0.5361, running_loss=0.4589, LR=0.000100
[2025-08-11 00:02:24,615][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084756] [Batch 03532/03692] [00:32:12/00:01:27, 0.547s/it]: train_loss_raw=0.3725, running_loss=0.4559, LR=0.000100
[2025-08-11 00:02:31,098][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084768] [Batch 03544/03692] [00:32:18/00:01:20, 0.547s/it]: train_loss_raw=0.4643, running_loss=0.4596, LR=0.000100
[2025-08-11 00:02:37,262][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084780] [Batch 03556/03692] [00:32:24/00:01:14, 0.547s/it]: train_loss_raw=0.4927, running_loss=0.4560, LR=0.000100
[2025-08-11 00:02:43,801][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084792] [Batch 03568/03692] [00:32:31/00:01:07, 0.547s/it]: train_loss_raw=0.4597, running_loss=0.4535, LR=0.000100
[2025-08-11 00:02:50,357][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084804] [Batch 03580/03692] [00:32:38/00:01:01, 0.547s/it]: train_loss_raw=0.5965, running_loss=0.4545, LR=0.000100
[2025-08-11 00:02:56,863][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084816] [Batch 03592/03692] [00:32:44/00:00:54, 0.547s/it]: train_loss_raw=0.4416, running_loss=0.4539, LR=0.000100
[2025-08-11 00:03:03,423][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084828] [Batch 03604/03692] [00:32:51/00:00:48, 0.547s/it]: train_loss_raw=0.5178, running_loss=0.4560, LR=0.000100
[2025-08-11 00:03:09,935][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084840] [Batch 03616/03692] [00:32:57/00:00:41, 0.547s/it]: train_loss_raw=0.4427, running_loss=0.4575, LR=0.000100
[2025-08-11 00:03:16,489][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084852] [Batch 03628/03692] [00:33:04/00:00:35, 0.547s/it]: train_loss_raw=0.5448, running_loss=0.4580, LR=0.000100
[2025-08-11 00:03:22,708][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084864] [Batch 03640/03692] [00:33:10/00:00:28, 0.547s/it]: train_loss_raw=0.5272, running_loss=0.4601, LR=0.000100
[2025-08-11 00:03:28,788][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084876] [Batch 03652/03692] [00:33:16/00:00:21, 0.547s/it]: train_loss_raw=0.4493, running_loss=0.4622, LR=0.000100
[2025-08-11 00:03:34,935][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084888] [Batch 03664/03692] [00:33:22/00:00:15, 0.547s/it]: train_loss_raw=0.3988, running_loss=0.4614, LR=0.000100
[2025-08-11 00:03:41,415][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084900] [Batch 03676/03692] [00:33:29/00:00:08, 0.547s/it]: train_loss_raw=0.5408, running_loss=0.4633, LR=0.000100
[2025-08-11 00:03:47,893][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 084912] [Batch 03688/03692] [00:33:35/00:00:02, 0.547s/it]: train_loss_raw=0.4873, running_loss=0.4613, LR=0.000100
[2025-08-11 00:03:54,910][__main__][INFO] - [VALIDATION] [Epoch 22/29] Starting validation.
[2025-08-11 00:04:25,894][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 084917] [Batch 00011/00025] [00:00:30/00:00:33, 2.582s/it]
[2025-08-11 00:04:41,414][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 084917] [Batch 00023/00025] [00:00:46/00:00:01, 1.938s/it]
[2025-08-11 00:04:42,568][__main__][INFO] - [VALIDATION] [Epoch 22/29] train_loss=0.45985, valid_loss=0.59112
[2025-08-11 00:04:42,569][__main__][INFO] - [VALIDATION] [Epoch 22/29] Metrics:
[2025-08-11 00:04:42,569][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_er      0.246
[2025-08-11 00:04:42,569][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_prec    0.538
[2025-08-11 00:04:42,569][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_recall  0.546
[2025-08-11 00:04:42,569][__main__][INFO] - [VALIDATION] [Epoch 22/29] - pep_recall 0.518
[2025-08-11 00:04:42,572][__main__][INFO] - [TRAIN] [Epoch 22/29] Epoch complete, total time 13:08:41, remaining time 04:00:02, 00:34:17 per epoch
[2025-08-11 00:04:48,064][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084924] [Batch 00008/03692] [00:00:03/00:29:34, 0.482s/it]: train_loss_raw=0.5173, running_loss=0.4142, LR=0.000100
[2025-08-11 00:04:54,316][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084936] [Batch 00020/03692] [00:00:10/00:30:55, 0.505s/it]: train_loss_raw=0.5270, running_loss=0.4224, LR=0.000100
[2025-08-11 00:05:00,514][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084948] [Batch 00032/03692] [00:00:16/00:31:04, 0.509s/it]: train_loss_raw=0.3825, running_loss=0.4246, LR=0.000100
[2025-08-11 00:05:06,739][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084960] [Batch 00044/03692] [00:00:22/00:31:07, 0.512s/it]: train_loss_raw=0.4601, running_loss=0.4260, LR=0.000100
[2025-08-11 00:05:12,856][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084972] [Batch 00056/03692] [00:00:28/00:30:59, 0.512s/it]: train_loss_raw=0.4548, running_loss=0.4290, LR=0.000100
[2025-08-11 00:05:19,021][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084984] [Batch 00068/03692] [00:00:34/00:30:55, 0.512s/it]: train_loss_raw=0.5144, running_loss=0.4333, LR=0.000100
[2025-08-11 00:05:25,514][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 084996] [Batch 00080/03692] [00:00:41/00:31:04, 0.516s/it]: train_loss_raw=0.4862, running_loss=0.4362, LR=0.000100
[2025-08-11 00:05:31,886][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085008] [Batch 00092/03692] [00:00:47/00:31:05, 0.518s/it]: train_loss_raw=0.4968, running_loss=0.4424, LR=0.000100
[2025-08-11 00:05:38,387][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085020] [Batch 00104/03692] [00:00:54/00:31:09, 0.521s/it]: train_loss_raw=0.5373, running_loss=0.4444, LR=0.000100
[2025-08-11 00:05:44,854][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085032] [Batch 00116/03692] [00:01:00/00:31:09, 0.523s/it]: train_loss_raw=0.4825, running_loss=0.4464, LR=0.000100
[2025-08-11 00:05:51,298][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085044] [Batch 00128/03692] [00:01:07/00:31:07, 0.524s/it]: train_loss_raw=0.4282, running_loss=0.4479, LR=0.000100
[2025-08-11 00:05:57,864][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085056] [Batch 00140/03692] [00:01:13/00:31:08, 0.526s/it]: train_loss_raw=0.4700, running_loss=0.4520, LR=0.000100
[2025-08-11 00:06:04,253][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085068] [Batch 00152/03692] [00:01:20/00:31:04, 0.527s/it]: train_loss_raw=0.4240, running_loss=0.4523, LR=0.000100
[2025-08-11 00:06:10,768][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085080] [Batch 00164/03692] [00:01:26/00:31:02, 0.528s/it]: train_loss_raw=0.5673, running_loss=0.4558, LR=0.000100
[2025-08-11 00:06:17,246][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085092] [Batch 00176/03692] [00:01:33/00:30:58, 0.529s/it]: train_loss_raw=0.5672, running_loss=0.4606, LR=0.000100
[2025-08-11 00:06:23,664][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085104] [Batch 00188/03692] [00:01:39/00:30:53, 0.529s/it]: train_loss_raw=0.4115, running_loss=0.4584, LR=0.000100
[2025-08-11 00:06:30,142][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085116] [Batch 00200/03692] [00:01:45/00:30:49, 0.530s/it]: train_loss_raw=0.4959, running_loss=0.4599, LR=0.000100
[2025-08-11 00:06:36,696][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085128] [Batch 00212/03692] [00:01:52/00:30:46, 0.531s/it]: train_loss_raw=0.3634, running_loss=0.4625, LR=0.000100
[2025-08-11 00:06:43,017][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085140] [Batch 00224/03692] [00:01:58/00:30:39, 0.530s/it]: train_loss_raw=0.4536, running_loss=0.4624, LR=0.000100
[2025-08-11 00:06:49,349][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085152] [Batch 00236/03692] [00:02:05/00:30:32, 0.530s/it]: train_loss_raw=0.3703, running_loss=0.4600, LR=0.000100
[2025-08-11 00:06:55,794][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085164] [Batch 00248/03692] [00:02:11/00:30:27, 0.531s/it]: train_loss_raw=0.4005, running_loss=0.4635, LR=0.000100
[2025-08-11 00:07:02,264][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085176] [Batch 00260/03692] [00:02:18/00:30:22, 0.531s/it]: train_loss_raw=0.4805, running_loss=0.4647, LR=0.000100
[2025-08-11 00:07:08,676][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085188] [Batch 00272/03692] [00:02:24/00:30:16, 0.531s/it]: train_loss_raw=0.6293, running_loss=0.4661, LR=0.000100
[2025-08-11 00:07:15,151][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085200] [Batch 00284/03692] [00:02:30/00:30:11, 0.531s/it]: train_loss_raw=0.3728, running_loss=0.4679, LR=0.000100
[2025-08-11 00:07:21,541][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085212] [Batch 00296/03692] [00:02:37/00:30:05, 0.532s/it]: train_loss_raw=0.4374, running_loss=0.4624, LR=0.000100
[2025-08-11 00:07:27,965][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085224] [Batch 00308/03692] [00:02:43/00:29:59, 0.532s/it]: train_loss_raw=0.4940, running_loss=0.4648, LR=0.000100
[2025-08-11 00:07:34,381][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085236] [Batch 00320/03692] [00:02:50/00:29:53, 0.532s/it]: train_loss_raw=0.4038, running_loss=0.4617, LR=0.000100
[2025-08-11 00:07:40,850][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085248] [Batch 00332/03692] [00:02:56/00:29:47, 0.532s/it]: train_loss_raw=0.4993, running_loss=0.4642, LR=0.000100
[2025-08-11 00:07:47,328][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085260] [Batch 00344/03692] [00:03:03/00:29:42, 0.532s/it]: train_loss_raw=0.4796, running_loss=0.4618, LR=0.000100
[2025-08-11 00:07:53,834][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085272] [Batch 00356/03692] [00:03:09/00:29:36, 0.533s/it]: train_loss_raw=0.3549, running_loss=0.4585, LR=0.000100
[2025-08-11 00:08:00,297][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085284] [Batch 00368/03692] [00:03:16/00:29:31, 0.533s/it]: train_loss_raw=0.5706, running_loss=0.4578, LR=0.000100
[2025-08-11 00:08:06,766][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085296] [Batch 00380/03692] [00:03:22/00:29:25, 0.533s/it]: train_loss_raw=0.5214, running_loss=0.4572, LR=0.000100
[2025-08-11 00:08:13,284][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085308] [Batch 00392/03692] [00:03:29/00:29:20, 0.533s/it]: train_loss_raw=0.4788, running_loss=0.4572, LR=0.000100
[2025-08-11 00:08:19,819][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085320] [Batch 00404/03692] [00:03:35/00:29:14, 0.534s/it]: train_loss_raw=0.5187, running_loss=0.4634, LR=0.000100
[2025-08-11 00:08:26,316][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085332] [Batch 00416/03692] [00:03:42/00:29:09, 0.534s/it]: train_loss_raw=0.3995, running_loss=0.4611, LR=0.000100
[2025-08-11 00:08:32,770][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085344] [Batch 00428/03692] [00:03:48/00:29:03, 0.534s/it]: train_loss_raw=0.4525, running_loss=0.4577, LR=0.000100
[2025-08-11 00:08:39,317][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085356] [Batch 00440/03692] [00:03:55/00:28:57, 0.534s/it]: train_loss_raw=0.4730, running_loss=0.4595, LR=0.000100
[2025-08-11 00:08:45,446][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085368] [Batch 00452/03692] [00:04:01/00:28:49, 0.534s/it]: train_loss_raw=0.4797, running_loss=0.4619, LR=0.000100
[2025-08-11 00:08:51,802][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085380] [Batch 00464/03692] [00:04:07/00:28:42, 0.534s/it]: train_loss_raw=0.4284, running_loss=0.4619, LR=0.000100
[2025-08-11 00:08:58,283][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085392] [Batch 00476/03692] [00:04:14/00:28:36, 0.534s/it]: train_loss_raw=0.5603, running_loss=0.4632, LR=0.000100
[2025-08-11 00:09:04,684][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085404] [Batch 00488/03692] [00:04:20/00:28:30, 0.534s/it]: train_loss_raw=0.3910, running_loss=0.4617, LR=0.000100
[2025-08-11 00:09:10,906][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085416] [Batch 00500/03692] [00:04:26/00:28:22, 0.533s/it]: train_loss_raw=0.4632, running_loss=0.4584, LR=0.000100
[2025-08-11 00:09:17,047][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085428] [Batch 00512/03692] [00:04:32/00:28:14, 0.533s/it]: train_loss_raw=0.4220, running_loss=0.4590, LR=0.000100
[2025-08-11 00:09:23,016][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085440] [Batch 00524/03692] [00:04:38/00:28:05, 0.532s/it]: train_loss_raw=0.4373, running_loss=0.4594, LR=0.000100
[2025-08-11 00:09:29,069][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085452] [Batch 00536/03692] [00:04:44/00:27:57, 0.531s/it]: train_loss_raw=0.5068, running_loss=0.4618, LR=0.000100
[2025-08-11 00:09:35,395][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085464] [Batch 00548/03692] [00:04:51/00:27:50, 0.531s/it]: train_loss_raw=0.3716, running_loss=0.4611, LR=0.000100
[2025-08-11 00:09:42,048][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085476] [Batch 00560/03692] [00:04:57/00:27:45, 0.532s/it]: train_loss_raw=0.4945, running_loss=0.4621, LR=0.000100
[2025-08-11 00:09:48,516][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085488] [Batch 00572/03692] [00:05:04/00:27:39, 0.532s/it]: train_loss_raw=0.5091, running_loss=0.4605, LR=0.000100
[2025-08-11 00:09:55,096][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085500] [Batch 00584/03692] [00:05:10/00:27:34, 0.532s/it]: train_loss_raw=0.4689, running_loss=0.4599, LR=0.000100
[2025-08-11 00:10:01,603][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085512] [Batch 00596/03692] [00:05:17/00:27:28, 0.533s/it]: train_loss_raw=0.5230, running_loss=0.4604, LR=0.000100
[2025-08-11 00:10:08,199][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085524] [Batch 00608/03692] [00:05:23/00:27:23, 0.533s/it]: train_loss_raw=0.5362, running_loss=0.4619, LR=0.000100
[2025-08-11 00:10:14,622][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085536] [Batch 00620/03692] [00:05:30/00:27:17, 0.533s/it]: train_loss_raw=0.4688, running_loss=0.4600, LR=0.000100
[2025-08-11 00:10:21,089][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085548] [Batch 00632/03692] [00:05:36/00:27:11, 0.533s/it]: train_loss_raw=0.4660, running_loss=0.4575, LR=0.000100
[2025-08-11 00:10:27,520][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085560] [Batch 00644/03692] [00:05:43/00:27:04, 0.533s/it]: train_loss_raw=0.4798, running_loss=0.4580, LR=0.000100
[2025-08-11 00:10:33,929][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085572] [Batch 00656/03692] [00:05:49/00:26:58, 0.533s/it]: train_loss_raw=0.5776, running_loss=0.4611, LR=0.000100
[2025-08-11 00:10:40,281][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085584] [Batch 00668/03692] [00:05:56/00:26:51, 0.533s/it]: train_loss_raw=0.4765, running_loss=0.4624, LR=0.000100
[2025-08-11 00:10:46,641][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085596] [Batch 00680/03692] [00:06:02/00:26:45, 0.533s/it]: train_loss_raw=0.3741, running_loss=0.4615, LR=0.000100
[2025-08-11 00:10:53,142][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085608] [Batch 00692/03692] [00:06:08/00:26:39, 0.533s/it]: train_loss_raw=0.3992, running_loss=0.4593, LR=0.000100
[2025-08-11 00:10:59,645][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085620] [Batch 00704/03692] [00:06:15/00:26:33, 0.533s/it]: train_loss_raw=0.4130, running_loss=0.4577, LR=0.000100
[2025-08-11 00:11:06,177][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085632] [Batch 00716/03692] [00:06:21/00:26:27, 0.533s/it]: train_loss_raw=0.5869, running_loss=0.4597, LR=0.000100
[2025-08-11 00:11:12,735][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085644] [Batch 00728/03692] [00:06:28/00:26:21, 0.534s/it]: train_loss_raw=0.4041, running_loss=0.4555, LR=0.000100
[2025-08-11 00:11:19,286][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085656] [Batch 00740/03692] [00:06:35/00:26:16, 0.534s/it]: train_loss_raw=0.4567, running_loss=0.4575, LR=0.000100
[2025-08-11 00:11:25,813][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085668] [Batch 00752/03692] [00:06:41/00:26:10, 0.534s/it]: train_loss_raw=0.4847, running_loss=0.4567, LR=0.000100
[2025-08-11 00:11:32,263][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085680] [Batch 00764/03692] [00:06:48/00:26:03, 0.534s/it]: train_loss_raw=0.4625, running_loss=0.4578, LR=0.000100
[2025-08-11 00:11:38,465][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085692] [Batch 00776/03692] [00:06:54/00:25:56, 0.534s/it]: train_loss_raw=0.4512, running_loss=0.4599, LR=0.000100
[2025-08-11 00:11:44,963][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085704] [Batch 00788/03692] [00:07:00/00:25:50, 0.534s/it]: train_loss_raw=0.5225, running_loss=0.4569, LR=0.000100
[2025-08-11 00:11:51,525][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085716] [Batch 00800/03692] [00:07:07/00:25:44, 0.534s/it]: train_loss_raw=0.4335, running_loss=0.4551, LR=0.000100
[2025-08-11 00:11:58,051][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085728] [Batch 00812/03692] [00:07:13/00:25:38, 0.534s/it]: train_loss_raw=0.4151, running_loss=0.4543, LR=0.000100
[2025-08-11 00:12:04,555][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085740] [Batch 00824/03692] [00:07:20/00:25:32, 0.534s/it]: train_loss_raw=0.4252, running_loss=0.4557, LR=0.000100
[2025-08-11 00:12:10,962][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085752] [Batch 00836/03692] [00:07:26/00:25:26, 0.534s/it]: train_loss_raw=0.3839, running_loss=0.4535, LR=0.000100
[2025-08-11 00:12:17,372][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085764] [Batch 00848/03692] [00:07:33/00:25:19, 0.534s/it]: train_loss_raw=0.5136, running_loss=0.4560, LR=0.000100
[2025-08-11 00:12:23,800][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085776] [Batch 00860/03692] [00:07:39/00:25:13, 0.534s/it]: train_loss_raw=0.4743, running_loss=0.4551, LR=0.000100
[2025-08-11 00:12:30,218][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085788] [Batch 00872/03692] [00:07:46/00:25:07, 0.534s/it]: train_loss_raw=0.4804, running_loss=0.4544, LR=0.000100
[2025-08-11 00:12:36,605][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085800] [Batch 00884/03692] [00:07:52/00:25:00, 0.534s/it]: train_loss_raw=0.4217, running_loss=0.4552, LR=0.000100
[2025-08-11 00:12:42,813][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085812] [Batch 00896/03692] [00:07:58/00:24:53, 0.534s/it]: train_loss_raw=0.4260, running_loss=0.4537, LR=0.000100
[2025-08-11 00:12:49,054][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085824] [Batch 00908/03692] [00:08:04/00:24:46, 0.534s/it]: train_loss_raw=0.5375, running_loss=0.4540, LR=0.000100
[2025-08-11 00:12:55,454][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085836] [Batch 00920/03692] [00:08:11/00:24:40, 0.534s/it]: train_loss_raw=0.4989, running_loss=0.4528, LR=0.000100
[2025-08-11 00:13:01,891][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085848] [Batch 00932/03692] [00:08:17/00:24:33, 0.534s/it]: train_loss_raw=0.4234, running_loss=0.4547, LR=0.000100
[2025-08-11 00:13:08,332][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085860] [Batch 00944/03692] [00:08:24/00:24:27, 0.534s/it]: train_loss_raw=0.5145, running_loss=0.4542, LR=0.000100
[2025-08-11 00:13:14,872][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085872] [Batch 00956/03692] [00:08:30/00:24:21, 0.534s/it]: train_loss_raw=0.4714, running_loss=0.4531, LR=0.000100
[2025-08-11 00:13:21,322][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085884] [Batch 00968/03692] [00:08:37/00:24:15, 0.534s/it]: train_loss_raw=0.4660, running_loss=0.4538, LR=0.000100
[2025-08-11 00:13:27,716][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085896] [Batch 00980/03692] [00:08:43/00:24:08, 0.534s/it]: train_loss_raw=0.4277, running_loss=0.4556, LR=0.000100
[2025-08-11 00:13:34,152][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085908] [Batch 00992/03692] [00:08:49/00:24:02, 0.534s/it]: train_loss_raw=0.4909, running_loss=0.4582, LR=0.000100
[2025-08-11 00:13:40,722][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085920] [Batch 01004/03692] [00:08:56/00:23:56, 0.534s/it]: train_loss_raw=0.4828, running_loss=0.4581, LR=0.000100
[2025-08-11 00:13:47,110][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085932] [Batch 01016/03692] [00:09:02/00:23:49, 0.534s/it]: train_loss_raw=0.4711, running_loss=0.4590, LR=0.000100
[2025-08-11 00:13:53,603][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085944] [Batch 01028/03692] [00:09:09/00:23:43, 0.534s/it]: train_loss_raw=0.3815, running_loss=0.4613, LR=0.000100
[2025-08-11 00:14:00,199][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085956] [Batch 01040/03692] [00:09:15/00:23:37, 0.535s/it]: train_loss_raw=0.4397, running_loss=0.4608, LR=0.000100
[2025-08-11 00:14:06,617][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085968] [Batch 01052/03692] [00:09:22/00:23:31, 0.535s/it]: train_loss_raw=0.4212, running_loss=0.4616, LR=0.000100
[2025-08-11 00:14:13,094][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085980] [Batch 01064/03692] [00:09:28/00:23:25, 0.535s/it]: train_loss_raw=0.4122, running_loss=0.4617, LR=0.000100
[2025-08-11 00:14:19,448][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 085992] [Batch 01076/03692] [00:09:35/00:23:18, 0.535s/it]: train_loss_raw=0.4781, running_loss=0.4632, LR=0.000100
[2025-08-11 00:14:30,645][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086004] [Batch 01088/03692] [00:09:46/00:23:23, 0.539s/it]: train_loss_raw=0.4691, running_loss=0.4642, LR=0.000100
[2025-08-11 00:14:36,793][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086016] [Batch 01100/03692] [00:09:52/00:23:16, 0.539s/it]: train_loss_raw=0.4046, running_loss=0.4619, LR=0.000100
[2025-08-11 00:14:43,308][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086028] [Batch 01112/03692] [00:09:59/00:23:09, 0.539s/it]: train_loss_raw=0.5127, running_loss=0.4612, LR=0.000100
[2025-08-11 00:14:49,815][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086040] [Batch 01124/03692] [00:10:05/00:23:03, 0.539s/it]: train_loss_raw=0.4495, running_loss=0.4606, LR=0.000100
[2025-08-11 00:14:56,408][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086052] [Batch 01136/03692] [00:10:12/00:22:57, 0.539s/it]: train_loss_raw=0.5161, running_loss=0.4618, LR=0.000100
[2025-08-11 00:15:02,971][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086064] [Batch 01148/03692] [00:10:18/00:22:51, 0.539s/it]: train_loss_raw=0.4490, running_loss=0.4618, LR=0.000100
[2025-08-11 00:15:09,448][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086076] [Batch 01160/03692] [00:10:25/00:22:44, 0.539s/it]: train_loss_raw=0.4483, running_loss=0.4599, LR=0.000100
[2025-08-11 00:15:15,807][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086088] [Batch 01172/03692] [00:10:31/00:22:38, 0.539s/it]: train_loss_raw=0.4999, running_loss=0.4619, LR=0.000100
[2025-08-11 00:15:22,301][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086100] [Batch 01184/03692] [00:10:38/00:22:31, 0.539s/it]: train_loss_raw=0.4726, running_loss=0.4632, LR=0.000100
[2025-08-11 00:15:28,591][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086112] [Batch 01196/03692] [00:10:44/00:22:24, 0.539s/it]: train_loss_raw=0.4755, running_loss=0.4649, LR=0.000100
[2025-08-11 00:15:35,074][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086124] [Batch 01208/03692] [00:10:50/00:22:18, 0.539s/it]: train_loss_raw=0.4753, running_loss=0.4652, LR=0.000100
[2025-08-11 00:15:41,577][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086136] [Batch 01220/03692] [00:10:57/00:22:11, 0.539s/it]: train_loss_raw=0.5650, running_loss=0.4640, LR=0.000100
[2025-08-11 00:15:48,026][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086148] [Batch 01232/03692] [00:11:03/00:22:05, 0.539s/it]: train_loss_raw=0.4718, running_loss=0.4644, LR=0.000100
[2025-08-11 00:15:54,430][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086160] [Batch 01244/03692] [00:11:10/00:21:58, 0.539s/it]: train_loss_raw=0.3821, running_loss=0.4620, LR=0.000100
[2025-08-11 00:16:00,737][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086172] [Batch 01256/03692] [00:11:16/00:21:52, 0.539s/it]: train_loss_raw=0.5189, running_loss=0.4634, LR=0.000100
[2025-08-11 00:16:07,090][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086184] [Batch 01268/03692] [00:11:22/00:21:45, 0.539s/it]: train_loss_raw=0.4663, running_loss=0.4647, LR=0.000100
[2025-08-11 00:16:13,498][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086196] [Batch 01280/03692] [00:11:29/00:21:38, 0.539s/it]: train_loss_raw=0.5197, running_loss=0.4630, LR=0.000100
[2025-08-11 00:16:19,869][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086208] [Batch 01292/03692] [00:11:35/00:21:32, 0.538s/it]: train_loss_raw=0.4371, running_loss=0.4609, LR=0.000100
[2025-08-11 00:16:26,186][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086220] [Batch 01304/03692] [00:11:41/00:21:25, 0.538s/it]: train_loss_raw=0.4740, running_loss=0.4585, LR=0.000100
[2025-08-11 00:16:32,535][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086232] [Batch 01316/03692] [00:11:48/00:21:18, 0.538s/it]: train_loss_raw=0.4301, running_loss=0.4589, LR=0.000100
[2025-08-11 00:16:38,947][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086244] [Batch 01328/03692] [00:11:54/00:21:12, 0.538s/it]: train_loss_raw=0.4140, running_loss=0.4586, LR=0.000100
[2025-08-11 00:16:45,389][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086256] [Batch 01340/03692] [00:12:01/00:21:05, 0.538s/it]: train_loss_raw=0.3804, running_loss=0.4559, LR=0.000100
[2025-08-11 00:16:51,968][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086268] [Batch 01352/03692] [00:12:07/00:20:59, 0.538s/it]: train_loss_raw=0.4239, running_loss=0.4526, LR=0.000100
[2025-08-11 00:16:58,425][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086280] [Batch 01364/03692] [00:12:14/00:20:53, 0.538s/it]: train_loss_raw=0.5914, running_loss=0.4569, LR=0.000100
[2025-08-11 00:17:04,764][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086292] [Batch 01376/03692] [00:12:20/00:20:46, 0.538s/it]: train_loss_raw=0.4264, running_loss=0.4543, LR=0.000100
[2025-08-11 00:17:11,069][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086304] [Batch 01388/03692] [00:12:26/00:20:39, 0.538s/it]: train_loss_raw=0.4429, running_loss=0.4547, LR=0.000100
[2025-08-11 00:17:17,430][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086316] [Batch 01400/03692] [00:12:33/00:20:33, 0.538s/it]: train_loss_raw=0.5137, running_loss=0.4569, LR=0.000100
[2025-08-11 00:17:23,933][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086328] [Batch 01412/03692] [00:12:39/00:20:26, 0.538s/it]: train_loss_raw=0.4498, running_loss=0.4577, LR=0.000100
[2025-08-11 00:17:30,312][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086340] [Batch 01424/03692] [00:12:46/00:20:20, 0.538s/it]: train_loss_raw=0.5150, running_loss=0.4559, LR=0.000100
[2025-08-11 00:17:36,716][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086352] [Batch 01436/03692] [00:12:52/00:20:13, 0.538s/it]: train_loss_raw=0.4676, running_loss=0.4544, LR=0.000100
[2025-08-11 00:17:43,157][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086364] [Batch 01448/03692] [00:12:58/00:20:07, 0.538s/it]: train_loss_raw=0.3441, running_loss=0.4534, LR=0.000100
[2025-08-11 00:17:49,649][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086376] [Batch 01460/03692] [00:13:05/00:20:00, 0.538s/it]: train_loss_raw=0.4551, running_loss=0.4557, LR=0.000100
[2025-08-11 00:17:56,012][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086388] [Batch 01472/03692] [00:13:11/00:19:54, 0.538s/it]: train_loss_raw=0.5082, running_loss=0.4585, LR=0.000100
[2025-08-11 00:18:02,405][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086400] [Batch 01484/03692] [00:13:18/00:19:47, 0.538s/it]: train_loss_raw=0.4689, running_loss=0.4553, LR=0.000100
[2025-08-11 00:18:08,864][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086412] [Batch 01496/03692] [00:13:24/00:19:41, 0.538s/it]: train_loss_raw=0.4661, running_loss=0.4595, LR=0.000100
[2025-08-11 00:18:15,145][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086424] [Batch 01508/03692] [00:13:30/00:19:34, 0.538s/it]: train_loss_raw=0.4134, running_loss=0.4586, LR=0.000100
[2025-08-11 00:18:21,245][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086436] [Batch 01520/03692] [00:13:37/00:19:27, 0.538s/it]: train_loss_raw=0.4069, running_loss=0.4583, LR=0.000100
[2025-08-11 00:18:27,749][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086448] [Batch 01532/03692] [00:13:43/00:19:21, 0.538s/it]: train_loss_raw=0.4032, running_loss=0.4569, LR=0.000100
[2025-08-11 00:18:34,260][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086460] [Batch 01544/03692] [00:13:50/00:19:14, 0.538s/it]: train_loss_raw=0.4754, running_loss=0.4627, LR=0.000100
[2025-08-11 00:18:40,767][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086472] [Batch 01556/03692] [00:13:56/00:19:08, 0.538s/it]: train_loss_raw=0.5213, running_loss=0.4636, LR=0.000100
[2025-08-11 00:18:47,082][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086484] [Batch 01568/03692] [00:14:02/00:19:01, 0.538s/it]: train_loss_raw=0.5694, running_loss=0.4641, LR=0.000100
[2025-08-11 00:18:53,178][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086496] [Batch 01580/03692] [00:14:08/00:18:54, 0.537s/it]: train_loss_raw=0.5102, running_loss=0.4603, LR=0.000100
[2025-08-11 00:18:59,447][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086508] [Batch 01592/03692] [00:14:15/00:18:48, 0.537s/it]: train_loss_raw=0.4172, running_loss=0.4541, LR=0.000100
[2025-08-11 00:19:05,798][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086520] [Batch 01604/03692] [00:14:21/00:18:41, 0.537s/it]: train_loss_raw=0.4888, running_loss=0.4549, LR=0.000100
[2025-08-11 00:19:11,893][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086532] [Batch 01616/03692] [00:14:27/00:18:34, 0.537s/it]: train_loss_raw=0.4606, running_loss=0.4541, LR=0.000100
[2025-08-11 00:19:18,000][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086544] [Batch 01628/03692] [00:14:33/00:18:27, 0.537s/it]: train_loss_raw=0.3592, running_loss=0.4555, LR=0.000100
[2025-08-11 00:19:24,137][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086556] [Batch 01640/03692] [00:14:39/00:18:20, 0.537s/it]: train_loss_raw=0.5043, running_loss=0.4550, LR=0.000100
[2025-08-11 00:19:30,356][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086568] [Batch 01652/03692] [00:14:46/00:18:14, 0.536s/it]: train_loss_raw=0.4061, running_loss=0.4560, LR=0.000100
[2025-08-11 00:19:36,525][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086580] [Batch 01664/03692] [00:14:52/00:18:07, 0.536s/it]: train_loss_raw=0.4291, running_loss=0.4550, LR=0.000100
[2025-08-11 00:19:42,849][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086592] [Batch 01676/03692] [00:14:58/00:18:00, 0.536s/it]: train_loss_raw=0.4421, running_loss=0.4569, LR=0.000100
[2025-08-11 00:19:49,215][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086604] [Batch 01688/03692] [00:15:05/00:17:54, 0.536s/it]: train_loss_raw=0.4540, running_loss=0.4588, LR=0.000100
[2025-08-11 00:19:55,298][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086616] [Batch 01700/03692] [00:15:11/00:17:47, 0.536s/it]: train_loss_raw=0.5303, running_loss=0.4592, LR=0.000100
[2025-08-11 00:20:01,360][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086628] [Batch 01712/03692] [00:15:17/00:17:40, 0.536s/it]: train_loss_raw=0.4614, running_loss=0.4582, LR=0.000100
[2025-08-11 00:20:07,372][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086640] [Batch 01724/03692] [00:15:23/00:17:33, 0.535s/it]: train_loss_raw=0.5413, running_loss=0.4554, LR=0.000100
[2025-08-11 00:20:13,923][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086652] [Batch 01736/03692] [00:15:29/00:17:27, 0.536s/it]: train_loss_raw=0.4835, running_loss=0.4537, LR=0.000100
[2025-08-11 00:20:20,432][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086664] [Batch 01748/03692] [00:15:36/00:17:21, 0.536s/it]: train_loss_raw=0.4354, running_loss=0.4556, LR=0.000100
[2025-08-11 00:20:26,630][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086676] [Batch 01760/03692] [00:15:42/00:17:14, 0.535s/it]: train_loss_raw=0.5272, running_loss=0.4557, LR=0.000100
[2025-08-11 00:20:32,806][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086688] [Batch 01772/03692] [00:15:48/00:17:07, 0.535s/it]: train_loss_raw=0.4711, running_loss=0.4592, LR=0.000100
[2025-08-11 00:20:38,973][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086700] [Batch 01784/03692] [00:15:54/00:17:01, 0.535s/it]: train_loss_raw=0.4527, running_loss=0.4573, LR=0.000100
[2025-08-11 00:20:45,190][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086712] [Batch 01796/03692] [00:16:00/00:16:54, 0.535s/it]: train_loss_raw=0.5160, running_loss=0.4561, LR=0.000100
[2025-08-11 00:20:51,391][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086724] [Batch 01808/03692] [00:16:07/00:16:47, 0.535s/it]: train_loss_raw=0.3793, running_loss=0.4581, LR=0.000100
[2025-08-11 00:20:57,508][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086736] [Batch 01820/03692] [00:16:13/00:16:41, 0.535s/it]: train_loss_raw=0.4150, running_loss=0.4562, LR=0.000100
[2025-08-11 00:21:03,596][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086748] [Batch 01832/03692] [00:16:19/00:16:34, 0.535s/it]: train_loss_raw=0.4203, running_loss=0.4554, LR=0.000100
[2025-08-11 00:21:09,839][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086760] [Batch 01844/03692] [00:16:25/00:16:27, 0.535s/it]: train_loss_raw=0.5191, running_loss=0.4561, LR=0.000100
[2025-08-11 00:21:16,254][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086772] [Batch 01856/03692] [00:16:32/00:16:21, 0.535s/it]: train_loss_raw=0.4895, running_loss=0.4551, LR=0.000100
[2025-08-11 00:21:22,585][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086784] [Batch 01868/03692] [00:16:38/00:16:14, 0.534s/it]: train_loss_raw=0.5010, running_loss=0.4563, LR=0.000100
[2025-08-11 00:21:28,740][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086796] [Batch 01880/03692] [00:16:44/00:16:08, 0.534s/it]: train_loss_raw=0.4090, running_loss=0.4557, LR=0.000100
[2025-08-11 00:21:35,073][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086808] [Batch 01892/03692] [00:16:50/00:16:01, 0.534s/it]: train_loss_raw=0.4968, running_loss=0.4534, LR=0.000100
[2025-08-11 00:21:41,477][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086820] [Batch 01904/03692] [00:16:57/00:15:55, 0.534s/it]: train_loss_raw=0.4918, running_loss=0.4551, LR=0.000100
[2025-08-11 00:21:47,905][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086832] [Batch 01916/03692] [00:17:03/00:15:48, 0.534s/it]: train_loss_raw=0.4304, running_loss=0.4538, LR=0.000100
[2025-08-11 00:21:54,360][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086844] [Batch 01928/03692] [00:17:10/00:15:42, 0.534s/it]: train_loss_raw=0.4292, running_loss=0.4567, LR=0.000100
[2025-08-11 00:22:00,776][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086856] [Batch 01940/03692] [00:17:16/00:15:36, 0.534s/it]: train_loss_raw=0.4088, running_loss=0.4540, LR=0.000100
[2025-08-11 00:22:07,176][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086868] [Batch 01952/03692] [00:17:22/00:15:29, 0.534s/it]: train_loss_raw=0.5040, running_loss=0.4554, LR=0.000100
[2025-08-11 00:22:13,480][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086880] [Batch 01964/03692] [00:17:29/00:15:23, 0.534s/it]: train_loss_raw=0.3598, running_loss=0.4534, LR=0.000100
[2025-08-11 00:22:19,737][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086892] [Batch 01976/03692] [00:17:35/00:15:16, 0.534s/it]: train_loss_raw=0.3849, running_loss=0.4548, LR=0.000100
[2025-08-11 00:22:26,136][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086904] [Batch 01988/03692] [00:17:41/00:15:10, 0.534s/it]: train_loss_raw=0.5491, running_loss=0.4557, LR=0.000100
[2025-08-11 00:22:32,813][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086916] [Batch 02000/03692] [00:17:48/00:15:04, 0.534s/it]: train_loss_raw=0.5174, running_loss=0.4571, LR=0.000100
[2025-08-11 00:22:39,090][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086928] [Batch 02012/03692] [00:17:54/00:14:57, 0.534s/it]: train_loss_raw=0.4603, running_loss=0.4562, LR=0.000100
[2025-08-11 00:22:45,547][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086940] [Batch 02024/03692] [00:18:01/00:14:51, 0.534s/it]: train_loss_raw=0.4526, running_loss=0.4533, LR=0.000100
[2025-08-11 00:22:52,011][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086952] [Batch 02036/03692] [00:18:07/00:14:44, 0.534s/it]: train_loss_raw=0.4665, running_loss=0.4555, LR=0.000100
[2025-08-11 00:22:58,356][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086964] [Batch 02048/03692] [00:18:14/00:14:38, 0.534s/it]: train_loss_raw=0.3566, running_loss=0.4544, LR=0.000100
[2025-08-11 00:23:04,872][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086976] [Batch 02060/03692] [00:18:20/00:14:31, 0.534s/it]: train_loss_raw=0.5331, running_loss=0.4557, LR=0.000100
[2025-08-11 00:23:11,204][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 086988] [Batch 02072/03692] [00:18:26/00:14:25, 0.534s/it]: train_loss_raw=0.3686, running_loss=0.4527, LR=0.000100
[2025-08-11 00:23:17,430][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087000] [Batch 02084/03692] [00:18:33/00:14:18, 0.534s/it]: train_loss_raw=0.4277, running_loss=0.4501, LR=0.000100
[2025-08-11 00:23:23,956][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087012] [Batch 02096/03692] [00:18:39/00:14:12, 0.534s/it]: train_loss_raw=0.4167, running_loss=0.4515, LR=0.000100
[2025-08-11 00:23:30,394][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087024] [Batch 02108/03692] [00:18:46/00:14:06, 0.534s/it]: train_loss_raw=0.4334, running_loss=0.4498, LR=0.000100
[2025-08-11 00:23:36,890][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087036] [Batch 02120/03692] [00:18:52/00:13:59, 0.534s/it]: train_loss_raw=0.4888, running_loss=0.4529, LR=0.000100
[2025-08-11 00:23:43,451][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087048] [Batch 02132/03692] [00:18:59/00:13:53, 0.534s/it]: train_loss_raw=0.5460, running_loss=0.4522, LR=0.000100
[2025-08-11 00:23:49,899][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087060] [Batch 02144/03692] [00:19:05/00:13:47, 0.534s/it]: train_loss_raw=0.5766, running_loss=0.4516, LR=0.000100
[2025-08-11 00:23:56,201][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087072] [Batch 02156/03692] [00:19:11/00:13:40, 0.534s/it]: train_loss_raw=0.4264, running_loss=0.4510, LR=0.000100
[2025-08-11 00:24:02,732][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087084] [Batch 02168/03692] [00:19:18/00:13:34, 0.534s/it]: train_loss_raw=0.3460, running_loss=0.4507, LR=0.000100
[2025-08-11 00:24:09,392][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087096] [Batch 02180/03692] [00:19:25/00:13:28, 0.534s/it]: train_loss_raw=0.3900, running_loss=0.4468, LR=0.000100
[2025-08-11 00:24:15,755][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087108] [Batch 02192/03692] [00:19:31/00:13:21, 0.534s/it]: train_loss_raw=0.5455, running_loss=0.4501, LR=0.000100
[2025-08-11 00:24:21,848][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087120] [Batch 02204/03692] [00:19:37/00:13:15, 0.534s/it]: train_loss_raw=0.4094, running_loss=0.4497, LR=0.000100
[2025-08-11 00:24:27,843][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087132] [Batch 02216/03692] [00:19:43/00:13:08, 0.534s/it]: train_loss_raw=0.4479, running_loss=0.4524, LR=0.000100
[2025-08-11 00:24:34,364][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087144] [Batch 02228/03692] [00:19:50/00:13:02, 0.534s/it]: train_loss_raw=0.4956, running_loss=0.4548, LR=0.000100
[2025-08-11 00:24:40,851][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087156] [Batch 02240/03692] [00:19:56/00:12:55, 0.534s/it]: train_loss_raw=0.4952, running_loss=0.4543, LR=0.000100
[2025-08-11 00:24:47,100][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087168] [Batch 02252/03692] [00:20:02/00:12:49, 0.534s/it]: train_loss_raw=0.4177, running_loss=0.4509, LR=0.000100
[2025-08-11 00:24:53,141][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087180] [Batch 02264/03692] [00:20:08/00:12:42, 0.534s/it]: train_loss_raw=0.5298, running_loss=0.4500, LR=0.000100
[2025-08-11 00:24:59,216][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087192] [Batch 02276/03692] [00:20:15/00:12:35, 0.534s/it]: train_loss_raw=0.4681, running_loss=0.4474, LR=0.000100
[2025-08-11 00:25:05,237][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087204] [Batch 02288/03692] [00:20:21/00:12:29, 0.534s/it]: train_loss_raw=0.3857, running_loss=0.4465, LR=0.000100
[2025-08-11 00:25:11,237][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087216] [Batch 02300/03692] [00:20:27/00:12:22, 0.533s/it]: train_loss_raw=0.3921, running_loss=0.4470, LR=0.000100
[2025-08-11 00:25:17,298][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087228] [Batch 02312/03692] [00:20:33/00:12:16, 0.533s/it]: train_loss_raw=0.4164, running_loss=0.4467, LR=0.000100
[2025-08-11 00:25:23,512][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087240] [Batch 02324/03692] [00:20:39/00:12:09, 0.533s/it]: train_loss_raw=0.4287, running_loss=0.4465, LR=0.000100
[2025-08-11 00:25:29,662][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087252] [Batch 02336/03692] [00:20:45/00:12:02, 0.533s/it]: train_loss_raw=0.4171, running_loss=0.4458, LR=0.000100
[2025-08-11 00:25:35,979][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087264] [Batch 02348/03692] [00:20:51/00:11:56, 0.533s/it]: train_loss_raw=0.4564, running_loss=0.4481, LR=0.000100
[2025-08-11 00:25:42,523][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087276] [Batch 02360/03692] [00:20:58/00:11:50, 0.533s/it]: train_loss_raw=0.4074, running_loss=0.4468, LR=0.000100
[2025-08-11 00:25:48,769][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087288] [Batch 02372/03692] [00:21:04/00:11:43, 0.533s/it]: train_loss_raw=0.3826, running_loss=0.4487, LR=0.000100
[2025-08-11 00:25:54,871][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087300] [Batch 02384/03692] [00:21:10/00:11:37, 0.533s/it]: train_loss_raw=0.4799, running_loss=0.4465, LR=0.000100
[2025-08-11 00:26:01,022][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087312] [Batch 02396/03692] [00:21:16/00:11:30, 0.533s/it]: train_loss_raw=0.4046, running_loss=0.4462, LR=0.000100
[2025-08-11 00:26:07,232][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087324] [Batch 02408/03692] [00:21:23/00:11:24, 0.533s/it]: train_loss_raw=0.4464, running_loss=0.4495, LR=0.000100
[2025-08-11 00:26:13,533][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087336] [Batch 02420/03692] [00:21:29/00:11:17, 0.533s/it]: train_loss_raw=0.5042, running_loss=0.4517, LR=0.000100
[2025-08-11 00:26:19,926][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087348] [Batch 02432/03692] [00:21:35/00:11:11, 0.533s/it]: train_loss_raw=0.3647, running_loss=0.4500, LR=0.000100
[2025-08-11 00:26:26,494][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087360] [Batch 02444/03692] [00:21:42/00:11:04, 0.533s/it]: train_loss_raw=0.4411, running_loss=0.4501, LR=0.000100
[2025-08-11 00:26:33,062][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087372] [Batch 02456/03692] [00:21:48/00:10:58, 0.533s/it]: train_loss_raw=0.4620, running_loss=0.4513, LR=0.000100
[2025-08-11 00:26:39,661][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087384] [Batch 02468/03692] [00:21:55/00:10:52, 0.533s/it]: train_loss_raw=0.5247, running_loss=0.4531, LR=0.000100
[2025-08-11 00:26:46,099][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087396] [Batch 02480/03692] [00:22:01/00:10:46, 0.533s/it]: train_loss_raw=0.4812, running_loss=0.4496, LR=0.000100
[2025-08-11 00:26:52,618][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087408] [Batch 02492/03692] [00:22:08/00:10:39, 0.533s/it]: train_loss_raw=0.5187, running_loss=0.4536, LR=0.000100
[2025-08-11 00:26:59,131][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087420] [Batch 02504/03692] [00:22:14/00:10:33, 0.533s/it]: train_loss_raw=0.4444, running_loss=0.4532, LR=0.000100
[2025-08-11 00:27:05,573][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087432] [Batch 02516/03692] [00:22:21/00:10:26, 0.533s/it]: train_loss_raw=0.4732, running_loss=0.4556, LR=0.000100
[2025-08-11 00:27:11,980][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087444] [Batch 02528/03692] [00:22:27/00:10:20, 0.533s/it]: train_loss_raw=0.4570, running_loss=0.4551, LR=0.000100
[2025-08-11 00:27:18,396][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087456] [Batch 02540/03692] [00:22:34/00:10:14, 0.533s/it]: train_loss_raw=0.5268, running_loss=0.4544, LR=0.000100
[2025-08-11 00:27:24,766][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087468] [Batch 02552/03692] [00:22:40/00:10:07, 0.533s/it]: train_loss_raw=0.3853, running_loss=0.4549, LR=0.000100
[2025-08-11 00:27:30,888][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087480] [Batch 02564/03692] [00:22:46/00:10:01, 0.533s/it]: train_loss_raw=0.4435, running_loss=0.4521, LR=0.000100
[2025-08-11 00:27:37,035][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087492] [Batch 02576/03692] [00:22:52/00:09:54, 0.533s/it]: train_loss_raw=0.3741, running_loss=0.4506, LR=0.000100
[2025-08-11 00:27:43,207][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087504] [Batch 02588/03692] [00:22:58/00:09:48, 0.533s/it]: train_loss_raw=0.4595, running_loss=0.4528, LR=0.000100
[2025-08-11 00:27:49,542][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087516] [Batch 02600/03692] [00:23:05/00:09:41, 0.533s/it]: train_loss_raw=0.4731, running_loss=0.4531, LR=0.000100
[2025-08-11 00:27:55,586][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087528] [Batch 02612/03692] [00:23:11/00:09:35, 0.533s/it]: train_loss_raw=0.3433, running_loss=0.4553, LR=0.000100
[2025-08-11 00:28:01,978][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087540] [Batch 02624/03692] [00:23:17/00:09:28, 0.533s/it]: train_loss_raw=0.4656, running_loss=0.4565, LR=0.000100
[2025-08-11 00:28:08,198][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087552] [Batch 02636/03692] [00:23:23/00:09:22, 0.533s/it]: train_loss_raw=0.5123, running_loss=0.4591, LR=0.000100
[2025-08-11 00:28:14,677][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087564] [Batch 02648/03692] [00:23:30/00:09:16, 0.533s/it]: train_loss_raw=0.3538, running_loss=0.4612, LR=0.000100
[2025-08-11 00:28:21,074][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087576] [Batch 02660/03692] [00:23:36/00:09:09, 0.533s/it]: train_loss_raw=0.4127, running_loss=0.4568, LR=0.000100
[2025-08-11 00:28:27,589][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087588] [Batch 02672/03692] [00:23:43/00:09:03, 0.533s/it]: train_loss_raw=0.4411, running_loss=0.4544, LR=0.000100
[2025-08-11 00:28:34,152][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087600] [Batch 02684/03692] [00:23:49/00:08:57, 0.533s/it]: train_loss_raw=0.4631, running_loss=0.4533, LR=0.000100
[2025-08-11 00:28:40,784][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087612] [Batch 02696/03692] [00:23:56/00:08:50, 0.533s/it]: train_loss_raw=0.5489, running_loss=0.4535, LR=0.000100
[2025-08-11 00:28:47,111][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087624] [Batch 02708/03692] [00:24:02/00:08:44, 0.533s/it]: train_loss_raw=0.4051, running_loss=0.4520, LR=0.000100
[2025-08-11 00:28:53,234][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087636] [Batch 02720/03692] [00:24:09/00:08:37, 0.533s/it]: train_loss_raw=0.4447, running_loss=0.4503, LR=0.000100
[2025-08-11 00:28:59,441][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087648] [Batch 02732/03692] [00:24:15/00:08:31, 0.533s/it]: train_loss_raw=0.5002, running_loss=0.4499, LR=0.000100
[2025-08-11 00:29:05,628][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087660] [Batch 02744/03692] [00:24:21/00:08:24, 0.533s/it]: train_loss_raw=0.4927, running_loss=0.4492, LR=0.000100
[2025-08-11 00:29:11,761][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087672] [Batch 02756/03692] [00:24:27/00:08:18, 0.532s/it]: train_loss_raw=0.5191, running_loss=0.4526, LR=0.000100
[2025-08-11 00:29:17,968][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087684] [Batch 02768/03692] [00:24:33/00:08:11, 0.532s/it]: train_loss_raw=0.4747, running_loss=0.4509, LR=0.000100
[2025-08-11 00:29:24,368][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087696] [Batch 02780/03692] [00:24:40/00:08:05, 0.532s/it]: train_loss_raw=0.5086, running_loss=0.4515, LR=0.000100
[2025-08-11 00:29:30,795][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087708] [Batch 02792/03692] [00:24:46/00:07:59, 0.532s/it]: train_loss_raw=0.4872, running_loss=0.4525, LR=0.000100
[2025-08-11 00:29:37,212][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087720] [Batch 02804/03692] [00:24:53/00:07:52, 0.532s/it]: train_loss_raw=0.3792, running_loss=0.4530, LR=0.000100
[2025-08-11 00:29:43,618][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087732] [Batch 02816/03692] [00:24:59/00:07:46, 0.532s/it]: train_loss_raw=0.4583, running_loss=0.4512, LR=0.000100
[2025-08-11 00:29:49,742][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087744] [Batch 02828/03692] [00:25:05/00:07:39, 0.532s/it]: train_loss_raw=0.4867, running_loss=0.4510, LR=0.000100
[2025-08-11 00:29:55,974][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087756] [Batch 02840/03692] [00:25:11/00:07:33, 0.532s/it]: train_loss_raw=0.3819, running_loss=0.4522, LR=0.000100
[2025-08-11 00:30:02,289][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087768] [Batch 02852/03692] [00:25:18/00:07:27, 0.532s/it]: train_loss_raw=0.4979, running_loss=0.4534, LR=0.000100
[2025-08-11 00:30:08,803][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087780] [Batch 02864/03692] [00:25:24/00:07:20, 0.532s/it]: train_loss_raw=0.4552, running_loss=0.4560, LR=0.000100
[2025-08-11 00:30:15,171][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087792] [Batch 02876/03692] [00:25:30/00:07:14, 0.532s/it]: train_loss_raw=0.4628, running_loss=0.4553, LR=0.000100
[2025-08-11 00:30:21,479][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087804] [Batch 02888/03692] [00:25:37/00:07:07, 0.532s/it]: train_loss_raw=0.3748, running_loss=0.4497, LR=0.000100
[2025-08-11 00:30:27,682][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087816] [Batch 02900/03692] [00:25:43/00:07:01, 0.532s/it]: train_loss_raw=0.4068, running_loss=0.4460, LR=0.000100
[2025-08-11 00:30:33,864][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087828] [Batch 02912/03692] [00:25:49/00:06:55, 0.532s/it]: train_loss_raw=0.3747, running_loss=0.4443, LR=0.000100
[2025-08-11 00:30:39,968][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087840] [Batch 02924/03692] [00:25:55/00:06:48, 0.532s/it]: train_loss_raw=0.2925, running_loss=0.4428, LR=0.000100
[2025-08-11 00:30:46,146][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087852] [Batch 02936/03692] [00:26:01/00:06:42, 0.532s/it]: train_loss_raw=0.5120, running_loss=0.4462, LR=0.000100
[2025-08-11 00:30:52,359][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087864] [Batch 02948/03692] [00:26:08/00:06:35, 0.532s/it]: train_loss_raw=0.4418, running_loss=0.4484, LR=0.000100
[2025-08-11 00:30:58,809][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087876] [Batch 02960/03692] [00:26:14/00:06:29, 0.532s/it]: train_loss_raw=0.3901, running_loss=0.4483, LR=0.000100
[2025-08-11 00:31:05,295][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087888] [Batch 02972/03692] [00:26:21/00:06:23, 0.532s/it]: train_loss_raw=0.4292, running_loss=0.4488, LR=0.000100
[2025-08-11 00:31:11,810][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087900] [Batch 02984/03692] [00:26:27/00:06:16, 0.532s/it]: train_loss_raw=0.4569, running_loss=0.4479, LR=0.000100
[2025-08-11 00:31:18,280][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087912] [Batch 02996/03692] [00:26:34/00:06:10, 0.532s/it]: train_loss_raw=0.4190, running_loss=0.4437, LR=0.000100
[2025-08-11 00:31:24,731][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087924] [Batch 03008/03692] [00:26:40/00:06:03, 0.532s/it]: train_loss_raw=0.3006, running_loss=0.4453, LR=0.000100
[2025-08-11 00:31:31,187][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087936] [Batch 03020/03692] [00:26:46/00:05:57, 0.532s/it]: train_loss_raw=0.4580, running_loss=0.4459, LR=0.000100
[2025-08-11 00:31:37,456][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087948] [Batch 03032/03692] [00:26:53/00:05:51, 0.532s/it]: train_loss_raw=0.4405, running_loss=0.4467, LR=0.000100
[2025-08-11 00:31:43,777][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087960] [Batch 03044/03692] [00:26:59/00:05:44, 0.532s/it]: train_loss_raw=0.3536, running_loss=0.4486, LR=0.000100
[2025-08-11 00:31:50,141][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087972] [Batch 03056/03692] [00:27:05/00:05:38, 0.532s/it]: train_loss_raw=0.4125, running_loss=0.4492, LR=0.000100
[2025-08-11 00:31:56,197][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087984] [Batch 03068/03692] [00:27:11/00:05:31, 0.532s/it]: train_loss_raw=0.4836, running_loss=0.4493, LR=0.000100
[2025-08-11 00:32:02,250][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 087996] [Batch 03080/03692] [00:27:18/00:05:25, 0.532s/it]: train_loss_raw=0.4929, running_loss=0.4518, LR=0.000100
[2025-08-11 00:32:12,971][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088008] [Batch 03092/03692] [00:27:28/00:05:19, 0.533s/it]: train_loss_raw=0.4852, running_loss=0.4538, LR=0.000100
[2025-08-11 00:32:19,023][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088020] [Batch 03104/03692] [00:27:34/00:05:13, 0.533s/it]: train_loss_raw=0.3693, running_loss=0.4545, LR=0.000100
[2025-08-11 00:32:25,039][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088032] [Batch 03116/03692] [00:27:40/00:05:07, 0.533s/it]: train_loss_raw=0.5977, running_loss=0.4551, LR=0.000100
[2025-08-11 00:32:31,088][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088044] [Batch 03128/03692] [00:27:46/00:05:00, 0.533s/it]: train_loss_raw=0.5051, running_loss=0.4537, LR=0.000100
[2025-08-11 00:32:37,617][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088056] [Batch 03140/03692] [00:27:53/00:04:54, 0.533s/it]: train_loss_raw=0.3689, running_loss=0.4517, LR=0.000100
[2025-08-11 00:32:43,836][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088068] [Batch 03152/03692] [00:27:59/00:04:47, 0.533s/it]: train_loss_raw=0.4563, running_loss=0.4492, LR=0.000100
[2025-08-11 00:32:49,918][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088080] [Batch 03164/03692] [00:28:05/00:04:41, 0.533s/it]: train_loss_raw=0.4120, running_loss=0.4514, LR=0.000100
[2025-08-11 00:32:55,997][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088092] [Batch 03176/03692] [00:28:11/00:04:34, 0.533s/it]: train_loss_raw=0.3932, running_loss=0.4532, LR=0.000100
[2025-08-11 00:33:01,921][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088104] [Batch 03188/03692] [00:28:17/00:04:28, 0.533s/it]: train_loss_raw=0.4916, running_loss=0.4507, LR=0.000100
[2025-08-11 00:33:07,985][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088116] [Batch 03200/03692] [00:28:23/00:04:21, 0.532s/it]: train_loss_raw=0.4602, running_loss=0.4535, LR=0.000100
[2025-08-11 00:33:14,214][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088128] [Batch 03212/03692] [00:28:30/00:04:15, 0.532s/it]: train_loss_raw=0.4833, running_loss=0.4532, LR=0.000100
[2025-08-11 00:33:20,352][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088140] [Batch 03224/03692] [00:28:36/00:04:09, 0.532s/it]: train_loss_raw=0.4457, running_loss=0.4499, LR=0.000100
[2025-08-11 00:33:26,444][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088152] [Batch 03236/03692] [00:28:42/00:04:02, 0.532s/it]: train_loss_raw=0.5052, running_loss=0.4507, LR=0.000100
[2025-08-11 00:33:32,529][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088164] [Batch 03248/03692] [00:28:48/00:03:56, 0.532s/it]: train_loss_raw=0.5092, running_loss=0.4513, LR=0.000100
[2025-08-11 00:33:38,751][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088176] [Batch 03260/03692] [00:28:54/00:03:49, 0.532s/it]: train_loss_raw=0.4510, running_loss=0.4495, LR=0.000100
[2025-08-11 00:33:44,971][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088188] [Batch 03272/03692] [00:29:00/00:03:43, 0.532s/it]: train_loss_raw=0.4429, running_loss=0.4516, LR=0.000100
[2025-08-11 00:33:51,147][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088200] [Batch 03284/03692] [00:29:06/00:03:37, 0.532s/it]: train_loss_raw=0.4563, running_loss=0.4521, LR=0.000100
[2025-08-11 00:33:57,398][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088212] [Batch 03296/03692] [00:29:13/00:03:30, 0.532s/it]: train_loss_raw=0.4714, running_loss=0.4512, LR=0.000100
[2025-08-11 00:34:03,647][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088224] [Batch 03308/03692] [00:29:19/00:03:24, 0.532s/it]: train_loss_raw=0.5109, running_loss=0.4502, LR=0.000100
[2025-08-11 00:34:09,868][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088236] [Batch 03320/03692] [00:29:25/00:03:17, 0.532s/it]: train_loss_raw=0.4395, running_loss=0.4474, LR=0.000100
[2025-08-11 00:34:15,877][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088248] [Batch 03332/03692] [00:29:31/00:03:11, 0.532s/it]: train_loss_raw=0.3708, running_loss=0.4469, LR=0.000100
[2025-08-11 00:34:21,873][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088260] [Batch 03344/03692] [00:29:37/00:03:04, 0.532s/it]: train_loss_raw=0.4074, running_loss=0.4453, LR=0.000100
[2025-08-11 00:34:27,890][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088272] [Batch 03356/03692] [00:29:43/00:02:58, 0.531s/it]: train_loss_raw=0.3899, running_loss=0.4431, LR=0.000100
[2025-08-11 00:34:34,120][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088284] [Batch 03368/03692] [00:29:49/00:02:52, 0.531s/it]: train_loss_raw=0.4339, running_loss=0.4428, LR=0.000100
[2025-08-11 00:34:40,519][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088296] [Batch 03380/03692] [00:29:56/00:02:45, 0.531s/it]: train_loss_raw=0.3937, running_loss=0.4424, LR=0.000100
[2025-08-11 00:34:46,996][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088308] [Batch 03392/03692] [00:30:02/00:02:39, 0.531s/it]: train_loss_raw=0.4502, running_loss=0.4444, LR=0.000100
[2025-08-11 00:34:53,123][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088320] [Batch 03404/03692] [00:30:08/00:02:33, 0.531s/it]: train_loss_raw=0.4087, running_loss=0.4444, LR=0.000100
[2025-08-11 00:34:59,146][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088332] [Batch 03416/03692] [00:30:14/00:02:26, 0.531s/it]: train_loss_raw=0.4530, running_loss=0.4439, LR=0.000100
[2025-08-11 00:35:05,286][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088344] [Batch 03428/03692] [00:30:21/00:02:20, 0.531s/it]: train_loss_raw=0.4999, running_loss=0.4464, LR=0.000100
[2025-08-11 00:35:11,317][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088356] [Batch 03440/03692] [00:30:27/00:02:13, 0.531s/it]: train_loss_raw=0.3993, running_loss=0.4415, LR=0.000100
[2025-08-11 00:35:17,338][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088368] [Batch 03452/03692] [00:30:33/00:02:07, 0.531s/it]: train_loss_raw=0.4613, running_loss=0.4397, LR=0.000100
[2025-08-11 00:35:23,422][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088380] [Batch 03464/03692] [00:30:39/00:02:01, 0.531s/it]: train_loss_raw=0.4279, running_loss=0.4428, LR=0.000100
[2025-08-11 00:35:29,402][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088392] [Batch 03476/03692] [00:30:45/00:01:54, 0.531s/it]: train_loss_raw=0.5278, running_loss=0.4447, LR=0.000100
[2025-08-11 00:35:35,525][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088404] [Batch 03488/03692] [00:30:51/00:01:48, 0.531s/it]: train_loss_raw=0.4319, running_loss=0.4425, LR=0.000100
[2025-08-11 00:35:41,651][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088416] [Batch 03500/03692] [00:30:57/00:01:41, 0.531s/it]: train_loss_raw=0.4797, running_loss=0.4421, LR=0.000100
[2025-08-11 00:35:47,709][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088428] [Batch 03512/03692] [00:31:03/00:01:35, 0.531s/it]: train_loss_raw=0.4726, running_loss=0.4427, LR=0.000100
[2025-08-11 00:35:53,840][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088440] [Batch 03524/03692] [00:31:09/00:01:29, 0.531s/it]: train_loss_raw=0.4328, running_loss=0.4419, LR=0.000100
[2025-08-11 00:36:00,347][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088452] [Batch 03536/03692] [00:31:16/00:01:22, 0.531s/it]: train_loss_raw=0.4257, running_loss=0.4440, LR=0.000100
[2025-08-11 00:36:06,515][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088464] [Batch 03548/03692] [00:31:22/00:01:16, 0.531s/it]: train_loss_raw=0.3339, running_loss=0.4423, LR=0.000100
[2025-08-11 00:36:12,562][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088476] [Batch 03560/03692] [00:31:28/00:01:10, 0.530s/it]: train_loss_raw=0.3181, running_loss=0.4377, LR=0.000100
[2025-08-11 00:36:18,640][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088488] [Batch 03572/03692] [00:31:34/00:01:03, 0.530s/it]: train_loss_raw=0.5266, running_loss=0.4397, LR=0.000100
[2025-08-11 00:36:24,984][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088500] [Batch 03584/03692] [00:31:40/00:00:57, 0.530s/it]: train_loss_raw=0.4515, running_loss=0.4407, LR=0.000100
[2025-08-11 00:36:31,292][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088512] [Batch 03596/03692] [00:31:47/00:00:50, 0.530s/it]: train_loss_raw=0.4774, running_loss=0.4424, LR=0.000100
[2025-08-11 00:36:37,465][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088524] [Batch 03608/03692] [00:31:53/00:00:44, 0.530s/it]: train_loss_raw=0.3732, running_loss=0.4467, LR=0.000100
[2025-08-11 00:36:43,987][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088536] [Batch 03620/03692] [00:31:59/00:00:38, 0.530s/it]: train_loss_raw=0.3495, running_loss=0.4455, LR=0.000100
[2025-08-11 00:36:50,469][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088548] [Batch 03632/03692] [00:32:06/00:00:31, 0.530s/it]: train_loss_raw=0.3807, running_loss=0.4459, LR=0.000100
[2025-08-11 00:36:56,866][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088560] [Batch 03644/03692] [00:32:12/00:00:25, 0.530s/it]: train_loss_raw=0.3723, running_loss=0.4455, LR=0.000100
[2025-08-11 00:37:03,267][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088572] [Batch 03656/03692] [00:32:19/00:00:19, 0.530s/it]: train_loss_raw=0.5428, running_loss=0.4494, LR=0.000100
[2025-08-11 00:37:09,668][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088584] [Batch 03668/03692] [00:32:25/00:00:12, 0.530s/it]: train_loss_raw=0.5405, running_loss=0.4491, LR=0.000100
[2025-08-11 00:37:16,129][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088596] [Batch 03680/03692] [00:32:31/00:00:06, 0.530s/it]: train_loss_raw=0.4533, running_loss=0.4472, LR=0.000100
[2025-08-11 00:37:46,524][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 088608] [Batch 03692/03692] [00:33:02/00:00:00, 0.537s/it]: train_loss_raw=0.3988, running_loss=0.4481, LR=0.000100
[2025-08-11 00:37:51,515][__main__][INFO] - [VALIDATION] [Epoch 23/29] Starting validation.
[2025-08-11 00:38:23,425][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 088609] [Batch 00011/00025] [00:00:31/00:00:34, 2.659s/it]
[2025-08-11 00:38:37,431][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 088609] [Batch 00023/00025] [00:00:45/00:00:01, 1.913s/it]
[2025-08-11 00:38:38,440][__main__][INFO] - [VALIDATION] [Epoch 23/29] train_loss=0.44809, valid_loss=0.58114
[2025-08-11 00:38:38,441][__main__][INFO] - [VALIDATION] [Epoch 23/29] Metrics:
[2025-08-11 00:38:38,441][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_er      0.239
[2025-08-11 00:38:38,441][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_prec    0.545
[2025-08-11 00:38:38,441][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_recall  0.552
[2025-08-11 00:38:38,441][__main__][INFO] - [VALIDATION] [Epoch 23/29] - pep_recall 0.526
[2025-08-11 00:38:38,444][__main__][INFO] - [TRAIN] [Epoch 23/29] Epoch complete, total time 13:42:37, remaining time 03:25:39, 00:34:16 per epoch
[2025-08-11 00:38:44,771][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088620] [Batch 00012/03692] [00:00:06/00:31:07, 0.508s/it]: train_loss_raw=0.5077, running_loss=0.3888, LR=0.000100
[2025-08-11 00:38:51,310][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088632] [Batch 00024/03692] [00:00:12/00:32:10, 0.526s/it]: train_loss_raw=0.3807, running_loss=0.3910, LR=0.000100
[2025-08-11 00:38:57,683][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088644] [Batch 00036/03692] [00:00:19/00:32:09, 0.528s/it]: train_loss_raw=0.3168, running_loss=0.3924, LR=0.000100
[2025-08-11 00:39:04,127][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088656] [Batch 00048/03692] [00:00:25/00:32:11, 0.530s/it]: train_loss_raw=0.3831, running_loss=0.3967, LR=0.000100
[2025-08-11 00:39:10,679][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088668] [Batch 00060/03692] [00:00:31/00:32:16, 0.533s/it]: train_loss_raw=0.4611, running_loss=0.3951, LR=0.000100
[2025-08-11 00:39:17,145][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088680] [Batch 00072/03692] [00:00:38/00:32:13, 0.534s/it]: train_loss_raw=0.4412, running_loss=0.3947, LR=0.000100
[2025-08-11 00:39:23,411][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088692] [Batch 00084/03692] [00:00:44/00:32:01, 0.533s/it]: train_loss_raw=0.4275, running_loss=0.3969, LR=0.000100
[2025-08-11 00:39:29,628][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088704] [Batch 00096/03692] [00:00:50/00:31:48, 0.531s/it]: train_loss_raw=0.4454, running_loss=0.3988, LR=0.000100
[2025-08-11 00:39:35,853][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088716] [Batch 00108/03692] [00:00:57/00:31:37, 0.529s/it]: train_loss_raw=0.4473, running_loss=0.4005, LR=0.000100
[2025-08-11 00:39:42,130][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088728] [Batch 00120/03692] [00:01:03/00:31:28, 0.529s/it]: train_loss_raw=0.4450, running_loss=0.4008, LR=0.000100
[2025-08-11 00:39:48,643][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088740] [Batch 00132/03692] [00:01:09/00:31:26, 0.530s/it]: train_loss_raw=0.4617, running_loss=0.4026, LR=0.000100
[2025-08-11 00:39:55,200][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088752] [Batch 00144/03692] [00:01:16/00:31:25, 0.531s/it]: train_loss_raw=0.4210, running_loss=0.4050, LR=0.000100
[2025-08-11 00:40:01,527][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088764] [Batch 00156/03692] [00:01:22/00:31:17, 0.531s/it]: train_loss_raw=0.4225, running_loss=0.4065, LR=0.000100
[2025-08-11 00:40:07,750][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088776] [Batch 00168/03692] [00:01:29/00:31:08, 0.530s/it]: train_loss_raw=0.4103, running_loss=0.4093, LR=0.000100
[2025-08-11 00:40:14,104][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088788] [Batch 00180/03692] [00:01:35/00:31:01, 0.530s/it]: train_loss_raw=0.3890, running_loss=0.4102, LR=0.000100
[2025-08-11 00:40:20,560][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088800] [Batch 00192/03692] [00:01:41/00:30:57, 0.531s/it]: train_loss_raw=0.5025, running_loss=0.4092, LR=0.000100
[2025-08-11 00:40:26,934][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088812] [Batch 00204/03692] [00:01:48/00:30:50, 0.531s/it]: train_loss_raw=0.3859, running_loss=0.4101, LR=0.000100
[2025-08-11 00:40:33,374][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088824] [Batch 00216/03692] [00:01:54/00:30:45, 0.531s/it]: train_loss_raw=0.3869, running_loss=0.4076, LR=0.000100
[2025-08-11 00:40:39,698][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088836] [Batch 00228/03692] [00:02:01/00:30:38, 0.531s/it]: train_loss_raw=0.4218, running_loss=0.4090, LR=0.000100
[2025-08-11 00:40:46,094][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088848] [Batch 00240/03692] [00:02:07/00:30:32, 0.531s/it]: train_loss_raw=0.3357, running_loss=0.4082, LR=0.000100
[2025-08-11 00:40:52,500][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088860] [Batch 00252/03692] [00:02:13/00:30:26, 0.531s/it]: train_loss_raw=0.3980, running_loss=0.4106, LR=0.000100
[2025-08-11 00:40:59,010][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088872] [Batch 00264/03692] [00:02:20/00:30:22, 0.532s/it]: train_loss_raw=0.4014, running_loss=0.4127, LR=0.000100
[2025-08-11 00:41:05,524][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088884] [Batch 00276/03692] [00:02:26/00:30:17, 0.532s/it]: train_loss_raw=0.3415, running_loss=0.4098, LR=0.000100
[2025-08-11 00:41:12,010][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088896] [Batch 00288/03692] [00:02:33/00:30:12, 0.532s/it]: train_loss_raw=0.4112, running_loss=0.4148, LR=0.000100
[2025-08-11 00:41:18,432][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088908] [Batch 00300/03692] [00:02:39/00:30:06, 0.533s/it]: train_loss_raw=0.4152, running_loss=0.4151, LR=0.000100
[2025-08-11 00:41:24,916][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088920] [Batch 00312/03692] [00:02:46/00:30:00, 0.533s/it]: train_loss_raw=0.3913, running_loss=0.4152, LR=0.000100
[2025-08-11 00:41:31,292][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088932] [Batch 00324/03692] [00:02:52/00:29:54, 0.533s/it]: train_loss_raw=0.3902, running_loss=0.4132, LR=0.000100
[2025-08-11 00:41:37,806][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088944] [Batch 00336/03692] [00:02:59/00:29:49, 0.533s/it]: train_loss_raw=0.3382, running_loss=0.4114, LR=0.000100
[2025-08-11 00:41:44,343][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088956] [Batch 00348/03692] [00:03:05/00:29:44, 0.534s/it]: train_loss_raw=0.4063, running_loss=0.4112, LR=0.000100
[2025-08-11 00:41:50,827][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088968] [Batch 00360/03692] [00:03:12/00:29:38, 0.534s/it]: train_loss_raw=0.3231, running_loss=0.4100, LR=0.000100
[2025-08-11 00:41:57,379][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088980] [Batch 00372/03692] [00:03:18/00:29:33, 0.534s/it]: train_loss_raw=0.3656, running_loss=0.4100, LR=0.000100
[2025-08-11 00:42:03,610][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 088992] [Batch 00384/03692] [00:03:24/00:29:25, 0.534s/it]: train_loss_raw=0.3901, running_loss=0.4083, LR=0.000100
[2025-08-11 00:42:09,998][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089004] [Batch 00396/03692] [00:03:31/00:29:18, 0.534s/it]: train_loss_raw=0.4370, running_loss=0.4099, LR=0.000100
[2025-08-11 00:42:16,261][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089016] [Batch 00408/03692] [00:03:37/00:29:11, 0.533s/it]: train_loss_raw=0.3680, running_loss=0.4071, LR=0.000100
[2025-08-11 00:42:22,387][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089028] [Batch 00420/03692] [00:03:43/00:29:02, 0.533s/it]: train_loss_raw=0.3437, running_loss=0.4084, LR=0.000100
[2025-08-11 00:42:28,614][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089040] [Batch 00432/03692] [00:03:49/00:28:55, 0.532s/it]: train_loss_raw=0.3553, running_loss=0.4053, LR=0.000100
[2025-08-11 00:42:34,811][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089052] [Batch 00444/03692] [00:03:56/00:28:47, 0.532s/it]: train_loss_raw=0.4273, running_loss=0.4060, LR=0.000100
[2025-08-11 00:42:40,980][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089064] [Batch 00456/03692] [00:04:02/00:28:39, 0.531s/it]: train_loss_raw=0.4218, running_loss=0.4069, LR=0.000100
[2025-08-11 00:42:47,072][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089076] [Batch 00468/03692] [00:04:08/00:28:31, 0.531s/it]: train_loss_raw=0.4508, running_loss=0.4080, LR=0.000100
[2025-08-11 00:42:53,226][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089088] [Batch 00480/03692] [00:04:14/00:28:23, 0.530s/it]: train_loss_raw=0.3484, running_loss=0.4061, LR=0.000100
[2025-08-11 00:42:59,609][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089100] [Batch 00492/03692] [00:04:20/00:28:17, 0.530s/it]: train_loss_raw=0.3750, running_loss=0.4060, LR=0.000100
[2025-08-11 00:43:06,152][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089112] [Batch 00504/03692] [00:04:27/00:28:11, 0.531s/it]: train_loss_raw=0.4841, running_loss=0.4090, LR=0.000100
[2025-08-11 00:43:12,631][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089124] [Batch 00516/03692] [00:04:33/00:28:06, 0.531s/it]: train_loss_raw=0.5286, running_loss=0.4147, LR=0.000100
[2025-08-11 00:43:18,936][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089136] [Batch 00528/03692] [00:04:40/00:27:59, 0.531s/it]: train_loss_raw=0.4405, running_loss=0.4142, LR=0.000100
[2025-08-11 00:43:25,336][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089148] [Batch 00540/03692] [00:04:46/00:27:53, 0.531s/it]: train_loss_raw=0.4568, running_loss=0.4164, LR=0.000100
[2025-08-11 00:43:31,668][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089160] [Batch 00552/03692] [00:04:52/00:27:46, 0.531s/it]: train_loss_raw=0.4084, running_loss=0.4152, LR=0.000100
[2025-08-11 00:43:38,054][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089172] [Batch 00564/03692] [00:04:59/00:27:40, 0.531s/it]: train_loss_raw=0.4415, running_loss=0.4153, LR=0.000100
[2025-08-11 00:43:44,481][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089184] [Batch 00576/03692] [00:05:05/00:27:34, 0.531s/it]: train_loss_raw=0.4379, running_loss=0.4164, LR=0.000100
[2025-08-11 00:43:51,003][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089196] [Batch 00588/03692] [00:05:12/00:27:28, 0.531s/it]: train_loss_raw=0.4839, running_loss=0.4161, LR=0.000100
[2025-08-11 00:43:57,617][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089208] [Batch 00600/03692] [00:05:18/00:27:23, 0.532s/it]: train_loss_raw=0.3373, running_loss=0.4168, LR=0.000100
[2025-08-11 00:44:04,007][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089220] [Batch 00612/03692] [00:05:25/00:27:17, 0.532s/it]: train_loss_raw=0.4133, running_loss=0.4176, LR=0.000100
[2025-08-11 00:44:10,318][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089232] [Batch 00624/03692] [00:05:31/00:27:10, 0.531s/it]: train_loss_raw=0.3637, running_loss=0.4163, LR=0.000100
[2025-08-11 00:44:16,740][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089244] [Batch 00636/03692] [00:05:38/00:27:04, 0.532s/it]: train_loss_raw=0.4734, running_loss=0.4166, LR=0.000100
[2025-08-11 00:44:23,131][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089256] [Batch 00648/03692] [00:05:44/00:26:58, 0.532s/it]: train_loss_raw=0.3800, running_loss=0.4161, LR=0.000100
[2025-08-11 00:44:29,564][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089268] [Batch 00660/03692] [00:05:50/00:26:51, 0.532s/it]: train_loss_raw=0.4503, running_loss=0.4167, LR=0.000100
[2025-08-11 00:44:36,019][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089280] [Batch 00672/03692] [00:05:57/00:26:45, 0.532s/it]: train_loss_raw=0.3844, running_loss=0.4113, LR=0.000100
[2025-08-11 00:44:42,497][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089292] [Batch 00684/03692] [00:06:03/00:26:39, 0.532s/it]: train_loss_raw=0.5550, running_loss=0.4112, LR=0.000100
[2025-08-11 00:44:48,884][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089304] [Batch 00696/03692] [00:06:10/00:26:33, 0.532s/it]: train_loss_raw=0.3794, running_loss=0.4119, LR=0.000100
[2025-08-11 00:44:55,356][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089316] [Batch 00708/03692] [00:06:16/00:26:27, 0.532s/it]: train_loss_raw=0.3798, running_loss=0.4116, LR=0.000100
[2025-08-11 00:45:01,750][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089328] [Batch 00720/03692] [00:06:23/00:26:21, 0.532s/it]: train_loss_raw=0.4577, running_loss=0.4141, LR=0.000100
[2025-08-11 00:45:08,156][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089340] [Batch 00732/03692] [00:06:29/00:26:14, 0.532s/it]: train_loss_raw=0.3676, running_loss=0.4148, LR=0.000100
[2025-08-11 00:45:14,505][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089352] [Batch 00744/03692] [00:06:35/00:26:08, 0.532s/it]: train_loss_raw=0.3776, running_loss=0.4147, LR=0.000100
[2025-08-11 00:45:21,043][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089364] [Batch 00756/03692] [00:06:42/00:26:02, 0.532s/it]: train_loss_raw=0.4375, running_loss=0.4128, LR=0.000100
[2025-08-11 00:45:27,492][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089376] [Batch 00768/03692] [00:06:48/00:25:56, 0.532s/it]: train_loss_raw=0.3740, running_loss=0.4130, LR=0.000100
[2025-08-11 00:45:33,859][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089388] [Batch 00780/03692] [00:06:55/00:25:49, 0.532s/it]: train_loss_raw=0.4253, running_loss=0.4161, LR=0.000100
[2025-08-11 00:45:40,247][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089400] [Batch 00792/03692] [00:07:01/00:25:43, 0.532s/it]: train_loss_raw=0.4545, running_loss=0.4176, LR=0.000100
[2025-08-11 00:45:46,626][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089412] [Batch 00804/03692] [00:07:07/00:25:37, 0.532s/it]: train_loss_raw=0.4545, running_loss=0.4184, LR=0.000100
[2025-08-11 00:45:53,105][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089424] [Batch 00816/03692] [00:07:14/00:25:31, 0.532s/it]: train_loss_raw=0.4179, running_loss=0.4182, LR=0.000100
[2025-08-11 00:45:59,523][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089436] [Batch 00828/03692] [00:07:20/00:25:24, 0.532s/it]: train_loss_raw=0.4229, running_loss=0.4177, LR=0.000100
[2025-08-11 00:46:05,970][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089448] [Batch 00840/03692] [00:07:27/00:25:18, 0.532s/it]: train_loss_raw=0.4049, running_loss=0.4184, LR=0.000100
[2025-08-11 00:46:12,365][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089460] [Batch 00852/03692] [00:07:33/00:25:12, 0.532s/it]: train_loss_raw=0.4319, running_loss=0.4188, LR=0.000100
[2025-08-11 00:46:18,726][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089472] [Batch 00864/03692] [00:07:40/00:25:05, 0.532s/it]: train_loss_raw=0.3862, running_loss=0.4177, LR=0.000100
[2025-08-11 00:46:25,204][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089484] [Batch 00876/03692] [00:07:46/00:24:59, 0.533s/it]: train_loss_raw=0.4448, running_loss=0.4165, LR=0.000100
[2025-08-11 00:46:31,613][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089496] [Batch 00888/03692] [00:07:52/00:24:53, 0.533s/it]: train_loss_raw=0.4097, running_loss=0.4139, LR=0.000100
[2025-08-11 00:46:38,140][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089508] [Batch 00900/03692] [00:07:59/00:24:47, 0.533s/it]: train_loss_raw=0.5174, running_loss=0.4159, LR=0.000100
[2025-08-11 00:46:44,582][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089520] [Batch 00912/03692] [00:08:05/00:24:41, 0.533s/it]: train_loss_raw=0.4757, running_loss=0.4154, LR=0.000100
[2025-08-11 00:46:50,962][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089532] [Batch 00924/03692] [00:08:12/00:24:34, 0.533s/it]: train_loss_raw=0.4406, running_loss=0.4162, LR=0.000100
[2025-08-11 00:46:57,447][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089544] [Batch 00936/03692] [00:08:18/00:24:28, 0.533s/it]: train_loss_raw=0.4322, running_loss=0.4147, LR=0.000100
[2025-08-11 00:47:03,848][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089556] [Batch 00948/03692] [00:08:25/00:24:22, 0.533s/it]: train_loss_raw=0.4682, running_loss=0.4194, LR=0.000100
[2025-08-11 00:47:10,310][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089568] [Batch 00960/03692] [00:08:31/00:24:16, 0.533s/it]: train_loss_raw=0.5071, running_loss=0.4224, LR=0.000100
[2025-08-11 00:47:16,861][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089580] [Batch 00972/03692] [00:08:38/00:24:10, 0.533s/it]: train_loss_raw=0.4160, running_loss=0.4201, LR=0.000100
[2025-08-11 00:47:23,313][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089592] [Batch 00984/03692] [00:08:44/00:24:03, 0.533s/it]: train_loss_raw=0.4412, running_loss=0.4229, LR=0.000100
[2025-08-11 00:47:29,860][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089604] [Batch 00996/03692] [00:08:51/00:23:57, 0.533s/it]: train_loss_raw=0.4848, running_loss=0.4246, LR=0.000100
[2025-08-11 00:47:36,288][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089616] [Batch 01008/03692] [00:08:57/00:23:51, 0.533s/it]: train_loss_raw=0.4931, running_loss=0.4272, LR=0.000100
[2025-08-11 00:47:42,665][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089628] [Batch 01020/03692] [00:09:03/00:23:45, 0.533s/it]: train_loss_raw=0.3137, running_loss=0.4240, LR=0.000100
[2025-08-11 00:47:49,192][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089640] [Batch 01032/03692] [00:09:10/00:23:38, 0.533s/it]: train_loss_raw=0.3660, running_loss=0.4221, LR=0.000100
[2025-08-11 00:47:55,697][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089652] [Batch 01044/03692] [00:09:17/00:23:32, 0.534s/it]: train_loss_raw=0.4149, running_loss=0.4215, LR=0.000100
[2025-08-11 00:48:02,185][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089664] [Batch 01056/03692] [00:09:23/00:23:26, 0.534s/it]: train_loss_raw=0.4669, running_loss=0.4197, LR=0.000100
[2025-08-11 00:48:08,684][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089676] [Batch 01068/03692] [00:09:30/00:23:20, 0.534s/it]: train_loss_raw=0.4624, running_loss=0.4219, LR=0.000100
[2025-08-11 00:48:14,989][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089688] [Batch 01080/03692] [00:09:36/00:23:13, 0.534s/it]: train_loss_raw=0.3428, running_loss=0.4222, LR=0.000100
[2025-08-11 00:48:21,293][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089700] [Batch 01092/03692] [00:09:42/00:23:07, 0.534s/it]: train_loss_raw=0.4294, running_loss=0.4196, LR=0.000100
[2025-08-11 00:48:27,679][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089712] [Batch 01104/03692] [00:09:48/00:23:00, 0.534s/it]: train_loss_raw=0.3389, running_loss=0.4213, LR=0.000100
[2025-08-11 00:48:34,055][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089724] [Batch 01116/03692] [00:09:55/00:22:54, 0.533s/it]: train_loss_raw=0.3556, running_loss=0.4199, LR=0.000100
[2025-08-11 00:48:40,546][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089736] [Batch 01128/03692] [00:10:01/00:22:48, 0.534s/it]: train_loss_raw=0.5602, running_loss=0.4206, LR=0.000100
[2025-08-11 00:48:47,004][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089748] [Batch 01140/03692] [00:10:08/00:22:41, 0.534s/it]: train_loss_raw=0.3643, running_loss=0.4204, LR=0.000100
[2025-08-11 00:48:53,409][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089760] [Batch 01152/03692] [00:10:14/00:22:35, 0.534s/it]: train_loss_raw=0.4984, running_loss=0.4241, LR=0.000100
[2025-08-11 00:48:59,854][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089772] [Batch 01164/03692] [00:10:21/00:22:29, 0.534s/it]: train_loss_raw=0.3311, running_loss=0.4237, LR=0.000100
[2025-08-11 00:49:06,237][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089784] [Batch 01176/03692] [00:10:27/00:22:22, 0.534s/it]: train_loss_raw=0.3554, running_loss=0.4231, LR=0.000100
[2025-08-11 00:49:12,618][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089796] [Batch 01188/03692] [00:10:33/00:22:16, 0.534s/it]: train_loss_raw=0.4233, running_loss=0.4235, LR=0.000100
[2025-08-11 00:49:19,036][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089808] [Batch 01200/03692] [00:10:40/00:22:09, 0.534s/it]: train_loss_raw=0.3538, running_loss=0.4220, LR=0.000100
[2025-08-11 00:49:25,612][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089820] [Batch 01212/03692] [00:10:46/00:22:03, 0.534s/it]: train_loss_raw=0.3800, running_loss=0.4201, LR=0.000100
[2025-08-11 00:49:32,041][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089832] [Batch 01224/03692] [00:10:53/00:21:57, 0.534s/it]: train_loss_raw=0.4143, running_loss=0.4193, LR=0.000100
[2025-08-11 00:49:38,155][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089844] [Batch 01236/03692] [00:10:59/00:21:50, 0.534s/it]: train_loss_raw=0.4756, running_loss=0.4196, LR=0.000100
[2025-08-11 00:49:44,309][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089856] [Batch 01248/03692] [00:11:05/00:21:43, 0.533s/it]: train_loss_raw=0.3157, running_loss=0.4198, LR=0.000100
[2025-08-11 00:49:50,525][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089868] [Batch 01260/03692] [00:11:11/00:21:36, 0.533s/it]: train_loss_raw=0.4588, running_loss=0.4189, LR=0.000100
[2025-08-11 00:49:56,806][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089880] [Batch 01272/03692] [00:11:18/00:21:30, 0.533s/it]: train_loss_raw=0.4538, running_loss=0.4187, LR=0.000100
[2025-08-11 00:50:03,158][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089892] [Batch 01284/03692] [00:11:24/00:21:23, 0.533s/it]: train_loss_raw=0.4419, running_loss=0.4187, LR=0.000100
[2025-08-11 00:50:09,548][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089904] [Batch 01296/03692] [00:11:30/00:21:17, 0.533s/it]: train_loss_raw=0.4875, running_loss=0.4204, LR=0.000100
[2025-08-11 00:50:15,753][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089916] [Batch 01308/03692] [00:11:37/00:21:10, 0.533s/it]: train_loss_raw=0.3890, running_loss=0.4225, LR=0.000100
[2025-08-11 00:50:21,922][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089928] [Batch 01320/03692] [00:11:43/00:21:03, 0.533s/it]: train_loss_raw=0.4605, running_loss=0.4228, LR=0.000100
[2025-08-11 00:50:28,160][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089940] [Batch 01332/03692] [00:11:49/00:20:57, 0.533s/it]: train_loss_raw=0.4392, running_loss=0.4218, LR=0.000100
[2025-08-11 00:50:34,267][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089952] [Batch 01344/03692] [00:11:55/00:20:50, 0.532s/it]: train_loss_raw=0.4992, running_loss=0.4201, LR=0.000100
[2025-08-11 00:50:40,319][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089964] [Batch 01356/03692] [00:12:01/00:20:43, 0.532s/it]: train_loss_raw=0.4895, running_loss=0.4209, LR=0.000100
[2025-08-11 00:50:46,405][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089976] [Batch 01368/03692] [00:12:07/00:20:36, 0.532s/it]: train_loss_raw=0.4195, running_loss=0.4221, LR=0.000100
[2025-08-11 00:50:52,498][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 089988] [Batch 01380/03692] [00:12:13/00:20:29, 0.532s/it]: train_loss_raw=0.4210, running_loss=0.4229, LR=0.000100
[2025-08-11 00:50:58,860][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090000] [Batch 01392/03692] [00:12:20/00:20:22, 0.532s/it]: train_loss_raw=0.3524, running_loss=0.4213, LR=0.000100
[2025-08-11 00:51:10,887][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090012] [Batch 01404/03692] [00:12:32/00:20:25, 0.536s/it]: train_loss_raw=0.3782, running_loss=0.4201, LR=0.000100
[2025-08-11 00:51:17,223][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090024] [Batch 01416/03692] [00:12:38/00:20:19, 0.536s/it]: train_loss_raw=0.4703, running_loss=0.4212, LR=0.000100
[2025-08-11 00:51:23,431][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090036] [Batch 01428/03692] [00:12:44/00:20:12, 0.536s/it]: train_loss_raw=0.3789, running_loss=0.4207, LR=0.000100
[2025-08-11 00:51:29,698][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090048] [Batch 01440/03692] [00:12:51/00:20:05, 0.535s/it]: train_loss_raw=0.4523, running_loss=0.4206, LR=0.000100
[2025-08-11 00:51:36,184][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090060] [Batch 01452/03692] [00:12:57/00:19:59, 0.535s/it]: train_loss_raw=0.3944, running_loss=0.4207, LR=0.000100
[2025-08-11 00:51:42,621][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090072] [Batch 01464/03692] [00:13:03/00:19:53, 0.535s/it]: train_loss_raw=0.4280, running_loss=0.4210, LR=0.000100
[2025-08-11 00:51:49,082][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090084] [Batch 01476/03692] [00:13:10/00:19:46, 0.536s/it]: train_loss_raw=0.4345, running_loss=0.4239, LR=0.000100
[2025-08-11 00:51:55,456][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090096] [Batch 01488/03692] [00:13:16/00:19:40, 0.535s/it]: train_loss_raw=0.3517, running_loss=0.4228, LR=0.000100
[2025-08-11 00:52:01,830][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090108] [Batch 01500/03692] [00:13:23/00:19:33, 0.535s/it]: train_loss_raw=0.5143, running_loss=0.4238, LR=0.000100
[2025-08-11 00:52:08,259][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090120] [Batch 01512/03692] [00:13:29/00:19:27, 0.535s/it]: train_loss_raw=0.4046, running_loss=0.4216, LR=0.000100
[2025-08-11 00:52:14,755][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090132] [Batch 01524/03692] [00:13:36/00:19:20, 0.535s/it]: train_loss_raw=0.4335, running_loss=0.4215, LR=0.000100
[2025-08-11 00:52:45,080][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090144] [Batch 01536/03692] [00:14:06/00:19:48, 0.551s/it]: train_loss_raw=0.3678, running_loss=0.4200, LR=0.000100
[2025-08-11 00:52:51,375][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090156] [Batch 01548/03692] [00:14:12/00:19:40, 0.551s/it]: train_loss_raw=0.3735, running_loss=0.4190, LR=0.000100
[2025-08-11 00:52:57,734][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090168] [Batch 01560/03692] [00:14:19/00:19:34, 0.551s/it]: train_loss_raw=0.4294, running_loss=0.4179, LR=0.000100
[2025-08-11 00:53:04,168][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090180] [Batch 01572/03692] [00:14:25/00:19:27, 0.551s/it]: train_loss_raw=0.3650, running_loss=0.4154, LR=0.000100
[2025-08-11 00:53:10,592][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090192] [Batch 01584/03692] [00:14:31/00:19:20, 0.550s/it]: train_loss_raw=0.4640, running_loss=0.4160, LR=0.000100
[2025-08-11 00:53:17,106][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090204] [Batch 01596/03692] [00:14:38/00:19:13, 0.550s/it]: train_loss_raw=0.4704, running_loss=0.4155, LR=0.000100
[2025-08-11 00:53:23,610][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090216] [Batch 01608/03692] [00:14:44/00:19:06, 0.550s/it]: train_loss_raw=0.5191, running_loss=0.4176, LR=0.000100
[2025-08-11 00:53:30,135][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090228] [Batch 01620/03692] [00:14:51/00:19:00, 0.550s/it]: train_loss_raw=0.3762, running_loss=0.4141, LR=0.000100
[2025-08-11 00:53:36,647][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090240] [Batch 01632/03692] [00:14:57/00:18:53, 0.550s/it]: train_loss_raw=0.4357, running_loss=0.4162, LR=0.000100
[2025-08-11 00:53:42,930][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090252] [Batch 01644/03692] [00:15:04/00:18:46, 0.550s/it]: train_loss_raw=0.4326, running_loss=0.4128, LR=0.000100
[2025-08-11 00:53:49,323][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090264] [Batch 01656/03692] [00:15:10/00:18:39, 0.550s/it]: train_loss_raw=0.4857, running_loss=0.4129, LR=0.000100
[2025-08-11 00:53:55,793][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090276] [Batch 01668/03692] [00:15:17/00:18:32, 0.550s/it]: train_loss_raw=0.4793, running_loss=0.4142, LR=0.000100
[2025-08-11 00:54:02,225][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090288] [Batch 01680/03692] [00:15:23/00:18:26, 0.550s/it]: train_loss_raw=0.3547, running_loss=0.4148, LR=0.000100
[2025-08-11 00:54:08,618][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090300] [Batch 01692/03692] [00:15:29/00:18:19, 0.550s/it]: train_loss_raw=0.4303, running_loss=0.4149, LR=0.000100
[2025-08-11 00:54:14,959][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090312] [Batch 01704/03692] [00:15:36/00:18:12, 0.549s/it]: train_loss_raw=0.3662, running_loss=0.4184, LR=0.000100
[2025-08-11 00:54:21,342][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090324] [Batch 01716/03692] [00:15:42/00:18:05, 0.549s/it]: train_loss_raw=0.4612, running_loss=0.4215, LR=0.000100
[2025-08-11 00:54:27,685][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090336] [Batch 01728/03692] [00:15:49/00:17:58, 0.549s/it]: train_loss_raw=0.3885, running_loss=0.4199, LR=0.000100
[2025-08-11 00:54:34,107][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090348] [Batch 01740/03692] [00:15:55/00:17:51, 0.549s/it]: train_loss_raw=0.4842, running_loss=0.4191, LR=0.000100
[2025-08-11 00:54:40,506][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090360] [Batch 01752/03692] [00:16:01/00:17:45, 0.549s/it]: train_loss_raw=0.4481, running_loss=0.4215, LR=0.000100
[2025-08-11 00:54:46,966][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090372] [Batch 01764/03692] [00:16:08/00:17:38, 0.549s/it]: train_loss_raw=0.3669, running_loss=0.4198, LR=0.000100
[2025-08-11 00:54:53,424][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090384] [Batch 01776/03692] [00:16:14/00:17:31, 0.549s/it]: train_loss_raw=0.4535, running_loss=0.4208, LR=0.000100
[2025-08-11 00:54:59,843][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090396] [Batch 01788/03692] [00:16:21/00:17:24, 0.549s/it]: train_loss_raw=0.4995, running_loss=0.4228, LR=0.000100
[2025-08-11 00:55:06,298][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090408] [Batch 01800/03692] [00:16:27/00:17:18, 0.549s/it]: train_loss_raw=0.3987, running_loss=0.4241, LR=0.000100
[2025-08-11 00:55:12,710][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090420] [Batch 01812/03692] [00:16:34/00:17:11, 0.549s/it]: train_loss_raw=0.3839, running_loss=0.4262, LR=0.000100
[2025-08-11 00:55:18,818][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090432] [Batch 01824/03692] [00:16:40/00:17:04, 0.548s/it]: train_loss_raw=0.3733, running_loss=0.4238, LR=0.000100
[2025-08-11 00:55:24,886][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090444] [Batch 01836/03692] [00:16:46/00:16:57, 0.548s/it]: train_loss_raw=0.4622, running_loss=0.4246, LR=0.000100
[2025-08-11 00:55:30,909][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090456] [Batch 01848/03692] [00:16:52/00:16:50, 0.548s/it]: train_loss_raw=0.3044, running_loss=0.4242, LR=0.000100
[2025-08-11 00:55:36,953][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090468] [Batch 01860/03692] [00:16:58/00:16:42, 0.547s/it]: train_loss_raw=0.4709, running_loss=0.4238, LR=0.000100
[2025-08-11 00:55:42,946][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090480] [Batch 01872/03692] [00:17:04/00:16:35, 0.547s/it]: train_loss_raw=0.4528, running_loss=0.4233, LR=0.000100
[2025-08-11 00:55:48,976][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090492] [Batch 01884/03692] [00:17:10/00:16:28, 0.547s/it]: train_loss_raw=0.3703, running_loss=0.4245, LR=0.000100
[2025-08-11 00:55:55,049][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090504] [Batch 01896/03692] [00:17:16/00:16:21, 0.547s/it]: train_loss_raw=0.4990, running_loss=0.4234, LR=0.000100
[2025-08-11 00:56:01,102][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090516] [Batch 01908/03692] [00:17:22/00:16:14, 0.546s/it]: train_loss_raw=0.3488, running_loss=0.4274, LR=0.000100
[2025-08-11 00:56:07,305][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090528] [Batch 01920/03692] [00:17:28/00:16:07, 0.546s/it]: train_loss_raw=0.3353, running_loss=0.4225, LR=0.000100
[2025-08-11 00:56:13,746][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090540] [Batch 01932/03692] [00:17:35/00:16:01, 0.546s/it]: train_loss_raw=0.3627, running_loss=0.4206, LR=0.000100
[2025-08-11 00:56:20,277][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090552] [Batch 01944/03692] [00:17:41/00:15:54, 0.546s/it]: train_loss_raw=0.4612, running_loss=0.4215, LR=0.000100
[2025-08-11 00:56:26,797][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090564] [Batch 01956/03692] [00:17:48/00:15:47, 0.546s/it]: train_loss_raw=0.4430, running_loss=0.4242, LR=0.000100
[2025-08-11 00:56:32,974][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090576] [Batch 01968/03692] [00:17:54/00:15:41, 0.546s/it]: train_loss_raw=0.4984, running_loss=0.4252, LR=0.000100
[2025-08-11 00:56:39,023][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090588] [Batch 01980/03692] [00:18:00/00:15:34, 0.546s/it]: train_loss_raw=0.4604, running_loss=0.4238, LR=0.000100
[2025-08-11 00:56:45,074][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090600] [Batch 01992/03692] [00:18:06/00:15:27, 0.545s/it]: train_loss_raw=0.3859, running_loss=0.4246, LR=0.000100
[2025-08-11 00:56:51,073][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090612] [Batch 02004/03692] [00:18:12/00:15:20, 0.545s/it]: train_loss_raw=0.3740, running_loss=0.4258, LR=0.000100
[2025-08-11 00:56:57,071][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090624] [Batch 02016/03692] [00:18:18/00:15:13, 0.545s/it]: train_loss_raw=0.3855, running_loss=0.4219, LR=0.000100
[2025-08-11 00:57:03,091][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090636] [Batch 02028/03692] [00:18:24/00:15:06, 0.545s/it]: train_loss_raw=0.5204, running_loss=0.4226, LR=0.000100
[2025-08-11 00:57:09,136][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090648] [Batch 02040/03692] [00:18:30/00:14:59, 0.544s/it]: train_loss_raw=0.4674, running_loss=0.4252, LR=0.000100
[2025-08-11 00:57:15,206][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090660] [Batch 02052/03692] [00:18:36/00:14:52, 0.544s/it]: train_loss_raw=0.4260, running_loss=0.4277, LR=0.000100
[2025-08-11 00:57:21,137][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090672] [Batch 02064/03692] [00:18:42/00:14:45, 0.544s/it]: train_loss_raw=0.4223, running_loss=0.4292, LR=0.000100
[2025-08-11 00:57:27,195][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090684] [Batch 02076/03692] [00:18:48/00:14:38, 0.544s/it]: train_loss_raw=0.3743, running_loss=0.4292, LR=0.000100
[2025-08-11 00:57:33,227][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090696] [Batch 02088/03692] [00:18:54/00:14:31, 0.543s/it]: train_loss_raw=0.3579, running_loss=0.4283, LR=0.000100
[2025-08-11 00:57:39,296][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090708] [Batch 02100/03692] [00:19:00/00:14:24, 0.543s/it]: train_loss_raw=0.4663, running_loss=0.4285, LR=0.000100
[2025-08-11 00:57:45,310][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090720] [Batch 02112/03692] [00:19:06/00:14:17, 0.543s/it]: train_loss_raw=0.3900, running_loss=0.4288, LR=0.000100
[2025-08-11 00:57:51,340][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090732] [Batch 02124/03692] [00:19:12/00:14:10, 0.543s/it]: train_loss_raw=0.4276, running_loss=0.4264, LR=0.000100
[2025-08-11 00:57:57,404][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090744] [Batch 02136/03692] [00:19:18/00:14:04, 0.542s/it]: train_loss_raw=0.3257, running_loss=0.4244, LR=0.000100
[2025-08-11 00:58:03,478][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090756] [Batch 02148/03692] [00:19:24/00:13:57, 0.542s/it]: train_loss_raw=0.4008, running_loss=0.4247, LR=0.000100
[2025-08-11 00:58:09,682][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090768] [Batch 02160/03692] [00:19:31/00:13:50, 0.542s/it]: train_loss_raw=0.4788, running_loss=0.4216, LR=0.000100
[2025-08-11 00:58:16,166][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090780] [Batch 02172/03692] [00:19:37/00:13:44, 0.542s/it]: train_loss_raw=0.5371, running_loss=0.4234, LR=0.000100
[2025-08-11 00:58:22,690][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090792] [Batch 02184/03692] [00:19:44/00:13:37, 0.542s/it]: train_loss_raw=0.4629, running_loss=0.4243, LR=0.000100
[2025-08-11 00:58:28,769][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090804] [Batch 02196/03692] [00:19:50/00:13:30, 0.542s/it]: train_loss_raw=0.4909, running_loss=0.4273, LR=0.000100
[2025-08-11 00:58:34,772][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090816] [Batch 02208/03692] [00:19:56/00:13:23, 0.542s/it]: train_loss_raw=0.4612, running_loss=0.4270, LR=0.000100
[2025-08-11 00:58:40,811][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090828] [Batch 02220/03692] [00:20:02/00:13:17, 0.542s/it]: train_loss_raw=0.4871, running_loss=0.4268, LR=0.000100
[2025-08-11 00:58:46,859][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090840] [Batch 02232/03692] [00:20:08/00:13:10, 0.541s/it]: train_loss_raw=0.4311, running_loss=0.4278, LR=0.000100
[2025-08-11 00:58:52,925][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090852] [Batch 02244/03692] [00:20:14/00:13:03, 0.541s/it]: train_loss_raw=0.3880, running_loss=0.4309, LR=0.000100
[2025-08-11 00:58:58,903][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090864] [Batch 02256/03692] [00:20:20/00:12:56, 0.541s/it]: train_loss_raw=0.4202, running_loss=0.4323, LR=0.000100
[2025-08-11 00:59:04,955][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090876] [Batch 02268/03692] [00:20:26/00:12:49, 0.541s/it]: train_loss_raw=0.4069, running_loss=0.4271, LR=0.000100
[2025-08-11 00:59:10,989][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090888] [Batch 02280/03692] [00:20:32/00:12:43, 0.540s/it]: train_loss_raw=0.4182, running_loss=0.4258, LR=0.000100
[2025-08-11 00:59:17,101][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090900] [Batch 02292/03692] [00:20:38/00:12:36, 0.540s/it]: train_loss_raw=0.4947, running_loss=0.4253, LR=0.000100
[2025-08-11 00:59:23,168][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090912] [Batch 02304/03692] [00:20:44/00:12:29, 0.540s/it]: train_loss_raw=0.4382, running_loss=0.4235, LR=0.000100
[2025-08-11 00:59:29,223][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090924] [Batch 02316/03692] [00:20:50/00:12:22, 0.540s/it]: train_loss_raw=0.4254, running_loss=0.4257, LR=0.000100
[2025-08-11 00:59:35,256][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090936] [Batch 02328/03692] [00:20:56/00:12:16, 0.540s/it]: train_loss_raw=0.4462, running_loss=0.4253, LR=0.000100
[2025-08-11 00:59:41,336][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090948] [Batch 02340/03692] [00:21:02/00:12:09, 0.540s/it]: train_loss_raw=0.4129, running_loss=0.4255, LR=0.000100
[2025-08-11 00:59:47,318][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090960] [Batch 02352/03692] [00:21:08/00:12:02, 0.539s/it]: train_loss_raw=0.4608, running_loss=0.4248, LR=0.000100
[2025-08-11 00:59:53,335][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090972] [Batch 02364/03692] [00:21:14/00:11:56, 0.539s/it]: train_loss_raw=0.3191, running_loss=0.4226, LR=0.000100
[2025-08-11 00:59:59,630][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090984] [Batch 02376/03692] [00:21:20/00:11:49, 0.539s/it]: train_loss_raw=0.4842, running_loss=0.4246, LR=0.000100
[2025-08-11 01:00:06,129][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 090996] [Batch 02388/03692] [00:21:27/00:11:43, 0.539s/it]: train_loss_raw=0.4600, running_loss=0.4249, LR=0.000100
[2025-08-11 01:00:12,212][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091008] [Batch 02400/03692] [00:21:33/00:11:36, 0.539s/it]: train_loss_raw=0.5226, running_loss=0.4272, LR=0.000100
[2025-08-11 01:00:18,265][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091020] [Batch 02412/03692] [00:21:39/00:11:29, 0.539s/it]: train_loss_raw=0.4019, running_loss=0.4255, LR=0.000100
[2025-08-11 01:00:24,318][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091032] [Batch 02424/03692] [00:21:45/00:11:22, 0.539s/it]: train_loss_raw=0.4294, running_loss=0.4231, LR=0.000100
[2025-08-11 01:00:30,357][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091044] [Batch 02436/03692] [00:21:51/00:11:16, 0.538s/it]: train_loss_raw=0.4118, running_loss=0.4224, LR=0.000100
[2025-08-11 01:00:36,689][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091056] [Batch 02448/03692] [00:21:58/00:11:09, 0.538s/it]: train_loss_raw=0.3868, running_loss=0.4235, LR=0.000100
[2025-08-11 01:00:42,958][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091068] [Batch 02460/03692] [00:22:04/00:11:03, 0.538s/it]: train_loss_raw=0.4999, running_loss=0.4235, LR=0.000100
[2025-08-11 01:00:49,002][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091080] [Batch 02472/03692] [00:22:10/00:10:56, 0.538s/it]: train_loss_raw=0.3732, running_loss=0.4224, LR=0.000100
[2025-08-11 01:00:55,061][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091092] [Batch 02484/03692] [00:22:16/00:10:49, 0.538s/it]: train_loss_raw=0.3859, running_loss=0.4214, LR=0.000100
[2025-08-11 01:01:01,204][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091104] [Batch 02496/03692] [00:22:22/00:10:43, 0.538s/it]: train_loss_raw=0.3745, running_loss=0.4225, LR=0.000100
[2025-08-11 01:01:07,548][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091116] [Batch 02508/03692] [00:22:28/00:10:36, 0.538s/it]: train_loss_raw=0.3000, running_loss=0.4194, LR=0.000100
[2025-08-11 01:01:13,580][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091128] [Batch 02520/03692] [00:22:34/00:10:30, 0.538s/it]: train_loss_raw=0.4331, running_loss=0.4182, LR=0.000100
[2025-08-11 01:01:19,585][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091140] [Batch 02532/03692] [00:22:40/00:10:23, 0.537s/it]: train_loss_raw=0.4656, running_loss=0.4185, LR=0.000100
[2025-08-11 01:01:25,619][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091152] [Batch 02544/03692] [00:22:46/00:10:16, 0.537s/it]: train_loss_raw=0.3514, running_loss=0.4188, LR=0.000100
[2025-08-11 01:01:31,668][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091164] [Batch 02556/03692] [00:22:52/00:10:10, 0.537s/it]: train_loss_raw=0.5149, running_loss=0.4198, LR=0.000100
[2025-08-11 01:01:37,856][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091176] [Batch 02568/03692] [00:22:59/00:10:03, 0.537s/it]: train_loss_raw=0.3270, running_loss=0.4189, LR=0.000100
[2025-08-11 01:01:44,019][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091188] [Batch 02580/03692] [00:23:05/00:09:57, 0.537s/it]: train_loss_raw=0.4921, running_loss=0.4196, LR=0.000100
[2025-08-11 01:01:50,069][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091200] [Batch 02592/03692] [00:23:11/00:09:50, 0.537s/it]: train_loss_raw=0.3620, running_loss=0.4186, LR=0.000100
[2025-08-11 01:01:56,092][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091212] [Batch 02604/03692] [00:23:17/00:09:43, 0.537s/it]: train_loss_raw=0.4793, running_loss=0.4202, LR=0.000100
[2025-08-11 01:02:02,137][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091224] [Batch 02616/03692] [00:23:23/00:09:37, 0.536s/it]: train_loss_raw=0.4395, running_loss=0.4216, LR=0.000100
[2025-08-11 01:02:08,358][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091236] [Batch 02628/03692] [00:23:29/00:09:30, 0.536s/it]: train_loss_raw=0.3747, running_loss=0.4235, LR=0.000100
[2025-08-11 01:02:14,968][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091248] [Batch 02640/03692] [00:23:36/00:09:24, 0.536s/it]: train_loss_raw=0.5050, running_loss=0.4219, LR=0.000100
[2025-08-11 01:02:21,304][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091260] [Batch 02652/03692] [00:23:42/00:09:17, 0.536s/it]: train_loss_raw=0.5181, running_loss=0.4210, LR=0.000100
[2025-08-11 01:02:27,852][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091272] [Batch 02664/03692] [00:23:49/00:09:11, 0.536s/it]: train_loss_raw=0.4441, running_loss=0.4218, LR=0.000100
[2025-08-11 01:02:34,338][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091284] [Batch 02676/03692] [00:23:55/00:09:05, 0.536s/it]: train_loss_raw=0.4802, running_loss=0.4206, LR=0.000100
[2025-08-11 01:02:40,897][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091296] [Batch 02688/03692] [00:24:02/00:08:58, 0.537s/it]: train_loss_raw=0.3791, running_loss=0.4184, LR=0.000100
[2025-08-11 01:02:47,363][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091308] [Batch 02700/03692] [00:24:08/00:08:52, 0.537s/it]: train_loss_raw=0.4906, running_loss=0.4208, LR=0.000100
[2025-08-11 01:02:53,881][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091320] [Batch 02712/03692] [00:24:15/00:08:45, 0.537s/it]: train_loss_raw=0.4602, running_loss=0.4222, LR=0.000100
[2025-08-11 01:03:00,298][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091332] [Batch 02724/03692] [00:24:21/00:08:39, 0.537s/it]: train_loss_raw=0.4085, running_loss=0.4183, LR=0.000100
[2025-08-11 01:03:06,759][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091344] [Batch 02736/03692] [00:24:28/00:08:32, 0.537s/it]: train_loss_raw=0.4018, running_loss=0.4143, LR=0.000100
[2025-08-11 01:03:13,288][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091356] [Batch 02748/03692] [00:24:34/00:08:26, 0.537s/it]: train_loss_raw=0.3648, running_loss=0.4128, LR=0.000100
[2025-08-11 01:03:19,691][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091368] [Batch 02760/03692] [00:24:41/00:08:20, 0.537s/it]: train_loss_raw=0.4344, running_loss=0.4182, LR=0.000100
[2025-08-11 01:03:26,130][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091380] [Batch 02772/03692] [00:24:47/00:08:13, 0.537s/it]: train_loss_raw=0.4336, running_loss=0.4168, LR=0.000100
[2025-08-11 01:03:32,472][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091392] [Batch 02784/03692] [00:24:53/00:08:07, 0.537s/it]: train_loss_raw=0.4596, running_loss=0.4159, LR=0.000100
[2025-08-11 01:03:38,863][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091404] [Batch 02796/03692] [00:25:00/00:08:00, 0.537s/it]: train_loss_raw=0.4563, running_loss=0.4184, LR=0.000100
[2025-08-11 01:03:45,252][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091416] [Batch 02808/03692] [00:25:06/00:07:54, 0.537s/it]: train_loss_raw=0.4309, running_loss=0.4158, LR=0.000100
[2025-08-11 01:03:51,597][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091428] [Batch 02820/03692] [00:25:12/00:07:47, 0.536s/it]: train_loss_raw=0.4448, running_loss=0.4163, LR=0.000100
[2025-08-11 01:03:57,968][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091440] [Batch 02832/03692] [00:25:19/00:07:41, 0.536s/it]: train_loss_raw=0.3683, running_loss=0.4153, LR=0.000100
[2025-08-11 01:04:04,385][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091452] [Batch 02844/03692] [00:25:25/00:07:34, 0.536s/it]: train_loss_raw=0.3887, running_loss=0.4134, LR=0.000100
[2025-08-11 01:04:10,766][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091464] [Batch 02856/03692] [00:25:32/00:07:28, 0.536s/it]: train_loss_raw=0.4489, running_loss=0.4144, LR=0.000100
[2025-08-11 01:04:17,193][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091476] [Batch 02868/03692] [00:25:38/00:07:22, 0.536s/it]: train_loss_raw=0.4221, running_loss=0.4133, LR=0.000100
[2025-08-11 01:04:23,576][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091488] [Batch 02880/03692] [00:25:44/00:07:15, 0.536s/it]: train_loss_raw=0.3882, running_loss=0.4158, LR=0.000100
[2025-08-11 01:04:29,980][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091500] [Batch 02892/03692] [00:25:51/00:07:09, 0.536s/it]: train_loss_raw=0.3589, running_loss=0.4138, LR=0.000100
[2025-08-11 01:04:36,409][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091512] [Batch 02904/03692] [00:25:57/00:07:02, 0.536s/it]: train_loss_raw=0.4386, running_loss=0.4169, LR=0.000100
[2025-08-11 01:04:42,803][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091524] [Batch 02916/03692] [00:26:04/00:06:56, 0.536s/it]: train_loss_raw=0.4472, running_loss=0.4191, LR=0.000100
[2025-08-11 01:04:49,221][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091536] [Batch 02928/03692] [00:26:10/00:06:49, 0.536s/it]: train_loss_raw=0.5340, running_loss=0.4214, LR=0.000100
[2025-08-11 01:04:55,595][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091548] [Batch 02940/03692] [00:26:16/00:06:43, 0.536s/it]: train_loss_raw=0.4211, running_loss=0.4162, LR=0.000100
[2025-08-11 01:05:02,110][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091560] [Batch 02952/03692] [00:26:23/00:06:36, 0.536s/it]: train_loss_raw=0.4131, running_loss=0.4184, LR=0.000100
[2025-08-11 01:05:08,261][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091572] [Batch 02964/03692] [00:26:29/00:06:30, 0.536s/it]: train_loss_raw=0.4475, running_loss=0.4212, LR=0.000100
[2025-08-11 01:05:14,794][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091584] [Batch 02976/03692] [00:26:36/00:06:24, 0.536s/it]: train_loss_raw=0.4732, running_loss=0.4202, LR=0.000100
[2025-08-11 01:05:21,321][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091596] [Batch 02988/03692] [00:26:42/00:06:17, 0.536s/it]: train_loss_raw=0.3018, running_loss=0.4218, LR=0.000100
[2025-08-11 01:05:27,701][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091608] [Batch 03000/03692] [00:26:49/00:06:11, 0.536s/it]: train_loss_raw=0.4158, running_loss=0.4216, LR=0.000100
[2025-08-11 01:05:34,058][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091620] [Batch 03012/03692] [00:26:55/00:06:04, 0.536s/it]: train_loss_raw=0.4141, running_loss=0.4240, LR=0.000100
[2025-08-11 01:05:40,402][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091632] [Batch 03024/03692] [00:27:01/00:05:58, 0.536s/it]: train_loss_raw=0.3108, running_loss=0.4199, LR=0.000100
[2025-08-11 01:05:46,811][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091644] [Batch 03036/03692] [00:27:08/00:05:51, 0.536s/it]: train_loss_raw=0.4159, running_loss=0.4190, LR=0.000100
[2025-08-11 01:05:53,287][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091656] [Batch 03048/03692] [00:27:14/00:05:45, 0.536s/it]: train_loss_raw=0.3983, running_loss=0.4197, LR=0.000100
[2025-08-11 01:05:59,681][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091668] [Batch 03060/03692] [00:27:20/00:05:38, 0.536s/it]: train_loss_raw=0.3539, running_loss=0.4181, LR=0.000100
[2025-08-11 01:06:06,075][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091680] [Batch 03072/03692] [00:27:27/00:05:32, 0.536s/it]: train_loss_raw=0.4375, running_loss=0.4176, LR=0.000100
[2025-08-11 01:06:12,501][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091692] [Batch 03084/03692] [00:27:33/00:05:26, 0.536s/it]: train_loss_raw=0.3629, running_loss=0.4161, LR=0.000100
[2025-08-11 01:06:18,868][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091704] [Batch 03096/03692] [00:27:40/00:05:19, 0.536s/it]: train_loss_raw=0.3401, running_loss=0.4140, LR=0.000100
[2025-08-11 01:06:25,303][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091716] [Batch 03108/03692] [00:27:46/00:05:13, 0.536s/it]: train_loss_raw=0.4170, running_loss=0.4117, LR=0.000100
[2025-08-11 01:06:31,880][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091728] [Batch 03120/03692] [00:27:53/00:05:06, 0.536s/it]: train_loss_raw=0.4007, running_loss=0.4152, LR=0.000100
[2025-08-11 01:06:38,434][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091740] [Batch 03132/03692] [00:27:59/00:05:00, 0.536s/it]: train_loss_raw=0.3729, running_loss=0.4160, LR=0.000100
[2025-08-11 01:06:45,001][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091752] [Batch 03144/03692] [00:28:06/00:04:53, 0.536s/it]: train_loss_raw=0.3654, running_loss=0.4125, LR=0.000100
[2025-08-11 01:06:51,386][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091764] [Batch 03156/03692] [00:28:12/00:04:47, 0.536s/it]: train_loss_raw=0.4202, running_loss=0.4092, LR=0.000100
[2025-08-11 01:06:57,757][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091776] [Batch 03168/03692] [00:28:19/00:04:41, 0.536s/it]: train_loss_raw=0.5301, running_loss=0.4137, LR=0.000100
[2025-08-11 01:07:04,198][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091788] [Batch 03180/03692] [00:28:25/00:04:34, 0.536s/it]: train_loss_raw=0.3397, running_loss=0.4137, LR=0.000100
[2025-08-11 01:07:10,604][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091800] [Batch 03192/03692] [00:28:31/00:04:28, 0.536s/it]: train_loss_raw=0.4269, running_loss=0.4123, LR=0.000100
[2025-08-11 01:07:17,248][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091812] [Batch 03204/03692] [00:28:38/00:04:21, 0.536s/it]: train_loss_raw=0.4585, running_loss=0.4118, LR=0.000100
[2025-08-11 01:07:23,650][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091824] [Batch 03216/03692] [00:28:44/00:04:15, 0.536s/it]: train_loss_raw=0.3914, running_loss=0.4139, LR=0.000100
[2025-08-11 01:07:30,059][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091836] [Batch 03228/03692] [00:28:51/00:04:08, 0.536s/it]: train_loss_raw=0.3838, running_loss=0.4106, LR=0.000100
[2025-08-11 01:07:36,448][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091848] [Batch 03240/03692] [00:28:57/00:04:02, 0.536s/it]: train_loss_raw=0.3499, running_loss=0.4073, LR=0.000100
[2025-08-11 01:07:42,756][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091860] [Batch 03252/03692] [00:29:04/00:03:55, 0.536s/it]: train_loss_raw=0.4104, running_loss=0.4111, LR=0.000100
[2025-08-11 01:07:49,222][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091872] [Batch 03264/03692] [00:29:10/00:03:49, 0.536s/it]: train_loss_raw=0.4652, running_loss=0.4123, LR=0.000100
[2025-08-11 01:07:55,585][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091884] [Batch 03276/03692] [00:29:16/00:03:43, 0.536s/it]: train_loss_raw=0.4949, running_loss=0.4121, LR=0.000100
[2025-08-11 01:08:01,728][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091896] [Batch 03288/03692] [00:29:23/00:03:36, 0.536s/it]: train_loss_raw=0.3895, running_loss=0.4107, LR=0.000100
[2025-08-11 01:08:08,259][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091908] [Batch 03300/03692] [00:29:29/00:03:30, 0.536s/it]: train_loss_raw=0.3836, running_loss=0.4108, LR=0.000100
[2025-08-11 01:08:14,759][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091920] [Batch 03312/03692] [00:29:36/00:03:23, 0.536s/it]: train_loss_raw=0.3204, running_loss=0.4094, LR=0.000100
[2025-08-11 01:08:21,209][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091932] [Batch 03324/03692] [00:29:42/00:03:17, 0.536s/it]: train_loss_raw=0.5254, running_loss=0.4107, LR=0.000100
[2025-08-11 01:08:27,627][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091944] [Batch 03336/03692] [00:29:48/00:03:10, 0.536s/it]: train_loss_raw=0.3840, running_loss=0.4135, LR=0.000100
[2025-08-11 01:08:34,019][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091956] [Batch 03348/03692] [00:29:55/00:03:04, 0.536s/it]: train_loss_raw=0.4776, running_loss=0.4139, LR=0.000100
[2025-08-11 01:08:40,311][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091968] [Batch 03360/03692] [00:30:01/00:02:58, 0.536s/it]: train_loss_raw=0.4535, running_loss=0.4135, LR=0.000100
[2025-08-11 01:08:46,689][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091980] [Batch 03372/03692] [00:30:08/00:02:51, 0.536s/it]: train_loss_raw=0.4492, running_loss=0.4131, LR=0.000100
[2025-08-11 01:08:53,164][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 091992] [Batch 03384/03692] [00:30:14/00:02:45, 0.536s/it]: train_loss_raw=0.3379, running_loss=0.4131, LR=0.000100
[2025-08-11 01:09:04,280][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092004] [Batch 03396/03692] [00:30:25/00:02:39, 0.538s/it]: train_loss_raw=0.3381, running_loss=0.4145, LR=0.000100
[2025-08-11 01:09:10,447][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092016] [Batch 03408/03692] [00:30:31/00:02:32, 0.537s/it]: train_loss_raw=0.4053, running_loss=0.4142, LR=0.000100
[2025-08-11 01:09:16,952][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092028] [Batch 03420/03692] [00:30:38/00:02:26, 0.538s/it]: train_loss_raw=0.4723, running_loss=0.4144, LR=0.000100
[2025-08-11 01:09:23,464][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092040] [Batch 03432/03692] [00:30:44/00:02:19, 0.538s/it]: train_loss_raw=0.4178, running_loss=0.4133, LR=0.000100
[2025-08-11 01:09:29,838][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092052] [Batch 03444/03692] [00:30:51/00:02:13, 0.538s/it]: train_loss_raw=0.4235, running_loss=0.4152, LR=0.000100
[2025-08-11 01:09:35,948][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092064] [Batch 03456/03692] [00:30:57/00:02:06, 0.537s/it]: train_loss_raw=0.3106, running_loss=0.4132, LR=0.000100
[2025-08-11 01:09:42,484][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092076] [Batch 03468/03692] [00:31:03/00:02:00, 0.537s/it]: train_loss_raw=0.3338, running_loss=0.4140, LR=0.000100
[2025-08-11 01:09:48,943][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092088] [Batch 03480/03692] [00:31:10/00:01:53, 0.537s/it]: train_loss_raw=0.3610, running_loss=0.4125, LR=0.000100
[2025-08-11 01:09:55,523][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092100] [Batch 03492/03692] [00:31:16/00:01:47, 0.537s/it]: train_loss_raw=0.3402, running_loss=0.4132, LR=0.000100
[2025-08-11 01:10:01,844][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092112] [Batch 03504/03692] [00:31:23/00:01:41, 0.537s/it]: train_loss_raw=0.4423, running_loss=0.4124, LR=0.000100
[2025-08-11 01:10:08,129][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092124] [Batch 03516/03692] [00:31:29/00:01:34, 0.537s/it]: train_loss_raw=0.4341, running_loss=0.4092, LR=0.000100
[2025-08-11 01:10:14,146][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092136] [Batch 03528/03692] [00:31:35/00:01:28, 0.537s/it]: train_loss_raw=0.4199, running_loss=0.4091, LR=0.000100
[2025-08-11 01:10:20,198][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092148] [Batch 03540/03692] [00:31:41/00:01:21, 0.537s/it]: train_loss_raw=0.4259, running_loss=0.4098, LR=0.000100
[2025-08-11 01:10:26,217][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092160] [Batch 03552/03692] [00:31:47/00:01:15, 0.537s/it]: train_loss_raw=0.4523, running_loss=0.4108, LR=0.000100
[2025-08-11 01:10:32,670][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092172] [Batch 03564/03692] [00:31:53/00:01:08, 0.537s/it]: train_loss_raw=0.4093, running_loss=0.4109, LR=0.000100
[2025-08-11 01:10:38,769][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092184] [Batch 03576/03692] [00:32:00/00:01:02, 0.537s/it]: train_loss_raw=0.5189, running_loss=0.4123, LR=0.000100
[2025-08-11 01:10:45,218][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092196] [Batch 03588/03692] [00:32:06/00:00:55, 0.537s/it]: train_loss_raw=0.5558, running_loss=0.4132, LR=0.000100
[2025-08-11 01:10:51,613][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092208] [Batch 03600/03692] [00:32:12/00:00:49, 0.537s/it]: train_loss_raw=0.4567, running_loss=0.4123, LR=0.000100
[2025-08-11 01:10:58,178][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092220] [Batch 03612/03692] [00:32:19/00:00:42, 0.537s/it]: train_loss_raw=0.3721, running_loss=0.4132, LR=0.000100
[2025-08-11 01:11:04,692][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092232] [Batch 03624/03692] [00:32:26/00:00:36, 0.537s/it]: train_loss_raw=0.4045, running_loss=0.4155, LR=0.000100
[2025-08-11 01:11:11,234][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092244] [Batch 03636/03692] [00:32:32/00:00:30, 0.537s/it]: train_loss_raw=0.3432, running_loss=0.4173, LR=0.000100
[2025-08-11 01:11:17,772][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092256] [Batch 03648/03692] [00:32:39/00:00:23, 0.537s/it]: train_loss_raw=0.3431, running_loss=0.4179, LR=0.000100
[2025-08-11 01:11:24,178][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092268] [Batch 03660/03692] [00:32:45/00:00:17, 0.537s/it]: train_loss_raw=0.4242, running_loss=0.4217, LR=0.000100
[2025-08-11 01:11:30,565][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092280] [Batch 03672/03692] [00:32:51/00:00:10, 0.537s/it]: train_loss_raw=0.4614, running_loss=0.4231, LR=0.000100
[2025-08-11 01:11:36,977][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 092292] [Batch 03684/03692] [00:32:58/00:00:04, 0.537s/it]: train_loss_raw=0.3247, running_loss=0.4228, LR=0.000100
[2025-08-11 01:11:46,271][__main__][INFO] - [VALIDATION] [Epoch 24/29] Starting validation.
[2025-08-11 01:12:19,305][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 092301] [Batch 00011/00025] [00:00:33/00:00:35, 2.753s/it]
[2025-08-11 01:12:35,433][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 092301] [Batch 00023/00025] [00:00:49/00:00:02, 2.048s/it]
[2025-08-11 01:12:36,551][__main__][INFO] - [VALIDATION] [Epoch 24/29] train_loss=0.42112, valid_loss=0.59079
[2025-08-11 01:12:36,551][__main__][INFO] - [VALIDATION] [Epoch 24/29] Metrics:
[2025-08-11 01:12:36,551][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_er      0.234
[2025-08-11 01:12:36,552][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_prec    0.547
[2025-08-11 01:12:36,552][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_recall  0.553
[2025-08-11 01:12:36,552][__main__][INFO] - [VALIDATION] [Epoch 24/29] - pep_recall 0.532
[2025-08-11 01:12:36,555][__main__][INFO] - [TRAIN] [Epoch 24/29] Epoch complete, total time 14:16:35, remaining time 02:51:19, 00:34:15 per epoch
[2025-08-11 01:12:38,586][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092304] [Batch 00004/03692] [00:00:01/00:26:58, 0.439s/it]: train_loss_raw=0.4765, running_loss=0.4193, LR=0.000100
[2025-08-11 01:12:45,210][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092316] [Batch 00016/03692] [00:00:08/00:32:05, 0.524s/it]: train_loss_raw=0.4246, running_loss=0.4200, LR=0.000100
[2025-08-11 01:12:51,710][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092328] [Batch 00028/03692] [00:00:14/00:32:26, 0.531s/it]: train_loss_raw=0.5006, running_loss=0.4212, LR=0.000100
[2025-08-11 01:12:58,198][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092340] [Batch 00040/03692] [00:00:21/00:32:30, 0.534s/it]: train_loss_raw=0.4648, running_loss=0.4209, LR=0.000100
[2025-08-11 01:13:04,579][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092352] [Batch 00052/03692] [00:00:27/00:32:22, 0.534s/it]: train_loss_raw=0.3862, running_loss=0.4209, LR=0.000100
[2025-08-11 01:13:10,780][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092364] [Batch 00064/03692] [00:00:33/00:32:04, 0.530s/it]: train_loss_raw=0.5011, running_loss=0.4244, LR=0.000100
[2025-08-11 01:13:17,015][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092376] [Batch 00076/03692] [00:00:40/00:31:51, 0.529s/it]: train_loss_raw=0.4222, running_loss=0.4230, LR=0.000100
[2025-08-11 01:13:23,039][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092388] [Batch 00088/03692] [00:00:46/00:31:32, 0.525s/it]: train_loss_raw=0.4566, running_loss=0.4215, LR=0.000100
[2025-08-11 01:13:29,087][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092400] [Batch 00100/03692] [00:00:52/00:31:17, 0.523s/it]: train_loss_raw=0.3302, running_loss=0.4199, LR=0.000100
[2025-08-11 01:13:35,145][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092412] [Batch 00112/03692] [00:00:58/00:31:03, 0.521s/it]: train_loss_raw=0.4619, running_loss=0.4173, LR=0.000100
[2025-08-11 01:13:41,210][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092424] [Batch 00124/03692] [00:01:04/00:30:52, 0.519s/it]: train_loss_raw=0.3353, running_loss=0.4175, LR=0.000100
[2025-08-11 01:13:47,202][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092436] [Batch 00136/03692] [00:01:10/00:30:39, 0.517s/it]: train_loss_raw=0.4612, running_loss=0.4163, LR=0.000100
[2025-08-11 01:13:53,389][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092448] [Batch 00148/03692] [00:01:16/00:30:33, 0.517s/it]: train_loss_raw=0.4623, running_loss=0.4178, LR=0.000100
[2025-08-11 01:13:59,512][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092460] [Batch 00160/03692] [00:01:22/00:30:25, 0.517s/it]: train_loss_raw=0.4948, running_loss=0.4209, LR=0.000100
[2025-08-11 01:14:05,509][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092472] [Batch 00172/03692] [00:01:28/00:30:14, 0.516s/it]: train_loss_raw=0.4011, running_loss=0.4221, LR=0.000100
[2025-08-11 01:14:11,471][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092484] [Batch 00184/03692] [00:01:34/00:30:04, 0.514s/it]: train_loss_raw=0.3782, running_loss=0.4207, LR=0.000100
[2025-08-11 01:14:17,481][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092496] [Batch 00196/03692] [00:01:40/00:29:55, 0.514s/it]: train_loss_raw=0.4179, running_loss=0.4204, LR=0.000100
[2025-08-11 01:14:23,552][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092508] [Batch 00208/03692] [00:01:46/00:29:47, 0.513s/it]: train_loss_raw=0.3627, running_loss=0.4155, LR=0.000100
[2025-08-11 01:14:29,666][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092520] [Batch 00220/03692] [00:01:52/00:29:40, 0.513s/it]: train_loss_raw=0.4111, running_loss=0.4161, LR=0.000100
[2025-08-11 01:14:35,714][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092532] [Batch 00232/03692] [00:01:58/00:29:32, 0.512s/it]: train_loss_raw=0.4001, running_loss=0.4141, LR=0.000100
[2025-08-11 01:14:41,806][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092544] [Batch 00244/03692] [00:02:04/00:29:26, 0.512s/it]: train_loss_raw=0.4410, running_loss=0.4128, LR=0.000100
[2025-08-11 01:14:48,106][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092556] [Batch 00256/03692] [00:02:11/00:29:21, 0.513s/it]: train_loss_raw=0.4529, running_loss=0.4133, LR=0.000100
[2025-08-11 01:14:54,327][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092568] [Batch 00268/03692] [00:02:17/00:29:16, 0.513s/it]: train_loss_raw=0.4905, running_loss=0.4128, LR=0.000100
[2025-08-11 01:15:00,736][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092580] [Batch 00280/03692] [00:02:23/00:29:13, 0.514s/it]: train_loss_raw=0.3520, running_loss=0.4123, LR=0.000100
[2025-08-11 01:15:06,902][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092592] [Batch 00292/03692] [00:02:30/00:29:07, 0.514s/it]: train_loss_raw=0.3626, running_loss=0.4135, LR=0.000100
[2025-08-11 01:15:13,370][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092604] [Batch 00304/03692] [00:02:36/00:29:04, 0.515s/it]: train_loss_raw=0.4194, running_loss=0.4120, LR=0.000100
[2025-08-11 01:15:19,532][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092616] [Batch 00316/03692] [00:02:42/00:28:58, 0.515s/it]: train_loss_raw=0.4474, running_loss=0.4134, LR=0.000100
[2025-08-11 01:15:25,574][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092628] [Batch 00328/03692] [00:02:48/00:28:50, 0.514s/it]: train_loss_raw=0.4881, running_loss=0.4137, LR=0.000100
[2025-08-11 01:15:31,636][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092640] [Batch 00340/03692] [00:02:54/00:28:43, 0.514s/it]: train_loss_raw=0.3120, running_loss=0.4116, LR=0.000100
[2025-08-11 01:15:37,607][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092652] [Batch 00352/03692] [00:03:00/00:28:35, 0.514s/it]: train_loss_raw=0.3740, running_loss=0.4133, LR=0.000100
[2025-08-11 01:15:43,628][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092664] [Batch 00364/03692] [00:03:06/00:28:27, 0.513s/it]: train_loss_raw=0.4922, running_loss=0.4156, LR=0.000100
[2025-08-11 01:15:49,799][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092676] [Batch 00376/03692] [00:03:12/00:28:21, 0.513s/it]: train_loss_raw=0.4094, running_loss=0.4152, LR=0.000100
[2025-08-11 01:15:56,200][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092688] [Batch 00388/03692] [00:03:19/00:28:17, 0.514s/it]: train_loss_raw=0.4553, running_loss=0.4122, LR=0.000100
[2025-08-11 01:16:02,627][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092700] [Batch 00400/03692] [00:03:25/00:28:13, 0.514s/it]: train_loss_raw=0.3870, running_loss=0.4129, LR=0.000100
[2025-08-11 01:16:09,132][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092712] [Batch 00412/03692] [00:03:32/00:28:10, 0.515s/it]: train_loss_raw=0.4053, running_loss=0.4124, LR=0.000100
[2025-08-11 01:16:15,543][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092724] [Batch 00424/03692] [00:03:38/00:28:05, 0.516s/it]: train_loss_raw=0.3902, running_loss=0.4139, LR=0.000100
[2025-08-11 01:16:21,939][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092736] [Batch 00436/03692] [00:03:45/00:28:01, 0.516s/it]: train_loss_raw=0.4143, running_loss=0.4168, LR=0.000100
[2025-08-11 01:16:28,438][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092748] [Batch 00448/03692] [00:03:51/00:27:57, 0.517s/it]: train_loss_raw=0.4050, running_loss=0.4165, LR=0.000100
[2025-08-11 01:16:34,797][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092760] [Batch 00460/03692] [00:03:57/00:27:51, 0.517s/it]: train_loss_raw=0.4136, running_loss=0.4199, LR=0.000100
[2025-08-11 01:16:41,160][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092772] [Batch 00472/03692] [00:04:04/00:27:46, 0.518s/it]: train_loss_raw=0.4110, running_loss=0.4198, LR=0.000100
[2025-08-11 01:16:47,581][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092784] [Batch 00484/03692] [00:04:10/00:27:41, 0.518s/it]: train_loss_raw=0.4575, running_loss=0.4190, LR=0.000100
[2025-08-11 01:16:53,974][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092796] [Batch 00496/03692] [00:04:17/00:27:36, 0.518s/it]: train_loss_raw=0.3252, running_loss=0.4149, LR=0.000100
[2025-08-11 01:17:00,377][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092808] [Batch 00508/03692] [00:04:23/00:27:31, 0.519s/it]: train_loss_raw=0.4328, running_loss=0.4168, LR=0.000100
[2025-08-11 01:17:06,646][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092820] [Batch 00520/03692] [00:04:29/00:27:25, 0.519s/it]: train_loss_raw=0.3598, running_loss=0.4163, LR=0.000100
[2025-08-11 01:17:13,014][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092832] [Batch 00532/03692] [00:04:36/00:27:20, 0.519s/it]: train_loss_raw=0.4549, running_loss=0.4172, LR=0.000100
[2025-08-11 01:17:19,377][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092844] [Batch 00544/03692] [00:04:42/00:27:15, 0.519s/it]: train_loss_raw=0.4230, running_loss=0.4173, LR=0.000100
[2025-08-11 01:17:25,808][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092856] [Batch 00556/03692] [00:04:48/00:27:09, 0.520s/it]: train_loss_raw=0.5098, running_loss=0.4182, LR=0.000100
[2025-08-11 01:17:32,190][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092868] [Batch 00568/03692] [00:04:55/00:27:04, 0.520s/it]: train_loss_raw=0.3920, running_loss=0.4160, LR=0.000100
[2025-08-11 01:17:38,538][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092880] [Batch 00580/03692] [00:05:01/00:26:58, 0.520s/it]: train_loss_raw=0.4244, running_loss=0.4151, LR=0.000100
[2025-08-11 01:17:44,967][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092892] [Batch 00592/03692] [00:05:08/00:26:53, 0.520s/it]: train_loss_raw=0.3620, running_loss=0.4162, LR=0.000100
[2025-08-11 01:17:51,379][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092904] [Batch 00604/03692] [00:05:14/00:26:48, 0.521s/it]: train_loss_raw=0.5151, running_loss=0.4175, LR=0.000100
[2025-08-11 01:17:57,768][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092916] [Batch 00616/03692] [00:05:20/00:26:42, 0.521s/it]: train_loss_raw=0.4550, running_loss=0.4188, LR=0.000100
[2025-08-11 01:18:04,262][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092928] [Batch 00628/03692] [00:05:27/00:26:37, 0.521s/it]: train_loss_raw=0.4778, running_loss=0.4203, LR=0.000100
[2025-08-11 01:18:10,486][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092940] [Batch 00640/03692] [00:05:33/00:26:31, 0.521s/it]: train_loss_raw=0.5171, running_loss=0.4191, LR=0.000100
[2025-08-11 01:18:16,954][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092952] [Batch 00652/03692] [00:05:40/00:26:25, 0.522s/it]: train_loss_raw=0.4272, running_loss=0.4180, LR=0.000100
[2025-08-11 01:18:23,289][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092964] [Batch 00664/03692] [00:05:46/00:26:19, 0.522s/it]: train_loss_raw=0.3949, running_loss=0.4191, LR=0.000100
[2025-08-11 01:18:29,656][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092976] [Batch 00676/03692] [00:05:52/00:26:14, 0.522s/it]: train_loss_raw=0.5788, running_loss=0.4204, LR=0.000100
[2025-08-11 01:18:36,141][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 092988] [Batch 00688/03692] [00:05:59/00:26:08, 0.522s/it]: train_loss_raw=0.4199, running_loss=0.4217, LR=0.000100
[2025-08-11 01:18:42,480][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093000] [Batch 00700/03692] [00:06:05/00:26:02, 0.522s/it]: train_loss_raw=0.4521, running_loss=0.4219, LR=0.000100
[2025-08-11 01:18:48,902][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093012] [Batch 00712/03692] [00:06:12/00:25:57, 0.523s/it]: train_loss_raw=0.4778, running_loss=0.4228, LR=0.000100
[2025-08-11 01:18:55,327][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093024] [Batch 00724/03692] [00:06:18/00:25:51, 0.523s/it]: train_loss_raw=0.4397, running_loss=0.4248, LR=0.000100
[2025-08-11 01:19:01,776][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093036] [Batch 00736/03692] [00:06:24/00:25:46, 0.523s/it]: train_loss_raw=0.4071, running_loss=0.4238, LR=0.000100
[2025-08-11 01:19:08,181][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093048] [Batch 00748/03692] [00:06:31/00:25:40, 0.523s/it]: train_loss_raw=0.3629, running_loss=0.4216, LR=0.000100
[2025-08-11 01:19:14,572][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093060] [Batch 00760/03692] [00:06:37/00:25:34, 0.523s/it]: train_loss_raw=0.3977, running_loss=0.4210, LR=0.000100
[2025-08-11 01:19:20,952][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093072] [Batch 00772/03692] [00:06:44/00:25:28, 0.523s/it]: train_loss_raw=0.4392, running_loss=0.4214, LR=0.000100
[2025-08-11 01:19:27,286][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093084] [Batch 00784/03692] [00:06:50/00:25:22, 0.524s/it]: train_loss_raw=0.4538, running_loss=0.4208, LR=0.000100
[2025-08-11 01:19:33,685][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093096] [Batch 00796/03692] [00:06:56/00:25:16, 0.524s/it]: train_loss_raw=0.4651, running_loss=0.4238, LR=0.000100
[2025-08-11 01:19:40,058][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093108] [Batch 00808/03692] [00:07:03/00:25:10, 0.524s/it]: train_loss_raw=0.4194, running_loss=0.4244, LR=0.000100
[2025-08-11 01:19:46,456][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093120] [Batch 00820/03692] [00:07:09/00:25:04, 0.524s/it]: train_loss_raw=0.5295, running_loss=0.4249, LR=0.000100
[2025-08-11 01:19:52,987][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093132] [Batch 00832/03692] [00:07:16/00:24:59, 0.524s/it]: train_loss_raw=0.3722, running_loss=0.4225, LR=0.000100
[2025-08-11 01:19:59,360][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093144] [Batch 00844/03692] [00:07:22/00:24:53, 0.524s/it]: train_loss_raw=0.3623, running_loss=0.4219, LR=0.000100
[2025-08-11 01:20:05,733][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093156] [Batch 00856/03692] [00:07:28/00:24:47, 0.524s/it]: train_loss_raw=0.4793, running_loss=0.4257, LR=0.000100
[2025-08-11 01:20:12,105][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093168] [Batch 00868/03692] [00:07:35/00:24:41, 0.525s/it]: train_loss_raw=0.4261, running_loss=0.4276, LR=0.000100
[2025-08-11 01:20:18,491][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093180] [Batch 00880/03692] [00:07:41/00:24:35, 0.525s/it]: train_loss_raw=0.3944, running_loss=0.4258, LR=0.000100
[2025-08-11 01:20:24,956][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093192] [Batch 00892/03692] [00:07:48/00:24:29, 0.525s/it]: train_loss_raw=0.4633, running_loss=0.4266, LR=0.000100
[2025-08-11 01:20:31,503][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093204] [Batch 00904/03692] [00:07:54/00:24:23, 0.525s/it]: train_loss_raw=0.5026, running_loss=0.4275, LR=0.000100
[2025-08-11 01:20:38,025][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093216] [Batch 00916/03692] [00:08:01/00:24:18, 0.525s/it]: train_loss_raw=0.4082, running_loss=0.4277, LR=0.000100
[2025-08-11 01:20:44,493][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093228] [Batch 00928/03692] [00:08:07/00:24:12, 0.525s/it]: train_loss_raw=0.4061, running_loss=0.4256, LR=0.000100
[2025-08-11 01:20:50,882][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093240] [Batch 00940/03692] [00:08:14/00:24:06, 0.526s/it]: train_loss_raw=0.4744, running_loss=0.4255, LR=0.000100
[2025-08-11 01:20:57,252][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093252] [Batch 00952/03692] [00:08:20/00:24:00, 0.526s/it]: train_loss_raw=0.3136, running_loss=0.4244, LR=0.000100
[2025-08-11 01:21:03,589][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093264] [Batch 00964/03692] [00:08:26/00:23:54, 0.526s/it]: train_loss_raw=0.5960, running_loss=0.4231, LR=0.000100
[2025-08-11 01:21:09,940][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093276] [Batch 00976/03692] [00:08:33/00:23:47, 0.526s/it]: train_loss_raw=0.4264, running_loss=0.4224, LR=0.000100
[2025-08-11 01:21:16,269][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093288] [Batch 00988/03692] [00:08:39/00:23:41, 0.526s/it]: train_loss_raw=0.4400, running_loss=0.4232, LR=0.000100
[2025-08-11 01:21:22,705][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093300] [Batch 01000/03692] [00:08:45/00:23:35, 0.526s/it]: train_loss_raw=0.4476, running_loss=0.4234, LR=0.000100
[2025-08-11 01:21:29,068][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093312] [Batch 01012/03692] [00:08:52/00:23:29, 0.526s/it]: train_loss_raw=0.5221, running_loss=0.4240, LR=0.000100
[2025-08-11 01:21:35,539][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093324] [Batch 01024/03692] [00:08:58/00:23:23, 0.526s/it]: train_loss_raw=0.4509, running_loss=0.4211, LR=0.000100
[2025-08-11 01:21:42,021][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093336] [Batch 01036/03692] [00:09:05/00:23:17, 0.526s/it]: train_loss_raw=0.4801, running_loss=0.4217, LR=0.000100
[2025-08-11 01:21:48,505][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093348] [Batch 01048/03692] [00:09:11/00:23:11, 0.526s/it]: train_loss_raw=0.3945, running_loss=0.4201, LR=0.000100
[2025-08-11 01:21:54,975][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093360] [Batch 01060/03692] [00:09:18/00:23:05, 0.527s/it]: train_loss_raw=0.3572, running_loss=0.4201, LR=0.000100
[2025-08-11 01:22:01,324][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093372] [Batch 01072/03692] [00:09:24/00:22:59, 0.527s/it]: train_loss_raw=0.3901, running_loss=0.4211, LR=0.000100
[2025-08-11 01:22:07,845][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093384] [Batch 01084/03692] [00:09:31/00:22:53, 0.527s/it]: train_loss_raw=0.4433, running_loss=0.4203, LR=0.000100
[2025-08-11 01:22:14,375][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093396] [Batch 01096/03692] [00:09:37/00:22:47, 0.527s/it]: train_loss_raw=0.4616, running_loss=0.4225, LR=0.000100
[2025-08-11 01:22:20,712][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093408] [Batch 01108/03692] [00:09:43/00:22:41, 0.527s/it]: train_loss_raw=0.4850, running_loss=0.4220, LR=0.000100
[2025-08-11 01:22:27,174][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093420] [Batch 01120/03692] [00:09:50/00:22:35, 0.527s/it]: train_loss_raw=0.4463, running_loss=0.4229, LR=0.000100
[2025-08-11 01:22:33,597][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093432] [Batch 01132/03692] [00:09:56/00:22:29, 0.527s/it]: train_loss_raw=0.3697, running_loss=0.4212, LR=0.000100
[2025-08-11 01:22:40,078][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093444] [Batch 01144/03692] [00:10:03/00:22:23, 0.527s/it]: train_loss_raw=0.3827, running_loss=0.4211, LR=0.000100
[2025-08-11 01:22:46,126][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093456] [Batch 01156/03692] [00:10:09/00:22:16, 0.527s/it]: train_loss_raw=0.5049, running_loss=0.4198, LR=0.000100
[2025-08-11 01:22:52,490][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093468] [Batch 01168/03692] [00:10:15/00:22:10, 0.527s/it]: train_loss_raw=0.3668, running_loss=0.4168, LR=0.000100
[2025-08-11 01:22:59,038][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093480] [Batch 01180/03692] [00:10:22/00:22:04, 0.527s/it]: train_loss_raw=0.3966, running_loss=0.4161, LR=0.000100
[2025-08-11 01:23:05,266][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093492] [Batch 01192/03692] [00:10:28/00:21:58, 0.527s/it]: train_loss_raw=0.4389, running_loss=0.4149, LR=0.000100
[2025-08-11 01:23:11,351][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093504] [Batch 01204/03692] [00:10:34/00:21:51, 0.527s/it]: train_loss_raw=0.4440, running_loss=0.4151, LR=0.000100
[2025-08-11 01:23:17,895][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093516] [Batch 01216/03692] [00:10:41/00:21:45, 0.527s/it]: train_loss_raw=0.4713, running_loss=0.4156, LR=0.000100
[2025-08-11 01:23:24,155][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093528] [Batch 01228/03692] [00:10:47/00:21:38, 0.527s/it]: train_loss_raw=0.4114, running_loss=0.4162, LR=0.000100
[2025-08-11 01:23:30,173][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093540] [Batch 01240/03692] [00:10:53/00:21:31, 0.527s/it]: train_loss_raw=0.4841, running_loss=0.4190, LR=0.000100
[2025-08-11 01:23:36,177][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093552] [Batch 01252/03692] [00:10:59/00:21:24, 0.527s/it]: train_loss_raw=0.3631, running_loss=0.4176, LR=0.000100
[2025-08-11 01:23:42,164][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093564] [Batch 01264/03692] [00:11:05/00:21:18, 0.526s/it]: train_loss_raw=0.4423, running_loss=0.4209, LR=0.000100
[2025-08-11 01:23:48,208][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093576] [Batch 01276/03692] [00:11:11/00:21:11, 0.526s/it]: train_loss_raw=0.3403, running_loss=0.4211, LR=0.000100
[2025-08-11 01:23:54,276][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093588] [Batch 01288/03692] [00:11:17/00:21:04, 0.526s/it]: train_loss_raw=0.4443, running_loss=0.4209, LR=0.000100
[2025-08-11 01:24:00,331][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093600] [Batch 01300/03692] [00:11:23/00:20:57, 0.526s/it]: train_loss_raw=0.3946, running_loss=0.4160, LR=0.000100
[2025-08-11 01:24:06,376][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093612] [Batch 01312/03692] [00:11:29/00:20:50, 0.526s/it]: train_loss_raw=0.4907, running_loss=0.4151, LR=0.000100
[2025-08-11 01:24:12,475][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093624] [Batch 01324/03692] [00:11:35/00:20:44, 0.525s/it]: train_loss_raw=0.4733, running_loss=0.4174, LR=0.000100
[2025-08-11 01:24:18,549][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093636] [Batch 01336/03692] [00:11:41/00:20:37, 0.525s/it]: train_loss_raw=0.4214, running_loss=0.4173, LR=0.000100
[2025-08-11 01:24:24,627][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093648] [Batch 01348/03692] [00:11:47/00:20:30, 0.525s/it]: train_loss_raw=0.4246, running_loss=0.4182, LR=0.000100
[2025-08-11 01:24:30,956][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093660] [Batch 01360/03692] [00:11:54/00:20:24, 0.525s/it]: train_loss_raw=0.3699, running_loss=0.4188, LR=0.000100
[2025-08-11 01:24:36,972][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093672] [Batch 01372/03692] [00:12:00/00:20:17, 0.525s/it]: train_loss_raw=0.3637, running_loss=0.4170, LR=0.000100
[2025-08-11 01:24:43,012][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093684] [Batch 01384/03692] [00:12:06/00:20:11, 0.525s/it]: train_loss_raw=0.3744, running_loss=0.4165, LR=0.000100
[2025-08-11 01:24:49,377][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093696] [Batch 01396/03692] [00:12:12/00:20:04, 0.525s/it]: train_loss_raw=0.5101, running_loss=0.4182, LR=0.000100
[2025-08-11 01:24:55,393][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093708] [Batch 01408/03692] [00:12:18/00:19:58, 0.525s/it]: train_loss_raw=0.6001, running_loss=0.4152, LR=0.000100
[2025-08-11 01:25:01,473][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093720] [Batch 01420/03692] [00:12:24/00:19:51, 0.524s/it]: train_loss_raw=0.4751, running_loss=0.4153, LR=0.000100
[2025-08-11 01:25:07,836][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093732] [Batch 01432/03692] [00:12:31/00:19:45, 0.524s/it]: train_loss_raw=0.5354, running_loss=0.4170, LR=0.000100
[2025-08-11 01:25:14,353][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093744] [Batch 01444/03692] [00:12:37/00:19:39, 0.525s/it]: train_loss_raw=0.4952, running_loss=0.4186, LR=0.000100
[2025-08-11 01:25:20,886][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093756] [Batch 01456/03692] [00:12:44/00:19:33, 0.525s/it]: train_loss_raw=0.3968, running_loss=0.4188, LR=0.000100
[2025-08-11 01:25:27,366][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093768] [Batch 01468/03692] [00:12:50/00:19:27, 0.525s/it]: train_loss_raw=0.4950, running_loss=0.4189, LR=0.000100
[2025-08-11 01:25:33,435][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093780] [Batch 01480/03692] [00:12:56/00:19:20, 0.525s/it]: train_loss_raw=0.5146, running_loss=0.4196, LR=0.000100
[2025-08-11 01:25:39,486][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093792] [Batch 01492/03692] [00:13:02/00:19:14, 0.525s/it]: train_loss_raw=0.3556, running_loss=0.4159, LR=0.000100
[2025-08-11 01:25:45,546][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093804] [Batch 01504/03692] [00:13:08/00:19:07, 0.524s/it]: train_loss_raw=0.4039, running_loss=0.4137, LR=0.000100
[2025-08-11 01:25:51,533][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093816] [Batch 01516/03692] [00:13:14/00:19:00, 0.524s/it]: train_loss_raw=0.3122, running_loss=0.4132, LR=0.000100
[2025-08-11 01:25:57,613][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093828] [Batch 01528/03692] [00:13:20/00:18:54, 0.524s/it]: train_loss_raw=0.3624, running_loss=0.4145, LR=0.000100
[2025-08-11 01:26:03,708][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093840] [Batch 01540/03692] [00:13:26/00:18:47, 0.524s/it]: train_loss_raw=0.4515, running_loss=0.4142, LR=0.000100
[2025-08-11 01:26:09,808][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093852] [Batch 01552/03692] [00:13:32/00:18:40, 0.524s/it]: train_loss_raw=0.3538, running_loss=0.4127, LR=0.000100
[2025-08-11 01:26:15,909][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093864] [Batch 01564/03692] [00:13:39/00:18:34, 0.524s/it]: train_loss_raw=0.3591, running_loss=0.4148, LR=0.000100
[2025-08-11 01:26:21,961][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093876] [Batch 01576/03692] [00:13:45/00:18:27, 0.524s/it]: train_loss_raw=0.3632, running_loss=0.4162, LR=0.000100
[2025-08-11 01:26:27,984][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093888] [Batch 01588/03692] [00:13:51/00:18:21, 0.523s/it]: train_loss_raw=0.3962, running_loss=0.4181, LR=0.000100
[2025-08-11 01:26:34,022][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093900] [Batch 01600/03692] [00:13:57/00:18:14, 0.523s/it]: train_loss_raw=0.4445, running_loss=0.4166, LR=0.000100
[2025-08-11 01:26:40,056][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093912] [Batch 01612/03692] [00:14:03/00:18:08, 0.523s/it]: train_loss_raw=0.4548, running_loss=0.4179, LR=0.000100
[2025-08-11 01:26:46,090][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093924] [Batch 01624/03692] [00:14:09/00:18:01, 0.523s/it]: train_loss_raw=0.4198, running_loss=0.4164, LR=0.000100
[2025-08-11 01:26:52,123][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093936] [Batch 01636/03692] [00:14:15/00:17:54, 0.523s/it]: train_loss_raw=0.4171, running_loss=0.4184, LR=0.000100
[2025-08-11 01:26:58,345][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093948] [Batch 01648/03692] [00:14:21/00:17:48, 0.523s/it]: train_loss_raw=0.3831, running_loss=0.4185, LR=0.000100
[2025-08-11 01:27:04,425][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093960] [Batch 01660/03692] [00:14:27/00:17:42, 0.523s/it]: train_loss_raw=0.4128, running_loss=0.4174, LR=0.000100
[2025-08-11 01:27:10,414][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093972] [Batch 01672/03692] [00:14:33/00:17:35, 0.522s/it]: train_loss_raw=0.3906, running_loss=0.4191, LR=0.000100
[2025-08-11 01:27:16,455][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093984] [Batch 01684/03692] [00:14:39/00:17:28, 0.522s/it]: train_loss_raw=0.4185, running_loss=0.4171, LR=0.000100
[2025-08-11 01:27:22,463][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 093996] [Batch 01696/03692] [00:14:45/00:17:22, 0.522s/it]: train_loss_raw=0.3634, running_loss=0.4166, LR=0.000100
[2025-08-11 01:27:32,939][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094008] [Batch 01708/03692] [00:14:56/00:17:20, 0.525s/it]: train_loss_raw=0.2609, running_loss=0.4187, LR=0.000100
[2025-08-11 01:27:38,910][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094020] [Batch 01720/03692] [00:15:02/00:17:14, 0.524s/it]: train_loss_raw=0.4227, running_loss=0.4188, LR=0.000100
[2025-08-11 01:27:44,924][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094032] [Batch 01732/03692] [00:15:08/00:17:07, 0.524s/it]: train_loss_raw=0.3816, running_loss=0.4167, LR=0.000100
[2025-08-11 01:27:50,924][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094044] [Batch 01744/03692] [00:15:14/00:17:01, 0.524s/it]: train_loss_raw=0.3731, running_loss=0.4156, LR=0.000100
[2025-08-11 01:27:57,112][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094056] [Batch 01756/03692] [00:15:20/00:16:54, 0.524s/it]: train_loss_raw=0.4142, running_loss=0.4130, LR=0.000100
[2025-08-11 01:28:03,629][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094068] [Batch 01768/03692] [00:15:26/00:16:48, 0.524s/it]: train_loss_raw=0.4032, running_loss=0.4129, LR=0.000100
[2025-08-11 01:28:10,170][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094080] [Batch 01780/03692] [00:15:33/00:16:42, 0.524s/it]: train_loss_raw=0.5067, running_loss=0.4138, LR=0.000100
[2025-08-11 01:28:16,508][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094092] [Batch 01792/03692] [00:15:39/00:16:36, 0.524s/it]: train_loss_raw=0.4431, running_loss=0.4133, LR=0.000100
[2025-08-11 01:28:22,735][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094104] [Batch 01804/03692] [00:15:45/00:16:29, 0.524s/it]: train_loss_raw=0.4067, running_loss=0.4151, LR=0.000100
[2025-08-11 01:28:29,041][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094116] [Batch 01816/03692] [00:15:52/00:16:23, 0.524s/it]: train_loss_raw=0.4291, running_loss=0.4156, LR=0.000100
[2025-08-11 01:28:35,164][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094128] [Batch 01828/03692] [00:15:58/00:16:17, 0.524s/it]: train_loss_raw=0.4223, running_loss=0.4138, LR=0.000100
[2025-08-11 01:28:41,259][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094140] [Batch 01840/03692] [00:16:04/00:16:10, 0.524s/it]: train_loss_raw=0.4250, running_loss=0.4095, LR=0.000100
[2025-08-11 01:28:47,523][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094152] [Batch 01852/03692] [00:16:10/00:16:04, 0.524s/it]: train_loss_raw=0.5632, running_loss=0.4136, LR=0.000100
[2025-08-11 01:28:53,844][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094164] [Batch 01864/03692] [00:16:17/00:15:58, 0.524s/it]: train_loss_raw=0.4864, running_loss=0.4156, LR=0.000100
[2025-08-11 01:28:59,890][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094176] [Batch 01876/03692] [00:16:23/00:15:51, 0.524s/it]: train_loss_raw=0.4311, running_loss=0.4148, LR=0.000100
[2025-08-11 01:29:05,985][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094188] [Batch 01888/03692] [00:16:29/00:15:45, 0.524s/it]: train_loss_raw=0.4154, running_loss=0.4148, LR=0.000100
[2025-08-11 01:29:12,083][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094200] [Batch 01900/03692] [00:16:35/00:15:38, 0.524s/it]: train_loss_raw=0.3651, running_loss=0.4126, LR=0.000100
[2025-08-11 01:29:18,172][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094212] [Batch 01912/03692] [00:16:41/00:15:32, 0.524s/it]: train_loss_raw=0.4906, running_loss=0.4117, LR=0.000100
[2025-08-11 01:29:24,315][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094224] [Batch 01924/03692] [00:16:47/00:15:25, 0.524s/it]: train_loss_raw=0.4305, running_loss=0.4121, LR=0.000100
[2025-08-11 01:29:30,401][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094236] [Batch 01936/03692] [00:16:53/00:15:19, 0.524s/it]: train_loss_raw=0.3448, running_loss=0.4129, LR=0.000100
[2025-08-11 01:29:36,452][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094248] [Batch 01948/03692] [00:16:59/00:15:12, 0.523s/it]: train_loss_raw=0.3096, running_loss=0.4095, LR=0.000100
[2025-08-11 01:29:42,578][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094260] [Batch 01960/03692] [00:17:05/00:15:06, 0.523s/it]: train_loss_raw=0.4015, running_loss=0.4087, LR=0.000100
[2025-08-11 01:29:48,698][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094272] [Batch 01972/03692] [00:17:11/00:15:00, 0.523s/it]: train_loss_raw=0.3843, running_loss=0.4065, LR=0.000100
[2025-08-11 01:29:54,997][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094284] [Batch 01984/03692] [00:17:18/00:14:53, 0.523s/it]: train_loss_raw=0.4012, running_loss=0.4064, LR=0.000100
[2025-08-11 01:30:01,234][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094296] [Batch 01996/03692] [00:17:24/00:14:47, 0.523s/it]: train_loss_raw=0.4366, running_loss=0.4082, LR=0.000100
[2025-08-11 01:30:07,480][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094308] [Batch 02008/03692] [00:17:30/00:14:41, 0.523s/it]: train_loss_raw=0.3910, running_loss=0.4085, LR=0.000100
[2025-08-11 01:30:13,621][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094320] [Batch 02020/03692] [00:17:36/00:14:34, 0.523s/it]: train_loss_raw=0.3653, running_loss=0.4097, LR=0.000100
[2025-08-11 01:30:19,795][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094332] [Batch 02032/03692] [00:17:42/00:14:28, 0.523s/it]: train_loss_raw=0.3647, running_loss=0.4106, LR=0.000100
[2025-08-11 01:30:26,282][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094344] [Batch 02044/03692] [00:17:49/00:14:22, 0.523s/it]: train_loss_raw=0.4882, running_loss=0.4098, LR=0.000100
[2025-08-11 01:30:32,665][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094356] [Batch 02056/03692] [00:17:55/00:14:16, 0.523s/it]: train_loss_raw=0.4301, running_loss=0.4111, LR=0.000100
[2025-08-11 01:30:39,058][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094368] [Batch 02068/03692] [00:18:02/00:14:09, 0.523s/it]: train_loss_raw=0.4762, running_loss=0.4144, LR=0.000100
[2025-08-11 01:30:45,269][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094380] [Batch 02080/03692] [00:18:08/00:14:03, 0.523s/it]: train_loss_raw=0.5177, running_loss=0.4154, LR=0.000100
[2025-08-11 01:30:51,516][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094392] [Batch 02092/03692] [00:18:14/00:13:57, 0.523s/it]: train_loss_raw=0.3746, running_loss=0.4167, LR=0.000100
[2025-08-11 01:30:57,753][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094404] [Batch 02104/03692] [00:18:20/00:13:50, 0.523s/it]: train_loss_raw=0.3881, running_loss=0.4152, LR=0.000100
[2025-08-11 01:31:03,935][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094416] [Batch 02116/03692] [00:18:27/00:13:44, 0.523s/it]: train_loss_raw=0.4465, running_loss=0.4127, LR=0.000100
[2025-08-11 01:31:10,131][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094428] [Batch 02128/03692] [00:18:33/00:13:38, 0.523s/it]: train_loss_raw=0.3658, running_loss=0.4125, LR=0.000100
[2025-08-11 01:31:16,313][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094440] [Batch 02140/03692] [00:18:39/00:13:31, 0.523s/it]: train_loss_raw=0.3841, running_loss=0.4122, LR=0.000100
[2025-08-11 01:31:22,391][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094452] [Batch 02152/03692] [00:18:45/00:13:25, 0.523s/it]: train_loss_raw=0.3300, running_loss=0.4083, LR=0.000100
[2025-08-11 01:31:35,606][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094464] [Batch 02164/03692] [00:18:58/00:13:24, 0.526s/it]: train_loss_raw=0.3642, running_loss=0.4074, LR=0.000100
[2025-08-11 01:31:41,720][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094476] [Batch 02176/03692] [00:19:04/00:13:17, 0.526s/it]: train_loss_raw=0.3526, running_loss=0.4090, LR=0.000100
[2025-08-11 01:31:47,819][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094488] [Batch 02188/03692] [00:19:10/00:13:11, 0.526s/it]: train_loss_raw=0.5084, running_loss=0.4132, LR=0.000100
[2025-08-11 01:31:53,869][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094500] [Batch 02200/03692] [00:19:17/00:13:04, 0.526s/it]: train_loss_raw=0.4983, running_loss=0.4146, LR=0.000100
[2025-08-11 01:32:00,106][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094512] [Batch 02212/03692] [00:19:23/00:12:58, 0.526s/it]: train_loss_raw=0.3663, running_loss=0.4175, LR=0.000100
[2025-08-11 01:32:06,432][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094524] [Batch 02224/03692] [00:19:29/00:12:52, 0.526s/it]: train_loss_raw=0.4841, running_loss=0.4175, LR=0.000100
[2025-08-11 01:32:12,624][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094536] [Batch 02236/03692] [00:19:35/00:12:45, 0.526s/it]: train_loss_raw=0.4547, running_loss=0.4188, LR=0.000100
[2025-08-11 01:32:18,681][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094548] [Batch 02248/03692] [00:19:41/00:12:39, 0.526s/it]: train_loss_raw=0.3777, running_loss=0.4182, LR=0.000100
[2025-08-11 01:32:24,723][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094560] [Batch 02260/03692] [00:19:47/00:12:32, 0.526s/it]: train_loss_raw=0.4490, running_loss=0.4187, LR=0.000100
[2025-08-11 01:32:30,756][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094572] [Batch 02272/03692] [00:19:53/00:12:26, 0.525s/it]: train_loss_raw=0.4561, running_loss=0.4180, LR=0.000100
[2025-08-11 01:32:36,787][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094584] [Batch 02284/03692] [00:19:59/00:12:19, 0.525s/it]: train_loss_raw=0.4198, running_loss=0.4165, LR=0.000100
[2025-08-11 01:32:42,795][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094596] [Batch 02296/03692] [00:20:05/00:12:13, 0.525s/it]: train_loss_raw=0.3953, running_loss=0.4167, LR=0.000100
[2025-08-11 01:32:48,898][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094608] [Batch 02308/03692] [00:20:12/00:12:06, 0.525s/it]: train_loss_raw=0.4260, running_loss=0.4166, LR=0.000100
[2025-08-11 01:32:55,040][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094620] [Batch 02320/03692] [00:20:18/00:12:00, 0.525s/it]: train_loss_raw=0.4464, running_loss=0.4160, LR=0.000100
[2025-08-11 01:33:01,216][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094632] [Batch 02332/03692] [00:20:24/00:11:54, 0.525s/it]: train_loss_raw=0.4399, running_loss=0.4155, LR=0.000100
[2025-08-11 01:33:07,306][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094644] [Batch 02344/03692] [00:20:30/00:11:47, 0.525s/it]: train_loss_raw=0.4348, running_loss=0.4140, LR=0.000100
[2025-08-11 01:33:13,395][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094656] [Batch 02356/03692] [00:20:36/00:11:41, 0.525s/it]: train_loss_raw=0.3730, running_loss=0.4123, LR=0.000100
[2025-08-11 01:33:19,755][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094668] [Batch 02368/03692] [00:20:42/00:11:34, 0.525s/it]: train_loss_raw=0.4065, running_loss=0.4156, LR=0.000100
[2025-08-11 01:33:26,087][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094680] [Batch 02380/03692] [00:20:49/00:11:28, 0.525s/it]: train_loss_raw=0.4096, running_loss=0.4152, LR=0.000100
[2025-08-11 01:33:32,163][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094692] [Batch 02392/03692] [00:20:55/00:11:22, 0.525s/it]: train_loss_raw=0.4491, running_loss=0.4165, LR=0.000100
[2025-08-11 01:33:38,247][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094704] [Batch 02404/03692] [00:21:01/00:11:15, 0.525s/it]: train_loss_raw=0.3715, running_loss=0.4157, LR=0.000100
[2025-08-11 01:33:44,568][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094716] [Batch 02416/03692] [00:21:07/00:11:09, 0.525s/it]: train_loss_raw=0.3997, running_loss=0.4183, LR=0.000100
[2025-08-11 01:33:50,960][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094728] [Batch 02428/03692] [00:21:14/00:11:03, 0.525s/it]: train_loss_raw=0.5300, running_loss=0.4195, LR=0.000100
[2025-08-11 01:33:57,332][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094740] [Batch 02440/03692] [00:21:20/00:10:57, 0.525s/it]: train_loss_raw=0.4317, running_loss=0.4213, LR=0.000100
[2025-08-11 01:34:03,382][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094752] [Batch 02452/03692] [00:21:26/00:10:50, 0.525s/it]: train_loss_raw=0.4690, running_loss=0.4200, LR=0.000100
[2025-08-11 01:34:09,364][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094764] [Batch 02464/03692] [00:21:32/00:10:44, 0.525s/it]: train_loss_raw=0.4502, running_loss=0.4204, LR=0.000100
[2025-08-11 01:34:15,358][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094776] [Batch 02476/03692] [00:21:38/00:10:37, 0.524s/it]: train_loss_raw=0.3666, running_loss=0.4182, LR=0.000100
[2025-08-11 01:34:21,340][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094788] [Batch 02488/03692] [00:21:44/00:10:31, 0.524s/it]: train_loss_raw=0.3780, running_loss=0.4184, LR=0.000100
[2025-08-11 01:34:27,344][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094800] [Batch 02500/03692] [00:21:50/00:10:24, 0.524s/it]: train_loss_raw=0.5503, running_loss=0.4200, LR=0.000100
[2025-08-11 01:34:33,394][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094812] [Batch 02512/03692] [00:21:56/00:10:18, 0.524s/it]: train_loss_raw=0.4952, running_loss=0.4194, LR=0.000100
[2025-08-11 01:34:39,457][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094824] [Batch 02524/03692] [00:22:02/00:10:12, 0.524s/it]: train_loss_raw=0.3718, running_loss=0.4177, LR=0.000100
[2025-08-11 01:34:45,455][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094836] [Batch 02536/03692] [00:22:08/00:10:05, 0.524s/it]: train_loss_raw=0.3483, running_loss=0.4151, LR=0.000100
[2025-08-11 01:34:51,875][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094848] [Batch 02548/03692] [00:22:15/00:09:59, 0.524s/it]: train_loss_raw=0.4669, running_loss=0.4117, LR=0.000100
[2025-08-11 01:34:58,002][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094860] [Batch 02560/03692] [00:22:21/00:09:53, 0.524s/it]: train_loss_raw=0.3723, running_loss=0.4137, LR=0.000100
[2025-08-11 01:35:04,066][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094872] [Batch 02572/03692] [00:22:27/00:09:46, 0.524s/it]: train_loss_raw=0.3457, running_loss=0.4141, LR=0.000100
[2025-08-11 01:35:10,134][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094884] [Batch 02584/03692] [00:22:33/00:09:40, 0.524s/it]: train_loss_raw=0.4155, running_loss=0.4152, LR=0.000100
[2025-08-11 01:35:16,189][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094896] [Batch 02596/03692] [00:22:39/00:09:33, 0.524s/it]: train_loss_raw=0.4803, running_loss=0.4174, LR=0.000100
[2025-08-11 01:35:22,748][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094908] [Batch 02608/03692] [00:22:45/00:09:27, 0.524s/it]: train_loss_raw=0.4472, running_loss=0.4130, LR=0.000100
[2025-08-11 01:35:29,215][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094920] [Batch 02620/03692] [00:22:52/00:09:21, 0.524s/it]: train_loss_raw=0.5267, running_loss=0.4147, LR=0.000100
[2025-08-11 01:35:35,731][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094932] [Batch 02632/03692] [00:22:58/00:09:15, 0.524s/it]: train_loss_raw=0.3717, running_loss=0.4175, LR=0.000100
[2025-08-11 01:35:42,167][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094944] [Batch 02644/03692] [00:23:05/00:09:09, 0.524s/it]: train_loss_raw=0.3987, running_loss=0.4196, LR=0.000100
[2025-08-11 01:35:48,624][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094956] [Batch 02656/03692] [00:23:11/00:09:02, 0.524s/it]: train_loss_raw=0.4046, running_loss=0.4186, LR=0.000100
[2025-08-11 01:35:55,139][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094968] [Batch 02668/03692] [00:23:18/00:08:56, 0.524s/it]: train_loss_raw=0.4858, running_loss=0.4209, LR=0.000100
[2025-08-11 01:36:01,682][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094980] [Batch 02680/03692] [00:23:24/00:08:50, 0.524s/it]: train_loss_raw=0.4710, running_loss=0.4201, LR=0.000100
[2025-08-11 01:36:08,195][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 094992] [Batch 02692/03692] [00:23:31/00:08:44, 0.524s/it]: train_loss_raw=0.4101, running_loss=0.4177, LR=0.000100
[2025-08-11 01:36:14,750][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095004] [Batch 02704/03692] [00:23:37/00:08:38, 0.524s/it]: train_loss_raw=0.3795, running_loss=0.4177, LR=0.000100
[2025-08-11 01:36:21,049][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095016] [Batch 02716/03692] [00:23:44/00:08:31, 0.524s/it]: train_loss_raw=0.4396, running_loss=0.4202, LR=0.000100
[2025-08-11 01:36:27,422][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095028] [Batch 02728/03692] [00:23:50/00:08:25, 0.524s/it]: train_loss_raw=0.4057, running_loss=0.4201, LR=0.000100
[2025-08-11 01:36:33,704][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095040] [Batch 02740/03692] [00:23:56/00:08:19, 0.524s/it]: train_loss_raw=0.3812, running_loss=0.4190, LR=0.000100
[2025-08-11 01:36:40,134][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095052] [Batch 02752/03692] [00:24:03/00:08:12, 0.524s/it]: train_loss_raw=0.4028, running_loss=0.4174, LR=0.000100
[2025-08-11 01:36:46,316][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095064] [Batch 02764/03692] [00:24:09/00:08:06, 0.524s/it]: train_loss_raw=0.3986, running_loss=0.4150, LR=0.000100
[2025-08-11 01:36:52,394][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095076] [Batch 02776/03692] [00:24:15/00:08:00, 0.524s/it]: train_loss_raw=0.3929, running_loss=0.4156, LR=0.000100
[2025-08-11 01:36:58,848][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095088] [Batch 02788/03692] [00:24:22/00:07:54, 0.524s/it]: train_loss_raw=0.3812, running_loss=0.4162, LR=0.000100
[2025-08-11 01:37:05,150][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095100] [Batch 02800/03692] [00:24:28/00:07:47, 0.524s/it]: train_loss_raw=0.3930, running_loss=0.4150, LR=0.000100
[2025-08-11 01:37:11,154][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095112] [Batch 02812/03692] [00:24:34/00:07:41, 0.524s/it]: train_loss_raw=0.4450, running_loss=0.4167, LR=0.000100
[2025-08-11 01:37:17,289][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095124] [Batch 02824/03692] [00:24:40/00:07:35, 0.524s/it]: train_loss_raw=0.4278, running_loss=0.4151, LR=0.000100
[2025-08-11 01:37:23,793][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095136] [Batch 02836/03692] [00:24:46/00:07:28, 0.524s/it]: train_loss_raw=0.3662, running_loss=0.4125, LR=0.000100
[2025-08-11 01:37:30,342][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095148] [Batch 02848/03692] [00:24:53/00:07:22, 0.524s/it]: train_loss_raw=0.3765, running_loss=0.4116, LR=0.000100
[2025-08-11 01:37:36,880][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095160] [Batch 02860/03692] [00:25:00/00:07:16, 0.524s/it]: train_loss_raw=0.4142, running_loss=0.4132, LR=0.000100
[2025-08-11 01:37:43,213][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095172] [Batch 02872/03692] [00:25:06/00:07:10, 0.525s/it]: train_loss_raw=0.3517, running_loss=0.4144, LR=0.000100
[2025-08-11 01:37:49,599][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095184] [Batch 02884/03692] [00:25:12/00:07:03, 0.525s/it]: train_loss_raw=0.4028, running_loss=0.4201, LR=0.000100
[2025-08-11 01:37:56,118][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095196] [Batch 02896/03692] [00:25:19/00:06:57, 0.525s/it]: train_loss_raw=0.3657, running_loss=0.4186, LR=0.000100
[2025-08-11 01:38:02,323][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095208] [Batch 02908/03692] [00:25:25/00:06:51, 0.525s/it]: train_loss_raw=0.4100, running_loss=0.4223, LR=0.000100
[2025-08-11 01:38:08,371][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095220] [Batch 02920/03692] [00:25:31/00:06:44, 0.525s/it]: train_loss_raw=0.3971, running_loss=0.4194, LR=0.000100
[2025-08-11 01:38:14,411][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095232] [Batch 02932/03692] [00:25:37/00:06:38, 0.524s/it]: train_loss_raw=0.4147, running_loss=0.4206, LR=0.000100
[2025-08-11 01:38:20,434][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095244] [Batch 02944/03692] [00:25:43/00:06:32, 0.524s/it]: train_loss_raw=0.5072, running_loss=0.4200, LR=0.000100
[2025-08-11 01:38:26,475][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095256] [Batch 02956/03692] [00:25:49/00:06:25, 0.524s/it]: train_loss_raw=0.4347, running_loss=0.4211, LR=0.000100
[2025-08-11 01:38:32,499][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095268] [Batch 02968/03692] [00:25:55/00:06:19, 0.524s/it]: train_loss_raw=0.4257, running_loss=0.4182, LR=0.000100
[2025-08-11 01:38:38,579][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095280] [Batch 02980/03692] [00:26:01/00:06:13, 0.524s/it]: train_loss_raw=0.4326, running_loss=0.4214, LR=0.000100
[2025-08-11 01:38:44,740][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095292] [Batch 02992/03692] [00:26:07/00:06:06, 0.524s/it]: train_loss_raw=0.3867, running_loss=0.4177, LR=0.000100
[2025-08-11 01:38:50,963][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095304] [Batch 03004/03692] [00:26:14/00:06:00, 0.524s/it]: train_loss_raw=0.3380, running_loss=0.4148, LR=0.000100
[2025-08-11 01:38:57,059][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095316] [Batch 03016/03692] [00:26:20/00:05:54, 0.524s/it]: train_loss_raw=0.3404, running_loss=0.4128, LR=0.000100
[2025-08-11 01:39:03,105][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095328] [Batch 03028/03692] [00:26:26/00:05:47, 0.524s/it]: train_loss_raw=0.4664, running_loss=0.4156, LR=0.000100
[2025-08-11 01:39:09,145][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095340] [Batch 03040/03692] [00:26:32/00:05:41, 0.524s/it]: train_loss_raw=0.3879, running_loss=0.4157, LR=0.000100
[2025-08-11 01:39:15,227][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095352] [Batch 03052/03692] [00:26:38/00:05:35, 0.524s/it]: train_loss_raw=0.4466, running_loss=0.4152, LR=0.000100
[2025-08-11 01:39:21,382][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095364] [Batch 03064/03692] [00:26:44/00:05:28, 0.524s/it]: train_loss_raw=0.3382, running_loss=0.4149, LR=0.000100
[2025-08-11 01:39:27,593][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095376] [Batch 03076/03692] [00:26:50/00:05:22, 0.524s/it]: train_loss_raw=0.4284, running_loss=0.4149, LR=0.000100
[2025-08-11 01:39:33,740][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095388] [Batch 03088/03692] [00:26:56/00:05:16, 0.524s/it]: train_loss_raw=0.3766, running_loss=0.4164, LR=0.000100
[2025-08-11 01:39:39,884][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095400] [Batch 03100/03692] [00:27:03/00:05:09, 0.524s/it]: train_loss_raw=0.4388, running_loss=0.4146, LR=0.000100
[2025-08-11 01:39:46,030][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095412] [Batch 03112/03692] [00:27:09/00:05:03, 0.524s/it]: train_loss_raw=0.4245, running_loss=0.4124, LR=0.000100
[2025-08-11 01:39:52,091][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095424] [Batch 03124/03692] [00:27:15/00:04:57, 0.523s/it]: train_loss_raw=0.4071, running_loss=0.4135, LR=0.000100
[2025-08-11 01:39:58,558][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095436] [Batch 03136/03692] [00:27:21/00:04:51, 0.524s/it]: train_loss_raw=0.3708, running_loss=0.4128, LR=0.000100
[2025-08-11 01:40:04,664][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095448] [Batch 03148/03692] [00:27:27/00:04:44, 0.523s/it]: train_loss_raw=0.4360, running_loss=0.4166, LR=0.000100
[2025-08-11 01:40:10,754][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095460] [Batch 03160/03692] [00:27:33/00:04:38, 0.523s/it]: train_loss_raw=0.3565, running_loss=0.4159, LR=0.000100
[2025-08-11 01:40:16,782][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095472] [Batch 03172/03692] [00:27:39/00:04:32, 0.523s/it]: train_loss_raw=0.4319, running_loss=0.4176, LR=0.000100
[2025-08-11 01:40:22,976][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095484] [Batch 03184/03692] [00:27:46/00:04:25, 0.523s/it]: train_loss_raw=0.3229, running_loss=0.4178, LR=0.000100
[2025-08-11 01:40:29,246][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095496] [Batch 03196/03692] [00:27:52/00:04:19, 0.523s/it]: train_loss_raw=0.5091, running_loss=0.4205, LR=0.000100
[2025-08-11 01:40:35,463][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095508] [Batch 03208/03692] [00:27:58/00:04:13, 0.523s/it]: train_loss_raw=0.5225, running_loss=0.4216, LR=0.000100
[2025-08-11 01:40:41,758][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095520] [Batch 03220/03692] [00:28:04/00:04:06, 0.523s/it]: train_loss_raw=0.3784, running_loss=0.4213, LR=0.000100
[2025-08-11 01:40:47,898][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095532] [Batch 03232/03692] [00:28:11/00:04:00, 0.523s/it]: train_loss_raw=0.4985, running_loss=0.4259, LR=0.000100
[2025-08-11 01:40:53,983][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095544] [Batch 03244/03692] [00:28:17/00:03:54, 0.523s/it]: train_loss_raw=0.4210, running_loss=0.4241, LR=0.000100
[2025-08-11 01:41:00,081][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095556] [Batch 03256/03692] [00:28:23/00:03:48, 0.523s/it]: train_loss_raw=0.5378, running_loss=0.4223, LR=0.000100
[2025-08-11 01:41:06,143][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095568] [Batch 03268/03692] [00:28:29/00:03:41, 0.523s/it]: train_loss_raw=0.5188, running_loss=0.4223, LR=0.000100
[2025-08-11 01:41:12,266][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095580] [Batch 03280/03692] [00:28:35/00:03:35, 0.523s/it]: train_loss_raw=0.4300, running_loss=0.4214, LR=0.000100
[2025-08-11 01:41:18,407][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095592] [Batch 03292/03692] [00:28:41/00:03:29, 0.523s/it]: train_loss_raw=0.4226, running_loss=0.4171, LR=0.000100
[2025-08-11 01:41:24,484][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095604] [Batch 03304/03692] [00:28:47/00:03:22, 0.523s/it]: train_loss_raw=0.4458, running_loss=0.4166, LR=0.000100
[2025-08-11 01:41:30,599][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095616] [Batch 03316/03692] [00:28:53/00:03:16, 0.523s/it]: train_loss_raw=0.4877, running_loss=0.4158, LR=0.000100
[2025-08-11 01:41:36,619][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095628] [Batch 03328/03692] [00:28:59/00:03:10, 0.523s/it]: train_loss_raw=0.3581, running_loss=0.4165, LR=0.000100
[2025-08-11 01:41:42,683][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095640] [Batch 03340/03692] [00:29:05/00:03:03, 0.523s/it]: train_loss_raw=0.3835, running_loss=0.4169, LR=0.000100
[2025-08-11 01:41:48,768][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095652] [Batch 03352/03692] [00:29:11/00:02:57, 0.523s/it]: train_loss_raw=0.5063, running_loss=0.4191, LR=0.000100
[2025-08-11 01:41:54,946][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095664] [Batch 03364/03692] [00:29:18/00:02:51, 0.523s/it]: train_loss_raw=0.5285, running_loss=0.4200, LR=0.000100
[2025-08-11 01:42:00,981][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095676] [Batch 03376/03692] [00:29:24/00:02:45, 0.523s/it]: train_loss_raw=0.4687, running_loss=0.4214, LR=0.000100
[2025-08-11 01:42:07,104][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095688] [Batch 03388/03692] [00:29:30/00:02:38, 0.523s/it]: train_loss_raw=0.4133, running_loss=0.4216, LR=0.000100
[2025-08-11 01:42:13,186][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095700] [Batch 03400/03692] [00:29:36/00:02:32, 0.522s/it]: train_loss_raw=0.3785, running_loss=0.4235, LR=0.000100
[2025-08-11 01:42:19,166][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095712] [Batch 03412/03692] [00:29:42/00:02:26, 0.522s/it]: train_loss_raw=0.4938, running_loss=0.4229, LR=0.000100
[2025-08-11 01:42:25,280][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095724] [Batch 03424/03692] [00:29:48/00:02:19, 0.522s/it]: train_loss_raw=0.4472, running_loss=0.4255, LR=0.000100
[2025-08-11 01:42:31,488][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095736] [Batch 03436/03692] [00:29:54/00:02:13, 0.522s/it]: train_loss_raw=0.4601, running_loss=0.4235, LR=0.000100
[2025-08-11 01:42:37,575][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095748] [Batch 03448/03692] [00:30:00/00:02:07, 0.522s/it]: train_loss_raw=0.3759, running_loss=0.4237, LR=0.000100
[2025-08-11 01:42:43,616][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095760] [Batch 03460/03692] [00:30:06/00:02:01, 0.522s/it]: train_loss_raw=0.4063, running_loss=0.4229, LR=0.000100
[2025-08-11 01:42:49,653][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095772] [Batch 03472/03692] [00:30:12/00:01:54, 0.522s/it]: train_loss_raw=0.3988, running_loss=0.4191, LR=0.000100
[2025-08-11 01:42:56,114][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095784] [Batch 03484/03692] [00:30:19/00:01:48, 0.522s/it]: train_loss_raw=0.4908, running_loss=0.4210, LR=0.000100
[2025-08-11 01:43:02,572][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095796] [Batch 03496/03692] [00:30:25/00:01:42, 0.522s/it]: train_loss_raw=0.3617, running_loss=0.4230, LR=0.000100
[2025-08-11 01:43:08,996][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095808] [Batch 03508/03692] [00:30:32/00:01:36, 0.522s/it]: train_loss_raw=0.3972, running_loss=0.4201, LR=0.000100
[2025-08-11 01:43:15,553][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095820] [Batch 03520/03692] [00:30:38/00:01:29, 0.522s/it]: train_loss_raw=0.3933, running_loss=0.4164, LR=0.000100
[2025-08-11 01:43:21,752][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095832] [Batch 03532/03692] [00:30:44/00:01:23, 0.522s/it]: train_loss_raw=0.3339, running_loss=0.4125, LR=0.000100
[2025-08-11 01:43:27,749][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095844] [Batch 03544/03692] [00:30:50/00:01:17, 0.522s/it]: train_loss_raw=0.4366, running_loss=0.4124, LR=0.000100
[2025-08-11 01:43:33,766][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095856] [Batch 03556/03692] [00:30:56/00:01:11, 0.522s/it]: train_loss_raw=0.3905, running_loss=0.4123, LR=0.000100
[2025-08-11 01:43:40,042][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095868] [Batch 03568/03692] [00:31:03/00:01:04, 0.522s/it]: train_loss_raw=0.3462, running_loss=0.4096, LR=0.000100
[2025-08-11 01:43:46,144][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095880] [Batch 03580/03692] [00:31:09/00:00:58, 0.522s/it]: train_loss_raw=0.3767, running_loss=0.4104, LR=0.000100
[2025-08-11 01:43:52,203][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095892] [Batch 03592/03692] [00:31:15/00:00:52, 0.522s/it]: train_loss_raw=0.2912, running_loss=0.4090, LR=0.000100
[2025-08-11 01:43:58,398][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095904] [Batch 03604/03692] [00:31:21/00:00:45, 0.522s/it]: train_loss_raw=0.3568, running_loss=0.4075, LR=0.000100
[2025-08-11 01:44:04,572][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095916] [Batch 03616/03692] [00:31:27/00:00:39, 0.522s/it]: train_loss_raw=0.4180, running_loss=0.4080, LR=0.000100
[2025-08-11 01:44:10,618][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095928] [Batch 03628/03692] [00:31:33/00:00:33, 0.522s/it]: train_loss_raw=0.3746, running_loss=0.4057, LR=0.000100
[2025-08-11 01:44:16,679][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095940] [Batch 03640/03692] [00:31:39/00:00:27, 0.522s/it]: train_loss_raw=0.3611, running_loss=0.4055, LR=0.000100
[2025-08-11 01:44:22,757][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095952] [Batch 03652/03692] [00:31:45/00:00:20, 0.522s/it]: train_loss_raw=0.4768, running_loss=0.4068, LR=0.000100
[2025-08-11 01:44:29,028][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095964] [Batch 03664/03692] [00:31:52/00:00:14, 0.522s/it]: train_loss_raw=0.3409, running_loss=0.4036, LR=0.000100
[2025-08-11 01:44:35,576][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095976] [Batch 03676/03692] [00:31:58/00:00:08, 0.522s/it]: train_loss_raw=0.5072, running_loss=0.4074, LR=0.000100
[2025-08-11 01:44:41,746][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 095988] [Batch 03688/03692] [00:32:04/00:00:02, 0.522s/it]: train_loss_raw=0.3928, running_loss=0.4064, LR=0.000100
[2025-08-11 01:45:13,818][__main__][INFO] - [VALIDATION] [Epoch 25/29] Starting validation.
[2025-08-11 01:45:46,631][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 095993] [Batch 00011/00025] [00:00:32/00:00:35, 2.734s/it]
[2025-08-11 01:46:02,067][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 095993] [Batch 00023/00025] [00:00:48/00:00:02, 2.010s/it]
[2025-08-11 01:46:03,077][__main__][INFO] - [VALIDATION] [Epoch 25/29] train_loss=0.40598, valid_loss=0.56472
[2025-08-11 01:46:03,077][__main__][INFO] - [VALIDATION] [Epoch 25/29] Metrics:
[2025-08-11 01:46:03,077][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_er      0.230
[2025-08-11 01:46:03,077][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_prec    0.556
[2025-08-11 01:46:03,077][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_recall  0.561
[2025-08-11 01:46:03,077][__main__][INFO] - [VALIDATION] [Epoch 25/29] - pep_recall 0.551
[2025-08-11 01:46:03,080][__main__][INFO] - [TRAIN] [Epoch 25/29] Epoch complete, total time 14:50:02, remaining time 02:16:55, 00:34:13 per epoch
[2025-08-11 01:46:08,332][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096000] [Batch 00008/03692] [00:00:03/00:29:13, 0.476s/it]: train_loss_raw=0.3971, running_loss=0.3777, LR=0.000100
[2025-08-11 01:46:19,251][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096012] [Batch 00020/03692] [00:00:14/00:45:03, 0.736s/it]: train_loss_raw=0.3248, running_loss=0.3720, LR=0.000100
[2025-08-11 01:46:25,583][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096024] [Batch 00032/03692] [00:00:21/00:40:08, 0.658s/it]: train_loss_raw=0.3621, running_loss=0.3707, LR=0.000100
[2025-08-11 01:46:31,977][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096036] [Batch 00044/03692] [00:00:27/00:37:56, 0.624s/it]: train_loss_raw=0.3463, running_loss=0.3700, LR=0.000100
[2025-08-11 01:46:38,386][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096048] [Batch 00056/03692] [00:00:33/00:36:38, 0.605s/it]: train_loss_raw=0.4335, running_loss=0.3684, LR=0.000100
[2025-08-11 01:46:44,870][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096060] [Batch 00068/03692] [00:00:40/00:35:50, 0.593s/it]: train_loss_raw=0.3671, running_loss=0.3644, LR=0.000100
[2025-08-11 01:46:51,348][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096072] [Batch 00080/03692] [00:00:46/00:35:14, 0.585s/it]: train_loss_raw=0.3057, running_loss=0.3669, LR=0.000100
[2025-08-11 01:46:57,756][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096084] [Batch 00092/03692] [00:00:53/00:34:42, 0.579s/it]: train_loss_raw=0.3539, running_loss=0.3643, LR=0.000100
[2025-08-11 01:47:04,143][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096096] [Batch 00104/03692] [00:00:59/00:34:16, 0.573s/it]: train_loss_raw=0.3657, running_loss=0.3628, LR=0.000100
[2025-08-11 01:47:10,595][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096108] [Batch 00116/03692] [00:01:06/00:33:56, 0.570s/it]: train_loss_raw=0.3673, running_loss=0.3602, LR=0.000100
[2025-08-11 01:47:16,951][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096120] [Batch 00128/03692] [00:01:12/00:33:36, 0.566s/it]: train_loss_raw=0.3406, running_loss=0.3605, LR=0.000100
[2025-08-11 01:47:23,255][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096132] [Batch 00140/03692] [00:01:18/00:33:17, 0.562s/it]: train_loss_raw=0.3425, running_loss=0.3633, LR=0.000100
[2025-08-11 01:47:29,765][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096144] [Batch 00152/03692] [00:01:25/00:33:05, 0.561s/it]: train_loss_raw=0.4213, running_loss=0.3642, LR=0.000100
[2025-08-11 01:47:36,262][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096156] [Batch 00164/03692] [00:01:31/00:32:53, 0.559s/it]: train_loss_raw=0.3135, running_loss=0.3637, LR=0.000100
[2025-08-11 01:47:42,796][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096168] [Batch 00176/03692] [00:01:38/00:32:43, 0.558s/it]: train_loss_raw=0.4906, running_loss=0.3631, LR=0.000100
[2025-08-11 01:47:49,192][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096180] [Batch 00188/03692] [00:01:44/00:32:30, 0.557s/it]: train_loss_raw=0.3353, running_loss=0.3638, LR=0.000100
[2025-08-11 01:47:55,515][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096192] [Batch 00200/03692] [00:01:50/00:32:17, 0.555s/it]: train_loss_raw=0.3231, running_loss=0.3617, LR=0.000100
[2025-08-11 01:48:01,897][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096204] [Batch 00212/03692] [00:01:57/00:32:06, 0.554s/it]: train_loss_raw=0.3645, running_loss=0.3599, LR=0.000100
[2025-08-11 01:48:08,242][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096216] [Batch 00224/03692] [00:02:03/00:31:55, 0.552s/it]: train_loss_raw=0.3614, running_loss=0.3605, LR=0.000100
[2025-08-11 01:48:14,598][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096228] [Batch 00236/03692] [00:02:10/00:31:44, 0.551s/it]: train_loss_raw=0.2889, running_loss=0.3583, LR=0.000100
[2025-08-11 01:48:20,995][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096240] [Batch 00248/03692] [00:02:16/00:31:35, 0.550s/it]: train_loss_raw=0.3859, running_loss=0.3571, LR=0.000100
[2025-08-11 01:48:27,363][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096252] [Batch 00260/03692] [00:02:22/00:31:25, 0.549s/it]: train_loss_raw=0.3496, running_loss=0.3572, LR=0.000100
[2025-08-11 01:48:33,780][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096264] [Batch 00272/03692] [00:02:29/00:31:16, 0.549s/it]: train_loss_raw=0.3503, running_loss=0.3588, LR=0.000100
[2025-08-11 01:48:40,176][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096276] [Batch 00284/03692] [00:02:35/00:31:07, 0.548s/it]: train_loss_raw=0.3365, running_loss=0.3587, LR=0.000100
[2025-08-11 01:48:46,575][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096288] [Batch 00296/03692] [00:02:42/00:30:59, 0.547s/it]: train_loss_raw=0.4643, running_loss=0.3607, LR=0.000100
[2025-08-11 01:48:52,982][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096300] [Batch 00308/03692] [00:02:48/00:30:50, 0.547s/it]: train_loss_raw=0.4164, running_loss=0.3604, LR=0.000100
[2025-08-11 01:48:59,398][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096312] [Batch 00320/03692] [00:02:54/00:30:42, 0.546s/it]: train_loss_raw=0.4753, running_loss=0.3602, LR=0.000100
[2025-08-11 01:49:05,828][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096324] [Batch 00332/03692] [00:03:01/00:30:34, 0.546s/it]: train_loss_raw=0.3317, running_loss=0.3578, LR=0.000100
[2025-08-11 01:49:12,203][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096336] [Batch 00344/03692] [00:03:07/00:30:26, 0.546s/it]: train_loss_raw=0.2845, running_loss=0.3567, LR=0.000100
[2025-08-11 01:49:18,605][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096348] [Batch 00356/03692] [00:03:14/00:30:18, 0.545s/it]: train_loss_raw=0.5344, running_loss=0.3600, LR=0.000100
[2025-08-11 01:49:25,034][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096360] [Batch 00368/03692] [00:03:20/00:30:11, 0.545s/it]: train_loss_raw=0.3709, running_loss=0.3629, LR=0.000100
[2025-08-11 01:49:31,374][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096372] [Batch 00380/03692] [00:03:26/00:30:02, 0.544s/it]: train_loss_raw=0.3975, running_loss=0.3646, LR=0.000100
[2025-08-11 01:49:37,791][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096384] [Batch 00392/03692] [00:03:33/00:29:55, 0.544s/it]: train_loss_raw=0.3972, running_loss=0.3667, LR=0.000100
[2025-08-11 01:49:44,277][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096396] [Batch 00404/03692] [00:03:39/00:29:48, 0.544s/it]: train_loss_raw=0.3188, running_loss=0.3654, LR=0.000100
[2025-08-11 01:49:50,718][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096408] [Batch 00416/03692] [00:03:46/00:29:41, 0.544s/it]: train_loss_raw=0.3866, running_loss=0.3653, LR=0.000100
[2025-08-11 01:49:57,100][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096420] [Batch 00428/03692] [00:03:52/00:29:33, 0.543s/it]: train_loss_raw=0.3590, running_loss=0.3669, LR=0.000100
[2025-08-11 01:50:03,582][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096432] [Batch 00440/03692] [00:03:59/00:29:26, 0.543s/it]: train_loss_raw=0.3854, running_loss=0.3665, LR=0.000100
[2025-08-11 01:50:10,110][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096444] [Batch 00452/03692] [00:04:05/00:29:20, 0.543s/it]: train_loss_raw=0.4494, running_loss=0.3682, LR=0.000100
[2025-08-11 01:50:16,509][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096456] [Batch 00464/03692] [00:04:11/00:29:13, 0.543s/it]: train_loss_raw=0.4311, running_loss=0.3700, LR=0.000100
[2025-08-11 01:50:22,875][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096468] [Batch 00476/03692] [00:04:18/00:29:05, 0.543s/it]: train_loss_raw=0.3684, running_loss=0.3684, LR=0.000100
[2025-08-11 01:50:29,346][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096480] [Batch 00488/03692] [00:04:24/00:28:58, 0.543s/it]: train_loss_raw=0.3854, running_loss=0.3670, LR=0.000100
[2025-08-11 01:50:35,726][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096492] [Batch 00500/03692] [00:04:31/00:28:51, 0.542s/it]: train_loss_raw=0.3768, running_loss=0.3691, LR=0.000100
[2025-08-11 01:50:42,129][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096504] [Batch 00512/03692] [00:04:37/00:28:44, 0.542s/it]: train_loss_raw=0.4569, running_loss=0.3721, LR=0.000100
[2025-08-11 01:50:48,582][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096516] [Batch 00524/03692] [00:04:44/00:28:37, 0.542s/it]: train_loss_raw=0.3400, running_loss=0.3720, LR=0.000100
[2025-08-11 01:50:54,930][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096528] [Batch 00536/03692] [00:04:50/00:28:29, 0.542s/it]: train_loss_raw=0.3368, running_loss=0.3710, LR=0.000100
[2025-08-11 01:51:01,378][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096540] [Batch 00548/03692] [00:04:56/00:28:23, 0.542s/it]: train_loss_raw=0.3350, running_loss=0.3700, LR=0.000100
[2025-08-11 01:51:07,802][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096552] [Batch 00560/03692] [00:05:03/00:28:16, 0.542s/it]: train_loss_raw=0.2715, running_loss=0.3686, LR=0.000100
[2025-08-11 01:51:14,211][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096564] [Batch 00572/03692] [00:05:09/00:28:09, 0.541s/it]: train_loss_raw=0.3472, running_loss=0.3692, LR=0.000100
[2025-08-11 01:51:20,586][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096576] [Batch 00584/03692] [00:05:16/00:28:02, 0.541s/it]: train_loss_raw=0.3671, running_loss=0.3697, LR=0.000100
[2025-08-11 01:51:26,921][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096588] [Batch 00596/03692] [00:05:22/00:27:54, 0.541s/it]: train_loss_raw=0.5091, running_loss=0.3702, LR=0.000100
[2025-08-11 01:51:33,502][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096600] [Batch 00608/03692] [00:05:28/00:27:48, 0.541s/it]: train_loss_raw=0.3925, running_loss=0.3698, LR=0.000100
[2025-08-11 01:51:39,901][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096612] [Batch 00620/03692] [00:05:35/00:27:41, 0.541s/it]: train_loss_raw=0.4076, running_loss=0.3705, LR=0.000100
[2025-08-11 01:51:46,208][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096624] [Batch 00632/03692] [00:05:41/00:27:34, 0.541s/it]: train_loss_raw=0.4069, running_loss=0.3733, LR=0.000100
[2025-08-11 01:51:52,637][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096636] [Batch 00644/03692] [00:05:48/00:27:27, 0.541s/it]: train_loss_raw=0.3715, running_loss=0.3702, LR=0.000100
[2025-08-11 01:51:59,053][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096648] [Batch 00656/03692] [00:05:54/00:27:20, 0.540s/it]: train_loss_raw=0.4175, running_loss=0.3701, LR=0.000100
[2025-08-11 01:52:05,456][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096660] [Batch 00668/03692] [00:06:00/00:27:13, 0.540s/it]: train_loss_raw=0.3495, running_loss=0.3687, LR=0.000100
[2025-08-11 01:52:11,802][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096672] [Batch 00680/03692] [00:06:07/00:27:06, 0.540s/it]: train_loss_raw=0.3486, running_loss=0.3691, LR=0.000100
[2025-08-11 01:52:18,129][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096684] [Batch 00692/03692] [00:06:13/00:26:59, 0.540s/it]: train_loss_raw=0.3528, running_loss=0.3675, LR=0.000100
[2025-08-11 01:52:24,517][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096696] [Batch 00704/03692] [00:06:19/00:26:52, 0.540s/it]: train_loss_raw=0.3425, running_loss=0.3705, LR=0.000100
[2025-08-11 01:52:30,904][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096708] [Batch 00716/03692] [00:06:26/00:26:45, 0.540s/it]: train_loss_raw=0.4382, running_loss=0.3707, LR=0.000100
[2025-08-11 01:52:37,290][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096720] [Batch 00728/03692] [00:06:32/00:26:39, 0.540s/it]: train_loss_raw=0.3677, running_loss=0.3727, LR=0.000100
[2025-08-11 01:52:43,690][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096732] [Batch 00740/03692] [00:06:39/00:26:32, 0.539s/it]: train_loss_raw=0.3044, running_loss=0.3714, LR=0.000100
[2025-08-11 01:52:50,058][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096744] [Batch 00752/03692] [00:06:45/00:26:25, 0.539s/it]: train_loss_raw=0.3118, running_loss=0.3731, LR=0.000100
[2025-08-11 01:52:56,423][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096756] [Batch 00764/03692] [00:06:51/00:26:18, 0.539s/it]: train_loss_raw=0.2595, running_loss=0.3710, LR=0.000100
[2025-08-11 01:53:02,781][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096768] [Batch 00776/03692] [00:06:58/00:26:11, 0.539s/it]: train_loss_raw=0.3619, running_loss=0.3702, LR=0.000100
[2025-08-11 01:53:09,112][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096780] [Batch 00788/03692] [00:07:04/00:26:04, 0.539s/it]: train_loss_raw=0.4627, running_loss=0.3742, LR=0.000100
[2025-08-11 01:53:15,516][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096792] [Batch 00800/03692] [00:07:10/00:25:58, 0.539s/it]: train_loss_raw=0.3798, running_loss=0.3728, LR=0.000100
[2025-08-11 01:53:21,895][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096804] [Batch 00812/03692] [00:07:17/00:25:51, 0.539s/it]: train_loss_raw=0.3322, running_loss=0.3726, LR=0.000100
[2025-08-11 01:53:28,270][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096816] [Batch 00824/03692] [00:07:23/00:25:44, 0.539s/it]: train_loss_raw=0.4417, running_loss=0.3740, LR=0.000100
[2025-08-11 01:53:34,637][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096828] [Batch 00836/03692] [00:07:30/00:25:37, 0.538s/it]: train_loss_raw=0.3951, running_loss=0.3783, LR=0.000100
[2025-08-11 01:53:41,046][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096840] [Batch 00848/03692] [00:07:36/00:25:31, 0.538s/it]: train_loss_raw=0.3723, running_loss=0.3797, LR=0.000100
[2025-08-11 01:53:47,398][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096852] [Batch 00860/03692] [00:07:42/00:25:24, 0.538s/it]: train_loss_raw=0.3952, running_loss=0.3783, LR=0.000100
[2025-08-11 01:53:53,932][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096864] [Batch 00872/03692] [00:07:49/00:25:18, 0.538s/it]: train_loss_raw=0.3707, running_loss=0.3783, LR=0.000100
[2025-08-11 01:54:00,282][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096876] [Batch 00884/03692] [00:07:55/00:25:11, 0.538s/it]: train_loss_raw=0.3719, running_loss=0.3773, LR=0.000100
[2025-08-11 01:54:06,680][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096888] [Batch 00896/03692] [00:08:02/00:25:04, 0.538s/it]: train_loss_raw=0.3017, running_loss=0.3786, LR=0.000100
[2025-08-11 01:54:13,164][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096900] [Batch 00908/03692] [00:08:08/00:24:58, 0.538s/it]: train_loss_raw=0.2635, running_loss=0.3788, LR=0.000100
[2025-08-11 01:54:19,569][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096912] [Batch 00920/03692] [00:08:15/00:24:51, 0.538s/it]: train_loss_raw=0.3719, running_loss=0.3783, LR=0.000100
[2025-08-11 01:54:25,986][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096924] [Batch 00932/03692] [00:08:21/00:24:45, 0.538s/it]: train_loss_raw=0.3190, running_loss=0.3777, LR=0.000100
[2025-08-11 01:54:32,336][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096936] [Batch 00944/03692] [00:08:27/00:24:38, 0.538s/it]: train_loss_raw=0.3898, running_loss=0.3767, LR=0.000100
[2025-08-11 01:54:38,783][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096948] [Batch 00956/03692] [00:08:34/00:24:31, 0.538s/it]: train_loss_raw=0.4103, running_loss=0.3785, LR=0.000100
[2025-08-11 01:54:45,202][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096960] [Batch 00968/03692] [00:08:40/00:24:25, 0.538s/it]: train_loss_raw=0.4419, running_loss=0.3789, LR=0.000100
[2025-08-11 01:54:51,743][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096972] [Batch 00980/03692] [00:08:47/00:24:18, 0.538s/it]: train_loss_raw=0.3656, running_loss=0.3799, LR=0.000100
[2025-08-11 01:54:58,220][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096984] [Batch 00992/03692] [00:08:53/00:24:12, 0.538s/it]: train_loss_raw=0.3308, running_loss=0.3754, LR=0.000100
[2025-08-11 01:55:04,681][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 096996] [Batch 01004/03692] [00:09:00/00:24:06, 0.538s/it]: train_loss_raw=0.3255, running_loss=0.3756, LR=0.000100
[2025-08-11 01:55:11,179][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097008] [Batch 01016/03692] [00:09:06/00:23:59, 0.538s/it]: train_loss_raw=0.3630, running_loss=0.3734, LR=0.000100
[2025-08-11 01:55:17,718][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097020] [Batch 01028/03692] [00:09:13/00:23:53, 0.538s/it]: train_loss_raw=0.3716, running_loss=0.3728, LR=0.000100
[2025-08-11 01:55:24,085][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097032] [Batch 01040/03692] [00:09:19/00:23:46, 0.538s/it]: train_loss_raw=0.3684, running_loss=0.3703, LR=0.000100
[2025-08-11 01:55:30,455][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097044] [Batch 01052/03692] [00:09:25/00:23:40, 0.538s/it]: train_loss_raw=0.3796, running_loss=0.3725, LR=0.000100
[2025-08-11 01:55:36,859][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097056] [Batch 01064/03692] [00:09:32/00:23:33, 0.538s/it]: train_loss_raw=0.3876, running_loss=0.3698, LR=0.000100
[2025-08-11 01:55:43,236][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097068] [Batch 01076/03692] [00:09:38/00:23:26, 0.538s/it]: train_loss_raw=0.3564, running_loss=0.3718, LR=0.000100
[2025-08-11 01:55:49,621][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097080] [Batch 01088/03692] [00:09:45/00:23:20, 0.538s/it]: train_loss_raw=0.3592, running_loss=0.3739, LR=0.000100
[2025-08-11 01:55:56,035][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097092] [Batch 01100/03692] [00:09:51/00:23:13, 0.538s/it]: train_loss_raw=0.4774, running_loss=0.3778, LR=0.000100
[2025-08-11 01:56:02,343][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097104] [Batch 01112/03692] [00:09:57/00:23:07, 0.538s/it]: train_loss_raw=0.3676, running_loss=0.3767, LR=0.000100
[2025-08-11 01:56:08,759][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097116] [Batch 01124/03692] [00:10:04/00:23:00, 0.538s/it]: train_loss_raw=0.3088, running_loss=0.3754, LR=0.000100
[2025-08-11 01:56:15,185][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097128] [Batch 01136/03692] [00:10:10/00:22:53, 0.538s/it]: train_loss_raw=0.3296, running_loss=0.3735, LR=0.000100
[2025-08-11 01:56:21,557][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097140] [Batch 01148/03692] [00:10:17/00:22:47, 0.537s/it]: train_loss_raw=0.4147, running_loss=0.3753, LR=0.000100
[2025-08-11 01:56:27,927][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097152] [Batch 01160/03692] [00:10:23/00:22:40, 0.537s/it]: train_loss_raw=0.3241, running_loss=0.3715, LR=0.000100
[2025-08-11 01:56:34,349][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097164] [Batch 01172/03692] [00:10:29/00:22:34, 0.537s/it]: train_loss_raw=0.3020, running_loss=0.3743, LR=0.000100
[2025-08-11 01:56:40,648][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097176] [Batch 01184/03692] [00:10:36/00:22:27, 0.537s/it]: train_loss_raw=0.3660, running_loss=0.3756, LR=0.000100
[2025-08-11 01:56:47,000][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097188] [Batch 01196/03692] [00:10:42/00:22:20, 0.537s/it]: train_loss_raw=0.3743, running_loss=0.3780, LR=0.000100
[2025-08-11 01:56:53,376][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097200] [Batch 01208/03692] [00:10:48/00:22:14, 0.537s/it]: train_loss_raw=0.4112, running_loss=0.3779, LR=0.000100
[2025-08-11 01:56:59,836][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097212] [Batch 01220/03692] [00:10:55/00:22:07, 0.537s/it]: train_loss_raw=0.3756, running_loss=0.3768, LR=0.000100
[2025-08-11 01:57:06,440][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097224] [Batch 01232/03692] [00:11:01/00:22:01, 0.537s/it]: train_loss_raw=0.4366, running_loss=0.3757, LR=0.000100
[2025-08-11 01:57:12,818][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097236] [Batch 01244/03692] [00:11:08/00:21:55, 0.537s/it]: train_loss_raw=0.3622, running_loss=0.3765, LR=0.000100
[2025-08-11 01:57:19,213][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097248] [Batch 01256/03692] [00:11:14/00:21:48, 0.537s/it]: train_loss_raw=0.2635, running_loss=0.3780, LR=0.000100
[2025-08-11 01:57:25,692][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097260] [Batch 01268/03692] [00:11:21/00:21:42, 0.537s/it]: train_loss_raw=0.3055, running_loss=0.3787, LR=0.000100
[2025-08-11 01:57:32,172][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097272] [Batch 01280/03692] [00:11:27/00:21:35, 0.537s/it]: train_loss_raw=0.2849, running_loss=0.3791, LR=0.000100
[2025-08-11 01:57:38,567][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097284] [Batch 01292/03692] [00:11:34/00:21:29, 0.537s/it]: train_loss_raw=0.3825, running_loss=0.3801, LR=0.000100
[2025-08-11 01:57:44,898][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097296] [Batch 01304/03692] [00:11:40/00:21:22, 0.537s/it]: train_loss_raw=0.3736, running_loss=0.3805, LR=0.000100
[2025-08-11 01:57:51,341][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097308] [Batch 01316/03692] [00:11:46/00:21:16, 0.537s/it]: train_loss_raw=0.4216, running_loss=0.3809, LR=0.000100
[2025-08-11 01:57:57,716][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097320] [Batch 01328/03692] [00:11:53/00:21:09, 0.537s/it]: train_loss_raw=0.4035, running_loss=0.3807, LR=0.000100
[2025-08-11 01:58:04,132][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097332] [Batch 01340/03692] [00:11:59/00:21:03, 0.537s/it]: train_loss_raw=0.3279, running_loss=0.3767, LR=0.000100
[2025-08-11 01:58:10,582][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097344] [Batch 01352/03692] [00:12:06/00:20:56, 0.537s/it]: train_loss_raw=0.3756, running_loss=0.3758, LR=0.000100
[2025-08-11 01:58:16,972][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097356] [Batch 01364/03692] [00:12:12/00:20:50, 0.537s/it]: train_loss_raw=0.3647, running_loss=0.3741, LR=0.000100
[2025-08-11 01:58:23,323][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097368] [Batch 01376/03692] [00:12:18/00:20:43, 0.537s/it]: train_loss_raw=0.4780, running_loss=0.3761, LR=0.000100
[2025-08-11 01:58:29,766][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097380] [Batch 01388/03692] [00:12:25/00:20:37, 0.537s/it]: train_loss_raw=0.4115, running_loss=0.3732, LR=0.000100
[2025-08-11 01:58:36,125][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097392] [Batch 01400/03692] [00:12:31/00:20:30, 0.537s/it]: train_loss_raw=0.3747, running_loss=0.3740, LR=0.000100
[2025-08-11 01:58:42,570][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097404] [Batch 01412/03692] [00:12:38/00:20:24, 0.537s/it]: train_loss_raw=0.3669, running_loss=0.3713, LR=0.000100
[2025-08-11 01:58:48,985][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097416] [Batch 01424/03692] [00:12:44/00:20:17, 0.537s/it]: train_loss_raw=0.3215, running_loss=0.3702, LR=0.000100
[2025-08-11 01:58:55,370][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097428] [Batch 01436/03692] [00:12:50/00:20:11, 0.537s/it]: train_loss_raw=0.4963, running_loss=0.3739, LR=0.000100
[2025-08-11 01:59:01,691][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097440] [Batch 01448/03692] [00:12:57/00:20:04, 0.537s/it]: train_loss_raw=0.3330, running_loss=0.3749, LR=0.000100
[2025-08-11 01:59:08,059][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097452] [Batch 01460/03692] [00:13:03/00:19:57, 0.537s/it]: train_loss_raw=0.3405, running_loss=0.3710, LR=0.000100
[2025-08-11 01:59:14,494][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097464] [Batch 01472/03692] [00:13:09/00:19:51, 0.537s/it]: train_loss_raw=0.4008, running_loss=0.3726, LR=0.000100
[2025-08-11 01:59:20,901][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097476] [Batch 01484/03692] [00:13:16/00:19:44, 0.537s/it]: train_loss_raw=0.5177, running_loss=0.3752, LR=0.000100
[2025-08-11 01:59:27,280][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097488] [Batch 01496/03692] [00:13:22/00:19:38, 0.537s/it]: train_loss_raw=0.4411, running_loss=0.3760, LR=0.000100
[2025-08-11 01:59:33,683][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097500] [Batch 01508/03692] [00:13:29/00:19:31, 0.537s/it]: train_loss_raw=0.2724, running_loss=0.3747, LR=0.000100
[2025-08-11 01:59:40,103][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097512] [Batch 01520/03692] [00:13:35/00:19:25, 0.537s/it]: train_loss_raw=0.3338, running_loss=0.3788, LR=0.000100
[2025-08-11 01:59:46,535][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097524] [Batch 01532/03692] [00:13:42/00:19:18, 0.537s/it]: train_loss_raw=0.4136, running_loss=0.3805, LR=0.000100
[2025-08-11 02:00:16,472][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097536] [Batch 01544/03692] [00:14:11/00:19:45, 0.552s/it]: train_loss_raw=0.5254, running_loss=0.3812, LR=0.000100
[2025-08-11 02:00:22,848][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097548] [Batch 01556/03692] [00:14:18/00:19:38, 0.552s/it]: train_loss_raw=0.4576, running_loss=0.3837, LR=0.000100
[2025-08-11 02:00:29,230][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097560] [Batch 01568/03692] [00:14:24/00:19:31, 0.551s/it]: train_loss_raw=0.3349, running_loss=0.3833, LR=0.000100
[2025-08-11 02:00:35,519][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097572] [Batch 01580/03692] [00:14:30/00:19:24, 0.551s/it]: train_loss_raw=0.4160, running_loss=0.3859, LR=0.000100
[2025-08-11 02:00:41,865][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097584] [Batch 01592/03692] [00:14:37/00:19:17, 0.551s/it]: train_loss_raw=0.3433, running_loss=0.3869, LR=0.000100
[2025-08-11 02:00:48,323][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097596] [Batch 01604/03692] [00:14:43/00:19:10, 0.551s/it]: train_loss_raw=0.3018, running_loss=0.3857, LR=0.000100
[2025-08-11 02:00:54,683][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097608] [Batch 01616/03692] [00:14:50/00:19:03, 0.551s/it]: train_loss_raw=0.3822, running_loss=0.3877, LR=0.000100
[2025-08-11 02:01:01,137][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097620] [Batch 01628/03692] [00:14:56/00:18:56, 0.551s/it]: train_loss_raw=0.4422, running_loss=0.3896, LR=0.000100
[2025-08-11 02:01:07,536][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097632] [Batch 01640/03692] [00:15:03/00:18:49, 0.551s/it]: train_loss_raw=0.4638, running_loss=0.3906, LR=0.000100
[2025-08-11 02:01:13,770][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097644] [Batch 01652/03692] [00:15:09/00:18:42, 0.550s/it]: train_loss_raw=0.3867, running_loss=0.3899, LR=0.000100
[2025-08-11 02:01:20,004][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097656] [Batch 01664/03692] [00:15:15/00:18:35, 0.550s/it]: train_loss_raw=0.3321, running_loss=0.3907, LR=0.000100
[2025-08-11 02:01:26,176][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097668] [Batch 01676/03692] [00:15:21/00:18:28, 0.550s/it]: train_loss_raw=0.4252, running_loss=0.3915, LR=0.000100
[2025-08-11 02:01:32,362][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097680] [Batch 01688/03692] [00:15:27/00:18:21, 0.550s/it]: train_loss_raw=0.2921, running_loss=0.3922, LR=0.000100
[2025-08-11 02:01:38,691][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097692] [Batch 01700/03692] [00:15:34/00:18:14, 0.550s/it]: train_loss_raw=0.3292, running_loss=0.3905, LR=0.000100
[2025-08-11 02:01:44,710][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097704] [Batch 01712/03692] [00:15:40/00:18:07, 0.549s/it]: train_loss_raw=0.3808, running_loss=0.3923, LR=0.000100
[2025-08-11 02:01:50,797][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097716] [Batch 01724/03692] [00:15:46/00:18:00, 0.549s/it]: train_loss_raw=0.3663, running_loss=0.3938, LR=0.000100
[2025-08-11 02:01:57,200][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097728] [Batch 01736/03692] [00:15:52/00:17:53, 0.549s/it]: train_loss_raw=0.3378, running_loss=0.3925, LR=0.000100
[2025-08-11 02:02:03,567][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097740] [Batch 01748/03692] [00:15:59/00:17:46, 0.549s/it]: train_loss_raw=0.4113, running_loss=0.3923, LR=0.000100
[2025-08-11 02:02:09,754][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097752] [Batch 01760/03692] [00:16:05/00:17:39, 0.548s/it]: train_loss_raw=0.4254, running_loss=0.3925, LR=0.000100
[2025-08-11 02:02:15,895][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097764] [Batch 01772/03692] [00:16:11/00:17:32, 0.548s/it]: train_loss_raw=0.4852, running_loss=0.3933, LR=0.000100
[2025-08-11 02:02:22,078][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097776] [Batch 01784/03692] [00:16:17/00:17:25, 0.548s/it]: train_loss_raw=0.2964, running_loss=0.3912, LR=0.000100
[2025-08-11 02:02:28,111][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097788] [Batch 01796/03692] [00:16:23/00:17:18, 0.548s/it]: train_loss_raw=0.3475, running_loss=0.3935, LR=0.000100
[2025-08-11 02:02:34,225][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097800] [Batch 01808/03692] [00:16:29/00:17:11, 0.547s/it]: train_loss_raw=0.3429, running_loss=0.3941, LR=0.000100
[2025-08-11 02:02:40,279][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097812] [Batch 01820/03692] [00:16:35/00:17:04, 0.547s/it]: train_loss_raw=0.2979, running_loss=0.3930, LR=0.000100
[2025-08-11 02:02:46,286][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097824] [Batch 01832/03692] [00:16:41/00:16:57, 0.547s/it]: train_loss_raw=0.3512, running_loss=0.3911, LR=0.000100
[2025-08-11 02:02:52,371][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097836] [Batch 01844/03692] [00:16:47/00:16:50, 0.547s/it]: train_loss_raw=0.4040, running_loss=0.3919, LR=0.000100
[2025-08-11 02:02:58,535][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097848] [Batch 01856/03692] [00:16:54/00:16:43, 0.546s/it]: train_loss_raw=0.3663, running_loss=0.3913, LR=0.000100
[2025-08-11 02:03:04,698][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097860] [Batch 01868/03692] [00:17:00/00:16:36, 0.546s/it]: train_loss_raw=0.4362, running_loss=0.3945, LR=0.000100
[2025-08-11 02:03:10,952][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097872] [Batch 01880/03692] [00:17:06/00:16:29, 0.546s/it]: train_loss_raw=0.3952, running_loss=0.3924, LR=0.000100
[2025-08-11 02:03:17,131][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097884] [Batch 01892/03692] [00:17:12/00:16:22, 0.546s/it]: train_loss_raw=0.3590, running_loss=0.3878, LR=0.000100
[2025-08-11 02:03:23,340][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097896] [Batch 01904/03692] [00:17:18/00:16:15, 0.546s/it]: train_loss_raw=0.4329, running_loss=0.3887, LR=0.000100
[2025-08-11 02:03:29,479][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097908] [Batch 01916/03692] [00:17:24/00:16:08, 0.545s/it]: train_loss_raw=0.3433, running_loss=0.3898, LR=0.000100
[2025-08-11 02:03:35,677][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097920] [Batch 01928/03692] [00:17:31/00:16:01, 0.545s/it]: train_loss_raw=0.3061, running_loss=0.3873, LR=0.000100
[2025-08-11 02:03:41,821][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097932] [Batch 01940/03692] [00:17:37/00:15:54, 0.545s/it]: train_loss_raw=0.3576, running_loss=0.3887, LR=0.000100
[2025-08-11 02:03:47,882][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097944] [Batch 01952/03692] [00:17:43/00:15:47, 0.545s/it]: train_loss_raw=0.4286, running_loss=0.3890, LR=0.000100
[2025-08-11 02:03:54,141][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097956] [Batch 01964/03692] [00:17:49/00:15:41, 0.545s/it]: train_loss_raw=0.3667, running_loss=0.3896, LR=0.000100
[2025-08-11 02:04:00,448][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097968] [Batch 01976/03692] [00:17:55/00:15:34, 0.544s/it]: train_loss_raw=0.3266, running_loss=0.3897, LR=0.000100
[2025-08-11 02:04:06,864][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097980] [Batch 01988/03692] [00:18:02/00:15:27, 0.544s/it]: train_loss_raw=0.4004, running_loss=0.3894, LR=0.000100
[2025-08-11 02:04:12,959][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 097992] [Batch 02000/03692] [00:18:08/00:15:20, 0.544s/it]: train_loss_raw=0.4082, running_loss=0.3913, LR=0.000100
[2025-08-11 02:04:23,509][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098004] [Batch 02012/03692] [00:18:18/00:15:17, 0.546s/it]: train_loss_raw=0.4353, running_loss=0.3917, LR=0.000100
[2025-08-11 02:04:29,543][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098016] [Batch 02024/03692] [00:18:25/00:15:10, 0.546s/it]: train_loss_raw=0.3155, running_loss=0.3931, LR=0.000100
[2025-08-11 02:04:35,724][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098028] [Batch 02036/03692] [00:18:31/00:15:03, 0.546s/it]: train_loss_raw=0.3075, running_loss=0.3913, LR=0.000100
[2025-08-11 02:04:41,910][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098040] [Batch 02048/03692] [00:18:37/00:14:56, 0.546s/it]: train_loss_raw=0.4940, running_loss=0.3905, LR=0.000100
[2025-08-11 02:04:48,108][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098052] [Batch 02060/03692] [00:18:43/00:14:50, 0.545s/it]: train_loss_raw=0.4723, running_loss=0.3925, LR=0.000100
[2025-08-11 02:04:54,490][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098064] [Batch 02072/03692] [00:18:49/00:14:43, 0.545s/it]: train_loss_raw=0.2796, running_loss=0.3930, LR=0.000100
[2025-08-11 02:05:00,699][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098076] [Batch 02084/03692] [00:18:56/00:14:36, 0.545s/it]: train_loss_raw=0.3897, running_loss=0.3909, LR=0.000100
[2025-08-11 02:05:06,938][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098088] [Batch 02096/03692] [00:19:02/00:14:29, 0.545s/it]: train_loss_raw=0.3834, running_loss=0.3920, LR=0.000100
[2025-08-11 02:05:13,129][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098100] [Batch 02108/03692] [00:19:08/00:14:23, 0.545s/it]: train_loss_raw=0.3805, running_loss=0.3949, LR=0.000100
[2025-08-11 02:05:19,403][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098112] [Batch 02120/03692] [00:19:14/00:14:16, 0.545s/it]: train_loss_raw=0.3990, running_loss=0.3953, LR=0.000100
[2025-08-11 02:05:25,874][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098124] [Batch 02132/03692] [00:19:21/00:14:09, 0.545s/it]: train_loss_raw=0.3225, running_loss=0.3951, LR=0.000100
[2025-08-11 02:05:32,024][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098136] [Batch 02144/03692] [00:19:27/00:14:02, 0.545s/it]: train_loss_raw=0.4210, running_loss=0.3954, LR=0.000100
[2025-08-11 02:05:38,438][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098148] [Batch 02156/03692] [00:19:33/00:13:56, 0.544s/it]: train_loss_raw=0.4337, running_loss=0.3954, LR=0.000100
[2025-08-11 02:05:45,045][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098160] [Batch 02168/03692] [00:19:40/00:13:49, 0.545s/it]: train_loss_raw=0.3505, running_loss=0.3974, LR=0.000100
[2025-08-11 02:05:51,442][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098172] [Batch 02180/03692] [00:19:46/00:13:43, 0.544s/it]: train_loss_raw=0.4090, running_loss=0.3966, LR=0.000100
[2025-08-11 02:05:57,463][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098184] [Batch 02192/03692] [00:19:52/00:13:36, 0.544s/it]: train_loss_raw=0.3328, running_loss=0.3974, LR=0.000100
[2025-08-11 02:06:03,625][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098196] [Batch 02204/03692] [00:19:59/00:13:29, 0.544s/it]: train_loss_raw=0.4057, running_loss=0.3979, LR=0.000100
[2025-08-11 02:06:09,739][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098208] [Batch 02216/03692] [00:20:05/00:13:22, 0.544s/it]: train_loss_raw=0.4440, running_loss=0.3975, LR=0.000100
[2025-08-11 02:06:16,280][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098220] [Batch 02228/03692] [00:20:11/00:13:16, 0.544s/it]: train_loss_raw=0.4352, running_loss=0.3978, LR=0.000100
[2025-08-11 02:06:22,333][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098232] [Batch 02240/03692] [00:20:17/00:13:09, 0.544s/it]: train_loss_raw=0.4509, running_loss=0.3966, LR=0.000100
[2025-08-11 02:06:28,374][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098244] [Batch 02252/03692] [00:20:23/00:13:02, 0.543s/it]: train_loss_raw=0.3133, running_loss=0.3954, LR=0.000100
[2025-08-11 02:06:34,445][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098256] [Batch 02264/03692] [00:20:29/00:12:55, 0.543s/it]: train_loss_raw=0.3227, running_loss=0.3964, LR=0.000100
[2025-08-11 02:06:40,449][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098268] [Batch 02276/03692] [00:20:35/00:12:48, 0.543s/it]: train_loss_raw=0.3318, running_loss=0.3930, LR=0.000100
[2025-08-11 02:06:46,451][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098280] [Batch 02288/03692] [00:20:41/00:12:42, 0.543s/it]: train_loss_raw=0.3201, running_loss=0.3926, LR=0.000100
[2025-08-11 02:06:52,524][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098292] [Batch 02300/03692] [00:20:47/00:12:35, 0.543s/it]: train_loss_raw=0.3190, running_loss=0.3906, LR=0.000100
[2025-08-11 02:06:58,530][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098304] [Batch 02312/03692] [00:20:54/00:12:28, 0.542s/it]: train_loss_raw=0.3893, running_loss=0.3927, LR=0.000100
[2025-08-11 02:07:04,561][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098316] [Batch 02324/03692] [00:21:00/00:12:21, 0.542s/it]: train_loss_raw=0.3691, running_loss=0.3922, LR=0.000100
[2025-08-11 02:07:10,586][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098328] [Batch 02336/03692] [00:21:06/00:12:14, 0.542s/it]: train_loss_raw=0.4041, running_loss=0.3914, LR=0.000100
[2025-08-11 02:07:16,673][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098340] [Batch 02348/03692] [00:21:12/00:12:08, 0.542s/it]: train_loss_raw=0.4302, running_loss=0.3872, LR=0.000100
[2025-08-11 02:07:22,919][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098352] [Batch 02360/03692] [00:21:18/00:12:01, 0.542s/it]: train_loss_raw=0.3382, running_loss=0.3867, LR=0.000100
[2025-08-11 02:07:29,072][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098364] [Batch 02372/03692] [00:21:24/00:11:54, 0.542s/it]: train_loss_raw=0.3854, running_loss=0.3872, LR=0.000100
[2025-08-11 02:07:35,102][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098376] [Batch 02384/03692] [00:21:30/00:11:48, 0.541s/it]: train_loss_raw=0.3612, running_loss=0.3872, LR=0.000100
[2025-08-11 02:07:41,478][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098388] [Batch 02396/03692] [00:21:36/00:11:41, 0.541s/it]: train_loss_raw=0.4600, running_loss=0.3866, LR=0.000100
[2025-08-11 02:07:47,683][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098400] [Batch 02408/03692] [00:21:43/00:11:34, 0.541s/it]: train_loss_raw=0.3533, running_loss=0.3895, LR=0.000100
[2025-08-11 02:07:53,720][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098412] [Batch 02420/03692] [00:21:49/00:11:28, 0.541s/it]: train_loss_raw=0.2625, running_loss=0.3864, LR=0.000100
[2025-08-11 02:07:59,908][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098424] [Batch 02432/03692] [00:21:55/00:11:21, 0.541s/it]: train_loss_raw=0.4373, running_loss=0.3882, LR=0.000100
[2025-08-11 02:08:06,167][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098436] [Batch 02444/03692] [00:22:01/00:11:14, 0.541s/it]: train_loss_raw=0.4249, running_loss=0.3885, LR=0.000100
[2025-08-11 02:08:12,338][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098448] [Batch 02456/03692] [00:22:07/00:11:08, 0.541s/it]: train_loss_raw=0.3835, running_loss=0.3874, LR=0.000100
[2025-08-11 02:08:18,873][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098460] [Batch 02468/03692] [00:22:14/00:11:01, 0.541s/it]: train_loss_raw=0.2932, running_loss=0.3897, LR=0.000100
[2025-08-11 02:08:25,385][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098472] [Batch 02480/03692] [00:22:20/00:10:55, 0.541s/it]: train_loss_raw=0.4312, running_loss=0.3917, LR=0.000100
[2025-08-11 02:08:31,720][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098484] [Batch 02492/03692] [00:22:27/00:10:48, 0.541s/it]: train_loss_raw=0.3810, running_loss=0.3927, LR=0.000100
[2025-08-11 02:08:38,226][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098496] [Batch 02504/03692] [00:22:33/00:10:42, 0.541s/it]: train_loss_raw=0.4018, running_loss=0.3939, LR=0.000100
[2025-08-11 02:08:44,654][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098508] [Batch 02516/03692] [00:22:40/00:10:35, 0.541s/it]: train_loss_raw=0.3667, running_loss=0.3925, LR=0.000100
[2025-08-11 02:08:51,124][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098520] [Batch 02528/03692] [00:22:46/00:10:29, 0.541s/it]: train_loss_raw=0.4116, running_loss=0.3928, LR=0.000100
[2025-08-11 02:08:57,601][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098532] [Batch 02540/03692] [00:22:53/00:10:22, 0.541s/it]: train_loss_raw=0.4092, running_loss=0.3918, LR=0.000100
[2025-08-11 02:09:03,976][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098544] [Batch 02552/03692] [00:22:59/00:10:16, 0.541s/it]: train_loss_raw=0.4146, running_loss=0.3910, LR=0.000100
[2025-08-11 02:09:10,333][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098556] [Batch 02564/03692] [00:23:05/00:10:09, 0.540s/it]: train_loss_raw=0.3453, running_loss=0.3890, LR=0.000100
[2025-08-11 02:09:16,845][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098568] [Batch 02576/03692] [00:23:12/00:10:03, 0.540s/it]: train_loss_raw=0.4065, running_loss=0.3889, LR=0.000100
[2025-08-11 02:09:23,242][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098580] [Batch 02588/03692] [00:23:18/00:09:56, 0.540s/it]: train_loss_raw=0.4096, running_loss=0.3907, LR=0.000100
[2025-08-11 02:09:29,543][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098592] [Batch 02600/03692] [00:23:25/00:09:50, 0.540s/it]: train_loss_raw=0.3555, running_loss=0.3891, LR=0.000100
[2025-08-11 02:09:35,941][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098604] [Batch 02612/03692] [00:23:31/00:09:43, 0.540s/it]: train_loss_raw=0.4753, running_loss=0.3872, LR=0.000100
[2025-08-11 02:09:42,378][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098616] [Batch 02624/03692] [00:23:37/00:09:37, 0.540s/it]: train_loss_raw=0.4143, running_loss=0.3866, LR=0.000100
[2025-08-11 02:09:48,816][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098628] [Batch 02636/03692] [00:23:44/00:09:30, 0.540s/it]: train_loss_raw=0.3466, running_loss=0.3877, LR=0.000100
[2025-08-11 02:09:55,460][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098640] [Batch 02648/03692] [00:23:50/00:09:24, 0.540s/it]: train_loss_raw=0.3884, running_loss=0.3909, LR=0.000100
[2025-08-11 02:10:01,927][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098652] [Batch 02660/03692] [00:23:57/00:09:17, 0.540s/it]: train_loss_raw=0.3218, running_loss=0.3913, LR=0.000100
[2025-08-11 02:10:08,415][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098664] [Batch 02672/03692] [00:24:03/00:09:11, 0.540s/it]: train_loss_raw=0.3605, running_loss=0.3941, LR=0.000100
[2025-08-11 02:10:14,909][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098676] [Batch 02684/03692] [00:24:10/00:09:04, 0.540s/it]: train_loss_raw=0.3529, running_loss=0.3927, LR=0.000100
[2025-08-11 02:10:21,371][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098688] [Batch 02696/03692] [00:24:16/00:08:58, 0.540s/it]: train_loss_raw=0.4329, running_loss=0.3914, LR=0.000100
[2025-08-11 02:10:27,755][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098700] [Batch 02708/03692] [00:24:23/00:08:51, 0.540s/it]: train_loss_raw=0.4005, running_loss=0.3902, LR=0.000100
[2025-08-11 02:10:34,168][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098712] [Batch 02720/03692] [00:24:29/00:08:45, 0.540s/it]: train_loss_raw=0.3316, running_loss=0.3876, LR=0.000100
[2025-08-11 02:10:40,640][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098724] [Batch 02732/03692] [00:24:36/00:08:38, 0.540s/it]: train_loss_raw=0.4401, running_loss=0.3892, LR=0.000100
[2025-08-11 02:10:47,150][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098736] [Batch 02744/03692] [00:24:42/00:08:32, 0.540s/it]: train_loss_raw=0.4272, running_loss=0.3891, LR=0.000100
[2025-08-11 02:10:53,539][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098748] [Batch 02756/03692] [00:24:49/00:08:25, 0.540s/it]: train_loss_raw=0.4019, running_loss=0.3873, LR=0.000100
[2025-08-11 02:10:59,605][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098760] [Batch 02768/03692] [00:24:55/00:08:19, 0.540s/it]: train_loss_raw=0.3696, running_loss=0.3870, LR=0.000100
[2025-08-11 02:11:05,645][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098772] [Batch 02780/03692] [00:25:01/00:08:12, 0.540s/it]: train_loss_raw=0.3936, running_loss=0.3869, LR=0.000100
[2025-08-11 02:11:11,701][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098784] [Batch 02792/03692] [00:25:07/00:08:05, 0.540s/it]: train_loss_raw=0.3702, running_loss=0.3902, LR=0.000100
[2025-08-11 02:11:18,296][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098796] [Batch 02804/03692] [00:25:13/00:07:59, 0.540s/it]: train_loss_raw=0.3382, running_loss=0.3910, LR=0.000100
[2025-08-11 02:11:24,844][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098808] [Batch 02816/03692] [00:25:20/00:07:52, 0.540s/it]: train_loss_raw=0.3112, running_loss=0.3900, LR=0.000100
[2025-08-11 02:11:31,355][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098820] [Batch 02828/03692] [00:25:26/00:07:46, 0.540s/it]: train_loss_raw=0.3751, running_loss=0.3904, LR=0.000100
[2025-08-11 02:11:37,814][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098832] [Batch 02840/03692] [00:25:33/00:07:39, 0.540s/it]: train_loss_raw=0.2936, running_loss=0.3902, LR=0.000100
[2025-08-11 02:11:44,293][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098844] [Batch 02852/03692] [00:25:39/00:07:33, 0.540s/it]: train_loss_raw=0.3777, running_loss=0.3924, LR=0.000100
[2025-08-11 02:11:50,778][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098856] [Batch 02864/03692] [00:25:46/00:07:27, 0.540s/it]: train_loss_raw=0.3990, running_loss=0.3902, LR=0.000100
[2025-08-11 02:11:57,149][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098868] [Batch 02876/03692] [00:25:52/00:07:20, 0.540s/it]: train_loss_raw=0.3484, running_loss=0.3891, LR=0.000100
[2025-08-11 02:12:03,432][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098880] [Batch 02888/03692] [00:25:58/00:07:13, 0.540s/it]: train_loss_raw=0.3898, running_loss=0.3901, LR=0.000100
[2025-08-11 02:12:09,689][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098892] [Batch 02900/03692] [00:26:05/00:07:07, 0.540s/it]: train_loss_raw=0.3270, running_loss=0.3896, LR=0.000100
[2025-08-11 02:12:16,325][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098904] [Batch 02912/03692] [00:26:11/00:07:01, 0.540s/it]: train_loss_raw=0.3057, running_loss=0.3904, LR=0.000100
[2025-08-11 02:12:22,367][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098916] [Batch 02924/03692] [00:26:17/00:06:54, 0.540s/it]: train_loss_raw=0.4416, running_loss=0.3940, LR=0.000100
[2025-08-11 02:12:28,772][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098928] [Batch 02936/03692] [00:26:24/00:06:47, 0.540s/it]: train_loss_raw=0.4362, running_loss=0.3914, LR=0.000100
[2025-08-11 02:12:35,308][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098940] [Batch 02948/03692] [00:26:30/00:06:41, 0.540s/it]: train_loss_raw=0.4069, running_loss=0.3938, LR=0.000100
[2025-08-11 02:12:41,618][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098952] [Batch 02960/03692] [00:26:37/00:06:34, 0.540s/it]: train_loss_raw=0.4222, running_loss=0.3911, LR=0.000100
[2025-08-11 02:12:47,926][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098964] [Batch 02972/03692] [00:26:43/00:06:28, 0.540s/it]: train_loss_raw=0.3907, running_loss=0.3901, LR=0.000100
[2025-08-11 02:12:53,932][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098976] [Batch 02984/03692] [00:26:49/00:06:21, 0.539s/it]: train_loss_raw=0.3978, running_loss=0.3910, LR=0.000100
[2025-08-11 02:12:59,920][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 098988] [Batch 02996/03692] [00:26:55/00:06:15, 0.539s/it]: train_loss_raw=0.4301, running_loss=0.3928, LR=0.000100
[2025-08-11 02:13:05,927][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099000] [Batch 03008/03692] [00:27:01/00:06:08, 0.539s/it]: train_loss_raw=0.4186, running_loss=0.3934, LR=0.000100
[2025-08-11 02:13:12,001][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099012] [Batch 03020/03692] [00:27:07/00:06:02, 0.539s/it]: train_loss_raw=0.4152, running_loss=0.3940, LR=0.000100
[2025-08-11 02:13:18,012][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099024] [Batch 03032/03692] [00:27:13/00:05:55, 0.539s/it]: train_loss_raw=0.3395, running_loss=0.3918, LR=0.000100
[2025-08-11 02:13:24,096][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099036] [Batch 03044/03692] [00:27:19/00:05:49, 0.539s/it]: train_loss_raw=0.3901, running_loss=0.3899, LR=0.000100
[2025-08-11 02:13:30,478][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099048] [Batch 03056/03692] [00:27:25/00:05:42, 0.539s/it]: train_loss_raw=0.4897, running_loss=0.3886, LR=0.000100
[2025-08-11 02:13:37,003][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099060] [Batch 03068/03692] [00:27:32/00:05:36, 0.539s/it]: train_loss_raw=0.4953, running_loss=0.3905, LR=0.000100
[2025-08-11 02:13:43,384][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099072] [Batch 03080/03692] [00:27:38/00:05:29, 0.539s/it]: train_loss_raw=0.3097, running_loss=0.3899, LR=0.000100
[2025-08-11 02:13:49,869][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099084] [Batch 03092/03692] [00:27:45/00:05:23, 0.539s/it]: train_loss_raw=0.3012, running_loss=0.3856, LR=0.000100
[2025-08-11 02:13:56,409][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099096] [Batch 03104/03692] [00:27:51/00:05:16, 0.539s/it]: train_loss_raw=0.3635, running_loss=0.3885, LR=0.000100
[2025-08-11 02:14:02,795][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099108] [Batch 03116/03692] [00:27:58/00:05:10, 0.539s/it]: train_loss_raw=0.3364, running_loss=0.3865, LR=0.000100
[2025-08-11 02:14:09,129][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099120] [Batch 03128/03692] [00:28:04/00:05:03, 0.539s/it]: train_loss_raw=0.4651, running_loss=0.3892, LR=0.000100
[2025-08-11 02:14:15,499][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099132] [Batch 03140/03692] [00:28:10/00:04:57, 0.539s/it]: train_loss_raw=0.3529, running_loss=0.3870, LR=0.000100
[2025-08-11 02:14:21,885][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099144] [Batch 03152/03692] [00:28:17/00:04:50, 0.539s/it]: train_loss_raw=0.3437, running_loss=0.3887, LR=0.000100
[2025-08-11 02:14:28,327][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099156] [Batch 03164/03692] [00:28:23/00:04:44, 0.538s/it]: train_loss_raw=0.4169, running_loss=0.3888, LR=0.000100
[2025-08-11 02:14:34,755][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099168] [Batch 03176/03692] [00:28:30/00:04:37, 0.538s/it]: train_loss_raw=0.3805, running_loss=0.3926, LR=0.000100
[2025-08-11 02:14:41,157][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099180] [Batch 03188/03692] [00:28:36/00:04:31, 0.538s/it]: train_loss_raw=0.3581, running_loss=0.3944, LR=0.000100
[2025-08-11 02:14:47,608][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099192] [Batch 03200/03692] [00:28:43/00:04:24, 0.538s/it]: train_loss_raw=0.3091, running_loss=0.3934, LR=0.000100
[2025-08-11 02:14:54,160][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099204] [Batch 03212/03692] [00:28:49/00:04:18, 0.538s/it]: train_loss_raw=0.3758, running_loss=0.3929, LR=0.000100
[2025-08-11 02:15:00,618][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099216] [Batch 03224/03692] [00:28:56/00:04:12, 0.538s/it]: train_loss_raw=0.3662, running_loss=0.3932, LR=0.000100
[2025-08-11 02:15:06,650][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099228] [Batch 03236/03692] [00:29:02/00:04:05, 0.538s/it]: train_loss_raw=0.4104, running_loss=0.3913, LR=0.000100
[2025-08-11 02:15:12,833][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099240] [Batch 03248/03692] [00:29:08/00:03:58, 0.538s/it]: train_loss_raw=0.3292, running_loss=0.3916, LR=0.000100
[2025-08-11 02:15:19,246][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099252] [Batch 03260/03692] [00:29:14/00:03:52, 0.538s/it]: train_loss_raw=0.3253, running_loss=0.3909, LR=0.000100
[2025-08-11 02:15:25,684][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099264] [Batch 03272/03692] [00:29:21/00:03:46, 0.538s/it]: train_loss_raw=0.4335, running_loss=0.3923, LR=0.000100
[2025-08-11 02:15:32,154][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099276] [Batch 03284/03692] [00:29:27/00:03:39, 0.538s/it]: train_loss_raw=0.3656, running_loss=0.3896, LR=0.000100
[2025-08-11 02:15:38,641][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099288] [Batch 03296/03692] [00:29:34/00:03:33, 0.538s/it]: train_loss_raw=0.3999, running_loss=0.3867, LR=0.000100
[2025-08-11 02:15:45,130][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099300] [Batch 03308/03692] [00:29:40/00:03:26, 0.538s/it]: train_loss_raw=0.2486, running_loss=0.3851, LR=0.000100
[2025-08-11 02:15:51,596][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099312] [Batch 03320/03692] [00:29:47/00:03:20, 0.538s/it]: train_loss_raw=0.4273, running_loss=0.3858, LR=0.000100
[2025-08-11 02:15:57,909][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099324] [Batch 03332/03692] [00:29:53/00:03:13, 0.538s/it]: train_loss_raw=0.4299, running_loss=0.3871, LR=0.000100
[2025-08-11 02:16:04,303][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099336] [Batch 03344/03692] [00:29:59/00:03:07, 0.538s/it]: train_loss_raw=0.4002, running_loss=0.3868, LR=0.000100
[2025-08-11 02:16:10,659][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099348] [Batch 03356/03692] [00:30:06/00:03:00, 0.538s/it]: train_loss_raw=0.3449, running_loss=0.3868, LR=0.000100
[2025-08-11 02:16:17,083][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099360] [Batch 03368/03692] [00:30:12/00:02:54, 0.538s/it]: train_loss_raw=0.4164, running_loss=0.3853, LR=0.000100
[2025-08-11 02:16:23,504][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099372] [Batch 03380/03692] [00:30:18/00:02:47, 0.538s/it]: train_loss_raw=0.3896, running_loss=0.3866, LR=0.000100
[2025-08-11 02:16:29,870][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099384] [Batch 03392/03692] [00:30:25/00:02:41, 0.538s/it]: train_loss_raw=0.2909, running_loss=0.3857, LR=0.000100
[2025-08-11 02:16:36,205][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099396] [Batch 03404/03692] [00:30:31/00:02:34, 0.538s/it]: train_loss_raw=0.2955, running_loss=0.3878, LR=0.000100
[2025-08-11 02:16:42,516][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099408] [Batch 03416/03692] [00:30:37/00:02:28, 0.538s/it]: train_loss_raw=0.3763, running_loss=0.3896, LR=0.000100
[2025-08-11 02:16:48,921][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099420] [Batch 03428/03692] [00:30:44/00:02:22, 0.538s/it]: train_loss_raw=0.4129, running_loss=0.3899, LR=0.000100
[2025-08-11 02:16:55,275][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099432] [Batch 03440/03692] [00:30:50/00:02:15, 0.538s/it]: train_loss_raw=0.3619, running_loss=0.3921, LR=0.000100
[2025-08-11 02:17:01,686][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099444] [Batch 03452/03692] [00:30:57/00:02:09, 0.538s/it]: train_loss_raw=0.3751, running_loss=0.3921, LR=0.000100
[2025-08-11 02:17:08,124][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099456] [Batch 03464/03692] [00:31:03/00:02:02, 0.538s/it]: train_loss_raw=0.3786, running_loss=0.3925, LR=0.000100
[2025-08-11 02:17:14,496][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099468] [Batch 03476/03692] [00:31:09/00:01:56, 0.538s/it]: train_loss_raw=0.3843, running_loss=0.3943, LR=0.000100
[2025-08-11 02:17:20,974][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099480] [Batch 03488/03692] [00:31:16/00:01:49, 0.538s/it]: train_loss_raw=0.3694, running_loss=0.3945, LR=0.000100
[2025-08-11 02:17:27,352][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099492] [Batch 03500/03692] [00:31:22/00:01:43, 0.538s/it]: train_loss_raw=0.2856, running_loss=0.3943, LR=0.000100
[2025-08-11 02:17:33,731][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099504] [Batch 03512/03692] [00:31:29/00:01:36, 0.538s/it]: train_loss_raw=0.4917, running_loss=0.3939, LR=0.000100
[2025-08-11 02:17:40,214][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099516] [Batch 03524/03692] [00:31:35/00:01:30, 0.538s/it]: train_loss_raw=0.4453, running_loss=0.3917, LR=0.000100
[2025-08-11 02:17:46,770][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099528] [Batch 03536/03692] [00:31:42/00:01:23, 0.538s/it]: train_loss_raw=0.3366, running_loss=0.3901, LR=0.000100
[2025-08-11 02:17:53,146][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099540] [Batch 03548/03692] [00:31:48/00:01:17, 0.538s/it]: train_loss_raw=0.4033, running_loss=0.3889, LR=0.000100
[2025-08-11 02:17:59,557][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099552] [Batch 03560/03692] [00:31:55/00:01:11, 0.538s/it]: train_loss_raw=0.5231, running_loss=0.3895, LR=0.000100
[2025-08-11 02:18:05,973][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099564] [Batch 03572/03692] [00:32:01/00:01:04, 0.538s/it]: train_loss_raw=0.3048, running_loss=0.3872, LR=0.000100
[2025-08-11 02:18:12,475][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099576] [Batch 03584/03692] [00:32:07/00:00:58, 0.538s/it]: train_loss_raw=0.3316, running_loss=0.3844, LR=0.000100
[2025-08-11 02:18:19,038][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099588] [Batch 03596/03692] [00:32:14/00:00:51, 0.538s/it]: train_loss_raw=0.3188, running_loss=0.3826, LR=0.000100
[2025-08-11 02:18:25,530][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099600] [Batch 03608/03692] [00:32:21/00:00:45, 0.538s/it]: train_loss_raw=0.3559, running_loss=0.3841, LR=0.000100
[2025-08-11 02:18:31,905][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099612] [Batch 03620/03692] [00:32:27/00:00:38, 0.538s/it]: train_loss_raw=0.4353, running_loss=0.3857, LR=0.000100
[2025-08-11 02:18:38,312][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099624] [Batch 03632/03692] [00:32:33/00:00:32, 0.538s/it]: train_loss_raw=0.3869, running_loss=0.3868, LR=0.000100
[2025-08-11 02:18:44,823][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099636] [Batch 03644/03692] [00:32:40/00:00:25, 0.538s/it]: train_loss_raw=0.4465, running_loss=0.3902, LR=0.000100
[2025-08-11 02:18:51,336][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099648] [Batch 03656/03692] [00:32:46/00:00:19, 0.538s/it]: train_loss_raw=0.3131, running_loss=0.3881, LR=0.000100
[2025-08-11 02:18:57,847][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099660] [Batch 03668/03692] [00:32:53/00:00:12, 0.538s/it]: train_loss_raw=0.4395, running_loss=0.3923, LR=0.000100
[2025-08-11 02:19:04,213][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099672] [Batch 03680/03692] [00:32:59/00:00:06, 0.538s/it]: train_loss_raw=0.2792, running_loss=0.3904, LR=0.000100
[2025-08-11 02:19:10,635][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 099684] [Batch 03692/03692] [00:33:06/00:00:00, 0.538s/it]: train_loss_raw=0.3444, running_loss=0.3936, LR=0.000100
[2025-08-11 02:19:16,164][__main__][INFO] - [VALIDATION] [Epoch 26/29] Starting validation.
[2025-08-11 02:19:50,119][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 099685] [Batch 00011/00025] [00:00:33/00:00:36, 2.830s/it]
[2025-08-11 02:20:06,285][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 099685] [Batch 00023/00025] [00:00:50/00:00:02, 2.088s/it]
[2025-08-11 02:20:07,437][__main__][INFO] - [VALIDATION] [Epoch 26/29] train_loss=0.39358, valid_loss=0.57521
[2025-08-11 02:20:07,438][__main__][INFO] - [VALIDATION] [Epoch 26/29] Metrics:
[2025-08-11 02:20:07,438][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_er      0.232
[2025-08-11 02:20:07,438][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_prec    0.568
[2025-08-11 02:20:07,438][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_recall  0.572
[2025-08-11 02:20:07,438][__main__][INFO] - [VALIDATION] [Epoch 26/29] - pep_recall 0.557
[2025-08-11 02:20:07,442][__main__][INFO] - [TRAIN] [Epoch 26/29] Epoch complete, total time 15:24:06, remaining time 01:42:40, 00:34:13 per epoch
[2025-08-11 02:20:15,103][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099696] [Batch 00012/03692] [00:00:06/00:31:17, 0.510s/it]: train_loss_raw=0.3218, running_loss=0.4384, LR=0.000100
[2025-08-11 02:20:21,543][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099708] [Batch 00024/03692] [00:00:12/00:32:00, 0.523s/it]: train_loss_raw=0.4521, running_loss=0.4337, LR=0.000100
[2025-08-11 02:20:28,028][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099720] [Batch 00036/03692] [00:00:19/00:32:14, 0.529s/it]: train_loss_raw=0.4168, running_loss=0.4284, LR=0.000100
[2025-08-11 02:20:34,437][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099732] [Batch 00048/03692] [00:00:25/00:32:12, 0.530s/it]: train_loss_raw=0.2648, running_loss=0.4241, LR=0.000100
[2025-08-11 02:20:40,793][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099744] [Batch 00060/03692] [00:00:31/00:32:05, 0.530s/it]: train_loss_raw=0.4106, running_loss=0.4196, LR=0.000100
[2025-08-11 02:20:47,348][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099756] [Batch 00072/03692] [00:00:38/00:32:09, 0.533s/it]: train_loss_raw=0.4111, running_loss=0.4143, LR=0.000100
[2025-08-11 02:20:53,916][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099768] [Batch 00084/03692] [00:00:44/00:32:10, 0.535s/it]: train_loss_raw=0.3491, running_loss=0.4118, LR=0.000100
[2025-08-11 02:21:00,230][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099780] [Batch 00096/03692] [00:00:51/00:31:59, 0.534s/it]: train_loss_raw=0.3455, running_loss=0.4067, LR=0.000100
[2025-08-11 02:21:06,764][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099792] [Batch 00108/03692] [00:00:57/00:31:57, 0.535s/it]: train_loss_raw=0.2887, running_loss=0.4050, LR=0.000100
[2025-08-11 02:21:13,288][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099804] [Batch 00120/03692] [00:01:04/00:31:54, 0.536s/it]: train_loss_raw=0.4268, running_loss=0.4067, LR=0.000100
[2025-08-11 02:21:19,775][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099816] [Batch 00132/03692] [00:01:10/00:31:49, 0.536s/it]: train_loss_raw=0.3896, running_loss=0.4051, LR=0.000100
[2025-08-11 02:21:26,248][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099828] [Batch 00144/03692] [00:01:17/00:31:43, 0.537s/it]: train_loss_raw=0.4761, running_loss=0.4022, LR=0.000100
[2025-08-11 02:21:32,413][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099840] [Batch 00156/03692] [00:01:23/00:31:31, 0.535s/it]: train_loss_raw=0.3722, running_loss=0.4021, LR=0.000100
[2025-08-11 02:21:38,461][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099852] [Batch 00168/03692] [00:01:29/00:31:16, 0.533s/it]: train_loss_raw=0.3763, running_loss=0.4001, LR=0.000100
[2025-08-11 02:21:44,929][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099864] [Batch 00180/03692] [00:01:35/00:31:12, 0.533s/it]: train_loss_raw=0.2710, running_loss=0.3971, LR=0.000100
[2025-08-11 02:21:51,424][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099876] [Batch 00192/03692] [00:01:42/00:31:07, 0.534s/it]: train_loss_raw=0.3772, running_loss=0.3959, LR=0.000100
[2025-08-11 02:21:57,899][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099888] [Batch 00204/03692] [00:01:48/00:31:02, 0.534s/it]: train_loss_raw=0.3835, running_loss=0.3941, LR=0.000100
[2025-08-11 02:22:04,113][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099900] [Batch 00216/03692] [00:01:55/00:30:52, 0.533s/it]: train_loss_raw=0.3829, running_loss=0.3936, LR=0.000100
[2025-08-11 02:22:10,096][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099912] [Batch 00228/03692] [00:02:01/00:30:40, 0.531s/it]: train_loss_raw=0.4293, running_loss=0.3919, LR=0.000100
[2025-08-11 02:22:16,552][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099924] [Batch 00240/03692] [00:02:07/00:30:34, 0.532s/it]: train_loss_raw=0.3135, running_loss=0.3906, LR=0.000100
[2025-08-11 02:22:22,559][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099936] [Batch 00252/03692] [00:02:13/00:30:23, 0.530s/it]: train_loss_raw=0.3478, running_loss=0.3903, LR=0.000100
[2025-08-11 02:22:28,587][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099948] [Batch 00264/03692] [00:02:19/00:30:12, 0.529s/it]: train_loss_raw=0.3212, running_loss=0.3879, LR=0.000100
[2025-08-11 02:22:34,634][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099960] [Batch 00276/03692] [00:02:25/00:30:02, 0.528s/it]: train_loss_raw=0.3793, running_loss=0.3891, LR=0.000100
[2025-08-11 02:22:40,960][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099972] [Batch 00288/03692] [00:02:31/00:29:56, 0.528s/it]: train_loss_raw=0.4408, running_loss=0.3894, LR=0.000100
[2025-08-11 02:22:47,343][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099984] [Batch 00300/03692] [00:02:38/00:29:50, 0.528s/it]: train_loss_raw=0.3831, running_loss=0.3864, LR=0.000100
[2025-08-11 02:22:53,729][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 099996] [Batch 00312/03692] [00:02:44/00:29:44, 0.528s/it]: train_loss_raw=0.3483, running_loss=0.3855, LR=0.000100
[2025-08-11 02:23:05,220][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100008] [Batch 00324/03692] [00:02:56/00:30:32, 0.544s/it]: train_loss_raw=0.2557, running_loss=0.3867, LR=0.000100
[2025-08-11 02:23:11,744][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100020] [Batch 00336/03692] [00:03:02/00:30:25, 0.544s/it]: train_loss_raw=0.3703, running_loss=0.3864, LR=0.000100
[2025-08-11 02:23:18,283][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100032] [Batch 00348/03692] [00:03:09/00:30:19, 0.544s/it]: train_loss_raw=0.3934, running_loss=0.3875, LR=0.000100
[2025-08-11 02:23:24,809][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100044] [Batch 00360/03692] [00:03:15/00:30:12, 0.544s/it]: train_loss_raw=0.4713, running_loss=0.3853, LR=0.000100
[2025-08-11 02:23:31,209][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100056] [Batch 00372/03692] [00:03:22/00:30:04, 0.544s/it]: train_loss_raw=0.3692, running_loss=0.3873, LR=0.000100
[2025-08-11 02:23:37,672][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100068] [Batch 00384/03692] [00:03:28/00:29:57, 0.543s/it]: train_loss_raw=0.4206, running_loss=0.3878, LR=0.000100
[2025-08-11 02:23:44,127][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100080] [Batch 00396/03692] [00:03:35/00:29:50, 0.543s/it]: train_loss_raw=0.4161, running_loss=0.3851, LR=0.000100
[2025-08-11 02:23:50,373][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100092] [Batch 00408/03692] [00:03:41/00:29:42, 0.543s/it]: train_loss_raw=0.4339, running_loss=0.3861, LR=0.000100
[2025-08-11 02:23:56,636][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100104] [Batch 00420/03692] [00:03:47/00:29:33, 0.542s/it]: train_loss_raw=0.3911, running_loss=0.3848, LR=0.000100
[2025-08-11 02:24:03,124][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100116] [Batch 00432/03692] [00:03:54/00:29:26, 0.542s/it]: train_loss_raw=0.4478, running_loss=0.3862, LR=0.000100
[2025-08-11 02:24:09,585][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100128] [Batch 00444/03692] [00:04:00/00:29:20, 0.542s/it]: train_loss_raw=0.3925, running_loss=0.3856, LR=0.000100
[2025-08-11 02:24:16,067][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100140] [Batch 00456/03692] [00:04:07/00:29:13, 0.542s/it]: train_loss_raw=0.4111, running_loss=0.3868, LR=0.000100
[2025-08-11 02:24:22,450][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100152] [Batch 00468/03692] [00:04:13/00:29:06, 0.542s/it]: train_loss_raw=0.4408, running_loss=0.3897, LR=0.000100
[2025-08-11 02:24:28,769][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100164] [Batch 00480/03692] [00:04:19/00:28:58, 0.541s/it]: train_loss_raw=0.4632, running_loss=0.3893, LR=0.000100
[2025-08-11 02:24:35,144][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100176] [Batch 00492/03692] [00:04:26/00:28:51, 0.541s/it]: train_loss_raw=0.4515, running_loss=0.3850, LR=0.000100
[2025-08-11 02:24:41,511][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100188] [Batch 00504/03692] [00:04:32/00:28:43, 0.541s/it]: train_loss_raw=0.3137, running_loss=0.3839, LR=0.000100
[2025-08-11 02:24:47,853][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100200] [Batch 00516/03692] [00:04:38/00:28:36, 0.540s/it]: train_loss_raw=0.4380, running_loss=0.3844, LR=0.000100
[2025-08-11 02:24:54,209][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100212] [Batch 00528/03692] [00:04:45/00:28:29, 0.540s/it]: train_loss_raw=0.5061, running_loss=0.3858, LR=0.000100
[2025-08-11 02:25:00,701][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100224] [Batch 00540/03692] [00:04:51/00:28:22, 0.540s/it]: train_loss_raw=0.3741, running_loss=0.3863, LR=0.000100
[2025-08-11 02:25:07,214][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100236] [Batch 00552/03692] [00:04:58/00:28:16, 0.540s/it]: train_loss_raw=0.4269, running_loss=0.3880, LR=0.000100
[2025-08-11 02:25:13,680][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100248] [Batch 00564/03692] [00:05:04/00:28:09, 0.540s/it]: train_loss_raw=0.3678, running_loss=0.3875, LR=0.000100
[2025-08-11 02:25:20,183][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100260] [Batch 00576/03692] [00:05:11/00:28:03, 0.540s/it]: train_loss_raw=0.4078, running_loss=0.3886, LR=0.000100
[2025-08-11 02:25:26,546][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100272] [Batch 00588/03692] [00:05:17/00:27:56, 0.540s/it]: train_loss_raw=0.5050, running_loss=0.3918, LR=0.000100
[2025-08-11 02:25:32,892][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100284] [Batch 00600/03692] [00:05:23/00:27:49, 0.540s/it]: train_loss_raw=0.4510, running_loss=0.3896, LR=0.000100
[2025-08-11 02:25:39,217][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100296] [Batch 00612/03692] [00:05:30/00:27:41, 0.540s/it]: train_loss_raw=0.4524, running_loss=0.3914, LR=0.000100
[2025-08-11 02:25:45,626][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100308] [Batch 00624/03692] [00:05:36/00:27:35, 0.539s/it]: train_loss_raw=0.4144, running_loss=0.3939, LR=0.000100
[2025-08-11 02:25:52,037][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100320] [Batch 00636/03692] [00:05:43/00:27:28, 0.539s/it]: train_loss_raw=0.4339, running_loss=0.3925, LR=0.000100
[2025-08-11 02:25:58,435][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100332] [Batch 00648/03692] [00:05:49/00:27:21, 0.539s/it]: train_loss_raw=0.3160, running_loss=0.3868, LR=0.000100
[2025-08-11 02:26:04,927][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100344] [Batch 00660/03692] [00:05:55/00:27:15, 0.539s/it]: train_loss_raw=0.3846, running_loss=0.3857, LR=0.000100
[2025-08-11 02:26:11,326][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100356] [Batch 00672/03692] [00:06:02/00:27:08, 0.539s/it]: train_loss_raw=0.4020, running_loss=0.3866, LR=0.000100
[2025-08-11 02:26:17,687][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100368] [Batch 00684/03692] [00:06:08/00:27:01, 0.539s/it]: train_loss_raw=0.2981, running_loss=0.3828, LR=0.000100
[2025-08-11 02:26:24,067][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100380] [Batch 00696/03692] [00:06:15/00:26:54, 0.539s/it]: train_loss_raw=0.3762, running_loss=0.3837, LR=0.000100
[2025-08-11 02:26:30,487][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100392] [Batch 00708/03692] [00:06:21/00:26:47, 0.539s/it]: train_loss_raw=0.4330, running_loss=0.3837, LR=0.000100
[2025-08-11 02:26:36,890][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100404] [Batch 00720/03692] [00:06:27/00:26:41, 0.539s/it]: train_loss_raw=0.4313, running_loss=0.3870, LR=0.000100
[2025-08-11 02:26:43,217][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100416] [Batch 00732/03692] [00:06:34/00:26:34, 0.539s/it]: train_loss_raw=0.5290, running_loss=0.3874, LR=0.000100
[2025-08-11 02:26:49,567][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100428] [Batch 00744/03692] [00:06:40/00:26:27, 0.538s/it]: train_loss_raw=0.3275, running_loss=0.3847, LR=0.000100
[2025-08-11 02:26:55,916][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100440] [Batch 00756/03692] [00:06:46/00:26:20, 0.538s/it]: train_loss_raw=0.4093, running_loss=0.3830, LR=0.000100
[2025-08-11 02:27:02,258][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100452] [Batch 00768/03692] [00:06:53/00:26:13, 0.538s/it]: train_loss_raw=0.3669, running_loss=0.3823, LR=0.000100
[2025-08-11 02:27:08,655][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100464] [Batch 00780/03692] [00:06:59/00:26:06, 0.538s/it]: train_loss_raw=0.3670, running_loss=0.3820, LR=0.000100
[2025-08-11 02:27:15,138][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100476] [Batch 00792/03692] [00:07:06/00:26:00, 0.538s/it]: train_loss_raw=0.4437, running_loss=0.3842, LR=0.000100
[2025-08-11 02:27:21,522][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100488] [Batch 00804/03692] [00:07:12/00:25:53, 0.538s/it]: train_loss_raw=0.3791, running_loss=0.3822, LR=0.000100
[2025-08-11 02:27:27,944][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100500] [Batch 00816/03692] [00:07:18/00:25:47, 0.538s/it]: train_loss_raw=0.3276, running_loss=0.3805, LR=0.000100
[2025-08-11 02:27:34,411][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100512] [Batch 00828/03692] [00:07:25/00:25:40, 0.538s/it]: train_loss_raw=0.4172, running_loss=0.3794, LR=0.000100
[2025-08-11 02:27:40,891][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100524] [Batch 00840/03692] [00:07:31/00:25:34, 0.538s/it]: train_loss_raw=0.4475, running_loss=0.3779, LR=0.000100
[2025-08-11 02:27:47,276][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100536] [Batch 00852/03692] [00:07:38/00:25:27, 0.538s/it]: train_loss_raw=0.4502, running_loss=0.3801, LR=0.000100
[2025-08-11 02:27:53,608][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100548] [Batch 00864/03692] [00:07:44/00:25:20, 0.538s/it]: train_loss_raw=0.3649, running_loss=0.3814, LR=0.000100
[2025-08-11 02:28:00,094][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100560] [Batch 00876/03692] [00:07:51/00:25:14, 0.538s/it]: train_loss_raw=0.3596, running_loss=0.3814, LR=0.000100
[2025-08-11 02:28:06,561][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100572] [Batch 00888/03692] [00:07:57/00:25:08, 0.538s/it]: train_loss_raw=0.3687, running_loss=0.3830, LR=0.000100
[2025-08-11 02:28:12,980][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100584] [Batch 00900/03692] [00:08:04/00:25:01, 0.538s/it]: train_loss_raw=0.3485, running_loss=0.3852, LR=0.000100
[2025-08-11 02:28:19,337][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100596] [Batch 00912/03692] [00:08:10/00:24:54, 0.538s/it]: train_loss_raw=0.3663, running_loss=0.3844, LR=0.000100
[2025-08-11 02:28:25,706][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100608] [Batch 00924/03692] [00:08:16/00:24:48, 0.538s/it]: train_loss_raw=0.4376, running_loss=0.3835, LR=0.000100
[2025-08-11 02:28:32,087][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100620] [Batch 00936/03692] [00:08:23/00:24:41, 0.538s/it]: train_loss_raw=0.4291, running_loss=0.3860, LR=0.000100
[2025-08-11 02:28:38,378][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100632] [Batch 00948/03692] [00:08:29/00:24:34, 0.537s/it]: train_loss_raw=0.3372, running_loss=0.3886, LR=0.000100
[2025-08-11 02:28:44,693][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100644] [Batch 00960/03692] [00:08:35/00:24:27, 0.537s/it]: train_loss_raw=0.3867, running_loss=0.3879, LR=0.000100
[2025-08-11 02:28:51,225][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100656] [Batch 00972/03692] [00:08:42/00:24:21, 0.537s/it]: train_loss_raw=0.3618, running_loss=0.3892, LR=0.000100
[2025-08-11 02:28:57,781][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100668] [Batch 00984/03692] [00:08:48/00:24:15, 0.537s/it]: train_loss_raw=0.3896, running_loss=0.3876, LR=0.000100
[2025-08-11 02:29:04,201][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100680] [Batch 00996/03692] [00:08:55/00:24:08, 0.537s/it]: train_loss_raw=0.2869, running_loss=0.3858, LR=0.000100
[2025-08-11 02:29:10,645][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100692] [Batch 01008/03692] [00:09:01/00:24:02, 0.537s/it]: train_loss_raw=0.3361, running_loss=0.3847, LR=0.000100
[2025-08-11 02:29:17,032][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100704] [Batch 01020/03692] [00:09:08/00:23:55, 0.537s/it]: train_loss_raw=0.2871, running_loss=0.3843, LR=0.000100
[2025-08-11 02:29:23,539][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100716] [Batch 01032/03692] [00:09:14/00:23:49, 0.537s/it]: train_loss_raw=0.3760, running_loss=0.3844, LR=0.000100
[2025-08-11 02:29:30,086][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100728] [Batch 01044/03692] [00:09:21/00:23:43, 0.537s/it]: train_loss_raw=0.3885, running_loss=0.3835, LR=0.000100
[2025-08-11 02:29:36,460][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100740] [Batch 01056/03692] [00:09:27/00:23:36, 0.537s/it]: train_loss_raw=0.3737, running_loss=0.3831, LR=0.000100
[2025-08-11 02:29:42,798][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100752] [Batch 01068/03692] [00:09:33/00:23:29, 0.537s/it]: train_loss_raw=0.3657, running_loss=0.3816, LR=0.000100
[2025-08-11 02:29:49,255][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100764] [Batch 01080/03692] [00:09:40/00:23:23, 0.537s/it]: train_loss_raw=0.4269, running_loss=0.3805, LR=0.000100
[2025-08-11 02:29:55,627][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100776] [Batch 01092/03692] [00:09:46/00:23:16, 0.537s/it]: train_loss_raw=0.4734, running_loss=0.3810, LR=0.000100
[2025-08-11 02:30:02,129][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100788] [Batch 01104/03692] [00:09:53/00:23:10, 0.537s/it]: train_loss_raw=0.4228, running_loss=0.3798, LR=0.000100
[2025-08-11 02:30:08,590][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100800] [Batch 01116/03692] [00:09:59/00:23:04, 0.537s/it]: train_loss_raw=0.4916, running_loss=0.3836, LR=0.000100
[2025-08-11 02:30:14,991][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100812] [Batch 01128/03692] [00:10:06/00:22:57, 0.537s/it]: train_loss_raw=0.3396, running_loss=0.3873, LR=0.000100
[2025-08-11 02:30:21,427][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100824] [Batch 01140/03692] [00:10:12/00:22:51, 0.537s/it]: train_loss_raw=0.3483, running_loss=0.3887, LR=0.000100
[2025-08-11 02:30:27,944][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100836] [Batch 01152/03692] [00:10:18/00:22:44, 0.537s/it]: train_loss_raw=0.4459, running_loss=0.3896, LR=0.000100
[2025-08-11 02:30:34,341][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100848] [Batch 01164/03692] [00:10:25/00:22:38, 0.537s/it]: train_loss_raw=0.3644, running_loss=0.3893, LR=0.000100
[2025-08-11 02:30:40,621][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100860] [Batch 01176/03692] [00:10:31/00:22:31, 0.537s/it]: train_loss_raw=0.3463, running_loss=0.3893, LR=0.000100
[2025-08-11 02:30:46,873][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100872] [Batch 01188/03692] [00:10:37/00:22:24, 0.537s/it]: train_loss_raw=0.4034, running_loss=0.3915, LR=0.000100
[2025-08-11 02:30:53,197][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100884] [Batch 01200/03692] [00:10:44/00:22:17, 0.537s/it]: train_loss_raw=0.4208, running_loss=0.3930, LR=0.000100
[2025-08-11 02:30:59,605][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100896] [Batch 01212/03692] [00:10:50/00:22:11, 0.537s/it]: train_loss_raw=0.4053, running_loss=0.3928, LR=0.000100
[2025-08-11 02:31:06,086][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100908] [Batch 01224/03692] [00:10:57/00:22:04, 0.537s/it]: train_loss_raw=0.4488, running_loss=0.3922, LR=0.000100
[2025-08-11 02:31:12,604][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100920] [Batch 01236/03692] [00:11:03/00:21:58, 0.537s/it]: train_loss_raw=0.3862, running_loss=0.3937, LR=0.000100
[2025-08-11 02:31:18,744][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100932] [Batch 01248/03692] [00:11:09/00:21:51, 0.537s/it]: train_loss_raw=0.3497, running_loss=0.3946, LR=0.000100
[2025-08-11 02:31:24,800][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100944] [Batch 01260/03692] [00:11:15/00:21:44, 0.536s/it]: train_loss_raw=0.3656, running_loss=0.3929, LR=0.000100
[2025-08-11 02:31:30,977][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100956] [Batch 01272/03692] [00:11:21/00:21:37, 0.536s/it]: train_loss_raw=0.4490, running_loss=0.3943, LR=0.000100
[2025-08-11 02:31:37,208][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100968] [Batch 01284/03692] [00:11:28/00:21:30, 0.536s/it]: train_loss_raw=0.3630, running_loss=0.3918, LR=0.000100
[2025-08-11 02:31:43,175][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100980] [Batch 01296/03692] [00:11:34/00:21:23, 0.536s/it]: train_loss_raw=0.4783, running_loss=0.3929, LR=0.000100
[2025-08-11 02:31:49,436][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 100992] [Batch 01308/03692] [00:11:40/00:21:16, 0.536s/it]: train_loss_raw=0.3202, running_loss=0.3911, LR=0.000100
[2025-08-11 02:31:55,982][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101004] [Batch 01320/03692] [00:11:47/00:21:10, 0.536s/it]: train_loss_raw=0.4107, running_loss=0.3910, LR=0.000100
[2025-08-11 02:32:02,105][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101016] [Batch 01332/03692] [00:11:53/00:21:03, 0.535s/it]: train_loss_raw=0.4124, running_loss=0.3904, LR=0.000100
[2025-08-11 02:32:08,557][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101028] [Batch 01344/03692] [00:11:59/00:20:57, 0.535s/it]: train_loss_raw=0.4123, running_loss=0.3901, LR=0.000100
[2025-08-11 02:32:15,059][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101040] [Batch 01356/03692] [00:12:06/00:20:50, 0.535s/it]: train_loss_raw=0.3894, running_loss=0.3891, LR=0.000100
[2025-08-11 02:32:21,160][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101052] [Batch 01368/03692] [00:12:12/00:20:43, 0.535s/it]: train_loss_raw=0.4057, running_loss=0.3904, LR=0.000100
[2025-08-11 02:32:27,259][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101064] [Batch 01380/03692] [00:12:18/00:20:36, 0.535s/it]: train_loss_raw=0.5073, running_loss=0.3919, LR=0.000100
[2025-08-11 02:32:33,463][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101076] [Batch 01392/03692] [00:12:24/00:20:30, 0.535s/it]: train_loss_raw=0.3273, running_loss=0.3900, LR=0.000100
[2025-08-11 02:32:39,539][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101088] [Batch 01404/03692] [00:12:30/00:20:23, 0.535s/it]: train_loss_raw=0.4374, running_loss=0.3917, LR=0.000100
[2025-08-11 02:32:46,055][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101100] [Batch 01416/03692] [00:12:37/00:20:16, 0.535s/it]: train_loss_raw=0.3714, running_loss=0.3909, LR=0.000100
[2025-08-11 02:32:52,608][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101112] [Batch 01428/03692] [00:12:43/00:20:10, 0.535s/it]: train_loss_raw=0.3785, running_loss=0.3880, LR=0.000100
[2025-08-11 02:32:59,155][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101124] [Batch 01440/03692] [00:12:50/00:20:04, 0.535s/it]: train_loss_raw=0.3801, running_loss=0.3897, LR=0.000100
[2025-08-11 02:33:05,668][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101136] [Batch 01452/03692] [00:12:56/00:19:58, 0.535s/it]: train_loss_raw=0.3782, running_loss=0.3879, LR=0.000100
[2025-08-11 02:33:12,103][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101148] [Batch 01464/03692] [00:13:03/00:19:51, 0.535s/it]: train_loss_raw=0.3803, running_loss=0.3892, LR=0.000100
[2025-08-11 02:33:18,449][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101160] [Batch 01476/03692] [00:13:09/00:19:45, 0.535s/it]: train_loss_raw=0.3878, running_loss=0.3887, LR=0.000100
[2025-08-11 02:33:24,958][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101172] [Batch 01488/03692] [00:13:15/00:19:38, 0.535s/it]: train_loss_raw=0.4383, running_loss=0.3886, LR=0.000100
[2025-08-11 02:33:31,523][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101184] [Batch 01500/03692] [00:13:22/00:19:32, 0.535s/it]: train_loss_raw=0.3858, running_loss=0.3872, LR=0.000100
[2025-08-11 02:33:37,777][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101196] [Batch 01512/03692] [00:13:28/00:19:26, 0.535s/it]: train_loss_raw=0.3873, running_loss=0.3845, LR=0.000100
[2025-08-11 02:33:43,930][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101208] [Batch 01524/03692] [00:13:34/00:19:19, 0.535s/it]: train_loss_raw=0.3495, running_loss=0.3842, LR=0.000100
[2025-08-11 02:33:50,055][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101220] [Batch 01536/03692] [00:13:41/00:19:12, 0.535s/it]: train_loss_raw=0.3894, running_loss=0.3835, LR=0.000100
[2025-08-11 02:33:56,155][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101232] [Batch 01548/03692] [00:13:47/00:19:05, 0.534s/it]: train_loss_raw=0.3760, running_loss=0.3834, LR=0.000100
[2025-08-11 02:34:02,242][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101244] [Batch 01560/03692] [00:13:53/00:18:58, 0.534s/it]: train_loss_raw=0.3280, running_loss=0.3836, LR=0.000100
[2025-08-11 02:34:08,281][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101256] [Batch 01572/03692] [00:13:59/00:18:51, 0.534s/it]: train_loss_raw=0.2753, running_loss=0.3833, LR=0.000100
[2025-08-11 02:34:14,291][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101268] [Batch 01584/03692] [00:14:05/00:18:44, 0.534s/it]: train_loss_raw=0.3360, running_loss=0.3816, LR=0.000100
[2025-08-11 02:34:20,379][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101280] [Batch 01596/03692] [00:14:11/00:18:38, 0.533s/it]: train_loss_raw=0.4227, running_loss=0.3814, LR=0.000100
[2025-08-11 02:34:26,672][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101292] [Batch 01608/03692] [00:14:17/00:18:31, 0.533s/it]: train_loss_raw=0.3340, running_loss=0.3822, LR=0.000100
[2025-08-11 02:34:32,843][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101304] [Batch 01620/03692] [00:14:23/00:18:24, 0.533s/it]: train_loss_raw=0.4222, running_loss=0.3847, LR=0.000100
[2025-08-11 02:34:39,060][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101316] [Batch 01632/03692] [00:14:30/00:18:18, 0.533s/it]: train_loss_raw=0.4037, running_loss=0.3837, LR=0.000100
[2025-08-11 02:34:45,179][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101328] [Batch 01644/03692] [00:14:36/00:18:11, 0.533s/it]: train_loss_raw=0.4361, running_loss=0.3838, LR=0.000100
[2025-08-11 02:34:51,236][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101340] [Batch 01656/03692] [00:14:42/00:18:04, 0.533s/it]: train_loss_raw=0.3573, running_loss=0.3828, LR=0.000100
[2025-08-11 02:34:57,449][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101352] [Batch 01668/03692] [00:14:48/00:17:58, 0.533s/it]: train_loss_raw=0.4010, running_loss=0.3839, LR=0.000100
[2025-08-11 02:35:03,770][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101364] [Batch 01680/03692] [00:14:54/00:17:51, 0.533s/it]: train_loss_raw=0.3294, running_loss=0.3823, LR=0.000100
[2025-08-11 02:35:10,013][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101376] [Batch 01692/03692] [00:15:01/00:17:45, 0.533s/it]: train_loss_raw=0.5542, running_loss=0.3828, LR=0.000100
[2025-08-11 02:35:16,362][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101388] [Batch 01704/03692] [00:15:07/00:17:38, 0.533s/it]: train_loss_raw=0.4194, running_loss=0.3833, LR=0.000100
[2025-08-11 02:35:22,843][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101400] [Batch 01716/03692] [00:15:13/00:17:32, 0.533s/it]: train_loss_raw=0.4381, running_loss=0.3857, LR=0.000100
[2025-08-11 02:35:29,108][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101412] [Batch 01728/03692] [00:15:20/00:17:25, 0.532s/it]: train_loss_raw=0.3768, running_loss=0.3858, LR=0.000100
[2025-08-11 02:35:35,320][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101424] [Batch 01740/03692] [00:15:26/00:17:19, 0.532s/it]: train_loss_raw=0.3571, running_loss=0.3865, LR=0.000100
[2025-08-11 02:35:41,548][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101436] [Batch 01752/03692] [00:15:32/00:17:12, 0.532s/it]: train_loss_raw=0.4532, running_loss=0.3872, LR=0.000100
[2025-08-11 02:35:47,574][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101448] [Batch 01764/03692] [00:15:38/00:17:05, 0.532s/it]: train_loss_raw=0.3663, running_loss=0.3870, LR=0.000100
[2025-08-11 02:35:53,599][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101460] [Batch 01776/03692] [00:15:44/00:16:59, 0.532s/it]: train_loss_raw=0.3400, running_loss=0.3876, LR=0.000100
[2025-08-11 02:35:59,673][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101472] [Batch 01788/03692] [00:15:50/00:16:52, 0.532s/it]: train_loss_raw=0.3719, running_loss=0.3869, LR=0.000100
[2025-08-11 02:36:06,139][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101484] [Batch 01800/03692] [00:15:57/00:16:46, 0.532s/it]: train_loss_raw=0.4013, running_loss=0.3894, LR=0.000100
[2025-08-11 02:36:12,269][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101496] [Batch 01812/03692] [00:16:03/00:16:39, 0.532s/it]: train_loss_raw=0.4106, running_loss=0.3893, LR=0.000100
[2025-08-11 02:36:18,466][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101508] [Batch 01824/03692] [00:16:09/00:16:32, 0.532s/it]: train_loss_raw=0.3877, running_loss=0.3903, LR=0.000100
[2025-08-11 02:36:24,935][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101520] [Batch 01836/03692] [00:16:15/00:16:26, 0.532s/it]: train_loss_raw=0.3793, running_loss=0.3872, LR=0.000100
[2025-08-11 02:36:31,404][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101532] [Batch 01848/03692] [00:16:22/00:16:20, 0.532s/it]: train_loss_raw=0.3996, running_loss=0.3857, LR=0.000100
[2025-08-11 02:36:37,603][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101544] [Batch 01860/03692] [00:16:28/00:16:13, 0.532s/it]: train_loss_raw=0.3986, running_loss=0.3866, LR=0.000100
[2025-08-11 02:36:43,649][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101556] [Batch 01872/03692] [00:16:34/00:16:07, 0.531s/it]: train_loss_raw=0.3687, running_loss=0.3881, LR=0.000100
[2025-08-11 02:36:49,604][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101568] [Batch 01884/03692] [00:16:40/00:16:00, 0.531s/it]: train_loss_raw=0.4305, running_loss=0.3854, LR=0.000100
[2025-08-11 02:36:55,683][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101580] [Batch 01896/03692] [00:16:46/00:15:53, 0.531s/it]: train_loss_raw=0.3986, running_loss=0.3895, LR=0.000100
[2025-08-11 02:37:01,684][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101592] [Batch 01908/03692] [00:16:52/00:15:46, 0.531s/it]: train_loss_raw=0.4344, running_loss=0.3896, LR=0.000100
[2025-08-11 02:37:07,847][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101604] [Batch 01920/03692] [00:16:58/00:15:40, 0.531s/it]: train_loss_raw=0.5096, running_loss=0.3925, LR=0.000100
[2025-08-11 02:37:14,075][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101616] [Batch 01932/03692] [00:17:05/00:15:33, 0.531s/it]: train_loss_raw=0.3966, running_loss=0.3908, LR=0.000100
[2025-08-11 02:37:20,640][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101628] [Batch 01944/03692] [00:17:11/00:15:27, 0.531s/it]: train_loss_raw=0.3620, running_loss=0.3906, LR=0.000100
[2025-08-11 02:37:26,848][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101640] [Batch 01956/03692] [00:17:17/00:15:21, 0.531s/it]: train_loss_raw=0.3697, running_loss=0.3896, LR=0.000100
[2025-08-11 02:37:32,987][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101652] [Batch 01968/03692] [00:17:24/00:15:14, 0.530s/it]: train_loss_raw=0.3461, running_loss=0.3901, LR=0.000100
[2025-08-11 02:37:39,227][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101664] [Batch 01980/03692] [00:17:30/00:15:08, 0.530s/it]: train_loss_raw=0.4253, running_loss=0.3889, LR=0.000100
[2025-08-11 02:37:45,784][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101676] [Batch 01992/03692] [00:17:36/00:15:01, 0.531s/it]: train_loss_raw=0.3856, running_loss=0.3911, LR=0.000100
[2025-08-11 02:37:52,335][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101688] [Batch 02004/03692] [00:17:43/00:14:55, 0.531s/it]: train_loss_raw=0.4274, running_loss=0.3885, LR=0.000100
[2025-08-11 02:37:58,705][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101700] [Batch 02016/03692] [00:17:49/00:14:49, 0.531s/it]: train_loss_raw=0.2879, running_loss=0.3879, LR=0.000100
[2025-08-11 02:38:04,908][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101712] [Batch 02028/03692] [00:17:55/00:14:42, 0.531s/it]: train_loss_raw=0.3020, running_loss=0.3869, LR=0.000100
[2025-08-11 02:38:11,011][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101724] [Batch 02040/03692] [00:18:02/00:14:36, 0.530s/it]: train_loss_raw=0.4630, running_loss=0.3880, LR=0.000100
[2025-08-11 02:38:16,970][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101736] [Batch 02052/03692] [00:18:07/00:14:29, 0.530s/it]: train_loss_raw=0.3215, running_loss=0.3896, LR=0.000100
[2025-08-11 02:38:23,171][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101748] [Batch 02064/03692] [00:18:14/00:14:23, 0.530s/it]: train_loss_raw=0.3602, running_loss=0.3849, LR=0.000100
[2025-08-11 02:38:29,247][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101760] [Batch 02076/03692] [00:18:20/00:14:16, 0.530s/it]: train_loss_raw=0.3821, running_loss=0.3874, LR=0.000100
[2025-08-11 02:38:35,456][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101772] [Batch 02088/03692] [00:18:26/00:14:09, 0.530s/it]: train_loss_raw=0.3541, running_loss=0.3840, LR=0.000100
[2025-08-11 02:38:41,836][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101784] [Batch 02100/03692] [00:18:32/00:14:03, 0.530s/it]: train_loss_raw=0.2999, running_loss=0.3822, LR=0.000100
[2025-08-11 02:38:47,857][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101796] [Batch 02112/03692] [00:18:38/00:13:57, 0.530s/it]: train_loss_raw=0.4937, running_loss=0.3824, LR=0.000100
[2025-08-11 02:38:53,903][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101808] [Batch 02124/03692] [00:18:44/00:13:50, 0.530s/it]: train_loss_raw=0.4618, running_loss=0.3807, LR=0.000100
[2025-08-11 02:39:00,337][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101820] [Batch 02136/03692] [00:18:51/00:13:44, 0.530s/it]: train_loss_raw=0.3041, running_loss=0.3826, LR=0.000100
[2025-08-11 02:39:06,840][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101832] [Batch 02148/03692] [00:18:57/00:13:37, 0.530s/it]: train_loss_raw=0.3541, running_loss=0.3802, LR=0.000100
[2025-08-11 02:39:20,124][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101844] [Batch 02160/03692] [00:19:11/00:13:36, 0.533s/it]: train_loss_raw=0.3640, running_loss=0.3832, LR=0.000100
[2025-08-11 02:39:26,422][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101856] [Batch 02172/03692] [00:19:17/00:13:29, 0.533s/it]: train_loss_raw=0.4340, running_loss=0.3800, LR=0.000100
[2025-08-11 02:39:32,437][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101868] [Batch 02184/03692] [00:19:23/00:13:23, 0.533s/it]: train_loss_raw=0.4592, running_loss=0.3827, LR=0.000100
[2025-08-11 02:39:38,419][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101880] [Batch 02196/03692] [00:19:29/00:13:16, 0.533s/it]: train_loss_raw=0.4165, running_loss=0.3815, LR=0.000100
[2025-08-11 02:39:44,377][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101892] [Batch 02208/03692] [00:19:35/00:13:09, 0.532s/it]: train_loss_raw=0.4034, running_loss=0.3805, LR=0.000100
[2025-08-11 02:39:50,457][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101904] [Batch 02220/03692] [00:19:41/00:13:03, 0.532s/it]: train_loss_raw=0.4261, running_loss=0.3789, LR=0.000100
[2025-08-11 02:39:56,656][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101916] [Batch 02232/03692] [00:19:47/00:12:56, 0.532s/it]: train_loss_raw=0.3240, running_loss=0.3768, LR=0.000100
[2025-08-11 02:40:02,870][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101928] [Batch 02244/03692] [00:19:53/00:12:50, 0.532s/it]: train_loss_raw=0.4495, running_loss=0.3806, LR=0.000100
[2025-08-11 02:40:09,288][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101940] [Batch 02256/03692] [00:20:00/00:12:44, 0.532s/it]: train_loss_raw=0.4208, running_loss=0.3832, LR=0.000100
[2025-08-11 02:40:15,781][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101952] [Batch 02268/03692] [00:20:06/00:12:37, 0.532s/it]: train_loss_raw=0.3861, running_loss=0.3838, LR=0.000100
[2025-08-11 02:40:22,355][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101964] [Batch 02280/03692] [00:20:13/00:12:31, 0.532s/it]: train_loss_raw=0.3276, running_loss=0.3844, LR=0.000100
[2025-08-11 02:40:28,512][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101976] [Batch 02292/03692] [00:20:19/00:12:24, 0.532s/it]: train_loss_raw=0.3327, running_loss=0.3858, LR=0.000100
[2025-08-11 02:40:34,661][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 101988] [Batch 02304/03692] [00:20:25/00:12:18, 0.532s/it]: train_loss_raw=0.3075, running_loss=0.3848, LR=0.000100
[2025-08-11 02:40:40,714][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102000] [Batch 02316/03692] [00:20:31/00:12:11, 0.532s/it]: train_loss_raw=0.3459, running_loss=0.3846, LR=0.000100
[2025-08-11 02:40:51,328][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102012] [Batch 02328/03692] [00:20:42/00:12:07, 0.534s/it]: train_loss_raw=0.5254, running_loss=0.3828, LR=0.000100
[2025-08-11 02:40:57,356][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102024] [Batch 02340/03692] [00:20:48/00:12:01, 0.533s/it]: train_loss_raw=0.3490, running_loss=0.3811, LR=0.000100
[2025-08-11 02:41:03,621][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102036] [Batch 02352/03692] [00:20:54/00:11:54, 0.533s/it]: train_loss_raw=0.4067, running_loss=0.3856, LR=0.000100
[2025-08-11 02:41:10,080][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102048] [Batch 02364/03692] [00:21:01/00:11:48, 0.533s/it]: train_loss_raw=0.3119, running_loss=0.3859, LR=0.000100
[2025-08-11 02:41:16,583][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102060] [Batch 02376/03692] [00:21:07/00:11:42, 0.534s/it]: train_loss_raw=0.4176, running_loss=0.3888, LR=0.000100
[2025-08-11 02:41:23,074][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102072] [Batch 02388/03692] [00:21:14/00:11:35, 0.534s/it]: train_loss_raw=0.4096, running_loss=0.3889, LR=0.000100
[2025-08-11 02:41:29,256][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102084] [Batch 02400/03692] [00:21:20/00:11:29, 0.533s/it]: train_loss_raw=0.3653, running_loss=0.3880, LR=0.000100
[2025-08-11 02:41:35,605][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102096] [Batch 02412/03692] [00:21:26/00:11:22, 0.533s/it]: train_loss_raw=0.4009, running_loss=0.3890, LR=0.000100
[2025-08-11 02:41:42,063][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102108] [Batch 02424/03692] [00:21:33/00:11:16, 0.533s/it]: train_loss_raw=0.3833, running_loss=0.3888, LR=0.000100
[2025-08-11 02:41:48,578][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102120] [Batch 02436/03692] [00:21:39/00:11:10, 0.533s/it]: train_loss_raw=0.3679, running_loss=0.3879, LR=0.000100
[2025-08-11 02:41:55,026][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102132] [Batch 02448/03692] [00:21:46/00:11:03, 0.534s/it]: train_loss_raw=0.3808, running_loss=0.3860, LR=0.000100
[2025-08-11 02:42:01,466][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102144] [Batch 02460/03692] [00:21:52/00:10:57, 0.534s/it]: train_loss_raw=0.3273, running_loss=0.3889, LR=0.000100
[2025-08-11 02:42:07,972][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102156] [Batch 02472/03692] [00:21:58/00:10:50, 0.534s/it]: train_loss_raw=0.4678, running_loss=0.3896, LR=0.000100
[2025-08-11 02:42:14,440][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102168] [Batch 02484/03692] [00:22:05/00:10:44, 0.534s/it]: train_loss_raw=0.3626, running_loss=0.3887, LR=0.000100
[2025-08-11 02:42:20,628][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102180] [Batch 02496/03692] [00:22:11/00:10:38, 0.534s/it]: train_loss_raw=0.4232, running_loss=0.3893, LR=0.000100
[2025-08-11 02:42:26,668][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102192] [Batch 02508/03692] [00:22:17/00:10:31, 0.533s/it]: train_loss_raw=0.4278, running_loss=0.3900, LR=0.000100
[2025-08-11 02:42:33,023][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102204] [Batch 02520/03692] [00:22:24/00:10:25, 0.533s/it]: train_loss_raw=0.3906, running_loss=0.3873, LR=0.000100
[2025-08-11 02:42:39,417][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102216] [Batch 02532/03692] [00:22:30/00:10:18, 0.533s/it]: train_loss_raw=0.2993, running_loss=0.3855, LR=0.000100
[2025-08-11 02:42:45,606][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102228] [Batch 02544/03692] [00:22:36/00:10:12, 0.533s/it]: train_loss_raw=0.3779, running_loss=0.3851, LR=0.000100
[2025-08-11 02:42:51,682][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102240] [Batch 02556/03692] [00:22:42/00:10:05, 0.533s/it]: train_loss_raw=0.4288, running_loss=0.3872, LR=0.000100
[2025-08-11 02:42:58,010][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102252] [Batch 02568/03692] [00:22:49/00:09:59, 0.533s/it]: train_loss_raw=0.4057, running_loss=0.3871, LR=0.000100
[2025-08-11 02:43:04,426][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102264] [Batch 02580/03692] [00:22:55/00:09:52, 0.533s/it]: train_loss_raw=0.3371, running_loss=0.3842, LR=0.000100
[2025-08-11 02:43:10,729][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102276] [Batch 02592/03692] [00:23:01/00:09:46, 0.533s/it]: train_loss_raw=0.3518, running_loss=0.3844, LR=0.000100
[2025-08-11 02:43:16,982][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102288] [Batch 02604/03692] [00:23:08/00:09:39, 0.533s/it]: train_loss_raw=0.4345, running_loss=0.3847, LR=0.000100
[2025-08-11 02:43:23,158][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102300] [Batch 02616/03692] [00:23:14/00:09:33, 0.533s/it]: train_loss_raw=0.3711, running_loss=0.3855, LR=0.000100
[2025-08-11 02:43:29,330][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102312] [Batch 02628/03692] [00:23:20/00:09:26, 0.533s/it]: train_loss_raw=0.4243, running_loss=0.3840, LR=0.000100
[2025-08-11 02:43:35,487][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102324] [Batch 02640/03692] [00:23:26/00:09:20, 0.533s/it]: train_loss_raw=0.3439, running_loss=0.3825, LR=0.000100
[2025-08-11 02:43:41,674][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102336] [Batch 02652/03692] [00:23:32/00:09:13, 0.533s/it]: train_loss_raw=0.5063, running_loss=0.3810, LR=0.000100
[2025-08-11 02:43:47,817][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102348] [Batch 02664/03692] [00:23:38/00:09:07, 0.533s/it]: train_loss_raw=0.3821, running_loss=0.3819, LR=0.000100
[2025-08-11 02:43:54,313][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102360] [Batch 02676/03692] [00:23:45/00:09:01, 0.533s/it]: train_loss_raw=0.5072, running_loss=0.3818, LR=0.000100
[2025-08-11 02:44:00,810][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102372] [Batch 02688/03692] [00:23:51/00:08:54, 0.533s/it]: train_loss_raw=0.3753, running_loss=0.3823, LR=0.000100
[2025-08-11 02:44:07,165][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102384] [Batch 02700/03692] [00:23:58/00:08:48, 0.533s/it]: train_loss_raw=0.3551, running_loss=0.3805, LR=0.000100
[2025-08-11 02:44:13,600][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102396] [Batch 02712/03692] [00:24:04/00:08:42, 0.533s/it]: train_loss_raw=0.3710, running_loss=0.3814, LR=0.000100
[2025-08-11 02:44:20,135][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102408] [Batch 02724/03692] [00:24:11/00:08:35, 0.533s/it]: train_loss_raw=0.3748, running_loss=0.3861, LR=0.000100
[2025-08-11 02:44:26,509][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102420] [Batch 02736/03692] [00:24:17/00:08:29, 0.533s/it]: train_loss_raw=0.3470, running_loss=0.3828, LR=0.000100
[2025-08-11 02:44:32,912][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102432] [Batch 02748/03692] [00:24:23/00:08:22, 0.533s/it]: train_loss_raw=0.3221, running_loss=0.3850, LR=0.000100
[2025-08-11 02:44:39,353][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102444] [Batch 02760/03692] [00:24:30/00:08:16, 0.533s/it]: train_loss_raw=0.4214, running_loss=0.3881, LR=0.000100
[2025-08-11 02:44:45,834][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102456] [Batch 02772/03692] [00:24:36/00:08:10, 0.533s/it]: train_loss_raw=0.4590, running_loss=0.3895, LR=0.000100
[2025-08-11 02:44:52,279][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102468] [Batch 02784/03692] [00:24:43/00:08:03, 0.533s/it]: train_loss_raw=0.2462, running_loss=0.3904, LR=0.000100
[2025-08-11 02:44:58,831][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102480] [Batch 02796/03692] [00:24:49/00:07:57, 0.533s/it]: train_loss_raw=0.3541, running_loss=0.3916, LR=0.000100
[2025-08-11 02:45:05,256][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102492] [Batch 02808/03692] [00:24:56/00:07:51, 0.533s/it]: train_loss_raw=0.3852, running_loss=0.3931, LR=0.000100
[2025-08-11 02:45:11,715][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102504] [Batch 02820/03692] [00:25:02/00:07:44, 0.533s/it]: train_loss_raw=0.3930, running_loss=0.3947, LR=0.000100
[2025-08-11 02:45:18,135][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102516] [Batch 02832/03692] [00:25:09/00:07:38, 0.533s/it]: train_loss_raw=0.4337, running_loss=0.3962, LR=0.000100
[2025-08-11 02:45:24,472][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102528] [Batch 02844/03692] [00:25:15/00:07:31, 0.533s/it]: train_loss_raw=0.3404, running_loss=0.3923, LR=0.000100
[2025-08-11 02:45:30,818][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102540] [Batch 02856/03692] [00:25:21/00:07:25, 0.533s/it]: train_loss_raw=0.4856, running_loss=0.3921, LR=0.000100
[2025-08-11 02:45:37,210][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102552] [Batch 02868/03692] [00:25:28/00:07:19, 0.533s/it]: train_loss_raw=0.3954, running_loss=0.3923, LR=0.000100
[2025-08-11 02:45:43,610][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102564] [Batch 02880/03692] [00:25:34/00:07:12, 0.533s/it]: train_loss_raw=0.3655, running_loss=0.3913, LR=0.000100
[2025-08-11 02:45:50,006][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102576] [Batch 02892/03692] [00:25:41/00:07:06, 0.533s/it]: train_loss_raw=0.3634, running_loss=0.3897, LR=0.000100
[2025-08-11 02:45:56,509][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102588] [Batch 02904/03692] [00:25:47/00:06:59, 0.533s/it]: train_loss_raw=0.4046, running_loss=0.3868, LR=0.000100
[2025-08-11 02:46:02,814][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102600] [Batch 02916/03692] [00:25:53/00:06:53, 0.533s/it]: train_loss_raw=0.3942, running_loss=0.3853, LR=0.000100
[2025-08-11 02:46:08,915][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102612] [Batch 02928/03692] [00:25:59/00:06:47, 0.533s/it]: train_loss_raw=0.3544, running_loss=0.3843, LR=0.000100
[2025-08-11 02:46:15,277][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102624] [Batch 02940/03692] [00:26:06/00:06:40, 0.533s/it]: train_loss_raw=0.3719, running_loss=0.3806, LR=0.000100
[2025-08-11 02:46:21,686][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102636] [Batch 02952/03692] [00:26:12/00:06:34, 0.533s/it]: train_loss_raw=0.4022, running_loss=0.3821, LR=0.000100
[2025-08-11 02:46:28,089][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102648] [Batch 02964/03692] [00:26:19/00:06:27, 0.533s/it]: train_loss_raw=0.3714, running_loss=0.3792, LR=0.000100
[2025-08-11 02:46:34,465][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102660] [Batch 02976/03692] [00:26:25/00:06:21, 0.533s/it]: train_loss_raw=0.3497, running_loss=0.3781, LR=0.000100
[2025-08-11 02:46:40,803][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102672] [Batch 02988/03692] [00:26:31/00:06:15, 0.533s/it]: train_loss_raw=0.3652, running_loss=0.3781, LR=0.000100
[2025-08-11 02:46:47,149][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102684] [Batch 03000/03692] [00:26:38/00:06:08, 0.533s/it]: train_loss_raw=0.3565, running_loss=0.3780, LR=0.000100
[2025-08-11 02:46:53,598][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102696] [Batch 03012/03692] [00:26:44/00:06:02, 0.533s/it]: train_loss_raw=0.3531, running_loss=0.3776, LR=0.000100
[2025-08-11 02:46:59,984][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102708] [Batch 03024/03692] [00:26:51/00:05:55, 0.533s/it]: train_loss_raw=0.4045, running_loss=0.3793, LR=0.000100
[2025-08-11 02:47:06,366][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102720] [Batch 03036/03692] [00:26:57/00:05:49, 0.533s/it]: train_loss_raw=0.3472, running_loss=0.3802, LR=0.000100
[2025-08-11 02:47:12,718][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102732] [Batch 03048/03692] [00:27:03/00:05:43, 0.533s/it]: train_loss_raw=0.3552, running_loss=0.3811, LR=0.000100
[2025-08-11 02:47:19,127][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102744] [Batch 03060/03692] [00:27:10/00:05:36, 0.533s/it]: train_loss_raw=0.4066, running_loss=0.3807, LR=0.000100
[2025-08-11 02:47:25,466][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102756] [Batch 03072/03692] [00:27:16/00:05:30, 0.533s/it]: train_loss_raw=0.3497, running_loss=0.3795, LR=0.000100
[2025-08-11 02:47:31,551][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102768] [Batch 03084/03692] [00:27:22/00:05:23, 0.533s/it]: train_loss_raw=0.2996, running_loss=0.3771, LR=0.000100
[2025-08-11 02:47:37,586][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102780] [Batch 03096/03692] [00:27:28/00:05:17, 0.532s/it]: train_loss_raw=0.2606, running_loss=0.3750, LR=0.000100
[2025-08-11 02:47:43,736][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102792] [Batch 03108/03692] [00:27:34/00:05:10, 0.532s/it]: train_loss_raw=0.3129, running_loss=0.3766, LR=0.000100
[2025-08-11 02:47:50,197][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102804] [Batch 03120/03692] [00:27:41/00:05:04, 0.532s/it]: train_loss_raw=0.3879, running_loss=0.3780, LR=0.000100
[2025-08-11 02:47:56,573][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102816] [Batch 03132/03692] [00:27:47/00:04:58, 0.532s/it]: train_loss_raw=0.3967, running_loss=0.3783, LR=0.000100
[2025-08-11 02:48:02,872][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102828] [Batch 03144/03692] [00:27:53/00:04:51, 0.532s/it]: train_loss_raw=0.3241, running_loss=0.3791, LR=0.000100
[2025-08-11 02:48:09,077][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102840] [Batch 03156/03692] [00:28:00/00:04:45, 0.532s/it]: train_loss_raw=0.3158, running_loss=0.3815, LR=0.000100
[2025-08-11 02:48:15,410][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102852] [Batch 03168/03692] [00:28:06/00:04:38, 0.532s/it]: train_loss_raw=0.4454, running_loss=0.3833, LR=0.000100
[2025-08-11 02:48:21,892][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102864] [Batch 03180/03692] [00:28:12/00:04:32, 0.532s/it]: train_loss_raw=0.4037, running_loss=0.3813, LR=0.000100
[2025-08-11 02:48:28,349][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102876] [Batch 03192/03692] [00:28:19/00:04:26, 0.532s/it]: train_loss_raw=0.3020, running_loss=0.3825, LR=0.000100
[2025-08-11 02:48:34,753][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102888] [Batch 03204/03692] [00:28:25/00:04:19, 0.532s/it]: train_loss_raw=0.4150, running_loss=0.3827, LR=0.000100
[2025-08-11 02:48:41,165][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102900] [Batch 03216/03692] [00:28:32/00:04:13, 0.532s/it]: train_loss_raw=0.3916, running_loss=0.3821, LR=0.000100
[2025-08-11 02:48:47,727][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102912] [Batch 03228/03692] [00:28:38/00:04:07, 0.532s/it]: train_loss_raw=0.4481, running_loss=0.3850, LR=0.000100
[2025-08-11 02:48:54,132][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102924] [Batch 03240/03692] [00:28:45/00:04:00, 0.532s/it]: train_loss_raw=0.3736, running_loss=0.3873, LR=0.000100
[2025-08-11 02:49:00,502][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102936] [Batch 03252/03692] [00:28:51/00:03:54, 0.532s/it]: train_loss_raw=0.3596, running_loss=0.3871, LR=0.000100
[2025-08-11 02:49:06,851][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102948] [Batch 03264/03692] [00:28:57/00:03:47, 0.532s/it]: train_loss_raw=0.3641, running_loss=0.3871, LR=0.000100
[2025-08-11 02:49:13,192][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102960] [Batch 03276/03692] [00:29:04/00:03:41, 0.532s/it]: train_loss_raw=0.4111, running_loss=0.3850, LR=0.000100
[2025-08-11 02:49:19,569][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102972] [Batch 03288/03692] [00:29:10/00:03:35, 0.532s/it]: train_loss_raw=0.3579, running_loss=0.3858, LR=0.000100
[2025-08-11 02:49:26,047][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102984] [Batch 03300/03692] [00:29:17/00:03:28, 0.532s/it]: train_loss_raw=0.3534, running_loss=0.3840, LR=0.000100
[2025-08-11 02:49:32,587][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 102996] [Batch 03312/03692] [00:29:23/00:03:22, 0.532s/it]: train_loss_raw=0.3089, running_loss=0.3804, LR=0.000100
[2025-08-11 02:49:38,931][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103008] [Batch 03324/03692] [00:29:29/00:03:15, 0.532s/it]: train_loss_raw=0.3952, running_loss=0.3793, LR=0.000100
[2025-08-11 02:49:45,355][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103020] [Batch 03336/03692] [00:29:36/00:03:09, 0.532s/it]: train_loss_raw=0.3536, running_loss=0.3791, LR=0.000100
[2025-08-11 02:49:51,788][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103032] [Batch 03348/03692] [00:29:42/00:03:03, 0.532s/it]: train_loss_raw=0.3630, running_loss=0.3790, LR=0.000100
[2025-08-11 02:49:58,310][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103044] [Batch 03360/03692] [00:29:49/00:02:56, 0.533s/it]: train_loss_raw=0.3253, running_loss=0.3786, LR=0.000100
[2025-08-11 02:50:04,862][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103056] [Batch 03372/03692] [00:29:55/00:02:50, 0.533s/it]: train_loss_raw=0.3369, running_loss=0.3761, LR=0.000100
[2025-08-11 02:50:11,319][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103068] [Batch 03384/03692] [00:30:02/00:02:44, 0.533s/it]: train_loss_raw=0.3421, running_loss=0.3753, LR=0.000100
[2025-08-11 02:50:17,726][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103080] [Batch 03396/03692] [00:30:08/00:02:37, 0.533s/it]: train_loss_raw=0.5615, running_loss=0.3770, LR=0.000100
[2025-08-11 02:50:24,129][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103092] [Batch 03408/03692] [00:30:15/00:02:31, 0.533s/it]: train_loss_raw=0.3105, running_loss=0.3770, LR=0.000100
[2025-08-11 02:50:30,521][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103104] [Batch 03420/03692] [00:30:21/00:02:24, 0.533s/it]: train_loss_raw=0.4062, running_loss=0.3779, LR=0.000100
[2025-08-11 02:50:36,886][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103116] [Batch 03432/03692] [00:30:27/00:02:18, 0.533s/it]: train_loss_raw=0.3627, running_loss=0.3783, LR=0.000100
[2025-08-11 02:50:43,314][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103128] [Batch 03444/03692] [00:30:34/00:02:12, 0.533s/it]: train_loss_raw=0.3017, running_loss=0.3787, LR=0.000100
[2025-08-11 02:50:49,778][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103140] [Batch 03456/03692] [00:30:40/00:02:05, 0.533s/it]: train_loss_raw=0.3626, running_loss=0.3794, LR=0.000100
[2025-08-11 02:50:56,275][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103152] [Batch 03468/03692] [00:30:47/00:01:59, 0.533s/it]: train_loss_raw=0.3769, running_loss=0.3790, LR=0.000100
[2025-08-11 02:51:02,782][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103164] [Batch 03480/03692] [00:30:53/00:01:52, 0.533s/it]: train_loss_raw=0.4320, running_loss=0.3809, LR=0.000100
[2025-08-11 02:51:09,253][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103176] [Batch 03492/03692] [00:31:00/00:01:46, 0.533s/it]: train_loss_raw=0.4240, running_loss=0.3822, LR=0.000100
[2025-08-11 02:51:15,650][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103188] [Batch 03504/03692] [00:31:06/00:01:40, 0.533s/it]: train_loss_raw=0.4135, running_loss=0.3824, LR=0.000100
[2025-08-11 02:51:22,163][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103200] [Batch 03516/03692] [00:31:13/00:01:33, 0.533s/it]: train_loss_raw=0.3968, running_loss=0.3841, LR=0.000100
[2025-08-11 02:51:28,661][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103212] [Batch 03528/03692] [00:31:19/00:01:27, 0.533s/it]: train_loss_raw=0.3758, running_loss=0.3850, LR=0.000100
[2025-08-11 02:51:35,124][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103224] [Batch 03540/03692] [00:31:26/00:01:20, 0.533s/it]: train_loss_raw=0.3591, running_loss=0.3840, LR=0.000100
[2025-08-11 02:51:41,215][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103236] [Batch 03552/03692] [00:31:32/00:01:14, 0.533s/it]: train_loss_raw=0.3969, running_loss=0.3891, LR=0.000100
[2025-08-11 02:51:47,720][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103248] [Batch 03564/03692] [00:31:38/00:01:08, 0.533s/it]: train_loss_raw=0.3324, running_loss=0.3882, LR=0.000100
[2025-08-11 02:51:54,243][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103260] [Batch 03576/03692] [00:31:45/00:01:01, 0.533s/it]: train_loss_raw=0.4632, running_loss=0.3878, LR=0.000100
[2025-08-11 02:52:00,525][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103272] [Batch 03588/03692] [00:31:51/00:00:55, 0.533s/it]: train_loss_raw=0.3606, running_loss=0.3894, LR=0.000100
[2025-08-11 02:52:06,750][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103284] [Batch 03600/03692] [00:31:57/00:00:49, 0.533s/it]: train_loss_raw=0.4018, running_loss=0.3894, LR=0.000100
[2025-08-11 02:52:13,235][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103296] [Batch 03612/03692] [00:32:04/00:00:42, 0.533s/it]: train_loss_raw=0.4809, running_loss=0.3870, LR=0.000100
[2025-08-11 02:52:19,644][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103308] [Batch 03624/03692] [00:32:10/00:00:36, 0.533s/it]: train_loss_raw=0.3646, running_loss=0.3834, LR=0.000100
[2025-08-11 02:52:26,036][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103320] [Batch 03636/03692] [00:32:17/00:00:29, 0.533s/it]: train_loss_raw=0.3876, running_loss=0.3834, LR=0.000100
[2025-08-11 02:52:32,440][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103332] [Batch 03648/03692] [00:32:23/00:00:23, 0.533s/it]: train_loss_raw=0.2974, running_loss=0.3836, LR=0.000100
[2025-08-11 02:52:39,017][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103344] [Batch 03660/03692] [00:32:30/00:00:17, 0.533s/it]: train_loss_raw=0.4632, running_loss=0.3863, LR=0.000100
[2025-08-11 02:52:45,369][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103356] [Batch 03672/03692] [00:32:36/00:00:10, 0.533s/it]: train_loss_raw=0.4822, running_loss=0.3844, LR=0.000100
[2025-08-11 02:52:51,756][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 103368] [Batch 03684/03692] [00:32:42/00:00:04, 0.533s/it]: train_loss_raw=0.3815, running_loss=0.3856, LR=0.000100
[2025-08-11 02:53:08,545][__main__][INFO] - [VALIDATION] [Epoch 27/29] Starting validation.
[2025-08-11 02:53:41,493][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 103377] [Batch 00011/00025] [00:00:32/00:00:35, 2.746s/it]
[2025-08-11 02:53:57,452][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 103377] [Batch 00023/00025] [00:00:48/00:00:02, 2.038s/it]
[2025-08-11 02:53:58,580][__main__][INFO] - [VALIDATION] [Epoch 27/29] train_loss=0.38369, valid_loss=0.56264
[2025-08-11 02:53:58,581][__main__][INFO] - [VALIDATION] [Epoch 27/29] Metrics:
[2025-08-11 02:53:58,581][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_er      0.229
[2025-08-11 02:53:58,581][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_prec    0.570
[2025-08-11 02:53:58,581][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_recall  0.576
[2025-08-11 02:53:58,581][__main__][INFO] - [VALIDATION] [Epoch 27/29] - pep_recall 0.556
[2025-08-11 02:53:58,585][__main__][INFO] - [TRAIN] [Epoch 27/29] Epoch complete, total time 15:57:57, remaining time 01:08:25, 00:34:12 per epoch
[2025-08-11 02:54:00,650][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103380] [Batch 00004/03692] [00:00:01/00:26:27, 0.431s/it]: train_loss_raw=0.4090, running_loss=0.3325, LR=0.000100
[2025-08-11 02:54:07,137][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103392] [Batch 00016/03692] [00:00:08/00:31:26, 0.513s/it]: train_loss_raw=0.3075, running_loss=0.3352, LR=0.000100
[2025-08-11 02:54:13,560][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103404] [Batch 00028/03692] [00:00:14/00:31:54, 0.523s/it]: train_loss_raw=0.3661, running_loss=0.3396, LR=0.000100
[2025-08-11 02:54:19,991][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103416] [Batch 00040/03692] [00:00:21/00:32:03, 0.527s/it]: train_loss_raw=0.4583, running_loss=0.3445, LR=0.000100
[2025-08-11 02:54:26,241][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103428] [Batch 00052/03692] [00:00:27/00:31:51, 0.525s/it]: train_loss_raw=0.3849, running_loss=0.3461, LR=0.000100
[2025-08-11 02:54:32,507][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103440] [Batch 00064/03692] [00:00:33/00:31:43, 0.525s/it]: train_loss_raw=0.3463, running_loss=0.3490, LR=0.000100
[2025-08-11 02:54:38,881][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103452] [Batch 00076/03692] [00:00:39/00:31:40, 0.526s/it]: train_loss_raw=0.2648, running_loss=0.3470, LR=0.000100
[2025-08-11 02:54:45,389][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103464] [Batch 00088/03692] [00:00:46/00:31:42, 0.528s/it]: train_loss_raw=0.2908, running_loss=0.3499, LR=0.000100
[2025-08-11 02:54:51,971][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103476] [Batch 00100/03692] [00:00:53/00:31:45, 0.530s/it]: train_loss_raw=0.3152, running_loss=0.3518, LR=0.000100
[2025-08-11 02:54:58,447][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103488] [Batch 00112/03692] [00:00:59/00:31:42, 0.531s/it]: train_loss_raw=0.4138, running_loss=0.3568, LR=0.000100
[2025-08-11 02:55:04,907][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103500] [Batch 00124/03692] [00:01:05/00:31:38, 0.532s/it]: train_loss_raw=0.3756, running_loss=0.3588, LR=0.000100
[2025-08-11 02:55:11,372][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103512] [Batch 00136/03692] [00:01:12/00:31:34, 0.533s/it]: train_loss_raw=0.4306, running_loss=0.3595, LR=0.000100
[2025-08-11 02:55:17,838][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103524] [Batch 00148/03692] [00:01:18/00:31:29, 0.533s/it]: train_loss_raw=0.4182, running_loss=0.3595, LR=0.000100
[2025-08-11 02:55:24,218][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103536] [Batch 00160/03692] [00:01:25/00:31:22, 0.533s/it]: train_loss_raw=0.3703, running_loss=0.3600, LR=0.000100
[2025-08-11 02:55:30,560][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103548] [Batch 00172/03692] [00:01:31/00:31:15, 0.533s/it]: train_loss_raw=0.3261, running_loss=0.3573, LR=0.000100
[2025-08-11 02:55:37,036][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103560] [Batch 00184/03692] [00:01:38/00:31:10, 0.533s/it]: train_loss_raw=0.4168, running_loss=0.3608, LR=0.000100
[2025-08-11 02:55:43,396][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103572] [Batch 00196/03692] [00:01:44/00:31:03, 0.533s/it]: train_loss_raw=0.4021, running_loss=0.3618, LR=0.000100
[2025-08-11 02:55:49,763][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103584] [Batch 00208/03692] [00:01:50/00:30:56, 0.533s/it]: train_loss_raw=0.2909, running_loss=0.3606, LR=0.000100
[2025-08-11 02:55:56,217][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103596] [Batch 00220/03692] [00:01:57/00:30:51, 0.533s/it]: train_loss_raw=0.3414, running_loss=0.3596, LR=0.000100
[2025-08-11 02:56:02,801][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103608] [Batch 00232/03692] [00:02:03/00:30:47, 0.534s/it]: train_loss_raw=0.3885, running_loss=0.3611, LR=0.000100
[2025-08-11 02:56:09,271][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103620] [Batch 00244/03692] [00:02:10/00:30:41, 0.534s/it]: train_loss_raw=0.3837, running_loss=0.3631, LR=0.000100
[2025-08-11 02:56:15,667][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103632] [Batch 00256/03692] [00:02:16/00:30:35, 0.534s/it]: train_loss_raw=0.3947, running_loss=0.3642, LR=0.000100
[2025-08-11 02:56:22,004][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103644] [Batch 00268/03692] [00:02:23/00:30:27, 0.534s/it]: train_loss_raw=0.4268, running_loss=0.3667, LR=0.000100
[2025-08-11 02:56:28,504][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103656] [Batch 00280/03692] [00:02:29/00:30:22, 0.534s/it]: train_loss_raw=0.2780, running_loss=0.3656, LR=0.000100
[2025-08-11 02:56:34,929][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103668] [Batch 00292/03692] [00:02:36/00:30:16, 0.534s/it]: train_loss_raw=0.3432, running_loss=0.3625, LR=0.000100
[2025-08-11 02:56:41,329][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103680] [Batch 00304/03692] [00:02:42/00:30:09, 0.534s/it]: train_loss_raw=0.3343, running_loss=0.3633, LR=0.000100
[2025-08-11 02:56:47,755][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103692] [Batch 00316/03692] [00:02:48/00:30:03, 0.534s/it]: train_loss_raw=0.3399, running_loss=0.3613, LR=0.000100
[2025-08-11 02:56:54,266][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103704] [Batch 00328/03692] [00:02:55/00:29:58, 0.535s/it]: train_loss_raw=0.4078, running_loss=0.3628, LR=0.000100
[2025-08-11 02:57:00,703][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103716] [Batch 00340/03692] [00:03:01/00:29:52, 0.535s/it]: train_loss_raw=0.4427, running_loss=0.3674, LR=0.000100
[2025-08-11 02:57:07,055][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103728] [Batch 00352/03692] [00:03:08/00:29:45, 0.534s/it]: train_loss_raw=0.3039, running_loss=0.3659, LR=0.000100
[2025-08-11 02:57:13,443][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103740] [Batch 00364/03692] [00:03:14/00:29:38, 0.534s/it]: train_loss_raw=0.3203, running_loss=0.3653, LR=0.000100
[2025-08-11 02:57:19,841][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103752] [Batch 00376/03692] [00:03:20/00:29:31, 0.534s/it]: train_loss_raw=0.3847, running_loss=0.3669, LR=0.000100
[2025-08-11 02:57:26,236][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103764] [Batch 00388/03692] [00:03:27/00:29:25, 0.534s/it]: train_loss_raw=0.3331, running_loss=0.3660, LR=0.000100
[2025-08-11 02:57:32,639][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103776] [Batch 00400/03692] [00:03:33/00:29:18, 0.534s/it]: train_loss_raw=0.3057, running_loss=0.3629, LR=0.000100
[2025-08-11 02:57:39,024][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103788] [Batch 00412/03692] [00:03:40/00:29:12, 0.534s/it]: train_loss_raw=0.4218, running_loss=0.3657, LR=0.000100
[2025-08-11 02:57:45,346][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103800] [Batch 00424/03692] [00:03:46/00:29:05, 0.534s/it]: train_loss_raw=0.2928, running_loss=0.3613, LR=0.000100
[2025-08-11 02:57:51,683][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103812] [Batch 00436/03692] [00:03:52/00:28:58, 0.534s/it]: train_loss_raw=0.3104, running_loss=0.3614, LR=0.000100
[2025-08-11 02:57:58,035][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103824] [Batch 00448/03692] [00:03:59/00:28:51, 0.534s/it]: train_loss_raw=0.3638, running_loss=0.3595, LR=0.000100
[2025-08-11 02:58:04,399][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103836] [Batch 00460/03692] [00:04:05/00:28:44, 0.534s/it]: train_loss_raw=0.4848, running_loss=0.3617, LR=0.000100
[2025-08-11 02:58:10,742][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103848] [Batch 00472/03692] [00:04:11/00:28:37, 0.534s/it]: train_loss_raw=0.3166, running_loss=0.3627, LR=0.000100
[2025-08-11 02:58:17,220][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103860] [Batch 00484/03692] [00:04:18/00:28:31, 0.534s/it]: train_loss_raw=0.2863, running_loss=0.3611, LR=0.000100
[2025-08-11 02:58:23,614][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103872] [Batch 00496/03692] [00:04:24/00:28:25, 0.534s/it]: train_loss_raw=0.4456, running_loss=0.3595, LR=0.000100
[2025-08-11 02:58:29,954][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103884] [Batch 00508/03692] [00:04:31/00:28:18, 0.534s/it]: train_loss_raw=0.4113, running_loss=0.3604, LR=0.000100
[2025-08-11 02:58:36,289][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103896] [Batch 00520/03692] [00:04:37/00:28:11, 0.533s/it]: train_loss_raw=0.3039, running_loss=0.3616, LR=0.000100
[2025-08-11 02:58:42,705][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103908] [Batch 00532/03692] [00:04:43/00:28:05, 0.533s/it]: train_loss_raw=0.4021, running_loss=0.3603, LR=0.000100
[2025-08-11 02:58:49,121][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103920] [Batch 00544/03692] [00:04:50/00:27:59, 0.533s/it]: train_loss_raw=0.3424, running_loss=0.3593, LR=0.000100
[2025-08-11 02:58:55,579][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103932] [Batch 00556/03692] [00:04:56/00:27:53, 0.534s/it]: train_loss_raw=0.4297, running_loss=0.3624, LR=0.000100
[2025-08-11 02:59:02,015][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103944] [Batch 00568/03692] [00:05:03/00:27:46, 0.534s/it]: train_loss_raw=0.3960, running_loss=0.3613, LR=0.000100
[2025-08-11 02:59:08,264][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103956] [Batch 00580/03692] [00:05:09/00:27:39, 0.533s/it]: train_loss_raw=0.3252, running_loss=0.3628, LR=0.000100
[2025-08-11 02:59:14,701][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103968] [Batch 00592/03692] [00:05:15/00:27:33, 0.533s/it]: train_loss_raw=0.3823, running_loss=0.3625, LR=0.000100
[2025-08-11 02:59:21,098][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103980] [Batch 00604/03692] [00:05:22/00:27:27, 0.533s/it]: train_loss_raw=0.2940, running_loss=0.3623, LR=0.000100
[2025-08-11 02:59:27,503][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 103992] [Batch 00616/03692] [00:05:28/00:27:20, 0.533s/it]: train_loss_raw=0.4414, running_loss=0.3641, LR=0.000100
[2025-08-11 02:59:39,622][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104004] [Batch 00628/03692] [00:05:40/00:27:42, 0.543s/it]: train_loss_raw=0.3560, running_loss=0.3636, LR=0.000100
[2025-08-11 02:59:45,965][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104016] [Batch 00640/03692] [00:05:47/00:27:34, 0.542s/it]: train_loss_raw=0.3909, running_loss=0.3635, LR=0.000100
[2025-08-11 02:59:52,349][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104028] [Batch 00652/03692] [00:05:53/00:27:27, 0.542s/it]: train_loss_raw=0.3017, running_loss=0.3637, LR=0.000100
[2025-08-11 02:59:58,679][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104040] [Batch 00664/03692] [00:05:59/00:27:20, 0.542s/it]: train_loss_raw=0.3124, running_loss=0.3647, LR=0.000100
[2025-08-11 03:00:05,153][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104052] [Batch 00676/03692] [00:06:06/00:27:13, 0.542s/it]: train_loss_raw=0.3787, running_loss=0.3620, LR=0.000100
[2025-08-11 03:00:11,483][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104064] [Batch 00688/03692] [00:06:12/00:27:06, 0.542s/it]: train_loss_raw=0.3757, running_loss=0.3615, LR=0.000100
[2025-08-11 03:00:17,963][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104076] [Batch 00700/03692] [00:06:19/00:27:00, 0.541s/it]: train_loss_raw=0.4214, running_loss=0.3639, LR=0.000100
[2025-08-11 03:00:24,321][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104088] [Batch 00712/03692] [00:06:25/00:26:53, 0.541s/it]: train_loss_raw=0.3113, running_loss=0.3661, LR=0.000100
[2025-08-11 03:00:30,688][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104100] [Batch 00724/03692] [00:06:31/00:26:46, 0.541s/it]: train_loss_raw=0.3948, running_loss=0.3667, LR=0.000100
[2025-08-11 03:00:37,143][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104112] [Batch 00736/03692] [00:06:38/00:26:39, 0.541s/it]: train_loss_raw=0.3108, running_loss=0.3664, LR=0.000100
[2025-08-11 03:00:43,531][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104124] [Batch 00748/03692] [00:06:44/00:26:32, 0.541s/it]: train_loss_raw=0.3533, running_loss=0.3665, LR=0.000100
[2025-08-11 03:00:50,019][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104136] [Batch 00760/03692] [00:06:51/00:26:25, 0.541s/it]: train_loss_raw=0.3642, running_loss=0.3682, LR=0.000100
[2025-08-11 03:00:56,549][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104148] [Batch 00772/03692] [00:06:57/00:26:19, 0.541s/it]: train_loss_raw=0.3425, running_loss=0.3689, LR=0.000100
[2025-08-11 03:01:03,075][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104160] [Batch 00784/03692] [00:07:04/00:26:13, 0.541s/it]: train_loss_raw=0.4546, running_loss=0.3693, LR=0.000100
[2025-08-11 03:01:09,497][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104172] [Batch 00796/03692] [00:07:10/00:26:06, 0.541s/it]: train_loss_raw=0.3554, running_loss=0.3684, LR=0.000100
[2025-08-11 03:01:15,946][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104184] [Batch 00808/03692] [00:07:17/00:25:59, 0.541s/it]: train_loss_raw=0.3491, running_loss=0.3670, LR=0.000100
[2025-08-11 03:01:22,414][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104196] [Batch 00820/03692] [00:07:23/00:25:53, 0.541s/it]: train_loss_raw=0.3417, running_loss=0.3673, LR=0.000100
[2025-08-11 03:01:28,853][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104208] [Batch 00832/03692] [00:07:29/00:25:46, 0.541s/it]: train_loss_raw=0.3542, running_loss=0.3675, LR=0.000100
[2025-08-11 03:01:35,350][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104220] [Batch 00844/03692] [00:07:36/00:25:40, 0.541s/it]: train_loss_raw=0.3820, running_loss=0.3654, LR=0.000100
[2025-08-11 03:01:41,821][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104232] [Batch 00856/03692] [00:07:42/00:25:33, 0.541s/it]: train_loss_raw=0.3771, running_loss=0.3661, LR=0.000100
[2025-08-11 03:01:48,303][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104244] [Batch 00868/03692] [00:07:49/00:25:27, 0.541s/it]: train_loss_raw=0.3295, running_loss=0.3663, LR=0.000100
[2025-08-11 03:01:54,734][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104256] [Batch 00880/03692] [00:07:55/00:25:20, 0.541s/it]: train_loss_raw=0.4738, running_loss=0.3678, LR=0.000100
[2025-08-11 03:02:01,107][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104268] [Batch 00892/03692] [00:08:02/00:25:13, 0.541s/it]: train_loss_raw=0.3779, running_loss=0.3674, LR=0.000100
[2025-08-11 03:02:07,472][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104280] [Batch 00904/03692] [00:08:08/00:25:06, 0.540s/it]: train_loss_raw=0.3498, running_loss=0.3682, LR=0.000100
[2025-08-11 03:02:13,948][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104292] [Batch 00916/03692] [00:08:15/00:25:00, 0.540s/it]: train_loss_raw=0.3643, running_loss=0.3704, LR=0.000100
[2025-08-11 03:02:20,488][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104304] [Batch 00928/03692] [00:08:21/00:24:53, 0.540s/it]: train_loss_raw=0.2850, running_loss=0.3705, LR=0.000100
[2025-08-11 03:02:26,927][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104316] [Batch 00940/03692] [00:08:27/00:24:47, 0.540s/it]: train_loss_raw=0.3823, running_loss=0.3691, LR=0.000100
[2025-08-11 03:02:33,306][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104328] [Batch 00952/03692] [00:08:34/00:24:40, 0.540s/it]: train_loss_raw=0.3982, running_loss=0.3673, LR=0.000100
[2025-08-11 03:02:39,627][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104340] [Batch 00964/03692] [00:08:40/00:24:33, 0.540s/it]: train_loss_raw=0.3093, running_loss=0.3686, LR=0.000100
[2025-08-11 03:02:46,086][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104352] [Batch 00976/03692] [00:08:47/00:24:26, 0.540s/it]: train_loss_raw=0.3091, running_loss=0.3685, LR=0.000100
[2025-08-11 03:02:52,480][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104364] [Batch 00988/03692] [00:08:53/00:24:20, 0.540s/it]: train_loss_raw=0.3674, running_loss=0.3649, LR=0.000100
[2025-08-11 03:02:58,915][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104376] [Batch 01000/03692] [00:08:59/00:24:13, 0.540s/it]: train_loss_raw=0.3761, running_loss=0.3633, LR=0.000100
[2025-08-11 03:03:05,297][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104388] [Batch 01012/03692] [00:09:06/00:24:06, 0.540s/it]: train_loss_raw=0.3545, running_loss=0.3677, LR=0.000100
[2025-08-11 03:03:11,687][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104400] [Batch 01024/03692] [00:09:12/00:24:00, 0.540s/it]: train_loss_raw=0.3640, running_loss=0.3662, LR=0.000100
[2025-08-11 03:03:18,060][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104412] [Batch 01036/03692] [00:09:19/00:23:53, 0.540s/it]: train_loss_raw=0.4057, running_loss=0.3690, LR=0.000100
[2025-08-11 03:03:24,516][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104424] [Batch 01048/03692] [00:09:25/00:23:46, 0.540s/it]: train_loss_raw=0.3616, running_loss=0.3675, LR=0.000100
[2025-08-11 03:03:30,885][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104436] [Batch 01060/03692] [00:09:31/00:23:40, 0.540s/it]: train_loss_raw=0.3855, running_loss=0.3647, LR=0.000100
[2025-08-11 03:03:37,316][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104448] [Batch 01072/03692] [00:09:38/00:23:33, 0.540s/it]: train_loss_raw=0.3679, running_loss=0.3634, LR=0.000100
[2025-08-11 03:03:43,629][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104460] [Batch 01084/03692] [00:09:44/00:23:26, 0.539s/it]: train_loss_raw=0.3647, running_loss=0.3631, LR=0.000100
[2025-08-11 03:03:49,958][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104472] [Batch 01096/03692] [00:09:51/00:23:19, 0.539s/it]: train_loss_raw=0.3650, running_loss=0.3648, LR=0.000100
[2025-08-11 03:03:56,406][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104484] [Batch 01108/03692] [00:09:57/00:23:13, 0.539s/it]: train_loss_raw=0.4350, running_loss=0.3666, LR=0.000100
[2025-08-11 03:04:02,927][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104496] [Batch 01120/03692] [00:10:03/00:23:07, 0.539s/it]: train_loss_raw=0.3188, running_loss=0.3660, LR=0.000100
[2025-08-11 03:04:09,268][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104508] [Batch 01132/03692] [00:10:10/00:23:00, 0.539s/it]: train_loss_raw=0.3415, running_loss=0.3627, LR=0.000100
[2025-08-11 03:04:15,685][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104520] [Batch 01144/03692] [00:10:16/00:22:53, 0.539s/it]: train_loss_raw=0.4902, running_loss=0.3689, LR=0.000100
[2025-08-11 03:04:22,265][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104532] [Batch 01156/03692] [00:10:23/00:22:47, 0.539s/it]: train_loss_raw=0.3199, running_loss=0.3678, LR=0.000100
[2025-08-11 03:04:28,724][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104544] [Batch 01168/03692] [00:10:29/00:22:40, 0.539s/it]: train_loss_raw=0.3095, running_loss=0.3673, LR=0.000100
[2025-08-11 03:04:35,100][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104556] [Batch 01180/03692] [00:10:36/00:22:34, 0.539s/it]: train_loss_raw=0.3263, running_loss=0.3674, LR=0.000100
[2025-08-11 03:04:41,499][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104568] [Batch 01192/03692] [00:10:42/00:22:27, 0.539s/it]: train_loss_raw=0.3348, running_loss=0.3664, LR=0.000100
[2025-08-11 03:04:47,968][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104580] [Batch 01204/03692] [00:10:49/00:22:21, 0.539s/it]: train_loss_raw=0.2818, running_loss=0.3662, LR=0.000100
[2025-08-11 03:04:54,469][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104592] [Batch 01216/03692] [00:10:55/00:22:14, 0.539s/it]: train_loss_raw=0.3181, running_loss=0.3664, LR=0.000100
[2025-08-11 03:05:00,945][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104604] [Batch 01228/03692] [00:11:02/00:22:08, 0.539s/it]: train_loss_raw=0.3067, running_loss=0.3655, LR=0.000100
[2025-08-11 03:05:07,460][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104616] [Batch 01240/03692] [00:11:08/00:22:01, 0.539s/it]: train_loss_raw=0.3890, running_loss=0.3640, LR=0.000100
[2025-08-11 03:05:14,019][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104628] [Batch 01252/03692] [00:11:15/00:21:55, 0.539s/it]: train_loss_raw=0.3175, running_loss=0.3654, LR=0.000100
[2025-08-11 03:05:20,518][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104640] [Batch 01264/03692] [00:11:21/00:21:49, 0.539s/it]: train_loss_raw=0.4354, running_loss=0.3628, LR=0.000100
[2025-08-11 03:05:26,932][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104652] [Batch 01276/03692] [00:11:28/00:21:42, 0.539s/it]: train_loss_raw=0.3942, running_loss=0.3667, LR=0.000100
[2025-08-11 03:05:33,461][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104664] [Batch 01288/03692] [00:11:34/00:21:36, 0.539s/it]: train_loss_raw=0.2981, running_loss=0.3645, LR=0.000100
[2025-08-11 03:05:39,884][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104676] [Batch 01300/03692] [00:11:40/00:21:29, 0.539s/it]: train_loss_raw=0.3443, running_loss=0.3646, LR=0.000100
[2025-08-11 03:05:46,257][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104688] [Batch 01312/03692] [00:11:47/00:21:23, 0.539s/it]: train_loss_raw=0.3176, running_loss=0.3631, LR=0.000100
[2025-08-11 03:05:52,749][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104700] [Batch 01324/03692] [00:11:53/00:21:16, 0.539s/it]: train_loss_raw=0.2867, running_loss=0.3632, LR=0.000100
[2025-08-11 03:05:59,050][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104712] [Batch 01336/03692] [00:12:00/00:21:09, 0.539s/it]: train_loss_raw=0.3852, running_loss=0.3660, LR=0.000100
[2025-08-11 03:06:05,424][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104724] [Batch 01348/03692] [00:12:06/00:21:03, 0.539s/it]: train_loss_raw=0.4173, running_loss=0.3683, LR=0.000100
[2025-08-11 03:06:11,819][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104736] [Batch 01360/03692] [00:12:12/00:20:56, 0.539s/it]: train_loss_raw=0.4365, running_loss=0.3673, LR=0.000100
[2025-08-11 03:06:18,200][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104748] [Batch 01372/03692] [00:12:19/00:20:50, 0.539s/it]: train_loss_raw=0.3403, running_loss=0.3682, LR=0.000100
[2025-08-11 03:06:24,547][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104760] [Batch 01384/03692] [00:12:25/00:20:43, 0.539s/it]: train_loss_raw=0.4818, running_loss=0.3632, LR=0.000100
[2025-08-11 03:06:30,956][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104772] [Batch 01396/03692] [00:12:32/00:20:36, 0.539s/it]: train_loss_raw=0.3370, running_loss=0.3622, LR=0.000100
[2025-08-11 03:06:37,443][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104784] [Batch 01408/03692] [00:12:38/00:20:30, 0.539s/it]: train_loss_raw=0.2192, running_loss=0.3618, LR=0.000100
[2025-08-11 03:06:43,899][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104796] [Batch 01420/03692] [00:12:44/00:20:23, 0.539s/it]: train_loss_raw=0.3574, running_loss=0.3638, LR=0.000100
[2025-08-11 03:06:50,364][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104808] [Batch 01432/03692] [00:12:51/00:20:17, 0.539s/it]: train_loss_raw=0.3899, running_loss=0.3645, LR=0.000100
[2025-08-11 03:06:56,749][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104820] [Batch 01444/03692] [00:12:57/00:20:10, 0.539s/it]: train_loss_raw=0.3377, running_loss=0.3639, LR=0.000100
[2025-08-11 03:07:03,152][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104832] [Batch 01456/03692] [00:13:04/00:20:04, 0.539s/it]: train_loss_raw=0.3422, running_loss=0.3626, LR=0.000100
[2025-08-11 03:07:09,424][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104844] [Batch 01468/03692] [00:13:10/00:19:57, 0.538s/it]: train_loss_raw=0.4589, running_loss=0.3635, LR=0.000100
[2025-08-11 03:07:15,812][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104856] [Batch 01480/03692] [00:13:16/00:19:51, 0.538s/it]: train_loss_raw=0.4067, running_loss=0.3673, LR=0.000100
[2025-08-11 03:07:22,165][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104868] [Batch 01492/03692] [00:13:23/00:19:44, 0.538s/it]: train_loss_raw=0.3424, running_loss=0.3693, LR=0.000100
[2025-08-11 03:07:28,602][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104880] [Batch 01504/03692] [00:13:29/00:19:37, 0.538s/it]: train_loss_raw=0.3266, running_loss=0.3682, LR=0.000100
[2025-08-11 03:07:34,928][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104892] [Batch 01516/03692] [00:13:36/00:19:31, 0.538s/it]: train_loss_raw=0.3535, running_loss=0.3653, LR=0.000100
[2025-08-11 03:07:41,331][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104904] [Batch 01528/03692] [00:13:42/00:19:24, 0.538s/it]: train_loss_raw=0.3973, running_loss=0.3666, LR=0.000100
[2025-08-11 03:08:32,669][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104916] [Batch 01540/03692] [00:14:33/00:20:20, 0.567s/it]: train_loss_raw=0.3587, running_loss=0.3685, LR=0.000100
[2025-08-11 03:08:38,962][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104928] [Batch 01552/03692] [00:14:40/00:20:13, 0.567s/it]: train_loss_raw=0.2957, running_loss=0.3688, LR=0.000100
[2025-08-11 03:08:45,358][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104940] [Batch 01564/03692] [00:14:46/00:20:06, 0.567s/it]: train_loss_raw=0.3001, running_loss=0.3659, LR=0.000100
[2025-08-11 03:08:51,682][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104952] [Batch 01576/03692] [00:14:52/00:19:58, 0.566s/it]: train_loss_raw=0.4202, running_loss=0.3654, LR=0.000100
[2025-08-11 03:08:58,026][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104964] [Batch 01588/03692] [00:14:59/00:19:51, 0.566s/it]: train_loss_raw=0.4347, running_loss=0.3672, LR=0.000100
[2025-08-11 03:09:04,332][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104976] [Batch 01600/03692] [00:15:05/00:19:43, 0.566s/it]: train_loss_raw=0.4518, running_loss=0.3693, LR=0.000100
[2025-08-11 03:09:10,745][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 104988] [Batch 01612/03692] [00:15:11/00:19:36, 0.566s/it]: train_loss_raw=0.3044, running_loss=0.3645, LR=0.000100
[2025-08-11 03:09:17,317][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105000] [Batch 01624/03692] [00:15:18/00:19:29, 0.566s/it]: train_loss_raw=0.4951, running_loss=0.3675, LR=0.000100
[2025-08-11 03:09:23,858][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105012] [Batch 01636/03692] [00:15:24/00:19:22, 0.565s/it]: train_loss_raw=0.5204, running_loss=0.3658, LR=0.000100
[2025-08-11 03:09:30,293][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105024] [Batch 01648/03692] [00:15:31/00:19:15, 0.565s/it]: train_loss_raw=0.4492, running_loss=0.3671, LR=0.000100
[2025-08-11 03:09:36,632][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105036] [Batch 01660/03692] [00:15:37/00:19:07, 0.565s/it]: train_loss_raw=0.3533, running_loss=0.3646, LR=0.000100
[2025-08-11 03:09:42,936][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105048] [Batch 01672/03692] [00:15:44/00:19:00, 0.565s/it]: train_loss_raw=0.3712, running_loss=0.3649, LR=0.000100
[2025-08-11 03:09:49,382][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105060] [Batch 01684/03692] [00:15:50/00:18:53, 0.564s/it]: train_loss_raw=0.4028, running_loss=0.3611, LR=0.000100
[2025-08-11 03:09:55,858][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105072] [Batch 01696/03692] [00:15:56/00:18:46, 0.564s/it]: train_loss_raw=0.3473, running_loss=0.3606, LR=0.000100
[2025-08-11 03:10:02,209][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105084] [Batch 01708/03692] [00:16:03/00:18:38, 0.564s/it]: train_loss_raw=0.2985, running_loss=0.3606, LR=0.000100
[2025-08-11 03:10:08,686][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105096] [Batch 01720/03692] [00:16:09/00:18:31, 0.564s/it]: train_loss_raw=0.3419, running_loss=0.3608, LR=0.000100
[2025-08-11 03:10:15,080][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105108] [Batch 01732/03692] [00:16:16/00:18:24, 0.564s/it]: train_loss_raw=0.3771, running_loss=0.3622, LR=0.000100
[2025-08-11 03:10:21,410][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105120] [Batch 01744/03692] [00:16:22/00:18:17, 0.563s/it]: train_loss_raw=0.3730, running_loss=0.3638, LR=0.000100
[2025-08-11 03:10:27,765][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105132] [Batch 01756/03692] [00:16:28/00:18:10, 0.563s/it]: train_loss_raw=0.3259, running_loss=0.3622, LR=0.000100
[2025-08-11 03:10:34,039][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105144] [Batch 01768/03692] [00:16:35/00:18:02, 0.563s/it]: train_loss_raw=0.3249, running_loss=0.3607, LR=0.000100
[2025-08-11 03:10:40,270][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105156] [Batch 01780/03692] [00:16:41/00:17:55, 0.563s/it]: train_loss_raw=0.4180, running_loss=0.3593, LR=0.000100
[2025-08-11 03:10:46,482][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105168] [Batch 01792/03692] [00:16:47/00:17:48, 0.562s/it]: train_loss_raw=0.4437, running_loss=0.3590, LR=0.000100
[2025-08-11 03:10:52,727][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105180] [Batch 01804/03692] [00:16:53/00:17:41, 0.562s/it]: train_loss_raw=0.3904, running_loss=0.3610, LR=0.000100
[2025-08-11 03:10:59,021][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105192] [Batch 01816/03692] [00:17:00/00:17:33, 0.562s/it]: train_loss_raw=0.2964, running_loss=0.3600, LR=0.000100
[2025-08-11 03:11:05,518][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105204] [Batch 01828/03692] [00:17:06/00:17:26, 0.562s/it]: train_loss_raw=0.3943, running_loss=0.3610, LR=0.000100
[2025-08-11 03:11:11,950][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105216] [Batch 01840/03692] [00:17:13/00:17:19, 0.561s/it]: train_loss_raw=0.4323, running_loss=0.3620, LR=0.000100
[2025-08-11 03:11:18,394][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105228] [Batch 01852/03692] [00:17:19/00:17:12, 0.561s/it]: train_loss_raw=0.3508, running_loss=0.3628, LR=0.000100
[2025-08-11 03:11:24,922][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105240] [Batch 01864/03692] [00:17:25/00:17:05, 0.561s/it]: train_loss_raw=0.3032, running_loss=0.3633, LR=0.000100
[2025-08-11 03:11:31,450][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105252] [Batch 01876/03692] [00:17:32/00:16:58, 0.561s/it]: train_loss_raw=0.3626, running_loss=0.3623, LR=0.000100
[2025-08-11 03:11:37,823][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105264] [Batch 01888/03692] [00:17:38/00:16:51, 0.561s/it]: train_loss_raw=0.4000, running_loss=0.3622, LR=0.000100
[2025-08-11 03:11:44,256][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105276] [Batch 01900/03692] [00:17:45/00:16:44, 0.561s/it]: train_loss_raw=0.3244, running_loss=0.3617, LR=0.000100
[2025-08-11 03:11:50,704][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105288] [Batch 01912/03692] [00:17:51/00:16:37, 0.561s/it]: train_loss_raw=0.2757, running_loss=0.3614, LR=0.000100
[2025-08-11 03:11:57,160][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105300] [Batch 01924/03692] [00:17:58/00:16:30, 0.560s/it]: train_loss_raw=0.3075, running_loss=0.3615, LR=0.000100
[2025-08-11 03:12:03,659][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105312] [Batch 01936/03692] [00:18:04/00:16:23, 0.560s/it]: train_loss_raw=0.3560, running_loss=0.3604, LR=0.000100
[2025-08-11 03:12:10,039][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105324] [Batch 01948/03692] [00:18:11/00:16:16, 0.560s/it]: train_loss_raw=0.2827, running_loss=0.3568, LR=0.000100
[2025-08-11 03:12:16,408][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105336] [Batch 01960/03692] [00:18:17/00:16:09, 0.560s/it]: train_loss_raw=0.3439, running_loss=0.3565, LR=0.000100
[2025-08-11 03:12:22,789][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105348] [Batch 01972/03692] [00:18:23/00:16:02, 0.560s/it]: train_loss_raw=0.3090, running_loss=0.3537, LR=0.000100
[2025-08-11 03:12:29,185][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105360] [Batch 01984/03692] [00:18:30/00:15:55, 0.560s/it]: train_loss_raw=0.3229, running_loss=0.3528, LR=0.000100
[2025-08-11 03:12:35,634][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105372] [Batch 01996/03692] [00:18:36/00:15:48, 0.559s/it]: train_loss_raw=0.3134, running_loss=0.3544, LR=0.000100
[2025-08-11 03:12:41,997][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105384] [Batch 02008/03692] [00:18:43/00:15:41, 0.559s/it]: train_loss_raw=0.4017, running_loss=0.3562, LR=0.000100
[2025-08-11 03:12:48,420][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105396] [Batch 02020/03692] [00:18:49/00:15:34, 0.559s/it]: train_loss_raw=0.4272, running_loss=0.3596, LR=0.000100
[2025-08-11 03:12:54,776][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105408] [Batch 02032/03692] [00:18:55/00:15:27, 0.559s/it]: train_loss_raw=0.3573, running_loss=0.3593, LR=0.000100
[2025-08-11 03:13:01,137][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105420] [Batch 02044/03692] [00:19:02/00:15:20, 0.559s/it]: train_loss_raw=0.3199, running_loss=0.3582, LR=0.000100
[2025-08-11 03:13:07,521][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105432] [Batch 02056/03692] [00:19:08/00:15:13, 0.559s/it]: train_loss_raw=0.2467, running_loss=0.3580, LR=0.000100
[2025-08-11 03:13:13,882][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105444] [Batch 02068/03692] [00:19:14/00:15:06, 0.558s/it]: train_loss_raw=0.3347, running_loss=0.3603, LR=0.000100
[2025-08-11 03:13:20,246][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105456] [Batch 02080/03692] [00:19:21/00:15:00, 0.558s/it]: train_loss_raw=0.3920, running_loss=0.3624, LR=0.000100
[2025-08-11 03:13:26,561][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105468] [Batch 02092/03692] [00:19:27/00:14:53, 0.558s/it]: train_loss_raw=0.4091, running_loss=0.3635, LR=0.000100
[2025-08-11 03:13:32,914][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105480] [Batch 02104/03692] [00:19:33/00:14:46, 0.558s/it]: train_loss_raw=0.3281, running_loss=0.3595, LR=0.000100
[2025-08-11 03:13:39,267][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105492] [Batch 02116/03692] [00:19:40/00:14:39, 0.558s/it]: train_loss_raw=0.3638, running_loss=0.3587, LR=0.000100
[2025-08-11 03:13:45,677][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105504] [Batch 02128/03692] [00:19:46/00:14:32, 0.558s/it]: train_loss_raw=0.2856, running_loss=0.3567, LR=0.000100
[2025-08-11 03:13:52,227][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105516] [Batch 02140/03692] [00:19:53/00:14:25, 0.558s/it]: train_loss_raw=0.3638, running_loss=0.3563, LR=0.000100
[2025-08-11 03:13:58,597][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105528] [Batch 02152/03692] [00:19:59/00:14:18, 0.557s/it]: train_loss_raw=0.3766, running_loss=0.3550, LR=0.000100
[2025-08-11 03:14:04,929][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105540] [Batch 02164/03692] [00:20:06/00:14:11, 0.557s/it]: train_loss_raw=0.3201, running_loss=0.3547, LR=0.000100
[2025-08-11 03:14:11,358][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105552] [Batch 02176/03692] [00:20:12/00:14:04, 0.557s/it]: train_loss_raw=0.2930, running_loss=0.3519, LR=0.000100
[2025-08-11 03:14:17,732][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105564] [Batch 02188/03692] [00:20:18/00:13:57, 0.557s/it]: train_loss_raw=0.3534, running_loss=0.3510, LR=0.000100
[2025-08-11 03:14:24,072][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105576] [Batch 02200/03692] [00:20:25/00:13:50, 0.557s/it]: train_loss_raw=0.2822, running_loss=0.3500, LR=0.000100
[2025-08-11 03:14:30,503][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105588] [Batch 02212/03692] [00:20:31/00:13:44, 0.557s/it]: train_loss_raw=0.2891, running_loss=0.3507, LR=0.000100
[2025-08-11 03:14:36,864][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105600] [Batch 02224/03692] [00:20:37/00:13:37, 0.557s/it]: train_loss_raw=0.3657, running_loss=0.3524, LR=0.000100
[2025-08-11 03:14:43,231][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105612] [Batch 02236/03692] [00:20:44/00:13:30, 0.556s/it]: train_loss_raw=0.3826, running_loss=0.3516, LR=0.000100
[2025-08-11 03:14:49,586][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105624] [Batch 02248/03692] [00:20:50/00:13:23, 0.556s/it]: train_loss_raw=0.2942, running_loss=0.3537, LR=0.000100
[2025-08-11 03:14:55,962][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105636] [Batch 02260/03692] [00:20:57/00:13:16, 0.556s/it]: train_loss_raw=0.4242, running_loss=0.3573, LR=0.000100
[2025-08-11 03:15:02,344][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105648] [Batch 02272/03692] [00:21:03/00:13:09, 0.556s/it]: train_loss_raw=0.3493, running_loss=0.3587, LR=0.000100
[2025-08-11 03:15:08,761][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105660] [Batch 02284/03692] [00:21:09/00:13:02, 0.556s/it]: train_loss_raw=0.4279, running_loss=0.3589, LR=0.000100
[2025-08-11 03:15:15,128][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105672] [Batch 02296/03692] [00:21:16/00:12:55, 0.556s/it]: train_loss_raw=0.4058, running_loss=0.3591, LR=0.000100
[2025-08-11 03:15:21,523][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105684] [Batch 02308/03692] [00:21:22/00:12:49, 0.556s/it]: train_loss_raw=0.4196, running_loss=0.3612, LR=0.000100
[2025-08-11 03:15:27,924][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105696] [Batch 02320/03692] [00:21:28/00:12:42, 0.556s/it]: train_loss_raw=0.3291, running_loss=0.3597, LR=0.000100
[2025-08-11 03:15:34,284][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105708] [Batch 02332/03692] [00:21:35/00:12:35, 0.555s/it]: train_loss_raw=0.3537, running_loss=0.3597, LR=0.000100
[2025-08-11 03:15:40,679][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105720] [Batch 02344/03692] [00:21:41/00:12:28, 0.555s/it]: train_loss_raw=0.3787, running_loss=0.3595, LR=0.000100
[2025-08-11 03:15:46,950][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105732] [Batch 02356/03692] [00:21:48/00:12:21, 0.555s/it]: train_loss_raw=0.3570, running_loss=0.3613, LR=0.000100
[2025-08-11 03:15:53,302][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105744] [Batch 02368/03692] [00:21:54/00:12:14, 0.555s/it]: train_loss_raw=0.3457, running_loss=0.3639, LR=0.000100
[2025-08-11 03:15:59,827][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105756] [Batch 02380/03692] [00:22:00/00:12:08, 0.555s/it]: train_loss_raw=0.4131, running_loss=0.3624, LR=0.000100
[2025-08-11 03:16:06,268][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105768] [Batch 02392/03692] [00:22:07/00:12:01, 0.555s/it]: train_loss_raw=0.3242, running_loss=0.3625, LR=0.000100
[2025-08-11 03:16:12,752][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105780] [Batch 02404/03692] [00:22:13/00:11:54, 0.555s/it]: train_loss_raw=0.3644, running_loss=0.3612, LR=0.000100
[2025-08-11 03:16:19,148][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105792] [Batch 02416/03692] [00:22:20/00:11:47, 0.555s/it]: train_loss_raw=0.4869, running_loss=0.3620, LR=0.000100
[2025-08-11 03:16:25,536][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105804] [Batch 02428/03692] [00:22:26/00:11:41, 0.555s/it]: train_loss_raw=0.3656, running_loss=0.3614, LR=0.000100
[2025-08-11 03:16:31,911][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105816] [Batch 02440/03692] [00:22:32/00:11:34, 0.555s/it]: train_loss_raw=0.2962, running_loss=0.3608, LR=0.000100
[2025-08-11 03:16:38,268][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105828] [Batch 02452/03692] [00:22:39/00:11:27, 0.554s/it]: train_loss_raw=0.4016, running_loss=0.3582, LR=0.000100
[2025-08-11 03:16:44,661][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105840] [Batch 02464/03692] [00:22:45/00:11:20, 0.554s/it]: train_loss_raw=0.4488, running_loss=0.3598, LR=0.000100
[2025-08-11 03:16:51,058][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105852] [Batch 02476/03692] [00:22:52/00:11:13, 0.554s/it]: train_loss_raw=0.3720, running_loss=0.3601, LR=0.000100
[2025-08-11 03:16:57,404][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105864] [Batch 02488/03692] [00:22:58/00:11:07, 0.554s/it]: train_loss_raw=0.3922, running_loss=0.3601, LR=0.000100
[2025-08-11 03:17:03,813][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105876] [Batch 02500/03692] [00:23:04/00:11:00, 0.554s/it]: train_loss_raw=0.3365, running_loss=0.3606, LR=0.000100
[2025-08-11 03:17:10,381][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105888] [Batch 02512/03692] [00:23:11/00:10:53, 0.554s/it]: train_loss_raw=0.3141, running_loss=0.3600, LR=0.000100
[2025-08-11 03:17:16,951][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105900] [Batch 02524/03692] [00:23:18/00:10:46, 0.554s/it]: train_loss_raw=0.3327, running_loss=0.3604, LR=0.000100
[2025-08-11 03:17:23,574][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105912] [Batch 02536/03692] [00:23:24/00:10:40, 0.554s/it]: train_loss_raw=0.4239, running_loss=0.3628, LR=0.000100
[2025-08-11 03:17:30,040][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105924] [Batch 02548/03692] [00:23:31/00:10:33, 0.554s/it]: train_loss_raw=0.4006, running_loss=0.3622, LR=0.000100
[2025-08-11 03:17:36,399][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105936] [Batch 02560/03692] [00:23:37/00:10:26, 0.554s/it]: train_loss_raw=0.3865, running_loss=0.3608, LR=0.000100
[2025-08-11 03:17:42,754][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105948] [Batch 02572/03692] [00:23:43/00:10:20, 0.554s/it]: train_loss_raw=0.3504, running_loss=0.3610, LR=0.000100
[2025-08-11 03:17:49,104][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105960] [Batch 02584/03692] [00:23:50/00:10:13, 0.553s/it]: train_loss_raw=0.4163, running_loss=0.3607, LR=0.000100
[2025-08-11 03:17:55,497][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105972] [Batch 02596/03692] [00:23:56/00:10:06, 0.553s/it]: train_loss_raw=0.3568, running_loss=0.3598, LR=0.000100
[2025-08-11 03:18:01,976][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105984] [Batch 02608/03692] [00:24:03/00:09:59, 0.553s/it]: train_loss_raw=0.4102, running_loss=0.3595, LR=0.000100
[2025-08-11 03:18:08,304][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 105996] [Batch 02620/03692] [00:24:09/00:09:53, 0.553s/it]: train_loss_raw=0.2928, running_loss=0.3600, LR=0.000100
[2025-08-11 03:18:19,254][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106008] [Batch 02632/03692] [00:24:20/00:09:48, 0.555s/it]: train_loss_raw=0.3984, running_loss=0.3616, LR=0.000100
[2025-08-11 03:18:25,621][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106020] [Batch 02644/03692] [00:24:26/00:09:41, 0.555s/it]: train_loss_raw=0.4139, running_loss=0.3607, LR=0.000100
[2025-08-11 03:18:32,024][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106032] [Batch 02656/03692] [00:24:33/00:09:34, 0.555s/it]: train_loss_raw=0.3393, running_loss=0.3592, LR=0.000100
[2025-08-11 03:18:38,427][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106044] [Batch 02668/03692] [00:24:39/00:09:27, 0.555s/it]: train_loss_raw=0.3409, running_loss=0.3610, LR=0.000100
[2025-08-11 03:18:45,013][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106056] [Batch 02680/03692] [00:24:46/00:09:21, 0.555s/it]: train_loss_raw=0.3596, running_loss=0.3658, LR=0.000100
[2025-08-11 03:18:51,486][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106068] [Batch 02692/03692] [00:24:52/00:09:14, 0.554s/it]: train_loss_raw=0.3441, running_loss=0.3627, LR=0.000100
[2025-08-11 03:18:57,959][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106080] [Batch 02704/03692] [00:24:59/00:09:07, 0.554s/it]: train_loss_raw=0.3998, running_loss=0.3630, LR=0.000100
[2025-08-11 03:19:04,554][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106092] [Batch 02716/03692] [00:25:05/00:09:01, 0.554s/it]: train_loss_raw=0.3982, running_loss=0.3605, LR=0.000100
[2025-08-11 03:19:10,982][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106104] [Batch 02728/03692] [00:25:12/00:08:54, 0.554s/it]: train_loss_raw=0.4731, running_loss=0.3584, LR=0.000100
[2025-08-11 03:19:17,406][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106116] [Batch 02740/03692] [00:25:18/00:08:47, 0.554s/it]: train_loss_raw=0.3784, running_loss=0.3595, LR=0.000100
[2025-08-11 03:19:23,732][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106128] [Batch 02752/03692] [00:25:24/00:08:40, 0.554s/it]: train_loss_raw=0.3479, running_loss=0.3601, LR=0.000100
[2025-08-11 03:19:30,231][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106140] [Batch 02764/03692] [00:25:31/00:08:34, 0.554s/it]: train_loss_raw=0.3932, running_loss=0.3613, LR=0.000100
[2025-08-11 03:19:36,851][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106152] [Batch 02776/03692] [00:25:37/00:08:27, 0.554s/it]: train_loss_raw=0.3789, running_loss=0.3604, LR=0.000100
[2025-08-11 03:19:43,428][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106164] [Batch 02788/03692] [00:25:44/00:08:20, 0.554s/it]: train_loss_raw=0.4125, running_loss=0.3605, LR=0.000100
[2025-08-11 03:19:49,985][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106176] [Batch 02800/03692] [00:25:51/00:08:14, 0.554s/it]: train_loss_raw=0.3684, running_loss=0.3582, LR=0.000100
[2025-08-11 03:19:56,572][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106188] [Batch 02812/03692] [00:25:57/00:08:07, 0.554s/it]: train_loss_raw=0.3905, running_loss=0.3594, LR=0.000100
[2025-08-11 03:20:03,124][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106200] [Batch 02824/03692] [00:26:04/00:08:00, 0.554s/it]: train_loss_raw=0.5267, running_loss=0.3585, LR=0.000100
[2025-08-11 03:20:09,657][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106212] [Batch 02836/03692] [00:26:10/00:07:54, 0.554s/it]: train_loss_raw=0.4076, running_loss=0.3593, LR=0.000100
[2025-08-11 03:20:16,119][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106224] [Batch 02848/03692] [00:26:17/00:07:47, 0.554s/it]: train_loss_raw=0.4058, running_loss=0.3605, LR=0.000100
[2025-08-11 03:20:22,529][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106236] [Batch 02860/03692] [00:26:23/00:07:40, 0.554s/it]: train_loss_raw=0.3946, running_loss=0.3613, LR=0.000100
[2025-08-11 03:20:28,934][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106248] [Batch 02872/03692] [00:26:30/00:07:33, 0.554s/it]: train_loss_raw=0.3105, running_loss=0.3642, LR=0.000100
[2025-08-11 03:20:35,265][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106260] [Batch 02884/03692] [00:26:36/00:07:27, 0.554s/it]: train_loss_raw=0.3386, running_loss=0.3632, LR=0.000100
[2025-08-11 03:20:41,800][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106272] [Batch 02896/03692] [00:26:42/00:07:20, 0.553s/it]: train_loss_raw=0.4847, running_loss=0.3649, LR=0.000100
[2025-08-11 03:20:48,195][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106284] [Batch 02908/03692] [00:26:49/00:07:13, 0.553s/it]: train_loss_raw=0.3669, running_loss=0.3623, LR=0.000100
[2025-08-11 03:20:54,547][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106296] [Batch 02920/03692] [00:26:55/00:07:07, 0.553s/it]: train_loss_raw=0.3475, running_loss=0.3610, LR=0.000100
[2025-08-11 03:21:00,972][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106308] [Batch 02932/03692] [00:27:02/00:07:00, 0.553s/it]: train_loss_raw=0.3818, running_loss=0.3639, LR=0.000100
[2025-08-11 03:21:07,412][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106320] [Batch 02944/03692] [00:27:08/00:06:53, 0.553s/it]: train_loss_raw=0.3386, running_loss=0.3602, LR=0.000100
[2025-08-11 03:21:13,624][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106332] [Batch 02956/03692] [00:27:14/00:06:47, 0.553s/it]: train_loss_raw=0.3521, running_loss=0.3609, LR=0.000100
[2025-08-11 03:21:19,983][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106344] [Batch 02968/03692] [00:27:21/00:06:40, 0.553s/it]: train_loss_raw=0.3773, running_loss=0.3584, LR=0.000100
[2025-08-11 03:21:26,342][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106356] [Batch 02980/03692] [00:27:27/00:06:33, 0.553s/it]: train_loss_raw=0.2999, running_loss=0.3587, LR=0.000100
[2025-08-11 03:21:32,698][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106368] [Batch 02992/03692] [00:27:33/00:06:26, 0.553s/it]: train_loss_raw=0.3913, running_loss=0.3603, LR=0.000100
[2025-08-11 03:21:39,229][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106380] [Batch 03004/03692] [00:27:40/00:06:20, 0.553s/it]: train_loss_raw=0.3840, running_loss=0.3592, LR=0.000100
[2025-08-11 03:21:45,741][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106392] [Batch 03016/03692] [00:27:46/00:06:13, 0.553s/it]: train_loss_raw=0.4496, running_loss=0.3566, LR=0.000100
[2025-08-11 03:21:52,223][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106404] [Batch 03028/03692] [00:27:53/00:06:06, 0.553s/it]: train_loss_raw=0.3880, running_loss=0.3573, LR=0.000100
[2025-08-11 03:21:58,680][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106416] [Batch 03040/03692] [00:27:59/00:06:00, 0.553s/it]: train_loss_raw=0.3788, running_loss=0.3577, LR=0.000100
[2025-08-11 03:22:05,136][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106428] [Batch 03052/03692] [00:28:06/00:05:53, 0.552s/it]: train_loss_raw=0.3995, running_loss=0.3612, LR=0.000100
[2025-08-11 03:22:11,579][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106440] [Batch 03064/03692] [00:28:12/00:05:46, 0.552s/it]: train_loss_raw=0.3087, running_loss=0.3593, LR=0.000100
[2025-08-11 03:22:18,059][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106452] [Batch 03076/03692] [00:28:19/00:05:40, 0.552s/it]: train_loss_raw=0.4406, running_loss=0.3633, LR=0.000100
[2025-08-11 03:22:24,500][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106464] [Batch 03088/03692] [00:28:25/00:05:33, 0.552s/it]: train_loss_raw=0.3233, running_loss=0.3627, LR=0.000100
[2025-08-11 03:22:30,882][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106476] [Batch 03100/03692] [00:28:31/00:05:26, 0.552s/it]: train_loss_raw=0.2672, running_loss=0.3615, LR=0.000100
[2025-08-11 03:22:37,347][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106488] [Batch 03112/03692] [00:28:38/00:05:20, 0.552s/it]: train_loss_raw=0.3251, running_loss=0.3631, LR=0.000100
[2025-08-11 03:22:43,691][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106500] [Batch 03124/03692] [00:28:44/00:05:13, 0.552s/it]: train_loss_raw=0.4070, running_loss=0.3621, LR=0.000100
[2025-08-11 03:22:50,040][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106512] [Batch 03136/03692] [00:28:51/00:05:06, 0.552s/it]: train_loss_raw=0.3643, running_loss=0.3601, LR=0.000100
[2025-08-11 03:22:56,416][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106524] [Batch 03148/03692] [00:28:57/00:05:00, 0.552s/it]: train_loss_raw=0.3889, running_loss=0.3613, LR=0.000100
[2025-08-11 03:23:02,952][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106536] [Batch 03160/03692] [00:29:04/00:04:53, 0.552s/it]: train_loss_raw=0.4250, running_loss=0.3608, LR=0.000100
[2025-08-11 03:23:09,378][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106548] [Batch 03172/03692] [00:29:10/00:04:46, 0.552s/it]: train_loss_raw=0.4604, running_loss=0.3622, LR=0.000100
[2025-08-11 03:23:15,720][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106560] [Batch 03184/03692] [00:29:16/00:04:40, 0.552s/it]: train_loss_raw=0.3364, running_loss=0.3589, LR=0.000100
[2025-08-11 03:23:22,088][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106572] [Batch 03196/03692] [00:29:23/00:04:33, 0.552s/it]: train_loss_raw=0.3002, running_loss=0.3591, LR=0.000100
[2025-08-11 03:23:28,482][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106584] [Batch 03208/03692] [00:29:29/00:04:26, 0.552s/it]: train_loss_raw=0.2669, running_loss=0.3573, LR=0.000100
[2025-08-11 03:23:34,754][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106596] [Batch 03220/03692] [00:29:35/00:04:20, 0.551s/it]: train_loss_raw=0.4289, running_loss=0.3602, LR=0.000100
[2025-08-11 03:23:41,159][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106608] [Batch 03232/03692] [00:29:42/00:04:13, 0.551s/it]: train_loss_raw=0.2821, running_loss=0.3630, LR=0.000100
[2025-08-11 03:23:47,546][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106620] [Batch 03244/03692] [00:29:48/00:04:07, 0.551s/it]: train_loss_raw=0.3582, running_loss=0.3636, LR=0.000100
[2025-08-11 03:23:53,950][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106632] [Batch 03256/03692] [00:29:55/00:04:00, 0.551s/it]: train_loss_raw=0.3982, running_loss=0.3661, LR=0.000100
[2025-08-11 03:24:00,337][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106644] [Batch 03268/03692] [00:30:01/00:03:53, 0.551s/it]: train_loss_raw=0.3432, running_loss=0.3618, LR=0.000100
[2025-08-11 03:24:06,716][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106656] [Batch 03280/03692] [00:30:07/00:03:47, 0.551s/it]: train_loss_raw=0.3989, running_loss=0.3599, LR=0.000100
[2025-08-11 03:24:13,088][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106668] [Batch 03292/03692] [00:30:14/00:03:40, 0.551s/it]: train_loss_raw=0.2708, running_loss=0.3601, LR=0.000100
[2025-08-11 03:24:19,611][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106680] [Batch 03304/03692] [00:30:20/00:03:33, 0.551s/it]: train_loss_raw=0.3849, running_loss=0.3606, LR=0.000100
[2025-08-11 03:24:26,169][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106692] [Batch 03316/03692] [00:30:27/00:03:27, 0.551s/it]: train_loss_raw=0.4490, running_loss=0.3621, LR=0.000100
[2025-08-11 03:24:32,489][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106704] [Batch 03328/03692] [00:30:33/00:03:20, 0.551s/it]: train_loss_raw=0.3786, running_loss=0.3604, LR=0.000100
[2025-08-11 03:24:38,935][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106716] [Batch 03340/03692] [00:30:40/00:03:13, 0.551s/it]: train_loss_raw=0.4065, running_loss=0.3612, LR=0.000100
[2025-08-11 03:24:45,300][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106728] [Batch 03352/03692] [00:30:46/00:03:07, 0.551s/it]: train_loss_raw=0.3739, running_loss=0.3607, LR=0.000100
[2025-08-11 03:24:51,740][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106740] [Batch 03364/03692] [00:30:52/00:03:00, 0.551s/it]: train_loss_raw=0.3021, running_loss=0.3627, LR=0.000100
[2025-08-11 03:24:58,122][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106752] [Batch 03376/03692] [00:30:59/00:02:54, 0.551s/it]: train_loss_raw=0.3245, running_loss=0.3588, LR=0.000100
[2025-08-11 03:25:04,475][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106764] [Batch 03388/03692] [00:31:05/00:02:47, 0.551s/it]: train_loss_raw=0.3559, running_loss=0.3578, LR=0.000100
[2025-08-11 03:25:10,820][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106776] [Batch 03400/03692] [00:31:11/00:02:40, 0.551s/it]: train_loss_raw=0.3588, running_loss=0.3590, LR=0.000100
[2025-08-11 03:25:17,245][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106788] [Batch 03412/03692] [00:31:18/00:02:34, 0.551s/it]: train_loss_raw=0.4099, running_loss=0.3589, LR=0.000100
[2025-08-11 03:25:23,697][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106800] [Batch 03424/03692] [00:31:24/00:02:27, 0.550s/it]: train_loss_raw=0.4586, running_loss=0.3622, LR=0.000100
[2025-08-11 03:25:30,203][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106812] [Batch 03436/03692] [00:31:31/00:02:20, 0.550s/it]: train_loss_raw=0.2742, running_loss=0.3612, LR=0.000100
[2025-08-11 03:25:36,583][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106824] [Batch 03448/03692] [00:31:37/00:02:14, 0.550s/it]: train_loss_raw=0.3240, running_loss=0.3609, LR=0.000100
[2025-08-11 03:25:43,001][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106836] [Batch 03460/03692] [00:31:44/00:02:07, 0.550s/it]: train_loss_raw=0.3223, running_loss=0.3619, LR=0.000100
[2025-08-11 03:25:49,349][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106848] [Batch 03472/03692] [00:31:50/00:02:01, 0.550s/it]: train_loss_raw=0.3743, running_loss=0.3642, LR=0.000100
[2025-08-11 03:25:55,793][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106860] [Batch 03484/03692] [00:31:56/00:01:54, 0.550s/it]: train_loss_raw=0.3714, running_loss=0.3642, LR=0.000100
[2025-08-11 03:26:02,342][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106872] [Batch 03496/03692] [00:32:03/00:01:47, 0.550s/it]: train_loss_raw=0.3440, running_loss=0.3629, LR=0.000100
[2025-08-11 03:26:08,680][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106884] [Batch 03508/03692] [00:32:09/00:01:41, 0.550s/it]: train_loss_raw=0.3186, running_loss=0.3613, LR=0.000100
[2025-08-11 03:26:15,071][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106896] [Batch 03520/03692] [00:32:16/00:01:34, 0.550s/it]: train_loss_raw=0.3869, running_loss=0.3627, LR=0.000100
[2025-08-11 03:26:21,509][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106908] [Batch 03532/03692] [00:32:22/00:01:27, 0.550s/it]: train_loss_raw=0.3120, running_loss=0.3628, LR=0.000100
[2025-08-11 03:26:28,160][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106920] [Batch 03544/03692] [00:32:29/00:01:21, 0.550s/it]: train_loss_raw=0.3379, running_loss=0.3629, LR=0.000100
[2025-08-11 03:26:34,696][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106932] [Batch 03556/03692] [00:32:35/00:01:14, 0.550s/it]: train_loss_raw=0.5025, running_loss=0.3641, LR=0.000100
[2025-08-11 03:26:41,154][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106944] [Batch 03568/03692] [00:32:42/00:01:08, 0.550s/it]: train_loss_raw=0.3900, running_loss=0.3632, LR=0.000100
[2025-08-11 03:26:47,590][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106956] [Batch 03580/03692] [00:32:48/00:01:01, 0.550s/it]: train_loss_raw=0.3907, running_loss=0.3621, LR=0.000100
[2025-08-11 03:26:54,065][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106968] [Batch 03592/03692] [00:32:55/00:00:54, 0.550s/it]: train_loss_raw=0.3130, running_loss=0.3613, LR=0.000100
[2025-08-11 03:27:00,519][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106980] [Batch 03604/03692] [00:33:01/00:00:48, 0.550s/it]: train_loss_raw=0.3532, running_loss=0.3565, LR=0.000100
[2025-08-11 03:27:06,939][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 106992] [Batch 03616/03692] [00:33:08/00:00:41, 0.550s/it]: train_loss_raw=0.2870, running_loss=0.3553, LR=0.000100
[2025-08-11 03:27:13,302][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107004] [Batch 03628/03692] [00:33:14/00:00:35, 0.550s/it]: train_loss_raw=0.3614, running_loss=0.3570, LR=0.000100
[2025-08-11 03:27:19,652][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107016] [Batch 03640/03692] [00:33:20/00:00:28, 0.550s/it]: train_loss_raw=0.4863, running_loss=0.3605, LR=0.000100
[2025-08-11 03:27:26,042][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107028] [Batch 03652/03692] [00:33:27/00:00:21, 0.550s/it]: train_loss_raw=0.3456, running_loss=0.3589, LR=0.000100
[2025-08-11 03:27:32,526][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107040] [Batch 03664/03692] [00:33:33/00:00:15, 0.550s/it]: train_loss_raw=0.4038, running_loss=0.3611, LR=0.000100
[2025-08-11 03:27:39,013][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107052] [Batch 03676/03692] [00:33:40/00:00:08, 0.550s/it]: train_loss_raw=0.3119, running_loss=0.3576, LR=0.000100
[2025-08-11 03:27:45,529][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 107064] [Batch 03688/03692] [00:33:46/00:00:02, 0.550s/it]: train_loss_raw=0.3441, running_loss=0.3568, LR=0.000100
[2025-08-11 03:27:53,021][__main__][INFO] - [VALIDATION] [Epoch 28/29] Starting validation.
[2025-08-11 03:28:26,304][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 107069] [Batch 00011/00025] [00:00:33/00:00:36, 2.774s/it]
[2025-08-11 03:28:41,636][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 107069] [Batch 00023/00025] [00:00:48/00:00:02, 2.026s/it]
[2025-08-11 03:28:42,762][__main__][INFO] - [VALIDATION] [Epoch 28/29] train_loss=0.35642, valid_loss=0.56726
[2025-08-11 03:28:42,763][__main__][INFO] - [VALIDATION] [Epoch 28/29] Metrics:
[2025-08-11 03:28:42,763][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_er      0.220
[2025-08-11 03:28:42,763][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_prec    0.577
[2025-08-11 03:28:42,763][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_recall  0.582
[2025-08-11 03:28:42,763][__main__][INFO] - [VALIDATION] [Epoch 28/29] - pep_recall 0.569
[2025-08-11 03:28:42,766][__main__][INFO] - [TRAIN] [Epoch 28/29] Epoch complete, total time 16:32:41, remaining time 00:34:13, 00:34:13 per epoch
[2025-08-11 03:28:46,934][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107076] [Batch 00008/03692] [00:00:03/00:29:27, 0.480s/it]: train_loss_raw=0.2555, running_loss=0.3960, LR=0.000100
[2025-08-11 03:28:53,421][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107088] [Batch 00020/03692] [00:00:10/00:31:35, 0.516s/it]: train_loss_raw=0.4335, running_loss=0.3913, LR=0.000100
[2025-08-11 03:28:59,829][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107100] [Batch 00032/03692] [00:00:16/00:31:53, 0.523s/it]: train_loss_raw=0.3973, running_loss=0.3898, LR=0.000100
[2025-08-11 03:29:06,199][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107112] [Batch 00044/03692] [00:00:23/00:31:55, 0.525s/it]: train_loss_raw=0.3225, running_loss=0.3885, LR=0.000100
[2025-08-11 03:29:12,660][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107124] [Batch 00056/03692] [00:00:29/00:31:59, 0.528s/it]: train_loss_raw=0.3866, running_loss=0.3870, LR=0.000100
[2025-08-11 03:29:19,111][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107136] [Batch 00068/03692] [00:00:36/00:31:59, 0.530s/it]: train_loss_raw=0.3985, running_loss=0.3839, LR=0.000100
[2025-08-11 03:29:25,494][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107148] [Batch 00080/03692] [00:00:42/00:31:54, 0.530s/it]: train_loss_raw=0.4050, running_loss=0.3850, LR=0.000100
[2025-08-11 03:29:31,905][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107160] [Batch 00092/03692] [00:00:48/00:31:49, 0.531s/it]: train_loss_raw=0.5112, running_loss=0.3819, LR=0.000100
[2025-08-11 03:29:38,280][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107172] [Batch 00104/03692] [00:00:55/00:31:43, 0.531s/it]: train_loss_raw=0.4807, running_loss=0.3813, LR=0.000100
[2025-08-11 03:29:44,666][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107184] [Batch 00116/03692] [00:01:01/00:31:38, 0.531s/it]: train_loss_raw=0.4531, running_loss=0.3798, LR=0.000100
[2025-08-11 03:29:51,067][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107196] [Batch 00128/03692] [00:01:07/00:31:32, 0.531s/it]: train_loss_raw=0.3233, running_loss=0.3773, LR=0.000100
[2025-08-11 03:29:57,447][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107208] [Batch 00140/03692] [00:01:14/00:31:26, 0.531s/it]: train_loss_raw=0.3750, running_loss=0.3752, LR=0.000100
[2025-08-11 03:30:03,846][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107220] [Batch 00152/03692] [00:01:20/00:31:20, 0.531s/it]: train_loss_raw=0.3114, running_loss=0.3731, LR=0.000100
[2025-08-11 03:30:10,314][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107232] [Batch 00164/03692] [00:01:27/00:31:16, 0.532s/it]: train_loss_raw=0.2749, running_loss=0.3709, LR=0.000100
[2025-08-11 03:30:16,652][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107244] [Batch 00176/03692] [00:01:33/00:31:08, 0.532s/it]: train_loss_raw=0.2899, running_loss=0.3696, LR=0.000100
[2025-08-11 03:30:23,030][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107256] [Batch 00188/03692] [00:01:39/00:31:02, 0.532s/it]: train_loss_raw=0.3690, running_loss=0.3709, LR=0.000100
[2025-08-11 03:30:29,435][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107268] [Batch 00200/03692] [00:01:46/00:30:56, 0.532s/it]: train_loss_raw=0.4714, running_loss=0.3727, LR=0.000100
[2025-08-11 03:30:35,801][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107280] [Batch 00212/03692] [00:01:52/00:30:50, 0.532s/it]: train_loss_raw=0.2658, running_loss=0.3721, LR=0.000100
[2025-08-11 03:30:42,190][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107292] [Batch 00224/03692] [00:01:59/00:30:43, 0.532s/it]: train_loss_raw=0.4119, running_loss=0.3714, LR=0.000100
[2025-08-11 03:30:48,683][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107304] [Batch 00236/03692] [00:02:05/00:30:39, 0.532s/it]: train_loss_raw=0.2944, running_loss=0.3690, LR=0.000100
[2025-08-11 03:30:55,191][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107316] [Batch 00248/03692] [00:02:12/00:30:34, 0.533s/it]: train_loss_raw=0.3445, running_loss=0.3663, LR=0.000100
[2025-08-11 03:31:01,604][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107328] [Batch 00260/03692] [00:02:18/00:30:28, 0.533s/it]: train_loss_raw=0.3990, running_loss=0.3650, LR=0.000100
[2025-08-11 03:31:07,952][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107340] [Batch 00272/03692] [00:02:24/00:30:21, 0.533s/it]: train_loss_raw=0.3131, running_loss=0.3609, LR=0.000100
[2025-08-11 03:31:14,310][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107352] [Batch 00284/03692] [00:02:31/00:30:14, 0.532s/it]: train_loss_raw=0.2616, running_loss=0.3586, LR=0.000100
[2025-08-11 03:31:20,632][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107364] [Batch 00296/03692] [00:02:37/00:30:07, 0.532s/it]: train_loss_raw=0.2743, running_loss=0.3582, LR=0.000100
[2025-08-11 03:31:26,978][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107376] [Batch 00308/03692] [00:02:43/00:30:00, 0.532s/it]: train_loss_raw=0.3490, running_loss=0.3566, LR=0.000100
[2025-08-11 03:31:33,415][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107388] [Batch 00320/03692] [00:02:50/00:29:54, 0.532s/it]: train_loss_raw=0.3807, running_loss=0.3592, LR=0.000100
[2025-08-11 03:31:39,820][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107400] [Batch 00332/03692] [00:02:56/00:29:48, 0.532s/it]: train_loss_raw=0.3887, running_loss=0.3578, LR=0.000100
[2025-08-11 03:31:46,296][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107412] [Batch 00344/03692] [00:03:03/00:29:43, 0.533s/it]: train_loss_raw=0.3638, running_loss=0.3571, LR=0.000100
[2025-08-11 03:31:52,732][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107424] [Batch 00356/03692] [00:03:09/00:29:37, 0.533s/it]: train_loss_raw=0.3061, running_loss=0.3565, LR=0.000100
[2025-08-11 03:31:59,130][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107436] [Batch 00368/03692] [00:03:16/00:29:30, 0.533s/it]: train_loss_raw=0.2949, running_loss=0.3558, LR=0.000100
[2025-08-11 03:32:05,559][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107448] [Batch 00380/03692] [00:03:22/00:29:24, 0.533s/it]: train_loss_raw=0.2836, running_loss=0.3575, LR=0.000100
[2025-08-11 03:32:11,893][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107460] [Batch 00392/03692] [00:03:28/00:29:17, 0.533s/it]: train_loss_raw=0.3935, running_loss=0.3551, LR=0.000100
[2025-08-11 03:32:18,261][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107472] [Batch 00404/03692] [00:03:35/00:29:11, 0.533s/it]: train_loss_raw=0.3651, running_loss=0.3563, LR=0.000100
[2025-08-11 03:32:24,635][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107484] [Batch 00416/03692] [00:03:41/00:29:04, 0.533s/it]: train_loss_raw=0.3959, running_loss=0.3580, LR=0.000100
[2025-08-11 03:32:30,941][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107496] [Batch 00428/03692] [00:03:47/00:28:57, 0.532s/it]: train_loss_raw=0.3132, running_loss=0.3563, LR=0.000100
[2025-08-11 03:32:37,253][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107508] [Batch 00440/03692] [00:03:54/00:28:50, 0.532s/it]: train_loss_raw=0.3819, running_loss=0.3567, LR=0.000100
[2025-08-11 03:32:43,655][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107520] [Batch 00452/03692] [00:04:00/00:28:44, 0.532s/it]: train_loss_raw=0.3895, running_loss=0.3567, LR=0.000100
[2025-08-11 03:32:49,980][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107532] [Batch 00464/03692] [00:04:06/00:28:37, 0.532s/it]: train_loss_raw=0.4120, running_loss=0.3559, LR=0.000100
[2025-08-11 03:32:56,384][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107544] [Batch 00476/03692] [00:04:13/00:28:31, 0.532s/it]: train_loss_raw=0.3419, running_loss=0.3569, LR=0.000100
[2025-08-11 03:33:02,724][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107556] [Batch 00488/03692] [00:04:19/00:28:24, 0.532s/it]: train_loss_raw=0.4470, running_loss=0.3590, LR=0.000100
[2025-08-11 03:33:09,090][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107568] [Batch 00500/03692] [00:04:25/00:28:18, 0.532s/it]: train_loss_raw=0.4784, running_loss=0.3607, LR=0.000100
[2025-08-11 03:33:15,416][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107580] [Batch 00512/03692] [00:04:32/00:28:11, 0.532s/it]: train_loss_raw=0.3950, running_loss=0.3581, LR=0.000100
[2025-08-11 03:33:21,705][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107592] [Batch 00524/03692] [00:04:38/00:28:04, 0.532s/it]: train_loss_raw=0.3847, running_loss=0.3586, LR=0.000100
[2025-08-11 03:33:28,045][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107604] [Batch 00536/03692] [00:04:44/00:27:57, 0.532s/it]: train_loss_raw=0.2956, running_loss=0.3584, LR=0.000100
[2025-08-11 03:33:34,366][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107616] [Batch 00548/03692] [00:04:51/00:27:51, 0.532s/it]: train_loss_raw=0.4290, running_loss=0.3632, LR=0.000100
[2025-08-11 03:33:40,794][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107628] [Batch 00560/03692] [00:04:57/00:27:44, 0.532s/it]: train_loss_raw=0.2983, running_loss=0.3643, LR=0.000100
[2025-08-11 03:33:47,171][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107640] [Batch 00572/03692] [00:05:04/00:27:38, 0.532s/it]: train_loss_raw=0.3323, running_loss=0.3649, LR=0.000100
[2025-08-11 03:33:53,477][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107652] [Batch 00584/03692] [00:05:10/00:27:31, 0.531s/it]: train_loss_raw=0.2857, running_loss=0.3633, LR=0.000100
[2025-08-11 03:33:59,823][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107664] [Batch 00596/03692] [00:05:16/00:27:25, 0.531s/it]: train_loss_raw=0.4168, running_loss=0.3618, LR=0.000100
[2025-08-11 03:34:06,239][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107676] [Batch 00608/03692] [00:05:23/00:27:19, 0.531s/it]: train_loss_raw=0.3257, running_loss=0.3617, LR=0.000100
[2025-08-11 03:34:12,682][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107688] [Batch 00620/03692] [00:05:29/00:27:13, 0.532s/it]: train_loss_raw=0.3347, running_loss=0.3607, LR=0.000100
[2025-08-11 03:34:19,027][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107700] [Batch 00632/03692] [00:05:35/00:27:06, 0.532s/it]: train_loss_raw=0.3815, running_loss=0.3608, LR=0.000100
[2025-08-11 03:34:25,432][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107712] [Batch 00644/03692] [00:05:42/00:27:00, 0.532s/it]: train_loss_raw=0.3711, running_loss=0.3597, LR=0.000100
[2025-08-11 03:34:31,796][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107724] [Batch 00656/03692] [00:05:48/00:26:53, 0.532s/it]: train_loss_raw=0.1998, running_loss=0.3605, LR=0.000100
[2025-08-11 03:34:38,149][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107736] [Batch 00668/03692] [00:05:55/00:26:47, 0.532s/it]: train_loss_raw=0.3500, running_loss=0.3591, LR=0.000100
[2025-08-11 03:34:44,673][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107748] [Batch 00680/03692] [00:06:01/00:26:41, 0.532s/it]: train_loss_raw=0.3404, running_loss=0.3591, LR=0.000100
[2025-08-11 03:34:51,137][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107760] [Batch 00692/03692] [00:06:08/00:26:35, 0.532s/it]: train_loss_raw=0.3751, running_loss=0.3592, LR=0.000100
[2025-08-11 03:34:57,559][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107772] [Batch 00704/03692] [00:06:14/00:26:29, 0.532s/it]: train_loss_raw=0.3203, running_loss=0.3596, LR=0.000100
[2025-08-11 03:35:03,912][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107784] [Batch 00716/03692] [00:06:20/00:26:22, 0.532s/it]: train_loss_raw=0.3343, running_loss=0.3555, LR=0.000100
[2025-08-11 03:35:10,254][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107796] [Batch 00728/03692] [00:06:27/00:26:16, 0.532s/it]: train_loss_raw=0.3286, running_loss=0.3555, LR=0.000100
[2025-08-11 03:35:16,749][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107808] [Batch 00740/03692] [00:06:33/00:26:10, 0.532s/it]: train_loss_raw=0.3683, running_loss=0.3597, LR=0.000100
[2025-08-11 03:35:23,179][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107820] [Batch 00752/03692] [00:06:40/00:26:04, 0.532s/it]: train_loss_raw=0.3125, running_loss=0.3618, LR=0.000100
[2025-08-11 03:35:29,534][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107832] [Batch 00764/03692] [00:06:46/00:25:57, 0.532s/it]: train_loss_raw=0.4443, running_loss=0.3622, LR=0.000100
[2025-08-11 03:35:35,881][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107844] [Batch 00776/03692] [00:06:52/00:25:51, 0.532s/it]: train_loss_raw=0.2742, running_loss=0.3620, LR=0.000100
[2025-08-11 03:35:42,269][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107856] [Batch 00788/03692] [00:06:59/00:25:44, 0.532s/it]: train_loss_raw=0.2864, running_loss=0.3633, LR=0.000100
[2025-08-11 03:35:48,724][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107868] [Batch 00800/03692] [00:07:05/00:25:38, 0.532s/it]: train_loss_raw=0.3300, running_loss=0.3604, LR=0.000100
[2025-08-11 03:35:55,105][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107880] [Batch 00812/03692] [00:07:12/00:25:32, 0.532s/it]: train_loss_raw=0.4388, running_loss=0.3610, LR=0.000100
[2025-08-11 03:36:01,433][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107892] [Batch 00824/03692] [00:07:18/00:25:25, 0.532s/it]: train_loss_raw=0.3897, running_loss=0.3603, LR=0.000100
[2025-08-11 03:36:07,830][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107904] [Batch 00836/03692] [00:07:24/00:25:19, 0.532s/it]: train_loss_raw=0.4335, running_loss=0.3626, LR=0.000100
[2025-08-11 03:36:14,190][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107916] [Batch 00848/03692] [00:07:31/00:25:12, 0.532s/it]: train_loss_raw=0.4135, running_loss=0.3618, LR=0.000100
[2025-08-11 03:36:20,614][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107928] [Batch 00860/03692] [00:07:37/00:25:06, 0.532s/it]: train_loss_raw=0.3329, running_loss=0.3635, LR=0.000100
[2025-08-11 03:36:26,972][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107940] [Batch 00872/03692] [00:07:43/00:25:00, 0.532s/it]: train_loss_raw=0.4175, running_loss=0.3634, LR=0.000100
[2025-08-11 03:36:33,307][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107952] [Batch 00884/03692] [00:07:50/00:24:53, 0.532s/it]: train_loss_raw=0.3588, running_loss=0.3616, LR=0.000100
[2025-08-11 03:36:39,707][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107964] [Batch 00896/03692] [00:07:56/00:24:47, 0.532s/it]: train_loss_raw=0.3818, running_loss=0.3609, LR=0.000100
[2025-08-11 03:36:46,148][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107976] [Batch 00908/03692] [00:08:03/00:24:41, 0.532s/it]: train_loss_raw=0.3493, running_loss=0.3620, LR=0.000100
[2025-08-11 03:36:52,486][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 107988] [Batch 00920/03692] [00:08:09/00:24:34, 0.532s/it]: train_loss_raw=0.3612, running_loss=0.3627, LR=0.000100
[2025-08-11 03:36:58,869][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108000] [Batch 00932/03692] [00:08:15/00:24:28, 0.532s/it]: train_loss_raw=0.3977, running_loss=0.3612, LR=0.000100
[2025-08-11 03:37:10,493][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108012] [Batch 00944/03692] [00:08:27/00:24:37, 0.537s/it]: train_loss_raw=0.3272, running_loss=0.3614, LR=0.000100
[2025-08-11 03:37:17,025][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108024] [Batch 00956/03692] [00:08:33/00:24:30, 0.538s/it]: train_loss_raw=0.3134, running_loss=0.3618, LR=0.000100
[2025-08-11 03:37:23,427][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108036] [Batch 00968/03692] [00:08:40/00:24:24, 0.538s/it]: train_loss_raw=0.3513, running_loss=0.3655, LR=0.000100
[2025-08-11 03:37:29,833][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108048] [Batch 00980/03692] [00:08:46/00:24:17, 0.537s/it]: train_loss_raw=0.4001, running_loss=0.3656, LR=0.000100
[2025-08-11 03:37:36,274][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108060] [Batch 00992/03692] [00:08:53/00:24:11, 0.537s/it]: train_loss_raw=0.3467, running_loss=0.3623, LR=0.000100
[2025-08-11 03:37:42,688][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108072] [Batch 01004/03692] [00:08:59/00:24:04, 0.537s/it]: train_loss_raw=0.3219, running_loss=0.3601, LR=0.000100
[2025-08-11 03:37:49,109][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108084] [Batch 01016/03692] [00:09:06/00:23:58, 0.537s/it]: train_loss_raw=0.4122, running_loss=0.3602, LR=0.000100
[2025-08-11 03:37:55,484][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108096] [Batch 01028/03692] [00:09:12/00:23:51, 0.537s/it]: train_loss_raw=0.3103, running_loss=0.3589, LR=0.000100
[2025-08-11 03:38:01,817][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108108] [Batch 01040/03692] [00:09:18/00:23:44, 0.537s/it]: train_loss_raw=0.3594, running_loss=0.3581, LR=0.000100
[2025-08-11 03:38:08,187][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108120] [Batch 01052/03692] [00:09:25/00:23:38, 0.537s/it]: train_loss_raw=0.4313, running_loss=0.3599, LR=0.000100
[2025-08-11 03:38:14,583][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108132] [Batch 01064/03692] [00:09:31/00:23:31, 0.537s/it]: train_loss_raw=0.2539, running_loss=0.3582, LR=0.000100
[2025-08-11 03:38:20,918][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108144] [Batch 01076/03692] [00:09:37/00:23:24, 0.537s/it]: train_loss_raw=0.2624, running_loss=0.3575, LR=0.000100
[2025-08-11 03:38:27,286][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108156] [Batch 01088/03692] [00:09:44/00:23:18, 0.537s/it]: train_loss_raw=0.4178, running_loss=0.3619, LR=0.000100
[2025-08-11 03:38:33,644][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108168] [Batch 01100/03692] [00:09:50/00:23:11, 0.537s/it]: train_loss_raw=0.3558, running_loss=0.3632, LR=0.000100
[2025-08-11 03:38:40,047][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108180] [Batch 01112/03692] [00:09:56/00:23:05, 0.537s/it]: train_loss_raw=0.4313, running_loss=0.3621, LR=0.000100
[2025-08-11 03:38:46,633][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108192] [Batch 01124/03692] [00:10:03/00:22:58, 0.537s/it]: train_loss_raw=0.3205, running_loss=0.3635, LR=0.000100
[2025-08-11 03:38:53,095][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108204] [Batch 01136/03692] [00:10:09/00:22:52, 0.537s/it]: train_loss_raw=0.3675, running_loss=0.3615, LR=0.000100
[2025-08-11 03:38:59,575][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108216] [Batch 01148/03692] [00:10:16/00:22:46, 0.537s/it]: train_loss_raw=0.6630, running_loss=0.3618, LR=0.000100
[2025-08-11 03:39:06,168][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108228] [Batch 01160/03692] [00:10:23/00:22:40, 0.537s/it]: train_loss_raw=0.3362, running_loss=0.3583, LR=0.000100
[2025-08-11 03:39:12,618][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108240] [Batch 01172/03692] [00:10:29/00:22:33, 0.537s/it]: train_loss_raw=0.3546, running_loss=0.3567, LR=0.000100
[2025-08-11 03:39:19,145][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108252] [Batch 01184/03692] [00:10:36/00:22:27, 0.537s/it]: train_loss_raw=0.4001, running_loss=0.3550, LR=0.000100
[2025-08-11 03:39:25,641][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108264] [Batch 01196/03692] [00:10:42/00:22:20, 0.537s/it]: train_loss_raw=0.3818, running_loss=0.3540, LR=0.000100
[2025-08-11 03:39:32,133][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108276] [Batch 01208/03692] [00:10:49/00:22:14, 0.537s/it]: train_loss_raw=0.3255, running_loss=0.3530, LR=0.000100
[2025-08-11 03:39:38,638][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108288] [Batch 01220/03692] [00:10:55/00:22:08, 0.537s/it]: train_loss_raw=0.3176, running_loss=0.3547, LR=0.000100
[2025-08-11 03:39:45,118][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108300] [Batch 01232/03692] [00:11:02/00:22:01, 0.537s/it]: train_loss_raw=0.3771, running_loss=0.3560, LR=0.000100
[2025-08-11 03:39:51,598][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108312] [Batch 01244/03692] [00:11:08/00:21:55, 0.537s/it]: train_loss_raw=0.3778, running_loss=0.3580, LR=0.000100
[2025-08-11 03:39:58,076][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108324] [Batch 01256/03692] [00:11:14/00:21:49, 0.537s/it]: train_loss_raw=0.3664, running_loss=0.3597, LR=0.000100
[2025-08-11 03:40:04,591][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108336] [Batch 01268/03692] [00:11:21/00:21:42, 0.537s/it]: train_loss_raw=0.3151, running_loss=0.3561, LR=0.000100
[2025-08-11 03:40:11,067][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108348] [Batch 01280/03692] [00:11:27/00:21:36, 0.537s/it]: train_loss_raw=0.3398, running_loss=0.3549, LR=0.000100
[2025-08-11 03:40:17,348][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108360] [Batch 01292/03692] [00:11:34/00:21:29, 0.537s/it]: train_loss_raw=0.3442, running_loss=0.3565, LR=0.000100
[2025-08-11 03:40:23,800][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108372] [Batch 01304/03692] [00:11:40/00:21:23, 0.537s/it]: train_loss_raw=0.3289, running_loss=0.3555, LR=0.000100
[2025-08-11 03:40:30,228][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108384] [Batch 01316/03692] [00:11:47/00:21:16, 0.537s/it]: train_loss_raw=0.3832, running_loss=0.3566, LR=0.000100
[2025-08-11 03:40:36,723][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108396] [Batch 01328/03692] [00:11:53/00:21:10, 0.537s/it]: train_loss_raw=0.3529, running_loss=0.3589, LR=0.000100
[2025-08-11 03:40:43,292][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108408] [Batch 01340/03692] [00:12:00/00:21:04, 0.537s/it]: train_loss_raw=0.3197, running_loss=0.3574, LR=0.000100
[2025-08-11 03:40:49,757][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108420] [Batch 01352/03692] [00:12:06/00:20:57, 0.537s/it]: train_loss_raw=0.3251, running_loss=0.3551, LR=0.000100
[2025-08-11 03:40:56,288][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108432] [Batch 01364/03692] [00:12:13/00:20:51, 0.538s/it]: train_loss_raw=0.3783, running_loss=0.3549, LR=0.000100
[2025-08-11 03:41:02,787][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108444] [Batch 01376/03692] [00:12:19/00:20:45, 0.538s/it]: train_loss_raw=0.3072, running_loss=0.3524, LR=0.000100
[2025-08-11 03:41:09,300][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108456] [Batch 01388/03692] [00:12:26/00:20:38, 0.538s/it]: train_loss_raw=0.3821, running_loss=0.3533, LR=0.000100
[2025-08-11 03:41:15,670][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108468] [Batch 01400/03692] [00:12:32/00:20:32, 0.538s/it]: train_loss_raw=0.3184, running_loss=0.3578, LR=0.000100
[2025-08-11 03:41:22,118][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108480] [Batch 01412/03692] [00:12:39/00:20:25, 0.538s/it]: train_loss_raw=0.3630, running_loss=0.3579, LR=0.000100
[2025-08-11 03:41:28,731][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108492] [Batch 01424/03692] [00:12:45/00:20:19, 0.538s/it]: train_loss_raw=0.3064, running_loss=0.3581, LR=0.000100
[2025-08-11 03:41:35,268][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108504] [Batch 01436/03692] [00:12:52/00:20:13, 0.538s/it]: train_loss_raw=0.2727, running_loss=0.3573, LR=0.000100
[2025-08-11 03:41:41,778][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108516] [Batch 01448/03692] [00:12:58/00:20:06, 0.538s/it]: train_loss_raw=0.3532, running_loss=0.3591, LR=0.000100
[2025-08-11 03:41:48,269][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108528] [Batch 01460/03692] [00:13:05/00:20:00, 0.538s/it]: train_loss_raw=0.4234, running_loss=0.3556, LR=0.000100
[2025-08-11 03:41:54,761][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108540] [Batch 01472/03692] [00:13:11/00:19:53, 0.538s/it]: train_loss_raw=0.3411, running_loss=0.3588, LR=0.000100
[2025-08-11 03:42:01,255][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108552] [Batch 01484/03692] [00:13:18/00:19:47, 0.538s/it]: train_loss_raw=0.3447, running_loss=0.3587, LR=0.000100
[2025-08-11 03:42:07,549][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108564] [Batch 01496/03692] [00:13:24/00:19:40, 0.538s/it]: train_loss_raw=0.3217, running_loss=0.3590, LR=0.000100
[2025-08-11 03:42:13,932][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108576] [Batch 01508/03692] [00:13:30/00:19:34, 0.538s/it]: train_loss_raw=0.3740, running_loss=0.3580, LR=0.000100
[2025-08-11 03:42:20,262][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108588] [Batch 01520/03692] [00:13:37/00:19:27, 0.538s/it]: train_loss_raw=0.3736, running_loss=0.3600, LR=0.000100
[2025-08-11 03:42:26,704][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108600] [Batch 01532/03692] [00:13:43/00:19:21, 0.538s/it]: train_loss_raw=0.2982, running_loss=0.3574, LR=0.000100
[2025-08-11 03:42:33,238][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108612] [Batch 01544/03692] [00:13:50/00:19:14, 0.538s/it]: train_loss_raw=0.3442, running_loss=0.3541, LR=0.000100
[2025-08-11 03:42:39,638][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108624] [Batch 01556/03692] [00:13:56/00:19:08, 0.538s/it]: train_loss_raw=0.3259, running_loss=0.3512, LR=0.000100
[2025-08-11 03:42:46,014][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108636] [Batch 01568/03692] [00:14:02/00:19:01, 0.538s/it]: train_loss_raw=0.3426, running_loss=0.3526, LR=0.000100
[2025-08-11 03:42:52,429][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108648] [Batch 01580/03692] [00:14:09/00:18:55, 0.538s/it]: train_loss_raw=0.3336, running_loss=0.3519, LR=0.000100
[2025-08-11 03:42:58,862][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108660] [Batch 01592/03692] [00:14:15/00:18:48, 0.538s/it]: train_loss_raw=0.3501, running_loss=0.3525, LR=0.000100
[2025-08-11 03:43:05,197][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108672] [Batch 01604/03692] [00:14:22/00:18:42, 0.537s/it]: train_loss_raw=0.3434, running_loss=0.3531, LR=0.000100
[2025-08-11 03:43:11,569][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108684] [Batch 01616/03692] [00:14:28/00:18:35, 0.537s/it]: train_loss_raw=0.4169, running_loss=0.3511, LR=0.000100
[2025-08-11 03:43:17,983][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108696] [Batch 01628/03692] [00:14:34/00:18:29, 0.537s/it]: train_loss_raw=0.2990, running_loss=0.3522, LR=0.000100
[2025-08-11 03:43:24,373][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108708] [Batch 01640/03692] [00:14:41/00:18:22, 0.537s/it]: train_loss_raw=0.3151, running_loss=0.3531, LR=0.000100
[2025-08-11 03:43:30,752][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108720] [Batch 01652/03692] [00:14:47/00:18:16, 0.537s/it]: train_loss_raw=0.3277, running_loss=0.3541, LR=0.000100
[2025-08-11 03:43:37,124][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108732] [Batch 01664/03692] [00:14:54/00:18:09, 0.537s/it]: train_loss_raw=0.3176, running_loss=0.3559, LR=0.000100
[2025-08-11 03:43:43,508][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108744] [Batch 01676/03692] [00:15:00/00:18:03, 0.537s/it]: train_loss_raw=0.3346, running_loss=0.3573, LR=0.000100
[2025-08-11 03:43:49,816][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108756] [Batch 01688/03692] [00:15:06/00:17:56, 0.537s/it]: train_loss_raw=0.3299, running_loss=0.3573, LR=0.000100
[2025-08-11 03:43:56,164][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108768] [Batch 01700/03692] [00:15:13/00:17:49, 0.537s/it]: train_loss_raw=0.3101, running_loss=0.3564, LR=0.000100
[2025-08-11 03:44:02,563][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108780] [Batch 01712/03692] [00:15:19/00:17:43, 0.537s/it]: train_loss_raw=0.3272, running_loss=0.3561, LR=0.000100
[2025-08-11 03:44:08,918][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108792] [Batch 01724/03692] [00:15:25/00:17:36, 0.537s/it]: train_loss_raw=0.3624, running_loss=0.3565, LR=0.000100
[2025-08-11 03:44:15,272][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108804] [Batch 01736/03692] [00:15:32/00:17:30, 0.537s/it]: train_loss_raw=0.3795, running_loss=0.3557, LR=0.000100
[2025-08-11 03:44:21,624][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108816] [Batch 01748/03692] [00:15:38/00:17:23, 0.537s/it]: train_loss_raw=0.2659, running_loss=0.3538, LR=0.000100
[2025-08-11 03:44:27,995][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108828] [Batch 01760/03692] [00:15:44/00:17:17, 0.537s/it]: train_loss_raw=0.3653, running_loss=0.3545, LR=0.000100
[2025-08-11 03:44:34,402][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108840] [Batch 01772/03692] [00:15:51/00:17:10, 0.537s/it]: train_loss_raw=0.4039, running_loss=0.3574, LR=0.000100
[2025-08-11 03:44:40,945][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108852] [Batch 01784/03692] [00:15:57/00:17:04, 0.537s/it]: train_loss_raw=0.4412, running_loss=0.3568, LR=0.000100
[2025-08-11 03:44:47,372][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108864] [Batch 01796/03692] [00:16:04/00:16:57, 0.537s/it]: train_loss_raw=0.3729, running_loss=0.3553, LR=0.000100
[2025-08-11 03:44:53,812][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108876] [Batch 01808/03692] [00:16:10/00:16:51, 0.537s/it]: train_loss_raw=0.3737, running_loss=0.3563, LR=0.000100
[2025-08-11 03:45:00,184][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108888] [Batch 01820/03692] [00:16:17/00:16:45, 0.537s/it]: train_loss_raw=0.4650, running_loss=0.3571, LR=0.000100
[2025-08-11 03:45:06,657][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108900] [Batch 01832/03692] [00:16:23/00:16:38, 0.537s/it]: train_loss_raw=0.3853, running_loss=0.3594, LR=0.000100
[2025-08-11 03:45:13,002][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108912] [Batch 01844/03692] [00:16:29/00:16:32, 0.537s/it]: train_loss_raw=0.4407, running_loss=0.3609, LR=0.000100
[2025-08-11 03:45:19,275][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108924] [Batch 01856/03692] [00:16:36/00:16:25, 0.537s/it]: train_loss_raw=0.3726, running_loss=0.3590, LR=0.000100
[2025-08-11 03:45:25,513][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108936] [Batch 01868/03692] [00:16:42/00:16:18, 0.537s/it]: train_loss_raw=0.3580, running_loss=0.3594, LR=0.000100
[2025-08-11 03:45:31,756][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108948] [Batch 01880/03692] [00:16:48/00:16:12, 0.537s/it]: train_loss_raw=0.3415, running_loss=0.3585, LR=0.000100
[2025-08-11 03:45:37,940][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108960] [Batch 01892/03692] [00:16:54/00:16:05, 0.536s/it]: train_loss_raw=0.3977, running_loss=0.3590, LR=0.000100
[2025-08-11 03:45:44,300][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108972] [Batch 01904/03692] [00:17:01/00:15:58, 0.536s/it]: train_loss_raw=0.3934, running_loss=0.3593, LR=0.000100
[2025-08-11 03:45:50,791][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108984] [Batch 01916/03692] [00:17:07/00:15:52, 0.536s/it]: train_loss_raw=0.3892, running_loss=0.3570, LR=0.000100
[2025-08-11 03:45:57,208][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 108996] [Batch 01928/03692] [00:17:14/00:15:46, 0.536s/it]: train_loss_raw=0.4321, running_loss=0.3580, LR=0.000100
[2025-08-11 03:46:03,586][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109008] [Batch 01940/03692] [00:17:20/00:15:39, 0.536s/it]: train_loss_raw=0.3636, running_loss=0.3581, LR=0.000100
[2025-08-11 03:46:09,989][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109020] [Batch 01952/03692] [00:17:26/00:15:33, 0.536s/it]: train_loss_raw=0.2865, running_loss=0.3587, LR=0.000100
[2025-08-11 03:46:16,436][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109032] [Batch 01964/03692] [00:17:33/00:15:26, 0.536s/it]: train_loss_raw=0.2506, running_loss=0.3586, LR=0.000100
[2025-08-11 03:46:22,920][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109044] [Batch 01976/03692] [00:17:39/00:15:20, 0.536s/it]: train_loss_raw=0.2709, running_loss=0.3552, LR=0.000100
[2025-08-11 03:46:29,385][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109056] [Batch 01988/03692] [00:17:46/00:15:13, 0.536s/it]: train_loss_raw=0.3003, running_loss=0.3545, LR=0.000100
[2025-08-11 03:46:35,849][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109068] [Batch 02000/03692] [00:17:52/00:15:07, 0.536s/it]: train_loss_raw=0.3284, running_loss=0.3563, LR=0.000100
[2025-08-11 03:46:42,392][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109080] [Batch 02012/03692] [00:17:59/00:15:01, 0.536s/it]: train_loss_raw=0.4429, running_loss=0.3599, LR=0.000100
[2025-08-11 03:46:48,866][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109092] [Batch 02024/03692] [00:18:05/00:14:54, 0.536s/it]: train_loss_raw=0.2583, running_loss=0.3579, LR=0.000100
[2025-08-11 03:46:55,217][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109104] [Batch 02036/03692] [00:18:12/00:14:48, 0.536s/it]: train_loss_raw=0.3647, running_loss=0.3610, LR=0.000100
[2025-08-11 03:47:01,598][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109116] [Batch 02048/03692] [00:18:18/00:14:41, 0.536s/it]: train_loss_raw=0.4243, running_loss=0.3611, LR=0.000100
[2025-08-11 03:47:08,063][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109128] [Batch 02060/03692] [00:18:24/00:14:35, 0.536s/it]: train_loss_raw=0.3898, running_loss=0.3627, LR=0.000100
[2025-08-11 03:47:14,437][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109140] [Batch 02072/03692] [00:18:31/00:14:28, 0.536s/it]: train_loss_raw=0.3651, running_loss=0.3608, LR=0.000100
[2025-08-11 03:47:20,807][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109152] [Batch 02084/03692] [00:18:37/00:14:22, 0.536s/it]: train_loss_raw=0.3668, running_loss=0.3593, LR=0.000100
[2025-08-11 03:47:27,175][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109164] [Batch 02096/03692] [00:18:44/00:14:15, 0.536s/it]: train_loss_raw=0.3491, running_loss=0.3616, LR=0.000100
[2025-08-11 03:47:33,559][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109176] [Batch 02108/03692] [00:18:50/00:14:09, 0.536s/it]: train_loss_raw=0.4288, running_loss=0.3602, LR=0.000100
[2025-08-11 03:47:39,928][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109188] [Batch 02120/03692] [00:18:56/00:14:02, 0.536s/it]: train_loss_raw=0.3762, running_loss=0.3590, LR=0.000100
[2025-08-11 03:47:46,377][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109200] [Batch 02132/03692] [00:19:03/00:13:56, 0.536s/it]: train_loss_raw=0.3231, running_loss=0.3566, LR=0.000100
[2025-08-11 03:47:52,786][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109212] [Batch 02144/03692] [00:19:09/00:13:50, 0.536s/it]: train_loss_raw=0.4310, running_loss=0.3606, LR=0.000100
[2025-08-11 03:47:59,171][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109224] [Batch 02156/03692] [00:19:16/00:13:43, 0.536s/it]: train_loss_raw=0.3812, running_loss=0.3596, LR=0.000100
[2025-08-11 03:48:05,586][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109236] [Batch 02168/03692] [00:19:22/00:13:37, 0.536s/it]: train_loss_raw=0.3211, running_loss=0.3562, LR=0.000100
[2025-08-11 03:48:12,005][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109248] [Batch 02180/03692] [00:19:28/00:13:30, 0.536s/it]: train_loss_raw=0.3229, running_loss=0.3586, LR=0.000100
[2025-08-11 03:48:18,362][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109260] [Batch 02192/03692] [00:19:35/00:13:24, 0.536s/it]: train_loss_raw=0.3107, running_loss=0.3566, LR=0.000100
[2025-08-11 03:48:24,819][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109272] [Batch 02204/03692] [00:19:41/00:13:17, 0.536s/it]: train_loss_raw=0.3316, running_loss=0.3543, LR=0.000100
[2025-08-11 03:48:31,377][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109284] [Batch 02216/03692] [00:19:48/00:13:11, 0.536s/it]: train_loss_raw=0.3386, running_loss=0.3539, LR=0.000100
[2025-08-11 03:48:37,840][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109296] [Batch 02228/03692] [00:19:54/00:13:05, 0.536s/it]: train_loss_raw=0.4015, running_loss=0.3564, LR=0.000100
[2025-08-11 03:48:44,243][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109308] [Batch 02240/03692] [00:20:01/00:12:58, 0.536s/it]: train_loss_raw=0.3164, running_loss=0.3559, LR=0.000100
[2025-08-11 03:48:50,633][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109320] [Batch 02252/03692] [00:20:07/00:12:52, 0.536s/it]: train_loss_raw=0.3792, running_loss=0.3576, LR=0.000100
[2025-08-11 03:48:56,932][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109332] [Batch 02264/03692] [00:20:13/00:12:45, 0.536s/it]: train_loss_raw=0.3432, running_loss=0.3588, LR=0.000100
[2025-08-11 03:49:03,318][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109344] [Batch 02276/03692] [00:20:20/00:12:39, 0.536s/it]: train_loss_raw=0.2964, running_loss=0.3552, LR=0.000100
[2025-08-11 03:49:09,709][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109356] [Batch 02288/03692] [00:20:26/00:12:32, 0.536s/it]: train_loss_raw=0.3154, running_loss=0.3562, LR=0.000100
[2025-08-11 03:49:16,100][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109368] [Batch 02300/03692] [00:20:33/00:12:26, 0.536s/it]: train_loss_raw=0.3739, running_loss=0.3580, LR=0.000100
[2025-08-11 03:49:22,493][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109380] [Batch 02312/03692] [00:20:39/00:12:19, 0.536s/it]: train_loss_raw=0.3023, running_loss=0.3566, LR=0.000100
[2025-08-11 03:49:28,884][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109392] [Batch 02324/03692] [00:20:45/00:12:13, 0.536s/it]: train_loss_raw=0.3989, running_loss=0.3571, LR=0.000100
[2025-08-11 03:49:35,363][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109404] [Batch 02336/03692] [00:20:52/00:12:06, 0.536s/it]: train_loss_raw=0.2405, running_loss=0.3566, LR=0.000100
[2025-08-11 03:49:41,830][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109416] [Batch 02348/03692] [00:20:58/00:12:00, 0.536s/it]: train_loss_raw=0.3406, running_loss=0.3556, LR=0.000100
[2025-08-11 03:49:48,237][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109428] [Batch 02360/03692] [00:21:05/00:11:54, 0.536s/it]: train_loss_raw=0.4153, running_loss=0.3570, LR=0.000100
[2025-08-11 03:49:54,668][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109440] [Batch 02372/03692] [00:21:11/00:11:47, 0.536s/it]: train_loss_raw=0.3307, running_loss=0.3556, LR=0.000100
[2025-08-11 03:50:01,111][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109452] [Batch 02384/03692] [00:21:18/00:11:41, 0.536s/it]: train_loss_raw=0.3761, running_loss=0.3594, LR=0.000100
[2025-08-11 03:50:07,568][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109464] [Batch 02396/03692] [00:21:24/00:11:34, 0.536s/it]: train_loss_raw=0.2809, running_loss=0.3579, LR=0.000100
[2025-08-11 03:50:13,948][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109476] [Batch 02408/03692] [00:21:30/00:11:28, 0.536s/it]: train_loss_raw=0.4223, running_loss=0.3589, LR=0.000100
[2025-08-11 03:50:20,325][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109488] [Batch 02420/03692] [00:21:37/00:11:21, 0.536s/it]: train_loss_raw=0.3410, running_loss=0.3585, LR=0.000100
[2025-08-11 03:50:26,648][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109500] [Batch 02432/03692] [00:21:43/00:11:15, 0.536s/it]: train_loss_raw=0.3259, running_loss=0.3612, LR=0.000100
[2025-08-11 03:50:33,073][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109512] [Batch 02444/03692] [00:21:49/00:11:08, 0.536s/it]: train_loss_raw=0.2998, running_loss=0.3569, LR=0.000100
[2025-08-11 03:50:39,533][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109524] [Batch 02456/03692] [00:21:56/00:11:02, 0.536s/it]: train_loss_raw=0.3228, running_loss=0.3554, LR=0.000100
[2025-08-11 03:50:45,873][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109536] [Batch 02468/03692] [00:22:02/00:10:56, 0.536s/it]: train_loss_raw=0.3008, running_loss=0.3572, LR=0.000100
[2025-08-11 03:50:52,257][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109548] [Batch 02480/03692] [00:22:09/00:10:49, 0.536s/it]: train_loss_raw=0.4186, running_loss=0.3555, LR=0.000100
[2025-08-11 03:50:58,669][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109560] [Batch 02492/03692] [00:22:15/00:10:43, 0.536s/it]: train_loss_raw=0.2836, running_loss=0.3574, LR=0.000100
[2025-08-11 03:51:05,134][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109572] [Batch 02504/03692] [00:22:22/00:10:36, 0.536s/it]: train_loss_raw=0.3999, running_loss=0.3585, LR=0.000100
[2025-08-11 03:51:11,537][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109584] [Batch 02516/03692] [00:22:28/00:10:30, 0.536s/it]: train_loss_raw=0.4136, running_loss=0.3603, LR=0.000100
[2025-08-11 03:51:17,848][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109596] [Batch 02528/03692] [00:22:34/00:10:23, 0.536s/it]: train_loss_raw=0.3140, running_loss=0.3566, LR=0.000100
[2025-08-11 03:51:24,243][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109608] [Batch 02540/03692] [00:22:41/00:10:17, 0.536s/it]: train_loss_raw=0.3260, running_loss=0.3565, LR=0.000100
[2025-08-11 03:51:30,723][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109620] [Batch 02552/03692] [00:22:47/00:10:10, 0.536s/it]: train_loss_raw=0.2731, running_loss=0.3548, LR=0.000100
[2025-08-11 03:51:37,090][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109632] [Batch 02564/03692] [00:22:53/00:10:04, 0.536s/it]: train_loss_raw=0.2690, running_loss=0.3529, LR=0.000100
[2025-08-11 03:51:43,452][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109644] [Batch 02576/03692] [00:23:00/00:09:58, 0.536s/it]: train_loss_raw=0.3694, running_loss=0.3531, LR=0.000100
[2025-08-11 03:51:49,792][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109656] [Batch 02588/03692] [00:23:06/00:09:51, 0.536s/it]: train_loss_raw=0.3272, running_loss=0.3520, LR=0.000100
[2025-08-11 03:51:56,190][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109668] [Batch 02600/03692] [00:23:13/00:09:45, 0.536s/it]: train_loss_raw=0.4383, running_loss=0.3520, LR=0.000100
[2025-08-11 03:52:02,490][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109680] [Batch 02612/03692] [00:23:19/00:09:38, 0.536s/it]: train_loss_raw=0.4332, running_loss=0.3556, LR=0.000100
[2025-08-11 03:52:08,830][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109692] [Batch 02624/03692] [00:23:25/00:09:32, 0.536s/it]: train_loss_raw=0.3955, running_loss=0.3584, LR=0.000100
[2025-08-11 03:52:15,180][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109704] [Batch 02636/03692] [00:23:32/00:09:25, 0.536s/it]: train_loss_raw=0.2773, running_loss=0.3565, LR=0.000100
[2025-08-11 03:52:21,550][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109716] [Batch 02648/03692] [00:23:38/00:09:19, 0.536s/it]: train_loss_raw=0.4379, running_loss=0.3568, LR=0.000100
[2025-08-11 03:52:27,904][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109728] [Batch 02660/03692] [00:23:44/00:09:12, 0.536s/it]: train_loss_raw=0.3578, running_loss=0.3573, LR=0.000100
[2025-08-11 03:52:34,303][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109740] [Batch 02672/03692] [00:23:51/00:09:06, 0.536s/it]: train_loss_raw=0.3525, running_loss=0.3578, LR=0.000100
[2025-08-11 03:52:40,708][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109752] [Batch 02684/03692] [00:23:57/00:08:59, 0.536s/it]: train_loss_raw=0.4152, running_loss=0.3621, LR=0.000100
[2025-08-11 03:52:47,182][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109764] [Batch 02696/03692] [00:24:04/00:08:53, 0.536s/it]: train_loss_raw=0.3820, running_loss=0.3631, LR=0.000100
[2025-08-11 03:52:53,549][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109776] [Batch 02708/03692] [00:24:10/00:08:47, 0.536s/it]: train_loss_raw=0.3402, running_loss=0.3611, LR=0.000100
[2025-08-11 03:52:59,911][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109788] [Batch 02720/03692] [00:24:16/00:08:40, 0.536s/it]: train_loss_raw=0.2940, running_loss=0.3605, LR=0.000100
[2025-08-11 03:53:06,231][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109800] [Batch 02732/03692] [00:24:23/00:08:34, 0.536s/it]: train_loss_raw=0.4299, running_loss=0.3606, LR=0.000100
[2025-08-11 03:53:12,661][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109812] [Batch 02744/03692] [00:24:29/00:08:27, 0.536s/it]: train_loss_raw=0.3082, running_loss=0.3612, LR=0.000100
[2025-08-11 03:53:19,003][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109824] [Batch 02756/03692] [00:24:35/00:08:21, 0.536s/it]: train_loss_raw=0.2899, running_loss=0.3584, LR=0.000100
[2025-08-11 03:53:25,521][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109836] [Batch 02768/03692] [00:24:42/00:08:14, 0.536s/it]: train_loss_raw=0.3853, running_loss=0.3594, LR=0.000100
[2025-08-11 03:53:31,994][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109848] [Batch 02780/03692] [00:24:48/00:08:08, 0.536s/it]: train_loss_raw=0.3106, running_loss=0.3579, LR=0.000100
[2025-08-11 03:53:38,598][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109860] [Batch 02792/03692] [00:24:55/00:08:02, 0.536s/it]: train_loss_raw=0.4400, running_loss=0.3594, LR=0.000100
[2025-08-11 03:53:44,828][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109872] [Batch 02804/03692] [00:25:01/00:07:55, 0.536s/it]: train_loss_raw=0.3564, running_loss=0.3579, LR=0.000100
[2025-08-11 03:53:50,915][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109884] [Batch 02816/03692] [00:25:07/00:07:49, 0.535s/it]: train_loss_raw=0.2677, running_loss=0.3562, LR=0.000100
[2025-08-11 03:53:57,445][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109896] [Batch 02828/03692] [00:25:14/00:07:42, 0.535s/it]: train_loss_raw=0.4100, running_loss=0.3592, LR=0.000100
[2025-08-11 03:54:03,895][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109908] [Batch 02840/03692] [00:25:20/00:07:36, 0.535s/it]: train_loss_raw=0.4661, running_loss=0.3591, LR=0.000100
[2025-08-11 03:54:10,413][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109920] [Batch 02852/03692] [00:25:27/00:07:29, 0.536s/it]: train_loss_raw=0.2770, running_loss=0.3589, LR=0.000100
[2025-08-11 03:54:16,909][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109932] [Batch 02864/03692] [00:25:33/00:07:23, 0.536s/it]: train_loss_raw=0.3256, running_loss=0.3604, LR=0.000100
[2025-08-11 03:54:23,349][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109944] [Batch 02876/03692] [00:25:40/00:07:17, 0.536s/it]: train_loss_raw=0.3627, running_loss=0.3593, LR=0.000100
[2025-08-11 03:54:29,836][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109956] [Batch 02888/03692] [00:25:46/00:07:10, 0.536s/it]: train_loss_raw=0.4003, running_loss=0.3598, LR=0.000100
[2025-08-11 03:54:36,320][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109968] [Batch 02900/03692] [00:25:53/00:07:04, 0.536s/it]: train_loss_raw=0.3162, running_loss=0.3586, LR=0.000100
[2025-08-11 03:54:42,571][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109980] [Batch 02912/03692] [00:25:59/00:06:57, 0.536s/it]: train_loss_raw=0.3184, running_loss=0.3593, LR=0.000100
[2025-08-11 03:54:48,876][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 109992] [Batch 02924/03692] [00:26:05/00:06:51, 0.535s/it]: train_loss_raw=0.3241, running_loss=0.3590, LR=0.000100
[2025-08-11 03:54:59,797][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110004] [Batch 02936/03692] [00:26:16/00:06:45, 0.537s/it]: train_loss_raw=0.3104, running_loss=0.3573, LR=0.000100
[2025-08-11 03:55:06,207][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110016] [Batch 02948/03692] [00:26:23/00:06:39, 0.537s/it]: train_loss_raw=0.4619, running_loss=0.3607, LR=0.000100
[2025-08-11 03:55:12,684][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110028] [Batch 02960/03692] [00:26:29/00:06:33, 0.537s/it]: train_loss_raw=0.3118, running_loss=0.3583, LR=0.000100
[2025-08-11 03:55:19,097][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110040] [Batch 02972/03692] [00:26:35/00:06:26, 0.537s/it]: train_loss_raw=0.3184, running_loss=0.3550, LR=0.000100
[2025-08-11 03:55:25,596][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110052] [Batch 02984/03692] [00:26:42/00:06:20, 0.537s/it]: train_loss_raw=0.3109, running_loss=0.3562, LR=0.000100
[2025-08-11 03:55:32,177][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110064] [Batch 02996/03692] [00:26:49/00:06:13, 0.537s/it]: train_loss_raw=0.2494, running_loss=0.3545, LR=0.000100
[2025-08-11 03:55:38,551][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110076] [Batch 03008/03692] [00:26:55/00:06:07, 0.537s/it]: train_loss_raw=0.2602, running_loss=0.3540, LR=0.000100
[2025-08-11 03:55:44,942][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110088] [Batch 03020/03692] [00:27:01/00:06:00, 0.537s/it]: train_loss_raw=0.3784, running_loss=0.3538, LR=0.000100
[2025-08-11 03:55:51,508][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110100] [Batch 03032/03692] [00:27:08/00:05:54, 0.537s/it]: train_loss_raw=0.2686, running_loss=0.3542, LR=0.000100
[2025-08-11 03:55:58,136][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110112] [Batch 03044/03692] [00:27:15/00:05:48, 0.537s/it]: train_loss_raw=0.3331, running_loss=0.3564, LR=0.000100
[2025-08-11 03:56:04,357][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110124] [Batch 03056/03692] [00:27:21/00:05:41, 0.537s/it]: train_loss_raw=0.3781, running_loss=0.3568, LR=0.000100
[2025-08-11 03:56:10,665][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110136] [Batch 03068/03692] [00:27:27/00:05:35, 0.537s/it]: train_loss_raw=0.3000, running_loss=0.3566, LR=0.000100
[2025-08-11 03:56:17,069][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110148] [Batch 03080/03692] [00:27:33/00:05:28, 0.537s/it]: train_loss_raw=0.4205, running_loss=0.3561, LR=0.000100
[2025-08-11 03:56:23,394][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110160] [Batch 03092/03692] [00:27:40/00:05:22, 0.537s/it]: train_loss_raw=0.3337, running_loss=0.3552, LR=0.000100
[2025-08-11 03:56:29,796][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110172] [Batch 03104/03692] [00:27:46/00:05:15, 0.537s/it]: train_loss_raw=0.4507, running_loss=0.3566, LR=0.000100
[2025-08-11 03:56:36,196][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110184] [Batch 03116/03692] [00:27:53/00:05:09, 0.537s/it]: train_loss_raw=0.3727, running_loss=0.3562, LR=0.000100
[2025-08-11 03:56:42,580][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110196] [Batch 03128/03692] [00:27:59/00:05:02, 0.537s/it]: train_loss_raw=0.3471, running_loss=0.3542, LR=0.000100
[2025-08-11 03:56:49,009][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110208] [Batch 03140/03692] [00:28:05/00:04:56, 0.537s/it]: train_loss_raw=0.2912, running_loss=0.3559, LR=0.000100
[2025-08-11 03:56:55,546][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110220] [Batch 03152/03692] [00:28:12/00:04:49, 0.537s/it]: train_loss_raw=0.4086, running_loss=0.3562, LR=0.000100
[2025-08-11 03:57:02,131][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110232] [Batch 03164/03692] [00:28:19/00:04:43, 0.537s/it]: train_loss_raw=0.2836, running_loss=0.3549, LR=0.000100
[2025-08-11 03:57:08,677][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110244] [Batch 03176/03692] [00:28:25/00:04:37, 0.537s/it]: train_loss_raw=0.3305, running_loss=0.3570, LR=0.000100
[2025-08-11 03:57:15,205][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110256] [Batch 03188/03692] [00:28:32/00:04:30, 0.537s/it]: train_loss_raw=0.3245, running_loss=0.3571, LR=0.000100
[2025-08-11 03:57:21,652][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110268] [Batch 03200/03692] [00:28:38/00:04:24, 0.537s/it]: train_loss_raw=0.3395, running_loss=0.3580, LR=0.000100
[2025-08-11 03:57:28,004][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110280] [Batch 03212/03692] [00:28:44/00:04:17, 0.537s/it]: train_loss_raw=0.2919, running_loss=0.3569, LR=0.000100
[2025-08-11 03:57:34,355][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110292] [Batch 03224/03692] [00:28:51/00:04:11, 0.537s/it]: train_loss_raw=0.4647, running_loss=0.3560, LR=0.000100
[2025-08-11 03:57:40,841][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110304] [Batch 03236/03692] [00:28:57/00:04:04, 0.537s/it]: train_loss_raw=0.4749, running_loss=0.3580, LR=0.000100
[2025-08-11 03:57:47,357][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110316] [Batch 03248/03692] [00:29:04/00:03:58, 0.537s/it]: train_loss_raw=0.3149, running_loss=0.3581, LR=0.000100
[2025-08-11 03:57:53,810][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110328] [Batch 03260/03692] [00:29:10/00:03:51, 0.537s/it]: train_loss_raw=0.3007, running_loss=0.3592, LR=0.000100
[2025-08-11 03:58:00,321][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110340] [Batch 03272/03692] [00:29:17/00:03:45, 0.537s/it]: train_loss_raw=0.3674, running_loss=0.3573, LR=0.000100
[2025-08-11 03:58:06,700][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110352] [Batch 03284/03692] [00:29:23/00:03:39, 0.537s/it]: train_loss_raw=0.3098, running_loss=0.3548, LR=0.000100
[2025-08-11 03:58:13,060][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110364] [Batch 03296/03692] [00:29:29/00:03:32, 0.537s/it]: train_loss_raw=0.3772, running_loss=0.3539, LR=0.000100
[2025-08-11 03:58:19,411][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110376] [Batch 03308/03692] [00:29:36/00:03:26, 0.537s/it]: train_loss_raw=0.3937, running_loss=0.3536, LR=0.000100
[2025-08-11 03:58:25,828][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110388] [Batch 03320/03692] [00:29:42/00:03:19, 0.537s/it]: train_loss_raw=0.4089, running_loss=0.3541, LR=0.000100
[2025-08-11 03:58:32,247][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110400] [Batch 03332/03692] [00:29:49/00:03:13, 0.537s/it]: train_loss_raw=0.3869, running_loss=0.3530, LR=0.000100
[2025-08-11 03:58:38,686][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110412] [Batch 03344/03692] [00:29:55/00:03:06, 0.537s/it]: train_loss_raw=0.4219, running_loss=0.3545, LR=0.000100
[2025-08-11 03:58:45,080][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110424] [Batch 03356/03692] [00:30:01/00:03:00, 0.537s/it]: train_loss_raw=0.4384, running_loss=0.3558, LR=0.000100
[2025-08-11 03:58:51,462][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110436] [Batch 03368/03692] [00:30:08/00:02:53, 0.537s/it]: train_loss_raw=0.3563, running_loss=0.3549, LR=0.000100
[2025-08-11 03:58:57,892][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110448] [Batch 03380/03692] [00:30:14/00:02:47, 0.537s/it]: train_loss_raw=0.3992, running_loss=0.3527, LR=0.000100
[2025-08-11 03:59:04,338][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110460] [Batch 03392/03692] [00:30:21/00:02:41, 0.537s/it]: train_loss_raw=0.3508, running_loss=0.3540, LR=0.000100
[2025-08-11 03:59:10,797][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110472] [Batch 03404/03692] [00:30:27/00:02:34, 0.537s/it]: train_loss_raw=0.3562, running_loss=0.3547, LR=0.000100
[2025-08-11 03:59:17,155][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110484] [Batch 03416/03692] [00:30:34/00:02:28, 0.537s/it]: train_loss_raw=0.3501, running_loss=0.3580, LR=0.000100
[2025-08-11 03:59:23,620][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110496] [Batch 03428/03692] [00:30:40/00:02:21, 0.537s/it]: train_loss_raw=0.3683, running_loss=0.3580, LR=0.000100
[2025-08-11 03:59:30,069][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110508] [Batch 03440/03692] [00:30:46/00:02:15, 0.537s/it]: train_loss_raw=0.3297, running_loss=0.3570, LR=0.000100
[2025-08-11 03:59:36,400][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110520] [Batch 03452/03692] [00:30:53/00:02:08, 0.537s/it]: train_loss_raw=0.3369, running_loss=0.3560, LR=0.000100
[2025-08-11 03:59:42,807][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110532] [Batch 03464/03692] [00:30:59/00:02:02, 0.537s/it]: train_loss_raw=0.4388, running_loss=0.3560, LR=0.000100
[2025-08-11 03:59:49,170][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110544] [Batch 03476/03692] [00:31:06/00:01:55, 0.537s/it]: train_loss_raw=0.2594, running_loss=0.3519, LR=0.000100
[2025-08-11 03:59:55,522][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110556] [Batch 03488/03692] [00:31:12/00:01:49, 0.537s/it]: train_loss_raw=0.4625, running_loss=0.3507, LR=0.000100
[2025-08-11 04:00:01,973][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110568] [Batch 03500/03692] [00:31:18/00:01:43, 0.537s/it]: train_loss_raw=0.3509, running_loss=0.3508, LR=0.000100
[2025-08-11 04:00:08,296][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110580] [Batch 03512/03692] [00:31:25/00:01:36, 0.537s/it]: train_loss_raw=0.3748, running_loss=0.3500, LR=0.000100
[2025-08-11 04:00:14,633][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110592] [Batch 03524/03692] [00:31:31/00:01:30, 0.537s/it]: train_loss_raw=0.2852, running_loss=0.3553, LR=0.000100
[2025-08-11 04:00:21,041][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110604] [Batch 03536/03692] [00:31:37/00:01:23, 0.537s/it]: train_loss_raw=0.3486, running_loss=0.3531, LR=0.000100
[2025-08-11 04:00:27,382][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110616] [Batch 03548/03692] [00:31:44/00:01:17, 0.537s/it]: train_loss_raw=0.4066, running_loss=0.3541, LR=0.000100
[2025-08-11 04:00:33,686][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110628] [Batch 03560/03692] [00:31:50/00:01:10, 0.537s/it]: train_loss_raw=0.3571, running_loss=0.3553, LR=0.000100
[2025-08-11 04:00:40,008][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110640] [Batch 03572/03692] [00:31:56/00:01:04, 0.537s/it]: train_loss_raw=0.3866, running_loss=0.3557, LR=0.000100
[2025-08-11 04:00:46,323][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110652] [Batch 03584/03692] [00:32:03/00:00:57, 0.537s/it]: train_loss_raw=0.3881, running_loss=0.3571, LR=0.000100
[2025-08-11 04:00:52,632][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110664] [Batch 03596/03692] [00:32:09/00:00:51, 0.537s/it]: train_loss_raw=0.3249, running_loss=0.3572, LR=0.000100
[2025-08-11 04:00:59,136][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110676] [Batch 03608/03692] [00:32:16/00:00:45, 0.537s/it]: train_loss_raw=0.3338, running_loss=0.3577, LR=0.000100
[2025-08-11 04:01:05,591][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110688] [Batch 03620/03692] [00:32:22/00:00:38, 0.537s/it]: train_loss_raw=0.3723, running_loss=0.3600, LR=0.000100
[2025-08-11 04:01:11,925][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110700] [Batch 03632/03692] [00:32:28/00:00:32, 0.537s/it]: train_loss_raw=0.4103, running_loss=0.3637, LR=0.000100
[2025-08-11 04:01:18,312][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110712] [Batch 03644/03692] [00:32:35/00:00:25, 0.537s/it]: train_loss_raw=0.3172, running_loss=0.3608, LR=0.000100
[2025-08-11 04:01:24,643][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110724] [Batch 03656/03692] [00:32:41/00:00:19, 0.537s/it]: train_loss_raw=0.3257, running_loss=0.3593, LR=0.000100
[2025-08-11 04:01:31,112][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110736] [Batch 03668/03692] [00:32:48/00:00:12, 0.537s/it]: train_loss_raw=0.3394, running_loss=0.3599, LR=0.000100
[2025-08-11 04:01:37,613][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110748] [Batch 03680/03692] [00:32:54/00:00:06, 0.537s/it]: train_loss_raw=0.4053, running_loss=0.3601, LR=0.000100
[2025-08-11 04:02:07,491][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 110760] [Batch 03692/03692] [00:33:24/00:00:00, 0.543s/it]: train_loss_raw=0.3033, running_loss=0.3602, LR=0.000100
[2025-08-11 04:02:12,220][__main__][INFO] - [VALIDATION] [Epoch 29/29] Starting validation.
[2025-08-11 04:02:43,929][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 110761] [Batch 00011/00025] [00:00:31/00:00:34, 2.642s/it]
[2025-08-11 04:02:58,210][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 110761] [Batch 00023/00025] [00:00:45/00:00:01, 1.916s/it]
[2025-08-11 04:02:59,331][__main__][INFO] - [VALIDATION] [Epoch 29/29] train_loss=0.36017, valid_loss=0.56012
[2025-08-11 04:02:59,331][__main__][INFO] - [VALIDATION] [Epoch 29/29] Metrics:
[2025-08-11 04:02:59,331][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_er      0.220
[2025-08-11 04:02:59,331][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_prec    0.577
[2025-08-11 04:02:59,332][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_recall  0.582
[2025-08-11 04:02:59,332][__main__][INFO] - [VALIDATION] [Epoch 29/29] - pep_recall 0.559
[2025-08-11 04:02:59,335][__main__][INFO] - [TRAIN] [Epoch 29/29] Epoch complete, total time 17:06:58, remaining time 00:00:00, 00:34:13 per epoch
[2025-08-11 04:03:00,716][__main__][INFO] - InstaNovo training finished.
