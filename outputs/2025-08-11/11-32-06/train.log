[2025-08-11 11:32:06,141][__main__][INFO] - Initializing training.
[2025-08-11 11:32:06,141][__main__][INFO] - Python version: 3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:24:24) [GCC 13.3.0]
[2025-08-11 11:32:06,141][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-11 11:32:06,141][__main__][INFO] - CUDA version: 12.1
[2025-08-11 11:32:06,148][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/1461_high/*.parquet
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 128
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: instanovo_1461raw_high
train_subset: 1.0
valid_subset_of_train: 0.01
valid_subset: 1
val_check_interval: 1.0
lazy_loading: true
max_shard_size: 1000000
preshuffle_shards: true
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: false
resume_checkpoint: /data/48/wuqian/fast/TipsNovo/model_save/1461Raw_high/epoch_28-step_106000.ckpt
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-11 11:32:06,153][__main__][INFO] - Starting transformer training
[2025-08-11 11:32:06,153][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-11 11:32:06,153][__main__][INFO] - Loading data
[2025-08-11 11:32:26,673][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-11 11:32:26,720][instanovo.utils.data_handler][INFO] - Pre-shuffling across 002 shards. This may take a while...
[2025-08-11 11:32:26,721][instanovo.utils.data_handler][INFO] - Computing new mapping per original shard
[2025-08-11 11:32:26,765][instanovo.utils.data_handler][INFO] - Extracting rows to create shuffled shards
[2025-08-11 11:33:05,172][instanovo.utils.data_handler][INFO] - Writing shuffled shard 000/002 to /tmp/tmpcokpmnsw/temp_5cadab4791ea4d44a5cb4e3faeafd54a.parquet [00:00:38/00:00:38, 38.407s/it]
[2025-08-11 11:34:27,607][instanovo.utils.data_handler][INFO] - Writing shuffled shard 001/002 to /tmp/tmpcokpmnsw/temp_ae0499905c7b424da43a869f9642eb63.parquet [00:02:00/00:00:00, 60.421s/it]
[2025-08-11 11:34:27,607][instanovo.utils.data_handler][INFO] - Removing unshuffled shards
[2025-08-11 11:34:47,756][instanovo.utils.data_handler][INFO] - Pre-shuffle complete
[2025-08-11 11:35:09,413][__main__][INFO] - Validation path not specified, generating from training set.
[2025-08-11 11:37:28,466][__main__][INFO] - Data splits saved to /data/48/wuqian/fast/TipsNovo/model_save/splits.csv
[2025-08-11 11:37:28,466][__main__][INFO] - Checking for unknown residues in 1,262,032 rows.
[2025-08-11 11:37:32,760][__main__][WARNING] - Unsupported residues found in evaluation set! These rows will be dropped.
[2025-08-11 11:37:32,761][__main__][INFO] - New residues found: 
{'O'}
[2025-08-11 11:37:32,761][__main__][INFO] - Residues supported: 
{'N[UNIMOD:7]', '[PAD]', 'L', 'T', 'R', 'E', '[UNIMOD:5]', 'V', 'Y[UNIMOD:21]', 'C', 'I', 'C[UNIMOD:4]', '[SOS]', 'P', 'A', 'S[UNIMOD:21]', 'F', 'D', 'K', 'G', 'Q', 'W', 'S', 'N', '[UNIMOD:1]', 'T[UNIMOD:21]', 'Q[UNIMOD:7]', 'M', 'Y', 'H', 'M[UNIMOD:35]', '[EOS]', '[UNIMOD:385]'}
[2025-08-11 11:40:03,662][__main__][WARNING] - 1 (0.00%) training rows dropped.
[2025-08-11 11:40:03,662][__main__][WARNING] - 0 (0.00%) validation rows dropped.
[2025-08-11 11:42:44,043][__main__][INFO] - Data loaded: 1,246,259 training samples; 15,772 validation samples
[2025-08-11 11:42:44,512][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-11 11:42:44,532][__main__][INFO] - No data leakage!
[2025-08-11 11:42:44,533][__main__][INFO] - Model checkpointing every 0.21 epochs.
[2025-08-11 11:42:44,534][__main__][INFO] - Updates per epoch: 9,737, step_scale=0.25
[2025-08-11 11:43:20,366][__main__][INFO] - Sample batch:
[2025-08-11 11:43:20,366][__main__][INFO] -  - spectra.shape=torch.Size([128, 200, 2])
[2025-08-11 11:43:20,366][__main__][INFO] -  - precursors.shape=torch.Size([128, 3])
[2025-08-11 11:43:20,366][__main__][INFO] -  - spectra_mask.shape=torch.Size([128, 200])
[2025-08-11 11:43:20,366][__main__][INFO] -  - peptides.shape=torch.Size([128, 41])
[2025-08-11 11:43:20,366][__main__][INFO] -  - peptides_mask.shape=torch.Size([128, 41])
[2025-08-11 11:43:20,541][__main__][INFO] - Loading model checkpoint from '/data/48/wuqian/fast/TipsNovo/model_save/1461Raw_high/epoch_28-step_106000.ckpt'
[2025-08-11 11:43:21,652][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-11 11:43:21,653][__main__][INFO] - Test forward pass:
[2025-08-11 11:43:37,489][__main__][INFO] -  - y.shape=torch.Size([128, 42, 33])
[2025-08-11 11:43:38,766][__main__][INFO] - Model saving enabled
[2025-08-11 11:43:38,767][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save/
[2025-08-11 11:43:38,767][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-11 11:43:38,780][__main__][INFO] - InstaNovo training started.
[2025-08-11 11:55:09,588][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-11 11:55:27,826][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000012] [Batch 00012/04869] [00:00:06/00:43:24, 0.536s/it]: train_loss_raw=0.5633, running_loss=0.4508, LR=0.000002
[2025-08-11 11:55:34,339][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/04869] [00:00:12/00:43:33, 0.540s/it]: train_loss_raw=0.3871, running_loss=0.4499, LR=0.000005
[2025-08-11 11:55:40,786][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000036] [Batch 00036/04869] [00:00:19/00:43:23, 0.539s/it]: train_loss_raw=0.4447, running_loss=0.4466, LR=0.000007
[2025-08-11 11:55:47,204][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/04869] [00:00:25/00:43:12, 0.538s/it]: train_loss_raw=0.4571, running_loss=0.4438, LR=0.000010
[2025-08-11 11:55:53,656][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000060] [Batch 00060/04869] [00:00:32/00:43:06, 0.538s/it]: train_loss_raw=0.3553, running_loss=0.4418, LR=0.000012
[2025-08-11 11:56:00,178][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/04869] [00:00:38/00:43:04, 0.539s/it]: train_loss_raw=0.4740, running_loss=0.4401, LR=0.000015
[2025-08-11 11:56:06,678][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000084] [Batch 00084/04869] [00:00:45/00:42:59, 0.539s/it]: train_loss_raw=0.4475, running_loss=0.4376, LR=0.000017
[2025-08-11 11:56:12,728][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/04869] [00:00:51/00:42:32, 0.535s/it]: train_loss_raw=0.3590, running_loss=0.4335, LR=0.000020
[2025-08-11 11:56:18,769][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000108] [Batch 00108/04869] [00:00:57/00:42:09, 0.531s/it]: train_loss_raw=0.4395, running_loss=0.4332, LR=0.000022
[2025-08-11 11:56:24,848][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/04869] [00:01:03/00:41:51, 0.529s/it]: train_loss_raw=0.4702, running_loss=0.4379, LR=0.000025
[2025-08-11 11:56:30,944][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000132] [Batch 00132/04869] [00:01:09/00:41:36, 0.527s/it]: train_loss_raw=0.3923, running_loss=0.4364, LR=0.000027
[2025-08-11 11:56:36,981][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/04869] [00:01:15/00:41:20, 0.525s/it]: train_loss_raw=0.4444, running_loss=0.4327, LR=0.000030
[2025-08-11 11:56:43,074][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000156] [Batch 00156/04869] [00:01:21/00:41:07, 0.524s/it]: train_loss_raw=0.4219, running_loss=0.4287, LR=0.000032
[2025-08-11 11:56:49,111][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/04869] [00:01:27/00:40:54, 0.522s/it]: train_loss_raw=0.4056, running_loss=0.4296, LR=0.000035
[2025-08-11 11:56:55,120][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000180] [Batch 00180/04869] [00:01:33/00:40:41, 0.521s/it]: train_loss_raw=0.3890, running_loss=0.4291, LR=0.000037
[2025-08-11 11:57:01,129][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/04869] [00:01:39/00:40:29, 0.519s/it]: train_loss_raw=0.4069, running_loss=0.4287, LR=0.000040
[2025-08-11 11:57:07,187][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000204] [Batch 00204/04869] [00:01:45/00:40:19, 0.519s/it]: train_loss_raw=0.4066, running_loss=0.4267, LR=0.000042
[2025-08-11 11:57:13,262][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/04869] [00:01:51/00:40:09, 0.518s/it]: train_loss_raw=0.3652, running_loss=0.4250, LR=0.000045
[2025-08-11 11:57:19,707][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000228] [Batch 00228/04869] [00:01:58/00:40:08, 0.519s/it]: train_loss_raw=0.4061, running_loss=0.4259, LR=0.000047
[2025-08-11 11:57:26,246][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/04869] [00:02:04/00:40:08, 0.520s/it]: train_loss_raw=0.3349, running_loss=0.4262, LR=0.000050
[2025-08-11 11:57:32,624][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000252] [Batch 00252/04869] [00:02:11/00:40:04, 0.521s/it]: train_loss_raw=0.5734, running_loss=0.4253, LR=0.000052
[2025-08-11 11:57:39,010][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/04869] [00:02:17/00:40:00, 0.521s/it]: train_loss_raw=0.4482, running_loss=0.4247, LR=0.000055
[2025-08-11 11:57:45,363][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000276] [Batch 00276/04869] [00:02:23/00:39:55, 0.522s/it]: train_loss_raw=0.4553, running_loss=0.4225, LR=0.000057
[2025-08-11 11:57:51,353][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/04869] [00:02:29/00:39:45, 0.521s/it]: train_loss_raw=0.5139, running_loss=0.4263, LR=0.000060
[2025-08-11 11:57:57,421][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000300] [Batch 00300/04869] [00:02:36/00:39:36, 0.520s/it]: train_loss_raw=0.3802, running_loss=0.4289, LR=0.000062
[2025-08-11 11:58:03,459][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/04869] [00:02:42/00:39:27, 0.519s/it]: train_loss_raw=0.3352, running_loss=0.4285, LR=0.000065
[2025-08-11 11:58:09,505][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000324] [Batch 00324/04869] [00:02:48/00:39:18, 0.519s/it]: train_loss_raw=0.4035, running_loss=0.4291, LR=0.000067
[2025-08-11 11:58:15,609][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/04869] [00:02:54/00:39:10, 0.519s/it]: train_loss_raw=0.4259, running_loss=0.4309, LR=0.000070
[2025-08-11 11:58:21,610][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000348] [Batch 00348/04869] [00:03:00/00:39:01, 0.518s/it]: train_loss_raw=0.4423, running_loss=0.4315, LR=0.000072
[2025-08-11 11:58:27,744][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/04869] [00:03:06/00:38:54, 0.518s/it]: train_loss_raw=0.4336, running_loss=0.4303, LR=0.000075
[2025-08-11 11:58:33,844][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000372] [Batch 00372/04869] [00:03:12/00:38:46, 0.517s/it]: train_loss_raw=0.4095, running_loss=0.4317, LR=0.000077
[2025-08-11 11:58:39,912][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/04869] [00:03:18/00:38:38, 0.517s/it]: train_loss_raw=0.6277, running_loss=0.4327, LR=0.000080
[2025-08-11 11:58:45,923][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000396] [Batch 00396/04869] [00:03:24/00:38:30, 0.516s/it]: train_loss_raw=0.4628, running_loss=0.4305, LR=0.000082
[2025-08-11 11:58:52,029][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/04869] [00:03:30/00:38:23, 0.516s/it]: train_loss_raw=0.4789, running_loss=0.4292, LR=0.000085
[2025-08-11 11:58:58,074][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000420] [Batch 00420/04869] [00:03:36/00:38:15, 0.516s/it]: train_loss_raw=0.4792, running_loss=0.4279, LR=0.000087
[2025-08-11 11:59:04,192][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/04869] [00:03:42/00:38:08, 0.516s/it]: train_loss_raw=0.5039, running_loss=0.4322, LR=0.000090
[2025-08-11 11:59:10,237][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000444] [Batch 00444/04869] [00:03:48/00:38:00, 0.515s/it]: train_loss_raw=0.4259, running_loss=0.4337, LR=0.000092
[2025-08-11 11:59:16,341][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/04869] [00:03:54/00:37:53, 0.515s/it]: train_loss_raw=0.4261, running_loss=0.4341, LR=0.000095
[2025-08-11 11:59:22,408][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000468] [Batch 00468/04869] [00:04:01/00:37:46, 0.515s/it]: train_loss_raw=0.4537, running_loss=0.4331, LR=0.000097
[2025-08-11 11:59:28,375][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/04869] [00:04:06/00:37:38, 0.515s/it]: train_loss_raw=0.3647, running_loss=0.4319, LR=0.000100
[2025-08-11 11:59:34,825][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000492] [Batch 00492/04869] [00:04:13/00:37:34, 0.515s/it]: train_loss_raw=0.4498, running_loss=0.4327, LR=0.000100
[2025-08-11 11:59:41,340][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/04869] [00:04:19/00:37:31, 0.516s/it]: train_loss_raw=0.3931, running_loss=0.4305, LR=0.000100
[2025-08-11 11:59:47,768][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000516] [Batch 00516/04869] [00:04:26/00:37:27, 0.516s/it]: train_loss_raw=0.3663, running_loss=0.4306, LR=0.000100
[2025-08-11 11:59:54,248][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/04869] [00:04:32/00:37:23, 0.517s/it]: train_loss_raw=0.4588, running_loss=0.4366, LR=0.000100
[2025-08-11 12:00:00,777][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000540] [Batch 00540/04869] [00:04:39/00:37:19, 0.517s/it]: train_loss_raw=0.5554, running_loss=0.4381, LR=0.000100
[2025-08-11 12:00:07,164][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/04869] [00:04:45/00:37:14, 0.518s/it]: train_loss_raw=0.4437, running_loss=0.4381, LR=0.000100
[2025-08-11 12:00:13,672][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000564] [Batch 00564/04869] [00:04:52/00:37:10, 0.518s/it]: train_loss_raw=0.4811, running_loss=0.4400, LR=0.000100
[2025-08-11 12:00:20,117][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/04869] [00:04:58/00:37:06, 0.519s/it]: train_loss_raw=0.4530, running_loss=0.4381, LR=0.000100
[2025-08-11 12:00:26,585][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000588] [Batch 00588/04869] [00:05:05/00:37:02, 0.519s/it]: train_loss_raw=0.4745, running_loss=0.4395, LR=0.000100
[2025-08-11 12:00:33,016][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/04869] [00:05:11/00:36:57, 0.519s/it]: train_loss_raw=0.5041, running_loss=0.4425, LR=0.000100
[2025-08-11 12:00:39,340][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000612] [Batch 00612/04869] [00:05:17/00:36:51, 0.520s/it]: train_loss_raw=0.4304, running_loss=0.4409, LR=0.000100
[2025-08-11 12:00:45,736][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/04869] [00:05:24/00:36:46, 0.520s/it]: train_loss_raw=0.4835, running_loss=0.4425, LR=0.000100
[2025-08-11 12:00:52,114][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000636] [Batch 00636/04869] [00:05:30/00:36:41, 0.520s/it]: train_loss_raw=0.4424, running_loss=0.4458, LR=0.000100
[2025-08-11 12:00:58,510][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/04869] [00:05:37/00:36:35, 0.520s/it]: train_loss_raw=0.4321, running_loss=0.4467, LR=0.000100
[2025-08-11 12:01:05,036][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000660] [Batch 00660/04869] [00:05:43/00:36:31, 0.521s/it]: train_loss_raw=0.4883, running_loss=0.4479, LR=0.000100
[2025-08-11 12:01:11,325][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/04869] [00:05:49/00:36:25, 0.521s/it]: train_loss_raw=0.4615, running_loss=0.4477, LR=0.000100
[2025-08-11 12:01:17,709][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000684] [Batch 00684/04869] [00:05:56/00:36:20, 0.521s/it]: train_loss_raw=0.4427, running_loss=0.4468, LR=0.000100
[2025-08-11 12:01:24,189][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/04869] [00:06:02/00:36:15, 0.521s/it]: train_loss_raw=0.5463, running_loss=0.4478, LR=0.000100
[2025-08-11 12:01:30,737][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000708] [Batch 00708/04869] [00:06:09/00:36:10, 0.522s/it]: train_loss_raw=0.4841, running_loss=0.4498, LR=0.000100
[2025-08-11 12:01:37,222][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/04869] [00:06:15/00:36:05, 0.522s/it]: train_loss_raw=0.5286, running_loss=0.4499, LR=0.000100
[2025-08-11 12:01:43,666][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000732] [Batch 00732/04869] [00:06:22/00:36:00, 0.522s/it]: train_loss_raw=0.3769, running_loss=0.4506, LR=0.000100
[2025-08-11 12:01:50,078][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/04869] [00:06:28/00:35:55, 0.522s/it]: train_loss_raw=0.3594, running_loss=0.4453, LR=0.000100
[2025-08-11 12:01:56,493][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000756] [Batch 00756/04869] [00:06:35/00:35:49, 0.523s/it]: train_loss_raw=0.4382, running_loss=0.4470, LR=0.000100
[2025-08-11 12:02:02,943][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/04869] [00:06:41/00:35:44, 0.523s/it]: train_loss_raw=0.4574, running_loss=0.4476, LR=0.000100
[2025-08-11 12:02:09,452][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000780] [Batch 00780/04869] [00:06:48/00:35:39, 0.523s/it]: train_loss_raw=0.5109, running_loss=0.4471, LR=0.000100
[2025-08-11 12:02:15,827][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/04869] [00:06:54/00:35:33, 0.523s/it]: train_loss_raw=0.5511, running_loss=0.4485, LR=0.000100
[2025-08-11 12:02:22,320][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000804] [Batch 00804/04869] [00:07:00/00:35:28, 0.524s/it]: train_loss_raw=0.4252, running_loss=0.4469, LR=0.000100
[2025-08-11 12:02:28,874][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/04869] [00:07:07/00:35:23, 0.524s/it]: train_loss_raw=0.4205, running_loss=0.4459, LR=0.000100
[2025-08-11 12:02:35,422][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000828] [Batch 00828/04869] [00:07:14/00:35:18, 0.524s/it]: train_loss_raw=0.3654, running_loss=0.4461, LR=0.000100
[2025-08-11 12:02:41,896][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000840] [Batch 00840/04869] [00:07:20/00:35:12, 0.524s/it]: train_loss_raw=0.4442, running_loss=0.4455, LR=0.000100
[2025-08-11 12:02:48,305][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000852] [Batch 00852/04869] [00:07:26/00:35:07, 0.525s/it]: train_loss_raw=0.4640, running_loss=0.4473, LR=0.000100
[2025-08-11 12:02:54,719][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000864] [Batch 00864/04869] [00:07:33/00:35:01, 0.525s/it]: train_loss_raw=0.5146, running_loss=0.4427, LR=0.000100
[2025-08-11 12:03:01,112][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000876] [Batch 00876/04869] [00:07:39/00:34:55, 0.525s/it]: train_loss_raw=0.4892, running_loss=0.4414, LR=0.000100
[2025-08-11 12:03:07,653][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000888] [Batch 00888/04869] [00:07:46/00:34:50, 0.525s/it]: train_loss_raw=0.4319, running_loss=0.4449, LR=0.000100
[2025-08-11 12:03:14,190][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000900] [Batch 00900/04869] [00:07:52/00:34:45, 0.525s/it]: train_loss_raw=0.5804, running_loss=0.4444, LR=0.000100
[2025-08-11 12:03:20,478][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000912] [Batch 00912/04869] [00:07:59/00:34:38, 0.525s/it]: train_loss_raw=0.3704, running_loss=0.4438, LR=0.000100
[2025-08-11 12:03:26,821][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000924] [Batch 00924/04869] [00:08:05/00:34:32, 0.525s/it]: train_loss_raw=0.4317, running_loss=0.4440, LR=0.000100
[2025-08-11 12:03:33,370][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000936] [Batch 00936/04869] [00:08:11/00:34:27, 0.526s/it]: train_loss_raw=0.3891, running_loss=0.4467, LR=0.000100
[2025-08-11 12:03:39,577][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000948] [Batch 00948/04869] [00:08:18/00:34:20, 0.526s/it]: train_loss_raw=0.5386, running_loss=0.4460, LR=0.000100
[2025-08-11 12:03:45,952][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000960] [Batch 00960/04869] [00:08:24/00:34:14, 0.526s/it]: train_loss_raw=0.4902, running_loss=0.4431, LR=0.000100
[2025-08-11 12:03:52,444][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000972] [Batch 00972/04869] [00:08:31/00:34:08, 0.526s/it]: train_loss_raw=0.3750, running_loss=0.4400, LR=0.000100
[2025-08-11 12:03:58,724][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000984] [Batch 00984/04869] [00:08:37/00:34:02, 0.526s/it]: train_loss_raw=0.4634, running_loss=0.4396, LR=0.000100
[2025-08-11 12:04:05,214][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000996] [Batch 00996/04869] [00:08:43/00:33:56, 0.526s/it]: train_loss_raw=0.4452, running_loss=0.4375, LR=0.000100
[2025-08-11 12:04:11,732][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001008] [Batch 01008/04869] [00:08:50/00:33:51, 0.526s/it]: train_loss_raw=0.4326, running_loss=0.4382, LR=0.000100
[2025-08-11 12:04:18,219][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001020] [Batch 01020/04869] [00:08:56/00:33:45, 0.526s/it]: train_loss_raw=0.3895, running_loss=0.4373, LR=0.000100
[2025-08-11 12:04:24,735][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001032] [Batch 01032/04869] [00:09:03/00:33:40, 0.526s/it]: train_loss_raw=0.3864, running_loss=0.4347, LR=0.000100
[2025-08-11 12:04:31,069][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001044] [Batch 01044/04869] [00:09:09/00:33:33, 0.527s/it]: train_loss_raw=0.4015, running_loss=0.4348, LR=0.000100
[2025-08-11 12:04:37,557][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001056] [Batch 01056/04869] [00:09:16/00:33:28, 0.527s/it]: train_loss_raw=0.5370, running_loss=0.4376, LR=0.000100
[2025-08-11 12:04:43,875][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001068] [Batch 01068/04869] [00:09:22/00:33:21, 0.527s/it]: train_loss_raw=0.5691, running_loss=0.4400, LR=0.000100
[2025-08-11 12:04:50,242][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001080] [Batch 01080/04869] [00:09:28/00:33:15, 0.527s/it]: train_loss_raw=0.3950, running_loss=0.4372, LR=0.000100
[2025-08-11 12:04:56,552][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001092] [Batch 01092/04869] [00:09:35/00:33:09, 0.527s/it]: train_loss_raw=0.4594, running_loss=0.4378, LR=0.000100
[2025-08-11 12:05:02,903][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001104] [Batch 01104/04869] [00:09:41/00:33:03, 0.527s/it]: train_loss_raw=0.4518, running_loss=0.4352, LR=0.000100
[2025-08-11 12:05:09,309][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001116] [Batch 01116/04869] [00:09:47/00:32:57, 0.527s/it]: train_loss_raw=0.4616, running_loss=0.4361, LR=0.000100
[2025-08-11 12:05:15,687][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001128] [Batch 01128/04869] [00:09:54/00:32:50, 0.527s/it]: train_loss_raw=0.3996, running_loss=0.4368, LR=0.000100
[2025-08-11 12:05:22,023][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001140] [Batch 01140/04869] [00:10:00/00:32:44, 0.527s/it]: train_loss_raw=0.4251, running_loss=0.4349, LR=0.000100
[2025-08-11 12:05:28,380][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001152] [Batch 01152/04869] [00:10:06/00:32:38, 0.527s/it]: train_loss_raw=0.4595, running_loss=0.4352, LR=0.000100
[2025-08-11 12:05:34,773][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001164] [Batch 01164/04869] [00:10:13/00:32:32, 0.527s/it]: train_loss_raw=0.5396, running_loss=0.4387, LR=0.000100
[2025-08-11 12:05:41,312][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001176] [Batch 01176/04869] [00:10:19/00:32:26, 0.527s/it]: train_loss_raw=0.4716, running_loss=0.4416, LR=0.000100
[2025-08-11 12:05:47,347][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001188] [Batch 01188/04869] [00:10:25/00:32:19, 0.527s/it]: train_loss_raw=0.4596, running_loss=0.4416, LR=0.000100
[2025-08-11 12:05:53,339][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001200] [Batch 01200/04869] [00:10:31/00:32:12, 0.527s/it]: train_loss_raw=0.4234, running_loss=0.4421, LR=0.000100
[2025-08-11 12:05:59,632][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001212] [Batch 01212/04869] [00:10:38/00:32:05, 0.527s/it]: train_loss_raw=0.4999, running_loss=0.4416, LR=0.000100
[2025-08-11 12:06:05,822][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001224] [Batch 01224/04869] [00:10:44/00:31:59, 0.526s/it]: train_loss_raw=0.4398, running_loss=0.4393, LR=0.000100
[2025-08-11 12:06:12,181][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001236] [Batch 01236/04869] [00:10:50/00:31:52, 0.527s/it]: train_loss_raw=0.4768, running_loss=0.4354, LR=0.000100
[2025-08-11 12:06:18,628][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001248] [Batch 01248/04869] [00:10:57/00:31:46, 0.527s/it]: train_loss_raw=0.4451, running_loss=0.4360, LR=0.000100
[2025-08-11 12:06:25,113][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001260] [Batch 01260/04869] [00:11:03/00:31:41, 0.527s/it]: train_loss_raw=0.4020, running_loss=0.4385, LR=0.000100
[2025-08-11 12:06:31,458][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001272] [Batch 01272/04869] [00:11:10/00:31:34, 0.527s/it]: train_loss_raw=0.5239, running_loss=0.4412, LR=0.000100
[2025-08-11 12:06:37,980][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001284] [Batch 01284/04869] [00:11:16/00:31:29, 0.527s/it]: train_loss_raw=0.5058, running_loss=0.4447, LR=0.000100
[2025-08-11 12:06:44,371][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001296] [Batch 01296/04869] [00:11:22/00:31:22, 0.527s/it]: train_loss_raw=0.4290, running_loss=0.4447, LR=0.000100
[2025-08-11 12:06:50,778][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001308] [Batch 01308/04869] [00:11:29/00:31:16, 0.527s/it]: train_loss_raw=0.3596, running_loss=0.4438, LR=0.000100
[2025-08-11 12:06:57,179][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001320] [Batch 01320/04869] [00:11:35/00:31:10, 0.527s/it]: train_loss_raw=0.4606, running_loss=0.4421, LR=0.000100
[2025-08-11 12:07:03,581][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001332] [Batch 01332/04869] [00:11:42/00:31:04, 0.527s/it]: train_loss_raw=0.4575, running_loss=0.4403, LR=0.000100
[2025-08-11 12:07:10,063][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001344] [Batch 01344/04869] [00:11:48/00:30:58, 0.527s/it]: train_loss_raw=0.3965, running_loss=0.4413, LR=0.000100
[2025-08-11 12:07:16,421][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001356] [Batch 01356/04869] [00:11:55/00:30:52, 0.527s/it]: train_loss_raw=0.5198, running_loss=0.4413, LR=0.000100
[2025-08-11 12:07:22,839][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001368] [Batch 01368/04869] [00:12:01/00:30:46, 0.527s/it]: train_loss_raw=0.5116, running_loss=0.4435, LR=0.000100
[2025-08-11 12:07:29,264][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001380] [Batch 01380/04869] [00:12:07/00:30:40, 0.527s/it]: train_loss_raw=0.4451, running_loss=0.4392, LR=0.000100
[2025-08-11 12:07:35,590][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001392] [Batch 01392/04869] [00:12:14/00:30:33, 0.527s/it]: train_loss_raw=0.5074, running_loss=0.4422, LR=0.000100
[2025-08-11 12:07:42,057][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001404] [Batch 01404/04869] [00:12:20/00:30:27, 0.528s/it]: train_loss_raw=0.4050, running_loss=0.4441, LR=0.000100
[2025-08-11 12:07:48,492][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001416] [Batch 01416/04869] [00:12:27/00:30:21, 0.528s/it]: train_loss_raw=0.3732, running_loss=0.4411, LR=0.000100
[2025-08-11 12:07:54,933][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001428] [Batch 01428/04869] [00:12:33/00:30:15, 0.528s/it]: train_loss_raw=0.4692, running_loss=0.4411, LR=0.000100
[2025-08-11 12:08:01,412][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001440] [Batch 01440/04869] [00:12:40/00:30:09, 0.528s/it]: train_loss_raw=0.4727, running_loss=0.4407, LR=0.000100
[2025-08-11 12:08:07,818][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001452] [Batch 01452/04869] [00:12:46/00:30:03, 0.528s/it]: train_loss_raw=0.4634, running_loss=0.4426, LR=0.000100
[2025-08-11 12:08:14,138][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001464] [Batch 01464/04869] [00:12:52/00:29:57, 0.528s/it]: train_loss_raw=0.3764, running_loss=0.4414, LR=0.000100
[2025-08-11 12:08:20,550][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001476] [Batch 01476/04869] [00:12:59/00:29:51, 0.528s/it]: train_loss_raw=0.4882, running_loss=0.4421, LR=0.000100
[2025-08-11 12:08:26,899][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001488] [Batch 01488/04869] [00:13:05/00:29:44, 0.528s/it]: train_loss_raw=0.4494, running_loss=0.4427, LR=0.000100
[2025-08-11 12:08:33,341][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001500] [Batch 01500/04869] [00:13:11/00:29:38, 0.528s/it]: train_loss_raw=0.4377, running_loss=0.4418, LR=0.000100
[2025-08-11 12:08:39,648][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001512] [Batch 01512/04869] [00:13:18/00:29:32, 0.528s/it]: train_loss_raw=0.4007, running_loss=0.4396, LR=0.000100
[2025-08-11 12:08:46,109][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001524] [Batch 01524/04869] [00:13:24/00:29:26, 0.528s/it]: train_loss_raw=0.3560, running_loss=0.4369, LR=0.000100
[2025-08-11 12:08:52,491][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001536] [Batch 01536/04869] [00:13:31/00:29:20, 0.528s/it]: train_loss_raw=0.4120, running_loss=0.4386, LR=0.000100
[2025-08-11 12:08:58,934][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001548] [Batch 01548/04869] [00:13:37/00:29:13, 0.528s/it]: train_loss_raw=0.3701, running_loss=0.4373, LR=0.000100
[2025-08-11 12:09:05,465][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001560] [Batch 01560/04869] [00:13:44/00:29:07, 0.528s/it]: train_loss_raw=0.3862, running_loss=0.4346, LR=0.000100
[2025-08-11 12:09:11,801][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001572] [Batch 01572/04869] [00:13:50/00:29:01, 0.528s/it]: train_loss_raw=0.5359, running_loss=0.4332, LR=0.000100
[2025-08-11 12:09:18,182][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001584] [Batch 01584/04869] [00:13:56/00:28:55, 0.528s/it]: train_loss_raw=0.4361, running_loss=0.4349, LR=0.000100
[2025-08-11 12:09:24,579][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001596] [Batch 01596/04869] [00:14:03/00:28:49, 0.528s/it]: train_loss_raw=0.4089, running_loss=0.4354, LR=0.000100
[2025-08-11 12:09:30,918][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001608] [Batch 01608/04869] [00:14:09/00:28:42, 0.528s/it]: train_loss_raw=0.3693, running_loss=0.4332, LR=0.000100
[2025-08-11 12:09:37,367][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001620] [Batch 01620/04869] [00:14:15/00:28:36, 0.528s/it]: train_loss_raw=0.4717, running_loss=0.4320, LR=0.000100
[2025-08-11 12:09:43,831][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001632] [Batch 01632/04869] [00:14:22/00:28:30, 0.528s/it]: train_loss_raw=0.4135, running_loss=0.4357, LR=0.000100
[2025-08-11 12:09:50,476][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001644] [Batch 01644/04869] [00:14:29/00:28:24, 0.529s/it]: train_loss_raw=0.4313, running_loss=0.4379, LR=0.000100
[2025-08-11 12:09:57,073][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001656] [Batch 01656/04869] [00:14:35/00:28:19, 0.529s/it]: train_loss_raw=0.4042, running_loss=0.4380, LR=0.000100
[2025-08-11 12:10:03,132][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001668] [Batch 01668/04869] [00:14:41/00:28:12, 0.529s/it]: train_loss_raw=0.5131, running_loss=0.4365, LR=0.000100
[2025-08-11 12:10:09,532][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001680] [Batch 01680/04869] [00:14:48/00:28:05, 0.529s/it]: train_loss_raw=0.4514, running_loss=0.4393, LR=0.000100
[2025-08-11 12:10:15,561][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001692] [Batch 01692/04869] [00:14:54/00:27:58, 0.528s/it]: train_loss_raw=0.5396, running_loss=0.4374, LR=0.000100
[2025-08-11 12:10:21,588][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001704] [Batch 01704/04869] [00:15:00/00:27:52, 0.528s/it]: train_loss_raw=0.3504, running_loss=0.4355, LR=0.000100
[2025-08-11 12:10:27,609][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001716] [Batch 01716/04869] [00:15:06/00:27:45, 0.528s/it]: train_loss_raw=0.4389, running_loss=0.4361, LR=0.000100
[2025-08-11 12:10:33,612][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001728] [Batch 01728/04869] [00:15:12/00:27:38, 0.528s/it]: train_loss_raw=0.4176, running_loss=0.4357, LR=0.000100
[2025-08-11 12:10:39,653][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001740] [Batch 01740/04869] [00:15:18/00:27:31, 0.528s/it]: train_loss_raw=0.3746, running_loss=0.4373, LR=0.000100
[2025-08-11 12:10:45,597][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001752] [Batch 01752/04869] [00:15:24/00:27:24, 0.528s/it]: train_loss_raw=0.3906, running_loss=0.4352, LR=0.000100
[2025-08-11 12:10:51,742][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001764] [Batch 01764/04869] [00:15:30/00:27:17, 0.527s/it]: train_loss_raw=0.4376, running_loss=0.4335, LR=0.000100
[2025-08-11 12:10:58,201][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001776] [Batch 01776/04869] [00:15:36/00:27:11, 0.527s/it]: train_loss_raw=0.6519, running_loss=0.4361, LR=0.000100
[2025-08-11 12:11:04,672][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001788] [Batch 01788/04869] [00:15:43/00:27:05, 0.528s/it]: train_loss_raw=0.4908, running_loss=0.4384, LR=0.000100
[2025-08-11 12:11:11,122][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001800] [Batch 01800/04869] [00:15:49/00:26:59, 0.528s/it]: train_loss_raw=0.4283, running_loss=0.4407, LR=0.000100
[2025-08-11 12:11:17,567][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001812] [Batch 01812/04869] [00:15:56/00:26:53, 0.528s/it]: train_loss_raw=0.4436, running_loss=0.4424, LR=0.000100
[2025-08-11 12:11:24,075][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001824] [Batch 01824/04869] [00:16:02/00:26:47, 0.528s/it]: train_loss_raw=0.5781, running_loss=0.4459, LR=0.000100
[2025-08-11 12:11:30,512][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001836] [Batch 01836/04869] [00:16:09/00:26:40, 0.528s/it]: train_loss_raw=0.4678, running_loss=0.4460, LR=0.000100
[2025-08-11 12:11:36,908][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001848] [Batch 01848/04869] [00:16:15/00:26:34, 0.528s/it]: train_loss_raw=0.3684, running_loss=0.4464, LR=0.000100
[2025-08-11 12:11:43,202][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001860] [Batch 01860/04869] [00:16:21/00:26:28, 0.528s/it]: train_loss_raw=0.5038, running_loss=0.4478, LR=0.000100
[2025-08-11 12:11:49,648][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001872] [Batch 01872/04869] [00:16:28/00:26:22, 0.528s/it]: train_loss_raw=0.3890, running_loss=0.4485, LR=0.000100
[2025-08-11 12:11:56,136][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001884] [Batch 01884/04869] [00:16:34/00:26:16, 0.528s/it]: train_loss_raw=0.3751, running_loss=0.4463, LR=0.000100
[2025-08-11 12:12:02,597][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001896] [Batch 01896/04869] [00:16:41/00:26:09, 0.528s/it]: train_loss_raw=0.4166, running_loss=0.4444, LR=0.000100
[2025-08-11 12:12:09,152][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001908] [Batch 01908/04869] [00:16:47/00:26:03, 0.528s/it]: train_loss_raw=0.5487, running_loss=0.4442, LR=0.000100
[2025-08-11 12:12:15,600][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001920] [Batch 01920/04869] [00:16:54/00:25:57, 0.528s/it]: train_loss_raw=0.4792, running_loss=0.4461, LR=0.000100
[2025-08-11 12:12:21,755][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001932] [Batch 01932/04869] [00:17:00/00:25:51, 0.528s/it]: train_loss_raw=0.4117, running_loss=0.4455, LR=0.000100
[2025-08-11 12:12:27,968][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001944] [Batch 01944/04869] [00:17:06/00:25:44, 0.528s/it]: train_loss_raw=0.5084, running_loss=0.4428, LR=0.000100
[2025-08-11 12:12:34,498][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001956] [Batch 01956/04869] [00:17:13/00:25:38, 0.528s/it]: train_loss_raw=0.5326, running_loss=0.4430, LR=0.000100
[2025-08-11 12:12:40,923][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001968] [Batch 01968/04869] [00:17:19/00:25:32, 0.528s/it]: train_loss_raw=0.4443, running_loss=0.4431, LR=0.000100
[2025-08-11 12:12:47,368][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001980] [Batch 01980/04869] [00:17:25/00:25:26, 0.528s/it]: train_loss_raw=0.4777, running_loss=0.4421, LR=0.000100
[2025-08-11 12:12:53,705][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001992] [Batch 01992/04869] [00:17:32/00:25:19, 0.528s/it]: train_loss_raw=0.5133, running_loss=0.4408, LR=0.000100
[2025-08-11 12:13:04,064][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002004] [Batch 02004/04869] [00:17:42/00:25:19, 0.530s/it]: train_loss_raw=0.4352, running_loss=0.4431, LR=0.000100
[2025-08-11 12:13:10,382][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002016] [Batch 02016/04869] [00:17:48/00:25:12, 0.530s/it]: train_loss_raw=0.4081, running_loss=0.4416, LR=0.000100
[2025-08-11 12:13:39,849][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002028] [Batch 02028/04869] [00:18:18/00:25:38, 0.542s/it]: train_loss_raw=0.4172, running_loss=0.4370, LR=0.000100
[2025-08-11 12:13:46,234][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002040] [Batch 02040/04869] [00:18:24/00:25:32, 0.542s/it]: train_loss_raw=0.5100, running_loss=0.4336, LR=0.000100
[2025-08-11 12:13:52,678][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002052] [Batch 02052/04869] [00:18:31/00:25:25, 0.542s/it]: train_loss_raw=0.4689, running_loss=0.4353, LR=0.000100
[2025-08-11 12:13:59,119][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002064] [Batch 02064/04869] [00:18:37/00:25:19, 0.542s/it]: train_loss_raw=0.4840, running_loss=0.4311, LR=0.000100
[2025-08-11 12:14:05,552][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002076] [Batch 02076/04869] [00:18:44/00:25:12, 0.542s/it]: train_loss_raw=0.4781, running_loss=0.4332, LR=0.000100
[2025-08-11 12:14:11,976][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002088] [Batch 02088/04869] [00:18:50/00:25:05, 0.541s/it]: train_loss_raw=0.5275, running_loss=0.4362, LR=0.000100
[2025-08-11 12:14:18,329][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002100] [Batch 02100/04869] [00:18:56/00:24:59, 0.541s/it]: train_loss_raw=0.4566, running_loss=0.4403, LR=0.000100
[2025-08-11 12:14:24,683][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002112] [Batch 02112/04869] [00:19:03/00:24:52, 0.541s/it]: train_loss_raw=0.4781, running_loss=0.4403, LR=0.000100
[2025-08-11 12:14:31,074][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002124] [Batch 02124/04869] [00:19:09/00:24:45, 0.541s/it]: train_loss_raw=0.3796, running_loss=0.4393, LR=0.000100
[2025-08-11 12:14:37,418][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002136] [Batch 02136/04869] [00:19:16/00:24:39, 0.541s/it]: train_loss_raw=0.4954, running_loss=0.4388, LR=0.000100
[2025-08-11 12:14:43,811][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002148] [Batch 02148/04869] [00:19:22/00:24:32, 0.541s/it]: train_loss_raw=0.3761, running_loss=0.4373, LR=0.000100
[2025-08-11 12:14:50,206][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002160] [Batch 02160/04869] [00:19:28/00:24:25, 0.541s/it]: train_loss_raw=0.4781, running_loss=0.4401, LR=0.000100
[2025-08-11 12:14:56,588][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002172] [Batch 02172/04869] [00:19:35/00:24:19, 0.541s/it]: train_loss_raw=0.5014, running_loss=0.4399, LR=0.000100
[2025-08-11 12:15:02,927][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002184] [Batch 02184/04869] [00:19:41/00:24:12, 0.541s/it]: train_loss_raw=0.4502, running_loss=0.4384, LR=0.000100
[2025-08-11 12:15:09,244][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002196] [Batch 02196/04869] [00:19:47/00:24:05, 0.541s/it]: train_loss_raw=0.4672, running_loss=0.4404, LR=0.000100
[2025-08-11 12:15:15,604][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002208] [Batch 02208/04869] [00:19:54/00:23:59, 0.541s/it]: train_loss_raw=0.4092, running_loss=0.4408, LR=0.000100
[2025-08-11 12:15:22,021][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002220] [Batch 02220/04869] [00:20:00/00:23:52, 0.541s/it]: train_loss_raw=0.4185, running_loss=0.4418, LR=0.000100
[2025-08-11 12:15:28,455][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002232] [Batch 02232/04869] [00:20:07/00:23:46, 0.541s/it]: train_loss_raw=0.4462, running_loss=0.4422, LR=0.000100
[2025-08-11 12:15:35,031][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002244] [Batch 02244/04869] [00:20:13/00:23:39, 0.541s/it]: train_loss_raw=0.4149, running_loss=0.4426, LR=0.000100
[2025-08-11 12:15:41,586][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002256] [Batch 02256/04869] [00:20:20/00:23:33, 0.541s/it]: train_loss_raw=0.4760, running_loss=0.4418, LR=0.000100
[2025-08-11 12:15:47,994][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002268] [Batch 02268/04869] [00:20:26/00:23:26, 0.541s/it]: train_loss_raw=0.4630, running_loss=0.4382, LR=0.000100
[2025-08-11 12:15:54,442][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002280] [Batch 02280/04869] [00:20:33/00:23:20, 0.541s/it]: train_loss_raw=0.4544, running_loss=0.4388, LR=0.000100
[2025-08-11 12:16:01,008][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002292] [Batch 02292/04869] [00:20:39/00:23:13, 0.541s/it]: train_loss_raw=0.4170, running_loss=0.4382, LR=0.000100
[2025-08-11 12:16:07,510][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002304] [Batch 02304/04869] [00:20:46/00:23:07, 0.541s/it]: train_loss_raw=0.4415, running_loss=0.4405, LR=0.000100
[2025-08-11 12:16:13,827][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002316] [Batch 02316/04869] [00:20:52/00:23:00, 0.541s/it]: train_loss_raw=0.5134, running_loss=0.4441, LR=0.000100
[2025-08-11 12:16:20,197][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002328] [Batch 02328/04869] [00:20:58/00:22:53, 0.541s/it]: train_loss_raw=0.4083, running_loss=0.4421, LR=0.000100
[2025-08-11 12:16:26,633][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002340] [Batch 02340/04869] [00:21:05/00:22:47, 0.541s/it]: train_loss_raw=0.4667, running_loss=0.4481, LR=0.000100
[2025-08-11 12:16:33,109][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002352] [Batch 02352/04869] [00:21:11/00:22:40, 0.541s/it]: train_loss_raw=0.4960, running_loss=0.4467, LR=0.000100
[2025-08-11 12:16:39,478][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002364] [Batch 02364/04869] [00:21:18/00:22:34, 0.541s/it]: train_loss_raw=0.4013, running_loss=0.4445, LR=0.000100
[2025-08-11 12:16:45,945][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002376] [Batch 02376/04869] [00:21:24/00:22:27, 0.541s/it]: train_loss_raw=0.5250, running_loss=0.4433, LR=0.000100
[2025-08-11 12:16:52,380][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002388] [Batch 02388/04869] [00:21:30/00:22:21, 0.541s/it]: train_loss_raw=0.4577, running_loss=0.4409, LR=0.000100
[2025-08-11 12:16:58,777][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002400] [Batch 02400/04869] [00:21:37/00:22:14, 0.541s/it]: train_loss_raw=0.4144, running_loss=0.4386, LR=0.000100
[2025-08-11 12:17:05,120][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002412] [Batch 02412/04869] [00:21:43/00:22:08, 0.541s/it]: train_loss_raw=0.4365, running_loss=0.4354, LR=0.000100
[2025-08-11 12:17:11,323][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002424] [Batch 02424/04869] [00:21:49/00:22:01, 0.540s/it]: train_loss_raw=0.4080, running_loss=0.4347, LR=0.000100
[2025-08-11 12:17:17,708][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002436] [Batch 02436/04869] [00:21:56/00:21:54, 0.540s/it]: train_loss_raw=0.3959, running_loss=0.4354, LR=0.000100
[2025-08-11 12:17:24,239][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002448] [Batch 02448/04869] [00:22:02/00:21:48, 0.540s/it]: train_loss_raw=0.4538, running_loss=0.4360, LR=0.000100
[2025-08-11 12:17:30,679][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002460] [Batch 02460/04869] [00:22:09/00:21:41, 0.540s/it]: train_loss_raw=0.4246, running_loss=0.4396, LR=0.000100
[2025-08-11 12:17:37,154][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002472] [Batch 02472/04869] [00:22:15/00:21:35, 0.540s/it]: train_loss_raw=0.4322, running_loss=0.4375, LR=0.000100
[2025-08-11 12:17:43,616][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002484] [Batch 02484/04869] [00:22:22/00:21:28, 0.540s/it]: train_loss_raw=0.4202, running_loss=0.4373, LR=0.000100
[2025-08-11 12:17:49,965][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002496] [Batch 02496/04869] [00:22:28/00:21:22, 0.540s/it]: train_loss_raw=0.4868, running_loss=0.4386, LR=0.000100
[2025-08-11 12:17:56,272][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002508] [Batch 02508/04869] [00:22:34/00:21:15, 0.540s/it]: train_loss_raw=0.4074, running_loss=0.4362, LR=0.000100
[2025-08-11 12:18:02,609][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002520] [Batch 02520/04869] [00:22:41/00:21:08, 0.540s/it]: train_loss_raw=0.4269, running_loss=0.4380, LR=0.000100
[2025-08-11 12:18:09,036][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002532] [Batch 02532/04869] [00:22:47/00:21:02, 0.540s/it]: train_loss_raw=0.4548, running_loss=0.4377, LR=0.000100
[2025-08-11 12:18:15,372][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002544] [Batch 02544/04869] [00:22:53/00:20:55, 0.540s/it]: train_loss_raw=0.4535, running_loss=0.4405, LR=0.000100
[2025-08-11 12:18:21,724][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002556] [Batch 02556/04869] [00:23:00/00:20:49, 0.540s/it]: train_loss_raw=0.4189, running_loss=0.4384, LR=0.000100
[2025-08-11 12:18:28,020][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002568] [Batch 02568/04869] [00:23:06/00:20:42, 0.540s/it]: train_loss_raw=0.4426, running_loss=0.4379, LR=0.000100
[2025-08-11 12:18:34,410][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002580] [Batch 02580/04869] [00:23:13/00:20:35, 0.540s/it]: train_loss_raw=0.3869, running_loss=0.4366, LR=0.000100
[2025-08-11 12:18:40,761][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002592] [Batch 02592/04869] [00:23:19/00:20:29, 0.540s/it]: train_loss_raw=0.4786, running_loss=0.4401, LR=0.000100
[2025-08-11 12:18:47,170][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002604] [Batch 02604/04869] [00:23:25/00:20:22, 0.540s/it]: train_loss_raw=0.4161, running_loss=0.4406, LR=0.000100
[2025-08-11 12:18:53,608][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002616] [Batch 02616/04869] [00:23:32/00:20:16, 0.540s/it]: train_loss_raw=0.3947, running_loss=0.4403, LR=0.000100
[2025-08-11 12:19:00,183][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002628] [Batch 02628/04869] [00:23:38/00:20:09, 0.540s/it]: train_loss_raw=0.4285, running_loss=0.4412, LR=0.000100
[2025-08-11 12:19:06,633][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002640] [Batch 02640/04869] [00:23:45/00:20:03, 0.540s/it]: train_loss_raw=0.3533, running_loss=0.4410, LR=0.000100
[2025-08-11 12:19:13,117][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002652] [Batch 02652/04869] [00:23:51/00:19:56, 0.540s/it]: train_loss_raw=0.4272, running_loss=0.4372, LR=0.000100
[2025-08-11 12:19:19,350][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002664] [Batch 02664/04869] [00:23:57/00:19:50, 0.540s/it]: train_loss_raw=0.5361, running_loss=0.4389, LR=0.000100
[2025-08-11 12:19:25,471][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002676] [Batch 02676/04869] [00:24:04/00:19:43, 0.540s/it]: train_loss_raw=0.4223, running_loss=0.4383, LR=0.000100
[2025-08-11 12:19:31,927][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002688] [Batch 02688/04869] [00:24:10/00:19:36, 0.540s/it]: train_loss_raw=0.5026, running_loss=0.4393, LR=0.000100
[2025-08-11 12:19:38,518][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002700] [Batch 02700/04869] [00:24:17/00:19:30, 0.540s/it]: train_loss_raw=0.4796, running_loss=0.4409, LR=0.000100
[2025-08-11 12:19:44,900][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002712] [Batch 02712/04869] [00:24:23/00:19:24, 0.540s/it]: train_loss_raw=0.4595, running_loss=0.4367, LR=0.000100
[2025-08-11 12:19:51,109][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002724] [Batch 02724/04869] [00:24:29/00:19:17, 0.540s/it]: train_loss_raw=0.4374, running_loss=0.4385, LR=0.000100
[2025-08-11 12:19:57,189][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002736] [Batch 02736/04869] [00:24:35/00:19:10, 0.539s/it]: train_loss_raw=0.5554, running_loss=0.4373, LR=0.000100
[2025-08-11 12:20:03,615][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002748] [Batch 02748/04869] [00:24:42/00:19:04, 0.539s/it]: train_loss_raw=0.3861, running_loss=0.4384, LR=0.000100
[2025-08-11 12:20:10,126][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002760] [Batch 02760/04869] [00:24:48/00:18:57, 0.539s/it]: train_loss_raw=0.3528, running_loss=0.4364, LR=0.000100
[2025-08-11 12:20:16,714][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002772] [Batch 02772/04869] [00:24:55/00:18:51, 0.539s/it]: train_loss_raw=0.3938, running_loss=0.4364, LR=0.000100
[2025-08-11 12:20:23,330][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002784] [Batch 02784/04869] [00:25:01/00:18:44, 0.539s/it]: train_loss_raw=0.4059, running_loss=0.4346, LR=0.000100
[2025-08-11 12:20:29,844][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002796] [Batch 02796/04869] [00:25:08/00:18:38, 0.540s/it]: train_loss_raw=0.3443, running_loss=0.4337, LR=0.000100
[2025-08-11 12:20:36,390][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002808] [Batch 02808/04869] [00:25:14/00:18:31, 0.540s/it]: train_loss_raw=0.3584, running_loss=0.4315, LR=0.000100
[2025-08-11 12:20:42,717][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002820] [Batch 02820/04869] [00:25:21/00:18:25, 0.539s/it]: train_loss_raw=0.5359, running_loss=0.4309, LR=0.000100
[2025-08-11 12:20:48,987][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002832] [Batch 02832/04869] [00:25:27/00:18:18, 0.539s/it]: train_loss_raw=0.4417, running_loss=0.4284, LR=0.000100
[2025-08-11 12:20:55,298][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002844] [Batch 02844/04869] [00:25:33/00:18:12, 0.539s/it]: train_loss_raw=0.3857, running_loss=0.4309, LR=0.000100
[2025-08-11 12:21:01,567][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002856] [Batch 02856/04869] [00:25:40/00:18:05, 0.539s/it]: train_loss_raw=0.4471, running_loss=0.4325, LR=0.000100
[2025-08-11 12:21:07,909][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002868] [Batch 02868/04869] [00:25:46/00:17:59, 0.539s/it]: train_loss_raw=0.3954, running_loss=0.4335, LR=0.000100
[2025-08-11 12:21:14,235][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002880] [Batch 02880/04869] [00:25:52/00:17:52, 0.539s/it]: train_loss_raw=0.3602, running_loss=0.4347, LR=0.000100
[2025-08-11 12:21:20,566][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002892] [Batch 02892/04869] [00:25:59/00:17:45, 0.539s/it]: train_loss_raw=0.4247, running_loss=0.4345, LR=0.000100
[2025-08-11 12:21:26,924][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002904] [Batch 02904/04869] [00:26:05/00:17:39, 0.539s/it]: train_loss_raw=0.5798, running_loss=0.4354, LR=0.000100
[2025-08-11 12:21:33,470][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002916] [Batch 02916/04869] [00:26:12/00:17:32, 0.539s/it]: train_loss_raw=0.3925, running_loss=0.4345, LR=0.000100
[2025-08-11 12:21:39,800][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002928] [Batch 02928/04869] [00:26:18/00:17:26, 0.539s/it]: train_loss_raw=0.4503, running_loss=0.4317, LR=0.000100
[2025-08-11 12:21:46,051][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002940] [Batch 02940/04869] [00:26:24/00:17:19, 0.539s/it]: train_loss_raw=0.4959, running_loss=0.4311, LR=0.000100
[2025-08-11 12:21:52,393][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002952] [Batch 02952/04869] [00:26:31/00:17:13, 0.539s/it]: train_loss_raw=0.3786, running_loss=0.4296, LR=0.000100
[2025-08-11 12:21:58,843][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002964] [Batch 02964/04869] [00:26:37/00:17:06, 0.539s/it]: train_loss_raw=0.4326, running_loss=0.4305, LR=0.000100
[2025-08-11 12:22:05,383][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002976] [Batch 02976/04869] [00:26:43/00:17:00, 0.539s/it]: train_loss_raw=0.4878, running_loss=0.4319, LR=0.000100
[2025-08-11 12:22:12,018][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002988] [Batch 02988/04869] [00:26:50/00:16:53, 0.539s/it]: train_loss_raw=0.3977, running_loss=0.4330, LR=0.000100
[2025-08-11 12:22:18,466][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003000] [Batch 03000/04869] [00:26:57/00:16:47, 0.539s/it]: train_loss_raw=0.3764, running_loss=0.4325, LR=0.000100
[2025-08-11 12:22:24,916][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003012] [Batch 03012/04869] [00:27:03/00:16:40, 0.539s/it]: train_loss_raw=0.4260, running_loss=0.4291, LR=0.000100
[2025-08-11 12:22:31,326][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003024] [Batch 03024/04869] [00:27:09/00:16:34, 0.539s/it]: train_loss_raw=0.5345, running_loss=0.4301, LR=0.000100
[2025-08-11 12:22:37,879][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003036] [Batch 03036/04869] [00:27:16/00:16:28, 0.539s/it]: train_loss_raw=0.3851, running_loss=0.4278, LR=0.000100
[2025-08-11 12:22:44,272][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003048] [Batch 03048/04869] [00:27:22/00:16:21, 0.539s/it]: train_loss_raw=0.4661, running_loss=0.4278, LR=0.000100
[2025-08-11 12:22:50,571][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003060] [Batch 03060/04869] [00:27:29/00:16:14, 0.539s/it]: train_loss_raw=0.6038, running_loss=0.4287, LR=0.000100
[2025-08-11 12:22:56,842][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003072] [Batch 03072/04869] [00:27:35/00:16:08, 0.539s/it]: train_loss_raw=0.5050, running_loss=0.4276, LR=0.000100
[2025-08-11 12:23:03,216][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003084] [Batch 03084/04869] [00:27:41/00:16:01, 0.539s/it]: train_loss_raw=0.4161, running_loss=0.4288, LR=0.000100
[2025-08-11 12:23:09,674][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003096] [Batch 03096/04869] [00:27:48/00:15:55, 0.539s/it]: train_loss_raw=0.4664, running_loss=0.4305, LR=0.000100
[2025-08-11 12:23:16,118][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003108] [Batch 03108/04869] [00:27:54/00:15:48, 0.539s/it]: train_loss_raw=0.3795, running_loss=0.4297, LR=0.000100
[2025-08-11 12:23:22,534][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003120] [Batch 03120/04869] [00:28:01/00:15:42, 0.539s/it]: train_loss_raw=0.3211, running_loss=0.4275, LR=0.000100
[2025-08-11 12:23:29,014][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003132] [Batch 03132/04869] [00:28:07/00:15:35, 0.539s/it]: train_loss_raw=0.3680, running_loss=0.4275, LR=0.000100
[2025-08-11 12:23:35,452][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003144] [Batch 03144/04869] [00:28:14/00:15:29, 0.539s/it]: train_loss_raw=0.4485, running_loss=0.4263, LR=0.000100
[2025-08-11 12:23:41,967][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003156] [Batch 03156/04869] [00:28:20/00:15:23, 0.539s/it]: train_loss_raw=0.3421, running_loss=0.4273, LR=0.000100
[2025-08-11 12:23:48,406][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003168] [Batch 03168/04869] [00:28:27/00:15:16, 0.539s/it]: train_loss_raw=0.3585, running_loss=0.4281, LR=0.000100
[2025-08-11 12:23:54,801][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003180] [Batch 03180/04869] [00:28:33/00:15:10, 0.539s/it]: train_loss_raw=0.4106, running_loss=0.4284, LR=0.000100
[2025-08-11 12:24:01,227][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003192] [Batch 03192/04869] [00:28:39/00:15:03, 0.539s/it]: train_loss_raw=0.4979, running_loss=0.4273, LR=0.000100
[2025-08-11 12:24:07,691][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003204] [Batch 03204/04869] [00:28:46/00:14:57, 0.539s/it]: train_loss_raw=0.4025, running_loss=0.4289, LR=0.000100
[2025-08-11 12:24:14,127][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003216] [Batch 03216/04869] [00:28:52/00:14:50, 0.539s/it]: train_loss_raw=0.3799, running_loss=0.4301, LR=0.000100
[2025-08-11 12:24:20,493][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003228] [Batch 03228/04869] [00:28:59/00:14:44, 0.539s/it]: train_loss_raw=0.3477, running_loss=0.4311, LR=0.000100
[2025-08-11 12:24:26,830][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003240] [Batch 03240/04869] [00:29:05/00:14:37, 0.539s/it]: train_loss_raw=0.3552, running_loss=0.4294, LR=0.000100
[2025-08-11 12:24:33,233][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003252] [Batch 03252/04869] [00:29:11/00:14:31, 0.539s/it]: train_loss_raw=0.3978, running_loss=0.4308, LR=0.000100
[2025-08-11 12:24:39,594][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003264] [Batch 03264/04869] [00:29:18/00:14:24, 0.539s/it]: train_loss_raw=0.4467, running_loss=0.4250, LR=0.000100
[2025-08-11 12:24:46,019][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003276] [Batch 03276/04869] [00:29:24/00:14:18, 0.539s/it]: train_loss_raw=0.4880, running_loss=0.4279, LR=0.000100
[2025-08-11 12:24:52,417][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003288] [Batch 03288/04869] [00:29:31/00:14:11, 0.539s/it]: train_loss_raw=0.4138, running_loss=0.4281, LR=0.000100
[2025-08-11 12:24:58,765][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003300] [Batch 03300/04869] [00:29:37/00:14:05, 0.539s/it]: train_loss_raw=0.4076, running_loss=0.4290, LR=0.000100
[2025-08-11 12:25:05,186][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003312] [Batch 03312/04869] [00:29:43/00:13:58, 0.539s/it]: train_loss_raw=0.4960, running_loss=0.4302, LR=0.000100
[2025-08-11 12:25:11,694][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003324] [Batch 03324/04869] [00:29:50/00:13:52, 0.539s/it]: train_loss_raw=0.4697, running_loss=0.4334, LR=0.000100
[2025-08-11 12:25:18,233][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003336] [Batch 03336/04869] [00:29:56/00:13:45, 0.539s/it]: train_loss_raw=0.4711, running_loss=0.4336, LR=0.000100
[2025-08-11 12:25:24,607][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003348] [Batch 03348/04869] [00:30:03/00:13:39, 0.539s/it]: train_loss_raw=0.5143, running_loss=0.4338, LR=0.000100
[2025-08-11 12:25:31,056][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003360] [Batch 03360/04869] [00:30:09/00:13:32, 0.539s/it]: train_loss_raw=0.3820, running_loss=0.4329, LR=0.000100
[2025-08-11 12:25:37,517][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003372] [Batch 03372/04869] [00:30:16/00:13:26, 0.539s/it]: train_loss_raw=0.4885, running_loss=0.4308, LR=0.000100
[2025-08-11 12:25:43,899][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003384] [Batch 03384/04869] [00:30:22/00:13:19, 0.539s/it]: train_loss_raw=0.4516, running_loss=0.4334, LR=0.000100
[2025-08-11 12:25:50,387][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003396] [Batch 03396/04869] [00:30:28/00:13:13, 0.539s/it]: train_loss_raw=0.4746, running_loss=0.4356, LR=0.000100
[2025-08-11 12:25:56,790][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003408] [Batch 03408/04869] [00:30:35/00:13:06, 0.539s/it]: train_loss_raw=0.3832, running_loss=0.4327, LR=0.000100
[2025-08-11 12:26:03,166][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003420] [Batch 03420/04869] [00:30:41/00:13:00, 0.539s/it]: train_loss_raw=0.4661, running_loss=0.4322, LR=0.000100
[2025-08-11 12:26:09,569][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003432] [Batch 03432/04869] [00:30:48/00:12:53, 0.539s/it]: train_loss_raw=0.4607, running_loss=0.4335, LR=0.000100
[2025-08-11 12:26:15,925][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003444] [Batch 03444/04869] [00:30:54/00:12:47, 0.538s/it]: train_loss_raw=0.5499, running_loss=0.4341, LR=0.000100
[2025-08-11 12:26:22,301][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003456] [Batch 03456/04869] [00:31:00/00:12:40, 0.538s/it]: train_loss_raw=0.3812, running_loss=0.4353, LR=0.000100
[2025-08-11 12:26:28,693][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003468] [Batch 03468/04869] [00:31:07/00:12:34, 0.538s/it]: train_loss_raw=0.3677, running_loss=0.4372, LR=0.000100
[2025-08-11 12:26:35,033][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003480] [Batch 03480/04869] [00:31:13/00:12:27, 0.538s/it]: train_loss_raw=0.4725, running_loss=0.4359, LR=0.000100
[2025-08-11 12:26:41,452][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003492] [Batch 03492/04869] [00:31:20/00:12:21, 0.538s/it]: train_loss_raw=0.4738, running_loss=0.4363, LR=0.000100
[2025-08-11 12:26:47,939][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003504] [Batch 03504/04869] [00:31:26/00:12:14, 0.538s/it]: train_loss_raw=0.3661, running_loss=0.4336, LR=0.000100
[2025-08-11 12:26:54,498][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003516] [Batch 03516/04869] [00:31:33/00:12:08, 0.538s/it]: train_loss_raw=0.4382, running_loss=0.4326, LR=0.000100
[2025-08-11 12:27:00,926][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003528] [Batch 03528/04869] [00:31:39/00:12:02, 0.538s/it]: train_loss_raw=0.4050, running_loss=0.4310, LR=0.000100
[2025-08-11 12:27:07,249][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003540] [Batch 03540/04869] [00:31:45/00:11:55, 0.538s/it]: train_loss_raw=0.4907, running_loss=0.4335, LR=0.000100
[2025-08-11 12:27:13,652][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003552] [Batch 03552/04869] [00:31:52/00:11:49, 0.538s/it]: train_loss_raw=0.4164, running_loss=0.4331, LR=0.000100
[2025-08-11 12:27:20,005][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003564] [Batch 03564/04869] [00:31:58/00:11:42, 0.538s/it]: train_loss_raw=0.3255, running_loss=0.4272, LR=0.000100
[2025-08-11 12:27:26,349][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003576] [Batch 03576/04869] [00:32:04/00:11:36, 0.538s/it]: train_loss_raw=0.5136, running_loss=0.4275, LR=0.000100
[2025-08-11 12:27:32,725][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003588] [Batch 03588/04869] [00:32:11/00:11:29, 0.538s/it]: train_loss_raw=0.4108, running_loss=0.4294, LR=0.000100
[2025-08-11 12:27:39,081][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003600] [Batch 03600/04869] [00:32:17/00:11:23, 0.538s/it]: train_loss_raw=0.3585, running_loss=0.4310, LR=0.000100
[2025-08-11 12:27:45,518][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003612] [Batch 03612/04869] [00:32:24/00:11:16, 0.538s/it]: train_loss_raw=0.5073, running_loss=0.4345, LR=0.000100
[2025-08-11 12:27:51,825][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003624] [Batch 03624/04869] [00:32:30/00:11:10, 0.538s/it]: train_loss_raw=0.3963, running_loss=0.4344, LR=0.000100
[2025-08-11 12:27:58,220][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003636] [Batch 03636/04869] [00:32:36/00:11:03, 0.538s/it]: train_loss_raw=0.4338, running_loss=0.4312, LR=0.000100
[2025-08-11 12:28:04,701][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003648] [Batch 03648/04869] [00:32:43/00:10:57, 0.538s/it]: train_loss_raw=0.4230, running_loss=0.4310, LR=0.000100
[2025-08-11 12:28:11,201][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003660] [Batch 03660/04869] [00:32:49/00:10:50, 0.538s/it]: train_loss_raw=0.5115, running_loss=0.4299, LR=0.000100
[2025-08-11 12:28:17,345][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003672] [Batch 03672/04869] [00:32:55/00:10:44, 0.538s/it]: train_loss_raw=0.4455, running_loss=0.4261, LR=0.000100
[2025-08-11 12:28:23,466][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003684] [Batch 03684/04869] [00:33:02/00:10:37, 0.538s/it]: train_loss_raw=0.5181, running_loss=0.4273, LR=0.000100
[2025-08-11 12:28:29,906][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003696] [Batch 03696/04869] [00:33:08/00:10:31, 0.538s/it]: train_loss_raw=0.4165, running_loss=0.4289, LR=0.000100
[2025-08-11 12:28:36,408][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003708] [Batch 03708/04869] [00:33:15/00:10:24, 0.538s/it]: train_loss_raw=0.3752, running_loss=0.4279, LR=0.000100
[2025-08-11 12:28:42,774][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003720] [Batch 03720/04869] [00:33:21/00:10:18, 0.538s/it]: train_loss_raw=0.4070, running_loss=0.4307, LR=0.000100
[2025-08-11 12:28:49,153][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003732] [Batch 03732/04869] [00:33:27/00:10:11, 0.538s/it]: train_loss_raw=0.4889, running_loss=0.4280, LR=0.000100
[2025-08-11 12:28:55,476][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003744] [Batch 03744/04869] [00:33:34/00:10:05, 0.538s/it]: train_loss_raw=0.4353, running_loss=0.4276, LR=0.000100
[2025-08-11 12:29:01,741][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003756] [Batch 03756/04869] [00:33:40/00:09:58, 0.538s/it]: train_loss_raw=0.4408, running_loss=0.4270, LR=0.000100
[2025-08-11 12:29:08,159][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003768] [Batch 03768/04869] [00:33:46/00:09:52, 0.538s/it]: train_loss_raw=0.4386, running_loss=0.4284, LR=0.000100
[2025-08-11 12:29:14,497][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003780] [Batch 03780/04869] [00:33:53/00:09:45, 0.538s/it]: train_loss_raw=0.4504, running_loss=0.4323, LR=0.000100
[2025-08-11 12:29:20,912][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003792] [Batch 03792/04869] [00:33:59/00:09:39, 0.538s/it]: train_loss_raw=0.2917, running_loss=0.4300, LR=0.000100
[2025-08-11 12:29:27,347][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003804] [Batch 03804/04869] [00:34:05/00:09:32, 0.538s/it]: train_loss_raw=0.3872, running_loss=0.4338, LR=0.000100
[2025-08-11 12:29:33,879][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003816] [Batch 03816/04869] [00:34:12/00:09:26, 0.538s/it]: train_loss_raw=0.4205, running_loss=0.4307, LR=0.000100
[2025-08-11 12:29:40,211][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003828] [Batch 03828/04869] [00:34:18/00:09:19, 0.538s/it]: train_loss_raw=0.4128, running_loss=0.4304, LR=0.000100
[2025-08-11 12:29:46,510][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003840] [Batch 03840/04869] [00:34:25/00:09:13, 0.538s/it]: train_loss_raw=0.3374, running_loss=0.4268, LR=0.000100
[2025-08-11 12:29:52,934][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003852] [Batch 03852/04869] [00:34:31/00:09:06, 0.538s/it]: train_loss_raw=0.3772, running_loss=0.4267, LR=0.000100
[2025-08-11 12:29:59,311][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003864] [Batch 03864/04869] [00:34:37/00:09:00, 0.538s/it]: train_loss_raw=0.3815, running_loss=0.4240, LR=0.000100
[2025-08-11 12:30:05,610][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003876] [Batch 03876/04869] [00:34:44/00:08:53, 0.538s/it]: train_loss_raw=0.4142, running_loss=0.4263, LR=0.000100
[2025-08-11 12:30:12,021][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003888] [Batch 03888/04869] [00:34:50/00:08:47, 0.538s/it]: train_loss_raw=0.4857, running_loss=0.4276, LR=0.000100
[2025-08-11 12:30:18,321][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003900] [Batch 03900/04869] [00:34:56/00:08:41, 0.538s/it]: train_loss_raw=0.3795, running_loss=0.4282, LR=0.000100
[2025-08-11 12:30:24,717][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003912] [Batch 03912/04869] [00:35:03/00:08:34, 0.538s/it]: train_loss_raw=0.5611, running_loss=0.4331, LR=0.000100
[2025-08-11 12:30:31,108][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003924] [Batch 03924/04869] [00:35:09/00:08:28, 0.538s/it]: train_loss_raw=0.4984, running_loss=0.4345, LR=0.000100
[2025-08-11 12:30:37,583][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003936] [Batch 03936/04869] [00:35:16/00:08:21, 0.538s/it]: train_loss_raw=0.3875, running_loss=0.4337, LR=0.000100
[2025-08-11 12:30:44,006][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003948] [Batch 03948/04869] [00:35:22/00:08:15, 0.538s/it]: train_loss_raw=0.4322, running_loss=0.4326, LR=0.000100
[2025-08-11 12:30:50,498][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003960] [Batch 03960/04869] [00:35:29/00:08:08, 0.538s/it]: train_loss_raw=0.4622, running_loss=0.4293, LR=0.000100
[2025-08-11 12:30:56,849][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003972] [Batch 03972/04869] [00:35:35/00:08:02, 0.538s/it]: train_loss_raw=0.5357, running_loss=0.4316, LR=0.000100
[2025-08-11 12:31:03,132][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003984] [Batch 03984/04869] [00:35:41/00:07:55, 0.538s/it]: train_loss_raw=0.3849, running_loss=0.4284, LR=0.000100
[2025-08-11 12:31:09,659][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003996] [Batch 03996/04869] [00:35:48/00:07:49, 0.538s/it]: train_loss_raw=0.3995, running_loss=0.4290, LR=0.000100
[2025-08-11 12:31:19,924][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004008] [Batch 04008/04869] [00:35:58/00:07:43, 0.539s/it]: train_loss_raw=0.4047, running_loss=0.4289, LR=0.000100
[2025-08-11 12:31:26,289][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004020] [Batch 04020/04869] [00:36:04/00:07:37, 0.539s/it]: train_loss_raw=0.3420, running_loss=0.4262, LR=0.000100
[2025-08-11 12:31:32,543][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004032] [Batch 04032/04869] [00:36:11/00:07:30, 0.538s/it]: train_loss_raw=0.4859, running_loss=0.4259, LR=0.000100
[2025-08-11 12:31:38,891][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004044] [Batch 04044/04869] [00:36:17/00:07:24, 0.538s/it]: train_loss_raw=0.4832, running_loss=0.4285, LR=0.000100
[2025-08-11 12:31:45,266][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004056] [Batch 04056/04869] [00:36:23/00:07:17, 0.538s/it]: train_loss_raw=0.5733, running_loss=0.4300, LR=0.000100
[2025-08-11 12:31:51,509][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004068] [Batch 04068/04869] [00:36:30/00:07:11, 0.538s/it]: train_loss_raw=0.4965, running_loss=0.4282, LR=0.000100
[2025-08-11 12:31:57,897][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004080] [Batch 04080/04869] [00:36:36/00:07:04, 0.538s/it]: train_loss_raw=0.4585, running_loss=0.4296, LR=0.000100
[2025-08-11 12:32:04,389][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004092] [Batch 04092/04869] [00:36:42/00:06:58, 0.538s/it]: train_loss_raw=0.3330, running_loss=0.4301, LR=0.000100
[2025-08-11 12:32:10,698][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004104] [Batch 04104/04869] [00:36:49/00:06:51, 0.538s/it]: train_loss_raw=0.4219, running_loss=0.4267, LR=0.000100
[2025-08-11 12:32:17,122][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004116] [Batch 04116/04869] [00:36:55/00:06:45, 0.538s/it]: train_loss_raw=0.4546, running_loss=0.4261, LR=0.000100
[2025-08-11 12:32:23,525][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004128] [Batch 04128/04869] [00:37:02/00:06:38, 0.538s/it]: train_loss_raw=0.4569, running_loss=0.4286, LR=0.000100
[2025-08-11 12:32:29,862][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004140] [Batch 04140/04869] [00:37:08/00:06:32, 0.538s/it]: train_loss_raw=0.4360, running_loss=0.4257, LR=0.000100
[2025-08-11 12:32:36,215][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004152] [Batch 04152/04869] [00:37:14/00:06:25, 0.538s/it]: train_loss_raw=0.3798, running_loss=0.4279, LR=0.000100
[2025-08-11 12:32:42,455][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004164] [Batch 04164/04869] [00:37:21/00:06:19, 0.538s/it]: train_loss_raw=0.4605, running_loss=0.4278, LR=0.000100
[2025-08-11 12:32:48,796][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004176] [Batch 04176/04869] [00:37:27/00:06:12, 0.538s/it]: train_loss_raw=0.3255, running_loss=0.4241, LR=0.000100
[2025-08-11 12:32:55,161][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004188] [Batch 04188/04869] [00:37:33/00:06:06, 0.538s/it]: train_loss_raw=0.4410, running_loss=0.4250, LR=0.000100
[2025-08-11 12:33:01,575][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004200] [Batch 04200/04869] [00:37:40/00:06:00, 0.538s/it]: train_loss_raw=0.4220, running_loss=0.4245, LR=0.000100
[2025-08-11 12:33:08,037][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004212] [Batch 04212/04869] [00:37:46/00:05:53, 0.538s/it]: train_loss_raw=0.4208, running_loss=0.4242, LR=0.000100
[2025-08-11 12:33:14,409][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004224] [Batch 04224/04869] [00:37:53/00:05:47, 0.538s/it]: train_loss_raw=0.4330, running_loss=0.4217, LR=0.000100
[2025-08-11 12:33:20,760][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004236] [Batch 04236/04869] [00:37:59/00:05:40, 0.538s/it]: train_loss_raw=0.4236, running_loss=0.4244, LR=0.000100
[2025-08-11 12:33:27,003][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004248] [Batch 04248/04869] [00:38:05/00:05:34, 0.538s/it]: train_loss_raw=0.4165, running_loss=0.4282, LR=0.000100
[2025-08-11 12:33:33,298][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004260] [Batch 04260/04869] [00:38:11/00:05:27, 0.538s/it]: train_loss_raw=0.5314, running_loss=0.4290, LR=0.000100
[2025-08-11 12:33:39,618][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004272] [Batch 04272/04869] [00:38:18/00:05:21, 0.538s/it]: train_loss_raw=0.4141, running_loss=0.4295, LR=0.000100
[2025-08-11 12:33:46,119][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004284] [Batch 04284/04869] [00:38:24/00:05:14, 0.538s/it]: train_loss_raw=0.5170, running_loss=0.4303, LR=0.000100
[2025-08-11 12:33:52,171][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004296] [Batch 04296/04869] [00:38:30/00:05:08, 0.538s/it]: train_loss_raw=0.4301, running_loss=0.4331, LR=0.000100
[2025-08-11 12:33:58,559][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004308] [Batch 04308/04869] [00:38:37/00:05:01, 0.538s/it]: train_loss_raw=0.5201, running_loss=0.4340, LR=0.000100
[2025-08-11 12:34:04,766][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004320] [Batch 04320/04869] [00:38:43/00:04:55, 0.538s/it]: train_loss_raw=0.5120, running_loss=0.4348, LR=0.000100
[2025-08-11 12:34:10,994][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004332] [Batch 04332/04869] [00:38:49/00:04:48, 0.538s/it]: train_loss_raw=0.4942, running_loss=0.4354, LR=0.000100
[2025-08-11 12:34:17,378][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004344] [Batch 04344/04869] [00:38:55/00:04:42, 0.538s/it]: train_loss_raw=0.4291, running_loss=0.4355, LR=0.000100
[2025-08-11 12:34:23,920][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004356] [Batch 04356/04869] [00:39:02/00:04:35, 0.538s/it]: train_loss_raw=0.4103, running_loss=0.4355, LR=0.000100
[2025-08-11 12:34:30,304][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004368] [Batch 04368/04869] [00:39:08/00:04:29, 0.538s/it]: train_loss_raw=0.4213, running_loss=0.4362, LR=0.000100
[2025-08-11 12:34:36,712][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004380] [Batch 04380/04869] [00:39:15/00:04:22, 0.538s/it]: train_loss_raw=0.5386, running_loss=0.4358, LR=0.000100
[2025-08-11 12:34:43,110][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004392] [Batch 04392/04869] [00:39:21/00:04:16, 0.538s/it]: train_loss_raw=0.3593, running_loss=0.4352, LR=0.000100
[2025-08-11 12:34:49,615][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004404] [Batch 04404/04869] [00:39:28/00:04:10, 0.538s/it]: train_loss_raw=0.5181, running_loss=0.4388, LR=0.000100
[2025-08-11 12:34:56,134][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004416] [Batch 04416/04869] [00:39:34/00:04:03, 0.538s/it]: train_loss_raw=0.4312, running_loss=0.4381, LR=0.000100
[2025-08-11 12:35:02,530][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004428] [Batch 04428/04869] [00:39:41/00:03:57, 0.538s/it]: train_loss_raw=0.4557, running_loss=0.4383, LR=0.000100
[2025-08-11 12:35:08,891][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004440] [Batch 04440/04869] [00:39:47/00:03:50, 0.538s/it]: train_loss_raw=0.5037, running_loss=0.4374, LR=0.000100
[2025-08-11 12:35:15,313][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004452] [Batch 04452/04869] [00:39:53/00:03:44, 0.538s/it]: train_loss_raw=0.5137, running_loss=0.4377, LR=0.000100
[2025-08-11 12:35:21,812][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004464] [Batch 04464/04869] [00:40:00/00:03:37, 0.538s/it]: train_loss_raw=0.4244, running_loss=0.4385, LR=0.000100
[2025-08-11 12:35:28,199][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004476] [Batch 04476/04869] [00:40:06/00:03:31, 0.538s/it]: train_loss_raw=0.4146, running_loss=0.4360, LR=0.000100
[2025-08-11 12:35:34,566][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004488] [Batch 04488/04869] [00:40:13/00:03:24, 0.538s/it]: train_loss_raw=0.4209, running_loss=0.4349, LR=0.000100
[2025-08-11 12:35:40,915][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004500] [Batch 04500/04869] [00:40:19/00:03:18, 0.538s/it]: train_loss_raw=0.4416, running_loss=0.4341, LR=0.000100
[2025-08-11 12:35:47,235][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004512] [Batch 04512/04869] [00:40:25/00:03:11, 0.538s/it]: train_loss_raw=0.4362, running_loss=0.4338, LR=0.000100
[2025-08-11 12:35:53,671][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004524] [Batch 04524/04869] [00:40:32/00:03:05, 0.538s/it]: train_loss_raw=0.5603, running_loss=0.4363, LR=0.000100
[2025-08-11 12:36:00,209][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004536] [Batch 04536/04869] [00:40:38/00:02:59, 0.538s/it]: train_loss_raw=0.5143, running_loss=0.4319, LR=0.000100
[2025-08-11 12:36:06,640][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004548] [Batch 04548/04869] [00:40:45/00:02:52, 0.538s/it]: train_loss_raw=0.3461, running_loss=0.4296, LR=0.000100
[2025-08-11 12:36:13,057][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004560] [Batch 04560/04869] [00:40:51/00:02:46, 0.538s/it]: train_loss_raw=0.3664, running_loss=0.4285, LR=0.000100
[2025-08-11 12:36:19,016][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004572] [Batch 04572/04869] [00:40:57/00:02:39, 0.538s/it]: train_loss_raw=0.3560, running_loss=0.4278, LR=0.000100
[2025-08-11 12:36:25,428][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004584] [Batch 04584/04869] [00:41:04/00:02:33, 0.538s/it]: train_loss_raw=0.4768, running_loss=0.4284, LR=0.000100
[2025-08-11 12:36:31,856][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004596] [Batch 04596/04869] [00:41:10/00:02:26, 0.538s/it]: train_loss_raw=0.4372, running_loss=0.4306, LR=0.000100
[2025-08-11 12:36:38,307][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004608] [Batch 04608/04869] [00:41:16/00:02:20, 0.538s/it]: train_loss_raw=0.4670, running_loss=0.4297, LR=0.000100
[2025-08-11 12:36:44,740][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004620] [Batch 04620/04869] [00:41:23/00:02:13, 0.538s/it]: train_loss_raw=0.4071, running_loss=0.4298, LR=0.000100
[2025-08-11 12:36:51,238][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004632] [Batch 04632/04869] [00:41:29/00:02:07, 0.538s/it]: train_loss_raw=0.4229, running_loss=0.4268, LR=0.000100
[2025-08-11 12:36:57,697][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004644] [Batch 04644/04869] [00:41:36/00:02:00, 0.538s/it]: train_loss_raw=0.4162, running_loss=0.4280, LR=0.000100
[2025-08-11 12:37:04,089][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004656] [Batch 04656/04869] [00:41:42/00:01:54, 0.538s/it]: train_loss_raw=0.4691, running_loss=0.4307, LR=0.000100
[2025-08-11 12:37:10,535][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004668] [Batch 04668/04869] [00:41:49/00:01:48, 0.538s/it]: train_loss_raw=0.4531, running_loss=0.4307, LR=0.000100
[2025-08-11 12:37:16,962][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004680] [Batch 04680/04869] [00:41:55/00:01:41, 0.538s/it]: train_loss_raw=0.3631, running_loss=0.4272, LR=0.000100
[2025-08-11 12:37:23,464][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004692] [Batch 04692/04869] [00:42:02/00:01:35, 0.538s/it]: train_loss_raw=0.3674, running_loss=0.4247, LR=0.000100
[2025-08-11 12:37:29,996][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004704] [Batch 04704/04869] [00:42:08/00:01:28, 0.538s/it]: train_loss_raw=0.4391, running_loss=0.4260, LR=0.000100
[2025-08-11 12:37:36,552][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004716] [Batch 04716/04869] [00:42:15/00:01:22, 0.538s/it]: train_loss_raw=0.3688, running_loss=0.4244, LR=0.000100
[2025-08-11 12:37:43,034][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004728] [Batch 04728/04869] [00:42:21/00:01:15, 0.538s/it]: train_loss_raw=0.4364, running_loss=0.4272, LR=0.000100
[2025-08-11 12:37:49,292][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004740] [Batch 04740/04869] [00:42:27/00:01:09, 0.538s/it]: train_loss_raw=0.3318, running_loss=0.4258, LR=0.000100
[2025-08-11 12:37:55,328][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004752] [Batch 04752/04869] [00:42:33/00:01:02, 0.537s/it]: train_loss_raw=0.4888, running_loss=0.4285, LR=0.000100
[2025-08-11 12:38:01,354][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004764] [Batch 04764/04869] [00:42:39/00:00:56, 0.537s/it]: train_loss_raw=0.3406, running_loss=0.4275, LR=0.000100
[2025-08-11 12:38:07,412][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004776] [Batch 04776/04869] [00:42:46/00:00:49, 0.537s/it]: train_loss_raw=0.3928, running_loss=0.4268, LR=0.000100
[2025-08-11 12:38:13,465][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004788] [Batch 04788/04869] [00:42:52/00:00:43, 0.537s/it]: train_loss_raw=0.4160, running_loss=0.4292, LR=0.000100
[2025-08-11 12:38:19,389][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004800] [Batch 04800/04869] [00:42:57/00:00:37, 0.537s/it]: train_loss_raw=0.5905, running_loss=0.4333, LR=0.000100
[2025-08-11 12:38:25,564][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004812] [Batch 04812/04869] [00:43:04/00:00:30, 0.537s/it]: train_loss_raw=0.3656, running_loss=0.4324, LR=0.000100
[2025-08-11 12:38:31,717][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004824] [Batch 04824/04869] [00:43:10/00:00:24, 0.537s/it]: train_loss_raw=0.4760, running_loss=0.4329, LR=0.000100
[2025-08-11 12:38:37,942][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004836] [Batch 04836/04869] [00:43:16/00:00:17, 0.537s/it]: train_loss_raw=0.4426, running_loss=0.4361, LR=0.000100
[2025-08-11 12:38:44,365][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004848] [Batch 04848/04869] [00:43:22/00:00:11, 0.537s/it]: train_loss_raw=0.3813, running_loss=0.4341, LR=0.000100
[2025-08-11 12:38:50,915][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004860] [Batch 04860/04869] [00:43:29/00:00:04, 0.537s/it]: train_loss_raw=0.4283, running_loss=0.4332, LR=0.000100
[2025-08-11 12:38:55,834][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-11 12:38:58,194][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00011/00062] [00:00:02/00:00:09, 0.197s/it]
[2025-08-11 12:39:32,140][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00023/00062] [00:00:36/00:00:57, 1.513s/it]
[2025-08-11 12:39:47,269][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00035/00062] [00:00:51/00:00:37, 1.429s/it]
[2025-08-11 12:40:02,259][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00047/00062] [00:01:06/00:00:19, 1.384s/it]
[2025-08-11 12:40:17,616][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00059/00062] [00:01:21/00:00:02, 1.363s/it]
[2025-08-11 12:40:31,907][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00009/00062] [00:01:36/00:08:19, 9.607s/it]
[2025-08-11 12:40:31,910][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=0.43387, valid_loss=0.39723
[2025-08-11 12:40:31,911][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-11 12:40:31,911][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.199
[2025-08-11 12:40:31,911][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.614
[2025-08-11 12:40:31,911][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.617
[2025-08-11 12:40:31,911][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.579
[2025-08-11 12:40:31,918][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:45:10, remaining time 21:50:05, 00:45:10 per epoch
[2025-08-11 12:40:33,422][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004872] [Batch 00003/04869] [00:00:01/00:32:29, 0.401s/it]: train_loss_raw=0.4073, running_loss=0.4394, LR=0.000100
[2025-08-11 12:40:40,006][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004884] [Batch 00015/04869] [00:00:07/00:41:59, 0.519s/it]: train_loss_raw=0.4263, running_loss=0.4352, LR=0.000100
[2025-08-11 12:40:46,581][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004896] [Batch 00027/04869] [00:00:14/00:42:55, 0.532s/it]: train_loss_raw=0.4795, running_loss=0.4361, LR=0.000100
[2025-08-11 12:40:52,986][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004908] [Batch 00039/04869] [00:00:20/00:42:51, 0.532s/it]: train_loss_raw=0.5085, running_loss=0.4358, LR=0.000100
[2025-08-11 12:40:59,243][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004920] [Batch 00051/04869] [00:00:27/00:42:32, 0.530s/it]: train_loss_raw=0.3948, running_loss=0.4350, LR=0.000100
[2025-08-11 12:41:05,520][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004932] [Batch 00063/04869] [00:00:33/00:42:20, 0.529s/it]: train_loss_raw=0.3944, running_loss=0.4329, LR=0.000100
[2025-08-11 12:41:11,893][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004944] [Batch 00075/04869] [00:00:39/00:42:15, 0.529s/it]: train_loss_raw=0.4251, running_loss=0.4312, LR=0.000100
[2025-08-11 12:41:18,229][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004956] [Batch 00087/04869] [00:00:46/00:42:08, 0.529s/it]: train_loss_raw=0.4118, running_loss=0.4292, LR=0.000100
[2025-08-11 12:41:24,548][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004968] [Batch 00099/04869] [00:00:52/00:42:01, 0.529s/it]: train_loss_raw=0.3528, running_loss=0.4252, LR=0.000100
[2025-08-11 12:41:31,129][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004980] [Batch 00111/04869] [00:00:58/00:42:05, 0.531s/it]: train_loss_raw=0.5572, running_loss=0.4298, LR=0.000100
[2025-08-11 12:41:37,621][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004992] [Batch 00123/04869] [00:01:05/00:42:03, 0.532s/it]: train_loss_raw=0.3590, running_loss=0.4303, LR=0.000100
[2025-08-11 12:41:43,874][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005004] [Batch 00135/04869] [00:01:11/00:41:52, 0.531s/it]: train_loss_raw=0.3364, running_loss=0.4268, LR=0.000100
[2025-08-11 12:41:50,213][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005016] [Batch 00147/04869] [00:01:17/00:41:45, 0.531s/it]: train_loss_raw=0.5191, running_loss=0.4281, LR=0.000100
[2025-08-11 12:41:56,584][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005028] [Batch 00159/04869] [00:01:24/00:41:39, 0.531s/it]: train_loss_raw=0.5088, running_loss=0.4287, LR=0.000100
[2025-08-11 12:42:02,992][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005040] [Batch 00171/04869] [00:01:30/00:41:33, 0.531s/it]: train_loss_raw=0.4758, running_loss=0.4281, LR=0.000100
[2025-08-11 12:42:09,435][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005052] [Batch 00183/04869] [00:01:37/00:41:29, 0.531s/it]: train_loss_raw=0.4715, running_loss=0.4313, LR=0.000100
[2025-08-11 12:42:15,842][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005064] [Batch 00195/04869] [00:01:43/00:41:23, 0.531s/it]: train_loss_raw=0.3915, running_loss=0.4345, LR=0.000100
[2025-08-11 12:42:22,197][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005076] [Batch 00207/04869] [00:01:49/00:41:16, 0.531s/it]: train_loss_raw=0.3933, running_loss=0.4388, LR=0.000100
[2025-08-11 12:42:28,571][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005088] [Batch 00219/04869] [00:01:56/00:41:10, 0.531s/it]: train_loss_raw=0.3627, running_loss=0.4343, LR=0.000100
[2025-08-11 12:42:34,930][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005100] [Batch 00231/04869] [00:02:02/00:41:03, 0.531s/it]: train_loss_raw=0.3253, running_loss=0.4336, LR=0.000100
[2025-08-11 12:42:41,332][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005112] [Batch 00243/04869] [00:02:09/00:40:57, 0.531s/it]: train_loss_raw=0.4447, running_loss=0.4330, LR=0.000100
[2025-08-11 12:42:47,676][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005124] [Batch 00255/04869] [00:02:15/00:40:50, 0.531s/it]: train_loss_raw=0.4621, running_loss=0.4318, LR=0.000100
[2025-08-11 12:42:53,971][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005136] [Batch 00267/04869] [00:02:21/00:40:43, 0.531s/it]: train_loss_raw=0.4335, running_loss=0.4336, LR=0.000100
[2025-08-11 12:43:00,341][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005148] [Batch 00279/04869] [00:02:28/00:40:36, 0.531s/it]: train_loss_raw=0.3836, running_loss=0.4334, LR=0.000100
[2025-08-11 12:43:06,566][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005160] [Batch 00291/04869] [00:02:34/00:40:28, 0.530s/it]: train_loss_raw=0.4697, running_loss=0.4346, LR=0.000100
[2025-08-11 12:43:12,772][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005172] [Batch 00303/04869] [00:02:40/00:40:19, 0.530s/it]: train_loss_raw=0.3064, running_loss=0.4357, LR=0.000100
[2025-08-11 12:43:19,008][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005184] [Batch 00315/04869] [00:02:46/00:40:11, 0.529s/it]: train_loss_raw=0.3339, running_loss=0.4353, LR=0.000100
[2025-08-11 12:43:25,395][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005196] [Batch 00327/04869] [00:02:53/00:40:05, 0.530s/it]: train_loss_raw=0.4020, running_loss=0.4345, LR=0.000100
[2025-08-11 12:43:31,747][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005208] [Batch 00339/04869] [00:02:59/00:39:58, 0.530s/it]: train_loss_raw=0.4911, running_loss=0.4329, LR=0.000100
[2025-08-11 12:43:38,251][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005220] [Batch 00351/04869] [00:03:06/00:39:54, 0.530s/it]: train_loss_raw=0.4374, running_loss=0.4335, LR=0.000100
[2025-08-11 12:43:44,632][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005232] [Batch 00363/04869] [00:03:12/00:39:48, 0.530s/it]: train_loss_raw=0.2606, running_loss=0.4300, LR=0.000100
[2025-08-11 12:43:51,024][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005244] [Batch 00375/04869] [00:03:18/00:39:42, 0.530s/it]: train_loss_raw=0.3903, running_loss=0.4331, LR=0.000100
[2025-08-11 12:43:57,400][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005256] [Batch 00387/04869] [00:03:25/00:39:36, 0.530s/it]: train_loss_raw=0.4715, running_loss=0.4348, LR=0.000100
[2025-08-11 12:44:03,726][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005268] [Batch 00399/04869] [00:03:31/00:39:29, 0.530s/it]: train_loss_raw=0.4274, running_loss=0.4331, LR=0.000100
[2025-08-11 12:44:10,069][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005280] [Batch 00411/04869] [00:03:37/00:39:22, 0.530s/it]: train_loss_raw=0.4885, running_loss=0.4338, LR=0.000100
[2025-08-11 12:44:16,370][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005292] [Batch 00423/04869] [00:03:44/00:39:15, 0.530s/it]: train_loss_raw=0.3954, running_loss=0.4322, LR=0.000100
[2025-08-11 12:44:22,689][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005304] [Batch 00435/04869] [00:03:50/00:39:09, 0.530s/it]: train_loss_raw=0.4825, running_loss=0.4319, LR=0.000100
[2025-08-11 12:44:29,047][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005316] [Batch 00447/04869] [00:03:56/00:39:02, 0.530s/it]: train_loss_raw=0.3941, running_loss=0.4316, LR=0.000100
[2025-08-11 12:44:35,485][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005328] [Batch 00459/04869] [00:04:03/00:38:57, 0.530s/it]: train_loss_raw=0.3743, running_loss=0.4326, LR=0.000100
[2025-08-11 12:44:41,819][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005340] [Batch 00471/04869] [00:04:09/00:38:50, 0.530s/it]: train_loss_raw=0.4086, running_loss=0.4256, LR=0.000100
[2025-08-11 12:44:48,154][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005352] [Batch 00483/04869] [00:04:15/00:38:44, 0.530s/it]: train_loss_raw=0.4706, running_loss=0.4266, LR=0.000100
[2025-08-11 12:44:54,367][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005364] [Batch 00495/04869] [00:04:22/00:38:36, 0.530s/it]: train_loss_raw=0.3997, running_loss=0.4283, LR=0.000100
[2025-08-11 12:45:00,735][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005376] [Batch 00507/04869] [00:04:28/00:38:30, 0.530s/it]: train_loss_raw=0.4934, running_loss=0.4311, LR=0.000100
[2025-08-11 12:45:07,057][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005388] [Batch 00519/04869] [00:04:34/00:38:23, 0.530s/it]: train_loss_raw=0.4890, running_loss=0.4295, LR=0.000100
[2025-08-11 12:45:13,558][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005400] [Batch 00531/04869] [00:04:41/00:38:18, 0.530s/it]: train_loss_raw=0.4535, running_loss=0.4293, LR=0.000100
[2025-08-11 12:45:19,909][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005412] [Batch 00543/04869] [00:04:47/00:38:11, 0.530s/it]: train_loss_raw=0.4209, running_loss=0.4280, LR=0.000100
[2025-08-11 12:45:26,163][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005424] [Batch 00555/04869] [00:04:53/00:38:04, 0.530s/it]: train_loss_raw=0.3885, running_loss=0.4262, LR=0.000100
[2025-08-11 12:45:32,477][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005436] [Batch 00567/04869] [00:05:00/00:37:58, 0.530s/it]: train_loss_raw=0.4715, running_loss=0.4268, LR=0.000100
[2025-08-11 12:45:38,895][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005448] [Batch 00579/04869] [00:05:06/00:37:52, 0.530s/it]: train_loss_raw=0.2921, running_loss=0.4276, LR=0.000100
[2025-08-11 12:45:45,345][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005460] [Batch 00591/04869] [00:05:13/00:37:46, 0.530s/it]: train_loss_raw=0.4105, running_loss=0.4241, LR=0.000100
[2025-08-11 12:45:51,729][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005472] [Batch 00603/04869] [00:05:19/00:37:40, 0.530s/it]: train_loss_raw=0.4356, running_loss=0.4237, LR=0.000100
[2025-08-11 12:45:58,185][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005484] [Batch 00615/04869] [00:05:25/00:37:34, 0.530s/it]: train_loss_raw=0.3956, running_loss=0.4247, LR=0.000100
[2025-08-11 12:46:04,487][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005496] [Batch 00627/04869] [00:05:32/00:37:27, 0.530s/it]: train_loss_raw=0.3867, running_loss=0.4229, LR=0.000100
[2025-08-11 12:46:10,889][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005508] [Batch 00639/04869] [00:05:38/00:37:21, 0.530s/it]: train_loss_raw=0.4840, running_loss=0.4273, LR=0.000100
[2025-08-11 12:46:17,295][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005520] [Batch 00651/04869] [00:05:45/00:37:15, 0.530s/it]: train_loss_raw=0.4448, running_loss=0.4219, LR=0.000100
[2025-08-11 12:46:23,385][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005532] [Batch 00663/04869] [00:05:51/00:37:07, 0.530s/it]: train_loss_raw=0.4373, running_loss=0.4247, LR=0.000100
[2025-08-11 12:46:29,435][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005544] [Batch 00675/04869] [00:05:57/00:36:59, 0.529s/it]: train_loss_raw=0.4177, running_loss=0.4213, LR=0.000100
[2025-08-11 12:46:35,563][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005556] [Batch 00687/04869] [00:06:03/00:36:51, 0.529s/it]: train_loss_raw=0.3510, running_loss=0.4199, LR=0.000100
[2025-08-11 12:46:41,991][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005568] [Batch 00699/04869] [00:06:09/00:36:45, 0.529s/it]: train_loss_raw=0.5868, running_loss=0.4186, LR=0.000100
[2025-08-11 12:46:48,159][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005580] [Batch 00711/04869] [00:06:15/00:36:38, 0.529s/it]: train_loss_raw=0.4126, running_loss=0.4166, LR=0.000100
[2025-08-11 12:46:54,206][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005592] [Batch 00723/04869] [00:06:21/00:36:30, 0.528s/it]: train_loss_raw=0.5688, running_loss=0.4177, LR=0.000100
[2025-08-11 12:47:00,750][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005604] [Batch 00735/04869] [00:06:28/00:36:25, 0.529s/it]: train_loss_raw=0.3503, running_loss=0.4141, LR=0.000100
[2025-08-11 12:47:07,151][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005616] [Batch 00747/04869] [00:06:34/00:36:19, 0.529s/it]: train_loss_raw=0.3984, running_loss=0.4165, LR=0.000100
[2025-08-11 12:47:13,602][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005628] [Batch 00759/04869] [00:06:41/00:36:13, 0.529s/it]: train_loss_raw=0.4408, running_loss=0.4166, LR=0.000100
[2025-08-11 12:47:19,984][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005640] [Batch 00771/04869] [00:06:47/00:36:07, 0.529s/it]: train_loss_raw=0.4330, running_loss=0.4196, LR=0.000100
[2025-08-11 12:47:26,395][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005652] [Batch 00783/04869] [00:06:54/00:36:01, 0.529s/it]: train_loss_raw=0.4091, running_loss=0.4209, LR=0.000100
[2025-08-11 12:47:32,819][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005664] [Batch 00795/04869] [00:07:00/00:35:55, 0.529s/it]: train_loss_raw=0.3924, running_loss=0.4203, LR=0.000100
[2025-08-11 12:47:39,365][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005676] [Batch 00807/04869] [00:07:07/00:35:50, 0.529s/it]: train_loss_raw=0.3444, running_loss=0.4183, LR=0.000100
[2025-08-11 12:47:45,860][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005688] [Batch 00819/04869] [00:07:13/00:35:44, 0.529s/it]: train_loss_raw=0.4609, running_loss=0.4179, LR=0.000100
[2025-08-11 12:47:52,352][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005700] [Batch 00831/04869] [00:07:20/00:35:38, 0.530s/it]: train_loss_raw=0.4968, running_loss=0.4188, LR=0.000100
[2025-08-11 12:47:58,733][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005712] [Batch 00843/04869] [00:07:26/00:35:32, 0.530s/it]: train_loss_raw=0.4446, running_loss=0.4184, LR=0.000100
[2025-08-11 12:48:05,150][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005724] [Batch 00855/04869] [00:07:32/00:35:26, 0.530s/it]: train_loss_raw=0.4346, running_loss=0.4182, LR=0.000100
[2025-08-11 12:48:11,635][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005736] [Batch 00867/04869] [00:07:39/00:35:20, 0.530s/it]: train_loss_raw=0.4928, running_loss=0.4169, LR=0.000100
[2025-08-11 12:48:18,273][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005748] [Batch 00879/04869] [00:07:46/00:35:15, 0.530s/it]: train_loss_raw=0.3815, running_loss=0.4133, LR=0.000100
[2025-08-11 12:48:24,671][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005760] [Batch 00891/04869] [00:07:52/00:35:09, 0.530s/it]: train_loss_raw=0.4378, running_loss=0.4147, LR=0.000100
[2025-08-11 12:48:31,203][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005772] [Batch 00903/04869] [00:07:58/00:35:03, 0.530s/it]: train_loss_raw=0.3632, running_loss=0.4118, LR=0.000100
[2025-08-11 12:48:37,209][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005784] [Batch 00915/04869] [00:08:04/00:34:55, 0.530s/it]: train_loss_raw=0.3503, running_loss=0.4100, LR=0.000100
[2025-08-11 12:48:43,238][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005796] [Batch 00927/04869] [00:08:11/00:34:48, 0.530s/it]: train_loss_raw=0.4778, running_loss=0.4113, LR=0.000100
[2025-08-11 12:48:49,405][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005808] [Batch 00939/04869] [00:08:17/00:34:40, 0.529s/it]: train_loss_raw=0.3535, running_loss=0.4119, LR=0.000100
[2025-08-11 12:48:55,869][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005820] [Batch 00951/04869] [00:08:23/00:34:34, 0.530s/it]: train_loss_raw=0.4063, running_loss=0.4126, LR=0.000100
[2025-08-11 12:49:02,346][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005832] [Batch 00963/04869] [00:08:30/00:34:29, 0.530s/it]: train_loss_raw=0.3968, running_loss=0.4142, LR=0.000100
[2025-08-11 12:49:08,545][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005844] [Batch 00975/04869] [00:08:36/00:34:22, 0.530s/it]: train_loss_raw=0.4704, running_loss=0.4160, LR=0.000100
[2025-08-11 12:49:14,904][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005856] [Batch 00987/04869] [00:08:42/00:34:15, 0.530s/it]: train_loss_raw=0.4186, running_loss=0.4146, LR=0.000100
[2025-08-11 12:49:20,891][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005868] [Batch 00999/04869] [00:08:48/00:34:08, 0.529s/it]: train_loss_raw=0.4413, running_loss=0.4185, LR=0.000100
[2025-08-11 12:49:27,268][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005880] [Batch 01011/04869] [00:08:55/00:34:01, 0.529s/it]: train_loss_raw=0.3953, running_loss=0.4211, LR=0.000100
[2025-08-11 12:49:33,313][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005892] [Batch 01023/04869] [00:09:01/00:33:54, 0.529s/it]: train_loss_raw=0.4190, running_loss=0.4204, LR=0.000100
[2025-08-11 12:49:39,743][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005904] [Batch 01035/04869] [00:09:07/00:33:48, 0.529s/it]: train_loss_raw=0.4242, running_loss=0.4186, LR=0.000100
[2025-08-11 12:49:46,170][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005916] [Batch 01047/04869] [00:09:13/00:33:42, 0.529s/it]: train_loss_raw=0.4766, running_loss=0.4229, LR=0.000100
[2025-08-11 12:49:52,648][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005928] [Batch 01059/04869] [00:09:20/00:33:36, 0.529s/it]: train_loss_raw=0.4695, running_loss=0.4239, LR=0.000100
[2025-08-11 12:49:58,851][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005940] [Batch 01071/04869] [00:09:26/00:33:29, 0.529s/it]: train_loss_raw=0.3844, running_loss=0.4242, LR=0.000100
[2025-08-11 12:50:04,889][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005952] [Batch 01083/04869] [00:09:32/00:33:21, 0.529s/it]: train_loss_raw=0.4927, running_loss=0.4275, LR=0.000100
[2025-08-11 12:50:11,173][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005964] [Batch 01095/04869] [00:09:38/00:33:15, 0.529s/it]: train_loss_raw=0.4056, running_loss=0.4272, LR=0.000100
[2025-08-11 12:50:17,536][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005976] [Batch 01107/04869] [00:09:45/00:33:09, 0.529s/it]: train_loss_raw=0.4307, running_loss=0.4282, LR=0.000100
[2025-08-11 12:50:23,897][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005988] [Batch 01119/04869] [00:09:51/00:33:02, 0.529s/it]: train_loss_raw=0.3359, running_loss=0.4287, LR=0.000100
[2025-08-11 12:50:30,238][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006000] [Batch 01131/04869] [00:09:58/00:32:56, 0.529s/it]: train_loss_raw=0.4203, running_loss=0.4262, LR=0.000100
[2025-08-11 12:50:40,898][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006012] [Batch 01143/04869] [00:10:08/00:33:04, 0.533s/it]: train_loss_raw=0.5126, running_loss=0.4274, LR=0.000100
[2025-08-11 12:50:47,276][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006024] [Batch 01155/04869] [00:10:15/00:32:57, 0.533s/it]: train_loss_raw=0.3159, running_loss=0.4233, LR=0.000100
[2025-08-11 12:50:53,661][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006036] [Batch 01167/04869] [00:10:21/00:32:51, 0.533s/it]: train_loss_raw=0.4894, running_loss=0.4229, LR=0.000100
[2025-08-11 12:51:00,005][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006048] [Batch 01179/04869] [00:10:27/00:32:44, 0.532s/it]: train_loss_raw=0.4561, running_loss=0.4221, LR=0.000100
[2025-08-11 12:51:06,552][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006060] [Batch 01191/04869] [00:10:34/00:32:38, 0.533s/it]: train_loss_raw=0.4283, running_loss=0.4203, LR=0.000100
[2025-08-11 12:51:12,758][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006072] [Batch 01203/04869] [00:10:40/00:32:31, 0.532s/it]: train_loss_raw=0.4040, running_loss=0.4220, LR=0.000100
[2025-08-11 12:51:19,212][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006084] [Batch 01215/04869] [00:10:46/00:32:25, 0.533s/it]: train_loss_raw=0.4176, running_loss=0.4206, LR=0.000100
[2025-08-11 12:51:25,596][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006096] [Batch 01227/04869] [00:10:53/00:32:19, 0.532s/it]: train_loss_raw=0.4216, running_loss=0.4192, LR=0.000100
[2025-08-11 12:51:31,940][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006108] [Batch 01239/04869] [00:10:59/00:32:12, 0.532s/it]: train_loss_raw=0.4995, running_loss=0.4237, LR=0.000100
[2025-08-11 12:51:37,942][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006120] [Batch 01251/04869] [00:11:05/00:32:05, 0.532s/it]: train_loss_raw=0.3657, running_loss=0.4209, LR=0.000100
[2025-08-11 12:51:44,201][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006132] [Batch 01263/04869] [00:11:11/00:31:58, 0.532s/it]: train_loss_raw=0.3709, running_loss=0.4216, LR=0.000100
[2025-08-11 12:51:50,696][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006144] [Batch 01275/04869] [00:11:18/00:31:52, 0.532s/it]: train_loss_raw=0.4195, running_loss=0.4232, LR=0.000100
[2025-08-11 12:51:57,075][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006156] [Batch 01287/04869] [00:11:24/00:31:46, 0.532s/it]: train_loss_raw=0.3199, running_loss=0.4213, LR=0.000100
[2025-08-11 12:52:03,064][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006168] [Batch 01299/04869] [00:11:30/00:31:38, 0.532s/it]: train_loss_raw=0.4461, running_loss=0.4208, LR=0.000100
[2025-08-11 12:52:09,126][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006180] [Batch 01311/04869] [00:11:36/00:31:31, 0.532s/it]: train_loss_raw=0.3134, running_loss=0.4182, LR=0.000100
[2025-08-11 12:52:15,336][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006192] [Batch 01323/04869] [00:11:43/00:31:24, 0.531s/it]: train_loss_raw=0.3754, running_loss=0.4211, LR=0.000100
[2025-08-11 12:52:21,665][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006204] [Batch 01335/04869] [00:11:49/00:31:18, 0.531s/it]: train_loss_raw=0.4426, running_loss=0.4204, LR=0.000100
[2025-08-11 12:52:28,144][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006216] [Batch 01347/04869] [00:11:55/00:31:11, 0.531s/it]: train_loss_raw=0.3669, running_loss=0.4206, LR=0.000100
[2025-08-11 12:52:34,566][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006228] [Batch 01359/04869] [00:12:02/00:31:05, 0.532s/it]: train_loss_raw=0.4376, running_loss=0.4209, LR=0.000100
[2025-08-11 12:52:41,039][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006240] [Batch 01371/04869] [00:12:08/00:30:59, 0.532s/it]: train_loss_raw=0.4080, running_loss=0.4183, LR=0.000100
[2025-08-11 12:52:47,357][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006252] [Batch 01383/04869] [00:12:15/00:30:52, 0.532s/it]: train_loss_raw=0.3837, running_loss=0.4190, LR=0.000100
[2025-08-11 12:52:53,590][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006264] [Batch 01395/04869] [00:12:21/00:30:46, 0.531s/it]: train_loss_raw=0.3909, running_loss=0.4166, LR=0.000100
[2025-08-11 12:52:59,969][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006276] [Batch 01407/04869] [00:12:27/00:30:39, 0.531s/it]: train_loss_raw=0.4539, running_loss=0.4172, LR=0.000100
[2025-08-11 12:53:06,297][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006288] [Batch 01419/04869] [00:12:34/00:30:33, 0.531s/it]: train_loss_raw=0.4022, running_loss=0.4174, LR=0.000100
[2025-08-11 12:53:12,601][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006300] [Batch 01431/04869] [00:12:40/00:30:26, 0.531s/it]: train_loss_raw=0.3989, running_loss=0.4186, LR=0.000100
[2025-08-11 12:53:18,966][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006312] [Batch 01443/04869] [00:12:46/00:30:20, 0.531s/it]: train_loss_raw=0.4594, running_loss=0.4240, LR=0.000100
[2025-08-11 12:53:25,406][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006324] [Batch 01455/04869] [00:12:53/00:30:14, 0.531s/it]: train_loss_raw=0.4229, running_loss=0.4218, LR=0.000100
[2025-08-11 12:53:31,741][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006336] [Batch 01467/04869] [00:12:59/00:30:07, 0.531s/it]: train_loss_raw=0.4497, running_loss=0.4210, LR=0.000100
[2025-08-11 12:53:38,018][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006348] [Batch 01479/04869] [00:13:05/00:30:01, 0.531s/it]: train_loss_raw=0.3363, running_loss=0.4224, LR=0.000100
[2025-08-11 12:53:44,421][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006360] [Batch 01491/04869] [00:13:12/00:29:54, 0.531s/it]: train_loss_raw=0.4332, running_loss=0.4235, LR=0.000100
[2025-08-11 12:53:50,802][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006372] [Batch 01503/04869] [00:13:18/00:29:48, 0.531s/it]: train_loss_raw=0.4609, running_loss=0.4229, LR=0.000100
[2025-08-11 12:53:57,268][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006384] [Batch 01515/04869] [00:13:25/00:29:42, 0.531s/it]: train_loss_raw=0.4053, running_loss=0.4240, LR=0.000100
[2025-08-11 12:54:03,636][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006396] [Batch 01527/04869] [00:13:31/00:29:35, 0.531s/it]: train_loss_raw=0.4778, running_loss=0.4224, LR=0.000100
[2025-08-11 12:54:09,979][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006408] [Batch 01539/04869] [00:13:37/00:29:29, 0.531s/it]: train_loss_raw=0.4657, running_loss=0.4215, LR=0.000100
[2025-08-11 12:54:16,508][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006420] [Batch 01551/04869] [00:13:44/00:29:23, 0.531s/it]: train_loss_raw=0.5295, running_loss=0.4202, LR=0.000100
[2025-08-11 12:54:22,786][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006432] [Batch 01563/04869] [00:13:50/00:29:16, 0.531s/it]: train_loss_raw=0.3570, running_loss=0.4199, LR=0.000100
[2025-08-11 12:54:29,142][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006444] [Batch 01575/04869] [00:13:56/00:29:10, 0.531s/it]: train_loss_raw=0.4522, running_loss=0.4222, LR=0.000100
[2025-08-11 12:54:35,535][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006456] [Batch 01587/04869] [00:14:03/00:29:04, 0.531s/it]: train_loss_raw=0.4641, running_loss=0.4224, LR=0.000100
[2025-08-11 12:54:41,907][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006468] [Batch 01599/04869] [00:14:09/00:28:57, 0.531s/it]: train_loss_raw=0.4688, running_loss=0.4213, LR=0.000100
[2025-08-11 12:54:47,880][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006480] [Batch 01611/04869] [00:14:15/00:28:50, 0.531s/it]: train_loss_raw=0.4090, running_loss=0.4217, LR=0.000100
[2025-08-11 12:54:54,024][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006492] [Batch 01623/04869] [00:14:21/00:28:43, 0.531s/it]: train_loss_raw=0.4211, running_loss=0.4219, LR=0.000100
[2025-08-11 12:55:00,294][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006504] [Batch 01635/04869] [00:14:28/00:28:37, 0.531s/it]: train_loss_raw=0.3986, running_loss=0.4246, LR=0.000100
[2025-08-11 12:55:06,760][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006516] [Batch 01647/04869] [00:14:34/00:28:30, 0.531s/it]: train_loss_raw=0.3900, running_loss=0.4216, LR=0.000100
[2025-08-11 12:55:13,187][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006528] [Batch 01659/04869] [00:14:40/00:28:24, 0.531s/it]: train_loss_raw=0.3305, running_loss=0.4212, LR=0.000100
[2025-08-11 12:55:19,554][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006540] [Batch 01671/04869] [00:14:47/00:28:18, 0.531s/it]: train_loss_raw=0.4699, running_loss=0.4243, LR=0.000100
[2025-08-11 12:55:26,011][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006552] [Batch 01683/04869] [00:14:53/00:28:11, 0.531s/it]: train_loss_raw=0.3918, running_loss=0.4235, LR=0.000100
[2025-08-11 12:55:32,246][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006564] [Batch 01695/04869] [00:15:00/00:28:05, 0.531s/it]: train_loss_raw=0.3412, running_loss=0.4203, LR=0.000100
[2025-08-11 12:55:38,354][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006576] [Batch 01707/04869] [00:15:06/00:27:58, 0.531s/it]: train_loss_raw=0.4352, running_loss=0.4192, LR=0.000100
[2025-08-11 12:55:44,578][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006588] [Batch 01719/04869] [00:15:12/00:27:51, 0.531s/it]: train_loss_raw=0.4250, running_loss=0.4204, LR=0.000100
[2025-08-11 12:55:50,788][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006600] [Batch 01731/04869] [00:15:18/00:27:45, 0.531s/it]: train_loss_raw=0.4016, running_loss=0.4229, LR=0.000100
[2025-08-11 12:55:57,068][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006612] [Batch 01743/04869] [00:15:24/00:27:38, 0.531s/it]: train_loss_raw=0.4857, running_loss=0.4188, LR=0.000100
[2025-08-11 12:56:03,410][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006624] [Batch 01755/04869] [00:15:31/00:27:32, 0.531s/it]: train_loss_raw=0.4279, running_loss=0.4189, LR=0.000100
[2025-08-11 12:56:09,650][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006636] [Batch 01767/04869] [00:15:37/00:27:25, 0.531s/it]: train_loss_raw=0.4916, running_loss=0.4189, LR=0.000100
[2025-08-11 12:56:15,754][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006648] [Batch 01779/04869] [00:15:43/00:27:18, 0.530s/it]: train_loss_raw=0.3793, running_loss=0.4224, LR=0.000100
[2025-08-11 12:56:21,887][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006660] [Batch 01791/04869] [00:15:49/00:27:12, 0.530s/it]: train_loss_raw=0.4493, running_loss=0.4225, LR=0.000100
[2025-08-11 12:56:28,250][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006672] [Batch 01803/04869] [00:15:56/00:27:05, 0.530s/it]: train_loss_raw=0.3969, running_loss=0.4275, LR=0.000100
[2025-08-11 12:56:34,658][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006684] [Batch 01815/04869] [00:16:02/00:26:59, 0.530s/it]: train_loss_raw=0.3999, running_loss=0.4273, LR=0.000100
[2025-08-11 12:56:40,957][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006696] [Batch 01827/04869] [00:16:08/00:26:52, 0.530s/it]: train_loss_raw=0.4075, running_loss=0.4239, LR=0.000100
[2025-08-11 12:56:47,266][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006708] [Batch 01839/04869] [00:16:15/00:26:46, 0.530s/it]: train_loss_raw=0.3775, running_loss=0.4244, LR=0.000100
[2025-08-11 12:56:53,797][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006720] [Batch 01851/04869] [00:16:21/00:26:40, 0.530s/it]: train_loss_raw=0.3902, running_loss=0.4200, LR=0.000100
[2025-08-11 12:57:00,292][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006732] [Batch 01863/04869] [00:16:28/00:26:34, 0.530s/it]: train_loss_raw=0.4250, running_loss=0.4186, LR=0.000100
[2025-08-11 12:57:06,615][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006744] [Batch 01875/04869] [00:16:34/00:26:27, 0.530s/it]: train_loss_raw=0.3821, running_loss=0.4184, LR=0.000100
[2025-08-11 12:57:12,902][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006756] [Batch 01887/04869] [00:16:40/00:26:21, 0.530s/it]: train_loss_raw=0.3758, running_loss=0.4172, LR=0.000100
[2025-08-11 12:57:19,246][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006768] [Batch 01899/04869] [00:16:47/00:26:14, 0.530s/it]: train_loss_raw=0.3468, running_loss=0.4174, LR=0.000100
[2025-08-11 12:57:25,422][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006780] [Batch 01911/04869] [00:16:53/00:26:08, 0.530s/it]: train_loss_raw=0.5487, running_loss=0.4192, LR=0.000100
[2025-08-11 12:57:31,723][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006792] [Batch 01923/04869] [00:16:59/00:26:01, 0.530s/it]: train_loss_raw=0.2895, running_loss=0.4208, LR=0.000100
[2025-08-11 12:57:38,096][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006804] [Batch 01935/04869] [00:17:05/00:25:55, 0.530s/it]: train_loss_raw=0.5484, running_loss=0.4219, LR=0.000100
[2025-08-11 12:57:44,409][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006816] [Batch 01947/04869] [00:17:12/00:25:49, 0.530s/it]: train_loss_raw=0.3750, running_loss=0.4206, LR=0.000100
[2025-08-11 12:57:50,762][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006828] [Batch 01959/04869] [00:17:18/00:25:42, 0.530s/it]: train_loss_raw=0.4912, running_loss=0.4214, LR=0.000100
[2025-08-11 12:57:57,092][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006840] [Batch 01971/04869] [00:17:24/00:25:36, 0.530s/it]: train_loss_raw=0.2987, running_loss=0.4196, LR=0.000100
[2025-08-11 12:58:03,438][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006852] [Batch 01983/04869] [00:17:31/00:25:29, 0.530s/it]: train_loss_raw=0.3147, running_loss=0.4148, LR=0.000100
[2025-08-11 12:58:09,803][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006864] [Batch 01995/04869] [00:17:37/00:25:23, 0.530s/it]: train_loss_raw=0.4920, running_loss=0.4155, LR=0.000100
[2025-08-11 12:58:16,162][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006876] [Batch 02007/04869] [00:17:43/00:25:17, 0.530s/it]: train_loss_raw=0.4220, running_loss=0.4170, LR=0.000100
[2025-08-11 12:58:22,545][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006888] [Batch 02019/04869] [00:17:50/00:25:10, 0.530s/it]: train_loss_raw=0.4053, running_loss=0.4199, LR=0.000100
[2025-08-11 12:58:29,062][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006900] [Batch 02031/04869] [00:17:56/00:25:04, 0.530s/it]: train_loss_raw=0.4276, running_loss=0.4153, LR=0.000100
[2025-08-11 12:58:35,502][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006912] [Batch 02043/04869] [00:18:03/00:24:58, 0.530s/it]: train_loss_raw=0.4319, running_loss=0.4152, LR=0.000100
[2025-08-11 12:58:41,771][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006924] [Batch 02055/04869] [00:18:09/00:24:51, 0.530s/it]: train_loss_raw=0.4881, running_loss=0.4156, LR=0.000100
[2025-08-11 12:58:48,309][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006936] [Batch 02067/04869] [00:18:16/00:24:45, 0.530s/it]: train_loss_raw=0.4305, running_loss=0.4172, LR=0.000100
[2025-08-11 12:58:54,653][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006948] [Batch 02079/04869] [00:18:22/00:24:39, 0.530s/it]: train_loss_raw=0.4332, running_loss=0.4211, LR=0.000100
[2025-08-11 12:59:01,022][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006960] [Batch 02091/04869] [00:18:28/00:24:33, 0.530s/it]: train_loss_raw=0.3926, running_loss=0.4215, LR=0.000100
[2025-08-11 12:59:07,391][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006972] [Batch 02103/04869] [00:18:35/00:24:26, 0.530s/it]: train_loss_raw=0.4277, running_loss=0.4199, LR=0.000100
[2025-08-11 12:59:13,812][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006984] [Batch 02115/04869] [00:18:41/00:24:20, 0.530s/it]: train_loss_raw=0.3232, running_loss=0.4181, LR=0.000100
[2025-08-11 12:59:20,184][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006996] [Batch 02127/04869] [00:18:47/00:24:14, 0.530s/it]: train_loss_raw=0.4886, running_loss=0.4203, LR=0.000100
[2025-08-11 12:59:26,549][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007008] [Batch 02139/04869] [00:18:54/00:24:07, 0.530s/it]: train_loss_raw=0.3680, running_loss=0.4197, LR=0.000100
[2025-08-11 12:59:32,952][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007020] [Batch 02151/04869] [00:19:00/00:24:01, 0.530s/it]: train_loss_raw=0.4302, running_loss=0.4197, LR=0.000100
[2025-08-11 12:59:39,314][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007032] [Batch 02163/04869] [00:19:07/00:23:55, 0.530s/it]: train_loss_raw=0.4506, running_loss=0.4197, LR=0.000100
[2025-08-11 12:59:45,586][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007044] [Batch 02175/04869] [00:19:13/00:23:48, 0.530s/it]: train_loss_raw=0.4099, running_loss=0.4168, LR=0.000100
[2025-08-11 12:59:51,944][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007056] [Batch 02187/04869] [00:19:19/00:23:42, 0.530s/it]: train_loss_raw=0.4749, running_loss=0.4171, LR=0.000100
[2025-08-11 12:59:58,237][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007068] [Batch 02199/04869] [00:19:26/00:23:35, 0.530s/it]: train_loss_raw=0.4708, running_loss=0.4166, LR=0.000100
[2025-08-11 13:00:04,598][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007080] [Batch 02211/04869] [00:19:32/00:23:29, 0.530s/it]: train_loss_raw=0.4812, running_loss=0.4174, LR=0.000100
[2025-08-11 13:00:10,980][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007092] [Batch 02223/04869] [00:19:38/00:23:23, 0.530s/it]: train_loss_raw=0.4360, running_loss=0.4209, LR=0.000100
[2025-08-11 13:00:17,388][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007104] [Batch 02235/04869] [00:19:45/00:23:16, 0.530s/it]: train_loss_raw=0.4206, running_loss=0.4254, LR=0.000100
[2025-08-11 13:00:23,778][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007116] [Batch 02247/04869] [00:19:51/00:23:10, 0.530s/it]: train_loss_raw=0.3790, running_loss=0.4237, LR=0.000100
[2025-08-11 13:00:30,133][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007128] [Batch 02259/04869] [00:19:57/00:23:04, 0.530s/it]: train_loss_raw=0.3733, running_loss=0.4248, LR=0.000100
[2025-08-11 13:00:36,492][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007140] [Batch 02271/04869] [00:20:04/00:22:57, 0.530s/it]: train_loss_raw=0.3397, running_loss=0.4230, LR=0.000100
[2025-08-11 13:00:42,828][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007152] [Batch 02283/04869] [00:20:10/00:22:51, 0.530s/it]: train_loss_raw=0.3467, running_loss=0.4218, LR=0.000100
[2025-08-11 13:00:49,141][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007164] [Batch 02295/04869] [00:20:16/00:22:44, 0.530s/it]: train_loss_raw=0.3570, running_loss=0.4204, LR=0.000100
[2025-08-11 13:00:55,434][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007176] [Batch 02307/04869] [00:20:23/00:22:38, 0.530s/it]: train_loss_raw=0.4271, running_loss=0.4205, LR=0.000100
[2025-08-11 13:01:01,795][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007188] [Batch 02319/04869] [00:20:29/00:22:32, 0.530s/it]: train_loss_raw=0.4312, running_loss=0.4234, LR=0.000100
[2025-08-11 13:01:08,213][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007200] [Batch 02331/04869] [00:20:35/00:22:25, 0.530s/it]: train_loss_raw=0.4428, running_loss=0.4211, LR=0.000100
[2025-08-11 13:01:14,641][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007212] [Batch 02343/04869] [00:20:42/00:22:19, 0.530s/it]: train_loss_raw=0.3760, running_loss=0.4205, LR=0.000100
[2025-08-11 13:01:21,035][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007224] [Batch 02355/04869] [00:20:48/00:22:13, 0.530s/it]: train_loss_raw=0.3221, running_loss=0.4202, LR=0.000100
[2025-08-11 13:01:27,357][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007236] [Batch 02367/04869] [00:20:55/00:22:06, 0.530s/it]: train_loss_raw=0.4437, running_loss=0.4221, LR=0.000100
[2025-08-11 13:01:33,766][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007248] [Batch 02379/04869] [00:21:01/00:22:00, 0.530s/it]: train_loss_raw=0.3762, running_loss=0.4221, LR=0.000100
[2025-08-11 13:01:40,202][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007260] [Batch 02391/04869] [00:21:07/00:21:54, 0.530s/it]: train_loss_raw=0.4009, running_loss=0.4229, LR=0.000100
[2025-08-11 13:01:46,515][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007272] [Batch 02403/04869] [00:21:14/00:21:47, 0.530s/it]: train_loss_raw=0.3623, running_loss=0.4228, LR=0.000100
[2025-08-11 13:01:52,842][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007284] [Batch 02415/04869] [00:21:20/00:21:41, 0.530s/it]: train_loss_raw=0.4466, running_loss=0.4207, LR=0.000100
[2025-08-11 13:01:59,191][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007296] [Batch 02427/04869] [00:21:26/00:21:34, 0.530s/it]: train_loss_raw=0.4517, running_loss=0.4218, LR=0.000100
[2025-08-11 13:02:05,578][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007308] [Batch 02439/04869] [00:21:33/00:21:28, 0.530s/it]: train_loss_raw=0.4266, running_loss=0.4226, LR=0.000100
[2025-08-11 13:02:11,933][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007320] [Batch 02451/04869] [00:21:39/00:21:22, 0.530s/it]: train_loss_raw=0.4909, running_loss=0.4227, LR=0.000100
[2025-08-11 13:02:18,312][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007332] [Batch 02463/04869] [00:21:46/00:21:15, 0.530s/it]: train_loss_raw=0.3054, running_loss=0.4223, LR=0.000100
[2025-08-11 13:02:24,654][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007344] [Batch 02475/04869] [00:21:52/00:21:09, 0.530s/it]: train_loss_raw=0.5687, running_loss=0.4255, LR=0.000100
[2025-08-11 13:02:31,168][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007356] [Batch 02487/04869] [00:21:58/00:21:03, 0.530s/it]: train_loss_raw=0.3529, running_loss=0.4238, LR=0.000100
[2025-08-11 13:02:37,490][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007368] [Batch 02499/04869] [00:22:05/00:20:56, 0.530s/it]: train_loss_raw=0.5212, running_loss=0.4239, LR=0.000100
[2025-08-11 13:02:43,969][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007380] [Batch 02511/04869] [00:22:11/00:20:50, 0.530s/it]: train_loss_raw=0.4654, running_loss=0.4235, LR=0.000100
[2025-08-11 13:02:50,542][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007392] [Batch 02523/04869] [00:22:18/00:20:44, 0.530s/it]: train_loss_raw=0.3807, running_loss=0.4252, LR=0.000100
[2025-08-11 13:02:56,855][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007404] [Batch 02535/04869] [00:22:24/00:20:38, 0.530s/it]: train_loss_raw=0.3921, running_loss=0.4226, LR=0.000100
[2025-08-11 13:03:03,361][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007416] [Batch 02547/04869] [00:22:31/00:20:31, 0.530s/it]: train_loss_raw=0.4305, running_loss=0.4214, LR=0.000100
[2025-08-11 13:03:09,622][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007428] [Batch 02559/04869] [00:22:37/00:20:25, 0.530s/it]: train_loss_raw=0.4479, running_loss=0.4236, LR=0.000100
[2025-08-11 13:03:15,617][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007440] [Batch 02571/04869] [00:22:43/00:20:18, 0.530s/it]: train_loss_raw=0.3108, running_loss=0.4203, LR=0.000100
[2025-08-11 13:03:21,762][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007452] [Batch 02583/04869] [00:22:49/00:20:12, 0.530s/it]: train_loss_raw=0.4502, running_loss=0.4188, LR=0.000100
[2025-08-11 13:03:28,000][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007464] [Batch 02595/04869] [00:22:55/00:20:05, 0.530s/it]: train_loss_raw=0.4549, running_loss=0.4185, LR=0.000100
[2025-08-11 13:03:34,321][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007476] [Batch 02607/04869] [00:23:02/00:19:59, 0.530s/it]: train_loss_raw=0.5464, running_loss=0.4190, LR=0.000100
[2025-08-11 13:03:40,557][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007488] [Batch 02619/04869] [00:23:08/00:19:52, 0.530s/it]: train_loss_raw=0.4116, running_loss=0.4220, LR=0.000100
[2025-08-11 13:03:46,590][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007500] [Batch 02631/04869] [00:23:14/00:19:46, 0.530s/it]: train_loss_raw=0.5062, running_loss=0.4232, LR=0.000100
[2025-08-11 13:03:52,802][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007512] [Batch 02643/04869] [00:23:20/00:19:39, 0.530s/it]: train_loss_raw=0.3878, running_loss=0.4204, LR=0.000100
[2025-08-11 13:03:59,032][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007524] [Batch 02655/04869] [00:23:26/00:19:33, 0.530s/it]: train_loss_raw=0.4719, running_loss=0.4218, LR=0.000100
[2025-08-11 13:04:05,242][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007536] [Batch 02667/04869] [00:23:33/00:19:26, 0.530s/it]: train_loss_raw=0.5225, running_loss=0.4271, LR=0.000100
[2025-08-11 13:04:11,440][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007548] [Batch 02679/04869] [00:23:39/00:19:20, 0.530s/it]: train_loss_raw=0.3281, running_loss=0.4255, LR=0.000100
[2025-08-11 13:04:17,503][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007560] [Batch 02691/04869] [00:23:45/00:19:13, 0.530s/it]: train_loss_raw=0.4654, running_loss=0.4252, LR=0.000100
[2025-08-11 13:04:23,616][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007572] [Batch 02703/04869] [00:23:51/00:19:07, 0.530s/it]: train_loss_raw=0.3957, running_loss=0.4246, LR=0.000100
[2025-08-11 13:04:29,730][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007584] [Batch 02715/04869] [00:23:57/00:19:00, 0.529s/it]: train_loss_raw=0.3757, running_loss=0.4226, LR=0.000100
[2025-08-11 13:04:35,805][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007596] [Batch 02727/04869] [00:24:03/00:18:53, 0.529s/it]: train_loss_raw=0.4167, running_loss=0.4234, LR=0.000100
[2025-08-11 13:04:42,007][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007608] [Batch 02739/04869] [00:24:09/00:18:47, 0.529s/it]: train_loss_raw=0.3940, running_loss=0.4227, LR=0.000100
[2025-08-11 13:04:48,258][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007620] [Batch 02751/04869] [00:24:16/00:18:41, 0.529s/it]: train_loss_raw=0.5184, running_loss=0.4214, LR=0.000100
[2025-08-11 13:04:54,532][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007632] [Batch 02763/04869] [00:24:22/00:18:34, 0.529s/it]: train_loss_raw=0.5446, running_loss=0.4214, LR=0.000100
[2025-08-11 13:05:00,997][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007644] [Batch 02775/04869] [00:24:28/00:18:28, 0.529s/it]: train_loss_raw=0.4289, running_loss=0.4216, LR=0.000100
[2025-08-11 13:05:07,550][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007656] [Batch 02787/04869] [00:24:35/00:18:22, 0.529s/it]: train_loss_raw=0.5026, running_loss=0.4209, LR=0.000100
[2025-08-11 13:05:14,103][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007668] [Batch 02799/04869] [00:24:41/00:18:15, 0.529s/it]: train_loss_raw=0.4298, running_loss=0.4235, LR=0.000100
[2025-08-11 13:05:20,531][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007680] [Batch 02811/04869] [00:24:48/00:18:09, 0.529s/it]: train_loss_raw=0.3815, running_loss=0.4231, LR=0.000100
[2025-08-11 13:05:26,985][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007692] [Batch 02823/04869] [00:24:54/00:18:03, 0.529s/it]: train_loss_raw=0.4178, running_loss=0.4247, LR=0.000100
[2025-08-11 13:05:33,236][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007704] [Batch 02835/04869] [00:25:01/00:17:56, 0.529s/it]: train_loss_raw=0.3829, running_loss=0.4243, LR=0.000100
[2025-08-11 13:05:47,057][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007716] [Batch 02847/04869] [00:25:14/00:17:55, 0.532s/it]: train_loss_raw=0.4620, running_loss=0.4253, LR=0.000100
[2025-08-11 13:05:53,463][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007728] [Batch 02859/04869] [00:25:21/00:17:49, 0.532s/it]: train_loss_raw=0.4054, running_loss=0.4262, LR=0.000100
[2025-08-11 13:05:59,795][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007740] [Batch 02871/04869] [00:25:27/00:17:43, 0.532s/it]: train_loss_raw=0.3683, running_loss=0.4265, LR=0.000100
[2025-08-11 13:06:06,295][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007752] [Batch 02883/04869] [00:25:34/00:17:36, 0.532s/it]: train_loss_raw=0.4444, running_loss=0.4275, LR=0.000100
[2025-08-11 13:06:12,675][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007764] [Batch 02895/04869] [00:25:40/00:17:30, 0.532s/it]: train_loss_raw=0.3701, running_loss=0.4249, LR=0.000100
[2025-08-11 13:06:19,066][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007776] [Batch 02907/04869] [00:25:46/00:17:24, 0.532s/it]: train_loss_raw=0.4644, running_loss=0.4230, LR=0.000100
[2025-08-11 13:06:25,251][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007788] [Batch 02919/04869] [00:25:53/00:17:17, 0.532s/it]: train_loss_raw=0.3735, running_loss=0.4219, LR=0.000100
[2025-08-11 13:06:31,495][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007800] [Batch 02931/04869] [00:25:59/00:17:11, 0.532s/it]: train_loss_raw=0.4804, running_loss=0.4172, LR=0.000100
[2025-08-11 13:06:37,874][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007812] [Batch 02943/04869] [00:26:05/00:17:04, 0.532s/it]: train_loss_raw=0.4502, running_loss=0.4157, LR=0.000100
[2025-08-11 13:06:44,258][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007824] [Batch 02955/04869] [00:26:12/00:16:58, 0.532s/it]: train_loss_raw=0.5384, running_loss=0.4180, LR=0.000100
[2025-08-11 13:06:50,737][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007836] [Batch 02967/04869] [00:26:18/00:16:51, 0.532s/it]: train_loss_raw=0.3294, running_loss=0.4154, LR=0.000100
[2025-08-11 13:06:57,273][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007848] [Batch 02979/04869] [00:26:25/00:16:45, 0.532s/it]: train_loss_raw=0.3293, running_loss=0.4163, LR=0.000100
[2025-08-11 13:07:03,728][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007860] [Batch 02991/04869] [00:26:31/00:16:39, 0.532s/it]: train_loss_raw=0.4059, running_loss=0.4176, LR=0.000100
[2025-08-11 13:07:10,122][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007872] [Batch 03003/04869] [00:26:37/00:16:32, 0.532s/it]: train_loss_raw=0.3310, running_loss=0.4168, LR=0.000100
[2025-08-11 13:07:16,585][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007884] [Batch 03015/04869] [00:26:44/00:16:26, 0.532s/it]: train_loss_raw=0.3893, running_loss=0.4204, LR=0.000100
[2025-08-11 13:07:23,032][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007896] [Batch 03027/04869] [00:26:50/00:16:20, 0.532s/it]: train_loss_raw=0.5002, running_loss=0.4212, LR=0.000100
[2025-08-11 13:07:29,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007908] [Batch 03039/04869] [00:26:57/00:16:13, 0.532s/it]: train_loss_raw=0.3153, running_loss=0.4191, LR=0.000100
[2025-08-11 13:07:35,733][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007920] [Batch 03051/04869] [00:27:03/00:16:07, 0.532s/it]: train_loss_raw=0.3890, running_loss=0.4164, LR=0.000100
[2025-08-11 13:07:42,085][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007932] [Batch 03063/04869] [00:27:09/00:16:00, 0.532s/it]: train_loss_raw=0.3691, running_loss=0.4165, LR=0.000100
[2025-08-11 13:07:48,493][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007944] [Batch 03075/04869] [00:27:16/00:15:54, 0.532s/it]: train_loss_raw=0.4349, running_loss=0.4184, LR=0.000100
[2025-08-11 13:07:54,877][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007956] [Batch 03087/04869] [00:27:22/00:15:48, 0.532s/it]: train_loss_raw=0.3893, running_loss=0.4168, LR=0.000100
[2025-08-11 13:08:01,234][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007968] [Batch 03099/04869] [00:27:29/00:15:41, 0.532s/it]: train_loss_raw=0.4281, running_loss=0.4182, LR=0.000100
[2025-08-11 13:08:07,521][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007980] [Batch 03111/04869] [00:27:35/00:15:35, 0.532s/it]: train_loss_raw=0.3514, running_loss=0.4190, LR=0.000100
[2025-08-11 13:08:13,986][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007992] [Batch 03123/04869] [00:27:41/00:15:29, 0.532s/it]: train_loss_raw=0.4049, running_loss=0.4221, LR=0.000100
[2025-08-11 13:08:24,678][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008004] [Batch 03135/04869] [00:27:52/00:15:25, 0.533s/it]: train_loss_raw=0.4208, running_loss=0.4240, LR=0.000100
[2025-08-11 13:08:31,048][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008016] [Batch 03147/04869] [00:27:58/00:15:18, 0.533s/it]: train_loss_raw=0.4139, running_loss=0.4286, LR=0.000100
[2025-08-11 13:08:37,640][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008028] [Batch 03159/04869] [00:28:05/00:15:12, 0.534s/it]: train_loss_raw=0.3280, running_loss=0.4253, LR=0.000100
[2025-08-11 13:08:44,034][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008040] [Batch 03171/04869] [00:28:11/00:15:05, 0.534s/it]: train_loss_raw=0.4851, running_loss=0.4264, LR=0.000100
[2025-08-11 13:08:50,389][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008052] [Batch 03183/04869] [00:28:18/00:14:59, 0.534s/it]: train_loss_raw=0.3893, running_loss=0.4291, LR=0.000100
[2025-08-11 13:08:56,678][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008064] [Batch 03195/04869] [00:28:24/00:14:53, 0.533s/it]: train_loss_raw=0.3779, running_loss=0.4271, LR=0.000100
[2025-08-11 13:09:03,160][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008076] [Batch 03207/04869] [00:28:30/00:14:46, 0.534s/it]: train_loss_raw=0.4165, running_loss=0.4239, LR=0.000100
[2025-08-11 13:09:09,686][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008088] [Batch 03219/04869] [00:28:37/00:14:40, 0.534s/it]: train_loss_raw=0.3779, running_loss=0.4210, LR=0.000100
[2025-08-11 13:09:16,190][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008100] [Batch 03231/04869] [00:28:43/00:14:33, 0.534s/it]: train_loss_raw=0.3868, running_loss=0.4216, LR=0.000100
[2025-08-11 13:09:22,483][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008112] [Batch 03243/04869] [00:28:50/00:14:27, 0.534s/it]: train_loss_raw=0.5378, running_loss=0.4232, LR=0.000100
[2025-08-11 13:09:28,521][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008124] [Batch 03255/04869] [00:28:56/00:14:20, 0.533s/it]: train_loss_raw=0.3969, running_loss=0.4252, LR=0.000100
[2025-08-11 13:09:34,583][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008136] [Batch 03267/04869] [00:29:02/00:14:14, 0.533s/it]: train_loss_raw=0.3934, running_loss=0.4266, LR=0.000100
[2025-08-11 13:09:40,573][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008148] [Batch 03279/04869] [00:29:08/00:14:07, 0.533s/it]: train_loss_raw=0.4656, running_loss=0.4277, LR=0.000100
[2025-08-11 13:09:46,691][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008160] [Batch 03291/04869] [00:29:14/00:14:01, 0.533s/it]: train_loss_raw=0.4452, running_loss=0.4280, LR=0.000100
[2025-08-11 13:09:53,087][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008172] [Batch 03303/04869] [00:29:20/00:13:54, 0.533s/it]: train_loss_raw=0.4796, running_loss=0.4275, LR=0.000100
[2025-08-11 13:09:59,244][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008184] [Batch 03315/04869] [00:29:27/00:13:48, 0.533s/it]: train_loss_raw=0.3605, running_loss=0.4237, LR=0.000100
[2025-08-11 13:10:05,487][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008196] [Batch 03327/04869] [00:29:33/00:13:41, 0.533s/it]: train_loss_raw=0.3667, running_loss=0.4252, LR=0.000100
[2025-08-11 13:10:12,010][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008208] [Batch 03339/04869] [00:29:39/00:13:35, 0.533s/it]: train_loss_raw=0.3765, running_loss=0.4235, LR=0.000100
[2025-08-11 13:10:18,486][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008220] [Batch 03351/04869] [00:29:46/00:13:29, 0.533s/it]: train_loss_raw=0.4150, running_loss=0.4224, LR=0.000100
[2025-08-11 13:10:25,051][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008232] [Batch 03363/04869] [00:29:52/00:13:22, 0.533s/it]: train_loss_raw=0.5076, running_loss=0.4262, LR=0.000100
[2025-08-11 13:10:31,621][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008244] [Batch 03375/04869] [00:29:59/00:13:16, 0.533s/it]: train_loss_raw=0.4340, running_loss=0.4277, LR=0.000100
[2025-08-11 13:10:38,134][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008256] [Batch 03387/04869] [00:30:05/00:13:10, 0.533s/it]: train_loss_raw=0.4037, running_loss=0.4281, LR=0.000100
[2025-08-11 13:10:44,632][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008268] [Batch 03399/04869] [00:30:12/00:13:03, 0.533s/it]: train_loss_raw=0.3633, running_loss=0.4281, LR=0.000100
[2025-08-11 13:10:50,996][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008280] [Batch 03411/04869] [00:30:18/00:12:57, 0.533s/it]: train_loss_raw=0.5633, running_loss=0.4293, LR=0.000100
[2025-08-11 13:10:57,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008292] [Batch 03423/04869] [00:30:25/00:12:51, 0.533s/it]: train_loss_raw=0.4607, running_loss=0.4284, LR=0.000100
[2025-08-11 13:11:03,659][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008304] [Batch 03435/04869] [00:30:31/00:12:44, 0.533s/it]: train_loss_raw=0.3685, running_loss=0.4296, LR=0.000100
[2025-08-11 13:11:10,047][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008316] [Batch 03447/04869] [00:30:37/00:12:38, 0.533s/it]: train_loss_raw=0.3529, running_loss=0.4244, LR=0.000100
[2025-08-11 13:11:16,253][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008328] [Batch 03459/04869] [00:30:44/00:12:31, 0.533s/it]: train_loss_raw=0.4995, running_loss=0.4250, LR=0.000100
[2025-08-11 13:11:22,558][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008340] [Batch 03471/04869] [00:30:50/00:12:25, 0.533s/it]: train_loss_raw=0.4447, running_loss=0.4277, LR=0.000100
[2025-08-11 13:11:29,076][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008352] [Batch 03483/04869] [00:30:56/00:12:18, 0.533s/it]: train_loss_raw=0.3582, running_loss=0.4255, LR=0.000100
[2025-08-11 13:11:35,565][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008364] [Batch 03495/04869] [00:31:03/00:12:12, 0.533s/it]: train_loss_raw=0.4038, running_loss=0.4252, LR=0.000100
[2025-08-11 13:11:42,032][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008376] [Batch 03507/04869] [00:31:09/00:12:06, 0.533s/it]: train_loss_raw=0.4041, running_loss=0.4236, LR=0.000100
[2025-08-11 13:11:48,542][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008388] [Batch 03519/04869] [00:31:16/00:11:59, 0.533s/it]: train_loss_raw=0.4105, running_loss=0.4247, LR=0.000100
[2025-08-11 13:11:54,519][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008400] [Batch 03531/04869] [00:31:22/00:11:53, 0.533s/it]: train_loss_raw=0.4455, running_loss=0.4247, LR=0.000100
[2025-08-11 13:12:00,509][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008412] [Batch 03543/04869] [00:31:28/00:11:46, 0.533s/it]: train_loss_raw=0.4362, running_loss=0.4228, LR=0.000100
[2025-08-11 13:12:06,789][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008424] [Batch 03555/04869] [00:31:34/00:11:40, 0.533s/it]: train_loss_raw=0.4584, running_loss=0.4224, LR=0.000100
[2025-08-11 13:12:13,271][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008436] [Batch 03567/04869] [00:31:41/00:11:33, 0.533s/it]: train_loss_raw=0.2912, running_loss=0.4205, LR=0.000100
[2025-08-11 13:12:19,602][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008448] [Batch 03579/04869] [00:31:47/00:11:27, 0.533s/it]: train_loss_raw=0.3011, running_loss=0.4181, LR=0.000100
[2025-08-11 13:12:26,004][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008460] [Batch 03591/04869] [00:31:53/00:11:21, 0.533s/it]: train_loss_raw=0.3874, running_loss=0.4160, LR=0.000100
[2025-08-11 13:12:32,542][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008472] [Batch 03603/04869] [00:32:00/00:11:14, 0.533s/it]: train_loss_raw=0.4349, running_loss=0.4154, LR=0.000100
[2025-08-11 13:12:39,005][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008484] [Batch 03615/04869] [00:32:06/00:11:08, 0.533s/it]: train_loss_raw=0.5987, running_loss=0.4158, LR=0.000100
[2025-08-11 13:12:45,156][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008496] [Batch 03627/04869] [00:32:12/00:11:01, 0.533s/it]: train_loss_raw=0.5712, running_loss=0.4174, LR=0.000100
[2025-08-11 13:12:51,151][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008508] [Batch 03639/04869] [00:32:18/00:10:55, 0.533s/it]: train_loss_raw=0.4008, running_loss=0.4156, LR=0.000100
[2025-08-11 13:12:57,172][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008520] [Batch 03651/04869] [00:32:24/00:10:48, 0.533s/it]: train_loss_raw=0.4152, running_loss=0.4178, LR=0.000100
[2025-08-11 13:13:03,645][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008532] [Batch 03663/04869] [00:32:31/00:10:42, 0.533s/it]: train_loss_raw=0.3464, running_loss=0.4144, LR=0.000100
[2025-08-11 13:13:10,141][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008544] [Batch 03675/04869] [00:32:37/00:10:36, 0.533s/it]: train_loss_raw=0.3703, running_loss=0.4149, LR=0.000100
[2025-08-11 13:13:16,535][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008556] [Batch 03687/04869] [00:32:44/00:10:29, 0.533s/it]: train_loss_raw=0.3735, running_loss=0.4158, LR=0.000100
[2025-08-11 13:13:22,956][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008568] [Batch 03699/04869] [00:32:50/00:10:23, 0.533s/it]: train_loss_raw=0.4295, running_loss=0.4198, LR=0.000100
[2025-08-11 13:13:29,450][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008580] [Batch 03711/04869] [00:32:57/00:10:16, 0.533s/it]: train_loss_raw=0.3827, running_loss=0.4175, LR=0.000100
[2025-08-11 13:13:35,904][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008592] [Batch 03723/04869] [00:33:03/00:10:10, 0.533s/it]: train_loss_raw=0.4776, running_loss=0.4215, LR=0.000100
[2025-08-11 13:13:42,302][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008604] [Batch 03735/04869] [00:33:10/00:10:04, 0.533s/it]: train_loss_raw=0.4302, running_loss=0.4249, LR=0.000100
[2025-08-11 13:13:48,784][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008616] [Batch 03747/04869] [00:33:16/00:09:57, 0.533s/it]: train_loss_raw=0.5253, running_loss=0.4243, LR=0.000100
[2025-08-11 13:13:55,007][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008628] [Batch 03759/04869] [00:33:22/00:09:51, 0.533s/it]: train_loss_raw=0.3025, running_loss=0.4242, LR=0.000100
[2025-08-11 13:14:01,512][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008640] [Batch 03771/04869] [00:33:29/00:09:45, 0.533s/it]: train_loss_raw=0.3254, running_loss=0.4192, LR=0.000100
[2025-08-11 13:14:08,002][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008652] [Batch 03783/04869] [00:33:35/00:09:38, 0.533s/it]: train_loss_raw=0.3218, running_loss=0.4177, LR=0.000100
[2025-08-11 13:14:14,286][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008664] [Batch 03795/04869] [00:33:42/00:09:32, 0.533s/it]: train_loss_raw=0.4046, running_loss=0.4156, LR=0.000100
[2025-08-11 13:14:20,585][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008676] [Batch 03807/04869] [00:33:48/00:09:25, 0.533s/it]: train_loss_raw=0.5005, running_loss=0.4179, LR=0.000100
[2025-08-11 13:14:26,572][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008688] [Batch 03819/04869] [00:33:54/00:09:19, 0.533s/it]: train_loss_raw=0.4223, running_loss=0.4167, LR=0.000100
[2025-08-11 13:14:32,774][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008700] [Batch 03831/04869] [00:34:00/00:09:12, 0.533s/it]: train_loss_raw=0.4476, running_loss=0.4160, LR=0.000100
[2025-08-11 13:14:39,110][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008712] [Batch 03843/04869] [00:34:06/00:09:06, 0.533s/it]: train_loss_raw=0.4367, running_loss=0.4120, LR=0.000100
[2025-08-11 13:14:45,098][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008724] [Batch 03855/04869] [00:34:12/00:08:59, 0.533s/it]: train_loss_raw=0.3226, running_loss=0.4155, LR=0.000100
[2025-08-11 13:14:51,097][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008736] [Batch 03867/04869] [00:34:18/00:08:53, 0.532s/it]: train_loss_raw=0.5182, running_loss=0.4129, LR=0.000100
[2025-08-11 13:14:57,515][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008748] [Batch 03879/04869] [00:34:25/00:08:47, 0.532s/it]: train_loss_raw=0.3736, running_loss=0.4115, LR=0.000100
[2025-08-11 13:15:03,885][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008760] [Batch 03891/04869] [00:34:31/00:08:40, 0.532s/it]: train_loss_raw=0.4639, running_loss=0.4117, LR=0.000100
[2025-08-11 13:15:10,263][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008772] [Batch 03903/04869] [00:34:38/00:08:34, 0.532s/it]: train_loss_raw=0.4020, running_loss=0.4139, LR=0.000100
[2025-08-11 13:15:16,654][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008784] [Batch 03915/04869] [00:34:44/00:08:27, 0.532s/it]: train_loss_raw=0.3414, running_loss=0.4152, LR=0.000100
[2025-08-11 13:15:23,024][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008796] [Batch 03927/04869] [00:34:50/00:08:21, 0.532s/it]: train_loss_raw=0.4007, running_loss=0.4149, LR=0.000100
[2025-08-11 13:15:29,453][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008808] [Batch 03939/04869] [00:34:57/00:08:15, 0.532s/it]: train_loss_raw=0.5523, running_loss=0.4141, LR=0.000100
[2025-08-11 13:15:35,799][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008820] [Batch 03951/04869] [00:35:03/00:08:08, 0.532s/it]: train_loss_raw=0.4122, running_loss=0.4160, LR=0.000100
[2025-08-11 13:15:42,163][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008832] [Batch 03963/04869] [00:35:09/00:08:02, 0.532s/it]: train_loss_raw=0.4679, running_loss=0.4153, LR=0.000100
[2025-08-11 13:15:48,632][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008844] [Batch 03975/04869] [00:35:16/00:07:55, 0.532s/it]: train_loss_raw=0.3962, running_loss=0.4162, LR=0.000100
[2025-08-11 13:15:55,137][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008856] [Batch 03987/04869] [00:35:22/00:07:49, 0.532s/it]: train_loss_raw=0.3961, running_loss=0.4181, LR=0.000100
[2025-08-11 13:16:01,609][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008868] [Batch 03999/04869] [00:35:29/00:07:43, 0.532s/it]: train_loss_raw=0.4123, running_loss=0.4230, LR=0.000100
[2025-08-11 13:16:08,006][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008880] [Batch 04011/04869] [00:35:35/00:07:36, 0.532s/it]: train_loss_raw=0.3614, running_loss=0.4197, LR=0.000100
[2025-08-11 13:16:14,508][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008892] [Batch 04023/04869] [00:35:42/00:07:30, 0.533s/it]: train_loss_raw=0.4560, running_loss=0.4219, LR=0.000100
[2025-08-11 13:16:20,871][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008904] [Batch 04035/04869] [00:35:48/00:07:24, 0.533s/it]: train_loss_raw=0.4835, running_loss=0.4231, LR=0.000100
[2025-08-11 13:16:27,163][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008916] [Batch 04047/04869] [00:35:54/00:07:17, 0.532s/it]: train_loss_raw=0.3994, running_loss=0.4225, LR=0.000100
[2025-08-11 13:16:33,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008928] [Batch 04059/04869] [00:36:01/00:07:11, 0.532s/it]: train_loss_raw=0.4372, running_loss=0.4196, LR=0.000100
[2025-08-11 13:16:39,618][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008940] [Batch 04071/04869] [00:36:07/00:07:04, 0.532s/it]: train_loss_raw=0.3543, running_loss=0.4207, LR=0.000100
[2025-08-11 13:16:46,164][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008952] [Batch 04083/04869] [00:36:13/00:06:58, 0.532s/it]: train_loss_raw=0.3599, running_loss=0.4202, LR=0.000100
[2025-08-11 13:16:52,542][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008964] [Batch 04095/04869] [00:36:20/00:06:52, 0.532s/it]: train_loss_raw=0.3883, running_loss=0.4187, LR=0.000100
[2025-08-11 13:16:58,789][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008976] [Batch 04107/04869] [00:36:26/00:06:45, 0.532s/it]: train_loss_raw=0.4480, running_loss=0.4180, LR=0.000100
[2025-08-11 13:17:04,971][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008988] [Batch 04119/04869] [00:36:32/00:06:39, 0.532s/it]: train_loss_raw=0.4201, running_loss=0.4192, LR=0.000100
[2025-08-11 13:17:11,342][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009000] [Batch 04131/04869] [00:36:39/00:06:32, 0.532s/it]: train_loss_raw=0.3998, running_loss=0.4180, LR=0.000100
[2025-08-11 13:17:17,533][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009012] [Batch 04143/04869] [00:36:45/00:06:26, 0.532s/it]: train_loss_raw=0.4915, running_loss=0.4212, LR=0.000100
[2025-08-11 13:17:23,943][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009024] [Batch 04155/04869] [00:36:51/00:06:20, 0.532s/it]: train_loss_raw=0.3692, running_loss=0.4219, LR=0.000100
[2025-08-11 13:17:30,241][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009036] [Batch 04167/04869] [00:36:58/00:06:13, 0.532s/it]: train_loss_raw=0.4282, running_loss=0.4218, LR=0.000100
[2025-08-11 13:17:36,549][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009048] [Batch 04179/04869] [00:37:04/00:06:07, 0.532s/it]: train_loss_raw=0.4153, running_loss=0.4217, LR=0.000100
[2025-08-11 13:17:42,987][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009060] [Batch 04191/04869] [00:37:10/00:06:00, 0.532s/it]: train_loss_raw=0.3856, running_loss=0.4190, LR=0.000100
[2025-08-11 13:17:49,286][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009072] [Batch 04203/04869] [00:37:17/00:05:54, 0.532s/it]: train_loss_raw=0.3452, running_loss=0.4185, LR=0.000100
[2025-08-11 13:17:55,692][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009084] [Batch 04215/04869] [00:37:23/00:05:48, 0.532s/it]: train_loss_raw=0.4250, running_loss=0.4206, LR=0.000100
[2025-08-11 13:18:02,024][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009096] [Batch 04227/04869] [00:37:29/00:05:41, 0.532s/it]: train_loss_raw=0.4050, running_loss=0.4237, LR=0.000100
[2025-08-11 13:18:08,388][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009108] [Batch 04239/04869] [00:37:36/00:05:35, 0.532s/it]: train_loss_raw=0.5901, running_loss=0.4226, LR=0.000100
[2025-08-11 13:18:14,811][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009120] [Batch 04251/04869] [00:37:42/00:05:28, 0.532s/it]: train_loss_raw=0.4063, running_loss=0.4216, LR=0.000100
[2025-08-11 13:18:21,174][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009132] [Batch 04263/04869] [00:37:48/00:05:22, 0.532s/it]: train_loss_raw=0.3542, running_loss=0.4228, LR=0.000100
[2025-08-11 13:18:27,544][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009144] [Batch 04275/04869] [00:37:55/00:05:16, 0.532s/it]: train_loss_raw=0.4354, running_loss=0.4236, LR=0.000100
[2025-08-11 13:18:33,973][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009156] [Batch 04287/04869] [00:38:01/00:05:09, 0.532s/it]: train_loss_raw=0.5104, running_loss=0.4227, LR=0.000100
[2025-08-11 13:18:40,335][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009168] [Batch 04299/04869] [00:38:08/00:05:03, 0.532s/it]: train_loss_raw=0.3622, running_loss=0.4238, LR=0.000100
[2025-08-11 13:18:46,705][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009180] [Batch 04311/04869] [00:38:14/00:04:56, 0.532s/it]: train_loss_raw=0.4373, running_loss=0.4226, LR=0.000100
[2025-08-11 13:18:53,047][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009192] [Batch 04323/04869] [00:38:20/00:04:50, 0.532s/it]: train_loss_raw=0.4741, running_loss=0.4214, LR=0.000100
[2025-08-11 13:18:59,529][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009204] [Batch 04335/04869] [00:38:27/00:04:44, 0.532s/it]: train_loss_raw=0.4689, running_loss=0.4174, LR=0.000100
[2025-08-11 13:19:06,025][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009216] [Batch 04347/04869] [00:38:33/00:04:37, 0.532s/it]: train_loss_raw=0.4059, running_loss=0.4178, LR=0.000100
[2025-08-11 13:19:12,390][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009228] [Batch 04359/04869] [00:38:40/00:04:31, 0.532s/it]: train_loss_raw=0.4596, running_loss=0.4168, LR=0.000100
[2025-08-11 13:19:18,846][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009240] [Batch 04371/04869] [00:38:46/00:04:25, 0.532s/it]: train_loss_raw=0.3609, running_loss=0.4176, LR=0.000100
[2025-08-11 13:19:25,361][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009252] [Batch 04383/04869] [00:38:53/00:04:18, 0.532s/it]: train_loss_raw=0.4048, running_loss=0.4187, LR=0.000100
[2025-08-11 13:19:31,855][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009264] [Batch 04395/04869] [00:38:59/00:04:12, 0.532s/it]: train_loss_raw=0.3742, running_loss=0.4187, LR=0.000100
[2025-08-11 13:19:38,128][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009276] [Batch 04407/04869] [00:39:05/00:04:05, 0.532s/it]: train_loss_raw=0.3860, running_loss=0.4203, LR=0.000100
[2025-08-11 13:19:44,544][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009288] [Batch 04419/04869] [00:39:12/00:03:59, 0.532s/it]: train_loss_raw=0.3863, running_loss=0.4200, LR=0.000100
[2025-08-11 13:19:50,851][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009300] [Batch 04431/04869] [00:39:18/00:03:53, 0.532s/it]: train_loss_raw=0.4361, running_loss=0.4180, LR=0.000100
[2025-08-11 13:19:57,103][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009312] [Batch 04443/04869] [00:39:24/00:03:46, 0.532s/it]: train_loss_raw=0.3878, running_loss=0.4173, LR=0.000100
[2025-08-11 13:20:03,478][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009324] [Batch 04455/04869] [00:39:31/00:03:40, 0.532s/it]: train_loss_raw=0.3884, running_loss=0.4183, LR=0.000100
[2025-08-11 13:20:09,851][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009336] [Batch 04467/04869] [00:39:37/00:03:33, 0.532s/it]: train_loss_raw=0.3133, running_loss=0.4178, LR=0.000100
[2025-08-11 13:20:16,045][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009348] [Batch 04479/04869] [00:39:43/00:03:27, 0.532s/it]: train_loss_raw=0.3404, running_loss=0.4165, LR=0.000100
[2025-08-11 13:20:22,362][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009360] [Batch 04491/04869] [00:39:50/00:03:21, 0.532s/it]: train_loss_raw=0.3318, running_loss=0.4163, LR=0.000100
[2025-08-11 13:20:28,685][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009372] [Batch 04503/04869] [00:39:56/00:03:14, 0.532s/it]: train_loss_raw=0.3177, running_loss=0.4156, LR=0.000100
[2025-08-11 13:20:35,085][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009384] [Batch 04515/04869] [00:40:02/00:03:08, 0.532s/it]: train_loss_raw=0.3750, running_loss=0.4171, LR=0.000100
[2025-08-11 13:20:41,557][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009396] [Batch 04527/04869] [00:40:09/00:03:02, 0.532s/it]: train_loss_raw=0.4858, running_loss=0.4194, LR=0.000100
[2025-08-11 13:20:47,791][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009408] [Batch 04539/04869] [00:40:15/00:02:55, 0.532s/it]: train_loss_raw=0.4438, running_loss=0.4186, LR=0.000100
[2025-08-11 13:20:54,172][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009420] [Batch 04551/04869] [00:40:21/00:02:49, 0.532s/it]: train_loss_raw=0.5031, running_loss=0.4210, LR=0.000100
[2025-08-11 13:21:00,547][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009432] [Batch 04563/04869] [00:40:28/00:02:42, 0.532s/it]: train_loss_raw=0.3433, running_loss=0.4190, LR=0.000100
[2025-08-11 13:21:07,030][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009444] [Batch 04575/04869] [00:40:34/00:02:36, 0.532s/it]: train_loss_raw=0.4932, running_loss=0.4184, LR=0.000100
[2025-08-11 13:21:13,481][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009456] [Batch 04587/04869] [00:40:41/00:02:30, 0.532s/it]: train_loss_raw=0.4036, running_loss=0.4189, LR=0.000100
[2025-08-11 13:21:19,797][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009468] [Batch 04599/04869] [00:40:47/00:02:23, 0.532s/it]: train_loss_raw=0.4257, running_loss=0.4177, LR=0.000100
[2025-08-11 13:21:26,241][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009480] [Batch 04611/04869] [00:40:54/00:02:17, 0.532s/it]: train_loss_raw=0.3747, running_loss=0.4184, LR=0.000100
[2025-08-11 13:21:32,685][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009492] [Batch 04623/04869] [00:41:00/00:02:10, 0.532s/it]: train_loss_raw=0.4030, running_loss=0.4203, LR=0.000100
[2025-08-11 13:21:38,988][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009504] [Batch 04635/04869] [00:41:06/00:02:04, 0.532s/it]: train_loss_raw=0.4927, running_loss=0.4202, LR=0.000100
[2025-08-11 13:21:45,420][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009516] [Batch 04647/04869] [00:41:13/00:01:58, 0.532s/it]: train_loss_raw=0.3189, running_loss=0.4155, LR=0.000100
[2025-08-11 13:21:51,834][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009528] [Batch 04659/04869] [00:41:19/00:01:51, 0.532s/it]: train_loss_raw=0.3673, running_loss=0.4150, LR=0.000100
[2025-08-11 13:21:58,205][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009540] [Batch 04671/04869] [00:41:25/00:01:45, 0.532s/it]: train_loss_raw=0.4460, running_loss=0.4160, LR=0.000100
[2025-08-11 13:22:04,563][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009552] [Batch 04683/04869] [00:41:32/00:01:38, 0.532s/it]: train_loss_raw=0.2781, running_loss=0.4109, LR=0.000100
[2025-08-11 13:22:10,995][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009564] [Batch 04695/04869] [00:41:38/00:01:32, 0.532s/it]: train_loss_raw=0.5336, running_loss=0.4116, LR=0.000100
[2025-08-11 13:22:17,475][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009576] [Batch 04707/04869] [00:41:45/00:01:26, 0.532s/it]: train_loss_raw=0.3713, running_loss=0.4121, LR=0.000100
[2025-08-11 13:22:23,810][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009588] [Batch 04719/04869] [00:41:51/00:01:19, 0.532s/it]: train_loss_raw=0.4562, running_loss=0.4136, LR=0.000100
[2025-08-11 13:22:30,197][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009600] [Batch 04731/04869] [00:41:57/00:01:13, 0.532s/it]: train_loss_raw=0.4678, running_loss=0.4137, LR=0.000100
[2025-08-11 13:22:36,472][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009612] [Batch 04743/04869] [00:42:04/00:01:07, 0.532s/it]: train_loss_raw=0.4401, running_loss=0.4141, LR=0.000100
[2025-08-11 13:22:42,821][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009624] [Batch 04755/04869] [00:42:10/00:01:00, 0.532s/it]: train_loss_raw=0.4112, running_loss=0.4130, LR=0.000100
[2025-08-11 13:22:49,142][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009636] [Batch 04767/04869] [00:42:16/00:00:54, 0.532s/it]: train_loss_raw=0.4189, running_loss=0.4128, LR=0.000100
[2025-08-11 13:22:55,549][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009648] [Batch 04779/04869] [00:42:23/00:00:47, 0.532s/it]: train_loss_raw=0.3544, running_loss=0.4145, LR=0.000100
[2025-08-11 13:23:01,895][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009660] [Batch 04791/04869] [00:42:29/00:00:41, 0.532s/it]: train_loss_raw=0.4227, running_loss=0.4120, LR=0.000100
[2025-08-11 13:23:08,334][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009672] [Batch 04803/04869] [00:42:36/00:00:35, 0.532s/it]: train_loss_raw=0.3328, running_loss=0.4102, LR=0.000100
[2025-08-11 13:23:14,828][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009684] [Batch 04815/04869] [00:42:42/00:00:28, 0.532s/it]: train_loss_raw=0.3654, running_loss=0.4082, LR=0.000100
[2025-08-11 13:23:21,134][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009696] [Batch 04827/04869] [00:42:48/00:00:22, 0.532s/it]: train_loss_raw=0.4709, running_loss=0.4089, LR=0.000100
[2025-08-11 13:23:27,455][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009708] [Batch 04839/04869] [00:42:55/00:00:15, 0.532s/it]: train_loss_raw=0.3516, running_loss=0.4116, LR=0.000100
[2025-08-11 13:23:33,952][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009720] [Batch 04851/04869] [00:43:01/00:00:09, 0.532s/it]: train_loss_raw=0.4401, running_loss=0.4129, LR=0.000100
[2025-08-11 13:23:40,487][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009732] [Batch 04863/04869] [00:43:08/00:00:03, 0.532s/it]: train_loss_raw=0.3485, running_loss=0.4131, LR=0.000100
[2025-08-11 13:23:57,056][__main__][INFO] - [VALIDATION] [Epoch 01/29] Starting validation.
[2025-08-11 13:24:12,006][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00011/00062] [00:00:14/00:01:02, 1.246s/it]
[2025-08-11 13:24:43,520][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00023/00062] [00:00:46/00:01:13, 1.936s/it]
[2025-08-11 13:24:58,732][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00035/00062] [00:01:01/00:00:44, 1.713s/it]
[2025-08-11 13:25:14,338][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00047/00062] [00:01:17/00:00:22, 1.610s/it]
[2025-08-11 13:25:28,846][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00059/00062] [00:01:31/00:00:03, 1.530s/it]
[2025-08-11 13:25:31,035][__main__][INFO] - [VALIDATION] [Epoch 01/29] train_loss=0.41276, valid_loss=0.37525
[2025-08-11 13:25:31,035][__main__][INFO] - [VALIDATION] [Epoch 01/29] Metrics:
[2025-08-11 13:25:31,035][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_er      0.204
[2025-08-11 13:25:31,036][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_prec    0.609
[2025-08-11 13:25:31,036][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_recall  0.614
[2025-08-11 13:25:31,036][__main__][INFO] - [VALIDATION] [Epoch 01/29] - pep_recall 0.579
[2025-08-11 13:25:31,040][__main__][INFO] - [TRAIN] [Epoch 01/29] Epoch complete, total time 01:30:09, remaining time 21:02:15, 00:45:04 per epoch
[2025-08-11 13:25:34,043][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009744] [Batch 00006/04869] [00:00:02/00:37:17, 0.460s/it]: train_loss_raw=0.4106, running_loss=0.3152, LR=0.000100
[2025-08-11 13:25:40,389][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009756] [Batch 00018/04869] [00:00:09/00:40:54, 0.506s/it]: train_loss_raw=0.2934, running_loss=0.3223, LR=0.000100
[2025-08-11 13:25:46,732][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009768] [Batch 00030/04869] [00:00:15/00:41:31, 0.515s/it]: train_loss_raw=0.3253, running_loss=0.3245, LR=0.000100
[2025-08-11 13:25:53,126][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009780] [Batch 00042/04869] [00:00:21/00:41:50, 0.520s/it]: train_loss_raw=0.3880, running_loss=0.3298, LR=0.000100
[2025-08-11 13:25:59,539][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009792] [Batch 00054/04869] [00:00:28/00:41:59, 0.523s/it]: train_loss_raw=0.4005, running_loss=0.3352, LR=0.000100
[2025-08-11 13:26:05,889][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009804] [Batch 00066/04869] [00:00:34/00:41:58, 0.524s/it]: train_loss_raw=0.3469, running_loss=0.3373, LR=0.000100
[2025-08-11 13:26:12,280][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009816] [Batch 00078/04869] [00:00:40/00:41:58, 0.526s/it]: train_loss_raw=0.4044, running_loss=0.3379, LR=0.000100
[2025-08-11 13:26:18,621][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009828] [Batch 00090/04869] [00:00:47/00:41:53, 0.526s/it]: train_loss_raw=0.2999, running_loss=0.3377, LR=0.000100
[2025-08-11 13:26:25,080][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009840] [Batch 00102/04869] [00:00:53/00:41:54, 0.527s/it]: train_loss_raw=0.2837, running_loss=0.3361, LR=0.000100
[2025-08-11 13:26:31,443][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009852] [Batch 00114/04869] [00:01:00/00:41:49, 0.528s/it]: train_loss_raw=0.3348, running_loss=0.3405, LR=0.000100
[2025-08-11 13:26:37,929][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009864] [Batch 00126/04869] [00:01:06/00:41:48, 0.529s/it]: train_loss_raw=0.2874, running_loss=0.3401, LR=0.000100
[2025-08-11 13:26:44,468][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009876] [Batch 00138/04869] [00:01:13/00:41:48, 0.530s/it]: train_loss_raw=0.3364, running_loss=0.3396, LR=0.000100
[2025-08-11 13:26:50,849][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009888] [Batch 00150/04869] [00:01:19/00:41:43, 0.530s/it]: train_loss_raw=0.3632, running_loss=0.3439, LR=0.000100
[2025-08-11 13:26:57,173][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009900] [Batch 00162/04869] [00:01:25/00:41:35, 0.530s/it]: train_loss_raw=0.4761, running_loss=0.3488, LR=0.000100
[2025-08-11 13:27:03,543][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009912] [Batch 00174/04869] [00:01:32/00:41:29, 0.530s/it]: train_loss_raw=0.3479, running_loss=0.3497, LR=0.000100
[2025-08-11 13:27:09,962][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009924] [Batch 00186/04869] [00:01:38/00:41:24, 0.531s/it]: train_loss_raw=0.3324, running_loss=0.3517, LR=0.000100
[2025-08-11 13:27:16,359][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009936] [Batch 00198/04869] [00:01:45/00:41:18, 0.531s/it]: train_loss_raw=0.2970, running_loss=0.3496, LR=0.000100
[2025-08-11 13:27:22,683][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009948] [Batch 00210/04869] [00:01:51/00:41:11, 0.530s/it]: train_loss_raw=0.3539, running_loss=0.3521, LR=0.000100
[2025-08-11 13:27:28,955][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009960] [Batch 00222/04869] [00:01:57/00:41:03, 0.530s/it]: train_loss_raw=0.3212, running_loss=0.3532, LR=0.000100
[2025-08-11 13:27:35,218][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009972] [Batch 00234/04869] [00:02:03/00:40:54, 0.530s/it]: train_loss_raw=0.3964, running_loss=0.3548, LR=0.000100
[2025-08-11 13:27:41,565][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009984] [Batch 00246/04869] [00:02:10/00:40:48, 0.530s/it]: train_loss_raw=0.4125, running_loss=0.3571, LR=0.000100
[2025-08-11 13:27:47,913][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009996] [Batch 00258/04869] [00:02:16/00:40:41, 0.530s/it]: train_loss_raw=0.3801, running_loss=0.3553, LR=0.000100
[2025-08-11 13:27:58,597][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010008] [Batch 00270/04869] [00:02:27/00:41:49, 0.546s/it]: train_loss_raw=0.2967, running_loss=0.3556, LR=0.000100
[2025-08-11 13:28:05,024][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010020] [Batch 00282/04869] [00:02:33/00:41:40, 0.545s/it]: train_loss_raw=0.3088, running_loss=0.3531, LR=0.000100
[2025-08-11 13:28:11,297][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010032] [Batch 00294/04869] [00:02:40/00:41:30, 0.544s/it]: train_loss_raw=0.3807, running_loss=0.3576, LR=0.000100
[2025-08-11 13:28:17,777][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010044] [Batch 00306/04869] [00:02:46/00:41:22, 0.544s/it]: train_loss_raw=0.3659, running_loss=0.3612, LR=0.000100
[2025-08-11 13:28:24,231][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010056] [Batch 00318/04869] [00:02:52/00:41:15, 0.544s/it]: train_loss_raw=0.3180, running_loss=0.3627, LR=0.000100
[2025-08-11 13:28:30,724][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010068] [Batch 00330/04869] [00:02:59/00:41:08, 0.544s/it]: train_loss_raw=0.3485, running_loss=0.3619, LR=0.000100
[2025-08-11 13:28:37,301][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010080] [Batch 00342/04869] [00:03:06/00:41:02, 0.544s/it]: train_loss_raw=0.4077, running_loss=0.3607, LR=0.000100
[2025-08-11 13:28:43,684][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010092] [Batch 00354/04869] [00:03:12/00:40:53, 0.544s/it]: train_loss_raw=0.3171, running_loss=0.3628, LR=0.000100
[2025-08-11 13:28:50,020][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010104] [Batch 00366/04869] [00:03:18/00:40:45, 0.543s/it]: train_loss_raw=0.3722, running_loss=0.3656, LR=0.000100
[2025-08-11 13:28:56,352][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010116] [Batch 00378/04869] [00:03:25/00:40:36, 0.543s/it]: train_loss_raw=0.3933, running_loss=0.3665, LR=0.000100
[2025-08-11 13:29:02,576][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010128] [Batch 00390/04869] [00:03:31/00:40:26, 0.542s/it]: train_loss_raw=0.3183, running_loss=0.3652, LR=0.000100
[2025-08-11 13:29:08,942][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010140] [Batch 00402/04869] [00:03:37/00:40:18, 0.541s/it]: train_loss_raw=0.4174, running_loss=0.3675, LR=0.000100
[2025-08-11 13:29:15,263][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010152] [Batch 00414/04869] [00:03:43/00:40:10, 0.541s/it]: train_loss_raw=0.3077, running_loss=0.3692, LR=0.000100
[2025-08-11 13:29:21,614][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010164] [Batch 00426/04869] [00:03:50/00:40:02, 0.541s/it]: train_loss_raw=0.3789, running_loss=0.3675, LR=0.000100
[2025-08-11 13:29:27,903][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010176] [Batch 00438/04869] [00:03:56/00:39:53, 0.540s/it]: train_loss_raw=0.3484, running_loss=0.3677, LR=0.000100
[2025-08-11 13:29:34,073][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010188] [Batch 00450/04869] [00:04:02/00:39:44, 0.540s/it]: train_loss_raw=0.4674, running_loss=0.3696, LR=0.000100
[2025-08-11 13:29:40,264][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010200] [Batch 00462/04869] [00:04:08/00:39:35, 0.539s/it]: train_loss_raw=0.5018, running_loss=0.3714, LR=0.000100
[2025-08-11 13:29:46,562][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010212] [Batch 00474/04869] [00:04:15/00:39:26, 0.539s/it]: train_loss_raw=0.3251, running_loss=0.3716, LR=0.000100
[2025-08-11 13:29:52,705][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010224] [Batch 00486/04869] [00:04:21/00:39:17, 0.538s/it]: train_loss_raw=0.4289, running_loss=0.3748, LR=0.000100
[2025-08-11 13:29:58,969][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010236] [Batch 00498/04869] [00:04:27/00:39:09, 0.538s/it]: train_loss_raw=0.4447, running_loss=0.3751, LR=0.000100
[2025-08-11 13:30:05,359][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010248] [Batch 00510/04869] [00:04:34/00:39:02, 0.537s/it]: train_loss_raw=0.2968, running_loss=0.3731, LR=0.000100
[2025-08-11 13:30:11,820][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010260] [Batch 00522/04869] [00:04:40/00:38:56, 0.537s/it]: train_loss_raw=0.2911, running_loss=0.3716, LR=0.000100
[2025-08-11 13:30:18,391][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010272] [Batch 00534/04869] [00:04:47/00:38:50, 0.538s/it]: train_loss_raw=0.3150, running_loss=0.3750, LR=0.000100
[2025-08-11 13:30:24,957][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010284] [Batch 00546/04869] [00:04:53/00:38:45, 0.538s/it]: train_loss_raw=0.4222, running_loss=0.3740, LR=0.000100
[2025-08-11 13:30:31,483][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010296] [Batch 00558/04869] [00:05:00/00:38:39, 0.538s/it]: train_loss_raw=0.3307, running_loss=0.3750, LR=0.000100
[2025-08-11 13:30:37,724][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010308] [Batch 00570/04869] [00:05:06/00:38:31, 0.538s/it]: train_loss_raw=0.3963, running_loss=0.3736, LR=0.000100
[2025-08-11 13:30:44,060][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010320] [Batch 00582/04869] [00:05:12/00:38:23, 0.537s/it]: train_loss_raw=0.3072, running_loss=0.3756, LR=0.000100
[2025-08-11 13:30:50,561][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010332] [Batch 00594/04869] [00:05:19/00:38:17, 0.538s/it]: train_loss_raw=0.3539, running_loss=0.3751, LR=0.000100
[2025-08-11 13:30:57,021][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010344] [Batch 00606/04869] [00:05:25/00:38:11, 0.538s/it]: train_loss_raw=0.2950, running_loss=0.3727, LR=0.000100
[2025-08-11 13:31:03,467][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010356] [Batch 00618/04869] [00:05:32/00:38:04, 0.538s/it]: train_loss_raw=0.3087, running_loss=0.3705, LR=0.000100
[2025-08-11 13:31:09,992][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010368] [Batch 00630/04869] [00:05:38/00:37:59, 0.538s/it]: train_loss_raw=0.2840, running_loss=0.3708, LR=0.000100
[2025-08-11 13:31:16,477][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010380] [Batch 00642/04869] [00:05:45/00:37:52, 0.538s/it]: train_loss_raw=0.4338, running_loss=0.3727, LR=0.000100
[2025-08-11 13:31:22,897][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010392] [Batch 00654/04869] [00:05:51/00:37:46, 0.538s/it]: train_loss_raw=0.3805, running_loss=0.3735, LR=0.000100
[2025-08-11 13:31:29,322][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010404] [Batch 00666/04869] [00:05:58/00:37:39, 0.538s/it]: train_loss_raw=0.3403, running_loss=0.3741, LR=0.000100
[2025-08-11 13:31:35,738][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010416] [Batch 00678/04869] [00:06:04/00:37:32, 0.538s/it]: train_loss_raw=0.4357, running_loss=0.3779, LR=0.000100
[2025-08-11 13:31:42,100][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010428] [Batch 00690/04869] [00:06:10/00:37:25, 0.537s/it]: train_loss_raw=0.4292, running_loss=0.3782, LR=0.000100
[2025-08-11 13:31:48,510][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010440] [Batch 00702/04869] [00:06:17/00:37:19, 0.537s/it]: train_loss_raw=0.3879, running_loss=0.3771, LR=0.000100
[2025-08-11 13:31:54,928][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010452] [Batch 00714/04869] [00:06:23/00:37:12, 0.537s/it]: train_loss_raw=0.3815, running_loss=0.3748, LR=0.000100
[2025-08-11 13:32:01,259][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010464] [Batch 00726/04869] [00:06:29/00:37:05, 0.537s/it]: train_loss_raw=0.3204, running_loss=0.3735, LR=0.000100
[2025-08-11 13:32:07,574][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010476] [Batch 00738/04869] [00:06:36/00:36:58, 0.537s/it]: train_loss_raw=0.3892, running_loss=0.3733, LR=0.000100
[2025-08-11 13:32:14,079][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010488] [Batch 00750/04869] [00:06:42/00:36:52, 0.537s/it]: train_loss_raw=0.3754, running_loss=0.3722, LR=0.000100
[2025-08-11 13:32:20,436][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010500] [Batch 00762/04869] [00:06:49/00:36:45, 0.537s/it]: train_loss_raw=0.4485, running_loss=0.3751, LR=0.000100
[2025-08-11 13:32:26,895][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010512] [Batch 00774/04869] [00:06:55/00:36:38, 0.537s/it]: train_loss_raw=0.4637, running_loss=0.3777, LR=0.000100
[2025-08-11 13:32:33,346][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010524] [Batch 00786/04869] [00:07:02/00:36:32, 0.537s/it]: train_loss_raw=0.2843, running_loss=0.3773, LR=0.000100
[2025-08-11 13:32:39,739][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010536] [Batch 00798/04869] [00:07:08/00:36:25, 0.537s/it]: train_loss_raw=0.2667, running_loss=0.3788, LR=0.000100
[2025-08-11 13:32:45,879][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010548] [Batch 00810/04869] [00:07:14/00:36:17, 0.537s/it]: train_loss_raw=0.4181, running_loss=0.3775, LR=0.000100
[2025-08-11 13:32:52,117][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010560] [Batch 00822/04869] [00:07:20/00:36:10, 0.536s/it]: train_loss_raw=0.3252, running_loss=0.3784, LR=0.000100
[2025-08-11 13:32:58,641][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010572] [Batch 00834/04869] [00:07:27/00:36:04, 0.536s/it]: train_loss_raw=0.3770, running_loss=0.3751, LR=0.000100
[2025-08-11 13:33:05,103][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010584] [Batch 00846/04869] [00:07:33/00:35:58, 0.536s/it]: train_loss_raw=0.4219, running_loss=0.3784, LR=0.000100
[2025-08-11 13:33:11,664][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010596] [Batch 00858/04869] [00:07:40/00:35:52, 0.537s/it]: train_loss_raw=0.3861, running_loss=0.3791, LR=0.000100
[2025-08-11 13:33:18,171][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010608] [Batch 00870/04869] [00:07:46/00:35:46, 0.537s/it]: train_loss_raw=0.5252, running_loss=0.3791, LR=0.000100
[2025-08-11 13:33:24,720][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010620] [Batch 00882/04869] [00:07:53/00:35:40, 0.537s/it]: train_loss_raw=0.4050, running_loss=0.3779, LR=0.000100
[2025-08-11 13:33:30,900][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010632] [Batch 00894/04869] [00:07:59/00:35:32, 0.536s/it]: train_loss_raw=0.3747, running_loss=0.3787, LR=0.000100
[2025-08-11 13:33:37,347][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010644] [Batch 00906/04869] [00:08:06/00:35:26, 0.536s/it]: train_loss_raw=0.3118, running_loss=0.3757, LR=0.000100
[2025-08-11 13:33:43,757][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010656] [Batch 00918/04869] [00:08:12/00:35:19, 0.536s/it]: train_loss_raw=0.3068, running_loss=0.3754, LR=0.000100
[2025-08-11 13:33:50,190][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010668] [Batch 00930/04869] [00:08:18/00:35:13, 0.536s/it]: train_loss_raw=0.3887, running_loss=0.3736, LR=0.000100
[2025-08-11 13:33:56,335][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010680] [Batch 00942/04869] [00:08:25/00:35:05, 0.536s/it]: train_loss_raw=0.4228, running_loss=0.3747, LR=0.000100
[2025-08-11 13:34:02,525][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010692] [Batch 00954/04869] [00:08:31/00:34:58, 0.536s/it]: train_loss_raw=0.3197, running_loss=0.3760, LR=0.000100
[2025-08-11 13:34:08,980][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010704] [Batch 00966/04869] [00:08:37/00:34:51, 0.536s/it]: train_loss_raw=0.2861, running_loss=0.3758, LR=0.000100
[2025-08-11 13:34:15,538][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010716] [Batch 00978/04869] [00:08:44/00:34:45, 0.536s/it]: train_loss_raw=0.3264, running_loss=0.3757, LR=0.000100
[2025-08-11 13:34:22,076][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010728] [Batch 00990/04869] [00:08:50/00:34:39, 0.536s/it]: train_loss_raw=0.3701, running_loss=0.3743, LR=0.000100
[2025-08-11 13:34:28,482][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010740] [Batch 01002/04869] [00:08:57/00:34:33, 0.536s/it]: train_loss_raw=0.4747, running_loss=0.3767, LR=0.000100
[2025-08-11 13:34:34,658][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010752] [Batch 01014/04869] [00:09:03/00:34:25, 0.536s/it]: train_loss_raw=0.4146, running_loss=0.3766, LR=0.000100
[2025-08-11 13:34:40,877][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010764] [Batch 01026/04869] [00:09:09/00:34:18, 0.536s/it]: train_loss_raw=0.3217, running_loss=0.3736, LR=0.000100
[2025-08-11 13:34:47,215][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010776] [Batch 01038/04869] [00:09:15/00:34:11, 0.536s/it]: train_loss_raw=0.4259, running_loss=0.3746, LR=0.000100
[2025-08-11 13:34:53,510][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010788] [Batch 01050/04869] [00:09:22/00:34:04, 0.535s/it]: train_loss_raw=0.4805, running_loss=0.3748, LR=0.000100
[2025-08-11 13:34:59,724][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010800] [Batch 01062/04869] [00:09:28/00:33:57, 0.535s/it]: train_loss_raw=0.4257, running_loss=0.3804, LR=0.000100
[2025-08-11 13:35:06,037][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010812] [Batch 01074/04869] [00:09:34/00:33:50, 0.535s/it]: train_loss_raw=0.3890, running_loss=0.3800, LR=0.000100
[2025-08-11 13:35:12,409][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010824] [Batch 01086/04869] [00:09:41/00:33:44, 0.535s/it]: train_loss_raw=0.3384, running_loss=0.3777, LR=0.000100
[2025-08-11 13:35:18,642][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010836] [Batch 01098/04869] [00:09:47/00:33:37, 0.535s/it]: train_loss_raw=0.4340, running_loss=0.3766, LR=0.000100
[2025-08-11 13:35:24,857][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010848] [Batch 01110/04869] [00:09:53/00:33:30, 0.535s/it]: train_loss_raw=0.5533, running_loss=0.3793, LR=0.000100
[2025-08-11 13:35:31,218][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010860] [Batch 01122/04869] [00:09:59/00:33:23, 0.535s/it]: train_loss_raw=0.3895, running_loss=0.3799, LR=0.000100
[2025-08-11 13:35:37,706][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010872] [Batch 01134/04869] [00:10:06/00:33:17, 0.535s/it]: train_loss_raw=0.3513, running_loss=0.3790, LR=0.000100
[2025-08-11 13:35:43,891][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010884] [Batch 01146/04869] [00:10:12/00:33:10, 0.535s/it]: train_loss_raw=0.5218, running_loss=0.3805, LR=0.000100
[2025-08-11 13:35:50,347][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010896] [Batch 01158/04869] [00:10:19/00:33:03, 0.535s/it]: train_loss_raw=0.3477, running_loss=0.3823, LR=0.000100
[2025-08-11 13:35:56,834][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010908] [Batch 01170/04869] [00:10:25/00:32:57, 0.535s/it]: train_loss_raw=0.5206, running_loss=0.3835, LR=0.000100
[2025-08-11 13:36:03,238][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010920] [Batch 01182/04869] [00:10:31/00:32:51, 0.535s/it]: train_loss_raw=0.4221, running_loss=0.3832, LR=0.000100
[2025-08-11 13:36:09,612][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010932] [Batch 01194/04869] [00:10:38/00:32:44, 0.535s/it]: train_loss_raw=0.4625, running_loss=0.3831, LR=0.000100
[2025-08-11 13:36:15,733][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010944] [Batch 01206/04869] [00:10:44/00:32:37, 0.534s/it]: train_loss_raw=0.3542, running_loss=0.3817, LR=0.000100
[2025-08-11 13:36:22,122][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010956] [Batch 01218/04869] [00:10:50/00:32:30, 0.534s/it]: train_loss_raw=0.3944, running_loss=0.3857, LR=0.000100
[2025-08-11 13:36:28,504][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010968] [Batch 01230/04869] [00:10:57/00:32:24, 0.534s/it]: train_loss_raw=0.3814, running_loss=0.3838, LR=0.000100
[2025-08-11 13:36:34,950][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010980] [Batch 01242/04869] [00:11:03/00:32:18, 0.534s/it]: train_loss_raw=0.2997, running_loss=0.3801, LR=0.000100
[2025-08-11 13:36:41,383][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010992] [Batch 01254/04869] [00:11:10/00:32:11, 0.534s/it]: train_loss_raw=0.4131, running_loss=0.3805, LR=0.000100
[2025-08-11 13:36:47,719][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011004] [Batch 01266/04869] [00:11:16/00:32:05, 0.534s/it]: train_loss_raw=0.3794, running_loss=0.3799, LR=0.000100
[2025-08-11 13:36:53,864][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011016] [Batch 01278/04869] [00:11:22/00:31:57, 0.534s/it]: train_loss_raw=0.3385, running_loss=0.3788, LR=0.000100
[2025-08-11 13:37:00,409][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011028] [Batch 01290/04869] [00:11:29/00:31:51, 0.534s/it]: train_loss_raw=0.3254, running_loss=0.3763, LR=0.000100
[2025-08-11 13:37:06,939][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011040] [Batch 01302/04869] [00:11:35/00:31:45, 0.534s/it]: train_loss_raw=0.4503, running_loss=0.3759, LR=0.000100
[2025-08-11 13:37:13,418][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011052] [Batch 01314/04869] [00:11:42/00:31:39, 0.534s/it]: train_loss_raw=0.3294, running_loss=0.3768, LR=0.000100
[2025-08-11 13:37:19,757][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011064] [Batch 01326/04869] [00:11:48/00:31:33, 0.534s/it]: train_loss_raw=0.4420, running_loss=0.3763, LR=0.000100
[2025-08-11 13:37:26,035][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011076] [Batch 01338/04869] [00:11:54/00:31:26, 0.534s/it]: train_loss_raw=0.3004, running_loss=0.3754, LR=0.000100
[2025-08-11 13:37:32,332][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011088] [Batch 01350/04869] [00:12:01/00:31:19, 0.534s/it]: train_loss_raw=0.2768, running_loss=0.3725, LR=0.000100
[2025-08-11 13:37:38,517][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011100] [Batch 01362/04869] [00:12:07/00:31:12, 0.534s/it]: train_loss_raw=0.3359, running_loss=0.3709, LR=0.000100
[2025-08-11 13:37:44,698][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011112] [Batch 01374/04869] [00:12:13/00:31:05, 0.534s/it]: train_loss_raw=0.4156, running_loss=0.3716, LR=0.000100
[2025-08-11 13:37:51,036][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011124] [Batch 01386/04869] [00:12:19/00:30:58, 0.534s/it]: train_loss_raw=0.3627, running_loss=0.3694, LR=0.000100
[2025-08-11 13:37:57,377][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011136] [Batch 01398/04869] [00:12:26/00:30:52, 0.534s/it]: train_loss_raw=0.4655, running_loss=0.3693, LR=0.000100
[2025-08-11 13:38:03,841][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011148] [Batch 01410/04869] [00:12:32/00:30:46, 0.534s/it]: train_loss_raw=0.3429, running_loss=0.3672, LR=0.000100
[2025-08-11 13:38:10,325][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011160] [Batch 01422/04869] [00:12:39/00:30:39, 0.534s/it]: train_loss_raw=0.3406, running_loss=0.3707, LR=0.000100
[2025-08-11 13:38:16,827][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011172] [Batch 01434/04869] [00:12:45/00:30:33, 0.534s/it]: train_loss_raw=0.3892, running_loss=0.3735, LR=0.000100
[2025-08-11 13:38:23,172][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011184] [Batch 01446/04869] [00:12:51/00:30:27, 0.534s/it]: train_loss_raw=0.3559, running_loss=0.3697, LR=0.000100
[2025-08-11 13:38:29,523][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011196] [Batch 01458/04869] [00:12:58/00:30:20, 0.534s/it]: train_loss_raw=0.4157, running_loss=0.3690, LR=0.000100
[2025-08-11 13:38:35,964][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011208] [Batch 01470/04869] [00:13:04/00:30:14, 0.534s/it]: train_loss_raw=0.3372, running_loss=0.3716, LR=0.000100
[2025-08-11 13:38:42,333][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011220] [Batch 01482/04869] [00:13:11/00:30:07, 0.534s/it]: train_loss_raw=0.4198, running_loss=0.3721, LR=0.000100
[2025-08-11 13:38:48,694][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011232] [Batch 01494/04869] [00:13:17/00:30:01, 0.534s/it]: train_loss_raw=0.4156, running_loss=0.3701, LR=0.000100
[2025-08-11 13:38:55,011][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011244] [Batch 01506/04869] [00:13:23/00:29:54, 0.534s/it]: train_loss_raw=0.3669, running_loss=0.3696, LR=0.000100
[2025-08-11 13:39:01,266][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011256] [Batch 01518/04869] [00:13:29/00:29:48, 0.534s/it]: train_loss_raw=0.3035, running_loss=0.3693, LR=0.000100
[2025-08-11 13:39:07,644][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011268] [Batch 01530/04869] [00:13:36/00:29:41, 0.534s/it]: train_loss_raw=0.4361, running_loss=0.3727, LR=0.000100
[2025-08-11 13:39:13,681][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011280] [Batch 01542/04869] [00:13:42/00:29:34, 0.533s/it]: train_loss_raw=0.3096, running_loss=0.3732, LR=0.000100
[2025-08-11 13:39:20,002][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011292] [Batch 01554/04869] [00:13:48/00:29:27, 0.533s/it]: train_loss_raw=0.2925, running_loss=0.3729, LR=0.000100
[2025-08-11 13:39:26,453][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011304] [Batch 01566/04869] [00:13:55/00:29:21, 0.533s/it]: train_loss_raw=0.3844, running_loss=0.3747, LR=0.000100
[2025-08-11 13:39:32,792][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011316] [Batch 01578/04869] [00:14:01/00:29:15, 0.533s/it]: train_loss_raw=0.3669, running_loss=0.3737, LR=0.000100
[2025-08-11 13:39:39,122][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011328] [Batch 01590/04869] [00:14:07/00:29:08, 0.533s/it]: train_loss_raw=0.3633, running_loss=0.3744, LR=0.000100
[2025-08-11 13:39:45,556][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011340] [Batch 01602/04869] [00:14:14/00:29:02, 0.533s/it]: train_loss_raw=0.3059, running_loss=0.3733, LR=0.000100
[2025-08-11 13:39:52,049][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011352] [Batch 01614/04869] [00:14:20/00:28:55, 0.533s/it]: train_loss_raw=0.3067, running_loss=0.3756, LR=0.000100
[2025-08-11 13:39:58,383][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011364] [Batch 01626/04869] [00:14:27/00:28:49, 0.533s/it]: train_loss_raw=0.3952, running_loss=0.3765, LR=0.000100
[2025-08-11 13:40:04,674][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011376] [Batch 01638/04869] [00:14:33/00:28:42, 0.533s/it]: train_loss_raw=0.3447, running_loss=0.3756, LR=0.000100
[2025-08-11 13:40:11,180][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011388] [Batch 01650/04869] [00:14:39/00:28:36, 0.533s/it]: train_loss_raw=0.4062, running_loss=0.3776, LR=0.000100
[2025-08-11 13:40:17,537][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011400] [Batch 01662/04869] [00:14:46/00:28:30, 0.533s/it]: train_loss_raw=0.4504, running_loss=0.3791, LR=0.000100
[2025-08-11 13:40:23,777][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011412] [Batch 01674/04869] [00:14:52/00:28:23, 0.533s/it]: train_loss_raw=0.4216, running_loss=0.3808, LR=0.000100
[2025-08-11 13:40:30,049][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011424] [Batch 01686/04869] [00:14:58/00:28:16, 0.533s/it]: train_loss_raw=0.2515, running_loss=0.3764, LR=0.000100
[2025-08-11 13:40:36,632][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011436] [Batch 01698/04869] [00:15:05/00:28:10, 0.533s/it]: train_loss_raw=0.3497, running_loss=0.3790, LR=0.000100
[2025-08-11 13:40:42,817][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011448] [Batch 01710/04869] [00:15:11/00:28:03, 0.533s/it]: train_loss_raw=0.2637, running_loss=0.3805, LR=0.000100
[2025-08-11 13:40:49,211][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011460] [Batch 01722/04869] [00:15:17/00:27:57, 0.533s/it]: train_loss_raw=0.3753, running_loss=0.3812, LR=0.000100
[2025-08-11 13:40:55,643][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011472] [Batch 01734/04869] [00:15:24/00:27:51, 0.533s/it]: train_loss_raw=0.3582, running_loss=0.3813, LR=0.000100
[2025-08-11 13:41:02,167][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011484] [Batch 01746/04869] [00:15:30/00:27:45, 0.533s/it]: train_loss_raw=0.4265, running_loss=0.3815, LR=0.000100
[2025-08-11 13:41:08,312][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011496] [Batch 01758/04869] [00:15:37/00:27:38, 0.533s/it]: train_loss_raw=0.3319, running_loss=0.3803, LR=0.000100
[2025-08-11 13:41:14,621][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011508] [Batch 01770/04869] [00:15:43/00:27:31, 0.533s/it]: train_loss_raw=0.4284, running_loss=0.3836, LR=0.000100
[2025-08-11 13:41:21,031][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011520] [Batch 01782/04869] [00:15:49/00:27:25, 0.533s/it]: train_loss_raw=0.3294, running_loss=0.3817, LR=0.000100
[2025-08-11 13:41:27,467][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011532] [Batch 01794/04869] [00:15:56/00:27:18, 0.533s/it]: train_loss_raw=0.5468, running_loss=0.3838, LR=0.000100
[2025-08-11 13:41:33,875][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011544] [Batch 01806/04869] [00:16:02/00:27:12, 0.533s/it]: train_loss_raw=0.4473, running_loss=0.3838, LR=0.000100
[2025-08-11 13:41:40,137][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011556] [Batch 01818/04869] [00:16:08/00:27:05, 0.533s/it]: train_loss_raw=0.3145, running_loss=0.3849, LR=0.000100
[2025-08-11 13:41:46,338][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011568] [Batch 01830/04869] [00:16:15/00:26:59, 0.533s/it]: train_loss_raw=0.3729, running_loss=0.3831, LR=0.000100
[2025-08-11 13:41:52,781][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011580] [Batch 01842/04869] [00:16:21/00:26:52, 0.533s/it]: train_loss_raw=0.3634, running_loss=0.3821, LR=0.000100
[2025-08-11 13:41:59,295][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011592] [Batch 01854/04869] [00:16:28/00:26:46, 0.533s/it]: train_loss_raw=0.3344, running_loss=0.3826, LR=0.000100
[2025-08-11 13:42:05,654][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011604] [Batch 01866/04869] [00:16:34/00:26:40, 0.533s/it]: train_loss_raw=0.3511, running_loss=0.3812, LR=0.000100
[2025-08-11 13:42:12,077][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011616] [Batch 01878/04869] [00:16:40/00:26:33, 0.533s/it]: train_loss_raw=0.3531, running_loss=0.3827, LR=0.000100
[2025-08-11 13:42:18,401][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011628] [Batch 01890/04869] [00:16:47/00:26:27, 0.533s/it]: train_loss_raw=0.4125, running_loss=0.3821, LR=0.000100
[2025-08-11 13:42:24,637][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011640] [Batch 01902/04869] [00:16:53/00:26:20, 0.533s/it]: train_loss_raw=0.4727, running_loss=0.3820, LR=0.000100
[2025-08-11 13:42:30,731][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011652] [Batch 01914/04869] [00:16:59/00:26:13, 0.533s/it]: train_loss_raw=0.3165, running_loss=0.3784, LR=0.000100
[2025-08-11 13:42:36,972][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011664] [Batch 01926/04869] [00:17:05/00:26:07, 0.533s/it]: train_loss_raw=0.3117, running_loss=0.3775, LR=0.000100
[2025-08-11 13:42:43,329][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011676] [Batch 01938/04869] [00:17:12/00:26:00, 0.533s/it]: train_loss_raw=0.3814, running_loss=0.3796, LR=0.000100
[2025-08-11 13:42:49,593][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011688] [Batch 01950/04869] [00:17:18/00:25:54, 0.532s/it]: train_loss_raw=0.3410, running_loss=0.3811, LR=0.000100
[2025-08-11 13:42:56,069][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011700] [Batch 01962/04869] [00:17:24/00:25:48, 0.533s/it]: train_loss_raw=0.4059, running_loss=0.3811, LR=0.000100
[2025-08-11 13:43:02,275][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011712] [Batch 01974/04869] [00:17:30/00:25:41, 0.532s/it]: train_loss_raw=0.4274, running_loss=0.3757, LR=0.000100
[2025-08-11 13:43:08,482][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011724] [Batch 01986/04869] [00:17:37/00:25:34, 0.532s/it]: train_loss_raw=0.3145, running_loss=0.3771, LR=0.000100
[2025-08-11 13:43:14,878][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011736] [Batch 01998/04869] [00:17:43/00:25:28, 0.532s/it]: train_loss_raw=0.4337, running_loss=0.3766, LR=0.000100
[2025-08-11 13:43:21,092][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011748] [Batch 02010/04869] [00:17:49/00:25:21, 0.532s/it]: train_loss_raw=0.3642, running_loss=0.3786, LR=0.000100
[2025-08-11 13:43:56,856][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011760] [Batch 02022/04869] [00:18:25/00:25:56, 0.547s/it]: train_loss_raw=0.3517, running_loss=0.3747, LR=0.000100
[2025-08-11 13:44:03,019][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011772] [Batch 02034/04869] [00:18:31/00:25:49, 0.547s/it]: train_loss_raw=0.3077, running_loss=0.3781, LR=0.000100
[2025-08-11 13:44:09,338][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011784] [Batch 02046/04869] [00:18:38/00:25:42, 0.546s/it]: train_loss_raw=0.3743, running_loss=0.3802, LR=0.000100
[2025-08-11 13:44:15,633][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011796] [Batch 02058/04869] [00:18:44/00:25:35, 0.546s/it]: train_loss_raw=0.3177, running_loss=0.3790, LR=0.000100
[2025-08-11 13:44:22,015][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011808] [Batch 02070/04869] [00:18:50/00:25:28, 0.546s/it]: train_loss_raw=0.3200, running_loss=0.3773, LR=0.000100
[2025-08-11 13:44:28,351][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011820] [Batch 02082/04869] [00:18:57/00:25:22, 0.546s/it]: train_loss_raw=0.4012, running_loss=0.3777, LR=0.000100
[2025-08-11 13:44:34,792][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011832] [Batch 02094/04869] [00:19:03/00:25:15, 0.546s/it]: train_loss_raw=0.3693, running_loss=0.3810, LR=0.000100
[2025-08-11 13:44:41,285][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011844] [Batch 02106/04869] [00:19:10/00:25:08, 0.546s/it]: train_loss_raw=0.4515, running_loss=0.3842, LR=0.000100
[2025-08-11 13:44:47,714][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011856] [Batch 02118/04869] [00:19:16/00:25:02, 0.546s/it]: train_loss_raw=0.3791, running_loss=0.3877, LR=0.000100
[2025-08-11 13:44:53,919][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011868] [Batch 02130/04869] [00:19:22/00:24:55, 0.546s/it]: train_loss_raw=0.4227, running_loss=0.3879, LR=0.000100
[2025-08-11 13:45:00,222][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011880] [Batch 02142/04869] [00:19:28/00:24:48, 0.546s/it]: train_loss_raw=0.3218, running_loss=0.3900, LR=0.000100
[2025-08-11 13:45:06,405][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011892] [Batch 02154/04869] [00:19:35/00:24:41, 0.546s/it]: train_loss_raw=0.3330, running_loss=0.3909, LR=0.000100
[2025-08-11 13:45:12,765][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011904] [Batch 02166/04869] [00:19:41/00:24:34, 0.545s/it]: train_loss_raw=0.3951, running_loss=0.3924, LR=0.000100
[2025-08-11 13:45:19,049][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011916] [Batch 02178/04869] [00:19:47/00:24:27, 0.545s/it]: train_loss_raw=0.3516, running_loss=0.3907, LR=0.000100
[2025-08-11 13:45:25,492][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011928] [Batch 02190/04869] [00:19:54/00:24:20, 0.545s/it]: train_loss_raw=0.4130, running_loss=0.3889, LR=0.000100
[2025-08-11 13:45:31,695][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011940] [Batch 02202/04869] [00:20:00/00:24:13, 0.545s/it]: train_loss_raw=0.3709, running_loss=0.3896, LR=0.000100
[2025-08-11 13:45:38,050][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011952] [Batch 02214/04869] [00:20:06/00:24:07, 0.545s/it]: train_loss_raw=0.3792, running_loss=0.3882, LR=0.000100
[2025-08-11 13:45:44,113][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011964] [Batch 02226/04869] [00:20:12/00:24:00, 0.545s/it]: train_loss_raw=0.3626, running_loss=0.3882, LR=0.000100
[2025-08-11 13:45:50,605][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011976] [Batch 02238/04869] [00:20:19/00:23:53, 0.545s/it]: train_loss_raw=0.3666, running_loss=0.3885, LR=0.000100
[2025-08-11 13:45:57,057][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011988] [Batch 02250/04869] [00:20:25/00:23:46, 0.545s/it]: train_loss_raw=0.3761, running_loss=0.3867, LR=0.000100
[2025-08-11 13:46:03,485][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012000] [Batch 02262/04869] [00:20:32/00:23:40, 0.545s/it]: train_loss_raw=0.3813, running_loss=0.3867, LR=0.000100
[2025-08-11 13:46:14,702][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012012] [Batch 02274/04869] [00:20:43/00:23:38, 0.547s/it]: train_loss_raw=0.3092, running_loss=0.3864, LR=0.000100
[2025-08-11 13:46:21,178][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012024] [Batch 02286/04869] [00:20:49/00:23:32, 0.547s/it]: train_loss_raw=0.3639, running_loss=0.3861, LR=0.000100
[2025-08-11 13:46:27,606][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012036] [Batch 02298/04869] [00:20:56/00:23:25, 0.547s/it]: train_loss_raw=0.3169, running_loss=0.3867, LR=0.000100
[2025-08-11 13:46:33,933][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012048] [Batch 02310/04869] [00:21:02/00:23:18, 0.547s/it]: train_loss_raw=0.3216, running_loss=0.3854, LR=0.000100
[2025-08-11 13:46:40,002][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012060] [Batch 02322/04869] [00:21:08/00:23:11, 0.546s/it]: train_loss_raw=0.4169, running_loss=0.3875, LR=0.000100
[2025-08-11 13:46:46,193][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012072] [Batch 02334/04869] [00:21:14/00:23:04, 0.546s/it]: train_loss_raw=0.3392, running_loss=0.3885, LR=0.000100
[2025-08-11 13:46:52,426][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012084] [Batch 02346/04869] [00:21:21/00:22:57, 0.546s/it]: train_loss_raw=0.3707, running_loss=0.3884, LR=0.000100
[2025-08-11 13:46:58,549][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012096] [Batch 02358/04869] [00:21:27/00:22:50, 0.546s/it]: train_loss_raw=0.4404, running_loss=0.3905, LR=0.000100
[2025-08-11 13:47:04,901][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012108] [Batch 02370/04869] [00:21:33/00:22:44, 0.546s/it]: train_loss_raw=0.4795, running_loss=0.3885, LR=0.000100
[2025-08-11 13:47:11,015][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012120] [Batch 02382/04869] [00:21:39/00:22:37, 0.546s/it]: train_loss_raw=0.3279, running_loss=0.3877, LR=0.000100
[2025-08-11 13:47:17,097][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012132] [Batch 02394/04869] [00:21:45/00:22:29, 0.545s/it]: train_loss_raw=0.3567, running_loss=0.3862, LR=0.000100
[2025-08-11 13:47:23,545][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012144] [Batch 02406/04869] [00:21:52/00:22:23, 0.545s/it]: train_loss_raw=0.4931, running_loss=0.3863, LR=0.000100
[2025-08-11 13:47:29,948][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012156] [Batch 02418/04869] [00:21:58/00:22:16, 0.545s/it]: train_loss_raw=0.3590, running_loss=0.3831, LR=0.000100
[2025-08-11 13:47:36,257][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012168] [Batch 02430/04869] [00:22:04/00:22:09, 0.545s/it]: train_loss_raw=0.4455, running_loss=0.3853, LR=0.000100
[2025-08-11 13:47:42,638][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012180] [Batch 02442/04869] [00:22:11/00:22:03, 0.545s/it]: train_loss_raw=0.4186, running_loss=0.3877, LR=0.000100
[2025-08-11 13:47:49,064][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012192] [Batch 02454/04869] [00:22:17/00:21:56, 0.545s/it]: train_loss_raw=0.4167, running_loss=0.3863, LR=0.000100
[2025-08-11 13:47:55,266][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012204] [Batch 02466/04869] [00:22:23/00:21:49, 0.545s/it]: train_loss_raw=0.3805, running_loss=0.3887, LR=0.000100
[2025-08-11 13:48:01,537][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012216] [Batch 02478/04869] [00:22:30/00:21:42, 0.545s/it]: train_loss_raw=0.4178, running_loss=0.3900, LR=0.000100
[2025-08-11 13:48:07,961][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012228] [Batch 02490/04869] [00:22:36/00:21:36, 0.545s/it]: train_loss_raw=0.3862, running_loss=0.3872, LR=0.000100
[2025-08-11 13:48:14,414][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012240] [Batch 02502/04869] [00:22:43/00:21:29, 0.545s/it]: train_loss_raw=0.4262, running_loss=0.3880, LR=0.000100
[2025-08-11 13:48:20,806][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012252] [Batch 02514/04869] [00:22:49/00:21:22, 0.545s/it]: train_loss_raw=0.4203, running_loss=0.3900, LR=0.000100
[2025-08-11 13:48:27,181][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012264] [Batch 02526/04869] [00:22:55/00:21:16, 0.545s/it]: train_loss_raw=0.3063, running_loss=0.3883, LR=0.000100
[2025-08-11 13:48:33,602][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012276] [Batch 02538/04869] [00:23:02/00:21:09, 0.545s/it]: train_loss_raw=0.3674, running_loss=0.3872, LR=0.000100
[2025-08-11 13:48:39,955][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012288] [Batch 02550/04869] [00:23:08/00:21:02, 0.545s/it]: train_loss_raw=0.2919, running_loss=0.3863, LR=0.000100
[2025-08-11 13:48:46,277][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012300] [Batch 02562/04869] [00:23:14/00:20:56, 0.544s/it]: train_loss_raw=0.3954, running_loss=0.3864, LR=0.000100
[2025-08-11 13:48:52,588][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012312] [Batch 02574/04869] [00:23:21/00:20:49, 0.544s/it]: train_loss_raw=0.3882, running_loss=0.3883, LR=0.000100
[2025-08-11 13:48:59,065][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012324] [Batch 02586/04869] [00:23:27/00:20:42, 0.544s/it]: train_loss_raw=0.4993, running_loss=0.3947, LR=0.000100
[2025-08-11 13:49:05,457][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012336] [Batch 02598/04869] [00:23:34/00:20:36, 0.544s/it]: train_loss_raw=0.4208, running_loss=0.3963, LR=0.000100
[2025-08-11 13:49:11,872][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012348] [Batch 02610/04869] [00:23:40/00:20:29, 0.544s/it]: train_loss_raw=0.3962, running_loss=0.3986, LR=0.000100
[2025-08-11 13:49:18,356][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012360] [Batch 02622/04869] [00:23:47/00:20:22, 0.544s/it]: train_loss_raw=0.3914, running_loss=0.4001, LR=0.000100
[2025-08-11 13:49:24,822][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012372] [Batch 02634/04869] [00:23:53/00:20:16, 0.544s/it]: train_loss_raw=0.3390, running_loss=0.3981, LR=0.000100
[2025-08-11 13:49:31,134][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012384] [Batch 02646/04869] [00:23:59/00:20:09, 0.544s/it]: train_loss_raw=0.3798, running_loss=0.3967, LR=0.000100
[2025-08-11 13:49:37,450][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012396] [Batch 02658/04869] [00:24:06/00:20:02, 0.544s/it]: train_loss_raw=0.4090, running_loss=0.3972, LR=0.000100
[2025-08-11 13:49:43,757][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012408] [Batch 02670/04869] [00:24:12/00:19:56, 0.544s/it]: train_loss_raw=0.3653, running_loss=0.3962, LR=0.000100
[2025-08-11 13:49:50,145][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012420] [Batch 02682/04869] [00:24:18/00:19:49, 0.544s/it]: train_loss_raw=0.3763, running_loss=0.3941, LR=0.000100
[2025-08-11 13:49:56,511][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012432] [Batch 02694/04869] [00:24:25/00:19:42, 0.544s/it]: train_loss_raw=0.3791, running_loss=0.3949, LR=0.000100
[2025-08-11 13:50:02,969][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012444] [Batch 02706/04869] [00:24:31/00:19:36, 0.544s/it]: train_loss_raw=0.3571, running_loss=0.3947, LR=0.000100
[2025-08-11 13:50:09,488][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012456] [Batch 02718/04869] [00:24:38/00:19:29, 0.544s/it]: train_loss_raw=0.4587, running_loss=0.3946, LR=0.000100
[2025-08-11 13:50:15,944][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012468] [Batch 02730/04869] [00:24:44/00:19:23, 0.544s/it]: train_loss_raw=0.4099, running_loss=0.3949, LR=0.000100
[2025-08-11 13:50:22,400][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012480] [Batch 02742/04869] [00:24:51/00:19:16, 0.544s/it]: train_loss_raw=0.3525, running_loss=0.3939, LR=0.000100
[2025-08-11 13:50:28,851][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012492] [Batch 02754/04869] [00:24:57/00:19:10, 0.544s/it]: train_loss_raw=0.4087, running_loss=0.3951, LR=0.000100
[2025-08-11 13:50:35,165][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012504] [Batch 02766/04869] [00:25:03/00:19:03, 0.544s/it]: train_loss_raw=0.4289, running_loss=0.3975, LR=0.000100
[2025-08-11 13:50:41,539][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012516] [Batch 02778/04869] [00:25:10/00:18:56, 0.544s/it]: train_loss_raw=0.3551, running_loss=0.3948, LR=0.000100
[2025-08-11 13:50:47,998][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012528] [Batch 02790/04869] [00:25:16/00:18:50, 0.544s/it]: train_loss_raw=0.3862, running_loss=0.3938, LR=0.000100
[2025-08-11 13:50:54,489][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012540] [Batch 02802/04869] [00:25:23/00:18:43, 0.544s/it]: train_loss_raw=0.2539, running_loss=0.3916, LR=0.000100
[2025-08-11 13:51:00,979][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012552] [Batch 02814/04869] [00:25:29/00:18:37, 0.544s/it]: train_loss_raw=0.3767, running_loss=0.3908, LR=0.000100
[2025-08-11 13:51:07,352][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012564] [Batch 02826/04869] [00:25:36/00:18:30, 0.544s/it]: train_loss_raw=0.4115, running_loss=0.3928, LR=0.000100
[2025-08-11 13:51:13,767][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012576] [Batch 02838/04869] [00:25:42/00:18:23, 0.544s/it]: train_loss_raw=0.3991, running_loss=0.3895, LR=0.000100
[2025-08-11 13:51:20,138][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012588] [Batch 02850/04869] [00:25:48/00:18:17, 0.543s/it]: train_loss_raw=0.3442, running_loss=0.3882, LR=0.000100
[2025-08-11 13:51:26,479][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012600] [Batch 02862/04869] [00:25:55/00:18:10, 0.543s/it]: train_loss_raw=0.4336, running_loss=0.3881, LR=0.000100
[2025-08-11 13:51:32,915][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012612] [Batch 02874/04869] [00:26:01/00:18:04, 0.543s/it]: train_loss_raw=0.3177, running_loss=0.3877, LR=0.000100
[2025-08-11 13:51:39,255][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012624] [Batch 02886/04869] [00:26:07/00:17:57, 0.543s/it]: train_loss_raw=0.3849, running_loss=0.3899, LR=0.000100
[2025-08-11 13:51:45,606][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012636] [Batch 02898/04869] [00:26:14/00:17:50, 0.543s/it]: train_loss_raw=0.4070, running_loss=0.3888, LR=0.000100
[2025-08-11 13:51:51,897][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012648] [Batch 02910/04869] [00:26:20/00:17:44, 0.543s/it]: train_loss_raw=0.4159, running_loss=0.3928, LR=0.000100
[2025-08-11 13:51:58,335][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012660] [Batch 02922/04869] [00:26:27/00:17:37, 0.543s/it]: train_loss_raw=0.3714, running_loss=0.3954, LR=0.000100
[2025-08-11 13:52:04,693][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012672] [Batch 02934/04869] [00:26:33/00:17:30, 0.543s/it]: train_loss_raw=0.4020, running_loss=0.3958, LR=0.000100
[2025-08-11 13:52:11,052][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012684] [Batch 02946/04869] [00:26:39/00:17:24, 0.543s/it]: train_loss_raw=0.4674, running_loss=0.3959, LR=0.000100
[2025-08-11 13:52:17,350][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012696] [Batch 02958/04869] [00:26:46/00:17:17, 0.543s/it]: train_loss_raw=0.3215, running_loss=0.3993, LR=0.000100
[2025-08-11 13:52:23,635][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012708] [Batch 02970/04869] [00:26:52/00:17:10, 0.543s/it]: train_loss_raw=0.4985, running_loss=0.3986, LR=0.000100
[2025-08-11 13:52:29,902][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012720] [Batch 02982/04869] [00:26:58/00:17:04, 0.543s/it]: train_loss_raw=0.3971, running_loss=0.3970, LR=0.000100
[2025-08-11 13:52:36,331][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012732] [Batch 02994/04869] [00:27:05/00:16:57, 0.543s/it]: train_loss_raw=0.5366, running_loss=0.3995, LR=0.000100
[2025-08-11 13:52:42,674][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012744] [Batch 03006/04869] [00:27:11/00:16:51, 0.543s/it]: train_loss_raw=0.3892, running_loss=0.3990, LR=0.000100
[2025-08-11 13:52:49,079][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012756] [Batch 03018/04869] [00:27:17/00:16:44, 0.543s/it]: train_loss_raw=0.3296, running_loss=0.3962, LR=0.000100
[2025-08-11 13:52:55,449][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012768] [Batch 03030/04869] [00:27:24/00:16:37, 0.543s/it]: train_loss_raw=0.3985, running_loss=0.3979, LR=0.000100
[2025-08-11 13:53:01,822][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012780] [Batch 03042/04869] [00:27:30/00:16:31, 0.543s/it]: train_loss_raw=0.4186, running_loss=0.3967, LR=0.000100
[2025-08-11 13:53:08,290][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012792] [Batch 03054/04869] [00:27:37/00:16:24, 0.543s/it]: train_loss_raw=0.3727, running_loss=0.3936, LR=0.000100
[2025-08-11 13:53:14,794][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012804] [Batch 03066/04869] [00:27:43/00:16:18, 0.543s/it]: train_loss_raw=0.3955, running_loss=0.3940, LR=0.000100
[2025-08-11 13:53:21,207][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012816] [Batch 03078/04869] [00:27:49/00:16:11, 0.543s/it]: train_loss_raw=0.4065, running_loss=0.3929, LR=0.000100
[2025-08-11 13:53:27,475][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012828] [Batch 03090/04869] [00:27:56/00:16:05, 0.542s/it]: train_loss_raw=0.3897, running_loss=0.3924, LR=0.000100
[2025-08-11 13:53:33,788][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012840] [Batch 03102/04869] [00:28:02/00:15:58, 0.542s/it]: train_loss_raw=0.3502, running_loss=0.3898, LR=0.000100
[2025-08-11 13:53:40,096][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012852] [Batch 03114/04869] [00:28:08/00:15:51, 0.542s/it]: train_loss_raw=0.3099, running_loss=0.3876, LR=0.000100
[2025-08-11 13:53:46,474][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012864] [Batch 03126/04869] [00:28:15/00:15:45, 0.542s/it]: train_loss_raw=0.4359, running_loss=0.3919, LR=0.000100
[2025-08-11 13:53:52,843][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012876] [Batch 03138/04869] [00:28:21/00:15:38, 0.542s/it]: train_loss_raw=0.4232, running_loss=0.3892, LR=0.000100
[2025-08-11 13:53:59,198][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012888] [Batch 03150/04869] [00:28:27/00:15:32, 0.542s/it]: train_loss_raw=0.4224, running_loss=0.3919, LR=0.000100
[2025-08-11 13:54:05,601][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012900] [Batch 03162/04869] [00:28:34/00:15:25, 0.542s/it]: train_loss_raw=0.3368, running_loss=0.3949, LR=0.000100
[2025-08-11 13:54:11,947][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012912] [Batch 03174/04869] [00:28:40/00:15:18, 0.542s/it]: train_loss_raw=0.3781, running_loss=0.3905, LR=0.000100
[2025-08-11 13:54:18,564][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012924] [Batch 03186/04869] [00:28:47/00:15:12, 0.542s/it]: train_loss_raw=0.3837, running_loss=0.3882, LR=0.000100
[2025-08-11 13:54:24,865][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012936] [Batch 03198/04869] [00:28:53/00:15:05, 0.542s/it]: train_loss_raw=0.3415, running_loss=0.3863, LR=0.000100
[2025-08-11 13:54:31,079][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012948] [Batch 03210/04869] [00:28:59/00:14:59, 0.542s/it]: train_loss_raw=0.4890, running_loss=0.3868, LR=0.000100
[2025-08-11 13:54:37,535][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012960] [Batch 03222/04869] [00:29:06/00:14:52, 0.542s/it]: train_loss_raw=0.4436, running_loss=0.3874, LR=0.000100
[2025-08-11 13:54:43,904][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012972] [Batch 03234/04869] [00:29:12/00:14:46, 0.542s/it]: train_loss_raw=0.4158, running_loss=0.3889, LR=0.000100
[2025-08-11 13:54:50,358][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012984] [Batch 03246/04869] [00:29:19/00:14:39, 0.542s/it]: train_loss_raw=0.3790, running_loss=0.3892, LR=0.000100
[2025-08-11 13:54:56,700][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012996] [Batch 03258/04869] [00:29:25/00:14:32, 0.542s/it]: train_loss_raw=0.4067, running_loss=0.3875, LR=0.000100
[2025-08-11 13:55:02,976][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013008] [Batch 03270/04869] [00:29:31/00:14:26, 0.542s/it]: train_loss_raw=0.3657, running_loss=0.3869, LR=0.000100
[2025-08-11 13:55:09,281][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013020] [Batch 03282/04869] [00:29:37/00:14:19, 0.542s/it]: train_loss_raw=0.4717, running_loss=0.3865, LR=0.000100
[2025-08-11 13:55:15,736][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013032] [Batch 03294/04869] [00:29:44/00:14:13, 0.542s/it]: train_loss_raw=0.4517, running_loss=0.3870, LR=0.000100
[2025-08-11 13:55:21,920][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013044] [Batch 03306/04869] [00:29:50/00:14:06, 0.542s/it]: train_loss_raw=0.3736, running_loss=0.3893, LR=0.000100
[2025-08-11 13:55:28,251][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013056] [Batch 03318/04869] [00:29:56/00:13:59, 0.542s/it]: train_loss_raw=0.3687, running_loss=0.3866, LR=0.000100
[2025-08-11 13:55:34,534][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013068] [Batch 03330/04869] [00:30:03/00:13:53, 0.542s/it]: train_loss_raw=0.4502, running_loss=0.3870, LR=0.000100
[2025-08-11 13:55:40,825][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013080] [Batch 03342/04869] [00:30:09/00:13:46, 0.541s/it]: train_loss_raw=0.3903, running_loss=0.3873, LR=0.000100
[2025-08-11 13:55:47,276][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013092] [Batch 03354/04869] [00:30:15/00:13:40, 0.541s/it]: train_loss_raw=0.3015, running_loss=0.3882, LR=0.000100
[2025-08-11 13:55:53,665][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013104] [Batch 03366/04869] [00:30:22/00:13:33, 0.541s/it]: train_loss_raw=0.3699, running_loss=0.3891, LR=0.000100
[2025-08-11 13:56:00,161][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013116] [Batch 03378/04869] [00:30:28/00:13:27, 0.541s/it]: train_loss_raw=0.4807, running_loss=0.3895, LR=0.000100
[2025-08-11 13:56:06,630][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013128] [Batch 03390/04869] [00:30:35/00:13:20, 0.541s/it]: train_loss_raw=0.5235, running_loss=0.3904, LR=0.000100
[2025-08-11 13:56:13,066][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013140] [Batch 03402/04869] [00:30:41/00:13:14, 0.541s/it]: train_loss_raw=0.4424, running_loss=0.3920, LR=0.000100
[2025-08-11 13:56:19,339][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013152] [Batch 03414/04869] [00:30:48/00:13:07, 0.541s/it]: train_loss_raw=0.3855, running_loss=0.3943, LR=0.000100
[2025-08-11 13:56:25,624][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013164] [Batch 03426/04869] [00:30:54/00:13:01, 0.541s/it]: train_loss_raw=0.3790, running_loss=0.3917, LR=0.000100
[2025-08-11 13:56:31,812][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013176] [Batch 03438/04869] [00:31:00/00:12:54, 0.541s/it]: train_loss_raw=0.4359, running_loss=0.3919, LR=0.000100
[2025-08-11 13:56:37,985][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013188] [Batch 03450/04869] [00:31:06/00:12:47, 0.541s/it]: train_loss_raw=0.5069, running_loss=0.3916, LR=0.000100
[2025-08-11 13:56:44,196][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013200] [Batch 03462/04869] [00:31:12/00:12:41, 0.541s/it]: train_loss_raw=0.4645, running_loss=0.3940, LR=0.000100
[2025-08-11 13:56:50,562][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013212] [Batch 03474/04869] [00:31:19/00:12:34, 0.541s/it]: train_loss_raw=0.3424, running_loss=0.3916, LR=0.000100
[2025-08-11 13:56:56,962][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013224] [Batch 03486/04869] [00:31:25/00:12:28, 0.541s/it]: train_loss_raw=0.3693, running_loss=0.3913, LR=0.000100
[2025-08-11 13:57:03,133][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013236] [Batch 03498/04869] [00:31:31/00:12:21, 0.541s/it]: train_loss_raw=0.4485, running_loss=0.3946, LR=0.000100
[2025-08-11 13:57:09,337][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013248] [Batch 03510/04869] [00:31:38/00:12:14, 0.541s/it]: train_loss_raw=0.3518, running_loss=0.3913, LR=0.000100
[2025-08-11 13:57:15,577][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013260] [Batch 03522/04869] [00:31:44/00:12:08, 0.541s/it]: train_loss_raw=0.4319, running_loss=0.3894, LR=0.000100
[2025-08-11 13:57:21,937][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013272] [Batch 03534/04869] [00:31:50/00:12:01, 0.541s/it]: train_loss_raw=0.4687, running_loss=0.3918, LR=0.000100
[2025-08-11 13:57:28,120][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013284] [Batch 03546/04869] [00:31:56/00:11:55, 0.541s/it]: train_loss_raw=0.5331, running_loss=0.3935, LR=0.000100
[2025-08-11 13:57:34,315][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013296] [Batch 03558/04869] [00:32:03/00:11:48, 0.540s/it]: train_loss_raw=0.2805, running_loss=0.3897, LR=0.000100
[2025-08-11 13:57:40,776][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013308] [Batch 03570/04869] [00:32:09/00:11:42, 0.540s/it]: train_loss_raw=0.3349, running_loss=0.3894, LR=0.000100
[2025-08-11 13:57:47,170][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013320] [Batch 03582/04869] [00:32:15/00:11:35, 0.540s/it]: train_loss_raw=0.3777, running_loss=0.3869, LR=0.000100
[2025-08-11 13:57:53,659][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013332] [Batch 03594/04869] [00:32:22/00:11:29, 0.540s/it]: train_loss_raw=0.4248, running_loss=0.3879, LR=0.000100
[2025-08-11 13:58:00,190][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013344] [Batch 03606/04869] [00:32:28/00:11:22, 0.540s/it]: train_loss_raw=0.3076, running_loss=0.3858, LR=0.000100
[2025-08-11 13:58:06,720][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013356] [Batch 03618/04869] [00:32:35/00:11:16, 0.540s/it]: train_loss_raw=0.3174, running_loss=0.3836, LR=0.000100
[2025-08-11 13:58:13,147][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013368] [Batch 03630/04869] [00:32:41/00:11:09, 0.540s/it]: train_loss_raw=0.4353, running_loss=0.3859, LR=0.000100
[2025-08-11 13:58:19,578][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013380] [Batch 03642/04869] [00:32:48/00:11:03, 0.540s/it]: train_loss_raw=0.4431, running_loss=0.3872, LR=0.000100
[2025-08-11 13:58:26,015][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013392] [Batch 03654/04869] [00:32:54/00:10:56, 0.540s/it]: train_loss_raw=0.3139, running_loss=0.3843, LR=0.000100
[2025-08-11 13:58:32,414][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013404] [Batch 03666/04869] [00:33:01/00:10:50, 0.540s/it]: train_loss_raw=0.3911, running_loss=0.3806, LR=0.000100
[2025-08-11 13:58:38,776][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013416] [Batch 03678/04869] [00:33:07/00:10:43, 0.540s/it]: train_loss_raw=0.4372, running_loss=0.3847, LR=0.000100
[2025-08-11 13:58:45,271][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013428] [Batch 03690/04869] [00:33:13/00:10:37, 0.540s/it]: train_loss_raw=0.3269, running_loss=0.3832, LR=0.000100
[2025-08-11 13:58:51,789][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013440] [Batch 03702/04869] [00:33:20/00:10:30, 0.540s/it]: train_loss_raw=0.4551, running_loss=0.3864, LR=0.000100
[2025-08-11 13:58:58,367][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013452] [Batch 03714/04869] [00:33:27/00:10:24, 0.540s/it]: train_loss_raw=0.3992, running_loss=0.3865, LR=0.000100
[2025-08-11 13:59:04,882][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013464] [Batch 03726/04869] [00:33:33/00:10:17, 0.540s/it]: train_loss_raw=0.4075, running_loss=0.3876, LR=0.000100
[2025-08-11 13:59:11,277][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013476] [Batch 03738/04869] [00:33:39/00:10:11, 0.540s/it]: train_loss_raw=0.4564, running_loss=0.3888, LR=0.000100
[2025-08-11 13:59:17,693][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013488] [Batch 03750/04869] [00:33:46/00:10:04, 0.540s/it]: train_loss_raw=0.3660, running_loss=0.3907, LR=0.000100
[2025-08-11 13:59:24,050][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013500] [Batch 03762/04869] [00:33:52/00:09:58, 0.540s/it]: train_loss_raw=0.3205, running_loss=0.3877, LR=0.000100
[2025-08-11 13:59:30,386][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013512] [Batch 03774/04869] [00:33:59/00:09:51, 0.540s/it]: train_loss_raw=0.2700, running_loss=0.3885, LR=0.000100
[2025-08-11 13:59:36,797][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013524] [Batch 03786/04869] [00:34:05/00:09:45, 0.540s/it]: train_loss_raw=0.3798, running_loss=0.3874, LR=0.000100
[2025-08-11 13:59:43,122][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013536] [Batch 03798/04869] [00:34:11/00:09:38, 0.540s/it]: train_loss_raw=0.4104, running_loss=0.3917, LR=0.000100
[2025-08-11 13:59:49,462][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013548] [Batch 03810/04869] [00:34:18/00:09:32, 0.540s/it]: train_loss_raw=0.3802, running_loss=0.3921, LR=0.000100
[2025-08-11 13:59:55,813][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013560] [Batch 03822/04869] [00:34:24/00:09:25, 0.540s/it]: train_loss_raw=0.3768, running_loss=0.3894, LR=0.000100
[2025-08-11 14:00:02,239][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013572] [Batch 03834/04869] [00:34:30/00:09:19, 0.540s/it]: train_loss_raw=0.3703, running_loss=0.3914, LR=0.000100
[2025-08-11 14:00:08,702][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013584] [Batch 03846/04869] [00:34:37/00:09:12, 0.540s/it]: train_loss_raw=0.4318, running_loss=0.3905, LR=0.000100
[2025-08-11 14:00:15,071][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013596] [Batch 03858/04869] [00:34:43/00:09:06, 0.540s/it]: train_loss_raw=0.3393, running_loss=0.3908, LR=0.000100
[2025-08-11 14:00:21,524][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013608] [Batch 03870/04869] [00:34:50/00:08:59, 0.540s/it]: train_loss_raw=0.3690, running_loss=0.3890, LR=0.000100
[2025-08-11 14:00:28,001][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013620] [Batch 03882/04869] [00:34:56/00:08:53, 0.540s/it]: train_loss_raw=0.3765, running_loss=0.3925, LR=0.000100
[2025-08-11 14:00:34,335][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013632] [Batch 03894/04869] [00:35:03/00:08:46, 0.540s/it]: train_loss_raw=0.3462, running_loss=0.3916, LR=0.000100
[2025-08-11 14:00:40,709][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013644] [Batch 03906/04869] [00:35:09/00:08:40, 0.540s/it]: train_loss_raw=0.3383, running_loss=0.3893, LR=0.000100
[2025-08-11 14:00:47,169][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013656] [Batch 03918/04869] [00:35:15/00:08:33, 0.540s/it]: train_loss_raw=0.4363, running_loss=0.3895, LR=0.000100
[2025-08-11 14:00:53,821][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013668] [Batch 03930/04869] [00:35:22/00:08:27, 0.540s/it]: train_loss_raw=0.4375, running_loss=0.3918, LR=0.000100
[2025-08-11 14:01:00,361][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013680] [Batch 03942/04869] [00:35:29/00:08:20, 0.540s/it]: train_loss_raw=0.4123, running_loss=0.3916, LR=0.000100
[2025-08-11 14:01:06,844][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013692] [Batch 03954/04869] [00:35:35/00:08:14, 0.540s/it]: train_loss_raw=0.4307, running_loss=0.3942, LR=0.000100
[2025-08-11 14:01:13,023][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013704] [Batch 03966/04869] [00:35:41/00:08:07, 0.540s/it]: train_loss_raw=0.4360, running_loss=0.3965, LR=0.000100
[2025-08-11 14:01:19,472][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013716] [Batch 03978/04869] [00:35:48/00:08:01, 0.540s/it]: train_loss_raw=0.4657, running_loss=0.3944, LR=0.000100
[2025-08-11 14:01:25,970][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013728] [Batch 03990/04869] [00:35:54/00:07:54, 0.540s/it]: train_loss_raw=0.2787, running_loss=0.3908, LR=0.000100
[2025-08-11 14:01:32,325][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013740] [Batch 04002/04869] [00:36:01/00:07:48, 0.540s/it]: train_loss_raw=0.3143, running_loss=0.3908, LR=0.000100
[2025-08-11 14:01:38,592][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013752] [Batch 04014/04869] [00:36:07/00:07:41, 0.540s/it]: train_loss_raw=0.4163, running_loss=0.3920, LR=0.000100
[2025-08-11 14:01:45,016][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013764] [Batch 04026/04869] [00:36:13/00:07:35, 0.540s/it]: train_loss_raw=0.3574, running_loss=0.3905, LR=0.000100
[2025-08-11 14:01:51,456][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013776] [Batch 04038/04869] [00:36:20/00:07:28, 0.540s/it]: train_loss_raw=0.3572, running_loss=0.3894, LR=0.000100
[2025-08-11 14:01:57,823][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013788] [Batch 04050/04869] [00:36:26/00:07:22, 0.540s/it]: train_loss_raw=0.3348, running_loss=0.3897, LR=0.000100
[2025-08-11 14:02:03,981][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013800] [Batch 04062/04869] [00:36:32/00:07:15, 0.540s/it]: train_loss_raw=0.4570, running_loss=0.3923, LR=0.000100
[2025-08-11 14:02:10,188][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013812] [Batch 04074/04869] [00:36:38/00:07:09, 0.540s/it]: train_loss_raw=0.4593, running_loss=0.3903, LR=0.000100
[2025-08-11 14:02:16,326][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013824] [Batch 04086/04869] [00:36:45/00:07:02, 0.540s/it]: train_loss_raw=0.4069, running_loss=0.3902, LR=0.000100
[2025-08-11 14:02:22,773][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013836] [Batch 04098/04869] [00:36:51/00:06:56, 0.540s/it]: train_loss_raw=0.4517, running_loss=0.3921, LR=0.000100
[2025-08-11 14:02:28,925][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013848] [Batch 04110/04869] [00:36:57/00:06:49, 0.540s/it]: train_loss_raw=0.3720, running_loss=0.3942, LR=0.000100
[2025-08-11 14:02:35,076][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013860] [Batch 04122/04869] [00:37:03/00:06:43, 0.539s/it]: train_loss_raw=0.4186, running_loss=0.3950, LR=0.000100
[2025-08-11 14:02:41,279][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013872] [Batch 04134/04869] [00:37:09/00:06:36, 0.539s/it]: train_loss_raw=0.3661, running_loss=0.3945, LR=0.000100
[2025-08-11 14:02:47,770][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013884] [Batch 04146/04869] [00:37:16/00:06:30, 0.539s/it]: train_loss_raw=0.3870, running_loss=0.3939, LR=0.000100
[2025-08-11 14:02:54,268][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013896] [Batch 04158/04869] [00:37:22/00:06:23, 0.539s/it]: train_loss_raw=0.3361, running_loss=0.3915, LR=0.000100
[2025-08-11 14:03:00,457][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013908] [Batch 04170/04869] [00:37:29/00:06:17, 0.539s/it]: train_loss_raw=0.4263, running_loss=0.3920, LR=0.000100
[2025-08-11 14:03:06,584][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013920] [Batch 04182/04869] [00:37:35/00:06:10, 0.539s/it]: train_loss_raw=0.3765, running_loss=0.3918, LR=0.000100
[2025-08-11 14:03:12,714][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013932] [Batch 04194/04869] [00:37:41/00:06:03, 0.539s/it]: train_loss_raw=0.3446, running_loss=0.3943, LR=0.000100
[2025-08-11 14:03:18,889][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013944] [Batch 04206/04869] [00:37:47/00:05:57, 0.539s/it]: train_loss_raw=0.4513, running_loss=0.3945, LR=0.000100
[2025-08-11 14:03:25,078][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013956] [Batch 04218/04869] [00:37:53/00:05:50, 0.539s/it]: train_loss_raw=0.4223, running_loss=0.3960, LR=0.000100
[2025-08-11 14:03:31,265][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013968] [Batch 04230/04869] [00:37:59/00:05:44, 0.539s/it]: train_loss_raw=0.4313, running_loss=0.3960, LR=0.000100
[2025-08-11 14:03:37,447][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013980] [Batch 04242/04869] [00:38:06/00:05:37, 0.539s/it]: train_loss_raw=0.3960, running_loss=0.3970, LR=0.000100
[2025-08-11 14:03:43,601][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013992] [Batch 04254/04869] [00:38:12/00:05:31, 0.539s/it]: train_loss_raw=0.4031, running_loss=0.4001, LR=0.000100
[2025-08-11 14:03:54,211][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014004] [Batch 04266/04869] [00:38:22/00:05:25, 0.540s/it]: train_loss_raw=0.3947, running_loss=0.3988, LR=0.000100
[2025-08-11 14:04:00,583][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014016] [Batch 04278/04869] [00:38:29/00:05:19, 0.540s/it]: train_loss_raw=0.3033, running_loss=0.3959, LR=0.000100
[2025-08-11 14:04:07,001][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014028] [Batch 04290/04869] [00:38:35/00:05:12, 0.540s/it]: train_loss_raw=0.3876, running_loss=0.3988, LR=0.000100
[2025-08-11 14:04:13,372][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014040] [Batch 04302/04869] [00:38:42/00:05:06, 0.540s/it]: train_loss_raw=0.3701, running_loss=0.3988, LR=0.000100
[2025-08-11 14:04:19,944][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014052] [Batch 04314/04869] [00:38:48/00:04:59, 0.540s/it]: train_loss_raw=0.3031, running_loss=0.4009, LR=0.000100
[2025-08-11 14:04:26,270][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014064] [Batch 04326/04869] [00:38:54/00:04:53, 0.540s/it]: train_loss_raw=0.2514, running_loss=0.3984, LR=0.000100
[2025-08-11 14:04:32,621][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014076] [Batch 04338/04869] [00:39:01/00:04:46, 0.540s/it]: train_loss_raw=0.3773, running_loss=0.3940, LR=0.000100
[2025-08-11 14:04:39,073][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014088] [Batch 04350/04869] [00:39:07/00:04:40, 0.540s/it]: train_loss_raw=0.3800, running_loss=0.3963, LR=0.000100
[2025-08-11 14:04:45,521][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014100] [Batch 04362/04869] [00:39:14/00:04:33, 0.540s/it]: train_loss_raw=0.4215, running_loss=0.3962, LR=0.000100
[2025-08-11 14:04:51,949][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014112] [Batch 04374/04869] [00:39:20/00:04:27, 0.540s/it]: train_loss_raw=0.3827, running_loss=0.3922, LR=0.000100
[2025-08-11 14:04:58,290][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014124] [Batch 04386/04869] [00:39:27/00:04:20, 0.540s/it]: train_loss_raw=0.3918, running_loss=0.3935, LR=0.000100
[2025-08-11 14:05:04,704][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014136] [Batch 04398/04869] [00:39:33/00:04:14, 0.540s/it]: train_loss_raw=0.3762, running_loss=0.3939, LR=0.000100
[2025-08-11 14:05:10,997][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014148] [Batch 04410/04869] [00:39:39/00:04:07, 0.540s/it]: train_loss_raw=0.3214, running_loss=0.3921, LR=0.000100
[2025-08-11 14:05:17,361][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014160] [Batch 04422/04869] [00:39:46/00:04:01, 0.540s/it]: train_loss_raw=0.3961, running_loss=0.3955, LR=0.000100
[2025-08-11 14:05:23,690][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014172] [Batch 04434/04869] [00:39:52/00:03:54, 0.540s/it]: train_loss_raw=0.3199, running_loss=0.3949, LR=0.000100
[2025-08-11 14:05:30,041][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014184] [Batch 04446/04869] [00:39:58/00:03:48, 0.540s/it]: train_loss_raw=0.3815, running_loss=0.3935, LR=0.000100
[2025-08-11 14:05:36,379][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014196] [Batch 04458/04869] [00:40:05/00:03:41, 0.540s/it]: train_loss_raw=0.3606, running_loss=0.3946, LR=0.000100
[2025-08-11 14:05:42,922][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014208] [Batch 04470/04869] [00:40:11/00:03:35, 0.540s/it]: train_loss_raw=0.4241, running_loss=0.3959, LR=0.000100
[2025-08-11 14:05:49,328][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014220] [Batch 04482/04869] [00:40:18/00:03:28, 0.540s/it]: train_loss_raw=0.3215, running_loss=0.3916, LR=0.000100
[2025-08-11 14:05:55,668][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014232] [Batch 04494/04869] [00:40:24/00:03:22, 0.539s/it]: train_loss_raw=0.5619, running_loss=0.3898, LR=0.000100
[2025-08-11 14:06:01,966][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014244] [Batch 04506/04869] [00:40:30/00:03:15, 0.539s/it]: train_loss_raw=0.5291, running_loss=0.3889, LR=0.000100
[2025-08-11 14:06:08,338][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014256] [Batch 04518/04869] [00:40:37/00:03:09, 0.539s/it]: train_loss_raw=0.3726, running_loss=0.3900, LR=0.000100
[2025-08-11 14:06:14,868][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014268] [Batch 04530/04869] [00:40:43/00:03:02, 0.539s/it]: train_loss_raw=0.3098, running_loss=0.3910, LR=0.000100
[2025-08-11 14:06:21,191][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014280] [Batch 04542/04869] [00:40:49/00:02:56, 0.539s/it]: train_loss_raw=0.3377, running_loss=0.3913, LR=0.000100
[2025-08-11 14:06:27,649][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014292] [Batch 04554/04869] [00:40:56/00:02:49, 0.539s/it]: train_loss_raw=0.4424, running_loss=0.3899, LR=0.000100
[2025-08-11 14:06:33,996][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014304] [Batch 04566/04869] [00:41:02/00:02:43, 0.539s/it]: train_loss_raw=0.4551, running_loss=0.3914, LR=0.000100
[2025-08-11 14:06:40,219][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014316] [Batch 04578/04869] [00:41:08/00:02:36, 0.539s/it]: train_loss_raw=0.4220, running_loss=0.3881, LR=0.000100
[2025-08-11 14:06:46,431][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014328] [Batch 04590/04869] [00:41:15/00:02:30, 0.539s/it]: train_loss_raw=0.4412, running_loss=0.3875, LR=0.000100
[2025-08-11 14:06:52,755][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014340] [Batch 04602/04869] [00:41:21/00:02:23, 0.539s/it]: train_loss_raw=0.3457, running_loss=0.3868, LR=0.000100
[2025-08-11 14:06:58,965][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014352] [Batch 04614/04869] [00:41:27/00:02:17, 0.539s/it]: train_loss_raw=0.4149, running_loss=0.3876, LR=0.000100
[2025-08-11 14:07:05,088][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014364] [Batch 04626/04869] [00:41:33/00:02:10, 0.539s/it]: train_loss_raw=0.4953, running_loss=0.3896, LR=0.000100
[2025-08-11 14:07:11,482][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014376] [Batch 04638/04869] [00:41:40/00:02:04, 0.539s/it]: train_loss_raw=0.3289, running_loss=0.3869, LR=0.000100
[2025-08-11 14:07:17,978][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014388] [Batch 04650/04869] [00:41:46/00:01:58, 0.539s/it]: train_loss_raw=0.4073, running_loss=0.3896, LR=0.000100
[2025-08-11 14:07:24,341][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014400] [Batch 04662/04869] [00:41:53/00:01:51, 0.539s/it]: train_loss_raw=0.3301, running_loss=0.3857, LR=0.000100
[2025-08-11 14:07:30,690][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014412] [Batch 04674/04869] [00:41:59/00:01:45, 0.539s/it]: train_loss_raw=0.3858, running_loss=0.3836, LR=0.000100
[2025-08-11 14:07:37,210][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014424] [Batch 04686/04869] [00:42:05/00:01:38, 0.539s/it]: train_loss_raw=0.3698, running_loss=0.3814, LR=0.000100
[2025-08-11 14:07:43,489][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014436] [Batch 04698/04869] [00:42:12/00:01:32, 0.539s/it]: train_loss_raw=0.4003, running_loss=0.3816, LR=0.000100
[2025-08-11 14:07:49,829][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014448] [Batch 04710/04869] [00:42:18/00:01:25, 0.539s/it]: train_loss_raw=0.3079, running_loss=0.3794, LR=0.000100
[2025-08-11 14:07:56,098][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014460] [Batch 04722/04869] [00:42:24/00:01:19, 0.539s/it]: train_loss_raw=0.4907, running_loss=0.3838, LR=0.000100
[2025-08-11 14:08:02,341][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014472] [Batch 04734/04869] [00:42:31/00:01:12, 0.539s/it]: train_loss_raw=0.3641, running_loss=0.3817, LR=0.000100
[2025-08-11 14:08:08,533][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014484] [Batch 04746/04869] [00:42:37/00:01:06, 0.539s/it]: train_loss_raw=0.4659, running_loss=0.3838, LR=0.000100
[2025-08-11 14:08:14,916][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014496] [Batch 04758/04869] [00:42:43/00:00:59, 0.539s/it]: train_loss_raw=0.4050, running_loss=0.3830, LR=0.000100
[2025-08-11 14:08:21,313][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014508] [Batch 04770/04869] [00:42:50/00:00:53, 0.539s/it]: train_loss_raw=0.3551, running_loss=0.3828, LR=0.000100
[2025-08-11 14:08:27,732][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014520] [Batch 04782/04869] [00:42:56/00:00:46, 0.539s/it]: train_loss_raw=0.3967, running_loss=0.3836, LR=0.000100
[2025-08-11 14:08:34,292][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014532] [Batch 04794/04869] [00:43:03/00:00:40, 0.539s/it]: train_loss_raw=0.3990, running_loss=0.3848, LR=0.000100
[2025-08-11 14:08:40,889][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014544] [Batch 04806/04869] [00:43:09/00:00:33, 0.539s/it]: train_loss_raw=0.3382, running_loss=0.3836, LR=0.000100
[2025-08-11 14:08:47,296][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014556] [Batch 04818/04869] [00:43:16/00:00:27, 0.539s/it]: train_loss_raw=0.3333, running_loss=0.3838, LR=0.000100
[2025-08-11 14:08:53,726][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014568] [Batch 04830/04869] [00:43:22/00:00:21, 0.539s/it]: train_loss_raw=0.3427, running_loss=0.3835, LR=0.000100
[2025-08-11 14:09:00,198][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014580] [Batch 04842/04869] [00:43:28/00:00:14, 0.539s/it]: train_loss_raw=0.4282, running_loss=0.3851, LR=0.000100
[2025-08-11 14:09:06,772][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014592] [Batch 04854/04869] [00:43:35/00:00:08, 0.539s/it]: train_loss_raw=0.4419, running_loss=0.3871, LR=0.000100
[2025-08-11 14:09:13,117][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014604] [Batch 04866/04869] [00:43:41/00:00:01, 0.539s/it]: train_loss_raw=0.3748, running_loss=0.3868, LR=0.000100
[2025-08-11 14:09:19,438][__main__][INFO] - [VALIDATION] [Epoch 02/29] Starting validation.
[2025-08-11 14:09:34,772][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00011/00062] [00:00:15/00:01:03, 1.278s/it]
[2025-08-11 14:10:07,946][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00023/00062] [00:00:48/00:01:16, 2.021s/it]
[2025-08-11 14:10:22,835][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00035/00062] [00:01:03/00:00:45, 1.761s/it]
[2025-08-11 14:10:36,654][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00047/00062] [00:01:17/00:00:22, 1.609s/it]
[2025-08-11 14:10:50,645][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00059/00062] [00:01:31/00:00:03, 1.520s/it]
[2025-08-11 14:10:52,760][__main__][INFO] - [VALIDATION] [Epoch 02/29] train_loss=0.38874, valid_loss=0.38076
[2025-08-11 14:10:52,761][__main__][INFO] - [VALIDATION] [Epoch 02/29] Metrics:
[2025-08-11 14:10:52,761][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_er      0.198
[2025-08-11 14:10:52,761][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_prec    0.613
[2025-08-11 14:10:52,761][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_recall  0.616
[2025-08-11 14:10:52,761][__main__][INFO] - [VALIDATION] [Epoch 02/29] - pep_recall 0.578
[2025-08-11 14:10:52,766][__main__][INFO] - [TRAIN] [Epoch 02/29] Epoch complete, total time 02:15:31, remaining time 20:19:42, 00:45:10 per epoch
[2025-08-11 14:10:57,373][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014616] [Batch 00009/04869] [00:00:04/00:39:16, 0.485s/it]: train_loss_raw=0.3688, running_loss=0.4744, LR=0.000100
[2025-08-11 14:11:03,816][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014628] [Batch 00021/04869] [00:00:10/00:41:34, 0.515s/it]: train_loss_raw=0.4159, running_loss=0.4635, LR=0.000100
[2025-08-11 14:11:10,186][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014640] [Batch 00033/04869] [00:00:17/00:41:57, 0.521s/it]: train_loss_raw=0.2804, running_loss=0.4541, LR=0.000100
[2025-08-11 14:11:16,496][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014652] [Batch 00045/04869] [00:00:23/00:41:57, 0.522s/it]: train_loss_raw=0.3862, running_loss=0.4484, LR=0.000100
[2025-08-11 14:11:22,822][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014664] [Batch 00057/04869] [00:00:29/00:41:56, 0.523s/it]: train_loss_raw=0.3509, running_loss=0.4432, LR=0.000100
[2025-08-11 14:11:29,185][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014676] [Batch 00069/04869] [00:00:36/00:41:56, 0.524s/it]: train_loss_raw=0.3563, running_loss=0.4365, LR=0.000100
[2025-08-11 14:11:35,539][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014688] [Batch 00081/04869] [00:00:42/00:41:54, 0.525s/it]: train_loss_raw=0.3314, running_loss=0.4294, LR=0.000100
[2025-08-11 14:11:41,856][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014700] [Batch 00093/04869] [00:00:48/00:41:48, 0.525s/it]: train_loss_raw=0.3863, running_loss=0.4226, LR=0.000100
[2025-08-11 14:11:48,205][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014712] [Batch 00105/04869] [00:00:55/00:41:44, 0.526s/it]: train_loss_raw=0.3759, running_loss=0.4170, LR=0.000100
[2025-08-11 14:11:54,604][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014724] [Batch 00117/04869] [00:01:01/00:41:41, 0.526s/it]: train_loss_raw=0.4211, running_loss=0.4135, LR=0.000100
[2025-08-11 14:12:01,015][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014736] [Batch 00129/04869] [00:01:08/00:41:38, 0.527s/it]: train_loss_raw=0.2881, running_loss=0.4113, LR=0.000100
[2025-08-11 14:12:07,364][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014748] [Batch 00141/04869] [00:01:14/00:41:33, 0.527s/it]: train_loss_raw=0.3732, running_loss=0.4050, LR=0.000100
[2025-08-11 14:12:13,673][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014760] [Batch 00153/04869] [00:01:20/00:41:26, 0.527s/it]: train_loss_raw=0.4995, running_loss=0.4021, LR=0.000100
[2025-08-11 14:12:19,972][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014772] [Batch 00165/04869] [00:01:26/00:41:19, 0.527s/it]: train_loss_raw=0.4488, running_loss=0.3999, LR=0.000100
[2025-08-11 14:12:26,331][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014784] [Batch 00177/04869] [00:01:33/00:41:13, 0.527s/it]: train_loss_raw=0.3903, running_loss=0.4001, LR=0.000100
[2025-08-11 14:12:32,806][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014796] [Batch 00189/04869] [00:01:39/00:41:11, 0.528s/it]: train_loss_raw=0.3814, running_loss=0.4005, LR=0.000100
[2025-08-11 14:12:39,197][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014808] [Batch 00201/04869] [00:01:46/00:41:06, 0.528s/it]: train_loss_raw=0.3470, running_loss=0.3990, LR=0.000100
[2025-08-11 14:12:45,530][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014820] [Batch 00213/04869] [00:01:52/00:40:59, 0.528s/it]: train_loss_raw=0.4776, running_loss=0.3976, LR=0.000100
[2025-08-11 14:12:51,943][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014832] [Batch 00225/04869] [00:01:58/00:40:54, 0.529s/it]: train_loss_raw=0.4976, running_loss=0.4023, LR=0.000100
[2025-08-11 14:12:58,393][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014844] [Batch 00237/04869] [00:02:05/00:40:50, 0.529s/it]: train_loss_raw=0.3487, running_loss=0.4002, LR=0.000100
[2025-08-11 14:13:04,876][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014856] [Batch 00249/04869] [00:02:11/00:40:46, 0.530s/it]: train_loss_raw=0.3429, running_loss=0.4007, LR=0.000100
[2025-08-11 14:13:11,245][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014868] [Batch 00261/04869] [00:02:18/00:40:40, 0.530s/it]: train_loss_raw=0.4412, running_loss=0.3979, LR=0.000100
[2025-08-11 14:13:17,588][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014880] [Batch 00273/04869] [00:02:24/00:40:34, 0.530s/it]: train_loss_raw=0.4068, running_loss=0.3969, LR=0.000100
[2025-08-11 14:13:23,926][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014892] [Batch 00285/04869] [00:02:30/00:40:27, 0.530s/it]: train_loss_raw=0.4268, running_loss=0.4006, LR=0.000100
[2025-08-11 14:13:30,246][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014904] [Batch 00297/04869] [00:02:37/00:40:20, 0.529s/it]: train_loss_raw=0.4122, running_loss=0.4014, LR=0.000100
[2025-08-11 14:13:36,583][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014916] [Batch 00309/04869] [00:02:43/00:40:13, 0.529s/it]: train_loss_raw=0.3469, running_loss=0.4013, LR=0.000100
[2025-08-11 14:13:42,896][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014928] [Batch 00321/04869] [00:02:49/00:40:07, 0.529s/it]: train_loss_raw=0.3910, running_loss=0.3990, LR=0.000100
[2025-08-11 14:13:49,357][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014940] [Batch 00333/04869] [00:02:56/00:40:02, 0.530s/it]: train_loss_raw=0.4048, running_loss=0.4004, LR=0.000100
[2025-08-11 14:13:55,831][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014952] [Batch 00345/04869] [00:03:02/00:39:57, 0.530s/it]: train_loss_raw=0.3188, running_loss=0.4000, LR=0.000100
[2025-08-11 14:14:02,235][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014964] [Batch 00357/04869] [00:03:09/00:39:51, 0.530s/it]: train_loss_raw=0.3547, running_loss=0.3993, LR=0.000100
[2025-08-11 14:14:08,803][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014976] [Batch 00369/04869] [00:03:15/00:39:47, 0.531s/it]: train_loss_raw=0.3768, running_loss=0.3957, LR=0.000100
[2025-08-11 14:14:15,117][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014988] [Batch 00381/04869] [00:03:22/00:39:40, 0.530s/it]: train_loss_raw=0.4253, running_loss=0.3953, LR=0.000100
[2025-08-11 14:14:21,418][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015000] [Batch 00393/04869] [00:03:28/00:39:33, 0.530s/it]: train_loss_raw=0.3346, running_loss=0.3941, LR=0.000100
[2025-08-11 14:14:27,737][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015012] [Batch 00405/04869] [00:03:34/00:39:26, 0.530s/it]: train_loss_raw=0.3180, running_loss=0.3935, LR=0.000100
[2025-08-11 14:14:34,167][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015024] [Batch 00417/04869] [00:03:41/00:39:21, 0.530s/it]: train_loss_raw=0.3463, running_loss=0.3928, LR=0.000100
[2025-08-11 14:14:40,526][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015036] [Batch 00429/04869] [00:03:47/00:39:14, 0.530s/it]: train_loss_raw=0.3895, running_loss=0.3910, LR=0.000100
[2025-08-11 14:14:47,005][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015048] [Batch 00441/04869] [00:03:53/00:39:09, 0.531s/it]: train_loss_raw=0.3683, running_loss=0.3905, LR=0.000100
[2025-08-11 14:14:53,482][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015060] [Batch 00453/04869] [00:04:00/00:39:04, 0.531s/it]: train_loss_raw=0.3982, running_loss=0.3894, LR=0.000100
[2025-08-11 14:14:59,862][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015072] [Batch 00465/04869] [00:04:06/00:38:57, 0.531s/it]: train_loss_raw=0.4745, running_loss=0.3889, LR=0.000100
[2025-08-11 14:15:06,330][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015084] [Batch 00477/04869] [00:04:13/00:38:52, 0.531s/it]: train_loss_raw=0.3713, running_loss=0.3858, LR=0.000100
[2025-08-11 14:15:12,704][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015096] [Batch 00489/04869] [00:04:19/00:38:46, 0.531s/it]: train_loss_raw=0.4324, running_loss=0.3859, LR=0.000100
[2025-08-11 14:15:19,144][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015108] [Batch 00501/04869] [00:04:26/00:38:40, 0.531s/it]: train_loss_raw=0.5373, running_loss=0.3866, LR=0.000100
[2025-08-11 14:15:25,517][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015120] [Batch 00513/04869] [00:04:32/00:38:33, 0.531s/it]: train_loss_raw=0.4735, running_loss=0.3869, LR=0.000100
[2025-08-11 14:15:31,880][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015132] [Batch 00525/04869] [00:04:38/00:38:27, 0.531s/it]: train_loss_raw=0.4085, running_loss=0.3908, LR=0.000100
[2025-08-11 14:15:38,229][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015144] [Batch 00537/04869] [00:04:45/00:38:20, 0.531s/it]: train_loss_raw=0.4759, running_loss=0.3940, LR=0.000100
[2025-08-11 14:15:44,561][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015156] [Batch 00549/04869] [00:04:51/00:38:14, 0.531s/it]: train_loss_raw=0.4425, running_loss=0.3958, LR=0.000100
[2025-08-11 14:15:50,948][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015168] [Batch 00561/04869] [00:04:57/00:38:07, 0.531s/it]: train_loss_raw=0.3270, running_loss=0.3895, LR=0.000100
[2025-08-11 14:15:57,449][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015180] [Batch 00573/04869] [00:05:04/00:38:02, 0.531s/it]: train_loss_raw=0.4317, running_loss=0.3916, LR=0.000100
[2025-08-11 14:16:03,873][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015192] [Batch 00585/04869] [00:05:10/00:37:56, 0.531s/it]: train_loss_raw=0.5058, running_loss=0.3917, LR=0.000100
[2025-08-11 14:16:10,215][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015204] [Batch 00597/04869] [00:05:17/00:37:49, 0.531s/it]: train_loss_raw=0.3992, running_loss=0.3922, LR=0.000100
[2025-08-11 14:16:16,653][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015216] [Batch 00609/04869] [00:05:23/00:37:43, 0.531s/it]: train_loss_raw=0.3440, running_loss=0.3928, LR=0.000100
[2025-08-11 14:16:23,041][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015228] [Batch 00621/04869] [00:05:30/00:37:37, 0.531s/it]: train_loss_raw=0.3510, running_loss=0.3894, LR=0.000100
[2025-08-11 14:16:29,486][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015240] [Batch 00633/04869] [00:05:36/00:37:31, 0.532s/it]: train_loss_raw=0.4157, running_loss=0.3894, LR=0.000100
[2025-08-11 14:16:35,946][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015252] [Batch 00645/04869] [00:05:42/00:37:25, 0.532s/it]: train_loss_raw=0.3271, running_loss=0.3866, LR=0.000100
[2025-08-11 14:16:42,408][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015264] [Batch 00657/04869] [00:05:49/00:37:19, 0.532s/it]: train_loss_raw=0.3489, running_loss=0.3837, LR=0.000100
[2025-08-11 14:16:48,873][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015276] [Batch 00669/04869] [00:05:55/00:37:14, 0.532s/it]: train_loss_raw=0.3936, running_loss=0.3824, LR=0.000100
[2025-08-11 14:16:55,216][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015288] [Batch 00681/04869] [00:06:02/00:37:07, 0.532s/it]: train_loss_raw=0.4553, running_loss=0.3858, LR=0.000100
[2025-08-11 14:17:01,574][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015300] [Batch 00693/04869] [00:06:08/00:37:00, 0.532s/it]: train_loss_raw=0.3070, running_loss=0.3844, LR=0.000100
[2025-08-11 14:17:07,992][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015312] [Batch 00705/04869] [00:06:14/00:36:54, 0.532s/it]: train_loss_raw=0.3468, running_loss=0.3855, LR=0.000100
[2025-08-11 14:17:14,518][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015324] [Batch 00717/04869] [00:06:21/00:36:49, 0.532s/it]: train_loss_raw=0.3856, running_loss=0.3818, LR=0.000100
[2025-08-11 14:17:20,866][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015336] [Batch 00729/04869] [00:06:27/00:36:42, 0.532s/it]: train_loss_raw=0.3910, running_loss=0.3840, LR=0.000100
[2025-08-11 14:17:27,265][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015348] [Batch 00741/04869] [00:06:34/00:36:36, 0.532s/it]: train_loss_raw=0.3034, running_loss=0.3830, LR=0.000100
[2025-08-11 14:17:33,597][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015360] [Batch 00753/04869] [00:06:40/00:36:29, 0.532s/it]: train_loss_raw=0.4109, running_loss=0.3844, LR=0.000100
[2025-08-11 14:17:39,923][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015372] [Batch 00765/04869] [00:06:46/00:36:22, 0.532s/it]: train_loss_raw=0.3718, running_loss=0.3832, LR=0.000100
[2025-08-11 14:17:46,267][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015384] [Batch 00777/04869] [00:06:53/00:36:16, 0.532s/it]: train_loss_raw=0.3385, running_loss=0.3825, LR=0.000100
[2025-08-11 14:17:52,590][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015396] [Batch 00789/04869] [00:06:59/00:36:09, 0.532s/it]: train_loss_raw=0.3505, running_loss=0.3843, LR=0.000100
[2025-08-11 14:17:58,986][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015408] [Batch 00801/04869] [00:07:05/00:36:03, 0.532s/it]: train_loss_raw=0.3318, running_loss=0.3850, LR=0.000100
[2025-08-11 14:18:05,398][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015420] [Batch 00813/04869] [00:07:12/00:35:57, 0.532s/it]: train_loss_raw=0.3611, running_loss=0.3807, LR=0.000100
[2025-08-11 14:18:11,758][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015432] [Batch 00825/04869] [00:07:18/00:35:50, 0.532s/it]: train_loss_raw=0.3870, running_loss=0.3800, LR=0.000100
[2025-08-11 14:18:18,071][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015444] [Batch 00837/04869] [00:07:25/00:35:43, 0.532s/it]: train_loss_raw=0.4102, running_loss=0.3797, LR=0.000100
[2025-08-11 14:18:24,427][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015456] [Batch 00849/04869] [00:07:31/00:35:37, 0.532s/it]: train_loss_raw=0.3919, running_loss=0.3806, LR=0.000100
[2025-08-11 14:18:30,926][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015468] [Batch 00861/04869] [00:07:37/00:35:31, 0.532s/it]: train_loss_raw=0.3346, running_loss=0.3820, LR=0.000100
[2025-08-11 14:18:37,273][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015480] [Batch 00873/04869] [00:07:44/00:35:25, 0.532s/it]: train_loss_raw=0.4896, running_loss=0.3819, LR=0.000100
[2025-08-11 14:18:43,525][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015492] [Batch 00885/04869] [00:07:50/00:35:18, 0.532s/it]: train_loss_raw=0.2906, running_loss=0.3801, LR=0.000100
[2025-08-11 14:18:50,051][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015504] [Batch 00897/04869] [00:07:57/00:35:12, 0.532s/it]: train_loss_raw=0.3461, running_loss=0.3840, LR=0.000100
[2025-08-11 14:18:56,600][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015516] [Batch 00909/04869] [00:08:03/00:35:06, 0.532s/it]: train_loss_raw=0.4601, running_loss=0.3846, LR=0.000100
[2025-08-11 14:19:03,138][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015528] [Batch 00921/04869] [00:08:10/00:35:01, 0.532s/it]: train_loss_raw=0.3979, running_loss=0.3833, LR=0.000100
[2025-08-11 14:19:09,605][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015540] [Batch 00933/04869] [00:08:16/00:34:54, 0.532s/it]: train_loss_raw=0.3674, running_loss=0.3847, LR=0.000100
[2025-08-11 14:19:16,005][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015552] [Batch 00945/04869] [00:08:22/00:34:48, 0.532s/it]: train_loss_raw=0.3418, running_loss=0.3824, LR=0.000100
[2025-08-11 14:19:22,403][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015564] [Batch 00957/04869] [00:08:29/00:34:42, 0.532s/it]: train_loss_raw=0.3425, running_loss=0.3839, LR=0.000100
[2025-08-11 14:19:28,754][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015576] [Batch 00969/04869] [00:08:35/00:34:35, 0.532s/it]: train_loss_raw=0.3470, running_loss=0.3850, LR=0.000100
[2025-08-11 14:19:35,095][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015588] [Batch 00981/04869] [00:08:42/00:34:29, 0.532s/it]: train_loss_raw=0.3403, running_loss=0.3833, LR=0.000100
[2025-08-11 14:19:41,451][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015600] [Batch 00993/04869] [00:08:48/00:34:22, 0.532s/it]: train_loss_raw=0.4262, running_loss=0.3850, LR=0.000100
[2025-08-11 14:19:47,832][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015612] [Batch 01005/04869] [00:08:54/00:34:16, 0.532s/it]: train_loss_raw=0.4158, running_loss=0.3859, LR=0.000100
[2025-08-11 14:19:54,446][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015624] [Batch 01017/04869] [00:09:01/00:34:10, 0.532s/it]: train_loss_raw=0.3722, running_loss=0.3861, LR=0.000100
[2025-08-11 14:20:00,853][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015636] [Batch 01029/04869] [00:09:07/00:34:04, 0.532s/it]: train_loss_raw=0.3192, running_loss=0.3843, LR=0.000100
[2025-08-11 14:20:07,263][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015648] [Batch 01041/04869] [00:09:14/00:33:58, 0.532s/it]: train_loss_raw=0.3591, running_loss=0.3838, LR=0.000100
[2025-08-11 14:20:13,675][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015660] [Batch 01053/04869] [00:09:20/00:33:51, 0.532s/it]: train_loss_raw=0.3613, running_loss=0.3868, LR=0.000100
[2025-08-11 14:20:20,011][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015672] [Batch 01065/04869] [00:09:27/00:33:45, 0.532s/it]: train_loss_raw=0.4865, running_loss=0.3884, LR=0.000100
[2025-08-11 14:20:26,402][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015684] [Batch 01077/04869] [00:09:33/00:33:38, 0.532s/it]: train_loss_raw=0.3120, running_loss=0.3911, LR=0.000100
[2025-08-11 14:20:32,815][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015696] [Batch 01089/04869] [00:09:39/00:33:32, 0.532s/it]: train_loss_raw=0.5440, running_loss=0.3904, LR=0.000100
[2025-08-11 14:20:39,268][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015708] [Batch 01101/04869] [00:09:46/00:33:26, 0.532s/it]: train_loss_raw=0.3684, running_loss=0.3886, LR=0.000100
[2025-08-11 14:20:45,633][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015720] [Batch 01113/04869] [00:09:52/00:33:19, 0.532s/it]: train_loss_raw=0.4401, running_loss=0.3923, LR=0.000100
[2025-08-11 14:20:51,968][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015732] [Batch 01125/04869] [00:09:58/00:33:13, 0.532s/it]: train_loss_raw=0.3235, running_loss=0.3895, LR=0.000100
[2025-08-11 14:20:58,365][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015744] [Batch 01137/04869] [00:10:05/00:33:06, 0.532s/it]: train_loss_raw=0.2773, running_loss=0.3871, LR=0.000100
[2025-08-11 14:21:04,718][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015756] [Batch 01149/04869] [00:10:11/00:33:00, 0.532s/it]: train_loss_raw=0.4113, running_loss=0.3869, LR=0.000100
[2025-08-11 14:21:10,929][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015768] [Batch 01161/04869] [00:10:17/00:32:53, 0.532s/it]: train_loss_raw=0.4310, running_loss=0.3899, LR=0.000100
[2025-08-11 14:21:17,158][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015780] [Batch 01173/04869] [00:10:24/00:32:46, 0.532s/it]: train_loss_raw=0.3706, running_loss=0.3875, LR=0.000100
[2025-08-11 14:21:23,322][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015792] [Batch 01185/04869] [00:10:30/00:32:39, 0.532s/it]: train_loss_raw=0.4131, running_loss=0.3906, LR=0.000100
[2025-08-11 14:21:29,727][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015804] [Batch 01197/04869] [00:10:36/00:32:33, 0.532s/it]: train_loss_raw=0.3436, running_loss=0.3882, LR=0.000100
[2025-08-11 14:21:36,171][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015816] [Batch 01209/04869] [00:10:43/00:32:27, 0.532s/it]: train_loss_raw=0.4265, running_loss=0.3890, LR=0.000100
[2025-08-11 14:21:42,648][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015828] [Batch 01221/04869] [00:10:49/00:32:20, 0.532s/it]: train_loss_raw=0.3051, running_loss=0.3897, LR=0.000100
[2025-08-11 14:21:49,093][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015840] [Batch 01233/04869] [00:10:56/00:32:14, 0.532s/it]: train_loss_raw=0.4185, running_loss=0.3888, LR=0.000100
[2025-08-11 14:21:55,534][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015852] [Batch 01245/04869] [00:11:02/00:32:08, 0.532s/it]: train_loss_raw=0.3846, running_loss=0.3875, LR=0.000100
[2025-08-11 14:22:02,036][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015864] [Batch 01257/04869] [00:11:09/00:32:02, 0.532s/it]: train_loss_raw=0.5135, running_loss=0.3865, LR=0.000100
[2025-08-11 14:22:08,505][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015876] [Batch 01269/04869] [00:11:15/00:31:56, 0.532s/it]: train_loss_raw=0.3014, running_loss=0.3878, LR=0.000100
[2025-08-11 14:22:15,001][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015888] [Batch 01281/04869] [00:11:21/00:31:50, 0.532s/it]: train_loss_raw=0.3397, running_loss=0.3862, LR=0.000100
[2025-08-11 14:22:21,628][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015900] [Batch 01293/04869] [00:11:28/00:31:44, 0.533s/it]: train_loss_raw=0.4124, running_loss=0.3854, LR=0.000100
[2025-08-11 14:22:27,960][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015912] [Batch 01305/04869] [00:11:34/00:31:37, 0.533s/it]: train_loss_raw=0.4640, running_loss=0.3883, LR=0.000100
[2025-08-11 14:22:34,314][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015924] [Batch 01317/04869] [00:11:41/00:31:31, 0.533s/it]: train_loss_raw=0.3786, running_loss=0.3850, LR=0.000100
[2025-08-11 14:22:40,653][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015936] [Batch 01329/04869] [00:11:47/00:31:24, 0.532s/it]: train_loss_raw=0.4583, running_loss=0.3866, LR=0.000100
[2025-08-11 14:22:47,013][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015948] [Batch 01341/04869] [00:11:54/00:31:18, 0.532s/it]: train_loss_raw=0.3222, running_loss=0.3869, LR=0.000100
[2025-08-11 14:22:53,334][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015960] [Batch 01353/04869] [00:12:00/00:31:11, 0.532s/it]: train_loss_raw=0.3289, running_loss=0.3856, LR=0.000100
[2025-08-11 14:22:59,696][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015972] [Batch 01365/04869] [00:12:06/00:31:05, 0.532s/it]: train_loss_raw=0.4104, running_loss=0.3873, LR=0.000100
[2025-08-11 14:23:06,047][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015984] [Batch 01377/04869] [00:12:13/00:30:58, 0.532s/it]: train_loss_raw=0.3409, running_loss=0.3878, LR=0.000100
[2025-08-11 14:23:12,557][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015996] [Batch 01389/04869] [00:12:19/00:30:52, 0.532s/it]: train_loss_raw=0.4111, running_loss=0.3887, LR=0.000100
[2025-08-11 14:23:23,610][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016008] [Batch 01401/04869] [00:12:30/00:30:58, 0.536s/it]: train_loss_raw=0.4268, running_loss=0.3897, LR=0.000100
[2025-08-11 14:23:30,109][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016020] [Batch 01413/04869] [00:12:37/00:30:51, 0.536s/it]: train_loss_raw=0.4226, running_loss=0.3896, LR=0.000100
[2025-08-11 14:23:36,517][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016032] [Batch 01425/04869] [00:12:43/00:30:45, 0.536s/it]: train_loss_raw=0.2872, running_loss=0.3877, LR=0.000100
[2025-08-11 14:23:42,850][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016044] [Batch 01437/04869] [00:12:49/00:30:38, 0.536s/it]: train_loss_raw=0.4209, running_loss=0.3910, LR=0.000100
[2025-08-11 14:23:49,139][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016056] [Batch 01449/04869] [00:12:56/00:30:31, 0.536s/it]: train_loss_raw=0.4210, running_loss=0.3899, LR=0.000100
[2025-08-11 14:23:55,475][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016068] [Batch 01461/04869] [00:13:02/00:30:25, 0.536s/it]: train_loss_raw=0.3059, running_loss=0.3871, LR=0.000100
[2025-08-11 14:24:01,843][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016080] [Batch 01473/04869] [00:13:08/00:30:18, 0.536s/it]: train_loss_raw=0.3505, running_loss=0.3872, LR=0.000100
[2025-08-11 14:24:08,216][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016092] [Batch 01485/04869] [00:13:15/00:30:12, 0.535s/it]: train_loss_raw=0.3941, running_loss=0.3857, LR=0.000100
[2025-08-11 14:24:14,392][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016104] [Batch 01497/04869] [00:13:21/00:30:05, 0.535s/it]: train_loss_raw=0.3081, running_loss=0.3852, LR=0.000100
[2025-08-11 14:24:20,736][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016116] [Batch 01509/04869] [00:13:27/00:29:58, 0.535s/it]: train_loss_raw=0.2602, running_loss=0.3832, LR=0.000100
[2025-08-11 14:24:27,059][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016128] [Batch 01521/04869] [00:13:34/00:29:51, 0.535s/it]: train_loss_raw=0.4128, running_loss=0.3854, LR=0.000100
[2025-08-11 14:24:33,419][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016140] [Batch 01533/04869] [00:13:40/00:29:45, 0.535s/it]: train_loss_raw=0.4423, running_loss=0.3846, LR=0.000100
[2025-08-11 14:24:39,830][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016152] [Batch 01545/04869] [00:13:46/00:29:38, 0.535s/it]: train_loss_raw=0.3921, running_loss=0.3840, LR=0.000100
[2025-08-11 14:24:46,116][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016164] [Batch 01557/04869] [00:13:53/00:29:32, 0.535s/it]: train_loss_raw=0.3227, running_loss=0.3833, LR=0.000100
[2025-08-11 14:24:52,324][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016176] [Batch 01569/04869] [00:13:59/00:29:25, 0.535s/it]: train_loss_raw=0.2784, running_loss=0.3827, LR=0.000100
[2025-08-11 14:24:58,491][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016188] [Batch 01581/04869] [00:14:05/00:29:18, 0.535s/it]: train_loss_raw=0.3673, running_loss=0.3833, LR=0.000100
[2025-08-11 14:25:04,712][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016200] [Batch 01593/04869] [00:14:11/00:29:11, 0.535s/it]: train_loss_raw=0.4112, running_loss=0.3842, LR=0.000100
[2025-08-11 14:25:10,929][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016212] [Batch 01605/04869] [00:14:17/00:29:04, 0.535s/it]: train_loss_raw=0.4994, running_loss=0.3831, LR=0.000100
[2025-08-11 14:25:17,120][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016224] [Batch 01617/04869] [00:14:24/00:28:57, 0.534s/it]: train_loss_raw=0.3538, running_loss=0.3821, LR=0.000100
[2025-08-11 14:25:23,294][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016236] [Batch 01629/04869] [00:14:30/00:28:50, 0.534s/it]: train_loss_raw=0.3457, running_loss=0.3813, LR=0.000100
[2025-08-11 14:25:29,428][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016248] [Batch 01641/04869] [00:14:36/00:28:43, 0.534s/it]: train_loss_raw=0.4096, running_loss=0.3836, LR=0.000100
[2025-08-11 14:25:35,632][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016260] [Batch 01653/04869] [00:14:42/00:28:37, 0.534s/it]: train_loss_raw=0.4482, running_loss=0.3823, LR=0.000100
[2025-08-11 14:25:41,771][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016272] [Batch 01665/04869] [00:14:48/00:28:30, 0.534s/it]: train_loss_raw=0.3197, running_loss=0.3803, LR=0.000100
[2025-08-11 14:25:48,027][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016284] [Batch 01677/04869] [00:14:55/00:28:23, 0.534s/it]: train_loss_raw=0.5187, running_loss=0.3823, LR=0.000100
[2025-08-11 14:25:54,191][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016296] [Batch 01689/04869] [00:15:01/00:28:16, 0.534s/it]: train_loss_raw=0.3350, running_loss=0.3811, LR=0.000100
[2025-08-11 14:26:00,326][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016308] [Batch 01701/04869] [00:15:07/00:28:09, 0.533s/it]: train_loss_raw=0.4262, running_loss=0.3788, LR=0.000100
[2025-08-11 14:26:06,530][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016320] [Batch 01713/04869] [00:15:13/00:28:03, 0.533s/it]: train_loss_raw=0.4376, running_loss=0.3789, LR=0.000100
[2025-08-11 14:26:12,656][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016332] [Batch 01725/04869] [00:15:19/00:27:56, 0.533s/it]: train_loss_raw=0.4393, running_loss=0.3853, LR=0.000100
[2025-08-11 14:26:18,790][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016344] [Batch 01737/04869] [00:15:25/00:27:49, 0.533s/it]: train_loss_raw=0.4426, running_loss=0.3839, LR=0.000100
[2025-08-11 14:26:24,957][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016356] [Batch 01749/04869] [00:15:31/00:27:42, 0.533s/it]: train_loss_raw=0.3389, running_loss=0.3851, LR=0.000100
[2025-08-11 14:26:31,209][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016368] [Batch 01761/04869] [00:15:38/00:27:35, 0.533s/it]: train_loss_raw=0.4101, running_loss=0.3854, LR=0.000100
[2025-08-11 14:26:37,402][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016380] [Batch 01773/04869] [00:15:44/00:27:29, 0.533s/it]: train_loss_raw=0.3354, running_loss=0.3832, LR=0.000100
[2025-08-11 14:26:43,578][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016392] [Batch 01785/04869] [00:15:50/00:27:22, 0.533s/it]: train_loss_raw=0.3780, running_loss=0.3842, LR=0.000100
[2025-08-11 14:26:49,740][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016404] [Batch 01797/04869] [00:15:56/00:27:15, 0.532s/it]: train_loss_raw=0.3715, running_loss=0.3847, LR=0.000100
[2025-08-11 14:26:55,864][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016416] [Batch 01809/04869] [00:16:02/00:27:08, 0.532s/it]: train_loss_raw=0.2889, running_loss=0.3835, LR=0.000100
[2025-08-11 14:27:02,222][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016428] [Batch 01821/04869] [00:16:09/00:27:02, 0.532s/it]: train_loss_raw=0.4559, running_loss=0.3828, LR=0.000100
[2025-08-11 14:27:08,547][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016440] [Batch 01833/04869] [00:16:15/00:26:55, 0.532s/it]: train_loss_raw=0.2846, running_loss=0.3836, LR=0.000100
[2025-08-11 14:27:15,027][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016452] [Batch 01845/04869] [00:16:22/00:26:49, 0.532s/it]: train_loss_raw=0.3054, running_loss=0.3847, LR=0.000100
[2025-08-11 14:27:21,441][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016464] [Batch 01857/04869] [00:16:28/00:26:43, 0.532s/it]: train_loss_raw=0.3345, running_loss=0.3851, LR=0.000100
[2025-08-11 14:27:27,889][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016476] [Batch 01869/04869] [00:16:34/00:26:36, 0.532s/it]: train_loss_raw=0.3815, running_loss=0.3834, LR=0.000100
[2025-08-11 14:27:34,194][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016488] [Batch 01881/04869] [00:16:41/00:26:30, 0.532s/it]: train_loss_raw=0.3472, running_loss=0.3791, LR=0.000100
[2025-08-11 14:27:40,660][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016500] [Batch 01893/04869] [00:16:47/00:26:24, 0.532s/it]: train_loss_raw=0.3779, running_loss=0.3793, LR=0.000100
[2025-08-11 14:27:46,962][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016512] [Batch 01905/04869] [00:16:53/00:26:17, 0.532s/it]: train_loss_raw=0.3829, running_loss=0.3804, LR=0.000100
[2025-08-11 14:27:53,318][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016524] [Batch 01917/04869] [00:17:00/00:26:11, 0.532s/it]: train_loss_raw=0.3684, running_loss=0.3802, LR=0.000100
[2025-08-11 14:27:59,733][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016536] [Batch 01929/04869] [00:17:06/00:26:04, 0.532s/it]: train_loss_raw=0.4407, running_loss=0.3833, LR=0.000100
[2025-08-11 14:28:06,015][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016548] [Batch 01941/04869] [00:17:13/00:25:58, 0.532s/it]: train_loss_raw=0.3831, running_loss=0.3860, LR=0.000100
[2025-08-11 14:28:12,452][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016560] [Batch 01953/04869] [00:17:19/00:25:51, 0.532s/it]: train_loss_raw=0.4308, running_loss=0.3867, LR=0.000100
[2025-08-11 14:28:18,949][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016572] [Batch 01965/04869] [00:17:25/00:25:45, 0.532s/it]: train_loss_raw=0.3599, running_loss=0.3884, LR=0.000100
[2025-08-11 14:28:25,392][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016584] [Batch 01977/04869] [00:17:32/00:25:39, 0.532s/it]: train_loss_raw=0.4317, running_loss=0.3910, LR=0.000100
[2025-08-11 14:28:31,733][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016596] [Batch 01989/04869] [00:17:38/00:25:32, 0.532s/it]: train_loss_raw=0.4136, running_loss=0.3912, LR=0.000100
[2025-08-11 14:28:38,148][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016608] [Batch 02001/04869] [00:17:45/00:25:26, 0.532s/it]: train_loss_raw=0.3601, running_loss=0.3927, LR=0.000100
[2025-08-11 14:28:44,471][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016620] [Batch 02013/04869] [00:17:51/00:25:20, 0.532s/it]: train_loss_raw=0.3751, running_loss=0.3915, LR=0.000100
[2025-08-11 14:28:50,594][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016632] [Batch 02025/04869] [00:17:57/00:25:13, 0.532s/it]: train_loss_raw=0.4248, running_loss=0.3925, LR=0.000100
[2025-08-11 14:28:56,930][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016644] [Batch 02037/04869] [00:18:03/00:25:06, 0.532s/it]: train_loss_raw=0.3321, running_loss=0.3930, LR=0.000100
[2025-08-11 14:29:03,376][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016656] [Batch 02049/04869] [00:18:10/00:25:00, 0.532s/it]: train_loss_raw=0.4848, running_loss=0.3927, LR=0.000100
[2025-08-11 14:29:09,776][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016668] [Batch 02061/04869] [00:18:16/00:24:54, 0.532s/it]: train_loss_raw=0.4286, running_loss=0.3900, LR=0.000100
[2025-08-11 14:29:16,140][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016680] [Batch 02073/04869] [00:18:23/00:24:47, 0.532s/it]: train_loss_raw=0.3615, running_loss=0.3886, LR=0.000100
[2025-08-11 14:29:22,453][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016692] [Batch 02085/04869] [00:18:29/00:24:41, 0.532s/it]: train_loss_raw=0.3792, running_loss=0.3873, LR=0.000100
[2025-08-11 14:29:28,807][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016704] [Batch 02097/04869] [00:18:35/00:24:34, 0.532s/it]: train_loss_raw=0.4242, running_loss=0.3865, LR=0.000100
[2025-08-11 14:29:35,134][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016716] [Batch 02109/04869] [00:18:42/00:24:28, 0.532s/it]: train_loss_raw=0.3309, running_loss=0.3849, LR=0.000100
[2025-08-11 14:29:41,484][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016728] [Batch 02121/04869] [00:18:48/00:24:22, 0.532s/it]: train_loss_raw=0.3825, running_loss=0.3879, LR=0.000100
[2025-08-11 14:29:47,959][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016740] [Batch 02133/04869] [00:18:54/00:24:15, 0.532s/it]: train_loss_raw=0.3876, running_loss=0.3905, LR=0.000100
[2025-08-11 14:29:54,086][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016752] [Batch 02145/04869] [00:19:01/00:24:09, 0.532s/it]: train_loss_raw=0.3957, running_loss=0.3871, LR=0.000100
[2025-08-11 14:30:00,397][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016764] [Batch 02157/04869] [00:19:07/00:24:02, 0.532s/it]: train_loss_raw=0.5105, running_loss=0.3873, LR=0.000100
[2025-08-11 14:30:06,587][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016776] [Batch 02169/04869] [00:19:13/00:23:55, 0.532s/it]: train_loss_raw=0.4218, running_loss=0.3842, LR=0.000100
[2025-08-11 14:30:12,865][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016788] [Batch 02181/04869] [00:19:19/00:23:49, 0.532s/it]: train_loss_raw=0.3856, running_loss=0.3843, LR=0.000100
[2025-08-11 14:30:19,208][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016800] [Batch 02193/04869] [00:19:26/00:23:43, 0.532s/it]: train_loss_raw=0.4980, running_loss=0.3850, LR=0.000100
[2025-08-11 14:30:25,364][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016812] [Batch 02205/04869] [00:19:32/00:23:36, 0.532s/it]: train_loss_raw=0.3631, running_loss=0.3862, LR=0.000100
[2025-08-11 14:30:31,872][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016824] [Batch 02217/04869] [00:19:38/00:23:30, 0.532s/it]: train_loss_raw=0.4376, running_loss=0.3862, LR=0.000100
[2025-08-11 14:30:38,093][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016836] [Batch 02229/04869] [00:19:45/00:23:23, 0.532s/it]: train_loss_raw=0.3618, running_loss=0.3861, LR=0.000100
[2025-08-11 14:30:44,250][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016848] [Batch 02241/04869] [00:19:51/00:23:16, 0.532s/it]: train_loss_raw=0.4041, running_loss=0.3864, LR=0.000100
[2025-08-11 14:30:50,413][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016860] [Batch 02253/04869] [00:19:57/00:23:10, 0.531s/it]: train_loss_raw=0.4055, running_loss=0.3857, LR=0.000100
[2025-08-11 14:30:56,561][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016872] [Batch 02265/04869] [00:20:03/00:23:03, 0.531s/it]: train_loss_raw=0.3762, running_loss=0.3837, LR=0.000100
[2025-08-11 14:31:02,734][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016884] [Batch 02277/04869] [00:20:09/00:22:57, 0.531s/it]: train_loss_raw=0.3381, running_loss=0.3810, LR=0.000100
[2025-08-11 14:31:08,874][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016896] [Batch 02289/04869] [00:20:15/00:22:50, 0.531s/it]: train_loss_raw=0.4047, running_loss=0.3814, LR=0.000100
[2025-08-11 14:31:15,011][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016908] [Batch 02301/04869] [00:20:22/00:22:43, 0.531s/it]: train_loss_raw=0.3523, running_loss=0.3784, LR=0.000100
[2025-08-11 14:31:21,135][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016920] [Batch 02313/04869] [00:20:28/00:22:37, 0.531s/it]: train_loss_raw=0.3410, running_loss=0.3810, LR=0.000100
[2025-08-11 14:31:27,261][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016932] [Batch 02325/04869] [00:20:34/00:22:30, 0.531s/it]: train_loss_raw=0.3539, running_loss=0.3773, LR=0.000100
[2025-08-11 14:31:33,405][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016944] [Batch 02337/04869] [00:20:40/00:22:23, 0.531s/it]: train_loss_raw=0.3044, running_loss=0.3763, LR=0.000100
[2025-08-11 14:31:39,529][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016956] [Batch 02349/04869] [00:20:46/00:22:17, 0.531s/it]: train_loss_raw=0.3129, running_loss=0.3786, LR=0.000100
[2025-08-11 14:31:45,648][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016968] [Batch 02361/04869] [00:20:52/00:22:10, 0.531s/it]: train_loss_raw=0.3951, running_loss=0.3807, LR=0.000100
[2025-08-11 14:31:51,787][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016980] [Batch 02373/04869] [00:20:58/00:22:04, 0.530s/it]: train_loss_raw=0.5461, running_loss=0.3829, LR=0.000100
[2025-08-11 14:31:57,927][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016992] [Batch 02385/04869] [00:21:04/00:21:57, 0.530s/it]: train_loss_raw=0.4301, running_loss=0.3861, LR=0.000100
[2025-08-11 14:32:04,116][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017004] [Batch 02397/04869] [00:21:11/00:21:50, 0.530s/it]: train_loss_raw=0.3625, running_loss=0.3857, LR=0.000100
[2025-08-11 14:32:10,291][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017016] [Batch 02409/04869] [00:21:17/00:21:44, 0.530s/it]: train_loss_raw=0.3957, running_loss=0.3895, LR=0.000100
[2025-08-11 14:32:16,433][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017028] [Batch 02421/04869] [00:21:23/00:21:37, 0.530s/it]: train_loss_raw=0.4047, running_loss=0.3848, LR=0.000100
[2025-08-11 14:32:22,607][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017040] [Batch 02433/04869] [00:21:29/00:21:31, 0.530s/it]: train_loss_raw=0.2977, running_loss=0.3811, LR=0.000100
[2025-08-11 14:32:29,064][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017052] [Batch 02445/04869] [00:21:36/00:21:24, 0.530s/it]: train_loss_raw=0.3751, running_loss=0.3812, LR=0.000100
[2025-08-11 14:32:35,237][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017064] [Batch 02457/04869] [00:21:42/00:21:18, 0.530s/it]: train_loss_raw=0.3379, running_loss=0.3788, LR=0.000100
[2025-08-11 14:32:41,384][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017076] [Batch 02469/04869] [00:21:48/00:21:11, 0.530s/it]: train_loss_raw=0.4514, running_loss=0.3800, LR=0.000100
[2025-08-11 14:32:47,578][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017088] [Batch 02481/04869] [00:21:54/00:21:05, 0.530s/it]: train_loss_raw=0.3590, running_loss=0.3771, LR=0.000100
[2025-08-11 14:32:53,901][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017100] [Batch 02493/04869] [00:22:00/00:20:58, 0.530s/it]: train_loss_raw=0.3792, running_loss=0.3784, LR=0.000100
[2025-08-11 14:33:00,343][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017112] [Batch 02505/04869] [00:22:07/00:20:52, 0.530s/it]: train_loss_raw=0.3565, running_loss=0.3767, LR=0.000100
[2025-08-11 14:33:06,463][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017124] [Batch 02517/04869] [00:22:13/00:20:46, 0.530s/it]: train_loss_raw=0.3692, running_loss=0.3754, LR=0.000100
[2025-08-11 14:33:12,963][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017136] [Batch 02529/04869] [00:22:19/00:20:39, 0.530s/it]: train_loss_raw=0.3772, running_loss=0.3771, LR=0.000100
[2025-08-11 14:33:19,419][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017148] [Batch 02541/04869] [00:22:26/00:20:33, 0.530s/it]: train_loss_raw=0.4176, running_loss=0.3766, LR=0.000100
[2025-08-11 14:33:25,862][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017160] [Batch 02553/04869] [00:22:32/00:20:27, 0.530s/it]: train_loss_raw=0.2417, running_loss=0.3733, LR=0.000100
[2025-08-11 14:33:32,253][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017172] [Batch 02565/04869] [00:22:39/00:20:20, 0.530s/it]: train_loss_raw=0.3798, running_loss=0.3737, LR=0.000100
[2025-08-11 14:33:38,614][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017184] [Batch 02577/04869] [00:22:45/00:20:14, 0.530s/it]: train_loss_raw=0.4399, running_loss=0.3726, LR=0.000100
[2025-08-11 14:33:44,963][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017196] [Batch 02589/04869] [00:22:51/00:20:08, 0.530s/it]: train_loss_raw=0.4264, running_loss=0.3767, LR=0.000100
[2025-08-11 14:33:51,258][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017208] [Batch 02601/04869] [00:22:58/00:20:01, 0.530s/it]: train_loss_raw=0.3415, running_loss=0.3778, LR=0.000100
[2025-08-11 14:33:57,609][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017220] [Batch 02613/04869] [00:23:04/00:19:55, 0.530s/it]: train_loss_raw=0.3774, running_loss=0.3786, LR=0.000100
[2025-08-11 14:34:04,046][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017232] [Batch 02625/04869] [00:23:11/00:19:49, 0.530s/it]: train_loss_raw=0.3843, running_loss=0.3790, LR=0.000100
[2025-08-11 14:34:10,443][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017244] [Batch 02637/04869] [00:23:17/00:19:42, 0.530s/it]: train_loss_raw=0.3277, running_loss=0.3790, LR=0.000100
[2025-08-11 14:34:16,892][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017256] [Batch 02649/04869] [00:23:23/00:19:36, 0.530s/it]: train_loss_raw=0.3450, running_loss=0.3815, LR=0.000100
[2025-08-11 14:34:23,285][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017268] [Batch 02661/04869] [00:23:30/00:19:30, 0.530s/it]: train_loss_raw=0.3183, running_loss=0.3762, LR=0.000100
[2025-08-11 14:34:29,620][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017280] [Batch 02673/04869] [00:23:36/00:19:23, 0.530s/it]: train_loss_raw=0.3294, running_loss=0.3753, LR=0.000100
[2025-08-11 14:34:35,960][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017292] [Batch 02685/04869] [00:23:42/00:19:17, 0.530s/it]: train_loss_raw=0.3252, running_loss=0.3774, LR=0.000100
[2025-08-11 14:34:42,284][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017304] [Batch 02697/04869] [00:23:49/00:19:11, 0.530s/it]: train_loss_raw=0.2914, running_loss=0.3782, LR=0.000100
[2025-08-11 14:34:48,615][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017316] [Batch 02709/04869] [00:23:55/00:19:04, 0.530s/it]: train_loss_raw=0.3320, running_loss=0.3794, LR=0.000100
[2025-08-11 14:34:54,943][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017328] [Batch 02721/04869] [00:24:01/00:18:58, 0.530s/it]: train_loss_raw=0.3811, running_loss=0.3781, LR=0.000100
[2025-08-11 14:35:01,256][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017340] [Batch 02733/04869] [00:24:08/00:18:51, 0.530s/it]: train_loss_raw=0.4405, running_loss=0.3790, LR=0.000100
[2025-08-11 14:35:07,632][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017352] [Batch 02745/04869] [00:24:14/00:18:45, 0.530s/it]: train_loss_raw=0.5513, running_loss=0.3823, LR=0.000100
[2025-08-11 14:35:14,094][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017364] [Batch 02757/04869] [00:24:21/00:18:39, 0.530s/it]: train_loss_raw=0.4935, running_loss=0.3836, LR=0.000100
[2025-08-11 14:35:20,474][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017376] [Batch 02769/04869] [00:24:27/00:18:32, 0.530s/it]: train_loss_raw=0.3643, running_loss=0.3843, LR=0.000100
[2025-08-11 14:35:26,878][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017388] [Batch 02781/04869] [00:24:33/00:18:26, 0.530s/it]: train_loss_raw=0.3639, running_loss=0.3873, LR=0.000100
[2025-08-11 14:35:33,423][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017400] [Batch 02793/04869] [00:24:40/00:18:20, 0.530s/it]: train_loss_raw=0.4190, running_loss=0.3885, LR=0.000100
[2025-08-11 14:35:39,879][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017412] [Batch 02805/04869] [00:24:46/00:18:14, 0.530s/it]: train_loss_raw=0.4516, running_loss=0.3892, LR=0.000100
[2025-08-11 14:35:46,184][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017424] [Batch 02817/04869] [00:24:53/00:18:07, 0.530s/it]: train_loss_raw=0.4404, running_loss=0.3879, LR=0.000100
[2025-08-11 14:35:52,435][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017436] [Batch 02829/04869] [00:24:59/00:18:01, 0.530s/it]: train_loss_raw=0.3462, running_loss=0.3840, LR=0.000100
[2025-08-11 14:35:58,570][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017448] [Batch 02841/04869] [00:25:05/00:17:54, 0.530s/it]: train_loss_raw=0.4206, running_loss=0.3847, LR=0.000100
[2025-08-11 14:36:04,714][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017460] [Batch 02853/04869] [00:25:11/00:17:48, 0.530s/it]: train_loss_raw=0.4276, running_loss=0.3846, LR=0.000100
[2025-08-11 14:36:10,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017472] [Batch 02865/04869] [00:25:17/00:17:41, 0.530s/it]: train_loss_raw=0.3963, running_loss=0.3821, LR=0.000100
[2025-08-11 14:36:17,281][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017484] [Batch 02877/04869] [00:25:24/00:17:35, 0.530s/it]: train_loss_raw=0.3870, running_loss=0.3842, LR=0.000100
[2025-08-11 14:36:23,681][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017496] [Batch 02889/04869] [00:25:30/00:17:29, 0.530s/it]: train_loss_raw=0.4516, running_loss=0.3875, LR=0.000100
[2025-08-11 14:36:29,839][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017508] [Batch 02901/04869] [00:25:36/00:17:22, 0.530s/it]: train_loss_raw=0.4840, running_loss=0.3888, LR=0.000100
[2025-08-11 14:36:35,978][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017520] [Batch 02913/04869] [00:25:42/00:17:16, 0.530s/it]: train_loss_raw=0.4272, running_loss=0.3879, LR=0.000100
[2025-08-11 14:36:42,138][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017532] [Batch 02925/04869] [00:25:49/00:17:09, 0.530s/it]: train_loss_raw=0.3074, running_loss=0.3841, LR=0.000100
[2025-08-11 14:36:48,305][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017544] [Batch 02937/04869] [00:25:55/00:17:03, 0.530s/it]: train_loss_raw=0.4615, running_loss=0.3840, LR=0.000100
[2025-08-11 14:36:54,511][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017556] [Batch 02949/04869] [00:26:01/00:16:56, 0.530s/it]: train_loss_raw=0.4007, running_loss=0.3844, LR=0.000100
[2025-08-11 14:37:00,632][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017568] [Batch 02961/04869] [00:26:07/00:16:50, 0.529s/it]: train_loss_raw=0.4427, running_loss=0.3849, LR=0.000100
[2025-08-11 14:37:06,759][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017580] [Batch 02973/04869] [00:26:13/00:16:43, 0.529s/it]: train_loss_raw=0.4515, running_loss=0.3835, LR=0.000100
[2025-08-11 14:37:13,010][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017592] [Batch 02985/04869] [00:26:20/00:16:37, 0.529s/it]: train_loss_raw=0.3181, running_loss=0.3804, LR=0.000100
[2025-08-11 14:37:19,194][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017604] [Batch 02997/04869] [00:26:26/00:16:30, 0.529s/it]: train_loss_raw=0.4024, running_loss=0.3801, LR=0.000100
[2025-08-11 14:37:25,340][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017616] [Batch 03009/04869] [00:26:32/00:16:24, 0.529s/it]: train_loss_raw=0.3680, running_loss=0.3816, LR=0.000100
[2025-08-11 14:37:31,473][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017628] [Batch 03021/04869] [00:26:38/00:16:17, 0.529s/it]: train_loss_raw=0.3168, running_loss=0.3794, LR=0.000100
[2025-08-11 14:37:37,632][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017640] [Batch 03033/04869] [00:26:44/00:16:11, 0.529s/it]: train_loss_raw=0.2645, running_loss=0.3792, LR=0.000100
[2025-08-11 14:37:43,816][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017652] [Batch 03045/04869] [00:26:50/00:16:04, 0.529s/it]: train_loss_raw=0.3382, running_loss=0.3797, LR=0.000100
[2025-08-11 14:37:49,971][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017664] [Batch 03057/04869] [00:26:56/00:15:58, 0.529s/it]: train_loss_raw=0.4056, running_loss=0.3818, LR=0.000100
[2025-08-11 14:37:56,178][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017676] [Batch 03069/04869] [00:27:03/00:15:52, 0.529s/it]: train_loss_raw=0.4103, running_loss=0.3797, LR=0.000100
[2025-08-11 14:38:02,314][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017688] [Batch 03081/04869] [00:27:09/00:15:45, 0.529s/it]: train_loss_raw=0.3678, running_loss=0.3763, LR=0.000100
[2025-08-11 14:38:08,390][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017700] [Batch 03093/04869] [00:27:15/00:15:39, 0.529s/it]: train_loss_raw=0.3480, running_loss=0.3776, LR=0.000100
[2025-08-11 14:38:14,583][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017712] [Batch 03105/04869] [00:27:21/00:15:32, 0.529s/it]: train_loss_raw=0.3717, running_loss=0.3770, LR=0.000100
[2025-08-11 14:38:20,728][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017724] [Batch 03117/04869] [00:27:27/00:15:26, 0.529s/it]: train_loss_raw=0.5383, running_loss=0.3806, LR=0.000100
[2025-08-11 14:38:26,881][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017736] [Batch 03129/04869] [00:27:33/00:15:19, 0.529s/it]: train_loss_raw=0.5256, running_loss=0.3825, LR=0.000100
[2025-08-11 14:38:33,030][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017748] [Batch 03141/04869] [00:27:40/00:15:13, 0.529s/it]: train_loss_raw=0.2889, running_loss=0.3813, LR=0.000100
[2025-08-11 14:38:39,158][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017760] [Batch 03153/04869] [00:27:46/00:15:06, 0.528s/it]: train_loss_raw=0.4545, running_loss=0.3803, LR=0.000100
[2025-08-11 14:38:45,541][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017772] [Batch 03165/04869] [00:27:52/00:15:00, 0.528s/it]: train_loss_raw=0.3872, running_loss=0.3809, LR=0.000100
[2025-08-11 14:38:51,916][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017784] [Batch 03177/04869] [00:27:58/00:14:54, 0.528s/it]: train_loss_raw=0.3858, running_loss=0.3810, LR=0.000100
[2025-08-11 14:38:58,272][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017796] [Batch 03189/04869] [00:28:05/00:14:47, 0.528s/it]: train_loss_raw=0.4059, running_loss=0.3837, LR=0.000100
[2025-08-11 14:39:04,730][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017808] [Batch 03201/04869] [00:28:11/00:14:41, 0.528s/it]: train_loss_raw=0.3422, running_loss=0.3850, LR=0.000100
[2025-08-11 14:39:11,133][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017820] [Batch 03213/04869] [00:28:18/00:14:35, 0.529s/it]: train_loss_raw=0.3831, running_loss=0.3867, LR=0.000100
[2025-08-11 14:39:17,585][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017832] [Batch 03225/04869] [00:28:24/00:14:28, 0.529s/it]: train_loss_raw=0.3376, running_loss=0.3854, LR=0.000100
[2025-08-11 14:39:24,107][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017844] [Batch 03237/04869] [00:28:31/00:14:22, 0.529s/it]: train_loss_raw=0.3930, running_loss=0.3852, LR=0.000100
[2025-08-11 14:39:30,650][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017856] [Batch 03249/04869] [00:28:37/00:14:16, 0.529s/it]: train_loss_raw=0.4231, running_loss=0.3862, LR=0.000100
[2025-08-11 14:39:37,199][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017868] [Batch 03261/04869] [00:28:44/00:14:10, 0.529s/it]: train_loss_raw=0.3446, running_loss=0.3862, LR=0.000100
[2025-08-11 14:39:43,795][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017880] [Batch 03273/04869] [00:28:50/00:14:03, 0.529s/it]: train_loss_raw=0.4196, running_loss=0.3860, LR=0.000100
[2025-08-11 14:39:50,314][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017892] [Batch 03285/04869] [00:28:57/00:13:57, 0.529s/it]: train_loss_raw=0.4613, running_loss=0.3873, LR=0.000100
[2025-08-11 14:39:56,873][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017904] [Batch 03297/04869] [00:29:03/00:13:51, 0.529s/it]: train_loss_raw=0.3844, running_loss=0.3905, LR=0.000100
[2025-08-11 14:40:03,170][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017916] [Batch 03309/04869] [00:29:10/00:13:45, 0.529s/it]: train_loss_raw=0.3675, running_loss=0.3868, LR=0.000100
[2025-08-11 14:40:09,569][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017928] [Batch 03321/04869] [00:29:16/00:13:38, 0.529s/it]: train_loss_raw=0.3176, running_loss=0.3833, LR=0.000100
[2025-08-11 14:40:15,891][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017940] [Batch 03333/04869] [00:29:22/00:13:32, 0.529s/it]: train_loss_raw=0.3301, running_loss=0.3830, LR=0.000100
[2025-08-11 14:40:22,257][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017952] [Batch 03345/04869] [00:29:29/00:13:26, 0.529s/it]: train_loss_raw=0.4153, running_loss=0.3844, LR=0.000100
[2025-08-11 14:40:28,642][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017964] [Batch 03357/04869] [00:29:35/00:13:19, 0.529s/it]: train_loss_raw=0.3270, running_loss=0.3837, LR=0.000100
[2025-08-11 14:40:35,001][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017976] [Batch 03369/04869] [00:29:41/00:13:13, 0.529s/it]: train_loss_raw=0.4087, running_loss=0.3881, LR=0.000100
[2025-08-11 14:40:41,375][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017988] [Batch 03381/04869] [00:29:48/00:13:07, 0.529s/it]: train_loss_raw=0.3688, running_loss=0.3877, LR=0.000100
[2025-08-11 14:40:47,769][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018000] [Batch 03393/04869] [00:29:54/00:13:00, 0.529s/it]: train_loss_raw=0.3734, running_loss=0.3850, LR=0.000100
[2025-08-11 14:40:58,245][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018012] [Batch 03405/04869] [00:30:05/00:12:56, 0.530s/it]: train_loss_raw=0.4102, running_loss=0.3876, LR=0.000100
[2025-08-11 14:41:04,727][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018024] [Batch 03417/04869] [00:30:11/00:12:49, 0.530s/it]: train_loss_raw=0.4272, running_loss=0.3895, LR=0.000100
[2025-08-11 14:41:11,161][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018036] [Batch 03429/04869] [00:30:18/00:12:43, 0.530s/it]: train_loss_raw=0.3766, running_loss=0.3880, LR=0.000100
[2025-08-11 14:41:17,529][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018048] [Batch 03441/04869] [00:30:24/00:12:37, 0.530s/it]: train_loss_raw=0.3267, running_loss=0.3888, LR=0.000100
[2025-08-11 14:41:23,943][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018060] [Batch 03453/04869] [00:30:30/00:12:30, 0.530s/it]: train_loss_raw=0.3897, running_loss=0.3883, LR=0.000100
[2025-08-11 14:41:30,518][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018072] [Batch 03465/04869] [00:30:37/00:12:24, 0.530s/it]: train_loss_raw=0.4664, running_loss=0.3910, LR=0.000100
[2025-08-11 14:41:36,991][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018084] [Batch 03477/04869] [00:30:43/00:12:18, 0.530s/it]: train_loss_raw=0.5084, running_loss=0.3954, LR=0.000100
[2025-08-11 14:41:43,382][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018096] [Batch 03489/04869] [00:30:50/00:12:11, 0.530s/it]: train_loss_raw=0.3837, running_loss=0.3933, LR=0.000100
[2025-08-11 14:41:49,704][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018108] [Batch 03501/04869] [00:30:56/00:12:05, 0.530s/it]: train_loss_raw=0.3412, running_loss=0.3924, LR=0.000100
[2025-08-11 14:41:56,148][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018120] [Batch 03513/04869] [00:31:03/00:11:59, 0.530s/it]: train_loss_raw=0.3529, running_loss=0.3908, LR=0.000100
[2025-08-11 14:42:02,659][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018132] [Batch 03525/04869] [00:31:09/00:11:52, 0.530s/it]: train_loss_raw=0.3487, running_loss=0.3897, LR=0.000100
[2025-08-11 14:42:09,335][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018144] [Batch 03537/04869] [00:31:16/00:11:46, 0.530s/it]: train_loss_raw=0.3533, running_loss=0.3917, LR=0.000100
[2025-08-11 14:42:15,882][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018156] [Batch 03549/04869] [00:31:22/00:11:40, 0.531s/it]: train_loss_raw=0.3823, running_loss=0.3882, LR=0.000100
[2025-08-11 14:42:22,327][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018168] [Batch 03561/04869] [00:31:29/00:11:33, 0.531s/it]: train_loss_raw=0.4233, running_loss=0.3875, LR=0.000100
[2025-08-11 14:42:28,696][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018180] [Batch 03573/04869] [00:31:35/00:11:27, 0.531s/it]: train_loss_raw=0.3368, running_loss=0.3871, LR=0.000100
[2025-08-11 14:42:35,169][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018192] [Batch 03585/04869] [00:31:42/00:11:21, 0.531s/it]: train_loss_raw=0.4059, running_loss=0.3857, LR=0.000100
[2025-08-11 14:42:41,499][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018204] [Batch 03597/04869] [00:31:48/00:11:14, 0.531s/it]: train_loss_raw=0.4552, running_loss=0.3855, LR=0.000100
[2025-08-11 14:42:47,828][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018216] [Batch 03609/04869] [00:31:54/00:11:08, 0.531s/it]: train_loss_raw=0.4535, running_loss=0.3866, LR=0.000100
[2025-08-11 14:42:54,214][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018228] [Batch 03621/04869] [00:32:01/00:11:02, 0.531s/it]: train_loss_raw=0.3548, running_loss=0.3860, LR=0.000100
[2025-08-11 14:43:00,555][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018240] [Batch 03633/04869] [00:32:07/00:10:55, 0.531s/it]: train_loss_raw=0.4634, running_loss=0.3832, LR=0.000100
[2025-08-11 14:43:06,896][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018252] [Batch 03645/04869] [00:32:13/00:10:49, 0.531s/it]: train_loss_raw=0.3415, running_loss=0.3818, LR=0.000100
[2025-08-11 14:43:13,372][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018264] [Batch 03657/04869] [00:32:20/00:10:43, 0.531s/it]: train_loss_raw=0.3989, running_loss=0.3849, LR=0.000100
[2025-08-11 14:43:19,888][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018276] [Batch 03669/04869] [00:32:26/00:10:36, 0.531s/it]: train_loss_raw=0.3815, running_loss=0.3871, LR=0.000100
[2025-08-11 14:43:26,199][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018288] [Batch 03681/04869] [00:32:33/00:10:30, 0.531s/it]: train_loss_raw=0.3395, running_loss=0.3850, LR=0.000100
[2025-08-11 14:43:32,537][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018300] [Batch 03693/04869] [00:32:39/00:10:23, 0.531s/it]: train_loss_raw=0.4206, running_loss=0.3847, LR=0.000100
[2025-08-11 14:43:38,917][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018312] [Batch 03705/04869] [00:32:45/00:10:17, 0.531s/it]: train_loss_raw=0.3972, running_loss=0.3846, LR=0.000100
[2025-08-11 14:43:45,345][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018324] [Batch 03717/04869] [00:32:52/00:10:11, 0.531s/it]: train_loss_raw=0.3985, running_loss=0.3862, LR=0.000100
[2025-08-11 14:43:51,700][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018336] [Batch 03729/04869] [00:32:58/00:10:04, 0.531s/it]: train_loss_raw=0.4286, running_loss=0.3873, LR=0.000100
[2025-08-11 14:43:58,016][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018348] [Batch 03741/04869] [00:33:05/00:09:58, 0.531s/it]: train_loss_raw=0.3655, running_loss=0.3888, LR=0.000100
[2025-08-11 14:44:04,355][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018360] [Batch 03753/04869] [00:33:11/00:09:52, 0.531s/it]: train_loss_raw=0.4462, running_loss=0.3894, LR=0.000100
[2025-08-11 14:44:10,759][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018372] [Batch 03765/04869] [00:33:17/00:09:45, 0.531s/it]: train_loss_raw=0.3835, running_loss=0.3864, LR=0.000100
[2025-08-11 14:44:17,183][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018384] [Batch 03777/04869] [00:33:24/00:09:39, 0.531s/it]: train_loss_raw=0.4276, running_loss=0.3875, LR=0.000100
[2025-08-11 14:44:23,641][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018396] [Batch 03789/04869] [00:33:30/00:09:33, 0.531s/it]: train_loss_raw=0.3519, running_loss=0.3861, LR=0.000100
[2025-08-11 14:44:30,072][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018408] [Batch 03801/04869] [00:33:37/00:09:26, 0.531s/it]: train_loss_raw=0.5275, running_loss=0.3868, LR=0.000100
[2025-08-11 14:44:36,469][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018420] [Batch 03813/04869] [00:33:43/00:09:20, 0.531s/it]: train_loss_raw=0.3948, running_loss=0.3850, LR=0.000100
[2025-08-11 14:44:42,830][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018432] [Batch 03825/04869] [00:33:49/00:09:14, 0.531s/it]: train_loss_raw=0.3675, running_loss=0.3819, LR=0.000100
[2025-08-11 14:44:49,191][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018444] [Batch 03837/04869] [00:33:56/00:09:07, 0.531s/it]: train_loss_raw=0.3450, running_loss=0.3808, LR=0.000100
[2025-08-11 14:44:55,554][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018456] [Batch 03849/04869] [00:34:02/00:09:01, 0.531s/it]: train_loss_raw=0.4577, running_loss=0.3817, LR=0.000100
[2025-08-11 14:45:01,719][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018468] [Batch 03861/04869] [00:34:08/00:08:54, 0.531s/it]: train_loss_raw=0.4693, running_loss=0.3817, LR=0.000100
[2025-08-11 14:45:07,904][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018480] [Batch 03873/04869] [00:34:14/00:08:48, 0.531s/it]: train_loss_raw=0.3639, running_loss=0.3840, LR=0.000100
[2025-08-11 14:45:14,321][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018492] [Batch 03885/04869] [00:34:21/00:08:42, 0.531s/it]: train_loss_raw=0.3517, running_loss=0.3841, LR=0.000100
[2025-08-11 14:45:20,577][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018504] [Batch 03897/04869] [00:34:27/00:08:35, 0.531s/it]: train_loss_raw=0.3882, running_loss=0.3839, LR=0.000100
[2025-08-11 14:45:26,874][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018516] [Batch 03909/04869] [00:34:33/00:08:29, 0.531s/it]: train_loss_raw=0.3859, running_loss=0.3847, LR=0.000100
[2025-08-11 14:45:33,330][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018528] [Batch 03921/04869] [00:34:40/00:08:22, 0.531s/it]: train_loss_raw=0.3478, running_loss=0.3823, LR=0.000100
[2025-08-11 14:45:39,768][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018540] [Batch 03933/04869] [00:34:46/00:08:16, 0.531s/it]: train_loss_raw=0.3291, running_loss=0.3831, LR=0.000100
[2025-08-11 14:45:46,100][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018552] [Batch 03945/04869] [00:34:53/00:08:10, 0.531s/it]: train_loss_raw=0.4204, running_loss=0.3871, LR=0.000100
[2025-08-11 14:45:52,435][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018564] [Batch 03957/04869] [00:34:59/00:08:03, 0.531s/it]: train_loss_raw=0.3414, running_loss=0.3843, LR=0.000100
[2025-08-11 14:45:58,744][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018576] [Batch 03969/04869] [00:35:05/00:07:57, 0.531s/it]: train_loss_raw=0.4491, running_loss=0.3844, LR=0.000100
[2025-08-11 14:46:05,128][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018588] [Batch 03981/04869] [00:35:12/00:07:51, 0.531s/it]: train_loss_raw=0.3591, running_loss=0.3861, LR=0.000100
[2025-08-11 14:46:11,515][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018600] [Batch 03993/04869] [00:35:18/00:07:44, 0.531s/it]: train_loss_raw=0.4810, running_loss=0.3873, LR=0.000100
[2025-08-11 14:46:17,938][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018612] [Batch 04005/04869] [00:35:24/00:07:38, 0.531s/it]: train_loss_raw=0.3678, running_loss=0.3872, LR=0.000100
[2025-08-11 14:46:24,364][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018624] [Batch 04017/04869] [00:35:31/00:07:32, 0.531s/it]: train_loss_raw=0.4660, running_loss=0.3841, LR=0.000100
[2025-08-11 14:46:30,610][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018636] [Batch 04029/04869] [00:35:37/00:07:25, 0.531s/it]: train_loss_raw=0.3433, running_loss=0.3850, LR=0.000100
[2025-08-11 14:46:37,012][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018648] [Batch 04041/04869] [00:35:44/00:07:19, 0.531s/it]: train_loss_raw=0.5533, running_loss=0.3849, LR=0.000100
[2025-08-11 14:46:43,513][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018660] [Batch 04053/04869] [00:35:50/00:07:12, 0.531s/it]: train_loss_raw=0.3841, running_loss=0.3862, LR=0.000100
[2025-08-11 14:46:49,860][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018672] [Batch 04065/04869] [00:35:56/00:07:06, 0.531s/it]: train_loss_raw=0.4182, running_loss=0.3847, LR=0.000100
[2025-08-11 14:46:56,329][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018684] [Batch 04077/04869] [00:36:03/00:07:00, 0.531s/it]: train_loss_raw=0.3422, running_loss=0.3824, LR=0.000100
[2025-08-11 14:47:02,820][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018696] [Batch 04089/04869] [00:36:09/00:06:53, 0.531s/it]: train_loss_raw=0.2666, running_loss=0.3842, LR=0.000100
[2025-08-11 14:47:09,177][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018708] [Batch 04101/04869] [00:36:16/00:06:47, 0.531s/it]: train_loss_raw=0.4347, running_loss=0.3825, LR=0.000100
[2025-08-11 14:47:15,478][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018720] [Batch 04113/04869] [00:36:22/00:06:41, 0.531s/it]: train_loss_raw=0.3423, running_loss=0.3784, LR=0.000100
[2025-08-11 14:47:21,930][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018732] [Batch 04125/04869] [00:36:28/00:06:34, 0.531s/it]: train_loss_raw=0.4205, running_loss=0.3809, LR=0.000100
[2025-08-11 14:47:28,344][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018744] [Batch 04137/04869] [00:36:35/00:06:28, 0.531s/it]: train_loss_raw=0.3205, running_loss=0.3789, LR=0.000100
[2025-08-11 14:47:34,755][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018756] [Batch 04149/04869] [00:36:41/00:06:22, 0.531s/it]: train_loss_raw=0.3531, running_loss=0.3800, LR=0.000100
[2025-08-11 14:47:41,233][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018768] [Batch 04161/04869] [00:36:48/00:06:15, 0.531s/it]: train_loss_raw=0.4558, running_loss=0.3804, LR=0.000100
[2025-08-11 14:47:47,617][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018780] [Batch 04173/04869] [00:36:54/00:06:09, 0.531s/it]: train_loss_raw=0.4322, running_loss=0.3799, LR=0.000100
[2025-08-11 14:47:54,062][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018792] [Batch 04185/04869] [00:37:01/00:06:03, 0.531s/it]: train_loss_raw=0.4009, running_loss=0.3790, LR=0.000100
[2025-08-11 14:48:00,488][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018804] [Batch 04197/04869] [00:37:07/00:05:56, 0.531s/it]: train_loss_raw=0.3888, running_loss=0.3782, LR=0.000100
[2025-08-11 14:48:06,949][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018816] [Batch 04209/04869] [00:37:13/00:05:50, 0.531s/it]: train_loss_raw=0.3647, running_loss=0.3762, LR=0.000100
[2025-08-11 14:48:13,409][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018828] [Batch 04221/04869] [00:37:20/00:05:43, 0.531s/it]: train_loss_raw=0.3627, running_loss=0.3771, LR=0.000100
[2025-08-11 14:48:19,774][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018840] [Batch 04233/04869] [00:37:26/00:05:37, 0.531s/it]: train_loss_raw=0.4480, running_loss=0.3784, LR=0.000100
[2025-08-11 14:48:26,045][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018852] [Batch 04245/04869] [00:37:33/00:05:31, 0.531s/it]: train_loss_raw=0.3833, running_loss=0.3814, LR=0.000100
[2025-08-11 14:48:32,325][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018864] [Batch 04257/04869] [00:37:39/00:05:24, 0.531s/it]: train_loss_raw=0.3338, running_loss=0.3794, LR=0.000100
[2025-08-11 14:48:38,743][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018876] [Batch 04269/04869] [00:37:45/00:05:18, 0.531s/it]: train_loss_raw=0.4323, running_loss=0.3792, LR=0.000100
[2025-08-11 14:48:45,188][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018888] [Batch 04281/04869] [00:37:52/00:05:12, 0.531s/it]: train_loss_raw=0.4413, running_loss=0.3795, LR=0.000100
[2025-08-11 14:48:51,544][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018900] [Batch 04293/04869] [00:37:58/00:05:05, 0.531s/it]: train_loss_raw=0.3798, running_loss=0.3790, LR=0.000100
[2025-08-11 14:48:57,921][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018912] [Batch 04305/04869] [00:38:04/00:04:59, 0.531s/it]: train_loss_raw=0.4244, running_loss=0.3784, LR=0.000100
[2025-08-11 14:49:04,325][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018924] [Batch 04317/04869] [00:38:11/00:04:52, 0.531s/it]: train_loss_raw=0.3260, running_loss=0.3785, LR=0.000100
[2025-08-11 14:49:10,680][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018936] [Batch 04329/04869] [00:38:17/00:04:46, 0.531s/it]: train_loss_raw=0.4556, running_loss=0.3803, LR=0.000100
[2025-08-11 14:49:17,026][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018948] [Batch 04341/04869] [00:38:24/00:04:40, 0.531s/it]: train_loss_raw=0.4392, running_loss=0.3812, LR=0.000100
[2025-08-11 14:49:23,402][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018960] [Batch 04353/04869] [00:38:30/00:04:33, 0.531s/it]: train_loss_raw=0.4692, running_loss=0.3821, LR=0.000100
[2025-08-11 14:49:29,848][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018972] [Batch 04365/04869] [00:38:36/00:04:27, 0.531s/it]: train_loss_raw=0.3875, running_loss=0.3858, LR=0.000100
[2025-08-11 14:49:36,224][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018984] [Batch 04377/04869] [00:38:43/00:04:21, 0.531s/it]: train_loss_raw=0.3835, running_loss=0.3842, LR=0.000100
[2025-08-11 14:49:42,622][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018996] [Batch 04389/04869] [00:38:49/00:04:14, 0.531s/it]: train_loss_raw=0.3907, running_loss=0.3857, LR=0.000100
[2025-08-11 14:49:49,007][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019008] [Batch 04401/04869] [00:38:55/00:04:08, 0.531s/it]: train_loss_raw=0.4434, running_loss=0.3830, LR=0.000100
[2025-08-11 14:49:55,461][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019020] [Batch 04413/04869] [00:39:02/00:04:02, 0.531s/it]: train_loss_raw=0.4318, running_loss=0.3836, LR=0.000100
[2025-08-11 14:50:01,866][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019032] [Batch 04425/04869] [00:39:08/00:03:55, 0.531s/it]: train_loss_raw=0.3878, running_loss=0.3842, LR=0.000100
[2025-08-11 14:50:08,033][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019044] [Batch 04437/04869] [00:39:15/00:03:49, 0.531s/it]: train_loss_raw=0.3187, running_loss=0.3834, LR=0.000100
[2025-08-11 14:50:14,397][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019056] [Batch 04449/04869] [00:39:21/00:03:42, 0.531s/it]: train_loss_raw=0.4382, running_loss=0.3829, LR=0.000100
[2025-08-11 14:50:20,891][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019068] [Batch 04461/04869] [00:39:27/00:03:36, 0.531s/it]: train_loss_raw=0.4189, running_loss=0.3826, LR=0.000100
[2025-08-11 14:50:27,225][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019080] [Batch 04473/04869] [00:39:34/00:03:30, 0.531s/it]: train_loss_raw=0.3753, running_loss=0.3808, LR=0.000100
[2025-08-11 14:50:33,558][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019092] [Batch 04485/04869] [00:39:40/00:03:23, 0.531s/it]: train_loss_raw=0.4010, running_loss=0.3799, LR=0.000100
[2025-08-11 14:50:39,888][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019104] [Batch 04497/04869] [00:39:46/00:03:17, 0.531s/it]: train_loss_raw=0.4745, running_loss=0.3810, LR=0.000100
[2025-08-11 14:50:46,272][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019116] [Batch 04509/04869] [00:39:53/00:03:11, 0.531s/it]: train_loss_raw=0.3688, running_loss=0.3812, LR=0.000100
[2025-08-11 14:50:52,720][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019128] [Batch 04521/04869] [00:39:59/00:03:04, 0.531s/it]: train_loss_raw=0.3658, running_loss=0.3787, LR=0.000100
[2025-08-11 14:50:59,108][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019140] [Batch 04533/04869] [00:40:06/00:02:58, 0.531s/it]: train_loss_raw=0.4156, running_loss=0.3775, LR=0.000100
[2025-08-11 14:51:05,415][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019152] [Batch 04545/04869] [00:40:12/00:02:51, 0.531s/it]: train_loss_raw=0.4254, running_loss=0.3786, LR=0.000100
[2025-08-11 14:51:11,711][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019164] [Batch 04557/04869] [00:40:18/00:02:45, 0.531s/it]: train_loss_raw=0.3885, running_loss=0.3806, LR=0.000100
[2025-08-11 14:51:18,065][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019176] [Batch 04569/04869] [00:40:25/00:02:39, 0.531s/it]: train_loss_raw=0.3277, running_loss=0.3816, LR=0.000100
[2025-08-11 14:51:24,472][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019188] [Batch 04581/04869] [00:40:31/00:02:32, 0.531s/it]: train_loss_raw=0.3659, running_loss=0.3798, LR=0.000100
[2025-08-11 14:51:30,925][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019200] [Batch 04593/04869] [00:40:37/00:02:26, 0.531s/it]: train_loss_raw=0.5160, running_loss=0.3818, LR=0.000100
[2025-08-11 14:51:37,284][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019212] [Batch 04605/04869] [00:40:44/00:02:20, 0.531s/it]: train_loss_raw=0.4717, running_loss=0.3873, LR=0.000100
[2025-08-11 14:51:43,572][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019224] [Batch 04617/04869] [00:40:50/00:02:13, 0.531s/it]: train_loss_raw=0.3437, running_loss=0.3884, LR=0.000100
[2025-08-11 14:51:49,900][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019236] [Batch 04629/04869] [00:40:56/00:02:07, 0.531s/it]: train_loss_raw=0.3788, running_loss=0.3888, LR=0.000100
[2025-08-11 14:51:56,268][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019248] [Batch 04641/04869] [00:41:03/00:02:01, 0.531s/it]: train_loss_raw=0.2979, running_loss=0.3865, LR=0.000100
[2025-08-11 14:52:02,716][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019260] [Batch 04653/04869] [00:41:09/00:01:54, 0.531s/it]: train_loss_raw=0.2917, running_loss=0.3810, LR=0.000100
[2025-08-11 14:52:09,093][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019272] [Batch 04665/04869] [00:41:16/00:01:48, 0.531s/it]: train_loss_raw=0.3577, running_loss=0.3816, LR=0.000100
[2025-08-11 14:52:15,445][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019284] [Batch 04677/04869] [00:41:22/00:01:41, 0.531s/it]: train_loss_raw=0.3896, running_loss=0.3813, LR=0.000100
[2025-08-11 14:52:21,879][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019296] [Batch 04689/04869] [00:41:28/00:01:35, 0.531s/it]: train_loss_raw=0.3904, running_loss=0.3801, LR=0.000100
[2025-08-11 14:52:28,229][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019308] [Batch 04701/04869] [00:41:35/00:01:29, 0.531s/it]: train_loss_raw=0.3649, running_loss=0.3787, LR=0.000100
[2025-08-11 14:52:34,561][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019320] [Batch 04713/04869] [00:41:41/00:01:22, 0.531s/it]: train_loss_raw=0.3414, running_loss=0.3787, LR=0.000100
[2025-08-11 14:52:40,838][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019332] [Batch 04725/04869] [00:41:47/00:01:16, 0.531s/it]: train_loss_raw=0.3094, running_loss=0.3785, LR=0.000100
[2025-08-11 14:52:47,165][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019344] [Batch 04737/04869] [00:41:54/00:01:10, 0.531s/it]: train_loss_raw=0.3804, running_loss=0.3785, LR=0.000100
[2025-08-11 14:52:53,493][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019356] [Batch 04749/04869] [00:42:00/00:01:03, 0.531s/it]: train_loss_raw=0.3446, running_loss=0.3772, LR=0.000100
[2025-08-11 14:52:59,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019368] [Batch 04761/04869] [00:42:06/00:00:57, 0.531s/it]: train_loss_raw=0.3983, running_loss=0.3802, LR=0.000100
[2025-08-11 14:53:06,239][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019380] [Batch 04773/04869] [00:42:13/00:00:50, 0.531s/it]: train_loss_raw=0.4531, running_loss=0.3793, LR=0.000100
[2025-08-11 14:53:12,726][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019392] [Batch 04785/04869] [00:42:19/00:00:44, 0.531s/it]: train_loss_raw=0.3616, running_loss=0.3829, LR=0.000100
[2025-08-11 14:53:19,176][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019404] [Batch 04797/04869] [00:42:26/00:00:38, 0.531s/it]: train_loss_raw=0.3609, running_loss=0.3815, LR=0.000100
[2025-08-11 14:53:25,405][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019416] [Batch 04809/04869] [00:42:32/00:00:31, 0.531s/it]: train_loss_raw=0.4016, running_loss=0.3801, LR=0.000100
[2025-08-11 14:53:31,730][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019428] [Batch 04821/04869] [00:42:38/00:00:25, 0.531s/it]: train_loss_raw=0.3768, running_loss=0.3865, LR=0.000100
[2025-08-11 14:53:38,065][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019440] [Batch 04833/04869] [00:42:45/00:00:19, 0.531s/it]: train_loss_raw=0.4183, running_loss=0.3850, LR=0.000100
[2025-08-11 14:53:44,444][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019452] [Batch 04845/04869] [00:42:51/00:00:12, 0.531s/it]: train_loss_raw=0.2992, running_loss=0.3848, LR=0.000100
[2025-08-11 14:53:50,893][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019464] [Batch 04857/04869] [00:42:57/00:00:06, 0.531s/it]: train_loss_raw=0.4870, running_loss=0.3847, LR=0.000100
[2025-08-11 14:54:05,275][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019476] [Batch 04869/04869] [00:43:12/00:00:00, 0.532s/it]: train_loss_raw=0.4289, running_loss=0.3824, LR=0.000100
[2025-08-11 14:54:09,711][__main__][INFO] - [VALIDATION] [Epoch 03/29] Starting validation.
[2025-08-11 14:54:24,041][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00011/00062] [00:00:14/00:00:59, 1.194s/it]
[2025-08-11 14:54:55,471][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00023/00062] [00:00:45/00:01:12, 1.907s/it]
[2025-08-11 14:55:10,976][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00035/00062] [00:01:01/00:00:44, 1.702s/it]
[2025-08-11 14:55:28,190][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00047/00062] [00:01:18/00:00:22, 1.635s/it]
[2025-08-11 14:55:43,274][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00059/00062] [00:01:33/00:00:03, 1.559s/it]
[2025-08-11 14:55:45,405][__main__][INFO] - [VALIDATION] [Epoch 03/29] train_loss=0.38244, valid_loss=0.37246
[2025-08-11 14:55:45,405][__main__][INFO] - [VALIDATION] [Epoch 03/29] Metrics:
[2025-08-11 14:55:45,405][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_er      0.193
[2025-08-11 14:55:45,405][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_prec    0.629
[2025-08-11 14:55:45,406][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_recall  0.634
[2025-08-11 14:55:45,406][__main__][INFO] - [VALIDATION] [Epoch 03/29] - pep_recall 0.593
[2025-08-11 14:55:45,409][__main__][INFO] - [TRAIN] [Epoch 03/29] Epoch complete, total time 03:00:24, remaining time 19:32:36, 00:45:06 per epoch
[2025-08-11 14:55:51,688][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019488] [Batch 00012/04869] [00:00:06/00:40:50, 0.504s/it]: train_loss_raw=0.5043, running_loss=0.3959, LR=0.000100
[2025-08-11 14:55:58,022][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019500] [Batch 00024/04869] [00:00:12/00:41:40, 0.516s/it]: train_loss_raw=0.4316, running_loss=0.3913, LR=0.000100
[2025-08-11 14:56:04,310][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019512] [Batch 00036/04869] [00:00:18/00:41:47, 0.519s/it]: train_loss_raw=0.4329, running_loss=0.3910, LR=0.000100
[2025-08-11 14:56:10,619][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019524] [Batch 00048/04869] [00:00:24/00:41:49, 0.521s/it]: train_loss_raw=0.4039, running_loss=0.3915, LR=0.000100
[2025-08-11 14:56:16,903][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019536] [Batch 00060/04869] [00:00:31/00:41:46, 0.521s/it]: train_loss_raw=0.4384, running_loss=0.3910, LR=0.000100
[2025-08-11 14:56:23,251][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019548] [Batch 00072/04869] [00:00:37/00:41:46, 0.522s/it]: train_loss_raw=0.2939, running_loss=0.3860, LR=0.000100
[2025-08-11 14:56:29,564][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019560] [Batch 00084/04869] [00:00:43/00:41:42, 0.523s/it]: train_loss_raw=0.3305, running_loss=0.3835, LR=0.000100
[2025-08-11 14:56:35,860][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019572] [Batch 00096/04869] [00:00:50/00:41:37, 0.523s/it]: train_loss_raw=0.3506, running_loss=0.3801, LR=0.000100
[2025-08-11 14:56:42,211][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019584] [Batch 00108/04869] [00:00:56/00:41:34, 0.524s/it]: train_loss_raw=0.3915, running_loss=0.3777, LR=0.000100
[2025-08-11 14:56:48,581][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019596] [Batch 00120/04869] [00:01:02/00:41:31, 0.525s/it]: train_loss_raw=0.4326, running_loss=0.3787, LR=0.000100
[2025-08-11 14:56:54,893][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019608] [Batch 00132/04869] [00:01:09/00:41:25, 0.525s/it]: train_loss_raw=0.3721, running_loss=0.3778, LR=0.000100
[2025-08-11 14:57:01,194][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019620] [Batch 00144/04869] [00:01:15/00:41:19, 0.525s/it]: train_loss_raw=0.4722, running_loss=0.3775, LR=0.000100
[2025-08-11 14:57:07,548][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019632] [Batch 00156/04869] [00:01:21/00:41:14, 0.525s/it]: train_loss_raw=0.2628, running_loss=0.3756, LR=0.000100
[2025-08-11 14:57:13,896][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019644] [Batch 00168/04869] [00:01:28/00:41:09, 0.525s/it]: train_loss_raw=0.3110, running_loss=0.3718, LR=0.000100
[2025-08-11 14:57:20,260][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019656] [Batch 00180/04869] [00:01:34/00:41:04, 0.526s/it]: train_loss_raw=0.4369, running_loss=0.3718, LR=0.000100
[2025-08-11 14:57:26,621][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019668] [Batch 00192/04869] [00:01:40/00:40:59, 0.526s/it]: train_loss_raw=0.3635, running_loss=0.3702, LR=0.000100
[2025-08-11 14:57:32,913][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019680] [Batch 00204/04869] [00:01:47/00:40:53, 0.526s/it]: train_loss_raw=0.3937, running_loss=0.3738, LR=0.000100
[2025-08-11 14:57:39,215][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019692] [Batch 00216/04869] [00:01:53/00:40:46, 0.526s/it]: train_loss_raw=0.3489, running_loss=0.3739, LR=0.000100
[2025-08-11 14:57:45,525][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019704] [Batch 00228/04869] [00:01:59/00:40:40, 0.526s/it]: train_loss_raw=0.3098, running_loss=0.3744, LR=0.000100
[2025-08-11 14:57:51,846][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019716] [Batch 00240/04869] [00:02:06/00:40:34, 0.526s/it]: train_loss_raw=0.4509, running_loss=0.3729, LR=0.000100
[2025-08-11 14:57:58,196][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019728] [Batch 00252/04869] [00:02:12/00:40:28, 0.526s/it]: train_loss_raw=0.4136, running_loss=0.3725, LR=0.000100
[2025-08-11 14:58:04,483][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019740] [Batch 00264/04869] [00:02:18/00:40:21, 0.526s/it]: train_loss_raw=0.3752, running_loss=0.3704, LR=0.000100
[2025-08-11 14:58:10,789][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019752] [Batch 00276/04869] [00:02:25/00:40:15, 0.526s/it]: train_loss_raw=0.3118, running_loss=0.3700, LR=0.000100
[2025-08-11 14:58:17,141][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019764] [Batch 00288/04869] [00:02:31/00:40:09, 0.526s/it]: train_loss_raw=0.4110, running_loss=0.3697, LR=0.000100
[2025-08-11 14:58:23,473][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019776] [Batch 00300/04869] [00:02:37/00:40:03, 0.526s/it]: train_loss_raw=0.3966, running_loss=0.3665, LR=0.000100
[2025-08-11 14:58:29,773][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019788] [Batch 00312/04869] [00:02:44/00:39:57, 0.526s/it]: train_loss_raw=0.4194, running_loss=0.3643, LR=0.000100
[2025-08-11 14:58:36,086][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019800] [Batch 00324/04869] [00:02:50/00:39:51, 0.526s/it]: train_loss_raw=0.4475, running_loss=0.3651, LR=0.000100
[2025-08-11 14:58:42,417][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019812] [Batch 00336/04869] [00:02:56/00:39:44, 0.526s/it]: train_loss_raw=0.3507, running_loss=0.3657, LR=0.000100
[2025-08-11 14:58:48,743][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019824] [Batch 00348/04869] [00:03:03/00:39:38, 0.526s/it]: train_loss_raw=0.4137, running_loss=0.3663, LR=0.000100
[2025-08-11 14:58:55,080][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019836] [Batch 00360/04869] [00:03:09/00:39:32, 0.526s/it]: train_loss_raw=0.4711, running_loss=0.3687, LR=0.000100
[2025-08-11 14:59:01,516][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019848] [Batch 00372/04869] [00:03:15/00:39:27, 0.527s/it]: train_loss_raw=0.4908, running_loss=0.3692, LR=0.000100
[2025-08-11 14:59:07,856][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019860] [Batch 00384/04869] [00:03:22/00:39:21, 0.527s/it]: train_loss_raw=0.3903, running_loss=0.3669, LR=0.000100
[2025-08-11 14:59:14,245][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019872] [Batch 00396/04869] [00:03:28/00:39:16, 0.527s/it]: train_loss_raw=0.5356, running_loss=0.3679, LR=0.000100
[2025-08-11 14:59:20,603][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019884] [Batch 00408/04869] [00:03:34/00:39:10, 0.527s/it]: train_loss_raw=0.3333, running_loss=0.3703, LR=0.000100
[2025-08-11 14:59:27,019][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019896] [Batch 00420/04869] [00:03:41/00:39:05, 0.527s/it]: train_loss_raw=0.4157, running_loss=0.3702, LR=0.000100
[2025-08-11 14:59:33,410][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019908] [Batch 00432/04869] [00:03:47/00:38:59, 0.527s/it]: train_loss_raw=0.4235, running_loss=0.3696, LR=0.000100
[2025-08-11 14:59:39,693][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019920] [Batch 00444/04869] [00:03:54/00:38:52, 0.527s/it]: train_loss_raw=0.3173, running_loss=0.3727, LR=0.000100
[2025-08-11 14:59:46,056][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019932] [Batch 00456/04869] [00:04:00/00:38:46, 0.527s/it]: train_loss_raw=0.4047, running_loss=0.3714, LR=0.000100
[2025-08-11 14:59:52,324][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019944] [Batch 00468/04869] [00:04:06/00:38:39, 0.527s/it]: train_loss_raw=0.3354, running_loss=0.3700, LR=0.000100
[2025-08-11 14:59:58,649][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019956] [Batch 00480/04869] [00:04:13/00:38:33, 0.527s/it]: train_loss_raw=0.3694, running_loss=0.3704, LR=0.000100
[2025-08-11 15:00:04,955][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019968] [Batch 00492/04869] [00:04:19/00:38:27, 0.527s/it]: train_loss_raw=0.3797, running_loss=0.3719, LR=0.000100
[2025-08-11 15:00:11,377][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019980] [Batch 00504/04869] [00:04:25/00:38:21, 0.527s/it]: train_loss_raw=0.4322, running_loss=0.3712, LR=0.000100
[2025-08-11 15:00:17,710][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019992] [Batch 00516/04869] [00:04:32/00:38:15, 0.527s/it]: train_loss_raw=0.5120, running_loss=0.3699, LR=0.000100
[2025-08-11 15:00:28,912][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020004] [Batch 00528/04869] [00:04:43/00:38:48, 0.537s/it]: train_loss_raw=0.4020, running_loss=0.3709, LR=0.000100
[2025-08-11 15:00:35,402][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020016] [Batch 00540/04869] [00:04:49/00:38:42, 0.537s/it]: train_loss_raw=0.3766, running_loss=0.3680, LR=0.000100
[2025-08-11 15:00:41,620][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020028] [Batch 00552/04869] [00:04:55/00:38:34, 0.536s/it]: train_loss_raw=0.3309, running_loss=0.3640, LR=0.000100
[2025-08-11 15:00:47,843][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020040] [Batch 00564/04869] [00:05:02/00:38:26, 0.536s/it]: train_loss_raw=0.3649, running_loss=0.3644, LR=0.000100
[2025-08-11 15:00:54,004][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020052] [Batch 00576/04869] [00:05:08/00:38:18, 0.535s/it]: train_loss_raw=0.4034, running_loss=0.3624, LR=0.000100
[2025-08-11 15:01:00,236][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020064] [Batch 00588/04869] [00:05:14/00:38:10, 0.535s/it]: train_loss_raw=0.3714, running_loss=0.3622, LR=0.000100
[2025-08-11 15:01:06,388][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020076] [Batch 00600/04869] [00:05:20/00:38:02, 0.535s/it]: train_loss_raw=0.3040, running_loss=0.3659, LR=0.000100
[2025-08-11 15:01:12,588][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020088] [Batch 00612/04869] [00:05:26/00:37:54, 0.534s/it]: train_loss_raw=0.4486, running_loss=0.3625, LR=0.000100
[2025-08-11 15:01:18,773][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020100] [Batch 00624/04869] [00:05:33/00:37:46, 0.534s/it]: train_loss_raw=0.3192, running_loss=0.3610, LR=0.000100
[2025-08-11 15:01:24,899][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020112] [Batch 00636/04869] [00:05:39/00:37:38, 0.533s/it]: train_loss_raw=0.3411, running_loss=0.3649, LR=0.000100
[2025-08-11 15:01:31,261][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020124] [Batch 00648/04869] [00:05:45/00:37:31, 0.533s/it]: train_loss_raw=0.3862, running_loss=0.3628, LR=0.000100
[2025-08-11 15:01:37,439][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020136] [Batch 00660/04869] [00:05:51/00:37:23, 0.533s/it]: train_loss_raw=0.3756, running_loss=0.3630, LR=0.000100
[2025-08-11 15:01:43,647][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020148] [Batch 00672/04869] [00:05:58/00:37:15, 0.533s/it]: train_loss_raw=0.3510, running_loss=0.3598, LR=0.000100
[2025-08-11 15:01:49,830][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020160] [Batch 00684/04869] [00:06:04/00:37:08, 0.532s/it]: train_loss_raw=0.2745, running_loss=0.3588, LR=0.000100
[2025-08-11 15:01:56,025][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020172] [Batch 00696/04869] [00:06:10/00:37:00, 0.532s/it]: train_loss_raw=0.4366, running_loss=0.3572, LR=0.000100
[2025-08-11 15:02:02,186][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020184] [Batch 00708/04869] [00:06:16/00:36:53, 0.532s/it]: train_loss_raw=0.5094, running_loss=0.3622, LR=0.000100
[2025-08-11 15:02:08,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020196] [Batch 00720/04869] [00:06:22/00:36:45, 0.532s/it]: train_loss_raw=0.3359, running_loss=0.3615, LR=0.000100
[2025-08-11 15:02:14,683][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020208] [Batch 00732/04869] [00:06:29/00:36:38, 0.531s/it]: train_loss_raw=0.3661, running_loss=0.3608, LR=0.000100
[2025-08-11 15:02:21,229][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020220] [Batch 00744/04869] [00:06:35/00:36:33, 0.532s/it]: train_loss_raw=0.3643, running_loss=0.3609, LR=0.000100
[2025-08-11 15:02:27,786][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020232] [Batch 00756/04869] [00:06:42/00:36:27, 0.532s/it]: train_loss_raw=0.3544, running_loss=0.3624, LR=0.000100
[2025-08-11 15:02:34,054][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020244] [Batch 00768/04869] [00:06:48/00:36:20, 0.532s/it]: train_loss_raw=0.3551, running_loss=0.3630, LR=0.000100
[2025-08-11 15:02:40,253][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020256] [Batch 00780/04869] [00:06:54/00:36:13, 0.532s/it]: train_loss_raw=0.3879, running_loss=0.3627, LR=0.000100
[2025-08-11 15:02:46,470][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020268] [Batch 00792/04869] [00:07:00/00:36:06, 0.531s/it]: train_loss_raw=0.3940, running_loss=0.3662, LR=0.000100
[2025-08-11 15:02:52,643][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020280] [Batch 00804/04869] [00:07:07/00:35:58, 0.531s/it]: train_loss_raw=0.3662, running_loss=0.3657, LR=0.000100
[2025-08-11 15:02:59,106][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020292] [Batch 00816/04869] [00:07:13/00:35:53, 0.531s/it]: train_loss_raw=0.3607, running_loss=0.3668, LR=0.000100
[2025-08-11 15:03:05,623][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020304] [Batch 00828/04869] [00:07:19/00:35:47, 0.531s/it]: train_loss_raw=0.3971, running_loss=0.3691, LR=0.000100
[2025-08-11 15:03:11,851][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020316] [Batch 00840/04869] [00:07:26/00:35:40, 0.531s/it]: train_loss_raw=0.4165, running_loss=0.3687, LR=0.000100
[2025-08-11 15:03:18,056][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020328] [Batch 00852/04869] [00:07:32/00:35:33, 0.531s/it]: train_loss_raw=0.3596, running_loss=0.3713, LR=0.000100
[2025-08-11 15:03:24,255][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020340] [Batch 00864/04869] [00:07:38/00:35:25, 0.531s/it]: train_loss_raw=0.4438, running_loss=0.3714, LR=0.000100
[2025-08-11 15:03:30,324][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020352] [Batch 00876/04869] [00:07:44/00:35:18, 0.530s/it]: train_loss_raw=0.2120, running_loss=0.3691, LR=0.000100
[2025-08-11 15:03:36,549][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020364] [Batch 00888/04869] [00:07:50/00:35:11, 0.530s/it]: train_loss_raw=0.3991, running_loss=0.3696, LR=0.000100
[2025-08-11 15:03:42,995][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020376] [Batch 00900/04869] [00:07:57/00:35:05, 0.530s/it]: train_loss_raw=0.3103, running_loss=0.3666, LR=0.000100
[2025-08-11 15:03:49,487][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020388] [Batch 00912/04869] [00:08:03/00:34:59, 0.531s/it]: train_loss_raw=0.3809, running_loss=0.3653, LR=0.000100
[2025-08-11 15:03:55,909][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020400] [Batch 00924/04869] [00:08:10/00:34:53, 0.531s/it]: train_loss_raw=0.3909, running_loss=0.3669, LR=0.000100
[2025-08-11 15:04:02,402][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020412] [Batch 00936/04869] [00:08:16/00:34:47, 0.531s/it]: train_loss_raw=0.3100, running_loss=0.3664, LR=0.000100
[2025-08-11 15:04:08,821][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020424] [Batch 00948/04869] [00:08:23/00:34:41, 0.531s/it]: train_loss_raw=0.4520, running_loss=0.3677, LR=0.000100
[2025-08-11 15:04:15,191][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020436] [Batch 00960/04869] [00:08:29/00:34:34, 0.531s/it]: train_loss_raw=0.4738, running_loss=0.3647, LR=0.000100
[2025-08-11 15:04:21,609][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020448] [Batch 00972/04869] [00:08:35/00:34:28, 0.531s/it]: train_loss_raw=0.3148, running_loss=0.3609, LR=0.000100
[2025-08-11 15:04:28,160][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020460] [Batch 00984/04869] [00:08:42/00:34:23, 0.531s/it]: train_loss_raw=0.3223, running_loss=0.3633, LR=0.000100
[2025-08-11 15:04:34,598][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020472] [Batch 00996/04869] [00:08:48/00:34:16, 0.531s/it]: train_loss_raw=0.3624, running_loss=0.3600, LR=0.000100
[2025-08-11 15:04:41,088][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020484] [Batch 01008/04869] [00:08:55/00:34:10, 0.531s/it]: train_loss_raw=0.3630, running_loss=0.3638, LR=0.000100
[2025-08-11 15:04:47,550][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020496] [Batch 01020/04869] [00:09:01/00:34:04, 0.531s/it]: train_loss_raw=0.4336, running_loss=0.3598, LR=0.000100
[2025-08-11 15:04:53,795][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020508] [Batch 01032/04869] [00:09:08/00:33:58, 0.531s/it]: train_loss_raw=0.4052, running_loss=0.3585, LR=0.000100
[2025-08-11 15:04:59,920][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020520] [Batch 01044/04869] [00:09:14/00:33:50, 0.531s/it]: train_loss_raw=0.2519, running_loss=0.3596, LR=0.000100
[2025-08-11 15:05:06,055][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020532] [Batch 01056/04869] [00:09:20/00:33:43, 0.531s/it]: train_loss_raw=0.4317, running_loss=0.3611, LR=0.000100
[2025-08-11 15:05:12,271][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020544] [Batch 01068/04869] [00:09:26/00:33:36, 0.531s/it]: train_loss_raw=0.4016, running_loss=0.3586, LR=0.000100
[2025-08-11 15:05:18,579][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020556] [Batch 01080/04869] [00:09:32/00:33:30, 0.531s/it]: train_loss_raw=0.4043, running_loss=0.3586, LR=0.000100
[2025-08-11 15:05:24,951][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020568] [Batch 01092/04869] [00:09:39/00:33:23, 0.531s/it]: train_loss_raw=0.2680, running_loss=0.3564, LR=0.000100
[2025-08-11 15:05:31,235][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020580] [Batch 01104/04869] [00:09:45/00:33:17, 0.530s/it]: train_loss_raw=0.3932, running_loss=0.3606, LR=0.000100
[2025-08-11 15:05:37,585][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020592] [Batch 01116/04869] [00:09:51/00:33:10, 0.530s/it]: train_loss_raw=0.4477, running_loss=0.3636, LR=0.000100
[2025-08-11 15:05:44,007][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020604] [Batch 01128/04869] [00:09:58/00:33:04, 0.530s/it]: train_loss_raw=0.4259, running_loss=0.3627, LR=0.000100
[2025-08-11 15:05:50,365][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020616] [Batch 01140/04869] [00:10:04/00:32:58, 0.530s/it]: train_loss_raw=0.3495, running_loss=0.3641, LR=0.000100
[2025-08-11 15:05:56,812][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020628] [Batch 01152/04869] [00:10:11/00:32:52, 0.531s/it]: train_loss_raw=0.3749, running_loss=0.3626, LR=0.000100
[2025-08-11 15:06:03,310][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020640] [Batch 01164/04869] [00:10:17/00:32:46, 0.531s/it]: train_loss_raw=0.3271, running_loss=0.3629, LR=0.000100
[2025-08-11 15:06:09,709][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020652] [Batch 01176/04869] [00:10:24/00:32:39, 0.531s/it]: train_loss_raw=0.3384, running_loss=0.3598, LR=0.000100
[2025-08-11 15:06:16,226][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020664] [Batch 01188/04869] [00:10:30/00:32:33, 0.531s/it]: train_loss_raw=0.3562, running_loss=0.3613, LR=0.000100
[2025-08-11 15:06:22,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020676] [Batch 01200/04869] [00:10:37/00:32:27, 0.531s/it]: train_loss_raw=0.3959, running_loss=0.3621, LR=0.000100
[2025-08-11 15:06:29,263][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020688] [Batch 01212/04869] [00:10:43/00:32:22, 0.531s/it]: train_loss_raw=0.3572, running_loss=0.3629, LR=0.000100
[2025-08-11 15:06:35,791][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020700] [Batch 01224/04869] [00:10:50/00:32:16, 0.531s/it]: train_loss_raw=0.3318, running_loss=0.3628, LR=0.000100
[2025-08-11 15:06:42,322][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020712] [Batch 01236/04869] [00:10:56/00:32:10, 0.531s/it]: train_loss_raw=0.3847, running_loss=0.3626, LR=0.000100
[2025-08-11 15:06:48,832][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020724] [Batch 01248/04869] [00:11:03/00:32:04, 0.531s/it]: train_loss_raw=0.3143, running_loss=0.3612, LR=0.000100
[2025-08-11 15:06:55,279][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020736] [Batch 01260/04869] [00:11:09/00:31:58, 0.531s/it]: train_loss_raw=0.3979, running_loss=0.3674, LR=0.000100
[2025-08-11 15:07:01,786][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020748] [Batch 01272/04869] [00:11:16/00:31:52, 0.532s/it]: train_loss_raw=0.3939, running_loss=0.3690, LR=0.000100
[2025-08-11 15:07:08,214][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020760] [Batch 01284/04869] [00:11:22/00:31:45, 0.532s/it]: train_loss_raw=0.2720, running_loss=0.3689, LR=0.000100
[2025-08-11 15:07:14,592][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020772] [Batch 01296/04869] [00:11:28/00:31:39, 0.532s/it]: train_loss_raw=0.4271, running_loss=0.3658, LR=0.000100
[2025-08-11 15:07:20,977][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020784] [Batch 01308/04869] [00:11:35/00:31:33, 0.532s/it]: train_loss_raw=0.3163, running_loss=0.3659, LR=0.000100
[2025-08-11 15:07:27,340][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020796] [Batch 01320/04869] [00:11:41/00:31:26, 0.532s/it]: train_loss_raw=0.2740, running_loss=0.3669, LR=0.000100
[2025-08-11 15:07:33,970][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020808] [Batch 01332/04869] [00:11:48/00:31:20, 0.532s/it]: train_loss_raw=0.3500, running_loss=0.3675, LR=0.000100
[2025-08-11 15:07:40,436][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020820] [Batch 01344/04869] [00:11:54/00:31:14, 0.532s/it]: train_loss_raw=0.3787, running_loss=0.3624, LR=0.000100
[2025-08-11 15:07:46,974][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020832] [Batch 01356/04869] [00:12:01/00:31:08, 0.532s/it]: train_loss_raw=0.3395, running_loss=0.3608, LR=0.000100
[2025-08-11 15:07:53,400][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020844] [Batch 01368/04869] [00:12:07/00:31:02, 0.532s/it]: train_loss_raw=0.3386, running_loss=0.3631, LR=0.000100
[2025-08-11 15:07:59,826][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020856] [Batch 01380/04869] [00:12:14/00:30:56, 0.532s/it]: train_loss_raw=0.3803, running_loss=0.3634, LR=0.000100
[2025-08-11 15:08:06,257][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020868] [Batch 01392/04869] [00:12:20/00:30:49, 0.532s/it]: train_loss_raw=0.3663, running_loss=0.3638, LR=0.000100
[2025-08-11 15:08:12,774][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020880] [Batch 01404/04869] [00:12:27/00:30:43, 0.532s/it]: train_loss_raw=0.3568, running_loss=0.3647, LR=0.000100
[2025-08-11 15:08:19,262][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020892] [Batch 01416/04869] [00:12:33/00:30:37, 0.532s/it]: train_loss_raw=0.3701, running_loss=0.3625, LR=0.000100
[2025-08-11 15:08:25,878][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020904] [Batch 01428/04869] [00:12:40/00:30:31, 0.532s/it]: train_loss_raw=0.4309, running_loss=0.3631, LR=0.000100
[2025-08-11 15:08:32,389][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020916] [Batch 01440/04869] [00:12:46/00:30:25, 0.532s/it]: train_loss_raw=0.3633, running_loss=0.3663, LR=0.000100
[2025-08-11 15:08:38,796][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020928] [Batch 01452/04869] [00:12:53/00:30:19, 0.532s/it]: train_loss_raw=0.4236, running_loss=0.3652, LR=0.000100
[2025-08-11 15:08:45,021][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020940] [Batch 01464/04869] [00:12:59/00:30:12, 0.532s/it]: train_loss_raw=0.3263, running_loss=0.3637, LR=0.000100
[2025-08-11 15:08:51,424][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020952] [Batch 01476/04869] [00:13:05/00:30:06, 0.532s/it]: train_loss_raw=0.3463, running_loss=0.3655, LR=0.000100
[2025-08-11 15:08:57,808][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020964] [Batch 01488/04869] [00:13:12/00:29:59, 0.532s/it]: train_loss_raw=0.3942, running_loss=0.3666, LR=0.000100
[2025-08-11 15:09:04,116][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020976] [Batch 01500/04869] [00:13:18/00:29:53, 0.532s/it]: train_loss_raw=0.3875, running_loss=0.3671, LR=0.000100
[2025-08-11 15:09:10,327][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020988] [Batch 01512/04869] [00:13:24/00:29:46, 0.532s/it]: train_loss_raw=0.2660, running_loss=0.3659, LR=0.000100
[2025-08-11 15:09:16,649][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021000] [Batch 01524/04869] [00:13:31/00:29:40, 0.532s/it]: train_loss_raw=0.3133, running_loss=0.3641, LR=0.000100
[2025-08-11 15:09:22,935][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021012] [Batch 01536/04869] [00:13:37/00:29:33, 0.532s/it]: train_loss_raw=0.3433, running_loss=0.3627, LR=0.000100
[2025-08-11 15:09:29,244][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021024] [Batch 01548/04869] [00:13:43/00:29:26, 0.532s/it]: train_loss_raw=0.3151, running_loss=0.3613, LR=0.000100
[2025-08-11 15:09:35,556][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021036] [Batch 01560/04869] [00:13:49/00:29:20, 0.532s/it]: train_loss_raw=0.3254, running_loss=0.3596, LR=0.000100
[2025-08-11 15:09:41,901][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021048] [Batch 01572/04869] [00:13:56/00:29:13, 0.532s/it]: train_loss_raw=0.2397, running_loss=0.3564, LR=0.000100
[2025-08-11 15:09:48,386][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021060] [Batch 01584/04869] [00:14:02/00:29:07, 0.532s/it]: train_loss_raw=0.3333, running_loss=0.3573, LR=0.000100
[2025-08-11 15:09:54,701][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021072] [Batch 01596/04869] [00:14:09/00:29:01, 0.532s/it]: train_loss_raw=0.4390, running_loss=0.3605, LR=0.000100
[2025-08-11 15:10:01,036][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021084] [Batch 01608/04869] [00:14:15/00:28:54, 0.532s/it]: train_loss_raw=0.3490, running_loss=0.3582, LR=0.000100
[2025-08-11 15:10:07,460][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021096] [Batch 01620/04869] [00:14:21/00:28:48, 0.532s/it]: train_loss_raw=0.4750, running_loss=0.3596, LR=0.000100
[2025-08-11 15:10:13,955][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021108] [Batch 01632/04869] [00:14:28/00:28:42, 0.532s/it]: train_loss_raw=0.3400, running_loss=0.3604, LR=0.000100
[2025-08-11 15:10:20,457][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021120] [Batch 01644/04869] [00:14:34/00:28:36, 0.532s/it]: train_loss_raw=0.3498, running_loss=0.3606, LR=0.000100
[2025-08-11 15:10:26,816][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021132] [Batch 01656/04869] [00:14:41/00:28:29, 0.532s/it]: train_loss_raw=0.4346, running_loss=0.3586, LR=0.000100
[2025-08-11 15:10:33,130][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021144] [Batch 01668/04869] [00:14:47/00:28:23, 0.532s/it]: train_loss_raw=0.3296, running_loss=0.3585, LR=0.000100
[2025-08-11 15:10:39,473][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021156] [Batch 01680/04869] [00:14:53/00:28:16, 0.532s/it]: train_loss_raw=0.3540, running_loss=0.3626, LR=0.000100
[2025-08-11 15:10:45,852][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021168] [Batch 01692/04869] [00:15:00/00:28:10, 0.532s/it]: train_loss_raw=0.4077, running_loss=0.3600, LR=0.000100
[2025-08-11 15:10:52,214][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021180] [Batch 01704/04869] [00:15:06/00:28:03, 0.532s/it]: train_loss_raw=0.3876, running_loss=0.3645, LR=0.000100
[2025-08-11 15:10:58,525][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021192] [Batch 01716/04869] [00:15:12/00:27:57, 0.532s/it]: train_loss_raw=0.4387, running_loss=0.3658, LR=0.000100
[2025-08-11 15:11:04,919][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021204] [Batch 01728/04869] [00:15:19/00:27:50, 0.532s/it]: train_loss_raw=0.3358, running_loss=0.3617, LR=0.000100
[2025-08-11 15:11:11,310][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021216] [Batch 01740/04869] [00:15:25/00:27:44, 0.532s/it]: train_loss_raw=0.3594, running_loss=0.3607, LR=0.000100
[2025-08-11 15:11:17,711][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021228] [Batch 01752/04869] [00:15:32/00:27:38, 0.532s/it]: train_loss_raw=0.4025, running_loss=0.3606, LR=0.000100
[2025-08-11 15:11:24,044][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021240] [Batch 01764/04869] [00:15:38/00:27:31, 0.532s/it]: train_loss_raw=0.3701, running_loss=0.3612, LR=0.000100
[2025-08-11 15:11:30,621][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021252] [Batch 01776/04869] [00:15:44/00:27:25, 0.532s/it]: train_loss_raw=0.2764, running_loss=0.3605, LR=0.000100
[2025-08-11 15:11:36,969][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021264] [Batch 01788/04869] [00:15:51/00:27:19, 0.532s/it]: train_loss_raw=0.3450, running_loss=0.3582, LR=0.000100
[2025-08-11 15:11:43,288][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021276] [Batch 01800/04869] [00:15:57/00:27:12, 0.532s/it]: train_loss_raw=0.3961, running_loss=0.3586, LR=0.000100
[2025-08-11 15:11:49,591][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021288] [Batch 01812/04869] [00:16:03/00:27:06, 0.532s/it]: train_loss_raw=0.2909, running_loss=0.3582, LR=0.000100
[2025-08-11 15:11:55,972][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021300] [Batch 01824/04869] [00:16:10/00:26:59, 0.532s/it]: train_loss_raw=0.3275, running_loss=0.3614, LR=0.000100
[2025-08-11 15:12:02,313][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021312] [Batch 01836/04869] [00:16:16/00:26:53, 0.532s/it]: train_loss_raw=0.3207, running_loss=0.3590, LR=0.000100
[2025-08-11 15:12:08,659][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021324] [Batch 01848/04869] [00:16:23/00:26:46, 0.532s/it]: train_loss_raw=0.3863, running_loss=0.3607, LR=0.000100
[2025-08-11 15:12:15,000][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021336] [Batch 01860/04869] [00:16:29/00:26:40, 0.532s/it]: train_loss_raw=0.4247, running_loss=0.3619, LR=0.000100
[2025-08-11 15:12:21,318][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021348] [Batch 01872/04869] [00:16:35/00:26:34, 0.532s/it]: train_loss_raw=0.3327, running_loss=0.3613, LR=0.000100
[2025-08-11 15:12:27,642][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021360] [Batch 01884/04869] [00:16:42/00:26:27, 0.532s/it]: train_loss_raw=0.4099, running_loss=0.3636, LR=0.000100
[2025-08-11 15:12:33,971][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021372] [Batch 01896/04869] [00:16:48/00:26:21, 0.532s/it]: train_loss_raw=0.4500, running_loss=0.3666, LR=0.000100
[2025-08-11 15:12:40,365][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021384] [Batch 01908/04869] [00:16:54/00:26:14, 0.532s/it]: train_loss_raw=0.3558, running_loss=0.3680, LR=0.000100
[2025-08-11 15:12:46,581][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021396] [Batch 01920/04869] [00:17:00/00:26:08, 0.532s/it]: train_loss_raw=0.3909, running_loss=0.3674, LR=0.000100
[2025-08-11 15:12:52,848][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021408] [Batch 01932/04869] [00:17:07/00:26:01, 0.532s/it]: train_loss_raw=0.4046, running_loss=0.3676, LR=0.000100
[2025-08-11 15:12:59,127][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021420] [Batch 01944/04869] [00:17:13/00:25:55, 0.532s/it]: train_loss_raw=0.3585, running_loss=0.3680, LR=0.000100
[2025-08-11 15:13:05,409][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021432] [Batch 01956/04869] [00:17:19/00:25:48, 0.532s/it]: train_loss_raw=0.3331, running_loss=0.3684, LR=0.000100
[2025-08-11 15:13:11,761][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021444] [Batch 01968/04869] [00:17:26/00:25:42, 0.532s/it]: train_loss_raw=0.3203, running_loss=0.3649, LR=0.000100
[2025-08-11 15:13:18,099][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021456] [Batch 01980/04869] [00:17:32/00:25:35, 0.532s/it]: train_loss_raw=0.3739, running_loss=0.3631, LR=0.000100
[2025-08-11 15:13:24,449][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021468] [Batch 01992/04869] [00:17:38/00:25:29, 0.532s/it]: train_loss_raw=0.3859, running_loss=0.3616, LR=0.000100
[2025-08-11 15:13:30,783][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021480] [Batch 02004/04869] [00:17:45/00:25:22, 0.532s/it]: train_loss_raw=0.3647, running_loss=0.3631, LR=0.000100
[2025-08-11 15:13:37,115][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021492] [Batch 02016/04869] [00:17:51/00:25:16, 0.531s/it]: train_loss_raw=0.3357, running_loss=0.3626, LR=0.000100
[2025-08-11 15:14:13,475][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021504] [Batch 02028/04869] [00:18:27/00:25:51, 0.546s/it]: train_loss_raw=0.3702, running_loss=0.3640, LR=0.000100
[2025-08-11 15:14:19,768][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021516] [Batch 02040/04869] [00:18:34/00:25:45, 0.546s/it]: train_loss_raw=0.3223, running_loss=0.3601, LR=0.000100
[2025-08-11 15:14:26,086][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021528] [Batch 02052/04869] [00:18:40/00:25:38, 0.546s/it]: train_loss_raw=0.3487, running_loss=0.3632, LR=0.000100
[2025-08-11 15:14:32,372][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021540] [Batch 02064/04869] [00:18:46/00:25:31, 0.546s/it]: train_loss_raw=0.4160, running_loss=0.3610, LR=0.000100
[2025-08-11 15:14:38,711][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021552] [Batch 02076/04869] [00:18:53/00:25:24, 0.546s/it]: train_loss_raw=0.4779, running_loss=0.3602, LR=0.000100
[2025-08-11 15:14:45,170][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021564] [Batch 02088/04869] [00:18:59/00:25:17, 0.546s/it]: train_loss_raw=0.3283, running_loss=0.3568, LR=0.000100
[2025-08-11 15:14:51,645][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021576] [Batch 02100/04869] [00:19:06/00:25:11, 0.546s/it]: train_loss_raw=0.3551, running_loss=0.3576, LR=0.000100
[2025-08-11 15:14:58,131][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021588] [Batch 02112/04869] [00:19:12/00:25:04, 0.546s/it]: train_loss_raw=0.3196, running_loss=0.3567, LR=0.000100
[2025-08-11 15:15:04,529][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021600] [Batch 02124/04869] [00:19:18/00:24:57, 0.546s/it]: train_loss_raw=0.3563, running_loss=0.3531, LR=0.000100
[2025-08-11 15:15:10,840][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021612] [Batch 02136/04869] [00:19:25/00:24:50, 0.546s/it]: train_loss_raw=0.3369, running_loss=0.3556, LR=0.000100
[2025-08-11 15:15:17,309][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021624] [Batch 02148/04869] [00:19:31/00:24:44, 0.545s/it]: train_loss_raw=0.4045, running_loss=0.3542, LR=0.000100
[2025-08-11 15:15:23,701][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021636] [Batch 02160/04869] [00:19:38/00:24:37, 0.545s/it]: train_loss_raw=0.3533, running_loss=0.3530, LR=0.000100
[2025-08-11 15:15:30,125][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021648] [Batch 02172/04869] [00:19:44/00:24:30, 0.545s/it]: train_loss_raw=0.3523, running_loss=0.3569, LR=0.000100
[2025-08-11 15:15:36,463][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021660] [Batch 02184/04869] [00:19:50/00:24:23, 0.545s/it]: train_loss_raw=0.3435, running_loss=0.3542, LR=0.000100
[2025-08-11 15:15:42,871][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021672] [Batch 02196/04869] [00:19:57/00:24:17, 0.545s/it]: train_loss_raw=0.3567, running_loss=0.3537, LR=0.000100
[2025-08-11 15:15:49,274][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021684] [Batch 02208/04869] [00:20:03/00:24:10, 0.545s/it]: train_loss_raw=0.3598, running_loss=0.3515, LR=0.000100
[2025-08-11 15:15:55,835][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021696] [Batch 02220/04869] [00:20:10/00:24:04, 0.545s/it]: train_loss_raw=0.3386, running_loss=0.3509, LR=0.000100
[2025-08-11 15:16:02,292][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021708] [Batch 02232/04869] [00:20:16/00:23:57, 0.545s/it]: train_loss_raw=0.3050, running_loss=0.3507, LR=0.000100
[2025-08-11 15:16:08,445][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021720] [Batch 02244/04869] [00:20:22/00:23:50, 0.545s/it]: train_loss_raw=0.3650, running_loss=0.3514, LR=0.000100
[2025-08-11 15:16:14,728][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021732] [Batch 02256/04869] [00:20:29/00:23:43, 0.545s/it]: train_loss_raw=0.4027, running_loss=0.3506, LR=0.000100
[2025-08-11 15:16:21,092][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021744] [Batch 02268/04869] [00:20:35/00:23:36, 0.545s/it]: train_loss_raw=0.4562, running_loss=0.3523, LR=0.000100
[2025-08-11 15:16:27,544][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021756] [Batch 02280/04869] [00:20:41/00:23:30, 0.545s/it]: train_loss_raw=0.3734, running_loss=0.3530, LR=0.000100
[2025-08-11 15:16:33,901][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021768] [Batch 02292/04869] [00:20:48/00:23:23, 0.545s/it]: train_loss_raw=0.3896, running_loss=0.3508, LR=0.000100
[2025-08-11 15:16:40,314][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021780] [Batch 02304/04869] [00:20:54/00:23:16, 0.545s/it]: train_loss_raw=0.3459, running_loss=0.3535, LR=0.000100
[2025-08-11 15:16:46,730][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021792] [Batch 02316/04869] [00:21:01/00:23:10, 0.545s/it]: train_loss_raw=0.3830, running_loss=0.3544, LR=0.000100
[2025-08-11 15:16:52,909][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021804] [Batch 02328/04869] [00:21:07/00:23:03, 0.544s/it]: train_loss_raw=0.2632, running_loss=0.3541, LR=0.000100
[2025-08-11 15:16:59,150][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021816] [Batch 02340/04869] [00:21:13/00:22:56, 0.544s/it]: train_loss_raw=0.2973, running_loss=0.3558, LR=0.000100
[2025-08-11 15:17:05,363][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021828] [Batch 02352/04869] [00:21:19/00:22:49, 0.544s/it]: train_loss_raw=0.4664, running_loss=0.3586, LR=0.000100
[2025-08-11 15:17:11,713][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021840] [Batch 02364/04869] [00:21:26/00:22:42, 0.544s/it]: train_loss_raw=0.4031, running_loss=0.3581, LR=0.000100
[2025-08-11 15:17:18,080][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021852] [Batch 02376/04869] [00:21:32/00:22:36, 0.544s/it]: train_loss_raw=0.4049, running_loss=0.3580, LR=0.000100
[2025-08-11 15:17:24,505][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021864] [Batch 02388/04869] [00:21:38/00:22:29, 0.544s/it]: train_loss_raw=0.4100, running_loss=0.3579, LR=0.000100
[2025-08-11 15:17:30,846][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021876] [Batch 02400/04869] [00:21:45/00:22:22, 0.544s/it]: train_loss_raw=0.3615, running_loss=0.3595, LR=0.000100
[2025-08-11 15:17:37,252][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021888] [Batch 02412/04869] [00:21:51/00:22:16, 0.544s/it]: train_loss_raw=0.3322, running_loss=0.3576, LR=0.000100
[2025-08-11 15:17:43,565][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021900] [Batch 02424/04869] [00:21:57/00:22:09, 0.544s/it]: train_loss_raw=0.4074, running_loss=0.3565, LR=0.000100
[2025-08-11 15:17:49,929][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021912] [Batch 02436/04869] [00:22:04/00:22:02, 0.544s/it]: train_loss_raw=0.3398, running_loss=0.3577, LR=0.000100
[2025-08-11 15:17:56,296][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021924] [Batch 02448/04869] [00:22:10/00:21:55, 0.544s/it]: train_loss_raw=0.3712, running_loss=0.3570, LR=0.000100
[2025-08-11 15:18:02,727][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021936] [Batch 02460/04869] [00:22:17/00:21:49, 0.544s/it]: train_loss_raw=0.4082, running_loss=0.3575, LR=0.000100
[2025-08-11 15:18:09,000][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021948] [Batch 02472/04869] [00:22:23/00:21:42, 0.543s/it]: train_loss_raw=0.3059, running_loss=0.3570, LR=0.000100
[2025-08-11 15:18:15,282][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021960] [Batch 02484/04869] [00:22:29/00:21:35, 0.543s/it]: train_loss_raw=0.2962, running_loss=0.3542, LR=0.000100
[2025-08-11 15:18:21,565][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021972] [Batch 02496/04869] [00:22:35/00:21:29, 0.543s/it]: train_loss_raw=0.3769, running_loss=0.3547, LR=0.000100
[2025-08-11 15:18:27,953][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021984] [Batch 02508/04869] [00:22:42/00:21:22, 0.543s/it]: train_loss_raw=0.3177, running_loss=0.3540, LR=0.000100
[2025-08-11 15:18:34,287][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021996] [Batch 02520/04869] [00:22:48/00:21:15, 0.543s/it]: train_loss_raw=0.4099, running_loss=0.3566, LR=0.000100
[2025-08-11 15:18:45,115][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022008] [Batch 02532/04869] [00:22:59/00:21:13, 0.545s/it]: train_loss_raw=0.3745, running_loss=0.3550, LR=0.000100
[2025-08-11 15:18:51,465][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022020] [Batch 02544/04869] [00:23:05/00:21:06, 0.545s/it]: train_loss_raw=0.3065, running_loss=0.3527, LR=0.000100
[2025-08-11 15:18:57,943][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022032] [Batch 02556/04869] [00:23:12/00:20:59, 0.545s/it]: train_loss_raw=0.3086, running_loss=0.3539, LR=0.000100
[2025-08-11 15:19:04,437][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022044] [Batch 02568/04869] [00:23:18/00:20:53, 0.545s/it]: train_loss_raw=0.3778, running_loss=0.3540, LR=0.000100
[2025-08-11 15:19:10,740][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022056] [Batch 02580/04869] [00:23:25/00:20:46, 0.545s/it]: train_loss_raw=0.2917, running_loss=0.3519, LR=0.000100
[2025-08-11 15:19:17,125][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022068] [Batch 02592/04869] [00:23:31/00:20:39, 0.545s/it]: train_loss_raw=0.3735, running_loss=0.3522, LR=0.000100
[2025-08-11 15:19:23,473][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022080] [Batch 02604/04869] [00:23:37/00:20:33, 0.544s/it]: train_loss_raw=0.4269, running_loss=0.3497, LR=0.000100
[2025-08-11 15:19:29,813][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022092] [Batch 02616/04869] [00:23:44/00:20:26, 0.544s/it]: train_loss_raw=0.3311, running_loss=0.3509, LR=0.000100
[2025-08-11 15:19:36,129][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022104] [Batch 02628/04869] [00:23:50/00:20:19, 0.544s/it]: train_loss_raw=0.4004, running_loss=0.3508, LR=0.000100
[2025-08-11 15:19:42,564][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022116] [Batch 02640/04869] [00:23:56/00:20:13, 0.544s/it]: train_loss_raw=0.3967, running_loss=0.3518, LR=0.000100
[2025-08-11 15:19:48,909][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022128] [Batch 02652/04869] [00:24:03/00:20:06, 0.544s/it]: train_loss_raw=0.3240, running_loss=0.3543, LR=0.000100
[2025-08-11 15:19:55,240][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022140] [Batch 02664/04869] [00:24:09/00:19:59, 0.544s/it]: train_loss_raw=0.3031, running_loss=0.3552, LR=0.000100
[2025-08-11 15:20:01,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022152] [Batch 02676/04869] [00:24:16/00:19:53, 0.544s/it]: train_loss_raw=0.2748, running_loss=0.3555, LR=0.000100
[2025-08-11 15:20:08,246][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022164] [Batch 02688/04869] [00:24:22/00:19:46, 0.544s/it]: train_loss_raw=0.4106, running_loss=0.3583, LR=0.000100
[2025-08-11 15:20:14,741][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022176] [Batch 02700/04869] [00:24:29/00:19:40, 0.544s/it]: train_loss_raw=0.3655, running_loss=0.3585, LR=0.000100
[2025-08-11 15:20:20,973][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022188] [Batch 02712/04869] [00:24:35/00:19:33, 0.544s/it]: train_loss_raw=0.3982, running_loss=0.3560, LR=0.000100
[2025-08-11 15:20:27,076][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022200] [Batch 02724/04869] [00:24:41/00:19:26, 0.544s/it]: train_loss_raw=0.3130, running_loss=0.3576, LR=0.000100
[2025-08-11 15:20:33,282][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022212] [Batch 02736/04869] [00:24:47/00:19:19, 0.544s/it]: train_loss_raw=0.3737, running_loss=0.3571, LR=0.000100
[2025-08-11 15:20:39,464][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022224] [Batch 02748/04869] [00:24:53/00:19:12, 0.544s/it]: train_loss_raw=0.4579, running_loss=0.3560, LR=0.000100
[2025-08-11 15:20:45,775][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022236] [Batch 02760/04869] [00:25:00/00:19:06, 0.544s/it]: train_loss_raw=0.4351, running_loss=0.3560, LR=0.000100
[2025-08-11 15:20:52,166][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022248] [Batch 02772/04869] [00:25:06/00:18:59, 0.543s/it]: train_loss_raw=0.3278, running_loss=0.3567, LR=0.000100
[2025-08-11 15:20:58,563][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022260] [Batch 02784/04869] [00:25:12/00:18:53, 0.543s/it]: train_loss_raw=0.3288, running_loss=0.3573, LR=0.000100
[2025-08-11 15:21:04,898][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022272] [Batch 02796/04869] [00:25:19/00:18:46, 0.543s/it]: train_loss_raw=0.3408, running_loss=0.3559, LR=0.000100
[2025-08-11 15:21:11,265][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022284] [Batch 02808/04869] [00:25:25/00:18:39, 0.543s/it]: train_loss_raw=0.3102, running_loss=0.3548, LR=0.000100
[2025-08-11 15:21:17,726][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022296] [Batch 02820/04869] [00:25:32/00:18:33, 0.543s/it]: train_loss_raw=0.4427, running_loss=0.3557, LR=0.000100
[2025-08-11 15:21:24,063][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022308] [Batch 02832/04869] [00:25:38/00:18:26, 0.543s/it]: train_loss_raw=0.3372, running_loss=0.3565, LR=0.000100
[2025-08-11 15:21:30,357][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022320] [Batch 02844/04869] [00:25:44/00:18:19, 0.543s/it]: train_loss_raw=0.2714, running_loss=0.3537, LR=0.000100
[2025-08-11 15:21:36,719][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022332] [Batch 02856/04869] [00:25:51/00:18:13, 0.543s/it]: train_loss_raw=0.3789, running_loss=0.3537, LR=0.000100
[2025-08-11 15:21:43,234][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022344] [Batch 02868/04869] [00:25:57/00:18:06, 0.543s/it]: train_loss_raw=0.3668, running_loss=0.3516, LR=0.000100
[2025-08-11 15:21:49,480][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022356] [Batch 02880/04869] [00:26:03/00:18:00, 0.543s/it]: train_loss_raw=0.2977, running_loss=0.3503, LR=0.000100
[2025-08-11 15:21:55,795][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022368] [Batch 02892/04869] [00:26:10/00:17:53, 0.543s/it]: train_loss_raw=0.4501, running_loss=0.3513, LR=0.000100
[2025-08-11 15:22:02,080][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022380] [Batch 02904/04869] [00:26:16/00:17:46, 0.543s/it]: train_loss_raw=0.3030, running_loss=0.3483, LR=0.000100
[2025-08-11 15:22:08,416][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022392] [Batch 02916/04869] [00:26:22/00:17:40, 0.543s/it]: train_loss_raw=0.3044, running_loss=0.3494, LR=0.000100
[2025-08-11 15:22:14,775][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022404] [Batch 02928/04869] [00:26:29/00:17:33, 0.543s/it]: train_loss_raw=0.3904, running_loss=0.3500, LR=0.000100
[2025-08-11 15:22:21,086][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022416] [Batch 02940/04869] [00:26:35/00:17:26, 0.543s/it]: train_loss_raw=0.3303, running_loss=0.3522, LR=0.000100
[2025-08-11 15:22:27,383][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022428] [Batch 02952/04869] [00:26:41/00:17:20, 0.543s/it]: train_loss_raw=0.2990, running_loss=0.3511, LR=0.000100
[2025-08-11 15:22:33,725][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022440] [Batch 02964/04869] [00:26:48/00:17:13, 0.543s/it]: train_loss_raw=0.3376, running_loss=0.3480, LR=0.000100
[2025-08-11 15:22:40,049][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022452] [Batch 02976/04869] [00:26:54/00:17:06, 0.542s/it]: train_loss_raw=0.3868, running_loss=0.3483, LR=0.000100
[2025-08-11 15:22:46,441][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022464] [Batch 02988/04869] [00:27:00/00:17:00, 0.542s/it]: train_loss_raw=0.2953, running_loss=0.3505, LR=0.000100
[2025-08-11 15:22:52,882][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022476] [Batch 03000/04869] [00:27:07/00:16:53, 0.542s/it]: train_loss_raw=0.3946, running_loss=0.3526, LR=0.000100
[2025-08-11 15:22:59,309][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022488] [Batch 03012/04869] [00:27:13/00:16:47, 0.542s/it]: train_loss_raw=0.2841, running_loss=0.3514, LR=0.000100
[2025-08-11 15:23:05,772][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022500] [Batch 03024/04869] [00:27:20/00:16:40, 0.542s/it]: train_loss_raw=0.3870, running_loss=0.3538, LR=0.000100
[2025-08-11 15:23:12,305][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022512] [Batch 03036/04869] [00:27:26/00:16:34, 0.542s/it]: train_loss_raw=0.4569, running_loss=0.3534, LR=0.000100
[2025-08-11 15:23:18,671][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022524] [Batch 03048/04869] [00:27:33/00:16:27, 0.542s/it]: train_loss_raw=0.3475, running_loss=0.3532, LR=0.000100
[2025-08-11 15:23:25,007][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022536] [Batch 03060/04869] [00:27:39/00:16:20, 0.542s/it]: train_loss_raw=0.2608, running_loss=0.3538, LR=0.000100
[2025-08-11 15:23:31,406][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022548] [Batch 03072/04869] [00:27:45/00:16:14, 0.542s/it]: train_loss_raw=0.4172, running_loss=0.3575, LR=0.000100
[2025-08-11 15:23:37,809][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022560] [Batch 03084/04869] [00:27:52/00:16:07, 0.542s/it]: train_loss_raw=0.4404, running_loss=0.3583, LR=0.000100
[2025-08-11 15:23:44,180][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022572] [Batch 03096/04869] [00:27:58/00:16:01, 0.542s/it]: train_loss_raw=0.2943, running_loss=0.3584, LR=0.000100
[2025-08-11 15:23:50,613][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022584] [Batch 03108/04869] [00:28:04/00:15:54, 0.542s/it]: train_loss_raw=0.3522, running_loss=0.3597, LR=0.000100
[2025-08-11 15:23:57,048][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022596] [Batch 03120/04869] [00:28:11/00:15:48, 0.542s/it]: train_loss_raw=0.3860, running_loss=0.3587, LR=0.000100
[2025-08-11 15:24:03,256][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022608] [Batch 03132/04869] [00:28:17/00:15:41, 0.542s/it]: train_loss_raw=0.3799, running_loss=0.3599, LR=0.000100
[2025-08-11 15:24:09,475][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022620] [Batch 03144/04869] [00:28:23/00:15:34, 0.542s/it]: train_loss_raw=0.2901, running_loss=0.3604, LR=0.000100
[2025-08-11 15:24:15,731][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022632] [Batch 03156/04869] [00:28:30/00:15:28, 0.542s/it]: train_loss_raw=0.4066, running_loss=0.3598, LR=0.000100
[2025-08-11 15:24:21,964][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022644] [Batch 03168/04869] [00:28:36/00:15:21, 0.542s/it]: train_loss_raw=0.3927, running_loss=0.3582, LR=0.000100
[2025-08-11 15:24:28,233][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022656] [Batch 03180/04869] [00:28:42/00:15:14, 0.542s/it]: train_loss_raw=0.3407, running_loss=0.3591, LR=0.000100
[2025-08-11 15:24:34,397][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022668] [Batch 03192/04869] [00:28:48/00:15:08, 0.542s/it]: train_loss_raw=0.3635, running_loss=0.3573, LR=0.000100
[2025-08-11 15:24:40,542][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022680] [Batch 03204/04869] [00:28:54/00:15:01, 0.541s/it]: train_loss_raw=0.2372, running_loss=0.3575, LR=0.000100
[2025-08-11 15:24:46,723][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022692] [Batch 03216/04869] [00:29:01/00:14:54, 0.541s/it]: train_loss_raw=0.3462, running_loss=0.3556, LR=0.000100
[2025-08-11 15:24:52,976][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022704] [Batch 03228/04869] [00:29:07/00:14:48, 0.541s/it]: train_loss_raw=0.4086, running_loss=0.3554, LR=0.000100
[2025-08-11 15:24:59,174][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022716] [Batch 03240/04869] [00:29:13/00:14:41, 0.541s/it]: train_loss_raw=0.4390, running_loss=0.3569, LR=0.000100
[2025-08-11 15:25:05,386][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022728] [Batch 03252/04869] [00:29:19/00:14:35, 0.541s/it]: train_loss_raw=0.3171, running_loss=0.3543, LR=0.000100
[2025-08-11 15:25:11,642][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022740] [Batch 03264/04869] [00:29:26/00:14:28, 0.541s/it]: train_loss_raw=0.4122, running_loss=0.3556, LR=0.000100
[2025-08-11 15:25:17,838][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022752] [Batch 03276/04869] [00:29:32/00:14:21, 0.541s/it]: train_loss_raw=0.3427, running_loss=0.3549, LR=0.000100
[2025-08-11 15:25:24,121][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022764] [Batch 03288/04869] [00:29:38/00:14:15, 0.541s/it]: train_loss_raw=0.2593, running_loss=0.3546, LR=0.000100
[2025-08-11 15:25:30,376][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022776] [Batch 03300/04869] [00:29:44/00:14:08, 0.541s/it]: train_loss_raw=0.3001, running_loss=0.3528, LR=0.000100
[2025-08-11 15:25:36,581][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022788] [Batch 03312/04869] [00:29:50/00:14:01, 0.541s/it]: train_loss_raw=0.2288, running_loss=0.3520, LR=0.000100
[2025-08-11 15:25:42,730][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022800] [Batch 03324/04869] [00:29:57/00:13:55, 0.541s/it]: train_loss_raw=0.3273, running_loss=0.3543, LR=0.000100
[2025-08-11 15:25:49,041][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022812] [Batch 03336/04869] [00:30:03/00:13:48, 0.541s/it]: train_loss_raw=0.3769, running_loss=0.3540, LR=0.000100
[2025-08-11 15:25:55,455][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022824] [Batch 03348/04869] [00:30:09/00:13:42, 0.541s/it]: train_loss_raw=0.2610, running_loss=0.3536, LR=0.000100
[2025-08-11 15:26:01,966][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022836] [Batch 03360/04869] [00:30:16/00:13:35, 0.541s/it]: train_loss_raw=0.3188, running_loss=0.3542, LR=0.000100
[2025-08-11 15:26:08,453][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022848] [Batch 03372/04869] [00:30:22/00:13:29, 0.541s/it]: train_loss_raw=0.3746, running_loss=0.3563, LR=0.000100
[2025-08-11 15:26:14,973][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022860] [Batch 03384/04869] [00:30:29/00:13:22, 0.541s/it]: train_loss_raw=0.2308, running_loss=0.3553, LR=0.000100
[2025-08-11 15:26:21,394][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022872] [Batch 03396/04869] [00:30:35/00:13:16, 0.541s/it]: train_loss_raw=0.3869, running_loss=0.3525, LR=0.000100
[2025-08-11 15:26:27,546][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022884] [Batch 03408/04869] [00:30:41/00:13:09, 0.540s/it]: train_loss_raw=0.4320, running_loss=0.3537, LR=0.000100
[2025-08-11 15:26:33,708][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022896] [Batch 03420/04869] [00:30:48/00:13:02, 0.540s/it]: train_loss_raw=0.3529, running_loss=0.3522, LR=0.000100
[2025-08-11 15:26:39,893][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022908] [Batch 03432/04869] [00:30:54/00:12:56, 0.540s/it]: train_loss_raw=0.3052, running_loss=0.3494, LR=0.000100
[2025-08-11 15:26:46,279][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022920] [Batch 03444/04869] [00:31:00/00:12:49, 0.540s/it]: train_loss_raw=0.3690, running_loss=0.3498, LR=0.000100
[2025-08-11 15:26:52,523][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022932] [Batch 03456/04869] [00:31:06/00:12:43, 0.540s/it]: train_loss_raw=0.3464, running_loss=0.3502, LR=0.000100
[2025-08-11 15:26:58,758][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022944] [Batch 03468/04869] [00:31:13/00:12:36, 0.540s/it]: train_loss_raw=0.3985, running_loss=0.3514, LR=0.000100
[2025-08-11 15:27:04,903][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022956] [Batch 03480/04869] [00:31:19/00:12:30, 0.540s/it]: train_loss_raw=0.4057, running_loss=0.3500, LR=0.000100
[2025-08-11 15:27:11,099][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022968] [Batch 03492/04869] [00:31:25/00:12:23, 0.540s/it]: train_loss_raw=0.2563, running_loss=0.3518, LR=0.000100
[2025-08-11 15:27:17,472][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022980] [Batch 03504/04869] [00:31:31/00:12:16, 0.540s/it]: train_loss_raw=0.4341, running_loss=0.3538, LR=0.000100
[2025-08-11 15:27:23,980][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022992] [Batch 03516/04869] [00:31:38/00:12:10, 0.540s/it]: train_loss_raw=0.3149, running_loss=0.3503, LR=0.000100
[2025-08-11 15:27:30,410][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023004] [Batch 03528/04869] [00:31:44/00:12:04, 0.540s/it]: train_loss_raw=0.2924, running_loss=0.3511, LR=0.000100
[2025-08-11 15:27:36,649][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023016] [Batch 03540/04869] [00:31:51/00:11:57, 0.540s/it]: train_loss_raw=0.3016, running_loss=0.3497, LR=0.000100
[2025-08-11 15:27:43,173][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023028] [Batch 03552/04869] [00:31:57/00:11:50, 0.540s/it]: train_loss_raw=0.4309, running_loss=0.3549, LR=0.000100
[2025-08-11 15:27:49,461][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023040] [Batch 03564/04869] [00:32:03/00:11:44, 0.540s/it]: train_loss_raw=0.3191, running_loss=0.3523, LR=0.000100
[2025-08-11 15:27:55,857][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023052] [Batch 03576/04869] [00:32:10/00:11:37, 0.540s/it]: train_loss_raw=0.4378, running_loss=0.3546, LR=0.000100
[2025-08-11 15:28:02,231][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023064] [Batch 03588/04869] [00:32:16/00:11:31, 0.540s/it]: train_loss_raw=0.4619, running_loss=0.3582, LR=0.000100
[2025-08-11 15:28:08,604][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023076] [Batch 03600/04869] [00:32:22/00:11:24, 0.540s/it]: train_loss_raw=0.3910, running_loss=0.3587, LR=0.000100
[2025-08-11 15:28:15,016][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023088] [Batch 03612/04869] [00:32:29/00:11:18, 0.540s/it]: train_loss_raw=0.4100, running_loss=0.3590, LR=0.000100
[2025-08-11 15:28:21,423][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023100] [Batch 03624/04869] [00:32:35/00:11:11, 0.540s/it]: train_loss_raw=0.3737, running_loss=0.3586, LR=0.000100
[2025-08-11 15:28:27,858][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023112] [Batch 03636/04869] [00:32:42/00:11:05, 0.540s/it]: train_loss_raw=0.3358, running_loss=0.3567, LR=0.000100
[2025-08-11 15:28:34,301][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023124] [Batch 03648/04869] [00:32:48/00:10:58, 0.540s/it]: train_loss_raw=0.4211, running_loss=0.3582, LR=0.000100
[2025-08-11 15:28:40,651][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023136] [Batch 03660/04869] [00:32:55/00:10:52, 0.540s/it]: train_loss_raw=0.4145, running_loss=0.3563, LR=0.000100
[2025-08-11 15:28:46,991][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023148] [Batch 03672/04869] [00:33:01/00:10:45, 0.540s/it]: train_loss_raw=0.3550, running_loss=0.3568, LR=0.000100
[2025-08-11 15:28:53,483][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023160] [Batch 03684/04869] [00:33:07/00:10:39, 0.540s/it]: train_loss_raw=0.3489, running_loss=0.3565, LR=0.000100
[2025-08-11 15:28:59,862][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023172] [Batch 03696/04869] [00:33:14/00:10:32, 0.540s/it]: train_loss_raw=0.3259, running_loss=0.3590, LR=0.000100
[2025-08-11 15:29:06,207][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023184] [Batch 03708/04869] [00:33:20/00:10:26, 0.540s/it]: train_loss_raw=0.3412, running_loss=0.3597, LR=0.000100
[2025-08-11 15:29:12,576][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023196] [Batch 03720/04869] [00:33:26/00:10:19, 0.540s/it]: train_loss_raw=0.2600, running_loss=0.3580, LR=0.000100
[2025-08-11 15:29:18,981][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023208] [Batch 03732/04869] [00:33:33/00:10:13, 0.539s/it]: train_loss_raw=0.3335, running_loss=0.3592, LR=0.000100
[2025-08-11 15:29:25,437][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023220] [Batch 03744/04869] [00:33:39/00:10:06, 0.539s/it]: train_loss_raw=0.2885, running_loss=0.3580, LR=0.000100
[2025-08-11 15:29:31,845][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023232] [Batch 03756/04869] [00:33:46/00:10:00, 0.539s/it]: train_loss_raw=0.4014, running_loss=0.3606, LR=0.000100
[2025-08-11 15:29:38,165][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023244] [Batch 03768/04869] [00:33:52/00:09:53, 0.539s/it]: train_loss_raw=0.3811, running_loss=0.3589, LR=0.000100
[2025-08-11 15:29:44,533][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023256] [Batch 03780/04869] [00:33:58/00:09:47, 0.539s/it]: train_loss_raw=0.3172, running_loss=0.3612, LR=0.000100
[2025-08-11 15:29:50,937][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023268] [Batch 03792/04869] [00:34:05/00:09:40, 0.539s/it]: train_loss_raw=0.4630, running_loss=0.3616, LR=0.000100
[2025-08-11 15:29:57,250][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023280] [Batch 03804/04869] [00:34:11/00:09:34, 0.539s/it]: train_loss_raw=0.3784, running_loss=0.3604, LR=0.000100
[2025-08-11 15:30:03,533][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023292] [Batch 03816/04869] [00:34:17/00:09:27, 0.539s/it]: train_loss_raw=0.3029, running_loss=0.3601, LR=0.000100
[2025-08-11 15:30:09,916][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023304] [Batch 03828/04869] [00:34:24/00:09:21, 0.539s/it]: train_loss_raw=0.2491, running_loss=0.3587, LR=0.000100
[2025-08-11 15:30:16,309][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023316] [Batch 03840/04869] [00:34:30/00:09:14, 0.539s/it]: train_loss_raw=0.3897, running_loss=0.3581, LR=0.000100
[2025-08-11 15:30:22,614][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023328] [Batch 03852/04869] [00:34:36/00:09:08, 0.539s/it]: train_loss_raw=0.4566, running_loss=0.3572, LR=0.000100
[2025-08-11 15:30:29,025][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023340] [Batch 03864/04869] [00:34:43/00:09:01, 0.539s/it]: train_loss_raw=0.3482, running_loss=0.3582, LR=0.000100
[2025-08-11 15:30:35,187][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023352] [Batch 03876/04869] [00:34:49/00:08:55, 0.539s/it]: train_loss_raw=0.3362, running_loss=0.3590, LR=0.000100
[2025-08-11 15:30:41,321][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023364] [Batch 03888/04869] [00:34:55/00:08:48, 0.539s/it]: train_loss_raw=0.3779, running_loss=0.3606, LR=0.000100
[2025-08-11 15:30:47,467][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023376] [Batch 03900/04869] [00:35:01/00:08:42, 0.539s/it]: train_loss_raw=0.3878, running_loss=0.3589, LR=0.000100
[2025-08-11 15:30:53,877][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023388] [Batch 03912/04869] [00:35:08/00:08:35, 0.539s/it]: train_loss_raw=0.2862, running_loss=0.3611, LR=0.000100
[2025-08-11 15:31:00,325][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023400] [Batch 03924/04869] [00:35:14/00:08:29, 0.539s/it]: train_loss_raw=0.3211, running_loss=0.3575, LR=0.000100
[2025-08-11 15:31:06,779][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023412] [Batch 03936/04869] [00:35:21/00:08:22, 0.539s/it]: train_loss_raw=0.2975, running_loss=0.3568, LR=0.000100
[2025-08-11 15:31:13,171][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023424] [Batch 03948/04869] [00:35:27/00:08:16, 0.539s/it]: train_loss_raw=0.3174, running_loss=0.3578, LR=0.000100
[2025-08-11 15:31:19,506][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023436] [Batch 03960/04869] [00:35:33/00:08:09, 0.539s/it]: train_loss_raw=0.4125, running_loss=0.3655, LR=0.000100
[2025-08-11 15:31:25,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023448] [Batch 03972/04869] [00:35:40/00:08:03, 0.539s/it]: train_loss_raw=0.4312, running_loss=0.3643, LR=0.000100
[2025-08-11 15:31:32,006][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023460] [Batch 03984/04869] [00:35:46/00:07:56, 0.539s/it]: train_loss_raw=0.4232, running_loss=0.3661, LR=0.000100
[2025-08-11 15:31:38,490][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023472] [Batch 03996/04869] [00:35:52/00:07:50, 0.539s/it]: train_loss_raw=0.3034, running_loss=0.3618, LR=0.000100
[2025-08-11 15:31:44,909][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023484] [Batch 04008/04869] [00:35:59/00:07:43, 0.539s/it]: train_loss_raw=0.3100, running_loss=0.3621, LR=0.000100
[2025-08-11 15:31:51,310][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023496] [Batch 04020/04869] [00:36:05/00:07:37, 0.539s/it]: train_loss_raw=0.3555, running_loss=0.3590, LR=0.000100
[2025-08-11 15:31:57,672][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023508] [Batch 04032/04869] [00:36:12/00:07:30, 0.539s/it]: train_loss_raw=0.2985, running_loss=0.3580, LR=0.000100
[2025-08-11 15:32:04,104][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023520] [Batch 04044/04869] [00:36:18/00:07:24, 0.539s/it]: train_loss_raw=0.4053, running_loss=0.3602, LR=0.000100
[2025-08-11 15:32:10,500][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023532] [Batch 04056/04869] [00:36:24/00:07:17, 0.539s/it]: train_loss_raw=0.3225, running_loss=0.3603, LR=0.000100
[2025-08-11 15:32:16,871][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023544] [Batch 04068/04869] [00:36:31/00:07:11, 0.539s/it]: train_loss_raw=0.4407, running_loss=0.3613, LR=0.000100
[2025-08-11 15:32:23,201][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023556] [Batch 04080/04869] [00:36:37/00:07:04, 0.539s/it]: train_loss_raw=0.3031, running_loss=0.3589, LR=0.000100
[2025-08-11 15:32:29,673][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023568] [Batch 04092/04869] [00:36:44/00:06:58, 0.539s/it]: train_loss_raw=0.3576, running_loss=0.3612, LR=0.000100
[2025-08-11 15:32:35,975][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023580] [Batch 04104/04869] [00:36:50/00:06:52, 0.539s/it]: train_loss_raw=0.4022, running_loss=0.3603, LR=0.000100
[2025-08-11 15:32:42,289][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023592] [Batch 04116/04869] [00:36:56/00:06:45, 0.539s/it]: train_loss_raw=0.3923, running_loss=0.3592, LR=0.000100
[2025-08-11 15:32:48,720][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023604] [Batch 04128/04869] [00:37:03/00:06:39, 0.539s/it]: train_loss_raw=0.3368, running_loss=0.3597, LR=0.000100
[2025-08-11 15:32:55,067][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023616] [Batch 04140/04869] [00:37:09/00:06:32, 0.539s/it]: train_loss_raw=0.4279, running_loss=0.3582, LR=0.000100
[2025-08-11 15:33:01,391][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023628] [Batch 04152/04869] [00:37:15/00:06:26, 0.538s/it]: train_loss_raw=0.4949, running_loss=0.3588, LR=0.000100
[2025-08-11 15:33:07,733][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023640] [Batch 04164/04869] [00:37:22/00:06:19, 0.538s/it]: train_loss_raw=0.3615, running_loss=0.3574, LR=0.000100
[2025-08-11 15:33:13,899][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023652] [Batch 04176/04869] [00:37:28/00:06:13, 0.538s/it]: train_loss_raw=0.3110, running_loss=0.3543, LR=0.000100
[2025-08-11 15:33:20,190][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023664] [Batch 04188/04869] [00:37:34/00:06:06, 0.538s/it]: train_loss_raw=0.3783, running_loss=0.3557, LR=0.000100
[2025-08-11 15:33:26,665][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023676] [Batch 04200/04869] [00:37:41/00:06:00, 0.538s/it]: train_loss_raw=0.3340, running_loss=0.3527, LR=0.000100
[2025-08-11 15:33:33,074][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023688] [Batch 04212/04869] [00:37:47/00:05:53, 0.538s/it]: train_loss_raw=0.3362, running_loss=0.3510, LR=0.000100
[2025-08-11 15:33:39,426][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023700] [Batch 04224/04869] [00:37:53/00:05:47, 0.538s/it]: train_loss_raw=0.3356, running_loss=0.3516, LR=0.000100
[2025-08-11 15:33:45,571][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023712] [Batch 04236/04869] [00:37:59/00:05:40, 0.538s/it]: train_loss_raw=0.2375, running_loss=0.3538, LR=0.000100
[2025-08-11 15:33:51,824][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023724] [Batch 04248/04869] [00:38:06/00:05:34, 0.538s/it]: train_loss_raw=0.3692, running_loss=0.3564, LR=0.000100
[2025-08-11 15:33:57,984][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023736] [Batch 04260/04869] [00:38:12/00:05:27, 0.538s/it]: train_loss_raw=0.4516, running_loss=0.3588, LR=0.000100
[2025-08-11 15:34:04,188][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023748] [Batch 04272/04869] [00:38:18/00:05:21, 0.538s/it]: train_loss_raw=0.3628, running_loss=0.3602, LR=0.000100
[2025-08-11 15:34:10,366][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023760] [Batch 04284/04869] [00:38:24/00:05:14, 0.538s/it]: train_loss_raw=0.2917, running_loss=0.3601, LR=0.000100
[2025-08-11 15:34:16,620][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023772] [Batch 04296/04869] [00:38:30/00:05:08, 0.538s/it]: train_loss_raw=0.5780, running_loss=0.3600, LR=0.000100
[2025-08-11 15:34:22,796][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023784] [Batch 04308/04869] [00:38:37/00:05:01, 0.538s/it]: train_loss_raw=0.3265, running_loss=0.3582, LR=0.000100
[2025-08-11 15:34:28,957][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023796] [Batch 04320/04869] [00:38:43/00:04:55, 0.538s/it]: train_loss_raw=0.2618, running_loss=0.3574, LR=0.000100
[2025-08-11 15:34:35,078][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023808] [Batch 04332/04869] [00:38:49/00:04:48, 0.538s/it]: train_loss_raw=0.3518, running_loss=0.3585, LR=0.000100
[2025-08-11 15:34:41,533][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023820] [Batch 04344/04869] [00:38:55/00:04:42, 0.538s/it]: train_loss_raw=0.3521, running_loss=0.3584, LR=0.000100
[2025-08-11 15:34:48,033][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023832] [Batch 04356/04869] [00:39:02/00:04:35, 0.538s/it]: train_loss_raw=0.3253, running_loss=0.3557, LR=0.000100
[2025-08-11 15:34:54,495][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023844] [Batch 04368/04869] [00:39:08/00:04:29, 0.538s/it]: train_loss_raw=0.3922, running_loss=0.3560, LR=0.000100
[2025-08-11 15:35:00,814][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023856] [Batch 04380/04869] [00:39:15/00:04:22, 0.538s/it]: train_loss_raw=0.3708, running_loss=0.3586, LR=0.000100
[2025-08-11 15:35:07,308][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023868] [Batch 04392/04869] [00:39:21/00:04:16, 0.538s/it]: train_loss_raw=0.3028, running_loss=0.3601, LR=0.000100
[2025-08-11 15:35:13,651][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023880] [Batch 04404/04869] [00:39:28/00:04:10, 0.538s/it]: train_loss_raw=0.4651, running_loss=0.3605, LR=0.000100
[2025-08-11 15:35:20,140][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023892] [Batch 04416/04869] [00:39:34/00:04:03, 0.538s/it]: train_loss_raw=0.3233, running_loss=0.3597, LR=0.000100
[2025-08-11 15:35:26,557][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023904] [Batch 04428/04869] [00:39:40/00:03:57, 0.538s/it]: train_loss_raw=0.4266, running_loss=0.3607, LR=0.000100
[2025-08-11 15:35:32,889][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023916] [Batch 04440/04869] [00:39:47/00:03:50, 0.538s/it]: train_loss_raw=0.3686, running_loss=0.3624, LR=0.000100
[2025-08-11 15:35:39,325][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023928] [Batch 04452/04869] [00:39:53/00:03:44, 0.538s/it]: train_loss_raw=0.2427, running_loss=0.3623, LR=0.000100
[2025-08-11 15:35:45,748][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023940] [Batch 04464/04869] [00:40:00/00:03:37, 0.538s/it]: train_loss_raw=0.4204, running_loss=0.3632, LR=0.000100
[2025-08-11 15:35:51,946][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023952] [Batch 04476/04869] [00:40:06/00:03:31, 0.538s/it]: train_loss_raw=0.3667, running_loss=0.3638, LR=0.000100
[2025-08-11 15:35:58,245][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023964] [Batch 04488/04869] [00:40:12/00:03:24, 0.538s/it]: train_loss_raw=0.4157, running_loss=0.3646, LR=0.000100
[2025-08-11 15:36:04,593][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023976] [Batch 04500/04869] [00:40:18/00:03:18, 0.538s/it]: train_loss_raw=0.5069, running_loss=0.3677, LR=0.000100
[2025-08-11 15:36:10,826][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023988] [Batch 04512/04869] [00:40:25/00:03:11, 0.537s/it]: train_loss_raw=0.3951, running_loss=0.3667, LR=0.000100
[2025-08-11 15:36:17,305][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024000] [Batch 04524/04869] [00:40:31/00:03:05, 0.538s/it]: train_loss_raw=0.4262, running_loss=0.3667, LR=0.000100
[2025-08-11 15:36:28,440][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024012] [Batch 04536/04869] [00:40:42/00:02:59, 0.539s/it]: train_loss_raw=0.3984, running_loss=0.3648, LR=0.000100
[2025-08-11 15:36:34,864][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024024] [Batch 04548/04869] [00:40:49/00:02:52, 0.539s/it]: train_loss_raw=0.4079, running_loss=0.3649, LR=0.000100
[2025-08-11 15:36:41,245][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024036] [Batch 04560/04869] [00:40:55/00:02:46, 0.539s/it]: train_loss_raw=0.3589, running_loss=0.3634, LR=0.000100
[2025-08-11 15:36:47,662][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024048] [Batch 04572/04869] [00:41:02/00:02:39, 0.539s/it]: train_loss_raw=0.3909, running_loss=0.3618, LR=0.000100
[2025-08-11 15:36:53,976][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024060] [Batch 04584/04869] [00:41:08/00:02:33, 0.538s/it]: train_loss_raw=0.4902, running_loss=0.3641, LR=0.000100
[2025-08-11 15:37:00,328][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024072] [Batch 04596/04869] [00:41:14/00:02:26, 0.538s/it]: train_loss_raw=0.3962, running_loss=0.3621, LR=0.000100
[2025-08-11 15:37:06,685][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024084] [Batch 04608/04869] [00:41:21/00:02:20, 0.538s/it]: train_loss_raw=0.3081, running_loss=0.3603, LR=0.000100
[2025-08-11 15:37:13,041][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024096] [Batch 04620/04869] [00:41:27/00:02:14, 0.538s/it]: train_loss_raw=0.4251, running_loss=0.3609, LR=0.000100
[2025-08-11 15:37:19,384][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024108] [Batch 04632/04869] [00:41:33/00:02:07, 0.538s/it]: train_loss_raw=0.3598, running_loss=0.3596, LR=0.000100
[2025-08-11 15:37:25,695][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024120] [Batch 04644/04869] [00:41:40/00:02:01, 0.538s/it]: train_loss_raw=0.4020, running_loss=0.3583, LR=0.000100
[2025-08-11 15:37:32,072][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024132] [Batch 04656/04869] [00:41:46/00:01:54, 0.538s/it]: train_loss_raw=0.4014, running_loss=0.3567, LR=0.000100
[2025-08-11 15:37:38,226][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024144] [Batch 04668/04869] [00:41:52/00:01:48, 0.538s/it]: train_loss_raw=0.4035, running_loss=0.3561, LR=0.000100
[2025-08-11 15:37:44,619][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024156] [Batch 04680/04869] [00:41:58/00:01:41, 0.538s/it]: train_loss_raw=0.3767, running_loss=0.3580, LR=0.000100
[2025-08-11 15:37:51,128][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024168] [Batch 04692/04869] [00:42:05/00:01:35, 0.538s/it]: train_loss_raw=0.3345, running_loss=0.3595, LR=0.000100
[2025-08-11 15:37:57,607][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024180] [Batch 04704/04869] [00:42:11/00:01:28, 0.538s/it]: train_loss_raw=0.2750, running_loss=0.3557, LR=0.000100
[2025-08-11 15:38:04,077][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024192] [Batch 04716/04869] [00:42:18/00:01:22, 0.538s/it]: train_loss_raw=0.2834, running_loss=0.3540, LR=0.000100
[2025-08-11 15:38:10,562][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024204] [Batch 04728/04869] [00:42:24/00:01:15, 0.538s/it]: train_loss_raw=0.3830, running_loss=0.3537, LR=0.000100
[2025-08-11 15:38:16,970][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024216] [Batch 04740/04869] [00:42:31/00:01:09, 0.538s/it]: train_loss_raw=0.4080, running_loss=0.3538, LR=0.000100
[2025-08-11 15:38:23,321][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024228] [Batch 04752/04869] [00:42:37/00:01:02, 0.538s/it]: train_loss_raw=0.3176, running_loss=0.3537, LR=0.000100
[2025-08-11 15:38:29,631][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024240] [Batch 04764/04869] [00:42:43/00:00:56, 0.538s/it]: train_loss_raw=0.3568, running_loss=0.3552, LR=0.000100
[2025-08-11 15:38:35,961][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024252] [Batch 04776/04869] [00:42:50/00:00:50, 0.538s/it]: train_loss_raw=0.2621, running_loss=0.3544, LR=0.000100
[2025-08-11 15:38:42,231][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024264] [Batch 04788/04869] [00:42:56/00:00:43, 0.538s/it]: train_loss_raw=0.4455, running_loss=0.3557, LR=0.000100
[2025-08-11 15:38:48,542][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024276] [Batch 04800/04869] [00:43:02/00:00:37, 0.538s/it]: train_loss_raw=0.3741, running_loss=0.3532, LR=0.000100
[2025-08-11 15:38:54,902][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024288] [Batch 04812/04869] [00:43:09/00:00:30, 0.538s/it]: train_loss_raw=0.3494, running_loss=0.3550, LR=0.000100
[2025-08-11 15:39:01,381][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024300] [Batch 04824/04869] [00:43:15/00:00:24, 0.538s/it]: train_loss_raw=0.3080, running_loss=0.3537, LR=0.000100
[2025-08-11 15:39:07,692][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024312] [Batch 04836/04869] [00:43:22/00:00:17, 0.538s/it]: train_loss_raw=0.4129, running_loss=0.3566, LR=0.000100
[2025-08-11 15:39:14,015][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024324] [Batch 04848/04869] [00:43:28/00:00:11, 0.538s/it]: train_loss_raw=0.3927, running_loss=0.3550, LR=0.000100
[2025-08-11 15:39:20,342][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024336] [Batch 04860/04869] [00:43:34/00:00:04, 0.538s/it]: train_loss_raw=0.3319, running_loss=0.3561, LR=0.000100
[2025-08-11 15:39:29,753][__main__][INFO] - [VALIDATION] [Epoch 04/29] Starting validation.
[2025-08-11 15:39:45,285][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00011/00062] [00:00:15/00:01:04, 1.294s/it]
[2025-08-11 15:40:18,707][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00023/00062] [00:00:48/00:01:17, 2.040s/it]
[2025-08-11 15:40:33,257][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00035/00062] [00:01:03/00:00:45, 1.764s/it]
[2025-08-11 15:40:47,576][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00047/00062] [00:01:17/00:00:22, 1.621s/it]
[2025-08-11 15:41:01,592][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00059/00062] [00:01:31/00:00:03, 1.531s/it]
[2025-08-11 15:41:03,871][__main__][INFO] - [VALIDATION] [Epoch 04/29] train_loss=0.35581, valid_loss=0.37434
[2025-08-11 15:41:03,871][__main__][INFO] - [VALIDATION] [Epoch 04/29] Metrics:
[2025-08-11 15:41:03,871][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_er      0.199
[2025-08-11 15:41:03,872][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_prec    0.621
[2025-08-11 15:41:03,872][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_recall  0.625
[2025-08-11 15:41:03,872][__main__][INFO] - [VALIDATION] [Epoch 04/29] - pep_recall 0.585
[2025-08-11 15:41:03,876][__main__][INFO] - [TRAIN] [Epoch 04/29] Epoch complete, total time 03:45:42, remaining time 18:48:32, 00:45:08 per epoch
[2025-08-11 15:41:05,251][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024348] [Batch 00003/04869] [00:00:01/00:30:59, 0.382s/it]: train_loss_raw=0.4290, running_loss=0.3591, LR=0.000100
[2025-08-11 15:41:11,533][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024360] [Batch 00015/04869] [00:00:07/00:40:03, 0.495s/it]: train_loss_raw=0.3033, running_loss=0.3584, LR=0.000100
[2025-08-11 15:41:17,799][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024372] [Batch 00027/04869] [00:00:13/00:40:55, 0.507s/it]: train_loss_raw=0.3107, running_loss=0.3574, LR=0.000100
[2025-08-11 15:41:24,161][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024384] [Batch 00039/04869] [00:00:20/00:41:23, 0.514s/it]: train_loss_raw=0.3299, running_loss=0.3572, LR=0.000100
[2025-08-11 15:41:30,582][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024396] [Batch 00051/04869] [00:00:26/00:41:41, 0.519s/it]: train_loss_raw=0.3183, running_loss=0.3570, LR=0.000100
[2025-08-11 15:41:36,959][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024408] [Batch 00063/04869] [00:00:32/00:41:46, 0.521s/it]: train_loss_raw=0.3212, running_loss=0.3551, LR=0.000100
[2025-08-11 15:41:43,325][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024420] [Batch 00075/04869] [00:00:39/00:41:46, 0.523s/it]: train_loss_raw=0.3127, running_loss=0.3570, LR=0.000100
[2025-08-11 15:41:49,713][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024432] [Batch 00087/04869] [00:00:45/00:41:46, 0.524s/it]: train_loss_raw=0.3632, running_loss=0.3579, LR=0.000100
[2025-08-11 15:41:55,975][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024444] [Batch 00099/04869] [00:00:51/00:41:39, 0.524s/it]: train_loss_raw=0.3431, running_loss=0.3568, LR=0.000100
[2025-08-11 15:42:02,273][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024456] [Batch 00111/04869] [00:00:58/00:41:33, 0.524s/it]: train_loss_raw=0.3111, running_loss=0.3573, LR=0.000100
[2025-08-11 15:42:08,585][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024468] [Batch 00123/04869] [00:01:04/00:41:28, 0.524s/it]: train_loss_raw=0.2652, running_loss=0.3567, LR=0.000100
[2025-08-11 15:42:14,980][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024480] [Batch 00135/04869] [00:01:10/00:41:25, 0.525s/it]: train_loss_raw=0.3521, running_loss=0.3544, LR=0.000100
[2025-08-11 15:42:21,274][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024492] [Batch 00147/04869] [00:01:17/00:41:18, 0.525s/it]: train_loss_raw=0.3326, running_loss=0.3540, LR=0.000100
[2025-08-11 15:42:27,607][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024504] [Batch 00159/04869] [00:01:23/00:41:13, 0.525s/it]: train_loss_raw=0.3187, running_loss=0.3541, LR=0.000100
[2025-08-11 15:42:33,939][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024516] [Batch 00171/04869] [00:01:29/00:41:08, 0.525s/it]: train_loss_raw=0.3089, running_loss=0.3529, LR=0.000100
[2025-08-11 15:42:40,411][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024528] [Batch 00183/04869] [00:01:36/00:41:06, 0.526s/it]: train_loss_raw=0.3612, running_loss=0.3534, LR=0.000100
[2025-08-11 15:42:46,749][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024540] [Batch 00195/04869] [00:01:42/00:41:00, 0.526s/it]: train_loss_raw=0.3325, running_loss=0.3531, LR=0.000100
[2025-08-11 15:42:53,036][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024552] [Batch 00207/04869] [00:01:48/00:40:53, 0.526s/it]: train_loss_raw=0.3943, running_loss=0.3483, LR=0.000100
[2025-08-11 15:42:59,406][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024564] [Batch 00219/04869] [00:01:55/00:40:48, 0.526s/it]: train_loss_raw=0.3300, running_loss=0.3480, LR=0.000100
[2025-08-11 15:43:05,553][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024576] [Batch 00231/04869] [00:02:01/00:40:38, 0.526s/it]: train_loss_raw=0.3989, running_loss=0.3494, LR=0.000100
[2025-08-11 15:43:11,519][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024588] [Batch 00243/04869] [00:02:07/00:40:25, 0.524s/it]: train_loss_raw=0.3783, running_loss=0.3523, LR=0.000100
[2025-08-11 15:43:17,781][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024600] [Batch 00255/04869] [00:02:13/00:40:18, 0.524s/it]: train_loss_raw=0.3894, running_loss=0.3535, LR=0.000100
[2025-08-11 15:43:24,144][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024612] [Batch 00267/04869] [00:02:20/00:40:13, 0.524s/it]: train_loss_raw=0.3810, running_loss=0.3557, LR=0.000100
[2025-08-11 15:43:30,572][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024624] [Batch 00279/04869] [00:02:26/00:40:09, 0.525s/it]: train_loss_raw=0.3990, running_loss=0.3565, LR=0.000100
[2025-08-11 15:43:37,046][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024636] [Batch 00291/04869] [00:02:32/00:40:06, 0.526s/it]: train_loss_raw=0.4075, running_loss=0.3571, LR=0.000100
[2025-08-11 15:43:43,540][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024648] [Batch 00303/04869] [00:02:39/00:40:02, 0.526s/it]: train_loss_raw=0.4097, running_loss=0.3588, LR=0.000100
[2025-08-11 15:43:49,893][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024660] [Batch 00315/04869] [00:02:45/00:39:56, 0.526s/it]: train_loss_raw=0.3778, running_loss=0.3568, LR=0.000100
[2025-08-11 15:43:56,212][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024672] [Batch 00327/04869] [00:02:52/00:39:50, 0.526s/it]: train_loss_raw=0.4049, running_loss=0.3582, LR=0.000100
[2025-08-11 15:44:02,568][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024684] [Batch 00339/04869] [00:02:58/00:39:44, 0.526s/it]: train_loss_raw=0.3460, running_loss=0.3574, LR=0.000100
[2025-08-11 15:44:08,910][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024696] [Batch 00351/04869] [00:03:04/00:39:38, 0.527s/it]: train_loss_raw=0.2936, running_loss=0.3584, LR=0.000100
[2025-08-11 15:44:15,286][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024708] [Batch 00363/04869] [00:03:11/00:39:33, 0.527s/it]: train_loss_raw=0.4435, running_loss=0.3575, LR=0.000100
[2025-08-11 15:44:21,582][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024720] [Batch 00375/04869] [00:03:17/00:39:26, 0.527s/it]: train_loss_raw=0.3180, running_loss=0.3552, LR=0.000100
[2025-08-11 15:44:27,961][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024732] [Batch 00387/04869] [00:03:23/00:39:20, 0.527s/it]: train_loss_raw=0.4705, running_loss=0.3569, LR=0.000100
[2025-08-11 15:44:34,382][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024744] [Batch 00399/04869] [00:03:30/00:39:15, 0.527s/it]: train_loss_raw=0.3245, running_loss=0.3551, LR=0.000100
[2025-08-11 15:44:40,810][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024756] [Batch 00411/04869] [00:03:36/00:39:10, 0.527s/it]: train_loss_raw=0.2779, running_loss=0.3572, LR=0.000100
[2025-08-11 15:44:47,196][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024768] [Batch 00423/04869] [00:03:43/00:39:04, 0.527s/it]: train_loss_raw=0.3990, running_loss=0.3558, LR=0.000100
[2025-08-11 15:44:53,552][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024780] [Batch 00435/04869] [00:03:49/00:38:58, 0.527s/it]: train_loss_raw=0.4109, running_loss=0.3560, LR=0.000100
[2025-08-11 15:44:59,985][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024792] [Batch 00447/04869] [00:03:55/00:38:53, 0.528s/it]: train_loss_raw=0.4824, running_loss=0.3565, LR=0.000100
[2025-08-11 15:45:06,325][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024804] [Batch 00459/04869] [00:04:02/00:38:47, 0.528s/it]: train_loss_raw=0.4089, running_loss=0.3574, LR=0.000100
[2025-08-11 15:45:12,617][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024816] [Batch 00471/04869] [00:04:08/00:38:40, 0.528s/it]: train_loss_raw=0.3427, running_loss=0.3556, LR=0.000100
[2025-08-11 15:45:18,991][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024828] [Batch 00483/04869] [00:04:14/00:38:34, 0.528s/it]: train_loss_raw=0.2493, running_loss=0.3550, LR=0.000100
[2025-08-11 15:45:25,336][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024840] [Batch 00495/04869] [00:04:21/00:38:28, 0.528s/it]: train_loss_raw=0.3114, running_loss=0.3555, LR=0.000100
[2025-08-11 15:45:31,661][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024852] [Batch 00507/04869] [00:04:27/00:38:21, 0.528s/it]: train_loss_raw=0.2869, running_loss=0.3550, LR=0.000100
[2025-08-11 15:45:38,031][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024864] [Batch 00519/04869] [00:04:33/00:38:15, 0.528s/it]: train_loss_raw=0.3906, running_loss=0.3577, LR=0.000100
[2025-08-11 15:45:44,300][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024876] [Batch 00531/04869] [00:04:40/00:38:09, 0.528s/it]: train_loss_raw=0.3216, running_loss=0.3560, LR=0.000100
[2025-08-11 15:45:50,646][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024888] [Batch 00543/04869] [00:04:46/00:38:02, 0.528s/it]: train_loss_raw=0.3121, running_loss=0.3565, LR=0.000100
[2025-08-11 15:45:57,017][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024900] [Batch 00555/04869] [00:04:52/00:37:56, 0.528s/it]: train_loss_raw=0.3771, running_loss=0.3567, LR=0.000100
[2025-08-11 15:46:03,359][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024912] [Batch 00567/04869] [00:04:59/00:37:50, 0.528s/it]: train_loss_raw=0.2817, running_loss=0.3550, LR=0.000100
[2025-08-11 15:46:09,743][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024924] [Batch 00579/04869] [00:05:05/00:37:44, 0.528s/it]: train_loss_raw=0.3423, running_loss=0.3534, LR=0.000100
[2025-08-11 15:46:16,141][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024936] [Batch 00591/04869] [00:05:12/00:37:38, 0.528s/it]: train_loss_raw=0.2739, running_loss=0.3527, LR=0.000100
[2025-08-11 15:46:22,556][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024948] [Batch 00603/04869] [00:05:18/00:37:32, 0.528s/it]: train_loss_raw=0.3644, running_loss=0.3534, LR=0.000100
[2025-08-11 15:46:29,000][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024960] [Batch 00615/04869] [00:05:24/00:37:27, 0.528s/it]: train_loss_raw=0.3104, running_loss=0.3521, LR=0.000100
[2025-08-11 15:46:35,323][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024972] [Batch 00627/04869] [00:05:31/00:37:20, 0.528s/it]: train_loss_raw=0.3157, running_loss=0.3540, LR=0.000100
[2025-08-11 15:46:41,701][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024984] [Batch 00639/04869] [00:05:37/00:37:14, 0.528s/it]: train_loss_raw=0.3121, running_loss=0.3522, LR=0.000100
[2025-08-11 15:46:47,963][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024996] [Batch 00651/04869] [00:05:43/00:37:07, 0.528s/it]: train_loss_raw=0.3390, running_loss=0.3514, LR=0.000100
[2025-08-11 15:46:54,202][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025008] [Batch 00663/04869] [00:05:50/00:37:00, 0.528s/it]: train_loss_raw=0.3446, running_loss=0.3491, LR=0.000100
[2025-08-11 15:47:00,477][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025020] [Batch 00675/04869] [00:05:56/00:36:54, 0.528s/it]: train_loss_raw=0.3730, running_loss=0.3537, LR=0.000100
[2025-08-11 15:47:06,822][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025032] [Batch 00687/04869] [00:06:02/00:36:47, 0.528s/it]: train_loss_raw=0.3633, running_loss=0.3536, LR=0.000100
[2025-08-11 15:47:13,192][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025044] [Batch 00699/04869] [00:06:09/00:36:41, 0.528s/it]: train_loss_raw=0.3118, running_loss=0.3526, LR=0.000100
[2025-08-11 15:47:19,559][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025056] [Batch 00711/04869] [00:06:15/00:36:35, 0.528s/it]: train_loss_raw=0.3447, running_loss=0.3532, LR=0.000100
[2025-08-11 15:47:25,971][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025068] [Batch 00723/04869] [00:06:21/00:36:29, 0.528s/it]: train_loss_raw=0.2901, running_loss=0.3547, LR=0.000100
[2025-08-11 15:47:32,385][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025080] [Batch 00735/04869] [00:06:28/00:36:23, 0.528s/it]: train_loss_raw=0.2628, running_loss=0.3526, LR=0.000100
[2025-08-11 15:47:38,756][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025092] [Batch 00747/04869] [00:06:34/00:36:17, 0.528s/it]: train_loss_raw=0.4158, running_loss=0.3556, LR=0.000100
[2025-08-11 15:47:45,126][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025104] [Batch 00759/04869] [00:06:41/00:36:11, 0.528s/it]: train_loss_raw=0.3523, running_loss=0.3550, LR=0.000100
[2025-08-11 15:47:51,468][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025116] [Batch 00771/04869] [00:06:47/00:36:05, 0.528s/it]: train_loss_raw=0.3494, running_loss=0.3553, LR=0.000100
[2025-08-11 15:47:57,759][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025128] [Batch 00783/04869] [00:06:53/00:35:58, 0.528s/it]: train_loss_raw=0.3048, running_loss=0.3558, LR=0.000100
[2025-08-11 15:48:04,131][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025140] [Batch 00795/04869] [00:07:00/00:35:52, 0.528s/it]: train_loss_raw=0.4468, running_loss=0.3565, LR=0.000100
[2025-08-11 15:48:10,417][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025152] [Batch 00807/04869] [00:07:06/00:35:45, 0.528s/it]: train_loss_raw=0.3613, running_loss=0.3548, LR=0.000100
[2025-08-11 15:48:16,719][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025164] [Batch 00819/04869] [00:07:12/00:35:39, 0.528s/it]: train_loss_raw=0.3480, running_loss=0.3567, LR=0.000100
[2025-08-11 15:48:23,031][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025176] [Batch 00831/04869] [00:07:18/00:35:32, 0.528s/it]: train_loss_raw=0.3579, running_loss=0.3549, LR=0.000100
[2025-08-11 15:48:29,408][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025188] [Batch 00843/04869] [00:07:25/00:35:26, 0.528s/it]: train_loss_raw=0.3110, running_loss=0.3542, LR=0.000100
[2025-08-11 15:48:35,994][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025200] [Batch 00855/04869] [00:07:31/00:35:21, 0.529s/it]: train_loss_raw=0.3375, running_loss=0.3531, LR=0.000100
[2025-08-11 15:48:42,470][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025212] [Batch 00867/04869] [00:07:38/00:35:15, 0.529s/it]: train_loss_raw=0.3888, running_loss=0.3540, LR=0.000100
[2025-08-11 15:48:49,046][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025224] [Batch 00879/04869] [00:07:44/00:35:10, 0.529s/it]: train_loss_raw=0.3924, running_loss=0.3564, LR=0.000100
[2025-08-11 15:48:55,525][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025236] [Batch 00891/04869] [00:07:51/00:35:04, 0.529s/it]: train_loss_raw=0.3818, running_loss=0.3567, LR=0.000100
[2025-08-11 15:49:01,852][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025248] [Batch 00903/04869] [00:07:57/00:34:58, 0.529s/it]: train_loss_raw=0.3922, running_loss=0.3557, LR=0.000100
[2025-08-11 15:49:08,128][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025260] [Batch 00915/04869] [00:08:04/00:34:51, 0.529s/it]: train_loss_raw=0.3461, running_loss=0.3548, LR=0.000100
[2025-08-11 15:49:14,452][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025272] [Batch 00927/04869] [00:08:10/00:34:45, 0.529s/it]: train_loss_raw=0.3746, running_loss=0.3549, LR=0.000100
[2025-08-11 15:49:20,729][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025284] [Batch 00939/04869] [00:08:16/00:34:38, 0.529s/it]: train_loss_raw=0.3706, running_loss=0.3525, LR=0.000100
[2025-08-11 15:49:27,071][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025296] [Batch 00951/04869] [00:08:22/00:34:32, 0.529s/it]: train_loss_raw=0.4465, running_loss=0.3540, LR=0.000100
[2025-08-11 15:49:33,210][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025308] [Batch 00963/04869] [00:08:29/00:34:24, 0.529s/it]: train_loss_raw=0.3290, running_loss=0.3550, LR=0.000100
[2025-08-11 15:49:39,325][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025320] [Batch 00975/04869] [00:08:35/00:34:17, 0.528s/it]: train_loss_raw=0.2922, running_loss=0.3540, LR=0.000100
[2025-08-11 15:49:45,556][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025332] [Batch 00987/04869] [00:08:41/00:34:10, 0.528s/it]: train_loss_raw=0.3306, running_loss=0.3585, LR=0.000100
[2025-08-11 15:49:51,755][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025344] [Batch 00999/04869] [00:08:47/00:34:04, 0.528s/it]: train_loss_raw=0.3466, running_loss=0.3602, LR=0.000100
[2025-08-11 15:49:58,253][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025356] [Batch 01011/04869] [00:08:54/00:33:58, 0.528s/it]: train_loss_raw=0.3285, running_loss=0.3609, LR=0.000100
[2025-08-11 15:50:04,521][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025368] [Batch 01023/04869] [00:09:00/00:33:51, 0.528s/it]: train_loss_raw=0.3522, running_loss=0.3591, LR=0.000100
[2025-08-11 15:50:10,690][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025380] [Batch 01035/04869] [00:09:06/00:33:44, 0.528s/it]: train_loss_raw=0.3030, running_loss=0.3590, LR=0.000100
[2025-08-11 15:50:16,820][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025392] [Batch 01047/04869] [00:09:12/00:33:37, 0.528s/it]: train_loss_raw=0.4332, running_loss=0.3577, LR=0.000100
[2025-08-11 15:50:23,032][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025404] [Batch 01059/04869] [00:09:18/00:33:30, 0.528s/it]: train_loss_raw=0.3861, running_loss=0.3582, LR=0.000100
[2025-08-11 15:50:29,199][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025416] [Batch 01071/04869] [00:09:25/00:33:23, 0.528s/it]: train_loss_raw=0.3760, running_loss=0.3572, LR=0.000100
[2025-08-11 15:50:35,372][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025428] [Batch 01083/04869] [00:09:31/00:33:17, 0.527s/it]: train_loss_raw=0.3287, running_loss=0.3560, LR=0.000100
[2025-08-11 15:50:41,526][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025440] [Batch 01095/04869] [00:09:37/00:33:10, 0.527s/it]: train_loss_raw=0.4184, running_loss=0.3580, LR=0.000100
[2025-08-11 15:50:47,699][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025452] [Batch 01107/04869] [00:09:43/00:33:03, 0.527s/it]: train_loss_raw=0.2968, running_loss=0.3547, LR=0.000100
[2025-08-11 15:50:54,102][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025464] [Batch 01119/04869] [00:09:49/00:32:57, 0.527s/it]: train_loss_raw=0.3423, running_loss=0.3522, LR=0.000100
[2025-08-11 15:51:00,253][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025476] [Batch 01131/04869] [00:09:56/00:32:50, 0.527s/it]: train_loss_raw=0.3606, running_loss=0.3525, LR=0.000100
[2025-08-11 15:51:06,413][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025488] [Batch 01143/04869] [00:10:02/00:32:43, 0.527s/it]: train_loss_raw=0.3734, running_loss=0.3530, LR=0.000100
[2025-08-11 15:51:12,523][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025500] [Batch 01155/04869] [00:10:08/00:32:36, 0.527s/it]: train_loss_raw=0.4605, running_loss=0.3556, LR=0.000100
[2025-08-11 15:51:18,661][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025512] [Batch 01167/04869] [00:10:14/00:32:29, 0.527s/it]: train_loss_raw=0.3555, running_loss=0.3517, LR=0.000100
[2025-08-11 15:51:24,762][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025524] [Batch 01179/04869] [00:10:20/00:32:22, 0.526s/it]: train_loss_raw=0.2639, running_loss=0.3546, LR=0.000100
[2025-08-11 15:51:30,967][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025536] [Batch 01191/04869] [00:10:26/00:32:15, 0.526s/it]: train_loss_raw=0.3938, running_loss=0.3564, LR=0.000100
[2025-08-11 15:51:37,162][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025548] [Batch 01203/04869] [00:10:33/00:32:09, 0.526s/it]: train_loss_raw=0.3660, running_loss=0.3560, LR=0.000100
[2025-08-11 15:51:43,587][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025560] [Batch 01215/04869] [00:10:39/00:32:03, 0.526s/it]: train_loss_raw=0.3457, running_loss=0.3584, LR=0.000100
[2025-08-11 15:51:49,973][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025572] [Batch 01227/04869] [00:10:45/00:31:57, 0.526s/it]: train_loss_raw=0.4450, running_loss=0.3581, LR=0.000100
[2025-08-11 15:51:56,402][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025584] [Batch 01239/04869] [00:10:52/00:31:51, 0.526s/it]: train_loss_raw=0.4068, running_loss=0.3575, LR=0.000100
[2025-08-11 15:52:02,849][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025596] [Batch 01251/04869] [00:10:58/00:31:45, 0.527s/it]: train_loss_raw=0.4633, running_loss=0.3569, LR=0.000100
[2025-08-11 15:52:09,315][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025608] [Batch 01263/04869] [00:11:05/00:31:39, 0.527s/it]: train_loss_raw=0.3776, running_loss=0.3568, LR=0.000100
[2025-08-11 15:52:15,806][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025620] [Batch 01275/04869] [00:11:11/00:31:33, 0.527s/it]: train_loss_raw=0.3737, running_loss=0.3540, LR=0.000100
[2025-08-11 15:52:22,183][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025632] [Batch 01287/04869] [00:11:18/00:31:27, 0.527s/it]: train_loss_raw=0.4234, running_loss=0.3553, LR=0.000100
[2025-08-11 15:52:28,454][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025644] [Batch 01299/04869] [00:11:24/00:31:20, 0.527s/it]: train_loss_raw=0.3904, running_loss=0.3560, LR=0.000100
[2025-08-11 15:52:34,870][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025656] [Batch 01311/04869] [00:11:30/00:31:14, 0.527s/it]: train_loss_raw=0.3537, running_loss=0.3565, LR=0.000100
[2025-08-11 15:52:41,357][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025668] [Batch 01323/04869] [00:11:37/00:31:08, 0.527s/it]: train_loss_raw=0.3853, running_loss=0.3593, LR=0.000100
[2025-08-11 15:52:47,675][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025680] [Batch 01335/04869] [00:11:43/00:31:02, 0.527s/it]: train_loss_raw=0.3902, running_loss=0.3578, LR=0.000100
[2025-08-11 15:52:54,044][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025692] [Batch 01347/04869] [00:11:49/00:30:56, 0.527s/it]: train_loss_raw=0.2476, running_loss=0.3574, LR=0.000100
[2025-08-11 15:53:00,291][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025704] [Batch 01359/04869] [00:11:56/00:30:49, 0.527s/it]: train_loss_raw=0.2480, running_loss=0.3571, LR=0.000100
[2025-08-11 15:53:06,671][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025716] [Batch 01371/04869] [00:12:02/00:30:43, 0.527s/it]: train_loss_raw=0.4037, running_loss=0.3556, LR=0.000100
[2025-08-11 15:53:13,002][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025728] [Batch 01383/04869] [00:12:08/00:30:37, 0.527s/it]: train_loss_raw=0.3095, running_loss=0.3576, LR=0.000100
[2025-08-11 15:53:19,146][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025740] [Batch 01395/04869] [00:12:15/00:30:30, 0.527s/it]: train_loss_raw=0.3129, running_loss=0.3552, LR=0.000100
[2025-08-11 15:53:25,300][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025752] [Batch 01407/04869] [00:12:21/00:30:23, 0.527s/it]: train_loss_raw=0.3209, running_loss=0.3574, LR=0.000100
[2025-08-11 15:53:31,445][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025764] [Batch 01419/04869] [00:12:27/00:30:17, 0.527s/it]: train_loss_raw=0.2946, running_loss=0.3550, LR=0.000100
[2025-08-11 15:53:37,661][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025776] [Batch 01431/04869] [00:12:33/00:30:10, 0.527s/it]: train_loss_raw=0.3404, running_loss=0.3559, LR=0.000100
[2025-08-11 15:53:43,774][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025788] [Batch 01443/04869] [00:12:39/00:30:03, 0.526s/it]: train_loss_raw=0.2730, running_loss=0.3551, LR=0.000100
[2025-08-11 15:53:49,913][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025800] [Batch 01455/04869] [00:12:45/00:29:56, 0.526s/it]: train_loss_raw=0.4296, running_loss=0.3586, LR=0.000100
[2025-08-11 15:53:56,079][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025812] [Batch 01467/04869] [00:12:51/00:29:50, 0.526s/it]: train_loss_raw=0.3426, running_loss=0.3578, LR=0.000100
[2025-08-11 15:54:02,221][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025824] [Batch 01479/04869] [00:12:58/00:29:43, 0.526s/it]: train_loss_raw=0.3686, running_loss=0.3598, LR=0.000100
[2025-08-11 15:54:08,388][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025836] [Batch 01491/04869] [00:13:04/00:29:36, 0.526s/it]: train_loss_raw=0.3497, running_loss=0.3590, LR=0.000100
[2025-08-11 15:54:14,552][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025848] [Batch 01503/04869] [00:13:10/00:29:30, 0.526s/it]: train_loss_raw=0.4444, running_loss=0.3582, LR=0.000100
[2025-08-11 15:54:20,665][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025860] [Batch 01515/04869] [00:13:16/00:29:23, 0.526s/it]: train_loss_raw=0.4130, running_loss=0.3581, LR=0.000100
[2025-08-11 15:54:26,805][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025872] [Batch 01527/04869] [00:13:22/00:29:16, 0.526s/it]: train_loss_raw=0.3375, running_loss=0.3576, LR=0.000100
[2025-08-11 15:54:32,954][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025884] [Batch 01539/04869] [00:13:28/00:29:10, 0.526s/it]: train_loss_raw=0.3703, running_loss=0.3575, LR=0.000100
[2025-08-11 15:54:39,109][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025896] [Batch 01551/04869] [00:13:35/00:29:03, 0.525s/it]: train_loss_raw=0.3819, running_loss=0.3559, LR=0.000100
[2025-08-11 15:54:45,477][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025908] [Batch 01563/04869] [00:13:41/00:28:57, 0.526s/it]: train_loss_raw=0.2961, running_loss=0.3526, LR=0.000100
[2025-08-11 15:54:51,576][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025920] [Batch 01575/04869] [00:13:47/00:28:50, 0.525s/it]: train_loss_raw=0.2388, running_loss=0.3549, LR=0.000100
[2025-08-11 15:54:57,776][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025932] [Batch 01587/04869] [00:13:53/00:28:44, 0.525s/it]: train_loss_raw=0.3562, running_loss=0.3553, LR=0.000100
[2025-08-11 15:55:04,052][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025944] [Batch 01599/04869] [00:13:59/00:28:37, 0.525s/it]: train_loss_raw=0.4044, running_loss=0.3557, LR=0.000100
[2025-08-11 15:55:10,225][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025956] [Batch 01611/04869] [00:14:06/00:28:31, 0.525s/it]: train_loss_raw=0.3178, running_loss=0.3555, LR=0.000100
[2025-08-11 15:55:16,385][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025968] [Batch 01623/04869] [00:14:12/00:28:24, 0.525s/it]: train_loss_raw=0.3972, running_loss=0.3539, LR=0.000100
[2025-08-11 15:55:22,644][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025980] [Batch 01635/04869] [00:14:18/00:28:18, 0.525s/it]: train_loss_raw=0.4048, running_loss=0.3564, LR=0.000100
[2025-08-11 15:55:29,026][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025992] [Batch 01647/04869] [00:14:24/00:28:12, 0.525s/it]: train_loss_raw=0.2380, running_loss=0.3559, LR=0.000100
[2025-08-11 15:55:39,669][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026004] [Batch 01659/04869] [00:14:35/00:28:14, 0.528s/it]: train_loss_raw=0.3661, running_loss=0.3523, LR=0.000100
[2025-08-11 15:55:45,828][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026016] [Batch 01671/04869] [00:14:41/00:28:07, 0.528s/it]: train_loss_raw=0.3500, running_loss=0.3529, LR=0.000100
[2025-08-11 15:55:52,004][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026028] [Batch 01683/04869] [00:14:47/00:28:00, 0.528s/it]: train_loss_raw=0.3636, running_loss=0.3524, LR=0.000100
[2025-08-11 15:55:58,244][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026040] [Batch 01695/04869] [00:14:54/00:27:54, 0.528s/it]: train_loss_raw=0.3346, running_loss=0.3541, LR=0.000100
[2025-08-11 15:56:04,327][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026052] [Batch 01707/04869] [00:15:00/00:27:47, 0.527s/it]: train_loss_raw=0.4383, running_loss=0.3538, LR=0.000100
[2025-08-11 15:56:10,526][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026064] [Batch 01719/04869] [00:15:06/00:27:40, 0.527s/it]: train_loss_raw=0.4462, running_loss=0.3555, LR=0.000100
[2025-08-11 15:56:17,013][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026076] [Batch 01731/04869] [00:15:12/00:27:34, 0.527s/it]: train_loss_raw=0.3029, running_loss=0.3549, LR=0.000100
[2025-08-11 15:56:23,316][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026088] [Batch 01743/04869] [00:15:19/00:27:28, 0.527s/it]: train_loss_raw=0.3981, running_loss=0.3559, LR=0.000100
[2025-08-11 15:56:29,672][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026100] [Batch 01755/04869] [00:15:25/00:27:22, 0.527s/it]: train_loss_raw=0.3386, running_loss=0.3538, LR=0.000100
[2025-08-11 15:56:36,026][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026112] [Batch 01767/04869] [00:15:31/00:27:16, 0.527s/it]: train_loss_raw=0.3782, running_loss=0.3523, LR=0.000100
[2025-08-11 15:56:42,413][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026124] [Batch 01779/04869] [00:15:38/00:27:09, 0.527s/it]: train_loss_raw=0.3266, running_loss=0.3513, LR=0.000100
[2025-08-11 15:56:48,738][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026136] [Batch 01791/04869] [00:15:44/00:27:03, 0.527s/it]: train_loss_raw=0.3825, running_loss=0.3528, LR=0.000100
[2025-08-11 15:56:55,079][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026148] [Batch 01803/04869] [00:15:50/00:26:57, 0.527s/it]: train_loss_raw=0.4227, running_loss=0.3555, LR=0.000100
[2025-08-11 15:57:01,356][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026160] [Batch 01815/04869] [00:15:57/00:26:50, 0.527s/it]: train_loss_raw=0.3396, running_loss=0.3550, LR=0.000100
[2025-08-11 15:57:07,810][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026172] [Batch 01827/04869] [00:16:03/00:26:44, 0.527s/it]: train_loss_raw=0.3499, running_loss=0.3549, LR=0.000100
[2025-08-11 15:57:14,293][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026184] [Batch 01839/04869] [00:16:10/00:26:38, 0.528s/it]: train_loss_raw=0.3981, running_loss=0.3559, LR=0.000100
[2025-08-11 15:57:20,638][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026196] [Batch 01851/04869] [00:16:16/00:26:32, 0.528s/it]: train_loss_raw=0.4411, running_loss=0.3543, LR=0.000100
[2025-08-11 15:57:27,094][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026208] [Batch 01863/04869] [00:16:22/00:26:26, 0.528s/it]: train_loss_raw=0.3921, running_loss=0.3549, LR=0.000100
[2025-08-11 15:57:33,542][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026220] [Batch 01875/04869] [00:16:29/00:26:19, 0.528s/it]: train_loss_raw=0.3337, running_loss=0.3560, LR=0.000100
[2025-08-11 15:57:39,874][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026232] [Batch 01887/04869] [00:16:35/00:26:13, 0.528s/it]: train_loss_raw=0.4281, running_loss=0.3567, LR=0.000100
[2025-08-11 15:57:46,370][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026244] [Batch 01899/04869] [00:16:42/00:26:07, 0.528s/it]: train_loss_raw=0.2598, running_loss=0.3576, LR=0.000100
[2025-08-11 15:57:52,834][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026256] [Batch 01911/04869] [00:16:48/00:26:01, 0.528s/it]: train_loss_raw=0.3887, running_loss=0.3599, LR=0.000100
[2025-08-11 15:57:59,128][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026268] [Batch 01923/04869] [00:16:55/00:25:54, 0.528s/it]: train_loss_raw=0.3517, running_loss=0.3579, LR=0.000100
[2025-08-11 15:58:05,401][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026280] [Batch 01935/04869] [00:17:01/00:25:48, 0.528s/it]: train_loss_raw=0.2882, running_loss=0.3588, LR=0.000100
[2025-08-11 15:58:11,855][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026292] [Batch 01947/04869] [00:17:07/00:25:42, 0.528s/it]: train_loss_raw=0.2972, running_loss=0.3555, LR=0.000100
[2025-08-11 15:58:18,262][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026304] [Batch 01959/04869] [00:17:14/00:25:36, 0.528s/it]: train_loss_raw=0.2903, running_loss=0.3527, LR=0.000100
[2025-08-11 15:58:24,581][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026316] [Batch 01971/04869] [00:17:20/00:25:29, 0.528s/it]: train_loss_raw=0.3608, running_loss=0.3528, LR=0.000100
[2025-08-11 15:58:31,004][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026328] [Batch 01983/04869] [00:17:26/00:25:23, 0.528s/it]: train_loss_raw=0.3834, running_loss=0.3538, LR=0.000100
[2025-08-11 15:58:37,419][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026340] [Batch 01995/04869] [00:17:33/00:25:17, 0.528s/it]: train_loss_raw=0.3587, running_loss=0.3568, LR=0.000100
[2025-08-11 15:58:43,766][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026352] [Batch 02007/04869] [00:17:39/00:25:11, 0.528s/it]: train_loss_raw=0.3262, running_loss=0.3556, LR=0.000100
[2025-08-11 15:58:50,209][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026364] [Batch 02019/04869] [00:17:46/00:25:04, 0.528s/it]: train_loss_raw=0.3439, running_loss=0.3564, LR=0.000100
[2025-08-11 15:58:56,567][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026376] [Batch 02031/04869] [00:17:52/00:24:58, 0.528s/it]: train_loss_raw=0.4076, running_loss=0.3569, LR=0.000100
[2025-08-11 15:59:02,762][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026388] [Batch 02043/04869] [00:17:58/00:24:52, 0.528s/it]: train_loss_raw=0.3162, running_loss=0.3544, LR=0.000100
[2025-08-11 15:59:09,149][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026400] [Batch 02055/04869] [00:18:05/00:24:45, 0.528s/it]: train_loss_raw=0.3975, running_loss=0.3523, LR=0.000100
[2025-08-11 15:59:15,662][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026412] [Batch 02067/04869] [00:18:11/00:24:39, 0.528s/it]: train_loss_raw=0.3120, running_loss=0.3531, LR=0.000100
[2025-08-11 15:59:22,224][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026424] [Batch 02079/04869] [00:18:18/00:24:33, 0.528s/it]: train_loss_raw=0.4040, running_loss=0.3547, LR=0.000100
[2025-08-11 15:59:28,358][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026436] [Batch 02091/04869] [00:18:24/00:24:27, 0.528s/it]: train_loss_raw=0.3183, running_loss=0.3566, LR=0.000100
[2025-08-11 15:59:34,456][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026448] [Batch 02103/04869] [00:18:30/00:24:20, 0.528s/it]: train_loss_raw=0.3670, running_loss=0.3560, LR=0.000100
[2025-08-11 15:59:40,601][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026460] [Batch 02115/04869] [00:18:36/00:24:13, 0.528s/it]: train_loss_raw=0.3985, running_loss=0.3553, LR=0.000100
[2025-08-11 15:59:47,036][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026472] [Batch 02127/04869] [00:18:42/00:24:07, 0.528s/it]: train_loss_raw=0.3417, running_loss=0.3556, LR=0.000100
[2025-08-11 15:59:53,492][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026484] [Batch 02139/04869] [00:18:49/00:24:01, 0.528s/it]: train_loss_raw=0.3232, running_loss=0.3549, LR=0.000100
[2025-08-11 15:59:59,918][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026496] [Batch 02151/04869] [00:18:55/00:23:55, 0.528s/it]: train_loss_raw=0.3860, running_loss=0.3535, LR=0.000100
[2025-08-11 16:00:06,205][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026508] [Batch 02163/04869] [00:19:02/00:23:48, 0.528s/it]: train_loss_raw=0.3414, running_loss=0.3551, LR=0.000100
[2025-08-11 16:00:12,494][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026520] [Batch 02175/04869] [00:19:08/00:23:42, 0.528s/it]: train_loss_raw=0.2407, running_loss=0.3523, LR=0.000100
[2025-08-11 16:00:18,833][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026532] [Batch 02187/04869] [00:19:14/00:23:36, 0.528s/it]: train_loss_raw=0.3271, running_loss=0.3528, LR=0.000100
[2025-08-11 16:00:25,275][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026544] [Batch 02199/04869] [00:19:21/00:23:29, 0.528s/it]: train_loss_raw=0.3821, running_loss=0.3542, LR=0.000100
[2025-08-11 16:00:31,681][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026556] [Batch 02211/04869] [00:19:27/00:23:23, 0.528s/it]: train_loss_raw=0.3666, running_loss=0.3543, LR=0.000100
[2025-08-11 16:00:38,071][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026568] [Batch 02223/04869] [00:19:33/00:23:17, 0.528s/it]: train_loss_raw=0.3674, running_loss=0.3532, LR=0.000100
[2025-08-11 16:00:44,565][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026580] [Batch 02235/04869] [00:19:40/00:23:11, 0.528s/it]: train_loss_raw=0.3420, running_loss=0.3541, LR=0.000100
[2025-08-11 16:00:50,945][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026592] [Batch 02247/04869] [00:19:46/00:23:04, 0.528s/it]: train_loss_raw=0.3998, running_loss=0.3584, LR=0.000100
[2025-08-11 16:00:57,317][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026604] [Batch 02259/04869] [00:19:53/00:22:58, 0.528s/it]: train_loss_raw=0.3611, running_loss=0.3602, LR=0.000100
[2025-08-11 16:01:03,620][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026616] [Batch 02271/04869] [00:19:59/00:22:52, 0.528s/it]: train_loss_raw=0.4398, running_loss=0.3598, LR=0.000100
[2025-08-11 16:01:09,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026628] [Batch 02283/04869] [00:20:05/00:22:45, 0.528s/it]: train_loss_raw=0.3068, running_loss=0.3590, LR=0.000100
[2025-08-11 16:01:15,882][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026640] [Batch 02295/04869] [00:20:11/00:22:39, 0.528s/it]: train_loss_raw=0.3347, running_loss=0.3605, LR=0.000100
[2025-08-11 16:01:22,379][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026652] [Batch 02307/04869] [00:20:18/00:22:32, 0.528s/it]: train_loss_raw=0.2924, running_loss=0.3616, LR=0.000100
[2025-08-11 16:01:28,521][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026664] [Batch 02319/04869] [00:20:24/00:22:26, 0.528s/it]: train_loss_raw=0.3168, running_loss=0.3601, LR=0.000100
[2025-08-11 16:01:34,768][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026676] [Batch 02331/04869] [00:20:30/00:22:19, 0.528s/it]: train_loss_raw=0.3631, running_loss=0.3589, LR=0.000100
[2025-08-11 16:01:41,014][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026688] [Batch 02343/04869] [00:20:36/00:22:13, 0.528s/it]: train_loss_raw=0.4293, running_loss=0.3622, LR=0.000100
[2025-08-11 16:01:47,339][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026700] [Batch 02355/04869] [00:20:43/00:22:07, 0.528s/it]: train_loss_raw=0.3743, running_loss=0.3614, LR=0.000100
[2025-08-11 16:01:53,556][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026712] [Batch 02367/04869] [00:20:49/00:22:00, 0.528s/it]: train_loss_raw=0.3427, running_loss=0.3598, LR=0.000100
[2025-08-11 16:01:59,734][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026724] [Batch 02379/04869] [00:20:55/00:21:54, 0.528s/it]: train_loss_raw=0.3891, running_loss=0.3603, LR=0.000100
[2025-08-11 16:02:05,884][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026736] [Batch 02391/04869] [00:21:01/00:21:47, 0.528s/it]: train_loss_raw=0.4240, running_loss=0.3607, LR=0.000100
[2025-08-11 16:02:11,984][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026748] [Batch 02403/04869] [00:21:07/00:21:41, 0.528s/it]: train_loss_raw=0.3161, running_loss=0.3560, LR=0.000100
[2025-08-11 16:02:18,096][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026760] [Batch 02415/04869] [00:21:13/00:21:34, 0.528s/it]: train_loss_raw=0.3651, running_loss=0.3562, LR=0.000100
[2025-08-11 16:02:24,261][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026772] [Batch 02427/04869] [00:21:20/00:21:28, 0.527s/it]: train_loss_raw=0.2811, running_loss=0.3560, LR=0.000100
[2025-08-11 16:02:30,420][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026784] [Batch 02439/04869] [00:21:26/00:21:21, 0.527s/it]: train_loss_raw=0.3604, running_loss=0.3567, LR=0.000100
[2025-08-11 16:02:36,515][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026796] [Batch 02451/04869] [00:21:32/00:21:15, 0.527s/it]: train_loss_raw=0.3224, running_loss=0.3588, LR=0.000100
[2025-08-11 16:02:42,839][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026808] [Batch 02463/04869] [00:21:38/00:21:08, 0.527s/it]: train_loss_raw=0.4481, running_loss=0.3628, LR=0.000100
[2025-08-11 16:02:49,199][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026820] [Batch 02475/04869] [00:21:45/00:21:02, 0.527s/it]: train_loss_raw=0.4737, running_loss=0.3636, LR=0.000100
[2025-08-11 16:02:55,552][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026832] [Batch 02487/04869] [00:21:51/00:20:56, 0.527s/it]: train_loss_raw=0.3386, running_loss=0.3622, LR=0.000100
[2025-08-11 16:03:01,887][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026844] [Batch 02499/04869] [00:21:57/00:20:49, 0.527s/it]: train_loss_raw=0.3674, running_loss=0.3585, LR=0.000100
[2025-08-11 16:03:08,244][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026856] [Batch 02511/04869] [00:22:04/00:20:43, 0.527s/it]: train_loss_raw=0.2839, running_loss=0.3549, LR=0.000100
[2025-08-11 16:03:14,692][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026868] [Batch 02523/04869] [00:22:10/00:20:37, 0.527s/it]: train_loss_raw=0.3481, running_loss=0.3533, LR=0.000100
[2025-08-11 16:03:21,139][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026880] [Batch 02535/04869] [00:22:17/00:20:31, 0.527s/it]: train_loss_raw=0.4089, running_loss=0.3536, LR=0.000100
[2025-08-11 16:03:27,610][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026892] [Batch 02547/04869] [00:22:23/00:20:24, 0.527s/it]: train_loss_raw=0.4341, running_loss=0.3544, LR=0.000100
[2025-08-11 16:03:34,069][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026904] [Batch 02559/04869] [00:22:29/00:20:18, 0.528s/it]: train_loss_raw=0.3621, running_loss=0.3550, LR=0.000100
[2025-08-11 16:03:40,535][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026916] [Batch 02571/04869] [00:22:36/00:20:12, 0.528s/it]: train_loss_raw=0.3152, running_loss=0.3541, LR=0.000100
[2025-08-11 16:03:46,849][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026928] [Batch 02583/04869] [00:22:42/00:20:06, 0.528s/it]: train_loss_raw=0.3015, running_loss=0.3520, LR=0.000100
[2025-08-11 16:03:53,181][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026940] [Batch 02595/04869] [00:22:49/00:19:59, 0.528s/it]: train_loss_raw=0.3934, running_loss=0.3515, LR=0.000100
[2025-08-11 16:03:59,493][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026952] [Batch 02607/04869] [00:22:55/00:19:53, 0.528s/it]: train_loss_raw=0.3382, running_loss=0.3524, LR=0.000100
[2025-08-11 16:04:05,888][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026964] [Batch 02619/04869] [00:23:01/00:19:47, 0.528s/it]: train_loss_raw=0.3054, running_loss=0.3534, LR=0.000100
[2025-08-11 16:04:12,227][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026976] [Batch 02631/04869] [00:23:08/00:19:40, 0.528s/it]: train_loss_raw=0.3696, running_loss=0.3564, LR=0.000100
[2025-08-11 16:04:18,565][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026988] [Batch 02643/04869] [00:23:14/00:19:34, 0.528s/it]: train_loss_raw=0.2451, running_loss=0.3523, LR=0.000100
[2025-08-11 16:04:24,966][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027000] [Batch 02655/04869] [00:23:20/00:19:28, 0.528s/it]: train_loss_raw=0.3746, running_loss=0.3503, LR=0.000100
[2025-08-11 16:04:31,401][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027012] [Batch 02667/04869] [00:23:27/00:19:21, 0.528s/it]: train_loss_raw=0.3730, running_loss=0.3506, LR=0.000100
[2025-08-11 16:04:37,676][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027024] [Batch 02679/04869] [00:23:33/00:19:15, 0.528s/it]: train_loss_raw=0.3036, running_loss=0.3517, LR=0.000100
[2025-08-11 16:04:44,005][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027036] [Batch 02691/04869] [00:23:39/00:19:09, 0.528s/it]: train_loss_raw=0.3087, running_loss=0.3537, LR=0.000100
[2025-08-11 16:04:50,303][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027048] [Batch 02703/04869] [00:23:46/00:19:02, 0.528s/it]: train_loss_raw=0.3379, running_loss=0.3547, LR=0.000100
[2025-08-11 16:04:56,585][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027060] [Batch 02715/04869] [00:23:52/00:18:56, 0.528s/it]: train_loss_raw=0.4012, running_loss=0.3574, LR=0.000100
[2025-08-11 16:05:02,904][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027072] [Batch 02727/04869] [00:23:58/00:18:50, 0.528s/it]: train_loss_raw=0.3567, running_loss=0.3602, LR=0.000100
[2025-08-11 16:05:09,234][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027084] [Batch 02739/04869] [00:24:05/00:18:43, 0.528s/it]: train_loss_raw=0.2615, running_loss=0.3593, LR=0.000100
[2025-08-11 16:05:15,655][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027096] [Batch 02751/04869] [00:24:11/00:18:37, 0.528s/it]: train_loss_raw=0.3243, running_loss=0.3590, LR=0.000100
[2025-08-11 16:05:22,217][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027108] [Batch 02763/04869] [00:24:18/00:18:31, 0.528s/it]: train_loss_raw=0.3844, running_loss=0.3612, LR=0.000100
[2025-08-11 16:05:28,804][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027120] [Batch 02775/04869] [00:24:24/00:18:25, 0.528s/it]: train_loss_raw=0.3111, running_loss=0.3631, LR=0.000100
[2025-08-11 16:05:35,158][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027132] [Batch 02787/04869] [00:24:31/00:18:18, 0.528s/it]: train_loss_raw=0.4318, running_loss=0.3653, LR=0.000100
[2025-08-11 16:05:41,477][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027144] [Batch 02799/04869] [00:24:37/00:18:12, 0.528s/it]: train_loss_raw=0.3146, running_loss=0.3613, LR=0.000100
[2025-08-11 16:05:47,775][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027156] [Batch 02811/04869] [00:24:43/00:18:06, 0.528s/it]: train_loss_raw=0.3308, running_loss=0.3623, LR=0.000100
[2025-08-11 16:05:54,138][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027168] [Batch 02823/04869] [00:24:50/00:17:59, 0.528s/it]: train_loss_raw=0.3272, running_loss=0.3648, LR=0.000100
[2025-08-11 16:06:00,353][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027180] [Batch 02835/04869] [00:24:56/00:17:53, 0.528s/it]: train_loss_raw=0.3670, running_loss=0.3650, LR=0.000100
[2025-08-11 16:06:06,430][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027192] [Batch 02847/04869] [00:25:02/00:17:46, 0.528s/it]: train_loss_raw=0.3752, running_loss=0.3642, LR=0.000100
[2025-08-11 16:06:12,738][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027204] [Batch 02859/04869] [00:25:08/00:17:40, 0.528s/it]: train_loss_raw=0.2867, running_loss=0.3649, LR=0.000100
[2025-08-11 16:06:19,126][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027216] [Batch 02871/04869] [00:25:15/00:17:34, 0.528s/it]: train_loss_raw=0.4078, running_loss=0.3625, LR=0.000100
[2025-08-11 16:06:25,382][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027228] [Batch 02883/04869] [00:25:21/00:17:27, 0.528s/it]: train_loss_raw=0.3774, running_loss=0.3610, LR=0.000100
[2025-08-11 16:06:31,560][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027240] [Batch 02895/04869] [00:25:27/00:17:21, 0.528s/it]: train_loss_raw=0.3933, running_loss=0.3613, LR=0.000100
[2025-08-11 16:06:37,702][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027252] [Batch 02907/04869] [00:25:33/00:17:15, 0.528s/it]: train_loss_raw=0.3214, running_loss=0.3606, LR=0.000100
[2025-08-11 16:06:43,820][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027264] [Batch 02919/04869] [00:25:39/00:17:08, 0.527s/it]: train_loss_raw=0.4066, running_loss=0.3621, LR=0.000100
[2025-08-11 16:06:50,122][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027276] [Batch 02931/04869] [00:25:46/00:17:02, 0.527s/it]: train_loss_raw=0.3955, running_loss=0.3616, LR=0.000100
[2025-08-11 16:06:56,582][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027288] [Batch 02943/04869] [00:25:52/00:16:55, 0.528s/it]: train_loss_raw=0.3705, running_loss=0.3617, LR=0.000100
[2025-08-11 16:07:02,762][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027300] [Batch 02955/04869] [00:25:58/00:16:49, 0.527s/it]: train_loss_raw=0.2934, running_loss=0.3601, LR=0.000100
[2025-08-11 16:07:08,917][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027312] [Batch 02967/04869] [00:26:04/00:16:43, 0.527s/it]: train_loss_raw=0.4375, running_loss=0.3614, LR=0.000100
[2025-08-11 16:07:15,081][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027324] [Batch 02979/04869] [00:26:10/00:16:36, 0.527s/it]: train_loss_raw=0.3966, running_loss=0.3579, LR=0.000100
[2025-08-11 16:07:21,253][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027336] [Batch 02991/04869] [00:26:17/00:16:30, 0.527s/it]: train_loss_raw=0.2898, running_loss=0.3549, LR=0.000100
[2025-08-11 16:07:27,327][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027348] [Batch 03003/04869] [00:26:23/00:16:23, 0.527s/it]: train_loss_raw=0.3143, running_loss=0.3541, LR=0.000100
[2025-08-11 16:07:33,470][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027360] [Batch 03015/04869] [00:26:29/00:16:17, 0.527s/it]: train_loss_raw=0.3130, running_loss=0.3535, LR=0.000100
[2025-08-11 16:07:39,651][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027372] [Batch 03027/04869] [00:26:35/00:16:10, 0.527s/it]: train_loss_raw=0.3636, running_loss=0.3535, LR=0.000100
[2025-08-11 16:07:46,026][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027384] [Batch 03039/04869] [00:26:41/00:16:04, 0.527s/it]: train_loss_raw=0.4196, running_loss=0.3564, LR=0.000100
[2025-08-11 16:07:52,345][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027396] [Batch 03051/04869] [00:26:48/00:15:58, 0.527s/it]: train_loss_raw=0.3729, running_loss=0.3570, LR=0.000100
[2025-08-11 16:07:58,625][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027408] [Batch 03063/04869] [00:26:54/00:15:51, 0.527s/it]: train_loss_raw=0.3811, running_loss=0.3557, LR=0.000100
[2025-08-11 16:08:04,972][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027420] [Batch 03075/04869] [00:27:00/00:15:45, 0.527s/it]: train_loss_raw=0.2867, running_loss=0.3547, LR=0.000100
[2025-08-11 16:08:11,345][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027432] [Batch 03087/04869] [00:27:07/00:15:39, 0.527s/it]: train_loss_raw=0.3586, running_loss=0.3524, LR=0.000100
[2025-08-11 16:08:17,818][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027444] [Batch 03099/04869] [00:27:13/00:15:33, 0.527s/it]: train_loss_raw=0.3894, running_loss=0.3490, LR=0.000100
[2025-08-11 16:08:24,168][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027456] [Batch 03111/04869] [00:27:20/00:15:26, 0.527s/it]: train_loss_raw=0.3615, running_loss=0.3480, LR=0.000100
[2025-08-11 16:08:30,529][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027468] [Batch 03123/04869] [00:27:26/00:15:20, 0.527s/it]: train_loss_raw=0.3229, running_loss=0.3480, LR=0.000100
[2025-08-11 16:08:36,881][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027480] [Batch 03135/04869] [00:27:32/00:15:14, 0.527s/it]: train_loss_raw=0.3439, running_loss=0.3490, LR=0.000100
[2025-08-11 16:08:43,201][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027492] [Batch 03147/04869] [00:27:39/00:15:07, 0.527s/it]: train_loss_raw=0.5232, running_loss=0.3521, LR=0.000100
[2025-08-11 16:08:49,547][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027504] [Batch 03159/04869] [00:27:45/00:15:01, 0.527s/it]: train_loss_raw=0.4264, running_loss=0.3523, LR=0.000100
[2025-08-11 16:08:55,805][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027516] [Batch 03171/04869] [00:27:51/00:14:55, 0.527s/it]: train_loss_raw=0.3821, running_loss=0.3542, LR=0.000100
[2025-08-11 16:09:02,127][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027528] [Batch 03183/04869] [00:27:58/00:14:48, 0.527s/it]: train_loss_raw=0.3508, running_loss=0.3536, LR=0.000100
[2025-08-11 16:09:08,530][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027540] [Batch 03195/04869] [00:28:04/00:14:42, 0.527s/it]: train_loss_raw=0.4690, running_loss=0.3558, LR=0.000100
[2025-08-11 16:09:14,817][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027552] [Batch 03207/04869] [00:28:10/00:14:36, 0.527s/it]: train_loss_raw=0.3662, running_loss=0.3537, LR=0.000100
[2025-08-11 16:09:21,082][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027564] [Batch 03219/04869] [00:28:16/00:14:29, 0.527s/it]: train_loss_raw=0.2972, running_loss=0.3521, LR=0.000100
[2025-08-11 16:09:27,386][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027576] [Batch 03231/04869] [00:28:23/00:14:23, 0.527s/it]: train_loss_raw=0.4087, running_loss=0.3512, LR=0.000100
[2025-08-11 16:09:33,750][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027588] [Batch 03243/04869] [00:28:29/00:14:17, 0.527s/it]: train_loss_raw=0.2845, running_loss=0.3504, LR=0.000100
[2025-08-11 16:09:40,249][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027600] [Batch 03255/04869] [00:28:36/00:14:10, 0.527s/it]: train_loss_raw=0.3210, running_loss=0.3514, LR=0.000100
[2025-08-11 16:09:46,689][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027612] [Batch 03267/04869] [00:28:42/00:14:04, 0.527s/it]: train_loss_raw=0.3576, running_loss=0.3529, LR=0.000100
[2025-08-11 16:09:52,981][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027624] [Batch 03279/04869] [00:28:48/00:13:58, 0.527s/it]: train_loss_raw=0.3906, running_loss=0.3550, LR=0.000100
[2025-08-11 16:09:59,333][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027636] [Batch 03291/04869] [00:28:55/00:13:52, 0.527s/it]: train_loss_raw=0.3879, running_loss=0.3595, LR=0.000100
[2025-08-11 16:10:05,585][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027648] [Batch 03303/04869] [00:29:01/00:13:45, 0.527s/it]: train_loss_raw=0.3685, running_loss=0.3584, LR=0.000100
[2025-08-11 16:10:11,986][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027660] [Batch 03315/04869] [00:29:07/00:13:39, 0.527s/it]: train_loss_raw=0.3353, running_loss=0.3584, LR=0.000100
[2025-08-11 16:10:18,415][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027672] [Batch 03327/04869] [00:29:14/00:13:33, 0.527s/it]: train_loss_raw=0.4189, running_loss=0.3594, LR=0.000100
[2025-08-11 16:10:24,853][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027684] [Batch 03339/04869] [00:29:20/00:13:26, 0.527s/it]: train_loss_raw=0.3517, running_loss=0.3587, LR=0.000100
[2025-08-11 16:10:31,143][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027696] [Batch 03351/04869] [00:29:27/00:13:20, 0.527s/it]: train_loss_raw=0.3611, running_loss=0.3592, LR=0.000100
[2025-08-11 16:10:37,512][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027708] [Batch 03363/04869] [00:29:33/00:13:14, 0.527s/it]: train_loss_raw=0.3265, running_loss=0.3562, LR=0.000100
[2025-08-11 16:10:44,067][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027720] [Batch 03375/04869] [00:29:39/00:13:07, 0.527s/it]: train_loss_raw=0.4182, running_loss=0.3561, LR=0.000100
[2025-08-11 16:10:50,432][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027732] [Batch 03387/04869] [00:29:46/00:13:01, 0.527s/it]: train_loss_raw=0.3263, running_loss=0.3550, LR=0.000100
[2025-08-11 16:10:56,855][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027744] [Batch 03399/04869] [00:29:52/00:12:55, 0.527s/it]: train_loss_raw=0.4031, running_loss=0.3531, LR=0.000100
[2025-08-11 16:11:03,335][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027756] [Batch 03411/04869] [00:29:59/00:12:49, 0.527s/it]: train_loss_raw=0.4015, running_loss=0.3524, LR=0.000100
[2025-08-11 16:11:09,637][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027768] [Batch 03423/04869] [00:30:05/00:12:42, 0.527s/it]: train_loss_raw=0.4115, running_loss=0.3528, LR=0.000100
[2025-08-11 16:11:15,979][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027780] [Batch 03435/04869] [00:30:11/00:12:36, 0.527s/it]: train_loss_raw=0.4766, running_loss=0.3557, LR=0.000100
[2025-08-11 16:11:22,281][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027792] [Batch 03447/04869] [00:30:18/00:12:30, 0.527s/it]: train_loss_raw=0.3487, running_loss=0.3584, LR=0.000100
[2025-08-11 16:11:28,764][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027804] [Batch 03459/04869] [00:30:24/00:12:23, 0.528s/it]: train_loss_raw=0.3435, running_loss=0.3592, LR=0.000100
[2025-08-11 16:11:35,064][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027816] [Batch 03471/04869] [00:30:30/00:12:17, 0.528s/it]: train_loss_raw=0.3723, running_loss=0.3593, LR=0.000100
[2025-08-11 16:11:41,351][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027828] [Batch 03483/04869] [00:30:37/00:12:11, 0.527s/it]: train_loss_raw=0.3588, running_loss=0.3587, LR=0.000100
[2025-08-11 16:11:47,668][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027840] [Batch 03495/04869] [00:30:43/00:12:04, 0.527s/it]: train_loss_raw=0.3707, running_loss=0.3615, LR=0.000100
[2025-08-11 16:11:53,990][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027852] [Batch 03507/04869] [00:30:49/00:11:58, 0.527s/it]: train_loss_raw=0.3665, running_loss=0.3617, LR=0.000100
[2025-08-11 16:12:00,285][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027864] [Batch 03519/04869] [00:30:56/00:11:52, 0.527s/it]: train_loss_raw=0.3768, running_loss=0.3610, LR=0.000100
[2025-08-11 16:12:06,678][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027876] [Batch 03531/04869] [00:31:02/00:11:45, 0.527s/it]: train_loss_raw=0.3777, running_loss=0.3635, LR=0.000100
[2025-08-11 16:12:12,936][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027888] [Batch 03543/04869] [00:31:08/00:11:39, 0.527s/it]: train_loss_raw=0.3546, running_loss=0.3605, LR=0.000100
[2025-08-11 16:12:19,131][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027900] [Batch 03555/04869] [00:31:15/00:11:33, 0.527s/it]: train_loss_raw=0.4087, running_loss=0.3601, LR=0.000100
[2025-08-11 16:12:25,259][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027912] [Batch 03567/04869] [00:31:21/00:11:26, 0.527s/it]: train_loss_raw=0.3372, running_loss=0.3594, LR=0.000100
[2025-08-11 16:12:31,423][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027924] [Batch 03579/04869] [00:31:27/00:11:20, 0.527s/it]: train_loss_raw=0.3548, running_loss=0.3613, LR=0.000100
[2025-08-11 16:12:37,565][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027936] [Batch 03591/04869] [00:31:33/00:11:13, 0.527s/it]: train_loss_raw=0.3745, running_loss=0.3632, LR=0.000100
[2025-08-11 16:12:43,717][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027948] [Batch 03603/04869] [00:31:39/00:11:07, 0.527s/it]: train_loss_raw=0.4082, running_loss=0.3622, LR=0.000100
[2025-08-11 16:12:49,874][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027960] [Batch 03615/04869] [00:31:45/00:11:01, 0.527s/it]: train_loss_raw=0.2922, running_loss=0.3612, LR=0.000100
[2025-08-11 16:12:56,046][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027972] [Batch 03627/04869] [00:31:51/00:10:54, 0.527s/it]: train_loss_raw=0.3173, running_loss=0.3585, LR=0.000100
[2025-08-11 16:13:02,232][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027984] [Batch 03639/04869] [00:31:58/00:10:48, 0.527s/it]: train_loss_raw=0.3217, running_loss=0.3612, LR=0.000100
[2025-08-11 16:13:08,394][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027996] [Batch 03651/04869] [00:32:04/00:10:41, 0.527s/it]: train_loss_raw=0.3258, running_loss=0.3617, LR=0.000100
[2025-08-11 16:13:19,325][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028008] [Batch 03663/04869] [00:32:15/00:10:37, 0.528s/it]: train_loss_raw=0.2867, running_loss=0.3599, LR=0.000100
[2025-08-11 16:13:25,479][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028020] [Batch 03675/04869] [00:32:21/00:10:30, 0.528s/it]: train_loss_raw=0.3361, running_loss=0.3589, LR=0.000100
[2025-08-11 16:13:31,625][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028032] [Batch 03687/04869] [00:32:27/00:10:24, 0.528s/it]: train_loss_raw=0.3845, running_loss=0.3611, LR=0.000100
[2025-08-11 16:13:37,838][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028044] [Batch 03699/04869] [00:32:33/00:10:17, 0.528s/it]: train_loss_raw=0.3355, running_loss=0.3618, LR=0.000100
[2025-08-11 16:13:44,041][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028056] [Batch 03711/04869] [00:32:39/00:10:11, 0.528s/it]: train_loss_raw=0.3562, running_loss=0.3620, LR=0.000100
[2025-08-11 16:13:50,449][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028068] [Batch 03723/04869] [00:32:46/00:10:05, 0.528s/it]: train_loss_raw=0.3619, running_loss=0.3611, LR=0.000100
[2025-08-11 16:13:56,988][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028080] [Batch 03735/04869] [00:32:52/00:09:58, 0.528s/it]: train_loss_raw=0.3032, running_loss=0.3606, LR=0.000100
[2025-08-11 16:14:03,361][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028092] [Batch 03747/04869] [00:32:59/00:09:52, 0.528s/it]: train_loss_raw=0.3169, running_loss=0.3591, LR=0.000100
[2025-08-11 16:14:09,742][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028104] [Batch 03759/04869] [00:33:05/00:09:46, 0.528s/it]: train_loss_raw=0.3446, running_loss=0.3582, LR=0.000100
[2025-08-11 16:14:16,244][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028116] [Batch 03771/04869] [00:33:12/00:09:40, 0.528s/it]: train_loss_raw=0.3625, running_loss=0.3599, LR=0.000100
[2025-08-11 16:14:22,648][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028128] [Batch 03783/04869] [00:33:18/00:09:33, 0.528s/it]: train_loss_raw=0.2289, running_loss=0.3565, LR=0.000100
[2025-08-11 16:14:29,104][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028140] [Batch 03795/04869] [00:33:24/00:09:27, 0.528s/it]: train_loss_raw=0.2180, running_loss=0.3548, LR=0.000100
[2025-08-11 16:14:35,572][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028152] [Batch 03807/04869] [00:33:31/00:09:21, 0.528s/it]: train_loss_raw=0.3756, running_loss=0.3558, LR=0.000100
[2025-08-11 16:14:41,862][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028164] [Batch 03819/04869] [00:33:37/00:09:14, 0.528s/it]: train_loss_raw=0.4888, running_loss=0.3585, LR=0.000100
[2025-08-11 16:14:48,193][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028176] [Batch 03831/04869] [00:33:44/00:09:08, 0.528s/it]: train_loss_raw=0.3374, running_loss=0.3571, LR=0.000100
[2025-08-11 16:14:54,697][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028188] [Batch 03843/04869] [00:33:50/00:09:02, 0.528s/it]: train_loss_raw=0.3058, running_loss=0.3551, LR=0.000100
[2025-08-11 16:15:01,109][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028200] [Batch 03855/04869] [00:33:57/00:08:55, 0.528s/it]: train_loss_raw=0.2909, running_loss=0.3521, LR=0.000100
[2025-08-11 16:15:07,469][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028212] [Batch 03867/04869] [00:34:03/00:08:49, 0.528s/it]: train_loss_raw=0.3092, running_loss=0.3508, LR=0.000100
[2025-08-11 16:15:13,784][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028224] [Batch 03879/04869] [00:34:09/00:08:43, 0.528s/it]: train_loss_raw=0.3502, running_loss=0.3525, LR=0.000100
[2025-08-11 16:15:20,243][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028236] [Batch 03891/04869] [00:34:16/00:08:36, 0.528s/it]: train_loss_raw=0.3950, running_loss=0.3533, LR=0.000100
[2025-08-11 16:15:26,557][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028248] [Batch 03903/04869] [00:34:22/00:08:30, 0.528s/it]: train_loss_raw=0.3342, running_loss=0.3557, LR=0.000100
[2025-08-11 16:15:32,892][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028260] [Batch 03915/04869] [00:34:28/00:08:24, 0.528s/it]: train_loss_raw=0.4039, running_loss=0.3535, LR=0.000100
[2025-08-11 16:15:39,259][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028272] [Batch 03927/04869] [00:34:35/00:08:17, 0.528s/it]: train_loss_raw=0.3166, running_loss=0.3543, LR=0.000100
[2025-08-11 16:15:45,637][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028284] [Batch 03939/04869] [00:34:41/00:08:11, 0.528s/it]: train_loss_raw=0.3317, running_loss=0.3497, LR=0.000100
[2025-08-11 16:15:52,028][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028296] [Batch 03951/04869] [00:34:47/00:08:05, 0.528s/it]: train_loss_raw=0.3319, running_loss=0.3485, LR=0.000100
[2025-08-11 16:15:58,378][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028308] [Batch 03963/04869] [00:34:54/00:07:58, 0.528s/it]: train_loss_raw=0.3924, running_loss=0.3482, LR=0.000100
[2025-08-11 16:16:04,835][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028320] [Batch 03975/04869] [00:35:00/00:07:52, 0.528s/it]: train_loss_raw=0.3175, running_loss=0.3498, LR=0.000100
[2025-08-11 16:16:11,166][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028332] [Batch 03987/04869] [00:35:07/00:07:46, 0.528s/it]: train_loss_raw=0.3668, running_loss=0.3473, LR=0.000100
[2025-08-11 16:16:17,459][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028344] [Batch 03999/04869] [00:35:13/00:07:39, 0.528s/it]: train_loss_raw=0.3330, running_loss=0.3483, LR=0.000100
[2025-08-11 16:16:23,857][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028356] [Batch 04011/04869] [00:35:19/00:07:33, 0.528s/it]: train_loss_raw=0.3290, running_loss=0.3471, LR=0.000100
[2025-08-11 16:16:30,276][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028368] [Batch 04023/04869] [00:35:26/00:07:27, 0.529s/it]: train_loss_raw=0.3339, running_loss=0.3488, LR=0.000100
[2025-08-11 16:16:36,642][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028380] [Batch 04035/04869] [00:35:32/00:07:20, 0.529s/it]: train_loss_raw=0.3569, running_loss=0.3479, LR=0.000100
[2025-08-11 16:16:43,093][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028392] [Batch 04047/04869] [00:35:38/00:07:14, 0.529s/it]: train_loss_raw=0.3254, running_loss=0.3469, LR=0.000100
[2025-08-11 16:16:49,414][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028404] [Batch 04059/04869] [00:35:45/00:07:08, 0.529s/it]: train_loss_raw=0.3786, running_loss=0.3503, LR=0.000100
[2025-08-11 16:16:55,763][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028416] [Batch 04071/04869] [00:35:51/00:07:01, 0.529s/it]: train_loss_raw=0.3348, running_loss=0.3500, LR=0.000100
[2025-08-11 16:17:02,184][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028428] [Batch 04083/04869] [00:35:58/00:06:55, 0.529s/it]: train_loss_raw=0.3246, running_loss=0.3496, LR=0.000100
[2025-08-11 16:17:08,558][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028440] [Batch 04095/04869] [00:36:04/00:06:49, 0.529s/it]: train_loss_raw=0.3364, running_loss=0.3525, LR=0.000100
[2025-08-11 16:17:15,021][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028452] [Batch 04107/04869] [00:36:10/00:06:42, 0.529s/it]: train_loss_raw=0.3423, running_loss=0.3533, LR=0.000100
[2025-08-11 16:17:21,368][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028464] [Batch 04119/04869] [00:36:17/00:06:36, 0.529s/it]: train_loss_raw=0.3084, running_loss=0.3540, LR=0.000100
[2025-08-11 16:17:27,831][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028476] [Batch 04131/04869] [00:36:23/00:06:30, 0.529s/it]: train_loss_raw=0.2835, running_loss=0.3515, LR=0.000100
[2025-08-11 16:17:34,158][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028488] [Batch 04143/04869] [00:36:30/00:06:23, 0.529s/it]: train_loss_raw=0.4018, running_loss=0.3570, LR=0.000100
[2025-08-11 16:17:40,502][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028500] [Batch 04155/04869] [00:36:36/00:06:17, 0.529s/it]: train_loss_raw=0.4031, running_loss=0.3596, LR=0.000100
[2025-08-11 16:17:46,911][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028512] [Batch 04167/04869] [00:36:42/00:06:11, 0.529s/it]: train_loss_raw=0.3542, running_loss=0.3574, LR=0.000100
[2025-08-11 16:17:53,253][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028524] [Batch 04179/04869] [00:36:49/00:06:04, 0.529s/it]: train_loss_raw=0.3541, running_loss=0.3576, LR=0.000100
[2025-08-11 16:17:59,674][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028536] [Batch 04191/04869] [00:36:55/00:05:58, 0.529s/it]: train_loss_raw=0.3341, running_loss=0.3551, LR=0.000100
[2025-08-11 16:18:06,049][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028548] [Batch 04203/04869] [00:37:01/00:05:52, 0.529s/it]: train_loss_raw=0.3344, running_loss=0.3560, LR=0.000100
[2025-08-11 16:18:12,540][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028560] [Batch 04215/04869] [00:37:08/00:05:45, 0.529s/it]: train_loss_raw=0.3453, running_loss=0.3553, LR=0.000100
[2025-08-11 16:18:18,824][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028572] [Batch 04227/04869] [00:37:14/00:05:39, 0.529s/it]: train_loss_raw=0.3720, running_loss=0.3574, LR=0.000100
[2025-08-11 16:18:25,034][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028584] [Batch 04239/04869] [00:37:20/00:05:33, 0.529s/it]: train_loss_raw=0.2481, running_loss=0.3567, LR=0.000100
[2025-08-11 16:18:31,309][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028596] [Batch 04251/04869] [00:37:27/00:05:26, 0.529s/it]: train_loss_raw=0.3456, running_loss=0.3571, LR=0.000100
[2025-08-11 16:18:37,497][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028608] [Batch 04263/04869] [00:37:33/00:05:20, 0.529s/it]: train_loss_raw=0.4231, running_loss=0.3576, LR=0.000100
[2025-08-11 16:18:43,665][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028620] [Batch 04275/04869] [00:37:39/00:05:13, 0.529s/it]: train_loss_raw=0.3514, running_loss=0.3585, LR=0.000100
[2025-08-11 16:18:49,823][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028632] [Batch 04287/04869] [00:37:45/00:05:07, 0.529s/it]: train_loss_raw=0.3630, running_loss=0.3594, LR=0.000100
[2025-08-11 16:18:55,930][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028644] [Batch 04299/04869] [00:37:51/00:05:01, 0.528s/it]: train_loss_raw=0.3372, running_loss=0.3610, LR=0.000100
[2025-08-11 16:19:02,060][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028656] [Batch 04311/04869] [00:37:57/00:04:54, 0.528s/it]: train_loss_raw=0.3675, running_loss=0.3613, LR=0.000100
[2025-08-11 16:19:08,210][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028668] [Batch 04323/04869] [00:38:04/00:04:48, 0.528s/it]: train_loss_raw=0.3615, running_loss=0.3588, LR=0.000100
[2025-08-11 16:19:14,382][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028680] [Batch 04335/04869] [00:38:10/00:04:42, 0.528s/it]: train_loss_raw=0.3643, running_loss=0.3603, LR=0.000100
[2025-08-11 16:19:20,522][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028692] [Batch 04347/04869] [00:38:16/00:04:35, 0.528s/it]: train_loss_raw=0.3474, running_loss=0.3585, LR=0.000100
[2025-08-11 16:19:26,655][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028704] [Batch 04359/04869] [00:38:22/00:04:29, 0.528s/it]: train_loss_raw=0.3023, running_loss=0.3555, LR=0.000100
[2025-08-11 16:19:33,060][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028716] [Batch 04371/04869] [00:38:28/00:04:23, 0.528s/it]: train_loss_raw=0.3141, running_loss=0.3551, LR=0.000100
[2025-08-11 16:19:39,249][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028728] [Batch 04383/04869] [00:38:35/00:04:16, 0.528s/it]: train_loss_raw=0.3606, running_loss=0.3561, LR=0.000100
[2025-08-11 16:19:45,408][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028740] [Batch 04395/04869] [00:38:41/00:04:10, 0.528s/it]: train_loss_raw=0.3172, running_loss=0.3534, LR=0.000100
[2025-08-11 16:19:51,672][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028752] [Batch 04407/04869] [00:38:47/00:04:04, 0.528s/it]: train_loss_raw=0.3467, running_loss=0.3546, LR=0.000100
[2025-08-11 16:19:58,091][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028764] [Batch 04419/04869] [00:38:53/00:03:57, 0.528s/it]: train_loss_raw=0.4082, running_loss=0.3586, LR=0.000100
[2025-08-11 16:20:04,526][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028776] [Batch 04431/04869] [00:39:00/00:03:51, 0.528s/it]: train_loss_raw=0.4254, running_loss=0.3599, LR=0.000100
[2025-08-11 16:20:10,697][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028788] [Batch 04443/04869] [00:39:06/00:03:44, 0.528s/it]: train_loss_raw=0.3686, running_loss=0.3587, LR=0.000100
[2025-08-11 16:20:16,856][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028800] [Batch 04455/04869] [00:39:12/00:03:38, 0.528s/it]: train_loss_raw=0.3452, running_loss=0.3564, LR=0.000100
[2025-08-11 16:20:23,228][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028812] [Batch 04467/04869] [00:39:19/00:03:32, 0.528s/it]: train_loss_raw=0.2508, running_loss=0.3547, LR=0.000100
[2025-08-11 16:20:29,583][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028824] [Batch 04479/04869] [00:39:25/00:03:25, 0.528s/it]: train_loss_raw=0.3382, running_loss=0.3567, LR=0.000100
[2025-08-11 16:20:35,703][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028836] [Batch 04491/04869] [00:39:31/00:03:19, 0.528s/it]: train_loss_raw=0.3784, running_loss=0.3547, LR=0.000100
[2025-08-11 16:20:41,872][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028848] [Batch 04503/04869] [00:39:37/00:03:13, 0.528s/it]: train_loss_raw=0.3145, running_loss=0.3549, LR=0.000100
[2025-08-11 16:20:47,977][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028860] [Batch 04515/04869] [00:39:43/00:03:06, 0.528s/it]: train_loss_raw=0.4207, running_loss=0.3567, LR=0.000100
[2025-08-11 16:20:54,155][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028872] [Batch 04527/04869] [00:39:50/00:03:00, 0.528s/it]: train_loss_raw=0.3519, running_loss=0.3575, LR=0.000100
[2025-08-11 16:21:00,314][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028884] [Batch 04539/04869] [00:39:56/00:02:54, 0.528s/it]: train_loss_raw=0.3375, running_loss=0.3566, LR=0.000100
[2025-08-11 16:21:06,432][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028896] [Batch 04551/04869] [00:40:02/00:02:47, 0.528s/it]: train_loss_raw=0.3893, running_loss=0.3587, LR=0.000100
[2025-08-11 16:21:12,601][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028908] [Batch 04563/04869] [00:40:08/00:02:41, 0.528s/it]: train_loss_raw=0.3664, running_loss=0.3588, LR=0.000100
[2025-08-11 16:21:18,733][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028920] [Batch 04575/04869] [00:40:14/00:02:35, 0.528s/it]: train_loss_raw=0.4089, running_loss=0.3583, LR=0.000100
[2025-08-11 16:21:24,865][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028932] [Batch 04587/04869] [00:40:20/00:02:28, 0.528s/it]: train_loss_raw=0.3707, running_loss=0.3582, LR=0.000100
[2025-08-11 16:21:30,976][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028944] [Batch 04599/04869] [00:40:26/00:02:22, 0.528s/it]: train_loss_raw=0.3741, running_loss=0.3565, LR=0.000100
[2025-08-11 16:21:37,169][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028956] [Batch 04611/04869] [00:40:33/00:02:16, 0.528s/it]: train_loss_raw=0.3727, running_loss=0.3552, LR=0.000100
[2025-08-11 16:21:43,569][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028968] [Batch 04623/04869] [00:40:39/00:02:09, 0.528s/it]: train_loss_raw=0.4856, running_loss=0.3569, LR=0.000100
[2025-08-11 16:21:49,933][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028980] [Batch 04635/04869] [00:40:45/00:02:03, 0.528s/it]: train_loss_raw=0.4201, running_loss=0.3549, LR=0.000100
[2025-08-11 16:21:56,212][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028992] [Batch 04647/04869] [00:40:52/00:01:57, 0.528s/it]: train_loss_raw=0.4187, running_loss=0.3566, LR=0.000100
[2025-08-11 16:22:02,505][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029004] [Batch 04659/04869] [00:40:58/00:01:50, 0.528s/it]: train_loss_raw=0.3799, running_loss=0.3575, LR=0.000100
[2025-08-11 16:22:08,810][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029016] [Batch 04671/04869] [00:41:04/00:01:44, 0.528s/it]: train_loss_raw=0.3895, running_loss=0.3544, LR=0.000100
[2025-08-11 16:22:15,154][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029028] [Batch 04683/04869] [00:41:11/00:01:38, 0.528s/it]: train_loss_raw=0.3647, running_loss=0.3561, LR=0.000100
[2025-08-11 16:22:21,575][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029040] [Batch 04695/04869] [00:41:17/00:01:31, 0.528s/it]: train_loss_raw=0.3501, running_loss=0.3544, LR=0.000100
[2025-08-11 16:22:27,970][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029052] [Batch 04707/04869] [00:41:23/00:01:25, 0.528s/it]: train_loss_raw=0.3577, running_loss=0.3550, LR=0.000100
[2025-08-11 16:22:34,388][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029064] [Batch 04719/04869] [00:41:30/00:01:19, 0.528s/it]: train_loss_raw=0.4435, running_loss=0.3552, LR=0.000100
[2025-08-11 16:22:40,888][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029076] [Batch 04731/04869] [00:41:36/00:01:12, 0.528s/it]: train_loss_raw=0.2754, running_loss=0.3561, LR=0.000100
[2025-08-11 16:22:47,375][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029088] [Batch 04743/04869] [00:41:43/00:01:06, 0.528s/it]: train_loss_raw=0.3372, running_loss=0.3560, LR=0.000100
[2025-08-11 16:22:53,709][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029100] [Batch 04755/04869] [00:41:49/00:01:00, 0.528s/it]: train_loss_raw=0.5070, running_loss=0.3591, LR=0.000100
[2025-08-11 16:23:00,014][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029112] [Batch 04767/04869] [00:41:55/00:00:53, 0.528s/it]: train_loss_raw=0.3157, running_loss=0.3582, LR=0.000100
[2025-08-11 16:23:06,340][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029124] [Batch 04779/04869] [00:42:02/00:00:47, 0.528s/it]: train_loss_raw=0.3705, running_loss=0.3559, LR=0.000100
[2025-08-11 16:23:12,646][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029136] [Batch 04791/04869] [00:42:08/00:00:41, 0.528s/it]: train_loss_raw=0.3651, running_loss=0.3561, LR=0.000100
[2025-08-11 16:23:19,041][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029148] [Batch 04803/04869] [00:42:14/00:00:34, 0.528s/it]: train_loss_raw=0.3984, running_loss=0.3547, LR=0.000100
[2025-08-11 16:23:25,345][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029160] [Batch 04815/04869] [00:42:21/00:00:28, 0.528s/it]: train_loss_raw=0.3853, running_loss=0.3550, LR=0.000100
[2025-08-11 16:23:31,621][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029172] [Batch 04827/04869] [00:42:27/00:00:22, 0.528s/it]: train_loss_raw=0.3339, running_loss=0.3566, LR=0.000100
[2025-08-11 16:23:38,022][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029184] [Batch 04839/04869] [00:42:33/00:00:15, 0.528s/it]: train_loss_raw=0.3258, running_loss=0.3583, LR=0.000100
[2025-08-11 16:23:44,472][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029196] [Batch 04851/04869] [00:42:40/00:00:09, 0.528s/it]: train_loss_raw=0.3286, running_loss=0.3563, LR=0.000100
[2025-08-11 16:23:50,765][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029208] [Batch 04863/04869] [00:42:46/00:00:03, 0.528s/it]: train_loss_raw=0.2768, running_loss=0.3542, LR=0.000100
[2025-08-11 16:24:07,310][__main__][INFO] - [VALIDATION] [Epoch 05/29] Starting validation.
[2025-08-11 16:24:21,867][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00011/00062] [00:00:14/00:01:00, 1.213s/it]
[2025-08-11 16:24:54,256][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00023/00062] [00:00:46/00:01:14, 1.956s/it]
[2025-08-11 16:25:10,036][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00035/00062] [00:01:02/00:00:45, 1.742s/it]
[2025-08-11 16:25:25,482][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00047/00062] [00:01:18/00:00:22, 1.629s/it]
[2025-08-11 16:25:40,344][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00059/00062] [00:01:33/00:00:03, 1.551s/it]
[2025-08-11 16:25:42,520][__main__][INFO] - [VALIDATION] [Epoch 05/29] train_loss=0.35416, valid_loss=0.37009
[2025-08-11 16:25:42,521][__main__][INFO] - [VALIDATION] [Epoch 05/29] Metrics:
[2025-08-11 16:25:42,521][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_er      0.187
[2025-08-11 16:25:42,521][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_prec    0.642
[2025-08-11 16:25:42,521][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_recall  0.645
[2025-08-11 16:25:42,521][__main__][INFO] - [VALIDATION] [Epoch 05/29] - pep_recall 0.597
[2025-08-11 16:25:42,524][__main__][INFO] - [TRAIN] [Epoch 05/29] Epoch complete, total time 04:30:21, remaining time 18:01:24, 00:45:03 per epoch
[2025-08-11 16:25:46,463][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029220] [Batch 00006/04869] [00:00:03/00:50:07, 0.618s/it]: train_loss_raw=0.3909, running_loss=0.3328, LR=0.000100
[2025-08-11 16:25:52,879][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029232] [Batch 00018/04869] [00:00:10/00:45:29, 0.563s/it]: train_loss_raw=0.4316, running_loss=0.3344, LR=0.000100
[2025-08-11 16:25:59,170][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029244] [Batch 00030/04869] [00:00:16/00:44:08, 0.547s/it]: train_loss_raw=0.2595, running_loss=0.3316, LR=0.000100
[2025-08-11 16:26:05,505][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029256] [Batch 00042/04869] [00:00:22/00:43:35, 0.542s/it]: train_loss_raw=0.3523, running_loss=0.3327, LR=0.000100
[2025-08-11 16:26:11,881][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029268] [Batch 00054/04869] [00:00:29/00:43:17, 0.539s/it]: train_loss_raw=0.3187, running_loss=0.3348, LR=0.000100
[2025-08-11 16:26:18,188][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029280] [Batch 00066/04869] [00:00:35/00:42:58, 0.537s/it]: train_loss_raw=0.3678, running_loss=0.3334, LR=0.000100
[2025-08-11 16:26:24,542][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029292] [Batch 00078/04869] [00:00:41/00:42:46, 0.536s/it]: train_loss_raw=0.2891, running_loss=0.3361, LR=0.000100
[2025-08-11 16:26:31,128][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029304] [Batch 00090/04869] [00:00:48/00:42:48, 0.538s/it]: train_loss_raw=0.3565, running_loss=0.3359, LR=0.000100
[2025-08-11 16:26:37,435][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029316] [Batch 00102/04869] [00:00:54/00:42:35, 0.536s/it]: train_loss_raw=0.3536, running_loss=0.3352, LR=0.000100
[2025-08-11 16:26:43,801][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029328] [Batch 00114/04869] [00:01:01/00:42:26, 0.536s/it]: train_loss_raw=0.3123, running_loss=0.3382, LR=0.000100
[2025-08-11 16:26:50,108][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029340] [Batch 00126/04869] [00:01:07/00:42:15, 0.535s/it]: train_loss_raw=0.3625, running_loss=0.3396, LR=0.000100
[2025-08-11 16:26:56,444][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029352] [Batch 00138/04869] [00:01:13/00:42:06, 0.534s/it]: train_loss_raw=0.3827, running_loss=0.3412, LR=0.000100
[2025-08-11 16:27:02,903][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029364] [Batch 00150/04869] [00:01:20/00:42:01, 0.534s/it]: train_loss_raw=0.2976, running_loss=0.3427, LR=0.000100
[2025-08-11 16:27:09,225][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029376] [Batch 00162/04869] [00:01:26/00:41:52, 0.534s/it]: train_loss_raw=0.3581, running_loss=0.3436, LR=0.000100
[2025-08-11 16:27:15,588][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029388] [Batch 00174/04869] [00:01:32/00:41:44, 0.534s/it]: train_loss_raw=0.3386, running_loss=0.3424, LR=0.000100
[2025-08-11 16:27:21,918][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029400] [Batch 00186/04869] [00:01:39/00:41:36, 0.533s/it]: train_loss_raw=0.3228, running_loss=0.3454, LR=0.000100
[2025-08-11 16:27:28,130][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029412] [Batch 00198/04869] [00:01:45/00:41:25, 0.532s/it]: train_loss_raw=0.3684, running_loss=0.3454, LR=0.000100
[2025-08-11 16:27:34,435][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029424] [Batch 00210/04869] [00:01:51/00:41:17, 0.532s/it]: train_loss_raw=0.3434, running_loss=0.3454, LR=0.000100
[2025-08-11 16:27:40,757][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029436] [Batch 00222/04869] [00:01:58/00:41:10, 0.532s/it]: train_loss_raw=0.3604, running_loss=0.3416, LR=0.000100
[2025-08-11 16:27:47,265][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029448] [Batch 00234/04869] [00:02:04/00:41:06, 0.532s/it]: train_loss_raw=0.3502, running_loss=0.3417, LR=0.000100
[2025-08-11 16:27:53,618][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029460] [Batch 00246/04869] [00:02:10/00:40:59, 0.532s/it]: train_loss_raw=0.3582, running_loss=0.3410, LR=0.000100
[2025-08-11 16:27:59,917][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029472] [Batch 00258/04869] [00:02:17/00:40:51, 0.532s/it]: train_loss_raw=0.4291, running_loss=0.3412, LR=0.000100
[2025-08-11 16:28:06,286][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029484] [Batch 00270/04869] [00:02:23/00:40:44, 0.532s/it]: train_loss_raw=0.2959, running_loss=0.3406, LR=0.000100
[2025-08-11 16:28:12,635][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029496] [Batch 00282/04869] [00:02:29/00:40:37, 0.531s/it]: train_loss_raw=0.2858, running_loss=0.3398, LR=0.000100
[2025-08-11 16:28:18,892][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029508] [Batch 00294/04869] [00:02:36/00:40:29, 0.531s/it]: train_loss_raw=0.3208, running_loss=0.3389, LR=0.000100
[2025-08-11 16:28:25,126][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029520] [Batch 00306/04869] [00:02:42/00:40:21, 0.531s/it]: train_loss_raw=0.3170, running_loss=0.3371, LR=0.000100
[2025-08-11 16:28:31,421][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029532] [Batch 00318/04869] [00:02:48/00:40:13, 0.530s/it]: train_loss_raw=0.3628, running_loss=0.3402, LR=0.000100
[2025-08-11 16:28:37,680][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029544] [Batch 00330/04869] [00:02:54/00:40:06, 0.530s/it]: train_loss_raw=0.3211, running_loss=0.3390, LR=0.000100
[2025-08-11 16:28:44,057][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029556] [Batch 00342/04869] [00:03:01/00:39:59, 0.530s/it]: train_loss_raw=0.4592, running_loss=0.3423, LR=0.000100
[2025-08-11 16:28:50,409][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029568] [Batch 00354/04869] [00:03:07/00:39:53, 0.530s/it]: train_loss_raw=0.4166, running_loss=0.3418, LR=0.000100
[2025-08-11 16:28:56,590][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029580] [Batch 00366/04869] [00:03:13/00:39:44, 0.530s/it]: train_loss_raw=0.3380, running_loss=0.3403, LR=0.000100
[2025-08-11 16:29:02,985][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029592] [Batch 00378/04869] [00:03:20/00:39:38, 0.530s/it]: train_loss_raw=0.3460, running_loss=0.3395, LR=0.000100
[2025-08-11 16:29:09,284][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029604] [Batch 00390/04869] [00:03:26/00:39:31, 0.530s/it]: train_loss_raw=0.2763, running_loss=0.3408, LR=0.000100
[2025-08-11 16:29:15,485][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029616] [Batch 00402/04869] [00:03:32/00:39:23, 0.529s/it]: train_loss_raw=0.3825, running_loss=0.3440, LR=0.000100
[2025-08-11 16:29:21,762][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029628] [Batch 00414/04869] [00:03:39/00:39:16, 0.529s/it]: train_loss_raw=0.2934, running_loss=0.3430, LR=0.000100
[2025-08-11 16:29:28,083][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029640] [Batch 00426/04869] [00:03:45/00:39:10, 0.529s/it]: train_loss_raw=0.3376, running_loss=0.3425, LR=0.000100
[2025-08-11 16:29:34,234][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029652] [Batch 00438/04869] [00:03:51/00:39:01, 0.528s/it]: train_loss_raw=0.4253, running_loss=0.3441, LR=0.000100
[2025-08-11 16:29:40,381][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029664] [Batch 00450/04869] [00:03:57/00:38:53, 0.528s/it]: train_loss_raw=0.3909, running_loss=0.3452, LR=0.000100
[2025-08-11 16:29:46,581][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029676] [Batch 00462/04869] [00:04:03/00:38:45, 0.528s/it]: train_loss_raw=0.2611, running_loss=0.3438, LR=0.000100
[2025-08-11 16:29:52,724][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029688] [Batch 00474/04869] [00:04:09/00:38:37, 0.527s/it]: train_loss_raw=0.4495, running_loss=0.3430, LR=0.000100
[2025-08-11 16:29:58,831][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029700] [Batch 00486/04869] [00:04:16/00:38:29, 0.527s/it]: train_loss_raw=0.3002, running_loss=0.3389, LR=0.000100
[2025-08-11 16:30:04,987][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029712] [Batch 00498/04869] [00:04:22/00:38:21, 0.527s/it]: train_loss_raw=0.3319, running_loss=0.3400, LR=0.000100
[2025-08-11 16:30:11,149][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029724] [Batch 00510/04869] [00:04:28/00:38:14, 0.526s/it]: train_loss_raw=0.3567, running_loss=0.3372, LR=0.000100
[2025-08-11 16:30:17,294][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029736] [Batch 00522/04869] [00:04:34/00:38:06, 0.526s/it]: train_loss_raw=0.3178, running_loss=0.3363, LR=0.000100
[2025-08-11 16:30:23,417][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029748] [Batch 00534/04869] [00:04:40/00:37:58, 0.526s/it]: train_loss_raw=0.3480, running_loss=0.3372, LR=0.000100
[2025-08-11 16:30:29,664][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029760] [Batch 00546/04869] [00:04:46/00:37:51, 0.525s/it]: train_loss_raw=0.3694, running_loss=0.3394, LR=0.000100
[2025-08-11 16:30:36,143][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029772] [Batch 00558/04869] [00:04:53/00:37:46, 0.526s/it]: train_loss_raw=0.4789, running_loss=0.3402, LR=0.000100
[2025-08-11 16:30:42,638][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029784] [Batch 00570/04869] [00:04:59/00:37:41, 0.526s/it]: train_loss_raw=0.2906, running_loss=0.3434, LR=0.000100
[2025-08-11 16:30:48,954][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029796] [Batch 00582/04869] [00:05:06/00:37:35, 0.526s/it]: train_loss_raw=0.3276, running_loss=0.3433, LR=0.000100
[2025-08-11 16:30:55,308][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029808] [Batch 00594/04869] [00:05:12/00:37:29, 0.526s/it]: train_loss_raw=0.3324, running_loss=0.3432, LR=0.000100
[2025-08-11 16:31:01,668][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029820] [Batch 00606/04869] [00:05:18/00:37:23, 0.526s/it]: train_loss_raw=0.4098, running_loss=0.3443, LR=0.000100
[2025-08-11 16:31:07,958][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029832] [Batch 00618/04869] [00:05:25/00:37:16, 0.526s/it]: train_loss_raw=0.3444, running_loss=0.3426, LR=0.000100
[2025-08-11 16:31:14,230][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029844] [Batch 00630/04869] [00:05:31/00:37:10, 0.526s/it]: train_loss_raw=0.3838, running_loss=0.3398, LR=0.000100
[2025-08-11 16:31:20,633][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029856] [Batch 00642/04869] [00:05:37/00:37:04, 0.526s/it]: train_loss_raw=0.3653, running_loss=0.3376, LR=0.000100
[2025-08-11 16:31:26,945][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029868] [Batch 00654/04869] [00:05:44/00:36:58, 0.526s/it]: train_loss_raw=0.3981, running_loss=0.3377, LR=0.000100
[2025-08-11 16:31:33,262][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029880] [Batch 00666/04869] [00:05:50/00:36:52, 0.526s/it]: train_loss_raw=0.3758, running_loss=0.3368, LR=0.000100
[2025-08-11 16:31:39,677][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029892] [Batch 00678/04869] [00:05:56/00:36:46, 0.526s/it]: train_loss_raw=0.3604, running_loss=0.3377, LR=0.000100
[2025-08-11 16:31:46,003][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029904] [Batch 00690/04869] [00:06:03/00:36:40, 0.526s/it]: train_loss_raw=0.3762, running_loss=0.3411, LR=0.000100
[2025-08-11 16:31:52,268][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029916] [Batch 00702/04869] [00:06:09/00:36:33, 0.526s/it]: train_loss_raw=0.2957, running_loss=0.3418, LR=0.000100
[2025-08-11 16:31:58,593][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029928] [Batch 00714/04869] [00:06:15/00:36:27, 0.526s/it]: train_loss_raw=0.3631, running_loss=0.3423, LR=0.000100
[2025-08-11 16:32:04,890][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029940] [Batch 00726/04869] [00:06:22/00:36:20, 0.526s/it]: train_loss_raw=0.4174, running_loss=0.3457, LR=0.000100
[2025-08-11 16:32:11,301][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029952] [Batch 00738/04869] [00:06:28/00:36:14, 0.526s/it]: train_loss_raw=0.3471, running_loss=0.3445, LR=0.000100
[2025-08-11 16:32:17,616][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029964] [Batch 00750/04869] [00:06:34/00:36:08, 0.526s/it]: train_loss_raw=0.4485, running_loss=0.3467, LR=0.000100
[2025-08-11 16:32:23,841][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029976] [Batch 00762/04869] [00:06:41/00:36:01, 0.526s/it]: train_loss_raw=0.4007, running_loss=0.3466, LR=0.000100
[2025-08-11 16:32:30,199][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029988] [Batch 00774/04869] [00:06:47/00:35:55, 0.526s/it]: train_loss_raw=0.2713, running_loss=0.3446, LR=0.000100
[2025-08-11 16:32:36,553][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030000] [Batch 00786/04869] [00:06:53/00:35:49, 0.526s/it]: train_loss_raw=0.3167, running_loss=0.3452, LR=0.000100
[2025-08-11 16:32:47,371][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030012] [Batch 00798/04869] [00:07:04/00:36:06, 0.532s/it]: train_loss_raw=0.3752, running_loss=0.3476, LR=0.000100
[2025-08-11 16:32:53,935][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030024] [Batch 00810/04869] [00:07:11/00:36:00, 0.532s/it]: train_loss_raw=0.3118, running_loss=0.3458, LR=0.000100
[2025-08-11 16:33:00,335][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030036] [Batch 00822/04869] [00:07:17/00:35:54, 0.532s/it]: train_loss_raw=0.3151, running_loss=0.3421, LR=0.000100
[2025-08-11 16:33:06,743][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030048] [Batch 00834/04869] [00:07:23/00:35:48, 0.532s/it]: train_loss_raw=0.2886, running_loss=0.3401, LR=0.000100
[2025-08-11 16:33:13,019][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030060] [Batch 00846/04869] [00:07:30/00:35:41, 0.532s/it]: train_loss_raw=0.3875, running_loss=0.3442, LR=0.000100
[2025-08-11 16:33:19,372][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030072] [Batch 00858/04869] [00:07:36/00:35:34, 0.532s/it]: train_loss_raw=0.3412, running_loss=0.3454, LR=0.000100
[2025-08-11 16:33:25,705][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030084] [Batch 00870/04869] [00:07:42/00:35:27, 0.532s/it]: train_loss_raw=0.3063, running_loss=0.3443, LR=0.000100
[2025-08-11 16:33:32,032][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030096] [Batch 00882/04869] [00:07:49/00:35:21, 0.532s/it]: train_loss_raw=0.3144, running_loss=0.3459, LR=0.000100
[2025-08-11 16:33:38,326][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030108] [Batch 00894/04869] [00:07:55/00:35:14, 0.532s/it]: train_loss_raw=0.3299, running_loss=0.3470, LR=0.000100
[2025-08-11 16:33:44,678][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030120] [Batch 00906/04869] [00:08:01/00:35:08, 0.532s/it]: train_loss_raw=0.2881, running_loss=0.3442, LR=0.000100
[2025-08-11 16:33:50,981][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030132] [Batch 00918/04869] [00:08:08/00:35:01, 0.532s/it]: train_loss_raw=0.3972, running_loss=0.3449, LR=0.000100
[2025-08-11 16:33:57,307][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030144] [Batch 00930/04869] [00:08:14/00:34:54, 0.532s/it]: train_loss_raw=0.2921, running_loss=0.3441, LR=0.000100
[2025-08-11 16:34:03,722][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030156] [Batch 00942/04869] [00:08:20/00:34:48, 0.532s/it]: train_loss_raw=0.3447, running_loss=0.3419, LR=0.000100
[2025-08-11 16:34:10,197][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030168] [Batch 00954/04869] [00:08:27/00:34:42, 0.532s/it]: train_loss_raw=0.3571, running_loss=0.3439, LR=0.000100
[2025-08-11 16:34:16,655][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030180] [Batch 00966/04869] [00:08:33/00:34:36, 0.532s/it]: train_loss_raw=0.3130, running_loss=0.3426, LR=0.000100
[2025-08-11 16:34:22,956][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030192] [Batch 00978/04869] [00:08:40/00:34:29, 0.532s/it]: train_loss_raw=0.3196, running_loss=0.3433, LR=0.000100
[2025-08-11 16:34:29,253][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030204] [Batch 00990/04869] [00:08:46/00:34:22, 0.532s/it]: train_loss_raw=0.3429, running_loss=0.3428, LR=0.000100
[2025-08-11 16:34:35,520][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030216] [Batch 01002/04869] [00:08:52/00:34:16, 0.532s/it]: train_loss_raw=0.3302, running_loss=0.3414, LR=0.000100
[2025-08-11 16:34:41,860][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030228] [Batch 01014/04869] [00:08:59/00:34:09, 0.532s/it]: train_loss_raw=0.3191, running_loss=0.3410, LR=0.000100
[2025-08-11 16:34:48,194][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030240] [Batch 01026/04869] [00:09:05/00:34:03, 0.532s/it]: train_loss_raw=0.3583, running_loss=0.3413, LR=0.000100
[2025-08-11 16:34:54,517][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030252] [Batch 01038/04869] [00:09:11/00:33:56, 0.532s/it]: train_loss_raw=0.2924, running_loss=0.3391, LR=0.000100
[2025-08-11 16:35:00,797][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030264] [Batch 01050/04869] [00:09:18/00:33:49, 0.531s/it]: train_loss_raw=0.3852, running_loss=0.3423, LR=0.000100
[2025-08-11 16:35:07,028][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030276] [Batch 01062/04869] [00:09:24/00:33:42, 0.531s/it]: train_loss_raw=0.2972, running_loss=0.3404, LR=0.000100
[2025-08-11 16:35:13,325][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030288] [Batch 01074/04869] [00:09:30/00:33:36, 0.531s/it]: train_loss_raw=0.2420, running_loss=0.3423, LR=0.000100
[2025-08-11 16:35:19,633][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030300] [Batch 01086/04869] [00:09:36/00:33:29, 0.531s/it]: train_loss_raw=0.3323, running_loss=0.3425, LR=0.000100
[2025-08-11 16:35:26,111][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030312] [Batch 01098/04869] [00:09:43/00:33:23, 0.531s/it]: train_loss_raw=0.3382, running_loss=0.3419, LR=0.000100
[2025-08-11 16:35:32,520][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030324] [Batch 01110/04869] [00:09:49/00:33:17, 0.531s/it]: train_loss_raw=0.2471, running_loss=0.3397, LR=0.000100
[2025-08-11 16:35:38,838][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030336] [Batch 01122/04869] [00:09:56/00:33:10, 0.531s/it]: train_loss_raw=0.3497, running_loss=0.3417, LR=0.000100
[2025-08-11 16:35:45,093][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030348] [Batch 01134/04869] [00:10:02/00:33:03, 0.531s/it]: train_loss_raw=0.4258, running_loss=0.3425, LR=0.000100
[2025-08-11 16:35:51,405][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030360] [Batch 01146/04869] [00:10:08/00:32:57, 0.531s/it]: train_loss_raw=0.3501, running_loss=0.3393, LR=0.000100
[2025-08-11 16:35:57,710][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030372] [Batch 01158/04869] [00:10:14/00:32:50, 0.531s/it]: train_loss_raw=0.2986, running_loss=0.3396, LR=0.000100
[2025-08-11 16:36:04,091][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030384] [Batch 01170/04869] [00:10:21/00:32:44, 0.531s/it]: train_loss_raw=0.2935, running_loss=0.3394, LR=0.000100
[2025-08-11 16:36:10,485][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030396] [Batch 01182/04869] [00:10:27/00:32:38, 0.531s/it]: train_loss_raw=0.2944, running_loss=0.3397, LR=0.000100
[2025-08-11 16:36:16,784][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030408] [Batch 01194/04869] [00:10:34/00:32:31, 0.531s/it]: train_loss_raw=0.3690, running_loss=0.3413, LR=0.000100
[2025-08-11 16:36:23,129][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030420] [Batch 01206/04869] [00:10:40/00:32:25, 0.531s/it]: train_loss_raw=0.4012, running_loss=0.3405, LR=0.000100
[2025-08-11 16:36:29,541][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030432] [Batch 01218/04869] [00:10:46/00:32:18, 0.531s/it]: train_loss_raw=0.2930, running_loss=0.3385, LR=0.000100
[2025-08-11 16:36:35,833][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030444] [Batch 01230/04869] [00:10:53/00:32:12, 0.531s/it]: train_loss_raw=0.2778, running_loss=0.3398, LR=0.000100
[2025-08-11 16:36:42,143][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030456] [Batch 01242/04869] [00:10:59/00:32:05, 0.531s/it]: train_loss_raw=0.3482, running_loss=0.3411, LR=0.000100
[2025-08-11 16:36:48,431][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030468] [Batch 01254/04869] [00:11:05/00:31:59, 0.531s/it]: train_loss_raw=0.3087, running_loss=0.3407, LR=0.000100
[2025-08-11 16:36:54,772][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030480] [Batch 01266/04869] [00:11:12/00:31:52, 0.531s/it]: train_loss_raw=0.3181, running_loss=0.3410, LR=0.000100
[2025-08-11 16:37:01,087][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030492] [Batch 01278/04869] [00:11:18/00:31:46, 0.531s/it]: train_loss_raw=0.3922, running_loss=0.3402, LR=0.000100
[2025-08-11 16:37:07,381][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030504] [Batch 01290/04869] [00:11:24/00:31:39, 0.531s/it]: train_loss_raw=0.3393, running_loss=0.3417, LR=0.000100
[2025-08-11 16:37:13,734][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030516] [Batch 01302/04869] [00:11:30/00:31:33, 0.531s/it]: train_loss_raw=0.3936, running_loss=0.3420, LR=0.000100
[2025-08-11 16:37:20,170][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030528] [Batch 01314/04869] [00:11:37/00:31:26, 0.531s/it]: train_loss_raw=0.3051, running_loss=0.3434, LR=0.000100
[2025-08-11 16:37:26,575][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030540] [Batch 01326/04869] [00:11:43/00:31:20, 0.531s/it]: train_loss_raw=0.2896, running_loss=0.3434, LR=0.000100
[2025-08-11 16:37:32,987][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030552] [Batch 01338/04869] [00:11:50/00:31:14, 0.531s/it]: train_loss_raw=0.2490, running_loss=0.3420, LR=0.000100
[2025-08-11 16:37:39,359][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030564] [Batch 01350/04869] [00:11:56/00:31:07, 0.531s/it]: train_loss_raw=0.3646, running_loss=0.3439, LR=0.000100
[2025-08-11 16:37:45,795][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030576] [Batch 01362/04869] [00:12:03/00:31:01, 0.531s/it]: train_loss_raw=0.4316, running_loss=0.3443, LR=0.000100
[2025-08-11 16:37:52,098][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030588] [Batch 01374/04869] [00:12:09/00:30:55, 0.531s/it]: train_loss_raw=0.3225, running_loss=0.3448, LR=0.000100
[2025-08-11 16:37:58,463][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030600] [Batch 01386/04869] [00:12:15/00:30:48, 0.531s/it]: train_loss_raw=0.2950, running_loss=0.3421, LR=0.000100
[2025-08-11 16:38:04,844][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030612] [Batch 01398/04869] [00:12:22/00:30:42, 0.531s/it]: train_loss_raw=0.3278, running_loss=0.3413, LR=0.000100
[2025-08-11 16:38:11,187][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030624] [Batch 01410/04869] [00:12:28/00:30:36, 0.531s/it]: train_loss_raw=0.3444, running_loss=0.3420, LR=0.000100
[2025-08-11 16:38:17,550][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030636] [Batch 01422/04869] [00:12:34/00:30:29, 0.531s/it]: train_loss_raw=0.3216, running_loss=0.3399, LR=0.000100
[2025-08-11 16:38:23,903][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030648] [Batch 01434/04869] [00:12:41/00:30:23, 0.531s/it]: train_loss_raw=0.3333, running_loss=0.3408, LR=0.000100
[2025-08-11 16:38:30,003][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030660] [Batch 01446/04869] [00:12:47/00:30:16, 0.531s/it]: train_loss_raw=0.3948, running_loss=0.3389, LR=0.000100
[2025-08-11 16:38:36,149][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030672] [Batch 01458/04869] [00:12:53/00:30:09, 0.530s/it]: train_loss_raw=0.2998, running_loss=0.3376, LR=0.000100
[2025-08-11 16:38:42,263][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030684] [Batch 01470/04869] [00:12:59/00:30:02, 0.530s/it]: train_loss_raw=0.3107, running_loss=0.3394, LR=0.000100
[2025-08-11 16:38:48,418][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030696] [Batch 01482/04869] [00:13:05/00:29:55, 0.530s/it]: train_loss_raw=0.3418, running_loss=0.3404, LR=0.000100
[2025-08-11 16:38:54,513][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030708] [Batch 01494/04869] [00:13:11/00:29:48, 0.530s/it]: train_loss_raw=0.3899, running_loss=0.3377, LR=0.000100
[2025-08-11 16:39:00,753][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030720] [Batch 01506/04869] [00:13:18/00:29:41, 0.530s/it]: train_loss_raw=0.3716, running_loss=0.3390, LR=0.000100
[2025-08-11 16:39:06,932][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030732] [Batch 01518/04869] [00:13:24/00:29:35, 0.530s/it]: train_loss_raw=0.3746, running_loss=0.3381, LR=0.000100
[2025-08-11 16:39:13,202][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030744] [Batch 01530/04869] [00:13:30/00:29:28, 0.530s/it]: train_loss_raw=0.3288, running_loss=0.3388, LR=0.000100
[2025-08-11 16:39:19,475][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030756] [Batch 01542/04869] [00:13:36/00:29:22, 0.530s/it]: train_loss_raw=0.2832, running_loss=0.3395, LR=0.000100
[2025-08-11 16:39:25,629][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030768] [Batch 01554/04869] [00:13:42/00:29:15, 0.530s/it]: train_loss_raw=0.3003, running_loss=0.3393, LR=0.000100
[2025-08-11 16:39:31,867][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030780] [Batch 01566/04869] [00:13:49/00:29:08, 0.529s/it]: train_loss_raw=0.3374, running_loss=0.3388, LR=0.000100
[2025-08-11 16:39:38,046][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030792] [Batch 01578/04869] [00:13:55/00:29:02, 0.529s/it]: train_loss_raw=0.4012, running_loss=0.3367, LR=0.000100
[2025-08-11 16:39:44,227][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030804] [Batch 01590/04869] [00:14:01/00:28:55, 0.529s/it]: train_loss_raw=0.3844, running_loss=0.3369, LR=0.000100
[2025-08-11 16:39:50,388][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030816] [Batch 01602/04869] [00:14:07/00:28:48, 0.529s/it]: train_loss_raw=0.3123, running_loss=0.3397, LR=0.000100
[2025-08-11 16:39:56,485][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030828] [Batch 01614/04869] [00:14:13/00:28:41, 0.529s/it]: train_loss_raw=0.3541, running_loss=0.3416, LR=0.000100
[2025-08-11 16:40:02,622][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030840] [Batch 01626/04869] [00:14:19/00:28:34, 0.529s/it]: train_loss_raw=0.3733, running_loss=0.3416, LR=0.000100
[2025-08-11 16:40:08,711][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030852] [Batch 01638/04869] [00:14:25/00:28:28, 0.529s/it]: train_loss_raw=0.3311, running_loss=0.3420, LR=0.000100
[2025-08-11 16:40:14,833][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030864] [Batch 01650/04869] [00:14:32/00:28:21, 0.529s/it]: train_loss_raw=0.3864, running_loss=0.3419, LR=0.000100
[2025-08-11 16:40:20,942][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030876] [Batch 01662/04869] [00:14:38/00:28:14, 0.528s/it]: train_loss_raw=0.2515, running_loss=0.3397, LR=0.000100
[2025-08-11 16:40:27,149][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030888] [Batch 01674/04869] [00:14:44/00:28:07, 0.528s/it]: train_loss_raw=0.4925, running_loss=0.3420, LR=0.000100
[2025-08-11 16:40:33,303][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030900] [Batch 01686/04869] [00:14:50/00:28:01, 0.528s/it]: train_loss_raw=0.3394, running_loss=0.3381, LR=0.000100
[2025-08-11 16:40:39,476][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030912] [Batch 01698/04869] [00:14:56/00:27:54, 0.528s/it]: train_loss_raw=0.3965, running_loss=0.3398, LR=0.000100
[2025-08-11 16:40:45,642][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030924] [Batch 01710/04869] [00:15:02/00:27:47, 0.528s/it]: train_loss_raw=0.3622, running_loss=0.3419, LR=0.000100
[2025-08-11 16:40:51,781][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030936] [Batch 01722/04869] [00:15:09/00:27:41, 0.528s/it]: train_loss_raw=0.3296, running_loss=0.3429, LR=0.000100
[2025-08-11 16:40:57,918][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030948] [Batch 01734/04869] [00:15:15/00:27:34, 0.528s/it]: train_loss_raw=0.3253, running_loss=0.3434, LR=0.000100
[2025-08-11 16:41:04,317][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030960] [Batch 01746/04869] [00:15:21/00:27:28, 0.528s/it]: train_loss_raw=0.3142, running_loss=0.3428, LR=0.000100
[2025-08-11 16:41:10,723][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030972] [Batch 01758/04869] [00:15:27/00:27:22, 0.528s/it]: train_loss_raw=0.2878, running_loss=0.3418, LR=0.000100
[2025-08-11 16:41:17,150][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030984] [Batch 01770/04869] [00:15:34/00:27:15, 0.528s/it]: train_loss_raw=0.2975, running_loss=0.3387, LR=0.000100
[2025-08-11 16:41:23,527][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030996] [Batch 01782/04869] [00:15:40/00:27:09, 0.528s/it]: train_loss_raw=0.3265, running_loss=0.3392, LR=0.000100
[2025-08-11 16:41:29,830][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031008] [Batch 01794/04869] [00:15:47/00:27:03, 0.528s/it]: train_loss_raw=0.3819, running_loss=0.3392, LR=0.000100
[2025-08-11 16:41:36,406][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031020] [Batch 01806/04869] [00:15:53/00:26:57, 0.528s/it]: train_loss_raw=0.2962, running_loss=0.3400, LR=0.000100
[2025-08-11 16:41:42,876][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031032] [Batch 01818/04869] [00:16:00/00:26:51, 0.528s/it]: train_loss_raw=0.3591, running_loss=0.3400, LR=0.000100
[2025-08-11 16:41:49,299][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031044] [Batch 01830/04869] [00:16:06/00:26:45, 0.528s/it]: train_loss_raw=0.3654, running_loss=0.3390, LR=0.000100
[2025-08-11 16:41:55,661][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031056] [Batch 01842/04869] [00:16:12/00:26:38, 0.528s/it]: train_loss_raw=0.3836, running_loss=0.3409, LR=0.000100
[2025-08-11 16:42:01,965][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031068] [Batch 01854/04869] [00:16:19/00:26:32, 0.528s/it]: train_loss_raw=0.3594, running_loss=0.3404, LR=0.000100
[2025-08-11 16:42:08,472][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031080] [Batch 01866/04869] [00:16:25/00:26:26, 0.528s/it]: train_loss_raw=0.3468, running_loss=0.3412, LR=0.000100
[2025-08-11 16:42:14,850][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031092] [Batch 01878/04869] [00:16:32/00:26:20, 0.528s/it]: train_loss_raw=0.2836, running_loss=0.3438, LR=0.000100
[2025-08-11 16:42:21,232][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031104] [Batch 01890/04869] [00:16:38/00:26:13, 0.528s/it]: train_loss_raw=0.4828, running_loss=0.3451, LR=0.000100
[2025-08-11 16:42:27,445][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031116] [Batch 01902/04869] [00:16:44/00:26:07, 0.528s/it]: train_loss_raw=0.2683, running_loss=0.3435, LR=0.000100
[2025-08-11 16:42:33,600][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031128] [Batch 01914/04869] [00:16:50/00:26:00, 0.528s/it]: train_loss_raw=0.3721, running_loss=0.3453, LR=0.000100
[2025-08-11 16:42:39,820][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031140] [Batch 01926/04869] [00:16:57/00:25:54, 0.528s/it]: train_loss_raw=0.4276, running_loss=0.3456, LR=0.000100
[2025-08-11 16:42:46,009][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031152] [Batch 01938/04869] [00:17:03/00:25:47, 0.528s/it]: train_loss_raw=0.3274, running_loss=0.3414, LR=0.000100
[2025-08-11 16:42:52,159][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031164] [Batch 01950/04869] [00:17:09/00:25:40, 0.528s/it]: train_loss_raw=0.3036, running_loss=0.3406, LR=0.000100
[2025-08-11 16:42:58,371][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031176] [Batch 01962/04869] [00:17:15/00:25:34, 0.528s/it]: train_loss_raw=0.3971, running_loss=0.3393, LR=0.000100
[2025-08-11 16:43:04,621][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031188] [Batch 01974/04869] [00:17:21/00:25:27, 0.528s/it]: train_loss_raw=0.3413, running_loss=0.3406, LR=0.000100
[2025-08-11 16:43:10,833][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031200] [Batch 01986/04869] [00:17:28/00:25:21, 0.528s/it]: train_loss_raw=0.3351, running_loss=0.3437, LR=0.000100
[2025-08-11 16:43:17,162][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031212] [Batch 01998/04869] [00:17:34/00:25:15, 0.528s/it]: train_loss_raw=0.3385, running_loss=0.3448, LR=0.000100
[2025-08-11 16:43:23,469][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031224] [Batch 02010/04869] [00:17:40/00:25:08, 0.528s/it]: train_loss_raw=0.3558, running_loss=0.3421, LR=0.000100
[2025-08-11 16:43:57,859][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031236] [Batch 02022/04869] [00:18:15/00:25:41, 0.542s/it]: train_loss_raw=0.4076, running_loss=0.3441, LR=0.000100
[2025-08-11 16:44:04,181][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031248] [Batch 02034/04869] [00:18:21/00:25:35, 0.542s/it]: train_loss_raw=0.2536, running_loss=0.3410, LR=0.000100
[2025-08-11 16:44:10,536][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031260] [Batch 02046/04869] [00:18:27/00:25:28, 0.541s/it]: train_loss_raw=0.2752, running_loss=0.3403, LR=0.000100
[2025-08-11 16:44:17,068][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031272] [Batch 02058/04869] [00:18:34/00:25:22, 0.541s/it]: train_loss_raw=0.3161, running_loss=0.3383, LR=0.000100
[2025-08-11 16:44:23,467][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031284] [Batch 02070/04869] [00:18:40/00:25:15, 0.541s/it]: train_loss_raw=0.2796, running_loss=0.3352, LR=0.000100
[2025-08-11 16:44:30,017][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031296] [Batch 02082/04869] [00:18:47/00:25:08, 0.541s/it]: train_loss_raw=0.2274, running_loss=0.3345, LR=0.000100
[2025-08-11 16:44:36,360][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031308] [Batch 02094/04869] [00:18:53/00:25:02, 0.541s/it]: train_loss_raw=0.3192, running_loss=0.3337, LR=0.000100
[2025-08-11 16:44:42,718][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031320] [Batch 02106/04869] [00:18:59/00:24:55, 0.541s/it]: train_loss_raw=0.3293, running_loss=0.3330, LR=0.000100
[2025-08-11 16:44:49,152][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031332] [Batch 02118/04869] [00:19:06/00:24:49, 0.541s/it]: train_loss_raw=0.3544, running_loss=0.3328, LR=0.000100
[2025-08-11 16:44:55,583][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031344] [Batch 02130/04869] [00:19:12/00:24:42, 0.541s/it]: train_loss_raw=0.3630, running_loss=0.3310, LR=0.000100
[2025-08-11 16:45:01,908][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031356] [Batch 02142/04869] [00:19:19/00:24:35, 0.541s/it]: train_loss_raw=0.3084, running_loss=0.3289, LR=0.000100
[2025-08-11 16:45:08,340][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031368] [Batch 02154/04869] [00:19:25/00:24:29, 0.541s/it]: train_loss_raw=0.2708, running_loss=0.3272, LR=0.000100
[2025-08-11 16:45:14,629][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031380] [Batch 02166/04869] [00:19:31/00:24:22, 0.541s/it]: train_loss_raw=0.3511, running_loss=0.3264, LR=0.000100
[2025-08-11 16:45:20,945][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031392] [Batch 02178/04869] [00:19:38/00:24:15, 0.541s/it]: train_loss_raw=0.3690, running_loss=0.3280, LR=0.000100
[2025-08-11 16:45:27,269][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031404] [Batch 02190/04869] [00:19:44/00:24:09, 0.541s/it]: train_loss_raw=0.3599, running_loss=0.3302, LR=0.000100
[2025-08-11 16:45:33,704][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031416] [Batch 02202/04869] [00:19:50/00:24:02, 0.541s/it]: train_loss_raw=0.3617, running_loss=0.3300, LR=0.000100
[2025-08-11 16:45:40,100][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031428] [Batch 02214/04869] [00:19:57/00:23:55, 0.541s/it]: train_loss_raw=0.2882, running_loss=0.3280, LR=0.000100
[2025-08-11 16:45:46,546][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031440] [Batch 02226/04869] [00:20:03/00:23:49, 0.541s/it]: train_loss_raw=0.2937, running_loss=0.3300, LR=0.000100
[2025-08-11 16:45:52,808][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031452] [Batch 02238/04869] [00:20:10/00:23:42, 0.541s/it]: train_loss_raw=0.2908, running_loss=0.3302, LR=0.000100
[2025-08-11 16:45:59,214][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031464] [Batch 02250/04869] [00:20:16/00:23:35, 0.541s/it]: train_loss_raw=0.3647, running_loss=0.3274, LR=0.000100
[2025-08-11 16:46:05,654][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031476] [Batch 02262/04869] [00:20:22/00:23:29, 0.541s/it]: train_loss_raw=0.3518, running_loss=0.3278, LR=0.000100
[2025-08-11 16:46:11,725][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031488] [Batch 02274/04869] [00:20:28/00:23:22, 0.540s/it]: train_loss_raw=0.2760, running_loss=0.3283, LR=0.000100
[2025-08-11 16:46:17,905][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031500] [Batch 02286/04869] [00:20:35/00:23:15, 0.540s/it]: train_loss_raw=0.4487, running_loss=0.3314, LR=0.000100
[2025-08-11 16:46:24,070][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031512] [Batch 02298/04869] [00:20:41/00:23:08, 0.540s/it]: train_loss_raw=0.3356, running_loss=0.3339, LR=0.000100
[2025-08-11 16:46:30,482][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031524] [Batch 02310/04869] [00:20:47/00:23:02, 0.540s/it]: train_loss_raw=0.2817, running_loss=0.3308, LR=0.000100
[2025-08-11 16:46:36,663][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031536] [Batch 02322/04869] [00:20:53/00:22:55, 0.540s/it]: train_loss_raw=0.3344, running_loss=0.3311, LR=0.000100
[2025-08-11 16:46:42,820][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031548] [Batch 02334/04869] [00:21:00/00:22:48, 0.540s/it]: train_loss_raw=0.2849, running_loss=0.3287, LR=0.000100
[2025-08-11 16:46:49,005][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031560] [Batch 02346/04869] [00:21:06/00:22:41, 0.540s/it]: train_loss_raw=0.3017, running_loss=0.3277, LR=0.000100
[2025-08-11 16:46:55,192][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031572] [Batch 02358/04869] [00:21:12/00:22:35, 0.540s/it]: train_loss_raw=0.3231, running_loss=0.3307, LR=0.000100
[2025-08-11 16:47:01,296][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031584] [Batch 02370/04869] [00:21:18/00:22:28, 0.539s/it]: train_loss_raw=0.3062, running_loss=0.3302, LR=0.000100
[2025-08-11 16:47:07,493][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031596] [Batch 02382/04869] [00:21:24/00:22:21, 0.539s/it]: train_loss_raw=0.3584, running_loss=0.3308, LR=0.000100
[2025-08-11 16:47:13,659][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031608] [Batch 02394/04869] [00:21:30/00:22:14, 0.539s/it]: train_loss_raw=0.3220, running_loss=0.3289, LR=0.000100
[2025-08-11 16:47:19,800][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031620] [Batch 02406/04869] [00:21:37/00:22:07, 0.539s/it]: train_loss_raw=0.3045, running_loss=0.3299, LR=0.000100
[2025-08-11 16:47:25,920][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031632] [Batch 02418/04869] [00:21:43/00:22:00, 0.539s/it]: train_loss_raw=0.4270, running_loss=0.3340, LR=0.000100
[2025-08-11 16:47:32,046][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031644] [Batch 02430/04869] [00:21:49/00:21:54, 0.539s/it]: train_loss_raw=0.2844, running_loss=0.3317, LR=0.000100
[2025-08-11 16:47:38,196][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031656] [Batch 02442/04869] [00:21:55/00:21:47, 0.539s/it]: train_loss_raw=0.3419, running_loss=0.3296, LR=0.000100
[2025-08-11 16:47:44,539][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031668] [Batch 02454/04869] [00:22:01/00:21:40, 0.539s/it]: train_loss_raw=0.4600, running_loss=0.3313, LR=0.000100
[2025-08-11 16:47:50,792][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031680] [Batch 02466/04869] [00:22:08/00:21:34, 0.539s/it]: train_loss_raw=0.3427, running_loss=0.3320, LR=0.000100
[2025-08-11 16:47:57,142][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031692] [Batch 02478/04869] [00:22:14/00:21:27, 0.538s/it]: train_loss_raw=0.2904, running_loss=0.3337, LR=0.000100
[2025-08-11 16:48:03,272][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031704] [Batch 02490/04869] [00:22:20/00:21:20, 0.538s/it]: train_loss_raw=0.2703, running_loss=0.3309, LR=0.000100
[2025-08-11 16:48:09,549][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031716] [Batch 02502/04869] [00:22:26/00:21:14, 0.538s/it]: train_loss_raw=0.4045, running_loss=0.3306, LR=0.000100
[2025-08-11 16:48:15,838][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031728] [Batch 02514/04869] [00:22:33/00:21:07, 0.538s/it]: train_loss_raw=0.3801, running_loss=0.3305, LR=0.000100
[2025-08-11 16:48:22,136][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031740] [Batch 02526/04869] [00:22:39/00:21:00, 0.538s/it]: train_loss_raw=0.2817, running_loss=0.3303, LR=0.000100
[2025-08-11 16:48:28,639][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031752] [Batch 02538/04869] [00:22:45/00:20:54, 0.538s/it]: train_loss_raw=0.2950, running_loss=0.3279, LR=0.000100
[2025-08-11 16:48:35,097][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031764] [Batch 02550/04869] [00:22:52/00:20:48, 0.538s/it]: train_loss_raw=0.2756, running_loss=0.3299, LR=0.000100
[2025-08-11 16:48:41,492][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031776] [Batch 02562/04869] [00:22:58/00:20:41, 0.538s/it]: train_loss_raw=0.3928, running_loss=0.3306, LR=0.000100
[2025-08-11 16:48:47,884][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031788] [Batch 02574/04869] [00:23:05/00:20:34, 0.538s/it]: train_loss_raw=0.2795, running_loss=0.3281, LR=0.000100
[2025-08-11 16:48:54,381][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031800] [Batch 02586/04869] [00:23:11/00:20:28, 0.538s/it]: train_loss_raw=0.3262, running_loss=0.3282, LR=0.000100
[2025-08-11 16:49:00,937][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031812] [Batch 02598/04869] [00:23:18/00:20:22, 0.538s/it]: train_loss_raw=0.3348, running_loss=0.3272, LR=0.000100
[2025-08-11 16:49:07,409][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031824] [Batch 02610/04869] [00:23:24/00:20:15, 0.538s/it]: train_loss_raw=0.2717, running_loss=0.3281, LR=0.000100
[2025-08-11 16:49:13,691][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031836] [Batch 02622/04869] [00:23:30/00:20:09, 0.538s/it]: train_loss_raw=0.2349, running_loss=0.3282, LR=0.000100
[2025-08-11 16:49:20,069][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031848] [Batch 02634/04869] [00:23:37/00:20:02, 0.538s/it]: train_loss_raw=0.3670, running_loss=0.3270, LR=0.000100
[2025-08-11 16:49:26,366][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031860] [Batch 02646/04869] [00:23:43/00:19:56, 0.538s/it]: train_loss_raw=0.3618, running_loss=0.3275, LR=0.000100
[2025-08-11 16:49:32,696][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031872] [Batch 02658/04869] [00:23:49/00:19:49, 0.538s/it]: train_loss_raw=0.3606, running_loss=0.3291, LR=0.000100
[2025-08-11 16:49:39,032][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031884] [Batch 02670/04869] [00:23:56/00:19:42, 0.538s/it]: train_loss_raw=0.3162, running_loss=0.3286, LR=0.000100
[2025-08-11 16:49:45,360][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031896] [Batch 02682/04869] [00:24:02/00:19:36, 0.538s/it]: train_loss_raw=0.3469, running_loss=0.3291, LR=0.000100
[2025-08-11 16:49:51,755][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031908] [Batch 02694/04869] [00:24:09/00:19:29, 0.538s/it]: train_loss_raw=0.3213, running_loss=0.3294, LR=0.000100
[2025-08-11 16:49:58,019][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031920] [Batch 02706/04869] [00:24:15/00:19:23, 0.538s/it]: train_loss_raw=0.2879, running_loss=0.3270, LR=0.000100
[2025-08-11 16:50:04,430][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031932] [Batch 02718/04869] [00:24:21/00:19:16, 0.538s/it]: train_loss_raw=0.3233, running_loss=0.3280, LR=0.000100
[2025-08-11 16:50:10,782][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031944] [Batch 02730/04869] [00:24:28/00:19:10, 0.538s/it]: train_loss_raw=0.3134, running_loss=0.3295, LR=0.000100
[2025-08-11 16:50:17,216][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031956] [Batch 02742/04869] [00:24:34/00:19:03, 0.538s/it]: train_loss_raw=0.2463, running_loss=0.3316, LR=0.000100
[2025-08-11 16:50:23,631][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031968] [Batch 02754/04869] [00:24:40/00:18:57, 0.538s/it]: train_loss_raw=0.3650, running_loss=0.3321, LR=0.000100
[2025-08-11 16:50:29,966][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031980] [Batch 02766/04869] [00:24:47/00:18:50, 0.538s/it]: train_loss_raw=0.2948, running_loss=0.3341, LR=0.000100
[2025-08-11 16:50:36,335][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031992] [Batch 02778/04869] [00:24:53/00:18:44, 0.538s/it]: train_loss_raw=0.3604, running_loss=0.3345, LR=0.000100
[2025-08-11 16:50:47,560][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032004] [Batch 02790/04869] [00:25:04/00:18:41, 0.539s/it]: train_loss_raw=0.3307, running_loss=0.3370, LR=0.000100
[2025-08-11 16:50:53,909][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032016] [Batch 02802/04869] [00:25:11/00:18:34, 0.539s/it]: train_loss_raw=0.4848, running_loss=0.3395, LR=0.000100
[2025-08-11 16:51:00,295][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032028] [Batch 02814/04869] [00:25:17/00:18:28, 0.539s/it]: train_loss_raw=0.4225, running_loss=0.3391, LR=0.000100
[2025-08-11 16:51:06,477][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032040] [Batch 02826/04869] [00:25:23/00:18:21, 0.539s/it]: train_loss_raw=0.3139, running_loss=0.3363, LR=0.000100
[2025-08-11 16:51:12,725][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032052] [Batch 02838/04869] [00:25:29/00:18:14, 0.539s/it]: train_loss_raw=0.2900, running_loss=0.3363, LR=0.000100
[2025-08-11 16:51:19,127][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032064] [Batch 02850/04869] [00:25:36/00:18:08, 0.539s/it]: train_loss_raw=0.2997, running_loss=0.3368, LR=0.000100
[2025-08-11 16:51:25,464][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032076] [Batch 02862/04869] [00:25:42/00:18:01, 0.539s/it]: train_loss_raw=0.2102, running_loss=0.3344, LR=0.000100
[2025-08-11 16:51:31,828][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032088] [Batch 02874/04869] [00:25:49/00:17:55, 0.539s/it]: train_loss_raw=0.3334, running_loss=0.3359, LR=0.000100
[2025-08-11 16:51:38,164][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032100] [Batch 02886/04869] [00:25:55/00:17:48, 0.539s/it]: train_loss_raw=0.2718, running_loss=0.3364, LR=0.000100
[2025-08-11 16:51:44,487][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032112] [Batch 02898/04869] [00:26:01/00:17:42, 0.539s/it]: train_loss_raw=0.3540, running_loss=0.3352, LR=0.000100
[2025-08-11 16:51:50,757][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032124] [Batch 02910/04869] [00:26:08/00:17:35, 0.539s/it]: train_loss_raw=0.2877, running_loss=0.3357, LR=0.000100
[2025-08-11 16:51:57,042][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032136] [Batch 02922/04869] [00:26:14/00:17:28, 0.539s/it]: train_loss_raw=0.2879, running_loss=0.3340, LR=0.000100
[2025-08-11 16:52:03,375][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032148] [Batch 02934/04869] [00:26:20/00:17:22, 0.539s/it]: train_loss_raw=0.3496, running_loss=0.3341, LR=0.000100
[2025-08-11 16:52:09,791][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032160] [Batch 02946/04869] [00:26:27/00:17:15, 0.539s/it]: train_loss_raw=0.3330, running_loss=0.3349, LR=0.000100
[2025-08-11 16:52:16,129][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032172] [Batch 02958/04869] [00:26:33/00:17:09, 0.539s/it]: train_loss_raw=0.2666, running_loss=0.3331, LR=0.000100
[2025-08-11 16:52:22,483][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032184] [Batch 02970/04869] [00:26:39/00:17:02, 0.539s/it]: train_loss_raw=0.3874, running_loss=0.3339, LR=0.000100
[2025-08-11 16:52:28,809][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032196] [Batch 02982/04869] [00:26:46/00:16:56, 0.539s/it]: train_loss_raw=0.3044, running_loss=0.3317, LR=0.000100
[2025-08-11 16:52:35,120][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032208] [Batch 02994/04869] [00:26:52/00:16:49, 0.539s/it]: train_loss_raw=0.4270, running_loss=0.3314, LR=0.000100
[2025-08-11 16:52:41,483][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032220] [Batch 03006/04869] [00:26:58/00:16:43, 0.539s/it]: train_loss_raw=0.3210, running_loss=0.3307, LR=0.000100
[2025-08-11 16:52:47,813][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032232] [Batch 03018/04869] [00:27:05/00:16:36, 0.538s/it]: train_loss_raw=0.3403, running_loss=0.3341, LR=0.000100
[2025-08-11 16:52:54,178][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032244] [Batch 03030/04869] [00:27:11/00:16:30, 0.538s/it]: train_loss_raw=0.3444, running_loss=0.3350, LR=0.000100
[2025-08-11 16:53:00,583][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032256] [Batch 03042/04869] [00:27:17/00:16:23, 0.538s/it]: train_loss_raw=0.2498, running_loss=0.3329, LR=0.000100
[2025-08-11 16:53:06,921][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032268] [Batch 03054/04869] [00:27:24/00:16:17, 0.538s/it]: train_loss_raw=0.3189, running_loss=0.3287, LR=0.000100
[2025-08-11 16:53:13,207][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032280] [Batch 03066/04869] [00:27:30/00:16:10, 0.538s/it]: train_loss_raw=0.3133, running_loss=0.3288, LR=0.000100
[2025-08-11 16:53:19,449][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032292] [Batch 03078/04869] [00:27:36/00:16:03, 0.538s/it]: train_loss_raw=0.2930, running_loss=0.3304, LR=0.000100
[2025-08-11 16:53:25,767][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032304] [Batch 03090/04869] [00:27:43/00:15:57, 0.538s/it]: train_loss_raw=0.3014, running_loss=0.3286, LR=0.000100
[2025-08-11 16:53:32,038][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032316] [Batch 03102/04869] [00:27:49/00:15:50, 0.538s/it]: train_loss_raw=0.4395, running_loss=0.3305, LR=0.000100
[2025-08-11 16:53:38,309][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032328] [Batch 03114/04869] [00:27:55/00:15:44, 0.538s/it]: train_loss_raw=0.3141, running_loss=0.3310, LR=0.000100
[2025-08-11 16:53:44,640][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032340] [Batch 03126/04869] [00:28:01/00:15:37, 0.538s/it]: train_loss_raw=0.3340, running_loss=0.3347, LR=0.000100
[2025-08-11 16:53:50,943][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032352] [Batch 03138/04869] [00:28:08/00:15:31, 0.538s/it]: train_loss_raw=0.3469, running_loss=0.3323, LR=0.000100
[2025-08-11 16:53:57,291][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032364] [Batch 03150/04869] [00:28:14/00:15:24, 0.538s/it]: train_loss_raw=0.3965, running_loss=0.3347, LR=0.000100
[2025-08-11 16:54:03,587][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032376] [Batch 03162/04869] [00:28:20/00:15:18, 0.538s/it]: train_loss_raw=0.3537, running_loss=0.3340, LR=0.000100
[2025-08-11 16:54:09,936][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032388] [Batch 03174/04869] [00:28:27/00:15:11, 0.538s/it]: train_loss_raw=0.2692, running_loss=0.3352, LR=0.000100
[2025-08-11 16:54:16,162][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032400] [Batch 03186/04869] [00:28:33/00:15:05, 0.538s/it]: train_loss_raw=0.3133, running_loss=0.3340, LR=0.000100
[2025-08-11 16:54:22,446][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032412] [Batch 03198/04869] [00:28:39/00:14:58, 0.538s/it]: train_loss_raw=0.2424, running_loss=0.3301, LR=0.000100
[2025-08-11 16:54:28,785][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032424] [Batch 03210/04869] [00:28:46/00:14:52, 0.538s/it]: train_loss_raw=0.3568, running_loss=0.3316, LR=0.000100
[2025-08-11 16:54:35,089][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032436] [Batch 03222/04869] [00:28:52/00:14:45, 0.538s/it]: train_loss_raw=0.3084, running_loss=0.3305, LR=0.000100
[2025-08-11 16:54:41,367][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032448] [Batch 03234/04869] [00:28:58/00:14:38, 0.538s/it]: train_loss_raw=0.2153, running_loss=0.3274, LR=0.000100
[2025-08-11 16:54:47,685][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032460] [Batch 03246/04869] [00:29:04/00:14:32, 0.538s/it]: train_loss_raw=0.3048, running_loss=0.3291, LR=0.000100
[2025-08-11 16:54:54,057][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032472] [Batch 03258/04869] [00:29:11/00:14:25, 0.538s/it]: train_loss_raw=0.3338, running_loss=0.3311, LR=0.000100
[2025-08-11 16:55:00,375][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032484] [Batch 03270/04869] [00:29:17/00:14:19, 0.537s/it]: train_loss_raw=0.2952, running_loss=0.3307, LR=0.000100
[2025-08-11 16:55:06,842][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032496] [Batch 03282/04869] [00:29:24/00:14:13, 0.538s/it]: train_loss_raw=0.3574, running_loss=0.3304, LR=0.000100
[2025-08-11 16:55:13,955][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032508] [Batch 03294/04869] [00:29:31/00:14:06, 0.538s/it]: train_loss_raw=0.3036, running_loss=0.3291, LR=0.000100
[2025-08-11 16:55:21,814][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032520] [Batch 03306/04869] [00:29:39/00:14:01, 0.538s/it]: train_loss_raw=0.3618, running_loss=0.3279, LR=0.000100
[2025-08-11 16:55:28,443][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032532] [Batch 03318/04869] [00:29:45/00:13:54, 0.538s/it]: train_loss_raw=0.4304, running_loss=0.3282, LR=0.000100
[2025-08-11 16:55:34,885][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032544] [Batch 03330/04869] [00:29:52/00:13:48, 0.538s/it]: train_loss_raw=0.2850, running_loss=0.3267, LR=0.000100
[2025-08-11 16:55:41,236][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032556] [Batch 03342/04869] [00:29:58/00:13:41, 0.538s/it]: train_loss_raw=0.3632, running_loss=0.3304, LR=0.000100
[2025-08-11 16:55:47,556][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032568] [Batch 03354/04869] [00:30:04/00:13:35, 0.538s/it]: train_loss_raw=0.2971, running_loss=0.3302, LR=0.000100
[2025-08-11 16:55:53,831][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032580] [Batch 03366/04869] [00:30:11/00:13:28, 0.538s/it]: train_loss_raw=0.3861, running_loss=0.3283, LR=0.000100
[2025-08-11 16:56:00,158][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032592] [Batch 03378/04869] [00:30:17/00:13:22, 0.538s/it]: train_loss_raw=0.3799, running_loss=0.3299, LR=0.000100
[2025-08-11 16:56:06,428][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032604] [Batch 03390/04869] [00:30:23/00:13:15, 0.538s/it]: train_loss_raw=0.3935, running_loss=0.3310, LR=0.000100
[2025-08-11 16:56:12,749][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032616] [Batch 03402/04869] [00:30:29/00:13:09, 0.538s/it]: train_loss_raw=0.2594, running_loss=0.3318, LR=0.000100
[2025-08-11 16:56:19,162][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032628] [Batch 03414/04869] [00:30:36/00:13:02, 0.538s/it]: train_loss_raw=0.2328, running_loss=0.3328, LR=0.000100
[2025-08-11 16:56:25,417][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032640] [Batch 03426/04869] [00:30:42/00:12:56, 0.538s/it]: train_loss_raw=0.3366, running_loss=0.3309, LR=0.000100
[2025-08-11 16:56:31,743][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032652] [Batch 03438/04869] [00:30:48/00:12:49, 0.538s/it]: train_loss_raw=0.3828, running_loss=0.3334, LR=0.000100
[2025-08-11 16:56:38,042][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032664] [Batch 03450/04869] [00:30:55/00:12:43, 0.538s/it]: train_loss_raw=0.3253, running_loss=0.3314, LR=0.000100
[2025-08-11 16:56:44,409][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032676] [Batch 03462/04869] [00:31:01/00:12:36, 0.538s/it]: train_loss_raw=0.2674, running_loss=0.3326, LR=0.000100
[2025-08-11 16:56:50,710][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032688] [Batch 03474/04869] [00:31:07/00:12:30, 0.538s/it]: train_loss_raw=0.2552, running_loss=0.3310, LR=0.000100
[2025-08-11 16:56:57,051][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032700] [Batch 03486/04869] [00:31:14/00:12:23, 0.538s/it]: train_loss_raw=0.3517, running_loss=0.3355, LR=0.000100
[2025-08-11 16:57:03,399][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032712] [Batch 03498/04869] [00:31:20/00:12:17, 0.538s/it]: train_loss_raw=0.3895, running_loss=0.3337, LR=0.000100
[2025-08-11 16:57:09,705][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032724] [Batch 03510/04869] [00:31:26/00:12:10, 0.538s/it]: train_loss_raw=0.4160, running_loss=0.3323, LR=0.000100
[2025-08-11 16:57:16,040][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032736] [Batch 03522/04869] [00:31:33/00:12:04, 0.538s/it]: train_loss_raw=0.2787, running_loss=0.3322, LR=0.000100
[2025-08-11 16:57:22,338][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032748] [Batch 03534/04869] [00:31:39/00:11:57, 0.538s/it]: train_loss_raw=0.3261, running_loss=0.3341, LR=0.000100
[2025-08-11 16:57:28,622][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032760] [Batch 03546/04869] [00:31:45/00:11:51, 0.537s/it]: train_loss_raw=0.4129, running_loss=0.3341, LR=0.000100
[2025-08-11 16:57:35,094][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032772] [Batch 03558/04869] [00:31:52/00:11:44, 0.537s/it]: train_loss_raw=0.3288, running_loss=0.3337, LR=0.000100
[2025-08-11 16:57:41,482][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032784] [Batch 03570/04869] [00:31:58/00:11:38, 0.537s/it]: train_loss_raw=0.4564, running_loss=0.3315, LR=0.000100
[2025-08-11 16:57:47,860][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032796] [Batch 03582/04869] [00:32:05/00:11:31, 0.537s/it]: train_loss_raw=0.3389, running_loss=0.3295, LR=0.000100
[2025-08-11 16:57:54,201][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032808] [Batch 03594/04869] [00:32:11/00:11:25, 0.537s/it]: train_loss_raw=0.2806, running_loss=0.3285, LR=0.000100
[2025-08-11 16:58:00,525][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032820] [Batch 03606/04869] [00:32:17/00:11:18, 0.537s/it]: train_loss_raw=0.2696, running_loss=0.3295, LR=0.000100
[2025-08-11 16:58:06,786][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032832] [Batch 03618/04869] [00:32:24/00:11:12, 0.537s/it]: train_loss_raw=0.2736, running_loss=0.3269, LR=0.000100
[2025-08-11 16:58:13,172][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032844] [Batch 03630/04869] [00:32:30/00:11:05, 0.537s/it]: train_loss_raw=0.2984, running_loss=0.3269, LR=0.000100
[2025-08-11 16:58:19,491][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032856] [Batch 03642/04869] [00:32:36/00:10:59, 0.537s/it]: train_loss_raw=0.3379, running_loss=0.3274, LR=0.000100
[2025-08-11 16:58:25,816][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032868] [Batch 03654/04869] [00:32:43/00:10:52, 0.537s/it]: train_loss_raw=0.3047, running_loss=0.3300, LR=0.000100
[2025-08-11 16:58:32,110][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032880] [Batch 03666/04869] [00:32:49/00:10:46, 0.537s/it]: train_loss_raw=0.3338, running_loss=0.3320, LR=0.000100
[2025-08-11 16:58:38,437][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032892] [Batch 03678/04869] [00:32:55/00:10:39, 0.537s/it]: train_loss_raw=0.3114, running_loss=0.3313, LR=0.000100
[2025-08-11 16:58:44,760][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032904] [Batch 03690/04869] [00:33:02/00:10:33, 0.537s/it]: train_loss_raw=0.3254, running_loss=0.3342, LR=0.000100
[2025-08-11 16:58:51,065][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032916] [Batch 03702/04869] [00:33:08/00:10:26, 0.537s/it]: train_loss_raw=0.4230, running_loss=0.3360, LR=0.000100
[2025-08-11 16:58:57,396][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032928] [Batch 03714/04869] [00:33:14/00:10:20, 0.537s/it]: train_loss_raw=0.3964, running_loss=0.3380, LR=0.000100
[2025-08-11 16:59:03,742][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032940] [Batch 03726/04869] [00:33:20/00:10:13, 0.537s/it]: train_loss_raw=0.3838, running_loss=0.3393, LR=0.000100
[2025-08-11 16:59:09,986][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032952] [Batch 03738/04869] [00:33:27/00:10:07, 0.537s/it]: train_loss_raw=0.2555, running_loss=0.3365, LR=0.000100
[2025-08-11 16:59:16,247][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032964] [Batch 03750/04869] [00:33:33/00:10:00, 0.537s/it]: train_loss_raw=0.2866, running_loss=0.3336, LR=0.000100
[2025-08-11 16:59:22,595][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032976] [Batch 03762/04869] [00:33:39/00:09:54, 0.537s/it]: train_loss_raw=0.2597, running_loss=0.3355, LR=0.000100
[2025-08-11 16:59:28,863][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032988] [Batch 03774/04869] [00:33:46/00:09:47, 0.537s/it]: train_loss_raw=0.2603, running_loss=0.3354, LR=0.000100
[2025-08-11 16:59:35,205][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033000] [Batch 03786/04869] [00:33:52/00:09:41, 0.537s/it]: train_loss_raw=0.4124, running_loss=0.3370, LR=0.000100
[2025-08-11 16:59:41,652][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033012] [Batch 03798/04869] [00:33:58/00:09:34, 0.537s/it]: train_loss_raw=0.3846, running_loss=0.3368, LR=0.000100
[2025-08-11 16:59:48,098][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033024] [Batch 03810/04869] [00:34:05/00:09:28, 0.537s/it]: train_loss_raw=0.2942, running_loss=0.3367, LR=0.000100
[2025-08-11 16:59:54,540][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033036] [Batch 03822/04869] [00:34:11/00:09:22, 0.537s/it]: train_loss_raw=0.2883, running_loss=0.3351, LR=0.000100
[2025-08-11 17:00:00,883][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033048] [Batch 03834/04869] [00:34:18/00:09:15, 0.537s/it]: train_loss_raw=0.3260, running_loss=0.3347, LR=0.000100
[2025-08-11 17:00:07,287][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033060] [Batch 03846/04869] [00:34:24/00:09:09, 0.537s/it]: train_loss_raw=0.2820, running_loss=0.3343, LR=0.000100
[2025-08-11 17:00:13,822][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033072] [Batch 03858/04869] [00:34:31/00:09:02, 0.537s/it]: train_loss_raw=0.2660, running_loss=0.3315, LR=0.000100
[2025-08-11 17:00:20,223][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033084] [Batch 03870/04869] [00:34:37/00:08:56, 0.537s/it]: train_loss_raw=0.2707, running_loss=0.3329, LR=0.000100
[2025-08-11 17:00:26,636][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033096] [Batch 03882/04869] [00:34:43/00:08:49, 0.537s/it]: train_loss_raw=0.3597, running_loss=0.3349, LR=0.000100
[2025-08-11 17:00:33,090][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033108] [Batch 03894/04869] [00:34:50/00:08:43, 0.537s/it]: train_loss_raw=0.3109, running_loss=0.3352, LR=0.000100
[2025-08-11 17:00:39,390][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033120] [Batch 03906/04869] [00:34:56/00:08:36, 0.537s/it]: train_loss_raw=0.4078, running_loss=0.3330, LR=0.000100
[2025-08-11 17:00:45,725][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033132] [Batch 03918/04869] [00:35:02/00:08:30, 0.537s/it]: train_loss_raw=0.3935, running_loss=0.3352, LR=0.000100
[2025-08-11 17:00:52,037][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033144] [Batch 03930/04869] [00:35:09/00:08:23, 0.537s/it]: train_loss_raw=0.3746, running_loss=0.3352, LR=0.000100
[2025-08-11 17:00:58,346][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033156] [Batch 03942/04869] [00:35:15/00:08:17, 0.537s/it]: train_loss_raw=0.4068, running_loss=0.3393, LR=0.000100
[2025-08-11 17:01:04,749][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033168] [Batch 03954/04869] [00:35:21/00:08:11, 0.537s/it]: train_loss_raw=0.2755, running_loss=0.3400, LR=0.000100
[2025-08-11 17:01:11,219][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033180] [Batch 03966/04869] [00:35:28/00:08:04, 0.537s/it]: train_loss_raw=0.3534, running_loss=0.3404, LR=0.000100
[2025-08-11 17:01:17,691][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033192] [Batch 03978/04869] [00:35:34/00:07:58, 0.537s/it]: train_loss_raw=0.3268, running_loss=0.3381, LR=0.000100
[2025-08-11 17:01:24,160][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033204] [Batch 03990/04869] [00:35:41/00:07:51, 0.537s/it]: train_loss_raw=0.3061, running_loss=0.3368, LR=0.000100
[2025-08-11 17:01:30,685][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033216] [Batch 04002/04869] [00:35:47/00:07:45, 0.537s/it]: train_loss_raw=0.3124, running_loss=0.3336, LR=0.000100
[2025-08-11 17:01:37,205][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033228] [Batch 04014/04869] [00:35:54/00:07:38, 0.537s/it]: train_loss_raw=0.2682, running_loss=0.3325, LR=0.000100
[2025-08-11 17:01:43,558][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033240] [Batch 04026/04869] [00:36:00/00:07:32, 0.537s/it]: train_loss_raw=0.3149, running_loss=0.3326, LR=0.000100
[2025-08-11 17:01:50,033][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033252] [Batch 04038/04869] [00:36:07/00:07:26, 0.537s/it]: train_loss_raw=0.4006, running_loss=0.3329, LR=0.000100
[2025-08-11 17:01:56,384][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033264] [Batch 04050/04869] [00:36:13/00:07:19, 0.537s/it]: train_loss_raw=0.4495, running_loss=0.3312, LR=0.000100
[2025-08-11 17:02:02,789][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033276] [Batch 04062/04869] [00:36:20/00:07:13, 0.537s/it]: train_loss_raw=0.3670, running_loss=0.3326, LR=0.000100
[2025-08-11 17:02:09,117][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033288] [Batch 04074/04869] [00:36:26/00:07:06, 0.537s/it]: train_loss_raw=0.2955, running_loss=0.3363, LR=0.000100
[2025-08-11 17:02:15,433][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033300] [Batch 04086/04869] [00:36:32/00:07:00, 0.537s/it]: train_loss_raw=0.3157, running_loss=0.3374, LR=0.000100
[2025-08-11 17:02:21,866][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033312] [Batch 04098/04869] [00:36:39/00:06:53, 0.537s/it]: train_loss_raw=0.2583, running_loss=0.3340, LR=0.000100
[2025-08-11 17:02:28,254][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033324] [Batch 04110/04869] [00:36:45/00:06:47, 0.537s/it]: train_loss_raw=0.3658, running_loss=0.3376, LR=0.000100
[2025-08-11 17:02:34,588][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033336] [Batch 04122/04869] [00:36:51/00:06:40, 0.537s/it]: train_loss_raw=0.3186, running_loss=0.3371, LR=0.000100
[2025-08-11 17:02:40,968][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033348] [Batch 04134/04869] [00:36:58/00:06:34, 0.537s/it]: train_loss_raw=0.3287, running_loss=0.3389, LR=0.000100
[2025-08-11 17:02:47,317][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033360] [Batch 04146/04869] [00:37:04/00:06:27, 0.537s/it]: train_loss_raw=0.3753, running_loss=0.3401, LR=0.000100
[2025-08-11 17:02:53,636][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033372] [Batch 04158/04869] [00:37:10/00:06:21, 0.537s/it]: train_loss_raw=0.2867, running_loss=0.3387, LR=0.000100
[2025-08-11 17:03:00,059][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033384] [Batch 04170/04869] [00:37:17/00:06:15, 0.537s/it]: train_loss_raw=0.3135, running_loss=0.3386, LR=0.000100
[2025-08-11 17:03:06,388][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033396] [Batch 04182/04869] [00:37:23/00:06:08, 0.536s/it]: train_loss_raw=0.4049, running_loss=0.3370, LR=0.000100
[2025-08-11 17:03:12,725][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033408] [Batch 04194/04869] [00:37:29/00:06:02, 0.536s/it]: train_loss_raw=0.2832, running_loss=0.3349, LR=0.000100
[2025-08-11 17:03:19,268][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033420] [Batch 04206/04869] [00:37:36/00:05:55, 0.536s/it]: train_loss_raw=0.3233, running_loss=0.3374, LR=0.000100
[2025-08-11 17:03:25,742][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033432] [Batch 04218/04869] [00:37:42/00:05:49, 0.537s/it]: train_loss_raw=0.3667, running_loss=0.3389, LR=0.000100
[2025-08-11 17:03:32,124][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033444] [Batch 04230/04869] [00:37:49/00:05:42, 0.536s/it]: train_loss_raw=0.4200, running_loss=0.3404, LR=0.000100
[2025-08-11 17:03:38,447][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033456] [Batch 04242/04869] [00:37:55/00:05:36, 0.536s/it]: train_loss_raw=0.2742, running_loss=0.3359, LR=0.000100
[2025-08-11 17:03:44,806][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033468] [Batch 04254/04869] [00:38:02/00:05:29, 0.536s/it]: train_loss_raw=0.3427, running_loss=0.3356, LR=0.000100
[2025-08-11 17:03:51,039][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033480] [Batch 04266/04869] [00:38:08/00:05:23, 0.536s/it]: train_loss_raw=0.3016, running_loss=0.3358, LR=0.000100
[2025-08-11 17:03:57,410][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033492] [Batch 04278/04869] [00:38:14/00:05:17, 0.536s/it]: train_loss_raw=0.3314, running_loss=0.3350, LR=0.000100
[2025-08-11 17:04:03,795][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033504] [Batch 04290/04869] [00:38:21/00:05:10, 0.536s/it]: train_loss_raw=0.3063, running_loss=0.3343, LR=0.000100
[2025-08-11 17:04:10,068][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033516] [Batch 04302/04869] [00:38:27/00:05:04, 0.536s/it]: train_loss_raw=0.3174, running_loss=0.3319, LR=0.000100
[2025-08-11 17:04:16,440][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033528] [Batch 04314/04869] [00:38:33/00:04:57, 0.536s/it]: train_loss_raw=0.3091, running_loss=0.3321, LR=0.000100
[2025-08-11 17:04:22,772][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033540] [Batch 04326/04869] [00:38:40/00:04:51, 0.536s/it]: train_loss_raw=0.3253, running_loss=0.3333, LR=0.000100
[2025-08-11 17:04:29,217][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033552] [Batch 04338/04869] [00:38:46/00:04:44, 0.536s/it]: train_loss_raw=0.3333, running_loss=0.3351, LR=0.000100
[2025-08-11 17:04:35,595][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033564] [Batch 04350/04869] [00:38:52/00:04:38, 0.536s/it]: train_loss_raw=0.3742, running_loss=0.3366, LR=0.000100
[2025-08-11 17:04:41,970][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033576] [Batch 04362/04869] [00:38:59/00:04:31, 0.536s/it]: train_loss_raw=0.2445, running_loss=0.3350, LR=0.000100
[2025-08-11 17:04:48,245][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033588] [Batch 04374/04869] [00:39:05/00:04:25, 0.536s/it]: train_loss_raw=0.2770, running_loss=0.3329, LR=0.000100
[2025-08-11 17:04:54,537][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033600] [Batch 04386/04869] [00:39:11/00:04:18, 0.536s/it]: train_loss_raw=0.3208, running_loss=0.3313, LR=0.000100
[2025-08-11 17:05:00,985][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033612] [Batch 04398/04869] [00:39:18/00:04:12, 0.536s/it]: train_loss_raw=0.3201, running_loss=0.3282, LR=0.000100
[2025-08-11 17:05:07,375][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033624] [Batch 04410/04869] [00:39:24/00:04:06, 0.536s/it]: train_loss_raw=0.4483, running_loss=0.3308, LR=0.000100
[2025-08-11 17:05:13,657][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033636] [Batch 04422/04869] [00:39:30/00:03:59, 0.536s/it]: train_loss_raw=0.3085, running_loss=0.3286, LR=0.000100
[2025-08-11 17:05:19,989][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033648] [Batch 04434/04869] [00:39:37/00:03:53, 0.536s/it]: train_loss_raw=0.2810, running_loss=0.3283, LR=0.000100
[2025-08-11 17:05:26,298][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033660] [Batch 04446/04869] [00:39:43/00:03:46, 0.536s/it]: train_loss_raw=0.3160, running_loss=0.3289, LR=0.000100
[2025-08-11 17:05:32,734][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033672] [Batch 04458/04869] [00:39:49/00:03:40, 0.536s/it]: train_loss_raw=0.4126, running_loss=0.3330, LR=0.000100
[2025-08-11 17:05:39,069][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033684] [Batch 04470/04869] [00:39:56/00:03:33, 0.536s/it]: train_loss_raw=0.3070, running_loss=0.3304, LR=0.000100
[2025-08-11 17:05:45,407][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033696] [Batch 04482/04869] [00:40:02/00:03:27, 0.536s/it]: train_loss_raw=0.3531, running_loss=0.3305, LR=0.000100
[2025-08-11 17:05:51,790][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033708] [Batch 04494/04869] [00:40:09/00:03:21, 0.536s/it]: train_loss_raw=0.3140, running_loss=0.3299, LR=0.000100
[2025-08-11 17:05:58,118][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033720] [Batch 04506/04869] [00:40:15/00:03:14, 0.536s/it]: train_loss_raw=0.3573, running_loss=0.3312, LR=0.000100
[2025-08-11 17:06:04,524][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033732] [Batch 04518/04869] [00:40:21/00:03:08, 0.536s/it]: train_loss_raw=0.2790, running_loss=0.3314, LR=0.000100
[2025-08-11 17:06:10,922][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033744] [Batch 04530/04869] [00:40:28/00:03:01, 0.536s/it]: train_loss_raw=0.3371, running_loss=0.3318, LR=0.000100
[2025-08-11 17:06:17,338][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033756] [Batch 04542/04869] [00:40:34/00:02:55, 0.536s/it]: train_loss_raw=0.3104, running_loss=0.3305, LR=0.000100
[2025-08-11 17:06:23,739][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033768] [Batch 04554/04869] [00:40:40/00:02:48, 0.536s/it]: train_loss_raw=0.2911, running_loss=0.3265, LR=0.000100
[2025-08-11 17:06:30,168][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033780] [Batch 04566/04869] [00:40:47/00:02:42, 0.536s/it]: train_loss_raw=0.5307, running_loss=0.3275, LR=0.000100
[2025-08-11 17:06:36,596][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033792] [Batch 04578/04869] [00:40:53/00:02:35, 0.536s/it]: train_loss_raw=0.2825, running_loss=0.3272, LR=0.000100
[2025-08-11 17:06:42,975][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033804] [Batch 04590/04869] [00:41:00/00:02:29, 0.536s/it]: train_loss_raw=0.3228, running_loss=0.3283, LR=0.000100
[2025-08-11 17:06:49,309][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033816] [Batch 04602/04869] [00:41:06/00:02:23, 0.536s/it]: train_loss_raw=0.4167, running_loss=0.3303, LR=0.000100
[2025-08-11 17:06:55,687][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033828] [Batch 04614/04869] [00:41:12/00:02:16, 0.536s/it]: train_loss_raw=0.2938, running_loss=0.3280, LR=0.000100
[2025-08-11 17:07:02,204][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033840] [Batch 04626/04869] [00:41:19/00:02:10, 0.536s/it]: train_loss_raw=0.2846, running_loss=0.3262, LR=0.000100
[2025-08-11 17:07:08,722][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033852] [Batch 04638/04869] [00:41:25/00:02:03, 0.536s/it]: train_loss_raw=0.3099, running_loss=0.3281, LR=0.000100
[2025-08-11 17:07:15,150][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033864] [Batch 04650/04869] [00:41:32/00:01:57, 0.536s/it]: train_loss_raw=0.2758, running_loss=0.3271, LR=0.000100
[2025-08-11 17:07:21,657][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033876] [Batch 04662/04869] [00:41:38/00:01:50, 0.536s/it]: train_loss_raw=0.3638, running_loss=0.3312, LR=0.000100
[2025-08-11 17:07:28,201][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033888] [Batch 04674/04869] [00:41:45/00:01:44, 0.536s/it]: train_loss_raw=0.2580, running_loss=0.3274, LR=0.000100
[2025-08-11 17:07:34,744][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033900] [Batch 04686/04869] [00:41:51/00:01:38, 0.536s/it]: train_loss_raw=0.3830, running_loss=0.3298, LR=0.000100
[2025-08-11 17:07:41,277][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033912] [Batch 04698/04869] [00:41:58/00:01:31, 0.536s/it]: train_loss_raw=0.4154, running_loss=0.3296, LR=0.000100
[2025-08-11 17:07:47,811][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033924] [Batch 04710/04869] [00:42:05/00:01:25, 0.536s/it]: train_loss_raw=0.2702, running_loss=0.3306, LR=0.000100
[2025-08-11 17:07:54,270][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033936] [Batch 04722/04869] [00:42:11/00:01:18, 0.536s/it]: train_loss_raw=0.2799, running_loss=0.3299, LR=0.000100
[2025-08-11 17:08:00,778][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033948] [Batch 04734/04869] [00:42:18/00:01:12, 0.536s/it]: train_loss_raw=0.3988, running_loss=0.3305, LR=0.000100
[2025-08-11 17:08:07,205][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033960] [Batch 04746/04869] [00:42:24/00:01:05, 0.536s/it]: train_loss_raw=0.2745, running_loss=0.3319, LR=0.000100
[2025-08-11 17:08:13,669][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033972] [Batch 04758/04869] [00:42:30/00:00:59, 0.536s/it]: train_loss_raw=0.3209, running_loss=0.3310, LR=0.000100
[2025-08-11 17:08:20,153][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033984] [Batch 04770/04869] [00:42:37/00:00:53, 0.536s/it]: train_loss_raw=0.3860, running_loss=0.3307, LR=0.000100
[2025-08-11 17:08:26,525][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033996] [Batch 04782/04869] [00:42:43/00:00:46, 0.536s/it]: train_loss_raw=0.4703, running_loss=0.3322, LR=0.000100
[2025-08-11 17:08:38,057][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034008] [Batch 04794/04869] [00:42:55/00:00:40, 0.537s/it]: train_loss_raw=0.3240, running_loss=0.3298, LR=0.000100
[2025-08-11 17:08:44,450][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034020] [Batch 04806/04869] [00:43:01/00:00:33, 0.537s/it]: train_loss_raw=0.3454, running_loss=0.3286, LR=0.000100
[2025-08-11 17:08:50,773][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034032] [Batch 04818/04869] [00:43:08/00:00:27, 0.537s/it]: train_loss_raw=0.2494, running_loss=0.3277, LR=0.000100
[2025-08-11 17:08:57,165][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034044] [Batch 04830/04869] [00:43:14/00:00:20, 0.537s/it]: train_loss_raw=0.3382, running_loss=0.3262, LR=0.000100
[2025-08-11 17:09:03,507][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034056] [Batch 04842/04869] [00:43:20/00:00:14, 0.537s/it]: train_loss_raw=0.2923, running_loss=0.3281, LR=0.000100
[2025-08-11 17:09:09,821][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034068] [Batch 04854/04869] [00:43:27/00:00:08, 0.537s/it]: train_loss_raw=0.3284, running_loss=0.3285, LR=0.000100
[2025-08-11 17:09:16,138][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034080] [Batch 04866/04869] [00:43:33/00:00:01, 0.537s/it]: train_loss_raw=0.3498, running_loss=0.3287, LR=0.000100
[2025-08-11 17:09:22,562][__main__][INFO] - [VALIDATION] [Epoch 06/29] Starting validation.
[2025-08-11 17:09:36,982][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00011/00062] [00:00:14/00:01:00, 1.202s/it]
[2025-08-11 17:10:10,143][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00023/00062] [00:00:47/00:01:15, 1.983s/it]
[2025-08-11 17:10:25,992][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00035/00062] [00:01:03/00:00:45, 1.762s/it]
[2025-08-11 17:10:42,186][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00047/00062] [00:01:19/00:00:23, 1.659s/it]
[2025-08-11 17:10:56,847][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00059/00062] [00:01:34/00:00:03, 1.571s/it]
[2025-08-11 17:10:58,965][__main__][INFO] - [VALIDATION] [Epoch 06/29] train_loss=0.32864, valid_loss=0.37727
[2025-08-11 17:10:58,966][__main__][INFO] - [VALIDATION] [Epoch 06/29] Metrics:
[2025-08-11 17:10:58,966][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_er      0.189
[2025-08-11 17:10:58,966][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_prec    0.633
[2025-08-11 17:10:58,966][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_recall  0.639
[2025-08-11 17:10:58,966][__main__][INFO] - [VALIDATION] [Epoch 06/29] - pep_recall 0.600
[2025-08-11 17:10:58,970][__main__][INFO] - [TRAIN] [Epoch 06/29] Epoch complete, total time 05:15:37, remaining time 17:17:03, 00:45:05 per epoch
[2025-08-11 17:11:03,525][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034092] [Batch 00009/04869] [00:00:04/00:38:52, 0.480s/it]: train_loss_raw=0.3037, running_loss=0.3317, LR=0.000100
[2025-08-11 17:11:09,893][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034104] [Batch 00021/04869] [00:00:10/00:41:07, 0.509s/it]: train_loss_raw=0.3799, running_loss=0.3329, LR=0.000100
[2025-08-11 17:11:16,129][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034116] [Batch 00033/04869] [00:00:16/00:41:20, 0.513s/it]: train_loss_raw=0.3900, running_loss=0.3342, LR=0.000100
[2025-08-11 17:11:22,457][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034128] [Batch 00045/04869] [00:00:23/00:41:32, 0.517s/it]: train_loss_raw=0.3695, running_loss=0.3365, LR=0.000100
[2025-08-11 17:11:28,821][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034140] [Batch 00057/04869] [00:00:29/00:41:40, 0.520s/it]: train_loss_raw=0.3364, running_loss=0.3366, LR=0.000100
[2025-08-11 17:11:35,165][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034152] [Batch 00069/04869] [00:00:35/00:41:41, 0.521s/it]: train_loss_raw=0.3983, running_loss=0.3329, LR=0.000100
[2025-08-11 17:11:41,563][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034164] [Batch 00081/04869] [00:00:42/00:41:43, 0.523s/it]: train_loss_raw=0.2789, running_loss=0.3315, LR=0.000100
[2025-08-11 17:11:48,009][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034176] [Batch 00093/04869] [00:00:48/00:41:46, 0.525s/it]: train_loss_raw=0.3844, running_loss=0.3333, LR=0.000100
[2025-08-11 17:11:54,390][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034188] [Batch 00105/04869] [00:00:55/00:41:43, 0.526s/it]: train_loss_raw=0.3891, running_loss=0.3346, LR=0.000100
[2025-08-11 17:12:00,867][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034200] [Batch 00117/04869] [00:01:01/00:41:44, 0.527s/it]: train_loss_raw=0.4251, running_loss=0.3348, LR=0.000100
[2025-08-11 17:12:07,427][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034212] [Batch 00129/04869] [00:01:08/00:41:46, 0.529s/it]: train_loss_raw=0.3085, running_loss=0.3348, LR=0.000100
[2025-08-11 17:12:13,936][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034224] [Batch 00141/04869] [00:01:14/00:41:45, 0.530s/it]: train_loss_raw=0.3573, running_loss=0.3335, LR=0.000100
[2025-08-11 17:12:20,329][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034236] [Batch 00153/04869] [00:01:21/00:41:40, 0.530s/it]: train_loss_raw=0.3782, running_loss=0.3324, LR=0.000100
[2025-08-11 17:12:26,709][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034248] [Batch 00165/04869] [00:01:27/00:41:34, 0.530s/it]: train_loss_raw=0.3878, running_loss=0.3320, LR=0.000100
[2025-08-11 17:12:33,071][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034260] [Batch 00177/04869] [00:01:33/00:41:28, 0.530s/it]: train_loss_raw=0.3572, running_loss=0.3296, LR=0.000100
[2025-08-11 17:12:39,516][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034272] [Batch 00189/04869] [00:01:40/00:41:23, 0.531s/it]: train_loss_raw=0.2662, running_loss=0.3276, LR=0.000100
[2025-08-11 17:12:46,016][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034284] [Batch 00201/04869] [00:01:46/00:41:20, 0.531s/it]: train_loss_raw=0.3407, running_loss=0.3289, LR=0.000100
[2025-08-11 17:12:52,406][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034296] [Batch 00213/04869] [00:01:53/00:41:14, 0.531s/it]: train_loss_raw=0.3059, running_loss=0.3297, LR=0.000100
[2025-08-11 17:12:58,767][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034308] [Batch 00225/04869] [00:01:59/00:41:07, 0.531s/it]: train_loss_raw=0.3108, running_loss=0.3312, LR=0.000100
[2025-08-11 17:13:05,133][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034320] [Batch 00237/04869] [00:02:05/00:41:01, 0.531s/it]: train_loss_raw=0.4224, running_loss=0.3310, LR=0.000100
[2025-08-11 17:13:11,511][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034332] [Batch 00249/04869] [00:02:12/00:40:54, 0.531s/it]: train_loss_raw=0.2342, running_loss=0.3296, LR=0.000100
[2025-08-11 17:13:17,853][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034344] [Batch 00261/04869] [00:02:18/00:40:47, 0.531s/it]: train_loss_raw=0.2792, running_loss=0.3298, LR=0.000100
[2025-08-11 17:13:24,155][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034356] [Batch 00273/04869] [00:02:24/00:40:40, 0.531s/it]: train_loss_raw=0.4407, running_loss=0.3315, LR=0.000100
[2025-08-11 17:13:30,616][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034368] [Batch 00285/04869] [00:02:31/00:40:35, 0.531s/it]: train_loss_raw=0.2907, running_loss=0.3322, LR=0.000100
[2025-08-11 17:13:37,024][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034380] [Batch 00297/04869] [00:02:37/00:40:29, 0.531s/it]: train_loss_raw=0.3222, running_loss=0.3344, LR=0.000100
[2025-08-11 17:13:43,345][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034392] [Batch 00309/04869] [00:02:44/00:40:22, 0.531s/it]: train_loss_raw=0.3312, running_loss=0.3303, LR=0.000100
[2025-08-11 17:13:49,659][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034404] [Batch 00321/04869] [00:02:50/00:40:15, 0.531s/it]: train_loss_raw=0.3904, running_loss=0.3281, LR=0.000100
[2025-08-11 17:13:56,085][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034416] [Batch 00333/04869] [00:02:56/00:40:09, 0.531s/it]: train_loss_raw=0.3917, running_loss=0.3301, LR=0.000100
[2025-08-11 17:14:02,455][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034428] [Batch 00345/04869] [00:03:03/00:40:02, 0.531s/it]: train_loss_raw=0.4077, running_loss=0.3309, LR=0.000100
[2025-08-11 17:14:08,827][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034440] [Batch 00357/04869] [00:03:09/00:39:56, 0.531s/it]: train_loss_raw=0.3386, running_loss=0.3334, LR=0.000100
[2025-08-11 17:14:15,092][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034452] [Batch 00369/04869] [00:03:15/00:39:48, 0.531s/it]: train_loss_raw=0.2670, running_loss=0.3311, LR=0.000100
[2025-08-11 17:14:21,472][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034464] [Batch 00381/04869] [00:03:22/00:39:42, 0.531s/it]: train_loss_raw=0.2800, running_loss=0.3331, LR=0.000100
[2025-08-11 17:14:27,841][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034476] [Batch 00393/04869] [00:03:28/00:39:36, 0.531s/it]: train_loss_raw=0.4017, running_loss=0.3333, LR=0.000100
[2025-08-11 17:14:34,207][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034488] [Batch 00405/04869] [00:03:35/00:39:29, 0.531s/it]: train_loss_raw=0.3137, running_loss=0.3325, LR=0.000100
[2025-08-11 17:14:40,742][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034500] [Batch 00417/04869] [00:03:41/00:39:25, 0.531s/it]: train_loss_raw=0.4048, running_loss=0.3325, LR=0.000100
[2025-08-11 17:14:47,249][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034512] [Batch 00429/04869] [00:03:48/00:39:20, 0.532s/it]: train_loss_raw=0.3329, running_loss=0.3328, LR=0.000100
[2025-08-11 17:14:53,677][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034524] [Batch 00441/04869] [00:03:54/00:39:14, 0.532s/it]: train_loss_raw=0.3754, running_loss=0.3305, LR=0.000100
[2025-08-11 17:14:59,996][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034536] [Batch 00453/04869] [00:04:00/00:39:07, 0.532s/it]: train_loss_raw=0.2517, running_loss=0.3292, LR=0.000100
[2025-08-11 17:15:06,373][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034548] [Batch 00465/04869] [00:04:07/00:39:00, 0.532s/it]: train_loss_raw=0.3618, running_loss=0.3298, LR=0.000100
[2025-08-11 17:15:12,758][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034560] [Batch 00477/04869] [00:04:13/00:38:54, 0.532s/it]: train_loss_raw=0.3001, running_loss=0.3329, LR=0.000100
[2025-08-11 17:15:19,136][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034572] [Batch 00489/04869] [00:04:19/00:38:48, 0.532s/it]: train_loss_raw=0.2679, running_loss=0.3323, LR=0.000100
[2025-08-11 17:15:25,536][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034584] [Batch 00501/04869] [00:04:26/00:38:42, 0.532s/it]: train_loss_raw=0.3211, running_loss=0.3359, LR=0.000100
[2025-08-11 17:15:31,900][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034596] [Batch 00513/04869] [00:04:32/00:38:35, 0.532s/it]: train_loss_raw=0.2661, running_loss=0.3366, LR=0.000100
[2025-08-11 17:15:38,273][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034608] [Batch 00525/04869] [00:04:39/00:38:29, 0.532s/it]: train_loss_raw=0.3282, running_loss=0.3355, LR=0.000100
[2025-08-11 17:15:44,668][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034620] [Batch 00537/04869] [00:04:45/00:38:22, 0.532s/it]: train_loss_raw=0.4110, running_loss=0.3370, LR=0.000100
[2025-08-11 17:15:51,037][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034632] [Batch 00549/04869] [00:04:51/00:38:16, 0.532s/it]: train_loss_raw=0.3785, running_loss=0.3379, LR=0.000100
[2025-08-11 17:15:57,396][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034644] [Batch 00561/04869] [00:04:58/00:38:09, 0.532s/it]: train_loss_raw=0.2317, running_loss=0.3354, LR=0.000100
[2025-08-11 17:16:03,816][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034656] [Batch 00573/04869] [00:05:04/00:38:03, 0.532s/it]: train_loss_raw=0.3010, running_loss=0.3329, LR=0.000100
[2025-08-11 17:16:10,242][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034668] [Batch 00585/04869] [00:05:11/00:37:57, 0.532s/it]: train_loss_raw=0.3986, running_loss=0.3344, LR=0.000100
[2025-08-11 17:16:16,545][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034680] [Batch 00597/04869] [00:05:17/00:37:50, 0.532s/it]: train_loss_raw=0.2823, running_loss=0.3325, LR=0.000100
[2025-08-11 17:16:22,968][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034692] [Batch 00609/04869] [00:05:23/00:37:44, 0.532s/it]: train_loss_raw=0.3162, running_loss=0.3337, LR=0.000100
[2025-08-11 17:16:29,288][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034704] [Batch 00621/04869] [00:05:30/00:37:37, 0.532s/it]: train_loss_raw=0.3140, running_loss=0.3324, LR=0.000100
[2025-08-11 17:16:35,632][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034716] [Batch 00633/04869] [00:05:36/00:37:31, 0.531s/it]: train_loss_raw=0.3385, running_loss=0.3331, LR=0.000100
[2025-08-11 17:16:41,981][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034728] [Batch 00645/04869] [00:05:42/00:37:24, 0.531s/it]: train_loss_raw=0.3433, running_loss=0.3380, LR=0.000100
[2025-08-11 17:16:48,347][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034740] [Batch 00657/04869] [00:05:49/00:37:18, 0.531s/it]: train_loss_raw=0.3112, running_loss=0.3363, LR=0.000100
[2025-08-11 17:16:54,676][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034752] [Batch 00669/04869] [00:05:55/00:37:11, 0.531s/it]: train_loss_raw=0.3606, running_loss=0.3366, LR=0.000100
[2025-08-11 17:17:01,035][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034764] [Batch 00681/04869] [00:06:01/00:37:05, 0.531s/it]: train_loss_raw=0.3876, running_loss=0.3372, LR=0.000100
[2025-08-11 17:17:07,551][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034776] [Batch 00693/04869] [00:06:08/00:36:59, 0.532s/it]: train_loss_raw=0.3419, running_loss=0.3359, LR=0.000100
[2025-08-11 17:17:13,885][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034788] [Batch 00705/04869] [00:06:14/00:36:53, 0.531s/it]: train_loss_raw=0.3846, running_loss=0.3360, LR=0.000100
[2025-08-11 17:17:20,319][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034800] [Batch 00717/04869] [00:06:21/00:36:46, 0.532s/it]: train_loss_raw=0.2732, running_loss=0.3331, LR=0.000100
[2025-08-11 17:17:26,697][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034812] [Batch 00729/04869] [00:06:27/00:36:40, 0.532s/it]: train_loss_raw=0.3630, running_loss=0.3344, LR=0.000100
[2025-08-11 17:17:33,168][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034824] [Batch 00741/04869] [00:06:33/00:36:34, 0.532s/it]: train_loss_raw=0.4347, running_loss=0.3341, LR=0.000100
[2025-08-11 17:17:39,649][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034836] [Batch 00753/04869] [00:06:40/00:36:28, 0.532s/it]: train_loss_raw=0.3306, running_loss=0.3300, LR=0.000100
[2025-08-11 17:17:46,199][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034848] [Batch 00765/04869] [00:06:46/00:36:23, 0.532s/it]: train_loss_raw=0.4409, running_loss=0.3305, LR=0.000100
[2025-08-11 17:17:52,563][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034860] [Batch 00777/04869] [00:06:53/00:36:16, 0.532s/it]: train_loss_raw=0.3061, running_loss=0.3316, LR=0.000100
[2025-08-11 17:17:58,736][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034872] [Batch 00789/04869] [00:06:59/00:36:09, 0.532s/it]: train_loss_raw=0.2821, running_loss=0.3314, LR=0.000100
[2025-08-11 17:18:05,032][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034884] [Batch 00801/04869] [00:07:05/00:36:02, 0.532s/it]: train_loss_raw=0.3957, running_loss=0.3338, LR=0.000100
[2025-08-11 17:18:11,392][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034896] [Batch 00813/04869] [00:07:12/00:35:56, 0.532s/it]: train_loss_raw=0.2821, running_loss=0.3316, LR=0.000100
[2025-08-11 17:18:17,639][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034908] [Batch 00825/04869] [00:07:18/00:35:49, 0.531s/it]: train_loss_raw=0.3546, running_loss=0.3315, LR=0.000100
[2025-08-11 17:18:23,818][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034920] [Batch 00837/04869] [00:07:24/00:35:41, 0.531s/it]: train_loss_raw=0.3805, running_loss=0.3322, LR=0.000100
[2025-08-11 17:18:30,080][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034932] [Batch 00849/04869] [00:07:30/00:35:34, 0.531s/it]: train_loss_raw=0.2961, running_loss=0.3333, LR=0.000100
[2025-08-11 17:18:36,329][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034944] [Batch 00861/04869] [00:07:37/00:35:27, 0.531s/it]: train_loss_raw=0.2716, running_loss=0.3322, LR=0.000100
[2025-08-11 17:18:42,746][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034956] [Batch 00873/04869] [00:07:43/00:35:21, 0.531s/it]: train_loss_raw=0.2859, running_loss=0.3307, LR=0.000100
[2025-08-11 17:18:49,014][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034968] [Batch 00885/04869] [00:07:49/00:35:14, 0.531s/it]: train_loss_raw=0.2995, running_loss=0.3306, LR=0.000100
[2025-08-11 17:18:55,551][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034980] [Batch 00897/04869] [00:07:56/00:35:09, 0.531s/it]: train_loss_raw=0.3941, running_loss=0.3339, LR=0.000100
[2025-08-11 17:19:01,690][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034992] [Batch 00909/04869] [00:08:02/00:35:01, 0.531s/it]: train_loss_raw=0.2627, running_loss=0.3342, LR=0.000100
[2025-08-11 17:19:07,919][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035004] [Batch 00921/04869] [00:08:08/00:34:54, 0.531s/it]: train_loss_raw=0.3679, running_loss=0.3328, LR=0.000100
[2025-08-11 17:19:14,155][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035016] [Batch 00933/04869] [00:08:14/00:34:48, 0.530s/it]: train_loss_raw=0.3441, running_loss=0.3347, LR=0.000100
[2025-08-11 17:19:20,343][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035028] [Batch 00945/04869] [00:08:21/00:34:40, 0.530s/it]: train_loss_raw=0.3039, running_loss=0.3336, LR=0.000100
[2025-08-11 17:19:26,455][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035040] [Batch 00957/04869] [00:08:27/00:34:33, 0.530s/it]: train_loss_raw=0.3590, running_loss=0.3317, LR=0.000100
[2025-08-11 17:19:32,578][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035052] [Batch 00969/04869] [00:08:33/00:34:26, 0.530s/it]: train_loss_raw=0.2753, running_loss=0.3309, LR=0.000100
[2025-08-11 17:19:38,869][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035064] [Batch 00981/04869] [00:08:39/00:34:19, 0.530s/it]: train_loss_raw=0.3638, running_loss=0.3316, LR=0.000100
[2025-08-11 17:19:45,406][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035076] [Batch 00993/04869] [00:08:46/00:34:13, 0.530s/it]: train_loss_raw=0.3749, running_loss=0.3326, LR=0.000100
[2025-08-11 17:19:51,992][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035088] [Batch 01005/04869] [00:08:52/00:34:08, 0.530s/it]: train_loss_raw=0.3788, running_loss=0.3334, LR=0.000100
[2025-08-11 17:19:58,357][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035100] [Batch 01017/04869] [00:08:59/00:34:02, 0.530s/it]: train_loss_raw=0.3555, running_loss=0.3330, LR=0.000100
[2025-08-11 17:20:04,764][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035112] [Batch 01029/04869] [00:09:05/00:33:55, 0.530s/it]: train_loss_raw=0.3310, running_loss=0.3353, LR=0.000100
[2025-08-11 17:20:11,295][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035124] [Batch 01041/04869] [00:09:12/00:33:50, 0.530s/it]: train_loss_raw=0.3469, running_loss=0.3359, LR=0.000100
[2025-08-11 17:20:17,821][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035136] [Batch 01053/04869] [00:09:18/00:33:44, 0.530s/it]: train_loss_raw=0.3051, running_loss=0.3353, LR=0.000100
[2025-08-11 17:20:24,289][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035148] [Batch 01065/04869] [00:09:25/00:33:38, 0.531s/it]: train_loss_raw=0.2979, running_loss=0.3370, LR=0.000100
[2025-08-11 17:20:30,863][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035160] [Batch 01077/04869] [00:09:31/00:33:32, 0.531s/it]: train_loss_raw=0.2944, running_loss=0.3369, LR=0.000100
[2025-08-11 17:20:37,311][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035172] [Batch 01089/04869] [00:09:38/00:33:26, 0.531s/it]: train_loss_raw=0.3235, running_loss=0.3370, LR=0.000100
[2025-08-11 17:20:43,805][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035184] [Batch 01101/04869] [00:09:44/00:33:20, 0.531s/it]: train_loss_raw=0.2891, running_loss=0.3324, LR=0.000100
[2025-08-11 17:20:50,289][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035196] [Batch 01113/04869] [00:09:51/00:33:14, 0.531s/it]: train_loss_raw=0.3041, running_loss=0.3342, LR=0.000100
[2025-08-11 17:20:56,778][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035208] [Batch 01125/04869] [00:09:57/00:33:08, 0.531s/it]: train_loss_raw=0.3874, running_loss=0.3323, LR=0.000100
[2025-08-11 17:21:03,085][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035220] [Batch 01137/04869] [00:10:03/00:33:02, 0.531s/it]: train_loss_raw=0.3715, running_loss=0.3337, LR=0.000100
[2025-08-11 17:21:09,509][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035232] [Batch 01149/04869] [00:10:10/00:32:55, 0.531s/it]: train_loss_raw=0.3714, running_loss=0.3349, LR=0.000100
[2025-08-11 17:21:15,917][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035244] [Batch 01161/04869] [00:10:16/00:32:49, 0.531s/it]: train_loss_raw=0.3735, running_loss=0.3371, LR=0.000100
[2025-08-11 17:21:22,497][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035256] [Batch 01173/04869] [00:10:23/00:32:43, 0.531s/it]: train_loss_raw=0.3089, running_loss=0.3357, LR=0.000100
[2025-08-11 17:21:28,909][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035268] [Batch 01185/04869] [00:10:29/00:32:37, 0.531s/it]: train_loss_raw=0.3305, running_loss=0.3391, LR=0.000100
[2025-08-11 17:21:35,094][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035280] [Batch 01197/04869] [00:10:35/00:32:30, 0.531s/it]: train_loss_raw=0.2979, running_loss=0.3378, LR=0.000100
[2025-08-11 17:21:41,359][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035292] [Batch 01209/04869] [00:10:42/00:32:23, 0.531s/it]: train_loss_raw=0.3419, running_loss=0.3357, LR=0.000100
[2025-08-11 17:21:47,582][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035304] [Batch 01221/04869] [00:10:48/00:32:17, 0.531s/it]: train_loss_raw=0.3352, running_loss=0.3361, LR=0.000100
[2025-08-11 17:21:53,971][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035316] [Batch 01233/04869] [00:10:54/00:32:10, 0.531s/it]: train_loss_raw=0.3150, running_loss=0.3320, LR=0.000100
[2025-08-11 17:22:00,365][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035328] [Batch 01245/04869] [00:11:01/00:32:04, 0.531s/it]: train_loss_raw=0.3301, running_loss=0.3298, LR=0.000100
[2025-08-11 17:22:06,864][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035340] [Batch 01257/04869] [00:11:07/00:31:58, 0.531s/it]: train_loss_raw=0.2913, running_loss=0.3296, LR=0.000100
[2025-08-11 17:22:13,263][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035352] [Batch 01269/04869] [00:11:14/00:31:52, 0.531s/it]: train_loss_raw=0.3219, running_loss=0.3267, LR=0.000100
[2025-08-11 17:22:19,581][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035364] [Batch 01281/04869] [00:11:20/00:31:45, 0.531s/it]: train_loss_raw=0.2820, running_loss=0.3264, LR=0.000100
[2025-08-11 17:22:25,897][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035376] [Batch 01293/04869] [00:11:26/00:31:39, 0.531s/it]: train_loss_raw=0.3378, running_loss=0.3268, LR=0.000100
[2025-08-11 17:22:32,237][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035388] [Batch 01305/04869] [00:11:33/00:31:32, 0.531s/it]: train_loss_raw=0.2617, running_loss=0.3297, LR=0.000100
[2025-08-11 17:22:38,689][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035400] [Batch 01317/04869] [00:11:39/00:31:26, 0.531s/it]: train_loss_raw=0.2472, running_loss=0.3295, LR=0.000100
[2025-08-11 17:22:45,084][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035412] [Batch 01329/04869] [00:11:45/00:31:20, 0.531s/it]: train_loss_raw=0.3182, running_loss=0.3315, LR=0.000100
[2025-08-11 17:22:51,534][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035424] [Batch 01341/04869] [00:11:52/00:31:14, 0.531s/it]: train_loss_raw=0.4445, running_loss=0.3349, LR=0.000100
[2025-08-11 17:22:57,910][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035436] [Batch 01353/04869] [00:11:58/00:31:07, 0.531s/it]: train_loss_raw=0.3323, running_loss=0.3359, LR=0.000100
[2025-08-11 17:23:04,311][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035448] [Batch 01365/04869] [00:12:05/00:31:01, 0.531s/it]: train_loss_raw=0.2929, running_loss=0.3379, LR=0.000100
[2025-08-11 17:23:10,588][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035460] [Batch 01377/04869] [00:12:11/00:30:54, 0.531s/it]: train_loss_raw=0.3182, running_loss=0.3358, LR=0.000100
[2025-08-11 17:23:16,939][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035472] [Batch 01389/04869] [00:12:17/00:30:48, 0.531s/it]: train_loss_raw=0.3073, running_loss=0.3352, LR=0.000100
[2025-08-11 17:23:23,273][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035484] [Batch 01401/04869] [00:12:24/00:30:41, 0.531s/it]: train_loss_raw=0.3841, running_loss=0.3351, LR=0.000100
[2025-08-11 17:23:29,739][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035496] [Batch 01413/04869] [00:12:30/00:30:35, 0.531s/it]: train_loss_raw=0.2790, running_loss=0.3341, LR=0.000100
[2025-08-11 17:23:36,243][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035508] [Batch 01425/04869] [00:12:37/00:30:29, 0.531s/it]: train_loss_raw=0.3471, running_loss=0.3349, LR=0.000100
[2025-08-11 17:23:42,723][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035520] [Batch 01437/04869] [00:12:43/00:30:23, 0.531s/it]: train_loss_raw=0.4453, running_loss=0.3324, LR=0.000100
[2025-08-11 17:23:48,889][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035532] [Batch 01449/04869] [00:12:49/00:30:16, 0.531s/it]: train_loss_raw=0.3693, running_loss=0.3330, LR=0.000100
[2025-08-11 17:23:55,287][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035544] [Batch 01461/04869] [00:12:56/00:30:10, 0.531s/it]: train_loss_raw=0.3833, running_loss=0.3335, LR=0.000100
[2025-08-11 17:24:01,609][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035556] [Batch 01473/04869] [00:13:02/00:30:03, 0.531s/it]: train_loss_raw=0.2729, running_loss=0.3321, LR=0.000100
[2025-08-11 17:24:07,957][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035568] [Batch 01485/04869] [00:13:08/00:29:57, 0.531s/it]: train_loss_raw=0.2940, running_loss=0.3299, LR=0.000100
[2025-08-11 17:24:14,449][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035580] [Batch 01497/04869] [00:13:15/00:29:51, 0.531s/it]: train_loss_raw=0.3664, running_loss=0.3287, LR=0.000100
[2025-08-11 17:24:20,860][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035592] [Batch 01509/04869] [00:13:21/00:29:44, 0.531s/it]: train_loss_raw=0.3419, running_loss=0.3252, LR=0.000100
[2025-08-11 17:24:27,161][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035604] [Batch 01521/04869] [00:13:27/00:29:38, 0.531s/it]: train_loss_raw=0.2883, running_loss=0.3269, LR=0.000100
[2025-08-11 17:24:33,503][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035616] [Batch 01533/04869] [00:13:34/00:29:32, 0.531s/it]: train_loss_raw=0.3180, running_loss=0.3274, LR=0.000100
[2025-08-11 17:24:39,901][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035628] [Batch 01545/04869] [00:13:40/00:29:25, 0.531s/it]: train_loss_raw=0.2677, running_loss=0.3271, LR=0.000100
[2025-08-11 17:24:46,241][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035640] [Batch 01557/04869] [00:13:47/00:29:19, 0.531s/it]: train_loss_raw=0.3048, running_loss=0.3283, LR=0.000100
[2025-08-11 17:24:52,632][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035652] [Batch 01569/04869] [00:13:53/00:29:12, 0.531s/it]: train_loss_raw=0.3260, running_loss=0.3259, LR=0.000100
[2025-08-11 17:24:58,913][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035664] [Batch 01581/04869] [00:13:59/00:29:06, 0.531s/it]: train_loss_raw=0.2698, running_loss=0.3268, LR=0.000100
[2025-08-11 17:25:05,266][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035676] [Batch 01593/04869] [00:14:06/00:28:59, 0.531s/it]: train_loss_raw=0.3479, running_loss=0.3268, LR=0.000100
[2025-08-11 17:25:11,616][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035688] [Batch 01605/04869] [00:14:12/00:28:53, 0.531s/it]: train_loss_raw=0.4148, running_loss=0.3266, LR=0.000100
[2025-08-11 17:25:17,950][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035700] [Batch 01617/04869] [00:14:18/00:28:47, 0.531s/it]: train_loss_raw=0.2847, running_loss=0.3229, LR=0.000100
[2025-08-11 17:25:24,349][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035712] [Batch 01629/04869] [00:14:25/00:28:40, 0.531s/it]: train_loss_raw=0.3554, running_loss=0.3241, LR=0.000100
[2025-08-11 17:25:30,668][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035724] [Batch 01641/04869] [00:14:31/00:28:34, 0.531s/it]: train_loss_raw=0.3309, running_loss=0.3264, LR=0.000100
[2025-08-11 17:25:37,122][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035736] [Batch 01653/04869] [00:14:37/00:28:28, 0.531s/it]: train_loss_raw=0.2551, running_loss=0.3273, LR=0.000100
[2025-08-11 17:25:43,433][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035748] [Batch 01665/04869] [00:14:44/00:28:21, 0.531s/it]: train_loss_raw=0.1967, running_loss=0.3273, LR=0.000100
[2025-08-11 17:25:49,800][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035760] [Batch 01677/04869] [00:14:50/00:28:15, 0.531s/it]: train_loss_raw=0.3322, running_loss=0.3262, LR=0.000100
[2025-08-11 17:25:56,168][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035772] [Batch 01689/04869] [00:14:56/00:28:08, 0.531s/it]: train_loss_raw=0.3884, running_loss=0.3274, LR=0.000100
[2025-08-11 17:26:02,484][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035784] [Batch 01701/04869] [00:15:03/00:28:02, 0.531s/it]: train_loss_raw=0.4125, running_loss=0.3305, LR=0.000100
[2025-08-11 17:26:08,873][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035796] [Batch 01713/04869] [00:15:09/00:27:55, 0.531s/it]: train_loss_raw=0.2425, running_loss=0.3293, LR=0.000100
[2025-08-11 17:26:15,154][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035808] [Batch 01725/04869] [00:15:15/00:27:49, 0.531s/it]: train_loss_raw=0.3166, running_loss=0.3300, LR=0.000100
[2025-08-11 17:26:21,547][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035820] [Batch 01737/04869] [00:15:22/00:27:43, 0.531s/it]: train_loss_raw=0.3815, running_loss=0.3312, LR=0.000100
[2025-08-11 17:26:27,877][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035832] [Batch 01749/04869] [00:15:28/00:27:36, 0.531s/it]: train_loss_raw=0.4459, running_loss=0.3334, LR=0.000100
[2025-08-11 17:26:34,229][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035844] [Batch 01761/04869] [00:15:35/00:27:30, 0.531s/it]: train_loss_raw=0.3958, running_loss=0.3332, LR=0.000100
[2025-08-11 17:26:40,576][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035856] [Batch 01773/04869] [00:15:41/00:27:23, 0.531s/it]: train_loss_raw=0.3884, running_loss=0.3317, LR=0.000100
[2025-08-11 17:26:46,954][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035868] [Batch 01785/04869] [00:15:47/00:27:17, 0.531s/it]: train_loss_raw=0.2965, running_loss=0.3308, LR=0.000100
[2025-08-11 17:26:53,313][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035880] [Batch 01797/04869] [00:15:54/00:27:11, 0.531s/it]: train_loss_raw=0.3442, running_loss=0.3322, LR=0.000100
[2025-08-11 17:26:59,637][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035892] [Batch 01809/04869] [00:16:00/00:27:04, 0.531s/it]: train_loss_raw=0.3852, running_loss=0.3310, LR=0.000100
[2025-08-11 17:27:06,005][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035904] [Batch 01821/04869] [00:16:06/00:26:58, 0.531s/it]: train_loss_raw=0.2737, running_loss=0.3320, LR=0.000100
[2025-08-11 17:27:12,373][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035916] [Batch 01833/04869] [00:16:13/00:26:51, 0.531s/it]: train_loss_raw=0.3103, running_loss=0.3329, LR=0.000100
[2025-08-11 17:27:18,731][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035928] [Batch 01845/04869] [00:16:19/00:26:45, 0.531s/it]: train_loss_raw=0.2517, running_loss=0.3338, LR=0.000100
[2025-08-11 17:27:25,105][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035940] [Batch 01857/04869] [00:16:25/00:26:39, 0.531s/it]: train_loss_raw=0.2735, running_loss=0.3340, LR=0.000100
[2025-08-11 17:27:31,479][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035952] [Batch 01869/04869] [00:16:32/00:26:32, 0.531s/it]: train_loss_raw=0.3138, running_loss=0.3343, LR=0.000100
[2025-08-11 17:27:37,915][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035964] [Batch 01881/04869] [00:16:38/00:26:26, 0.531s/it]: train_loss_raw=0.3423, running_loss=0.3349, LR=0.000100
[2025-08-11 17:27:44,312][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035976] [Batch 01893/04869] [00:16:45/00:26:20, 0.531s/it]: train_loss_raw=0.4064, running_loss=0.3371, LR=0.000100
[2025-08-11 17:27:50,717][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035988] [Batch 01905/04869] [00:16:51/00:26:13, 0.531s/it]: train_loss_raw=0.3396, running_loss=0.3385, LR=0.000100
[2025-08-11 17:27:57,105][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036000] [Batch 01917/04869] [00:16:57/00:26:07, 0.531s/it]: train_loss_raw=0.3214, running_loss=0.3402, LR=0.000100
[2025-08-11 17:28:08,584][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036012] [Batch 01929/04869] [00:17:09/00:26:08, 0.534s/it]: train_loss_raw=0.3132, running_loss=0.3383, LR=0.000100
[2025-08-11 17:28:14,874][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036024] [Batch 01941/04869] [00:17:15/00:26:02, 0.534s/it]: train_loss_raw=0.3437, running_loss=0.3388, LR=0.000100
[2025-08-11 17:28:21,301][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036036] [Batch 01953/04869] [00:17:22/00:25:55, 0.534s/it]: train_loss_raw=0.3191, running_loss=0.3391, LR=0.000100
[2025-08-11 17:28:27,577][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036048] [Batch 01965/04869] [00:17:28/00:25:49, 0.534s/it]: train_loss_raw=0.3543, running_loss=0.3377, LR=0.000100
[2025-08-11 17:28:33,856][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036060] [Batch 01977/04869] [00:17:34/00:25:42, 0.533s/it]: train_loss_raw=0.3521, running_loss=0.3390, LR=0.000100
[2025-08-11 17:28:40,205][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036072] [Batch 01989/04869] [00:17:40/00:25:36, 0.533s/it]: train_loss_raw=0.4352, running_loss=0.3399, LR=0.000100
[2025-08-11 17:28:46,585][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036084] [Batch 02001/04869] [00:17:47/00:25:29, 0.533s/it]: train_loss_raw=0.3848, running_loss=0.3397, LR=0.000100
[2025-08-11 17:28:52,964][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036096] [Batch 02013/04869] [00:17:53/00:25:23, 0.533s/it]: train_loss_raw=0.2992, running_loss=0.3401, LR=0.000100
[2025-08-11 17:28:59,357][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036108] [Batch 02025/04869] [00:18:00/00:25:17, 0.533s/it]: train_loss_raw=0.3991, running_loss=0.3420, LR=0.000100
[2025-08-11 17:29:05,865][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036120] [Batch 02037/04869] [00:18:06/00:25:10, 0.533s/it]: train_loss_raw=0.3732, running_loss=0.3395, LR=0.000100
[2025-08-11 17:29:12,245][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036132] [Batch 02049/04869] [00:18:13/00:25:04, 0.533s/it]: train_loss_raw=0.3290, running_loss=0.3389, LR=0.000100
[2025-08-11 17:29:18,729][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036144] [Batch 02061/04869] [00:18:19/00:24:58, 0.533s/it]: train_loss_raw=0.2879, running_loss=0.3391, LR=0.000100
[2025-08-11 17:29:25,176][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036156] [Batch 02073/04869] [00:18:25/00:24:51, 0.534s/it]: train_loss_raw=0.2728, running_loss=0.3382, LR=0.000100
[2025-08-11 17:29:31,560][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036168] [Batch 02085/04869] [00:18:32/00:24:45, 0.534s/it]: train_loss_raw=0.2698, running_loss=0.3368, LR=0.000100
[2025-08-11 17:29:37,917][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036180] [Batch 02097/04869] [00:18:38/00:24:38, 0.533s/it]: train_loss_raw=0.2980, running_loss=0.3353, LR=0.000100
[2025-08-11 17:29:44,275][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036192] [Batch 02109/04869] [00:18:45/00:24:32, 0.533s/it]: train_loss_raw=0.3634, running_loss=0.3351, LR=0.000100
[2025-08-11 17:29:50,614][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036204] [Batch 02121/04869] [00:18:51/00:24:25, 0.533s/it]: train_loss_raw=0.3115, running_loss=0.3346, LR=0.000100
[2025-08-11 17:29:57,000][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036216] [Batch 02133/04869] [00:18:57/00:24:19, 0.533s/it]: train_loss_raw=0.3758, running_loss=0.3351, LR=0.000100
[2025-08-11 17:30:03,417][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036228] [Batch 02145/04869] [00:19:04/00:24:13, 0.533s/it]: train_loss_raw=0.3356, running_loss=0.3351, LR=0.000100
[2025-08-11 17:30:09,967][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036240] [Batch 02157/04869] [00:19:10/00:24:06, 0.534s/it]: train_loss_raw=0.4125, running_loss=0.3383, LR=0.000100
[2025-08-11 17:30:16,373][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036252] [Batch 02169/04869] [00:19:17/00:24:00, 0.534s/it]: train_loss_raw=0.3601, running_loss=0.3389, LR=0.000100
[2025-08-11 17:30:22,713][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036264] [Batch 02181/04869] [00:19:23/00:23:53, 0.533s/it]: train_loss_raw=0.2594, running_loss=0.3389, LR=0.000100
[2025-08-11 17:30:29,219][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036276] [Batch 02193/04869] [00:19:30/00:23:47, 0.534s/it]: train_loss_raw=0.3826, running_loss=0.3380, LR=0.000100
[2025-08-11 17:30:35,615][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036288] [Batch 02205/04869] [00:19:36/00:23:41, 0.534s/it]: train_loss_raw=0.3825, running_loss=0.3402, LR=0.000100
[2025-08-11 17:30:41,911][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036300] [Batch 02217/04869] [00:19:42/00:23:34, 0.533s/it]: train_loss_raw=0.2219, running_loss=0.3354, LR=0.000100
[2025-08-11 17:30:48,270][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036312] [Batch 02229/04869] [00:19:49/00:23:28, 0.533s/it]: train_loss_raw=0.4069, running_loss=0.3349, LR=0.000100
[2025-08-11 17:30:54,720][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036324] [Batch 02241/04869] [00:19:55/00:23:21, 0.533s/it]: train_loss_raw=0.3812, running_loss=0.3380, LR=0.000100
[2025-08-11 17:31:01,116][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036336] [Batch 02253/04869] [00:20:01/00:23:15, 0.533s/it]: train_loss_raw=0.3302, running_loss=0.3374, LR=0.000100
[2025-08-11 17:31:07,589][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036348] [Batch 02265/04869] [00:20:08/00:23:09, 0.534s/it]: train_loss_raw=0.3867, running_loss=0.3380, LR=0.000100
[2025-08-11 17:31:13,991][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036360] [Batch 02277/04869] [00:20:14/00:23:02, 0.534s/it]: train_loss_raw=0.3293, running_loss=0.3377, LR=0.000100
[2025-08-11 17:31:20,345][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036372] [Batch 02289/04869] [00:20:21/00:22:56, 0.533s/it]: train_loss_raw=0.3512, running_loss=0.3370, LR=0.000100
[2025-08-11 17:31:26,759][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036384] [Batch 02301/04869] [00:20:27/00:22:49, 0.533s/it]: train_loss_raw=0.3046, running_loss=0.3363, LR=0.000100
[2025-08-11 17:31:33,165][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036396] [Batch 02313/04869] [00:20:33/00:22:43, 0.533s/it]: train_loss_raw=0.3430, running_loss=0.3362, LR=0.000100
[2025-08-11 17:31:39,518][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036408] [Batch 02325/04869] [00:20:40/00:22:37, 0.533s/it]: train_loss_raw=0.3050, running_loss=0.3350, LR=0.000100
[2025-08-11 17:31:45,921][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036420] [Batch 02337/04869] [00:20:46/00:22:30, 0.533s/it]: train_loss_raw=0.3695, running_loss=0.3354, LR=0.000100
[2025-08-11 17:31:52,321][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036432] [Batch 02349/04869] [00:20:53/00:22:24, 0.533s/it]: train_loss_raw=0.3285, running_loss=0.3364, LR=0.000100
[2025-08-11 17:31:58,899][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036444] [Batch 02361/04869] [00:20:59/00:22:18, 0.534s/it]: train_loss_raw=0.3936, running_loss=0.3358, LR=0.000100
[2025-08-11 17:32:05,312][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036456] [Batch 02373/04869] [00:21:06/00:22:11, 0.534s/it]: train_loss_raw=0.4288, running_loss=0.3379, LR=0.000100
[2025-08-11 17:32:11,675][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036468] [Batch 02385/04869] [00:21:12/00:22:05, 0.534s/it]: train_loss_raw=0.2923, running_loss=0.3353, LR=0.000100
[2025-08-11 17:32:17,969][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036480] [Batch 02397/04869] [00:21:18/00:21:58, 0.533s/it]: train_loss_raw=0.2063, running_loss=0.3357, LR=0.000100
[2025-08-11 17:32:24,352][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036492] [Batch 02409/04869] [00:21:25/00:21:52, 0.533s/it]: train_loss_raw=0.3876, running_loss=0.3375, LR=0.000100
[2025-08-11 17:32:30,757][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036504] [Batch 02421/04869] [00:21:31/00:21:45, 0.533s/it]: train_loss_raw=0.2837, running_loss=0.3375, LR=0.000100
[2025-08-11 17:32:37,135][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036516] [Batch 02433/04869] [00:21:37/00:21:39, 0.533s/it]: train_loss_raw=0.3722, running_loss=0.3359, LR=0.000100
[2025-08-11 17:32:43,600][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036528] [Batch 02445/04869] [00:21:44/00:21:33, 0.533s/it]: train_loss_raw=0.3409, running_loss=0.3348, LR=0.000100
[2025-08-11 17:32:50,024][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036540] [Batch 02457/04869] [00:21:50/00:21:26, 0.534s/it]: train_loss_raw=0.2641, running_loss=0.3342, LR=0.000100
[2025-08-11 17:32:56,486][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036552] [Batch 02469/04869] [00:21:57/00:21:20, 0.534s/it]: train_loss_raw=0.2871, running_loss=0.3307, LR=0.000100
[2025-08-11 17:33:02,895][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036564] [Batch 02481/04869] [00:22:03/00:21:14, 0.534s/it]: train_loss_raw=0.2753, running_loss=0.3294, LR=0.000100
[2025-08-11 17:33:09,285][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036576] [Batch 02493/04869] [00:22:10/00:21:07, 0.534s/it]: train_loss_raw=0.3163, running_loss=0.3323, LR=0.000100
[2025-08-11 17:33:15,666][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036588] [Batch 02505/04869] [00:22:16/00:21:01, 0.534s/it]: train_loss_raw=0.3226, running_loss=0.3337, LR=0.000100
[2025-08-11 17:33:21,811][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036600] [Batch 02517/04869] [00:22:22/00:20:54, 0.533s/it]: train_loss_raw=0.3286, running_loss=0.3338, LR=0.000100
[2025-08-11 17:33:28,145][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036612] [Batch 02529/04869] [00:22:28/00:20:48, 0.533s/it]: train_loss_raw=0.3467, running_loss=0.3327, LR=0.000100
[2025-08-11 17:33:34,479][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036624] [Batch 02541/04869] [00:22:35/00:20:41, 0.533s/it]: train_loss_raw=0.3249, running_loss=0.3311, LR=0.000100
[2025-08-11 17:33:40,875][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036636] [Batch 02553/04869] [00:22:41/00:20:35, 0.533s/it]: train_loss_raw=0.4294, running_loss=0.3327, LR=0.000100
[2025-08-11 17:33:47,171][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036648] [Batch 02565/04869] [00:22:47/00:20:28, 0.533s/it]: train_loss_raw=0.3915, running_loss=0.3360, LR=0.000100
[2025-08-11 17:33:53,550][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036660] [Batch 02577/04869] [00:22:54/00:20:22, 0.533s/it]: train_loss_raw=0.4668, running_loss=0.3389, LR=0.000100
[2025-08-11 17:33:59,943][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036672] [Batch 02589/04869] [00:23:00/00:20:15, 0.533s/it]: train_loss_raw=0.4844, running_loss=0.3402, LR=0.000100
[2025-08-11 17:34:06,273][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036684] [Batch 02601/04869] [00:23:07/00:20:09, 0.533s/it]: train_loss_raw=0.3723, running_loss=0.3426, LR=0.000100
[2025-08-11 17:34:12,637][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036696] [Batch 02613/04869] [00:23:13/00:20:03, 0.533s/it]: train_loss_raw=0.3464, running_loss=0.3381, LR=0.000100
[2025-08-11 17:34:19,061][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036708] [Batch 02625/04869] [00:23:19/00:19:56, 0.533s/it]: train_loss_raw=0.3157, running_loss=0.3329, LR=0.000100
[2025-08-11 17:34:25,433][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036720] [Batch 02637/04869] [00:23:26/00:19:50, 0.533s/it]: train_loss_raw=0.2664, running_loss=0.3336, LR=0.000100
[2025-08-11 17:34:31,743][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036732] [Batch 02649/04869] [00:23:32/00:19:43, 0.533s/it]: train_loss_raw=0.2594, running_loss=0.3315, LR=0.000100
[2025-08-11 17:34:38,137][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036744] [Batch 02661/04869] [00:23:38/00:19:37, 0.533s/it]: train_loss_raw=0.3036, running_loss=0.3341, LR=0.000100
[2025-08-11 17:34:44,533][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036756] [Batch 02673/04869] [00:23:45/00:19:30, 0.533s/it]: train_loss_raw=0.3213, running_loss=0.3344, LR=0.000100
[2025-08-11 17:34:50,866][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036768] [Batch 02685/04869] [00:23:51/00:19:24, 0.533s/it]: train_loss_raw=0.3474, running_loss=0.3330, LR=0.000100
[2025-08-11 17:34:57,290][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036780] [Batch 02697/04869] [00:23:58/00:19:18, 0.533s/it]: train_loss_raw=0.3760, running_loss=0.3336, LR=0.000100
[2025-08-11 17:35:03,747][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036792] [Batch 02709/04869] [00:24:04/00:19:11, 0.533s/it]: train_loss_raw=0.2745, running_loss=0.3329, LR=0.000100
[2025-08-11 17:35:10,177][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036804] [Batch 02721/04869] [00:24:10/00:19:05, 0.533s/it]: train_loss_raw=0.3107, running_loss=0.3303, LR=0.000100
[2025-08-11 17:35:16,505][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036816] [Batch 02733/04869] [00:24:17/00:18:58, 0.533s/it]: train_loss_raw=0.2863, running_loss=0.3325, LR=0.000100
[2025-08-11 17:35:22,938][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036828] [Batch 02745/04869] [00:24:23/00:18:52, 0.533s/it]: train_loss_raw=0.2615, running_loss=0.3307, LR=0.000100
[2025-08-11 17:35:29,481][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036840] [Batch 02757/04869] [00:24:30/00:18:46, 0.533s/it]: train_loss_raw=0.4066, running_loss=0.3313, LR=0.000100
[2025-08-11 17:35:35,915][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036852] [Batch 02769/04869] [00:24:36/00:18:39, 0.533s/it]: train_loss_raw=0.2941, running_loss=0.3309, LR=0.000100
[2025-08-11 17:35:42,257][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036864] [Batch 02781/04869] [00:24:43/00:18:33, 0.533s/it]: train_loss_raw=0.3151, running_loss=0.3325, LR=0.000100
[2025-08-11 17:35:48,585][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036876] [Batch 02793/04869] [00:24:49/00:18:27, 0.533s/it]: train_loss_raw=0.2817, running_loss=0.3306, LR=0.000100
[2025-08-11 17:35:55,017][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036888] [Batch 02805/04869] [00:24:55/00:18:20, 0.533s/it]: train_loss_raw=0.2644, running_loss=0.3279, LR=0.000100
[2025-08-11 17:36:01,392][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036900] [Batch 02817/04869] [00:25:02/00:18:14, 0.533s/it]: train_loss_raw=0.2788, running_loss=0.3288, LR=0.000100
[2025-08-11 17:36:07,673][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036912] [Batch 02829/04869] [00:25:08/00:18:07, 0.533s/it]: train_loss_raw=0.3006, running_loss=0.3270, LR=0.000100
[2025-08-11 17:36:14,154][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036924] [Batch 02841/04869] [00:25:14/00:18:01, 0.533s/it]: train_loss_raw=0.2777, running_loss=0.3294, LR=0.000100
[2025-08-11 17:36:20,530][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036936] [Batch 02853/04869] [00:25:21/00:17:55, 0.533s/it]: train_loss_raw=0.2908, running_loss=0.3295, LR=0.000100
[2025-08-11 17:36:26,902][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036948] [Batch 02865/04869] [00:25:27/00:17:48, 0.533s/it]: train_loss_raw=0.3133, running_loss=0.3270, LR=0.000100
[2025-08-11 17:36:33,297][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036960] [Batch 02877/04869] [00:25:34/00:17:42, 0.533s/it]: train_loss_raw=0.2901, running_loss=0.3240, LR=0.000100
[2025-08-11 17:36:39,707][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036972] [Batch 02889/04869] [00:25:40/00:17:35, 0.533s/it]: train_loss_raw=0.3411, running_loss=0.3252, LR=0.000100
[2025-08-11 17:36:46,202][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036984] [Batch 02901/04869] [00:25:46/00:17:29, 0.533s/it]: train_loss_raw=0.2972, running_loss=0.3270, LR=0.000100
[2025-08-11 17:36:52,488][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036996] [Batch 02913/04869] [00:25:53/00:17:22, 0.533s/it]: train_loss_raw=0.3984, running_loss=0.3269, LR=0.000100
[2025-08-11 17:36:58,913][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037008] [Batch 02925/04869] [00:25:59/00:17:16, 0.533s/it]: train_loss_raw=0.3883, running_loss=0.3279, LR=0.000100
[2025-08-11 17:37:05,333][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037020] [Batch 02937/04869] [00:26:06/00:17:10, 0.533s/it]: train_loss_raw=0.3893, running_loss=0.3282, LR=0.000100
[2025-08-11 17:37:11,685][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037032] [Batch 02949/04869] [00:26:12/00:17:03, 0.533s/it]: train_loss_raw=0.3282, running_loss=0.3289, LR=0.000100
[2025-08-11 17:37:18,105][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037044] [Batch 02961/04869] [00:26:18/00:16:57, 0.533s/it]: train_loss_raw=0.3464, running_loss=0.3331, LR=0.000100
[2025-08-11 17:37:24,445][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037056] [Batch 02973/04869] [00:26:25/00:16:50, 0.533s/it]: train_loss_raw=0.3647, running_loss=0.3326, LR=0.000100
[2025-08-11 17:37:30,824][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037068] [Batch 02985/04869] [00:26:31/00:16:44, 0.533s/it]: train_loss_raw=0.3393, running_loss=0.3328, LR=0.000100
[2025-08-11 17:37:37,261][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037080] [Batch 02997/04869] [00:26:38/00:16:38, 0.533s/it]: train_loss_raw=0.2709, running_loss=0.3314, LR=0.000100
[2025-08-11 17:37:43,807][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037092] [Batch 03009/04869] [00:26:44/00:16:31, 0.533s/it]: train_loss_raw=0.3028, running_loss=0.3304, LR=0.000100
[2025-08-11 17:37:50,214][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037104] [Batch 03021/04869] [00:26:51/00:16:25, 0.533s/it]: train_loss_raw=0.4629, running_loss=0.3327, LR=0.000100
[2025-08-11 17:37:56,702][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037116] [Batch 03033/04869] [00:26:57/00:16:19, 0.533s/it]: train_loss_raw=0.3019, running_loss=0.3313, LR=0.000100
[2025-08-11 17:38:03,201][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037128] [Batch 03045/04869] [00:27:03/00:16:12, 0.533s/it]: train_loss_raw=0.3893, running_loss=0.3335, LR=0.000100
[2025-08-11 17:38:09,500][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037140] [Batch 03057/04869] [00:27:10/00:16:06, 0.533s/it]: train_loss_raw=0.3075, running_loss=0.3340, LR=0.000100
[2025-08-11 17:38:16,019][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037152] [Batch 03069/04869] [00:27:16/00:16:00, 0.533s/it]: train_loss_raw=0.3105, running_loss=0.3359, LR=0.000100
[2025-08-11 17:38:22,537][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037164] [Batch 03081/04869] [00:27:23/00:15:53, 0.533s/it]: train_loss_raw=0.3855, running_loss=0.3382, LR=0.000100
[2025-08-11 17:38:28,985][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037176] [Batch 03093/04869] [00:27:29/00:15:47, 0.533s/it]: train_loss_raw=0.4249, running_loss=0.3392, LR=0.000100
[2025-08-11 17:38:35,516][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037188] [Batch 03105/04869] [00:27:36/00:15:40, 0.533s/it]: train_loss_raw=0.3676, running_loss=0.3384, LR=0.000100
[2025-08-11 17:38:41,848][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037200] [Batch 03117/04869] [00:27:42/00:15:34, 0.533s/it]: train_loss_raw=0.4035, running_loss=0.3396, LR=0.000100
[2025-08-11 17:38:48,159][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037212] [Batch 03129/04869] [00:27:48/00:15:28, 0.533s/it]: train_loss_raw=0.3457, running_loss=0.3378, LR=0.000100
[2025-08-11 17:38:54,463][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037224] [Batch 03141/04869] [00:27:55/00:15:21, 0.533s/it]: train_loss_raw=0.3110, running_loss=0.3372, LR=0.000100
[2025-08-11 17:39:00,796][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037236] [Batch 03153/04869] [00:28:01/00:15:15, 0.533s/it]: train_loss_raw=0.2453, running_loss=0.3364, LR=0.000100
[2025-08-11 17:39:07,201][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037248] [Batch 03165/04869] [00:28:07/00:15:08, 0.533s/it]: train_loss_raw=0.3877, running_loss=0.3369, LR=0.000100
[2025-08-11 17:39:13,454][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037260] [Batch 03177/04869] [00:28:14/00:15:02, 0.533s/it]: train_loss_raw=0.3094, running_loss=0.3363, LR=0.000100
[2025-08-11 17:39:19,812][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037272] [Batch 03189/04869] [00:28:20/00:14:55, 0.533s/it]: train_loss_raw=0.3358, running_loss=0.3355, LR=0.000100
[2025-08-11 17:39:26,232][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037284] [Batch 03201/04869] [00:28:27/00:14:49, 0.533s/it]: train_loss_raw=0.2873, running_loss=0.3348, LR=0.000100
[2025-08-11 17:39:32,567][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037296] [Batch 03213/04869] [00:28:33/00:14:43, 0.533s/it]: train_loss_raw=0.2520, running_loss=0.3331, LR=0.000100
[2025-08-11 17:39:38,941][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037308] [Batch 03225/04869] [00:28:39/00:14:36, 0.533s/it]: train_loss_raw=0.3071, running_loss=0.3333, LR=0.000100
[2025-08-11 17:39:45,373][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037320] [Batch 03237/04869] [00:28:46/00:14:30, 0.533s/it]: train_loss_raw=0.3867, running_loss=0.3353, LR=0.000100
[2025-08-11 17:39:51,744][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037332] [Batch 03249/04869] [00:28:52/00:14:23, 0.533s/it]: train_loss_raw=0.3497, running_loss=0.3343, LR=0.000100
[2025-08-11 17:39:58,165][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037344] [Batch 03261/04869] [00:28:58/00:14:17, 0.533s/it]: train_loss_raw=0.3567, running_loss=0.3349, LR=0.000100
[2025-08-11 17:40:04,468][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037356] [Batch 03273/04869] [00:29:05/00:14:11, 0.533s/it]: train_loss_raw=0.3563, running_loss=0.3347, LR=0.000100
[2025-08-11 17:40:10,841][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037368] [Batch 03285/04869] [00:29:11/00:14:04, 0.533s/it]: train_loss_raw=0.3397, running_loss=0.3337, LR=0.000100
[2025-08-11 17:40:17,285][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037380] [Batch 03297/04869] [00:29:18/00:13:58, 0.533s/it]: train_loss_raw=0.3484, running_loss=0.3352, LR=0.000100
[2025-08-11 17:40:23,722][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037392] [Batch 03309/04869] [00:29:24/00:13:51, 0.533s/it]: train_loss_raw=0.3612, running_loss=0.3338, LR=0.000100
[2025-08-11 17:40:30,114][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037404] [Batch 03321/04869] [00:29:30/00:13:45, 0.533s/it]: train_loss_raw=0.2682, running_loss=0.3360, LR=0.000100
[2025-08-11 17:40:36,517][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037416] [Batch 03333/04869] [00:29:37/00:13:39, 0.533s/it]: train_loss_raw=0.3856, running_loss=0.3367, LR=0.000100
[2025-08-11 17:40:42,831][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037428] [Batch 03345/04869] [00:29:43/00:13:32, 0.533s/it]: train_loss_raw=0.2846, running_loss=0.3364, LR=0.000100
[2025-08-11 17:40:49,156][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037440] [Batch 03357/04869] [00:29:49/00:13:26, 0.533s/it]: train_loss_raw=0.3776, running_loss=0.3332, LR=0.000100
[2025-08-11 17:40:55,534][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037452] [Batch 03369/04869] [00:29:56/00:13:19, 0.533s/it]: train_loss_raw=0.3216, running_loss=0.3319, LR=0.000100
[2025-08-11 17:41:01,878][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037464] [Batch 03381/04869] [00:30:02/00:13:13, 0.533s/it]: train_loss_raw=0.2171, running_loss=0.3291, LR=0.000100
[2025-08-11 17:41:08,352][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037476] [Batch 03393/04869] [00:30:09/00:13:07, 0.533s/it]: train_loss_raw=0.3431, running_loss=0.3283, LR=0.000100
[2025-08-11 17:41:14,777][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037488] [Batch 03405/04869] [00:30:15/00:13:00, 0.533s/it]: train_loss_raw=0.2951, running_loss=0.3299, LR=0.000100
[2025-08-11 17:41:21,215][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037500] [Batch 03417/04869] [00:30:22/00:12:54, 0.533s/it]: train_loss_raw=0.2668, running_loss=0.3322, LR=0.000100
[2025-08-11 17:41:27,709][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037512] [Batch 03429/04869] [00:30:28/00:12:47, 0.533s/it]: train_loss_raw=0.2746, running_loss=0.3308, LR=0.000100
[2025-08-11 17:41:34,068][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037524] [Batch 03441/04869] [00:30:34/00:12:41, 0.533s/it]: train_loss_raw=0.4611, running_loss=0.3318, LR=0.000100
[2025-08-11 17:41:40,290][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037536] [Batch 03453/04869] [00:30:41/00:12:34, 0.533s/it]: train_loss_raw=0.3120, running_loss=0.3331, LR=0.000100
[2025-08-11 17:41:46,535][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037548] [Batch 03465/04869] [00:30:47/00:12:28, 0.533s/it]: train_loss_raw=0.3068, running_loss=0.3340, LR=0.000100
[2025-08-11 17:41:52,993][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037560] [Batch 03477/04869] [00:30:53/00:12:22, 0.533s/it]: train_loss_raw=0.3640, running_loss=0.3328, LR=0.000100
[2025-08-11 17:41:59,378][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037572] [Batch 03489/04869] [00:31:00/00:12:15, 0.533s/it]: train_loss_raw=0.3945, running_loss=0.3342, LR=0.000100
[2025-08-11 17:42:05,810][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037584] [Batch 03501/04869] [00:31:06/00:12:09, 0.533s/it]: train_loss_raw=0.2170, running_loss=0.3324, LR=0.000100
[2025-08-11 17:42:12,217][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037596] [Batch 03513/04869] [00:31:13/00:12:02, 0.533s/it]: train_loss_raw=0.3701, running_loss=0.3317, LR=0.000100
[2025-08-11 17:42:18,623][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037608] [Batch 03525/04869] [00:31:19/00:11:56, 0.533s/it]: train_loss_raw=0.2859, running_loss=0.3290, LR=0.000100
[2025-08-11 17:42:24,935][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037620] [Batch 03537/04869] [00:31:25/00:11:50, 0.533s/it]: train_loss_raw=0.3851, running_loss=0.3287, LR=0.000100
[2025-08-11 17:42:31,276][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037632] [Batch 03549/04869] [00:31:32/00:11:43, 0.533s/it]: train_loss_raw=0.3464, running_loss=0.3314, LR=0.000100
[2025-08-11 17:42:37,754][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037644] [Batch 03561/04869] [00:31:38/00:11:37, 0.533s/it]: train_loss_raw=0.4234, running_loss=0.3326, LR=0.000100
[2025-08-11 17:42:44,116][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037656] [Batch 03573/04869] [00:31:44/00:11:30, 0.533s/it]: train_loss_raw=0.3143, running_loss=0.3343, LR=0.000100
[2025-08-11 17:42:50,569][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037668] [Batch 03585/04869] [00:31:51/00:11:24, 0.533s/it]: train_loss_raw=0.3803, running_loss=0.3358, LR=0.000100
[2025-08-11 17:42:56,890][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037680] [Batch 03597/04869] [00:31:57/00:11:18, 0.533s/it]: train_loss_raw=0.3217, running_loss=0.3357, LR=0.000100
[2025-08-11 17:43:03,258][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037692] [Batch 03609/04869] [00:32:04/00:11:11, 0.533s/it]: train_loss_raw=0.3615, running_loss=0.3346, LR=0.000100
[2025-08-11 17:43:09,610][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037704] [Batch 03621/04869] [00:32:10/00:11:05, 0.533s/it]: train_loss_raw=0.4172, running_loss=0.3368, LR=0.000100
[2025-08-11 17:43:15,964][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037716] [Batch 03633/04869] [00:32:16/00:10:58, 0.533s/it]: train_loss_raw=0.3301, running_loss=0.3345, LR=0.000100
[2025-08-11 17:43:22,355][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037728] [Batch 03645/04869] [00:32:23/00:10:52, 0.533s/it]: train_loss_raw=0.2631, running_loss=0.3339, LR=0.000100
[2025-08-11 17:43:28,746][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037740] [Batch 03657/04869] [00:32:29/00:10:46, 0.533s/it]: train_loss_raw=0.3787, running_loss=0.3357, LR=0.000100
[2025-08-11 17:43:35,102][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037752] [Batch 03669/04869] [00:32:35/00:10:39, 0.533s/it]: train_loss_raw=0.3331, running_loss=0.3337, LR=0.000100
[2025-08-11 17:43:41,447][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037764] [Batch 03681/04869] [00:32:42/00:10:33, 0.533s/it]: train_loss_raw=0.3581, running_loss=0.3338, LR=0.000100
[2025-08-11 17:43:47,750][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037776] [Batch 03693/04869] [00:32:48/00:10:26, 0.533s/it]: train_loss_raw=0.4357, running_loss=0.3371, LR=0.000100
[2025-08-11 17:43:54,165][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037788] [Batch 03705/04869] [00:32:54/00:10:20, 0.533s/it]: train_loss_raw=0.3113, running_loss=0.3380, LR=0.000100
[2025-08-11 17:44:00,629][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037800] [Batch 03717/04869] [00:33:01/00:10:14, 0.533s/it]: train_loss_raw=0.4642, running_loss=0.3359, LR=0.000100
[2025-08-11 17:44:06,963][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037812] [Batch 03729/04869] [00:33:07/00:10:07, 0.533s/it]: train_loss_raw=0.3547, running_loss=0.3349, LR=0.000100
[2025-08-11 17:44:13,243][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037824] [Batch 03741/04869] [00:33:14/00:10:01, 0.533s/it]: train_loss_raw=0.3558, running_loss=0.3352, LR=0.000100
[2025-08-11 17:44:19,651][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037836] [Batch 03753/04869] [00:33:20/00:09:54, 0.533s/it]: train_loss_raw=0.2767, running_loss=0.3325, LR=0.000100
[2025-08-11 17:44:26,155][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037848] [Batch 03765/04869] [00:33:26/00:09:48, 0.533s/it]: train_loss_raw=0.2961, running_loss=0.3346, LR=0.000100
[2025-08-11 17:44:32,500][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037860] [Batch 03777/04869] [00:33:33/00:09:42, 0.533s/it]: train_loss_raw=0.3157, running_loss=0.3351, LR=0.000100
[2025-08-11 17:44:38,852][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037872] [Batch 03789/04869] [00:33:39/00:09:35, 0.533s/it]: train_loss_raw=0.3295, running_loss=0.3361, LR=0.000100
[2025-08-11 17:44:45,261][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037884] [Batch 03801/04869] [00:33:46/00:09:29, 0.533s/it]: train_loss_raw=0.3012, running_loss=0.3350, LR=0.000100
[2025-08-11 17:44:51,546][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037896] [Batch 03813/04869] [00:33:52/00:09:22, 0.533s/it]: train_loss_raw=0.2775, running_loss=0.3330, LR=0.000100
[2025-08-11 17:44:57,855][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037908] [Batch 03825/04869] [00:33:58/00:09:16, 0.533s/it]: train_loss_raw=0.2568, running_loss=0.3300, LR=0.000100
[2025-08-11 17:45:04,182][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037920] [Batch 03837/04869] [00:34:04/00:09:10, 0.533s/it]: train_loss_raw=0.3139, running_loss=0.3316, LR=0.000100
[2025-08-11 17:45:10,562][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037932] [Batch 03849/04869] [00:34:11/00:09:03, 0.533s/it]: train_loss_raw=0.2980, running_loss=0.3302, LR=0.000100
[2025-08-11 17:45:16,797][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037944] [Batch 03861/04869] [00:34:17/00:08:57, 0.533s/it]: train_loss_raw=0.2817, running_loss=0.3307, LR=0.000100
[2025-08-11 17:45:23,123][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037956] [Batch 03873/04869] [00:34:23/00:08:50, 0.533s/it]: train_loss_raw=0.2984, running_loss=0.3309, LR=0.000100
[2025-08-11 17:45:29,455][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037968] [Batch 03885/04869] [00:34:30/00:08:44, 0.533s/it]: train_loss_raw=0.3476, running_loss=0.3286, LR=0.000100
[2025-08-11 17:45:35,795][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037980] [Batch 03897/04869] [00:34:36/00:08:37, 0.533s/it]: train_loss_raw=0.3191, running_loss=0.3308, LR=0.000100
[2025-08-11 17:45:42,246][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037992] [Batch 03909/04869] [00:34:43/00:08:31, 0.533s/it]: train_loss_raw=0.3617, running_loss=0.3308, LR=0.000100
[2025-08-11 17:45:53,513][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038004] [Batch 03921/04869] [00:34:54/00:08:26, 0.534s/it]: train_loss_raw=0.2749, running_loss=0.3299, LR=0.000100
[2025-08-11 17:45:59,835][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038016] [Batch 03933/04869] [00:35:00/00:08:19, 0.534s/it]: train_loss_raw=0.2957, running_loss=0.3304, LR=0.000100
[2025-08-11 17:46:06,161][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038028] [Batch 03945/04869] [00:35:06/00:08:13, 0.534s/it]: train_loss_raw=0.3168, running_loss=0.3306, LR=0.000100
[2025-08-11 17:46:12,443][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038040] [Batch 03957/04869] [00:35:13/00:08:07, 0.534s/it]: train_loss_raw=0.3669, running_loss=0.3313, LR=0.000100
[2025-08-11 17:46:18,888][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038052] [Batch 03969/04869] [00:35:19/00:08:00, 0.534s/it]: train_loss_raw=0.2774, running_loss=0.3337, LR=0.000100
[2025-08-11 17:46:25,305][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038064] [Batch 03981/04869] [00:35:26/00:07:54, 0.534s/it]: train_loss_raw=0.3590, running_loss=0.3353, LR=0.000100
[2025-08-11 17:46:31,913][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038076] [Batch 03993/04869] [00:35:32/00:07:47, 0.534s/it]: train_loss_raw=0.3976, running_loss=0.3354, LR=0.000100
[2025-08-11 17:46:38,253][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038088] [Batch 04005/04869] [00:35:39/00:07:41, 0.534s/it]: train_loss_raw=0.3921, running_loss=0.3359, LR=0.000100
[2025-08-11 17:46:44,554][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038100] [Batch 04017/04869] [00:35:45/00:07:35, 0.534s/it]: train_loss_raw=0.3662, running_loss=0.3351, LR=0.000100
[2025-08-11 17:46:50,923][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038112] [Batch 04029/04869] [00:35:51/00:07:28, 0.534s/it]: train_loss_raw=0.3543, running_loss=0.3357, LR=0.000100
[2025-08-11 17:46:57,199][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038124] [Batch 04041/04869] [00:35:57/00:07:22, 0.534s/it]: train_loss_raw=0.3533, running_loss=0.3359, LR=0.000100
[2025-08-11 17:47:03,327][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038136] [Batch 04053/04869] [00:36:04/00:07:15, 0.534s/it]: train_loss_raw=0.2995, running_loss=0.3346, LR=0.000100
[2025-08-11 17:47:09,561][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038148] [Batch 04065/04869] [00:36:10/00:07:09, 0.534s/it]: train_loss_raw=0.2748, running_loss=0.3323, LR=0.000100
[2025-08-11 17:47:15,888][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038160] [Batch 04077/04869] [00:36:16/00:07:02, 0.534s/it]: train_loss_raw=0.3675, running_loss=0.3341, LR=0.000100
[2025-08-11 17:47:22,190][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038172] [Batch 04089/04869] [00:36:22/00:06:56, 0.534s/it]: train_loss_raw=0.2958, running_loss=0.3330, LR=0.000100
[2025-08-11 17:47:28,582][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038184] [Batch 04101/04869] [00:36:29/00:06:50, 0.534s/it]: train_loss_raw=0.2611, running_loss=0.3305, LR=0.000100
[2025-08-11 17:47:34,967][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038196] [Batch 04113/04869] [00:36:35/00:06:43, 0.534s/it]: train_loss_raw=0.3369, running_loss=0.3316, LR=0.000100
[2025-08-11 17:47:41,280][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038208] [Batch 04125/04869] [00:36:42/00:06:37, 0.534s/it]: train_loss_raw=0.3697, running_loss=0.3278, LR=0.000100
[2025-08-11 17:47:47,618][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038220] [Batch 04137/04869] [00:36:48/00:06:30, 0.534s/it]: train_loss_raw=0.3360, running_loss=0.3255, LR=0.000100
[2025-08-11 17:47:53,945][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038232] [Batch 04149/04869] [00:36:54/00:06:24, 0.534s/it]: train_loss_raw=0.3451, running_loss=0.3283, LR=0.000100
[2025-08-11 17:48:00,317][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038244] [Batch 04161/04869] [00:37:01/00:06:17, 0.534s/it]: train_loss_raw=0.3668, running_loss=0.3288, LR=0.000100
[2025-08-11 17:48:06,828][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038256] [Batch 04173/04869] [00:37:07/00:06:11, 0.534s/it]: train_loss_raw=0.3241, running_loss=0.3291, LR=0.000100
[2025-08-11 17:48:13,205][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038268] [Batch 04185/04869] [00:37:13/00:06:05, 0.534s/it]: train_loss_raw=0.3656, running_loss=0.3304, LR=0.000100
[2025-08-11 17:48:19,310][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038280] [Batch 04197/04869] [00:37:20/00:05:58, 0.534s/it]: train_loss_raw=0.2549, running_loss=0.3293, LR=0.000100
[2025-08-11 17:48:25,575][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038292] [Batch 04209/04869] [00:37:26/00:05:52, 0.534s/it]: train_loss_raw=0.3147, running_loss=0.3326, LR=0.000100
[2025-08-11 17:48:31,687][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038304] [Batch 04221/04869] [00:37:32/00:05:45, 0.534s/it]: train_loss_raw=0.4114, running_loss=0.3313, LR=0.000100
[2025-08-11 17:48:37,864][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038316] [Batch 04233/04869] [00:37:38/00:05:39, 0.534s/it]: train_loss_raw=0.3015, running_loss=0.3300, LR=0.000100
[2025-08-11 17:48:43,985][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038328] [Batch 04245/04869] [00:37:44/00:05:32, 0.534s/it]: train_loss_raw=0.3371, running_loss=0.3326, LR=0.000100
[2025-08-11 17:48:50,122][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038340] [Batch 04257/04869] [00:37:50/00:05:26, 0.533s/it]: train_loss_raw=0.3691, running_loss=0.3360, LR=0.000100
[2025-08-11 17:48:56,268][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038352] [Batch 04269/04869] [00:37:57/00:05:20, 0.533s/it]: train_loss_raw=0.4264, running_loss=0.3370, LR=0.000100
[2025-08-11 17:49:02,498][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038364] [Batch 04281/04869] [00:38:03/00:05:13, 0.533s/it]: train_loss_raw=0.4224, running_loss=0.3356, LR=0.000100
[2025-08-11 17:49:08,839][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038376] [Batch 04293/04869] [00:38:09/00:05:07, 0.533s/it]: train_loss_raw=0.3842, running_loss=0.3382, LR=0.000100
[2025-08-11 17:49:15,342][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038388] [Batch 04305/04869] [00:38:16/00:05:00, 0.533s/it]: train_loss_raw=0.3701, running_loss=0.3371, LR=0.000100
[2025-08-11 17:49:21,965][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038400] [Batch 04317/04869] [00:38:22/00:04:54, 0.533s/it]: train_loss_raw=0.3537, running_loss=0.3374, LR=0.000100
[2025-08-11 17:49:28,539][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038412] [Batch 04329/04869] [00:38:29/00:04:48, 0.533s/it]: train_loss_raw=0.3082, running_loss=0.3365, LR=0.000100
[2025-08-11 17:49:35,184][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038424] [Batch 04341/04869] [00:38:35/00:04:41, 0.534s/it]: train_loss_raw=0.3690, running_loss=0.3355, LR=0.000100
[2025-08-11 17:49:41,433][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038436] [Batch 04353/04869] [00:38:42/00:04:35, 0.533s/it]: train_loss_raw=0.3413, running_loss=0.3355, LR=0.000100
[2025-08-11 17:49:47,664][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038448] [Batch 04365/04869] [00:38:48/00:04:28, 0.533s/it]: train_loss_raw=0.3238, running_loss=0.3356, LR=0.000100
[2025-08-11 17:49:54,142][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038460] [Batch 04377/04869] [00:38:54/00:04:22, 0.533s/it]: train_loss_raw=0.3305, running_loss=0.3341, LR=0.000100
[2025-08-11 17:50:00,558][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038472] [Batch 04389/04869] [00:39:01/00:04:16, 0.533s/it]: train_loss_raw=0.3240, running_loss=0.3343, LR=0.000100
[2025-08-11 17:50:06,990][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038484] [Batch 04401/04869] [00:39:07/00:04:09, 0.533s/it]: train_loss_raw=0.3269, running_loss=0.3353, LR=0.000100
[2025-08-11 17:50:13,255][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038496] [Batch 04413/04869] [00:39:14/00:04:03, 0.533s/it]: train_loss_raw=0.3271, running_loss=0.3343, LR=0.000100
[2025-08-11 17:50:19,745][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038508] [Batch 04425/04869] [00:39:20/00:03:56, 0.533s/it]: train_loss_raw=0.2803, running_loss=0.3343, LR=0.000100
[2025-08-11 17:50:26,188][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038520] [Batch 04437/04869] [00:39:26/00:03:50, 0.533s/it]: train_loss_raw=0.2949, running_loss=0.3337, LR=0.000100
[2025-08-11 17:50:32,793][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038532] [Batch 04449/04869] [00:39:33/00:03:44, 0.534s/it]: train_loss_raw=0.3915, running_loss=0.3346, LR=0.000100
[2025-08-11 17:50:39,269][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038544] [Batch 04461/04869] [00:39:40/00:03:37, 0.534s/it]: train_loss_raw=0.3062, running_loss=0.3360, LR=0.000100
[2025-08-11 17:50:45,700][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038556] [Batch 04473/04869] [00:39:46/00:03:31, 0.534s/it]: train_loss_raw=0.3575, running_loss=0.3362, LR=0.000100
[2025-08-11 17:50:52,166][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038568] [Batch 04485/04869] [00:39:52/00:03:24, 0.534s/it]: train_loss_raw=0.2972, running_loss=0.3352, LR=0.000100
[2025-08-11 17:50:58,691][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038580] [Batch 04497/04869] [00:39:59/00:03:18, 0.534s/it]: train_loss_raw=0.3142, running_loss=0.3394, LR=0.000100
[2025-08-11 17:51:05,174][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038592] [Batch 04509/04869] [00:40:05/00:03:12, 0.534s/it]: train_loss_raw=0.3966, running_loss=0.3390, LR=0.000100
[2025-08-11 17:51:11,734][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038604] [Batch 04521/04869] [00:40:12/00:03:05, 0.534s/it]: train_loss_raw=0.2738, running_loss=0.3408, LR=0.000100
[2025-08-11 17:51:18,222][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038616] [Batch 04533/04869] [00:40:19/00:02:59, 0.534s/it]: train_loss_raw=0.3148, running_loss=0.3408, LR=0.000100
[2025-08-11 17:51:24,663][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038628] [Batch 04545/04869] [00:40:25/00:02:52, 0.534s/it]: train_loss_raw=0.2810, running_loss=0.3404, LR=0.000100
[2025-08-11 17:51:31,190][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038640] [Batch 04557/04869] [00:40:31/00:02:46, 0.534s/it]: train_loss_raw=0.3378, running_loss=0.3377, LR=0.000100
[2025-08-11 17:51:37,766][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038652] [Batch 04569/04869] [00:40:38/00:02:40, 0.534s/it]: train_loss_raw=0.3682, running_loss=0.3364, LR=0.000100
[2025-08-11 17:51:44,372][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038664] [Batch 04581/04869] [00:40:45/00:02:33, 0.534s/it]: train_loss_raw=0.3239, running_loss=0.3370, LR=0.000100
[2025-08-11 17:51:50,883][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038676] [Batch 04593/04869] [00:40:51/00:02:27, 0.534s/it]: train_loss_raw=0.3027, running_loss=0.3345, LR=0.000100
[2025-08-11 17:51:57,643][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038688] [Batch 04605/04869] [00:40:58/00:02:20, 0.534s/it]: train_loss_raw=0.3645, running_loss=0.3359, LR=0.000100
[2025-08-11 17:52:04,183][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038700] [Batch 04617/04869] [00:41:04/00:02:14, 0.534s/it]: train_loss_raw=0.2346, running_loss=0.3340, LR=0.000100
[2025-08-11 17:52:10,642][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038712] [Batch 04629/04869] [00:41:11/00:02:08, 0.534s/it]: train_loss_raw=0.2534, running_loss=0.3327, LR=0.000100
[2025-08-11 17:52:17,173][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038724] [Batch 04641/04869] [00:41:17/00:02:01, 0.534s/it]: train_loss_raw=0.3528, running_loss=0.3312, LR=0.000100
[2025-08-11 17:52:23,634][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038736] [Batch 04653/04869] [00:41:24/00:01:55, 0.534s/it]: train_loss_raw=0.2638, running_loss=0.3319, LR=0.000100
[2025-08-11 17:52:30,115][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038748] [Batch 04665/04869] [00:41:30/00:01:48, 0.534s/it]: train_loss_raw=0.4478, running_loss=0.3317, LR=0.000100
[2025-08-11 17:52:36,613][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038760] [Batch 04677/04869] [00:41:37/00:01:42, 0.534s/it]: train_loss_raw=0.2886, running_loss=0.3300, LR=0.000100
[2025-08-11 17:52:43,192][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038772] [Batch 04689/04869] [00:41:43/00:01:36, 0.534s/it]: train_loss_raw=0.3118, running_loss=0.3286, LR=0.000100
[2025-08-11 17:52:49,878][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038784] [Batch 04701/04869] [00:41:50/00:01:29, 0.534s/it]: train_loss_raw=0.2670, running_loss=0.3267, LR=0.000100
[2025-08-11 17:52:56,385][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038796] [Batch 04713/04869] [00:41:57/00:01:23, 0.534s/it]: train_loss_raw=0.3533, running_loss=0.3289, LR=0.000100
[2025-08-11 17:53:02,826][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038808] [Batch 04725/04869] [00:42:03/00:01:16, 0.534s/it]: train_loss_raw=0.2781, running_loss=0.3284, LR=0.000100
[2025-08-11 17:53:09,240][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038820] [Batch 04737/04869] [00:42:10/00:01:10, 0.534s/it]: train_loss_raw=0.3979, running_loss=0.3304, LR=0.000100
[2025-08-11 17:53:15,655][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038832] [Batch 04749/04869] [00:42:16/00:01:04, 0.534s/it]: train_loss_raw=0.3439, running_loss=0.3258, LR=0.000100
[2025-08-11 17:53:22,067][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038844] [Batch 04761/04869] [00:42:22/00:00:57, 0.534s/it]: train_loss_raw=0.3300, running_loss=0.3242, LR=0.000100
[2025-08-11 17:53:28,511][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038856] [Batch 04773/04869] [00:42:29/00:00:51, 0.534s/it]: train_loss_raw=0.2099, running_loss=0.3230, LR=0.000100
[2025-08-11 17:53:34,824][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038868] [Batch 04785/04869] [00:42:35/00:00:44, 0.534s/it]: train_loss_raw=0.2945, running_loss=0.3281, LR=0.000100
[2025-08-11 17:53:41,189][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038880] [Batch 04797/04869] [00:42:41/00:00:38, 0.534s/it]: train_loss_raw=0.3614, running_loss=0.3293, LR=0.000100
[2025-08-11 17:53:47,801][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038892] [Batch 04809/04869] [00:42:48/00:00:32, 0.534s/it]: train_loss_raw=0.2796, running_loss=0.3269, LR=0.000100
[2025-08-11 17:53:54,133][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038904] [Batch 04821/04869] [00:42:54/00:00:25, 0.534s/it]: train_loss_raw=0.3404, running_loss=0.3273, LR=0.000100
[2025-08-11 17:54:00,569][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038916] [Batch 04833/04869] [00:43:01/00:00:19, 0.534s/it]: train_loss_raw=0.3125, running_loss=0.3276, LR=0.000100
[2025-08-11 17:54:06,949][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038928] [Batch 04845/04869] [00:43:07/00:00:12, 0.534s/it]: train_loss_raw=0.4932, running_loss=0.3269, LR=0.000100
[2025-08-11 17:54:13,386][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038940] [Batch 04857/04869] [00:43:14/00:00:06, 0.534s/it]: train_loss_raw=0.3633, running_loss=0.3270, LR=0.000100
[2025-08-11 17:54:43,635][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038952] [Batch 04869/04869] [00:43:44/00:00:00, 0.539s/it]: train_loss_raw=0.2655, running_loss=0.3256, LR=0.000100
[2025-08-11 17:54:48,510][__main__][INFO] - [VALIDATION] [Epoch 07/29] Starting validation.
[2025-08-11 17:55:03,935][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00011/00062] [00:00:15/00:01:04, 1.285s/it]
[2025-08-11 17:55:38,190][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00023/00062] [00:00:49/00:01:18, 2.070s/it]
[2025-08-11 17:55:54,202][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00035/00062] [00:01:05/00:00:47, 1.825s/it]
[2025-08-11 17:56:10,190][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00047/00062] [00:01:21/00:00:23, 1.702s/it]
[2025-08-11 17:56:25,366][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00059/00062] [00:01:36/00:00:03, 1.614s/it]
[2025-08-11 17:56:27,784][__main__][INFO] - [VALIDATION] [Epoch 07/29] train_loss=0.32562, valid_loss=0.38450
[2025-08-11 17:56:27,785][__main__][INFO] - [VALIDATION] [Epoch 07/29] Metrics:
[2025-08-11 17:56:27,785][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_er      0.187
[2025-08-11 17:56:27,785][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_prec    0.636
[2025-08-11 17:56:27,785][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_recall  0.640
[2025-08-11 17:56:27,785][__main__][INFO] - [VALIDATION] [Epoch 07/29] - pep_recall 0.600
[2025-08-11 17:56:27,791][__main__][INFO] - [TRAIN] [Epoch 07/29] Epoch complete, total time 06:01:06, remaining time 16:33:02, 00:45:08 per epoch
[2025-08-11 17:56:34,075][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 038964] [Batch 00012/04869] [00:00:05/00:40:17, 0.498s/it]: train_loss_raw=0.3762, running_loss=0.2857, LR=0.000100
[2025-08-11 17:56:40,447][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 038976] [Batch 00024/04869] [00:00:12/00:41:32, 0.514s/it]: train_loss_raw=0.2724, running_loss=0.2899, LR=0.000100
[2025-08-11 17:56:46,845][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 038988] [Batch 00036/04869] [00:00:18/00:41:56, 0.521s/it]: train_loss_raw=0.3589, running_loss=0.2953, LR=0.000100
[2025-08-11 17:56:53,237][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039000] [Batch 00048/04869] [00:00:25/00:42:04, 0.524s/it]: train_loss_raw=0.2658, running_loss=0.2977, LR=0.000100
[2025-08-11 17:56:59,556][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039012] [Batch 00060/04869] [00:00:31/00:42:01, 0.524s/it]: train_loss_raw=0.3338, running_loss=0.3002, LR=0.000100
[2025-08-11 17:57:06,031][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039024] [Batch 00072/04869] [00:00:37/00:42:07, 0.527s/it]: train_loss_raw=0.3257, running_loss=0.3061, LR=0.000100
[2025-08-11 17:57:12,521][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039036] [Batch 00084/04869] [00:00:44/00:42:10, 0.529s/it]: train_loss_raw=0.3907, running_loss=0.3089, LR=0.000100
[2025-08-11 17:57:18,863][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039048] [Batch 00096/04869] [00:00:50/00:42:03, 0.529s/it]: train_loss_raw=0.2639, running_loss=0.3128, LR=0.000100
[2025-08-11 17:57:25,229][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039060] [Batch 00108/04869] [00:00:57/00:41:58, 0.529s/it]: train_loss_raw=0.3110, running_loss=0.3150, LR=0.000100
[2025-08-11 17:57:31,569][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039072] [Batch 00120/04869] [00:01:03/00:41:51, 0.529s/it]: train_loss_raw=0.3913, running_loss=0.3150, LR=0.000100
[2025-08-11 17:57:38,127][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039084] [Batch 00132/04869] [00:01:10/00:41:52, 0.530s/it]: train_loss_raw=0.2795, running_loss=0.3153, LR=0.000100
[2025-08-11 17:57:44,555][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039096] [Batch 00144/04869] [00:01:16/00:41:48, 0.531s/it]: train_loss_raw=0.2905, running_loss=0.3149, LR=0.000100
[2025-08-11 17:57:51,086][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039108] [Batch 00156/04869] [00:01:22/00:41:47, 0.532s/it]: train_loss_raw=0.3280, running_loss=0.3155, LR=0.000100
[2025-08-11 17:57:57,286][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039120] [Batch 00168/04869] [00:01:29/00:41:35, 0.531s/it]: train_loss_raw=0.3435, running_loss=0.3154, LR=0.000100
[2025-08-11 17:58:03,608][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039132] [Batch 00180/04869] [00:01:35/00:41:27, 0.531s/it]: train_loss_raw=0.2999, running_loss=0.3141, LR=0.000100
[2025-08-11 17:58:09,975][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039144] [Batch 00192/04869] [00:01:41/00:41:21, 0.531s/it]: train_loss_raw=0.3527, running_loss=0.3140, LR=0.000100
[2025-08-11 17:58:16,460][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039156] [Batch 00204/04869] [00:01:48/00:41:17, 0.531s/it]: train_loss_raw=0.3116, running_loss=0.3135, LR=0.000100
[2025-08-11 17:58:22,993][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039168] [Batch 00216/04869] [00:01:54/00:41:14, 0.532s/it]: train_loss_raw=0.2857, running_loss=0.3165, LR=0.000100
[2025-08-11 17:58:29,507][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039180] [Batch 00228/04869] [00:02:01/00:41:11, 0.532s/it]: train_loss_raw=0.3931, running_loss=0.3173, LR=0.000100
[2025-08-11 17:58:35,929][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039192] [Batch 00240/04869] [00:02:07/00:41:05, 0.533s/it]: train_loss_raw=0.4072, running_loss=0.3177, LR=0.000100
[2025-08-11 17:58:42,210][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039204] [Batch 00252/04869] [00:02:14/00:40:57, 0.532s/it]: train_loss_raw=0.3302, running_loss=0.3174, LR=0.000100
[2025-08-11 17:58:48,553][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039216] [Batch 00264/04869] [00:02:20/00:40:49, 0.532s/it]: train_loss_raw=0.3624, running_loss=0.3177, LR=0.000100
[2025-08-11 17:58:54,845][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039228] [Batch 00276/04869] [00:02:26/00:40:42, 0.532s/it]: train_loss_raw=0.3026, running_loss=0.3172, LR=0.000100
[2025-08-11 17:59:01,124][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039240] [Batch 00288/04869] [00:02:33/00:40:34, 0.531s/it]: train_loss_raw=0.2557, running_loss=0.3188, LR=0.000100
[2025-08-11 17:59:07,522][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039252] [Batch 00300/04869] [00:02:39/00:40:27, 0.531s/it]: train_loss_raw=0.3133, running_loss=0.3202, LR=0.000100
[2025-08-11 17:59:13,963][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039264] [Batch 00312/04869] [00:02:45/00:40:22, 0.532s/it]: train_loss_raw=0.3965, running_loss=0.3224, LR=0.000100
[2025-08-11 17:59:20,503][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039276] [Batch 00324/04869] [00:02:52/00:40:18, 0.532s/it]: train_loss_raw=0.4161, running_loss=0.3222, LR=0.000100
[2025-08-11 17:59:26,864][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039288] [Batch 00336/04869] [00:02:58/00:40:11, 0.532s/it]: train_loss_raw=0.3723, running_loss=0.3224, LR=0.000100
[2025-08-11 17:59:33,230][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039300] [Batch 00348/04869] [00:03:05/00:40:05, 0.532s/it]: train_loss_raw=0.2786, running_loss=0.3250, LR=0.000100
[2025-08-11 17:59:39,583][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039312] [Batch 00360/04869] [00:03:11/00:39:58, 0.532s/it]: train_loss_raw=0.2787, running_loss=0.3239, LR=0.000100
[2025-08-11 17:59:45,921][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039324] [Batch 00372/04869] [00:03:17/00:39:51, 0.532s/it]: train_loss_raw=0.2589, running_loss=0.3223, LR=0.000100
[2025-08-11 17:59:52,433][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039336] [Batch 00384/04869] [00:03:24/00:39:46, 0.532s/it]: train_loss_raw=0.2988, running_loss=0.3249, LR=0.000100
[2025-08-11 17:59:58,926][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039348] [Batch 00396/04869] [00:03:30/00:39:41, 0.532s/it]: train_loss_raw=0.3686, running_loss=0.3240, LR=0.000100
[2025-08-11 18:00:05,466][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039360] [Batch 00408/04869] [00:03:37/00:39:36, 0.533s/it]: train_loss_raw=0.2719, running_loss=0.3235, LR=0.000100
[2025-08-11 18:00:11,942][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039372] [Batch 00420/04869] [00:03:43/00:39:31, 0.533s/it]: train_loss_raw=0.3722, running_loss=0.3226, LR=0.000100
[2025-08-11 18:00:18,392][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039384] [Batch 00432/04869] [00:03:50/00:39:25, 0.533s/it]: train_loss_raw=0.3553, running_loss=0.3220, LR=0.000100
[2025-08-11 18:00:24,947][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039396] [Batch 00444/04869] [00:03:56/00:39:20, 0.533s/it]: train_loss_raw=0.3370, running_loss=0.3223, LR=0.000100
[2025-08-11 18:00:31,491][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039408] [Batch 00456/04869] [00:04:03/00:39:15, 0.534s/it]: train_loss_raw=0.3226, running_loss=0.3233, LR=0.000100
[2025-08-11 18:00:38,028][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039420] [Batch 00468/04869] [00:04:09/00:39:10, 0.534s/it]: train_loss_raw=0.3170, running_loss=0.3252, LR=0.000100
[2025-08-11 18:00:44,470][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039432] [Batch 00480/04869] [00:04:16/00:39:04, 0.534s/it]: train_loss_raw=0.2951, running_loss=0.3284, LR=0.000100
[2025-08-11 18:00:50,989][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039444] [Batch 00492/04869] [00:04:22/00:38:58, 0.534s/it]: train_loss_raw=0.3621, running_loss=0.3296, LR=0.000100
[2025-08-11 18:00:57,426][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039456] [Batch 00504/04869] [00:04:29/00:38:52, 0.534s/it]: train_loss_raw=0.4193, running_loss=0.3303, LR=0.000100
[2025-08-11 18:01:03,950][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039468] [Batch 00516/04869] [00:04:35/00:38:47, 0.535s/it]: train_loss_raw=0.4547, running_loss=0.3305, LR=0.000100
[2025-08-11 18:01:10,166][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039480] [Batch 00528/04869] [00:04:42/00:38:39, 0.534s/it]: train_loss_raw=0.3370, running_loss=0.3319, LR=0.000100
[2025-08-11 18:01:16,345][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039492] [Batch 00540/04869] [00:04:48/00:38:30, 0.534s/it]: train_loss_raw=0.3646, running_loss=0.3262, LR=0.000100
[2025-08-11 18:01:22,519][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039504] [Batch 00552/04869] [00:04:54/00:38:22, 0.533s/it]: train_loss_raw=0.2945, running_loss=0.3260, LR=0.000100
[2025-08-11 18:01:28,646][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039516] [Batch 00564/04869] [00:05:00/00:38:14, 0.533s/it]: train_loss_raw=0.3200, running_loss=0.3257, LR=0.000100
[2025-08-11 18:01:34,917][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039528] [Batch 00576/04869] [00:05:06/00:38:06, 0.533s/it]: train_loss_raw=0.3501, running_loss=0.3255, LR=0.000100
[2025-08-11 18:01:41,048][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039540] [Batch 00588/04869] [00:05:12/00:37:58, 0.532s/it]: train_loss_raw=0.2667, running_loss=0.3243, LR=0.000100
[2025-08-11 18:01:47,241][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039552] [Batch 00600/04869] [00:05:19/00:37:50, 0.532s/it]: train_loss_raw=0.3466, running_loss=0.3234, LR=0.000100
[2025-08-11 18:01:53,425][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039564] [Batch 00612/04869] [00:05:25/00:37:42, 0.532s/it]: train_loss_raw=0.2855, running_loss=0.3224, LR=0.000100
[2025-08-11 18:01:59,675][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039576] [Batch 00624/04869] [00:05:31/00:37:35, 0.531s/it]: train_loss_raw=0.3332, running_loss=0.3241, LR=0.000100
[2025-08-11 18:02:05,945][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039588] [Batch 00636/04869] [00:05:37/00:37:28, 0.531s/it]: train_loss_raw=0.3293, running_loss=0.3230, LR=0.000100
[2025-08-11 18:02:12,067][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039600] [Batch 00648/04869] [00:05:43/00:37:20, 0.531s/it]: train_loss_raw=0.4043, running_loss=0.3231, LR=0.000100
[2025-08-11 18:02:18,478][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039612] [Batch 00660/04869] [00:05:50/00:37:14, 0.531s/it]: train_loss_raw=0.4452, running_loss=0.3235, LR=0.000100
[2025-08-11 18:02:24,849][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039624] [Batch 00672/04869] [00:05:56/00:37:08, 0.531s/it]: train_loss_raw=0.3674, running_loss=0.3228, LR=0.000100
[2025-08-11 18:02:31,283][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039636] [Batch 00684/04869] [00:06:03/00:37:02, 0.531s/it]: train_loss_raw=0.2851, running_loss=0.3216, LR=0.000100
[2025-08-11 18:02:37,708][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039648] [Batch 00696/04869] [00:06:09/00:36:56, 0.531s/it]: train_loss_raw=0.3350, running_loss=0.3205, LR=0.000100
[2025-08-11 18:02:44,218][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039660] [Batch 00708/04869] [00:06:16/00:36:50, 0.531s/it]: train_loss_raw=0.3083, running_loss=0.3215, LR=0.000100
[2025-08-11 18:02:50,511][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039672] [Batch 00720/04869] [00:06:22/00:36:43, 0.531s/it]: train_loss_raw=0.2751, running_loss=0.3215, LR=0.000100
[2025-08-11 18:02:56,904][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039684] [Batch 00732/04869] [00:06:28/00:36:37, 0.531s/it]: train_loss_raw=0.3031, running_loss=0.3201, LR=0.000100
[2025-08-11 18:03:03,098][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039696] [Batch 00744/04869] [00:06:34/00:36:30, 0.531s/it]: train_loss_raw=0.2961, running_loss=0.3209, LR=0.000100
[2025-08-11 18:03:09,432][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039708] [Batch 00756/04869] [00:06:41/00:36:23, 0.531s/it]: train_loss_raw=0.2815, running_loss=0.3204, LR=0.000100
[2025-08-11 18:03:15,842][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039720] [Batch 00768/04869] [00:06:47/00:36:17, 0.531s/it]: train_loss_raw=0.3156, running_loss=0.3196, LR=0.000100
[2025-08-11 18:03:22,100][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039732] [Batch 00780/04869] [00:06:53/00:36:10, 0.531s/it]: train_loss_raw=0.3574, running_loss=0.3224, LR=0.000100
[2025-08-11 18:03:28,422][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039744] [Batch 00792/04869] [00:07:00/00:36:03, 0.531s/it]: train_loss_raw=0.3078, running_loss=0.3246, LR=0.000100
[2025-08-11 18:03:34,741][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039756] [Batch 00804/04869] [00:07:06/00:35:57, 0.531s/it]: train_loss_raw=0.3671, running_loss=0.3261, LR=0.000100
[2025-08-11 18:03:41,019][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039768] [Batch 00816/04869] [00:07:12/00:35:50, 0.531s/it]: train_loss_raw=0.2467, running_loss=0.3253, LR=0.000100
[2025-08-11 18:03:47,303][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039780] [Batch 00828/04869] [00:07:19/00:35:43, 0.530s/it]: train_loss_raw=0.3863, running_loss=0.3263, LR=0.000100
[2025-08-11 18:03:53,494][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039792] [Batch 00840/04869] [00:07:25/00:35:36, 0.530s/it]: train_loss_raw=0.2398, running_loss=0.3224, LR=0.000100
[2025-08-11 18:03:59,795][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039804] [Batch 00852/04869] [00:07:31/00:35:29, 0.530s/it]: train_loss_raw=0.3423, running_loss=0.3219, LR=0.000100
[2025-08-11 18:04:06,178][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039816] [Batch 00864/04869] [00:07:38/00:35:23, 0.530s/it]: train_loss_raw=0.3879, running_loss=0.3230, LR=0.000100
[2025-08-11 18:04:12,529][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039828] [Batch 00876/04869] [00:07:44/00:35:16, 0.530s/it]: train_loss_raw=0.3409, running_loss=0.3252, LR=0.000100
[2025-08-11 18:04:19,086][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039840] [Batch 00888/04869] [00:07:50/00:35:11, 0.530s/it]: train_loss_raw=0.3539, running_loss=0.3265, LR=0.000100
[2025-08-11 18:04:25,509][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039852] [Batch 00900/04869] [00:07:57/00:35:05, 0.530s/it]: train_loss_raw=0.3103, running_loss=0.3254, LR=0.000100
[2025-08-11 18:04:31,892][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039864] [Batch 00912/04869] [00:08:03/00:34:59, 0.530s/it]: train_loss_raw=0.2147, running_loss=0.3255, LR=0.000100
[2025-08-11 18:04:38,175][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039876] [Batch 00924/04869] [00:08:10/00:34:52, 0.530s/it]: train_loss_raw=0.3231, running_loss=0.3240, LR=0.000100
[2025-08-11 18:04:44,544][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039888] [Batch 00936/04869] [00:08:16/00:34:46, 0.530s/it]: train_loss_raw=0.3588, running_loss=0.3246, LR=0.000100
[2025-08-11 18:04:50,918][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039900] [Batch 00948/04869] [00:08:22/00:34:39, 0.530s/it]: train_loss_raw=0.3421, running_loss=0.3227, LR=0.000100
[2025-08-11 18:04:57,376][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039912] [Batch 00960/04869] [00:08:29/00:34:33, 0.530s/it]: train_loss_raw=0.2434, running_loss=0.3235, LR=0.000100
[2025-08-11 18:05:03,836][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039924] [Batch 00972/04869] [00:08:35/00:34:27, 0.531s/it]: train_loss_raw=0.3360, running_loss=0.3223, LR=0.000100
[2025-08-11 18:05:10,150][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039936] [Batch 00984/04869] [00:08:42/00:34:21, 0.531s/it]: train_loss_raw=0.3667, running_loss=0.3218, LR=0.000100
[2025-08-11 18:05:16,561][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039948] [Batch 00996/04869] [00:08:48/00:34:14, 0.531s/it]: train_loss_raw=0.2655, running_loss=0.3202, LR=0.000100
[2025-08-11 18:05:22,897][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039960] [Batch 01008/04869] [00:08:54/00:34:08, 0.531s/it]: train_loss_raw=0.3728, running_loss=0.3212, LR=0.000100
[2025-08-11 18:05:29,255][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039972] [Batch 01020/04869] [00:09:01/00:34:02, 0.531s/it]: train_loss_raw=0.3071, running_loss=0.3233, LR=0.000100
[2025-08-11 18:05:35,590][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039984] [Batch 01032/04869] [00:09:07/00:33:55, 0.531s/it]: train_loss_raw=0.3000, running_loss=0.3238, LR=0.000100
[2025-08-11 18:05:41,870][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039996] [Batch 01044/04869] [00:09:13/00:33:48, 0.530s/it]: train_loss_raw=0.3376, running_loss=0.3253, LR=0.000100
[2025-08-11 18:05:52,582][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040008] [Batch 01056/04869] [00:09:24/00:33:58, 0.535s/it]: train_loss_raw=0.3429, running_loss=0.3260, LR=0.000100
[2025-08-11 18:05:58,929][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040020] [Batch 01068/04869] [00:09:30/00:33:51, 0.534s/it]: train_loss_raw=0.2681, running_loss=0.3258, LR=0.000100
[2025-08-11 18:06:05,410][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040032] [Batch 01080/04869] [00:09:37/00:33:45, 0.535s/it]: train_loss_raw=0.3800, running_loss=0.3262, LR=0.000100
[2025-08-11 18:06:11,898][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040044] [Batch 01092/04869] [00:09:43/00:33:39, 0.535s/it]: train_loss_raw=0.3107, running_loss=0.3266, LR=0.000100
[2025-08-11 18:06:18,362][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040056] [Batch 01104/04869] [00:09:50/00:33:32, 0.535s/it]: train_loss_raw=0.3360, running_loss=0.3232, LR=0.000100
[2025-08-11 18:06:24,836][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040068] [Batch 01116/04869] [00:09:56/00:33:26, 0.535s/it]: train_loss_raw=0.3122, running_loss=0.3229, LR=0.000100
[2025-08-11 18:06:31,211][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040080] [Batch 01128/04869] [00:10:03/00:33:20, 0.535s/it]: train_loss_raw=0.2772, running_loss=0.3225, LR=0.000100
[2025-08-11 18:06:37,439][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040092] [Batch 01140/04869] [00:10:09/00:33:13, 0.535s/it]: train_loss_raw=0.2607, running_loss=0.3205, LR=0.000100
[2025-08-11 18:06:43,764][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040104] [Batch 01152/04869] [00:10:15/00:33:06, 0.534s/it]: train_loss_raw=0.2956, running_loss=0.3194, LR=0.000100
[2025-08-11 18:06:50,137][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040116] [Batch 01164/04869] [00:10:22/00:32:59, 0.534s/it]: train_loss_raw=0.3121, running_loss=0.3195, LR=0.000100
[2025-08-11 18:06:56,485][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040128] [Batch 01176/04869] [00:10:28/00:32:53, 0.534s/it]: train_loss_raw=0.4107, running_loss=0.3213, LR=0.000100
[2025-08-11 18:07:02,773][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040140] [Batch 01188/04869] [00:10:34/00:32:46, 0.534s/it]: train_loss_raw=0.3142, running_loss=0.3230, LR=0.000100
[2025-08-11 18:07:09,062][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040152] [Batch 01200/04869] [00:10:40/00:32:39, 0.534s/it]: train_loss_raw=0.2917, running_loss=0.3223, LR=0.000100
[2025-08-11 18:07:15,359][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040164] [Batch 01212/04869] [00:10:47/00:32:32, 0.534s/it]: train_loss_raw=0.2505, running_loss=0.3187, LR=0.000100
[2025-08-11 18:07:21,661][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040176] [Batch 01224/04869] [00:10:53/00:32:26, 0.534s/it]: train_loss_raw=0.3977, running_loss=0.3175, LR=0.000100
[2025-08-11 18:07:28,013][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040188] [Batch 01236/04869] [00:10:59/00:32:19, 0.534s/it]: train_loss_raw=0.2110, running_loss=0.3161, LR=0.000100
[2025-08-11 18:07:34,431][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040200] [Batch 01248/04869] [00:11:06/00:32:13, 0.534s/it]: train_loss_raw=0.2718, running_loss=0.3159, LR=0.000100
[2025-08-11 18:07:40,719][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040212] [Batch 01260/04869] [00:11:12/00:32:06, 0.534s/it]: train_loss_raw=0.2870, running_loss=0.3182, LR=0.000100
[2025-08-11 18:07:47,151][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040224] [Batch 01272/04869] [00:11:19/00:32:00, 0.534s/it]: train_loss_raw=0.3257, running_loss=0.3172, LR=0.000100
[2025-08-11 18:07:53,408][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040236] [Batch 01284/04869] [00:11:25/00:31:53, 0.534s/it]: train_loss_raw=0.3383, running_loss=0.3163, LR=0.000100
[2025-08-11 18:07:59,821][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040248] [Batch 01296/04869] [00:11:31/00:31:47, 0.534s/it]: train_loss_raw=0.3189, running_loss=0.3147, LR=0.000100
[2025-08-11 18:08:06,145][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040260] [Batch 01308/04869] [00:11:38/00:31:40, 0.534s/it]: train_loss_raw=0.1873, running_loss=0.3146, LR=0.000100
[2025-08-11 18:08:12,437][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040272] [Batch 01320/04869] [00:11:44/00:31:33, 0.534s/it]: train_loss_raw=0.3270, running_loss=0.3141, LR=0.000100
[2025-08-11 18:08:18,819][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040284] [Batch 01332/04869] [00:11:50/00:31:27, 0.534s/it]: train_loss_raw=0.3173, running_loss=0.3144, LR=0.000100
[2025-08-11 18:08:25,318][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040296] [Batch 01344/04869] [00:11:57/00:31:21, 0.534s/it]: train_loss_raw=0.4775, running_loss=0.3169, LR=0.000100
[2025-08-11 18:08:31,737][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040308] [Batch 01356/04869] [00:12:03/00:31:14, 0.534s/it]: train_loss_raw=0.3319, running_loss=0.3154, LR=0.000100
[2025-08-11 18:08:37,973][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040320] [Batch 01368/04869] [00:12:09/00:31:07, 0.534s/it]: train_loss_raw=0.3314, running_loss=0.3155, LR=0.000100
[2025-08-11 18:08:44,304][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040332] [Batch 01380/04869] [00:12:16/00:31:01, 0.533s/it]: train_loss_raw=0.2628, running_loss=0.3178, LR=0.000100
[2025-08-11 18:08:50,602][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040344] [Batch 01392/04869] [00:12:22/00:30:54, 0.533s/it]: train_loss_raw=0.1924, running_loss=0.3183, LR=0.000100
[2025-08-11 18:08:56,869][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040356] [Batch 01404/04869] [00:12:28/00:30:47, 0.533s/it]: train_loss_raw=0.3675, running_loss=0.3182, LR=0.000100
[2025-08-11 18:09:03,181][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040368] [Batch 01416/04869] [00:12:35/00:30:41, 0.533s/it]: train_loss_raw=0.2934, running_loss=0.3176, LR=0.000100
[2025-08-11 18:09:09,573][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040380] [Batch 01428/04869] [00:12:41/00:30:34, 0.533s/it]: train_loss_raw=0.3313, running_loss=0.3195, LR=0.000100
[2025-08-11 18:09:16,087][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040392] [Batch 01440/04869] [00:12:47/00:30:28, 0.533s/it]: train_loss_raw=0.3899, running_loss=0.3191, LR=0.000100
[2025-08-11 18:09:22,440][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040404] [Batch 01452/04869] [00:12:54/00:30:22, 0.533s/it]: train_loss_raw=0.3235, running_loss=0.3194, LR=0.000100
[2025-08-11 18:09:28,848][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040416] [Batch 01464/04869] [00:13:00/00:30:15, 0.533s/it]: train_loss_raw=0.2653, running_loss=0.3215, LR=0.000100
[2025-08-11 18:09:35,249][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040428] [Batch 01476/04869] [00:13:07/00:30:09, 0.533s/it]: train_loss_raw=0.2698, running_loss=0.3229, LR=0.000100
[2025-08-11 18:09:41,652][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040440] [Batch 01488/04869] [00:13:13/00:30:03, 0.533s/it]: train_loss_raw=0.2852, running_loss=0.3237, LR=0.000100
[2025-08-11 18:09:48,022][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040452] [Batch 01500/04869] [00:13:19/00:29:56, 0.533s/it]: train_loss_raw=0.3378, running_loss=0.3246, LR=0.000100
[2025-08-11 18:09:54,322][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040464] [Batch 01512/04869] [00:13:26/00:29:50, 0.533s/it]: train_loss_raw=0.3325, running_loss=0.3247, LR=0.000100
[2025-08-11 18:10:00,738][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040476] [Batch 01524/04869] [00:13:32/00:29:43, 0.533s/it]: train_loss_raw=0.3716, running_loss=0.3268, LR=0.000100
[2025-08-11 18:10:07,169][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040488] [Batch 01536/04869] [00:13:39/00:29:37, 0.533s/it]: train_loss_raw=0.2967, running_loss=0.3268, LR=0.000100
[2025-08-11 18:10:13,620][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040500] [Batch 01548/04869] [00:13:45/00:29:31, 0.533s/it]: train_loss_raw=0.3007, running_loss=0.3251, LR=0.000100
[2025-08-11 18:10:20,001][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040512] [Batch 01560/04869] [00:13:51/00:29:24, 0.533s/it]: train_loss_raw=0.3178, running_loss=0.3261, LR=0.000100
[2025-08-11 18:10:26,162][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040524] [Batch 01572/04869] [00:13:58/00:29:17, 0.533s/it]: train_loss_raw=0.2348, running_loss=0.3240, LR=0.000100
[2025-08-11 18:10:32,316][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040536] [Batch 01584/04869] [00:14:04/00:29:10, 0.533s/it]: train_loss_raw=0.2874, running_loss=0.3219, LR=0.000100
[2025-08-11 18:10:38,680][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040548] [Batch 01596/04869] [00:14:10/00:29:04, 0.533s/it]: train_loss_raw=0.3509, running_loss=0.3195, LR=0.000100
[2025-08-11 18:10:44,902][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040560] [Batch 01608/04869] [00:14:16/00:28:57, 0.533s/it]: train_loss_raw=0.3025, running_loss=0.3202, LR=0.000100
[2025-08-11 18:10:51,213][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040572] [Batch 01620/04869] [00:14:23/00:28:51, 0.533s/it]: train_loss_raw=0.3101, running_loss=0.3188, LR=0.000100
[2025-08-11 18:10:57,620][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040584] [Batch 01632/04869] [00:14:29/00:28:44, 0.533s/it]: train_loss_raw=0.3230, running_loss=0.3178, LR=0.000100
[2025-08-11 18:11:04,153][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040596] [Batch 01644/04869] [00:14:36/00:28:38, 0.533s/it]: train_loss_raw=0.3403, running_loss=0.3196, LR=0.000100
[2025-08-11 18:11:10,374][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040608] [Batch 01656/04869] [00:14:42/00:28:31, 0.533s/it]: train_loss_raw=0.3415, running_loss=0.3190, LR=0.000100
[2025-08-11 18:11:16,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040620] [Batch 01668/04869] [00:14:48/00:28:25, 0.533s/it]: train_loss_raw=0.3291, running_loss=0.3190, LR=0.000100
[2025-08-11 18:11:23,022][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040632] [Batch 01680/04869] [00:14:54/00:28:18, 0.533s/it]: train_loss_raw=0.3215, running_loss=0.3205, LR=0.000100
[2025-08-11 18:11:29,213][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040644] [Batch 01692/04869] [00:15:01/00:28:11, 0.533s/it]: train_loss_raw=0.2229, running_loss=0.3188, LR=0.000100
[2025-08-11 18:11:35,373][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040656] [Batch 01704/04869] [00:15:07/00:28:05, 0.532s/it]: train_loss_raw=0.2844, running_loss=0.3190, LR=0.000100
[2025-08-11 18:11:41,567][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040668] [Batch 01716/04869] [00:15:13/00:27:58, 0.532s/it]: train_loss_raw=0.2995, running_loss=0.3198, LR=0.000100
[2025-08-11 18:11:47,781][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040680] [Batch 01728/04869] [00:15:19/00:27:51, 0.532s/it]: train_loss_raw=0.3174, running_loss=0.3195, LR=0.000100
[2025-08-11 18:11:53,951][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040692] [Batch 01740/04869] [00:15:25/00:27:44, 0.532s/it]: train_loss_raw=0.3387, running_loss=0.3228, LR=0.000100
[2025-08-11 18:12:00,146][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040704] [Batch 01752/04869] [00:15:32/00:27:38, 0.532s/it]: train_loss_raw=0.4285, running_loss=0.3223, LR=0.000100
[2025-08-11 18:12:06,214][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040716] [Batch 01764/04869] [00:15:38/00:27:31, 0.532s/it]: train_loss_raw=0.3117, running_loss=0.3241, LR=0.000100
[2025-08-11 18:12:12,373][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040728] [Batch 01776/04869] [00:15:44/00:27:24, 0.532s/it]: train_loss_raw=0.2924, running_loss=0.3251, LR=0.000100
[2025-08-11 18:12:18,569][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040740] [Batch 01788/04869] [00:15:50/00:27:17, 0.532s/it]: train_loss_raw=0.2404, running_loss=0.3231, LR=0.000100
[2025-08-11 18:12:24,848][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040752] [Batch 01800/04869] [00:15:56/00:27:11, 0.532s/it]: train_loss_raw=0.3144, running_loss=0.3237, LR=0.000100
[2025-08-11 18:12:31,153][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040764] [Batch 01812/04869] [00:16:03/00:27:04, 0.531s/it]: train_loss_raw=0.2547, running_loss=0.3243, LR=0.000100
[2025-08-11 18:12:37,267][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040776] [Batch 01824/04869] [00:16:09/00:26:57, 0.531s/it]: train_loss_raw=0.3854, running_loss=0.3246, LR=0.000100
[2025-08-11 18:12:43,709][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040788] [Batch 01836/04869] [00:16:15/00:26:51, 0.531s/it]: train_loss_raw=0.3062, running_loss=0.3252, LR=0.000100
[2025-08-11 18:12:50,027][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040800] [Batch 01848/04869] [00:16:21/00:26:45, 0.531s/it]: train_loss_raw=0.2335, running_loss=0.3223, LR=0.000100
[2025-08-11 18:12:56,309][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040812] [Batch 01860/04869] [00:16:28/00:26:38, 0.531s/it]: train_loss_raw=0.3361, running_loss=0.3212, LR=0.000100
[2025-08-11 18:13:02,731][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040824] [Batch 01872/04869] [00:16:34/00:26:32, 0.531s/it]: train_loss_raw=0.2826, running_loss=0.3228, LR=0.000100
[2025-08-11 18:13:08,985][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040836] [Batch 01884/04869] [00:16:40/00:26:25, 0.531s/it]: train_loss_raw=0.3824, running_loss=0.3252, LR=0.000100
[2025-08-11 18:13:15,209][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040848] [Batch 01896/04869] [00:16:47/00:26:19, 0.531s/it]: train_loss_raw=0.2981, running_loss=0.3264, LR=0.000100
[2025-08-11 18:13:21,514][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040860] [Batch 01908/04869] [00:16:53/00:26:12, 0.531s/it]: train_loss_raw=0.3521, running_loss=0.3274, LR=0.000100
[2025-08-11 18:13:27,821][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040872] [Batch 01920/04869] [00:16:59/00:26:06, 0.531s/it]: train_loss_raw=0.3281, running_loss=0.3293, LR=0.000100
[2025-08-11 18:13:34,169][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040884] [Batch 01932/04869] [00:17:06/00:25:59, 0.531s/it]: train_loss_raw=0.2926, running_loss=0.3292, LR=0.000100
[2025-08-11 18:13:40,495][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040896] [Batch 01944/04869] [00:17:12/00:25:53, 0.531s/it]: train_loss_raw=0.3494, running_loss=0.3287, LR=0.000100
[2025-08-11 18:13:46,845][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040908] [Batch 01956/04869] [00:17:18/00:25:46, 0.531s/it]: train_loss_raw=0.2567, running_loss=0.3276, LR=0.000100
[2025-08-11 18:13:53,149][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040920] [Batch 01968/04869] [00:17:25/00:25:40, 0.531s/it]: train_loss_raw=0.3016, running_loss=0.3269, LR=0.000100
[2025-08-11 18:13:59,447][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040932] [Batch 01980/04869] [00:17:31/00:25:34, 0.531s/it]: train_loss_raw=0.3108, running_loss=0.3276, LR=0.000100
[2025-08-11 18:14:05,789][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040944] [Batch 01992/04869] [00:17:37/00:25:27, 0.531s/it]: train_loss_raw=0.3241, running_loss=0.3268, LR=0.000100
[2025-08-11 18:14:12,253][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040956] [Batch 02004/04869] [00:17:44/00:25:21, 0.531s/it]: train_loss_raw=0.3444, running_loss=0.3291, LR=0.000100
[2025-08-11 18:14:18,620][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040968] [Batch 02016/04869] [00:17:50/00:25:14, 0.531s/it]: train_loss_raw=0.3234, running_loss=0.3272, LR=0.000100
[2025-08-11 18:14:52,421][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040980] [Batch 02028/04869] [00:18:24/00:25:47, 0.545s/it]: train_loss_raw=0.3014, running_loss=0.3264, LR=0.000100
[2025-08-11 18:14:58,856][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040992] [Batch 02040/04869] [00:18:30/00:25:40, 0.544s/it]: train_loss_raw=0.3399, running_loss=0.3197, LR=0.000100
[2025-08-11 18:15:05,233][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041004] [Batch 02052/04869] [00:18:37/00:25:33, 0.544s/it]: train_loss_raw=0.2235, running_loss=0.3173, LR=0.000100
[2025-08-11 18:15:11,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041016] [Batch 02064/04869] [00:18:43/00:25:26, 0.544s/it]: train_loss_raw=0.2968, running_loss=0.3185, LR=0.000100
[2025-08-11 18:15:18,005][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041028] [Batch 02076/04869] [00:18:49/00:25:20, 0.544s/it]: train_loss_raw=0.2535, running_loss=0.3166, LR=0.000100
[2025-08-11 18:15:24,315][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041040] [Batch 02088/04869] [00:18:56/00:25:13, 0.544s/it]: train_loss_raw=0.3753, running_loss=0.3196, LR=0.000100
[2025-08-11 18:15:30,601][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041052] [Batch 02100/04869] [00:19:02/00:25:06, 0.544s/it]: train_loss_raw=0.3299, running_loss=0.3177, LR=0.000100
[2025-08-11 18:15:36,950][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041064] [Batch 02112/04869] [00:19:08/00:24:59, 0.544s/it]: train_loss_raw=0.2451, running_loss=0.3160, LR=0.000100
[2025-08-11 18:15:43,294][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041076] [Batch 02124/04869] [00:19:15/00:24:52, 0.544s/it]: train_loss_raw=0.2137, running_loss=0.3143, LR=0.000100
[2025-08-11 18:15:49,608][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041088] [Batch 02136/04869] [00:19:21/00:24:46, 0.544s/it]: train_loss_raw=0.2801, running_loss=0.3126, LR=0.000100
[2025-08-11 18:15:55,945][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041100] [Batch 02148/04869] [00:19:27/00:24:39, 0.544s/it]: train_loss_raw=0.2938, running_loss=0.3105, LR=0.000100
[2025-08-11 18:16:02,304][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041112] [Batch 02160/04869] [00:19:34/00:24:32, 0.544s/it]: train_loss_raw=0.2878, running_loss=0.3105, LR=0.000100
[2025-08-11 18:16:08,593][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041124] [Batch 02172/04869] [00:19:40/00:24:25, 0.544s/it]: train_loss_raw=0.3851, running_loss=0.3105, LR=0.000100
[2025-08-11 18:16:14,962][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041136] [Batch 02184/04869] [00:19:46/00:24:19, 0.543s/it]: train_loss_raw=0.3620, running_loss=0.3111, LR=0.000100
[2025-08-11 18:16:21,322][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041148] [Batch 02196/04869] [00:19:53/00:24:12, 0.543s/it]: train_loss_raw=0.2604, running_loss=0.3114, LR=0.000100
[2025-08-11 18:16:27,663][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041160] [Batch 02208/04869] [00:19:59/00:24:05, 0.543s/it]: train_loss_raw=0.3471, running_loss=0.3113, LR=0.000100
[2025-08-11 18:16:34,067][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041172] [Batch 02220/04869] [00:20:05/00:23:59, 0.543s/it]: train_loss_raw=0.3079, running_loss=0.3111, LR=0.000100
[2025-08-11 18:16:40,403][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041184] [Batch 02232/04869] [00:20:12/00:23:52, 0.543s/it]: train_loss_raw=0.3344, running_loss=0.3113, LR=0.000100
[2025-08-11 18:16:46,768][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041196] [Batch 02244/04869] [00:20:18/00:23:45, 0.543s/it]: train_loss_raw=0.3042, running_loss=0.3117, LR=0.000100
[2025-08-11 18:16:53,270][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041208] [Batch 02256/04869] [00:20:25/00:23:39, 0.543s/it]: train_loss_raw=0.3189, running_loss=0.3104, LR=0.000100
[2025-08-11 18:16:59,751][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041220] [Batch 02268/04869] [00:20:31/00:23:32, 0.543s/it]: train_loss_raw=0.2999, running_loss=0.3130, LR=0.000100
[2025-08-11 18:17:06,154][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041232] [Batch 02280/04869] [00:20:38/00:23:25, 0.543s/it]: train_loss_raw=0.3016, running_loss=0.3145, LR=0.000100
[2025-08-11 18:17:12,516][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041244] [Batch 02292/04869] [00:20:44/00:23:19, 0.543s/it]: train_loss_raw=0.3681, running_loss=0.3126, LR=0.000100
[2025-08-11 18:17:18,874][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041256] [Batch 02304/04869] [00:20:50/00:23:12, 0.543s/it]: train_loss_raw=0.3168, running_loss=0.3147, LR=0.000100
[2025-08-11 18:17:25,256][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041268] [Batch 02316/04869] [00:20:57/00:23:05, 0.543s/it]: train_loss_raw=0.2966, running_loss=0.3122, LR=0.000100
[2025-08-11 18:17:31,686][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041280] [Batch 02328/04869] [00:21:03/00:22:59, 0.543s/it]: train_loss_raw=0.2895, running_loss=0.3140, LR=0.000100
[2025-08-11 18:17:37,894][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041292] [Batch 02340/04869] [00:21:09/00:22:52, 0.543s/it]: train_loss_raw=0.2345, running_loss=0.3137, LR=0.000100
[2025-08-11 18:17:44,174][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041304] [Batch 02352/04869] [00:21:16/00:22:45, 0.543s/it]: train_loss_raw=0.2997, running_loss=0.3128, LR=0.000100
[2025-08-11 18:17:50,463][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041316] [Batch 02364/04869] [00:21:22/00:22:38, 0.542s/it]: train_loss_raw=0.3317, running_loss=0.3126, LR=0.000100
[2025-08-11 18:17:56,712][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041328] [Batch 02376/04869] [00:21:28/00:22:32, 0.542s/it]: train_loss_raw=0.3105, running_loss=0.3110, LR=0.000100
[2025-08-11 18:18:03,001][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041340] [Batch 02388/04869] [00:21:34/00:22:25, 0.542s/it]: train_loss_raw=0.2545, running_loss=0.3116, LR=0.000100
[2025-08-11 18:18:09,290][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041352] [Batch 02400/04869] [00:21:41/00:22:18, 0.542s/it]: train_loss_raw=0.2660, running_loss=0.3119, LR=0.000100
[2025-08-11 18:18:15,694][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041364] [Batch 02412/04869] [00:21:47/00:22:11, 0.542s/it]: train_loss_raw=0.3331, running_loss=0.3100, LR=0.000100
[2025-08-11 18:18:22,172][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041376] [Batch 02424/04869] [00:21:54/00:22:05, 0.542s/it]: train_loss_raw=0.3553, running_loss=0.3100, LR=0.000100
[2025-08-11 18:18:28,601][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041388] [Batch 02436/04869] [00:22:00/00:21:58, 0.542s/it]: train_loss_raw=0.2740, running_loss=0.3092, LR=0.000100
[2025-08-11 18:18:35,081][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041400] [Batch 02448/04869] [00:22:06/00:21:52, 0.542s/it]: train_loss_raw=0.2280, running_loss=0.3072, LR=0.000100
[2025-08-11 18:18:41,498][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041412] [Batch 02460/04869] [00:22:13/00:21:45, 0.542s/it]: train_loss_raw=0.3216, running_loss=0.3070, LR=0.000100
[2025-08-11 18:18:48,016][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041424] [Batch 02472/04869] [00:22:19/00:21:39, 0.542s/it]: train_loss_raw=0.3643, running_loss=0.3046, LR=0.000100
[2025-08-11 18:18:54,527][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041436] [Batch 02484/04869] [00:22:26/00:21:32, 0.542s/it]: train_loss_raw=0.3162, running_loss=0.3052, LR=0.000100
[2025-08-11 18:19:00,998][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041448] [Batch 02496/04869] [00:22:32/00:21:26, 0.542s/it]: train_loss_raw=0.3705, running_loss=0.3082, LR=0.000100
[2025-08-11 18:19:07,492][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041460] [Batch 02508/04869] [00:22:39/00:21:19, 0.542s/it]: train_loss_raw=0.3401, running_loss=0.3112, LR=0.000100
[2025-08-11 18:19:13,881][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041472] [Batch 02520/04869] [00:22:45/00:21:13, 0.542s/it]: train_loss_raw=0.2858, running_loss=0.3135, LR=0.000100
[2025-08-11 18:19:20,274][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041484] [Batch 02532/04869] [00:22:52/00:21:06, 0.542s/it]: train_loss_raw=0.3164, running_loss=0.3148, LR=0.000100
[2025-08-11 18:19:26,596][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041496] [Batch 02544/04869] [00:22:58/00:20:59, 0.542s/it]: train_loss_raw=0.3004, running_loss=0.3121, LR=0.000100
[2025-08-11 18:19:32,988][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041508] [Batch 02556/04869] [00:23:04/00:20:53, 0.542s/it]: train_loss_raw=0.3410, running_loss=0.3115, LR=0.000100
[2025-08-11 18:19:39,387][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041520] [Batch 02568/04869] [00:23:11/00:20:46, 0.542s/it]: train_loss_raw=0.3324, running_loss=0.3134, LR=0.000100
[2025-08-11 18:19:45,731][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041532] [Batch 02580/04869] [00:23:17/00:20:39, 0.542s/it]: train_loss_raw=0.4487, running_loss=0.3148, LR=0.000100
[2025-08-11 18:19:52,073][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041544] [Batch 02592/04869] [00:23:23/00:20:33, 0.542s/it]: train_loss_raw=0.2366, running_loss=0.3137, LR=0.000100
[2025-08-11 18:19:58,467][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041556] [Batch 02604/04869] [00:23:30/00:20:26, 0.542s/it]: train_loss_raw=0.3288, running_loss=0.3129, LR=0.000100
[2025-08-11 18:20:04,909][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041568] [Batch 02616/04869] [00:23:36/00:20:20, 0.542s/it]: train_loss_raw=0.3241, running_loss=0.3100, LR=0.000100
[2025-08-11 18:20:11,212][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041580] [Batch 02628/04869] [00:23:43/00:20:13, 0.542s/it]: train_loss_raw=0.2434, running_loss=0.3087, LR=0.000100
[2025-08-11 18:20:17,542][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041592] [Batch 02640/04869] [00:23:49/00:20:06, 0.541s/it]: train_loss_raw=0.2515, running_loss=0.3089, LR=0.000100
[2025-08-11 18:20:23,945][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041604] [Batch 02652/04869] [00:23:55/00:20:00, 0.541s/it]: train_loss_raw=0.3833, running_loss=0.3097, LR=0.000100
[2025-08-11 18:20:30,266][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041616] [Batch 02664/04869] [00:24:02/00:19:53, 0.541s/it]: train_loss_raw=0.2800, running_loss=0.3107, LR=0.000100
[2025-08-11 18:20:36,680][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041628] [Batch 02676/04869] [00:24:08/00:19:47, 0.541s/it]: train_loss_raw=0.3616, running_loss=0.3113, LR=0.000100
[2025-08-11 18:20:42,988][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041640] [Batch 02688/04869] [00:24:14/00:19:40, 0.541s/it]: train_loss_raw=0.2847, running_loss=0.3114, LR=0.000100
[2025-08-11 18:20:49,263][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041652] [Batch 02700/04869] [00:24:21/00:19:33, 0.541s/it]: train_loss_raw=0.2929, running_loss=0.3114, LR=0.000100
[2025-08-11 18:20:55,671][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041664] [Batch 02712/04869] [00:24:27/00:19:27, 0.541s/it]: train_loss_raw=0.2790, running_loss=0.3107, LR=0.000100
[2025-08-11 18:21:02,131][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041676] [Batch 02724/04869] [00:24:34/00:19:20, 0.541s/it]: train_loss_raw=0.2855, running_loss=0.3115, LR=0.000100
[2025-08-11 18:21:08,506][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041688] [Batch 02736/04869] [00:24:40/00:19:14, 0.541s/it]: train_loss_raw=0.2911, running_loss=0.3129, LR=0.000100
[2025-08-11 18:21:14,941][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041700] [Batch 02748/04869] [00:24:46/00:19:07, 0.541s/it]: train_loss_raw=0.3242, running_loss=0.3159, LR=0.000100
[2025-08-11 18:21:21,365][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041712] [Batch 02760/04869] [00:24:53/00:19:01, 0.541s/it]: train_loss_raw=0.2770, running_loss=0.3146, LR=0.000100
[2025-08-11 18:21:27,697][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041724] [Batch 02772/04869] [00:24:59/00:18:54, 0.541s/it]: train_loss_raw=0.2664, running_loss=0.3107, LR=0.000100
[2025-08-11 18:21:34,058][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041736] [Batch 02784/04869] [00:25:05/00:18:47, 0.541s/it]: train_loss_raw=0.2975, running_loss=0.3105, LR=0.000100
[2025-08-11 18:21:40,484][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041748] [Batch 02796/04869] [00:25:12/00:18:41, 0.541s/it]: train_loss_raw=0.2915, running_loss=0.3079, LR=0.000100
[2025-08-11 18:21:47,067][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041760] [Batch 02808/04869] [00:25:18/00:18:34, 0.541s/it]: train_loss_raw=0.2616, running_loss=0.3064, LR=0.000100
[2025-08-11 18:21:53,456][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041772] [Batch 02820/04869] [00:25:25/00:18:28, 0.541s/it]: train_loss_raw=0.3271, running_loss=0.3060, LR=0.000100
[2025-08-11 18:21:59,903][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041784] [Batch 02832/04869] [00:25:31/00:18:21, 0.541s/it]: train_loss_raw=0.3092, running_loss=0.3062, LR=0.000100
[2025-08-11 18:22:06,373][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041796] [Batch 02844/04869] [00:25:38/00:18:15, 0.541s/it]: train_loss_raw=0.3402, running_loss=0.3063, LR=0.000100
[2025-08-11 18:22:12,822][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041808] [Batch 02856/04869] [00:25:44/00:18:08, 0.541s/it]: train_loss_raw=0.2798, running_loss=0.3074, LR=0.000100
[2025-08-11 18:22:19,366][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041820] [Batch 02868/04869] [00:25:51/00:18:02, 0.541s/it]: train_loss_raw=0.3050, running_loss=0.3072, LR=0.000100
[2025-08-11 18:22:25,828][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041832] [Batch 02880/04869] [00:25:57/00:17:55, 0.541s/it]: train_loss_raw=0.3366, running_loss=0.3076, LR=0.000100
[2025-08-11 18:22:32,253][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041844] [Batch 02892/04869] [00:26:04/00:17:49, 0.541s/it]: train_loss_raw=0.2957, running_loss=0.3070, LR=0.000100
[2025-08-11 18:22:38,747][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041856] [Batch 02904/04869] [00:26:10/00:17:42, 0.541s/it]: train_loss_raw=0.2822, running_loss=0.3088, LR=0.000100
[2025-08-11 18:22:45,229][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041868] [Batch 02916/04869] [00:26:17/00:17:36, 0.541s/it]: train_loss_raw=0.2188, running_loss=0.3087, LR=0.000100
[2025-08-11 18:22:51,637][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041880] [Batch 02928/04869] [00:26:23/00:17:29, 0.541s/it]: train_loss_raw=0.3568, running_loss=0.3115, LR=0.000100
[2025-08-11 18:22:58,149][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041892] [Batch 02940/04869] [00:26:30/00:17:23, 0.541s/it]: train_loss_raw=0.3587, running_loss=0.3120, LR=0.000100
[2025-08-11 18:23:04,587][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041904] [Batch 02952/04869] [00:26:36/00:17:16, 0.541s/it]: train_loss_raw=0.3358, running_loss=0.3131, LR=0.000100
[2025-08-11 18:23:10,942][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041916] [Batch 02964/04869] [00:26:42/00:17:10, 0.541s/it]: train_loss_raw=0.3358, running_loss=0.3087, LR=0.000100
[2025-08-11 18:23:17,434][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041928] [Batch 02976/04869] [00:26:49/00:17:03, 0.541s/it]: train_loss_raw=0.2951, running_loss=0.3091, LR=0.000100
[2025-08-11 18:23:23,954][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041940] [Batch 02988/04869] [00:26:55/00:16:57, 0.541s/it]: train_loss_raw=0.2808, running_loss=0.3099, LR=0.000100
[2025-08-11 18:23:30,403][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041952] [Batch 03000/04869] [00:27:02/00:16:50, 0.541s/it]: train_loss_raw=0.2477, running_loss=0.3101, LR=0.000100
[2025-08-11 18:23:36,890][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041964] [Batch 03012/04869] [00:27:08/00:16:44, 0.541s/it]: train_loss_raw=0.2941, running_loss=0.3117, LR=0.000100
[2025-08-11 18:23:43,330][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041976] [Batch 03024/04869] [00:27:15/00:16:37, 0.541s/it]: train_loss_raw=0.3575, running_loss=0.3135, LR=0.000100
[2025-08-11 18:23:49,867][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041988] [Batch 03036/04869] [00:27:21/00:16:31, 0.541s/it]: train_loss_raw=0.2736, running_loss=0.3112, LR=0.000100
[2025-08-11 18:23:56,345][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042000] [Batch 03048/04869] [00:27:28/00:16:24, 0.541s/it]: train_loss_raw=0.3001, running_loss=0.3112, LR=0.000100
[2025-08-11 18:24:08,718][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042012] [Batch 03060/04869] [00:27:40/00:16:21, 0.543s/it]: train_loss_raw=0.2873, running_loss=0.3122, LR=0.000100
[2025-08-11 18:24:15,157][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042024] [Batch 03072/04869] [00:27:47/00:16:15, 0.543s/it]: train_loss_raw=0.3124, running_loss=0.3104, LR=0.000100
[2025-08-11 18:24:21,562][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042036] [Batch 03084/04869] [00:27:53/00:16:08, 0.543s/it]: train_loss_raw=0.2336, running_loss=0.3090, LR=0.000100
[2025-08-11 18:24:28,092][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042048] [Batch 03096/04869] [00:27:59/00:16:02, 0.543s/it]: train_loss_raw=0.4097, running_loss=0.3077, LR=0.000100
[2025-08-11 18:24:34,627][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042060] [Batch 03108/04869] [00:28:06/00:15:55, 0.543s/it]: train_loss_raw=0.3677, running_loss=0.3063, LR=0.000100
[2025-08-11 18:24:41,081][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042072] [Batch 03120/04869] [00:28:12/00:15:49, 0.543s/it]: train_loss_raw=0.3500, running_loss=0.3095, LR=0.000100
[2025-08-11 18:24:47,548][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042084] [Batch 03132/04869] [00:28:19/00:15:42, 0.543s/it]: train_loss_raw=0.3616, running_loss=0.3123, LR=0.000100
[2025-08-11 18:24:54,010][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042096] [Batch 03144/04869] [00:28:25/00:15:35, 0.543s/it]: train_loss_raw=0.3625, running_loss=0.3143, LR=0.000100
[2025-08-11 18:25:00,482][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042108] [Batch 03156/04869] [00:28:32/00:15:29, 0.543s/it]: train_loss_raw=0.2834, running_loss=0.3128, LR=0.000100
[2025-08-11 18:25:06,936][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042120] [Batch 03168/04869] [00:28:38/00:15:22, 0.543s/it]: train_loss_raw=0.2956, running_loss=0.3124, LR=0.000100
[2025-08-11 18:25:13,369][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042132] [Batch 03180/04869] [00:28:45/00:15:16, 0.543s/it]: train_loss_raw=0.2897, running_loss=0.3100, LR=0.000100
[2025-08-11 18:25:19,912][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042144] [Batch 03192/04869] [00:28:51/00:15:09, 0.543s/it]: train_loss_raw=0.2692, running_loss=0.3098, LR=0.000100
[2025-08-11 18:25:26,413][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042156] [Batch 03204/04869] [00:28:58/00:15:03, 0.543s/it]: train_loss_raw=0.2583, running_loss=0.3118, LR=0.000100
[2025-08-11 18:25:32,973][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042168] [Batch 03216/04869] [00:29:04/00:14:56, 0.543s/it]: train_loss_raw=0.2912, running_loss=0.3106, LR=0.000100
[2025-08-11 18:25:39,517][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042180] [Batch 03228/04869] [00:29:11/00:14:50, 0.543s/it]: train_loss_raw=0.2754, running_loss=0.3092, LR=0.000100
[2025-08-11 18:25:45,986][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042192] [Batch 03240/04869] [00:29:17/00:14:43, 0.543s/it]: train_loss_raw=0.2952, running_loss=0.3082, LR=0.000100
[2025-08-11 18:25:52,548][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042204] [Batch 03252/04869] [00:29:24/00:14:37, 0.543s/it]: train_loss_raw=0.4428, running_loss=0.3094, LR=0.000100
[2025-08-11 18:25:59,023][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042216] [Batch 03264/04869] [00:29:30/00:14:30, 0.543s/it]: train_loss_raw=0.3583, running_loss=0.3097, LR=0.000100
[2025-08-11 18:26:05,579][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042228] [Batch 03276/04869] [00:29:37/00:14:24, 0.543s/it]: train_loss_raw=0.3408, running_loss=0.3084, LR=0.000100
[2025-08-11 18:26:11,995][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042240] [Batch 03288/04869] [00:29:43/00:14:17, 0.543s/it]: train_loss_raw=0.2283, running_loss=0.3065, LR=0.000100
[2025-08-11 18:26:18,564][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042252] [Batch 03300/04869] [00:29:50/00:14:11, 0.543s/it]: train_loss_raw=0.3161, running_loss=0.3086, LR=0.000100
[2025-08-11 18:26:25,026][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042264] [Batch 03312/04869] [00:29:56/00:14:04, 0.543s/it]: train_loss_raw=0.3192, running_loss=0.3100, LR=0.000100
[2025-08-11 18:26:31,541][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042276] [Batch 03324/04869] [00:30:03/00:13:58, 0.543s/it]: train_loss_raw=0.2863, running_loss=0.3090, LR=0.000100
[2025-08-11 18:26:38,088][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042288] [Batch 03336/04869] [00:30:09/00:13:51, 0.543s/it]: train_loss_raw=0.2880, running_loss=0.3122, LR=0.000100
[2025-08-11 18:26:44,589][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042300] [Batch 03348/04869] [00:30:16/00:13:45, 0.543s/it]: train_loss_raw=0.3015, running_loss=0.3110, LR=0.000100
[2025-08-11 18:26:51,101][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042312] [Batch 03360/04869] [00:30:22/00:13:38, 0.543s/it]: train_loss_raw=0.3321, running_loss=0.3131, LR=0.000100
[2025-08-11 18:26:57,545][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042324] [Batch 03372/04869] [00:30:29/00:13:32, 0.543s/it]: train_loss_raw=0.2426, running_loss=0.3114, LR=0.000100
[2025-08-11 18:27:04,066][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042336] [Batch 03384/04869] [00:30:35/00:13:25, 0.543s/it]: train_loss_raw=0.3048, running_loss=0.3110, LR=0.000100
[2025-08-11 18:27:10,523][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042348] [Batch 03396/04869] [00:30:42/00:13:19, 0.543s/it]: train_loss_raw=0.2934, running_loss=0.3124, LR=0.000100
[2025-08-11 18:27:17,071][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042360] [Batch 03408/04869] [00:30:48/00:13:12, 0.543s/it]: train_loss_raw=0.3724, running_loss=0.3126, LR=0.000100
[2025-08-11 18:27:23,622][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042372] [Batch 03420/04869] [00:30:55/00:13:06, 0.543s/it]: train_loss_raw=0.2667, running_loss=0.3125, LR=0.000100
[2025-08-11 18:27:30,123][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042384] [Batch 03432/04869] [00:31:02/00:12:59, 0.543s/it]: train_loss_raw=0.2874, running_loss=0.3125, LR=0.000100
[2025-08-11 18:27:36,657][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042396] [Batch 03444/04869] [00:31:08/00:12:53, 0.543s/it]: train_loss_raw=0.3113, running_loss=0.3136, LR=0.000100
[2025-08-11 18:27:43,171][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042408] [Batch 03456/04869] [00:31:15/00:12:46, 0.543s/it]: train_loss_raw=0.2995, running_loss=0.3148, LR=0.000100
[2025-08-11 18:27:49,634][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042420] [Batch 03468/04869] [00:31:21/00:12:40, 0.543s/it]: train_loss_raw=0.2650, running_loss=0.3148, LR=0.000100
[2025-08-11 18:27:56,061][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042432] [Batch 03480/04869] [00:31:27/00:12:33, 0.543s/it]: train_loss_raw=0.3769, running_loss=0.3127, LR=0.000100
[2025-08-11 18:28:02,649][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042444] [Batch 03492/04869] [00:31:34/00:12:27, 0.543s/it]: train_loss_raw=0.3641, running_loss=0.3151, LR=0.000100
[2025-08-11 18:28:09,166][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042456] [Batch 03504/04869] [00:31:41/00:12:20, 0.543s/it]: train_loss_raw=0.3153, running_loss=0.3131, LR=0.000100
[2025-08-11 18:28:15,638][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042468] [Batch 03516/04869] [00:31:47/00:12:14, 0.543s/it]: train_loss_raw=0.3831, running_loss=0.3159, LR=0.000100
[2025-08-11 18:28:22,194][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042480] [Batch 03528/04869] [00:31:54/00:12:07, 0.543s/it]: train_loss_raw=0.3378, running_loss=0.3134, LR=0.000100
[2025-08-11 18:28:28,660][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042492] [Batch 03540/04869] [00:32:00/00:12:01, 0.543s/it]: train_loss_raw=0.3569, running_loss=0.3145, LR=0.000100
[2025-08-11 18:28:35,197][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042504] [Batch 03552/04869] [00:32:07/00:11:54, 0.543s/it]: train_loss_raw=0.2565, running_loss=0.3158, LR=0.000100
[2025-08-11 18:28:41,638][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042516] [Batch 03564/04869] [00:32:13/00:11:47, 0.543s/it]: train_loss_raw=0.3110, running_loss=0.3132, LR=0.000100
[2025-08-11 18:28:48,143][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042528] [Batch 03576/04869] [00:32:20/00:11:41, 0.543s/it]: train_loss_raw=0.3547, running_loss=0.3120, LR=0.000100
[2025-08-11 18:28:54,626][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042540] [Batch 03588/04869] [00:32:26/00:11:34, 0.543s/it]: train_loss_raw=0.3281, running_loss=0.3130, LR=0.000100
[2025-08-11 18:29:01,074][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042552] [Batch 03600/04869] [00:32:32/00:11:28, 0.542s/it]: train_loss_raw=0.3864, running_loss=0.3131, LR=0.000100
[2025-08-11 18:29:07,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042564] [Batch 03612/04869] [00:32:39/00:11:21, 0.542s/it]: train_loss_raw=0.4350, running_loss=0.3172, LR=0.000100
[2025-08-11 18:29:14,004][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042576] [Batch 03624/04869] [00:32:45/00:11:15, 0.542s/it]: train_loss_raw=0.2339, running_loss=0.3144, LR=0.000100
[2025-08-11 18:29:20,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042588] [Batch 03636/04869] [00:32:52/00:11:08, 0.542s/it]: train_loss_raw=0.3007, running_loss=0.3137, LR=0.000100
[2025-08-11 18:29:27,094][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042600] [Batch 03648/04869] [00:32:58/00:11:02, 0.542s/it]: train_loss_raw=0.3412, running_loss=0.3144, LR=0.000100
[2025-08-11 18:29:33,610][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042612] [Batch 03660/04869] [00:33:05/00:10:55, 0.542s/it]: train_loss_raw=0.3131, running_loss=0.3132, LR=0.000100
[2025-08-11 18:29:40,028][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042624] [Batch 03672/04869] [00:33:11/00:10:49, 0.542s/it]: train_loss_raw=0.3073, running_loss=0.3124, LR=0.000100
[2025-08-11 18:29:46,549][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042636] [Batch 03684/04869] [00:33:18/00:10:42, 0.542s/it]: train_loss_raw=0.3998, running_loss=0.3143, LR=0.000100
[2025-08-11 18:29:52,943][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042648] [Batch 03696/04869] [00:33:24/00:10:36, 0.542s/it]: train_loss_raw=0.3639, running_loss=0.3135, LR=0.000100
[2025-08-11 18:29:59,387][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042660] [Batch 03708/04869] [00:33:31/00:10:29, 0.542s/it]: train_loss_raw=0.3237, running_loss=0.3118, LR=0.000100
[2025-08-11 18:30:05,880][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042672] [Batch 03720/04869] [00:33:37/00:10:23, 0.542s/it]: train_loss_raw=0.3946, running_loss=0.3129, LR=0.000100
[2025-08-11 18:30:12,435][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042684] [Batch 03732/04869] [00:33:44/00:10:16, 0.542s/it]: train_loss_raw=0.3028, running_loss=0.3102, LR=0.000100
[2025-08-11 18:30:18,970][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042696] [Batch 03744/04869] [00:33:50/00:10:10, 0.542s/it]: train_loss_raw=0.2696, running_loss=0.3128, LR=0.000100
[2025-08-11 18:30:25,434][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042708] [Batch 03756/04869] [00:33:57/00:10:03, 0.542s/it]: train_loss_raw=0.3380, running_loss=0.3149, LR=0.000100
[2025-08-11 18:30:31,984][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042720] [Batch 03768/04869] [00:34:03/00:09:57, 0.542s/it]: train_loss_raw=0.3074, running_loss=0.3145, LR=0.000100
[2025-08-11 18:30:38,469][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042732] [Batch 03780/04869] [00:34:10/00:09:50, 0.542s/it]: train_loss_raw=0.3340, running_loss=0.3159, LR=0.000100
[2025-08-11 18:30:44,974][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042744] [Batch 03792/04869] [00:34:16/00:09:44, 0.542s/it]: train_loss_raw=0.2706, running_loss=0.3154, LR=0.000100
[2025-08-11 18:30:51,525][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042756] [Batch 03804/04869] [00:34:23/00:09:37, 0.542s/it]: train_loss_raw=0.2711, running_loss=0.3171, LR=0.000100
[2025-08-11 18:30:58,036][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042768] [Batch 03816/04869] [00:34:29/00:09:31, 0.542s/it]: train_loss_raw=0.3436, running_loss=0.3208, LR=0.000100
[2025-08-11 18:31:04,520][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042780] [Batch 03828/04869] [00:34:36/00:09:24, 0.542s/it]: train_loss_raw=0.3056, running_loss=0.3204, LR=0.000100
[2025-08-11 18:31:11,028][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042792] [Batch 03840/04869] [00:34:42/00:09:18, 0.542s/it]: train_loss_raw=0.3710, running_loss=0.3220, LR=0.000100
[2025-08-11 18:31:17,528][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042804] [Batch 03852/04869] [00:34:49/00:09:11, 0.542s/it]: train_loss_raw=0.2467, running_loss=0.3192, LR=0.000100
[2025-08-11 18:31:23,992][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042816] [Batch 03864/04869] [00:34:55/00:09:05, 0.542s/it]: train_loss_raw=0.2891, running_loss=0.3209, LR=0.000100
[2025-08-11 18:31:30,445][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042828] [Batch 03876/04869] [00:35:02/00:08:58, 0.542s/it]: train_loss_raw=0.2657, running_loss=0.3209, LR=0.000100
[2025-08-11 18:31:37,009][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042840] [Batch 03888/04869] [00:35:08/00:08:52, 0.542s/it]: train_loss_raw=0.2877, running_loss=0.3195, LR=0.000100
[2025-08-11 18:31:43,515][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042852] [Batch 03900/04869] [00:35:15/00:08:45, 0.542s/it]: train_loss_raw=0.3190, running_loss=0.3174, LR=0.000100
[2025-08-11 18:31:50,009][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042864] [Batch 03912/04869] [00:35:21/00:08:39, 0.542s/it]: train_loss_raw=0.2772, running_loss=0.3160, LR=0.000100
[2025-08-11 18:31:56,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042876] [Batch 03924/04869] [00:35:28/00:08:32, 0.542s/it]: train_loss_raw=0.3252, running_loss=0.3135, LR=0.000100
[2025-08-11 18:32:03,121][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042888] [Batch 03936/04869] [00:35:35/00:08:26, 0.542s/it]: train_loss_raw=0.3136, running_loss=0.3126, LR=0.000100
[2025-08-11 18:32:09,589][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042900] [Batch 03948/04869] [00:35:41/00:08:19, 0.542s/it]: train_loss_raw=0.3941, running_loss=0.3160, LR=0.000100
[2025-08-11 18:32:16,071][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042912] [Batch 03960/04869] [00:35:47/00:08:13, 0.542s/it]: train_loss_raw=0.2916, running_loss=0.3154, LR=0.000100
[2025-08-11 18:32:22,518][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042924] [Batch 03972/04869] [00:35:54/00:08:06, 0.542s/it]: train_loss_raw=0.2500, running_loss=0.3145, LR=0.000100
[2025-08-11 18:32:29,102][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042936] [Batch 03984/04869] [00:36:00/00:08:00, 0.542s/it]: train_loss_raw=0.3034, running_loss=0.3143, LR=0.000100
[2025-08-11 18:32:35,733][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042948] [Batch 03996/04869] [00:36:07/00:07:53, 0.542s/it]: train_loss_raw=0.2794, running_loss=0.3143, LR=0.000100
[2025-08-11 18:32:42,292][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042960] [Batch 04008/04869] [00:36:14/00:07:47, 0.542s/it]: train_loss_raw=0.3104, running_loss=0.3132, LR=0.000100
[2025-08-11 18:32:48,748][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042972] [Batch 04020/04869] [00:36:20/00:07:40, 0.542s/it]: train_loss_raw=0.3006, running_loss=0.3116, LR=0.000100
[2025-08-11 18:32:55,234][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042984] [Batch 04032/04869] [00:36:27/00:07:34, 0.542s/it]: train_loss_raw=0.2415, running_loss=0.3120, LR=0.000100
[2025-08-11 18:33:01,774][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042996] [Batch 04044/04869] [00:36:33/00:07:27, 0.542s/it]: train_loss_raw=0.3172, running_loss=0.3115, LR=0.000100
[2025-08-11 18:33:08,328][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043008] [Batch 04056/04869] [00:36:40/00:07:21, 0.542s/it]: train_loss_raw=0.2656, running_loss=0.3102, LR=0.000100
[2025-08-11 18:33:14,909][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043020] [Batch 04068/04869] [00:36:46/00:07:14, 0.542s/it]: train_loss_raw=0.2523, running_loss=0.3088, LR=0.000100
[2025-08-11 18:33:21,440][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043032] [Batch 04080/04869] [00:36:53/00:07:08, 0.542s/it]: train_loss_raw=0.3810, running_loss=0.3104, LR=0.000100
[2025-08-11 18:33:27,899][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043044] [Batch 04092/04869] [00:36:59/00:07:01, 0.542s/it]: train_loss_raw=0.4516, running_loss=0.3129, LR=0.000100
[2025-08-11 18:33:34,472][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043056] [Batch 04104/04869] [00:37:06/00:06:55, 0.542s/it]: train_loss_raw=0.2685, running_loss=0.3113, LR=0.000100
[2025-08-11 18:33:40,906][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043068] [Batch 04116/04869] [00:37:12/00:06:48, 0.542s/it]: train_loss_raw=0.2751, running_loss=0.3115, LR=0.000100
[2025-08-11 18:33:47,372][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043080] [Batch 04128/04869] [00:37:19/00:06:41, 0.542s/it]: train_loss_raw=0.3417, running_loss=0.3128, LR=0.000100
[2025-08-11 18:33:53,862][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043092] [Batch 04140/04869] [00:37:25/00:06:35, 0.542s/it]: train_loss_raw=0.2962, running_loss=0.3170, LR=0.000100
[2025-08-11 18:34:00,307][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043104] [Batch 04152/04869] [00:37:32/00:06:28, 0.542s/it]: train_loss_raw=0.3346, running_loss=0.3156, LR=0.000100
[2025-08-11 18:34:06,795][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043116] [Batch 04164/04869] [00:37:38/00:06:22, 0.542s/it]: train_loss_raw=0.3178, running_loss=0.3121, LR=0.000100
[2025-08-11 18:34:13,278][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043128] [Batch 04176/04869] [00:37:45/00:06:15, 0.542s/it]: train_loss_raw=0.3380, running_loss=0.3115, LR=0.000100
[2025-08-11 18:34:19,783][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043140] [Batch 04188/04869] [00:37:51/00:06:09, 0.542s/it]: train_loss_raw=0.2584, running_loss=0.3120, LR=0.000100
[2025-08-11 18:34:26,279][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043152] [Batch 04200/04869] [00:37:58/00:06:02, 0.542s/it]: train_loss_raw=0.3481, running_loss=0.3112, LR=0.000100
[2025-08-11 18:34:32,779][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043164] [Batch 04212/04869] [00:38:04/00:05:56, 0.542s/it]: train_loss_raw=0.3628, running_loss=0.3099, LR=0.000100
[2025-08-11 18:34:39,240][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043176] [Batch 04224/04869] [00:38:11/00:05:49, 0.542s/it]: train_loss_raw=0.3743, running_loss=0.3126, LR=0.000100
[2025-08-11 18:34:45,737][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043188] [Batch 04236/04869] [00:38:17/00:05:43, 0.542s/it]: train_loss_raw=0.4442, running_loss=0.3138, LR=0.000100
[2025-08-11 18:34:52,266][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043200] [Batch 04248/04869] [00:38:24/00:05:36, 0.542s/it]: train_loss_raw=0.2928, running_loss=0.3143, LR=0.000100
[2025-08-11 18:34:58,769][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043212] [Batch 04260/04869] [00:38:30/00:05:30, 0.542s/it]: train_loss_raw=0.3073, running_loss=0.3141, LR=0.000100
[2025-08-11 18:35:05,234][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043224] [Batch 04272/04869] [00:38:37/00:05:23, 0.542s/it]: train_loss_raw=0.4008, running_loss=0.3160, LR=0.000100
[2025-08-11 18:35:11,754][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043236] [Batch 04284/04869] [00:38:43/00:05:17, 0.542s/it]: train_loss_raw=0.2847, running_loss=0.3133, LR=0.000100
[2025-08-11 18:35:18,233][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043248] [Batch 04296/04869] [00:38:50/00:05:10, 0.542s/it]: train_loss_raw=0.3277, running_loss=0.3143, LR=0.000100
[2025-08-11 18:35:24,801][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043260] [Batch 04308/04869] [00:38:56/00:05:04, 0.542s/it]: train_loss_raw=0.2966, running_loss=0.3120, LR=0.000100
[2025-08-11 18:35:31,305][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043272] [Batch 04320/04869] [00:39:03/00:04:57, 0.542s/it]: train_loss_raw=0.2701, running_loss=0.3091, LR=0.000100
[2025-08-11 18:35:37,747][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043284] [Batch 04332/04869] [00:39:09/00:04:51, 0.542s/it]: train_loss_raw=0.3685, running_loss=0.3092, LR=0.000100
[2025-08-11 18:35:44,206][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043296] [Batch 04344/04869] [00:39:16/00:04:44, 0.542s/it]: train_loss_raw=0.3401, running_loss=0.3113, LR=0.000100
[2025-08-11 18:35:50,767][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043308] [Batch 04356/04869] [00:39:22/00:04:38, 0.542s/it]: train_loss_raw=0.3470, running_loss=0.3122, LR=0.000100
[2025-08-11 18:35:57,212][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043320] [Batch 04368/04869] [00:39:29/00:04:31, 0.542s/it]: train_loss_raw=0.2860, running_loss=0.3123, LR=0.000100
[2025-08-11 18:36:03,771][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043332] [Batch 04380/04869] [00:39:35/00:04:25, 0.542s/it]: train_loss_raw=0.2715, running_loss=0.3121, LR=0.000100
[2025-08-11 18:36:10,379][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043344] [Batch 04392/04869] [00:39:42/00:04:18, 0.542s/it]: train_loss_raw=0.4157, running_loss=0.3144, LR=0.000100
[2025-08-11 18:36:16,975][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043356] [Batch 04404/04869] [00:39:48/00:04:12, 0.542s/it]: train_loss_raw=0.3214, running_loss=0.3152, LR=0.000100
[2025-08-11 18:36:23,422][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043368] [Batch 04416/04869] [00:39:55/00:04:05, 0.542s/it]: train_loss_raw=0.3572, running_loss=0.3160, LR=0.000100
[2025-08-11 18:36:29,786][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043380] [Batch 04428/04869] [00:40:01/00:03:59, 0.542s/it]: train_loss_raw=0.3297, running_loss=0.3169, LR=0.000100
[2025-08-11 18:36:36,128][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043392] [Batch 04440/04869] [00:40:08/00:03:52, 0.542s/it]: train_loss_raw=0.2822, running_loss=0.3186, LR=0.000100
[2025-08-11 18:36:42,498][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043404] [Batch 04452/04869] [00:40:14/00:03:46, 0.542s/it]: train_loss_raw=0.3375, running_loss=0.3192, LR=0.000100
[2025-08-11 18:36:48,833][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043416] [Batch 04464/04869] [00:40:20/00:03:39, 0.542s/it]: train_loss_raw=0.2850, running_loss=0.3182, LR=0.000100
[2025-08-11 18:36:55,192][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043428] [Batch 04476/04869] [00:40:27/00:03:33, 0.542s/it]: train_loss_raw=0.3200, running_loss=0.3168, LR=0.000100
[2025-08-11 18:37:01,549][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043440] [Batch 04488/04869] [00:40:33/00:03:26, 0.542s/it]: train_loss_raw=0.3588, running_loss=0.3191, LR=0.000100
[2025-08-11 18:37:07,916][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043452] [Batch 04500/04869] [00:40:39/00:03:20, 0.542s/it]: train_loss_raw=0.2839, running_loss=0.3207, LR=0.000100
[2025-08-11 18:37:14,145][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043464] [Batch 04512/04869] [00:40:46/00:03:13, 0.542s/it]: train_loss_raw=0.2808, running_loss=0.3198, LR=0.000100
[2025-08-11 18:37:20,578][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043476] [Batch 04524/04869] [00:40:52/00:03:07, 0.542s/it]: train_loss_raw=0.3085, running_loss=0.3207, LR=0.000100
[2025-08-11 18:37:26,900][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043488] [Batch 04536/04869] [00:40:58/00:03:00, 0.542s/it]: train_loss_raw=0.3670, running_loss=0.3207, LR=0.000100
[2025-08-11 18:37:33,333][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043500] [Batch 04548/04869] [00:41:05/00:02:53, 0.542s/it]: train_loss_raw=0.2909, running_loss=0.3203, LR=0.000100
[2025-08-11 18:37:39,840][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043512] [Batch 04560/04869] [00:41:11/00:02:47, 0.542s/it]: train_loss_raw=0.3946, running_loss=0.3189, LR=0.000100
[2025-08-11 18:37:46,215][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043524] [Batch 04572/04869] [00:41:18/00:02:40, 0.542s/it]: train_loss_raw=0.2675, running_loss=0.3190, LR=0.000100
[2025-08-11 18:37:52,715][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043536] [Batch 04584/04869] [00:41:24/00:02:34, 0.542s/it]: train_loss_raw=0.3389, running_loss=0.3185, LR=0.000100
[2025-08-11 18:37:59,192][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043548] [Batch 04596/04869] [00:41:31/00:02:27, 0.542s/it]: train_loss_raw=0.2750, running_loss=0.3173, LR=0.000100
[2025-08-11 18:38:05,645][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043560] [Batch 04608/04869] [00:41:37/00:02:21, 0.542s/it]: train_loss_raw=0.3198, running_loss=0.3169, LR=0.000100
[2025-08-11 18:38:12,116][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043572] [Batch 04620/04869] [00:41:44/00:02:14, 0.542s/it]: train_loss_raw=0.3397, running_loss=0.3174, LR=0.000100
[2025-08-11 18:38:18,810][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043584] [Batch 04632/04869] [00:41:50/00:02:08, 0.542s/it]: train_loss_raw=0.4245, running_loss=0.3181, LR=0.000100
[2025-08-11 18:38:25,322][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043596] [Batch 04644/04869] [00:41:57/00:02:01, 0.542s/it]: train_loss_raw=0.2920, running_loss=0.3180, LR=0.000100
[2025-08-11 18:38:31,787][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043608] [Batch 04656/04869] [00:42:03/00:01:55, 0.542s/it]: train_loss_raw=0.3561, running_loss=0.3177, LR=0.000100
[2025-08-11 18:38:38,174][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043620] [Batch 04668/04869] [00:42:10/00:01:48, 0.542s/it]: train_loss_raw=0.3431, running_loss=0.3183, LR=0.000100
[2025-08-11 18:38:44,777][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043632] [Batch 04680/04869] [00:42:16/00:01:42, 0.542s/it]: train_loss_raw=0.3228, running_loss=0.3163, LR=0.000100
[2025-08-11 18:38:51,318][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043644] [Batch 04692/04869] [00:42:23/00:01:35, 0.542s/it]: train_loss_raw=0.3725, running_loss=0.3156, LR=0.000100
[2025-08-11 18:38:57,838][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043656] [Batch 04704/04869] [00:42:29/00:01:29, 0.542s/it]: train_loss_raw=0.3409, running_loss=0.3161, LR=0.000100
[2025-08-11 18:39:04,354][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043668] [Batch 04716/04869] [00:42:36/00:01:22, 0.542s/it]: train_loss_raw=0.2929, running_loss=0.3160, LR=0.000100
[2025-08-11 18:39:10,778][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043680] [Batch 04728/04869] [00:42:42/00:01:16, 0.542s/it]: train_loss_raw=0.2858, running_loss=0.3136, LR=0.000100
[2025-08-11 18:39:17,343][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043692] [Batch 04740/04869] [00:42:49/00:01:09, 0.542s/it]: train_loss_raw=0.2749, running_loss=0.3143, LR=0.000100
[2025-08-11 18:39:23,805][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043704] [Batch 04752/04869] [00:42:55/00:01:03, 0.542s/it]: train_loss_raw=0.2665, running_loss=0.3114, LR=0.000100
[2025-08-11 18:39:30,341][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043716] [Batch 04764/04869] [00:43:02/00:00:56, 0.542s/it]: train_loss_raw=0.3273, running_loss=0.3117, LR=0.000100
[2025-08-11 18:39:36,819][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043728] [Batch 04776/04869] [00:43:08/00:00:50, 0.542s/it]: train_loss_raw=0.3327, running_loss=0.3127, LR=0.000100
[2025-08-11 18:39:43,429][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043740] [Batch 04788/04869] [00:43:15/00:00:43, 0.542s/it]: train_loss_raw=0.2595, running_loss=0.3122, LR=0.000100
[2025-08-11 18:39:49,938][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043752] [Batch 04800/04869] [00:43:21/00:00:37, 0.542s/it]: train_loss_raw=0.3526, running_loss=0.3113, LR=0.000100
[2025-08-11 18:39:56,401][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043764] [Batch 04812/04869] [00:43:28/00:00:30, 0.542s/it]: train_loss_raw=0.3338, running_loss=0.3108, LR=0.000100
[2025-08-11 18:40:02,912][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043776] [Batch 04824/04869] [00:43:34/00:00:24, 0.542s/it]: train_loss_raw=0.3371, running_loss=0.3095, LR=0.000100
[2025-08-11 18:40:09,507][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043788] [Batch 04836/04869] [00:43:41/00:00:17, 0.542s/it]: train_loss_raw=0.3725, running_loss=0.3129, LR=0.000100
[2025-08-11 18:40:15,997][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043800] [Batch 04848/04869] [00:43:47/00:00:11, 0.542s/it]: train_loss_raw=0.4029, running_loss=0.3168, LR=0.000100
[2025-08-11 18:40:22,457][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043812] [Batch 04860/04869] [00:43:54/00:00:04, 0.542s/it]: train_loss_raw=0.3460, running_loss=0.3152, LR=0.000100
[2025-08-11 18:40:32,485][__main__][INFO] - [VALIDATION] [Epoch 08/29] Starting validation.
[2025-08-11 18:40:47,808][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00011/00062] [00:00:15/00:01:03, 1.277s/it]
[2025-08-11 18:41:20,547][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00023/00062] [00:00:48/00:01:16, 2.003s/it]
[2025-08-11 18:41:36,272][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00035/00062] [00:01:03/00:00:46, 1.772s/it]
[2025-08-11 18:41:52,278][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00047/00062] [00:01:19/00:00:23, 1.662s/it]
[2025-08-11 18:42:07,797][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00059/00062] [00:01:35/00:00:03, 1.589s/it]
[2025-08-11 18:42:10,310][__main__][INFO] - [VALIDATION] [Epoch 08/29] train_loss=0.31421, valid_loss=0.38408
[2025-08-11 18:42:10,311][__main__][INFO] - [VALIDATION] [Epoch 08/29] Metrics:
[2025-08-11 18:42:10,311][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_er      0.186
[2025-08-11 18:42:10,311][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_prec    0.637
[2025-08-11 18:42:10,311][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_recall  0.642
[2025-08-11 18:42:10,312][__main__][INFO] - [VALIDATION] [Epoch 08/29] - pep_recall 0.607
[2025-08-11 18:42:10,316][__main__][INFO] - [TRAIN] [Epoch 08/29] Epoch complete, total time 06:46:48, remaining time 15:49:14, 00:45:12 per epoch
[2025-08-11 18:42:11,780][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043824] [Batch 00003/04869] [00:00:01/00:31:40, 0.391s/it]: train_loss_raw=0.3544, running_loss=0.2002, LR=0.000100
[2025-08-11 18:42:18,234][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043836] [Batch 00015/04869] [00:00:07/00:41:07, 0.508s/it]: train_loss_raw=0.4491, running_loss=0.2153, LR=0.000100
[2025-08-11 18:42:24,766][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043848] [Batch 00027/04869] [00:00:14/00:42:18, 0.524s/it]: train_loss_raw=0.3066, running_loss=0.2274, LR=0.000100
[2025-08-11 18:42:31,152][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043860] [Batch 00039/04869] [00:00:20/00:42:24, 0.527s/it]: train_loss_raw=0.3849, running_loss=0.2377, LR=0.000100
[2025-08-11 18:42:37,670][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043872] [Batch 00051/04869] [00:00:27/00:42:36, 0.531s/it]: train_loss_raw=0.2565, running_loss=0.2472, LR=0.000100
[2025-08-11 18:42:44,144][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043884] [Batch 00063/04869] [00:00:33/00:42:38, 0.532s/it]: train_loss_raw=0.2583, running_loss=0.2553, LR=0.000100
[2025-08-11 18:42:50,683][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043896] [Batch 00075/04869] [00:00:40/00:42:41, 0.534s/it]: train_loss_raw=0.2750, running_loss=0.2613, LR=0.000100
[2025-08-11 18:42:57,153][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043908] [Batch 00087/04869] [00:00:46/00:42:38, 0.535s/it]: train_loss_raw=0.2907, running_loss=0.2676, LR=0.000100
[2025-08-11 18:43:03,642][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043920] [Batch 00099/04869] [00:00:53/00:42:35, 0.536s/it]: train_loss_raw=0.2961, running_loss=0.2736, LR=0.000100
[2025-08-11 18:43:10,173][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043932] [Batch 00111/04869] [00:00:59/00:42:33, 0.537s/it]: train_loss_raw=0.2854, running_loss=0.2767, LR=0.000100
[2025-08-11 18:43:16,674][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043944] [Batch 00123/04869] [00:01:06/00:42:29, 0.537s/it]: train_loss_raw=0.3591, running_loss=0.2820, LR=0.000100
[2025-08-11 18:43:23,180][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043956] [Batch 00135/04869] [00:01:12/00:42:24, 0.538s/it]: train_loss_raw=0.3127, running_loss=0.2836, LR=0.000100
[2025-08-11 18:43:29,692][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043968] [Batch 00147/04869] [00:01:19/00:42:20, 0.538s/it]: train_loss_raw=0.2655, running_loss=0.2869, LR=0.000100
[2025-08-11 18:43:36,255][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043980] [Batch 00159/04869] [00:01:25/00:42:17, 0.539s/it]: train_loss_raw=0.3641, running_loss=0.2884, LR=0.000100
[2025-08-11 18:43:42,634][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043992] [Batch 00171/04869] [00:01:32/00:42:08, 0.538s/it]: train_loss_raw=0.3694, running_loss=0.2918, LR=0.000100
[2025-08-11 18:43:54,453][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044004] [Batch 00183/04869] [00:01:43/00:44:19, 0.567s/it]: train_loss_raw=0.2807, running_loss=0.2958, LR=0.000100
[2025-08-11 18:44:00,960][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044016] [Batch 00195/04869] [00:01:50/00:44:05, 0.566s/it]: train_loss_raw=0.3056, running_loss=0.2980, LR=0.000100
[2025-08-11 18:44:07,388][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044028] [Batch 00207/04869] [00:01:56/00:43:50, 0.564s/it]: train_loss_raw=0.4975, running_loss=0.3036, LR=0.000100
[2025-08-11 18:44:13,812][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044040] [Batch 00219/04869] [00:02:03/00:43:35, 0.563s/it]: train_loss_raw=0.2829, running_loss=0.3071, LR=0.000100
[2025-08-11 18:44:20,242][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044052] [Batch 00231/04869] [00:02:09/00:43:22, 0.561s/it]: train_loss_raw=0.2493, running_loss=0.3074, LR=0.000100
[2025-08-11 18:44:26,716][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044064] [Batch 00243/04869] [00:02:16/00:43:11, 0.560s/it]: train_loss_raw=0.2795, running_loss=0.3063, LR=0.000100
[2025-08-11 18:44:33,119][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044076] [Batch 00255/04869] [00:02:22/00:42:58, 0.559s/it]: train_loss_raw=0.2205, running_loss=0.3055, LR=0.000100
[2025-08-11 18:44:39,590][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044088] [Batch 00267/04869] [00:02:28/00:42:47, 0.558s/it]: train_loss_raw=0.2552, running_loss=0.3069, LR=0.000100
[2025-08-11 18:44:46,044][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044100] [Batch 00279/04869] [00:02:35/00:42:37, 0.557s/it]: train_loss_raw=0.3079, running_loss=0.3078, LR=0.000100
[2025-08-11 18:44:52,513][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044112] [Batch 00291/04869] [00:02:41/00:42:27, 0.556s/it]: train_loss_raw=0.2324, running_loss=0.3055, LR=0.000100
[2025-08-11 18:44:58,941][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044124] [Batch 00303/04869] [00:02:48/00:42:16, 0.556s/it]: train_loss_raw=0.2997, running_loss=0.3080, LR=0.000100
[2025-08-11 18:45:05,397][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044136] [Batch 00315/04869] [00:02:54/00:42:06, 0.555s/it]: train_loss_raw=0.3489, running_loss=0.3080, LR=0.000100
[2025-08-11 18:45:11,845][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044148] [Batch 00327/04869] [00:03:01/00:41:57, 0.554s/it]: train_loss_raw=0.3336, running_loss=0.3083, LR=0.000100
[2025-08-11 18:45:18,230][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044160] [Batch 00339/04869] [00:03:07/00:41:47, 0.553s/it]: train_loss_raw=0.3249, running_loss=0.3085, LR=0.000100
[2025-08-11 18:45:24,594][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044172] [Batch 00351/04869] [00:03:13/00:41:36, 0.553s/it]: train_loss_raw=0.2555, running_loss=0.3092, LR=0.000100
[2025-08-11 18:45:31,042][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044184] [Batch 00363/04869] [00:03:20/00:41:28, 0.552s/it]: train_loss_raw=0.3347, running_loss=0.3091, LR=0.000100
[2025-08-11 18:45:37,481][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044196] [Batch 00375/04869] [00:03:26/00:41:19, 0.552s/it]: train_loss_raw=0.2897, running_loss=0.3109, LR=0.000100
[2025-08-11 18:45:43,976][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044208] [Batch 00387/04869] [00:03:33/00:41:11, 0.551s/it]: train_loss_raw=0.3254, running_loss=0.3090, LR=0.000100
[2025-08-11 18:45:50,420][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044220] [Batch 00399/04869] [00:03:39/00:41:02, 0.551s/it]: train_loss_raw=0.3768, running_loss=0.3114, LR=0.000100
[2025-08-11 18:45:56,915][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044232] [Batch 00411/04869] [00:03:46/00:40:54, 0.551s/it]: train_loss_raw=0.3011, running_loss=0.3117, LR=0.000100
[2025-08-11 18:46:03,443][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044244] [Batch 00423/04869] [00:03:52/00:40:47, 0.550s/it]: train_loss_raw=0.3188, running_loss=0.3102, LR=0.000100
[2025-08-11 18:46:09,913][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044256] [Batch 00435/04869] [00:03:59/00:40:39, 0.550s/it]: train_loss_raw=0.2904, running_loss=0.3106, LR=0.000100
[2025-08-11 18:46:16,420][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044268] [Batch 00447/04869] [00:04:05/00:40:31, 0.550s/it]: train_loss_raw=0.2790, running_loss=0.3126, LR=0.000100
[2025-08-11 18:46:22,872][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044280] [Batch 00459/04869] [00:04:12/00:40:23, 0.550s/it]: train_loss_raw=0.2850, running_loss=0.3132, LR=0.000100
[2025-08-11 18:46:29,378][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044292] [Batch 00471/04869] [00:04:18/00:40:16, 0.549s/it]: train_loss_raw=0.3308, running_loss=0.3130, LR=0.000100
[2025-08-11 18:46:35,823][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044304] [Batch 00483/04869] [00:04:25/00:40:08, 0.549s/it]: train_loss_raw=0.4094, running_loss=0.3131, LR=0.000100
[2025-08-11 18:46:42,357][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044316] [Batch 00495/04869] [00:04:31/00:40:01, 0.549s/it]: train_loss_raw=0.2786, running_loss=0.3123, LR=0.000100
[2025-08-11 18:46:48,860][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044328] [Batch 00507/04869] [00:04:38/00:39:53, 0.549s/it]: train_loss_raw=0.4039, running_loss=0.3145, LR=0.000100
[2025-08-11 18:46:55,346][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044340] [Batch 00519/04869] [00:04:44/00:39:46, 0.549s/it]: train_loss_raw=0.3003, running_loss=0.3158, LR=0.000100
[2025-08-11 18:47:01,793][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044352] [Batch 00531/04869] [00:04:51/00:39:38, 0.548s/it]: train_loss_raw=0.2409, running_loss=0.3145, LR=0.000100
[2025-08-11 18:47:08,334][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044364] [Batch 00543/04869] [00:04:57/00:39:31, 0.548s/it]: train_loss_raw=0.3742, running_loss=0.3134, LR=0.000100
[2025-08-11 18:47:14,798][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044376] [Batch 00555/04869] [00:05:04/00:39:24, 0.548s/it]: train_loss_raw=0.3592, running_loss=0.3140, LR=0.000100
[2025-08-11 18:47:21,347][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044388] [Batch 00567/04869] [00:05:10/00:39:17, 0.548s/it]: train_loss_raw=0.2812, running_loss=0.3124, LR=0.000100
[2025-08-11 18:47:27,810][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044400] [Batch 00579/04869] [00:05:17/00:39:10, 0.548s/it]: train_loss_raw=0.3109, running_loss=0.3107, LR=0.000100
[2025-08-11 18:47:34,225][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044412] [Batch 00591/04869] [00:05:23/00:39:02, 0.548s/it]: train_loss_raw=0.2675, running_loss=0.3077, LR=0.000100
[2025-08-11 18:47:40,668][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044424] [Batch 00603/04869] [00:05:30/00:38:55, 0.547s/it]: train_loss_raw=0.2886, running_loss=0.3059, LR=0.000100
[2025-08-11 18:47:47,176][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044436] [Batch 00615/04869] [00:05:36/00:38:48, 0.547s/it]: train_loss_raw=0.3703, running_loss=0.3074, LR=0.000100
[2025-08-11 18:47:53,670][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044448] [Batch 00627/04869] [00:05:43/00:38:40, 0.547s/it]: train_loss_raw=0.3546, running_loss=0.3113, LR=0.000100
[2025-08-11 18:48:00,160][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044460] [Batch 00639/04869] [00:05:49/00:38:33, 0.547s/it]: train_loss_raw=0.3894, running_loss=0.3110, LR=0.000100
[2025-08-11 18:48:06,584][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044472] [Batch 00651/04869] [00:05:55/00:38:26, 0.547s/it]: train_loss_raw=0.2901, running_loss=0.3103, LR=0.000100
[2025-08-11 18:48:13,083][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044484] [Batch 00663/04869] [00:06:02/00:38:19, 0.547s/it]: train_loss_raw=0.2718, running_loss=0.3102, LR=0.000100
[2025-08-11 18:48:19,625][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044496] [Batch 00675/04869] [00:06:09/00:38:12, 0.547s/it]: train_loss_raw=0.2219, running_loss=0.3091, LR=0.000100
[2025-08-11 18:48:26,067][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044508] [Batch 00687/04869] [00:06:15/00:38:05, 0.547s/it]: train_loss_raw=0.2196, running_loss=0.3091, LR=0.000100
[2025-08-11 18:48:32,659][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044520] [Batch 00699/04869] [00:06:22/00:37:59, 0.547s/it]: train_loss_raw=0.3279, running_loss=0.3085, LR=0.000100
[2025-08-11 18:48:39,173][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044532] [Batch 00711/04869] [00:06:28/00:37:52, 0.547s/it]: train_loss_raw=0.3779, running_loss=0.3108, LR=0.000100
[2025-08-11 18:48:45,695][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044544] [Batch 00723/04869] [00:06:35/00:37:45, 0.546s/it]: train_loss_raw=0.3661, running_loss=0.3128, LR=0.000100
[2025-08-11 18:48:52,189][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044556] [Batch 00735/04869] [00:06:41/00:37:38, 0.546s/it]: train_loss_raw=0.3307, running_loss=0.3130, LR=0.000100
[2025-08-11 18:48:58,613][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044568] [Batch 00747/04869] [00:06:48/00:37:31, 0.546s/it]: train_loss_raw=0.2227, running_loss=0.3132, LR=0.000100
[2025-08-11 18:49:05,115][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044580] [Batch 00759/04869] [00:06:54/00:37:24, 0.546s/it]: train_loss_raw=0.2354, running_loss=0.3132, LR=0.000100
[2025-08-11 18:49:11,626][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044592] [Batch 00771/04869] [00:07:01/00:37:17, 0.546s/it]: train_loss_raw=0.2694, running_loss=0.3116, LR=0.000100
[2025-08-11 18:49:18,108][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044604] [Batch 00783/04869] [00:07:07/00:37:10, 0.546s/it]: train_loss_raw=0.3951, running_loss=0.3132, LR=0.000100
[2025-08-11 18:49:24,599][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044616] [Batch 00795/04869] [00:07:13/00:37:03, 0.546s/it]: train_loss_raw=0.2264, running_loss=0.3113, LR=0.000100
[2025-08-11 18:49:31,013][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044628] [Batch 00807/04869] [00:07:20/00:36:56, 0.546s/it]: train_loss_raw=0.2934, running_loss=0.3120, LR=0.000100
[2025-08-11 18:49:37,501][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044640] [Batch 00819/04869] [00:07:26/00:36:49, 0.546s/it]: train_loss_raw=0.3605, running_loss=0.3148, LR=0.000100
[2025-08-11 18:49:43,993][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044652] [Batch 00831/04869] [00:07:33/00:36:43, 0.546s/it]: train_loss_raw=0.3836, running_loss=0.3143, LR=0.000100
[2025-08-11 18:49:50,528][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044664] [Batch 00843/04869] [00:07:39/00:36:36, 0.546s/it]: train_loss_raw=0.3105, running_loss=0.3153, LR=0.000100
[2025-08-11 18:49:57,151][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044676] [Batch 00855/04869] [00:07:46/00:36:30, 0.546s/it]: train_loss_raw=0.3409, running_loss=0.3130, LR=0.000100
[2025-08-11 18:50:03,691][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044688] [Batch 00867/04869] [00:07:53/00:36:23, 0.546s/it]: train_loss_raw=0.2877, running_loss=0.3144, LR=0.000100
[2025-08-11 18:50:10,267][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044700] [Batch 00879/04869] [00:07:59/00:36:17, 0.546s/it]: train_loss_raw=0.3677, running_loss=0.3148, LR=0.000100
[2025-08-11 18:50:16,808][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044712] [Batch 00891/04869] [00:08:06/00:36:10, 0.546s/it]: train_loss_raw=0.2991, running_loss=0.3146, LR=0.000100
[2025-08-11 18:50:23,317][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044724] [Batch 00903/04869] [00:08:12/00:36:03, 0.546s/it]: train_loss_raw=0.2444, running_loss=0.3144, LR=0.000100
[2025-08-11 18:50:29,777][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044736] [Batch 00915/04869] [00:08:19/00:35:57, 0.546s/it]: train_loss_raw=0.2436, running_loss=0.3132, LR=0.000100
[2025-08-11 18:50:36,228][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044748] [Batch 00927/04869] [00:08:25/00:35:50, 0.545s/it]: train_loss_raw=0.3330, running_loss=0.3156, LR=0.000100
[2025-08-11 18:50:42,711][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044760] [Batch 00939/04869] [00:08:32/00:35:43, 0.545s/it]: train_loss_raw=0.4038, running_loss=0.3145, LR=0.000100
[2025-08-11 18:50:49,214][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044772] [Batch 00951/04869] [00:08:38/00:35:36, 0.545s/it]: train_loss_raw=0.3312, running_loss=0.3154, LR=0.000100
[2025-08-11 18:50:55,665][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044784] [Batch 00963/04869] [00:08:45/00:35:29, 0.545s/it]: train_loss_raw=0.3109, running_loss=0.3141, LR=0.000100
[2025-08-11 18:51:02,079][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044796] [Batch 00975/04869] [00:08:51/00:35:22, 0.545s/it]: train_loss_raw=0.2720, running_loss=0.3123, LR=0.000100
[2025-08-11 18:51:08,561][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044808] [Batch 00987/04869] [00:08:57/00:35:15, 0.545s/it]: train_loss_raw=0.2830, running_loss=0.3118, LR=0.000100
[2025-08-11 18:51:15,061][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044820] [Batch 00999/04869] [00:09:04/00:35:09, 0.545s/it]: train_loss_raw=0.2960, running_loss=0.3100, LR=0.000100
[2025-08-11 18:51:21,570][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044832] [Batch 01011/04869] [00:09:10/00:35:02, 0.545s/it]: train_loss_raw=0.3377, running_loss=0.3109, LR=0.000100
[2025-08-11 18:51:28,103][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044844] [Batch 01023/04869] [00:09:17/00:34:55, 0.545s/it]: train_loss_raw=0.3526, running_loss=0.3133, LR=0.000100
[2025-08-11 18:51:34,595][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044856] [Batch 01035/04869] [00:09:23/00:34:49, 0.545s/it]: train_loss_raw=0.3386, running_loss=0.3138, LR=0.000100
[2025-08-11 18:51:41,183][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044868] [Batch 01047/04869] [00:09:30/00:34:42, 0.545s/it]: train_loss_raw=0.3003, running_loss=0.3130, LR=0.000100
[2025-08-11 18:51:47,665][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044880] [Batch 01059/04869] [00:09:37/00:34:36, 0.545s/it]: train_loss_raw=0.3224, running_loss=0.3149, LR=0.000100
[2025-08-11 18:51:54,229][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044892] [Batch 01071/04869] [00:09:43/00:34:29, 0.545s/it]: train_loss_raw=0.2873, running_loss=0.3159, LR=0.000100
[2025-08-11 18:52:00,754][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044904] [Batch 01083/04869] [00:09:50/00:34:23, 0.545s/it]: train_loss_raw=0.2069, running_loss=0.3174, LR=0.000100
[2025-08-11 18:52:07,234][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044916] [Batch 01095/04869] [00:09:56/00:34:16, 0.545s/it]: train_loss_raw=0.3238, running_loss=0.3168, LR=0.000100
[2025-08-11 18:52:13,587][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044928] [Batch 01107/04869] [00:10:02/00:34:09, 0.545s/it]: train_loss_raw=0.2877, running_loss=0.3185, LR=0.000100
[2025-08-11 18:52:20,095][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044940] [Batch 01119/04869] [00:10:09/00:34:02, 0.545s/it]: train_loss_raw=0.3522, running_loss=0.3202, LR=0.000100
[2025-08-11 18:52:26,538][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044952] [Batch 01131/04869] [00:10:15/00:33:55, 0.545s/it]: train_loss_raw=0.3360, running_loss=0.3182, LR=0.000100
[2025-08-11 18:52:33,007][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044964] [Batch 01143/04869] [00:10:22/00:33:48, 0.545s/it]: train_loss_raw=0.3288, running_loss=0.3194, LR=0.000100
[2025-08-11 18:52:39,505][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044976] [Batch 01155/04869] [00:10:28/00:33:42, 0.544s/it]: train_loss_raw=0.2611, running_loss=0.3170, LR=0.000100
[2025-08-11 18:52:46,031][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044988] [Batch 01167/04869] [00:10:35/00:33:35, 0.544s/it]: train_loss_raw=0.3345, running_loss=0.3190, LR=0.000100
[2025-08-11 18:52:52,575][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045000] [Batch 01179/04869] [00:10:41/00:33:29, 0.545s/it]: train_loss_raw=0.3176, running_loss=0.3182, LR=0.000100
[2025-08-11 18:52:59,079][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045012] [Batch 01191/04869] [00:10:48/00:33:22, 0.544s/it]: train_loss_raw=0.3280, running_loss=0.3156, LR=0.000100
[2025-08-11 18:53:05,537][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045024] [Batch 01203/04869] [00:10:54/00:33:15, 0.544s/it]: train_loss_raw=0.2717, running_loss=0.3177, LR=0.000100
[2025-08-11 18:53:12,048][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045036] [Batch 01215/04869] [00:11:01/00:33:09, 0.544s/it]: train_loss_raw=0.2571, running_loss=0.3186, LR=0.000100
[2025-08-11 18:53:18,606][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045048] [Batch 01227/04869] [00:11:07/00:33:02, 0.544s/it]: train_loss_raw=0.2622, running_loss=0.3200, LR=0.000100
[2025-08-11 18:53:25,181][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045060] [Batch 01239/04869] [00:11:14/00:32:56, 0.544s/it]: train_loss_raw=0.3179, running_loss=0.3207, LR=0.000100
[2025-08-11 18:53:31,654][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045072] [Batch 01251/04869] [00:11:21/00:32:49, 0.544s/it]: train_loss_raw=0.3165, running_loss=0.3205, LR=0.000100
[2025-08-11 18:53:38,127][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045084] [Batch 01263/04869] [00:11:27/00:32:42, 0.544s/it]: train_loss_raw=0.4443, running_loss=0.3193, LR=0.000100
[2025-08-11 18:53:44,634][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045096] [Batch 01275/04869] [00:11:34/00:32:36, 0.544s/it]: train_loss_raw=0.3617, running_loss=0.3203, LR=0.000100
[2025-08-11 18:53:51,097][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045108] [Batch 01287/04869] [00:11:40/00:32:29, 0.544s/it]: train_loss_raw=0.2980, running_loss=0.3184, LR=0.000100
[2025-08-11 18:53:57,590][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045120] [Batch 01299/04869] [00:11:46/00:32:22, 0.544s/it]: train_loss_raw=0.3238, running_loss=0.3193, LR=0.000100
[2025-08-11 18:54:04,058][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045132] [Batch 01311/04869] [00:11:53/00:32:16, 0.544s/it]: train_loss_raw=0.3957, running_loss=0.3173, LR=0.000100
[2025-08-11 18:54:10,547][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045144] [Batch 01323/04869] [00:11:59/00:32:09, 0.544s/it]: train_loss_raw=0.3475, running_loss=0.3180, LR=0.000100
[2025-08-11 18:54:17,100][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045156] [Batch 01335/04869] [00:12:06/00:32:03, 0.544s/it]: train_loss_raw=0.2729, running_loss=0.3172, LR=0.000100
[2025-08-11 18:54:23,661][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045168] [Batch 01347/04869] [00:12:13/00:31:56, 0.544s/it]: train_loss_raw=0.3185, running_loss=0.3155, LR=0.000100
[2025-08-11 18:54:30,153][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045180] [Batch 01359/04869] [00:12:19/00:31:50, 0.544s/it]: train_loss_raw=0.3420, running_loss=0.3161, LR=0.000100
[2025-08-11 18:54:36,673][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045192] [Batch 01371/04869] [00:12:26/00:31:43, 0.544s/it]: train_loss_raw=0.2018, running_loss=0.3143, LR=0.000100
[2025-08-11 18:54:43,202][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045204] [Batch 01383/04869] [00:12:32/00:31:36, 0.544s/it]: train_loss_raw=0.2769, running_loss=0.3123, LR=0.000100
[2025-08-11 18:54:49,808][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045216] [Batch 01395/04869] [00:12:39/00:31:30, 0.544s/it]: train_loss_raw=0.2914, running_loss=0.3090, LR=0.000100
[2025-08-11 18:54:56,357][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045228] [Batch 01407/04869] [00:12:45/00:31:24, 0.544s/it]: train_loss_raw=0.2991, running_loss=0.3071, LR=0.000100
[2025-08-11 18:55:02,835][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045240] [Batch 01419/04869] [00:12:52/00:31:17, 0.544s/it]: train_loss_raw=0.3338, running_loss=0.3081, LR=0.000100
[2025-08-11 18:55:09,274][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045252] [Batch 01431/04869] [00:12:58/00:31:10, 0.544s/it]: train_loss_raw=0.3326, running_loss=0.3082, LR=0.000100
[2025-08-11 18:55:15,719][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045264] [Batch 01443/04869] [00:13:05/00:31:04, 0.544s/it]: train_loss_raw=0.3163, running_loss=0.3081, LR=0.000100
[2025-08-11 18:55:22,159][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045276] [Batch 01455/04869] [00:13:11/00:30:57, 0.544s/it]: train_loss_raw=0.2704, running_loss=0.3087, LR=0.000100
[2025-08-11 18:55:28,639][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045288] [Batch 01467/04869] [00:13:18/00:30:50, 0.544s/it]: train_loss_raw=0.2902, running_loss=0.3090, LR=0.000100
[2025-08-11 18:55:35,202][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045300] [Batch 01479/04869] [00:13:24/00:30:44, 0.544s/it]: train_loss_raw=0.3102, running_loss=0.3102, LR=0.000100
[2025-08-11 18:55:41,709][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045312] [Batch 01491/04869] [00:13:31/00:30:37, 0.544s/it]: train_loss_raw=0.2836, running_loss=0.3122, LR=0.000100
[2025-08-11 18:55:48,209][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045324] [Batch 01503/04869] [00:13:37/00:30:31, 0.544s/it]: train_loss_raw=0.3110, running_loss=0.3146, LR=0.000100
[2025-08-11 18:55:54,753][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045336] [Batch 01515/04869] [00:13:44/00:30:24, 0.544s/it]: train_loss_raw=0.3489, running_loss=0.3161, LR=0.000100
[2025-08-11 18:56:01,249][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045348] [Batch 01527/04869] [00:13:50/00:30:17, 0.544s/it]: train_loss_raw=0.2490, running_loss=0.3160, LR=0.000100
[2025-08-11 18:56:07,740][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045360] [Batch 01539/04869] [00:13:57/00:30:11, 0.544s/it]: train_loss_raw=0.1928, running_loss=0.3150, LR=0.000100
[2025-08-11 18:56:14,214][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045372] [Batch 01551/04869] [00:14:03/00:30:04, 0.544s/it]: train_loss_raw=0.2668, running_loss=0.3142, LR=0.000100
[2025-08-11 18:56:20,685][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045384] [Batch 01563/04869] [00:14:10/00:29:58, 0.544s/it]: train_loss_raw=0.2560, running_loss=0.3119, LR=0.000100
[2025-08-11 18:56:27,161][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045396] [Batch 01575/04869] [00:14:16/00:29:51, 0.544s/it]: train_loss_raw=0.2577, running_loss=0.3142, LR=0.000100
[2025-08-11 18:56:33,693][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045408] [Batch 01587/04869] [00:14:23/00:29:44, 0.544s/it]: train_loss_raw=0.2460, running_loss=0.3131, LR=0.000100
[2025-08-11 18:56:40,151][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045420] [Batch 01599/04869] [00:14:29/00:29:38, 0.544s/it]: train_loss_raw=0.2153, running_loss=0.3128, LR=0.000100
[2025-08-11 18:56:46,631][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045432] [Batch 01611/04869] [00:14:36/00:29:31, 0.544s/it]: train_loss_raw=0.3128, running_loss=0.3118, LR=0.000100
[2025-08-11 18:56:53,099][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045444] [Batch 01623/04869] [00:14:42/00:29:24, 0.544s/it]: train_loss_raw=0.2777, running_loss=0.3124, LR=0.000100
[2025-08-11 18:56:59,715][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045456] [Batch 01635/04869] [00:14:49/00:29:18, 0.544s/it]: train_loss_raw=0.3275, running_loss=0.3118, LR=0.000100
[2025-08-11 18:57:06,184][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045468] [Batch 01647/04869] [00:14:55/00:29:11, 0.544s/it]: train_loss_raw=0.3924, running_loss=0.3133, LR=0.000100
[2025-08-11 18:57:12,857][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045480] [Batch 01659/04869] [00:15:02/00:29:05, 0.544s/it]: train_loss_raw=0.2416, running_loss=0.3138, LR=0.000100
[2025-08-11 18:57:19,373][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045492] [Batch 01671/04869] [00:15:08/00:28:59, 0.544s/it]: train_loss_raw=0.2479, running_loss=0.3149, LR=0.000100
[2025-08-11 18:57:25,875][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045504] [Batch 01683/04869] [00:15:15/00:28:52, 0.544s/it]: train_loss_raw=0.2966, running_loss=0.3139, LR=0.000100
[2025-08-11 18:57:32,370][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045516] [Batch 01695/04869] [00:15:21/00:28:46, 0.544s/it]: train_loss_raw=0.2813, running_loss=0.3120, LR=0.000100
[2025-08-11 18:57:38,791][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045528] [Batch 01707/04869] [00:15:28/00:28:39, 0.544s/it]: train_loss_raw=0.2686, running_loss=0.3145, LR=0.000100
[2025-08-11 18:57:45,312][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045540] [Batch 01719/04869] [00:15:34/00:28:32, 0.544s/it]: train_loss_raw=0.2674, running_loss=0.3124, LR=0.000100
[2025-08-11 18:57:51,750][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045552] [Batch 01731/04869] [00:15:41/00:28:26, 0.544s/it]: train_loss_raw=0.2406, running_loss=0.3117, LR=0.000100
[2025-08-11 18:57:58,253][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045564] [Batch 01743/04869] [00:15:47/00:28:19, 0.544s/it]: train_loss_raw=0.2486, running_loss=0.3126, LR=0.000100
[2025-08-11 18:58:04,655][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045576] [Batch 01755/04869] [00:15:54/00:28:12, 0.544s/it]: train_loss_raw=0.3151, running_loss=0.3121, LR=0.000100
[2025-08-11 18:58:11,106][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045588] [Batch 01767/04869] [00:16:00/00:28:06, 0.544s/it]: train_loss_raw=0.2710, running_loss=0.3112, LR=0.000100
[2025-08-11 18:58:17,566][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045600] [Batch 01779/04869] [00:16:06/00:27:59, 0.544s/it]: train_loss_raw=0.3463, running_loss=0.3143, LR=0.000100
[2025-08-11 18:58:24,008][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045612] [Batch 01791/04869] [00:16:13/00:27:52, 0.543s/it]: train_loss_raw=0.2576, running_loss=0.3138, LR=0.000100
[2025-08-11 18:58:30,514][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045624] [Batch 01803/04869] [00:16:19/00:27:46, 0.543s/it]: train_loss_raw=0.3384, running_loss=0.3141, LR=0.000100
[2025-08-11 18:58:37,033][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045636] [Batch 01815/04869] [00:16:26/00:27:39, 0.543s/it]: train_loss_raw=0.3448, running_loss=0.3133, LR=0.000100
[2025-08-11 18:58:43,512][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045648] [Batch 01827/04869] [00:16:32/00:27:33, 0.543s/it]: train_loss_raw=0.3745, running_loss=0.3155, LR=0.000100
[2025-08-11 18:58:49,951][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045660] [Batch 01839/04869] [00:16:39/00:27:26, 0.543s/it]: train_loss_raw=0.3228, running_loss=0.3163, LR=0.000100
[2025-08-11 18:58:56,384][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045672] [Batch 01851/04869] [00:16:45/00:27:19, 0.543s/it]: train_loss_raw=0.3868, running_loss=0.3153, LR=0.000100
[2025-08-11 18:59:02,942][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045684] [Batch 01863/04869] [00:16:52/00:27:13, 0.543s/it]: train_loss_raw=0.3115, running_loss=0.3134, LR=0.000100
[2025-08-11 18:59:09,421][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045696] [Batch 01875/04869] [00:16:58/00:27:06, 0.543s/it]: train_loss_raw=0.3732, running_loss=0.3136, LR=0.000100
[2025-08-11 18:59:15,920][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045708] [Batch 01887/04869] [00:17:05/00:27:00, 0.543s/it]: train_loss_raw=0.3232, running_loss=0.3146, LR=0.000100
[2025-08-11 18:59:22,464][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045720] [Batch 01899/04869] [00:17:11/00:26:53, 0.543s/it]: train_loss_raw=0.2255, running_loss=0.3148, LR=0.000100
[2025-08-11 18:59:29,025][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045732] [Batch 01911/04869] [00:17:18/00:26:47, 0.543s/it]: train_loss_raw=0.4194, running_loss=0.3172, LR=0.000100
[2025-08-11 18:59:35,469][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045744] [Batch 01923/04869] [00:17:24/00:26:40, 0.543s/it]: train_loss_raw=0.2484, running_loss=0.3156, LR=0.000100
[2025-08-11 18:59:42,017][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045756] [Batch 01935/04869] [00:17:31/00:26:34, 0.543s/it]: train_loss_raw=0.4248, running_loss=0.3160, LR=0.000100
[2025-08-11 18:59:48,474][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045768] [Batch 01947/04869] [00:17:37/00:26:27, 0.543s/it]: train_loss_raw=0.3624, running_loss=0.3155, LR=0.000100
[2025-08-11 18:59:54,904][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045780] [Batch 01959/04869] [00:17:44/00:26:20, 0.543s/it]: train_loss_raw=0.2839, running_loss=0.3149, LR=0.000100
[2025-08-11 19:00:01,427][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045792] [Batch 01971/04869] [00:17:50/00:26:14, 0.543s/it]: train_loss_raw=0.2961, running_loss=0.3136, LR=0.000100
[2025-08-11 19:00:07,997][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045804] [Batch 01983/04869] [00:17:57/00:26:07, 0.543s/it]: train_loss_raw=0.2155, running_loss=0.3144, LR=0.000100
[2025-08-11 19:00:14,695][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045816] [Batch 01995/04869] [00:18:04/00:26:01, 0.543s/it]: train_loss_raw=0.2941, running_loss=0.3150, LR=0.000100
[2025-08-11 19:00:21,165][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045828] [Batch 02007/04869] [00:18:10/00:25:55, 0.543s/it]: train_loss_raw=0.2908, running_loss=0.3161, LR=0.000100
[2025-08-11 19:00:27,666][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045840] [Batch 02019/04869] [00:18:17/00:25:48, 0.543s/it]: train_loss_raw=0.2445, running_loss=0.3135, LR=0.000100
[2025-08-11 19:00:34,158][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045852] [Batch 02031/04869] [00:18:23/00:25:42, 0.543s/it]: train_loss_raw=0.3132, running_loss=0.3107, LR=0.000100
[2025-08-11 19:00:40,610][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045864] [Batch 02043/04869] [00:18:30/00:25:35, 0.543s/it]: train_loss_raw=0.3827, running_loss=0.3101, LR=0.000100
[2025-08-11 19:00:47,110][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045876] [Batch 02055/04869] [00:18:36/00:25:28, 0.543s/it]: train_loss_raw=0.3875, running_loss=0.3103, LR=0.000100
[2025-08-11 19:00:53,608][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045888] [Batch 02067/04869] [00:18:42/00:25:22, 0.543s/it]: train_loss_raw=0.3389, running_loss=0.3113, LR=0.000100
[2025-08-11 19:01:00,134][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045900] [Batch 02079/04869] [00:18:49/00:25:15, 0.543s/it]: train_loss_raw=0.2654, running_loss=0.3128, LR=0.000100
[2025-08-11 19:01:06,615][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045912] [Batch 02091/04869] [00:18:56/00:25:09, 0.543s/it]: train_loss_raw=0.2333, running_loss=0.3121, LR=0.000100
[2025-08-11 19:01:13,049][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045924] [Batch 02103/04869] [00:19:02/00:25:02, 0.543s/it]: train_loss_raw=0.3879, running_loss=0.3142, LR=0.000100
[2025-08-11 19:01:19,654][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045936] [Batch 02115/04869] [00:19:09/00:24:56, 0.543s/it]: train_loss_raw=0.4166, running_loss=0.3162, LR=0.000100
[2025-08-11 19:01:26,131][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045948] [Batch 02127/04869] [00:19:15/00:24:49, 0.543s/it]: train_loss_raw=0.3477, running_loss=0.3167, LR=0.000100
[2025-08-11 19:01:32,660][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045960] [Batch 02139/04869] [00:19:22/00:24:43, 0.543s/it]: train_loss_raw=0.2722, running_loss=0.3166, LR=0.000100
[2025-08-11 19:01:39,273][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045972] [Batch 02151/04869] [00:19:28/00:24:36, 0.543s/it]: train_loss_raw=0.3087, running_loss=0.3166, LR=0.000100
[2025-08-11 19:01:45,745][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045984] [Batch 02163/04869] [00:19:35/00:24:30, 0.543s/it]: train_loss_raw=0.3185, running_loss=0.3182, LR=0.000100
[2025-08-11 19:01:52,242][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045996] [Batch 02175/04869] [00:19:41/00:24:23, 0.543s/it]: train_loss_raw=0.2762, running_loss=0.3168, LR=0.000100
[2025-08-11 19:02:03,737][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046008] [Batch 02187/04869] [00:19:53/00:24:23, 0.546s/it]: train_loss_raw=0.2906, running_loss=0.3162, LR=0.000100
[2025-08-11 19:02:10,244][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046020] [Batch 02199/04869] [00:19:59/00:24:16, 0.546s/it]: train_loss_raw=0.4300, running_loss=0.3172, LR=0.000100
[2025-08-11 19:02:16,686][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046032] [Batch 02211/04869] [00:20:06/00:24:09, 0.545s/it]: train_loss_raw=0.3091, running_loss=0.3202, LR=0.000100
[2025-08-11 19:02:23,157][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046044] [Batch 02223/04869] [00:20:12/00:24:03, 0.545s/it]: train_loss_raw=0.3729, running_loss=0.3211, LR=0.000100
[2025-08-11 19:02:29,774][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046056] [Batch 02235/04869] [00:20:19/00:23:56, 0.545s/it]: train_loss_raw=0.2752, running_loss=0.3192, LR=0.000100
[2025-08-11 19:02:36,240][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046068] [Batch 02247/04869] [00:20:25/00:23:50, 0.545s/it]: train_loss_raw=0.2315, running_loss=0.3188, LR=0.000100
[2025-08-11 19:02:42,684][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046080] [Batch 02259/04869] [00:20:32/00:23:43, 0.545s/it]: train_loss_raw=0.2259, running_loss=0.3192, LR=0.000100
[2025-08-11 19:02:49,125][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046092] [Batch 02271/04869] [00:20:38/00:23:36, 0.545s/it]: train_loss_raw=0.2371, running_loss=0.3157, LR=0.000100
[2025-08-11 19:02:55,655][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046104] [Batch 02283/04869] [00:20:45/00:23:30, 0.545s/it]: train_loss_raw=0.3988, running_loss=0.3178, LR=0.000100
[2025-08-11 19:03:02,118][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046116] [Batch 02295/04869] [00:20:51/00:23:23, 0.545s/it]: train_loss_raw=0.2959, running_loss=0.3154, LR=0.000100
[2025-08-11 19:03:08,518][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046128] [Batch 02307/04869] [00:20:57/00:23:16, 0.545s/it]: train_loss_raw=0.3254, running_loss=0.3115, LR=0.000100
[2025-08-11 19:03:14,997][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046140] [Batch 02319/04869] [00:21:04/00:23:10, 0.545s/it]: train_loss_raw=0.2809, running_loss=0.3114, LR=0.000100
[2025-08-11 19:03:21,541][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046152] [Batch 02331/04869] [00:21:10/00:23:03, 0.545s/it]: train_loss_raw=0.2915, running_loss=0.3127, LR=0.000100
[2025-08-11 19:03:28,040][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046164] [Batch 02343/04869] [00:21:17/00:22:57, 0.545s/it]: train_loss_raw=0.3652, running_loss=0.3143, LR=0.000100
[2025-08-11 19:03:34,526][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046176] [Batch 02355/04869] [00:21:23/00:22:50, 0.545s/it]: train_loss_raw=0.2775, running_loss=0.3135, LR=0.000100
[2025-08-11 19:03:40,957][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046188] [Batch 02367/04869] [00:21:30/00:22:43, 0.545s/it]: train_loss_raw=0.2472, running_loss=0.3125, LR=0.000100
[2025-08-11 19:03:47,416][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046200] [Batch 02379/04869] [00:21:36/00:22:37, 0.545s/it]: train_loss_raw=0.4024, running_loss=0.3146, LR=0.000100
[2025-08-11 19:03:53,930][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046212] [Batch 02391/04869] [00:21:43/00:22:30, 0.545s/it]: train_loss_raw=0.2791, running_loss=0.3131, LR=0.000100
[2025-08-11 19:04:00,319][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046224] [Batch 02403/04869] [00:21:49/00:22:24, 0.545s/it]: train_loss_raw=0.2743, running_loss=0.3116, LR=0.000100
[2025-08-11 19:04:06,851][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046236] [Batch 02415/04869] [00:21:56/00:22:17, 0.545s/it]: train_loss_raw=0.2743, running_loss=0.3109, LR=0.000100
[2025-08-11 19:04:13,379][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046248] [Batch 02427/04869] [00:22:02/00:22:10, 0.545s/it]: train_loss_raw=0.2963, running_loss=0.3108, LR=0.000100
[2025-08-11 19:04:19,900][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046260] [Batch 02439/04869] [00:22:09/00:22:04, 0.545s/it]: train_loss_raw=0.3134, running_loss=0.3116, LR=0.000100
[2025-08-11 19:04:26,368][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046272] [Batch 02451/04869] [00:22:15/00:21:57, 0.545s/it]: train_loss_raw=0.2613, running_loss=0.3102, LR=0.000100
[2025-08-11 19:04:32,778][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046284] [Batch 02463/04869] [00:22:22/00:21:51, 0.545s/it]: train_loss_raw=0.2879, running_loss=0.3122, LR=0.000100
[2025-08-11 19:04:39,272][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046296] [Batch 02475/04869] [00:22:28/00:21:44, 0.545s/it]: train_loss_raw=0.2382, running_loss=0.3106, LR=0.000100
[2025-08-11 19:04:45,752][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046308] [Batch 02487/04869] [00:22:35/00:21:37, 0.545s/it]: train_loss_raw=0.3227, running_loss=0.3113, LR=0.000100
[2025-08-11 19:04:52,170][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046320] [Batch 02499/04869] [00:22:41/00:21:31, 0.545s/it]: train_loss_raw=0.3239, running_loss=0.3125, LR=0.000100
[2025-08-11 19:04:58,670][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046332] [Batch 02511/04869] [00:22:48/00:21:24, 0.545s/it]: train_loss_raw=0.3017, running_loss=0.3149, LR=0.000100
[2025-08-11 19:05:05,094][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046344] [Batch 02523/04869] [00:22:54/00:21:18, 0.545s/it]: train_loss_raw=0.3425, running_loss=0.3150, LR=0.000100
[2025-08-11 19:05:11,504][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046356] [Batch 02535/04869] [00:23:00/00:21:11, 0.545s/it]: train_loss_raw=0.3157, running_loss=0.3173, LR=0.000100
[2025-08-11 19:05:17,873][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046368] [Batch 02547/04869] [00:23:07/00:21:04, 0.545s/it]: train_loss_raw=0.2402, running_loss=0.3182, LR=0.000100
[2025-08-11 19:05:24,473][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046380] [Batch 02559/04869] [00:23:13/00:20:58, 0.545s/it]: train_loss_raw=0.2929, running_loss=0.3189, LR=0.000100
[2025-08-11 19:05:30,920][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046392] [Batch 02571/04869] [00:23:20/00:20:51, 0.545s/it]: train_loss_raw=0.2578, running_loss=0.3193, LR=0.000100
[2025-08-11 19:05:37,425][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046404] [Batch 02583/04869] [00:23:26/00:20:45, 0.545s/it]: train_loss_raw=0.2689, running_loss=0.3144, LR=0.000100
[2025-08-11 19:05:43,972][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046416] [Batch 02595/04869] [00:23:33/00:20:38, 0.545s/it]: train_loss_raw=0.2961, running_loss=0.3148, LR=0.000100
[2025-08-11 19:05:50,362][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046428] [Batch 02607/04869] [00:23:39/00:20:31, 0.545s/it]: train_loss_raw=0.3172, running_loss=0.3136, LR=0.000100
[2025-08-11 19:05:56,816][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046440] [Batch 02619/04869] [00:23:46/00:20:25, 0.545s/it]: train_loss_raw=0.3373, running_loss=0.3137, LR=0.000100
[2025-08-11 19:06:03,374][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046452] [Batch 02631/04869] [00:23:52/00:20:18, 0.545s/it]: train_loss_raw=0.3452, running_loss=0.3138, LR=0.000100
[2025-08-11 19:06:09,897][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046464] [Batch 02643/04869] [00:23:59/00:20:12, 0.545s/it]: train_loss_raw=0.2983, running_loss=0.3135, LR=0.000100
[2025-08-11 19:06:16,456][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046476] [Batch 02655/04869] [00:24:05/00:20:05, 0.545s/it]: train_loss_raw=0.4392, running_loss=0.3145, LR=0.000100
[2025-08-11 19:06:23,010][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046488] [Batch 02667/04869] [00:24:12/00:19:59, 0.545s/it]: train_loss_raw=0.3219, running_loss=0.3154, LR=0.000100
[2025-08-11 19:06:29,597][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046500] [Batch 02679/04869] [00:24:18/00:19:52, 0.545s/it]: train_loss_raw=0.3494, running_loss=0.3159, LR=0.000100
[2025-08-11 19:06:36,128][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046512] [Batch 02691/04869] [00:24:25/00:19:46, 0.545s/it]: train_loss_raw=0.3962, running_loss=0.3170, LR=0.000100
[2025-08-11 19:06:42,515][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046524] [Batch 02703/04869] [00:24:31/00:19:39, 0.545s/it]: train_loss_raw=0.4134, running_loss=0.3153, LR=0.000100
[2025-08-11 19:06:49,052][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046536] [Batch 02715/04869] [00:24:38/00:19:32, 0.545s/it]: train_loss_raw=0.3293, running_loss=0.3161, LR=0.000100
[2025-08-11 19:06:55,564][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046548] [Batch 02727/04869] [00:24:44/00:19:26, 0.545s/it]: train_loss_raw=0.2389, running_loss=0.3163, LR=0.000100
[2025-08-11 19:07:02,044][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046560] [Batch 02739/04869] [00:24:51/00:19:19, 0.545s/it]: train_loss_raw=0.2666, running_loss=0.3130, LR=0.000100
[2025-08-11 19:07:08,494][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046572] [Batch 02751/04869] [00:24:57/00:19:13, 0.544s/it]: train_loss_raw=0.3397, running_loss=0.3130, LR=0.000100
[2025-08-11 19:07:14,889][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046584] [Batch 02763/04869] [00:25:04/00:19:06, 0.544s/it]: train_loss_raw=0.3554, running_loss=0.3143, LR=0.000100
[2025-08-11 19:07:21,387][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046596] [Batch 02775/04869] [00:25:10/00:19:00, 0.544s/it]: train_loss_raw=0.4053, running_loss=0.3169, LR=0.000100
[2025-08-11 19:07:27,838][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046608] [Batch 02787/04869] [00:25:17/00:18:53, 0.544s/it]: train_loss_raw=0.2986, running_loss=0.3135, LR=0.000100
[2025-08-11 19:07:34,375][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046620] [Batch 02799/04869] [00:25:23/00:18:46, 0.544s/it]: train_loss_raw=0.2960, running_loss=0.3104, LR=0.000100
[2025-08-11 19:07:40,937][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046632] [Batch 02811/04869] [00:25:30/00:18:40, 0.544s/it]: train_loss_raw=0.3711, running_loss=0.3077, LR=0.000100
[2025-08-11 19:07:47,524][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046644] [Batch 02823/04869] [00:25:36/00:18:33, 0.544s/it]: train_loss_raw=0.2375, running_loss=0.3107, LR=0.000100
[2025-08-11 19:07:54,107][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046656] [Batch 02835/04869] [00:25:43/00:18:27, 0.544s/it]: train_loss_raw=0.3659, running_loss=0.3095, LR=0.000100
[2025-08-11 19:08:08,298][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046668] [Batch 02847/04869] [00:25:57/00:18:26, 0.547s/it]: train_loss_raw=0.3427, running_loss=0.3096, LR=0.000100
[2025-08-11 19:08:14,509][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046680] [Batch 02859/04869] [00:26:03/00:18:19, 0.547s/it]: train_loss_raw=0.3008, running_loss=0.3095, LR=0.000100
[2025-08-11 19:08:21,029][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046692] [Batch 02871/04869] [00:26:10/00:18:12, 0.547s/it]: train_loss_raw=0.3686, running_loss=0.3096, LR=0.000100
[2025-08-11 19:08:27,472][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046704] [Batch 02883/04869] [00:26:16/00:18:06, 0.547s/it]: train_loss_raw=0.3218, running_loss=0.3113, LR=0.000100
[2025-08-11 19:08:34,053][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046716] [Batch 02895/04869] [00:26:23/00:17:59, 0.547s/it]: train_loss_raw=0.3103, running_loss=0.3133, LR=0.000100
[2025-08-11 19:08:40,592][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046728] [Batch 02907/04869] [00:26:29/00:17:53, 0.547s/it]: train_loss_raw=0.2680, running_loss=0.3140, LR=0.000100
[2025-08-11 19:08:47,015][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046740] [Batch 02919/04869] [00:26:36/00:17:46, 0.547s/it]: train_loss_raw=0.2732, running_loss=0.3145, LR=0.000100
[2025-08-11 19:08:53,530][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046752] [Batch 02931/04869] [00:26:42/00:17:39, 0.547s/it]: train_loss_raw=0.4485, running_loss=0.3142, LR=0.000100
[2025-08-11 19:08:59,992][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046764] [Batch 02943/04869] [00:26:49/00:17:33, 0.547s/it]: train_loss_raw=0.3380, running_loss=0.3129, LR=0.000100
[2025-08-11 19:09:06,558][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046776] [Batch 02955/04869] [00:26:55/00:17:26, 0.547s/it]: train_loss_raw=0.3030, running_loss=0.3130, LR=0.000100
[2025-08-11 19:09:13,102][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046788] [Batch 02967/04869] [00:27:02/00:17:20, 0.547s/it]: train_loss_raw=0.3121, running_loss=0.3132, LR=0.000100
[2025-08-11 19:09:19,627][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046800] [Batch 02979/04869] [00:27:09/00:17:13, 0.547s/it]: train_loss_raw=0.2699, running_loss=0.3149, LR=0.000100
[2025-08-11 19:09:26,114][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046812] [Batch 02991/04869] [00:27:15/00:17:06, 0.547s/it]: train_loss_raw=0.2616, running_loss=0.3144, LR=0.000100
[2025-08-11 19:09:32,742][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046824] [Batch 03003/04869] [00:27:22/00:17:00, 0.547s/it]: train_loss_raw=0.2900, running_loss=0.3143, LR=0.000100
[2025-08-11 19:09:39,313][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046836] [Batch 03015/04869] [00:27:28/00:16:53, 0.547s/it]: train_loss_raw=0.2305, running_loss=0.3158, LR=0.000100
[2025-08-11 19:09:45,665][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046848] [Batch 03027/04869] [00:27:35/00:16:47, 0.547s/it]: train_loss_raw=0.3048, running_loss=0.3192, LR=0.000100
[2025-08-11 19:09:52,145][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046860] [Batch 03039/04869] [00:27:41/00:16:40, 0.547s/it]: train_loss_raw=0.3778, running_loss=0.3167, LR=0.000100
[2025-08-11 19:09:58,603][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046872] [Batch 03051/04869] [00:27:47/00:16:33, 0.547s/it]: train_loss_raw=0.3239, running_loss=0.3188, LR=0.000100
[2025-08-11 19:10:05,087][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046884] [Batch 03063/04869] [00:27:54/00:16:27, 0.547s/it]: train_loss_raw=0.2997, running_loss=0.3170, LR=0.000100
[2025-08-11 19:10:11,512][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046896] [Batch 03075/04869] [00:28:00/00:16:20, 0.547s/it]: train_loss_raw=0.3847, running_loss=0.3186, LR=0.000100
[2025-08-11 19:10:17,985][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046908] [Batch 03087/04869] [00:28:07/00:16:14, 0.547s/it]: train_loss_raw=0.3291, running_loss=0.3211, LR=0.000100
[2025-08-11 19:10:24,496][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046920] [Batch 03099/04869] [00:28:13/00:16:07, 0.547s/it]: train_loss_raw=0.3666, running_loss=0.3233, LR=0.000100
[2025-08-11 19:10:31,007][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046932] [Batch 03111/04869] [00:28:20/00:16:00, 0.547s/it]: train_loss_raw=0.3221, running_loss=0.3238, LR=0.000100
[2025-08-11 19:10:37,502][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046944] [Batch 03123/04869] [00:28:26/00:15:54, 0.547s/it]: train_loss_raw=0.3344, running_loss=0.3241, LR=0.000100
[2025-08-11 19:10:43,876][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046956] [Batch 03135/04869] [00:28:33/00:15:47, 0.546s/it]: train_loss_raw=0.2951, running_loss=0.3210, LR=0.000100
[2025-08-11 19:10:49,956][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046968] [Batch 03147/04869] [00:28:39/00:15:40, 0.546s/it]: train_loss_raw=0.2270, running_loss=0.3206, LR=0.000100
[2025-08-11 19:10:56,118][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046980] [Batch 03159/04869] [00:28:45/00:15:34, 0.546s/it]: train_loss_raw=0.3734, running_loss=0.3210, LR=0.000100
[2025-08-11 19:11:02,117][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046992] [Batch 03171/04869] [00:28:51/00:15:27, 0.546s/it]: train_loss_raw=0.3439, running_loss=0.3214, LR=0.000100
[2025-08-11 19:11:08,132][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047004] [Batch 03183/04869] [00:28:57/00:15:20, 0.546s/it]: train_loss_raw=0.2754, running_loss=0.3192, LR=0.000100
[2025-08-11 19:11:14,120][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047016] [Batch 03195/04869] [00:29:03/00:15:13, 0.546s/it]: train_loss_raw=0.3759, running_loss=0.3192, LR=0.000100
[2025-08-11 19:11:20,293][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047028] [Batch 03207/04869] [00:29:09/00:15:06, 0.546s/it]: train_loss_raw=0.2816, running_loss=0.3207, LR=0.000100
[2025-08-11 19:11:26,445][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047040] [Batch 03219/04869] [00:29:15/00:15:00, 0.545s/it]: train_loss_raw=0.2821, running_loss=0.3192, LR=0.000100
[2025-08-11 19:11:32,521][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047052] [Batch 03231/04869] [00:29:21/00:14:53, 0.545s/it]: train_loss_raw=0.3066, running_loss=0.3199, LR=0.000100
[2025-08-11 19:11:38,461][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047064] [Batch 03243/04869] [00:29:27/00:14:46, 0.545s/it]: train_loss_raw=0.3474, running_loss=0.3191, LR=0.000100
[2025-08-11 19:11:44,311][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047076] [Batch 03255/04869] [00:29:33/00:14:39, 0.545s/it]: train_loss_raw=0.2941, running_loss=0.3182, LR=0.000100
[2025-08-11 19:11:50,259][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047088] [Batch 03267/04869] [00:29:39/00:14:32, 0.545s/it]: train_loss_raw=0.3360, running_loss=0.3179, LR=0.000100
[2025-08-11 19:11:56,266][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047100] [Batch 03279/04869] [00:29:45/00:14:25, 0.545s/it]: train_loss_raw=0.3295, running_loss=0.3157, LR=0.000100
[2025-08-11 19:12:02,317][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047112] [Batch 03291/04869] [00:29:51/00:14:19, 0.544s/it]: train_loss_raw=0.2896, running_loss=0.3156, LR=0.000100
[2025-08-11 19:12:08,036][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047124] [Batch 03303/04869] [00:29:57/00:14:12, 0.544s/it]: train_loss_raw=0.3162, running_loss=0.3164, LR=0.000100
[2025-08-11 19:12:13,772][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047136] [Batch 03315/04869] [00:30:03/00:14:05, 0.544s/it]: train_loss_raw=0.3401, running_loss=0.3161, LR=0.000100
[2025-08-11 19:12:19,800][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047148] [Batch 03327/04869] [00:30:09/00:13:58, 0.544s/it]: train_loss_raw=0.2848, running_loss=0.3160, LR=0.000100
[2025-08-11 19:12:25,980][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047160] [Batch 03339/04869] [00:30:15/00:13:51, 0.544s/it]: train_loss_raw=0.2619, running_loss=0.3174, LR=0.000100
[2025-08-11 19:12:31,953][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047172] [Batch 03351/04869] [00:30:21/00:13:45, 0.544s/it]: train_loss_raw=0.3413, running_loss=0.3163, LR=0.000100
[2025-08-11 19:12:38,152][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047184] [Batch 03363/04869] [00:30:27/00:13:38, 0.543s/it]: train_loss_raw=0.2841, running_loss=0.3164, LR=0.000100
[2025-08-11 19:12:44,687][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047196] [Batch 03375/04869] [00:30:34/00:13:31, 0.543s/it]: train_loss_raw=0.3502, running_loss=0.3152, LR=0.000100
[2025-08-11 19:12:51,192][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047208] [Batch 03387/04869] [00:30:40/00:13:25, 0.543s/it]: train_loss_raw=0.3821, running_loss=0.3176, LR=0.000100
[2025-08-11 19:12:57,707][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047220] [Batch 03399/04869] [00:30:47/00:13:18, 0.543s/it]: train_loss_raw=0.3169, running_loss=0.3190, LR=0.000100
[2025-08-11 19:13:04,236][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047232] [Batch 03411/04869] [00:30:53/00:13:12, 0.543s/it]: train_loss_raw=0.2946, running_loss=0.3186, LR=0.000100
[2025-08-11 19:13:10,760][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047244] [Batch 03423/04869] [00:31:00/00:13:05, 0.543s/it]: train_loss_raw=0.2952, running_loss=0.3199, LR=0.000100
[2025-08-11 19:13:17,314][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047256] [Batch 03435/04869] [00:31:06/00:12:59, 0.543s/it]: train_loss_raw=0.3785, running_loss=0.3182, LR=0.000100
[2025-08-11 19:13:23,892][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047268] [Batch 03447/04869] [00:31:13/00:12:52, 0.543s/it]: train_loss_raw=0.3020, running_loss=0.3206, LR=0.000100
[2025-08-11 19:13:30,505][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047280] [Batch 03459/04869] [00:31:19/00:12:46, 0.543s/it]: train_loss_raw=0.1921, running_loss=0.3164, LR=0.000100
[2025-08-11 19:13:37,031][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047292] [Batch 03471/04869] [00:31:26/00:12:39, 0.543s/it]: train_loss_raw=0.3241, running_loss=0.3150, LR=0.000100
[2025-08-11 19:13:43,513][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047304] [Batch 03483/04869] [00:31:32/00:12:33, 0.543s/it]: train_loss_raw=0.3361, running_loss=0.3144, LR=0.000100
[2025-08-11 19:13:49,996][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047316] [Batch 03495/04869] [00:31:39/00:12:26, 0.543s/it]: train_loss_raw=0.3296, running_loss=0.3120, LR=0.000100
[2025-08-11 19:13:56,461][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047328] [Batch 03507/04869] [00:31:45/00:12:20, 0.543s/it]: train_loss_raw=0.3155, running_loss=0.3134, LR=0.000100
[2025-08-11 19:14:03,013][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047340] [Batch 03519/04869] [00:31:52/00:12:13, 0.543s/it]: train_loss_raw=0.3313, running_loss=0.3155, LR=0.000100
[2025-08-11 19:14:09,564][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047352] [Batch 03531/04869] [00:31:58/00:12:07, 0.543s/it]: train_loss_raw=0.3575, running_loss=0.3158, LR=0.000100
[2025-08-11 19:14:15,934][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047364] [Batch 03543/04869] [00:32:05/00:12:00, 0.543s/it]: train_loss_raw=0.3900, running_loss=0.3144, LR=0.000100
[2025-08-11 19:14:22,377][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047376] [Batch 03555/04869] [00:32:11/00:11:54, 0.543s/it]: train_loss_raw=0.3460, running_loss=0.3158, LR=0.000100
[2025-08-11 19:14:28,832][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047388] [Batch 03567/04869] [00:32:18/00:11:47, 0.543s/it]: train_loss_raw=0.3818, running_loss=0.3212, LR=0.000100
[2025-08-11 19:14:35,168][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047400] [Batch 03579/04869] [00:32:24/00:11:40, 0.543s/it]: train_loss_raw=0.3411, running_loss=0.3224, LR=0.000100
[2025-08-11 19:14:41,502][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047412] [Batch 03591/04869] [00:32:30/00:11:34, 0.543s/it]: train_loss_raw=0.3522, running_loss=0.3223, LR=0.000100
[2025-08-11 19:14:48,002][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047424] [Batch 03603/04869] [00:32:37/00:11:27, 0.543s/it]: train_loss_raw=0.3860, running_loss=0.3214, LR=0.000100
[2025-08-11 19:14:54,309][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047436] [Batch 03615/04869] [00:32:43/00:11:21, 0.543s/it]: train_loss_raw=0.2909, running_loss=0.3230, LR=0.000100
[2025-08-11 19:15:00,739][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047448] [Batch 03627/04869] [00:32:50/00:11:14, 0.543s/it]: train_loss_raw=0.4725, running_loss=0.3212, LR=0.000100
[2025-08-11 19:15:07,182][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047460] [Batch 03639/04869] [00:32:56/00:11:08, 0.543s/it]: train_loss_raw=0.3096, running_loss=0.3206, LR=0.000100
[2025-08-11 19:15:13,569][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047472] [Batch 03651/04869] [00:33:02/00:11:01, 0.543s/it]: train_loss_raw=0.3103, running_loss=0.3177, LR=0.000100
[2025-08-11 19:15:19,960][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047484] [Batch 03663/04869] [00:33:09/00:10:54, 0.543s/it]: train_loss_raw=0.3128, running_loss=0.3188, LR=0.000100
[2025-08-11 19:15:26,492][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047496] [Batch 03675/04869] [00:33:15/00:10:48, 0.543s/it]: train_loss_raw=0.2822, running_loss=0.3168, LR=0.000100
[2025-08-11 19:15:32,851][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047508] [Batch 03687/04869] [00:33:22/00:10:41, 0.543s/it]: train_loss_raw=0.3139, running_loss=0.3138, LR=0.000100
[2025-08-11 19:15:39,198][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047520] [Batch 03699/04869] [00:33:28/00:10:35, 0.543s/it]: train_loss_raw=0.3139, running_loss=0.3150, LR=0.000100
[2025-08-11 19:15:45,620][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047532] [Batch 03711/04869] [00:33:35/00:10:28, 0.543s/it]: train_loss_raw=0.2768, running_loss=0.3128, LR=0.000100
[2025-08-11 19:15:51,969][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047544] [Batch 03723/04869] [00:33:41/00:10:22, 0.543s/it]: train_loss_raw=0.2410, running_loss=0.3103, LR=0.000100
[2025-08-11 19:15:58,345][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047556] [Batch 03735/04869] [00:33:47/00:10:15, 0.543s/it]: train_loss_raw=0.2989, running_loss=0.3117, LR=0.000100
[2025-08-11 19:16:04,787][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047568] [Batch 03747/04869] [00:33:54/00:10:09, 0.543s/it]: train_loss_raw=0.2933, running_loss=0.3132, LR=0.000100
[2025-08-11 19:16:11,222][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047580] [Batch 03759/04869] [00:34:00/00:10:02, 0.543s/it]: train_loss_raw=0.3768, running_loss=0.3142, LR=0.000100
[2025-08-11 19:16:17,589][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047592] [Batch 03771/04869] [00:34:06/00:09:56, 0.543s/it]: train_loss_raw=0.2813, running_loss=0.3154, LR=0.000100
[2025-08-11 19:16:23,931][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047604] [Batch 03783/04869] [00:34:13/00:09:49, 0.543s/it]: train_loss_raw=0.3081, running_loss=0.3172, LR=0.000100
[2025-08-11 19:16:30,347][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047616] [Batch 03795/04869] [00:34:19/00:09:42, 0.543s/it]: train_loss_raw=0.2910, running_loss=0.3148, LR=0.000100
[2025-08-11 19:16:36,918][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047628] [Batch 03807/04869] [00:34:26/00:09:36, 0.543s/it]: train_loss_raw=0.3190, running_loss=0.3154, LR=0.000100
[2025-08-11 19:16:43,364][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047640] [Batch 03819/04869] [00:34:32/00:09:29, 0.543s/it]: train_loss_raw=0.2909, running_loss=0.3151, LR=0.000100
[2025-08-11 19:16:49,852][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047652] [Batch 03831/04869] [00:34:39/00:09:23, 0.543s/it]: train_loss_raw=0.3063, running_loss=0.3135, LR=0.000100
[2025-08-11 19:16:56,349][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047664] [Batch 03843/04869] [00:34:45/00:09:16, 0.543s/it]: train_loss_raw=0.3568, running_loss=0.3119, LR=0.000100
[2025-08-11 19:17:02,862][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047676] [Batch 03855/04869] [00:34:52/00:09:10, 0.543s/it]: train_loss_raw=0.2568, running_loss=0.3114, LR=0.000100
[2025-08-11 19:17:09,355][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047688] [Batch 03867/04869] [00:34:58/00:09:03, 0.543s/it]: train_loss_raw=0.3047, running_loss=0.3108, LR=0.000100
[2025-08-11 19:17:15,966][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047700] [Batch 03879/04869] [00:35:05/00:08:57, 0.543s/it]: train_loss_raw=0.3904, running_loss=0.3118, LR=0.000100
[2025-08-11 19:17:22,533][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047712] [Batch 03891/04869] [00:35:11/00:08:50, 0.543s/it]: train_loss_raw=0.3730, running_loss=0.3134, LR=0.000100
[2025-08-11 19:17:28,953][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047724] [Batch 03903/04869] [00:35:18/00:08:44, 0.543s/it]: train_loss_raw=0.3572, running_loss=0.3114, LR=0.000100
[2025-08-11 19:17:35,573][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047736] [Batch 03915/04869] [00:35:24/00:08:37, 0.543s/it]: train_loss_raw=0.4148, running_loss=0.3123, LR=0.000100
[2025-08-11 19:17:42,074][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047748] [Batch 03927/04869] [00:35:31/00:08:31, 0.543s/it]: train_loss_raw=0.3107, running_loss=0.3135, LR=0.000100
[2025-08-11 19:17:48,588][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047760] [Batch 03939/04869] [00:35:37/00:08:24, 0.543s/it]: train_loss_raw=0.2723, running_loss=0.3130, LR=0.000100
[2025-08-11 19:17:55,145][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047772] [Batch 03951/04869] [00:35:44/00:08:18, 0.543s/it]: train_loss_raw=0.3481, running_loss=0.3136, LR=0.000100
[2025-08-11 19:18:01,668][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047784] [Batch 03963/04869] [00:35:51/00:08:11, 0.543s/it]: train_loss_raw=0.3877, running_loss=0.3152, LR=0.000100
[2025-08-11 19:18:08,234][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047796] [Batch 03975/04869] [00:35:57/00:08:05, 0.543s/it]: train_loss_raw=0.3616, running_loss=0.3120, LR=0.000100
[2025-08-11 19:18:14,789][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047808] [Batch 03987/04869] [00:36:04/00:07:58, 0.543s/it]: train_loss_raw=0.3660, running_loss=0.3130, LR=0.000100
[2025-08-11 19:18:21,355][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047820] [Batch 03999/04869] [00:36:10/00:07:52, 0.543s/it]: train_loss_raw=0.3655, running_loss=0.3132, LR=0.000100
[2025-08-11 19:18:27,879][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047832] [Batch 04011/04869] [00:36:17/00:07:45, 0.543s/it]: train_loss_raw=0.2797, running_loss=0.3113, LR=0.000100
[2025-08-11 19:18:34,481][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047844] [Batch 04023/04869] [00:36:23/00:07:39, 0.543s/it]: train_loss_raw=0.2626, running_loss=0.3118, LR=0.000100
[2025-08-11 19:18:41,055][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047856] [Batch 04035/04869] [00:36:30/00:07:32, 0.543s/it]: train_loss_raw=0.2762, running_loss=0.3095, LR=0.000100
[2025-08-11 19:18:47,564][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047868] [Batch 04047/04869] [00:36:36/00:07:26, 0.543s/it]: train_loss_raw=0.4336, running_loss=0.3109, LR=0.000100
[2025-08-11 19:18:54,130][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047880] [Batch 04059/04869] [00:36:43/00:07:19, 0.543s/it]: train_loss_raw=0.3749, running_loss=0.3116, LR=0.000100
[2025-08-11 19:19:00,663][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047892] [Batch 04071/04869] [00:36:50/00:07:13, 0.543s/it]: train_loss_raw=0.3264, running_loss=0.3103, LR=0.000100
[2025-08-11 19:19:07,112][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047904] [Batch 04083/04869] [00:36:56/00:07:06, 0.543s/it]: train_loss_raw=0.2649, running_loss=0.3114, LR=0.000100
[2025-08-11 19:19:13,567][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047916] [Batch 04095/04869] [00:37:02/00:07:00, 0.543s/it]: train_loss_raw=0.3549, running_loss=0.3153, LR=0.000100
[2025-08-11 19:19:20,064][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047928] [Batch 04107/04869] [00:37:09/00:06:53, 0.543s/it]: train_loss_raw=0.2915, running_loss=0.3150, LR=0.000100
[2025-08-11 19:19:26,496][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047940] [Batch 04119/04869] [00:37:15/00:06:47, 0.543s/it]: train_loss_raw=0.3104, running_loss=0.3152, LR=0.000100
[2025-08-11 19:19:32,973][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047952] [Batch 04131/04869] [00:37:22/00:06:40, 0.543s/it]: train_loss_raw=0.3352, running_loss=0.3141, LR=0.000100
[2025-08-11 19:19:39,424][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047964] [Batch 04143/04869] [00:37:28/00:06:34, 0.543s/it]: train_loss_raw=0.3176, running_loss=0.3128, LR=0.000100
[2025-08-11 19:19:45,891][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047976] [Batch 04155/04869] [00:37:35/00:06:27, 0.543s/it]: train_loss_raw=0.3066, running_loss=0.3131, LR=0.000100
[2025-08-11 19:19:52,422][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 047988] [Batch 04167/04869] [00:37:41/00:06:21, 0.543s/it]: train_loss_raw=0.2155, running_loss=0.3146, LR=0.000100
[2025-08-11 19:19:58,897][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048000] [Batch 04179/04869] [00:37:48/00:06:14, 0.543s/it]: train_loss_raw=0.3428, running_loss=0.3163, LR=0.000100
[2025-08-11 19:20:10,424][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048012] [Batch 04191/04869] [00:37:59/00:06:08, 0.544s/it]: train_loss_raw=0.2417, running_loss=0.3155, LR=0.000100
[2025-08-11 19:20:16,840][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048024] [Batch 04203/04869] [00:38:06/00:06:02, 0.544s/it]: train_loss_raw=0.2618, running_loss=0.3138, LR=0.000100
[2025-08-11 19:20:23,252][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048036] [Batch 04215/04869] [00:38:12/00:05:55, 0.544s/it]: train_loss_raw=0.2726, running_loss=0.3134, LR=0.000100
[2025-08-11 19:20:29,769][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048048] [Batch 04227/04869] [00:38:19/00:05:49, 0.544s/it]: train_loss_raw=0.3816, running_loss=0.3114, LR=0.000100
[2025-08-11 19:20:36,225][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048060] [Batch 04239/04869] [00:38:25/00:05:42, 0.544s/it]: train_loss_raw=0.3228, running_loss=0.3088, LR=0.000100
[2025-08-11 19:20:42,672][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048072] [Batch 04251/04869] [00:38:32/00:05:36, 0.544s/it]: train_loss_raw=0.3567, running_loss=0.3077, LR=0.000100
[2025-08-11 19:20:49,208][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048084] [Batch 04263/04869] [00:38:38/00:05:29, 0.544s/it]: train_loss_raw=0.2956, running_loss=0.3077, LR=0.000100
[2025-08-11 19:20:55,757][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048096] [Batch 04275/04869] [00:38:45/00:05:23, 0.544s/it]: train_loss_raw=0.2719, running_loss=0.3092, LR=0.000100
[2025-08-11 19:21:02,246][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048108] [Batch 04287/04869] [00:38:51/00:05:16, 0.544s/it]: train_loss_raw=0.4312, running_loss=0.3119, LR=0.000100
[2025-08-11 19:21:08,779][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048120] [Batch 04299/04869] [00:38:58/00:05:10, 0.544s/it]: train_loss_raw=0.3240, running_loss=0.3107, LR=0.000100
[2025-08-11 19:21:15,208][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048132] [Batch 04311/04869] [00:39:04/00:05:03, 0.544s/it]: train_loss_raw=0.4010, running_loss=0.3122, LR=0.000100
[2025-08-11 19:21:21,819][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048144] [Batch 04323/04869] [00:39:11/00:04:56, 0.544s/it]: train_loss_raw=0.3306, running_loss=0.3156, LR=0.000100
[2025-08-11 19:21:28,222][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048156] [Batch 04335/04869] [00:39:17/00:04:50, 0.544s/it]: train_loss_raw=0.3365, running_loss=0.3162, LR=0.000100
[2025-08-11 19:21:34,770][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048168] [Batch 04347/04869] [00:39:24/00:04:43, 0.544s/it]: train_loss_raw=0.2729, running_loss=0.3158, LR=0.000100
[2025-08-11 19:21:41,219][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048180] [Batch 04359/04869] [00:39:30/00:04:37, 0.544s/it]: train_loss_raw=0.3404, running_loss=0.3166, LR=0.000100
[2025-08-11 19:21:47,803][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048192] [Batch 04371/04869] [00:39:37/00:04:30, 0.544s/it]: train_loss_raw=0.2649, running_loss=0.3147, LR=0.000100
[2025-08-11 19:21:54,230][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048204] [Batch 04383/04869] [00:39:43/00:04:24, 0.544s/it]: train_loss_raw=0.2745, running_loss=0.3142, LR=0.000100
[2025-08-11 19:22:00,818][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048216] [Batch 04395/04869] [00:39:50/00:04:17, 0.544s/it]: train_loss_raw=0.3244, running_loss=0.3139, LR=0.000100
[2025-08-11 19:22:07,311][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048228] [Batch 04407/04869] [00:39:56/00:04:11, 0.544s/it]: train_loss_raw=0.3019, running_loss=0.3123, LR=0.000100
[2025-08-11 19:22:13,786][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048240] [Batch 04419/04869] [00:40:03/00:04:04, 0.544s/it]: train_loss_raw=0.2750, running_loss=0.3111, LR=0.000100
[2025-08-11 19:22:20,256][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048252] [Batch 04431/04869] [00:40:09/00:03:58, 0.544s/it]: train_loss_raw=0.3061, running_loss=0.3125, LR=0.000100
[2025-08-11 19:22:26,723][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048264] [Batch 04443/04869] [00:40:16/00:03:51, 0.544s/it]: train_loss_raw=0.2793, running_loss=0.3128, LR=0.000100
[2025-08-11 19:22:33,194][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048276] [Batch 04455/04869] [00:40:22/00:03:45, 0.544s/it]: train_loss_raw=0.3479, running_loss=0.3129, LR=0.000100
[2025-08-11 19:22:39,720][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048288] [Batch 04467/04869] [00:40:29/00:03:38, 0.544s/it]: train_loss_raw=0.2637, running_loss=0.3117, LR=0.000100
[2025-08-11 19:22:46,244][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048300] [Batch 04479/04869] [00:40:35/00:03:32, 0.544s/it]: train_loss_raw=0.2797, running_loss=0.3111, LR=0.000100
[2025-08-11 19:22:52,866][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048312] [Batch 04491/04869] [00:40:42/00:03:25, 0.544s/it]: train_loss_raw=0.3006, running_loss=0.3096, LR=0.000100
[2025-08-11 19:22:59,431][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048324] [Batch 04503/04869] [00:40:48/00:03:19, 0.544s/it]: train_loss_raw=0.3399, running_loss=0.3100, LR=0.000100
[2025-08-11 19:23:05,998][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048336] [Batch 04515/04869] [00:40:55/00:03:12, 0.544s/it]: train_loss_raw=0.4213, running_loss=0.3119, LR=0.000100
[2025-08-11 19:23:12,512][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048348] [Batch 04527/04869] [00:41:01/00:03:05, 0.544s/it]: train_loss_raw=0.3185, running_loss=0.3118, LR=0.000100
[2025-08-11 19:23:19,056][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048360] [Batch 04539/04869] [00:41:08/00:02:59, 0.544s/it]: train_loss_raw=0.3311, running_loss=0.3116, LR=0.000100
[2025-08-11 19:23:25,516][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048372] [Batch 04551/04869] [00:41:14/00:02:52, 0.544s/it]: train_loss_raw=0.3688, running_loss=0.3124, LR=0.000100
[2025-08-11 19:23:32,021][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048384] [Batch 04563/04869] [00:41:21/00:02:46, 0.544s/it]: train_loss_raw=0.3359, running_loss=0.3132, LR=0.000100
[2025-08-11 19:23:38,529][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048396] [Batch 04575/04869] [00:41:27/00:02:39, 0.544s/it]: train_loss_raw=0.2629, running_loss=0.3139, LR=0.000100
[2025-08-11 19:23:45,087][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048408] [Batch 04587/04869] [00:41:34/00:02:33, 0.544s/it]: train_loss_raw=0.3323, running_loss=0.3149, LR=0.000100
[2025-08-11 19:23:51,645][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048420] [Batch 04599/04869] [00:41:41/00:02:26, 0.544s/it]: train_loss_raw=0.2734, running_loss=0.3126, LR=0.000100
[2025-08-11 19:23:58,150][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048432] [Batch 04611/04869] [00:41:47/00:02:20, 0.544s/it]: train_loss_raw=0.3247, running_loss=0.3138, LR=0.000100
[2025-08-11 19:24:04,525][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048444] [Batch 04623/04869] [00:41:53/00:02:13, 0.544s/it]: train_loss_raw=0.2698, running_loss=0.3134, LR=0.000100
[2025-08-11 19:24:11,024][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048456] [Batch 04635/04869] [00:42:00/00:02:07, 0.544s/it]: train_loss_raw=0.2836, running_loss=0.3128, LR=0.000100
[2025-08-11 19:24:17,541][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048468] [Batch 04647/04869] [00:42:06/00:02:00, 0.544s/it]: train_loss_raw=0.3154, running_loss=0.3140, LR=0.000100
[2025-08-11 19:24:24,067][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048480] [Batch 04659/04869] [00:42:13/00:01:54, 0.544s/it]: train_loss_raw=0.2764, running_loss=0.3135, LR=0.000100
[2025-08-11 19:24:30,529][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048492] [Batch 04671/04869] [00:42:19/00:01:47, 0.544s/it]: train_loss_raw=0.2665, running_loss=0.3106, LR=0.000100
[2025-08-11 19:24:37,057][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048504] [Batch 04683/04869] [00:42:26/00:01:41, 0.544s/it]: train_loss_raw=0.3106, running_loss=0.3116, LR=0.000100
[2025-08-11 19:24:43,617][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048516] [Batch 04695/04869] [00:42:33/00:01:34, 0.544s/it]: train_loss_raw=0.2448, running_loss=0.3124, LR=0.000100
[2025-08-11 19:24:50,202][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048528] [Batch 04707/04869] [00:42:39/00:01:28, 0.544s/it]: train_loss_raw=0.3881, running_loss=0.3141, LR=0.000100
[2025-08-11 19:24:56,632][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048540] [Batch 04719/04869] [00:42:46/00:01:21, 0.544s/it]: train_loss_raw=0.2966, running_loss=0.3139, LR=0.000100
[2025-08-11 19:25:03,242][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048552] [Batch 04731/04869] [00:42:52/00:01:15, 0.544s/it]: train_loss_raw=0.2535, running_loss=0.3121, LR=0.000100
[2025-08-11 19:25:09,764][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048564] [Batch 04743/04869] [00:42:59/00:01:08, 0.544s/it]: train_loss_raw=0.2743, running_loss=0.3111, LR=0.000100
[2025-08-11 19:25:16,383][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048576] [Batch 04755/04869] [00:43:05/00:01:01, 0.544s/it]: train_loss_raw=0.3936, running_loss=0.3102, LR=0.000100
[2025-08-11 19:25:22,824][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048588] [Batch 04767/04869] [00:43:12/00:00:55, 0.544s/it]: train_loss_raw=0.2774, running_loss=0.3103, LR=0.000100
[2025-08-11 19:25:29,423][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048600] [Batch 04779/04869] [00:43:18/00:00:48, 0.544s/it]: train_loss_raw=0.4348, running_loss=0.3109, LR=0.000100
[2025-08-11 19:25:35,979][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048612] [Batch 04791/04869] [00:43:25/00:00:42, 0.544s/it]: train_loss_raw=0.2449, running_loss=0.3074, LR=0.000100
[2025-08-11 19:25:42,559][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048624] [Batch 04803/04869] [00:43:31/00:00:35, 0.544s/it]: train_loss_raw=0.3312, running_loss=0.3111, LR=0.000100
[2025-08-11 19:25:49,130][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048636] [Batch 04815/04869] [00:43:38/00:00:29, 0.544s/it]: train_loss_raw=0.3396, running_loss=0.3126, LR=0.000100
[2025-08-11 19:25:55,548][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048648] [Batch 04827/04869] [00:43:44/00:00:22, 0.544s/it]: train_loss_raw=0.3545, running_loss=0.3121, LR=0.000100
[2025-08-11 19:26:02,021][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048660] [Batch 04839/04869] [00:43:51/00:00:16, 0.544s/it]: train_loss_raw=0.3343, running_loss=0.3139, LR=0.000100
[2025-08-11 19:26:08,435][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048672] [Batch 04851/04869] [00:43:57/00:00:09, 0.544s/it]: train_loss_raw=0.3248, running_loss=0.3139, LR=0.000100
[2025-08-11 19:26:14,890][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 048684] [Batch 04863/04869] [00:44:04/00:00:03, 0.544s/it]: train_loss_raw=0.2773, running_loss=0.3143, LR=0.000100
[2025-08-11 19:26:51,198][__main__][INFO] - [VALIDATION] [Epoch 09/29] Starting validation.
[2025-08-11 19:27:06,683][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 048691] [Batch 00011/00062] [00:00:15/00:01:04, 1.290s/it]
[2025-08-11 19:27:41,533][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 048691] [Batch 00023/00062] [00:00:50/00:01:19, 2.097s/it]
[2025-08-11 19:27:57,216][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 048691] [Batch 00035/00062] [00:01:06/00:00:47, 1.834s/it]
[2025-08-11 19:28:13,250][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 048691] [Batch 00047/00062] [00:01:22/00:00:23, 1.709s/it]
[2025-08-11 19:28:28,686][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 048691] [Batch 00059/00062] [00:01:37/00:00:03, 1.625s/it]
[2025-08-11 19:28:31,145][__main__][INFO] - [VALIDATION] [Epoch 09/29] train_loss=0.31127, valid_loss=0.36429
[2025-08-11 19:28:31,146][__main__][INFO] - [VALIDATION] [Epoch 09/29] Metrics:
[2025-08-11 19:28:31,146][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_er      0.183
[2025-08-11 19:28:31,147][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_prec    0.644
[2025-08-11 19:28:31,147][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_recall  0.647
[2025-08-11 19:28:31,147][__main__][INFO] - [VALIDATION] [Epoch 09/29] - pep_recall 0.607
[2025-08-11 19:28:31,152][__main__][INFO] - [TRAIN] [Epoch 09/29] Epoch complete, total time 07:33:09, remaining time 15:06:19, 00:45:18 per epoch
[2025-08-11 19:28:34,283][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048696] [Batch 00006/04869] [00:00:02/00:38:02, 0.469s/it]: train_loss_raw=0.2995, running_loss=0.2748, LR=0.000100
[2025-08-11 19:28:40,768][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048708] [Batch 00018/04869] [00:00:09/00:41:46, 0.517s/it]: train_loss_raw=0.2164, running_loss=0.2754, LR=0.000100
[2025-08-11 19:28:47,251][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048720] [Batch 00030/04869] [00:00:15/00:42:26, 0.526s/it]: train_loss_raw=0.2455, running_loss=0.2766, LR=0.000100
[2025-08-11 19:28:53,740][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048732] [Batch 00042/04869] [00:00:22/00:42:39, 0.530s/it]: train_loss_raw=0.2883, running_loss=0.2734, LR=0.000100
[2025-08-11 19:29:00,243][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048744] [Batch 00054/04869] [00:00:28/00:42:46, 0.533s/it]: train_loss_raw=0.2783, running_loss=0.2748, LR=0.000100
[2025-08-11 19:29:06,749][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048756] [Batch 00066/04869] [00:00:35/00:42:47, 0.535s/it]: train_loss_raw=0.3605, running_loss=0.2715, LR=0.000100
[2025-08-11 19:29:13,218][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048768] [Batch 00078/04869] [00:00:41/00:42:44, 0.535s/it]: train_loss_raw=0.2275, running_loss=0.2717, LR=0.000100
[2025-08-11 19:29:19,693][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048780] [Batch 00090/04869] [00:00:48/00:42:40, 0.536s/it]: train_loss_raw=0.2912, running_loss=0.2742, LR=0.000100
[2025-08-11 19:29:26,155][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048792] [Batch 00102/04869] [00:00:54/00:42:35, 0.536s/it]: train_loss_raw=0.3009, running_loss=0.2745, LR=0.000100
[2025-08-11 19:29:32,617][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048804] [Batch 00114/04869] [00:01:01/00:42:30, 0.536s/it]: train_loss_raw=0.1658, running_loss=0.2738, LR=0.000100
[2025-08-11 19:29:39,089][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048816] [Batch 00126/04869] [00:01:07/00:42:25, 0.537s/it]: train_loss_raw=0.2969, running_loss=0.2736, LR=0.000100
[2025-08-11 19:29:45,591][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048828] [Batch 00138/04869] [00:01:14/00:42:21, 0.537s/it]: train_loss_raw=0.2390, running_loss=0.2734, LR=0.000100
[2025-08-11 19:29:52,078][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048840] [Batch 00150/04869] [00:01:20/00:42:16, 0.537s/it]: train_loss_raw=0.2391, running_loss=0.2724, LR=0.000100
[2025-08-11 19:29:58,599][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048852] [Batch 00162/04869] [00:01:27/00:42:11, 0.538s/it]: train_loss_raw=0.2761, running_loss=0.2744, LR=0.000100
[2025-08-11 19:30:05,024][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048864] [Batch 00174/04869] [00:01:33/00:42:04, 0.538s/it]: train_loss_raw=0.2851, running_loss=0.2750, LR=0.000100
[2025-08-11 19:30:11,488][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048876] [Batch 00186/04869] [00:01:40/00:41:58, 0.538s/it]: train_loss_raw=0.2674, running_loss=0.2758, LR=0.000100
[2025-08-11 19:30:17,995][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048888] [Batch 00198/04869] [00:01:46/00:41:53, 0.538s/it]: train_loss_raw=0.2270, running_loss=0.2748, LR=0.000100
[2025-08-11 19:30:24,505][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048900] [Batch 00210/04869] [00:01:53/00:41:47, 0.538s/it]: train_loss_raw=0.2694, running_loss=0.2790, LR=0.000100
[2025-08-11 19:30:31,046][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048912] [Batch 00222/04869] [00:01:59/00:41:43, 0.539s/it]: train_loss_raw=0.2823, running_loss=0.2798, LR=0.000100
[2025-08-11 19:30:37,582][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048924] [Batch 00234/04869] [00:02:06/00:41:38, 0.539s/it]: train_loss_raw=0.1835, running_loss=0.2780, LR=0.000100
[2025-08-11 19:30:44,064][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048936] [Batch 00246/04869] [00:02:12/00:41:31, 0.539s/it]: train_loss_raw=0.2582, running_loss=0.2776, LR=0.000100
[2025-08-11 19:30:50,568][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048948] [Batch 00258/04869] [00:02:19/00:41:26, 0.539s/it]: train_loss_raw=0.2499, running_loss=0.2775, LR=0.000100
[2025-08-11 19:30:57,036][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048960] [Batch 00270/04869] [00:02:25/00:41:19, 0.539s/it]: train_loss_raw=0.2155, running_loss=0.2768, LR=0.000100
[2025-08-11 19:31:03,505][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048972] [Batch 00282/04869] [00:02:32/00:41:13, 0.539s/it]: train_loss_raw=0.2690, running_loss=0.2762, LR=0.000100
[2025-08-11 19:31:10,012][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048984] [Batch 00294/04869] [00:02:38/00:41:07, 0.539s/it]: train_loss_raw=0.1952, running_loss=0.2762, LR=0.000100
[2025-08-11 19:31:16,507][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 048996] [Batch 00306/04869] [00:02:45/00:41:01, 0.539s/it]: train_loss_raw=0.2665, running_loss=0.2768, LR=0.000100
[2025-08-11 19:31:23,123][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049008] [Batch 00318/04869] [00:02:51/00:40:56, 0.540s/it]: train_loss_raw=0.3030, running_loss=0.2786, LR=0.000100
[2025-08-11 19:31:29,619][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049020] [Batch 00330/04869] [00:02:58/00:40:50, 0.540s/it]: train_loss_raw=0.3964, running_loss=0.2824, LR=0.000100
[2025-08-11 19:31:36,069][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049032] [Batch 00342/04869] [00:03:04/00:40:43, 0.540s/it]: train_loss_raw=0.2440, running_loss=0.2822, LR=0.000100
[2025-08-11 19:31:42,594][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049044] [Batch 00354/04869] [00:03:11/00:40:37, 0.540s/it]: train_loss_raw=0.3199, running_loss=0.2813, LR=0.000100
[2025-08-11 19:31:49,009][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049056] [Batch 00366/04869] [00:03:17/00:40:30, 0.540s/it]: train_loss_raw=0.3041, running_loss=0.2823, LR=0.000100
[2025-08-11 19:31:55,509][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049068] [Batch 00378/04869] [00:03:24/00:40:24, 0.540s/it]: train_loss_raw=0.3243, running_loss=0.2824, LR=0.000100
[2025-08-11 19:32:01,968][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049080] [Batch 00390/04869] [00:03:30/00:40:17, 0.540s/it]: train_loss_raw=0.2805, running_loss=0.2839, LR=0.000100
[2025-08-11 19:32:08,500][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049092] [Batch 00402/04869] [00:03:37/00:40:11, 0.540s/it]: train_loss_raw=0.2519, running_loss=0.2831, LR=0.000100
[2025-08-11 19:32:15,070][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049104] [Batch 00414/04869] [00:03:43/00:40:06, 0.540s/it]: train_loss_raw=0.2889, running_loss=0.2831, LR=0.000100
[2025-08-11 19:32:21,560][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049116] [Batch 00426/04869] [00:03:50/00:39:59, 0.540s/it]: train_loss_raw=0.2280, running_loss=0.2829, LR=0.000100
[2025-08-11 19:32:28,189][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049128] [Batch 00438/04869] [00:03:56/00:39:54, 0.540s/it]: train_loss_raw=0.2357, running_loss=0.2855, LR=0.000100
[2025-08-11 19:32:34,682][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049140] [Batch 00450/04869] [00:04:03/00:39:48, 0.540s/it]: train_loss_raw=0.2944, running_loss=0.2852, LR=0.000100
[2025-08-11 19:32:41,152][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049152] [Batch 00462/04869] [00:04:09/00:39:41, 0.540s/it]: train_loss_raw=0.3056, running_loss=0.2874, LR=0.000100
[2025-08-11 19:32:47,612][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049164] [Batch 00474/04869] [00:04:16/00:39:35, 0.540s/it]: train_loss_raw=0.3012, running_loss=0.2871, LR=0.000100
[2025-08-11 19:32:53,994][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049176] [Batch 00486/04869] [00:04:22/00:39:27, 0.540s/it]: train_loss_raw=0.3122, running_loss=0.2880, LR=0.000100
[2025-08-11 19:33:00,484][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049188] [Batch 00498/04869] [00:04:29/00:39:21, 0.540s/it]: train_loss_raw=0.3346, running_loss=0.2891, LR=0.000100
[2025-08-11 19:33:07,037][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049200] [Batch 00510/04869] [00:04:35/00:39:15, 0.540s/it]: train_loss_raw=0.2490, running_loss=0.2886, LR=0.000100
[2025-08-11 19:33:13,561][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049212] [Batch 00522/04869] [00:04:42/00:39:09, 0.540s/it]: train_loss_raw=0.3204, running_loss=0.2886, LR=0.000100
[2025-08-11 19:33:20,080][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049224] [Batch 00534/04869] [00:04:48/00:39:02, 0.540s/it]: train_loss_raw=0.3715, running_loss=0.2883, LR=0.000100
[2025-08-11 19:33:26,621][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049236] [Batch 00546/04869] [00:04:55/00:38:56, 0.541s/it]: train_loss_raw=0.2714, running_loss=0.2875, LR=0.000100
[2025-08-11 19:33:33,153][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049248] [Batch 00558/04869] [00:05:01/00:38:50, 0.541s/it]: train_loss_raw=0.3286, running_loss=0.2888, LR=0.000100
[2025-08-11 19:33:39,655][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049260] [Batch 00570/04869] [00:05:08/00:38:44, 0.541s/it]: train_loss_raw=0.3119, running_loss=0.2895, LR=0.000100
[2025-08-11 19:33:46,123][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049272] [Batch 00582/04869] [00:05:14/00:38:37, 0.541s/it]: train_loss_raw=0.2843, running_loss=0.2885, LR=0.000100
[2025-08-11 19:33:52,620][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049284] [Batch 00594/04869] [00:05:21/00:38:31, 0.541s/it]: train_loss_raw=0.2541, running_loss=0.2866, LR=0.000100
[2025-08-11 19:33:59,169][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049296] [Batch 00606/04869] [00:05:27/00:38:25, 0.541s/it]: train_loss_raw=0.2218, running_loss=0.2875, LR=0.000100
[2025-08-11 19:34:05,736][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049308] [Batch 00618/04869] [00:05:34/00:38:19, 0.541s/it]: train_loss_raw=0.3069, running_loss=0.2860, LR=0.000100
[2025-08-11 19:34:12,144][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049320] [Batch 00630/04869] [00:05:40/00:38:12, 0.541s/it]: train_loss_raw=0.3114, running_loss=0.2867, LR=0.000100
[2025-08-11 19:34:18,646][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049332] [Batch 00642/04869] [00:05:47/00:38:05, 0.541s/it]: train_loss_raw=0.2799, running_loss=0.2846, LR=0.000100
[2025-08-11 19:34:25,158][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049344] [Batch 00654/04869] [00:05:53/00:37:59, 0.541s/it]: train_loss_raw=0.2559, running_loss=0.2823, LR=0.000100
[2025-08-11 19:34:31,673][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049356] [Batch 00666/04869] [00:06:00/00:37:53, 0.541s/it]: train_loss_raw=0.2262, running_loss=0.2789, LR=0.000100
[2025-08-11 19:34:38,191][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049368] [Batch 00678/04869] [00:06:06/00:37:46, 0.541s/it]: train_loss_raw=0.4204, running_loss=0.2790, LR=0.000100
[2025-08-11 19:34:44,694][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049380] [Batch 00690/04869] [00:06:13/00:37:40, 0.541s/it]: train_loss_raw=0.2632, running_loss=0.2800, LR=0.000100
[2025-08-11 19:34:51,180][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049392] [Batch 00702/04869] [00:06:19/00:37:33, 0.541s/it]: train_loss_raw=0.2430, running_loss=0.2814, LR=0.000100
[2025-08-11 19:34:57,700][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049404] [Batch 00714/04869] [00:06:26/00:37:27, 0.541s/it]: train_loss_raw=0.2872, running_loss=0.2818, LR=0.000100
[2025-08-11 19:35:04,195][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049416] [Batch 00726/04869] [00:06:32/00:37:21, 0.541s/it]: train_loss_raw=0.2138, running_loss=0.2845, LR=0.000100
[2025-08-11 19:35:10,729][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049428] [Batch 00738/04869] [00:06:39/00:37:14, 0.541s/it]: train_loss_raw=0.2868, running_loss=0.2853, LR=0.000100
[2025-08-11 19:35:17,301][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049440] [Batch 00750/04869] [00:06:45/00:37:08, 0.541s/it]: train_loss_raw=0.3197, running_loss=0.2835, LR=0.000100
[2025-08-11 19:35:23,742][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049452] [Batch 00762/04869] [00:06:52/00:37:02, 0.541s/it]: train_loss_raw=0.2656, running_loss=0.2840, LR=0.000100
[2025-08-11 19:35:30,244][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049464] [Batch 00774/04869] [00:06:58/00:36:55, 0.541s/it]: train_loss_raw=0.3511, running_loss=0.2849, LR=0.000100
[2025-08-11 19:35:36,808][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049476] [Batch 00786/04869] [00:07:05/00:36:49, 0.541s/it]: train_loss_raw=0.2722, running_loss=0.2862, LR=0.000100
[2025-08-11 19:35:43,250][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049488] [Batch 00798/04869] [00:07:11/00:36:42, 0.541s/it]: train_loss_raw=0.3037, running_loss=0.2848, LR=0.000100
[2025-08-11 19:35:49,837][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049500] [Batch 00810/04869] [00:07:18/00:36:36, 0.541s/it]: train_loss_raw=0.2044, running_loss=0.2820, LR=0.000100
[2025-08-11 19:35:56,351][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049512] [Batch 00822/04869] [00:07:24/00:36:30, 0.541s/it]: train_loss_raw=0.2467, running_loss=0.2822, LR=0.000100
[2025-08-11 19:36:02,838][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049524] [Batch 00834/04869] [00:07:31/00:36:23, 0.541s/it]: train_loss_raw=0.3416, running_loss=0.2830, LR=0.000100
[2025-08-11 19:36:09,361][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049536] [Batch 00846/04869] [00:07:37/00:36:17, 0.541s/it]: train_loss_raw=0.2608, running_loss=0.2848, LR=0.000100
[2025-08-11 19:36:15,896][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049548] [Batch 00858/04869] [00:07:44/00:36:11, 0.541s/it]: train_loss_raw=0.2833, running_loss=0.2851, LR=0.000100
[2025-08-11 19:36:22,389][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049560] [Batch 00870/04869] [00:07:50/00:36:04, 0.541s/it]: train_loss_raw=0.2767, running_loss=0.2869, LR=0.000100
[2025-08-11 19:36:28,879][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049572] [Batch 00882/04869] [00:07:57/00:35:58, 0.541s/it]: train_loss_raw=0.2080, running_loss=0.2856, LR=0.000100
[2025-08-11 19:36:35,462][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049584] [Batch 00894/04869] [00:08:03/00:35:51, 0.541s/it]: train_loss_raw=0.3347, running_loss=0.2864, LR=0.000100
[2025-08-11 19:36:41,985][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049596] [Batch 00906/04869] [00:08:10/00:35:45, 0.541s/it]: train_loss_raw=0.3277, running_loss=0.2882, LR=0.000100
[2025-08-11 19:36:48,548][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049608] [Batch 00918/04869] [00:08:17/00:35:39, 0.541s/it]: train_loss_raw=0.2565, running_loss=0.2875, LR=0.000100
[2025-08-11 19:36:55,049][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049620] [Batch 00930/04869] [00:08:23/00:35:32, 0.541s/it]: train_loss_raw=0.3710, running_loss=0.2906, LR=0.000100
[2025-08-11 19:37:01,494][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049632] [Batch 00942/04869] [00:08:30/00:35:26, 0.541s/it]: train_loss_raw=0.2406, running_loss=0.2904, LR=0.000100
[2025-08-11 19:37:07,976][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049644] [Batch 00954/04869] [00:08:36/00:35:19, 0.541s/it]: train_loss_raw=0.1977, running_loss=0.2892, LR=0.000100
[2025-08-11 19:37:14,461][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049656] [Batch 00966/04869] [00:08:42/00:35:13, 0.541s/it]: train_loss_raw=0.2620, running_loss=0.2872, LR=0.000100
[2025-08-11 19:37:21,033][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049668] [Batch 00978/04869] [00:08:49/00:35:06, 0.541s/it]: train_loss_raw=0.3150, running_loss=0.2889, LR=0.000100
[2025-08-11 19:37:27,577][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049680] [Batch 00990/04869] [00:08:56/00:35:00, 0.542s/it]: train_loss_raw=0.3412, running_loss=0.2886, LR=0.000100
[2025-08-11 19:37:33,978][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049692] [Batch 01002/04869] [00:09:02/00:34:53, 0.541s/it]: train_loss_raw=0.2710, running_loss=0.2914, LR=0.000100
[2025-08-11 19:37:40,472][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049704] [Batch 01014/04869] [00:09:09/00:34:47, 0.541s/it]: train_loss_raw=0.3039, running_loss=0.2894, LR=0.000100
[2025-08-11 19:37:47,015][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049716] [Batch 01026/04869] [00:09:15/00:34:40, 0.541s/it]: train_loss_raw=0.2988, running_loss=0.2880, LR=0.000100
[2025-08-11 19:37:53,598][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049728] [Batch 01038/04869] [00:09:22/00:34:34, 0.542s/it]: train_loss_raw=0.3014, running_loss=0.2852, LR=0.000100
[2025-08-11 19:38:00,145][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049740] [Batch 01050/04869] [00:09:28/00:34:28, 0.542s/it]: train_loss_raw=0.2727, running_loss=0.2858, LR=0.000100
[2025-08-11 19:38:06,641][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049752] [Batch 01062/04869] [00:09:35/00:34:21, 0.542s/it]: train_loss_raw=0.2704, running_loss=0.2860, LR=0.000100
[2025-08-11 19:38:13,254][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049764] [Batch 01074/04869] [00:09:41/00:34:15, 0.542s/it]: train_loss_raw=0.3072, running_loss=0.2886, LR=0.000100
[2025-08-11 19:38:19,703][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049776] [Batch 01086/04869] [00:09:48/00:34:09, 0.542s/it]: train_loss_raw=0.3212, running_loss=0.2899, LR=0.000100
[2025-08-11 19:38:26,128][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049788] [Batch 01098/04869] [00:09:54/00:34:02, 0.542s/it]: train_loss_raw=0.2943, running_loss=0.2890, LR=0.000100
[2025-08-11 19:38:32,655][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049800] [Batch 01110/04869] [00:10:01/00:33:55, 0.542s/it]: train_loss_raw=0.2364, running_loss=0.2884, LR=0.000100
[2025-08-11 19:38:39,192][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049812] [Batch 01122/04869] [00:10:07/00:33:49, 0.542s/it]: train_loss_raw=0.2816, running_loss=0.2889, LR=0.000100
[2025-08-11 19:38:45,808][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049824] [Batch 01134/04869] [00:10:14/00:33:43, 0.542s/it]: train_loss_raw=0.3436, running_loss=0.2872, LR=0.000100
[2025-08-11 19:38:52,385][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049836] [Batch 01146/04869] [00:10:20/00:33:37, 0.542s/it]: train_loss_raw=0.2951, running_loss=0.2878, LR=0.000100
[2025-08-11 19:38:58,829][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049848] [Batch 01158/04869] [00:10:27/00:33:30, 0.542s/it]: train_loss_raw=0.3150, running_loss=0.2852, LR=0.000100
[2025-08-11 19:39:05,350][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049860] [Batch 01170/04869] [00:10:33/00:33:24, 0.542s/it]: train_loss_raw=0.2907, running_loss=0.2857, LR=0.000100
[2025-08-11 19:39:11,870][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049872] [Batch 01182/04869] [00:10:40/00:33:17, 0.542s/it]: train_loss_raw=0.3547, running_loss=0.2834, LR=0.000100
[2025-08-11 19:39:18,397][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049884] [Batch 01194/04869] [00:10:46/00:33:11, 0.542s/it]: train_loss_raw=0.2932, running_loss=0.2820, LR=0.000100
[2025-08-11 19:39:24,828][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049896] [Batch 01206/04869] [00:10:53/00:33:04, 0.542s/it]: train_loss_raw=0.3195, running_loss=0.2818, LR=0.000100
[2025-08-11 19:39:31,430][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049908] [Batch 01218/04869] [00:10:59/00:32:58, 0.542s/it]: train_loss_raw=0.3762, running_loss=0.2799, LR=0.000100
[2025-08-11 19:39:37,934][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049920] [Batch 01230/04869] [00:11:06/00:32:51, 0.542s/it]: train_loss_raw=0.2292, running_loss=0.2811, LR=0.000100
[2025-08-11 19:39:44,453][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049932] [Batch 01242/04869] [00:11:12/00:32:45, 0.542s/it]: train_loss_raw=0.3903, running_loss=0.2823, LR=0.000100
[2025-08-11 19:39:50,931][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049944] [Batch 01254/04869] [00:11:19/00:32:38, 0.542s/it]: train_loss_raw=0.2621, running_loss=0.2836, LR=0.000100
[2025-08-11 19:39:57,429][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049956] [Batch 01266/04869] [00:11:25/00:32:32, 0.542s/it]: train_loss_raw=0.3074, running_loss=0.2857, LR=0.000100
[2025-08-11 19:40:03,979][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049968] [Batch 01278/04869] [00:11:32/00:32:25, 0.542s/it]: train_loss_raw=0.3090, running_loss=0.2856, LR=0.000100
[2025-08-11 19:40:10,405][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049980] [Batch 01290/04869] [00:11:38/00:32:19, 0.542s/it]: train_loss_raw=0.2563, running_loss=0.2863, LR=0.000100
[2025-08-11 19:40:16,933][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 049992] [Batch 01302/04869] [00:11:45/00:32:12, 0.542s/it]: train_loss_raw=0.2923, running_loss=0.2868, LR=0.000100
[2025-08-11 19:40:28,637][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050004] [Batch 01314/04869] [00:11:57/00:32:20, 0.546s/it]: train_loss_raw=0.2944, running_loss=0.2882, LR=0.000100
[2025-08-11 19:40:35,080][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050016] [Batch 01326/04869] [00:12:03/00:32:13, 0.546s/it]: train_loss_raw=0.2911, running_loss=0.2892, LR=0.000100
[2025-08-11 19:40:41,568][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050028] [Batch 01338/04869] [00:12:10/00:32:06, 0.546s/it]: train_loss_raw=0.3387, running_loss=0.2912, LR=0.000100
[2025-08-11 19:40:48,093][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050040] [Batch 01350/04869] [00:12:16/00:32:00, 0.546s/it]: train_loss_raw=0.2233, running_loss=0.2907, LR=0.000100
[2025-08-11 19:40:54,674][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050052] [Batch 01362/04869] [00:12:23/00:31:53, 0.546s/it]: train_loss_raw=0.3044, running_loss=0.2913, LR=0.000100
[2025-08-11 19:41:01,150][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050064] [Batch 01374/04869] [00:12:29/00:31:46, 0.546s/it]: train_loss_raw=0.3793, running_loss=0.2928, LR=0.000100
[2025-08-11 19:41:07,614][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050076] [Batch 01386/04869] [00:12:36/00:31:40, 0.546s/it]: train_loss_raw=0.2343, running_loss=0.2911, LR=0.000100
[2025-08-11 19:41:14,121][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050088] [Batch 01398/04869] [00:12:42/00:31:33, 0.546s/it]: train_loss_raw=0.2421, running_loss=0.2903, LR=0.000100
[2025-08-11 19:41:20,628][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050100] [Batch 01410/04869] [00:12:49/00:31:26, 0.546s/it]: train_loss_raw=0.3267, running_loss=0.2913, LR=0.000100
[2025-08-11 19:41:27,167][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050112] [Batch 01422/04869] [00:12:55/00:31:20, 0.546s/it]: train_loss_raw=0.2409, running_loss=0.2917, LR=0.000100
[2025-08-11 19:41:33,704][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050124] [Batch 01434/04869] [00:13:02/00:31:13, 0.545s/it]: train_loss_raw=0.2320, running_loss=0.2904, LR=0.000100
[2025-08-11 19:41:40,181][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050136] [Batch 01446/04869] [00:13:08/00:31:07, 0.545s/it]: train_loss_raw=0.3391, running_loss=0.2912, LR=0.000100
[2025-08-11 19:41:46,684][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050148] [Batch 01458/04869] [00:13:15/00:31:00, 0.545s/it]: train_loss_raw=0.3897, running_loss=0.2929, LR=0.000100
[2025-08-11 19:41:53,128][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050160] [Batch 01470/04869] [00:13:21/00:30:53, 0.545s/it]: train_loss_raw=0.3571, running_loss=0.2917, LR=0.000100
[2025-08-11 19:41:59,538][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050172] [Batch 01482/04869] [00:13:28/00:30:46, 0.545s/it]: train_loss_raw=0.3452, running_loss=0.2924, LR=0.000100
[2025-08-11 19:42:06,086][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050184] [Batch 01494/04869] [00:13:34/00:30:40, 0.545s/it]: train_loss_raw=0.2473, running_loss=0.2923, LR=0.000100
[2025-08-11 19:42:12,616][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050196] [Batch 01506/04869] [00:13:41/00:30:33, 0.545s/it]: train_loss_raw=0.3071, running_loss=0.2935, LR=0.000100
[2025-08-11 19:42:19,124][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050208] [Batch 01518/04869] [00:13:47/00:30:27, 0.545s/it]: train_loss_raw=0.2635, running_loss=0.2948, LR=0.000100
[2025-08-11 19:42:25,546][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050220] [Batch 01530/04869] [00:13:54/00:30:20, 0.545s/it]: train_loss_raw=0.4054, running_loss=0.2957, LR=0.000100
[2025-08-11 19:42:32,071][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050232] [Batch 01542/04869] [00:14:00/00:30:13, 0.545s/it]: train_loss_raw=0.3144, running_loss=0.2930, LR=0.000100
[2025-08-11 19:42:38,541][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050244] [Batch 01554/04869] [00:14:07/00:30:06, 0.545s/it]: train_loss_raw=0.3545, running_loss=0.2954, LR=0.000100
[2025-08-11 19:42:45,020][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050256] [Batch 01566/04869] [00:14:13/00:30:00, 0.545s/it]: train_loss_raw=0.3351, running_loss=0.2957, LR=0.000100
[2025-08-11 19:42:51,493][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050268] [Batch 01578/04869] [00:14:20/00:29:53, 0.545s/it]: train_loss_raw=0.2311, running_loss=0.2967, LR=0.000100
[2025-08-11 19:42:58,029][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050280] [Batch 01590/04869] [00:14:26/00:29:47, 0.545s/it]: train_loss_raw=0.2839, running_loss=0.2980, LR=0.000100
[2025-08-11 19:43:04,664][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050292] [Batch 01602/04869] [00:14:33/00:29:40, 0.545s/it]: train_loss_raw=0.2706, running_loss=0.2961, LR=0.000100
[2025-08-11 19:43:11,187][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050304] [Batch 01614/04869] [00:14:39/00:29:34, 0.545s/it]: train_loss_raw=0.3312, running_loss=0.2961, LR=0.000100
[2025-08-11 19:43:17,720][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050316] [Batch 01626/04869] [00:14:46/00:29:27, 0.545s/it]: train_loss_raw=0.2668, running_loss=0.2950, LR=0.000100
[2025-08-11 19:43:24,255][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050328] [Batch 01638/04869] [00:14:52/00:29:21, 0.545s/it]: train_loss_raw=0.2992, running_loss=0.2932, LR=0.000100
[2025-08-11 19:43:30,750][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050340] [Batch 01650/04869] [00:14:59/00:29:14, 0.545s/it]: train_loss_raw=0.2971, running_loss=0.2925, LR=0.000100
[2025-08-11 19:43:37,344][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050352] [Batch 01662/04869] [00:15:05/00:29:07, 0.545s/it]: train_loss_raw=0.2148, running_loss=0.2898, LR=0.000100
[2025-08-11 19:43:43,843][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050364] [Batch 01674/04869] [00:15:12/00:29:01, 0.545s/it]: train_loss_raw=0.2186, running_loss=0.2884, LR=0.000100
[2025-08-11 19:43:50,394][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050376] [Batch 01686/04869] [00:15:18/00:28:54, 0.545s/it]: train_loss_raw=0.3431, running_loss=0.2915, LR=0.000100
[2025-08-11 19:43:56,877][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050388] [Batch 01698/04869] [00:15:25/00:28:48, 0.545s/it]: train_loss_raw=0.3227, running_loss=0.2915, LR=0.000100
[2025-08-11 19:44:03,433][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050400] [Batch 01710/04869] [00:15:31/00:28:41, 0.545s/it]: train_loss_raw=0.2659, running_loss=0.2935, LR=0.000100
[2025-08-11 19:44:10,039][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050412] [Batch 01722/04869] [00:15:38/00:28:35, 0.545s/it]: train_loss_raw=0.3640, running_loss=0.2950, LR=0.000100
[2025-08-11 19:44:16,521][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050424] [Batch 01734/04869] [00:15:45/00:28:28, 0.545s/it]: train_loss_raw=0.2857, running_loss=0.2949, LR=0.000100
[2025-08-11 19:44:23,089][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050436] [Batch 01746/04869] [00:15:51/00:28:22, 0.545s/it]: train_loss_raw=0.4255, running_loss=0.2942, LR=0.000100
[2025-08-11 19:44:29,569][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050448] [Batch 01758/04869] [00:15:58/00:28:15, 0.545s/it]: train_loss_raw=0.3164, running_loss=0.2937, LR=0.000100
[2025-08-11 19:44:36,015][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050460] [Batch 01770/04869] [00:16:04/00:28:08, 0.545s/it]: train_loss_raw=0.2827, running_loss=0.2945, LR=0.000100
[2025-08-11 19:44:42,514][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050472] [Batch 01782/04869] [00:16:11/00:28:02, 0.545s/it]: train_loss_raw=0.3309, running_loss=0.2952, LR=0.000100
[2025-08-11 19:44:49,134][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050484] [Batch 01794/04869] [00:16:17/00:27:55, 0.545s/it]: train_loss_raw=0.2523, running_loss=0.2926, LR=0.000100
[2025-08-11 19:44:55,785][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050496] [Batch 01806/04869] [00:16:24/00:27:49, 0.545s/it]: train_loss_raw=0.3056, running_loss=0.2934, LR=0.000100
[2025-08-11 19:45:02,290][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050508] [Batch 01818/04869] [00:16:30/00:27:42, 0.545s/it]: train_loss_raw=0.3254, running_loss=0.2923, LR=0.000100
[2025-08-11 19:45:08,785][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050520] [Batch 01830/04869] [00:16:37/00:27:36, 0.545s/it]: train_loss_raw=0.3480, running_loss=0.2912, LR=0.000100
[2025-08-11 19:45:15,293][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050532] [Batch 01842/04869] [00:16:43/00:27:29, 0.545s/it]: train_loss_raw=0.2589, running_loss=0.2904, LR=0.000100
[2025-08-11 19:45:21,871][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050544] [Batch 01854/04869] [00:16:50/00:27:23, 0.545s/it]: train_loss_raw=0.2895, running_loss=0.2907, LR=0.000100
[2025-08-11 19:45:28,363][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050556] [Batch 01866/04869] [00:16:56/00:27:16, 0.545s/it]: train_loss_raw=0.2434, running_loss=0.2920, LR=0.000100
[2025-08-11 19:45:34,884][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050568] [Batch 01878/04869] [00:17:03/00:27:09, 0.545s/it]: train_loss_raw=0.2395, running_loss=0.2946, LR=0.000100
[2025-08-11 19:45:41,373][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050580] [Batch 01890/04869] [00:17:09/00:27:03, 0.545s/it]: train_loss_raw=0.3020, running_loss=0.2950, LR=0.000100
[2025-08-11 19:45:47,928][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050592] [Batch 01902/04869] [00:17:16/00:26:56, 0.545s/it]: train_loss_raw=0.2898, running_loss=0.2968, LR=0.000100
[2025-08-11 19:45:54,434][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050604] [Batch 01914/04869] [00:17:22/00:26:50, 0.545s/it]: train_loss_raw=0.2594, running_loss=0.2958, LR=0.000100
[2025-08-11 19:46:00,946][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050616] [Batch 01926/04869] [00:17:29/00:26:43, 0.545s/it]: train_loss_raw=0.2809, running_loss=0.2966, LR=0.000100
[2025-08-11 19:46:07,414][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050628] [Batch 01938/04869] [00:17:35/00:26:36, 0.545s/it]: train_loss_raw=0.2863, running_loss=0.2939, LR=0.000100
[2025-08-11 19:46:13,958][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050640] [Batch 01950/04869] [00:17:42/00:26:30, 0.545s/it]: train_loss_raw=0.3813, running_loss=0.2953, LR=0.000100
[2025-08-11 19:46:20,527][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050652] [Batch 01962/04869] [00:17:49/00:26:23, 0.545s/it]: train_loss_raw=0.3081, running_loss=0.2952, LR=0.000100
[2025-08-11 19:46:27,085][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050664] [Batch 01974/04869] [00:17:55/00:26:17, 0.545s/it]: train_loss_raw=0.3346, running_loss=0.2955, LR=0.000100
[2025-08-11 19:46:33,615][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050676] [Batch 01986/04869] [00:18:02/00:26:10, 0.545s/it]: train_loss_raw=0.3656, running_loss=0.2966, LR=0.000100
[2025-08-11 19:46:40,189][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050688] [Batch 01998/04869] [00:18:08/00:26:04, 0.545s/it]: train_loss_raw=0.2603, running_loss=0.2962, LR=0.000100
[2025-08-11 19:46:46,693][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050700] [Batch 02010/04869] [00:18:15/00:25:57, 0.545s/it]: train_loss_raw=0.1812, running_loss=0.2941, LR=0.000100
[2025-08-11 19:46:53,237][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050712] [Batch 02022/04869] [00:18:21/00:25:51, 0.545s/it]: train_loss_raw=0.3152, running_loss=0.2953, LR=0.000100
[2025-08-11 19:46:59,717][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050724] [Batch 02034/04869] [00:18:28/00:25:44, 0.545s/it]: train_loss_raw=0.2476, running_loss=0.2954, LR=0.000100
[2025-08-11 19:47:06,347][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050736] [Batch 02046/04869] [00:18:34/00:25:38, 0.545s/it]: train_loss_raw=0.3119, running_loss=0.2939, LR=0.000100
[2025-08-11 19:47:12,882][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050748] [Batch 02058/04869] [00:18:41/00:25:31, 0.545s/it]: train_loss_raw=0.2652, running_loss=0.2915, LR=0.000100
[2025-08-11 19:47:19,381][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050760] [Batch 02070/04869] [00:18:47/00:25:25, 0.545s/it]: train_loss_raw=0.3032, running_loss=0.2883, LR=0.000100
[2025-08-11 19:47:25,844][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050772] [Batch 02082/04869] [00:18:54/00:25:18, 0.545s/it]: train_loss_raw=0.2644, running_loss=0.2876, LR=0.000100
[2025-08-11 19:47:32,356][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050784] [Batch 02094/04869] [00:19:00/00:25:11, 0.545s/it]: train_loss_raw=0.2952, running_loss=0.2915, LR=0.000100
[2025-08-11 19:47:38,894][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050796] [Batch 02106/04869] [00:19:07/00:25:05, 0.545s/it]: train_loss_raw=0.3110, running_loss=0.2919, LR=0.000100
[2025-08-11 19:47:45,517][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050808] [Batch 02118/04869] [00:19:14/00:24:58, 0.545s/it]: train_loss_raw=0.2251, running_loss=0.2932, LR=0.000100
[2025-08-11 19:47:52,100][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050820] [Batch 02130/04869] [00:19:20/00:24:52, 0.545s/it]: train_loss_raw=0.3888, running_loss=0.2928, LR=0.000100
[2025-08-11 19:47:58,629][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050832] [Batch 02142/04869] [00:19:27/00:24:45, 0.545s/it]: train_loss_raw=0.2818, running_loss=0.2961, LR=0.000100
[2025-08-11 19:48:05,165][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050844] [Batch 02154/04869] [00:19:33/00:24:39, 0.545s/it]: train_loss_raw=0.3396, running_loss=0.2938, LR=0.000100
[2025-08-11 19:48:11,741][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050856] [Batch 02166/04869] [00:19:40/00:24:32, 0.545s/it]: train_loss_raw=0.3267, running_loss=0.2947, LR=0.000100
[2025-08-11 19:48:18,187][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050868] [Batch 02178/04869] [00:19:46/00:24:26, 0.545s/it]: train_loss_raw=0.2905, running_loss=0.2957, LR=0.000100
[2025-08-11 19:48:24,611][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050880] [Batch 02190/04869] [00:19:53/00:24:19, 0.545s/it]: train_loss_raw=0.3157, running_loss=0.2979, LR=0.000100
[2025-08-11 19:48:31,191][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050892] [Batch 02202/04869] [00:19:59/00:24:13, 0.545s/it]: train_loss_raw=0.2376, running_loss=0.2962, LR=0.000100
[2025-08-11 19:48:37,763][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050904] [Batch 02214/04869] [00:20:06/00:24:06, 0.545s/it]: train_loss_raw=0.2701, running_loss=0.2967, LR=0.000100
[2025-08-11 19:48:44,321][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050916] [Batch 02226/04869] [00:20:12/00:24:00, 0.545s/it]: train_loss_raw=0.1972, running_loss=0.2935, LR=0.000100
[2025-08-11 19:48:50,842][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050928] [Batch 02238/04869] [00:20:19/00:23:53, 0.545s/it]: train_loss_raw=0.2772, running_loss=0.2920, LR=0.000100
[2025-08-11 19:48:57,351][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050940] [Batch 02250/04869] [00:20:25/00:23:46, 0.545s/it]: train_loss_raw=0.3299, running_loss=0.2905, LR=0.000100
[2025-08-11 19:49:03,817][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050952] [Batch 02262/04869] [00:20:32/00:23:40, 0.545s/it]: train_loss_raw=0.2431, running_loss=0.2916, LR=0.000100
[2025-08-11 19:49:10,231][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050964] [Batch 02274/04869] [00:20:38/00:23:33, 0.545s/it]: train_loss_raw=0.2386, running_loss=0.2931, LR=0.000100
[2025-08-11 19:49:16,857][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050976] [Batch 02286/04869] [00:20:45/00:23:27, 0.545s/it]: train_loss_raw=0.3736, running_loss=0.2953, LR=0.000100
[2025-08-11 19:49:23,409][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 050988] [Batch 02298/04869] [00:20:51/00:23:20, 0.545s/it]: train_loss_raw=0.3148, running_loss=0.2965, LR=0.000100
[2025-08-11 19:49:29,979][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051000] [Batch 02310/04869] [00:20:58/00:23:14, 0.545s/it]: train_loss_raw=0.2841, running_loss=0.2949, LR=0.000100
[2025-08-11 19:49:36,466][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051012] [Batch 02322/04869] [00:21:05/00:23:07, 0.545s/it]: train_loss_raw=0.2887, running_loss=0.2951, LR=0.000100
[2025-08-11 19:49:42,883][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051024] [Batch 02334/04869] [00:21:11/00:23:00, 0.545s/it]: train_loss_raw=0.2895, running_loss=0.2944, LR=0.000100
[2025-08-11 19:49:49,467][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051036] [Batch 02346/04869] [00:21:18/00:22:54, 0.545s/it]: train_loss_raw=0.2837, running_loss=0.2949, LR=0.000100
[2025-08-11 19:49:56,032][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051048] [Batch 02358/04869] [00:21:24/00:22:47, 0.545s/it]: train_loss_raw=0.3230, running_loss=0.2943, LR=0.000100
[2025-08-11 19:50:02,581][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051060] [Batch 02370/04869] [00:21:31/00:22:41, 0.545s/it]: train_loss_raw=0.2864, running_loss=0.2964, LR=0.000100
[2025-08-11 19:50:09,134][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051072] [Batch 02382/04869] [00:21:37/00:22:34, 0.545s/it]: train_loss_raw=0.3212, running_loss=0.2969, LR=0.000100
[2025-08-11 19:50:15,574][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051084] [Batch 02394/04869] [00:21:44/00:22:28, 0.545s/it]: train_loss_raw=0.2786, running_loss=0.2950, LR=0.000100
[2025-08-11 19:50:22,121][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051096] [Batch 02406/04869] [00:21:50/00:22:21, 0.545s/it]: train_loss_raw=0.2429, running_loss=0.2935, LR=0.000100
[2025-08-11 19:50:28,565][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051108] [Batch 02418/04869] [00:21:57/00:22:15, 0.545s/it]: train_loss_raw=0.3182, running_loss=0.2919, LR=0.000100
[2025-08-11 19:50:35,060][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051120] [Batch 02430/04869] [00:22:03/00:22:08, 0.545s/it]: train_loss_raw=0.3479, running_loss=0.2907, LR=0.000100
[2025-08-11 19:50:41,612][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051132] [Batch 02442/04869] [00:22:10/00:22:01, 0.545s/it]: train_loss_raw=0.2922, running_loss=0.2900, LR=0.000100
[2025-08-11 19:50:48,103][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051144] [Batch 02454/04869] [00:22:16/00:21:55, 0.545s/it]: train_loss_raw=0.3929, running_loss=0.2924, LR=0.000100
[2025-08-11 19:50:54,683][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051156] [Batch 02466/04869] [00:22:23/00:21:48, 0.545s/it]: train_loss_raw=0.3614, running_loss=0.2918, LR=0.000100
[2025-08-11 19:51:01,225][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051168] [Batch 02478/04869] [00:22:29/00:21:42, 0.545s/it]: train_loss_raw=0.2705, running_loss=0.2892, LR=0.000100
[2025-08-11 19:51:07,706][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051180] [Batch 02490/04869] [00:22:36/00:21:35, 0.545s/it]: train_loss_raw=0.2380, running_loss=0.2887, LR=0.000100
[2025-08-11 19:51:14,180][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051192] [Batch 02502/04869] [00:22:42/00:21:29, 0.545s/it]: train_loss_raw=0.3086, running_loss=0.2920, LR=0.000100
[2025-08-11 19:51:20,619][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051204] [Batch 02514/04869] [00:22:49/00:21:22, 0.545s/it]: train_loss_raw=0.4139, running_loss=0.2936, LR=0.000100
[2025-08-11 19:51:27,063][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051216] [Batch 02526/04869] [00:22:55/00:21:15, 0.545s/it]: train_loss_raw=0.2449, running_loss=0.2926, LR=0.000100
[2025-08-11 19:51:33,489][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051228] [Batch 02538/04869] [00:23:02/00:21:09, 0.545s/it]: train_loss_raw=0.2428, running_loss=0.2900, LR=0.000100
[2025-08-11 19:51:40,088][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051240] [Batch 02550/04869] [00:23:08/00:21:02, 0.545s/it]: train_loss_raw=0.3090, running_loss=0.2944, LR=0.000100
[2025-08-11 19:51:46,552][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051252] [Batch 02562/04869] [00:23:15/00:20:56, 0.545s/it]: train_loss_raw=0.3580, running_loss=0.2948, LR=0.000100
[2025-08-11 19:51:53,066][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051264] [Batch 02574/04869] [00:23:21/00:20:49, 0.545s/it]: train_loss_raw=0.3976, running_loss=0.2951, LR=0.000100
[2025-08-11 19:51:59,523][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051276] [Batch 02586/04869] [00:23:28/00:20:43, 0.544s/it]: train_loss_raw=0.2855, running_loss=0.2944, LR=0.000100
[2025-08-11 19:52:05,963][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051288] [Batch 02598/04869] [00:23:34/00:20:36, 0.544s/it]: train_loss_raw=0.3090, running_loss=0.2955, LR=0.000100
[2025-08-11 19:52:12,442][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051300] [Batch 02610/04869] [00:23:40/00:20:29, 0.544s/it]: train_loss_raw=0.3089, running_loss=0.2965, LR=0.000100
[2025-08-11 19:52:18,927][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051312] [Batch 02622/04869] [00:23:47/00:20:23, 0.544s/it]: train_loss_raw=0.3319, running_loss=0.2963, LR=0.000100
[2025-08-11 19:52:25,448][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051324] [Batch 02634/04869] [00:23:53/00:20:16, 0.544s/it]: train_loss_raw=0.2362, running_loss=0.2955, LR=0.000100
[2025-08-11 19:52:31,945][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051336] [Batch 02646/04869] [00:24:00/00:20:10, 0.544s/it]: train_loss_raw=0.2027, running_loss=0.2967, LR=0.000100
[2025-08-11 19:52:38,514][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051348] [Batch 02658/04869] [00:24:07/00:20:03, 0.544s/it]: train_loss_raw=0.3047, running_loss=0.2949, LR=0.000100
[2025-08-11 19:52:45,018][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051360] [Batch 02670/04869] [00:24:13/00:19:57, 0.544s/it]: train_loss_raw=0.2966, running_loss=0.2924, LR=0.000100
[2025-08-11 19:52:51,533][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051372] [Batch 02682/04869] [00:24:20/00:19:50, 0.544s/it]: train_loss_raw=0.3160, running_loss=0.2941, LR=0.000100
[2025-08-11 19:52:58,046][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051384] [Batch 02694/04869] [00:24:26/00:19:44, 0.544s/it]: train_loss_raw=0.3620, running_loss=0.2939, LR=0.000100
[2025-08-11 19:53:04,561][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051396] [Batch 02706/04869] [00:24:33/00:19:37, 0.544s/it]: train_loss_raw=0.3286, running_loss=0.2945, LR=0.000100
[2025-08-11 19:53:11,081][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051408] [Batch 02718/04869] [00:24:39/00:19:30, 0.544s/it]: train_loss_raw=0.3145, running_loss=0.2940, LR=0.000100
[2025-08-11 19:53:17,592][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051420] [Batch 02730/04869] [00:24:46/00:19:24, 0.544s/it]: train_loss_raw=0.2956, running_loss=0.2932, LR=0.000100
[2025-08-11 19:53:24,061][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051432] [Batch 02742/04869] [00:24:52/00:19:17, 0.544s/it]: train_loss_raw=0.3428, running_loss=0.2924, LR=0.000100
[2025-08-11 19:53:30,502][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051444] [Batch 02754/04869] [00:24:59/00:19:11, 0.544s/it]: train_loss_raw=0.2985, running_loss=0.2927, LR=0.000100
[2025-08-11 19:53:37,041][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051456] [Batch 02766/04869] [00:25:05/00:19:04, 0.544s/it]: train_loss_raw=0.3629, running_loss=0.2944, LR=0.000100
[2025-08-11 19:53:43,604][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051468] [Batch 02778/04869] [00:25:12/00:18:58, 0.544s/it]: train_loss_raw=0.3226, running_loss=0.2956, LR=0.000100
[2025-08-11 19:53:50,001][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051480] [Batch 02790/04869] [00:25:18/00:18:51, 0.544s/it]: train_loss_raw=0.3316, running_loss=0.2962, LR=0.000100
[2025-08-11 19:53:56,523][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051492] [Batch 02802/04869] [00:25:25/00:18:45, 0.544s/it]: train_loss_raw=0.2378, running_loss=0.2964, LR=0.000100
[2025-08-11 19:54:03,066][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051504] [Batch 02814/04869] [00:25:31/00:18:38, 0.544s/it]: train_loss_raw=0.3796, running_loss=0.2986, LR=0.000100
[2025-08-11 19:54:09,590][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051516] [Batch 02826/04869] [00:25:38/00:18:31, 0.544s/it]: train_loss_raw=0.3342, running_loss=0.2986, LR=0.000100
[2025-08-11 19:54:16,118][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051528] [Batch 02838/04869] [00:25:44/00:18:25, 0.544s/it]: train_loss_raw=0.2455, running_loss=0.2997, LR=0.000100
[2025-08-11 19:54:22,629][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051540] [Batch 02850/04869] [00:25:51/00:18:18, 0.544s/it]: train_loss_raw=0.2703, running_loss=0.2995, LR=0.000100
[2025-08-11 19:54:29,053][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051552] [Batch 02862/04869] [00:25:57/00:18:12, 0.544s/it]: train_loss_raw=0.4033, running_loss=0.2978, LR=0.000100
[2025-08-11 19:54:35,507][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051564] [Batch 02874/04869] [00:26:04/00:18:05, 0.544s/it]: train_loss_raw=0.2886, running_loss=0.2987, LR=0.000100
[2025-08-11 19:54:42,037][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051576] [Batch 02886/04869] [00:26:10/00:17:59, 0.544s/it]: train_loss_raw=0.2371, running_loss=0.2974, LR=0.000100
[2025-08-11 19:54:48,524][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051588] [Batch 02898/04869] [00:26:17/00:17:52, 0.544s/it]: train_loss_raw=0.2813, running_loss=0.2969, LR=0.000100
[2025-08-11 19:54:55,074][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051600] [Batch 02910/04869] [00:26:23/00:17:46, 0.544s/it]: train_loss_raw=0.3407, running_loss=0.2955, LR=0.000100
[2025-08-11 19:55:01,516][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051612] [Batch 02922/04869] [00:26:30/00:17:39, 0.544s/it]: train_loss_raw=0.2005, running_loss=0.2935, LR=0.000100
[2025-08-11 19:55:08,012][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051624] [Batch 02934/04869] [00:26:36/00:17:32, 0.544s/it]: train_loss_raw=0.3700, running_loss=0.2944, LR=0.000100
[2025-08-11 19:55:14,563][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051636] [Batch 02946/04869] [00:26:43/00:17:26, 0.544s/it]: train_loss_raw=0.3207, running_loss=0.2952, LR=0.000100
[2025-08-11 19:55:21,004][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051648] [Batch 02958/04869] [00:26:49/00:17:19, 0.544s/it]: train_loss_raw=0.3167, running_loss=0.2959, LR=0.000100
[2025-08-11 19:55:27,505][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051660] [Batch 02970/04869] [00:26:56/00:17:13, 0.544s/it]: train_loss_raw=0.2486, running_loss=0.2956, LR=0.000100
[2025-08-11 19:55:33,981][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051672] [Batch 02982/04869] [00:27:02/00:17:06, 0.544s/it]: train_loss_raw=0.2029, running_loss=0.2932, LR=0.000100
[2025-08-11 19:55:40,486][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051684] [Batch 02994/04869] [00:27:09/00:17:00, 0.544s/it]: train_loss_raw=0.2782, running_loss=0.2920, LR=0.000100
[2025-08-11 19:55:47,035][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051696] [Batch 03006/04869] [00:27:15/00:16:53, 0.544s/it]: train_loss_raw=0.2959, running_loss=0.2900, LR=0.000100
[2025-08-11 19:55:53,503][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051708] [Batch 03018/04869] [00:27:22/00:16:47, 0.544s/it]: train_loss_raw=0.2443, running_loss=0.2903, LR=0.000100
[2025-08-11 19:55:59,993][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051720] [Batch 03030/04869] [00:27:28/00:16:40, 0.544s/it]: train_loss_raw=0.2703, running_loss=0.2890, LR=0.000100
[2025-08-11 19:56:06,636][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051732] [Batch 03042/04869] [00:27:35/00:16:34, 0.544s/it]: train_loss_raw=0.2376, running_loss=0.2908, LR=0.000100
[2025-08-11 19:56:13,097][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051744] [Batch 03054/04869] [00:27:41/00:16:27, 0.544s/it]: train_loss_raw=0.2744, running_loss=0.2915, LR=0.000100
[2025-08-11 19:56:19,547][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051756] [Batch 03066/04869] [00:27:48/00:16:20, 0.544s/it]: train_loss_raw=0.3005, running_loss=0.2907, LR=0.000100
[2025-08-11 19:56:26,178][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051768] [Batch 03078/04869] [00:27:54/00:16:14, 0.544s/it]: train_loss_raw=0.3707, running_loss=0.2897, LR=0.000100
[2025-08-11 19:56:32,746][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051780] [Batch 03090/04869] [00:28:01/00:16:07, 0.544s/it]: train_loss_raw=0.2693, running_loss=0.2909, LR=0.000100
[2025-08-11 19:56:39,293][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051792] [Batch 03102/04869] [00:28:07/00:16:01, 0.544s/it]: train_loss_raw=0.3455, running_loss=0.2931, LR=0.000100
[2025-08-11 19:56:45,726][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051804] [Batch 03114/04869] [00:28:14/00:15:54, 0.544s/it]: train_loss_raw=0.3143, running_loss=0.2924, LR=0.000100
[2025-08-11 19:56:52,241][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051816] [Batch 03126/04869] [00:28:20/00:15:48, 0.544s/it]: train_loss_raw=0.2502, running_loss=0.2911, LR=0.000100
[2025-08-11 19:56:58,666][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051828] [Batch 03138/04869] [00:28:27/00:15:41, 0.544s/it]: train_loss_raw=0.2848, running_loss=0.2890, LR=0.000100
[2025-08-11 19:57:05,165][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051840] [Batch 03150/04869] [00:28:33/00:15:35, 0.544s/it]: train_loss_raw=0.2399, running_loss=0.2862, LR=0.000100
[2025-08-11 19:57:11,705][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051852] [Batch 03162/04869] [00:28:40/00:15:28, 0.544s/it]: train_loss_raw=0.2964, running_loss=0.2875, LR=0.000100
[2025-08-11 19:57:18,205][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051864] [Batch 03174/04869] [00:28:46/00:15:22, 0.544s/it]: train_loss_raw=0.3379, running_loss=0.2892, LR=0.000100
[2025-08-11 19:57:24,780][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051876] [Batch 03186/04869] [00:28:53/00:15:15, 0.544s/it]: train_loss_raw=0.3223, running_loss=0.2907, LR=0.000100
[2025-08-11 19:57:31,344][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051888] [Batch 03198/04869] [00:28:59/00:15:09, 0.544s/it]: train_loss_raw=0.2958, running_loss=0.2905, LR=0.000100
[2025-08-11 19:57:37,850][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051900] [Batch 03210/04869] [00:29:06/00:15:02, 0.544s/it]: train_loss_raw=0.3345, running_loss=0.2918, LR=0.000100
[2025-08-11 19:57:44,374][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051912] [Batch 03222/04869] [00:29:12/00:14:56, 0.544s/it]: train_loss_raw=0.3002, running_loss=0.2902, LR=0.000100
[2025-08-11 19:57:50,875][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051924] [Batch 03234/04869] [00:29:19/00:14:49, 0.544s/it]: train_loss_raw=0.3228, running_loss=0.2903, LR=0.000100
[2025-08-11 19:57:57,400][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051936] [Batch 03246/04869] [00:29:25/00:14:42, 0.544s/it]: train_loss_raw=0.2379, running_loss=0.2901, LR=0.000100
[2025-08-11 19:58:03,860][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051948] [Batch 03258/04869] [00:29:32/00:14:36, 0.544s/it]: train_loss_raw=0.2462, running_loss=0.2918, LR=0.000100
[2025-08-11 19:58:10,398][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051960] [Batch 03270/04869] [00:29:38/00:14:29, 0.544s/it]: train_loss_raw=0.3011, running_loss=0.2928, LR=0.000100
[2025-08-11 19:58:16,906][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051972] [Batch 03282/04869] [00:29:45/00:14:23, 0.544s/it]: train_loss_raw=0.2654, running_loss=0.2926, LR=0.000100
[2025-08-11 19:58:23,482][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051984] [Batch 03294/04869] [00:29:52/00:14:16, 0.544s/it]: train_loss_raw=0.2646, running_loss=0.2915, LR=0.000100
[2025-08-11 19:58:29,968][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 051996] [Batch 03306/04869] [00:29:58/00:14:10, 0.544s/it]: train_loss_raw=0.3187, running_loss=0.2931, LR=0.000100
[2025-08-11 19:58:41,676][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052008] [Batch 03318/04869] [00:30:10/00:14:06, 0.546s/it]: train_loss_raw=0.3492, running_loss=0.2934, LR=0.000100
[2025-08-11 19:58:48,289][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052020] [Batch 03330/04869] [00:30:16/00:13:59, 0.546s/it]: train_loss_raw=0.3277, running_loss=0.2965, LR=0.000100
[2025-08-11 19:58:54,749][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052032] [Batch 03342/04869] [00:30:23/00:13:53, 0.546s/it]: train_loss_raw=0.2827, running_loss=0.2991, LR=0.000100
[2025-08-11 19:59:01,239][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052044] [Batch 03354/04869] [00:30:29/00:13:46, 0.546s/it]: train_loss_raw=0.3304, running_loss=0.2996, LR=0.000100
[2025-08-11 19:59:07,768][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052056] [Batch 03366/04869] [00:30:36/00:13:39, 0.546s/it]: train_loss_raw=0.3076, running_loss=0.2985, LR=0.000100
[2025-08-11 19:59:14,288][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052068] [Batch 03378/04869] [00:30:42/00:13:33, 0.546s/it]: train_loss_raw=0.2992, running_loss=0.2981, LR=0.000100
[2025-08-11 19:59:20,801][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052080] [Batch 03390/04869] [00:30:49/00:13:26, 0.546s/it]: train_loss_raw=0.2102, running_loss=0.2953, LR=0.000100
[2025-08-11 19:59:27,305][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052092] [Batch 03402/04869] [00:30:55/00:13:20, 0.546s/it]: train_loss_raw=0.2455, running_loss=0.2947, LR=0.000100
[2025-08-11 19:59:33,866][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052104] [Batch 03414/04869] [00:31:02/00:13:13, 0.546s/it]: train_loss_raw=0.1914, running_loss=0.2959, LR=0.000100
[2025-08-11 19:59:40,432][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052116] [Batch 03426/04869] [00:31:08/00:13:07, 0.546s/it]: train_loss_raw=0.2705, running_loss=0.2957, LR=0.000100
[2025-08-11 19:59:46,864][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052128] [Batch 03438/04869] [00:31:15/00:13:00, 0.545s/it]: train_loss_raw=0.2474, running_loss=0.2946, LR=0.000100
[2025-08-11 19:59:53,295][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052140] [Batch 03450/04869] [00:31:21/00:12:54, 0.545s/it]: train_loss_raw=0.3414, running_loss=0.2966, LR=0.000100
[2025-08-11 19:59:59,787][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052152] [Batch 03462/04869] [00:31:28/00:12:47, 0.545s/it]: train_loss_raw=0.3625, running_loss=0.2979, LR=0.000100
[2025-08-11 20:00:06,318][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052164] [Batch 03474/04869] [00:31:34/00:12:40, 0.545s/it]: train_loss_raw=0.2476, running_loss=0.2976, LR=0.000100
[2025-08-11 20:00:12,799][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052176] [Batch 03486/04869] [00:31:41/00:12:34, 0.545s/it]: train_loss_raw=0.2638, running_loss=0.2977, LR=0.000100
[2025-08-11 20:00:19,335][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052188] [Batch 03498/04869] [00:31:47/00:12:27, 0.545s/it]: train_loss_raw=0.3110, running_loss=0.2945, LR=0.000100
[2025-08-11 20:00:25,863][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052200] [Batch 03510/04869] [00:31:54/00:12:21, 0.545s/it]: train_loss_raw=0.3830, running_loss=0.2962, LR=0.000100
[2025-08-11 20:00:32,402][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052212] [Batch 03522/04869] [00:32:00/00:12:14, 0.545s/it]: train_loss_raw=0.2954, running_loss=0.2978, LR=0.000100
[2025-08-11 20:00:38,804][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052224] [Batch 03534/04869] [00:32:07/00:12:08, 0.545s/it]: train_loss_raw=0.3322, running_loss=0.3007, LR=0.000100
[2025-08-11 20:00:45,335][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052236] [Batch 03546/04869] [00:32:13/00:12:01, 0.545s/it]: train_loss_raw=0.3559, running_loss=0.3010, LR=0.000100
[2025-08-11 20:00:51,913][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052248] [Batch 03558/04869] [00:32:20/00:11:54, 0.545s/it]: train_loss_raw=0.2902, running_loss=0.2982, LR=0.000100
[2025-08-11 20:00:58,389][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052260] [Batch 03570/04869] [00:32:26/00:11:48, 0.545s/it]: train_loss_raw=0.3455, running_loss=0.2985, LR=0.000100
[2025-08-11 20:01:04,902][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052272] [Batch 03582/04869] [00:32:33/00:11:41, 0.545s/it]: train_loss_raw=0.2671, running_loss=0.2976, LR=0.000100
[2025-08-11 20:01:11,380][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052284] [Batch 03594/04869] [00:32:39/00:11:35, 0.545s/it]: train_loss_raw=0.2945, running_loss=0.2993, LR=0.000100
[2025-08-11 20:01:18,003][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052296] [Batch 03606/04869] [00:32:46/00:11:28, 0.545s/it]: train_loss_raw=0.2999, running_loss=0.2988, LR=0.000100
[2025-08-11 20:01:24,517][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052308] [Batch 03618/04869] [00:32:53/00:11:22, 0.545s/it]: train_loss_raw=0.2154, running_loss=0.2972, LR=0.000100
[2025-08-11 20:01:31,084][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052320] [Batch 03630/04869] [00:32:59/00:11:15, 0.545s/it]: train_loss_raw=0.3353, running_loss=0.2961, LR=0.000100
[2025-08-11 20:01:37,589][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052332] [Batch 03642/04869] [00:33:06/00:11:09, 0.545s/it]: train_loss_raw=0.4031, running_loss=0.2951, LR=0.000100
[2025-08-11 20:01:44,120][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052344] [Batch 03654/04869] [00:33:12/00:11:02, 0.545s/it]: train_loss_raw=0.2857, running_loss=0.2964, LR=0.000100
[2025-08-11 20:01:50,593][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052356] [Batch 03666/04869] [00:33:19/00:10:56, 0.545s/it]: train_loss_raw=0.2951, running_loss=0.2966, LR=0.000100
[2025-08-11 20:01:56,978][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052368] [Batch 03678/04869] [00:33:25/00:10:49, 0.545s/it]: train_loss_raw=0.3397, running_loss=0.2946, LR=0.000100
[2025-08-11 20:02:03,454][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052380] [Batch 03690/04869] [00:33:31/00:10:42, 0.545s/it]: train_loss_raw=0.2982, running_loss=0.2923, LR=0.000100
[2025-08-11 20:02:09,913][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052392] [Batch 03702/04869] [00:33:38/00:10:36, 0.545s/it]: train_loss_raw=0.2759, running_loss=0.2927, LR=0.000100
[2025-08-11 20:02:16,430][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052404] [Batch 03714/04869] [00:33:44/00:10:29, 0.545s/it]: train_loss_raw=0.3174, running_loss=0.2906, LR=0.000100
[2025-08-11 20:02:22,897][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052416] [Batch 03726/04869] [00:33:51/00:10:23, 0.545s/it]: train_loss_raw=0.3495, running_loss=0.2925, LR=0.000100
[2025-08-11 20:02:29,441][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052428] [Batch 03738/04869] [00:33:57/00:10:16, 0.545s/it]: train_loss_raw=0.2456, running_loss=0.2934, LR=0.000100
[2025-08-11 20:02:35,925][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052440] [Batch 03750/04869] [00:34:04/00:10:10, 0.545s/it]: train_loss_raw=0.3391, running_loss=0.2950, LR=0.000100
[2025-08-11 20:02:42,342][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052452] [Batch 03762/04869] [00:34:10/00:10:03, 0.545s/it]: train_loss_raw=0.2969, running_loss=0.2958, LR=0.000100
[2025-08-11 20:02:48,842][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052464] [Batch 03774/04869] [00:34:17/00:09:56, 0.545s/it]: train_loss_raw=0.4091, running_loss=0.2979, LR=0.000100
[2025-08-11 20:02:55,274][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052476] [Batch 03786/04869] [00:34:23/00:09:50, 0.545s/it]: train_loss_raw=0.3586, running_loss=0.2987, LR=0.000100
[2025-08-11 20:03:01,730][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052488] [Batch 03798/04869] [00:34:30/00:09:43, 0.545s/it]: train_loss_raw=0.2726, running_loss=0.2961, LR=0.000100
[2025-08-11 20:03:08,173][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052500] [Batch 03810/04869] [00:34:36/00:09:37, 0.545s/it]: train_loss_raw=0.3400, running_loss=0.2976, LR=0.000100
[2025-08-11 20:03:14,722][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052512] [Batch 03822/04869] [00:34:43/00:09:30, 0.545s/it]: train_loss_raw=0.2725, running_loss=0.2982, LR=0.000100
[2025-08-11 20:03:21,183][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052524] [Batch 03834/04869] [00:34:49/00:09:24, 0.545s/it]: train_loss_raw=0.2857, running_loss=0.2986, LR=0.000100
[2025-08-11 20:03:27,668][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052536] [Batch 03846/04869] [00:34:56/00:09:17, 0.545s/it]: train_loss_raw=0.2821, running_loss=0.2982, LR=0.000100
[2025-08-11 20:03:34,131][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052548] [Batch 03858/04869] [00:35:02/00:09:11, 0.545s/it]: train_loss_raw=0.2687, running_loss=0.2983, LR=0.000100
[2025-08-11 20:03:40,622][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052560] [Batch 03870/04869] [00:35:09/00:09:04, 0.545s/it]: train_loss_raw=0.3138, running_loss=0.3002, LR=0.000100
[2025-08-11 20:03:47,118][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052572] [Batch 03882/04869] [00:35:15/00:08:57, 0.545s/it]: train_loss_raw=0.2680, running_loss=0.3009, LR=0.000100
[2025-08-11 20:03:53,633][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052584] [Batch 03894/04869] [00:35:22/00:08:51, 0.545s/it]: train_loss_raw=0.2933, running_loss=0.3038, LR=0.000100
[2025-08-11 20:04:00,135][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052596] [Batch 03906/04869] [00:35:28/00:08:44, 0.545s/it]: train_loss_raw=0.3175, running_loss=0.3043, LR=0.000100
[2025-08-11 20:04:06,698][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052608] [Batch 03918/04869] [00:35:35/00:08:38, 0.545s/it]: train_loss_raw=0.2832, running_loss=0.3023, LR=0.000100
[2025-08-11 20:04:13,211][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052620] [Batch 03930/04869] [00:35:41/00:08:31, 0.545s/it]: train_loss_raw=0.3004, running_loss=0.3006, LR=0.000100
[2025-08-11 20:04:19,804][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052632] [Batch 03942/04869] [00:35:48/00:08:25, 0.545s/it]: train_loss_raw=0.3400, running_loss=0.2990, LR=0.000100
[2025-08-11 20:04:26,302][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052644] [Batch 03954/04869] [00:35:54/00:08:18, 0.545s/it]: train_loss_raw=0.2717, running_loss=0.2998, LR=0.000100
[2025-08-11 20:04:32,711][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052656] [Batch 03966/04869] [00:36:01/00:08:12, 0.545s/it]: train_loss_raw=0.2988, running_loss=0.3001, LR=0.000100
[2025-08-11 20:04:39,243][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052668] [Batch 03978/04869] [00:36:07/00:08:05, 0.545s/it]: train_loss_raw=0.2832, running_loss=0.3003, LR=0.000100
[2025-08-11 20:04:45,743][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052680] [Batch 03990/04869] [00:36:14/00:07:58, 0.545s/it]: train_loss_raw=0.2787, running_loss=0.2986, LR=0.000100
[2025-08-11 20:04:52,229][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052692] [Batch 04002/04869] [00:36:20/00:07:52, 0.545s/it]: train_loss_raw=0.1974, running_loss=0.2976, LR=0.000100
[2025-08-11 20:04:58,679][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052704] [Batch 04014/04869] [00:36:27/00:07:45, 0.545s/it]: train_loss_raw=0.2040, running_loss=0.2985, LR=0.000100
[2025-08-11 20:05:05,206][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052716] [Batch 04026/04869] [00:36:33/00:07:39, 0.545s/it]: train_loss_raw=0.2493, running_loss=0.2972, LR=0.000100
[2025-08-11 20:05:11,656][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052728] [Batch 04038/04869] [00:36:40/00:07:32, 0.545s/it]: train_loss_raw=0.2533, running_loss=0.2931, LR=0.000100
[2025-08-11 20:05:18,149][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052740] [Batch 04050/04869] [00:36:46/00:07:26, 0.545s/it]: train_loss_raw=0.3409, running_loss=0.2928, LR=0.000100
[2025-08-11 20:05:24,681][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052752] [Batch 04062/04869] [00:36:53/00:07:19, 0.545s/it]: train_loss_raw=0.2951, running_loss=0.2928, LR=0.000100
[2025-08-11 20:05:31,179][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052764] [Batch 04074/04869] [00:36:59/00:07:13, 0.545s/it]: train_loss_raw=0.2393, running_loss=0.2909, LR=0.000100
[2025-08-11 20:05:37,643][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052776] [Batch 04086/04869] [00:37:06/00:07:06, 0.545s/it]: train_loss_raw=0.3128, running_loss=0.2919, LR=0.000100
[2025-08-11 20:05:44,121][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052788] [Batch 04098/04869] [00:37:12/00:07:00, 0.545s/it]: train_loss_raw=0.3910, running_loss=0.2916, LR=0.000100
[2025-08-11 20:05:50,603][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052800] [Batch 04110/04869] [00:37:19/00:06:53, 0.545s/it]: train_loss_raw=0.2666, running_loss=0.2926, LR=0.000100
[2025-08-11 20:05:57,035][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052812] [Batch 04122/04869] [00:37:25/00:06:46, 0.545s/it]: train_loss_raw=0.4045, running_loss=0.2960, LR=0.000100
[2025-08-11 20:06:03,503][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052824] [Batch 04134/04869] [00:37:32/00:06:40, 0.545s/it]: train_loss_raw=0.2573, running_loss=0.2954, LR=0.000100
[2025-08-11 20:06:09,986][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052836] [Batch 04146/04869] [00:37:38/00:06:33, 0.545s/it]: train_loss_raw=0.2802, running_loss=0.2951, LR=0.000100
[2025-08-11 20:06:16,449][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052848] [Batch 04158/04869] [00:37:44/00:06:27, 0.545s/it]: train_loss_raw=0.4014, running_loss=0.2974, LR=0.000100
[2025-08-11 20:06:22,907][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052860] [Batch 04170/04869] [00:37:51/00:06:20, 0.545s/it]: train_loss_raw=0.2699, running_loss=0.2950, LR=0.000100
[2025-08-11 20:06:29,456][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052872] [Batch 04182/04869] [00:37:57/00:06:14, 0.545s/it]: train_loss_raw=0.2847, running_loss=0.2943, LR=0.000100
[2025-08-11 20:06:36,001][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052884] [Batch 04194/04869] [00:38:04/00:06:07, 0.545s/it]: train_loss_raw=0.2524, running_loss=0.2939, LR=0.000100
[2025-08-11 20:06:42,537][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052896] [Batch 04206/04869] [00:38:11/00:06:01, 0.545s/it]: train_loss_raw=0.3196, running_loss=0.2953, LR=0.000100
[2025-08-11 20:06:48,988][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052908] [Batch 04218/04869] [00:38:17/00:05:54, 0.545s/it]: train_loss_raw=0.2869, running_loss=0.2952, LR=0.000100
[2025-08-11 20:06:55,470][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052920] [Batch 04230/04869] [00:38:24/00:05:48, 0.545s/it]: train_loss_raw=0.2248, running_loss=0.2923, LR=0.000100
[2025-08-11 20:07:01,981][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052932] [Batch 04242/04869] [00:38:30/00:05:41, 0.545s/it]: train_loss_raw=0.3555, running_loss=0.2920, LR=0.000100
[2025-08-11 20:07:08,492][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052944] [Batch 04254/04869] [00:38:37/00:05:34, 0.545s/it]: train_loss_raw=0.2979, running_loss=0.2904, LR=0.000100
[2025-08-11 20:07:14,897][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052956] [Batch 04266/04869] [00:38:43/00:05:28, 0.545s/it]: train_loss_raw=0.2788, running_loss=0.2896, LR=0.000100
[2025-08-11 20:07:21,417][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052968] [Batch 04278/04869] [00:38:49/00:05:21, 0.545s/it]: train_loss_raw=0.3755, running_loss=0.2899, LR=0.000100
[2025-08-11 20:07:27,943][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052980] [Batch 04290/04869] [00:38:56/00:05:15, 0.545s/it]: train_loss_raw=0.3969, running_loss=0.2925, LR=0.000100
[2025-08-11 20:07:34,514][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 052992] [Batch 04302/04869] [00:39:03/00:05:08, 0.545s/it]: train_loss_raw=0.2889, running_loss=0.2920, LR=0.000100
[2025-08-11 20:07:40,970][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053004] [Batch 04314/04869] [00:39:09/00:05:02, 0.545s/it]: train_loss_raw=0.2122, running_loss=0.2906, LR=0.000100
[2025-08-11 20:07:47,485][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053016] [Batch 04326/04869] [00:39:16/00:04:55, 0.545s/it]: train_loss_raw=0.3987, running_loss=0.2967, LR=0.000100
[2025-08-11 20:07:54,112][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053028] [Batch 04338/04869] [00:39:22/00:04:49, 0.545s/it]: train_loss_raw=0.2963, running_loss=0.2981, LR=0.000100
[2025-08-11 20:08:00,573][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053040] [Batch 04350/04869] [00:39:29/00:04:42, 0.545s/it]: train_loss_raw=0.3337, running_loss=0.2976, LR=0.000100
[2025-08-11 20:08:07,082][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053052] [Batch 04362/04869] [00:39:35/00:04:36, 0.545s/it]: train_loss_raw=0.3284, running_loss=0.2966, LR=0.000100
[2025-08-11 20:08:13,711][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053064] [Batch 04374/04869] [00:39:42/00:04:29, 0.545s/it]: train_loss_raw=0.3449, running_loss=0.2966, LR=0.000100
[2025-08-11 20:08:20,162][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053076] [Batch 04386/04869] [00:39:48/00:04:23, 0.545s/it]: train_loss_raw=0.2918, running_loss=0.2982, LR=0.000100
[2025-08-11 20:08:26,850][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053088] [Batch 04398/04869] [00:39:55/00:04:16, 0.545s/it]: train_loss_raw=0.2903, running_loss=0.2974, LR=0.000100
[2025-08-11 20:08:33,397][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053100] [Batch 04410/04869] [00:40:01/00:04:09, 0.545s/it]: train_loss_raw=0.2959, running_loss=0.2975, LR=0.000100
[2025-08-11 20:08:39,880][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053112] [Batch 04422/04869] [00:40:08/00:04:03, 0.545s/it]: train_loss_raw=0.3935, running_loss=0.2973, LR=0.000100
[2025-08-11 20:08:46,265][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053124] [Batch 04434/04869] [00:40:14/00:03:56, 0.545s/it]: train_loss_raw=0.3445, running_loss=0.2968, LR=0.000100
[2025-08-11 20:08:52,765][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053136] [Batch 04446/04869] [00:40:21/00:03:50, 0.545s/it]: train_loss_raw=0.2153, running_loss=0.2962, LR=0.000100
[2025-08-11 20:08:59,279][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053148] [Batch 04458/04869] [00:40:27/00:03:43, 0.545s/it]: train_loss_raw=0.2641, running_loss=0.2938, LR=0.000100
[2025-08-11 20:09:05,871][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053160] [Batch 04470/04869] [00:40:34/00:03:37, 0.545s/it]: train_loss_raw=0.2698, running_loss=0.2938, LR=0.000100
[2025-08-11 20:09:12,506][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053172] [Batch 04482/04869] [00:40:41/00:03:30, 0.545s/it]: train_loss_raw=0.3227, running_loss=0.2947, LR=0.000100
[2025-08-11 20:09:19,054][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053184] [Batch 04494/04869] [00:40:47/00:03:24, 0.545s/it]: train_loss_raw=0.2574, running_loss=0.2930, LR=0.000100
[2025-08-11 20:09:25,535][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053196] [Batch 04506/04869] [00:40:54/00:03:17, 0.545s/it]: train_loss_raw=0.3102, running_loss=0.2940, LR=0.000100
[2025-08-11 20:09:32,063][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053208] [Batch 04518/04869] [00:41:00/00:03:11, 0.545s/it]: train_loss_raw=0.3599, running_loss=0.2930, LR=0.000100
[2025-08-11 20:09:38,540][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053220] [Batch 04530/04869] [00:41:07/00:03:04, 0.545s/it]: train_loss_raw=0.3434, running_loss=0.2919, LR=0.000100
[2025-08-11 20:09:45,115][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053232] [Batch 04542/04869] [00:41:13/00:02:58, 0.545s/it]: train_loss_raw=0.3427, running_loss=0.2924, LR=0.000100
[2025-08-11 20:09:51,586][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053244] [Batch 04554/04869] [00:41:20/00:02:51, 0.545s/it]: train_loss_raw=0.3496, running_loss=0.2955, LR=0.000100
[2025-08-11 20:09:58,009][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053256] [Batch 04566/04869] [00:41:26/00:02:45, 0.545s/it]: train_loss_raw=0.3442, running_loss=0.2997, LR=0.000100
[2025-08-11 20:10:04,493][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053268] [Batch 04578/04869] [00:41:33/00:02:38, 0.545s/it]: train_loss_raw=0.3553, running_loss=0.2962, LR=0.000100
[2025-08-11 20:10:11,034][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053280] [Batch 04590/04869] [00:41:39/00:02:31, 0.545s/it]: train_loss_raw=0.3051, running_loss=0.2965, LR=0.000100
[2025-08-11 20:10:17,548][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053292] [Batch 04602/04869] [00:41:46/00:02:25, 0.545s/it]: train_loss_raw=0.3308, running_loss=0.2951, LR=0.000100
[2025-08-11 20:10:24,077][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053304] [Batch 04614/04869] [00:41:52/00:02:18, 0.545s/it]: train_loss_raw=0.3035, running_loss=0.2945, LR=0.000100
[2025-08-11 20:10:30,641][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053316] [Batch 04626/04869] [00:41:59/00:02:12, 0.545s/it]: train_loss_raw=0.2868, running_loss=0.2956, LR=0.000100
[2025-08-11 20:10:37,218][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053328] [Batch 04638/04869] [00:42:05/00:02:05, 0.545s/it]: train_loss_raw=0.3276, running_loss=0.2937, LR=0.000100
[2025-08-11 20:10:43,733][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053340] [Batch 04650/04869] [00:42:12/00:01:59, 0.545s/it]: train_loss_raw=0.2697, running_loss=0.2931, LR=0.000100
[2025-08-11 20:10:50,247][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053352] [Batch 04662/04869] [00:42:18/00:01:52, 0.545s/it]: train_loss_raw=0.2043, running_loss=0.2938, LR=0.000100
[2025-08-11 20:10:56,789][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053364] [Batch 04674/04869] [00:42:25/00:01:46, 0.545s/it]: train_loss_raw=0.2740, running_loss=0.2936, LR=0.000100
[2025-08-11 20:11:03,256][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053376] [Batch 04686/04869] [00:42:31/00:01:39, 0.545s/it]: train_loss_raw=0.3015, running_loss=0.2932, LR=0.000100
[2025-08-11 20:11:09,689][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053388] [Batch 04698/04869] [00:42:38/00:01:33, 0.545s/it]: train_loss_raw=0.3635, running_loss=0.2954, LR=0.000100
[2025-08-11 20:11:16,172][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053400] [Batch 04710/04869] [00:42:44/00:01:26, 0.545s/it]: train_loss_raw=0.3245, running_loss=0.2961, LR=0.000100
[2025-08-11 20:11:22,647][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053412] [Batch 04722/04869] [00:42:51/00:01:20, 0.545s/it]: train_loss_raw=0.3845, running_loss=0.2964, LR=0.000100
[2025-08-11 20:11:29,211][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053424] [Batch 04734/04869] [00:42:57/00:01:13, 0.545s/it]: train_loss_raw=0.2879, running_loss=0.2991, LR=0.000100
[2025-08-11 20:11:35,778][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053436] [Batch 04746/04869] [00:43:04/00:01:06, 0.545s/it]: train_loss_raw=0.2096, running_loss=0.2974, LR=0.000100
[2025-08-11 20:11:42,224][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053448] [Batch 04758/04869] [00:43:10/00:01:00, 0.545s/it]: train_loss_raw=0.3015, running_loss=0.2953, LR=0.000100
[2025-08-11 20:11:48,693][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053460] [Batch 04770/04869] [00:43:17/00:00:53, 0.544s/it]: train_loss_raw=0.3406, running_loss=0.2959, LR=0.000100
[2025-08-11 20:11:55,224][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053472] [Batch 04782/04869] [00:43:23/00:00:47, 0.544s/it]: train_loss_raw=0.3613, running_loss=0.2976, LR=0.000100
[2025-08-11 20:12:01,740][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053484] [Batch 04794/04869] [00:43:30/00:00:40, 0.544s/it]: train_loss_raw=0.3044, running_loss=0.3005, LR=0.000100
[2025-08-11 20:12:08,226][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053496] [Batch 04806/04869] [00:43:36/00:00:34, 0.544s/it]: train_loss_raw=0.3340, running_loss=0.2998, LR=0.000100
[2025-08-11 20:12:14,708][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053508] [Batch 04818/04869] [00:43:43/00:00:27, 0.544s/it]: train_loss_raw=0.2539, running_loss=0.2984, LR=0.000100
[2025-08-11 20:12:21,181][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053520] [Batch 04830/04869] [00:43:49/00:00:21, 0.544s/it]: train_loss_raw=0.3286, running_loss=0.3003, LR=0.000100
[2025-08-11 20:12:27,656][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053532] [Batch 04842/04869] [00:43:56/00:00:14, 0.544s/it]: train_loss_raw=0.2332, running_loss=0.3006, LR=0.000100
[2025-08-11 20:12:34,124][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053544] [Batch 04854/04869] [00:44:02/00:00:08, 0.544s/it]: train_loss_raw=0.2687, running_loss=0.2994, LR=0.000100
[2025-08-11 20:12:40,601][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 053556] [Batch 04866/04869] [00:44:09/00:00:01, 0.544s/it]: train_loss_raw=0.3167, running_loss=0.3004, LR=0.000100
[2025-08-11 20:12:46,730][__main__][INFO] - [VALIDATION] [Epoch 10/29] Starting validation.
[2025-08-11 20:13:01,982][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 053560] [Batch 00011/00062] [00:00:15/00:01:03, 1.271s/it]
[2025-08-11 20:13:36,841][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 053560] [Batch 00023/00062] [00:00:50/00:01:19, 2.088s/it]
[2025-08-11 20:13:52,369][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 053560] [Batch 00035/00062] [00:01:05/00:00:47, 1.823s/it]
[2025-08-11 20:14:07,835][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 053560] [Batch 00047/00062] [00:01:21/00:00:23, 1.690s/it]
[2025-08-11 20:14:23,150][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 053560] [Batch 00059/00062] [00:01:36/00:00:03, 1.607s/it]
[2025-08-11 20:14:25,631][__main__][INFO] - [VALIDATION] [Epoch 10/29] train_loss=0.29901, valid_loss=0.37048
[2025-08-11 20:14:25,632][__main__][INFO] - [VALIDATION] [Epoch 10/29] Metrics:
[2025-08-11 20:14:25,632][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_er      0.188
[2025-08-11 20:14:25,632][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_prec    0.637
[2025-08-11 20:14:25,632][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_recall  0.641
[2025-08-11 20:14:25,632][__main__][INFO] - [VALIDATION] [Epoch 10/29] - pep_recall 0.604
[2025-08-11 20:14:25,637][__main__][INFO] - [TRAIN] [Epoch 10/29] Epoch complete, total time 08:19:04, remaining time 14:22:01, 00:45:22 per epoch
[2025-08-11 20:14:31,628][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053568] [Batch 00009/04869] [00:00:05/00:51:25, 0.635s/it]: train_loss_raw=0.3573, running_loss=0.3793, LR=0.000100
[2025-08-11 20:14:38,023][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053580] [Batch 00021/04869] [00:00:12/00:46:35, 0.577s/it]: train_loss_raw=0.2596, running_loss=0.3687, LR=0.000100
[2025-08-11 20:14:44,533][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053592] [Batch 00033/04869] [00:00:18/00:45:28, 0.564s/it]: train_loss_raw=0.2736, running_loss=0.3598, LR=0.000100
[2025-08-11 20:14:50,958][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053604] [Batch 00045/04869] [00:00:25/00:44:44, 0.557s/it]: train_loss_raw=0.2626, running_loss=0.3499, LR=0.000100
[2025-08-11 20:14:57,520][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053616] [Batch 00057/04869] [00:00:31/00:44:28, 0.554s/it]: train_loss_raw=0.3373, running_loss=0.3420, LR=0.000100
[2025-08-11 20:15:03,980][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053628] [Batch 00069/04869] [00:00:38/00:44:07, 0.552s/it]: train_loss_raw=0.3915, running_loss=0.3383, LR=0.000100
[2025-08-11 20:15:10,468][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053640] [Batch 00081/04869] [00:00:44/00:43:53, 0.550s/it]: train_loss_raw=0.3055, running_loss=0.3332, LR=0.000100
[2025-08-11 20:15:16,926][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053652] [Batch 00093/04869] [00:00:51/00:43:39, 0.549s/it]: train_loss_raw=0.2630, running_loss=0.3285, LR=0.000100
[2025-08-11 20:15:23,404][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053664] [Batch 00105/04869] [00:00:57/00:43:28, 0.548s/it]: train_loss_raw=0.2811, running_loss=0.3254, LR=0.000100
[2025-08-11 20:15:30,009][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053676] [Batch 00117/04869] [00:01:04/00:43:23, 0.548s/it]: train_loss_raw=0.3451, running_loss=0.3214, LR=0.000100
[2025-08-11 20:15:36,520][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053688] [Batch 00129/04869] [00:01:10/00:43:14, 0.547s/it]: train_loss_raw=0.2659, running_loss=0.3178, LR=0.000100
[2025-08-11 20:15:43,001][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053700] [Batch 00141/04869] [00:01:17/00:43:04, 0.547s/it]: train_loss_raw=0.2369, running_loss=0.3177, LR=0.000100
[2025-08-11 20:15:49,478][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053712] [Batch 00153/04869] [00:01:23/00:42:55, 0.546s/it]: train_loss_raw=0.3171, running_loss=0.3143, LR=0.000100
[2025-08-11 20:15:55,965][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053724] [Batch 00165/04869] [00:01:30/00:42:47, 0.546s/it]: train_loss_raw=0.2785, running_loss=0.3090, LR=0.000100
[2025-08-11 20:16:02,493][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053736] [Batch 00177/04869] [00:01:36/00:42:40, 0.546s/it]: train_loss_raw=0.3204, running_loss=0.3108, LR=0.000100
[2025-08-11 20:16:08,896][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053748] [Batch 00189/04869] [00:01:42/00:42:30, 0.545s/it]: train_loss_raw=0.2700, running_loss=0.3056, LR=0.000100
[2025-08-11 20:16:15,352][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053760] [Batch 00201/04869] [00:01:49/00:42:21, 0.544s/it]: train_loss_raw=0.2549, running_loss=0.3045, LR=0.000100
[2025-08-11 20:16:21,793][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053772] [Batch 00213/04869] [00:01:55/00:42:13, 0.544s/it]: train_loss_raw=0.2142, running_loss=0.3007, LR=0.000100
[2025-08-11 20:16:28,265][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053784] [Batch 00225/04869] [00:02:02/00:42:05, 0.544s/it]: train_loss_raw=0.3367, running_loss=0.2998, LR=0.000100
[2025-08-11 20:16:34,661][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053796] [Batch 00237/04869] [00:02:08/00:41:56, 0.543s/it]: train_loss_raw=0.2727, running_loss=0.2978, LR=0.000100
[2025-08-11 20:16:41,159][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053808] [Batch 00249/04869] [00:02:15/00:41:49, 0.543s/it]: train_loss_raw=0.3833, running_loss=0.3013, LR=0.000100
[2025-08-11 20:16:47,565][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053820] [Batch 00261/04869] [00:02:21/00:41:40, 0.543s/it]: train_loss_raw=0.3192, running_loss=0.3039, LR=0.000100
[2025-08-11 20:16:54,036][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053832] [Batch 00273/04869] [00:02:28/00:41:33, 0.543s/it]: train_loss_raw=0.2957, running_loss=0.3032, LR=0.000100
[2025-08-11 20:17:00,610][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053844] [Batch 00285/04869] [00:02:34/00:41:28, 0.543s/it]: train_loss_raw=0.2757, running_loss=0.3047, LR=0.000100
[2025-08-11 20:17:07,122][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053856] [Batch 00297/04869] [00:02:41/00:41:21, 0.543s/it]: train_loss_raw=0.3095, running_loss=0.3030, LR=0.000100
[2025-08-11 20:17:13,552][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053868] [Batch 00309/04869] [00:02:47/00:41:13, 0.543s/it]: train_loss_raw=0.2937, running_loss=0.3020, LR=0.000100
[2025-08-11 20:17:20,083][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053880] [Batch 00321/04869] [00:02:54/00:41:07, 0.543s/it]: train_loss_raw=0.2378, running_loss=0.2991, LR=0.000100
[2025-08-11 20:17:26,624][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053892] [Batch 00333/04869] [00:03:00/00:41:01, 0.543s/it]: train_loss_raw=0.2813, running_loss=0.2992, LR=0.000100
[2025-08-11 20:17:33,058][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053904] [Batch 00345/04869] [00:03:07/00:40:54, 0.542s/it]: train_loss_raw=0.1915, running_loss=0.2978, LR=0.000100
[2025-08-11 20:17:39,504][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053916] [Batch 00357/04869] [00:03:13/00:40:46, 0.542s/it]: train_loss_raw=0.3239, running_loss=0.2972, LR=0.000100
[2025-08-11 20:17:45,955][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053928] [Batch 00369/04869] [00:03:20/00:40:39, 0.542s/it]: train_loss_raw=0.2501, running_loss=0.2965, LR=0.000100
[2025-08-11 20:17:52,411][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053940] [Batch 00381/04869] [00:03:26/00:40:32, 0.542s/it]: train_loss_raw=0.2622, running_loss=0.2932, LR=0.000100
[2025-08-11 20:17:58,918][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053952] [Batch 00393/04869] [00:03:33/00:40:25, 0.542s/it]: train_loss_raw=0.3399, running_loss=0.2936, LR=0.000100
[2025-08-11 20:18:05,450][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053964] [Batch 00405/04869] [00:03:39/00:40:19, 0.542s/it]: train_loss_raw=0.3259, running_loss=0.2951, LR=0.000100
[2025-08-11 20:18:11,872][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053976] [Batch 00417/04869] [00:03:45/00:40:12, 0.542s/it]: train_loss_raw=0.3556, running_loss=0.2940, LR=0.000100
[2025-08-11 20:18:18,328][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 053988] [Batch 00429/04869] [00:03:52/00:40:05, 0.542s/it]: train_loss_raw=0.2822, running_loss=0.2936, LR=0.000100
[2025-08-11 20:18:24,833][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054000] [Batch 00441/04869] [00:03:58/00:39:58, 0.542s/it]: train_loss_raw=0.2858, running_loss=0.2954, LR=0.000100
[2025-08-11 20:18:37,187][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054012] [Batch 00453/04869] [00:04:11/00:40:49, 0.555s/it]: train_loss_raw=0.2599, running_loss=0.2967, LR=0.000100
[2025-08-11 20:18:43,617][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054024] [Batch 00465/04869] [00:04:17/00:40:40, 0.554s/it]: train_loss_raw=0.3518, running_loss=0.2973, LR=0.000100
[2025-08-11 20:18:50,168][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054036] [Batch 00477/04869] [00:04:24/00:40:33, 0.554s/it]: train_loss_raw=0.3284, running_loss=0.2933, LR=0.000100
[2025-08-11 20:18:56,624][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054048] [Batch 00489/04869] [00:04:30/00:40:24, 0.554s/it]: train_loss_raw=0.3127, running_loss=0.2939, LR=0.000100
[2025-08-11 20:19:03,144][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054060] [Batch 00501/04869] [00:04:37/00:40:17, 0.553s/it]: train_loss_raw=0.2091, running_loss=0.2942, LR=0.000100
[2025-08-11 20:19:09,569][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054072] [Batch 00513/04869] [00:04:43/00:40:08, 0.553s/it]: train_loss_raw=0.2668, running_loss=0.2944, LR=0.000100
[2025-08-11 20:19:16,104][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054084] [Batch 00525/04869] [00:04:50/00:40:01, 0.553s/it]: train_loss_raw=0.3450, running_loss=0.2952, LR=0.000100
[2025-08-11 20:19:22,616][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054096] [Batch 00537/04869] [00:04:56/00:39:53, 0.553s/it]: train_loss_raw=0.3487, running_loss=0.2988, LR=0.000100
[2025-08-11 20:19:29,083][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054108] [Batch 00549/04869] [00:05:03/00:39:45, 0.552s/it]: train_loss_raw=0.3270, running_loss=0.3001, LR=0.000100
[2025-08-11 20:19:35,558][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054120] [Batch 00561/04869] [00:05:09/00:39:37, 0.552s/it]: train_loss_raw=0.2506, running_loss=0.3029, LR=0.000100
[2025-08-11 20:19:42,057][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054132] [Batch 00573/04869] [00:05:16/00:39:30, 0.552s/it]: train_loss_raw=0.3180, running_loss=0.3023, LR=0.000100
[2025-08-11 20:19:48,551][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054144] [Batch 00585/04869] [00:05:22/00:39:22, 0.552s/it]: train_loss_raw=0.3334, running_loss=0.3017, LR=0.000100
[2025-08-11 20:19:54,924][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054156] [Batch 00597/04869] [00:05:29/00:39:14, 0.551s/it]: train_loss_raw=0.3354, running_loss=0.2995, LR=0.000100
[2025-08-11 20:20:01,409][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054168] [Batch 00609/04869] [00:05:35/00:39:06, 0.551s/it]: train_loss_raw=0.2574, running_loss=0.3017, LR=0.000100
[2025-08-11 20:20:07,882][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054180] [Batch 00621/04869] [00:05:41/00:38:59, 0.551s/it]: train_loss_raw=0.2538, running_loss=0.3003, LR=0.000100
[2025-08-11 20:20:14,296][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054192] [Batch 00633/04869] [00:05:48/00:38:51, 0.550s/it]: train_loss_raw=0.2732, running_loss=0.2995, LR=0.000100
[2025-08-11 20:20:20,825][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054204] [Batch 00645/04869] [00:05:54/00:38:44, 0.550s/it]: train_loss_raw=0.3276, running_loss=0.2986, LR=0.000100
[2025-08-11 20:20:27,332][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054216] [Batch 00657/04869] [00:06:01/00:38:37, 0.550s/it]: train_loss_raw=0.2735, running_loss=0.2978, LR=0.000100
[2025-08-11 20:20:33,824][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054228] [Batch 00669/04869] [00:06:07/00:38:29, 0.550s/it]: train_loss_raw=0.3807, running_loss=0.2990, LR=0.000100
[2025-08-11 20:20:40,364][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054240] [Batch 00681/04869] [00:06:14/00:38:22, 0.550s/it]: train_loss_raw=0.3304, running_loss=0.2988, LR=0.000100
[2025-08-11 20:20:46,872][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054252] [Batch 00693/04869] [00:06:20/00:38:15, 0.550s/it]: train_loss_raw=0.3002, running_loss=0.2984, LR=0.000100
[2025-08-11 20:20:53,301][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054264] [Batch 00705/04869] [00:06:27/00:38:08, 0.549s/it]: train_loss_raw=0.2845, running_loss=0.2983, LR=0.000100
[2025-08-11 20:20:59,829][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054276] [Batch 00717/04869] [00:06:33/00:38:01, 0.549s/it]: train_loss_raw=0.3064, running_loss=0.2981, LR=0.000100
[2025-08-11 20:21:06,360][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054288] [Batch 00729/04869] [00:06:40/00:37:54, 0.549s/it]: train_loss_raw=0.3279, running_loss=0.2996, LR=0.000100
[2025-08-11 20:21:12,819][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054300] [Batch 00741/04869] [00:06:46/00:37:46, 0.549s/it]: train_loss_raw=0.2643, running_loss=0.2987, LR=0.000100
[2025-08-11 20:21:19,240][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054312] [Batch 00753/04869] [00:06:53/00:37:39, 0.549s/it]: train_loss_raw=0.2128, running_loss=0.2973, LR=0.000100
[2025-08-11 20:21:25,696][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054324] [Batch 00765/04869] [00:06:59/00:37:32, 0.549s/it]: train_loss_raw=0.3307, running_loss=0.2988, LR=0.000100
[2025-08-11 20:21:32,148][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054336] [Batch 00777/04869] [00:07:06/00:37:24, 0.549s/it]: train_loss_raw=0.4012, running_loss=0.2980, LR=0.000100
[2025-08-11 20:21:38,712][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054348] [Batch 00789/04869] [00:07:12/00:37:18, 0.549s/it]: train_loss_raw=0.2874, running_loss=0.2977, LR=0.000100
[2025-08-11 20:21:45,108][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054360] [Batch 00801/04869] [00:07:19/00:37:10, 0.548s/it]: train_loss_raw=0.2712, running_loss=0.2966, LR=0.000100
[2025-08-11 20:21:51,591][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054372] [Batch 00813/04869] [00:07:25/00:37:03, 0.548s/it]: train_loss_raw=0.3349, running_loss=0.2964, LR=0.000100
[2025-08-11 20:21:58,060][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054384] [Batch 00825/04869] [00:07:32/00:36:56, 0.548s/it]: train_loss_raw=0.2911, running_loss=0.2980, LR=0.000100
[2025-08-11 20:22:04,620][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054396] [Batch 00837/04869] [00:07:38/00:36:49, 0.548s/it]: train_loss_raw=0.2643, running_loss=0.2967, LR=0.000100
[2025-08-11 20:22:11,091][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054408] [Batch 00849/04869] [00:07:45/00:36:42, 0.548s/it]: train_loss_raw=0.2235, running_loss=0.2968, LR=0.000100
[2025-08-11 20:22:17,699][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054420] [Batch 00861/04869] [00:07:51/00:36:36, 0.548s/it]: train_loss_raw=0.3151, running_loss=0.2979, LR=0.000100
[2025-08-11 20:22:24,249][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054432] [Batch 00873/04869] [00:07:58/00:36:29, 0.548s/it]: train_loss_raw=0.2773, running_loss=0.3005, LR=0.000100
[2025-08-11 20:22:30,700][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054444] [Batch 00885/04869] [00:08:04/00:36:22, 0.548s/it]: train_loss_raw=0.3335, running_loss=0.3017, LR=0.000100
[2025-08-11 20:22:37,236][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054456] [Batch 00897/04869] [00:08:11/00:36:15, 0.548s/it]: train_loss_raw=0.3017, running_loss=0.3014, LR=0.000100
[2025-08-11 20:22:43,720][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054468] [Batch 00909/04869] [00:08:17/00:36:08, 0.548s/it]: train_loss_raw=0.3530, running_loss=0.3010, LR=0.000100
[2025-08-11 20:22:50,258][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054480] [Batch 00921/04869] [00:08:24/00:36:01, 0.548s/it]: train_loss_raw=0.2900, running_loss=0.3025, LR=0.000100
[2025-08-11 20:22:56,743][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054492] [Batch 00933/04869] [00:08:30/00:35:55, 0.548s/it]: train_loss_raw=0.3310, running_loss=0.3006, LR=0.000100
[2025-08-11 20:23:03,265][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054504] [Batch 00945/04869] [00:08:37/00:35:48, 0.547s/it]: train_loss_raw=0.2897, running_loss=0.2971, LR=0.000100
[2025-08-11 20:23:09,921][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054516] [Batch 00957/04869] [00:08:44/00:35:42, 0.548s/it]: train_loss_raw=0.2724, running_loss=0.2969, LR=0.000100
[2025-08-11 20:23:16,494][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054528] [Batch 00969/04869] [00:08:50/00:35:35, 0.548s/it]: train_loss_raw=0.2306, running_loss=0.2941, LR=0.000100
[2025-08-11 20:23:23,034][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054540] [Batch 00981/04869] [00:08:57/00:35:28, 0.548s/it]: train_loss_raw=0.2237, running_loss=0.2895, LR=0.000100
[2025-08-11 20:23:29,551][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054552] [Batch 00993/04869] [00:09:03/00:35:21, 0.547s/it]: train_loss_raw=0.4785, running_loss=0.2942, LR=0.000100
[2025-08-11 20:23:36,050][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054564] [Batch 01005/04869] [00:09:10/00:35:15, 0.547s/it]: train_loss_raw=0.3266, running_loss=0.2944, LR=0.000100
[2025-08-11 20:23:42,542][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054576] [Batch 01017/04869] [00:09:16/00:35:08, 0.547s/it]: train_loss_raw=0.3151, running_loss=0.2928, LR=0.000100
[2025-08-11 20:23:49,062][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054588] [Batch 01029/04869] [00:09:23/00:35:01, 0.547s/it]: train_loss_raw=0.2527, running_loss=0.2952, LR=0.000100
[2025-08-11 20:23:55,472][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054600] [Batch 01041/04869] [00:09:29/00:34:54, 0.547s/it]: train_loss_raw=0.2984, running_loss=0.2991, LR=0.000100
[2025-08-11 20:24:01,914][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054612] [Batch 01053/04869] [00:09:35/00:34:47, 0.547s/it]: train_loss_raw=0.2674, running_loss=0.2950, LR=0.000100
[2025-08-11 20:24:08,412][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054624] [Batch 01065/04869] [00:09:42/00:34:40, 0.547s/it]: train_loss_raw=0.2938, running_loss=0.2948, LR=0.000100
[2025-08-11 20:24:14,915][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054636] [Batch 01077/04869] [00:09:48/00:34:33, 0.547s/it]: train_loss_raw=0.3136, running_loss=0.2968, LR=0.000100
[2025-08-11 20:24:21,480][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054648] [Batch 01089/04869] [00:09:55/00:34:27, 0.547s/it]: train_loss_raw=0.3340, running_loss=0.2928, LR=0.000100
[2025-08-11 20:24:28,110][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054660] [Batch 01101/04869] [00:10:02/00:34:20, 0.547s/it]: train_loss_raw=0.3376, running_loss=0.2927, LR=0.000100
[2025-08-11 20:24:34,597][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054672] [Batch 01113/04869] [00:10:08/00:34:14, 0.547s/it]: train_loss_raw=0.2921, running_loss=0.2938, LR=0.000100
[2025-08-11 20:24:41,064][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054684] [Batch 01125/04869] [00:10:15/00:34:07, 0.547s/it]: train_loss_raw=0.2956, running_loss=0.2937, LR=0.000100
[2025-08-11 20:24:47,604][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054696] [Batch 01137/04869] [00:10:21/00:34:00, 0.547s/it]: train_loss_raw=0.3896, running_loss=0.2959, LR=0.000100
[2025-08-11 20:24:54,103][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054708] [Batch 01149/04869] [00:10:28/00:33:53, 0.547s/it]: train_loss_raw=0.2141, running_loss=0.2971, LR=0.000100
[2025-08-11 20:25:00,613][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054720] [Batch 01161/04869] [00:10:34/00:33:47, 0.547s/it]: train_loss_raw=0.2392, running_loss=0.2977, LR=0.000100
[2025-08-11 20:25:07,181][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054732] [Batch 01173/04869] [00:10:41/00:33:40, 0.547s/it]: train_loss_raw=0.2994, running_loss=0.2980, LR=0.000100
[2025-08-11 20:25:13,567][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054744] [Batch 01185/04869] [00:10:47/00:33:33, 0.547s/it]: train_loss_raw=0.3182, running_loss=0.2981, LR=0.000100
[2025-08-11 20:25:19,988][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054756] [Batch 01197/04869] [00:10:54/00:33:26, 0.546s/it]: train_loss_raw=0.3363, running_loss=0.2988, LR=0.000100
[2025-08-11 20:25:26,390][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054768] [Batch 01209/04869] [00:11:00/00:33:19, 0.546s/it]: train_loss_raw=0.2237, running_loss=0.2977, LR=0.000100
[2025-08-11 20:25:32,946][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054780] [Batch 01221/04869] [00:11:07/00:33:12, 0.546s/it]: train_loss_raw=0.3094, running_loss=0.2997, LR=0.000100
[2025-08-11 20:25:39,388][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054792] [Batch 01233/04869] [00:11:13/00:33:06, 0.546s/it]: train_loss_raw=0.2290, running_loss=0.2993, LR=0.000100
[2025-08-11 20:25:45,897][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054804] [Batch 01245/04869] [00:11:19/00:32:59, 0.546s/it]: train_loss_raw=0.3220, running_loss=0.2981, LR=0.000100
[2025-08-11 20:25:52,379][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054816] [Batch 01257/04869] [00:11:26/00:32:52, 0.546s/it]: train_loss_raw=0.3751, running_loss=0.2978, LR=0.000100
[2025-08-11 20:25:58,830][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054828] [Batch 01269/04869] [00:11:32/00:32:45, 0.546s/it]: train_loss_raw=0.3395, running_loss=0.2998, LR=0.000100
[2025-08-11 20:26:05,413][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054840] [Batch 01281/04869] [00:11:39/00:32:39, 0.546s/it]: train_loss_raw=0.2625, running_loss=0.2971, LR=0.000100
[2025-08-11 20:26:11,960][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054852] [Batch 01293/04869] [00:11:46/00:32:32, 0.546s/it]: train_loss_raw=0.3515, running_loss=0.2968, LR=0.000100
[2025-08-11 20:26:18,403][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054864] [Batch 01305/04869] [00:11:52/00:32:25, 0.546s/it]: train_loss_raw=0.2826, running_loss=0.2933, LR=0.000100
[2025-08-11 20:26:24,903][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054876] [Batch 01317/04869] [00:11:58/00:32:19, 0.546s/it]: train_loss_raw=0.3763, running_loss=0.2926, LR=0.000100
[2025-08-11 20:26:31,370][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054888] [Batch 01329/04869] [00:12:05/00:32:12, 0.546s/it]: train_loss_raw=0.3319, running_loss=0.2940, LR=0.000100
[2025-08-11 20:26:37,954][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054900] [Batch 01341/04869] [00:12:12/00:32:05, 0.546s/it]: train_loss_raw=0.2681, running_loss=0.2920, LR=0.000100
[2025-08-11 20:26:44,354][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054912] [Batch 01353/04869] [00:12:18/00:31:58, 0.546s/it]: train_loss_raw=0.3132, running_loss=0.2915, LR=0.000100
[2025-08-11 20:26:50,871][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054924] [Batch 01365/04869] [00:12:24/00:31:52, 0.546s/it]: train_loss_raw=0.2783, running_loss=0.2909, LR=0.000100
[2025-08-11 20:26:57,355][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054936] [Batch 01377/04869] [00:12:31/00:31:45, 0.546s/it]: train_loss_raw=0.2999, running_loss=0.2913, LR=0.000100
[2025-08-11 20:27:03,868][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054948] [Batch 01389/04869] [00:12:37/00:31:38, 0.546s/it]: train_loss_raw=0.3329, running_loss=0.2942, LR=0.000100
[2025-08-11 20:27:10,400][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054960] [Batch 01401/04869] [00:12:44/00:31:32, 0.546s/it]: train_loss_raw=0.3262, running_loss=0.2950, LR=0.000100
[2025-08-11 20:27:16,888][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054972] [Batch 01413/04869] [00:12:50/00:31:25, 0.546s/it]: train_loss_raw=0.3375, running_loss=0.2955, LR=0.000100
[2025-08-11 20:27:23,377][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054984] [Batch 01425/04869] [00:12:57/00:31:19, 0.546s/it]: train_loss_raw=0.2973, running_loss=0.2955, LR=0.000100
[2025-08-11 20:27:29,889][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 054996] [Batch 01437/04869] [00:13:03/00:31:12, 0.546s/it]: train_loss_raw=0.3437, running_loss=0.2959, LR=0.000100
[2025-08-11 20:27:36,411][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055008] [Batch 01449/04869] [00:13:10/00:31:05, 0.546s/it]: train_loss_raw=0.3710, running_loss=0.2957, LR=0.000100
[2025-08-11 20:27:42,872][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055020] [Batch 01461/04869] [00:13:16/00:30:59, 0.545s/it]: train_loss_raw=0.2698, running_loss=0.2967, LR=0.000100
[2025-08-11 20:27:49,346][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055032] [Batch 01473/04869] [00:13:23/00:30:52, 0.545s/it]: train_loss_raw=0.2300, running_loss=0.2956, LR=0.000100
[2025-08-11 20:27:55,813][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055044] [Batch 01485/04869] [00:13:29/00:30:45, 0.545s/it]: train_loss_raw=0.3370, running_loss=0.2979, LR=0.000100
[2025-08-11 20:28:02,256][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055056] [Batch 01497/04869] [00:13:36/00:30:38, 0.545s/it]: train_loss_raw=0.2770, running_loss=0.2993, LR=0.000100
[2025-08-11 20:28:08,796][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055068] [Batch 01509/04869] [00:13:42/00:30:32, 0.545s/it]: train_loss_raw=0.2975, running_loss=0.2999, LR=0.000100
[2025-08-11 20:28:15,264][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055080] [Batch 01521/04869] [00:13:49/00:30:25, 0.545s/it]: train_loss_raw=0.2365, running_loss=0.3025, LR=0.000100
[2025-08-11 20:28:21,641][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055092] [Batch 01533/04869] [00:13:55/00:30:18, 0.545s/it]: train_loss_raw=0.3533, running_loss=0.3045, LR=0.000100
[2025-08-11 20:28:28,145][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055104] [Batch 01545/04869] [00:14:02/00:30:12, 0.545s/it]: train_loss_raw=0.2502, running_loss=0.3026, LR=0.000100
[2025-08-11 20:28:34,597][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055116] [Batch 01557/04869] [00:14:08/00:30:05, 0.545s/it]: train_loss_raw=0.3401, running_loss=0.3017, LR=0.000100
[2025-08-11 20:28:41,102][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055128] [Batch 01569/04869] [00:14:15/00:29:58, 0.545s/it]: train_loss_raw=0.2826, running_loss=0.3018, LR=0.000100
[2025-08-11 20:28:47,621][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055140] [Batch 01581/04869] [00:14:21/00:29:52, 0.545s/it]: train_loss_raw=0.2357, running_loss=0.2995, LR=0.000100
[2025-08-11 20:28:54,110][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055152] [Batch 01593/04869] [00:14:28/00:29:45, 0.545s/it]: train_loss_raw=0.3369, running_loss=0.2970, LR=0.000100
[2025-08-11 20:29:00,606][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055164] [Batch 01605/04869] [00:14:34/00:29:38, 0.545s/it]: train_loss_raw=0.2441, running_loss=0.2955, LR=0.000100
[2025-08-11 20:29:07,083][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055176] [Batch 01617/04869] [00:14:41/00:29:32, 0.545s/it]: train_loss_raw=0.3128, running_loss=0.2943, LR=0.000100
[2025-08-11 20:29:13,570][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055188] [Batch 01629/04869] [00:14:47/00:29:25, 0.545s/it]: train_loss_raw=0.3025, running_loss=0.2951, LR=0.000100
[2025-08-11 20:29:20,118][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055200] [Batch 01641/04869] [00:14:54/00:29:18, 0.545s/it]: train_loss_raw=0.3303, running_loss=0.2936, LR=0.000100
[2025-08-11 20:29:26,620][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055212] [Batch 01653/04869] [00:15:00/00:29:12, 0.545s/it]: train_loss_raw=0.2418, running_loss=0.2903, LR=0.000100
[2025-08-11 20:29:33,163][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055224] [Batch 01665/04869] [00:15:07/00:29:05, 0.545s/it]: train_loss_raw=0.3324, running_loss=0.2919, LR=0.000100
[2025-08-11 20:29:39,834][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055236] [Batch 01677/04869] [00:15:13/00:28:59, 0.545s/it]: train_loss_raw=0.3103, running_loss=0.2966, LR=0.000100
[2025-08-11 20:29:46,400][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055248] [Batch 01689/04869] [00:15:20/00:28:53, 0.545s/it]: train_loss_raw=0.2384, running_loss=0.2933, LR=0.000100
[2025-08-11 20:29:52,891][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055260] [Batch 01701/04869] [00:15:26/00:28:46, 0.545s/it]: train_loss_raw=0.2634, running_loss=0.2933, LR=0.000100
[2025-08-11 20:29:59,456][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055272] [Batch 01713/04869] [00:15:33/00:28:39, 0.545s/it]: train_loss_raw=0.2685, running_loss=0.2959, LR=0.000100
[2025-08-11 20:30:06,041][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055284] [Batch 01725/04869] [00:15:40/00:28:33, 0.545s/it]: train_loss_raw=0.2800, running_loss=0.2990, LR=0.000100
[2025-08-11 20:30:12,586][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055296] [Batch 01737/04869] [00:15:46/00:28:26, 0.545s/it]: train_loss_raw=0.2520, running_loss=0.2984, LR=0.000100
[2025-08-11 20:30:19,065][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055308] [Batch 01749/04869] [00:15:53/00:28:20, 0.545s/it]: train_loss_raw=0.3257, running_loss=0.2970, LR=0.000100
[2025-08-11 20:30:25,613][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055320] [Batch 01761/04869] [00:15:59/00:28:13, 0.545s/it]: train_loss_raw=0.2288, running_loss=0.2969, LR=0.000100
[2025-08-11 20:30:32,038][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055332] [Batch 01773/04869] [00:16:06/00:28:07, 0.545s/it]: train_loss_raw=0.2919, running_loss=0.2965, LR=0.000100
[2025-08-11 20:30:38,448][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055344] [Batch 01785/04869] [00:16:12/00:28:00, 0.545s/it]: train_loss_raw=0.3270, running_loss=0.2971, LR=0.000100
[2025-08-11 20:30:44,963][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055356] [Batch 01797/04869] [00:16:19/00:27:53, 0.545s/it]: train_loss_raw=0.2313, running_loss=0.2994, LR=0.000100
[2025-08-11 20:30:51,482][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055368] [Batch 01809/04869] [00:16:25/00:27:47, 0.545s/it]: train_loss_raw=0.2803, running_loss=0.3008, LR=0.000100
[2025-08-11 20:30:58,079][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055380] [Batch 01821/04869] [00:16:32/00:27:40, 0.545s/it]: train_loss_raw=0.3766, running_loss=0.3013, LR=0.000100
[2025-08-11 20:31:04,531][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055392] [Batch 01833/04869] [00:16:38/00:27:34, 0.545s/it]: train_loss_raw=0.2796, running_loss=0.3009, LR=0.000100
[2025-08-11 20:31:11,005][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055404] [Batch 01845/04869] [00:16:45/00:27:27, 0.545s/it]: train_loss_raw=0.2662, running_loss=0.2999, LR=0.000100
[2025-08-11 20:31:17,464][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055416] [Batch 01857/04869] [00:16:51/00:27:20, 0.545s/it]: train_loss_raw=0.3123, running_loss=0.3032, LR=0.000100
[2025-08-11 20:31:24,025][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055428] [Batch 01869/04869] [00:16:58/00:27:14, 0.545s/it]: train_loss_raw=0.3349, running_loss=0.3063, LR=0.000100
[2025-08-11 20:31:30,604][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055440] [Batch 01881/04869] [00:17:04/00:27:07, 0.545s/it]: train_loss_raw=0.2197, running_loss=0.3062, LR=0.000100
[2025-08-11 20:31:37,164][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055452] [Batch 01893/04869] [00:17:11/00:27:01, 0.545s/it]: train_loss_raw=0.2294, running_loss=0.3047, LR=0.000100
[2025-08-11 20:31:43,672][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055464] [Batch 01905/04869] [00:17:17/00:26:54, 0.545s/it]: train_loss_raw=0.2826, running_loss=0.3043, LR=0.000100
[2025-08-11 20:31:50,147][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055476] [Batch 01917/04869] [00:17:24/00:26:48, 0.545s/it]: train_loss_raw=0.3404, running_loss=0.3028, LR=0.000100
[2025-08-11 20:31:56,736][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055488] [Batch 01929/04869] [00:17:30/00:26:41, 0.545s/it]: train_loss_raw=0.2333, running_loss=0.3000, LR=0.000100
[2025-08-11 20:32:03,219][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055500] [Batch 01941/04869] [00:17:37/00:26:34, 0.545s/it]: train_loss_raw=0.3065, running_loss=0.3005, LR=0.000100
[2025-08-11 20:32:09,716][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055512] [Batch 01953/04869] [00:17:43/00:26:28, 0.545s/it]: train_loss_raw=0.2731, running_loss=0.2981, LR=0.000100
[2025-08-11 20:32:16,213][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055524] [Batch 01965/04869] [00:17:50/00:26:21, 0.545s/it]: train_loss_raw=0.2267, running_loss=0.2977, LR=0.000100
[2025-08-11 20:32:22,645][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055536] [Batch 01977/04869] [00:17:56/00:26:15, 0.545s/it]: train_loss_raw=0.3361, running_loss=0.2994, LR=0.000100
[2025-08-11 20:32:29,159][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055548] [Batch 01989/04869] [00:18:03/00:26:08, 0.545s/it]: train_loss_raw=0.2885, running_loss=0.3008, LR=0.000100
[2025-08-11 20:32:35,794][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055560] [Batch 02001/04869] [00:18:09/00:26:02, 0.545s/it]: train_loss_raw=0.2568, running_loss=0.2994, LR=0.000100
[2025-08-11 20:32:42,253][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055572] [Batch 02013/04869] [00:18:16/00:25:55, 0.545s/it]: train_loss_raw=0.3640, running_loss=0.2983, LR=0.000100
[2025-08-11 20:32:48,710][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055584] [Batch 02025/04869] [00:18:22/00:25:48, 0.545s/it]: train_loss_raw=0.2655, running_loss=0.2989, LR=0.000100
[2025-08-11 20:32:55,224][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055596] [Batch 02037/04869] [00:18:29/00:25:42, 0.545s/it]: train_loss_raw=0.2456, running_loss=0.3010, LR=0.000100
[2025-08-11 20:33:01,702][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055608] [Batch 02049/04869] [00:18:35/00:25:35, 0.545s/it]: train_loss_raw=0.3410, running_loss=0.2988, LR=0.000100
[2025-08-11 20:33:08,259][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055620] [Batch 02061/04869] [00:18:42/00:25:29, 0.545s/it]: train_loss_raw=0.2945, running_loss=0.2997, LR=0.000100
[2025-08-11 20:33:14,768][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055632] [Batch 02073/04869] [00:18:48/00:25:22, 0.545s/it]: train_loss_raw=0.2910, running_loss=0.3009, LR=0.000100
[2025-08-11 20:33:21,356][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055644] [Batch 02085/04869] [00:18:55/00:25:16, 0.545s/it]: train_loss_raw=0.3323, running_loss=0.2993, LR=0.000100
[2025-08-11 20:33:27,797][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055656] [Batch 02097/04869] [00:19:01/00:25:09, 0.545s/it]: train_loss_raw=0.2965, running_loss=0.2977, LR=0.000100
[2025-08-11 20:33:34,236][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055668] [Batch 02109/04869] [00:19:08/00:25:02, 0.544s/it]: train_loss_raw=0.2961, running_loss=0.2971, LR=0.000100
[2025-08-11 20:33:40,689][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055680] [Batch 02121/04869] [00:19:14/00:24:56, 0.544s/it]: train_loss_raw=0.3103, running_loss=0.2981, LR=0.000100
[2025-08-11 20:33:47,101][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055692] [Batch 02133/04869] [00:19:21/00:24:49, 0.544s/it]: train_loss_raw=0.2754, running_loss=0.2984, LR=0.000100
[2025-08-11 20:33:53,524][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055704] [Batch 02145/04869] [00:19:27/00:24:42, 0.544s/it]: train_loss_raw=0.2525, running_loss=0.2971, LR=0.000100
[2025-08-11 20:33:59,989][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055716] [Batch 02157/04869] [00:19:34/00:24:36, 0.544s/it]: train_loss_raw=0.3119, running_loss=0.2963, LR=0.000100
[2025-08-11 20:34:06,476][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055728] [Batch 02169/04869] [00:19:40/00:24:29, 0.544s/it]: train_loss_raw=0.2838, running_loss=0.2969, LR=0.000100
[2025-08-11 20:34:12,867][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055740] [Batch 02181/04869] [00:19:46/00:24:22, 0.544s/it]: train_loss_raw=0.3289, running_loss=0.2960, LR=0.000100
[2025-08-11 20:34:19,386][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055752] [Batch 02193/04869] [00:19:53/00:24:16, 0.544s/it]: train_loss_raw=0.3138, running_loss=0.2949, LR=0.000100
[2025-08-11 20:34:25,925][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055764] [Batch 02205/04869] [00:20:00/00:24:09, 0.544s/it]: train_loss_raw=0.3260, running_loss=0.2931, LR=0.000100
[2025-08-11 20:34:32,482][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055776] [Batch 02217/04869] [00:20:06/00:24:03, 0.544s/it]: train_loss_raw=0.3185, running_loss=0.2918, LR=0.000100
[2025-08-11 20:34:38,991][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055788] [Batch 02229/04869] [00:20:13/00:23:56, 0.544s/it]: train_loss_raw=0.3230, running_loss=0.2933, LR=0.000100
[2025-08-11 20:34:45,569][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055800] [Batch 02241/04869] [00:20:19/00:23:50, 0.544s/it]: train_loss_raw=0.3660, running_loss=0.2941, LR=0.000100
[2025-08-11 20:34:52,032][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055812] [Batch 02253/04869] [00:20:26/00:23:43, 0.544s/it]: train_loss_raw=0.2651, running_loss=0.2975, LR=0.000100
[2025-08-11 20:34:58,500][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055824] [Batch 02265/04869] [00:20:32/00:23:37, 0.544s/it]: train_loss_raw=0.3209, running_loss=0.2986, LR=0.000100
[2025-08-11 20:35:05,049][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055836] [Batch 02277/04869] [00:20:39/00:23:30, 0.544s/it]: train_loss_raw=0.3007, running_loss=0.2976, LR=0.000100
[2025-08-11 20:35:11,569][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055848] [Batch 02289/04869] [00:20:45/00:23:24, 0.544s/it]: train_loss_raw=0.3465, running_loss=0.2991, LR=0.000100
[2025-08-11 20:35:18,131][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055860] [Batch 02301/04869] [00:20:52/00:23:17, 0.544s/it]: train_loss_raw=0.2985, running_loss=0.2995, LR=0.000100
[2025-08-11 20:35:24,577][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055872] [Batch 02313/04869] [00:20:58/00:23:10, 0.544s/it]: train_loss_raw=0.3630, running_loss=0.3015, LR=0.000100
[2025-08-11 20:35:31,051][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055884] [Batch 02325/04869] [00:21:05/00:23:04, 0.544s/it]: train_loss_raw=0.3124, running_loss=0.3003, LR=0.000100
[2025-08-11 20:35:37,626][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055896] [Batch 02337/04869] [00:21:11/00:22:57, 0.544s/it]: train_loss_raw=0.3365, running_loss=0.3012, LR=0.000100
[2025-08-11 20:35:44,186][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055908] [Batch 02349/04869] [00:21:18/00:22:51, 0.544s/it]: train_loss_raw=0.2843, running_loss=0.3008, LR=0.000100
[2025-08-11 20:35:50,745][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055920] [Batch 02361/04869] [00:21:24/00:22:44, 0.544s/it]: train_loss_raw=0.3117, running_loss=0.3016, LR=0.000100
[2025-08-11 20:35:57,197][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055932] [Batch 02373/04869] [00:21:31/00:22:38, 0.544s/it]: train_loss_raw=0.2712, running_loss=0.2997, LR=0.000100
[2025-08-11 20:36:03,621][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055944] [Batch 02385/04869] [00:21:37/00:22:31, 0.544s/it]: train_loss_raw=0.2967, running_loss=0.2991, LR=0.000100
[2025-08-11 20:36:10,079][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055956] [Batch 02397/04869] [00:21:44/00:22:24, 0.544s/it]: train_loss_raw=0.3285, running_loss=0.2981, LR=0.000100
[2025-08-11 20:36:16,524][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055968] [Batch 02409/04869] [00:21:50/00:22:18, 0.544s/it]: train_loss_raw=0.2907, running_loss=0.2984, LR=0.000100
[2025-08-11 20:36:23,001][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055980] [Batch 02421/04869] [00:21:57/00:22:11, 0.544s/it]: train_loss_raw=0.2558, running_loss=0.3004, LR=0.000100
[2025-08-11 20:36:29,481][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 055992] [Batch 02433/04869] [00:22:03/00:22:05, 0.544s/it]: train_loss_raw=0.3396, running_loss=0.3010, LR=0.000100
[2025-08-11 20:36:40,900][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056004] [Batch 02445/04869] [00:22:14/00:22:03, 0.546s/it]: train_loss_raw=0.2478, running_loss=0.3009, LR=0.000100
[2025-08-11 20:36:47,236][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056016] [Batch 02457/04869] [00:22:21/00:21:56, 0.546s/it]: train_loss_raw=0.3875, running_loss=0.3034, LR=0.000100
[2025-08-11 20:36:53,642][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056028] [Batch 02469/04869] [00:22:27/00:21:50, 0.546s/it]: train_loss_raw=0.2981, running_loss=0.3024, LR=0.000100
[2025-08-11 20:37:00,067][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056040] [Batch 02481/04869] [00:22:34/00:21:43, 0.546s/it]: train_loss_raw=0.2639, running_loss=0.3012, LR=0.000100
[2025-08-11 20:37:06,668][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056052] [Batch 02493/04869] [00:22:40/00:21:36, 0.546s/it]: train_loss_raw=0.2844, running_loss=0.2997, LR=0.000100
[2025-08-11 20:37:13,117][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056064] [Batch 02505/04869] [00:22:47/00:21:30, 0.546s/it]: train_loss_raw=0.3418, running_loss=0.2967, LR=0.000100
[2025-08-11 20:37:19,629][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056076] [Batch 02517/04869] [00:22:53/00:21:23, 0.546s/it]: train_loss_raw=0.3265, running_loss=0.2964, LR=0.000100
[2025-08-11 20:37:26,061][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056088] [Batch 02529/04869] [00:23:00/00:21:17, 0.546s/it]: train_loss_raw=0.2807, running_loss=0.2962, LR=0.000100
[2025-08-11 20:37:32,618][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056100] [Batch 02541/04869] [00:23:06/00:21:10, 0.546s/it]: train_loss_raw=0.3017, running_loss=0.2960, LR=0.000100
[2025-08-11 20:37:39,124][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056112] [Batch 02553/04869] [00:23:13/00:21:03, 0.546s/it]: train_loss_raw=0.3146, running_loss=0.2947, LR=0.000100
[2025-08-11 20:37:45,625][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056124] [Batch 02565/04869] [00:23:19/00:20:57, 0.546s/it]: train_loss_raw=0.2515, running_loss=0.2966, LR=0.000100
[2025-08-11 20:37:52,149][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056136] [Batch 02577/04869] [00:23:26/00:20:50, 0.546s/it]: train_loss_raw=0.2509, running_loss=0.2969, LR=0.000100
[2025-08-11 20:37:58,591][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056148] [Batch 02589/04869] [00:23:32/00:20:44, 0.546s/it]: train_loss_raw=0.2433, running_loss=0.2965, LR=0.000100
[2025-08-11 20:38:05,073][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056160] [Batch 02601/04869] [00:23:39/00:20:37, 0.546s/it]: train_loss_raw=0.3323, running_loss=0.2961, LR=0.000100
[2025-08-11 20:38:11,612][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056172] [Batch 02613/04869] [00:23:45/00:20:30, 0.546s/it]: train_loss_raw=0.2597, running_loss=0.2964, LR=0.000100
[2025-08-11 20:38:18,079][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056184] [Batch 02625/04869] [00:23:52/00:20:24, 0.546s/it]: train_loss_raw=0.2938, running_loss=0.2954, LR=0.000100
[2025-08-11 20:38:24,508][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056196] [Batch 02637/04869] [00:23:58/00:20:17, 0.546s/it]: train_loss_raw=0.3937, running_loss=0.2965, LR=0.000100
[2025-08-11 20:38:30,993][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056208] [Batch 02649/04869] [00:24:05/00:20:11, 0.546s/it]: train_loss_raw=0.2866, running_loss=0.2968, LR=0.000100
[2025-08-11 20:38:37,435][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056220] [Batch 02661/04869] [00:24:11/00:20:04, 0.545s/it]: train_loss_raw=0.2975, running_loss=0.2970, LR=0.000100
[2025-08-11 20:38:43,942][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056232] [Batch 02673/04869] [00:24:18/00:19:57, 0.545s/it]: train_loss_raw=0.2159, running_loss=0.2949, LR=0.000100
[2025-08-11 20:38:50,440][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056244] [Batch 02685/04869] [00:24:24/00:19:51, 0.545s/it]: train_loss_raw=0.2844, running_loss=0.2930, LR=0.000100
[2025-08-11 20:38:56,952][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056256] [Batch 02697/04869] [00:24:31/00:19:44, 0.545s/it]: train_loss_raw=0.3068, running_loss=0.2921, LR=0.000100
[2025-08-11 20:39:03,377][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056268] [Batch 02709/04869] [00:24:37/00:19:38, 0.545s/it]: train_loss_raw=0.2662, running_loss=0.2922, LR=0.000100
[2025-08-11 20:39:09,856][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056280] [Batch 02721/04869] [00:24:43/00:19:31, 0.545s/it]: train_loss_raw=0.2670, running_loss=0.2916, LR=0.000100
[2025-08-11 20:39:16,475][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056292] [Batch 02733/04869] [00:24:50/00:19:24, 0.545s/it]: train_loss_raw=0.2622, running_loss=0.2899, LR=0.000100
[2025-08-11 20:39:22,936][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056304] [Batch 02745/04869] [00:24:57/00:19:18, 0.545s/it]: train_loss_raw=0.3091, running_loss=0.2886, LR=0.000100
[2025-08-11 20:39:29,494][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056316] [Batch 02757/04869] [00:25:03/00:19:11, 0.545s/it]: train_loss_raw=0.3159, running_loss=0.2894, LR=0.000100
[2025-08-11 20:39:35,931][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056328] [Batch 02769/04869] [00:25:10/00:19:05, 0.545s/it]: train_loss_raw=0.2408, running_loss=0.2917, LR=0.000100
[2025-08-11 20:39:42,524][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056340] [Batch 02781/04869] [00:25:16/00:18:58, 0.545s/it]: train_loss_raw=0.2902, running_loss=0.2952, LR=0.000100
[2025-08-11 20:39:49,060][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056352] [Batch 02793/04869] [00:25:23/00:18:52, 0.545s/it]: train_loss_raw=0.4027, running_loss=0.2952, LR=0.000100
[2025-08-11 20:39:55,522][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056364] [Batch 02805/04869] [00:25:29/00:18:45, 0.545s/it]: train_loss_raw=0.2774, running_loss=0.2963, LR=0.000100
[2025-08-11 20:40:02,048][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056376] [Batch 02817/04869] [00:25:36/00:18:38, 0.545s/it]: train_loss_raw=0.3030, running_loss=0.2980, LR=0.000100
[2025-08-11 20:40:08,516][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056388] [Batch 02829/04869] [00:25:42/00:18:32, 0.545s/it]: train_loss_raw=0.3846, running_loss=0.2975, LR=0.000100
[2025-08-11 20:40:14,959][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056400] [Batch 02841/04869] [00:25:49/00:18:25, 0.545s/it]: train_loss_raw=0.2943, running_loss=0.3007, LR=0.000100
[2025-08-11 20:40:30,684][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056412] [Batch 02853/04869] [00:26:04/00:18:25, 0.548s/it]: train_loss_raw=0.3211, running_loss=0.3007, LR=0.000100
[2025-08-11 20:40:37,141][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056424] [Batch 02865/04869] [00:26:11/00:18:19, 0.548s/it]: train_loss_raw=0.2862, running_loss=0.2996, LR=0.000100
[2025-08-11 20:40:43,627][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056436] [Batch 02877/04869] [00:26:17/00:18:12, 0.548s/it]: train_loss_raw=0.2992, running_loss=0.3011, LR=0.000100
[2025-08-11 20:40:50,100][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056448] [Batch 02889/04869] [00:26:24/00:18:05, 0.548s/it]: train_loss_raw=0.3163, running_loss=0.3008, LR=0.000100
[2025-08-11 20:40:56,658][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056460] [Batch 02901/04869] [00:26:30/00:17:59, 0.548s/it]: train_loss_raw=0.2664, running_loss=0.3009, LR=0.000100
[2025-08-11 20:41:03,130][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056472] [Batch 02913/04869] [00:26:37/00:17:52, 0.548s/it]: train_loss_raw=0.2488, running_loss=0.3001, LR=0.000100
[2025-08-11 20:41:09,625][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056484] [Batch 02925/04869] [00:26:43/00:17:45, 0.548s/it]: train_loss_raw=0.2914, running_loss=0.3008, LR=0.000100
[2025-08-11 20:41:16,089][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056496] [Batch 02937/04869] [00:26:50/00:17:39, 0.548s/it]: train_loss_raw=0.2747, running_loss=0.3025, LR=0.000100
[2025-08-11 20:41:22,532][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056508] [Batch 02949/04869] [00:26:56/00:17:32, 0.548s/it]: train_loss_raw=0.2845, running_loss=0.3017, LR=0.000100
[2025-08-11 20:41:28,968][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056520] [Batch 02961/04869] [00:27:03/00:17:25, 0.548s/it]: train_loss_raw=0.3253, running_loss=0.3018, LR=0.000100
[2025-08-11 20:41:35,425][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056532] [Batch 02973/04869] [00:27:09/00:17:19, 0.548s/it]: train_loss_raw=0.3280, running_loss=0.3030, LR=0.000100
[2025-08-11 20:41:41,809][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056544] [Batch 02985/04869] [00:27:15/00:17:12, 0.548s/it]: train_loss_raw=0.2505, running_loss=0.3030, LR=0.000100
[2025-08-11 20:41:48,264][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056556] [Batch 02997/04869] [00:27:22/00:17:05, 0.548s/it]: train_loss_raw=0.2459, running_loss=0.3019, LR=0.000100
[2025-08-11 20:41:54,776][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056568] [Batch 03009/04869] [00:27:28/00:16:59, 0.548s/it]: train_loss_raw=0.2992, running_loss=0.2998, LR=0.000100
[2025-08-11 20:42:01,249][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056580] [Batch 03021/04869] [00:27:35/00:16:52, 0.548s/it]: train_loss_raw=0.3600, running_loss=0.3008, LR=0.000100
[2025-08-11 20:42:07,666][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056592] [Batch 03033/04869] [00:27:41/00:16:45, 0.548s/it]: train_loss_raw=0.2894, running_loss=0.3014, LR=0.000100
[2025-08-11 20:42:14,164][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056604] [Batch 03045/04869] [00:27:48/00:16:39, 0.548s/it]: train_loss_raw=0.3346, running_loss=0.3015, LR=0.000100
[2025-08-11 20:42:20,657][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056616] [Batch 03057/04869] [00:27:54/00:16:32, 0.548s/it]: train_loss_raw=0.3038, running_loss=0.3029, LR=0.000100
[2025-08-11 20:42:27,213][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056628] [Batch 03069/04869] [00:28:01/00:16:26, 0.548s/it]: train_loss_raw=0.3680, running_loss=0.3043, LR=0.000100
[2025-08-11 20:42:33,702][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056640] [Batch 03081/04869] [00:28:07/00:16:19, 0.548s/it]: train_loss_raw=0.2898, running_loss=0.3042, LR=0.000100
[2025-08-11 20:42:40,131][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056652] [Batch 03093/04869] [00:28:14/00:16:12, 0.548s/it]: train_loss_raw=0.2808, running_loss=0.3060, LR=0.000100
[2025-08-11 20:42:46,598][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056664] [Batch 03105/04869] [00:28:20/00:16:06, 0.548s/it]: train_loss_raw=0.2742, running_loss=0.3053, LR=0.000100
[2025-08-11 20:42:53,160][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056676] [Batch 03117/04869] [00:28:27/00:15:59, 0.548s/it]: train_loss_raw=0.2583, running_loss=0.3071, LR=0.000100
[2025-08-11 20:42:59,571][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056688] [Batch 03129/04869] [00:28:33/00:15:52, 0.548s/it]: train_loss_raw=0.3706, running_loss=0.3047, LR=0.000100
[2025-08-11 20:43:06,006][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056700] [Batch 03141/04869] [00:28:40/00:15:46, 0.548s/it]: train_loss_raw=0.3454, running_loss=0.3050, LR=0.000100
[2025-08-11 20:43:12,502][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056712] [Batch 03153/04869] [00:28:46/00:15:39, 0.548s/it]: train_loss_raw=0.3686, running_loss=0.3054, LR=0.000100
[2025-08-11 20:43:18,927][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056724] [Batch 03165/04869] [00:28:53/00:15:33, 0.548s/it]: train_loss_raw=0.3162, running_loss=0.3072, LR=0.000100
[2025-08-11 20:43:25,356][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056736] [Batch 03177/04869] [00:28:59/00:15:26, 0.548s/it]: train_loss_raw=0.3410, running_loss=0.3095, LR=0.000100
[2025-08-11 20:43:31,825][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056748] [Batch 03189/04869] [00:29:05/00:15:19, 0.547s/it]: train_loss_raw=0.2373, running_loss=0.3061, LR=0.000100
[2025-08-11 20:43:38,368][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056760] [Batch 03201/04869] [00:29:12/00:15:13, 0.547s/it]: train_loss_raw=0.3276, running_loss=0.3073, LR=0.000100
[2025-08-11 20:43:44,766][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056772] [Batch 03213/04869] [00:29:18/00:15:06, 0.547s/it]: train_loss_raw=0.2707, running_loss=0.3078, LR=0.000100
[2025-08-11 20:43:51,269][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056784] [Batch 03225/04869] [00:29:25/00:14:59, 0.547s/it]: train_loss_raw=0.2395, running_loss=0.3086, LR=0.000100
[2025-08-11 20:43:57,803][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056796] [Batch 03237/04869] [00:29:31/00:14:53, 0.547s/it]: train_loss_raw=0.2544, running_loss=0.3095, LR=0.000100
[2025-08-11 20:44:04,316][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056808] [Batch 03249/04869] [00:29:38/00:14:46, 0.547s/it]: train_loss_raw=0.2884, running_loss=0.3075, LR=0.000100
[2025-08-11 20:44:10,781][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056820] [Batch 03261/04869] [00:29:44/00:14:40, 0.547s/it]: train_loss_raw=0.2857, running_loss=0.3070, LR=0.000100
[2025-08-11 20:44:17,402][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056832] [Batch 03273/04869] [00:29:51/00:14:33, 0.547s/it]: train_loss_raw=0.3101, running_loss=0.3066, LR=0.000100
[2025-08-11 20:44:23,849][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056844] [Batch 03285/04869] [00:29:57/00:14:26, 0.547s/it]: train_loss_raw=0.3359, running_loss=0.3061, LR=0.000100
[2025-08-11 20:44:30,385][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056856] [Batch 03297/04869] [00:30:04/00:14:20, 0.547s/it]: train_loss_raw=0.2452, running_loss=0.3068, LR=0.000100
[2025-08-11 20:44:36,941][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056868] [Batch 03309/04869] [00:30:11/00:14:13, 0.547s/it]: train_loss_raw=0.3915, running_loss=0.3076, LR=0.000100
[2025-08-11 20:44:43,411][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056880] [Batch 03321/04869] [00:30:17/00:14:07, 0.547s/it]: train_loss_raw=0.3505, running_loss=0.3067, LR=0.000100
[2025-08-11 20:44:49,859][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056892] [Batch 03333/04869] [00:30:23/00:14:00, 0.547s/it]: train_loss_raw=0.3393, running_loss=0.3086, LR=0.000100
[2025-08-11 20:44:56,310][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056904] [Batch 03345/04869] [00:30:30/00:13:53, 0.547s/it]: train_loss_raw=0.3256, running_loss=0.3088, LR=0.000100
[2025-08-11 20:45:02,817][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056916] [Batch 03357/04869] [00:30:36/00:13:47, 0.547s/it]: train_loss_raw=0.3574, running_loss=0.3074, LR=0.000100
[2025-08-11 20:45:09,312][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056928] [Batch 03369/04869] [00:30:43/00:13:40, 0.547s/it]: train_loss_raw=0.3054, running_loss=0.3078, LR=0.000100
[2025-08-11 20:45:15,892][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056940] [Batch 03381/04869] [00:30:49/00:13:34, 0.547s/it]: train_loss_raw=0.2591, running_loss=0.3068, LR=0.000100
[2025-08-11 20:45:22,326][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056952] [Batch 03393/04869] [00:30:56/00:13:27, 0.547s/it]: train_loss_raw=0.3565, running_loss=0.3063, LR=0.000100
[2025-08-11 20:45:28,752][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056964] [Batch 03405/04869] [00:31:02/00:13:20, 0.547s/it]: train_loss_raw=0.3564, running_loss=0.3049, LR=0.000100
[2025-08-11 20:45:35,202][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056976] [Batch 03417/04869] [00:31:09/00:13:14, 0.547s/it]: train_loss_raw=0.3155, running_loss=0.3075, LR=0.000100
[2025-08-11 20:45:41,686][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 056988] [Batch 03429/04869] [00:31:15/00:13:07, 0.547s/it]: train_loss_raw=0.2917, running_loss=0.3061, LR=0.000100
[2025-08-11 20:45:48,169][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057000] [Batch 03441/04869] [00:31:22/00:13:01, 0.547s/it]: train_loss_raw=0.2298, running_loss=0.3052, LR=0.000100
[2025-08-11 20:45:54,666][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057012] [Batch 03453/04869] [00:31:28/00:12:54, 0.547s/it]: train_loss_raw=0.3535, running_loss=0.3100, LR=0.000100
[2025-08-11 20:46:01,224][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057024] [Batch 03465/04869] [00:31:35/00:12:47, 0.547s/it]: train_loss_raw=0.3368, running_loss=0.3096, LR=0.000100
[2025-08-11 20:46:07,773][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057036] [Batch 03477/04869] [00:31:41/00:12:41, 0.547s/it]: train_loss_raw=0.3476, running_loss=0.3105, LR=0.000100
[2025-08-11 20:46:14,262][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057048] [Batch 03489/04869] [00:31:48/00:12:34, 0.547s/it]: train_loss_raw=0.3194, running_loss=0.3096, LR=0.000100
[2025-08-11 20:46:20,777][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057060] [Batch 03501/04869] [00:31:54/00:12:28, 0.547s/it]: train_loss_raw=0.3109, running_loss=0.3067, LR=0.000100
[2025-08-11 20:46:27,246][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057072] [Batch 03513/04869] [00:32:01/00:12:21, 0.547s/it]: train_loss_raw=0.2813, running_loss=0.3064, LR=0.000100
[2025-08-11 20:46:33,846][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057084] [Batch 03525/04869] [00:32:07/00:12:15, 0.547s/it]: train_loss_raw=0.3675, running_loss=0.3067, LR=0.000100
[2025-08-11 20:46:40,352][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057096] [Batch 03537/04869] [00:32:14/00:12:08, 0.547s/it]: train_loss_raw=0.3066, running_loss=0.3106, LR=0.000100
[2025-08-11 20:46:46,773][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057108] [Batch 03549/04869] [00:32:20/00:12:01, 0.547s/it]: train_loss_raw=0.2957, running_loss=0.3109, LR=0.000100
[2025-08-11 20:46:53,216][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057120] [Batch 03561/04869] [00:32:27/00:11:55, 0.547s/it]: train_loss_raw=0.3810, running_loss=0.3102, LR=0.000100
[2025-08-11 20:46:59,679][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057132] [Batch 03573/04869] [00:32:33/00:11:48, 0.547s/it]: train_loss_raw=0.3173, running_loss=0.3123, LR=0.000100
[2025-08-11 20:47:06,177][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057144] [Batch 03585/04869] [00:32:40/00:11:42, 0.547s/it]: train_loss_raw=0.2828, running_loss=0.3079, LR=0.000100
[2025-08-11 20:47:12,702][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057156] [Batch 03597/04869] [00:32:46/00:11:35, 0.547s/it]: train_loss_raw=0.3616, running_loss=0.3115, LR=0.000100
[2025-08-11 20:47:19,211][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057168] [Batch 03609/04869] [00:32:53/00:11:28, 0.547s/it]: train_loss_raw=0.3088, running_loss=0.3133, LR=0.000100
[2025-08-11 20:47:25,723][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057180] [Batch 03621/04869] [00:32:59/00:11:22, 0.547s/it]: train_loss_raw=0.3222, running_loss=0.3131, LR=0.000100
[2025-08-11 20:47:32,246][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057192] [Batch 03633/04869] [00:33:06/00:11:15, 0.547s/it]: train_loss_raw=0.2752, running_loss=0.3116, LR=0.000100
[2025-08-11 20:47:38,669][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057204] [Batch 03645/04869] [00:33:12/00:11:09, 0.547s/it]: train_loss_raw=0.3142, running_loss=0.3111, LR=0.000100
[2025-08-11 20:47:45,107][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057216] [Batch 03657/04869] [00:33:19/00:11:02, 0.547s/it]: train_loss_raw=0.3337, running_loss=0.3102, LR=0.000100
[2025-08-11 20:47:51,669][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057228] [Batch 03669/04869] [00:33:25/00:10:56, 0.547s/it]: train_loss_raw=0.3176, running_loss=0.3089, LR=0.000100
[2025-08-11 20:47:58,144][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057240] [Batch 03681/04869] [00:33:32/00:10:49, 0.547s/it]: train_loss_raw=0.2948, running_loss=0.3091, LR=0.000100
[2025-08-11 20:48:04,564][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057252] [Batch 03693/04869] [00:33:38/00:10:42, 0.547s/it]: train_loss_raw=0.2854, running_loss=0.3066, LR=0.000100
[2025-08-11 20:48:11,073][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057264] [Batch 03705/04869] [00:33:45/00:10:36, 0.547s/it]: train_loss_raw=0.3635, running_loss=0.3102, LR=0.000100
[2025-08-11 20:48:17,596][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057276] [Batch 03717/04869] [00:33:51/00:10:29, 0.547s/it]: train_loss_raw=0.2774, running_loss=0.3090, LR=0.000100
[2025-08-11 20:48:24,257][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057288] [Batch 03729/04869] [00:33:58/00:10:23, 0.547s/it]: train_loss_raw=0.3261, running_loss=0.3116, LR=0.000100
[2025-08-11 20:48:30,697][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057300] [Batch 03741/04869] [00:34:04/00:10:16, 0.547s/it]: train_loss_raw=0.3751, running_loss=0.3113, LR=0.000100
[2025-08-11 20:48:37,149][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057312] [Batch 03753/04869] [00:34:11/00:10:09, 0.547s/it]: train_loss_raw=0.2954, running_loss=0.3093, LR=0.000100
[2025-08-11 20:48:43,651][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057324] [Batch 03765/04869] [00:34:17/00:10:03, 0.547s/it]: train_loss_raw=0.3687, running_loss=0.3089, LR=0.000100
[2025-08-11 20:48:50,151][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057336] [Batch 03777/04869] [00:34:24/00:09:56, 0.547s/it]: train_loss_raw=0.2727, running_loss=0.3085, LR=0.000100
[2025-08-11 20:48:56,529][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057348] [Batch 03789/04869] [00:34:30/00:09:50, 0.546s/it]: train_loss_raw=0.2743, running_loss=0.3080, LR=0.000100
[2025-08-11 20:49:02,893][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057360] [Batch 03801/04869] [00:34:36/00:09:43, 0.546s/it]: train_loss_raw=0.3177, running_loss=0.3058, LR=0.000100
[2025-08-11 20:49:09,376][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057372] [Batch 03813/04869] [00:34:43/00:09:37, 0.546s/it]: train_loss_raw=0.4197, running_loss=0.3060, LR=0.000100
[2025-08-11 20:49:15,801][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057384] [Batch 03825/04869] [00:34:49/00:09:30, 0.546s/it]: train_loss_raw=0.2863, running_loss=0.3035, LR=0.000100
[2025-08-11 20:49:22,381][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057396] [Batch 03837/04869] [00:34:56/00:09:23, 0.546s/it]: train_loss_raw=0.3951, running_loss=0.3011, LR=0.000100
[2025-08-11 20:49:28,849][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057408] [Batch 03849/04869] [00:35:02/00:09:17, 0.546s/it]: train_loss_raw=0.3315, running_loss=0.3009, LR=0.000100
[2025-08-11 20:49:35,375][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057420] [Batch 03861/04869] [00:35:09/00:09:10, 0.546s/it]: train_loss_raw=0.3649, running_loss=0.2987, LR=0.000100
[2025-08-11 20:49:41,853][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057432] [Batch 03873/04869] [00:35:15/00:09:04, 0.546s/it]: train_loss_raw=0.2971, running_loss=0.2986, LR=0.000100
[2025-08-11 20:49:48,452][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057444] [Batch 03885/04869] [00:35:22/00:08:57, 0.546s/it]: train_loss_raw=0.2602, running_loss=0.2994, LR=0.000100
[2025-08-11 20:49:54,920][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057456] [Batch 03897/04869] [00:35:29/00:08:51, 0.546s/it]: train_loss_raw=0.3306, running_loss=0.3003, LR=0.000100
[2025-08-11 20:50:01,409][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057468] [Batch 03909/04869] [00:35:35/00:08:44, 0.546s/it]: train_loss_raw=0.2931, running_loss=0.3012, LR=0.000100
[2025-08-11 20:50:07,896][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057480] [Batch 03921/04869] [00:35:41/00:08:37, 0.546s/it]: train_loss_raw=0.3160, running_loss=0.2998, LR=0.000100
[2025-08-11 20:50:14,422][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057492] [Batch 03933/04869] [00:35:48/00:08:31, 0.546s/it]: train_loss_raw=0.3346, running_loss=0.3014, LR=0.000100
[2025-08-11 20:50:20,815][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057504] [Batch 03945/04869] [00:35:54/00:08:24, 0.546s/it]: train_loss_raw=0.2507, running_loss=0.2983, LR=0.000100
[2025-08-11 20:50:27,223][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057516] [Batch 03957/04869] [00:36:01/00:08:18, 0.546s/it]: train_loss_raw=0.2574, running_loss=0.3014, LR=0.000100
[2025-08-11 20:50:33,666][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057528] [Batch 03969/04869] [00:36:07/00:08:11, 0.546s/it]: train_loss_raw=0.2951, running_loss=0.3018, LR=0.000100
[2025-08-11 20:50:40,205][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057540] [Batch 03981/04869] [00:36:14/00:08:04, 0.546s/it]: train_loss_raw=0.4534, running_loss=0.3044, LR=0.000100
[2025-08-11 20:50:46,739][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057552] [Batch 03993/04869] [00:36:20/00:07:58, 0.546s/it]: train_loss_raw=0.2727, running_loss=0.3052, LR=0.000100
[2025-08-11 20:50:53,237][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057564] [Batch 04005/04869] [00:36:27/00:07:51, 0.546s/it]: train_loss_raw=0.2462, running_loss=0.3058, LR=0.000100
[2025-08-11 20:50:59,665][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057576] [Batch 04017/04869] [00:36:33/00:07:45, 0.546s/it]: train_loss_raw=0.2857, running_loss=0.3039, LR=0.000100
[2025-08-11 20:51:06,145][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057588] [Batch 04029/04869] [00:36:40/00:07:38, 0.546s/it]: train_loss_raw=0.2433, running_loss=0.3049, LR=0.000100
[2025-08-11 20:51:12,595][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057600] [Batch 04041/04869] [00:36:46/00:07:32, 0.546s/it]: train_loss_raw=0.3508, running_loss=0.3067, LR=0.000100
[2025-08-11 20:51:19,068][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057612] [Batch 04053/04869] [00:36:53/00:07:25, 0.546s/it]: train_loss_raw=0.3630, running_loss=0.3077, LR=0.000100
[2025-08-11 20:51:25,601][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057624] [Batch 04065/04869] [00:36:59/00:07:19, 0.546s/it]: train_loss_raw=0.3216, running_loss=0.3059, LR=0.000100
[2025-08-11 20:51:32,070][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057636] [Batch 04077/04869] [00:37:06/00:07:12, 0.546s/it]: train_loss_raw=0.2962, running_loss=0.3057, LR=0.000100
[2025-08-11 20:51:38,604][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057648] [Batch 04089/04869] [00:37:12/00:07:05, 0.546s/it]: train_loss_raw=0.2878, running_loss=0.3047, LR=0.000100
[2025-08-11 20:51:45,039][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057660] [Batch 04101/04869] [00:37:19/00:06:59, 0.546s/it]: train_loss_raw=0.2295, running_loss=0.3060, LR=0.000100
[2025-08-11 20:51:51,470][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057672] [Batch 04113/04869] [00:37:25/00:06:52, 0.546s/it]: train_loss_raw=0.3041, running_loss=0.3042, LR=0.000100
[2025-08-11 20:51:57,944][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057684] [Batch 04125/04869] [00:37:32/00:06:46, 0.546s/it]: train_loss_raw=0.1840, running_loss=0.3033, LR=0.000100
[2025-08-11 20:52:04,442][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057696] [Batch 04137/04869] [00:37:38/00:06:39, 0.546s/it]: train_loss_raw=0.2023, running_loss=0.2972, LR=0.000100
[2025-08-11 20:52:10,927][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057708] [Batch 04149/04869] [00:37:45/00:06:33, 0.546s/it]: train_loss_raw=0.2632, running_loss=0.2965, LR=0.000100
[2025-08-11 20:52:17,449][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057720] [Batch 04161/04869] [00:37:51/00:06:26, 0.546s/it]: train_loss_raw=0.2695, running_loss=0.2967, LR=0.000100
[2025-08-11 20:52:23,976][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057732] [Batch 04173/04869] [00:37:58/00:06:19, 0.546s/it]: train_loss_raw=0.3583, running_loss=0.2980, LR=0.000100
[2025-08-11 20:52:30,412][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057744] [Batch 04185/04869] [00:38:04/00:06:13, 0.546s/it]: train_loss_raw=0.2689, running_loss=0.3003, LR=0.000100
[2025-08-11 20:52:36,875][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057756] [Batch 04197/04869] [00:38:10/00:06:06, 0.546s/it]: train_loss_raw=0.3121, running_loss=0.3018, LR=0.000100
[2025-08-11 20:52:43,298][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057768] [Batch 04209/04869] [00:38:17/00:06:00, 0.546s/it]: train_loss_raw=0.2970, running_loss=0.2993, LR=0.000100
[2025-08-11 20:52:49,850][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057780] [Batch 04221/04869] [00:38:23/00:05:53, 0.546s/it]: train_loss_raw=0.2900, running_loss=0.2985, LR=0.000100
[2025-08-11 20:52:56,341][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057792] [Batch 04233/04869] [00:38:30/00:05:47, 0.546s/it]: train_loss_raw=0.3020, running_loss=0.2985, LR=0.000100
[2025-08-11 20:53:02,838][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057804] [Batch 04245/04869] [00:38:36/00:05:40, 0.546s/it]: train_loss_raw=0.3593, running_loss=0.2986, LR=0.000100
[2025-08-11 20:53:09,338][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057816] [Batch 04257/04869] [00:38:43/00:05:34, 0.546s/it]: train_loss_raw=0.3045, running_loss=0.2996, LR=0.000100
[2025-08-11 20:53:15,803][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057828] [Batch 04269/04869] [00:38:49/00:05:27, 0.546s/it]: train_loss_raw=0.3361, running_loss=0.3013, LR=0.000100
[2025-08-11 20:53:22,255][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057840] [Batch 04281/04869] [00:38:56/00:05:20, 0.546s/it]: train_loss_raw=0.3402, running_loss=0.3052, LR=0.000100
[2025-08-11 20:53:28,728][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057852] [Batch 04293/04869] [00:39:02/00:05:14, 0.546s/it]: train_loss_raw=0.2969, running_loss=0.3046, LR=0.000100
[2025-08-11 20:53:35,229][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057864] [Batch 04305/04869] [00:39:09/00:05:07, 0.546s/it]: train_loss_raw=0.2737, running_loss=0.3072, LR=0.000100
[2025-08-11 20:53:41,661][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057876] [Batch 04317/04869] [00:39:15/00:05:01, 0.546s/it]: train_loss_raw=0.3125, running_loss=0.3075, LR=0.000100
[2025-08-11 20:53:48,168][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057888] [Batch 04329/04869] [00:39:22/00:04:54, 0.546s/it]: train_loss_raw=0.4318, running_loss=0.3065, LR=0.000100
[2025-08-11 20:53:54,645][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057900] [Batch 04341/04869] [00:39:28/00:04:48, 0.546s/it]: train_loss_raw=0.3056, running_loss=0.3044, LR=0.000100
[2025-08-11 20:54:01,143][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057912] [Batch 04353/04869] [00:39:35/00:04:41, 0.546s/it]: train_loss_raw=0.2071, running_loss=0.3039, LR=0.000100
[2025-08-11 20:54:07,541][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057924] [Batch 04365/04869] [00:39:41/00:04:34, 0.546s/it]: train_loss_raw=0.4000, running_loss=0.3053, LR=0.000100
[2025-08-11 20:54:13,998][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057936] [Batch 04377/04869] [00:39:48/00:04:28, 0.546s/it]: train_loss_raw=0.2983, running_loss=0.3069, LR=0.000100
[2025-08-11 20:54:20,490][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057948] [Batch 04389/04869] [00:39:54/00:04:21, 0.546s/it]: train_loss_raw=0.3680, running_loss=0.3037, LR=0.000100
[2025-08-11 20:54:26,976][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057960] [Batch 04401/04869] [00:40:01/00:04:15, 0.546s/it]: train_loss_raw=0.2337, running_loss=0.3033, LR=0.000100
[2025-08-11 20:54:33,413][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057972] [Batch 04413/04869] [00:40:07/00:04:08, 0.546s/it]: train_loss_raw=0.2363, running_loss=0.3033, LR=0.000100
[2025-08-11 20:54:40,017][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057984] [Batch 04425/04869] [00:40:14/00:04:02, 0.546s/it]: train_loss_raw=0.2819, running_loss=0.3038, LR=0.000100
[2025-08-11 20:54:46,524][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 057996] [Batch 04437/04869] [00:40:20/00:03:55, 0.546s/it]: train_loss_raw=0.3180, running_loss=0.3040, LR=0.000100
[2025-08-11 20:54:58,519][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058008] [Batch 04449/04869] [00:40:32/00:03:49, 0.547s/it]: train_loss_raw=0.3710, running_loss=0.3094, LR=0.000100
[2025-08-11 20:55:04,960][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058020] [Batch 04461/04869] [00:40:39/00:03:43, 0.547s/it]: train_loss_raw=0.2681, running_loss=0.3105, LR=0.000100
[2025-08-11 20:55:11,354][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058032] [Batch 04473/04869] [00:40:45/00:03:36, 0.547s/it]: train_loss_raw=0.3137, running_loss=0.3123, LR=0.000100
[2025-08-11 20:55:17,807][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058044] [Batch 04485/04869] [00:40:51/00:03:29, 0.547s/it]: train_loss_raw=0.3250, running_loss=0.3100, LR=0.000100
[2025-08-11 20:55:24,223][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058056] [Batch 04497/04869] [00:40:58/00:03:23, 0.547s/it]: train_loss_raw=0.2411, running_loss=0.3080, LR=0.000100
[2025-08-11 20:55:30,639][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058068] [Batch 04509/04869] [00:41:04/00:03:16, 0.547s/it]: train_loss_raw=0.2628, running_loss=0.3064, LR=0.000100
[2025-08-11 20:55:37,251][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058080] [Batch 04521/04869] [00:41:11/00:03:10, 0.547s/it]: train_loss_raw=0.3078, running_loss=0.3076, LR=0.000100
[2025-08-11 20:55:43,698][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058092] [Batch 04533/04869] [00:41:17/00:03:03, 0.547s/it]: train_loss_raw=0.3452, running_loss=0.3088, LR=0.000100
[2025-08-11 20:55:50,173][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058104] [Batch 04545/04869] [00:41:24/00:02:57, 0.547s/it]: train_loss_raw=0.3837, running_loss=0.3096, LR=0.000100
[2025-08-11 20:55:56,647][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058116] [Batch 04557/04869] [00:41:30/00:02:50, 0.547s/it]: train_loss_raw=0.4436, running_loss=0.3074, LR=0.000100
[2025-08-11 20:56:03,119][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058128] [Batch 04569/04869] [00:41:37/00:02:43, 0.547s/it]: train_loss_raw=0.3665, running_loss=0.3065, LR=0.000100
[2025-08-11 20:56:09,605][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058140] [Batch 04581/04869] [00:41:43/00:02:37, 0.547s/it]: train_loss_raw=0.2681, running_loss=0.3063, LR=0.000100
[2025-08-11 20:56:16,061][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058152] [Batch 04593/04869] [00:41:50/00:02:30, 0.547s/it]: train_loss_raw=0.3448, running_loss=0.3059, LR=0.000100
[2025-08-11 20:56:22,468][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058164] [Batch 04605/04869] [00:41:56/00:02:24, 0.546s/it]: train_loss_raw=0.3599, running_loss=0.3079, LR=0.000100
[2025-08-11 20:56:28,890][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058176] [Batch 04617/04869] [00:42:02/00:02:17, 0.546s/it]: train_loss_raw=0.2891, running_loss=0.3049, LR=0.000100
[2025-08-11 20:56:35,337][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058188] [Batch 04629/04869] [00:42:09/00:02:11, 0.546s/it]: train_loss_raw=0.3822, running_loss=0.3046, LR=0.000100
[2025-08-11 20:56:41,815][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058200] [Batch 04641/04869] [00:42:15/00:02:04, 0.546s/it]: train_loss_raw=0.2638, running_loss=0.3021, LR=0.000100
[2025-08-11 20:56:48,297][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058212] [Batch 04653/04869] [00:42:22/00:01:58, 0.546s/it]: train_loss_raw=0.3945, running_loss=0.3036, LR=0.000100
[2025-08-11 20:56:54,799][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058224] [Batch 04665/04869] [00:42:28/00:01:51, 0.546s/it]: train_loss_raw=0.3757, running_loss=0.3065, LR=0.000100
[2025-08-11 20:57:01,333][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058236] [Batch 04677/04869] [00:42:35/00:01:44, 0.546s/it]: train_loss_raw=0.2229, running_loss=0.3068, LR=0.000100
[2025-08-11 20:57:07,781][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058248] [Batch 04689/04869] [00:42:41/00:01:38, 0.546s/it]: train_loss_raw=0.2748, running_loss=0.3052, LR=0.000100
[2025-08-11 20:57:14,380][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058260] [Batch 04701/04869] [00:42:48/00:01:31, 0.546s/it]: train_loss_raw=0.3377, running_loss=0.3040, LR=0.000100
[2025-08-11 20:57:20,797][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058272] [Batch 04713/04869] [00:42:54/00:01:25, 0.546s/it]: train_loss_raw=0.2484, running_loss=0.3018, LR=0.000100
[2025-08-11 20:57:27,360][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058284] [Batch 04725/04869] [00:43:01/00:01:18, 0.546s/it]: train_loss_raw=0.3265, running_loss=0.3025, LR=0.000100
[2025-08-11 20:57:33,633][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058296] [Batch 04737/04869] [00:43:07/00:01:12, 0.546s/it]: train_loss_raw=0.2915, running_loss=0.3038, LR=0.000100
[2025-08-11 20:57:39,798][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058308] [Batch 04749/04869] [00:43:13/00:01:05, 0.546s/it]: train_loss_raw=0.3314, running_loss=0.3040, LR=0.000100
[2025-08-11 20:57:46,221][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058320] [Batch 04761/04869] [00:43:20/00:00:58, 0.546s/it]: train_loss_raw=0.3537, running_loss=0.3068, LR=0.000100
[2025-08-11 20:57:52,897][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058332] [Batch 04773/04869] [00:43:26/00:00:52, 0.546s/it]: train_loss_raw=0.3467, running_loss=0.3083, LR=0.000100
[2025-08-11 20:57:59,066][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058344] [Batch 04785/04869] [00:43:33/00:00:45, 0.546s/it]: train_loss_raw=0.2497, running_loss=0.3085, LR=0.000100
[2025-08-11 20:58:05,138][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058356] [Batch 04797/04869] [00:43:39/00:00:39, 0.546s/it]: train_loss_raw=0.4285, running_loss=0.3125, LR=0.000100
[2025-08-11 20:58:11,339][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058368] [Batch 04809/04869] [00:43:45/00:00:32, 0.546s/it]: train_loss_raw=0.3564, running_loss=0.3133, LR=0.000100
[2025-08-11 20:58:17,499][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058380] [Batch 04821/04869] [00:43:51/00:00:26, 0.546s/it]: train_loss_raw=0.3966, running_loss=0.3131, LR=0.000100
[2025-08-11 20:58:23,531][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058392] [Batch 04833/04869] [00:43:57/00:00:19, 0.546s/it]: train_loss_raw=0.2379, running_loss=0.3139, LR=0.000100
[2025-08-11 20:58:29,635][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058404] [Batch 04845/04869] [00:44:03/00:00:13, 0.546s/it]: train_loss_raw=0.3183, running_loss=0.3119, LR=0.000100
[2025-08-11 20:58:35,673][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058416] [Batch 04857/04869] [00:44:09/00:00:06, 0.546s/it]: train_loss_raw=0.2813, running_loss=0.3105, LR=0.000100
[2025-08-11 20:58:48,631][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 058428] [Batch 04869/04869] [00:44:22/00:00:00, 0.547s/it]: train_loss_raw=0.2042, running_loss=0.3091, LR=0.000100
[2025-08-11 20:58:52,632][__main__][INFO] - [VALIDATION] [Epoch 11/29] Starting validation.
[2025-08-11 20:59:06,912][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 058429] [Batch 00011/00062] [00:00:14/00:00:59, 1.190s/it]
[2025-08-11 20:59:38,334][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 058429] [Batch 00023/00062] [00:00:45/00:01:12, 1.904s/it]
[2025-08-11 20:59:53,049][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 058429] [Batch 00035/00062] [00:01:00/00:00:43, 1.678s/it]
[2025-08-11 21:00:06,879][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 058429] [Batch 00047/00062] [00:01:14/00:00:21, 1.547s/it]
[2025-08-11 21:00:21,284][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 058429] [Batch 00059/00062] [00:01:28/00:00:02, 1.478s/it]
[2025-08-11 21:00:23,547][__main__][INFO] - [VALIDATION] [Epoch 11/29] train_loss=0.30912, valid_loss=0.36561
[2025-08-11 21:00:23,548][__main__][INFO] - [VALIDATION] [Epoch 11/29] Metrics:
[2025-08-11 21:00:23,548][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_er      0.179
[2025-08-11 21:00:23,548][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_prec    0.646
[2025-08-11 21:00:23,548][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_recall  0.651
[2025-08-11 21:00:23,548][__main__][INFO] - [VALIDATION] [Epoch 11/29] - pep_recall 0.621
[2025-08-11 21:00:23,553][__main__][INFO] - [TRAIN] [Epoch 11/29] Epoch complete, total time 09:05:02, remaining time 13:37:33, 00:45:25 per epoch
[2025-08-11 21:00:32,668][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058440] [Batch 00012/04869] [00:00:08/00:59:33, 0.736s/it]: train_loss_raw=0.2940, running_loss=0.1898, LR=0.000100
[2025-08-11 21:00:39,184][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058452] [Batch 00024/04869] [00:00:15/00:51:37, 0.639s/it]: train_loss_raw=0.2399, running_loss=0.1982, LR=0.000100
[2025-08-11 21:00:45,252][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058464] [Batch 00036/04869] [00:00:21/00:47:54, 0.595s/it]: train_loss_raw=0.2949, running_loss=0.2060, LR=0.000100
[2025-08-11 21:00:51,317][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058476] [Batch 00048/04869] [00:00:27/00:45:59, 0.572s/it]: train_loss_raw=0.2552, running_loss=0.2126, LR=0.000100
[2025-08-11 21:00:57,381][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058488] [Batch 00060/04869] [00:00:33/00:44:48, 0.559s/it]: train_loss_raw=0.2641, running_loss=0.2154, LR=0.000100
[2025-08-11 21:01:03,496][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058500] [Batch 00072/04869] [00:00:39/00:44:02, 0.551s/it]: train_loss_raw=0.2653, running_loss=0.2198, LR=0.000100
[2025-08-11 21:01:09,498][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058512] [Batch 00084/04869] [00:00:45/00:43:20, 0.544s/it]: train_loss_raw=0.3528, running_loss=0.2253, LR=0.000100
[2025-08-11 21:01:15,488][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058524] [Batch 00096/04869] [00:00:51/00:42:47, 0.538s/it]: train_loss_raw=0.1674, running_loss=0.2254, LR=0.000100
[2025-08-11 21:01:21,594][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058536] [Batch 00108/04869] [00:00:57/00:42:26, 0.535s/it]: train_loss_raw=0.2730, running_loss=0.2274, LR=0.000100
[2025-08-11 21:01:27,594][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058548] [Batch 00120/04869] [00:01:03/00:42:03, 0.531s/it]: train_loss_raw=0.2349, running_loss=0.2305, LR=0.000100
[2025-08-11 21:01:33,589][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058560] [Batch 00132/04869] [00:01:09/00:41:43, 0.528s/it]: train_loss_raw=0.2403, running_loss=0.2319, LR=0.000100
[2025-08-11 21:01:39,636][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058572] [Batch 00144/04869] [00:01:15/00:41:27, 0.526s/it]: train_loss_raw=0.3016, running_loss=0.2355, LR=0.000100
[2025-08-11 21:01:45,690][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058584] [Batch 00156/04869] [00:01:21/00:41:12, 0.525s/it]: train_loss_raw=0.2963, running_loss=0.2392, LR=0.000100
[2025-08-11 21:01:51,837][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058596] [Batch 00168/04869] [00:01:27/00:41:02, 0.524s/it]: train_loss_raw=0.2257, running_loss=0.2381, LR=0.000100
[2025-08-11 21:01:57,962][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058608] [Batch 00180/04869] [00:01:34/00:40:51, 0.523s/it]: train_loss_raw=0.2836, running_loss=0.2402, LR=0.000100
[2025-08-11 21:02:03,943][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058620] [Batch 00192/04869] [00:01:40/00:40:38, 0.521s/it]: train_loss_raw=0.2563, running_loss=0.2432, LR=0.000100
[2025-08-11 21:02:10,138][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058632] [Batch 00204/04869] [00:01:46/00:40:30, 0.521s/it]: train_loss_raw=0.2581, running_loss=0.2433, LR=0.000100
[2025-08-11 21:02:16,265][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058644] [Batch 00216/04869] [00:01:52/00:40:21, 0.520s/it]: train_loss_raw=0.2733, running_loss=0.2431, LR=0.000100
[2025-08-11 21:02:22,278][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058656] [Batch 00228/04869] [00:01:58/00:40:10, 0.519s/it]: train_loss_raw=0.2851, running_loss=0.2457, LR=0.000100
[2025-08-11 21:02:28,437][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058668] [Batch 00240/04869] [00:02:04/00:40:03, 0.519s/it]: train_loss_raw=0.2311, running_loss=0.2452, LR=0.000100
[2025-08-11 21:02:34,528][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058680] [Batch 00252/04869] [00:02:10/00:39:54, 0.519s/it]: train_loss_raw=0.2852, running_loss=0.2468, LR=0.000100
[2025-08-11 21:02:40,607][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058692] [Batch 00264/04869] [00:02:16/00:39:45, 0.518s/it]: train_loss_raw=0.2488, running_loss=0.2480, LR=0.000100
[2025-08-11 21:02:46,681][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058704] [Batch 00276/04869] [00:02:22/00:39:37, 0.518s/it]: train_loss_raw=0.2837, running_loss=0.2477, LR=0.000100
[2025-08-11 21:02:52,798][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058716] [Batch 00288/04869] [00:02:28/00:39:29, 0.517s/it]: train_loss_raw=0.2918, running_loss=0.2478, LR=0.000100
[2025-08-11 21:02:59,002][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058728] [Batch 00300/04869] [00:02:35/00:39:23, 0.517s/it]: train_loss_raw=0.2466, running_loss=0.2482, LR=0.000100
[2025-08-11 21:03:05,037][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058740] [Batch 00312/04869] [00:02:41/00:39:14, 0.517s/it]: train_loss_raw=0.3410, running_loss=0.2499, LR=0.000100
[2025-08-11 21:03:11,022][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058752] [Batch 00324/04869] [00:02:47/00:39:05, 0.516s/it]: train_loss_raw=0.2058, running_loss=0.2491, LR=0.000100
[2025-08-11 21:03:17,086][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058764] [Batch 00336/04869] [00:02:53/00:38:57, 0.516s/it]: train_loss_raw=0.2167, running_loss=0.2515, LR=0.000100
[2025-08-11 21:03:23,175][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058776] [Batch 00348/04869] [00:02:59/00:38:49, 0.515s/it]: train_loss_raw=0.2578, running_loss=0.2513, LR=0.000100
[2025-08-11 21:03:29,234][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058788] [Batch 00360/04869] [00:03:05/00:38:42, 0.515s/it]: train_loss_raw=0.2250, running_loss=0.2501, LR=0.000100
[2025-08-11 21:03:35,319][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058800] [Batch 00372/04869] [00:03:11/00:38:34, 0.515s/it]: train_loss_raw=0.2551, running_loss=0.2507, LR=0.000100
[2025-08-11 21:03:41,377][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058812] [Batch 00384/04869] [00:03:17/00:38:27, 0.514s/it]: train_loss_raw=0.2444, running_loss=0.2505, LR=0.000100
[2025-08-11 21:03:47,512][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058824] [Batch 00396/04869] [00:03:23/00:38:20, 0.514s/it]: train_loss_raw=0.2394, running_loss=0.2529, LR=0.000100
[2025-08-11 21:03:53,628][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058836] [Batch 00408/04869] [00:03:29/00:38:13, 0.514s/it]: train_loss_raw=0.2207, running_loss=0.2503, LR=0.000100
[2025-08-11 21:03:59,662][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058848] [Batch 00420/04869] [00:03:35/00:38:06, 0.514s/it]: train_loss_raw=0.2402, running_loss=0.2519, LR=0.000100
[2025-08-11 21:04:05,658][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058860] [Batch 00432/04869] [00:03:41/00:37:58, 0.513s/it]: train_loss_raw=0.3394, running_loss=0.2553, LR=0.000100
[2025-08-11 21:04:11,788][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058872] [Batch 00444/04869] [00:03:47/00:37:51, 0.513s/it]: train_loss_raw=0.2555, running_loss=0.2574, LR=0.000100
[2025-08-11 21:04:17,840][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058884] [Batch 00456/04869] [00:03:54/00:37:44, 0.513s/it]: train_loss_raw=0.2757, running_loss=0.2599, LR=0.000100
[2025-08-11 21:04:23,960][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058896] [Batch 00468/04869] [00:04:00/00:37:38, 0.513s/it]: train_loss_raw=0.3000, running_loss=0.2608, LR=0.000100
[2025-08-11 21:04:30,009][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058908] [Batch 00480/04869] [00:04:06/00:37:30, 0.513s/it]: train_loss_raw=0.3100, running_loss=0.2622, LR=0.000100
[2025-08-11 21:04:36,140][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058920] [Batch 00492/04869] [00:04:12/00:37:24, 0.513s/it]: train_loss_raw=0.2969, running_loss=0.2621, LR=0.000100
[2025-08-11 21:04:42,335][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058932] [Batch 00504/04869] [00:04:18/00:37:18, 0.513s/it]: train_loss_raw=0.1534, running_loss=0.2606, LR=0.000100
[2025-08-11 21:04:48,418][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058944] [Batch 00516/04869] [00:04:24/00:37:12, 0.513s/it]: train_loss_raw=0.2698, running_loss=0.2585, LR=0.000100
[2025-08-11 21:04:54,417][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058956] [Batch 00528/04869] [00:04:30/00:37:04, 0.512s/it]: train_loss_raw=0.2982, running_loss=0.2577, LR=0.000100
[2025-08-11 21:05:00,826][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058968] [Batch 00540/04869] [00:04:36/00:37:00, 0.513s/it]: train_loss_raw=0.2809, running_loss=0.2596, LR=0.000100
[2025-08-11 21:05:07,469][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058980] [Batch 00552/04869] [00:04:43/00:36:58, 0.514s/it]: train_loss_raw=0.2520, running_loss=0.2593, LR=0.000100
[2025-08-11 21:05:14,083][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 058992] [Batch 00564/04869] [00:04:50/00:36:55, 0.515s/it]: train_loss_raw=0.2295, running_loss=0.2569, LR=0.000100
[2025-08-11 21:05:20,587][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059004] [Batch 00576/04869] [00:04:56/00:36:51, 0.515s/it]: train_loss_raw=0.1955, running_loss=0.2582, LR=0.000100
[2025-08-11 21:05:27,146][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059016] [Batch 00588/04869] [00:05:03/00:36:48, 0.516s/it]: train_loss_raw=0.2357, running_loss=0.2561, LR=0.000100
[2025-08-11 21:05:33,538][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059028] [Batch 00600/04869] [00:05:09/00:36:43, 0.516s/it]: train_loss_raw=0.3696, running_loss=0.2567, LR=0.000100
[2025-08-11 21:05:39,609][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059040] [Batch 00612/04869] [00:05:15/00:36:36, 0.516s/it]: train_loss_raw=0.3185, running_loss=0.2587, LR=0.000100
[2025-08-11 21:05:45,623][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059052] [Batch 00624/04869] [00:05:21/00:36:29, 0.516s/it]: train_loss_raw=0.3387, running_loss=0.2597, LR=0.000100
[2025-08-11 21:05:51,688][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059064] [Batch 00636/04869] [00:05:27/00:36:22, 0.515s/it]: train_loss_raw=0.2766, running_loss=0.2573, LR=0.000100
[2025-08-11 21:05:57,645][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059076] [Batch 00648/04869] [00:05:33/00:36:14, 0.515s/it]: train_loss_raw=0.3299, running_loss=0.2586, LR=0.000100
[2025-08-11 21:06:03,619][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059088] [Batch 00660/04869] [00:05:39/00:36:06, 0.515s/it]: train_loss_raw=0.2922, running_loss=0.2578, LR=0.000100
[2025-08-11 21:06:09,817][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059100] [Batch 00672/04869] [00:05:45/00:36:00, 0.515s/it]: train_loss_raw=0.2723, running_loss=0.2612, LR=0.000100
[2025-08-11 21:06:15,953][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059112] [Batch 00684/04869] [00:05:52/00:35:54, 0.515s/it]: train_loss_raw=0.2282, running_loss=0.2605, LR=0.000100
[2025-08-11 21:06:22,065][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059124] [Batch 00696/04869] [00:05:58/00:35:47, 0.515s/it]: train_loss_raw=0.2957, running_loss=0.2607, LR=0.000100
[2025-08-11 21:06:28,078][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059136] [Batch 00708/04869] [00:06:04/00:35:40, 0.514s/it]: train_loss_raw=0.2592, running_loss=0.2625, LR=0.000100
[2025-08-11 21:06:34,119][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059148] [Batch 00720/04869] [00:06:10/00:35:33, 0.514s/it]: train_loss_raw=0.2394, running_loss=0.2621, LR=0.000100
[2025-08-11 21:06:40,168][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059160] [Batch 00732/04869] [00:06:16/00:35:26, 0.514s/it]: train_loss_raw=0.2604, running_loss=0.2605, LR=0.000100
[2025-08-11 21:06:46,186][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059172] [Batch 00744/04869] [00:06:22/00:35:19, 0.514s/it]: train_loss_raw=0.2910, running_loss=0.2622, LR=0.000100
[2025-08-11 21:06:52,327][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059184] [Batch 00756/04869] [00:06:28/00:35:13, 0.514s/it]: train_loss_raw=0.1871, running_loss=0.2630, LR=0.000100
[2025-08-11 21:06:58,363][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059196] [Batch 00768/04869] [00:06:34/00:35:06, 0.514s/it]: train_loss_raw=0.2599, running_loss=0.2636, LR=0.000100
[2025-08-11 21:07:04,858][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059208] [Batch 00780/04869] [00:06:41/00:35:02, 0.514s/it]: train_loss_raw=0.2775, running_loss=0.2646, LR=0.000100
[2025-08-11 21:07:11,158][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059220] [Batch 00792/04869] [00:06:47/00:34:56, 0.514s/it]: train_loss_raw=0.2316, running_loss=0.2624, LR=0.000100
[2025-08-11 21:07:17,437][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059232] [Batch 00804/04869] [00:06:53/00:34:51, 0.514s/it]: train_loss_raw=0.2453, running_loss=0.2630, LR=0.000100
[2025-08-11 21:07:23,803][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059244] [Batch 00816/04869] [00:06:59/00:34:45, 0.515s/it]: train_loss_raw=0.2857, running_loss=0.2647, LR=0.000100
[2025-08-11 21:07:29,979][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059256] [Batch 00828/04869] [00:07:06/00:34:39, 0.515s/it]: train_loss_raw=0.2424, running_loss=0.2646, LR=0.000100
[2025-08-11 21:07:36,267][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059268] [Batch 00840/04869] [00:07:12/00:34:34, 0.515s/it]: train_loss_raw=0.2719, running_loss=0.2638, LR=0.000100
[2025-08-11 21:07:42,291][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059280] [Batch 00852/04869] [00:07:18/00:34:27, 0.515s/it]: train_loss_raw=0.3091, running_loss=0.2676, LR=0.000100
[2025-08-11 21:07:48,386][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059292] [Batch 00864/04869] [00:07:24/00:34:20, 0.515s/it]: train_loss_raw=0.2331, running_loss=0.2686, LR=0.000100
[2025-08-11 21:07:54,777][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059304] [Batch 00876/04869] [00:07:30/00:34:15, 0.515s/it]: train_loss_raw=0.2593, running_loss=0.2665, LR=0.000100
[2025-08-11 21:08:01,307][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059316] [Batch 00888/04869] [00:07:37/00:34:10, 0.515s/it]: train_loss_raw=0.2838, running_loss=0.2665, LR=0.000100
[2025-08-11 21:08:07,690][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059328] [Batch 00900/04869] [00:07:43/00:34:05, 0.515s/it]: train_loss_raw=0.3712, running_loss=0.2694, LR=0.000100
[2025-08-11 21:08:13,745][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059340] [Batch 00912/04869] [00:07:49/00:33:58, 0.515s/it]: train_loss_raw=0.2361, running_loss=0.2696, LR=0.000100
[2025-08-11 21:08:19,815][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059352] [Batch 00924/04869] [00:07:55/00:33:52, 0.515s/it]: train_loss_raw=0.3178, running_loss=0.2705, LR=0.000100
[2025-08-11 21:08:25,890][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059364] [Batch 00936/04869] [00:08:02/00:33:45, 0.515s/it]: train_loss_raw=0.2289, running_loss=0.2689, LR=0.000100
[2025-08-11 21:08:32,017][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059376] [Batch 00948/04869] [00:08:08/00:33:39, 0.515s/it]: train_loss_raw=0.2305, running_loss=0.2707, LR=0.000100
[2025-08-11 21:08:38,144][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059388] [Batch 00960/04869] [00:08:14/00:33:32, 0.515s/it]: train_loss_raw=0.3281, running_loss=0.2723, LR=0.000100
[2025-08-11 21:08:44,297][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059400] [Batch 00972/04869] [00:08:20/00:33:26, 0.515s/it]: train_loss_raw=0.2319, running_loss=0.2687, LR=0.000100
[2025-08-11 21:08:50,479][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059412] [Batch 00984/04869] [00:08:26/00:33:20, 0.515s/it]: train_loss_raw=0.3010, running_loss=0.2707, LR=0.000100
[2025-08-11 21:08:56,493][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059424] [Batch 00996/04869] [00:08:32/00:33:13, 0.515s/it]: train_loss_raw=0.1709, running_loss=0.2702, LR=0.000100
[2025-08-11 21:09:02,501][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059436] [Batch 01008/04869] [00:08:38/00:33:06, 0.515s/it]: train_loss_raw=0.3162, running_loss=0.2712, LR=0.000100
[2025-08-11 21:09:08,770][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059448] [Batch 01020/04869] [00:08:44/00:33:00, 0.515s/it]: train_loss_raw=0.3277, running_loss=0.2760, LR=0.000100
[2025-08-11 21:09:15,208][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059460] [Batch 01032/04869] [00:08:51/00:32:55, 0.515s/it]: train_loss_raw=0.2422, running_loss=0.2769, LR=0.000100
[2025-08-11 21:09:21,246][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059472] [Batch 01044/04869] [00:08:57/00:32:48, 0.515s/it]: train_loss_raw=0.2920, running_loss=0.2762, LR=0.000100
[2025-08-11 21:09:27,355][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059484] [Batch 01056/04869] [00:09:03/00:32:42, 0.515s/it]: train_loss_raw=0.3045, running_loss=0.2764, LR=0.000100
[2025-08-11 21:09:33,550][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059496] [Batch 01068/04869] [00:09:09/00:32:36, 0.515s/it]: train_loss_raw=0.2255, running_loss=0.2734, LR=0.000100
[2025-08-11 21:09:39,584][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059508] [Batch 01080/04869] [00:09:15/00:32:29, 0.515s/it]: train_loss_raw=0.2697, running_loss=0.2728, LR=0.000100
[2025-08-11 21:09:45,577][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059520] [Batch 01092/04869] [00:09:21/00:32:22, 0.514s/it]: train_loss_raw=0.2481, running_loss=0.2715, LR=0.000100
[2025-08-11 21:09:51,933][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059532] [Batch 01104/04869] [00:09:28/00:32:17, 0.515s/it]: train_loss_raw=0.3013, running_loss=0.2714, LR=0.000100
[2025-08-11 21:09:58,591][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059544] [Batch 01116/04869] [00:09:34/00:32:12, 0.515s/it]: train_loss_raw=0.2998, running_loss=0.2731, LR=0.000100
[2025-08-11 21:10:04,798][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059556] [Batch 01128/04869] [00:09:40/00:32:06, 0.515s/it]: train_loss_raw=0.2767, running_loss=0.2696, LR=0.000100
[2025-08-11 21:10:11,003][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059568] [Batch 01140/04869] [00:09:47/00:32:00, 0.515s/it]: train_loss_raw=0.3323, running_loss=0.2696, LR=0.000100
[2025-08-11 21:10:17,552][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059580] [Batch 01152/04869] [00:09:53/00:31:55, 0.515s/it]: train_loss_raw=0.3781, running_loss=0.2717, LR=0.000100
[2025-08-11 21:10:24,100][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059592] [Batch 01164/04869] [00:10:00/00:31:50, 0.516s/it]: train_loss_raw=0.2408, running_loss=0.2712, LR=0.000100
[2025-08-11 21:10:30,332][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059604] [Batch 01176/04869] [00:10:06/00:31:44, 0.516s/it]: train_loss_raw=0.2334, running_loss=0.2712, LR=0.000100
[2025-08-11 21:10:36,477][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059616] [Batch 01188/04869] [00:10:12/00:31:38, 0.516s/it]: train_loss_raw=0.2055, running_loss=0.2684, LR=0.000100
[2025-08-11 21:10:42,589][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059628] [Batch 01200/04869] [00:10:18/00:31:31, 0.516s/it]: train_loss_raw=0.2926, running_loss=0.2703, LR=0.000100
[2025-08-11 21:10:48,655][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059640] [Batch 01212/04869] [00:10:24/00:31:25, 0.516s/it]: train_loss_raw=0.2715, running_loss=0.2707, LR=0.000100
[2025-08-11 21:10:54,705][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059652] [Batch 01224/04869] [00:10:30/00:31:18, 0.515s/it]: train_loss_raw=0.2652, running_loss=0.2687, LR=0.000100
[2025-08-11 21:11:00,882][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059664] [Batch 01236/04869] [00:10:37/00:31:12, 0.515s/it]: train_loss_raw=0.2748, running_loss=0.2726, LR=0.000100
[2025-08-11 21:11:06,908][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059676] [Batch 01248/04869] [00:10:43/00:31:05, 0.515s/it]: train_loss_raw=0.2202, running_loss=0.2732, LR=0.000100
[2025-08-11 21:11:12,922][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059688] [Batch 01260/04869] [00:10:49/00:30:59, 0.515s/it]: train_loss_raw=0.2752, running_loss=0.2726, LR=0.000100
[2025-08-11 21:11:19,137][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059700] [Batch 01272/04869] [00:10:55/00:30:53, 0.515s/it]: train_loss_raw=0.3323, running_loss=0.2730, LR=0.000100
[2025-08-11 21:11:25,309][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059712] [Batch 01284/04869] [00:11:01/00:30:46, 0.515s/it]: train_loss_raw=0.3116, running_loss=0.2724, LR=0.000100
[2025-08-11 21:11:31,624][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059724] [Batch 01296/04869] [00:11:07/00:30:41, 0.515s/it]: train_loss_raw=0.2670, running_loss=0.2743, LR=0.000100
[2025-08-11 21:11:37,961][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059736] [Batch 01308/04869] [00:11:14/00:30:35, 0.515s/it]: train_loss_raw=0.2300, running_loss=0.2746, LR=0.000100
[2025-08-11 21:11:44,219][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059748] [Batch 01320/04869] [00:11:20/00:30:29, 0.515s/it]: train_loss_raw=0.1931, running_loss=0.2732, LR=0.000100
[2025-08-11 21:11:50,585][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059760] [Batch 01332/04869] [00:11:26/00:30:23, 0.516s/it]: train_loss_raw=0.3583, running_loss=0.2748, LR=0.000100
[2025-08-11 21:11:56,846][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059772] [Batch 01344/04869] [00:11:33/00:30:17, 0.516s/it]: train_loss_raw=0.2280, running_loss=0.2743, LR=0.000100
[2025-08-11 21:12:03,061][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059784] [Batch 01356/04869] [00:11:39/00:30:11, 0.516s/it]: train_loss_raw=0.2366, running_loss=0.2743, LR=0.000100
[2025-08-11 21:12:09,167][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059796] [Batch 01368/04869] [00:11:45/00:30:05, 0.516s/it]: train_loss_raw=0.2841, running_loss=0.2750, LR=0.000100
[2025-08-11 21:12:15,581][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059808] [Batch 01380/04869] [00:11:51/00:29:59, 0.516s/it]: train_loss_raw=0.2779, running_loss=0.2751, LR=0.000100
[2025-08-11 21:12:21,658][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059820] [Batch 01392/04869] [00:11:57/00:29:53, 0.516s/it]: train_loss_raw=0.2830, running_loss=0.2771, LR=0.000100
[2025-08-11 21:12:27,964][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059832] [Batch 01404/04869] [00:12:04/00:29:47, 0.516s/it]: train_loss_raw=0.3519, running_loss=0.2792, LR=0.000100
[2025-08-11 21:12:34,161][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059844] [Batch 01416/04869] [00:12:10/00:29:40, 0.516s/it]: train_loss_raw=0.2705, running_loss=0.2790, LR=0.000100
[2025-08-11 21:12:40,280][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059856] [Batch 01428/04869] [00:12:16/00:29:34, 0.516s/it]: train_loss_raw=0.2795, running_loss=0.2789, LR=0.000100
[2025-08-11 21:12:46,461][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059868] [Batch 01440/04869] [00:12:22/00:29:28, 0.516s/it]: train_loss_raw=0.3249, running_loss=0.2787, LR=0.000100
[2025-08-11 21:12:52,877][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059880] [Batch 01452/04869] [00:12:29/00:29:22, 0.516s/it]: train_loss_raw=0.2638, running_loss=0.2799, LR=0.000100
[2025-08-11 21:12:58,997][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059892] [Batch 01464/04869] [00:12:35/00:29:16, 0.516s/it]: train_loss_raw=0.2065, running_loss=0.2812, LR=0.000100
[2025-08-11 21:13:05,025][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059904] [Batch 01476/04869] [00:12:41/00:29:09, 0.516s/it]: train_loss_raw=0.2354, running_loss=0.2795, LR=0.000100
[2025-08-11 21:13:11,024][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059916] [Batch 01488/04869] [00:12:47/00:29:03, 0.516s/it]: train_loss_raw=0.2800, running_loss=0.2784, LR=0.000100
[2025-08-11 21:13:17,046][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059928] [Batch 01500/04869] [00:12:53/00:28:56, 0.515s/it]: train_loss_raw=0.3341, running_loss=0.2769, LR=0.000100
[2025-08-11 21:13:23,107][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059940] [Batch 01512/04869] [00:12:59/00:28:50, 0.515s/it]: train_loss_raw=0.3419, running_loss=0.2771, LR=0.000100
[2025-08-11 21:13:29,127][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059952] [Batch 01524/04869] [00:13:05/00:28:43, 0.515s/it]: train_loss_raw=0.2764, running_loss=0.2760, LR=0.000100
[2025-08-11 21:13:35,202][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059964] [Batch 01536/04869] [00:13:11/00:28:37, 0.515s/it]: train_loss_raw=0.2163, running_loss=0.2753, LR=0.000100
[2025-08-11 21:13:41,251][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059976] [Batch 01548/04869] [00:13:17/00:28:30, 0.515s/it]: train_loss_raw=0.3517, running_loss=0.2758, LR=0.000100
[2025-08-11 21:13:47,231][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 059988] [Batch 01560/04869] [00:13:23/00:28:24, 0.515s/it]: train_loss_raw=0.3130, running_loss=0.2770, LR=0.000100
[2025-08-11 21:13:53,215][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060000] [Batch 01572/04869] [00:13:29/00:28:17, 0.515s/it]: train_loss_raw=0.2227, running_loss=0.2749, LR=0.000100
[2025-08-11 21:14:03,669][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060012] [Batch 01584/04869] [00:13:39/00:28:20, 0.518s/it]: train_loss_raw=0.2198, running_loss=0.2756, LR=0.000100
[2025-08-11 21:14:09,702][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060024] [Batch 01596/04869] [00:13:45/00:28:13, 0.517s/it]: train_loss_raw=0.2896, running_loss=0.2759, LR=0.000100
[2025-08-11 21:14:15,765][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060036] [Batch 01608/04869] [00:13:51/00:28:07, 0.517s/it]: train_loss_raw=0.2658, running_loss=0.2767, LR=0.000100
[2025-08-11 21:14:21,774][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060048] [Batch 01620/04869] [00:13:57/00:28:00, 0.517s/it]: train_loss_raw=0.2397, running_loss=0.2753, LR=0.000100
[2025-08-11 21:14:27,829][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060060] [Batch 01632/04869] [00:14:03/00:27:54, 0.517s/it]: train_loss_raw=0.2708, running_loss=0.2737, LR=0.000100
[2025-08-11 21:14:33,829][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060072] [Batch 01644/04869] [00:14:09/00:27:47, 0.517s/it]: train_loss_raw=0.2757, running_loss=0.2742, LR=0.000100
[2025-08-11 21:14:39,836][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060084] [Batch 01656/04869] [00:14:15/00:27:40, 0.517s/it]: train_loss_raw=0.2107, running_loss=0.2744, LR=0.000100
[2025-08-11 21:14:45,925][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060096] [Batch 01668/04869] [00:14:22/00:27:34, 0.517s/it]: train_loss_raw=0.2740, running_loss=0.2732, LR=0.000100
[2025-08-11 21:14:52,005][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060108] [Batch 01680/04869] [00:14:28/00:27:27, 0.517s/it]: train_loss_raw=0.2824, running_loss=0.2740, LR=0.000100
[2025-08-11 21:14:57,984][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060120] [Batch 01692/04869] [00:14:34/00:27:21, 0.517s/it]: train_loss_raw=0.2047, running_loss=0.2738, LR=0.000100
[2025-08-11 21:15:04,049][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060132] [Batch 01704/04869] [00:14:40/00:27:14, 0.517s/it]: train_loss_raw=0.2702, running_loss=0.2747, LR=0.000100
[2025-08-11 21:15:10,065][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060144] [Batch 01716/04869] [00:14:46/00:27:08, 0.516s/it]: train_loss_raw=0.2544, running_loss=0.2712, LR=0.000100
[2025-08-11 21:15:16,224][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060156] [Batch 01728/04869] [00:14:52/00:27:02, 0.516s/it]: train_loss_raw=0.3126, running_loss=0.2721, LR=0.000100
[2025-08-11 21:15:22,141][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060168] [Batch 01740/04869] [00:14:58/00:26:55, 0.516s/it]: train_loss_raw=0.1943, running_loss=0.2718, LR=0.000100
[2025-08-11 21:15:28,186][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060180] [Batch 01752/04869] [00:15:04/00:26:48, 0.516s/it]: train_loss_raw=0.3011, running_loss=0.2758, LR=0.000100
[2025-08-11 21:15:34,220][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060192] [Batch 01764/04869] [00:15:10/00:26:42, 0.516s/it]: train_loss_raw=0.3258, running_loss=0.2766, LR=0.000100
[2025-08-11 21:15:40,546][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060204] [Batch 01776/04869] [00:15:16/00:26:36, 0.516s/it]: train_loss_raw=0.2865, running_loss=0.2766, LR=0.000100
[2025-08-11 21:15:46,720][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060216] [Batch 01788/04869] [00:15:22/00:26:30, 0.516s/it]: train_loss_raw=0.2730, running_loss=0.2749, LR=0.000100
[2025-08-11 21:15:52,796][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060228] [Batch 01800/04869] [00:15:28/00:26:23, 0.516s/it]: train_loss_raw=0.3310, running_loss=0.2764, LR=0.000100
[2025-08-11 21:15:58,805][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060240] [Batch 01812/04869] [00:15:34/00:26:17, 0.516s/it]: train_loss_raw=0.3429, running_loss=0.2787, LR=0.000100
[2025-08-11 21:16:04,857][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060252] [Batch 01824/04869] [00:15:41/00:26:10, 0.516s/it]: train_loss_raw=0.3374, running_loss=0.2801, LR=0.000100
[2025-08-11 21:16:11,297][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060264] [Batch 01836/04869] [00:15:47/00:26:05, 0.516s/it]: train_loss_raw=0.2380, running_loss=0.2791, LR=0.000100
[2025-08-11 21:16:17,548][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060276] [Batch 01848/04869] [00:15:53/00:25:59, 0.516s/it]: train_loss_raw=0.2755, running_loss=0.2796, LR=0.000100
[2025-08-11 21:16:24,034][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060288] [Batch 01860/04869] [00:16:00/00:25:53, 0.516s/it]: train_loss_raw=0.2771, running_loss=0.2797, LR=0.000100
[2025-08-11 21:16:30,236][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060300] [Batch 01872/04869] [00:16:06/00:25:47, 0.516s/it]: train_loss_raw=0.2205, running_loss=0.2798, LR=0.000100
[2025-08-11 21:16:36,255][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060312] [Batch 01884/04869] [00:16:12/00:25:40, 0.516s/it]: train_loss_raw=0.3683, running_loss=0.2811, LR=0.000100
[2025-08-11 21:16:42,253][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060324] [Batch 01896/04869] [00:16:18/00:25:34, 0.516s/it]: train_loss_raw=0.2865, running_loss=0.2814, LR=0.000100
[2025-08-11 21:16:48,255][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060336] [Batch 01908/04869] [00:16:24/00:25:27, 0.516s/it]: train_loss_raw=0.2593, running_loss=0.2808, LR=0.000100
[2025-08-11 21:16:54,581][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060348] [Batch 01920/04869] [00:16:30/00:25:21, 0.516s/it]: train_loss_raw=0.3204, running_loss=0.2800, LR=0.000100
[2025-08-11 21:17:01,053][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060360] [Batch 01932/04869] [00:16:37/00:25:15, 0.516s/it]: train_loss_raw=0.2675, running_loss=0.2785, LR=0.000100
[2025-08-11 21:17:07,303][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060372] [Batch 01944/04869] [00:16:43/00:25:09, 0.516s/it]: train_loss_raw=0.2979, running_loss=0.2757, LR=0.000100
[2025-08-11 21:17:13,458][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060384] [Batch 01956/04869] [00:16:49/00:25:03, 0.516s/it]: train_loss_raw=0.2949, running_loss=0.2757, LR=0.000100
[2025-08-11 21:17:19,947][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060396] [Batch 01968/04869] [00:16:56/00:24:57, 0.516s/it]: train_loss_raw=0.2345, running_loss=0.2762, LR=0.000100
[2025-08-11 21:17:26,514][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060408] [Batch 01980/04869] [00:17:02/00:24:52, 0.517s/it]: train_loss_raw=0.3110, running_loss=0.2775, LR=0.000100
[2025-08-11 21:17:32,672][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060420] [Batch 01992/04869] [00:17:08/00:24:45, 0.516s/it]: train_loss_raw=0.2502, running_loss=0.2774, LR=0.000100
[2025-08-11 21:17:38,966][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060432] [Batch 02004/04869] [00:17:15/00:24:39, 0.517s/it]: train_loss_raw=0.2939, running_loss=0.2778, LR=0.000100
[2025-08-11 21:17:45,418][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060444] [Batch 02016/04869] [00:17:21/00:24:34, 0.517s/it]: train_loss_raw=0.3163, running_loss=0.2791, LR=0.000100
[2025-08-11 21:18:20,010][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060456] [Batch 02028/04869] [00:17:56/00:25:07, 0.531s/it]: train_loss_raw=0.3172, running_loss=0.2774, LR=0.000100
[2025-08-11 21:18:26,105][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060468] [Batch 02040/04869] [00:18:02/00:25:00, 0.531s/it]: train_loss_raw=0.2573, running_loss=0.2778, LR=0.000100
[2025-08-11 21:18:32,178][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060480] [Batch 02052/04869] [00:18:08/00:24:54, 0.530s/it]: train_loss_raw=0.3638, running_loss=0.2802, LR=0.000100
[2025-08-11 21:18:38,253][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060492] [Batch 02064/04869] [00:18:14/00:24:47, 0.530s/it]: train_loss_raw=0.2866, running_loss=0.2822, LR=0.000100
[2025-08-11 21:18:44,264][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060504] [Batch 02076/04869] [00:18:20/00:24:40, 0.530s/it]: train_loss_raw=0.2569, running_loss=0.2811, LR=0.000100
[2025-08-11 21:18:50,288][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060516] [Batch 02088/04869] [00:18:26/00:24:33, 0.530s/it]: train_loss_raw=0.2619, running_loss=0.2815, LR=0.000100
[2025-08-11 21:18:56,324][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060528] [Batch 02100/04869] [00:18:32/00:24:26, 0.530s/it]: train_loss_raw=0.2524, running_loss=0.2811, LR=0.000100
[2025-08-11 21:19:02,331][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060540] [Batch 02112/04869] [00:18:38/00:24:20, 0.530s/it]: train_loss_raw=0.3061, running_loss=0.2807, LR=0.000100
[2025-08-11 21:19:08,276][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060552] [Batch 02124/04869] [00:18:44/00:24:13, 0.529s/it]: train_loss_raw=0.2938, running_loss=0.2824, LR=0.000100
[2025-08-11 21:19:14,229][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060564] [Batch 02136/04869] [00:18:50/00:24:06, 0.529s/it]: train_loss_raw=0.2875, running_loss=0.2825, LR=0.000100
[2025-08-11 21:19:20,293][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060576] [Batch 02148/04869] [00:18:56/00:23:59, 0.529s/it]: train_loss_raw=0.2737, running_loss=0.2822, LR=0.000100
[2025-08-11 21:19:26,315][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060588] [Batch 02160/04869] [00:19:02/00:23:52, 0.529s/it]: train_loss_raw=0.4141, running_loss=0.2839, LR=0.000100
[2025-08-11 21:19:32,403][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060600] [Batch 02172/04869] [00:19:08/00:23:46, 0.529s/it]: train_loss_raw=0.2577, running_loss=0.2836, LR=0.000100
[2025-08-11 21:19:38,507][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060612] [Batch 02184/04869] [00:19:14/00:23:39, 0.529s/it]: train_loss_raw=0.2797, running_loss=0.2816, LR=0.000100
[2025-08-11 21:19:44,567][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060624] [Batch 02196/04869] [00:19:20/00:23:32, 0.529s/it]: train_loss_raw=0.3827, running_loss=0.2834, LR=0.000100
[2025-08-11 21:19:50,581][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060636] [Batch 02208/04869] [00:19:26/00:23:26, 0.528s/it]: train_loss_raw=0.2920, running_loss=0.2841, LR=0.000100
[2025-08-11 21:19:56,587][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060648] [Batch 02220/04869] [00:19:32/00:23:19, 0.528s/it]: train_loss_raw=0.3127, running_loss=0.2856, LR=0.000100
[2025-08-11 21:20:02,619][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060660] [Batch 02232/04869] [00:19:38/00:23:12, 0.528s/it]: train_loss_raw=0.2934, running_loss=0.2861, LR=0.000100
[2025-08-11 21:20:08,670][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060672] [Batch 02244/04869] [00:19:44/00:23:05, 0.528s/it]: train_loss_raw=0.2487, running_loss=0.2863, LR=0.000100
[2025-08-11 21:20:14,655][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060684] [Batch 02256/04869] [00:19:50/00:22:59, 0.528s/it]: train_loss_raw=0.2882, running_loss=0.2851, LR=0.000100
[2025-08-11 21:20:20,781][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060696] [Batch 02268/04869] [00:19:56/00:22:52, 0.528s/it]: train_loss_raw=0.2091, running_loss=0.2859, LR=0.000100
[2025-08-11 21:20:26,953][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060708] [Batch 02280/04869] [00:20:03/00:22:46, 0.528s/it]: train_loss_raw=0.3292, running_loss=0.2867, LR=0.000100
[2025-08-11 21:20:33,247][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060720] [Batch 02292/04869] [00:20:09/00:22:39, 0.528s/it]: train_loss_raw=0.2788, running_loss=0.2838, LR=0.000100
[2025-08-11 21:20:39,285][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060732] [Batch 02304/04869] [00:20:15/00:22:33, 0.528s/it]: train_loss_raw=0.2832, running_loss=0.2867, LR=0.000100
[2025-08-11 21:20:45,364][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060744] [Batch 02316/04869] [00:20:21/00:22:26, 0.527s/it]: train_loss_raw=0.2506, running_loss=0.2859, LR=0.000100
[2025-08-11 21:20:51,353][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060756] [Batch 02328/04869] [00:20:27/00:22:19, 0.527s/it]: train_loss_raw=0.2524, running_loss=0.2830, LR=0.000100
[2025-08-11 21:20:57,351][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060768] [Batch 02340/04869] [00:20:33/00:22:13, 0.527s/it]: train_loss_raw=0.3059, running_loss=0.2842, LR=0.000100
[2025-08-11 21:21:03,719][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060780] [Batch 02352/04869] [00:20:39/00:22:06, 0.527s/it]: train_loss_raw=0.2717, running_loss=0.2833, LR=0.000100
[2025-08-11 21:21:09,849][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060792] [Batch 02364/04869] [00:20:46/00:22:00, 0.527s/it]: train_loss_raw=0.3074, running_loss=0.2820, LR=0.000100
[2025-08-11 21:21:15,908][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060804] [Batch 02376/04869] [00:20:52/00:21:53, 0.527s/it]: train_loss_raw=0.2735, running_loss=0.2811, LR=0.000100
[2025-08-11 21:21:21,884][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060816] [Batch 02388/04869] [00:20:58/00:21:47, 0.527s/it]: train_loss_raw=0.3298, running_loss=0.2818, LR=0.000100
[2025-08-11 21:21:27,989][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060828] [Batch 02400/04869] [00:21:04/00:21:40, 0.527s/it]: train_loss_raw=0.2392, running_loss=0.2800, LR=0.000100
[2025-08-11 21:21:34,029][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060840] [Batch 02412/04869] [00:21:10/00:21:33, 0.527s/it]: train_loss_raw=0.3910, running_loss=0.2842, LR=0.000100
[2025-08-11 21:21:40,062][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060852] [Batch 02424/04869] [00:21:16/00:21:27, 0.526s/it]: train_loss_raw=0.2743, running_loss=0.2848, LR=0.000100
[2025-08-11 21:21:46,317][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060864] [Batch 02436/04869] [00:21:22/00:21:20, 0.526s/it]: train_loss_raw=0.3111, running_loss=0.2829, LR=0.000100
[2025-08-11 21:21:52,922][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060876] [Batch 02448/04869] [00:21:29/00:21:14, 0.527s/it]: train_loss_raw=0.3090, running_loss=0.2829, LR=0.000100
[2025-08-11 21:21:59,195][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060888] [Batch 02460/04869] [00:21:35/00:21:08, 0.527s/it]: train_loss_raw=0.3540, running_loss=0.2819, LR=0.000100
[2025-08-11 21:22:05,471][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060900] [Batch 02472/04869] [00:21:41/00:21:02, 0.527s/it]: train_loss_raw=0.3028, running_loss=0.2822, LR=0.000100
[2025-08-11 21:22:11,737][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060912] [Batch 02484/04869] [00:21:47/00:20:55, 0.527s/it]: train_loss_raw=0.2807, running_loss=0.2803, LR=0.000100
[2025-08-11 21:22:17,922][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060924] [Batch 02496/04869] [00:21:54/00:20:49, 0.526s/it]: train_loss_raw=0.2340, running_loss=0.2809, LR=0.000100
[2025-08-11 21:22:23,993][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060936] [Batch 02508/04869] [00:22:00/00:20:42, 0.526s/it]: train_loss_raw=0.3508, running_loss=0.2827, LR=0.000100
[2025-08-11 21:22:29,941][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060948] [Batch 02520/04869] [00:22:06/00:20:36, 0.526s/it]: train_loss_raw=0.3214, running_loss=0.2848, LR=0.000100
[2025-08-11 21:22:35,993][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060960] [Batch 02532/04869] [00:22:12/00:20:29, 0.526s/it]: train_loss_raw=0.2486, running_loss=0.2877, LR=0.000100
[2025-08-11 21:22:42,085][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060972] [Batch 02544/04869] [00:22:18/00:20:23, 0.526s/it]: train_loss_raw=0.2519, running_loss=0.2891, LR=0.000100
[2025-08-11 21:22:48,080][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060984] [Batch 02556/04869] [00:22:24/00:20:16, 0.526s/it]: train_loss_raw=0.2497, running_loss=0.2879, LR=0.000100
[2025-08-11 21:22:54,127][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 060996] [Batch 02568/04869] [00:22:30/00:20:09, 0.526s/it]: train_loss_raw=0.3076, running_loss=0.2869, LR=0.000100
[2025-08-11 21:23:00,125][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061008] [Batch 02580/04869] [00:22:36/00:20:03, 0.526s/it]: train_loss_raw=0.2873, running_loss=0.2864, LR=0.000100
[2025-08-11 21:23:06,101][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061020] [Batch 02592/04869] [00:22:42/00:19:56, 0.526s/it]: train_loss_raw=0.2715, running_loss=0.2868, LR=0.000100
[2025-08-11 21:23:12,120][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061032] [Batch 02604/04869] [00:22:48/00:19:50, 0.525s/it]: train_loss_raw=0.2324, running_loss=0.2834, LR=0.000100
[2025-08-11 21:23:18,153][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061044] [Batch 02616/04869] [00:22:54/00:19:43, 0.525s/it]: train_loss_raw=0.3074, running_loss=0.2843, LR=0.000100
[2025-08-11 21:23:24,220][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061056] [Batch 02628/04869] [00:23:00/00:19:37, 0.525s/it]: train_loss_raw=0.2948, running_loss=0.2822, LR=0.000100
[2025-08-11 21:23:30,178][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061068] [Batch 02640/04869] [00:23:06/00:19:30, 0.525s/it]: train_loss_raw=0.3076, running_loss=0.2845, LR=0.000100
[2025-08-11 21:23:36,232][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061080] [Batch 02652/04869] [00:23:12/00:19:24, 0.525s/it]: train_loss_raw=0.3288, running_loss=0.2879, LR=0.000100
[2025-08-11 21:23:42,463][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061092] [Batch 02664/04869] [00:23:18/00:19:17, 0.525s/it]: train_loss_raw=0.2941, running_loss=0.2887, LR=0.000100
[2025-08-11 21:23:48,824][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061104] [Batch 02676/04869] [00:23:24/00:19:11, 0.525s/it]: train_loss_raw=0.2593, running_loss=0.2869, LR=0.000100
[2025-08-11 21:23:55,344][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061116] [Batch 02688/04869] [00:23:31/00:19:05, 0.525s/it]: train_loss_raw=0.2963, running_loss=0.2883, LR=0.000100
[2025-08-11 21:24:01,808][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061128] [Batch 02700/04869] [00:23:37/00:18:59, 0.525s/it]: train_loss_raw=0.3400, running_loss=0.2885, LR=0.000100
[2025-08-11 21:24:08,228][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061140] [Batch 02712/04869] [00:23:44/00:18:52, 0.525s/it]: train_loss_raw=0.2691, running_loss=0.2863, LR=0.000100
[2025-08-11 21:24:14,818][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061152] [Batch 02724/04869] [00:23:50/00:18:46, 0.525s/it]: train_loss_raw=0.2973, running_loss=0.2863, LR=0.000100
[2025-08-11 21:24:21,335][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061164] [Batch 02736/04869] [00:23:57/00:18:40, 0.525s/it]: train_loss_raw=0.2693, running_loss=0.2852, LR=0.000100
[2025-08-11 21:24:27,799][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061176] [Batch 02748/04869] [00:24:03/00:18:34, 0.525s/it]: train_loss_raw=0.2086, running_loss=0.2845, LR=0.000100
[2025-08-11 21:24:33,985][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061188] [Batch 02760/04869] [00:24:10/00:18:28, 0.525s/it]: train_loss_raw=0.2868, running_loss=0.2853, LR=0.000100
[2025-08-11 21:24:40,042][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061200] [Batch 02772/04869] [00:24:16/00:18:21, 0.525s/it]: train_loss_raw=0.2547, running_loss=0.2837, LR=0.000100
[2025-08-11 21:24:46,513][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061212] [Batch 02784/04869] [00:24:22/00:18:15, 0.525s/it]: train_loss_raw=0.2250, running_loss=0.2829, LR=0.000100
[2025-08-11 21:24:53,020][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061224] [Batch 02796/04869] [00:24:29/00:18:09, 0.525s/it]: train_loss_raw=0.2871, running_loss=0.2849, LR=0.000100
[2025-08-11 21:24:59,568][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061236] [Batch 02808/04869] [00:24:35/00:18:03, 0.526s/it]: train_loss_raw=0.3300, running_loss=0.2847, LR=0.000100
[2025-08-11 21:25:06,022][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061248] [Batch 02820/04869] [00:24:42/00:17:56, 0.526s/it]: train_loss_raw=0.2593, running_loss=0.2846, LR=0.000100
[2025-08-11 21:25:12,490][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061260] [Batch 02832/04869] [00:24:48/00:17:50, 0.526s/it]: train_loss_raw=0.2821, running_loss=0.2866, LR=0.000100
[2025-08-11 21:25:19,099][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061272] [Batch 02844/04869] [00:24:55/00:17:44, 0.526s/it]: train_loss_raw=0.3019, running_loss=0.2871, LR=0.000100
[2025-08-11 21:25:25,654][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061284] [Batch 02856/04869] [00:25:01/00:17:38, 0.526s/it]: train_loss_raw=0.2341, running_loss=0.2882, LR=0.000100
[2025-08-11 21:25:32,009][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061296] [Batch 02868/04869] [00:25:08/00:17:32, 0.526s/it]: train_loss_raw=0.2196, running_loss=0.2883, LR=0.000100
[2025-08-11 21:25:38,317][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061308] [Batch 02880/04869] [00:25:14/00:17:25, 0.526s/it]: train_loss_raw=0.2355, running_loss=0.2878, LR=0.000100
[2025-08-11 21:25:44,380][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061320] [Batch 02892/04869] [00:25:20/00:17:19, 0.526s/it]: train_loss_raw=0.3274, running_loss=0.2888, LR=0.000100
[2025-08-11 21:25:50,415][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061332] [Batch 02904/04869] [00:25:26/00:17:12, 0.526s/it]: train_loss_raw=0.2862, running_loss=0.2896, LR=0.000100
[2025-08-11 21:25:56,580][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061344] [Batch 02916/04869] [00:25:32/00:17:06, 0.526s/it]: train_loss_raw=0.2939, running_loss=0.2889, LR=0.000100
[2025-08-11 21:26:02,580][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061356] [Batch 02928/04869] [00:25:38/00:17:00, 0.526s/it]: train_loss_raw=0.3689, running_loss=0.2895, LR=0.000100
[2025-08-11 21:26:08,586][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061368] [Batch 02940/04869] [00:25:44/00:16:53, 0.525s/it]: train_loss_raw=0.2548, running_loss=0.2860, LR=0.000100
[2025-08-11 21:26:14,600][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061380] [Batch 02952/04869] [00:25:50/00:16:47, 0.525s/it]: train_loss_raw=0.2823, running_loss=0.2872, LR=0.000100
[2025-08-11 21:26:20,755][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061392] [Batch 02964/04869] [00:25:56/00:16:40, 0.525s/it]: train_loss_raw=0.2578, running_loss=0.2844, LR=0.000100
[2025-08-11 21:26:26,860][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061404] [Batch 02976/04869] [00:26:03/00:16:34, 0.525s/it]: train_loss_raw=0.3258, running_loss=0.2871, LR=0.000100
[2025-08-11 21:26:32,972][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061416] [Batch 02988/04869] [00:26:09/00:16:27, 0.525s/it]: train_loss_raw=0.2278, running_loss=0.2868, LR=0.000100
[2025-08-11 21:26:39,214][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061428] [Batch 03000/04869] [00:26:15/00:16:21, 0.525s/it]: train_loss_raw=0.3024, running_loss=0.2880, LR=0.000100
[2025-08-11 21:26:45,653][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061440] [Batch 03012/04869] [00:26:21/00:16:15, 0.525s/it]: train_loss_raw=0.2837, running_loss=0.2867, LR=0.000100
[2025-08-11 21:26:52,264][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061452] [Batch 03024/04869] [00:26:28/00:16:09, 0.525s/it]: train_loss_raw=0.2851, running_loss=0.2881, LR=0.000100
[2025-08-11 21:26:58,568][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061464] [Batch 03036/04869] [00:26:34/00:16:02, 0.525s/it]: train_loss_raw=0.2502, running_loss=0.2911, LR=0.000100
[2025-08-11 21:27:04,847][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061476] [Batch 03048/04869] [00:26:41/00:15:56, 0.525s/it]: train_loss_raw=0.2873, running_loss=0.2911, LR=0.000100
[2025-08-11 21:27:11,009][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061488] [Batch 03060/04869] [00:26:47/00:15:50, 0.525s/it]: train_loss_raw=0.4153, running_loss=0.2908, LR=0.000100
[2025-08-11 21:27:17,080][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061500] [Batch 03072/04869] [00:26:53/00:15:43, 0.525s/it]: train_loss_raw=0.2790, running_loss=0.2912, LR=0.000100
[2025-08-11 21:27:23,125][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061512] [Batch 03084/04869] [00:26:59/00:15:37, 0.525s/it]: train_loss_raw=0.2394, running_loss=0.2893, LR=0.000100
[2025-08-11 21:27:29,299][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061524] [Batch 03096/04869] [00:27:05/00:15:30, 0.525s/it]: train_loss_raw=0.2969, running_loss=0.2870, LR=0.000100
[2025-08-11 21:27:35,463][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061536] [Batch 03108/04869] [00:27:11/00:15:24, 0.525s/it]: train_loss_raw=0.2530, running_loss=0.2906, LR=0.000100
[2025-08-11 21:27:42,016][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061548] [Batch 03120/04869] [00:27:18/00:15:18, 0.525s/it]: train_loss_raw=0.2139, running_loss=0.2892, LR=0.000100
[2025-08-11 21:27:48,494][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061560] [Batch 03132/04869] [00:27:24/00:15:12, 0.525s/it]: train_loss_raw=0.3098, running_loss=0.2890, LR=0.000100
[2025-08-11 21:27:55,054][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061572] [Batch 03144/04869] [00:27:31/00:15:05, 0.525s/it]: train_loss_raw=0.2486, running_loss=0.2858, LR=0.000100
[2025-08-11 21:28:01,387][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061584] [Batch 03156/04869] [00:27:37/00:14:59, 0.525s/it]: train_loss_raw=0.2457, running_loss=0.2839, LR=0.000100
[2025-08-11 21:28:07,575][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061596] [Batch 03168/04869] [00:27:43/00:14:53, 0.525s/it]: train_loss_raw=0.2744, running_loss=0.2858, LR=0.000100
[2025-08-11 21:28:13,683][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061608] [Batch 03180/04869] [00:27:49/00:14:46, 0.525s/it]: train_loss_raw=0.2513, running_loss=0.2835, LR=0.000100
[2025-08-11 21:28:19,914][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061620] [Batch 03192/04869] [00:27:56/00:14:40, 0.525s/it]: train_loss_raw=0.2706, running_loss=0.2839, LR=0.000100
[2025-08-11 21:28:26,125][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061632] [Batch 03204/04869] [00:28:02/00:14:34, 0.525s/it]: train_loss_raw=0.2926, running_loss=0.2826, LR=0.000100
[2025-08-11 21:28:32,250][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061644] [Batch 03216/04869] [00:28:08/00:14:27, 0.525s/it]: train_loss_raw=0.3321, running_loss=0.2830, LR=0.000100
[2025-08-11 21:28:38,417][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061656] [Batch 03228/04869] [00:28:14/00:14:21, 0.525s/it]: train_loss_raw=0.3365, running_loss=0.2854, LR=0.000100
[2025-08-11 21:28:44,606][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061668] [Batch 03240/04869] [00:28:20/00:14:15, 0.525s/it]: train_loss_raw=0.3443, running_loss=0.2881, LR=0.000100
[2025-08-11 21:28:50,755][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061680] [Batch 03252/04869] [00:28:26/00:14:08, 0.525s/it]: train_loss_raw=0.3279, running_loss=0.2903, LR=0.000100
[2025-08-11 21:28:56,879][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061692] [Batch 03264/04869] [00:28:33/00:14:02, 0.525s/it]: train_loss_raw=0.3091, running_loss=0.2903, LR=0.000100
[2025-08-11 21:29:03,104][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061704] [Batch 03276/04869] [00:28:39/00:13:56, 0.525s/it]: train_loss_raw=0.2598, running_loss=0.2890, LR=0.000100
[2025-08-11 21:29:09,480][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061716] [Batch 03288/04869] [00:28:45/00:13:49, 0.525s/it]: train_loss_raw=0.2585, running_loss=0.2889, LR=0.000100
[2025-08-11 21:29:15,908][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061728] [Batch 03300/04869] [00:28:52/00:13:43, 0.525s/it]: train_loss_raw=0.2255, running_loss=0.2881, LR=0.000100
[2025-08-11 21:29:22,201][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061740] [Batch 03312/04869] [00:28:58/00:13:37, 0.525s/it]: train_loss_raw=0.2983, running_loss=0.2896, LR=0.000100
[2025-08-11 21:29:28,664][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061752] [Batch 03324/04869] [00:29:04/00:13:30, 0.525s/it]: train_loss_raw=0.3207, running_loss=0.2907, LR=0.000100
[2025-08-11 21:29:34,681][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061764] [Batch 03336/04869] [00:29:10/00:13:24, 0.525s/it]: train_loss_raw=0.2440, running_loss=0.2893, LR=0.000100
[2025-08-11 21:29:40,840][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061776] [Batch 03348/04869] [00:29:17/00:13:18, 0.525s/it]: train_loss_raw=0.3277, running_loss=0.2901, LR=0.000100
[2025-08-11 21:29:46,903][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061788] [Batch 03360/04869] [00:29:23/00:13:11, 0.525s/it]: train_loss_raw=0.2424, running_loss=0.2891, LR=0.000100
[2025-08-11 21:29:52,935][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061800] [Batch 03372/04869] [00:29:29/00:13:05, 0.525s/it]: train_loss_raw=0.2815, running_loss=0.2894, LR=0.000100
[2025-08-11 21:29:58,912][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061812] [Batch 03384/04869] [00:29:35/00:12:58, 0.525s/it]: train_loss_raw=0.3060, running_loss=0.2890, LR=0.000100
[2025-08-11 21:30:05,189][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061824] [Batch 03396/04869] [00:29:41/00:12:52, 0.525s/it]: train_loss_raw=0.3578, running_loss=0.2891, LR=0.000100
[2025-08-11 21:30:11,283][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061836] [Batch 03408/04869] [00:29:47/00:12:46, 0.524s/it]: train_loss_raw=0.2539, running_loss=0.2904, LR=0.000100
[2025-08-11 21:30:17,645][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061848] [Batch 03420/04869] [00:29:53/00:12:40, 0.525s/it]: train_loss_raw=0.3238, running_loss=0.2902, LR=0.000100
[2025-08-11 21:30:23,998][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061860] [Batch 03432/04869] [00:30:00/00:12:33, 0.525s/it]: train_loss_raw=0.2720, running_loss=0.2893, LR=0.000100
[2025-08-11 21:30:29,986][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061872] [Batch 03444/04869] [00:30:06/00:12:27, 0.524s/it]: train_loss_raw=0.2514, running_loss=0.2887, LR=0.000100
[2025-08-11 21:30:35,980][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061884] [Batch 03456/04869] [00:30:12/00:12:20, 0.524s/it]: train_loss_raw=0.3273, running_loss=0.2875, LR=0.000100
[2025-08-11 21:30:42,324][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061896] [Batch 03468/04869] [00:30:18/00:12:14, 0.524s/it]: train_loss_raw=0.3188, running_loss=0.2851, LR=0.000100
[2025-08-11 21:30:48,838][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061908] [Batch 03480/04869] [00:30:24/00:12:08, 0.524s/it]: train_loss_raw=0.2515, running_loss=0.2835, LR=0.000100
[2025-08-11 21:30:55,318][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061920] [Batch 03492/04869] [00:30:31/00:12:02, 0.524s/it]: train_loss_raw=0.3012, running_loss=0.2841, LR=0.000100
[2025-08-11 21:31:01,713][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061932] [Batch 03504/04869] [00:30:37/00:11:55, 0.525s/it]: train_loss_raw=0.2742, running_loss=0.2822, LR=0.000100
[2025-08-11 21:31:07,986][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061944] [Batch 03516/04869] [00:30:44/00:11:49, 0.525s/it]: train_loss_raw=0.3438, running_loss=0.2804, LR=0.000100
[2025-08-11 21:31:13,972][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061956] [Batch 03528/04869] [00:30:50/00:11:43, 0.524s/it]: train_loss_raw=0.2723, running_loss=0.2790, LR=0.000100
[2025-08-11 21:31:20,369][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061968] [Batch 03540/04869] [00:30:56/00:11:36, 0.524s/it]: train_loss_raw=0.3373, running_loss=0.2806, LR=0.000100
[2025-08-11 21:31:26,493][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061980] [Batch 03552/04869] [00:31:02/00:11:30, 0.524s/it]: train_loss_raw=0.3093, running_loss=0.2818, LR=0.000100
[2025-08-11 21:31:32,689][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 061992] [Batch 03564/04869] [00:31:08/00:11:24, 0.524s/it]: train_loss_raw=0.3149, running_loss=0.2827, LR=0.000100
[2025-08-11 21:31:43,412][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062004] [Batch 03576/04869] [00:31:19/00:11:19, 0.526s/it]: train_loss_raw=0.2677, running_loss=0.2837, LR=0.000100
[2025-08-11 21:31:49,552][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062016] [Batch 03588/04869] [00:31:25/00:11:13, 0.526s/it]: train_loss_raw=0.2448, running_loss=0.2830, LR=0.000100
[2025-08-11 21:31:55,695][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062028] [Batch 03600/04869] [00:31:31/00:11:06, 0.526s/it]: train_loss_raw=0.2397, running_loss=0.2822, LR=0.000100
[2025-08-11 21:32:01,762][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062040] [Batch 03612/04869] [00:31:37/00:11:00, 0.525s/it]: train_loss_raw=0.2660, running_loss=0.2823, LR=0.000100
[2025-08-11 21:32:07,991][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062052] [Batch 03624/04869] [00:31:44/00:10:54, 0.525s/it]: train_loss_raw=0.2725, running_loss=0.2831, LR=0.000100
[2025-08-11 21:32:14,437][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062064] [Batch 03636/04869] [00:31:50/00:10:47, 0.525s/it]: train_loss_raw=0.2580, running_loss=0.2839, LR=0.000100
[2025-08-11 21:32:20,688][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062076] [Batch 03648/04869] [00:31:56/00:10:41, 0.525s/it]: train_loss_raw=0.2184, running_loss=0.2833, LR=0.000100
[2025-08-11 21:32:26,829][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062088] [Batch 03660/04869] [00:32:02/00:10:35, 0.525s/it]: train_loss_raw=0.4083, running_loss=0.2849, LR=0.000100
[2025-08-11 21:32:33,066][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062100] [Batch 03672/04869] [00:32:09/00:10:28, 0.525s/it]: train_loss_raw=0.3078, running_loss=0.2875, LR=0.000100
[2025-08-11 21:32:39,634][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062112] [Batch 03684/04869] [00:32:15/00:10:22, 0.525s/it]: train_loss_raw=0.2851, running_loss=0.2860, LR=0.000100
[2025-08-11 21:32:46,256][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062124] [Batch 03696/04869] [00:32:22/00:10:16, 0.526s/it]: train_loss_raw=0.2793, running_loss=0.2872, LR=0.000100
[2025-08-11 21:32:52,846][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062136] [Batch 03708/04869] [00:32:29/00:10:10, 0.526s/it]: train_loss_raw=0.3808, running_loss=0.2880, LR=0.000100
[2025-08-11 21:32:59,483][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062148] [Batch 03720/04869] [00:32:35/00:10:04, 0.526s/it]: train_loss_raw=0.2954, running_loss=0.2896, LR=0.000100
[2025-08-11 21:33:05,711][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062160] [Batch 03732/04869] [00:32:41/00:09:57, 0.526s/it]: train_loss_raw=0.2947, running_loss=0.2869, LR=0.000100
[2025-08-11 21:33:11,901][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062172] [Batch 03744/04869] [00:32:48/00:09:51, 0.526s/it]: train_loss_raw=0.2748, running_loss=0.2875, LR=0.000100
[2025-08-11 21:33:18,244][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062184] [Batch 03756/04869] [00:32:54/00:09:45, 0.526s/it]: train_loss_raw=0.3469, running_loss=0.2878, LR=0.000100
[2025-08-11 21:33:24,877][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062196] [Batch 03768/04869] [00:33:01/00:09:38, 0.526s/it]: train_loss_raw=0.3309, running_loss=0.2883, LR=0.000100
[2025-08-11 21:33:31,505][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062208] [Batch 03780/04869] [00:33:07/00:09:32, 0.526s/it]: train_loss_raw=0.2750, running_loss=0.2876, LR=0.000100
[2025-08-11 21:33:37,602][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062220] [Batch 03792/04869] [00:33:13/00:09:26, 0.526s/it]: train_loss_raw=0.3777, running_loss=0.2906, LR=0.000100
[2025-08-11 21:33:43,680][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062232] [Batch 03804/04869] [00:33:19/00:09:19, 0.526s/it]: train_loss_raw=0.2920, running_loss=0.2896, LR=0.000100
[2025-08-11 21:33:49,730][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062244] [Batch 03816/04869] [00:33:25/00:09:13, 0.526s/it]: train_loss_raw=0.3368, running_loss=0.2873, LR=0.000100
[2025-08-11 21:33:55,865][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062256] [Batch 03828/04869] [00:33:32/00:09:07, 0.526s/it]: train_loss_raw=0.2462, running_loss=0.2834, LR=0.000100
[2025-08-11 21:34:02,083][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062268] [Batch 03840/04869] [00:33:38/00:09:00, 0.526s/it]: train_loss_raw=0.3370, running_loss=0.2834, LR=0.000100
[2025-08-11 21:34:08,220][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062280] [Batch 03852/04869] [00:33:44/00:08:54, 0.526s/it]: train_loss_raw=0.1947, running_loss=0.2829, LR=0.000100
[2025-08-11 21:34:14,306][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062292] [Batch 03864/04869] [00:33:50/00:08:48, 0.525s/it]: train_loss_raw=0.2145, running_loss=0.2829, LR=0.000100
[2025-08-11 21:34:20,634][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062304] [Batch 03876/04869] [00:33:56/00:08:41, 0.525s/it]: train_loss_raw=0.1982, running_loss=0.2838, LR=0.000100
[2025-08-11 21:34:27,176][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062316] [Batch 03888/04869] [00:34:03/00:08:35, 0.526s/it]: train_loss_raw=0.2739, running_loss=0.2841, LR=0.000100
[2025-08-11 21:34:33,155][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062328] [Batch 03900/04869] [00:34:09/00:08:29, 0.525s/it]: train_loss_raw=0.3757, running_loss=0.2868, LR=0.000100
[2025-08-11 21:34:39,291][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062340] [Batch 03912/04869] [00:34:15/00:08:22, 0.525s/it]: train_loss_raw=0.3362, running_loss=0.2887, LR=0.000100
[2025-08-11 21:34:45,638][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062352] [Batch 03924/04869] [00:34:21/00:08:16, 0.525s/it]: train_loss_raw=0.2660, running_loss=0.2889, LR=0.000100
[2025-08-11 21:34:51,897][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062364] [Batch 03936/04869] [00:34:28/00:08:10, 0.525s/it]: train_loss_raw=0.3056, running_loss=0.2910, LR=0.000100
[2025-08-11 21:34:57,884][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062376] [Batch 03948/04869] [00:34:34/00:08:03, 0.525s/it]: train_loss_raw=0.2348, running_loss=0.2909, LR=0.000100
[2025-08-11 21:35:04,012][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062388] [Batch 03960/04869] [00:34:40/00:07:57, 0.525s/it]: train_loss_raw=0.2650, running_loss=0.2914, LR=0.000100
[2025-08-11 21:35:10,024][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062400] [Batch 03972/04869] [00:34:46/00:07:51, 0.525s/it]: train_loss_raw=0.2163, running_loss=0.2873, LR=0.000100
[2025-08-11 21:35:16,214][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062412] [Batch 03984/04869] [00:34:52/00:07:44, 0.525s/it]: train_loss_raw=0.2617, running_loss=0.2891, LR=0.000100
[2025-08-11 21:35:22,704][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062424] [Batch 03996/04869] [00:34:58/00:07:38, 0.525s/it]: train_loss_raw=0.3053, running_loss=0.2900, LR=0.000100
[2025-08-11 21:35:28,942][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062436] [Batch 04008/04869] [00:35:05/00:07:32, 0.525s/it]: train_loss_raw=0.3393, running_loss=0.2895, LR=0.000100
[2025-08-11 21:35:35,058][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062448] [Batch 04020/04869] [00:35:11/00:07:25, 0.525s/it]: train_loss_raw=0.2527, running_loss=0.2891, LR=0.000100
[2025-08-11 21:35:41,330][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062460] [Batch 04032/04869] [00:35:17/00:07:19, 0.525s/it]: train_loss_raw=0.2378, running_loss=0.2869, LR=0.000100
[2025-08-11 21:35:47,460][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062472] [Batch 04044/04869] [00:35:23/00:07:13, 0.525s/it]: train_loss_raw=0.3084, running_loss=0.2865, LR=0.000100
[2025-08-11 21:35:53,596][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062484] [Batch 04056/04869] [00:35:29/00:07:06, 0.525s/it]: train_loss_raw=0.3000, running_loss=0.2879, LR=0.000100
[2025-08-11 21:35:59,654][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062496] [Batch 04068/04869] [00:35:35/00:07:00, 0.525s/it]: train_loss_raw=0.3090, running_loss=0.2888, LR=0.000100
[2025-08-11 21:36:05,672][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062508] [Batch 04080/04869] [00:35:41/00:06:54, 0.525s/it]: train_loss_raw=0.3129, running_loss=0.2895, LR=0.000100
[2025-08-11 21:36:11,818][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062520] [Batch 04092/04869] [00:35:47/00:06:47, 0.525s/it]: train_loss_raw=0.2955, running_loss=0.2892, LR=0.000100
[2025-08-11 21:36:17,840][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062532] [Batch 04104/04869] [00:35:54/00:06:41, 0.525s/it]: train_loss_raw=0.2616, running_loss=0.2905, LR=0.000100
[2025-08-11 21:36:23,906][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062544] [Batch 04116/04869] [00:36:00/00:06:35, 0.525s/it]: train_loss_raw=0.2702, running_loss=0.2889, LR=0.000100
[2025-08-11 21:36:29,927][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062556] [Batch 04128/04869] [00:36:06/00:06:28, 0.525s/it]: train_loss_raw=0.3315, running_loss=0.2898, LR=0.000100
[2025-08-11 21:36:35,961][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062568] [Batch 04140/04869] [00:36:12/00:06:22, 0.525s/it]: train_loss_raw=0.3374, running_loss=0.2916, LR=0.000100
[2025-08-11 21:36:42,075][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062580] [Batch 04152/04869] [00:36:18/00:06:16, 0.525s/it]: train_loss_raw=0.2884, running_loss=0.2895, LR=0.000100
[2025-08-11 21:36:48,508][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062592] [Batch 04164/04869] [00:36:24/00:06:09, 0.525s/it]: train_loss_raw=0.3012, running_loss=0.2915, LR=0.000100
[2025-08-11 21:36:54,691][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062604] [Batch 04176/04869] [00:36:30/00:06:03, 0.525s/it]: train_loss_raw=0.2993, running_loss=0.2891, LR=0.000100
[2025-08-11 21:37:00,883][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062616] [Batch 04188/04869] [00:36:37/00:05:57, 0.525s/it]: train_loss_raw=0.2761, running_loss=0.2903, LR=0.000100
[2025-08-11 21:37:07,013][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062628] [Batch 04200/04869] [00:36:43/00:05:50, 0.525s/it]: train_loss_raw=0.2503, running_loss=0.2891, LR=0.000100
[2025-08-11 21:37:13,509][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062640] [Batch 04212/04869] [00:36:49/00:05:44, 0.525s/it]: train_loss_raw=0.2563, running_loss=0.2880, LR=0.000100
[2025-08-11 21:37:20,225][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062652] [Batch 04224/04869] [00:36:56/00:05:38, 0.525s/it]: train_loss_raw=0.3020, running_loss=0.2891, LR=0.000100
[2025-08-11 21:37:26,818][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062664] [Batch 04236/04869] [00:37:02/00:05:32, 0.525s/it]: train_loss_raw=0.2905, running_loss=0.2891, LR=0.000100
[2025-08-11 21:37:33,347][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062676] [Batch 04248/04869] [00:37:09/00:05:25, 0.525s/it]: train_loss_raw=0.3196, running_loss=0.2885, LR=0.000100
[2025-08-11 21:37:39,501][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062688] [Batch 04260/04869] [00:37:15/00:05:19, 0.525s/it]: train_loss_raw=0.3486, running_loss=0.2915, LR=0.000100
[2025-08-11 21:37:45,530][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062700] [Batch 04272/04869] [00:37:21/00:05:13, 0.525s/it]: train_loss_raw=0.2091, running_loss=0.2915, LR=0.000100
[2025-08-11 21:37:51,662][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062712] [Batch 04284/04869] [00:37:27/00:05:06, 0.525s/it]: train_loss_raw=0.2848, running_loss=0.2913, LR=0.000100
[2025-08-11 21:37:58,268][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062724] [Batch 04296/04869] [00:37:34/00:05:00, 0.525s/it]: train_loss_raw=0.2361, running_loss=0.2902, LR=0.000100
[2025-08-11 21:38:04,808][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062736] [Batch 04308/04869] [00:37:40/00:04:54, 0.525s/it]: train_loss_raw=0.2561, running_loss=0.2909, LR=0.000100
[2025-08-11 21:38:11,039][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062748] [Batch 04320/04869] [00:37:47/00:04:48, 0.525s/it]: train_loss_raw=0.3345, running_loss=0.2920, LR=0.000100
[2025-08-11 21:38:17,323][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062760] [Batch 04332/04869] [00:37:53/00:04:41, 0.525s/it]: train_loss_raw=0.2736, running_loss=0.2895, LR=0.000100
[2025-08-11 21:38:23,429][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062772] [Batch 04344/04869] [00:37:59/00:04:35, 0.525s/it]: train_loss_raw=0.3270, running_loss=0.2909, LR=0.000100
[2025-08-11 21:38:29,778][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062784] [Batch 04356/04869] [00:38:05/00:04:29, 0.525s/it]: train_loss_raw=0.3466, running_loss=0.2902, LR=0.000100
[2025-08-11 21:38:36,314][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062796] [Batch 04368/04869] [00:38:12/00:04:22, 0.525s/it]: train_loss_raw=0.3231, running_loss=0.2874, LR=0.000100
[2025-08-11 21:38:42,609][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062808] [Batch 04380/04869] [00:38:18/00:04:16, 0.525s/it]: train_loss_raw=0.1981, running_loss=0.2851, LR=0.000100
[2025-08-11 21:38:48,973][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062820] [Batch 04392/04869] [00:38:25/00:04:10, 0.525s/it]: train_loss_raw=0.2934, running_loss=0.2834, LR=0.000100
[2025-08-11 21:38:55,370][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062832] [Batch 04404/04869] [00:38:31/00:04:04, 0.525s/it]: train_loss_raw=0.2920, running_loss=0.2822, LR=0.000100
[2025-08-11 21:39:01,854][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062844] [Batch 04416/04869] [00:38:38/00:03:57, 0.525s/it]: train_loss_raw=0.3145, running_loss=0.2827, LR=0.000100
[2025-08-11 21:39:07,879][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062856] [Batch 04428/04869] [00:38:44/00:03:51, 0.525s/it]: train_loss_raw=0.2667, running_loss=0.2852, LR=0.000100
[2025-08-11 21:39:14,089][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062868] [Batch 04440/04869] [00:38:50/00:03:45, 0.525s/it]: train_loss_raw=0.2645, running_loss=0.2875, LR=0.000100
[2025-08-11 21:39:20,281][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062880] [Batch 04452/04869] [00:38:56/00:03:38, 0.525s/it]: train_loss_raw=0.3528, running_loss=0.2865, LR=0.000100
[2025-08-11 21:39:26,313][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062892] [Batch 04464/04869] [00:39:02/00:03:32, 0.525s/it]: train_loss_raw=0.2714, running_loss=0.2851, LR=0.000100
[2025-08-11 21:39:32,342][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062904] [Batch 04476/04869] [00:39:08/00:03:26, 0.525s/it]: train_loss_raw=0.2563, running_loss=0.2854, LR=0.000100
[2025-08-11 21:39:38,341][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062916] [Batch 04488/04869] [00:39:14/00:03:19, 0.525s/it]: train_loss_raw=0.2397, running_loss=0.2847, LR=0.000100
[2025-08-11 21:39:44,333][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062928] [Batch 04500/04869] [00:39:20/00:03:13, 0.525s/it]: train_loss_raw=0.2151, running_loss=0.2856, LR=0.000100
[2025-08-11 21:39:50,490][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062940] [Batch 04512/04869] [00:39:26/00:03:07, 0.525s/it]: train_loss_raw=0.3261, running_loss=0.2855, LR=0.000100
[2025-08-11 21:39:56,722][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062952] [Batch 04524/04869] [00:39:32/00:03:00, 0.525s/it]: train_loss_raw=0.3127, running_loss=0.2853, LR=0.000100
[2025-08-11 21:40:02,769][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062964] [Batch 04536/04869] [00:39:38/00:02:54, 0.524s/it]: train_loss_raw=0.2741, running_loss=0.2832, LR=0.000100
[2025-08-11 21:40:08,854][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062976] [Batch 04548/04869] [00:39:45/00:02:48, 0.524s/it]: train_loss_raw=0.3147, running_loss=0.2828, LR=0.000100
[2025-08-11 21:40:14,918][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 062988] [Batch 04560/04869] [00:39:51/00:02:42, 0.524s/it]: train_loss_raw=0.2070, running_loss=0.2828, LR=0.000100
[2025-08-11 21:40:21,274][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063000] [Batch 04572/04869] [00:39:57/00:02:35, 0.524s/it]: train_loss_raw=0.2366, running_loss=0.2820, LR=0.000100
[2025-08-11 21:40:27,503][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063012] [Batch 04584/04869] [00:40:03/00:02:29, 0.524s/it]: train_loss_raw=0.2064, running_loss=0.2823, LR=0.000100
[2025-08-11 21:40:33,715][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063024] [Batch 04596/04869] [00:40:09/00:02:23, 0.524s/it]: train_loss_raw=0.2868, running_loss=0.2837, LR=0.000100
[2025-08-11 21:40:39,680][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063036] [Batch 04608/04869] [00:40:15/00:02:16, 0.524s/it]: train_loss_raw=0.2589, running_loss=0.2826, LR=0.000100
[2025-08-11 21:40:45,734][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063048] [Batch 04620/04869] [00:40:21/00:02:10, 0.524s/it]: train_loss_raw=0.3284, running_loss=0.2848, LR=0.000100
[2025-08-11 21:40:52,006][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063060] [Batch 04632/04869] [00:40:28/00:02:04, 0.524s/it]: train_loss_raw=0.2551, running_loss=0.2867, LR=0.000100
[2025-08-11 21:40:58,100][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063072] [Batch 04644/04869] [00:40:34/00:01:57, 0.524s/it]: train_loss_raw=0.2334, running_loss=0.2847, LR=0.000100
[2025-08-11 21:41:04,116][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063084] [Batch 04656/04869] [00:40:40/00:01:51, 0.524s/it]: train_loss_raw=0.3034, running_loss=0.2860, LR=0.000100
[2025-08-11 21:41:10,133][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063096] [Batch 04668/04869] [00:40:46/00:01:45, 0.524s/it]: train_loss_raw=0.2373, running_loss=0.2825, LR=0.000100
[2025-08-11 21:41:16,156][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063108] [Batch 04680/04869] [00:40:52/00:01:39, 0.524s/it]: train_loss_raw=0.3213, running_loss=0.2817, LR=0.000100
[2025-08-11 21:41:22,292][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063120] [Batch 04692/04869] [00:40:58/00:01:32, 0.524s/it]: train_loss_raw=0.2509, running_loss=0.2818, LR=0.000100
[2025-08-11 21:41:28,341][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063132] [Batch 04704/04869] [00:41:04/00:01:26, 0.524s/it]: train_loss_raw=0.2858, running_loss=0.2827, LR=0.000100
[2025-08-11 21:41:34,445][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063144] [Batch 04716/04869] [00:41:10/00:01:20, 0.524s/it]: train_loss_raw=0.2226, running_loss=0.2817, LR=0.000100
[2025-08-11 21:41:40,700][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063156] [Batch 04728/04869] [00:41:16/00:01:13, 0.524s/it]: train_loss_raw=0.3185, running_loss=0.2821, LR=0.000100
[2025-08-11 21:41:46,893][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063168] [Batch 04740/04869] [00:41:23/00:01:07, 0.524s/it]: train_loss_raw=0.2571, running_loss=0.2837, LR=0.000100
[2025-08-11 21:41:53,036][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063180] [Batch 04752/04869] [00:41:29/00:01:01, 0.524s/it]: train_loss_raw=0.2479, running_loss=0.2835, LR=0.000100
[2025-08-11 21:41:59,158][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063192] [Batch 04764/04869] [00:41:35/00:00:54, 0.524s/it]: train_loss_raw=0.1964, running_loss=0.2838, LR=0.000100
[2025-08-11 21:42:05,179][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063204] [Batch 04776/04869] [00:41:41/00:00:48, 0.524s/it]: train_loss_raw=0.2799, running_loss=0.2845, LR=0.000100
[2025-08-11 21:42:11,228][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063216] [Batch 04788/04869] [00:41:47/00:00:42, 0.524s/it]: train_loss_raw=0.2479, running_loss=0.2826, LR=0.000100
[2025-08-11 21:42:17,211][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063228] [Batch 04800/04869] [00:41:53/00:00:36, 0.524s/it]: train_loss_raw=0.3416, running_loss=0.2808, LR=0.000100
[2025-08-11 21:42:23,245][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063240] [Batch 04812/04869] [00:41:59/00:00:29, 0.524s/it]: train_loss_raw=0.2704, running_loss=0.2810, LR=0.000100
[2025-08-11 21:42:29,263][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 063252] [Batch 04824/04869] [00:42:05/00:00:23, 0.524s/it]: train_loss_raw=0.3649, running_loss=0.2835, LR=0.000100
