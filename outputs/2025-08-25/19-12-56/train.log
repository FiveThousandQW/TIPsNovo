[2025-08-25 19:12:56,387][__main__][INFO] - Initializing training.
[2025-08-25 19:12:56,387][__main__][INFO] - Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
[2025-08-25 19:12:56,387][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-25 19:12:56,387][__main__][INFO] - CUDA version: 12.1
[2025-08-25 19:12:56,391][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/1461_high/*.parquet
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 192
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
epochs: 50
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: 1461rawHigh_120m_singleGPU_256batch
train_subset: 1
valid_subset_of_train: 0.01
valid_subset: 1
val_check_interval: 1.0
lazy_loading: true
max_shard_size: 1000000
preshuffle_shards: false
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
resume_checkpoint: null
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-25 19:12:56,395][__main__][INFO] - Starting transformer training
[2025-08-25 19:12:56,396][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-25 19:12:56,396][__main__][INFO] - Loading data
[2025-08-25 19:13:10,318][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-25 19:13:23,040][__main__][INFO] - Validation path not specified, generating from training set.
[2025-08-25 19:14:34,669][__main__][INFO] - Data splits saved to /data/48/wuqian/fast/TipsNovo/model_save/splits.csv
[2025-08-25 19:14:34,670][__main__][INFO] - Checking for unknown residues in 1,262,032 rows.
[2025-08-25 19:14:37,631][__main__][WARNING] - Unsupported residues found in evaluation set! These rows will be dropped.
[2025-08-25 19:14:37,631][__main__][INFO] - New residues found: 
{'O'}
[2025-08-25 19:14:37,631][__main__][INFO] - Residues supported: 
{'[SOS]', 'Q', 'C[UNIMOD:4]', '[UNIMOD:1]', 'E', 'R', '[EOS]', 'N', 'S[UNIMOD:21]', '[UNIMOD:5]', 'P', 'Y[UNIMOD:21]', 'G', 'D', 'K', 'T[UNIMOD:21]', 'S', 'Y', 'N[UNIMOD:7]', 'L', 'C', 'A', 'V', 'M', '[PAD]', '[UNIMOD:385]', 'T', 'W', 'I', 'F', 'H', 'M[UNIMOD:35]', 'Q[UNIMOD:7]'}
[2025-08-25 19:15:55,946][__main__][WARNING] - 1 (0.00%) training rows dropped.
[2025-08-25 19:15:55,946][__main__][WARNING] - 0 (0.00%) validation rows dropped.
[2025-08-25 19:17:16,397][__main__][INFO] - Data loaded: 1,246,259 training samples; 15,772 validation samples
[2025-08-25 19:17:16,860][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-25 19:17:16,909][__main__][INFO] - No data leakage!
[2025-08-25 19:17:16,910][__main__][INFO] - Model checkpointing every 0.31 epochs.
[2025-08-25 19:17:16,910][__main__][INFO] - Updates per epoch: 6,491, step_scale=0.16666666666666666
[2025-08-25 19:17:29,542][__main__][INFO] - Sample batch:
[2025-08-25 19:17:29,542][__main__][INFO] -  - spectra.shape=torch.Size([192, 200, 2])
[2025-08-25 19:17:29,542][__main__][INFO] -  - precursors.shape=torch.Size([192, 3])
[2025-08-25 19:17:29,542][__main__][INFO] -  - spectra_mask.shape=torch.Size([192, 200])
[2025-08-25 19:17:29,542][__main__][INFO] -  - peptides.shape=torch.Size([192, 41])
[2025-08-25 19:17:29,542][__main__][INFO] -  - peptides_mask.shape=torch.Size([192, 41])
[2025-08-25 19:17:29,687][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-25 19:17:29,688][__main__][INFO] - Test forward pass:
[2025-08-25 19:17:39,179][__main__][INFO] -  - y.shape=torch.Size([192, 42, 33])
[2025-08-25 19:17:40,462][__main__][INFO] - Profiler trace will be saved to: /data/48/wuqian/fast/TipsNovo/log/1461rawHigh_120m_singleGPU_256batch_25_08_25_19_12/profiler
[2025-08-25 19:17:40,463][__main__][INFO] - Model saving enabled
[2025-08-25 19:17:40,463][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save/
[2025-08-25 19:17:40,463][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-25 19:17:40,474][__main__][INFO] - InstaNovo training started.
[2025-08-25 19:17:45,609][__main__][INFO] - [VALIDATION] [Epoch 00/49] Starting validation.
[2025-08-25 19:17:59,339][__main__][INFO] - [VALIDATION] [Epoch 00/49 Step 000001] [Batch 00007/00124] [00:00:13/00:03:19, 1.716s/it]
[2025-08-25 19:19:56,694][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000008] [Batch 00008/06491] [00:00:05/01:09:18, 0.641s/it]: train_loss_raw=3.4979, running_loss=3.5974, LR=0.000001
[2025-08-25 19:20:26,963][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000016] [Batch 00016/06491] [00:00:35/03:58:46, 2.213s/it]: train_loss_raw=3.2140, running_loss=3.5766, LR=0.000003
[2025-08-25 19:20:32,403][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000024] [Batch 00024/06491] [00:00:40/03:03:24, 1.702s/it]: train_loss_raw=3.0584, running_loss=3.5406, LR=0.000005
[2025-08-25 19:20:37,908][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000032] [Batch 00032/06491] [00:00:46/02:35:54, 1.448s/it]: train_loss_raw=2.9986, running_loss=3.5005, LR=0.000006
[2025-08-25 19:20:43,188][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000040] [Batch 00040/06491] [00:00:51/02:18:45, 1.291s/it]: train_loss_raw=2.9642, running_loss=3.4605, LR=0.000008
[2025-08-25 19:20:48,445][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000048] [Batch 00048/06491] [00:00:56/02:07:15, 1.185s/it]: train_loss_raw=2.9539, running_loss=3.4216, LR=0.000010
[2025-08-25 19:20:54,017][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000056] [Batch 00056/06491] [00:01:02/01:59:36, 1.115s/it]: train_loss_raw=2.9138, running_loss=3.3835, LR=0.000011
[2025-08-25 19:20:59,812][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000064] [Batch 00064/06491] [00:01:08/01:54:13, 1.066s/it]: train_loss_raw=2.8251, running_loss=3.3445, LR=0.000013
[2025-08-25 19:21:05,338][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000072] [Batch 00072/06491] [00:01:13/01:49:37, 1.025s/it]: train_loss_raw=2.7862, running_loss=3.3031, LR=0.000015
[2025-08-25 19:21:10,877][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000080] [Batch 00080/06491] [00:01:19/01:45:56, 0.991s/it]: train_loss_raw=2.7767, running_loss=3.2625, LR=0.000016
[2025-08-25 19:21:16,148][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000088] [Batch 00088/06491] [00:01:24/01:42:34, 0.961s/it]: train_loss_raw=2.7500, running_loss=3.2241, LR=0.000018
[2025-08-25 19:21:21,403][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000096] [Batch 00096/06491] [00:01:29/01:39:44, 0.936s/it]: train_loss_raw=2.7358, running_loss=3.1884, LR=0.000020
[2025-08-25 19:21:26,659][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000104] [Batch 00104/06491] [00:01:35/01:37:20, 0.914s/it]: train_loss_raw=2.7415, running_loss=3.1540, LR=0.000021
[2025-08-25 19:21:31,930][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000112] [Batch 00112/06491] [00:01:40/01:35:16, 0.896s/it]: train_loss_raw=2.7485, running_loss=3.1218, LR=0.000023
[2025-08-25 19:21:37,260][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000120] [Batch 00120/06491] [00:01:45/01:33:31, 0.881s/it]: train_loss_raw=2.7246, running_loss=3.0920, LR=0.000025
[2025-08-25 19:21:42,505][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000128] [Batch 00128/06491] [00:01:50/01:31:55, 0.867s/it]: train_loss_raw=2.7459, running_loss=3.0638, LR=0.000026
[2025-08-25 19:21:48,013][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000136] [Batch 00136/06491] [00:01:56/01:30:41, 0.856s/it]: train_loss_raw=2.7219, running_loss=3.0380, LR=0.000028
[2025-08-25 19:21:53,313][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000144] [Batch 00144/06491] [00:02:01/01:29:26, 0.845s/it]: train_loss_raw=2.7271, running_loss=3.0137, LR=0.000030
[2025-08-25 19:21:58,805][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000152] [Batch 00152/06491] [00:02:07/01:28:26, 0.837s/it]: train_loss_raw=2.7513, running_loss=2.9903, LR=0.000031
[2025-08-25 19:22:04,109][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000160] [Batch 00160/06491] [00:02:12/01:27:24, 0.828s/it]: train_loss_raw=2.6889, running_loss=2.9680, LR=0.000033
[2025-08-25 19:22:09,586][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000168] [Batch 00168/06491] [00:02:18/01:26:34, 0.822s/it]: train_loss_raw=2.7082, running_loss=2.9482, LR=0.000035
[2025-08-25 19:22:14,853][__main__][INFO] - [TRAIN] [Epoch 00/49 Step 000176] [Batch 00176/06491] [00:02:23/01:25:41, 0.814s/it]: train_loss_raw=2.7297, running_loss=2.9295, LR=0.000036
