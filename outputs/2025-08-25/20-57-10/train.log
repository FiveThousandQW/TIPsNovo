[2025-08-25 20:57:10,509][__main__][INFO] - Initializing training.
[2025-08-25 20:57:10,509][__main__][INFO] - Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
[2025-08-25 20:57:10,509][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-25 20:57:10,509][__main__][INFO] - CUDA version: 12.1
[2025-08-25 20:57:10,513][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/1461_high/*.parquet
profiler: false
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: 600k_192BS
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 192
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
train_subset: 0.75
valid_subset_of_train: 0.01
valid_subset: 1
val_check_interval: 1.0
lazy_loading: true
max_shard_size: 1000000
preshuffle_shards: false
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
resume_checkpoint: null
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-25 20:57:10,517][__main__][INFO] - Starting transformer training
[2025-08-25 20:57:10,518][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-25 20:57:10,518][__main__][INFO] - Loading data
[2025-08-25 20:57:24,267][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-25 20:57:36,962][__main__][INFO] - Validation path not specified, generating from training set.
[2025-08-25 20:58:47,282][__main__][INFO] - Data splits saved to /data/48/wuqian/fast/TipsNovo/model_save/splits.csv
[2025-08-25 20:58:47,282][__main__][INFO] - Checking for unknown residues in 1,262,032 rows.
[2025-08-25 20:58:50,070][__main__][WARNING] - Unsupported residues found in evaluation set! These rows will be dropped.
[2025-08-25 20:58:50,070][__main__][INFO] - New residues found: 
{'O'}
[2025-08-25 20:58:50,070][__main__][INFO] - Residues supported: 
{'H', 'I', '[UNIMOD:5]', 'S[UNIMOD:21]', 'K', 'W', 'F', 'S', '[UNIMOD:385]', 'M[UNIMOD:35]', 'Q[UNIMOD:7]', 'P', 'Y', 'C', 'C[UNIMOD:4]', 'V', 'D', 'T[UNIMOD:21]', 'E', '[PAD]', 'T', 'N', 'R', 'N[UNIMOD:7]', 'L', '[SOS]', 'M', 'G', 'Y[UNIMOD:21]', '[EOS]', 'Q', 'A', '[UNIMOD:1]'}
[2025-08-25 21:00:06,954][__main__][WARNING] - 1 (0.00%) training rows dropped.
[2025-08-25 21:00:06,954][__main__][WARNING] - 0 (0.00%) validation rows dropped.
[2025-08-25 21:01:27,652][__main__][INFO] - Data loaded: 934,714 training samples; 15,772 validation samples
[2025-08-25 21:01:28,025][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-25 21:01:28,056][__main__][INFO] - No data leakage!
[2025-08-25 21:01:28,056][__main__][INFO] - Model checkpointing every 0.41 epochs.
[2025-08-25 21:01:28,057][__main__][INFO] - Updates per epoch: 4,869, step_scale=0.16666666666666666
[2025-08-25 21:01:48,028][__main__][INFO] - Sample batch:
[2025-08-25 21:01:48,028][__main__][INFO] -  - spectra.shape=torch.Size([192, 200, 2])
[2025-08-25 21:01:48,028][__main__][INFO] -  - precursors.shape=torch.Size([192, 3])
[2025-08-25 21:01:48,028][__main__][INFO] -  - spectra_mask.shape=torch.Size([192, 200])
[2025-08-25 21:01:48,028][__main__][INFO] -  - peptides.shape=torch.Size([192, 41])
[2025-08-25 21:01:48,028][__main__][INFO] -  - peptides_mask.shape=torch.Size([192, 41])
[2025-08-25 21:01:48,157][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-25 21:01:48,157][__main__][INFO] - Test forward pass:
[2025-08-25 21:01:57,980][__main__][INFO] -  - y.shape=torch.Size([192, 42, 33])
[2025-08-25 21:01:58,905][__main__][INFO] - Model saving enabled
[2025-08-25 21:01:58,906][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save/
[2025-08-25 21:01:58,906][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-25 21:01:58,913][__main__][INFO] - InstaNovo training started.
[2025-08-25 21:02:04,454][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-25 21:02:15,021][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 000001] [Batch 00007/00124] [00:00:10/00:02:33, 1.321s/it]
[2025-08-25 21:02:22,976][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000008] [Batch 00008/04869] [00:00:05/00:52:34, 0.649s/it]: train_loss_raw=3.4811, running_loss=3.6086, LR=0.000001
[2025-08-25 21:02:28,512][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000016] [Batch 00016/04869] [00:00:10/00:54:14, 0.671s/it]: train_loss_raw=3.1981, running_loss=3.5871, LR=0.000003
[2025-08-25 21:02:33,939][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/04869] [00:00:16/00:54:21, 0.673s/it]: train_loss_raw=3.0773, running_loss=3.5505, LR=0.000005
[2025-08-25 21:02:39,120][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000032] [Batch 00032/04869] [00:00:21/00:53:45, 0.667s/it]: train_loss_raw=2.9817, running_loss=3.5091, LR=0.000006
[2025-08-25 21:02:44,326][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000040] [Batch 00040/04869] [00:00:26/00:53:24, 0.664s/it]: train_loss_raw=2.9748, running_loss=3.4682, LR=0.000008
[2025-08-25 21:02:49,639][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/04869] [00:00:31/00:53:19, 0.664s/it]: train_loss_raw=2.9527, running_loss=3.4287, LR=0.000010
[2025-08-25 21:02:55,083][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000056] [Batch 00056/04869] [00:00:37/00:53:25, 0.666s/it]: train_loss_raw=2.9071, running_loss=3.3900, LR=0.000011
[2025-08-25 21:03:00,282][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000064] [Batch 00064/04869] [00:00:42/00:53:10, 0.664s/it]: train_loss_raw=2.8452, running_loss=3.3504, LR=0.000013
[2025-08-25 21:03:05,504][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/04869] [00:00:47/00:52:59, 0.663s/it]: train_loss_raw=2.7872, running_loss=3.3092, LR=0.000015
[2025-08-25 21:03:11,009][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000080] [Batch 00080/04869] [00:00:53/00:53:06, 0.665s/it]: train_loss_raw=2.7590, running_loss=3.2672, LR=0.000016
[2025-08-25 21:03:16,395][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000088] [Batch 00088/04869] [00:00:58/00:53:04, 0.666s/it]: train_loss_raw=2.7643, running_loss=3.2286, LR=0.000018
[2025-08-25 21:03:21,606][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/04869] [00:01:03/00:52:53, 0.665s/it]: train_loss_raw=2.7327, running_loss=3.1914, LR=0.000020
[2025-08-25 21:03:27,344][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000104] [Batch 00104/04869] [00:01:09/00:53:07, 0.669s/it]: train_loss_raw=2.7401, running_loss=3.1565, LR=0.000021
[2025-08-25 21:03:32,959][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000112] [Batch 00112/04869] [00:01:15/00:53:12, 0.671s/it]: train_loss_raw=2.7136, running_loss=3.1232, LR=0.000023
[2025-08-25 21:03:38,406][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/04869] [00:01:20/00:53:10, 0.672s/it]: train_loss_raw=2.7120, running_loss=3.0932, LR=0.000025
[2025-08-25 21:03:43,615][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000128] [Batch 00128/04869] [00:01:25/00:52:59, 0.671s/it]: train_loss_raw=2.7389, running_loss=3.0648, LR=0.000026
[2025-08-25 21:03:48,817][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000136] [Batch 00136/04869] [00:01:31/00:52:48, 0.669s/it]: train_loss_raw=2.7108, running_loss=3.0382, LR=0.000028
[2025-08-25 21:03:54,135][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/04869] [00:01:36/00:52:41, 0.669s/it]: train_loss_raw=2.7016, running_loss=3.0132, LR=0.000030
[2025-08-25 21:03:59,356][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000152] [Batch 00152/04869] [00:01:41/00:52:32, 0.668s/it]: train_loss_raw=2.7009, running_loss=2.9894, LR=0.000031
[2025-08-25 21:04:04,574][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000160] [Batch 00160/04869] [00:01:46/00:52:22, 0.667s/it]: train_loss_raw=2.6980, running_loss=2.9675, LR=0.000033
[2025-08-25 21:04:09,882][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/04869] [00:01:52/00:52:16, 0.667s/it]: train_loss_raw=2.7142, running_loss=2.9468, LR=0.000035
[2025-08-25 21:04:15,215][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000176] [Batch 00176/04869] [00:01:57/00:52:11, 0.667s/it]: train_loss_raw=2.7298, running_loss=2.9283, LR=0.000036
[2025-08-25 21:04:20,581][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000184] [Batch 00184/04869] [00:02:02/00:52:06, 0.667s/it]: train_loss_raw=2.6951, running_loss=2.9109, LR=0.000038
[2025-08-25 21:04:25,895][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/04869] [00:02:08/00:52:00, 0.667s/it]: train_loss_raw=2.7213, running_loss=2.8949, LR=0.000040
[2025-08-25 21:04:31,100][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000200] [Batch 00200/04869] [00:02:13/00:51:52, 0.667s/it]: train_loss_raw=2.6999, running_loss=2.8803, LR=0.000041
[2025-08-25 21:04:36,478][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000208] [Batch 00208/04869] [00:02:18/00:51:47, 0.667s/it]: train_loss_raw=2.6831, running_loss=2.8668, LR=0.000043
[2025-08-25 21:04:42,359][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/04869] [00:02:24/00:51:54, 0.669s/it]: train_loss_raw=2.6841, running_loss=2.8538, LR=0.000045
[2025-08-25 21:04:47,650][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000224] [Batch 00224/04869] [00:02:29/00:51:47, 0.669s/it]: train_loss_raw=2.6918, running_loss=2.8416, LR=0.000046
[2025-08-25 21:04:53,206][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000232] [Batch 00232/04869] [00:02:35/00:51:46, 0.670s/it]: train_loss_raw=2.6956, running_loss=2.8296, LR=0.000048
[2025-08-25 21:04:58,397][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/04869] [00:02:40/00:51:37, 0.669s/it]: train_loss_raw=2.7083, running_loss=2.8192, LR=0.000050
[2025-08-25 21:05:03,593][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000248] [Batch 00248/04869] [00:02:45/00:51:29, 0.669s/it]: train_loss_raw=2.6847, running_loss=2.8094, LR=0.000051
[2025-08-25 21:05:08,793][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000256] [Batch 00256/04869] [00:02:51/00:51:21, 0.668s/it]: train_loss_raw=2.6683, running_loss=2.7993, LR=0.000053
[2025-08-25 21:05:14,322][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/04869] [00:02:56/00:51:19, 0.669s/it]: train_loss_raw=2.7125, running_loss=2.7905, LR=0.000055
[2025-08-25 21:05:19,795][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000272] [Batch 00272/04869] [00:03:02/00:51:16, 0.669s/it]: train_loss_raw=2.6870, running_loss=2.7822, LR=0.000056
[2025-08-25 21:05:25,193][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000280] [Batch 00280/04869] [00:03:07/00:51:11, 0.669s/it]: train_loss_raw=2.6753, running_loss=2.7734, LR=0.000058
[2025-08-25 21:05:30,837][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/04869] [00:03:13/00:51:10, 0.670s/it]: train_loss_raw=2.6989, running_loss=2.7662, LR=0.000060
[2025-08-25 21:05:36,043][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000296] [Batch 00296/04869] [00:03:18/00:51:02, 0.670s/it]: train_loss_raw=2.6891, running_loss=2.7601, LR=0.000061
[2025-08-25 21:05:41,342][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000304] [Batch 00304/04869] [00:03:23/00:50:56, 0.670s/it]: train_loss_raw=2.6890, running_loss=2.7548, LR=0.000063
[2025-08-25 21:05:46,588][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/04869] [00:03:28/00:50:49, 0.669s/it]: train_loss_raw=2.6940, running_loss=2.7499, LR=0.000065
[2025-08-25 21:05:52,041][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000320] [Batch 00320/04869] [00:03:34/00:50:45, 0.670s/it]: train_loss_raw=2.6511, running_loss=2.7446, LR=0.000066
[2025-08-25 21:05:57,758][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000328] [Batch 00328/04869] [00:03:39/00:50:45, 0.671s/it]: train_loss_raw=2.6825, running_loss=2.7396, LR=0.000068
[2025-08-25 21:06:03,490][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/04869] [00:03:45/00:50:45, 0.672s/it]: train_loss_raw=2.6563, running_loss=2.7340, LR=0.000070
[2025-08-25 21:06:09,033][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000344] [Batch 00344/04869] [00:03:51/00:50:41, 0.672s/it]: train_loss_raw=2.6673, running_loss=2.7295, LR=0.000071
[2025-08-25 21:06:14,274][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000352] [Batch 00352/04869] [00:03:56/00:50:34, 0.672s/it]: train_loss_raw=2.6751, running_loss=2.7255, LR=0.000073
[2025-08-25 21:06:19,527][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/04869] [00:04:01/00:50:27, 0.672s/it]: train_loss_raw=2.6906, running_loss=2.7214, LR=0.000075
[2025-08-25 21:06:24,853][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000368] [Batch 00368/04869] [00:04:07/00:50:21, 0.671s/it]: train_loss_raw=2.6622, running_loss=2.7175, LR=0.000076
[2025-08-25 21:06:30,375][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000376] [Batch 00376/04869] [00:04:12/00:50:18, 0.672s/it]: train_loss_raw=2.6709, running_loss=2.7142, LR=0.000078
[2025-08-25 21:06:35,740][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/04869] [00:04:17/00:50:12, 0.672s/it]: train_loss_raw=2.6846, running_loss=2.7103, LR=0.000080
[2025-08-25 21:06:40,963][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000392] [Batch 00392/04869] [00:04:23/00:50:05, 0.671s/it]: train_loss_raw=2.6705, running_loss=2.7078, LR=0.000081
[2025-08-25 21:06:46,157][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000400] [Batch 00400/04869] [00:04:28/00:49:58, 0.671s/it]: train_loss_raw=2.6769, running_loss=2.7048, LR=0.000083
[2025-08-25 21:06:51,349][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/04869] [00:04:33/00:49:51, 0.671s/it]: train_loss_raw=2.6719, running_loss=2.7028, LR=0.000085
[2025-08-25 21:06:56,585][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000416] [Batch 00416/04869] [00:04:38/00:49:44, 0.670s/it]: train_loss_raw=2.6620, running_loss=2.6997, LR=0.000086
[2025-08-25 21:07:01,812][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000424] [Batch 00424/04869] [00:04:44/00:49:37, 0.670s/it]: train_loss_raw=2.6746, running_loss=2.6972, LR=0.000088
[2025-08-25 21:07:07,171][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/04869] [00:04:49/00:49:32, 0.670s/it]: train_loss_raw=2.6746, running_loss=2.6957, LR=0.000090
[2025-08-25 21:07:12,475][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000440] [Batch 00440/04869] [00:04:54/00:49:26, 0.670s/it]: train_loss_raw=2.6719, running_loss=2.6934, LR=0.000091
[2025-08-25 21:07:17,987][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000448] [Batch 00448/04869] [00:05:00/00:49:22, 0.670s/it]: train_loss_raw=2.6705, running_loss=2.6910, LR=0.000093
[2025-08-25 21:07:23,583][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/04869] [00:05:05/00:49:19, 0.671s/it]: train_loss_raw=2.6584, running_loss=2.6888, LR=0.000095
[2025-08-25 21:07:29,122][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000464] [Batch 00464/04869] [00:05:11/00:49:15, 0.671s/it]: train_loss_raw=2.6752, running_loss=2.6868, LR=0.000096
[2025-08-25 21:07:34,329][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000472] [Batch 00472/04869] [00:05:16/00:49:08, 0.671s/it]: train_loss_raw=2.6742, running_loss=2.6848, LR=0.000098
[2025-08-25 21:07:39,592][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/04869] [00:05:21/00:49:02, 0.670s/it]: train_loss_raw=2.6673, running_loss=2.6833, LR=0.000100
[2025-08-25 21:07:45,188][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000488] [Batch 00488/04869] [00:05:27/00:48:59, 0.671s/it]: train_loss_raw=2.6298, running_loss=2.6801, LR=0.000100
[2025-08-25 21:07:50,542][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000496] [Batch 00496/04869] [00:05:32/00:48:53, 0.671s/it]: train_loss_raw=2.6668, running_loss=2.6790, LR=0.000100
[2025-08-25 21:07:55,749][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/04869] [00:05:37/00:48:47, 0.671s/it]: train_loss_raw=2.6410, running_loss=2.6776, LR=0.000100
[2025-08-25 21:08:00,966][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000512] [Batch 00512/04869] [00:05:43/00:48:40, 0.670s/it]: train_loss_raw=2.6496, running_loss=2.6751, LR=0.000100
[2025-08-25 21:08:06,162][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000520] [Batch 00520/04869] [00:05:48/00:48:33, 0.670s/it]: train_loss_raw=2.6413, running_loss=2.6722, LR=0.000100
[2025-08-25 21:08:11,640][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/04869] [00:05:53/00:48:29, 0.670s/it]: train_loss_raw=2.6480, running_loss=2.6701, LR=0.000100
[2025-08-25 21:08:16,841][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000536] [Batch 00536/04869] [00:05:59/00:48:22, 0.670s/it]: train_loss_raw=2.6386, running_loss=2.6681, LR=0.000100
[2025-08-25 21:08:22,229][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000544] [Batch 00544/04869] [00:06:04/00:48:17, 0.670s/it]: train_loss_raw=2.6424, running_loss=2.6661, LR=0.000100
[2025-08-25 21:08:27,562][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/04869] [00:06:09/00:48:11, 0.670s/it]: train_loss_raw=2.6677, running_loss=2.6647, LR=0.000100
[2025-08-25 21:08:32,975][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000560] [Batch 00560/04869] [00:06:15/00:48:06, 0.670s/it]: train_loss_raw=2.6502, running_loss=2.6638, LR=0.000100
[2025-08-25 21:08:38,217][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000568] [Batch 00568/04869] [00:06:20/00:48:00, 0.670s/it]: train_loss_raw=2.6571, running_loss=2.6628, LR=0.000100
[2025-08-25 21:08:43,635][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/04869] [00:06:25/00:47:55, 0.670s/it]: train_loss_raw=2.6712, running_loss=2.6617, LR=0.000100
[2025-08-25 21:08:48,862][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000584] [Batch 00584/04869] [00:06:31/00:47:49, 0.670s/it]: train_loss_raw=2.6137, running_loss=2.6597, LR=0.000100
[2025-08-25 21:08:54,352][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000592] [Batch 00592/04869] [00:06:36/00:47:45, 0.670s/it]: train_loss_raw=2.6565, running_loss=2.6586, LR=0.000100
[2025-08-25 21:08:59,707][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/04869] [00:06:41/00:47:39, 0.670s/it]: train_loss_raw=2.6697, running_loss=2.6574, LR=0.000100
[2025-08-25 21:09:05,426][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000608] [Batch 00608/04869] [00:06:47/00:47:36, 0.670s/it]: train_loss_raw=2.6316, running_loss=2.6570, LR=0.000100
[2025-08-25 21:09:10,625][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000616] [Batch 00616/04869] [00:06:52/00:47:30, 0.670s/it]: train_loss_raw=2.6431, running_loss=2.6567, LR=0.000100
[2025-08-25 21:09:16,023][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/04869] [00:06:58/00:47:25, 0.670s/it]: train_loss_raw=2.6380, running_loss=2.6549, LR=0.000100
[2025-08-25 21:09:21,466][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000632] [Batch 00632/04869] [00:07:03/00:47:20, 0.670s/it]: train_loss_raw=2.6304, running_loss=2.6529, LR=0.000100
[2025-08-25 21:09:26,921][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000640] [Batch 00640/04869] [00:07:09/00:47:15, 0.671s/it]: train_loss_raw=2.6587, running_loss=2.6511, LR=0.000100
[2025-08-25 21:09:32,186][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/04869] [00:07:14/00:47:09, 0.670s/it]: train_loss_raw=2.6666, running_loss=2.6496, LR=0.000100
[2025-08-25 21:09:37,380][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000656] [Batch 00656/04869] [00:07:19/00:47:03, 0.670s/it]: train_loss_raw=2.6429, running_loss=2.6479, LR=0.000100
[2025-08-25 21:09:42,943][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000664] [Batch 00664/04869] [00:07:25/00:46:59, 0.670s/it]: train_loss_raw=2.6088, running_loss=2.6460, LR=0.000100
[2025-08-25 21:09:48,246][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/04869] [00:07:30/00:46:53, 0.670s/it]: train_loss_raw=2.5893, running_loss=2.6437, LR=0.000100
[2025-08-25 21:09:53,570][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000680] [Batch 00680/04869] [00:07:35/00:46:47, 0.670s/it]: train_loss_raw=2.5959, running_loss=2.6414, LR=0.000100
[2025-08-25 21:09:58,827][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000688] [Batch 00688/04869] [00:07:41/00:46:41, 0.670s/it]: train_loss_raw=2.6008, running_loss=2.6392, LR=0.000100
[2025-08-25 21:10:04,480][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/04869] [00:07:46/00:46:38, 0.671s/it]: train_loss_raw=2.5755, running_loss=2.6365, LR=0.000100
[2025-08-25 21:10:10,285][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000704] [Batch 00704/04869] [00:07:52/00:46:35, 0.671s/it]: train_loss_raw=2.6203, running_loss=2.6346, LR=0.000100
[2025-08-25 21:10:15,516][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000712] [Batch 00712/04869] [00:07:57/00:46:29, 0.671s/it]: train_loss_raw=2.6046, running_loss=2.6332, LR=0.000100
[2025-08-25 21:10:20,743][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/04869] [00:08:02/00:46:23, 0.671s/it]: train_loss_raw=2.5920, running_loss=2.6297, LR=0.000100
[2025-08-25 21:10:25,962][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000728] [Batch 00728/04869] [00:08:08/00:46:16, 0.671s/it]: train_loss_raw=2.5992, running_loss=2.6290, LR=0.000100
[2025-08-25 21:10:31,169][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000736] [Batch 00736/04869] [00:08:13/00:46:10, 0.670s/it]: train_loss_raw=2.6612, running_loss=2.6283, LR=0.000100
[2025-08-25 21:10:36,385][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/04869] [00:08:18/00:46:04, 0.670s/it]: train_loss_raw=2.6161, running_loss=2.6255, LR=0.000100
[2025-08-25 21:10:41,611][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000752] [Batch 00752/04869] [00:08:23/00:45:58, 0.670s/it]: train_loss_raw=2.6108, running_loss=2.6228, LR=0.000100
[2025-08-25 21:10:46,830][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000760] [Batch 00760/04869] [00:08:29/00:45:52, 0.670s/it]: train_loss_raw=2.6118, running_loss=2.6215, LR=0.000100
[2025-08-25 21:10:52,038][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/04869] [00:08:34/00:45:46, 0.670s/it]: train_loss_raw=2.5819, running_loss=2.6200, LR=0.000100
[2025-08-25 21:10:57,287][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000776] [Batch 00776/04869] [00:08:39/00:45:40, 0.669s/it]: train_loss_raw=2.5822, running_loss=2.6187, LR=0.000100
[2025-08-25 21:11:02,528][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000784] [Batch 00784/04869] [00:08:44/00:45:34, 0.669s/it]: train_loss_raw=2.5508, running_loss=2.6168, LR=0.000100
[2025-08-25 21:11:07,970][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/04869] [00:08:50/00:45:29, 0.669s/it]: train_loss_raw=2.6080, running_loss=2.6140, LR=0.000100
[2025-08-25 21:11:13,204][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000800] [Batch 00800/04869] [00:08:55/00:45:23, 0.669s/it]: train_loss_raw=2.5888, running_loss=2.6119, LR=0.000100
[2025-08-25 21:11:18,823][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000808] [Batch 00808/04869] [00:09:01/00:45:19, 0.670s/it]: train_loss_raw=2.6200, running_loss=2.6102, LR=0.000100
[2025-08-25 21:11:24,123][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/04869] [00:09:06/00:45:13, 0.670s/it]: train_loss_raw=2.5973, running_loss=2.6081, LR=0.000100
[2025-08-25 21:11:29,330][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000824] [Batch 00824/04869] [00:09:11/00:45:07, 0.669s/it]: train_loss_raw=2.5389, running_loss=2.6049, LR=0.000100
[2025-08-25 21:11:34,621][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000832] [Batch 00832/04869] [00:09:16/00:45:01, 0.669s/it]: train_loss_raw=2.5649, running_loss=2.6031, LR=0.000100
[2025-08-25 21:11:39,812][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000840] [Batch 00840/04869] [00:09:22/00:44:55, 0.669s/it]: train_loss_raw=2.5164, running_loss=2.6014, LR=0.000100
[2025-08-25 21:11:45,149][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000848] [Batch 00848/04869] [00:09:27/00:44:50, 0.669s/it]: train_loss_raw=2.6163, running_loss=2.5996, LR=0.000100
[2025-08-25 21:11:50,355][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000856] [Batch 00856/04869] [00:09:32/00:44:44, 0.669s/it]: train_loss_raw=2.5877, running_loss=2.5964, LR=0.000100
[2025-08-25 21:11:55,703][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000864] [Batch 00864/04869] [00:09:37/00:44:38, 0.669s/it]: train_loss_raw=2.5368, running_loss=2.5935, LR=0.000100
[2025-08-25 21:12:00,951][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000872] [Batch 00872/04869] [00:09:43/00:44:33, 0.669s/it]: train_loss_raw=2.5719, running_loss=2.5921, LR=0.000100
[2025-08-25 21:12:06,520][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000880] [Batch 00880/04869] [00:09:48/00:44:28, 0.669s/it]: train_loss_raw=2.5368, running_loss=2.5904, LR=0.000100
[2025-08-25 21:12:11,737][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000888] [Batch 00888/04869] [00:09:53/00:44:22, 0.669s/it]: train_loss_raw=2.5619, running_loss=2.5886, LR=0.000100
[2025-08-25 21:12:17,291][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000896] [Batch 00896/04869] [00:09:59/00:44:18, 0.669s/it]: train_loss_raw=2.5821, running_loss=2.5875, LR=0.000100
[2025-08-25 21:12:22,725][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000904] [Batch 00904/04869] [00:10:04/00:44:13, 0.669s/it]: train_loss_raw=2.6168, running_loss=2.5877, LR=0.000100
[2025-08-25 21:12:27,915][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000912] [Batch 00912/04869] [00:10:10/00:44:07, 0.669s/it]: train_loss_raw=2.5472, running_loss=2.5864, LR=0.000100
[2025-08-25 21:12:33,113][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000920] [Batch 00920/04869] [00:10:15/00:44:01, 0.669s/it]: train_loss_raw=2.5846, running_loss=2.5861, LR=0.000100
[2025-08-25 21:12:38,298][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000928] [Batch 00928/04869] [00:10:20/00:43:55, 0.669s/it]: train_loss_raw=2.5862, running_loss=2.5848, LR=0.000100
[2025-08-25 21:12:43,493][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000936] [Batch 00936/04869] [00:10:25/00:43:49, 0.668s/it]: train_loss_raw=2.5334, running_loss=2.5831, LR=0.000100
[2025-08-25 21:12:48,682][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000944] [Batch 00944/04869] [00:10:30/00:43:43, 0.668s/it]: train_loss_raw=2.5640, running_loss=2.5811, LR=0.000100
[2025-08-25 21:12:53,867][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000952] [Batch 00952/04869] [00:10:36/00:43:37, 0.668s/it]: train_loss_raw=2.5572, running_loss=2.5796, LR=0.000100
[2025-08-25 21:12:59,048][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000960] [Batch 00960/04869] [00:10:41/00:43:31, 0.668s/it]: train_loss_raw=2.5722, running_loss=2.5772, LR=0.000100
[2025-08-25 21:13:04,587][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000968] [Batch 00968/04869] [00:10:46/00:43:26, 0.668s/it]: train_loss_raw=2.5587, running_loss=2.5783, LR=0.000100
[2025-08-25 21:13:09,943][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000976] [Batch 00976/04869] [00:10:52/00:43:21, 0.668s/it]: train_loss_raw=2.5120, running_loss=2.5760, LR=0.000100
[2025-08-25 21:13:15,263][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000984] [Batch 00984/04869] [00:10:57/00:43:15, 0.668s/it]: train_loss_raw=2.5131, running_loss=2.5735, LR=0.000100
[2025-08-25 21:13:20,631][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000992] [Batch 00992/04869] [00:11:02/00:43:10, 0.668s/it]: train_loss_raw=2.5943, running_loss=2.5731, LR=0.000100
[2025-08-25 21:13:26,100][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001000] [Batch 01000/04869] [00:11:08/00:43:05, 0.668s/it]: train_loss_raw=2.5831, running_loss=2.5717, LR=0.000100
[2025-08-25 21:13:31,516][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001008] [Batch 01008/04869] [00:11:13/00:43:00, 0.668s/it]: train_loss_raw=2.5296, running_loss=2.5702, LR=0.000100
[2025-08-25 21:13:37,189][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001016] [Batch 01016/04869] [00:11:19/00:42:56, 0.669s/it]: train_loss_raw=2.5478, running_loss=2.5697, LR=0.000100
[2025-08-25 21:13:42,703][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001024] [Batch 01024/04869] [00:11:24/00:42:51, 0.669s/it]: train_loss_raw=2.6041, running_loss=2.5696, LR=0.000100
[2025-08-25 21:13:48,422][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001032] [Batch 01032/04869] [00:11:30/00:42:47, 0.669s/it]: train_loss_raw=2.4925, running_loss=2.5684, LR=0.000100
[2025-08-25 21:13:53,755][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001040] [Batch 01040/04869] [00:11:35/00:42:42, 0.669s/it]: train_loss_raw=2.5244, running_loss=2.5668, LR=0.000100
[2025-08-25 21:13:59,114][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001048] [Batch 01048/04869] [00:11:41/00:42:37, 0.669s/it]: train_loss_raw=2.5792, running_loss=2.5663, LR=0.000100
[2025-08-25 21:14:04,309][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001056] [Batch 01056/04869] [00:11:46/00:42:31, 0.669s/it]: train_loss_raw=2.5403, running_loss=2.5633, LR=0.000100
[2025-08-25 21:14:09,556][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001064] [Batch 01064/04869] [00:11:51/00:42:25, 0.669s/it]: train_loss_raw=2.4867, running_loss=2.5614, LR=0.000100
[2025-08-25 21:14:14,981][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001072] [Batch 01072/04869] [00:11:57/00:42:20, 0.669s/it]: train_loss_raw=2.4725, running_loss=2.5604, LR=0.000100
[2025-08-25 21:14:20,773][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001080] [Batch 01080/04869] [00:12:02/00:42:16, 0.669s/it]: train_loss_raw=2.4991, running_loss=2.5582, LR=0.000100
[2025-08-25 21:14:26,112][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001088] [Batch 01088/04869] [00:12:08/00:42:11, 0.669s/it]: train_loss_raw=2.5579, running_loss=2.5575, LR=0.000100
[2025-08-25 21:14:31,557][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001096] [Batch 01096/04869] [00:12:13/00:42:06, 0.670s/it]: train_loss_raw=2.5008, running_loss=2.5567, LR=0.000100
[2025-08-25 21:14:36,763][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001104] [Batch 01104/04869] [00:12:18/00:42:00, 0.669s/it]: train_loss_raw=2.5739, running_loss=2.5564, LR=0.000100
[2025-08-25 21:14:41,961][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001112] [Batch 01112/04869] [00:12:24/00:41:54, 0.669s/it]: train_loss_raw=2.5563, running_loss=2.5553, LR=0.000100
[2025-08-25 21:14:47,162][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001120] [Batch 01120/04869] [00:12:29/00:41:48, 0.669s/it]: train_loss_raw=2.5082, running_loss=2.5521, LR=0.000100
[2025-08-25 21:14:52,366][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001128] [Batch 01128/04869] [00:12:34/00:41:42, 0.669s/it]: train_loss_raw=2.4331, running_loss=2.5509, LR=0.000100
[2025-08-25 21:14:57,871][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001136] [Batch 01136/04869] [00:12:40/00:41:37, 0.669s/it]: train_loss_raw=2.4629, running_loss=2.5493, LR=0.000100
[2025-08-25 21:15:03,129][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001144] [Batch 01144/04869] [00:12:45/00:41:32, 0.669s/it]: train_loss_raw=2.5466, running_loss=2.5493, LR=0.000100
[2025-08-25 21:15:08,316][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001152] [Batch 01152/04869] [00:12:50/00:41:26, 0.669s/it]: train_loss_raw=2.5239, running_loss=2.5474, LR=0.000100
[2025-08-25 21:15:13,964][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001160] [Batch 01160/04869] [00:12:56/00:41:21, 0.669s/it]: train_loss_raw=2.5083, running_loss=2.5455, LR=0.000100
[2025-08-25 21:15:19,190][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001168] [Batch 01168/04869] [00:13:01/00:41:16, 0.669s/it]: train_loss_raw=2.5440, running_loss=2.5451, LR=0.000100
[2025-08-25 21:15:24,393][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001176] [Batch 01176/04869] [00:13:06/00:41:10, 0.669s/it]: train_loss_raw=2.5588, running_loss=2.5451, LR=0.000100
[2025-08-25 21:15:29,890][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001184] [Batch 01184/04869] [00:13:12/00:41:05, 0.669s/it]: train_loss_raw=2.5719, running_loss=2.5434, LR=0.000100
[2025-08-25 21:15:35,109][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001192] [Batch 01192/04869] [00:13:17/00:40:59, 0.669s/it]: train_loss_raw=2.5291, running_loss=2.5419, LR=0.000100
[2025-08-25 21:15:40,348][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001200] [Batch 01200/04869] [00:13:22/00:40:53, 0.669s/it]: train_loss_raw=2.5827, running_loss=2.5406, LR=0.000100
[2025-08-25 21:15:45,949][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001208] [Batch 01208/04869] [00:13:28/00:40:49, 0.669s/it]: train_loss_raw=2.5840, running_loss=2.5372, LR=0.000100
[2025-08-25 21:15:51,243][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001216] [Batch 01216/04869] [00:13:33/00:40:43, 0.669s/it]: train_loss_raw=2.4936, running_loss=2.5364, LR=0.000100
[2025-08-25 21:15:56,913][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001224] [Batch 01224/04869] [00:13:39/00:40:39, 0.669s/it]: train_loss_raw=2.5131, running_loss=2.5363, LR=0.000100
[2025-08-25 21:16:02,696][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001232] [Batch 01232/04869] [00:13:44/00:40:35, 0.670s/it]: train_loss_raw=2.4913, running_loss=2.5345, LR=0.000100
[2025-08-25 21:16:07,979][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001240] [Batch 01240/04869] [00:13:50/00:40:29, 0.670s/it]: train_loss_raw=2.5317, running_loss=2.5330, LR=0.000100
[2025-08-25 21:16:13,192][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001248] [Batch 01248/04869] [00:13:55/00:40:23, 0.669s/it]: train_loss_raw=2.5492, running_loss=2.5313, LR=0.000100
[2025-08-25 21:16:18,406][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001256] [Batch 01256/04869] [00:14:00/00:40:18, 0.669s/it]: train_loss_raw=2.5235, running_loss=2.5302, LR=0.000100
[2025-08-25 21:16:23,611][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001264] [Batch 01264/04869] [00:14:05/00:40:12, 0.669s/it]: train_loss_raw=2.4286, running_loss=2.5281, LR=0.000100
[2025-08-25 21:16:28,834][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001272] [Batch 01272/04869] [00:14:11/00:40:06, 0.669s/it]: train_loss_raw=2.4888, running_loss=2.5258, LR=0.000100
[2025-08-25 21:16:34,057][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001280] [Batch 01280/04869] [00:14:16/00:40:00, 0.669s/it]: train_loss_raw=2.5496, running_loss=2.5254, LR=0.000100
[2025-08-25 21:16:39,279][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001288] [Batch 01288/04869] [00:14:21/00:39:55, 0.669s/it]: train_loss_raw=2.5372, running_loss=2.5255, LR=0.000100
[2025-08-25 21:16:44,512][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001296] [Batch 01296/04869] [00:14:26/00:39:49, 0.669s/it]: train_loss_raw=2.4981, running_loss=2.5228, LR=0.000100
[2025-08-25 21:16:49,748][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001304] [Batch 01304/04869] [00:14:31/00:39:43, 0.669s/it]: train_loss_raw=2.5112, running_loss=2.5212, LR=0.000100
[2025-08-25 21:16:54,962][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001312] [Batch 01312/04869] [00:14:37/00:39:38, 0.669s/it]: train_loss_raw=2.5162, running_loss=2.5207, LR=0.000100
[2025-08-25 21:17:00,172][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001320] [Batch 01320/04869] [00:14:42/00:39:32, 0.668s/it]: train_loss_raw=2.5243, running_loss=2.5198, LR=0.000100
[2025-08-25 21:17:05,403][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001328] [Batch 01328/04869] [00:14:47/00:39:26, 0.668s/it]: train_loss_raw=2.4787, running_loss=2.5181, LR=0.000100
[2025-08-25 21:17:10,866][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001336] [Batch 01336/04869] [00:14:53/00:39:21, 0.668s/it]: train_loss_raw=2.4959, running_loss=2.5175, LR=0.000100
[2025-08-25 21:17:16,064][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001344] [Batch 01344/04869] [00:14:58/00:39:15, 0.668s/it]: train_loss_raw=2.4549, running_loss=2.5162, LR=0.000100
[2025-08-25 21:17:21,398][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001352] [Batch 01352/04869] [00:15:03/00:39:10, 0.668s/it]: train_loss_raw=2.4953, running_loss=2.5163, LR=0.000100
[2025-08-25 21:17:26,610][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001360] [Batch 01360/04869] [00:15:08/00:39:04, 0.668s/it]: train_loss_raw=2.5160, running_loss=2.5150, LR=0.000100
[2025-08-25 21:17:32,246][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001368] [Batch 01368/04869] [00:15:14/00:39:00, 0.668s/it]: train_loss_raw=2.5524, running_loss=2.5130, LR=0.000100
[2025-08-25 21:17:37,765][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001376] [Batch 01376/04869] [00:15:19/00:38:55, 0.669s/it]: train_loss_raw=2.5813, running_loss=2.5123, LR=0.000100
[2025-08-25 21:17:43,254][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001384] [Batch 01384/04869] [00:15:25/00:38:50, 0.669s/it]: train_loss_raw=2.5275, running_loss=2.5122, LR=0.000100
[2025-08-25 21:17:48,494][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001392] [Batch 01392/04869] [00:15:30/00:38:44, 0.669s/it]: train_loss_raw=2.4729, running_loss=2.5096, LR=0.000100
[2025-08-25 21:17:54,083][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001400] [Batch 01400/04869] [00:15:36/00:38:40, 0.669s/it]: train_loss_raw=2.5181, running_loss=2.5112, LR=0.000100
[2025-08-25 21:17:59,363][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001408] [Batch 01408/04869] [00:15:41/00:38:34, 0.669s/it]: train_loss_raw=2.5180, running_loss=2.5098, LR=0.000100
[2025-08-25 21:18:04,597][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001416] [Batch 01416/04869] [00:15:46/00:38:28, 0.669s/it]: train_loss_raw=2.4597, running_loss=2.5084, LR=0.000100
[2025-08-25 21:18:09,806][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001424] [Batch 01424/04869] [00:15:52/00:38:23, 0.669s/it]: train_loss_raw=2.4813, running_loss=2.5070, LR=0.000100
[2025-08-25 21:18:15,090][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001432] [Batch 01432/04869] [00:15:57/00:38:17, 0.669s/it]: train_loss_raw=2.4940, running_loss=2.5044, LR=0.000100
[2025-08-25 21:18:20,419][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001440] [Batch 01440/04869] [00:16:02/00:38:12, 0.668s/it]: train_loss_raw=2.5139, running_loss=2.5043, LR=0.000100
[2025-08-25 21:18:25,869][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001448] [Batch 01448/04869] [00:16:08/00:38:07, 0.669s/it]: train_loss_raw=2.5297, running_loss=2.5044, LR=0.000100
[2025-08-25 21:18:31,074][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001456] [Batch 01456/04869] [00:16:13/00:38:01, 0.668s/it]: train_loss_raw=2.4618, running_loss=2.5028, LR=0.000100
[2025-08-25 21:18:36,296][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001464] [Batch 01464/04869] [00:16:18/00:37:55, 0.668s/it]: train_loss_raw=2.5032, running_loss=2.5027, LR=0.000100
[2025-08-25 21:18:41,514][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001472] [Batch 01472/04869] [00:16:23/00:37:50, 0.668s/it]: train_loss_raw=2.5161, running_loss=2.5043, LR=0.000100
[2025-08-25 21:18:46,748][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001480] [Batch 01480/04869] [00:16:28/00:37:44, 0.668s/it]: train_loss_raw=2.4929, running_loss=2.5036, LR=0.000100
[2025-08-25 21:18:52,201][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001488] [Batch 01488/04869] [00:16:34/00:37:39, 0.668s/it]: train_loss_raw=2.4990, running_loss=2.5019, LR=0.000100
[2025-08-25 21:18:57,563][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001496] [Batch 01496/04869] [00:16:39/00:37:34, 0.668s/it]: train_loss_raw=2.4654, running_loss=2.5017, LR=0.000100
[2025-08-25 21:19:02,765][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001504] [Batch 01504/04869] [00:16:44/00:37:28, 0.668s/it]: train_loss_raw=2.5204, running_loss=2.5003, LR=0.000100
[2025-08-25 21:19:08,378][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001512] [Batch 01512/04869] [00:16:50/00:37:23, 0.668s/it]: train_loss_raw=2.5646, running_loss=2.5003, LR=0.000100
[2025-08-25 21:19:13,592][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001520] [Batch 01520/04869] [00:16:55/00:37:18, 0.668s/it]: train_loss_raw=2.4945, running_loss=2.4992, LR=0.000100
[2025-08-25 21:19:18,809][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001528] [Batch 01528/04869] [00:17:01/00:37:12, 0.668s/it]: train_loss_raw=2.4947, running_loss=2.4985, LR=0.000100
[2025-08-25 21:19:24,027][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001536] [Batch 01536/04869] [00:17:06/00:37:06, 0.668s/it]: train_loss_raw=2.4997, running_loss=2.4986, LR=0.000100
[2025-08-25 21:19:29,274][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001544] [Batch 01544/04869] [00:17:11/00:37:01, 0.668s/it]: train_loss_raw=2.5330, running_loss=2.4991, LR=0.000100
[2025-08-25 21:19:34,506][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001552] [Batch 01552/04869] [00:17:16/00:36:55, 0.668s/it]: train_loss_raw=2.4820, running_loss=2.4992, LR=0.000100
[2025-08-25 21:19:39,732][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001560] [Batch 01560/04869] [00:17:21/00:36:50, 0.668s/it]: train_loss_raw=2.4368, running_loss=2.4981, LR=0.000100
[2025-08-25 21:19:44,964][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001568] [Batch 01568/04869] [00:17:27/00:36:44, 0.668s/it]: train_loss_raw=2.4789, running_loss=2.4975, LR=0.000100
[2025-08-25 21:19:50,193][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001576] [Batch 01576/04869] [00:17:32/00:36:38, 0.668s/it]: train_loss_raw=2.5011, running_loss=2.4970, LR=0.000100
[2025-08-25 21:19:55,442][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001584] [Batch 01584/04869] [00:17:37/00:36:33, 0.668s/it]: train_loss_raw=2.5133, running_loss=2.4970, LR=0.000100
[2025-08-25 21:20:00,747][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001592] [Batch 01592/04869] [00:17:42/00:36:28, 0.668s/it]: train_loss_raw=2.4640, running_loss=2.4957, LR=0.000100
[2025-08-25 21:20:06,631][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001600] [Batch 01600/04869] [00:17:48/00:36:23, 0.668s/it]: train_loss_raw=2.4650, running_loss=2.4953, LR=0.000100
[2025-08-25 21:20:11,839][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001608] [Batch 01608/04869] [00:17:54/00:36:18, 0.668s/it]: train_loss_raw=2.3607, running_loss=2.4932, LR=0.000100
[2025-08-25 21:20:17,052][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001616] [Batch 01616/04869] [00:17:59/00:36:12, 0.668s/it]: train_loss_raw=2.4431, running_loss=2.4921, LR=0.000100
[2025-08-25 21:20:22,407][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001624] [Batch 01624/04869] [00:18:04/00:36:07, 0.668s/it]: train_loss_raw=2.5115, running_loss=2.4906, LR=0.000100
[2025-08-25 21:20:27,991][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001632] [Batch 01632/04869] [00:18:10/00:36:02, 0.668s/it]: train_loss_raw=2.5163, running_loss=2.4897, LR=0.000100
[2025-08-25 21:20:33,181][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001640] [Batch 01640/04869] [00:18:15/00:35:56, 0.668s/it]: train_loss_raw=2.5660, running_loss=2.4913, LR=0.000100
[2025-08-25 21:20:38,648][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001648] [Batch 01648/04869] [00:18:20/00:35:51, 0.668s/it]: train_loss_raw=2.4973, running_loss=2.4910, LR=0.000100
[2025-08-25 21:20:44,084][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001656] [Batch 01656/04869] [00:18:26/00:35:46, 0.668s/it]: train_loss_raw=2.4271, running_loss=2.4890, LR=0.000100
[2025-08-25 21:20:49,735][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001664] [Batch 01664/04869] [00:18:31/00:35:41, 0.668s/it]: train_loss_raw=2.5181, running_loss=2.4889, LR=0.000100
[2025-08-25 21:20:54,943][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001672] [Batch 01672/04869] [00:18:37/00:35:36, 0.668s/it]: train_loss_raw=2.4859, running_loss=2.4875, LR=0.000100
[2025-08-25 21:21:00,118][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001680] [Batch 01680/04869] [00:18:42/00:35:30, 0.668s/it]: train_loss_raw=2.4366, running_loss=2.4857, LR=0.000100
[2025-08-25 21:21:05,291][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001688] [Batch 01688/04869] [00:18:47/00:35:24, 0.668s/it]: train_loss_raw=2.4498, running_loss=2.4824, LR=0.000100
[2025-08-25 21:21:10,460][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001696] [Batch 01696/04869] [00:18:52/00:35:19, 0.668s/it]: train_loss_raw=2.4868, running_loss=2.4813, LR=0.000100
[2025-08-25 21:21:16,030][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001704] [Batch 01704/04869] [00:18:58/00:35:14, 0.668s/it]: train_loss_raw=2.4652, running_loss=2.4809, LR=0.000100
[2025-08-25 21:21:21,221][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001712] [Batch 01712/04869] [00:19:03/00:35:08, 0.668s/it]: train_loss_raw=2.4713, running_loss=2.4800, LR=0.000100
[2025-08-25 21:21:26,405][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001720] [Batch 01720/04869] [00:19:08/00:35:02, 0.668s/it]: train_loss_raw=2.4728, running_loss=2.4791, LR=0.000100
[2025-08-25 21:21:31,670][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001728] [Batch 01728/04869] [00:19:13/00:34:57, 0.668s/it]: train_loss_raw=2.5043, running_loss=2.4783, LR=0.000100
[2025-08-25 21:21:36,959][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001736] [Batch 01736/04869] [00:19:19/00:34:51, 0.668s/it]: train_loss_raw=2.4756, running_loss=2.4783, LR=0.000100
[2025-08-25 21:21:42,201][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001744] [Batch 01744/04869] [00:19:24/00:34:46, 0.668s/it]: train_loss_raw=2.4813, running_loss=2.4760, LR=0.000100
[2025-08-25 21:21:47,392][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001752] [Batch 01752/04869] [00:19:29/00:34:40, 0.668s/it]: train_loss_raw=2.4918, running_loss=2.4751, LR=0.000100
[2025-08-25 21:21:52,589][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001760] [Batch 01760/04869] [00:19:34/00:34:35, 0.668s/it]: train_loss_raw=2.4628, running_loss=2.4763, LR=0.000100
[2025-08-25 21:21:58,048][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001768] [Batch 01768/04869] [00:19:40/00:34:30, 0.668s/it]: train_loss_raw=2.4213, running_loss=2.4745, LR=0.000100
[2025-08-25 21:22:03,245][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001776] [Batch 01776/04869] [00:19:45/00:34:24, 0.667s/it]: train_loss_raw=2.4489, running_loss=2.4733, LR=0.000100
[2025-08-25 21:22:08,409][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001784] [Batch 01784/04869] [00:19:50/00:34:18, 0.667s/it]: train_loss_raw=2.4394, running_loss=2.4715, LR=0.000100
[2025-08-25 21:22:13,648][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001792] [Batch 01792/04869] [00:19:55/00:34:13, 0.667s/it]: train_loss_raw=2.5157, running_loss=2.4710, LR=0.000100
[2025-08-25 21:22:18,842][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001800] [Batch 01800/04869] [00:20:01/00:34:07, 0.667s/it]: train_loss_raw=2.4263, running_loss=2.4699, LR=0.000100
[2025-08-25 21:22:24,047][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001808] [Batch 01808/04869] [00:20:06/00:34:02, 0.667s/it]: train_loss_raw=2.4600, running_loss=2.4695, LR=0.000100
[2025-08-25 21:22:29,328][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001816] [Batch 01816/04869] [00:20:11/00:33:56, 0.667s/it]: train_loss_raw=2.4631, running_loss=2.4684, LR=0.000100
[2025-08-25 21:22:35,126][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001824] [Batch 01824/04869] [00:20:17/00:33:52, 0.667s/it]: train_loss_raw=2.4012, running_loss=2.4671, LR=0.000100
[2025-08-25 21:22:40,693][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001832] [Batch 01832/04869] [00:20:22/00:33:47, 0.668s/it]: train_loss_raw=2.4475, running_loss=2.4676, LR=0.000100
[2025-08-25 21:22:45,886][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001840] [Batch 01840/04869] [00:20:28/00:33:41, 0.667s/it]: train_loss_raw=2.4606, running_loss=2.4662, LR=0.000100
[2025-08-25 21:22:51,125][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001848] [Batch 01848/04869] [00:20:33/00:33:36, 0.667s/it]: train_loss_raw=2.4376, running_loss=2.4645, LR=0.000100
[2025-08-25 21:22:56,560][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001856] [Batch 01856/04869] [00:20:38/00:33:31, 0.667s/it]: train_loss_raw=2.4009, running_loss=2.4626, LR=0.000100
[2025-08-25 21:23:01,766][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001864] [Batch 01864/04869] [00:20:43/00:33:25, 0.667s/it]: train_loss_raw=2.4550, running_loss=2.4636, LR=0.000100
[2025-08-25 21:23:06,970][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001872] [Batch 01872/04869] [00:20:49/00:33:19, 0.667s/it]: train_loss_raw=2.4743, running_loss=2.4622, LR=0.000100
[2025-08-25 21:23:12,478][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001880] [Batch 01880/04869] [00:20:54/00:33:14, 0.667s/it]: train_loss_raw=2.5086, running_loss=2.4633, LR=0.000100
[2025-08-25 21:23:17,698][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001888] [Batch 01888/04869] [00:20:59/00:33:09, 0.667s/it]: train_loss_raw=2.4584, running_loss=2.4620, LR=0.000100
[2025-08-25 21:23:22,922][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001896] [Batch 01896/04869] [00:21:05/00:33:03, 0.667s/it]: train_loss_raw=2.4804, running_loss=2.4612, LR=0.000100
[2025-08-25 21:23:28,129][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001904] [Batch 01904/04869] [00:21:10/00:32:58, 0.667s/it]: train_loss_raw=2.4114, running_loss=2.4611, LR=0.000100
[2025-08-25 21:23:33,323][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001912] [Batch 01912/04869] [00:21:15/00:32:52, 0.667s/it]: train_loss_raw=2.4340, running_loss=2.4590, LR=0.000100
[2025-08-25 21:23:38,764][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001920] [Batch 01920/04869] [00:21:20/00:32:47, 0.667s/it]: train_loss_raw=2.4532, running_loss=2.4573, LR=0.000100
[2025-08-25 21:23:44,216][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001928] [Batch 01928/04869] [00:21:26/00:32:42, 0.667s/it]: train_loss_raw=2.4501, running_loss=2.4574, LR=0.000100
[2025-08-25 21:23:49,493][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001936] [Batch 01936/04869] [00:21:31/00:32:36, 0.667s/it]: train_loss_raw=2.4737, running_loss=2.4569, LR=0.000100
[2025-08-25 21:23:54,857][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001944] [Batch 01944/04869] [00:21:37/00:32:31, 0.667s/it]: train_loss_raw=2.4332, running_loss=2.4568, LR=0.000100
[2025-08-25 21:24:00,096][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001952] [Batch 01952/04869] [00:21:42/00:32:26, 0.667s/it]: train_loss_raw=2.3953, running_loss=2.4550, LR=0.000100
[2025-08-25 21:24:05,497][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001960] [Batch 01960/04869] [00:21:47/00:32:20, 0.667s/it]: train_loss_raw=2.4124, running_loss=2.4561, LR=0.000100
[2025-08-25 21:24:10,693][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001968] [Batch 01968/04869] [00:21:52/00:32:15, 0.667s/it]: train_loss_raw=2.3306, running_loss=2.4528, LR=0.000100
[2025-08-25 21:24:15,883][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001976] [Batch 01976/04869] [00:21:58/00:32:09, 0.667s/it]: train_loss_raw=2.4588, running_loss=2.4529, LR=0.000100
[2025-08-25 21:24:21,421][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001984] [Batch 01984/04869] [00:22:03/00:32:04, 0.667s/it]: train_loss_raw=2.4621, running_loss=2.4509, LR=0.000100
[2025-08-25 21:24:27,065][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001992] [Batch 01992/04869] [00:22:09/00:31:59, 0.667s/it]: train_loss_raw=2.5075, running_loss=2.4499, LR=0.000100
[2025-08-25 21:24:32,434][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002000] [Batch 02000/04869] [00:22:14/00:31:54, 0.667s/it]: train_loss_raw=2.4153, running_loss=2.4491, LR=0.000100
[2025-08-25 21:24:41,600][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002008] [Batch 02008/04869] [00:22:23/00:31:54, 0.669s/it]: train_loss_raw=2.4294, running_loss=2.4489, LR=0.000100
[2025-08-25 21:24:47,412][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002016] [Batch 02016/04869] [00:22:29/00:31:49, 0.669s/it]: train_loss_raw=2.4354, running_loss=2.4486, LR=0.000100
[2025-08-25 21:24:52,904][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002024] [Batch 02024/04869] [00:22:35/00:31:44, 0.670s/it]: train_loss_raw=2.4081, running_loss=2.4472, LR=0.000100
[2025-08-25 21:24:58,731][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002032] [Batch 02032/04869] [00:22:40/00:31:40, 0.670s/it]: train_loss_raw=2.4547, running_loss=2.4464, LR=0.000100
[2025-08-25 21:25:04,232][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002040] [Batch 02040/04869] [00:22:46/00:31:34, 0.670s/it]: train_loss_raw=2.4075, running_loss=2.4451, LR=0.000100
[2025-08-25 21:25:09,426][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002048] [Batch 02048/04869] [00:22:51/00:31:29, 0.670s/it]: train_loss_raw=2.4825, running_loss=2.4438, LR=0.000100
[2025-08-25 21:25:14,604][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002056] [Batch 02056/04869] [00:22:56/00:31:23, 0.670s/it]: train_loss_raw=2.4584, running_loss=2.4422, LR=0.000100
[2025-08-25 21:25:19,801][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002064] [Batch 02064/04869] [00:23:02/00:31:18, 0.670s/it]: train_loss_raw=2.4658, running_loss=2.4425, LR=0.000100
[2025-08-25 21:25:25,013][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002072] [Batch 02072/04869] [00:23:07/00:31:12, 0.670s/it]: train_loss_raw=2.4153, running_loss=2.4422, LR=0.000100
[2025-08-25 21:25:30,191][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002080] [Batch 02080/04869] [00:23:12/00:31:07, 0.669s/it]: train_loss_raw=2.3927, running_loss=2.4427, LR=0.000100
[2025-08-25 21:25:35,967][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002088] [Batch 02088/04869] [00:23:18/00:31:02, 0.670s/it]: train_loss_raw=2.4802, running_loss=2.4429, LR=0.000100
[2025-08-25 21:25:41,601][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002096] [Batch 02096/04869] [00:23:23/00:30:57, 0.670s/it]: train_loss_raw=2.4751, running_loss=2.4425, LR=0.000100
[2025-08-25 21:25:46,792][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002104] [Batch 02104/04869] [00:23:29/00:30:51, 0.670s/it]: train_loss_raw=2.4192, running_loss=2.4417, LR=0.000100
[2025-08-25 21:25:51,964][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002112] [Batch 02112/04869] [00:23:34/00:30:46, 0.670s/it]: train_loss_raw=2.4400, running_loss=2.4401, LR=0.000100
[2025-08-25 21:25:57,134][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002120] [Batch 02120/04869] [00:23:39/00:30:40, 0.670s/it]: train_loss_raw=2.4535, running_loss=2.4407, LR=0.000100
[2025-08-25 21:26:02,321][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002128] [Batch 02128/04869] [00:23:44/00:30:34, 0.669s/it]: train_loss_raw=2.4526, running_loss=2.4397, LR=0.000100
[2025-08-25 21:26:07,492][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002136] [Batch 02136/04869] [00:23:49/00:30:29, 0.669s/it]: train_loss_raw=2.3924, running_loss=2.4378, LR=0.000100
[2025-08-25 21:26:12,676][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002144] [Batch 02144/04869] [00:23:54/00:30:23, 0.669s/it]: train_loss_raw=2.4775, running_loss=2.4382, LR=0.000100
[2025-08-25 21:26:17,876][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002152] [Batch 02152/04869] [00:24:00/00:30:18, 0.669s/it]: train_loss_raw=2.3793, running_loss=2.4358, LR=0.000100
[2025-08-25 21:26:23,064][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002160] [Batch 02160/04869] [00:24:05/00:30:12, 0.669s/it]: train_loss_raw=2.3842, running_loss=2.4333, LR=0.000100
[2025-08-25 21:26:28,255][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002168] [Batch 02168/04869] [00:24:10/00:30:07, 0.669s/it]: train_loss_raw=2.4183, running_loss=2.4338, LR=0.000100
[2025-08-25 21:26:33,979][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002176] [Batch 02176/04869] [00:24:16/00:30:02, 0.669s/it]: train_loss_raw=2.4456, running_loss=2.4338, LR=0.000100
[2025-08-25 21:26:39,162][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002184] [Batch 02184/04869] [00:24:21/00:29:56, 0.669s/it]: train_loss_raw=2.3865, running_loss=2.4319, LR=0.000100
[2025-08-25 21:26:44,324][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002192] [Batch 02192/04869] [00:24:26/00:29:51, 0.669s/it]: train_loss_raw=2.4081, running_loss=2.4327, LR=0.000100
[2025-08-25 21:26:49,649][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002200] [Batch 02200/04869] [00:24:31/00:29:45, 0.669s/it]: train_loss_raw=2.4653, running_loss=2.4338, LR=0.000100
[2025-08-25 21:26:54,822][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002208] [Batch 02208/04869] [00:24:37/00:29:40, 0.669s/it]: train_loss_raw=2.4118, running_loss=2.4331, LR=0.000100
[2025-08-25 21:27:00,375][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002216] [Batch 02216/04869] [00:24:42/00:29:34, 0.669s/it]: train_loss_raw=2.4026, running_loss=2.4333, LR=0.000100
[2025-08-25 21:27:05,969][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002224] [Batch 02224/04869] [00:24:48/00:29:29, 0.669s/it]: train_loss_raw=2.4239, running_loss=2.4331, LR=0.000100
[2025-08-25 21:27:11,146][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002232] [Batch 02232/04869] [00:24:53/00:29:24, 0.669s/it]: train_loss_raw=2.3953, running_loss=2.4327, LR=0.000100
[2025-08-25 21:27:16,573][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002240] [Batch 02240/04869] [00:24:58/00:29:19, 0.669s/it]: train_loss_raw=2.4556, running_loss=2.4311, LR=0.000100
[2025-08-25 21:27:22,386][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002248] [Batch 02248/04869] [00:25:04/00:29:14, 0.669s/it]: train_loss_raw=2.4038, running_loss=2.4311, LR=0.000100
[2025-08-25 21:27:27,599][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002256] [Batch 02256/04869] [00:25:09/00:29:08, 0.669s/it]: train_loss_raw=2.3804, running_loss=2.4301, LR=0.000100
[2025-08-25 21:27:32,908][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002264] [Batch 02264/04869] [00:25:15/00:29:03, 0.669s/it]: train_loss_raw=2.4187, running_loss=2.4306, LR=0.000100
[2025-08-25 21:27:38,222][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002272] [Batch 02272/04869] [00:25:20/00:28:57, 0.669s/it]: train_loss_raw=2.4321, running_loss=2.4311, LR=0.000100
[2025-08-25 21:27:43,543][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002280] [Batch 02280/04869] [00:25:25/00:28:52, 0.669s/it]: train_loss_raw=2.4227, running_loss=2.4303, LR=0.000100
[2025-08-25 21:27:48,848][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002288] [Batch 02288/04869] [00:25:31/00:28:47, 0.669s/it]: train_loss_raw=2.4183, running_loss=2.4290, LR=0.000100
[2025-08-25 21:27:54,314][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002296] [Batch 02296/04869] [00:25:36/00:28:41, 0.669s/it]: train_loss_raw=2.4507, running_loss=2.4282, LR=0.000100
[2025-08-25 21:27:59,720][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002304] [Batch 02304/04869] [00:25:41/00:28:36, 0.669s/it]: train_loss_raw=2.3827, running_loss=2.4279, LR=0.000100
[2025-08-25 21:28:05,337][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002312] [Batch 02312/04869] [00:25:47/00:28:31, 0.669s/it]: train_loss_raw=2.4620, running_loss=2.4283, LR=0.000100
[2025-08-25 21:28:10,849][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002320] [Batch 02320/04869] [00:25:53/00:28:26, 0.669s/it]: train_loss_raw=2.3974, running_loss=2.4277, LR=0.000100
[2025-08-25 21:28:16,167][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002328] [Batch 02328/04869] [00:25:58/00:28:20, 0.669s/it]: train_loss_raw=2.4539, running_loss=2.4278, LR=0.000100
[2025-08-25 21:28:21,359][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002336] [Batch 02336/04869] [00:26:03/00:28:15, 0.669s/it]: train_loss_raw=2.4341, running_loss=2.4276, LR=0.000100
[2025-08-25 21:28:26,511][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002344] [Batch 02344/04869] [00:26:08/00:28:09, 0.669s/it]: train_loss_raw=2.4499, running_loss=2.4265, LR=0.000100
[2025-08-25 21:28:31,675][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002352] [Batch 02352/04869] [00:26:13/00:28:04, 0.669s/it]: train_loss_raw=2.3947, running_loss=2.4251, LR=0.000100
[2025-08-25 21:28:36,845][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002360] [Batch 02360/04869] [00:26:19/00:27:58, 0.669s/it]: train_loss_raw=2.4226, running_loss=2.4240, LR=0.000100
[2025-08-25 21:28:42,082][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002368] [Batch 02368/04869] [00:26:24/00:27:53, 0.669s/it]: train_loss_raw=2.4451, running_loss=2.4230, LR=0.000100
[2025-08-25 21:28:47,587][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002376] [Batch 02376/04869] [00:26:29/00:27:48, 0.669s/it]: train_loss_raw=2.3164, running_loss=2.4201, LR=0.000100
[2025-08-25 21:28:53,298][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002384] [Batch 02384/04869] [00:26:35/00:27:43, 0.669s/it]: train_loss_raw=2.4062, running_loss=2.4196, LR=0.000100
[2025-08-25 21:28:58,666][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002392] [Batch 02392/04869] [00:26:40/00:27:37, 0.669s/it]: train_loss_raw=2.2968, running_loss=2.4185, LR=0.000100
[2025-08-25 21:29:03,982][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002400] [Batch 02400/04869] [00:26:46/00:27:32, 0.669s/it]: train_loss_raw=2.4178, running_loss=2.4205, LR=0.000100
[2025-08-25 21:29:09,887][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002408] [Batch 02408/04869] [00:26:52/00:27:27, 0.669s/it]: train_loss_raw=2.4026, running_loss=2.4200, LR=0.000100
[2025-08-25 21:29:15,421][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002416] [Batch 02416/04869] [00:26:57/00:27:22, 0.670s/it]: train_loss_raw=2.2765, running_loss=2.4189, LR=0.000100
[2025-08-25 21:29:20,623][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002424] [Batch 02424/04869] [00:27:02/00:27:16, 0.669s/it]: train_loss_raw=2.4296, running_loss=2.4190, LR=0.000100
[2025-08-25 21:29:26,259][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002432] [Batch 02432/04869] [00:27:08/00:27:11, 0.670s/it]: train_loss_raw=2.4385, running_loss=2.4185, LR=0.000100
[2025-08-25 21:29:31,536][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002440] [Batch 02440/04869] [00:27:13/00:27:06, 0.670s/it]: train_loss_raw=2.3744, running_loss=2.4165, LR=0.000100
[2025-08-25 21:29:36,816][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002448] [Batch 02448/04869] [00:27:19/00:27:00, 0.670s/it]: train_loss_raw=2.3799, running_loss=2.4170, LR=0.000100
[2025-08-25 21:29:42,490][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002456] [Batch 02456/04869] [00:27:24/00:26:55, 0.670s/it]: train_loss_raw=2.3845, running_loss=2.4154, LR=0.000100
[2025-08-25 21:29:48,265][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002464] [Batch 02464/04869] [00:27:30/00:26:50, 0.670s/it]: train_loss_raw=2.3838, running_loss=2.4148, LR=0.000100
[2025-08-25 21:29:54,047][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002472] [Batch 02472/04869] [00:27:36/00:26:46, 0.670s/it]: train_loss_raw=2.3953, running_loss=2.4141, LR=0.000100
[2025-08-25 21:29:59,376][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002480] [Batch 02480/04869] [00:27:41/00:26:40, 0.670s/it]: train_loss_raw=2.4905, running_loss=2.4148, LR=0.000100
[2025-08-25 21:30:04,550][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002488] [Batch 02488/04869] [00:27:46/00:26:35, 0.670s/it]: train_loss_raw=2.3730, running_loss=2.4143, LR=0.000100
[2025-08-25 21:30:09,987][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002496] [Batch 02496/04869] [00:27:52/00:26:29, 0.670s/it]: train_loss_raw=2.3403, running_loss=2.4123, LR=0.000100
[2025-08-25 21:30:15,605][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002504] [Batch 02504/04869] [00:27:57/00:26:24, 0.670s/it]: train_loss_raw=2.4697, running_loss=2.4138, LR=0.000100
[2025-08-25 21:30:20,769][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002512] [Batch 02512/04869] [00:28:02/00:26:19, 0.670s/it]: train_loss_raw=2.3936, running_loss=2.4133, LR=0.000100
[2025-08-25 21:30:25,976][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002520] [Batch 02520/04869] [00:28:08/00:26:13, 0.670s/it]: train_loss_raw=2.4194, running_loss=2.4127, LR=0.000100
[2025-08-25 21:30:31,464][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002528] [Batch 02528/04869] [00:28:13/00:26:08, 0.670s/it]: train_loss_raw=2.3655, running_loss=2.4124, LR=0.000100
[2025-08-25 21:30:36,973][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002536] [Batch 02536/04869] [00:28:19/00:26:03, 0.670s/it]: train_loss_raw=2.4795, running_loss=2.4124, LR=0.000100
[2025-08-25 21:30:42,766][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002544] [Batch 02544/04869] [00:28:24/00:25:58, 0.670s/it]: train_loss_raw=2.3624, running_loss=2.4110, LR=0.000100
[2025-08-25 21:30:48,687][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002552] [Batch 02552/04869] [00:28:30/00:25:53, 0.670s/it]: train_loss_raw=2.3890, running_loss=2.4098, LR=0.000100
[2025-08-25 21:30:54,635][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002560] [Batch 02560/04869] [00:28:36/00:25:48, 0.671s/it]: train_loss_raw=2.4195, running_loss=2.4095, LR=0.000100
[2025-08-25 21:30:59,806][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002568] [Batch 02568/04869] [00:28:42/00:25:42, 0.671s/it]: train_loss_raw=2.3995, running_loss=2.4103, LR=0.000100
[2025-08-25 21:31:04,984][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002576] [Batch 02576/04869] [00:28:47/00:25:37, 0.670s/it]: train_loss_raw=2.4473, running_loss=2.4092, LR=0.000100
[2025-08-25 21:31:10,456][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002584] [Batch 02584/04869] [00:28:52/00:25:32, 0.671s/it]: train_loss_raw=2.4222, running_loss=2.4086, LR=0.000100
[2025-08-25 21:31:15,657][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002592] [Batch 02592/04869] [00:28:57/00:25:26, 0.670s/it]: train_loss_raw=2.4409, running_loss=2.4081, LR=0.000100
[2025-08-25 21:31:20,850][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002600] [Batch 02600/04869] [00:29:03/00:25:21, 0.670s/it]: train_loss_raw=2.3074, running_loss=2.4074, LR=0.000100
[2025-08-25 21:31:26,051][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002608] [Batch 02608/04869] [00:29:08/00:25:15, 0.670s/it]: train_loss_raw=2.4146, running_loss=2.4072, LR=0.000100
[2025-08-25 21:31:31,583][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002616] [Batch 02616/04869] [00:29:13/00:25:10, 0.670s/it]: train_loss_raw=2.3689, running_loss=2.4048, LR=0.000100
[2025-08-25 21:31:36,779][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002624] [Batch 02624/04869] [00:29:18/00:25:04, 0.670s/it]: train_loss_raw=2.4500, running_loss=2.4027, LR=0.000100
[2025-08-25 21:31:41,964][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002632] [Batch 02632/04869] [00:29:24/00:24:59, 0.670s/it]: train_loss_raw=2.4119, running_loss=2.4040, LR=0.000100
[2025-08-25 21:31:47,364][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002640] [Batch 02640/04869] [00:29:29/00:24:54, 0.670s/it]: train_loss_raw=2.3251, running_loss=2.4010, LR=0.000100
[2025-08-25 21:31:53,152][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002648] [Batch 02648/04869] [00:29:35/00:24:49, 0.670s/it]: train_loss_raw=2.4617, running_loss=2.4028, LR=0.000100
[2025-08-25 21:31:58,511][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002656] [Batch 02656/04869] [00:29:40/00:24:43, 0.670s/it]: train_loss_raw=2.4219, running_loss=2.4006, LR=0.000100
[2025-08-25 21:32:03,710][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002664] [Batch 02664/04869] [00:29:45/00:24:38, 0.670s/it]: train_loss_raw=2.3949, running_loss=2.3990, LR=0.000100
[2025-08-25 21:32:08,896][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002672] [Batch 02672/04869] [00:29:51/00:24:32, 0.670s/it]: train_loss_raw=2.3997, running_loss=2.3986, LR=0.000100
[2025-08-25 21:32:14,082][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002680] [Batch 02680/04869] [00:29:56/00:24:27, 0.670s/it]: train_loss_raw=2.3233, running_loss=2.3999, LR=0.000100
[2025-08-25 21:32:19,376][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002688] [Batch 02688/04869] [00:30:01/00:24:21, 0.670s/it]: train_loss_raw=2.3855, running_loss=2.3997, LR=0.000100
[2025-08-25 21:32:24,904][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002696] [Batch 02696/04869] [00:30:07/00:24:16, 0.670s/it]: train_loss_raw=2.3621, running_loss=2.4007, LR=0.000100
[2025-08-25 21:32:30,288][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002704] [Batch 02704/04869] [00:30:12/00:24:11, 0.670s/it]: train_loss_raw=2.4173, running_loss=2.4000, LR=0.000100
[2025-08-25 21:32:35,970][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002712] [Batch 02712/04869] [00:30:18/00:24:06, 0.670s/it]: train_loss_raw=2.3235, running_loss=2.3992, LR=0.000100
[2025-08-25 21:32:41,365][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002720] [Batch 02720/04869] [00:30:23/00:24:00, 0.670s/it]: train_loss_raw=2.4451, running_loss=2.4004, LR=0.000100
[2025-08-25 21:32:46,776][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002728] [Batch 02728/04869] [00:30:28/00:23:55, 0.670s/it]: train_loss_raw=2.4182, running_loss=2.4009, LR=0.000100
[2025-08-25 21:32:52,310][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002736] [Batch 02736/04869] [00:30:34/00:23:50, 0.671s/it]: train_loss_raw=2.3851, running_loss=2.3993, LR=0.000100
[2025-08-25 21:32:57,782][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002744] [Batch 02744/04869] [00:30:39/00:23:44, 0.671s/it]: train_loss_raw=2.4022, running_loss=2.4000, LR=0.000100
[2025-08-25 21:33:02,984][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002752] [Batch 02752/04869] [00:30:45/00:23:39, 0.670s/it]: train_loss_raw=2.4199, running_loss=2.3989, LR=0.000100
[2025-08-25 21:33:08,598][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002760] [Batch 02760/04869] [00:30:50/00:23:34, 0.671s/it]: train_loss_raw=2.3463, running_loss=2.3987, LR=0.000100
[2025-08-25 21:33:14,161][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002768] [Batch 02768/04869] [00:30:56/00:23:29, 0.671s/it]: train_loss_raw=2.3560, running_loss=2.3979, LR=0.000100
[2025-08-25 21:33:19,623][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002776] [Batch 02776/04869] [00:31:01/00:23:23, 0.671s/it]: train_loss_raw=2.3247, running_loss=2.3967, LR=0.000100
[2025-08-25 21:33:25,444][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002784] [Batch 02784/04869] [00:31:07/00:23:18, 0.671s/it]: train_loss_raw=2.3833, running_loss=2.3951, LR=0.000100
[2025-08-25 21:33:30,645][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002792] [Batch 02792/04869] [00:31:12/00:23:13, 0.671s/it]: train_loss_raw=2.4457, running_loss=2.3958, LR=0.000100
[2025-08-25 21:33:35,960][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002800] [Batch 02800/04869] [00:31:18/00:23:07, 0.671s/it]: train_loss_raw=2.4698, running_loss=2.3959, LR=0.000100
[2025-08-25 21:33:41,148][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002808] [Batch 02808/04869] [00:31:23/00:23:02, 0.671s/it]: train_loss_raw=2.3565, running_loss=2.3953, LR=0.000100
[2025-08-25 21:33:46,607][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002816] [Batch 02816/04869] [00:31:28/00:22:57, 0.671s/it]: train_loss_raw=2.3334, running_loss=2.3924, LR=0.000100
[2025-08-25 21:33:52,092][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002824] [Batch 02824/04869] [00:31:34/00:22:51, 0.671s/it]: train_loss_raw=2.3568, running_loss=2.3916, LR=0.000100
[2025-08-25 21:33:57,258][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002832] [Batch 02832/04869] [00:31:39/00:22:46, 0.671s/it]: train_loss_raw=2.3988, running_loss=2.3911, LR=0.000100
[2025-08-25 21:34:02,543][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002840] [Batch 02840/04869] [00:31:44/00:22:40, 0.671s/it]: train_loss_raw=2.3992, running_loss=2.3918, LR=0.000100
[2025-08-25 21:34:08,018][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002848] [Batch 02848/04869] [00:31:50/00:22:35, 0.671s/it]: train_loss_raw=2.3572, running_loss=2.3913, LR=0.000100
[2025-08-25 21:34:13,247][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002856] [Batch 02856/04869] [00:31:55/00:22:30, 0.671s/it]: train_loss_raw=2.3951, running_loss=2.3909, LR=0.000100
[2025-08-25 21:34:19,079][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002864] [Batch 02864/04869] [00:32:01/00:22:25, 0.671s/it]: train_loss_raw=2.3370, running_loss=2.3889, LR=0.000100
[2025-08-25 21:34:24,432][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002872] [Batch 02872/04869] [00:32:06/00:22:19, 0.671s/it]: train_loss_raw=2.3976, running_loss=2.3880, LR=0.000100
[2025-08-25 21:34:29,949][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002880] [Batch 02880/04869] [00:32:12/00:22:14, 0.671s/it]: train_loss_raw=2.4198, running_loss=2.3884, LR=0.000100
[2025-08-25 21:34:35,633][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002888] [Batch 02888/04869] [00:32:17/00:22:09, 0.671s/it]: train_loss_raw=2.4104, running_loss=2.3864, LR=0.000100
[2025-08-25 21:34:40,825][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002896] [Batch 02896/04869] [00:32:23/00:22:03, 0.671s/it]: train_loss_raw=2.4149, running_loss=2.3855, LR=0.000100
[2025-08-25 21:34:45,990][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002904] [Batch 02904/04869] [00:32:28/00:21:58, 0.671s/it]: train_loss_raw=2.4152, running_loss=2.3850, LR=0.000100
[2025-08-25 21:34:51,200][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002912] [Batch 02912/04869] [00:32:33/00:21:52, 0.671s/it]: train_loss_raw=2.4320, running_loss=2.3842, LR=0.000100
[2025-08-25 21:34:56,373][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002920] [Batch 02920/04869] [00:32:38/00:21:47, 0.671s/it]: train_loss_raw=2.3679, running_loss=2.3830, LR=0.000100
[2025-08-25 21:35:01,570][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002928] [Batch 02928/04869] [00:32:43/00:21:41, 0.671s/it]: train_loss_raw=2.3196, running_loss=2.3809, LR=0.000100
[2025-08-25 21:35:06,753][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002936] [Batch 02936/04869] [00:32:48/00:21:36, 0.671s/it]: train_loss_raw=2.4557, running_loss=2.3813, LR=0.000100
[2025-08-25 21:35:11,944][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002944] [Batch 02944/04869] [00:32:54/00:21:30, 0.671s/it]: train_loss_raw=2.2826, running_loss=2.3799, LR=0.000100
[2025-08-25 21:35:17,684][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002952] [Batch 02952/04869] [00:32:59/00:21:25, 0.671s/it]: train_loss_raw=2.3825, running_loss=2.3791, LR=0.000100
[2025-08-25 21:35:22,936][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002960] [Batch 02960/04869] [00:33:05/00:21:20, 0.671s/it]: train_loss_raw=2.2898, running_loss=2.3772, LR=0.000100
[2025-08-25 21:35:28,083][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002968] [Batch 02968/04869] [00:33:10/00:21:14, 0.671s/it]: train_loss_raw=2.3330, running_loss=2.3761, LR=0.000100
[2025-08-25 21:35:33,407][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002976] [Batch 02976/04869] [00:33:15/00:21:09, 0.671s/it]: train_loss_raw=2.3579, running_loss=2.3762, LR=0.000100
[2025-08-25 21:35:38,678][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002984] [Batch 02984/04869] [00:33:20/00:21:03, 0.671s/it]: train_loss_raw=2.3773, running_loss=2.3764, LR=0.000100
[2025-08-25 21:35:43,963][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002992] [Batch 02992/04869] [00:33:26/00:20:58, 0.671s/it]: train_loss_raw=2.3464, running_loss=2.3754, LR=0.000100
[2025-08-25 21:35:49,725][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003000] [Batch 03000/04869] [00:33:31/00:20:53, 0.671s/it]: train_loss_raw=2.3120, running_loss=2.3731, LR=0.000100
[2025-08-25 21:35:55,262][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003008] [Batch 03008/04869] [00:33:37/00:20:48, 0.671s/it]: train_loss_raw=2.3475, running_loss=2.3743, LR=0.000100
[2025-08-25 21:36:00,454][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003016] [Batch 03016/04869] [00:33:42/00:20:42, 0.671s/it]: train_loss_raw=2.3689, running_loss=2.3744, LR=0.000100
[2025-08-25 21:36:05,640][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003024] [Batch 03024/04869] [00:33:47/00:20:37, 0.671s/it]: train_loss_raw=2.3187, running_loss=2.3723, LR=0.000100
[2025-08-25 21:36:10,849][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003032] [Batch 03032/04869] [00:33:53/00:20:31, 0.671s/it]: train_loss_raw=2.4022, running_loss=2.3726, LR=0.000100
[2025-08-25 21:36:16,312][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003040] [Batch 03040/04869] [00:33:58/00:20:26, 0.671s/it]: train_loss_raw=2.3700, running_loss=2.3728, LR=0.000100
[2025-08-25 21:36:21,509][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003048] [Batch 03048/04869] [00:34:03/00:20:21, 0.671s/it]: train_loss_raw=2.2404, running_loss=2.3711, LR=0.000100
[2025-08-25 21:36:26,954][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003056] [Batch 03056/04869] [00:34:09/00:20:15, 0.671s/it]: train_loss_raw=2.3330, running_loss=2.3704, LR=0.000100
[2025-08-25 21:36:32,500][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003064] [Batch 03064/04869] [00:34:14/00:20:10, 0.671s/it]: train_loss_raw=2.3683, running_loss=2.3707, LR=0.000100
[2025-08-25 21:36:37,877][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003072] [Batch 03072/04869] [00:34:20/00:20:05, 0.671s/it]: train_loss_raw=2.4404, running_loss=2.3698, LR=0.000100
[2025-08-25 21:36:43,081][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003080] [Batch 03080/04869] [00:34:25/00:19:59, 0.671s/it]: train_loss_raw=2.3593, running_loss=2.3688, LR=0.000100
[2025-08-25 21:36:48,390][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003088] [Batch 03088/04869] [00:34:30/00:19:54, 0.671s/it]: train_loss_raw=2.3005, running_loss=2.3681, LR=0.000100
[2025-08-25 21:36:53,933][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003096] [Batch 03096/04869] [00:34:36/00:19:48, 0.671s/it]: train_loss_raw=2.3886, running_loss=2.3672, LR=0.000100
[2025-08-25 21:36:59,118][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003104] [Batch 03104/04869] [00:34:41/00:19:43, 0.671s/it]: train_loss_raw=2.3578, running_loss=2.3677, LR=0.000100
[2025-08-25 21:37:04,296][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003112] [Batch 03112/04869] [00:34:46/00:19:38, 0.670s/it]: train_loss_raw=2.3670, running_loss=2.3681, LR=0.000100
[2025-08-25 21:37:09,501][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003120] [Batch 03120/04869] [00:34:51/00:19:32, 0.670s/it]: train_loss_raw=2.3423, running_loss=2.3652, LR=0.000100
[2025-08-25 21:37:14,706][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003128] [Batch 03128/04869] [00:34:56/00:19:27, 0.670s/it]: train_loss_raw=2.3813, running_loss=2.3665, LR=0.000100
[2025-08-25 21:37:20,054][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003136] [Batch 03136/04869] [00:35:02/00:19:21, 0.670s/it]: train_loss_raw=2.3861, running_loss=2.3676, LR=0.000100
[2025-08-25 21:37:25,422][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003144] [Batch 03144/04869] [00:35:07/00:19:16, 0.670s/it]: train_loss_raw=2.3476, running_loss=2.3656, LR=0.000100
[2025-08-25 21:37:30,671][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003152] [Batch 03152/04869] [00:35:12/00:19:10, 0.670s/it]: train_loss_raw=2.3626, running_loss=2.3673, LR=0.000100
[2025-08-25 21:37:36,296][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003160] [Batch 03160/04869] [00:35:18/00:19:05, 0.670s/it]: train_loss_raw=2.3686, running_loss=2.3658, LR=0.000100
[2025-08-25 21:37:41,747][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003168] [Batch 03168/04869] [00:35:23/00:19:00, 0.670s/it]: train_loss_raw=2.3628, running_loss=2.3670, LR=0.000100
[2025-08-25 21:37:46,915][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003176] [Batch 03176/04869] [00:35:29/00:18:54, 0.670s/it]: train_loss_raw=2.2800, running_loss=2.3667, LR=0.000100
[2025-08-25 21:37:52,426][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003184] [Batch 03184/04869] [00:35:34/00:18:49, 0.670s/it]: train_loss_raw=2.4114, running_loss=2.3687, LR=0.000100
[2025-08-25 21:37:58,205][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003192] [Batch 03192/04869] [00:35:40/00:18:44, 0.671s/it]: train_loss_raw=2.3746, running_loss=2.3676, LR=0.000100
[2025-08-25 21:38:03,846][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003200] [Batch 03200/04869] [00:35:46/00:18:39, 0.671s/it]: train_loss_raw=2.3752, running_loss=2.3676, LR=0.000100
[2025-08-25 21:38:09,432][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003208] [Batch 03208/04869] [00:35:51/00:18:34, 0.671s/it]: train_loss_raw=2.3386, running_loss=2.3652, LR=0.000100
[2025-08-25 21:38:14,786][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003216] [Batch 03216/04869] [00:35:57/00:18:28, 0.671s/it]: train_loss_raw=2.3608, running_loss=2.3655, LR=0.000100
[2025-08-25 21:38:20,027][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003224] [Batch 03224/04869] [00:36:02/00:18:23, 0.671s/it]: train_loss_raw=2.3698, running_loss=2.3643, LR=0.000100
[2025-08-25 21:38:25,271][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003232] [Batch 03232/04869] [00:36:07/00:18:17, 0.671s/it]: train_loss_raw=2.3436, running_loss=2.3632, LR=0.000100
[2025-08-25 21:38:30,800][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003240] [Batch 03240/04869] [00:36:13/00:18:12, 0.671s/it]: train_loss_raw=2.4147, running_loss=2.3619, LR=0.000100
[2025-08-25 21:38:36,098][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003248] [Batch 03248/04869] [00:36:18/00:18:07, 0.671s/it]: train_loss_raw=2.3311, running_loss=2.3618, LR=0.000100
[2025-08-25 21:38:41,572][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003256] [Batch 03256/04869] [00:36:23/00:18:01, 0.671s/it]: train_loss_raw=2.3386, running_loss=2.3613, LR=0.000100
[2025-08-25 21:38:47,086][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003264] [Batch 03264/04869] [00:36:29/00:17:56, 0.671s/it]: train_loss_raw=2.3800, running_loss=2.3630, LR=0.000100
[2025-08-25 21:38:52,848][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003272] [Batch 03272/04869] [00:36:35/00:17:51, 0.671s/it]: train_loss_raw=2.4121, running_loss=2.3624, LR=0.000100
[2025-08-25 21:38:58,070][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003280] [Batch 03280/04869] [00:36:40/00:17:45, 0.671s/it]: train_loss_raw=2.3146, running_loss=2.3616, LR=0.000100
[2025-08-25 21:39:03,293][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003288] [Batch 03288/04869] [00:36:45/00:17:40, 0.671s/it]: train_loss_raw=2.3373, running_loss=2.3596, LR=0.000100
[2025-08-25 21:39:08,475][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003296] [Batch 03296/04869] [00:36:50/00:17:35, 0.671s/it]: train_loss_raw=2.4418, running_loss=2.3597, LR=0.000100
[2025-08-25 21:39:13,790][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003304] [Batch 03304/04869] [00:36:56/00:17:29, 0.671s/it]: train_loss_raw=2.3285, running_loss=2.3576, LR=0.000100
[2025-08-25 21:39:19,034][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003312] [Batch 03312/04869] [00:37:01/00:17:24, 0.671s/it]: train_loss_raw=2.3767, running_loss=2.3564, LR=0.000100
[2025-08-25 21:39:24,249][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003320] [Batch 03320/04869] [00:37:06/00:17:18, 0.671s/it]: train_loss_raw=2.2598, running_loss=2.3556, LR=0.000100
[2025-08-25 21:39:29,539][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003328] [Batch 03328/04869] [00:37:11/00:17:13, 0.671s/it]: train_loss_raw=2.3895, running_loss=2.3556, LR=0.000100
[2025-08-25 21:39:35,312][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003336] [Batch 03336/04869] [00:37:17/00:17:08, 0.671s/it]: train_loss_raw=2.3174, running_loss=2.3547, LR=0.000100
[2025-08-25 21:39:40,886][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003344] [Batch 03344/04869] [00:37:23/00:17:02, 0.671s/it]: train_loss_raw=2.3596, running_loss=2.3535, LR=0.000100
[2025-08-25 21:39:46,362][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003352] [Batch 03352/04869] [00:37:28/00:16:57, 0.671s/it]: train_loss_raw=2.4014, running_loss=2.3533, LR=0.000100
[2025-08-25 21:39:52,177][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003360] [Batch 03360/04869] [00:37:34/00:16:52, 0.671s/it]: train_loss_raw=2.3404, running_loss=2.3524, LR=0.000100
[2025-08-25 21:39:57,364][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003368] [Batch 03368/04869] [00:37:39/00:16:47, 0.671s/it]: train_loss_raw=2.3318, running_loss=2.3515, LR=0.000100
[2025-08-25 21:40:02,672][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003376] [Batch 03376/04869] [00:37:44/00:16:41, 0.671s/it]: train_loss_raw=2.2921, running_loss=2.3499, LR=0.000100
[2025-08-25 21:40:08,094][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003384] [Batch 03384/04869] [00:37:50/00:16:36, 0.671s/it]: train_loss_raw=2.3823, running_loss=2.3494, LR=0.000100
[2025-08-25 21:40:13,272][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003392] [Batch 03392/04869] [00:37:55/00:16:30, 0.671s/it]: train_loss_raw=2.3950, running_loss=2.3490, LR=0.000100
[2025-08-25 21:40:18,467][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003400] [Batch 03400/04869] [00:38:00/00:16:25, 0.671s/it]: train_loss_raw=2.2832, running_loss=2.3466, LR=0.000100
[2025-08-25 21:40:23,701][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003408] [Batch 03408/04869] [00:38:05/00:16:19, 0.671s/it]: train_loss_raw=2.2811, running_loss=2.3474, LR=0.000100
[2025-08-25 21:40:28,952][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003416] [Batch 03416/04869] [00:38:11/00:16:14, 0.671s/it]: train_loss_raw=2.3762, running_loss=2.3469, LR=0.000100
[2025-08-25 21:40:34,146][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003424] [Batch 03424/04869] [00:38:16/00:16:09, 0.671s/it]: train_loss_raw=2.4114, running_loss=2.3466, LR=0.000100
[2025-08-25 21:40:39,662][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003432] [Batch 03432/04869] [00:38:21/00:16:03, 0.671s/it]: train_loss_raw=2.2975, running_loss=2.3449, LR=0.000100
[2025-08-25 21:40:44,875][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003440] [Batch 03440/04869] [00:38:27/00:15:58, 0.671s/it]: train_loss_raw=2.3321, running_loss=2.3453, LR=0.000100
[2025-08-25 21:40:50,455][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003448] [Batch 03448/04869] [00:38:32/00:15:53, 0.671s/it]: train_loss_raw=2.3411, running_loss=2.3448, LR=0.000100
[2025-08-25 21:40:55,924][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003456] [Batch 03456/04869] [00:38:38/00:15:47, 0.671s/it]: train_loss_raw=2.3484, running_loss=2.3435, LR=0.000100
[2025-08-25 21:41:01,117][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003464] [Batch 03464/04869] [00:38:43/00:15:42, 0.671s/it]: train_loss_raw=2.3540, running_loss=2.3425, LR=0.000100
[2025-08-25 21:41:06,305][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003472] [Batch 03472/04869] [00:38:48/00:15:36, 0.671s/it]: train_loss_raw=2.4104, running_loss=2.3436, LR=0.000100
[2025-08-25 21:41:11,516][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003480] [Batch 03480/04869] [00:38:53/00:15:31, 0.671s/it]: train_loss_raw=2.4052, running_loss=2.3431, LR=0.000100
[2025-08-25 21:41:16,716][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003488] [Batch 03488/04869] [00:38:58/00:15:26, 0.671s/it]: train_loss_raw=2.3343, running_loss=2.3434, LR=0.000100
[2025-08-25 21:41:22,018][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003496] [Batch 03496/04869] [00:39:04/00:15:20, 0.671s/it]: train_loss_raw=2.4048, running_loss=2.3437, LR=0.000100
[2025-08-25 21:41:27,208][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003504] [Batch 03504/04869] [00:39:09/00:15:15, 0.670s/it]: train_loss_raw=2.3642, running_loss=2.3436, LR=0.000100
[2025-08-25 21:41:32,393][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003512] [Batch 03512/04869] [00:39:14/00:15:09, 0.670s/it]: train_loss_raw=2.2798, running_loss=2.3429, LR=0.000100
[2025-08-25 21:41:37,571][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003520] [Batch 03520/04869] [00:39:19/00:15:04, 0.670s/it]: train_loss_raw=2.2270, running_loss=2.3413, LR=0.000100
[2025-08-25 21:41:43,126][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003528] [Batch 03528/04869] [00:39:25/00:14:59, 0.670s/it]: train_loss_raw=2.3578, running_loss=2.3389, LR=0.000100
[2025-08-25 21:41:48,739][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003536] [Batch 03536/04869] [00:39:30/00:14:53, 0.671s/it]: train_loss_raw=2.3497, running_loss=2.3400, LR=0.000100
[2025-08-25 21:41:54,109][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003544] [Batch 03544/04869] [00:39:36/00:14:48, 0.671s/it]: train_loss_raw=2.3244, running_loss=2.3392, LR=0.000100
[2025-08-25 21:41:59,511][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003552] [Batch 03552/04869] [00:39:41/00:14:43, 0.671s/it]: train_loss_raw=2.3548, running_loss=2.3393, LR=0.000100
[2025-08-25 21:42:04,945][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003560] [Batch 03560/04869] [00:39:47/00:14:37, 0.671s/it]: train_loss_raw=2.2811, running_loss=2.3389, LR=0.000100
[2025-08-25 21:42:10,556][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003568] [Batch 03568/04869] [00:39:52/00:14:32, 0.671s/it]: train_loss_raw=2.2983, running_loss=2.3364, LR=0.000100
[2025-08-25 21:42:15,829][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003576] [Batch 03576/04869] [00:39:58/00:14:27, 0.671s/it]: train_loss_raw=2.3452, running_loss=2.3358, LR=0.000100
[2025-08-25 21:42:21,001][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003584] [Batch 03584/04869] [00:40:03/00:14:21, 0.671s/it]: train_loss_raw=2.3170, running_loss=2.3347, LR=0.000100
[2025-08-25 21:42:26,371][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003592] [Batch 03592/04869] [00:40:08/00:14:16, 0.671s/it]: train_loss_raw=2.3198, running_loss=2.3346, LR=0.000100
[2025-08-25 21:42:31,847][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003600] [Batch 03600/04869] [00:40:14/00:14:10, 0.671s/it]: train_loss_raw=2.3231, running_loss=2.3329, LR=0.000100
[2025-08-25 21:42:37,083][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003608] [Batch 03608/04869] [00:40:19/00:14:05, 0.671s/it]: train_loss_raw=2.4344, running_loss=2.3351, LR=0.000100
[2025-08-25 21:42:42,417][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003616] [Batch 03616/04869] [00:40:24/00:14:00, 0.671s/it]: train_loss_raw=2.3332, running_loss=2.3357, LR=0.000100
[2025-08-25 21:42:47,876][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003624] [Batch 03624/04869] [00:40:30/00:13:54, 0.671s/it]: train_loss_raw=2.3882, running_loss=2.3350, LR=0.000100
[2025-08-25 21:42:53,062][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003632] [Batch 03632/04869] [00:40:35/00:13:49, 0.671s/it]: train_loss_raw=2.3053, running_loss=2.3350, LR=0.000100
[2025-08-25 21:42:58,317][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003640] [Batch 03640/04869] [00:40:40/00:13:44, 0.670s/it]: train_loss_raw=2.3647, running_loss=2.3348, LR=0.000100
[2025-08-25 21:43:03,522][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003648] [Batch 03648/04869] [00:40:45/00:13:38, 0.670s/it]: train_loss_raw=2.2718, running_loss=2.3330, LR=0.000100
[2025-08-25 21:43:08,695][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003656] [Batch 03656/04869] [00:40:50/00:13:33, 0.670s/it]: train_loss_raw=2.3157, running_loss=2.3308, LR=0.000100
[2025-08-25 21:43:13,886][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003664] [Batch 03664/04869] [00:40:56/00:13:27, 0.670s/it]: train_loss_raw=2.2972, running_loss=2.3300, LR=0.000100
[2025-08-25 21:43:19,070][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003672] [Batch 03672/04869] [00:41:01/00:13:22, 0.670s/it]: train_loss_raw=2.3274, running_loss=2.3305, LR=0.000100
[2025-08-25 21:43:24,256][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003680] [Batch 03680/04869] [00:41:06/00:13:16, 0.670s/it]: train_loss_raw=2.3319, running_loss=2.3301, LR=0.000100
[2025-08-25 21:43:29,654][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003688] [Batch 03688/04869] [00:41:11/00:13:11, 0.670s/it]: train_loss_raw=2.3245, running_loss=2.3294, LR=0.000100
[2025-08-25 21:43:35,280][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003696] [Batch 03696/04869] [00:41:17/00:13:06, 0.670s/it]: train_loss_raw=2.3611, running_loss=2.3272, LR=0.000100
[2025-08-25 21:43:40,676][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003704] [Batch 03704/04869] [00:41:22/00:13:00, 0.670s/it]: train_loss_raw=2.3774, running_loss=2.3288, LR=0.000100
[2025-08-25 21:43:46,020][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003712] [Batch 03712/04869] [00:41:28/00:12:55, 0.670s/it]: train_loss_raw=2.2690, running_loss=2.3270, LR=0.000100
[2025-08-25 21:43:51,219][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003720] [Batch 03720/04869] [00:41:33/00:12:50, 0.670s/it]: train_loss_raw=2.3842, running_loss=2.3278, LR=0.000100
[2025-08-25 21:43:56,517][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003728] [Batch 03728/04869] [00:41:38/00:12:44, 0.670s/it]: train_loss_raw=2.3604, running_loss=2.3252, LR=0.000100
[2025-08-25 21:44:01,694][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003736] [Batch 03736/04869] [00:41:43/00:12:39, 0.670s/it]: train_loss_raw=2.3200, running_loss=2.3227, LR=0.000100
[2025-08-25 21:44:06,894][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003744] [Batch 03744/04869] [00:41:49/00:12:33, 0.670s/it]: train_loss_raw=2.2400, running_loss=2.3204, LR=0.000100
[2025-08-25 21:44:12,050][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003752] [Batch 03752/04869] [00:41:54/00:12:28, 0.670s/it]: train_loss_raw=2.3910, running_loss=2.3196, LR=0.000100
[2025-08-25 21:44:17,245][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003760] [Batch 03760/04869] [00:41:59/00:12:23, 0.670s/it]: train_loss_raw=2.3481, running_loss=2.3200, LR=0.000100
[2025-08-25 21:44:22,449][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003768] [Batch 03768/04869] [00:42:04/00:12:17, 0.670s/it]: train_loss_raw=2.2545, running_loss=2.3162, LR=0.000100
[2025-08-25 21:44:27,652][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003776] [Batch 03776/04869] [00:42:09/00:12:12, 0.670s/it]: train_loss_raw=2.3124, running_loss=2.3165, LR=0.000100
[2025-08-25 21:44:32,866][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003784] [Batch 03784/04869] [00:42:15/00:12:06, 0.670s/it]: train_loss_raw=2.3327, running_loss=2.3144, LR=0.000100
[2025-08-25 21:44:38,045][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003792] [Batch 03792/04869] [00:42:20/00:12:01, 0.670s/it]: train_loss_raw=2.2790, running_loss=2.3121, LR=0.000100
[2025-08-25 21:44:43,262][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003800] [Batch 03800/04869] [00:42:25/00:11:56, 0.670s/it]: train_loss_raw=2.3971, running_loss=2.3118, LR=0.000100
[2025-08-25 21:44:48,468][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003808] [Batch 03808/04869] [00:42:30/00:11:50, 0.670s/it]: train_loss_raw=2.3934, running_loss=2.3117, LR=0.000100
[2025-08-25 21:44:53,679][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003816] [Batch 03816/04869] [00:42:35/00:11:45, 0.670s/it]: train_loss_raw=2.3550, running_loss=2.3114, LR=0.000100
[2025-08-25 21:44:58,876][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003824] [Batch 03824/04869] [00:42:41/00:11:39, 0.670s/it]: train_loss_raw=2.3172, running_loss=2.3101, LR=0.000100
[2025-08-25 21:45:04,072][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003832] [Batch 03832/04869] [00:42:46/00:11:34, 0.670s/it]: train_loss_raw=2.2833, running_loss=2.3111, LR=0.000100
[2025-08-25 21:45:09,249][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003840] [Batch 03840/04869] [00:42:51/00:11:29, 0.670s/it]: train_loss_raw=2.2468, running_loss=2.3116, LR=0.000100
[2025-08-25 21:45:14,415][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003848] [Batch 03848/04869] [00:42:56/00:11:23, 0.670s/it]: train_loss_raw=2.2871, running_loss=2.3113, LR=0.000100
[2025-08-25 21:45:19,626][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003856] [Batch 03856/04869] [00:43:01/00:11:18, 0.670s/it]: train_loss_raw=2.3521, running_loss=2.3100, LR=0.000100
[2025-08-25 21:45:31,067][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003864] [Batch 03864/04869] [00:43:13/00:11:14, 0.671s/it]: train_loss_raw=2.2639, running_loss=2.3110, LR=0.000100
[2025-08-25 21:45:36,417][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003872] [Batch 03872/04869] [00:43:18/00:11:09, 0.671s/it]: train_loss_raw=2.3267, running_loss=2.3095, LR=0.000100
[2025-08-25 21:45:41,610][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003880] [Batch 03880/04869] [00:43:23/00:11:03, 0.671s/it]: train_loss_raw=2.2748, running_loss=2.3091, LR=0.000100
[2025-08-25 21:45:46,799][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003888] [Batch 03888/04869] [00:43:29/00:10:58, 0.671s/it]: train_loss_raw=2.3424, running_loss=2.3081, LR=0.000100
[2025-08-25 21:45:51,981][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003896] [Batch 03896/04869] [00:43:34/00:10:52, 0.671s/it]: train_loss_raw=2.3341, running_loss=2.3084, LR=0.000100
[2025-08-25 21:45:57,182][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003904] [Batch 03904/04869] [00:43:39/00:10:47, 0.671s/it]: train_loss_raw=2.3101, running_loss=2.3105, LR=0.000100
[2025-08-25 21:46:02,370][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003912] [Batch 03912/04869] [00:43:44/00:10:42, 0.671s/it]: train_loss_raw=2.3777, running_loss=2.3102, LR=0.000100
[2025-08-25 21:46:07,575][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003920] [Batch 03920/04869] [00:43:49/00:10:36, 0.671s/it]: train_loss_raw=2.2476, running_loss=2.3077, LR=0.000100
[2025-08-25 21:46:12,817][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003928] [Batch 03928/04869] [00:43:55/00:10:31, 0.671s/it]: train_loss_raw=2.2959, running_loss=2.3069, LR=0.000100
[2025-08-25 21:46:18,047][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003936] [Batch 03936/04869] [00:44:00/00:10:25, 0.671s/it]: train_loss_raw=2.3171, running_loss=2.3067, LR=0.000100
[2025-08-25 21:46:23,293][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003944] [Batch 03944/04869] [00:44:05/00:10:20, 0.671s/it]: train_loss_raw=2.3126, running_loss=2.3056, LR=0.000100
[2025-08-25 21:46:28,530][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003952] [Batch 03952/04869] [00:44:10/00:10:15, 0.671s/it]: train_loss_raw=2.2779, running_loss=2.3069, LR=0.000100
[2025-08-25 21:46:33,765][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003960] [Batch 03960/04869] [00:44:15/00:10:09, 0.671s/it]: train_loss_raw=2.2765, running_loss=2.3069, LR=0.000100
[2025-08-25 21:46:38,977][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003968] [Batch 03968/04869] [00:44:21/00:10:04, 0.671s/it]: train_loss_raw=2.3420, running_loss=2.3046, LR=0.000100
[2025-08-25 21:46:44,187][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003976] [Batch 03976/04869] [00:44:26/00:09:58, 0.671s/it]: train_loss_raw=2.2931, running_loss=2.3035, LR=0.000100
[2025-08-25 21:46:49,422][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003984] [Batch 03984/04869] [00:44:31/00:09:53, 0.671s/it]: train_loss_raw=2.2476, running_loss=2.3036, LR=0.000100
[2025-08-25 21:46:54,640][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003992] [Batch 03992/04869] [00:44:36/00:09:48, 0.671s/it]: train_loss_raw=2.2978, running_loss=2.3034, LR=0.000100
[2025-08-25 21:46:59,867][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004000] [Batch 04000/04869] [00:44:42/00:09:42, 0.671s/it]: train_loss_raw=2.2547, running_loss=2.3044, LR=0.000100
[2025-08-25 21:47:08,841][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004008] [Batch 04008/04869] [00:44:51/00:09:38, 0.671s/it]: train_loss_raw=2.3302, running_loss=2.3029, LR=0.000100
[2025-08-25 21:47:14,102][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004016] [Batch 04016/04869] [00:44:56/00:09:32, 0.671s/it]: train_loss_raw=2.2787, running_loss=2.3019, LR=0.000100
[2025-08-25 21:47:19,327][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004024] [Batch 04024/04869] [00:45:01/00:09:27, 0.671s/it]: train_loss_raw=2.3127, running_loss=2.3036, LR=0.000100
[2025-08-25 21:47:24,705][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004032] [Batch 04032/04869] [00:45:06/00:09:21, 0.671s/it]: train_loss_raw=2.3045, running_loss=2.3019, LR=0.000100
[2025-08-25 21:47:30,286][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004040] [Batch 04040/04869] [00:45:12/00:09:16, 0.671s/it]: train_loss_raw=2.3650, running_loss=2.3024, LR=0.000100
[2025-08-25 21:47:35,631][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004048] [Batch 04048/04869] [00:45:17/00:09:11, 0.671s/it]: train_loss_raw=2.3407, running_loss=2.3036, LR=0.000100
[2025-08-25 21:47:41,188][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004056] [Batch 04056/04869] [00:45:23/00:09:05, 0.671s/it]: train_loss_raw=2.2185, running_loss=2.3023, LR=0.000100
[2025-08-25 21:47:46,414][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004064] [Batch 04064/04869] [00:45:28/00:09:00, 0.671s/it]: train_loss_raw=2.3047, running_loss=2.3018, LR=0.000100
[2025-08-25 21:47:51,648][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004072] [Batch 04072/04869] [00:45:33/00:08:55, 0.671s/it]: train_loss_raw=2.3452, running_loss=2.3024, LR=0.000100
[2025-08-25 21:47:57,196][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004080] [Batch 04080/04869] [00:45:39/00:08:49, 0.671s/it]: train_loss_raw=2.2479, running_loss=2.3004, LR=0.000100
[2025-08-25 21:48:02,524][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004088] [Batch 04088/04869] [00:45:44/00:08:44, 0.671s/it]: train_loss_raw=2.2640, running_loss=2.2984, LR=0.000100
[2025-08-25 21:48:08,143][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004096] [Batch 04096/04869] [00:45:50/00:08:39, 0.671s/it]: train_loss_raw=2.2700, running_loss=2.2978, LR=0.000100
[2025-08-25 21:48:13,860][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004104] [Batch 04104/04869] [00:45:56/00:08:33, 0.672s/it]: train_loss_raw=2.2893, running_loss=2.2967, LR=0.000100
[2025-08-25 21:48:19,540][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004112] [Batch 04112/04869] [00:46:01/00:08:28, 0.672s/it]: train_loss_raw=2.2405, running_loss=2.2978, LR=0.000100
[2025-08-25 21:48:25,163][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004120] [Batch 04120/04869] [00:46:07/00:08:23, 0.672s/it]: train_loss_raw=2.2278, running_loss=2.2964, LR=0.000100
[2025-08-25 21:48:30,537][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004128] [Batch 04128/04869] [00:46:12/00:08:17, 0.672s/it]: train_loss_raw=2.3075, running_loss=2.2969, LR=0.000100
[2025-08-25 21:48:36,040][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004136] [Batch 04136/04869] [00:46:18/00:08:12, 0.672s/it]: train_loss_raw=2.2722, running_loss=2.2969, LR=0.000100
[2025-08-25 21:48:41,406][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004144] [Batch 04144/04869] [00:46:23/00:08:06, 0.672s/it]: train_loss_raw=2.1965, running_loss=2.2965, LR=0.000100
[2025-08-25 21:48:46,653][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004152] [Batch 04152/04869] [00:46:28/00:08:01, 0.672s/it]: train_loss_raw=2.2675, running_loss=2.2947, LR=0.000100
[2025-08-25 21:48:51,846][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004160] [Batch 04160/04869] [00:46:34/00:07:56, 0.672s/it]: train_loss_raw=2.2555, running_loss=2.2952, LR=0.000100
[2025-08-25 21:48:57,025][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004168] [Batch 04168/04869] [00:46:39/00:07:50, 0.672s/it]: train_loss_raw=2.3245, running_loss=2.2941, LR=0.000100
[2025-08-25 21:49:02,231][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004176] [Batch 04176/04869] [00:46:44/00:07:45, 0.672s/it]: train_loss_raw=2.2713, running_loss=2.2941, LR=0.000100
[2025-08-25 21:49:07,470][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004184] [Batch 04184/04869] [00:46:49/00:07:39, 0.672s/it]: train_loss_raw=2.3261, running_loss=2.2912, LR=0.000100
[2025-08-25 21:49:12,719][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004192] [Batch 04192/04869] [00:46:54/00:07:34, 0.672s/it]: train_loss_raw=2.2718, running_loss=2.2901, LR=0.000100
[2025-08-25 21:49:17,937][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004200] [Batch 04200/04869] [00:47:00/00:07:29, 0.671s/it]: train_loss_raw=2.2836, running_loss=2.2898, LR=0.000100
[2025-08-25 21:49:23,467][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004208] [Batch 04208/04869] [00:47:05/00:07:23, 0.672s/it]: train_loss_raw=2.2990, running_loss=2.2904, LR=0.000100
[2025-08-25 21:49:28,715][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004216] [Batch 04216/04869] [00:47:10/00:07:18, 0.671s/it]: train_loss_raw=2.3011, running_loss=2.2905, LR=0.000100
[2025-08-25 21:49:34,290][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004224] [Batch 04224/04869] [00:47:16/00:07:13, 0.672s/it]: train_loss_raw=2.2585, running_loss=2.2907, LR=0.000100
[2025-08-25 21:49:39,730][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004232] [Batch 04232/04869] [00:47:21/00:07:07, 0.672s/it]: train_loss_raw=2.2691, running_loss=2.2906, LR=0.000100
[2025-08-25 21:49:45,005][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004240] [Batch 04240/04869] [00:47:27/00:07:02, 0.672s/it]: train_loss_raw=2.3089, running_loss=2.2925, LR=0.000100
[2025-08-25 21:49:50,486][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004248] [Batch 04248/04869] [00:47:32/00:06:57, 0.672s/it]: train_loss_raw=2.2529, running_loss=2.2921, LR=0.000100
[2025-08-25 21:49:55,800][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004256] [Batch 04256/04869] [00:47:38/00:06:51, 0.672s/it]: train_loss_raw=2.3420, running_loss=2.2918, LR=0.000100
[2025-08-25 21:50:01,269][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004264] [Batch 04264/04869] [00:47:43/00:06:46, 0.672s/it]: train_loss_raw=2.2592, running_loss=2.2927, LR=0.000100
[2025-08-25 21:50:06,527][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004272] [Batch 04272/04869] [00:47:48/00:06:40, 0.672s/it]: train_loss_raw=2.2587, running_loss=2.2915, LR=0.000100
[2025-08-25 21:50:12,176][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004280] [Batch 04280/04869] [00:47:54/00:06:35, 0.672s/it]: train_loss_raw=2.3235, running_loss=2.2912, LR=0.000100
[2025-08-25 21:50:17,517][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004288] [Batch 04288/04869] [00:47:59/00:06:30, 0.672s/it]: train_loss_raw=2.2589, running_loss=2.2904, LR=0.000100
[2025-08-25 21:50:23,336][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004296] [Batch 04296/04869] [00:48:05/00:06:24, 0.672s/it]: train_loss_raw=2.2423, running_loss=2.2882, LR=0.000100
[2025-08-25 21:50:29,391][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004304] [Batch 04304/04869] [00:48:11/00:06:19, 0.672s/it]: train_loss_raw=2.3103, running_loss=2.2870, LR=0.000100
[2025-08-25 21:50:35,067][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004312] [Batch 04312/04869] [00:48:17/00:06:14, 0.672s/it]: train_loss_raw=2.3495, running_loss=2.2873, LR=0.000100
[2025-08-25 21:50:40,684][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004320] [Batch 04320/04869] [00:48:22/00:06:08, 0.672s/it]: train_loss_raw=2.2519, running_loss=2.2874, LR=0.000100
[2025-08-25 21:50:47,019][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004328] [Batch 04328/04869] [00:48:29/00:06:03, 0.672s/it]: train_loss_raw=2.2796, running_loss=2.2863, LR=0.000100
[2025-08-25 21:50:52,967][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004336] [Batch 04336/04869] [00:48:35/00:05:58, 0.672s/it]: train_loss_raw=2.2909, running_loss=2.2860, LR=0.000100
[2025-08-25 21:50:58,737][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004344] [Batch 04344/04869] [00:48:40/00:05:53, 0.672s/it]: train_loss_raw=2.2612, running_loss=2.2841, LR=0.000100
[2025-08-25 21:51:04,131][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004352] [Batch 04352/04869] [00:48:46/00:05:47, 0.672s/it]: train_loss_raw=2.3257, running_loss=2.2847, LR=0.000100
[2025-08-25 21:51:09,834][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004360] [Batch 04360/04869] [00:48:52/00:05:42, 0.672s/it]: train_loss_raw=2.2651, running_loss=2.2839, LR=0.000100
[2025-08-25 21:51:15,420][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004368] [Batch 04368/04869] [00:48:57/00:05:36, 0.673s/it]: train_loss_raw=2.2301, running_loss=2.2829, LR=0.000100
[2025-08-25 21:51:21,095][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004376] [Batch 04376/04869] [00:49:03/00:05:31, 0.673s/it]: train_loss_raw=2.3081, running_loss=2.2820, LR=0.000100
[2025-08-25 21:51:26,861][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004384] [Batch 04384/04869] [00:49:09/00:05:26, 0.673s/it]: train_loss_raw=2.2729, running_loss=2.2822, LR=0.000100
[2025-08-25 21:51:32,644][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004392] [Batch 04392/04869] [00:49:14/00:05:20, 0.673s/it]: train_loss_raw=2.3444, running_loss=2.2821, LR=0.000100
[2025-08-25 21:51:38,523][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004400] [Batch 04400/04869] [00:49:20/00:05:15, 0.673s/it]: train_loss_raw=2.2851, running_loss=2.2812, LR=0.000100
[2025-08-25 21:51:44,075][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004408] [Batch 04408/04869] [00:49:26/00:05:10, 0.673s/it]: train_loss_raw=2.2493, running_loss=2.2802, LR=0.000100
[2025-08-25 21:51:49,832][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004416] [Batch 04416/04869] [00:49:32/00:05:04, 0.673s/it]: train_loss_raw=2.3074, running_loss=2.2792, LR=0.000100
[2025-08-25 21:51:55,889][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004424] [Batch 04424/04869] [00:49:38/00:04:59, 0.673s/it]: train_loss_raw=2.2728, running_loss=2.2785, LR=0.000100
[2025-08-25 21:52:01,159][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004432] [Batch 04432/04869] [00:49:43/00:04:54, 0.673s/it]: train_loss_raw=2.2520, running_loss=2.2781, LR=0.000100
[2025-08-25 21:52:06,804][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004440] [Batch 04440/04869] [00:49:49/00:04:48, 0.673s/it]: train_loss_raw=2.3009, running_loss=2.2778, LR=0.000100
[2025-08-25 21:52:12,324][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004448] [Batch 04448/04869] [00:49:54/00:04:43, 0.673s/it]: train_loss_raw=2.3576, running_loss=2.2763, LR=0.000100
[2025-08-25 21:52:18,280][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004456] [Batch 04456/04869] [00:50:00/00:04:38, 0.673s/it]: train_loss_raw=2.2388, running_loss=2.2774, LR=0.000100
[2025-08-25 21:52:23,669][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004464] [Batch 04464/04869] [00:50:05/00:04:32, 0.673s/it]: train_loss_raw=2.2637, running_loss=2.2761, LR=0.000100
[2025-08-25 21:52:29,356][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004472] [Batch 04472/04869] [00:50:11/00:04:27, 0.673s/it]: train_loss_raw=2.2837, running_loss=2.2763, LR=0.000100
[2025-08-25 21:52:34,787][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004480] [Batch 04480/04869] [00:50:17/00:04:21, 0.673s/it]: train_loss_raw=2.2245, running_loss=2.2737, LR=0.000100
[2025-08-25 21:52:40,019][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004488] [Batch 04488/04869] [00:50:22/00:04:16, 0.673s/it]: train_loss_raw=2.3429, running_loss=2.2743, LR=0.000100
[2025-08-25 21:52:45,715][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004496] [Batch 04496/04869] [00:50:27/00:04:11, 0.673s/it]: train_loss_raw=2.3195, running_loss=2.2758, LR=0.000100
[2025-08-25 21:52:51,519][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004504] [Batch 04504/04869] [00:50:33/00:04:05, 0.674s/it]: train_loss_raw=2.2438, running_loss=2.2743, LR=0.000100
[2025-08-25 21:52:57,266][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004512] [Batch 04512/04869] [00:50:39/00:04:00, 0.674s/it]: train_loss_raw=2.2521, running_loss=2.2731, LR=0.000100
[2025-08-25 21:53:03,212][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004520] [Batch 04520/04869] [00:50:45/00:03:55, 0.674s/it]: train_loss_raw=2.3089, running_loss=2.2732, LR=0.000100
[2025-08-25 21:53:09,089][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004528] [Batch 04528/04869] [00:50:51/00:03:49, 0.674s/it]: train_loss_raw=2.2142, running_loss=2.2727, LR=0.000100
[2025-08-25 21:53:14,910][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004536] [Batch 04536/04869] [00:50:57/00:03:44, 0.674s/it]: train_loss_raw=2.2195, running_loss=2.2727, LR=0.000100
[2025-08-25 21:53:20,801][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004544] [Batch 04544/04869] [00:51:03/00:03:39, 0.674s/it]: train_loss_raw=2.2563, running_loss=2.2709, LR=0.000100
[2025-08-25 21:53:26,518][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004552] [Batch 04552/04869] [00:51:08/00:03:33, 0.674s/it]: train_loss_raw=2.2528, running_loss=2.2709, LR=0.000100
[2025-08-25 21:53:32,211][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004560] [Batch 04560/04869] [00:51:14/00:03:28, 0.674s/it]: train_loss_raw=2.1743, running_loss=2.2703, LR=0.000100
[2025-08-25 21:53:37,939][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004568] [Batch 04568/04869] [00:51:20/00:03:22, 0.674s/it]: train_loss_raw=2.3038, running_loss=2.2684, LR=0.000100
[2025-08-25 21:53:43,726][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004576] [Batch 04576/04869] [00:51:25/00:03:17, 0.674s/it]: train_loss_raw=2.3165, running_loss=2.2681, LR=0.000100
[2025-08-25 21:53:49,462][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004584] [Batch 04584/04869] [00:51:31/00:03:12, 0.674s/it]: train_loss_raw=2.2853, running_loss=2.2687, LR=0.000100
[2025-08-25 21:53:54,925][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004592] [Batch 04592/04869] [00:51:37/00:03:06, 0.674s/it]: train_loss_raw=2.3166, running_loss=2.2698, LR=0.000100
[2025-08-25 21:54:00,777][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004600] [Batch 04600/04869] [00:51:42/00:03:01, 0.675s/it]: train_loss_raw=2.3058, running_loss=2.2704, LR=0.000100
[2025-08-25 21:54:06,645][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004608] [Batch 04608/04869] [00:51:48/00:02:56, 0.675s/it]: train_loss_raw=2.2383, running_loss=2.2683, LR=0.000100
[2025-08-25 21:54:12,315][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004616] [Batch 04616/04869] [00:51:54/00:02:50, 0.675s/it]: train_loss_raw=2.2527, running_loss=2.2676, LR=0.000100
[2025-08-25 21:54:17,977][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004624] [Batch 04624/04869] [00:52:00/00:02:45, 0.675s/it]: train_loss_raw=2.2291, running_loss=2.2639, LR=0.000100
[2025-08-25 21:54:23,759][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004632] [Batch 04632/04869] [00:52:05/00:02:39, 0.675s/it]: train_loss_raw=2.2712, running_loss=2.2628, LR=0.000100
[2025-08-25 21:54:29,550][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004640] [Batch 04640/04869] [00:52:11/00:02:34, 0.675s/it]: train_loss_raw=2.3045, running_loss=2.2621, LR=0.000100
[2025-08-25 21:54:35,568][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004648] [Batch 04648/04869] [00:52:17/00:02:29, 0.675s/it]: train_loss_raw=2.2202, running_loss=2.2603, LR=0.000100
[2025-08-25 21:54:41,446][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004656] [Batch 04656/04869] [00:52:23/00:02:23, 0.675s/it]: train_loss_raw=2.2818, running_loss=2.2619, LR=0.000100
[2025-08-25 21:54:47,185][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004664] [Batch 04664/04869] [00:52:29/00:02:18, 0.675s/it]: train_loss_raw=2.2541, running_loss=2.2615, LR=0.000100
[2025-08-25 21:54:52,570][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004672] [Batch 04672/04869] [00:52:34/00:02:13, 0.675s/it]: train_loss_raw=2.1968, running_loss=2.2608, LR=0.000100
[2025-08-25 21:54:58,123][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004680] [Batch 04680/04869] [00:52:40/00:02:07, 0.675s/it]: train_loss_raw=2.2316, running_loss=2.2619, LR=0.000100
[2025-08-25 21:55:03,944][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004688] [Batch 04688/04869] [00:52:46/00:02:02, 0.675s/it]: train_loss_raw=2.3172, running_loss=2.2619, LR=0.000100
[2025-08-25 21:55:09,919][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004696] [Batch 04696/04869] [00:52:52/00:01:56, 0.675s/it]: train_loss_raw=2.2275, running_loss=2.2594, LR=0.000100
[2025-08-25 21:55:15,645][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004704] [Batch 04704/04869] [00:52:57/00:01:51, 0.676s/it]: train_loss_raw=2.2346, running_loss=2.2570, LR=0.000100
[2025-08-25 21:55:21,528][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004712] [Batch 04712/04869] [00:53:03/00:01:46, 0.676s/it]: train_loss_raw=2.2729, running_loss=2.2574, LR=0.000100
[2025-08-25 21:55:27,395][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004720] [Batch 04720/04869] [00:53:09/00:01:40, 0.676s/it]: train_loss_raw=2.1820, running_loss=2.2570, LR=0.000100
[2025-08-25 21:55:33,254][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004728] [Batch 04728/04869] [00:53:15/00:01:35, 0.676s/it]: train_loss_raw=2.2629, running_loss=2.2568, LR=0.000100
[2025-08-25 21:55:39,171][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004736] [Batch 04736/04869] [00:53:21/00:01:29, 0.676s/it]: train_loss_raw=2.3029, running_loss=2.2578, LR=0.000100
[2025-08-25 21:55:45,211][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004744] [Batch 04744/04869] [00:53:27/00:01:24, 0.676s/it]: train_loss_raw=2.2765, running_loss=2.2583, LR=0.000100
[2025-08-25 21:55:51,285][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004752] [Batch 04752/04869] [00:53:33/00:01:19, 0.676s/it]: train_loss_raw=2.2945, running_loss=2.2597, LR=0.000100
[2025-08-25 21:55:57,103][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004760] [Batch 04760/04869] [00:53:39/00:01:13, 0.676s/it]: train_loss_raw=2.3038, running_loss=2.2586, LR=0.000100
[2025-08-25 21:56:02,910][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004768] [Batch 04768/04869] [00:53:45/00:01:08, 0.676s/it]: train_loss_raw=2.2528, running_loss=2.2563, LR=0.000100
[2025-08-25 21:56:08,749][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004776] [Batch 04776/04869] [00:53:50/00:01:02, 0.677s/it]: train_loss_raw=2.1638, running_loss=2.2553, LR=0.000100
[2025-08-25 21:56:14,230][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004784] [Batch 04784/04869] [00:53:56/00:00:57, 0.677s/it]: train_loss_raw=2.2282, running_loss=2.2564, LR=0.000100
[2025-08-25 21:56:19,972][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004792] [Batch 04792/04869] [00:54:02/00:00:52, 0.677s/it]: train_loss_raw=2.2648, running_loss=2.2548, LR=0.000100
[2025-08-25 21:56:25,666][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004800] [Batch 04800/04869] [00:54:07/00:00:46, 0.677s/it]: train_loss_raw=2.2420, running_loss=2.2557, LR=0.000100
[2025-08-25 21:56:31,467][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004808] [Batch 04808/04869] [00:54:13/00:00:41, 0.677s/it]: train_loss_raw=2.2535, running_loss=2.2573, LR=0.000100
[2025-08-25 21:56:37,361][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004816] [Batch 04816/04869] [00:54:19/00:00:35, 0.677s/it]: train_loss_raw=2.2633, running_loss=2.2569, LR=0.000100
[2025-08-25 21:56:43,047][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004824] [Batch 04824/04869] [00:54:25/00:00:30, 0.677s/it]: train_loss_raw=2.1582, running_loss=2.2572, LR=0.000100
[2025-08-25 21:56:48,707][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004832] [Batch 04832/04869] [00:54:30/00:00:25, 0.677s/it]: train_loss_raw=2.3112, running_loss=2.2593, LR=0.000100
[2025-08-25 21:56:54,340][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004840] [Batch 04840/04869] [00:54:36/00:00:19, 0.677s/it]: train_loss_raw=2.2815, running_loss=2.2594, LR=0.000100
[2025-08-25 21:56:59,905][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004848] [Batch 04848/04869] [00:54:42/00:00:14, 0.677s/it]: train_loss_raw=2.3238, running_loss=2.2585, LR=0.000100
[2025-08-25 21:57:05,700][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004856] [Batch 04856/04869] [00:54:47/00:00:08, 0.677s/it]: train_loss_raw=2.2573, running_loss=2.2584, LR=0.000100
[2025-08-25 21:57:11,188][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004864] [Batch 04864/04869] [00:54:53/00:00:03, 0.677s/it]: train_loss_raw=2.2721, running_loss=2.2582, LR=0.000100
[2025-08-25 21:57:22,537][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-25 21:57:30,505][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00015/00124] [00:00:07/00:00:53, 0.498s/it]
[2025-08-25 21:57:41,792][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00023/00124] [00:00:19/00:01:20, 0.802s/it]
[2025-08-25 21:57:52,982][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00031/00124] [00:00:30/00:01:27, 0.951s/it]
[2025-08-25 21:58:12,938][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00039/00124] [00:00:50/00:01:45, 1.260s/it]
[2025-08-25 21:58:24,074][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00047/00124] [00:01:01/00:01:37, 1.282s/it]
[2025-08-25 21:58:34,726][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00055/00124] [00:01:12/00:01:27, 1.289s/it]
[2025-08-25 21:58:45,145][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00063/00124] [00:01:22/00:01:17, 1.291s/it]
[2025-08-25 21:58:56,039][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00071/00124] [00:01:33/00:01:07, 1.299s/it]
[2025-08-25 21:59:06,591][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00079/00124] [00:01:44/00:00:57, 1.301s/it]
[2025-08-25 21:59:17,062][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00087/00124] [00:01:54/00:00:46, 1.301s/it]
[2025-08-25 21:59:28,280][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00095/00124] [00:02:05/00:00:36, 1.310s/it]
[2025-08-25 21:59:39,884][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00103/00124] [00:02:17/00:00:26, 1.321s/it]
[2025-08-25 21:59:51,641][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00111/00124] [00:02:29/00:00:15, 1.331s/it]
[2025-08-25 22:00:02,405][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00119/00124] [00:02:39/00:00:05, 1.332s/it]
[2025-08-25 22:00:12,928][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00003/00124] [00:02:50/01:25:11, 42.598s/it]
[2025-08-25 22:00:20,210][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=2.25611, valid_loss=2.31024
[2025-08-25 22:00:20,210][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-25 22:00:20,211][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.822
[2025-08-25 22:00:20,211][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.015
[2025-08-25 22:00:20,211][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.015
[2025-08-25 22:00:20,211][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.000
[2025-08-25 22:00:20,218][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:58:02, remaining time 28:03:10, 00:58:02 per epoch
[2025-08-25 22:00:22,064][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004872] [Batch 00003/04869] [00:00:01/00:43:51, 0.541s/it]: train_loss_raw=2.2628, running_loss=2.1696, LR=0.000100
[2025-08-25 22:00:27,915][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004880] [Batch 00011/04869] [00:00:07/00:55:00, 0.679s/it]: train_loss_raw=2.1483, running_loss=2.1747, LR=0.000100
[2025-08-25 22:00:33,485][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004888] [Batch 00019/04869] [00:00:13/00:55:29, 0.686s/it]: train_loss_raw=2.1661, running_loss=2.1757, LR=0.000100
[2025-08-25 22:00:39,209][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004896] [Batch 00027/04869] [00:00:18/00:56:05, 0.695s/it]: train_loss_raw=2.2992, running_loss=2.1797, LR=0.000100
[2025-08-25 22:00:44,790][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004904] [Batch 00035/04869] [00:00:24/00:56:02, 0.696s/it]: train_loss_raw=2.1920, running_loss=2.1831, LR=0.000100
[2025-08-25 22:00:50,519][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004912] [Batch 00043/04869] [00:00:30/00:56:15, 0.699s/it]: train_loss_raw=2.2125, running_loss=2.1867, LR=0.000100
[2025-08-25 22:00:56,550][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004920] [Batch 00051/04869] [00:00:36/00:56:51, 0.708s/it]: train_loss_raw=2.1871, running_loss=2.1885, LR=0.000100
[2025-08-25 22:01:01,885][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004928] [Batch 00059/04869] [00:00:41/00:56:18, 0.702s/it]: train_loss_raw=2.2568, running_loss=2.1921, LR=0.000100
[2025-08-25 22:01:07,689][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004936] [Batch 00067/04869] [00:00:47/00:56:26, 0.705s/it]: train_loss_raw=2.1889, running_loss=2.1934, LR=0.000100
[2025-08-25 22:01:13,425][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004944] [Batch 00075/04869] [00:00:52/00:56:26, 0.706s/it]: train_loss_raw=2.2995, running_loss=2.1979, LR=0.000100
[2025-08-25 22:01:19,085][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004952] [Batch 00083/04869] [00:00:58/00:56:21, 0.707s/it]: train_loss_raw=2.2367, running_loss=2.1998, LR=0.000100
[2025-08-25 22:01:24,754][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004960] [Batch 00091/04869] [00:01:04/00:56:16, 0.707s/it]: train_loss_raw=2.1931, running_loss=2.1994, LR=0.000100
[2025-08-25 22:01:30,389][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004968] [Batch 00099/04869] [00:01:09/00:56:10, 0.707s/it]: train_loss_raw=2.2419, running_loss=2.2012, LR=0.000100
[2025-08-25 22:01:35,925][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004976] [Batch 00107/04869] [00:01:15/00:55:59, 0.705s/it]: train_loss_raw=2.2271, running_loss=2.2036, LR=0.000100
[2025-08-25 22:01:41,476][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004984] [Batch 00115/04869] [00:01:21/00:55:49, 0.705s/it]: train_loss_raw=2.2080, running_loss=2.2054, LR=0.000100
[2025-08-25 22:01:47,161][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004992] [Batch 00123/04869] [00:01:26/00:55:46, 0.705s/it]: train_loss_raw=2.2494, running_loss=2.2072, LR=0.000100
[2025-08-25 22:01:52,769][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005000] [Batch 00131/04869] [00:01:32/00:55:39, 0.705s/it]: train_loss_raw=2.3081, running_loss=2.2092, LR=0.000100
[2025-08-25 22:01:57,936][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005008] [Batch 00139/04869] [00:01:37/00:55:17, 0.701s/it]: train_loss_raw=2.2142, running_loss=2.2100, LR=0.000100
[2025-08-25 22:02:03,270][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005016] [Batch 00147/04869] [00:01:42/00:55:03, 0.700s/it]: train_loss_raw=2.2133, running_loss=2.2099, LR=0.000100
[2025-08-25 22:02:08,746][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005024] [Batch 00155/04869] [00:01:48/00:54:53, 0.699s/it]: train_loss_raw=2.2557, running_loss=2.2127, LR=0.000100
[2025-08-25 22:02:13,953][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005032] [Batch 00163/04869] [00:01:53/00:54:37, 0.696s/it]: train_loss_raw=2.1948, running_loss=2.2134, LR=0.000100
[2025-08-25 22:02:19,277][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005040] [Batch 00171/04869] [00:01:58/00:54:24, 0.695s/it]: train_loss_raw=2.2803, running_loss=2.2154, LR=0.000100
[2025-08-25 22:02:24,605][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005048] [Batch 00179/04869] [00:02:04/00:54:13, 0.694s/it]: train_loss_raw=2.2525, running_loss=2.2173, LR=0.000100
[2025-08-25 22:02:30,057][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005056] [Batch 00187/04869] [00:02:09/00:54:05, 0.693s/it]: train_loss_raw=2.1629, running_loss=2.2193, LR=0.000100
[2025-08-25 22:02:35,701][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005064] [Batch 00195/04869] [00:02:15/00:54:02, 0.694s/it]: train_loss_raw=2.2579, running_loss=2.2213, LR=0.000100
[2025-08-25 22:02:41,343][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005072] [Batch 00203/04869] [00:02:20/00:53:58, 0.694s/it]: train_loss_raw=2.2166, running_loss=2.2194, LR=0.000100
[2025-08-25 22:02:46,981][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005080] [Batch 00211/04869] [00:02:26/00:53:54, 0.694s/it]: train_loss_raw=2.2095, running_loss=2.2200, LR=0.000100
[2025-08-25 22:02:52,734][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005088] [Batch 00219/04869] [00:02:32/00:53:53, 0.695s/it]: train_loss_raw=2.2514, running_loss=2.2231, LR=0.000100
[2025-08-25 22:02:58,444][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005096] [Batch 00227/04869] [00:02:38/00:53:51, 0.696s/it]: train_loss_raw=2.3103, running_loss=2.2245, LR=0.000100
[2025-08-25 22:03:04,144][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005104] [Batch 00235/04869] [00:02:43/00:53:48, 0.697s/it]: train_loss_raw=2.1300, running_loss=2.2238, LR=0.000100
[2025-08-25 22:03:09,799][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005112] [Batch 00243/04869] [00:02:49/00:53:44, 0.697s/it]: train_loss_raw=2.2791, running_loss=2.2274, LR=0.000100
[2025-08-25 22:03:15,485][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005120] [Batch 00251/04869] [00:02:55/00:53:40, 0.697s/it]: train_loss_raw=2.1680, running_loss=2.2283, LR=0.000100
[2025-08-25 22:03:21,132][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005128] [Batch 00259/04869] [00:03:00/00:53:36, 0.698s/it]: train_loss_raw=2.2305, running_loss=2.2296, LR=0.000100
[2025-08-25 22:03:26,681][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005136] [Batch 00267/04869] [00:03:06/00:53:30, 0.698s/it]: train_loss_raw=2.2748, running_loss=2.2290, LR=0.000100
[2025-08-25 22:03:32,312][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005144] [Batch 00275/04869] [00:03:11/00:53:25, 0.698s/it]: train_loss_raw=2.2926, running_loss=2.2294, LR=0.000100
[2025-08-25 22:03:37,971][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005152] [Batch 00283/04869] [00:03:17/00:53:20, 0.698s/it]: train_loss_raw=2.2034, running_loss=2.2269, LR=0.000100
[2025-08-25 22:03:43,708][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005160] [Batch 00291/04869] [00:03:23/00:53:17, 0.699s/it]: train_loss_raw=2.1803, running_loss=2.2277, LR=0.000100
[2025-08-25 22:03:49,611][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005168] [Batch 00299/04869] [00:03:29/00:53:17, 0.700s/it]: train_loss_raw=2.2681, running_loss=2.2281, LR=0.000100
[2025-08-25 22:03:55,464][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005176] [Batch 00307/04869] [00:03:35/00:53:15, 0.700s/it]: train_loss_raw=2.2998, running_loss=2.2292, LR=0.000100
[2025-08-25 22:04:00,869][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005184] [Batch 00315/04869] [00:03:40/00:53:06, 0.700s/it]: train_loss_raw=2.2353, running_loss=2.2279, LR=0.000100
[2025-08-25 22:04:06,372][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005192] [Batch 00323/04869] [00:03:45/00:52:59, 0.699s/it]: train_loss_raw=2.2349, running_loss=2.2279, LR=0.000100
[2025-08-25 22:04:12,056][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005200] [Batch 00331/04869] [00:03:51/00:52:55, 0.700s/it]: train_loss_raw=2.2343, running_loss=2.2272, LR=0.000100
[2025-08-25 22:04:17,735][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005208] [Batch 00339/04869] [00:03:57/00:52:50, 0.700s/it]: train_loss_raw=2.1491, running_loss=2.2258, LR=0.000100
[2025-08-25 22:04:23,385][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005216] [Batch 00347/04869] [00:04:02/00:52:45, 0.700s/it]: train_loss_raw=2.2138, running_loss=2.2257, LR=0.000100
[2025-08-25 22:04:29,229][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005224] [Batch 00355/04869] [00:04:08/00:52:43, 0.701s/it]: train_loss_raw=2.2187, running_loss=2.2265, LR=0.000100
[2025-08-25 22:04:34,773][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005232] [Batch 00363/04869] [00:04:14/00:52:37, 0.701s/it]: train_loss_raw=2.2894, running_loss=2.2275, LR=0.000100
[2025-08-25 22:04:40,315][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005240] [Batch 00371/04869] [00:04:19/00:52:30, 0.700s/it]: train_loss_raw=2.2253, running_loss=2.2264, LR=0.000100
[2025-08-25 22:04:45,997][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005248] [Batch 00379/04869] [00:04:25/00:52:26, 0.701s/it]: train_loss_raw=2.1869, running_loss=2.2277, LR=0.000100
[2025-08-25 22:04:51,722][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005256] [Batch 00387/04869] [00:04:31/00:52:21, 0.701s/it]: train_loss_raw=2.2527, running_loss=2.2271, LR=0.000100
[2025-08-25 22:04:57,430][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005264] [Batch 00395/04869] [00:04:36/00:52:17, 0.701s/it]: train_loss_raw=2.2034, running_loss=2.2280, LR=0.000100
[2025-08-25 22:05:03,143][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005272] [Batch 00403/04869] [00:04:42/00:52:12, 0.701s/it]: train_loss_raw=2.2765, running_loss=2.2277, LR=0.000100
[2025-08-25 22:05:08,863][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005280] [Batch 00411/04869] [00:04:48/00:52:08, 0.702s/it]: train_loss_raw=2.1769, running_loss=2.2242, LR=0.000100
[2025-08-25 22:05:14,634][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005288] [Batch 00419/04869] [00:04:54/00:52:04, 0.702s/it]: train_loss_raw=2.2214, running_loss=2.2256, LR=0.000100
[2025-08-25 22:05:20,304][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005296] [Batch 00427/04869] [00:04:59/00:51:59, 0.702s/it]: train_loss_raw=2.2702, running_loss=2.2238, LR=0.000100
[2025-08-25 22:05:25,963][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005304] [Batch 00435/04869] [00:05:05/00:51:54, 0.702s/it]: train_loss_raw=2.1949, running_loss=2.2227, LR=0.000100
[2025-08-25 22:05:31,662][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005312] [Batch 00443/04869] [00:05:11/00:51:49, 0.703s/it]: train_loss_raw=2.1789, running_loss=2.2222, LR=0.000100
[2025-08-25 22:05:36,965][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005320] [Batch 00451/04869] [00:05:16/00:51:40, 0.702s/it]: train_loss_raw=2.2723, running_loss=2.2216, LR=0.000100
[2025-08-25 22:05:42,230][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005328] [Batch 00459/04869] [00:05:21/00:51:31, 0.701s/it]: train_loss_raw=2.2959, running_loss=2.2222, LR=0.000100
[2025-08-25 22:05:47,679][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005336] [Batch 00467/04869] [00:05:27/00:51:24, 0.701s/it]: train_loss_raw=2.1853, running_loss=2.2227, LR=0.000100
[2025-08-25 22:05:53,010][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005344] [Batch 00475/04869] [00:05:32/00:51:16, 0.700s/it]: train_loss_raw=2.2565, running_loss=2.2213, LR=0.000100
[2025-08-25 22:05:58,298][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005352] [Batch 00483/04869] [00:05:37/00:51:07, 0.699s/it]: train_loss_raw=2.1818, running_loss=2.2198, LR=0.000100
[2025-08-25 22:06:03,543][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005360] [Batch 00491/04869] [00:05:43/00:50:59, 0.699s/it]: train_loss_raw=2.2169, running_loss=2.2184, LR=0.000100
[2025-08-25 22:06:09,229][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005368] [Batch 00499/04869] [00:05:48/00:50:54, 0.699s/it]: train_loss_raw=2.2994, running_loss=2.2207, LR=0.000100
[2025-08-25 22:06:14,584][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005376] [Batch 00507/04869] [00:05:54/00:50:46, 0.699s/it]: train_loss_raw=2.1907, running_loss=2.2199, LR=0.000100
[2025-08-25 22:06:19,801][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005384] [Batch 00515/04869] [00:05:59/00:50:38, 0.698s/it]: train_loss_raw=2.2050, running_loss=2.2188, LR=0.000100
[2025-08-25 22:06:25,563][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005392] [Batch 00523/04869] [00:06:05/00:50:34, 0.698s/it]: train_loss_raw=2.2675, running_loss=2.2189, LR=0.000100
[2025-08-25 22:06:30,827][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005400] [Batch 00531/04869] [00:06:10/00:50:25, 0.698s/it]: train_loss_raw=2.2768, running_loss=2.2198, LR=0.000100
[2025-08-25 22:06:36,561][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005408] [Batch 00539/04869] [00:06:16/00:50:21, 0.698s/it]: train_loss_raw=2.1759, running_loss=2.2207, LR=0.000100
[2025-08-25 22:06:41,768][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005416] [Batch 00547/04869] [00:06:21/00:50:12, 0.697s/it]: train_loss_raw=2.2055, running_loss=2.2197, LR=0.000100
[2025-08-25 22:06:47,137][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005424] [Batch 00555/04869] [00:06:26/00:50:05, 0.697s/it]: train_loss_raw=2.2592, running_loss=2.2176, LR=0.000100
[2025-08-25 22:06:52,819][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005432] [Batch 00563/04869] [00:06:32/00:50:01, 0.697s/it]: train_loss_raw=2.2033, running_loss=2.2187, LR=0.000100
[2025-08-25 22:06:58,514][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005440] [Batch 00571/04869] [00:06:38/00:49:56, 0.697s/it]: train_loss_raw=2.1829, running_loss=2.2193, LR=0.000100
[2025-08-25 22:07:04,179][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005448] [Batch 00579/04869] [00:06:43/00:49:51, 0.697s/it]: train_loss_raw=2.2131, running_loss=2.2203, LR=0.000100
[2025-08-25 22:07:10,027][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005456] [Batch 00587/04869] [00:06:49/00:49:47, 0.698s/it]: train_loss_raw=2.1897, running_loss=2.2192, LR=0.000100
[2025-08-25 22:07:15,432][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005464] [Batch 00595/04869] [00:06:54/00:49:40, 0.697s/it]: train_loss_raw=2.1877, running_loss=2.2169, LR=0.000100
[2025-08-25 22:07:20,724][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005472] [Batch 00603/04869] [00:07:00/00:49:33, 0.697s/it]: train_loss_raw=2.1541, running_loss=2.2154, LR=0.000100
[2025-08-25 22:07:26,293][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005480] [Batch 00611/04869] [00:07:05/00:49:27, 0.697s/it]: train_loss_raw=2.1694, running_loss=2.2159, LR=0.000100
[2025-08-25 22:07:31,553][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005488] [Batch 00619/04869] [00:07:11/00:49:19, 0.696s/it]: train_loss_raw=2.1563, running_loss=2.2138, LR=0.000100
[2025-08-25 22:07:36,868][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005496] [Batch 00627/04869] [00:07:16/00:49:12, 0.696s/it]: train_loss_raw=2.2330, running_loss=2.2125, LR=0.000100
[2025-08-25 22:07:42,031][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005504] [Batch 00635/04869] [00:07:21/00:49:04, 0.695s/it]: train_loss_raw=2.2148, running_loss=2.2123, LR=0.000100
[2025-08-25 22:07:47,376][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005512] [Batch 00643/04869] [00:07:26/00:48:57, 0.695s/it]: train_loss_raw=2.1969, running_loss=2.2124, LR=0.000100
[2025-08-25 22:07:52,829][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005520] [Batch 00651/04869] [00:07:32/00:48:51, 0.695s/it]: train_loss_raw=2.2012, running_loss=2.2145, LR=0.000100
[2025-08-25 22:07:58,110][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005528] [Batch 00659/04869] [00:07:37/00:48:43, 0.694s/it]: train_loss_raw=2.1870, running_loss=2.2157, LR=0.000100
[2025-08-25 22:08:03,700][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005536] [Batch 00667/04869] [00:07:43/00:48:38, 0.695s/it]: train_loss_raw=2.2554, running_loss=2.2165, LR=0.000100
[2025-08-25 22:08:09,492][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005544] [Batch 00675/04869] [00:07:49/00:48:34, 0.695s/it]: train_loss_raw=2.1381, running_loss=2.2160, LR=0.000100
[2025-08-25 22:08:14,938][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005552] [Batch 00683/04869] [00:07:54/00:48:28, 0.695s/it]: train_loss_raw=2.2289, running_loss=2.2161, LR=0.000100
[2025-08-25 22:08:20,387][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005560] [Batch 00691/04869] [00:07:59/00:48:21, 0.695s/it]: train_loss_raw=2.2632, running_loss=2.2178, LR=0.000100
[2025-08-25 22:08:25,730][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005568] [Batch 00699/04869] [00:08:05/00:48:15, 0.694s/it]: train_loss_raw=2.2481, running_loss=2.2158, LR=0.000100
[2025-08-25 22:08:31,430][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005576] [Batch 00707/04869] [00:08:10/00:48:10, 0.694s/it]: train_loss_raw=2.2703, running_loss=2.2147, LR=0.000100
[2025-08-25 22:08:37,019][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005584] [Batch 00715/04869] [00:08:16/00:48:05, 0.695s/it]: train_loss_raw=2.2721, running_loss=2.2141, LR=0.000100
[2025-08-25 22:08:42,166][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005592] [Batch 00723/04869] [00:08:21/00:47:57, 0.694s/it]: train_loss_raw=2.2225, running_loss=2.2136, LR=0.000100
[2025-08-25 22:08:47,306][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005600] [Batch 00731/04869] [00:08:26/00:47:49, 0.693s/it]: train_loss_raw=2.2155, running_loss=2.2156, LR=0.000100
[2025-08-25 22:08:52,765][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005608] [Batch 00739/04869] [00:08:32/00:47:43, 0.693s/it]: train_loss_raw=2.1393, running_loss=2.2140, LR=0.000100
[2025-08-25 22:08:58,063][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005616] [Batch 00747/04869] [00:08:37/00:47:36, 0.693s/it]: train_loss_raw=2.2086, running_loss=2.2142, LR=0.000100
[2025-08-25 22:09:03,817][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005624] [Batch 00755/04869] [00:08:43/00:47:31, 0.693s/it]: train_loss_raw=2.2635, running_loss=2.2122, LR=0.000100
[2025-08-25 22:09:09,441][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005632] [Batch 00763/04869] [00:08:48/00:47:26, 0.693s/it]: train_loss_raw=2.2545, running_loss=2.2149, LR=0.000100
[2025-08-25 22:09:14,582][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005640] [Batch 00771/04869] [00:08:54/00:47:19, 0.693s/it]: train_loss_raw=2.1688, running_loss=2.2129, LR=0.000100
[2025-08-25 22:09:20,292][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005648] [Batch 00779/04869] [00:08:59/00:47:14, 0.693s/it]: train_loss_raw=2.2297, running_loss=2.2136, LR=0.000100
[2025-08-25 22:09:26,150][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005656] [Batch 00787/04869] [00:09:05/00:47:10, 0.693s/it]: train_loss_raw=2.2566, running_loss=2.2121, LR=0.000100
[2025-08-25 22:09:31,928][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005664] [Batch 00795/04869] [00:09:11/00:47:06, 0.694s/it]: train_loss_raw=2.1983, running_loss=2.2112, LR=0.000100
[2025-08-25 22:09:37,831][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005672] [Batch 00803/04869] [00:09:17/00:47:02, 0.694s/it]: train_loss_raw=2.2022, running_loss=2.2134, LR=0.000100
[2025-08-25 22:09:43,308][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005680] [Batch 00811/04869] [00:09:22/00:46:56, 0.694s/it]: train_loss_raw=2.1883, running_loss=2.2121, LR=0.000100
[2025-08-25 22:09:48,634][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005688] [Batch 00819/04869] [00:09:28/00:46:49, 0.694s/it]: train_loss_raw=2.1525, running_loss=2.2107, LR=0.000100
[2025-08-25 22:09:54,372][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005696] [Batch 00827/04869] [00:09:33/00:46:45, 0.694s/it]: train_loss_raw=2.2813, running_loss=2.2125, LR=0.000100
[2025-08-25 22:09:59,913][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005704] [Batch 00835/04869] [00:09:39/00:46:39, 0.694s/it]: train_loss_raw=2.1870, running_loss=2.2119, LR=0.000100
[2025-08-25 22:10:06,041][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005712] [Batch 00843/04869] [00:09:45/00:46:36, 0.695s/it]: train_loss_raw=2.2152, running_loss=2.2120, LR=0.000100
[2025-08-25 22:10:11,780][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005720] [Batch 00851/04869] [00:09:51/00:46:32, 0.695s/it]: train_loss_raw=2.2786, running_loss=2.2102, LR=0.000100
[2025-08-25 22:10:17,336][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005728] [Batch 00859/04869] [00:09:56/00:46:26, 0.695s/it]: train_loss_raw=2.2742, running_loss=2.2093, LR=0.000100
[2025-08-25 22:10:23,107][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005736] [Batch 00867/04869] [00:10:02/00:46:21, 0.695s/it]: train_loss_raw=2.1998, running_loss=2.2090, LR=0.000100
[2025-08-25 22:10:28,847][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005744] [Batch 00875/04869] [00:10:08/00:46:17, 0.695s/it]: train_loss_raw=2.2590, running_loss=2.2086, LR=0.000100
[2025-08-25 22:10:34,628][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005752] [Batch 00883/04869] [00:10:14/00:46:12, 0.696s/it]: train_loss_raw=2.1481, running_loss=2.2083, LR=0.000100
[2025-08-25 22:10:40,577][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005760] [Batch 00891/04869] [00:10:20/00:46:08, 0.696s/it]: train_loss_raw=2.2829, running_loss=2.2089, LR=0.000100
[2025-08-25 22:10:46,360][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005768] [Batch 00899/04869] [00:10:25/00:46:04, 0.696s/it]: train_loss_raw=2.2024, running_loss=2.2075, LR=0.000100
[2025-08-25 22:10:52,181][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005776] [Batch 00907/04869] [00:10:31/00:45:59, 0.697s/it]: train_loss_raw=2.2105, running_loss=2.2089, LR=0.000100
[2025-08-25 22:10:58,015][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005784] [Batch 00915/04869] [00:10:37/00:45:55, 0.697s/it]: train_loss_raw=2.1846, running_loss=2.2074, LR=0.000100
[2025-08-25 22:11:03,906][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005792] [Batch 00923/04869] [00:10:43/00:45:50, 0.697s/it]: train_loss_raw=2.1458, running_loss=2.2037, LR=0.000100
[2025-08-25 22:11:09,275][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005800] [Batch 00931/04869] [00:10:48/00:45:44, 0.697s/it]: train_loss_raw=2.2397, running_loss=2.2039, LR=0.000100
[2025-08-25 22:11:15,063][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005808] [Batch 00939/04869] [00:10:54/00:45:39, 0.697s/it]: train_loss_raw=2.2023, running_loss=2.2065, LR=0.000100
[2025-08-25 22:11:20,448][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005816] [Batch 00947/04869] [00:11:00/00:45:33, 0.697s/it]: train_loss_raw=2.1800, running_loss=2.2075, LR=0.000100
[2025-08-25 22:11:26,433][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005824] [Batch 00955/04869] [00:11:05/00:45:29, 0.697s/it]: train_loss_raw=2.2279, running_loss=2.2099, LR=0.000100
[2025-08-25 22:11:31,992][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005832] [Batch 00963/04869] [00:11:11/00:45:23, 0.697s/it]: train_loss_raw=2.2189, running_loss=2.2095, LR=0.000100
[2025-08-25 22:11:37,545][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005840] [Batch 00971/04869] [00:11:17/00:45:18, 0.697s/it]: train_loss_raw=2.2317, running_loss=2.2059, LR=0.000100
[2025-08-25 22:11:43,170][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005848] [Batch 00979/04869] [00:11:22/00:45:12, 0.697s/it]: train_loss_raw=2.1192, running_loss=2.2023, LR=0.000100
[2025-08-25 22:11:48,825][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005856] [Batch 00987/04869] [00:11:28/00:45:07, 0.697s/it]: train_loss_raw=2.2208, running_loss=2.2017, LR=0.000100
[2025-08-25 22:11:54,379][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005864] [Batch 00995/04869] [00:11:33/00:45:01, 0.697s/it]: train_loss_raw=2.2333, running_loss=2.2003, LR=0.000100
[2025-08-25 22:11:59,851][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005872] [Batch 01003/04869] [00:11:39/00:44:55, 0.697s/it]: train_loss_raw=2.3119, running_loss=2.2014, LR=0.000100
[2025-08-25 22:12:20,503][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005880] [Batch 01011/04869] [00:12:00/00:45:47, 0.712s/it]: train_loss_raw=2.1751, running_loss=2.2012, LR=0.000100
[2025-08-25 22:12:25,888][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005888] [Batch 01019/04869] [00:12:05/00:45:40, 0.712s/it]: train_loss_raw=2.2555, running_loss=2.2023, LR=0.000100
[2025-08-25 22:12:31,822][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005896] [Batch 01027/04869] [00:12:11/00:45:36, 0.712s/it]: train_loss_raw=2.1049, running_loss=2.2026, LR=0.000100
[2025-08-25 22:12:37,870][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005904] [Batch 01035/04869] [00:12:17/00:45:31, 0.712s/it]: train_loss_raw=2.2780, running_loss=2.2019, LR=0.000100
[2025-08-25 22:12:43,503][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005912] [Batch 01043/04869] [00:12:23/00:45:25, 0.712s/it]: train_loss_raw=2.2242, running_loss=2.2021, LR=0.000100
[2025-08-25 22:12:49,095][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005920] [Batch 01051/04869] [00:12:28/00:45:19, 0.712s/it]: train_loss_raw=2.1754, running_loss=2.2001, LR=0.000100
[2025-08-25 22:12:54,948][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005928] [Batch 01059/04869] [00:12:34/00:45:14, 0.712s/it]: train_loss_raw=2.2112, running_loss=2.1999, LR=0.000100
[2025-08-25 22:13:00,634][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005936] [Batch 01067/04869] [00:12:40/00:45:08, 0.712s/it]: train_loss_raw=2.1861, running_loss=2.1981, LR=0.000100
[2025-08-25 22:13:06,467][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005944] [Batch 01075/04869] [00:12:46/00:45:03, 0.713s/it]: train_loss_raw=2.2305, running_loss=2.1947, LR=0.000100
[2025-08-25 22:13:11,848][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005952] [Batch 01083/04869] [00:12:51/00:44:56, 0.712s/it]: train_loss_raw=2.1449, running_loss=2.1944, LR=0.000100
[2025-08-25 22:13:17,754][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005960] [Batch 01091/04869] [00:12:57/00:44:51, 0.712s/it]: train_loss_raw=2.2144, running_loss=2.1948, LR=0.000100
[2025-08-25 22:13:23,212][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005968] [Batch 01099/04869] [00:13:02/00:44:45, 0.712s/it]: train_loss_raw=2.2045, running_loss=2.1939, LR=0.000100
[2025-08-25 22:13:28,944][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005976] [Batch 01107/04869] [00:13:08/00:44:39, 0.712s/it]: train_loss_raw=2.2005, running_loss=2.1942, LR=0.000100
[2025-08-25 22:13:34,366][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005984] [Batch 01115/04869] [00:13:13/00:44:32, 0.712s/it]: train_loss_raw=2.2052, running_loss=2.1939, LR=0.000100
[2025-08-25 22:13:40,300][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005992] [Batch 01123/04869] [00:13:19/00:44:28, 0.712s/it]: train_loss_raw=2.1874, running_loss=2.1930, LR=0.000100
[2025-08-25 22:13:45,996][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006000] [Batch 01131/04869] [00:13:25/00:44:22, 0.712s/it]: train_loss_raw=2.2776, running_loss=2.1941, LR=0.000100
[2025-08-25 22:13:55,263][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006008] [Batch 01139/04869] [00:13:34/00:44:28, 0.715s/it]: train_loss_raw=2.2180, running_loss=2.1966, LR=0.000100
[2025-08-25 22:14:01,056][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006016] [Batch 01147/04869] [00:13:40/00:44:22, 0.715s/it]: train_loss_raw=2.1512, running_loss=2.1959, LR=0.000100
[2025-08-25 22:14:06,652][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006024] [Batch 01155/04869] [00:13:46/00:44:16, 0.715s/it]: train_loss_raw=2.1684, running_loss=2.1960, LR=0.000100
[2025-08-25 22:14:11,818][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006032] [Batch 01163/04869] [00:13:51/00:44:09, 0.715s/it]: train_loss_raw=2.1463, running_loss=2.1952, LR=0.000100
[2025-08-25 22:14:16,969][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006040] [Batch 01171/04869] [00:13:56/00:44:01, 0.714s/it]: train_loss_raw=2.1616, running_loss=2.1943, LR=0.000100
[2025-08-25 22:14:22,132][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006048] [Batch 01179/04869] [00:14:01/00:43:54, 0.714s/it]: train_loss_raw=2.2610, running_loss=2.1964, LR=0.000100
[2025-08-25 22:14:27,411][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006056] [Batch 01187/04869] [00:14:06/00:43:47, 0.714s/it]: train_loss_raw=2.2063, running_loss=2.1972, LR=0.000100
[2025-08-25 22:14:32,958][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006064] [Batch 01195/04869] [00:14:12/00:43:41, 0.713s/it]: train_loss_raw=2.2409, running_loss=2.1953, LR=0.000100
[2025-08-25 22:14:38,621][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006072] [Batch 01203/04869] [00:14:18/00:43:35, 0.713s/it]: train_loss_raw=2.1081, running_loss=2.1945, LR=0.000100
[2025-08-25 22:14:43,876][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006080] [Batch 01211/04869] [00:14:23/00:43:28, 0.713s/it]: train_loss_raw=2.1909, running_loss=2.1931, LR=0.000100
[2025-08-25 22:14:49,151][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006088] [Batch 01219/04869] [00:14:28/00:43:21, 0.713s/it]: train_loss_raw=2.1406, running_loss=2.1928, LR=0.000100
[2025-08-25 22:14:54,726][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006096] [Batch 01227/04869] [00:14:34/00:43:15, 0.713s/it]: train_loss_raw=2.1888, running_loss=2.1937, LR=0.000100
[2025-08-25 22:15:00,565][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006104] [Batch 01235/04869] [00:14:40/00:43:09, 0.713s/it]: train_loss_raw=2.2600, running_loss=2.1937, LR=0.000100
[2025-08-25 22:15:06,256][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006112] [Batch 01243/04869] [00:14:45/00:43:04, 0.713s/it]: train_loss_raw=2.1332, running_loss=2.1933, LR=0.000100
[2025-08-25 22:15:12,106][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006120] [Batch 01251/04869] [00:14:51/00:42:58, 0.713s/it]: train_loss_raw=2.2171, running_loss=2.1934, LR=0.000100
[2025-08-25 22:15:17,470][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006128] [Batch 01259/04869] [00:14:57/00:42:52, 0.712s/it]: train_loss_raw=2.2555, running_loss=2.1935, LR=0.000100
[2025-08-25 22:15:23,437][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006136] [Batch 01267/04869] [00:15:02/00:42:47, 0.713s/it]: train_loss_raw=2.2138, running_loss=2.1928, LR=0.000100
[2025-08-25 22:15:29,003][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006144] [Batch 01275/04869] [00:15:08/00:42:41, 0.713s/it]: train_loss_raw=2.2290, running_loss=2.1924, LR=0.000100
[2025-08-25 22:15:34,217][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006152] [Batch 01283/04869] [00:15:13/00:42:34, 0.712s/it]: train_loss_raw=2.1504, running_loss=2.1928, LR=0.000100
[2025-08-25 22:15:39,529][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006160] [Batch 01291/04869] [00:15:19/00:42:27, 0.712s/it]: train_loss_raw=2.1606, running_loss=2.1928, LR=0.000100
[2025-08-25 22:15:45,323][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006168] [Batch 01299/04869] [00:15:24/00:42:21, 0.712s/it]: train_loss_raw=2.1499, running_loss=2.1925, LR=0.000100
[2025-08-25 22:15:51,171][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006176] [Batch 01307/04869] [00:15:30/00:42:16, 0.712s/it]: train_loss_raw=2.2075, running_loss=2.1904, LR=0.000100
[2025-08-25 22:15:56,911][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006184] [Batch 01315/04869] [00:15:36/00:42:10, 0.712s/it]: train_loss_raw=2.1732, running_loss=2.1902, LR=0.000100
[2025-08-25 22:16:02,845][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006192] [Batch 01323/04869] [00:15:42/00:42:05, 0.712s/it]: train_loss_raw=2.1937, running_loss=2.1897, LR=0.000100
[2025-08-25 22:16:08,475][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006200] [Batch 01331/04869] [00:15:48/00:42:00, 0.712s/it]: train_loss_raw=2.2833, running_loss=2.1889, LR=0.000100
[2025-08-25 22:16:14,329][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006208] [Batch 01339/04869] [00:15:53/00:41:54, 0.712s/it]: train_loss_raw=2.1370, running_loss=2.1879, LR=0.000100
[2025-08-25 22:16:19,967][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006216] [Batch 01347/04869] [00:15:59/00:41:48, 0.712s/it]: train_loss_raw=2.1947, running_loss=2.1880, LR=0.000100
[2025-08-25 22:16:25,823][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006224] [Batch 01355/04869] [00:16:05/00:41:43, 0.712s/it]: train_loss_raw=2.1913, running_loss=2.1892, LR=0.000100
[2025-08-25 22:16:31,262][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006232] [Batch 01363/04869] [00:16:10/00:41:37, 0.712s/it]: train_loss_raw=2.1917, running_loss=2.1886, LR=0.000100
[2025-08-25 22:16:36,843][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006240] [Batch 01371/04869] [00:16:16/00:41:31, 0.712s/it]: train_loss_raw=2.1808, running_loss=2.1849, LR=0.000100
[2025-08-25 22:16:42,215][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006248] [Batch 01379/04869] [00:16:21/00:41:24, 0.712s/it]: train_loss_raw=2.2058, running_loss=2.1848, LR=0.000100
[2025-08-25 22:16:47,922][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006256] [Batch 01387/04869] [00:16:27/00:41:19, 0.712s/it]: train_loss_raw=2.1955, running_loss=2.1852, LR=0.000100
[2025-08-25 22:16:53,708][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006264] [Batch 01395/04869] [00:16:33/00:41:13, 0.712s/it]: train_loss_raw=2.0674, running_loss=2.1833, LR=0.000100
[2025-08-25 22:16:59,936][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006272] [Batch 01403/04869] [00:16:39/00:41:09, 0.712s/it]: train_loss_raw=2.1822, running_loss=2.1837, LR=0.000100
[2025-08-25 22:17:05,870][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006280] [Batch 01411/04869] [00:16:45/00:41:04, 0.713s/it]: train_loss_raw=2.2532, running_loss=2.1857, LR=0.000100
[2025-08-25 22:17:11,644][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006288] [Batch 01419/04869] [00:16:51/00:40:58, 0.713s/it]: train_loss_raw=2.2081, running_loss=2.1858, LR=0.000100
[2025-08-25 22:17:17,451][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006296] [Batch 01427/04869] [00:16:57/00:40:53, 0.713s/it]: train_loss_raw=2.1995, running_loss=2.1851, LR=0.000100
[2025-08-25 22:17:22,782][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006304] [Batch 01435/04869] [00:17:02/00:40:46, 0.712s/it]: train_loss_raw=2.1553, running_loss=2.1856, LR=0.000100
[2025-08-25 22:17:28,538][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006312] [Batch 01443/04869] [00:17:08/00:40:40, 0.712s/it]: train_loss_raw=2.1980, running_loss=2.1853, LR=0.000100
[2025-08-25 22:17:34,918][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006320] [Batch 01451/04869] [00:17:14/00:40:36, 0.713s/it]: train_loss_raw=2.1932, running_loss=2.1847, LR=0.000100
[2025-08-25 22:17:40,652][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006328] [Batch 01459/04869] [00:17:20/00:40:31, 0.713s/it]: train_loss_raw=2.2122, running_loss=2.1848, LR=0.000100
[2025-08-25 22:17:46,114][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006336] [Batch 01467/04869] [00:17:25/00:40:24, 0.713s/it]: train_loss_raw=2.1883, running_loss=2.1841, LR=0.000100
[2025-08-25 22:17:51,790][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006344] [Batch 01475/04869] [00:17:31/00:40:19, 0.713s/it]: train_loss_raw=2.1818, running_loss=2.1828, LR=0.000100
[2025-08-25 22:17:57,489][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006352] [Batch 01483/04869] [00:17:37/00:40:13, 0.713s/it]: train_loss_raw=2.1807, running_loss=2.1813, LR=0.000100
[2025-08-25 22:18:02,872][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006360] [Batch 01491/04869] [00:17:42/00:40:07, 0.713s/it]: train_loss_raw=2.2031, running_loss=2.1829, LR=0.000100
[2025-08-25 22:18:08,514][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006368] [Batch 01499/04869] [00:17:48/00:40:01, 0.713s/it]: train_loss_raw=2.2294, running_loss=2.1816, LR=0.000100
[2025-08-25 22:18:14,192][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006376] [Batch 01507/04869] [00:17:53/00:39:55, 0.713s/it]: train_loss_raw=2.2081, running_loss=2.1809, LR=0.000100
[2025-08-25 22:18:19,840][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006384] [Batch 01515/04869] [00:17:59/00:39:49, 0.712s/it]: train_loss_raw=2.1847, running_loss=2.1819, LR=0.000100
[2025-08-25 22:18:25,458][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006392] [Batch 01523/04869] [00:18:05/00:39:43, 0.712s/it]: train_loss_raw=2.1136, running_loss=2.1815, LR=0.000100
[2025-08-25 22:18:30,619][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006400] [Batch 01531/04869] [00:18:10/00:39:36, 0.712s/it]: train_loss_raw=2.1980, running_loss=2.1822, LR=0.000100
[2025-08-25 22:18:36,264][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006408] [Batch 01539/04869] [00:18:15/00:39:31, 0.712s/it]: train_loss_raw=2.1853, running_loss=2.1818, LR=0.000100
[2025-08-25 22:18:41,562][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006416] [Batch 01547/04869] [00:18:21/00:39:24, 0.712s/it]: train_loss_raw=2.0984, running_loss=2.1792, LR=0.000100
[2025-08-25 22:18:46,922][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006424] [Batch 01555/04869] [00:18:26/00:39:18, 0.712s/it]: train_loss_raw=2.1742, running_loss=2.1788, LR=0.000100
[2025-08-25 22:18:52,501][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006432] [Batch 01563/04869] [00:18:32/00:39:12, 0.711s/it]: train_loss_raw=2.1304, running_loss=2.1779, LR=0.000100
[2025-08-25 22:18:57,701][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006440] [Batch 01571/04869] [00:18:37/00:39:05, 0.711s/it]: train_loss_raw=2.2305, running_loss=2.1775, LR=0.000100
[2025-08-25 22:19:03,015][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006448] [Batch 01579/04869] [00:18:42/00:38:58, 0.711s/it]: train_loss_raw=2.1700, running_loss=2.1790, LR=0.000100
[2025-08-25 22:19:08,167][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006456] [Batch 01587/04869] [00:18:47/00:38:52, 0.711s/it]: train_loss_raw=2.1984, running_loss=2.1810, LR=0.000100
[2025-08-25 22:19:13,891][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006464] [Batch 01595/04869] [00:18:53/00:38:46, 0.711s/it]: train_loss_raw=2.2319, running_loss=2.1851, LR=0.000100
[2025-08-25 22:19:19,927][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006472] [Batch 01603/04869] [00:18:59/00:38:41, 0.711s/it]: train_loss_raw=2.2004, running_loss=2.1854, LR=0.000100
[2025-08-25 22:19:25,373][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006480] [Batch 01611/04869] [00:19:04/00:38:35, 0.711s/it]: train_loss_raw=2.2216, running_loss=2.1836, LR=0.000100
[2025-08-25 22:19:30,943][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006488] [Batch 01619/04869] [00:19:10/00:38:29, 0.711s/it]: train_loss_raw=2.1579, running_loss=2.1823, LR=0.000100
[2025-08-25 22:19:36,649][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006496] [Batch 01627/04869] [00:19:16/00:38:23, 0.711s/it]: train_loss_raw=2.2181, running_loss=2.1834, LR=0.000100
[2025-08-25 22:19:42,410][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006504] [Batch 01635/04869] [00:19:21/00:38:18, 0.711s/it]: train_loss_raw=2.1805, running_loss=2.1838, LR=0.000100
[2025-08-25 22:19:48,554][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006512] [Batch 01643/04869] [00:19:28/00:38:13, 0.711s/it]: train_loss_raw=2.2463, running_loss=2.1852, LR=0.000100
[2025-08-25 22:19:54,787][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006520] [Batch 01651/04869] [00:19:34/00:38:08, 0.711s/it]: train_loss_raw=2.1551, running_loss=2.1832, LR=0.000100
[2025-08-25 22:20:00,967][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006528] [Batch 01659/04869] [00:19:40/00:38:04, 0.712s/it]: train_loss_raw=2.2302, running_loss=2.1839, LR=0.000100
[2025-08-25 22:20:06,951][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006536] [Batch 01667/04869] [00:19:46/00:37:59, 0.712s/it]: train_loss_raw=2.1794, running_loss=2.1840, LR=0.000100
[2025-08-25 22:20:12,917][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006544] [Batch 01675/04869] [00:19:52/00:37:53, 0.712s/it]: train_loss_raw=2.1860, running_loss=2.1853, LR=0.000100
[2025-08-25 22:20:18,531][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006552] [Batch 01683/04869] [00:19:58/00:37:48, 0.712s/it]: train_loss_raw=2.1816, running_loss=2.1839, LR=0.000100
[2025-08-25 22:20:23,870][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006560] [Batch 01691/04869] [00:20:03/00:37:41, 0.712s/it]: train_loss_raw=2.1752, running_loss=2.1826, LR=0.000100
[2025-08-25 22:20:29,658][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006568] [Batch 01699/04869] [00:20:09/00:37:36, 0.712s/it]: train_loss_raw=2.2268, running_loss=2.1819, LR=0.000100
[2025-08-25 22:20:35,632][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006576] [Batch 01707/04869] [00:20:15/00:37:30, 0.712s/it]: train_loss_raw=2.1195, running_loss=2.1792, LR=0.000100
[2025-08-25 22:20:41,321][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006584] [Batch 01715/04869] [00:20:20/00:37:25, 0.712s/it]: train_loss_raw=2.2561, running_loss=2.1787, LR=0.000100
[2025-08-25 22:20:46,669][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006592] [Batch 01723/04869] [00:20:26/00:37:18, 0.712s/it]: train_loss_raw=2.1380, running_loss=2.1799, LR=0.000100
[2025-08-25 22:20:52,227][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006600] [Batch 01731/04869] [00:20:31/00:37:13, 0.712s/it]: train_loss_raw=2.1316, running_loss=2.1781, LR=0.000100
[2025-08-25 22:20:58,121][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006608] [Batch 01739/04869] [00:20:37/00:37:07, 0.712s/it]: train_loss_raw=2.0692, running_loss=2.1767, LR=0.000100
[2025-08-25 22:21:04,070][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006616] [Batch 01747/04869] [00:20:43/00:37:02, 0.712s/it]: train_loss_raw=2.1011, running_loss=2.1771, LR=0.000100
[2025-08-25 22:21:09,790][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006624] [Batch 01755/04869] [00:20:49/00:36:56, 0.712s/it]: train_loss_raw=2.1852, running_loss=2.1780, LR=0.000100
[2025-08-25 22:21:15,450][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006632] [Batch 01763/04869] [00:20:55/00:36:51, 0.712s/it]: train_loss_raw=2.2037, running_loss=2.1776, LR=0.000100
[2025-08-25 22:21:20,765][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006640] [Batch 01771/04869] [00:21:00/00:36:44, 0.712s/it]: train_loss_raw=2.1383, running_loss=2.1768, LR=0.000100
[2025-08-25 22:21:26,097][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006648] [Batch 01779/04869] [00:21:05/00:36:38, 0.711s/it]: train_loss_raw=2.1518, running_loss=2.1778, LR=0.000100
[2025-08-25 22:21:31,848][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006656] [Batch 01787/04869] [00:21:11/00:36:32, 0.711s/it]: train_loss_raw=2.1955, running_loss=2.1774, LR=0.000100
[2025-08-25 22:21:37,668][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006664] [Batch 01795/04869] [00:21:17/00:36:27, 0.712s/it]: train_loss_raw=2.1802, running_loss=2.1782, LR=0.000100
[2025-08-25 22:21:42,863][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006672] [Batch 01803/04869] [00:21:22/00:36:20, 0.711s/it]: train_loss_raw=2.2145, running_loss=2.1761, LR=0.000100
[2025-08-25 22:21:48,045][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006680] [Batch 01811/04869] [00:21:27/00:36:14, 0.711s/it]: train_loss_raw=2.1775, running_loss=2.1766, LR=0.000100
[2025-08-25 22:21:53,701][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006688] [Batch 01819/04869] [00:21:33/00:36:08, 0.711s/it]: train_loss_raw=2.1429, running_loss=2.1753, LR=0.000100
[2025-08-25 22:21:59,914][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006696] [Batch 01827/04869] [00:21:39/00:36:03, 0.711s/it]: train_loss_raw=2.2389, running_loss=2.1724, LR=0.000100
[2025-08-25 22:22:05,162][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006704] [Batch 01835/04869] [00:21:44/00:35:57, 0.711s/it]: train_loss_raw=2.1505, running_loss=2.1726, LR=0.000100
[2025-08-25 22:22:10,941][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006712] [Batch 01843/04869] [00:21:50/00:35:51, 0.711s/it]: train_loss_raw=2.0569, running_loss=2.1711, LR=0.000100
[2025-08-25 22:22:16,427][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006720] [Batch 01851/04869] [00:21:55/00:35:45, 0.711s/it]: train_loss_raw=2.2070, running_loss=2.1710, LR=0.000100
[2025-08-25 22:22:21,890][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006728] [Batch 01859/04869] [00:22:01/00:35:39, 0.711s/it]: train_loss_raw=2.1330, running_loss=2.1711, LR=0.000100
[2025-08-25 22:22:27,749][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006736] [Batch 01867/04869] [00:22:07/00:35:34, 0.711s/it]: train_loss_raw=2.1749, running_loss=2.1712, LR=0.000100
[2025-08-25 22:22:33,090][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006744] [Batch 01875/04869] [00:22:12/00:35:27, 0.711s/it]: train_loss_raw=2.1749, running_loss=2.1694, LR=0.000100
[2025-08-25 22:22:38,317][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006752] [Batch 01883/04869] [00:22:17/00:35:21, 0.711s/it]: train_loss_raw=2.2185, running_loss=2.1704, LR=0.000100
[2025-08-25 22:22:43,875][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006760] [Batch 01891/04869] [00:22:23/00:35:15, 0.710s/it]: train_loss_raw=2.2239, running_loss=2.1701, LR=0.000100
[2025-08-25 22:22:49,533][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006768] [Batch 01899/04869] [00:22:29/00:35:09, 0.710s/it]: train_loss_raw=2.1590, running_loss=2.1700, LR=0.000100
[2025-08-25 22:22:54,865][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006776] [Batch 01907/04869] [00:22:34/00:35:03, 0.710s/it]: train_loss_raw=2.2427, running_loss=2.1692, LR=0.000100
[2025-08-25 22:23:00,077][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006784] [Batch 01915/04869] [00:22:39/00:34:57, 0.710s/it]: train_loss_raw=2.1773, running_loss=2.1690, LR=0.000100
[2025-08-25 22:23:05,734][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006792] [Batch 01923/04869] [00:22:45/00:34:51, 0.710s/it]: train_loss_raw=2.1182, running_loss=2.1693, LR=0.000100
[2025-08-25 22:23:11,079][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006800] [Batch 01931/04869] [00:22:50/00:34:45, 0.710s/it]: train_loss_raw=2.1476, running_loss=2.1683, LR=0.000100
[2025-08-25 22:23:16,530][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006808] [Batch 01939/04869] [00:22:56/00:34:39, 0.710s/it]: train_loss_raw=2.1542, running_loss=2.1668, LR=0.000100
[2025-08-25 22:23:22,251][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006816] [Batch 01947/04869] [00:23:01/00:34:33, 0.710s/it]: train_loss_raw=2.2204, running_loss=2.1683, LR=0.000100
[2025-08-25 22:23:28,121][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006824] [Batch 01955/04869] [00:23:07/00:34:28, 0.710s/it]: train_loss_raw=2.1781, running_loss=2.1689, LR=0.000100
[2025-08-25 22:23:33,833][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006832] [Batch 01963/04869] [00:23:13/00:34:22, 0.710s/it]: train_loss_raw=2.1149, running_loss=2.1685, LR=0.000100
[2025-08-25 22:23:39,529][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006840] [Batch 01971/04869] [00:23:19/00:34:17, 0.710s/it]: train_loss_raw=2.2103, running_loss=2.1680, LR=0.000100
[2025-08-25 22:23:45,195][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006848] [Batch 01979/04869] [00:23:24/00:34:11, 0.710s/it]: train_loss_raw=2.0856, running_loss=2.1680, LR=0.000100
[2025-08-25 22:23:51,028][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006856] [Batch 01987/04869] [00:23:30/00:34:05, 0.710s/it]: train_loss_raw=2.2177, running_loss=2.1647, LR=0.000100
[2025-08-25 22:23:57,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006864] [Batch 01995/04869] [00:23:36/00:34:01, 0.710s/it]: train_loss_raw=2.1717, running_loss=2.1638, LR=0.000100
[2025-08-25 22:24:03,041][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006872] [Batch 02003/04869] [00:23:42/00:33:55, 0.710s/it]: train_loss_raw=2.0505, running_loss=2.1632, LR=0.000100
[2025-08-25 22:24:08,514][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006880] [Batch 02011/04869] [00:23:48/00:33:49, 0.710s/it]: train_loss_raw=2.2621, running_loss=2.1636, LR=0.000100
[2025-08-25 22:24:14,731][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006888] [Batch 02019/04869] [00:23:54/00:33:44, 0.710s/it]: train_loss_raw=2.1632, running_loss=2.1623, LR=0.000100
[2025-08-25 22:24:20,798][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006896] [Batch 02027/04869] [00:24:00/00:33:39, 0.711s/it]: train_loss_raw=2.1664, running_loss=2.1621, LR=0.000100
[2025-08-25 22:24:26,545][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006904] [Batch 02035/04869] [00:24:06/00:33:33, 0.711s/it]: train_loss_raw=2.1850, running_loss=2.1605, LR=0.000100
[2025-08-25 22:24:32,122][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006912] [Batch 02043/04869] [00:24:11/00:33:28, 0.711s/it]: train_loss_raw=2.1720, running_loss=2.1595, LR=0.000100
[2025-08-25 22:24:37,742][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006920] [Batch 02051/04869] [00:24:17/00:33:22, 0.711s/it]: train_loss_raw=2.2162, running_loss=2.1601, LR=0.000100
[2025-08-25 22:24:43,537][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006928] [Batch 02059/04869] [00:24:23/00:33:16, 0.711s/it]: train_loss_raw=2.1673, running_loss=2.1581, LR=0.000100
[2025-08-25 22:24:49,239][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006936] [Batch 02067/04869] [00:24:28/00:33:11, 0.711s/it]: train_loss_raw=2.0826, running_loss=2.1586, LR=0.000100
[2025-08-25 22:24:54,886][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006944] [Batch 02075/04869] [00:24:34/00:33:05, 0.711s/it]: train_loss_raw=2.2097, running_loss=2.1606, LR=0.000100
[2025-08-25 22:25:00,669][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006952] [Batch 02083/04869] [00:24:40/00:32:59, 0.711s/it]: train_loss_raw=2.2209, running_loss=2.1615, LR=0.000100
[2025-08-25 22:25:07,001][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006960] [Batch 02091/04869] [00:24:46/00:32:54, 0.711s/it]: train_loss_raw=2.0934, running_loss=2.1608, LR=0.000100
[2025-08-25 22:25:12,847][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006968] [Batch 02099/04869] [00:24:52/00:32:49, 0.711s/it]: train_loss_raw=2.1916, running_loss=2.1610, LR=0.000100
[2025-08-25 22:25:18,694][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006976] [Batch 02107/04869] [00:24:58/00:32:44, 0.711s/it]: train_loss_raw=2.1386, running_loss=2.1583, LR=0.000100
[2025-08-25 22:25:24,443][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006984] [Batch 02115/04869] [00:25:04/00:32:38, 0.711s/it]: train_loss_raw=2.1306, running_loss=2.1571, LR=0.000100
[2025-08-25 22:25:29,900][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006992] [Batch 02123/04869] [00:25:09/00:32:32, 0.711s/it]: train_loss_raw=2.1351, running_loss=2.1563, LR=0.000100
[2025-08-25 22:25:35,734][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007000] [Batch 02131/04869] [00:25:15/00:32:26, 0.711s/it]: train_loss_raw=2.1283, running_loss=2.1552, LR=0.000100
[2025-08-25 22:25:40,890][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007008] [Batch 02139/04869] [00:25:20/00:32:20, 0.711s/it]: train_loss_raw=2.1962, running_loss=2.1535, LR=0.000100
[2025-08-25 22:25:46,511][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007016] [Batch 02147/04869] [00:25:26/00:32:14, 0.711s/it]: train_loss_raw=2.1964, running_loss=2.1556, LR=0.000100
[2025-08-25 22:25:52,522][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007024] [Batch 02155/04869] [00:25:32/00:32:09, 0.711s/it]: train_loss_raw=2.0958, running_loss=2.1563, LR=0.000100
[2025-08-25 22:25:57,849][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007032] [Batch 02163/04869] [00:25:37/00:32:03, 0.711s/it]: train_loss_raw=2.1685, running_loss=2.1573, LR=0.000100
[2025-08-25 22:26:03,833][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007040] [Batch 02171/04869] [00:25:43/00:31:58, 0.711s/it]: train_loss_raw=2.1660, running_loss=2.1556, LR=0.000100
[2025-08-25 22:26:09,653][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007048] [Batch 02179/04869] [00:25:49/00:31:52, 0.711s/it]: train_loss_raw=2.1929, running_loss=2.1574, LR=0.000100
[2025-08-25 22:26:15,543][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007056] [Batch 02187/04869] [00:25:55/00:31:47, 0.711s/it]: train_loss_raw=2.1859, running_loss=2.1563, LR=0.000100
[2025-08-25 22:26:21,096][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007064] [Batch 02195/04869] [00:26:00/00:31:41, 0.711s/it]: train_loss_raw=2.1478, running_loss=2.1553, LR=0.000100
[2025-08-25 22:26:26,532][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007072] [Batch 02203/04869] [00:26:06/00:31:35, 0.711s/it]: train_loss_raw=2.2860, running_loss=2.1569, LR=0.000100
[2025-08-25 22:26:31,922][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007080] [Batch 02211/04869] [00:26:11/00:31:29, 0.711s/it]: train_loss_raw=2.1829, running_loss=2.1572, LR=0.000100
[2025-08-25 22:26:37,291][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007088] [Batch 02219/04869] [00:26:16/00:31:23, 0.711s/it]: train_loss_raw=2.1306, running_loss=2.1557, LR=0.000100
[2025-08-25 22:26:43,266][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007096] [Batch 02227/04869] [00:26:22/00:31:17, 0.711s/it]: train_loss_raw=2.1554, running_loss=2.1541, LR=0.000100
[2025-08-25 22:26:49,283][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007104] [Batch 02235/04869] [00:26:28/00:31:12, 0.711s/it]: train_loss_raw=2.2045, running_loss=2.1540, LR=0.000100
[2025-08-25 22:26:55,287][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007112] [Batch 02243/04869] [00:26:34/00:31:07, 0.711s/it]: train_loss_raw=2.1522, running_loss=2.1540, LR=0.000100
[2025-08-25 22:27:01,124][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007120] [Batch 02251/04869] [00:26:40/00:31:01, 0.711s/it]: train_loss_raw=2.1621, running_loss=2.1527, LR=0.000100
[2025-08-25 22:27:07,102][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007128] [Batch 02259/04869] [00:26:46/00:30:56, 0.711s/it]: train_loss_raw=2.1664, running_loss=2.1562, LR=0.000100
[2025-08-25 22:27:13,022][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007136] [Batch 02267/04869] [00:26:52/00:30:50, 0.711s/it]: train_loss_raw=2.0641, running_loss=2.1544, LR=0.000100
[2025-08-25 22:27:18,638][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007144] [Batch 02275/04869] [00:26:58/00:30:45, 0.711s/it]: train_loss_raw=2.2032, running_loss=2.1556, LR=0.000100
[2025-08-25 22:27:24,344][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007152] [Batch 02283/04869] [00:27:03/00:30:39, 0.711s/it]: train_loss_raw=2.1578, running_loss=2.1573, LR=0.000100
[2025-08-25 22:27:30,054][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007160] [Batch 02291/04869] [00:27:09/00:30:33, 0.711s/it]: train_loss_raw=2.1709, running_loss=2.1562, LR=0.000100
[2025-08-25 22:27:35,392][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007168] [Batch 02299/04869] [00:27:14/00:30:27, 0.711s/it]: train_loss_raw=2.1134, running_loss=2.1524, LR=0.000100
[2025-08-25 22:27:41,410][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007176] [Batch 02307/04869] [00:27:20/00:30:22, 0.711s/it]: train_loss_raw=2.1308, running_loss=2.1530, LR=0.000100
[2025-08-25 22:27:46,644][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007184] [Batch 02315/04869] [00:27:26/00:30:16, 0.711s/it]: train_loss_raw=2.1580, running_loss=2.1528, LR=0.000100
[2025-08-25 22:27:52,095][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007192] [Batch 02323/04869] [00:27:31/00:30:10, 0.711s/it]: train_loss_raw=2.1570, running_loss=2.1516, LR=0.000100
[2025-08-25 22:27:57,744][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007200] [Batch 02331/04869] [00:27:37/00:30:04, 0.711s/it]: train_loss_raw=2.1744, running_loss=2.1518, LR=0.000100
[2025-08-25 22:28:03,515][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007208] [Batch 02339/04869] [00:27:43/00:29:58, 0.711s/it]: train_loss_raw=2.1046, running_loss=2.1509, LR=0.000100
[2025-08-25 22:28:09,516][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007216] [Batch 02347/04869] [00:27:49/00:29:53, 0.711s/it]: train_loss_raw=2.1807, running_loss=2.1503, LR=0.000100
[2025-08-25 22:28:15,310][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007224] [Batch 02355/04869] [00:27:54/00:29:47, 0.711s/it]: train_loss_raw=2.1477, running_loss=2.1509, LR=0.000100
[2025-08-25 22:28:20,811][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007232] [Batch 02363/04869] [00:28:00/00:29:42, 0.711s/it]: train_loss_raw=2.1813, running_loss=2.1517, LR=0.000100
[2025-08-25 22:28:26,506][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007240] [Batch 02371/04869] [00:28:06/00:29:36, 0.711s/it]: train_loss_raw=2.1952, running_loss=2.1516, LR=0.000100
[2025-08-25 22:28:31,885][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007248] [Batch 02379/04869] [00:28:11/00:29:30, 0.711s/it]: train_loss_raw=2.1261, running_loss=2.1508, LR=0.000100
[2025-08-25 22:28:37,367][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007256] [Batch 02387/04869] [00:28:16/00:29:24, 0.711s/it]: train_loss_raw=2.1613, running_loss=2.1518, LR=0.000100
[2025-08-25 22:28:43,203][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007264] [Batch 02395/04869] [00:28:22/00:29:18, 0.711s/it]: train_loss_raw=2.0972, running_loss=2.1487, LR=0.000100
[2025-08-25 22:28:48,945][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007272] [Batch 02403/04869] [00:28:28/00:29:13, 0.711s/it]: train_loss_raw=2.0635, running_loss=2.1493, LR=0.000100
[2025-08-25 22:28:54,345][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007280] [Batch 02411/04869] [00:28:33/00:29:07, 0.711s/it]: train_loss_raw=2.0768, running_loss=2.1493, LR=0.000100
[2025-08-25 22:28:59,704][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007288] [Batch 02419/04869] [00:28:39/00:29:01, 0.711s/it]: train_loss_raw=2.1260, running_loss=2.1478, LR=0.000100
[2025-08-25 22:29:05,148][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007296] [Batch 02427/04869] [00:28:44/00:28:55, 0.711s/it]: train_loss_raw=2.1383, running_loss=2.1471, LR=0.000100
[2025-08-25 22:29:10,367][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007304] [Batch 02435/04869] [00:28:49/00:28:49, 0.710s/it]: train_loss_raw=2.1376, running_loss=2.1457, LR=0.000100
[2025-08-25 22:29:16,135][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007312] [Batch 02443/04869] [00:28:55/00:28:43, 0.710s/it]: train_loss_raw=2.1899, running_loss=2.1462, LR=0.000100
[2025-08-25 22:29:21,596][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007320] [Batch 02451/04869] [00:29:01/00:28:37, 0.710s/it]: train_loss_raw=2.1297, running_loss=2.1459, LR=0.000100
[2025-08-25 22:29:27,076][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007328] [Batch 02459/04869] [00:29:06/00:28:31, 0.710s/it]: train_loss_raw=2.1497, running_loss=2.1446, LR=0.000100
[2025-08-25 22:29:32,648][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007336] [Batch 02467/04869] [00:29:12/00:28:26, 0.710s/it]: train_loss_raw=2.0864, running_loss=2.1438, LR=0.000100
[2025-08-25 22:29:38,532][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007344] [Batch 02475/04869] [00:29:18/00:28:20, 0.710s/it]: train_loss_raw=2.1079, running_loss=2.1433, LR=0.000100
[2025-08-25 22:29:44,209][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007352] [Batch 02483/04869] [00:29:23/00:28:14, 0.710s/it]: train_loss_raw=2.1544, running_loss=2.1411, LR=0.000100
[2025-08-25 22:29:50,049][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007360] [Batch 02491/04869] [00:29:29/00:28:09, 0.710s/it]: train_loss_raw=2.1368, running_loss=2.1409, LR=0.000100
[2025-08-25 22:29:55,633][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007368] [Batch 02499/04869] [00:29:35/00:28:03, 0.710s/it]: train_loss_raw=2.2201, running_loss=2.1427, LR=0.000100
[2025-08-25 22:30:01,362][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007376] [Batch 02507/04869] [00:29:40/00:27:57, 0.710s/it]: train_loss_raw=2.1230, running_loss=2.1414, LR=0.000100
[2025-08-25 22:30:07,323][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007384] [Batch 02515/04869] [00:29:46/00:27:52, 0.710s/it]: train_loss_raw=2.1218, running_loss=2.1406, LR=0.000100
[2025-08-25 22:30:12,933][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007392] [Batch 02523/04869] [00:29:52/00:27:46, 0.710s/it]: train_loss_raw=2.0372, running_loss=2.1385, LR=0.000100
[2025-08-25 22:30:18,843][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007400] [Batch 02531/04869] [00:29:58/00:27:41, 0.711s/it]: train_loss_raw=2.1495, running_loss=2.1398, LR=0.000100
[2025-08-25 22:30:24,461][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007408] [Batch 02539/04869] [00:30:04/00:27:35, 0.711s/it]: train_loss_raw=2.1583, running_loss=2.1390, LR=0.000100
[2025-08-25 22:30:29,596][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007416] [Batch 02547/04869] [00:30:09/00:27:29, 0.710s/it]: train_loss_raw=2.0716, running_loss=2.1367, LR=0.000100
[2025-08-25 22:30:34,846][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007424] [Batch 02555/04869] [00:30:14/00:27:23, 0.710s/it]: train_loss_raw=2.0495, running_loss=2.1361, LR=0.000100
[2025-08-25 22:30:40,678][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007432] [Batch 02563/04869] [00:30:20/00:27:17, 0.710s/it]: train_loss_raw=2.1596, running_loss=2.1358, LR=0.000100
[2025-08-25 22:30:46,439][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007440] [Batch 02571/04869] [00:30:25/00:27:12, 0.710s/it]: train_loss_raw=2.1084, running_loss=2.1368, LR=0.000100
[2025-08-25 22:30:52,523][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007448] [Batch 02579/04869] [00:30:32/00:27:06, 0.710s/it]: train_loss_raw=2.1379, running_loss=2.1374, LR=0.000100
[2025-08-25 22:30:58,143][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007456] [Batch 02587/04869] [00:30:37/00:27:01, 0.710s/it]: train_loss_raw=2.1887, running_loss=2.1393, LR=0.000100
[2025-08-25 22:31:03,640][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007464] [Batch 02595/04869] [00:30:43/00:26:55, 0.710s/it]: train_loss_raw=2.0784, running_loss=2.1398, LR=0.000100
[2025-08-25 22:31:08,918][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007472] [Batch 02603/04869] [00:30:48/00:26:49, 0.710s/it]: train_loss_raw=2.0681, running_loss=2.1372, LR=0.000100
[2025-08-25 22:31:14,256][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007480] [Batch 02611/04869] [00:30:53/00:26:43, 0.710s/it]: train_loss_raw=2.0874, running_loss=2.1372, LR=0.000100
[2025-08-25 22:31:19,644][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007488] [Batch 02619/04869] [00:30:59/00:26:37, 0.710s/it]: train_loss_raw=2.0968, running_loss=2.1349, LR=0.000100
[2025-08-25 22:31:24,993][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007496] [Batch 02627/04869] [00:31:04/00:26:31, 0.710s/it]: train_loss_raw=2.1667, running_loss=2.1340, LR=0.000100
[2025-08-25 22:31:30,641][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007504] [Batch 02635/04869] [00:31:10/00:26:25, 0.710s/it]: train_loss_raw=2.1689, running_loss=2.1330, LR=0.000100
[2025-08-25 22:31:36,257][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007512] [Batch 02643/04869] [00:31:15/00:26:19, 0.710s/it]: train_loss_raw=2.1248, running_loss=2.1313, LR=0.000100
[2025-08-25 22:31:41,912][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007520] [Batch 02651/04869] [00:31:21/00:26:14, 0.710s/it]: train_loss_raw=2.1169, running_loss=2.1287, LR=0.000100
[2025-08-25 22:31:47,129][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007528] [Batch 02659/04869] [00:31:26/00:26:08, 0.710s/it]: train_loss_raw=2.1639, running_loss=2.1303, LR=0.000100
[2025-08-25 22:31:52,621][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007536] [Batch 02667/04869] [00:31:32/00:26:02, 0.709s/it]: train_loss_raw=2.1687, running_loss=2.1298, LR=0.000100
[2025-08-25 22:31:58,027][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007544] [Batch 02675/04869] [00:31:37/00:25:56, 0.709s/it]: train_loss_raw=2.1177, running_loss=2.1285, LR=0.000100
[2025-08-25 22:32:03,598][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007552] [Batch 02683/04869] [00:31:43/00:25:50, 0.709s/it]: train_loss_raw=2.1352, running_loss=2.1284, LR=0.000100
[2025-08-25 22:32:09,175][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007560] [Batch 02691/04869] [00:31:48/00:25:44, 0.709s/it]: train_loss_raw=2.1218, running_loss=2.1272, LR=0.000100
[2025-08-25 22:32:15,271][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007568] [Batch 02699/04869] [00:31:54/00:25:39, 0.709s/it]: train_loss_raw=2.1762, running_loss=2.1269, LR=0.000100
[2025-08-25 22:32:20,591][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007576] [Batch 02707/04869] [00:32:00/00:25:33, 0.709s/it]: train_loss_raw=2.1704, running_loss=2.1293, LR=0.000100
[2025-08-25 22:32:26,016][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007584] [Batch 02715/04869] [00:32:05/00:25:27, 0.709s/it]: train_loss_raw=2.1297, running_loss=2.1286, LR=0.000100
[2025-08-25 22:32:31,567][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007592] [Batch 02723/04869] [00:32:11/00:25:21, 0.709s/it]: train_loss_raw=2.1115, running_loss=2.1288, LR=0.000100
[2025-08-25 22:32:37,129][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007600] [Batch 02731/04869] [00:32:16/00:25:16, 0.709s/it]: train_loss_raw=2.1936, running_loss=2.1295, LR=0.000100
[2025-08-25 22:32:42,297][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007608] [Batch 02739/04869] [00:32:21/00:25:10, 0.709s/it]: train_loss_raw=2.1752, running_loss=2.1296, LR=0.000100
[2025-08-25 22:32:47,655][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007616] [Batch 02747/04869] [00:32:27/00:25:04, 0.709s/it]: train_loss_raw=2.1845, running_loss=2.1317, LR=0.000100
[2025-08-25 22:32:53,384][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007624] [Batch 02755/04869] [00:32:32/00:24:58, 0.709s/it]: train_loss_raw=2.0979, running_loss=2.1316, LR=0.000100
[2025-08-25 22:32:58,886][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007632] [Batch 02763/04869] [00:32:38/00:24:52, 0.709s/it]: train_loss_raw=2.1071, running_loss=2.1311, LR=0.000100
[2025-08-25 22:33:04,624][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007640] [Batch 02771/04869] [00:32:44/00:24:47, 0.709s/it]: train_loss_raw=2.1154, running_loss=2.1278, LR=0.000100
[2025-08-25 22:33:10,048][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007648] [Batch 02779/04869] [00:32:49/00:24:41, 0.709s/it]: train_loss_raw=2.0825, running_loss=2.1268, LR=0.000100
[2025-08-25 22:33:15,704][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007656] [Batch 02787/04869] [00:32:55/00:24:35, 0.709s/it]: train_loss_raw=2.1352, running_loss=2.1272, LR=0.000100
[2025-08-25 22:33:21,294][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007664] [Batch 02795/04869] [00:33:00/00:24:29, 0.709s/it]: train_loss_raw=2.1234, running_loss=2.1259, LR=0.000100
[2025-08-25 22:33:26,617][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007672] [Batch 02803/04869] [00:33:06/00:24:23, 0.709s/it]: train_loss_raw=2.1554, running_loss=2.1279, LR=0.000100
[2025-08-25 22:33:32,292][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007680] [Batch 02811/04869] [00:33:11/00:24:18, 0.709s/it]: train_loss_raw=2.2203, running_loss=2.1289, LR=0.000100
[2025-08-25 22:33:37,619][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007688] [Batch 02819/04869] [00:33:17/00:24:12, 0.708s/it]: train_loss_raw=2.0450, running_loss=2.1278, LR=0.000100
[2025-08-25 22:33:42,755][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007696] [Batch 02827/04869] [00:33:22/00:24:06, 0.708s/it]: train_loss_raw=2.2003, running_loss=2.1291, LR=0.000100
[2025-08-25 22:33:47,920][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007704] [Batch 02835/04869] [00:33:27/00:24:00, 0.708s/it]: train_loss_raw=2.1284, running_loss=2.1297, LR=0.000100
[2025-08-25 22:33:53,079][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007712] [Batch 02843/04869] [00:33:32/00:23:54, 0.708s/it]: train_loss_raw=2.1211, running_loss=2.1290, LR=0.000100
[2025-08-25 22:33:58,321][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007720] [Batch 02851/04869] [00:33:37/00:23:48, 0.708s/it]: train_loss_raw=2.1048, running_loss=2.1265, LR=0.000100
[2025-08-25 22:34:04,054][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007728] [Batch 02859/04869] [00:33:43/00:23:42, 0.708s/it]: train_loss_raw=2.1123, running_loss=2.1291, LR=0.000100
[2025-08-25 22:34:10,362][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007736] [Batch 02867/04869] [00:33:49/00:23:37, 0.708s/it]: train_loss_raw=2.1087, running_loss=2.1271, LR=0.000100
[2025-08-25 22:34:16,360][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007744] [Batch 02875/04869] [00:33:55/00:23:32, 0.708s/it]: train_loss_raw=2.2091, running_loss=2.1285, LR=0.000100
[2025-08-25 22:34:22,379][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007752] [Batch 02883/04869] [00:34:01/00:23:26, 0.708s/it]: train_loss_raw=2.0987, running_loss=2.1296, LR=0.000100
[2025-08-25 22:34:28,350][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007760] [Batch 02891/04869] [00:34:07/00:23:21, 0.708s/it]: train_loss_raw=2.0904, running_loss=2.1300, LR=0.000100
[2025-08-25 22:34:34,313][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007768] [Batch 02899/04869] [00:34:13/00:23:15, 0.708s/it]: train_loss_raw=2.1685, running_loss=2.1299, LR=0.000100
[2025-08-25 22:34:40,316][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007776] [Batch 02907/04869] [00:34:19/00:23:10, 0.709s/it]: train_loss_raw=2.1512, running_loss=2.1300, LR=0.000100
[2025-08-25 22:34:45,858][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007784] [Batch 02915/04869] [00:34:25/00:23:04, 0.709s/it]: train_loss_raw=2.1310, running_loss=2.1315, LR=0.000100
[2025-08-25 22:34:51,128][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007792] [Batch 02923/04869] [00:34:30/00:22:58, 0.708s/it]: train_loss_raw=2.1345, running_loss=2.1288, LR=0.000100
[2025-08-25 22:34:57,057][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007800] [Batch 02931/04869] [00:34:36/00:22:53, 0.709s/it]: train_loss_raw=2.1872, running_loss=2.1310, LR=0.000100
[2025-08-25 22:35:02,288][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007808] [Batch 02939/04869] [00:34:41/00:22:47, 0.708s/it]: train_loss_raw=2.1168, running_loss=2.1305, LR=0.000100
[2025-08-25 22:35:07,518][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007816] [Batch 02947/04869] [00:34:47/00:22:41, 0.708s/it]: train_loss_raw=2.1597, running_loss=2.1316, LR=0.000100
[2025-08-25 22:35:12,875][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007824] [Batch 02955/04869] [00:34:52/00:22:35, 0.708s/it]: train_loss_raw=2.1256, running_loss=2.1292, LR=0.000100
[2025-08-25 22:35:18,748][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007832] [Batch 02963/04869] [00:34:58/00:22:29, 0.708s/it]: train_loss_raw=2.1301, running_loss=2.1275, LR=0.000100
[2025-08-25 22:35:24,351][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007840] [Batch 02971/04869] [00:35:03/00:22:24, 0.708s/it]: train_loss_raw=2.1709, running_loss=2.1290, LR=0.000100
[2025-08-25 22:35:30,084][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007848] [Batch 02979/04869] [00:35:09/00:22:18, 0.708s/it]: train_loss_raw=2.1593, running_loss=2.1297, LR=0.000100
[2025-08-25 22:35:35,903][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007856] [Batch 02987/04869] [00:35:15/00:22:12, 0.708s/it]: train_loss_raw=2.1283, running_loss=2.1295, LR=0.000100
[2025-08-25 22:35:41,627][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007864] [Batch 02995/04869] [00:35:21/00:22:07, 0.708s/it]: train_loss_raw=2.1165, running_loss=2.1266, LR=0.000100
[2025-08-25 22:35:47,235][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007872] [Batch 03003/04869] [00:35:26/00:22:01, 0.708s/it]: train_loss_raw=2.0518, running_loss=2.1251, LR=0.000100
[2025-08-25 22:35:52,858][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007880] [Batch 03011/04869] [00:35:32/00:21:55, 0.708s/it]: train_loss_raw=2.1003, running_loss=2.1231, LR=0.000100
[2025-08-25 22:35:58,545][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007888] [Batch 03019/04869] [00:35:38/00:21:50, 0.708s/it]: train_loss_raw=2.1572, running_loss=2.1224, LR=0.000100
[2025-08-25 22:36:04,027][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007896] [Batch 03027/04869] [00:35:43/00:21:44, 0.708s/it]: train_loss_raw=2.1271, running_loss=2.1191, LR=0.000100
[2025-08-25 22:36:09,884][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007904] [Batch 03035/04869] [00:35:49/00:21:38, 0.708s/it]: train_loss_raw=2.0640, running_loss=2.1185, LR=0.000100
[2025-08-25 22:36:15,628][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007912] [Batch 03043/04869] [00:35:55/00:21:33, 0.708s/it]: train_loss_raw=2.1049, running_loss=2.1194, LR=0.000100
[2025-08-25 22:36:20,854][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007920] [Batch 03051/04869] [00:36:00/00:21:27, 0.708s/it]: train_loss_raw=2.0839, running_loss=2.1192, LR=0.000100
[2025-08-25 22:36:26,622][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007928] [Batch 03059/04869] [00:36:06/00:21:21, 0.708s/it]: train_loss_raw=2.1249, running_loss=2.1176, LR=0.000100
[2025-08-25 22:36:32,162][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007936] [Batch 03067/04869] [00:36:11/00:21:15, 0.708s/it]: train_loss_raw=2.0611, running_loss=2.1168, LR=0.000100
[2025-08-25 22:36:37,783][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007944] [Batch 03075/04869] [00:36:17/00:21:10, 0.708s/it]: train_loss_raw=2.0921, running_loss=2.1173, LR=0.000100
[2025-08-25 22:36:43,134][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007952] [Batch 03083/04869] [00:36:22/00:21:04, 0.708s/it]: train_loss_raw=2.1068, running_loss=2.1168, LR=0.000100
[2025-08-25 22:36:48,705][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007960] [Batch 03091/04869] [00:36:28/00:20:58, 0.708s/it]: train_loss_raw=2.1221, running_loss=2.1153, LR=0.000100
[2025-08-25 22:36:54,195][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007968] [Batch 03099/04869] [00:36:33/00:20:52, 0.708s/it]: train_loss_raw=2.1936, running_loss=2.1153, LR=0.000100
[2025-08-25 22:36:59,882][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007976] [Batch 03107/04869] [00:36:39/00:20:47, 0.708s/it]: train_loss_raw=2.1101, running_loss=2.1149, LR=0.000100
[2025-08-25 22:37:05,192][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007984] [Batch 03115/04869] [00:36:44/00:20:41, 0.708s/it]: train_loss_raw=2.0633, running_loss=2.1141, LR=0.000100
[2025-08-25 22:37:10,486][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007992] [Batch 03123/04869] [00:36:50/00:20:35, 0.708s/it]: train_loss_raw=2.1131, running_loss=2.1144, LR=0.000100
[2025-08-25 22:37:16,437][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008000] [Batch 03131/04869] [00:36:55/00:20:30, 0.708s/it]: train_loss_raw=2.1495, running_loss=2.1138, LR=0.000100
[2025-08-25 22:37:25,629][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008008] [Batch 03139/04869] [00:37:05/00:20:26, 0.709s/it]: train_loss_raw=2.0645, running_loss=2.1152, LR=0.000100
[2025-08-25 22:37:30,935][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008016] [Batch 03147/04869] [00:37:10/00:20:20, 0.709s/it]: train_loss_raw=2.1163, running_loss=2.1133, LR=0.000100
[2025-08-25 22:37:36,251][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008024] [Batch 03155/04869] [00:37:15/00:20:14, 0.709s/it]: train_loss_raw=2.1094, running_loss=2.1142, LR=0.000100
[2025-08-25 22:37:41,952][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008032] [Batch 03163/04869] [00:37:21/00:20:08, 0.709s/it]: train_loss_raw=2.1111, running_loss=2.1145, LR=0.000100
[2025-08-25 22:37:47,416][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008040] [Batch 03171/04869] [00:37:26/00:20:03, 0.709s/it]: train_loss_raw=2.1132, running_loss=2.1137, LR=0.000100
[2025-08-25 22:37:53,681][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008048] [Batch 03179/04869] [00:37:33/00:19:57, 0.709s/it]: train_loss_raw=2.0485, running_loss=2.1131, LR=0.000100
[2025-08-25 22:37:59,437][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008056] [Batch 03187/04869] [00:37:38/00:19:52, 0.709s/it]: train_loss_raw=2.1877, running_loss=2.1117, LR=0.000100
[2025-08-25 22:38:05,159][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008064] [Batch 03195/04869] [00:37:44/00:19:46, 0.709s/it]: train_loss_raw=2.1114, running_loss=2.1120, LR=0.000100
[2025-08-25 22:38:10,815][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008072] [Batch 03203/04869] [00:37:50/00:19:40, 0.709s/it]: train_loss_raw=2.0945, running_loss=2.1112, LR=0.000100
[2025-08-25 22:38:16,641][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008080] [Batch 03211/04869] [00:37:56/00:19:35, 0.709s/it]: train_loss_raw=2.0991, running_loss=2.1113, LR=0.000100
[2025-08-25 22:38:22,185][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008088] [Batch 03219/04869] [00:38:01/00:19:29, 0.709s/it]: train_loss_raw=2.1408, running_loss=2.1116, LR=0.000100
[2025-08-25 22:38:27,543][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008096] [Batch 03227/04869] [00:38:07/00:19:23, 0.709s/it]: train_loss_raw=2.0716, running_loss=2.1119, LR=0.000100
[2025-08-25 22:38:32,960][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008104] [Batch 03235/04869] [00:38:12/00:19:17, 0.709s/it]: train_loss_raw=2.1335, running_loss=2.1126, LR=0.000100
[2025-08-25 22:38:38,691][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008112] [Batch 03243/04869] [00:38:18/00:19:12, 0.709s/it]: train_loss_raw=2.0179, running_loss=2.1116, LR=0.000100
[2025-08-25 22:38:44,660][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008120] [Batch 03251/04869] [00:38:24/00:19:06, 0.709s/it]: train_loss_raw=2.0999, running_loss=2.1139, LR=0.000100
[2025-08-25 22:38:50,821][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008128] [Batch 03259/04869] [00:38:30/00:19:01, 0.709s/it]: train_loss_raw=2.0233, running_loss=2.1125, LR=0.000100
[2025-08-25 22:38:56,446][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008136] [Batch 03267/04869] [00:38:36/00:18:55, 0.709s/it]: train_loss_raw=2.0902, running_loss=2.1113, LR=0.000100
[2025-08-25 22:39:01,983][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008144] [Batch 03275/04869] [00:38:41/00:18:49, 0.709s/it]: train_loss_raw=2.0938, running_loss=2.1109, LR=0.000100
[2025-08-25 22:39:07,720][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008152] [Batch 03283/04869] [00:38:47/00:18:44, 0.709s/it]: train_loss_raw=2.0762, running_loss=2.1115, LR=0.000100
[2025-08-25 22:39:13,534][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008160] [Batch 03291/04869] [00:38:53/00:18:38, 0.709s/it]: train_loss_raw=2.1392, running_loss=2.1110, LR=0.000100
[2025-08-25 22:39:19,936][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008168] [Batch 03299/04869] [00:38:59/00:18:33, 0.709s/it]: train_loss_raw=2.0353, running_loss=2.1086, LR=0.000100
[2025-08-25 22:39:25,426][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008176] [Batch 03307/04869] [00:39:04/00:18:27, 0.709s/it]: train_loss_raw=2.1118, running_loss=2.1098, LR=0.000100
[2025-08-25 22:39:30,727][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008184] [Batch 03315/04869] [00:39:10/00:18:21, 0.709s/it]: train_loss_raw=2.0782, running_loss=2.1109, LR=0.000100
[2025-08-25 22:39:36,310][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008192] [Batch 03323/04869] [00:39:15/00:18:16, 0.709s/it]: train_loss_raw=2.1103, running_loss=2.1123, LR=0.000100
[2025-08-25 22:39:41,688][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008200] [Batch 03331/04869] [00:39:21/00:18:10, 0.709s/it]: train_loss_raw=2.1649, running_loss=2.1122, LR=0.000100
[2025-08-25 22:39:46,924][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008208] [Batch 03339/04869] [00:39:26/00:18:04, 0.709s/it]: train_loss_raw=2.1484, running_loss=2.1129, LR=0.000100
[2025-08-25 22:39:52,762][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008216] [Batch 03347/04869] [00:39:32/00:17:58, 0.709s/it]: train_loss_raw=2.0877, running_loss=2.1125, LR=0.000100
[2025-08-25 22:39:58,444][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008224] [Batch 03355/04869] [00:39:38/00:17:53, 0.709s/it]: train_loss_raw=2.0608, running_loss=2.1122, LR=0.000100
[2025-08-25 22:40:04,591][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008232] [Batch 03363/04869] [00:39:44/00:17:47, 0.709s/it]: train_loss_raw=2.1456, running_loss=2.1116, LR=0.000100
[2025-08-25 22:40:09,833][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008240] [Batch 03371/04869] [00:39:49/00:17:41, 0.709s/it]: train_loss_raw=2.1260, running_loss=2.1117, LR=0.000100
[2025-08-25 22:40:15,215][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008248] [Batch 03379/04869] [00:39:54/00:17:35, 0.709s/it]: train_loss_raw=2.1120, running_loss=2.1113, LR=0.000100
[2025-08-25 22:40:20,554][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008256] [Batch 03387/04869] [00:40:00/00:17:30, 0.709s/it]: train_loss_raw=2.1227, running_loss=2.1102, LR=0.000100
[2025-08-25 22:40:25,871][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008264] [Batch 03395/04869] [00:40:05/00:17:24, 0.709s/it]: train_loss_raw=2.1450, running_loss=2.1131, LR=0.000100
[2025-08-25 22:40:31,709][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008272] [Batch 03403/04869] [00:40:11/00:17:18, 0.709s/it]: train_loss_raw=2.0728, running_loss=2.1106, LR=0.000100
[2025-08-25 22:40:36,990][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008280] [Batch 03411/04869] [00:40:16/00:17:12, 0.708s/it]: train_loss_raw=2.1597, running_loss=2.1103, LR=0.000100
[2025-08-25 22:40:42,732][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008288] [Batch 03419/04869] [00:40:22/00:17:07, 0.708s/it]: train_loss_raw=2.1002, running_loss=2.1113, LR=0.000100
[2025-08-25 22:40:48,537][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008296] [Batch 03427/04869] [00:40:28/00:17:01, 0.709s/it]: train_loss_raw=2.0516, running_loss=2.1094, LR=0.000100
[2025-08-25 22:40:53,793][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008304] [Batch 03435/04869] [00:40:33/00:16:55, 0.708s/it]: train_loss_raw=2.1952, running_loss=2.1111, LR=0.000100
[2025-08-25 22:40:58,947][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008312] [Batch 03443/04869] [00:40:38/00:16:49, 0.708s/it]: train_loss_raw=2.1318, running_loss=2.1099, LR=0.000100
[2025-08-25 22:41:04,390][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008320] [Batch 03451/04869] [00:40:43/00:16:44, 0.708s/it]: train_loss_raw=2.1217, running_loss=2.1115, LR=0.000100
[2025-08-25 22:41:09,810][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008328] [Batch 03459/04869] [00:40:49/00:16:38, 0.708s/it]: train_loss_raw=2.0254, running_loss=2.1076, LR=0.000100
[2025-08-25 22:41:15,256][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008336] [Batch 03467/04869] [00:40:54/00:16:32, 0.708s/it]: train_loss_raw=2.0938, running_loss=2.1097, LR=0.000100
[2025-08-25 22:41:20,400][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008344] [Batch 03475/04869] [00:40:59/00:16:26, 0.708s/it]: train_loss_raw=2.0765, running_loss=2.1090, LR=0.000100
[2025-08-25 22:41:25,887][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008352] [Batch 03483/04869] [00:41:05/00:16:21, 0.708s/it]: train_loss_raw=2.1266, running_loss=2.1089, LR=0.000100
[2025-08-25 22:41:31,459][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008360] [Batch 03491/04869] [00:41:11/00:16:15, 0.708s/it]: train_loss_raw=2.1662, running_loss=2.1102, LR=0.000100
[2025-08-25 22:41:36,835][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008368] [Batch 03499/04869] [00:41:16/00:16:09, 0.708s/it]: train_loss_raw=2.0204, running_loss=2.1108, LR=0.000100
[2025-08-25 22:41:42,380][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008376] [Batch 03507/04869] [00:41:21/00:16:03, 0.708s/it]: train_loss_raw=2.0366, running_loss=2.1095, LR=0.000100
[2025-08-25 22:41:47,561][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008384] [Batch 03515/04869] [00:41:27/00:15:58, 0.708s/it]: train_loss_raw=2.1683, running_loss=2.1088, LR=0.000100
[2025-08-25 22:41:52,729][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008392] [Batch 03523/04869] [00:41:32/00:15:52, 0.707s/it]: train_loss_raw=2.0789, running_loss=2.1092, LR=0.000100
[2025-08-25 22:41:58,011][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008400] [Batch 03531/04869] [00:41:37/00:15:46, 0.707s/it]: train_loss_raw=2.0831, running_loss=2.1083, LR=0.000100
[2025-08-25 22:42:03,770][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008408] [Batch 03539/04869] [00:41:43/00:15:40, 0.707s/it]: train_loss_raw=2.1448, running_loss=2.1063, LR=0.000100
[2025-08-25 22:42:09,643][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008416] [Batch 03547/04869] [00:41:49/00:15:35, 0.707s/it]: train_loss_raw=1.9777, running_loss=2.1041, LR=0.000100
[2025-08-25 22:42:15,746][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008424] [Batch 03555/04869] [00:41:55/00:15:29, 0.708s/it]: train_loss_raw=2.0641, running_loss=2.1027, LR=0.000100
[2025-08-25 22:42:21,613][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008432] [Batch 03563/04869] [00:42:01/00:15:24, 0.708s/it]: train_loss_raw=2.1855, running_loss=2.1036, LR=0.000100
[2025-08-25 22:42:26,773][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008440] [Batch 03571/04869] [00:42:06/00:15:18, 0.707s/it]: train_loss_raw=2.0783, running_loss=2.1030, LR=0.000100
[2025-08-25 22:42:31,927][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008448] [Batch 03579/04869] [00:42:11/00:15:12, 0.707s/it]: train_loss_raw=2.1581, running_loss=2.1045, LR=0.000100
[2025-08-25 22:42:37,091][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008456] [Batch 03587/04869] [00:42:16/00:15:06, 0.707s/it]: train_loss_raw=2.0461, running_loss=2.1033, LR=0.000100
[2025-08-25 22:42:42,269][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008464] [Batch 03595/04869] [00:42:21/00:15:00, 0.707s/it]: train_loss_raw=2.0764, running_loss=2.1038, LR=0.000100
[2025-08-25 22:42:47,543][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008472] [Batch 03603/04869] [00:42:27/00:14:54, 0.707s/it]: train_loss_raw=2.1241, running_loss=2.1048, LR=0.000100
[2025-08-25 22:42:52,788][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008480] [Batch 03611/04869] [00:42:32/00:14:49, 0.707s/it]: train_loss_raw=2.0370, running_loss=2.1056, LR=0.000100
[2025-08-25 22:42:57,974][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008488] [Batch 03619/04869] [00:42:37/00:14:43, 0.707s/it]: train_loss_raw=2.1195, running_loss=2.1054, LR=0.000100
[2025-08-25 22:43:03,163][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008496] [Batch 03627/04869] [00:42:42/00:14:37, 0.707s/it]: train_loss_raw=2.0550, running_loss=2.1034, LR=0.000100
[2025-08-25 22:43:08,363][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008504] [Batch 03635/04869] [00:42:47/00:14:31, 0.706s/it]: train_loss_raw=2.1280, running_loss=2.1038, LR=0.000100
[2025-08-25 22:43:14,240][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008512] [Batch 03643/04869] [00:42:53/00:14:26, 0.707s/it]: train_loss_raw=2.0933, running_loss=2.1028, LR=0.000100
[2025-08-25 22:43:19,765][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008520] [Batch 03651/04869] [00:42:59/00:14:20, 0.706s/it]: train_loss_raw=2.0777, running_loss=2.1034, LR=0.000100
[2025-08-25 22:43:24,941][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008528] [Batch 03659/04869] [00:43:04/00:14:14, 0.706s/it]: train_loss_raw=2.1534, running_loss=2.1023, LR=0.000100
[2025-08-25 22:43:30,106][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008536] [Batch 03667/04869] [00:43:09/00:14:08, 0.706s/it]: train_loss_raw=2.0448, running_loss=2.1007, LR=0.000100
[2025-08-25 22:43:35,279][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008544] [Batch 03675/04869] [00:43:14/00:14:03, 0.706s/it]: train_loss_raw=2.0744, running_loss=2.0990, LR=0.000100
[2025-08-25 22:43:40,770][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008552] [Batch 03683/04869] [00:43:20/00:13:57, 0.706s/it]: train_loss_raw=2.0995, running_loss=2.0993, LR=0.000100
[2025-08-25 22:43:46,646][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008560] [Batch 03691/04869] [00:43:26/00:13:51, 0.706s/it]: train_loss_raw=2.1060, running_loss=2.1004, LR=0.000100
[2025-08-25 22:43:52,670][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008568] [Batch 03699/04869] [00:43:32/00:13:46, 0.706s/it]: train_loss_raw=2.1003, running_loss=2.0961, LR=0.000100
[2025-08-25 22:43:58,158][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008576] [Batch 03707/04869] [00:43:37/00:13:40, 0.706s/it]: train_loss_raw=2.1322, running_loss=2.0967, LR=0.000100
[2025-08-25 22:44:03,615][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008584] [Batch 03715/04869] [00:43:43/00:13:34, 0.706s/it]: train_loss_raw=2.0756, running_loss=2.0953, LR=0.000100
[2025-08-25 22:44:09,032][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008592] [Batch 03723/04869] [00:43:48/00:13:29, 0.706s/it]: train_loss_raw=2.0168, running_loss=2.0929, LR=0.000100
[2025-08-25 22:44:14,836][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008600] [Batch 03731/04869] [00:43:54/00:13:23, 0.706s/it]: train_loss_raw=2.0879, running_loss=2.0957, LR=0.000100
[2025-08-25 22:44:20,582][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008608] [Batch 03739/04869] [00:44:00/00:13:17, 0.706s/it]: train_loss_raw=2.0681, running_loss=2.0963, LR=0.000100
[2025-08-25 22:44:26,521][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008616] [Batch 03747/04869] [00:44:06/00:13:12, 0.706s/it]: train_loss_raw=2.1050, running_loss=2.0975, LR=0.000100
[2025-08-25 22:44:32,520][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008624] [Batch 03755/04869] [00:44:12/00:13:06, 0.706s/it]: train_loss_raw=2.0218, running_loss=2.0960, LR=0.000100
[2025-08-25 22:44:38,231][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008632] [Batch 03763/04869] [00:44:17/00:13:01, 0.706s/it]: train_loss_raw=2.0527, running_loss=2.0963, LR=0.000100
[2025-08-25 22:44:44,013][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008640] [Batch 03771/04869] [00:44:23/00:12:55, 0.706s/it]: train_loss_raw=2.1476, running_loss=2.0978, LR=0.000100
[2025-08-25 22:44:49,411][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008648] [Batch 03779/04869] [00:44:28/00:12:49, 0.706s/it]: train_loss_raw=2.0485, running_loss=2.0977, LR=0.000100
[2025-08-25 22:44:55,008][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008656] [Batch 03787/04869] [00:44:34/00:12:44, 0.706s/it]: train_loss_raw=2.0564, running_loss=2.0980, LR=0.000100
[2025-08-25 22:45:00,906][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008664] [Batch 03795/04869] [00:44:40/00:12:38, 0.706s/it]: train_loss_raw=2.1483, running_loss=2.0994, LR=0.000100
[2025-08-25 22:45:06,172][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008672] [Batch 03803/04869] [00:44:45/00:12:32, 0.706s/it]: train_loss_raw=1.9972, running_loss=2.0975, LR=0.000100
[2025-08-25 22:45:12,120][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008680] [Batch 03811/04869] [00:44:51/00:12:27, 0.706s/it]: train_loss_raw=2.0633, running_loss=2.0931, LR=0.000100
[2025-08-25 22:45:17,320][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008688] [Batch 03819/04869] [00:44:56/00:12:21, 0.706s/it]: train_loss_raw=2.0983, running_loss=2.0935, LR=0.000100
[2025-08-25 22:45:22,871][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008696] [Batch 03827/04869] [00:45:02/00:12:15, 0.706s/it]: train_loss_raw=2.0405, running_loss=2.0920, LR=0.000100
[2025-08-25 22:45:28,292][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008704] [Batch 03835/04869] [00:45:07/00:12:10, 0.706s/it]: train_loss_raw=2.1375, running_loss=2.0914, LR=0.000100
[2025-08-25 22:45:33,840][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008712] [Batch 03843/04869] [00:45:13/00:12:04, 0.706s/it]: train_loss_raw=2.0681, running_loss=2.0914, LR=0.000100
[2025-08-25 22:45:39,029][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008720] [Batch 03851/04869] [00:45:18/00:11:58, 0.706s/it]: train_loss_raw=2.0608, running_loss=2.0910, LR=0.000100
[2025-08-25 22:45:45,046][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008728] [Batch 03859/04869] [00:45:24/00:11:53, 0.706s/it]: train_loss_raw=2.1216, running_loss=2.0907, LR=0.000100
[2025-08-25 22:45:51,146][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008736] [Batch 03867/04869] [00:45:30/00:11:47, 0.706s/it]: train_loss_raw=2.1772, running_loss=2.0911, LR=0.000100
[2025-08-25 22:45:56,705][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008744] [Batch 03875/04869] [00:45:36/00:11:41, 0.706s/it]: train_loss_raw=2.1289, running_loss=2.0901, LR=0.000100
[2025-08-25 22:46:02,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008752] [Batch 03883/04869] [00:45:41/00:11:36, 0.706s/it]: train_loss_raw=2.0610, running_loss=2.0904, LR=0.000100
[2025-08-25 22:46:08,230][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008760] [Batch 03891/04869] [00:45:47/00:11:30, 0.706s/it]: train_loss_raw=2.1097, running_loss=2.0896, LR=0.000100
[2025-08-25 22:46:14,196][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008768] [Batch 03899/04869] [00:45:53/00:11:25, 0.706s/it]: train_loss_raw=2.1141, running_loss=2.0897, LR=0.000100
[2025-08-25 22:46:19,801][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008776] [Batch 03907/04869] [00:45:59/00:11:19, 0.706s/it]: train_loss_raw=2.1162, running_loss=2.0908, LR=0.000100
[2025-08-25 22:46:25,195][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008784] [Batch 03915/04869] [00:46:04/00:11:13, 0.706s/it]: train_loss_raw=2.0370, running_loss=2.0899, LR=0.000100
[2025-08-25 22:46:30,855][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008792] [Batch 03923/04869] [00:46:10/00:11:08, 0.706s/it]: train_loss_raw=2.1612, running_loss=2.0919, LR=0.000100
[2025-08-25 22:46:37,001][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008800] [Batch 03931/04869] [00:46:16/00:11:02, 0.706s/it]: train_loss_raw=2.1083, running_loss=2.0907, LR=0.000100
[2025-08-25 22:46:43,038][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008808] [Batch 03939/04869] [00:46:22/00:10:56, 0.706s/it]: train_loss_raw=2.1478, running_loss=2.0921, LR=0.000100
[2025-08-25 22:46:48,811][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008816] [Batch 03947/04869] [00:46:28/00:10:51, 0.706s/it]: train_loss_raw=2.0393, running_loss=2.0927, LR=0.000100
[2025-08-25 22:46:54,426][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008824] [Batch 03955/04869] [00:46:33/00:10:45, 0.706s/it]: train_loss_raw=2.0918, running_loss=2.0932, LR=0.000100
[2025-08-25 22:47:00,350][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008832] [Batch 03963/04869] [00:46:39/00:10:40, 0.707s/it]: train_loss_raw=2.0337, running_loss=2.0925, LR=0.000100
[2025-08-25 22:47:05,729][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008840] [Batch 03971/04869] [00:46:45/00:10:34, 0.706s/it]: train_loss_raw=2.1322, running_loss=2.0925, LR=0.000100
[2025-08-25 22:47:11,194][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008848] [Batch 03979/04869] [00:46:50/00:10:28, 0.706s/it]: train_loss_raw=2.1267, running_loss=2.0911, LR=0.000100
[2025-08-25 22:47:17,188][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008856] [Batch 03987/04869] [00:46:56/00:10:23, 0.706s/it]: train_loss_raw=2.0865, running_loss=2.0887, LR=0.000100
[2025-08-25 22:47:23,023][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008864] [Batch 03995/04869] [00:47:02/00:10:17, 0.707s/it]: train_loss_raw=2.1562, running_loss=2.0872, LR=0.000100
[2025-08-25 22:47:29,005][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008872] [Batch 04003/04869] [00:47:08/00:10:11, 0.707s/it]: train_loss_raw=2.0334, running_loss=2.0863, LR=0.000100
[2025-08-25 22:47:35,123][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008880] [Batch 04011/04869] [00:47:14/00:10:06, 0.707s/it]: train_loss_raw=2.0555, running_loss=2.0865, LR=0.000100
[2025-08-25 22:47:40,341][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008888] [Batch 04019/04869] [00:47:19/00:10:00, 0.707s/it]: train_loss_raw=2.0902, running_loss=2.0865, LR=0.000100
[2025-08-25 22:47:46,024][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008896] [Batch 04027/04869] [00:47:25/00:09:54, 0.707s/it]: train_loss_raw=2.0390, running_loss=2.0871, LR=0.000100
[2025-08-25 22:47:51,903][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008904] [Batch 04035/04869] [00:47:31/00:09:49, 0.707s/it]: train_loss_raw=2.0705, running_loss=2.0860, LR=0.000100
[2025-08-25 22:47:57,065][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008912] [Batch 04043/04869] [00:47:36/00:09:43, 0.707s/it]: train_loss_raw=2.1018, running_loss=2.0863, LR=0.000100
[2025-08-25 22:48:02,239][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008920] [Batch 04051/04869] [00:47:41/00:09:37, 0.706s/it]: train_loss_raw=2.0585, running_loss=2.0842, LR=0.000100
[2025-08-25 22:48:07,873][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008928] [Batch 04059/04869] [00:47:47/00:09:32, 0.706s/it]: train_loss_raw=2.0685, running_loss=2.0849, LR=0.000100
[2025-08-25 22:48:13,051][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008936] [Batch 04067/04869] [00:47:52/00:09:26, 0.706s/it]: train_loss_raw=2.1133, running_loss=2.0836, LR=0.000100
[2025-08-25 22:48:18,241][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008944] [Batch 04075/04869] [00:47:57/00:09:20, 0.706s/it]: train_loss_raw=2.1389, running_loss=2.0855, LR=0.000100
[2025-08-25 22:48:23,621][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008952] [Batch 04083/04869] [00:48:03/00:09:15, 0.706s/it]: train_loss_raw=2.0439, running_loss=2.0865, LR=0.000100
[2025-08-25 22:48:29,155][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008960] [Batch 04091/04869] [00:48:08/00:09:09, 0.706s/it]: train_loss_raw=2.0670, running_loss=2.0863, LR=0.000100
[2025-08-25 22:48:34,746][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008968] [Batch 04099/04869] [00:48:14/00:09:03, 0.706s/it]: train_loss_raw=2.1819, running_loss=2.0883, LR=0.000100
[2025-08-25 22:48:40,767][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008976] [Batch 04107/04869] [00:48:20/00:08:58, 0.706s/it]: train_loss_raw=2.1768, running_loss=2.0901, LR=0.000100
[2025-08-25 22:48:46,928][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008984] [Batch 04115/04869] [00:48:26/00:08:52, 0.706s/it]: train_loss_raw=2.0870, running_loss=2.0897, LR=0.000100
[2025-08-25 22:48:52,456][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008992] [Batch 04123/04869] [00:48:32/00:08:46, 0.706s/it]: train_loss_raw=2.0786, running_loss=2.0885, LR=0.000100
[2025-08-25 22:48:58,357][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009000] [Batch 04131/04869] [00:48:37/00:08:41, 0.706s/it]: train_loss_raw=2.0504, running_loss=2.0877, LR=0.000100
[2025-08-25 22:49:04,375][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009008] [Batch 04139/04869] [00:48:43/00:08:35, 0.706s/it]: train_loss_raw=2.2093, running_loss=2.0892, LR=0.000100
[2025-08-25 22:49:10,057][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009016] [Batch 04147/04869] [00:48:49/00:08:30, 0.706s/it]: train_loss_raw=2.0331, running_loss=2.0876, LR=0.000100
[2025-08-25 22:49:15,390][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009024] [Batch 04155/04869] [00:48:54/00:08:24, 0.706s/it]: train_loss_raw=2.1322, running_loss=2.0856, LR=0.000100
[2025-08-25 22:49:21,469][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009032] [Batch 04163/04869] [00:49:01/00:08:18, 0.706s/it]: train_loss_raw=2.0603, running_loss=2.0842, LR=0.000100
[2025-08-25 22:49:26,886][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009040] [Batch 04171/04869] [00:49:06/00:08:13, 0.706s/it]: train_loss_raw=2.1056, running_loss=2.0833, LR=0.000100
[2025-08-25 22:49:32,782][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009048] [Batch 04179/04869] [00:49:12/00:08:07, 0.706s/it]: train_loss_raw=2.0277, running_loss=2.0816, LR=0.000100
[2025-08-25 22:49:37,958][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009056] [Batch 04187/04869] [00:49:17/00:08:01, 0.706s/it]: train_loss_raw=2.0550, running_loss=2.0810, LR=0.000100
[2025-08-25 22:49:43,161][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009064] [Batch 04195/04869] [00:49:22/00:07:56, 0.706s/it]: train_loss_raw=2.0737, running_loss=2.0779, LR=0.000100
[2025-08-25 22:49:48,384][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009072] [Batch 04203/04869] [00:49:27/00:07:50, 0.706s/it]: train_loss_raw=2.0615, running_loss=2.0761, LR=0.000100
[2025-08-25 22:49:53,566][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009080] [Batch 04211/04869] [00:49:33/00:07:44, 0.706s/it]: train_loss_raw=2.1062, running_loss=2.0770, LR=0.000100
[2025-08-25 22:49:58,924][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009088] [Batch 04219/04869] [00:49:38/00:07:38, 0.706s/it]: train_loss_raw=2.0986, running_loss=2.0755, LR=0.000100
[2025-08-25 22:50:04,841][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009096] [Batch 04227/04869] [00:49:44/00:07:33, 0.706s/it]: train_loss_raw=2.0678, running_loss=2.0778, LR=0.000100
[2025-08-25 22:50:09,972][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009104] [Batch 04235/04869] [00:49:49/00:07:27, 0.706s/it]: train_loss_raw=2.0645, running_loss=2.0776, LR=0.000100
[2025-08-25 22:50:15,113][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009112] [Batch 04243/04869] [00:49:54/00:07:21, 0.706s/it]: train_loss_raw=2.0745, running_loss=2.0769, LR=0.000100
[2025-08-25 22:50:20,404][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009120] [Batch 04251/04869] [00:49:59/00:07:16, 0.706s/it]: train_loss_raw=2.1005, running_loss=2.0775, LR=0.000100
[2025-08-25 22:50:26,000][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009128] [Batch 04259/04869] [00:50:05/00:07:10, 0.706s/it]: train_loss_raw=2.0494, running_loss=2.0774, LR=0.000100
[2025-08-25 22:50:31,886][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009136] [Batch 04267/04869] [00:50:11/00:07:04, 0.706s/it]: train_loss_raw=2.1042, running_loss=2.0781, LR=0.000100
[2025-08-25 22:50:37,690][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009144] [Batch 04275/04869] [00:50:17/00:06:59, 0.706s/it]: train_loss_raw=2.0609, running_loss=2.0795, LR=0.000100
[2025-08-25 22:50:42,835][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009152] [Batch 04283/04869] [00:50:22/00:06:53, 0.706s/it]: train_loss_raw=1.9998, running_loss=2.0765, LR=0.000100
[2025-08-25 22:50:48,052][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009160] [Batch 04291/04869] [00:50:27/00:06:47, 0.706s/it]: train_loss_raw=1.9551, running_loss=2.0763, LR=0.000100
[2025-08-25 22:50:53,414][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009168] [Batch 04299/04869] [00:50:32/00:06:42, 0.706s/it]: train_loss_raw=2.0757, running_loss=2.0772, LR=0.000100
[2025-08-25 22:50:58,888][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009176] [Batch 04307/04869] [00:50:38/00:06:36, 0.705s/it]: train_loss_raw=2.0215, running_loss=2.0765, LR=0.000100
[2025-08-25 22:51:04,234][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009184] [Batch 04315/04869] [00:50:43/00:06:30, 0.705s/it]: train_loss_raw=2.0543, running_loss=2.0772, LR=0.000100
[2025-08-25 22:51:09,516][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009192] [Batch 04323/04869] [00:50:49/00:06:25, 0.705s/it]: train_loss_raw=2.0235, running_loss=2.0779, LR=0.000100
[2025-08-25 22:51:14,831][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009200] [Batch 04331/04869] [00:50:54/00:06:19, 0.705s/it]: train_loss_raw=2.0314, running_loss=2.0768, LR=0.000100
[2025-08-25 22:51:19,971][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009208] [Batch 04339/04869] [00:50:59/00:06:13, 0.705s/it]: train_loss_raw=2.0547, running_loss=2.0758, LR=0.000100
[2025-08-25 22:51:25,308][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009216] [Batch 04347/04869] [00:51:04/00:06:08, 0.705s/it]: train_loss_raw=2.0753, running_loss=2.0753, LR=0.000100
[2025-08-25 22:51:30,517][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009224] [Batch 04355/04869] [00:51:10/00:06:02, 0.705s/it]: train_loss_raw=2.0610, running_loss=2.0769, LR=0.000100
[2025-08-25 22:51:35,675][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009232] [Batch 04363/04869] [00:51:15/00:05:56, 0.705s/it]: train_loss_raw=2.0927, running_loss=2.0764, LR=0.000100
[2025-08-25 22:51:40,963][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009240] [Batch 04371/04869] [00:51:20/00:05:50, 0.705s/it]: train_loss_raw=2.1462, running_loss=2.0782, LR=0.000100
[2025-08-25 22:51:46,355][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009248] [Batch 04379/04869] [00:51:25/00:05:45, 0.705s/it]: train_loss_raw=2.1023, running_loss=2.0773, LR=0.000100
[2025-08-25 22:51:51,638][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009256] [Batch 04387/04869] [00:51:31/00:05:39, 0.705s/it]: train_loss_raw=2.0411, running_loss=2.0792, LR=0.000100
[2025-08-25 22:51:57,346][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009264] [Batch 04395/04869] [00:51:36/00:05:34, 0.705s/it]: train_loss_raw=2.1236, running_loss=2.0794, LR=0.000100
[2025-08-25 22:52:03,385][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009272] [Batch 04403/04869] [00:51:42/00:05:28, 0.705s/it]: train_loss_raw=1.9965, running_loss=2.0789, LR=0.000100
[2025-08-25 22:52:08,576][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009280] [Batch 04411/04869] [00:51:48/00:05:22, 0.705s/it]: train_loss_raw=2.1196, running_loss=2.0791, LR=0.000100
[2025-08-25 22:52:13,981][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009288] [Batch 04419/04869] [00:51:53/00:05:17, 0.705s/it]: train_loss_raw=2.0497, running_loss=2.0778, LR=0.000100
[2025-08-25 22:52:19,450][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009296] [Batch 04427/04869] [00:51:59/00:05:11, 0.705s/it]: train_loss_raw=2.1098, running_loss=2.0770, LR=0.000100
[2025-08-25 22:52:24,801][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009304] [Batch 04435/04869] [00:52:04/00:05:05, 0.704s/it]: train_loss_raw=2.0667, running_loss=2.0785, LR=0.000100
[2025-08-25 22:52:30,421][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009312] [Batch 04443/04869] [00:52:09/00:05:00, 0.704s/it]: train_loss_raw=2.0340, running_loss=2.0773, LR=0.000100
[2025-08-25 22:52:36,090][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009320] [Batch 04451/04869] [00:52:15/00:04:54, 0.704s/it]: train_loss_raw=2.0516, running_loss=2.0784, LR=0.000100
[2025-08-25 22:52:41,380][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009328] [Batch 04459/04869] [00:52:20/00:04:48, 0.704s/it]: train_loss_raw=2.0686, running_loss=2.0790, LR=0.000100
[2025-08-25 22:52:47,159][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009336] [Batch 04467/04869] [00:52:26/00:04:43, 0.704s/it]: train_loss_raw=2.1018, running_loss=2.0801, LR=0.000100
[2025-08-25 22:52:52,455][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009344] [Batch 04475/04869] [00:52:32/00:04:37, 0.704s/it]: train_loss_raw=2.0226, running_loss=2.0773, LR=0.000100
[2025-08-25 22:52:57,811][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009352] [Batch 04483/04869] [00:52:37/00:04:31, 0.704s/it]: train_loss_raw=2.0409, running_loss=2.0780, LR=0.000100
[2025-08-25 22:53:03,407][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009360] [Batch 04491/04869] [00:52:42/00:04:26, 0.704s/it]: train_loss_raw=2.1107, running_loss=2.0793, LR=0.000100
[2025-08-25 22:53:09,450][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009368] [Batch 04499/04869] [00:52:49/00:04:20, 0.704s/it]: train_loss_raw=2.1922, running_loss=2.0808, LR=0.000100
[2025-08-25 22:53:15,664][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009376] [Batch 04507/04869] [00:52:55/00:04:15, 0.705s/it]: train_loss_raw=2.0563, running_loss=2.0781, LR=0.000100
[2025-08-25 22:53:20,830][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009384] [Batch 04515/04869] [00:53:00/00:04:09, 0.704s/it]: train_loss_raw=2.0266, running_loss=2.0764, LR=0.000100
[2025-08-25 22:53:26,007][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009392] [Batch 04523/04869] [00:53:05/00:04:03, 0.704s/it]: train_loss_raw=2.1054, running_loss=2.0769, LR=0.000100
[2025-08-25 22:53:31,261][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009400] [Batch 04531/04869] [00:53:10/00:03:58, 0.704s/it]: train_loss_raw=2.0146, running_loss=2.0760, LR=0.000100
[2025-08-25 22:53:36,577][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009408] [Batch 04539/04869] [00:53:16/00:03:52, 0.704s/it]: train_loss_raw=2.0331, running_loss=2.0772, LR=0.000100
[2025-08-25 22:53:41,769][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009416] [Batch 04547/04869] [00:53:21/00:03:46, 0.704s/it]: train_loss_raw=2.0150, running_loss=2.0772, LR=0.000100
[2025-08-25 22:53:46,967][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009424] [Batch 04555/04869] [00:53:26/00:03:41, 0.704s/it]: train_loss_raw=2.0943, running_loss=2.0761, LR=0.000100
[2025-08-25 22:53:52,597][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009432] [Batch 04563/04869] [00:53:32/00:03:35, 0.704s/it]: train_loss_raw=2.0637, running_loss=2.0744, LR=0.000100
[2025-08-25 22:53:57,799][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009440] [Batch 04571/04869] [00:53:37/00:03:29, 0.704s/it]: train_loss_raw=2.1527, running_loss=2.0790, LR=0.000100
[2025-08-25 22:54:03,429][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009448] [Batch 04579/04869] [00:53:42/00:03:24, 0.704s/it]: train_loss_raw=2.0445, running_loss=2.0762, LR=0.000100
[2025-08-25 22:54:08,809][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009456] [Batch 04587/04869] [00:53:48/00:03:18, 0.704s/it]: train_loss_raw=2.0888, running_loss=2.0776, LR=0.000100
