[2025-08-25 21:39:55,176][__main__][INFO] - Initializing training.
[2025-08-25 21:39:55,176][__main__][INFO] - Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
[2025-08-25 21:39:55,176][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-25 21:39:55,176][__main__][INFO] - CUDA version: 12.1
[2025-08-25 21:39:55,181][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/anno_mgf/3HCD_high.mgf
profiler: false
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: 600k_192BS
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 192
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
train_subset: 0.75
valid_subset_of_train: 0.01
valid_subset: 1
val_check_interval: 1.0
lazy_loading: true
max_shard_size: 1000000
preshuffle_shards: true
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
resume_checkpoint: null
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-25 21:39:55,186][__main__][INFO] - Starting transformer training
[2025-08-25 21:39:55,186][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-25 21:39:55,186][__main__][INFO] - Loading data
[2025-08-25 21:39:55,187][instanovo.utils.data_handler][INFO] - Loading file 001 of 001: /data/48/wuqian/Proteometools/part1/anno_mgf/3HCD_high.mgf
[2025-08-25 21:44:35,546][instanovo.utils.data_handler][INFO] - Saving temporary file to /tmp/tmpnkm4wa7z/temp_d780ab7ff7424d2fb8252b4ccb38d3b4.parquet
[2025-08-25 21:44:39,743][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-25 21:49:25,661][__main__][INFO] - Validation path not specified, generating from training set.
[2025-08-25 21:49:44,819][__main__][INFO] - Data splits saved to /data/48/wuqian/fast/TipsNovo/model_save/splits.csv
[2025-08-25 21:49:44,819][__main__][INFO] - Checking for unknown residues in 319,144 rows.
[2025-08-25 21:50:07,373][__main__][INFO] - Data loaded: 236,895 training samples; 3,271 validation samples
[2025-08-25 21:50:07,530][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-25 21:50:07,548][__main__][INFO] - No data leakage!
[2025-08-25 21:50:07,549][__main__][INFO] - Model checkpointing every 1.62 epochs.
[2025-08-25 21:50:07,549][__main__][INFO] - Updates per epoch: 1,234, step_scale=0.16666666666666666
[2025-08-25 21:50:19,496][__main__][INFO] - Sample batch:
[2025-08-25 21:50:19,496][__main__][INFO] -  - spectra.shape=torch.Size([192, 200, 2])
[2025-08-25 21:50:19,497][__main__][INFO] -  - precursors.shape=torch.Size([192, 3])
[2025-08-25 21:50:19,497][__main__][INFO] -  - spectra_mask.shape=torch.Size([192, 200])
[2025-08-25 21:50:19,497][__main__][INFO] -  - peptides.shape=torch.Size([192, 41])
[2025-08-25 21:50:19,497][__main__][INFO] -  - peptides_mask.shape=torch.Size([192, 41])
[2025-08-25 21:50:19,660][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-25 21:50:19,660][__main__][INFO] - Test forward pass:
[2025-08-25 21:50:29,922][__main__][INFO] -  - y.shape=torch.Size([192, 42, 33])
[2025-08-25 21:50:31,338][__main__][INFO] - Model saving enabled
[2025-08-25 21:50:31,339][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save/
[2025-08-25 21:50:31,339][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-25 21:50:31,351][__main__][INFO] - InstaNovo training started.
[2025-08-25 21:50:36,612][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-25 21:50:48,030][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 000001] [Batch 00007/00026] [00:00:11/00:00:25, 1.427s/it]
[2025-08-25 21:50:55,864][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000008] [Batch 00008/01234] [00:00:05/00:12:54, 0.632s/it]: train_loss_raw=3.4935, running_loss=3.5979, LR=0.000001
[2025-08-25 21:51:01,186][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000016] [Batch 00016/01234] [00:00:10/00:13:10, 0.649s/it]: train_loss_raw=3.2050, running_loss=3.5774, LR=0.000003
[2025-08-25 21:51:06,302][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/01234] [00:00:15/00:13:01, 0.646s/it]: train_loss_raw=3.0680, running_loss=3.5419, LR=0.000005
[2025-08-25 21:51:11,485][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000032] [Batch 00032/01234] [00:00:20/00:12:56, 0.646s/it]: train_loss_raw=2.9960, running_loss=3.5021, LR=0.000006
[2025-08-25 21:51:17,001][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000040] [Batch 00040/01234] [00:00:26/00:13:01, 0.655s/it]: train_loss_raw=2.9716, running_loss=3.4623, LR=0.000008
[2025-08-25 21:51:22,578][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/01234] [00:00:31/00:13:04, 0.662s/it]: train_loss_raw=2.9527, running_loss=3.4238, LR=0.000010
[2025-08-25 21:51:27,860][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000056] [Batch 00056/01234] [00:00:37/00:12:59, 0.662s/it]: train_loss_raw=2.9409, running_loss=3.3864, LR=0.000011
[2025-08-25 21:51:33,448][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000064] [Batch 00064/01234] [00:00:42/00:12:59, 0.666s/it]: train_loss_raw=2.8126, running_loss=3.3468, LR=0.000013
[2025-08-25 21:51:38,716][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/01234] [00:00:47/00:12:53, 0.665s/it]: train_loss_raw=2.7795, running_loss=3.3051, LR=0.000015
[2025-08-25 21:51:44,263][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000080] [Batch 00080/01234] [00:00:53/00:12:51, 0.668s/it]: train_loss_raw=2.7763, running_loss=3.2651, LR=0.000016
[2025-08-25 21:51:49,905][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000088] [Batch 00088/01234] [00:00:59/00:12:49, 0.672s/it]: train_loss_raw=2.7717, running_loss=3.2265, LR=0.000018
[2025-08-25 21:51:55,550][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/01234] [00:01:04/00:12:47, 0.674s/it]: train_loss_raw=2.7479, running_loss=3.1895, LR=0.000020
[2025-08-25 21:52:00,666][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000104] [Batch 00104/01234] [00:01:09/00:12:39, 0.672s/it]: train_loss_raw=2.7329, running_loss=3.1549, LR=0.000021
[2025-08-25 21:52:05,795][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000112] [Batch 00112/01234] [00:01:14/00:12:31, 0.670s/it]: train_loss_raw=2.7598, running_loss=3.1228, LR=0.000023
[2025-08-25 21:52:10,950][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/01234] [00:01:20/00:12:23, 0.668s/it]: train_loss_raw=2.7039, running_loss=3.0917, LR=0.000025
[2025-08-25 21:52:16,720][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000128] [Batch 00128/01234] [00:01:25/00:12:22, 0.671s/it]: train_loss_raw=2.7166, running_loss=3.0636, LR=0.000026
[2025-08-25 21:52:22,101][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000136] [Batch 00136/01234] [00:01:31/00:12:17, 0.671s/it]: train_loss_raw=2.7145, running_loss=3.0374, LR=0.000028
[2025-08-25 21:52:27,621][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/01234] [00:01:36/00:12:12, 0.672s/it]: train_loss_raw=2.7326, running_loss=3.0128, LR=0.000030
[2025-08-25 21:52:33,178][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000152] [Batch 00152/01234] [00:01:42/00:12:08, 0.673s/it]: train_loss_raw=2.6860, running_loss=2.9891, LR=0.000031
[2025-08-25 21:52:38,241][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000160] [Batch 00160/01234] [00:01:47/00:12:01, 0.671s/it]: train_loss_raw=2.7030, running_loss=2.9677, LR=0.000033
[2025-08-25 21:52:43,492][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/01234] [00:01:52/00:11:55, 0.671s/it]: train_loss_raw=2.7106, running_loss=2.9474, LR=0.000035
[2025-08-25 21:52:48,595][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000176] [Batch 00176/01234] [00:01:57/00:11:48, 0.669s/it]: train_loss_raw=2.7041, running_loss=2.9292, LR=0.000036
[2025-08-25 21:52:53,713][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000184] [Batch 00184/01234] [00:02:02/00:11:41, 0.668s/it]: train_loss_raw=2.7016, running_loss=2.9113, LR=0.000038
[2025-08-25 21:52:58,896][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/01234] [00:02:08/00:11:35, 0.667s/it]: train_loss_raw=2.6829, running_loss=2.8951, LR=0.000040
[2025-08-25 21:53:04,530][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000200] [Batch 00200/01234] [00:02:13/00:11:31, 0.669s/it]: train_loss_raw=2.7052, running_loss=2.8793, LR=0.000041
[2025-08-25 21:53:10,040][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000208] [Batch 00208/01234] [00:02:19/00:11:26, 0.669s/it]: train_loss_raw=2.6932, running_loss=2.8653, LR=0.000043
[2025-08-25 21:53:15,587][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/01234] [00:02:24/00:11:22, 0.670s/it]: train_loss_raw=2.6657, running_loss=2.8522, LR=0.000045
[2025-08-25 21:53:21,384][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000224] [Batch 00224/01234] [00:02:30/00:11:18, 0.672s/it]: train_loss_raw=2.6974, running_loss=2.8404, LR=0.000046
[2025-08-25 21:53:26,809][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000232] [Batch 00232/01234] [00:02:36/00:11:13, 0.672s/it]: train_loss_raw=2.6689, running_loss=2.8294, LR=0.000048
[2025-08-25 21:53:32,302][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/01234] [00:02:41/00:11:08, 0.673s/it]: train_loss_raw=2.7170, running_loss=2.8185, LR=0.000050
[2025-08-25 21:53:37,430][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000248] [Batch 00248/01234] [00:02:46/00:11:02, 0.672s/it]: train_loss_raw=2.6747, running_loss=2.8092, LR=0.000051
[2025-08-25 21:53:42,949][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000256] [Batch 00256/01234] [00:02:52/00:10:57, 0.672s/it]: train_loss_raw=2.7026, running_loss=2.8004, LR=0.000053
[2025-08-25 21:53:48,515][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/01234] [00:02:57/00:10:52, 0.673s/it]: train_loss_raw=2.6664, running_loss=2.7918, LR=0.000055
[2025-08-25 21:53:54,042][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000272] [Batch 00272/01234] [00:03:03/00:10:48, 0.674s/it]: train_loss_raw=2.6701, running_loss=2.7843, LR=0.000056
[2025-08-25 21:53:59,498][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000280] [Batch 00280/01234] [00:03:08/00:10:42, 0.674s/it]: train_loss_raw=2.6617, running_loss=2.7767, LR=0.000058
[2025-08-25 21:54:05,071][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/01234] [00:03:14/00:10:38, 0.675s/it]: train_loss_raw=2.6718, running_loss=2.7693, LR=0.000060
[2025-08-25 21:54:10,483][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000296] [Batch 00296/01234] [00:03:19/00:10:32, 0.675s/it]: train_loss_raw=2.6828, running_loss=2.7631, LR=0.000061
[2025-08-25 21:54:15,825][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000304] [Batch 00304/01234] [00:03:25/00:10:27, 0.674s/it]: train_loss_raw=2.6681, running_loss=2.7570, LR=0.000063
[2025-08-25 21:54:20,956][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/01234] [00:03:30/00:10:21, 0.674s/it]: train_loss_raw=2.6781, running_loss=2.7508, LR=0.000065
[2025-08-25 21:54:26,492][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000320] [Batch 00320/01234] [00:03:35/00:10:16, 0.674s/it]: train_loss_raw=2.6898, running_loss=2.7451, LR=0.000066
[2025-08-25 21:54:32,184][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000328] [Batch 00328/01234] [00:03:41/00:10:11, 0.675s/it]: train_loss_raw=2.6842, running_loss=2.7395, LR=0.000068
[2025-08-25 21:54:37,813][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/01234] [00:03:47/00:10:06, 0.676s/it]: train_loss_raw=2.6932, running_loss=2.7345, LR=0.000070
[2025-08-25 21:54:43,388][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000344] [Batch 00344/01234] [00:03:52/00:10:01, 0.676s/it]: train_loss_raw=2.6782, running_loss=2.7296, LR=0.000071
[2025-08-25 21:54:48,893][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000352] [Batch 00352/01234] [00:03:58/00:09:56, 0.676s/it]: train_loss_raw=2.6882, running_loss=2.7255, LR=0.000073
[2025-08-25 21:54:54,412][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/01234] [00:04:03/00:09:51, 0.677s/it]: train_loss_raw=2.6788, running_loss=2.7211, LR=0.000075
[2025-08-25 21:54:59,688][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000368] [Batch 00368/01234] [00:04:08/00:09:45, 0.676s/it]: train_loss_raw=2.6479, running_loss=2.7175, LR=0.000076
[2025-08-25 21:55:05,199][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000376] [Batch 00376/01234] [00:04:14/00:09:40, 0.677s/it]: train_loss_raw=2.6743, running_loss=2.7142, LR=0.000078
[2025-08-25 21:55:10,706][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/01234] [00:04:19/00:09:35, 0.677s/it]: train_loss_raw=2.6531, running_loss=2.7100, LR=0.000080
[2025-08-25 21:55:15,840][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000392] [Batch 00392/01234] [00:04:25/00:09:29, 0.676s/it]: train_loss_raw=2.6431, running_loss=2.7061, LR=0.000081
[2025-08-25 21:55:21,252][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000400] [Batch 00400/01234] [00:04:30/00:09:23, 0.676s/it]: train_loss_raw=2.6492, running_loss=2.7021, LR=0.000083
[2025-08-25 21:55:26,791][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/01234] [00:04:35/00:09:18, 0.676s/it]: train_loss_raw=2.6646, running_loss=2.6980, LR=0.000085
[2025-08-25 21:55:32,376][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000416] [Batch 00416/01234] [00:04:41/00:09:13, 0.677s/it]: train_loss_raw=2.6255, running_loss=2.6935, LR=0.000086
[2025-08-25 21:55:37,936][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000424] [Batch 00424/01234] [00:04:47/00:09:08, 0.677s/it]: train_loss_raw=2.6169, running_loss=2.6887, LR=0.000088
[2025-08-25 21:55:43,457][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/01234] [00:04:52/00:09:03, 0.677s/it]: train_loss_raw=2.6083, running_loss=2.6837, LR=0.000090
[2025-08-25 21:55:49,040][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000440] [Batch 00440/01234] [00:04:58/00:08:58, 0.678s/it]: train_loss_raw=2.6374, running_loss=2.6786, LR=0.000091
[2025-08-25 21:55:54,371][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000448] [Batch 00448/01234] [00:05:03/00:08:52, 0.678s/it]: train_loss_raw=2.6103, running_loss=2.6741, LR=0.000093
[2025-08-25 21:55:59,767][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/01234] [00:05:08/00:08:47, 0.678s/it]: train_loss_raw=2.5912, running_loss=2.6695, LR=0.000095
[2025-08-25 21:56:04,937][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000464] [Batch 00464/01234] [00:05:14/00:08:41, 0.677s/it]: train_loss_raw=2.6204, running_loss=2.6648, LR=0.000096
[2025-08-25 21:56:10,445][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000472] [Batch 00472/01234] [00:05:19/00:08:36, 0.677s/it]: train_loss_raw=2.6044, running_loss=2.6596, LR=0.000098
[2025-08-25 21:56:15,912][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/01234] [00:05:25/00:08:30, 0.677s/it]: train_loss_raw=2.5692, running_loss=2.6544, LR=0.000100
[2025-08-25 21:56:21,189][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000488] [Batch 00488/01234] [00:05:30/00:08:25, 0.677s/it]: train_loss_raw=2.5460, running_loss=2.6489, LR=0.000100
[2025-08-25 21:56:26,710][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000496] [Batch 00496/01234] [00:05:35/00:08:19, 0.677s/it]: train_loss_raw=2.5581, running_loss=2.6439, LR=0.000100
[2025-08-25 21:56:32,368][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/01234] [00:05:41/00:08:14, 0.678s/it]: train_loss_raw=2.6001, running_loss=2.6402, LR=0.000100
[2025-08-25 21:56:37,735][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000512] [Batch 00512/01234] [00:05:46/00:08:09, 0.678s/it]: train_loss_raw=2.5851, running_loss=2.6358, LR=0.000100
[2025-08-25 21:56:42,895][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000520] [Batch 00520/01234] [00:05:52/00:08:03, 0.677s/it]: train_loss_raw=2.6025, running_loss=2.6327, LR=0.000100
[2025-08-25 21:56:48,010][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/01234] [00:05:57/00:07:57, 0.677s/it]: train_loss_raw=2.5667, running_loss=2.6278, LR=0.000100
[2025-08-25 21:56:53,082][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000536] [Batch 00536/01234] [00:06:02/00:07:51, 0.676s/it]: train_loss_raw=2.5865, running_loss=2.6232, LR=0.000100
[2025-08-25 21:56:58,213][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000544] [Batch 00544/01234] [00:06:07/00:07:46, 0.675s/it]: train_loss_raw=2.5397, running_loss=2.6187, LR=0.000100
[2025-08-25 21:57:03,318][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/01234] [00:06:12/00:07:40, 0.675s/it]: train_loss_raw=2.5436, running_loss=2.6144, LR=0.000100
[2025-08-25 21:57:08,811][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000560] [Batch 00560/01234] [00:06:18/00:07:34, 0.675s/it]: train_loss_raw=2.5746, running_loss=2.6104, LR=0.000100
[2025-08-25 21:57:14,772][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000568] [Batch 00568/01234] [00:06:23/00:07:30, 0.676s/it]: train_loss_raw=2.5744, running_loss=2.6069, LR=0.000100
[2025-08-25 21:57:20,237][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/01234] [00:06:29/00:07:24, 0.676s/it]: train_loss_raw=2.5661, running_loss=2.6034, LR=0.000100
[2025-08-25 21:57:25,706][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000584] [Batch 00584/01234] [00:06:34/00:07:19, 0.676s/it]: train_loss_raw=2.5110, running_loss=2.5992, LR=0.000100
[2025-08-25 21:57:31,293][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000592] [Batch 00592/01234] [00:06:40/00:07:14, 0.676s/it]: train_loss_raw=2.5369, running_loss=2.5937, LR=0.000100
[2025-08-25 21:57:36,846][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/01234] [00:06:46/00:07:09, 0.677s/it]: train_loss_raw=2.5420, running_loss=2.5908, LR=0.000100
[2025-08-25 21:57:42,409][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000608] [Batch 00608/01234] [00:06:51/00:07:03, 0.677s/it]: train_loss_raw=2.5381, running_loss=2.5858, LR=0.000100
[2025-08-25 21:57:48,040][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000616] [Batch 00616/01234] [00:06:57/00:06:58, 0.677s/it]: train_loss_raw=2.4961, running_loss=2.5807, LR=0.000100
[2025-08-25 21:57:53,579][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/01234] [00:07:02/00:06:53, 0.678s/it]: train_loss_raw=2.5249, running_loss=2.5755, LR=0.000100
[2025-08-25 21:57:58,900][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000632] [Batch 00632/01234] [00:07:08/00:06:47, 0.677s/it]: train_loss_raw=2.5371, running_loss=2.5709, LR=0.000100
[2025-08-25 21:58:04,050][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000640] [Batch 00640/01234] [00:07:13/00:06:42, 0.677s/it]: train_loss_raw=2.5150, running_loss=2.5682, LR=0.000100
[2025-08-25 21:58:09,440][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/01234] [00:07:18/00:06:36, 0.677s/it]: train_loss_raw=2.4597, running_loss=2.5619, LR=0.000100
[2025-08-25 21:58:14,985][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000656] [Batch 00656/01234] [00:07:24/00:06:31, 0.677s/it]: train_loss_raw=2.5029, running_loss=2.5567, LR=0.000100
[2025-08-25 21:58:20,526][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000664] [Batch 00664/01234] [00:07:29/00:06:26, 0.677s/it]: train_loss_raw=2.5083, running_loss=2.5526, LR=0.000100
[2025-08-25 21:58:26,080][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/01234] [00:07:35/00:06:20, 0.677s/it]: train_loss_raw=2.4768, running_loss=2.5488, LR=0.000100
[2025-08-25 21:58:31,657][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000680] [Batch 00680/01234] [00:07:40/00:06:15, 0.678s/it]: train_loss_raw=2.4485, running_loss=2.5439, LR=0.000100
[2025-08-25 21:58:37,178][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000688] [Batch 00688/01234] [00:07:46/00:06:10, 0.678s/it]: train_loss_raw=2.4706, running_loss=2.5398, LR=0.000100
[2025-08-25 21:58:42,680][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/01234] [00:07:51/00:06:04, 0.678s/it]: train_loss_raw=2.5002, running_loss=2.5360, LR=0.000100
[2025-08-25 21:58:48,307][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000704] [Batch 00704/01234] [00:07:57/00:05:59, 0.678s/it]: train_loss_raw=2.5339, running_loss=2.5330, LR=0.000100
[2025-08-25 21:58:53,674][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000712] [Batch 00712/01234] [00:08:02/00:05:54, 0.678s/it]: train_loss_raw=2.5227, running_loss=2.5311, LR=0.000100
[2025-08-25 21:58:59,322][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/01234] [00:08:08/00:05:48, 0.678s/it]: train_loss_raw=2.5051, running_loss=2.5269, LR=0.000100
[2025-08-25 21:59:04,902][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000728] [Batch 00728/01234] [00:08:14/00:05:43, 0.679s/it]: train_loss_raw=2.4085, running_loss=2.5228, LR=0.000100
[2025-08-25 21:59:10,400][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000736] [Batch 00736/01234] [00:08:19/00:05:38, 0.679s/it]: train_loss_raw=2.5013, running_loss=2.5199, LR=0.000100
[2025-08-25 21:59:15,943][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/01234] [00:08:25/00:05:32, 0.679s/it]: train_loss_raw=2.4258, running_loss=2.5172, LR=0.000100
[2025-08-25 21:59:21,594][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000752] [Batch 00752/01234] [00:08:30/00:05:27, 0.679s/it]: train_loss_raw=2.4662, running_loss=2.5134, LR=0.000100
[2025-08-25 21:59:27,183][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000760] [Batch 00760/01234] [00:08:36/00:05:22, 0.679s/it]: train_loss_raw=2.5049, running_loss=2.5091, LR=0.000100
[2025-08-25 21:59:32,752][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/01234] [00:08:41/00:05:16, 0.680s/it]: train_loss_raw=2.5326, running_loss=2.5063, LR=0.000100
[2025-08-25 21:59:38,346][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000776] [Batch 00776/01234] [00:08:47/00:05:11, 0.680s/it]: train_loss_raw=2.4331, running_loss=2.5033, LR=0.000100
[2025-08-25 21:59:44,247][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000784] [Batch 00784/01234] [00:08:53/00:05:06, 0.680s/it]: train_loss_raw=2.4117, running_loss=2.5007, LR=0.000100
[2025-08-25 21:59:49,939][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/01234] [00:08:59/00:05:00, 0.681s/it]: train_loss_raw=2.4851, running_loss=2.4992, LR=0.000100
[2025-08-25 21:59:55,567][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000800] [Batch 00800/01234] [00:09:04/00:04:55, 0.681s/it]: train_loss_raw=2.4852, running_loss=2.4953, LR=0.000100
[2025-08-25 22:00:00,945][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000808] [Batch 00808/01234] [00:09:10/00:04:50, 0.681s/it]: train_loss_raw=2.4643, running_loss=2.4919, LR=0.000100
[2025-08-25 22:00:06,069][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/01234] [00:09:15/00:04:44, 0.680s/it]: train_loss_raw=2.3972, running_loss=2.4874, LR=0.000100
[2025-08-25 22:00:11,392][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000824] [Batch 00824/01234] [00:09:20/00:04:38, 0.680s/it]: train_loss_raw=2.3608, running_loss=2.4822, LR=0.000100
[2025-08-25 22:00:16,956][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000832] [Batch 00832/01234] [00:09:26/00:04:33, 0.680s/it]: train_loss_raw=2.4368, running_loss=2.4790, LR=0.000100
[2025-08-25 22:00:22,515][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000840] [Batch 00840/01234] [00:09:31/00:04:28, 0.681s/it]: train_loss_raw=2.4576, running_loss=2.4750, LR=0.000100
[2025-08-25 22:00:28,225][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000848] [Batch 00848/01234] [00:09:37/00:04:22, 0.681s/it]: train_loss_raw=2.3817, running_loss=2.4712, LR=0.000100
[2025-08-25 22:00:33,729][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000856] [Batch 00856/01234] [00:09:42/00:04:17, 0.681s/it]: train_loss_raw=2.3486, running_loss=2.4675, LR=0.000100
[2025-08-25 22:00:39,217][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000864] [Batch 00864/01234] [00:09:48/00:04:11, 0.681s/it]: train_loss_raw=2.4330, running_loss=2.4644, LR=0.000100
[2025-08-25 22:00:44,343][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000872] [Batch 00872/01234] [00:09:53/00:04:06, 0.681s/it]: train_loss_raw=2.3988, running_loss=2.4607, LR=0.000100
[2025-08-25 22:00:49,611][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000880] [Batch 00880/01234] [00:09:58/00:04:00, 0.680s/it]: train_loss_raw=2.4480, running_loss=2.4583, LR=0.000100
[2025-08-25 22:00:55,450][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000888] [Batch 00888/01234] [00:10:04/00:03:55, 0.681s/it]: train_loss_raw=2.3897, running_loss=2.4559, LR=0.000100
[2025-08-25 22:01:00,860][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000896] [Batch 00896/01234] [00:10:10/00:03:50, 0.681s/it]: train_loss_raw=2.4048, running_loss=2.4536, LR=0.000100
[2025-08-25 22:01:06,143][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000904] [Batch 00904/01234] [00:10:15/00:03:44, 0.681s/it]: train_loss_raw=2.4294, running_loss=2.4516, LR=0.000100
[2025-08-25 22:01:11,493][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000912] [Batch 00912/01234] [00:10:20/00:03:39, 0.681s/it]: train_loss_raw=2.3902, running_loss=2.4489, LR=0.000100
[2025-08-25 22:01:16,579][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000920] [Batch 00920/01234] [00:10:25/00:03:33, 0.680s/it]: train_loss_raw=2.4100, running_loss=2.4464, LR=0.000100
[2025-08-25 22:01:21,677][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000928] [Batch 00928/01234] [00:10:30/00:03:28, 0.680s/it]: train_loss_raw=2.4043, running_loss=2.4439, LR=0.000100
[2025-08-25 22:01:26,755][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000936] [Batch 00936/01234] [00:10:35/00:03:22, 0.679s/it]: train_loss_raw=2.3784, running_loss=2.4396, LR=0.000100
[2025-08-25 22:01:31,966][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000944] [Batch 00944/01234] [00:10:41/00:03:16, 0.679s/it]: train_loss_raw=2.4260, running_loss=2.4365, LR=0.000100
[2025-08-25 22:01:37,495][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000952] [Batch 00952/01234] [00:10:46/00:03:11, 0.679s/it]: train_loss_raw=2.4274, running_loss=2.4316, LR=0.000100
[2025-08-25 22:01:42,834][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000960] [Batch 00960/01234] [00:10:52/00:03:06, 0.679s/it]: train_loss_raw=2.4206, running_loss=2.4279, LR=0.000100
[2025-08-25 22:01:48,082][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000968] [Batch 00968/01234] [00:10:57/00:03:00, 0.679s/it]: train_loss_raw=2.4495, running_loss=2.4235, LR=0.000100
[2025-08-25 22:01:53,585][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000976] [Batch 00976/01234] [00:11:02/00:02:55, 0.679s/it]: train_loss_raw=2.3648, running_loss=2.4213, LR=0.000100
[2025-08-25 22:01:59,026][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000984] [Batch 00984/01234] [00:11:08/00:02:49, 0.679s/it]: train_loss_raw=2.4065, running_loss=2.4176, LR=0.000100
[2025-08-25 22:02:04,192][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000992] [Batch 00992/01234] [00:11:13/00:02:44, 0.679s/it]: train_loss_raw=2.4061, running_loss=2.4155, LR=0.000100
[2025-08-25 22:02:09,750][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001000] [Batch 01000/01234] [00:11:18/00:02:38, 0.679s/it]: train_loss_raw=2.3512, running_loss=2.4128, LR=0.000100
[2025-08-25 22:02:15,223][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001008] [Batch 01008/01234] [00:11:24/00:02:33, 0.679s/it]: train_loss_raw=2.4191, running_loss=2.4089, LR=0.000100
[2025-08-25 22:02:20,291][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001016] [Batch 01016/01234] [00:11:29/00:02:27, 0.679s/it]: train_loss_raw=2.4466, running_loss=2.4062, LR=0.000100
[2025-08-25 22:02:25,355][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001024] [Batch 01024/01234] [00:11:34/00:02:22, 0.678s/it]: train_loss_raw=2.3505, running_loss=2.4040, LR=0.000100
[2025-08-25 22:02:30,463][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001032] [Batch 01032/01234] [00:11:39/00:02:16, 0.678s/it]: train_loss_raw=2.3381, running_loss=2.4004, LR=0.000100
[2025-08-25 22:02:35,579][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001040] [Batch 01040/01234] [00:11:44/00:02:11, 0.678s/it]: train_loss_raw=2.3527, running_loss=2.3981, LR=0.000100
[2025-08-25 22:02:40,643][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001048] [Batch 01048/01234] [00:11:49/00:02:05, 0.677s/it]: train_loss_raw=2.3874, running_loss=2.3963, LR=0.000100
[2025-08-25 22:02:45,715][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001056] [Batch 01056/01234] [00:11:54/00:02:00, 0.677s/it]: train_loss_raw=2.3765, running_loss=2.3929, LR=0.000100
[2025-08-25 22:02:50,823][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001064] [Batch 01064/01234] [00:12:00/00:01:55, 0.677s/it]: train_loss_raw=2.3321, running_loss=2.3907, LR=0.000100
[2025-08-25 22:02:55,910][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001072] [Batch 01072/01234] [00:12:05/00:01:49, 0.676s/it]: train_loss_raw=2.4561, running_loss=2.3898, LR=0.000100
[2025-08-25 22:03:00,990][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001080] [Batch 01080/01234] [00:12:10/00:01:44, 0.676s/it]: train_loss_raw=2.3193, running_loss=2.3872, LR=0.000100
[2025-08-25 22:03:06,078][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001088] [Batch 01088/01234] [00:12:15/00:01:38, 0.676s/it]: train_loss_raw=2.3189, running_loss=2.3845, LR=0.000100
[2025-08-25 22:03:11,152][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001096] [Batch 01096/01234] [00:12:20/00:01:33, 0.675s/it]: train_loss_raw=2.3719, running_loss=2.3834, LR=0.000100
[2025-08-25 22:03:16,216][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001104] [Batch 01104/01234] [00:12:25/00:01:27, 0.675s/it]: train_loss_raw=2.3211, running_loss=2.3825, LR=0.000100
[2025-08-25 22:03:21,277][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001112] [Batch 01112/01234] [00:12:30/00:01:22, 0.675s/it]: train_loss_raw=2.3546, running_loss=2.3814, LR=0.000100
[2025-08-25 22:03:26,360][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001120] [Batch 01120/01234] [00:12:35/00:01:16, 0.675s/it]: train_loss_raw=2.3805, running_loss=2.3771, LR=0.000100
[2025-08-25 22:03:31,450][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001128] [Batch 01128/01234] [00:12:40/00:01:11, 0.674s/it]: train_loss_raw=2.3749, running_loss=2.3739, LR=0.000100
[2025-08-25 22:03:36,530][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001136] [Batch 01136/01234] [00:12:45/00:01:06, 0.674s/it]: train_loss_raw=2.3565, running_loss=2.3695, LR=0.000100
[2025-08-25 22:03:41,690][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001144] [Batch 01144/01234] [00:12:50/00:01:00, 0.674s/it]: train_loss_raw=2.3570, running_loss=2.3675, LR=0.000100
[2025-08-25 22:03:46,969][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001152] [Batch 01152/01234] [00:12:56/00:00:55, 0.674s/it]: train_loss_raw=2.3538, running_loss=2.3636, LR=0.000100
[2025-08-25 22:03:52,520][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001160] [Batch 01160/01234] [00:13:01/00:00:49, 0.674s/it]: train_loss_raw=2.3783, running_loss=2.3629, LR=0.000100
[2025-08-25 22:03:57,671][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001168] [Batch 01168/01234] [00:13:06/00:00:44, 0.674s/it]: train_loss_raw=2.3752, running_loss=2.3604, LR=0.000100
[2025-08-25 22:04:02,839][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001176] [Batch 01176/01234] [00:13:12/00:00:39, 0.673s/it]: train_loss_raw=2.3997, running_loss=2.3608, LR=0.000100
[2025-08-25 22:04:08,198][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001184] [Batch 01184/01234] [00:13:17/00:00:33, 0.673s/it]: train_loss_raw=2.2694, running_loss=2.3582, LR=0.000100
[2025-08-25 22:04:13,303][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001192] [Batch 01192/01234] [00:13:22/00:00:28, 0.673s/it]: train_loss_raw=2.3920, running_loss=2.3575, LR=0.000100
[2025-08-25 22:04:18,418][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001200] [Batch 01200/01234] [00:13:27/00:00:22, 0.673s/it]: train_loss_raw=2.3581, running_loss=2.3576, LR=0.000100
[2025-08-25 22:04:23,508][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001208] [Batch 01208/01234] [00:13:32/00:00:17, 0.673s/it]: train_loss_raw=2.2987, running_loss=2.3559, LR=0.000100
[2025-08-25 22:04:28,920][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001216] [Batch 01216/01234] [00:13:38/00:00:12, 0.673s/it]: train_loss_raw=2.3426, running_loss=2.3562, LR=0.000100
[2025-08-25 22:04:34,451][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001224] [Batch 01224/01234] [00:13:43/00:00:06, 0.673s/it]: train_loss_raw=2.3469, running_loss=2.3557, LR=0.000100
[2025-08-25 22:04:39,800][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001232] [Batch 01232/01234] [00:13:48/00:00:01, 0.673s/it]: train_loss_raw=2.3724, running_loss=2.3545, LR=0.000100
[2025-08-25 22:04:45,962][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-25 22:04:53,559][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 001235] [Batch 00015/00026] [00:00:07/00:00:04, 0.475s/it]
[2025-08-25 22:05:03,957][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 001235] [Batch 00023/00026] [00:00:17/00:00:01, 0.750s/it]
[2025-08-25 22:05:14,333][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 001235] [Batch 00005/00026] [00:00:28/00:01:34, 4.729s/it]
[2025-08-25 22:05:19,304][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=2.35414, valid_loss=2.38776
[2025-08-25 22:05:19,304][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-25 22:05:19,304][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.875
[2025-08-25 22:05:19,304][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.019
[2025-08-25 22:05:19,304][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.020
[2025-08-25 22:05:19,304][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.000
[2025-08-25 22:05:19,306][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:14:28, remaining time 06:59:46, 00:14:28 per epoch
[2025-08-25 22:05:22,836][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001240] [Batch 00006/01234] [00:00:03/00:11:30, 0.563s/it]: train_loss_raw=2.3348, running_loss=2.3497, LR=0.000100
[2025-08-25 22:05:28,053][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001248] [Batch 00014/01234] [00:00:08/00:12:28, 0.614s/it]: train_loss_raw=2.2976, running_loss=2.3471, LR=0.000100
[2025-08-25 22:05:33,278][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001256] [Batch 00022/01234] [00:00:13/00:12:41, 0.628s/it]: train_loss_raw=2.3415, running_loss=2.3442, LR=0.000100
[2025-08-25 22:05:38,771][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001264] [Batch 00030/01234] [00:00:19/00:12:55, 0.644s/it]: train_loss_raw=2.3213, running_loss=2.3436, LR=0.000100
[2025-08-25 22:05:44,277][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001272] [Batch 00038/01234] [00:00:24/00:13:01, 0.653s/it]: train_loss_raw=2.3006, running_loss=2.3414, LR=0.000100
[2025-08-25 22:05:49,841][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001280] [Batch 00046/01234] [00:00:30/00:13:04, 0.660s/it]: train_loss_raw=2.2967, running_loss=2.3374, LR=0.000100
[2025-08-25 22:05:55,183][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001288] [Batch 00054/01234] [00:00:35/00:13:00, 0.662s/it]: train_loss_raw=2.3209, running_loss=2.3369, LR=0.000100
[2025-08-25 22:06:00,512][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001296] [Batch 00062/01234] [00:00:41/00:12:56, 0.662s/it]: train_loss_raw=2.3046, running_loss=2.3352, LR=0.000100
[2025-08-25 22:06:05,838][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001304] [Batch 00070/01234] [00:00:46/00:12:51, 0.663s/it]: train_loss_raw=2.2964, running_loss=2.3324, LR=0.000100
[2025-08-25 22:06:11,438][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001312] [Batch 00078/01234] [00:00:51/00:12:50, 0.666s/it]: train_loss_raw=2.3119, running_loss=2.3322, LR=0.000100
[2025-08-25 22:06:16,735][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001320] [Batch 00086/01234] [00:00:57/00:12:44, 0.666s/it]: train_loss_raw=2.3137, running_loss=2.3291, LR=0.000100
[2025-08-25 22:06:22,155][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001328] [Batch 00094/01234] [00:01:02/00:12:40, 0.667s/it]: train_loss_raw=2.2689, running_loss=2.3279, LR=0.000100
[2025-08-25 22:06:27,730][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001336] [Batch 00102/01234] [00:01:08/00:12:37, 0.669s/it]: train_loss_raw=2.3469, running_loss=2.3263, LR=0.000100
[2025-08-25 22:06:33,312][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001344] [Batch 00110/01234] [00:01:13/00:12:34, 0.671s/it]: train_loss_raw=2.2594, running_loss=2.3244, LR=0.000100
[2025-08-25 22:06:38,726][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001352] [Batch 00118/01234] [00:01:19/00:12:29, 0.672s/it]: train_loss_raw=2.2356, running_loss=2.3224, LR=0.000100
[2025-08-25 22:06:43,933][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001360] [Batch 00126/01234] [00:01:24/00:12:22, 0.670s/it]: train_loss_raw=2.3121, running_loss=2.3192, LR=0.000100
[2025-08-25 22:06:49,227][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001368] [Batch 00134/01234] [00:01:29/00:12:16, 0.670s/it]: train_loss_raw=2.2882, running_loss=2.3183, LR=0.000100
[2025-08-25 22:06:54,460][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001376] [Batch 00142/01234] [00:01:35/00:12:10, 0.669s/it]: train_loss_raw=2.2432, running_loss=2.3144, LR=0.000100
[2025-08-25 22:06:59,884][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001384] [Batch 00150/01234] [00:01:40/00:12:05, 0.669s/it]: train_loss_raw=2.2913, running_loss=2.3131, LR=0.000100
[2025-08-25 22:07:05,205][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001392] [Batch 00158/01234] [00:01:45/00:12:00, 0.669s/it]: train_loss_raw=2.2629, running_loss=2.3109, LR=0.000100
[2025-08-25 22:07:10,735][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001400] [Batch 00166/01234] [00:01:51/00:11:55, 0.670s/it]: train_loss_raw=2.3623, running_loss=2.3103, LR=0.000100
[2025-08-25 22:07:15,846][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001408] [Batch 00174/01234] [00:01:56/00:11:49, 0.669s/it]: train_loss_raw=2.2748, running_loss=2.3111, LR=0.000100
[2025-08-25 22:07:21,272][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001416] [Batch 00182/01234] [00:02:01/00:11:44, 0.669s/it]: train_loss_raw=2.2448, running_loss=2.3079, LR=0.000100
[2025-08-25 22:07:26,778][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001424] [Batch 00190/01234] [00:02:07/00:11:39, 0.670s/it]: train_loss_raw=2.3132, running_loss=2.3083, LR=0.000100
[2025-08-25 22:07:32,194][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001432] [Batch 00198/01234] [00:02:12/00:11:34, 0.670s/it]: train_loss_raw=2.1924, running_loss=2.3055, LR=0.000100
[2025-08-25 22:07:37,674][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001440] [Batch 00206/01234] [00:02:18/00:11:29, 0.671s/it]: train_loss_raw=2.2825, running_loss=2.3070, LR=0.000100
[2025-08-25 22:07:43,222][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001448] [Batch 00214/01234] [00:02:23/00:11:25, 0.672s/it]: train_loss_raw=2.2210, running_loss=2.3061, LR=0.000100
[2025-08-25 22:07:48,723][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001456] [Batch 00222/01234] [00:02:29/00:11:20, 0.672s/it]: train_loss_raw=2.2921, running_loss=2.3054, LR=0.000100
[2025-08-25 22:07:54,100][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001464] [Batch 00230/01234] [00:02:34/00:11:15, 0.672s/it]: train_loss_raw=2.2957, running_loss=2.3059, LR=0.000100
[2025-08-25 22:07:59,316][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001472] [Batch 00238/01234] [00:02:39/00:11:08, 0.672s/it]: train_loss_raw=2.2403, running_loss=2.3060, LR=0.000100
[2025-08-25 22:08:04,474][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001480] [Batch 00246/01234] [00:02:45/00:11:02, 0.671s/it]: train_loss_raw=2.2905, running_loss=2.3035, LR=0.000100
[2025-08-25 22:08:10,088][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001488] [Batch 00254/01234] [00:02:50/00:10:58, 0.672s/it]: train_loss_raw=2.2770, running_loss=2.3023, LR=0.000100
[2025-08-25 22:08:15,594][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001496] [Batch 00262/01234] [00:02:56/00:10:53, 0.672s/it]: train_loss_raw=2.1704, running_loss=2.2992, LR=0.000100
[2025-08-25 22:08:20,943][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001504] [Batch 00270/01234] [00:03:01/00:10:47, 0.672s/it]: train_loss_raw=2.2823, running_loss=2.2969, LR=0.000100
[2025-08-25 22:08:26,017][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001512] [Batch 00278/01234] [00:03:06/00:10:41, 0.671s/it]: train_loss_raw=2.2985, running_loss=2.2975, LR=0.000100
[2025-08-25 22:08:31,520][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001520] [Batch 00286/01234] [00:03:12/00:10:36, 0.672s/it]: train_loss_raw=2.2932, running_loss=2.2961, LR=0.000100
[2025-08-25 22:08:36,745][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001528] [Batch 00294/01234] [00:03:17/00:10:30, 0.671s/it]: train_loss_raw=2.3773, running_loss=2.2964, LR=0.000100
[2025-08-25 22:08:41,850][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001536] [Batch 00302/01234] [00:03:22/00:10:24, 0.670s/it]: train_loss_raw=2.2217, running_loss=2.2934, LR=0.000100
[2025-08-25 22:08:47,062][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001544] [Batch 00310/01234] [00:03:27/00:10:18, 0.670s/it]: train_loss_raw=2.2091, running_loss=2.2902, LR=0.000100
[2025-08-25 22:08:52,266][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001552] [Batch 00318/01234] [00:03:32/00:10:12, 0.669s/it]: train_loss_raw=2.2362, running_loss=2.2875, LR=0.000100
[2025-08-25 22:08:57,505][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001560] [Batch 00326/01234] [00:03:38/00:10:07, 0.669s/it]: train_loss_raw=2.3129, running_loss=2.2868, LR=0.000100
[2025-08-25 22:09:02,776][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001568] [Batch 00334/01234] [00:03:43/00:10:01, 0.669s/it]: train_loss_raw=2.2422, running_loss=2.2860, LR=0.000100
[2025-08-25 22:09:08,341][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001576] [Batch 00342/01234] [00:03:48/00:09:56, 0.669s/it]: train_loss_raw=2.2413, running_loss=2.2839, LR=0.000100
[2025-08-25 22:09:13,446][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001584] [Batch 00350/01234] [00:03:53/00:09:50, 0.669s/it]: train_loss_raw=2.3282, running_loss=2.2828, LR=0.000100
[2025-08-25 22:09:18,812][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001592] [Batch 00358/01234] [00:03:59/00:09:45, 0.669s/it]: train_loss_raw=2.2738, running_loss=2.2829, LR=0.000100
[2025-08-25 22:09:24,197][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001600] [Batch 00366/01234] [00:04:04/00:09:40, 0.669s/it]: train_loss_raw=2.2870, running_loss=2.2816, LR=0.000100
[2025-08-25 22:09:29,728][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001608] [Batch 00374/01234] [00:04:10/00:09:35, 0.669s/it]: train_loss_raw=2.3150, running_loss=2.2795, LR=0.000100
[2025-08-25 22:09:35,065][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001616] [Batch 00382/01234] [00:04:15/00:09:30, 0.669s/it]: train_loss_raw=2.2610, running_loss=2.2793, LR=0.000100
[2025-08-25 22:09:40,797][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001624] [Batch 00390/01234] [00:04:21/00:09:25, 0.670s/it]: train_loss_raw=2.2820, running_loss=2.2785, LR=0.000100
[2025-08-25 22:09:46,274][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001632] [Batch 00398/01234] [00:04:26/00:09:20, 0.670s/it]: train_loss_raw=2.2900, running_loss=2.2778, LR=0.000100
[2025-08-25 22:09:51,603][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001640] [Batch 00406/01234] [00:04:32/00:09:15, 0.670s/it]: train_loss_raw=2.2474, running_loss=2.2752, LR=0.000100
[2025-08-25 22:09:56,918][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001648] [Batch 00414/01234] [00:04:37/00:09:09, 0.670s/it]: train_loss_raw=2.2328, running_loss=2.2735, LR=0.000100
[2025-08-25 22:10:02,655][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001656] [Batch 00422/01234] [00:04:43/00:09:04, 0.671s/it]: train_loss_raw=2.2375, running_loss=2.2708, LR=0.000100
[2025-08-25 22:10:08,531][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001664] [Batch 00430/01234] [00:04:49/00:09:00, 0.672s/it]: train_loss_raw=2.2398, running_loss=2.2699, LR=0.000100
[2025-08-25 22:10:14,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001672] [Batch 00438/01234] [00:04:54/00:08:55, 0.673s/it]: train_loss_raw=2.2354, running_loss=2.2676, LR=0.000100
[2025-08-25 22:10:19,831][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001680] [Batch 00446/01234] [00:05:00/00:08:50, 0.673s/it]: train_loss_raw=2.2544, running_loss=2.2651, LR=0.000100
[2025-08-25 22:10:25,250][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001688] [Batch 00454/01234] [00:05:05/00:08:45, 0.674s/it]: train_loss_raw=2.1780, running_loss=2.2630, LR=0.000100
[2025-08-25 22:10:30,903][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001696] [Batch 00462/01234] [00:05:11/00:08:40, 0.674s/it]: train_loss_raw=2.2488, running_loss=2.2625, LR=0.000100
[2025-08-25 22:10:36,593][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001704] [Batch 00470/01234] [00:05:17/00:08:35, 0.675s/it]: train_loss_raw=2.2415, running_loss=2.2619, LR=0.000100
[2025-08-25 22:10:42,375][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001712] [Batch 00478/01234] [00:05:22/00:08:30, 0.676s/it]: train_loss_raw=2.1556, running_loss=2.2605, LR=0.000100
[2025-08-25 22:10:47,927][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001720] [Batch 00486/01234] [00:05:28/00:08:25, 0.676s/it]: train_loss_raw=2.1836, running_loss=2.2588, LR=0.000100
[2025-08-25 22:10:53,387][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001728] [Batch 00494/01234] [00:05:33/00:08:20, 0.676s/it]: train_loss_raw=2.2324, running_loss=2.2571, LR=0.000100
[2025-08-25 22:10:59,030][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001736] [Batch 00502/01234] [00:05:39/00:08:15, 0.676s/it]: train_loss_raw=2.1931, running_loss=2.2568, LR=0.000100
[2025-08-25 22:11:04,791][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001744] [Batch 00510/01234] [00:05:45/00:08:10, 0.677s/it]: train_loss_raw=2.2883, running_loss=2.2562, LR=0.000100
[2025-08-25 22:11:10,378][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001752] [Batch 00518/01234] [00:05:50/00:08:05, 0.677s/it]: train_loss_raw=2.2097, running_loss=2.2547, LR=0.000100
[2025-08-25 22:11:16,026][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001760] [Batch 00526/01234] [00:05:56/00:07:59, 0.678s/it]: train_loss_raw=2.2609, running_loss=2.2552, LR=0.000100
[2025-08-25 22:11:21,595][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001768] [Batch 00534/01234] [00:06:02/00:07:54, 0.678s/it]: train_loss_raw=2.2793, running_loss=2.2543, LR=0.000100
[2025-08-25 22:11:27,356][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001776] [Batch 00542/01234] [00:06:07/00:07:49, 0.679s/it]: train_loss_raw=2.1736, running_loss=2.2540, LR=0.000100
[2025-08-25 22:11:32,772][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001784] [Batch 00550/01234] [00:06:13/00:07:44, 0.679s/it]: train_loss_raw=2.2667, running_loss=2.2525, LR=0.000100
[2025-08-25 22:11:37,922][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001792] [Batch 00558/01234] [00:06:18/00:07:38, 0.678s/it]: train_loss_raw=2.2643, running_loss=2.2519, LR=0.000100
[2025-08-25 22:11:43,075][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001800] [Batch 00566/01234] [00:06:23/00:07:32, 0.678s/it]: train_loss_raw=2.2560, running_loss=2.2507, LR=0.000100
[2025-08-25 22:11:48,343][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001808] [Batch 00574/01234] [00:06:28/00:07:27, 0.677s/it]: train_loss_raw=2.2731, running_loss=2.2492, LR=0.000100
[2025-08-25 22:11:53,921][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001816] [Batch 00582/01234] [00:06:34/00:07:21, 0.678s/it]: train_loss_raw=2.2563, running_loss=2.2477, LR=0.000100
[2025-08-25 22:11:59,493][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001824] [Batch 00590/01234] [00:06:40/00:07:16, 0.678s/it]: train_loss_raw=2.2922, running_loss=2.2489, LR=0.000100
[2025-08-25 22:12:04,811][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001832] [Batch 00598/01234] [00:06:45/00:07:11, 0.678s/it]: train_loss_raw=2.2557, running_loss=2.2488, LR=0.000100
[2025-08-25 22:12:10,012][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001840] [Batch 00606/01234] [00:06:50/00:07:05, 0.677s/it]: train_loss_raw=2.2033, running_loss=2.2466, LR=0.000100
[2025-08-25 22:12:15,126][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001848] [Batch 00614/01234] [00:06:55/00:06:59, 0.677s/it]: train_loss_raw=2.1862, running_loss=2.2453, LR=0.000100
[2025-08-25 22:12:20,244][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001856] [Batch 00622/01234] [00:07:00/00:06:54, 0.677s/it]: train_loss_raw=2.2375, running_loss=2.2420, LR=0.000100
[2025-08-25 22:12:25,760][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001864] [Batch 00630/01234] [00:07:06/00:06:48, 0.677s/it]: train_loss_raw=2.1864, running_loss=2.2405, LR=0.000100
[2025-08-25 22:12:31,459][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001872] [Batch 00638/01234] [00:07:11/00:06:43, 0.677s/it]: train_loss_raw=2.1715, running_loss=2.2376, LR=0.000100
[2025-08-25 22:12:37,385][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001880] [Batch 00646/01234] [00:07:17/00:06:38, 0.678s/it]: train_loss_raw=2.2584, running_loss=2.2348, LR=0.000100
[2025-08-25 22:12:43,043][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001888] [Batch 00654/01234] [00:07:23/00:06:33, 0.678s/it]: train_loss_raw=2.2354, running_loss=2.2340, LR=0.000100
[2025-08-25 22:12:48,743][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001896] [Batch 00662/01234] [00:07:29/00:06:28, 0.679s/it]: train_loss_raw=2.2952, running_loss=2.2341, LR=0.000100
[2025-08-25 22:12:54,510][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001904] [Batch 00670/01234] [00:07:35/00:06:23, 0.679s/it]: train_loss_raw=2.1619, running_loss=2.2322, LR=0.000100
[2025-08-25 22:13:00,239][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001912] [Batch 00678/01234] [00:07:40/00:06:17, 0.680s/it]: train_loss_raw=2.2715, running_loss=2.2313, LR=0.000100
[2025-08-25 22:13:06,005][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001920] [Batch 00686/01234] [00:07:46/00:06:12, 0.680s/it]: train_loss_raw=2.2046, running_loss=2.2272, LR=0.000100
[2025-08-25 22:13:11,542][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001928] [Batch 00694/01234] [00:07:52/00:06:07, 0.680s/it]: train_loss_raw=2.1275, running_loss=2.2260, LR=0.000100
[2025-08-25 22:13:17,307][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001936] [Batch 00702/01234] [00:07:57/00:06:02, 0.681s/it]: train_loss_raw=2.2159, running_loss=2.2240, LR=0.000100
[2025-08-25 22:13:22,896][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001944] [Batch 00710/01234] [00:08:03/00:05:56, 0.681s/it]: train_loss_raw=2.1973, running_loss=2.2226, LR=0.000100
[2025-08-25 22:13:28,538][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001952] [Batch 00718/01234] [00:08:09/00:05:51, 0.681s/it]: train_loss_raw=2.2006, running_loss=2.2206, LR=0.000100
[2025-08-25 22:13:34,199][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001960] [Batch 00726/01234] [00:08:14/00:05:46, 0.681s/it]: train_loss_raw=2.2330, running_loss=2.2204, LR=0.000100
[2025-08-25 22:13:39,965][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001968] [Batch 00734/01234] [00:08:20/00:05:40, 0.682s/it]: train_loss_raw=2.1485, running_loss=2.2197, LR=0.000100
[2025-08-25 22:13:45,468][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001976] [Batch 00742/01234] [00:08:26/00:05:35, 0.682s/it]: train_loss_raw=2.1334, running_loss=2.2167, LR=0.000100
[2025-08-25 22:13:50,819][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001984] [Batch 00750/01234] [00:08:31/00:05:29, 0.682s/it]: train_loss_raw=2.1919, running_loss=2.2168, LR=0.000100
[2025-08-25 22:13:56,105][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001992] [Batch 00758/01234] [00:08:36/00:05:24, 0.682s/it]: train_loss_raw=2.1988, running_loss=2.2148, LR=0.000100
[2025-08-25 22:14:01,794][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002000] [Batch 00766/01234] [00:08:42/00:05:19, 0.682s/it]: train_loss_raw=2.1704, running_loss=2.2129, LR=0.000100
[2025-08-25 22:14:11,429][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002008] [Batch 00774/01234] [00:08:51/00:05:16, 0.687s/it]: train_loss_raw=2.2636, running_loss=2.2115, LR=0.000100
[2025-08-25 22:14:16,611][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002016] [Batch 00782/01234] [00:08:57/00:05:10, 0.687s/it]: train_loss_raw=2.1192, running_loss=2.2069, LR=0.000100
[2025-08-25 22:14:21,804][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002024] [Batch 00790/01234] [00:09:02/00:05:04, 0.687s/it]: train_loss_raw=2.2058, running_loss=2.2060, LR=0.000100
[2025-08-25 22:14:26,981][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002032] [Batch 00798/01234] [00:09:07/00:04:59, 0.686s/it]: train_loss_raw=2.2364, running_loss=2.2064, LR=0.000100
[2025-08-25 22:14:32,521][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002040] [Batch 00806/01234] [00:09:13/00:04:53, 0.686s/it]: train_loss_raw=2.1459, running_loss=2.2035, LR=0.000100
[2025-08-25 22:14:38,116][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002048] [Batch 00814/01234] [00:09:18/00:04:48, 0.686s/it]: train_loss_raw=2.2642, running_loss=2.2032, LR=0.000100
[2025-08-25 22:14:43,274][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002056] [Batch 00822/01234] [00:09:23/00:04:42, 0.686s/it]: train_loss_raw=2.1997, running_loss=2.2026, LR=0.000100
[2025-08-25 22:14:48,694][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002064] [Batch 00830/01234] [00:09:29/00:04:37, 0.686s/it]: train_loss_raw=2.2411, running_loss=2.2010, LR=0.000100
[2025-08-25 22:14:54,406][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002072] [Batch 00838/01234] [00:09:34/00:04:31, 0.686s/it]: train_loss_raw=2.1441, running_loss=2.1983, LR=0.000100
[2025-08-25 22:15:00,183][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002080] [Batch 00846/01234] [00:09:40/00:04:26, 0.686s/it]: train_loss_raw=2.1403, running_loss=2.1946, LR=0.000100
[2025-08-25 22:15:05,430][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002088] [Batch 00854/01234] [00:09:45/00:04:20, 0.686s/it]: train_loss_raw=2.1068, running_loss=2.1930, LR=0.000100
[2025-08-25 22:15:10,864][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002096] [Batch 00862/01234] [00:09:51/00:04:15, 0.686s/it]: train_loss_raw=2.1807, running_loss=2.1919, LR=0.000100
[2025-08-25 22:15:16,406][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002104] [Batch 00870/01234] [00:09:56/00:04:09, 0.686s/it]: train_loss_raw=2.1497, running_loss=2.1915, LR=0.000100
[2025-08-25 22:15:22,061][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002112] [Batch 00878/01234] [00:10:02/00:04:04, 0.686s/it]: train_loss_raw=2.1679, running_loss=2.1887, LR=0.000100
[2025-08-25 22:15:27,773][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002120] [Batch 00886/01234] [00:10:08/00:03:58, 0.687s/it]: train_loss_raw=2.2199, running_loss=2.1877, LR=0.000100
[2025-08-25 22:15:33,133][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002128] [Batch 00894/01234] [00:10:13/00:03:53, 0.686s/it]: train_loss_raw=2.1617, running_loss=2.1852, LR=0.000100
[2025-08-25 22:15:38,404][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002136] [Batch 00902/01234] [00:10:18/00:03:47, 0.686s/it]: train_loss_raw=2.0530, running_loss=2.1827, LR=0.000100
[2025-08-25 22:15:44,139][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002144] [Batch 00910/01234] [00:10:24/00:03:42, 0.686s/it]: train_loss_raw=2.2443, running_loss=2.1795, LR=0.000100
[2025-08-25 22:15:49,534][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002152] [Batch 00918/01234] [00:10:30/00:03:36, 0.686s/it]: train_loss_raw=2.2323, running_loss=2.1803, LR=0.000100
[2025-08-25 22:15:54,934][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002160] [Batch 00926/01234] [00:10:35/00:03:31, 0.686s/it]: train_loss_raw=2.2553, running_loss=2.1813, LR=0.000100
[2025-08-25 22:16:00,579][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002168] [Batch 00934/01234] [00:10:41/00:03:25, 0.686s/it]: train_loss_raw=2.1469, running_loss=2.1783, LR=0.000100
[2025-08-25 22:16:05,715][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002176] [Batch 00942/01234] [00:10:46/00:03:20, 0.686s/it]: train_loss_raw=2.1430, running_loss=2.1752, LR=0.000100
[2025-08-25 22:16:11,139][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002184] [Batch 00950/01234] [00:10:51/00:03:14, 0.686s/it]: train_loss_raw=2.1889, running_loss=2.1737, LR=0.000100
[2025-08-25 22:16:16,483][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002192] [Batch 00958/01234] [00:10:57/00:03:09, 0.686s/it]: train_loss_raw=2.2592, running_loss=2.1737, LR=0.000100
[2025-08-25 22:16:21,793][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002200] [Batch 00966/01234] [00:11:02/00:03:03, 0.686s/it]: train_loss_raw=2.1668, running_loss=2.1707, LR=0.000100
[2025-08-25 22:16:27,543][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002208] [Batch 00974/01234] [00:11:08/00:02:58, 0.686s/it]: train_loss_raw=2.1773, running_loss=2.1712, LR=0.000100
[2025-08-25 22:16:32,661][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002216] [Batch 00982/01234] [00:11:13/00:02:52, 0.686s/it]: train_loss_raw=2.1188, running_loss=2.1705, LR=0.000100
[2025-08-25 22:16:38,277][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002224] [Batch 00990/01234] [00:11:18/00:02:47, 0.686s/it]: train_loss_raw=2.1299, running_loss=2.1696, LR=0.000100
[2025-08-25 22:16:43,602][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002232] [Batch 00998/01234] [00:11:24/00:02:41, 0.686s/it]: train_loss_raw=2.1242, running_loss=2.1691, LR=0.000100
[2025-08-25 22:16:48,745][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002240] [Batch 01006/01234] [00:11:29/00:02:36, 0.685s/it]: train_loss_raw=2.1591, running_loss=2.1698, LR=0.000100
[2025-08-25 22:16:53,938][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002248] [Batch 01014/01234] [00:11:34/00:02:30, 0.685s/it]: train_loss_raw=2.2474, running_loss=2.1677, LR=0.000100
[2025-08-25 22:16:59,690][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002256] [Batch 01022/01234] [00:11:40/00:02:25, 0.685s/it]: train_loss_raw=2.1810, running_loss=2.1683, LR=0.000100
[2025-08-25 22:17:05,161][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002264] [Batch 01030/01234] [00:11:45/00:02:19, 0.685s/it]: train_loss_raw=2.0834, running_loss=2.1659, LR=0.000100
[2025-08-25 22:17:10,246][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002272] [Batch 01038/01234] [00:11:50/00:02:14, 0.685s/it]: train_loss_raw=2.0773, running_loss=2.1627, LR=0.000100
[2025-08-25 22:17:15,340][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002280] [Batch 01046/01234] [00:11:55/00:02:08, 0.684s/it]: train_loss_raw=2.1739, running_loss=2.1617, LR=0.000100
[2025-08-25 22:17:20,834][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002288] [Batch 01054/01234] [00:12:01/00:02:03, 0.684s/it]: train_loss_raw=2.1882, running_loss=2.1613, LR=0.000100
[2025-08-25 22:17:25,936][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002296] [Batch 01062/01234] [00:12:06/00:01:57, 0.684s/it]: train_loss_raw=2.1493, running_loss=2.1612, LR=0.000100
[2025-08-25 22:17:31,623][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002304] [Batch 01070/01234] [00:12:12/00:01:52, 0.684s/it]: train_loss_raw=2.1922, running_loss=2.1614, LR=0.000100
[2025-08-25 22:17:37,382][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002312] [Batch 01078/01234] [00:12:17/00:01:46, 0.685s/it]: train_loss_raw=2.1421, running_loss=2.1614, LR=0.000100
[2025-08-25 22:17:42,692][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002320] [Batch 01086/01234] [00:12:23/00:01:41, 0.684s/it]: train_loss_raw=2.1545, running_loss=2.1626, LR=0.000100
[2025-08-25 22:17:48,183][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002328] [Batch 01094/01234] [00:12:28/00:01:35, 0.684s/it]: train_loss_raw=2.1305, running_loss=2.1614, LR=0.000100
[2025-08-25 22:17:53,511][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002336] [Batch 01102/01234] [00:12:34/00:01:30, 0.684s/it]: train_loss_raw=2.2121, running_loss=2.1615, LR=0.000100
[2025-08-25 22:17:59,021][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002344] [Batch 01110/01234] [00:12:39/00:01:24, 0.684s/it]: train_loss_raw=2.1599, running_loss=2.1612, LR=0.000100
[2025-08-25 22:18:04,223][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002352] [Batch 01118/01234] [00:12:44/00:01:19, 0.684s/it]: train_loss_raw=2.0691, running_loss=2.1583, LR=0.000100
[2025-08-25 22:18:09,402][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002360] [Batch 01126/01234] [00:12:49/00:01:13, 0.684s/it]: train_loss_raw=2.1384, running_loss=2.1589, LR=0.000100
[2025-08-25 22:18:14,603][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002368] [Batch 01134/01234] [00:12:55/00:01:08, 0.684s/it]: train_loss_raw=2.2459, running_loss=2.1588, LR=0.000100
[2025-08-25 22:18:20,135][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002376] [Batch 01142/01234] [00:13:00/00:01:02, 0.684s/it]: train_loss_raw=2.1547, running_loss=2.1596, LR=0.000100
[2025-08-25 22:18:25,752][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002384] [Batch 01150/01234] [00:13:06/00:00:57, 0.684s/it]: train_loss_raw=2.1312, running_loss=2.1571, LR=0.000100
[2025-08-25 22:18:30,933][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002392] [Batch 01158/01234] [00:13:11/00:00:51, 0.683s/it]: train_loss_raw=2.1202, running_loss=2.1522, LR=0.000100
[2025-08-25 22:18:36,771][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002400] [Batch 01166/01234] [00:13:17/00:00:46, 0.684s/it]: train_loss_raw=2.1148, running_loss=2.1510, LR=0.000100
[2025-08-25 22:18:41,962][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002408] [Batch 01174/01234] [00:13:22/00:00:41, 0.684s/it]: train_loss_raw=2.1529, running_loss=2.1496, LR=0.000100
[2025-08-25 22:18:47,330][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002416] [Batch 01182/01234] [00:13:27/00:00:35, 0.683s/it]: train_loss_raw=2.1733, running_loss=2.1482, LR=0.000100
[2025-08-25 22:18:52,548][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002424] [Batch 01190/01234] [00:13:33/00:00:30, 0.683s/it]: train_loss_raw=2.1350, running_loss=2.1497, LR=0.000100
[2025-08-25 22:18:57,910][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002432] [Batch 01198/01234] [00:13:38/00:00:24, 0.683s/it]: train_loss_raw=2.0548, running_loss=2.1473, LR=0.000100
[2025-08-25 22:19:03,106][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002440] [Batch 01206/01234] [00:13:43/00:00:19, 0.683s/it]: train_loss_raw=2.0963, running_loss=2.1448, LR=0.000100
[2025-08-25 22:19:08,569][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002448] [Batch 01214/01234] [00:13:49/00:00:13, 0.683s/it]: train_loss_raw=2.1424, running_loss=2.1442, LR=0.000100
[2025-08-25 22:19:14,231][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002456] [Batch 01222/01234] [00:13:54/00:00:08, 0.683s/it]: train_loss_raw=2.0800, running_loss=2.1425, LR=0.000100
[2025-08-25 22:19:20,064][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 002464] [Batch 01230/01234] [00:14:00/00:00:02, 0.683s/it]: train_loss_raw=2.1507, running_loss=2.1407, LR=0.000100
[2025-08-25 22:19:28,179][__main__][INFO] - [VALIDATION] [Epoch 01/29] Starting validation.
[2025-08-25 22:19:38,311][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 002469] [Batch 00007/00026] [00:00:10/00:00:22, 1.266s/it]
[2025-08-25 22:19:48,987][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 002469] [Batch 00015/00026] [00:00:20/00:00:13, 1.300s/it]
[2025-08-25 22:20:00,026][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 002469] [Batch 00023/00026] [00:00:31/00:00:02, 1.327s/it]
[2025-08-25 22:20:02,321][__main__][INFO] - [VALIDATION] [Epoch 01/29] train_loss=2.14008, valid_loss=2.13411
[2025-08-25 22:20:02,322][__main__][INFO] - [VALIDATION] [Epoch 01/29] Metrics:
[2025-08-25 22:20:02,322][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_er      0.840
[2025-08-25 22:20:02,322][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_prec    0.020
[2025-08-25 22:20:02,322][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_recall  0.021
[2025-08-25 22:20:02,322][__main__][INFO] - [VALIDATION] [Epoch 01/29] - pep_recall 0.000
[2025-08-25 22:20:02,323][__main__][INFO] - [TRAIN] [Epoch 01/29] Epoch complete, total time 00:29:11, remaining time 06:48:41, 00:14:35 per epoch
[2025-08-25 22:20:04,540][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002472] [Batch 00004/01234] [00:00:02/00:10:37, 0.518s/it]: train_loss_raw=2.1091, running_loss=2.0735, LR=0.000100
[2025-08-25 22:20:10,020][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002480] [Batch 00012/01234] [00:00:07/00:12:49, 0.629s/it]: train_loss_raw=2.0538, running_loss=2.0766, LR=0.000100
[2025-08-25 22:20:15,697][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002488] [Batch 00020/01234] [00:00:13/00:13:23, 0.661s/it]: train_loss_raw=2.1689, running_loss=2.0790, LR=0.000100
[2025-08-25 22:20:20,896][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002496] [Batch 00028/01234] [00:00:18/00:13:13, 0.658s/it]: train_loss_raw=2.1227, running_loss=2.0822, LR=0.000100
[2025-08-25 22:20:26,536][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002504] [Batch 00036/01234] [00:00:24/00:13:20, 0.669s/it]: train_loss_raw=2.1142, running_loss=2.0842, LR=0.000100
[2025-08-25 22:20:31,719][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002512] [Batch 00044/01234] [00:00:29/00:13:11, 0.665s/it]: train_loss_raw=2.0771, running_loss=2.0839, LR=0.000100
[2025-08-25 22:20:37,358][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002520] [Batch 00052/01234] [00:00:34/00:13:13, 0.671s/it]: train_loss_raw=2.1408, running_loss=2.0865, LR=0.000100
[2025-08-25 22:20:43,020][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002528] [Batch 00060/01234] [00:00:40/00:13:13, 0.676s/it]: train_loss_raw=2.0487, running_loss=2.0880, LR=0.000100
[2025-08-25 22:20:48,271][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002536] [Batch 00068/01234] [00:00:45/00:13:05, 0.674s/it]: train_loss_raw=2.1170, running_loss=2.0915, LR=0.000100
[2025-08-25 22:20:53,659][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002544] [Batch 00076/01234] [00:00:51/00:12:59, 0.674s/it]: train_loss_raw=2.1975, running_loss=2.0932, LR=0.000100
[2025-08-25 22:20:59,389][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002552] [Batch 00084/01234] [00:00:56/00:12:59, 0.678s/it]: train_loss_raw=2.1150, running_loss=2.0946, LR=0.000100
[2025-08-25 22:21:05,039][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002560] [Batch 00092/01234] [00:01:02/00:12:56, 0.680s/it]: train_loss_raw=2.1063, running_loss=2.0953, LR=0.000100
[2025-08-25 22:21:10,149][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002568] [Batch 00100/01234] [00:01:07/00:12:47, 0.677s/it]: train_loss_raw=2.0883, running_loss=2.0942, LR=0.000100
[2025-08-25 22:21:15,282][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002576] [Batch 00108/01234] [00:01:12/00:12:39, 0.674s/it]: train_loss_raw=2.0673, running_loss=2.0937, LR=0.000100
[2025-08-25 22:21:20,434][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002584] [Batch 00116/01234] [00:01:17/00:12:31, 0.672s/it]: train_loss_raw=2.0764, running_loss=2.0948, LR=0.000100
[2025-08-25 22:21:25,675][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002592] [Batch 00124/01234] [00:01:23/00:12:24, 0.671s/it]: train_loss_raw=2.0560, running_loss=2.0937, LR=0.000100
[2025-08-25 22:21:30,844][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002600] [Batch 00132/01234] [00:01:28/00:12:17, 0.670s/it]: train_loss_raw=2.1153, running_loss=2.0947, LR=0.000100
[2025-08-25 22:21:35,992][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002608] [Batch 00140/01234] [00:01:33/00:12:10, 0.668s/it]: train_loss_raw=2.0988, running_loss=2.0934, LR=0.000100
[2025-08-25 22:21:41,718][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002616] [Batch 00148/01234] [00:01:39/00:12:08, 0.671s/it]: train_loss_raw=2.1661, running_loss=2.0934, LR=0.000100
[2025-08-25 22:21:47,204][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002624] [Batch 00156/01234] [00:01:44/00:12:03, 0.671s/it]: train_loss_raw=2.0661, running_loss=2.0925, LR=0.000100
[2025-08-25 22:21:52,777][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002632] [Batch 00164/01234] [00:01:50/00:11:59, 0.673s/it]: train_loss_raw=2.0584, running_loss=2.0914, LR=0.000100
[2025-08-25 22:21:58,849][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002640] [Batch 00172/01234] [00:01:56/00:11:58, 0.677s/it]: train_loss_raw=2.1221, running_loss=2.0920, LR=0.000100
[2025-08-25 22:22:04,337][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002648] [Batch 00180/01234] [00:02:01/00:11:53, 0.677s/it]: train_loss_raw=2.0871, running_loss=2.0935, LR=0.000100
[2025-08-25 22:22:09,591][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002656] [Batch 00188/01234] [00:02:07/00:11:47, 0.676s/it]: train_loss_raw=2.1210, running_loss=2.0917, LR=0.000100
[2025-08-25 22:22:14,643][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002664] [Batch 00196/01234] [00:02:12/00:11:39, 0.674s/it]: train_loss_raw=2.1440, running_loss=2.0932, LR=0.000100
[2025-08-25 22:22:19,728][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002672] [Batch 00204/01234] [00:02:17/00:11:33, 0.673s/it]: train_loss_raw=2.1333, running_loss=2.0940, LR=0.000100
[2025-08-25 22:22:24,760][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002680] [Batch 00212/01234] [00:02:22/00:11:25, 0.671s/it]: train_loss_raw=2.1569, running_loss=2.0941, LR=0.000100
[2025-08-25 22:22:29,806][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002688] [Batch 00220/01234] [00:02:27/00:11:19, 0.670s/it]: train_loss_raw=2.0143, running_loss=2.0917, LR=0.000100
[2025-08-25 22:22:35,150][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002696] [Batch 00228/01234] [00:02:32/00:11:13, 0.670s/it]: train_loss_raw=2.1430, running_loss=2.0932, LR=0.000100
[2025-08-25 22:22:40,506][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002704] [Batch 00236/01234] [00:02:38/00:11:08, 0.670s/it]: train_loss_raw=2.1383, running_loss=2.0922, LR=0.000100
[2025-08-25 22:22:46,119][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002712] [Batch 00244/01234] [00:02:43/00:11:03, 0.671s/it]: train_loss_raw=2.0730, running_loss=2.0914, LR=0.000100
[2025-08-25 22:22:51,539][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002720] [Batch 00252/01234] [00:02:49/00:10:58, 0.671s/it]: train_loss_raw=2.0663, running_loss=2.0892, LR=0.000100
[2025-08-25 22:22:56,628][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002728] [Batch 00260/01234] [00:02:54/00:10:52, 0.670s/it]: train_loss_raw=1.9757, running_loss=2.0865, LR=0.000100
[2025-08-25 22:23:02,229][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002736] [Batch 00268/01234] [00:02:59/00:10:47, 0.671s/it]: train_loss_raw=2.1271, running_loss=2.0864, LR=0.000100
[2025-08-25 22:23:07,349][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002744] [Batch 00276/01234] [00:03:04/00:10:41, 0.670s/it]: train_loss_raw=2.0907, running_loss=2.0872, LR=0.000100
[2025-08-25 22:23:12,977][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002752] [Batch 00284/01234] [00:03:10/00:10:37, 0.671s/it]: train_loss_raw=1.9923, running_loss=2.0840, LR=0.000100
[2025-08-25 22:23:18,444][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002760] [Batch 00292/01234] [00:03:15/00:10:32, 0.671s/it]: train_loss_raw=2.0310, running_loss=2.0821, LR=0.000100
[2025-08-25 22:23:24,416][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002768] [Batch 00300/01234] [00:03:21/00:10:28, 0.673s/it]: train_loss_raw=2.0181, running_loss=2.0815, LR=0.000100
[2025-08-25 22:23:29,839][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002776] [Batch 00308/01234] [00:03:27/00:10:23, 0.673s/it]: train_loss_raw=2.1606, running_loss=2.0826, LR=0.000100
[2025-08-25 22:23:35,296][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002784] [Batch 00316/01234] [00:03:32/00:10:18, 0.674s/it]: train_loss_raw=2.1003, running_loss=2.0827, LR=0.000100
[2025-08-25 22:23:40,889][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002792] [Batch 00324/01234] [00:03:38/00:10:13, 0.674s/it]: train_loss_raw=2.1236, running_loss=2.0824, LR=0.000100
[2025-08-25 22:23:45,984][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002800] [Batch 00332/01234] [00:03:43/00:10:07, 0.673s/it]: train_loss_raw=1.9940, running_loss=2.0807, LR=0.000100
[2025-08-25 22:23:51,142][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002808] [Batch 00340/01234] [00:03:48/00:10:01, 0.673s/it]: train_loss_raw=2.0202, running_loss=2.0777, LR=0.000100
[2025-08-25 22:23:57,264][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002816] [Batch 00348/01234] [00:03:54/00:09:57, 0.675s/it]: train_loss_raw=2.0602, running_loss=2.0758, LR=0.000100
[2025-08-25 22:24:02,531][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002824] [Batch 00356/01234] [00:04:00/00:09:52, 0.674s/it]: train_loss_raw=2.1088, running_loss=2.0759, LR=0.000100
[2025-08-25 22:24:07,929][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002832] [Batch 00364/01234] [00:04:05/00:09:46, 0.674s/it]: train_loss_raw=1.9453, running_loss=2.0753, LR=0.000100
[2025-08-25 22:24:13,584][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002840] [Batch 00372/01234] [00:04:11/00:09:41, 0.675s/it]: train_loss_raw=2.0779, running_loss=2.0762, LR=0.000100
[2025-08-25 22:24:19,412][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002848] [Batch 00380/01234] [00:04:16/00:09:37, 0.676s/it]: train_loss_raw=2.0206, running_loss=2.0745, LR=0.000100
[2025-08-25 22:24:24,780][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002856] [Batch 00388/01234] [00:04:22/00:09:31, 0.676s/it]: train_loss_raw=2.0507, running_loss=2.0726, LR=0.000100
[2025-08-25 22:24:29,848][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002864] [Batch 00396/01234] [00:04:27/00:09:25, 0.675s/it]: train_loss_raw=2.0396, running_loss=2.0706, LR=0.000100
[2025-08-25 22:24:35,231][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002872] [Batch 00404/01234] [00:04:32/00:09:20, 0.675s/it]: train_loss_raw=2.0618, running_loss=2.0709, LR=0.000100
[2025-08-25 22:24:40,484][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002880] [Batch 00412/01234] [00:04:38/00:09:14, 0.675s/it]: train_loss_raw=2.0528, running_loss=2.0700, LR=0.000100
[2025-08-25 22:24:45,521][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002888] [Batch 00420/01234] [00:04:43/00:09:08, 0.674s/it]: train_loss_raw=2.0999, running_loss=2.0713, LR=0.000100
[2025-08-25 22:24:50,556][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002896] [Batch 00428/01234] [00:04:48/00:09:02, 0.673s/it]: train_loss_raw=2.1099, running_loss=2.0697, LR=0.000100
[2025-08-25 22:24:55,595][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002904] [Batch 00436/01234] [00:04:53/00:08:56, 0.672s/it]: train_loss_raw=1.9022, running_loss=2.0678, LR=0.000100
[2025-08-25 22:25:00,847][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002912] [Batch 00444/01234] [00:04:58/00:08:50, 0.672s/it]: train_loss_raw=2.1720, running_loss=2.0670, LR=0.000100
[2025-08-25 22:25:06,867][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002920] [Batch 00452/01234] [00:05:04/00:08:46, 0.673s/it]: train_loss_raw=2.1283, running_loss=2.0656, LR=0.000100
[2025-08-25 22:25:12,188][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002928] [Batch 00460/01234] [00:05:09/00:08:41, 0.673s/it]: train_loss_raw=2.0197, running_loss=2.0645, LR=0.000100
[2025-08-25 22:25:17,262][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002936] [Batch 00468/01234] [00:05:14/00:08:35, 0.673s/it]: train_loss_raw=2.0353, running_loss=2.0631, LR=0.000100
[2025-08-25 22:25:22,728][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002944] [Batch 00476/01234] [00:05:20/00:08:29, 0.673s/it]: train_loss_raw=2.0888, running_loss=2.0619, LR=0.000100
[2025-08-25 22:25:28,061][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002952] [Batch 00484/01234] [00:05:25/00:08:24, 0.673s/it]: train_loss_raw=2.0638, running_loss=2.0617, LR=0.000100
[2025-08-25 22:25:33,379][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002960] [Batch 00492/01234] [00:05:30/00:08:19, 0.673s/it]: train_loss_raw=2.0506, running_loss=2.0614, LR=0.000100
[2025-08-25 22:25:38,517][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002968] [Batch 00500/01234] [00:05:36/00:08:13, 0.672s/it]: train_loss_raw=2.0632, running_loss=2.0615, LR=0.000100
[2025-08-25 22:25:43,669][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002976] [Batch 00508/01234] [00:05:41/00:08:07, 0.672s/it]: train_loss_raw=2.0823, running_loss=2.0617, LR=0.000100
[2025-08-25 22:25:49,619][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002984] [Batch 00516/01234] [00:05:47/00:08:03, 0.673s/it]: train_loss_raw=2.0711, running_loss=2.0596, LR=0.000100
[2025-08-25 22:25:55,147][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002992] [Batch 00524/01234] [00:05:52/00:07:57, 0.673s/it]: train_loss_raw=2.0788, running_loss=2.0584, LR=0.000100
[2025-08-25 22:26:00,828][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003000] [Batch 00532/01234] [00:05:58/00:07:52, 0.674s/it]: train_loss_raw=2.0196, running_loss=2.0570, LR=0.000100
[2025-08-25 22:26:05,866][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003008] [Batch 00540/01234] [00:06:03/00:07:47, 0.673s/it]: train_loss_raw=2.0414, running_loss=2.0560, LR=0.000100
[2025-08-25 22:26:10,887][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003016] [Batch 00548/01234] [00:06:08/00:07:41, 0.672s/it]: train_loss_raw=2.0441, running_loss=2.0532, LR=0.000100
[2025-08-25 22:26:15,936][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003024] [Batch 00556/01234] [00:06:13/00:07:35, 0.672s/it]: train_loss_raw=2.0163, running_loss=2.0514, LR=0.000100
[2025-08-25 22:26:21,026][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003032] [Batch 00564/01234] [00:06:18/00:07:29, 0.671s/it]: train_loss_raw=2.0296, running_loss=2.0521, LR=0.000100
[2025-08-25 22:26:26,061][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003040] [Batch 00572/01234] [00:06:23/00:07:23, 0.671s/it]: train_loss_raw=2.1175, running_loss=2.0524, LR=0.000100
[2025-08-25 22:26:31,417][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003048] [Batch 00580/01234] [00:06:28/00:07:18, 0.671s/it]: train_loss_raw=2.0657, running_loss=2.0513, LR=0.000100
[2025-08-25 22:26:36,712][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003056] [Batch 00588/01234] [00:06:34/00:07:13, 0.670s/it]: train_loss_raw=2.0275, running_loss=2.0503, LR=0.000100
[2025-08-25 22:26:42,532][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003064] [Batch 00596/01234] [00:06:40/00:07:08, 0.671s/it]: train_loss_raw=2.0554, running_loss=2.0482, LR=0.000100
[2025-08-25 22:26:48,407][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003072] [Batch 00604/01234] [00:06:45/00:07:03, 0.672s/it]: train_loss_raw=2.0773, running_loss=2.0479, LR=0.000100
[2025-08-25 22:26:54,316][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003080] [Batch 00612/01234] [00:06:51/00:06:58, 0.673s/it]: train_loss_raw=2.0209, running_loss=2.0480, LR=0.000100
[2025-08-25 22:27:00,152][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003088] [Batch 00620/01234] [00:06:57/00:06:53, 0.674s/it]: train_loss_raw=2.0138, running_loss=2.0459, LR=0.000100
[2025-08-25 22:27:05,867][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003096] [Batch 00628/01234] [00:07:03/00:06:48, 0.674s/it]: train_loss_raw=1.9732, running_loss=2.0452, LR=0.000100
[2025-08-25 22:27:11,620][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003104] [Batch 00636/01234] [00:07:09/00:06:43, 0.675s/it]: train_loss_raw=2.0196, running_loss=2.0445, LR=0.000100
[2025-08-25 22:27:16,860][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003112] [Batch 00644/01234] [00:07:14/00:06:37, 0.675s/it]: train_loss_raw=2.0152, running_loss=2.0436, LR=0.000100
[2025-08-25 22:27:21,914][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003120] [Batch 00652/01234] [00:07:19/00:06:32, 0.674s/it]: train_loss_raw=1.9833, running_loss=2.0395, LR=0.000100
[2025-08-25 22:27:26,974][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003128] [Batch 00660/01234] [00:07:24/00:06:26, 0.673s/it]: train_loss_raw=2.0485, running_loss=2.0398, LR=0.000100
[2025-08-25 22:27:32,060][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003136] [Batch 00668/01234] [00:07:29/00:06:20, 0.673s/it]: train_loss_raw=2.0410, running_loss=2.0379, LR=0.000100
[2025-08-25 22:27:37,460][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003144] [Batch 00676/01234] [00:07:34/00:06:15, 0.673s/it]: train_loss_raw=2.0507, running_loss=2.0378, LR=0.000100
[2025-08-25 22:27:43,297][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003152] [Batch 00684/01234] [00:07:40/00:06:10, 0.674s/it]: train_loss_raw=2.0426, running_loss=2.0377, LR=0.000100
[2025-08-25 22:27:48,670][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003160] [Batch 00692/01234] [00:07:46/00:06:05, 0.674s/it]: train_loss_raw=2.0365, running_loss=2.0376, LR=0.000100
[2025-08-25 22:27:53,713][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003168] [Batch 00700/01234] [00:07:51/00:05:59, 0.673s/it]: train_loss_raw=2.0164, running_loss=2.0357, LR=0.000100
[2025-08-25 22:27:58,975][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003176] [Batch 00708/01234] [00:07:56/00:05:54, 0.673s/it]: train_loss_raw=2.0287, running_loss=2.0342, LR=0.000100
[2025-08-25 22:28:04,241][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003184] [Batch 00716/01234] [00:08:01/00:05:48, 0.673s/it]: train_loss_raw=2.0629, running_loss=2.0332, LR=0.000100
[2025-08-25 22:28:09,843][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003192] [Batch 00724/01234] [00:08:07/00:05:43, 0.673s/it]: train_loss_raw=2.0888, running_loss=2.0320, LR=0.000100
[2025-08-25 22:28:15,445][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003200] [Batch 00732/01234] [00:08:12/00:05:38, 0.673s/it]: train_loss_raw=2.0288, running_loss=2.0330, LR=0.000100
[2025-08-25 22:28:20,579][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003208] [Batch 00740/01234] [00:08:18/00:05:32, 0.673s/it]: train_loss_raw=2.0234, running_loss=2.0338, LR=0.000100
[2025-08-25 22:28:25,693][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003216] [Batch 00748/01234] [00:08:23/00:05:26, 0.673s/it]: train_loss_raw=2.0635, running_loss=2.0334, LR=0.000100
[2025-08-25 22:28:30,995][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003224] [Batch 00756/01234] [00:08:28/00:05:21, 0.673s/it]: train_loss_raw=2.0513, running_loss=2.0333, LR=0.000100
[2025-08-25 22:28:36,353][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003232] [Batch 00764/01234] [00:08:33/00:05:16, 0.673s/it]: train_loss_raw=2.0167, running_loss=2.0333, LR=0.000100
[2025-08-25 22:28:41,837][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003240] [Batch 00772/01234] [00:08:39/00:05:10, 0.673s/it]: train_loss_raw=2.0139, running_loss=2.0298, LR=0.000100
[2025-08-25 22:28:47,308][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003248] [Batch 00780/01234] [00:08:44/00:05:05, 0.673s/it]: train_loss_raw=1.9070, running_loss=2.0285, LR=0.000100
[2025-08-25 22:28:52,417][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003256] [Batch 00788/01234] [00:08:49/00:04:59, 0.673s/it]: train_loss_raw=1.9065, running_loss=2.0257, LR=0.000100
[2025-08-25 22:28:57,617][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003264] [Batch 00796/01234] [00:08:55/00:04:54, 0.672s/it]: train_loss_raw=1.9291, running_loss=2.0254, LR=0.000100
[2025-08-25 22:29:03,128][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003272] [Batch 00804/01234] [00:09:00/00:04:49, 0.672s/it]: train_loss_raw=1.9953, running_loss=2.0230, LR=0.000100
[2025-08-25 22:29:08,352][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003280] [Batch 00812/01234] [00:09:05/00:04:43, 0.672s/it]: train_loss_raw=2.0509, running_loss=2.0235, LR=0.000100
[2025-08-25 22:29:13,817][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003288] [Batch 00820/01234] [00:09:11/00:04:38, 0.672s/it]: train_loss_raw=1.9775, running_loss=2.0237, LR=0.000100
[2025-08-25 22:29:19,214][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003296] [Batch 00828/01234] [00:09:16/00:04:32, 0.672s/it]: train_loss_raw=1.9705, running_loss=2.0238, LR=0.000100
[2025-08-25 22:29:24,318][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003304] [Batch 00836/01234] [00:09:21/00:04:27, 0.672s/it]: train_loss_raw=2.0158, running_loss=2.0221, LR=0.000100
[2025-08-25 22:29:29,452][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003312] [Batch 00844/01234] [00:09:26/00:04:21, 0.672s/it]: train_loss_raw=2.0177, running_loss=2.0204, LR=0.000100
[2025-08-25 22:29:34,718][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003320] [Batch 00852/01234] [00:09:32/00:04:16, 0.672s/it]: train_loss_raw=1.9603, running_loss=2.0185, LR=0.000100
[2025-08-25 22:29:40,294][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003328] [Batch 00860/01234] [00:09:37/00:04:11, 0.672s/it]: train_loss_raw=2.0179, running_loss=2.0193, LR=0.000100
[2025-08-25 22:29:45,822][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003336] [Batch 00868/01234] [00:09:43/00:04:05, 0.672s/it]: train_loss_raw=1.9846, running_loss=2.0192, LR=0.000100
[2025-08-25 22:29:51,309][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003344] [Batch 00876/01234] [00:09:48/00:04:00, 0.672s/it]: train_loss_raw=1.9635, running_loss=2.0180, LR=0.000100
[2025-08-25 22:29:56,521][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003352] [Batch 00884/01234] [00:09:54/00:03:55, 0.672s/it]: train_loss_raw=2.0046, running_loss=2.0181, LR=0.000100
[2025-08-25 22:30:01,985][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003360] [Batch 00892/01234] [00:09:59/00:03:49, 0.672s/it]: train_loss_raw=2.0343, running_loss=2.0176, LR=0.000100
[2025-08-25 22:30:07,405][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003368] [Batch 00900/01234] [00:10:04/00:03:44, 0.672s/it]: train_loss_raw=2.0745, running_loss=2.0165, LR=0.000100
[2025-08-25 22:30:12,561][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003376] [Batch 00908/01234] [00:10:10/00:03:39, 0.672s/it]: train_loss_raw=2.0013, running_loss=2.0140, LR=0.000100
[2025-08-25 22:30:18,037][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003384] [Batch 00916/01234] [00:10:15/00:03:33, 0.672s/it]: train_loss_raw=2.0469, running_loss=2.0152, LR=0.000100
[2025-08-25 22:30:23,240][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003392] [Batch 00924/01234] [00:10:20/00:03:28, 0.672s/it]: train_loss_raw=2.0665, running_loss=2.0150, LR=0.000100
[2025-08-25 22:30:28,458][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003400] [Batch 00932/01234] [00:10:25/00:03:22, 0.672s/it]: train_loss_raw=2.0440, running_loss=2.0137, LR=0.000100
[2025-08-25 22:30:33,665][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003408] [Batch 00940/01234] [00:10:31/00:03:17, 0.671s/it]: train_loss_raw=1.9944, running_loss=2.0122, LR=0.000100
[2025-08-25 22:30:39,092][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003416] [Batch 00948/01234] [00:10:36/00:03:12, 0.672s/it]: train_loss_raw=2.0514, running_loss=2.0112, LR=0.000100
[2025-08-25 22:30:44,281][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003424] [Batch 00956/01234] [00:10:41/00:03:06, 0.671s/it]: train_loss_raw=2.0612, running_loss=2.0109, LR=0.000100
[2025-08-25 22:30:49,730][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003432] [Batch 00964/01234] [00:10:47/00:03:01, 0.671s/it]: train_loss_raw=2.0563, running_loss=2.0113, LR=0.000100
[2025-08-25 22:30:55,627][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003440] [Batch 00972/01234] [00:10:53/00:02:56, 0.672s/it]: train_loss_raw=1.9183, running_loss=2.0104, LR=0.000100
[2025-08-25 22:31:01,109][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003448] [Batch 00980/01234] [00:10:58/00:02:50, 0.672s/it]: train_loss_raw=1.9876, running_loss=2.0108, LR=0.000100
[2025-08-25 22:31:06,735][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003456] [Batch 00988/01234] [00:11:04/00:02:45, 0.672s/it]: train_loss_raw=2.0423, running_loss=2.0101, LR=0.000100
[2025-08-25 22:31:11,777][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003464] [Batch 00996/01234] [00:11:09/00:02:39, 0.672s/it]: train_loss_raw=1.9677, running_loss=2.0098, LR=0.000100
[2025-08-25 22:31:17,065][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003472] [Batch 01004/01234] [00:11:14/00:02:34, 0.672s/it]: train_loss_raw=2.1236, running_loss=2.0091, LR=0.000100
[2025-08-25 22:31:22,542][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003480] [Batch 01012/01234] [00:11:20/00:02:29, 0.672s/it]: train_loss_raw=1.9674, running_loss=2.0081, LR=0.000100
[2025-08-25 22:31:27,675][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003488] [Batch 01020/01234] [00:11:25/00:02:23, 0.672s/it]: train_loss_raw=1.9696, running_loss=2.0053, LR=0.000100
[2025-08-25 22:31:32,818][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003496] [Batch 01028/01234] [00:11:30/00:02:18, 0.672s/it]: train_loss_raw=2.0138, running_loss=2.0030, LR=0.000100
[2025-08-25 22:31:38,110][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003504] [Batch 01036/01234] [00:11:35/00:02:12, 0.671s/it]: train_loss_raw=2.0439, running_loss=2.0038, LR=0.000100
[2025-08-25 22:31:43,386][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003512] [Batch 01044/01234] [00:11:40/00:02:07, 0.671s/it]: train_loss_raw=1.8827, running_loss=2.0029, LR=0.000100
[2025-08-25 22:31:48,489][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003520] [Batch 01052/01234] [00:11:46/00:02:02, 0.671s/it]: train_loss_raw=2.0666, running_loss=2.0026, LR=0.000100
[2025-08-25 22:31:53,557][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003528] [Batch 01060/01234] [00:11:51/00:01:56, 0.671s/it]: train_loss_raw=1.9905, running_loss=2.0014, LR=0.000100
[2025-08-25 22:31:58,687][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003536] [Batch 01068/01234] [00:11:56/00:01:51, 0.671s/it]: train_loss_raw=2.0159, running_loss=2.0007, LR=0.000100
[2025-08-25 22:32:04,109][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003544] [Batch 01076/01234] [00:12:01/00:01:45, 0.671s/it]: train_loss_raw=1.9757, running_loss=1.9996, LR=0.000100
[2025-08-25 22:32:09,220][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003552] [Batch 01084/01234] [00:12:06/00:01:40, 0.670s/it]: train_loss_raw=2.0101, running_loss=2.0005, LR=0.000100
[2025-08-25 22:32:14,587][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003560] [Batch 01092/01234] [00:12:12/00:01:35, 0.670s/it]: train_loss_raw=2.0525, running_loss=1.9991, LR=0.000100
[2025-08-25 22:32:20,373][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003568] [Batch 01100/01234] [00:12:17/00:01:29, 0.671s/it]: train_loss_raw=2.0029, running_loss=1.9983, LR=0.000100
[2025-08-25 22:32:25,757][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003576] [Batch 01108/01234] [00:12:23/00:01:24, 0.671s/it]: train_loss_raw=2.0172, running_loss=1.9997, LR=0.000100
[2025-08-25 22:32:31,389][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003584] [Batch 01116/01234] [00:12:28/00:01:19, 0.671s/it]: train_loss_raw=1.9689, running_loss=1.9972, LR=0.000100
[2025-08-25 22:32:36,583][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003592] [Batch 01124/01234] [00:12:34/00:01:13, 0.671s/it]: train_loss_raw=2.0445, running_loss=1.9973, LR=0.000100
[2025-08-25 22:32:41,706][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003600] [Batch 01132/01234] [00:12:39/00:01:08, 0.671s/it]: train_loss_raw=2.0237, running_loss=1.9966, LR=0.000100
[2025-08-25 22:32:46,863][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003608] [Batch 01140/01234] [00:12:44/00:01:03, 0.671s/it]: train_loss_raw=1.9999, running_loss=1.9936, LR=0.000100
[2025-08-25 22:32:51,936][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003616] [Batch 01148/01234] [00:12:49/00:00:57, 0.670s/it]: train_loss_raw=1.9702, running_loss=1.9912, LR=0.000100
[2025-08-25 22:32:56,991][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003624] [Batch 01156/01234] [00:12:54/00:00:52, 0.670s/it]: train_loss_raw=2.0075, running_loss=1.9921, LR=0.000100
[2025-08-25 22:33:02,620][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003632] [Batch 01164/01234] [00:13:00/00:00:46, 0.670s/it]: train_loss_raw=2.0470, running_loss=1.9931, LR=0.000100
[2025-08-25 22:33:08,063][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003640] [Batch 01172/01234] [00:13:05/00:00:41, 0.670s/it]: train_loss_raw=1.9413, running_loss=1.9907, LR=0.000100
[2025-08-25 22:33:13,987][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003648] [Batch 01180/01234] [00:13:11/00:00:36, 0.671s/it]: train_loss_raw=1.9198, running_loss=1.9899, LR=0.000100
[2025-08-25 22:33:19,740][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003656] [Batch 01188/01234] [00:13:17/00:00:30, 0.671s/it]: train_loss_raw=2.0344, running_loss=1.9898, LR=0.000100
[2025-08-25 22:33:25,412][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003664] [Batch 01196/01234] [00:13:22/00:00:25, 0.671s/it]: train_loss_raw=1.9872, running_loss=1.9872, LR=0.000100
[2025-08-25 22:33:31,034][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003672] [Batch 01204/01234] [00:13:28/00:00:20, 0.672s/it]: train_loss_raw=1.9819, running_loss=1.9856, LR=0.000100
[2025-08-25 22:33:36,534][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003680] [Batch 01212/01234] [00:13:34/00:00:14, 0.672s/it]: train_loss_raw=1.8975, running_loss=1.9844, LR=0.000100
[2025-08-25 22:33:41,861][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003688] [Batch 01220/01234] [00:13:39/00:00:09, 0.672s/it]: train_loss_raw=2.0100, running_loss=1.9856, LR=0.000100
[2025-08-25 22:33:47,076][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 003696] [Batch 01228/01234] [00:13:44/00:00:04, 0.672s/it]: train_loss_raw=2.0560, running_loss=1.9860, LR=0.000100
[2025-08-25 22:33:56,633][__main__][INFO] - [VALIDATION] [Epoch 02/29] Starting validation.
[2025-08-25 22:34:06,837][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 003703] [Batch 00007/00026] [00:00:10/00:00:22, 1.276s/it]
[2025-08-25 22:34:17,698][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 003703] [Batch 00015/00026] [00:00:21/00:00:13, 1.317s/it]
[2025-08-25 22:34:28,012][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 003703] [Batch 00023/00026] [00:00:31/00:00:02, 1.307s/it]
[2025-08-25 22:34:30,283][__main__][INFO] - [VALIDATION] [Epoch 02/29] train_loss=1.98480, valid_loss=1.97810
[2025-08-25 22:34:30,283][__main__][INFO] - [VALIDATION] [Epoch 02/29] Metrics:
[2025-08-25 22:34:30,283][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_er      0.783
[2025-08-25 22:34:30,283][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_prec    0.021
[2025-08-25 22:34:30,283][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_recall  0.022
[2025-08-25 22:34:30,283][__main__][INFO] - [VALIDATION] [Epoch 02/29] - pep_recall 0.000
[2025-08-25 22:34:30,285][__main__][INFO] - [TRAIN] [Epoch 02/29] Epoch complete, total time 00:43:39, remaining time 06:32:55, 00:14:33 per epoch
[2025-08-25 22:34:31,189][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003704] [Batch 00002/01234] [00:00:00/00:07:58, 0.389s/it]: train_loss_raw=1.9644, running_loss=2.0499, LR=0.000100
[2025-08-25 22:34:36,243][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003712] [Batch 00010/01234] [00:00:05/00:11:53, 0.583s/it]: train_loss_raw=1.9634, running_loss=2.0424, LR=0.000100
[2025-08-25 22:34:41,778][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003720] [Batch 00018/01234] [00:00:11/00:12:47, 0.631s/it]: train_loss_raw=1.9515, running_loss=2.0331, LR=0.000100
[2025-08-25 22:34:47,342][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003728] [Batch 00026/01234] [00:00:16/00:13:06, 0.651s/it]: train_loss_raw=1.9228, running_loss=2.0275, LR=0.000100
[2025-08-25 22:34:52,958][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003736] [Batch 00034/01234] [00:00:22/00:13:15, 0.663s/it]: train_loss_raw=2.0072, running_loss=2.0212, LR=0.000100
[2025-08-25 22:34:58,466][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003744] [Batch 00042/01234] [00:00:28/00:13:16, 0.668s/it]: train_loss_raw=1.8868, running_loss=2.0143, LR=0.000100
[2025-08-25 22:35:03,629][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003752] [Batch 00050/01234] [00:00:33/00:13:06, 0.664s/it]: train_loss_raw=2.0396, running_loss=2.0108, LR=0.000100
[2025-08-25 22:35:09,042][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003760] [Batch 00058/01234] [00:00:38/00:13:03, 0.666s/it]: train_loss_raw=1.9175, running_loss=2.0067, LR=0.000100
[2025-08-25 22:35:14,885][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003768] [Batch 00066/01234] [00:00:44/00:13:07, 0.674s/it]: train_loss_raw=1.9870, running_loss=2.0036, LR=0.000100
[2025-08-25 22:35:19,964][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003776] [Batch 00074/01234] [00:00:49/00:12:56, 0.670s/it]: train_loss_raw=2.0082, running_loss=1.9982, LR=0.000100
[2025-08-25 22:35:25,145][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003784] [Batch 00082/01234] [00:00:54/00:12:48, 0.667s/it]: train_loss_raw=1.9316, running_loss=1.9947, LR=0.000100
[2025-08-25 22:35:30,214][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003792] [Batch 00090/01234] [00:00:59/00:12:40, 0.664s/it]: train_loss_raw=1.9327, running_loss=1.9912, LR=0.000100
[2025-08-25 22:35:35,322][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003800] [Batch 00098/01234] [00:01:04/00:12:32, 0.662s/it]: train_loss_raw=2.0165, running_loss=1.9894, LR=0.000100
[2025-08-25 22:35:40,391][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003808] [Batch 00106/01234] [00:01:09/00:12:24, 0.660s/it]: train_loss_raw=1.8545, running_loss=1.9849, LR=0.000100
[2025-08-25 22:35:45,531][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003816] [Batch 00114/01234] [00:01:15/00:12:18, 0.659s/it]: train_loss_raw=1.9462, running_loss=1.9833, LR=0.000100
[2025-08-25 22:35:50,587][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003824] [Batch 00122/01234] [00:01:20/00:12:10, 0.657s/it]: train_loss_raw=1.9286, running_loss=1.9819, LR=0.000100
[2025-08-25 22:35:55,627][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003832] [Batch 00130/01234] [00:01:25/00:12:03, 0.656s/it]: train_loss_raw=1.9887, running_loss=1.9811, LR=0.000100
[2025-08-25 22:36:01,041][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003840] [Batch 00138/01234] [00:01:30/00:11:59, 0.657s/it]: train_loss_raw=2.0321, running_loss=1.9803, LR=0.000100
[2025-08-25 22:36:06,448][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003848] [Batch 00146/01234] [00:01:36/00:11:55, 0.658s/it]: train_loss_raw=1.9231, running_loss=1.9785, LR=0.000100
[2025-08-25 22:36:11,580][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003856] [Batch 00154/01234] [00:01:41/00:11:49, 0.657s/it]: train_loss_raw=1.9235, running_loss=1.9750, LR=0.000100
[2025-08-25 22:36:17,151][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003864] [Batch 00162/01234] [00:01:46/00:11:46, 0.659s/it]: train_loss_raw=1.9994, running_loss=1.9760, LR=0.000100
[2025-08-25 22:36:22,871][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003872] [Batch 00170/01234] [00:01:52/00:11:43, 0.662s/it]: train_loss_raw=2.0225, running_loss=1.9745, LR=0.000100
[2025-08-25 22:36:28,011][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003880] [Batch 00178/01234] [00:01:57/00:11:37, 0.661s/it]: train_loss_raw=1.9762, running_loss=1.9734, LR=0.000100
[2025-08-25 22:36:33,602][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003888] [Batch 00186/01234] [00:02:03/00:11:34, 0.662s/it]: train_loss_raw=1.8984, running_loss=1.9677, LR=0.000100
[2025-08-25 22:36:38,786][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003896] [Batch 00194/01234] [00:02:08/00:11:28, 0.662s/it]: train_loss_raw=1.9421, running_loss=1.9670, LR=0.000100
[2025-08-25 22:36:44,009][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003904] [Batch 00202/01234] [00:02:13/00:11:22, 0.661s/it]: train_loss_raw=1.9929, running_loss=1.9641, LR=0.000100
[2025-08-25 22:36:49,530][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003912] [Batch 00210/01234] [00:02:19/00:11:18, 0.662s/it]: train_loss_raw=1.9050, running_loss=1.9622, LR=0.000100
[2025-08-25 22:36:54,880][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003920] [Batch 00218/01234] [00:02:24/00:11:13, 0.663s/it]: train_loss_raw=1.9269, running_loss=1.9616, LR=0.000100
[2025-08-25 22:37:00,240][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003928] [Batch 00226/01234] [00:02:29/00:11:08, 0.663s/it]: train_loss_raw=1.9198, running_loss=1.9617, LR=0.000100
[2025-08-25 22:37:05,540][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003936] [Batch 00234/01234] [00:02:35/00:11:02, 0.663s/it]: train_loss_raw=1.9630, running_loss=1.9635, LR=0.000100
[2025-08-25 22:37:10,986][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003944] [Batch 00242/01234] [00:02:40/00:10:58, 0.664s/it]: train_loss_raw=1.9963, running_loss=1.9614, LR=0.000100
[2025-08-25 22:37:16,892][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003952] [Batch 00250/01234] [00:02:46/00:10:55, 0.666s/it]: train_loss_raw=1.9191, running_loss=1.9588, LR=0.000100
[2025-08-25 22:37:21,923][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003960] [Batch 00258/01234] [00:02:51/00:10:48, 0.665s/it]: train_loss_raw=1.9217, running_loss=1.9566, LR=0.000100
[2025-08-25 22:37:26,986][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003968] [Batch 00266/01234] [00:02:56/00:10:42, 0.664s/it]: train_loss_raw=1.9617, running_loss=1.9558, LR=0.000100
[2025-08-25 22:37:32,532][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003976] [Batch 00274/01234] [00:03:02/00:10:38, 0.665s/it]: train_loss_raw=1.9478, running_loss=1.9546, LR=0.000100
[2025-08-25 22:37:37,840][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003984] [Batch 00282/01234] [00:03:07/00:10:32, 0.665s/it]: train_loss_raw=1.9256, running_loss=1.9528, LR=0.000100
[2025-08-25 22:37:43,028][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003992] [Batch 00290/01234] [00:03:12/00:10:26, 0.664s/it]: train_loss_raw=1.9418, running_loss=1.9520, LR=0.000100
[2025-08-25 22:37:48,324][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004000] [Batch 00298/01234] [00:03:17/00:10:21, 0.664s/it]: train_loss_raw=1.9724, running_loss=1.9514, LR=0.000100
[2025-08-25 22:38:00,001][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004008] [Batch 00306/01234] [00:03:29/00:10:35, 0.685s/it]: train_loss_raw=1.9657, running_loss=1.9519, LR=0.000100
[2025-08-25 22:38:05,189][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004016] [Batch 00314/01234] [00:03:34/00:10:29, 0.684s/it]: train_loss_raw=1.9466, running_loss=1.9500, LR=0.000100
[2025-08-25 22:38:10,419][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004024] [Batch 00322/01234] [00:03:40/00:10:23, 0.683s/it]: train_loss_raw=1.9336, running_loss=1.9470, LR=0.000100
[2025-08-25 22:38:15,605][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004032] [Batch 00330/01234] [00:03:45/00:10:16, 0.682s/it]: train_loss_raw=1.9791, running_loss=1.9465, LR=0.000100
[2025-08-25 22:38:20,887][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004040] [Batch 00338/01234] [00:03:50/00:10:10, 0.682s/it]: train_loss_raw=1.9808, running_loss=1.9445, LR=0.000100
[2025-08-25 22:38:26,361][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004048] [Batch 00346/01234] [00:03:55/00:10:05, 0.682s/it]: train_loss_raw=1.9449, running_loss=1.9447, LR=0.000100
[2025-08-25 22:38:31,681][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004056] [Batch 00354/01234] [00:04:01/00:09:59, 0.682s/it]: train_loss_raw=1.8970, running_loss=1.9426, LR=0.000100
[2025-08-25 22:38:36,781][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004064] [Batch 00362/01234] [00:04:06/00:09:53, 0.681s/it]: train_loss_raw=1.9001, running_loss=1.9432, LR=0.000100
[2025-08-25 22:38:41,955][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004072] [Batch 00370/01234] [00:04:11/00:09:47, 0.680s/it]: train_loss_raw=1.9123, running_loss=1.9413, LR=0.000100
[2025-08-25 22:38:47,593][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004080] [Batch 00378/01234] [00:04:17/00:09:42, 0.680s/it]: train_loss_raw=1.9963, running_loss=1.9409, LR=0.000100
[2025-08-25 22:38:52,980][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004088] [Batch 00386/01234] [00:04:22/00:09:36, 0.680s/it]: train_loss_raw=1.9954, running_loss=1.9416, LR=0.000100
[2025-08-25 22:38:58,082][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004096] [Batch 00394/01234] [00:04:27/00:09:30, 0.679s/it]: train_loss_raw=2.0105, running_loss=1.9429, LR=0.000100
[2025-08-25 22:39:03,244][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004104] [Batch 00402/01234] [00:04:32/00:09:24, 0.679s/it]: train_loss_raw=1.9407, running_loss=1.9404, LR=0.000100
[2025-08-25 22:39:08,428][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004112] [Batch 00410/01234] [00:04:38/00:09:18, 0.678s/it]: train_loss_raw=1.8991, running_loss=1.9388, LR=0.000100
[2025-08-25 22:39:13,684][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004120] [Batch 00418/01234] [00:04:43/00:09:12, 0.678s/it]: train_loss_raw=1.8928, running_loss=1.9353, LR=0.000100
[2025-08-25 22:39:20,050][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004128] [Batch 00426/01234] [00:04:49/00:09:09, 0.680s/it]: train_loss_raw=1.9341, running_loss=1.9335, LR=0.000100
[2025-08-25 22:39:25,737][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004136] [Batch 00434/01234] [00:04:55/00:09:04, 0.680s/it]: train_loss_raw=1.8962, running_loss=1.9308, LR=0.000100
[2025-08-25 22:39:31,295][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004144] [Batch 00442/01234] [00:05:00/00:08:59, 0.681s/it]: train_loss_raw=1.9372, running_loss=1.9296, LR=0.000100
[2025-08-25 22:39:36,978][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004152] [Batch 00450/01234] [00:05:06/00:08:54, 0.681s/it]: train_loss_raw=1.8862, running_loss=1.9286, LR=0.000100
[2025-08-25 22:39:42,163][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004160] [Batch 00458/01234] [00:05:11/00:08:48, 0.681s/it]: train_loss_raw=1.8921, running_loss=1.9287, LR=0.000100
[2025-08-25 22:39:47,691][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004168] [Batch 00466/01234] [00:05:17/00:08:42, 0.681s/it]: train_loss_raw=1.9022, running_loss=1.9271, LR=0.000100
[2025-08-25 22:39:53,624][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004176] [Batch 00474/01234] [00:05:23/00:08:38, 0.682s/it]: train_loss_raw=1.9293, running_loss=1.9250, LR=0.000100
[2025-08-25 22:39:59,431][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004184] [Batch 00482/01234] [00:05:29/00:08:33, 0.683s/it]: train_loss_raw=1.9564, running_loss=1.9257, LR=0.000100
[2025-08-25 22:40:05,365][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004192] [Batch 00490/01234] [00:05:34/00:08:28, 0.684s/it]: train_loss_raw=1.9550, running_loss=1.9272, LR=0.000100
[2025-08-25 22:40:10,938][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004200] [Batch 00498/01234] [00:05:40/00:08:23, 0.684s/it]: train_loss_raw=1.9527, running_loss=1.9270, LR=0.000100
[2025-08-25 22:40:16,696][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004208] [Batch 00506/01234] [00:05:46/00:08:18, 0.684s/it]: train_loss_raw=1.8690, running_loss=1.9271, LR=0.000100
[2025-08-25 22:40:21,939][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004216] [Batch 00514/01234] [00:05:51/00:08:12, 0.684s/it]: train_loss_raw=1.8432, running_loss=1.9257, LR=0.000100
[2025-08-25 22:40:27,760][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004224] [Batch 00522/01234] [00:05:57/00:08:07, 0.685s/it]: train_loss_raw=1.7891, running_loss=1.9247, LR=0.000100
[2025-08-25 22:40:33,506][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004232] [Batch 00530/01234] [00:06:03/00:08:02, 0.685s/it]: train_loss_raw=1.9062, running_loss=1.9236, LR=0.000100
[2025-08-25 22:40:39,259][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004240] [Batch 00538/01234] [00:06:08/00:07:57, 0.686s/it]: train_loss_raw=1.9888, running_loss=1.9229, LR=0.000100
[2025-08-25 22:40:44,460][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004248] [Batch 00546/01234] [00:06:14/00:07:51, 0.685s/it]: train_loss_raw=1.9405, running_loss=1.9243, LR=0.000100
[2025-08-25 22:40:49,856][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004256] [Batch 00554/01234] [00:06:19/00:07:45, 0.685s/it]: train_loss_raw=1.9513, running_loss=1.9232, LR=0.000100
[2025-08-25 22:40:55,217][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004264] [Batch 00562/01234] [00:06:24/00:07:40, 0.685s/it]: train_loss_raw=1.9476, running_loss=1.9214, LR=0.000100
[2025-08-25 22:41:00,772][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004272] [Batch 00570/01234] [00:06:30/00:07:34, 0.685s/it]: train_loss_raw=1.8180, running_loss=1.9214, LR=0.000100
[2025-08-25 22:41:05,914][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004280] [Batch 00578/01234] [00:06:35/00:07:28, 0.684s/it]: train_loss_raw=1.8829, running_loss=1.9213, LR=0.000100
[2025-08-25 22:41:11,087][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004288] [Batch 00586/01234] [00:06:40/00:07:23, 0.684s/it]: train_loss_raw=1.9811, running_loss=1.9212, LR=0.000100
[2025-08-25 22:41:16,195][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004296] [Batch 00594/01234] [00:06:45/00:07:17, 0.683s/it]: train_loss_raw=1.8546, running_loss=1.9207, LR=0.000100
[2025-08-25 22:41:21,288][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004304] [Batch 00602/01234] [00:06:50/00:07:11, 0.683s/it]: train_loss_raw=1.8576, running_loss=1.9193, LR=0.000100
[2025-08-25 22:41:26,740][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004312] [Batch 00610/01234] [00:06:56/00:07:05, 0.683s/it]: train_loss_raw=1.9533, running_loss=1.9199, LR=0.000100
[2025-08-25 22:41:31,855][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004320] [Batch 00618/01234] [00:07:01/00:07:00, 0.682s/it]: train_loss_raw=1.8713, running_loss=1.9205, LR=0.000100
[2025-08-25 22:41:37,485][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004328] [Batch 00626/01234] [00:07:07/00:06:54, 0.682s/it]: train_loss_raw=1.8767, running_loss=1.9213, LR=0.000100
[2025-08-25 22:41:42,616][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004336] [Batch 00634/01234] [00:07:12/00:06:49, 0.682s/it]: train_loss_raw=1.9760, running_loss=1.9221, LR=0.000100
[2025-08-25 22:41:47,757][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004344] [Batch 00642/01234] [00:07:17/00:06:43, 0.681s/it]: train_loss_raw=1.8890, running_loss=1.9236, LR=0.000100
[2025-08-25 22:41:53,296][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004352] [Batch 00650/01234] [00:07:22/00:06:37, 0.681s/it]: train_loss_raw=1.9113, running_loss=1.9218, LR=0.000100
[2025-08-25 22:41:58,830][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004360] [Batch 00658/01234] [00:07:28/00:06:32, 0.681s/it]: train_loss_raw=1.9196, running_loss=1.9211, LR=0.000100
[2025-08-25 22:42:04,672][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004368] [Batch 00666/01234] [00:07:34/00:06:27, 0.682s/it]: train_loss_raw=1.9403, running_loss=1.9220, LR=0.000100
[2025-08-25 22:42:09,846][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004376] [Batch 00674/01234] [00:07:39/00:06:21, 0.682s/it]: train_loss_raw=1.9075, running_loss=1.9232, LR=0.000100
[2025-08-25 22:42:15,386][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004384] [Batch 00682/01234] [00:07:44/00:06:16, 0.682s/it]: train_loss_raw=1.9259, running_loss=1.9236, LR=0.000100
[2025-08-25 22:42:20,759][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004392] [Batch 00690/01234] [00:07:50/00:06:10, 0.682s/it]: train_loss_raw=1.9336, running_loss=1.9224, LR=0.000100
[2025-08-25 22:42:25,814][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004400] [Batch 00698/01234] [00:07:55/00:06:05, 0.681s/it]: train_loss_raw=1.9149, running_loss=1.9211, LR=0.000100
[2025-08-25 22:42:30,922][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004408] [Batch 00706/01234] [00:08:00/00:05:59, 0.681s/it]: train_loss_raw=1.9591, running_loss=1.9229, LR=0.000100
[2025-08-25 22:42:36,037][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004416] [Batch 00714/01234] [00:08:05/00:05:53, 0.680s/it]: train_loss_raw=1.8768, running_loss=1.9215, LR=0.000100
[2025-08-25 22:42:41,123][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004424] [Batch 00722/01234] [00:08:10/00:05:47, 0.680s/it]: train_loss_raw=1.9657, running_loss=1.9208, LR=0.000100
[2025-08-25 22:42:46,217][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004432] [Batch 00730/01234] [00:08:15/00:05:42, 0.679s/it]: train_loss_raw=1.9048, running_loss=1.9222, LR=0.000100
[2025-08-25 22:42:51,274][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004440] [Batch 00738/01234] [00:08:20/00:05:36, 0.679s/it]: train_loss_raw=1.9497, running_loss=1.9227, LR=0.000100
[2025-08-25 22:42:56,341][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004448] [Batch 00746/01234] [00:08:25/00:05:30, 0.678s/it]: train_loss_raw=1.9850, running_loss=1.9234, LR=0.000100
[2025-08-25 22:43:01,468][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004456] [Batch 00754/01234] [00:08:31/00:05:25, 0.678s/it]: train_loss_raw=1.8636, running_loss=1.9231, LR=0.000100
[2025-08-25 22:43:06,553][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004464] [Batch 00762/01234] [00:08:36/00:05:19, 0.677s/it]: train_loss_raw=2.0018, running_loss=1.9216, LR=0.000100
[2025-08-25 22:43:11,942][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004472] [Batch 00770/01234] [00:08:41/00:05:14, 0.677s/it]: train_loss_raw=1.8845, running_loss=1.9201, LR=0.000100
[2025-08-25 22:43:17,501][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004480] [Batch 00778/01234] [00:08:47/00:05:08, 0.677s/it]: train_loss_raw=1.8980, running_loss=1.9194, LR=0.000100
[2025-08-25 22:43:22,731][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004488] [Batch 00786/01234] [00:08:52/00:05:03, 0.677s/it]: train_loss_raw=1.8735, running_loss=1.9191, LR=0.000100
[2025-08-25 22:43:27,817][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004496] [Batch 00794/01234] [00:08:57/00:04:57, 0.677s/it]: train_loss_raw=1.8476, running_loss=1.9189, LR=0.000100
[2025-08-25 22:43:32,935][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004504] [Batch 00802/01234] [00:09:02/00:04:52, 0.676s/it]: train_loss_raw=1.8870, running_loss=1.9185, LR=0.000100
[2025-08-25 22:43:38,551][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004512] [Batch 00810/01234] [00:09:08/00:04:46, 0.677s/it]: train_loss_raw=1.9396, running_loss=1.9157, LR=0.000100
[2025-08-25 22:43:44,171][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004520] [Batch 00818/01234] [00:09:13/00:04:41, 0.677s/it]: train_loss_raw=1.9256, running_loss=1.9155, LR=0.000100
[2025-08-25 22:43:49,580][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004528] [Batch 00826/01234] [00:09:19/00:04:36, 0.677s/it]: train_loss_raw=1.9704, running_loss=1.9154, LR=0.000100
[2025-08-25 22:43:55,182][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004536] [Batch 00834/01234] [00:09:24/00:04:30, 0.677s/it]: train_loss_raw=1.9294, running_loss=1.9145, LR=0.000100
[2025-08-25 22:44:00,822][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004544] [Batch 00842/01234] [00:09:30/00:04:25, 0.677s/it]: train_loss_raw=1.9399, running_loss=1.9109, LR=0.000100
[2025-08-25 22:44:06,331][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004552] [Batch 00850/01234] [00:09:35/00:04:20, 0.678s/it]: train_loss_raw=1.9632, running_loss=1.9095, LR=0.000100
[2025-08-25 22:44:11,544][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004560] [Batch 00858/01234] [00:09:41/00:04:14, 0.677s/it]: train_loss_raw=1.8850, running_loss=1.9077, LR=0.000100
[2025-08-25 22:44:16,918][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004568] [Batch 00866/01234] [00:09:46/00:04:09, 0.677s/it]: train_loss_raw=1.8912, running_loss=1.9083, LR=0.000100
[2025-08-25 22:44:22,217][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004576] [Batch 00874/01234] [00:09:51/00:04:03, 0.677s/it]: train_loss_raw=1.8330, running_loss=1.9072, LR=0.000100
[2025-08-25 22:44:27,394][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004584] [Batch 00882/01234] [00:09:56/00:03:58, 0.677s/it]: train_loss_raw=1.9180, running_loss=1.9071, LR=0.000100
[2025-08-25 22:44:33,236][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004592] [Batch 00890/01234] [00:10:02/00:03:53, 0.677s/it]: train_loss_raw=1.8934, running_loss=1.9074, LR=0.000100
[2025-08-25 22:44:38,386][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004600] [Batch 00898/01234] [00:10:07/00:03:47, 0.677s/it]: train_loss_raw=1.9214, running_loss=1.9077, LR=0.000100
[2025-08-25 22:44:43,566][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004608] [Batch 00906/01234] [00:10:13/00:03:41, 0.677s/it]: train_loss_raw=1.9359, running_loss=1.9088, LR=0.000100
[2025-08-25 22:44:49,000][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004616] [Batch 00914/01234] [00:10:18/00:03:36, 0.677s/it]: train_loss_raw=1.9340, running_loss=1.9048, LR=0.000100
[2025-08-25 22:44:54,141][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004624] [Batch 00922/01234] [00:10:23/00:03:31, 0.676s/it]: train_loss_raw=1.9068, running_loss=1.9023, LR=0.000100
[2025-08-25 22:44:59,636][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004632] [Batch 00930/01234] [00:10:29/00:03:25, 0.677s/it]: train_loss_raw=1.9356, running_loss=1.9028, LR=0.000100
[2025-08-25 22:45:05,017][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004640] [Batch 00938/01234] [00:10:34/00:03:20, 0.677s/it]: train_loss_raw=1.9098, running_loss=1.9033, LR=0.000100
[2025-08-25 22:45:10,789][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004648] [Batch 00946/01234] [00:10:40/00:03:14, 0.677s/it]: train_loss_raw=1.8955, running_loss=1.9009, LR=0.000100
[2025-08-25 22:45:16,480][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004656] [Batch 00954/01234] [00:10:46/00:03:09, 0.677s/it]: train_loss_raw=1.9206, running_loss=1.9013, LR=0.000100
[2025-08-25 22:45:21,787][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004664] [Batch 00962/01234] [00:10:51/00:03:04, 0.677s/it]: train_loss_raw=1.9226, running_loss=1.9015, LR=0.000100
[2025-08-25 22:45:26,885][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004672] [Batch 00970/01234] [00:10:56/00:02:58, 0.677s/it]: train_loss_raw=1.9010, running_loss=1.8989, LR=0.000100
[2025-08-25 22:45:32,059][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004680] [Batch 00978/01234] [00:11:01/00:02:53, 0.677s/it]: train_loss_raw=1.9337, running_loss=1.8995, LR=0.000100
[2025-08-25 22:45:37,551][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004688] [Batch 00986/01234] [00:11:07/00:02:47, 0.677s/it]: train_loss_raw=1.9041, running_loss=1.8998, LR=0.000100
[2025-08-25 22:45:43,118][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004696] [Batch 00994/01234] [00:11:12/00:02:42, 0.677s/it]: train_loss_raw=1.9215, running_loss=1.8996, LR=0.000100
[2025-08-25 22:45:49,011][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004704] [Batch 01002/01234] [00:11:18/00:02:37, 0.677s/it]: train_loss_raw=1.8588, running_loss=1.8985, LR=0.000100
[2025-08-25 22:45:54,407][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004712] [Batch 01010/01234] [00:11:23/00:02:31, 0.677s/it]: train_loss_raw=1.8056, running_loss=1.8964, LR=0.000100
[2025-08-25 22:45:59,616][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004720] [Batch 01018/01234] [00:11:29/00:02:26, 0.677s/it]: train_loss_raw=1.9167, running_loss=1.8949, LR=0.000100
[2025-08-25 22:46:04,962][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004728] [Batch 01026/01234] [00:11:34/00:02:20, 0.677s/it]: train_loss_raw=1.9152, running_loss=1.8953, LR=0.000100
[2025-08-25 22:46:10,720][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004736] [Batch 01034/01234] [00:11:40/00:02:15, 0.677s/it]: train_loss_raw=1.8770, running_loss=1.8958, LR=0.000100
[2025-08-25 22:46:16,577][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004744] [Batch 01042/01234] [00:11:46/00:02:10, 0.678s/it]: train_loss_raw=1.8606, running_loss=1.8957, LR=0.000100
[2025-08-25 22:46:22,146][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004752] [Batch 01050/01234] [00:11:51/00:02:04, 0.678s/it]: train_loss_raw=1.9895, running_loss=1.8949, LR=0.000100
[2025-08-25 22:46:27,759][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004760] [Batch 01058/01234] [00:11:57/00:01:59, 0.678s/it]: train_loss_raw=1.8606, running_loss=1.8924, LR=0.000100
[2025-08-25 22:46:32,937][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004768] [Batch 01066/01234] [00:12:02/00:01:53, 0.678s/it]: train_loss_raw=1.9122, running_loss=1.8922, LR=0.000100
[2025-08-25 22:46:38,217][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004776] [Batch 01074/01234] [00:12:07/00:01:48, 0.678s/it]: train_loss_raw=1.9001, running_loss=1.8925, LR=0.000100
[2025-08-25 22:46:43,475][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004784] [Batch 01082/01234] [00:12:13/00:01:42, 0.678s/it]: train_loss_raw=1.8193, running_loss=1.8894, LR=0.000100
[2025-08-25 22:46:48,658][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004792] [Batch 01090/01234] [00:12:18/00:01:37, 0.677s/it]: train_loss_raw=1.8546, running_loss=1.8897, LR=0.000100
[2025-08-25 22:46:53,956][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004800] [Batch 01098/01234] [00:12:23/00:01:32, 0.677s/it]: train_loss_raw=1.9259, running_loss=1.8899, LR=0.000100
[2025-08-25 22:46:59,733][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004808] [Batch 01106/01234] [00:12:29/00:01:26, 0.678s/it]: train_loss_raw=1.8355, running_loss=1.8886, LR=0.000100
[2025-08-25 22:47:05,099][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004816] [Batch 01114/01234] [00:12:34/00:01:21, 0.677s/it]: train_loss_raw=1.8339, running_loss=1.8861, LR=0.000100
[2025-08-25 22:47:10,633][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004824] [Batch 01122/01234] [00:12:40/00:01:15, 0.678s/it]: train_loss_raw=1.8750, running_loss=1.8849, LR=0.000100
[2025-08-25 22:47:16,493][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004832] [Batch 01130/01234] [00:12:46/00:01:10, 0.678s/it]: train_loss_raw=1.9387, running_loss=1.8837, LR=0.000100
[2025-08-25 22:47:21,597][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004840] [Batch 01138/01234] [00:12:51/00:01:05, 0.678s/it]: train_loss_raw=1.8081, running_loss=1.8812, LR=0.000100
[2025-08-25 22:47:26,969][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004848] [Batch 01146/01234] [00:12:56/00:00:59, 0.678s/it]: train_loss_raw=1.7867, running_loss=1.8802, LR=0.000100
[2025-08-25 22:47:33,148][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004856] [Batch 01154/01234] [00:13:02/00:00:54, 0.678s/it]: train_loss_raw=1.8671, running_loss=1.8802, LR=0.000100
[2025-08-25 22:47:38,985][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004864] [Batch 01162/01234] [00:13:08/00:00:48, 0.679s/it]: train_loss_raw=1.8373, running_loss=1.8805, LR=0.000100
[2025-08-25 22:47:44,850][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004872] [Batch 01170/01234] [00:13:14/00:00:43, 0.679s/it]: train_loss_raw=1.8657, running_loss=1.8815, LR=0.000100
[2025-08-25 22:47:50,296][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004880] [Batch 01178/01234] [00:13:19/00:00:38, 0.679s/it]: train_loss_raw=1.8616, running_loss=1.8826, LR=0.000100
[2025-08-25 22:47:55,435][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004888] [Batch 01186/01234] [00:13:25/00:00:32, 0.679s/it]: train_loss_raw=1.9065, running_loss=1.8840, LR=0.000100
[2025-08-25 22:48:00,584][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004896] [Batch 01194/01234] [00:13:30/00:00:27, 0.679s/it]: train_loss_raw=1.8207, running_loss=1.8829, LR=0.000100
[2025-08-25 22:48:06,046][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004904] [Batch 01202/01234] [00:13:35/00:00:21, 0.679s/it]: train_loss_raw=1.8623, running_loss=1.8815, LR=0.000100
[2025-08-25 22:48:11,567][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004912] [Batch 01210/01234] [00:13:41/00:00:16, 0.679s/it]: train_loss_raw=1.8880, running_loss=1.8813, LR=0.000100
[2025-08-25 22:48:16,723][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004920] [Batch 01218/01234] [00:13:46/00:00:10, 0.678s/it]: train_loss_raw=1.9452, running_loss=1.8822, LR=0.000100
[2025-08-25 22:48:22,155][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004928] [Batch 01226/01234] [00:13:51/00:00:05, 0.678s/it]: train_loss_raw=1.7887, running_loss=1.8807, LR=0.000100
[2025-08-25 22:48:33,760][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 004936] [Batch 01234/01234] [00:14:03/00:00:00, 0.683s/it]: train_loss_raw=1.7521, running_loss=1.8793, LR=0.000100
[2025-08-25 22:48:34,225][__main__][INFO] - [VALIDATION] [Epoch 03/29] Starting validation.
[2025-08-25 22:48:44,832][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 004937] [Batch 00007/00026] [00:00:10/00:00:23, 1.326s/it]
[2025-08-25 22:48:55,351][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 004937] [Batch 00015/00026] [00:00:21/00:00:13, 1.320s/it]
[2025-08-25 22:49:05,720][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 004937] [Batch 00023/00026] [00:00:31/00:00:02, 1.312s/it]
[2025-08-25 22:49:08,034][__main__][INFO] - [VALIDATION] [Epoch 03/29] train_loss=1.87930, valid_loss=1.87960
[2025-08-25 22:49:08,034][__main__][INFO] - [VALIDATION] [Epoch 03/29] Metrics:
[2025-08-25 22:49:08,034][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_er      0.762
[2025-08-25 22:49:08,034][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_prec    0.028
[2025-08-25 22:49:08,035][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_recall  0.030
[2025-08-25 22:49:08,035][__main__][INFO] - [VALIDATION] [Epoch 03/29] - pep_recall 0.001
[2025-08-25 22:49:08,036][__main__][INFO] - [TRAIN] [Epoch 03/29] Epoch complete, total time 00:58:17, remaining time 06:18:51, 00:14:34 per epoch
[2025-08-25 22:49:13,016][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004944] [Batch 00008/01234] [00:00:04/00:12:23, 0.606s/it]: train_loss_raw=1.8803, running_loss=1.8758, LR=0.000100
[2025-08-25 22:49:18,638][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004952] [Batch 00016/01234] [00:00:10/00:13:17, 0.655s/it]: train_loss_raw=1.7898, running_loss=1.8718, LR=0.000100
[2025-08-25 22:49:24,232][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004960] [Batch 00024/01234] [00:00:16/00:13:30, 0.669s/it]: train_loss_raw=1.9017, running_loss=1.8717, LR=0.000100
[2025-08-25 22:49:29,343][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004968] [Batch 00032/01234] [00:00:21/00:13:15, 0.662s/it]: train_loss_raw=1.8455, running_loss=1.8692, LR=0.000100
[2025-08-25 22:49:35,102][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004976] [Batch 00040/01234] [00:00:26/00:13:24, 0.673s/it]: train_loss_raw=1.8573, running_loss=1.8680, LR=0.000100
[2025-08-25 22:49:40,170][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004984] [Batch 00048/01234] [00:00:32/00:13:10, 0.667s/it]: train_loss_raw=1.9406, running_loss=1.8648, LR=0.000100
[2025-08-25 22:49:45,611][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004992] [Batch 00056/01234] [00:00:37/00:13:07, 0.669s/it]: train_loss_raw=1.8760, running_loss=1.8636, LR=0.000100
[2025-08-25 22:49:50,657][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005000] [Batch 00064/01234] [00:00:42/00:12:56, 0.664s/it]: train_loss_raw=1.9046, running_loss=1.8628, LR=0.000100
[2025-08-25 22:49:55,841][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005008] [Batch 00072/01234] [00:00:47/00:12:49, 0.662s/it]: train_loss_raw=1.9085, running_loss=1.8629, LR=0.000100
[2025-08-25 22:50:01,261][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005016] [Batch 00080/01234] [00:00:53/00:12:45, 0.664s/it]: train_loss_raw=1.8773, running_loss=1.8616, LR=0.000100
[2025-08-25 22:50:06,442][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005024] [Batch 00088/01234] [00:00:58/00:12:38, 0.662s/it]: train_loss_raw=1.8475, running_loss=1.8590, LR=0.000100
[2025-08-25 22:50:11,526][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005032] [Batch 00096/01234] [00:01:03/00:12:31, 0.660s/it]: train_loss_raw=1.9389, running_loss=1.8603, LR=0.000100
[2025-08-25 22:50:16,600][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005040] [Batch 00104/01234] [00:01:08/00:12:23, 0.658s/it]: train_loss_raw=1.7966, running_loss=1.8592, LR=0.000100
[2025-08-25 22:50:21,726][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005048] [Batch 00112/01234] [00:01:13/00:12:16, 0.657s/it]: train_loss_raw=1.8119, running_loss=1.8577, LR=0.000100
[2025-08-25 22:50:27,001][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005056] [Batch 00120/01234] [00:01:18/00:12:11, 0.657s/it]: train_loss_raw=1.8023, running_loss=1.8562, LR=0.000100
[2025-08-25 22:50:32,176][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005064] [Batch 00128/01234] [00:01:24/00:12:05, 0.656s/it]: train_loss_raw=1.8874, running_loss=1.8568, LR=0.000100
[2025-08-25 22:50:37,246][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005072] [Batch 00136/01234] [00:01:29/00:11:59, 0.655s/it]: train_loss_raw=1.8757, running_loss=1.8579, LR=0.000100
[2025-08-25 22:50:42,309][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005080] [Batch 00144/01234] [00:01:34/00:11:52, 0.654s/it]: train_loss_raw=1.8511, running_loss=1.8566, LR=0.000100
[2025-08-25 22:50:47,636][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005088] [Batch 00152/01234] [00:01:39/00:11:48, 0.654s/it]: train_loss_raw=1.8444, running_loss=1.8562, LR=0.000100
[2025-08-25 22:50:53,074][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005096] [Batch 00160/01234] [00:01:44/00:11:44, 0.656s/it]: train_loss_raw=1.8047, running_loss=1.8540, LR=0.000100
[2025-08-25 22:50:58,569][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005104] [Batch 00168/01234] [00:01:50/00:11:40, 0.657s/it]: train_loss_raw=1.9341, running_loss=1.8524, LR=0.000100
[2025-08-25 22:51:04,076][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005112] [Batch 00176/01234] [00:01:55/00:11:36, 0.659s/it]: train_loss_raw=1.9093, running_loss=1.8520, LR=0.000100
[2025-08-25 22:51:09,244][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005120] [Batch 00184/01234] [00:02:01/00:11:30, 0.658s/it]: train_loss_raw=1.7894, running_loss=1.8524, LR=0.000100
[2025-08-25 22:51:14,842][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005128] [Batch 00192/01234] [00:02:06/00:11:27, 0.660s/it]: train_loss_raw=1.9300, running_loss=1.8502, LR=0.000100
[2025-08-25 22:51:20,169][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005136] [Batch 00200/01234] [00:02:12/00:11:22, 0.660s/it]: train_loss_raw=1.9529, running_loss=1.8508, LR=0.000100
[2025-08-25 22:51:25,268][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005144] [Batch 00208/01234] [00:02:17/00:11:16, 0.659s/it]: train_loss_raw=1.8128, running_loss=1.8506, LR=0.000100
[2025-08-25 22:51:30,368][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005152] [Batch 00216/01234] [00:02:22/00:11:10, 0.658s/it]: train_loss_raw=1.9037, running_loss=1.8498, LR=0.000100
[2025-08-25 22:51:35,553][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005160] [Batch 00224/01234] [00:02:27/00:11:04, 0.658s/it]: train_loss_raw=1.7646, running_loss=1.8506, LR=0.000100
[2025-08-25 22:51:41,310][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005168] [Batch 00232/01234] [00:02:33/00:11:01, 0.660s/it]: train_loss_raw=1.8414, running_loss=1.8489, LR=0.000100
[2025-08-25 22:51:46,516][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005176] [Batch 00240/01234] [00:02:38/00:10:55, 0.660s/it]: train_loss_raw=1.8328, running_loss=1.8481, LR=0.000100
[2025-08-25 22:51:51,884][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005184] [Batch 00248/01234] [00:02:43/00:10:50, 0.660s/it]: train_loss_raw=1.8198, running_loss=1.8449, LR=0.000100
[2025-08-25 22:51:57,878][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005192] [Batch 00256/01234] [00:02:49/00:10:48, 0.663s/it]: train_loss_raw=1.8727, running_loss=1.8437, LR=0.000100
[2025-08-25 22:52:03,465][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005200] [Batch 00264/01234] [00:02:55/00:10:44, 0.664s/it]: train_loss_raw=1.8911, running_loss=1.8450, LR=0.000100
[2025-08-25 22:52:08,974][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005208] [Batch 00272/01234] [00:03:00/00:10:39, 0.665s/it]: train_loss_raw=1.8609, running_loss=1.8452, LR=0.000100
[2025-08-25 22:52:14,281][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005216] [Batch 00280/01234] [00:03:06/00:10:34, 0.665s/it]: train_loss_raw=1.8966, running_loss=1.8440, LR=0.000100
[2025-08-25 22:52:19,525][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005224] [Batch 00288/01234] [00:03:11/00:10:28, 0.664s/it]: train_loss_raw=1.8667, running_loss=1.8442, LR=0.000100
[2025-08-25 22:52:24,630][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005232] [Batch 00296/01234] [00:03:16/00:10:22, 0.664s/it]: train_loss_raw=1.8739, running_loss=1.8447, LR=0.000100
[2025-08-25 22:52:30,263][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005240] [Batch 00304/01234] [00:03:22/00:10:18, 0.665s/it]: train_loss_raw=1.8632, running_loss=1.8440, LR=0.000100
[2025-08-25 22:52:36,211][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005248] [Batch 00312/01234] [00:03:28/00:10:14, 0.667s/it]: train_loss_raw=1.9534, running_loss=1.8442, LR=0.000100
[2025-08-25 22:52:41,774][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005256] [Batch 00320/01234] [00:03:33/00:10:10, 0.668s/it]: train_loss_raw=1.8766, running_loss=1.8435, LR=0.000100
[2025-08-25 22:52:47,441][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005264] [Batch 00328/01234] [00:03:39/00:10:05, 0.669s/it]: train_loss_raw=1.7738, running_loss=1.8404, LR=0.000100
[2025-08-25 22:52:52,835][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005272] [Batch 00336/01234] [00:03:44/00:10:00, 0.669s/it]: train_loss_raw=1.8321, running_loss=1.8395, LR=0.000100
[2025-08-25 22:52:58,275][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005280] [Batch 00344/01234] [00:03:50/00:09:55, 0.669s/it]: train_loss_raw=1.9682, running_loss=1.8411, LR=0.000100
[2025-08-25 22:53:03,420][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005288] [Batch 00352/01234] [00:03:55/00:09:49, 0.668s/it]: train_loss_raw=1.8820, running_loss=1.8426, LR=0.000100
[2025-08-25 22:53:09,166][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005296] [Batch 00360/01234] [00:04:01/00:09:45, 0.669s/it]: train_loss_raw=1.8058, running_loss=1.8413, LR=0.000100
[2025-08-25 22:53:14,855][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005304] [Batch 00368/01234] [00:04:06/00:09:40, 0.670s/it]: train_loss_raw=1.7570, running_loss=1.8388, LR=0.000100
[2025-08-25 22:53:20,603][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005312] [Batch 00376/01234] [00:04:12/00:09:36, 0.671s/it]: train_loss_raw=1.9000, running_loss=1.8396, LR=0.000100
[2025-08-25 22:53:26,302][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005320] [Batch 00384/01234] [00:04:18/00:09:31, 0.672s/it]: train_loss_raw=1.8266, running_loss=1.8404, LR=0.000100
[2025-08-25 22:53:31,966][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005328] [Batch 00392/01234] [00:04:23/00:09:26, 0.673s/it]: train_loss_raw=1.8014, running_loss=1.8391, LR=0.000100
[2025-08-25 22:53:37,557][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005336] [Batch 00400/01234] [00:04:29/00:09:21, 0.673s/it]: train_loss_raw=1.9029, running_loss=1.8396, LR=0.000100
[2025-08-25 22:53:42,661][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005344] [Batch 00408/01234] [00:04:34/00:09:15, 0.673s/it]: train_loss_raw=1.8358, running_loss=1.8384, LR=0.000100
[2025-08-25 22:53:47,936][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005352] [Batch 00416/01234] [00:04:39/00:09:10, 0.673s/it]: train_loss_raw=1.8780, running_loss=1.8356, LR=0.000100
[2025-08-25 22:53:53,264][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005360] [Batch 00424/01234] [00:04:45/00:09:04, 0.672s/it]: train_loss_raw=1.8206, running_loss=1.8376, LR=0.000100
[2025-08-25 22:53:59,031][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005368] [Batch 00432/01234] [00:04:50/00:08:59, 0.673s/it]: train_loss_raw=1.8642, running_loss=1.8357, LR=0.000100
[2025-08-25 22:54:04,545][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005376] [Batch 00440/01234] [00:04:56/00:08:54, 0.674s/it]: train_loss_raw=1.8752, running_loss=1.8347, LR=0.000100
[2025-08-25 22:54:09,791][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005384] [Batch 00448/01234] [00:05:01/00:08:49, 0.673s/it]: train_loss_raw=1.7230, running_loss=1.8316, LR=0.000100
[2025-08-25 22:54:15,040][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005392] [Batch 00456/01234] [00:05:06/00:08:43, 0.673s/it]: train_loss_raw=1.8757, running_loss=1.8317, LR=0.000100
[2025-08-25 22:54:20,074][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005400] [Batch 00464/01234] [00:05:11/00:08:37, 0.672s/it]: train_loss_raw=1.8393, running_loss=1.8326, LR=0.000100
[2025-08-25 22:54:25,106][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005408] [Batch 00472/01234] [00:05:16/00:08:31, 0.671s/it]: train_loss_raw=1.8348, running_loss=1.8315, LR=0.000100
[2025-08-25 22:54:30,792][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005416] [Batch 00480/01234] [00:05:22/00:08:26, 0.672s/it]: train_loss_raw=1.8940, running_loss=1.8325, LR=0.000100
[2025-08-25 22:54:36,086][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005424] [Batch 00488/01234] [00:05:27/00:08:21, 0.672s/it]: train_loss_raw=1.7942, running_loss=1.8302, LR=0.000100
[2025-08-25 22:54:41,128][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005432] [Batch 00496/01234] [00:05:32/00:08:15, 0.671s/it]: train_loss_raw=1.8588, running_loss=1.8295, LR=0.000100
[2025-08-25 22:54:46,167][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005440] [Batch 00504/01234] [00:05:38/00:08:09, 0.671s/it]: train_loss_raw=1.8496, running_loss=1.8286, LR=0.000100
[2025-08-25 22:54:51,710][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005448] [Batch 00512/01234] [00:05:43/00:08:04, 0.671s/it]: train_loss_raw=1.8681, running_loss=1.8317, LR=0.000100
[2025-08-25 22:54:57,003][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005456] [Batch 00520/01234] [00:05:48/00:07:58, 0.671s/it]: train_loss_raw=1.9355, running_loss=1.8346, LR=0.000100
[2025-08-25 22:55:02,326][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005464] [Batch 00528/01234] [00:05:54/00:07:53, 0.671s/it]: train_loss_raw=1.8314, running_loss=1.8349, LR=0.000100
[2025-08-25 22:55:07,380][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005472] [Batch 00536/01234] [00:05:59/00:07:47, 0.670s/it]: train_loss_raw=1.9042, running_loss=1.8342, LR=0.000100
[2025-08-25 22:55:12,425][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005480] [Batch 00544/01234] [00:06:04/00:07:42, 0.670s/it]: train_loss_raw=1.7294, running_loss=1.8328, LR=0.000100
[2025-08-25 22:55:17,465][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005488] [Batch 00552/01234] [00:06:09/00:07:36, 0.669s/it]: train_loss_raw=1.7777, running_loss=1.8324, LR=0.000100
[2025-08-25 22:55:22,804][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005496] [Batch 00560/01234] [00:06:14/00:07:30, 0.669s/it]: train_loss_raw=1.7980, running_loss=1.8317, LR=0.000100
[2025-08-25 22:55:28,203][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005504] [Batch 00568/01234] [00:06:20/00:07:25, 0.669s/it]: train_loss_raw=1.8510, running_loss=1.8324, LR=0.000100
[2025-08-25 22:55:33,251][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005512] [Batch 00576/01234] [00:06:25/00:07:19, 0.669s/it]: train_loss_raw=1.7713, running_loss=1.8316, LR=0.000100
[2025-08-25 22:55:38,310][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005520] [Batch 00584/01234] [00:06:30/00:07:14, 0.668s/it]: train_loss_raw=1.6438, running_loss=1.8293, LR=0.000100
[2025-08-25 22:55:43,369][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005528] [Batch 00592/01234] [00:06:35/00:07:08, 0.668s/it]: train_loss_raw=1.7670, running_loss=1.8289, LR=0.000100
[2025-08-25 22:55:48,661][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005536] [Batch 00600/01234] [00:06:40/00:07:03, 0.667s/it]: train_loss_raw=1.9011, running_loss=1.8298, LR=0.000100
[2025-08-25 22:55:53,704][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005544] [Batch 00608/01234] [00:06:45/00:06:57, 0.667s/it]: train_loss_raw=1.8881, running_loss=1.8308, LR=0.000100
[2025-08-25 22:55:59,293][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005552] [Batch 00616/01234] [00:06:51/00:06:52, 0.667s/it]: train_loss_raw=1.8936, running_loss=1.8295, LR=0.000100
[2025-08-25 22:56:04,459][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005560] [Batch 00624/01234] [00:06:56/00:06:46, 0.667s/it]: train_loss_raw=1.8724, running_loss=1.8296, LR=0.000100
[2025-08-25 22:56:09,849][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005568] [Batch 00632/01234] [00:07:01/00:06:41, 0.667s/it]: train_loss_raw=1.8736, running_loss=1.8319, LR=0.000100
[2025-08-25 22:56:14,888][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005576] [Batch 00640/01234] [00:07:06/00:06:36, 0.667s/it]: train_loss_raw=1.8249, running_loss=1.8318, LR=0.000100
[2025-08-25 22:56:20,281][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005584] [Batch 00648/01234] [00:07:12/00:06:30, 0.667s/it]: train_loss_raw=1.7567, running_loss=1.8319, LR=0.000100
[2025-08-25 22:56:26,289][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005592] [Batch 00656/01234] [00:07:18/00:06:26, 0.668s/it]: train_loss_raw=1.8693, running_loss=1.8329, LR=0.000100
[2025-08-25 22:56:32,274][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005600] [Batch 00664/01234] [00:07:24/00:06:21, 0.669s/it]: train_loss_raw=1.7306, running_loss=1.8338, LR=0.000100
[2025-08-25 22:56:37,784][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005608] [Batch 00672/01234] [00:07:29/00:06:16, 0.669s/it]: train_loss_raw=1.8829, running_loss=1.8337, LR=0.000100
[2025-08-25 22:56:43,561][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005616] [Batch 00680/01234] [00:07:35/00:06:11, 0.670s/it]: train_loss_raw=1.8412, running_loss=1.8329, LR=0.000100
[2025-08-25 22:56:49,328][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005624] [Batch 00688/01234] [00:07:41/00:06:05, 0.670s/it]: train_loss_raw=1.7821, running_loss=1.8318, LR=0.000100
[2025-08-25 22:56:54,495][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005632] [Batch 00696/01234] [00:07:46/00:06:00, 0.670s/it]: train_loss_raw=1.8475, running_loss=1.8318, LR=0.000100
[2025-08-25 22:57:00,338][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005640] [Batch 00704/01234] [00:07:52/00:05:55, 0.671s/it]: train_loss_raw=1.8057, running_loss=1.8325, LR=0.000100
[2025-08-25 22:57:05,608][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005648] [Batch 00712/01234] [00:07:57/00:05:50, 0.671s/it]: train_loss_raw=1.8040, running_loss=1.8323, LR=0.000100
[2025-08-25 22:57:11,806][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005656] [Batch 00720/01234] [00:08:03/00:05:45, 0.672s/it]: train_loss_raw=1.8474, running_loss=1.8318, LR=0.000100
[2025-08-25 22:57:16,932][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005664] [Batch 00728/01234] [00:08:08/00:05:39, 0.671s/it]: train_loss_raw=1.8286, running_loss=1.8313, LR=0.000100
[2025-08-25 22:57:21,967][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005672] [Batch 00736/01234] [00:08:13/00:05:34, 0.671s/it]: train_loss_raw=1.9207, running_loss=1.8337, LR=0.000100
[2025-08-25 22:57:27,007][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005680] [Batch 00744/01234] [00:08:18/00:05:28, 0.670s/it]: train_loss_raw=1.8850, running_loss=1.8333, LR=0.000100
[2025-08-25 22:57:32,633][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005688] [Batch 00752/01234] [00:08:24/00:05:23, 0.671s/it]: train_loss_raw=1.8870, running_loss=1.8334, LR=0.000100
[2025-08-25 22:57:37,906][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005696] [Batch 00760/01234] [00:08:29/00:05:17, 0.671s/it]: train_loss_raw=1.8423, running_loss=1.8336, LR=0.000100
[2025-08-25 22:57:43,095][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005704] [Batch 00768/01234] [00:08:34/00:05:12, 0.670s/it]: train_loss_raw=1.8340, running_loss=1.8324, LR=0.000100
[2025-08-25 22:57:48,129][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005712] [Batch 00776/01234] [00:08:39/00:05:06, 0.670s/it]: train_loss_raw=1.7746, running_loss=1.8310, LR=0.000100
[2025-08-25 22:57:53,486][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005720] [Batch 00784/01234] [00:08:45/00:05:01, 0.670s/it]: train_loss_raw=1.6983, running_loss=1.8289, LR=0.000100
[2025-08-25 22:57:59,312][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005728] [Batch 00792/01234] [00:08:51/00:04:56, 0.671s/it]: train_loss_raw=1.8544, running_loss=1.8279, LR=0.000100
[2025-08-25 22:58:05,191][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005736] [Batch 00800/01234] [00:08:57/00:04:51, 0.671s/it]: train_loss_raw=1.8622, running_loss=1.8297, LR=0.000100
[2025-08-25 22:58:11,226][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005744] [Batch 00808/01234] [00:09:03/00:04:46, 0.672s/it]: train_loss_raw=1.7962, running_loss=1.8269, LR=0.000100
[2025-08-25 22:58:16,529][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005752] [Batch 00816/01234] [00:09:08/00:04:40, 0.672s/it]: train_loss_raw=1.7372, running_loss=1.8265, LR=0.000100
[2025-08-25 22:58:22,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005760] [Batch 00824/01234] [00:09:14/00:04:35, 0.673s/it]: train_loss_raw=1.7262, running_loss=1.8244, LR=0.000100
[2025-08-25 22:58:27,817][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005768] [Batch 00832/01234] [00:09:19/00:04:30, 0.673s/it]: train_loss_raw=1.8360, running_loss=1.8263, LR=0.000100
[2025-08-25 22:58:32,987][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005776] [Batch 00840/01234] [00:09:24/00:04:24, 0.672s/it]: train_loss_raw=1.8306, running_loss=1.8261, LR=0.000100
[2025-08-25 22:58:38,167][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005784] [Batch 00848/01234] [00:09:30/00:04:19, 0.672s/it]: train_loss_raw=1.8866, running_loss=1.8265, LR=0.000100
[2025-08-25 22:58:43,363][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005792] [Batch 00856/01234] [00:09:35/00:04:14, 0.672s/it]: train_loss_raw=1.8715, running_loss=1.8243, LR=0.000100
[2025-08-25 22:58:48,929][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005800] [Batch 00864/01234] [00:09:40/00:04:08, 0.672s/it]: train_loss_raw=1.8439, running_loss=1.8241, LR=0.000100
[2025-08-25 22:58:54,226][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005808] [Batch 00872/01234] [00:09:46/00:04:03, 0.672s/it]: train_loss_raw=1.8499, running_loss=1.8238, LR=0.000100
[2025-08-25 22:58:59,744][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005816] [Batch 00880/01234] [00:09:51/00:03:57, 0.672s/it]: train_loss_raw=1.7991, running_loss=1.8238, LR=0.000100
[2025-08-25 22:59:04,849][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005824] [Batch 00888/01234] [00:09:56/00:03:52, 0.672s/it]: train_loss_raw=1.8248, running_loss=1.8222, LR=0.000100
[2025-08-25 22:59:10,179][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005832] [Batch 00896/01234] [00:10:02/00:03:47, 0.672s/it]: train_loss_raw=1.8484, running_loss=1.8222, LR=0.000100
[2025-08-25 22:59:15,306][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005840] [Batch 00904/01234] [00:10:07/00:03:41, 0.672s/it]: train_loss_raw=1.7693, running_loss=1.8231, LR=0.000100
[2025-08-25 22:59:20,948][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005848] [Batch 00912/01234] [00:10:12/00:03:36, 0.672s/it]: train_loss_raw=1.8570, running_loss=1.8257, LR=0.000100
[2025-08-25 22:59:26,475][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005856] [Batch 00920/01234] [00:10:18/00:03:31, 0.672s/it]: train_loss_raw=1.8553, running_loss=1.8264, LR=0.000100
[2025-08-25 22:59:31,562][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005864] [Batch 00928/01234] [00:10:23/00:03:25, 0.672s/it]: train_loss_raw=1.7701, running_loss=1.8245, LR=0.000100
[2025-08-25 22:59:36,692][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005872] [Batch 00936/01234] [00:10:28/00:03:20, 0.672s/it]: train_loss_raw=1.8039, running_loss=1.8235, LR=0.000100
[2025-08-25 22:59:42,088][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005880] [Batch 00944/01234] [00:10:33/00:03:14, 0.672s/it]: train_loss_raw=1.7428, running_loss=1.8212, LR=0.000100
[2025-08-25 22:59:47,591][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005888] [Batch 00952/01234] [00:10:39/00:03:09, 0.672s/it]: train_loss_raw=1.7963, running_loss=1.8198, LR=0.000100
[2025-08-25 22:59:53,177][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005896] [Batch 00960/01234] [00:10:45/00:03:04, 0.672s/it]: train_loss_raw=1.8021, running_loss=1.8215, LR=0.000100
[2025-08-25 22:59:58,236][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005904] [Batch 00968/01234] [00:10:50/00:02:58, 0.672s/it]: train_loss_raw=1.8919, running_loss=1.8220, LR=0.000100
[2025-08-25 23:00:03,865][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005912] [Batch 00976/01234] [00:10:55/00:02:53, 0.672s/it]: train_loss_raw=1.8298, running_loss=1.8213, LR=0.000100
[2025-08-25 23:00:08,972][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005920] [Batch 00984/01234] [00:11:00/00:02:47, 0.672s/it]: train_loss_raw=1.8189, running_loss=1.8202, LR=0.000100
[2025-08-25 23:00:14,460][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005928] [Batch 00992/01234] [00:11:06/00:02:42, 0.672s/it]: train_loss_raw=1.8487, running_loss=1.8207, LR=0.000100
[2025-08-25 23:00:20,167][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005936] [Batch 01000/01234] [00:11:12/00:02:37, 0.672s/it]: train_loss_raw=1.8406, running_loss=1.8197, LR=0.000100
[2025-08-25 23:00:25,285][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005944] [Batch 01008/01234] [00:11:17/00:02:31, 0.672s/it]: train_loss_raw=1.8661, running_loss=1.8213, LR=0.000100
[2025-08-25 23:00:30,857][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005952] [Batch 01016/01234] [00:11:22/00:02:26, 0.672s/it]: train_loss_raw=1.8217, running_loss=1.8191, LR=0.000100
[2025-08-25 23:00:36,463][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005960] [Batch 01024/01234] [00:11:28/00:02:21, 0.672s/it]: train_loss_raw=1.7553, running_loss=1.8175, LR=0.000100
[2025-08-25 23:00:41,526][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005968] [Batch 01032/01234] [00:11:33/00:02:15, 0.672s/it]: train_loss_raw=1.7256, running_loss=1.8165, LR=0.000100
[2025-08-25 23:00:46,610][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005976] [Batch 01040/01234] [00:11:38/00:02:10, 0.672s/it]: train_loss_raw=1.8233, running_loss=1.8172, LR=0.000100
[2025-08-25 23:00:51,848][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005984] [Batch 01048/01234] [00:11:43/00:02:04, 0.671s/it]: train_loss_raw=1.8558, running_loss=1.8144, LR=0.000100
[2025-08-25 23:00:56,872][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 005992] [Batch 01056/01234] [00:11:48/00:01:59, 0.671s/it]: train_loss_raw=1.7977, running_loss=1.8135, LR=0.000100
[2025-08-25 23:01:02,515][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006000] [Batch 01064/01234] [00:11:54/00:01:54, 0.671s/it]: train_loss_raw=1.8107, running_loss=1.8115, LR=0.000100
[2025-08-25 23:01:11,713][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006008] [Batch 01072/01234] [00:12:03/00:01:49, 0.675s/it]: train_loss_raw=1.8851, running_loss=1.8131, LR=0.000100
[2025-08-25 23:01:16,930][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006016] [Batch 01080/01234] [00:12:08/00:01:43, 0.675s/it]: train_loss_raw=1.7315, running_loss=1.8115, LR=0.000100
[2025-08-25 23:01:22,390][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006024] [Batch 01088/01234] [00:12:14/00:01:38, 0.675s/it]: train_loss_raw=1.8479, running_loss=1.8127, LR=0.000100
[2025-08-25 23:01:27,541][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006032] [Batch 01096/01234] [00:12:19/00:01:33, 0.675s/it]: train_loss_raw=1.9437, running_loss=1.8157, LR=0.000100
[2025-08-25 23:01:32,899][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006040] [Batch 01104/01234] [00:12:24/00:01:27, 0.675s/it]: train_loss_raw=1.8310, running_loss=1.8166, LR=0.000100
[2025-08-25 23:01:37,969][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006048] [Batch 01112/01234] [00:12:29/00:01:22, 0.674s/it]: train_loss_raw=1.7662, running_loss=1.8169, LR=0.000100
[2025-08-25 23:01:43,317][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006056] [Batch 01120/01234] [00:12:35/00:01:16, 0.674s/it]: train_loss_raw=1.8671, running_loss=1.8146, LR=0.000100
[2025-08-25 23:01:48,612][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006064] [Batch 01128/01234] [00:12:40/00:01:11, 0.674s/it]: train_loss_raw=1.7777, running_loss=1.8126, LR=0.000100
[2025-08-25 23:01:54,148][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006072] [Batch 01136/01234] [00:12:45/00:01:06, 0.674s/it]: train_loss_raw=1.8794, running_loss=1.8130, LR=0.000100
[2025-08-25 23:01:59,410][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006080] [Batch 01144/01234] [00:12:51/00:01:00, 0.674s/it]: train_loss_raw=1.7777, running_loss=1.8124, LR=0.000100
[2025-08-25 23:02:05,097][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006088] [Batch 01152/01234] [00:12:56/00:00:55, 0.674s/it]: train_loss_raw=1.8184, running_loss=1.8141, LR=0.000100
[2025-08-25 23:02:10,164][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006096] [Batch 01160/01234] [00:13:01/00:00:49, 0.674s/it]: train_loss_raw=1.8391, running_loss=1.8137, LR=0.000100
[2025-08-25 23:02:15,576][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006104] [Batch 01168/01234] [00:13:07/00:00:44, 0.674s/it]: train_loss_raw=1.8396, running_loss=1.8150, LR=0.000100
[2025-08-25 23:02:21,202][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006112] [Batch 01176/01234] [00:13:13/00:00:39, 0.674s/it]: train_loss_raw=1.8484, running_loss=1.8156, LR=0.000100
[2025-08-25 23:02:26,246][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006120] [Batch 01184/01234] [00:13:18/00:00:33, 0.674s/it]: train_loss_raw=1.7861, running_loss=1.8143, LR=0.000100
[2025-08-25 23:02:31,683][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006128] [Batch 01192/01234] [00:13:23/00:00:28, 0.674s/it]: train_loss_raw=1.8098, running_loss=1.8144, LR=0.000100
[2025-08-25 23:02:37,010][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006136] [Batch 01200/01234] [00:13:28/00:00:22, 0.674s/it]: train_loss_raw=1.8671, running_loss=1.8142, LR=0.000100
[2025-08-25 23:02:42,070][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006144] [Batch 01208/01234] [00:13:33/00:00:17, 0.674s/it]: train_loss_raw=1.8098, running_loss=1.8129, LR=0.000100
[2025-08-25 23:02:47,145][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006152] [Batch 01216/01234] [00:13:38/00:00:12, 0.674s/it]: train_loss_raw=1.7663, running_loss=1.8129, LR=0.000100
[2025-08-25 23:02:52,406][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006160] [Batch 01224/01234] [00:13:44/00:00:06, 0.673s/it]: train_loss_raw=1.9068, running_loss=1.8131, LR=0.000100
[2025-08-25 23:02:57,570][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 006168] [Batch 01232/01234] [00:13:49/00:00:01, 0.673s/it]: train_loss_raw=1.7767, running_loss=1.8104, LR=0.000100
[2025-08-25 23:03:03,990][__main__][INFO] - [VALIDATION] [Epoch 04/29] Starting validation.
[2025-08-25 23:03:14,039][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 006171] [Batch 00007/00026] [00:00:10/00:00:22, 1.256s/it]
[2025-08-25 23:03:24,753][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 006171] [Batch 00015/00026] [00:00:20/00:00:12, 1.298s/it]
[2025-08-25 23:03:35,052][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 006171] [Batch 00023/00026] [00:00:31/00:00:02, 1.294s/it]
[2025-08-25 23:03:37,381][__main__][INFO] - [VALIDATION] [Epoch 04/29] train_loss=1.81022, valid_loss=1.82522
[2025-08-25 23:03:37,382][__main__][INFO] - [VALIDATION] [Epoch 04/29] Metrics:
[2025-08-25 23:03:37,382][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_er      0.767
[2025-08-25 23:03:37,382][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_prec    0.027
[2025-08-25 23:03:37,383][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_recall  0.029
[2025-08-25 23:03:37,383][__main__][INFO] - [VALIDATION] [Epoch 04/29] - pep_recall 0.001
[2025-08-25 23:03:37,386][__main__][INFO] - [TRAIN] [Epoch 04/29] Epoch complete, total time 01:12:46, remaining time 06:03:52, 00:14:33 per epoch
[2025-08-25 23:03:41,274][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006176] [Batch 00006/01234] [00:00:03/00:12:43, 0.622s/it]: train_loss_raw=1.7708, running_loss=1.8068, LR=0.000100
[2025-08-25 23:03:46,880][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006184] [Batch 00014/01234] [00:00:09/00:13:33, 0.667s/it]: train_loss_raw=1.8657, running_loss=1.8054, LR=0.000100
[2025-08-25 23:03:52,211][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006192] [Batch 00022/01234] [00:00:14/00:13:28, 0.667s/it]: train_loss_raw=1.8901, running_loss=1.8040, LR=0.000100
[2025-08-25 23:03:58,324][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006200] [Batch 00030/01234] [00:00:20/00:13:54, 0.693s/it]: train_loss_raw=1.7979, running_loss=1.8037, LR=0.000100
[2025-08-25 23:04:04,123][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006208] [Batch 00038/01234] [00:00:26/00:13:56, 0.700s/it]: train_loss_raw=1.8069, running_loss=1.8031, LR=0.000100
[2025-08-25 23:04:09,749][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006216] [Batch 00046/01234] [00:00:32/00:13:51, 0.700s/it]: train_loss_raw=1.7952, running_loss=1.7986, LR=0.000100
[2025-08-25 23:04:15,589][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006224] [Batch 00054/01234] [00:00:38/00:13:51, 0.705s/it]: train_loss_raw=1.8146, running_loss=1.7989, LR=0.000100
[2025-08-25 23:04:21,432][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006232] [Batch 00062/01234] [00:00:43/00:13:49, 0.708s/it]: train_loss_raw=1.7727, running_loss=1.7975, LR=0.000100
[2025-08-25 23:04:26,882][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006240] [Batch 00070/01234] [00:00:49/00:13:40, 0.705s/it]: train_loss_raw=1.7554, running_loss=1.7962, LR=0.000100
[2025-08-25 23:04:31,952][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006248] [Batch 00078/01234] [00:00:54/00:13:26, 0.698s/it]: train_loss_raw=1.8103, running_loss=1.7949, LR=0.000100
[2025-08-25 23:04:37,493][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006256] [Batch 00086/01234] [00:00:59/00:13:20, 0.697s/it]: train_loss_raw=1.7290, running_loss=1.7925, LR=0.000100
[2025-08-25 23:04:43,116][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006264] [Batch 00094/01234] [00:01:05/00:13:15, 0.698s/it]: train_loss_raw=1.8607, running_loss=1.7922, LR=0.000100
[2025-08-25 23:04:48,606][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006272] [Batch 00102/01234] [00:01:11/00:13:08, 0.697s/it]: train_loss_raw=1.7712, running_loss=1.7909, LR=0.000100
[2025-08-25 23:04:53,669][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006280] [Batch 00110/01234] [00:01:16/00:12:57, 0.692s/it]: train_loss_raw=1.8596, running_loss=1.7903, LR=0.000100
[2025-08-25 23:04:58,713][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006288] [Batch 00118/01234] [00:01:21/00:12:47, 0.688s/it]: train_loss_raw=1.7793, running_loss=1.7909, LR=0.000100
[2025-08-25 23:05:04,115][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006296] [Batch 00126/01234] [00:01:26/00:12:41, 0.687s/it]: train_loss_raw=1.7451, running_loss=1.7900, LR=0.000100
[2025-08-25 23:05:09,287][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006304] [Batch 00134/01234] [00:01:31/00:12:33, 0.685s/it]: train_loss_raw=1.8177, running_loss=1.7886, LR=0.000100
[2025-08-25 23:05:14,323][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006312] [Batch 00142/01234] [00:01:36/00:12:24, 0.682s/it]: train_loss_raw=1.7564, running_loss=1.7872, LR=0.000100
[2025-08-25 23:05:19,359][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006320] [Batch 00150/01234] [00:01:41/00:12:15, 0.679s/it]: train_loss_raw=1.7829, running_loss=1.7875, LR=0.000100
[2025-08-25 23:05:24,824][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006328] [Batch 00158/01234] [00:01:47/00:12:10, 0.679s/it]: train_loss_raw=1.7724, running_loss=1.7880, LR=0.000100
[2025-08-25 23:05:30,334][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006336] [Batch 00166/01234] [00:01:52/00:12:05, 0.679s/it]: train_loss_raw=1.7683, running_loss=1.7866, LR=0.000100
[2025-08-25 23:05:35,805][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006344] [Batch 00174/01234] [00:01:58/00:12:00, 0.680s/it]: train_loss_raw=1.8484, running_loss=1.7872, LR=0.000100
[2025-08-25 23:05:41,413][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006352] [Batch 00182/01234] [00:02:03/00:11:55, 0.681s/it]: train_loss_raw=1.7583, running_loss=1.7885, LR=0.000100
[2025-08-25 23:05:47,191][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006360] [Batch 00190/01234] [00:02:09/00:11:52, 0.682s/it]: train_loss_raw=1.8585, running_loss=1.7882, LR=0.000100
[2025-08-25 23:05:52,656][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006368] [Batch 00198/01234] [00:02:15/00:11:46, 0.682s/it]: train_loss_raw=1.6916, running_loss=1.7867, LR=0.000100
[2025-08-25 23:05:58,224][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006376] [Batch 00206/01234] [00:02:20/00:11:42, 0.683s/it]: train_loss_raw=1.7605, running_loss=1.7867, LR=0.000100
[2025-08-25 23:06:03,940][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006384] [Batch 00214/01234] [00:02:26/00:11:37, 0.684s/it]: train_loss_raw=1.8376, running_loss=1.7887, LR=0.000100
[2025-08-25 23:06:09,594][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006392] [Batch 00222/01234] [00:02:32/00:11:33, 0.685s/it]: train_loss_raw=1.7631, running_loss=1.7871, LR=0.000100
[2025-08-25 23:06:15,042][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006400] [Batch 00230/01234] [00:02:37/00:11:27, 0.685s/it]: train_loss_raw=1.7852, running_loss=1.7853, LR=0.000100
[2025-08-25 23:06:20,300][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006408] [Batch 00238/01234] [00:02:42/00:11:21, 0.684s/it]: train_loss_raw=1.7275, running_loss=1.7822, LR=0.000100
[2025-08-25 23:06:25,813][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006416] [Batch 00246/01234] [00:02:48/00:11:15, 0.684s/it]: train_loss_raw=1.7411, running_loss=1.7784, LR=0.000100
[2025-08-25 23:06:31,548][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006424] [Batch 00254/01234] [00:02:54/00:11:11, 0.685s/it]: train_loss_raw=1.8299, running_loss=1.7798, LR=0.000100
[2025-08-25 23:06:36,940][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006432] [Batch 00262/01234] [00:02:59/00:11:05, 0.685s/it]: train_loss_raw=1.7384, running_loss=1.7790, LR=0.000100
[2025-08-25 23:06:42,041][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006440] [Batch 00270/01234] [00:03:04/00:10:58, 0.683s/it]: train_loss_raw=1.7605, running_loss=1.7784, LR=0.000100
[2025-08-25 23:06:47,248][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006448] [Batch 00278/01234] [00:03:09/00:10:52, 0.682s/it]: train_loss_raw=1.7838, running_loss=1.7782, LR=0.000100
[2025-08-25 23:06:53,089][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006456] [Batch 00286/01234] [00:03:15/00:10:48, 0.684s/it]: train_loss_raw=1.8013, running_loss=1.7780, LR=0.000100
[2025-08-25 23:06:58,364][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006464] [Batch 00294/01234] [00:03:20/00:10:42, 0.683s/it]: train_loss_raw=1.7927, running_loss=1.7782, LR=0.000100
[2025-08-25 23:07:04,064][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006472] [Batch 00302/01234] [00:03:26/00:10:37, 0.684s/it]: train_loss_raw=1.7278, running_loss=1.7781, LR=0.000100
[2025-08-25 23:07:09,742][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006480] [Batch 00310/01234] [00:03:32/00:10:32, 0.685s/it]: train_loss_raw=1.8030, running_loss=1.7769, LR=0.000100
[2025-08-25 23:07:15,148][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006488] [Batch 00318/01234] [00:03:37/00:10:26, 0.684s/it]: train_loss_raw=1.7758, running_loss=1.7751, LR=0.000100
[2025-08-25 23:07:20,389][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006496] [Batch 00326/01234] [00:03:42/00:10:20, 0.684s/it]: train_loss_raw=1.7173, running_loss=1.7730, LR=0.000100
[2025-08-25 23:07:25,951][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006504] [Batch 00334/01234] [00:03:48/00:10:15, 0.684s/it]: train_loss_raw=1.8053, running_loss=1.7722, LR=0.000100
[2025-08-25 23:07:32,015][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006512] [Batch 00342/01234] [00:03:54/00:10:11, 0.686s/it]: train_loss_raw=1.8474, running_loss=1.7713, LR=0.000100
[2025-08-25 23:07:38,091][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006520] [Batch 00350/01234] [00:04:00/00:10:07, 0.687s/it]: train_loss_raw=1.8274, running_loss=1.7733, LR=0.000100
[2025-08-25 23:07:43,835][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006528] [Batch 00358/01234] [00:04:06/00:10:02, 0.688s/it]: train_loss_raw=1.7793, running_loss=1.7717, LR=0.000100
[2025-08-25 23:07:49,273][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006536] [Batch 00366/01234] [00:04:11/00:09:57, 0.688s/it]: train_loss_raw=1.7510, running_loss=1.7709, LR=0.000100
[2025-08-25 23:07:54,489][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006544] [Batch 00374/01234] [00:04:16/00:09:50, 0.687s/it]: train_loss_raw=1.6740, running_loss=1.7729, LR=0.000100
[2025-08-25 23:07:59,616][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006552] [Batch 00382/01234] [00:04:22/00:09:44, 0.686s/it]: train_loss_raw=1.6445, running_loss=1.7724, LR=0.000100
[2025-08-25 23:08:05,385][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006560] [Batch 00390/01234] [00:04:27/00:09:39, 0.687s/it]: train_loss_raw=1.7065, running_loss=1.7732, LR=0.000100
[2025-08-25 23:08:11,236][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006568] [Batch 00398/01234] [00:04:33/00:09:34, 0.688s/it]: train_loss_raw=1.6956, running_loss=1.7711, LR=0.000100
[2025-08-25 23:08:16,604][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006576] [Batch 00406/01234] [00:04:39/00:09:29, 0.687s/it]: train_loss_raw=1.7899, running_loss=1.7684, LR=0.000100
[2025-08-25 23:08:22,350][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006584] [Batch 00414/01234] [00:04:44/00:09:24, 0.688s/it]: train_loss_raw=1.7944, running_loss=1.7697, LR=0.000100
[2025-08-25 23:08:28,078][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006592] [Batch 00422/01234] [00:04:50/00:09:19, 0.688s/it]: train_loss_raw=1.8195, running_loss=1.7693, LR=0.000100
[2025-08-25 23:08:33,208][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006600] [Batch 00430/01234] [00:04:55/00:09:12, 0.688s/it]: train_loss_raw=1.7523, running_loss=1.7686, LR=0.000100
[2025-08-25 23:08:38,969][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006608] [Batch 00438/01234] [00:05:01/00:09:07, 0.688s/it]: train_loss_raw=1.7613, running_loss=1.7684, LR=0.000100
[2025-08-25 23:08:44,504][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006616] [Batch 00446/01234] [00:05:06/00:09:02, 0.688s/it]: train_loss_raw=1.6728, running_loss=1.7693, LR=0.000100
[2025-08-25 23:08:50,418][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006624] [Batch 00454/01234] [00:05:12/00:08:57, 0.689s/it]: train_loss_raw=1.7737, running_loss=1.7705, LR=0.000100
[2025-08-25 23:08:55,822][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006632] [Batch 00462/01234] [00:05:18/00:08:51, 0.689s/it]: train_loss_raw=1.6515, running_loss=1.7687, LR=0.000100
[2025-08-25 23:09:01,064][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006640] [Batch 00470/01234] [00:05:23/00:08:45, 0.688s/it]: train_loss_raw=1.7893, running_loss=1.7706, LR=0.000100
[2025-08-25 23:09:06,299][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006648] [Batch 00478/01234] [00:05:28/00:08:39, 0.688s/it]: train_loss_raw=1.8490, running_loss=1.7730, LR=0.000100
[2025-08-25 23:09:11,883][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006656] [Batch 00486/01234] [00:05:34/00:08:34, 0.688s/it]: train_loss_raw=1.7870, running_loss=1.7734, LR=0.000100
[2025-08-25 23:09:17,814][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006664] [Batch 00494/01234] [00:05:40/00:08:29, 0.689s/it]: train_loss_raw=1.7527, running_loss=1.7712, LR=0.000100
[2025-08-25 23:09:23,480][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006672] [Batch 00502/01234] [00:05:45/00:08:24, 0.689s/it]: train_loss_raw=1.8534, running_loss=1.7720, LR=0.000100
[2025-08-25 23:09:29,224][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006680] [Batch 00510/01234] [00:05:51/00:08:19, 0.690s/it]: train_loss_raw=1.9196, running_loss=1.7719, LR=0.000100
[2025-08-25 23:09:35,031][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006688] [Batch 00518/01234] [00:05:57/00:08:14, 0.690s/it]: train_loss_raw=1.7377, running_loss=1.7702, LR=0.000100
[2025-08-25 23:09:40,520][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006696] [Batch 00526/01234] [00:06:02/00:08:08, 0.690s/it]: train_loss_raw=1.8198, running_loss=1.7710, LR=0.000100
[2025-08-25 23:09:45,755][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006704] [Batch 00534/01234] [00:06:08/00:08:02, 0.690s/it]: train_loss_raw=1.8571, running_loss=1.7711, LR=0.000100
[2025-08-25 23:09:50,909][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006712] [Batch 00542/01234] [00:06:13/00:07:56, 0.689s/it]: train_loss_raw=1.7608, running_loss=1.7694, LR=0.000100
[2025-08-25 23:09:56,573][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006720] [Batch 00550/01234] [00:06:19/00:07:51, 0.689s/it]: train_loss_raw=1.7651, running_loss=1.7699, LR=0.000100
[2025-08-25 23:10:01,909][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006728] [Batch 00558/01234] [00:06:24/00:07:45, 0.689s/it]: train_loss_raw=1.8293, running_loss=1.7709, LR=0.000100
[2025-08-25 23:10:07,525][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006736] [Batch 00566/01234] [00:06:29/00:07:40, 0.689s/it]: train_loss_raw=1.7566, running_loss=1.7720, LR=0.000100
[2025-08-25 23:10:13,131][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006744] [Batch 00574/01234] [00:06:35/00:07:34, 0.689s/it]: train_loss_raw=1.7340, running_loss=1.7730, LR=0.000100
[2025-08-25 23:10:19,348][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006752] [Batch 00582/01234] [00:06:41/00:07:30, 0.690s/it]: train_loss_raw=1.7506, running_loss=1.7720, LR=0.000100
[2025-08-25 23:10:25,216][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006760] [Batch 00590/01234] [00:06:47/00:07:24, 0.691s/it]: train_loss_raw=1.6337, running_loss=1.7694, LR=0.000100
[2025-08-25 23:10:30,991][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006768] [Batch 00598/01234] [00:06:53/00:07:19, 0.691s/it]: train_loss_raw=1.8048, running_loss=1.7683, LR=0.000100
[2025-08-25 23:10:36,817][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006776] [Batch 00606/01234] [00:06:59/00:07:14, 0.692s/it]: train_loss_raw=1.7804, running_loss=1.7687, LR=0.000100
[2025-08-25 23:10:42,725][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006784] [Batch 00614/01234] [00:07:05/00:07:09, 0.692s/it]: train_loss_raw=1.7367, running_loss=1.7682, LR=0.000100
[2025-08-25 23:10:48,205][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006792] [Batch 00622/01234] [00:07:10/00:07:03, 0.692s/it]: train_loss_raw=1.7315, running_loss=1.7678, LR=0.000100
[2025-08-25 23:10:53,294][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006800] [Batch 00630/01234] [00:07:15/00:06:57, 0.692s/it]: train_loss_raw=1.7698, running_loss=1.7668, LR=0.000100
[2025-08-25 23:10:58,744][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006808] [Batch 00638/01234] [00:07:21/00:06:52, 0.692s/it]: train_loss_raw=1.8312, running_loss=1.7685, LR=0.000100
[2025-08-25 23:11:04,662][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006816] [Batch 00646/01234] [00:07:27/00:06:46, 0.692s/it]: train_loss_raw=1.7519, running_loss=1.7690, LR=0.000100
[2025-08-25 23:11:10,488][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006824] [Batch 00654/01234] [00:07:32/00:06:41, 0.693s/it]: train_loss_raw=1.7365, running_loss=1.7694, LR=0.000100
[2025-08-25 23:11:16,222][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006832] [Batch 00662/01234] [00:07:38/00:06:36, 0.693s/it]: train_loss_raw=1.7917, running_loss=1.7694, LR=0.000100
[2025-08-25 23:11:21,832][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006840] [Batch 00670/01234] [00:07:44/00:06:30, 0.693s/it]: train_loss_raw=1.6783, running_loss=1.7669, LR=0.000100
[2025-08-25 23:11:27,471][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006848] [Batch 00678/01234] [00:07:49/00:06:25, 0.693s/it]: train_loss_raw=1.8058, running_loss=1.7669, LR=0.000100
[2025-08-25 23:11:33,140][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006856] [Batch 00686/01234] [00:07:55/00:06:19, 0.693s/it]: train_loss_raw=1.8379, running_loss=1.7672, LR=0.000100
[2025-08-25 23:11:38,877][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006864] [Batch 00694/01234] [00:08:01/00:06:14, 0.694s/it]: train_loss_raw=1.6801, running_loss=1.7661, LR=0.000100
[2025-08-25 23:11:44,769][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006872] [Batch 00702/01234] [00:08:07/00:06:09, 0.694s/it]: train_loss_raw=1.8060, running_loss=1.7659, LR=0.000100
[2025-08-25 23:11:50,438][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006880] [Batch 00710/01234] [00:08:12/00:06:03, 0.694s/it]: train_loss_raw=1.7661, running_loss=1.7644, LR=0.000100
[2025-08-25 23:11:55,540][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006888] [Batch 00718/01234] [00:08:17/00:05:57, 0.694s/it]: train_loss_raw=1.7661, running_loss=1.7644, LR=0.000100
[2025-08-25 23:12:00,925][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006896] [Batch 00726/01234] [00:08:23/00:05:52, 0.693s/it]: train_loss_raw=1.8270, running_loss=1.7650, LR=0.000100
[2025-08-25 23:12:06,032][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006904] [Batch 00734/01234] [00:08:28/00:05:46, 0.693s/it]: train_loss_raw=1.7348, running_loss=1.7633, LR=0.000100
[2025-08-25 23:12:11,797][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006912] [Batch 00742/01234] [00:08:34/00:05:40, 0.693s/it]: train_loss_raw=1.8503, running_loss=1.7646, LR=0.000100
[2025-08-25 23:12:17,255][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006920] [Batch 00750/01234] [00:08:39/00:05:35, 0.693s/it]: train_loss_raw=1.7380, running_loss=1.7639, LR=0.000100
[2025-08-25 23:12:22,987][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006928] [Batch 00758/01234] [00:08:45/00:05:29, 0.693s/it]: train_loss_raw=1.6697, running_loss=1.7632, LR=0.000100
[2025-08-25 23:12:28,933][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006936] [Batch 00766/01234] [00:08:51/00:05:24, 0.694s/it]: train_loss_raw=1.7250, running_loss=1.7623, LR=0.000100
[2025-08-25 23:12:34,743][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006944] [Batch 00774/01234] [00:08:57/00:05:19, 0.694s/it]: train_loss_raw=1.7648, running_loss=1.7618, LR=0.000100
[2025-08-25 23:12:40,444][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006952] [Batch 00782/01234] [00:09:02/00:05:13, 0.694s/it]: train_loss_raw=1.7287, running_loss=1.7616, LR=0.000100
[2025-08-25 23:12:46,430][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006960] [Batch 00790/01234] [00:09:08/00:05:08, 0.695s/it]: train_loss_raw=1.7804, running_loss=1.7622, LR=0.000100
[2025-08-25 23:12:52,325][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006968] [Batch 00798/01234] [00:09:14/00:05:03, 0.695s/it]: train_loss_raw=1.7453, running_loss=1.7627, LR=0.000100
[2025-08-25 23:12:57,643][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006976] [Batch 00806/01234] [00:09:20/00:04:57, 0.695s/it]: train_loss_raw=1.7476, running_loss=1.7617, LR=0.000100
[2025-08-25 23:13:03,186][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006984] [Batch 00814/01234] [00:09:25/00:04:51, 0.695s/it]: train_loss_raw=1.7852, running_loss=1.7611, LR=0.000100
[2025-08-25 23:13:08,950][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 006992] [Batch 00822/01234] [00:09:31/00:04:46, 0.695s/it]: train_loss_raw=1.7895, running_loss=1.7614, LR=0.000100
[2025-08-25 23:13:14,308][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007000] [Batch 00830/01234] [00:09:36/00:04:40, 0.695s/it]: train_loss_raw=1.7585, running_loss=1.7607, LR=0.000100
[2025-08-25 23:13:20,182][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007008] [Batch 00838/01234] [00:09:42/00:04:35, 0.695s/it]: train_loss_raw=1.7010, running_loss=1.7603, LR=0.000100
[2025-08-25 23:13:25,939][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007016] [Batch 00846/01234] [00:09:48/00:04:29, 0.696s/it]: train_loss_raw=1.7000, running_loss=1.7604, LR=0.000100
[2025-08-25 23:13:31,224][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007024] [Batch 00854/01234] [00:09:53/00:04:24, 0.695s/it]: train_loss_raw=1.7570, running_loss=1.7611, LR=0.000100
[2025-08-25 23:13:36,695][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007032] [Batch 00862/01234] [00:09:59/00:04:18, 0.695s/it]: train_loss_raw=1.7159, running_loss=1.7597, LR=0.000100
[2025-08-25 23:13:42,556][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007040] [Batch 00870/01234] [00:10:05/00:04:13, 0.695s/it]: train_loss_raw=1.7684, running_loss=1.7594, LR=0.000100
[2025-08-25 23:13:47,895][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007048] [Batch 00878/01234] [00:10:10/00:04:07, 0.695s/it]: train_loss_raw=1.7408, running_loss=1.7575, LR=0.000100
[2025-08-25 23:13:53,103][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007056] [Batch 00886/01234] [00:10:15/00:04:01, 0.695s/it]: train_loss_raw=1.7480, running_loss=1.7571, LR=0.000100
[2025-08-25 23:13:58,413][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007064] [Batch 00894/01234] [00:10:20/00:03:56, 0.694s/it]: train_loss_raw=1.7187, running_loss=1.7573, LR=0.000100
[2025-08-25 23:14:03,533][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007072] [Batch 00902/01234] [00:10:25/00:03:50, 0.694s/it]: train_loss_raw=1.6970, running_loss=1.7600, LR=0.000100
[2025-08-25 23:14:08,817][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007080] [Batch 00910/01234] [00:10:31/00:03:44, 0.694s/it]: train_loss_raw=1.7304, running_loss=1.7618, LR=0.000100
[2025-08-25 23:14:14,168][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007088] [Batch 00918/01234] [00:10:36/00:03:39, 0.693s/it]: train_loss_raw=1.7610, running_loss=1.7620, LR=0.000100
[2025-08-25 23:14:19,689][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007096] [Batch 00926/01234] [00:10:42/00:03:33, 0.693s/it]: train_loss_raw=1.7174, running_loss=1.7607, LR=0.000100
[2025-08-25 23:14:25,291][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007104] [Batch 00934/01234] [00:10:47/00:03:28, 0.694s/it]: train_loss_raw=1.7662, running_loss=1.7602, LR=0.000100
[2025-08-25 23:14:30,863][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007112] [Batch 00942/01234] [00:10:53/00:03:22, 0.694s/it]: train_loss_raw=1.6671, running_loss=1.7582, LR=0.000100
[2025-08-25 23:14:36,036][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007120] [Batch 00950/01234] [00:10:58/00:03:16, 0.693s/it]: train_loss_raw=1.8405, running_loss=1.7579, LR=0.000100
[2025-08-25 23:14:41,715][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007128] [Batch 00958/01234] [00:11:04/00:03:11, 0.693s/it]: train_loss_raw=1.7373, running_loss=1.7550, LR=0.000100
[2025-08-25 23:14:47,626][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007136] [Batch 00966/01234] [00:11:10/00:03:05, 0.694s/it]: train_loss_raw=1.8142, running_loss=1.7561, LR=0.000100
[2025-08-25 23:14:53,134][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007144] [Batch 00974/01234] [00:11:15/00:03:00, 0.694s/it]: train_loss_raw=1.7898, running_loss=1.7547, LR=0.000100
[2025-08-25 23:14:58,720][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007152] [Batch 00982/01234] [00:11:21/00:02:54, 0.694s/it]: train_loss_raw=1.7321, running_loss=1.7555, LR=0.000100
[2025-08-25 23:15:04,572][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007160] [Batch 00990/01234] [00:11:27/00:02:49, 0.694s/it]: train_loss_raw=1.6999, running_loss=1.7531, LR=0.000100
[2025-08-25 23:15:10,486][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007168] [Batch 00998/01234] [00:11:32/00:02:43, 0.694s/it]: train_loss_raw=1.7733, running_loss=1.7545, LR=0.000100
[2025-08-25 23:15:16,171][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007176] [Batch 01006/01234] [00:11:38/00:02:38, 0.694s/it]: train_loss_raw=1.6985, running_loss=1.7540, LR=0.000100
[2025-08-25 23:15:21,880][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007184] [Batch 01014/01234] [00:11:44/00:02:32, 0.695s/it]: train_loss_raw=1.8176, running_loss=1.7565, LR=0.000100
[2025-08-25 23:15:27,319][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007192] [Batch 01022/01234] [00:11:49/00:02:27, 0.694s/it]: train_loss_raw=1.7590, running_loss=1.7583, LR=0.000100
[2025-08-25 23:15:32,376][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007200] [Batch 01030/01234] [00:11:54/00:02:21, 0.694s/it]: train_loss_raw=1.6947, running_loss=1.7578, LR=0.000100
[2025-08-25 23:15:37,593][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007208] [Batch 01038/01234] [00:12:00/00:02:15, 0.694s/it]: train_loss_raw=1.7338, running_loss=1.7573, LR=0.000100
[2025-08-25 23:15:43,036][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007216] [Batch 01046/01234] [00:12:05/00:02:10, 0.694s/it]: train_loss_raw=1.7161, running_loss=1.7571, LR=0.000100
[2025-08-25 23:15:48,427][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007224] [Batch 01054/01234] [00:12:10/00:02:04, 0.693s/it]: train_loss_raw=1.6912, running_loss=1.7596, LR=0.000100
[2025-08-25 23:15:53,832][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007232] [Batch 01062/01234] [00:12:16/00:01:59, 0.693s/it]: train_loss_raw=1.7395, running_loss=1.7584, LR=0.000100
[2025-08-25 23:15:59,336][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007240] [Batch 01070/01234] [00:12:21/00:01:53, 0.693s/it]: train_loss_raw=1.7492, running_loss=1.7596, LR=0.000100
[2025-08-25 23:16:04,559][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007248] [Batch 01078/01234] [00:12:27/00:01:48, 0.693s/it]: train_loss_raw=1.7379, running_loss=1.7593, LR=0.000100
[2025-08-25 23:16:10,155][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007256] [Batch 01086/01234] [00:12:32/00:01:42, 0.693s/it]: train_loss_raw=1.7118, running_loss=1.7585, LR=0.000100
[2025-08-25 23:16:15,588][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007264] [Batch 01094/01234] [00:12:38/00:01:37, 0.693s/it]: train_loss_raw=1.8102, running_loss=1.7578, LR=0.000100
[2025-08-25 23:16:20,908][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007272] [Batch 01102/01234] [00:12:43/00:01:31, 0.693s/it]: train_loss_raw=1.8279, running_loss=1.7595, LR=0.000100
[2025-08-25 23:16:26,012][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007280] [Batch 01110/01234] [00:12:48/00:01:25, 0.692s/it]: train_loss_raw=1.7631, running_loss=1.7585, LR=0.000100
[2025-08-25 23:16:31,491][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007288] [Batch 01118/01234] [00:12:53/00:01:20, 0.692s/it]: train_loss_raw=1.7277, running_loss=1.7571, LR=0.000100
[2025-08-25 23:16:37,415][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007296] [Batch 01126/01234] [00:12:59/00:01:14, 0.693s/it]: train_loss_raw=1.8054, running_loss=1.7554, LR=0.000100
[2025-08-25 23:16:42,879][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007304] [Batch 01134/01234] [00:13:05/00:01:09, 0.693s/it]: train_loss_raw=1.7986, running_loss=1.7531, LR=0.000100
[2025-08-25 23:16:48,641][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007312] [Batch 01142/01234] [00:13:11/00:01:03, 0.693s/it]: train_loss_raw=1.7244, running_loss=1.7524, LR=0.000100
[2025-08-25 23:16:53,759][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007320] [Batch 01150/01234] [00:13:16/00:00:58, 0.692s/it]: train_loss_raw=1.7994, running_loss=1.7522, LR=0.000100
[2025-08-25 23:16:59,260][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007328] [Batch 01158/01234] [00:13:21/00:00:52, 0.692s/it]: train_loss_raw=1.6879, running_loss=1.7502, LR=0.000100
[2025-08-25 23:17:04,404][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007336] [Batch 01166/01234] [00:13:26/00:00:47, 0.692s/it]: train_loss_raw=1.6091, running_loss=1.7501, LR=0.000100
[2025-08-25 23:17:09,501][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007344] [Batch 01174/01234] [00:13:31/00:00:41, 0.692s/it]: train_loss_raw=1.7769, running_loss=1.7528, LR=0.000100
[2025-08-25 23:17:14,583][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007352] [Batch 01182/01234] [00:13:37/00:00:35, 0.691s/it]: train_loss_raw=1.7542, running_loss=1.7538, LR=0.000100
[2025-08-25 23:17:20,197][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007360] [Batch 01190/01234] [00:13:42/00:00:30, 0.691s/it]: train_loss_raw=1.7662, running_loss=1.7551, LR=0.000100
[2025-08-25 23:17:25,846][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007368] [Batch 01198/01234] [00:13:48/00:00:24, 0.691s/it]: train_loss_raw=1.7308, running_loss=1.7541, LR=0.000100
[2025-08-25 23:17:31,663][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007376] [Batch 01206/01234] [00:13:54/00:00:19, 0.692s/it]: train_loss_raw=1.6920, running_loss=1.7540, LR=0.000100
[2025-08-25 23:17:37,323][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007384] [Batch 01214/01234] [00:13:59/00:00:13, 0.692s/it]: train_loss_raw=1.8797, running_loss=1.7581, LR=0.000100
[2025-08-25 23:17:42,456][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007392] [Batch 01222/01234] [00:14:04/00:00:08, 0.691s/it]: train_loss_raw=1.7545, running_loss=1.7582, LR=0.000100
[2025-08-25 23:17:48,117][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 007400] [Batch 01230/01234] [00:14:10/00:00:02, 0.692s/it]: train_loss_raw=1.7886, running_loss=1.7593, LR=0.000100
[2025-08-25 23:17:56,525][__main__][INFO] - [VALIDATION] [Epoch 05/29] Starting validation.
[2025-08-25 23:18:06,862][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 007405] [Batch 00007/00026] [00:00:10/00:00:23, 1.292s/it]
[2025-08-25 23:18:17,360][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 007405] [Batch 00015/00026] [00:00:20/00:00:13, 1.302s/it]
[2025-08-25 23:18:27,629][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 007405] [Batch 00023/00026] [00:00:31/00:00:02, 1.296s/it]
[2025-08-25 23:18:29,921][__main__][INFO] - [VALIDATION] [Epoch 05/29] train_loss=1.75796, valid_loss=1.77224
[2025-08-25 23:18:29,921][__main__][INFO] - [VALIDATION] [Epoch 05/29] Metrics:
[2025-08-25 23:18:29,922][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_er      0.726
[2025-08-25 23:18:29,922][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_prec    0.032
[2025-08-25 23:18:29,922][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_recall  0.033
[2025-08-25 23:18:29,922][__main__][INFO] - [VALIDATION] [Epoch 05/29] - pep_recall 0.003
[2025-08-25 23:18:29,923][__main__][INFO] - [TRAIN] [Epoch 05/29] Epoch complete, total time 01:27:39, remaining time 05:50:36, 00:14:36 per epoch
[2025-08-25 23:18:32,105][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007408] [Batch 00004/01234] [00:00:02/00:10:31, 0.514s/it]: train_loss_raw=1.6845, running_loss=1.7019, LR=0.000100
[2025-08-25 23:18:37,574][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007416] [Batch 00012/01234] [00:00:07/00:12:46, 0.627s/it]: train_loss_raw=1.7848, running_loss=1.7023, LR=0.000100
[2025-08-25 23:18:43,542][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007424] [Batch 00020/01234] [00:00:13/00:13:39, 0.675s/it]: train_loss_raw=1.8209, running_loss=1.7035, LR=0.000100
[2025-08-25 23:18:48,733][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007432] [Batch 00028/01234] [00:00:18/00:13:24, 0.667s/it]: train_loss_raw=1.7346, running_loss=1.7037, LR=0.000100
[2025-08-25 23:18:53,781][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007440] [Batch 00036/01234] [00:00:23/00:13:09, 0.659s/it]: train_loss_raw=1.6908, running_loss=1.7057, LR=0.000100
[2025-08-25 23:18:58,913][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007448] [Batch 00044/01234] [00:00:28/00:13:00, 0.656s/it]: train_loss_raw=1.7255, running_loss=1.7068, LR=0.000100
[2025-08-25 23:19:04,643][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007456] [Batch 00052/01234] [00:00:34/00:13:06, 0.665s/it]: train_loss_raw=1.7055, running_loss=1.7071, LR=0.000100
[2025-08-25 23:19:09,932][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007464] [Batch 00060/01234] [00:00:39/00:13:00, 0.665s/it]: train_loss_raw=1.7808, running_loss=1.7086, LR=0.000100
[2025-08-25 23:19:15,098][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007472] [Batch 00068/01234] [00:00:45/00:12:52, 0.662s/it]: train_loss_raw=1.7516, running_loss=1.7098, LR=0.000100
[2025-08-25 23:19:20,223][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007480] [Batch 00076/01234] [00:00:50/00:12:44, 0.660s/it]: train_loss_raw=1.7433, running_loss=1.7122, LR=0.000100
[2025-08-25 23:19:25,395][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007488] [Batch 00084/01234] [00:00:55/00:12:37, 0.659s/it]: train_loss_raw=1.7679, running_loss=1.7123, LR=0.000100
[2025-08-25 23:19:30,586][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007496] [Batch 00092/01234] [00:01:00/00:12:31, 0.658s/it]: train_loss_raw=1.7549, running_loss=1.7127, LR=0.000100
[2025-08-25 23:19:36,601][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007504] [Batch 00100/01234] [00:01:06/00:12:34, 0.666s/it]: train_loss_raw=1.7238, running_loss=1.7124, LR=0.000100
[2025-08-25 23:19:42,004][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007512] [Batch 00108/01234] [00:01:11/00:12:30, 0.666s/it]: train_loss_raw=1.6924, running_loss=1.7131, LR=0.000100
[2025-08-25 23:19:47,166][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007520] [Batch 00116/01234] [00:01:17/00:12:23, 0.665s/it]: train_loss_raw=1.7102, running_loss=1.7140, LR=0.000100
[2025-08-25 23:19:52,889][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007528] [Batch 00124/01234] [00:01:22/00:12:21, 0.668s/it]: train_loss_raw=1.6920, running_loss=1.7144, LR=0.000100
[2025-08-25 23:19:58,420][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007536] [Batch 00132/01234] [00:01:28/00:12:17, 0.669s/it]: train_loss_raw=1.6918, running_loss=1.7157, LR=0.000100
[2025-08-25 23:20:03,842][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007544] [Batch 00140/01234] [00:01:33/00:12:12, 0.670s/it]: train_loss_raw=1.7232, running_loss=1.7180, LR=0.000100
[2025-08-25 23:20:09,505][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007552] [Batch 00148/01234] [00:01:39/00:12:09, 0.672s/it]: train_loss_raw=1.7318, running_loss=1.7181, LR=0.000100
[2025-08-25 23:20:15,388][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007560] [Batch 00156/01234] [00:01:45/00:12:07, 0.675s/it]: train_loss_raw=1.6970, running_loss=1.7170, LR=0.000100
[2025-08-25 23:20:20,725][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007568] [Batch 00164/01234] [00:01:50/00:12:02, 0.675s/it]: train_loss_raw=1.6471, running_loss=1.7158, LR=0.000100
[2025-08-25 23:20:26,084][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007576] [Batch 00172/01234] [00:01:56/00:11:56, 0.675s/it]: train_loss_raw=1.6586, running_loss=1.7139, LR=0.000100
[2025-08-25 23:20:31,658][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007584] [Batch 00180/01234] [00:02:01/00:11:52, 0.676s/it]: train_loss_raw=1.7547, running_loss=1.7147, LR=0.000100
[2025-08-25 23:20:36,717][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007592] [Batch 00188/01234] [00:02:06/00:11:44, 0.674s/it]: train_loss_raw=1.6797, running_loss=1.7126, LR=0.000100
[2025-08-25 23:20:42,254][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007600] [Batch 00196/01234] [00:02:12/00:11:40, 0.675s/it]: train_loss_raw=1.6871, running_loss=1.7138, LR=0.000100
[2025-08-25 23:20:47,353][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007608] [Batch 00204/01234] [00:02:17/00:11:33, 0.673s/it]: train_loss_raw=1.6823, running_loss=1.7168, LR=0.000100
[2025-08-25 23:20:52,629][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007616] [Batch 00212/01234] [00:02:22/00:11:27, 0.673s/it]: train_loss_raw=1.8359, running_loss=1.7183, LR=0.000100
[2025-08-25 23:20:58,136][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007624] [Batch 00220/01234] [00:02:28/00:11:22, 0.673s/it]: train_loss_raw=1.7238, running_loss=1.7193, LR=0.000100
[2025-08-25 23:21:03,232][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007632] [Batch 00228/01234] [00:02:33/00:11:15, 0.672s/it]: train_loss_raw=1.6671, running_loss=1.7173, LR=0.000100
[2025-08-25 23:21:08,400][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007640] [Batch 00236/01234] [00:02:38/00:11:09, 0.671s/it]: train_loss_raw=1.6451, running_loss=1.7162, LR=0.000100
[2025-08-25 23:21:13,678][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007648] [Batch 00244/01234] [00:02:43/00:11:03, 0.671s/it]: train_loss_raw=1.7636, running_loss=1.7162, LR=0.000100
[2025-08-25 23:21:19,140][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007656] [Batch 00252/01234] [00:02:49/00:10:58, 0.671s/it]: train_loss_raw=1.6307, running_loss=1.7158, LR=0.000100
[2025-08-25 23:21:24,926][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007664] [Batch 00260/01234] [00:02:54/00:10:55, 0.673s/it]: train_loss_raw=1.7573, running_loss=1.7140, LR=0.000100
[2025-08-25 23:21:30,810][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007672] [Batch 00268/01234] [00:03:00/00:10:51, 0.674s/it]: train_loss_raw=1.7178, running_loss=1.7164, LR=0.000100
[2025-08-25 23:21:35,886][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007680] [Batch 00276/01234] [00:03:05/00:10:45, 0.673s/it]: train_loss_raw=1.7334, running_loss=1.7166, LR=0.000100
[2025-08-25 23:21:40,988][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007688] [Batch 00284/01234] [00:03:10/00:10:38, 0.672s/it]: train_loss_raw=1.8524, running_loss=1.7171, LR=0.000100
[2025-08-25 23:21:46,214][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007696] [Batch 00292/01234] [00:03:16/00:10:32, 0.672s/it]: train_loss_raw=1.7222, running_loss=1.7181, LR=0.000100
[2025-08-25 23:21:51,279][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007704] [Batch 00300/01234] [00:03:21/00:10:26, 0.671s/it]: train_loss_raw=1.7266, running_loss=1.7178, LR=0.000100
[2025-08-25 23:21:56,707][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007712] [Batch 00308/01234] [00:03:26/00:10:21, 0.671s/it]: train_loss_raw=1.7404, running_loss=1.7156, LR=0.000100
[2025-08-25 23:22:02,687][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007720] [Batch 00316/01234] [00:03:32/00:10:17, 0.673s/it]: train_loss_raw=1.7635, running_loss=1.7162, LR=0.000100
[2025-08-25 23:22:08,138][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007728] [Batch 00324/01234] [00:03:38/00:10:12, 0.673s/it]: train_loss_raw=1.7037, running_loss=1.7163, LR=0.000100
[2025-08-25 23:22:13,347][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007736] [Batch 00332/01234] [00:03:43/00:10:06, 0.673s/it]: train_loss_raw=1.6506, running_loss=1.7152, LR=0.000100
[2025-08-25 23:22:18,457][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007744] [Batch 00340/01234] [00:03:48/00:10:00, 0.672s/it]: train_loss_raw=1.7346, running_loss=1.7157, LR=0.000100
[2025-08-25 23:22:23,530][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007752] [Batch 00348/01234] [00:03:53/00:09:54, 0.671s/it]: train_loss_raw=1.7678, running_loss=1.7159, LR=0.000100
[2025-08-25 23:22:28,639][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007760] [Batch 00356/01234] [00:03:58/00:09:48, 0.670s/it]: train_loss_raw=1.6204, running_loss=1.7148, LR=0.000100
[2025-08-25 23:22:33,711][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007768] [Batch 00364/01234] [00:04:03/00:09:42, 0.669s/it]: train_loss_raw=1.5974, running_loss=1.7135, LR=0.000100
[2025-08-25 23:22:39,137][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007776] [Batch 00372/01234] [00:04:09/00:09:37, 0.670s/it]: train_loss_raw=1.7093, running_loss=1.7120, LR=0.000100
[2025-08-25 23:22:44,492][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007784] [Batch 00380/01234] [00:04:14/00:09:31, 0.670s/it]: train_loss_raw=1.6230, running_loss=1.7116, LR=0.000100
[2025-08-25 23:22:50,325][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007792] [Batch 00388/01234] [00:04:20/00:09:27, 0.671s/it]: train_loss_raw=1.7282, running_loss=1.7124, LR=0.000100
[2025-08-25 23:22:55,883][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007800] [Batch 00396/01234] [00:04:25/00:09:22, 0.671s/it]: train_loss_raw=1.7733, running_loss=1.7129, LR=0.000100
[2025-08-25 23:23:01,604][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007808] [Batch 00404/01234] [00:04:31/00:09:17, 0.672s/it]: train_loss_raw=1.7186, running_loss=1.7145, LR=0.000100
[2025-08-25 23:23:07,128][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007816] [Batch 00412/01234] [00:04:37/00:09:12, 0.673s/it]: train_loss_raw=1.7028, running_loss=1.7164, LR=0.000100
[2025-08-25 23:23:12,934][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007824] [Batch 00420/01234] [00:04:42/00:09:08, 0.674s/it]: train_loss_raw=1.6955, running_loss=1.7141, LR=0.000100
[2025-08-25 23:23:18,697][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007832] [Batch 00428/01234] [00:04:48/00:09:03, 0.674s/it]: train_loss_raw=1.7915, running_loss=1.7164, LR=0.000100
[2025-08-25 23:23:23,964][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007840] [Batch 00436/01234] [00:04:53/00:08:57, 0.674s/it]: train_loss_raw=1.7238, running_loss=1.7170, LR=0.000100
[2025-08-25 23:23:29,681][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007848] [Batch 00444/01234] [00:04:59/00:08:53, 0.675s/it]: train_loss_raw=1.7170, running_loss=1.7159, LR=0.000100
[2025-08-25 23:23:35,725][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007856] [Batch 00452/01234] [00:05:05/00:08:48, 0.676s/it]: train_loss_raw=1.6493, running_loss=1.7161, LR=0.000100
[2025-08-25 23:23:41,541][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007864] [Batch 00460/01234] [00:05:11/00:08:44, 0.677s/it]: train_loss_raw=1.7695, running_loss=1.7188, LR=0.000100
[2025-08-25 23:23:47,377][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007872] [Batch 00468/01234] [00:05:17/00:08:39, 0.678s/it]: train_loss_raw=1.6980, running_loss=1.7187, LR=0.000100
[2025-08-25 23:23:53,180][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007880] [Batch 00476/01234] [00:05:23/00:08:34, 0.679s/it]: train_loss_raw=1.6861, running_loss=1.7170, LR=0.000100
[2025-08-25 23:23:58,276][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007888] [Batch 00484/01234] [00:05:28/00:08:28, 0.678s/it]: train_loss_raw=1.7344, running_loss=1.7179, LR=0.000100
[2025-08-25 23:24:03,823][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007896] [Batch 00492/01234] [00:05:33/00:08:23, 0.678s/it]: train_loss_raw=1.7261, running_loss=1.7160, LR=0.000100
[2025-08-25 23:24:09,441][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007904] [Batch 00500/01234] [00:05:39/00:08:18, 0.679s/it]: train_loss_raw=1.6876, running_loss=1.7152, LR=0.000100
[2025-08-25 23:24:14,919][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007912] [Batch 00508/01234] [00:05:44/00:08:12, 0.679s/it]: train_loss_raw=1.6634, running_loss=1.7157, LR=0.000100
[2025-08-25 23:24:20,030][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007920] [Batch 00516/01234] [00:05:49/00:08:06, 0.678s/it]: train_loss_raw=1.6733, running_loss=1.7155, LR=0.000100
[2025-08-25 23:24:25,460][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007928] [Batch 00524/01234] [00:05:55/00:08:01, 0.678s/it]: train_loss_raw=1.7984, running_loss=1.7155, LR=0.000100
[2025-08-25 23:24:31,035][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007936] [Batch 00532/01234] [00:06:00/00:07:56, 0.679s/it]: train_loss_raw=1.7229, running_loss=1.7165, LR=0.000100
[2025-08-25 23:24:36,316][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007944] [Batch 00540/01234] [00:06:06/00:07:50, 0.678s/it]: train_loss_raw=1.7662, running_loss=1.7174, LR=0.000100
[2025-08-25 23:24:41,746][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007952] [Batch 00548/01234] [00:06:11/00:07:45, 0.678s/it]: train_loss_raw=1.8012, running_loss=1.7152, LR=0.000100
[2025-08-25 23:24:47,412][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007960] [Batch 00556/01234] [00:06:17/00:07:40, 0.679s/it]: train_loss_raw=1.7529, running_loss=1.7157, LR=0.000100
[2025-08-25 23:24:53,123][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007968] [Batch 00564/01234] [00:06:23/00:07:35, 0.679s/it]: train_loss_raw=1.7190, running_loss=1.7145, LR=0.000100
[2025-08-25 23:24:58,781][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007976] [Batch 00572/01234] [00:06:28/00:07:29, 0.680s/it]: train_loss_raw=1.6990, running_loss=1.7144, LR=0.000100
[2025-08-25 23:25:04,424][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007984] [Batch 00580/01234] [00:06:34/00:07:24, 0.680s/it]: train_loss_raw=1.7414, running_loss=1.7147, LR=0.000100
[2025-08-25 23:25:09,680][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 007992] [Batch 00588/01234] [00:06:39/00:07:19, 0.680s/it]: train_loss_raw=1.6955, running_loss=1.7138, LR=0.000100
[2025-08-25 23:25:15,084][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008000] [Batch 00596/01234] [00:06:45/00:07:13, 0.680s/it]: train_loss_raw=1.6387, running_loss=1.7131, LR=0.000100
[2025-08-25 23:25:24,491][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008008] [Batch 00604/01234] [00:06:54/00:07:12, 0.686s/it]: train_loss_raw=1.6777, running_loss=1.7132, LR=0.000100
[2025-08-25 23:25:30,211][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008016] [Batch 00612/01234] [00:07:00/00:07:07, 0.687s/it]: train_loss_raw=1.7201, running_loss=1.7151, LR=0.000100
[2025-08-25 23:25:35,905][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008024] [Batch 00620/01234] [00:07:05/00:07:01, 0.687s/it]: train_loss_raw=1.6603, running_loss=1.7135, LR=0.000100
[2025-08-25 23:25:41,612][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008032] [Batch 00628/01234] [00:07:11/00:06:56, 0.687s/it]: train_loss_raw=1.8140, running_loss=1.7159, LR=0.000100
[2025-08-25 23:25:47,131][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008040] [Batch 00636/01234] [00:07:17/00:06:50, 0.687s/it]: train_loss_raw=1.7372, running_loss=1.7152, LR=0.000100
[2025-08-25 23:25:52,492][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008048] [Batch 00644/01234] [00:07:22/00:06:45, 0.687s/it]: train_loss_raw=1.7753, running_loss=1.7166, LR=0.000100
[2025-08-25 23:25:58,301][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008056] [Batch 00652/01234] [00:07:28/00:06:40, 0.688s/it]: train_loss_raw=1.7046, running_loss=1.7162, LR=0.000100
[2025-08-25 23:26:03,722][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008064] [Batch 00660/01234] [00:07:33/00:06:34, 0.687s/it]: train_loss_raw=1.7321, running_loss=1.7182, LR=0.000100
[2025-08-25 23:26:09,021][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008072] [Batch 00668/01234] [00:07:38/00:06:28, 0.687s/it]: train_loss_raw=1.7163, running_loss=1.7174, LR=0.000100
[2025-08-25 23:26:14,146][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008080] [Batch 00676/01234] [00:07:44/00:06:23, 0.687s/it]: train_loss_raw=1.7409, running_loss=1.7197, LR=0.000100
[2025-08-25 23:26:19,633][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008088] [Batch 00684/01234] [00:07:49/00:06:17, 0.687s/it]: train_loss_raw=1.6629, running_loss=1.7193, LR=0.000100
[2025-08-25 23:26:25,455][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008096] [Batch 00692/01234] [00:07:55/00:06:12, 0.687s/it]: train_loss_raw=1.7595, running_loss=1.7194, LR=0.000100
[2025-08-25 23:26:31,163][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008104] [Batch 00700/01234] [00:08:01/00:06:07, 0.687s/it]: train_loss_raw=1.7338, running_loss=1.7183, LR=0.000100
[2025-08-25 23:26:36,568][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008112] [Batch 00708/01234] [00:08:06/00:06:01, 0.687s/it]: train_loss_raw=1.7134, running_loss=1.7174, LR=0.000100
[2025-08-25 23:26:41,681][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008120] [Batch 00716/01234] [00:08:11/00:05:55, 0.687s/it]: train_loss_raw=1.6994, running_loss=1.7156, LR=0.000100
[2025-08-25 23:26:47,198][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008128] [Batch 00724/01234] [00:08:17/00:05:50, 0.687s/it]: train_loss_raw=1.7298, running_loss=1.7152, LR=0.000100
[2025-08-25 23:26:52,931][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008136] [Batch 00732/01234] [00:08:22/00:05:44, 0.687s/it]: train_loss_raw=1.6409, running_loss=1.7152, LR=0.000100
[2025-08-25 23:26:59,005][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008144] [Batch 00740/01234] [00:08:28/00:05:39, 0.688s/it]: train_loss_raw=1.7261, running_loss=1.7165, LR=0.000100
[2025-08-25 23:27:04,231][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008152] [Batch 00748/01234] [00:08:34/00:05:34, 0.687s/it]: train_loss_raw=1.5774, running_loss=1.7145, LR=0.000100
[2025-08-25 23:27:09,340][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008160] [Batch 00756/01234] [00:08:39/00:05:28, 0.687s/it]: train_loss_raw=1.6226, running_loss=1.7144, LR=0.000100
[2025-08-25 23:27:14,925][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008168] [Batch 00764/01234] [00:08:44/00:05:22, 0.687s/it]: train_loss_raw=1.7679, running_loss=1.7159, LR=0.000100
[2025-08-25 23:27:20,388][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008176] [Batch 00772/01234] [00:08:50/00:05:17, 0.687s/it]: train_loss_raw=1.6785, running_loss=1.7182, LR=0.000100
[2025-08-25 23:27:26,173][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008184] [Batch 00780/01234] [00:08:56/00:05:12, 0.687s/it]: train_loss_raw=1.6866, running_loss=1.7169, LR=0.000100
[2025-08-25 23:27:31,465][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008192] [Batch 00788/01234] [00:09:01/00:05:06, 0.687s/it]: train_loss_raw=1.7836, running_loss=1.7158, LR=0.000100
[2025-08-25 23:27:37,412][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008200] [Batch 00796/01234] [00:09:07/00:05:01, 0.688s/it]: train_loss_raw=1.7117, running_loss=1.7151, LR=0.000100
[2025-08-25 23:27:42,617][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008208] [Batch 00804/01234] [00:09:12/00:04:55, 0.687s/it]: train_loss_raw=1.7831, running_loss=1.7156, LR=0.000100
[2025-08-25 23:27:48,466][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008216] [Batch 00812/01234] [00:09:18/00:04:50, 0.688s/it]: train_loss_raw=1.7860, running_loss=1.7159, LR=0.000100
[2025-08-25 23:27:54,112][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008224] [Batch 00820/01234] [00:09:24/00:04:44, 0.688s/it]: train_loss_raw=1.7612, running_loss=1.7157, LR=0.000100
[2025-08-25 23:27:59,669][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008232] [Batch 00828/01234] [00:09:29/00:04:39, 0.688s/it]: train_loss_raw=1.7829, running_loss=1.7168, LR=0.000100
[2025-08-25 23:28:05,077][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008240] [Batch 00836/01234] [00:09:35/00:04:33, 0.688s/it]: train_loss_raw=1.6838, running_loss=1.7170, LR=0.000100
[2025-08-25 23:28:10,522][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008248] [Batch 00844/01234] [00:09:40/00:04:28, 0.688s/it]: train_loss_raw=1.7366, running_loss=1.7165, LR=0.000100
[2025-08-25 23:28:15,599][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008256] [Batch 00852/01234] [00:09:45/00:04:22, 0.687s/it]: train_loss_raw=1.6717, running_loss=1.7159, LR=0.000100
[2025-08-25 23:28:21,225][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008264] [Batch 00860/01234] [00:09:51/00:04:17, 0.687s/it]: train_loss_raw=1.7136, running_loss=1.7162, LR=0.000100
[2025-08-25 23:28:26,492][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008272] [Batch 00868/01234] [00:09:56/00:04:11, 0.687s/it]: train_loss_raw=1.7527, running_loss=1.7152, LR=0.000100
[2025-08-25 23:28:32,091][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008280] [Batch 00876/01234] [00:10:02/00:04:06, 0.687s/it]: train_loss_raw=1.7237, running_loss=1.7182, LR=0.000100
[2025-08-25 23:28:37,985][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008288] [Batch 00884/01234] [00:10:07/00:04:00, 0.688s/it]: train_loss_raw=1.7382, running_loss=1.7189, LR=0.000100
[2025-08-25 23:28:43,306][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008296] [Batch 00892/01234] [00:10:13/00:03:55, 0.688s/it]: train_loss_raw=1.7086, running_loss=1.7186, LR=0.000100
[2025-08-25 23:28:48,471][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008304] [Batch 00900/01234] [00:10:18/00:03:49, 0.687s/it]: train_loss_raw=1.6814, running_loss=1.7143, LR=0.000100
[2025-08-25 23:28:53,949][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008312] [Batch 00908/01234] [00:10:23/00:03:43, 0.687s/it]: train_loss_raw=1.7286, running_loss=1.7143, LR=0.000100
[2025-08-25 23:28:59,042][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008320] [Batch 00916/01234] [00:10:28/00:03:38, 0.687s/it]: train_loss_raw=1.7295, running_loss=1.7131, LR=0.000100
[2025-08-25 23:29:04,850][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008328] [Batch 00924/01234] [00:10:34/00:03:32, 0.687s/it]: train_loss_raw=1.6678, running_loss=1.7124, LR=0.000100
[2025-08-25 23:29:09,925][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008336] [Batch 00932/01234] [00:10:39/00:03:27, 0.687s/it]: train_loss_raw=1.7132, running_loss=1.7124, LR=0.000100
[2025-08-25 23:29:15,029][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008344] [Batch 00940/01234] [00:10:44/00:03:21, 0.686s/it]: train_loss_raw=1.7113, running_loss=1.7127, LR=0.000100
[2025-08-25 23:29:20,121][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008352] [Batch 00948/01234] [00:10:50/00:03:16, 0.686s/it]: train_loss_raw=1.7389, running_loss=1.7107, LR=0.000100
[2025-08-25 23:29:25,508][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008360] [Batch 00956/01234] [00:10:55/00:03:10, 0.686s/it]: train_loss_raw=1.6443, running_loss=1.7092, LR=0.000100
[2025-08-25 23:29:31,239][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008368] [Batch 00964/01234] [00:11:01/00:03:05, 0.686s/it]: train_loss_raw=1.6425, running_loss=1.7091, LR=0.000100
[2025-08-25 23:29:36,996][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008376] [Batch 00972/01234] [00:11:06/00:02:59, 0.686s/it]: train_loss_raw=1.7389, running_loss=1.7102, LR=0.000100
[2025-08-25 23:29:42,312][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008384] [Batch 00980/01234] [00:11:12/00:02:54, 0.686s/it]: train_loss_raw=1.5998, running_loss=1.7096, LR=0.000100
[2025-08-25 23:29:47,395][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008392] [Batch 00988/01234] [00:11:17/00:02:48, 0.686s/it]: train_loss_raw=1.7135, running_loss=1.7075, LR=0.000100
[2025-08-25 23:29:52,480][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008400] [Batch 00996/01234] [00:11:22/00:02:43, 0.685s/it]: train_loss_raw=1.7736, running_loss=1.7054, LR=0.000100
[2025-08-25 23:29:57,905][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008408] [Batch 01004/01234] [00:11:27/00:02:37, 0.685s/it]: train_loss_raw=1.7107, running_loss=1.7040, LR=0.000100
[2025-08-25 23:30:03,323][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008416] [Batch 01012/01234] [00:11:33/00:02:32, 0.685s/it]: train_loss_raw=1.7599, running_loss=1.7051, LR=0.000100
[2025-08-25 23:30:09,102][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008424] [Batch 01020/01234] [00:11:39/00:02:26, 0.685s/it]: train_loss_raw=1.6915, running_loss=1.7035, LR=0.000100
[2025-08-25 23:30:14,270][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008432] [Batch 01028/01234] [00:11:44/00:02:21, 0.685s/it]: train_loss_raw=1.5946, running_loss=1.7018, LR=0.000100
[2025-08-25 23:30:19,352][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008440] [Batch 01036/01234] [00:11:49/00:02:15, 0.685s/it]: train_loss_raw=1.6884, running_loss=1.7055, LR=0.000100
[2025-08-25 23:30:24,718][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008448] [Batch 01044/01234] [00:11:54/00:02:10, 0.685s/it]: train_loss_raw=1.7437, running_loss=1.7033, LR=0.000100
[2025-08-25 23:30:29,905][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008456] [Batch 01052/01234] [00:11:59/00:02:04, 0.684s/it]: train_loss_raw=1.7563, running_loss=1.7050, LR=0.000100
[2025-08-25 23:30:35,023][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008464] [Batch 01060/01234] [00:12:04/00:01:59, 0.684s/it]: train_loss_raw=1.7411, running_loss=1.7054, LR=0.000100
[2025-08-25 23:30:40,177][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008472] [Batch 01068/01234] [00:12:10/00:01:53, 0.684s/it]: train_loss_raw=1.5874, running_loss=1.7034, LR=0.000100
[2025-08-25 23:30:45,580][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008480] [Batch 01076/01234] [00:12:15/00:01:48, 0.684s/it]: train_loss_raw=1.7573, running_loss=1.7038, LR=0.000100
[2025-08-25 23:30:51,132][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008488] [Batch 01084/01234] [00:12:21/00:01:42, 0.684s/it]: train_loss_raw=1.7104, running_loss=1.7068, LR=0.000100
[2025-08-25 23:30:56,623][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008496] [Batch 01092/01234] [00:12:26/00:01:37, 0.684s/it]: train_loss_raw=1.6773, running_loss=1.7037, LR=0.000100
[2025-08-25 23:31:01,760][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008504] [Batch 01100/01234] [00:12:31/00:01:31, 0.683s/it]: train_loss_raw=1.7551, running_loss=1.7046, LR=0.000100
[2025-08-25 23:31:06,928][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008512] [Batch 01108/01234] [00:12:36/00:01:26, 0.683s/it]: train_loss_raw=1.7293, running_loss=1.7046, LR=0.000100
[2025-08-25 23:31:12,354][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008520] [Batch 01116/01234] [00:12:42/00:01:20, 0.683s/it]: train_loss_raw=1.6981, running_loss=1.7036, LR=0.000100
[2025-08-25 23:31:17,621][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008528] [Batch 01124/01234] [00:12:47/00:01:15, 0.683s/it]: train_loss_raw=1.6851, running_loss=1.7021, LR=0.000100
[2025-08-25 23:31:22,805][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008536] [Batch 01132/01234] [00:12:52/00:01:09, 0.683s/it]: train_loss_raw=1.6449, running_loss=1.7017, LR=0.000100
[2025-08-25 23:31:28,240][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008544] [Batch 01140/01234] [00:12:58/00:01:04, 0.683s/it]: train_loss_raw=1.7902, running_loss=1.7034, LR=0.000100
[2025-08-25 23:31:34,084][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008552] [Batch 01148/01234] [00:13:04/00:00:58, 0.683s/it]: train_loss_raw=1.7501, running_loss=1.7022, LR=0.000100
[2025-08-25 23:31:39,640][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008560] [Batch 01156/01234] [00:13:09/00:00:53, 0.683s/it]: train_loss_raw=1.6477, running_loss=1.6999, LR=0.000100
[2025-08-25 23:31:45,257][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008568] [Batch 01164/01234] [00:13:15/00:00:47, 0.683s/it]: train_loss_raw=1.7399, running_loss=1.6998, LR=0.000100
[2025-08-25 23:31:50,652][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008576] [Batch 01172/01234] [00:13:20/00:00:42, 0.683s/it]: train_loss_raw=1.6312, running_loss=1.6997, LR=0.000100
[2025-08-25 23:31:56,492][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008584] [Batch 01180/01234] [00:13:26/00:00:36, 0.683s/it]: train_loss_raw=1.7149, running_loss=1.7015, LR=0.000100
[2025-08-25 23:32:01,742][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008592] [Batch 01188/01234] [00:13:31/00:00:31, 0.683s/it]: train_loss_raw=1.7239, running_loss=1.7031, LR=0.000100
[2025-08-25 23:32:07,001][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008600] [Batch 01196/01234] [00:13:36/00:00:25, 0.683s/it]: train_loss_raw=1.7566, running_loss=1.7047, LR=0.000100
[2025-08-25 23:32:12,231][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008608] [Batch 01204/01234] [00:13:42/00:00:20, 0.683s/it]: train_loss_raw=1.6622, running_loss=1.7044, LR=0.000100
[2025-08-25 23:32:17,854][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008616] [Batch 01212/01234] [00:13:47/00:00:15, 0.683s/it]: train_loss_raw=1.6206, running_loss=1.7031, LR=0.000100
[2025-08-25 23:32:23,695][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008624] [Batch 01220/01234] [00:13:53/00:00:09, 0.683s/it]: train_loss_raw=1.6484, running_loss=1.7014, LR=0.000100
[2025-08-25 23:32:29,241][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 008632] [Batch 01228/01234] [00:13:59/00:00:04, 0.683s/it]: train_loss_raw=1.5994, running_loss=1.6993, LR=0.000100
[2025-08-25 23:32:39,145][__main__][INFO] - [VALIDATION] [Epoch 06/29] Starting validation.
[2025-08-25 23:32:50,376][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 008639] [Batch 00007/00026] [00:00:11/00:00:25, 1.404s/it]
[2025-08-25 23:33:01,022][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 008639] [Batch 00015/00026] [00:00:21/00:00:13, 1.367s/it]
[2025-08-25 23:33:12,522][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 008639] [Batch 00023/00026] [00:00:33/00:00:02, 1.391s/it]
[2025-08-25 23:33:15,123][__main__][INFO] - [VALIDATION] [Epoch 06/29] train_loss=1.69933, valid_loss=1.72991
[2025-08-25 23:33:15,123][__main__][INFO] - [VALIDATION] [Epoch 06/29] Metrics:
[2025-08-25 23:33:15,123][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_er      0.732
[2025-08-25 23:33:15,123][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_prec    0.039
[2025-08-25 23:33:15,124][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_recall  0.041
[2025-08-25 23:33:15,124][__main__][INFO] - [VALIDATION] [Epoch 06/29] - pep_recall 0.005
[2025-08-25 23:33:15,126][__main__][INFO] - [TRAIN] [Epoch 06/29] Epoch complete, total time 01:42:24, remaining time 05:36:28, 00:14:37 per epoch
[2025-08-25 23:33:16,233][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008640] [Batch 00002/01234] [00:00:00/00:08:46, 0.427s/it]: train_loss_raw=1.7012, running_loss=1.6464, LR=0.000100
[2025-08-25 23:33:21,733][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008648] [Batch 00010/01234] [00:00:06/00:12:57, 0.635s/it]: train_loss_raw=1.6865, running_loss=1.6469, LR=0.000100
[2025-08-25 23:33:27,228][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008656] [Batch 00018/01234] [00:00:11/00:13:20, 0.658s/it]: train_loss_raw=1.5711, running_loss=1.6472, LR=0.000100
[2025-08-25 23:33:32,805][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008664] [Batch 00026/01234] [00:00:17/00:13:29, 0.670s/it]: train_loss_raw=1.6117, running_loss=1.6482, LR=0.000100
[2025-08-25 23:33:37,872][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008672] [Batch 00034/01234] [00:00:22/00:13:13, 0.662s/it]: train_loss_raw=1.6894, running_loss=1.6500, LR=0.000100
[2025-08-25 23:33:43,185][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008680] [Batch 00042/01234] [00:00:27/00:13:09, 0.662s/it]: train_loss_raw=1.7078, running_loss=1.6520, LR=0.000100
[2025-08-25 23:33:48,372][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008688] [Batch 00050/01234] [00:00:32/00:13:01, 0.660s/it]: train_loss_raw=1.6272, running_loss=1.6535, LR=0.000100
[2025-08-25 23:33:54,230][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008696] [Batch 00058/01234] [00:00:38/00:13:07, 0.670s/it]: train_loss_raw=1.6986, running_loss=1.6527, LR=0.000100
[2025-08-25 23:33:59,421][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008704] [Batch 00066/01234] [00:00:44/00:12:59, 0.667s/it]: train_loss_raw=1.6282, running_loss=1.6528, LR=0.000100
[2025-08-25 23:34:05,232][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008712] [Batch 00074/01234] [00:00:49/00:13:01, 0.674s/it]: train_loss_raw=1.6698, running_loss=1.6548, LR=0.000100
[2025-08-25 23:34:10,680][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008720] [Batch 00082/01234] [00:00:55/00:12:56, 0.674s/it]: train_loss_raw=1.6907, running_loss=1.6549, LR=0.000100
[2025-08-25 23:34:15,799][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008728] [Batch 00090/01234] [00:01:00/00:12:48, 0.671s/it]: train_loss_raw=1.6379, running_loss=1.6536, LR=0.000100
[2025-08-25 23:34:21,330][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008736] [Batch 00098/01234] [00:01:05/00:12:44, 0.673s/it]: train_loss_raw=1.4857, running_loss=1.6509, LR=0.000100
[2025-08-25 23:34:26,540][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008744] [Batch 00106/01234] [00:01:11/00:12:37, 0.671s/it]: train_loss_raw=1.6751, running_loss=1.6526, LR=0.000100
[2025-08-25 23:34:32,270][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008752] [Batch 00114/01234] [00:01:16/00:12:35, 0.674s/it]: train_loss_raw=1.6132, running_loss=1.6531, LR=0.000100
[2025-08-25 23:34:37,622][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008760] [Batch 00122/01234] [00:01:22/00:12:29, 0.674s/it]: train_loss_raw=1.7003, running_loss=1.6548, LR=0.000100
[2025-08-25 23:34:42,984][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008768] [Batch 00130/01234] [00:01:27/00:12:23, 0.674s/it]: train_loss_raw=1.6709, running_loss=1.6551, LR=0.000100
[2025-08-25 23:34:48,116][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008776] [Batch 00138/01234] [00:01:32/00:12:16, 0.672s/it]: train_loss_raw=1.6605, running_loss=1.6548, LR=0.000100
[2025-08-25 23:34:53,758][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008784] [Batch 00146/01234] [00:01:38/00:12:13, 0.674s/it]: train_loss_raw=1.7123, running_loss=1.6585, LR=0.000100
[2025-08-25 23:34:58,952][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008792] [Batch 00154/01234] [00:01:43/00:12:06, 0.673s/it]: train_loss_raw=1.5947, running_loss=1.6564, LR=0.000100
[2025-08-25 23:35:04,520][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008800] [Batch 00162/01234] [00:01:49/00:12:02, 0.674s/it]: train_loss_raw=1.7045, running_loss=1.6578, LR=0.000100
[2025-08-25 23:35:09,793][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008808] [Batch 00170/01234] [00:01:54/00:11:56, 0.673s/it]: train_loss_raw=1.7107, running_loss=1.6595, LR=0.000100
[2025-08-25 23:35:15,094][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008816] [Batch 00178/01234] [00:01:59/00:11:50, 0.673s/it]: train_loss_raw=1.5928, running_loss=1.6581, LR=0.000100
[2025-08-25 23:35:20,707][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008824] [Batch 00186/01234] [00:02:05/00:11:46, 0.674s/it]: train_loss_raw=1.6871, running_loss=1.6588, LR=0.000100
[2025-08-25 23:35:25,784][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008832] [Batch 00194/01234] [00:02:10/00:11:39, 0.672s/it]: train_loss_raw=1.6005, running_loss=1.6586, LR=0.000100
[2025-08-25 23:35:30,941][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008840] [Batch 00202/01234] [00:02:15/00:11:32, 0.671s/it]: train_loss_raw=1.6649, running_loss=1.6600, LR=0.000100
[2025-08-25 23:35:36,089][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008848] [Batch 00210/01234] [00:02:20/00:11:26, 0.670s/it]: train_loss_raw=1.6266, running_loss=1.6589, LR=0.000100
[2025-08-25 23:35:41,334][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008856] [Batch 00218/01234] [00:02:25/00:11:20, 0.670s/it]: train_loss_raw=1.6412, running_loss=1.6570, LR=0.000100
[2025-08-25 23:35:47,095][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008864] [Batch 00226/01234] [00:02:31/00:11:16, 0.671s/it]: train_loss_raw=1.5801, running_loss=1.6567, LR=0.000100
[2025-08-25 23:35:52,239][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008872] [Batch 00234/01234] [00:02:36/00:11:10, 0.670s/it]: train_loss_raw=1.6991, running_loss=1.6559, LR=0.000100
[2025-08-25 23:35:57,334][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008880] [Batch 00242/01234] [00:02:41/00:11:03, 0.669s/it]: train_loss_raw=1.5980, running_loss=1.6549, LR=0.000100
[2025-08-25 23:36:02,428][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008888] [Batch 00250/01234] [00:02:47/00:10:57, 0.668s/it]: train_loss_raw=1.7073, running_loss=1.6549, LR=0.000100
[2025-08-25 23:36:07,819][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008896] [Batch 00258/01234] [00:02:52/00:10:52, 0.668s/it]: train_loss_raw=1.5499, running_loss=1.6553, LR=0.000100
[2025-08-25 23:36:13,554][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008904] [Batch 00266/01234] [00:02:58/00:10:48, 0.670s/it]: train_loss_raw=1.6942, running_loss=1.6557, LR=0.000100
[2025-08-25 23:36:19,205][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008912] [Batch 00274/01234] [00:03:03/00:10:44, 0.671s/it]: train_loss_raw=1.5995, running_loss=1.6561, LR=0.000100
[2025-08-25 23:36:24,991][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008920] [Batch 00282/01234] [00:03:09/00:10:40, 0.672s/it]: train_loss_raw=1.6450, running_loss=1.6586, LR=0.000100
[2025-08-25 23:36:30,255][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008928] [Batch 00290/01234] [00:03:14/00:10:34, 0.672s/it]: train_loss_raw=1.6524, running_loss=1.6600, LR=0.000100
[2025-08-25 23:36:35,436][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008936] [Batch 00298/01234] [00:03:20/00:10:28, 0.671s/it]: train_loss_raw=1.7131, running_loss=1.6614, LR=0.000100
[2025-08-25 23:36:40,549][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008944] [Batch 00306/01234] [00:03:25/00:10:22, 0.670s/it]: train_loss_raw=1.7251, running_loss=1.6647, LR=0.000100
[2025-08-25 23:36:45,940][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008952] [Batch 00314/01234] [00:03:30/00:10:16, 0.671s/it]: train_loss_raw=1.6495, running_loss=1.6637, LR=0.000100
[2025-08-25 23:36:51,358][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008960] [Batch 00322/01234] [00:03:35/00:10:11, 0.671s/it]: train_loss_raw=1.6280, running_loss=1.6644, LR=0.000100
[2025-08-25 23:36:57,141][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008968] [Batch 00330/01234] [00:03:41/00:10:07, 0.672s/it]: train_loss_raw=1.6105, running_loss=1.6648, LR=0.000100
[2025-08-25 23:37:02,784][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008976] [Batch 00338/01234] [00:03:47/00:10:02, 0.673s/it]: train_loss_raw=1.6495, running_loss=1.6636, LR=0.000100
[2025-08-25 23:37:07,995][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008984] [Batch 00346/01234] [00:03:52/00:09:57, 0.672s/it]: train_loss_raw=1.6155, running_loss=1.6624, LR=0.000100
[2025-08-25 23:37:13,576][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 008992] [Batch 00354/01234] [00:03:58/00:09:52, 0.673s/it]: train_loss_raw=1.6259, running_loss=1.6617, LR=0.000100
[2025-08-25 23:37:18,679][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009000] [Batch 00362/01234] [00:04:03/00:09:46, 0.672s/it]: train_loss_raw=1.6703, running_loss=1.6617, LR=0.000100
[2025-08-25 23:37:23,946][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009008] [Batch 00370/01234] [00:04:08/00:09:40, 0.672s/it]: train_loss_raw=1.6071, running_loss=1.6619, LR=0.000100
[2025-08-25 23:37:29,582][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009016] [Batch 00378/01234] [00:04:14/00:09:35, 0.672s/it]: train_loss_raw=1.6423, running_loss=1.6627, LR=0.000100
[2025-08-25 23:37:34,707][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009024] [Batch 00386/01234] [00:04:19/00:09:29, 0.672s/it]: train_loss_raw=1.6435, running_loss=1.6635, LR=0.000100
[2025-08-25 23:37:39,810][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009032] [Batch 00394/01234] [00:04:24/00:09:23, 0.671s/it]: train_loss_raw=1.7376, running_loss=1.6646, LR=0.000100
[2025-08-25 23:37:45,274][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009040] [Batch 00402/01234] [00:04:29/00:09:18, 0.671s/it]: train_loss_raw=1.5887, running_loss=1.6616, LR=0.000100
[2025-08-25 23:37:50,470][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009048] [Batch 00410/01234] [00:04:35/00:09:12, 0.671s/it]: train_loss_raw=1.6335, running_loss=1.6617, LR=0.000100
[2025-08-25 23:37:55,721][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009056] [Batch 00418/01234] [00:04:40/00:09:07, 0.671s/it]: train_loss_raw=1.6966, running_loss=1.6618, LR=0.000100
[2025-08-25 23:38:01,515][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009064] [Batch 00426/01234] [00:04:46/00:09:02, 0.672s/it]: train_loss_raw=1.7064, running_loss=1.6615, LR=0.000100
[2025-08-25 23:38:06,921][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009072] [Batch 00434/01234] [00:04:51/00:08:57, 0.672s/it]: train_loss_raw=1.6228, running_loss=1.6602, LR=0.000100
[2025-08-25 23:38:12,615][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009080] [Batch 00442/01234] [00:04:57/00:08:52, 0.672s/it]: train_loss_raw=1.5793, running_loss=1.6607, LR=0.000100
[2025-08-25 23:38:18,231][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009088] [Batch 00450/01234] [00:05:02/00:08:47, 0.673s/it]: train_loss_raw=1.6853, running_loss=1.6596, LR=0.000100
[2025-08-25 23:38:23,778][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009096] [Batch 00458/01234] [00:05:08/00:08:42, 0.673s/it]: train_loss_raw=1.6934, running_loss=1.6616, LR=0.000100
[2025-08-25 23:38:29,407][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009104] [Batch 00466/01234] [00:05:14/00:08:37, 0.674s/it]: train_loss_raw=1.6507, running_loss=1.6621, LR=0.000100
[2025-08-25 23:38:35,230][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009112] [Batch 00474/01234] [00:05:19/00:08:32, 0.675s/it]: train_loss_raw=1.7576, running_loss=1.6612, LR=0.000100
[2025-08-25 23:38:40,858][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009120] [Batch 00482/01234] [00:05:25/00:08:27, 0.675s/it]: train_loss_raw=1.5677, running_loss=1.6594, LR=0.000100
[2025-08-25 23:38:45,936][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009128] [Batch 00490/01234] [00:05:30/00:08:21, 0.675s/it]: train_loss_raw=1.6674, running_loss=1.6595, LR=0.000100
[2025-08-25 23:38:51,105][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009136] [Batch 00498/01234] [00:05:35/00:08:16, 0.674s/it]: train_loss_raw=1.7040, running_loss=1.6625, LR=0.000100
[2025-08-25 23:38:56,566][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009144] [Batch 00506/01234] [00:05:41/00:08:10, 0.674s/it]: train_loss_raw=1.6238, running_loss=1.6630, LR=0.000100
[2025-08-25 23:39:02,397][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009152] [Batch 00514/01234] [00:05:47/00:08:06, 0.675s/it]: train_loss_raw=1.6812, running_loss=1.6631, LR=0.000100
[2025-08-25 23:39:08,309][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009160] [Batch 00522/01234] [00:05:52/00:08:01, 0.676s/it]: train_loss_raw=1.6330, running_loss=1.6633, LR=0.000100
[2025-08-25 23:39:14,030][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009168] [Batch 00530/01234] [00:05:58/00:07:56, 0.677s/it]: train_loss_raw=1.5775, running_loss=1.6617, LR=0.000100
[2025-08-25 23:39:19,521][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009176] [Batch 00538/01234] [00:06:04/00:07:51, 0.677s/it]: train_loss_raw=1.6644, running_loss=1.6613, LR=0.000100
[2025-08-25 23:39:24,858][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009184] [Batch 00546/01234] [00:06:09/00:07:45, 0.677s/it]: train_loss_raw=1.6480, running_loss=1.6612, LR=0.000100
[2025-08-25 23:39:29,958][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009192] [Batch 00554/01234] [00:06:14/00:07:39, 0.676s/it]: train_loss_raw=1.5709, running_loss=1.6610, LR=0.000100
[2025-08-25 23:39:35,382][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009200] [Batch 00562/01234] [00:06:20/00:07:34, 0.676s/it]: train_loss_raw=1.6475, running_loss=1.6603, LR=0.000100
[2025-08-25 23:39:40,498][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009208] [Batch 00570/01234] [00:06:25/00:07:28, 0.676s/it]: train_loss_raw=1.6371, running_loss=1.6594, LR=0.000100
[2025-08-25 23:39:46,213][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009216] [Batch 00578/01234] [00:06:30/00:07:23, 0.676s/it]: train_loss_raw=1.6998, running_loss=1.6602, LR=0.000100
[2025-08-25 23:39:52,017][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009224] [Batch 00586/01234] [00:06:36/00:07:18, 0.677s/it]: train_loss_raw=1.6604, running_loss=1.6608, LR=0.000100
[2025-08-25 23:39:57,583][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009232] [Batch 00594/01234] [00:06:42/00:07:13, 0.677s/it]: train_loss_raw=1.6367, running_loss=1.6627, LR=0.000100
[2025-08-25 23:40:03,103][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009240] [Batch 00602/01234] [00:06:47/00:07:08, 0.677s/it]: train_loss_raw=1.6530, running_loss=1.6626, LR=0.000100
[2025-08-25 23:40:08,312][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009248] [Batch 00610/01234] [00:06:52/00:07:02, 0.677s/it]: train_loss_raw=1.6332, running_loss=1.6620, LR=0.000100
[2025-08-25 23:40:13,410][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009256] [Batch 00618/01234] [00:06:58/00:06:56, 0.676s/it]: train_loss_raw=1.7639, running_loss=1.6619, LR=0.000100
[2025-08-25 23:40:19,185][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009264] [Batch 00626/01234] [00:07:03/00:06:51, 0.677s/it]: train_loss_raw=1.6137, running_loss=1.6640, LR=0.000100
[2025-08-25 23:40:25,068][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009272] [Batch 00634/01234] [00:07:09/00:06:46, 0.678s/it]: train_loss_raw=1.6436, running_loss=1.6628, LR=0.000100
[2025-08-25 23:40:30,948][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009280] [Batch 00642/01234] [00:07:15/00:06:41, 0.678s/it]: train_loss_raw=1.5994, running_loss=1.6609, LR=0.000100
[2025-08-25 23:40:36,830][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009288] [Batch 00650/01234] [00:07:21/00:06:36, 0.679s/it]: train_loss_raw=1.6879, running_loss=1.6632, LR=0.000100
[2025-08-25 23:40:42,094][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009296] [Batch 00658/01234] [00:07:26/00:06:31, 0.679s/it]: train_loss_raw=1.6098, running_loss=1.6643, LR=0.000100
[2025-08-25 23:40:47,596][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009304] [Batch 00666/01234] [00:07:32/00:06:25, 0.679s/it]: train_loss_raw=1.5818, running_loss=1.6638, LR=0.000100
[2025-08-25 23:40:53,378][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009312] [Batch 00674/01234] [00:07:37/00:06:20, 0.680s/it]: train_loss_raw=1.5638, running_loss=1.6627, LR=0.000100
[2025-08-25 23:40:58,464][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009320] [Batch 00682/01234] [00:07:43/00:06:14, 0.679s/it]: train_loss_raw=1.7478, running_loss=1.6636, LR=0.000100
[2025-08-25 23:41:03,561][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009328] [Batch 00690/01234] [00:07:48/00:06:09, 0.679s/it]: train_loss_raw=1.6628, running_loss=1.6630, LR=0.000100
[2025-08-25 23:41:08,918][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009336] [Batch 00698/01234] [00:07:53/00:06:03, 0.678s/it]: train_loss_raw=1.6425, running_loss=1.6627, LR=0.000100
[2025-08-25 23:41:14,149][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009344] [Batch 00706/01234] [00:07:58/00:05:58, 0.678s/it]: train_loss_raw=1.7040, running_loss=1.6621, LR=0.000100
[2025-08-25 23:41:19,516][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009352] [Batch 00714/01234] [00:08:04/00:05:52, 0.678s/it]: train_loss_raw=1.6539, running_loss=1.6620, LR=0.000100
[2025-08-25 23:41:25,062][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009360] [Batch 00722/01234] [00:08:09/00:05:47, 0.678s/it]: train_loss_raw=1.6370, running_loss=1.6627, LR=0.000100
[2025-08-25 23:41:30,611][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009368] [Batch 00730/01234] [00:08:15/00:05:41, 0.678s/it]: train_loss_raw=1.6369, running_loss=1.6618, LR=0.000100
[2025-08-25 23:41:36,252][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009376] [Batch 00738/01234] [00:08:20/00:05:36, 0.679s/it]: train_loss_raw=1.6845, running_loss=1.6617, LR=0.000100
[2025-08-25 23:41:41,786][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009384] [Batch 00746/01234] [00:08:26/00:05:31, 0.679s/it]: train_loss_raw=1.7219, running_loss=1.6633, LR=0.000100
[2025-08-25 23:41:47,052][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009392] [Batch 00754/01234] [00:08:31/00:05:25, 0.679s/it]: train_loss_raw=1.6865, running_loss=1.6649, LR=0.000100
[2025-08-25 23:41:53,026][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009400] [Batch 00762/01234] [00:08:37/00:05:20, 0.679s/it]: train_loss_raw=1.6662, running_loss=1.6655, LR=0.000100
[2025-08-25 23:41:58,532][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009408] [Batch 00770/01234] [00:08:43/00:05:15, 0.679s/it]: train_loss_raw=1.6542, running_loss=1.6657, LR=0.000100
[2025-08-25 23:42:04,340][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009416] [Batch 00778/01234] [00:08:48/00:05:10, 0.680s/it]: train_loss_raw=1.6665, running_loss=1.6675, LR=0.000100
[2025-08-25 23:42:09,877][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009424] [Batch 00786/01234] [00:08:54/00:05:04, 0.680s/it]: train_loss_raw=1.6924, running_loss=1.6674, LR=0.000100
[2025-08-25 23:42:15,242][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009432] [Batch 00794/01234] [00:08:59/00:04:59, 0.680s/it]: train_loss_raw=1.6569, running_loss=1.6661, LR=0.000100
[2025-08-25 23:42:20,488][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009440] [Batch 00802/01234] [00:09:05/00:04:53, 0.680s/it]: train_loss_raw=1.6878, running_loss=1.6668, LR=0.000100
[2025-08-25 23:42:25,548][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009448] [Batch 00810/01234] [00:09:10/00:04:47, 0.679s/it]: train_loss_raw=1.6350, running_loss=1.6643, LR=0.000100
[2025-08-25 23:42:30,855][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009456] [Batch 00818/01234] [00:09:15/00:04:42, 0.679s/it]: train_loss_raw=1.7051, running_loss=1.6653, LR=0.000100
[2025-08-25 23:42:36,488][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009464] [Batch 00826/01234] [00:09:21/00:04:37, 0.679s/it]: train_loss_raw=1.7526, running_loss=1.6662, LR=0.000100
[2025-08-25 23:42:41,623][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009472] [Batch 00834/01234] [00:09:26/00:04:31, 0.679s/it]: train_loss_raw=1.6931, running_loss=1.6673, LR=0.000100
[2025-08-25 23:42:47,395][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009480] [Batch 00842/01234] [00:09:32/00:04:26, 0.679s/it]: train_loss_raw=1.7383, running_loss=1.6649, LR=0.000100
[2025-08-25 23:42:53,165][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009488] [Batch 00850/01234] [00:09:37/00:04:21, 0.680s/it]: train_loss_raw=1.6682, running_loss=1.6639, LR=0.000100
[2025-08-25 23:42:58,372][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009496] [Batch 00858/01234] [00:09:42/00:04:15, 0.679s/it]: train_loss_raw=1.6909, running_loss=1.6624, LR=0.000100
[2025-08-25 23:43:03,926][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009504] [Batch 00866/01234] [00:09:48/00:04:10, 0.680s/it]: train_loss_raw=1.6915, running_loss=1.6599, LR=0.000100
[2025-08-25 23:43:09,878][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009512] [Batch 00874/01234] [00:09:54/00:04:04, 0.680s/it]: train_loss_raw=1.6805, running_loss=1.6596, LR=0.000100
[2025-08-25 23:43:15,409][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009520] [Batch 00882/01234] [00:10:00/00:03:59, 0.680s/it]: train_loss_raw=1.6340, running_loss=1.6618, LR=0.000100
[2025-08-25 23:43:20,840][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009528] [Batch 00890/01234] [00:10:05/00:03:54, 0.680s/it]: train_loss_raw=1.6401, running_loss=1.6617, LR=0.000100
[2025-08-25 23:43:26,394][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009536] [Batch 00898/01234] [00:10:11/00:03:48, 0.680s/it]: train_loss_raw=1.6752, running_loss=1.6627, LR=0.000100
[2025-08-25 23:43:31,579][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009544] [Batch 00906/01234] [00:10:16/00:03:43, 0.680s/it]: train_loss_raw=1.6296, running_loss=1.6616, LR=0.000100
[2025-08-25 23:43:37,100][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009552] [Batch 00914/01234] [00:10:21/00:03:37, 0.680s/it]: train_loss_raw=1.6170, running_loss=1.6600, LR=0.000100
[2025-08-25 23:43:42,779][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009560] [Batch 00922/01234] [00:10:27/00:03:32, 0.680s/it]: train_loss_raw=1.6422, running_loss=1.6584, LR=0.000100
[2025-08-25 23:43:48,013][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009568] [Batch 00930/01234] [00:10:32/00:03:26, 0.680s/it]: train_loss_raw=1.6106, running_loss=1.6570, LR=0.000100
[2025-08-25 23:43:53,761][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009576] [Batch 00938/01234] [00:10:38/00:03:21, 0.681s/it]: train_loss_raw=1.6277, running_loss=1.6582, LR=0.000100
[2025-08-25 23:43:59,344][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009584] [Batch 00946/01234] [00:10:43/00:03:16, 0.681s/it]: train_loss_raw=1.6538, running_loss=1.6579, LR=0.000100
[2025-08-25 23:44:05,004][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009592] [Batch 00954/01234] [00:10:49/00:03:10, 0.681s/it]: train_loss_raw=1.6827, running_loss=1.6582, LR=0.000100
[2025-08-25 23:44:10,842][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009600] [Batch 00962/01234] [00:10:55/00:03:05, 0.681s/it]: train_loss_raw=1.5807, running_loss=1.6602, LR=0.000100
[2025-08-25 23:44:16,044][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009608] [Batch 00970/01234] [00:11:00/00:02:59, 0.681s/it]: train_loss_raw=1.6594, running_loss=1.6607, LR=0.000100
[2025-08-25 23:44:21,642][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009616] [Batch 00978/01234] [00:11:06/00:02:54, 0.681s/it]: train_loss_raw=1.7551, running_loss=1.6600, LR=0.000100
[2025-08-25 23:44:27,514][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009624] [Batch 00986/01234] [00:11:12/00:02:49, 0.682s/it]: train_loss_raw=1.6408, running_loss=1.6606, LR=0.000100
[2025-08-25 23:44:32,786][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009632] [Batch 00994/01234] [00:11:17/00:02:43, 0.681s/it]: train_loss_raw=1.6574, running_loss=1.6609, LR=0.000100
[2025-08-25 23:44:38,145][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009640] [Batch 01002/01234] [00:11:22/00:02:38, 0.681s/it]: train_loss_raw=1.7117, running_loss=1.6614, LR=0.000100
[2025-08-25 23:44:43,757][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009648] [Batch 01010/01234] [00:11:28/00:02:32, 0.682s/it]: train_loss_raw=1.5848, running_loss=1.6612, LR=0.000100
[2025-08-25 23:44:49,072][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009656] [Batch 01018/01234] [00:11:33/00:02:27, 0.681s/it]: train_loss_raw=1.6596, running_loss=1.6600, LR=0.000100
[2025-08-25 23:44:54,399][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009664] [Batch 01026/01234] [00:11:39/00:02:21, 0.681s/it]: train_loss_raw=1.5815, running_loss=1.6603, LR=0.000100
[2025-08-25 23:44:59,857][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009672] [Batch 01034/01234] [00:11:44/00:02:16, 0.681s/it]: train_loss_raw=1.6398, running_loss=1.6601, LR=0.000100
[2025-08-25 23:45:05,819][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009680] [Batch 01042/01234] [00:11:50/00:02:10, 0.682s/it]: train_loss_raw=1.6725, running_loss=1.6607, LR=0.000100
[2025-08-25 23:45:11,518][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009688] [Batch 01050/01234] [00:11:56/00:02:05, 0.682s/it]: train_loss_raw=1.7727, running_loss=1.6601, LR=0.000100
[2025-08-25 23:45:16,980][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009696] [Batch 01058/01234] [00:12:01/00:02:00, 0.682s/it]: train_loss_raw=1.6612, running_loss=1.6616, LR=0.000100
[2025-08-25 23:45:22,890][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009704] [Batch 01066/01234] [00:12:07/00:01:54, 0.682s/it]: train_loss_raw=1.7627, running_loss=1.6624, LR=0.000100
[2025-08-25 23:45:28,864][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009712] [Batch 01074/01234] [00:12:13/00:01:49, 0.683s/it]: train_loss_raw=1.6165, running_loss=1.6610, LR=0.000100
[2025-08-25 23:45:34,357][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009720] [Batch 01082/01234] [00:12:18/00:01:43, 0.683s/it]: train_loss_raw=1.6734, running_loss=1.6608, LR=0.000100
[2025-08-25 23:45:40,059][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009728] [Batch 01090/01234] [00:12:24/00:01:38, 0.683s/it]: train_loss_raw=1.6319, running_loss=1.6607, LR=0.000100
[2025-08-25 23:45:45,667][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009736] [Batch 01098/01234] [00:12:30/00:01:32, 0.683s/it]: train_loss_raw=1.7350, running_loss=1.6596, LR=0.000100
[2025-08-25 23:45:50,773][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009744] [Batch 01106/01234] [00:12:35/00:01:27, 0.683s/it]: train_loss_raw=1.6272, running_loss=1.6567, LR=0.000100
[2025-08-25 23:45:56,382][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009752] [Batch 01114/01234] [00:12:41/00:01:21, 0.683s/it]: train_loss_raw=1.6666, running_loss=1.6598, LR=0.000100
[2025-08-25 23:46:01,931][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009760] [Batch 01122/01234] [00:12:46/00:01:16, 0.683s/it]: train_loss_raw=1.7240, running_loss=1.6616, LR=0.000100
[2025-08-25 23:46:07,658][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009768] [Batch 01130/01234] [00:12:52/00:01:11, 0.683s/it]: train_loss_raw=1.6609, running_loss=1.6607, LR=0.000100
[2025-08-25 23:46:13,712][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009776] [Batch 01138/01234] [00:12:58/00:01:05, 0.684s/it]: train_loss_raw=1.6170, running_loss=1.6597, LR=0.000100
[2025-08-25 23:46:19,158][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009784] [Batch 01146/01234] [00:13:03/00:01:00, 0.684s/it]: train_loss_raw=1.7056, running_loss=1.6598, LR=0.000100
[2025-08-25 23:46:24,366][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009792] [Batch 01154/01234] [00:13:08/00:00:54, 0.684s/it]: train_loss_raw=1.6100, running_loss=1.6596, LR=0.000100
[2025-08-25 23:46:30,131][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009800] [Batch 01162/01234] [00:13:14/00:00:49, 0.684s/it]: train_loss_raw=1.6537, running_loss=1.6612, LR=0.000100
[2025-08-25 23:46:35,766][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009808] [Batch 01170/01234] [00:13:20/00:00:43, 0.684s/it]: train_loss_raw=1.6200, running_loss=1.6593, LR=0.000100
[2025-08-25 23:46:40,893][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009816] [Batch 01178/01234] [00:13:25/00:00:38, 0.684s/it]: train_loss_raw=1.6780, running_loss=1.6594, LR=0.000100
[2025-08-25 23:46:46,031][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009824] [Batch 01186/01234] [00:13:30/00:00:32, 0.684s/it]: train_loss_raw=1.6349, running_loss=1.6578, LR=0.000100
[2025-08-25 23:46:52,060][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009832] [Batch 01194/01234] [00:13:36/00:00:27, 0.684s/it]: train_loss_raw=1.6573, running_loss=1.6582, LR=0.000100
[2025-08-25 23:46:57,816][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009840] [Batch 01202/01234] [00:13:42/00:00:21, 0.684s/it]: train_loss_raw=1.6234, running_loss=1.6582, LR=0.000100
[2025-08-25 23:47:03,545][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009848] [Batch 01210/01234] [00:13:48/00:00:16, 0.684s/it]: train_loss_raw=1.6371, running_loss=1.6563, LR=0.000100
[2025-08-25 23:47:09,093][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009856] [Batch 01218/01234] [00:13:53/00:00:10, 0.684s/it]: train_loss_raw=1.7146, running_loss=1.6573, LR=0.000100
[2025-08-25 23:47:14,193][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009864] [Batch 01226/01234] [00:13:58/00:00:05, 0.684s/it]: train_loss_raw=1.6082, running_loss=1.6560, LR=0.000100
[2025-08-25 23:47:25,132][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 009872] [Batch 01234/01234] [00:14:09/00:00:00, 0.689s/it]: train_loss_raw=1.5334, running_loss=1.6532, LR=0.000100
[2025-08-25 23:47:25,619][__main__][INFO] - [VALIDATION] [Epoch 07/29] Starting validation.
[2025-08-25 23:47:36,563][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 009873] [Batch 00007/00026] [00:00:10/00:00:24, 1.368s/it]
[2025-08-25 23:47:47,745][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 009873] [Batch 00015/00026] [00:00:22/00:00:13, 1.383s/it]
[2025-08-25 23:47:58,991][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 009873] [Batch 00023/00026] [00:00:33/00:00:02, 1.390s/it]
[2025-08-25 23:48:01,413][__main__][INFO] - [VALIDATION] [Epoch 07/29] train_loss=1.65324, valid_loss=1.68687
[2025-08-25 23:48:01,413][__main__][INFO] - [VALIDATION] [Epoch 07/29] Metrics:
[2025-08-25 23:48:01,413][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_er      0.695
[2025-08-25 23:48:01,413][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_prec    0.036
[2025-08-25 23:48:01,413][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_recall  0.036
[2025-08-25 23:48:01,413][__main__][INFO] - [VALIDATION] [Epoch 07/29] - pep_recall 0.004
[2025-08-25 23:48:01,416][__main__][INFO] - [TRAIN] [Epoch 07/29] Epoch complete, total time 01:57:10, remaining time 05:22:14, 00:14:38 per epoch
[2025-08-25 23:48:06,507][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009880] [Batch 00008/01234] [00:00:04/00:12:24, 0.608s/it]: train_loss_raw=1.6111, running_loss=1.6033, LR=0.000100
[2025-08-25 23:48:12,106][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009888] [Batch 00016/01234] [00:00:10/00:13:16, 0.654s/it]: train_loss_raw=1.6245, running_loss=1.6041, LR=0.000100
[2025-08-25 23:48:17,334][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009896] [Batch 00024/01234] [00:00:15/00:13:10, 0.654s/it]: train_loss_raw=1.6057, running_loss=1.6057, LR=0.000100
[2025-08-25 23:48:22,398][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009904] [Batch 00032/01234] [00:00:20/00:12:59, 0.648s/it]: train_loss_raw=1.6350, running_loss=1.6060, LR=0.000100
[2025-08-25 23:48:27,482][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009912] [Batch 00040/01234] [00:00:25/00:12:51, 0.646s/it]: train_loss_raw=1.6965, running_loss=1.6061, LR=0.000100
[2025-08-25 23:48:32,769][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009920] [Batch 00048/01234] [00:00:31/00:12:48, 0.648s/it]: train_loss_raw=1.6646, running_loss=1.6077, LR=0.000100
[2025-08-25 23:48:38,204][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009928] [Batch 00056/01234] [00:00:36/00:12:49, 0.653s/it]: train_loss_raw=1.6502, running_loss=1.6092, LR=0.000100
[2025-08-25 23:48:43,291][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009936] [Batch 00064/01234] [00:00:41/00:12:41, 0.651s/it]: train_loss_raw=1.6012, running_loss=1.6094, LR=0.000100
[2025-08-25 23:48:48,401][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009944] [Batch 00072/01234] [00:00:46/00:12:34, 0.649s/it]: train_loss_raw=1.6745, running_loss=1.6114, LR=0.000100
[2025-08-25 23:48:53,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009952] [Batch 00080/01234] [00:00:52/00:12:30, 0.650s/it]: train_loss_raw=1.6927, running_loss=1.6101, LR=0.000100
[2025-08-25 23:48:59,109][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009960] [Batch 00088/01234] [00:00:57/00:12:28, 0.653s/it]: train_loss_raw=1.4728, running_loss=1.6085, LR=0.000100
[2025-08-25 23:49:04,882][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009968] [Batch 00096/01234] [00:01:03/00:12:29, 0.659s/it]: train_loss_raw=1.6399, running_loss=1.6086, LR=0.000100
[2025-08-25 23:49:10,653][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009976] [Batch 00104/01234] [00:01:09/00:12:29, 0.664s/it]: train_loss_raw=1.6412, running_loss=1.6084, LR=0.000100
[2025-08-25 23:49:16,192][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009984] [Batch 00112/01234] [00:01:14/00:12:26, 0.666s/it]: train_loss_raw=1.5525, running_loss=1.6100, LR=0.000100
[2025-08-25 23:49:21,841][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 009992] [Batch 00120/01234] [00:01:20/00:12:24, 0.668s/it]: train_loss_raw=1.6183, running_loss=1.6112, LR=0.000100
[2025-08-25 23:49:26,921][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010000] [Batch 00128/01234] [00:01:25/00:12:16, 0.666s/it]: train_loss_raw=1.5796, running_loss=1.6112, LR=0.000100
[2025-08-25 23:49:35,877][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010008] [Batch 00136/01234] [00:01:34/00:12:40, 0.693s/it]: train_loss_raw=1.6484, running_loss=1.6132, LR=0.000100
[2025-08-25 23:49:41,451][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010016] [Batch 00144/01234] [00:01:39/00:12:35, 0.693s/it]: train_loss_raw=1.5922, running_loss=1.6121, LR=0.000100
[2025-08-25 23:49:46,909][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010024] [Batch 00152/01234] [00:01:45/00:12:29, 0.693s/it]: train_loss_raw=1.5853, running_loss=1.6133, LR=0.000100
[2025-08-25 23:49:52,168][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010032] [Batch 00160/01234] [00:01:50/00:12:21, 0.691s/it]: train_loss_raw=1.6188, running_loss=1.6103, LR=0.000100
[2025-08-25 23:49:57,430][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010040] [Batch 00168/01234] [00:01:55/00:12:14, 0.689s/it]: train_loss_raw=1.6019, running_loss=1.6116, LR=0.000100
[2025-08-25 23:50:02,534][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010048] [Batch 00176/01234] [00:02:00/00:12:06, 0.687s/it]: train_loss_raw=1.6837, running_loss=1.6116, LR=0.000100
[2025-08-25 23:50:07,799][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010056] [Batch 00184/01234] [00:02:06/00:11:59, 0.686s/it]: train_loss_raw=1.5478, running_loss=1.6098, LR=0.000100
[2025-08-25 23:50:13,435][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010064] [Batch 00192/01234] [00:02:11/00:11:55, 0.686s/it]: train_loss_raw=1.5938, running_loss=1.6119, LR=0.000100
[2025-08-25 23:50:19,188][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010072] [Batch 00200/01234] [00:02:17/00:11:51, 0.688s/it]: train_loss_raw=1.5886, running_loss=1.6124, LR=0.000100
[2025-08-25 23:50:24,539][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010080] [Batch 00208/01234] [00:02:22/00:11:44, 0.687s/it]: train_loss_raw=1.5525, running_loss=1.6107, LR=0.000100
[2025-08-25 23:50:30,289][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010088] [Batch 00216/01234] [00:02:28/00:11:40, 0.688s/it]: train_loss_raw=1.5907, running_loss=1.6101, LR=0.000100
[2025-08-25 23:50:36,205][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010096] [Batch 00224/01234] [00:02:34/00:11:36, 0.690s/it]: train_loss_raw=1.5607, running_loss=1.6097, LR=0.000100
[2025-08-25 23:50:42,331][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010104] [Batch 00232/01234] [00:02:40/00:11:33, 0.693s/it]: train_loss_raw=1.6039, running_loss=1.6079, LR=0.000100
[2025-08-25 23:50:47,955][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010112] [Batch 00240/01234] [00:02:46/00:11:28, 0.693s/it]: train_loss_raw=1.5855, running_loss=1.6062, LR=0.000100
[2025-08-25 23:50:53,614][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010120] [Batch 00248/01234] [00:02:51/00:11:23, 0.693s/it]: train_loss_raw=1.6227, running_loss=1.6074, LR=0.000100
[2025-08-25 23:50:59,304][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010128] [Batch 00256/01234] [00:02:57/00:11:18, 0.694s/it]: train_loss_raw=1.6351, running_loss=1.6078, LR=0.000100
[2025-08-25 23:51:04,754][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010136] [Batch 00264/01234] [00:03:03/00:11:12, 0.694s/it]: train_loss_raw=1.5620, running_loss=1.6073, LR=0.000100
[2025-08-25 23:51:10,353][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010144] [Batch 00272/01234] [00:03:08/00:11:07, 0.694s/it]: train_loss_raw=1.5885, running_loss=1.6081, LR=0.000100
[2025-08-25 23:51:15,411][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010152] [Batch 00280/01234] [00:03:13/00:11:00, 0.692s/it]: train_loss_raw=1.6594, running_loss=1.6098, LR=0.000100
[2025-08-25 23:51:20,491][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010160] [Batch 00288/01234] [00:03:18/00:10:53, 0.690s/it]: train_loss_raw=1.6351, running_loss=1.6104, LR=0.000100
[2025-08-25 23:51:25,562][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010168] [Batch 00296/01234] [00:03:23/00:10:46, 0.689s/it]: train_loss_raw=1.6511, running_loss=1.6107, LR=0.000100
[2025-08-25 23:51:30,627][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010176] [Batch 00304/01234] [00:03:28/00:10:39, 0.687s/it]: train_loss_raw=1.6431, running_loss=1.6126, LR=0.000100
[2025-08-25 23:51:36,045][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010184] [Batch 00312/01234] [00:03:34/00:10:33, 0.687s/it]: train_loss_raw=1.6325, running_loss=1.6140, LR=0.000100
[2025-08-25 23:51:41,706][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010192] [Batch 00320/01234] [00:03:40/00:10:28, 0.688s/it]: train_loss_raw=1.5632, running_loss=1.6108, LR=0.000100
[2025-08-25 23:51:47,616][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010200] [Batch 00328/01234] [00:03:45/00:10:24, 0.689s/it]: train_loss_raw=1.7143, running_loss=1.6104, LR=0.000100
[2025-08-25 23:51:52,809][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010208] [Batch 00336/01234] [00:03:51/00:10:17, 0.688s/it]: train_loss_raw=1.6541, running_loss=1.6124, LR=0.000100
[2025-08-25 23:51:58,408][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010216] [Batch 00344/01234] [00:03:56/00:10:12, 0.688s/it]: train_loss_raw=1.7380, running_loss=1.6144, LR=0.000100
[2025-08-25 23:52:03,674][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010224] [Batch 00352/01234] [00:04:02/00:10:06, 0.688s/it]: train_loss_raw=1.6908, running_loss=1.6138, LR=0.000100
[2025-08-25 23:52:08,774][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010232] [Batch 00360/01234] [00:04:07/00:09:59, 0.686s/it]: train_loss_raw=1.6183, running_loss=1.6146, LR=0.000100
[2025-08-25 23:52:13,925][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010240] [Batch 00368/01234] [00:04:12/00:09:53, 0.686s/it]: train_loss_raw=1.6834, running_loss=1.6161, LR=0.000100
[2025-08-25 23:52:19,147][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010248] [Batch 00376/01234] [00:04:17/00:09:47, 0.685s/it]: train_loss_raw=1.4344, running_loss=1.6158, LR=0.000100
[2025-08-25 23:52:24,462][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010256] [Batch 00384/01234] [00:04:22/00:09:41, 0.684s/it]: train_loss_raw=1.5900, running_loss=1.6148, LR=0.000100
[2025-08-25 23:52:29,742][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010264] [Batch 00392/01234] [00:04:28/00:09:35, 0.684s/it]: train_loss_raw=1.6740, running_loss=1.6140, LR=0.000100
[2025-08-25 23:52:34,834][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010272] [Batch 00400/01234] [00:04:33/00:09:29, 0.683s/it]: train_loss_raw=1.5268, running_loss=1.6154, LR=0.000100
[2025-08-25 23:52:40,084][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010280] [Batch 00408/01234] [00:04:38/00:09:23, 0.682s/it]: train_loss_raw=1.6361, running_loss=1.6141, LR=0.000100
[2025-08-25 23:52:45,327][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010288] [Batch 00416/01234] [00:04:43/00:09:17, 0.682s/it]: train_loss_raw=1.7244, running_loss=1.6148, LR=0.000100
[2025-08-25 23:52:51,077][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010296] [Batch 00424/01234] [00:04:49/00:09:12, 0.683s/it]: train_loss_raw=1.5647, running_loss=1.6178, LR=0.000100
[2025-08-25 23:52:56,670][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010304] [Batch 00432/01234] [00:04:55/00:09:07, 0.683s/it]: train_loss_raw=1.5630, running_loss=1.6188, LR=0.000100
[2025-08-25 23:53:02,288][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010312] [Batch 00440/01234] [00:05:00/00:09:02, 0.683s/it]: train_loss_raw=1.5310, running_loss=1.6205, LR=0.000100
[2025-08-25 23:53:07,488][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010320] [Batch 00448/01234] [00:05:05/00:08:56, 0.683s/it]: train_loss_raw=1.6744, running_loss=1.6180, LR=0.000100
[2025-08-25 23:53:12,901][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010328] [Batch 00456/01234] [00:05:11/00:08:51, 0.683s/it]: train_loss_raw=1.6140, running_loss=1.6186, LR=0.000100
[2025-08-25 23:53:18,146][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010336] [Batch 00464/01234] [00:05:16/00:08:45, 0.682s/it]: train_loss_raw=1.6853, running_loss=1.6186, LR=0.000100
[2025-08-25 23:53:23,323][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010344] [Batch 00472/01234] [00:05:21/00:08:39, 0.682s/it]: train_loss_raw=1.6291, running_loss=1.6204, LR=0.000100
[2025-08-25 23:53:28,693][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010352] [Batch 00480/01234] [00:05:27/00:08:33, 0.681s/it]: train_loss_raw=1.5480, running_loss=1.6201, LR=0.000100
[2025-08-25 23:53:34,199][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010360] [Batch 00488/01234] [00:05:32/00:08:28, 0.681s/it]: train_loss_raw=1.6286, running_loss=1.6210, LR=0.000100
[2025-08-25 23:53:39,293][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010368] [Batch 00496/01234] [00:05:37/00:08:22, 0.681s/it]: train_loss_raw=1.6496, running_loss=1.6183, LR=0.000100
[2025-08-25 23:53:44,398][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010376] [Batch 00504/01234] [00:05:42/00:08:16, 0.680s/it]: train_loss_raw=1.5734, running_loss=1.6189, LR=0.000100
[2025-08-25 23:53:49,806][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010384] [Batch 00512/01234] [00:05:48/00:08:10, 0.680s/it]: train_loss_raw=1.6186, running_loss=1.6183, LR=0.000100
[2025-08-25 23:53:54,886][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010392] [Batch 00520/01234] [00:05:53/00:08:05, 0.679s/it]: train_loss_raw=1.6036, running_loss=1.6171, LR=0.000100
[2025-08-25 23:54:00,711][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010400] [Batch 00528/01234] [00:05:59/00:08:00, 0.680s/it]: train_loss_raw=1.5898, running_loss=1.6170, LR=0.000100
[2025-08-25 23:54:06,356][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010408] [Batch 00536/01234] [00:06:04/00:07:54, 0.680s/it]: train_loss_raw=1.6419, running_loss=1.6175, LR=0.000100
[2025-08-25 23:54:12,012][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010416] [Batch 00544/01234] [00:06:10/00:07:49, 0.681s/it]: train_loss_raw=1.6178, running_loss=1.6189, LR=0.000100
[2025-08-25 23:54:17,616][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010424] [Batch 00552/01234] [00:06:15/00:07:44, 0.681s/it]: train_loss_raw=1.5819, running_loss=1.6206, LR=0.000100
[2025-08-25 23:54:22,985][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010432] [Batch 00560/01234] [00:06:21/00:07:38, 0.681s/it]: train_loss_raw=1.6442, running_loss=1.6209, LR=0.000100
[2025-08-25 23:54:28,492][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010440] [Batch 00568/01234] [00:06:26/00:07:33, 0.681s/it]: train_loss_raw=1.5390, running_loss=1.6198, LR=0.000100
[2025-08-25 23:54:34,050][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010448] [Batch 00576/01234] [00:06:32/00:07:28, 0.681s/it]: train_loss_raw=1.6998, running_loss=1.6213, LR=0.000100
[2025-08-25 23:54:39,272][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010456] [Batch 00584/01234] [00:06:37/00:07:22, 0.681s/it]: train_loss_raw=1.6433, running_loss=1.6218, LR=0.000100
[2025-08-25 23:54:44,880][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010464] [Batch 00592/01234] [00:06:43/00:07:17, 0.681s/it]: train_loss_raw=1.5870, running_loss=1.6213, LR=0.000100
[2025-08-25 23:54:50,381][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010472] [Batch 00600/01234] [00:06:48/00:07:11, 0.681s/it]: train_loss_raw=1.5776, running_loss=1.6207, LR=0.000100
[2025-08-25 23:54:55,767][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010480] [Batch 00608/01234] [00:06:54/00:07:06, 0.681s/it]: train_loss_raw=1.6959, running_loss=1.6210, LR=0.000100
[2025-08-25 23:55:01,404][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010488] [Batch 00616/01234] [00:06:59/00:07:01, 0.681s/it]: train_loss_raw=1.6386, running_loss=1.6220, LR=0.000100
[2025-08-25 23:55:06,855][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010496] [Batch 00624/01234] [00:07:05/00:06:55, 0.681s/it]: train_loss_raw=1.5953, running_loss=1.6206, LR=0.000100
[2025-08-25 23:55:12,299][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010504] [Batch 00632/01234] [00:07:10/00:06:50, 0.681s/it]: train_loss_raw=1.6848, running_loss=1.6198, LR=0.000100
[2025-08-25 23:55:18,233][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010512] [Batch 00640/01234] [00:07:16/00:06:45, 0.682s/it]: train_loss_raw=1.7106, running_loss=1.6207, LR=0.000100
[2025-08-25 23:55:23,581][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010520] [Batch 00648/01234] [00:07:21/00:06:39, 0.682s/it]: train_loss_raw=1.6470, running_loss=1.6203, LR=0.000100
[2025-08-25 23:55:28,671][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010528] [Batch 00656/01234] [00:07:27/00:06:33, 0.681s/it]: train_loss_raw=1.5333, running_loss=1.6215, LR=0.000100
[2025-08-25 23:55:34,214][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010536] [Batch 00664/01234] [00:07:32/00:06:28, 0.682s/it]: train_loss_raw=1.5292, running_loss=1.6211, LR=0.000100
[2025-08-25 23:55:39,322][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010544] [Batch 00672/01234] [00:07:37/00:06:22, 0.681s/it]: train_loss_raw=1.6177, running_loss=1.6223, LR=0.000100
[2025-08-25 23:55:44,647][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010552] [Batch 00680/01234] [00:07:42/00:06:17, 0.681s/it]: train_loss_raw=1.7004, running_loss=1.6251, LR=0.000100
[2025-08-25 23:55:50,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010560] [Batch 00688/01234] [00:07:48/00:06:12, 0.682s/it]: train_loss_raw=1.6245, running_loss=1.6236, LR=0.000100
[2025-08-25 23:55:55,913][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010568] [Batch 00696/01234] [00:07:54/00:06:06, 0.681s/it]: train_loss_raw=1.5887, running_loss=1.6236, LR=0.000100
[2025-08-25 23:56:01,335][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010576] [Batch 00704/01234] [00:07:59/00:06:01, 0.681s/it]: train_loss_raw=1.6408, running_loss=1.6198, LR=0.000100
[2025-08-25 23:56:06,526][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010584] [Batch 00712/01234] [00:08:04/00:05:55, 0.681s/it]: train_loss_raw=1.6620, running_loss=1.6207, LR=0.000100
[2025-08-25 23:56:12,126][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010592] [Batch 00720/01234] [00:08:10/00:05:50, 0.681s/it]: train_loss_raw=1.6174, running_loss=1.6197, LR=0.000100
[2025-08-25 23:56:17,589][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010600] [Batch 00728/01234] [00:08:15/00:05:44, 0.681s/it]: train_loss_raw=1.6037, running_loss=1.6192, LR=0.000100
[2025-08-25 23:56:23,494][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010608] [Batch 00736/01234] [00:08:21/00:05:39, 0.682s/it]: train_loss_raw=1.6701, running_loss=1.6213, LR=0.000100
[2025-08-25 23:56:29,348][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010616] [Batch 00744/01234] [00:08:27/00:05:34, 0.682s/it]: train_loss_raw=1.5619, running_loss=1.6201, LR=0.000100
[2025-08-25 23:56:34,733][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010624] [Batch 00752/01234] [00:08:33/00:05:28, 0.682s/it]: train_loss_raw=1.5430, running_loss=1.6197, LR=0.000100
[2025-08-25 23:56:39,934][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010632] [Batch 00760/01234] [00:08:38/00:05:23, 0.682s/it]: train_loss_raw=1.6673, running_loss=1.6205, LR=0.000100
[2025-08-25 23:56:45,647][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010640] [Batch 00768/01234] [00:08:44/00:05:17, 0.682s/it]: train_loss_raw=1.6601, running_loss=1.6209, LR=0.000100
[2025-08-25 23:56:51,126][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010648] [Batch 00776/01234] [00:08:49/00:05:12, 0.682s/it]: train_loss_raw=1.6074, running_loss=1.6204, LR=0.000100
[2025-08-25 23:56:56,856][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010656] [Batch 00784/01234] [00:08:55/00:05:07, 0.683s/it]: train_loss_raw=1.6640, running_loss=1.6211, LR=0.000100
[2025-08-25 23:57:02,380][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010664] [Batch 00792/01234] [00:09:00/00:05:01, 0.683s/it]: train_loss_raw=1.7413, running_loss=1.6219, LR=0.000100
[2025-08-25 23:57:07,680][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010672] [Batch 00800/01234] [00:09:06/00:04:56, 0.683s/it]: train_loss_raw=1.5820, running_loss=1.6212, LR=0.000100
[2025-08-25 23:57:12,902][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010680] [Batch 00808/01234] [00:09:11/00:04:50, 0.682s/it]: train_loss_raw=1.5876, running_loss=1.6207, LR=0.000100
[2025-08-25 23:57:18,036][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010688] [Batch 00816/01234] [00:09:16/00:04:45, 0.682s/it]: train_loss_raw=1.7265, running_loss=1.6203, LR=0.000100
[2025-08-25 23:57:23,176][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010696] [Batch 00824/01234] [00:09:21/00:04:39, 0.681s/it]: train_loss_raw=1.5696, running_loss=1.6216, LR=0.000100
[2025-08-25 23:57:28,313][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010704] [Batch 00832/01234] [00:09:26/00:04:33, 0.681s/it]: train_loss_raw=1.5990, running_loss=1.6227, LR=0.000100
[2025-08-25 23:57:33,431][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010712] [Batch 00840/01234] [00:09:31/00:04:28, 0.681s/it]: train_loss_raw=1.5719, running_loss=1.6226, LR=0.000100
[2025-08-25 23:57:38,552][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010720] [Batch 00848/01234] [00:09:36/00:04:22, 0.680s/it]: train_loss_raw=1.6408, running_loss=1.6249, LR=0.000100
[2025-08-25 23:57:43,677][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010728] [Batch 00856/01234] [00:09:42/00:04:17, 0.680s/it]: train_loss_raw=1.6480, running_loss=1.6243, LR=0.000100
[2025-08-25 23:57:48,875][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010736] [Batch 00864/01234] [00:09:47/00:04:11, 0.680s/it]: train_loss_raw=1.6845, running_loss=1.6229, LR=0.000100
[2025-08-25 23:57:54,408][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010744] [Batch 00872/01234] [00:09:52/00:04:06, 0.680s/it]: train_loss_raw=1.5291, running_loss=1.6196, LR=0.000100
[2025-08-25 23:57:59,705][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010752] [Batch 00880/01234] [00:09:58/00:04:00, 0.680s/it]: train_loss_raw=1.5538, running_loss=1.6182, LR=0.000100
[2025-08-25 23:58:04,977][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010760] [Batch 00888/01234] [00:10:03/00:03:55, 0.679s/it]: train_loss_raw=1.5616, running_loss=1.6156, LR=0.000100
[2025-08-25 23:58:10,720][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010768] [Batch 00896/01234] [00:10:09/00:03:49, 0.680s/it]: train_loss_raw=1.6260, running_loss=1.6151, LR=0.000100
[2025-08-25 23:58:16,001][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010776] [Batch 00904/01234] [00:10:14/00:03:44, 0.680s/it]: train_loss_raw=1.6809, running_loss=1.6163, LR=0.000100
[2025-08-25 23:58:21,214][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010784] [Batch 00912/01234] [00:10:19/00:03:38, 0.679s/it]: train_loss_raw=1.6278, running_loss=1.6188, LR=0.000100
[2025-08-25 23:58:26,885][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010792] [Batch 00920/01234] [00:10:25/00:03:33, 0.680s/it]: train_loss_raw=1.5459, running_loss=1.6184, LR=0.000100
[2025-08-25 23:58:32,067][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010800] [Batch 00928/01234] [00:10:30/00:03:27, 0.679s/it]: train_loss_raw=1.6245, running_loss=1.6165, LR=0.000100
[2025-08-25 23:58:37,739][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010808] [Batch 00936/01234] [00:10:36/00:03:22, 0.680s/it]: train_loss_raw=1.6270, running_loss=1.6179, LR=0.000100
[2025-08-25 23:58:43,183][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010816] [Batch 00944/01234] [00:10:41/00:03:17, 0.680s/it]: train_loss_raw=1.6139, running_loss=1.6184, LR=0.000100
[2025-08-25 23:58:48,297][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010824] [Batch 00952/01234] [00:10:46/00:03:11, 0.679s/it]: train_loss_raw=1.5669, running_loss=1.6192, LR=0.000100
[2025-08-25 23:58:54,382][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010832] [Batch 00960/01234] [00:10:52/00:03:06, 0.680s/it]: train_loss_raw=1.6164, running_loss=1.6182, LR=0.000100
[2025-08-25 23:59:00,051][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010840] [Batch 00968/01234] [00:10:58/00:03:00, 0.680s/it]: train_loss_raw=1.5627, running_loss=1.6175, LR=0.000100
[2025-08-25 23:59:05,575][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010848] [Batch 00976/01234] [00:11:03/00:02:55, 0.680s/it]: train_loss_raw=1.6667, running_loss=1.6196, LR=0.000100
[2025-08-25 23:59:11,140][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010856] [Batch 00984/01234] [00:11:09/00:02:50, 0.680s/it]: train_loss_raw=1.5979, running_loss=1.6217, LR=0.000100
[2025-08-25 23:59:16,268][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010864] [Batch 00992/01234] [00:11:14/00:02:44, 0.680s/it]: train_loss_raw=1.5397, running_loss=1.6189, LR=0.000100
[2025-08-25 23:59:21,879][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010872] [Batch 01000/01234] [00:11:20/00:02:39, 0.680s/it]: train_loss_raw=1.6636, running_loss=1.6193, LR=0.000100
[2025-08-25 23:59:27,056][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010880] [Batch 01008/01234] [00:11:25/00:02:33, 0.680s/it]: train_loss_raw=1.7050, running_loss=1.6217, LR=0.000100
[2025-08-25 23:59:32,181][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010888] [Batch 01016/01234] [00:11:30/00:02:28, 0.680s/it]: train_loss_raw=1.5463, running_loss=1.6238, LR=0.000100
[2025-08-25 23:59:37,296][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010896] [Batch 01024/01234] [00:11:35/00:02:22, 0.679s/it]: train_loss_raw=1.5454, running_loss=1.6174, LR=0.000100
[2025-08-25 23:59:43,098][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010904] [Batch 01032/01234] [00:11:41/00:02:17, 0.680s/it]: train_loss_raw=1.6467, running_loss=1.6171, LR=0.000100
[2025-08-25 23:59:48,637][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010912] [Batch 01040/01234] [00:11:46/00:02:11, 0.680s/it]: train_loss_raw=1.5719, running_loss=1.6166, LR=0.000100
[2025-08-25 23:59:53,816][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010920] [Batch 01048/01234] [00:11:52/00:02:06, 0.680s/it]: train_loss_raw=1.6575, running_loss=1.6198, LR=0.000100
[2025-08-25 23:59:59,361][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010928] [Batch 01056/01234] [00:11:57/00:02:00, 0.680s/it]: train_loss_raw=1.6552, running_loss=1.6199, LR=0.000100
[2025-08-26 00:00:04,472][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010936] [Batch 01064/01234] [00:12:02/00:01:55, 0.679s/it]: train_loss_raw=1.5610, running_loss=1.6185, LR=0.000100
[2025-08-26 00:00:09,560][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010944] [Batch 01072/01234] [00:12:07/00:01:50, 0.679s/it]: train_loss_raw=1.6661, running_loss=1.6200, LR=0.000100
[2025-08-26 00:00:15,534][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010952] [Batch 01080/01234] [00:12:13/00:01:44, 0.680s/it]: train_loss_raw=1.6484, running_loss=1.6219, LR=0.000100
[2025-08-26 00:00:20,848][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010960] [Batch 01088/01234] [00:12:19/00:01:39, 0.679s/it]: train_loss_raw=1.5685, running_loss=1.6203, LR=0.000100
[2025-08-26 00:00:25,966][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010968] [Batch 01096/01234] [00:12:24/00:01:33, 0.679s/it]: train_loss_raw=1.6268, running_loss=1.6201, LR=0.000100
[2025-08-26 00:00:31,631][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010976] [Batch 01104/01234] [00:12:29/00:01:28, 0.679s/it]: train_loss_raw=1.5522, running_loss=1.6184, LR=0.000100
[2025-08-26 00:00:36,799][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010984] [Batch 01112/01234] [00:12:35/00:01:22, 0.679s/it]: train_loss_raw=1.5538, running_loss=1.6162, LR=0.000100
[2025-08-26 00:00:42,035][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 010992] [Batch 01120/01234] [00:12:40/00:01:17, 0.679s/it]: train_loss_raw=1.5745, running_loss=1.6157, LR=0.000100
[2025-08-26 00:00:47,814][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011000] [Batch 01128/01234] [00:12:46/00:01:11, 0.679s/it]: train_loss_raw=1.5534, running_loss=1.6141, LR=0.000100
[2025-08-26 00:00:53,573][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011008] [Batch 01136/01234] [00:12:51/00:01:06, 0.680s/it]: train_loss_raw=1.5867, running_loss=1.6133, LR=0.000100
[2025-08-26 00:00:59,430][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011016] [Batch 01144/01234] [00:12:57/00:01:01, 0.680s/it]: train_loss_raw=1.6148, running_loss=1.6131, LR=0.000100
[2025-08-26 00:01:05,360][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011024] [Batch 01152/01234] [00:13:03/00:00:55, 0.680s/it]: train_loss_raw=1.6788, running_loss=1.6126, LR=0.000100
[2025-08-26 00:01:11,028][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011032] [Batch 01160/01234] [00:13:09/00:00:50, 0.681s/it]: train_loss_raw=1.5260, running_loss=1.6135, LR=0.000100
[2025-08-26 00:01:17,065][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011040] [Batch 01168/01234] [00:13:15/00:00:44, 0.681s/it]: train_loss_raw=1.6652, running_loss=1.6159, LR=0.000100
[2025-08-26 00:01:22,908][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011048] [Batch 01176/01234] [00:13:21/00:00:39, 0.681s/it]: train_loss_raw=1.6546, running_loss=1.6149, LR=0.000100
[2025-08-26 00:01:28,382][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011056] [Batch 01184/01234] [00:13:26/00:00:34, 0.681s/it]: train_loss_raw=1.4996, running_loss=1.6160, LR=0.000100
[2025-08-26 00:01:34,147][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011064] [Batch 01192/01234] [00:13:32/00:00:28, 0.682s/it]: train_loss_raw=1.6351, running_loss=1.6141, LR=0.000100
[2025-08-26 00:01:40,046][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011072] [Batch 01200/01234] [00:13:38/00:00:23, 0.682s/it]: train_loss_raw=1.6395, running_loss=1.6152, LR=0.000100
[2025-08-26 00:01:45,456][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011080] [Batch 01208/01234] [00:13:43/00:00:17, 0.682s/it]: train_loss_raw=1.6655, running_loss=1.6160, LR=0.000100
[2025-08-26 00:01:51,472][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011088] [Batch 01216/01234] [00:13:49/00:00:12, 0.682s/it]: train_loss_raw=1.5618, running_loss=1.6139, LR=0.000100
[2025-08-26 00:01:57,340][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011096] [Batch 01224/01234] [00:13:55/00:00:06, 0.683s/it]: train_loss_raw=1.6334, running_loss=1.6140, LR=0.000100
[2025-08-26 00:02:03,344][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 011104] [Batch 01232/01234] [00:14:01/00:00:01, 0.683s/it]: train_loss_raw=1.5466, running_loss=1.6115, LR=0.000100
[2025-08-26 00:02:12,536][__main__][INFO] - [VALIDATION] [Epoch 08/29] Starting validation.
[2025-08-26 00:02:23,480][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 011107] [Batch 00007/00026] [00:00:10/00:00:24, 1.368s/it]
[2025-08-26 00:02:35,277][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 011107] [Batch 00015/00026] [00:00:22/00:00:14, 1.421s/it]
[2025-08-26 00:02:46,674][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 011107] [Batch 00023/00026] [00:00:34/00:00:02, 1.422s/it]
[2025-08-26 00:02:49,419][__main__][INFO] - [VALIDATION] [Epoch 08/29] train_loss=1.61141, valid_loss=1.67425
[2025-08-26 00:02:49,419][__main__][INFO] - [VALIDATION] [Epoch 08/29] Metrics:
[2025-08-26 00:02:49,419][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_er      0.693
[2025-08-26 00:02:49,419][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_prec    0.037
[2025-08-26 00:02:49,420][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_recall  0.037
[2025-08-26 00:02:49,420][__main__][INFO] - [VALIDATION] [Epoch 08/29] - pep_recall 0.003
[2025-08-26 00:02:49,422][__main__][INFO] - [TRAIN] [Epoch 08/29] Epoch complete, total time 02:11:58, remaining time 05:07:56, 00:14:39 per epoch
[2025-08-26 00:02:53,449][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011112] [Batch 00006/01234] [00:00:03/00:12:50, 0.627s/it]: train_loss_raw=1.5861, running_loss=1.4717, LR=0.000100
[2025-08-26 00:02:59,006][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011120] [Batch 00014/01234] [00:00:09/00:13:32, 0.666s/it]: train_loss_raw=1.6139, running_loss=1.4824, LR=0.000100
[2025-08-26 00:03:04,784][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011128] [Batch 00022/01234] [00:00:15/00:13:51, 0.686s/it]: train_loss_raw=1.4655, running_loss=1.4869, LR=0.000100
[2025-08-26 00:03:10,802][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011136] [Batch 00030/01234] [00:00:21/00:14:07, 0.704s/it]: train_loss_raw=1.5039, running_loss=1.4936, LR=0.000100
[2025-08-26 00:03:16,371][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011144] [Batch 00038/01234] [00:00:26/00:13:59, 0.702s/it]: train_loss_raw=1.6860, running_loss=1.5025, LR=0.000100
[2025-08-26 00:03:22,562][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011152] [Batch 00046/01234] [00:00:32/00:14:09, 0.715s/it]: train_loss_raw=1.5053, running_loss=1.5054, LR=0.000100
[2025-08-26 00:03:28,387][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011160] [Batch 00054/01234] [00:00:38/00:14:05, 0.717s/it]: train_loss_raw=1.6141, running_loss=1.5117, LR=0.000100
[2025-08-26 00:03:34,186][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011168] [Batch 00062/01234] [00:00:44/00:14:01, 0.718s/it]: train_loss_raw=1.4870, running_loss=1.5150, LR=0.000100
[2025-08-26 00:03:39,884][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011176] [Batch 00070/01234] [00:00:50/00:13:54, 0.717s/it]: train_loss_raw=1.4360, running_loss=1.5160, LR=0.000100
[2025-08-26 00:03:45,298][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011184] [Batch 00078/01234] [00:00:55/00:13:44, 0.713s/it]: train_loss_raw=1.5554, running_loss=1.5187, LR=0.000100
[2025-08-26 00:03:50,844][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011192] [Batch 00086/01234] [00:01:01/00:13:36, 0.711s/it]: train_loss_raw=1.5346, running_loss=1.5239, LR=0.000100
[2025-08-26 00:03:56,207][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011200] [Batch 00094/01234] [00:01:06/00:13:26, 0.708s/it]: train_loss_raw=1.6506, running_loss=1.5286, LR=0.000100
[2025-08-26 00:04:01,598][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011208] [Batch 00102/01234] [00:01:11/00:13:18, 0.705s/it]: train_loss_raw=1.5702, running_loss=1.5321, LR=0.000100
[2025-08-26 00:04:07,054][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011216] [Batch 00110/01234] [00:01:17/00:13:10, 0.703s/it]: train_loss_raw=1.5452, running_loss=1.5362, LR=0.000100
[2025-08-26 00:04:12,187][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011224] [Batch 00118/01234] [00:01:22/00:13:00, 0.699s/it]: train_loss_raw=1.5464, running_loss=1.5361, LR=0.000100
[2025-08-26 00:04:17,490][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011232] [Batch 00126/01234] [00:01:27/00:12:52, 0.697s/it]: train_loss_raw=1.6490, running_loss=1.5397, LR=0.000100
[2025-08-26 00:04:22,768][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011240] [Batch 00134/01234] [00:01:33/00:12:44, 0.695s/it]: train_loss_raw=1.6265, running_loss=1.5423, LR=0.000100
[2025-08-26 00:04:28,098][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011248] [Batch 00142/01234] [00:01:38/00:12:36, 0.693s/it]: train_loss_raw=1.6256, running_loss=1.5461, LR=0.000100
[2025-08-26 00:04:33,672][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011256] [Batch 00150/01234] [00:01:43/00:12:31, 0.693s/it]: train_loss_raw=1.5618, running_loss=1.5487, LR=0.000100
[2025-08-26 00:04:38,757][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011264] [Batch 00158/01234] [00:01:49/00:12:22, 0.690s/it]: train_loss_raw=1.5832, running_loss=1.5520, LR=0.000100
[2025-08-26 00:04:43,856][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011272] [Batch 00166/01234] [00:01:54/00:12:14, 0.688s/it]: train_loss_raw=1.5463, running_loss=1.5525, LR=0.000100
[2025-08-26 00:04:49,554][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011280] [Batch 00174/01234] [00:01:59/00:12:10, 0.689s/it]: train_loss_raw=1.5361, running_loss=1.5533, LR=0.000100
[2025-08-26 00:04:55,320][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011288] [Batch 00182/01234] [00:02:05/00:12:06, 0.690s/it]: train_loss_raw=1.5183, running_loss=1.5542, LR=0.000100
[2025-08-26 00:05:00,963][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011296] [Batch 00190/01234] [00:02:11/00:12:01, 0.691s/it]: train_loss_raw=1.5202, running_loss=1.5557, LR=0.000100
[2025-08-26 00:05:06,412][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011304] [Batch 00198/01234] [00:02:16/00:11:55, 0.691s/it]: train_loss_raw=1.6300, running_loss=1.5573, LR=0.000100
[2025-08-26 00:05:11,715][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011312] [Batch 00206/01234] [00:02:22/00:11:48, 0.689s/it]: train_loss_raw=1.6228, running_loss=1.5610, LR=0.000100
[2025-08-26 00:05:17,390][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011320] [Batch 00214/01234] [00:02:27/00:11:44, 0.690s/it]: train_loss_raw=1.6348, running_loss=1.5620, LR=0.000100
[2025-08-26 00:05:22,668][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011328] [Batch 00222/01234] [00:02:32/00:11:37, 0.689s/it]: train_loss_raw=1.4837, running_loss=1.5603, LR=0.000100
[2025-08-26 00:05:28,309][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011336] [Batch 00230/01234] [00:02:38/00:11:32, 0.690s/it]: train_loss_raw=1.5660, running_loss=1.5616, LR=0.000100
[2025-08-26 00:05:33,744][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011344] [Batch 00238/01234] [00:02:44/00:11:26, 0.689s/it]: train_loss_raw=1.5463, running_loss=1.5615, LR=0.000100
[2025-08-26 00:05:38,980][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011352] [Batch 00246/01234] [00:02:49/00:11:19, 0.688s/it]: train_loss_raw=1.5089, running_loss=1.5618, LR=0.000100
[2025-08-26 00:05:44,398][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011360] [Batch 00254/01234] [00:02:54/00:11:14, 0.688s/it]: train_loss_raw=1.6533, running_loss=1.5657, LR=0.000100
[2025-08-26 00:05:50,122][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011368] [Batch 00262/01234] [00:03:00/00:11:09, 0.689s/it]: train_loss_raw=1.6387, running_loss=1.5674, LR=0.000100
[2025-08-26 00:05:55,245][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011376] [Batch 00270/01234] [00:03:05/00:11:02, 0.687s/it]: train_loss_raw=1.6559, running_loss=1.5682, LR=0.000100
[2025-08-26 00:06:00,340][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011384] [Batch 00278/01234] [00:03:10/00:10:55, 0.686s/it]: train_loss_raw=1.5309, running_loss=1.5682, LR=0.000100
[2025-08-26 00:06:05,465][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011392] [Batch 00286/01234] [00:03:15/00:10:48, 0.685s/it]: train_loss_raw=1.5640, running_loss=1.5672, LR=0.000100
[2025-08-26 00:06:10,625][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011400] [Batch 00294/01234] [00:03:20/00:10:42, 0.683s/it]: train_loss_raw=1.6101, running_loss=1.5686, LR=0.000100
[2025-08-26 00:06:16,356][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011408] [Batch 00302/01234] [00:03:26/00:10:37, 0.684s/it]: train_loss_raw=1.5020, running_loss=1.5657, LR=0.000100
[2025-08-26 00:06:21,476][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011416] [Batch 00310/01234] [00:03:31/00:10:31, 0.683s/it]: train_loss_raw=1.5236, running_loss=1.5690, LR=0.000100
[2025-08-26 00:06:27,335][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011424] [Batch 00318/01234] [00:03:37/00:10:26, 0.684s/it]: train_loss_raw=1.6256, running_loss=1.5694, LR=0.000100
[2025-08-26 00:06:32,989][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011432] [Batch 00326/01234] [00:03:43/00:10:21, 0.685s/it]: train_loss_raw=1.5532, running_loss=1.5682, LR=0.000100
[2025-08-26 00:06:38,329][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011440] [Batch 00334/01234] [00:03:48/00:10:16, 0.685s/it]: train_loss_raw=1.5670, running_loss=1.5716, LR=0.000100
[2025-08-26 00:06:44,292][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011448] [Batch 00342/01234] [00:03:54/00:10:11, 0.686s/it]: train_loss_raw=1.5488, running_loss=1.5709, LR=0.000100
[2025-08-26 00:06:49,851][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011456] [Batch 00350/01234] [00:04:00/00:10:06, 0.686s/it]: train_loss_raw=1.5923, running_loss=1.5685, LR=0.000100
[2025-08-26 00:06:55,039][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011464] [Batch 00358/01234] [00:04:05/00:10:00, 0.685s/it]: train_loss_raw=1.5835, running_loss=1.5678, LR=0.000100
[2025-08-26 00:07:00,848][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011472] [Batch 00366/01234] [00:04:11/00:09:55, 0.686s/it]: train_loss_raw=1.6341, running_loss=1.5711, LR=0.000100
[2025-08-26 00:07:06,723][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011480] [Batch 00374/01234] [00:04:17/00:09:51, 0.687s/it]: train_loss_raw=1.5094, running_loss=1.5724, LR=0.000100
[2025-08-26 00:07:12,472][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011488] [Batch 00382/01234] [00:04:22/00:09:46, 0.688s/it]: train_loss_raw=1.5763, running_loss=1.5726, LR=0.000100
[2025-08-26 00:07:18,340][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011496] [Batch 00390/01234] [00:04:28/00:09:41, 0.689s/it]: train_loss_raw=1.5579, running_loss=1.5731, LR=0.000100
[2025-08-26 00:07:24,207][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011504] [Batch 00398/01234] [00:04:34/00:09:36, 0.690s/it]: train_loss_raw=1.5399, running_loss=1.5710, LR=0.000100
[2025-08-26 00:07:30,255][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011512] [Batch 00406/01234] [00:04:40/00:09:32, 0.691s/it]: train_loss_raw=1.5951, running_loss=1.5706, LR=0.000100
[2025-08-26 00:07:35,352][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011520] [Batch 00414/01234] [00:04:45/00:09:25, 0.690s/it]: train_loss_raw=1.5941, running_loss=1.5715, LR=0.000100
[2025-08-26 00:07:40,881][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011528] [Batch 00422/01234] [00:04:51/00:09:20, 0.690s/it]: train_loss_raw=1.5786, running_loss=1.5714, LR=0.000100
[2025-08-26 00:07:46,279][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011536] [Batch 00430/01234] [00:04:56/00:09:14, 0.690s/it]: train_loss_raw=1.6061, running_loss=1.5731, LR=0.000100
[2025-08-26 00:07:51,374][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011544] [Batch 00438/01234] [00:05:01/00:09:08, 0.689s/it]: train_loss_raw=1.4366, running_loss=1.5722, LR=0.000100
[2025-08-26 00:07:56,471][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011552] [Batch 00446/01234] [00:05:06/00:09:02, 0.688s/it]: train_loss_raw=1.5967, running_loss=1.5741, LR=0.000100
[2025-08-26 00:08:01,564][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011560] [Batch 00454/01234] [00:05:11/00:08:55, 0.687s/it]: train_loss_raw=1.5446, running_loss=1.5744, LR=0.000100
[2025-08-26 00:08:07,094][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011568] [Batch 00462/01234] [00:05:17/00:08:50, 0.687s/it]: train_loss_raw=1.4557, running_loss=1.5731, LR=0.000100
[2025-08-26 00:08:12,307][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011576] [Batch 00470/01234] [00:05:22/00:08:44, 0.686s/it]: train_loss_raw=1.5622, running_loss=1.5707, LR=0.000100
[2025-08-26 00:08:17,394][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011584] [Batch 00478/01234] [00:05:27/00:08:38, 0.686s/it]: train_loss_raw=1.5902, running_loss=1.5693, LR=0.000100
[2025-08-26 00:08:22,645][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011592] [Batch 00486/01234] [00:05:32/00:08:32, 0.685s/it]: train_loss_raw=1.5289, running_loss=1.5705, LR=0.000100
[2025-08-26 00:08:27,836][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011600] [Batch 00494/01234] [00:05:38/00:08:26, 0.685s/it]: train_loss_raw=1.6611, running_loss=1.5711, LR=0.000100
[2025-08-26 00:08:33,703][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011608] [Batch 00502/01234] [00:05:44/00:08:21, 0.685s/it]: train_loss_raw=1.5305, running_loss=1.5740, LR=0.000100
[2025-08-26 00:08:39,736][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011616] [Batch 00510/01234] [00:05:50/00:08:16, 0.686s/it]: train_loss_raw=1.5751, running_loss=1.5733, LR=0.000100
[2025-08-26 00:08:45,040][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011624] [Batch 00518/01234] [00:05:55/00:08:11, 0.686s/it]: train_loss_raw=1.5893, running_loss=1.5740, LR=0.000100
[2025-08-26 00:08:50,267][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011632] [Batch 00526/01234] [00:06:00/00:08:05, 0.686s/it]: train_loss_raw=1.6224, running_loss=1.5755, LR=0.000100
[2025-08-26 00:08:55,633][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011640] [Batch 00534/01234] [00:06:05/00:07:59, 0.685s/it]: train_loss_raw=1.6532, running_loss=1.5767, LR=0.000100
[2025-08-26 00:09:01,469][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011648] [Batch 00542/01234] [00:06:11/00:07:54, 0.686s/it]: train_loss_raw=1.6061, running_loss=1.5773, LR=0.000100
[2025-08-26 00:09:06,632][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011656] [Batch 00550/01234] [00:06:16/00:07:48, 0.685s/it]: train_loss_raw=1.6177, running_loss=1.5798, LR=0.000100
[2025-08-26 00:09:12,514][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011664] [Batch 00558/01234] [00:06:22/00:07:43, 0.686s/it]: train_loss_raw=1.6472, running_loss=1.5794, LR=0.000100
[2025-08-26 00:09:18,085][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011672] [Batch 00566/01234] [00:06:28/00:07:38, 0.686s/it]: train_loss_raw=1.5839, running_loss=1.5797, LR=0.000100
[2025-08-26 00:09:23,616][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011680] [Batch 00574/01234] [00:06:33/00:07:32, 0.686s/it]: train_loss_raw=1.5316, running_loss=1.5800, LR=0.000100
[2025-08-26 00:09:29,086][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011688] [Batch 00582/01234] [00:06:39/00:07:27, 0.686s/it]: train_loss_raw=1.5956, running_loss=1.5768, LR=0.000100
[2025-08-26 00:09:34,548][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011696] [Batch 00590/01234] [00:06:44/00:07:21, 0.686s/it]: train_loss_raw=1.6277, running_loss=1.5776, LR=0.000100
[2025-08-26 00:09:39,743][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011704] [Batch 00598/01234] [00:06:50/00:07:16, 0.686s/it]: train_loss_raw=1.5513, running_loss=1.5772, LR=0.000100
[2025-08-26 00:09:45,116][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011712] [Batch 00606/01234] [00:06:55/00:07:10, 0.686s/it]: train_loss_raw=1.5148, running_loss=1.5782, LR=0.000100
[2025-08-26 00:09:50,188][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011720] [Batch 00614/01234] [00:07:00/00:07:04, 0.685s/it]: train_loss_raw=1.6090, running_loss=1.5768, LR=0.000100
[2025-08-26 00:09:55,242][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011728] [Batch 00622/01234] [00:07:05/00:06:58, 0.684s/it]: train_loss_raw=1.6126, running_loss=1.5788, LR=0.000100
[2025-08-26 00:10:01,006][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011736] [Batch 00630/01234] [00:07:11/00:06:53, 0.685s/it]: train_loss_raw=1.5070, running_loss=1.5794, LR=0.000100
[2025-08-26 00:10:06,336][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011744] [Batch 00638/01234] [00:07:16/00:06:47, 0.684s/it]: train_loss_raw=1.5649, running_loss=1.5778, LR=0.000100
[2025-08-26 00:10:11,535][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011752] [Batch 00646/01234] [00:07:21/00:06:42, 0.684s/it]: train_loss_raw=1.5792, running_loss=1.5771, LR=0.000100
[2025-08-26 00:10:17,297][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011760] [Batch 00654/01234] [00:07:27/00:06:36, 0.684s/it]: train_loss_raw=1.6452, running_loss=1.5788, LR=0.000100
[2025-08-26 00:10:23,109][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011768] [Batch 00662/01234] [00:07:33/00:06:31, 0.685s/it]: train_loss_raw=1.6121, running_loss=1.5775, LR=0.000100
[2025-08-26 00:10:28,205][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011776] [Batch 00670/01234] [00:07:38/00:06:25, 0.684s/it]: train_loss_raw=1.5969, running_loss=1.5797, LR=0.000100
[2025-08-26 00:10:33,603][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011784] [Batch 00678/01234] [00:07:43/00:06:20, 0.684s/it]: train_loss_raw=1.5437, running_loss=1.5789, LR=0.000100
[2025-08-26 00:10:38,691][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011792] [Batch 00686/01234] [00:07:49/00:06:14, 0.684s/it]: train_loss_raw=1.5599, running_loss=1.5795, LR=0.000100
[2025-08-26 00:10:43,782][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011800] [Batch 00694/01234] [00:07:54/00:06:08, 0.683s/it]: train_loss_raw=1.6245, running_loss=1.5796, LR=0.000100
[2025-08-26 00:10:48,898][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011808] [Batch 00702/01234] [00:07:59/00:06:03, 0.683s/it]: train_loss_raw=1.5399, running_loss=1.5800, LR=0.000100
[2025-08-26 00:10:54,004][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011816] [Batch 00710/01234] [00:08:04/00:05:57, 0.682s/it]: train_loss_raw=1.5764, running_loss=1.5801, LR=0.000100
[2025-08-26 00:10:59,207][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011824] [Batch 00718/01234] [00:08:09/00:05:51, 0.682s/it]: train_loss_raw=1.6123, running_loss=1.5798, LR=0.000100
[2025-08-26 00:11:04,820][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011832] [Batch 00726/01234] [00:08:15/00:05:46, 0.682s/it]: train_loss_raw=1.5928, running_loss=1.5800, LR=0.000100
[2025-08-26 00:11:10,411][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011840] [Batch 00734/01234] [00:08:20/00:05:41, 0.682s/it]: train_loss_raw=1.6013, running_loss=1.5804, LR=0.000100
[2025-08-26 00:11:16,069][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011848] [Batch 00742/01234] [00:08:26/00:05:35, 0.682s/it]: train_loss_raw=1.6017, running_loss=1.5786, LR=0.000100
[2025-08-26 00:11:21,985][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011856] [Batch 00750/01234] [00:08:32/00:05:30, 0.683s/it]: train_loss_raw=1.5086, running_loss=1.5808, LR=0.000100
[2025-08-26 00:11:27,655][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011864] [Batch 00758/01234] [00:08:37/00:05:25, 0.683s/it]: train_loss_raw=1.6349, running_loss=1.5805, LR=0.000100
[2025-08-26 00:11:33,152][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011872] [Batch 00766/01234] [00:08:43/00:05:19, 0.683s/it]: train_loss_raw=1.5273, running_loss=1.5786, LR=0.000100
[2025-08-26 00:11:38,851][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011880] [Batch 00774/01234] [00:08:49/00:05:14, 0.684s/it]: train_loss_raw=1.5282, running_loss=1.5769, LR=0.000100
[2025-08-26 00:11:44,630][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011888] [Batch 00782/01234] [00:08:54/00:05:09, 0.684s/it]: train_loss_raw=1.5632, running_loss=1.5772, LR=0.000100
[2025-08-26 00:11:50,097][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011896] [Batch 00790/01234] [00:09:00/00:05:03, 0.684s/it]: train_loss_raw=1.6233, running_loss=1.5780, LR=0.000100
[2025-08-26 00:11:55,187][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011904] [Batch 00798/01234] [00:09:05/00:04:58, 0.684s/it]: train_loss_raw=1.5776, running_loss=1.5787, LR=0.000100
[2025-08-26 00:12:00,647][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011912] [Batch 00806/01234] [00:09:10/00:04:52, 0.684s/it]: train_loss_raw=1.5911, running_loss=1.5775, LR=0.000100
[2025-08-26 00:12:05,749][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011920] [Batch 00814/01234] [00:09:16/00:04:46, 0.683s/it]: train_loss_raw=1.5450, running_loss=1.5756, LR=0.000100
[2025-08-26 00:12:11,403][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011928] [Batch 00822/01234] [00:09:21/00:04:41, 0.683s/it]: train_loss_raw=1.6098, running_loss=1.5763, LR=0.000100
[2025-08-26 00:12:17,139][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011936] [Batch 00830/01234] [00:09:27/00:04:36, 0.684s/it]: train_loss_raw=1.4719, running_loss=1.5750, LR=0.000100
[2025-08-26 00:12:22,405][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011944] [Batch 00838/01234] [00:09:32/00:04:30, 0.683s/it]: train_loss_raw=1.6090, running_loss=1.5729, LR=0.000100
[2025-08-26 00:12:27,493][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011952] [Batch 00846/01234] [00:09:37/00:04:24, 0.683s/it]: train_loss_raw=1.6347, running_loss=1.5730, LR=0.000100
[2025-08-26 00:12:32,631][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011960] [Batch 00854/01234] [00:09:42/00:04:19, 0.683s/it]: train_loss_raw=1.5575, running_loss=1.5718, LR=0.000100
[2025-08-26 00:12:38,411][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011968] [Batch 00862/01234] [00:09:48/00:04:14, 0.683s/it]: train_loss_raw=1.6272, running_loss=1.5733, LR=0.000100
[2025-08-26 00:12:44,152][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011976] [Batch 00870/01234] [00:09:54/00:04:08, 0.683s/it]: train_loss_raw=1.5852, running_loss=1.5751, LR=0.000100
[2025-08-26 00:12:49,881][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011984] [Batch 00878/01234] [00:10:00/00:04:03, 0.684s/it]: train_loss_raw=1.5479, running_loss=1.5738, LR=0.000100
[2025-08-26 00:12:55,413][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 011992] [Batch 00886/01234] [00:10:05/00:03:57, 0.684s/it]: train_loss_raw=1.6155, running_loss=1.5757, LR=0.000100
[2025-08-26 00:13:01,216][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012000] [Batch 00894/01234] [00:10:11/00:03:52, 0.684s/it]: train_loss_raw=1.5217, running_loss=1.5770, LR=0.000100
[2025-08-26 00:13:10,696][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012008] [Batch 00902/01234] [00:10:21/00:03:48, 0.688s/it]: train_loss_raw=1.6418, running_loss=1.5781, LR=0.000100
[2025-08-26 00:13:16,181][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012016] [Batch 00910/01234] [00:10:26/00:03:43, 0.688s/it]: train_loss_raw=1.5253, running_loss=1.5767, LR=0.000100
[2025-08-26 00:13:21,553][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012024] [Batch 00918/01234] [00:10:31/00:03:37, 0.688s/it]: train_loss_raw=1.5568, running_loss=1.5766, LR=0.000100
[2025-08-26 00:13:26,856][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012032] [Batch 00926/01234] [00:10:37/00:03:31, 0.688s/it]: train_loss_raw=1.5356, running_loss=1.5765, LR=0.000100
[2025-08-26 00:13:32,290][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012040] [Batch 00934/01234] [00:10:42/00:03:26, 0.688s/it]: train_loss_raw=1.5654, running_loss=1.5768, LR=0.000100
[2025-08-26 00:13:38,019][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012048] [Batch 00942/01234] [00:10:48/00:03:20, 0.688s/it]: train_loss_raw=1.4963, running_loss=1.5762, LR=0.000100
[2025-08-26 00:13:43,533][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012056] [Batch 00950/01234] [00:10:53/00:03:15, 0.688s/it]: train_loss_raw=1.5980, running_loss=1.5749, LR=0.000100
[2025-08-26 00:13:48,850][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012064] [Batch 00958/01234] [00:10:59/00:03:09, 0.688s/it]: train_loss_raw=1.5831, running_loss=1.5738, LR=0.000100
[2025-08-26 00:13:54,436][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012072] [Batch 00966/01234] [00:11:04/00:03:04, 0.688s/it]: train_loss_raw=1.4666, running_loss=1.5744, LR=0.000100
[2025-08-26 00:13:59,891][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012080] [Batch 00974/01234] [00:11:10/00:02:58, 0.688s/it]: train_loss_raw=1.5205, running_loss=1.5738, LR=0.000100
[2025-08-26 00:14:05,258][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012088] [Batch 00982/01234] [00:11:15/00:02:53, 0.688s/it]: train_loss_raw=1.5105, running_loss=1.5718, LR=0.000100
[2025-08-26 00:14:10,469][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012096] [Batch 00990/01234] [00:11:20/00:02:47, 0.688s/it]: train_loss_raw=1.5923, running_loss=1.5691, LR=0.000100
[2025-08-26 00:14:15,621][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012104] [Batch 00998/01234] [00:11:25/00:02:42, 0.687s/it]: train_loss_raw=1.4949, running_loss=1.5689, LR=0.000100
[2025-08-26 00:14:20,745][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012112] [Batch 01006/01234] [00:11:31/00:02:36, 0.687s/it]: train_loss_raw=1.5497, running_loss=1.5694, LR=0.000100
[2025-08-26 00:14:25,953][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012120] [Batch 01014/01234] [00:11:36/00:02:31, 0.687s/it]: train_loss_raw=1.5013, running_loss=1.5675, LR=0.000100
[2025-08-26 00:14:31,360][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012128] [Batch 01022/01234] [00:11:41/00:02:25, 0.687s/it]: train_loss_raw=1.6046, running_loss=1.5691, LR=0.000100
[2025-08-26 00:14:36,988][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012136] [Batch 01030/01234] [00:11:47/00:02:20, 0.687s/it]: train_loss_raw=1.5200, running_loss=1.5688, LR=0.000100
[2025-08-26 00:14:42,451][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012144] [Batch 01038/01234] [00:11:52/00:02:14, 0.687s/it]: train_loss_raw=1.5520, running_loss=1.5682, LR=0.000100
[2025-08-26 00:14:48,093][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012152] [Batch 01046/01234] [00:11:58/00:02:09, 0.687s/it]: train_loss_raw=1.5451, running_loss=1.5693, LR=0.000100
[2025-08-26 00:14:53,838][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012160] [Batch 01054/01234] [00:12:04/00:02:03, 0.687s/it]: train_loss_raw=1.5753, running_loss=1.5705, LR=0.000100
[2025-08-26 00:14:59,059][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012168] [Batch 01062/01234] [00:12:09/00:01:58, 0.687s/it]: train_loss_raw=1.5410, running_loss=1.5692, LR=0.000100
[2025-08-26 00:15:04,351][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012176] [Batch 01070/01234] [00:12:14/00:01:52, 0.687s/it]: train_loss_raw=1.5315, running_loss=1.5692, LR=0.000100
[2025-08-26 00:15:09,470][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012184] [Batch 01078/01234] [00:12:19/00:01:47, 0.686s/it]: train_loss_raw=1.6189, running_loss=1.5723, LR=0.000100
[2025-08-26 00:15:14,914][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012192] [Batch 01086/01234] [00:12:25/00:01:41, 0.686s/it]: train_loss_raw=1.5502, running_loss=1.5727, LR=0.000100
[2025-08-26 00:15:20,548][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012200] [Batch 01094/01234] [00:12:30/00:01:36, 0.686s/it]: train_loss_raw=1.5699, running_loss=1.5693, LR=0.000100
[2025-08-26 00:15:25,901][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012208] [Batch 01102/01234] [00:12:36/00:01:30, 0.686s/it]: train_loss_raw=1.5911, running_loss=1.5691, LR=0.000100
[2025-08-26 00:15:31,044][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012216] [Batch 01110/01234] [00:12:41/00:01:25, 0.686s/it]: train_loss_raw=1.6199, running_loss=1.5702, LR=0.000100
[2025-08-26 00:15:36,733][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012224] [Batch 01118/01234] [00:12:47/00:01:19, 0.686s/it]: train_loss_raw=1.5229, running_loss=1.5691, LR=0.000100
[2025-08-26 00:15:42,287][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012232] [Batch 01126/01234] [00:12:52/00:01:14, 0.686s/it]: train_loss_raw=1.4983, running_loss=1.5664, LR=0.000100
[2025-08-26 00:15:48,047][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012240] [Batch 01134/01234] [00:12:58/00:01:08, 0.686s/it]: train_loss_raw=1.6062, running_loss=1.5661, LR=0.000100
[2025-08-26 00:15:53,375][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012248] [Batch 01142/01234] [00:13:03/00:01:03, 0.686s/it]: train_loss_raw=1.5522, running_loss=1.5661, LR=0.000100
[2025-08-26 00:15:58,710][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012256] [Batch 01150/01234] [00:13:09/00:00:57, 0.686s/it]: train_loss_raw=1.5388, running_loss=1.5662, LR=0.000100
[2025-08-26 00:16:04,136][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012264] [Batch 01158/01234] [00:13:14/00:00:52, 0.686s/it]: train_loss_raw=1.5249, running_loss=1.5626, LR=0.000100
[2025-08-26 00:16:09,926][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012272] [Batch 01166/01234] [00:13:20/00:00:46, 0.686s/it]: train_loss_raw=1.6822, running_loss=1.5656, LR=0.000100
[2025-08-26 00:16:15,745][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012280] [Batch 01174/01234] [00:13:26/00:00:41, 0.687s/it]: train_loss_raw=1.5558, running_loss=1.5650, LR=0.000100
[2025-08-26 00:16:21,336][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012288] [Batch 01182/01234] [00:13:31/00:00:35, 0.687s/it]: train_loss_raw=1.4870, running_loss=1.5663, LR=0.000100
[2025-08-26 00:16:26,618][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012296] [Batch 01190/01234] [00:13:36/00:00:30, 0.686s/it]: train_loss_raw=1.6121, running_loss=1.5700, LR=0.000100
[2025-08-26 00:16:32,393][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012304] [Batch 01198/01234] [00:13:42/00:00:24, 0.687s/it]: train_loss_raw=1.5718, running_loss=1.5695, LR=0.000100
[2025-08-26 00:16:38,227][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012312] [Batch 01206/01234] [00:13:48/00:00:19, 0.687s/it]: train_loss_raw=1.5496, running_loss=1.5681, LR=0.000100
[2025-08-26 00:16:43,654][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012320] [Batch 01214/01234] [00:13:53/00:00:13, 0.687s/it]: train_loss_raw=1.6080, running_loss=1.5689, LR=0.000100
[2025-08-26 00:16:49,000][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012328] [Batch 01222/01234] [00:13:59/00:00:08, 0.687s/it]: train_loss_raw=1.5269, running_loss=1.5665, LR=0.000100
[2025-08-26 00:16:54,193][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 012336] [Batch 01230/01234] [00:14:04/00:00:02, 0.687s/it]: train_loss_raw=1.5941, running_loss=1.5668, LR=0.000100
[2025-08-26 00:17:03,474][__main__][INFO] - [VALIDATION] [Epoch 09/29] Starting validation.
[2025-08-26 00:17:14,016][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 012341] [Batch 00007/00026] [00:00:10/00:00:23, 1.318s/it]
[2025-08-26 00:17:25,017][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 012341] [Batch 00015/00026] [00:00:21/00:00:13, 1.346s/it]
[2025-08-26 00:17:35,907][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 012341] [Batch 00023/00026] [00:00:32/00:00:02, 1.351s/it]
[2025-08-26 00:17:38,196][__main__][INFO] - [VALIDATION] [Epoch 09/29] train_loss=1.56425, valid_loss=1.64978
[2025-08-26 00:17:38,196][__main__][INFO] - [VALIDATION] [Epoch 09/29] Metrics:
[2025-08-26 00:17:38,196][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_er      0.685
[2025-08-26 00:17:38,196][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_prec    0.038
[2025-08-26 00:17:38,196][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_recall  0.039
[2025-08-26 00:17:38,196][__main__][INFO] - [VALIDATION] [Epoch 09/29] - pep_recall 0.006
[2025-08-26 00:17:38,198][__main__][INFO] - [TRAIN] [Epoch 09/29] Epoch complete, total time 02:26:47, remaining time 04:53:34, 00:14:40 per epoch
[2025-08-26 00:17:40,734][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012344] [Batch 00004/01234] [00:00:02/00:12:19, 0.601s/it]: train_loss_raw=1.5161, running_loss=1.5234, LR=0.000100
[2025-08-26 00:17:46,498][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012352] [Batch 00012/01234] [00:00:08/00:13:51, 0.681s/it]: train_loss_raw=1.5034, running_loss=1.5230, LR=0.000100
[2025-08-26 00:17:52,057][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012360] [Batch 00020/01234] [00:00:13/00:13:53, 0.686s/it]: train_loss_raw=1.4331, running_loss=1.5237, LR=0.000100
[2025-08-26 00:17:57,557][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012368] [Batch 00028/01234] [00:00:19/00:13:48, 0.687s/it]: train_loss_raw=1.5199, running_loss=1.5234, LR=0.000100
[2025-08-26 00:18:03,121][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012376] [Batch 00036/01234] [00:00:24/00:13:44, 0.689s/it]: train_loss_raw=1.5863, running_loss=1.5227, LR=0.000100
[2025-08-26 00:18:08,615][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012384] [Batch 00044/01234] [00:00:30/00:13:39, 0.688s/it]: train_loss_raw=1.5627, running_loss=1.5229, LR=0.000100
[2025-08-26 00:18:13,894][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012392] [Batch 00052/01234] [00:00:35/00:13:28, 0.684s/it]: train_loss_raw=1.5333, running_loss=1.5233, LR=0.000100
[2025-08-26 00:18:19,689][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012400] [Batch 00060/01234] [00:00:41/00:13:29, 0.689s/it]: train_loss_raw=1.5274, running_loss=1.5232, LR=0.000100
[2025-08-26 00:18:25,661][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012408] [Batch 00068/01234] [00:00:47/00:13:31, 0.696s/it]: train_loss_raw=1.5368, running_loss=1.5232, LR=0.000100
[2025-08-26 00:18:31,342][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012416] [Batch 00076/01234] [00:00:53/00:13:27, 0.698s/it]: train_loss_raw=1.5309, running_loss=1.5231, LR=0.000100
[2025-08-26 00:18:36,452][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012424] [Batch 00084/01234] [00:00:58/00:13:15, 0.692s/it]: train_loss_raw=1.5558, running_loss=1.5234, LR=0.000100
[2025-08-26 00:18:41,733][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012432] [Batch 00092/01234] [00:01:03/00:13:07, 0.689s/it]: train_loss_raw=1.5493, running_loss=1.5260, LR=0.000100
[2025-08-26 00:18:47,406][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012440] [Batch 00100/01234] [00:01:09/00:13:03, 0.691s/it]: train_loss_raw=1.5856, running_loss=1.5277, LR=0.000100
[2025-08-26 00:18:53,138][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012448] [Batch 00108/01234] [00:01:14/00:12:59, 0.693s/it]: train_loss_raw=1.4683, running_loss=1.5281, LR=0.000100
[2025-08-26 00:18:58,644][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012456] [Batch 00116/01234] [00:01:20/00:12:54, 0.692s/it]: train_loss_raw=1.4432, running_loss=1.5255, LR=0.000100
[2025-08-26 00:19:04,451][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012464] [Batch 00124/01234] [00:01:26/00:12:50, 0.695s/it]: train_loss_raw=1.5142, running_loss=1.5241, LR=0.000100
[2025-08-26 00:19:10,206][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012472] [Batch 00132/01234] [00:01:31/00:12:47, 0.696s/it]: train_loss_raw=1.4568, running_loss=1.5226, LR=0.000100
[2025-08-26 00:19:15,942][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012480] [Batch 00140/01234] [00:01:37/00:12:42, 0.697s/it]: train_loss_raw=1.5619, running_loss=1.5231, LR=0.000100
[2025-08-26 00:19:21,422][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012488] [Batch 00148/01234] [00:01:43/00:12:36, 0.697s/it]: train_loss_raw=1.5075, running_loss=1.5213, LR=0.000100
[2025-08-26 00:19:26,812][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012496] [Batch 00156/01234] [00:01:48/00:12:29, 0.695s/it]: train_loss_raw=1.5277, running_loss=1.5225, LR=0.000100
[2025-08-26 00:19:32,607][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012504] [Batch 00164/01234] [00:01:54/00:12:25, 0.697s/it]: train_loss_raw=1.5003, running_loss=1.5239, LR=0.000100
[2025-08-26 00:19:38,312][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012512] [Batch 00172/01234] [00:01:59/00:12:20, 0.698s/it]: train_loss_raw=1.5311, running_loss=1.5223, LR=0.000100
[2025-08-26 00:19:43,782][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012520] [Batch 00180/01234] [00:02:05/00:12:14, 0.697s/it]: train_loss_raw=1.5707, running_loss=1.5221, LR=0.000100
[2025-08-26 00:19:49,825][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012528] [Batch 00188/01234] [00:02:11/00:12:11, 0.699s/it]: train_loss_raw=1.4512, running_loss=1.5205, LR=0.000100
[2025-08-26 00:19:55,541][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012536] [Batch 00196/01234] [00:02:17/00:12:06, 0.700s/it]: train_loss_raw=1.5128, running_loss=1.5215, LR=0.000100
[2025-08-26 00:20:00,919][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012544] [Batch 00204/01234] [00:02:22/00:11:59, 0.699s/it]: train_loss_raw=1.4954, running_loss=1.5238, LR=0.000100
[2025-08-26 00:20:06,612][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012552] [Batch 00212/01234] [00:02:28/00:11:54, 0.699s/it]: train_loss_raw=1.5998, running_loss=1.5250, LR=0.000100
[2025-08-26 00:20:11,784][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012560] [Batch 00220/01234] [00:02:33/00:11:47, 0.698s/it]: train_loss_raw=1.5753, running_loss=1.5249, LR=0.000100
[2025-08-26 00:20:17,567][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012568] [Batch 00228/01234] [00:02:39/00:11:42, 0.698s/it]: train_loss_raw=1.5146, running_loss=1.5259, LR=0.000100
[2025-08-26 00:20:22,714][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012576] [Batch 00236/01234] [00:02:44/00:11:35, 0.697s/it]: train_loss_raw=1.4738, running_loss=1.5243, LR=0.000100
[2025-08-26 00:20:27,873][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012584] [Batch 00244/01234] [00:02:49/00:11:27, 0.695s/it]: train_loss_raw=1.4786, running_loss=1.5250, LR=0.000100
[2025-08-26 00:20:32,964][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012592] [Batch 00252/01234] [00:02:54/00:11:20, 0.693s/it]: train_loss_raw=1.6191, running_loss=1.5258, LR=0.000100
[2025-08-26 00:20:38,277][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012600] [Batch 00260/01234] [00:02:59/00:11:14, 0.692s/it]: train_loss_raw=1.5103, running_loss=1.5236, LR=0.000100
[2025-08-26 00:20:43,394][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012608] [Batch 00268/01234] [00:03:05/00:11:07, 0.691s/it]: train_loss_raw=1.5918, running_loss=1.5219, LR=0.000100
[2025-08-26 00:20:48,491][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012616] [Batch 00276/01234] [00:03:10/00:11:00, 0.689s/it]: train_loss_raw=1.5595, running_loss=1.5248, LR=0.000100
[2025-08-26 00:20:54,367][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012624] [Batch 00284/01234] [00:03:16/00:10:55, 0.690s/it]: train_loss_raw=1.5071, running_loss=1.5250, LR=0.000100
[2025-08-26 00:20:59,673][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012632] [Batch 00292/01234] [00:03:21/00:10:49, 0.690s/it]: train_loss_raw=1.4068, running_loss=1.5241, LR=0.000100
[2025-08-26 00:21:04,863][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012640] [Batch 00300/01234] [00:03:26/00:10:43, 0.688s/it]: train_loss_raw=1.5889, running_loss=1.5267, LR=0.000100
[2025-08-26 00:21:10,534][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012648] [Batch 00308/01234] [00:03:32/00:10:37, 0.689s/it]: train_loss_raw=1.4801, running_loss=1.5268, LR=0.000100
[2025-08-26 00:21:15,929][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012656] [Batch 00316/01234] [00:03:37/00:10:32, 0.689s/it]: train_loss_raw=1.5724, running_loss=1.5261, LR=0.000100
[2025-08-26 00:21:21,338][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012664] [Batch 00324/01234] [00:03:43/00:10:26, 0.688s/it]: train_loss_raw=1.4142, running_loss=1.5263, LR=0.000100
[2025-08-26 00:21:26,453][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012672] [Batch 00332/01234] [00:03:48/00:10:19, 0.687s/it]: train_loss_raw=1.4829, running_loss=1.5263, LR=0.000100
[2025-08-26 00:21:31,899][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012680] [Batch 00340/01234] [00:03:53/00:10:14, 0.687s/it]: train_loss_raw=1.4392, running_loss=1.5245, LR=0.000100
[2025-08-26 00:21:37,742][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012688] [Batch 00348/01234] [00:03:59/00:10:09, 0.688s/it]: train_loss_raw=1.5378, running_loss=1.5244, LR=0.000100
[2025-08-26 00:21:43,504][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012696] [Batch 00356/01234] [00:04:05/00:10:04, 0.689s/it]: train_loss_raw=1.5020, running_loss=1.5260, LR=0.000100
[2025-08-26 00:21:48,811][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012704] [Batch 00364/01234] [00:04:10/00:09:58, 0.688s/it]: train_loss_raw=1.3749, running_loss=1.5230, LR=0.000100
[2025-08-26 00:21:53,972][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012712] [Batch 00372/01234] [00:04:15/00:09:52, 0.687s/it]: train_loss_raw=1.5369, running_loss=1.5249, LR=0.000100
[2025-08-26 00:21:59,057][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012720] [Batch 00380/01234] [00:04:20/00:09:45, 0.686s/it]: train_loss_raw=1.5149, running_loss=1.5246, LR=0.000100
[2025-08-26 00:22:04,658][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012728] [Batch 00388/01234] [00:04:26/00:09:40, 0.686s/it]: train_loss_raw=1.5662, running_loss=1.5246, LR=0.000100
[2025-08-26 00:22:09,883][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012736] [Batch 00396/01234] [00:04:31/00:09:34, 0.686s/it]: train_loss_raw=1.6215, running_loss=1.5264, LR=0.000100
[2025-08-26 00:22:15,351][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012744] [Batch 00404/01234] [00:04:37/00:09:29, 0.686s/it]: train_loss_raw=1.5177, running_loss=1.5246, LR=0.000100
[2025-08-26 00:22:20,544][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012752] [Batch 00412/01234] [00:04:42/00:09:23, 0.685s/it]: train_loss_raw=1.5224, running_loss=1.5233, LR=0.000100
[2025-08-26 00:22:25,987][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012760] [Batch 00420/01234] [00:04:47/00:09:17, 0.685s/it]: train_loss_raw=1.5180, running_loss=1.5226, LR=0.000100
[2025-08-26 00:22:31,224][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012768] [Batch 00428/01234] [00:04:52/00:09:11, 0.684s/it]: train_loss_raw=1.5061, running_loss=1.5238, LR=0.000100
[2025-08-26 00:22:36,470][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012776] [Batch 00436/01234] [00:04:58/00:09:05, 0.684s/it]: train_loss_raw=1.5616, running_loss=1.5266, LR=0.000100
[2025-08-26 00:22:41,793][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012784] [Batch 00444/01234] [00:05:03/00:08:59, 0.683s/it]: train_loss_raw=1.5753, running_loss=1.5267, LR=0.000100
[2025-08-26 00:22:47,183][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012792] [Batch 00452/01234] [00:05:08/00:08:54, 0.683s/it]: train_loss_raw=1.5554, running_loss=1.5281, LR=0.000100
[2025-08-26 00:22:52,723][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012800] [Batch 00460/01234] [00:05:14/00:08:49, 0.683s/it]: train_loss_raw=1.3954, running_loss=1.5277, LR=0.000100
[2025-08-26 00:22:57,816][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012808] [Batch 00468/01234] [00:05:19/00:08:42, 0.683s/it]: train_loss_raw=1.5519, running_loss=1.5308, LR=0.000100
[2025-08-26 00:23:02,963][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012816] [Batch 00476/01234] [00:05:24/00:08:36, 0.682s/it]: train_loss_raw=1.5731, running_loss=1.5307, LR=0.000100
[2025-08-26 00:23:08,041][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012824] [Batch 00484/01234] [00:05:29/00:08:30, 0.681s/it]: train_loss_raw=1.4931, running_loss=1.5334, LR=0.000100
[2025-08-26 00:23:13,122][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012832] [Batch 00492/01234] [00:05:34/00:08:24, 0.680s/it]: train_loss_raw=1.4518, running_loss=1.5330, LR=0.000100
[2025-08-26 00:23:18,304][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012840] [Batch 00500/01234] [00:05:39/00:08:19, 0.680s/it]: train_loss_raw=1.5539, running_loss=1.5344, LR=0.000100
[2025-08-26 00:23:23,618][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012848] [Batch 00508/01234] [00:05:45/00:08:13, 0.680s/it]: train_loss_raw=1.6196, running_loss=1.5357, LR=0.000100
[2025-08-26 00:23:29,110][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012856] [Batch 00516/01234] [00:05:50/00:08:08, 0.680s/it]: train_loss_raw=1.5335, running_loss=1.5370, LR=0.000100
[2025-08-26 00:23:35,300][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012864] [Batch 00524/01234] [00:05:56/00:08:03, 0.681s/it]: train_loss_raw=1.5807, running_loss=1.5342, LR=0.000100
[2025-08-26 00:23:40,387][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012872] [Batch 00532/01234] [00:06:02/00:07:57, 0.681s/it]: train_loss_raw=1.5477, running_loss=1.5338, LR=0.000100
[2025-08-26 00:23:45,703][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012880] [Batch 00540/01234] [00:06:07/00:07:52, 0.680s/it]: train_loss_raw=1.5680, running_loss=1.5348, LR=0.000100
[2025-08-26 00:23:51,465][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012888] [Batch 00548/01234] [00:06:13/00:07:47, 0.681s/it]: train_loss_raw=1.5292, running_loss=1.5326, LR=0.000100
[2025-08-26 00:23:57,222][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012896] [Batch 00556/01234] [00:06:18/00:07:42, 0.681s/it]: train_loss_raw=1.5138, running_loss=1.5334, LR=0.000100
[2025-08-26 00:24:02,650][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012904] [Batch 00564/01234] [00:06:24/00:07:36, 0.681s/it]: train_loss_raw=1.6049, running_loss=1.5328, LR=0.000100
[2025-08-26 00:24:07,744][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012912] [Batch 00572/01234] [00:06:29/00:07:30, 0.681s/it]: train_loss_raw=1.4819, running_loss=1.5309, LR=0.000100
[2025-08-26 00:24:13,487][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012920] [Batch 00580/01234] [00:06:35/00:07:25, 0.681s/it]: train_loss_raw=1.5226, running_loss=1.5331, LR=0.000100
[2025-08-26 00:24:18,727][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012928] [Batch 00588/01234] [00:06:40/00:07:19, 0.681s/it]: train_loss_raw=1.5194, running_loss=1.5348, LR=0.000100
[2025-08-26 00:24:24,193][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012936] [Batch 00596/01234] [00:06:45/00:07:14, 0.681s/it]: train_loss_raw=1.5496, running_loss=1.5347, LR=0.000100
[2025-08-26 00:24:29,255][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012944] [Batch 00604/01234] [00:06:50/00:07:08, 0.680s/it]: train_loss_raw=1.4899, running_loss=1.5327, LR=0.000100
[2025-08-26 00:24:34,312][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012952] [Batch 00612/01234] [00:06:55/00:07:02, 0.680s/it]: train_loss_raw=1.4793, running_loss=1.5320, LR=0.000100
[2025-08-26 00:24:39,871][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012960] [Batch 00620/01234] [00:07:01/00:06:57, 0.680s/it]: train_loss_raw=1.4510, running_loss=1.5293, LR=0.000100
[2025-08-26 00:24:45,377][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012968] [Batch 00628/01234] [00:07:07/00:06:52, 0.680s/it]: train_loss_raw=1.4278, running_loss=1.5278, LR=0.000100
[2025-08-26 00:24:50,721][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012976] [Batch 00636/01234] [00:07:12/00:06:46, 0.680s/it]: train_loss_raw=1.5610, running_loss=1.5289, LR=0.000100
[2025-08-26 00:24:56,077][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012984] [Batch 00644/01234] [00:07:17/00:06:41, 0.680s/it]: train_loss_raw=1.5453, running_loss=1.5329, LR=0.000100
[2025-08-26 00:25:01,231][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 012992] [Batch 00652/01234] [00:07:22/00:06:35, 0.679s/it]: train_loss_raw=1.5013, running_loss=1.5317, LR=0.000100
[2025-08-26 00:25:06,737][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013000] [Batch 00660/01234] [00:07:28/00:06:29, 0.679s/it]: train_loss_raw=1.5160, running_loss=1.5304, LR=0.000100
[2025-08-26 00:25:12,096][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013008] [Batch 00668/01234] [00:07:33/00:06:24, 0.679s/it]: train_loss_raw=1.6033, running_loss=1.5330, LR=0.000100
[2025-08-26 00:25:17,726][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013016] [Batch 00676/01234] [00:07:39/00:06:19, 0.680s/it]: train_loss_raw=1.5135, running_loss=1.5337, LR=0.000100
[2025-08-26 00:25:23,105][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013024] [Batch 00684/01234] [00:07:44/00:06:13, 0.679s/it]: train_loss_raw=1.4448, running_loss=1.5328, LR=0.000100
[2025-08-26 00:25:28,564][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013032] [Batch 00692/01234] [00:07:50/00:06:08, 0.680s/it]: train_loss_raw=1.5607, running_loss=1.5334, LR=0.000100
[2025-08-26 00:25:34,039][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013040] [Batch 00700/01234] [00:07:55/00:06:02, 0.680s/it]: train_loss_raw=1.5800, running_loss=1.5352, LR=0.000100
[2025-08-26 00:25:39,604][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013048] [Batch 00708/01234] [00:08:01/00:05:57, 0.680s/it]: train_loss_raw=1.5306, running_loss=1.5333, LR=0.000100
[2025-08-26 00:25:45,310][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013056] [Batch 00716/01234] [00:08:06/00:05:52, 0.680s/it]: train_loss_raw=1.4902, running_loss=1.5350, LR=0.000100
[2025-08-26 00:25:51,088][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013064] [Batch 00724/01234] [00:08:12/00:05:47, 0.681s/it]: train_loss_raw=1.3930, running_loss=1.5314, LR=0.000100
[2025-08-26 00:25:56,821][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013072] [Batch 00732/01234] [00:08:18/00:05:41, 0.681s/it]: train_loss_raw=1.4523, running_loss=1.5296, LR=0.000100
[2025-08-26 00:26:02,579][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013080] [Batch 00740/01234] [00:08:24/00:05:36, 0.681s/it]: train_loss_raw=1.4802, running_loss=1.5297, LR=0.000100
[2025-08-26 00:26:07,814][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013088] [Batch 00748/01234] [00:08:29/00:05:31, 0.681s/it]: train_loss_raw=1.4981, running_loss=1.5295, LR=0.000100
[2025-08-26 00:26:13,473][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013096] [Batch 00756/01234] [00:08:35/00:05:25, 0.681s/it]: train_loss_raw=1.6055, running_loss=1.5305, LR=0.000100
[2025-08-26 00:26:19,003][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013104] [Batch 00764/01234] [00:08:40/00:05:20, 0.682s/it]: train_loss_raw=1.5174, running_loss=1.5300, LR=0.000100
[2025-08-26 00:26:24,207][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013112] [Batch 00772/01234] [00:08:45/00:05:14, 0.681s/it]: train_loss_raw=1.6256, running_loss=1.5322, LR=0.000100
[2025-08-26 00:26:29,832][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013120] [Batch 00780/01234] [00:08:51/00:05:09, 0.681s/it]: train_loss_raw=1.4479, running_loss=1.5315, LR=0.000100
[2025-08-26 00:26:35,492][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013128] [Batch 00788/01234] [00:08:57/00:05:04, 0.682s/it]: train_loss_raw=1.5710, running_loss=1.5311, LR=0.000100
[2025-08-26 00:26:40,882][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013136] [Batch 00796/01234] [00:09:02/00:04:58, 0.682s/it]: train_loss_raw=1.6046, running_loss=1.5301, LR=0.000100
[2025-08-26 00:26:46,343][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013144] [Batch 00804/01234] [00:09:08/00:04:53, 0.682s/it]: train_loss_raw=1.6228, running_loss=1.5303, LR=0.000100
[2025-08-26 00:26:51,414][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013152] [Batch 00812/01234] [00:09:13/00:04:47, 0.681s/it]: train_loss_raw=1.4603, running_loss=1.5287, LR=0.000100
[2025-08-26 00:26:56,814][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013160] [Batch 00820/01234] [00:09:18/00:04:41, 0.681s/it]: train_loss_raw=1.5427, running_loss=1.5295, LR=0.000100
[2025-08-26 00:27:02,323][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013168] [Batch 00828/01234] [00:09:23/00:04:36, 0.681s/it]: train_loss_raw=1.4383, running_loss=1.5304, LR=0.000100
[2025-08-26 00:27:07,418][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013176] [Batch 00836/01234] [00:09:29/00:04:30, 0.681s/it]: train_loss_raw=1.4423, running_loss=1.5316, LR=0.000100
[2025-08-26 00:27:12,521][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013184] [Batch 00844/01234] [00:09:34/00:04:25, 0.680s/it]: train_loss_raw=1.4617, running_loss=1.5329, LR=0.000100
[2025-08-26 00:27:17,659][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013192] [Batch 00852/01234] [00:09:39/00:04:19, 0.680s/it]: train_loss_raw=1.5553, running_loss=1.5326, LR=0.000100
[2025-08-26 00:27:23,015][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013200] [Batch 00860/01234] [00:09:44/00:04:14, 0.680s/it]: train_loss_raw=1.5048, running_loss=1.5318, LR=0.000100
[2025-08-26 00:27:28,094][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013208] [Batch 00868/01234] [00:09:49/00:04:08, 0.679s/it]: train_loss_raw=1.5928, running_loss=1.5327, LR=0.000100
[2025-08-26 00:27:33,601][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013216] [Batch 00876/01234] [00:09:55/00:04:03, 0.680s/it]: train_loss_raw=1.5047, running_loss=1.5305, LR=0.000100
[2025-08-26 00:27:38,967][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013224] [Batch 00884/01234] [00:10:00/00:03:57, 0.679s/it]: train_loss_raw=1.4942, running_loss=1.5287, LR=0.000100
[2025-08-26 00:27:44,057][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013232] [Batch 00892/01234] [00:10:05/00:03:52, 0.679s/it]: train_loss_raw=1.5832, running_loss=1.5289, LR=0.000100
[2025-08-26 00:27:49,145][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013240] [Batch 00900/01234] [00:10:10/00:03:46, 0.679s/it]: train_loss_raw=1.4144, running_loss=1.5279, LR=0.000100
[2025-08-26 00:27:54,232][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013248] [Batch 00908/01234] [00:10:15/00:03:41, 0.678s/it]: train_loss_raw=1.5103, running_loss=1.5296, LR=0.000100
[2025-08-26 00:27:59,645][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013256] [Batch 00916/01234] [00:10:21/00:03:35, 0.678s/it]: train_loss_raw=1.5814, running_loss=1.5291, LR=0.000100
[2025-08-26 00:28:04,906][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013264] [Batch 00924/01234] [00:10:26/00:03:30, 0.678s/it]: train_loss_raw=1.5131, running_loss=1.5277, LR=0.000100
[2025-08-26 00:28:10,073][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013272] [Batch 00932/01234] [00:10:31/00:03:24, 0.678s/it]: train_loss_raw=1.4870, running_loss=1.5256, LR=0.000100
[2025-08-26 00:28:15,248][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013280] [Batch 00940/01234] [00:10:36/00:03:19, 0.678s/it]: train_loss_raw=1.5421, running_loss=1.5259, LR=0.000100
[2025-08-26 00:28:20,361][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013288] [Batch 00948/01234] [00:10:42/00:03:13, 0.677s/it]: train_loss_raw=1.5726, running_loss=1.5267, LR=0.000100
[2025-08-26 00:28:26,123][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013296] [Batch 00956/01234] [00:10:47/00:03:08, 0.678s/it]: train_loss_raw=1.5938, running_loss=1.5277, LR=0.000100
[2025-08-26 00:28:31,747][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013304] [Batch 00964/01234] [00:10:53/00:03:03, 0.678s/it]: train_loss_raw=1.4518, running_loss=1.5280, LR=0.000100
[2025-08-26 00:28:37,190][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013312] [Batch 00972/01234] [00:10:58/00:02:57, 0.678s/it]: train_loss_raw=1.5479, running_loss=1.5320, LR=0.000100
[2025-08-26 00:28:42,877][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013320] [Batch 00980/01234] [00:11:04/00:02:52, 0.678s/it]: train_loss_raw=1.5544, running_loss=1.5311, LR=0.000100
[2025-08-26 00:28:48,790][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013328] [Batch 00988/01234] [00:11:10/00:02:46, 0.679s/it]: train_loss_raw=1.5373, running_loss=1.5320, LR=0.000100
[2025-08-26 00:28:54,511][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013336] [Batch 00996/01234] [00:11:16/00:02:41, 0.679s/it]: train_loss_raw=1.5759, running_loss=1.5341, LR=0.000100
[2025-08-26 00:29:00,006][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013344] [Batch 01004/01234] [00:11:21/00:02:36, 0.679s/it]: train_loss_raw=1.5122, running_loss=1.5325, LR=0.000100
[2025-08-26 00:29:05,209][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013352] [Batch 01012/01234] [00:11:26/00:02:30, 0.679s/it]: train_loss_raw=1.5019, running_loss=1.5297, LR=0.000100
[2025-08-26 00:29:10,791][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013360] [Batch 01020/01234] [00:11:32/00:02:25, 0.679s/it]: train_loss_raw=1.5926, running_loss=1.5312, LR=0.000100
[2025-08-26 00:29:16,568][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013368] [Batch 01028/01234] [00:11:38/00:02:19, 0.679s/it]: train_loss_raw=1.5617, running_loss=1.5304, LR=0.000100
[2025-08-26 00:29:22,280][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013376] [Batch 01036/01234] [00:11:43/00:02:14, 0.679s/it]: train_loss_raw=1.5248, running_loss=1.5311, LR=0.000100
[2025-08-26 00:29:28,012][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013384] [Batch 01044/01234] [00:11:49/00:02:09, 0.680s/it]: train_loss_raw=1.4351, running_loss=1.5296, LR=0.000100
[2025-08-26 00:29:33,741][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013392] [Batch 01052/01234] [00:11:55/00:02:03, 0.680s/it]: train_loss_raw=1.5365, running_loss=1.5304, LR=0.000100
[2025-08-26 00:29:39,280][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013400] [Batch 01060/01234] [00:12:00/00:01:58, 0.680s/it]: train_loss_raw=1.5115, running_loss=1.5295, LR=0.000100
[2025-08-26 00:29:44,818][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013408] [Batch 01068/01234] [00:12:06/00:01:52, 0.680s/it]: train_loss_raw=1.5901, running_loss=1.5295, LR=0.000100
[2025-08-26 00:29:49,900][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013416] [Batch 01076/01234] [00:12:11/00:01:47, 0.680s/it]: train_loss_raw=1.4832, running_loss=1.5285, LR=0.000100
[2025-08-26 00:29:55,049][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013424] [Batch 01084/01234] [00:12:16/00:01:41, 0.680s/it]: train_loss_raw=1.5980, running_loss=1.5308, LR=0.000100
[2025-08-26 00:30:00,136][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013432] [Batch 01092/01234] [00:12:21/00:01:36, 0.679s/it]: train_loss_raw=1.5286, running_loss=1.5294, LR=0.000100
[2025-08-26 00:30:05,309][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013440] [Batch 01100/01234] [00:12:26/00:01:30, 0.679s/it]: train_loss_raw=1.4319, running_loss=1.5253, LR=0.000100
[2025-08-26 00:30:10,968][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013448] [Batch 01108/01234] [00:12:32/00:01:25, 0.679s/it]: train_loss_raw=1.4782, running_loss=1.5240, LR=0.000100
[2025-08-26 00:30:16,836][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013456] [Batch 01116/01234] [00:12:38/00:01:20, 0.680s/it]: train_loss_raw=1.5222, running_loss=1.5234, LR=0.000100
[2025-08-26 00:30:22,604][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013464] [Batch 01124/01234] [00:12:44/00:01:14, 0.680s/it]: train_loss_raw=1.5214, running_loss=1.5261, LR=0.000100
[2025-08-26 00:30:27,779][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013472] [Batch 01132/01234] [00:12:49/00:01:09, 0.680s/it]: train_loss_raw=1.5617, running_loss=1.5267, LR=0.000100
[2025-08-26 00:30:32,872][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013480] [Batch 01140/01234] [00:12:54/00:01:03, 0.679s/it]: train_loss_raw=1.5171, running_loss=1.5286, LR=0.000100
[2025-08-26 00:30:38,521][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013488] [Batch 01148/01234] [00:13:00/00:00:58, 0.680s/it]: train_loss_raw=1.4943, running_loss=1.5267, LR=0.000100
[2025-08-26 00:30:43,868][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013496] [Batch 01156/01234] [00:13:05/00:00:53, 0.680s/it]: train_loss_raw=1.4597, running_loss=1.5268, LR=0.000100
[2025-08-26 00:30:49,463][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013504] [Batch 01164/01234] [00:13:11/00:00:47, 0.680s/it]: train_loss_raw=1.4676, running_loss=1.5264, LR=0.000100
[2025-08-26 00:30:54,858][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013512] [Batch 01172/01234] [00:13:16/00:00:42, 0.680s/it]: train_loss_raw=1.4668, running_loss=1.5290, LR=0.000100
[2025-08-26 00:30:59,972][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013520] [Batch 01180/01234] [00:13:21/00:00:36, 0.679s/it]: train_loss_raw=1.6053, running_loss=1.5309, LR=0.000100
[2025-08-26 00:31:05,708][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013528] [Batch 01188/01234] [00:13:27/00:00:31, 0.680s/it]: train_loss_raw=1.5612, running_loss=1.5324, LR=0.000100
[2025-08-26 00:31:11,439][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013536] [Batch 01196/01234] [00:13:33/00:00:25, 0.680s/it]: train_loss_raw=1.4713, running_loss=1.5308, LR=0.000100
[2025-08-26 00:31:17,202][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013544] [Batch 01204/01234] [00:13:38/00:00:20, 0.680s/it]: train_loss_raw=1.5662, running_loss=1.5337, LR=0.000100
[2025-08-26 00:31:22,992][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013552] [Batch 01212/01234] [00:13:44/00:00:14, 0.680s/it]: train_loss_raw=1.5172, running_loss=1.5319, LR=0.000100
[2025-08-26 00:31:28,919][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013560] [Batch 01220/01234] [00:13:50/00:00:09, 0.681s/it]: train_loss_raw=1.5191, running_loss=1.5332, LR=0.000100
[2025-08-26 00:31:34,413][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 013568] [Batch 01228/01234] [00:13:56/00:00:04, 0.681s/it]: train_loss_raw=1.5374, running_loss=1.5302, LR=0.000100
[2025-08-26 00:31:44,050][__main__][INFO] - [VALIDATION] [Epoch 10/29] Starting validation.
[2025-08-26 00:31:54,417][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 013575] [Batch 00007/00026] [00:00:10/00:00:23, 1.296s/it]
[2025-08-26 00:32:04,891][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 013575] [Batch 00015/00026] [00:00:20/00:00:13, 1.303s/it]
[2025-08-26 00:32:16,548][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 013575] [Batch 00023/00026] [00:00:32/00:00:02, 1.354s/it]
[2025-08-26 00:32:18,959][__main__][INFO] - [VALIDATION] [Epoch 10/29] train_loss=1.53062, valid_loss=1.63023
[2025-08-26 00:32:18,959][__main__][INFO] - [VALIDATION] [Epoch 10/29] Metrics:
[2025-08-26 00:32:18,959][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_er      0.685
[2025-08-26 00:32:18,959][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_prec    0.032
[2025-08-26 00:32:18,959][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_recall  0.032
[2025-08-26 00:32:18,959][__main__][INFO] - [VALIDATION] [Epoch 10/29] - pep_recall 0.004
[2025-08-26 00:32:18,961][__main__][INFO] - [TRAIN] [Epoch 10/29] Epoch complete, total time 02:41:28, remaining time 04:38:54, 00:14:40 per epoch
[2025-08-26 00:32:19,966][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013576] [Batch 00002/01234] [00:00:00/00:09:00, 0.439s/it]: train_loss_raw=1.5241, running_loss=1.5585, LR=0.000100
[2025-08-26 00:32:26,072][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013584] [Batch 00010/01234] [00:00:06/00:14:14, 0.698s/it]: train_loss_raw=1.3916, running_loss=1.5526, LR=0.000100
[2025-08-26 00:32:31,890][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013592] [Batch 00018/01234] [00:00:12/00:14:24, 0.711s/it]: train_loss_raw=1.5069, running_loss=1.5455, LR=0.000100
[2025-08-26 00:32:37,106][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013600] [Batch 00026/01234] [00:00:18/00:13:57, 0.693s/it]: train_loss_raw=1.4933, running_loss=1.5393, LR=0.000100
[2025-08-26 00:32:42,551][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013608] [Batch 00034/01234] [00:00:23/00:13:48, 0.690s/it]: train_loss_raw=1.5069, running_loss=1.5285, LR=0.000100
[2025-08-26 00:32:48,327][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013616] [Batch 00042/01234] [00:00:29/00:13:49, 0.696s/it]: train_loss_raw=1.5298, running_loss=1.5234, LR=0.000100
[2025-08-26 00:32:54,224][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013624] [Batch 00050/01234] [00:00:35/00:13:52, 0.703s/it]: train_loss_raw=1.4677, running_loss=1.5197, LR=0.000100
[2025-08-26 00:33:00,138][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013632] [Batch 00058/01234] [00:00:41/00:13:52, 0.708s/it]: train_loss_raw=1.5579, running_loss=1.5167, LR=0.000100
[2025-08-26 00:33:05,231][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013640] [Batch 00066/01234] [00:00:46/00:13:36, 0.699s/it]: train_loss_raw=1.4095, running_loss=1.5143, LR=0.000100
[2025-08-26 00:33:10,547][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013648] [Batch 00074/01234] [00:00:51/00:13:26, 0.695s/it]: train_loss_raw=1.6086, running_loss=1.5129, LR=0.000100
[2025-08-26 00:33:15,775][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013656] [Batch 00082/01234] [00:00:56/00:13:16, 0.691s/it]: train_loss_raw=1.4658, running_loss=1.5104, LR=0.000100
[2025-08-26 00:33:21,229][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013664] [Batch 00090/01234] [00:01:02/00:13:09, 0.690s/it]: train_loss_raw=1.4966, running_loss=1.5058, LR=0.000100
[2025-08-26 00:33:27,168][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013672] [Batch 00098/01234] [00:01:08/00:13:09, 0.695s/it]: train_loss_raw=1.5315, running_loss=1.5048, LR=0.000100
[2025-08-26 00:33:32,989][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013680] [Batch 00106/01234] [00:01:13/00:13:06, 0.697s/it]: train_loss_raw=1.5284, running_loss=1.5023, LR=0.000100
[2025-08-26 00:33:38,371][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013688] [Batch 00114/01234] [00:01:19/00:12:58, 0.695s/it]: train_loss_raw=1.4641, running_loss=1.4997, LR=0.000100
[2025-08-26 00:33:43,618][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013696] [Batch 00122/01234] [00:01:24/00:12:50, 0.693s/it]: train_loss_raw=1.5098, running_loss=1.5012, LR=0.000100
[2025-08-26 00:33:49,033][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013704] [Batch 00130/01234] [00:01:29/00:12:43, 0.692s/it]: train_loss_raw=1.4858, running_loss=1.4992, LR=0.000100
[2025-08-26 00:33:54,487][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013712] [Batch 00138/01234] [00:01:35/00:12:37, 0.691s/it]: train_loss_raw=1.4703, running_loss=1.4984, LR=0.000100
[2025-08-26 00:33:59,721][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013720] [Batch 00146/01234] [00:01:40/00:12:29, 0.689s/it]: train_loss_raw=1.4312, running_loss=1.4968, LR=0.000100
[2025-08-26 00:34:05,104][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013728] [Batch 00154/01234] [00:01:46/00:12:23, 0.688s/it]: train_loss_raw=1.4578, running_loss=1.4955, LR=0.000100
[2025-08-26 00:34:10,943][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013736] [Batch 00162/01234] [00:01:51/00:12:20, 0.690s/it]: train_loss_raw=1.5178, running_loss=1.4953, LR=0.000100
[2025-08-26 00:34:16,298][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013744] [Batch 00170/01234] [00:01:57/00:12:13, 0.689s/it]: train_loss_raw=1.6111, running_loss=1.4958, LR=0.000100
[2025-08-26 00:34:22,158][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013752] [Batch 00178/01234] [00:02:03/00:12:10, 0.691s/it]: train_loss_raw=1.5042, running_loss=1.4931, LR=0.000100
[2025-08-26 00:34:27,927][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013760] [Batch 00186/01234] [00:02:08/00:12:05, 0.693s/it]: train_loss_raw=1.4474, running_loss=1.4907, LR=0.000100
[2025-08-26 00:34:33,367][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013768] [Batch 00194/01234] [00:02:14/00:11:59, 0.692s/it]: train_loss_raw=1.5498, running_loss=1.4907, LR=0.000100
[2025-08-26 00:34:38,736][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013776] [Batch 00202/01234] [00:02:19/00:11:53, 0.691s/it]: train_loss_raw=1.4362, running_loss=1.4894, LR=0.000100
[2025-08-26 00:34:44,011][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013784] [Batch 00210/01234] [00:02:24/00:11:46, 0.690s/it]: train_loss_raw=1.3731, running_loss=1.4891, LR=0.000100
[2025-08-26 00:34:49,451][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013792] [Batch 00218/01234] [00:02:30/00:11:40, 0.690s/it]: train_loss_raw=1.5022, running_loss=1.4866, LR=0.000100
[2025-08-26 00:34:55,045][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013800] [Batch 00226/01234] [00:02:35/00:11:35, 0.690s/it]: train_loss_raw=1.4269, running_loss=1.4857, LR=0.000100
[2025-08-26 00:35:00,231][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013808] [Batch 00234/01234] [00:02:41/00:11:28, 0.689s/it]: train_loss_raw=1.5586, running_loss=1.4850, LR=0.000100
[2025-08-26 00:35:05,756][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013816] [Batch 00242/01234] [00:02:46/00:11:23, 0.689s/it]: train_loss_raw=1.4387, running_loss=1.4826, LR=0.000100
[2025-08-26 00:35:11,461][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013824] [Batch 00250/01234] [00:02:52/00:11:18, 0.689s/it]: train_loss_raw=1.5049, running_loss=1.4828, LR=0.000100
[2025-08-26 00:35:16,923][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013832] [Batch 00258/01234] [00:02:57/00:11:12, 0.689s/it]: train_loss_raw=1.4708, running_loss=1.4808, LR=0.000100
[2025-08-26 00:35:22,426][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013840] [Batch 00266/01234] [00:03:03/00:11:07, 0.689s/it]: train_loss_raw=1.4371, running_loss=1.4791, LR=0.000100
[2025-08-26 00:35:27,876][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013848] [Batch 00274/01234] [00:03:08/00:11:01, 0.689s/it]: train_loss_raw=1.4175, running_loss=1.4804, LR=0.000100
[2025-08-26 00:35:33,214][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013856] [Batch 00282/01234] [00:03:14/00:10:55, 0.688s/it]: train_loss_raw=1.4850, running_loss=1.4799, LR=0.000100
[2025-08-26 00:35:38,636][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013864] [Batch 00290/01234] [00:03:19/00:10:49, 0.688s/it]: train_loss_raw=1.4302, running_loss=1.4793, LR=0.000100
[2025-08-26 00:35:44,381][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013872] [Batch 00298/01234] [00:03:25/00:10:44, 0.689s/it]: train_loss_raw=1.4567, running_loss=1.4807, LR=0.000100
[2025-08-26 00:35:49,851][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013880] [Batch 00306/01234] [00:03:30/00:10:39, 0.689s/it]: train_loss_raw=1.4921, running_loss=1.4821, LR=0.000100
[2025-08-26 00:35:55,522][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013888] [Batch 00314/01234] [00:03:36/00:10:34, 0.689s/it]: train_loss_raw=1.5088, running_loss=1.4834, LR=0.000100
[2025-08-26 00:36:01,027][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013896] [Batch 00322/01234] [00:03:41/00:10:28, 0.689s/it]: train_loss_raw=1.4133, running_loss=1.4804, LR=0.000100
[2025-08-26 00:36:06,384][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013904] [Batch 00330/01234] [00:03:47/00:10:22, 0.689s/it]: train_loss_raw=1.5478, running_loss=1.4814, LR=0.000100
[2025-08-26 00:36:11,562][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013912] [Batch 00338/01234] [00:03:52/00:10:16, 0.688s/it]: train_loss_raw=1.4120, running_loss=1.4805, LR=0.000100
[2025-08-26 00:36:16,866][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013920] [Batch 00346/01234] [00:03:57/00:10:10, 0.687s/it]: train_loss_raw=1.4864, running_loss=1.4800, LR=0.000100
[2025-08-26 00:36:22,609][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013928] [Batch 00354/01234] [00:04:03/00:10:05, 0.688s/it]: train_loss_raw=1.5299, running_loss=1.4815, LR=0.000100
[2025-08-26 00:36:28,244][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013936] [Batch 00362/01234] [00:04:09/00:10:00, 0.688s/it]: train_loss_raw=1.4500, running_loss=1.4808, LR=0.000100
[2025-08-26 00:36:34,036][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013944] [Batch 00370/01234] [00:04:14/00:09:55, 0.689s/it]: train_loss_raw=1.5790, running_loss=1.4844, LR=0.000100
[2025-08-26 00:36:39,462][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013952] [Batch 00378/01234] [00:04:20/00:09:49, 0.689s/it]: train_loss_raw=1.4103, running_loss=1.4830, LR=0.000100
[2025-08-26 00:36:44,945][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013960] [Batch 00386/01234] [00:04:25/00:09:44, 0.689s/it]: train_loss_raw=1.4953, running_loss=1.4829, LR=0.000100
[2025-08-26 00:36:50,217][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013968] [Batch 00394/01234] [00:04:31/00:09:38, 0.688s/it]: train_loss_raw=1.4615, running_loss=1.4853, LR=0.000100
[2025-08-26 00:36:55,682][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013976] [Batch 00402/01234] [00:04:36/00:09:32, 0.688s/it]: train_loss_raw=1.4705, running_loss=1.4876, LR=0.000100
[2025-08-26 00:37:01,214][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013984] [Batch 00410/01234] [00:04:42/00:09:27, 0.688s/it]: train_loss_raw=1.4081, running_loss=1.4869, LR=0.000100
[2025-08-26 00:37:06,370][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 013992] [Batch 00418/01234] [00:04:47/00:09:20, 0.687s/it]: train_loss_raw=1.4996, running_loss=1.4863, LR=0.000100
[2025-08-26 00:37:11,542][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014000] [Batch 00426/01234] [00:04:52/00:09:14, 0.687s/it]: train_loss_raw=1.4384, running_loss=1.4851, LR=0.000100
[2025-08-26 00:37:20,806][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014008] [Batch 00434/01234] [00:05:01/00:09:16, 0.695s/it]: train_loss_raw=1.5441, running_loss=1.4839, LR=0.000100
[2025-08-26 00:37:26,471][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014016] [Batch 00442/01234] [00:05:07/00:09:10, 0.695s/it]: train_loss_raw=1.4409, running_loss=1.4811, LR=0.000100
[2025-08-26 00:37:32,120][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014024] [Batch 00450/01234] [00:05:13/00:09:05, 0.696s/it]: train_loss_raw=1.4799, running_loss=1.4823, LR=0.000100
[2025-08-26 00:37:37,238][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014032] [Batch 00458/01234] [00:05:18/00:08:59, 0.695s/it]: train_loss_raw=1.4872, running_loss=1.4836, LR=0.000100
[2025-08-26 00:37:42,343][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014040] [Batch 00466/01234] [00:05:23/00:08:52, 0.694s/it]: train_loss_raw=1.5209, running_loss=1.4842, LR=0.000100
[2025-08-26 00:37:47,446][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014048] [Batch 00474/01234] [00:05:28/00:08:46, 0.693s/it]: train_loss_raw=1.4218, running_loss=1.4842, LR=0.000100
[2025-08-26 00:37:53,485][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014056] [Batch 00482/01234] [00:05:34/00:08:41, 0.694s/it]: train_loss_raw=1.5501, running_loss=1.4835, LR=0.000100
[2025-08-26 00:37:59,247][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014064] [Batch 00490/01234] [00:05:40/00:08:36, 0.694s/it]: train_loss_raw=1.5117, running_loss=1.4824, LR=0.000100
[2025-08-26 00:38:05,034][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014072] [Batch 00498/01234] [00:05:45/00:08:31, 0.695s/it]: train_loss_raw=1.5875, running_loss=1.4851, LR=0.000100
[2025-08-26 00:38:10,149][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014080] [Batch 00506/01234] [00:05:51/00:08:25, 0.694s/it]: train_loss_raw=1.4750, running_loss=1.4841, LR=0.000100
[2025-08-26 00:38:15,330][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014088] [Batch 00514/01234] [00:05:56/00:08:19, 0.693s/it]: train_loss_raw=1.4997, running_loss=1.4850, LR=0.000100
[2025-08-26 00:38:20,801][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014096] [Batch 00522/01234] [00:06:01/00:08:13, 0.693s/it]: train_loss_raw=1.4835, running_loss=1.4844, LR=0.000100
[2025-08-26 00:38:26,099][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014104] [Batch 00530/01234] [00:06:07/00:08:07, 0.692s/it]: train_loss_raw=1.4187, running_loss=1.4856, LR=0.000100
[2025-08-26 00:38:31,651][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014112] [Batch 00538/01234] [00:06:12/00:08:01, 0.692s/it]: train_loss_raw=1.4964, running_loss=1.4871, LR=0.000100
[2025-08-26 00:38:36,804][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014120] [Batch 00546/01234] [00:06:17/00:07:55, 0.692s/it]: train_loss_raw=1.4437, running_loss=1.4881, LR=0.000100
[2025-08-26 00:38:42,621][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014128] [Batch 00554/01234] [00:06:23/00:07:50, 0.692s/it]: train_loss_raw=1.3900, running_loss=1.4882, LR=0.000100
[2025-08-26 00:38:47,863][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014136] [Batch 00562/01234] [00:06:28/00:07:44, 0.692s/it]: train_loss_raw=1.5452, running_loss=1.4866, LR=0.000100
[2025-08-26 00:38:53,199][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014144] [Batch 00570/01234] [00:06:34/00:07:39, 0.691s/it]: train_loss_raw=1.4490, running_loss=1.4858, LR=0.000100
[2025-08-26 00:38:58,745][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014152] [Batch 00578/01234] [00:06:39/00:07:33, 0.691s/it]: train_loss_raw=1.5159, running_loss=1.4852, LR=0.000100
[2025-08-26 00:39:03,811][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014160] [Batch 00586/01234] [00:06:44/00:07:27, 0.691s/it]: train_loss_raw=1.5275, running_loss=1.4867, LR=0.000100
[2025-08-26 00:39:09,038][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014168] [Batch 00594/01234] [00:06:49/00:07:21, 0.690s/it]: train_loss_raw=1.3907, running_loss=1.4866, LR=0.000100
[2025-08-26 00:39:14,655][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014176] [Batch 00602/01234] [00:06:55/00:07:16, 0.690s/it]: train_loss_raw=1.5137, running_loss=1.4858, LR=0.000100
[2025-08-26 00:39:20,138][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014184] [Batch 00610/01234] [00:07:01/00:07:10, 0.690s/it]: train_loss_raw=1.5383, running_loss=1.4855, LR=0.000100
[2025-08-26 00:39:25,219][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014192] [Batch 00618/01234] [00:07:06/00:07:04, 0.690s/it]: train_loss_raw=1.4782, running_loss=1.4866, LR=0.000100
[2025-08-26 00:39:30,324][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014200] [Batch 00626/01234] [00:07:11/00:06:58, 0.689s/it]: train_loss_raw=1.4672, running_loss=1.4884, LR=0.000100
[2025-08-26 00:39:35,665][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014208] [Batch 00634/01234] [00:07:16/00:06:53, 0.689s/it]: train_loss_raw=1.4491, running_loss=1.4869, LR=0.000100
[2025-08-26 00:39:40,917][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014216] [Batch 00642/01234] [00:07:21/00:06:47, 0.688s/it]: train_loss_raw=1.4124, running_loss=1.4849, LR=0.000100
[2025-08-26 00:39:46,012][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014224] [Batch 00650/01234] [00:07:26/00:06:41, 0.688s/it]: train_loss_raw=1.5118, running_loss=1.4862, LR=0.000100
[2025-08-26 00:39:51,195][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014232] [Batch 00658/01234] [00:07:32/00:06:35, 0.687s/it]: train_loss_raw=1.3950, running_loss=1.4838, LR=0.000100
[2025-08-26 00:39:56,825][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014240] [Batch 00666/01234] [00:07:37/00:06:30, 0.687s/it]: train_loss_raw=1.4177, running_loss=1.4842, LR=0.000100
[2025-08-26 00:40:02,405][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014248] [Batch 00674/01234] [00:07:43/00:06:24, 0.687s/it]: train_loss_raw=1.5290, running_loss=1.4857, LR=0.000100
[2025-08-26 00:40:07,510][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014256] [Batch 00682/01234] [00:07:48/00:06:19, 0.687s/it]: train_loss_raw=1.4026, running_loss=1.4851, LR=0.000100
[2025-08-26 00:40:13,099][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014264] [Batch 00690/01234] [00:07:54/00:06:13, 0.687s/it]: train_loss_raw=1.5480, running_loss=1.4862, LR=0.000100
[2025-08-26 00:40:18,681][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014272] [Batch 00698/01234] [00:07:59/00:06:08, 0.687s/it]: train_loss_raw=1.4662, running_loss=1.4865, LR=0.000100
[2025-08-26 00:40:24,376][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014280] [Batch 00706/01234] [00:08:05/00:06:02, 0.687s/it]: train_loss_raw=1.5255, running_loss=1.4879, LR=0.000100
[2025-08-26 00:40:29,813][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014288] [Batch 00714/01234] [00:08:10/00:05:57, 0.687s/it]: train_loss_raw=1.4487, running_loss=1.4872, LR=0.000100
[2025-08-26 00:40:35,545][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014296] [Batch 00722/01234] [00:08:16/00:05:52, 0.688s/it]: train_loss_raw=1.5143, running_loss=1.4858, LR=0.000100
[2025-08-26 00:40:41,450][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014304] [Batch 00730/01234] [00:08:22/00:05:46, 0.688s/it]: train_loss_raw=1.4832, running_loss=1.4859, LR=0.000100
[2025-08-26 00:40:47,199][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014312] [Batch 00738/01234] [00:08:28/00:05:41, 0.688s/it]: train_loss_raw=1.5037, running_loss=1.4851, LR=0.000100
[2025-08-26 00:40:52,894][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014320] [Batch 00746/01234] [00:08:33/00:05:36, 0.689s/it]: train_loss_raw=1.4509, running_loss=1.4816, LR=0.000100
[2025-08-26 00:40:58,282][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014328] [Batch 00754/01234] [00:08:39/00:05:30, 0.689s/it]: train_loss_raw=1.5569, running_loss=1.4846, LR=0.000100
[2025-08-26 00:41:03,716][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014336] [Batch 00762/01234] [00:08:44/00:05:24, 0.688s/it]: train_loss_raw=1.4386, running_loss=1.4838, LR=0.000100
[2025-08-26 00:41:09,361][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014344] [Batch 00770/01234] [00:08:50/00:05:19, 0.689s/it]: train_loss_raw=1.4850, running_loss=1.4866, LR=0.000100
[2025-08-26 00:41:14,662][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014352] [Batch 00778/01234] [00:08:55/00:05:13, 0.688s/it]: train_loss_raw=1.5112, running_loss=1.4889, LR=0.000100
[2025-08-26 00:41:20,660][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014360] [Batch 00786/01234] [00:09:01/00:05:08, 0.689s/it]: train_loss_raw=1.4031, running_loss=1.4880, LR=0.000100
[2025-08-26 00:41:26,289][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014368] [Batch 00794/01234] [00:09:07/00:05:03, 0.689s/it]: train_loss_raw=1.5309, running_loss=1.4875, LR=0.000100
[2025-08-26 00:41:31,880][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014376] [Batch 00802/01234] [00:09:12/00:04:57, 0.689s/it]: train_loss_raw=1.5113, running_loss=1.4867, LR=0.000100
[2025-08-26 00:41:37,630][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014384] [Batch 00810/01234] [00:09:18/00:04:52, 0.690s/it]: train_loss_raw=1.4451, running_loss=1.4855, LR=0.000100
[2025-08-26 00:41:42,850][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014392] [Batch 00818/01234] [00:09:23/00:04:46, 0.689s/it]: train_loss_raw=1.4288, running_loss=1.4858, LR=0.000100
[2025-08-26 00:41:48,713][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014400] [Batch 00826/01234] [00:09:29/00:04:41, 0.690s/it]: train_loss_raw=1.4703, running_loss=1.4864, LR=0.000100
[2025-08-26 00:41:54,293][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014408] [Batch 00834/01234] [00:09:35/00:04:35, 0.690s/it]: train_loss_raw=1.4727, running_loss=1.4850, LR=0.000100
[2025-08-26 00:41:59,429][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014416] [Batch 00842/01234] [00:09:40/00:04:30, 0.689s/it]: train_loss_raw=1.5400, running_loss=1.4871, LR=0.000100
[2025-08-26 00:42:05,124][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014424] [Batch 00850/01234] [00:09:46/00:04:24, 0.689s/it]: train_loss_raw=1.5107, running_loss=1.4885, LR=0.000100
[2025-08-26 00:42:10,419][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014432] [Batch 00858/01234] [00:09:51/00:04:19, 0.689s/it]: train_loss_raw=1.4584, running_loss=1.4869, LR=0.000100
[2025-08-26 00:42:15,706][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014440] [Batch 00866/01234] [00:09:56/00:04:13, 0.689s/it]: train_loss_raw=1.5377, running_loss=1.4883, LR=0.000100
[2025-08-26 00:42:21,250][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014448] [Batch 00874/01234] [00:10:02/00:04:08, 0.689s/it]: train_loss_raw=1.5041, running_loss=1.4889, LR=0.000100
[2025-08-26 00:42:26,352][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014456] [Batch 00882/01234] [00:10:07/00:04:02, 0.689s/it]: train_loss_raw=1.4816, running_loss=1.4884, LR=0.000100
[2025-08-26 00:42:31,784][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014464] [Batch 00890/01234] [00:10:12/00:03:56, 0.688s/it]: train_loss_raw=1.4309, running_loss=1.4866, LR=0.000100
[2025-08-26 00:42:37,189][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014472] [Batch 00898/01234] [00:10:18/00:03:51, 0.688s/it]: train_loss_raw=1.5113, running_loss=1.4869, LR=0.000100
[2025-08-26 00:42:42,445][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014480] [Batch 00906/01234] [00:10:23/00:03:45, 0.688s/it]: train_loss_raw=1.5151, running_loss=1.4909, LR=0.000100
[2025-08-26 00:42:47,968][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014488] [Batch 00914/01234] [00:10:28/00:03:40, 0.688s/it]: train_loss_raw=1.4795, running_loss=1.4902, LR=0.000100
[2025-08-26 00:42:53,038][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014496] [Batch 00922/01234] [00:10:33/00:03:34, 0.688s/it]: train_loss_raw=1.4784, running_loss=1.4906, LR=0.000100
[2025-08-26 00:42:58,422][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014504] [Batch 00930/01234] [00:10:39/00:03:28, 0.687s/it]: train_loss_raw=1.4258, running_loss=1.4894, LR=0.000100
[2025-08-26 00:43:04,083][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014512] [Batch 00938/01234] [00:10:44/00:03:23, 0.688s/it]: train_loss_raw=1.5352, running_loss=1.4926, LR=0.000100
[2025-08-26 00:43:09,819][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014520] [Batch 00946/01234] [00:10:50/00:03:18, 0.688s/it]: train_loss_raw=1.5098, running_loss=1.4927, LR=0.000100
[2025-08-26 00:43:15,686][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014528] [Batch 00954/01234] [00:10:56/00:03:12, 0.688s/it]: train_loss_raw=1.4819, running_loss=1.4933, LR=0.000100
[2025-08-26 00:43:20,848][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014536] [Batch 00962/01234] [00:11:01/00:03:07, 0.688s/it]: train_loss_raw=1.4652, running_loss=1.4925, LR=0.000100
[2025-08-26 00:43:25,933][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014544] [Batch 00970/01234] [00:11:06/00:03:01, 0.687s/it]: train_loss_raw=1.5414, running_loss=1.4918, LR=0.000100
[2025-08-26 00:43:31,062][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014552] [Batch 00978/01234] [00:11:11/00:02:55, 0.687s/it]: train_loss_raw=1.4348, running_loss=1.4941, LR=0.000100
[2025-08-26 00:43:36,693][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014560] [Batch 00986/01234] [00:11:17/00:02:50, 0.687s/it]: train_loss_raw=1.5599, running_loss=1.4951, LR=0.000100
[2025-08-26 00:43:42,430][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014568] [Batch 00994/01234] [00:11:23/00:02:44, 0.687s/it]: train_loss_raw=1.5256, running_loss=1.4955, LR=0.000100
[2025-08-26 00:43:48,295][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014576] [Batch 01002/01234] [00:11:29/00:02:39, 0.688s/it]: train_loss_raw=1.4977, running_loss=1.4945, LR=0.000100
[2025-08-26 00:43:54,109][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014584] [Batch 01010/01234] [00:11:35/00:02:34, 0.688s/it]: train_loss_raw=1.4255, running_loss=1.4908, LR=0.000100
[2025-08-26 00:43:59,967][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014592] [Batch 01018/01234] [00:11:40/00:02:28, 0.688s/it]: train_loss_raw=1.6219, running_loss=1.4941, LR=0.000100
[2025-08-26 00:44:05,427][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014600] [Batch 01026/01234] [00:11:46/00:02:23, 0.688s/it]: train_loss_raw=1.4822, running_loss=1.4914, LR=0.000100
[2025-08-26 00:44:11,026][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014608] [Batch 01034/01234] [00:11:51/00:02:17, 0.689s/it]: train_loss_raw=1.5709, running_loss=1.4933, LR=0.000100
[2025-08-26 00:44:16,870][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014616] [Batch 01042/01234] [00:11:57/00:02:12, 0.689s/it]: train_loss_raw=1.4268, running_loss=1.4921, LR=0.000100
[2025-08-26 00:44:21,979][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014624] [Batch 01050/01234] [00:12:02/00:02:06, 0.688s/it]: train_loss_raw=1.5443, running_loss=1.4917, LR=0.000100
[2025-08-26 00:44:27,093][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014632] [Batch 01058/01234] [00:12:08/00:02:01, 0.688s/it]: train_loss_raw=1.4680, running_loss=1.4923, LR=0.000100
[2025-08-26 00:44:32,659][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014640] [Batch 01066/01234] [00:12:13/00:01:55, 0.688s/it]: train_loss_raw=1.4539, running_loss=1.4922, LR=0.000100
[2025-08-26 00:44:37,852][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014648] [Batch 01074/01234] [00:12:18/00:01:50, 0.688s/it]: train_loss_raw=1.5425, running_loss=1.4911, LR=0.000100
[2025-08-26 00:44:43,495][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014656] [Batch 01082/01234] [00:12:24/00:01:44, 0.688s/it]: train_loss_raw=1.4892, running_loss=1.4901, LR=0.000100
[2025-08-26 00:44:48,811][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014664] [Batch 01090/01234] [00:12:29/00:01:39, 0.688s/it]: train_loss_raw=1.3902, running_loss=1.4874, LR=0.000100
[2025-08-26 00:44:54,066][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014672] [Batch 01098/01234] [00:12:34/00:01:33, 0.688s/it]: train_loss_raw=1.5226, running_loss=1.4875, LR=0.000100
[2025-08-26 00:44:59,150][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014680] [Batch 01106/01234] [00:12:40/00:01:27, 0.687s/it]: train_loss_raw=1.5250, running_loss=1.4889, LR=0.000100
[2025-08-26 00:45:04,244][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014688] [Batch 01114/01234] [00:12:45/00:01:22, 0.687s/it]: train_loss_raw=1.4618, running_loss=1.4887, LR=0.000100
[2025-08-26 00:45:09,360][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014696] [Batch 01122/01234] [00:12:50/00:01:16, 0.687s/it]: train_loss_raw=1.5723, running_loss=1.4892, LR=0.000100
[2025-08-26 00:45:14,483][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014704] [Batch 01130/01234] [00:12:55/00:01:11, 0.686s/it]: train_loss_raw=1.5287, running_loss=1.4906, LR=0.000100
[2025-08-26 00:45:19,910][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014712] [Batch 01138/01234] [00:13:00/00:01:05, 0.686s/it]: train_loss_raw=1.4986, running_loss=1.4899, LR=0.000100
[2025-08-26 00:45:25,394][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014720] [Batch 01146/01234] [00:13:06/00:01:00, 0.686s/it]: train_loss_raw=1.5898, running_loss=1.4910, LR=0.000100
[2025-08-26 00:45:30,916][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014728] [Batch 01154/01234] [00:13:11/00:00:54, 0.686s/it]: train_loss_raw=1.4905, running_loss=1.4920, LR=0.000100
[2025-08-26 00:45:36,548][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014736] [Batch 01162/01234] [00:13:17/00:00:49, 0.686s/it]: train_loss_raw=1.4930, running_loss=1.4913, LR=0.000100
[2025-08-26 00:45:41,659][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014744] [Batch 01170/01234] [00:13:22/00:00:43, 0.686s/it]: train_loss_raw=1.5003, running_loss=1.4896, LR=0.000100
[2025-08-26 00:45:46,870][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014752] [Batch 01178/01234] [00:13:27/00:00:38, 0.686s/it]: train_loss_raw=1.4186, running_loss=1.4863, LR=0.000100
[2025-08-26 00:45:52,625][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014760] [Batch 01186/01234] [00:13:33/00:00:32, 0.686s/it]: train_loss_raw=1.3882, running_loss=1.4852, LR=0.000100
[2025-08-26 00:45:58,269][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014768] [Batch 01194/01234] [00:13:39/00:00:27, 0.686s/it]: train_loss_raw=1.4722, running_loss=1.4840, LR=0.000100
[2025-08-26 00:46:04,014][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014776] [Batch 01202/01234] [00:13:44/00:00:21, 0.686s/it]: train_loss_raw=1.5184, running_loss=1.4837, LR=0.000100
[2025-08-26 00:46:09,641][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014784] [Batch 01210/01234] [00:13:50/00:00:16, 0.686s/it]: train_loss_raw=1.4568, running_loss=1.4828, LR=0.000100
[2025-08-26 00:46:14,955][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014792] [Batch 01218/01234] [00:13:55/00:00:10, 0.686s/it]: train_loss_raw=1.5460, running_loss=1.4824, LR=0.000100
[2025-08-26 00:46:20,879][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014800] [Batch 01226/01234] [00:14:01/00:00:05, 0.687s/it]: train_loss_raw=1.4959, running_loss=1.4808, LR=0.000100
[2025-08-26 00:46:31,458][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 014808] [Batch 01234/01234] [00:14:12/00:00:00, 0.691s/it]: train_loss_raw=1.3583, running_loss=1.4799, LR=0.000100
[2025-08-26 00:46:31,909][__main__][INFO] - [VALIDATION] [Epoch 11/29] Starting validation.
[2025-08-26 00:46:42,417][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 014809] [Batch 00007/00026] [00:00:10/00:00:23, 1.313s/it]
[2025-08-26 00:46:52,971][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 014809] [Batch 00015/00026] [00:00:21/00:00:13, 1.316s/it]
[2025-08-26 00:47:03,220][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 014809] [Batch 00023/00026] [00:00:31/00:00:02, 1.305s/it]
[2025-08-26 00:47:05,494][__main__][INFO] - [VALIDATION] [Epoch 11/29] train_loss=1.47988, valid_loss=1.60345
[2025-08-26 00:47:05,494][__main__][INFO] - [VALIDATION] [Epoch 11/29] Metrics:
[2025-08-26 00:47:05,494][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_er      0.652
[2025-08-26 00:47:05,494][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_prec    0.046
[2025-08-26 00:47:05,495][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_recall  0.047
[2025-08-26 00:47:05,495][__main__][INFO] - [VALIDATION] [Epoch 11/29] - pep_recall 0.005
[2025-08-26 00:47:05,496][__main__][INFO] - [TRAIN] [Epoch 11/29] Epoch complete, total time 02:56:14, remaining time 04:24:22, 00:14:41 per epoch
[2025-08-26 00:47:10,916][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014816] [Batch 00008/01234] [00:00:05/00:13:30, 0.661s/it]: train_loss_raw=1.4329, running_loss=1.4956, LR=0.000100
[2025-08-26 00:47:16,635][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014824] [Batch 00016/01234] [00:00:11/00:13:58, 0.688s/it]: train_loss_raw=1.3713, running_loss=1.4880, LR=0.000100
[2025-08-26 00:47:22,174][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014832] [Batch 00024/01234] [00:00:16/00:13:54, 0.690s/it]: train_loss_raw=1.3923, running_loss=1.4840, LR=0.000100
[2025-08-26 00:47:27,375][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014840] [Batch 00032/01234] [00:00:21/00:13:37, 0.680s/it]: train_loss_raw=1.4116, running_loss=1.4786, LR=0.000100
[2025-08-26 00:47:32,707][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014848] [Batch 00040/01234] [00:00:27/00:13:28, 0.677s/it]: train_loss_raw=1.4308, running_loss=1.4746, LR=0.000100
[2025-08-26 00:47:37,810][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014856] [Batch 00048/01234] [00:00:32/00:13:15, 0.671s/it]: train_loss_raw=1.4696, running_loss=1.4710, LR=0.000100
[2025-08-26 00:47:43,199][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014864] [Batch 00056/01234] [00:00:37/00:13:10, 0.671s/it]: train_loss_raw=1.4049, running_loss=1.4685, LR=0.000100
[2025-08-26 00:47:48,543][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014872] [Batch 00064/01234] [00:00:42/00:13:04, 0.671s/it]: train_loss_raw=1.4358, running_loss=1.4652, LR=0.000100
[2025-08-26 00:47:54,156][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014880] [Batch 00072/01234] [00:00:48/00:13:03, 0.674s/it]: train_loss_raw=1.4093, running_loss=1.4572, LR=0.000100
[2025-08-26 00:47:59,636][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014888] [Batch 00080/01234] [00:00:54/00:12:59, 0.675s/it]: train_loss_raw=1.5282, running_loss=1.4561, LR=0.000100
[2025-08-26 00:48:05,067][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014896] [Batch 00088/01234] [00:00:59/00:12:54, 0.675s/it]: train_loss_raw=1.5635, running_loss=1.4547, LR=0.000100
[2025-08-26 00:48:10,732][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014904] [Batch 00096/01234] [00:01:05/00:12:51, 0.678s/it]: train_loss_raw=1.4029, running_loss=1.4549, LR=0.000100
[2025-08-26 00:48:16,032][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014912] [Batch 00104/01234] [00:01:10/00:12:45, 0.677s/it]: train_loss_raw=1.3692, running_loss=1.4536, LR=0.000100
[2025-08-26 00:48:21,739][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014920] [Batch 00112/01234] [00:01:16/00:12:42, 0.680s/it]: train_loss_raw=1.4598, running_loss=1.4538, LR=0.000100
[2025-08-26 00:48:26,997][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014928] [Batch 00120/01234] [00:01:21/00:12:35, 0.678s/it]: train_loss_raw=1.3279, running_loss=1.4507, LR=0.000100
[2025-08-26 00:48:32,829][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014936] [Batch 00128/01234] [00:01:27/00:12:33, 0.681s/it]: train_loss_raw=1.4718, running_loss=1.4502, LR=0.000100
[2025-08-26 00:48:38,272][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014944] [Batch 00136/01234] [00:01:32/00:12:27, 0.681s/it]: train_loss_raw=1.5215, running_loss=1.4479, LR=0.000100
[2025-08-26 00:48:43,364][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014952] [Batch 00144/01234] [00:01:37/00:12:19, 0.679s/it]: train_loss_raw=1.3892, running_loss=1.4474, LR=0.000100
[2025-08-26 00:48:48,786][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014960] [Batch 00152/01234] [00:01:43/00:12:14, 0.679s/it]: train_loss_raw=1.5203, running_loss=1.4464, LR=0.000100
[2025-08-26 00:48:54,583][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014968] [Batch 00160/01234] [00:01:48/00:12:11, 0.681s/it]: train_loss_raw=1.3466, running_loss=1.4455, LR=0.000100
[2025-08-26 00:48:59,887][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014976] [Batch 00168/01234] [00:01:54/00:12:05, 0.680s/it]: train_loss_raw=1.3850, running_loss=1.4456, LR=0.000100
[2025-08-26 00:49:05,092][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014984] [Batch 00176/01234] [00:01:59/00:11:58, 0.679s/it]: train_loss_raw=1.5539, running_loss=1.4462, LR=0.000100
[2025-08-26 00:49:10,366][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 014992] [Batch 00184/01234] [00:02:04/00:11:51, 0.678s/it]: train_loss_raw=1.4835, running_loss=1.4437, LR=0.000100
[2025-08-26 00:49:15,509][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015000] [Batch 00192/01234] [00:02:09/00:11:44, 0.676s/it]: train_loss_raw=1.3638, running_loss=1.4423, LR=0.000100
[2025-08-26 00:49:20,897][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015008] [Batch 00200/01234] [00:02:15/00:11:39, 0.676s/it]: train_loss_raw=1.5711, running_loss=1.4438, LR=0.000100
[2025-08-26 00:49:26,054][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015016] [Batch 00208/01234] [00:02:20/00:11:32, 0.675s/it]: train_loss_raw=1.3982, running_loss=1.4455, LR=0.000100
[2025-08-26 00:49:31,143][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015024] [Batch 00216/01234] [00:02:25/00:11:25, 0.674s/it]: train_loss_raw=1.4449, running_loss=1.4470, LR=0.000100
[2025-08-26 00:49:36,235][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015032] [Batch 00224/01234] [00:02:30/00:11:19, 0.672s/it]: train_loss_raw=1.3232, running_loss=1.4445, LR=0.000100
[2025-08-26 00:49:41,336][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015040] [Batch 00232/01234] [00:02:35/00:11:12, 0.671s/it]: train_loss_raw=1.4543, running_loss=1.4430, LR=0.000100
[2025-08-26 00:49:46,431][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015048] [Batch 00240/01234] [00:02:40/00:11:06, 0.670s/it]: train_loss_raw=1.4424, running_loss=1.4417, LR=0.000100
[2025-08-26 00:49:51,801][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015056] [Batch 00248/01234] [00:02:46/00:11:00, 0.670s/it]: train_loss_raw=1.4601, running_loss=1.4418, LR=0.000100
[2025-08-26 00:49:57,561][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015064] [Batch 00256/01234] [00:02:51/00:10:56, 0.672s/it]: train_loss_raw=1.3830, running_loss=1.4398, LR=0.000100
[2025-08-26 00:50:03,182][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015072] [Batch 00264/01234] [00:02:57/00:10:52, 0.673s/it]: train_loss_raw=1.3877, running_loss=1.4393, LR=0.000100
[2025-08-26 00:50:08,641][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015080] [Batch 00272/01234] [00:03:03/00:10:47, 0.673s/it]: train_loss_raw=1.4762, running_loss=1.4386, LR=0.000100
[2025-08-26 00:50:13,864][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015088] [Batch 00280/01234] [00:03:08/00:10:41, 0.672s/it]: train_loss_raw=1.5040, running_loss=1.4410, LR=0.000100
[2025-08-26 00:50:19,343][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015096] [Batch 00288/01234] [00:03:13/00:10:36, 0.673s/it]: train_loss_raw=1.4163, running_loss=1.4407, LR=0.000100
[2025-08-26 00:50:25,105][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015104] [Batch 00296/01234] [00:03:19/00:10:32, 0.674s/it]: train_loss_raw=1.5294, running_loss=1.4416, LR=0.000100
[2025-08-26 00:50:30,286][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015112] [Batch 00304/01234] [00:03:24/00:10:26, 0.673s/it]: train_loss_raw=1.4135, running_loss=1.4431, LR=0.000100
[2025-08-26 00:50:35,884][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015120] [Batch 00312/01234] [00:03:30/00:10:21, 0.674s/it]: train_loss_raw=1.4647, running_loss=1.4422, LR=0.000100
[2025-08-26 00:50:41,023][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015128] [Batch 00320/01234] [00:03:35/00:10:15, 0.673s/it]: train_loss_raw=1.3846, running_loss=1.4419, LR=0.000100
[2025-08-26 00:50:46,145][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015136] [Batch 00328/01234] [00:03:40/00:10:09, 0.672s/it]: train_loss_raw=1.4060, running_loss=1.4427, LR=0.000100
[2025-08-26 00:50:51,225][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015144] [Batch 00336/01234] [00:03:45/00:10:02, 0.671s/it]: train_loss_raw=1.3869, running_loss=1.4432, LR=0.000100
[2025-08-26 00:50:56,297][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015152] [Batch 00344/01234] [00:03:50/00:09:56, 0.671s/it]: train_loss_raw=1.4254, running_loss=1.4453, LR=0.000100
[2025-08-26 00:51:01,706][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015160] [Batch 00352/01234] [00:03:56/00:09:51, 0.671s/it]: train_loss_raw=1.4510, running_loss=1.4433, LR=0.000100
[2025-08-26 00:51:07,076][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015168] [Batch 00360/01234] [00:04:01/00:09:46, 0.671s/it]: train_loss_raw=1.4629, running_loss=1.4422, LR=0.000100
[2025-08-26 00:51:12,733][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015176] [Batch 00368/01234] [00:04:07/00:09:41, 0.671s/it]: train_loss_raw=1.4750, running_loss=1.4437, LR=0.000100
[2025-08-26 00:51:18,514][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015184] [Batch 00376/01234] [00:04:12/00:09:37, 0.673s/it]: train_loss_raw=1.4684, running_loss=1.4438, LR=0.000100
[2025-08-26 00:51:24,291][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015192] [Batch 00384/01234] [00:04:18/00:09:32, 0.674s/it]: train_loss_raw=1.4179, running_loss=1.4405, LR=0.000100
[2025-08-26 00:51:30,051][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015200] [Batch 00392/01234] [00:04:24/00:09:27, 0.675s/it]: train_loss_raw=1.4780, running_loss=1.4380, LR=0.000100
[2025-08-26 00:51:35,629][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015208] [Batch 00400/01234] [00:04:30/00:09:22, 0.675s/it]: train_loss_raw=1.4392, running_loss=1.4373, LR=0.000100
[2025-08-26 00:51:41,584][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015216] [Batch 00408/01234] [00:04:35/00:09:18, 0.676s/it]: train_loss_raw=1.4913, running_loss=1.4354, LR=0.000100
[2025-08-26 00:51:46,651][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015224] [Batch 00416/01234] [00:04:41/00:09:12, 0.676s/it]: train_loss_raw=1.4536, running_loss=1.4348, LR=0.000100
[2025-08-26 00:51:52,181][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015232] [Batch 00424/01234] [00:04:46/00:09:07, 0.676s/it]: train_loss_raw=1.4123, running_loss=1.4322, LR=0.000100
[2025-08-26 00:51:57,301][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015240] [Batch 00432/01234] [00:04:51/00:09:01, 0.675s/it]: train_loss_raw=1.4928, running_loss=1.4329, LR=0.000100
[2025-08-26 00:52:02,649][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015248] [Batch 00440/01234] [00:04:57/00:08:55, 0.675s/it]: train_loss_raw=1.4310, running_loss=1.4361, LR=0.000100
[2025-08-26 00:52:07,881][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015256] [Batch 00448/01234] [00:05:02/00:08:50, 0.675s/it]: train_loss_raw=1.4193, running_loss=1.4376, LR=0.000100
[2025-08-26 00:52:12,974][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015264] [Batch 00456/01234] [00:05:07/00:08:44, 0.674s/it]: train_loss_raw=1.4134, running_loss=1.4380, LR=0.000100
[2025-08-26 00:52:18,102][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015272] [Batch 00464/01234] [00:05:12/00:08:38, 0.673s/it]: train_loss_raw=1.4008, running_loss=1.4384, LR=0.000100
[2025-08-26 00:52:23,154][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015280] [Batch 00472/01234] [00:05:17/00:08:32, 0.673s/it]: train_loss_raw=1.6142, running_loss=1.4433, LR=0.000100
[2025-08-26 00:52:28,254][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015288] [Batch 00480/01234] [00:05:22/00:08:26, 0.672s/it]: train_loss_raw=1.4705, running_loss=1.4417, LR=0.000100
[2025-08-26 00:52:33,748][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015296] [Batch 00488/01234] [00:05:28/00:08:21, 0.672s/it]: train_loss_raw=1.4103, running_loss=1.4413, LR=0.000100
[2025-08-26 00:52:39,434][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015304] [Batch 00496/01234] [00:05:33/00:08:16, 0.673s/it]: train_loss_raw=1.4900, running_loss=1.4417, LR=0.000100
[2025-08-26 00:52:45,200][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015312] [Batch 00504/01234] [00:05:39/00:08:11, 0.674s/it]: train_loss_raw=1.4353, running_loss=1.4413, LR=0.000100
[2025-08-26 00:52:50,803][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015320] [Batch 00512/01234] [00:05:45/00:08:06, 0.674s/it]: train_loss_raw=1.4245, running_loss=1.4403, LR=0.000100
[2025-08-26 00:52:56,473][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015328] [Batch 00520/01234] [00:05:50/00:08:01, 0.675s/it]: train_loss_raw=1.4885, running_loss=1.4421, LR=0.000100
[2025-08-26 00:53:02,298][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015336] [Batch 00528/01234] [00:05:56/00:07:56, 0.676s/it]: train_loss_raw=1.4739, running_loss=1.4418, LR=0.000100
[2025-08-26 00:53:07,535][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015344] [Batch 00536/01234] [00:06:01/00:07:51, 0.675s/it]: train_loss_raw=1.4654, running_loss=1.4412, LR=0.000100
[2025-08-26 00:53:13,016][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015352] [Batch 00544/01234] [00:06:07/00:07:45, 0.675s/it]: train_loss_raw=1.4683, running_loss=1.4430, LR=0.000100
[2025-08-26 00:53:18,886][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015360] [Batch 00552/01234] [00:06:13/00:07:41, 0.676s/it]: train_loss_raw=1.4697, running_loss=1.4462, LR=0.000100
[2025-08-26 00:53:24,447][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015368] [Batch 00560/01234] [00:06:18/00:07:35, 0.676s/it]: train_loss_raw=1.4929, running_loss=1.4465, LR=0.000100
[2025-08-26 00:53:29,999][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015376] [Batch 00568/01234] [00:06:24/00:07:30, 0.677s/it]: train_loss_raw=1.3898, running_loss=1.4471, LR=0.000100
[2025-08-26 00:53:35,484][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015384] [Batch 00576/01234] [00:06:29/00:07:25, 0.677s/it]: train_loss_raw=1.3815, running_loss=1.4482, LR=0.000100
[2025-08-26 00:53:40,972][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015392] [Batch 00584/01234] [00:06:35/00:07:20, 0.677s/it]: train_loss_raw=1.4659, running_loss=1.4501, LR=0.000100
[2025-08-26 00:53:46,354][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015400] [Batch 00592/01234] [00:06:40/00:07:14, 0.677s/it]: train_loss_raw=1.3741, running_loss=1.4499, LR=0.000100
[2025-08-26 00:53:52,164][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015408] [Batch 00600/01234] [00:06:46/00:07:09, 0.678s/it]: train_loss_raw=1.4665, running_loss=1.4485, LR=0.000100
[2025-08-26 00:53:57,578][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015416] [Batch 00608/01234] [00:06:51/00:07:04, 0.678s/it]: train_loss_raw=1.4339, running_loss=1.4464, LR=0.000100
[2025-08-26 00:54:02,690][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015424] [Batch 00616/01234] [00:06:57/00:06:58, 0.677s/it]: train_loss_raw=1.4712, running_loss=1.4455, LR=0.000100
[2025-08-26 00:54:07,790][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015432] [Batch 00624/01234] [00:07:02/00:06:52, 0.677s/it]: train_loss_raw=1.3318, running_loss=1.4447, LR=0.000100
[2025-08-26 00:54:13,375][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015440] [Batch 00632/01234] [00:07:07/00:06:47, 0.677s/it]: train_loss_raw=1.4569, running_loss=1.4458, LR=0.000100
[2025-08-26 00:54:18,846][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015448] [Batch 00640/01234] [00:07:13/00:06:42, 0.677s/it]: train_loss_raw=1.4494, running_loss=1.4471, LR=0.000100
[2025-08-26 00:54:24,704][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015456] [Batch 00648/01234] [00:07:19/00:06:37, 0.678s/it]: train_loss_raw=1.3798, running_loss=1.4466, LR=0.000100
[2025-08-26 00:54:30,918][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015464] [Batch 00656/01234] [00:07:25/00:06:32, 0.679s/it]: train_loss_raw=1.4380, running_loss=1.4457, LR=0.000100
[2025-08-26 00:54:36,133][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015472] [Batch 00664/01234] [00:07:30/00:06:26, 0.678s/it]: train_loss_raw=1.5065, running_loss=1.4449, LR=0.000100
[2025-08-26 00:54:41,407][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015480] [Batch 00672/01234] [00:07:35/00:06:21, 0.678s/it]: train_loss_raw=1.4149, running_loss=1.4454, LR=0.000100
[2025-08-26 00:54:46,715][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015488] [Batch 00680/01234] [00:07:41/00:06:15, 0.678s/it]: train_loss_raw=1.5079, running_loss=1.4433, LR=0.000100
[2025-08-26 00:54:52,516][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015496] [Batch 00688/01234] [00:07:46/00:06:10, 0.679s/it]: train_loss_raw=1.4173, running_loss=1.4416, LR=0.000100
[2025-08-26 00:54:57,626][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015504] [Batch 00696/01234] [00:07:52/00:06:04, 0.678s/it]: train_loss_raw=1.4691, running_loss=1.4411, LR=0.000100
[2025-08-26 00:55:02,736][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015512] [Batch 00704/01234] [00:07:57/00:05:59, 0.678s/it]: train_loss_raw=1.4598, running_loss=1.4440, LR=0.000100
[2025-08-26 00:55:08,137][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015520] [Batch 00712/01234] [00:08:02/00:05:53, 0.678s/it]: train_loss_raw=1.4293, running_loss=1.4450, LR=0.000100
[2025-08-26 00:55:13,344][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015528] [Batch 00720/01234] [00:08:07/00:05:48, 0.677s/it]: train_loss_raw=1.4142, running_loss=1.4453, LR=0.000100
[2025-08-26 00:55:18,825][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015536] [Batch 00728/01234] [00:08:13/00:05:42, 0.677s/it]: train_loss_raw=1.4405, running_loss=1.4435, LR=0.000100
[2025-08-26 00:55:23,930][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015544] [Batch 00736/01234] [00:08:18/00:05:37, 0.677s/it]: train_loss_raw=1.4057, running_loss=1.4437, LR=0.000100
[2025-08-26 00:55:29,098][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015552] [Batch 00744/01234] [00:08:23/00:05:31, 0.677s/it]: train_loss_raw=1.5046, running_loss=1.4456, LR=0.000100
[2025-08-26 00:55:34,245][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015560] [Batch 00752/01234] [00:08:28/00:05:26, 0.676s/it]: train_loss_raw=1.4348, running_loss=1.4465, LR=0.000100
[2025-08-26 00:55:39,899][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015568] [Batch 00760/01234] [00:08:34/00:05:20, 0.677s/it]: train_loss_raw=1.5129, running_loss=1.4478, LR=0.000100
[2025-08-26 00:55:45,732][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015576] [Batch 00768/01234] [00:08:40/00:05:15, 0.677s/it]: train_loss_raw=1.4701, running_loss=1.4486, LR=0.000100
[2025-08-26 00:55:51,307][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015584] [Batch 00776/01234] [00:08:45/00:05:10, 0.677s/it]: train_loss_raw=1.5110, running_loss=1.4455, LR=0.000100
[2025-08-26 00:55:56,432][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015592] [Batch 00784/01234] [00:08:50/00:05:04, 0.677s/it]: train_loss_raw=1.4477, running_loss=1.4451, LR=0.000100
[2025-08-26 00:56:01,718][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015600] [Batch 00792/01234] [00:08:56/00:04:59, 0.677s/it]: train_loss_raw=1.3704, running_loss=1.4444, LR=0.000100
[2025-08-26 00:56:07,062][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015608] [Batch 00800/01234] [00:09:01/00:04:53, 0.677s/it]: train_loss_raw=1.4430, running_loss=1.4422, LR=0.000100
[2025-08-26 00:56:12,157][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015616] [Batch 00808/01234] [00:09:06/00:04:48, 0.676s/it]: train_loss_raw=1.5522, running_loss=1.4448, LR=0.000100
[2025-08-26 00:56:17,380][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015624] [Batch 00816/01234] [00:09:11/00:04:42, 0.676s/it]: train_loss_raw=1.4589, running_loss=1.4459, LR=0.000100
[2025-08-26 00:56:22,533][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015632] [Batch 00824/01234] [00:09:16/00:04:37, 0.676s/it]: train_loss_raw=1.4011, running_loss=1.4443, LR=0.000100
[2025-08-26 00:56:27,675][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015640] [Batch 00832/01234] [00:09:22/00:04:31, 0.676s/it]: train_loss_raw=1.4263, running_loss=1.4458, LR=0.000100
[2025-08-26 00:56:33,423][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015648] [Batch 00840/01234] [00:09:27/00:04:26, 0.676s/it]: train_loss_raw=1.4555, running_loss=1.4456, LR=0.000100
[2025-08-26 00:56:39,132][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015656] [Batch 00848/01234] [00:09:33/00:04:21, 0.676s/it]: train_loss_raw=1.4681, running_loss=1.4459, LR=0.000100
[2025-08-26 00:56:44,881][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015664] [Batch 00856/01234] [00:09:39/00:04:15, 0.677s/it]: train_loss_raw=1.4481, running_loss=1.4446, LR=0.000100
[2025-08-26 00:56:50,378][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015672] [Batch 00864/01234] [00:09:44/00:04:10, 0.677s/it]: train_loss_raw=1.4534, running_loss=1.4446, LR=0.000100
[2025-08-26 00:56:55,646][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015680] [Batch 00872/01234] [00:09:50/00:04:04, 0.677s/it]: train_loss_raw=1.6119, running_loss=1.4453, LR=0.000100
[2025-08-26 00:57:01,344][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015688] [Batch 00880/01234] [00:09:55/00:03:59, 0.677s/it]: train_loss_raw=1.4106, running_loss=1.4449, LR=0.000100
[2025-08-26 00:57:07,119][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015696] [Batch 00888/01234] [00:10:01/00:03:54, 0.677s/it]: train_loss_raw=1.4014, running_loss=1.4449, LR=0.000100
[2025-08-26 00:57:12,190][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015704] [Batch 00896/01234] [00:10:06/00:03:48, 0.677s/it]: train_loss_raw=1.4913, running_loss=1.4449, LR=0.000100
[2025-08-26 00:57:17,930][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015712] [Batch 00904/01234] [00:10:12/00:03:43, 0.677s/it]: train_loss_raw=1.4386, running_loss=1.4447, LR=0.000100
[2025-08-26 00:57:23,324][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015720] [Batch 00912/01234] [00:10:17/00:03:38, 0.677s/it]: train_loss_raw=1.4947, running_loss=1.4403, LR=0.000100
[2025-08-26 00:57:28,663][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015728] [Batch 00920/01234] [00:10:23/00:03:32, 0.677s/it]: train_loss_raw=1.3526, running_loss=1.4380, LR=0.000100
[2025-08-26 00:57:34,041][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015736] [Batch 00928/01234] [00:10:28/00:03:27, 0.677s/it]: train_loss_raw=1.5272, running_loss=1.4414, LR=0.000100
[2025-08-26 00:57:39,604][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015744] [Batch 00936/01234] [00:10:33/00:03:21, 0.677s/it]: train_loss_raw=1.3804, running_loss=1.4413, LR=0.000100
[2025-08-26 00:57:45,002][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015752] [Batch 00944/01234] [00:10:39/00:03:16, 0.677s/it]: train_loss_raw=1.4658, running_loss=1.4405, LR=0.000100
[2025-08-26 00:57:50,686][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015760] [Batch 00952/01234] [00:10:45/00:03:11, 0.678s/it]: train_loss_raw=1.5070, running_loss=1.4412, LR=0.000100
[2025-08-26 00:57:55,790][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015768] [Batch 00960/01234] [00:10:50/00:03:05, 0.677s/it]: train_loss_raw=1.4426, running_loss=1.4408, LR=0.000100
[2025-08-26 00:58:00,900][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015776] [Batch 00968/01234] [00:10:55/00:03:00, 0.677s/it]: train_loss_raw=1.4061, running_loss=1.4439, LR=0.000100
[2025-08-26 00:58:06,214][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015784] [Batch 00976/01234] [00:11:00/00:02:54, 0.677s/it]: train_loss_raw=1.4184, running_loss=1.4431, LR=0.000100
[2025-08-26 00:58:11,803][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015792] [Batch 00984/01234] [00:11:06/00:02:49, 0.677s/it]: train_loss_raw=1.5518, running_loss=1.4426, LR=0.000100
[2025-08-26 00:58:17,342][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015800] [Batch 00992/01234] [00:11:11/00:02:43, 0.677s/it]: train_loss_raw=1.4028, running_loss=1.4431, LR=0.000100
[2025-08-26 00:58:22,418][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015808] [Batch 01000/01234] [00:11:16/00:02:38, 0.677s/it]: train_loss_raw=1.4799, running_loss=1.4444, LR=0.000100
[2025-08-26 00:58:27,505][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015816] [Batch 01008/01234] [00:11:21/00:02:32, 0.676s/it]: train_loss_raw=1.4256, running_loss=1.4434, LR=0.000100
[2025-08-26 00:58:32,613][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015824] [Batch 01016/01234] [00:11:26/00:02:27, 0.676s/it]: train_loss_raw=1.4040, running_loss=1.4415, LR=0.000100
[2025-08-26 00:58:38,136][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015832] [Batch 01024/01234] [00:11:32/00:02:22, 0.676s/it]: train_loss_raw=1.4423, running_loss=1.4407, LR=0.000100
[2025-08-26 00:58:43,543][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015840] [Batch 01032/01234] [00:11:37/00:02:16, 0.676s/it]: train_loss_raw=1.4075, running_loss=1.4406, LR=0.000100
[2025-08-26 00:58:48,934][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015848] [Batch 01040/01234] [00:11:43/00:02:11, 0.676s/it]: train_loss_raw=1.4512, running_loss=1.4422, LR=0.000100
[2025-08-26 00:58:54,225][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015856] [Batch 01048/01234] [00:11:48/00:02:05, 0.676s/it]: train_loss_raw=1.4744, running_loss=1.4428, LR=0.000100
[2025-08-26 00:58:59,444][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015864] [Batch 01056/01234] [00:11:53/00:02:00, 0.676s/it]: train_loss_raw=1.5095, running_loss=1.4404, LR=0.000100
[2025-08-26 00:59:05,007][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015872] [Batch 01064/01234] [00:11:59/00:01:54, 0.676s/it]: train_loss_raw=1.4525, running_loss=1.4371, LR=0.000100
[2025-08-26 00:59:10,909][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015880] [Batch 01072/01234] [00:12:05/00:01:49, 0.677s/it]: train_loss_raw=1.5083, running_loss=1.4389, LR=0.000100
[2025-08-26 00:59:16,512][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015888] [Batch 01080/01234] [00:12:10/00:01:44, 0.677s/it]: train_loss_raw=1.3955, running_loss=1.4379, LR=0.000100
[2025-08-26 00:59:22,343][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015896] [Batch 01088/01234] [00:12:16/00:01:38, 0.677s/it]: train_loss_raw=1.4927, running_loss=1.4373, LR=0.000100
[2025-08-26 00:59:27,873][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015904] [Batch 01096/01234] [00:12:22/00:01:33, 0.677s/it]: train_loss_raw=1.4073, running_loss=1.4394, LR=0.000100
[2025-08-26 00:59:33,732][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015912] [Batch 01104/01234] [00:12:28/00:01:28, 0.678s/it]: train_loss_raw=1.5258, running_loss=1.4408, LR=0.000100
[2025-08-26 00:59:39,571][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015920] [Batch 01112/01234] [00:12:33/00:01:22, 0.678s/it]: train_loss_raw=1.4534, running_loss=1.4391, LR=0.000100
[2025-08-26 00:59:45,416][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015928] [Batch 01120/01234] [00:12:39/00:01:17, 0.678s/it]: train_loss_raw=1.4986, running_loss=1.4409, LR=0.000100
[2025-08-26 00:59:51,611][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015936] [Batch 01128/01234] [00:12:45/00:01:11, 0.679s/it]: train_loss_raw=1.4107, running_loss=1.4422, LR=0.000100
[2025-08-26 00:59:57,431][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015944] [Batch 01136/01234] [00:12:51/00:01:06, 0.679s/it]: train_loss_raw=1.4414, running_loss=1.4413, LR=0.000100
[2025-08-26 01:00:03,389][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015952] [Batch 01144/01234] [00:12:57/00:01:01, 0.680s/it]: train_loss_raw=1.4176, running_loss=1.4411, LR=0.000100
[2025-08-26 01:00:09,348][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015960] [Batch 01152/01234] [00:13:03/00:00:55, 0.680s/it]: train_loss_raw=1.3951, running_loss=1.4419, LR=0.000100
[2025-08-26 01:00:14,648][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015968] [Batch 01160/01234] [00:13:09/00:00:50, 0.680s/it]: train_loss_raw=1.4154, running_loss=1.4409, LR=0.000100
[2025-08-26 01:00:20,407][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015976] [Batch 01168/01234] [00:13:14/00:00:44, 0.680s/it]: train_loss_raw=1.3678, running_loss=1.4402, LR=0.000100
[2025-08-26 01:00:26,263][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015984] [Batch 01176/01234] [00:13:20/00:00:39, 0.681s/it]: train_loss_raw=1.5512, running_loss=1.4400, LR=0.000100
[2025-08-26 01:00:32,200][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 015992] [Batch 01184/01234] [00:13:26/00:00:34, 0.681s/it]: train_loss_raw=1.4230, running_loss=1.4395, LR=0.000100
[2025-08-26 01:00:37,983][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 016000] [Batch 01192/01234] [00:13:32/00:00:28, 0.682s/it]: train_loss_raw=1.5241, running_loss=1.4408, LR=0.000100
[2025-08-26 01:00:47,685][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 016008] [Batch 01200/01234] [00:13:42/00:00:23, 0.685s/it]: train_loss_raw=1.4004, running_loss=1.4406, LR=0.000100
[2025-08-26 01:00:53,526][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 016016] [Batch 01208/01234] [00:13:47/00:00:17, 0.685s/it]: train_loss_raw=1.5316, running_loss=1.4439, LR=0.000100
[2025-08-26 01:00:59,376][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 016024] [Batch 01216/01234] [00:13:53/00:00:12, 0.686s/it]: train_loss_raw=1.3969, running_loss=1.4440, LR=0.000100
[2025-08-26 01:01:05,480][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 016032] [Batch 01224/01234] [00:13:59/00:00:06, 0.686s/it]: train_loss_raw=1.5447, running_loss=1.4456, LR=0.000100
[2025-08-26 01:01:11,524][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 016040] [Batch 01232/01234] [00:14:05/00:00:01, 0.687s/it]: train_loss_raw=1.3952, running_loss=1.4410, LR=0.000100
[2025-08-26 01:01:18,635][__main__][INFO] - [VALIDATION] [Epoch 12/29] Starting validation.
[2025-08-26 01:01:30,255][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 016043] [Batch 00007/00026] [00:00:11/00:00:26, 1.452s/it]
[2025-08-26 01:01:42,121][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 016043] [Batch 00015/00026] [00:00:23/00:00:14, 1.468s/it]
[2025-08-26 01:01:53,738][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 016043] [Batch 00023/00026] [00:00:35/00:00:02, 1.463s/it]
[2025-08-26 01:01:56,368][__main__][INFO] - [VALIDATION] [Epoch 12/29] train_loss=1.43952, valid_loss=1.57497
[2025-08-26 01:01:56,368][__main__][INFO] - [VALIDATION] [Epoch 12/29] Metrics:
[2025-08-26 01:01:56,369][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_er      0.663
[2025-08-26 01:01:56,369][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_prec    0.040
[2025-08-26 01:01:56,369][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_recall  0.040
[2025-08-26 01:01:56,369][__main__][INFO] - [VALIDATION] [Epoch 12/29] - pep_recall 0.008
[2025-08-26 01:01:56,372][__main__][INFO] - [TRAIN] [Epoch 12/29] Epoch complete, total time 03:11:05, remaining time 04:09:53, 00:14:41 per epoch
[2025-08-26 01:02:00,347][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016048] [Batch 00006/01234] [00:00:03/00:12:50, 0.627s/it]: train_loss_raw=1.4769, running_loss=1.3775, LR=0.000100
[2025-08-26 01:02:06,133][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016056] [Batch 00014/01234] [00:00:09/00:13:52, 0.682s/it]: train_loss_raw=1.4352, running_loss=1.3764, LR=0.000100
[2025-08-26 01:02:12,087][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016064] [Batch 00022/01234] [00:00:15/00:14:14, 0.705s/it]: train_loss_raw=1.4412, running_loss=1.3775, LR=0.000100
[2025-08-26 01:02:18,159][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016072] [Batch 00030/01234] [00:00:21/00:14:25, 0.719s/it]: train_loss_raw=1.2612, running_loss=1.3772, LR=0.000100
[2025-08-26 01:02:24,012][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016080] [Batch 00038/01234] [00:00:27/00:14:23, 0.722s/it]: train_loss_raw=1.4068, running_loss=1.3776, LR=0.000100
[2025-08-26 01:02:29,849][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016088] [Batch 00046/01234] [00:00:33/00:14:19, 0.723s/it]: train_loss_raw=1.4336, running_loss=1.3767, LR=0.000100
[2025-08-26 01:02:35,513][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016096] [Batch 00054/01234] [00:00:38/00:14:10, 0.721s/it]: train_loss_raw=1.3999, running_loss=1.3765, LR=0.000100
[2025-08-26 01:02:41,274][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016104] [Batch 00062/01234] [00:00:44/00:14:04, 0.721s/it]: train_loss_raw=1.3722, running_loss=1.3746, LR=0.000100
[2025-08-26 01:02:46,711][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016112] [Batch 00070/01234] [00:00:50/00:13:53, 0.716s/it]: train_loss_raw=1.4064, running_loss=1.3736, LR=0.000100
[2025-08-26 01:02:52,642][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016120] [Batch 00078/01234] [00:00:56/00:13:50, 0.719s/it]: train_loss_raw=1.4190, running_loss=1.3753, LR=0.000100
[2025-08-26 01:02:58,399][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016128] [Batch 00086/01234] [00:01:01/00:13:45, 0.719s/it]: train_loss_raw=1.3876, running_loss=1.3775, LR=0.000100
[2025-08-26 01:03:03,919][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016136] [Batch 00094/01234] [00:01:07/00:13:36, 0.716s/it]: train_loss_raw=1.3497, running_loss=1.3791, LR=0.000100
[2025-08-26 01:03:09,325][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016144] [Batch 00102/01234] [00:01:12/00:13:27, 0.713s/it]: train_loss_raw=1.3853, running_loss=1.3782, LR=0.000100
[2025-08-26 01:03:14,837][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016152] [Batch 00110/01234] [00:01:18/00:13:19, 0.711s/it]: train_loss_raw=1.4039, running_loss=1.3770, LR=0.000100
[2025-08-26 01:03:20,007][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016160] [Batch 00118/01234] [00:01:23/00:13:09, 0.707s/it]: train_loss_raw=1.3790, running_loss=1.3793, LR=0.000100
[2025-08-26 01:03:25,442][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016168] [Batch 00126/01234] [00:01:28/00:13:01, 0.705s/it]: train_loss_raw=1.3454, running_loss=1.3794, LR=0.000100
[2025-08-26 01:03:31,199][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016176] [Batch 00134/01234] [00:01:34/00:12:56, 0.706s/it]: train_loss_raw=1.4695, running_loss=1.3801, LR=0.000100
[2025-08-26 01:03:36,757][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016184] [Batch 00142/01234] [00:01:40/00:12:50, 0.705s/it]: train_loss_raw=1.3556, running_loss=1.3826, LR=0.000100
[2025-08-26 01:03:41,873][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016192] [Batch 00150/01234] [00:01:45/00:12:40, 0.702s/it]: train_loss_raw=1.3278, running_loss=1.3811, LR=0.000100
[2025-08-26 01:03:47,195][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016200] [Batch 00158/01234] [00:01:50/00:12:33, 0.700s/it]: train_loss_raw=1.5400, running_loss=1.3829, LR=0.000100
[2025-08-26 01:03:52,733][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016208] [Batch 00166/01234] [00:01:56/00:12:27, 0.700s/it]: train_loss_raw=1.5304, running_loss=1.3857, LR=0.000100
[2025-08-26 01:03:57,978][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016216] [Batch 00174/01234] [00:02:01/00:12:19, 0.698s/it]: train_loss_raw=1.2849, running_loss=1.3856, LR=0.000100
[2025-08-26 01:04:03,307][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016224] [Batch 00182/01234] [00:02:06/00:12:12, 0.696s/it]: train_loss_raw=1.4446, running_loss=1.3859, LR=0.000100
[2025-08-26 01:04:08,394][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016232] [Batch 00190/01234] [00:02:11/00:12:04, 0.694s/it]: train_loss_raw=1.5192, running_loss=1.3887, LR=0.000100
[2025-08-26 01:04:13,876][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016240] [Batch 00198/01234] [00:02:17/00:11:58, 0.693s/it]: train_loss_raw=1.3220, running_loss=1.3893, LR=0.000100
[2025-08-26 01:04:19,103][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016248] [Batch 00206/01234] [00:02:22/00:11:51, 0.692s/it]: train_loss_raw=1.3362, running_loss=1.3887, LR=0.000100
[2025-08-26 01:04:24,817][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016256] [Batch 00214/01234] [00:02:28/00:11:46, 0.693s/it]: train_loss_raw=1.2844, running_loss=1.3889, LR=0.000100
[2025-08-26 01:04:30,325][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016264] [Batch 00222/01234] [00:02:33/00:11:40, 0.693s/it]: train_loss_raw=1.3936, running_loss=1.3883, LR=0.000100
[2025-08-26 01:04:36,094][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016272] [Batch 00230/01234] [00:02:39/00:11:36, 0.694s/it]: train_loss_raw=1.3085, running_loss=1.3878, LR=0.000100
[2025-08-26 01:04:41,867][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016280] [Batch 00238/01234] [00:02:45/00:11:31, 0.694s/it]: train_loss_raw=1.3168, running_loss=1.3885, LR=0.000100
[2025-08-26 01:04:47,342][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016288] [Batch 00246/01234] [00:02:50/00:11:25, 0.694s/it]: train_loss_raw=1.4444, running_loss=1.3892, LR=0.000100
[2025-08-26 01:04:52,489][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016296] [Batch 00254/01234] [00:02:55/00:11:18, 0.693s/it]: train_loss_raw=1.3103, running_loss=1.3874, LR=0.000100
[2025-08-26 01:04:58,342][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016304] [Batch 00262/01234] [00:03:01/00:11:14, 0.694s/it]: train_loss_raw=1.4617, running_loss=1.3916, LR=0.000100
[2025-08-26 01:05:04,063][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016312] [Batch 00270/01234] [00:03:07/00:11:09, 0.694s/it]: train_loss_raw=1.3503, running_loss=1.3905, LR=0.000100
[2025-08-26 01:05:09,126][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016320] [Batch 00278/01234] [00:03:12/00:11:02, 0.693s/it]: train_loss_raw=1.4508, running_loss=1.3923, LR=0.000100
[2025-08-26 01:05:14,322][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016328] [Batch 00286/01234] [00:03:17/00:10:55, 0.691s/it]: train_loss_raw=1.4467, running_loss=1.3952, LR=0.000100
[2025-08-26 01:05:19,949][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016336] [Batch 00294/01234] [00:03:23/00:10:50, 0.692s/it]: train_loss_raw=1.3208, running_loss=1.3944, LR=0.000100
[2025-08-26 01:05:25,361][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016344] [Batch 00302/01234] [00:03:28/00:10:44, 0.691s/it]: train_loss_raw=1.3188, running_loss=1.3937, LR=0.000100
[2025-08-26 01:05:30,539][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016352] [Batch 00310/01234] [00:03:33/00:10:37, 0.690s/it]: train_loss_raw=1.4143, running_loss=1.3935, LR=0.000100
[2025-08-26 01:05:36,036][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016360] [Batch 00318/01234] [00:03:39/00:10:32, 0.690s/it]: train_loss_raw=1.4245, running_loss=1.3975, LR=0.000100
[2025-08-26 01:05:41,131][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016368] [Batch 00326/01234] [00:03:44/00:10:25, 0.689s/it]: train_loss_raw=1.4068, running_loss=1.3982, LR=0.000100
[2025-08-26 01:05:46,221][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016376] [Batch 00334/01234] [00:03:49/00:10:18, 0.688s/it]: train_loss_raw=1.4383, running_loss=1.3976, LR=0.000100
[2025-08-26 01:05:51,318][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016384] [Batch 00342/01234] [00:03:54/00:10:12, 0.686s/it]: train_loss_raw=1.4116, running_loss=1.3983, LR=0.000100
[2025-08-26 01:05:56,599][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016392] [Batch 00350/01234] [00:04:00/00:10:06, 0.686s/it]: train_loss_raw=1.3366, running_loss=1.3966, LR=0.000100
[2025-08-26 01:06:01,693][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016400] [Batch 00358/01234] [00:04:05/00:09:59, 0.685s/it]: train_loss_raw=1.2988, running_loss=1.3955, LR=0.000100
[2025-08-26 01:06:07,110][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016408] [Batch 00366/01234] [00:04:10/00:09:54, 0.685s/it]: train_loss_raw=1.3496, running_loss=1.3949, LR=0.000100
[2025-08-26 01:06:12,729][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016416] [Batch 00374/01234] [00:04:16/00:09:49, 0.685s/it]: train_loss_raw=1.3937, running_loss=1.3939, LR=0.000100
[2025-08-26 01:06:17,960][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016424] [Batch 00382/01234] [00:04:21/00:09:42, 0.684s/it]: train_loss_raw=1.4689, running_loss=1.3959, LR=0.000100
[2025-08-26 01:06:23,164][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016432] [Batch 00390/01234] [00:04:26/00:09:36, 0.684s/it]: train_loss_raw=1.3909, running_loss=1.3954, LR=0.000100
[2025-08-26 01:06:28,370][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016440] [Batch 00398/01234] [00:04:31/00:09:30, 0.683s/it]: train_loss_raw=1.3158, running_loss=1.3935, LR=0.000100
[2025-08-26 01:06:33,578][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016448] [Batch 00406/01234] [00:04:36/00:09:24, 0.682s/it]: train_loss_raw=1.3912, running_loss=1.3920, LR=0.000100
[2025-08-26 01:06:39,141][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016456] [Batch 00414/01234] [00:04:42/00:09:19, 0.683s/it]: train_loss_raw=1.4078, running_loss=1.3919, LR=0.000100
[2025-08-26 01:06:44,516][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016464] [Batch 00422/01234] [00:04:47/00:09:14, 0.682s/it]: train_loss_raw=1.3484, running_loss=1.3913, LR=0.000100
[2025-08-26 01:06:50,065][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016472] [Batch 00430/01234] [00:04:53/00:09:08, 0.683s/it]: train_loss_raw=1.5453, running_loss=1.3950, LR=0.000100
[2025-08-26 01:06:55,460][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016480] [Batch 00438/01234] [00:04:58/00:09:03, 0.682s/it]: train_loss_raw=1.4634, running_loss=1.3957, LR=0.000100
[2025-08-26 01:07:00,877][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016488] [Batch 00446/01234] [00:05:04/00:08:57, 0.682s/it]: train_loss_raw=1.4554, running_loss=1.3934, LR=0.000100
[2025-08-26 01:07:06,378][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016496] [Batch 00454/01234] [00:05:09/00:08:52, 0.682s/it]: train_loss_raw=1.3634, running_loss=1.3925, LR=0.000100
[2025-08-26 01:07:11,677][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016504] [Batch 00462/01234] [00:05:15/00:08:46, 0.682s/it]: train_loss_raw=1.4619, running_loss=1.3941, LR=0.000100
[2025-08-26 01:07:17,553][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016512] [Batch 00470/01234] [00:05:20/00:08:41, 0.683s/it]: train_loss_raw=1.4637, running_loss=1.3924, LR=0.000100
[2025-08-26 01:07:23,250][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016520] [Batch 00478/01234] [00:05:26/00:08:36, 0.683s/it]: train_loss_raw=1.4416, running_loss=1.3940, LR=0.000100
[2025-08-26 01:07:28,480][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016528] [Batch 00486/01234] [00:05:31/00:08:30, 0.683s/it]: train_loss_raw=1.4466, running_loss=1.3946, LR=0.000100
[2025-08-26 01:07:34,185][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016536] [Batch 00494/01234] [00:05:37/00:08:25, 0.683s/it]: train_loss_raw=1.4173, running_loss=1.3955, LR=0.000100
[2025-08-26 01:07:39,527][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016544] [Batch 00502/01234] [00:05:42/00:08:20, 0.683s/it]: train_loss_raw=1.4195, running_loss=1.3940, LR=0.000100
[2025-08-26 01:07:44,620][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016552] [Batch 00510/01234] [00:05:48/00:08:14, 0.682s/it]: train_loss_raw=1.4267, running_loss=1.3934, LR=0.000100
[2025-08-26 01:07:50,082][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016560] [Batch 00518/01234] [00:05:53/00:08:08, 0.682s/it]: train_loss_raw=1.3795, running_loss=1.3951, LR=0.000100
[2025-08-26 01:07:55,795][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016568] [Batch 00526/01234] [00:05:59/00:08:03, 0.683s/it]: train_loss_raw=1.4063, running_loss=1.3957, LR=0.000100
[2025-08-26 01:08:01,016][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016576] [Batch 00534/01234] [00:06:04/00:07:57, 0.682s/it]: train_loss_raw=1.4644, running_loss=1.3999, LR=0.000100
[2025-08-26 01:08:06,420][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016584] [Batch 00542/01234] [00:06:09/00:07:52, 0.682s/it]: train_loss_raw=1.4487, running_loss=1.4000, LR=0.000100
[2025-08-26 01:08:11,732][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016592] [Batch 00550/01234] [00:06:15/00:07:46, 0.682s/it]: train_loss_raw=1.5211, running_loss=1.3998, LR=0.000100
[2025-08-26 01:08:16,947][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016600] [Batch 00558/01234] [00:06:20/00:07:40, 0.682s/it]: train_loss_raw=1.3898, running_loss=1.3990, LR=0.000100
[2025-08-26 01:08:22,303][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016608] [Batch 00566/01234] [00:06:25/00:07:35, 0.681s/it]: train_loss_raw=1.4746, running_loss=1.3984, LR=0.000100
[2025-08-26 01:08:28,064][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016616] [Batch 00574/01234] [00:06:31/00:07:30, 0.682s/it]: train_loss_raw=1.4188, running_loss=1.3962, LR=0.000100
[2025-08-26 01:08:33,610][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016624] [Batch 00582/01234] [00:06:37/00:07:24, 0.682s/it]: train_loss_raw=1.4229, running_loss=1.3983, LR=0.000100
[2025-08-26 01:08:39,367][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016632] [Batch 00590/01234] [00:06:42/00:07:19, 0.683s/it]: train_loss_raw=1.3567, running_loss=1.3986, LR=0.000100
[2025-08-26 01:08:44,835][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016640] [Batch 00598/01234] [00:06:48/00:07:14, 0.683s/it]: train_loss_raw=1.3916, running_loss=1.3980, LR=0.000100
[2025-08-26 01:08:49,920][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016648] [Batch 00606/01234] [00:06:53/00:07:08, 0.682s/it]: train_loss_raw=1.3881, running_loss=1.3989, LR=0.000100
[2025-08-26 01:08:55,385][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016656] [Batch 00614/01234] [00:06:58/00:07:02, 0.682s/it]: train_loss_raw=1.3633, running_loss=1.4009, LR=0.000100
[2025-08-26 01:09:01,423][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016664] [Batch 00622/01234] [00:07:04/00:06:58, 0.683s/it]: train_loss_raw=1.3678, running_loss=1.4024, LR=0.000100
[2025-08-26 01:09:06,753][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016672] [Batch 00630/01234] [00:07:10/00:06:52, 0.683s/it]: train_loss_raw=1.3296, running_loss=1.4008, LR=0.000100
[2025-08-26 01:09:12,490][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016680] [Batch 00638/01234] [00:07:15/00:06:47, 0.683s/it]: train_loss_raw=1.5625, running_loss=1.4025, LR=0.000100
[2025-08-26 01:09:17,545][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016688] [Batch 00646/01234] [00:07:20/00:06:41, 0.683s/it]: train_loss_raw=1.4057, running_loss=1.4025, LR=0.000100
[2025-08-26 01:09:22,981][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016696] [Batch 00654/01234] [00:07:26/00:06:35, 0.683s/it]: train_loss_raw=1.3821, running_loss=1.4046, LR=0.000100
[2025-08-26 01:09:28,814][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016704] [Batch 00662/01234] [00:07:32/00:06:30, 0.683s/it]: train_loss_raw=1.3804, running_loss=1.4028, LR=0.000100
[2025-08-26 01:09:34,695][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016712] [Batch 00670/01234] [00:07:38/00:06:25, 0.684s/it]: train_loss_raw=1.3928, running_loss=1.4011, LR=0.000100
[2025-08-26 01:09:40,600][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016720] [Batch 00678/01234] [00:07:44/00:06:20, 0.684s/it]: train_loss_raw=1.5027, running_loss=1.4040, LR=0.000100
[2025-08-26 01:09:46,270][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016728] [Batch 00686/01234] [00:07:49/00:06:15, 0.685s/it]: train_loss_raw=1.4849, running_loss=1.4043, LR=0.000100
[2025-08-26 01:09:52,013][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016736] [Batch 00694/01234] [00:07:55/00:06:09, 0.685s/it]: train_loss_raw=1.4287, running_loss=1.4026, LR=0.000100
[2025-08-26 01:09:57,377][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016744] [Batch 00702/01234] [00:08:00/00:06:04, 0.685s/it]: train_loss_raw=1.3927, running_loss=1.4034, LR=0.000100
[2025-08-26 01:10:02,614][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016752] [Batch 00710/01234] [00:08:06/00:05:58, 0.685s/it]: train_loss_raw=1.4161, running_loss=1.4034, LR=0.000100
[2025-08-26 01:10:08,118][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016760] [Batch 00718/01234] [00:08:11/00:05:53, 0.685s/it]: train_loss_raw=1.4088, running_loss=1.3990, LR=0.000100
[2025-08-26 01:10:13,966][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016768] [Batch 00726/01234] [00:08:17/00:05:48, 0.685s/it]: train_loss_raw=1.4389, running_loss=1.3977, LR=0.000100
[2025-08-26 01:10:19,108][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016776] [Batch 00734/01234] [00:08:22/00:05:42, 0.685s/it]: train_loss_raw=1.4341, running_loss=1.3962, LR=0.000100
[2025-08-26 01:10:24,425][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016784] [Batch 00742/01234] [00:08:27/00:05:36, 0.684s/it]: train_loss_raw=1.4436, running_loss=1.3976, LR=0.000100
[2025-08-26 01:10:29,977][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016792] [Batch 00750/01234] [00:08:33/00:05:31, 0.685s/it]: train_loss_raw=1.4056, running_loss=1.3980, LR=0.000100
[2025-08-26 01:10:35,554][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016800] [Batch 00758/01234] [00:08:38/00:05:25, 0.685s/it]: train_loss_raw=1.4399, running_loss=1.4015, LR=0.000100
[2025-08-26 01:10:40,618][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016808] [Batch 00766/01234] [00:08:44/00:05:20, 0.684s/it]: train_loss_raw=1.4336, running_loss=1.4007, LR=0.000100
[2025-08-26 01:10:45,706][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016816] [Batch 00774/01234] [00:08:49/00:05:14, 0.684s/it]: train_loss_raw=1.3153, running_loss=1.4012, LR=0.000100
[2025-08-26 01:10:50,780][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016824] [Batch 00782/01234] [00:08:54/00:05:08, 0.683s/it]: train_loss_raw=1.4277, running_loss=1.4029, LR=0.000100
[2025-08-26 01:10:55,850][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016832] [Batch 00790/01234] [00:08:59/00:05:03, 0.683s/it]: train_loss_raw=1.5133, running_loss=1.4027, LR=0.000100
[2025-08-26 01:11:00,942][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016840] [Batch 00798/01234] [00:09:04/00:04:57, 0.682s/it]: train_loss_raw=1.4437, running_loss=1.4030, LR=0.000100
[2025-08-26 01:11:06,399][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016848] [Batch 00806/01234] [00:09:09/00:04:51, 0.682s/it]: train_loss_raw=1.3275, running_loss=1.4019, LR=0.000100
[2025-08-26 01:11:11,602][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016856] [Batch 00814/01234] [00:09:15/00:04:46, 0.682s/it]: train_loss_raw=1.3897, running_loss=1.3990, LR=0.000100
[2025-08-26 01:11:16,983][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016864] [Batch 00822/01234] [00:09:20/00:04:40, 0.682s/it]: train_loss_raw=1.4009, running_loss=1.3975, LR=0.000100
[2025-08-26 01:11:22,724][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016872] [Batch 00830/01234] [00:09:26/00:04:35, 0.682s/it]: train_loss_raw=1.4271, running_loss=1.4000, LR=0.000100
[2025-08-26 01:11:27,855][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016880] [Batch 00838/01234] [00:09:31/00:04:29, 0.682s/it]: train_loss_raw=1.3694, running_loss=1.3997, LR=0.000100
[2025-08-26 01:11:33,421][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016888] [Batch 00846/01234] [00:09:36/00:04:24, 0.682s/it]: train_loss_raw=1.3814, running_loss=1.4020, LR=0.000100
[2025-08-26 01:11:39,147][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016896] [Batch 00854/01234] [00:09:42/00:04:19, 0.682s/it]: train_loss_raw=1.3608, running_loss=1.4010, LR=0.000100
[2025-08-26 01:11:44,548][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016904] [Batch 00862/01234] [00:09:47/00:04:13, 0.682s/it]: train_loss_raw=1.2486, running_loss=1.3997, LR=0.000100
[2025-08-26 01:11:49,627][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016912] [Batch 00870/01234] [00:09:53/00:04:08, 0.682s/it]: train_loss_raw=1.3768, running_loss=1.3983, LR=0.000100
[2025-08-26 01:11:55,027][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016920] [Batch 00878/01234] [00:09:58/00:04:02, 0.682s/it]: train_loss_raw=1.2890, running_loss=1.3972, LR=0.000100
[2025-08-26 01:12:00,875][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016928] [Batch 00886/01234] [00:10:04/00:03:57, 0.682s/it]: train_loss_raw=1.4471, running_loss=1.3971, LR=0.000100
[2025-08-26 01:12:06,687][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016936] [Batch 00894/01234] [00:10:10/00:03:52, 0.682s/it]: train_loss_raw=1.4482, running_loss=1.3984, LR=0.000100
[2025-08-26 01:12:12,346][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016944] [Batch 00902/01234] [00:10:15/00:03:46, 0.683s/it]: train_loss_raw=1.3923, running_loss=1.3994, LR=0.000100
[2025-08-26 01:12:17,453][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016952] [Batch 00910/01234] [00:10:20/00:03:41, 0.682s/it]: train_loss_raw=1.5302, running_loss=1.3985, LR=0.000100
[2025-08-26 01:12:22,654][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016960] [Batch 00918/01234] [00:10:26/00:03:35, 0.682s/it]: train_loss_raw=1.3483, running_loss=1.3988, LR=0.000100
[2025-08-26 01:12:28,000][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016968] [Batch 00926/01234] [00:10:31/00:03:30, 0.682s/it]: train_loss_raw=1.3667, running_loss=1.3971, LR=0.000100
[2025-08-26 01:12:33,083][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016976] [Batch 00934/01234] [00:10:36/00:03:24, 0.681s/it]: train_loss_raw=1.4101, running_loss=1.3964, LR=0.000100
[2025-08-26 01:12:38,390][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016984] [Batch 00942/01234] [00:10:41/00:03:18, 0.681s/it]: train_loss_raw=1.4410, running_loss=1.3982, LR=0.000100
[2025-08-26 01:12:43,457][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 016992] [Batch 00950/01234] [00:10:46/00:03:13, 0.681s/it]: train_loss_raw=1.3976, running_loss=1.3967, LR=0.000100
[2025-08-26 01:12:48,511][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017000] [Batch 00958/01234] [00:10:51/00:03:07, 0.681s/it]: train_loss_raw=1.3728, running_loss=1.3970, LR=0.000100
[2025-08-26 01:12:53,649][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017008] [Batch 00966/01234] [00:10:57/00:03:02, 0.680s/it]: train_loss_raw=1.4031, running_loss=1.3970, LR=0.000100
[2025-08-26 01:12:59,314][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017016] [Batch 00974/01234] [00:11:02/00:02:56, 0.680s/it]: train_loss_raw=1.3956, running_loss=1.3973, LR=0.000100
[2025-08-26 01:13:04,534][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017024] [Batch 00982/01234] [00:11:07/00:02:51, 0.680s/it]: train_loss_raw=1.4571, running_loss=1.3954, LR=0.000100
[2025-08-26 01:13:10,018][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017032] [Batch 00990/01234] [00:11:13/00:02:45, 0.680s/it]: train_loss_raw=1.3845, running_loss=1.3961, LR=0.000100
[2025-08-26 01:13:15,319][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017040] [Batch 00998/01234] [00:11:18/00:02:40, 0.680s/it]: train_loss_raw=1.4273, running_loss=1.3944, LR=0.000100
[2025-08-26 01:13:20,471][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017048] [Batch 01006/01234] [00:11:23/00:02:34, 0.680s/it]: train_loss_raw=1.3849, running_loss=1.3961, LR=0.000100
[2025-08-26 01:13:26,044][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017056] [Batch 01014/01234] [00:11:29/00:02:29, 0.680s/it]: train_loss_raw=1.3767, running_loss=1.3971, LR=0.000100
[2025-08-26 01:13:31,714][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017064] [Batch 01022/01234] [00:11:35/00:02:24, 0.680s/it]: train_loss_raw=1.3805, running_loss=1.3973, LR=0.000100
[2025-08-26 01:13:36,794][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017072] [Batch 01030/01234] [00:11:40/00:02:18, 0.680s/it]: train_loss_raw=1.3529, running_loss=1.3988, LR=0.000100
[2025-08-26 01:13:42,145][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017080] [Batch 01038/01234] [00:11:45/00:02:13, 0.680s/it]: train_loss_raw=1.5269, running_loss=1.4006, LR=0.000100
[2025-08-26 01:13:47,690][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017088] [Batch 01046/01234] [00:11:51/00:02:07, 0.680s/it]: train_loss_raw=1.3963, running_loss=1.4008, LR=0.000100
[2025-08-26 01:13:53,436][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017096] [Batch 01054/01234] [00:11:56/00:02:02, 0.680s/it]: train_loss_raw=1.4643, running_loss=1.4008, LR=0.000100
[2025-08-26 01:13:58,984][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017104] [Batch 01062/01234] [00:12:02/00:01:56, 0.680s/it]: train_loss_raw=1.3356, running_loss=1.3995, LR=0.000100
[2025-08-26 01:14:04,407][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017112] [Batch 01070/01234] [00:12:07/00:01:51, 0.680s/it]: train_loss_raw=1.4053, running_loss=1.3990, LR=0.000100
[2025-08-26 01:14:09,481][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017120] [Batch 01078/01234] [00:12:12/00:01:46, 0.680s/it]: train_loss_raw=1.3347, running_loss=1.3982, LR=0.000100
[2025-08-26 01:14:15,166][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017128] [Batch 01086/01234] [00:12:18/00:01:40, 0.680s/it]: train_loss_raw=1.4026, running_loss=1.3989, LR=0.000100
[2025-08-26 01:14:20,690][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017136] [Batch 01094/01234] [00:12:24/00:01:35, 0.680s/it]: train_loss_raw=1.3218, running_loss=1.3982, LR=0.000100
[2025-08-26 01:14:26,010][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017144] [Batch 01102/01234] [00:12:29/00:01:29, 0.680s/it]: train_loss_raw=1.3384, running_loss=1.3970, LR=0.000100
[2025-08-26 01:14:31,862][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017152] [Batch 01110/01234] [00:12:35/00:01:24, 0.680s/it]: train_loss_raw=1.4043, running_loss=1.3981, LR=0.000100
[2025-08-26 01:14:37,537][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017160] [Batch 01118/01234] [00:12:40/00:01:18, 0.681s/it]: train_loss_raw=1.3979, running_loss=1.3981, LR=0.000100
[2025-08-26 01:14:43,244][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017168] [Batch 01126/01234] [00:12:46/00:01:13, 0.681s/it]: train_loss_raw=1.3964, running_loss=1.3994, LR=0.000100
[2025-08-26 01:14:48,627][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017176] [Batch 01134/01234] [00:12:52/00:01:08, 0.681s/it]: train_loss_raw=1.4143, running_loss=1.3971, LR=0.000100
[2025-08-26 01:14:53,817][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017184] [Batch 01142/01234] [00:12:57/00:01:02, 0.681s/it]: train_loss_raw=1.4430, running_loss=1.3965, LR=0.000100
[2025-08-26 01:14:59,213][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017192] [Batch 01150/01234] [00:13:02/00:00:57, 0.681s/it]: train_loss_raw=1.4170, running_loss=1.3970, LR=0.000100
[2025-08-26 01:15:04,780][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017200] [Batch 01158/01234] [00:13:08/00:00:51, 0.681s/it]: train_loss_raw=1.4737, running_loss=1.3998, LR=0.000100
[2025-08-26 01:15:10,060][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017208] [Batch 01166/01234] [00:13:13/00:00:46, 0.681s/it]: train_loss_raw=1.3828, running_loss=1.3997, LR=0.000100
[2025-08-26 01:15:15,678][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017216] [Batch 01174/01234] [00:13:19/00:00:40, 0.681s/it]: train_loss_raw=1.4519, running_loss=1.3993, LR=0.000100
[2025-08-26 01:15:20,843][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017224] [Batch 01182/01234] [00:13:24/00:00:35, 0.680s/it]: train_loss_raw=1.4497, running_loss=1.4022, LR=0.000100
[2025-08-26 01:15:25,917][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017232] [Batch 01190/01234] [00:13:29/00:00:29, 0.680s/it]: train_loss_raw=1.3514, running_loss=1.4040, LR=0.000100
[2025-08-26 01:15:31,647][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017240] [Batch 01198/01234] [00:13:35/00:00:24, 0.680s/it]: train_loss_raw=1.4203, running_loss=1.4048, LR=0.000100
[2025-08-26 01:15:37,406][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017248] [Batch 01206/01234] [00:13:40/00:00:19, 0.681s/it]: train_loss_raw=1.3773, running_loss=1.4059, LR=0.000100
[2025-08-26 01:15:43,101][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017256] [Batch 01214/01234] [00:13:46/00:00:13, 0.681s/it]: train_loss_raw=1.4478, running_loss=1.4044, LR=0.000100
[2025-08-26 01:15:48,384][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017264] [Batch 01222/01234] [00:13:51/00:00:08, 0.681s/it]: train_loss_raw=1.4860, running_loss=1.4041, LR=0.000100
[2025-08-26 01:15:53,601][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 017272] [Batch 01230/01234] [00:13:57/00:00:02, 0.681s/it]: train_loss_raw=1.3854, running_loss=1.4044, LR=0.000100
[2025-08-26 01:16:02,114][__main__][INFO] - [VALIDATION] [Epoch 13/29] Starting validation.
[2025-08-26 01:16:12,388][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 017277] [Batch 00007/00026] [00:00:10/00:00:23, 1.284s/it]
[2025-08-26 01:16:23,779][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 017277] [Batch 00015/00026] [00:00:21/00:00:13, 1.354s/it]
[2025-08-26 01:16:34,656][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 017277] [Batch 00023/00026] [00:00:32/00:00:02, 1.356s/it]
[2025-08-26 01:16:36,949][__main__][INFO] - [VALIDATION] [Epoch 13/29] train_loss=1.40341, valid_loss=1.55821
[2025-08-26 01:16:36,949][__main__][INFO] - [VALIDATION] [Epoch 13/29] Metrics:
[2025-08-26 01:16:36,949][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_er      0.645
[2025-08-26 01:16:36,949][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_prec    0.046
[2025-08-26 01:16:36,949][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_recall  0.046
[2025-08-26 01:16:36,949][__main__][INFO] - [VALIDATION] [Epoch 13/29] - pep_recall 0.009
[2025-08-26 01:16:36,951][__main__][INFO] - [TRAIN] [Epoch 13/29] Epoch complete, total time 03:25:46, remaining time 03:55:09, 00:14:41 per epoch
[2025-08-26 01:16:39,219][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017280] [Batch 00004/01234] [00:00:02/00:10:57, 0.534s/it]: train_loss_raw=1.3218, running_loss=1.3848, LR=0.000100
[2025-08-26 01:16:45,070][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017288] [Batch 00012/01234] [00:00:07/00:13:33, 0.666s/it]: train_loss_raw=1.3346, running_loss=1.3806, LR=0.000100
[2025-08-26 01:16:50,453][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017296] [Batch 00020/01234] [00:00:13/00:13:31, 0.669s/it]: train_loss_raw=1.3313, running_loss=1.3771, LR=0.000100
[2025-08-26 01:16:55,847][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017304] [Batch 00028/01234] [00:00:18/00:13:28, 0.670s/it]: train_loss_raw=1.4002, running_loss=1.3769, LR=0.000100
[2025-08-26 01:17:01,291][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017312] [Batch 00036/01234] [00:00:24/00:13:25, 0.672s/it]: train_loss_raw=1.3322, running_loss=1.3747, LR=0.000100
[2025-08-26 01:17:06,487][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017320] [Batch 00044/01234] [00:00:29/00:13:15, 0.668s/it]: train_loss_raw=1.4103, running_loss=1.3725, LR=0.000100
[2025-08-26 01:17:12,121][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017328] [Batch 00052/01234] [00:00:35/00:13:16, 0.674s/it]: train_loss_raw=1.2550, running_loss=1.3692, LR=0.000100
[2025-08-26 01:17:17,792][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017336] [Batch 00060/01234] [00:00:40/00:13:16, 0.678s/it]: train_loss_raw=1.2555, running_loss=1.3651, LR=0.000100
[2025-08-26 01:17:23,573][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017344] [Batch 00068/01234] [00:00:46/00:13:17, 0.684s/it]: train_loss_raw=1.3022, running_loss=1.3600, LR=0.000100
[2025-08-26 01:17:29,120][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017352] [Batch 00076/01234] [00:00:52/00:13:12, 0.685s/it]: train_loss_raw=1.3962, running_loss=1.3587, LR=0.000100
[2025-08-26 01:17:35,155][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017360] [Batch 00084/01234] [00:00:58/00:13:15, 0.691s/it]: train_loss_raw=1.3168, running_loss=1.3561, LR=0.000100
[2025-08-26 01:17:40,975][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017368] [Batch 00092/01234] [00:01:03/00:13:13, 0.694s/it]: train_loss_raw=1.4343, running_loss=1.3555, LR=0.000100
[2025-08-26 01:17:46,465][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017376] [Batch 00100/01234] [00:01:09/00:13:06, 0.694s/it]: train_loss_raw=1.3826, running_loss=1.3545, LR=0.000100
[2025-08-26 01:17:51,741][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017384] [Batch 00108/01234] [00:01:14/00:12:58, 0.691s/it]: train_loss_raw=1.3769, running_loss=1.3529, LR=0.000100
[2025-08-26 01:17:57,070][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017392] [Batch 00116/01234] [00:01:19/00:12:50, 0.690s/it]: train_loss_raw=1.3080, running_loss=1.3514, LR=0.000100
[2025-08-26 01:18:02,771][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017400] [Batch 00124/01234] [00:01:25/00:12:47, 0.691s/it]: train_loss_raw=1.3340, running_loss=1.3512, LR=0.000100
[2025-08-26 01:18:07,915][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017408] [Batch 00132/01234] [00:01:30/00:12:38, 0.688s/it]: train_loss_raw=1.3257, running_loss=1.3519, LR=0.000100
[2025-08-26 01:18:13,712][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017416] [Batch 00140/01234] [00:01:36/00:12:35, 0.690s/it]: train_loss_raw=1.4427, running_loss=1.3535, LR=0.000100
[2025-08-26 01:18:19,153][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017424] [Batch 00148/01234] [00:01:42/00:12:28, 0.690s/it]: train_loss_raw=1.3280, running_loss=1.3542, LR=0.000100
[2025-08-26 01:18:24,393][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017432] [Batch 00156/01234] [00:01:47/00:12:21, 0.688s/it]: train_loss_raw=1.3513, running_loss=1.3545, LR=0.000100
[2025-08-26 01:18:29,465][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017440] [Batch 00164/01234] [00:01:52/00:12:13, 0.685s/it]: train_loss_raw=1.3470, running_loss=1.3523, LR=0.000100
[2025-08-26 01:18:35,068][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017448] [Batch 00172/01234] [00:01:57/00:12:08, 0.686s/it]: train_loss_raw=1.2839, running_loss=1.3515, LR=0.000100
[2025-08-26 01:18:40,790][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017456] [Batch 00180/01234] [00:02:03/00:12:04, 0.687s/it]: train_loss_raw=1.3322, running_loss=1.3505, LR=0.000100
[2025-08-26 01:18:46,462][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017464] [Batch 00188/01234] [00:02:09/00:11:59, 0.688s/it]: train_loss_raw=1.3414, running_loss=1.3493, LR=0.000100
[2025-08-26 01:18:51,914][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017472] [Batch 00196/01234] [00:02:14/00:11:54, 0.688s/it]: train_loss_raw=1.3110, running_loss=1.3482, LR=0.000100
[2025-08-26 01:18:57,762][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017480] [Batch 00204/01234] [00:02:20/00:11:50, 0.690s/it]: train_loss_raw=1.2977, running_loss=1.3474, LR=0.000100
[2025-08-26 01:19:03,829][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017488] [Batch 00212/01234] [00:02:26/00:11:47, 0.692s/it]: train_loss_raw=1.2977, running_loss=1.3456, LR=0.000100
[2025-08-26 01:19:09,457][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017496] [Batch 00220/01234] [00:02:32/00:11:42, 0.693s/it]: train_loss_raw=1.2918, running_loss=1.3461, LR=0.000100
[2025-08-26 01:19:14,644][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017504] [Batch 00228/01234] [00:02:37/00:11:35, 0.691s/it]: train_loss_raw=1.4088, running_loss=1.3474, LR=0.000100
[2025-08-26 01:19:20,461][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017512] [Batch 00236/01234] [00:02:43/00:11:30, 0.692s/it]: train_loss_raw=1.4544, running_loss=1.3500, LR=0.000100
[2025-08-26 01:19:25,529][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017520] [Batch 00244/01234] [00:02:48/00:11:23, 0.690s/it]: train_loss_raw=1.2438, running_loss=1.3478, LR=0.000100
[2025-08-26 01:19:30,675][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017528] [Batch 00252/01234] [00:02:53/00:11:16, 0.689s/it]: train_loss_raw=1.4079, running_loss=1.3457, LR=0.000100
[2025-08-26 01:19:36,323][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017536] [Batch 00260/01234] [00:02:59/00:11:11, 0.689s/it]: train_loss_raw=1.4040, running_loss=1.3466, LR=0.000100
[2025-08-26 01:19:41,572][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017544] [Batch 00268/01234] [00:03:04/00:11:04, 0.688s/it]: train_loss_raw=1.3526, running_loss=1.3470, LR=0.000100
[2025-08-26 01:19:46,648][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017552] [Batch 00276/01234] [00:03:09/00:10:57, 0.687s/it]: train_loss_raw=1.4411, running_loss=1.3466, LR=0.000100
[2025-08-26 01:19:52,231][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017560] [Batch 00284/01234] [00:03:15/00:10:52, 0.687s/it]: train_loss_raw=1.3122, running_loss=1.3480, LR=0.000100
[2025-08-26 01:19:57,338][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017568] [Batch 00292/01234] [00:03:20/00:10:46, 0.686s/it]: train_loss_raw=1.3046, running_loss=1.3463, LR=0.000100
[2025-08-26 01:20:03,061][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017576] [Batch 00300/01234] [00:03:25/00:10:41, 0.687s/it]: train_loss_raw=1.3616, running_loss=1.3478, LR=0.000100
[2025-08-26 01:20:08,916][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017584] [Batch 00308/01234] [00:03:31/00:10:36, 0.688s/it]: train_loss_raw=1.3403, running_loss=1.3474, LR=0.000100
[2025-08-26 01:20:14,695][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017592] [Batch 00316/01234] [00:03:37/00:10:32, 0.689s/it]: train_loss_raw=1.3306, running_loss=1.3467, LR=0.000100
[2025-08-26 01:20:20,989][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017600] [Batch 00324/01234] [00:03:43/00:10:28, 0.691s/it]: train_loss_raw=1.3731, running_loss=1.3456, LR=0.000100
[2025-08-26 01:20:26,336][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017608] [Batch 00332/01234] [00:03:49/00:10:22, 0.691s/it]: train_loss_raw=1.3082, running_loss=1.3468, LR=0.000100
[2025-08-26 01:20:32,131][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017616] [Batch 00340/01234] [00:03:55/00:10:18, 0.691s/it]: train_loss_raw=1.3324, running_loss=1.3471, LR=0.000100
[2025-08-26 01:20:37,336][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017624] [Batch 00348/01234] [00:04:00/00:10:11, 0.690s/it]: train_loss_raw=1.3628, running_loss=1.3487, LR=0.000100
[2025-08-26 01:20:42,821][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017632] [Batch 00356/01234] [00:04:05/00:10:06, 0.690s/it]: train_loss_raw=1.3489, running_loss=1.3486, LR=0.000100
[2025-08-26 01:20:47,931][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017640] [Batch 00364/01234] [00:04:10/00:09:59, 0.689s/it]: train_loss_raw=1.3493, running_loss=1.3502, LR=0.000100
[2025-08-26 01:20:53,382][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017648] [Batch 00372/01234] [00:04:16/00:09:53, 0.689s/it]: train_loss_raw=1.3318, running_loss=1.3519, LR=0.000100
[2025-08-26 01:20:58,448][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017656] [Batch 00380/01234] [00:04:21/00:09:47, 0.688s/it]: train_loss_raw=1.2545, running_loss=1.3509, LR=0.000100
[2025-08-26 01:21:04,102][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017664] [Batch 00388/01234] [00:04:27/00:09:42, 0.688s/it]: train_loss_raw=1.2675, running_loss=1.3483, LR=0.000100
[2025-08-26 01:21:09,655][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017672] [Batch 00396/01234] [00:04:32/00:09:36, 0.688s/it]: train_loss_raw=1.3465, running_loss=1.3470, LR=0.000100
[2025-08-26 01:21:14,724][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017680] [Batch 00404/01234] [00:04:37/00:09:30, 0.687s/it]: train_loss_raw=1.2719, running_loss=1.3434, LR=0.000100
[2025-08-26 01:21:19,771][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017688] [Batch 00412/01234] [00:04:42/00:09:24, 0.686s/it]: train_loss_raw=1.3224, running_loss=1.3422, LR=0.000100
[2025-08-26 01:21:25,153][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017696] [Batch 00420/01234] [00:04:48/00:09:18, 0.686s/it]: train_loss_raw=1.3332, running_loss=1.3451, LR=0.000100
[2025-08-26 01:21:30,212][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017704] [Batch 00428/01234] [00:04:53/00:09:12, 0.685s/it]: train_loss_raw=1.2533, running_loss=1.3433, LR=0.000100
[2025-08-26 01:21:35,301][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017712] [Batch 00436/01234] [00:04:58/00:09:05, 0.684s/it]: train_loss_raw=1.3459, running_loss=1.3409, LR=0.000100
[2025-08-26 01:21:40,556][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017720] [Batch 00444/01234] [00:05:03/00:08:59, 0.684s/it]: train_loss_raw=1.2988, running_loss=1.3418, LR=0.000100
[2025-08-26 01:21:46,171][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017728] [Batch 00452/01234] [00:05:09/00:08:54, 0.684s/it]: train_loss_raw=1.3835, running_loss=1.3434, LR=0.000100
[2025-08-26 01:21:51,907][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017736] [Batch 00460/01234] [00:05:14/00:08:49, 0.684s/it]: train_loss_raw=1.3704, running_loss=1.3463, LR=0.000100
[2025-08-26 01:21:58,007][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017744] [Batch 00468/01234] [00:05:20/00:08:45, 0.686s/it]: train_loss_raw=1.2305, running_loss=1.3494, LR=0.000100
[2025-08-26 01:22:03,404][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017752] [Batch 00476/01234] [00:05:26/00:08:39, 0.686s/it]: train_loss_raw=1.3683, running_loss=1.3484, LR=0.000100
[2025-08-26 01:22:08,598][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017760] [Batch 00484/01234] [00:05:31/00:08:33, 0.685s/it]: train_loss_raw=1.2906, running_loss=1.3475, LR=0.000100
[2025-08-26 01:22:13,738][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017768] [Batch 00492/01234] [00:05:36/00:08:27, 0.684s/it]: train_loss_raw=1.3395, running_loss=1.3459, LR=0.000100
[2025-08-26 01:22:19,038][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017776] [Batch 00500/01234] [00:05:41/00:08:21, 0.684s/it]: train_loss_raw=1.3420, running_loss=1.3473, LR=0.000100
[2025-08-26 01:22:24,109][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017784] [Batch 00508/01234] [00:05:47/00:08:15, 0.683s/it]: train_loss_raw=1.4159, running_loss=1.3452, LR=0.000100
[2025-08-26 01:22:29,599][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017792] [Batch 00516/01234] [00:05:52/00:08:10, 0.683s/it]: train_loss_raw=1.3762, running_loss=1.3451, LR=0.000100
[2025-08-26 01:22:35,288][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017800] [Batch 00524/01234] [00:05:58/00:08:05, 0.684s/it]: train_loss_raw=1.4107, running_loss=1.3451, LR=0.000100
[2025-08-26 01:22:41,159][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017808] [Batch 00532/01234] [00:06:04/00:08:00, 0.684s/it]: train_loss_raw=1.2782, running_loss=1.3442, LR=0.000100
[2025-08-26 01:22:46,506][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017816] [Batch 00540/01234] [00:06:09/00:07:54, 0.684s/it]: train_loss_raw=1.3413, running_loss=1.3450, LR=0.000100
[2025-08-26 01:22:51,989][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017824] [Batch 00548/01234] [00:06:14/00:07:49, 0.684s/it]: train_loss_raw=1.3491, running_loss=1.3476, LR=0.000100
[2025-08-26 01:22:57,230][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017832] [Batch 00556/01234] [00:06:20/00:07:43, 0.684s/it]: train_loss_raw=1.3910, running_loss=1.3507, LR=0.000100
[2025-08-26 01:23:02,573][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017840] [Batch 00564/01234] [00:06:25/00:07:37, 0.683s/it]: train_loss_raw=1.4019, running_loss=1.3524, LR=0.000100
[2025-08-26 01:23:07,662][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017848] [Batch 00572/01234] [00:06:30/00:07:32, 0.683s/it]: train_loss_raw=1.4163, running_loss=1.3512, LR=0.000100
[2025-08-26 01:23:12,742][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017856] [Batch 00580/01234] [00:06:35/00:07:26, 0.682s/it]: train_loss_raw=1.3593, running_loss=1.3500, LR=0.000100
[2025-08-26 01:23:18,225][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017864] [Batch 00588/01234] [00:06:41/00:07:20, 0.682s/it]: train_loss_raw=1.3398, running_loss=1.3487, LR=0.000100
[2025-08-26 01:23:23,536][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017872] [Batch 00596/01234] [00:06:46/00:07:15, 0.682s/it]: train_loss_raw=1.4737, running_loss=1.3511, LR=0.000100
[2025-08-26 01:23:28,789][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017880] [Batch 00604/01234] [00:06:51/00:07:09, 0.682s/it]: train_loss_raw=1.3154, running_loss=1.3504, LR=0.000100
[2025-08-26 01:23:33,854][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017888] [Batch 00612/01234] [00:06:56/00:07:03, 0.681s/it]: train_loss_raw=1.2659, running_loss=1.3485, LR=0.000100
[2025-08-26 01:23:39,473][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017896] [Batch 00620/01234] [00:07:02/00:06:58, 0.681s/it]: train_loss_raw=1.3372, running_loss=1.3467, LR=0.000100
[2025-08-26 01:23:45,245][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017904] [Batch 00628/01234] [00:07:08/00:06:53, 0.682s/it]: train_loss_raw=1.3906, running_loss=1.3453, LR=0.000100
[2025-08-26 01:23:50,958][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017912] [Batch 00636/01234] [00:07:13/00:06:47, 0.682s/it]: train_loss_raw=1.3855, running_loss=1.3484, LR=0.000100
[2025-08-26 01:23:56,488][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017920] [Batch 00644/01234] [00:07:19/00:06:42, 0.682s/it]: train_loss_raw=1.3223, running_loss=1.3485, LR=0.000100
[2025-08-26 01:24:01,960][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017928] [Batch 00652/01234] [00:07:24/00:06:37, 0.682s/it]: train_loss_raw=1.4504, running_loss=1.3481, LR=0.000100
[2025-08-26 01:24:07,223][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017936] [Batch 00660/01234] [00:07:30/00:06:31, 0.682s/it]: train_loss_raw=1.4304, running_loss=1.3486, LR=0.000100
[2025-08-26 01:24:12,395][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017944] [Batch 00668/01234] [00:07:35/00:06:25, 0.682s/it]: train_loss_raw=1.3423, running_loss=1.3529, LR=0.000100
[2025-08-26 01:24:17,625][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017952] [Batch 00676/01234] [00:07:40/00:06:20, 0.681s/it]: train_loss_raw=1.4348, running_loss=1.3536, LR=0.000100
[2025-08-26 01:24:23,275][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017960] [Batch 00684/01234] [00:07:46/00:06:14, 0.682s/it]: train_loss_raw=1.3512, running_loss=1.3510, LR=0.000100
[2025-08-26 01:24:28,677][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017968] [Batch 00692/01234] [00:07:51/00:06:09, 0.681s/it]: train_loss_raw=1.3527, running_loss=1.3511, LR=0.000100
[2025-08-26 01:24:34,074][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017976] [Batch 00700/01234] [00:07:56/00:06:03, 0.681s/it]: train_loss_raw=1.4238, running_loss=1.3519, LR=0.000100
[2025-08-26 01:24:39,138][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017984] [Batch 00708/01234] [00:08:02/00:05:58, 0.681s/it]: train_loss_raw=1.4655, running_loss=1.3536, LR=0.000100
[2025-08-26 01:24:44,927][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 017992] [Batch 00716/01234] [00:08:07/00:05:52, 0.681s/it]: train_loss_raw=1.3322, running_loss=1.3519, LR=0.000100
[2025-08-26 01:24:50,480][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018000] [Batch 00724/01234] [00:08:13/00:05:47, 0.681s/it]: train_loss_raw=1.3191, running_loss=1.3522, LR=0.000100
[2025-08-26 01:24:59,375][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018008] [Batch 00732/01234] [00:08:22/00:05:44, 0.686s/it]: train_loss_raw=1.4389, running_loss=1.3528, LR=0.000100
[2025-08-26 01:25:04,798][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018016] [Batch 00740/01234] [00:08:27/00:05:38, 0.686s/it]: train_loss_raw=1.3376, running_loss=1.3547, LR=0.000100
[2025-08-26 01:25:10,267][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018024] [Batch 00748/01234] [00:08:33/00:05:33, 0.686s/it]: train_loss_raw=1.2601, running_loss=1.3546, LR=0.000100
[2025-08-26 01:25:15,565][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018032] [Batch 00756/01234] [00:08:38/00:05:27, 0.686s/it]: train_loss_raw=1.4088, running_loss=1.3540, LR=0.000100
[2025-08-26 01:25:21,005][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018040] [Batch 00764/01234] [00:08:43/00:05:22, 0.686s/it]: train_loss_raw=1.3279, running_loss=1.3539, LR=0.000100
[2025-08-26 01:25:26,734][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018048] [Batch 00772/01234] [00:08:49/00:05:16, 0.686s/it]: train_loss_raw=1.3226, running_loss=1.3560, LR=0.000100
[2025-08-26 01:25:31,847][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018056] [Batch 00780/01234] [00:08:54/00:05:11, 0.686s/it]: train_loss_raw=1.3281, running_loss=1.3553, LR=0.000100
[2025-08-26 01:25:37,018][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018064] [Batch 00788/01234] [00:08:59/00:05:05, 0.685s/it]: train_loss_raw=1.3360, running_loss=1.3547, LR=0.000100
[2025-08-26 01:25:42,512][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018072] [Batch 00796/01234] [00:09:05/00:05:00, 0.685s/it]: train_loss_raw=1.3599, running_loss=1.3547, LR=0.000100
[2025-08-26 01:25:47,834][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018080] [Batch 00804/01234] [00:09:10/00:04:54, 0.685s/it]: train_loss_raw=1.3571, running_loss=1.3573, LR=0.000100
[2025-08-26 01:25:53,001][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018088] [Batch 00812/01234] [00:09:15/00:04:48, 0.685s/it]: train_loss_raw=1.3771, running_loss=1.3573, LR=0.000100
[2025-08-26 01:25:58,141][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018096] [Batch 00820/01234] [00:09:21/00:04:43, 0.684s/it]: train_loss_raw=1.4228, running_loss=1.3581, LR=0.000100
[2025-08-26 01:26:03,189][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018104] [Batch 00828/01234] [00:09:26/00:04:37, 0.684s/it]: train_loss_raw=1.3230, running_loss=1.3561, LR=0.000100
[2025-08-26 01:26:08,275][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018112] [Batch 00836/01234] [00:09:31/00:04:31, 0.683s/it]: train_loss_raw=1.3309, running_loss=1.3567, LR=0.000100
[2025-08-26 01:26:13,803][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018120] [Batch 00844/01234] [00:09:36/00:04:26, 0.683s/it]: train_loss_raw=1.4021, running_loss=1.3576, LR=0.000100
[2025-08-26 01:26:18,851][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018128] [Batch 00852/01234] [00:09:41/00:04:20, 0.683s/it]: train_loss_raw=1.3951, running_loss=1.3568, LR=0.000100
[2025-08-26 01:26:23,893][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018136] [Batch 00860/01234] [00:09:46/00:04:15, 0.682s/it]: train_loss_raw=1.4334, running_loss=1.3581, LR=0.000100
[2025-08-26 01:26:29,036][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018144] [Batch 00868/01234] [00:09:51/00:04:09, 0.682s/it]: train_loss_raw=1.4255, running_loss=1.3581, LR=0.000100
[2025-08-26 01:26:34,197][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018152] [Batch 00876/01234] [00:09:57/00:04:04, 0.682s/it]: train_loss_raw=1.3689, running_loss=1.3584, LR=0.000100
[2025-08-26 01:26:39,423][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018160] [Batch 00884/01234] [00:10:02/00:03:58, 0.681s/it]: train_loss_raw=1.3807, running_loss=1.3595, LR=0.000100
[2025-08-26 01:26:44,973][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018168] [Batch 00892/01234] [00:10:07/00:03:53, 0.681s/it]: train_loss_raw=1.3777, running_loss=1.3609, LR=0.000100
[2025-08-26 01:26:50,043][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018176] [Batch 00900/01234] [00:10:12/00:03:47, 0.681s/it]: train_loss_raw=1.3597, running_loss=1.3649, LR=0.000100
[2025-08-26 01:26:55,104][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018184] [Batch 00908/01234] [00:10:18/00:03:41, 0.681s/it]: train_loss_raw=1.4189, running_loss=1.3630, LR=0.000100
[2025-08-26 01:27:00,341][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018192] [Batch 00916/01234] [00:10:23/00:03:36, 0.680s/it]: train_loss_raw=1.4028, running_loss=1.3618, LR=0.000100
[2025-08-26 01:27:06,068][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018200] [Batch 00924/01234] [00:10:28/00:03:31, 0.681s/it]: train_loss_raw=1.2718, running_loss=1.3619, LR=0.000100
[2025-08-26 01:27:11,115][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018208] [Batch 00932/01234] [00:10:34/00:03:25, 0.680s/it]: train_loss_raw=1.2977, running_loss=1.3598, LR=0.000100
[2025-08-26 01:27:16,166][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018216] [Batch 00940/01234] [00:10:39/00:03:19, 0.680s/it]: train_loss_raw=1.4082, running_loss=1.3603, LR=0.000100
[2025-08-26 01:27:21,203][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018224] [Batch 00948/01234] [00:10:44/00:03:14, 0.679s/it]: train_loss_raw=1.3079, running_loss=1.3609, LR=0.000100
[2025-08-26 01:27:26,718][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018232] [Batch 00956/01234] [00:10:49/00:03:08, 0.680s/it]: train_loss_raw=1.3587, running_loss=1.3625, LR=0.000100
[2025-08-26 01:27:31,777][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018240] [Batch 00964/01234] [00:10:54/00:03:03, 0.679s/it]: train_loss_raw=1.3097, running_loss=1.3619, LR=0.000100
[2025-08-26 01:27:37,251][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018248] [Batch 00972/01234] [00:11:00/00:02:57, 0.679s/it]: train_loss_raw=1.3286, running_loss=1.3597, LR=0.000100
[2025-08-26 01:27:42,297][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018256] [Batch 00980/01234] [00:11:05/00:02:52, 0.679s/it]: train_loss_raw=1.3827, running_loss=1.3597, LR=0.000100
[2025-08-26 01:27:47,348][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018264] [Batch 00988/01234] [00:11:10/00:02:46, 0.678s/it]: train_loss_raw=1.3940, running_loss=1.3601, LR=0.000100
[2025-08-26 01:27:52,717][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018272] [Batch 00996/01234] [00:11:15/00:02:41, 0.678s/it]: train_loss_raw=1.2815, running_loss=1.3574, LR=0.000100
[2025-08-26 01:27:58,063][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018280] [Batch 01004/01234] [00:11:20/00:02:36, 0.678s/it]: train_loss_raw=1.3306, running_loss=1.3564, LR=0.000100
[2025-08-26 01:28:03,438][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018288] [Batch 01012/01234] [00:11:26/00:02:30, 0.678s/it]: train_loss_raw=1.3029, running_loss=1.3584, LR=0.000100
[2025-08-26 01:28:09,099][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018296] [Batch 01020/01234] [00:11:32/00:02:25, 0.678s/it]: train_loss_raw=1.2409, running_loss=1.3538, LR=0.000100
[2025-08-26 01:28:14,121][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018304] [Batch 01028/01234] [00:11:37/00:02:19, 0.678s/it]: train_loss_raw=1.3624, running_loss=1.3547, LR=0.000100
[2025-08-26 01:28:19,150][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018312] [Batch 01036/01234] [00:11:42/00:02:14, 0.678s/it]: train_loss_raw=1.4156, running_loss=1.3567, LR=0.000100
[2025-08-26 01:28:24,617][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018320] [Batch 01044/01234] [00:11:47/00:02:08, 0.678s/it]: train_loss_raw=1.4052, running_loss=1.3586, LR=0.000100
[2025-08-26 01:28:29,785][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018328] [Batch 01052/01234] [00:11:52/00:02:03, 0.677s/it]: train_loss_raw=1.4016, running_loss=1.3607, LR=0.000100
[2025-08-26 01:28:34,844][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018336] [Batch 01060/01234] [00:11:57/00:01:57, 0.677s/it]: train_loss_raw=1.1833, running_loss=1.3609, LR=0.000100
[2025-08-26 01:28:39,901][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018344] [Batch 01068/01234] [00:12:02/00:01:52, 0.677s/it]: train_loss_raw=1.3228, running_loss=1.3592, LR=0.000100
[2025-08-26 01:28:44,996][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018352] [Batch 01076/01234] [00:12:07/00:01:46, 0.676s/it]: train_loss_raw=1.4114, running_loss=1.3613, LR=0.000100
[2025-08-26 01:28:50,469][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018360] [Batch 01084/01234] [00:12:13/00:01:41, 0.677s/it]: train_loss_raw=1.2368, running_loss=1.3607, LR=0.000100
[2025-08-26 01:28:55,531][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018368] [Batch 01092/01234] [00:12:18/00:01:36, 0.676s/it]: train_loss_raw=1.3784, running_loss=1.3598, LR=0.000100
[2025-08-26 01:29:01,302][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018376] [Batch 01100/01234] [00:12:24/00:01:30, 0.677s/it]: train_loss_raw=1.3591, running_loss=1.3602, LR=0.000100
[2025-08-26 01:29:06,661][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018384] [Batch 01108/01234] [00:12:29/00:01:25, 0.677s/it]: train_loss_raw=1.3130, running_loss=1.3617, LR=0.000100
[2025-08-26 01:29:11,680][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018392] [Batch 01116/01234] [00:12:34/00:01:19, 0.676s/it]: train_loss_raw=1.3521, running_loss=1.3606, LR=0.000100
[2025-08-26 01:29:16,845][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018400] [Batch 01124/01234] [00:12:39/00:01:14, 0.676s/it]: train_loss_raw=1.3631, running_loss=1.3570, LR=0.000100
[2025-08-26 01:29:21,886][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018408] [Batch 01132/01234] [00:12:44/00:01:08, 0.676s/it]: train_loss_raw=1.3979, running_loss=1.3593, LR=0.000100
[2025-08-26 01:29:27,338][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018416] [Batch 01140/01234] [00:12:50/00:01:03, 0.676s/it]: train_loss_raw=1.3477, running_loss=1.3560, LR=0.000100
[2025-08-26 01:29:32,931][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018424] [Batch 01148/01234] [00:12:55/00:00:58, 0.676s/it]: train_loss_raw=1.3925, running_loss=1.3547, LR=0.000100
[2025-08-26 01:29:38,369][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018432] [Batch 01156/01234] [00:13:01/00:00:52, 0.676s/it]: train_loss_raw=1.3626, running_loss=1.3554, LR=0.000100
[2025-08-26 01:29:43,453][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018440] [Batch 01164/01234] [00:13:06/00:00:47, 0.676s/it]: train_loss_raw=1.4118, running_loss=1.3575, LR=0.000100
[2025-08-26 01:29:48,687][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018448] [Batch 01172/01234] [00:13:11/00:00:41, 0.675s/it]: train_loss_raw=1.2992, running_loss=1.3565, LR=0.000100
[2025-08-26 01:29:54,369][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018456] [Batch 01180/01234] [00:13:17/00:00:36, 0.676s/it]: train_loss_raw=1.4259, running_loss=1.3549, LR=0.000100
[2025-08-26 01:29:59,604][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018464] [Batch 01188/01234] [00:13:22/00:00:31, 0.676s/it]: train_loss_raw=1.3363, running_loss=1.3546, LR=0.000100
[2025-08-26 01:30:05,202][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018472] [Batch 01196/01234] [00:13:28/00:00:25, 0.676s/it]: train_loss_raw=1.3722, running_loss=1.3551, LR=0.000100
[2025-08-26 01:30:10,379][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018480] [Batch 01204/01234] [00:13:33/00:00:20, 0.675s/it]: train_loss_raw=1.3560, running_loss=1.3541, LR=0.000100
[2025-08-26 01:30:15,589][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018488] [Batch 01212/01234] [00:13:38/00:00:14, 0.675s/it]: train_loss_raw=1.3690, running_loss=1.3568, LR=0.000100
[2025-08-26 01:30:21,295][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018496] [Batch 01220/01234] [00:13:44/00:00:09, 0.676s/it]: train_loss_raw=1.3130, running_loss=1.3559, LR=0.000100
[2025-08-26 01:30:26,436][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 018504] [Batch 01228/01234] [00:13:49/00:00:04, 0.675s/it]: train_loss_raw=1.2880, running_loss=1.3535, LR=0.000100
[2025-08-26 01:30:36,654][__main__][INFO] - [VALIDATION] [Epoch 14/29] Starting validation.
[2025-08-26 01:30:47,069][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 018511] [Batch 00007/00026] [00:00:10/00:00:23, 1.302s/it]
[2025-08-26 01:30:58,543][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 018511] [Batch 00015/00026] [00:00:21/00:00:13, 1.368s/it]
[2025-08-26 01:31:09,046][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 018511] [Batch 00023/00026] [00:00:32/00:00:02, 1.350s/it]
[2025-08-26 01:31:11,460][__main__][INFO] - [VALIDATION] [Epoch 14/29] train_loss=1.35284, valid_loss=1.53262
[2025-08-26 01:31:11,460][__main__][INFO] - [VALIDATION] [Epoch 14/29] Metrics:
[2025-08-26 01:31:11,460][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_er      0.642
[2025-08-26 01:31:11,460][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_prec    0.051
[2025-08-26 01:31:11,460][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_recall  0.052
[2025-08-26 01:31:11,460][__main__][INFO] - [VALIDATION] [Epoch 14/29] - pep_recall 0.012
[2025-08-26 01:31:11,462][__main__][INFO] - [TRAIN] [Epoch 14/29] Epoch complete, total time 03:40:20, remaining time 03:40:20, 00:14:41 per epoch
[2025-08-26 01:31:12,563][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018512] [Batch 00002/01234] [00:00:00/00:08:38, 0.421s/it]: train_loss_raw=1.3037, running_loss=1.2165, LR=0.000100
[2025-08-26 01:31:17,614][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018520] [Batch 00010/01234] [00:00:05/00:12:01, 0.589s/it]: train_loss_raw=1.3159, running_loss=1.2221, LR=0.000100
[2025-08-26 01:31:23,211][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018528] [Batch 00018/01234] [00:00:11/00:12:56, 0.638s/it]: train_loss_raw=1.3045, running_loss=1.2271, LR=0.000100
[2025-08-26 01:31:29,008][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018536] [Batch 00026/01234] [00:00:17/00:13:23, 0.665s/it]: train_loss_raw=1.2830, running_loss=1.2326, LR=0.000100
[2025-08-26 01:31:34,337][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018544] [Batch 00034/01234] [00:00:22/00:13:18, 0.665s/it]: train_loss_raw=1.4289, running_loss=1.2381, LR=0.000100
[2025-08-26 01:31:39,751][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018552] [Batch 00042/01234] [00:00:28/00:13:15, 0.667s/it]: train_loss_raw=1.2541, running_loss=1.2420, LR=0.000100
[2025-08-26 01:31:45,203][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018560] [Batch 00050/01234] [00:00:33/00:13:12, 0.670s/it]: train_loss_raw=1.2295, running_loss=1.2447, LR=0.000100
[2025-08-26 01:31:50,374][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018568] [Batch 00058/01234] [00:00:38/00:13:03, 0.666s/it]: train_loss_raw=1.3597, running_loss=1.2514, LR=0.000100
[2025-08-26 01:31:55,762][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018576] [Batch 00066/01234] [00:00:44/00:12:59, 0.667s/it]: train_loss_raw=1.2171, running_loss=1.2525, LR=0.000100
[2025-08-26 01:32:00,839][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018584] [Batch 00074/01234] [00:00:49/00:12:49, 0.664s/it]: train_loss_raw=1.3224, running_loss=1.2537, LR=0.000100
[2025-08-26 01:32:06,197][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018592] [Batch 00082/01234] [00:00:54/00:12:45, 0.664s/it]: train_loss_raw=1.2764, running_loss=1.2575, LR=0.000100
[2025-08-26 01:32:11,741][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018600] [Batch 00090/01234] [00:01:00/00:12:42, 0.667s/it]: train_loss_raw=1.3163, running_loss=1.2620, LR=0.000100
[2025-08-26 01:32:17,263][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018608] [Batch 00098/01234] [00:01:05/00:12:39, 0.669s/it]: train_loss_raw=1.3208, running_loss=1.2637, LR=0.000100
[2025-08-26 01:32:22,336][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018616] [Batch 00106/01234] [00:01:10/00:12:31, 0.666s/it]: train_loss_raw=1.1897, running_loss=1.2633, LR=0.000100
[2025-08-26 01:32:27,813][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018624] [Batch 00114/01234] [00:01:16/00:12:27, 0.667s/it]: train_loss_raw=1.2371, running_loss=1.2630, LR=0.000100
[2025-08-26 01:32:33,171][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018632] [Batch 00122/01234] [00:01:21/00:12:22, 0.668s/it]: train_loss_raw=1.2658, running_loss=1.2632, LR=0.000100
[2025-08-26 01:32:39,079][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018640] [Batch 00130/01234] [00:01:27/00:12:21, 0.672s/it]: train_loss_raw=1.1047, running_loss=1.2636, LR=0.000100
[2025-08-26 01:32:44,686][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018648] [Batch 00138/01234] [00:01:32/00:12:18, 0.674s/it]: train_loss_raw=1.2303, running_loss=1.2637, LR=0.000100
[2025-08-26 01:32:50,615][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018656] [Batch 00146/01234] [00:01:38/00:12:16, 0.677s/it]: train_loss_raw=1.2014, running_loss=1.2637, LR=0.000100
[2025-08-26 01:32:56,227][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018664] [Batch 00154/01234] [00:01:44/00:12:12, 0.679s/it]: train_loss_raw=1.2421, running_loss=1.2650, LR=0.000100
[2025-08-26 01:33:01,280][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018672] [Batch 00162/01234] [00:01:49/00:12:04, 0.676s/it]: train_loss_raw=1.2138, running_loss=1.2668, LR=0.000100
[2025-08-26 01:33:06,305][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018680] [Batch 00170/01234] [00:01:54/00:11:57, 0.674s/it]: train_loss_raw=1.2000, running_loss=1.2665, LR=0.000100
[2025-08-26 01:33:11,867][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018688] [Batch 00178/01234] [00:02:00/00:11:52, 0.675s/it]: train_loss_raw=1.2363, running_loss=1.2672, LR=0.000100
[2025-08-26 01:33:16,948][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018696] [Batch 00186/01234] [00:02:05/00:11:45, 0.673s/it]: train_loss_raw=1.2895, running_loss=1.2708, LR=0.000100
[2025-08-26 01:33:22,381][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018704] [Batch 00194/01234] [00:02:10/00:11:40, 0.674s/it]: train_loss_raw=1.2229, running_loss=1.2743, LR=0.000100
[2025-08-26 01:33:27,549][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018712] [Batch 00202/01234] [00:02:15/00:11:33, 0.672s/it]: train_loss_raw=1.2559, running_loss=1.2748, LR=0.000100
[2025-08-26 01:33:32,882][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018720] [Batch 00210/01234] [00:02:21/00:11:28, 0.672s/it]: train_loss_raw=1.3239, running_loss=1.2758, LR=0.000100
[2025-08-26 01:33:38,347][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018728] [Batch 00218/01234] [00:02:26/00:11:23, 0.673s/it]: train_loss_raw=1.2881, running_loss=1.2797, LR=0.000100
[2025-08-26 01:33:43,474][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018736] [Batch 00226/01234] [00:02:31/00:11:16, 0.671s/it]: train_loss_raw=1.2819, running_loss=1.2846, LR=0.000100
[2025-08-26 01:33:48,529][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018744] [Batch 00234/01234] [00:02:36/00:11:10, 0.670s/it]: train_loss_raw=1.2589, running_loss=1.2889, LR=0.000100
[2025-08-26 01:33:53,578][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018752] [Batch 00242/01234] [00:02:41/00:11:03, 0.669s/it]: train_loss_raw=1.2718, running_loss=1.2891, LR=0.000100
[2025-08-26 01:33:58,990][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018760] [Batch 00250/01234] [00:02:47/00:10:58, 0.669s/it]: train_loss_raw=1.3079, running_loss=1.2895, LR=0.000100
[2025-08-26 01:34:04,436][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018768] [Batch 00258/01234] [00:02:52/00:10:53, 0.669s/it]: train_loss_raw=1.4500, running_loss=1.2917, LR=0.000100
[2025-08-26 01:34:10,153][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018776] [Batch 00266/01234] [00:02:58/00:10:49, 0.671s/it]: train_loss_raw=1.2436, running_loss=1.2917, LR=0.000100
[2025-08-26 01:34:16,037][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018784] [Batch 00274/01234] [00:03:04/00:10:45, 0.673s/it]: train_loss_raw=1.3351, running_loss=1.2937, LR=0.000100
[2025-08-26 01:34:21,924][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018792] [Batch 00282/01234] [00:03:10/00:10:42, 0.674s/it]: train_loss_raw=1.3137, running_loss=1.2975, LR=0.000100
[2025-08-26 01:34:27,479][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018800] [Batch 00290/01234] [00:03:15/00:10:37, 0.675s/it]: train_loss_raw=1.3124, running_loss=1.2977, LR=0.000100
[2025-08-26 01:34:32,830][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018808] [Batch 00298/01234] [00:03:21/00:10:31, 0.675s/it]: train_loss_raw=1.3872, running_loss=1.2971, LR=0.000100
[2025-08-26 01:34:38,589][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018816] [Batch 00306/01234] [00:03:26/00:10:27, 0.676s/it]: train_loss_raw=1.2104, running_loss=1.2973, LR=0.000100
[2025-08-26 01:34:44,168][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018824] [Batch 00314/01234] [00:03:32/00:10:22, 0.677s/it]: train_loss_raw=1.2568, running_loss=1.2964, LR=0.000100
[2025-08-26 01:34:49,326][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018832] [Batch 00322/01234] [00:03:37/00:10:16, 0.676s/it]: train_loss_raw=1.2611, running_loss=1.2952, LR=0.000100
[2025-08-26 01:34:54,722][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018840] [Batch 00330/01234] [00:03:43/00:10:10, 0.676s/it]: train_loss_raw=1.2973, running_loss=1.2936, LR=0.000100
[2025-08-26 01:35:00,411][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018848] [Batch 00338/01234] [00:03:48/00:10:06, 0.677s/it]: train_loss_raw=1.3263, running_loss=1.2960, LR=0.000100
[2025-08-26 01:35:05,774][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018856] [Batch 00346/01234] [00:03:54/00:10:00, 0.676s/it]: train_loss_raw=1.3137, running_loss=1.2990, LR=0.000100
[2025-08-26 01:35:11,567][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018864] [Batch 00354/01234] [00:03:59/00:09:56, 0.678s/it]: train_loss_raw=1.3558, running_loss=1.2983, LR=0.000100
[2025-08-26 01:35:16,783][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018872] [Batch 00362/01234] [00:04:05/00:09:50, 0.677s/it]: train_loss_raw=1.3985, running_loss=1.2996, LR=0.000100
[2025-08-26 01:35:22,275][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018880] [Batch 00370/01234] [00:04:10/00:09:45, 0.677s/it]: train_loss_raw=1.3741, running_loss=1.2999, LR=0.000100
[2025-08-26 01:35:27,776][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018888] [Batch 00378/01234] [00:04:16/00:09:39, 0.677s/it]: train_loss_raw=1.3986, running_loss=1.2988, LR=0.000100
[2025-08-26 01:35:33,080][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018896] [Batch 00386/01234] [00:04:21/00:09:34, 0.677s/it]: train_loss_raw=1.2681, running_loss=1.2994, LR=0.000100
[2025-08-26 01:35:38,437][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018904] [Batch 00394/01234] [00:04:26/00:09:28, 0.677s/it]: train_loss_raw=1.3089, running_loss=1.3018, LR=0.000100
[2025-08-26 01:35:43,901][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018912] [Batch 00402/01234] [00:04:32/00:09:23, 0.677s/it]: train_loss_raw=1.1877, running_loss=1.3023, LR=0.000100
[2025-08-26 01:35:49,212][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018920] [Batch 00410/01234] [00:04:37/00:09:17, 0.677s/it]: train_loss_raw=1.2769, running_loss=1.3000, LR=0.000100
[2025-08-26 01:35:54,449][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018928] [Batch 00418/01234] [00:04:42/00:09:11, 0.676s/it]: train_loss_raw=1.3805, running_loss=1.3007, LR=0.000100
[2025-08-26 01:35:59,653][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018936] [Batch 00426/01234] [00:04:47/00:09:06, 0.676s/it]: train_loss_raw=1.2694, running_loss=1.3006, LR=0.000100
[2025-08-26 01:36:05,340][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018944] [Batch 00434/01234] [00:04:53/00:09:01, 0.677s/it]: train_loss_raw=1.2773, running_loss=1.3002, LR=0.000100
[2025-08-26 01:36:10,723][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018952] [Batch 00442/01234] [00:04:59/00:08:55, 0.676s/it]: train_loss_raw=1.2995, running_loss=1.2993, LR=0.000100
[2025-08-26 01:36:15,778][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018960] [Batch 00450/01234] [00:05:04/00:08:49, 0.676s/it]: train_loss_raw=1.3004, running_loss=1.2988, LR=0.000100
[2025-08-26 01:36:21,307][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018968] [Batch 00458/01234] [00:05:09/00:08:44, 0.676s/it]: train_loss_raw=1.2546, running_loss=1.2995, LR=0.000100
[2025-08-26 01:36:26,800][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018976] [Batch 00466/01234] [00:05:15/00:08:39, 0.676s/it]: train_loss_raw=1.3720, running_loss=1.3012, LR=0.000100
[2025-08-26 01:36:32,264][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018984] [Batch 00474/01234] [00:05:20/00:08:33, 0.676s/it]: train_loss_raw=1.4356, running_loss=1.3018, LR=0.000100
[2025-08-26 01:36:37,450][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 018992] [Batch 00482/01234] [00:05:25/00:08:28, 0.676s/it]: train_loss_raw=1.3058, running_loss=1.3033, LR=0.000100
[2025-08-26 01:36:42,638][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019000] [Batch 00490/01234] [00:05:30/00:08:22, 0.675s/it]: train_loss_raw=1.3197, running_loss=1.3035, LR=0.000100
[2025-08-26 01:36:47,819][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019008] [Batch 00498/01234] [00:05:36/00:08:16, 0.675s/it]: train_loss_raw=1.2222, running_loss=1.3018, LR=0.000100
[2025-08-26 01:36:53,000][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019016] [Batch 00506/01234] [00:05:41/00:08:11, 0.674s/it]: train_loss_raw=1.2309, running_loss=1.3011, LR=0.000100
[2025-08-26 01:36:58,196][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019024] [Batch 00514/01234] [00:05:46/00:08:05, 0.674s/it]: train_loss_raw=1.3111, running_loss=1.3010, LR=0.000100
[2025-08-26 01:37:03,350][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019032] [Batch 00522/01234] [00:05:51/00:07:59, 0.674s/it]: train_loss_raw=1.2616, running_loss=1.3026, LR=0.000100
[2025-08-26 01:37:08,861][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019040] [Batch 00530/01234] [00:05:57/00:07:54, 0.674s/it]: train_loss_raw=1.2795, running_loss=1.3004, LR=0.000100
[2025-08-26 01:37:14,705][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019048] [Batch 00538/01234] [00:06:02/00:07:49, 0.675s/it]: train_loss_raw=1.2631, running_loss=1.3004, LR=0.000100
[2025-08-26 01:37:20,169][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019056] [Batch 00546/01234] [00:06:08/00:07:44, 0.675s/it]: train_loss_raw=1.3298, running_loss=1.2984, LR=0.000100
[2025-08-26 01:37:25,617][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019064] [Batch 00554/01234] [00:06:13/00:07:38, 0.675s/it]: train_loss_raw=1.3504, running_loss=1.2991, LR=0.000100
[2025-08-26 01:37:30,813][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019072] [Batch 00562/01234] [00:06:19/00:07:33, 0.675s/it]: train_loss_raw=1.3276, running_loss=1.3001, LR=0.000100
[2025-08-26 01:37:36,565][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019080] [Batch 00570/01234] [00:06:24/00:07:28, 0.675s/it]: train_loss_raw=1.3666, running_loss=1.3012, LR=0.000100
[2025-08-26 01:37:42,074][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019088] [Batch 00578/01234] [00:06:30/00:07:23, 0.675s/it]: train_loss_raw=1.3564, running_loss=1.3030, LR=0.000100
[2025-08-26 01:37:47,498][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019096] [Batch 00586/01234] [00:06:35/00:07:17, 0.675s/it]: train_loss_raw=1.3755, running_loss=1.3019, LR=0.000100
[2025-08-26 01:37:52,973][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019104] [Batch 00594/01234] [00:06:41/00:07:12, 0.676s/it]: train_loss_raw=1.2570, running_loss=1.3028, LR=0.000100
[2025-08-26 01:37:58,728][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019112] [Batch 00602/01234] [00:06:47/00:07:07, 0.676s/it]: train_loss_raw=1.2521, running_loss=1.3030, LR=0.000100
[2025-08-26 01:38:04,105][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019120] [Batch 00610/01234] [00:06:52/00:07:01, 0.676s/it]: train_loss_raw=1.3409, running_loss=1.3055, LR=0.000100
[2025-08-26 01:38:09,627][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019128] [Batch 00618/01234] [00:06:57/00:06:56, 0.676s/it]: train_loss_raw=1.3915, running_loss=1.3065, LR=0.000100
[2025-08-26 01:38:15,001][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019136] [Batch 00626/01234] [00:07:03/00:06:51, 0.676s/it]: train_loss_raw=1.2425, running_loss=1.3063, LR=0.000100
[2025-08-26 01:38:20,885][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019144] [Batch 00634/01234] [00:07:09/00:06:46, 0.677s/it]: train_loss_raw=1.3419, running_loss=1.3063, LR=0.000100
[2025-08-26 01:38:25,913][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019152] [Batch 00642/01234] [00:07:14/00:06:40, 0.676s/it]: train_loss_raw=1.3340, running_loss=1.3061, LR=0.000100
[2025-08-26 01:38:31,231][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019160] [Batch 00650/01234] [00:07:19/00:06:34, 0.676s/it]: train_loss_raw=1.3082, running_loss=1.3048, LR=0.000100
[2025-08-26 01:38:36,329][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019168] [Batch 00658/01234] [00:07:24/00:06:29, 0.676s/it]: train_loss_raw=1.3171, running_loss=1.3060, LR=0.000100
[2025-08-26 01:38:41,911][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019176] [Batch 00666/01234] [00:07:30/00:06:23, 0.676s/it]: train_loss_raw=1.3535, running_loss=1.3089, LR=0.000100
[2025-08-26 01:38:47,014][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019184] [Batch 00674/01234] [00:07:35/00:06:18, 0.676s/it]: train_loss_raw=1.2402, running_loss=1.3083, LR=0.000100
[2025-08-26 01:38:52,076][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019192] [Batch 00682/01234] [00:07:40/00:06:12, 0.675s/it]: train_loss_raw=1.3321, running_loss=1.3072, LR=0.000100
[2025-08-26 01:38:57,579][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019200] [Batch 00690/01234] [00:07:45/00:06:07, 0.675s/it]: train_loss_raw=1.3393, running_loss=1.3119, LR=0.000100
[2025-08-26 01:39:03,155][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019208] [Batch 00698/01234] [00:07:51/00:06:02, 0.675s/it]: train_loss_raw=1.3008, running_loss=1.3094, LR=0.000100
[2025-08-26 01:39:08,229][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019216] [Batch 00706/01234] [00:07:56/00:05:56, 0.675s/it]: train_loss_raw=1.3076, running_loss=1.3129, LR=0.000100
[2025-08-26 01:39:13,331][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019224] [Batch 00714/01234] [00:08:01/00:05:50, 0.675s/it]: train_loss_raw=1.4210, running_loss=1.3139, LR=0.000100
[2025-08-26 01:39:18,460][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019232] [Batch 00722/01234] [00:08:06/00:05:45, 0.674s/it]: train_loss_raw=1.3448, running_loss=1.3133, LR=0.000100
[2025-08-26 01:39:24,166][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019240] [Batch 00730/01234] [00:08:12/00:05:39, 0.675s/it]: train_loss_raw=1.2015, running_loss=1.3087, LR=0.000100
[2025-08-26 01:39:29,256][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019248] [Batch 00738/01234] [00:08:17/00:05:34, 0.674s/it]: train_loss_raw=1.2241, running_loss=1.3090, LR=0.000100
[2025-08-26 01:39:34,523][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019256] [Batch 00746/01234] [00:08:22/00:05:28, 0.674s/it]: train_loss_raw=1.3033, running_loss=1.3092, LR=0.000100
[2025-08-26 01:39:40,539][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019264] [Batch 00754/01234] [00:08:28/00:05:23, 0.675s/it]: train_loss_raw=1.3152, running_loss=1.3078, LR=0.000100
[2025-08-26 01:39:46,011][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019272] [Batch 00762/01234] [00:08:34/00:05:18, 0.675s/it]: train_loss_raw=1.3714, running_loss=1.3070, LR=0.000100
[2025-08-26 01:39:51,445][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019280] [Batch 00770/01234] [00:08:39/00:05:13, 0.675s/it]: train_loss_raw=1.3951, running_loss=1.3056, LR=0.000100
[2025-08-26 01:39:57,008][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019288] [Batch 00778/01234] [00:08:45/00:05:07, 0.675s/it]: train_loss_raw=1.2959, running_loss=1.3088, LR=0.000100
[2025-08-26 01:40:02,073][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019296] [Batch 00786/01234] [00:08:50/00:05:02, 0.675s/it]: train_loss_raw=1.3063, running_loss=1.3089, LR=0.000100
[2025-08-26 01:40:07,702][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019304] [Batch 00794/01234] [00:08:55/00:04:57, 0.675s/it]: train_loss_raw=1.4073, running_loss=1.3101, LR=0.000100
[2025-08-26 01:40:13,170][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019312] [Batch 00802/01234] [00:09:01/00:04:51, 0.675s/it]: train_loss_raw=1.2533, running_loss=1.3081, LR=0.000100
[2025-08-26 01:40:18,238][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019320] [Batch 00810/01234] [00:09:06/00:04:46, 0.675s/it]: train_loss_raw=1.2579, running_loss=1.3068, LR=0.000100
[2025-08-26 01:40:23,707][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019328] [Batch 00818/01234] [00:09:11/00:04:40, 0.675s/it]: train_loss_raw=1.3097, running_loss=1.3083, LR=0.000100
[2025-08-26 01:40:29,221][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019336] [Batch 00826/01234] [00:09:17/00:04:35, 0.675s/it]: train_loss_raw=1.2967, running_loss=1.3093, LR=0.000100
[2025-08-26 01:40:34,573][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019344] [Batch 00834/01234] [00:09:22/00:04:29, 0.675s/it]: train_loss_raw=1.2414, running_loss=1.3083, LR=0.000100
[2025-08-26 01:40:39,627][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019352] [Batch 00842/01234] [00:09:27/00:04:24, 0.674s/it]: train_loss_raw=1.3677, running_loss=1.3088, LR=0.000100
[2025-08-26 01:40:44,755][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019360] [Batch 00850/01234] [00:09:33/00:04:18, 0.674s/it]: train_loss_raw=1.3016, running_loss=1.3101, LR=0.000100
[2025-08-26 01:40:49,922][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019368] [Batch 00858/01234] [00:09:38/00:04:13, 0.674s/it]: train_loss_raw=1.2943, running_loss=1.3104, LR=0.000100
[2025-08-26 01:40:55,519][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019376] [Batch 00866/01234] [00:09:43/00:04:08, 0.674s/it]: train_loss_raw=1.2335, running_loss=1.3065, LR=0.000100
[2025-08-26 01:41:00,596][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019384] [Batch 00874/01234] [00:09:48/00:04:02, 0.674s/it]: train_loss_raw=1.3141, running_loss=1.3067, LR=0.000100
[2025-08-26 01:41:06,028][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019392] [Batch 00882/01234] [00:09:54/00:03:57, 0.674s/it]: train_loss_raw=1.2780, running_loss=1.3054, LR=0.000100
[2025-08-26 01:41:11,128][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019400] [Batch 00890/01234] [00:09:59/00:03:51, 0.673s/it]: train_loss_raw=1.2800, running_loss=1.3044, LR=0.000100
[2025-08-26 01:41:16,591][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019408] [Batch 00898/01234] [00:10:04/00:03:46, 0.674s/it]: train_loss_raw=1.4177, running_loss=1.3062, LR=0.000100
[2025-08-26 01:41:22,325][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019416] [Batch 00906/01234] [00:10:10/00:03:41, 0.674s/it]: train_loss_raw=1.3555, running_loss=1.3075, LR=0.000100
[2025-08-26 01:41:27,636][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019424] [Batch 00914/01234] [00:10:15/00:03:35, 0.674s/it]: train_loss_raw=1.2759, running_loss=1.3060, LR=0.000100
[2025-08-26 01:41:33,092][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019432] [Batch 00922/01234] [00:10:21/00:03:30, 0.674s/it]: train_loss_raw=1.3420, running_loss=1.3073, LR=0.000100
[2025-08-26 01:41:38,542][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019440] [Batch 00930/01234] [00:10:26/00:03:24, 0.674s/it]: train_loss_raw=1.3293, running_loss=1.3080, LR=0.000100
[2025-08-26 01:41:43,610][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019448] [Batch 00938/01234] [00:10:31/00:03:19, 0.674s/it]: train_loss_raw=1.2189, running_loss=1.3082, LR=0.000100
[2025-08-26 01:41:48,738][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019456] [Batch 00946/01234] [00:10:37/00:03:13, 0.673s/it]: train_loss_raw=1.2245, running_loss=1.3075, LR=0.000100
[2025-08-26 01:41:53,800][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019464] [Batch 00954/01234] [00:10:42/00:03:08, 0.673s/it]: train_loss_raw=1.2670, running_loss=1.3060, LR=0.000100
[2025-08-26 01:41:58,894][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019472] [Batch 00962/01234] [00:10:47/00:03:02, 0.673s/it]: train_loss_raw=1.3309, running_loss=1.3060, LR=0.000100
[2025-08-26 01:42:04,085][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019480] [Batch 00970/01234] [00:10:52/00:02:57, 0.673s/it]: train_loss_raw=1.4263, running_loss=1.3068, LR=0.000100
[2025-08-26 01:42:09,575][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019488] [Batch 00978/01234] [00:10:57/00:02:52, 0.673s/it]: train_loss_raw=1.3750, running_loss=1.3081, LR=0.000100
[2025-08-26 01:42:14,708][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019496] [Batch 00986/01234] [00:11:02/00:02:46, 0.672s/it]: train_loss_raw=1.3419, running_loss=1.3089, LR=0.000100
[2025-08-26 01:42:19,865][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019504] [Batch 00994/01234] [00:11:08/00:02:41, 0.672s/it]: train_loss_raw=1.3608, running_loss=1.3100, LR=0.000100
[2025-08-26 01:42:25,755][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019512] [Batch 01002/01234] [00:11:14/00:02:36, 0.673s/it]: train_loss_raw=1.4264, running_loss=1.3108, LR=0.000100
[2025-08-26 01:42:31,500][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019520] [Batch 01010/01234] [00:11:19/00:02:30, 0.673s/it]: train_loss_raw=1.3336, running_loss=1.3143, LR=0.000100
[2025-08-26 01:42:36,899][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019528] [Batch 01018/01234] [00:11:25/00:02:25, 0.673s/it]: train_loss_raw=1.2932, running_loss=1.3145, LR=0.000100
[2025-08-26 01:42:42,170][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019536] [Batch 01026/01234] [00:11:30/00:02:19, 0.673s/it]: train_loss_raw=1.2244, running_loss=1.3131, LR=0.000100
[2025-08-26 01:42:47,248][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019544] [Batch 01034/01234] [00:11:35/00:02:14, 0.673s/it]: train_loss_raw=1.2848, running_loss=1.3146, LR=0.000100
[2025-08-26 01:42:52,306][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019552] [Batch 01042/01234] [00:11:40/00:02:09, 0.672s/it]: train_loss_raw=1.3123, running_loss=1.3157, LR=0.000100
[2025-08-26 01:42:57,589][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019560] [Batch 01050/01234] [00:11:45/00:02:03, 0.672s/it]: train_loss_raw=1.3192, running_loss=1.3137, LR=0.000100
[2025-08-26 01:43:03,311][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019568] [Batch 01058/01234] [00:11:51/00:01:58, 0.673s/it]: train_loss_raw=1.2728, running_loss=1.3135, LR=0.000100
[2025-08-26 01:43:08,513][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019576] [Batch 01066/01234] [00:11:56/00:01:52, 0.672s/it]: train_loss_raw=1.3366, running_loss=1.3135, LR=0.000100
[2025-08-26 01:43:13,598][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019584] [Batch 01074/01234] [00:12:01/00:01:47, 0.672s/it]: train_loss_raw=1.2949, running_loss=1.3131, LR=0.000100
[2025-08-26 01:43:18,925][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019592] [Batch 01082/01234] [00:12:07/00:01:42, 0.672s/it]: train_loss_raw=1.2996, running_loss=1.3129, LR=0.000100
[2025-08-26 01:43:24,291][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019600] [Batch 01090/01234] [00:12:12/00:01:36, 0.672s/it]: train_loss_raw=1.2480, running_loss=1.3139, LR=0.000100
[2025-08-26 01:43:29,386][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019608] [Batch 01098/01234] [00:12:17/00:01:31, 0.672s/it]: train_loss_raw=1.3697, running_loss=1.3123, LR=0.000100
[2025-08-26 01:43:34,482][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019616] [Batch 01106/01234] [00:12:22/00:01:25, 0.672s/it]: train_loss_raw=1.2470, running_loss=1.3117, LR=0.000100
[2025-08-26 01:43:39,669][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019624] [Batch 01114/01234] [00:12:27/00:01:20, 0.671s/it]: train_loss_raw=1.3667, running_loss=1.3125, LR=0.000100
[2025-08-26 01:43:45,270][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019632] [Batch 01122/01234] [00:12:33/00:01:15, 0.672s/it]: train_loss_raw=1.3015, running_loss=1.3137, LR=0.000100
[2025-08-26 01:43:50,836][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019640] [Batch 01130/01234] [00:12:39/00:01:09, 0.672s/it]: train_loss_raw=1.3566, running_loss=1.3154, LR=0.000100
[2025-08-26 01:43:56,426][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019648] [Batch 01138/01234] [00:12:44/00:01:04, 0.672s/it]: train_loss_raw=1.3673, running_loss=1.3156, LR=0.000100
[2025-08-26 01:44:01,949][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019656] [Batch 01146/01234] [00:12:50/00:00:59, 0.672s/it]: train_loss_raw=1.3174, running_loss=1.3186, LR=0.000100
[2025-08-26 01:44:07,017][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019664] [Batch 01154/01234] [00:12:55/00:00:53, 0.672s/it]: train_loss_raw=1.3550, running_loss=1.3180, LR=0.000100
[2025-08-26 01:44:12,099][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019672] [Batch 01162/01234] [00:13:00/00:00:48, 0.672s/it]: train_loss_raw=1.3999, running_loss=1.3195, LR=0.000100
[2025-08-26 01:44:17,163][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019680] [Batch 01170/01234] [00:13:05/00:00:42, 0.671s/it]: train_loss_raw=1.3555, running_loss=1.3210, LR=0.000100
[2025-08-26 01:44:22,460][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019688] [Batch 01178/01234] [00:13:10/00:00:37, 0.671s/it]: train_loss_raw=1.4160, running_loss=1.3224, LR=0.000100
[2025-08-26 01:44:28,204][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019696] [Batch 01186/01234] [00:13:16/00:00:32, 0.672s/it]: train_loss_raw=1.3988, running_loss=1.3236, LR=0.000100
[2025-08-26 01:44:33,626][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019704] [Batch 01194/01234] [00:13:21/00:00:26, 0.672s/it]: train_loss_raw=1.4015, running_loss=1.3266, LR=0.000100
[2025-08-26 01:44:39,160][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019712] [Batch 01202/01234] [00:13:27/00:00:21, 0.672s/it]: train_loss_raw=1.3165, running_loss=1.3247, LR=0.000100
[2025-08-26 01:44:44,348][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019720] [Batch 01210/01234] [00:13:32/00:00:16, 0.672s/it]: train_loss_raw=1.3798, running_loss=1.3245, LR=0.000100
[2025-08-26 01:44:49,505][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019728] [Batch 01218/01234] [00:13:37/00:00:10, 0.671s/it]: train_loss_raw=1.3020, running_loss=1.3227, LR=0.000100
[2025-08-26 01:44:54,825][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019736] [Batch 01226/01234] [00:13:43/00:00:05, 0.671s/it]: train_loss_raw=1.3761, running_loss=1.3216, LR=0.000100
[2025-08-26 01:45:04,924][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 019744] [Batch 01234/01234] [00:13:53/00:00:00, 0.675s/it]: train_loss_raw=1.2742, running_loss=1.3210, LR=0.000100
[2025-08-26 01:45:05,378][__main__][INFO] - [VALIDATION] [Epoch 15/29] Starting validation.
[2025-08-26 01:45:15,458][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 019745] [Batch 00007/00026] [00:00:10/00:00:22, 1.260s/it]
[2025-08-26 01:45:25,662][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 019745] [Batch 00015/00026] [00:00:20/00:00:12, 1.268s/it]
[2025-08-26 01:45:35,877][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 019745] [Batch 00023/00026] [00:00:30/00:00:02, 1.271s/it]
[2025-08-26 01:45:38,124][__main__][INFO] - [VALIDATION] [Epoch 15/29] train_loss=1.32095, valid_loss=1.53264
[2025-08-26 01:45:38,125][__main__][INFO] - [VALIDATION] [Epoch 15/29] Metrics:
[2025-08-26 01:45:38,125][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_er      0.636
[2025-08-26 01:45:38,125][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_prec    0.054
[2025-08-26 01:45:38,125][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_recall  0.056
[2025-08-26 01:45:38,125][__main__][INFO] - [VALIDATION] [Epoch 15/29] - pep_recall 0.011
[2025-08-26 01:45:38,127][__main__][INFO] - [TRAIN] [Epoch 15/29] Epoch complete, total time 03:54:47, remaining time 03:25:26, 00:14:40 per epoch
[2025-08-26 01:45:42,863][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019752] [Batch 00008/01234] [00:00:04/00:11:45, 0.575s/it]: train_loss_raw=1.2320, running_loss=1.2055, LR=0.000100
[2025-08-26 01:45:48,173][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019760] [Batch 00016/01234] [00:00:09/00:12:34, 0.620s/it]: train_loss_raw=1.2411, running_loss=1.2069, LR=0.000100
[2025-08-26 01:45:53,412][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019768] [Batch 00024/01234] [00:00:15/00:12:43, 0.631s/it]: train_loss_raw=1.2956, running_loss=1.2085, LR=0.000100
[2025-08-26 01:45:58,486][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019776] [Batch 00032/01234] [00:00:20/00:12:39, 0.632s/it]: train_loss_raw=1.2674, running_loss=1.2125, LR=0.000100
[2025-08-26 01:46:03,824][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019784] [Batch 00040/01234] [00:00:25/00:12:43, 0.639s/it]: train_loss_raw=1.2168, running_loss=1.2155, LR=0.000100
[2025-08-26 01:46:08,897][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019792] [Batch 00048/01234] [00:00:30/00:12:37, 0.638s/it]: train_loss_raw=1.2066, running_loss=1.2168, LR=0.000100
[2025-08-26 01:46:14,233][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019800] [Batch 00056/01234] [00:00:35/00:12:36, 0.642s/it]: train_loss_raw=1.3049, running_loss=1.2191, LR=0.000100
[2025-08-26 01:46:19,397][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019808] [Batch 00064/01234] [00:00:41/00:12:32, 0.643s/it]: train_loss_raw=1.2280, running_loss=1.2220, LR=0.000100
[2025-08-26 01:46:24,460][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019816] [Batch 00072/01234] [00:00:46/00:12:25, 0.642s/it]: train_loss_raw=1.2110, running_loss=1.2211, LR=0.000100
[2025-08-26 01:46:29,899][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019824] [Batch 00080/01234] [00:00:51/00:12:24, 0.646s/it]: train_loss_raw=1.2158, running_loss=1.2229, LR=0.000100
[2025-08-26 01:46:35,474][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019832] [Batch 00088/01234] [00:00:57/00:12:25, 0.650s/it]: train_loss_raw=1.1928, running_loss=1.2256, LR=0.000100
[2025-08-26 01:46:40,879][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019840] [Batch 00096/01234] [00:01:02/00:12:22, 0.652s/it]: train_loss_raw=1.2247, running_loss=1.2275, LR=0.000100
[2025-08-26 01:46:46,131][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019848] [Batch 00104/01234] [00:01:07/00:12:17, 0.653s/it]: train_loss_raw=1.2216, running_loss=1.2284, LR=0.000100
[2025-08-26 01:46:51,590][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019856] [Batch 00112/01234] [00:01:13/00:12:14, 0.655s/it]: train_loss_raw=1.3190, running_loss=1.2324, LR=0.000100
[2025-08-26 01:46:57,482][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019864] [Batch 00120/01234] [00:01:19/00:12:15, 0.660s/it]: train_loss_raw=1.2356, running_loss=1.2353, LR=0.000100
[2025-08-26 01:47:03,194][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019872] [Batch 00128/01234] [00:01:24/00:12:13, 0.664s/it]: train_loss_raw=1.2610, running_loss=1.2366, LR=0.000100
[2025-08-26 01:47:09,102][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019880] [Batch 00136/01234] [00:01:30/00:12:13, 0.668s/it]: train_loss_raw=1.2749, running_loss=1.2356, LR=0.000100
[2025-08-26 01:47:14,826][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019888] [Batch 00144/01234] [00:01:36/00:12:10, 0.671s/it]: train_loss_raw=1.3347, running_loss=1.2358, LR=0.000100
[2025-08-26 01:47:20,090][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019896] [Batch 00152/01234] [00:01:41/00:12:04, 0.670s/it]: train_loss_raw=1.2627, running_loss=1.2346, LR=0.000100
[2025-08-26 01:47:25,744][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019904] [Batch 00160/01234] [00:01:47/00:12:01, 0.672s/it]: train_loss_raw=1.3138, running_loss=1.2355, LR=0.000100
[2025-08-26 01:47:30,909][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019912] [Batch 00168/01234] [00:01:52/00:11:54, 0.671s/it]: train_loss_raw=1.1958, running_loss=1.2379, LR=0.000100
[2025-08-26 01:47:35,966][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019920] [Batch 00176/01234] [00:01:57/00:11:47, 0.669s/it]: train_loss_raw=1.3275, running_loss=1.2390, LR=0.000100
[2025-08-26 01:47:41,035][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019928] [Batch 00184/01234] [00:02:02/00:11:40, 0.667s/it]: train_loss_raw=1.2490, running_loss=1.2415, LR=0.000100
[2025-08-26 01:47:46,418][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019936] [Batch 00192/01234] [00:02:08/00:11:35, 0.667s/it]: train_loss_raw=1.2005, running_loss=1.2414, LR=0.000100
[2025-08-26 01:47:51,944][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019944] [Batch 00200/01234] [00:02:13/00:11:31, 0.668s/it]: train_loss_raw=1.1773, running_loss=1.2409, LR=0.000100
[2025-08-26 01:47:57,084][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019952] [Batch 00208/01234] [00:02:18/00:11:24, 0.667s/it]: train_loss_raw=1.2743, running_loss=1.2438, LR=0.000100
[2025-08-26 01:48:02,404][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019960] [Batch 00216/01234] [00:02:24/00:11:19, 0.667s/it]: train_loss_raw=1.2524, running_loss=1.2442, LR=0.000100
[2025-08-26 01:48:08,140][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019968] [Batch 00224/01234] [00:02:29/00:11:15, 0.669s/it]: train_loss_raw=1.1561, running_loss=1.2448, LR=0.000100
[2025-08-26 01:48:13,800][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019976] [Batch 00232/01234] [00:02:35/00:11:11, 0.670s/it]: train_loss_raw=1.1677, running_loss=1.2453, LR=0.000100
[2025-08-26 01:48:19,059][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019984] [Batch 00240/01234] [00:02:40/00:11:05, 0.670s/it]: train_loss_raw=1.3250, running_loss=1.2465, LR=0.000100
[2025-08-26 01:48:24,242][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 019992] [Batch 00248/01234] [00:02:45/00:10:59, 0.669s/it]: train_loss_raw=1.2756, running_loss=1.2468, LR=0.000100
[2025-08-26 01:48:29,556][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020000] [Batch 00256/01234] [00:02:51/00:10:54, 0.669s/it]: train_loss_raw=1.2937, running_loss=1.2498, LR=0.000100
[2025-08-26 01:48:38,257][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020008] [Batch 00264/01234] [00:02:59/00:11:01, 0.682s/it]: train_loss_raw=1.2564, running_loss=1.2506, LR=0.000100
[2025-08-26 01:48:43,340][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020016] [Batch 00272/01234] [00:03:05/00:10:54, 0.680s/it]: train_loss_raw=1.2522, running_loss=1.2507, LR=0.000100
[2025-08-26 01:48:48,843][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020024] [Batch 00280/01234] [00:03:10/00:10:49, 0.681s/it]: train_loss_raw=1.1877, running_loss=1.2506, LR=0.000100
[2025-08-26 01:48:53,931][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020032] [Batch 00288/01234] [00:03:15/00:10:42, 0.679s/it]: train_loss_raw=1.2747, running_loss=1.2518, LR=0.000100
[2025-08-26 01:48:59,028][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020040] [Batch 00296/01234] [00:03:20/00:10:36, 0.678s/it]: train_loss_raw=1.2682, running_loss=1.2526, LR=0.000100
[2025-08-26 01:49:04,101][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020048] [Batch 00304/01234] [00:03:25/00:10:29, 0.677s/it]: train_loss_raw=1.2605, running_loss=1.2537, LR=0.000100
[2025-08-26 01:49:09,188][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020056] [Batch 00312/01234] [00:03:30/00:10:23, 0.676s/it]: train_loss_raw=1.2120, running_loss=1.2536, LR=0.000100
[2025-08-26 01:49:14,446][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020064] [Batch 00320/01234] [00:03:36/00:10:17, 0.676s/it]: train_loss_raw=1.2415, running_loss=1.2550, LR=0.000100
[2025-08-26 01:49:19,787][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020072] [Batch 00328/01234] [00:03:41/00:10:11, 0.675s/it]: train_loss_raw=1.2228, running_loss=1.2563, LR=0.000100
[2025-08-26 01:49:25,058][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020080] [Batch 00336/01234] [00:03:46/00:10:06, 0.675s/it]: train_loss_raw=1.2465, running_loss=1.2567, LR=0.000100
[2025-08-26 01:49:30,833][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020088] [Batch 00344/01234] [00:03:52/00:10:01, 0.676s/it]: train_loss_raw=1.1877, running_loss=1.2542, LR=0.000100
[2025-08-26 01:49:36,960][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020096] [Batch 00352/01234] [00:03:58/00:09:58, 0.678s/it]: train_loss_raw=1.1880, running_loss=1.2546, LR=0.000100
[2025-08-26 01:49:42,643][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020104] [Batch 00360/01234] [00:04:04/00:09:53, 0.679s/it]: train_loss_raw=1.2674, running_loss=1.2533, LR=0.000100
[2025-08-26 01:49:48,579][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020112] [Batch 00368/01234] [00:04:10/00:09:49, 0.680s/it]: train_loss_raw=1.2645, running_loss=1.2559, LR=0.000100
[2025-08-26 01:49:54,018][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020120] [Batch 00376/01234] [00:04:15/00:09:43, 0.680s/it]: train_loss_raw=1.3073, running_loss=1.2572, LR=0.000100
[2025-08-26 01:49:59,108][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020128] [Batch 00384/01234] [00:04:20/00:09:37, 0.679s/it]: train_loss_raw=1.2175, running_loss=1.2577, LR=0.000100
[2025-08-26 01:50:04,194][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020136] [Batch 00392/01234] [00:04:25/00:09:31, 0.678s/it]: train_loss_raw=1.1453, running_loss=1.2564, LR=0.000100
[2025-08-26 01:50:09,765][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020144] [Batch 00400/01234] [00:04:31/00:09:26, 0.679s/it]: train_loss_raw=1.2681, running_loss=1.2559, LR=0.000100
[2025-08-26 01:50:14,988][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020152] [Batch 00408/01234] [00:04:36/00:09:20, 0.678s/it]: train_loss_raw=1.2790, running_loss=1.2557, LR=0.000100
[2025-08-26 01:50:20,034][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020160] [Batch 00416/01234] [00:04:41/00:09:14, 0.677s/it]: train_loss_raw=1.2322, running_loss=1.2567, LR=0.000100
[2025-08-26 01:50:25,748][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020168] [Batch 00424/01234] [00:04:47/00:09:09, 0.678s/it]: train_loss_raw=1.2637, running_loss=1.2598, LR=0.000100
[2025-08-26 01:50:30,936][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020176] [Batch 00432/01234] [00:04:52/00:09:03, 0.677s/it]: train_loss_raw=1.2969, running_loss=1.2586, LR=0.000100
[2025-08-26 01:50:36,190][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020184] [Batch 00440/01234] [00:04:57/00:08:57, 0.677s/it]: train_loss_raw=1.2608, running_loss=1.2593, LR=0.000100
[2025-08-26 01:50:41,331][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020192] [Batch 00448/01234] [00:05:03/00:08:51, 0.677s/it]: train_loss_raw=1.1590, running_loss=1.2591, LR=0.000100
[2025-08-26 01:50:46,858][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020200] [Batch 00456/01234] [00:05:08/00:08:46, 0.677s/it]: train_loss_raw=1.2076, running_loss=1.2584, LR=0.000100
[2025-08-26 01:50:52,200][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020208] [Batch 00464/01234] [00:05:13/00:08:40, 0.677s/it]: train_loss_raw=1.2866, running_loss=1.2594, LR=0.000100
[2025-08-26 01:50:57,991][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020216] [Batch 00472/01234] [00:05:19/00:08:36, 0.677s/it]: train_loss_raw=1.3078, running_loss=1.2599, LR=0.000100
[2025-08-26 01:51:03,947][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020224] [Batch 00480/01234] [00:05:25/00:08:31, 0.679s/it]: train_loss_raw=1.2369, running_loss=1.2576, LR=0.000100
[2025-08-26 01:51:09,117][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020232] [Batch 00488/01234] [00:05:30/00:08:25, 0.678s/it]: train_loss_raw=1.3653, running_loss=1.2602, LR=0.000100
[2025-08-26 01:51:14,286][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020240] [Batch 00496/01234] [00:05:36/00:08:19, 0.677s/it]: train_loss_raw=1.1593, running_loss=1.2582, LR=0.000100
[2025-08-26 01:51:19,912][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020248] [Batch 00504/01234] [00:05:41/00:08:14, 0.678s/it]: train_loss_raw=1.2124, running_loss=1.2556, LR=0.000100
[2025-08-26 01:51:25,004][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020256] [Batch 00512/01234] [00:05:46/00:08:08, 0.677s/it]: train_loss_raw=1.2546, running_loss=1.2561, LR=0.000100
[2025-08-26 01:51:30,531][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020264] [Batch 00520/01234] [00:05:52/00:08:03, 0.677s/it]: train_loss_raw=1.2864, running_loss=1.2577, LR=0.000100
[2025-08-26 01:51:35,620][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020272] [Batch 00528/01234] [00:05:57/00:07:57, 0.677s/it]: train_loss_raw=1.2009, running_loss=1.2556, LR=0.000100
[2025-08-26 01:51:41,080][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020280] [Batch 00536/01234] [00:06:02/00:07:52, 0.677s/it]: train_loss_raw=1.3107, running_loss=1.2582, LR=0.000100
[2025-08-26 01:51:46,527][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020288] [Batch 00544/01234] [00:06:08/00:07:47, 0.677s/it]: train_loss_raw=1.3277, running_loss=1.2599, LR=0.000100
[2025-08-26 01:51:51,833][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020296] [Batch 00552/01234] [00:06:13/00:07:41, 0.677s/it]: train_loss_raw=1.3069, running_loss=1.2614, LR=0.000100
[2025-08-26 01:51:56,908][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020304] [Batch 00560/01234] [00:06:18/00:07:35, 0.676s/it]: train_loss_raw=1.2757, running_loss=1.2613, LR=0.000100
[2025-08-26 01:52:02,626][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020312] [Batch 00568/01234] [00:06:24/00:07:30, 0.677s/it]: train_loss_raw=1.3277, running_loss=1.2606, LR=0.000100
[2025-08-26 01:52:07,948][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020320] [Batch 00576/01234] [00:06:29/00:07:25, 0.677s/it]: train_loss_raw=1.2890, running_loss=1.2597, LR=0.000100
[2025-08-26 01:52:13,160][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020328] [Batch 00584/01234] [00:06:34/00:07:19, 0.676s/it]: train_loss_raw=1.1598, running_loss=1.2571, LR=0.000100
[2025-08-26 01:52:18,329][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020336] [Batch 00592/01234] [00:06:40/00:07:13, 0.676s/it]: train_loss_raw=1.2493, running_loss=1.2577, LR=0.000100
[2025-08-26 01:52:23,884][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020344] [Batch 00600/01234] [00:06:45/00:07:08, 0.676s/it]: train_loss_raw=1.3557, running_loss=1.2589, LR=0.000100
[2025-08-26 01:52:29,639][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020352] [Batch 00608/01234] [00:06:51/00:07:03, 0.677s/it]: train_loss_raw=1.2482, running_loss=1.2597, LR=0.000100
[2025-08-26 01:52:35,408][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020360] [Batch 00616/01234] [00:06:57/00:06:58, 0.677s/it]: train_loss_raw=1.2126, running_loss=1.2605, LR=0.000100
[2025-08-26 01:52:41,013][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020368] [Batch 00624/01234] [00:07:02/00:06:53, 0.677s/it]: train_loss_raw=1.2285, running_loss=1.2598, LR=0.000100
[2025-08-26 01:52:46,800][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020376] [Batch 00632/01234] [00:07:08/00:06:48, 0.678s/it]: train_loss_raw=1.1920, running_loss=1.2573, LR=0.000100
[2025-08-26 01:52:51,888][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020384] [Batch 00640/01234] [00:07:13/00:06:42, 0.678s/it]: train_loss_raw=1.3026, running_loss=1.2593, LR=0.000100
[2025-08-26 01:52:57,369][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020392] [Batch 00648/01234] [00:07:19/00:06:37, 0.678s/it]: train_loss_raw=1.3751, running_loss=1.2629, LR=0.000100
[2025-08-26 01:53:02,986][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020400] [Batch 00656/01234] [00:07:24/00:06:31, 0.678s/it]: train_loss_raw=1.2483, running_loss=1.2645, LR=0.000100
[2025-08-26 01:53:08,225][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020408] [Batch 00664/01234] [00:07:29/00:06:26, 0.678s/it]: train_loss_raw=1.1948, running_loss=1.2651, LR=0.000100
[2025-08-26 01:53:13,444][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020416] [Batch 00672/01234] [00:07:35/00:06:20, 0.677s/it]: train_loss_raw=1.2454, running_loss=1.2638, LR=0.000100
[2025-08-26 01:53:19,135][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020424] [Batch 00680/01234] [00:07:40/00:06:15, 0.678s/it]: train_loss_raw=1.2325, running_loss=1.2635, LR=0.000100
[2025-08-26 01:53:24,357][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020432] [Batch 00688/01234] [00:07:46/00:06:09, 0.677s/it]: train_loss_raw=1.3084, running_loss=1.2636, LR=0.000100
[2025-08-26 01:53:29,407][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020440] [Batch 00696/01234] [00:07:51/00:06:04, 0.677s/it]: train_loss_raw=1.2553, running_loss=1.2626, LR=0.000100
[2025-08-26 01:53:34,483][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020448] [Batch 00704/01234] [00:07:56/00:05:58, 0.676s/it]: train_loss_raw=1.2512, running_loss=1.2626, LR=0.000100
[2025-08-26 01:53:39,733][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020456] [Batch 00712/01234] [00:08:01/00:05:52, 0.676s/it]: train_loss_raw=1.2216, running_loss=1.2612, LR=0.000100
[2025-08-26 01:53:44,884][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020464] [Batch 00720/01234] [00:08:06/00:05:47, 0.676s/it]: train_loss_raw=1.3064, running_loss=1.2645, LR=0.000100
[2025-08-26 01:53:50,442][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020472] [Batch 00728/01234] [00:08:12/00:05:42, 0.676s/it]: train_loss_raw=1.1547, running_loss=1.2647, LR=0.000100
[2025-08-26 01:53:55,675][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020480] [Batch 00736/01234] [00:08:17/00:05:36, 0.676s/it]: train_loss_raw=1.2901, running_loss=1.2650, LR=0.000100
[2025-08-26 01:54:00,855][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020488] [Batch 00744/01234] [00:08:22/00:05:31, 0.676s/it]: train_loss_raw=1.2388, running_loss=1.2674, LR=0.000100
[2025-08-26 01:54:05,974][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020496] [Batch 00752/01234] [00:08:27/00:05:25, 0.675s/it]: train_loss_raw=1.3520, running_loss=1.2678, LR=0.000100
[2025-08-26 01:54:11,201][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020504] [Batch 00760/01234] [00:08:32/00:05:19, 0.675s/it]: train_loss_raw=1.2446, running_loss=1.2660, LR=0.000100
[2025-08-26 01:54:16,298][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020512] [Batch 00768/01234] [00:08:38/00:05:14, 0.675s/it]: train_loss_raw=1.2828, running_loss=1.2643, LR=0.000100
[2025-08-26 01:54:21,460][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020520] [Batch 00776/01234] [00:08:43/00:05:08, 0.674s/it]: train_loss_raw=1.3944, running_loss=1.2652, LR=0.000100
[2025-08-26 01:54:27,157][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020528] [Batch 00784/01234] [00:08:48/00:05:03, 0.675s/it]: train_loss_raw=1.3626, running_loss=1.2652, LR=0.000100
[2025-08-26 01:54:32,768][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020536] [Batch 00792/01234] [00:08:54/00:04:58, 0.675s/it]: train_loss_raw=1.2360, running_loss=1.2628, LR=0.000100
[2025-08-26 01:54:38,509][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020544] [Batch 00800/01234] [00:09:00/00:04:53, 0.675s/it]: train_loss_raw=1.2262, running_loss=1.2604, LR=0.000100
[2025-08-26 01:54:43,971][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020552] [Batch 00808/01234] [00:09:05/00:04:47, 0.675s/it]: train_loss_raw=1.2163, running_loss=1.2606, LR=0.000100
[2025-08-26 01:54:49,038][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020560] [Batch 00816/01234] [00:09:10/00:04:42, 0.675s/it]: train_loss_raw=1.3168, running_loss=1.2608, LR=0.000100
[2025-08-26 01:54:54,089][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020568] [Batch 00824/01234] [00:09:15/00:04:36, 0.675s/it]: train_loss_raw=1.2909, running_loss=1.2612, LR=0.000100
[2025-08-26 01:54:59,129][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020576] [Batch 00832/01234] [00:09:20/00:04:30, 0.674s/it]: train_loss_raw=1.2324, running_loss=1.2600, LR=0.000100
[2025-08-26 01:55:05,037][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020584] [Batch 00840/01234] [00:09:26/00:04:25, 0.675s/it]: train_loss_raw=1.0781, running_loss=1.2588, LR=0.000100
[2025-08-26 01:55:10,248][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020592] [Batch 00848/01234] [00:09:31/00:04:20, 0.675s/it]: train_loss_raw=1.3332, running_loss=1.2599, LR=0.000100
[2025-08-26 01:55:16,043][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020600] [Batch 00856/01234] [00:09:37/00:04:15, 0.675s/it]: train_loss_raw=1.1885, running_loss=1.2606, LR=0.000100
[2025-08-26 01:55:21,103][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020608] [Batch 00864/01234] [00:09:42/00:04:09, 0.675s/it]: train_loss_raw=1.3239, running_loss=1.2623, LR=0.000100
[2025-08-26 01:55:26,148][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020616] [Batch 00872/01234] [00:09:47/00:04:04, 0.674s/it]: train_loss_raw=1.1967, running_loss=1.2595, LR=0.000100
[2025-08-26 01:55:31,169][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020624] [Batch 00880/01234] [00:09:52/00:03:58, 0.674s/it]: train_loss_raw=1.3287, running_loss=1.2589, LR=0.000100
[2025-08-26 01:55:36,922][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020632] [Batch 00888/01234] [00:09:58/00:03:53, 0.674s/it]: train_loss_raw=1.3418, running_loss=1.2611, LR=0.000100
[2025-08-26 01:55:42,701][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020640] [Batch 00896/01234] [00:10:04/00:03:48, 0.675s/it]: train_loss_raw=1.2978, running_loss=1.2621, LR=0.000100
[2025-08-26 01:55:48,097][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020648] [Batch 00904/01234] [00:10:09/00:03:42, 0.675s/it]: train_loss_raw=1.2997, running_loss=1.2645, LR=0.000100
[2025-08-26 01:55:53,653][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020656] [Batch 00912/01234] [00:10:15/00:03:37, 0.675s/it]: train_loss_raw=1.2558, running_loss=1.2653, LR=0.000100
[2025-08-26 01:55:58,915][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020664] [Batch 00920/01234] [00:10:20/00:03:31, 0.675s/it]: train_loss_raw=1.3072, running_loss=1.2666, LR=0.000100
[2025-08-26 01:56:04,208][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020672] [Batch 00928/01234] [00:10:25/00:03:26, 0.675s/it]: train_loss_raw=1.2391, running_loss=1.2673, LR=0.000100
[2025-08-26 01:56:09,270][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020680] [Batch 00936/01234] [00:10:31/00:03:20, 0.674s/it]: train_loss_raw=1.1672, running_loss=1.2664, LR=0.000100
[2025-08-26 01:56:14,357][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020688] [Batch 00944/01234] [00:10:36/00:03:15, 0.674s/it]: train_loss_raw=1.3370, running_loss=1.2675, LR=0.000100
[2025-08-26 01:56:19,951][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020696] [Batch 00952/01234] [00:10:41/00:03:10, 0.674s/it]: train_loss_raw=1.1941, running_loss=1.2645, LR=0.000100
[2025-08-26 01:56:25,499][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020704] [Batch 00960/01234] [00:10:47/00:03:04, 0.674s/it]: train_loss_raw=1.3482, running_loss=1.2664, LR=0.000100
[2025-08-26 01:56:30,911][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020712] [Batch 00968/01234] [00:10:52/00:02:59, 0.674s/it]: train_loss_raw=1.2240, running_loss=1.2676, LR=0.000100
[2025-08-26 01:56:35,983][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020720] [Batch 00976/01234] [00:10:57/00:02:53, 0.674s/it]: train_loss_raw=1.1816, running_loss=1.2686, LR=0.000100
[2025-08-26 01:56:41,062][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020728] [Batch 00984/01234] [00:11:02/00:02:48, 0.674s/it]: train_loss_raw=1.3240, running_loss=1.2713, LR=0.000100
[2025-08-26 01:56:46,138][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020736] [Batch 00992/01234] [00:11:07/00:02:42, 0.673s/it]: train_loss_raw=1.3219, running_loss=1.2726, LR=0.000100
[2025-08-26 01:56:51,535][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020744] [Batch 01000/01234] [00:11:13/00:02:37, 0.673s/it]: train_loss_raw=1.3100, running_loss=1.2736, LR=0.000100
[2025-08-26 01:56:56,948][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020752] [Batch 01008/01234] [00:11:18/00:02:32, 0.673s/it]: train_loss_raw=1.3874, running_loss=1.2748, LR=0.000100
[2025-08-26 01:57:02,705][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020760] [Batch 01016/01234] [00:11:24/00:02:26, 0.674s/it]: train_loss_raw=1.2421, running_loss=1.2745, LR=0.000100
[2025-08-26 01:57:08,198][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020768] [Batch 01024/01234] [00:11:29/00:02:21, 0.674s/it]: train_loss_raw=1.2793, running_loss=1.2749, LR=0.000100
[2025-08-26 01:57:13,625][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020776] [Batch 01032/01234] [00:11:35/00:02:16, 0.674s/it]: train_loss_raw=1.2736, running_loss=1.2718, LR=0.000100
[2025-08-26 01:57:18,771][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020784] [Batch 01040/01234] [00:11:40/00:02:10, 0.674s/it]: train_loss_raw=1.2437, running_loss=1.2724, LR=0.000100
[2025-08-26 01:57:23,930][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020792] [Batch 01048/01234] [00:11:45/00:02:05, 0.673s/it]: train_loss_raw=1.2962, running_loss=1.2753, LR=0.000100
[2025-08-26 01:57:29,013][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020800] [Batch 01056/01234] [00:11:50/00:01:59, 0.673s/it]: train_loss_raw=1.3214, running_loss=1.2764, LR=0.000100
[2025-08-26 01:57:34,247][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020808] [Batch 01064/01234] [00:11:55/00:01:54, 0.673s/it]: train_loss_raw=1.3832, running_loss=1.2769, LR=0.000100
[2025-08-26 01:57:40,080][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020816] [Batch 01072/01234] [00:12:01/00:01:49, 0.673s/it]: train_loss_raw=1.3003, running_loss=1.2762, LR=0.000100
[2025-08-26 01:57:45,312][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020824] [Batch 01080/01234] [00:12:07/00:01:43, 0.673s/it]: train_loss_raw=1.1504, running_loss=1.2741, LR=0.000100
[2025-08-26 01:57:50,373][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020832] [Batch 01088/01234] [00:12:12/00:01:38, 0.673s/it]: train_loss_raw=1.2903, running_loss=1.2737, LR=0.000100
[2025-08-26 01:57:55,982][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020840] [Batch 01096/01234] [00:12:17/00:01:32, 0.673s/it]: train_loss_raw=1.2537, running_loss=1.2737, LR=0.000100
[2025-08-26 01:58:01,482][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020848] [Batch 01104/01234] [00:12:23/00:01:27, 0.673s/it]: train_loss_raw=1.1221, running_loss=1.2715, LR=0.000100
[2025-08-26 01:58:07,255][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020856] [Batch 01112/01234] [00:12:28/00:01:22, 0.674s/it]: train_loss_raw=1.3329, running_loss=1.2719, LR=0.000100
[2025-08-26 01:58:13,118][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020864] [Batch 01120/01234] [00:12:34/00:01:16, 0.674s/it]: train_loss_raw=1.3002, running_loss=1.2706, LR=0.000100
[2025-08-26 01:58:19,005][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020872] [Batch 01128/01234] [00:12:40/00:01:11, 0.674s/it]: train_loss_raw=1.2368, running_loss=1.2708, LR=0.000100
[2025-08-26 01:58:24,692][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020880] [Batch 01136/01234] [00:12:46/00:01:06, 0.675s/it]: train_loss_raw=1.2896, running_loss=1.2714, LR=0.000100
[2025-08-26 01:58:30,201][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020888] [Batch 01144/01234] [00:12:51/00:01:00, 0.675s/it]: train_loss_raw=1.2956, running_loss=1.2719, LR=0.000100
[2025-08-26 01:58:36,375][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020896] [Batch 01152/01234] [00:12:58/00:00:55, 0.675s/it]: train_loss_raw=1.2301, running_loss=1.2719, LR=0.000100
[2025-08-26 01:58:42,581][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020904] [Batch 01160/01234] [00:13:04/00:00:50, 0.676s/it]: train_loss_raw=1.2989, running_loss=1.2708, LR=0.000100
[2025-08-26 01:58:48,384][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020912] [Batch 01168/01234] [00:13:10/00:00:44, 0.676s/it]: train_loss_raw=1.2477, running_loss=1.2692, LR=0.000100
[2025-08-26 01:58:54,178][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020920] [Batch 01176/01234] [00:13:15/00:00:39, 0.677s/it]: train_loss_raw=1.2068, running_loss=1.2695, LR=0.000100
[2025-08-26 01:59:00,223][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020928] [Batch 01184/01234] [00:13:21/00:00:33, 0.677s/it]: train_loss_raw=1.2963, running_loss=1.2681, LR=0.000100
[2025-08-26 01:59:05,808][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020936] [Batch 01192/01234] [00:13:27/00:00:28, 0.677s/it]: train_loss_raw=1.3214, running_loss=1.2693, LR=0.000100
[2025-08-26 01:59:11,220][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020944] [Batch 01200/01234] [00:13:32/00:00:23, 0.677s/it]: train_loss_raw=1.2850, running_loss=1.2705, LR=0.000100
[2025-08-26 01:59:16,858][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020952] [Batch 01208/01234] [00:13:38/00:00:17, 0.678s/it]: train_loss_raw=1.2576, running_loss=1.2687, LR=0.000100
[2025-08-26 01:59:22,110][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020960] [Batch 01216/01234] [00:13:43/00:00:12, 0.678s/it]: train_loss_raw=1.3131, running_loss=1.2693, LR=0.000100
[2025-08-26 01:59:27,912][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020968] [Batch 01224/01234] [00:13:49/00:00:06, 0.678s/it]: train_loss_raw=1.2567, running_loss=1.2645, LR=0.000100
[2025-08-26 01:59:33,122][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 020976] [Batch 01232/01234] [00:13:54/00:00:01, 0.678s/it]: train_loss_raw=1.3192, running_loss=1.2667, LR=0.000100
[2025-08-26 01:59:41,784][__main__][INFO] - [VALIDATION] [Epoch 16/29] Starting validation.
[2025-08-26 01:59:52,637][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 020979] [Batch 00007/00026] [00:00:10/00:00:24, 1.357s/it]
[2025-08-26 02:00:04,634][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 020979] [Batch 00015/00026] [00:00:22/00:00:14, 1.428s/it]
[2025-08-26 02:00:16,595][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 020979] [Batch 00023/00026] [00:00:34/00:00:02, 1.450s/it]
[2025-08-26 02:00:19,403][__main__][INFO] - [VALIDATION] [Epoch 16/29] train_loss=1.26706, valid_loss=1.52307
[2025-08-26 02:00:19,403][__main__][INFO] - [VALIDATION] [Epoch 16/29] Metrics:
[2025-08-26 02:00:19,403][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_er      0.628
[2025-08-26 02:00:19,403][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_prec    0.054
[2025-08-26 02:00:19,403][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_recall  0.054
[2025-08-26 02:00:19,403][__main__][INFO] - [VALIDATION] [Epoch 16/29] - pep_recall 0.016
[2025-08-26 02:00:19,406][__main__][INFO] - [TRAIN] [Epoch 16/29] Epoch complete, total time 04:09:28, remaining time 03:10:46, 00:14:40 per epoch
[2025-08-26 02:00:23,380][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 020984] [Batch 00006/01234] [00:00:03/00:12:37, 0.617s/it]: train_loss_raw=1.2475, running_loss=1.1209, LR=0.000100
[2025-08-26 02:00:29,396][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 020992] [Batch 00014/01234] [00:00:09/00:14:06, 0.694s/it]: train_loss_raw=1.1533, running_loss=1.1267, LR=0.000100
[2025-08-26 02:00:35,311][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021000] [Batch 00022/01234] [00:00:15/00:14:21, 0.711s/it]: train_loss_raw=1.1642, running_loss=1.1304, LR=0.000100
[2025-08-26 02:00:41,030][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021008] [Batch 00030/01234] [00:00:21/00:14:16, 0.712s/it]: train_loss_raw=1.2744, running_loss=1.1373, LR=0.000100
[2025-08-26 02:00:46,869][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021016] [Batch 00038/01234] [00:00:27/00:14:15, 0.716s/it]: train_loss_raw=1.2690, running_loss=1.1396, LR=0.000100
[2025-08-26 02:00:52,757][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021024] [Batch 00046/01234] [00:00:33/00:14:14, 0.719s/it]: train_loss_raw=1.0398, running_loss=1.1430, LR=0.000100
[2025-08-26 02:00:58,575][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021032] [Batch 00054/01234] [00:00:38/00:14:09, 0.720s/it]: train_loss_raw=1.1370, running_loss=1.1461, LR=0.000100
[2025-08-26 02:01:03,972][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021040] [Batch 00062/01234] [00:00:44/00:13:57, 0.714s/it]: train_loss_raw=1.2175, running_loss=1.1476, LR=0.000100
[2025-08-26 02:01:09,753][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021048] [Batch 00070/01234] [00:00:50/00:13:52, 0.715s/it]: train_loss_raw=1.0997, running_loss=1.1485, LR=0.000100
[2025-08-26 02:01:15,561][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021056] [Batch 00078/01234] [00:00:55/00:13:48, 0.716s/it]: train_loss_raw=1.2565, running_loss=1.1524, LR=0.000100
[2025-08-26 02:01:21,375][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021064] [Batch 00086/01234] [00:01:01/00:13:43, 0.717s/it]: train_loss_raw=1.1945, running_loss=1.1572, LR=0.000100
[2025-08-26 02:01:26,832][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021072] [Batch 00094/01234] [00:01:07/00:13:34, 0.714s/it]: train_loss_raw=1.1410, running_loss=1.1618, LR=0.000100
[2025-08-26 02:01:31,919][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021080] [Batch 00102/01234] [00:01:12/00:13:21, 0.708s/it]: train_loss_raw=1.2867, running_loss=1.1643, LR=0.000100
[2025-08-26 02:01:37,021][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021088] [Batch 00110/01234] [00:01:17/00:13:10, 0.703s/it]: train_loss_raw=1.3021, running_loss=1.1703, LR=0.000100
[2025-08-26 02:01:42,436][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021096] [Batch 00118/01234] [00:01:22/00:13:02, 0.701s/it]: train_loss_raw=1.2529, running_loss=1.1725, LR=0.000100
[2025-08-26 02:01:47,819][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021104] [Batch 00126/01234] [00:01:28/00:12:55, 0.700s/it]: train_loss_raw=1.3301, running_loss=1.1744, LR=0.000100
[2025-08-26 02:01:53,297][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021112] [Batch 00134/01234] [00:01:33/00:12:48, 0.699s/it]: train_loss_raw=1.3140, running_loss=1.1774, LR=0.000100
[2025-08-26 02:01:58,348][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021120] [Batch 00142/01234] [00:01:38/00:12:38, 0.695s/it]: train_loss_raw=1.2629, running_loss=1.1814, LR=0.000100
[2025-08-26 02:02:03,904][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021128] [Batch 00150/01234] [00:01:44/00:12:33, 0.695s/it]: train_loss_raw=1.1532, running_loss=1.1829, LR=0.000100
[2025-08-26 02:02:08,980][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021136] [Batch 00158/01234] [00:01:49/00:12:24, 0.692s/it]: train_loss_raw=1.2220, running_loss=1.1854, LR=0.000100
[2025-08-26 02:02:14,204][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021144] [Batch 00166/01234] [00:01:54/00:12:16, 0.690s/it]: train_loss_raw=1.2107, running_loss=1.1855, LR=0.000100
[2025-08-26 02:02:19,252][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021152] [Batch 00174/01234] [00:01:59/00:12:08, 0.687s/it]: train_loss_raw=1.1843, running_loss=1.1869, LR=0.000100
[2025-08-26 02:02:24,642][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021160] [Batch 00182/01234] [00:02:04/00:12:02, 0.687s/it]: train_loss_raw=1.2007, running_loss=1.1855, LR=0.000100
[2025-08-26 02:02:29,701][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021168] [Batch 00190/01234] [00:02:10/00:11:54, 0.684s/it]: train_loss_raw=1.2391, running_loss=1.1891, LR=0.000100
[2025-08-26 02:02:34,766][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021176] [Batch 00198/01234] [00:02:15/00:11:46, 0.682s/it]: train_loss_raw=1.1692, running_loss=1.1921, LR=0.000100
[2025-08-26 02:02:39,871][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021184] [Batch 00206/01234] [00:02:20/00:11:39, 0.681s/it]: train_loss_raw=1.2124, running_loss=1.1940, LR=0.000100
[2025-08-26 02:02:45,122][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021192] [Batch 00214/01234] [00:02:25/00:11:33, 0.680s/it]: train_loss_raw=1.3230, running_loss=1.1988, LR=0.000100
[2025-08-26 02:02:50,918][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021200] [Batch 00222/01234] [00:02:31/00:11:29, 0.681s/it]: train_loss_raw=1.2445, running_loss=1.2007, LR=0.000100
[2025-08-26 02:02:55,982][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021208] [Batch 00230/01234] [00:02:36/00:11:22, 0.680s/it]: train_loss_raw=1.1514, running_loss=1.2015, LR=0.000100
[2025-08-26 02:03:01,067][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021216] [Batch 00238/01234] [00:02:41/00:11:15, 0.678s/it]: train_loss_raw=1.1837, running_loss=1.2035, LR=0.000100
[2025-08-26 02:03:06,464][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021224] [Batch 00246/01234] [00:02:46/00:11:09, 0.678s/it]: train_loss_raw=1.1888, running_loss=1.2044, LR=0.000100
[2025-08-26 02:03:11,752][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021232] [Batch 00254/01234] [00:02:52/00:11:03, 0.677s/it]: train_loss_raw=1.2155, running_loss=1.2057, LR=0.000100
[2025-08-26 02:03:17,131][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021240] [Batch 00262/01234] [00:02:57/00:10:58, 0.677s/it]: train_loss_raw=1.1774, running_loss=1.2048, LR=0.000100
[2025-08-26 02:03:22,698][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021248] [Batch 00270/01234] [00:03:03/00:10:53, 0.678s/it]: train_loss_raw=1.1509, running_loss=1.2034, LR=0.000100
[2025-08-26 02:03:28,261][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021256] [Batch 00278/01234] [00:03:08/00:10:48, 0.678s/it]: train_loss_raw=1.1488, running_loss=1.2053, LR=0.000100
[2025-08-26 02:03:33,402][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021264] [Batch 00286/01234] [00:03:13/00:10:42, 0.677s/it]: train_loss_raw=1.1705, running_loss=1.2060, LR=0.000100
[2025-08-26 02:03:39,066][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021272] [Batch 00294/01234] [00:03:19/00:10:37, 0.678s/it]: train_loss_raw=1.1738, running_loss=1.2056, LR=0.000100
[2025-08-26 02:03:44,210][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021280] [Batch 00302/01234] [00:03:24/00:10:31, 0.677s/it]: train_loss_raw=1.2150, running_loss=1.2070, LR=0.000100
[2025-08-26 02:03:49,627][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021288] [Batch 00310/01234] [00:03:29/00:10:25, 0.677s/it]: train_loss_raw=1.1728, running_loss=1.2076, LR=0.000100
[2025-08-26 02:03:54,921][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021296] [Batch 00318/01234] [00:03:35/00:10:20, 0.677s/it]: train_loss_raw=1.3194, running_loss=1.2092, LR=0.000100
[2025-08-26 02:04:00,567][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021304] [Batch 00326/01234] [00:03:40/00:10:15, 0.678s/it]: train_loss_raw=1.2384, running_loss=1.2121, LR=0.000100
[2025-08-26 02:04:06,157][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021312] [Batch 00334/01234] [00:03:46/00:10:10, 0.678s/it]: train_loss_raw=1.2372, running_loss=1.2112, LR=0.000100
[2025-08-26 02:04:11,275][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021320] [Batch 00342/01234] [00:03:51/00:10:04, 0.677s/it]: train_loss_raw=1.2201, running_loss=1.2102, LR=0.000100
[2025-08-26 02:04:16,677][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021328] [Batch 00350/01234] [00:03:56/00:09:58, 0.677s/it]: train_loss_raw=1.1874, running_loss=1.2111, LR=0.000100
[2025-08-26 02:04:22,291][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021336] [Batch 00358/01234] [00:04:02/00:09:53, 0.678s/it]: train_loss_raw=1.1894, running_loss=1.2128, LR=0.000100
[2025-08-26 02:04:27,567][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021344] [Batch 00366/01234] [00:04:07/00:09:47, 0.677s/it]: train_loss_raw=1.2517, running_loss=1.2123, LR=0.000100
[2025-08-26 02:04:33,188][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021352] [Batch 00374/01234] [00:04:13/00:09:42, 0.678s/it]: train_loss_raw=1.1575, running_loss=1.2100, LR=0.000100
[2025-08-26 02:04:38,325][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021360] [Batch 00382/01234] [00:04:18/00:09:36, 0.677s/it]: train_loss_raw=1.3536, running_loss=1.2126, LR=0.000100
[2025-08-26 02:04:43,465][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021368] [Batch 00390/01234] [00:04:23/00:09:30, 0.676s/it]: train_loss_raw=1.1660, running_loss=1.2124, LR=0.000100
[2025-08-26 02:04:49,134][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021376] [Batch 00398/01234] [00:04:29/00:09:25, 0.677s/it]: train_loss_raw=1.2331, running_loss=1.2138, LR=0.000100
[2025-08-26 02:04:54,713][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021384] [Batch 00406/01234] [00:04:35/00:09:20, 0.677s/it]: train_loss_raw=1.3352, running_loss=1.2145, LR=0.000100
[2025-08-26 02:05:00,143][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021392] [Batch 00414/01234] [00:04:40/00:09:15, 0.677s/it]: train_loss_raw=1.1289, running_loss=1.2151, LR=0.000100
[2025-08-26 02:05:05,273][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021400] [Batch 00422/01234] [00:04:45/00:09:09, 0.677s/it]: train_loss_raw=1.2859, running_loss=1.2174, LR=0.000100
[2025-08-26 02:05:11,234][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021408] [Batch 00430/01234] [00:04:51/00:09:05, 0.678s/it]: train_loss_raw=1.0359, running_loss=1.2143, LR=0.000100
[2025-08-26 02:05:17,004][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021416] [Batch 00438/01234] [00:04:57/00:09:00, 0.679s/it]: train_loss_raw=1.1741, running_loss=1.2145, LR=0.000100
[2025-08-26 02:05:22,498][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021424] [Batch 00446/01234] [00:05:02/00:08:55, 0.679s/it]: train_loss_raw=1.2090, running_loss=1.2133, LR=0.000100
[2025-08-26 02:05:27,624][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021432] [Batch 00454/01234] [00:05:07/00:08:49, 0.678s/it]: train_loss_raw=1.1651, running_loss=1.2122, LR=0.000100
[2025-08-26 02:05:32,771][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021440] [Batch 00462/01234] [00:05:13/00:08:43, 0.678s/it]: train_loss_raw=1.1899, running_loss=1.2127, LR=0.000100
[2025-08-26 02:05:38,316][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021448] [Batch 00470/01234] [00:05:18/00:08:37, 0.678s/it]: train_loss_raw=1.2395, running_loss=1.2122, LR=0.000100
[2025-08-26 02:05:43,920][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021456] [Batch 00478/01234] [00:05:24/00:08:32, 0.678s/it]: train_loss_raw=1.2043, running_loss=1.2108, LR=0.000100
[2025-08-26 02:05:49,330][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021464] [Batch 00486/01234] [00:05:29/00:08:27, 0.678s/it]: train_loss_raw=1.2219, running_loss=1.2120, LR=0.000100
[2025-08-26 02:05:54,639][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021472] [Batch 00494/01234] [00:05:34/00:08:21, 0.678s/it]: train_loss_raw=1.2643, running_loss=1.2106, LR=0.000100
[2025-08-26 02:05:59,788][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021480] [Batch 00502/01234] [00:05:40/00:08:15, 0.678s/it]: train_loss_raw=1.0837, running_loss=1.2122, LR=0.000100
[2025-08-26 02:06:05,428][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021488] [Batch 00510/01234] [00:05:45/00:08:10, 0.678s/it]: train_loss_raw=1.2882, running_loss=1.2130, LR=0.000100
[2025-08-26 02:06:11,002][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021496] [Batch 00518/01234] [00:05:51/00:08:05, 0.678s/it]: train_loss_raw=1.2020, running_loss=1.2131, LR=0.000100
[2025-08-26 02:06:16,282][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021504] [Batch 00526/01234] [00:05:56/00:07:59, 0.678s/it]: train_loss_raw=1.2307, running_loss=1.2140, LR=0.000100
[2025-08-26 02:06:21,801][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021512] [Batch 00534/01234] [00:06:02/00:07:54, 0.678s/it]: train_loss_raw=1.2179, running_loss=1.2164, LR=0.000100
[2025-08-26 02:06:27,691][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021520] [Batch 00542/01234] [00:06:08/00:07:49, 0.679s/it]: train_loss_raw=1.1892, running_loss=1.2137, LR=0.000100
[2025-08-26 02:06:33,022][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021528] [Batch 00550/01234] [00:06:13/00:07:44, 0.679s/it]: train_loss_raw=1.2128, running_loss=1.2133, LR=0.000100
[2025-08-26 02:06:38,518][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021536] [Batch 00558/01234] [00:06:18/00:07:38, 0.679s/it]: train_loss_raw=1.2463, running_loss=1.2149, LR=0.000100
[2025-08-26 02:06:43,734][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021544] [Batch 00566/01234] [00:06:24/00:07:33, 0.679s/it]: train_loss_raw=1.2912, running_loss=1.2171, LR=0.000100
[2025-08-26 02:06:48,779][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021552] [Batch 00574/01234] [00:06:29/00:07:27, 0.678s/it]: train_loss_raw=1.2114, running_loss=1.2179, LR=0.000100
[2025-08-26 02:06:53,991][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021560] [Batch 00582/01234] [00:06:34/00:07:21, 0.678s/it]: train_loss_raw=1.0458, running_loss=1.2155, LR=0.000100
[2025-08-26 02:06:59,037][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021568] [Batch 00590/01234] [00:06:39/00:07:15, 0.677s/it]: train_loss_raw=1.2371, running_loss=1.2172, LR=0.000100
[2025-08-26 02:07:04,084][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021576] [Batch 00598/01234] [00:06:44/00:07:10, 0.676s/it]: train_loss_raw=1.1777, running_loss=1.2154, LR=0.000100
[2025-08-26 02:07:09,143][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021584] [Batch 00606/01234] [00:06:49/00:07:04, 0.676s/it]: train_loss_raw=1.2541, running_loss=1.2165, LR=0.000100
[2025-08-26 02:07:14,574][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021592] [Batch 00614/01234] [00:06:54/00:06:58, 0.676s/it]: train_loss_raw=1.1165, running_loss=1.2183, LR=0.000100
[2025-08-26 02:07:19,627][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021600] [Batch 00622/01234] [00:06:59/00:06:53, 0.675s/it]: train_loss_raw=1.1944, running_loss=1.2206, LR=0.000100
[2025-08-26 02:07:24,674][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021608] [Batch 00630/01234] [00:07:04/00:06:47, 0.675s/it]: train_loss_raw=1.2144, running_loss=1.2185, LR=0.000100
[2025-08-26 02:07:29,877][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021616] [Batch 00638/01234] [00:07:10/00:06:41, 0.674s/it]: train_loss_raw=1.2228, running_loss=1.2193, LR=0.000100
[2025-08-26 02:07:34,942][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021624] [Batch 00646/01234] [00:07:15/00:06:36, 0.674s/it]: train_loss_raw=1.2702, running_loss=1.2195, LR=0.000100
[2025-08-26 02:07:40,330][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021632] [Batch 00654/01234] [00:07:20/00:06:30, 0.674s/it]: train_loss_raw=1.2326, running_loss=1.2190, LR=0.000100
[2025-08-26 02:07:45,382][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021640] [Batch 00662/01234] [00:07:25/00:06:25, 0.673s/it]: train_loss_raw=1.2114, running_loss=1.2191, LR=0.000100
[2025-08-26 02:07:51,086][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021648] [Batch 00670/01234] [00:07:31/00:06:19, 0.674s/it]: train_loss_raw=1.0934, running_loss=1.2189, LR=0.000100
[2025-08-26 02:07:56,834][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021656] [Batch 00678/01234] [00:07:37/00:06:14, 0.674s/it]: train_loss_raw=1.2002, running_loss=1.2192, LR=0.000100
[2025-08-26 02:08:02,571][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021664] [Batch 00686/01234] [00:07:42/00:06:09, 0.675s/it]: train_loss_raw=1.2591, running_loss=1.2208, LR=0.000100
[2025-08-26 02:08:07,999][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021672] [Batch 00694/01234] [00:07:48/00:06:04, 0.675s/it]: train_loss_raw=1.2639, running_loss=1.2225, LR=0.000100
[2025-08-26 02:08:13,200][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021680] [Batch 00702/01234] [00:07:53/00:05:58, 0.675s/it]: train_loss_raw=1.1594, running_loss=1.2207, LR=0.000100
[2025-08-26 02:08:18,600][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021688] [Batch 00710/01234] [00:07:58/00:05:53, 0.675s/it]: train_loss_raw=1.1724, running_loss=1.2214, LR=0.000100
[2025-08-26 02:08:23,640][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021696] [Batch 00718/01234] [00:08:03/00:05:47, 0.674s/it]: train_loss_raw=1.2050, running_loss=1.2205, LR=0.000100
[2025-08-26 02:08:28,880][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021704] [Batch 00726/01234] [00:08:09/00:05:42, 0.674s/it]: train_loss_raw=1.2025, running_loss=1.2202, LR=0.000100
[2025-08-26 02:08:34,666][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021712] [Batch 00734/01234] [00:08:14/00:05:37, 0.674s/it]: train_loss_raw=1.2393, running_loss=1.2194, LR=0.000100
[2025-08-26 02:08:40,225][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021720] [Batch 00742/01234] [00:08:20/00:05:31, 0.675s/it]: train_loss_raw=1.2324, running_loss=1.2206, LR=0.000100
[2025-08-26 02:08:45,427][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021728] [Batch 00750/01234] [00:08:25/00:05:26, 0.674s/it]: train_loss_raw=1.2071, running_loss=1.2181, LR=0.000100
[2025-08-26 02:08:50,567][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021736] [Batch 00758/01234] [00:08:30/00:05:20, 0.674s/it]: train_loss_raw=1.2301, running_loss=1.2200, LR=0.000100
[2025-08-26 02:08:55,885][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021744] [Batch 00766/01234] [00:08:36/00:05:15, 0.674s/it]: train_loss_raw=1.2066, running_loss=1.2195, LR=0.000100
[2025-08-26 02:09:01,306][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021752] [Batch 00774/01234] [00:08:41/00:05:10, 0.674s/it]: train_loss_raw=1.2949, running_loss=1.2215, LR=0.000100
[2025-08-26 02:09:07,200][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021760] [Batch 00782/01234] [00:08:47/00:05:04, 0.675s/it]: train_loss_raw=1.1690, running_loss=1.2246, LR=0.000100
[2025-08-26 02:09:12,738][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021768] [Batch 00790/01234] [00:08:53/00:04:59, 0.675s/it]: train_loss_raw=1.2646, running_loss=1.2268, LR=0.000100
[2025-08-26 02:09:17,839][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021776] [Batch 00798/01234] [00:08:58/00:04:54, 0.674s/it]: train_loss_raw=1.2964, running_loss=1.2281, LR=0.000100
[2025-08-26 02:09:22,936][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021784] [Batch 00806/01234] [00:09:03/00:04:48, 0.674s/it]: train_loss_raw=1.2109, running_loss=1.2271, LR=0.000100
[2025-08-26 02:09:28,107][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021792] [Batch 00814/01234] [00:09:08/00:04:42, 0.674s/it]: train_loss_raw=1.2091, running_loss=1.2262, LR=0.000100
[2025-08-26 02:09:33,840][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021800] [Batch 00822/01234] [00:09:14/00:04:37, 0.674s/it]: train_loss_raw=1.3430, running_loss=1.2269, LR=0.000100
[2025-08-26 02:09:39,303][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021808] [Batch 00830/01234] [00:09:19/00:04:32, 0.674s/it]: train_loss_raw=1.1755, running_loss=1.2273, LR=0.000100
[2025-08-26 02:09:44,696][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021816] [Batch 00838/01234] [00:09:25/00:04:27, 0.674s/it]: train_loss_raw=1.2811, running_loss=1.2266, LR=0.000100
[2025-08-26 02:09:50,112][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021824] [Batch 00846/01234] [00:09:30/00:04:21, 0.674s/it]: train_loss_raw=1.2056, running_loss=1.2283, LR=0.000100
[2025-08-26 02:09:55,169][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021832] [Batch 00854/01234] [00:09:35/00:04:16, 0.674s/it]: train_loss_raw=1.2507, running_loss=1.2285, LR=0.000100
[2025-08-26 02:10:00,255][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021840] [Batch 00862/01234] [00:09:40/00:04:10, 0.674s/it]: train_loss_raw=1.2140, running_loss=1.2296, LR=0.000100
[2025-08-26 02:10:05,332][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021848] [Batch 00870/01234] [00:09:45/00:04:05, 0.673s/it]: train_loss_raw=1.1997, running_loss=1.2297, LR=0.000100
[2025-08-26 02:10:10,365][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021856] [Batch 00878/01234] [00:09:50/00:03:59, 0.673s/it]: train_loss_raw=1.1832, running_loss=1.2307, LR=0.000100
[2025-08-26 02:10:15,441][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021864] [Batch 00886/01234] [00:09:55/00:03:54, 0.672s/it]: train_loss_raw=1.2588, running_loss=1.2306, LR=0.000100
[2025-08-26 02:10:20,779][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021872] [Batch 00894/01234] [00:10:01/00:03:48, 0.672s/it]: train_loss_raw=1.2601, running_loss=1.2314, LR=0.000100
[2025-08-26 02:10:26,766][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021880] [Batch 00902/01234] [00:10:07/00:03:43, 0.673s/it]: train_loss_raw=1.2073, running_loss=1.2310, LR=0.000100
[2025-08-26 02:10:32,556][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021888] [Batch 00910/01234] [00:10:12/00:03:38, 0.673s/it]: train_loss_raw=1.1935, running_loss=1.2312, LR=0.000100
[2025-08-26 02:10:38,432][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021896] [Batch 00918/01234] [00:10:18/00:03:32, 0.674s/it]: train_loss_raw=1.2315, running_loss=1.2281, LR=0.000100
[2025-08-26 02:10:43,996][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021904] [Batch 00926/01234] [00:10:24/00:03:27, 0.674s/it]: train_loss_raw=1.2721, running_loss=1.2271, LR=0.000100
[2025-08-26 02:10:49,529][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021912] [Batch 00934/01234] [00:10:29/00:03:22, 0.674s/it]: train_loss_raw=1.2093, running_loss=1.2264, LR=0.000100
[2025-08-26 02:10:55,296][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021920] [Batch 00942/01234] [00:10:35/00:03:17, 0.675s/it]: train_loss_raw=1.1536, running_loss=1.2248, LR=0.000100
[2025-08-26 02:11:00,856][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021928] [Batch 00950/01234] [00:10:41/00:03:11, 0.675s/it]: train_loss_raw=1.2592, running_loss=1.2244, LR=0.000100
[2025-08-26 02:11:05,999][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021936] [Batch 00958/01234] [00:10:46/00:03:06, 0.675s/it]: train_loss_raw=1.1081, running_loss=1.2242, LR=0.000100
[2025-08-26 02:11:11,474][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021944] [Batch 00966/01234] [00:10:51/00:03:00, 0.675s/it]: train_loss_raw=1.1485, running_loss=1.2236, LR=0.000100
[2025-08-26 02:11:16,565][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021952] [Batch 00974/01234] [00:10:56/00:02:55, 0.674s/it]: train_loss_raw=1.3040, running_loss=1.2230, LR=0.000100
[2025-08-26 02:11:21,680][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021960] [Batch 00982/01234] [00:11:02/00:02:49, 0.674s/it]: train_loss_raw=1.2473, running_loss=1.2244, LR=0.000100
[2025-08-26 02:11:26,977][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021968] [Batch 00990/01234] [00:11:07/00:02:44, 0.674s/it]: train_loss_raw=1.3067, running_loss=1.2274, LR=0.000100
[2025-08-26 02:11:32,846][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021976] [Batch 00998/01234] [00:11:13/00:02:39, 0.675s/it]: train_loss_raw=1.1527, running_loss=1.2292, LR=0.000100
[2025-08-26 02:11:38,091][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021984] [Batch 01006/01234] [00:11:18/00:02:33, 0.674s/it]: train_loss_raw=1.1168, running_loss=1.2272, LR=0.000100
[2025-08-26 02:11:43,671][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 021992] [Batch 01014/01234] [00:11:23/00:02:28, 0.675s/it]: train_loss_raw=1.2613, running_loss=1.2283, LR=0.000100
[2025-08-26 02:11:48,923][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022000] [Batch 01022/01234] [00:11:29/00:02:22, 0.674s/it]: train_loss_raw=1.3400, running_loss=1.2304, LR=0.000100
[2025-08-26 02:11:58,103][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022008] [Batch 01030/01234] [00:11:38/00:02:18, 0.678s/it]: train_loss_raw=1.1611, running_loss=1.2297, LR=0.000100
[2025-08-26 02:12:03,984][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022016] [Batch 01038/01234] [00:11:44/00:02:12, 0.679s/it]: train_loss_raw=1.2191, running_loss=1.2298, LR=0.000100
[2025-08-26 02:12:09,139][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022024] [Batch 01046/01234] [00:11:49/00:02:07, 0.678s/it]: train_loss_raw=1.2731, running_loss=1.2297, LR=0.000100
[2025-08-26 02:12:14,786][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022032] [Batch 01054/01234] [00:11:55/00:02:02, 0.678s/it]: train_loss_raw=1.1494, running_loss=1.2298, LR=0.000100
[2025-08-26 02:12:19,850][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022040] [Batch 01062/01234] [00:12:00/00:01:56, 0.678s/it]: train_loss_raw=1.2103, running_loss=1.2289, LR=0.000100
[2025-08-26 02:12:25,308][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022048] [Batch 01070/01234] [00:12:05/00:01:51, 0.678s/it]: train_loss_raw=1.2684, running_loss=1.2302, LR=0.000100
[2025-08-26 02:12:30,382][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022056] [Batch 01078/01234] [00:12:10/00:01:45, 0.678s/it]: train_loss_raw=1.1855, running_loss=1.2273, LR=0.000100
[2025-08-26 02:12:35,918][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022064] [Batch 01086/01234] [00:12:16/00:01:40, 0.678s/it]: train_loss_raw=1.3050, running_loss=1.2299, LR=0.000100
[2025-08-26 02:12:41,588][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022072] [Batch 01094/01234] [00:12:21/00:01:34, 0.678s/it]: train_loss_raw=1.2495, running_loss=1.2315, LR=0.000100
[2025-08-26 02:12:46,844][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022080] [Batch 01102/01234] [00:12:27/00:01:29, 0.678s/it]: train_loss_raw=1.1623, running_loss=1.2302, LR=0.000100
[2025-08-26 02:12:52,219][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022088] [Batch 01110/01234] [00:12:32/00:01:24, 0.678s/it]: train_loss_raw=1.2502, running_loss=1.2315, LR=0.000100
[2025-08-26 02:12:58,103][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022096] [Batch 01118/01234] [00:12:38/00:01:18, 0.678s/it]: train_loss_raw=1.2502, running_loss=1.2304, LR=0.000100
[2025-08-26 02:13:03,165][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022104] [Batch 01126/01234] [00:12:43/00:01:13, 0.678s/it]: train_loss_raw=1.2514, running_loss=1.2309, LR=0.000100
[2025-08-26 02:13:08,611][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022112] [Batch 01134/01234] [00:12:48/00:01:07, 0.678s/it]: train_loss_raw=1.1783, running_loss=1.2313, LR=0.000100
[2025-08-26 02:13:13,990][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022120] [Batch 01142/01234] [00:12:54/00:01:02, 0.678s/it]: train_loss_raw=1.2763, running_loss=1.2319, LR=0.000100
[2025-08-26 02:13:19,477][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022128] [Batch 01150/01234] [00:12:59/00:00:56, 0.678s/it]: train_loss_raw=1.2170, running_loss=1.2301, LR=0.000100
[2025-08-26 02:13:25,383][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022136] [Batch 01158/01234] [00:13:05/00:00:51, 0.679s/it]: train_loss_raw=1.2216, running_loss=1.2308, LR=0.000100
[2025-08-26 02:13:31,349][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022144] [Batch 01166/01234] [00:13:11/00:00:46, 0.679s/it]: train_loss_raw=1.3015, running_loss=1.2357, LR=0.000100
[2025-08-26 02:13:37,180][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022152] [Batch 01174/01234] [00:13:17/00:00:40, 0.679s/it]: train_loss_raw=1.2255, running_loss=1.2341, LR=0.000100
[2025-08-26 02:13:42,731][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022160] [Batch 01182/01234] [00:13:23/00:00:35, 0.679s/it]: train_loss_raw=1.1652, running_loss=1.2341, LR=0.000100
[2025-08-26 02:13:47,800][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022168] [Batch 01190/01234] [00:13:28/00:00:29, 0.679s/it]: train_loss_raw=1.2018, running_loss=1.2320, LR=0.000100
[2025-08-26 02:13:53,236][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022176] [Batch 01198/01234] [00:13:33/00:00:24, 0.679s/it]: train_loss_raw=1.1344, running_loss=1.2315, LR=0.000100
[2025-08-26 02:13:58,999][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022184] [Batch 01206/01234] [00:13:39/00:00:19, 0.679s/it]: train_loss_raw=1.2899, running_loss=1.2325, LR=0.000100
[2025-08-26 02:14:04,738][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022192] [Batch 01214/01234] [00:13:45/00:00:13, 0.680s/it]: train_loss_raw=1.1761, running_loss=1.2301, LR=0.000100
[2025-08-26 02:14:10,365][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022200] [Batch 01222/01234] [00:13:50/00:00:08, 0.680s/it]: train_loss_raw=1.2334, running_loss=1.2288, LR=0.000100
[2025-08-26 02:14:16,311][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 022208] [Batch 01230/01234] [00:13:56/00:00:02, 0.680s/it]: train_loss_raw=1.1903, running_loss=1.2258, LR=0.000100
[2025-08-26 02:14:24,627][__main__][INFO] - [VALIDATION] [Epoch 17/29] Starting validation.
[2025-08-26 02:14:34,489][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 022213] [Batch 00007/00026] [00:00:09/00:00:22, 1.233s/it]
[2025-08-26 02:14:45,173][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 022213] [Batch 00015/00026] [00:00:20/00:00:12, 1.284s/it]
[2025-08-26 02:14:55,832][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 022213] [Batch 00023/00026] [00:00:31/00:00:02, 1.300s/it]
[2025-08-26 02:14:58,579][__main__][INFO] - [VALIDATION] [Epoch 17/29] train_loss=1.22465, valid_loss=1.53952
[2025-08-26 02:14:58,580][__main__][INFO] - [VALIDATION] [Epoch 17/29] Metrics:
[2025-08-26 02:14:58,580][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_er      0.628
[2025-08-26 02:14:58,580][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_prec    0.056
[2025-08-26 02:14:58,580][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_recall  0.057
[2025-08-26 02:14:58,580][__main__][INFO] - [VALIDATION] [Epoch 17/29] - pep_recall 0.016
[2025-08-26 02:14:58,582][__main__][INFO] - [TRAIN] [Epoch 17/29] Epoch complete, total time 04:24:07, remaining time 02:56:05, 00:14:40 per epoch
[2025-08-26 02:15:00,978][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022216] [Batch 00004/01234] [00:00:02/00:11:22, 0.555s/it]: train_loss_raw=1.1818, running_loss=1.1904, LR=0.000100
[2025-08-26 02:15:06,304][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022224] [Batch 00012/01234] [00:00:07/00:12:48, 0.629s/it]: train_loss_raw=1.2102, running_loss=1.1857, LR=0.000100
[2025-08-26 02:15:11,761][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022232] [Batch 00020/01234] [00:00:13/00:13:09, 0.650s/it]: train_loss_raw=1.1387, running_loss=1.1839, LR=0.000100
[2025-08-26 02:15:17,138][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022240] [Batch 00028/01234] [00:00:18/00:13:11, 0.656s/it]: train_loss_raw=1.0949, running_loss=1.1792, LR=0.000100
[2025-08-26 02:15:22,647][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022248] [Batch 00036/01234] [00:00:23/00:13:14, 0.664s/it]: train_loss_raw=1.1833, running_loss=1.1767, LR=0.000100
[2025-08-26 02:15:27,801][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022256] [Batch 00044/01234] [00:00:29/00:13:05, 0.660s/it]: train_loss_raw=1.1656, running_loss=1.1739, LR=0.000100
[2025-08-26 02:15:33,219][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022264] [Batch 00052/01234] [00:00:34/00:13:03, 0.663s/it]: train_loss_raw=1.2245, running_loss=1.1733, LR=0.000100
[2025-08-26 02:15:38,327][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022272] [Batch 00060/01234] [00:00:39/00:12:54, 0.659s/it]: train_loss_raw=1.1551, running_loss=1.1716, LR=0.000100
[2025-08-26 02:15:43,412][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022280] [Batch 00068/01234] [00:00:44/00:12:45, 0.657s/it]: train_loss_raw=1.1890, running_loss=1.1695, LR=0.000100
[2025-08-26 02:15:48,513][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022288] [Batch 00076/01234] [00:00:49/00:12:38, 0.655s/it]: train_loss_raw=1.0847, running_loss=1.1671, LR=0.000100
[2025-08-26 02:15:54,035][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022296] [Batch 00084/01234] [00:00:55/00:12:36, 0.658s/it]: train_loss_raw=1.0845, running_loss=1.1656, LR=0.000100
[2025-08-26 02:15:59,360][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022304] [Batch 00092/01234] [00:01:00/00:12:32, 0.659s/it]: train_loss_raw=1.1880, running_loss=1.1651, LR=0.000100
[2025-08-26 02:16:04,781][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022312] [Batch 00100/01234] [00:01:06/00:12:28, 0.660s/it]: train_loss_raw=1.1447, running_loss=1.1644, LR=0.000100
[2025-08-26 02:16:10,799][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022320] [Batch 00108/01234] [00:01:12/00:12:31, 0.667s/it]: train_loss_raw=1.1679, running_loss=1.1642, LR=0.000100
[2025-08-26 02:16:16,165][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022328] [Batch 00116/01234] [00:01:17/00:12:26, 0.667s/it]: train_loss_raw=1.1967, running_loss=1.1643, LR=0.000100
[2025-08-26 02:16:21,278][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022336] [Batch 00124/01234] [00:01:22/00:12:18, 0.665s/it]: train_loss_raw=1.1702, running_loss=1.1635, LR=0.000100
[2025-08-26 02:16:26,593][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022344] [Batch 00132/01234] [00:01:27/00:12:13, 0.665s/it]: train_loss_raw=1.1946, running_loss=1.1623, LR=0.000100
[2025-08-26 02:16:32,088][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022352] [Batch 00140/01234] [00:01:33/00:12:09, 0.667s/it]: train_loss_raw=1.1655, running_loss=1.1609, LR=0.000100
[2025-08-26 02:16:37,661][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022360] [Batch 00148/01234] [00:01:38/00:12:05, 0.668s/it]: train_loss_raw=1.1761, running_loss=1.1616, LR=0.000100
[2025-08-26 02:16:43,211][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022368] [Batch 00156/01234] [00:01:44/00:12:01, 0.670s/it]: train_loss_raw=1.1235, running_loss=1.1600, LR=0.000100
[2025-08-26 02:16:48,719][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022376] [Batch 00164/01234] [00:01:49/00:11:57, 0.670s/it]: train_loss_raw=1.2120, running_loss=1.1593, LR=0.000100
[2025-08-26 02:16:54,402][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022384] [Batch 00172/01234] [00:01:55/00:11:54, 0.672s/it]: train_loss_raw=1.0719, running_loss=1.1562, LR=0.000100
[2025-08-26 02:17:00,199][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022392] [Batch 00180/01234] [00:02:01/00:11:51, 0.675s/it]: train_loss_raw=1.1080, running_loss=1.1582, LR=0.000100
[2025-08-26 02:17:05,953][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022400] [Batch 00188/01234] [00:02:07/00:11:47, 0.677s/it]: train_loss_raw=1.1335, running_loss=1.1567, LR=0.000100
[2025-08-26 02:17:11,601][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022408] [Batch 00196/01234] [00:02:12/00:11:43, 0.678s/it]: train_loss_raw=1.1362, running_loss=1.1543, LR=0.000100
[2025-08-26 02:17:16,819][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022416] [Batch 00204/01234] [00:02:18/00:11:37, 0.677s/it]: train_loss_raw=1.1510, running_loss=1.1561, LR=0.000100
[2025-08-26 02:17:22,144][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022424] [Batch 00212/01234] [00:02:23/00:11:31, 0.676s/it]: train_loss_raw=1.1792, running_loss=1.1564, LR=0.000100
[2025-08-26 02:17:28,009][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022432] [Batch 00220/01234] [00:02:29/00:11:27, 0.678s/it]: train_loss_raw=1.1055, running_loss=1.1557, LR=0.000100
[2025-08-26 02:17:33,619][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022440] [Batch 00228/01234] [00:02:34/00:11:23, 0.679s/it]: train_loss_raw=1.1456, running_loss=1.1560, LR=0.000100
[2025-08-26 02:17:39,151][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022448] [Batch 00236/01234] [00:02:40/00:11:18, 0.680s/it]: train_loss_raw=1.1853, running_loss=1.1569, LR=0.000100
[2025-08-26 02:17:44,559][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022456] [Batch 00244/01234] [00:02:45/00:11:12, 0.680s/it]: train_loss_raw=1.1804, running_loss=1.1557, LR=0.000100
[2025-08-26 02:17:49,742][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022464] [Batch 00252/01234] [00:02:50/00:11:06, 0.679s/it]: train_loss_raw=1.1426, running_loss=1.1569, LR=0.000100
[2025-08-26 02:17:55,522][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022472] [Batch 00260/01234] [00:02:56/00:11:02, 0.680s/it]: train_loss_raw=1.3116, running_loss=1.1589, LR=0.000100
[2025-08-26 02:18:01,139][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022480] [Batch 00268/01234] [00:03:02/00:10:57, 0.681s/it]: train_loss_raw=1.1506, running_loss=1.1586, LR=0.000100
[2025-08-26 02:18:06,201][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022488] [Batch 00276/01234] [00:03:07/00:10:50, 0.679s/it]: train_loss_raw=1.2033, running_loss=1.1597, LR=0.000100
[2025-08-26 02:18:11,266][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022496] [Batch 00284/01234] [00:03:12/00:10:43, 0.678s/it]: train_loss_raw=1.1961, running_loss=1.1624, LR=0.000100
[2025-08-26 02:18:17,141][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022504] [Batch 00292/01234] [00:03:18/00:10:39, 0.679s/it]: train_loss_raw=1.2733, running_loss=1.1652, LR=0.000100
[2025-08-26 02:18:22,703][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022512] [Batch 00300/01234] [00:03:23/00:10:34, 0.680s/it]: train_loss_raw=1.1838, running_loss=1.1672, LR=0.000100
[2025-08-26 02:18:27,794][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022520] [Batch 00308/01234] [00:03:29/00:10:28, 0.679s/it]: train_loss_raw=1.2103, running_loss=1.1675, LR=0.000100
[2025-08-26 02:18:33,457][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022528] [Batch 00316/01234] [00:03:34/00:10:23, 0.679s/it]: train_loss_raw=1.1232, running_loss=1.1662, LR=0.000100
[2025-08-26 02:18:38,575][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022536] [Batch 00324/01234] [00:03:39/00:10:17, 0.678s/it]: train_loss_raw=1.1626, running_loss=1.1675, LR=0.000100
[2025-08-26 02:18:43,675][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022544] [Batch 00332/01234] [00:03:44/00:10:11, 0.677s/it]: train_loss_raw=1.1937, running_loss=1.1671, LR=0.000100
[2025-08-26 02:18:49,059][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022552] [Batch 00340/01234] [00:03:50/00:10:05, 0.677s/it]: train_loss_raw=1.1703, running_loss=1.1668, LR=0.000100
[2025-08-26 02:18:54,460][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022560] [Batch 00348/01234] [00:03:55/00:10:00, 0.677s/it]: train_loss_raw=1.1175, running_loss=1.1661, LR=0.000100
[2025-08-26 02:18:59,710][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022568] [Batch 00356/01234] [00:04:00/00:09:54, 0.677s/it]: train_loss_raw=1.0759, running_loss=1.1663, LR=0.000100
[2025-08-26 02:19:04,778][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022576] [Batch 00364/01234] [00:04:06/00:09:48, 0.676s/it]: train_loss_raw=1.1622, running_loss=1.1653, LR=0.000100
[2025-08-26 02:19:10,092][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022584] [Batch 00372/01234] [00:04:11/00:09:42, 0.676s/it]: train_loss_raw=1.1936, running_loss=1.1666, LR=0.000100
[2025-08-26 02:19:15,308][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022592] [Batch 00380/01234] [00:04:16/00:09:36, 0.675s/it]: train_loss_raw=1.1747, running_loss=1.1661, LR=0.000100
[2025-08-26 02:19:20,775][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022600] [Batch 00388/01234] [00:04:22/00:09:31, 0.675s/it]: train_loss_raw=1.1387, running_loss=1.1682, LR=0.000100
[2025-08-26 02:19:25,890][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022608] [Batch 00396/01234] [00:04:27/00:09:25, 0.675s/it]: train_loss_raw=1.0863, running_loss=1.1681, LR=0.000100
[2025-08-26 02:19:30,961][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022616] [Batch 00404/01234] [00:04:32/00:09:19, 0.674s/it]: train_loss_raw=1.2238, running_loss=1.1716, LR=0.000100
[2025-08-26 02:19:36,413][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022624] [Batch 00412/01234] [00:04:37/00:09:13, 0.674s/it]: train_loss_raw=1.1365, running_loss=1.1707, LR=0.000100
[2025-08-26 02:19:42,070][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022632] [Batch 00420/01234] [00:04:43/00:09:09, 0.675s/it]: train_loss_raw=1.2286, running_loss=1.1716, LR=0.000100
[2025-08-26 02:19:47,453][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022640] [Batch 00428/01234] [00:04:48/00:09:03, 0.675s/it]: train_loss_raw=1.1323, running_loss=1.1727, LR=0.000100
[2025-08-26 02:19:53,097][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022648] [Batch 00436/01234] [00:04:54/00:08:58, 0.675s/it]: train_loss_raw=1.2344, running_loss=1.1740, LR=0.000100
[2025-08-26 02:19:58,467][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022656] [Batch 00444/01234] [00:04:59/00:08:53, 0.675s/it]: train_loss_raw=1.2941, running_loss=1.1751, LR=0.000100
[2025-08-26 02:20:03,930][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022664] [Batch 00452/01234] [00:05:05/00:08:47, 0.675s/it]: train_loss_raw=1.2673, running_loss=1.1766, LR=0.000100
[2025-08-26 02:20:08,976][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022672] [Batch 00460/01234] [00:05:10/00:08:41, 0.674s/it]: train_loss_raw=1.1517, running_loss=1.1773, LR=0.000100
[2025-08-26 02:20:14,722][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022680] [Batch 00468/01234] [00:05:15/00:08:37, 0.675s/it]: train_loss_raw=1.1454, running_loss=1.1787, LR=0.000100
[2025-08-26 02:20:20,355][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022688] [Batch 00476/01234] [00:05:21/00:08:32, 0.676s/it]: train_loss_raw=1.1327, running_loss=1.1779, LR=0.000100
[2025-08-26 02:20:25,441][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022696] [Batch 00484/01234] [00:05:26/00:08:26, 0.675s/it]: train_loss_raw=1.1872, running_loss=1.1765, LR=0.000100
[2025-08-26 02:20:30,517][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022704] [Batch 00492/01234] [00:05:31/00:08:20, 0.674s/it]: train_loss_raw=1.1475, running_loss=1.1754, LR=0.000100
[2025-08-26 02:20:36,113][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022712] [Batch 00500/01234] [00:05:37/00:08:15, 0.675s/it]: train_loss_raw=1.2492, running_loss=1.1784, LR=0.000100
[2025-08-26 02:20:41,770][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022720] [Batch 00508/01234] [00:05:43/00:08:10, 0.675s/it]: train_loss_raw=1.1335, running_loss=1.1781, LR=0.000100
[2025-08-26 02:20:46,844][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022728] [Batch 00516/01234] [00:05:48/00:08:04, 0.675s/it]: train_loss_raw=1.1218, running_loss=1.1754, LR=0.000100
[2025-08-26 02:20:52,596][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022736] [Batch 00524/01234] [00:05:53/00:07:59, 0.675s/it]: train_loss_raw=1.1635, running_loss=1.1740, LR=0.000100
[2025-08-26 02:20:57,716][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022744] [Batch 00532/01234] [00:05:58/00:07:53, 0.675s/it]: train_loss_raw=1.0959, running_loss=1.1761, LR=0.000100
[2025-08-26 02:21:02,835][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022752] [Batch 00540/01234] [00:06:04/00:07:47, 0.674s/it]: train_loss_raw=1.2153, running_loss=1.1729, LR=0.000100
[2025-08-26 02:21:07,913][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022760] [Batch 00548/01234] [00:06:09/00:07:42, 0.674s/it]: train_loss_raw=1.2210, running_loss=1.1732, LR=0.000100
[2025-08-26 02:21:13,250][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022768] [Batch 00556/01234] [00:06:14/00:07:36, 0.674s/it]: train_loss_raw=1.2064, running_loss=1.1741, LR=0.000100
[2025-08-26 02:21:19,064][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022776] [Batch 00564/01234] [00:06:20/00:07:31, 0.674s/it]: train_loss_raw=1.2719, running_loss=1.1760, LR=0.000100
[2025-08-26 02:21:24,170][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022784] [Batch 00572/01234] [00:06:25/00:07:26, 0.674s/it]: train_loss_raw=1.3481, running_loss=1.1785, LR=0.000100
[2025-08-26 02:21:29,287][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022792] [Batch 00580/01234] [00:06:30/00:07:20, 0.673s/it]: train_loss_raw=1.1926, running_loss=1.1788, LR=0.000100
[2025-08-26 02:21:35,039][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022800] [Batch 00588/01234] [00:06:36/00:07:15, 0.674s/it]: train_loss_raw=1.2614, running_loss=1.1799, LR=0.000100
[2025-08-26 02:21:40,460][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022808] [Batch 00596/01234] [00:06:41/00:07:10, 0.674s/it]: train_loss_raw=1.3260, running_loss=1.1809, LR=0.000100
[2025-08-26 02:21:45,546][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022816] [Batch 00604/01234] [00:06:46/00:07:04, 0.673s/it]: train_loss_raw=1.2030, running_loss=1.1803, LR=0.000100
[2025-08-26 02:21:51,011][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022824] [Batch 00612/01234] [00:06:52/00:06:58, 0.674s/it]: train_loss_raw=1.1837, running_loss=1.1804, LR=0.000100
[2025-08-26 02:21:56,377][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022832] [Batch 00620/01234] [00:06:57/00:06:53, 0.674s/it]: train_loss_raw=1.1985, running_loss=1.1826, LR=0.000100
[2025-08-26 02:22:01,577][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022840] [Batch 00628/01234] [00:07:02/00:06:48, 0.673s/it]: train_loss_raw=1.1168, running_loss=1.1817, LR=0.000100
[2025-08-26 02:22:06,793][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022848] [Batch 00636/01234] [00:07:08/00:06:42, 0.673s/it]: train_loss_raw=1.1025, running_loss=1.1825, LR=0.000100
[2025-08-26 02:22:11,843][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022856] [Batch 00644/01234] [00:07:13/00:06:36, 0.672s/it]: train_loss_raw=1.1988, running_loss=1.1812, LR=0.000100
[2025-08-26 02:22:16,888][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022864] [Batch 00652/01234] [00:07:18/00:06:31, 0.672s/it]: train_loss_raw=1.1593, running_loss=1.1826, LR=0.000100
[2025-08-26 02:22:21,933][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022872] [Batch 00660/01234] [00:07:23/00:06:25, 0.671s/it]: train_loss_raw=1.2349, running_loss=1.1841, LR=0.000100
[2025-08-26 02:22:26,998][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022880] [Batch 00668/01234] [00:07:28/00:06:19, 0.671s/it]: train_loss_raw=1.1909, running_loss=1.1866, LR=0.000100
[2025-08-26 02:22:32,056][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022888] [Batch 00676/01234] [00:07:33/00:06:14, 0.671s/it]: train_loss_raw=1.1702, running_loss=1.1873, LR=0.000100
[2025-08-26 02:22:37,408][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022896] [Batch 00684/01234] [00:07:38/00:06:08, 0.671s/it]: train_loss_raw=1.2334, running_loss=1.1880, LR=0.000100
[2025-08-26 02:22:42,959][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022904] [Batch 00692/01234] [00:07:44/00:06:03, 0.671s/it]: train_loss_raw=1.1936, running_loss=1.1887, LR=0.000100
[2025-08-26 02:22:48,888][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022912] [Batch 00700/01234] [00:07:50/00:05:58, 0.672s/it]: train_loss_raw=1.1926, running_loss=1.1890, LR=0.000100
[2025-08-26 02:22:54,492][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022920] [Batch 00708/01234] [00:07:55/00:05:53, 0.672s/it]: train_loss_raw=1.1748, running_loss=1.1869, LR=0.000100
[2025-08-26 02:23:00,246][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022928] [Batch 00716/01234] [00:08:01/00:05:48, 0.672s/it]: train_loss_raw=1.2260, running_loss=1.1886, LR=0.000100
[2025-08-26 02:23:06,282][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022936] [Batch 00724/01234] [00:08:07/00:05:43, 0.673s/it]: train_loss_raw=1.1840, running_loss=1.1897, LR=0.000100
[2025-08-26 02:23:11,999][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022944] [Batch 00732/01234] [00:08:13/00:05:38, 0.674s/it]: train_loss_raw=1.2016, running_loss=1.1892, LR=0.000100
[2025-08-26 02:23:17,098][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022952] [Batch 00740/01234] [00:08:18/00:05:32, 0.673s/it]: train_loss_raw=1.2680, running_loss=1.1901, LR=0.000100
[2025-08-26 02:23:22,937][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022960] [Batch 00748/01234] [00:08:24/00:05:27, 0.674s/it]: train_loss_raw=1.1644, running_loss=1.1907, LR=0.000100
[2025-08-26 02:23:28,542][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022968] [Batch 00756/01234] [00:08:29/00:05:22, 0.674s/it]: train_loss_raw=1.1776, running_loss=1.1903, LR=0.000100
[2025-08-26 02:23:33,630][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022976] [Batch 00764/01234] [00:08:34/00:05:16, 0.674s/it]: train_loss_raw=1.2973, running_loss=1.1935, LR=0.000100
[2025-08-26 02:23:39,220][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022984] [Batch 00772/01234] [00:08:40/00:05:11, 0.674s/it]: train_loss_raw=1.2612, running_loss=1.1937, LR=0.000100
[2025-08-26 02:23:44,295][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 022992] [Batch 00780/01234] [00:08:45/00:05:05, 0.674s/it]: train_loss_raw=1.2483, running_loss=1.1933, LR=0.000100
[2025-08-26 02:23:50,077][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023000] [Batch 00788/01234] [00:08:51/00:05:00, 0.674s/it]: train_loss_raw=1.2196, running_loss=1.1936, LR=0.000100
[2025-08-26 02:23:55,962][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023008] [Batch 00796/01234] [00:08:57/00:04:55, 0.675s/it]: train_loss_raw=1.2013, running_loss=1.1919, LR=0.000100
[2025-08-26 02:24:01,205][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023016] [Batch 00804/01234] [00:09:02/00:04:50, 0.675s/it]: train_loss_raw=1.1911, running_loss=1.1913, LR=0.000100
[2025-08-26 02:24:06,890][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023024] [Batch 00812/01234] [00:09:08/00:04:44, 0.675s/it]: train_loss_raw=1.1535, running_loss=1.1911, LR=0.000100
[2025-08-26 02:24:12,301][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023032] [Batch 00820/01234] [00:09:13/00:04:39, 0.675s/it]: train_loss_raw=1.2074, running_loss=1.1904, LR=0.000100
[2025-08-26 02:24:17,458][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023040] [Batch 00828/01234] [00:09:18/00:04:33, 0.675s/it]: train_loss_raw=1.2622, running_loss=1.1931, LR=0.000100
[2025-08-26 02:24:22,747][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023048] [Batch 00836/01234] [00:09:23/00:04:28, 0.675s/it]: train_loss_raw=1.2301, running_loss=1.1937, LR=0.000100
[2025-08-26 02:24:27,819][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023056] [Batch 00844/01234] [00:09:29/00:04:22, 0.674s/it]: train_loss_raw=1.2072, running_loss=1.1941, LR=0.000100
[2025-08-26 02:24:32,904][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023064] [Batch 00852/01234] [00:09:34/00:04:17, 0.674s/it]: train_loss_raw=1.2324, running_loss=1.1946, LR=0.000100
[2025-08-26 02:24:37,998][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023072] [Batch 00860/01234] [00:09:39/00:04:11, 0.674s/it]: train_loss_raw=1.0926, running_loss=1.1905, LR=0.000100
[2025-08-26 02:24:43,173][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023080] [Batch 00868/01234] [00:09:44/00:04:06, 0.673s/it]: train_loss_raw=1.0885, running_loss=1.1927, LR=0.000100
[2025-08-26 02:24:48,406][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023088] [Batch 00876/01234] [00:09:49/00:04:00, 0.673s/it]: train_loss_raw=1.1151, running_loss=1.1921, LR=0.000100
[2025-08-26 02:24:53,608][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023096] [Batch 00884/01234] [00:09:54/00:03:55, 0.673s/it]: train_loss_raw=1.3006, running_loss=1.1925, LR=0.000100
[2025-08-26 02:24:58,726][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023104] [Batch 00892/01234] [00:09:59/00:03:50, 0.673s/it]: train_loss_raw=1.1532, running_loss=1.1966, LR=0.000100
[2025-08-26 02:25:03,965][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023112] [Batch 00900/01234] [00:10:05/00:03:44, 0.672s/it]: train_loss_raw=1.1980, running_loss=1.1959, LR=0.000100
[2025-08-26 02:25:09,430][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023120] [Batch 00908/01234] [00:10:10/00:03:39, 0.673s/it]: train_loss_raw=1.0866, running_loss=1.1963, LR=0.000100
[2025-08-26 02:25:14,713][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023128] [Batch 00916/01234] [00:10:15/00:03:33, 0.672s/it]: train_loss_raw=1.2083, running_loss=1.1964, LR=0.000100
[2025-08-26 02:25:20,189][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023136] [Batch 00924/01234] [00:10:21/00:03:28, 0.673s/it]: train_loss_raw=1.1673, running_loss=1.1957, LR=0.000100
[2025-08-26 02:25:25,700][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023144] [Batch 00932/01234] [00:10:26/00:03:23, 0.673s/it]: train_loss_raw=1.2267, running_loss=1.1964, LR=0.000100
[2025-08-26 02:25:31,332][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023152] [Batch 00940/01234] [00:10:32/00:03:17, 0.673s/it]: train_loss_raw=1.2664, running_loss=1.1988, LR=0.000100
[2025-08-26 02:25:37,011][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023160] [Batch 00948/01234] [00:10:38/00:03:12, 0.673s/it]: train_loss_raw=1.1576, running_loss=1.1959, LR=0.000100
[2025-08-26 02:25:42,622][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023168] [Batch 00956/01234] [00:10:43/00:03:07, 0.673s/it]: train_loss_raw=1.1670, running_loss=1.1955, LR=0.000100
[2025-08-26 02:25:47,938][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023176] [Batch 00964/01234] [00:10:49/00:03:01, 0.673s/it]: train_loss_raw=1.1072, running_loss=1.1944, LR=0.000100
[2025-08-26 02:25:53,391][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023184] [Batch 00972/01234] [00:10:54/00:02:56, 0.673s/it]: train_loss_raw=1.2432, running_loss=1.1958, LR=0.000100
[2025-08-26 02:25:58,822][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023192] [Batch 00980/01234] [00:11:00/00:02:51, 0.674s/it]: train_loss_raw=1.1394, running_loss=1.1941, LR=0.000100
[2025-08-26 02:26:03,877][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023200] [Batch 00988/01234] [00:11:05/00:02:45, 0.673s/it]: train_loss_raw=1.2535, running_loss=1.1941, LR=0.000100
[2025-08-26 02:26:09,361][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023208] [Batch 00996/01234] [00:11:10/00:02:40, 0.673s/it]: train_loss_raw=1.0826, running_loss=1.1915, LR=0.000100
[2025-08-26 02:26:15,044][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023216] [Batch 01004/01234] [00:11:16/00:02:34, 0.674s/it]: train_loss_raw=1.1492, running_loss=1.1901, LR=0.000100
[2025-08-26 02:26:20,259][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023224] [Batch 01012/01234] [00:11:21/00:02:29, 0.673s/it]: train_loss_raw=1.2936, running_loss=1.1903, LR=0.000100
[2025-08-26 02:26:25,366][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023232] [Batch 01020/01234] [00:11:26/00:02:24, 0.673s/it]: train_loss_raw=1.1207, running_loss=1.1878, LR=0.000100
[2025-08-26 02:26:30,529][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023240] [Batch 01028/01234] [00:11:31/00:02:18, 0.673s/it]: train_loss_raw=1.0823, running_loss=1.1880, LR=0.000100
[2025-08-26 02:26:36,230][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023248] [Batch 01036/01234] [00:11:37/00:02:13, 0.673s/it]: train_loss_raw=1.2013, running_loss=1.1898, LR=0.000100
[2025-08-26 02:26:41,674][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023256] [Batch 01044/01234] [00:11:42/00:02:07, 0.673s/it]: train_loss_raw=1.0975, running_loss=1.1878, LR=0.000100
[2025-08-26 02:26:47,196][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023264] [Batch 01052/01234] [00:11:48/00:02:02, 0.673s/it]: train_loss_raw=1.2112, running_loss=1.1892, LR=0.000100
[2025-08-26 02:26:52,298][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023272] [Batch 01060/01234] [00:11:53/00:01:57, 0.673s/it]: train_loss_raw=1.2487, running_loss=1.1893, LR=0.000100
[2025-08-26 02:26:57,386][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023280] [Batch 01068/01234] [00:11:58/00:01:51, 0.673s/it]: train_loss_raw=1.2196, running_loss=1.1913, LR=0.000100
[2025-08-26 02:27:02,880][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023288] [Batch 01076/01234] [00:12:04/00:01:46, 0.673s/it]: train_loss_raw=1.1788, running_loss=1.1927, LR=0.000100
[2025-08-26 02:27:08,042][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023296] [Batch 01084/01234] [00:12:09/00:01:40, 0.673s/it]: train_loss_raw=1.3001, running_loss=1.1926, LR=0.000100
[2025-08-26 02:27:13,573][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023304] [Batch 01092/01234] [00:12:14/00:01:35, 0.673s/it]: train_loss_raw=1.2230, running_loss=1.1881, LR=0.000100
[2025-08-26 02:27:18,669][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023312] [Batch 01100/01234] [00:12:19/00:01:30, 0.673s/it]: train_loss_raw=1.2078, running_loss=1.1879, LR=0.000100
[2025-08-26 02:27:23,753][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023320] [Batch 01108/01234] [00:12:24/00:01:24, 0.672s/it]: train_loss_raw=1.1262, running_loss=1.1863, LR=0.000100
[2025-08-26 02:27:28,840][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023328] [Batch 01116/01234] [00:12:30/00:01:19, 0.672s/it]: train_loss_raw=1.2126, running_loss=1.1880, LR=0.000100
[2025-08-26 02:27:33,919][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023336] [Batch 01124/01234] [00:12:35/00:01:13, 0.672s/it]: train_loss_raw=1.1459, running_loss=1.1881, LR=0.000100
[2025-08-26 02:27:39,000][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023344] [Batch 01132/01234] [00:12:40/00:01:08, 0.672s/it]: train_loss_raw=1.2077, running_loss=1.1892, LR=0.000100
[2025-08-26 02:27:44,115][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023352] [Batch 01140/01234] [00:12:45/00:01:03, 0.671s/it]: train_loss_raw=1.2256, running_loss=1.1871, LR=0.000100
[2025-08-26 02:27:49,196][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023360] [Batch 01148/01234] [00:12:50/00:00:57, 0.671s/it]: train_loss_raw=1.1595, running_loss=1.1875, LR=0.000100
[2025-08-26 02:27:54,273][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023368] [Batch 01156/01234] [00:12:55/00:00:52, 0.671s/it]: train_loss_raw=1.1166, running_loss=1.1859, LR=0.000100
[2025-08-26 02:27:59,407][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023376] [Batch 01164/01234] [00:13:00/00:00:46, 0.671s/it]: train_loss_raw=1.0935, running_loss=1.1828, LR=0.000100
[2025-08-26 02:28:04,602][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023384] [Batch 01172/01234] [00:13:05/00:00:41, 0.671s/it]: train_loss_raw=1.1823, running_loss=1.1838, LR=0.000100
[2025-08-26 02:28:09,709][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023392] [Batch 01180/01234] [00:13:10/00:00:36, 0.670s/it]: train_loss_raw=1.1533, running_loss=1.1841, LR=0.000100
[2025-08-26 02:28:15,549][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023400] [Batch 01188/01234] [00:13:16/00:00:30, 0.671s/it]: train_loss_raw=1.2593, running_loss=1.1845, LR=0.000100
[2025-08-26 02:28:21,212][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023408] [Batch 01196/01234] [00:13:22/00:00:25, 0.671s/it]: train_loss_raw=1.2541, running_loss=1.1860, LR=0.000100
[2025-08-26 02:28:26,946][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023416] [Batch 01204/01234] [00:13:28/00:00:20, 0.671s/it]: train_loss_raw=1.0954, running_loss=1.1866, LR=0.000100
[2025-08-26 02:28:32,337][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023424] [Batch 01212/01234] [00:13:33/00:00:14, 0.671s/it]: train_loss_raw=1.2440, running_loss=1.1881, LR=0.000100
[2025-08-26 02:28:38,137][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023432] [Batch 01220/01234] [00:13:39/00:00:09, 0.672s/it]: train_loss_raw=1.2122, running_loss=1.1894, LR=0.000100
[2025-08-26 02:28:43,817][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 023440] [Batch 01228/01234] [00:13:45/00:00:04, 0.672s/it]: train_loss_raw=1.2010, running_loss=1.1872, LR=0.000100
[2025-08-26 02:28:53,139][__main__][INFO] - [VALIDATION] [Epoch 18/29] Starting validation.
[2025-08-26 02:29:03,407][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 023447] [Batch 00007/00026] [00:00:10/00:00:23, 1.283s/it]
[2025-08-26 02:29:13,729][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 023447] [Batch 00015/00026] [00:00:20/00:00:12, 1.287s/it]
[2025-08-26 02:29:24,040][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 023447] [Batch 00023/00026] [00:00:30/00:00:02, 1.287s/it]
[2025-08-26 02:29:26,331][__main__][INFO] - [VALIDATION] [Epoch 18/29] train_loss=1.18590, valid_loss=1.50506
[2025-08-26 02:29:26,331][__main__][INFO] - [VALIDATION] [Epoch 18/29] Metrics:
[2025-08-26 02:29:26,331][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_er      0.610
[2025-08-26 02:29:26,331][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_prec    0.051
[2025-08-26 02:29:26,331][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_recall  0.051
[2025-08-26 02:29:26,331][__main__][INFO] - [VALIDATION] [Epoch 18/29] - pep_recall 0.014
[2025-08-26 02:29:26,333][__main__][INFO] - [TRAIN] [Epoch 18/29] Epoch complete, total time 04:38:35, remaining time 02:41:17, 00:14:39 per epoch
[2025-08-26 02:29:27,245][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023448] [Batch 00002/01234] [00:00:00/00:07:59, 0.389s/it]: train_loss_raw=1.0915, running_loss=1.0941, LR=0.000100
[2025-08-26 02:29:32,435][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023456] [Batch 00010/01234] [00:00:05/00:12:10, 0.597s/it]: train_loss_raw=1.0490, running_loss=1.0950, LR=0.000100
[2025-08-26 02:29:38,097][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023464] [Batch 00018/01234] [00:00:11/00:13:05, 0.646s/it]: train_loss_raw=1.0164, running_loss=1.0965, LR=0.000100
[2025-08-26 02:29:43,226][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023472] [Batch 00026/01234] [00:00:16/00:12:58, 0.645s/it]: train_loss_raw=1.0915, running_loss=1.0972, LR=0.000100
[2025-08-26 02:29:48,594][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023480] [Batch 00034/01234] [00:00:22/00:13:00, 0.651s/it]: train_loss_raw=1.1992, running_loss=1.1005, LR=0.000100
[2025-08-26 02:29:53,831][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023488] [Batch 00042/01234] [00:00:27/00:12:56, 0.652s/it]: train_loss_raw=1.1788, running_loss=1.1012, LR=0.000100
[2025-08-26 02:29:59,313][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023496] [Batch 00050/01234] [00:00:32/00:12:57, 0.657s/it]: train_loss_raw=1.0294, running_loss=1.1013, LR=0.000100
[2025-08-26 02:30:04,735][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023504] [Batch 00058/01234] [00:00:38/00:12:55, 0.660s/it]: train_loss_raw=1.1382, running_loss=1.1029, LR=0.000100
[2025-08-26 02:30:09,836][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023512] [Batch 00066/01234] [00:00:43/00:12:47, 0.657s/it]: train_loss_raw=1.2249, running_loss=1.1034, LR=0.000100
[2025-08-26 02:30:15,021][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023520] [Batch 00074/01234] [00:00:48/00:12:41, 0.656s/it]: train_loss_raw=1.0690, running_loss=1.1025, LR=0.000100
[2025-08-26 02:30:20,408][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023528] [Batch 00082/01234] [00:00:53/00:12:37, 0.658s/it]: train_loss_raw=1.1542, running_loss=1.1020, LR=0.000100
[2025-08-26 02:30:25,709][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023536] [Batch 00090/01234] [00:00:59/00:12:33, 0.658s/it]: train_loss_raw=1.0841, running_loss=1.1033, LR=0.000100
[2025-08-26 02:30:30,903][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023544] [Batch 00098/01234] [00:01:04/00:12:26, 0.658s/it]: train_loss_raw=1.0669, running_loss=1.1043, LR=0.000100
[2025-08-26 02:30:36,479][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023552] [Batch 00106/01234] [00:01:10/00:12:25, 0.660s/it]: train_loss_raw=1.1431, running_loss=1.1052, LR=0.000100
[2025-08-26 02:30:41,571][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023560] [Batch 00114/01234] [00:01:15/00:12:17, 0.659s/it]: train_loss_raw=1.1547, running_loss=1.1050, LR=0.000100
[2025-08-26 02:30:46,676][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023568] [Batch 00122/01234] [00:01:20/00:12:11, 0.657s/it]: train_loss_raw=1.0785, running_loss=1.1064, LR=0.000100
[2025-08-26 02:30:52,321][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023576] [Batch 00130/01234] [00:01:25/00:12:09, 0.660s/it]: train_loss_raw=1.1287, running_loss=1.1074, LR=0.000100
[2025-08-26 02:30:57,501][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023584] [Batch 00138/01234] [00:01:31/00:12:02, 0.660s/it]: train_loss_raw=1.1310, running_loss=1.1066, LR=0.000100
[2025-08-26 02:31:03,353][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023592] [Batch 00146/01234] [00:01:36/00:12:02, 0.664s/it]: train_loss_raw=1.0659, running_loss=1.1060, LR=0.000100
[2025-08-26 02:31:09,350][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023600] [Batch 00154/01234] [00:01:42/00:12:01, 0.668s/it]: train_loss_raw=1.0552, running_loss=1.1070, LR=0.000100
[2025-08-26 02:31:14,864][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023608] [Batch 00162/01234] [00:01:48/00:11:57, 0.669s/it]: train_loss_raw=1.1688, running_loss=1.1078, LR=0.000100
[2025-08-26 02:31:20,204][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023616] [Batch 00170/01234] [00:01:53/00:11:51, 0.669s/it]: train_loss_raw=1.2188, running_loss=1.1120, LR=0.000100
[2025-08-26 02:31:25,509][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023624] [Batch 00178/01234] [00:01:59/00:11:46, 0.669s/it]: train_loss_raw=1.0686, running_loss=1.1105, LR=0.000100
[2025-08-26 02:31:30,607][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023632] [Batch 00186/01234] [00:02:04/00:11:39, 0.667s/it]: train_loss_raw=1.1757, running_loss=1.1115, LR=0.000100
[2025-08-26 02:31:35,690][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023640] [Batch 00194/01234] [00:02:09/00:11:32, 0.666s/it]: train_loss_raw=1.1036, running_loss=1.1115, LR=0.000100
[2025-08-26 02:31:40,777][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023648] [Batch 00202/01234] [00:02:14/00:11:26, 0.665s/it]: train_loss_raw=1.0473, running_loss=1.1110, LR=0.000100
[2025-08-26 02:31:46,092][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023656] [Batch 00210/01234] [00:02:19/00:11:20, 0.665s/it]: train_loss_raw=1.0234, running_loss=1.1116, LR=0.000100
[2025-08-26 02:31:51,176][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023664] [Batch 00218/01234] [00:02:24/00:11:14, 0.664s/it]: train_loss_raw=1.1470, running_loss=1.1120, LR=0.000100
[2025-08-26 02:31:56,471][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023672] [Batch 00226/01234] [00:02:30/00:11:09, 0.664s/it]: train_loss_raw=1.1785, running_loss=1.1145, LR=0.000100
[2025-08-26 02:32:01,713][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023680] [Batch 00234/01234] [00:02:35/00:11:03, 0.663s/it]: train_loss_raw=1.0860, running_loss=1.1141, LR=0.000100
[2025-08-26 02:32:06,944][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023688] [Batch 00242/01234] [00:02:40/00:10:57, 0.663s/it]: train_loss_raw=1.1438, running_loss=1.1143, LR=0.000100
[2025-08-26 02:32:12,028][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023696] [Batch 00250/01234] [00:02:45/00:10:51, 0.662s/it]: train_loss_raw=1.0159, running_loss=1.1131, LR=0.000100
[2025-08-26 02:32:17,450][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023704] [Batch 00258/01234] [00:02:50/00:10:46, 0.663s/it]: train_loss_raw=1.1690, running_loss=1.1155, LR=0.000100
[2025-08-26 02:32:23,323][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023712] [Batch 00266/01234] [00:02:56/00:10:43, 0.665s/it]: train_loss_raw=1.1424, running_loss=1.1137, LR=0.000100
[2025-08-26 02:32:28,827][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023720] [Batch 00274/01234] [00:03:02/00:10:38, 0.666s/it]: train_loss_raw=1.1045, running_loss=1.1135, LR=0.000100
[2025-08-26 02:32:34,218][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023728] [Batch 00282/01234] [00:03:07/00:10:33, 0.666s/it]: train_loss_raw=1.0383, running_loss=1.1133, LR=0.000100
[2025-08-26 02:32:39,854][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023736] [Batch 00290/01234] [00:03:13/00:10:29, 0.667s/it]: train_loss_raw=1.1443, running_loss=1.1119, LR=0.000100
[2025-08-26 02:32:45,798][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023744] [Batch 00298/01234] [00:03:19/00:10:26, 0.669s/it]: train_loss_raw=1.0707, running_loss=1.1103, LR=0.000100
[2025-08-26 02:32:51,191][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023752] [Batch 00306/01234] [00:03:24/00:10:20, 0.669s/it]: train_loss_raw=1.1251, running_loss=1.1125, LR=0.000100
[2025-08-26 02:32:56,917][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023760] [Batch 00314/01234] [00:03:30/00:10:16, 0.670s/it]: train_loss_raw=1.1695, running_loss=1.1120, LR=0.000100
[2025-08-26 02:33:02,656][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023768] [Batch 00322/01234] [00:03:36/00:10:12, 0.671s/it]: train_loss_raw=1.0736, running_loss=1.1139, LR=0.000100
[2025-08-26 02:33:08,158][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023776] [Batch 00330/01234] [00:03:41/00:10:07, 0.672s/it]: train_loss_raw=1.1815, running_loss=1.1160, LR=0.000100
[2025-08-26 02:33:13,603][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023784] [Batch 00338/01234] [00:03:47/00:10:02, 0.672s/it]: train_loss_raw=1.1963, running_loss=1.1178, LR=0.000100
[2025-08-26 02:33:19,119][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023792] [Batch 00346/01234] [00:03:52/00:09:57, 0.672s/it]: train_loss_raw=1.1243, running_loss=1.1190, LR=0.000100
[2025-08-26 02:33:24,973][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023800] [Batch 00354/01234] [00:03:58/00:09:52, 0.674s/it]: train_loss_raw=1.1513, running_loss=1.1205, LR=0.000100
[2025-08-26 02:33:30,451][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023808] [Batch 00362/01234] [00:04:03/00:09:47, 0.674s/it]: train_loss_raw=1.1802, running_loss=1.1231, LR=0.000100
[2025-08-26 02:33:36,017][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023816] [Batch 00370/01234] [00:04:09/00:09:42, 0.674s/it]: train_loss_raw=1.1342, running_loss=1.1247, LR=0.000100
[2025-08-26 02:33:41,694][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023824] [Batch 00378/01234] [00:04:15/00:09:37, 0.675s/it]: train_loss_raw=1.1404, running_loss=1.1233, LR=0.000100
[2025-08-26 02:33:46,911][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023832] [Batch 00386/01234] [00:04:20/00:09:32, 0.675s/it]: train_loss_raw=1.1113, running_loss=1.1238, LR=0.000100
[2025-08-26 02:33:52,288][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023840] [Batch 00394/01234] [00:04:25/00:09:26, 0.675s/it]: train_loss_raw=1.1531, running_loss=1.1269, LR=0.000100
[2025-08-26 02:33:57,655][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023848] [Batch 00402/01234] [00:04:31/00:09:21, 0.675s/it]: train_loss_raw=1.0852, running_loss=1.1283, LR=0.000100
[2025-08-26 02:34:03,098][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023856] [Batch 00410/01234] [00:04:36/00:09:15, 0.675s/it]: train_loss_raw=1.0415, running_loss=1.1264, LR=0.000100
[2025-08-26 02:34:08,286][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023864] [Batch 00418/01234] [00:04:41/00:09:10, 0.674s/it]: train_loss_raw=1.0985, running_loss=1.1245, LR=0.000100
[2025-08-26 02:34:13,803][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023872] [Batch 00426/01234] [00:04:47/00:09:04, 0.675s/it]: train_loss_raw=1.2144, running_loss=1.1242, LR=0.000100
[2025-08-26 02:34:19,090][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023880] [Batch 00434/01234] [00:04:52/00:08:59, 0.674s/it]: train_loss_raw=1.1607, running_loss=1.1239, LR=0.000100
[2025-08-26 02:34:24,521][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023888] [Batch 00442/01234] [00:04:58/00:08:54, 0.674s/it]: train_loss_raw=1.0918, running_loss=1.1250, LR=0.000100
[2025-08-26 02:34:29,969][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023896] [Batch 00450/01234] [00:05:03/00:08:48, 0.674s/it]: train_loss_raw=1.1240, running_loss=1.1291, LR=0.000100
[2025-08-26 02:34:35,271][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023904] [Batch 00458/01234] [00:05:08/00:08:43, 0.674s/it]: train_loss_raw=1.1263, running_loss=1.1315, LR=0.000100
[2025-08-26 02:34:40,999][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023912] [Batch 00466/01234] [00:05:14/00:08:38, 0.675s/it]: train_loss_raw=1.1459, running_loss=1.1301, LR=0.000100
[2025-08-26 02:34:46,334][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023920] [Batch 00474/01234] [00:05:19/00:08:32, 0.675s/it]: train_loss_raw=1.0813, running_loss=1.1311, LR=0.000100
[2025-08-26 02:34:51,449][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023928] [Batch 00482/01234] [00:05:24/00:08:27, 0.674s/it]: train_loss_raw=1.1623, running_loss=1.1316, LR=0.000100
[2025-08-26 02:34:56,710][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023936] [Batch 00490/01234] [00:05:30/00:08:21, 0.674s/it]: train_loss_raw=1.1163, running_loss=1.1313, LR=0.000100
[2025-08-26 02:35:02,288][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023944] [Batch 00498/01234] [00:05:35/00:08:16, 0.674s/it]: train_loss_raw=0.9894, running_loss=1.1310, LR=0.000100
[2025-08-26 02:35:07,362][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023952] [Batch 00506/01234] [00:05:40/00:08:10, 0.674s/it]: train_loss_raw=1.0582, running_loss=1.1309, LR=0.000100
[2025-08-26 02:35:12,428][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023960] [Batch 00514/01234] [00:05:45/00:08:04, 0.673s/it]: train_loss_raw=1.1366, running_loss=1.1307, LR=0.000100
[2025-08-26 02:35:17,956][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023968] [Batch 00522/01234] [00:05:51/00:07:59, 0.673s/it]: train_loss_raw=1.1126, running_loss=1.1309, LR=0.000100
[2025-08-26 02:35:23,409][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023976] [Batch 00530/01234] [00:05:56/00:07:54, 0.673s/it]: train_loss_raw=1.0966, running_loss=1.1309, LR=0.000100
[2025-08-26 02:35:29,373][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023984] [Batch 00538/01234] [00:06:02/00:07:49, 0.675s/it]: train_loss_raw=1.1095, running_loss=1.1306, LR=0.000100
[2025-08-26 02:35:34,469][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 023992] [Batch 00546/01234] [00:06:08/00:07:43, 0.674s/it]: train_loss_raw=1.2306, running_loss=1.1313, LR=0.000100
[2025-08-26 02:35:39,589][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024000] [Batch 00554/01234] [00:06:13/00:07:37, 0.674s/it]: train_loss_raw=1.1135, running_loss=1.1322, LR=0.000100
[2025-08-26 02:35:49,203][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024008] [Batch 00562/01234] [00:06:22/00:07:37, 0.681s/it]: train_loss_raw=1.1629, running_loss=1.1345, LR=0.000100
[2025-08-26 02:35:55,091][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024016] [Batch 00570/01234] [00:06:28/00:07:32, 0.682s/it]: train_loss_raw=1.1478, running_loss=1.1330, LR=0.000100
[2025-08-26 02:36:00,892][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024024] [Batch 00578/01234] [00:06:34/00:07:27, 0.682s/it]: train_loss_raw=1.2157, running_loss=1.1325, LR=0.000100
[2025-08-26 02:36:06,658][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024032] [Batch 00586/01234] [00:06:40/00:07:22, 0.683s/it]: train_loss_raw=1.1917, running_loss=1.1343, LR=0.000100
[2025-08-26 02:36:12,037][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024040] [Batch 00594/01234] [00:06:45/00:07:16, 0.683s/it]: train_loss_raw=1.1347, running_loss=1.1352, LR=0.000100
[2025-08-26 02:36:17,865][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024048] [Batch 00602/01234] [00:06:51/00:07:11, 0.683s/it]: train_loss_raw=1.1362, running_loss=1.1354, LR=0.000100
[2025-08-26 02:36:23,515][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024056] [Batch 00610/01234] [00:06:57/00:07:06, 0.684s/it]: train_loss_raw=1.0861, running_loss=1.1354, LR=0.000100
[2025-08-26 02:36:28,920][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024064] [Batch 00618/01234] [00:07:02/00:07:01, 0.684s/it]: train_loss_raw=1.1420, running_loss=1.1333, LR=0.000100
[2025-08-26 02:36:34,658][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024072] [Batch 00626/01234] [00:07:08/00:06:55, 0.684s/it]: train_loss_raw=1.0940, running_loss=1.1339, LR=0.000100
[2025-08-26 02:36:39,727][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024080] [Batch 00634/01234] [00:07:13/00:06:50, 0.683s/it]: train_loss_raw=1.1214, running_loss=1.1367, LR=0.000100
[2025-08-26 02:36:44,926][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024088] [Batch 00642/01234] [00:07:18/00:06:44, 0.683s/it]: train_loss_raw=1.1403, running_loss=1.1384, LR=0.000100
[2025-08-26 02:36:50,894][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024096] [Batch 00650/01234] [00:07:24/00:06:39, 0.684s/it]: train_loss_raw=1.1116, running_loss=1.1379, LR=0.000100
[2025-08-26 02:36:56,649][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024104] [Batch 00658/01234] [00:07:30/00:06:34, 0.684s/it]: train_loss_raw=1.1810, running_loss=1.1380, LR=0.000100
[2025-08-26 02:37:02,436][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024112] [Batch 00666/01234] [00:07:35/00:06:28, 0.685s/it]: train_loss_raw=1.1494, running_loss=1.1380, LR=0.000100
[2025-08-26 02:37:07,781][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024120] [Batch 00674/01234] [00:07:41/00:06:23, 0.684s/it]: train_loss_raw=1.2129, running_loss=1.1389, LR=0.000100
[2025-08-26 02:37:13,220][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024128] [Batch 00682/01234] [00:07:46/00:06:17, 0.684s/it]: train_loss_raw=1.0161, running_loss=1.1392, LR=0.000100
[2025-08-26 02:37:18,341][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024136] [Batch 00690/01234] [00:07:51/00:06:12, 0.684s/it]: train_loss_raw=1.0310, running_loss=1.1358, LR=0.000100
[2025-08-26 02:37:23,485][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024144] [Batch 00698/01234] [00:07:57/00:06:06, 0.683s/it]: train_loss_raw=1.0932, running_loss=1.1352, LR=0.000100
[2025-08-26 02:37:28,919][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024152] [Batch 00706/01234] [00:08:02/00:06:00, 0.683s/it]: train_loss_raw=1.1866, running_loss=1.1387, LR=0.000100
[2025-08-26 02:37:34,688][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024160] [Batch 00714/01234] [00:08:08/00:05:55, 0.684s/it]: train_loss_raw=1.0598, running_loss=1.1411, LR=0.000100
[2025-08-26 02:37:40,165][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024168] [Batch 00722/01234] [00:08:13/00:05:50, 0.684s/it]: train_loss_raw=1.1967, running_loss=1.1413, LR=0.000100
[2025-08-26 02:37:45,667][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024176] [Batch 00730/01234] [00:08:19/00:05:44, 0.684s/it]: train_loss_raw=1.1025, running_loss=1.1421, LR=0.000100
[2025-08-26 02:37:51,122][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024184] [Batch 00738/01234] [00:08:24/00:05:39, 0.684s/it]: train_loss_raw=1.1424, running_loss=1.1420, LR=0.000100
[2025-08-26 02:37:56,233][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024192] [Batch 00746/01234] [00:08:29/00:05:33, 0.683s/it]: train_loss_raw=1.1380, running_loss=1.1402, LR=0.000100
[2025-08-26 02:38:01,787][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024200] [Batch 00754/01234] [00:08:35/00:05:28, 0.683s/it]: train_loss_raw=1.2114, running_loss=1.1424, LR=0.000100
[2025-08-26 02:38:07,377][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024208] [Batch 00762/01234] [00:08:40/00:05:22, 0.684s/it]: train_loss_raw=1.2706, running_loss=1.1454, LR=0.000100
[2025-08-26 02:38:13,189][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024216] [Batch 00770/01234] [00:08:46/00:05:17, 0.684s/it]: train_loss_raw=1.1351, running_loss=1.1466, LR=0.000100
[2025-08-26 02:38:18,493][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024224] [Batch 00778/01234] [00:08:52/00:05:11, 0.684s/it]: train_loss_raw=1.1513, running_loss=1.1474, LR=0.000100
[2025-08-26 02:38:23,637][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024232] [Batch 00786/01234] [00:08:57/00:05:06, 0.683s/it]: train_loss_raw=1.1843, running_loss=1.1504, LR=0.000100
[2025-08-26 02:38:28,773][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024240] [Batch 00794/01234] [00:09:02/00:05:00, 0.683s/it]: train_loss_raw=1.1131, running_loss=1.1492, LR=0.000100
[2025-08-26 02:38:34,142][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024248] [Batch 00802/01234] [00:09:07/00:04:55, 0.683s/it]: train_loss_raw=1.1523, running_loss=1.1479, LR=0.000100
[2025-08-26 02:38:39,305][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024256] [Batch 00810/01234] [00:09:12/00:04:49, 0.683s/it]: train_loss_raw=1.1791, running_loss=1.1502, LR=0.000100
[2025-08-26 02:38:44,511][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024264] [Batch 00818/01234] [00:09:18/00:04:43, 0.682s/it]: train_loss_raw=1.1273, running_loss=1.1493, LR=0.000100
[2025-08-26 02:38:49,682][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024272] [Batch 00826/01234] [00:09:23/00:04:38, 0.682s/it]: train_loss_raw=1.1155, running_loss=1.1500, LR=0.000100
[2025-08-26 02:38:55,164][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024280] [Batch 00834/01234] [00:09:28/00:04:32, 0.682s/it]: train_loss_raw=1.1644, running_loss=1.1514, LR=0.000100
[2025-08-26 02:39:00,578][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024288] [Batch 00842/01234] [00:09:34/00:04:27, 0.682s/it]: train_loss_raw=1.1081, running_loss=1.1522, LR=0.000100
[2025-08-26 02:39:05,661][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024296] [Batch 00850/01234] [00:09:39/00:04:21, 0.681s/it]: train_loss_raw=1.1250, running_loss=1.1491, LR=0.000100
[2025-08-26 02:39:10,747][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024304] [Batch 00858/01234] [00:09:44/00:04:16, 0.681s/it]: train_loss_raw=1.1420, running_loss=1.1515, LR=0.000100
[2025-08-26 02:39:16,253][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024312] [Batch 00866/01234] [00:09:49/00:04:10, 0.681s/it]: train_loss_raw=1.2670, running_loss=1.1528, LR=0.000100
[2025-08-26 02:39:21,433][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024320] [Batch 00874/01234] [00:09:54/00:04:05, 0.681s/it]: train_loss_raw=1.1558, running_loss=1.1513, LR=0.000100
[2025-08-26 02:39:26,545][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024328] [Batch 00882/01234] [00:10:00/00:03:59, 0.680s/it]: train_loss_raw=1.1244, running_loss=1.1519, LR=0.000100
[2025-08-26 02:39:32,108][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024336] [Batch 00890/01234] [00:10:05/00:03:54, 0.680s/it]: train_loss_raw=1.1661, running_loss=1.1509, LR=0.000100
[2025-08-26 02:39:37,554][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024344] [Batch 00898/01234] [00:10:11/00:03:48, 0.680s/it]: train_loss_raw=1.2363, running_loss=1.1520, LR=0.000100
[2025-08-26 02:39:42,805][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024352] [Batch 00906/01234] [00:10:16/00:03:43, 0.680s/it]: train_loss_raw=1.1603, running_loss=1.1507, LR=0.000100
[2025-08-26 02:39:48,314][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024360] [Batch 00914/01234] [00:10:21/00:03:37, 0.680s/it]: train_loss_raw=1.1125, running_loss=1.1511, LR=0.000100
[2025-08-26 02:39:53,626][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024368] [Batch 00922/01234] [00:10:27/00:03:32, 0.680s/it]: train_loss_raw=1.1271, running_loss=1.1498, LR=0.000100
[2025-08-26 02:39:59,012][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024376] [Batch 00930/01234] [00:10:32/00:03:26, 0.680s/it]: train_loss_raw=1.0900, running_loss=1.1515, LR=0.000100
[2025-08-26 02:40:04,207][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024384] [Batch 00938/01234] [00:10:37/00:03:21, 0.680s/it]: train_loss_raw=1.1958, running_loss=1.1518, LR=0.000100
[2025-08-26 02:40:09,407][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024392] [Batch 00946/01234] [00:10:42/00:03:15, 0.680s/it]: train_loss_raw=1.0933, running_loss=1.1510, LR=0.000100
[2025-08-26 02:40:14,831][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024400] [Batch 00954/01234] [00:10:48/00:03:10, 0.680s/it]: train_loss_raw=1.1282, running_loss=1.1507, LR=0.000100
[2025-08-26 02:40:20,120][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024408] [Batch 00962/01234] [00:10:53/00:03:04, 0.679s/it]: train_loss_raw=1.1621, running_loss=1.1501, LR=0.000100
[2025-08-26 02:40:25,254][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024416] [Batch 00970/01234] [00:10:58/00:02:59, 0.679s/it]: train_loss_raw=1.1094, running_loss=1.1495, LR=0.000100
[2025-08-26 02:40:30,390][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024424] [Batch 00978/01234] [00:11:03/00:02:53, 0.679s/it]: train_loss_raw=1.1791, running_loss=1.1517, LR=0.000100
[2025-08-26 02:40:35,506][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024432] [Batch 00986/01234] [00:11:09/00:02:48, 0.679s/it]: train_loss_raw=1.2478, running_loss=1.1527, LR=0.000100
[2025-08-26 02:40:40,608][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024440] [Batch 00994/01234] [00:11:14/00:02:42, 0.678s/it]: train_loss_raw=1.2671, running_loss=1.1540, LR=0.000100
[2025-08-26 02:40:45,750][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024448] [Batch 01002/01234] [00:11:19/00:02:37, 0.678s/it]: train_loss_raw=1.2107, running_loss=1.1545, LR=0.000100
[2025-08-26 02:40:50,929][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024456] [Batch 01010/01234] [00:11:24/00:02:31, 0.678s/it]: train_loss_raw=1.1751, running_loss=1.1537, LR=0.000100
[2025-08-26 02:40:56,191][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024464] [Batch 01018/01234] [00:11:29/00:02:26, 0.678s/it]: train_loss_raw=1.1214, running_loss=1.1506, LR=0.000100
[2025-08-26 02:41:01,419][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024472] [Batch 01026/01234] [00:11:34/00:02:20, 0.677s/it]: train_loss_raw=1.0706, running_loss=1.1514, LR=0.000100
[2025-08-26 02:41:06,634][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024480] [Batch 01034/01234] [00:11:40/00:02:15, 0.677s/it]: train_loss_raw=1.2458, running_loss=1.1532, LR=0.000100
[2025-08-26 02:41:11,854][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024488] [Batch 01042/01234] [00:11:45/00:02:09, 0.677s/it]: train_loss_raw=1.1559, running_loss=1.1535, LR=0.000100
[2025-08-26 02:41:17,476][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024496] [Batch 01050/01234] [00:11:51/00:02:04, 0.677s/it]: train_loss_raw=1.1944, running_loss=1.1528, LR=0.000100
[2025-08-26 02:41:22,621][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024504] [Batch 01058/01234] [00:11:56/00:01:59, 0.677s/it]: train_loss_raw=1.2026, running_loss=1.1545, LR=0.000100
[2025-08-26 02:41:27,725][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024512] [Batch 01066/01234] [00:12:01/00:01:53, 0.677s/it]: train_loss_raw=1.1381, running_loss=1.1556, LR=0.000100
[2025-08-26 02:41:32,886][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024520] [Batch 01074/01234] [00:12:06/00:01:48, 0.676s/it]: train_loss_raw=1.1890, running_loss=1.1557, LR=0.000100
[2025-08-26 02:41:38,302][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024528] [Batch 01082/01234] [00:12:11/00:01:42, 0.676s/it]: train_loss_raw=1.2295, running_loss=1.1541, LR=0.000100
[2025-08-26 02:41:43,591][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024536] [Batch 01090/01234] [00:12:17/00:01:37, 0.676s/it]: train_loss_raw=1.1123, running_loss=1.1544, LR=0.000100
[2025-08-26 02:41:48,805][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024544] [Batch 01098/01234] [00:12:22/00:01:31, 0.676s/it]: train_loss_raw=1.1350, running_loss=1.1549, LR=0.000100
[2025-08-26 02:41:54,009][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024552] [Batch 01106/01234] [00:12:27/00:01:26, 0.676s/it]: train_loss_raw=1.0865, running_loss=1.1544, LR=0.000100
[2025-08-26 02:41:59,161][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024560] [Batch 01114/01234] [00:12:32/00:01:21, 0.676s/it]: train_loss_raw=1.2076, running_loss=1.1533, LR=0.000100
[2025-08-26 02:42:04,428][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024568] [Batch 01122/01234] [00:12:37/00:01:15, 0.676s/it]: train_loss_raw=1.2127, running_loss=1.1527, LR=0.000100
[2025-08-26 02:42:10,038][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024576] [Batch 01130/01234] [00:12:43/00:01:10, 0.676s/it]: train_loss_raw=1.1545, running_loss=1.1537, LR=0.000100
[2025-08-26 02:42:15,798][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024584] [Batch 01138/01234] [00:12:49/00:01:04, 0.676s/it]: train_loss_raw=1.1844, running_loss=1.1521, LR=0.000100
[2025-08-26 02:42:20,988][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024592] [Batch 01146/01234] [00:12:54/00:00:59, 0.676s/it]: train_loss_raw=1.1799, running_loss=1.1507, LR=0.000100
[2025-08-26 02:42:26,931][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024600] [Batch 01154/01234] [00:13:00/00:00:54, 0.676s/it]: train_loss_raw=1.2231, running_loss=1.1533, LR=0.000100
[2025-08-26 02:42:32,393][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024608] [Batch 01162/01234] [00:13:05/00:00:48, 0.676s/it]: train_loss_raw=1.2205, running_loss=1.1535, LR=0.000100
[2025-08-26 02:42:37,958][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024616] [Batch 01170/01234] [00:13:11/00:00:43, 0.676s/it]: train_loss_raw=1.1846, running_loss=1.1536, LR=0.000100
[2025-08-26 02:42:43,225][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024624] [Batch 01178/01234] [00:13:16/00:00:37, 0.676s/it]: train_loss_raw=1.2625, running_loss=1.1539, LR=0.000100
[2025-08-26 02:42:48,489][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024632] [Batch 01186/01234] [00:13:22/00:00:32, 0.676s/it]: train_loss_raw=1.1747, running_loss=1.1550, LR=0.000100
[2025-08-26 02:42:54,060][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024640] [Batch 01194/01234] [00:13:27/00:00:27, 0.676s/it]: train_loss_raw=1.2596, running_loss=1.1532, LR=0.000100
[2025-08-26 02:42:59,651][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024648] [Batch 01202/01234] [00:13:33/00:00:21, 0.677s/it]: train_loss_raw=1.1481, running_loss=1.1528, LR=0.000100
[2025-08-26 02:43:05,268][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024656] [Batch 01210/01234] [00:13:38/00:00:16, 0.677s/it]: train_loss_raw=1.1972, running_loss=1.1538, LR=0.000100
[2025-08-26 02:43:10,502][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024664] [Batch 01218/01234] [00:13:44/00:00:10, 0.677s/it]: train_loss_raw=1.1435, running_loss=1.1544, LR=0.000100
[2025-08-26 02:43:15,843][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024672] [Batch 01226/01234] [00:13:49/00:00:05, 0.676s/it]: train_loss_raw=1.2252, running_loss=1.1559, LR=0.000100
[2025-08-26 02:43:25,903][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 024680] [Batch 01234/01234] [00:13:59/00:00:00, 0.680s/it]: train_loss_raw=1.1015, running_loss=1.1560, LR=0.000100
[2025-08-26 02:43:26,292][__main__][INFO] - [VALIDATION] [Epoch 19/29] Starting validation.
[2025-08-26 02:43:36,742][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 024681] [Batch 00007/00026] [00:00:10/00:00:23, 1.306s/it]
[2025-08-26 02:43:47,231][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 024681] [Batch 00015/00026] [00:00:20/00:00:13, 1.309s/it]
[2025-08-26 02:43:58,607][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 024681] [Batch 00023/00026] [00:00:32/00:00:02, 1.346s/it]
[2025-08-26 02:44:00,903][__main__][INFO] - [VALIDATION] [Epoch 19/29] train_loss=1.15600, valid_loss=1.54575
[2025-08-26 02:44:00,903][__main__][INFO] - [VALIDATION] [Epoch 19/29] Metrics:
[2025-08-26 02:44:00,903][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_er      0.620
[2025-08-26 02:44:00,904][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_prec    0.053
[2025-08-26 02:44:00,904][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_recall  0.054
[2025-08-26 02:44:00,904][__main__][INFO] - [VALIDATION] [Epoch 19/29] - pep_recall 0.016
[2025-08-26 02:44:00,905][__main__][INFO] - [TRAIN] [Epoch 19/29] Epoch complete, total time 04:53:10, remaining time 02:26:35, 00:14:39 per epoch
[2025-08-26 02:44:05,636][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024688] [Batch 00008/01234] [00:00:04/00:11:44, 0.575s/it]: train_loss_raw=0.9995, running_loss=1.1030, LR=0.000100
[2025-08-26 02:44:11,045][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024696] [Batch 00016/01234] [00:00:10/00:12:41, 0.625s/it]: train_loss_raw=1.0593, running_loss=1.0983, LR=0.000100
[2025-08-26 02:44:17,131][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024704] [Batch 00024/01234] [00:00:16/00:13:31, 0.671s/it]: train_loss_raw=1.0988, running_loss=1.0965, LR=0.000100
[2025-08-26 02:44:22,798][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024712] [Batch 00032/01234] [00:00:21/00:13:37, 0.680s/it]: train_loss_raw=1.0614, running_loss=1.0948, LR=0.000100
[2025-08-26 02:44:28,098][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024720] [Batch 00040/01234] [00:00:27/00:13:27, 0.676s/it]: train_loss_raw=1.1491, running_loss=1.0939, LR=0.000100
[2025-08-26 02:44:33,952][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024728] [Batch 00048/01234] [00:00:32/00:13:33, 0.686s/it]: train_loss_raw=1.0374, running_loss=1.0913, LR=0.000100
[2025-08-26 02:44:39,368][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024736] [Batch 00056/01234] [00:00:38/00:13:26, 0.684s/it]: train_loss_raw=1.1573, running_loss=1.0904, LR=0.000100
[2025-08-26 02:44:44,984][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024744] [Batch 00064/01234] [00:00:43/00:13:23, 0.687s/it]: train_loss_raw=1.1247, running_loss=1.0881, LR=0.000100
[2025-08-26 02:44:50,621][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024752] [Batch 00072/01234] [00:00:49/00:13:20, 0.689s/it]: train_loss_raw=1.0472, running_loss=1.0848, LR=0.000100
[2025-08-26 02:44:55,697][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024760] [Batch 00080/01234] [00:00:54/00:13:08, 0.683s/it]: train_loss_raw=1.0732, running_loss=1.0832, LR=0.000100
[2025-08-26 02:45:01,397][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024768] [Batch 00088/01234] [00:01:00/00:13:06, 0.686s/it]: train_loss_raw=0.9628, running_loss=1.0798, LR=0.000100
[2025-08-26 02:45:06,726][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024776] [Batch 00096/01234] [00:01:05/00:12:58, 0.684s/it]: train_loss_raw=1.0852, running_loss=1.0781, LR=0.000100
[2025-08-26 02:45:12,030][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024784] [Batch 00104/01234] [00:01:10/00:12:51, 0.683s/it]: train_loss_raw=1.0863, running_loss=1.0768, LR=0.000100
[2025-08-26 02:45:17,519][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024792] [Batch 00112/01234] [00:01:16/00:12:46, 0.683s/it]: train_loss_raw=1.1073, running_loss=1.0760, LR=0.000100
[2025-08-26 02:45:23,215][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024800] [Batch 00120/01234] [00:01:22/00:12:42, 0.685s/it]: train_loss_raw=1.0665, running_loss=1.0738, LR=0.000100
[2025-08-26 02:45:29,134][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024808] [Batch 00128/01234] [00:01:28/00:12:41, 0.688s/it]: train_loss_raw=1.0413, running_loss=1.0717, LR=0.000100
[2025-08-26 02:45:34,926][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024816] [Batch 00136/01234] [00:01:33/00:12:38, 0.690s/it]: train_loss_raw=1.0918, running_loss=1.0708, LR=0.000100
[2025-08-26 02:45:40,142][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024824] [Batch 00144/01234] [00:01:39/00:12:30, 0.688s/it]: train_loss_raw=0.9944, running_loss=1.0703, LR=0.000100
[2025-08-26 02:45:45,668][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024832] [Batch 00152/01234] [00:01:44/00:12:24, 0.688s/it]: train_loss_raw=1.1697, running_loss=1.0701, LR=0.000100
[2025-08-26 02:45:50,921][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024840] [Batch 00160/01234] [00:01:49/00:12:17, 0.687s/it]: train_loss_raw=0.9930, running_loss=1.0712, LR=0.000100
[2025-08-26 02:45:56,050][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024848] [Batch 00168/01234] [00:01:55/00:12:09, 0.685s/it]: train_loss_raw=1.0811, running_loss=1.0695, LR=0.000100
[2025-08-26 02:46:01,349][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024856] [Batch 00176/01234] [00:02:00/00:12:03, 0.684s/it]: train_loss_raw=1.0477, running_loss=1.0699, LR=0.000100
[2025-08-26 02:46:06,503][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024864] [Batch 00184/01234] [00:02:05/00:11:55, 0.682s/it]: train_loss_raw=0.9857, running_loss=1.0689, LR=0.000100
[2025-08-26 02:46:12,412][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024872] [Batch 00192/01234] [00:02:11/00:11:52, 0.684s/it]: train_loss_raw=1.0801, running_loss=1.0700, LR=0.000100
[2025-08-26 02:46:17,498][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024880] [Batch 00200/01234] [00:02:16/00:11:45, 0.682s/it]: train_loss_raw=1.0235, running_loss=1.0700, LR=0.000100
[2025-08-26 02:46:22,586][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024888] [Batch 00208/01234] [00:02:21/00:11:38, 0.681s/it]: train_loss_raw=1.0431, running_loss=1.0702, LR=0.000100
[2025-08-26 02:46:28,124][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024896] [Batch 00216/01234] [00:02:27/00:11:33, 0.681s/it]: train_loss_raw=1.1077, running_loss=1.0702, LR=0.000100
[2025-08-26 02:46:33,209][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024904] [Batch 00224/01234] [00:02:32/00:11:26, 0.679s/it]: train_loss_raw=1.1276, running_loss=1.0735, LR=0.000100
[2025-08-26 02:46:38,638][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024912] [Batch 00232/01234] [00:02:37/00:11:20, 0.679s/it]: train_loss_raw=1.0688, running_loss=1.0756, LR=0.000100
[2025-08-26 02:46:44,358][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024920] [Batch 00240/01234] [00:02:43/00:11:16, 0.680s/it]: train_loss_raw=1.1138, running_loss=1.0753, LR=0.000100
[2025-08-26 02:46:49,470][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024928] [Batch 00248/01234] [00:02:48/00:11:09, 0.679s/it]: train_loss_raw=1.0434, running_loss=1.0744, LR=0.000100
[2025-08-26 02:46:55,117][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024936] [Batch 00256/01234] [00:02:54/00:11:05, 0.680s/it]: train_loss_raw=1.0421, running_loss=1.0740, LR=0.000100
[2025-08-26 02:47:00,220][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024944] [Batch 00264/01234] [00:02:59/00:10:58, 0.679s/it]: train_loss_raw=1.1254, running_loss=1.0749, LR=0.000100
[2025-08-26 02:47:05,888][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024952] [Batch 00272/01234] [00:03:04/00:10:53, 0.680s/it]: train_loss_raw=1.1149, running_loss=1.0753, LR=0.000100
[2025-08-26 02:47:11,610][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024960] [Batch 00280/01234] [00:03:10/00:10:49, 0.681s/it]: train_loss_raw=1.1067, running_loss=1.0757, LR=0.000100
[2025-08-26 02:47:17,531][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024968] [Batch 00288/01234] [00:03:16/00:10:45, 0.682s/it]: train_loss_raw=0.9988, running_loss=1.0764, LR=0.000100
[2025-08-26 02:47:23,477][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024976] [Batch 00296/01234] [00:03:22/00:10:41, 0.684s/it]: train_loss_raw=1.1129, running_loss=1.0766, LR=0.000100
[2025-08-26 02:47:28,735][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024984] [Batch 00304/01234] [00:03:27/00:10:35, 0.683s/it]: train_loss_raw=1.1197, running_loss=1.0776, LR=0.000100
[2025-08-26 02:47:33,953][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 024992] [Batch 00312/01234] [00:03:32/00:10:29, 0.682s/it]: train_loss_raw=1.0258, running_loss=1.0787, LR=0.000100
[2025-08-26 02:47:39,706][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025000] [Batch 00320/01234] [00:03:38/00:10:24, 0.683s/it]: train_loss_raw=1.1044, running_loss=1.0808, LR=0.000100
[2025-08-26 02:47:44,779][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025008] [Batch 00328/01234] [00:03:43/00:10:18, 0.682s/it]: train_loss_raw=1.1004, running_loss=1.0820, LR=0.000100
[2025-08-26 02:47:49,877][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025016] [Batch 00336/01234] [00:03:48/00:10:11, 0.681s/it]: train_loss_raw=1.1169, running_loss=1.0810, LR=0.000100
[2025-08-26 02:47:54,994][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025024] [Batch 00344/01234] [00:03:53/00:10:05, 0.680s/it]: train_loss_raw=1.0838, running_loss=1.0805, LR=0.000100
[2025-08-26 02:48:00,832][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025032] [Batch 00352/01234] [00:03:59/00:10:00, 0.681s/it]: train_loss_raw=1.1087, running_loss=1.0853, LR=0.000100
[2025-08-26 02:48:06,789][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025040] [Batch 00360/01234] [00:04:05/00:09:56, 0.683s/it]: train_loss_raw=1.1448, running_loss=1.0863, LR=0.000100
[2025-08-26 02:48:12,514][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025048] [Batch 00368/01234] [00:04:11/00:09:51, 0.683s/it]: train_loss_raw=1.0109, running_loss=1.0850, LR=0.000100
[2025-08-26 02:48:18,226][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025056] [Batch 00376/01234] [00:04:17/00:09:46, 0.684s/it]: train_loss_raw=1.1200, running_loss=1.0872, LR=0.000100
[2025-08-26 02:48:23,633][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025064] [Batch 00384/01234] [00:04:22/00:09:41, 0.684s/it]: train_loss_raw=1.1494, running_loss=1.0892, LR=0.000100
[2025-08-26 02:48:29,128][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025072] [Batch 00392/01234] [00:04:28/00:09:35, 0.684s/it]: train_loss_raw=1.0873, running_loss=1.0889, LR=0.000100
[2025-08-26 02:48:34,568][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025080] [Batch 00400/01234] [00:04:33/00:09:30, 0.684s/it]: train_loss_raw=1.0791, running_loss=1.0897, LR=0.000100
[2025-08-26 02:48:40,183][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025088] [Batch 00408/01234] [00:04:39/00:09:25, 0.684s/it]: train_loss_raw=1.0821, running_loss=1.0894, LR=0.000100
[2025-08-26 02:48:45,508][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025096] [Batch 00416/01234] [00:04:44/00:09:19, 0.684s/it]: train_loss_raw=1.1655, running_loss=1.0930, LR=0.000100
[2025-08-26 02:48:51,134][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025104] [Batch 00424/01234] [00:04:50/00:09:14, 0.684s/it]: train_loss_raw=1.0337, running_loss=1.0911, LR=0.000100
[2025-08-26 02:48:56,339][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025112] [Batch 00432/01234] [00:04:55/00:09:08, 0.684s/it]: train_loss_raw=1.0267, running_loss=1.0902, LR=0.000100
[2025-08-26 02:49:01,699][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025120] [Batch 00440/01234] [00:05:00/00:09:02, 0.683s/it]: train_loss_raw=1.0830, running_loss=1.0908, LR=0.000100
[2025-08-26 02:49:07,646][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025128] [Batch 00448/01234] [00:05:06/00:08:57, 0.684s/it]: train_loss_raw=1.0882, running_loss=1.0919, LR=0.000100
[2025-08-26 02:49:13,313][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025136] [Batch 00456/01234] [00:05:12/00:08:52, 0.685s/it]: train_loss_raw=1.0434, running_loss=1.0932, LR=0.000100
[2025-08-26 02:49:18,862][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025144] [Batch 00464/01234] [00:05:17/00:08:47, 0.685s/it]: train_loss_raw=1.0773, running_loss=1.0932, LR=0.000100
[2025-08-26 02:49:24,435][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025152] [Batch 00472/01234] [00:05:23/00:08:42, 0.685s/it]: train_loss_raw=1.0054, running_loss=1.0930, LR=0.000100
[2025-08-26 02:49:29,719][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025160] [Batch 00480/01234] [00:05:28/00:08:36, 0.685s/it]: train_loss_raw=1.1291, running_loss=1.0952, LR=0.000100
[2025-08-26 02:49:35,711][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025168] [Batch 00488/01234] [00:05:34/00:08:31, 0.686s/it]: train_loss_raw=1.1538, running_loss=1.0978, LR=0.000100
[2025-08-26 02:49:40,943][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025176] [Batch 00496/01234] [00:05:39/00:08:25, 0.685s/it]: train_loss_raw=1.0228, running_loss=1.0968, LR=0.000100
[2025-08-26 02:49:46,052][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025184] [Batch 00504/01234] [00:05:45/00:08:19, 0.685s/it]: train_loss_raw=1.1022, running_loss=1.0946, LR=0.000100
[2025-08-26 02:49:51,225][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025192] [Batch 00512/01234] [00:05:50/00:08:13, 0.684s/it]: train_loss_raw=1.0446, running_loss=1.0982, LR=0.000100
[2025-08-26 02:49:56,415][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025200] [Batch 00520/01234] [00:05:55/00:08:07, 0.683s/it]: train_loss_raw=1.1543, running_loss=1.0977, LR=0.000100
[2025-08-26 02:50:02,136][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025208] [Batch 00528/01234] [00:06:01/00:08:02, 0.684s/it]: train_loss_raw=1.2185, running_loss=1.0993, LR=0.000100
[2025-08-26 02:50:07,899][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025216] [Batch 00536/01234] [00:06:06/00:07:57, 0.684s/it]: train_loss_raw=1.1778, running_loss=1.1002, LR=0.000100
[2025-08-26 02:50:13,465][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025224] [Batch 00544/01234] [00:06:12/00:07:52, 0.685s/it]: train_loss_raw=1.1362, running_loss=1.1017, LR=0.000100
[2025-08-26 02:50:18,543][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025232] [Batch 00552/01234] [00:06:17/00:07:46, 0.684s/it]: train_loss_raw=1.1443, running_loss=1.1032, LR=0.000100
[2025-08-26 02:50:23,610][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025240] [Batch 00560/01234] [00:06:22/00:07:40, 0.683s/it]: train_loss_raw=1.1795, running_loss=1.1039, LR=0.000100
[2025-08-26 02:50:28,971][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025248] [Batch 00568/01234] [00:06:27/00:07:34, 0.683s/it]: train_loss_raw=1.1136, running_loss=1.1006, LR=0.000100
[2025-08-26 02:50:34,705][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025256] [Batch 00576/01234] [00:06:33/00:07:29, 0.683s/it]: train_loss_raw=1.0521, running_loss=1.1004, LR=0.000100
[2025-08-26 02:50:39,959][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025264] [Batch 00584/01234] [00:06:38/00:07:24, 0.683s/it]: train_loss_raw=1.1508, running_loss=1.1006, LR=0.000100
[2025-08-26 02:50:45,140][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025272] [Batch 00592/01234] [00:06:44/00:07:18, 0.683s/it]: train_loss_raw=1.0836, running_loss=1.1002, LR=0.000100
[2025-08-26 02:50:50,262][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025280] [Batch 00600/01234] [00:06:49/00:07:12, 0.682s/it]: train_loss_raw=1.0571, running_loss=1.0993, LR=0.000100
[2025-08-26 02:50:55,435][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025288] [Batch 00608/01234] [00:06:54/00:07:06, 0.682s/it]: train_loss_raw=1.0551, running_loss=1.0989, LR=0.000100
[2025-08-26 02:51:00,541][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025296] [Batch 00616/01234] [00:06:59/00:07:00, 0.681s/it]: train_loss_raw=1.0276, running_loss=1.0982, LR=0.000100
[2025-08-26 02:51:05,791][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025304] [Batch 00624/01234] [00:07:04/00:06:55, 0.681s/it]: train_loss_raw=1.0836, running_loss=1.0980, LR=0.000100
[2025-08-26 02:51:11,459][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025312] [Batch 00632/01234] [00:07:10/00:06:49, 0.681s/it]: train_loss_raw=1.1200, running_loss=1.0992, LR=0.000100
[2025-08-26 02:51:17,207][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025320] [Batch 00640/01234] [00:07:16/00:06:44, 0.682s/it]: train_loss_raw=1.1043, running_loss=1.0988, LR=0.000100
[2025-08-26 02:51:22,995][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025328] [Batch 00648/01234] [00:07:21/00:06:39, 0.682s/it]: train_loss_raw=1.1430, running_loss=1.1002, LR=0.000100
[2025-08-26 02:51:28,751][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025336] [Batch 00656/01234] [00:07:27/00:06:34, 0.682s/it]: train_loss_raw=1.0632, running_loss=1.0984, LR=0.000100
[2025-08-26 02:51:33,987][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025344] [Batch 00664/01234] [00:07:32/00:06:28, 0.682s/it]: train_loss_raw=1.1066, running_loss=1.0977, LR=0.000100
[2025-08-26 02:51:39,305][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025352] [Batch 00672/01234] [00:07:38/00:06:23, 0.682s/it]: train_loss_raw=1.1093, running_loss=1.0994, LR=0.000100
[2025-08-26 02:51:44,670][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025360] [Batch 00680/01234] [00:07:43/00:06:17, 0.682s/it]: train_loss_raw=1.1620, running_loss=1.1016, LR=0.000100
[2025-08-26 02:51:49,753][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025368] [Batch 00688/01234] [00:07:48/00:06:11, 0.681s/it]: train_loss_raw=1.1357, running_loss=1.1012, LR=0.000100
[2025-08-26 02:51:54,872][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025376] [Batch 00696/01234] [00:07:53/00:06:06, 0.681s/it]: train_loss_raw=1.1080, running_loss=1.1022, LR=0.000100
[2025-08-26 02:52:00,840][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025384] [Batch 00704/01234] [00:07:59/00:06:01, 0.682s/it]: train_loss_raw=1.0980, running_loss=1.1028, LR=0.000100
[2025-08-26 02:52:06,766][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025392] [Batch 00712/01234] [00:08:05/00:05:56, 0.682s/it]: train_loss_raw=1.1317, running_loss=1.1026, LR=0.000100
[2025-08-26 02:52:12,578][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025400] [Batch 00720/01234] [00:08:11/00:05:50, 0.683s/it]: train_loss_raw=1.1120, running_loss=1.1051, LR=0.000100
[2025-08-26 02:52:18,097][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025408] [Batch 00728/01234] [00:08:17/00:05:45, 0.683s/it]: train_loss_raw=1.1403, running_loss=1.1057, LR=0.000100
[2025-08-26 02:52:24,057][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025416] [Batch 00736/01234] [00:08:23/00:05:40, 0.683s/it]: train_loss_raw=1.1464, running_loss=1.1060, LR=0.000100
[2025-08-26 02:52:29,204][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025424] [Batch 00744/01234] [00:08:28/00:05:34, 0.683s/it]: train_loss_raw=1.0417, running_loss=1.1064, LR=0.000100
[2025-08-26 02:52:34,635][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025432] [Batch 00752/01234] [00:08:33/00:05:29, 0.683s/it]: train_loss_raw=1.0948, running_loss=1.1065, LR=0.000100
[2025-08-26 02:52:40,079][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025440] [Batch 00760/01234] [00:08:39/00:05:23, 0.683s/it]: train_loss_raw=1.1111, running_loss=1.1050, LR=0.000100
[2025-08-26 02:52:45,339][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025448] [Batch 00768/01234] [00:08:44/00:05:18, 0.683s/it]: train_loss_raw=1.0657, running_loss=1.1087, LR=0.000100
[2025-08-26 02:52:51,166][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025456] [Batch 00776/01234] [00:08:50/00:05:12, 0.683s/it]: train_loss_raw=1.2004, running_loss=1.1099, LR=0.000100
[2025-08-26 02:52:56,973][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025464] [Batch 00784/01234] [00:08:55/00:05:07, 0.684s/it]: train_loss_raw=1.0441, running_loss=1.1099, LR=0.000100
[2025-08-26 02:53:02,814][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025472] [Batch 00792/01234] [00:09:01/00:05:02, 0.684s/it]: train_loss_raw=1.1113, running_loss=1.1098, LR=0.000100
[2025-08-26 02:53:08,568][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025480] [Batch 00800/01234] [00:09:07/00:04:57, 0.684s/it]: train_loss_raw=1.0546, running_loss=1.1089, LR=0.000100
[2025-08-26 02:53:14,347][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025488] [Batch 00808/01234] [00:09:13/00:04:51, 0.685s/it]: train_loss_raw=1.2328, running_loss=1.1109, LR=0.000100
[2025-08-26 02:53:20,181][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025496] [Batch 00816/01234] [00:09:19/00:04:46, 0.685s/it]: train_loss_raw=1.1641, running_loss=1.1120, LR=0.000100
[2025-08-26 02:53:25,641][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025504] [Batch 00824/01234] [00:09:24/00:04:40, 0.685s/it]: train_loss_raw=1.0522, running_loss=1.1126, LR=0.000100
[2025-08-26 02:53:31,064][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025512] [Batch 00832/01234] [00:09:30/00:04:35, 0.685s/it]: train_loss_raw=1.1482, running_loss=1.1137, LR=0.000100
[2025-08-26 02:53:36,486][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025520] [Batch 00840/01234] [00:09:35/00:04:29, 0.685s/it]: train_loss_raw=1.1311, running_loss=1.1130, LR=0.000100
[2025-08-26 02:53:42,140][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025528] [Batch 00848/01234] [00:09:41/00:04:24, 0.685s/it]: train_loss_raw=1.0908, running_loss=1.1123, LR=0.000100
[2025-08-26 02:53:47,785][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025536] [Batch 00856/01234] [00:09:46/00:04:19, 0.685s/it]: train_loss_raw=1.1350, running_loss=1.1137, LR=0.000100
[2025-08-26 02:53:52,929][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025544] [Batch 00864/01234] [00:09:51/00:04:13, 0.685s/it]: train_loss_raw=1.0033, running_loss=1.1126, LR=0.000100
[2025-08-26 02:53:58,510][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025552] [Batch 00872/01234] [00:09:57/00:04:08, 0.685s/it]: train_loss_raw=1.1379, running_loss=1.1143, LR=0.000100
[2025-08-26 02:54:03,587][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025560] [Batch 00880/01234] [00:10:02/00:04:02, 0.685s/it]: train_loss_raw=1.0338, running_loss=1.1151, LR=0.000100
[2025-08-26 02:54:08,648][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025568] [Batch 00888/01234] [00:10:07/00:03:56, 0.684s/it]: train_loss_raw=1.1141, running_loss=1.1144, LR=0.000100
[2025-08-26 02:54:14,354][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025576] [Batch 00896/01234] [00:10:13/00:03:51, 0.685s/it]: train_loss_raw=1.2434, running_loss=1.1138, LR=0.000100
[2025-08-26 02:54:20,125][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025584] [Batch 00904/01234] [00:10:19/00:03:45, 0.685s/it]: train_loss_raw=1.1710, running_loss=1.1123, LR=0.000100
[2025-08-26 02:54:25,973][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025592] [Batch 00912/01234] [00:10:24/00:03:40, 0.685s/it]: train_loss_raw=1.0879, running_loss=1.1114, LR=0.000100
[2025-08-26 02:54:31,829][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025600] [Batch 00920/01234] [00:10:30/00:03:35, 0.686s/it]: train_loss_raw=1.0375, running_loss=1.1091, LR=0.000100
[2025-08-26 02:54:37,488][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025608] [Batch 00928/01234] [00:10:36/00:03:29, 0.686s/it]: train_loss_raw=1.0946, running_loss=1.1083, LR=0.000100
[2025-08-26 02:54:42,889][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025616] [Batch 00936/01234] [00:10:41/00:03:24, 0.686s/it]: train_loss_raw=1.0622, running_loss=1.1070, LR=0.000100
[2025-08-26 02:54:48,070][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025624] [Batch 00944/01234] [00:10:47/00:03:18, 0.685s/it]: train_loss_raw=1.1065, running_loss=1.1089, LR=0.000100
[2025-08-26 02:54:53,720][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025632] [Batch 00952/01234] [00:10:52/00:03:13, 0.686s/it]: train_loss_raw=1.1080, running_loss=1.1090, LR=0.000100
[2025-08-26 02:54:59,405][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025640] [Batch 00960/01234] [00:10:58/00:03:07, 0.686s/it]: train_loss_raw=1.0232, running_loss=1.1089, LR=0.000100
[2025-08-26 02:55:04,799][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025648] [Batch 00968/01234] [00:11:03/00:03:02, 0.686s/it]: train_loss_raw=1.1354, running_loss=1.1106, LR=0.000100
[2025-08-26 02:55:10,066][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025656] [Batch 00976/01234] [00:11:09/00:02:56, 0.685s/it]: train_loss_raw=1.0444, running_loss=1.1104, LR=0.000100
[2025-08-26 02:55:15,151][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025664] [Batch 00984/01234] [00:11:14/00:02:51, 0.685s/it]: train_loss_raw=1.0356, running_loss=1.1111, LR=0.000100
[2025-08-26 02:55:20,224][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025672] [Batch 00992/01234] [00:11:19/00:02:45, 0.685s/it]: train_loss_raw=1.0832, running_loss=1.1103, LR=0.000100
[2025-08-26 02:55:25,361][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025680] [Batch 01000/01234] [00:11:24/00:02:40, 0.684s/it]: train_loss_raw=1.0502, running_loss=1.1098, LR=0.000100
[2025-08-26 02:55:30,441][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025688] [Batch 01008/01234] [00:11:29/00:02:34, 0.684s/it]: train_loss_raw=1.1350, running_loss=1.1099, LR=0.000100
[2025-08-26 02:55:36,036][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025696] [Batch 01016/01234] [00:11:34/00:02:29, 0.684s/it]: train_loss_raw=1.1046, running_loss=1.1083, LR=0.000100
[2025-08-26 02:55:41,490][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025704] [Batch 01024/01234] [00:11:40/00:02:23, 0.684s/it]: train_loss_raw=1.0374, running_loss=1.1063, LR=0.000100
[2025-08-26 02:55:47,290][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025712] [Batch 01032/01234] [00:11:46/00:02:18, 0.684s/it]: train_loss_raw=1.0505, running_loss=1.1058, LR=0.000100
[2025-08-26 02:55:52,791][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025720] [Batch 01040/01234] [00:11:51/00:02:12, 0.684s/it]: train_loss_raw=1.0669, running_loss=1.1055, LR=0.000100
[2025-08-26 02:55:57,980][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025728] [Batch 01048/01234] [00:11:56/00:02:07, 0.684s/it]: train_loss_raw=0.9939, running_loss=1.1037, LR=0.000100
[2025-08-26 02:56:03,068][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025736] [Batch 01056/01234] [00:12:02/00:02:01, 0.684s/it]: train_loss_raw=1.1490, running_loss=1.1043, LR=0.000100
[2025-08-26 02:56:08,426][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025744] [Batch 01064/01234] [00:12:07/00:01:56, 0.684s/it]: train_loss_raw=0.9816, running_loss=1.1029, LR=0.000100
[2025-08-26 02:56:13,577][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025752] [Batch 01072/01234] [00:12:12/00:01:50, 0.683s/it]: train_loss_raw=1.1622, running_loss=1.1048, LR=0.000100
[2025-08-26 02:56:18,793][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025760] [Batch 01080/01234] [00:12:17/00:01:45, 0.683s/it]: train_loss_raw=1.2131, running_loss=1.1053, LR=0.000100
[2025-08-26 02:56:23,921][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025768] [Batch 01088/01234] [00:12:22/00:01:39, 0.683s/it]: train_loss_raw=1.1588, running_loss=1.1070, LR=0.000100
[2025-08-26 02:56:29,002][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025776] [Batch 01096/01234] [00:12:27/00:01:34, 0.682s/it]: train_loss_raw=1.1611, running_loss=1.1058, LR=0.000100
[2025-08-26 02:56:34,094][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025784] [Batch 01104/01234] [00:12:33/00:01:28, 0.682s/it]: train_loss_raw=1.1960, running_loss=1.1073, LR=0.000100
[2025-08-26 02:56:39,183][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025792] [Batch 01112/01234] [00:12:38/00:01:23, 0.682s/it]: train_loss_raw=1.0411, running_loss=1.1054, LR=0.000100
[2025-08-26 02:56:44,260][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025800] [Batch 01120/01234] [00:12:43/00:01:17, 0.681s/it]: train_loss_raw=1.0929, running_loss=1.1058, LR=0.000100
[2025-08-26 02:56:49,346][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025808] [Batch 01128/01234] [00:12:48/00:01:12, 0.681s/it]: train_loss_raw=1.1198, running_loss=1.1108, LR=0.000100
[2025-08-26 02:56:54,437][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025816] [Batch 01136/01234] [00:12:53/00:01:06, 0.681s/it]: train_loss_raw=1.2212, running_loss=1.1133, LR=0.000100
[2025-08-26 02:56:59,627][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025824] [Batch 01144/01234] [00:12:58/00:01:01, 0.681s/it]: train_loss_raw=1.0921, running_loss=1.1131, LR=0.000100
[2025-08-26 02:57:04,753][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025832] [Batch 01152/01234] [00:13:03/00:00:55, 0.680s/it]: train_loss_raw=1.1013, running_loss=1.1121, LR=0.000100
[2025-08-26 02:57:09,797][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025840] [Batch 01160/01234] [00:13:08/00:00:50, 0.680s/it]: train_loss_raw=1.1240, running_loss=1.1147, LR=0.000100
[2025-08-26 02:57:14,850][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025848] [Batch 01168/01234] [00:13:13/00:00:44, 0.680s/it]: train_loss_raw=1.0858, running_loss=1.1151, LR=0.000100
[2025-08-26 02:57:20,415][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025856] [Batch 01176/01234] [00:13:19/00:00:39, 0.680s/it]: train_loss_raw=1.0651, running_loss=1.1167, LR=0.000100
[2025-08-26 02:57:26,184][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025864] [Batch 01184/01234] [00:13:25/00:00:34, 0.680s/it]: train_loss_raw=1.0881, running_loss=1.1164, LR=0.000100
[2025-08-26 02:57:31,931][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025872] [Batch 01192/01234] [00:13:30/00:00:28, 0.680s/it]: train_loss_raw=1.2143, running_loss=1.1188, LR=0.000100
[2025-08-26 02:57:37,775][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025880] [Batch 01200/01234] [00:13:36/00:00:23, 0.681s/it]: train_loss_raw=1.0623, running_loss=1.1179, LR=0.000100
[2025-08-26 02:57:43,552][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025888] [Batch 01208/01234] [00:13:42/00:00:17, 0.681s/it]: train_loss_raw=1.1031, running_loss=1.1167, LR=0.000100
[2025-08-26 02:57:49,527][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025896] [Batch 01216/01234] [00:13:48/00:00:12, 0.681s/it]: train_loss_raw=1.0549, running_loss=1.1134, LR=0.000100
[2025-08-26 02:57:55,385][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025904] [Batch 01224/01234] [00:13:54/00:00:06, 0.682s/it]: train_loss_raw=1.1319, running_loss=1.1116, LR=0.000100
[2025-08-26 02:58:01,305][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 025912] [Batch 01232/01234] [00:14:00/00:00:01, 0.682s/it]: train_loss_raw=1.0947, running_loss=1.1102, LR=0.000100
[2025-08-26 02:58:10,145][__main__][INFO] - [VALIDATION] [Epoch 20/29] Starting validation.
[2025-08-26 02:58:20,899][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 025915] [Batch 00007/00026] [00:00:10/00:00:24, 1.344s/it]
[2025-08-26 02:58:32,554][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 025915] [Batch 00015/00026] [00:00:22/00:00:14, 1.401s/it]
[2025-08-26 02:58:44,199][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 025915] [Batch 00023/00026] [00:00:34/00:00:02, 1.419s/it]
[2025-08-26 02:58:46,902][__main__][INFO] - [VALIDATION] [Epoch 20/29] train_loss=1.11072, valid_loss=1.54752
[2025-08-26 02:58:46,903][__main__][INFO] - [VALIDATION] [Epoch 20/29] Metrics:
[2025-08-26 02:58:46,903][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_er      0.601
[2025-08-26 02:58:46,903][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_prec    0.057
[2025-08-26 02:58:46,903][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_recall  0.057
[2025-08-26 02:58:46,903][__main__][INFO] - [VALIDATION] [Epoch 20/29] - pep_recall 0.020
[2025-08-26 02:58:46,906][__main__][INFO] - [TRAIN] [Epoch 20/29] Epoch complete, total time 05:07:56, remaining time 02:11:58, 00:14:39 per epoch
[2025-08-26 02:58:51,223][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025920] [Batch 00006/01234] [00:00:04/00:13:51, 0.677s/it]: train_loss_raw=1.0349, running_loss=0.9922, LR=0.000100
[2025-08-26 02:58:57,167][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025928] [Batch 00014/01234] [00:00:10/00:14:32, 0.715s/it]: train_loss_raw=0.9978, running_loss=0.9951, LR=0.000100
[2025-08-26 02:59:02,524][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025936] [Batch 00022/01234] [00:00:15/00:14:06, 0.698s/it]: train_loss_raw=0.9133, running_loss=0.9967, LR=0.000100
[2025-08-26 02:59:08,308][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025944] [Batch 00030/01234] [00:00:21/00:14:08, 0.705s/it]: train_loss_raw=1.0073, running_loss=0.9985, LR=0.000100
[2025-08-26 02:59:14,182][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025952] [Batch 00038/01234] [00:00:27/00:14:10, 0.711s/it]: train_loss_raw=0.9576, running_loss=1.0003, LR=0.000100
[2025-08-26 02:59:19,932][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025960] [Batch 00046/01234] [00:00:32/00:14:06, 0.712s/it]: train_loss_raw=0.9787, running_loss=1.0000, LR=0.000100
[2025-08-26 02:59:25,766][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025968] [Batch 00054/01234] [00:00:38/00:14:03, 0.715s/it]: train_loss_raw=1.0353, running_loss=1.0013, LR=0.000100
[2025-08-26 02:59:31,949][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025976] [Batch 00062/01234] [00:00:44/00:14:06, 0.722s/it]: train_loss_raw=1.0447, running_loss=1.0057, LR=0.000100
[2025-08-26 02:59:37,997][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025984] [Batch 00070/01234] [00:00:50/00:14:05, 0.726s/it]: train_loss_raw=0.9809, running_loss=1.0067, LR=0.000100
[2025-08-26 02:59:44,071][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 025992] [Batch 00078/01234] [00:00:56/00:14:03, 0.730s/it]: train_loss_raw=0.9840, running_loss=1.0079, LR=0.000100
[2025-08-26 02:59:49,903][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026000] [Batch 00086/01234] [00:01:02/00:13:57, 0.730s/it]: train_loss_raw=1.0070, running_loss=1.0089, LR=0.000100
[2025-08-26 03:00:00,002][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026008] [Batch 00094/01234] [00:01:12/00:14:43, 0.775s/it]: train_loss_raw=1.1235, running_loss=1.0097, LR=0.000100
[2025-08-26 03:00:05,842][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026016] [Batch 00102/01234] [00:01:18/00:14:33, 0.771s/it]: train_loss_raw=1.0621, running_loss=1.0102, LR=0.000100
[2025-08-26 03:00:11,692][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026024] [Batch 00110/01234] [00:01:24/00:14:23, 0.768s/it]: train_loss_raw=1.0587, running_loss=1.0116, LR=0.000100
[2025-08-26 03:00:17,740][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026032] [Batch 00118/01234] [00:01:30/00:14:16, 0.768s/it]: train_loss_raw=1.0336, running_loss=1.0128, LR=0.000100
[2025-08-26 03:00:23,572][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026040] [Batch 00126/01234] [00:01:36/00:14:07, 0.765s/it]: train_loss_raw=1.0098, running_loss=1.0150, LR=0.000100
[2025-08-26 03:00:28,824][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026048] [Batch 00134/01234] [00:01:41/00:13:54, 0.759s/it]: train_loss_raw=0.9551, running_loss=1.0148, LR=0.000100
[2025-08-26 03:00:33,943][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026056] [Batch 00142/01234] [00:01:46/00:13:41, 0.752s/it]: train_loss_raw=0.9875, running_loss=1.0152, LR=0.000100
[2025-08-26 03:00:39,210][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026064] [Batch 00150/01234] [00:01:52/00:13:29, 0.747s/it]: train_loss_raw=0.9915, running_loss=1.0161, LR=0.000100
[2025-08-26 03:00:45,007][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026072] [Batch 00158/01234] [00:01:57/00:13:22, 0.746s/it]: train_loss_raw=1.0147, running_loss=1.0182, LR=0.000100
[2025-08-26 03:00:50,413][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026080] [Batch 00166/01234] [00:02:03/00:13:12, 0.742s/it]: train_loss_raw=1.0631, running_loss=1.0182, LR=0.000100
[2025-08-26 03:00:55,904][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026088] [Batch 00174/01234] [00:02:08/00:13:04, 0.740s/it]: train_loss_raw=1.0768, running_loss=1.0179, LR=0.000100
[2025-08-26 03:01:01,159][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026096] [Batch 00182/01234] [00:02:14/00:12:54, 0.736s/it]: train_loss_raw=1.0701, running_loss=1.0200, LR=0.000100
[2025-08-26 03:01:06,704][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026104] [Batch 00190/01234] [00:02:19/00:12:46, 0.734s/it]: train_loss_raw=1.0017, running_loss=1.0209, LR=0.000100
[2025-08-26 03:01:12,474][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026112] [Batch 00198/01234] [00:02:25/00:12:40, 0.734s/it]: train_loss_raw=0.9409, running_loss=1.0202, LR=0.000100
[2025-08-26 03:01:17,733][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026120] [Batch 00206/01234] [00:02:30/00:12:31, 0.731s/it]: train_loss_raw=1.0332, running_loss=1.0221, LR=0.000100
[2025-08-26 03:01:23,418][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026128] [Batch 00214/01234] [00:02:36/00:12:24, 0.730s/it]: train_loss_raw=0.9869, running_loss=1.0210, LR=0.000100
[2025-08-26 03:01:28,938][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026136] [Batch 00222/01234] [00:02:41/00:12:17, 0.729s/it]: train_loss_raw=1.0488, running_loss=1.0229, LR=0.000100
[2025-08-26 03:01:34,500][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026144] [Batch 00230/01234] [00:02:47/00:12:10, 0.728s/it]: train_loss_raw=0.9680, running_loss=1.0237, LR=0.000100
[2025-08-26 03:01:39,953][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026152] [Batch 00238/01234] [00:02:52/00:12:03, 0.726s/it]: train_loss_raw=1.0660, running_loss=1.0246, LR=0.000100
[2025-08-26 03:01:45,262][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026160] [Batch 00246/01234] [00:02:58/00:11:55, 0.724s/it]: train_loss_raw=0.9105, running_loss=1.0263, LR=0.000100
[2025-08-26 03:01:50,585][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026168] [Batch 00254/01234] [00:03:03/00:11:47, 0.722s/it]: train_loss_raw=1.1256, running_loss=1.0282, LR=0.000100
[2025-08-26 03:01:55,700][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026176] [Batch 00262/01234] [00:03:08/00:11:39, 0.720s/it]: train_loss_raw=0.9992, running_loss=1.0277, LR=0.000100
[2025-08-26 03:02:01,143][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026184] [Batch 00270/01234] [00:03:13/00:11:32, 0.718s/it]: train_loss_raw=1.1279, running_loss=1.0273, LR=0.000100
[2025-08-26 03:02:06,574][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026192] [Batch 00278/01234] [00:03:19/00:11:25, 0.717s/it]: train_loss_raw=1.0242, running_loss=1.0289, LR=0.000100
[2025-08-26 03:02:11,779][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026200] [Batch 00286/01234] [00:03:24/00:11:18, 0.715s/it]: train_loss_raw=1.0843, running_loss=1.0295, LR=0.000100
[2025-08-26 03:02:16,977][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026208] [Batch 00294/01234] [00:03:29/00:11:10, 0.714s/it]: train_loss_raw=1.0671, running_loss=1.0311, LR=0.000100
[2025-08-26 03:02:22,121][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026216] [Batch 00302/01234] [00:03:34/00:11:03, 0.712s/it]: train_loss_raw=1.0936, running_loss=1.0335, LR=0.000100
[2025-08-26 03:02:27,418][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026224] [Batch 00310/01234] [00:03:40/00:10:56, 0.711s/it]: train_loss_raw=1.0807, running_loss=1.0333, LR=0.000100
[2025-08-26 03:02:32,935][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026232] [Batch 00318/01234] [00:03:45/00:10:50, 0.710s/it]: train_loss_raw=1.1564, running_loss=1.0368, LR=0.000100
[2025-08-26 03:02:38,028][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026240] [Batch 00326/01234] [00:03:50/00:10:43, 0.708s/it]: train_loss_raw=1.0565, running_loss=1.0407, LR=0.000100
[2025-08-26 03:02:43,462][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026248] [Batch 00334/01234] [00:03:56/00:10:36, 0.707s/it]: train_loss_raw=1.1657, running_loss=1.0414, LR=0.000100
[2025-08-26 03:02:48,966][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026256] [Batch 00342/01234] [00:04:01/00:10:30, 0.707s/it]: train_loss_raw=1.0852, running_loss=1.0440, LR=0.000100
[2025-08-26 03:02:54,498][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026264] [Batch 00350/01234] [00:04:07/00:10:24, 0.707s/it]: train_loss_raw=1.0684, running_loss=1.0447, LR=0.000100
[2025-08-26 03:02:59,689][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026272] [Batch 00358/01234] [00:04:12/00:10:17, 0.705s/it]: train_loss_raw=1.0616, running_loss=1.0475, LR=0.000100
[2025-08-26 03:03:05,373][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026280] [Batch 00366/01234] [00:04:18/00:10:12, 0.706s/it]: train_loss_raw=1.1202, running_loss=1.0468, LR=0.000100
[2025-08-26 03:03:11,173][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026288] [Batch 00374/01234] [00:04:24/00:10:07, 0.706s/it]: train_loss_raw=1.0545, running_loss=1.0475, LR=0.000100
[2025-08-26 03:03:16,937][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026296] [Batch 00382/01234] [00:04:29/00:10:01, 0.706s/it]: train_loss_raw=1.0603, running_loss=1.0466, LR=0.000100
[2025-08-26 03:03:22,562][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026304] [Batch 00390/01234] [00:04:35/00:09:56, 0.706s/it]: train_loss_raw=1.0029, running_loss=1.0473, LR=0.000100
[2025-08-26 03:03:28,223][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026312] [Batch 00398/01234] [00:04:41/00:09:50, 0.706s/it]: train_loss_raw=1.0496, running_loss=1.0466, LR=0.000100
[2025-08-26 03:03:33,840][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026320] [Batch 00406/01234] [00:04:46/00:09:44, 0.706s/it]: train_loss_raw=1.0218, running_loss=1.0465, LR=0.000100
[2025-08-26 03:03:39,232][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026328] [Batch 00414/01234] [00:04:52/00:09:38, 0.705s/it]: train_loss_raw=0.9821, running_loss=1.0476, LR=0.000100
[2025-08-26 03:03:44,383][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026336] [Batch 00422/01234] [00:04:57/00:09:31, 0.704s/it]: train_loss_raw=1.1152, running_loss=1.0506, LR=0.000100
[2025-08-26 03:03:49,464][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026344] [Batch 00430/01234] [00:05:02/00:09:25, 0.703s/it]: train_loss_raw=1.1184, running_loss=1.0557, LR=0.000100
[2025-08-26 03:03:54,542][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026352] [Batch 00438/01234] [00:05:07/00:09:18, 0.702s/it]: train_loss_raw=0.9954, running_loss=1.0554, LR=0.000100
[2025-08-26 03:03:59,906][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026360] [Batch 00446/01234] [00:05:12/00:09:12, 0.701s/it]: train_loss_raw=1.1728, running_loss=1.0576, LR=0.000100
[2025-08-26 03:04:05,712][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026368] [Batch 00454/01234] [00:05:18/00:09:07, 0.702s/it]: train_loss_raw=1.0653, running_loss=1.0566, LR=0.000100
[2025-08-26 03:04:11,400][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026376] [Batch 00462/01234] [00:05:24/00:09:01, 0.702s/it]: train_loss_raw=1.1147, running_loss=1.0567, LR=0.000100
[2025-08-26 03:04:17,208][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026384] [Batch 00470/01234] [00:05:30/00:08:56, 0.702s/it]: train_loss_raw=1.0565, running_loss=1.0544, LR=0.000100
[2025-08-26 03:04:22,908][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026392] [Batch 00478/01234] [00:05:35/00:08:51, 0.702s/it]: train_loss_raw=1.0667, running_loss=1.0531, LR=0.000100
[2025-08-26 03:04:28,557][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026400] [Batch 00486/01234] [00:05:41/00:08:45, 0.702s/it]: train_loss_raw=1.0051, running_loss=1.0532, LR=0.000100
[2025-08-26 03:04:33,907][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026408] [Batch 00494/01234] [00:05:46/00:08:39, 0.702s/it]: train_loss_raw=1.0483, running_loss=1.0567, LR=0.000100
[2025-08-26 03:04:39,010][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026416] [Batch 00502/01234] [00:05:51/00:08:33, 0.701s/it]: train_loss_raw=1.0440, running_loss=1.0560, LR=0.000100
[2025-08-26 03:04:44,137][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026424] [Batch 00510/01234] [00:05:56/00:08:26, 0.700s/it]: train_loss_raw=1.0393, running_loss=1.0561, LR=0.000100
[2025-08-26 03:04:49,825][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026432] [Batch 00518/01234] [00:06:02/00:08:21, 0.700s/it]: train_loss_raw=1.0650, running_loss=1.0554, LR=0.000100
[2025-08-26 03:04:54,876][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026440] [Batch 00526/01234] [00:06:07/00:08:14, 0.699s/it]: train_loss_raw=1.2145, running_loss=1.0575, LR=0.000100
[2025-08-26 03:05:00,009][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026448] [Batch 00534/01234] [00:06:12/00:08:08, 0.698s/it]: train_loss_raw=1.0922, running_loss=1.0570, LR=0.000100
[2025-08-26 03:05:05,470][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026456] [Batch 00542/01234] [00:06:18/00:08:03, 0.698s/it]: train_loss_raw=1.0193, running_loss=1.0560, LR=0.000100
[2025-08-26 03:05:10,728][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026464] [Batch 00550/01234] [00:06:23/00:07:57, 0.697s/it]: train_loss_raw=1.0330, running_loss=1.0528, LR=0.000100
[2025-08-26 03:05:15,998][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026472] [Batch 00558/01234] [00:06:28/00:07:51, 0.697s/it]: train_loss_raw=1.0259, running_loss=1.0529, LR=0.000100
[2025-08-26 03:05:21,049][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026480] [Batch 00566/01234] [00:06:33/00:07:44, 0.696s/it]: train_loss_raw=1.0431, running_loss=1.0527, LR=0.000100
[2025-08-26 03:05:26,257][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026488] [Batch 00574/01234] [00:06:39/00:07:38, 0.695s/it]: train_loss_raw=1.0985, running_loss=1.0536, LR=0.000100
[2025-08-26 03:05:31,359][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026496] [Batch 00582/01234] [00:06:44/00:07:32, 0.695s/it]: train_loss_raw=1.0420, running_loss=1.0552, LR=0.000100
[2025-08-26 03:05:36,728][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026504] [Batch 00590/01234] [00:06:49/00:07:27, 0.694s/it]: train_loss_raw=1.0556, running_loss=1.0546, LR=0.000100
[2025-08-26 03:05:41,867][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026512] [Batch 00598/01234] [00:06:54/00:07:21, 0.693s/it]: train_loss_raw=0.9633, running_loss=1.0547, LR=0.000100
[2025-08-26 03:05:47,469][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026520] [Batch 00606/01234] [00:07:00/00:07:15, 0.694s/it]: train_loss_raw=1.0791, running_loss=1.0547, LR=0.000100
[2025-08-26 03:05:52,774][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026528] [Batch 00614/01234] [00:07:05/00:07:09, 0.693s/it]: train_loss_raw=1.0611, running_loss=1.0524, LR=0.000100
[2025-08-26 03:05:58,403][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026536] [Batch 00622/01234] [00:07:11/00:07:04, 0.693s/it]: train_loss_raw=1.1732, running_loss=1.0533, LR=0.000100
[2025-08-26 03:06:03,650][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026544] [Batch 00630/01234] [00:07:16/00:06:58, 0.693s/it]: train_loss_raw=0.9657, running_loss=1.0542, LR=0.000100
[2025-08-26 03:06:09,107][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026552] [Batch 00638/01234] [00:07:21/00:06:52, 0.693s/it]: train_loss_raw=0.9980, running_loss=1.0529, LR=0.000100
[2025-08-26 03:06:14,449][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026560] [Batch 00646/01234] [00:07:27/00:06:47, 0.692s/it]: train_loss_raw=0.9973, running_loss=1.0543, LR=0.000100
[2025-08-26 03:06:19,697][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026568] [Batch 00654/01234] [00:07:32/00:06:41, 0.692s/it]: train_loss_raw=1.0605, running_loss=1.0549, LR=0.000100
[2025-08-26 03:06:24,940][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026576] [Batch 00662/01234] [00:07:37/00:06:35, 0.692s/it]: train_loss_raw=1.0246, running_loss=1.0548, LR=0.000100
[2025-08-26 03:06:30,076][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026584] [Batch 00670/01234] [00:07:42/00:06:29, 0.691s/it]: train_loss_raw=1.1485, running_loss=1.0544, LR=0.000100
[2025-08-26 03:06:35,517][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026592] [Batch 00678/01234] [00:07:48/00:06:24, 0.691s/it]: train_loss_raw=1.0791, running_loss=1.0552, LR=0.000100
[2025-08-26 03:06:40,982][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026600] [Batch 00686/01234] [00:07:53/00:06:18, 0.691s/it]: train_loss_raw=1.2235, running_loss=1.0576, LR=0.000100
[2025-08-26 03:06:46,335][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026608] [Batch 00694/01234] [00:07:59/00:06:12, 0.690s/it]: train_loss_raw=0.9500, running_loss=1.0553, LR=0.000100
[2025-08-26 03:06:51,432][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026616] [Batch 00702/01234] [00:08:04/00:06:06, 0.690s/it]: train_loss_raw=1.0798, running_loss=1.0560, LR=0.000100
[2025-08-26 03:06:56,799][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026624] [Batch 00710/01234] [00:08:09/00:06:01, 0.690s/it]: train_loss_raw=1.0898, running_loss=1.0574, LR=0.000100
[2025-08-26 03:07:02,235][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026632] [Batch 00718/01234] [00:08:15/00:05:55, 0.690s/it]: train_loss_raw=1.1510, running_loss=1.0574, LR=0.000100
[2025-08-26 03:07:07,521][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026640] [Batch 00726/01234] [00:08:20/00:05:50, 0.689s/it]: train_loss_raw=1.0328, running_loss=1.0561, LR=0.000100
[2025-08-26 03:07:12,931][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026648] [Batch 00734/01234] [00:08:25/00:05:44, 0.689s/it]: train_loss_raw=1.1054, running_loss=1.0593, LR=0.000100
[2025-08-26 03:07:18,390][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026656] [Batch 00742/01234] [00:08:31/00:05:38, 0.689s/it]: train_loss_raw=1.1008, running_loss=1.0592, LR=0.000100
[2025-08-26 03:07:23,805][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026664] [Batch 00750/01234] [00:08:36/00:05:33, 0.689s/it]: train_loss_raw=1.1550, running_loss=1.0606, LR=0.000100
[2025-08-26 03:07:29,038][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026672] [Batch 00758/01234] [00:08:41/00:05:27, 0.688s/it]: train_loss_raw=1.1243, running_loss=1.0633, LR=0.000100
[2025-08-26 03:07:34,384][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026680] [Batch 00766/01234] [00:08:47/00:05:22, 0.688s/it]: train_loss_raw=1.0963, running_loss=1.0634, LR=0.000100
[2025-08-26 03:07:40,088][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026688] [Batch 00774/01234] [00:08:52/00:05:16, 0.689s/it]: train_loss_raw=1.1135, running_loss=1.0627, LR=0.000100
[2025-08-26 03:07:45,246][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026696] [Batch 00782/01234] [00:08:58/00:05:11, 0.688s/it]: train_loss_raw=1.1615, running_loss=1.0642, LR=0.000100
[2025-08-26 03:07:50,925][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026704] [Batch 00790/01234] [00:09:03/00:05:05, 0.688s/it]: train_loss_raw=0.9766, running_loss=1.0654, LR=0.000100
[2025-08-26 03:07:56,440][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026712] [Batch 00798/01234] [00:09:09/00:05:00, 0.688s/it]: train_loss_raw=1.0210, running_loss=1.0674, LR=0.000100
[2025-08-26 03:08:02,302][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026720] [Batch 00806/01234] [00:09:15/00:04:54, 0.689s/it]: train_loss_raw=1.0823, running_loss=1.0697, LR=0.000100
[2025-08-26 03:08:07,851][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026728] [Batch 00814/01234] [00:09:20/00:04:49, 0.689s/it]: train_loss_raw=1.0461, running_loss=1.0700, LR=0.000100
[2025-08-26 03:08:13,570][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026736] [Batch 00822/01234] [00:09:26/00:04:43, 0.689s/it]: train_loss_raw=1.0693, running_loss=1.0711, LR=0.000100
[2025-08-26 03:08:19,234][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026744] [Batch 00830/01234] [00:09:32/00:04:38, 0.689s/it]: train_loss_raw=1.1022, running_loss=1.0720, LR=0.000100
[2025-08-26 03:08:24,762][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026752] [Batch 00838/01234] [00:09:37/00:04:32, 0.689s/it]: train_loss_raw=0.9721, running_loss=1.0708, LR=0.000100
[2025-08-26 03:08:30,460][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026760] [Batch 00846/01234] [00:09:43/00:04:27, 0.689s/it]: train_loss_raw=1.1073, running_loss=1.0705, LR=0.000100
[2025-08-26 03:08:36,144][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026768] [Batch 00854/01234] [00:09:48/00:04:22, 0.690s/it]: train_loss_raw=1.0588, running_loss=1.0685, LR=0.000100
[2025-08-26 03:08:41,231][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026776] [Batch 00862/01234] [00:09:54/00:04:16, 0.689s/it]: train_loss_raw=1.0020, running_loss=1.0678, LR=0.000100
[2025-08-26 03:08:46,536][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026784] [Batch 00870/01234] [00:09:59/00:04:10, 0.689s/it]: train_loss_raw=1.0606, running_loss=1.0679, LR=0.000100
[2025-08-26 03:08:52,175][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026792] [Batch 00878/01234] [00:10:05/00:04:05, 0.689s/it]: train_loss_raw=1.1201, running_loss=1.0680, LR=0.000100
[2025-08-26 03:08:57,258][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026800] [Batch 00886/01234] [00:10:10/00:03:59, 0.689s/it]: train_loss_raw=1.0711, running_loss=1.0705, LR=0.000100
[2025-08-26 03:09:02,449][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026808] [Batch 00894/01234] [00:10:15/00:03:54, 0.688s/it]: train_loss_raw=1.1296, running_loss=1.0706, LR=0.000100
[2025-08-26 03:09:08,138][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026816] [Batch 00902/01234] [00:10:20/00:03:48, 0.688s/it]: train_loss_raw=1.0442, running_loss=1.0710, LR=0.000100
[2025-08-26 03:09:13,288][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026824] [Batch 00910/01234] [00:10:26/00:03:42, 0.688s/it]: train_loss_raw=1.1507, running_loss=1.0716, LR=0.000100
[2025-08-26 03:09:18,618][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026832] [Batch 00918/01234] [00:10:31/00:03:37, 0.688s/it]: train_loss_raw=1.0941, running_loss=1.0735, LR=0.000100
[2025-08-26 03:09:23,777][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026840] [Batch 00926/01234] [00:10:36/00:03:31, 0.687s/it]: train_loss_raw=1.1172, running_loss=1.0717, LR=0.000100
[2025-08-26 03:09:28,941][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026848] [Batch 00934/01234] [00:10:41/00:03:26, 0.687s/it]: train_loss_raw=1.0796, running_loss=1.0708, LR=0.000100
[2025-08-26 03:09:34,619][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026856] [Batch 00942/01234] [00:10:47/00:03:20, 0.687s/it]: train_loss_raw=1.0808, running_loss=1.0712, LR=0.000100
[2025-08-26 03:09:40,247][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026864] [Batch 00950/01234] [00:10:53/00:03:15, 0.687s/it]: train_loss_raw=1.0013, running_loss=1.0695, LR=0.000100
[2025-08-26 03:09:45,310][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026872] [Batch 00958/01234] [00:10:58/00:03:09, 0.687s/it]: train_loss_raw=1.0845, running_loss=1.0694, LR=0.000100
[2025-08-26 03:09:50,685][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026880] [Batch 00966/01234] [00:11:03/00:03:04, 0.687s/it]: train_loss_raw=1.1084, running_loss=1.0682, LR=0.000100
[2025-08-26 03:09:55,993][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026888] [Batch 00974/01234] [00:11:08/00:02:58, 0.687s/it]: train_loss_raw=1.0066, running_loss=1.0688, LR=0.000100
[2025-08-26 03:10:01,518][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026896] [Batch 00982/01234] [00:11:14/00:02:53, 0.687s/it]: train_loss_raw=1.0836, running_loss=1.0693, LR=0.000100
[2025-08-26 03:10:06,904][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026904] [Batch 00990/01234] [00:11:19/00:02:47, 0.687s/it]: train_loss_raw=1.0481, running_loss=1.0688, LR=0.000100
[2025-08-26 03:10:12,226][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026912] [Batch 00998/01234] [00:11:25/00:02:41, 0.686s/it]: train_loss_raw=0.9780, running_loss=1.0676, LR=0.000100
[2025-08-26 03:10:17,341][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026920] [Batch 01006/01234] [00:11:30/00:02:36, 0.686s/it]: train_loss_raw=0.9687, running_loss=1.0667, LR=0.000100
[2025-08-26 03:10:22,899][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026928] [Batch 01014/01234] [00:11:35/00:02:30, 0.686s/it]: train_loss_raw=1.1423, running_loss=1.0674, LR=0.000100
[2025-08-26 03:10:28,638][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026936] [Batch 01022/01234] [00:11:41/00:02:25, 0.686s/it]: train_loss_raw=1.1100, running_loss=1.0686, LR=0.000100
[2025-08-26 03:10:34,200][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026944] [Batch 01030/01234] [00:11:47/00:02:20, 0.686s/it]: train_loss_raw=1.0832, running_loss=1.0684, LR=0.000100
[2025-08-26 03:10:39,525][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026952] [Batch 01038/01234] [00:11:52/00:02:14, 0.686s/it]: train_loss_raw=1.1014, running_loss=1.0673, LR=0.000100
[2025-08-26 03:10:44,844][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026960] [Batch 01046/01234] [00:11:57/00:02:08, 0.686s/it]: train_loss_raw=1.0120, running_loss=1.0686, LR=0.000100
[2025-08-26 03:10:50,237][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026968] [Batch 01054/01234] [00:12:03/00:02:03, 0.686s/it]: train_loss_raw=1.1121, running_loss=1.0690, LR=0.000100
[2025-08-26 03:10:56,240][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026976] [Batch 01062/01234] [00:12:09/00:01:58, 0.687s/it]: train_loss_raw=1.1598, running_loss=1.0696, LR=0.000100
[2025-08-26 03:11:01,796][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026984] [Batch 01070/01234] [00:12:14/00:01:52, 0.687s/it]: train_loss_raw=1.0962, running_loss=1.0711, LR=0.000100
[2025-08-26 03:11:07,166][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 026992] [Batch 01078/01234] [00:12:20/00:01:47, 0.686s/it]: train_loss_raw=1.0190, running_loss=1.0700, LR=0.000100
[2025-08-26 03:11:12,374][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027000] [Batch 01086/01234] [00:12:25/00:01:41, 0.686s/it]: train_loss_raw=1.0662, running_loss=1.0728, LR=0.000100
[2025-08-26 03:11:17,515][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027008] [Batch 01094/01234] [00:12:30/00:01:36, 0.686s/it]: train_loss_raw=1.0535, running_loss=1.0744, LR=0.000100
[2025-08-26 03:11:22,973][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027016] [Batch 01102/01234] [00:12:35/00:01:30, 0.686s/it]: train_loss_raw=1.0682, running_loss=1.0750, LR=0.000100
[2025-08-26 03:11:28,734][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027024] [Batch 01110/01234] [00:12:41/00:01:25, 0.686s/it]: train_loss_raw=1.0846, running_loss=1.0730, LR=0.000100
[2025-08-26 03:11:34,341][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027032] [Batch 01118/01234] [00:12:47/00:01:19, 0.686s/it]: train_loss_raw=1.0614, running_loss=1.0746, LR=0.000100
[2025-08-26 03:11:39,465][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027040] [Batch 01126/01234] [00:12:52/00:01:14, 0.686s/it]: train_loss_raw=1.1940, running_loss=1.0769, LR=0.000100
[2025-08-26 03:11:44,580][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027048] [Batch 01134/01234] [00:12:57/00:01:08, 0.686s/it]: train_loss_raw=1.0320, running_loss=1.0770, LR=0.000100
[2025-08-26 03:11:49,766][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027056] [Batch 01142/01234] [00:13:02/00:01:03, 0.685s/it]: train_loss_raw=1.2459, running_loss=1.0802, LR=0.000100
[2025-08-26 03:11:54,911][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027064] [Batch 01150/01234] [00:13:07/00:00:57, 0.685s/it]: train_loss_raw=1.0312, running_loss=1.0790, LR=0.000100
[2025-08-26 03:12:00,347][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027072] [Batch 01158/01234] [00:13:13/00:00:52, 0.685s/it]: train_loss_raw=1.1526, running_loss=1.0800, LR=0.000100
[2025-08-26 03:12:05,659][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027080] [Batch 01166/01234] [00:13:18/00:00:46, 0.685s/it]: train_loss_raw=0.9689, running_loss=1.0789, LR=0.000100
[2025-08-26 03:12:10,926][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027088] [Batch 01174/01234] [00:13:23/00:00:41, 0.685s/it]: train_loss_raw=1.0960, running_loss=1.0785, LR=0.000100
[2025-08-26 03:12:16,013][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027096] [Batch 01182/01234] [00:13:28/00:00:35, 0.684s/it]: train_loss_raw=1.1388, running_loss=1.0792, LR=0.000100
[2025-08-26 03:12:21,166][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027104] [Batch 01190/01234] [00:13:34/00:00:30, 0.684s/it]: train_loss_raw=1.2077, running_loss=1.0816, LR=0.000100
[2025-08-26 03:12:26,815][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027112] [Batch 01198/01234] [00:13:39/00:00:24, 0.684s/it]: train_loss_raw=1.1552, running_loss=1.0812, LR=0.000100
[2025-08-26 03:12:32,742][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027120] [Batch 01206/01234] [00:13:45/00:00:19, 0.685s/it]: train_loss_raw=1.1153, running_loss=1.0807, LR=0.000100
[2025-08-26 03:12:38,163][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027128] [Batch 01214/01234] [00:13:51/00:00:13, 0.685s/it]: train_loss_raw=1.0193, running_loss=1.0785, LR=0.000100
[2025-08-26 03:12:43,249][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027136] [Batch 01222/01234] [00:13:56/00:00:08, 0.684s/it]: train_loss_raw=1.1797, running_loss=1.0794, LR=0.000100
[2025-08-26 03:12:48,434][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 027144] [Batch 01230/01234] [00:14:01/00:00:02, 0.684s/it]: train_loss_raw=1.1290, running_loss=1.0796, LR=0.000100
[2025-08-26 03:12:57,396][__main__][INFO] - [VALIDATION] [Epoch 21/29] Starting validation.
[2025-08-26 03:13:08,343][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 027149] [Batch 00007/00026] [00:00:10/00:00:24, 1.368s/it]
[2025-08-26 03:13:18,558][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 027149] [Batch 00015/00026] [00:00:21/00:00:13, 1.323s/it]
[2025-08-26 03:13:29,498][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 027149] [Batch 00023/00026] [00:00:32/00:00:02, 1.338s/it]
[2025-08-26 03:13:31,803][__main__][INFO] - [VALIDATION] [Epoch 21/29] train_loss=1.07932, valid_loss=1.55324
[2025-08-26 03:13:31,804][__main__][INFO] - [VALIDATION] [Epoch 21/29] Metrics:
[2025-08-26 03:13:31,804][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_er      0.614
[2025-08-26 03:13:31,804][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_prec    0.058
[2025-08-26 03:13:31,804][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_recall  0.059
[2025-08-26 03:13:31,804][__main__][INFO] - [VALIDATION] [Epoch 21/29] - pep_recall 0.019
[2025-08-26 03:13:31,805][__main__][INFO] - [TRAIN] [Epoch 21/29] Epoch complete, total time 05:22:40, remaining time 01:57:20, 00:14:40 per epoch
[2025-08-26 03:13:33,993][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027152] [Batch 00004/01234] [00:00:02/00:10:31, 0.514s/it]: train_loss_raw=1.0614, running_loss=1.0184, LR=0.000100
[2025-08-26 03:13:39,949][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027160] [Batch 00012/01234] [00:00:08/00:13:35, 0.668s/it]: train_loss_raw=1.0458, running_loss=1.0151, LR=0.000100
[2025-08-26 03:13:45,934][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027168] [Batch 00020/01234] [00:00:13/00:14:09, 0.700s/it]: train_loss_raw=0.9985, running_loss=1.0106, LR=0.000100
[2025-08-26 03:13:51,667][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027176] [Batch 00028/01234] [00:00:19/00:14:09, 0.705s/it]: train_loss_raw=0.9169, running_loss=1.0079, LR=0.000100
[2025-08-26 03:13:57,499][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027184] [Batch 00036/01234] [00:00:25/00:14:10, 0.710s/it]: train_loss_raw=0.9663, running_loss=1.0050, LR=0.000100
[2025-08-26 03:14:02,861][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027192] [Batch 00044/01234] [00:00:30/00:13:56, 0.703s/it]: train_loss_raw=1.0150, running_loss=1.0040, LR=0.000100
[2025-08-26 03:14:07,945][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027200] [Batch 00052/01234] [00:00:36/00:13:38, 0.692s/it]: train_loss_raw=0.9419, running_loss=1.0015, LR=0.000100
[2025-08-26 03:14:13,070][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027208] [Batch 00060/01234] [00:00:41/00:13:24, 0.686s/it]: train_loss_raw=0.9602, running_loss=0.9985, LR=0.000100
[2025-08-26 03:14:18,175][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027216] [Batch 00068/01234] [00:00:46/00:13:12, 0.680s/it]: train_loss_raw=0.9310, running_loss=0.9962, LR=0.000100
[2025-08-26 03:14:23,280][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027224] [Batch 00076/01234] [00:00:51/00:13:02, 0.676s/it]: train_loss_raw=0.9496, running_loss=0.9947, LR=0.000100
[2025-08-26 03:14:28,384][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027232] [Batch 00084/01234] [00:00:56/00:12:52, 0.672s/it]: train_loss_raw=0.9607, running_loss=0.9927, LR=0.000100
[2025-08-26 03:14:33,489][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027240] [Batch 00092/01234] [00:01:01/00:12:44, 0.669s/it]: train_loss_raw=0.9609, running_loss=0.9939, LR=0.000100
[2025-08-26 03:14:39,053][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027248] [Batch 00100/01234] [00:01:07/00:12:41, 0.671s/it]: train_loss_raw=1.0233, running_loss=0.9945, LR=0.000100
[2025-08-26 03:14:44,482][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027256] [Batch 00108/01234] [00:01:12/00:12:36, 0.672s/it]: train_loss_raw=0.9796, running_loss=0.9944, LR=0.000100
[2025-08-26 03:14:49,897][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027264] [Batch 00116/01234] [00:01:17/00:12:31, 0.672s/it]: train_loss_raw=0.9439, running_loss=0.9922, LR=0.000100
[2025-08-26 03:14:55,477][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027272] [Batch 00124/01234] [00:01:23/00:12:27, 0.674s/it]: train_loss_raw=0.9568, running_loss=0.9926, LR=0.000100
[2025-08-26 03:15:00,571][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027280] [Batch 00132/01234] [00:01:28/00:12:19, 0.671s/it]: train_loss_raw=1.0056, running_loss=0.9956, LR=0.000100
[2025-08-26 03:15:06,333][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027288] [Batch 00140/01234] [00:01:34/00:12:17, 0.674s/it]: train_loss_raw=1.0157, running_loss=0.9976, LR=0.000100
[2025-08-26 03:15:11,834][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027296] [Batch 00148/01234] [00:01:39/00:12:13, 0.675s/it]: train_loss_raw=0.9437, running_loss=0.9939, LR=0.000100
[2025-08-26 03:15:16,933][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027304] [Batch 00156/01234] [00:01:44/00:12:05, 0.673s/it]: train_loss_raw=0.9853, running_loss=0.9922, LR=0.000100
[2025-08-26 03:15:22,439][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027312] [Batch 00164/01234] [00:01:50/00:12:00, 0.674s/it]: train_loss_raw=0.9346, running_loss=0.9910, LR=0.000100
[2025-08-26 03:15:27,545][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027320] [Batch 00172/01234] [00:01:55/00:11:53, 0.672s/it]: train_loss_raw=1.0294, running_loss=0.9931, LR=0.000100
[2025-08-26 03:15:32,666][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027328] [Batch 00180/01234] [00:02:00/00:11:46, 0.671s/it]: train_loss_raw=0.9289, running_loss=0.9908, LR=0.000100
[2025-08-26 03:15:38,311][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027336] [Batch 00188/01234] [00:02:06/00:11:43, 0.672s/it]: train_loss_raw=1.0274, running_loss=0.9924, LR=0.000100
[2025-08-26 03:15:43,832][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027344] [Batch 00196/01234] [00:02:11/00:11:38, 0.673s/it]: train_loss_raw=1.0037, running_loss=0.9941, LR=0.000100
[2025-08-26 03:15:49,369][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027352] [Batch 00204/01234] [00:02:17/00:11:33, 0.674s/it]: train_loss_raw=1.0673, running_loss=0.9956, LR=0.000100
[2025-08-26 03:15:55,162][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027360] [Batch 00212/01234] [00:02:23/00:11:30, 0.676s/it]: train_loss_raw=0.9536, running_loss=0.9926, LR=0.000100
[2025-08-26 03:16:00,222][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027368] [Batch 00220/01234] [00:02:28/00:11:23, 0.674s/it]: train_loss_raw=0.9768, running_loss=0.9937, LR=0.000100
[2025-08-26 03:16:05,301][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027376] [Batch 00228/01234] [00:02:33/00:11:16, 0.673s/it]: train_loss_raw=0.9758, running_loss=0.9929, LR=0.000100
[2025-08-26 03:16:10,842][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027384] [Batch 00236/01234] [00:02:38/00:11:11, 0.673s/it]: train_loss_raw=1.0860, running_loss=0.9945, LR=0.000100
[2025-08-26 03:16:15,908][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027392] [Batch 00244/01234] [00:02:43/00:11:05, 0.672s/it]: train_loss_raw=1.0624, running_loss=0.9969, LR=0.000100
[2025-08-26 03:16:20,997][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027400] [Batch 00252/01234] [00:02:49/00:10:58, 0.671s/it]: train_loss_raw=1.0620, running_loss=0.9979, LR=0.000100
[2025-08-26 03:16:26,448][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027408] [Batch 00260/01234] [00:02:54/00:10:53, 0.671s/it]: train_loss_raw=0.9432, running_loss=0.9989, LR=0.000100
[2025-08-26 03:16:32,149][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027416] [Batch 00268/01234] [00:03:00/00:10:49, 0.672s/it]: train_loss_raw=1.0196, running_loss=0.9993, LR=0.000100
[2025-08-26 03:16:37,814][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027424] [Batch 00276/01234] [00:03:05/00:10:45, 0.673s/it]: train_loss_raw=1.1085, running_loss=0.9993, LR=0.000100
[2025-08-26 03:16:42,878][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027432] [Batch 00284/01234] [00:03:10/00:10:38, 0.672s/it]: train_loss_raw=0.9665, running_loss=1.0017, LR=0.000100
[2025-08-26 03:16:47,930][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027440] [Batch 00292/01234] [00:03:15/00:10:32, 0.671s/it]: train_loss_raw=0.9800, running_loss=1.0034, LR=0.000100
[2025-08-26 03:16:53,575][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027448] [Batch 00300/01234] [00:03:21/00:10:27, 0.672s/it]: train_loss_raw=1.0586, running_loss=1.0029, LR=0.000100
[2025-08-26 03:16:59,450][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027456] [Batch 00308/01234] [00:03:27/00:10:23, 0.674s/it]: train_loss_raw=0.9997, running_loss=1.0004, LR=0.000100
[2025-08-26 03:17:04,646][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027464] [Batch 00316/01234] [00:03:32/00:10:17, 0.673s/it]: train_loss_raw=0.9501, running_loss=0.9998, LR=0.000100
[2025-08-26 03:17:09,948][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027472] [Batch 00324/01234] [00:03:38/00:10:12, 0.673s/it]: train_loss_raw=0.9258, running_loss=1.0004, LR=0.000100
[2025-08-26 03:17:15,511][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027480] [Batch 00332/01234] [00:03:43/00:10:07, 0.673s/it]: train_loss_raw=0.9261, running_loss=1.0003, LR=0.000100
[2025-08-26 03:17:21,086][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027488] [Batch 00340/01234] [00:03:49/00:10:02, 0.674s/it]: train_loss_raw=1.1184, running_loss=1.0010, LR=0.000100
[2025-08-26 03:17:26,336][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027496] [Batch 00348/01234] [00:03:54/00:09:56, 0.674s/it]: train_loss_raw=0.9941, running_loss=1.0012, LR=0.000100
[2025-08-26 03:17:31,739][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027504] [Batch 00356/01234] [00:03:59/00:09:51, 0.674s/it]: train_loss_raw=1.0232, running_loss=1.0020, LR=0.000100
[2025-08-26 03:17:36,893][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027512] [Batch 00364/01234] [00:04:04/00:09:45, 0.673s/it]: train_loss_raw=1.1082, running_loss=1.0046, LR=0.000100
[2025-08-26 03:17:42,092][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027520] [Batch 00372/01234] [00:04:10/00:09:39, 0.672s/it]: train_loss_raw=1.0375, running_loss=1.0069, LR=0.000100
[2025-08-26 03:17:47,338][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027528] [Batch 00380/01234] [00:04:15/00:09:33, 0.672s/it]: train_loss_raw=1.0584, running_loss=1.0075, LR=0.000100
[2025-08-26 03:17:52,525][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027536] [Batch 00388/01234] [00:04:20/00:09:28, 0.672s/it]: train_loss_raw=0.9787, running_loss=1.0091, LR=0.000100
[2025-08-26 03:17:57,780][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027544] [Batch 00396/01234] [00:04:25/00:09:22, 0.671s/it]: train_loss_raw=0.9976, running_loss=1.0071, LR=0.000100
[2025-08-26 03:18:02,998][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027552] [Batch 00404/01234] [00:04:31/00:09:16, 0.671s/it]: train_loss_raw=1.0584, running_loss=1.0061, LR=0.000100
[2025-08-26 03:18:08,618][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027560] [Batch 00412/01234] [00:04:36/00:09:12, 0.672s/it]: train_loss_raw=0.9224, running_loss=1.0064, LR=0.000100
[2025-08-26 03:18:14,036][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027568] [Batch 00420/01234] [00:04:42/00:09:06, 0.672s/it]: train_loss_raw=1.0537, running_loss=1.0088, LR=0.000100
[2025-08-26 03:18:19,102][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027576] [Batch 00428/01234] [00:04:47/00:09:00, 0.671s/it]: train_loss_raw=0.9911, running_loss=1.0067, LR=0.000100
[2025-08-26 03:18:24,240][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027584] [Batch 00436/01234] [00:04:52/00:08:54, 0.670s/it]: train_loss_raw=1.0595, running_loss=1.0059, LR=0.000100
[2025-08-26 03:18:29,773][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027592] [Batch 00444/01234] [00:04:57/00:08:49, 0.671s/it]: train_loss_raw=0.9510, running_loss=1.0053, LR=0.000100
[2025-08-26 03:18:35,463][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027600] [Batch 00452/01234] [00:05:03/00:08:45, 0.672s/it]: train_loss_raw=0.9540, running_loss=1.0056, LR=0.000100
[2025-08-26 03:18:40,544][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027608] [Batch 00460/01234] [00:05:08/00:08:39, 0.671s/it]: train_loss_raw=1.0856, running_loss=1.0088, LR=0.000100
[2025-08-26 03:18:45,631][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027616] [Batch 00468/01234] [00:05:13/00:08:33, 0.670s/it]: train_loss_raw=1.0086, running_loss=1.0105, LR=0.000100
[2025-08-26 03:18:50,791][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027624] [Batch 00476/01234] [00:05:18/00:08:27, 0.670s/it]: train_loss_raw=1.0071, running_loss=1.0110, LR=0.000100
[2025-08-26 03:18:56,499][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027632] [Batch 00484/01234] [00:05:24/00:08:22, 0.671s/it]: train_loss_raw=1.0157, running_loss=1.0095, LR=0.000100
[2025-08-26 03:19:02,241][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027640] [Batch 00492/01234] [00:05:30/00:08:18, 0.671s/it]: train_loss_raw=0.9939, running_loss=1.0086, LR=0.000100
[2025-08-26 03:19:08,313][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027648] [Batch 00500/01234] [00:05:36/00:08:13, 0.673s/it]: train_loss_raw=1.0351, running_loss=1.0112, LR=0.000100
[2025-08-26 03:19:13,979][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027656] [Batch 00508/01234] [00:05:42/00:08:08, 0.673s/it]: train_loss_raw=1.0676, running_loss=1.0117, LR=0.000100
[2025-08-26 03:19:19,035][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027664] [Batch 00516/01234] [00:05:47/00:08:02, 0.673s/it]: train_loss_raw=1.0926, running_loss=1.0144, LR=0.000100
[2025-08-26 03:19:24,093][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027672] [Batch 00524/01234] [00:05:52/00:07:57, 0.672s/it]: train_loss_raw=1.0062, running_loss=1.0148, LR=0.000100
[2025-08-26 03:19:29,574][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027680] [Batch 00532/01234] [00:05:57/00:07:51, 0.672s/it]: train_loss_raw=0.9830, running_loss=1.0155, LR=0.000100
[2025-08-26 03:19:35,085][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027688] [Batch 00540/01234] [00:06:03/00:07:46, 0.672s/it]: train_loss_raw=1.0214, running_loss=1.0165, LR=0.000100
[2025-08-26 03:19:40,307][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027696] [Batch 00548/01234] [00:06:08/00:07:41, 0.672s/it]: train_loss_raw=1.0118, running_loss=1.0172, LR=0.000100
[2025-08-26 03:19:46,006][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027704] [Batch 00556/01234] [00:06:14/00:07:36, 0.673s/it]: train_loss_raw=1.0258, running_loss=1.0165, LR=0.000100
[2025-08-26 03:19:51,683][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027712] [Batch 00564/01234] [00:06:19/00:07:31, 0.673s/it]: train_loss_raw=1.0926, running_loss=1.0172, LR=0.000100
[2025-08-26 03:19:56,739][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027720] [Batch 00572/01234] [00:06:24/00:07:25, 0.673s/it]: train_loss_raw=1.0376, running_loss=1.0188, LR=0.000100
[2025-08-26 03:20:02,283][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027728] [Batch 00580/01234] [00:06:30/00:07:20, 0.673s/it]: train_loss_raw=1.0233, running_loss=1.0186, LR=0.000100
[2025-08-26 03:20:08,014][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027736] [Batch 00588/01234] [00:06:36/00:07:15, 0.674s/it]: train_loss_raw=1.0240, running_loss=1.0194, LR=0.000100
[2025-08-26 03:20:13,952][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027744] [Batch 00596/01234] [00:06:42/00:07:10, 0.675s/it]: train_loss_raw=1.0896, running_loss=1.0188, LR=0.000100
[2025-08-26 03:20:20,010][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027752] [Batch 00604/01234] [00:06:48/00:07:05, 0.676s/it]: train_loss_raw=1.1032, running_loss=1.0211, LR=0.000100
[2025-08-26 03:20:25,549][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027760] [Batch 00612/01234] [00:06:53/00:07:00, 0.676s/it]: train_loss_raw=1.0533, running_loss=1.0196, LR=0.000100
[2025-08-26 03:20:30,668][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027768] [Batch 00620/01234] [00:06:58/00:06:54, 0.675s/it]: train_loss_raw=1.0618, running_loss=1.0219, LR=0.000100
[2025-08-26 03:20:35,857][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027776] [Batch 00628/01234] [00:07:03/00:06:49, 0.675s/it]: train_loss_raw=1.0621, running_loss=1.0225, LR=0.000100
[2025-08-26 03:20:41,221][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027784] [Batch 00636/01234] [00:07:09/00:06:43, 0.675s/it]: train_loss_raw=1.1363, running_loss=1.0237, LR=0.000100
[2025-08-26 03:20:46,531][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027792] [Batch 00644/01234] [00:07:14/00:06:38, 0.675s/it]: train_loss_raw=1.0370, running_loss=1.0217, LR=0.000100
[2025-08-26 03:20:52,446][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027800] [Batch 00652/01234] [00:07:20/00:06:33, 0.676s/it]: train_loss_raw=1.1088, running_loss=1.0230, LR=0.000100
[2025-08-26 03:20:58,038][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027808] [Batch 00660/01234] [00:07:26/00:06:27, 0.676s/it]: train_loss_raw=0.9501, running_loss=1.0214, LR=0.000100
[2025-08-26 03:21:03,126][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027816] [Batch 00668/01234] [00:07:31/00:06:22, 0.675s/it]: train_loss_raw=0.9624, running_loss=1.0221, LR=0.000100
[2025-08-26 03:21:08,802][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027824] [Batch 00676/01234] [00:07:36/00:06:17, 0.676s/it]: train_loss_raw=1.0268, running_loss=1.0217, LR=0.000100
[2025-08-26 03:21:14,203][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027832] [Batch 00684/01234] [00:07:42/00:06:11, 0.676s/it]: train_loss_raw=1.0583, running_loss=1.0211, LR=0.000100
[2025-08-26 03:21:19,398][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027840] [Batch 00692/01234] [00:07:47/00:06:06, 0.676s/it]: train_loss_raw=0.9770, running_loss=1.0196, LR=0.000100
[2025-08-26 03:21:24,753][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027848] [Batch 00700/01234] [00:07:52/00:06:00, 0.675s/it]: train_loss_raw=1.0466, running_loss=1.0189, LR=0.000100
[2025-08-26 03:21:29,828][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027856] [Batch 00708/01234] [00:07:57/00:05:55, 0.675s/it]: train_loss_raw=1.0274, running_loss=1.0211, LR=0.000100
[2025-08-26 03:21:35,477][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027864] [Batch 00716/01234] [00:08:03/00:05:49, 0.675s/it]: train_loss_raw=0.9856, running_loss=1.0231, LR=0.000100
[2025-08-26 03:21:40,577][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027872] [Batch 00724/01234] [00:08:08/00:05:44, 0.675s/it]: train_loss_raw=0.9499, running_loss=1.0219, LR=0.000100
[2025-08-26 03:21:45,884][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027880] [Batch 00732/01234] [00:08:13/00:05:38, 0.675s/it]: train_loss_raw=0.9579, running_loss=1.0223, LR=0.000100
[2025-08-26 03:21:51,159][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027888] [Batch 00740/01234] [00:08:19/00:05:33, 0.675s/it]: train_loss_raw=0.9963, running_loss=1.0232, LR=0.000100
[2025-08-26 03:21:56,772][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027896] [Batch 00748/01234] [00:08:24/00:05:28, 0.675s/it]: train_loss_raw=1.0593, running_loss=1.0252, LR=0.000100
[2025-08-26 03:22:01,836][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027904] [Batch 00756/01234] [00:08:29/00:05:22, 0.674s/it]: train_loss_raw=1.0618, running_loss=1.0231, LR=0.000100
[2025-08-26 03:22:07,073][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027912] [Batch 00764/01234] [00:08:35/00:05:16, 0.674s/it]: train_loss_raw=1.0804, running_loss=1.0258, LR=0.000100
[2025-08-26 03:22:12,988][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027920] [Batch 00772/01234] [00:08:41/00:05:11, 0.675s/it]: train_loss_raw=0.9669, running_loss=1.0269, LR=0.000100
[2025-08-26 03:22:18,462][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027928] [Batch 00780/01234] [00:08:46/00:05:06, 0.675s/it]: train_loss_raw=0.9617, running_loss=1.0258, LR=0.000100
[2025-08-26 03:22:23,982][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027936] [Batch 00788/01234] [00:08:52/00:05:01, 0.675s/it]: train_loss_raw=0.9854, running_loss=1.0264, LR=0.000100
[2025-08-26 03:22:29,480][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027944] [Batch 00796/01234] [00:08:57/00:04:55, 0.675s/it]: train_loss_raw=0.9684, running_loss=1.0268, LR=0.000100
[2025-08-26 03:22:35,359][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027952] [Batch 00804/01234] [00:09:03/00:04:50, 0.676s/it]: train_loss_raw=1.0371, running_loss=1.0279, LR=0.000100
[2025-08-26 03:22:41,418][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027960] [Batch 00812/01234] [00:09:09/00:04:45, 0.677s/it]: train_loss_raw=1.0749, running_loss=1.0304, LR=0.000100
[2025-08-26 03:22:46,790][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027968] [Batch 00820/01234] [00:09:14/00:04:40, 0.677s/it]: train_loss_raw=1.1146, running_loss=1.0321, LR=0.000100
[2025-08-26 03:22:51,862][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027976] [Batch 00828/01234] [00:09:19/00:04:34, 0.676s/it]: train_loss_raw=1.0476, running_loss=1.0344, LR=0.000100
[2025-08-26 03:22:57,206][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027984] [Batch 00836/01234] [00:09:25/00:04:29, 0.676s/it]: train_loss_raw=0.9879, running_loss=1.0341, LR=0.000100
[2025-08-26 03:23:03,111][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 027992] [Batch 00844/01234] [00:09:31/00:04:23, 0.677s/it]: train_loss_raw=0.8804, running_loss=1.0348, LR=0.000100
[2025-08-26 03:23:08,557][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028000] [Batch 00852/01234] [00:09:36/00:04:18, 0.677s/it]: train_loss_raw=1.1348, running_loss=1.0382, LR=0.000100
[2025-08-26 03:23:17,214][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028008] [Batch 00860/01234] [00:09:45/00:04:14, 0.681s/it]: train_loss_raw=1.0128, running_loss=1.0376, LR=0.000100
[2025-08-26 03:23:22,333][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028016] [Batch 00868/01234] [00:09:50/00:04:08, 0.680s/it]: train_loss_raw=1.1159, running_loss=1.0370, LR=0.000100
[2025-08-26 03:23:27,515][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028024] [Batch 00876/01234] [00:09:55/00:04:03, 0.680s/it]: train_loss_raw=1.0245, running_loss=1.0325, LR=0.000100
[2025-08-26 03:23:32,683][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028032] [Batch 00884/01234] [00:10:00/00:03:57, 0.680s/it]: train_loss_raw=1.0866, running_loss=1.0339, LR=0.000100
[2025-08-26 03:23:38,042][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028040] [Batch 00892/01234] [00:10:06/00:03:52, 0.679s/it]: train_loss_raw=1.0199, running_loss=1.0331, LR=0.000100
[2025-08-26 03:23:43,443][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028048] [Batch 00900/01234] [00:10:11/00:03:46, 0.679s/it]: train_loss_raw=1.0583, running_loss=1.0308, LR=0.000100
[2025-08-26 03:23:49,196][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028056] [Batch 00908/01234] [00:10:17/00:03:41, 0.680s/it]: train_loss_raw=1.0203, running_loss=1.0318, LR=0.000100
[2025-08-26 03:23:54,471][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028064] [Batch 00916/01234] [00:10:22/00:03:36, 0.680s/it]: train_loss_raw=1.0425, running_loss=1.0323, LR=0.000100
[2025-08-26 03:23:59,713][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028072] [Batch 00924/01234] [00:10:27/00:03:30, 0.679s/it]: train_loss_raw=1.0722, running_loss=1.0330, LR=0.000100
[2025-08-26 03:24:05,336][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028080] [Batch 00932/01234] [00:10:33/00:03:25, 0.680s/it]: train_loss_raw=0.9887, running_loss=1.0318, LR=0.000100
[2025-08-26 03:24:10,649][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028088] [Batch 00940/01234] [00:10:38/00:03:19, 0.679s/it]: train_loss_raw=1.0020, running_loss=1.0311, LR=0.000100
[2025-08-26 03:24:16,352][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028096] [Batch 00948/01234] [00:10:44/00:03:14, 0.680s/it]: train_loss_raw=1.0701, running_loss=1.0313, LR=0.000100
[2025-08-26 03:24:21,645][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028104] [Batch 00956/01234] [00:10:49/00:03:08, 0.680s/it]: train_loss_raw=1.1230, running_loss=1.0313, LR=0.000100
[2025-08-26 03:24:26,962][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028112] [Batch 00964/01234] [00:10:55/00:03:03, 0.679s/it]: train_loss_raw=1.0014, running_loss=1.0302, LR=0.000100
[2025-08-26 03:24:32,246][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028120] [Batch 00972/01234] [00:11:00/00:02:57, 0.679s/it]: train_loss_raw=1.0342, running_loss=1.0313, LR=0.000100
[2025-08-26 03:24:37,882][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028128] [Batch 00980/01234] [00:11:05/00:02:52, 0.680s/it]: train_loss_raw=1.0516, running_loss=1.0320, LR=0.000100
[2025-08-26 03:24:43,378][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028136] [Batch 00988/01234] [00:11:11/00:02:47, 0.680s/it]: train_loss_raw=1.0316, running_loss=1.0319, LR=0.000100
[2025-08-26 03:24:48,527][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028144] [Batch 00996/01234] [00:11:16/00:02:41, 0.679s/it]: train_loss_raw=0.9904, running_loss=1.0330, LR=0.000100
[2025-08-26 03:24:53,654][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028152] [Batch 01004/01234] [00:11:21/00:02:36, 0.679s/it]: train_loss_raw=0.8450, running_loss=1.0304, LR=0.000100
[2025-08-26 03:24:58,837][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028160] [Batch 01012/01234] [00:11:26/00:02:30, 0.679s/it]: train_loss_raw=1.0306, running_loss=1.0336, LR=0.000100
[2025-08-26 03:25:04,164][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028168] [Batch 01020/01234] [00:11:32/00:02:25, 0.679s/it]: train_loss_raw=1.0366, running_loss=1.0319, LR=0.000100
[2025-08-26 03:25:09,548][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028176] [Batch 01028/01234] [00:11:37/00:02:19, 0.679s/it]: train_loss_raw=1.1243, running_loss=1.0319, LR=0.000100
[2025-08-26 03:25:14,944][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028184] [Batch 01036/01234] [00:11:43/00:02:14, 0.679s/it]: train_loss_raw=1.1556, running_loss=1.0325, LR=0.000100
[2025-08-26 03:25:20,022][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028192] [Batch 01044/01234] [00:11:48/00:02:08, 0.678s/it]: train_loss_raw=1.0393, running_loss=1.0337, LR=0.000100
[2025-08-26 03:25:25,407][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028200] [Batch 01052/01234] [00:11:53/00:02:03, 0.678s/it]: train_loss_raw=1.0276, running_loss=1.0345, LR=0.000100
[2025-08-26 03:25:31,057][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028208] [Batch 01060/01234] [00:11:59/00:01:58, 0.678s/it]: train_loss_raw=1.0015, running_loss=1.0361, LR=0.000100
[2025-08-26 03:25:36,128][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028216] [Batch 01068/01234] [00:12:04/00:01:52, 0.678s/it]: train_loss_raw=1.0566, running_loss=1.0376, LR=0.000100
[2025-08-26 03:25:41,204][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028224] [Batch 01076/01234] [00:12:09/00:01:47, 0.678s/it]: train_loss_raw=1.0162, running_loss=1.0388, LR=0.000100
[2025-08-26 03:25:46,579][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028232] [Batch 01084/01234] [00:12:14/00:01:41, 0.678s/it]: train_loss_raw=0.9719, running_loss=1.0391, LR=0.000100
[2025-08-26 03:25:52,130][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028240] [Batch 01092/01234] [00:12:20/00:01:36, 0.678s/it]: train_loss_raw=1.0581, running_loss=1.0388, LR=0.000100
[2025-08-26 03:25:58,183][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028248] [Batch 01100/01234] [00:12:26/00:01:30, 0.678s/it]: train_loss_raw=0.9882, running_loss=1.0335, LR=0.000100
[2025-08-26 03:26:03,273][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028256] [Batch 01108/01234] [00:12:31/00:01:25, 0.678s/it]: train_loss_raw=0.9765, running_loss=1.0314, LR=0.000100
[2025-08-26 03:26:08,783][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028264] [Batch 01116/01234] [00:12:36/00:01:20, 0.678s/it]: train_loss_raw=1.0573, running_loss=1.0328, LR=0.000100
[2025-08-26 03:26:13,993][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028272] [Batch 01124/01234] [00:12:42/00:01:14, 0.678s/it]: train_loss_raw=0.9647, running_loss=1.0342, LR=0.000100
[2025-08-26 03:26:19,586][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028280] [Batch 01132/01234] [00:12:47/00:01:09, 0.678s/it]: train_loss_raw=1.1086, running_loss=1.0363, LR=0.000100
[2025-08-26 03:26:24,656][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028288] [Batch 01140/01234] [00:12:52/00:01:03, 0.678s/it]: train_loss_raw=1.0636, running_loss=1.0367, LR=0.000100
[2025-08-26 03:26:30,148][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028296] [Batch 01148/01234] [00:12:58/00:00:58, 0.678s/it]: train_loss_raw=0.9352, running_loss=1.0361, LR=0.000100
[2025-08-26 03:26:35,822][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028304] [Batch 01156/01234] [00:13:03/00:00:52, 0.678s/it]: train_loss_raw=1.0936, running_loss=1.0357, LR=0.000100
[2025-08-26 03:26:41,517][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028312] [Batch 01164/01234] [00:13:09/00:00:47, 0.678s/it]: train_loss_raw=1.1292, running_loss=1.0389, LR=0.000100
[2025-08-26 03:26:47,034][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028320] [Batch 01172/01234] [00:13:15/00:00:42, 0.678s/it]: train_loss_raw=1.0924, running_loss=1.0399, LR=0.000100
[2025-08-26 03:26:52,106][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028328] [Batch 01180/01234] [00:13:20/00:00:36, 0.678s/it]: train_loss_raw=1.0436, running_loss=1.0404, LR=0.000100
[2025-08-26 03:26:57,850][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028336] [Batch 01188/01234] [00:13:25/00:00:31, 0.678s/it]: train_loss_raw=1.0324, running_loss=1.0388, LR=0.000100
[2025-08-26 03:27:03,164][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028344] [Batch 01196/01234] [00:13:31/00:00:25, 0.678s/it]: train_loss_raw=1.0526, running_loss=1.0382, LR=0.000100
[2025-08-26 03:27:08,637][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028352] [Batch 01204/01234] [00:13:36/00:00:20, 0.678s/it]: train_loss_raw=0.9949, running_loss=1.0404, LR=0.000100
[2025-08-26 03:27:13,840][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028360] [Batch 01212/01234] [00:13:41/00:00:14, 0.678s/it]: train_loss_raw=0.9654, running_loss=1.0395, LR=0.000100
[2025-08-26 03:27:18,929][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028368] [Batch 01220/01234] [00:13:46/00:00:09, 0.678s/it]: train_loss_raw=1.0818, running_loss=1.0376, LR=0.000100
[2025-08-26 03:27:24,007][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 028376] [Batch 01228/01234] [00:13:52/00:00:04, 0.678s/it]: train_loss_raw=1.0345, running_loss=1.0379, LR=0.000100
[2025-08-26 03:27:33,269][__main__][INFO] - [VALIDATION] [Epoch 22/29] Starting validation.
[2025-08-26 03:27:43,536][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 028383] [Batch 00007/00026] [00:00:10/00:00:23, 1.283s/it]
[2025-08-26 03:27:53,670][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 028383] [Batch 00015/00026] [00:00:20/00:00:12, 1.275s/it]
[2025-08-26 03:28:03,859][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 028383] [Batch 00023/00026] [00:00:30/00:00:02, 1.275s/it]
[2025-08-26 03:28:06,290][__main__][INFO] - [VALIDATION] [Epoch 22/29] train_loss=1.03689, valid_loss=1.56743
[2025-08-26 03:28:06,290][__main__][INFO] - [VALIDATION] [Epoch 22/29] Metrics:
[2025-08-26 03:28:06,290][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_er      0.600
[2025-08-26 03:28:06,290][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_prec    0.060
[2025-08-26 03:28:06,291][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_recall  0.061
[2025-08-26 03:28:06,291][__main__][INFO] - [VALIDATION] [Epoch 22/29] - pep_recall 0.017
[2025-08-26 03:28:06,293][__main__][INFO] - [TRAIN] [Epoch 22/29] Epoch complete, total time 05:37:15, remaining time 01:42:38, 00:14:39 per epoch
[2025-08-26 03:28:07,481][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028384] [Batch 00002/01234] [00:00:00/00:09:26, 0.460s/it]: train_loss_raw=0.8747, running_loss=0.9389, LR=0.000100
[2025-08-26 03:28:13,637][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028392] [Batch 00010/01234] [00:00:07/00:14:26, 0.708s/it]: train_loss_raw=0.8868, running_loss=0.9382, LR=0.000100
[2025-08-26 03:28:19,596][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028400] [Batch 00018/01234] [00:00:13/00:14:40, 0.724s/it]: train_loss_raw=1.0571, running_loss=0.9401, LR=0.000100
[2025-08-26 03:28:25,057][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028408] [Batch 00026/01234] [00:00:18/00:14:19, 0.711s/it]: train_loss_raw=0.8800, running_loss=0.9387, LR=0.000100
[2025-08-26 03:28:30,141][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028416] [Batch 00034/01234] [00:00:23/00:13:52, 0.694s/it]: train_loss_raw=0.8786, running_loss=0.9363, LR=0.000100
[2025-08-26 03:28:35,226][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028424] [Batch 00042/01234] [00:00:28/00:13:33, 0.682s/it]: train_loss_raw=0.9734, running_loss=0.9353, LR=0.000100
[2025-08-26 03:28:40,559][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028432] [Batch 00050/01234] [00:00:33/00:13:25, 0.680s/it]: train_loss_raw=0.9689, running_loss=0.9361, LR=0.000100
[2025-08-26 03:28:45,662][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028440] [Batch 00058/01234] [00:00:39/00:13:12, 0.674s/it]: train_loss_raw=0.9830, running_loss=0.9361, LR=0.000100
[2025-08-26 03:28:51,057][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028448] [Batch 00066/01234] [00:00:44/00:13:07, 0.674s/it]: train_loss_raw=0.9036, running_loss=0.9367, LR=0.000100
[2025-08-26 03:28:56,711][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028456] [Batch 00074/01234] [00:00:50/00:13:06, 0.678s/it]: train_loss_raw=0.9828, running_loss=0.9381, LR=0.000100
[2025-08-26 03:29:02,194][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028464] [Batch 00082/01234] [00:00:55/00:13:01, 0.678s/it]: train_loss_raw=0.9352, running_loss=0.9384, LR=0.000100
[2025-08-26 03:29:07,230][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028472] [Batch 00090/01234] [00:01:00/00:12:51, 0.674s/it]: train_loss_raw=0.8593, running_loss=0.9385, LR=0.000100
[2025-08-26 03:29:12,290][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028480] [Batch 00098/01234] [00:01:05/00:12:41, 0.671s/it]: train_loss_raw=0.8540, running_loss=0.9397, LR=0.000100
[2025-08-26 03:29:17,430][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028488] [Batch 00106/01234] [00:01:10/00:12:34, 0.669s/it]: train_loss_raw=0.9772, running_loss=0.9443, LR=0.000100
[2025-08-26 03:29:22,480][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028496] [Batch 00114/01234] [00:01:15/00:12:25, 0.666s/it]: train_loss_raw=0.9282, running_loss=0.9434, LR=0.000100
[2025-08-26 03:29:27,557][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028504] [Batch 00122/01234] [00:01:20/00:12:18, 0.664s/it]: train_loss_raw=0.9760, running_loss=0.9439, LR=0.000100
[2025-08-26 03:29:33,019][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028512] [Batch 00130/01234] [00:01:26/00:12:14, 0.665s/it]: train_loss_raw=0.9690, running_loss=0.9434, LR=0.000100
[2025-08-26 03:29:38,441][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028520] [Batch 00138/01234] [00:01:31/00:12:09, 0.666s/it]: train_loss_raw=0.9892, running_loss=0.9433, LR=0.000100
[2025-08-26 03:29:44,013][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028528] [Batch 00146/01234] [00:01:37/00:12:06, 0.667s/it]: train_loss_raw=0.9051, running_loss=0.9437, LR=0.000100
[2025-08-26 03:29:49,265][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028536] [Batch 00154/01234] [00:01:42/00:12:00, 0.667s/it]: train_loss_raw=0.9697, running_loss=0.9423, LR=0.000100
[2025-08-26 03:29:54,330][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028544] [Batch 00162/01234] [00:01:47/00:11:53, 0.665s/it]: train_loss_raw=0.9024, running_loss=0.9438, LR=0.000100
[2025-08-26 03:29:59,401][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028552] [Batch 00170/01234] [00:01:52/00:11:46, 0.664s/it]: train_loss_raw=1.0435, running_loss=0.9465, LR=0.000100
[2025-08-26 03:30:04,461][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028560] [Batch 00178/01234] [00:01:57/00:11:39, 0.662s/it]: train_loss_raw=1.0277, running_loss=0.9450, LR=0.000100
[2025-08-26 03:30:09,717][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028568] [Batch 00186/01234] [00:02:03/00:11:33, 0.662s/it]: train_loss_raw=1.0202, running_loss=0.9444, LR=0.000100
[2025-08-26 03:30:15,117][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028576] [Batch 00194/01234] [00:02:08/00:11:29, 0.663s/it]: train_loss_raw=0.9696, running_loss=0.9444, LR=0.000100
[2025-08-26 03:30:20,187][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028584] [Batch 00202/01234] [00:02:13/00:11:22, 0.662s/it]: train_loss_raw=0.9516, running_loss=0.9467, LR=0.000100
[2025-08-26 03:30:25,618][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028592] [Batch 00210/01234] [00:02:19/00:11:18, 0.662s/it]: train_loss_raw=1.0367, running_loss=0.9481, LR=0.000100
[2025-08-26 03:30:31,181][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028600] [Batch 00218/01234] [00:02:24/00:11:14, 0.663s/it]: train_loss_raw=0.9655, running_loss=0.9490, LR=0.000100
[2025-08-26 03:30:36,482][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028608] [Batch 00226/01234] [00:02:29/00:11:08, 0.663s/it]: train_loss_raw=1.0096, running_loss=0.9491, LR=0.000100
[2025-08-26 03:30:42,371][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028616] [Batch 00234/01234] [00:02:35/00:11:05, 0.666s/it]: train_loss_raw=0.8732, running_loss=0.9503, LR=0.000100
[2025-08-26 03:30:47,856][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028624] [Batch 00242/01234] [00:02:41/00:11:01, 0.667s/it]: train_loss_raw=0.9016, running_loss=0.9506, LR=0.000100
[2025-08-26 03:30:52,964][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028632] [Batch 00250/01234] [00:02:46/00:10:54, 0.666s/it]: train_loss_raw=0.9200, running_loss=0.9501, LR=0.000100
[2025-08-26 03:30:58,103][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028640] [Batch 00258/01234] [00:02:51/00:10:48, 0.665s/it]: train_loss_raw=1.0326, running_loss=0.9525, LR=0.000100
[2025-08-26 03:31:03,721][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028648] [Batch 00266/01234] [00:02:57/00:10:44, 0.666s/it]: train_loss_raw=1.0014, running_loss=0.9539, LR=0.000100
[2025-08-26 03:31:08,833][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028656] [Batch 00274/01234] [00:03:02/00:10:38, 0.665s/it]: train_loss_raw=0.9606, running_loss=0.9567, LR=0.000100
[2025-08-26 03:31:13,871][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028664] [Batch 00282/01234] [00:03:07/00:10:32, 0.664s/it]: train_loss_raw=0.9259, running_loss=0.9551, LR=0.000100
[2025-08-26 03:31:19,099][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028672] [Batch 00290/01234] [00:03:12/00:10:26, 0.664s/it]: train_loss_raw=1.0082, running_loss=0.9562, LR=0.000100
[2025-08-26 03:31:24,308][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028680] [Batch 00298/01234] [00:03:17/00:10:21, 0.664s/it]: train_loss_raw=0.8979, running_loss=0.9538, LR=0.000100
[2025-08-26 03:31:30,126][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028688] [Batch 00306/01234] [00:03:23/00:10:17, 0.665s/it]: train_loss_raw=0.9091, running_loss=0.9543, LR=0.000100
[2025-08-26 03:31:35,740][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028696] [Batch 00314/01234] [00:03:29/00:10:12, 0.666s/it]: train_loss_raw=0.9735, running_loss=0.9550, LR=0.000100
[2025-08-26 03:31:41,155][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028704] [Batch 00322/01234] [00:03:34/00:10:07, 0.666s/it]: train_loss_raw=1.0453, running_loss=0.9575, LR=0.000100
[2025-08-26 03:31:46,225][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028712] [Batch 00330/01234] [00:03:39/00:10:01, 0.666s/it]: train_loss_raw=1.0516, running_loss=0.9595, LR=0.000100
[2025-08-26 03:31:51,288][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028720] [Batch 00338/01234] [00:03:44/00:09:55, 0.665s/it]: train_loss_raw=0.9643, running_loss=0.9595, LR=0.000100
[2025-08-26 03:31:56,503][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028728] [Batch 00346/01234] [00:03:49/00:09:50, 0.665s/it]: train_loss_raw=0.8307, running_loss=0.9607, LR=0.000100
[2025-08-26 03:32:02,072][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028736] [Batch 00354/01234] [00:03:55/00:09:45, 0.665s/it]: train_loss_raw=1.0401, running_loss=0.9596, LR=0.000100
[2025-08-26 03:32:07,151][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028744] [Batch 00362/01234] [00:04:00/00:09:39, 0.665s/it]: train_loss_raw=0.9843, running_loss=0.9613, LR=0.000100
[2025-08-26 03:32:12,234][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028752] [Batch 00370/01234] [00:04:05/00:09:33, 0.664s/it]: train_loss_raw=1.0209, running_loss=0.9612, LR=0.000100
[2025-08-26 03:32:17,332][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028760] [Batch 00378/01234] [00:04:10/00:09:27, 0.663s/it]: train_loss_raw=1.0184, running_loss=0.9622, LR=0.000100
[2025-08-26 03:32:22,511][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028768] [Batch 00386/01234] [00:04:15/00:09:22, 0.663s/it]: train_loss_raw=1.0288, running_loss=0.9644, LR=0.000100
[2025-08-26 03:32:28,156][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028776] [Batch 00394/01234] [00:04:21/00:09:17, 0.664s/it]: train_loss_raw=1.0276, running_loss=0.9661, LR=0.000100
[2025-08-26 03:32:33,240][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028784] [Batch 00402/01234] [00:04:26/00:09:11, 0.663s/it]: train_loss_raw=1.0475, running_loss=0.9664, LR=0.000100
[2025-08-26 03:32:38,553][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028792] [Batch 00410/01234] [00:04:31/00:09:06, 0.663s/it]: train_loss_raw=0.9011, running_loss=0.9660, LR=0.000100
[2025-08-26 03:32:44,456][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028800] [Batch 00418/01234] [00:04:37/00:09:02, 0.665s/it]: train_loss_raw=0.9876, running_loss=0.9668, LR=0.000100
[2025-08-26 03:32:50,183][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028808] [Batch 00426/01234] [00:04:43/00:08:57, 0.666s/it]: train_loss_raw=0.9452, running_loss=0.9691, LR=0.000100
[2025-08-26 03:32:56,078][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028816] [Batch 00434/01234] [00:04:49/00:08:53, 0.667s/it]: train_loss_raw=1.0055, running_loss=0.9696, LR=0.000100
[2025-08-26 03:33:02,063][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028824] [Batch 00442/01234] [00:04:55/00:08:49, 0.669s/it]: train_loss_raw=0.9902, running_loss=0.9708, LR=0.000100
[2025-08-26 03:33:07,618][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028832] [Batch 00450/01234] [00:05:01/00:08:44, 0.669s/it]: train_loss_raw=0.9256, running_loss=0.9716, LR=0.000100
[2025-08-26 03:33:12,785][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028840] [Batch 00458/01234] [00:05:06/00:08:38, 0.669s/it]: train_loss_raw=0.9861, running_loss=0.9739, LR=0.000100
[2025-08-26 03:33:17,989][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028848] [Batch 00466/01234] [00:05:11/00:08:33, 0.668s/it]: train_loss_raw=1.0427, running_loss=0.9752, LR=0.000100
[2025-08-26 03:33:23,231][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028856] [Batch 00474/01234] [00:05:16/00:08:27, 0.668s/it]: train_loss_raw=0.9208, running_loss=0.9741, LR=0.000100
[2025-08-26 03:33:28,330][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028864] [Batch 00482/01234] [00:05:21/00:08:22, 0.668s/it]: train_loss_raw=0.9261, running_loss=0.9764, LR=0.000100
[2025-08-26 03:33:34,035][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028872] [Batch 00490/01234] [00:05:27/00:08:17, 0.668s/it]: train_loss_raw=1.0743, running_loss=0.9775, LR=0.000100
[2025-08-26 03:33:39,381][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028880] [Batch 00498/01234] [00:05:32/00:08:11, 0.668s/it]: train_loss_raw=1.0396, running_loss=0.9791, LR=0.000100
[2025-08-26 03:33:44,665][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028888] [Batch 00506/01234] [00:05:38/00:08:06, 0.668s/it]: train_loss_raw=0.9107, running_loss=0.9791, LR=0.000100
[2025-08-26 03:33:50,289][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028896] [Batch 00514/01234] [00:05:43/00:08:01, 0.669s/it]: train_loss_raw=1.0378, running_loss=0.9774, LR=0.000100
[2025-08-26 03:33:55,371][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028904] [Batch 00522/01234] [00:05:48/00:07:55, 0.668s/it]: train_loss_raw=1.0281, running_loss=0.9759, LR=0.000100
[2025-08-26 03:34:00,452][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028912] [Batch 00530/01234] [00:05:53/00:07:50, 0.668s/it]: train_loss_raw=0.9435, running_loss=0.9746, LR=0.000100
[2025-08-26 03:34:05,631][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028920] [Batch 00538/01234] [00:05:59/00:07:44, 0.667s/it]: train_loss_raw=0.9927, running_loss=0.9782, LR=0.000100
[2025-08-26 03:34:11,014][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028928] [Batch 00546/01234] [00:06:04/00:07:39, 0.667s/it]: train_loss_raw=1.0631, running_loss=0.9807, LR=0.000100
[2025-08-26 03:34:16,119][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028936] [Batch 00554/01234] [00:06:09/00:07:33, 0.667s/it]: train_loss_raw=1.0378, running_loss=0.9820, LR=0.000100
[2025-08-26 03:34:21,215][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028944] [Batch 00562/01234] [00:06:14/00:07:27, 0.667s/it]: train_loss_raw=0.9772, running_loss=0.9813, LR=0.000100
[2025-08-26 03:34:26,312][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028952] [Batch 00570/01234] [00:06:19/00:07:22, 0.666s/it]: train_loss_raw=0.9970, running_loss=0.9822, LR=0.000100
[2025-08-26 03:34:31,705][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028960] [Batch 00578/01234] [00:06:25/00:07:17, 0.666s/it]: train_loss_raw=1.0046, running_loss=0.9838, LR=0.000100
[2025-08-26 03:34:36,770][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028968] [Batch 00586/01234] [00:06:30/00:07:11, 0.666s/it]: train_loss_raw=1.0003, running_loss=0.9825, LR=0.000100
[2025-08-26 03:34:41,853][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028976] [Batch 00594/01234] [00:06:35/00:07:05, 0.665s/it]: train_loss_raw=0.9370, running_loss=0.9803, LR=0.000100
[2025-08-26 03:34:47,318][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028984] [Batch 00602/01234] [00:06:40/00:07:00, 0.666s/it]: train_loss_raw=0.9530, running_loss=0.9814, LR=0.000100
[2025-08-26 03:34:53,039][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 028992] [Batch 00610/01234] [00:06:46/00:06:55, 0.666s/it]: train_loss_raw=0.9118, running_loss=0.9811, LR=0.000100
[2025-08-26 03:34:58,337][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029000] [Batch 00618/01234] [00:06:51/00:06:50, 0.666s/it]: train_loss_raw=0.8998, running_loss=0.9810, LR=0.000100
[2025-08-26 03:35:03,512][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029008] [Batch 00626/01234] [00:06:56/00:06:44, 0.666s/it]: train_loss_raw=0.9658, running_loss=0.9791, LR=0.000100
[2025-08-26 03:35:08,579][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029016] [Batch 00634/01234] [00:07:02/00:06:39, 0.666s/it]: train_loss_raw=0.9449, running_loss=0.9803, LR=0.000100
[2025-08-26 03:35:13,811][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029024] [Batch 00642/01234] [00:07:07/00:06:33, 0.665s/it]: train_loss_raw=1.0632, running_loss=0.9823, LR=0.000100
[2025-08-26 03:35:19,461][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029032] [Batch 00650/01234] [00:07:12/00:06:28, 0.666s/it]: train_loss_raw=0.9814, running_loss=0.9839, LR=0.000100
[2025-08-26 03:35:25,251][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029040] [Batch 00658/01234] [00:07:18/00:06:24, 0.667s/it]: train_loss_raw=0.8613, running_loss=0.9827, LR=0.000100
[2025-08-26 03:35:30,657][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029048] [Batch 00666/01234] [00:07:24/00:06:18, 0.667s/it]: train_loss_raw=1.1351, running_loss=0.9829, LR=0.000100
[2025-08-26 03:35:36,243][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029056] [Batch 00674/01234] [00:07:29/00:06:13, 0.667s/it]: train_loss_raw=1.0068, running_loss=0.9815, LR=0.000100
[2025-08-26 03:35:41,953][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029064] [Batch 00682/01234] [00:07:35/00:06:08, 0.668s/it]: train_loss_raw=0.9897, running_loss=0.9826, LR=0.000100
[2025-08-26 03:35:47,032][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029072] [Batch 00690/01234] [00:07:40/00:06:03, 0.667s/it]: train_loss_raw=1.0862, running_loss=0.9852, LR=0.000100
[2025-08-26 03:35:52,150][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029080] [Batch 00698/01234] [00:07:45/00:05:57, 0.667s/it]: train_loss_raw=0.9704, running_loss=0.9855, LR=0.000100
[2025-08-26 03:35:58,070][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029088] [Batch 00706/01234] [00:07:51/00:05:52, 0.668s/it]: train_loss_raw=0.9700, running_loss=0.9861, LR=0.000100
[2025-08-26 03:36:03,867][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029096] [Batch 00714/01234] [00:07:57/00:05:47, 0.668s/it]: train_loss_raw=0.9354, running_loss=0.9865, LR=0.000100
[2025-08-26 03:36:09,747][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029104] [Batch 00722/01234] [00:08:03/00:05:42, 0.669s/it]: train_loss_raw=1.0812, running_loss=0.9873, LR=0.000100
[2025-08-26 03:36:15,078][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029112] [Batch 00730/01234] [00:08:08/00:05:37, 0.669s/it]: train_loss_raw=0.9330, running_loss=0.9871, LR=0.000100
[2025-08-26 03:36:20,567][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029120] [Batch 00738/01234] [00:08:14/00:05:32, 0.669s/it]: train_loss_raw=1.0349, running_loss=0.9859, LR=0.000100
[2025-08-26 03:36:26,053][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029128] [Batch 00746/01234] [00:08:19/00:05:26, 0.670s/it]: train_loss_raw=0.9313, running_loss=0.9858, LR=0.000100
[2025-08-26 03:36:31,732][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029136] [Batch 00754/01234] [00:08:25/00:05:21, 0.670s/it]: train_loss_raw=0.9946, running_loss=0.9853, LR=0.000100
[2025-08-26 03:36:37,516][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029144] [Batch 00762/01234] [00:08:30/00:05:16, 0.671s/it]: train_loss_raw=1.0288, running_loss=0.9875, LR=0.000100
[2025-08-26 03:36:42,694][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029152] [Batch 00770/01234] [00:08:36/00:05:11, 0.670s/it]: train_loss_raw=1.0628, running_loss=0.9854, LR=0.000100
[2025-08-26 03:36:47,755][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029160] [Batch 00778/01234] [00:08:41/00:05:05, 0.670s/it]: train_loss_raw=0.9104, running_loss=0.9868, LR=0.000100
[2025-08-26 03:36:53,050][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029168] [Batch 00786/01234] [00:08:46/00:05:00, 0.670s/it]: train_loss_raw=0.9728, running_loss=0.9853, LR=0.000100
[2025-08-26 03:36:58,170][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029176] [Batch 00794/01234] [00:08:51/00:04:54, 0.670s/it]: train_loss_raw=0.9597, running_loss=0.9853, LR=0.000100
[2025-08-26 03:37:03,453][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029184] [Batch 00802/01234] [00:08:56/00:04:49, 0.669s/it]: train_loss_raw=0.9853, running_loss=0.9851, LR=0.000100
[2025-08-26 03:37:08,523][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029192] [Batch 00810/01234] [00:09:01/00:04:43, 0.669s/it]: train_loss_raw=1.0545, running_loss=0.9842, LR=0.000100
[2025-08-26 03:37:14,309][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029200] [Batch 00818/01234] [00:09:07/00:04:38, 0.670s/it]: train_loss_raw=0.9391, running_loss=0.9868, LR=0.000100
[2025-08-26 03:37:20,179][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029208] [Batch 00826/01234] [00:09:13/00:04:33, 0.670s/it]: train_loss_raw=0.9841, running_loss=0.9892, LR=0.000100
[2025-08-26 03:37:25,652][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029216] [Batch 00834/01234] [00:09:19/00:04:28, 0.670s/it]: train_loss_raw=1.1008, running_loss=0.9908, LR=0.000100
[2025-08-26 03:37:30,896][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029224] [Batch 00842/01234] [00:09:24/00:04:22, 0.670s/it]: train_loss_raw=1.0196, running_loss=0.9908, LR=0.000100
[2025-08-26 03:37:36,270][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029232] [Batch 00850/01234] [00:09:29/00:04:17, 0.670s/it]: train_loss_raw=0.9017, running_loss=0.9902, LR=0.000100
[2025-08-26 03:37:41,789][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029240] [Batch 00858/01234] [00:09:35/00:04:12, 0.670s/it]: train_loss_raw=1.0480, running_loss=0.9905, LR=0.000100
[2025-08-26 03:37:47,181][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029248] [Batch 00866/01234] [00:09:40/00:04:06, 0.670s/it]: train_loss_raw=0.9013, running_loss=0.9906, LR=0.000100
[2025-08-26 03:37:52,453][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029256] [Batch 00874/01234] [00:09:45/00:04:01, 0.670s/it]: train_loss_raw=1.0062, running_loss=0.9921, LR=0.000100
[2025-08-26 03:37:57,570][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029264] [Batch 00882/01234] [00:09:51/00:03:55, 0.670s/it]: train_loss_raw=1.0040, running_loss=0.9906, LR=0.000100
[2025-08-26 03:38:03,035][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029272] [Batch 00890/01234] [00:09:56/00:03:50, 0.670s/it]: train_loss_raw=1.0758, running_loss=0.9923, LR=0.000100
[2025-08-26 03:38:09,024][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029280] [Batch 00898/01234] [00:10:02/00:03:45, 0.671s/it]: train_loss_raw=1.0059, running_loss=0.9929, LR=0.000100
[2025-08-26 03:38:14,716][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029288] [Batch 00906/01234] [00:10:08/00:03:40, 0.671s/it]: train_loss_raw=1.0431, running_loss=0.9937, LR=0.000100
[2025-08-26 03:38:19,804][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029296] [Batch 00914/01234] [00:10:13/00:03:34, 0.671s/it]: train_loss_raw=0.8818, running_loss=0.9919, LR=0.000100
[2025-08-26 03:38:24,887][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029304] [Batch 00922/01234] [00:10:18/00:03:29, 0.671s/it]: train_loss_raw=1.0351, running_loss=0.9916, LR=0.000100
[2025-08-26 03:38:30,383][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029312] [Batch 00930/01234] [00:10:23/00:03:23, 0.671s/it]: train_loss_raw=1.0071, running_loss=0.9918, LR=0.000100
[2025-08-26 03:38:36,300][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029320] [Batch 00938/01234] [00:10:29/00:03:18, 0.671s/it]: train_loss_raw=0.9757, running_loss=0.9914, LR=0.000100
[2025-08-26 03:38:42,372][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029328] [Batch 00946/01234] [00:10:35/00:03:13, 0.672s/it]: train_loss_raw=0.9271, running_loss=0.9940, LR=0.000100
[2025-08-26 03:38:47,865][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029336] [Batch 00954/01234] [00:10:41/00:03:08, 0.672s/it]: train_loss_raw=1.0448, running_loss=0.9958, LR=0.000100
[2025-08-26 03:38:52,948][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029344] [Batch 00962/01234] [00:10:46/00:03:02, 0.672s/it]: train_loss_raw=1.0048, running_loss=0.9947, LR=0.000100
[2025-08-26 03:38:58,049][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029352] [Batch 00970/01234] [00:10:51/00:02:57, 0.672s/it]: train_loss_raw=0.9944, running_loss=0.9953, LR=0.000100
[2025-08-26 03:39:03,153][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029360] [Batch 00978/01234] [00:10:56/00:02:51, 0.671s/it]: train_loss_raw=1.0135, running_loss=0.9929, LR=0.000100
[2025-08-26 03:39:08,237][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029368] [Batch 00986/01234] [00:11:01/00:02:46, 0.671s/it]: train_loss_raw=0.9728, running_loss=0.9930, LR=0.000100
[2025-08-26 03:39:13,450][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029376] [Batch 00994/01234] [00:11:06/00:02:41, 0.671s/it]: train_loss_raw=0.9849, running_loss=0.9938, LR=0.000100
[2025-08-26 03:39:18,509][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029384] [Batch 01002/01234] [00:11:11/00:02:35, 0.671s/it]: train_loss_raw=0.9760, running_loss=0.9931, LR=0.000100
[2025-08-26 03:39:24,045][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029392] [Batch 01010/01234] [00:11:17/00:02:30, 0.671s/it]: train_loss_raw=1.0253, running_loss=0.9939, LR=0.000100
[2025-08-26 03:39:29,537][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029400] [Batch 01018/01234] [00:11:22/00:02:24, 0.671s/it]: train_loss_raw=0.9571, running_loss=0.9927, LR=0.000100
[2025-08-26 03:39:34,745][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029408] [Batch 01026/01234] [00:11:28/00:02:19, 0.671s/it]: train_loss_raw=0.9447, running_loss=0.9912, LR=0.000100
[2025-08-26 03:39:40,251][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029416] [Batch 01034/01234] [00:11:33/00:02:14, 0.671s/it]: train_loss_raw=1.0112, running_loss=0.9904, LR=0.000100
[2025-08-26 03:39:45,629][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029424] [Batch 01042/01234] [00:11:39/00:02:08, 0.671s/it]: train_loss_raw=0.9723, running_loss=0.9913, LR=0.000100
[2025-08-26 03:39:50,692][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029432] [Batch 01050/01234] [00:11:44/00:02:03, 0.671s/it]: train_loss_raw=0.9847, running_loss=0.9906, LR=0.000100
[2025-08-26 03:39:55,756][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029440] [Batch 01058/01234] [00:11:49/00:01:57, 0.670s/it]: train_loss_raw=1.0574, running_loss=0.9908, LR=0.000100
[2025-08-26 03:40:01,284][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029448] [Batch 01066/01234] [00:11:54/00:01:52, 0.670s/it]: train_loss_raw=0.9313, running_loss=0.9890, LR=0.000100
[2025-08-26 03:40:06,598][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029456] [Batch 01074/01234] [00:12:00/00:01:47, 0.670s/it]: train_loss_raw=1.0114, running_loss=0.9912, LR=0.000100
[2025-08-26 03:40:11,822][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029464] [Batch 01082/01234] [00:12:05/00:01:41, 0.670s/it]: train_loss_raw=0.9215, running_loss=0.9929, LR=0.000100
[2025-08-26 03:40:17,713][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029472] [Batch 01090/01234] [00:12:11/00:01:36, 0.671s/it]: train_loss_raw=1.0975, running_loss=0.9931, LR=0.000100
[2025-08-26 03:40:23,497][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029480] [Batch 01098/01234] [00:12:16/00:01:31, 0.671s/it]: train_loss_raw=0.9361, running_loss=0.9934, LR=0.000100
[2025-08-26 03:40:29,112][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029488] [Batch 01106/01234] [00:12:22/00:01:25, 0.671s/it]: train_loss_raw=1.0696, running_loss=0.9937, LR=0.000100
[2025-08-26 03:40:34,180][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029496] [Batch 01114/01234] [00:12:27/00:01:20, 0.671s/it]: train_loss_raw=1.0465, running_loss=0.9974, LR=0.000100
[2025-08-26 03:40:39,235][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029504] [Batch 01122/01234] [00:12:32/00:01:15, 0.671s/it]: train_loss_raw=1.0350, running_loss=0.9950, LR=0.000100
[2025-08-26 03:40:44,445][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029512] [Batch 01130/01234] [00:12:37/00:01:09, 0.671s/it]: train_loss_raw=1.0526, running_loss=0.9970, LR=0.000100
[2025-08-26 03:40:50,427][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029520] [Batch 01138/01234] [00:12:43/00:01:04, 0.671s/it]: train_loss_raw=1.0708, running_loss=0.9989, LR=0.000100
[2025-08-26 03:40:56,040][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029528] [Batch 01146/01234] [00:12:49/00:00:59, 0.671s/it]: train_loss_raw=1.0047, running_loss=0.9988, LR=0.000100
[2025-08-26 03:41:01,443][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029536] [Batch 01154/01234] [00:12:54/00:00:53, 0.671s/it]: train_loss_raw=0.9769, running_loss=0.9972, LR=0.000100
[2025-08-26 03:41:06,511][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029544] [Batch 01162/01234] [00:12:59/00:00:48, 0.671s/it]: train_loss_raw=0.9611, running_loss=0.9961, LR=0.000100
[2025-08-26 03:41:11,554][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029552] [Batch 01170/01234] [00:13:04/00:00:42, 0.671s/it]: train_loss_raw=1.0517, running_loss=0.9955, LR=0.000100
[2025-08-26 03:41:16,625][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029560] [Batch 01178/01234] [00:13:10/00:00:37, 0.671s/it]: train_loss_raw=0.9859, running_loss=0.9982, LR=0.000100
[2025-08-26 03:41:21,688][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029568] [Batch 01186/01234] [00:13:15/00:00:32, 0.670s/it]: train_loss_raw=1.0326, running_loss=0.9999, LR=0.000100
[2025-08-26 03:41:26,793][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029576] [Batch 01194/01234] [00:13:20/00:00:26, 0.670s/it]: train_loss_raw=0.9450, running_loss=0.9992, LR=0.000100
[2025-08-26 03:41:32,360][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029584] [Batch 01202/01234] [00:13:25/00:00:21, 0.670s/it]: train_loss_raw=1.0319, running_loss=0.9988, LR=0.000100
[2025-08-26 03:41:37,407][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029592] [Batch 01210/01234] [00:13:30/00:00:16, 0.670s/it]: train_loss_raw=1.1459, running_loss=1.0001, LR=0.000100
[2025-08-26 03:41:42,819][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029600] [Batch 01218/01234] [00:13:36/00:00:10, 0.670s/it]: train_loss_raw=1.1243, running_loss=1.0012, LR=0.000100
[2025-08-26 03:41:47,930][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029608] [Batch 01226/01234] [00:13:41/00:00:05, 0.670s/it]: train_loss_raw=1.0168, running_loss=1.0004, LR=0.000100
[2025-08-26 03:41:59,464][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 029616] [Batch 01234/01234] [00:13:52/00:00:00, 0.675s/it]: train_loss_raw=0.9122, running_loss=1.0006, LR=0.000100
[2025-08-26 03:41:59,908][__main__][INFO] - [VALIDATION] [Epoch 23/29] Starting validation.
[2025-08-26 03:42:10,412][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 029617] [Batch 00007/00026] [00:00:10/00:00:23, 1.313s/it]
[2025-08-26 03:42:21,695][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 029617] [Batch 00015/00026] [00:00:21/00:00:13, 1.362s/it]
[2025-08-26 03:42:32,468][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 029617] [Batch 00023/00026] [00:00:32/00:00:02, 1.357s/it]
[2025-08-26 03:42:34,764][__main__][INFO] - [VALIDATION] [Epoch 23/29] train_loss=1.00058, valid_loss=1.63168
[2025-08-26 03:42:34,765][__main__][INFO] - [VALIDATION] [Epoch 23/29] Metrics:
[2025-08-26 03:42:34,765][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_er      0.602
[2025-08-26 03:42:34,765][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_prec    0.061
[2025-08-26 03:42:34,765][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_recall  0.062
[2025-08-26 03:42:34,765][__main__][INFO] - [VALIDATION] [Epoch 23/29] - pep_recall 0.019
[2025-08-26 03:42:34,766][__main__][INFO] - [TRAIN] [Epoch 23/29] Epoch complete, total time 05:51:43, remaining time 01:27:55, 00:14:39 per epoch
[2025-08-26 03:42:39,477][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029624] [Batch 00008/01234] [00:00:04/00:11:41, 0.572s/it]: train_loss_raw=0.9398, running_loss=0.8496, LR=0.000100
[2025-08-26 03:42:45,007][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029632] [Batch 00016/01234] [00:00:10/00:12:49, 0.632s/it]: train_loss_raw=0.9013, running_loss=0.8523, LR=0.000100
[2025-08-26 03:42:50,463][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029640] [Batch 00024/01234] [00:00:15/00:13:04, 0.649s/it]: train_loss_raw=0.8388, running_loss=0.8540, LR=0.000100
[2025-08-26 03:42:55,616][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029648] [Batch 00032/01234] [00:00:20/00:12:58, 0.647s/it]: train_loss_raw=0.8484, running_loss=0.8548, LR=0.000100
[2025-08-26 03:43:01,213][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029656] [Batch 00040/01234] [00:00:26/00:13:05, 0.658s/it]: train_loss_raw=0.7930, running_loss=0.8601, LR=0.000100
[2025-08-26 03:43:06,395][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029664] [Batch 00048/01234] [00:00:31/00:12:58, 0.656s/it]: train_loss_raw=0.8880, running_loss=0.8645, LR=0.000100
[2025-08-26 03:43:12,201][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029672] [Batch 00056/01234] [00:00:37/00:13:04, 0.666s/it]: train_loss_raw=0.9892, running_loss=0.8687, LR=0.000100
[2025-08-26 03:43:17,734][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029680] [Batch 00064/01234] [00:00:42/00:13:03, 0.669s/it]: train_loss_raw=0.9479, running_loss=0.8722, LR=0.000100
[2025-08-26 03:43:23,785][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029688] [Batch 00072/01234] [00:00:48/00:13:08, 0.679s/it]: train_loss_raw=0.8857, running_loss=0.8740, LR=0.000100
[2025-08-26 03:43:29,814][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029696] [Batch 00080/01234] [00:00:54/00:13:12, 0.686s/it]: train_loss_raw=0.9046, running_loss=0.8734, LR=0.000100
[2025-08-26 03:43:35,768][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029704] [Batch 00088/01234] [00:01:00/00:13:12, 0.692s/it]: train_loss_raw=0.9373, running_loss=0.8759, LR=0.000100
[2025-08-26 03:43:41,195][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029712] [Batch 00096/01234] [00:01:06/00:13:05, 0.691s/it]: train_loss_raw=0.9205, running_loss=0.8765, LR=0.000100
[2025-08-26 03:43:46,553][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029720] [Batch 00104/01234] [00:01:11/00:12:58, 0.689s/it]: train_loss_raw=0.9896, running_loss=0.8811, LR=0.000100
[2025-08-26 03:43:52,113][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029728] [Batch 00112/01234] [00:01:17/00:12:53, 0.689s/it]: train_loss_raw=0.9012, running_loss=0.8826, LR=0.000100
[2025-08-26 03:43:57,424][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029736] [Batch 00120/01234] [00:01:22/00:12:46, 0.688s/it]: train_loss_raw=0.8205, running_loss=0.8849, LR=0.000100
[2025-08-26 03:44:03,149][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029744] [Batch 00128/01234] [00:01:28/00:12:42, 0.689s/it]: train_loss_raw=0.8867, running_loss=0.8859, LR=0.000100
[2025-08-26 03:44:08,222][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029752] [Batch 00136/01234] [00:01:33/00:12:33, 0.686s/it]: train_loss_raw=0.8845, running_loss=0.8883, LR=0.000100
[2025-08-26 03:44:14,239][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029760] [Batch 00144/01234] [00:01:39/00:12:31, 0.690s/it]: train_loss_raw=0.9546, running_loss=0.8891, LR=0.000100
[2025-08-26 03:44:19,464][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029768] [Batch 00152/01234] [00:01:44/00:12:24, 0.688s/it]: train_loss_raw=0.8422, running_loss=0.8916, LR=0.000100
[2025-08-26 03:44:25,033][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029776] [Batch 00160/01234] [00:01:50/00:12:19, 0.688s/it]: train_loss_raw=0.9545, running_loss=0.8942, LR=0.000100
[2025-08-26 03:44:30,822][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029784] [Batch 00168/01234] [00:01:55/00:12:15, 0.690s/it]: train_loss_raw=0.9105, running_loss=0.8963, LR=0.000100
[2025-08-26 03:44:36,294][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029792] [Batch 00176/01234] [00:02:01/00:12:09, 0.690s/it]: train_loss_raw=0.8866, running_loss=0.8958, LR=0.000100
[2025-08-26 03:44:41,678][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029800] [Batch 00184/01234] [00:02:06/00:12:03, 0.689s/it]: train_loss_raw=0.9332, running_loss=0.8968, LR=0.000100
[2025-08-26 03:44:47,246][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029808] [Batch 00192/01234] [00:02:12/00:11:58, 0.689s/it]: train_loss_raw=0.9267, running_loss=0.8992, LR=0.000100
[2025-08-26 03:44:52,522][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029816] [Batch 00200/01234] [00:02:17/00:11:51, 0.688s/it]: train_loss_raw=0.9232, running_loss=0.9026, LR=0.000100
[2025-08-26 03:44:58,119][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029824] [Batch 00208/01234] [00:02:23/00:11:46, 0.689s/it]: train_loss_raw=0.9020, running_loss=0.9043, LR=0.000100
[2025-08-26 03:45:03,729][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029832] [Batch 00216/01234] [00:02:28/00:11:41, 0.689s/it]: train_loss_raw=0.8980, running_loss=0.9047, LR=0.000100
[2025-08-26 03:45:09,515][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029840] [Batch 00224/01234] [00:02:34/00:11:37, 0.690s/it]: train_loss_raw=0.8064, running_loss=0.9055, LR=0.000100
[2025-08-26 03:45:14,739][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029848] [Batch 00232/01234] [00:02:39/00:11:30, 0.689s/it]: train_loss_raw=0.9580, running_loss=0.9069, LR=0.000100
[2025-08-26 03:45:20,396][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029856] [Batch 00240/01234] [00:02:45/00:11:25, 0.690s/it]: train_loss_raw=0.8879, running_loss=0.9071, LR=0.000100
[2025-08-26 03:45:25,943][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029864] [Batch 00248/01234] [00:02:51/00:11:20, 0.690s/it]: train_loss_raw=0.8996, running_loss=0.9105, LR=0.000100
[2025-08-26 03:45:31,311][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029872] [Batch 00256/01234] [00:02:56/00:11:13, 0.689s/it]: train_loss_raw=0.8480, running_loss=0.9116, LR=0.000100
[2025-08-26 03:45:36,356][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029880] [Batch 00264/01234] [00:03:01/00:11:06, 0.687s/it]: train_loss_raw=0.8779, running_loss=0.9100, LR=0.000100
[2025-08-26 03:45:41,739][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029888] [Batch 00272/01234] [00:03:06/00:11:00, 0.687s/it]: train_loss_raw=0.9528, running_loss=0.9104, LR=0.000100
[2025-08-26 03:45:47,437][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029896] [Batch 00280/01234] [00:03:12/00:10:56, 0.688s/it]: train_loss_raw=0.9734, running_loss=0.9135, LR=0.000100
[2025-08-26 03:45:52,514][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029904] [Batch 00288/01234] [00:03:17/00:10:49, 0.686s/it]: train_loss_raw=0.9389, running_loss=0.9161, LR=0.000100
[2025-08-26 03:45:58,277][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029912] [Batch 00296/01234] [00:03:23/00:10:44, 0.687s/it]: train_loss_raw=0.9253, running_loss=0.9172, LR=0.000100
[2025-08-26 03:46:03,610][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029920] [Batch 00304/01234] [00:03:28/00:10:38, 0.687s/it]: train_loss_raw=0.8587, running_loss=0.9179, LR=0.000100
[2025-08-26 03:46:09,120][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029928] [Batch 00312/01234] [00:03:34/00:10:33, 0.687s/it]: train_loss_raw=0.9240, running_loss=0.9174, LR=0.000100
[2025-08-26 03:46:14,472][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029936] [Batch 00320/01234] [00:03:39/00:10:27, 0.686s/it]: train_loss_raw=0.9221, running_loss=0.9194, LR=0.000100
[2025-08-26 03:46:20,111][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029944] [Batch 00328/01234] [00:03:45/00:10:22, 0.687s/it]: train_loss_raw=0.8359, running_loss=0.9190, LR=0.000100
[2025-08-26 03:46:25,286][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029952] [Batch 00336/01234] [00:03:50/00:10:15, 0.686s/it]: train_loss_raw=0.8769, running_loss=0.9182, LR=0.000100
[2025-08-26 03:46:30,401][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029960] [Batch 00344/01234] [00:03:55/00:10:09, 0.685s/it]: train_loss_raw=0.9124, running_loss=0.9178, LR=0.000100
[2025-08-26 03:46:35,481][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029968] [Batch 00352/01234] [00:04:00/00:10:02, 0.683s/it]: train_loss_raw=0.9960, running_loss=0.9213, LR=0.000100
[2025-08-26 03:46:40,545][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029976] [Batch 00360/01234] [00:04:05/00:09:56, 0.682s/it]: train_loss_raw=0.9575, running_loss=0.9219, LR=0.000100
[2025-08-26 03:46:45,618][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029984] [Batch 00368/01234] [00:04:10/00:09:50, 0.681s/it]: train_loss_raw=0.9139, running_loss=0.9249, LR=0.000100
[2025-08-26 03:46:51,342][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 029992] [Batch 00376/01234] [00:04:16/00:09:45, 0.682s/it]: train_loss_raw=0.9633, running_loss=0.9245, LR=0.000100
[2025-08-26 03:46:57,062][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030000] [Batch 00384/01234] [00:04:22/00:09:40, 0.683s/it]: train_loss_raw=0.9831, running_loss=0.9287, LR=0.000100
[2025-08-26 03:47:06,484][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030008] [Batch 00392/01234] [00:04:31/00:09:43, 0.693s/it]: train_loss_raw=0.9694, running_loss=0.9307, LR=0.000100
[2025-08-26 03:47:11,931][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030016] [Batch 00400/01234] [00:04:37/00:09:37, 0.693s/it]: train_loss_raw=0.9128, running_loss=0.9304, LR=0.000100
[2025-08-26 03:47:17,910][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030024] [Batch 00408/01234] [00:04:43/00:09:32, 0.694s/it]: train_loss_raw=0.8314, running_loss=0.9279, LR=0.000100
[2025-08-26 03:47:23,609][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030032] [Batch 00416/01234] [00:04:48/00:09:27, 0.694s/it]: train_loss_raw=0.9703, running_loss=0.9299, LR=0.000100
[2025-08-26 03:47:29,053][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030040] [Batch 00424/01234] [00:04:54/00:09:21, 0.694s/it]: train_loss_raw=0.8996, running_loss=0.9296, LR=0.000100
[2025-08-26 03:47:34,679][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030048] [Batch 00432/01234] [00:04:59/00:09:16, 0.694s/it]: train_loss_raw=0.9137, running_loss=0.9317, LR=0.000100
[2025-08-26 03:47:39,918][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030056] [Batch 00440/01234] [00:05:05/00:09:10, 0.693s/it]: train_loss_raw=1.0608, running_loss=0.9346, LR=0.000100
[2025-08-26 03:47:45,127][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030064] [Batch 00448/01234] [00:05:10/00:09:04, 0.692s/it]: train_loss_raw=0.8520, running_loss=0.9342, LR=0.000100
[2025-08-26 03:47:50,252][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030072] [Batch 00456/01234] [00:05:15/00:08:58, 0.692s/it]: train_loss_raw=0.8716, running_loss=0.9323, LR=0.000100
[2025-08-26 03:47:55,904][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030080] [Batch 00464/01234] [00:05:21/00:08:52, 0.692s/it]: train_loss_raw=0.9820, running_loss=0.9337, LR=0.000100
[2025-08-26 03:48:01,171][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030088] [Batch 00472/01234] [00:05:26/00:08:46, 0.691s/it]: train_loss_raw=0.9486, running_loss=0.9336, LR=0.000100
[2025-08-26 03:48:06,916][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030096] [Batch 00480/01234] [00:05:32/00:08:41, 0.692s/it]: train_loss_raw=0.8707, running_loss=0.9323, LR=0.000100
[2025-08-26 03:48:12,591][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030104] [Batch 00488/01234] [00:05:37/00:08:36, 0.692s/it]: train_loss_raw=0.9504, running_loss=0.9332, LR=0.000100
[2025-08-26 03:48:17,653][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030112] [Batch 00496/01234] [00:05:42/00:08:29, 0.691s/it]: train_loss_raw=0.9817, running_loss=0.9344, LR=0.000100
[2025-08-26 03:48:22,705][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030120] [Batch 00504/01234] [00:05:47/00:08:23, 0.690s/it]: train_loss_raw=0.9047, running_loss=0.9326, LR=0.000100
[2025-08-26 03:48:27,792][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030128] [Batch 00512/01234] [00:05:52/00:08:17, 0.689s/it]: train_loss_raw=0.9785, running_loss=0.9320, LR=0.000100
[2025-08-26 03:48:32,972][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030136] [Batch 00520/01234] [00:05:58/00:08:11, 0.689s/it]: train_loss_raw=0.9598, running_loss=0.9318, LR=0.000100
[2025-08-26 03:48:38,341][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030144] [Batch 00528/01234] [00:06:03/00:08:05, 0.688s/it]: train_loss_raw=0.9716, running_loss=0.9337, LR=0.000100
[2025-08-26 03:48:43,562][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030152] [Batch 00536/01234] [00:06:08/00:08:00, 0.688s/it]: train_loss_raw=0.9264, running_loss=0.9340, LR=0.000100
[2025-08-26 03:48:49,091][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030160] [Batch 00544/01234] [00:06:14/00:07:54, 0.688s/it]: train_loss_raw=0.8791, running_loss=0.9354, LR=0.000100
[2025-08-26 03:48:54,528][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030168] [Batch 00552/01234] [00:06:19/00:07:49, 0.688s/it]: train_loss_raw=0.9097, running_loss=0.9353, LR=0.000100
[2025-08-26 03:49:00,253][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030176] [Batch 00560/01234] [00:06:25/00:07:43, 0.688s/it]: train_loss_raw=0.9829, running_loss=0.9387, LR=0.000100
[2025-08-26 03:49:05,931][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030184] [Batch 00568/01234] [00:06:31/00:07:38, 0.688s/it]: train_loss_raw=0.9902, running_loss=0.9408, LR=0.000100
[2025-08-26 03:49:11,049][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030192] [Batch 00576/01234] [00:06:36/00:07:32, 0.688s/it]: train_loss_raw=0.9815, running_loss=0.9404, LR=0.000100
[2025-08-26 03:49:16,664][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030200] [Batch 00584/01234] [00:06:41/00:07:27, 0.688s/it]: train_loss_raw=0.8661, running_loss=0.9414, LR=0.000100
[2025-08-26 03:49:21,762][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030208] [Batch 00592/01234] [00:06:46/00:07:21, 0.687s/it]: train_loss_raw=0.9409, running_loss=0.9441, LR=0.000100
[2025-08-26 03:49:26,851][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030216] [Batch 00600/01234] [00:06:51/00:07:15, 0.687s/it]: train_loss_raw=1.0181, running_loss=0.9450, LR=0.000100
[2025-08-26 03:49:32,531][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030224] [Batch 00608/01234] [00:06:57/00:07:09, 0.687s/it]: train_loss_raw=0.9933, running_loss=0.9453, LR=0.000100
[2025-08-26 03:49:37,771][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030232] [Batch 00616/01234] [00:07:02/00:07:04, 0.686s/it]: train_loss_raw=0.9921, running_loss=0.9450, LR=0.000100
[2025-08-26 03:49:43,355][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030240] [Batch 00624/01234] [00:07:08/00:06:58, 0.687s/it]: train_loss_raw=0.8835, running_loss=0.9435, LR=0.000100
[2025-08-26 03:49:49,084][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030248] [Batch 00632/01234] [00:07:14/00:06:53, 0.687s/it]: train_loss_raw=1.0290, running_loss=0.9449, LR=0.000100
[2025-08-26 03:49:54,767][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030256] [Batch 00640/01234] [00:07:19/00:06:48, 0.687s/it]: train_loss_raw=0.9548, running_loss=0.9453, LR=0.000100
[2025-08-26 03:49:59,852][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030264] [Batch 00648/01234] [00:07:24/00:06:42, 0.687s/it]: train_loss_raw=0.9284, running_loss=0.9440, LR=0.000100
[2025-08-26 03:50:04,926][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030272] [Batch 00656/01234] [00:07:30/00:06:36, 0.686s/it]: train_loss_raw=0.8530, running_loss=0.9427, LR=0.000100
[2025-08-26 03:50:10,101][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030280] [Batch 00664/01234] [00:07:35/00:06:30, 0.686s/it]: train_loss_raw=0.9496, running_loss=0.9439, LR=0.000100
[2025-08-26 03:50:15,503][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030288] [Batch 00672/01234] [00:07:40/00:06:25, 0.685s/it]: train_loss_raw=0.9290, running_loss=0.9458, LR=0.000100
[2025-08-26 03:50:20,719][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030296] [Batch 00680/01234] [00:07:45/00:06:19, 0.685s/it]: train_loss_raw=0.9341, running_loss=0.9475, LR=0.000100
[2025-08-26 03:50:26,895][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030304] [Batch 00688/01234] [00:07:51/00:06:14, 0.686s/it]: train_loss_raw=0.9613, running_loss=0.9471, LR=0.000100
[2025-08-26 03:50:32,133][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030312] [Batch 00696/01234] [00:07:57/00:06:08, 0.686s/it]: train_loss_raw=0.9509, running_loss=0.9467, LR=0.000100
[2025-08-26 03:50:37,356][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030320] [Batch 00704/01234] [00:08:02/00:06:03, 0.685s/it]: train_loss_raw=1.0237, running_loss=0.9484, LR=0.000100
[2025-08-26 03:50:43,031][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030328] [Batch 00712/01234] [00:08:08/00:05:57, 0.686s/it]: train_loss_raw=1.0341, running_loss=0.9504, LR=0.000100
[2025-08-26 03:50:48,256][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030336] [Batch 00720/01234] [00:08:13/00:05:52, 0.685s/it]: train_loss_raw=0.9744, running_loss=0.9501, LR=0.000100
[2025-08-26 03:50:53,592][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030344] [Batch 00728/01234] [00:08:18/00:05:46, 0.685s/it]: train_loss_raw=0.8824, running_loss=0.9491, LR=0.000100
[2025-08-26 03:50:59,125][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030352] [Batch 00736/01234] [00:08:24/00:05:41, 0.685s/it]: train_loss_raw=0.9526, running_loss=0.9492, LR=0.000100
[2025-08-26 03:51:04,523][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030360] [Batch 00744/01234] [00:08:29/00:05:35, 0.685s/it]: train_loss_raw=0.9256, running_loss=0.9478, LR=0.000100
[2025-08-26 03:51:09,689][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030368] [Batch 00752/01234] [00:08:34/00:05:29, 0.685s/it]: train_loss_raw=0.9661, running_loss=0.9472, LR=0.000100
[2025-08-26 03:51:15,305][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030376] [Batch 00760/01234] [00:08:40/00:05:24, 0.685s/it]: train_loss_raw=0.9524, running_loss=0.9482, LR=0.000100
[2025-08-26 03:51:20,800][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030384] [Batch 00768/01234] [00:08:45/00:05:19, 0.685s/it]: train_loss_raw=0.9865, running_loss=0.9482, LR=0.000100
[2025-08-26 03:51:26,223][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030392] [Batch 00776/01234] [00:08:51/00:05:13, 0.685s/it]: train_loss_raw=0.8695, running_loss=0.9481, LR=0.000100
[2025-08-26 03:51:32,113][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030400] [Batch 00784/01234] [00:08:57/00:05:08, 0.685s/it]: train_loss_raw=0.9833, running_loss=0.9493, LR=0.000100
[2025-08-26 03:51:37,265][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030408] [Batch 00792/01234] [00:09:02/00:05:02, 0.685s/it]: train_loss_raw=0.9080, running_loss=0.9526, LR=0.000100
[2025-08-26 03:51:42,334][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030416] [Batch 00800/01234] [00:09:07/00:04:56, 0.684s/it]: train_loss_raw=1.0088, running_loss=0.9542, LR=0.000100
[2025-08-26 03:51:47,908][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030424] [Batch 00808/01234] [00:09:13/00:04:51, 0.684s/it]: train_loss_raw=1.0423, running_loss=0.9536, LR=0.000100
[2025-08-26 03:51:53,584][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030432] [Batch 00816/01234] [00:09:18/00:04:46, 0.685s/it]: train_loss_raw=0.8856, running_loss=0.9524, LR=0.000100
[2025-08-26 03:51:59,247][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030440] [Batch 00824/01234] [00:09:24/00:04:40, 0.685s/it]: train_loss_raw=1.0101, running_loss=0.9533, LR=0.000100
[2025-08-26 03:52:04,996][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030448] [Batch 00832/01234] [00:09:30/00:04:35, 0.685s/it]: train_loss_raw=1.0278, running_loss=0.9567, LR=0.000100
[2025-08-26 03:52:10,923][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030456] [Batch 00840/01234] [00:09:36/00:04:30, 0.686s/it]: train_loss_raw=0.9289, running_loss=0.9556, LR=0.000100
[2025-08-26 03:52:16,598][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030464] [Batch 00848/01234] [00:09:41/00:04:24, 0.686s/it]: train_loss_raw=0.9232, running_loss=0.9542, LR=0.000100
[2025-08-26 03:52:21,767][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030472] [Batch 00856/01234] [00:09:46/00:04:19, 0.686s/it]: train_loss_raw=0.9742, running_loss=0.9552, LR=0.000100
[2025-08-26 03:52:27,165][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030480] [Batch 00864/01234] [00:09:52/00:04:13, 0.685s/it]: train_loss_raw=0.9484, running_loss=0.9559, LR=0.000100
[2025-08-26 03:52:32,821][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030488] [Batch 00872/01234] [00:09:57/00:04:08, 0.686s/it]: train_loss_raw=0.9967, running_loss=0.9572, LR=0.000100
[2025-08-26 03:52:37,968][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030496] [Batch 00880/01234] [00:10:03/00:04:02, 0.685s/it]: train_loss_raw=0.9641, running_loss=0.9566, LR=0.000100
[2025-08-26 03:52:43,084][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030504] [Batch 00888/01234] [00:10:08/00:03:56, 0.685s/it]: train_loss_raw=0.9881, running_loss=0.9553, LR=0.000100
[2025-08-26 03:52:48,360][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030512] [Batch 00896/01234] [00:10:13/00:03:51, 0.685s/it]: train_loss_raw=0.9715, running_loss=0.9557, LR=0.000100
[2025-08-26 03:52:53,409][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030520] [Batch 00904/01234] [00:10:18/00:03:45, 0.684s/it]: train_loss_raw=0.9304, running_loss=0.9581, LR=0.000100
[2025-08-26 03:52:58,545][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030528] [Batch 00912/01234] [00:10:23/00:03:40, 0.684s/it]: train_loss_raw=1.0220, running_loss=0.9580, LR=0.000100
[2025-08-26 03:53:04,304][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030536] [Batch 00920/01234] [00:10:29/00:03:34, 0.684s/it]: train_loss_raw=1.0018, running_loss=0.9589, LR=0.000100
[2025-08-26 03:53:09,644][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030544] [Batch 00928/01234] [00:10:34/00:03:29, 0.684s/it]: train_loss_raw=0.9578, running_loss=0.9576, LR=0.000100
[2025-08-26 03:53:14,927][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030552] [Batch 00936/01234] [00:10:40/00:03:23, 0.684s/it]: train_loss_raw=0.9760, running_loss=0.9565, LR=0.000100
[2025-08-26 03:53:20,478][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030560] [Batch 00944/01234] [00:10:45/00:03:18, 0.684s/it]: train_loss_raw=0.9480, running_loss=0.9552, LR=0.000100
[2025-08-26 03:53:25,556][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030568] [Batch 00952/01234] [00:10:50/00:03:12, 0.683s/it]: train_loss_raw=0.9204, running_loss=0.9604, LR=0.000100
[2025-08-26 03:53:30,622][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030576] [Batch 00960/01234] [00:10:55/00:03:07, 0.683s/it]: train_loss_raw=0.9327, running_loss=0.9606, LR=0.000100
[2025-08-26 03:53:35,673][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030584] [Batch 00968/01234] [00:11:00/00:03:01, 0.683s/it]: train_loss_raw=1.0649, running_loss=0.9611, LR=0.000100
[2025-08-26 03:53:41,109][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030592] [Batch 00976/01234] [00:11:06/00:02:56, 0.683s/it]: train_loss_raw=0.9939, running_loss=0.9599, LR=0.000100
[2025-08-26 03:53:46,315][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030600] [Batch 00984/01234] [00:11:11/00:02:50, 0.682s/it]: train_loss_raw=0.9339, running_loss=0.9580, LR=0.000100
[2025-08-26 03:53:51,582][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030608] [Batch 00992/01234] [00:11:16/00:02:45, 0.682s/it]: train_loss_raw=1.0065, running_loss=0.9602, LR=0.000100
[2025-08-26 03:53:57,293][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030616] [Batch 01000/01234] [00:11:22/00:02:39, 0.682s/it]: train_loss_raw=0.9811, running_loss=0.9589, LR=0.000100
[2025-08-26 03:54:03,038][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030624] [Batch 01008/01234] [00:11:28/00:02:34, 0.683s/it]: train_loss_raw=1.0627, running_loss=0.9602, LR=0.000100
[2025-08-26 03:54:08,754][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030632] [Batch 01016/01234] [00:11:33/00:02:28, 0.683s/it]: train_loss_raw=0.9601, running_loss=0.9619, LR=0.000100
[2025-08-26 03:54:14,483][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030640] [Batch 01024/01234] [00:11:39/00:02:23, 0.683s/it]: train_loss_raw=0.9501, running_loss=0.9604, LR=0.000100
[2025-08-26 03:54:19,643][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030648] [Batch 01032/01234] [00:11:44/00:02:17, 0.683s/it]: train_loss_raw=0.9329, running_loss=0.9577, LR=0.000100
[2025-08-26 03:54:24,683][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030656] [Batch 01040/01234] [00:11:49/00:02:12, 0.682s/it]: train_loss_raw=0.9251, running_loss=0.9536, LR=0.000100
[2025-08-26 03:54:29,782][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030664] [Batch 01048/01234] [00:11:54/00:02:06, 0.682s/it]: train_loss_raw=0.9991, running_loss=0.9535, LR=0.000100
[2025-08-26 03:54:35,440][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030672] [Batch 01056/01234] [00:12:00/00:02:01, 0.682s/it]: train_loss_raw=0.9260, running_loss=0.9513, LR=0.000100
[2025-08-26 03:54:41,153][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030680] [Batch 01064/01234] [00:12:06/00:01:56, 0.683s/it]: train_loss_raw=0.9596, running_loss=0.9538, LR=0.000100
[2025-08-26 03:54:46,283][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030688] [Batch 01072/01234] [00:12:11/00:01:50, 0.682s/it]: train_loss_raw=0.9116, running_loss=0.9517, LR=0.000100
[2025-08-26 03:54:51,386][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030696] [Batch 01080/01234] [00:12:16/00:01:45, 0.682s/it]: train_loss_raw=0.9865, running_loss=0.9521, LR=0.000100
[2025-08-26 03:54:56,463][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030704] [Batch 01088/01234] [00:12:21/00:01:39, 0.682s/it]: train_loss_raw=0.9388, running_loss=0.9517, LR=0.000100
[2025-08-26 03:55:01,630][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030712] [Batch 01096/01234] [00:12:26/00:01:34, 0.681s/it]: train_loss_raw=1.0123, running_loss=0.9509, LR=0.000100
[2025-08-26 03:55:07,445][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030720] [Batch 01104/01234] [00:12:32/00:01:28, 0.682s/it]: train_loss_raw=0.9817, running_loss=0.9520, LR=0.000100
[2025-08-26 03:55:13,194][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030728] [Batch 01112/01234] [00:12:38/00:01:23, 0.682s/it]: train_loss_raw=0.8965, running_loss=0.9525, LR=0.000100
[2025-08-26 03:55:18,304][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030736] [Batch 01120/01234] [00:12:43/00:01:17, 0.682s/it]: train_loss_raw=1.0278, running_loss=0.9536, LR=0.000100
[2025-08-26 03:55:23,981][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030744] [Batch 01128/01234] [00:12:49/00:01:12, 0.682s/it]: train_loss_raw=0.9758, running_loss=0.9567, LR=0.000100
[2025-08-26 03:55:29,723][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030752] [Batch 01136/01234] [00:12:54/00:01:06, 0.682s/it]: train_loss_raw=1.0510, running_loss=0.9582, LR=0.000100
[2025-08-26 03:55:34,980][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030760] [Batch 01144/01234] [00:13:00/00:01:01, 0.682s/it]: train_loss_raw=0.9377, running_loss=0.9583, LR=0.000100
[2025-08-26 03:55:40,286][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030768] [Batch 01152/01234] [00:13:05/00:00:55, 0.682s/it]: train_loss_raw=0.8446, running_loss=0.9542, LR=0.000100
[2025-08-26 03:55:46,040][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030776] [Batch 01160/01234] [00:13:11/00:00:50, 0.682s/it]: train_loss_raw=0.9421, running_loss=0.9539, LR=0.000100
[2025-08-26 03:55:52,012][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030784] [Batch 01168/01234] [00:13:17/00:00:45, 0.682s/it]: train_loss_raw=1.0207, running_loss=0.9565, LR=0.000100
[2025-08-26 03:55:57,901][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030792] [Batch 01176/01234] [00:13:23/00:00:39, 0.683s/it]: train_loss_raw=1.0588, running_loss=0.9604, LR=0.000100
[2025-08-26 03:56:03,719][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030800] [Batch 01184/01234] [00:13:28/00:00:34, 0.683s/it]: train_loss_raw=0.9568, running_loss=0.9613, LR=0.000100
[2025-08-26 03:56:09,254][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030808] [Batch 01192/01234] [00:13:34/00:00:28, 0.683s/it]: train_loss_raw=0.9749, running_loss=0.9614, LR=0.000100
[2025-08-26 03:56:14,685][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030816] [Batch 01200/01234] [00:13:39/00:00:23, 0.683s/it]: train_loss_raw=1.0045, running_loss=0.9626, LR=0.000100
[2025-08-26 03:56:19,790][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030824] [Batch 01208/01234] [00:13:44/00:00:17, 0.683s/it]: train_loss_raw=0.9924, running_loss=0.9632, LR=0.000100
[2025-08-26 03:56:25,442][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030832] [Batch 01216/01234] [00:13:50/00:00:12, 0.683s/it]: train_loss_raw=0.9103, running_loss=0.9630, LR=0.000100
[2025-08-26 03:56:31,038][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030840] [Batch 01224/01234] [00:13:56/00:00:06, 0.683s/it]: train_loss_raw=1.0094, running_loss=0.9658, LR=0.000100
[2025-08-26 03:56:36,886][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 030848] [Batch 01232/01234] [00:14:01/00:00:01, 0.683s/it]: train_loss_raw=0.9393, running_loss=0.9651, LR=0.000100
[2025-08-26 03:56:45,314][__main__][INFO] - [VALIDATION] [Epoch 24/29] Starting validation.
[2025-08-26 03:56:56,257][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 030851] [Batch 00007/00026] [00:00:10/00:00:24, 1.368s/it]
[2025-08-26 03:57:06,885][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 030851] [Batch 00015/00026] [00:00:21/00:00:13, 1.348s/it]
[2025-08-26 03:57:18,547][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 030851] [Batch 00023/00026] [00:00:33/00:00:02, 1.385s/it]
[2025-08-26 03:57:21,123][__main__][INFO] - [VALIDATION] [Epoch 24/29] train_loss=0.96299, valid_loss=1.64535
[2025-08-26 03:57:21,124][__main__][INFO] - [VALIDATION] [Epoch 24/29] Metrics:
[2025-08-26 03:57:21,124][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_er      0.589
[2025-08-26 03:57:21,124][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_prec    0.065
[2025-08-26 03:57:21,124][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_recall  0.065
[2025-08-26 03:57:21,124][__main__][INFO] - [VALIDATION] [Epoch 24/29] - pep_recall 0.022
[2025-08-26 03:57:21,127][__main__][INFO] - [TRAIN] [Epoch 24/29] Epoch complete, total time 06:06:30, remaining time 01:13:18, 00:14:39 per epoch
[2025-08-26 03:57:25,493][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030856] [Batch 00006/01234] [00:00:04/00:14:00, 0.684s/it]: train_loss_raw=0.8823, running_loss=0.7961, LR=0.000100
[2025-08-26 03:57:31,676][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030864] [Batch 00014/01234] [00:00:10/00:14:56, 0.735s/it]: train_loss_raw=0.8226, running_loss=0.7989, LR=0.000100
[2025-08-26 03:57:37,542][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030872] [Batch 00022/01234] [00:00:16/00:14:49, 0.734s/it]: train_loss_raw=0.7547, running_loss=0.8034, LR=0.000100
[2025-08-26 03:57:43,378][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030880] [Batch 00030/01234] [00:00:21/00:14:42, 0.733s/it]: train_loss_raw=0.8150, running_loss=0.8066, LR=0.000100
[2025-08-26 03:57:49,444][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030888] [Batch 00038/01234] [00:00:28/00:14:43, 0.738s/it]: train_loss_raw=0.8848, running_loss=0.8104, LR=0.000100
[2025-08-26 03:57:55,730][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030896] [Batch 00046/01234] [00:00:34/00:14:46, 0.747s/it]: train_loss_raw=0.9222, running_loss=0.8146, LR=0.000100
[2025-08-26 03:58:01,890][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030904] [Batch 00054/01234] [00:00:40/00:14:45, 0.750s/it]: train_loss_raw=0.9261, running_loss=0.8203, LR=0.000100
[2025-08-26 03:58:07,883][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030912] [Batch 00062/01234] [00:00:46/00:14:38, 0.750s/it]: train_loss_raw=0.9184, running_loss=0.8231, LR=0.000100
[2025-08-26 03:58:13,882][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030920] [Batch 00070/01234] [00:00:52/00:14:32, 0.750s/it]: train_loss_raw=0.8915, running_loss=0.8274, LR=0.000100
[2025-08-26 03:58:19,973][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030928] [Batch 00078/01234] [00:00:58/00:14:28, 0.751s/it]: train_loss_raw=0.7536, running_loss=0.8297, LR=0.000100
[2025-08-26 03:58:25,733][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030936] [Batch 00086/01234] [00:01:04/00:14:18, 0.748s/it]: train_loss_raw=0.8873, running_loss=0.8313, LR=0.000100
[2025-08-26 03:58:31,756][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030944] [Batch 00094/01234] [00:01:10/00:14:13, 0.749s/it]: train_loss_raw=0.8818, running_loss=0.8342, LR=0.000100
[2025-08-26 03:58:37,557][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030952] [Batch 00102/01234] [00:01:16/00:14:05, 0.747s/it]: train_loss_raw=0.8393, running_loss=0.8363, LR=0.000100
[2025-08-26 03:58:43,034][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030960] [Batch 00110/01234] [00:01:21/00:13:54, 0.742s/it]: train_loss_raw=0.8669, running_loss=0.8378, LR=0.000100
[2025-08-26 03:58:49,132][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030968] [Batch 00118/01234] [00:01:27/00:13:49, 0.744s/it]: train_loss_raw=0.8559, running_loss=0.8390, LR=0.000100
[2025-08-26 03:58:54,994][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030976] [Batch 00126/01234] [00:01:33/00:13:43, 0.743s/it]: train_loss_raw=0.8419, running_loss=0.8403, LR=0.000100
[2025-08-26 03:59:01,128][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030984] [Batch 00134/01234] [00:01:39/00:13:38, 0.744s/it]: train_loss_raw=0.8805, running_loss=0.8413, LR=0.000100
[2025-08-26 03:59:07,252][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 030992] [Batch 00142/01234] [00:01:45/00:13:34, 0.746s/it]: train_loss_raw=0.8095, running_loss=0.8424, LR=0.000100
[2025-08-26 03:59:13,207][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031000] [Batch 00150/01234] [00:01:51/00:13:28, 0.745s/it]: train_loss_raw=0.9337, running_loss=0.8432, LR=0.000100
[2025-08-26 03:59:19,012][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031008] [Batch 00158/01234] [00:01:57/00:13:21, 0.744s/it]: train_loss_raw=0.8155, running_loss=0.8457, LR=0.000100
[2025-08-26 03:59:24,385][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031016] [Batch 00166/01234] [00:02:02/00:13:11, 0.741s/it]: train_loss_raw=0.8358, running_loss=0.8476, LR=0.000100
[2025-08-26 03:59:29,489][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031024] [Batch 00174/01234] [00:02:08/00:13:00, 0.736s/it]: train_loss_raw=0.8830, running_loss=0.8508, LR=0.000100
[2025-08-26 03:59:35,381][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031032] [Batch 00182/01234] [00:02:13/00:12:54, 0.736s/it]: train_loss_raw=0.9497, running_loss=0.8519, LR=0.000100
[2025-08-26 03:59:41,220][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031040] [Batch 00190/01234] [00:02:19/00:12:48, 0.736s/it]: train_loss_raw=0.8404, running_loss=0.8494, LR=0.000100
[2025-08-26 03:59:47,088][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031048] [Batch 00198/01234] [00:02:25/00:12:42, 0.736s/it]: train_loss_raw=0.8881, running_loss=0.8502, LR=0.000100
[2025-08-26 03:59:52,623][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031056] [Batch 00206/01234] [00:02:31/00:12:34, 0.734s/it]: train_loss_raw=0.9060, running_loss=0.8546, LR=0.000100
[2025-08-26 03:59:57,761][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031064] [Batch 00214/01234] [00:02:36/00:12:25, 0.731s/it]: train_loss_raw=0.8058, running_loss=0.8578, LR=0.000100
[2025-08-26 04:00:03,030][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031072] [Batch 00222/01234] [00:02:41/00:12:16, 0.728s/it]: train_loss_raw=0.9419, running_loss=0.8602, LR=0.000100
[2025-08-26 04:00:08,479][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031080] [Batch 00230/01234] [00:02:47/00:12:09, 0.726s/it]: train_loss_raw=0.8785, running_loss=0.8629, LR=0.000100
[2025-08-26 04:00:13,619][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031088] [Batch 00238/01234] [00:02:52/00:12:00, 0.724s/it]: train_loss_raw=0.9064, running_loss=0.8649, LR=0.000100
[2025-08-26 04:00:19,439][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031096] [Batch 00246/01234] [00:02:58/00:11:55, 0.724s/it]: train_loss_raw=0.8517, running_loss=0.8638, LR=0.000100
[2025-08-26 04:00:24,719][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031104] [Batch 00254/01234] [00:03:03/00:11:47, 0.722s/it]: train_loss_raw=0.8532, running_loss=0.8661, LR=0.000100
[2025-08-26 04:00:30,280][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031112] [Batch 00262/01234] [00:03:08/00:11:40, 0.721s/it]: train_loss_raw=0.9177, running_loss=0.8674, LR=0.000100
[2025-08-26 04:00:35,687][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031120] [Batch 00270/01234] [00:03:14/00:11:33, 0.720s/it]: train_loss_raw=0.7925, running_loss=0.8694, LR=0.000100
[2025-08-26 04:00:41,305][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031128] [Batch 00278/01234] [00:03:19/00:11:27, 0.719s/it]: train_loss_raw=0.9011, running_loss=0.8702, LR=0.000100
[2025-08-26 04:00:46,377][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031136] [Batch 00286/01234] [00:03:24/00:11:19, 0.717s/it]: train_loss_raw=0.8771, running_loss=0.8712, LR=0.000100
[2025-08-26 04:00:52,131][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031144] [Batch 00294/01234] [00:03:30/00:11:13, 0.717s/it]: train_loss_raw=0.9144, running_loss=0.8734, LR=0.000100
[2025-08-26 04:00:57,873][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031152] [Batch 00302/01234] [00:03:36/00:11:08, 0.717s/it]: train_loss_raw=0.9747, running_loss=0.8763, LR=0.000100
[2025-08-26 04:01:03,246][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031160] [Batch 00310/01234] [00:03:41/00:11:01, 0.716s/it]: train_loss_raw=0.9299, running_loss=0.8778, LR=0.000100
[2025-08-26 04:01:08,744][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031168] [Batch 00318/01234] [00:03:47/00:10:54, 0.715s/it]: train_loss_raw=0.8909, running_loss=0.8783, LR=0.000100
[2025-08-26 04:01:14,005][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031176] [Batch 00326/01234] [00:03:52/00:10:47, 0.714s/it]: train_loss_raw=0.9264, running_loss=0.8774, LR=0.000100
[2025-08-26 04:01:19,473][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031184] [Batch 00334/01234] [00:03:58/00:10:41, 0.713s/it]: train_loss_raw=0.8638, running_loss=0.8800, LR=0.000100
[2025-08-26 04:01:25,390][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031192] [Batch 00342/01234] [00:04:04/00:10:36, 0.713s/it]: train_loss_raw=0.8299, running_loss=0.8794, LR=0.000100
[2025-08-26 04:01:31,574][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031200] [Batch 00350/01234] [00:04:10/00:10:31, 0.715s/it]: train_loss_raw=0.8018, running_loss=0.8802, LR=0.000100
[2025-08-26 04:01:37,585][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031208] [Batch 00358/01234] [00:04:16/00:10:26, 0.716s/it]: train_loss_raw=0.8583, running_loss=0.8803, LR=0.000100
[2025-08-26 04:01:43,229][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031216] [Batch 00366/01234] [00:04:21/00:10:20, 0.715s/it]: train_loss_raw=0.9373, running_loss=0.8823, LR=0.000100
[2025-08-26 04:01:48,466][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031224] [Batch 00374/01234] [00:04:27/00:10:14, 0.714s/it]: train_loss_raw=0.9052, running_loss=0.8819, LR=0.000100
[2025-08-26 04:01:54,423][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031232] [Batch 00382/01234] [00:04:33/00:10:08, 0.715s/it]: train_loss_raw=0.8750, running_loss=0.8832, LR=0.000100
[2025-08-26 04:02:00,057][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031240] [Batch 00390/01234] [00:04:38/00:10:03, 0.715s/it]: train_loss_raw=0.8347, running_loss=0.8835, LR=0.000100
[2025-08-26 04:02:05,979][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031248] [Batch 00398/01234] [00:04:44/00:09:57, 0.715s/it]: train_loss_raw=0.8886, running_loss=0.8838, LR=0.000100
[2025-08-26 04:02:11,799][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031256] [Batch 00406/01234] [00:04:50/00:09:52, 0.715s/it]: train_loss_raw=0.8755, running_loss=0.8856, LR=0.000100
[2025-08-26 04:02:17,361][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031264] [Batch 00414/01234] [00:04:55/00:09:46, 0.715s/it]: train_loss_raw=0.9378, running_loss=0.8869, LR=0.000100
[2025-08-26 04:02:22,436][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031272] [Batch 00422/01234] [00:05:01/00:09:39, 0.713s/it]: train_loss_raw=0.9691, running_loss=0.8875, LR=0.000100
[2025-08-26 04:02:27,992][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031280] [Batch 00430/01234] [00:05:06/00:09:33, 0.713s/it]: train_loss_raw=0.9100, running_loss=0.8877, LR=0.000100
[2025-08-26 04:02:33,747][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031288] [Batch 00438/01234] [00:05:12/00:09:27, 0.713s/it]: train_loss_raw=0.9834, running_loss=0.8901, LR=0.000100
[2025-08-26 04:02:39,145][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031296] [Batch 00446/01234] [00:05:17/00:09:21, 0.712s/it]: train_loss_raw=0.9087, running_loss=0.8887, LR=0.000100
[2025-08-26 04:02:44,425][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031304] [Batch 00454/01234] [00:05:23/00:09:14, 0.712s/it]: train_loss_raw=0.8872, running_loss=0.8905, LR=0.000100
[2025-08-26 04:02:49,901][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031312] [Batch 00462/01234] [00:05:28/00:09:08, 0.711s/it]: train_loss_raw=0.9139, running_loss=0.8929, LR=0.000100
[2025-08-26 04:02:55,221][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031320] [Batch 00470/01234] [00:05:33/00:09:02, 0.710s/it]: train_loss_raw=0.8514, running_loss=0.8932, LR=0.000100
[2025-08-26 04:03:01,011][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031328] [Batch 00478/01234] [00:05:39/00:08:57, 0.711s/it]: train_loss_raw=0.8880, running_loss=0.8934, LR=0.000100
[2025-08-26 04:03:06,737][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031336] [Batch 00486/01234] [00:05:45/00:08:51, 0.711s/it]: train_loss_raw=0.8481, running_loss=0.8913, LR=0.000100
[2025-08-26 04:03:12,316][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031344] [Batch 00494/01234] [00:05:50/00:08:45, 0.710s/it]: train_loss_raw=0.8934, running_loss=0.8923, LR=0.000100
[2025-08-26 04:03:18,242][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031352] [Batch 00502/01234] [00:05:56/00:08:40, 0.711s/it]: train_loss_raw=0.9103, running_loss=0.8913, LR=0.000100
[2025-08-26 04:03:24,106][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031360] [Batch 00510/01234] [00:06:02/00:08:34, 0.711s/it]: train_loss_raw=0.9448, running_loss=0.8917, LR=0.000100
[2025-08-26 04:03:29,720][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031368] [Batch 00518/01234] [00:06:08/00:08:29, 0.711s/it]: train_loss_raw=0.8102, running_loss=0.8915, LR=0.000100
[2025-08-26 04:03:35,060][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031376] [Batch 00526/01234] [00:06:13/00:08:22, 0.710s/it]: train_loss_raw=0.9401, running_loss=0.8940, LR=0.000100
[2025-08-26 04:03:40,651][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031384] [Batch 00534/01234] [00:06:19/00:08:17, 0.710s/it]: train_loss_raw=0.9300, running_loss=0.8956, LR=0.000100
[2025-08-26 04:03:46,497][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031392] [Batch 00542/01234] [00:06:25/00:08:11, 0.711s/it]: train_loss_raw=0.9024, running_loss=0.8962, LR=0.000100
[2025-08-26 04:03:51,954][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031400] [Batch 00550/01234] [00:06:30/00:08:05, 0.710s/it]: train_loss_raw=0.8892, running_loss=0.8973, LR=0.000100
[2025-08-26 04:03:57,646][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031408] [Batch 00558/01234] [00:06:36/00:08:00, 0.710s/it]: train_loss_raw=0.8353, running_loss=0.8989, LR=0.000100
[2025-08-26 04:04:02,713][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031416] [Batch 00566/01234] [00:06:41/00:07:53, 0.709s/it]: train_loss_raw=0.9803, running_loss=0.8985, LR=0.000100
[2025-08-26 04:04:07,766][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031424] [Batch 00574/01234] [00:06:46/00:07:47, 0.708s/it]: train_loss_raw=0.8754, running_loss=0.8989, LR=0.000100
[2025-08-26 04:04:12,856][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031432] [Batch 00582/01234] [00:06:51/00:07:40, 0.707s/it]: train_loss_raw=0.9746, running_loss=0.8991, LR=0.000100
[2025-08-26 04:04:18,576][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031440] [Batch 00590/01234] [00:06:57/00:07:35, 0.707s/it]: train_loss_raw=0.9564, running_loss=0.9004, LR=0.000100
[2025-08-26 04:04:23,995][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031448] [Batch 00598/01234] [00:07:02/00:07:29, 0.707s/it]: train_loss_raw=0.9307, running_loss=0.9023, LR=0.000100
[2025-08-26 04:04:29,344][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031456] [Batch 00606/01234] [00:07:07/00:07:23, 0.706s/it]: train_loss_raw=0.8908, running_loss=0.9030, LR=0.000100
[2025-08-26 04:04:34,578][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031464] [Batch 00614/01234] [00:07:13/00:07:17, 0.706s/it]: train_loss_raw=0.9361, running_loss=0.9049, LR=0.000100
[2025-08-26 04:04:39,887][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031472] [Batch 00622/01234] [00:07:18/00:07:11, 0.705s/it]: train_loss_raw=0.8653, running_loss=0.9024, LR=0.000100
[2025-08-26 04:04:45,307][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031480] [Batch 00630/01234] [00:07:23/00:07:05, 0.705s/it]: train_loss_raw=1.0121, running_loss=0.9060, LR=0.000100
[2025-08-26 04:04:50,482][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031488] [Batch 00638/01234] [00:07:29/00:06:59, 0.704s/it]: train_loss_raw=0.8838, running_loss=0.9064, LR=0.000100
[2025-08-26 04:04:55,586][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031496] [Batch 00646/01234] [00:07:34/00:06:53, 0.703s/it]: train_loss_raw=0.9525, running_loss=0.9091, LR=0.000100
[2025-08-26 04:05:00,786][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031504] [Batch 00654/01234] [00:07:39/00:06:47, 0.702s/it]: train_loss_raw=0.8958, running_loss=0.9105, LR=0.000100
[2025-08-26 04:05:06,139][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031512] [Batch 00662/01234] [00:07:44/00:06:41, 0.702s/it]: train_loss_raw=0.8721, running_loss=0.9085, LR=0.000100
[2025-08-26 04:05:11,200][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031520] [Batch 00670/01234] [00:07:49/00:06:35, 0.701s/it]: train_loss_raw=0.9126, running_loss=0.9112, LR=0.000100
[2025-08-26 04:05:16,316][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031528] [Batch 00678/01234] [00:07:54/00:06:29, 0.700s/it]: train_loss_raw=0.9994, running_loss=0.9127, LR=0.000100
[2025-08-26 04:05:21,536][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031536] [Batch 00686/01234] [00:08:00/00:06:23, 0.700s/it]: train_loss_raw=0.9394, running_loss=0.9120, LR=0.000100
[2025-08-26 04:05:27,005][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031544] [Batch 00694/01234] [00:08:05/00:06:17, 0.700s/it]: train_loss_raw=0.9546, running_loss=0.9114, LR=0.000100
[2025-08-26 04:05:32,089][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031552] [Batch 00702/01234] [00:08:10/00:06:11, 0.699s/it]: train_loss_raw=0.8925, running_loss=0.9124, LR=0.000100
[2025-08-26 04:05:37,772][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031560] [Batch 00710/01234] [00:08:16/00:06:06, 0.699s/it]: train_loss_raw=0.8162, running_loss=0.9116, LR=0.000100
[2025-08-26 04:05:43,004][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031568] [Batch 00718/01234] [00:08:21/00:06:00, 0.699s/it]: train_loss_raw=0.8100, running_loss=0.9120, LR=0.000100
[2025-08-26 04:05:48,166][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031576] [Batch 00726/01234] [00:08:26/00:05:54, 0.698s/it]: train_loss_raw=0.8548, running_loss=0.9120, LR=0.000100
[2025-08-26 04:05:53,302][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031584] [Batch 00734/01234] [00:08:31/00:05:48, 0.697s/it]: train_loss_raw=0.9664, running_loss=0.9132, LR=0.000100
[2025-08-26 04:05:58,472][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031592] [Batch 00742/01234] [00:08:37/00:05:42, 0.697s/it]: train_loss_raw=0.8085, running_loss=0.9110, LR=0.000100
[2025-08-26 04:06:03,796][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031600] [Batch 00750/01234] [00:08:42/00:05:37, 0.697s/it]: train_loss_raw=0.8750, running_loss=0.9115, LR=0.000100
[2025-08-26 04:06:09,220][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031608] [Batch 00758/01234] [00:08:47/00:05:31, 0.696s/it]: train_loss_raw=0.8468, running_loss=0.9104, LR=0.000100
[2025-08-26 04:06:15,003][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031616] [Batch 00766/01234] [00:08:53/00:05:26, 0.697s/it]: train_loss_raw=0.9272, running_loss=0.9108, LR=0.000100
[2025-08-26 04:06:20,519][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031624] [Batch 00774/01234] [00:08:59/00:05:20, 0.697s/it]: train_loss_raw=0.9246, running_loss=0.9126, LR=0.000100
[2025-08-26 04:06:25,607][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031632] [Batch 00782/01234] [00:09:04/00:05:14, 0.696s/it]: train_loss_raw=0.9706, running_loss=0.9138, LR=0.000100
[2025-08-26 04:06:31,178][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031640] [Batch 00790/01234] [00:09:09/00:05:08, 0.696s/it]: train_loss_raw=0.8747, running_loss=0.9133, LR=0.000100
[2025-08-26 04:06:36,423][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031648] [Batch 00798/01234] [00:09:15/00:05:03, 0.696s/it]: train_loss_raw=0.8363, running_loss=0.9111, LR=0.000100
[2025-08-26 04:06:42,101][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031656] [Batch 00806/01234] [00:09:20/00:04:57, 0.696s/it]: train_loss_raw=0.9088, running_loss=0.9111, LR=0.000100
[2025-08-26 04:06:47,950][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031664] [Batch 00814/01234] [00:09:26/00:04:52, 0.696s/it]: train_loss_raw=0.7873, running_loss=0.9114, LR=0.000100
[2025-08-26 04:06:53,634][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031672] [Batch 00822/01234] [00:09:32/00:04:46, 0.696s/it]: train_loss_raw=0.9349, running_loss=0.9133, LR=0.000100
[2025-08-26 04:06:58,978][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031680] [Batch 00830/01234] [00:09:37/00:04:41, 0.696s/it]: train_loss_raw=0.9192, running_loss=0.9147, LR=0.000100
[2025-08-26 04:07:04,608][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031688] [Batch 00838/01234] [00:09:43/00:04:35, 0.696s/it]: train_loss_raw=0.8843, running_loss=0.9146, LR=0.000100
[2025-08-26 04:07:10,350][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031696] [Batch 00846/01234] [00:09:48/00:04:30, 0.696s/it]: train_loss_raw=0.9423, running_loss=0.9137, LR=0.000100
[2025-08-26 04:07:16,019][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031704] [Batch 00854/01234] [00:09:54/00:04:24, 0.696s/it]: train_loss_raw=0.8566, running_loss=0.9141, LR=0.000100
[2025-08-26 04:07:21,551][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031712] [Batch 00862/01234] [00:10:00/00:04:19, 0.696s/it]: train_loss_raw=0.9013, running_loss=0.9147, LR=0.000100
[2025-08-26 04:07:26,793][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031720] [Batch 00870/01234] [00:10:05/00:04:13, 0.696s/it]: train_loss_raw=0.8913, running_loss=0.9156, LR=0.000100
[2025-08-26 04:07:31,898][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031728] [Batch 00878/01234] [00:10:10/00:04:07, 0.695s/it]: train_loss_raw=0.8673, running_loss=0.9160, LR=0.000100
[2025-08-26 04:07:37,491][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031736] [Batch 00886/01234] [00:10:16/00:04:01, 0.695s/it]: train_loss_raw=1.0120, running_loss=0.9169, LR=0.000100
[2025-08-26 04:07:42,727][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031744] [Batch 00894/01234] [00:10:21/00:03:56, 0.695s/it]: train_loss_raw=0.9490, running_loss=0.9172, LR=0.000100
[2025-08-26 04:07:48,125][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031752] [Batch 00902/01234] [00:10:26/00:03:50, 0.695s/it]: train_loss_raw=0.9201, running_loss=0.9205, LR=0.000100
[2025-08-26 04:07:53,205][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031760] [Batch 00910/01234] [00:10:31/00:03:44, 0.694s/it]: train_loss_raw=0.9396, running_loss=0.9199, LR=0.000100
[2025-08-26 04:07:58,391][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031768] [Batch 00918/01234] [00:10:37/00:03:39, 0.694s/it]: train_loss_raw=0.9589, running_loss=0.9216, LR=0.000100
[2025-08-26 04:08:03,704][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031776] [Batch 00926/01234] [00:10:42/00:03:33, 0.694s/it]: train_loss_raw=0.9303, running_loss=0.9217, LR=0.000100
[2025-08-26 04:08:09,534][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031784] [Batch 00934/01234] [00:10:48/00:03:28, 0.694s/it]: train_loss_raw=0.9043, running_loss=0.9211, LR=0.000100
[2025-08-26 04:08:14,659][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031792] [Batch 00942/01234] [00:10:53/00:03:22, 0.693s/it]: train_loss_raw=0.9293, running_loss=0.9215, LR=0.000100
[2025-08-26 04:08:20,307][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031800] [Batch 00950/01234] [00:10:58/00:03:16, 0.694s/it]: train_loss_raw=0.9478, running_loss=0.9230, LR=0.000100
[2025-08-26 04:08:25,970][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031808] [Batch 00958/01234] [00:11:04/00:03:11, 0.694s/it]: train_loss_raw=0.9245, running_loss=0.9227, LR=0.000100
[2025-08-26 04:08:31,391][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031816] [Batch 00966/01234] [00:11:10/00:03:05, 0.694s/it]: train_loss_raw=0.9445, running_loss=0.9244, LR=0.000100
[2025-08-26 04:08:36,526][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031824] [Batch 00974/01234] [00:11:15/00:03:00, 0.693s/it]: train_loss_raw=0.8562, running_loss=0.9223, LR=0.000100
[2025-08-26 04:08:41,869][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031832] [Batch 00982/01234] [00:11:20/00:02:54, 0.693s/it]: train_loss_raw=0.8064, running_loss=0.9211, LR=0.000100
[2025-08-26 04:08:47,331][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031840] [Batch 00990/01234] [00:11:25/00:02:49, 0.693s/it]: train_loss_raw=0.9490, running_loss=0.9240, LR=0.000100
[2025-08-26 04:08:52,459][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031848] [Batch 00998/01234] [00:11:31/00:02:43, 0.692s/it]: train_loss_raw=0.9086, running_loss=0.9236, LR=0.000100
[2025-08-26 04:08:57,987][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031856] [Batch 01006/01234] [00:11:36/00:02:37, 0.692s/it]: train_loss_raw=0.9834, running_loss=0.9248, LR=0.000100
[2025-08-26 04:09:03,556][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031864] [Batch 01014/01234] [00:11:42/00:02:32, 0.692s/it]: train_loss_raw=0.9170, running_loss=0.9232, LR=0.000100
[2025-08-26 04:09:09,314][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031872] [Batch 01022/01234] [00:11:47/00:02:26, 0.693s/it]: train_loss_raw=0.8996, running_loss=0.9237, LR=0.000100
[2025-08-26 04:09:15,218][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031880] [Batch 01030/01234] [00:11:53/00:02:21, 0.693s/it]: train_loss_raw=0.9921, running_loss=0.9251, LR=0.000100
[2025-08-26 04:09:20,432][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031888] [Batch 01038/01234] [00:11:59/00:02:15, 0.693s/it]: train_loss_raw=0.9464, running_loss=0.9260, LR=0.000100
[2025-08-26 04:09:26,277][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031896] [Batch 01046/01234] [00:12:04/00:02:10, 0.693s/it]: train_loss_raw=0.8253, running_loss=0.9252, LR=0.000100
[2025-08-26 04:09:31,685][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031904] [Batch 01054/01234] [00:12:10/00:02:04, 0.693s/it]: train_loss_raw=0.8709, running_loss=0.9237, LR=0.000100
[2025-08-26 04:09:37,042][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031912] [Batch 01062/01234] [00:12:15/00:01:59, 0.693s/it]: train_loss_raw=0.9515, running_loss=0.9247, LR=0.000100
[2025-08-26 04:09:42,133][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031920] [Batch 01070/01234] [00:12:20/00:01:53, 0.692s/it]: train_loss_raw=0.9466, running_loss=0.9229, LR=0.000100
[2025-08-26 04:09:47,472][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031928] [Batch 01078/01234] [00:12:26/00:01:47, 0.692s/it]: train_loss_raw=0.9560, running_loss=0.9241, LR=0.000100
[2025-08-26 04:09:52,579][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031936] [Batch 01086/01234] [00:12:31/00:01:42, 0.692s/it]: train_loss_raw=0.9287, running_loss=0.9238, LR=0.000100
[2025-08-26 04:09:57,781][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031944] [Batch 01094/01234] [00:12:36/00:01:36, 0.691s/it]: train_loss_raw=0.8929, running_loss=0.9243, LR=0.000100
[2025-08-26 04:10:02,914][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031952] [Batch 01102/01234] [00:12:41/00:01:31, 0.691s/it]: train_loss_raw=0.9751, running_loss=0.9249, LR=0.000100
[2025-08-26 04:10:08,051][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031960] [Batch 01110/01234] [00:12:46/00:01:25, 0.691s/it]: train_loss_raw=0.9556, running_loss=0.9228, LR=0.000100
[2025-08-26 04:10:13,767][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031968] [Batch 01118/01234] [00:12:52/00:01:20, 0.691s/it]: train_loss_raw=0.8561, running_loss=0.9202, LR=0.000100
[2025-08-26 04:10:19,287][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031976] [Batch 01126/01234] [00:12:57/00:01:14, 0.691s/it]: train_loss_raw=0.9956, running_loss=0.9227, LR=0.000100
[2025-08-26 04:10:24,937][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031984] [Batch 01134/01234] [00:13:03/00:01:09, 0.691s/it]: train_loss_raw=0.9215, running_loss=0.9209, LR=0.000100
[2025-08-26 04:10:30,022][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 031992] [Batch 01142/01234] [00:13:08/00:01:03, 0.691s/it]: train_loss_raw=0.7867, running_loss=0.9182, LR=0.000100
[2025-08-26 04:10:35,522][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032000] [Batch 01150/01234] [00:13:14/00:00:58, 0.691s/it]: train_loss_raw=0.9307, running_loss=0.9207, LR=0.000100
[2025-08-26 04:10:44,569][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032008] [Batch 01158/01234] [00:13:23/00:00:52, 0.694s/it]: train_loss_raw=0.8912, running_loss=0.9216, LR=0.000100
[2025-08-26 04:10:50,273][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032016] [Batch 01166/01234] [00:13:28/00:00:47, 0.694s/it]: train_loss_raw=0.9546, running_loss=0.9233, LR=0.000100
[2025-08-26 04:10:55,884][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032024] [Batch 01174/01234] [00:13:34/00:00:41, 0.694s/it]: train_loss_raw=0.9459, running_loss=0.9239, LR=0.000100
[2025-08-26 04:11:01,229][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032032] [Batch 01182/01234] [00:13:39/00:00:36, 0.694s/it]: train_loss_raw=0.9303, running_loss=0.9261, LR=0.000100
[2025-08-26 04:11:06,454][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032040] [Batch 01190/01234] [00:13:45/00:00:30, 0.693s/it]: train_loss_raw=0.9254, running_loss=0.9255, LR=0.000100
[2025-08-26 04:11:12,242][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032048] [Batch 01198/01234] [00:13:50/00:00:24, 0.694s/it]: train_loss_raw=0.9266, running_loss=0.9252, LR=0.000100
[2025-08-26 04:11:17,764][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032056] [Batch 01206/01234] [00:13:56/00:00:19, 0.694s/it]: train_loss_raw=0.9570, running_loss=0.9249, LR=0.000100
[2025-08-26 04:11:23,429][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032064] [Batch 01214/01234] [00:14:02/00:00:13, 0.694s/it]: train_loss_raw=0.8890, running_loss=0.9235, LR=0.000100
[2025-08-26 04:11:28,504][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032072] [Batch 01222/01234] [00:14:07/00:00:08, 0.693s/it]: train_loss_raw=0.9101, running_loss=0.9267, LR=0.000100
[2025-08-26 04:11:33,924][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 032080] [Batch 01230/01234] [00:14:12/00:00:02, 0.693s/it]: train_loss_raw=0.9543, running_loss=0.9270, LR=0.000100
[2025-08-26 04:11:42,755][__main__][INFO] - [VALIDATION] [Epoch 25/29] Starting validation.
[2025-08-26 04:11:53,484][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 032085] [Batch 00007/00026] [00:00:10/00:00:24, 1.341s/it]
[2025-08-26 04:12:04,647][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 032085] [Batch 00015/00026] [00:00:21/00:00:13, 1.368s/it]
[2025-08-26 04:12:15,226][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 032085] [Batch 00023/00026] [00:00:32/00:00:02, 1.353s/it]
[2025-08-26 04:12:17,623][__main__][INFO] - [VALIDATION] [Epoch 25/29] train_loss=0.92502, valid_loss=1.65517
[2025-08-26 04:12:17,623][__main__][INFO] - [VALIDATION] [Epoch 25/29] Metrics:
[2025-08-26 04:12:17,623][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_er      0.608
[2025-08-26 04:12:17,623][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_prec    0.059
[2025-08-26 04:12:17,623][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_recall  0.060
[2025-08-26 04:12:17,623][__main__][INFO] - [VALIDATION] [Epoch 25/29] - pep_recall 0.019
[2025-08-26 04:12:17,625][__main__][INFO] - [TRAIN] [Epoch 25/29] Epoch complete, total time 06:21:26, remaining time 00:58:41, 00:14:40 per epoch
[2025-08-26 04:12:20,059][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032088] [Batch 00004/01234] [00:00:02/00:11:32, 0.563s/it]: train_loss_raw=0.8541, running_loss=0.8655, LR=0.000100
[2025-08-26 04:12:25,893][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032096] [Batch 00012/01234] [00:00:08/00:13:43, 0.674s/it]: train_loss_raw=0.7306, running_loss=0.8626, LR=0.000100
[2025-08-26 04:12:31,741][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032104] [Batch 00020/01234] [00:00:13/00:14:05, 0.697s/it]: train_loss_raw=0.7918, running_loss=0.8581, LR=0.000100
[2025-08-26 04:12:37,178][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032112] [Batch 00028/01234] [00:00:19/00:13:54, 0.692s/it]: train_loss_raw=0.8560, running_loss=0.8551, LR=0.000100
[2025-08-26 04:12:42,208][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032120] [Batch 00036/01234] [00:00:24/00:13:32, 0.678s/it]: train_loss_raw=0.8404, running_loss=0.8526, LR=0.000100
[2025-08-26 04:12:47,267][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032128] [Batch 00044/01234] [00:00:29/00:13:16, 0.670s/it]: train_loss_raw=0.8176, running_loss=0.8498, LR=0.000100
[2025-08-26 04:12:52,330][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032136] [Batch 00052/01234] [00:00:34/00:13:04, 0.664s/it]: train_loss_raw=0.8144, running_loss=0.8470, LR=0.000100
[2025-08-26 04:12:57,672][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032144] [Batch 00060/01234] [00:00:39/00:13:00, 0.664s/it]: train_loss_raw=0.7787, running_loss=0.8450, LR=0.000100
[2025-08-26 04:13:03,014][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032152] [Batch 00068/01234] [00:00:45/00:12:55, 0.665s/it]: train_loss_raw=0.7624, running_loss=0.8433, LR=0.000100
[2025-08-26 04:13:08,593][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032160] [Batch 00076/01234] [00:00:50/00:12:53, 0.668s/it]: train_loss_raw=0.8029, running_loss=0.8425, LR=0.000100
[2025-08-26 04:13:13,829][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032168] [Batch 00084/01234] [00:00:56/00:12:46, 0.667s/it]: train_loss_raw=0.8025, running_loss=0.8402, LR=0.000100
[2025-08-26 04:13:19,040][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032176] [Batch 00092/01234] [00:01:01/00:12:40, 0.666s/it]: train_loss_raw=0.9119, running_loss=0.8377, LR=0.000100
[2025-08-26 04:13:24,436][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032184] [Batch 00100/01234] [00:01:06/00:12:35, 0.666s/it]: train_loss_raw=0.8109, running_loss=0.8370, LR=0.000100
[2025-08-26 04:13:29,575][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032192] [Batch 00108/01234] [00:01:11/00:12:28, 0.665s/it]: train_loss_raw=0.8164, running_loss=0.8349, LR=0.000100
[2025-08-26 04:13:34,974][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032200] [Batch 00116/01234] [00:01:17/00:12:23, 0.665s/it]: train_loss_raw=0.8194, running_loss=0.8353, LR=0.000100
[2025-08-26 04:13:40,520][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032208] [Batch 00124/01234] [00:01:22/00:12:20, 0.667s/it]: train_loss_raw=0.7576, running_loss=0.8343, LR=0.000100
[2025-08-26 04:13:45,981][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032216] [Batch 00132/01234] [00:01:28/00:12:16, 0.668s/it]: train_loss_raw=0.8813, running_loss=0.8377, LR=0.000100
[2025-08-26 04:13:51,797][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032224] [Batch 00140/01234] [00:01:33/00:12:14, 0.671s/it]: train_loss_raw=0.8696, running_loss=0.8370, LR=0.000100
[2025-08-26 04:13:57,239][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032232] [Batch 00148/01234] [00:01:39/00:12:09, 0.672s/it]: train_loss_raw=0.8891, running_loss=0.8393, LR=0.000100
[2025-08-26 04:14:03,017][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032240] [Batch 00156/01234] [00:01:45/00:12:07, 0.674s/it]: train_loss_raw=0.8277, running_loss=0.8368, LR=0.000100
[2025-08-26 04:14:08,792][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032248] [Batch 00164/01234] [00:01:50/00:12:04, 0.677s/it]: train_loss_raw=0.8551, running_loss=0.8365, LR=0.000100
[2025-08-26 04:14:14,542][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032256] [Batch 00172/01234] [00:01:56/00:12:00, 0.679s/it]: train_loss_raw=0.8294, running_loss=0.8350, LR=0.000100
[2025-08-26 04:14:20,400][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032264] [Batch 00180/01234] [00:02:02/00:11:57, 0.681s/it]: train_loss_raw=0.8512, running_loss=0.8357, LR=0.000100
[2025-08-26 04:14:26,137][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032272] [Batch 00188/01234] [00:02:08/00:11:54, 0.683s/it]: train_loss_raw=0.8864, running_loss=0.8360, LR=0.000100
[2025-08-26 04:14:31,320][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032280] [Batch 00196/01234] [00:02:13/00:11:47, 0.681s/it]: train_loss_raw=0.7922, running_loss=0.8360, LR=0.000100
[2025-08-26 04:14:36,904][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032288] [Batch 00204/01234] [00:02:19/00:11:42, 0.682s/it]: train_loss_raw=0.8542, running_loss=0.8361, LR=0.000100
[2025-08-26 04:14:42,321][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032296] [Batch 00212/01234] [00:02:24/00:11:36, 0.682s/it]: train_loss_raw=0.8468, running_loss=0.8372, LR=0.000100
[2025-08-26 04:14:47,633][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032304] [Batch 00220/01234] [00:02:29/00:11:30, 0.681s/it]: train_loss_raw=0.7824, running_loss=0.8393, LR=0.000100
[2025-08-26 04:14:52,721][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032312] [Batch 00228/01234] [00:02:34/00:11:23, 0.679s/it]: train_loss_raw=0.8170, running_loss=0.8403, LR=0.000100
[2025-08-26 04:14:57,816][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032320] [Batch 00236/01234] [00:02:40/00:11:16, 0.678s/it]: train_loss_raw=0.8545, running_loss=0.8403, LR=0.000100
[2025-08-26 04:15:03,523][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032328] [Batch 00244/01234] [00:02:45/00:11:12, 0.679s/it]: train_loss_raw=0.8508, running_loss=0.8420, LR=0.000100
[2025-08-26 04:15:09,376][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032336] [Batch 00252/01234] [00:02:51/00:11:08, 0.681s/it]: train_loss_raw=0.8162, running_loss=0.8417, LR=0.000100
[2025-08-26 04:15:15,262][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032344] [Batch 00260/01234] [00:02:57/00:11:04, 0.683s/it]: train_loss_raw=0.8408, running_loss=0.8418, LR=0.000100
[2025-08-26 04:15:20,974][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032352] [Batch 00268/01234] [00:03:03/00:11:00, 0.683s/it]: train_loss_raw=0.9142, running_loss=0.8438, LR=0.000100
[2025-08-26 04:15:26,919][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032360] [Batch 00276/01234] [00:03:09/00:10:56, 0.685s/it]: train_loss_raw=0.7197, running_loss=0.8423, LR=0.000100
[2025-08-26 04:15:32,563][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032368] [Batch 00284/01234] [00:03:14/00:10:51, 0.686s/it]: train_loss_raw=0.8660, running_loss=0.8443, LR=0.000100
[2025-08-26 04:15:38,070][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032376] [Batch 00292/01234] [00:03:20/00:10:46, 0.686s/it]: train_loss_raw=0.7918, running_loss=0.8434, LR=0.000100
[2025-08-26 04:15:43,404][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032384] [Batch 00300/01234] [00:03:25/00:10:40, 0.685s/it]: train_loss_raw=0.8630, running_loss=0.8451, LR=0.000100
[2025-08-26 04:15:49,124][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032392] [Batch 00308/01234] [00:03:31/00:10:35, 0.686s/it]: train_loss_raw=0.9200, running_loss=0.8485, LR=0.000100
[2025-08-26 04:15:54,581][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032400] [Batch 00316/01234] [00:03:36/00:10:29, 0.686s/it]: train_loss_raw=0.8550, running_loss=0.8479, LR=0.000100
[2025-08-26 04:15:59,987][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032408] [Batch 00324/01234] [00:03:42/00:10:24, 0.686s/it]: train_loss_raw=0.8925, running_loss=0.8485, LR=0.000100
[2025-08-26 04:16:05,366][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032416] [Batch 00332/01234] [00:03:47/00:10:18, 0.685s/it]: train_loss_raw=0.8104, running_loss=0.8487, LR=0.000100
[2025-08-26 04:16:10,988][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032424] [Batch 00340/01234] [00:03:53/00:10:13, 0.686s/it]: train_loss_raw=0.8369, running_loss=0.8485, LR=0.000100
[2025-08-26 04:16:16,315][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032432] [Batch 00348/01234] [00:03:58/00:10:07, 0.685s/it]: train_loss_raw=0.8796, running_loss=0.8498, LR=0.000100
[2025-08-26 04:16:21,704][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032440] [Batch 00356/01234] [00:04:03/00:10:01, 0.685s/it]: train_loss_raw=0.8631, running_loss=0.8482, LR=0.000100
[2025-08-26 04:16:27,230][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032448] [Batch 00364/01234] [00:04:09/00:09:56, 0.685s/it]: train_loss_raw=0.8263, running_loss=0.8467, LR=0.000100
[2025-08-26 04:16:32,414][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032456] [Batch 00372/01234] [00:04:14/00:09:49, 0.684s/it]: train_loss_raw=0.8236, running_loss=0.8483, LR=0.000100
[2025-08-26 04:16:37,797][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032464] [Batch 00380/01234] [00:04:19/00:09:44, 0.684s/it]: train_loss_raw=0.9078, running_loss=0.8497, LR=0.000100
[2025-08-26 04:16:42,825][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032472] [Batch 00388/01234] [00:04:25/00:09:37, 0.683s/it]: train_loss_raw=0.8936, running_loss=0.8497, LR=0.000100
[2025-08-26 04:16:47,894][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032480] [Batch 00396/01234] [00:04:30/00:09:31, 0.682s/it]: train_loss_raw=0.7433, running_loss=0.8498, LR=0.000100
[2025-08-26 04:16:52,953][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032488] [Batch 00404/01234] [00:04:35/00:09:25, 0.681s/it]: train_loss_raw=0.9494, running_loss=0.8487, LR=0.000100
[2025-08-26 04:16:58,813][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032496] [Batch 00412/01234] [00:04:41/00:09:20, 0.682s/it]: train_loss_raw=0.8250, running_loss=0.8489, LR=0.000100
[2025-08-26 04:17:03,948][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032504] [Batch 00420/01234] [00:04:46/00:09:14, 0.681s/it]: train_loss_raw=0.8710, running_loss=0.8496, LR=0.000100
[2025-08-26 04:17:09,034][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032512] [Batch 00428/01234] [00:04:51/00:09:08, 0.680s/it]: train_loss_raw=0.7576, running_loss=0.8487, LR=0.000100
[2025-08-26 04:17:14,455][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032520] [Batch 00436/01234] [00:04:56/00:09:02, 0.680s/it]: train_loss_raw=0.8762, running_loss=0.8489, LR=0.000100
[2025-08-26 04:17:19,624][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032528] [Batch 00444/01234] [00:05:01/00:08:57, 0.680s/it]: train_loss_raw=0.9296, running_loss=0.8515, LR=0.000100
[2025-08-26 04:17:24,787][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032536] [Batch 00452/01234] [00:05:06/00:08:51, 0.679s/it]: train_loss_raw=0.9070, running_loss=0.8515, LR=0.000100
[2025-08-26 04:17:30,342][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032544] [Batch 00460/01234] [00:05:12/00:08:45, 0.679s/it]: train_loss_raw=0.8442, running_loss=0.8519, LR=0.000100
[2025-08-26 04:17:36,052][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032552] [Batch 00468/01234] [00:05:18/00:08:40, 0.680s/it]: train_loss_raw=0.8198, running_loss=0.8520, LR=0.000100
[2025-08-26 04:17:41,754][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032560] [Batch 00476/01234] [00:05:23/00:08:35, 0.681s/it]: train_loss_raw=0.8899, running_loss=0.8539, LR=0.000100
[2025-08-26 04:17:47,507][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032568] [Batch 00484/01234] [00:05:29/00:08:30, 0.681s/it]: train_loss_raw=0.7513, running_loss=0.8542, LR=0.000100
[2025-08-26 04:17:52,783][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032576] [Batch 00492/01234] [00:05:34/00:08:25, 0.681s/it]: train_loss_raw=0.8797, running_loss=0.8589, LR=0.000100
[2025-08-26 04:17:58,471][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032584] [Batch 00500/01234] [00:05:40/00:08:20, 0.681s/it]: train_loss_raw=0.9058, running_loss=0.8591, LR=0.000100
[2025-08-26 04:18:04,019][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032592] [Batch 00508/01234] [00:05:46/00:08:14, 0.682s/it]: train_loss_raw=0.8326, running_loss=0.8613, LR=0.000100
[2025-08-26 04:18:09,056][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032600] [Batch 00516/01234] [00:05:51/00:08:08, 0.681s/it]: train_loss_raw=0.8576, running_loss=0.8618, LR=0.000100
[2025-08-26 04:18:14,131][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032608] [Batch 00524/01234] [00:05:56/00:08:02, 0.680s/it]: train_loss_raw=0.8408, running_loss=0.8609, LR=0.000100
[2025-08-26 04:18:19,669][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032616] [Batch 00532/01234] [00:06:01/00:07:57, 0.680s/it]: train_loss_raw=0.8794, running_loss=0.8620, LR=0.000100
[2025-08-26 04:18:24,707][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032624] [Batch 00540/01234] [00:06:06/00:07:51, 0.679s/it]: train_loss_raw=0.7814, running_loss=0.8633, LR=0.000100
[2025-08-26 04:18:30,311][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032632] [Batch 00548/01234] [00:06:12/00:07:46, 0.680s/it]: train_loss_raw=0.9382, running_loss=0.8632, LR=0.000100
[2025-08-26 04:18:36,023][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032640] [Batch 00556/01234] [00:06:18/00:07:41, 0.680s/it]: train_loss_raw=0.8224, running_loss=0.8617, LR=0.000100
[2025-08-26 04:18:41,193][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032648] [Batch 00564/01234] [00:06:23/00:07:35, 0.680s/it]: train_loss_raw=0.8939, running_loss=0.8618, LR=0.000100
[2025-08-26 04:18:46,811][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032656] [Batch 00572/01234] [00:06:29/00:07:30, 0.680s/it]: train_loss_raw=0.8886, running_loss=0.8610, LR=0.000100
[2025-08-26 04:18:52,188][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032664] [Batch 00580/01234] [00:06:34/00:07:24, 0.680s/it]: train_loss_raw=0.8513, running_loss=0.8611, LR=0.000100
[2025-08-26 04:18:58,024][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032672] [Batch 00588/01234] [00:06:40/00:07:19, 0.681s/it]: train_loss_raw=0.9013, running_loss=0.8623, LR=0.000100
[2025-08-26 04:19:03,879][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032680] [Batch 00596/01234] [00:06:46/00:07:14, 0.681s/it]: train_loss_raw=0.8578, running_loss=0.8643, LR=0.000100
[2025-08-26 04:19:09,598][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032688] [Batch 00604/01234] [00:06:51/00:07:09, 0.682s/it]: train_loss_raw=0.8699, running_loss=0.8637, LR=0.000100
[2025-08-26 04:19:14,732][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032696] [Batch 00612/01234] [00:06:56/00:07:03, 0.681s/it]: train_loss_raw=0.8395, running_loss=0.8629, LR=0.000100
[2025-08-26 04:19:20,540][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032704] [Batch 00620/01234] [00:07:02/00:06:58, 0.682s/it]: train_loss_raw=0.8641, running_loss=0.8633, LR=0.000100
[2025-08-26 04:19:26,198][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032712] [Batch 00628/01234] [00:07:08/00:06:53, 0.682s/it]: train_loss_raw=0.8105, running_loss=0.8629, LR=0.000100
[2025-08-26 04:19:31,765][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032720] [Batch 00636/01234] [00:07:13/00:06:48, 0.682s/it]: train_loss_raw=0.9036, running_loss=0.8640, LR=0.000100
[2025-08-26 04:19:37,872][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032728] [Batch 00644/01234] [00:07:20/00:06:43, 0.683s/it]: train_loss_raw=0.8302, running_loss=0.8649, LR=0.000100
[2025-08-26 04:19:43,798][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032736] [Batch 00652/01234] [00:07:25/00:06:38, 0.684s/it]: train_loss_raw=0.8760, running_loss=0.8668, LR=0.000100
[2025-08-26 04:19:49,425][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032744] [Batch 00660/01234] [00:07:31/00:06:32, 0.684s/it]: train_loss_raw=0.8507, running_loss=0.8667, LR=0.000100
[2025-08-26 04:19:54,469][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032752] [Batch 00668/01234] [00:07:36/00:06:26, 0.684s/it]: train_loss_raw=0.8433, running_loss=0.8697, LR=0.000100
[2025-08-26 04:19:59,517][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032760] [Batch 00676/01234] [00:07:41/00:06:21, 0.683s/it]: train_loss_raw=0.8589, running_loss=0.8694, LR=0.000100
[2025-08-26 04:20:04,550][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032768] [Batch 00684/01234] [00:07:46/00:06:15, 0.682s/it]: train_loss_raw=0.8656, running_loss=0.8687, LR=0.000100
[2025-08-26 04:20:09,588][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032776] [Batch 00692/01234] [00:07:51/00:06:09, 0.682s/it]: train_loss_raw=0.9654, running_loss=0.8677, LR=0.000100
[2025-08-26 04:20:15,074][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032784] [Batch 00700/01234] [00:07:57/00:06:04, 0.682s/it]: train_loss_raw=0.8331, running_loss=0.8671, LR=0.000100
[2025-08-26 04:20:20,588][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032792] [Batch 00708/01234] [00:08:02/00:05:58, 0.682s/it]: train_loss_raw=0.8324, running_loss=0.8665, LR=0.000100
[2025-08-26 04:20:25,751][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032800] [Batch 00716/01234] [00:08:07/00:05:53, 0.681s/it]: train_loss_raw=0.9342, running_loss=0.8663, LR=0.000100
[2025-08-26 04:20:30,960][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032808] [Batch 00724/01234] [00:08:13/00:05:47, 0.681s/it]: train_loss_raw=0.8212, running_loss=0.8664, LR=0.000100
[2025-08-26 04:20:36,752][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032816] [Batch 00732/01234] [00:08:18/00:05:42, 0.682s/it]: train_loss_raw=0.8845, running_loss=0.8674, LR=0.000100
[2025-08-26 04:20:42,314][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032824] [Batch 00740/01234] [00:08:24/00:05:36, 0.682s/it]: train_loss_raw=0.8375, running_loss=0.8656, LR=0.000100
[2025-08-26 04:20:47,996][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032832] [Batch 00748/01234] [00:08:30/00:05:31, 0.682s/it]: train_loss_raw=0.9083, running_loss=0.8659, LR=0.000100
[2025-08-26 04:20:53,669][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032840] [Batch 00756/01234] [00:08:35/00:05:26, 0.682s/it]: train_loss_raw=0.8987, running_loss=0.8655, LR=0.000100
[2025-08-26 04:20:58,878][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032848] [Batch 00764/01234] [00:08:41/00:05:20, 0.682s/it]: train_loss_raw=0.9335, running_loss=0.8691, LR=0.000100
[2025-08-26 04:21:04,595][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032856] [Batch 00772/01234] [00:08:46/00:05:15, 0.682s/it]: train_loss_raw=0.8165, running_loss=0.8692, LR=0.000100
[2025-08-26 04:21:10,347][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032864] [Batch 00780/01234] [00:08:52/00:05:09, 0.683s/it]: train_loss_raw=0.9037, running_loss=0.8693, LR=0.000100
[2025-08-26 04:21:16,099][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032872] [Batch 00788/01234] [00:08:58/00:05:04, 0.683s/it]: train_loss_raw=0.9112, running_loss=0.8689, LR=0.000100
[2025-08-26 04:21:21,200][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032880] [Batch 00796/01234] [00:09:03/00:04:59, 0.683s/it]: train_loss_raw=0.8455, running_loss=0.8703, LR=0.000100
[2025-08-26 04:21:26,575][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032888] [Batch 00804/01234] [00:09:08/00:04:53, 0.683s/it]: train_loss_raw=0.7578, running_loss=0.8685, LR=0.000100
[2025-08-26 04:21:32,267][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032896] [Batch 00812/01234] [00:09:14/00:04:48, 0.683s/it]: train_loss_raw=0.9627, running_loss=0.8709, LR=0.000100
[2025-08-26 04:21:37,752][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032904] [Batch 00820/01234] [00:09:19/00:04:42, 0.683s/it]: train_loss_raw=0.9020, running_loss=0.8715, LR=0.000100
[2025-08-26 04:21:43,272][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032912] [Batch 00828/01234] [00:09:25/00:04:37, 0.683s/it]: train_loss_raw=0.8301, running_loss=0.8723, LR=0.000100
[2025-08-26 04:21:49,012][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032920] [Batch 00836/01234] [00:09:31/00:04:31, 0.683s/it]: train_loss_raw=0.7036, running_loss=0.8720, LR=0.000100
[2025-08-26 04:21:54,796][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032928] [Batch 00844/01234] [00:09:36/00:04:26, 0.684s/it]: train_loss_raw=0.9727, running_loss=0.8745, LR=0.000100
[2025-08-26 04:22:00,418][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032936] [Batch 00852/01234] [00:09:42/00:04:21, 0.684s/it]: train_loss_raw=0.9641, running_loss=0.8754, LR=0.000100
[2025-08-26 04:22:05,466][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032944] [Batch 00860/01234] [00:09:47/00:04:15, 0.683s/it]: train_loss_raw=0.8532, running_loss=0.8760, LR=0.000100
[2025-08-26 04:22:11,113][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032952] [Batch 00868/01234] [00:09:53/00:04:10, 0.684s/it]: train_loss_raw=0.8490, running_loss=0.8761, LR=0.000100
[2025-08-26 04:22:16,844][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032960] [Batch 00876/01234] [00:09:59/00:04:04, 0.684s/it]: train_loss_raw=0.9147, running_loss=0.8782, LR=0.000100
[2025-08-26 04:22:22,340][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032968] [Batch 00884/01234] [00:10:04/00:03:59, 0.684s/it]: train_loss_raw=0.9259, running_loss=0.8776, LR=0.000100
[2025-08-26 04:22:28,144][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032976] [Batch 00892/01234] [00:10:10/00:03:54, 0.684s/it]: train_loss_raw=0.8863, running_loss=0.8799, LR=0.000100
[2025-08-26 04:22:33,457][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032984] [Batch 00900/01234] [00:10:15/00:03:48, 0.684s/it]: train_loss_raw=0.9149, running_loss=0.8818, LR=0.000100
[2025-08-26 04:22:38,905][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 032992] [Batch 00908/01234] [00:10:21/00:03:42, 0.684s/it]: train_loss_raw=0.9549, running_loss=0.8830, LR=0.000100
[2025-08-26 04:22:44,612][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033000] [Batch 00916/01234] [00:10:26/00:03:37, 0.684s/it]: train_loss_raw=0.8745, running_loss=0.8832, LR=0.000100
[2025-08-26 04:22:49,887][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033008] [Batch 00924/01234] [00:10:32/00:03:32, 0.684s/it]: train_loss_raw=0.8032, running_loss=0.8806, LR=0.000100
[2025-08-26 04:22:55,571][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033016] [Batch 00932/01234] [00:10:37/00:03:26, 0.684s/it]: train_loss_raw=0.8721, running_loss=0.8812, LR=0.000100
[2025-08-26 04:23:01,124][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033024] [Batch 00940/01234] [00:10:43/00:03:21, 0.684s/it]: train_loss_raw=0.8745, running_loss=0.8837, LR=0.000100
[2025-08-26 04:23:06,280][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033032] [Batch 00948/01234] [00:10:48/00:03:15, 0.684s/it]: train_loss_raw=0.8526, running_loss=0.8835, LR=0.000100
[2025-08-26 04:23:11,945][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033040] [Batch 00956/01234] [00:10:54/00:03:10, 0.684s/it]: train_loss_raw=0.8763, running_loss=0.8859, LR=0.000100
[2025-08-26 04:23:17,305][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033048] [Batch 00964/01234] [00:10:59/00:03:04, 0.684s/it]: train_loss_raw=0.9253, running_loss=0.8875, LR=0.000100
[2025-08-26 04:23:22,869][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033056] [Batch 00972/01234] [00:11:05/00:02:59, 0.684s/it]: train_loss_raw=0.7749, running_loss=0.8866, LR=0.000100
[2025-08-26 04:23:27,929][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033064] [Batch 00980/01234] [00:11:10/00:02:53, 0.684s/it]: train_loss_raw=0.9087, running_loss=0.8856, LR=0.000100
[2025-08-26 04:23:33,093][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033072] [Batch 00988/01234] [00:11:15/00:02:48, 0.683s/it]: train_loss_raw=0.9083, running_loss=0.8847, LR=0.000100
[2025-08-26 04:23:38,787][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033080] [Batch 00996/01234] [00:11:20/00:02:42, 0.684s/it]: train_loss_raw=0.7834, running_loss=0.8844, LR=0.000100
[2025-08-26 04:23:44,407][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033088] [Batch 01004/01234] [00:11:26/00:02:37, 0.684s/it]: train_loss_raw=0.8485, running_loss=0.8832, LR=0.000100
[2025-08-26 04:23:49,433][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033096] [Batch 01012/01234] [00:11:31/00:02:31, 0.683s/it]: train_loss_raw=0.9178, running_loss=0.8845, LR=0.000100
[2025-08-26 04:23:54,669][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033104] [Batch 01020/01234] [00:11:36/00:02:26, 0.683s/it]: train_loss_raw=0.8546, running_loss=0.8834, LR=0.000100
[2025-08-26 04:23:59,957][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033112] [Batch 01028/01234] [00:11:42/00:02:20, 0.683s/it]: train_loss_raw=0.8628, running_loss=0.8858, LR=0.000100
[2025-08-26 04:24:05,018][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033120] [Batch 01036/01234] [00:11:47/00:02:15, 0.683s/it]: train_loss_raw=0.9620, running_loss=0.8859, LR=0.000100
[2025-08-26 04:24:10,568][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033128] [Batch 01044/01234] [00:11:52/00:02:09, 0.683s/it]: train_loss_raw=0.8610, running_loss=0.8867, LR=0.000100
[2025-08-26 04:24:15,939][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033136] [Batch 01052/01234] [00:11:58/00:02:04, 0.683s/it]: train_loss_raw=0.8301, running_loss=0.8839, LR=0.000100
[2025-08-26 04:24:21,406][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033144] [Batch 01060/01234] [00:12:03/00:01:58, 0.683s/it]: train_loss_raw=0.8767, running_loss=0.8832, LR=0.000100
[2025-08-26 04:24:26,838][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033152] [Batch 01068/01234] [00:12:09/00:01:53, 0.683s/it]: train_loss_raw=0.9183, running_loss=0.8869, LR=0.000100
[2025-08-26 04:24:32,071][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033160] [Batch 01076/01234] [00:12:14/00:01:47, 0.682s/it]: train_loss_raw=0.8840, running_loss=0.8875, LR=0.000100
[2025-08-26 04:24:37,754][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033168] [Batch 01084/01234] [00:12:19/00:01:42, 0.683s/it]: train_loss_raw=1.0025, running_loss=0.8882, LR=0.000100
[2025-08-26 04:24:43,064][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033176] [Batch 01092/01234] [00:12:25/00:01:36, 0.682s/it]: train_loss_raw=0.8940, running_loss=0.8868, LR=0.000100
[2025-08-26 04:24:48,213][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033184] [Batch 01100/01234] [00:12:30/00:01:31, 0.682s/it]: train_loss_raw=0.8875, running_loss=0.8867, LR=0.000100
[2025-08-26 04:24:54,134][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033192] [Batch 01108/01234] [00:12:36/00:01:26, 0.683s/it]: train_loss_raw=0.8099, running_loss=0.8880, LR=0.000100
[2025-08-26 04:24:59,597][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033200] [Batch 01116/01234] [00:12:41/00:01:20, 0.683s/it]: train_loss_raw=0.8381, running_loss=0.8876, LR=0.000100
[2025-08-26 04:25:04,756][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033208] [Batch 01124/01234] [00:12:46/00:01:15, 0.682s/it]: train_loss_raw=0.8932, running_loss=0.8868, LR=0.000100
[2025-08-26 04:25:10,599][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033216] [Batch 01132/01234] [00:12:52/00:01:09, 0.683s/it]: train_loss_raw=0.8530, running_loss=0.8857, LR=0.000100
[2025-08-26 04:25:16,194][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033224] [Batch 01140/01234] [00:12:58/00:01:04, 0.683s/it]: train_loss_raw=0.8478, running_loss=0.8862, LR=0.000100
[2025-08-26 04:25:21,750][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033232] [Batch 01148/01234] [00:13:03/00:00:58, 0.683s/it]: train_loss_raw=0.9240, running_loss=0.8862, LR=0.000100
[2025-08-26 04:25:27,205][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033240] [Batch 01156/01234] [00:13:09/00:00:53, 0.683s/it]: train_loss_raw=0.8518, running_loss=0.8852, LR=0.000100
[2025-08-26 04:25:32,719][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033248] [Batch 01164/01234] [00:13:14/00:00:47, 0.683s/it]: train_loss_raw=0.9805, running_loss=0.8881, LR=0.000100
[2025-08-26 04:25:38,118][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033256] [Batch 01172/01234] [00:13:20/00:00:42, 0.683s/it]: train_loss_raw=0.8225, running_loss=0.8863, LR=0.000100
[2025-08-26 04:25:43,581][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033264] [Batch 01180/01234] [00:13:25/00:00:36, 0.683s/it]: train_loss_raw=0.8462, running_loss=0.8849, LR=0.000100
[2025-08-26 04:25:49,016][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033272] [Batch 01188/01234] [00:13:31/00:00:31, 0.683s/it]: train_loss_raw=0.9562, running_loss=0.8848, LR=0.000100
[2025-08-26 04:25:54,657][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033280] [Batch 01196/01234] [00:13:36/00:00:25, 0.683s/it]: train_loss_raw=0.9436, running_loss=0.8869, LR=0.000100
[2025-08-26 04:26:00,645][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033288] [Batch 01204/01234] [00:13:42/00:00:20, 0.683s/it]: train_loss_raw=0.9973, running_loss=0.8864, LR=0.000100
[2025-08-26 04:26:06,341][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033296] [Batch 01212/01234] [00:13:48/00:00:15, 0.684s/it]: train_loss_raw=0.9192, running_loss=0.8882, LR=0.000100
[2025-08-26 04:26:12,061][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033304] [Batch 01220/01234] [00:13:54/00:00:09, 0.684s/it]: train_loss_raw=0.9356, running_loss=0.8907, LR=0.000100
[2025-08-26 04:26:17,742][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 033312] [Batch 01228/01234] [00:13:59/00:00:04, 0.684s/it]: train_loss_raw=0.9096, running_loss=0.8909, LR=0.000100
[2025-08-26 04:26:27,323][__main__][INFO] - [VALIDATION] [Epoch 26/29] Starting validation.
[2025-08-26 04:26:38,294][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 033319] [Batch 00007/00026] [00:00:10/00:00:24, 1.371s/it]
[2025-08-26 04:26:49,180][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 033319] [Batch 00015/00026] [00:00:21/00:00:13, 1.366s/it]
[2025-08-26 04:27:00,464][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 033319] [Batch 00023/00026] [00:00:33/00:00:02, 1.381s/it]
[2025-08-26 04:27:02,742][__main__][INFO] - [VALIDATION] [Epoch 26/29] train_loss=0.89170, valid_loss=1.65931
[2025-08-26 04:27:02,742][__main__][INFO] - [VALIDATION] [Epoch 26/29] Metrics:
[2025-08-26 04:27:02,742][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_er      0.592
[2025-08-26 04:27:02,742][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_prec    0.069
[2025-08-26 04:27:02,742][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_recall  0.071
[2025-08-26 04:27:02,742][__main__][INFO] - [VALIDATION] [Epoch 26/29] - pep_recall 0.025
[2025-08-26 04:27:02,744][__main__][INFO] - [TRAIN] [Epoch 26/29] Epoch complete, total time 06:36:11, remaining time 00:44:01, 00:14:40 per epoch
[2025-08-26 04:27:03,644][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033320] [Batch 00002/01234] [00:00:00/00:07:57, 0.388s/it]: train_loss_raw=0.8007, running_loss=0.8317, LR=0.000100
[2025-08-26 04:27:09,138][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033328] [Batch 00010/01234] [00:00:06/00:12:47, 0.627s/it]: train_loss_raw=0.6901, running_loss=0.8266, LR=0.000100
[2025-08-26 04:27:14,550][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033336] [Batch 00018/01234] [00:00:11/00:13:09, 0.649s/it]: train_loss_raw=0.7393, running_loss=0.8243, LR=0.000100
[2025-08-26 04:27:19,964][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033344] [Batch 00026/01234] [00:00:17/00:13:14, 0.658s/it]: train_loss_raw=0.6802, running_loss=0.8195, LR=0.000100
[2025-08-26 04:27:25,753][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033352] [Batch 00034/01234] [00:00:22/00:13:27, 0.673s/it]: train_loss_raw=0.6873, running_loss=0.8154, LR=0.000100
[2025-08-26 04:27:30,833][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033360] [Batch 00042/01234] [00:00:27/00:13:13, 0.666s/it]: train_loss_raw=0.8008, running_loss=0.8135, LR=0.000100
[2025-08-26 04:27:36,291][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033368] [Batch 00050/01234] [00:00:33/00:13:11, 0.668s/it]: train_loss_raw=0.7529, running_loss=0.8090, LR=0.000100
[2025-08-26 04:27:41,537][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033376] [Batch 00058/01234] [00:00:38/00:13:04, 0.667s/it]: train_loss_raw=0.7480, running_loss=0.8062, LR=0.000100
[2025-08-26 04:27:46,909][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033384] [Batch 00066/01234] [00:00:44/00:12:59, 0.667s/it]: train_loss_raw=0.8061, running_loss=0.8017, LR=0.000100
[2025-08-26 04:27:52,418][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033392] [Batch 00074/01234] [00:00:49/00:12:56, 0.670s/it]: train_loss_raw=0.8279, running_loss=0.8013, LR=0.000100
[2025-08-26 04:27:58,081][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033400] [Batch 00082/01234] [00:00:55/00:12:55, 0.673s/it]: train_loss_raw=0.8260, running_loss=0.8001, LR=0.000100
[2025-08-26 04:28:03,616][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033408] [Batch 00090/01234] [00:01:00/00:12:52, 0.675s/it]: train_loss_raw=0.7598, running_loss=0.7995, LR=0.000100
[2025-08-26 04:28:09,052][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033416] [Batch 00098/01234] [00:01:06/00:12:47, 0.675s/it]: train_loss_raw=0.8588, running_loss=0.7976, LR=0.000100
[2025-08-26 04:28:14,549][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033424] [Batch 00106/01234] [00:01:11/00:12:42, 0.676s/it]: train_loss_raw=0.7619, running_loss=0.7981, LR=0.000100
[2025-08-26 04:28:19,986][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033432] [Batch 00114/01234] [00:01:17/00:12:37, 0.676s/it]: train_loss_raw=0.7547, running_loss=0.7950, LR=0.000100
[2025-08-26 04:28:25,175][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033440] [Batch 00122/01234] [00:01:22/00:12:30, 0.675s/it]: train_loss_raw=0.8235, running_loss=0.7935, LR=0.000100
[2025-08-26 04:28:30,791][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033448] [Batch 00130/01234] [00:01:27/00:12:26, 0.676s/it]: train_loss_raw=0.6924, running_loss=0.7924, LR=0.000100
[2025-08-26 04:28:36,669][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033456] [Batch 00138/01234] [00:01:33/00:12:24, 0.680s/it]: train_loss_raw=0.9242, running_loss=0.7962, LR=0.000100
[2025-08-26 04:28:42,136][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033464] [Batch 00146/01234] [00:01:39/00:12:19, 0.680s/it]: train_loss_raw=0.8024, running_loss=0.7966, LR=0.000100
[2025-08-26 04:28:47,525][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033472] [Batch 00154/01234] [00:01:44/00:12:13, 0.680s/it]: train_loss_raw=0.8324, running_loss=0.7979, LR=0.000100
[2025-08-26 04:28:53,392][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033480] [Batch 00162/01234] [00:01:50/00:12:11, 0.682s/it]: train_loss_raw=0.7548, running_loss=0.7998, LR=0.000100
[2025-08-26 04:28:58,628][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033488] [Batch 00170/01234] [00:01:55/00:12:04, 0.681s/it]: train_loss_raw=0.7850, running_loss=0.8002, LR=0.000100
[2025-08-26 04:29:03,848][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033496] [Batch 00178/01234] [00:02:00/00:11:57, 0.680s/it]: train_loss_raw=0.8198, running_loss=0.8007, LR=0.000100
[2025-08-26 04:29:08,916][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033504] [Batch 00186/01234] [00:02:06/00:11:50, 0.678s/it]: train_loss_raw=0.8293, running_loss=0.8022, LR=0.000100
[2025-08-26 04:29:14,149][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033512] [Batch 00194/01234] [00:02:11/00:11:43, 0.677s/it]: train_loss_raw=0.8147, running_loss=0.8041, LR=0.000100
[2025-08-26 04:29:19,501][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033520] [Batch 00202/01234] [00:02:16/00:11:38, 0.676s/it]: train_loss_raw=0.7401, running_loss=0.8024, LR=0.000100
[2025-08-26 04:29:24,678][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033528] [Batch 00210/01234] [00:02:21/00:11:31, 0.675s/it]: train_loss_raw=0.7623, running_loss=0.8016, LR=0.000100
[2025-08-26 04:29:29,752][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033536] [Batch 00218/01234] [00:02:26/00:11:24, 0.674s/it]: train_loss_raw=0.8170, running_loss=0.7983, LR=0.000100
[2025-08-26 04:29:35,223][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033544] [Batch 00226/01234] [00:02:32/00:11:19, 0.674s/it]: train_loss_raw=0.8582, running_loss=0.7985, LR=0.000100
[2025-08-26 04:29:41,148][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033552] [Batch 00234/01234] [00:02:38/00:11:16, 0.676s/it]: train_loss_raw=0.8129, running_loss=0.7975, LR=0.000100
[2025-08-26 04:29:46,757][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033560] [Batch 00242/01234] [00:02:43/00:11:11, 0.677s/it]: train_loss_raw=0.8592, running_loss=0.7969, LR=0.000100
[2025-08-26 04:29:51,941][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033568] [Batch 00250/01234] [00:02:49/00:11:05, 0.676s/it]: train_loss_raw=0.8307, running_loss=0.7979, LR=0.000100
[2025-08-26 04:29:57,141][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033576] [Batch 00258/01234] [00:02:54/00:10:59, 0.675s/it]: train_loss_raw=0.7799, running_loss=0.7989, LR=0.000100
[2025-08-26 04:30:03,192][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033584] [Batch 00266/01234] [00:03:00/00:10:56, 0.678s/it]: train_loss_raw=0.6933, running_loss=0.7956, LR=0.000100
[2025-08-26 04:30:08,733][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033592] [Batch 00274/01234] [00:03:05/00:10:51, 0.678s/it]: train_loss_raw=0.8346, running_loss=0.7948, LR=0.000100
[2025-08-26 04:30:13,884][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033600] [Batch 00282/01234] [00:03:11/00:10:44, 0.677s/it]: train_loss_raw=0.7753, running_loss=0.7962, LR=0.000100
[2025-08-26 04:30:19,272][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033608] [Batch 00290/01234] [00:03:16/00:10:39, 0.677s/it]: train_loss_raw=0.7581, running_loss=0.7963, LR=0.000100
[2025-08-26 04:30:24,926][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033616] [Batch 00298/01234] [00:03:22/00:10:34, 0.678s/it]: train_loss_raw=0.8669, running_loss=0.7984, LR=0.000100
[2025-08-26 04:30:30,515][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033624] [Batch 00306/01234] [00:03:27/00:10:29, 0.679s/it]: train_loss_raw=0.7944, running_loss=0.7988, LR=0.000100
[2025-08-26 04:30:36,347][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033632] [Batch 00314/01234] [00:03:33/00:10:25, 0.680s/it]: train_loss_raw=0.8450, running_loss=0.7993, LR=0.000100
[2025-08-26 04:30:42,044][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033640] [Batch 00322/01234] [00:03:39/00:10:20, 0.681s/it]: train_loss_raw=0.8276, running_loss=0.8009, LR=0.000100
[2025-08-26 04:30:47,627][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033648] [Batch 00330/01234] [00:03:44/00:10:15, 0.681s/it]: train_loss_raw=0.8956, running_loss=0.8021, LR=0.000100
[2025-08-26 04:30:53,620][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033656] [Batch 00338/01234] [00:03:50/00:10:11, 0.683s/it]: train_loss_raw=0.8808, running_loss=0.8040, LR=0.000100
[2025-08-26 04:30:59,418][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033664] [Batch 00346/01234] [00:03:56/00:10:07, 0.684s/it]: train_loss_raw=0.7321, running_loss=0.8054, LR=0.000100
[2025-08-26 04:31:04,515][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033672] [Batch 00354/01234] [00:04:01/00:10:00, 0.683s/it]: train_loss_raw=0.9176, running_loss=0.8071, LR=0.000100
[2025-08-26 04:31:10,033][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033680] [Batch 00362/01234] [00:04:07/00:09:55, 0.683s/it]: train_loss_raw=0.7970, running_loss=0.8060, LR=0.000100
[2025-08-26 04:31:15,736][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033688] [Batch 00370/01234] [00:04:12/00:09:50, 0.683s/it]: train_loss_raw=0.8098, running_loss=0.8068, LR=0.000100
[2025-08-26 04:31:21,192][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033696] [Batch 00378/01234] [00:04:18/00:09:44, 0.683s/it]: train_loss_raw=0.8553, running_loss=0.8079, LR=0.000100
[2025-08-26 04:31:27,104][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033704] [Batch 00386/01234] [00:04:24/00:09:40, 0.685s/it]: train_loss_raw=0.8114, running_loss=0.8068, LR=0.000100
[2025-08-26 04:31:32,666][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033712] [Batch 00394/01234] [00:04:29/00:09:35, 0.685s/it]: train_loss_raw=0.8606, running_loss=0.8076, LR=0.000100
[2025-08-26 04:31:37,709][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033720] [Batch 00402/01234] [00:04:34/00:09:28, 0.684s/it]: train_loss_raw=0.7224, running_loss=0.8078, LR=0.000100
[2025-08-26 04:31:42,884][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033728] [Batch 00410/01234] [00:04:40/00:09:22, 0.683s/it]: train_loss_raw=0.7623, running_loss=0.8097, LR=0.000100
[2025-08-26 04:31:47,955][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033736] [Batch 00418/01234] [00:04:45/00:09:16, 0.682s/it]: train_loss_raw=0.8004, running_loss=0.8105, LR=0.000100
[2025-08-26 04:31:53,361][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033744] [Batch 00426/01234] [00:04:50/00:09:10, 0.682s/it]: train_loss_raw=0.8142, running_loss=0.8091, LR=0.000100
[2025-08-26 04:31:58,617][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033752] [Batch 00434/01234] [00:04:55/00:09:05, 0.681s/it]: train_loss_raw=0.7862, running_loss=0.8085, LR=0.000100
[2025-08-26 04:32:04,126][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033760] [Batch 00442/01234] [00:05:01/00:08:59, 0.682s/it]: train_loss_raw=0.8033, running_loss=0.8080, LR=0.000100
[2025-08-26 04:32:09,645][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033768] [Batch 00450/01234] [00:05:06/00:08:54, 0.682s/it]: train_loss_raw=0.8888, running_loss=0.8079, LR=0.000100
[2025-08-26 04:32:14,794][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033776] [Batch 00458/01234] [00:05:11/00:08:48, 0.681s/it]: train_loss_raw=0.8933, running_loss=0.8103, LR=0.000100
[2025-08-26 04:32:20,403][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033784] [Batch 00466/01234] [00:05:17/00:08:43, 0.681s/it]: train_loss_raw=0.8038, running_loss=0.8131, LR=0.000100
[2025-08-26 04:32:26,069][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033792] [Batch 00474/01234] [00:05:23/00:08:38, 0.682s/it]: train_loss_raw=0.7666, running_loss=0.8142, LR=0.000100
[2025-08-26 04:32:32,210][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033800] [Batch 00482/01234] [00:05:29/00:08:33, 0.683s/it]: train_loss_raw=0.8769, running_loss=0.8169, LR=0.000100
[2025-08-26 04:32:37,930][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033808] [Batch 00490/01234] [00:05:35/00:08:28, 0.684s/it]: train_loss_raw=0.9675, running_loss=0.8207, LR=0.000100
[2025-08-26 04:32:43,443][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033816] [Batch 00498/01234] [00:05:40/00:08:23, 0.684s/it]: train_loss_raw=0.7764, running_loss=0.8210, LR=0.000100
[2025-08-26 04:32:48,777][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033824] [Batch 00506/01234] [00:05:45/00:08:17, 0.684s/it]: train_loss_raw=0.8816, running_loss=0.8225, LR=0.000100
[2025-08-26 04:32:54,361][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033832] [Batch 00514/01234] [00:05:51/00:08:12, 0.684s/it]: train_loss_raw=0.8521, running_loss=0.8229, LR=0.000100
[2025-08-26 04:32:59,435][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033840] [Batch 00522/01234] [00:05:56/00:08:06, 0.683s/it]: train_loss_raw=0.7140, running_loss=0.8222, LR=0.000100
[2025-08-26 04:33:04,804][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033848] [Batch 00530/01234] [00:06:01/00:08:00, 0.683s/it]: train_loss_raw=0.7502, running_loss=0.8239, LR=0.000100
[2025-08-26 04:33:09,938][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033856] [Batch 00538/01234] [00:06:07/00:07:54, 0.682s/it]: train_loss_raw=0.8762, running_loss=0.8255, LR=0.000100
[2025-08-26 04:33:15,168][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033864] [Batch 00546/01234] [00:06:12/00:07:49, 0.682s/it]: train_loss_raw=0.9214, running_loss=0.8272, LR=0.000100
[2025-08-26 04:33:20,992][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033872] [Batch 00554/01234] [00:06:18/00:07:44, 0.683s/it]: train_loss_raw=0.8265, running_loss=0.8272, LR=0.000100
[2025-08-26 04:33:26,485][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033880] [Batch 00562/01234] [00:06:23/00:07:38, 0.683s/it]: train_loss_raw=0.7803, running_loss=0.8271, LR=0.000100
[2025-08-26 04:33:32,209][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033888] [Batch 00570/01234] [00:06:29/00:07:33, 0.683s/it]: train_loss_raw=0.7968, running_loss=0.8276, LR=0.000100
[2025-08-26 04:33:37,556][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033896] [Batch 00578/01234] [00:06:34/00:07:27, 0.683s/it]: train_loss_raw=0.7771, running_loss=0.8285, LR=0.000100
[2025-08-26 04:33:42,810][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033904] [Batch 00586/01234] [00:06:39/00:07:22, 0.682s/it]: train_loss_raw=0.7434, running_loss=0.8304, LR=0.000100
[2025-08-26 04:33:47,856][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033912] [Batch 00594/01234] [00:06:44/00:07:16, 0.682s/it]: train_loss_raw=0.8560, running_loss=0.8329, LR=0.000100
[2025-08-26 04:33:53,464][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033920] [Batch 00602/01234] [00:06:50/00:07:11, 0.682s/it]: train_loss_raw=0.8733, running_loss=0.8314, LR=0.000100
[2025-08-26 04:33:59,204][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033928] [Batch 00610/01234] [00:06:56/00:07:05, 0.683s/it]: train_loss_raw=0.8436, running_loss=0.8326, LR=0.000100
[2025-08-26 04:34:04,801][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033936] [Batch 00618/01234] [00:07:01/00:07:00, 0.683s/it]: train_loss_raw=0.7989, running_loss=0.8302, LR=0.000100
[2025-08-26 04:34:10,650][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033944] [Batch 00626/01234] [00:07:07/00:06:55, 0.683s/it]: train_loss_raw=0.8645, running_loss=0.8341, LR=0.000100
[2025-08-26 04:34:15,749][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033952] [Batch 00634/01234] [00:07:12/00:06:49, 0.683s/it]: train_loss_raw=0.8003, running_loss=0.8329, LR=0.000100
[2025-08-26 04:34:20,882][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033960] [Batch 00642/01234] [00:07:18/00:06:43, 0.682s/it]: train_loss_raw=0.8842, running_loss=0.8340, LR=0.000100
[2025-08-26 04:34:26,373][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033968] [Batch 00650/01234] [00:07:23/00:06:38, 0.682s/it]: train_loss_raw=0.8021, running_loss=0.8341, LR=0.000100
[2025-08-26 04:34:32,015][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033976] [Batch 00658/01234] [00:07:29/00:06:33, 0.683s/it]: train_loss_raw=0.7667, running_loss=0.8348, LR=0.000100
[2025-08-26 04:34:37,994][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033984] [Batch 00666/01234] [00:07:35/00:06:28, 0.683s/it]: train_loss_raw=0.8267, running_loss=0.8337, LR=0.000100
[2025-08-26 04:34:43,066][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 033992] [Batch 00674/01234] [00:07:40/00:06:22, 0.683s/it]: train_loss_raw=0.8803, running_loss=0.8353, LR=0.000100
[2025-08-26 04:34:48,206][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034000] [Batch 00682/01234] [00:07:45/00:06:16, 0.682s/it]: train_loss_raw=0.8747, running_loss=0.8362, LR=0.000100
[2025-08-26 04:34:57,162][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034008] [Batch 00690/01234] [00:07:54/00:06:13, 0.687s/it]: train_loss_raw=0.8078, running_loss=0.8378, LR=0.000100
[2025-08-26 04:35:02,227][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034016] [Batch 00698/01234] [00:07:59/00:06:08, 0.687s/it]: train_loss_raw=0.7443, running_loss=0.8375, LR=0.000100
[2025-08-26 04:35:07,640][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034024] [Batch 00706/01234] [00:08:04/00:06:02, 0.687s/it]: train_loss_raw=0.7632, running_loss=0.8375, LR=0.000100
[2025-08-26 04:35:12,786][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034032] [Batch 00714/01234] [00:08:09/00:05:56, 0.686s/it]: train_loss_raw=0.8517, running_loss=0.8372, LR=0.000100
[2025-08-26 04:35:17,840][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034040] [Batch 00722/01234] [00:08:14/00:05:51, 0.686s/it]: train_loss_raw=0.8764, running_loss=0.8382, LR=0.000100
[2025-08-26 04:35:23,184][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034048] [Batch 00730/01234] [00:08:20/00:05:45, 0.685s/it]: train_loss_raw=0.8613, running_loss=0.8359, LR=0.000100
[2025-08-26 04:35:28,642][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034056] [Batch 00738/01234] [00:08:25/00:05:39, 0.685s/it]: train_loss_raw=0.8177, running_loss=0.8381, LR=0.000100
[2025-08-26 04:35:33,749][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034064] [Batch 00746/01234] [00:08:30/00:05:34, 0.685s/it]: train_loss_raw=0.8807, running_loss=0.8384, LR=0.000100
[2025-08-26 04:35:39,101][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034072] [Batch 00754/01234] [00:08:36/00:05:28, 0.685s/it]: train_loss_raw=0.8841, running_loss=0.8406, LR=0.000100
[2025-08-26 04:35:44,328][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034080] [Batch 00762/01234] [00:08:41/00:05:23, 0.684s/it]: train_loss_raw=0.7691, running_loss=0.8390, LR=0.000100
[2025-08-26 04:35:49,844][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034088] [Batch 00770/01234] [00:08:46/00:05:17, 0.684s/it]: train_loss_raw=0.8271, running_loss=0.8369, LR=0.000100
[2025-08-26 04:35:55,510][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034096] [Batch 00778/01234] [00:08:52/00:05:12, 0.685s/it]: train_loss_raw=0.8083, running_loss=0.8371, LR=0.000100
[2025-08-26 04:36:00,918][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034104] [Batch 00786/01234] [00:08:58/00:05:06, 0.685s/it]: train_loss_raw=0.8042, running_loss=0.8385, LR=0.000100
[2025-08-26 04:36:06,393][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034112] [Batch 00794/01234] [00:09:03/00:05:01, 0.685s/it]: train_loss_raw=0.8393, running_loss=0.8382, LR=0.000100
[2025-08-26 04:36:11,437][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034120] [Batch 00802/01234] [00:09:08/00:04:55, 0.684s/it]: train_loss_raw=0.8846, running_loss=0.8372, LR=0.000100
[2025-08-26 04:36:17,078][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034128] [Batch 00810/01234] [00:09:14/00:04:50, 0.684s/it]: train_loss_raw=0.9113, running_loss=0.8395, LR=0.000100
[2025-08-26 04:36:22,284][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034136] [Batch 00818/01234] [00:09:19/00:04:44, 0.684s/it]: train_loss_raw=0.8668, running_loss=0.8419, LR=0.000100
[2025-08-26 04:36:27,499][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034144] [Batch 00826/01234] [00:09:24/00:04:38, 0.684s/it]: train_loss_raw=0.7724, running_loss=0.8420, LR=0.000100
[2025-08-26 04:36:33,092][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034152] [Batch 00834/01234] [00:09:30/00:04:33, 0.684s/it]: train_loss_raw=0.8333, running_loss=0.8417, LR=0.000100
[2025-08-26 04:36:38,597][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034160] [Batch 00842/01234] [00:09:35/00:04:28, 0.684s/it]: train_loss_raw=0.7270, running_loss=0.8410, LR=0.000100
[2025-08-26 04:36:44,117][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034168] [Batch 00850/01234] [00:09:41/00:04:22, 0.684s/it]: train_loss_raw=0.8413, running_loss=0.8435, LR=0.000100
[2025-08-26 04:36:49,676][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034176] [Batch 00858/01234] [00:09:46/00:04:17, 0.684s/it]: train_loss_raw=0.8489, running_loss=0.8440, LR=0.000100
[2025-08-26 04:36:54,749][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034184] [Batch 00866/01234] [00:09:51/00:04:11, 0.683s/it]: train_loss_raw=0.8699, running_loss=0.8454, LR=0.000100
[2025-08-26 04:36:59,842][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034192] [Batch 00874/01234] [00:09:56/00:04:05, 0.683s/it]: train_loss_raw=0.8407, running_loss=0.8463, LR=0.000100
[2025-08-26 04:37:05,598][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034200] [Batch 00882/01234] [00:10:02/00:04:00, 0.683s/it]: train_loss_raw=0.8408, running_loss=0.8461, LR=0.000100
[2025-08-26 04:37:11,418][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034208] [Batch 00890/01234] [00:10:08/00:03:55, 0.684s/it]: train_loss_raw=0.8784, running_loss=0.8467, LR=0.000100
[2025-08-26 04:37:16,752][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034216] [Batch 00898/01234] [00:10:13/00:03:49, 0.684s/it]: train_loss_raw=0.8055, running_loss=0.8474, LR=0.000100
[2025-08-26 04:37:22,032][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034224] [Batch 00906/01234] [00:10:19/00:03:44, 0.683s/it]: train_loss_raw=0.8294, running_loss=0.8471, LR=0.000100
[2025-08-26 04:37:27,547][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034232] [Batch 00914/01234] [00:10:24/00:03:38, 0.683s/it]: train_loss_raw=0.8672, running_loss=0.8482, LR=0.000100
[2025-08-26 04:37:32,782][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034240] [Batch 00922/01234] [00:10:29/00:03:33, 0.683s/it]: train_loss_raw=0.8230, running_loss=0.8483, LR=0.000100
[2025-08-26 04:37:38,036][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034248] [Batch 00930/01234] [00:10:35/00:03:27, 0.683s/it]: train_loss_raw=0.8739, running_loss=0.8482, LR=0.000100
[2025-08-26 04:37:43,076][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034256] [Batch 00938/01234] [00:10:40/00:03:22, 0.683s/it]: train_loss_raw=0.8010, running_loss=0.8496, LR=0.000100
[2025-08-26 04:37:48,136][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034264] [Batch 00946/01234] [00:10:45/00:03:16, 0.682s/it]: train_loss_raw=0.8324, running_loss=0.8495, LR=0.000100
[2025-08-26 04:37:53,197][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034272] [Batch 00954/01234] [00:10:50/00:03:10, 0.682s/it]: train_loss_raw=0.8224, running_loss=0.8487, LR=0.000100
[2025-08-26 04:37:58,635][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034280] [Batch 00962/01234] [00:10:55/00:03:05, 0.682s/it]: train_loss_raw=0.8996, running_loss=0.8493, LR=0.000100
[2025-08-26 04:38:04,327][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034288] [Batch 00970/01234] [00:11:01/00:03:00, 0.682s/it]: train_loss_raw=0.8456, running_loss=0.8515, LR=0.000100
[2025-08-26 04:38:10,085][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034296] [Batch 00978/01234] [00:11:07/00:02:54, 0.682s/it]: train_loss_raw=0.8818, running_loss=0.8510, LR=0.000100
[2025-08-26 04:38:15,364][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034304] [Batch 00986/01234] [00:11:12/00:02:49, 0.682s/it]: train_loss_raw=0.7760, running_loss=0.8523, LR=0.000100
[2025-08-26 04:38:20,485][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034312] [Batch 00994/01234] [00:11:17/00:02:43, 0.682s/it]: train_loss_raw=0.8303, running_loss=0.8506, LR=0.000100
[2025-08-26 04:38:25,638][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034320] [Batch 01002/01234] [00:11:22/00:02:38, 0.681s/it]: train_loss_raw=0.8803, running_loss=0.8513, LR=0.000100
[2025-08-26 04:38:30,958][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034328] [Batch 01010/01234] [00:11:28/00:02:32, 0.681s/it]: train_loss_raw=0.8551, running_loss=0.8519, LR=0.000100
[2025-08-26 04:38:36,367][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034336] [Batch 01018/01234] [00:11:33/00:02:27, 0.681s/it]: train_loss_raw=0.8617, running_loss=0.8519, LR=0.000100
[2025-08-26 04:38:41,438][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034344] [Batch 01026/01234] [00:11:38/00:02:21, 0.681s/it]: train_loss_raw=0.8981, running_loss=0.8531, LR=0.000100
[2025-08-26 04:38:47,248][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034352] [Batch 01034/01234] [00:11:44/00:02:16, 0.681s/it]: train_loss_raw=0.7960, running_loss=0.8568, LR=0.000100
[2025-08-26 04:38:52,402][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034360] [Batch 01042/01234] [00:11:49/00:02:10, 0.681s/it]: train_loss_raw=0.8100, running_loss=0.8545, LR=0.000100
[2025-08-26 04:38:57,614][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034368] [Batch 01050/01234] [00:11:54/00:02:05, 0.681s/it]: train_loss_raw=0.8598, running_loss=0.8556, LR=0.000100
[2025-08-26 04:39:02,845][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034376] [Batch 01058/01234] [00:11:59/00:01:59, 0.681s/it]: train_loss_raw=0.8108, running_loss=0.8534, LR=0.000100
[2025-08-26 04:39:08,674][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034384] [Batch 01066/01234] [00:12:05/00:01:54, 0.681s/it]: train_loss_raw=0.8499, running_loss=0.8526, LR=0.000100
[2025-08-26 04:39:14,403][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034392] [Batch 01074/01234] [00:12:11/00:01:48, 0.681s/it]: train_loss_raw=0.8453, running_loss=0.8525, LR=0.000100
[2025-08-26 04:39:19,936][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034400] [Batch 01082/01234] [00:12:17/00:01:43, 0.681s/it]: train_loss_raw=0.8395, running_loss=0.8547, LR=0.000100
[2025-08-26 04:39:25,358][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034408] [Batch 01090/01234] [00:12:22/00:01:38, 0.681s/it]: train_loss_raw=0.8478, running_loss=0.8543, LR=0.000100
[2025-08-26 04:39:31,011][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034416] [Batch 01098/01234] [00:12:28/00:01:32, 0.681s/it]: train_loss_raw=0.8503, running_loss=0.8542, LR=0.000100
[2025-08-26 04:39:36,227][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034424] [Batch 01106/01234] [00:12:33/00:01:27, 0.681s/it]: train_loss_raw=0.8485, running_loss=0.8531, LR=0.000100
[2025-08-26 04:39:41,658][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034432] [Batch 01114/01234] [00:12:38/00:01:21, 0.681s/it]: train_loss_raw=0.8672, running_loss=0.8507, LR=0.000100
[2025-08-26 04:39:46,815][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034440] [Batch 01122/01234] [00:12:43/00:01:16, 0.681s/it]: train_loss_raw=0.9143, running_loss=0.8504, LR=0.000100
[2025-08-26 04:39:51,944][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034448] [Batch 01130/01234] [00:12:49/00:01:10, 0.681s/it]: train_loss_raw=0.8797, running_loss=0.8508, LR=0.000100
[2025-08-26 04:39:57,076][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034456] [Batch 01138/01234] [00:12:54/00:01:05, 0.680s/it]: train_loss_raw=0.9186, running_loss=0.8511, LR=0.000100
[2025-08-26 04:40:02,202][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034464] [Batch 01146/01234] [00:12:59/00:00:59, 0.680s/it]: train_loss_raw=0.9210, running_loss=0.8515, LR=0.000100
[2025-08-26 04:40:07,322][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034472] [Batch 01154/01234] [00:13:04/00:00:54, 0.680s/it]: train_loss_raw=0.8710, running_loss=0.8502, LR=0.000100
[2025-08-26 04:40:12,455][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034480] [Batch 01162/01234] [00:13:09/00:00:48, 0.680s/it]: train_loss_raw=0.8459, running_loss=0.8499, LR=0.000100
[2025-08-26 04:40:17,787][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034488] [Batch 01170/01234] [00:13:14/00:00:43, 0.679s/it]: train_loss_raw=0.8293, running_loss=0.8525, LR=0.000100
[2025-08-26 04:40:23,725][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034496] [Batch 01178/01234] [00:13:20/00:00:38, 0.680s/it]: train_loss_raw=0.8063, running_loss=0.8511, LR=0.000100
[2025-08-26 04:40:29,355][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034504] [Batch 01186/01234] [00:13:26/00:00:32, 0.680s/it]: train_loss_raw=0.8624, running_loss=0.8519, LR=0.000100
[2025-08-26 04:40:34,431][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034512] [Batch 01194/01234] [00:13:31/00:00:27, 0.680s/it]: train_loss_raw=0.7865, running_loss=0.8527, LR=0.000100
[2025-08-26 04:40:40,107][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034520] [Batch 01202/01234] [00:13:37/00:00:21, 0.680s/it]: train_loss_raw=0.8599, running_loss=0.8518, LR=0.000100
[2025-08-26 04:40:45,418][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034528] [Batch 01210/01234] [00:13:42/00:00:16, 0.680s/it]: train_loss_raw=0.8368, running_loss=0.8494, LR=0.000100
[2025-08-26 04:40:50,843][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034536] [Batch 01218/01234] [00:13:47/00:00:10, 0.680s/it]: train_loss_raw=0.8821, running_loss=0.8485, LR=0.000100
[2025-08-26 04:40:56,032][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034544] [Batch 01226/01234] [00:13:53/00:00:05, 0.680s/it]: train_loss_raw=0.8295, running_loss=0.8483, LR=0.000100
[2025-08-26 04:41:06,944][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 034552] [Batch 01234/01234] [00:14:04/00:00:00, 0.684s/it]: train_loss_raw=0.7694, running_loss=0.8479, LR=0.000100
[2025-08-26 04:41:07,334][__main__][INFO] - [VALIDATION] [Epoch 27/29] Starting validation.
[2025-08-26 04:41:17,401][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 034553] [Batch 00007/00026] [00:00:10/00:00:22, 1.258s/it]
[2025-08-26 04:41:28,688][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 034553] [Batch 00015/00026] [00:00:21/00:00:13, 1.335s/it]
[2025-08-26 04:41:39,107][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 034553] [Batch 00023/00026] [00:00:31/00:00:02, 1.324s/it]
[2025-08-26 04:41:41,389][__main__][INFO] - [VALIDATION] [Epoch 27/29] train_loss=0.84790, valid_loss=1.71441
[2025-08-26 04:41:41,389][__main__][INFO] - [VALIDATION] [Epoch 27/29] Metrics:
[2025-08-26 04:41:41,389][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_er      0.588
[2025-08-26 04:41:41,389][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_prec    0.065
[2025-08-26 04:41:41,390][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_recall  0.066
[2025-08-26 04:41:41,390][__main__][INFO] - [VALIDATION] [Epoch 27/29] - pep_recall 0.026
[2025-08-26 04:41:41,391][__main__][INFO] - [TRAIN] [Epoch 27/29] Epoch complete, total time 06:50:50, remaining time 00:29:20, 00:14:40 per epoch
[2025-08-26 04:41:46,086][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034560] [Batch 00008/01234] [00:00:04/00:11:40, 0.571s/it]: train_loss_raw=0.6277, running_loss=0.8000, LR=0.000100
[2025-08-26 04:41:51,161][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034568] [Batch 00016/01234] [00:00:09/00:12:14, 0.603s/it]: train_loss_raw=0.6916, running_loss=0.7966, LR=0.000100
[2025-08-26 04:41:56,213][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034576] [Batch 00024/01234] [00:00:14/00:12:21, 0.612s/it]: train_loss_raw=0.7788, running_loss=0.7926, LR=0.000100
[2025-08-26 04:42:01,286][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034584] [Batch 00032/01234] [00:00:19/00:12:22, 0.618s/it]: train_loss_raw=0.8294, running_loss=0.7869, LR=0.000100
[2025-08-26 04:42:06,655][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034592] [Batch 00040/01234] [00:00:25/00:12:30, 0.628s/it]: train_loss_raw=0.7450, running_loss=0.7833, LR=0.000100
[2025-08-26 04:42:11,697][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034600] [Batch 00048/01234] [00:00:30/00:12:25, 0.629s/it]: train_loss_raw=0.7774, running_loss=0.7807, LR=0.000100
[2025-08-26 04:42:16,859][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034608] [Batch 00056/01234] [00:00:35/00:12:23, 0.631s/it]: train_loss_raw=0.6018, running_loss=0.7759, LR=0.000100
[2025-08-26 04:42:22,619][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034616] [Batch 00064/01234] [00:00:41/00:12:31, 0.642s/it]: train_loss_raw=0.7195, running_loss=0.7728, LR=0.000100
[2025-08-26 04:42:28,168][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034624] [Batch 00072/01234] [00:00:46/00:12:32, 0.648s/it]: train_loss_raw=0.7230, running_loss=0.7690, LR=0.000100
[2025-08-26 04:42:33,929][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034632] [Batch 00080/01234] [00:00:52/00:12:36, 0.655s/it]: train_loss_raw=0.7086, running_loss=0.7666, LR=0.000100
[2025-08-26 04:42:39,900][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034640] [Batch 00088/01234] [00:00:58/00:12:40, 0.663s/it]: train_loss_raw=0.7632, running_loss=0.7657, LR=0.000100
[2025-08-26 04:42:45,366][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034648] [Batch 00096/01234] [00:01:03/00:12:36, 0.665s/it]: train_loss_raw=0.7752, running_loss=0.7646, LR=0.000100
[2025-08-26 04:42:51,260][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034656] [Batch 00104/01234] [00:01:09/00:12:37, 0.671s/it]: train_loss_raw=0.7741, running_loss=0.7632, LR=0.000100
[2025-08-26 04:42:56,416][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034664] [Batch 00112/01234] [00:01:14/00:12:30, 0.669s/it]: train_loss_raw=0.8258, running_loss=0.7627, LR=0.000100
[2025-08-26 04:43:01,836][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034672] [Batch 00120/01234] [00:01:20/00:12:25, 0.669s/it]: train_loss_raw=0.7447, running_loss=0.7609, LR=0.000100
[2025-08-26 04:43:07,158][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034680] [Batch 00128/01234] [00:01:25/00:12:20, 0.669s/it]: train_loss_raw=0.7821, running_loss=0.7601, LR=0.000100
[2025-08-26 04:43:12,492][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034688] [Batch 00136/01234] [00:01:30/00:12:14, 0.669s/it]: train_loss_raw=0.7724, running_loss=0.7588, LR=0.000100
[2025-08-26 04:43:17,894][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034696] [Batch 00144/01234] [00:01:36/00:12:09, 0.669s/it]: train_loss_raw=0.7502, running_loss=0.7590, LR=0.000100
[2025-08-26 04:43:23,307][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034704] [Batch 00152/01234] [00:01:41/00:12:04, 0.670s/it]: train_loss_raw=0.7662, running_loss=0.7569, LR=0.000100
[2025-08-26 04:43:28,947][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034712] [Batch 00160/01234] [00:01:47/00:12:01, 0.671s/it]: train_loss_raw=0.7057, running_loss=0.7554, LR=0.000100
[2025-08-26 04:43:34,494][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034720] [Batch 00168/01234] [00:01:52/00:11:56, 0.672s/it]: train_loss_raw=0.7353, running_loss=0.7555, LR=0.000100
[2025-08-26 04:43:39,903][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034728] [Batch 00176/01234] [00:01:58/00:11:51, 0.673s/it]: train_loss_raw=0.7295, running_loss=0.7549, LR=0.000100
[2025-08-26 04:43:45,934][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034736] [Batch 00184/01234] [00:02:04/00:11:49, 0.676s/it]: train_loss_raw=0.7783, running_loss=0.7565, LR=0.000100
[2025-08-26 04:43:51,840][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034744] [Batch 00192/01234] [00:02:10/00:11:47, 0.679s/it]: train_loss_raw=0.6915, running_loss=0.7574, LR=0.000100
[2025-08-26 04:43:57,244][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034752] [Batch 00200/01234] [00:02:15/00:11:41, 0.679s/it]: train_loss_raw=0.7547, running_loss=0.7588, LR=0.000100
[2025-08-26 04:44:02,903][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034760] [Batch 00208/01234] [00:02:21/00:11:37, 0.680s/it]: train_loss_raw=0.8573, running_loss=0.7598, LR=0.000100
[2025-08-26 04:44:08,836][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034768] [Batch 00216/01234] [00:02:27/00:11:34, 0.682s/it]: train_loss_raw=0.7325, running_loss=0.7600, LR=0.000100
[2025-08-26 04:44:13,979][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034776] [Batch 00224/01234] [00:02:32/00:11:27, 0.681s/it]: train_loss_raw=0.7641, running_loss=0.7604, LR=0.000100
[2025-08-26 04:44:19,206][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034784] [Batch 00232/01234] [00:02:37/00:11:21, 0.680s/it]: train_loss_raw=0.7524, running_loss=0.7608, LR=0.000100
[2025-08-26 04:44:25,032][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034792] [Batch 00240/01234] [00:02:43/00:11:17, 0.681s/it]: train_loss_raw=0.7327, running_loss=0.7584, LR=0.000100
[2025-08-26 04:44:30,236][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034800] [Batch 00248/01234] [00:02:48/00:11:10, 0.680s/it]: train_loss_raw=0.7894, running_loss=0.7596, LR=0.000100
[2025-08-26 04:44:35,458][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034808] [Batch 00256/01234] [00:02:53/00:11:04, 0.679s/it]: train_loss_raw=0.7794, running_loss=0.7615, LR=0.000100
[2025-08-26 04:44:40,840][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034816] [Batch 00264/01234] [00:02:59/00:10:58, 0.679s/it]: train_loss_raw=0.7813, running_loss=0.7615, LR=0.000100
[2025-08-26 04:44:46,056][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034824] [Batch 00272/01234] [00:03:04/00:10:52, 0.678s/it]: train_loss_raw=0.7109, running_loss=0.7603, LR=0.000100
[2025-08-26 04:44:51,619][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034832] [Batch 00280/01234] [00:03:10/00:10:47, 0.679s/it]: train_loss_raw=0.7426, running_loss=0.7600, LR=0.000100
[2025-08-26 04:44:56,695][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034840] [Batch 00288/01234] [00:03:15/00:10:41, 0.678s/it]: train_loss_raw=0.8048, running_loss=0.7608, LR=0.000100
[2025-08-26 04:45:01,771][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034848] [Batch 00296/01234] [00:03:20/00:10:34, 0.677s/it]: train_loss_raw=0.7777, running_loss=0.7638, LR=0.000100
[2025-08-26 04:45:07,133][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034856] [Batch 00304/01234] [00:03:25/00:10:29, 0.676s/it]: train_loss_raw=0.7695, running_loss=0.7646, LR=0.000100
[2025-08-26 04:45:12,349][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034864] [Batch 00312/01234] [00:03:30/00:10:23, 0.676s/it]: train_loss_raw=0.7933, running_loss=0.7640, LR=0.000100
[2025-08-26 04:45:17,446][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034872] [Batch 00320/01234] [00:03:35/00:10:16, 0.675s/it]: train_loss_raw=0.8796, running_loss=0.7675, LR=0.000100
[2025-08-26 04:45:23,085][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034880] [Batch 00328/01234] [00:03:41/00:10:12, 0.676s/it]: train_loss_raw=0.7676, running_loss=0.7682, LR=0.000100
[2025-08-26 04:45:28,191][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034888] [Batch 00336/01234] [00:03:46/00:10:05, 0.675s/it]: train_loss_raw=0.7694, running_loss=0.7683, LR=0.000100
[2025-08-26 04:45:33,415][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034896] [Batch 00344/01234] [00:03:51/00:09:59, 0.674s/it]: train_loss_raw=0.8020, running_loss=0.7701, LR=0.000100
[2025-08-26 04:45:39,051][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034904] [Batch 00352/01234] [00:03:57/00:09:55, 0.675s/it]: train_loss_raw=0.7868, running_loss=0.7704, LR=0.000100
[2025-08-26 04:45:44,807][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034912] [Batch 00360/01234] [00:04:03/00:09:50, 0.676s/it]: train_loss_raw=0.7672, running_loss=0.7713, LR=0.000100
[2025-08-26 04:45:50,318][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034920] [Batch 00368/01234] [00:04:08/00:09:45, 0.676s/it]: train_loss_raw=0.7333, running_loss=0.7700, LR=0.000100
[2025-08-26 04:45:56,159][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034928] [Batch 00376/01234] [00:04:14/00:09:41, 0.677s/it]: train_loss_raw=0.7714, running_loss=0.7718, LR=0.000100
[2025-08-26 04:46:01,736][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034936] [Batch 00384/01234] [00:04:20/00:09:36, 0.678s/it]: train_loss_raw=0.8062, running_loss=0.7718, LR=0.000100
[2025-08-26 04:46:06,982][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034944] [Batch 00392/01234] [00:04:25/00:09:30, 0.677s/it]: train_loss_raw=0.8521, running_loss=0.7745, LR=0.000100
[2025-08-26 04:46:12,300][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034952] [Batch 00400/01234] [00:04:30/00:09:24, 0.677s/it]: train_loss_raw=0.7764, running_loss=0.7732, LR=0.000100
[2025-08-26 04:46:17,794][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034960] [Batch 00408/01234] [00:04:36/00:09:19, 0.677s/it]: train_loss_raw=0.7844, running_loss=0.7733, LR=0.000100
[2025-08-26 04:46:23,287][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034968] [Batch 00416/01234] [00:04:41/00:09:14, 0.677s/it]: train_loss_raw=0.7083, running_loss=0.7731, LR=0.000100
[2025-08-26 04:46:28,567][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034976] [Batch 00424/01234] [00:04:47/00:09:08, 0.677s/it]: train_loss_raw=0.8123, running_loss=0.7751, LR=0.000100
[2025-08-26 04:46:34,272][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034984] [Batch 00432/01234] [00:04:52/00:09:03, 0.678s/it]: train_loss_raw=0.8104, running_loss=0.7742, LR=0.000100
[2025-08-26 04:46:39,743][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 034992] [Batch 00440/01234] [00:04:58/00:08:58, 0.678s/it]: train_loss_raw=0.8078, running_loss=0.7767, LR=0.000100
[2025-08-26 04:46:44,824][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035000] [Batch 00448/01234] [00:05:03/00:08:52, 0.677s/it]: train_loss_raw=0.7822, running_loss=0.7773, LR=0.000100
[2025-08-26 04:46:49,882][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035008] [Batch 00456/01234] [00:05:08/00:08:46, 0.676s/it]: train_loss_raw=0.7790, running_loss=0.7774, LR=0.000100
[2025-08-26 04:46:54,932][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035016] [Batch 00464/01234] [00:05:13/00:08:40, 0.675s/it]: train_loss_raw=0.7984, running_loss=0.7761, LR=0.000100
[2025-08-26 04:47:00,063][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035024] [Batch 00472/01234] [00:05:18/00:08:34, 0.675s/it]: train_loss_raw=0.8492, running_loss=0.7770, LR=0.000100
[2025-08-26 04:47:05,518][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035032] [Batch 00480/01234] [00:05:24/00:08:28, 0.675s/it]: train_loss_raw=0.7973, running_loss=0.7777, LR=0.000100
[2025-08-26 04:47:11,088][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035040] [Batch 00488/01234] [00:05:29/00:08:23, 0.675s/it]: train_loss_raw=0.8099, running_loss=0.7792, LR=0.000100
[2025-08-26 04:47:16,522][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035048] [Batch 00496/01234] [00:05:35/00:08:18, 0.675s/it]: train_loss_raw=0.8912, running_loss=0.7817, LR=0.000100
[2025-08-26 04:47:22,216][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035056] [Batch 00504/01234] [00:05:40/00:08:13, 0.676s/it]: train_loss_raw=0.8011, running_loss=0.7827, LR=0.000100
[2025-08-26 04:47:27,368][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035064] [Batch 00512/01234] [00:05:45/00:08:07, 0.675s/it]: train_loss_raw=0.8274, running_loss=0.7820, LR=0.000100
[2025-08-26 04:47:32,459][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035072] [Batch 00520/01234] [00:05:50/00:08:01, 0.675s/it]: train_loss_raw=0.7992, running_loss=0.7829, LR=0.000100
[2025-08-26 04:47:37,804][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035080] [Batch 00528/01234] [00:05:56/00:07:56, 0.675s/it]: train_loss_raw=0.7983, running_loss=0.7831, LR=0.000100
[2025-08-26 04:47:42,979][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035088] [Batch 00536/01234] [00:06:01/00:07:50, 0.674s/it]: train_loss_raw=0.7610, running_loss=0.7832, LR=0.000100
[2025-08-26 04:47:48,091][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035096] [Batch 00544/01234] [00:06:06/00:07:44, 0.674s/it]: train_loss_raw=0.8528, running_loss=0.7855, LR=0.000100
[2025-08-26 04:47:53,711][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035104] [Batch 00552/01234] [00:06:12/00:07:39, 0.674s/it]: train_loss_raw=0.8589, running_loss=0.7886, LR=0.000100
[2025-08-26 04:47:58,974][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035112] [Batch 00560/01234] [00:06:17/00:07:34, 0.674s/it]: train_loss_raw=0.8290, running_loss=0.7892, LR=0.000100
[2025-08-26 04:48:04,148][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035120] [Batch 00568/01234] [00:06:22/00:07:28, 0.674s/it]: train_loss_raw=0.8041, running_loss=0.7877, LR=0.000100
[2025-08-26 04:48:09,737][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035128] [Batch 00576/01234] [00:06:28/00:07:23, 0.674s/it]: train_loss_raw=0.7722, running_loss=0.7885, LR=0.000100
[2025-08-26 04:48:15,327][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035136] [Batch 00584/01234] [00:06:33/00:07:18, 0.674s/it]: train_loss_raw=0.8040, running_loss=0.7916, LR=0.000100
[2025-08-26 04:48:20,684][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035144] [Batch 00592/01234] [00:06:39/00:07:12, 0.674s/it]: train_loss_raw=0.8473, running_loss=0.7930, LR=0.000100
[2025-08-26 04:48:26,090][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035152] [Batch 00600/01234] [00:06:44/00:07:07, 0.674s/it]: train_loss_raw=0.7732, running_loss=0.7930, LR=0.000100
[2025-08-26 04:48:31,311][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035160] [Batch 00608/01234] [00:06:49/00:07:01, 0.674s/it]: train_loss_raw=0.8276, running_loss=0.7937, LR=0.000100
[2025-08-26 04:48:36,710][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035168] [Batch 00616/01234] [00:06:55/00:06:56, 0.674s/it]: train_loss_raw=0.7748, running_loss=0.7941, LR=0.000100
[2025-08-26 04:48:41,989][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035176] [Batch 00624/01234] [00:07:00/00:06:51, 0.674s/it]: train_loss_raw=0.8645, running_loss=0.7968, LR=0.000100
[2025-08-26 04:48:47,140][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035184] [Batch 00632/01234] [00:07:05/00:06:45, 0.673s/it]: train_loss_raw=0.7900, running_loss=0.7993, LR=0.000100
[2025-08-26 04:48:52,242][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035192] [Batch 00640/01234] [00:07:10/00:06:39, 0.673s/it]: train_loss_raw=0.7817, running_loss=0.7994, LR=0.000100
[2025-08-26 04:48:57,659][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035200] [Batch 00648/01234] [00:07:16/00:06:34, 0.673s/it]: train_loss_raw=0.7830, running_loss=0.8005, LR=0.000100
[2025-08-26 04:49:02,939][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035208] [Batch 00656/01234] [00:07:21/00:06:28, 0.673s/it]: train_loss_raw=0.8169, running_loss=0.8017, LR=0.000100
[2025-08-26 04:49:08,462][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035216] [Batch 00664/01234] [00:07:26/00:06:23, 0.673s/it]: train_loss_raw=0.8084, running_loss=0.8011, LR=0.000100
[2025-08-26 04:49:13,930][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035224] [Batch 00672/01234] [00:07:32/00:06:18, 0.673s/it]: train_loss_raw=0.8469, running_loss=0.8003, LR=0.000100
[2025-08-26 04:49:19,529][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035232] [Batch 00680/01234] [00:07:38/00:06:13, 0.674s/it]: train_loss_raw=0.8446, running_loss=0.8016, LR=0.000100
[2025-08-26 04:49:25,095][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035240] [Batch 00688/01234] [00:07:43/00:06:07, 0.674s/it]: train_loss_raw=0.7559, running_loss=0.8021, LR=0.000100
[2025-08-26 04:49:30,898][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035248] [Batch 00696/01234] [00:07:49/00:06:02, 0.674s/it]: train_loss_raw=0.8034, running_loss=0.8017, LR=0.000100
[2025-08-26 04:49:36,635][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035256] [Batch 00704/01234] [00:07:55/00:05:57, 0.675s/it]: train_loss_raw=0.7776, running_loss=0.8008, LR=0.000100
[2025-08-26 04:49:42,386][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035264] [Batch 00712/01234] [00:08:00/00:05:52, 0.675s/it]: train_loss_raw=0.8210, running_loss=0.8006, LR=0.000100
[2025-08-26 04:49:48,242][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035272] [Batch 00720/01234] [00:08:06/00:05:47, 0.676s/it]: train_loss_raw=0.8506, running_loss=0.8006, LR=0.000100
[2025-08-26 04:49:53,950][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035280] [Batch 00728/01234] [00:08:12/00:05:42, 0.676s/it]: train_loss_raw=0.7726, running_loss=0.7990, LR=0.000100
[2025-08-26 04:49:58,993][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035288] [Batch 00736/01234] [00:08:17/00:05:36, 0.676s/it]: train_loss_raw=0.8350, running_loss=0.8003, LR=0.000100
[2025-08-26 04:50:04,372][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035296] [Batch 00744/01234] [00:08:22/00:05:31, 0.676s/it]: train_loss_raw=0.7449, running_loss=0.7982, LR=0.000100
[2025-08-26 04:50:10,167][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035304] [Batch 00752/01234] [00:08:28/00:05:26, 0.676s/it]: train_loss_raw=0.7811, running_loss=0.8008, LR=0.000100
[2025-08-26 04:50:15,232][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035312] [Batch 00760/01234] [00:08:33/00:05:20, 0.676s/it]: train_loss_raw=0.9102, running_loss=0.8045, LR=0.000100
[2025-08-26 04:50:20,490][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035320] [Batch 00768/01234] [00:08:38/00:05:14, 0.676s/it]: train_loss_raw=0.8884, running_loss=0.8052, LR=0.000100
[2025-08-26 04:50:26,088][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035328] [Batch 00776/01234] [00:08:44/00:05:09, 0.676s/it]: train_loss_raw=0.7844, running_loss=0.8045, LR=0.000100
[2025-08-26 04:50:31,186][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035336] [Batch 00784/01234] [00:08:49/00:05:04, 0.676s/it]: train_loss_raw=0.8321, running_loss=0.8053, LR=0.000100
[2025-08-26 04:50:36,266][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035344] [Batch 00792/01234] [00:08:54/00:04:58, 0.675s/it]: train_loss_raw=0.9096, running_loss=0.8059, LR=0.000100
[2025-08-26 04:50:41,366][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035352] [Batch 00800/01234] [00:08:59/00:04:52, 0.675s/it]: train_loss_raw=0.9276, running_loss=0.8060, LR=0.000100
[2025-08-26 04:50:46,468][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035360] [Batch 00808/01234] [00:09:04/00:04:47, 0.674s/it]: train_loss_raw=0.8256, running_loss=0.8072, LR=0.000100
[2025-08-26 04:50:51,832][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035368] [Batch 00816/01234] [00:09:10/00:04:41, 0.674s/it]: train_loss_raw=0.8374, running_loss=0.8082, LR=0.000100
[2025-08-26 04:50:57,072][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035376] [Batch 00824/01234] [00:09:15/00:04:36, 0.674s/it]: train_loss_raw=0.8232, running_loss=0.8080, LR=0.000100
[2025-08-26 04:51:02,510][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035384] [Batch 00832/01234] [00:09:20/00:04:31, 0.674s/it]: train_loss_raw=0.8261, running_loss=0.8106, LR=0.000100
[2025-08-26 04:51:08,055][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035392] [Batch 00840/01234] [00:09:26/00:04:25, 0.674s/it]: train_loss_raw=0.8524, running_loss=0.8120, LR=0.000100
[2025-08-26 04:51:13,547][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035400] [Batch 00848/01234] [00:09:32/00:04:20, 0.675s/it]: train_loss_raw=0.8760, running_loss=0.8098, LR=0.000100
[2025-08-26 04:51:18,693][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035408] [Batch 00856/01234] [00:09:37/00:04:14, 0.674s/it]: train_loss_raw=0.9564, running_loss=0.8129, LR=0.000100
[2025-08-26 04:51:24,052][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035416] [Batch 00864/01234] [00:09:42/00:04:09, 0.674s/it]: train_loss_raw=0.7607, running_loss=0.8136, LR=0.000100
[2025-08-26 04:51:29,252][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035424] [Batch 00872/01234] [00:09:47/00:04:03, 0.674s/it]: train_loss_raw=0.8163, running_loss=0.8139, LR=0.000100
[2025-08-26 04:51:34,514][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035432] [Batch 00880/01234] [00:09:52/00:03:58, 0.674s/it]: train_loss_raw=0.8374, running_loss=0.8130, LR=0.000100
[2025-08-26 04:51:39,890][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035440] [Batch 00888/01234] [00:09:58/00:03:53, 0.674s/it]: train_loss_raw=0.8611, running_loss=0.8126, LR=0.000100
[2025-08-26 04:51:45,143][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035448] [Batch 00896/01234] [00:10:03/00:03:47, 0.674s/it]: train_loss_raw=0.8673, running_loss=0.8130, LR=0.000100
[2025-08-26 04:51:50,702][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035456] [Batch 00904/01234] [00:10:09/00:03:42, 0.674s/it]: train_loss_raw=0.7490, running_loss=0.8133, LR=0.000100
[2025-08-26 04:51:56,015][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035464] [Batch 00912/01234] [00:10:14/00:03:36, 0.674s/it]: train_loss_raw=0.7850, running_loss=0.8133, LR=0.000100
[2025-08-26 04:52:01,297][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035472] [Batch 00920/01234] [00:10:19/00:03:31, 0.674s/it]: train_loss_raw=0.8123, running_loss=0.8113, LR=0.000100
[2025-08-26 04:52:07,121][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035480] [Batch 00928/01234] [00:10:25/00:03:26, 0.674s/it]: train_loss_raw=0.8564, running_loss=0.8130, LR=0.000100
[2025-08-26 04:52:12,725][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035488] [Batch 00936/01234] [00:10:31/00:03:20, 0.674s/it]: train_loss_raw=0.7988, running_loss=0.8126, LR=0.000100
[2025-08-26 04:52:17,831][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035496] [Batch 00944/01234] [00:10:36/00:03:15, 0.674s/it]: train_loss_raw=0.7413, running_loss=0.8146, LR=0.000100
[2025-08-26 04:52:23,559][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035504] [Batch 00952/01234] [00:10:42/00:03:10, 0.674s/it]: train_loss_raw=0.7988, running_loss=0.8150, LR=0.000100
[2025-08-26 04:52:29,226][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035512] [Batch 00960/01234] [00:10:47/00:03:04, 0.675s/it]: train_loss_raw=0.7889, running_loss=0.8157, LR=0.000100
[2025-08-26 04:52:34,706][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035520] [Batch 00968/01234] [00:10:53/00:02:59, 0.675s/it]: train_loss_raw=0.8893, running_loss=0.8160, LR=0.000100
[2025-08-26 04:52:40,411][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035528] [Batch 00976/01234] [00:10:58/00:02:54, 0.675s/it]: train_loss_raw=0.8165, running_loss=0.8161, LR=0.000100
[2025-08-26 04:52:46,188][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035536] [Batch 00984/01234] [00:11:04/00:02:48, 0.675s/it]: train_loss_raw=0.8199, running_loss=0.8167, LR=0.000100
[2025-08-26 04:52:51,530][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035544] [Batch 00992/01234] [00:11:10/00:02:43, 0.675s/it]: train_loss_raw=0.8077, running_loss=0.8192, LR=0.000100
[2025-08-26 04:52:56,937][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035552] [Batch 01000/01234] [00:11:15/00:02:38, 0.675s/it]: train_loss_raw=0.8694, running_loss=0.8192, LR=0.000100
[2025-08-26 04:53:02,355][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035560] [Batch 01008/01234] [00:11:20/00:02:32, 0.675s/it]: train_loss_raw=0.7061, running_loss=0.8184, LR=0.000100
[2025-08-26 04:53:07,990][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035568] [Batch 01016/01234] [00:11:26/00:02:27, 0.676s/it]: train_loss_raw=0.7963, running_loss=0.8175, LR=0.000100
[2025-08-26 04:53:13,663][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035576] [Batch 01024/01234] [00:11:32/00:02:21, 0.676s/it]: train_loss_raw=0.7968, running_loss=0.8157, LR=0.000100
[2025-08-26 04:53:18,890][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035584] [Batch 01032/01234] [00:11:37/00:02:16, 0.676s/it]: train_loss_raw=0.7639, running_loss=0.8149, LR=0.000100
[2025-08-26 04:53:24,195][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035592] [Batch 01040/01234] [00:11:42/00:02:11, 0.676s/it]: train_loss_raw=0.8197, running_loss=0.8164, LR=0.000100
[2025-08-26 04:53:29,290][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035600] [Batch 01048/01234] [00:11:47/00:02:05, 0.675s/it]: train_loss_raw=0.7945, running_loss=0.8154, LR=0.000100
[2025-08-26 04:53:34,573][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035608] [Batch 01056/01234] [00:11:53/00:02:00, 0.675s/it]: train_loss_raw=0.7742, running_loss=0.8160, LR=0.000100
[2025-08-26 04:53:40,447][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035616] [Batch 01064/01234] [00:11:58/00:01:54, 0.676s/it]: train_loss_raw=0.7713, running_loss=0.8148, LR=0.000100
[2025-08-26 04:53:46,003][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035624] [Batch 01072/01234] [00:12:04/00:01:49, 0.676s/it]: train_loss_raw=0.8123, running_loss=0.8156, LR=0.000100
[2025-08-26 04:53:51,178][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035632] [Batch 01080/01234] [00:12:09/00:01:44, 0.676s/it]: train_loss_raw=0.8549, running_loss=0.8167, LR=0.000100
[2025-08-26 04:53:57,026][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035640] [Batch 01088/01234] [00:12:15/00:01:38, 0.676s/it]: train_loss_raw=0.7612, running_loss=0.8159, LR=0.000100
[2025-08-26 04:54:02,838][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035648] [Batch 01096/01234] [00:12:21/00:01:33, 0.676s/it]: train_loss_raw=0.8031, running_loss=0.8154, LR=0.000100
[2025-08-26 04:54:08,925][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035656] [Batch 01104/01234] [00:12:27/00:01:28, 0.677s/it]: train_loss_raw=0.8684, running_loss=0.8153, LR=0.000100
[2025-08-26 04:54:14,687][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035664] [Batch 01112/01234] [00:12:33/00:01:22, 0.677s/it]: train_loss_raw=0.8156, running_loss=0.8141, LR=0.000100
[2025-08-26 04:54:20,208][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035672] [Batch 01120/01234] [00:12:38/00:01:17, 0.677s/it]: train_loss_raw=0.8688, running_loss=0.8123, LR=0.000100
[2025-08-26 04:54:25,384][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035680] [Batch 01128/01234] [00:12:43/00:01:11, 0.677s/it]: train_loss_raw=0.8680, running_loss=0.8142, LR=0.000100
[2025-08-26 04:54:31,296][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035688] [Batch 01136/01234] [00:12:49/00:01:06, 0.678s/it]: train_loss_raw=0.8887, running_loss=0.8152, LR=0.000100
[2025-08-26 04:54:36,983][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035696] [Batch 01144/01234] [00:12:55/00:01:01, 0.678s/it]: train_loss_raw=0.7730, running_loss=0.8155, LR=0.000100
[2025-08-26 04:54:42,414][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035704] [Batch 01152/01234] [00:13:00/00:00:55, 0.678s/it]: train_loss_raw=0.8298, running_loss=0.8162, LR=0.000100
[2025-08-26 04:54:47,848][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035712] [Batch 01160/01234] [00:13:06/00:00:50, 0.678s/it]: train_loss_raw=0.7833, running_loss=0.8162, LR=0.000100
[2025-08-26 04:54:52,998][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035720] [Batch 01168/01234] [00:13:11/00:00:44, 0.678s/it]: train_loss_raw=0.8191, running_loss=0.8156, LR=0.000100
[2025-08-26 04:54:58,827][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035728] [Batch 01176/01234] [00:13:17/00:00:39, 0.678s/it]: train_loss_raw=0.7467, running_loss=0.8141, LR=0.000100
[2025-08-26 04:55:04,401][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035736] [Batch 01184/01234] [00:13:22/00:00:33, 0.678s/it]: train_loss_raw=0.7274, running_loss=0.8145, LR=0.000100
[2025-08-26 04:55:09,919][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035744] [Batch 01192/01234] [00:13:28/00:00:28, 0.678s/it]: train_loss_raw=0.7817, running_loss=0.8136, LR=0.000100
[2025-08-26 04:55:15,486][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035752] [Batch 01200/01234] [00:13:33/00:00:23, 0.678s/it]: train_loss_raw=0.8813, running_loss=0.8148, LR=0.000100
[2025-08-26 04:55:21,403][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035760] [Batch 01208/01234] [00:13:39/00:00:17, 0.679s/it]: train_loss_raw=0.7569, running_loss=0.8141, LR=0.000100
[2025-08-26 04:55:27,089][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035768] [Batch 01216/01234] [00:13:45/00:00:12, 0.679s/it]: train_loss_raw=0.8154, running_loss=0.8166, LR=0.000100
[2025-08-26 04:55:32,622][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035776] [Batch 01224/01234] [00:13:51/00:00:06, 0.679s/it]: train_loss_raw=0.8834, running_loss=0.8193, LR=0.000100
[2025-08-26 04:55:38,239][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 035784] [Batch 01232/01234] [00:13:56/00:00:01, 0.679s/it]: train_loss_raw=0.7740, running_loss=0.8212, LR=0.000100
[2025-08-26 04:55:47,400][__main__][INFO] - [VALIDATION] [Epoch 28/29] Starting validation.
[2025-08-26 04:55:58,238][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 035787] [Batch 00007/00026] [00:00:10/00:00:24, 1.355s/it]
[2025-08-26 04:56:10,287][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 035787] [Batch 00015/00026] [00:00:22/00:00:14, 1.430s/it]
[2025-08-26 04:56:21,258][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 035787] [Batch 00023/00026] [00:00:33/00:00:02, 1.411s/it]
[2025-08-26 04:56:23,532][__main__][INFO] - [VALIDATION] [Epoch 28/29] train_loss=0.81912, valid_loss=1.76748
[2025-08-26 04:56:23,532][__main__][INFO] - [VALIDATION] [Epoch 28/29] Metrics:
[2025-08-26 04:56:23,532][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_er      0.590
[2025-08-26 04:56:23,532][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_prec    0.065
[2025-08-26 04:56:23,532][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_recall  0.065
[2025-08-26 04:56:23,533][__main__][INFO] - [VALIDATION] [Epoch 28/29] - pep_recall 0.026
[2025-08-26 04:56:23,534][__main__][INFO] - [TRAIN] [Epoch 28/29] Epoch complete, total time 07:05:32, remaining time 00:14:40, 00:14:40 per epoch
[2025-08-26 04:56:27,179][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035792] [Batch 00006/01234] [00:00:03/00:11:58, 0.585s/it]: train_loss_raw=0.6899, running_loss=0.8112, LR=0.000100
[2025-08-26 04:56:33,292][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035800] [Batch 00014/01234] [00:00:09/00:13:58, 0.687s/it]: train_loss_raw=0.7266, running_loss=0.8028, LR=0.000100
[2025-08-26 04:56:39,172][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035808] [Batch 00022/01234] [00:00:15/00:14:13, 0.705s/it]: train_loss_raw=0.6855, running_loss=0.7935, LR=0.000100
[2025-08-26 04:56:44,924][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035816] [Batch 00030/01234] [00:00:21/00:14:12, 0.708s/it]: train_loss_raw=0.7234, running_loss=0.7884, LR=0.000100
[2025-08-26 04:56:51,079][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035824] [Batch 00038/01234] [00:00:27/00:14:22, 0.721s/it]: train_loss_raw=0.7075, running_loss=0.7822, LR=0.000100
[2025-08-26 04:56:56,890][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035832] [Batch 00046/01234] [00:00:33/00:14:17, 0.722s/it]: train_loss_raw=0.6894, running_loss=0.7773, LR=0.000100
[2025-08-26 04:57:02,688][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035840] [Batch 00054/01234] [00:00:39/00:14:12, 0.723s/it]: train_loss_raw=0.7550, running_loss=0.7741, LR=0.000100
[2025-08-26 04:57:08,319][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035848] [Batch 00062/01234] [00:00:44/00:14:03, 0.720s/it]: train_loss_raw=0.7097, running_loss=0.7685, LR=0.000100
[2025-08-26 04:57:14,354][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035856] [Batch 00070/01234] [00:00:50/00:14:02, 0.724s/it]: train_loss_raw=0.7700, running_loss=0.7655, LR=0.000100
[2025-08-26 04:57:20,596][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035864] [Batch 00078/01234] [00:00:56/00:14:03, 0.730s/it]: train_loss_raw=0.6888, running_loss=0.7615, LR=0.000100
[2025-08-26 04:57:26,500][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035872] [Batch 00086/01234] [00:01:02/00:13:58, 0.731s/it]: train_loss_raw=0.7027, running_loss=0.7574, LR=0.000100
[2025-08-26 04:57:32,336][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035880] [Batch 00094/01234] [00:01:08/00:13:52, 0.730s/it]: train_loss_raw=0.7389, running_loss=0.7550, LR=0.000100
[2025-08-26 04:57:38,396][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035888] [Batch 00102/01234] [00:01:14/00:13:49, 0.733s/it]: train_loss_raw=0.6694, running_loss=0.7496, LR=0.000100
[2025-08-26 04:57:44,323][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035896] [Batch 00110/01234] [00:01:20/00:13:44, 0.733s/it]: train_loss_raw=0.7495, running_loss=0.7463, LR=0.000100
[2025-08-26 04:57:50,451][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035904] [Batch 00118/01234] [00:01:26/00:13:40, 0.735s/it]: train_loss_raw=0.6578, running_loss=0.7426, LR=0.000100
[2025-08-26 04:57:56,643][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035912] [Batch 00126/01234] [00:01:32/00:13:37, 0.738s/it]: train_loss_raw=0.6956, running_loss=0.7417, LR=0.000100
[2025-08-26 04:58:02,753][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035920] [Batch 00134/01234] [00:01:39/00:13:33, 0.739s/it]: train_loss_raw=0.6477, running_loss=0.7416, LR=0.000100
[2025-08-26 04:58:07,976][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035928] [Batch 00142/01234] [00:01:44/00:13:22, 0.735s/it]: train_loss_raw=0.7411, running_loss=0.7420, LR=0.000100
[2025-08-26 04:58:13,560][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035936] [Batch 00150/01234] [00:01:49/00:13:14, 0.733s/it]: train_loss_raw=0.6839, running_loss=0.7397, LR=0.000100
[2025-08-26 04:58:19,316][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035944] [Batch 00158/01234] [00:01:55/00:13:07, 0.732s/it]: train_loss_raw=0.6910, running_loss=0.7362, LR=0.000100
[2025-08-26 04:58:25,030][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035952] [Batch 00166/01234] [00:02:01/00:13:00, 0.731s/it]: train_loss_raw=0.7280, running_loss=0.7348, LR=0.000100
[2025-08-26 04:58:31,125][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035960] [Batch 00174/01234] [00:02:07/00:12:56, 0.732s/it]: train_loss_raw=0.6659, running_loss=0.7322, LR=0.000100
[2025-08-26 04:58:37,350][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035968] [Batch 00182/01234] [00:02:13/00:12:52, 0.734s/it]: train_loss_raw=0.7255, running_loss=0.7327, LR=0.000100
[2025-08-26 04:58:43,140][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035976] [Batch 00190/01234] [00:02:19/00:12:46, 0.734s/it]: train_loss_raw=0.6912, running_loss=0.7320, LR=0.000100
[2025-08-26 04:58:49,123][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035984] [Batch 00198/01234] [00:02:25/00:12:41, 0.735s/it]: train_loss_raw=0.6173, running_loss=0.7309, LR=0.000100
[2025-08-26 04:58:54,491][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 035992] [Batch 00206/01234] [00:02:30/00:12:32, 0.732s/it]: train_loss_raw=0.7650, running_loss=0.7316, LR=0.000100
[2025-08-26 04:58:59,803][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036000] [Batch 00214/01234] [00:02:36/00:12:24, 0.730s/it]: train_loss_raw=0.7977, running_loss=0.7330, LR=0.000100
[2025-08-26 04:59:08,521][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036008] [Batch 00222/01234] [00:02:44/00:12:31, 0.743s/it]: train_loss_raw=0.7890, running_loss=0.7354, LR=0.000100
[2025-08-26 04:59:14,378][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036016] [Batch 00230/01234] [00:02:50/00:12:25, 0.742s/it]: train_loss_raw=0.7458, running_loss=0.7342, LR=0.000100
[2025-08-26 04:59:19,865][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036024] [Batch 00238/01234] [00:02:56/00:12:17, 0.740s/it]: train_loss_raw=0.8093, running_loss=0.7338, LR=0.000100
[2025-08-26 04:59:25,473][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036032] [Batch 00246/01234] [00:03:01/00:12:10, 0.739s/it]: train_loss_raw=0.6690, running_loss=0.7305, LR=0.000100
[2025-08-26 04:59:30,553][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036040] [Batch 00254/01234] [00:03:06/00:12:01, 0.736s/it]: train_loss_raw=0.7154, running_loss=0.7310, LR=0.000100
[2025-08-26 04:59:36,055][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036048] [Batch 00262/01234] [00:03:12/00:11:53, 0.734s/it]: train_loss_raw=0.6451, running_loss=0.7297, LR=0.000100
[2025-08-26 04:59:41,600][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036056] [Batch 00270/01234] [00:03:17/00:11:46, 0.733s/it]: train_loss_raw=0.6538, running_loss=0.7281, LR=0.000100
[2025-08-26 04:59:47,335][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036064] [Batch 00278/01234] [00:03:23/00:11:40, 0.733s/it]: train_loss_raw=0.7316, running_loss=0.7272, LR=0.000100
[2025-08-26 04:59:52,875][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036072] [Batch 00286/01234] [00:03:29/00:11:33, 0.731s/it]: train_loss_raw=0.7355, running_loss=0.7259, LR=0.000100
[2025-08-26 04:59:58,687][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036080] [Batch 00294/01234] [00:03:35/00:11:27, 0.731s/it]: train_loss_raw=0.7799, running_loss=0.7249, LR=0.000100
[2025-08-26 05:00:04,295][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036088] [Batch 00302/01234] [00:03:40/00:11:20, 0.731s/it]: train_loss_raw=0.6831, running_loss=0.7249, LR=0.000100
[2025-08-26 05:00:09,394][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036096] [Batch 00310/01234] [00:03:45/00:11:12, 0.728s/it]: train_loss_raw=0.8676, running_loss=0.7288, LR=0.000100
[2025-08-26 05:00:14,506][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036104] [Batch 00318/01234] [00:03:50/00:11:04, 0.726s/it]: train_loss_raw=0.7588, running_loss=0.7290, LR=0.000100
[2025-08-26 05:00:19,641][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036112] [Batch 00326/01234] [00:03:55/00:10:57, 0.724s/it]: train_loss_raw=0.7902, running_loss=0.7314, LR=0.000100
[2025-08-26 05:00:25,146][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036120] [Batch 00334/01234] [00:04:01/00:10:50, 0.723s/it]: train_loss_raw=0.6933, running_loss=0.7307, LR=0.000100
[2025-08-26 05:00:30,378][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036128] [Batch 00342/01234] [00:04:06/00:10:43, 0.721s/it]: train_loss_raw=0.7205, running_loss=0.7306, LR=0.000100
[2025-08-26 05:00:35,885][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036136] [Batch 00350/01234] [00:04:12/00:10:37, 0.721s/it]: train_loss_raw=0.7557, running_loss=0.7337, LR=0.000100
[2025-08-26 05:00:41,302][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036144] [Batch 00358/01234] [00:04:17/00:10:30, 0.720s/it]: train_loss_raw=0.7055, running_loss=0.7338, LR=0.000100
[2025-08-26 05:00:46,477][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036152] [Batch 00366/01234] [00:04:22/00:10:23, 0.718s/it]: train_loss_raw=0.7669, running_loss=0.7351, LR=0.000100
[2025-08-26 05:00:51,553][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036160] [Batch 00374/01234] [00:04:27/00:10:15, 0.716s/it]: train_loss_raw=0.7845, running_loss=0.7336, LR=0.000100
[2025-08-26 05:00:56,641][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036168] [Batch 00382/01234] [00:04:32/00:10:08, 0.715s/it]: train_loss_raw=0.7070, running_loss=0.7338, LR=0.000100
[2025-08-26 05:01:01,928][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036176] [Batch 00390/01234] [00:04:38/00:10:02, 0.713s/it]: train_loss_raw=0.7122, running_loss=0.7341, LR=0.000100
[2025-08-26 05:01:07,120][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036184] [Batch 00398/01234] [00:04:43/00:09:55, 0.712s/it]: train_loss_raw=0.7706, running_loss=0.7330, LR=0.000100
[2025-08-26 05:01:12,948][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036192] [Batch 00406/01234] [00:04:49/00:09:49, 0.713s/it]: train_loss_raw=0.7215, running_loss=0.7341, LR=0.000100
[2025-08-26 05:01:18,658][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036200] [Batch 00414/01234] [00:04:54/00:09:44, 0.713s/it]: train_loss_raw=0.7493, running_loss=0.7340, LR=0.000100
[2025-08-26 05:01:24,437][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036208] [Batch 00422/01234] [00:05:00/00:09:38, 0.713s/it]: train_loss_raw=0.8273, running_loss=0.7351, LR=0.000100
[2025-08-26 05:01:29,969][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036216] [Batch 00430/01234] [00:05:06/00:09:32, 0.712s/it]: train_loss_raw=0.7091, running_loss=0.7360, LR=0.000100
[2025-08-26 05:01:35,533][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036224] [Batch 00438/01234] [00:05:11/00:09:26, 0.712s/it]: train_loss_raw=0.7135, running_loss=0.7358, LR=0.000100
[2025-08-26 05:01:41,326][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036232] [Batch 00446/01234] [00:05:17/00:09:21, 0.712s/it]: train_loss_raw=0.7806, running_loss=0.7382, LR=0.000100
[2025-08-26 05:01:47,011][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036240] [Batch 00454/01234] [00:05:23/00:09:15, 0.712s/it]: train_loss_raw=0.7136, running_loss=0.7401, LR=0.000100
[2025-08-26 05:01:52,110][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036248] [Batch 00462/01234] [00:05:28/00:09:08, 0.711s/it]: train_loss_raw=0.6986, running_loss=0.7419, LR=0.000100
[2025-08-26 05:01:57,765][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036256] [Batch 00470/01234] [00:05:34/00:09:03, 0.711s/it]: train_loss_raw=0.7328, running_loss=0.7434, LR=0.000100
[2025-08-26 05:02:03,666][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036264] [Batch 00478/01234] [00:05:39/00:08:57, 0.711s/it]: train_loss_raw=0.8246, running_loss=0.7433, LR=0.000100
[2025-08-26 05:02:09,564][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036272] [Batch 00486/01234] [00:05:45/00:08:52, 0.712s/it]: train_loss_raw=0.8211, running_loss=0.7450, LR=0.000100
[2025-08-26 05:02:15,237][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036280] [Batch 00494/01234] [00:05:51/00:08:46, 0.712s/it]: train_loss_raw=0.7639, running_loss=0.7472, LR=0.000100
[2025-08-26 05:02:20,656][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036288] [Batch 00502/01234] [00:05:56/00:08:40, 0.711s/it]: train_loss_raw=0.7208, running_loss=0.7484, LR=0.000100
[2025-08-26 05:02:26,358][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036296] [Batch 00510/01234] [00:06:02/00:08:34, 0.711s/it]: train_loss_raw=0.8077, running_loss=0.7513, LR=0.000100
[2025-08-26 05:02:31,544][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036304] [Batch 00518/01234] [00:06:07/00:08:28, 0.710s/it]: train_loss_raw=0.7633, running_loss=0.7519, LR=0.000100
[2025-08-26 05:02:37,322][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036312] [Batch 00526/01234] [00:06:13/00:08:22, 0.710s/it]: train_loss_raw=0.8174, running_loss=0.7515, LR=0.000100
[2025-08-26 05:02:42,925][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036320] [Batch 00534/01234] [00:06:19/00:08:17, 0.710s/it]: train_loss_raw=0.7295, running_loss=0.7519, LR=0.000100
[2025-08-26 05:02:48,949][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036328] [Batch 00542/01234] [00:06:25/00:08:11, 0.711s/it]: train_loss_raw=0.7729, running_loss=0.7526, LR=0.000100
[2025-08-26 05:02:54,886][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036336] [Batch 00550/01234] [00:06:31/00:08:06, 0.711s/it]: train_loss_raw=0.6987, running_loss=0.7523, LR=0.000100
[2025-08-26 05:03:00,615][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036344] [Batch 00558/01234] [00:06:36/00:08:00, 0.711s/it]: train_loss_raw=0.7579, running_loss=0.7522, LR=0.000100
[2025-08-26 05:03:05,832][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036352] [Batch 00566/01234] [00:06:42/00:07:54, 0.711s/it]: train_loss_raw=0.8518, running_loss=0.7521, LR=0.000100
[2025-08-26 05:03:10,940][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036360] [Batch 00574/01234] [00:06:47/00:07:48, 0.710s/it]: train_loss_raw=0.7444, running_loss=0.7518, LR=0.000100
[2025-08-26 05:03:16,685][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036368] [Batch 00582/01234] [00:06:53/00:07:42, 0.710s/it]: train_loss_raw=0.7544, running_loss=0.7526, LR=0.000100
[2025-08-26 05:03:21,941][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036376] [Batch 00590/01234] [00:06:58/00:07:36, 0.709s/it]: train_loss_raw=0.6739, running_loss=0.7522, LR=0.000100
[2025-08-26 05:03:27,097][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036384] [Batch 00598/01234] [00:07:03/00:07:30, 0.708s/it]: train_loss_raw=0.8244, running_loss=0.7544, LR=0.000100
[2025-08-26 05:03:32,539][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036392] [Batch 00606/01234] [00:07:08/00:07:24, 0.708s/it]: train_loss_raw=0.6643, running_loss=0.7543, LR=0.000100
[2025-08-26 05:03:37,835][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036400] [Batch 00614/01234] [00:07:14/00:07:18, 0.707s/it]: train_loss_raw=0.7249, running_loss=0.7555, LR=0.000100
[2025-08-26 05:03:43,709][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036408] [Batch 00622/01234] [00:07:20/00:07:12, 0.707s/it]: train_loss_raw=0.7794, running_loss=0.7538, LR=0.000100
[2025-08-26 05:03:49,445][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036416] [Batch 00630/01234] [00:07:25/00:07:07, 0.708s/it]: train_loss_raw=0.7558, running_loss=0.7551, LR=0.000100
[2025-08-26 05:03:54,664][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036424] [Batch 00638/01234] [00:07:30/00:07:01, 0.707s/it]: train_loss_raw=0.7747, running_loss=0.7573, LR=0.000100
[2025-08-26 05:03:59,820][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036432] [Batch 00646/01234] [00:07:36/00:06:55, 0.706s/it]: train_loss_raw=0.7655, running_loss=0.7570, LR=0.000100
[2025-08-26 05:04:04,977][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036440] [Batch 00654/01234] [00:07:41/00:06:49, 0.705s/it]: train_loss_raw=0.7596, running_loss=0.7580, LR=0.000100
[2025-08-26 05:04:10,208][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036448] [Batch 00662/01234] [00:07:46/00:06:43, 0.705s/it]: train_loss_raw=0.7468, running_loss=0.7597, LR=0.000100
[2025-08-26 05:04:15,570][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036456] [Batch 00670/01234] [00:07:51/00:06:37, 0.704s/it]: train_loss_raw=0.7970, running_loss=0.7596, LR=0.000100
[2025-08-26 05:04:20,981][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036464] [Batch 00678/01234] [00:07:57/00:06:31, 0.704s/it]: train_loss_raw=0.6940, running_loss=0.7582, LR=0.000100
[2025-08-26 05:04:26,343][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036472] [Batch 00686/01234] [00:08:02/00:06:25, 0.704s/it]: train_loss_raw=0.7973, running_loss=0.7599, LR=0.000100
[2025-08-26 05:04:31,444][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036480] [Batch 00694/01234] [00:08:07/00:06:19, 0.703s/it]: train_loss_raw=0.7688, running_loss=0.7619, LR=0.000100
[2025-08-26 05:04:36,521][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036488] [Batch 00702/01234] [00:08:12/00:06:13, 0.702s/it]: train_loss_raw=0.7851, running_loss=0.7628, LR=0.000100
[2025-08-26 05:04:42,229][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036496] [Batch 00710/01234] [00:08:18/00:06:07, 0.702s/it]: train_loss_raw=0.7079, running_loss=0.7624, LR=0.000100
[2025-08-26 05:04:47,305][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036504] [Batch 00718/01234] [00:08:23/00:06:01, 0.701s/it]: train_loss_raw=0.7120, running_loss=0.7619, LR=0.000100
[2025-08-26 05:04:52,423][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036512] [Batch 00726/01234] [00:08:28/00:05:55, 0.701s/it]: train_loss_raw=0.7300, running_loss=0.7619, LR=0.000100
[2025-08-26 05:04:57,506][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036520] [Batch 00734/01234] [00:08:33/00:05:50, 0.700s/it]: train_loss_raw=0.7363, running_loss=0.7643, LR=0.000100
[2025-08-26 05:05:02,602][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036528] [Batch 00742/01234] [00:08:38/00:05:44, 0.699s/it]: train_loss_raw=0.7721, running_loss=0.7648, LR=0.000100
[2025-08-26 05:05:07,751][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036536] [Batch 00750/01234] [00:08:44/00:05:38, 0.699s/it]: train_loss_raw=0.7983, running_loss=0.7651, LR=0.000100
[2025-08-26 05:05:13,179][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036544] [Batch 00758/01234] [00:08:49/00:05:32, 0.699s/it]: train_loss_raw=0.7694, running_loss=0.7655, LR=0.000100
[2025-08-26 05:05:18,389][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036552] [Batch 00766/01234] [00:08:54/00:05:26, 0.698s/it]: train_loss_raw=0.8349, running_loss=0.7673, LR=0.000100
[2025-08-26 05:05:23,638][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036560] [Batch 00774/01234] [00:08:59/00:05:20, 0.698s/it]: train_loss_raw=0.7769, running_loss=0.7675, LR=0.000100
[2025-08-26 05:05:29,044][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036568] [Batch 00782/01234] [00:09:05/00:05:15, 0.697s/it]: train_loss_raw=0.7445, running_loss=0.7674, LR=0.000100
[2025-08-26 05:05:34,383][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036576] [Batch 00790/01234] [00:09:10/00:05:09, 0.697s/it]: train_loss_raw=0.7561, running_loss=0.7678, LR=0.000100
[2025-08-26 05:05:40,017][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036584] [Batch 00798/01234] [00:09:16/00:05:03, 0.697s/it]: train_loss_raw=0.7815, running_loss=0.7681, LR=0.000100
[2025-08-26 05:05:45,685][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036592] [Batch 00806/01234] [00:09:22/00:04:58, 0.697s/it]: train_loss_raw=0.7593, running_loss=0.7682, LR=0.000100
[2025-08-26 05:05:51,676][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036600] [Batch 00814/01234] [00:09:28/00:04:53, 0.698s/it]: train_loss_raw=0.7410, running_loss=0.7678, LR=0.000100
[2025-08-26 05:05:57,815][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036608] [Batch 00822/01234] [00:09:34/00:04:47, 0.698s/it]: train_loss_raw=0.8134, running_loss=0.7698, LR=0.000100
[2025-08-26 05:06:04,072][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036616] [Batch 00830/01234] [00:09:40/00:04:42, 0.699s/it]: train_loss_raw=0.8007, running_loss=0.7717, LR=0.000100
[2025-08-26 05:06:09,744][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036624] [Batch 00838/01234] [00:09:46/00:04:36, 0.699s/it]: train_loss_raw=0.7225, running_loss=0.7716, LR=0.000100
[2025-08-26 05:06:15,528][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036632] [Batch 00846/01234] [00:09:51/00:04:31, 0.700s/it]: train_loss_raw=0.7563, running_loss=0.7718, LR=0.000100
[2025-08-26 05:06:20,913][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036640] [Batch 00854/01234] [00:09:57/00:04:25, 0.699s/it]: train_loss_raw=0.7689, running_loss=0.7719, LR=0.000100
[2025-08-26 05:06:25,966][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036648] [Batch 00862/01234] [00:10:02/00:04:19, 0.699s/it]: train_loss_raw=0.7774, running_loss=0.7725, LR=0.000100
[2025-08-26 05:06:31,257][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036656] [Batch 00870/01234] [00:10:07/00:04:14, 0.698s/it]: train_loss_raw=0.7047, running_loss=0.7730, LR=0.000100
[2025-08-26 05:06:36,372][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036664] [Batch 00878/01234] [00:10:12/00:04:08, 0.698s/it]: train_loss_raw=0.8271, running_loss=0.7749, LR=0.000100
[2025-08-26 05:06:41,872][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036672] [Batch 00886/01234] [00:10:18/00:04:02, 0.698s/it]: train_loss_raw=0.7375, running_loss=0.7745, LR=0.000100
[2025-08-26 05:06:46,960][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036680] [Batch 00894/01234] [00:10:23/00:03:57, 0.697s/it]: train_loss_raw=0.8277, running_loss=0.7772, LR=0.000100
[2025-08-26 05:06:52,447][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036688] [Batch 00902/01234] [00:10:28/00:03:51, 0.697s/it]: train_loss_raw=0.7424, running_loss=0.7783, LR=0.000100
[2025-08-26 05:06:57,988][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036696] [Batch 00910/01234] [00:10:34/00:03:45, 0.697s/it]: train_loss_raw=0.7752, running_loss=0.7777, LR=0.000100
[2025-08-26 05:07:03,884][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036704] [Batch 00918/01234] [00:10:40/00:03:40, 0.697s/it]: train_loss_raw=0.7619, running_loss=0.7773, LR=0.000100
[2025-08-26 05:07:09,191][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036712] [Batch 00926/01234] [00:10:45/00:03:34, 0.697s/it]: train_loss_raw=0.7596, running_loss=0.7768, LR=0.000100
[2025-08-26 05:07:14,979][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036720] [Batch 00934/01234] [00:10:51/00:03:29, 0.697s/it]: train_loss_raw=0.7879, running_loss=0.7798, LR=0.000100
[2025-08-26 05:07:20,647][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036728] [Batch 00942/01234] [00:10:56/00:03:23, 0.697s/it]: train_loss_raw=0.7198, running_loss=0.7806, LR=0.000100
[2025-08-26 05:07:25,968][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036736] [Batch 00950/01234] [00:11:02/00:03:17, 0.697s/it]: train_loss_raw=0.7593, running_loss=0.7800, LR=0.000100
[2025-08-26 05:07:31,253][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036744] [Batch 00958/01234] [00:11:07/00:03:12, 0.697s/it]: train_loss_raw=0.8519, running_loss=0.7805, LR=0.000100
[2025-08-26 05:07:36,786][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036752] [Batch 00966/01234] [00:11:13/00:03:06, 0.697s/it]: train_loss_raw=0.6922, running_loss=0.7778, LR=0.000100
[2025-08-26 05:07:42,345][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036760] [Batch 00974/01234] [00:11:18/00:03:01, 0.697s/it]: train_loss_raw=0.7352, running_loss=0.7781, LR=0.000100
[2025-08-26 05:07:48,095][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036768] [Batch 00982/01234] [00:11:24/00:02:55, 0.697s/it]: train_loss_raw=0.7653, running_loss=0.7804, LR=0.000100
[2025-08-26 05:07:53,541][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036776] [Batch 00990/01234] [00:11:29/00:02:50, 0.697s/it]: train_loss_raw=0.7701, running_loss=0.7773, LR=0.000100
[2025-08-26 05:07:59,028][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036784] [Batch 00998/01234] [00:11:35/00:02:44, 0.697s/it]: train_loss_raw=0.7649, running_loss=0.7775, LR=0.000100
[2025-08-26 05:08:04,559][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036792] [Batch 01006/01234] [00:11:40/00:02:38, 0.697s/it]: train_loss_raw=0.7651, running_loss=0.7764, LR=0.000100
[2025-08-26 05:08:09,735][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036800] [Batch 01014/01234] [00:11:46/00:02:33, 0.696s/it]: train_loss_raw=0.7452, running_loss=0.7777, LR=0.000100
[2025-08-26 05:08:15,346][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036808] [Batch 01022/01234] [00:11:51/00:02:27, 0.696s/it]: train_loss_raw=0.8023, running_loss=0.7791, LR=0.000100
[2025-08-26 05:08:20,600][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036816] [Batch 01030/01234] [00:11:56/00:02:21, 0.696s/it]: train_loss_raw=0.8386, running_loss=0.7800, LR=0.000100
[2025-08-26 05:08:26,047][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036824] [Batch 01038/01234] [00:12:02/00:02:16, 0.696s/it]: train_loss_raw=0.7909, running_loss=0.7802, LR=0.000100
[2025-08-26 05:08:31,159][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036832] [Batch 01046/01234] [00:12:07/00:02:10, 0.695s/it]: train_loss_raw=0.7554, running_loss=0.7817, LR=0.000100
[2025-08-26 05:08:36,558][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036840] [Batch 01054/01234] [00:12:12/00:02:05, 0.695s/it]: train_loss_raw=0.8181, running_loss=0.7813, LR=0.000100
[2025-08-26 05:08:41,948][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036848] [Batch 01062/01234] [00:12:18/00:01:59, 0.695s/it]: train_loss_raw=0.7028, running_loss=0.7817, LR=0.000100
[2025-08-26 05:08:47,439][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036856] [Batch 01070/01234] [00:12:23/00:01:53, 0.695s/it]: train_loss_raw=0.7990, running_loss=0.7822, LR=0.000100
[2025-08-26 05:08:52,499][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036864] [Batch 01078/01234] [00:12:28/00:01:48, 0.695s/it]: train_loss_raw=0.7905, running_loss=0.7835, LR=0.000100
[2025-08-26 05:08:57,576][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036872] [Batch 01086/01234] [00:12:33/00:01:42, 0.694s/it]: train_loss_raw=0.8423, running_loss=0.7842, LR=0.000100
[2025-08-26 05:09:02,937][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036880] [Batch 01094/01234] [00:12:39/00:01:37, 0.694s/it]: train_loss_raw=0.7343, running_loss=0.7823, LR=0.000100
[2025-08-26 05:09:08,590][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036888] [Batch 01102/01234] [00:12:44/00:01:31, 0.694s/it]: train_loss_raw=0.8037, running_loss=0.7827, LR=0.000100
[2025-08-26 05:09:13,767][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036896] [Batch 01110/01234] [00:12:50/00:01:26, 0.694s/it]: train_loss_raw=0.6681, running_loss=0.7822, LR=0.000100
[2025-08-26 05:09:19,567][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036904] [Batch 01118/01234] [00:12:55/00:01:20, 0.694s/it]: train_loss_raw=0.8614, running_loss=0.7836, LR=0.000100
[2025-08-26 05:09:25,399][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036912] [Batch 01126/01234] [00:13:01/00:01:14, 0.694s/it]: train_loss_raw=0.8450, running_loss=0.7861, LR=0.000100
[2025-08-26 05:09:30,742][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036920] [Batch 01134/01234] [00:13:07/00:01:09, 0.694s/it]: train_loss_raw=0.7603, running_loss=0.7883, LR=0.000100
[2025-08-26 05:09:35,836][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036928] [Batch 01142/01234] [00:13:12/00:01:03, 0.694s/it]: train_loss_raw=0.8818, running_loss=0.7864, LR=0.000100
[2025-08-26 05:09:41,643][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036936] [Batch 01150/01234] [00:13:17/00:00:58, 0.694s/it]: train_loss_raw=0.8120, running_loss=0.7848, LR=0.000100
[2025-08-26 05:09:47,365][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036944] [Batch 01158/01234] [00:13:23/00:00:52, 0.694s/it]: train_loss_raw=0.8636, running_loss=0.7851, LR=0.000100
[2025-08-26 05:09:53,332][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036952] [Batch 01166/01234] [00:13:29/00:00:47, 0.694s/it]: train_loss_raw=0.8072, running_loss=0.7856, LR=0.000100
[2025-08-26 05:09:59,112][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036960] [Batch 01174/01234] [00:13:35/00:00:41, 0.695s/it]: train_loss_raw=0.7680, running_loss=0.7878, LR=0.000100
[2025-08-26 05:10:04,530][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036968] [Batch 01182/01234] [00:13:40/00:00:36, 0.694s/it]: train_loss_raw=0.8367, running_loss=0.7874, LR=0.000100
[2025-08-26 05:10:09,667][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036976] [Batch 01190/01234] [00:13:45/00:00:30, 0.694s/it]: train_loss_raw=0.7909, running_loss=0.7876, LR=0.000100
[2025-08-26 05:10:15,255][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036984] [Batch 01198/01234] [00:13:51/00:00:24, 0.694s/it]: train_loss_raw=0.8681, running_loss=0.7890, LR=0.000100
[2025-08-26 05:10:20,562][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 036992] [Batch 01206/01234] [00:13:56/00:00:19, 0.694s/it]: train_loss_raw=0.8426, running_loss=0.7885, LR=0.000100
[2025-08-26 05:10:25,635][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 037000] [Batch 01214/01234] [00:14:01/00:00:13, 0.694s/it]: train_loss_raw=0.8119, running_loss=0.7912, LR=0.000100
[2025-08-26 05:10:31,161][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 037008] [Batch 01222/01234] [00:14:07/00:00:08, 0.694s/it]: train_loss_raw=0.7432, running_loss=0.7907, LR=0.000100
[2025-08-26 05:10:36,860][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 037016] [Batch 01230/01234] [00:14:13/00:00:02, 0.694s/it]: train_loss_raw=0.8375, running_loss=0.7907, LR=0.000100
[2025-08-26 05:10:46,277][__main__][INFO] - [VALIDATION] [Epoch 29/29] Starting validation.
[2025-08-26 05:10:56,386][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 037021] [Batch 00007/00026] [00:00:10/00:00:22, 1.264s/it]
[2025-08-26 05:11:06,753][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 037021] [Batch 00015/00026] [00:00:20/00:00:12, 1.280s/it]
[2025-08-26 05:11:17,142][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 037021] [Batch 00023/00026] [00:00:30/00:00:02, 1.286s/it]
[2025-08-26 05:11:19,394][__main__][INFO] - [VALIDATION] [Epoch 29/29] train_loss=0.78857, valid_loss=1.81211
[2025-08-26 05:11:19,395][__main__][INFO] - [VALIDATION] [Epoch 29/29] Metrics:
[2025-08-26 05:11:19,395][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_er      0.587
[2025-08-26 05:11:19,395][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_prec    0.065
[2025-08-26 05:11:19,395][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_recall  0.065
[2025-08-26 05:11:19,395][__main__][INFO] - [VALIDATION] [Epoch 29/29] - pep_recall 0.026
[2025-08-26 05:11:19,396][__main__][INFO] - [TRAIN] [Epoch 29/29] Epoch complete, total time 07:20:28, remaining time 00:00:00, 00:14:40 per epoch
[2025-08-26 05:11:20,488][__main__][INFO] - InstaNovo training finished.
