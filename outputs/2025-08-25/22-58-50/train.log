[2025-08-25 22:58:50,402][__main__][INFO] - Initializing training.
[2025-08-25 22:58:50,402][__main__][INFO] - Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
[2025-08-25 22:58:50,402][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-25 22:58:50,402][__main__][INFO] - CUDA version: 12.1
[2025-08-25 22:58:50,406][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/1461_high/*.parquet
profiler: false
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: 600k_allengry_192BS
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 192
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
train_subset: 0.75
valid_subset_of_train: 0.01
valid_subset: 1
val_check_interval: 1.0
lazy_loading: true
max_shard_size: 1000000
preshuffle_shards: false
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
resume_checkpoint: null
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-25 22:58:50,411][__main__][INFO] - Starting transformer training
[2025-08-25 22:58:50,411][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-25 22:58:50,411][__main__][INFO] - Loading data
[2025-08-25 22:59:05,992][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-25 22:59:19,989][__main__][INFO] - Validation path not specified, generating from training set.
[2025-08-25 23:00:36,309][__main__][INFO] - Data splits saved to /data/48/wuqian/fast/TipsNovo/model_save/splits.csv
[2025-08-25 23:00:36,309][__main__][INFO] - Checking for unknown residues in 1,262,032 rows.
[2025-08-25 23:00:39,240][__main__][WARNING] - Unsupported residues found in evaluation set! These rows will be dropped.
[2025-08-25 23:00:39,240][__main__][INFO] - New residues found: 
{'O'}
[2025-08-25 23:00:39,241][__main__][INFO] - Residues supported: 
{'E', 'Q[UNIMOD:7]', 'Y[UNIMOD:21]', 'H', '[EOS]', 'K', 'V', 'P', 'A', '[UNIMOD:5]', 'S', 'I', 'C[UNIMOD:4]', '[UNIMOD:385]', 'S[UNIMOD:21]', '[UNIMOD:1]', 'D', 'T[UNIMOD:21]', 'N', 'Q', 'L', 'N[UNIMOD:7]', 'T', 'M[UNIMOD:35]', '[PAD]', '[SOS]', 'Y', 'W', 'C', 'G', 'R', 'F', 'M'}
[2025-08-25 23:02:01,688][__main__][WARNING] - 1 (0.00%) training rows dropped.
[2025-08-25 23:02:01,688][__main__][WARNING] - 0 (0.00%) validation rows dropped.
[2025-08-25 23:03:25,465][__main__][INFO] - Data loaded: 934,714 training samples; 15,772 validation samples
[2025-08-25 23:03:25,871][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-25 23:03:25,905][__main__][INFO] - No data leakage!
[2025-08-25 23:03:25,906][__main__][INFO] - Model checkpointing every 0.41 epochs.
[2025-08-25 23:03:25,906][__main__][INFO] - Updates per epoch: 4,869, step_scale=0.16666666666666666
[2025-08-25 23:03:50,459][__main__][INFO] - Sample batch:
[2025-08-25 23:03:50,459][__main__][INFO] -  - spectra.shape=torch.Size([192, 200, 2])
[2025-08-25 23:03:50,459][__main__][INFO] -  - precursors.shape=torch.Size([192, 3])
[2025-08-25 23:03:50,459][__main__][INFO] -  - spectra_mask.shape=torch.Size([192, 200])
[2025-08-25 23:03:50,459][__main__][INFO] -  - peptides.shape=torch.Size([192, 41])
[2025-08-25 23:03:50,459][__main__][INFO] -  - peptides_mask.shape=torch.Size([192, 41])
[2025-08-25 23:03:50,606][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-25 23:03:50,606][__main__][INFO] - Test forward pass:
[2025-08-25 23:04:00,197][__main__][INFO] -  - y.shape=torch.Size([192, 42, 33])
[2025-08-25 23:04:01,103][__main__][INFO] - Model saving enabled
[2025-08-25 23:04:01,103][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save/
[2025-08-25 23:04:01,103][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-25 23:04:01,110][__main__][INFO] - InstaNovo training started.
[2025-08-25 23:04:06,345][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-25 23:04:17,189][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 000001] [Batch 00007/00124] [00:00:10/00:02:37, 1.355s/it]
[2025-08-25 23:04:25,423][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000008] [Batch 00008/04869] [00:00:05/00:55:11, 0.681s/it]: train_loss_raw=3.4811, running_loss=3.6086, LR=0.000001
[2025-08-25 23:04:31,338][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000016] [Batch 00016/04869] [00:00:11/00:57:27, 0.710s/it]: train_loss_raw=3.1981, running_loss=3.5871, LR=0.000003
[2025-08-25 23:04:37,336][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/04869] [00:00:17/00:58:25, 0.723s/it]: train_loss_raw=3.0773, running_loss=3.5505, LR=0.000005
[2025-08-25 23:04:42,968][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000032] [Batch 00032/04869] [00:00:22/00:57:55, 0.719s/it]: train_loss_raw=2.9817, running_loss=3.5091, LR=0.000006
[2025-08-25 23:04:48,475][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000040] [Batch 00040/04869] [00:00:28/00:57:20, 0.713s/it]: train_loss_raw=2.9748, running_loss=3.4682, LR=0.000008
[2025-08-25 23:04:54,007][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/04869] [00:00:34/00:56:58, 0.709s/it]: train_loss_raw=2.9527, running_loss=3.4287, LR=0.000010
[2025-08-25 23:04:59,912][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000056] [Batch 00056/04869] [00:00:39/00:57:12, 0.713s/it]: train_loss_raw=2.9070, running_loss=3.3900, LR=0.000011
[2025-08-25 23:05:05,508][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000064] [Batch 00064/04869] [00:00:45/00:56:58, 0.711s/it]: train_loss_raw=2.8452, running_loss=3.3504, LR=0.000013
[2025-08-25 23:05:10,767][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/04869] [00:00:50/00:56:24, 0.705s/it]: train_loss_raw=2.7872, running_loss=3.3092, LR=0.000015
[2025-08-25 23:05:16,512][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000080] [Batch 00080/04869] [00:00:56/00:56:24, 0.707s/it]: train_loss_raw=2.7590, running_loss=3.2672, LR=0.000016
[2025-08-25 23:05:21,700][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000088] [Batch 00088/04869] [00:01:01/00:55:53, 0.701s/it]: train_loss_raw=2.7643, running_loss=3.2286, LR=0.000018
[2025-08-25 23:05:26,904][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/04869] [00:01:06/00:55:27, 0.697s/it]: train_loss_raw=2.7326, running_loss=3.1914, LR=0.000020
[2025-08-25 23:05:32,350][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000104] [Batch 00104/04869] [00:01:12/00:55:16, 0.696s/it]: train_loss_raw=2.7402, running_loss=3.1565, LR=0.000021
[2025-08-25 23:05:38,240][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000112] [Batch 00112/04869] [00:01:18/00:55:24, 0.699s/it]: train_loss_raw=2.7135, running_loss=3.1232, LR=0.000023
[2025-08-25 23:05:43,460][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/04869] [00:01:23/00:55:04, 0.696s/it]: train_loss_raw=2.7120, running_loss=3.0932, LR=0.000025
[2025-08-25 23:05:48,755][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000128] [Batch 00128/04869] [00:01:28/00:54:48, 0.694s/it]: train_loss_raw=2.7389, running_loss=3.0648, LR=0.000026
[2025-08-25 23:05:54,020][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000136] [Batch 00136/04869] [00:01:34/00:54:32, 0.692s/it]: train_loss_raw=2.7108, running_loss=3.0382, LR=0.000028
[2025-08-25 23:05:59,761][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/04869] [00:01:39/00:54:34, 0.693s/it]: train_loss_raw=2.7015, running_loss=3.0131, LR=0.000030
[2025-08-25 23:06:05,000][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000152] [Batch 00152/04869] [00:01:45/00:54:19, 0.691s/it]: train_loss_raw=2.7009, running_loss=2.9894, LR=0.000031
[2025-08-25 23:06:10,507][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000160] [Batch 00160/04869] [00:01:50/00:54:13, 0.691s/it]: train_loss_raw=2.6982, running_loss=2.9675, LR=0.000033
[2025-08-25 23:06:16,037][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/04869] [00:01:56/00:54:07, 0.691s/it]: train_loss_raw=2.7143, running_loss=2.9468, LR=0.000035
[2025-08-25 23:06:21,769][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000176] [Batch 00176/04869] [00:02:01/00:54:07, 0.692s/it]: train_loss_raw=2.7301, running_loss=2.9283, LR=0.000036
[2025-08-25 23:06:27,503][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000184] [Batch 00184/04869] [00:02:07/00:54:07, 0.693s/it]: train_loss_raw=2.6947, running_loss=2.9109, LR=0.000038
[2025-08-25 23:06:33,010][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/04869] [00:02:13/00:54:00, 0.693s/it]: train_loss_raw=2.7214, running_loss=2.8949, LR=0.000040
[2025-08-25 23:06:38,991][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000200] [Batch 00200/04869] [00:02:19/00:54:05, 0.695s/it]: train_loss_raw=2.7002, running_loss=2.8803, LR=0.000041
[2025-08-25 23:06:44,947][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000208] [Batch 00208/04869] [00:02:24/00:54:08, 0.697s/it]: train_loss_raw=2.6837, running_loss=2.8668, LR=0.000043
[2025-08-25 23:06:50,880][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/04869] [00:02:30/00:54:10, 0.699s/it]: train_loss_raw=2.6840, running_loss=2.8538, LR=0.000045
[2025-08-25 23:06:56,098][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000224] [Batch 00224/04869] [00:02:36/00:53:57, 0.697s/it]: train_loss_raw=2.6921, running_loss=2.8416, LR=0.000046
[2025-08-25 23:07:01,361][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000232] [Batch 00232/04869] [00:02:41/00:53:45, 0.696s/it]: train_loss_raw=2.6955, running_loss=2.8297, LR=0.000048
[2025-08-25 23:07:06,605][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/04869] [00:02:46/00:53:33, 0.694s/it]: train_loss_raw=2.7080, running_loss=2.8192, LR=0.000050
[2025-08-25 23:07:11,881][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000248] [Batch 00248/04869] [00:02:51/00:53:23, 0.693s/it]: train_loss_raw=2.6850, running_loss=2.8095, LR=0.000051
[2025-08-25 23:07:17,157][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000256] [Batch 00256/04869] [00:02:57/00:53:12, 0.692s/it]: train_loss_raw=2.6684, running_loss=2.7993, LR=0.000053
[2025-08-25 23:07:22,467][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/04869] [00:03:02/00:53:03, 0.691s/it]: train_loss_raw=2.7123, running_loss=2.7905, LR=0.000055
[2025-08-25 23:07:27,801][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000272] [Batch 00272/04869] [00:03:07/00:52:54, 0.691s/it]: train_loss_raw=2.6870, running_loss=2.7822, LR=0.000056
[2025-08-25 23:07:34,060][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000280] [Batch 00280/04869] [00:03:14/00:53:00, 0.693s/it]: train_loss_raw=2.6754, running_loss=2.7734, LR=0.000058
[2025-08-25 23:07:39,678][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/04869] [00:03:19/00:52:56, 0.693s/it]: train_loss_raw=2.6986, running_loss=2.7662, LR=0.000060
[2025-08-25 23:07:44,900][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000296] [Batch 00296/04869] [00:03:24/00:52:45, 0.692s/it]: train_loss_raw=2.6889, running_loss=2.7601, LR=0.000061
[2025-08-25 23:07:50,404][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000304] [Batch 00304/04869] [00:03:30/00:52:39, 0.692s/it]: train_loss_raw=2.6882, running_loss=2.7548, LR=0.000063
[2025-08-25 23:07:56,367][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/04869] [00:03:36/00:52:40, 0.694s/it]: train_loss_raw=2.6937, running_loss=2.7499, LR=0.000065
[2025-08-25 23:08:02,394][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000320] [Batch 00320/04869] [00:03:42/00:52:41, 0.695s/it]: train_loss_raw=2.6512, running_loss=2.7446, LR=0.000066
[2025-08-25 23:08:07,636][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000328] [Batch 00328/04869] [00:03:47/00:52:31, 0.694s/it]: train_loss_raw=2.6826, running_loss=2.7396, LR=0.000068
[2025-08-25 23:08:13,554][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/04869] [00:03:53/00:52:31, 0.695s/it]: train_loss_raw=2.6569, running_loss=2.7340, LR=0.000070
[2025-08-25 23:08:19,220][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000344] [Batch 00344/04869] [00:03:59/00:52:27, 0.695s/it]: train_loss_raw=2.6674, running_loss=2.7295, LR=0.000071
[2025-08-25 23:08:24,617][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000352] [Batch 00352/04869] [00:04:04/00:52:19, 0.695s/it]: train_loss_raw=2.6753, running_loss=2.7254, LR=0.000073
[2025-08-25 23:08:30,063][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/04869] [00:04:10/00:52:12, 0.695s/it]: train_loss_raw=2.6906, running_loss=2.7214, LR=0.000075
[2025-08-25 23:08:35,584][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000368] [Batch 00368/04869] [00:04:15/00:52:06, 0.695s/it]: train_loss_raw=2.6619, running_loss=2.7175, LR=0.000076
[2025-08-25 23:08:41,208][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000376] [Batch 00376/04869] [00:04:21/00:52:01, 0.695s/it]: train_loss_raw=2.6703, running_loss=2.7141, LR=0.000078
[2025-08-25 23:08:47,244][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/04869] [00:04:27/00:52:01, 0.696s/it]: train_loss_raw=2.6851, running_loss=2.7103, LR=0.000080
[2025-08-25 23:08:52,783][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000392] [Batch 00392/04869] [00:04:32/00:51:55, 0.696s/it]: train_loss_raw=2.6705, running_loss=2.7078, LR=0.000081
[2025-08-25 23:08:58,274][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000400] [Batch 00400/04869] [00:04:38/00:51:49, 0.696s/it]: train_loss_raw=2.6773, running_loss=2.7048, LR=0.000083
[2025-08-25 23:09:03,983][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/04869] [00:04:44/00:51:45, 0.696s/it]: train_loss_raw=2.6723, running_loss=2.7028, LR=0.000085
[2025-08-25 23:09:09,560][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000416] [Batch 00416/04869] [00:04:49/00:51:39, 0.696s/it]: train_loss_raw=2.6620, running_loss=2.6998, LR=0.000086
[2025-08-25 23:09:14,798][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000424] [Batch 00424/04869] [00:04:54/00:51:30, 0.695s/it]: train_loss_raw=2.6743, running_loss=2.6972, LR=0.000088
[2025-08-25 23:09:20,681][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/04869] [00:05:00/00:51:28, 0.696s/it]: train_loss_raw=2.6742, running_loss=2.6957, LR=0.000090
[2025-08-25 23:09:26,626][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000440] [Batch 00440/04869] [00:05:06/00:51:26, 0.697s/it]: train_loss_raw=2.6718, running_loss=2.6934, LR=0.000091
[2025-08-25 23:09:32,167][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000448] [Batch 00448/04869] [00:05:12/00:51:20, 0.697s/it]: train_loss_raw=2.6692, running_loss=2.6910, LR=0.000093
[2025-08-25 23:09:37,422][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/04869] [00:05:17/00:51:12, 0.696s/it]: train_loss_raw=2.6579, running_loss=2.6888, LR=0.000095
[2025-08-25 23:09:42,608][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000464] [Batch 00464/04869] [00:05:22/00:51:02, 0.695s/it]: train_loss_raw=2.6750, running_loss=2.6868, LR=0.000096
[2025-08-25 23:09:48,133][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000472] [Batch 00472/04869] [00:05:28/00:50:57, 0.695s/it]: train_loss_raw=2.6749, running_loss=2.6848, LR=0.000098
[2025-08-25 23:09:53,343][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/04869] [00:05:33/00:50:48, 0.695s/it]: train_loss_raw=2.6680, running_loss=2.6834, LR=0.000100
[2025-08-25 23:09:58,641][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000488] [Batch 00488/04869] [00:05:38/00:50:40, 0.694s/it]: train_loss_raw=2.6304, running_loss=2.6802, LR=0.000100
[2025-08-25 23:10:03,956][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000496] [Batch 00496/04869] [00:05:43/00:50:32, 0.694s/it]: train_loss_raw=2.6674, running_loss=2.6791, LR=0.000100
[2025-08-25 23:10:09,141][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/04869] [00:05:49/00:50:24, 0.693s/it]: train_loss_raw=2.6399, running_loss=2.6776, LR=0.000100
[2025-08-25 23:10:15,243][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000512] [Batch 00512/04869] [00:05:55/00:50:23, 0.694s/it]: train_loss_raw=2.6496, running_loss=2.6751, LR=0.000100
[2025-08-25 23:10:21,450][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000520] [Batch 00520/04869] [00:06:01/00:50:23, 0.695s/it]: train_loss_raw=2.6411, running_loss=2.6721, LR=0.000100
[2025-08-25 23:10:26,952][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/04869] [00:06:06/00:50:17, 0.695s/it]: train_loss_raw=2.6471, running_loss=2.6700, LR=0.000100
[2025-08-25 23:10:32,174][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000536] [Batch 00536/04869] [00:06:12/00:50:08, 0.694s/it]: train_loss_raw=2.6391, running_loss=2.6680, LR=0.000100
[2025-08-25 23:10:37,467][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000544] [Batch 00544/04869] [00:06:17/00:50:01, 0.694s/it]: train_loss_raw=2.6429, running_loss=2.6660, LR=0.000100
[2025-08-25 23:10:43,331][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/04869] [00:06:23/00:49:58, 0.694s/it]: train_loss_raw=2.6681, running_loss=2.6646, LR=0.000100
[2025-08-25 23:10:48,555][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000560] [Batch 00560/04869] [00:06:28/00:49:49, 0.694s/it]: train_loss_raw=2.6509, running_loss=2.6637, LR=0.000100
[2025-08-25 23:10:53,755][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000568] [Batch 00568/04869] [00:06:33/00:49:41, 0.693s/it]: train_loss_raw=2.6568, running_loss=2.6627, LR=0.000100
[2025-08-25 23:10:58,959][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/04869] [00:06:38/00:49:33, 0.693s/it]: train_loss_raw=2.6717, running_loss=2.6617, LR=0.000100
[2025-08-25 23:11:04,728][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000584] [Batch 00584/04869] [00:06:44/00:49:29, 0.693s/it]: train_loss_raw=2.6150, running_loss=2.6597, LR=0.000100
[2025-08-25 23:11:10,018][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000592] [Batch 00592/04869] [00:06:50/00:49:22, 0.693s/it]: train_loss_raw=2.6556, running_loss=2.6586, LR=0.000100
[2025-08-25 23:11:15,692][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/04869] [00:06:55/00:49:17, 0.693s/it]: train_loss_raw=2.6700, running_loss=2.6574, LR=0.000100
[2025-08-25 23:11:21,342][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000608] [Batch 00608/04869] [00:07:01/00:49:13, 0.693s/it]: train_loss_raw=2.6350, running_loss=2.6569, LR=0.000100
[2025-08-25 23:11:27,247][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000616] [Batch 00616/04869] [00:07:07/00:49:09, 0.694s/it]: train_loss_raw=2.6422, running_loss=2.6566, LR=0.000100
[2025-08-25 23:11:32,471][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/04869] [00:07:12/00:49:02, 0.693s/it]: train_loss_raw=2.6391, running_loss=2.6547, LR=0.000100
[2025-08-25 23:11:37,705][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000632] [Batch 00632/04869] [00:07:17/00:48:54, 0.693s/it]: train_loss_raw=2.6298, running_loss=2.6528, LR=0.000100
[2025-08-25 23:11:43,475][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000640] [Batch 00640/04869] [00:07:23/00:48:50, 0.693s/it]: train_loss_raw=2.6584, running_loss=2.6510, LR=0.000100
[2025-08-25 23:11:49,137][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/04869] [00:07:29/00:48:45, 0.693s/it]: train_loss_raw=2.6642, running_loss=2.6493, LR=0.000100
[2025-08-25 23:11:54,531][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000656] [Batch 00656/04869] [00:07:34/00:48:39, 0.693s/it]: train_loss_raw=2.6420, running_loss=2.6476, LR=0.000100
[2025-08-25 23:11:59,952][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000664] [Batch 00664/04869] [00:07:39/00:48:32, 0.693s/it]: train_loss_raw=2.6079, running_loss=2.6456, LR=0.000100
[2025-08-25 23:12:05,847][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/04869] [00:07:45/00:48:29, 0.693s/it]: train_loss_raw=2.5903, running_loss=2.6434, LR=0.000100
[2025-08-25 23:12:11,296][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000680] [Batch 00680/04869] [00:07:51/00:48:23, 0.693s/it]: train_loss_raw=2.5965, running_loss=2.6412, LR=0.000100
[2025-08-25 23:12:16,544][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000688] [Batch 00688/04869] [00:07:56/00:48:16, 0.693s/it]: train_loss_raw=2.6039, running_loss=2.6392, LR=0.000100
[2025-08-25 23:12:21,794][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/04869] [00:08:01/00:48:08, 0.692s/it]: train_loss_raw=2.5694, running_loss=2.6365, LR=0.000100
[2025-08-25 23:12:27,376][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000704] [Batch 00704/04869] [00:08:07/00:48:03, 0.692s/it]: train_loss_raw=2.6229, running_loss=2.6345, LR=0.000100
[2025-08-25 23:12:32,637][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000712] [Batch 00712/04869] [00:08:12/00:47:56, 0.692s/it]: train_loss_raw=2.6020, running_loss=2.6330, LR=0.000100
[2025-08-25 23:12:37,860][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/04869] [00:08:17/00:47:49, 0.692s/it]: train_loss_raw=2.5911, running_loss=2.6294, LR=0.000100
[2025-08-25 23:12:43,396][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000728] [Batch 00728/04869] [00:08:23/00:47:43, 0.692s/it]: train_loss_raw=2.5948, running_loss=2.6287, LR=0.000100
[2025-08-25 23:12:49,071][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000736] [Batch 00736/04869] [00:08:29/00:47:38, 0.692s/it]: train_loss_raw=2.6639, running_loss=2.6280, LR=0.000100
[2025-08-25 23:12:54,260][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/04869] [00:08:34/00:47:31, 0.691s/it]: train_loss_raw=2.6100, running_loss=2.6252, LR=0.000100
[2025-08-25 23:12:59,450][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000752] [Batch 00752/04869] [00:08:39/00:47:23, 0.691s/it]: train_loss_raw=2.6097, running_loss=2.6224, LR=0.000100
[2025-08-25 23:13:04,692][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000760] [Batch 00760/04869] [00:08:44/00:47:16, 0.690s/it]: train_loss_raw=2.6116, running_loss=2.6212, LR=0.000100
[2025-08-25 23:13:10,550][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/04869] [00:08:50/00:47:13, 0.691s/it]: train_loss_raw=2.5792, running_loss=2.6198, LR=0.000100
[2025-08-25 23:13:16,500][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000776] [Batch 00776/04869] [00:08:56/00:47:09, 0.691s/it]: train_loss_raw=2.5821, running_loss=2.6185, LR=0.000100
[2025-08-25 23:13:22,594][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000784] [Batch 00784/04869] [00:09:02/00:47:07, 0.692s/it]: train_loss_raw=2.5522, running_loss=2.6167, LR=0.000100
[2025-08-25 23:13:28,011][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/04869] [00:09:08/00:47:01, 0.692s/it]: train_loss_raw=2.6077, running_loss=2.6139, LR=0.000100
[2025-08-25 23:13:33,402][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000800] [Batch 00800/04869] [00:09:13/00:46:54, 0.692s/it]: train_loss_raw=2.5879, running_loss=2.6118, LR=0.000100
[2025-08-25 23:13:38,868][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000808] [Batch 00808/04869] [00:09:18/00:46:48, 0.692s/it]: train_loss_raw=2.6190, running_loss=2.6099, LR=0.000100
[2025-08-25 23:13:44,755][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/04869] [00:09:24/00:46:45, 0.692s/it]: train_loss_raw=2.5987, running_loss=2.6077, LR=0.000100
[2025-08-25 23:13:49,970][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000824] [Batch 00824/04869] [00:09:29/00:46:38, 0.692s/it]: train_loss_raw=2.5355, running_loss=2.6045, LR=0.000100
[2025-08-25 23:13:55,208][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000832] [Batch 00832/04869] [00:09:35/00:46:31, 0.691s/it]: train_loss_raw=2.5655, running_loss=2.6028, LR=0.000100
[2025-08-25 23:14:00,451][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000840] [Batch 00840/04869] [00:09:40/00:46:24, 0.691s/it]: train_loss_raw=2.5210, running_loss=2.6011, LR=0.000100
[2025-08-25 23:14:05,669][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000848] [Batch 00848/04869] [00:09:45/00:46:17, 0.691s/it]: train_loss_raw=2.6168, running_loss=2.5993, LR=0.000100
[2025-08-25 23:14:10,902][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000856] [Batch 00856/04869] [00:09:50/00:46:10, 0.690s/it]: train_loss_raw=2.5845, running_loss=2.5961, LR=0.000100
[2025-08-25 23:14:16,136][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000864] [Batch 00864/04869] [00:09:56/00:46:03, 0.690s/it]: train_loss_raw=2.5357, running_loss=2.5934, LR=0.000100
[2025-08-25 23:14:21,331][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000872] [Batch 00872/04869] [00:10:01/00:45:56, 0.690s/it]: train_loss_raw=2.5724, running_loss=2.5920, LR=0.000100
[2025-08-25 23:14:26,943][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000880] [Batch 00880/04869] [00:10:06/00:45:51, 0.690s/it]: train_loss_raw=2.5383, running_loss=2.5904, LR=0.000100
[2025-08-25 23:14:32,514][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000888] [Batch 00888/04869] [00:10:12/00:45:46, 0.690s/it]: train_loss_raw=2.5600, running_loss=2.5886, LR=0.000100
[2025-08-25 23:14:37,769][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000896] [Batch 00896/04869] [00:10:17/00:45:39, 0.690s/it]: train_loss_raw=2.5806, running_loss=2.5875, LR=0.000100
[2025-08-25 23:14:43,820][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000904] [Batch 00904/04869] [00:10:23/00:45:36, 0.690s/it]: train_loss_raw=2.6160, running_loss=2.5876, LR=0.000100
[2025-08-25 23:14:49,656][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000912] [Batch 00912/04869] [00:10:29/00:45:32, 0.690s/it]: train_loss_raw=2.5455, running_loss=2.5862, LR=0.000100
[2025-08-25 23:14:54,968][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000920] [Batch 00920/04869] [00:10:34/00:45:25, 0.690s/it]: train_loss_raw=2.5884, running_loss=2.5860, LR=0.000100
[2025-08-25 23:15:00,214][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000928] [Batch 00928/04869] [00:10:40/00:45:18, 0.690s/it]: train_loss_raw=2.5875, running_loss=2.5846, LR=0.000100
[2025-08-25 23:15:06,264][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000936] [Batch 00936/04869] [00:10:46/00:45:15, 0.690s/it]: train_loss_raw=2.5320, running_loss=2.5829, LR=0.000100
[2025-08-25 23:15:11,768][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000944] [Batch 00944/04869] [00:10:51/00:45:10, 0.690s/it]: train_loss_raw=2.5654, running_loss=2.5808, LR=0.000100
[2025-08-25 23:15:17,112][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000952] [Batch 00952/04869] [00:10:57/00:45:03, 0.690s/it]: train_loss_raw=2.5538, running_loss=2.5795, LR=0.000100
[2025-08-25 23:15:22,626][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000960] [Batch 00960/04869] [00:11:02/00:44:58, 0.690s/it]: train_loss_raw=2.5755, running_loss=2.5773, LR=0.000100
[2025-08-25 23:15:28,186][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000968] [Batch 00968/04869] [00:11:08/00:44:52, 0.690s/it]: train_loss_raw=2.5677, running_loss=2.5785, LR=0.000100
[2025-08-25 23:15:33,837][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000976] [Batch 00976/04869] [00:11:13/00:44:47, 0.690s/it]: train_loss_raw=2.5120, running_loss=2.5762, LR=0.000100
[2025-08-25 23:15:39,594][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000984] [Batch 00984/04869] [00:11:19/00:44:43, 0.691s/it]: train_loss_raw=2.5101, running_loss=2.5737, LR=0.000100
[2025-08-25 23:15:45,181][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000992] [Batch 00992/04869] [00:11:25/00:44:37, 0.691s/it]: train_loss_raw=2.6013, running_loss=2.5733, LR=0.000100
[2025-08-25 23:15:50,961][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001000] [Batch 01000/04869] [00:11:30/00:44:33, 0.691s/it]: train_loss_raw=2.5811, running_loss=2.5719, LR=0.000100
[2025-08-25 23:15:56,338][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001008] [Batch 01008/04869] [00:11:36/00:44:27, 0.691s/it]: train_loss_raw=2.5232, running_loss=2.5703, LR=0.000100
[2025-08-25 23:16:01,959][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001016] [Batch 01016/04869] [00:11:41/00:44:22, 0.691s/it]: train_loss_raw=2.5423, running_loss=2.5696, LR=0.000100
[2025-08-25 23:16:07,742][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001024] [Batch 01024/04869] [00:11:47/00:44:17, 0.691s/it]: train_loss_raw=2.6047, running_loss=2.5695, LR=0.000100
[2025-08-25 23:16:13,222][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001032] [Batch 01032/04869] [00:11:53/00:44:11, 0.691s/it]: train_loss_raw=2.4967, running_loss=2.5684, LR=0.000100
[2025-08-25 23:16:18,439][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001040] [Batch 01040/04869] [00:11:58/00:44:05, 0.691s/it]: train_loss_raw=2.5278, running_loss=2.5671, LR=0.000100
[2025-08-25 23:16:23,804][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001048] [Batch 01048/04869] [00:12:03/00:43:59, 0.691s/it]: train_loss_raw=2.5841, running_loss=2.5669, LR=0.000100
[2025-08-25 23:16:29,764][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001056] [Batch 01056/04869] [00:12:09/00:43:55, 0.691s/it]: train_loss_raw=2.5441, running_loss=2.5640, LR=0.000100
[2025-08-25 23:16:35,561][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001064] [Batch 01064/04869] [00:12:15/00:43:50, 0.691s/it]: train_loss_raw=2.4915, running_loss=2.5624, LR=0.000100
[2025-08-25 23:16:40,946][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001072] [Batch 01072/04869] [00:12:20/00:43:44, 0.691s/it]: train_loss_raw=2.4745, running_loss=2.5618, LR=0.000100
[2025-08-25 23:16:46,843][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001080] [Batch 01080/04869] [00:12:26/00:43:40, 0.692s/it]: train_loss_raw=2.4995, running_loss=2.5598, LR=0.000100
[2025-08-25 23:16:52,834][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001088] [Batch 01088/04869] [00:12:32/00:43:36, 0.692s/it]: train_loss_raw=2.5618, running_loss=2.5593, LR=0.000100
[2025-08-25 23:16:58,215][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001096] [Batch 01096/04869] [00:12:38/00:43:30, 0.692s/it]: train_loss_raw=2.4994, running_loss=2.5587, LR=0.000100
[2025-08-25 23:17:03,542][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001104] [Batch 01104/04869] [00:12:43/00:43:24, 0.692s/it]: train_loss_raw=2.5718, running_loss=2.5581, LR=0.000100
[2025-08-25 23:17:08,760][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001112] [Batch 01112/04869] [00:12:48/00:43:17, 0.691s/it]: train_loss_raw=2.5567, running_loss=2.5569, LR=0.000100
[2025-08-25 23:17:14,229][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001120] [Batch 01120/04869] [00:12:54/00:43:11, 0.691s/it]: train_loss_raw=2.5040, running_loss=2.5535, LR=0.000100
[2025-08-25 23:17:20,065][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001128] [Batch 01128/04869] [00:13:00/00:43:07, 0.692s/it]: train_loss_raw=2.4286, running_loss=2.5519, LR=0.000100
[2025-08-25 23:17:25,318][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001136] [Batch 01136/04869] [00:13:05/00:43:00, 0.691s/it]: train_loss_raw=2.4683, running_loss=2.5501, LR=0.000100
[2025-08-25 23:17:31,216][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001144] [Batch 01144/04869] [00:13:11/00:42:56, 0.692s/it]: train_loss_raw=2.5518, running_loss=2.5501, LR=0.000100
[2025-08-25 23:17:36,748][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001152] [Batch 01152/04869] [00:13:16/00:42:50, 0.692s/it]: train_loss_raw=2.5207, running_loss=2.5483, LR=0.000100
[2025-08-25 23:17:42,280][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001160] [Batch 01160/04869] [00:13:22/00:42:45, 0.692s/it]: train_loss_raw=2.5096, running_loss=2.5465, LR=0.000100
[2025-08-25 23:17:48,162][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001168] [Batch 01168/04869] [00:13:28/00:42:40, 0.692s/it]: train_loss_raw=2.5413, running_loss=2.5459, LR=0.000100
[2025-08-25 23:17:54,062][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001176] [Batch 01176/04869] [00:13:34/00:42:36, 0.692s/it]: train_loss_raw=2.5633, running_loss=2.5460, LR=0.000100
[2025-08-25 23:17:59,724][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001184] [Batch 01184/04869] [00:13:39/00:42:31, 0.692s/it]: train_loss_raw=2.5749, running_loss=2.5445, LR=0.000100
[2025-08-25 23:18:05,705][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001192] [Batch 01192/04869] [00:13:45/00:42:27, 0.693s/it]: train_loss_raw=2.5277, running_loss=2.5429, LR=0.000100
[2025-08-25 23:18:11,745][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001200] [Batch 01200/04869] [00:13:51/00:42:23, 0.693s/it]: train_loss_raw=2.5873, running_loss=2.5418, LR=0.000100
[2025-08-25 23:18:17,823][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001208] [Batch 01208/04869] [00:13:57/00:42:19, 0.694s/it]: train_loss_raw=2.5869, running_loss=2.5382, LR=0.000100
[2025-08-25 23:18:23,888][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001216] [Batch 01216/04869] [00:14:03/00:42:15, 0.694s/it]: train_loss_raw=2.4884, running_loss=2.5374, LR=0.000100
[2025-08-25 23:18:29,903][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001224] [Batch 01224/04869] [00:14:09/00:42:11, 0.694s/it]: train_loss_raw=2.5141, running_loss=2.5372, LR=0.000100
[2025-08-25 23:18:35,275][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001232] [Batch 01232/04869] [00:14:15/00:42:04, 0.694s/it]: train_loss_raw=2.4971, running_loss=2.5355, LR=0.000100
[2025-08-25 23:18:40,870][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001240] [Batch 01240/04869] [00:14:20/00:41:59, 0.694s/it]: train_loss_raw=2.5387, running_loss=2.5340, LR=0.000100
[2025-08-25 23:18:46,645][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001248] [Batch 01248/04869] [00:14:26/00:41:54, 0.694s/it]: train_loss_raw=2.5451, running_loss=2.5324, LR=0.000100
[2025-08-25 23:18:52,302][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001256] [Batch 01256/04869] [00:14:32/00:41:49, 0.695s/it]: train_loss_raw=2.5239, running_loss=2.5312, LR=0.000100
[2025-08-25 23:18:57,552][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001264] [Batch 01264/04869] [00:14:37/00:41:42, 0.694s/it]: train_loss_raw=2.4261, running_loss=2.5291, LR=0.000100
[2025-08-25 23:19:02,798][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001272] [Batch 01272/04869] [00:14:42/00:41:36, 0.694s/it]: train_loss_raw=2.4966, running_loss=2.5269, LR=0.000100
[2025-08-25 23:19:08,273][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001280] [Batch 01280/04869] [00:14:48/00:41:30, 0.694s/it]: train_loss_raw=2.5475, running_loss=2.5264, LR=0.000100
[2025-08-25 23:19:14,107][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001288] [Batch 01288/04869] [00:14:54/00:41:25, 0.694s/it]: train_loss_raw=2.5334, running_loss=2.5263, LR=0.000100
[2025-08-25 23:19:19,826][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001296] [Batch 01296/04869] [00:14:59/00:41:20, 0.694s/it]: train_loss_raw=2.5000, running_loss=2.5237, LR=0.000100
[2025-08-25 23:19:25,772][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001304] [Batch 01304/04869] [00:15:05/00:41:16, 0.695s/it]: train_loss_raw=2.5146, running_loss=2.5221, LR=0.000100
[2025-08-25 23:19:31,829][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001312] [Batch 01312/04869] [00:15:11/00:41:12, 0.695s/it]: train_loss_raw=2.5105, running_loss=2.5215, LR=0.000100
[2025-08-25 23:19:37,715][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001320] [Batch 01320/04869] [00:15:17/00:41:07, 0.695s/it]: train_loss_raw=2.5212, running_loss=2.5206, LR=0.000100
[2025-08-25 23:19:43,503][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001328] [Batch 01328/04869] [00:15:23/00:41:02, 0.695s/it]: train_loss_raw=2.4848, running_loss=2.5190, LR=0.000100
[2025-08-25 23:19:49,143][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001336] [Batch 01336/04869] [00:15:29/00:40:57, 0.695s/it]: train_loss_raw=2.4946, running_loss=2.5183, LR=0.000100
[2025-08-25 23:19:54,638][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001344] [Batch 01344/04869] [00:15:34/00:40:51, 0.695s/it]: train_loss_raw=2.4565, running_loss=2.5172, LR=0.000100
[2025-08-25 23:20:00,484][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001352] [Batch 01352/04869] [00:15:40/00:40:46, 0.696s/it]: train_loss_raw=2.4980, running_loss=2.5171, LR=0.000100
[2025-08-25 23:20:06,565][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001360] [Batch 01360/04869] [00:15:46/00:40:42, 0.696s/it]: train_loss_raw=2.5190, running_loss=2.5158, LR=0.000100
[2025-08-25 23:20:12,085][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001368] [Batch 01368/04869] [00:15:52/00:40:36, 0.696s/it]: train_loss_raw=2.5534, running_loss=2.5141, LR=0.000100
[2025-08-25 23:20:17,789][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001376] [Batch 01376/04869] [00:15:57/00:40:31, 0.696s/it]: train_loss_raw=2.5810, running_loss=2.5134, LR=0.000100
[2025-08-25 23:20:22,964][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001384] [Batch 01384/04869] [00:16:02/00:40:24, 0.696s/it]: train_loss_raw=2.5280, running_loss=2.5131, LR=0.000100
[2025-08-25 23:20:28,576][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001392] [Batch 01392/04869] [00:16:08/00:40:19, 0.696s/it]: train_loss_raw=2.4726, running_loss=2.5105, LR=0.000100
[2025-08-25 23:20:34,653][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001400] [Batch 01400/04869] [00:16:14/00:40:15, 0.696s/it]: train_loss_raw=2.5154, running_loss=2.5122, LR=0.000100
[2025-08-25 23:20:39,868][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001408] [Batch 01408/04869] [00:16:19/00:40:08, 0.696s/it]: train_loss_raw=2.5193, running_loss=2.5108, LR=0.000100
[2025-08-25 23:20:45,449][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001416] [Batch 01416/04869] [00:16:25/00:40:03, 0.696s/it]: train_loss_raw=2.4611, running_loss=2.5095, LR=0.000100
[2025-08-25 23:20:51,045][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001424] [Batch 01424/04869] [00:16:31/00:39:57, 0.696s/it]: train_loss_raw=2.4819, running_loss=2.5081, LR=0.000100
[2025-08-25 23:20:56,562][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001432] [Batch 01432/04869] [00:16:36/00:39:51, 0.696s/it]: train_loss_raw=2.4896, running_loss=2.5055, LR=0.000100
[2025-08-25 23:21:01,774][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001440] [Batch 01440/04869] [00:16:41/00:39:45, 0.696s/it]: train_loss_raw=2.5114, running_loss=2.5055, LR=0.000100
[2025-08-25 23:21:07,081][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001448] [Batch 01448/04869] [00:16:47/00:39:39, 0.696s/it]: train_loss_raw=2.5326, running_loss=2.5058, LR=0.000100
[2025-08-25 23:21:12,678][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001456] [Batch 01456/04869] [00:16:52/00:39:33, 0.696s/it]: train_loss_raw=2.4674, running_loss=2.5042, LR=0.000100
[2025-08-25 23:21:17,952][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001464] [Batch 01464/04869] [00:16:57/00:39:27, 0.695s/it]: train_loss_raw=2.5085, running_loss=2.5040, LR=0.000100
[2025-08-25 23:21:23,330][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001472] [Batch 01472/04869] [00:17:03/00:39:21, 0.695s/it]: train_loss_raw=2.5173, running_loss=2.5054, LR=0.000100
[2025-08-25 23:21:29,723][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001480] [Batch 01480/04869] [00:17:09/00:39:17, 0.696s/it]: train_loss_raw=2.4973, running_loss=2.5047, LR=0.000100
[2025-08-25 23:21:34,975][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001488] [Batch 01488/04869] [00:17:15/00:39:11, 0.696s/it]: train_loss_raw=2.5009, running_loss=2.5032, LR=0.000100
[2025-08-25 23:21:40,569][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001496] [Batch 01496/04869] [00:17:20/00:39:06, 0.696s/it]: train_loss_raw=2.4704, running_loss=2.5029, LR=0.000100
[2025-08-25 23:21:45,873][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001504] [Batch 01504/04869] [00:17:25/00:39:00, 0.695s/it]: train_loss_raw=2.5228, running_loss=2.5016, LR=0.000100
[2025-08-25 23:21:51,474][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001512] [Batch 01512/04869] [00:17:31/00:38:54, 0.695s/it]: train_loss_raw=2.5641, running_loss=2.5018, LR=0.000100
[2025-08-25 23:21:57,159][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001520] [Batch 01520/04869] [00:17:37/00:38:49, 0.696s/it]: train_loss_raw=2.4948, running_loss=2.5005, LR=0.000100
[2025-08-25 23:22:03,090][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001528] [Batch 01528/04869] [00:17:43/00:38:44, 0.696s/it]: train_loss_raw=2.4931, running_loss=2.4998, LR=0.000100
[2025-08-25 23:22:08,658][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001536] [Batch 01536/04869] [00:17:48/00:38:38, 0.696s/it]: train_loss_raw=2.4992, running_loss=2.4999, LR=0.000100
[2025-08-25 23:22:14,290][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001544] [Batch 01544/04869] [00:17:54/00:38:33, 0.696s/it]: train_loss_raw=2.5353, running_loss=2.5004, LR=0.000100
[2025-08-25 23:22:20,130][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001552] [Batch 01552/04869] [00:18:00/00:38:28, 0.696s/it]: train_loss_raw=2.4812, running_loss=2.5006, LR=0.000100
[2025-08-25 23:22:25,329][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001560] [Batch 01560/04869] [00:18:05/00:38:22, 0.696s/it]: train_loss_raw=2.4346, running_loss=2.4993, LR=0.000100
[2025-08-25 23:22:30,556][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001568] [Batch 01568/04869] [00:18:10/00:38:15, 0.696s/it]: train_loss_raw=2.4793, running_loss=2.4986, LR=0.000100
[2025-08-25 23:22:36,221][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001576] [Batch 01576/04869] [00:18:16/00:38:10, 0.696s/it]: train_loss_raw=2.5030, running_loss=2.4981, LR=0.000100
[2025-08-25 23:22:41,516][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001584] [Batch 01584/04869] [00:18:21/00:38:04, 0.695s/it]: train_loss_raw=2.5126, running_loss=2.4983, LR=0.000100
[2025-08-25 23:22:46,751][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001592] [Batch 01592/04869] [00:18:26/00:37:58, 0.695s/it]: train_loss_raw=2.4634, running_loss=2.4970, LR=0.000100
[2025-08-25 23:22:52,348][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001600] [Batch 01600/04869] [00:18:32/00:37:52, 0.695s/it]: train_loss_raw=2.4657, running_loss=2.4967, LR=0.000100
[2025-08-25 23:22:57,742][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001608] [Batch 01608/04869] [00:18:37/00:37:46, 0.695s/it]: train_loss_raw=2.3707, running_loss=2.4948, LR=0.000100
[2025-08-25 23:23:03,187][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001616] [Batch 01616/04869] [00:18:43/00:37:41, 0.695s/it]: train_loss_raw=2.4500, running_loss=2.4938, LR=0.000100
[2025-08-25 23:23:08,568][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001624] [Batch 01624/04869] [00:18:48/00:37:35, 0.695s/it]: train_loss_raw=2.5167, running_loss=2.4923, LR=0.000100
[2025-08-25 23:23:13,822][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001632] [Batch 01632/04869] [00:18:53/00:37:28, 0.695s/it]: train_loss_raw=2.5181, running_loss=2.4912, LR=0.000100
[2025-08-25 23:23:19,658][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001640] [Batch 01640/04869] [00:18:59/00:37:23, 0.695s/it]: train_loss_raw=2.5686, running_loss=2.4922, LR=0.000100
[2025-08-25 23:23:25,010][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001648] [Batch 01648/04869] [00:19:05/00:37:17, 0.695s/it]: train_loss_raw=2.4995, running_loss=2.4918, LR=0.000100
[2025-08-25 23:23:30,435][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001656] [Batch 01656/04869] [00:19:10/00:37:12, 0.695s/it]: train_loss_raw=2.4233, running_loss=2.4898, LR=0.000100
[2025-08-25 23:23:36,344][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001664] [Batch 01664/04869] [00:19:16/00:37:07, 0.695s/it]: train_loss_raw=2.5261, running_loss=2.4896, LR=0.000100
[2025-08-25 23:23:41,876][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001672] [Batch 01672/04869] [00:19:21/00:37:01, 0.695s/it]: train_loss_raw=2.4939, running_loss=2.4882, LR=0.000100
[2025-08-25 23:23:47,105][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001680] [Batch 01680/04869] [00:19:27/00:36:55, 0.695s/it]: train_loss_raw=2.4454, running_loss=2.4865, LR=0.000100
[2025-08-25 23:23:52,910][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001688] [Batch 01688/04869] [00:19:32/00:36:50, 0.695s/it]: train_loss_raw=2.4560, running_loss=2.4833, LR=0.000100
[2025-08-25 23:23:58,095][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001696] [Batch 01696/04869] [00:19:38/00:36:44, 0.695s/it]: train_loss_raw=2.4871, running_loss=2.4823, LR=0.000100
[2025-08-25 23:24:03,520][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001704] [Batch 01704/04869] [00:19:43/00:36:38, 0.695s/it]: train_loss_raw=2.4656, running_loss=2.4819, LR=0.000100
[2025-08-25 23:24:08,872][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001712] [Batch 01712/04869] [00:19:48/00:36:32, 0.694s/it]: train_loss_raw=2.4701, running_loss=2.4809, LR=0.000100
[2025-08-25 23:24:14,095][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001720] [Batch 01720/04869] [00:19:54/00:36:26, 0.694s/it]: train_loss_raw=2.4765, running_loss=2.4801, LR=0.000100
[2025-08-25 23:24:19,306][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001728] [Batch 01728/04869] [00:19:59/00:36:20, 0.694s/it]: train_loss_raw=2.5085, running_loss=2.4793, LR=0.000100
[2025-08-25 23:24:24,529][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001736] [Batch 01736/04869] [00:20:04/00:36:13, 0.694s/it]: train_loss_raw=2.4695, running_loss=2.4792, LR=0.000100
[2025-08-25 23:24:29,743][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001744] [Batch 01744/04869] [00:20:09/00:36:07, 0.694s/it]: train_loss_raw=2.4835, running_loss=2.4770, LR=0.000100
[2025-08-25 23:24:35,539][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001752] [Batch 01752/04869] [00:20:15/00:36:02, 0.694s/it]: train_loss_raw=2.4853, running_loss=2.4761, LR=0.000100
[2025-08-25 23:24:40,732][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001760] [Batch 01760/04869] [00:20:20/00:35:56, 0.694s/it]: train_loss_raw=2.4663, running_loss=2.4772, LR=0.000100
[2025-08-25 23:24:46,497][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001768] [Batch 01768/04869] [00:20:26/00:35:51, 0.694s/it]: train_loss_raw=2.4210, running_loss=2.4753, LR=0.000100
[2025-08-25 23:24:51,688][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001776] [Batch 01776/04869] [00:20:31/00:35:45, 0.694s/it]: train_loss_raw=2.4485, running_loss=2.4742, LR=0.000100
[2025-08-25 23:24:56,891][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001784] [Batch 01784/04869] [00:20:36/00:35:38, 0.693s/it]: train_loss_raw=2.4382, running_loss=2.4725, LR=0.000100
[2025-08-25 23:25:02,169][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001792] [Batch 01792/04869] [00:20:42/00:35:32, 0.693s/it]: train_loss_raw=2.5148, running_loss=2.4721, LR=0.000100
[2025-08-25 23:25:07,347][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001800] [Batch 01800/04869] [00:20:47/00:35:26, 0.693s/it]: train_loss_raw=2.4275, running_loss=2.4712, LR=0.000100
[2025-08-25 23:25:12,584][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001808] [Batch 01808/04869] [00:20:52/00:35:20, 0.693s/it]: train_loss_raw=2.4668, running_loss=2.4711, LR=0.000100
[2025-08-25 23:25:17,810][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001816] [Batch 01816/04869] [00:20:57/00:35:14, 0.693s/it]: train_loss_raw=2.4646, running_loss=2.4701, LR=0.000100
[2025-08-25 23:25:22,999][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001824] [Batch 01824/04869] [00:21:03/00:35:08, 0.692s/it]: train_loss_raw=2.4018, running_loss=2.4686, LR=0.000100
[2025-08-25 23:25:28,267][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001832] [Batch 01832/04869] [00:21:08/00:35:02, 0.692s/it]: train_loss_raw=2.4463, running_loss=2.4688, LR=0.000100
[2025-08-25 23:25:33,771][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001840] [Batch 01840/04869] [00:21:13/00:34:56, 0.692s/it]: train_loss_raw=2.4652, running_loss=2.4673, LR=0.000100
[2025-08-25 23:25:38,970][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001848] [Batch 01848/04869] [00:21:18/00:34:50, 0.692s/it]: train_loss_raw=2.4393, running_loss=2.4655, LR=0.000100
[2025-08-25 23:25:44,168][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001856] [Batch 01856/04869] [00:21:24/00:34:44, 0.692s/it]: train_loss_raw=2.3972, running_loss=2.4634, LR=0.000100
[2025-08-25 23:25:49,825][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001864] [Batch 01864/04869] [00:21:29/00:34:39, 0.692s/it]: train_loss_raw=2.4583, running_loss=2.4641, LR=0.000100
[2025-08-25 23:25:55,715][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001872] [Batch 01872/04869] [00:21:35/00:34:34, 0.692s/it]: train_loss_raw=2.4733, running_loss=2.4624, LR=0.000100
[2025-08-25 23:26:01,352][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001880] [Batch 01880/04869] [00:21:41/00:34:29, 0.692s/it]: train_loss_raw=2.5063, running_loss=2.4633, LR=0.000100
[2025-08-25 23:26:06,562][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001888] [Batch 01888/04869] [00:21:46/00:34:22, 0.692s/it]: train_loss_raw=2.4471, running_loss=2.4619, LR=0.000100
[2025-08-25 23:26:11,975][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001896] [Batch 01896/04869] [00:21:52/00:34:17, 0.692s/it]: train_loss_raw=2.4774, running_loss=2.4610, LR=0.000100
[2025-08-25 23:26:17,956][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001904] [Batch 01904/04869] [00:21:57/00:34:12, 0.692s/it]: train_loss_raw=2.4047, running_loss=2.4604, LR=0.000100
[2025-08-25 23:26:23,449][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001912] [Batch 01912/04869] [00:22:03/00:34:06, 0.692s/it]: train_loss_raw=2.4275, running_loss=2.4581, LR=0.000100
[2025-08-25 23:26:28,642][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001920] [Batch 01920/04869] [00:22:08/00:34:00, 0.692s/it]: train_loss_raw=2.4526, running_loss=2.4564, LR=0.000100
[2025-08-25 23:26:34,027][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001928] [Batch 01928/04869] [00:22:14/00:33:54, 0.692s/it]: train_loss_raw=2.4552, running_loss=2.4566, LR=0.000100
[2025-08-25 23:26:39,304][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001936] [Batch 01936/04869] [00:22:19/00:33:49, 0.692s/it]: train_loss_raw=2.4690, running_loss=2.4562, LR=0.000100
[2025-08-25 23:26:44,928][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001944] [Batch 01944/04869] [00:22:24/00:33:43, 0.692s/it]: train_loss_raw=2.4345, running_loss=2.4562, LR=0.000100
[2025-08-25 23:26:50,205][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001952] [Batch 01952/04869] [00:22:30/00:33:37, 0.692s/it]: train_loss_raw=2.3915, running_loss=2.4542, LR=0.000100
[2025-08-25 23:26:56,040][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001960] [Batch 01960/04869] [00:22:36/00:33:32, 0.692s/it]: train_loss_raw=2.4064, running_loss=2.4554, LR=0.000100
[2025-08-25 23:27:01,588][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001968] [Batch 01968/04869] [00:22:41/00:33:27, 0.692s/it]: train_loss_raw=2.3381, running_loss=2.4519, LR=0.000100
[2025-08-25 23:27:07,026][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001976] [Batch 01976/04869] [00:22:47/00:33:21, 0.692s/it]: train_loss_raw=2.4707, running_loss=2.4522, LR=0.000100
[2025-08-25 23:27:12,463][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001984] [Batch 01984/04869] [00:22:52/00:33:15, 0.692s/it]: train_loss_raw=2.4709, running_loss=2.4503, LR=0.000100
[2025-08-25 23:27:17,858][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 001992] [Batch 01992/04869] [00:22:57/00:33:10, 0.692s/it]: train_loss_raw=2.5127, running_loss=2.4494, LR=0.000100
[2025-08-25 23:27:23,316][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002000] [Batch 02000/04869] [00:23:03/00:33:04, 0.692s/it]: train_loss_raw=2.4117, running_loss=2.4486, LR=0.000100
[2025-08-25 23:27:32,565][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002008] [Batch 02008/04869] [00:23:12/00:33:04, 0.694s/it]: train_loss_raw=2.4263, running_loss=2.4486, LR=0.000100
[2025-08-25 23:27:38,336][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002016] [Batch 02016/04869] [00:23:18/00:32:58, 0.694s/it]: train_loss_raw=2.4319, running_loss=2.4485, LR=0.000100
[2025-08-25 23:27:44,201][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002024] [Batch 02024/04869] [00:23:24/00:32:53, 0.694s/it]: train_loss_raw=2.4120, running_loss=2.4473, LR=0.000100
[2025-08-25 23:27:49,667][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002032] [Batch 02032/04869] [00:23:29/00:32:48, 0.694s/it]: train_loss_raw=2.4479, running_loss=2.4465, LR=0.000100
[2025-08-25 23:27:54,874][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002040] [Batch 02040/04869] [00:23:34/00:32:42, 0.694s/it]: train_loss_raw=2.4066, running_loss=2.4453, LR=0.000100
[2025-08-25 23:28:00,661][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002048] [Batch 02048/04869] [00:23:40/00:32:36, 0.694s/it]: train_loss_raw=2.4849, running_loss=2.4441, LR=0.000100
[2025-08-25 23:28:06,381][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002056] [Batch 02056/04869] [00:23:46/00:32:31, 0.694s/it]: train_loss_raw=2.4604, running_loss=2.4427, LR=0.000100
[2025-08-25 23:28:12,060][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002064] [Batch 02064/04869] [00:23:52/00:32:26, 0.694s/it]: train_loss_raw=2.4681, running_loss=2.4430, LR=0.000100
[2025-08-25 23:28:17,722][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002072] [Batch 02072/04869] [00:23:57/00:32:20, 0.694s/it]: train_loss_raw=2.4066, running_loss=2.4428, LR=0.000100
[2025-08-25 23:28:22,946][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002080] [Batch 02080/04869] [00:24:02/00:32:14, 0.694s/it]: train_loss_raw=2.3855, running_loss=2.4432, LR=0.000100
[2025-08-25 23:28:28,181][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002088] [Batch 02088/04869] [00:24:08/00:32:08, 0.694s/it]: train_loss_raw=2.4768, running_loss=2.4433, LR=0.000100
[2025-08-25 23:28:33,886][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002096] [Batch 02096/04869] [00:24:13/00:32:03, 0.694s/it]: train_loss_raw=2.4810, running_loss=2.4429, LR=0.000100
[2025-08-25 23:28:39,332][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002104] [Batch 02104/04869] [00:24:19/00:31:57, 0.694s/it]: train_loss_raw=2.4148, running_loss=2.4418, LR=0.000100
[2025-08-25 23:28:44,560][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002112] [Batch 02112/04869] [00:24:24/00:31:51, 0.693s/it]: train_loss_raw=2.4471, running_loss=2.4401, LR=0.000100
[2025-08-25 23:28:50,158][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002120] [Batch 02120/04869] [00:24:30/00:31:46, 0.693s/it]: train_loss_raw=2.4592, running_loss=2.4410, LR=0.000100
[2025-08-25 23:28:55,684][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002128] [Batch 02128/04869] [00:24:35/00:31:40, 0.693s/it]: train_loss_raw=2.4496, running_loss=2.4400, LR=0.000100
[2025-08-25 23:29:01,323][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002136] [Batch 02136/04869] [00:24:41/00:31:35, 0.694s/it]: train_loss_raw=2.3989, running_loss=2.4382, LR=0.000100
[2025-08-25 23:29:06,825][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002144] [Batch 02144/04869] [00:24:46/00:31:29, 0.693s/it]: train_loss_raw=2.4697, running_loss=2.4386, LR=0.000100
[2025-08-25 23:29:12,572][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002152] [Batch 02152/04869] [00:24:52/00:31:24, 0.694s/it]: train_loss_raw=2.3834, running_loss=2.4362, LR=0.000100
[2025-08-25 23:29:17,830][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002160] [Batch 02160/04869] [00:24:57/00:31:18, 0.693s/it]: train_loss_raw=2.3858, running_loss=2.4339, LR=0.000100
[2025-08-25 23:29:23,068][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002168] [Batch 02168/04869] [00:25:03/00:31:12, 0.693s/it]: train_loss_raw=2.4228, running_loss=2.4342, LR=0.000100
[2025-08-25 23:29:28,295][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002176] [Batch 02176/04869] [00:25:08/00:31:06, 0.693s/it]: train_loss_raw=2.4357, running_loss=2.4342, LR=0.000100
[2025-08-25 23:29:33,528][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002184] [Batch 02184/04869] [00:25:13/00:31:00, 0.693s/it]: train_loss_raw=2.3915, running_loss=2.4324, LR=0.000100
[2025-08-25 23:29:38,863][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002192] [Batch 02192/04869] [00:25:18/00:30:54, 0.693s/it]: train_loss_raw=2.4101, running_loss=2.4333, LR=0.000100
[2025-08-25 23:29:44,597][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002200] [Batch 02200/04869] [00:25:24/00:30:49, 0.693s/it]: train_loss_raw=2.4650, running_loss=2.4347, LR=0.000100
[2025-08-25 23:29:49,828][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002208] [Batch 02208/04869] [00:25:29/00:30:43, 0.693s/it]: train_loss_raw=2.4104, running_loss=2.4339, LR=0.000100
[2025-08-25 23:29:55,101][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002216] [Batch 02216/04869] [00:25:35/00:30:37, 0.693s/it]: train_loss_raw=2.4023, running_loss=2.4339, LR=0.000100
[2025-08-25 23:30:00,308][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002224] [Batch 02224/04869] [00:25:40/00:30:31, 0.693s/it]: train_loss_raw=2.4156, running_loss=2.4334, LR=0.000100
[2025-08-25 23:30:06,076][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002232] [Batch 02232/04869] [00:25:46/00:30:26, 0.693s/it]: train_loss_raw=2.3898, running_loss=2.4325, LR=0.000100
[2025-08-25 23:30:11,362][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002240] [Batch 02240/04869] [00:25:51/00:30:20, 0.693s/it]: train_loss_raw=2.4598, running_loss=2.4311, LR=0.000100
[2025-08-25 23:30:16,602][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002248] [Batch 02248/04869] [00:25:56/00:30:14, 0.692s/it]: train_loss_raw=2.4018, running_loss=2.4311, LR=0.000100
[2025-08-25 23:30:21,784][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002256] [Batch 02256/04869] [00:26:01/00:30:08, 0.692s/it]: train_loss_raw=2.3918, running_loss=2.4300, LR=0.000100
[2025-08-25 23:30:26,973][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002264] [Batch 02264/04869] [00:26:07/00:30:03, 0.692s/it]: train_loss_raw=2.4148, running_loss=2.4306, LR=0.000100
[2025-08-25 23:30:32,192][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002272] [Batch 02272/04869] [00:26:12/00:29:57, 0.692s/it]: train_loss_raw=2.4387, running_loss=2.4312, LR=0.000100
[2025-08-25 23:30:37,406][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002280] [Batch 02280/04869] [00:26:17/00:29:51, 0.692s/it]: train_loss_raw=2.4133, running_loss=2.4303, LR=0.000100
[2025-08-25 23:30:42,649][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002288] [Batch 02288/04869] [00:26:22/00:29:45, 0.692s/it]: train_loss_raw=2.4188, running_loss=2.4289, LR=0.000100
[2025-08-25 23:30:47,877][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002296] [Batch 02296/04869] [00:26:27/00:29:39, 0.692s/it]: train_loss_raw=2.4483, running_loss=2.4281, LR=0.000100
[2025-08-25 23:30:53,124][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002304] [Batch 02304/04869] [00:26:33/00:29:33, 0.691s/it]: train_loss_raw=2.3853, running_loss=2.4277, LR=0.000100
[2025-08-25 23:30:58,760][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002312] [Batch 02312/04869] [00:26:38/00:29:28, 0.692s/it]: train_loss_raw=2.4679, running_loss=2.4282, LR=0.000100
[2025-08-25 23:31:04,246][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002320] [Batch 02320/04869] [00:26:44/00:29:22, 0.691s/it]: train_loss_raw=2.3972, running_loss=2.4278, LR=0.000100
[2025-08-25 23:31:09,558][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002328] [Batch 02328/04869] [00:26:49/00:29:16, 0.691s/it]: train_loss_raw=2.4513, running_loss=2.4277, LR=0.000100
[2025-08-25 23:31:14,786][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002336] [Batch 02336/04869] [00:26:54/00:29:10, 0.691s/it]: train_loss_raw=2.4367, running_loss=2.4277, LR=0.000100
[2025-08-25 23:31:19,960][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002344] [Batch 02344/04869] [00:26:59/00:29:05, 0.691s/it]: train_loss_raw=2.4472, running_loss=2.4265, LR=0.000100
[2025-08-25 23:31:25,131][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002352] [Batch 02352/04869] [00:27:05/00:28:59, 0.691s/it]: train_loss_raw=2.3947, running_loss=2.4252, LR=0.000100
[2025-08-25 23:31:30,510][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002360] [Batch 02360/04869] [00:27:10/00:28:53, 0.691s/it]: train_loss_raw=2.4339, running_loss=2.4242, LR=0.000100
[2025-08-25 23:31:35,960][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002368] [Batch 02368/04869] [00:27:15/00:28:47, 0.691s/it]: train_loss_raw=2.4543, running_loss=2.4236, LR=0.000100
[2025-08-25 23:31:41,648][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002376] [Batch 02376/04869] [00:27:21/00:28:42, 0.691s/it]: train_loss_raw=2.3111, running_loss=2.4205, LR=0.000100
[2025-08-25 23:31:47,003][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002384] [Batch 02384/04869] [00:27:27/00:28:36, 0.691s/it]: train_loss_raw=2.4063, running_loss=2.4201, LR=0.000100
[2025-08-25 23:31:52,208][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002392] [Batch 02392/04869] [00:27:32/00:28:30, 0.691s/it]: train_loss_raw=2.3030, running_loss=2.4189, LR=0.000100
[2025-08-25 23:31:57,754][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002400] [Batch 02400/04869] [00:27:37/00:28:25, 0.691s/it]: train_loss_raw=2.4169, running_loss=2.4205, LR=0.000100
[2025-08-25 23:32:02,998][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002408] [Batch 02408/04869] [00:27:43/00:28:19, 0.691s/it]: train_loss_raw=2.3901, running_loss=2.4198, LR=0.000100
[2025-08-25 23:32:08,206][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002416] [Batch 02416/04869] [00:27:48/00:28:13, 0.690s/it]: train_loss_raw=2.2783, running_loss=2.4186, LR=0.000100
[2025-08-25 23:32:13,406][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002424] [Batch 02424/04869] [00:27:53/00:28:07, 0.690s/it]: train_loss_raw=2.4320, running_loss=2.4187, LR=0.000100
[2025-08-25 23:32:19,259][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002432] [Batch 02432/04869] [00:27:59/00:28:02, 0.690s/it]: train_loss_raw=2.4373, running_loss=2.4183, LR=0.000100
[2025-08-25 23:32:24,565][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002440] [Batch 02440/04869] [00:28:04/00:27:56, 0.690s/it]: train_loss_raw=2.3840, running_loss=2.4161, LR=0.000100
[2025-08-25 23:32:29,817][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002448] [Batch 02448/04869] [00:28:09/00:27:51, 0.690s/it]: train_loss_raw=2.3797, running_loss=2.4164, LR=0.000100
[2025-08-25 23:32:35,498][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002456] [Batch 02456/04869] [00:28:15/00:27:45, 0.690s/it]: train_loss_raw=2.3771, running_loss=2.4146, LR=0.000100
[2025-08-25 23:32:41,387][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002464] [Batch 02464/04869] [00:28:21/00:27:40, 0.691s/it]: train_loss_raw=2.3846, running_loss=2.4142, LR=0.000100
[2025-08-25 23:32:47,727][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002472] [Batch 02472/04869] [00:28:27/00:27:35, 0.691s/it]: train_loss_raw=2.3975, running_loss=2.4137, LR=0.000100
[2025-08-25 23:32:53,572][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002480] [Batch 02480/04869] [00:28:33/00:27:30, 0.691s/it]: train_loss_raw=2.4899, running_loss=2.4143, LR=0.000100
[2025-08-25 23:32:59,595][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002488] [Batch 02488/04869] [00:28:39/00:27:25, 0.691s/it]: train_loss_raw=2.3702, running_loss=2.4137, LR=0.000100
[2025-08-25 23:33:05,938][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002496] [Batch 02496/04869] [00:28:45/00:27:20, 0.691s/it]: train_loss_raw=2.3465, running_loss=2.4119, LR=0.000100
[2025-08-25 23:33:11,593][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002504] [Batch 02504/04869] [00:28:51/00:27:15, 0.692s/it]: train_loss_raw=2.4746, running_loss=2.4135, LR=0.000100
[2025-08-25 23:33:17,183][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002512] [Batch 02512/04869] [00:28:57/00:27:10, 0.692s/it]: train_loss_raw=2.3902, running_loss=2.4128, LR=0.000100
[2025-08-25 23:33:22,512][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002520] [Batch 02520/04869] [00:29:02/00:27:04, 0.691s/it]: train_loss_raw=2.4170, running_loss=2.4122, LR=0.000100
[2025-08-25 23:33:28,697][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002528] [Batch 02528/04869] [00:29:08/00:26:59, 0.692s/it]: train_loss_raw=2.3627, running_loss=2.4121, LR=0.000100
[2025-08-25 23:33:34,169][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002536] [Batch 02536/04869] [00:29:14/00:26:53, 0.692s/it]: train_loss_raw=2.4845, running_loss=2.4124, LR=0.000100
[2025-08-25 23:33:39,375][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002544] [Batch 02544/04869] [00:29:19/00:26:47, 0.692s/it]: train_loss_raw=2.3530, running_loss=2.4106, LR=0.000100
[2025-08-25 23:33:44,613][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002552] [Batch 02552/04869] [00:29:24/00:26:42, 0.691s/it]: train_loss_raw=2.3919, running_loss=2.4096, LR=0.000100
[2025-08-25 23:33:50,455][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002560] [Batch 02560/04869] [00:29:30/00:26:36, 0.692s/it]: train_loss_raw=2.4145, running_loss=2.4090, LR=0.000100
[2025-08-25 23:33:55,663][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002568] [Batch 02568/04869] [00:29:35/00:26:31, 0.691s/it]: train_loss_raw=2.3984, running_loss=2.4099, LR=0.000100
[2025-08-25 23:34:00,896][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002576] [Batch 02576/04869] [00:29:40/00:26:25, 0.691s/it]: train_loss_raw=2.4449, running_loss=2.4089, LR=0.000100
[2025-08-25 23:34:06,539][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002584] [Batch 02584/04869] [00:29:46/00:26:19, 0.691s/it]: train_loss_raw=2.4143, running_loss=2.4079, LR=0.000100
[2025-08-25 23:34:11,708][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002592] [Batch 02592/04869] [00:29:51/00:26:13, 0.691s/it]: train_loss_raw=2.4247, running_loss=2.4072, LR=0.000100
[2025-08-25 23:34:16,872][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002600] [Batch 02600/04869] [00:29:56/00:26:08, 0.691s/it]: train_loss_raw=2.3070, running_loss=2.4063, LR=0.000100
[2025-08-25 23:34:22,451][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002608] [Batch 02608/04869] [00:30:02/00:26:02, 0.691s/it]: train_loss_raw=2.4116, running_loss=2.4059, LR=0.000100
[2025-08-25 23:34:27,721][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002616] [Batch 02616/04869] [00:30:07/00:25:56, 0.691s/it]: train_loss_raw=2.3723, running_loss=2.4033, LR=0.000100
[2025-08-25 23:34:33,578][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002624] [Batch 02624/04869] [00:30:13/00:25:51, 0.691s/it]: train_loss_raw=2.4410, running_loss=2.4012, LR=0.000100
[2025-08-25 23:34:38,772][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002632] [Batch 02632/04869] [00:30:18/00:25:45, 0.691s/it]: train_loss_raw=2.4108, running_loss=2.4026, LR=0.000100
[2025-08-25 23:34:43,941][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002640] [Batch 02640/04869] [00:30:23/00:25:40, 0.691s/it]: train_loss_raw=2.3232, running_loss=2.3994, LR=0.000100
[2025-08-25 23:34:49,124][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002648] [Batch 02648/04869] [00:30:29/00:25:34, 0.691s/it]: train_loss_raw=2.4664, running_loss=2.4012, LR=0.000100
[2025-08-25 23:34:54,326][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002656] [Batch 02656/04869] [00:30:34/00:25:28, 0.691s/it]: train_loss_raw=2.4206, running_loss=2.3990, LR=0.000100
[2025-08-25 23:34:59,524][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002664] [Batch 02664/04869] [00:30:39/00:25:22, 0.691s/it]: train_loss_raw=2.4034, running_loss=2.3977, LR=0.000100
[2025-08-25 23:35:04,725][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002672] [Batch 02672/04869] [00:30:44/00:25:16, 0.690s/it]: train_loss_raw=2.4024, running_loss=2.3973, LR=0.000100
[2025-08-25 23:35:10,434][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002680] [Batch 02680/04869] [00:30:50/00:25:11, 0.690s/it]: train_loss_raw=2.3169, running_loss=2.3984, LR=0.000100
[2025-08-25 23:35:15,757][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002688] [Batch 02688/04869] [00:30:55/00:25:05, 0.690s/it]: train_loss_raw=2.3837, running_loss=2.3980, LR=0.000100
[2025-08-25 23:35:21,438][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002696] [Batch 02696/04869] [00:31:01/00:25:00, 0.690s/it]: train_loss_raw=2.3608, running_loss=2.3988, LR=0.000100
[2025-08-25 23:35:26,618][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002704] [Batch 02704/04869] [00:31:06/00:24:54, 0.690s/it]: train_loss_raw=2.4111, running_loss=2.3982, LR=0.000100
[2025-08-25 23:35:31,834][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002712] [Batch 02712/04869] [00:31:11/00:24:48, 0.690s/it]: train_loss_raw=2.3249, running_loss=2.3973, LR=0.000100
[2025-08-25 23:35:37,083][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002720] [Batch 02720/04869] [00:31:17/00:24:43, 0.690s/it]: train_loss_raw=2.4372, running_loss=2.3984, LR=0.000100
[2025-08-25 23:35:42,450][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002728] [Batch 02728/04869] [00:31:22/00:24:37, 0.690s/it]: train_loss_raw=2.4091, running_loss=2.3986, LR=0.000100
[2025-08-25 23:35:48,120][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002736] [Batch 02736/04869] [00:31:28/00:24:32, 0.690s/it]: train_loss_raw=2.3766, running_loss=2.3968, LR=0.000100
[2025-08-25 23:35:53,441][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002744] [Batch 02744/04869] [00:31:33/00:24:26, 0.690s/it]: train_loss_raw=2.3941, running_loss=2.3973, LR=0.000100
[2025-08-25 23:35:58,703][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002752] [Batch 02752/04869] [00:31:38/00:24:20, 0.690s/it]: train_loss_raw=2.4269, running_loss=2.3960, LR=0.000100
[2025-08-25 23:36:04,233][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002760] [Batch 02760/04869] [00:31:44/00:24:15, 0.690s/it]: train_loss_raw=2.3438, running_loss=2.3956, LR=0.000100
[2025-08-25 23:36:09,647][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002768] [Batch 02768/04869] [00:31:49/00:24:09, 0.690s/it]: train_loss_raw=2.3610, running_loss=2.3948, LR=0.000100
[2025-08-25 23:36:14,968][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002776] [Batch 02776/04869] [00:31:54/00:24:03, 0.690s/it]: train_loss_raw=2.3258, running_loss=2.3937, LR=0.000100
[2025-08-25 23:36:20,811][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002784] [Batch 02784/04869] [00:32:00/00:23:58, 0.690s/it]: train_loss_raw=2.3790, running_loss=2.3925, LR=0.000100
[2025-08-25 23:36:26,881][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002792] [Batch 02792/04869] [00:32:06/00:23:53, 0.690s/it]: train_loss_raw=2.4384, running_loss=2.3931, LR=0.000100
[2025-08-25 23:36:32,554][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002800] [Batch 02800/04869] [00:32:12/00:23:48, 0.690s/it]: train_loss_raw=2.4672, running_loss=2.3932, LR=0.000100
[2025-08-25 23:36:37,865][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002808] [Batch 02808/04869] [00:32:17/00:23:42, 0.690s/it]: train_loss_raw=2.3513, running_loss=2.3928, LR=0.000100
[2025-08-25 23:36:43,095][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002816] [Batch 02816/04869] [00:32:23/00:23:36, 0.690s/it]: train_loss_raw=2.3200, running_loss=2.3898, LR=0.000100
[2025-08-25 23:36:48,311][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002824] [Batch 02824/04869] [00:32:28/00:23:30, 0.690s/it]: train_loss_raw=2.3581, running_loss=2.3892, LR=0.000100
[2025-08-25 23:36:53,524][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002832] [Batch 02832/04869] [00:32:33/00:23:25, 0.690s/it]: train_loss_raw=2.3871, running_loss=2.3885, LR=0.000100
[2025-08-25 23:36:59,551][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002840] [Batch 02840/04869] [00:32:39/00:23:19, 0.690s/it]: train_loss_raw=2.3983, running_loss=2.3889, LR=0.000100
[2025-08-25 23:37:05,220][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002848] [Batch 02848/04869] [00:32:45/00:23:14, 0.690s/it]: train_loss_raw=2.3470, running_loss=2.3885, LR=0.000100
[2025-08-25 23:37:10,588][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002856] [Batch 02856/04869] [00:32:50/00:23:08, 0.690s/it]: train_loss_raw=2.3907, running_loss=2.3877, LR=0.000100
[2025-08-25 23:37:16,050][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002864] [Batch 02864/04869] [00:32:56/00:23:03, 0.690s/it]: train_loss_raw=2.3471, running_loss=2.3859, LR=0.000100
[2025-08-25 23:37:21,243][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002872] [Batch 02872/04869] [00:33:01/00:22:57, 0.690s/it]: train_loss_raw=2.3946, running_loss=2.3851, LR=0.000100
[2025-08-25 23:37:27,115][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002880] [Batch 02880/04869] [00:33:07/00:22:52, 0.690s/it]: train_loss_raw=2.4115, running_loss=2.3855, LR=0.000100
[2025-08-25 23:37:32,903][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002888] [Batch 02888/04869] [00:33:12/00:22:47, 0.690s/it]: train_loss_raw=2.4120, running_loss=2.3838, LR=0.000100
[2025-08-25 23:37:38,418][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002896] [Batch 02896/04869] [00:33:18/00:22:41, 0.690s/it]: train_loss_raw=2.4070, running_loss=2.3831, LR=0.000100
[2025-08-25 23:37:44,054][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002904] [Batch 02904/04869] [00:33:24/00:22:36, 0.690s/it]: train_loss_raw=2.4119, running_loss=2.3832, LR=0.000100
[2025-08-25 23:37:49,282][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002912] [Batch 02912/04869] [00:33:29/00:22:30, 0.690s/it]: train_loss_raw=2.4266, running_loss=2.3827, LR=0.000100
[2025-08-25 23:37:55,259][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002920] [Batch 02920/04869] [00:33:35/00:22:25, 0.690s/it]: train_loss_raw=2.3691, running_loss=2.3817, LR=0.000100
[2025-08-25 23:38:01,083][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002928] [Batch 02928/04869] [00:33:41/00:22:19, 0.690s/it]: train_loss_raw=2.3080, running_loss=2.3797, LR=0.000100
[2025-08-25 23:38:06,778][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002936] [Batch 02936/04869] [00:33:46/00:22:14, 0.690s/it]: train_loss_raw=2.4566, running_loss=2.3800, LR=0.000100
[2025-08-25 23:38:12,454][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002944] [Batch 02944/04869] [00:33:52/00:22:08, 0.690s/it]: train_loss_raw=2.2863, running_loss=2.3785, LR=0.000100
[2025-08-25 23:38:17,717][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002952] [Batch 02952/04869] [00:33:57/00:22:03, 0.690s/it]: train_loss_raw=2.3837, running_loss=2.3777, LR=0.000100
[2025-08-25 23:38:22,990][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002960] [Batch 02960/04869] [00:34:03/00:21:57, 0.690s/it]: train_loss_raw=2.2961, running_loss=2.3755, LR=0.000100
[2025-08-25 23:38:28,260][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002968] [Batch 02968/04869] [00:34:08/00:21:51, 0.690s/it]: train_loss_raw=2.3359, running_loss=2.3742, LR=0.000100
[2025-08-25 23:38:33,751][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002976] [Batch 02976/04869] [00:34:13/00:21:46, 0.690s/it]: train_loss_raw=2.3501, running_loss=2.3741, LR=0.000100
[2025-08-25 23:38:39,040][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002984] [Batch 02984/04869] [00:34:19/00:21:40, 0.690s/it]: train_loss_raw=2.3815, running_loss=2.3742, LR=0.000100
[2025-08-25 23:38:44,324][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 002992] [Batch 02992/04869] [00:34:24/00:21:35, 0.690s/it]: train_loss_raw=2.3442, running_loss=2.3731, LR=0.000100
[2025-08-25 23:38:50,208][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003000] [Batch 03000/04869] [00:34:30/00:21:29, 0.690s/it]: train_loss_raw=2.3050, running_loss=2.3709, LR=0.000100
[2025-08-25 23:38:55,609][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003008] [Batch 03008/04869] [00:34:35/00:21:24, 0.690s/it]: train_loss_raw=2.3498, running_loss=2.3721, LR=0.000100
[2025-08-25 23:39:01,488][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003016] [Batch 03016/04869] [00:34:41/00:21:18, 0.690s/it]: train_loss_raw=2.3627, running_loss=2.3722, LR=0.000100
[2025-08-25 23:39:07,429][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003024] [Batch 03024/04869] [00:34:47/00:21:13, 0.690s/it]: train_loss_raw=2.3122, running_loss=2.3699, LR=0.000100
[2025-08-25 23:39:13,225][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003032] [Batch 03032/04869] [00:34:53/00:21:08, 0.690s/it]: train_loss_raw=2.4062, running_loss=2.3700, LR=0.000100
[2025-08-25 23:39:18,747][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003040] [Batch 03040/04869] [00:34:58/00:21:02, 0.690s/it]: train_loss_raw=2.3604, running_loss=2.3701, LR=0.000100
[2025-08-25 23:39:24,708][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003048] [Batch 03048/04869] [00:35:04/00:20:57, 0.691s/it]: train_loss_raw=2.2482, running_loss=2.3685, LR=0.000100
[2025-08-25 23:39:30,608][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003056] [Batch 03056/04869] [00:35:10/00:20:52, 0.691s/it]: train_loss_raw=2.3312, running_loss=2.3676, LR=0.000100
[2025-08-25 23:39:36,208][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003064] [Batch 03064/04869] [00:35:16/00:20:46, 0.691s/it]: train_loss_raw=2.3656, running_loss=2.3678, LR=0.000100
[2025-08-25 23:39:41,419][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003072] [Batch 03072/04869] [00:35:21/00:20:40, 0.691s/it]: train_loss_raw=2.4307, running_loss=2.3670, LR=0.000100
[2025-08-25 23:39:47,018][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003080] [Batch 03080/04869] [00:35:27/00:20:35, 0.691s/it]: train_loss_raw=2.3630, running_loss=2.3662, LR=0.000100
[2025-08-25 23:39:52,477][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003088] [Batch 03088/04869] [00:35:32/00:20:29, 0.691s/it]: train_loss_raw=2.2922, running_loss=2.3652, LR=0.000100
[2025-08-25 23:39:58,032][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003096] [Batch 03096/04869] [00:35:38/00:20:24, 0.691s/it]: train_loss_raw=2.3724, running_loss=2.3641, LR=0.000100
[2025-08-25 23:40:03,359][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003104] [Batch 03104/04869] [00:35:43/00:20:18, 0.691s/it]: train_loss_raw=2.3496, running_loss=2.3644, LR=0.000100
[2025-08-25 23:40:08,580][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003112] [Batch 03112/04869] [00:35:48/00:20:13, 0.690s/it]: train_loss_raw=2.3547, running_loss=2.3647, LR=0.000100
[2025-08-25 23:40:14,116][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003120] [Batch 03120/04869] [00:35:54/00:20:07, 0.690s/it]: train_loss_raw=2.3336, running_loss=2.3616, LR=0.000100
[2025-08-25 23:40:19,344][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003128] [Batch 03128/04869] [00:35:59/00:20:01, 0.690s/it]: train_loss_raw=2.3610, running_loss=2.3627, LR=0.000100
[2025-08-25 23:40:24,782][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003136] [Batch 03136/04869] [00:36:04/00:19:56, 0.690s/it]: train_loss_raw=2.3898, running_loss=2.3637, LR=0.000100
[2025-08-25 23:40:30,324][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003144] [Batch 03144/04869] [00:36:10/00:19:50, 0.690s/it]: train_loss_raw=2.3439, running_loss=2.3618, LR=0.000100
[2025-08-25 23:40:35,929][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003152] [Batch 03152/04869] [00:36:15/00:19:45, 0.690s/it]: train_loss_raw=2.3519, running_loss=2.3631, LR=0.000100
[2025-08-25 23:40:41,128][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003160] [Batch 03160/04869] [00:36:21/00:19:39, 0.690s/it]: train_loss_raw=2.3698, running_loss=2.3619, LR=0.000100
[2025-08-25 23:40:46,618][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003168] [Batch 03168/04869] [00:36:26/00:19:34, 0.690s/it]: train_loss_raw=2.3537, running_loss=2.3633, LR=0.000100
[2025-08-25 23:40:51,807][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003176] [Batch 03176/04869] [00:36:31/00:19:28, 0.690s/it]: train_loss_raw=2.2798, running_loss=2.3628, LR=0.000100
[2025-08-25 23:40:57,260][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003184] [Batch 03184/04869] [00:36:37/00:19:22, 0.690s/it]: train_loss_raw=2.4059, running_loss=2.3648, LR=0.000100
[2025-08-25 23:41:03,200][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003192] [Batch 03192/04869] [00:36:43/00:19:17, 0.690s/it]: train_loss_raw=2.3809, running_loss=2.3637, LR=0.000100
[2025-08-25 23:41:08,879][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003200] [Batch 03200/04869] [00:36:48/00:19:12, 0.690s/it]: train_loss_raw=2.3702, running_loss=2.3639, LR=0.000100
[2025-08-25 23:41:14,480][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003208] [Batch 03208/04869] [00:36:54/00:19:06, 0.690s/it]: train_loss_raw=2.3349, running_loss=2.3613, LR=0.000100
[2025-08-25 23:41:19,842][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003216] [Batch 03216/04869] [00:36:59/00:19:00, 0.690s/it]: train_loss_raw=2.3611, running_loss=2.3614, LR=0.000100
[2025-08-25 23:41:25,178][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003224] [Batch 03224/04869] [00:37:05/00:18:55, 0.690s/it]: train_loss_raw=2.3648, running_loss=2.3599, LR=0.000100
[2025-08-25 23:41:30,362][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003232] [Batch 03232/04869] [00:37:10/00:18:49, 0.690s/it]: train_loss_raw=2.3398, running_loss=2.3587, LR=0.000100
[2025-08-25 23:41:36,115][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003240] [Batch 03240/04869] [00:37:16/00:18:44, 0.690s/it]: train_loss_raw=2.4164, running_loss=2.3576, LR=0.000100
[2025-08-25 23:41:41,330][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003248] [Batch 03248/04869] [00:37:21/00:18:38, 0.690s/it]: train_loss_raw=2.3300, running_loss=2.3577, LR=0.000100
[2025-08-25 23:41:46,564][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003256] [Batch 03256/04869] [00:37:26/00:18:32, 0.690s/it]: train_loss_raw=2.3391, running_loss=2.3574, LR=0.000100
[2025-08-25 23:41:52,542][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003264] [Batch 03264/04869] [00:37:32/00:18:27, 0.690s/it]: train_loss_raw=2.3709, running_loss=2.3595, LR=0.000100
[2025-08-25 23:41:57,727][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003272] [Batch 03272/04869] [00:37:37/00:18:21, 0.690s/it]: train_loss_raw=2.4163, running_loss=2.3592, LR=0.000100
[2025-08-25 23:42:03,030][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003280] [Batch 03280/04869] [00:37:43/00:18:16, 0.690s/it]: train_loss_raw=2.3001, running_loss=2.3581, LR=0.000100
[2025-08-25 23:42:08,494][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003288] [Batch 03288/04869] [00:37:48/00:18:10, 0.690s/it]: train_loss_raw=2.3356, running_loss=2.3565, LR=0.000100
[2025-08-25 23:42:13,861][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003296] [Batch 03296/04869] [00:37:53/00:18:05, 0.690s/it]: train_loss_raw=2.4348, running_loss=2.3564, LR=0.000100
[2025-08-25 23:42:19,190][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003304] [Batch 03304/04869] [00:37:59/00:17:59, 0.690s/it]: train_loss_raw=2.3247, running_loss=2.3542, LR=0.000100
[2025-08-25 23:42:24,564][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003312] [Batch 03312/04869] [00:38:04/00:17:54, 0.690s/it]: train_loss_raw=2.3824, running_loss=2.3529, LR=0.000100
[2025-08-25 23:42:29,939][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003320] [Batch 03320/04869] [00:38:09/00:17:48, 0.690s/it]: train_loss_raw=2.2750, running_loss=2.3521, LR=0.000100
[2025-08-25 23:42:35,312][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003328] [Batch 03328/04869] [00:38:15/00:17:42, 0.690s/it]: train_loss_raw=2.3862, running_loss=2.3521, LR=0.000100
[2025-08-25 23:42:40,688][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003336] [Batch 03336/04869] [00:38:20/00:17:37, 0.690s/it]: train_loss_raw=2.3200, running_loss=2.3515, LR=0.000100
[2025-08-25 23:42:46,121][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003344] [Batch 03344/04869] [00:38:26/00:17:31, 0.690s/it]: train_loss_raw=2.3546, running_loss=2.3501, LR=0.000100
[2025-08-25 23:42:51,645][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003352] [Batch 03352/04869] [00:38:31/00:17:26, 0.690s/it]: train_loss_raw=2.4000, running_loss=2.3498, LR=0.000100
[2025-08-25 23:42:56,952][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003360] [Batch 03360/04869] [00:38:36/00:17:20, 0.690s/it]: train_loss_raw=2.3339, running_loss=2.3489, LR=0.000100
[2025-08-25 23:43:02,625][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003368] [Batch 03368/04869] [00:38:42/00:17:15, 0.690s/it]: train_loss_raw=2.3185, running_loss=2.3476, LR=0.000100
[2025-08-25 23:43:08,232][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003376] [Batch 03376/04869] [00:38:48/00:17:09, 0.690s/it]: train_loss_raw=2.2816, running_loss=2.3454, LR=0.000100
[2025-08-25 23:43:14,142][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003384] [Batch 03384/04869] [00:38:54/00:17:04, 0.690s/it]: train_loss_raw=2.3816, running_loss=2.3450, LR=0.000100
[2025-08-25 23:43:19,406][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003392] [Batch 03392/04869] [00:38:59/00:16:58, 0.690s/it]: train_loss_raw=2.3872, running_loss=2.3442, LR=0.000100
[2025-08-25 23:43:24,790][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003400] [Batch 03400/04869] [00:39:04/00:16:53, 0.690s/it]: train_loss_raw=2.2723, running_loss=2.3417, LR=0.000100
[2025-08-25 23:43:30,005][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003408] [Batch 03408/04869] [00:39:10/00:16:47, 0.690s/it]: train_loss_raw=2.2805, running_loss=2.3427, LR=0.000100
[2025-08-25 23:43:35,532][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003416] [Batch 03416/04869] [00:39:15/00:16:41, 0.690s/it]: train_loss_raw=2.3765, running_loss=2.3420, LR=0.000100
[2025-08-25 23:43:40,727][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003424] [Batch 03424/04869] [00:39:20/00:16:36, 0.689s/it]: train_loss_raw=2.4097, running_loss=2.3412, LR=0.000100
[2025-08-25 23:43:46,597][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003432] [Batch 03432/04869] [00:39:26/00:16:30, 0.690s/it]: train_loss_raw=2.2943, running_loss=2.3394, LR=0.000100
[2025-08-25 23:43:52,118][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003440] [Batch 03440/04869] [00:39:32/00:16:25, 0.690s/it]: train_loss_raw=2.3225, running_loss=2.3398, LR=0.000100
[2025-08-25 23:43:57,543][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003448] [Batch 03448/04869] [00:39:37/00:16:19, 0.690s/it]: train_loss_raw=2.3274, running_loss=2.3394, LR=0.000100
[2025-08-25 23:44:03,065][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003456] [Batch 03456/04869] [00:39:43/00:16:14, 0.690s/it]: train_loss_raw=2.3466, running_loss=2.3383, LR=0.000100
[2025-08-25 23:44:08,419][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003464] [Batch 03464/04869] [00:39:48/00:16:08, 0.690s/it]: train_loss_raw=2.3496, running_loss=2.3371, LR=0.000100
[2025-08-25 23:44:14,238][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003472] [Batch 03472/04869] [00:39:54/00:16:03, 0.690s/it]: train_loss_raw=2.4040, running_loss=2.3382, LR=0.000100
[2025-08-25 23:44:19,440][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003480] [Batch 03480/04869] [00:39:59/00:15:57, 0.690s/it]: train_loss_raw=2.4080, running_loss=2.3377, LR=0.000100
[2025-08-25 23:44:24,645][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003488] [Batch 03488/04869] [00:40:04/00:15:52, 0.689s/it]: train_loss_raw=2.3365, running_loss=2.3381, LR=0.000100
[2025-08-25 23:44:30,527][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003496] [Batch 03496/04869] [00:40:10/00:15:46, 0.690s/it]: train_loss_raw=2.3980, running_loss=2.3383, LR=0.000100
[2025-08-25 23:44:35,756][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003504] [Batch 03504/04869] [00:40:15/00:15:41, 0.689s/it]: train_loss_raw=2.3562, running_loss=2.3382, LR=0.000100
[2025-08-25 23:44:40,998][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003512] [Batch 03512/04869] [00:40:21/00:15:35, 0.689s/it]: train_loss_raw=2.2732, running_loss=2.3375, LR=0.000100
[2025-08-25 23:44:46,744][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003520] [Batch 03520/04869] [00:40:26/00:15:30, 0.689s/it]: train_loss_raw=2.2263, running_loss=2.3361, LR=0.000100
[2025-08-25 23:44:51,957][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003528] [Batch 03528/04869] [00:40:31/00:15:24, 0.689s/it]: train_loss_raw=2.3415, running_loss=2.3336, LR=0.000100
[2025-08-25 23:44:57,163][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003536] [Batch 03536/04869] [00:40:37/00:15:18, 0.689s/it]: train_loss_raw=2.3418, running_loss=2.3347, LR=0.000100
[2025-08-25 23:45:03,109][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003544] [Batch 03544/04869] [00:40:43/00:15:13, 0.689s/it]: train_loss_raw=2.3166, running_loss=2.3335, LR=0.000100
[2025-08-25 23:45:08,650][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003552] [Batch 03552/04869] [00:40:48/00:15:07, 0.689s/it]: train_loss_raw=2.3418, running_loss=2.3337, LR=0.000100
[2025-08-25 23:45:13,874][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003560] [Batch 03560/04869] [00:40:53/00:15:02, 0.689s/it]: train_loss_raw=2.2783, running_loss=2.3330, LR=0.000100
[2025-08-25 23:45:19,457][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003568] [Batch 03568/04869] [00:40:59/00:14:56, 0.689s/it]: train_loss_raw=2.2971, running_loss=2.3305, LR=0.000100
[2025-08-25 23:45:24,958][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003576] [Batch 03576/04869] [00:41:04/00:14:51, 0.689s/it]: train_loss_raw=2.3446, running_loss=2.3303, LR=0.000100
[2025-08-25 23:45:31,182][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003584] [Batch 03584/04869] [00:41:11/00:14:46, 0.690s/it]: train_loss_raw=2.3064, running_loss=2.3289, LR=0.000100
[2025-08-25 23:45:36,725][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003592] [Batch 03592/04869] [00:41:16/00:14:40, 0.690s/it]: train_loss_raw=2.3186, running_loss=2.3288, LR=0.000100
[2025-08-25 23:45:42,898][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003600] [Batch 03600/04869] [00:41:22/00:14:35, 0.690s/it]: train_loss_raw=2.3117, running_loss=2.3272, LR=0.000100
[2025-08-25 23:45:48,364][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003608] [Batch 03608/04869] [00:41:28/00:14:29, 0.690s/it]: train_loss_raw=2.4391, running_loss=2.3296, LR=0.000100
[2025-08-25 23:45:53,789][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003616] [Batch 03616/04869] [00:41:33/00:14:24, 0.690s/it]: train_loss_raw=2.3107, running_loss=2.3302, LR=0.000100
[2025-08-25 23:45:59,411][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003624] [Batch 03624/04869] [00:41:39/00:14:18, 0.690s/it]: train_loss_raw=2.3778, running_loss=2.3293, LR=0.000100
[2025-08-25 23:46:05,388][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003632] [Batch 03632/04869] [00:41:45/00:14:13, 0.690s/it]: train_loss_raw=2.3032, running_loss=2.3297, LR=0.000100
[2025-08-25 23:46:10,915][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003640] [Batch 03640/04869] [00:41:50/00:14:07, 0.690s/it]: train_loss_raw=2.3601, running_loss=2.3297, LR=0.000100
[2025-08-25 23:46:16,990][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003648] [Batch 03648/04869] [00:41:57/00:14:02, 0.690s/it]: train_loss_raw=2.2735, running_loss=2.3281, LR=0.000100
[2025-08-25 23:46:22,320][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003656] [Batch 03656/04869] [00:42:02/00:13:56, 0.690s/it]: train_loss_raw=2.3095, running_loss=2.3261, LR=0.000100
[2025-08-25 23:46:27,514][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003664] [Batch 03664/04869] [00:42:07/00:13:51, 0.690s/it]: train_loss_raw=2.2733, running_loss=2.3254, LR=0.000100
[2025-08-25 23:46:32,719][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003672] [Batch 03672/04869] [00:42:12/00:13:45, 0.690s/it]: train_loss_raw=2.3157, running_loss=2.3258, LR=0.000100
[2025-08-25 23:46:37,964][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003680] [Batch 03680/04869] [00:42:17/00:13:40, 0.690s/it]: train_loss_raw=2.3292, running_loss=2.3252, LR=0.000100
[2025-08-25 23:46:43,401][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003688] [Batch 03688/04869] [00:42:23/00:13:34, 0.690s/it]: train_loss_raw=2.3203, running_loss=2.3243, LR=0.000100
[2025-08-25 23:46:49,123][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003696] [Batch 03696/04869] [00:42:29/00:13:29, 0.690s/it]: train_loss_raw=2.3482, running_loss=2.3221, LR=0.000100
[2025-08-25 23:46:54,710][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003704] [Batch 03704/04869] [00:42:34/00:13:23, 0.690s/it]: train_loss_raw=2.3657, running_loss=2.3238, LR=0.000100
[2025-08-25 23:47:00,040][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003712] [Batch 03712/04869] [00:42:40/00:13:17, 0.690s/it]: train_loss_raw=2.2695, running_loss=2.3222, LR=0.000100
[2025-08-25 23:47:05,257][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003720] [Batch 03720/04869] [00:42:45/00:13:12, 0.690s/it]: train_loss_raw=2.3737, running_loss=2.3228, LR=0.000100
[2025-08-25 23:47:10,671][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003728] [Batch 03728/04869] [00:42:50/00:13:06, 0.690s/it]: train_loss_raw=2.3493, running_loss=2.3209, LR=0.000100
[2025-08-25 23:47:15,871][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003736] [Batch 03736/04869] [00:42:55/00:13:01, 0.689s/it]: train_loss_raw=2.3097, running_loss=2.3185, LR=0.000100
[2025-08-25 23:47:21,525][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003744] [Batch 03744/04869] [00:43:01/00:12:55, 0.690s/it]: train_loss_raw=2.2440, running_loss=2.3169, LR=0.000100
[2025-08-25 23:47:27,425][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003752] [Batch 03752/04869] [00:43:07/00:12:50, 0.690s/it]: train_loss_raw=2.3942, running_loss=2.3162, LR=0.000100
[2025-08-25 23:47:32,962][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003760] [Batch 03760/04869] [00:43:12/00:12:44, 0.690s/it]: train_loss_raw=2.3467, running_loss=2.3166, LR=0.000100
[2025-08-25 23:47:38,883][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003768] [Batch 03768/04869] [00:43:18/00:12:39, 0.690s/it]: train_loss_raw=2.2478, running_loss=2.3130, LR=0.000100
[2025-08-25 23:47:44,843][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003776] [Batch 03776/04869] [00:43:24/00:12:34, 0.690s/it]: train_loss_raw=2.3054, running_loss=2.3129, LR=0.000100
[2025-08-25 23:47:50,805][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003784] [Batch 03784/04869] [00:43:30/00:12:28, 0.690s/it]: train_loss_raw=2.3244, running_loss=2.3104, LR=0.000100
[2025-08-25 23:47:56,091][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003792] [Batch 03792/04869] [00:43:36/00:12:23, 0.690s/it]: train_loss_raw=2.2803, running_loss=2.3083, LR=0.000100
[2025-08-25 23:48:01,681][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003800] [Batch 03800/04869] [00:43:41/00:12:17, 0.690s/it]: train_loss_raw=2.3964, running_loss=2.3084, LR=0.000100
[2025-08-25 23:48:07,661][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003808] [Batch 03808/04869] [00:43:47/00:12:12, 0.690s/it]: train_loss_raw=2.3857, running_loss=2.3083, LR=0.000100
[2025-08-25 23:48:13,612][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003816] [Batch 03816/04869] [00:43:53/00:12:06, 0.690s/it]: train_loss_raw=2.3589, running_loss=2.3079, LR=0.000100
[2025-08-25 23:48:19,271][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003824] [Batch 03824/04869] [00:43:59/00:12:01, 0.690s/it]: train_loss_raw=2.3120, running_loss=2.3067, LR=0.000100
[2025-08-25 23:48:24,566][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003832] [Batch 03832/04869] [00:44:04/00:11:55, 0.690s/it]: train_loss_raw=2.2795, running_loss=2.3076, LR=0.000100
[2025-08-25 23:48:30,144][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003840] [Batch 03840/04869] [00:44:10/00:11:50, 0.690s/it]: train_loss_raw=2.2425, running_loss=2.3081, LR=0.000100
[2025-08-25 23:48:35,567][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003848] [Batch 03848/04869] [00:44:15/00:11:44, 0.690s/it]: train_loss_raw=2.2806, running_loss=2.3079, LR=0.000100
[2025-08-25 23:48:41,022][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003856] [Batch 03856/04869] [00:44:21/00:11:39, 0.690s/it]: train_loss_raw=2.3421, running_loss=2.3064, LR=0.000100
[2025-08-25 23:48:54,183][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003864] [Batch 03864/04869] [00:44:34/00:11:35, 0.692s/it]: train_loss_raw=2.2750, running_loss=2.3077, LR=0.000100
[2025-08-25 23:48:59,473][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003872] [Batch 03872/04869] [00:44:39/00:11:29, 0.692s/it]: train_loss_raw=2.3169, running_loss=2.3057, LR=0.000100
[2025-08-25 23:49:04,928][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003880] [Batch 03880/04869] [00:44:44/00:11:24, 0.692s/it]: train_loss_raw=2.2662, running_loss=2.3050, LR=0.000100
[2025-08-25 23:49:10,301][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003888] [Batch 03888/04869] [00:44:50/00:11:18, 0.692s/it]: train_loss_raw=2.3362, running_loss=2.3039, LR=0.000100
[2025-08-25 23:49:15,768][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003896] [Batch 03896/04869] [00:44:55/00:11:13, 0.692s/it]: train_loss_raw=2.3230, running_loss=2.3042, LR=0.000100
[2025-08-25 23:49:21,965][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003904] [Batch 03904/04869] [00:45:01/00:11:07, 0.692s/it]: train_loss_raw=2.3071, running_loss=2.3064, LR=0.000100
[2025-08-25 23:49:27,684][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003912] [Batch 03912/04869] [00:45:07/00:11:02, 0.692s/it]: train_loss_raw=2.3689, running_loss=2.3062, LR=0.000100
[2025-08-25 23:49:32,932][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003920] [Batch 03920/04869] [00:45:12/00:10:56, 0.692s/it]: train_loss_raw=2.2401, running_loss=2.3040, LR=0.000100
[2025-08-25 23:49:38,141][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003928] [Batch 03928/04869] [00:45:18/00:10:51, 0.692s/it]: train_loss_raw=2.2785, running_loss=2.3030, LR=0.000100
[2025-08-25 23:49:43,620][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003936] [Batch 03936/04869] [00:45:23/00:10:45, 0.692s/it]: train_loss_raw=2.3236, running_loss=2.3032, LR=0.000100
[2025-08-25 23:49:49,465][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003944] [Batch 03944/04869] [00:45:29/00:10:40, 0.692s/it]: train_loss_raw=2.3161, running_loss=2.3020, LR=0.000100
[2025-08-25 23:49:55,489][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003952] [Batch 03952/04869] [00:45:35/00:10:34, 0.692s/it]: train_loss_raw=2.2788, running_loss=2.3031, LR=0.000100
[2025-08-25 23:50:00,687][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003960] [Batch 03960/04869] [00:45:40/00:10:29, 0.692s/it]: train_loss_raw=2.2794, running_loss=2.3035, LR=0.000100
[2025-08-25 23:50:06,092][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003968] [Batch 03968/04869] [00:45:46/00:10:23, 0.692s/it]: train_loss_raw=2.3330, running_loss=2.3011, LR=0.000100
[2025-08-25 23:50:11,524][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003976] [Batch 03976/04869] [00:45:51/00:10:17, 0.692s/it]: train_loss_raw=2.2956, running_loss=2.2998, LR=0.000100
[2025-08-25 23:50:16,924][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003984] [Batch 03984/04869] [00:45:56/00:10:12, 0.692s/it]: train_loss_raw=2.2342, running_loss=2.2999, LR=0.000100
[2025-08-25 23:50:22,125][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 003992] [Batch 03992/04869] [00:46:02/00:10:06, 0.692s/it]: train_loss_raw=2.2966, running_loss=2.2997, LR=0.000100
[2025-08-25 23:50:27,598][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004000] [Batch 04000/04869] [00:46:07/00:10:01, 0.692s/it]: train_loss_raw=2.2457, running_loss=2.3005, LR=0.000100
[2025-08-25 23:50:37,212][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004008] [Batch 04008/04869] [00:46:17/00:09:56, 0.693s/it]: train_loss_raw=2.3244, running_loss=2.2988, LR=0.000100
[2025-08-25 23:50:43,428][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004016] [Batch 04016/04869] [00:46:23/00:09:51, 0.693s/it]: train_loss_raw=2.2871, running_loss=2.2983, LR=0.000100
[2025-08-25 23:50:49,265][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004024] [Batch 04024/04869] [00:46:29/00:09:45, 0.693s/it]: train_loss_raw=2.3016, running_loss=2.2998, LR=0.000100
[2025-08-25 23:50:54,792][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004032] [Batch 04032/04869] [00:46:34/00:09:40, 0.693s/it]: train_loss_raw=2.2995, running_loss=2.2979, LR=0.000100
[2025-08-25 23:51:00,003][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004040] [Batch 04040/04869] [00:46:40/00:09:34, 0.693s/it]: train_loss_raw=2.3555, running_loss=2.2981, LR=0.000100
[2025-08-25 23:51:05,370][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004048] [Batch 04048/04869] [00:46:45/00:09:28, 0.693s/it]: train_loss_raw=2.3404, running_loss=2.2994, LR=0.000100
[2025-08-25 23:51:11,260][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004056] [Batch 04056/04869] [00:46:51/00:09:23, 0.693s/it]: train_loss_raw=2.2132, running_loss=2.2979, LR=0.000100
[2025-08-25 23:51:16,578][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004064] [Batch 04064/04869] [00:46:56/00:09:17, 0.693s/it]: train_loss_raw=2.3140, running_loss=2.2977, LR=0.000100
[2025-08-25 23:51:22,230][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004072] [Batch 04072/04869] [00:47:02/00:09:12, 0.693s/it]: train_loss_raw=2.3273, running_loss=2.2979, LR=0.000100
[2025-08-25 23:51:27,865][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004080] [Batch 04080/04869] [00:47:07/00:09:06, 0.693s/it]: train_loss_raw=2.2470, running_loss=2.2958, LR=0.000100
[2025-08-25 23:51:33,080][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004088] [Batch 04088/04869] [00:47:13/00:09:01, 0.693s/it]: train_loss_raw=2.2462, running_loss=2.2937, LR=0.000100
[2025-08-25 23:51:38,276][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004096] [Batch 04096/04869] [00:47:18/00:08:55, 0.693s/it]: train_loss_raw=2.2752, running_loss=2.2932, LR=0.000100
[2025-08-25 23:51:44,411][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004104] [Batch 04104/04869] [00:47:24/00:08:50, 0.693s/it]: train_loss_raw=2.2789, running_loss=2.2914, LR=0.000100
[2025-08-25 23:51:50,073][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004112] [Batch 04112/04869] [00:47:30/00:08:44, 0.693s/it]: train_loss_raw=2.2391, running_loss=2.2929, LR=0.000100
[2025-08-25 23:51:55,270][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004120] [Batch 04120/04869] [00:47:35/00:08:39, 0.693s/it]: train_loss_raw=2.2202, running_loss=2.2916, LR=0.000100
[2025-08-25 23:52:01,040][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004128] [Batch 04128/04869] [00:47:41/00:08:33, 0.693s/it]: train_loss_raw=2.3115, running_loss=2.2917, LR=0.000100
[2025-08-25 23:52:06,431][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004136] [Batch 04136/04869] [00:47:46/00:08:28, 0.693s/it]: train_loss_raw=2.2569, running_loss=2.2913, LR=0.000100
[2025-08-25 23:52:12,358][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004144] [Batch 04144/04869] [00:47:52/00:08:22, 0.693s/it]: train_loss_raw=2.1757, running_loss=2.2910, LR=0.000100
[2025-08-25 23:52:18,245][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004152] [Batch 04152/04869] [00:47:58/00:08:17, 0.693s/it]: train_loss_raw=2.2719, running_loss=2.2891, LR=0.000100
[2025-08-25 23:52:23,461][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004160] [Batch 04160/04869] [00:48:03/00:08:11, 0.693s/it]: train_loss_raw=2.2523, running_loss=2.2899, LR=0.000100
[2025-08-25 23:52:28,680][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004168] [Batch 04168/04869] [00:48:08/00:08:05, 0.693s/it]: train_loss_raw=2.3218, running_loss=2.2889, LR=0.000100
[2025-08-25 23:52:33,885][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004176] [Batch 04176/04869] [00:48:13/00:08:00, 0.693s/it]: train_loss_raw=2.2623, running_loss=2.2890, LR=0.000100
[2025-08-25 23:52:39,098][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004184] [Batch 04184/04869] [00:48:19/00:07:54, 0.693s/it]: train_loss_raw=2.3253, running_loss=2.2861, LR=0.000100
[2025-08-25 23:52:44,312][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004192] [Batch 04192/04869] [00:48:24/00:07:49, 0.693s/it]: train_loss_raw=2.2683, running_loss=2.2855, LR=0.000100
[2025-08-25 23:52:49,523][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004200] [Batch 04200/04869] [00:48:29/00:07:43, 0.693s/it]: train_loss_raw=2.2737, running_loss=2.2856, LR=0.000100
[2025-08-25 23:52:55,173][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004208] [Batch 04208/04869] [00:48:35/00:07:37, 0.693s/it]: train_loss_raw=2.2996, running_loss=2.2865, LR=0.000100
[2025-08-25 23:53:00,516][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004216] [Batch 04216/04869] [00:48:40/00:07:32, 0.693s/it]: train_loss_raw=2.2899, running_loss=2.2864, LR=0.000100
[2025-08-25 23:53:05,752][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004224] [Batch 04224/04869] [00:48:45/00:07:26, 0.693s/it]: train_loss_raw=2.2449, running_loss=2.2868, LR=0.000100
[2025-08-25 23:53:11,448][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004232] [Batch 04232/04869] [00:48:51/00:07:21, 0.693s/it]: train_loss_raw=2.2550, running_loss=2.2863, LR=0.000100
[2025-08-25 23:53:16,683][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004240] [Batch 04240/04869] [00:48:56/00:07:15, 0.693s/it]: train_loss_raw=2.3144, running_loss=2.2883, LR=0.000100
[2025-08-25 23:53:21,939][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004248] [Batch 04248/04869] [00:49:01/00:07:10, 0.693s/it]: train_loss_raw=2.2498, running_loss=2.2875, LR=0.000100
[2025-08-25 23:53:27,169][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004256] [Batch 04256/04869] [00:49:07/00:07:04, 0.692s/it]: train_loss_raw=2.3288, running_loss=2.2874, LR=0.000100
[2025-08-25 23:53:32,565][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004264] [Batch 04264/04869] [00:49:12/00:06:58, 0.692s/it]: train_loss_raw=2.2608, running_loss=2.2877, LR=0.000100
[2025-08-25 23:53:38,482][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004272] [Batch 04272/04869] [00:49:18/00:06:53, 0.693s/it]: train_loss_raw=2.2547, running_loss=2.2863, LR=0.000100
[2025-08-25 23:53:44,059][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004280] [Batch 04280/04869] [00:49:24/00:06:47, 0.693s/it]: train_loss_raw=2.3293, running_loss=2.2860, LR=0.000100
[2025-08-25 23:53:49,306][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004288] [Batch 04288/04869] [00:49:29/00:06:42, 0.692s/it]: train_loss_raw=2.2634, running_loss=2.2857, LR=0.000100
[2025-08-25 23:53:54,520][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004296] [Batch 04296/04869] [00:49:34/00:06:36, 0.692s/it]: train_loss_raw=2.2412, running_loss=2.2835, LR=0.000100
[2025-08-25 23:54:00,171][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004304] [Batch 04304/04869] [00:49:40/00:06:31, 0.692s/it]: train_loss_raw=2.2984, running_loss=2.2822, LR=0.000100
[2025-08-25 23:54:05,539][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004312] [Batch 04312/04869] [00:49:45/00:06:25, 0.692s/it]: train_loss_raw=2.3510, running_loss=2.2826, LR=0.000100
[2025-08-25 23:54:10,753][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004320] [Batch 04320/04869] [00:49:50/00:06:20, 0.692s/it]: train_loss_raw=2.2435, running_loss=2.2829, LR=0.000100
[2025-08-25 23:54:16,063][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004328] [Batch 04328/04869] [00:49:56/00:06:14, 0.692s/it]: train_loss_raw=2.2852, running_loss=2.2816, LR=0.000100
[2025-08-25 23:54:21,618][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004336] [Batch 04336/04869] [00:50:01/00:06:08, 0.692s/it]: train_loss_raw=2.2975, running_loss=2.2812, LR=0.000100
[2025-08-25 23:54:26,952][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004344] [Batch 04344/04869] [00:50:06/00:06:03, 0.692s/it]: train_loss_raw=2.2628, running_loss=2.2794, LR=0.000100
[2025-08-25 23:54:32,261][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004352] [Batch 04352/04869] [00:50:12/00:05:57, 0.692s/it]: train_loss_raw=2.3208, running_loss=2.2800, LR=0.000100
[2025-08-25 23:54:37,509][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004360] [Batch 04360/04869] [00:50:17/00:05:52, 0.692s/it]: train_loss_raw=2.2594, running_loss=2.2793, LR=0.000100
[2025-08-25 23:54:43,178][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004368] [Batch 04368/04869] [00:50:23/00:05:46, 0.692s/it]: train_loss_raw=2.2109, running_loss=2.2783, LR=0.000100
[2025-08-25 23:54:48,794][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004376] [Batch 04376/04869] [00:50:28/00:05:41, 0.692s/it]: train_loss_raw=2.2997, running_loss=2.2771, LR=0.000100
[2025-08-25 23:54:54,156][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004384] [Batch 04384/04869] [00:50:34/00:05:35, 0.692s/it]: train_loss_raw=2.2671, running_loss=2.2771, LR=0.000100
[2025-08-25 23:54:59,480][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004392] [Batch 04392/04869] [00:50:39/00:05:30, 0.692s/it]: train_loss_raw=2.3433, running_loss=2.2771, LR=0.000100
[2025-08-25 23:55:04,859][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004400] [Batch 04400/04869] [00:50:44/00:05:24, 0.692s/it]: train_loss_raw=2.2875, running_loss=2.2763, LR=0.000100
[2025-08-25 23:55:10,182][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004408] [Batch 04408/04869] [00:50:50/00:05:18, 0.692s/it]: train_loss_raw=2.2581, running_loss=2.2757, LR=0.000100
[2025-08-25 23:55:16,183][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004416] [Batch 04416/04869] [00:50:56/00:05:13, 0.692s/it]: train_loss_raw=2.3032, running_loss=2.2750, LR=0.000100
[2025-08-25 23:55:21,948][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004424] [Batch 04424/04869] [00:51:01/00:05:07, 0.692s/it]: train_loss_raw=2.2698, running_loss=2.2742, LR=0.000100
[2025-08-25 23:55:27,785][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004432] [Batch 04432/04869] [00:51:07/00:05:02, 0.692s/it]: train_loss_raw=2.2440, running_loss=2.2740, LR=0.000100
[2025-08-25 23:55:33,179][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004440] [Batch 04440/04869] [00:51:13/00:04:56, 0.692s/it]: train_loss_raw=2.2873, running_loss=2.2741, LR=0.000100
[2025-08-25 23:55:38,566][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004448] [Batch 04448/04869] [00:51:18/00:04:51, 0.692s/it]: train_loss_raw=2.3471, running_loss=2.2727, LR=0.000100
[2025-08-25 23:55:43,802][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004456] [Batch 04456/04869] [00:51:23/00:04:45, 0.692s/it]: train_loss_raw=2.2347, running_loss=2.2739, LR=0.000100
[2025-08-25 23:55:49,309][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004464] [Batch 04464/04869] [00:51:29/00:04:40, 0.692s/it]: train_loss_raw=2.2488, running_loss=2.2726, LR=0.000100
[2025-08-25 23:55:54,815][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004472] [Batch 04472/04869] [00:51:34/00:04:34, 0.692s/it]: train_loss_raw=2.2644, running_loss=2.2727, LR=0.000100
[2025-08-25 23:56:00,219][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004480] [Batch 04480/04869] [00:51:40/00:04:29, 0.692s/it]: train_loss_raw=2.2311, running_loss=2.2705, LR=0.000100
[2025-08-25 23:56:05,498][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004488] [Batch 04488/04869] [00:51:45/00:04:23, 0.692s/it]: train_loss_raw=2.3415, running_loss=2.2712, LR=0.000100
[2025-08-25 23:56:10,678][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004496] [Batch 04496/04869] [00:51:50/00:04:18, 0.692s/it]: train_loss_raw=2.3191, running_loss=2.2724, LR=0.000100
[2025-08-25 23:56:16,355][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004504] [Batch 04504/04869] [00:51:56/00:04:12, 0.692s/it]: train_loss_raw=2.2333, running_loss=2.2708, LR=0.000100
[2025-08-25 23:56:22,319][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004512] [Batch 04512/04869] [00:52:02/00:04:07, 0.692s/it]: train_loss_raw=2.2402, running_loss=2.2698, LR=0.000100
[2025-08-25 23:56:28,108][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004520] [Batch 04520/04869] [00:52:08/00:04:01, 0.692s/it]: train_loss_raw=2.3135, running_loss=2.2700, LR=0.000100
[2025-08-25 23:56:33,773][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004528] [Batch 04528/04869] [00:52:13/00:03:56, 0.692s/it]: train_loss_raw=2.2151, running_loss=2.2698, LR=0.000100
[2025-08-25 23:56:38,984][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004536] [Batch 04536/04869] [00:52:19/00:03:50, 0.692s/it]: train_loss_raw=2.2218, running_loss=2.2700, LR=0.000100
[2025-08-25 23:56:44,179][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004544] [Batch 04544/04869] [00:52:24/00:03:44, 0.692s/it]: train_loss_raw=2.2438, running_loss=2.2679, LR=0.000100
[2025-08-25 23:56:49,344][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004552] [Batch 04552/04869] [00:52:29/00:03:39, 0.692s/it]: train_loss_raw=2.2482, running_loss=2.2677, LR=0.000100
[2025-08-25 23:56:54,543][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004560] [Batch 04560/04869] [00:52:34/00:03:33, 0.692s/it]: train_loss_raw=2.1788, running_loss=2.2671, LR=0.000100
[2025-08-25 23:57:00,268][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004568] [Batch 04568/04869] [00:52:40/00:03:28, 0.692s/it]: train_loss_raw=2.2997, running_loss=2.2655, LR=0.000100
[2025-08-25 23:57:05,533][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004576] [Batch 04576/04869] [00:52:45/00:03:22, 0.692s/it]: train_loss_raw=2.3117, running_loss=2.2653, LR=0.000100
[2025-08-25 23:57:10,778][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004584] [Batch 04584/04869] [00:52:50/00:03:17, 0.692s/it]: train_loss_raw=2.2691, running_loss=2.2656, LR=0.000100
[2025-08-25 23:57:16,204][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004592] [Batch 04592/04869] [00:52:56/00:03:11, 0.692s/it]: train_loss_raw=2.3142, running_loss=2.2669, LR=0.000100
[2025-08-25 23:57:21,762][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004600] [Batch 04600/04869] [00:53:01/00:03:06, 0.692s/it]: train_loss_raw=2.3021, running_loss=2.2675, LR=0.000100
[2025-08-25 23:57:26,981][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004608] [Batch 04608/04869] [00:53:07/00:03:00, 0.692s/it]: train_loss_raw=2.2397, running_loss=2.2656, LR=0.000100
[2025-08-25 23:57:32,534][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004616] [Batch 04616/04869] [00:53:12/00:02:54, 0.692s/it]: train_loss_raw=2.2457, running_loss=2.2649, LR=0.000100
[2025-08-25 23:57:37,727][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004624] [Batch 04624/04869] [00:53:17/00:02:49, 0.692s/it]: train_loss_raw=2.2340, running_loss=2.2615, LR=0.000100
[2025-08-25 23:57:43,276][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004632] [Batch 04632/04869] [00:53:23/00:02:43, 0.692s/it]: train_loss_raw=2.2702, running_loss=2.2606, LR=0.000100
[2025-08-25 23:57:48,531][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004640] [Batch 04640/04869] [00:53:28/00:02:38, 0.691s/it]: train_loss_raw=2.3119, running_loss=2.2603, LR=0.000100
[2025-08-25 23:57:54,079][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004648] [Batch 04648/04869] [00:53:34/00:02:32, 0.692s/it]: train_loss_raw=2.2253, running_loss=2.2583, LR=0.000100
[2025-08-25 23:57:59,700][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004656] [Batch 04656/04869] [00:53:39/00:02:27, 0.692s/it]: train_loss_raw=2.2888, running_loss=2.2602, LR=0.000100
[2025-08-25 23:58:05,464][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004664] [Batch 04664/04869] [00:53:45/00:02:21, 0.692s/it]: train_loss_raw=2.2478, running_loss=2.2600, LR=0.000100
[2025-08-25 23:58:10,654][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004672] [Batch 04672/04869] [00:53:50/00:02:16, 0.691s/it]: train_loss_raw=2.2082, running_loss=2.2595, LR=0.000100
[2025-08-25 23:58:16,196][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004680] [Batch 04680/04869] [00:53:56/00:02:10, 0.692s/it]: train_loss_raw=2.2170, running_loss=2.2605, LR=0.000100
[2025-08-25 23:58:21,744][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004688] [Batch 04688/04869] [00:54:01/00:02:05, 0.692s/it]: train_loss_raw=2.3154, running_loss=2.2609, LR=0.000100
[2025-08-25 23:58:26,955][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004696] [Batch 04696/04869] [00:54:06/00:01:59, 0.691s/it]: train_loss_raw=2.2287, running_loss=2.2582, LR=0.000100
[2025-08-25 23:58:32,339][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004704] [Batch 04704/04869] [00:54:12/00:01:54, 0.691s/it]: train_loss_raw=2.2474, running_loss=2.2554, LR=0.000100
[2025-08-25 23:58:37,996][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004712] [Batch 04712/04869] [00:54:18/00:01:48, 0.691s/it]: train_loss_raw=2.2702, running_loss=2.2560, LR=0.000100
[2025-08-25 23:58:43,594][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004720] [Batch 04720/04869] [00:54:23/00:01:43, 0.691s/it]: train_loss_raw=2.1845, running_loss=2.2555, LR=0.000100
[2025-08-25 23:58:49,326][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004728] [Batch 04728/04869] [00:54:29/00:01:37, 0.691s/it]: train_loss_raw=2.2568, running_loss=2.2551, LR=0.000100
[2025-08-25 23:58:55,496][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004736] [Batch 04736/04869] [00:54:35/00:01:31, 0.692s/it]: train_loss_raw=2.3039, running_loss=2.2559, LR=0.000100
[2025-08-25 23:59:00,946][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004744] [Batch 04744/04869] [00:54:40/00:01:26, 0.692s/it]: train_loss_raw=2.2732, running_loss=2.2561, LR=0.000100
[2025-08-25 23:59:06,475][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004752] [Batch 04752/04869] [00:54:46/00:01:20, 0.692s/it]: train_loss_raw=2.2840, running_loss=2.2580, LR=0.000100
[2025-08-25 23:59:12,457][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004760] [Batch 04760/04869] [00:54:52/00:01:15, 0.692s/it]: train_loss_raw=2.3019, running_loss=2.2569, LR=0.000100
[2025-08-25 23:59:17,661][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004768] [Batch 04768/04869] [00:54:57/00:01:09, 0.692s/it]: train_loss_raw=2.2493, running_loss=2.2545, LR=0.000100
[2025-08-25 23:59:22,838][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004776] [Batch 04776/04869] [00:55:02/00:01:04, 0.692s/it]: train_loss_raw=2.1581, running_loss=2.2535, LR=0.000100
[2025-08-25 23:59:28,120][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004784] [Batch 04784/04869] [00:55:08/00:00:58, 0.692s/it]: train_loss_raw=2.2268, running_loss=2.2541, LR=0.000100
[2025-08-25 23:59:33,407][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004792] [Batch 04792/04869] [00:55:13/00:00:53, 0.691s/it]: train_loss_raw=2.2603, running_loss=2.2525, LR=0.000100
[2025-08-25 23:59:39,106][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004800] [Batch 04800/04869] [00:55:19/00:00:47, 0.691s/it]: train_loss_raw=2.2323, running_loss=2.2526, LR=0.000100
[2025-08-25 23:59:44,651][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004808] [Batch 04808/04869] [00:55:24/00:00:42, 0.691s/it]: train_loss_raw=2.2495, running_loss=2.2541, LR=0.000100
[2025-08-25 23:59:50,239][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004816] [Batch 04816/04869] [00:55:30/00:00:36, 0.692s/it]: train_loss_raw=2.2467, running_loss=2.2533, LR=0.000100
[2025-08-25 23:59:55,934][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004824] [Batch 04824/04869] [00:55:35/00:00:31, 0.692s/it]: train_loss_raw=2.1613, running_loss=2.2537, LR=0.000100
[2025-08-26 00:00:01,613][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004832] [Batch 04832/04869] [00:55:41/00:00:25, 0.692s/it]: train_loss_raw=2.3106, running_loss=2.2555, LR=0.000100
[2025-08-26 00:00:06,815][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004840] [Batch 04840/04869] [00:55:46/00:00:20, 0.691s/it]: train_loss_raw=2.2794, running_loss=2.2558, LR=0.000100
[2025-08-26 00:00:12,013][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004848] [Batch 04848/04869] [00:55:52/00:00:14, 0.691s/it]: train_loss_raw=2.3238, running_loss=2.2547, LR=0.000100
[2025-08-26 00:00:17,396][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004856] [Batch 04856/04869] [00:55:57/00:00:08, 0.691s/it]: train_loss_raw=2.2627, running_loss=2.2547, LR=0.000100
[2025-08-26 00:00:22,568][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 004864] [Batch 04864/04869] [00:56:02/00:00:03, 0.691s/it]: train_loss_raw=2.2743, running_loss=2.2547, LR=0.000100
[2025-08-26 00:00:39,721][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-26 00:00:47,429][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00015/00124] [00:00:07/00:00:52, 0.482s/it]
[2025-08-26 00:00:57,787][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00023/00124] [00:00:18/00:01:15, 0.753s/it]
[2025-08-26 00:01:08,477][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00031/00124] [00:00:28/00:01:22, 0.899s/it]
[2025-08-26 00:01:28,823][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00039/00124] [00:00:49/00:01:43, 1.228s/it]
[2025-08-26 00:01:39,627][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00047/00124] [00:00:59/00:01:34, 1.248s/it]
[2025-08-26 00:01:50,870][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00055/00124] [00:01:11/00:01:26, 1.271s/it]
[2025-08-26 00:02:01,681][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00063/00124] [00:01:21/00:01:16, 1.281s/it]
[2025-08-26 00:02:12,409][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00071/00124] [00:01:32/00:01:06, 1.287s/it]
[2025-08-26 00:02:23,869][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00079/00124] [00:01:44/00:00:57, 1.302s/it]
[2025-08-26 00:02:35,393][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00087/00124] [00:01:55/00:00:47, 1.314s/it]
[2025-08-26 00:02:47,448][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00095/00124] [00:02:07/00:00:37, 1.330s/it]
[2025-08-26 00:02:58,360][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00103/00124] [00:02:18/00:00:26, 1.333s/it]
[2025-08-26 00:03:09,450][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00111/00124] [00:02:29/00:00:16, 1.337s/it]
[2025-08-26 00:03:20,423][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00119/00124] [00:02:40/00:00:05, 1.339s/it]
[2025-08-26 00:03:31,245][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 004870] [Batch 00003/00124] [00:02:51/01:25:45, 42.881s/it]
[2025-08-26 00:03:38,821][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=2.25349, valid_loss=2.30165
[2025-08-26 00:03:38,822][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-26 00:03:38,822][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.812
[2025-08-26 00:03:38,822][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.017
[2025-08-26 00:03:38,822][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.017
[2025-08-26 00:03:38,822][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.000
[2025-08-26 00:03:38,825][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:59:18, remaining time 28:40:06, 00:59:18 per epoch
[2025-08-26 00:03:40,434][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004872] [Batch 00003/04869] [00:00:01/00:39:29, 0.487s/it]: train_loss_raw=2.2319, running_loss=2.2547, LR=0.000100
[2025-08-26 00:03:46,204][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004880] [Batch 00011/04869] [00:00:07/00:53:13, 0.657s/it]: train_loss_raw=2.1851, running_loss=2.2534, LR=0.000100
[2025-08-26 00:03:52,001][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004888] [Batch 00019/04869] [00:00:13/00:55:25, 0.686s/it]: train_loss_raw=2.2041, running_loss=2.2509, LR=0.000100
[2025-08-26 00:03:57,797][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004896] [Batch 00027/04869] [00:00:18/00:56:15, 0.697s/it]: train_loss_raw=2.2257, running_loss=2.2496, LR=0.000100
[2025-08-26 00:04:03,304][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004904] [Batch 00035/04869] [00:00:24/00:56:00, 0.695s/it]: train_loss_raw=2.2581, running_loss=2.2491, LR=0.000100
[2025-08-26 00:04:08,826][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004912] [Batch 00043/04869] [00:00:29/00:55:50, 0.694s/it]: train_loss_raw=2.1336, running_loss=2.2461, LR=0.000100
[2025-08-26 00:04:14,144][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004920] [Batch 00051/04869] [00:00:35/00:55:22, 0.690s/it]: train_loss_raw=2.3369, running_loss=2.2469, LR=0.000100
[2025-08-26 00:04:20,083][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004928] [Batch 00059/04869] [00:00:41/00:55:51, 0.697s/it]: train_loss_raw=2.1990, running_loss=2.2468, LR=0.000100
[2025-08-26 00:04:25,412][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004936] [Batch 00067/04869] [00:00:46/00:55:28, 0.693s/it]: train_loss_raw=2.2536, running_loss=2.2464, LR=0.000100
[2025-08-26 00:04:30,622][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004944] [Batch 00075/04869] [00:00:51/00:55:01, 0.689s/it]: train_loss_raw=2.2219, running_loss=2.2471, LR=0.000100
[2025-08-26 00:04:35,837][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004952] [Batch 00083/04869] [00:00:56/00:54:38, 0.685s/it]: train_loss_raw=2.2654, running_loss=2.2452, LR=0.000100
[2025-08-26 00:04:41,046][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004960] [Batch 00091/04869] [00:01:02/00:54:19, 0.682s/it]: train_loss_raw=2.1944, running_loss=2.2444, LR=0.000100
[2025-08-26 00:04:46,276][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004968] [Batch 00099/04869] [00:01:07/00:54:02, 0.680s/it]: train_loss_raw=2.2503, running_loss=2.2469, LR=0.000100
[2025-08-26 00:04:52,073][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004976] [Batch 00107/04869] [00:01:13/00:54:13, 0.683s/it]: train_loss_raw=2.1915, running_loss=2.2462, LR=0.000100
[2025-08-26 00:04:57,671][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004984] [Batch 00115/04869] [00:01:18/00:54:13, 0.684s/it]: train_loss_raw=2.2451, running_loss=2.2463, LR=0.000100
[2025-08-26 00:05:03,445][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 004992] [Batch 00123/04869] [00:01:24/00:54:19, 0.687s/it]: train_loss_raw=2.2293, running_loss=2.2461, LR=0.000100
[2025-08-26 00:05:08,842][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005000] [Batch 00131/04869] [00:01:29/00:54:10, 0.686s/it]: train_loss_raw=2.2458, running_loss=2.2459, LR=0.000100
[2025-08-26 00:05:14,672][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005008] [Batch 00139/04869] [00:01:35/00:54:16, 0.688s/it]: train_loss_raw=2.1451, running_loss=2.2441, LR=0.000100
[2025-08-26 00:05:20,003][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005016] [Batch 00147/04869] [00:01:41/00:54:05, 0.687s/it]: train_loss_raw=2.2834, running_loss=2.2427, LR=0.000100
[2025-08-26 00:05:25,198][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005024] [Batch 00155/04869] [00:01:46/00:53:50, 0.685s/it]: train_loss_raw=2.2238, running_loss=2.2419, LR=0.000100
[2025-08-26 00:05:30,904][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005032] [Batch 00163/04869] [00:01:51/00:53:51, 0.687s/it]: train_loss_raw=2.2281, running_loss=2.2421, LR=0.000100
[2025-08-26 00:05:36,076][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005040] [Batch 00171/04869] [00:01:57/00:53:37, 0.685s/it]: train_loss_raw=2.3350, running_loss=2.2429, LR=0.000100
[2025-08-26 00:05:41,435][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005048] [Batch 00179/04869] [00:02:02/00:53:28, 0.684s/it]: train_loss_raw=2.2706, running_loss=2.2415, LR=0.000100
[2025-08-26 00:05:46,788][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005056] [Batch 00187/04869] [00:02:07/00:53:20, 0.684s/it]: train_loss_raw=2.1741, running_loss=2.2400, LR=0.000100
[2025-08-26 00:05:52,239][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005064] [Batch 00195/04869] [00:02:13/00:53:14, 0.683s/it]: train_loss_raw=2.2323, running_loss=2.2402, LR=0.000100
[2025-08-26 00:05:57,808][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005072] [Batch 00203/04869] [00:02:18/00:53:11, 0.684s/it]: train_loss_raw=2.1563, running_loss=2.2376, LR=0.000100
[2025-08-26 00:06:03,382][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005080] [Batch 00211/04869] [00:02:24/00:53:07, 0.684s/it]: train_loss_raw=2.2487, running_loss=2.2382, LR=0.000100
[2025-08-26 00:06:08,734][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005088] [Batch 00219/04869] [00:02:29/00:52:59, 0.684s/it]: train_loss_raw=2.1933, running_loss=2.2368, LR=0.000100
[2025-08-26 00:06:14,497][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005096] [Batch 00227/04869] [00:02:35/00:53:00, 0.685s/it]: train_loss_raw=2.2579, running_loss=2.2369, LR=0.000100
[2025-08-26 00:06:20,002][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005104] [Batch 00235/04869] [00:02:41/00:52:55, 0.685s/it]: train_loss_raw=2.2389, running_loss=2.2361, LR=0.000100
[2025-08-26 00:06:25,740][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005112] [Batch 00243/04869] [00:02:46/00:52:54, 0.686s/it]: train_loss_raw=2.2494, running_loss=2.2348, LR=0.000100
[2025-08-26 00:06:31,087][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005120] [Batch 00251/04869] [00:02:52/00:52:46, 0.686s/it]: train_loss_raw=2.1694, running_loss=2.2342, LR=0.000100
[2025-08-26 00:06:36,312][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005128] [Batch 00259/04869] [00:02:57/00:52:36, 0.685s/it]: train_loss_raw=2.2124, running_loss=2.2343, LR=0.000100
[2025-08-26 00:06:41,565][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005136] [Batch 00267/04869] [00:03:02/00:52:27, 0.684s/it]: train_loss_raw=2.1732, running_loss=2.2321, LR=0.000100
[2025-08-26 00:06:47,382][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005144] [Batch 00275/04869] [00:03:08/00:52:27, 0.685s/it]: train_loss_raw=2.2156, running_loss=2.2323, LR=0.000100
[2025-08-26 00:06:53,123][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005152] [Batch 00283/04869] [00:03:14/00:52:26, 0.686s/it]: train_loss_raw=2.1724, running_loss=2.2312, LR=0.000100
[2025-08-26 00:06:58,310][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005160] [Batch 00291/04869] [00:03:19/00:52:15, 0.685s/it]: train_loss_raw=2.2740, running_loss=2.2310, LR=0.000100
[2025-08-26 00:07:03,804][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005168] [Batch 00299/04869] [00:03:24/00:52:10, 0.685s/it]: train_loss_raw=2.2061, running_loss=2.2312, LR=0.000100
[2025-08-26 00:07:08,987][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005176] [Batch 00307/04869] [00:03:30/00:52:00, 0.684s/it]: train_loss_raw=2.1223, running_loss=2.2306, LR=0.000100
[2025-08-26 00:07:14,180][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005184] [Batch 00315/04869] [00:03:35/00:51:51, 0.683s/it]: train_loss_raw=2.2271, running_loss=2.2293, LR=0.000100
[2025-08-26 00:07:19,773][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005192] [Batch 00323/04869] [00:03:40/00:51:47, 0.684s/it]: train_loss_raw=2.2214, running_loss=2.2318, LR=0.000100
[2025-08-26 00:07:25,391][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005200] [Batch 00331/04869] [00:03:46/00:51:44, 0.684s/it]: train_loss_raw=2.3003, running_loss=2.2303, LR=0.000100
[2025-08-26 00:07:31,247][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005208] [Batch 00339/04869] [00:03:52/00:51:43, 0.685s/it]: train_loss_raw=2.1751, running_loss=2.2266, LR=0.000100
[2025-08-26 00:07:36,453][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005216] [Batch 00347/04869] [00:03:57/00:51:34, 0.684s/it]: train_loss_raw=2.2606, running_loss=2.2234, LR=0.000100
[2025-08-26 00:07:41,722][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005224] [Batch 00355/04869] [00:04:02/00:51:26, 0.684s/it]: train_loss_raw=2.1896, running_loss=2.2224, LR=0.000100
[2025-08-26 00:07:47,119][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005232] [Batch 00363/04869] [00:04:08/00:51:20, 0.684s/it]: train_loss_raw=2.2625, running_loss=2.2243, LR=0.000100
[2025-08-26 00:07:52,610][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005240] [Batch 00371/04869] [00:04:13/00:51:15, 0.684s/it]: train_loss_raw=2.2165, running_loss=2.2253, LR=0.000100
[2025-08-26 00:07:57,861][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005248] [Batch 00379/04869] [00:04:18/00:51:07, 0.683s/it]: train_loss_raw=2.2612, running_loss=2.2256, LR=0.000100
[2025-08-26 00:08:03,299][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005256] [Batch 00387/04869] [00:04:24/00:51:01, 0.683s/it]: train_loss_raw=2.2819, running_loss=2.2263, LR=0.000100
[2025-08-26 00:08:08,905][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005264] [Batch 00395/04869] [00:04:29/00:50:57, 0.683s/it]: train_loss_raw=2.2521, running_loss=2.2272, LR=0.000100
[2025-08-26 00:08:14,236][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005272] [Batch 00403/04869] [00:04:35/00:50:50, 0.683s/it]: train_loss_raw=2.1914, running_loss=2.2258, LR=0.000100
[2025-08-26 00:08:19,584][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005280] [Batch 00411/04869] [00:04:40/00:50:43, 0.683s/it]: train_loss_raw=2.1850, running_loss=2.2238, LR=0.000100
[2025-08-26 00:08:24,963][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005288] [Batch 00419/04869] [00:04:45/00:50:37, 0.683s/it]: train_loss_raw=2.1872, running_loss=2.2223, LR=0.000100
[2025-08-26 00:08:30,364][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005296] [Batch 00427/04869] [00:04:51/00:50:31, 0.682s/it]: train_loss_raw=2.2418, running_loss=2.2207, LR=0.000100
[2025-08-26 00:08:35,971][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005304] [Batch 00435/04869] [00:04:56/00:50:27, 0.683s/it]: train_loss_raw=2.2062, running_loss=2.2192, LR=0.000100
[2025-08-26 00:08:41,882][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005312] [Batch 00443/04869] [00:05:02/00:50:26, 0.684s/it]: train_loss_raw=2.2372, running_loss=2.2180, LR=0.000100
[2025-08-26 00:08:47,531][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005320] [Batch 00451/04869] [00:05:08/00:50:22, 0.684s/it]: train_loss_raw=2.2421, running_loss=2.2177, LR=0.000100
[2025-08-26 00:08:52,772][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005328] [Batch 00459/04869] [00:05:13/00:50:14, 0.684s/it]: train_loss_raw=2.2596, running_loss=2.2172, LR=0.000100
[2025-08-26 00:08:58,569][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005336] [Batch 00467/04869] [00:05:19/00:50:12, 0.684s/it]: train_loss_raw=2.2132, running_loss=2.2191, LR=0.000100
[2025-08-26 00:09:03,779][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005344] [Batch 00475/04869] [00:05:24/00:50:04, 0.684s/it]: train_loss_raw=2.1861, running_loss=2.2185, LR=0.000100
[2025-08-26 00:09:09,057][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005352] [Batch 00483/04869] [00:05:30/00:49:57, 0.683s/it]: train_loss_raw=2.2117, running_loss=2.2182, LR=0.000100
[2025-08-26 00:09:15,179][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005360] [Batch 00491/04869] [00:05:36/00:49:57, 0.685s/it]: train_loss_raw=2.2086, running_loss=2.2158, LR=0.000100
[2025-08-26 00:09:20,695][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005368] [Batch 00499/04869] [00:05:41/00:49:52, 0.685s/it]: train_loss_raw=2.2399, running_loss=2.2170, LR=0.000100
[2025-08-26 00:09:26,190][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005376] [Batch 00507/04869] [00:05:47/00:49:47, 0.685s/it]: train_loss_raw=2.1295, running_loss=2.2164, LR=0.000100
[2025-08-26 00:09:31,412][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005384] [Batch 00515/04869] [00:05:52/00:49:39, 0.684s/it]: train_loss_raw=2.2323, running_loss=2.2165, LR=0.000100
[2025-08-26 00:09:36,658][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005392] [Batch 00523/04869] [00:05:57/00:49:32, 0.684s/it]: train_loss_raw=2.2753, running_loss=2.2181, LR=0.000100
[2025-08-26 00:09:42,053][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005400] [Batch 00531/04869] [00:06:03/00:49:26, 0.684s/it]: train_loss_raw=2.2720, running_loss=2.2168, LR=0.000100
[2025-08-26 00:09:47,672][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005408] [Batch 00539/04869] [00:06:08/00:49:21, 0.684s/it]: train_loss_raw=2.2254, running_loss=2.2169, LR=0.000100
[2025-08-26 00:09:53,042][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005416] [Batch 00547/04869] [00:06:14/00:49:15, 0.684s/it]: train_loss_raw=2.2155, running_loss=2.2162, LR=0.000100
[2025-08-26 00:09:58,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005424] [Batch 00555/04869] [00:06:19/00:49:07, 0.683s/it]: train_loss_raw=2.1510, running_loss=2.2154, LR=0.000100
[2025-08-26 00:10:03,863][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005432] [Batch 00563/04869] [00:06:24/00:49:03, 0.684s/it]: train_loss_raw=2.1505, running_loss=2.2144, LR=0.000100
[2025-08-26 00:10:09,098][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005440] [Batch 00571/04869] [00:06:30/00:48:56, 0.683s/it]: train_loss_raw=2.2373, running_loss=2.2145, LR=0.000100
[2025-08-26 00:10:14,297][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005448] [Batch 00579/04869] [00:06:35/00:48:49, 0.683s/it]: train_loss_raw=2.1813, running_loss=2.2115, LR=0.000100
[2025-08-26 00:10:20,281][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005456] [Batch 00587/04869] [00:06:41/00:48:47, 0.684s/it]: train_loss_raw=2.2024, running_loss=2.2089, LR=0.000100
[2025-08-26 00:10:25,804][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005464] [Batch 00595/04869] [00:06:46/00:48:42, 0.684s/it]: train_loss_raw=2.2490, running_loss=2.2097, LR=0.000100
[2025-08-26 00:10:31,149][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005472] [Batch 00603/04869] [00:06:52/00:48:35, 0.684s/it]: train_loss_raw=2.2537, running_loss=2.2095, LR=0.000100
[2025-08-26 00:10:36,393][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005480] [Batch 00611/04869] [00:06:57/00:48:28, 0.683s/it]: train_loss_raw=2.2881, running_loss=2.2095, LR=0.000100
[2025-08-26 00:10:41,631][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005488] [Batch 00619/04869] [00:07:02/00:48:21, 0.683s/it]: train_loss_raw=2.2352, running_loss=2.2098, LR=0.000100
[2025-08-26 00:10:46,861][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005496] [Batch 00627/04869] [00:07:07/00:48:14, 0.682s/it]: train_loss_raw=2.1898, running_loss=2.2082, LR=0.000100
[2025-08-26 00:10:52,335][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005504] [Batch 00635/04869] [00:07:13/00:48:09, 0.682s/it]: train_loss_raw=2.2669, running_loss=2.2102, LR=0.000100
[2025-08-26 00:10:57,644][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005512] [Batch 00643/04869] [00:07:18/00:48:03, 0.682s/it]: train_loss_raw=2.1593, running_loss=2.2094, LR=0.000100
[2025-08-26 00:11:02,908][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005520] [Batch 00651/04869] [00:07:23/00:47:56, 0.682s/it]: train_loss_raw=2.2402, running_loss=2.2096, LR=0.000100
[2025-08-26 00:11:08,132][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005528] [Batch 00659/04869] [00:07:29/00:47:49, 0.682s/it]: train_loss_raw=2.1983, running_loss=2.2074, LR=0.000100
[2025-08-26 00:11:13,592][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005536] [Batch 00667/04869] [00:07:34/00:47:44, 0.682s/it]: train_loss_raw=2.2290, running_loss=2.2080, LR=0.000100
[2025-08-26 00:11:19,328][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005544] [Batch 00675/04869] [00:07:40/00:47:40, 0.682s/it]: train_loss_raw=2.1290, running_loss=2.2095, LR=0.000100
[2025-08-26 00:11:24,575][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005552] [Batch 00683/04869] [00:07:45/00:47:33, 0.682s/it]: train_loss_raw=2.1812, running_loss=2.2062, LR=0.000100
[2025-08-26 00:11:29,881][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005560] [Batch 00691/04869] [00:07:50/00:47:27, 0.681s/it]: train_loss_raw=2.2288, running_loss=2.2087, LR=0.000100
[2025-08-26 00:11:35,220][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005568] [Batch 00699/04869] [00:07:56/00:47:21, 0.681s/it]: train_loss_raw=2.1594, running_loss=2.2077, LR=0.000100
[2025-08-26 00:11:40,567][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005576] [Batch 00707/04869] [00:08:01/00:47:15, 0.681s/it]: train_loss_raw=2.1708, running_loss=2.2104, LR=0.000100
[2025-08-26 00:11:46,211][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005584] [Batch 00715/04869] [00:08:07/00:47:10, 0.681s/it]: train_loss_raw=2.2535, running_loss=2.2100, LR=0.000100
[2025-08-26 00:11:51,758][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005592] [Batch 00723/04869] [00:08:12/00:47:05, 0.682s/it]: train_loss_raw=2.2171, running_loss=2.2106, LR=0.000100
[2025-08-26 00:11:56,955][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005600] [Batch 00731/04869] [00:08:17/00:46:58, 0.681s/it]: train_loss_raw=2.2085, running_loss=2.2113, LR=0.000100
[2025-08-26 00:12:02,283][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005608] [Batch 00739/04869] [00:08:23/00:46:52, 0.681s/it]: train_loss_raw=2.1704, running_loss=2.2114, LR=0.000100
[2025-08-26 00:12:07,865][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005616] [Batch 00747/04869] [00:08:28/00:46:48, 0.681s/it]: train_loss_raw=2.2644, running_loss=2.2139, LR=0.000100
[2025-08-26 00:12:13,317][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005624] [Batch 00755/04869] [00:08:34/00:46:42, 0.681s/it]: train_loss_raw=2.1719, running_loss=2.2125, LR=0.000100
[2025-08-26 00:12:19,052][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005632] [Batch 00763/04869] [00:08:40/00:46:38, 0.682s/it]: train_loss_raw=2.1486, running_loss=2.2088, LR=0.000100
[2025-08-26 00:12:24,301][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005640] [Batch 00771/04869] [00:08:45/00:46:32, 0.681s/it]: train_loss_raw=2.2074, running_loss=2.2076, LR=0.000100
[2025-08-26 00:12:29,853][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005648] [Batch 00779/04869] [00:08:50/00:46:27, 0.681s/it]: train_loss_raw=2.2363, running_loss=2.2076, LR=0.000100
[2025-08-26 00:12:35,046][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005656] [Batch 00787/04869] [00:08:56/00:46:20, 0.681s/it]: train_loss_raw=2.1916, running_loss=2.2071, LR=0.000100
[2025-08-26 00:12:40,260][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005664] [Batch 00795/04869] [00:09:01/00:46:13, 0.681s/it]: train_loss_raw=2.2226, running_loss=2.2080, LR=0.000100
[2025-08-26 00:12:45,471][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005672] [Batch 00803/04869] [00:09:06/00:46:07, 0.681s/it]: train_loss_raw=2.2118, running_loss=2.2082, LR=0.000100
[2025-08-26 00:12:50,976][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005680] [Batch 00811/04869] [00:09:12/00:46:02, 0.681s/it]: train_loss_raw=2.2415, running_loss=2.2084, LR=0.000100
[2025-08-26 00:12:56,365][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005688] [Batch 00819/04869] [00:09:17/00:45:56, 0.681s/it]: train_loss_raw=2.2538, running_loss=2.2091, LR=0.000100
[2025-08-26 00:13:02,376][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005696] [Batch 00827/04869] [00:09:23/00:45:53, 0.681s/it]: train_loss_raw=2.1204, running_loss=2.2057, LR=0.000100
[2025-08-26 00:13:07,674][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005704] [Batch 00835/04869] [00:09:28/00:45:47, 0.681s/it]: train_loss_raw=2.1865, running_loss=2.2067, LR=0.000100
[2025-08-26 00:13:13,231][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005712] [Batch 00843/04869] [00:09:34/00:45:42, 0.681s/it]: train_loss_raw=2.2197, running_loss=2.2085, LR=0.000100
[2025-08-26 00:13:18,460][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005720] [Batch 00851/04869] [00:09:39/00:45:36, 0.681s/it]: train_loss_raw=2.2103, running_loss=2.2079, LR=0.000100
[2025-08-26 00:13:23,678][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005728] [Batch 00859/04869] [00:09:44/00:45:29, 0.681s/it]: train_loss_raw=2.2722, running_loss=2.2081, LR=0.000100
[2025-08-26 00:13:28,902][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005736] [Batch 00867/04869] [00:09:49/00:45:23, 0.680s/it]: train_loss_raw=2.2979, running_loss=2.2101, LR=0.000100
[2025-08-26 00:13:34,320][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005744] [Batch 00875/04869] [00:09:55/00:45:17, 0.680s/it]: train_loss_raw=2.1139, running_loss=2.2090, LR=0.000100
[2025-08-26 00:13:39,523][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005752] [Batch 00883/04869] [00:10:00/00:45:10, 0.680s/it]: train_loss_raw=2.2072, running_loss=2.2110, LR=0.000100
[2025-08-26 00:13:44,711][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005760] [Batch 00891/04869] [00:10:05/00:45:04, 0.680s/it]: train_loss_raw=2.2293, running_loss=2.2123, LR=0.000100
[2025-08-26 00:13:49,913][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005768] [Batch 00899/04869] [00:10:10/00:44:57, 0.680s/it]: train_loss_raw=2.1967, running_loss=2.2118, LR=0.000100
[2025-08-26 00:13:55,277][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005776] [Batch 00907/04869] [00:10:16/00:44:52, 0.679s/it]: train_loss_raw=2.1784, running_loss=2.2103, LR=0.000100
[2025-08-26 00:14:00,607][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005784] [Batch 00915/04869] [00:10:21/00:44:46, 0.679s/it]: train_loss_raw=2.1959, running_loss=2.2095, LR=0.000100
[2025-08-26 00:14:06,369][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005792] [Batch 00923/04869] [00:10:27/00:44:42, 0.680s/it]: train_loss_raw=2.2748, running_loss=2.2083, LR=0.000100
[2025-08-26 00:14:11,717][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005800] [Batch 00931/04869] [00:10:32/00:44:36, 0.680s/it]: train_loss_raw=2.2213, running_loss=2.2086, LR=0.000100
[2025-08-26 00:14:17,164][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005808] [Batch 00939/04869] [00:10:38/00:44:31, 0.680s/it]: train_loss_raw=2.2153, running_loss=2.2077, LR=0.000100
[2025-08-26 00:14:22,388][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005816] [Batch 00947/04869] [00:10:43/00:44:24, 0.679s/it]: train_loss_raw=2.2320, running_loss=2.2087, LR=0.000100
[2025-08-26 00:14:27,817][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005824] [Batch 00955/04869] [00:10:48/00:44:19, 0.679s/it]: train_loss_raw=2.2251, running_loss=2.2073, LR=0.000100
[2025-08-26 00:14:33,500][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005832] [Batch 00963/04869] [00:10:54/00:44:14, 0.680s/it]: train_loss_raw=2.2246, running_loss=2.2072, LR=0.000100
[2025-08-26 00:14:38,975][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005840] [Batch 00971/04869] [00:11:00/00:44:09, 0.680s/it]: train_loss_raw=2.1803, running_loss=2.2065, LR=0.000100
[2025-08-26 00:14:44,420][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005848] [Batch 00979/04869] [00:11:05/00:44:04, 0.680s/it]: train_loss_raw=2.2217, running_loss=2.2053, LR=0.000100
[2025-08-26 00:14:49,644][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005856] [Batch 00987/04869] [00:11:10/00:43:57, 0.680s/it]: train_loss_raw=2.1465, running_loss=2.2035, LR=0.000100
[2025-08-26 00:14:54,896][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005864] [Batch 00995/04869] [00:11:15/00:43:51, 0.679s/it]: train_loss_raw=2.2227, running_loss=2.2021, LR=0.000100
[2025-08-26 00:15:00,203][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005872] [Batch 01003/04869] [00:11:21/00:43:45, 0.679s/it]: train_loss_raw=2.2042, running_loss=2.2041, LR=0.000100
[2025-08-26 00:15:05,525][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005880] [Batch 01011/04869] [00:11:26/00:43:39, 0.679s/it]: train_loss_raw=2.2263, running_loss=2.2026, LR=0.000100
[2025-08-26 00:15:10,936][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005888] [Batch 01019/04869] [00:11:31/00:43:34, 0.679s/it]: train_loss_raw=2.3150, running_loss=2.2036, LR=0.000100
[2025-08-26 00:15:16,775][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005896] [Batch 01027/04869] [00:11:37/00:43:30, 0.679s/it]: train_loss_raw=2.1835, running_loss=2.2015, LR=0.000100
[2025-08-26 00:15:22,542][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005904] [Batch 01035/04869] [00:11:43/00:43:26, 0.680s/it]: train_loss_raw=2.2301, running_loss=2.2021, LR=0.000100
[2025-08-26 00:15:28,335][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005912] [Batch 01043/04869] [00:11:49/00:43:22, 0.680s/it]: train_loss_raw=2.1692, running_loss=2.2012, LR=0.000100
[2025-08-26 00:15:34,043][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005920] [Batch 01051/04869] [00:11:55/00:43:17, 0.680s/it]: train_loss_raw=2.2239, running_loss=2.1982, LR=0.000100
[2025-08-26 00:15:39,973][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005928] [Batch 01059/04869] [00:12:01/00:43:13, 0.681s/it]: train_loss_raw=2.2146, running_loss=2.1977, LR=0.000100
[2025-08-26 00:15:46,103][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005936] [Batch 01067/04869] [00:12:07/00:43:10, 0.681s/it]: train_loss_raw=2.2272, running_loss=2.1982, LR=0.000100
[2025-08-26 00:15:51,665][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005944] [Batch 01075/04869] [00:12:12/00:43:05, 0.682s/it]: train_loss_raw=2.2804, running_loss=2.1993, LR=0.000100
[2025-08-26 00:15:57,423][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005952] [Batch 01083/04869] [00:12:18/00:43:01, 0.682s/it]: train_loss_raw=2.1728, running_loss=2.1984, LR=0.000100
[2025-08-26 00:16:03,307][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005960] [Batch 01091/04869] [00:12:24/00:42:57, 0.682s/it]: train_loss_raw=2.1717, running_loss=2.1980, LR=0.000100
[2025-08-26 00:16:08,537][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005968] [Batch 01099/04869] [00:12:29/00:42:51, 0.682s/it]: train_loss_raw=2.1738, running_loss=2.1976, LR=0.000100
[2025-08-26 00:16:13,739][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005976] [Batch 01107/04869] [00:12:34/00:42:44, 0.682s/it]: train_loss_raw=2.2273, running_loss=2.1981, LR=0.000100
[2025-08-26 00:16:18,964][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005984] [Batch 01115/04869] [00:12:39/00:42:38, 0.682s/it]: train_loss_raw=2.1561, running_loss=2.1965, LR=0.000100
[2025-08-26 00:16:24,183][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 005992] [Batch 01123/04869] [00:12:45/00:42:32, 0.681s/it]: train_loss_raw=2.2447, running_loss=2.1973, LR=0.000100
[2025-08-26 00:16:29,428][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006000] [Batch 01131/04869] [00:12:50/00:42:26, 0.681s/it]: train_loss_raw=2.1662, running_loss=2.1981, LR=0.000100
[2025-08-26 00:16:38,175][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006008] [Batch 01139/04869] [00:12:59/00:42:31, 0.684s/it]: train_loss_raw=2.1461, running_loss=2.1962, LR=0.000100
[2025-08-26 00:16:43,388][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006016] [Batch 01147/04869] [00:13:04/00:42:25, 0.684s/it]: train_loss_raw=2.2022, running_loss=2.1969, LR=0.000100
[2025-08-26 00:16:48,705][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006024] [Batch 01155/04869] [00:13:09/00:42:19, 0.684s/it]: train_loss_raw=2.1529, running_loss=2.1960, LR=0.000100
[2025-08-26 00:16:54,139][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006032] [Batch 01163/04869] [00:13:15/00:42:13, 0.684s/it]: train_loss_raw=2.1703, running_loss=2.1948, LR=0.000100
[2025-08-26 00:16:59,599][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006040] [Batch 01171/04869] [00:13:20/00:42:08, 0.684s/it]: train_loss_raw=2.2269, running_loss=2.1938, LR=0.000100
[2025-08-26 00:17:04,856][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006048] [Batch 01179/04869] [00:13:25/00:42:02, 0.684s/it]: train_loss_raw=2.1058, running_loss=2.1933, LR=0.000100
[2025-08-26 00:17:10,122][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006056] [Batch 01187/04869] [00:13:31/00:41:56, 0.683s/it]: train_loss_raw=2.2059, running_loss=2.1930, LR=0.000100
[2025-08-26 00:17:16,403][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006064] [Batch 01195/04869] [00:13:37/00:41:53, 0.684s/it]: train_loss_raw=2.1692, running_loss=2.1933, LR=0.000100
[2025-08-26 00:17:22,147][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006072] [Batch 01203/04869] [00:13:43/00:41:48, 0.684s/it]: train_loss_raw=2.1334, running_loss=2.1925, LR=0.000100
[2025-08-26 00:17:27,510][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006080] [Batch 01211/04869] [00:13:48/00:41:42, 0.684s/it]: train_loss_raw=2.2052, running_loss=2.1935, LR=0.000100
[2025-08-26 00:17:33,313][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006088] [Batch 01219/04869] [00:13:54/00:41:38, 0.684s/it]: train_loss_raw=2.1770, running_loss=2.1913, LR=0.000100
[2025-08-26 00:17:39,152][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006096] [Batch 01227/04869] [00:14:00/00:41:33, 0.685s/it]: train_loss_raw=2.2735, running_loss=2.1902, LR=0.000100
[2025-08-26 00:17:45,335][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006104] [Batch 01235/04869] [00:14:06/00:41:30, 0.685s/it]: train_loss_raw=2.1823, running_loss=2.1893, LR=0.000100
[2025-08-26 00:17:50,964][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006112] [Batch 01243/04869] [00:14:11/00:41:25, 0.685s/it]: train_loss_raw=2.1730, running_loss=2.1892, LR=0.000100
[2025-08-26 00:17:56,812][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006120] [Batch 01251/04869] [00:14:17/00:41:20, 0.686s/it]: train_loss_raw=2.2113, running_loss=2.1880, LR=0.000100
[2025-08-26 00:18:02,681][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006128] [Batch 01259/04869] [00:14:23/00:41:16, 0.686s/it]: train_loss_raw=2.1378, running_loss=2.1885, LR=0.000100
[2025-08-26 00:18:07,903][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006136] [Batch 01267/04869] [00:14:28/00:41:10, 0.686s/it]: train_loss_raw=2.1797, running_loss=2.1886, LR=0.000100
[2025-08-26 00:18:13,135][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006144] [Batch 01275/04869] [00:14:34/00:41:04, 0.686s/it]: train_loss_raw=2.2223, running_loss=2.1891, LR=0.000100
[2025-08-26 00:18:18,362][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006152] [Batch 01283/04869] [00:14:39/00:40:57, 0.685s/it]: train_loss_raw=2.1689, running_loss=2.1888, LR=0.000100
[2025-08-26 00:18:24,062][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006160] [Batch 01291/04869] [00:14:45/00:40:53, 0.686s/it]: train_loss_raw=2.1774, running_loss=2.1861, LR=0.000100
[2025-08-26 00:18:29,915][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006168] [Batch 01299/04869] [00:14:50/00:40:48, 0.686s/it]: train_loss_raw=2.1829, running_loss=2.1861, LR=0.000100
[2025-08-26 00:18:35,224][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006176] [Batch 01307/04869] [00:14:56/00:40:42, 0.686s/it]: train_loss_raw=2.2186, running_loss=2.1862, LR=0.000100
[2025-08-26 00:18:40,679][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006184] [Batch 01315/04869] [00:15:01/00:40:37, 0.686s/it]: train_loss_raw=2.1720, running_loss=2.1869, LR=0.000100
[2025-08-26 00:18:46,023][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006192] [Batch 01323/04869] [00:15:07/00:40:31, 0.686s/it]: train_loss_raw=2.2522, running_loss=2.1864, LR=0.000100
[2025-08-26 00:18:51,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006200] [Batch 01331/04869] [00:15:12/00:40:24, 0.685s/it]: train_loss_raw=2.2178, running_loss=2.1851, LR=0.000100
[2025-08-26 00:18:56,531][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006208] [Batch 01339/04869] [00:15:17/00:40:18, 0.685s/it]: train_loss_raw=2.2762, running_loss=2.1866, LR=0.000100
[2025-08-26 00:19:01,723][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006216] [Batch 01347/04869] [00:15:22/00:40:12, 0.685s/it]: train_loss_raw=2.1708, running_loss=2.1883, LR=0.000100
[2025-08-26 00:19:06,996][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006224] [Batch 01355/04869] [00:15:28/00:40:06, 0.685s/it]: train_loss_raw=2.1798, running_loss=2.1883, LR=0.000100
[2025-08-26 00:19:12,279][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006232] [Batch 01363/04869] [00:15:33/00:40:00, 0.685s/it]: train_loss_raw=2.1627, running_loss=2.1880, LR=0.000100
[2025-08-26 00:19:17,574][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006240] [Batch 01371/04869] [00:15:38/00:39:54, 0.685s/it]: train_loss_raw=2.1565, running_loss=2.1877, LR=0.000100
[2025-08-26 00:19:23,051][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006248] [Batch 01379/04869] [00:15:44/00:39:49, 0.685s/it]: train_loss_raw=2.1738, running_loss=2.1850, LR=0.000100
[2025-08-26 00:19:28,635][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006256] [Batch 01387/04869] [00:15:49/00:39:44, 0.685s/it]: train_loss_raw=2.2137, running_loss=2.1867, LR=0.000100
[2025-08-26 00:19:34,292][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006264] [Batch 01395/04869] [00:15:55/00:39:39, 0.685s/it]: train_loss_raw=2.1934, running_loss=2.1855, LR=0.000100
[2025-08-26 00:19:39,794][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006272] [Batch 01403/04869] [00:16:00/00:39:33, 0.685s/it]: train_loss_raw=2.1781, running_loss=2.1840, LR=0.000100
[2025-08-26 00:19:45,162][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006280] [Batch 01411/04869] [00:16:06/00:39:27, 0.685s/it]: train_loss_raw=2.1559, running_loss=2.1817, LR=0.000100
[2025-08-26 00:19:51,200][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006288] [Batch 01419/04869] [00:16:12/00:39:23, 0.685s/it]: train_loss_raw=2.1480, running_loss=2.1803, LR=0.000100
[2025-08-26 00:19:56,416][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006296] [Batch 01427/04869] [00:16:17/00:39:17, 0.685s/it]: train_loss_raw=2.1826, running_loss=2.1795, LR=0.000100
[2025-08-26 00:20:01,640][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006304] [Batch 01435/04869] [00:16:22/00:39:11, 0.685s/it]: train_loss_raw=2.1299, running_loss=2.1758, LR=0.000100
[2025-08-26 00:20:06,999][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006312] [Batch 01443/04869] [00:16:28/00:39:05, 0.685s/it]: train_loss_raw=2.2272, running_loss=2.1755, LR=0.000100
[2025-08-26 00:20:12,565][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006320] [Batch 01451/04869] [00:16:33/00:39:00, 0.685s/it]: train_loss_raw=2.1883, running_loss=2.1760, LR=0.000100
[2025-08-26 00:20:18,418][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006328] [Batch 01459/04869] [00:16:39/00:38:55, 0.685s/it]: train_loss_raw=2.0852, running_loss=2.1743, LR=0.000100
[2025-08-26 00:20:23,941][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006336] [Batch 01467/04869] [00:16:44/00:38:50, 0.685s/it]: train_loss_raw=2.1463, running_loss=2.1744, LR=0.000100
[2025-08-26 00:20:29,530][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006344] [Batch 01475/04869] [00:16:50/00:38:45, 0.685s/it]: train_loss_raw=2.1383, running_loss=2.1707, LR=0.000100
[2025-08-26 00:20:34,750][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006352] [Batch 01483/04869] [00:16:55/00:38:39, 0.685s/it]: train_loss_raw=2.2022, running_loss=2.1722, LR=0.000100
[2025-08-26 00:20:40,053][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006360] [Batch 01491/04869] [00:17:01/00:38:33, 0.685s/it]: train_loss_raw=2.1901, running_loss=2.1715, LR=0.000100
[2025-08-26 00:20:45,531][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006368] [Batch 01499/04869] [00:17:06/00:38:27, 0.685s/it]: train_loss_raw=2.1508, running_loss=2.1708, LR=0.000100
[2025-08-26 00:20:50,948][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006376] [Batch 01507/04869] [00:17:11/00:38:22, 0.685s/it]: train_loss_raw=2.1759, running_loss=2.1718, LR=0.000100
[2025-08-26 00:20:57,059][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006384] [Batch 01515/04869] [00:17:18/00:38:18, 0.685s/it]: train_loss_raw=2.1821, running_loss=2.1720, LR=0.000100
[2025-08-26 00:21:02,590][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006392] [Batch 01523/04869] [00:17:23/00:38:12, 0.685s/it]: train_loss_raw=2.1889, running_loss=2.1697, LR=0.000100
[2025-08-26 00:21:08,405][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006400] [Batch 01531/04869] [00:17:29/00:38:08, 0.685s/it]: train_loss_raw=2.1134, running_loss=2.1672, LR=0.000100
[2025-08-26 00:21:13,739][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006408] [Batch 01539/04869] [00:17:34/00:38:02, 0.685s/it]: train_loss_raw=2.1892, running_loss=2.1689, LR=0.000100
[2025-08-26 00:21:19,496][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006416] [Batch 01547/04869] [00:17:40/00:37:57, 0.686s/it]: train_loss_raw=2.1795, running_loss=2.1706, LR=0.000100
[2025-08-26 00:21:24,733][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006424] [Batch 01555/04869] [00:17:45/00:37:51, 0.685s/it]: train_loss_raw=2.0866, running_loss=2.1708, LR=0.000100
[2025-08-26 00:21:29,949][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006432] [Batch 01563/04869] [00:17:50/00:37:45, 0.685s/it]: train_loss_raw=2.1169, running_loss=2.1685, LR=0.000100
[2025-08-26 00:21:35,714][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006440] [Batch 01571/04869] [00:17:56/00:37:40, 0.685s/it]: train_loss_raw=2.1434, running_loss=2.1691, LR=0.000100
[2025-08-26 00:21:40,932][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006448] [Batch 01579/04869] [00:18:01/00:37:34, 0.685s/it]: train_loss_raw=2.2098, running_loss=2.1689, LR=0.000100
[2025-08-26 00:21:46,255][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006456] [Batch 01587/04869] [00:18:07/00:37:28, 0.685s/it]: train_loss_raw=2.0956, running_loss=2.1677, LR=0.000100
[2025-08-26 00:21:51,973][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006464] [Batch 01595/04869] [00:18:13/00:37:23, 0.685s/it]: train_loss_raw=2.1922, running_loss=2.1672, LR=0.000100
[2025-08-26 00:21:57,560][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006472] [Batch 01603/04869] [00:18:18/00:37:18, 0.685s/it]: train_loss_raw=2.2089, running_loss=2.1676, LR=0.000100
[2025-08-26 00:22:02,891][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006480] [Batch 01611/04869] [00:18:23/00:37:12, 0.685s/it]: train_loss_raw=2.1451, running_loss=2.1652, LR=0.000100
[2025-08-26 00:22:08,210][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006488] [Batch 01619/04869] [00:18:29/00:37:06, 0.685s/it]: train_loss_raw=2.2268, running_loss=2.1675, LR=0.000100
[2025-08-26 00:22:13,821][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006496] [Batch 01627/04869] [00:18:34/00:37:01, 0.685s/it]: train_loss_raw=2.2002, running_loss=2.1679, LR=0.000100
[2025-08-26 00:22:19,214][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006504] [Batch 01635/04869] [00:18:40/00:36:55, 0.685s/it]: train_loss_raw=2.0834, running_loss=2.1672, LR=0.000100
[2025-08-26 00:22:24,453][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006512] [Batch 01643/04869] [00:18:45/00:36:49, 0.685s/it]: train_loss_raw=2.1956, running_loss=2.1676, LR=0.000100
[2025-08-26 00:22:29,667][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006520] [Batch 01651/04869] [00:18:50/00:36:43, 0.685s/it]: train_loss_raw=2.1957, running_loss=2.1691, LR=0.000100
[2025-08-26 00:22:34,883][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006528] [Batch 01659/04869] [00:18:55/00:36:37, 0.685s/it]: train_loss_raw=2.1908, running_loss=2.1697, LR=0.000100
[2025-08-26 00:22:40,106][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006536] [Batch 01667/04869] [00:19:01/00:36:31, 0.685s/it]: train_loss_raw=2.1775, running_loss=2.1681, LR=0.000100
[2025-08-26 00:22:45,557][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006544] [Batch 01675/04869] [00:19:06/00:36:26, 0.685s/it]: train_loss_raw=2.2300, running_loss=2.1679, LR=0.000100
[2025-08-26 00:22:50,802][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006552] [Batch 01683/04869] [00:19:11/00:36:20, 0.684s/it]: train_loss_raw=2.1936, running_loss=2.1695, LR=0.000100
[2025-08-26 00:22:56,378][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006560] [Batch 01691/04869] [00:19:17/00:36:15, 0.684s/it]: train_loss_raw=2.1481, running_loss=2.1680, LR=0.000100
[2025-08-26 00:23:01,613][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006568] [Batch 01699/04869] [00:19:22/00:36:09, 0.684s/it]: train_loss_raw=2.1421, running_loss=2.1661, LR=0.000100
[2025-08-26 00:23:06,845][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006576] [Batch 01707/04869] [00:19:27/00:36:03, 0.684s/it]: train_loss_raw=2.1082, running_loss=2.1660, LR=0.000100
[2025-08-26 00:23:12,420][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006584] [Batch 01715/04869] [00:19:33/00:35:58, 0.684s/it]: train_loss_raw=2.1625, running_loss=2.1662, LR=0.000100
[2025-08-26 00:23:18,044][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006592] [Batch 01723/04869] [00:19:39/00:35:52, 0.684s/it]: train_loss_raw=2.2210, running_loss=2.1656, LR=0.000100
[2025-08-26 00:23:23,401][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006600] [Batch 01731/04869] [00:19:44/00:35:47, 0.684s/it]: train_loss_raw=2.1481, running_loss=2.1629, LR=0.000100
[2025-08-26 00:23:29,479][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006608] [Batch 01739/04869] [00:19:50/00:35:42, 0.685s/it]: train_loss_raw=2.0429, running_loss=2.1643, LR=0.000100
[2025-08-26 00:23:35,834][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006616] [Batch 01747/04869] [00:19:56/00:35:38, 0.685s/it]: train_loss_raw=2.1598, running_loss=2.1650, LR=0.000100
[2025-08-26 00:23:41,169][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006624] [Batch 01755/04869] [00:20:02/00:35:33, 0.685s/it]: train_loss_raw=2.1025, running_loss=2.1658, LR=0.000100
[2025-08-26 00:23:46,472][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006632] [Batch 01763/04869] [00:20:07/00:35:27, 0.685s/it]: train_loss_raw=2.1953, running_loss=2.1685, LR=0.000100
[2025-08-26 00:23:51,685][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006640] [Batch 01771/04869] [00:20:12/00:35:21, 0.685s/it]: train_loss_raw=2.1586, running_loss=2.1671, LR=0.000100
[2025-08-26 00:23:56,925][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006648] [Batch 01779/04869] [00:20:17/00:35:15, 0.685s/it]: train_loss_raw=2.0988, running_loss=2.1678, LR=0.000100
[2025-08-26 00:24:02,220][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006656] [Batch 01787/04869] [00:20:23/00:35:09, 0.685s/it]: train_loss_raw=2.0883, running_loss=2.1656, LR=0.000100
[2025-08-26 00:24:07,486][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006664] [Batch 01795/04869] [00:20:28/00:35:03, 0.684s/it]: train_loss_raw=2.1925, running_loss=2.1644, LR=0.000100
[2025-08-26 00:24:13,645][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006672] [Batch 01803/04869] [00:20:34/00:34:59, 0.685s/it]: train_loss_raw=2.2175, running_loss=2.1645, LR=0.000100
[2025-08-26 00:24:19,439][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006680] [Batch 01811/04869] [00:20:40/00:34:54, 0.685s/it]: train_loss_raw=2.1102, running_loss=2.1631, LR=0.000100
[2025-08-26 00:24:24,693][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006688] [Batch 01819/04869] [00:20:45/00:34:48, 0.685s/it]: train_loss_raw=2.1681, running_loss=2.1625, LR=0.000100
[2025-08-26 00:24:30,267][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006696] [Batch 01827/04869] [00:20:51/00:34:43, 0.685s/it]: train_loss_raw=2.1637, running_loss=2.1608, LR=0.000100
[2025-08-26 00:24:35,855][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006704] [Batch 01835/04869] [00:20:56/00:34:38, 0.685s/it]: train_loss_raw=2.2482, running_loss=2.1609, LR=0.000100
[2025-08-26 00:24:41,673][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006712] [Batch 01843/04869] [00:21:02/00:34:33, 0.685s/it]: train_loss_raw=2.1822, running_loss=2.1608, LR=0.000100
[2025-08-26 00:24:46,937][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006720] [Batch 01851/04869] [00:21:07/00:34:27, 0.685s/it]: train_loss_raw=2.1682, running_loss=2.1605, LR=0.000100
[2025-08-26 00:24:52,278][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006728] [Batch 01859/04869] [00:21:13/00:34:21, 0.685s/it]: train_loss_raw=2.1395, running_loss=2.1594, LR=0.000100
[2025-08-26 00:24:57,926][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006736] [Batch 01867/04869] [00:21:18/00:34:16, 0.685s/it]: train_loss_raw=2.0876, running_loss=2.1570, LR=0.000100
[2025-08-26 00:25:03,214][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006744] [Batch 01875/04869] [00:21:24/00:34:10, 0.685s/it]: train_loss_raw=2.1529, running_loss=2.1569, LR=0.000100
[2025-08-26 00:25:08,869][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006752] [Batch 01883/04869] [00:21:29/00:34:05, 0.685s/it]: train_loss_raw=2.1651, running_loss=2.1550, LR=0.000100
[2025-08-26 00:25:14,240][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006760] [Batch 01891/04869] [00:21:35/00:33:59, 0.685s/it]: train_loss_raw=2.1034, running_loss=2.1557, LR=0.000100
[2025-08-26 00:25:19,552][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006768] [Batch 01899/04869] [00:21:40/00:33:54, 0.685s/it]: train_loss_raw=2.0708, running_loss=2.1530, LR=0.000100
[2025-08-26 00:25:24,827][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006776] [Batch 01907/04869] [00:21:45/00:33:48, 0.685s/it]: train_loss_raw=2.2089, running_loss=2.1533, LR=0.000100
[2025-08-26 00:25:30,276][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006784] [Batch 01915/04869] [00:21:51/00:33:42, 0.685s/it]: train_loss_raw=2.1957, running_loss=2.1544, LR=0.000100
[2025-08-26 00:25:35,791][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006792] [Batch 01923/04869] [00:21:56/00:33:37, 0.685s/it]: train_loss_raw=2.1890, running_loss=2.1567, LR=0.000100
[2025-08-26 00:25:41,096][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006800] [Batch 01931/04869] [00:22:02/00:33:31, 0.685s/it]: train_loss_raw=2.0536, running_loss=2.1567, LR=0.000100
[2025-08-26 00:25:46,289][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006808] [Batch 01939/04869] [00:22:07/00:33:25, 0.685s/it]: train_loss_raw=2.1151, running_loss=2.1561, LR=0.000100
[2025-08-26 00:25:51,483][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006816] [Batch 01947/04869] [00:22:12/00:33:19, 0.684s/it]: train_loss_raw=2.1649, running_loss=2.1556, LR=0.000100
[2025-08-26 00:25:56,694][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006824] [Batch 01955/04869] [00:22:17/00:33:13, 0.684s/it]: train_loss_raw=2.2415, running_loss=2.1546, LR=0.000100
[2025-08-26 00:26:01,910][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006832] [Batch 01963/04869] [00:22:22/00:33:08, 0.684s/it]: train_loss_raw=2.0624, running_loss=2.1532, LR=0.000100
[2025-08-26 00:26:07,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006840] [Batch 01971/04869] [00:22:28/00:33:02, 0.684s/it]: train_loss_raw=2.1542, running_loss=2.1556, LR=0.000100
[2025-08-26 00:26:12,824][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006848] [Batch 01979/04869] [00:22:33/00:32:57, 0.684s/it]: train_loss_raw=2.0957, running_loss=2.1553, LR=0.000100
[2025-08-26 00:26:18,795][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006856] [Batch 01987/04869] [00:22:39/00:32:52, 0.684s/it]: train_loss_raw=2.1525, running_loss=2.1534, LR=0.000100
[2025-08-26 00:26:24,281][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006864] [Batch 01995/04869] [00:22:45/00:32:46, 0.684s/it]: train_loss_raw=2.1481, running_loss=2.1532, LR=0.000100
[2025-08-26 00:26:30,305][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006872] [Batch 02003/04869] [00:22:51/00:32:42, 0.685s/it]: train_loss_raw=2.1921, running_loss=2.1551, LR=0.000100
[2025-08-26 00:26:35,807][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006880] [Batch 02011/04869] [00:22:56/00:32:36, 0.685s/it]: train_loss_raw=2.2183, running_loss=2.1565, LR=0.000100
[2025-08-26 00:26:41,023][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006888] [Batch 02019/04869] [00:23:02/00:32:30, 0.685s/it]: train_loss_raw=2.1420, running_loss=2.1562, LR=0.000100
[2025-08-26 00:26:46,261][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006896] [Batch 02027/04869] [00:23:07/00:32:25, 0.684s/it]: train_loss_raw=2.1315, running_loss=2.1535, LR=0.000100
[2025-08-26 00:26:51,476][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006904] [Batch 02035/04869] [00:23:12/00:32:19, 0.684s/it]: train_loss_raw=2.1800, running_loss=2.1526, LR=0.000100
[2025-08-26 00:26:56,793][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006912] [Batch 02043/04869] [00:23:17/00:32:13, 0.684s/it]: train_loss_raw=2.2007, running_loss=2.1532, LR=0.000100
[2025-08-26 00:27:02,508][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006920] [Batch 02051/04869] [00:23:23/00:32:08, 0.684s/it]: train_loss_raw=2.2161, running_loss=2.1540, LR=0.000100
[2025-08-26 00:27:08,093][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006928] [Batch 02059/04869] [00:23:29/00:32:03, 0.684s/it]: train_loss_raw=2.0946, running_loss=2.1541, LR=0.000100
[2025-08-26 00:27:13,332][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006936] [Batch 02067/04869] [00:23:34/00:31:57, 0.684s/it]: train_loss_raw=2.0729, running_loss=2.1521, LR=0.000100
[2025-08-26 00:27:18,559][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006944] [Batch 02075/04869] [00:23:39/00:31:51, 0.684s/it]: train_loss_raw=2.1357, running_loss=2.1507, LR=0.000100
[2025-08-26 00:27:23,794][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006952] [Batch 02083/04869] [00:23:44/00:31:45, 0.684s/it]: train_loss_raw=2.0867, running_loss=2.1492, LR=0.000100
[2025-08-26 00:27:28,998][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006960] [Batch 02091/04869] [00:23:50/00:31:39, 0.684s/it]: train_loss_raw=2.0669, running_loss=2.1482, LR=0.000100
[2025-08-26 00:27:34,858][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006968] [Batch 02099/04869] [00:23:55/00:31:34, 0.684s/it]: train_loss_raw=2.1560, running_loss=2.1467, LR=0.000100
[2025-08-26 00:27:40,437][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006976] [Batch 02107/04869] [00:24:01/00:31:29, 0.684s/it]: train_loss_raw=2.1493, running_loss=2.1466, LR=0.000100
[2025-08-26 00:27:45,921][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006984] [Batch 02115/04869] [00:24:06/00:31:24, 0.684s/it]: train_loss_raw=2.2021, running_loss=2.1455, LR=0.000100
[2025-08-26 00:27:51,677][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 006992] [Batch 02123/04869] [00:24:12/00:31:19, 0.684s/it]: train_loss_raw=2.1439, running_loss=2.1473, LR=0.000100
[2025-08-26 00:27:57,714][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007000] [Batch 02131/04869] [00:24:18/00:31:14, 0.685s/it]: train_loss_raw=2.1515, running_loss=2.1482, LR=0.000100
[2025-08-26 00:28:03,468][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007008] [Batch 02139/04869] [00:24:24/00:31:09, 0.685s/it]: train_loss_raw=2.2281, running_loss=2.1475, LR=0.000100
[2025-08-26 00:28:09,051][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007016] [Batch 02147/04869] [00:24:30/00:31:03, 0.685s/it]: train_loss_raw=2.1749, running_loss=2.1447, LR=0.000100
[2025-08-26 00:28:14,298][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007024] [Batch 02155/04869] [00:24:35/00:30:58, 0.685s/it]: train_loss_raw=2.1904, running_loss=2.1444, LR=0.000100
[2025-08-26 00:28:19,515][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007032] [Batch 02163/04869] [00:24:40/00:30:52, 0.684s/it]: train_loss_raw=2.1619, running_loss=2.1426, LR=0.000100
[2025-08-26 00:28:24,754][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007040] [Batch 02171/04869] [00:24:45/00:30:46, 0.684s/it]: train_loss_raw=2.1224, running_loss=2.1433, LR=0.000100
[2025-08-26 00:28:30,851][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007048] [Batch 02179/04869] [00:24:51/00:30:41, 0.685s/it]: train_loss_raw=2.1126, running_loss=2.1418, LR=0.000100
[2025-08-26 00:28:36,284][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007056] [Batch 02187/04869] [00:24:57/00:30:36, 0.685s/it]: train_loss_raw=2.1185, running_loss=2.1396, LR=0.000100
[2025-08-26 00:28:41,499][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007064] [Batch 02195/04869] [00:25:02/00:30:30, 0.685s/it]: train_loss_raw=2.2336, running_loss=2.1416, LR=0.000100
[2025-08-26 00:28:46,899][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007072] [Batch 02203/04869] [00:25:07/00:30:24, 0.684s/it]: train_loss_raw=2.1535, running_loss=2.1418, LR=0.000100
[2025-08-26 00:28:52,392][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007080] [Batch 02211/04869] [00:25:13/00:30:19, 0.684s/it]: train_loss_raw=2.1735, running_loss=2.1412, LR=0.000100
[2025-08-26 00:28:57,581][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007088] [Batch 02219/04869] [00:25:18/00:30:13, 0.684s/it]: train_loss_raw=2.1545, running_loss=2.1423, LR=0.000100
[2025-08-26 00:29:02,821][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007096] [Batch 02227/04869] [00:25:23/00:30:07, 0.684s/it]: train_loss_raw=2.1362, running_loss=2.1412, LR=0.000100
[2025-08-26 00:29:08,204][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007104] [Batch 02235/04869] [00:25:29/00:30:02, 0.684s/it]: train_loss_raw=2.0994, running_loss=2.1401, LR=0.000100
[2025-08-26 00:29:13,804][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007112] [Batch 02243/04869] [00:25:34/00:29:56, 0.684s/it]: train_loss_raw=2.1275, running_loss=2.1416, LR=0.000100
[2025-08-26 00:29:19,050][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007120] [Batch 02251/04869] [00:25:40/00:29:51, 0.684s/it]: train_loss_raw=2.1961, running_loss=2.1419, LR=0.000100
[2025-08-26 00:29:24,276][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007128] [Batch 02259/04869] [00:25:45/00:29:45, 0.684s/it]: train_loss_raw=2.1791, running_loss=2.1419, LR=0.000100
[2025-08-26 00:29:29,537][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007136] [Batch 02267/04869] [00:25:50/00:29:39, 0.684s/it]: train_loss_raw=2.1318, running_loss=2.1423, LR=0.000100
[2025-08-26 00:29:34,863][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007144] [Batch 02275/04869] [00:25:55/00:29:34, 0.684s/it]: train_loss_raw=2.1552, running_loss=2.1400, LR=0.000100
[2025-08-26 00:29:40,404][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007152] [Batch 02283/04869] [00:26:01/00:29:28, 0.684s/it]: train_loss_raw=2.2201, running_loss=2.1419, LR=0.000100
[2025-08-26 00:29:45,627][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007160] [Batch 02291/04869] [00:26:06/00:29:22, 0.684s/it]: train_loss_raw=2.1212, running_loss=2.1408, LR=0.000100
[2025-08-26 00:29:50,853][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007168] [Batch 02299/04869] [00:26:11/00:29:17, 0.684s/it]: train_loss_raw=2.1312, running_loss=2.1413, LR=0.000100
[2025-08-26 00:29:56,107][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007176] [Batch 02307/04869] [00:26:17/00:29:11, 0.684s/it]: train_loss_raw=2.1679, running_loss=2.1407, LR=0.000100
[2025-08-26 00:30:01,549][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007184] [Batch 02315/04869] [00:26:22/00:29:05, 0.684s/it]: train_loss_raw=2.0614, running_loss=2.1374, LR=0.000100
[2025-08-26 00:30:06,810][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007192] [Batch 02323/04869] [00:26:27/00:29:00, 0.684s/it]: train_loss_raw=2.1276, running_loss=2.1357, LR=0.000100
[2025-08-26 00:30:12,250][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007200] [Batch 02331/04869] [00:26:33/00:28:54, 0.684s/it]: train_loss_raw=2.1000, running_loss=2.1347, LR=0.000100
[2025-08-26 00:30:17,608][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007208] [Batch 02339/04869] [00:26:38/00:28:49, 0.683s/it]: train_loss_raw=2.1590, running_loss=2.1343, LR=0.000100
[2025-08-26 00:30:22,835][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007216] [Batch 02347/04869] [00:26:43/00:28:43, 0.683s/it]: train_loss_raw=2.1462, running_loss=2.1353, LR=0.000100
[2025-08-26 00:30:28,061][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007224] [Batch 02355/04869] [00:26:49/00:28:37, 0.683s/it]: train_loss_raw=2.0750, running_loss=2.1336, LR=0.000100
[2025-08-26 00:30:33,689][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007232] [Batch 02363/04869] [00:26:54/00:28:32, 0.683s/it]: train_loss_raw=2.0867, running_loss=2.1332, LR=0.000100
[2025-08-26 00:30:39,113][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007240] [Batch 02371/04869] [00:27:00/00:28:26, 0.683s/it]: train_loss_raw=2.1840, running_loss=2.1341, LR=0.000100
[2025-08-26 00:30:44,312][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007248] [Batch 02379/04869] [00:27:05/00:28:21, 0.683s/it]: train_loss_raw=2.1093, running_loss=2.1337, LR=0.000100
[2025-08-26 00:30:49,781][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007256] [Batch 02387/04869] [00:27:10/00:28:15, 0.683s/it]: train_loss_raw=2.1614, running_loss=2.1339, LR=0.000100
[2025-08-26 00:30:55,004][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007264] [Batch 02395/04869] [00:27:16/00:28:09, 0.683s/it]: train_loss_raw=2.1931, running_loss=2.1340, LR=0.000100
[2025-08-26 00:31:00,219][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007272] [Batch 02403/04869] [00:27:21/00:28:04, 0.683s/it]: train_loss_raw=2.1146, running_loss=2.1341, LR=0.000100
[2025-08-26 00:31:05,568][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007280] [Batch 02411/04869] [00:27:26/00:27:58, 0.683s/it]: train_loss_raw=2.1661, running_loss=2.1336, LR=0.000100
[2025-08-26 00:31:10,774][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007288] [Batch 02419/04869] [00:27:31/00:27:52, 0.683s/it]: train_loss_raw=2.1055, running_loss=2.1337, LR=0.000100
[2025-08-26 00:31:16,004][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007296] [Batch 02427/04869] [00:27:37/00:27:47, 0.683s/it]: train_loss_raw=2.1717, running_loss=2.1358, LR=0.000100
[2025-08-26 00:31:21,219][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007304] [Batch 02435/04869] [00:27:42/00:27:41, 0.683s/it]: train_loss_raw=2.0272, running_loss=2.1338, LR=0.000100
[2025-08-26 00:31:26,783][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007312] [Batch 02443/04869] [00:27:47/00:27:36, 0.683s/it]: train_loss_raw=2.1691, running_loss=2.1329, LR=0.000100
[2025-08-26 00:31:32,024][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007320] [Batch 02451/04869] [00:27:53/00:27:30, 0.683s/it]: train_loss_raw=2.1219, running_loss=2.1328, LR=0.000100
[2025-08-26 00:31:37,250][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007328] [Batch 02459/04869] [00:27:58/00:27:24, 0.683s/it]: train_loss_raw=2.2036, running_loss=2.1335, LR=0.000100
[2025-08-26 00:31:42,825][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007336] [Batch 02467/04869] [00:28:03/00:27:19, 0.683s/it]: train_loss_raw=2.1294, running_loss=2.1332, LR=0.000100
[2025-08-26 00:31:48,253][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007344] [Batch 02475/04869] [00:28:09/00:27:13, 0.683s/it]: train_loss_raw=2.1334, running_loss=2.1320, LR=0.000100
[2025-08-26 00:31:54,080][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007352] [Batch 02483/04869] [00:28:15/00:27:08, 0.683s/it]: train_loss_raw=2.1520, running_loss=2.1325, LR=0.000100
[2025-08-26 00:32:00,146][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007360] [Batch 02491/04869] [00:28:21/00:27:04, 0.683s/it]: train_loss_raw=2.1743, running_loss=2.1331, LR=0.000100
[2025-08-26 00:32:06,134][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007368] [Batch 02499/04869] [00:28:27/00:26:59, 0.683s/it]: train_loss_raw=2.1030, running_loss=2.1341, LR=0.000100
[2025-08-26 00:32:12,596][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007376] [Batch 02507/04869] [00:28:33/00:26:54, 0.684s/it]: train_loss_raw=2.1526, running_loss=2.1319, LR=0.000100
[2025-08-26 00:32:18,900][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007384] [Batch 02515/04869] [00:28:39/00:26:49, 0.684s/it]: train_loss_raw=2.1933, running_loss=2.1332, LR=0.000100
[2025-08-26 00:32:25,172][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007392] [Batch 02523/04869] [00:28:46/00:26:45, 0.684s/it]: train_loss_raw=2.2452, running_loss=2.1344, LR=0.000100
[2025-08-26 00:32:30,736][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007400] [Batch 02531/04869] [00:28:51/00:26:39, 0.684s/it]: train_loss_raw=2.0893, running_loss=2.1341, LR=0.000100
[2025-08-26 00:32:36,161][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007408] [Batch 02539/04869] [00:28:57/00:26:34, 0.684s/it]: train_loss_raw=2.0947, running_loss=2.1336, LR=0.000100
[2025-08-26 00:32:41,357][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007416] [Batch 02547/04869] [00:29:02/00:26:28, 0.684s/it]: train_loss_raw=2.1081, running_loss=2.1305, LR=0.000100
[2025-08-26 00:32:46,587][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007424] [Batch 02555/04869] [00:29:07/00:26:22, 0.684s/it]: train_loss_raw=2.1559, running_loss=2.1287, LR=0.000100
[2025-08-26 00:32:52,541][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007432] [Batch 02563/04869] [00:29:13/00:26:17, 0.684s/it]: train_loss_raw=2.2014, running_loss=2.1284, LR=0.000100
[2025-08-26 00:32:58,107][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007440] [Batch 02571/04869] [00:29:19/00:26:12, 0.684s/it]: train_loss_raw=2.1698, running_loss=2.1280, LR=0.000100
[2025-08-26 00:33:03,307][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007448] [Batch 02579/04869] [00:29:24/00:26:06, 0.684s/it]: train_loss_raw=2.0613, running_loss=2.1271, LR=0.000100
[2025-08-26 00:33:08,988][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007456] [Batch 02587/04869] [00:29:30/00:26:01, 0.684s/it]: train_loss_raw=2.0973, running_loss=2.1256, LR=0.000100
[2025-08-26 00:33:14,184][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007464] [Batch 02595/04869] [00:29:35/00:25:55, 0.684s/it]: train_loss_raw=2.1656, running_loss=2.1272, LR=0.000100
[2025-08-26 00:33:19,400][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007472] [Batch 02603/04869] [00:29:40/00:25:49, 0.684s/it]: train_loss_raw=2.1883, running_loss=2.1262, LR=0.000100
[2025-08-26 00:33:24,864][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007480] [Batch 02611/04869] [00:29:45/00:25:44, 0.684s/it]: train_loss_raw=2.0963, running_loss=2.1263, LR=0.000100
[2025-08-26 00:33:30,863][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007488] [Batch 02619/04869] [00:29:51/00:25:39, 0.684s/it]: train_loss_raw=2.2599, running_loss=2.1276, LR=0.000100
[2025-08-26 00:33:36,074][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007496] [Batch 02627/04869] [00:29:57/00:25:33, 0.684s/it]: train_loss_raw=2.1946, running_loss=2.1313, LR=0.000100
[2025-08-26 00:33:41,553][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007504] [Batch 02635/04869] [00:30:02/00:25:28, 0.684s/it]: train_loss_raw=2.0855, running_loss=2.1300, LR=0.000100
[2025-08-26 00:33:46,829][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007512] [Batch 02643/04869] [00:30:07/00:25:22, 0.684s/it]: train_loss_raw=2.1543, running_loss=2.1311, LR=0.000100
[2025-08-26 00:33:52,045][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007520] [Batch 02651/04869] [00:30:13/00:25:16, 0.684s/it]: train_loss_raw=2.0571, running_loss=2.1309, LR=0.000100
[2025-08-26 00:33:57,395][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007528] [Batch 02659/04869] [00:30:18/00:25:11, 0.684s/it]: train_loss_raw=2.1768, running_loss=2.1330, LR=0.000100
[2025-08-26 00:34:02,604][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007536] [Batch 02667/04869] [00:30:23/00:25:05, 0.684s/it]: train_loss_raw=2.1594, running_loss=2.1318, LR=0.000100
[2025-08-26 00:34:08,107][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007544] [Batch 02675/04869] [00:30:29/00:25:00, 0.684s/it]: train_loss_raw=2.1521, running_loss=2.1317, LR=0.000100
[2025-08-26 00:34:13,715][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007552] [Batch 02683/04869] [00:30:34/00:24:54, 0.684s/it]: train_loss_raw=2.0708, running_loss=2.1298, LR=0.000100
[2025-08-26 00:34:19,299][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007560] [Batch 02691/04869] [00:30:40/00:24:49, 0.684s/it]: train_loss_raw=2.1401, running_loss=2.1305, LR=0.000100
[2025-08-26 00:34:24,563][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007568] [Batch 02699/04869] [00:30:45/00:24:43, 0.684s/it]: train_loss_raw=2.1464, running_loss=2.1326, LR=0.000100
[2025-08-26 00:34:30,407][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007576] [Batch 02707/04869] [00:30:51/00:24:38, 0.684s/it]: train_loss_raw=2.1150, running_loss=2.1321, LR=0.000100
[2025-08-26 00:34:35,879][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007584] [Batch 02715/04869] [00:30:56/00:24:33, 0.684s/it]: train_loss_raw=2.0888, running_loss=2.1312, LR=0.000100
[2025-08-26 00:34:41,074][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007592] [Batch 02723/04869] [00:31:02/00:24:27, 0.684s/it]: train_loss_raw=2.1331, running_loss=2.1313, LR=0.000100
[2025-08-26 00:34:46,289][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007600] [Batch 02731/04869] [00:31:07/00:24:21, 0.684s/it]: train_loss_raw=2.2099, running_loss=2.1323, LR=0.000100
[2025-08-26 00:34:51,493][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007608] [Batch 02739/04869] [00:31:12/00:24:16, 0.684s/it]: train_loss_raw=2.1342, running_loss=2.1346, LR=0.000100
[2025-08-26 00:34:56,709][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007616] [Batch 02747/04869] [00:31:17/00:24:10, 0.684s/it]: train_loss_raw=2.1206, running_loss=2.1344, LR=0.000100
[2025-08-26 00:35:01,953][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007624] [Batch 02755/04869] [00:31:22/00:24:04, 0.683s/it]: train_loss_raw=2.1017, running_loss=2.1347, LR=0.000100
[2025-08-26 00:35:07,666][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007632] [Batch 02763/04869] [00:31:28/00:23:59, 0.684s/it]: train_loss_raw=2.1091, running_loss=2.1338, LR=0.000100
[2025-08-26 00:35:12,914][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007640] [Batch 02771/04869] [00:31:33/00:23:53, 0.683s/it]: train_loss_raw=2.1213, running_loss=2.1343, LR=0.000100
[2025-08-26 00:35:18,445][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007648] [Batch 02779/04869] [00:31:39/00:23:48, 0.684s/it]: train_loss_raw=2.1943, running_loss=2.1350, LR=0.000100
[2025-08-26 00:35:23,804][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007656] [Batch 02787/04869] [00:31:44/00:23:42, 0.683s/it]: train_loss_raw=2.1116, running_loss=2.1344, LR=0.000100
[2025-08-26 00:35:29,048][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007664] [Batch 02795/04869] [00:31:50/00:23:37, 0.683s/it]: train_loss_raw=2.2079, running_loss=2.1350, LR=0.000100
[2025-08-26 00:35:34,280][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007672] [Batch 02803/04869] [00:31:55/00:23:31, 0.683s/it]: train_loss_raw=2.1322, running_loss=2.1320, LR=0.000100
[2025-08-26 00:35:39,517][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007680] [Batch 02811/04869] [00:32:00/00:23:26, 0.683s/it]: train_loss_raw=2.1442, running_loss=2.1313, LR=0.000100
[2025-08-26 00:35:44,760][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007688] [Batch 02819/04869] [00:32:05/00:23:20, 0.683s/it]: train_loss_raw=2.0938, running_loss=2.1279, LR=0.000100
[2025-08-26 00:35:49,993][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007696] [Batch 02827/04869] [00:32:11/00:23:14, 0.683s/it]: train_loss_raw=2.0531, running_loss=2.1265, LR=0.000100
[2025-08-26 00:35:55,206][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007704] [Batch 02835/04869] [00:32:16/00:23:09, 0.683s/it]: train_loss_raw=2.1234, running_loss=2.1235, LR=0.000100
[2025-08-26 00:36:00,609][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007712] [Batch 02843/04869] [00:32:21/00:23:03, 0.683s/it]: train_loss_raw=2.1096, running_loss=2.1234, LR=0.000100
[2025-08-26 00:36:05,861][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007720] [Batch 02851/04869] [00:32:26/00:22:58, 0.683s/it]: train_loss_raw=2.1286, running_loss=2.1241, LR=0.000100
[2025-08-26 00:36:11,102][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007728] [Batch 02859/04869] [00:32:32/00:22:52, 0.683s/it]: train_loss_raw=2.1563, running_loss=2.1244, LR=0.000100
[2025-08-26 00:36:16,309][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007736] [Batch 02867/04869] [00:32:37/00:22:46, 0.683s/it]: train_loss_raw=2.1024, running_loss=2.1236, LR=0.000100
[2025-08-26 00:36:21,528][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007744] [Batch 02875/04869] [00:32:42/00:22:41, 0.683s/it]: train_loss_raw=2.1415, running_loss=2.1226, LR=0.000100
[2025-08-26 00:36:27,223][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007752] [Batch 02883/04869] [00:32:48/00:22:35, 0.683s/it]: train_loss_raw=2.0298, running_loss=2.1219, LR=0.000100
[2025-08-26 00:36:32,407][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007760] [Batch 02891/04869] [00:32:53/00:22:30, 0.683s/it]: train_loss_raw=2.1473, running_loss=2.1225, LR=0.000100
[2025-08-26 00:36:37,929][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007768] [Batch 02899/04869] [00:32:58/00:22:24, 0.683s/it]: train_loss_raw=2.0858, running_loss=2.1241, LR=0.000100
[2025-08-26 00:36:43,406][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007776] [Batch 02907/04869] [00:33:04/00:22:19, 0.683s/it]: train_loss_raw=2.1357, running_loss=2.1250, LR=0.000100
[2025-08-26 00:36:48,637][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007784] [Batch 02915/04869] [00:33:09/00:22:13, 0.683s/it]: train_loss_raw=2.0803, running_loss=2.1230, LR=0.000100
[2025-08-26 00:36:54,073][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007792] [Batch 02923/04869] [00:33:15/00:22:08, 0.683s/it]: train_loss_raw=2.0988, running_loss=2.1221, LR=0.000100
[2025-08-26 00:36:59,865][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007800] [Batch 02931/04869] [00:33:20/00:22:03, 0.683s/it]: train_loss_raw=2.1244, running_loss=2.1224, LR=0.000100
[2025-08-26 00:37:05,836][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007808] [Batch 02939/04869] [00:33:26/00:21:57, 0.683s/it]: train_loss_raw=2.1413, running_loss=2.1214, LR=0.000100
[2025-08-26 00:37:11,074][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007816] [Batch 02947/04869] [00:33:32/00:21:52, 0.683s/it]: train_loss_raw=2.1128, running_loss=2.1205, LR=0.000100
[2025-08-26 00:37:16,401][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007824] [Batch 02955/04869] [00:33:37/00:21:46, 0.683s/it]: train_loss_raw=2.1002, running_loss=2.1202, LR=0.000100
[2025-08-26 00:37:21,865][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007832] [Batch 02963/04869] [00:33:42/00:21:41, 0.683s/it]: train_loss_raw=1.9282, running_loss=2.1172, LR=0.000100
[2025-08-26 00:37:27,109][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007840] [Batch 02971/04869] [00:33:48/00:21:35, 0.683s/it]: train_loss_raw=2.1124, running_loss=2.1174, LR=0.000100
[2025-08-26 00:37:32,316][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007848] [Batch 02979/04869] [00:33:53/00:21:30, 0.683s/it]: train_loss_raw=2.1354, running_loss=2.1170, LR=0.000100
[2025-08-26 00:37:37,700][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007856] [Batch 02987/04869] [00:33:58/00:21:24, 0.683s/it]: train_loss_raw=2.1096, running_loss=2.1170, LR=0.000100
[2025-08-26 00:37:42,946][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007864] [Batch 02995/04869] [00:34:03/00:21:18, 0.682s/it]: train_loss_raw=2.1121, running_loss=2.1171, LR=0.000100
[2025-08-26 00:37:48,628][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007872] [Batch 03003/04869] [00:34:09/00:21:13, 0.683s/it]: train_loss_raw=2.1088, running_loss=2.1169, LR=0.000100
[2025-08-26 00:37:54,710][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007880] [Batch 03011/04869] [00:34:15/00:21:08, 0.683s/it]: train_loss_raw=2.0511, running_loss=2.1173, LR=0.000100
[2025-08-26 00:38:00,191][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007888] [Batch 03019/04869] [00:34:21/00:21:03, 0.683s/it]: train_loss_raw=2.0398, running_loss=2.1153, LR=0.000100
[2025-08-26 00:38:05,569][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007896] [Batch 03027/04869] [00:34:26/00:20:57, 0.683s/it]: train_loss_raw=2.0621, running_loss=2.1152, LR=0.000100
[2025-08-26 00:38:10,812][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007904] [Batch 03035/04869] [00:34:31/00:20:51, 0.683s/it]: train_loss_raw=2.1426, running_loss=2.1130, LR=0.000100
[2025-08-26 00:38:16,573][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007912] [Batch 03043/04869] [00:34:37/00:20:46, 0.683s/it]: train_loss_raw=2.0799, running_loss=2.1101, LR=0.000100
[2025-08-26 00:38:22,325][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007920] [Batch 03051/04869] [00:34:43/00:20:41, 0.683s/it]: train_loss_raw=2.0877, running_loss=2.1092, LR=0.000100
[2025-08-26 00:38:27,684][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007928] [Batch 03059/04869] [00:34:48/00:20:35, 0.683s/it]: train_loss_raw=2.1415, running_loss=2.1107, LR=0.000100
[2025-08-26 00:38:32,934][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007936] [Batch 03067/04869] [00:34:53/00:20:30, 0.683s/it]: train_loss_raw=2.0996, running_loss=2.1114, LR=0.000100
[2025-08-26 00:38:38,347][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007944] [Batch 03075/04869] [00:34:59/00:20:24, 0.683s/it]: train_loss_raw=2.1203, running_loss=2.1091, LR=0.000100
[2025-08-26 00:38:44,480][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007952] [Batch 03083/04869] [00:35:05/00:20:19, 0.683s/it]: train_loss_raw=2.0253, running_loss=2.1084, LR=0.000100
[2025-08-26 00:38:49,780][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007960] [Batch 03091/04869] [00:35:10/00:20:14, 0.683s/it]: train_loss_raw=2.0831, running_loss=2.1094, LR=0.000100
[2025-08-26 00:38:55,041][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007968] [Batch 03099/04869] [00:35:16/00:20:08, 0.683s/it]: train_loss_raw=2.0513, running_loss=2.1080, LR=0.000100
[2025-08-26 00:39:01,048][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007976] [Batch 03107/04869] [00:35:22/00:20:03, 0.683s/it]: train_loss_raw=2.0027, running_loss=2.1053, LR=0.000100
[2025-08-26 00:39:06,987][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007984] [Batch 03115/04869] [00:35:28/00:19:58, 0.683s/it]: train_loss_raw=2.1608, running_loss=2.1047, LR=0.000100
[2025-08-26 00:39:12,443][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 007992] [Batch 03123/04869] [00:35:33/00:19:52, 0.683s/it]: train_loss_raw=2.1202, running_loss=2.1053, LR=0.000100
[2025-08-26 00:39:18,323][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008000] [Batch 03131/04869] [00:35:39/00:19:47, 0.683s/it]: train_loss_raw=2.1784, running_loss=2.1048, LR=0.000100
[2025-08-26 00:39:27,647][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008008] [Batch 03139/04869] [00:35:48/00:19:44, 0.685s/it]: train_loss_raw=2.1224, running_loss=2.1061, LR=0.000100
[2025-08-26 00:39:33,309][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008016] [Batch 03147/04869] [00:35:54/00:19:38, 0.685s/it]: train_loss_raw=2.1033, running_loss=2.1060, LR=0.000100
[2025-08-26 00:39:38,588][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008024] [Batch 03155/04869] [00:35:59/00:19:33, 0.685s/it]: train_loss_raw=2.0246, running_loss=2.1063, LR=0.000100
[2025-08-26 00:39:43,748][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008032] [Batch 03163/04869] [00:36:04/00:19:27, 0.684s/it]: train_loss_raw=2.0752, running_loss=2.1053, LR=0.000100
[2025-08-26 00:39:48,931][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008040] [Batch 03171/04869] [00:36:09/00:19:21, 0.684s/it]: train_loss_raw=2.0592, running_loss=2.1054, LR=0.000100
[2025-08-26 00:39:54,107][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008048] [Batch 03179/04869] [00:36:15/00:19:16, 0.684s/it]: train_loss_raw=2.1564, running_loss=2.1046, LR=0.000100
[2025-08-26 00:39:59,313][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008056] [Batch 03187/04869] [00:36:20/00:19:10, 0.684s/it]: train_loss_raw=2.0818, running_loss=2.1057, LR=0.000100
[2025-08-26 00:40:04,532][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008064] [Batch 03195/04869] [00:36:25/00:19:05, 0.684s/it]: train_loss_raw=2.1060, running_loss=2.1063, LR=0.000100
[2025-08-26 00:40:09,911][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008072] [Batch 03203/04869] [00:36:30/00:18:59, 0.684s/it]: train_loss_raw=2.1043, running_loss=2.1088, LR=0.000100
[2025-08-26 00:40:15,773][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008080] [Batch 03211/04869] [00:36:36/00:18:54, 0.684s/it]: train_loss_raw=2.0270, running_loss=2.1085, LR=0.000100
[2025-08-26 00:40:21,110][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008088] [Batch 03219/04869] [00:36:42/00:18:48, 0.684s/it]: train_loss_raw=2.0754, running_loss=2.1072, LR=0.000100
[2025-08-26 00:40:26,306][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008096] [Batch 03227/04869] [00:36:47/00:18:43, 0.684s/it]: train_loss_raw=2.1155, running_loss=2.1084, LR=0.000100
[2025-08-26 00:40:31,511][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008104] [Batch 03235/04869] [00:36:52/00:18:37, 0.684s/it]: train_loss_raw=2.1255, running_loss=2.1085, LR=0.000100
[2025-08-26 00:40:37,282][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008112] [Batch 03243/04869] [00:36:58/00:18:32, 0.684s/it]: train_loss_raw=2.1281, running_loss=2.1082, LR=0.000100
[2025-08-26 00:40:42,977][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008120] [Batch 03251/04869] [00:37:04/00:18:26, 0.684s/it]: train_loss_raw=2.1156, running_loss=2.1090, LR=0.000100
[2025-08-26 00:40:48,244][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008128] [Batch 03259/04869] [00:37:09/00:18:21, 0.684s/it]: train_loss_raw=2.1153, running_loss=2.1099, LR=0.000100
[2025-08-26 00:40:53,465][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008136] [Batch 03267/04869] [00:37:14/00:18:15, 0.684s/it]: train_loss_raw=2.0792, running_loss=2.1073, LR=0.000100
[2025-08-26 00:40:58,654][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008144] [Batch 03275/04869] [00:37:19/00:18:10, 0.684s/it]: train_loss_raw=2.0642, running_loss=2.1054, LR=0.000100
[2025-08-26 00:41:04,045][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008152] [Batch 03283/04869] [00:37:25/00:18:04, 0.684s/it]: train_loss_raw=2.1201, running_loss=2.1059, LR=0.000100
[2025-08-26 00:41:10,030][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008160] [Batch 03291/04869] [00:37:31/00:17:59, 0.684s/it]: train_loss_raw=2.0883, running_loss=2.1056, LR=0.000100
[2025-08-26 00:41:15,241][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008168] [Batch 03299/04869] [00:37:36/00:17:53, 0.684s/it]: train_loss_raw=2.0871, running_loss=2.1065, LR=0.000100
[2025-08-26 00:41:21,184][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008176] [Batch 03307/04869] [00:37:42/00:17:48, 0.684s/it]: train_loss_raw=2.1552, running_loss=2.1071, LR=0.000100
[2025-08-26 00:41:26,764][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008184] [Batch 03315/04869] [00:37:47/00:17:43, 0.684s/it]: train_loss_raw=2.0891, running_loss=2.1083, LR=0.000100
[2025-08-26 00:41:31,992][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008192] [Batch 03323/04869] [00:37:53/00:17:37, 0.684s/it]: train_loss_raw=2.0884, running_loss=2.1076, LR=0.000100
[2025-08-26 00:41:37,219][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008200] [Batch 03331/04869] [00:37:58/00:17:31, 0.684s/it]: train_loss_raw=2.0703, running_loss=2.1077, LR=0.000100
[2025-08-26 00:41:42,838][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008208] [Batch 03339/04869] [00:38:03/00:17:26, 0.684s/it]: train_loss_raw=2.1283, running_loss=2.1078, LR=0.000100
[2025-08-26 00:41:48,512][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008216] [Batch 03347/04869] [00:38:09/00:17:21, 0.684s/it]: train_loss_raw=2.1324, running_loss=2.1079, LR=0.000100
[2025-08-26 00:41:53,733][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008224] [Batch 03355/04869] [00:38:14/00:17:15, 0.684s/it]: train_loss_raw=2.0788, running_loss=2.1071, LR=0.000100
[2025-08-26 00:41:59,270][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008232] [Batch 03363/04869] [00:38:20/00:17:10, 0.684s/it]: train_loss_raw=2.1450, running_loss=2.1079, LR=0.000100
[2025-08-26 00:42:05,162][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008240] [Batch 03371/04869] [00:38:26/00:17:04, 0.684s/it]: train_loss_raw=2.0801, running_loss=2.1073, LR=0.000100
[2025-08-26 00:42:10,390][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008248] [Batch 03379/04869] [00:38:31/00:16:59, 0.684s/it]: train_loss_raw=2.0540, running_loss=2.1063, LR=0.000100
[2025-08-26 00:42:15,583][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008256] [Batch 03387/04869] [00:38:36/00:16:53, 0.684s/it]: train_loss_raw=2.0218, running_loss=2.1024, LR=0.000100
[2025-08-26 00:42:20,775][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008264] [Batch 03395/04869] [00:38:41/00:16:48, 0.684s/it]: train_loss_raw=2.0775, running_loss=2.1038, LR=0.000100
[2025-08-26 00:42:26,006][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008272] [Batch 03403/04869] [00:38:47/00:16:42, 0.684s/it]: train_loss_raw=2.0322, running_loss=2.1027, LR=0.000100
[2025-08-26 00:42:31,225][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008280] [Batch 03411/04869] [00:38:52/00:16:36, 0.684s/it]: train_loss_raw=2.0565, running_loss=2.1037, LR=0.000100
[2025-08-26 00:42:36,445][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008288] [Batch 03419/04869] [00:38:57/00:16:31, 0.684s/it]: train_loss_raw=2.0600, running_loss=2.1035, LR=0.000100
[2025-08-26 00:42:41,654][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008296] [Batch 03427/04869] [00:39:02/00:16:25, 0.684s/it]: train_loss_raw=2.0910, running_loss=2.1036, LR=0.000100
[2025-08-26 00:42:46,858][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008304] [Batch 03435/04869] [00:39:07/00:16:20, 0.684s/it]: train_loss_raw=2.0949, running_loss=2.1015, LR=0.000100
[2025-08-26 00:42:52,314][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008312] [Batch 03443/04869] [00:39:13/00:16:14, 0.684s/it]: train_loss_raw=2.0802, running_loss=2.1044, LR=0.000100
[2025-08-26 00:42:57,615][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008320] [Batch 03451/04869] [00:39:18/00:16:09, 0.683s/it]: train_loss_raw=2.1307, running_loss=2.1042, LR=0.000100
[2025-08-26 00:43:02,837][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008328] [Batch 03459/04869] [00:39:23/00:16:03, 0.683s/it]: train_loss_raw=2.1113, running_loss=2.1020, LR=0.000100
[2025-08-26 00:43:08,062][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008336] [Batch 03467/04869] [00:39:29/00:15:58, 0.683s/it]: train_loss_raw=2.1062, running_loss=2.1027, LR=0.000100
[2025-08-26 00:43:13,328][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008344] [Batch 03475/04869] [00:39:34/00:15:52, 0.683s/it]: train_loss_raw=2.1143, running_loss=2.1014, LR=0.000100
[2025-08-26 00:43:19,184][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008352] [Batch 03483/04869] [00:39:40/00:15:47, 0.683s/it]: train_loss_raw=2.1148, running_loss=2.1013, LR=0.000100
[2025-08-26 00:43:24,848][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008360] [Batch 03491/04869] [00:39:45/00:15:41, 0.683s/it]: train_loss_raw=2.1051, running_loss=2.1018, LR=0.000100
[2025-08-26 00:43:30,435][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008368] [Batch 03499/04869] [00:39:51/00:15:36, 0.683s/it]: train_loss_raw=2.1151, running_loss=2.0989, LR=0.000100
[2025-08-26 00:43:36,030][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008376] [Batch 03507/04869] [00:39:57/00:15:30, 0.684s/it]: train_loss_raw=2.1292, running_loss=2.1002, LR=0.000100
[2025-08-26 00:43:41,253][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008384] [Batch 03515/04869] [00:40:02/00:15:25, 0.683s/it]: train_loss_raw=2.0931, running_loss=2.0999, LR=0.000100
[2025-08-26 00:43:46,921][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008392] [Batch 03523/04869] [00:40:07/00:15:19, 0.683s/it]: train_loss_raw=2.0668, running_loss=2.0977, LR=0.000100
[2025-08-26 00:43:52,384][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008400] [Batch 03531/04869] [00:40:13/00:15:14, 0.683s/it]: train_loss_raw=2.1105, running_loss=2.0982, LR=0.000100
[2025-08-26 00:43:58,385][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008408] [Batch 03539/04869] [00:40:19/00:15:09, 0.684s/it]: train_loss_raw=2.0758, running_loss=2.0975, LR=0.000100
[2025-08-26 00:44:04,263][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008416] [Batch 03547/04869] [00:40:25/00:15:03, 0.684s/it]: train_loss_raw=2.0921, running_loss=2.0974, LR=0.000100
[2025-08-26 00:44:09,613][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008424] [Batch 03555/04869] [00:40:30/00:14:58, 0.684s/it]: train_loss_raw=2.0111, running_loss=2.0956, LR=0.000100
[2025-08-26 00:44:15,647][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008432] [Batch 03563/04869] [00:40:36/00:14:53, 0.684s/it]: train_loss_raw=1.9882, running_loss=2.0934, LR=0.000100
[2025-08-26 00:44:21,066][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008440] [Batch 03571/04869] [00:40:42/00:14:47, 0.684s/it]: train_loss_raw=2.0967, running_loss=2.0941, LR=0.000100
[2025-08-26 00:44:26,271][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008448] [Batch 03579/04869] [00:40:47/00:14:42, 0.684s/it]: train_loss_raw=2.0867, running_loss=2.0946, LR=0.000100
[2025-08-26 00:44:31,685][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008456] [Batch 03587/04869] [00:40:52/00:14:36, 0.684s/it]: train_loss_raw=2.0424, running_loss=2.0940, LR=0.000100
[2025-08-26 00:44:36,935][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008464] [Batch 03595/04869] [00:40:57/00:14:31, 0.684s/it]: train_loss_raw=2.1450, running_loss=2.0945, LR=0.000100
[2025-08-26 00:44:42,682][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008472] [Batch 03603/04869] [00:41:03/00:14:25, 0.684s/it]: train_loss_raw=2.1591, running_loss=2.0950, LR=0.000100
[2025-08-26 00:44:48,334][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008480] [Batch 03611/04869] [00:41:09/00:14:20, 0.684s/it]: train_loss_raw=2.0720, running_loss=2.0966, LR=0.000100
[2025-08-26 00:44:53,689][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008488] [Batch 03619/04869] [00:41:14/00:14:14, 0.684s/it]: train_loss_raw=2.0755, running_loss=2.0944, LR=0.000100
[2025-08-26 00:44:58,897][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008496] [Batch 03627/04869] [00:41:19/00:14:09, 0.684s/it]: train_loss_raw=2.0280, running_loss=2.0920, LR=0.000100
[2025-08-26 00:45:04,119][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008504] [Batch 03635/04869] [00:41:25/00:14:03, 0.684s/it]: train_loss_raw=2.0912, running_loss=2.0893, LR=0.000100
[2025-08-26 00:45:09,602][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008512] [Batch 03643/04869] [00:41:30/00:13:58, 0.684s/it]: train_loss_raw=2.1206, running_loss=2.0906, LR=0.000100
[2025-08-26 00:45:15,134][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008520] [Batch 03651/04869] [00:41:36/00:13:52, 0.684s/it]: train_loss_raw=1.9913, running_loss=2.0894, LR=0.000100
[2025-08-26 00:45:20,755][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008528] [Batch 03659/04869] [00:41:41/00:13:47, 0.684s/it]: train_loss_raw=2.1188, running_loss=2.0880, LR=0.000100
[2025-08-26 00:45:26,048][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008536] [Batch 03667/04869] [00:41:47/00:13:41, 0.684s/it]: train_loss_raw=2.1417, running_loss=2.0890, LR=0.000100
[2025-08-26 00:45:31,552][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008544] [Batch 03675/04869] [00:41:52/00:13:36, 0.684s/it]: train_loss_raw=2.0367, running_loss=2.0878, LR=0.000100
[2025-08-26 00:45:37,097][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008552] [Batch 03683/04869] [00:41:58/00:13:30, 0.684s/it]: train_loss_raw=2.1830, running_loss=2.0895, LR=0.000100
[2025-08-26 00:45:42,309][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008560] [Batch 03691/04869] [00:42:03/00:13:25, 0.684s/it]: train_loss_raw=2.1251, running_loss=2.0901, LR=0.000100
[2025-08-26 00:45:47,534][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008568] [Batch 03699/04869] [00:42:08/00:13:19, 0.684s/it]: train_loss_raw=2.0882, running_loss=2.0879, LR=0.000100
[2025-08-26 00:45:52,767][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008576] [Batch 03707/04869] [00:42:13/00:13:14, 0.684s/it]: train_loss_raw=2.1423, running_loss=2.0872, LR=0.000100
[2025-08-26 00:45:58,397][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008584] [Batch 03715/04869] [00:42:19/00:13:08, 0.684s/it]: train_loss_raw=2.0876, running_loss=2.0883, LR=0.000100
[2025-08-26 00:46:03,628][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008592] [Batch 03723/04869] [00:42:24/00:13:03, 0.683s/it]: train_loss_raw=2.0520, running_loss=2.0890, LR=0.000100
[2025-08-26 00:46:09,194][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008600] [Batch 03731/04869] [00:42:30/00:12:57, 0.684s/it]: train_loss_raw=2.0499, running_loss=2.0875, LR=0.000100
[2025-08-26 00:46:15,041][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008608] [Batch 03739/04869] [00:42:36/00:12:52, 0.684s/it]: train_loss_raw=2.1105, running_loss=2.0876, LR=0.000100
[2025-08-26 00:46:20,561][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008616] [Batch 03747/04869] [00:42:41/00:12:47, 0.684s/it]: train_loss_raw=2.1364, running_loss=2.0871, LR=0.000100
[2025-08-26 00:46:25,756][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008624] [Batch 03755/04869] [00:42:46/00:12:41, 0.684s/it]: train_loss_raw=2.0479, running_loss=2.0873, LR=0.000100
[2025-08-26 00:46:31,391][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008632] [Batch 03763/04869] [00:42:52/00:12:36, 0.684s/it]: train_loss_raw=2.1119, running_loss=2.0867, LR=0.000100
[2025-08-26 00:46:36,914][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008640] [Batch 03771/04869] [00:42:57/00:12:30, 0.684s/it]: train_loss_raw=2.1452, running_loss=2.0872, LR=0.000100
[2025-08-26 00:46:42,913][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008648] [Batch 03779/04869] [00:43:03/00:12:25, 0.684s/it]: train_loss_raw=2.0794, running_loss=2.0853, LR=0.000100
[2025-08-26 00:46:48,620][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008656] [Batch 03787/04869] [00:43:09/00:12:19, 0.684s/it]: train_loss_raw=2.0849, running_loss=2.0842, LR=0.000100
[2025-08-26 00:46:54,773][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008664] [Batch 03795/04869] [00:43:15/00:12:14, 0.684s/it]: train_loss_raw=2.0957, running_loss=2.0845, LR=0.000100
[2025-08-26 00:47:00,746][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008672] [Batch 03803/04869] [00:43:21/00:12:09, 0.684s/it]: train_loss_raw=2.1680, running_loss=2.0863, LR=0.000100
[2025-08-26 00:47:06,768][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008680] [Batch 03811/04869] [00:43:27/00:12:03, 0.684s/it]: train_loss_raw=2.0847, running_loss=2.0884, LR=0.000100
[2025-08-26 00:47:12,216][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008688] [Batch 03819/04869] [00:43:33/00:11:58, 0.684s/it]: train_loss_raw=2.1133, running_loss=2.0898, LR=0.000100
[2025-08-26 00:47:17,752][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008696] [Batch 03827/04869] [00:43:38/00:11:53, 0.684s/it]: train_loss_raw=2.0682, running_loss=2.0903, LR=0.000100
[2025-08-26 00:47:23,383][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008704] [Batch 03835/04869] [00:43:44/00:11:47, 0.684s/it]: train_loss_raw=2.0162, running_loss=2.0887, LR=0.000100
[2025-08-26 00:47:28,716][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008712] [Batch 03843/04869] [00:43:49/00:11:42, 0.684s/it]: train_loss_raw=2.0540, running_loss=2.0878, LR=0.000100
[2025-08-26 00:47:33,923][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008720] [Batch 03851/04869] [00:43:54/00:11:36, 0.684s/it]: train_loss_raw=2.0941, running_loss=2.0868, LR=0.000100
[2025-08-26 00:47:46,081][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008728] [Batch 03859/04869] [00:44:07/00:11:32, 0.686s/it]: train_loss_raw=2.1534, running_loss=2.0863, LR=0.000100
[2025-08-26 00:47:51,693][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008736] [Batch 03867/04869] [00:44:12/00:11:27, 0.686s/it]: train_loss_raw=2.1020, running_loss=2.0846, LR=0.000100
[2025-08-26 00:47:57,677][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008744] [Batch 03875/04869] [00:44:18/00:11:22, 0.686s/it]: train_loss_raw=2.1079, running_loss=2.0842, LR=0.000100
[2025-08-26 00:48:03,381][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008752] [Batch 03883/04869] [00:44:24/00:11:16, 0.686s/it]: train_loss_raw=2.1012, running_loss=2.0862, LR=0.000100
[2025-08-26 00:48:08,655][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008760] [Batch 03891/04869] [00:44:29/00:11:11, 0.686s/it]: train_loss_raw=2.0684, running_loss=2.0848, LR=0.000100
[2025-08-26 00:48:13,862][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008768] [Batch 03899/04869] [00:44:34/00:11:05, 0.686s/it]: train_loss_raw=2.0427, running_loss=2.0860, LR=0.000100
[2025-08-26 00:48:19,075][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008776] [Batch 03907/04869] [00:44:40/00:10:59, 0.686s/it]: train_loss_raw=2.1343, running_loss=2.0837, LR=0.000100
[2025-08-26 00:48:24,301][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008784] [Batch 03915/04869] [00:44:45/00:10:54, 0.686s/it]: train_loss_raw=2.1169, running_loss=2.0826, LR=0.000100
[2025-08-26 00:48:29,903][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008792] [Batch 03923/04869] [00:44:50/00:10:48, 0.686s/it]: train_loss_raw=2.0414, running_loss=2.0815, LR=0.000100
[2025-08-26 00:48:35,084][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008800] [Batch 03931/04869] [00:44:56/00:10:43, 0.686s/it]: train_loss_raw=2.1082, running_loss=2.0810, LR=0.000100
[2025-08-26 00:48:40,659][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008808] [Batch 03939/04869] [00:45:01/00:10:37, 0.686s/it]: train_loss_raw=2.1048, running_loss=2.0808, LR=0.000100
[2025-08-26 00:48:46,032][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008816] [Batch 03947/04869] [00:45:07/00:10:32, 0.686s/it]: train_loss_raw=2.0511, running_loss=2.0805, LR=0.000100
[2025-08-26 00:48:51,408][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008824] [Batch 03955/04869] [00:45:12/00:10:26, 0.686s/it]: train_loss_raw=2.0194, running_loss=2.0793, LR=0.000100
[2025-08-26 00:48:56,774][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008832] [Batch 03963/04869] [00:45:17/00:10:21, 0.686s/it]: train_loss_raw=2.0660, running_loss=2.0822, LR=0.000100
[2025-08-26 00:49:02,277][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008840] [Batch 03971/04869] [00:45:23/00:10:15, 0.686s/it]: train_loss_raw=2.0997, running_loss=2.0833, LR=0.000100
[2025-08-26 00:49:08,033][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008848] [Batch 03979/04869] [00:45:29/00:10:10, 0.686s/it]: train_loss_raw=2.1172, running_loss=2.0828, LR=0.000100
[2025-08-26 00:49:13,368][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008856] [Batch 03987/04869] [00:45:34/00:10:04, 0.686s/it]: train_loss_raw=2.1845, running_loss=2.0848, LR=0.000100
[2025-08-26 00:49:18,764][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008864] [Batch 03995/04869] [00:45:39/00:09:59, 0.686s/it]: train_loss_raw=2.0415, running_loss=2.0836, LR=0.000100
[2025-08-26 00:49:24,142][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008872] [Batch 04003/04869] [00:45:45/00:09:53, 0.686s/it]: train_loss_raw=2.0620, running_loss=2.0846, LR=0.000100
[2025-08-26 00:49:29,512][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008880] [Batch 04011/04869] [00:45:50/00:09:48, 0.686s/it]: train_loss_raw=2.0936, running_loss=2.0855, LR=0.000100
[2025-08-26 00:49:34,704][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008888] [Batch 04019/04869] [00:45:55/00:09:42, 0.686s/it]: train_loss_raw=2.1262, running_loss=2.0845, LR=0.000100
[2025-08-26 00:49:39,879][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008896] [Batch 04027/04869] [00:46:00/00:09:37, 0.686s/it]: train_loss_raw=2.0869, running_loss=2.0824, LR=0.000100
[2025-08-26 00:49:45,242][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008904] [Batch 04035/04869] [00:46:06/00:09:31, 0.686s/it]: train_loss_raw=2.1224, running_loss=2.0823, LR=0.000100
[2025-08-26 00:49:50,698][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008912] [Batch 04043/04869] [00:46:11/00:09:26, 0.686s/it]: train_loss_raw=2.0325, running_loss=2.0822, LR=0.000100
[2025-08-26 00:49:55,989][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008920] [Batch 04051/04869] [00:46:17/00:09:20, 0.686s/it]: train_loss_raw=2.0745, running_loss=2.0809, LR=0.000100
[2025-08-26 00:50:01,287][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008928] [Batch 04059/04869] [00:46:22/00:09:15, 0.685s/it]: train_loss_raw=2.0298, running_loss=2.0809, LR=0.000100
[2025-08-26 00:50:06,639][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008936] [Batch 04067/04869] [00:46:27/00:09:09, 0.685s/it]: train_loss_raw=2.0908, running_loss=2.0803, LR=0.000100
[2025-08-26 00:50:12,105][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008944] [Batch 04075/04869] [00:46:33/00:09:04, 0.685s/it]: train_loss_raw=2.2014, running_loss=2.0832, LR=0.000100
[2025-08-26 00:50:17,310][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008952] [Batch 04083/04869] [00:46:38/00:08:58, 0.685s/it]: train_loss_raw=2.0467, running_loss=2.0837, LR=0.000100
[2025-08-26 00:50:22,486][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008960] [Batch 04091/04869] [00:46:43/00:08:53, 0.685s/it]: train_loss_raw=1.9551, running_loss=2.0781, LR=0.000100
[2025-08-26 00:50:27,790][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008968] [Batch 04099/04869] [00:46:48/00:08:47, 0.685s/it]: train_loss_raw=2.0643, running_loss=2.0795, LR=0.000100
[2025-08-26 00:50:33,044][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008976] [Batch 04107/04869] [00:46:54/00:08:42, 0.685s/it]: train_loss_raw=2.0827, running_loss=2.0788, LR=0.000100
[2025-08-26 00:50:38,358][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008984] [Batch 04115/04869] [00:46:59/00:08:36, 0.685s/it]: train_loss_raw=2.1456, running_loss=2.0794, LR=0.000100
[2025-08-26 00:50:43,600][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 008992] [Batch 04123/04869] [00:47:04/00:08:31, 0.685s/it]: train_loss_raw=1.9928, running_loss=2.0798, LR=0.000100
[2025-08-26 00:50:49,242][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009000] [Batch 04131/04869] [00:47:10/00:08:25, 0.685s/it]: train_loss_raw=2.0468, running_loss=2.0793, LR=0.000100
[2025-08-26 00:50:54,591][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009008] [Batch 04139/04869] [00:47:15/00:08:20, 0.685s/it]: train_loss_raw=2.0819, running_loss=2.0793, LR=0.000100
[2025-08-26 00:51:00,327][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009016] [Batch 04147/04869] [00:47:21/00:08:14, 0.685s/it]: train_loss_raw=2.1103, running_loss=2.0830, LR=0.000100
[2025-08-26 00:51:05,597][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009024] [Batch 04155/04869] [00:47:26/00:08:09, 0.685s/it]: train_loss_raw=2.0003, running_loss=2.0839, LR=0.000100
[2025-08-26 00:51:11,179][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009032] [Batch 04163/04869] [00:47:32/00:08:03, 0.685s/it]: train_loss_raw=2.0622, running_loss=2.0808, LR=0.000100
[2025-08-26 00:51:16,392][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009040] [Batch 04171/04869] [00:47:37/00:07:58, 0.685s/it]: train_loss_raw=2.0706, running_loss=2.0803, LR=0.000100
[2025-08-26 00:51:22,041][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009048] [Batch 04179/04869] [00:47:43/00:07:52, 0.685s/it]: train_loss_raw=2.0730, running_loss=2.0809, LR=0.000100
[2025-08-26 00:51:27,379][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009056] [Batch 04187/04869] [00:47:48/00:07:47, 0.685s/it]: train_loss_raw=2.0902, running_loss=2.0798, LR=0.000100
[2025-08-26 00:51:33,300][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009064] [Batch 04195/04869] [00:47:54/00:07:41, 0.685s/it]: train_loss_raw=2.0628, running_loss=2.0788, LR=0.000100
[2025-08-26 00:51:38,542][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009072] [Batch 04203/04869] [00:47:59/00:07:36, 0.685s/it]: train_loss_raw=2.0602, running_loss=2.0784, LR=0.000100
[2025-08-26 00:51:44,427][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009080] [Batch 04211/04869] [00:48:05/00:07:30, 0.685s/it]: train_loss_raw=2.0884, running_loss=2.0775, LR=0.000100
[2025-08-26 00:51:49,931][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009088] [Batch 04219/04869] [00:48:10/00:07:25, 0.685s/it]: train_loss_raw=2.0457, running_loss=2.0783, LR=0.000100
[2025-08-26 00:51:55,250][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009096] [Batch 04227/04869] [00:48:16/00:07:19, 0.685s/it]: train_loss_raw=2.0171, running_loss=2.0789, LR=0.000100
[2025-08-26 00:52:00,457][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009104] [Batch 04235/04869] [00:48:21/00:07:14, 0.685s/it]: train_loss_raw=2.1326, running_loss=2.0802, LR=0.000100
[2025-08-26 00:52:05,681][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009112] [Batch 04243/04869] [00:48:26/00:07:08, 0.685s/it]: train_loss_raw=2.0539, running_loss=2.0815, LR=0.000100
[2025-08-26 00:52:10,925][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009120] [Batch 04251/04869] [00:48:31/00:07:03, 0.685s/it]: train_loss_raw=2.1778, running_loss=2.0835, LR=0.000100
[2025-08-26 00:52:16,406][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009128] [Batch 04259/04869] [00:48:37/00:06:57, 0.685s/it]: train_loss_raw=2.0276, running_loss=2.0796, LR=0.000100
[2025-08-26 00:52:21,601][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009136] [Batch 04267/04869] [00:48:42/00:06:52, 0.685s/it]: train_loss_raw=2.0449, running_loss=2.0798, LR=0.000100
[2025-08-26 00:52:26,939][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009144] [Batch 04275/04869] [00:48:47/00:06:46, 0.685s/it]: train_loss_raw=2.0878, running_loss=2.0803, LR=0.000100
[2025-08-26 00:52:32,230][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009152] [Batch 04283/04869] [00:48:53/00:06:41, 0.685s/it]: train_loss_raw=2.1017, running_loss=2.0792, LR=0.000100
[2025-08-26 00:52:37,581][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009160] [Batch 04291/04869] [00:48:58/00:06:35, 0.685s/it]: train_loss_raw=2.0266, running_loss=2.0803, LR=0.000100
[2025-08-26 00:52:42,821][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009168] [Batch 04299/04869] [00:49:03/00:06:30, 0.685s/it]: train_loss_raw=2.0634, running_loss=2.0774, LR=0.000100
[2025-08-26 00:52:48,042][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009176] [Batch 04307/04869] [00:49:09/00:06:24, 0.685s/it]: train_loss_raw=1.9608, running_loss=2.0768, LR=0.000100
[2025-08-26 00:52:53,232][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009184] [Batch 04315/04869] [00:49:14/00:06:19, 0.685s/it]: train_loss_raw=2.0587, running_loss=2.0760, LR=0.000100
[2025-08-26 00:52:59,247][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009192] [Batch 04323/04869] [00:49:20/00:06:13, 0.685s/it]: train_loss_raw=2.1022, running_loss=2.0774, LR=0.000100
[2025-08-26 00:53:04,676][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009200] [Batch 04331/04869] [00:49:25/00:06:08, 0.685s/it]: train_loss_raw=2.0728, running_loss=2.0750, LR=0.000100
[2025-08-26 00:53:10,120][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009208] [Batch 04339/04869] [00:49:31/00:06:02, 0.685s/it]: train_loss_raw=2.0427, running_loss=2.0729, LR=0.000100
[2025-08-26 00:53:15,347][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009216] [Batch 04347/04869] [00:49:36/00:05:57, 0.685s/it]: train_loss_raw=2.0148, running_loss=2.0728, LR=0.000100
[2025-08-26 00:53:21,333][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009224] [Batch 04355/04869] [00:49:42/00:05:51, 0.685s/it]: train_loss_raw=2.1194, running_loss=2.0734, LR=0.000100
[2025-08-26 00:53:26,574][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009232] [Batch 04363/04869] [00:49:47/00:05:46, 0.685s/it]: train_loss_raw=2.1327, running_loss=2.0733, LR=0.000100
[2025-08-26 00:53:32,390][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009240] [Batch 04371/04869] [00:49:53/00:05:41, 0.685s/it]: train_loss_raw=2.0426, running_loss=2.0729, LR=0.000100
[2025-08-26 00:53:37,801][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009248] [Batch 04379/04869] [00:49:58/00:05:35, 0.685s/it]: train_loss_raw=2.0498, running_loss=2.0714, LR=0.000100
[2025-08-26 00:53:43,095][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009256] [Batch 04387/04869] [00:50:04/00:05:30, 0.685s/it]: train_loss_raw=2.0061, running_loss=2.0713, LR=0.000100
[2025-08-26 00:53:48,613][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009264] [Batch 04395/04869] [00:50:09/00:05:24, 0.685s/it]: train_loss_raw=2.0521, running_loss=2.0702, LR=0.000100
[2025-08-26 00:53:54,106][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009272] [Batch 04403/04869] [00:50:15/00:05:19, 0.685s/it]: train_loss_raw=2.1530, running_loss=2.0722, LR=0.000100
[2025-08-26 00:53:59,357][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009280] [Batch 04411/04869] [00:50:20/00:05:13, 0.685s/it]: train_loss_raw=2.1000, running_loss=2.0739, LR=0.000100
[2025-08-26 00:54:04,923][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009288] [Batch 04419/04869] [00:50:25/00:05:08, 0.685s/it]: train_loss_raw=2.0584, running_loss=2.0735, LR=0.000100
[2025-08-26 00:54:10,243][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009296] [Batch 04427/04869] [00:50:31/00:05:02, 0.685s/it]: train_loss_raw=2.0693, running_loss=2.0710, LR=0.000100
[2025-08-26 00:54:15,702][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009304] [Batch 04435/04869] [00:50:36/00:04:57, 0.685s/it]: train_loss_raw=2.0112, running_loss=2.0687, LR=0.000100
[2025-08-26 00:54:20,986][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009312] [Batch 04443/04869] [00:50:42/00:04:51, 0.685s/it]: train_loss_raw=2.0738, running_loss=2.0700, LR=0.000100
[2025-08-26 00:54:26,730][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009320] [Batch 04451/04869] [00:50:47/00:04:46, 0.685s/it]: train_loss_raw=2.0321, running_loss=2.0689, LR=0.000100
[2025-08-26 00:54:32,500][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009328] [Batch 04459/04869] [00:50:53/00:04:40, 0.685s/it]: train_loss_raw=2.1301, running_loss=2.0697, LR=0.000100
[2025-08-26 00:54:37,850][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009336] [Batch 04467/04869] [00:50:58/00:04:35, 0.685s/it]: train_loss_raw=1.9606, running_loss=2.0675, LR=0.000100
[2025-08-26 00:54:43,599][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009344] [Batch 04475/04869] [00:51:04/00:04:29, 0.685s/it]: train_loss_raw=2.0130, running_loss=2.0665, LR=0.000100
[2025-08-26 00:54:49,306][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009352] [Batch 04483/04869] [00:51:10/00:04:24, 0.685s/it]: train_loss_raw=2.0869, running_loss=2.0666, LR=0.000100
[2025-08-26 00:54:54,533][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009360] [Batch 04491/04869] [00:51:15/00:04:18, 0.685s/it]: train_loss_raw=2.0960, running_loss=2.0664, LR=0.000100
[2025-08-26 00:54:59,803][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009368] [Batch 04499/04869] [00:51:20/00:04:13, 0.685s/it]: train_loss_raw=2.1512, running_loss=2.0644, LR=0.000100
[2025-08-26 00:55:05,506][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009376] [Batch 04507/04869] [00:51:26/00:04:07, 0.685s/it]: train_loss_raw=2.0883, running_loss=2.0651, LR=0.000100
[2025-08-26 00:55:10,716][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009384] [Batch 04515/04869] [00:51:31/00:04:02, 0.685s/it]: train_loss_raw=2.0349, running_loss=2.0643, LR=0.000100
[2025-08-26 00:55:16,076][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009392] [Batch 04523/04869] [00:51:37/00:03:56, 0.685s/it]: train_loss_raw=2.0241, running_loss=2.0640, LR=0.000100
[2025-08-26 00:55:21,648][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009400] [Batch 04531/04869] [00:51:42/00:03:51, 0.685s/it]: train_loss_raw=2.0248, running_loss=2.0639, LR=0.000100
[2025-08-26 00:55:26,980][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009408] [Batch 04539/04869] [00:51:48/00:03:45, 0.685s/it]: train_loss_raw=2.1115, running_loss=2.0631, LR=0.000100
[2025-08-26 00:55:32,176][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009416] [Batch 04547/04869] [00:51:53/00:03:40, 0.685s/it]: train_loss_raw=2.1417, running_loss=2.0647, LR=0.000100
[2025-08-26 00:55:37,361][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009424] [Batch 04555/04869] [00:51:58/00:03:34, 0.685s/it]: train_loss_raw=2.0814, running_loss=2.0675, LR=0.000100
[2025-08-26 00:55:42,836][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009432] [Batch 04563/04869] [00:52:03/00:03:29, 0.685s/it]: train_loss_raw=2.0646, running_loss=2.0670, LR=0.000100
[2025-08-26 00:55:48,101][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009440] [Batch 04571/04869] [00:52:09/00:03:23, 0.685s/it]: train_loss_raw=2.0071, running_loss=2.0669, LR=0.000100
[2025-08-26 00:55:53,398][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009448] [Batch 04579/04869] [00:52:14/00:03:18, 0.685s/it]: train_loss_raw=2.1035, running_loss=2.0675, LR=0.000100
[2025-08-26 00:55:58,978][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009456] [Batch 04587/04869] [00:52:20/00:03:13, 0.685s/it]: train_loss_raw=1.9795, running_loss=2.0665, LR=0.000100
[2025-08-26 00:56:04,180][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009464] [Batch 04595/04869] [00:52:25/00:03:07, 0.684s/it]: train_loss_raw=2.0478, running_loss=2.0660, LR=0.000100
[2025-08-26 00:56:09,399][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009472] [Batch 04603/04869] [00:52:30/00:03:02, 0.684s/it]: train_loss_raw=2.1003, running_loss=2.0667, LR=0.000100
[2025-08-26 00:56:14,928][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009480] [Batch 04611/04869] [00:52:35/00:02:56, 0.684s/it]: train_loss_raw=2.0873, running_loss=2.0673, LR=0.000100
[2025-08-26 00:56:20,147][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009488] [Batch 04619/04869] [00:52:41/00:02:51, 0.684s/it]: train_loss_raw=2.1462, running_loss=2.0673, LR=0.000100
[2025-08-26 00:56:25,477][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009496] [Batch 04627/04869] [00:52:46/00:02:45, 0.684s/it]: train_loss_raw=2.1082, running_loss=2.0666, LR=0.000100
[2025-08-26 00:56:30,699][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009504] [Batch 04635/04869] [00:52:51/00:02:40, 0.684s/it]: train_loss_raw=2.1033, running_loss=2.0683, LR=0.000100
[2025-08-26 00:56:35,900][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009512] [Batch 04643/04869] [00:52:56/00:02:34, 0.684s/it]: train_loss_raw=2.0478, running_loss=2.0688, LR=0.000100
[2025-08-26 00:56:41,610][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009520] [Batch 04651/04869] [00:53:02/00:02:29, 0.684s/it]: train_loss_raw=2.1668, running_loss=2.0686, LR=0.000100
[2025-08-26 00:56:47,390][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009528] [Batch 04659/04869] [00:53:08/00:02:23, 0.684s/it]: train_loss_raw=2.0856, running_loss=2.0681, LR=0.000100
[2025-08-26 00:56:52,877][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009536] [Batch 04667/04869] [00:53:13/00:02:18, 0.684s/it]: train_loss_raw=2.1275, running_loss=2.0689, LR=0.000100
[2025-08-26 00:56:58,048][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009544] [Batch 04675/04869] [00:53:19/00:02:12, 0.684s/it]: train_loss_raw=2.1579, running_loss=2.0682, LR=0.000100
[2025-08-26 00:57:03,245][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009552] [Batch 04683/04869] [00:53:24/00:02:07, 0.684s/it]: train_loss_raw=2.0589, running_loss=2.0681, LR=0.000100
[2025-08-26 00:57:08,875][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009560] [Batch 04691/04869] [00:53:29/00:02:01, 0.684s/it]: train_loss_raw=2.1424, running_loss=2.0698, LR=0.000100
[2025-08-26 00:57:14,544][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009568] [Batch 04699/04869] [00:53:35/00:01:56, 0.684s/it]: train_loss_raw=2.1387, running_loss=2.0698, LR=0.000100
[2025-08-26 00:57:20,053][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009576] [Batch 04707/04869] [00:53:41/00:01:50, 0.684s/it]: train_loss_raw=2.1292, running_loss=2.0693, LR=0.000100
[2025-08-26 00:57:25,630][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009584] [Batch 04715/04869] [00:53:46/00:01:45, 0.684s/it]: train_loss_raw=2.0124, running_loss=2.0699, LR=0.000100
[2025-08-26 00:57:30,943][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009592] [Batch 04723/04869] [00:53:51/00:01:39, 0.684s/it]: train_loss_raw=2.1198, running_loss=2.0689, LR=0.000100
[2025-08-26 00:57:36,145][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009600] [Batch 04731/04869] [00:53:57/00:01:34, 0.684s/it]: train_loss_raw=2.0637, running_loss=2.0663, LR=0.000100
[2025-08-26 00:57:41,326][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009608] [Batch 04739/04869] [00:54:02/00:01:28, 0.684s/it]: train_loss_raw=2.0646, running_loss=2.0658, LR=0.000100
[2025-08-26 00:57:46,900][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009616] [Batch 04747/04869] [00:54:07/00:01:23, 0.684s/it]: train_loss_raw=2.0101, running_loss=2.0638, LR=0.000100
[2025-08-26 00:57:52,274][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009624] [Batch 04755/04869] [00:54:13/00:01:17, 0.684s/it]: train_loss_raw=2.0252, running_loss=2.0633, LR=0.000100
[2025-08-26 00:57:57,487][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009632] [Batch 04763/04869] [00:54:18/00:01:12, 0.684s/it]: train_loss_raw=2.0104, running_loss=2.0620, LR=0.000100
[2025-08-26 00:58:02,784][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009640] [Batch 04771/04869] [00:54:23/00:01:07, 0.684s/it]: train_loss_raw=1.9996, running_loss=2.0620, LR=0.000100
[2025-08-26 00:58:08,056][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009648] [Batch 04779/04869] [00:54:29/00:01:01, 0.684s/it]: train_loss_raw=2.0943, running_loss=2.0607, LR=0.000100
[2025-08-26 00:58:13,941][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009656] [Batch 04787/04869] [00:54:34/00:00:56, 0.684s/it]: train_loss_raw=2.0075, running_loss=2.0593, LR=0.000100
[2025-08-26 00:58:19,487][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009664] [Batch 04795/04869] [00:54:40/00:00:50, 0.684s/it]: train_loss_raw=2.0484, running_loss=2.0619, LR=0.000100
[2025-08-26 00:58:24,703][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009672] [Batch 04803/04869] [00:54:45/00:00:45, 0.684s/it]: train_loss_raw=2.1104, running_loss=2.0631, LR=0.000100
[2025-08-26 00:58:29,926][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009680] [Batch 04811/04869] [00:54:50/00:00:39, 0.684s/it]: train_loss_raw=2.1106, running_loss=2.0622, LR=0.000100
[2025-08-26 00:58:35,158][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009688] [Batch 04819/04869] [00:54:56/00:00:34, 0.684s/it]: train_loss_raw=2.0302, running_loss=2.0588, LR=0.000100
[2025-08-26 00:58:40,657][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009696] [Batch 04827/04869] [00:55:01/00:00:28, 0.684s/it]: train_loss_raw=2.0713, running_loss=2.0584, LR=0.000100
[2025-08-26 00:58:46,749][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009704] [Batch 04835/04869] [00:55:07/00:00:23, 0.684s/it]: train_loss_raw=1.9849, running_loss=2.0572, LR=0.000100
[2025-08-26 00:58:52,010][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009712] [Batch 04843/04869] [00:55:13/00:00:17, 0.684s/it]: train_loss_raw=2.0882, running_loss=2.0563, LR=0.000100
[2025-08-26 00:58:57,745][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009720] [Batch 04851/04869] [00:55:18/00:00:12, 0.684s/it]: train_loss_raw=2.1227, running_loss=2.0578, LR=0.000100
[2025-08-26 00:59:03,377][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009728] [Batch 04859/04869] [00:55:24/00:00:06, 0.684s/it]: train_loss_raw=2.0859, running_loss=2.0581, LR=0.000100
[2025-08-26 00:59:09,333][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 009736] [Batch 04867/04869] [00:55:30/00:00:01, 0.684s/it]: train_loss_raw=2.0458, running_loss=2.0578, LR=0.000100
[2025-08-26 00:59:30,641][__main__][INFO] - [VALIDATION] [Epoch 01/29] Starting validation.
[2025-08-26 00:59:41,176][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00007/00124] [00:00:10/00:02:32, 1.317s/it]
[2025-08-26 00:59:52,462][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00015/00124] [00:00:21/00:02:27, 1.364s/it]
[2025-08-26 01:00:03,272][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00023/00124] [00:00:32/00:02:15, 1.360s/it]
[2025-08-26 01:00:23,028][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00031/00124] [00:00:52/00:02:30, 1.637s/it]
[2025-08-26 01:00:33,841][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00039/00124] [00:01:03/00:02:12, 1.580s/it]
[2025-08-26 01:00:44,273][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00047/00124] [00:01:13/00:01:56, 1.534s/it]
[2025-08-26 01:00:54,641][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00055/00124] [00:01:23/00:01:41, 1.500s/it]
[2025-08-26 01:01:05,420][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00063/00124] [00:01:34/00:01:28, 1.481s/it]
[2025-08-26 01:01:16,743][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00071/00124] [00:01:46/00:01:16, 1.474s/it]
[2025-08-26 01:01:28,007][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00079/00124] [00:01:57/00:01:04, 1.467s/it]
[2025-08-26 01:01:39,846][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00087/00124] [00:02:09/00:00:52, 1.468s/it]
[2025-08-26 01:01:51,284][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00095/00124] [00:02:20/00:00:41, 1.465s/it]
[2025-08-26 01:02:01,887][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00103/00124] [00:02:31/00:00:29, 1.454s/it]
[2025-08-26 01:02:12,647][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00111/00124] [00:02:42/00:00:17, 1.446s/it]
[2025-08-26 01:02:23,610][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 009739] [Batch 00119/00124] [00:02:52/00:00:05, 1.441s/it]
[2025-08-26 01:02:28,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] train_loss=2.05779, valid_loss=2.08986
[2025-08-26 01:02:28,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] Metrics:
[2025-08-26 01:02:28,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_er      0.783
[2025-08-26 01:02:28,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_prec    0.025
[2025-08-26 01:02:28,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_recall  0.025
[2025-08-26 01:02:28,507][__main__][INFO] - [VALIDATION] [Epoch 01/29] - pep_recall 0.001
[2025-08-26 01:02:28,511][__main__][INFO] - [TRAIN] [Epoch 01/29] Epoch complete, total time 01:58:08, remaining time 27:33:59, 00:59:04 per epoch
[2025-08-26 01:02:32,061][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009744] [Batch 00006/04869] [00:00:03/00:46:01, 0.568s/it]: train_loss_raw=2.0193, running_loss=2.1352, LR=0.000100
[2025-08-26 01:02:38,223][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009752] [Batch 00014/04869] [00:00:09/00:55:18, 0.684s/it]: train_loss_raw=2.0148, running_loss=2.1272, LR=0.000100
[2025-08-26 01:02:44,347][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009760] [Batch 00022/04869] [00:00:15/00:57:37, 0.713s/it]: train_loss_raw=2.0695, running_loss=2.1196, LR=0.000100
[2025-08-26 01:02:49,847][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009768] [Batch 00030/04869] [00:00:21/00:56:58, 0.706s/it]: train_loss_raw=2.0258, running_loss=2.1117, LR=0.000100
[2025-08-26 01:02:55,325][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009776] [Batch 00038/04869] [00:00:26/00:56:30, 0.702s/it]: train_loss_raw=2.0854, running_loss=2.1075, LR=0.000100
[2025-08-26 01:03:00,831][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009784] [Batch 00046/04869] [00:00:32/00:56:13, 0.700s/it]: train_loss_raw=1.9614, running_loss=2.1002, LR=0.000100
[2025-08-26 01:03:06,206][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009792] [Batch 00054/04869] [00:00:37/00:55:48, 0.695s/it]: train_loss_raw=2.0612, running_loss=2.0951, LR=0.000100
[2025-08-26 01:03:11,407][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009800] [Batch 00062/04869] [00:00:42/00:55:14, 0.690s/it]: train_loss_raw=1.9645, running_loss=2.0927, LR=0.000100
[2025-08-26 01:03:16,582][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009808] [Batch 00070/04869] [00:00:47/00:54:45, 0.685s/it]: train_loss_raw=2.0512, running_loss=2.0868, LR=0.000100
[2025-08-26 01:03:21,767][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009816] [Batch 00078/04869] [00:00:53/00:54:22, 0.681s/it]: train_loss_raw=1.9704, running_loss=2.0820, LR=0.000100
[2025-08-26 01:03:26,968][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009824] [Batch 00086/04869] [00:00:58/00:54:03, 0.678s/it]: train_loss_raw=1.9914, running_loss=2.0793, LR=0.000100
[2025-08-26 01:03:32,355][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009832] [Batch 00094/04869] [00:01:03/00:53:55, 0.678s/it]: train_loss_raw=2.0889, running_loss=2.0769, LR=0.000100
[2025-08-26 01:03:38,189][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009840] [Batch 00102/04869] [00:01:09/00:54:09, 0.682s/it]: train_loss_raw=2.0220, running_loss=2.0759, LR=0.000100
[2025-08-26 01:03:43,520][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009848] [Batch 00110/04869] [00:01:14/00:53:58, 0.681s/it]: train_loss_raw=2.1145, running_loss=2.0760, LR=0.000100
[2025-08-26 01:03:48,985][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009856] [Batch 00118/04869] [00:01:20/00:53:54, 0.681s/it]: train_loss_raw=1.8545, running_loss=2.0729, LR=0.000100
[2025-08-26 01:03:54,198][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009864] [Batch 00126/04869] [00:01:25/00:53:40, 0.679s/it]: train_loss_raw=2.0833, running_loss=2.0706, LR=0.000100
[2025-08-26 01:03:59,813][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009872] [Batch 00134/04869] [00:01:31/00:53:41, 0.680s/it]: train_loss_raw=2.0681, running_loss=2.0687, LR=0.000100
[2025-08-26 01:04:05,764][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009880] [Batch 00142/04869] [00:01:37/00:53:52, 0.684s/it]: train_loss_raw=2.0262, running_loss=2.0668, LR=0.000100
[2025-08-26 01:04:11,466][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009888] [Batch 00150/04869] [00:01:42/00:53:54, 0.685s/it]: train_loss_raw=2.0732, running_loss=2.0642, LR=0.000100
[2025-08-26 01:04:16,855][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009896] [Batch 00158/04869] [00:01:48/00:53:46, 0.685s/it]: train_loss_raw=2.0160, running_loss=2.0605, LR=0.000100
[2025-08-26 01:04:22,437][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009904] [Batch 00166/04869] [00:01:53/00:53:43, 0.685s/it]: train_loss_raw=2.0372, running_loss=2.0570, LR=0.000100
[2025-08-26 01:04:27,620][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009912] [Batch 00174/04869] [00:01:58/00:53:30, 0.684s/it]: train_loss_raw=1.9840, running_loss=2.0540, LR=0.000100
[2025-08-26 01:04:32,799][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009920] [Batch 00182/04869] [00:02:04/00:53:17, 0.682s/it]: train_loss_raw=2.1206, running_loss=2.0534, LR=0.000100
[2025-08-26 01:04:37,979][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009928] [Batch 00190/04869] [00:02:09/00:53:04, 0.681s/it]: train_loss_raw=1.9952, running_loss=2.0530, LR=0.000100
[2025-08-26 01:04:43,152][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009936] [Batch 00198/04869] [00:02:14/00:52:52, 0.679s/it]: train_loss_raw=2.1004, running_loss=2.0523, LR=0.000100
[2025-08-26 01:04:48,740][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009944] [Batch 00206/04869] [00:02:20/00:52:50, 0.680s/it]: train_loss_raw=2.1210, running_loss=2.0524, LR=0.000100
[2025-08-26 01:04:54,542][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009952] [Batch 00214/04869] [00:02:25/00:52:53, 0.682s/it]: train_loss_raw=1.9717, running_loss=2.0513, LR=0.000100
[2025-08-26 01:05:00,052][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009960] [Batch 00222/04869] [00:02:31/00:52:49, 0.682s/it]: train_loss_raw=2.1635, running_loss=2.0503, LR=0.000100
[2025-08-26 01:05:05,440][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009968] [Batch 00230/04869] [00:02:36/00:52:42, 0.682s/it]: train_loss_raw=2.0053, running_loss=2.0511, LR=0.000100
[2025-08-26 01:05:10,698][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009976] [Batch 00238/04869] [00:02:42/00:52:33, 0.681s/it]: train_loss_raw=2.0724, running_loss=2.0502, LR=0.000100
[2025-08-26 01:05:15,999][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009984] [Batch 00246/04869] [00:02:47/00:52:24, 0.680s/it]: train_loss_raw=2.0114, running_loss=2.0487, LR=0.000100
[2025-08-26 01:05:21,304][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 009992] [Batch 00254/04869] [00:02:52/00:52:16, 0.680s/it]: train_loss_raw=1.9919, running_loss=2.0468, LR=0.000100
[2025-08-26 01:05:26,656][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010000] [Batch 00262/04869] [00:02:58/00:52:09, 0.679s/it]: train_loss_raw=2.0228, running_loss=2.0456, LR=0.000100
[2025-08-26 01:05:35,619][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010008] [Batch 00270/04869] [00:03:06/00:53:04, 0.692s/it]: train_loss_raw=2.0489, running_loss=2.0442, LR=0.000100
[2025-08-26 01:05:40,792][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010016] [Batch 00278/04869] [00:03:12/00:52:53, 0.691s/it]: train_loss_raw=1.9754, running_loss=2.0432, LR=0.000100
[2025-08-26 01:05:45,967][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010024] [Batch 00286/04869] [00:03:17/00:52:41, 0.690s/it]: train_loss_raw=2.0296, running_loss=2.0396, LR=0.000100
[2025-08-26 01:05:51,166][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010032] [Batch 00294/04869] [00:03:22/00:52:31, 0.689s/it]: train_loss_raw=2.0787, running_loss=2.0390, LR=0.000100
[2025-08-26 01:05:56,885][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010040] [Batch 00302/04869] [00:03:28/00:52:28, 0.690s/it]: train_loss_raw=1.9602, running_loss=2.0364, LR=0.000100
[2025-08-26 01:06:02,422][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010048] [Batch 00310/04869] [00:03:33/00:52:23, 0.690s/it]: train_loss_raw=1.9928, running_loss=2.0347, LR=0.000100
[2025-08-26 01:06:08,363][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010056] [Batch 00318/04869] [00:03:39/00:52:24, 0.691s/it]: train_loss_raw=2.0226, running_loss=2.0342, LR=0.000100
[2025-08-26 01:06:13,611][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010064] [Batch 00326/04869] [00:03:44/00:52:14, 0.690s/it]: train_loss_raw=2.0521, running_loss=2.0342, LR=0.000100
[2025-08-26 01:06:19,107][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010072] [Batch 00334/04869] [00:03:50/00:52:09, 0.690s/it]: train_loss_raw=2.0071, running_loss=2.0359, LR=0.000100
[2025-08-26 01:06:24,445][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010080] [Batch 00342/04869] [00:03:55/00:52:01, 0.689s/it]: train_loss_raw=1.9712, running_loss=2.0349, LR=0.000100
[2025-08-26 01:06:30,250][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010088] [Batch 00350/04869] [00:04:01/00:51:59, 0.690s/it]: train_loss_raw=2.0099, running_loss=2.0370, LR=0.000100
[2025-08-26 01:06:35,796][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010096] [Batch 00358/04869] [00:04:07/00:51:54, 0.690s/it]: train_loss_raw=2.0191, running_loss=2.0353, LR=0.000100
[2025-08-26 01:06:41,054][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010104] [Batch 00366/04869] [00:04:12/00:51:45, 0.690s/it]: train_loss_raw=2.0901, running_loss=2.0377, LR=0.000100
[2025-08-26 01:06:46,535][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010112] [Batch 00374/04869] [00:04:17/00:51:39, 0.690s/it]: train_loss_raw=2.0367, running_loss=2.0359, LR=0.000100
[2025-08-26 01:06:51,745][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010120] [Batch 00382/04869] [00:04:23/00:51:30, 0.689s/it]: train_loss_raw=2.0825, running_loss=2.0394, LR=0.000100
[2025-08-26 01:06:56,956][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010128] [Batch 00390/04869] [00:04:28/00:51:21, 0.688s/it]: train_loss_raw=2.0916, running_loss=2.0384, LR=0.000100
[2025-08-26 01:07:02,224][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010136] [Batch 00398/04869] [00:04:33/00:51:13, 0.687s/it]: train_loss_raw=2.0477, running_loss=2.0380, LR=0.000100
[2025-08-26 01:07:07,438][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010144] [Batch 00406/04869] [00:04:38/00:51:04, 0.687s/it]: train_loss_raw=1.9978, running_loss=2.0394, LR=0.000100
[2025-08-26 01:07:12,951][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010152] [Batch 00414/04869] [00:04:44/00:50:59, 0.687s/it]: train_loss_raw=1.9984, running_loss=2.0378, LR=0.000100
[2025-08-26 01:07:18,819][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010160] [Batch 00422/04869] [00:04:50/00:50:57, 0.688s/it]: train_loss_raw=2.0315, running_loss=2.0385, LR=0.000100
[2025-08-26 01:07:24,261][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010168] [Batch 00430/04869] [00:04:55/00:50:51, 0.687s/it]: train_loss_raw=2.1210, running_loss=2.0379, LR=0.000100
[2025-08-26 01:07:29,616][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010176] [Batch 00438/04869] [00:05:00/00:50:44, 0.687s/it]: train_loss_raw=2.1187, running_loss=2.0391, LR=0.000100
[2025-08-26 01:07:35,056][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010184] [Batch 00446/04869] [00:05:06/00:50:38, 0.687s/it]: train_loss_raw=1.9854, running_loss=2.0386, LR=0.000100
[2025-08-26 01:07:40,566][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010192] [Batch 00454/04869] [00:05:11/00:50:33, 0.687s/it]: train_loss_raw=1.9065, running_loss=2.0388, LR=0.000100
[2025-08-26 01:07:46,061][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010200] [Batch 00462/04869] [00:05:17/00:50:27, 0.687s/it]: train_loss_raw=2.0218, running_loss=2.0375, LR=0.000100
[2025-08-26 01:07:51,305][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010208] [Batch 00470/04869] [00:05:22/00:50:19, 0.686s/it]: train_loss_raw=2.0970, running_loss=2.0364, LR=0.000100
[2025-08-26 01:07:56,576][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010216] [Batch 00478/04869] [00:05:27/00:50:12, 0.686s/it]: train_loss_raw=2.0141, running_loss=2.0347, LR=0.000100
[2025-08-26 01:08:02,074][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010224] [Batch 00486/04869] [00:05:33/00:50:06, 0.686s/it]: train_loss_raw=2.0062, running_loss=2.0324, LR=0.000100
[2025-08-26 01:08:07,280][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010232] [Batch 00494/04869] [00:05:38/00:49:58, 0.685s/it]: train_loss_raw=2.0346, running_loss=2.0308, LR=0.000100
[2025-08-26 01:08:12,649][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010240] [Batch 00502/04869] [00:05:43/00:49:52, 0.685s/it]: train_loss_raw=1.9711, running_loss=2.0310, LR=0.000100
[2025-08-26 01:08:18,557][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010248] [Batch 00510/04869] [00:05:49/00:49:50, 0.686s/it]: train_loss_raw=2.0368, running_loss=2.0306, LR=0.000100
[2025-08-26 01:08:24,045][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010256] [Batch 00518/04869] [00:05:55/00:49:45, 0.686s/it]: train_loss_raw=2.0102, running_loss=2.0304, LR=0.000100
[2025-08-26 01:08:29,225][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010264] [Batch 00526/04869] [00:06:00/00:49:37, 0.685s/it]: train_loss_raw=1.9665, running_loss=2.0302, LR=0.000100
[2025-08-26 01:08:34,864][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010272] [Batch 00534/04869] [00:06:06/00:49:32, 0.686s/it]: train_loss_raw=2.0400, running_loss=2.0307, LR=0.000100
[2025-08-26 01:08:40,510][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010280] [Batch 00542/04869] [00:06:11/00:49:28, 0.686s/it]: train_loss_raw=1.9511, running_loss=2.0310, LR=0.000100
[2025-08-26 01:08:45,886][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010288] [Batch 00550/04869] [00:06:17/00:49:22, 0.686s/it]: train_loss_raw=2.0168, running_loss=2.0304, LR=0.000100
[2025-08-26 01:08:51,086][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010296] [Batch 00558/04869] [00:06:22/00:49:14, 0.685s/it]: train_loss_raw=2.1141, running_loss=2.0288, LR=0.000100
[2025-08-26 01:08:56,759][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010304] [Batch 00566/04869] [00:06:28/00:49:10, 0.686s/it]: train_loss_raw=2.0275, running_loss=2.0292, LR=0.000100
[2025-08-26 01:09:02,431][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010312] [Batch 00574/04869] [00:06:33/00:49:06, 0.686s/it]: train_loss_raw=2.0668, running_loss=2.0316, LR=0.000100
[2025-08-26 01:09:07,818][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010320] [Batch 00582/04869] [00:06:39/00:49:00, 0.686s/it]: train_loss_raw=2.0146, running_loss=2.0299, LR=0.000100
[2025-08-26 01:09:13,314][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010328] [Batch 00590/04869] [00:06:44/00:48:54, 0.686s/it]: train_loss_raw=2.0504, running_loss=2.0308, LR=0.000100
[2025-08-26 01:09:18,536][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010336] [Batch 00598/04869] [00:06:49/00:48:47, 0.685s/it]: train_loss_raw=1.9197, running_loss=2.0278, LR=0.000100
[2025-08-26 01:09:24,030][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010344] [Batch 00606/04869] [00:06:55/00:48:42, 0.685s/it]: train_loss_raw=2.0263, running_loss=2.0295, LR=0.000100
[2025-08-26 01:09:29,905][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010352] [Batch 00614/04869] [00:07:01/00:48:39, 0.686s/it]: train_loss_raw=1.9505, running_loss=2.0305, LR=0.000100
[2025-08-26 01:09:35,832][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010360] [Batch 00622/04869] [00:07:07/00:48:36, 0.687s/it]: train_loss_raw=2.0162, running_loss=2.0285, LR=0.000100
[2025-08-26 01:09:41,428][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010368] [Batch 00630/04869] [00:07:12/00:48:31, 0.687s/it]: train_loss_raw=2.0286, running_loss=2.0301, LR=0.000100
[2025-08-26 01:09:46,820][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010376] [Batch 00638/04869] [00:07:18/00:48:25, 0.687s/it]: train_loss_raw=2.0655, running_loss=2.0295, LR=0.000100
[2025-08-26 01:09:52,558][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010384] [Batch 00646/04869] [00:07:23/00:48:21, 0.687s/it]: train_loss_raw=2.0884, running_loss=2.0308, LR=0.000100
[2025-08-26 01:09:57,769][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010392] [Batch 00654/04869] [00:07:29/00:48:14, 0.687s/it]: train_loss_raw=2.1071, running_loss=2.0316, LR=0.000100
[2025-08-26 01:10:02,995][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010400] [Batch 00662/04869] [00:07:34/00:48:07, 0.686s/it]: train_loss_raw=1.9995, running_loss=2.0300, LR=0.000100
[2025-08-26 01:10:08,692][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010408] [Batch 00670/04869] [00:07:40/00:48:03, 0.687s/it]: train_loss_raw=2.0463, running_loss=2.0318, LR=0.000100
[2025-08-26 01:10:14,380][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010416] [Batch 00678/04869] [00:07:45/00:47:58, 0.687s/it]: train_loss_raw=2.0500, running_loss=2.0310, LR=0.000100
[2025-08-26 01:10:19,591][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010424] [Batch 00686/04869] [00:07:50/00:47:51, 0.686s/it]: train_loss_raw=2.0166, running_loss=2.0298, LR=0.000100
[2025-08-26 01:10:24,799][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010432] [Batch 00694/04869] [00:07:56/00:47:44, 0.686s/it]: train_loss_raw=2.0469, running_loss=2.0310, LR=0.000100
[2025-08-26 01:10:30,021][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010440] [Batch 00702/04869] [00:08:01/00:47:37, 0.686s/it]: train_loss_raw=1.9940, running_loss=2.0282, LR=0.000100
[2025-08-26 01:10:35,253][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010448] [Batch 00710/04869] [00:08:06/00:47:30, 0.685s/it]: train_loss_raw=2.0243, running_loss=2.0281, LR=0.000100
[2025-08-26 01:10:40,453][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010456] [Batch 00718/04869] [00:08:11/00:47:23, 0.685s/it]: train_loss_raw=1.9439, running_loss=2.0278, LR=0.000100
[2025-08-26 01:10:45,658][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010464] [Batch 00726/04869] [00:08:17/00:47:16, 0.685s/it]: train_loss_raw=2.1062, running_loss=2.0276, LR=0.000100
[2025-08-26 01:10:50,907][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010472] [Batch 00734/04869] [00:08:22/00:47:09, 0.684s/it]: train_loss_raw=2.0355, running_loss=2.0289, LR=0.000100
[2025-08-26 01:10:56,124][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010480] [Batch 00742/04869] [00:08:27/00:47:02, 0.684s/it]: train_loss_raw=1.9708, running_loss=2.0285, LR=0.000100
[2025-08-26 01:11:01,340][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010488] [Batch 00750/04869] [00:08:32/00:46:55, 0.684s/it]: train_loss_raw=2.0253, running_loss=2.0301, LR=0.000100
[2025-08-26 01:11:06,554][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010496] [Batch 00758/04869] [00:08:37/00:46:48, 0.683s/it]: train_loss_raw=1.9910, running_loss=2.0320, LR=0.000100
[2025-08-26 01:11:11,756][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010504] [Batch 00766/04869] [00:08:43/00:46:41, 0.683s/it]: train_loss_raw=1.9550, running_loss=2.0313, LR=0.000100
[2025-08-26 01:11:17,021][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010512] [Batch 00774/04869] [00:08:48/00:46:35, 0.683s/it]: train_loss_raw=1.9735, running_loss=2.0318, LR=0.000100
[2025-08-26 01:11:22,240][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010520] [Batch 00782/04869] [00:08:53/00:46:28, 0.682s/it]: train_loss_raw=1.9925, running_loss=2.0310, LR=0.000100
[2025-08-26 01:11:27,452][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010528] [Batch 00790/04869] [00:08:58/00:46:21, 0.682s/it]: train_loss_raw=1.9745, running_loss=2.0304, LR=0.000100
[2025-08-26 01:11:33,338][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010536] [Batch 00798/04869] [00:09:04/00:46:18, 0.683s/it]: train_loss_raw=2.1127, running_loss=2.0306, LR=0.000100
[2025-08-26 01:11:38,529][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010544] [Batch 00806/04869] [00:09:09/00:46:11, 0.682s/it]: train_loss_raw=2.0209, running_loss=2.0297, LR=0.000100
[2025-08-26 01:11:43,736][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010552] [Batch 00814/04869] [00:09:15/00:46:05, 0.682s/it]: train_loss_raw=2.1191, running_loss=2.0319, LR=0.000100
[2025-08-26 01:11:49,085][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010560] [Batch 00822/04869] [00:09:20/00:45:59, 0.682s/it]: train_loss_raw=2.0369, running_loss=2.0317, LR=0.000100
[2025-08-26 01:11:54,605][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010568] [Batch 00830/04869] [00:09:25/00:45:54, 0.682s/it]: train_loss_raw=2.0190, running_loss=2.0312, LR=0.000100
[2025-08-26 01:12:00,068][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010576] [Batch 00838/04869] [00:09:31/00:45:48, 0.682s/it]: train_loss_raw=2.0654, running_loss=2.0304, LR=0.000100
[2025-08-26 01:12:05,317][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010584] [Batch 00846/04869] [00:09:36/00:45:42, 0.682s/it]: train_loss_raw=2.0761, running_loss=2.0264, LR=0.000100
[2025-08-26 01:12:10,516][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010592] [Batch 00854/04869] [00:09:41/00:45:35, 0.681s/it]: train_loss_raw=2.1194, running_loss=2.0274, LR=0.000100
[2025-08-26 01:12:15,744][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010600] [Batch 00862/04869] [00:09:47/00:45:29, 0.681s/it]: train_loss_raw=2.0419, running_loss=2.0267, LR=0.000100
[2025-08-26 01:12:20,926][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010608] [Batch 00870/04869] [00:09:52/00:45:22, 0.681s/it]: train_loss_raw=2.0531, running_loss=2.0235, LR=0.000100
[2025-08-26 01:12:26,103][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010616] [Batch 00878/04869] [00:09:57/00:45:15, 0.680s/it]: train_loss_raw=1.9944, running_loss=2.0222, LR=0.000100
[2025-08-26 01:12:31,720][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010624] [Batch 00886/04869] [00:10:03/00:45:11, 0.681s/it]: train_loss_raw=2.0611, running_loss=2.0217, LR=0.000100
[2025-08-26 01:12:37,359][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010632] [Batch 00894/04869] [00:10:08/00:45:06, 0.681s/it]: train_loss_raw=1.9631, running_loss=2.0206, LR=0.000100
[2025-08-26 01:12:42,879][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010640] [Batch 00902/04869] [00:10:14/00:45:01, 0.681s/it]: train_loss_raw=2.0450, running_loss=2.0219, LR=0.000100
[2025-08-26 01:12:48,094][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010648] [Batch 00910/04869] [00:10:19/00:44:54, 0.681s/it]: train_loss_raw=2.0432, running_loss=2.0220, LR=0.000100
[2025-08-26 01:12:53,262][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010656] [Batch 00918/04869] [00:10:24/00:44:48, 0.680s/it]: train_loss_raw=2.0159, running_loss=2.0215, LR=0.000100
[2025-08-26 01:12:58,457][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010664] [Batch 00926/04869] [00:10:29/00:44:41, 0.680s/it]: train_loss_raw=2.0049, running_loss=2.0210, LR=0.000100
[2025-08-26 01:13:03,641][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010672] [Batch 00934/04869] [00:10:34/00:44:35, 0.680s/it]: train_loss_raw=2.0844, running_loss=2.0200, LR=0.000100
[2025-08-26 01:13:09,115][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010680] [Batch 00942/04869] [00:10:40/00:44:29, 0.680s/it]: train_loss_raw=1.9273, running_loss=2.0199, LR=0.000100
[2025-08-26 01:13:14,523][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010688] [Batch 00950/04869] [00:10:45/00:44:24, 0.680s/it]: train_loss_raw=2.1115, running_loss=2.0213, LR=0.000100
[2025-08-26 01:13:19,752][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010696] [Batch 00958/04869] [00:10:51/00:44:18, 0.680s/it]: train_loss_raw=1.9802, running_loss=2.0190, LR=0.000100
[2025-08-26 01:13:25,376][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010704] [Batch 00966/04869] [00:10:56/00:44:13, 0.680s/it]: train_loss_raw=2.0688, running_loss=2.0217, LR=0.000100
[2025-08-26 01:13:30,556][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010712] [Batch 00974/04869] [00:11:01/00:44:06, 0.680s/it]: train_loss_raw=2.0908, running_loss=2.0237, LR=0.000100
[2025-08-26 01:13:35,730][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010720] [Batch 00982/04869] [00:11:07/00:44:00, 0.679s/it]: train_loss_raw=2.0223, running_loss=2.0235, LR=0.000100
[2025-08-26 01:13:41,130][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010728] [Batch 00990/04869] [00:11:12/00:43:54, 0.679s/it]: train_loss_raw=1.9725, running_loss=2.0232, LR=0.000100
[2025-08-26 01:13:46,684][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010736] [Batch 00998/04869] [00:11:18/00:43:49, 0.679s/it]: train_loss_raw=1.9896, running_loss=2.0218, LR=0.000100
[2025-08-26 01:13:51,897][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010744] [Batch 01006/04869] [00:11:23/00:43:43, 0.679s/it]: train_loss_raw=2.0783, running_loss=2.0230, LR=0.000100
[2025-08-26 01:13:57,357][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010752] [Batch 01014/04869] [00:11:28/00:43:38, 0.679s/it]: train_loss_raw=1.9999, running_loss=2.0240, LR=0.000100
[2025-08-26 01:14:02,743][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010760] [Batch 01022/04869] [00:11:34/00:43:32, 0.679s/it]: train_loss_raw=1.9317, running_loss=2.0205, LR=0.000100
[2025-08-26 01:14:07,943][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010768] [Batch 01030/04869] [00:11:39/00:43:26, 0.679s/it]: train_loss_raw=2.1036, running_loss=2.0204, LR=0.000100
[2025-08-26 01:14:13,146][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010776] [Batch 01038/04869] [00:11:44/00:43:20, 0.679s/it]: train_loss_raw=1.9896, running_loss=2.0190, LR=0.000100
[2025-08-26 01:14:18,793][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010784] [Batch 01046/04869] [00:11:50/00:43:15, 0.679s/it]: train_loss_raw=2.0391, running_loss=2.0201, LR=0.000100
[2025-08-26 01:14:24,135][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010792] [Batch 01054/04869] [00:11:55/00:43:09, 0.679s/it]: train_loss_raw=2.0573, running_loss=2.0222, LR=0.000100
[2025-08-26 01:14:29,352][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010800] [Batch 01062/04869] [00:12:00/00:43:03, 0.679s/it]: train_loss_raw=1.9430, running_loss=2.0192, LR=0.000100
[2025-08-26 01:14:34,891][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010808] [Batch 01070/04869] [00:12:06/00:42:58, 0.679s/it]: train_loss_raw=1.8962, running_loss=2.0179, LR=0.000100
[2025-08-26 01:14:40,130][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010816] [Batch 01078/04869] [00:12:11/00:42:52, 0.679s/it]: train_loss_raw=1.9425, running_loss=2.0131, LR=0.000100
[2025-08-26 01:14:45,514][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010824] [Batch 01086/04869] [00:12:16/00:42:46, 0.679s/it]: train_loss_raw=2.0449, running_loss=2.0163, LR=0.000100
[2025-08-26 01:14:50,969][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010832] [Batch 01094/04869] [00:12:22/00:42:41, 0.679s/it]: train_loss_raw=2.0518, running_loss=2.0153, LR=0.000100
[2025-08-26 01:14:56,148][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010840] [Batch 01102/04869] [00:12:27/00:42:35, 0.678s/it]: train_loss_raw=2.0464, running_loss=2.0138, LR=0.000100
[2025-08-26 01:15:01,775][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010848] [Batch 01110/04869] [00:12:33/00:42:30, 0.678s/it]: train_loss_raw=2.1475, running_loss=2.0144, LR=0.000100
[2025-08-26 01:15:06,974][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010856] [Batch 01118/04869] [00:12:38/00:42:24, 0.678s/it]: train_loss_raw=2.0565, running_loss=2.0149, LR=0.000100
[2025-08-26 01:15:12,434][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010864] [Batch 01126/04869] [00:12:43/00:42:18, 0.678s/it]: train_loss_raw=1.9970, running_loss=2.0158, LR=0.000100
[2025-08-26 01:15:18,079][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010872] [Batch 01134/04869] [00:12:49/00:42:14, 0.679s/it]: train_loss_raw=2.0309, running_loss=2.0190, LR=0.000100
[2025-08-26 01:15:23,687][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010880] [Batch 01142/04869] [00:12:55/00:42:09, 0.679s/it]: train_loss_raw=2.0422, running_loss=2.0183, LR=0.000100
[2025-08-26 01:15:29,135][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010888] [Batch 01150/04869] [00:13:00/00:42:04, 0.679s/it]: train_loss_raw=2.0014, running_loss=2.0192, LR=0.000100
[2025-08-26 01:15:35,216][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010896] [Batch 01158/04869] [00:13:06/00:42:00, 0.679s/it]: train_loss_raw=2.0746, running_loss=2.0174, LR=0.000100
[2025-08-26 01:15:40,568][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010904] [Batch 01166/04869] [00:13:11/00:41:54, 0.679s/it]: train_loss_raw=1.9348, running_loss=2.0157, LR=0.000100
[2025-08-26 01:15:46,016][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010912] [Batch 01174/04869] [00:13:17/00:41:49, 0.679s/it]: train_loss_raw=1.9147, running_loss=2.0133, LR=0.000100
[2025-08-26 01:15:51,662][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010920] [Batch 01182/04869] [00:13:23/00:41:44, 0.679s/it]: train_loss_raw=2.0058, running_loss=2.0120, LR=0.000100
[2025-08-26 01:15:57,445][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010928] [Batch 01190/04869] [00:13:28/00:41:40, 0.680s/it]: train_loss_raw=2.0849, running_loss=2.0121, LR=0.000100
[2025-08-26 01:16:02,720][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010936] [Batch 01198/04869] [00:13:34/00:41:34, 0.680s/it]: train_loss_raw=2.0039, running_loss=2.0121, LR=0.000100
[2025-08-26 01:16:08,727][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010944] [Batch 01206/04869] [00:13:40/00:41:30, 0.680s/it]: train_loss_raw=2.0568, running_loss=2.0125, LR=0.000100
[2025-08-26 01:16:15,118][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010952] [Batch 01214/04869] [00:13:46/00:41:28, 0.681s/it]: train_loss_raw=1.9956, running_loss=2.0147, LR=0.000100
[2025-08-26 01:16:21,505][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010960] [Batch 01222/04869] [00:13:52/00:41:25, 0.682s/it]: train_loss_raw=2.1387, running_loss=2.0152, LR=0.000100
[2025-08-26 01:16:27,115][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010968] [Batch 01230/04869] [00:13:58/00:41:20, 0.682s/it]: train_loss_raw=1.9531, running_loss=2.0144, LR=0.000100
[2025-08-26 01:16:33,038][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010976] [Batch 01238/04869] [00:14:04/00:41:16, 0.682s/it]: train_loss_raw=2.0015, running_loss=2.0135, LR=0.000100
[2025-08-26 01:16:38,339][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010984] [Batch 01246/04869] [00:14:09/00:41:10, 0.682s/it]: train_loss_raw=2.0756, running_loss=2.0119, LR=0.000100
[2025-08-26 01:16:44,146][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 010992] [Batch 01254/04869] [00:14:15/00:41:06, 0.682s/it]: train_loss_raw=2.0165, running_loss=2.0116, LR=0.000100
[2025-08-26 01:16:49,750][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011000] [Batch 01262/04869] [00:14:21/00:41:01, 0.682s/it]: train_loss_raw=1.9668, running_loss=2.0108, LR=0.000100
[2025-08-26 01:16:55,427][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011008] [Batch 01270/04869] [00:14:26/00:40:56, 0.682s/it]: train_loss_raw=2.0769, running_loss=2.0135, LR=0.000100
[2025-08-26 01:17:00,794][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011016] [Batch 01278/04869] [00:14:32/00:40:50, 0.682s/it]: train_loss_raw=2.0327, running_loss=2.0114, LR=0.000100
[2025-08-26 01:17:06,526][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011024] [Batch 01286/04869] [00:14:37/00:40:45, 0.683s/it]: train_loss_raw=1.9621, running_loss=2.0087, LR=0.000100
[2025-08-26 01:17:11,700][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011032] [Batch 01294/04869] [00:14:43/00:40:39, 0.682s/it]: train_loss_raw=2.0789, running_loss=2.0086, LR=0.000100
[2025-08-26 01:17:16,928][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011040] [Batch 01302/04869] [00:14:48/00:40:33, 0.682s/it]: train_loss_raw=2.0829, running_loss=2.0067, LR=0.000100
[2025-08-26 01:17:22,428][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011048] [Batch 01310/04869] [00:14:53/00:40:28, 0.682s/it]: train_loss_raw=1.9018, running_loss=2.0057, LR=0.000100
[2025-08-26 01:17:27,776][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011056] [Batch 01318/04869] [00:14:59/00:40:22, 0.682s/it]: train_loss_raw=2.1150, running_loss=2.0059, LR=0.000100
[2025-08-26 01:17:33,725][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011064] [Batch 01326/04869] [00:15:05/00:40:18, 0.683s/it]: train_loss_raw=2.0907, running_loss=2.0054, LR=0.000100
[2025-08-26 01:17:39,361][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011072] [Batch 01334/04869] [00:15:10/00:40:13, 0.683s/it]: train_loss_raw=2.0186, running_loss=2.0057, LR=0.000100
[2025-08-26 01:17:44,604][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011080] [Batch 01342/04869] [00:15:15/00:40:07, 0.683s/it]: train_loss_raw=2.0399, running_loss=2.0060, LR=0.000100
[2025-08-26 01:17:49,858][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011088] [Batch 01350/04869] [00:15:21/00:40:01, 0.682s/it]: train_loss_raw=1.9820, running_loss=2.0063, LR=0.000100
[2025-08-26 01:17:55,097][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011096] [Batch 01358/04869] [00:15:26/00:39:55, 0.682s/it]: train_loss_raw=1.9374, running_loss=2.0069, LR=0.000100
[2025-08-26 01:18:00,367][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011104] [Batch 01366/04869] [00:15:31/00:39:49, 0.682s/it]: train_loss_raw=2.0805, running_loss=2.0051, LR=0.000100
[2025-08-26 01:18:05,618][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011112] [Batch 01374/04869] [00:15:36/00:39:43, 0.682s/it]: train_loss_raw=2.0317, running_loss=2.0058, LR=0.000100
[2025-08-26 01:18:11,352][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011120] [Batch 01382/04869] [00:15:42/00:39:38, 0.682s/it]: train_loss_raw=1.9489, running_loss=2.0053, LR=0.000100
[2025-08-26 01:18:16,714][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011128] [Batch 01390/04869] [00:15:48/00:39:32, 0.682s/it]: train_loss_raw=1.9459, running_loss=2.0073, LR=0.000100
[2025-08-26 01:18:21,947][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011136] [Batch 01398/04869] [00:15:53/00:39:26, 0.682s/it]: train_loss_raw=2.0186, running_loss=2.0082, LR=0.000100
[2025-08-26 01:18:27,195][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011144] [Batch 01406/04869] [00:15:58/00:39:20, 0.682s/it]: train_loss_raw=2.0000, running_loss=2.0078, LR=0.000100
[2025-08-26 01:18:32,521][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011152] [Batch 01414/04869] [00:16:03/00:39:15, 0.682s/it]: train_loss_raw=1.8894, running_loss=2.0054, LR=0.000100
[2025-08-26 01:18:37,728][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011160] [Batch 01422/04869] [00:16:09/00:39:09, 0.681s/it]: train_loss_raw=2.0333, running_loss=2.0024, LR=0.000100
[2025-08-26 01:18:43,434][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011168] [Batch 01430/04869] [00:16:14/00:39:04, 0.682s/it]: train_loss_raw=2.0222, running_loss=2.0048, LR=0.000100
[2025-08-26 01:18:48,889][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011176] [Batch 01438/04869] [00:16:20/00:38:58, 0.682s/it]: train_loss_raw=1.9441, running_loss=2.0057, LR=0.000100
[2025-08-26 01:18:54,555][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011184] [Batch 01446/04869] [00:16:25/00:38:53, 0.682s/it]: train_loss_raw=1.9224, running_loss=2.0051, LR=0.000100
[2025-08-26 01:19:00,346][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011192] [Batch 01454/04869] [00:16:31/00:38:49, 0.682s/it]: train_loss_raw=1.9670, running_loss=2.0036, LR=0.000100
[2025-08-26 01:19:06,125][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011200] [Batch 01462/04869] [00:16:37/00:38:44, 0.682s/it]: train_loss_raw=2.0714, running_loss=2.0044, LR=0.000100
[2025-08-26 01:19:11,751][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011208] [Batch 01470/04869] [00:16:43/00:38:39, 0.682s/it]: train_loss_raw=2.0186, running_loss=2.0025, LR=0.000100
[2025-08-26 01:19:16,947][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011216] [Batch 01478/04869] [00:16:48/00:38:33, 0.682s/it]: train_loss_raw=1.9651, running_loss=2.0035, LR=0.000100
[2025-08-26 01:19:22,519][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011224] [Batch 01486/04869] [00:16:53/00:38:28, 0.682s/it]: train_loss_raw=2.0271, running_loss=2.0037, LR=0.000100
[2025-08-26 01:19:27,830][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011232] [Batch 01494/04869] [00:16:59/00:38:22, 0.682s/it]: train_loss_raw=2.0703, running_loss=2.0022, LR=0.000100
[2025-08-26 01:19:33,560][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011240] [Batch 01502/04869] [00:17:04/00:38:17, 0.682s/it]: train_loss_raw=2.0405, running_loss=2.0036, LR=0.000100
[2025-08-26 01:19:39,159][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011248] [Batch 01510/04869] [00:17:10/00:38:12, 0.682s/it]: train_loss_raw=2.0210, running_loss=2.0049, LR=0.000100
[2025-08-26 01:19:44,999][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011256] [Batch 01518/04869] [00:17:16/00:38:07, 0.683s/it]: train_loss_raw=1.9694, running_loss=2.0022, LR=0.000100
[2025-08-26 01:19:50,377][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011264] [Batch 01526/04869] [00:17:21/00:38:02, 0.683s/it]: train_loss_raw=1.9883, running_loss=2.0003, LR=0.000100
[2025-08-26 01:19:55,601][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011272] [Batch 01534/04869] [00:17:26/00:37:56, 0.682s/it]: train_loss_raw=2.0438, running_loss=2.0027, LR=0.000100
[2025-08-26 01:20:01,386][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011280] [Batch 01542/04869] [00:17:32/00:37:51, 0.683s/it]: train_loss_raw=2.0352, running_loss=2.0047, LR=0.000100
[2025-08-26 01:20:07,349][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011288] [Batch 01550/04869] [00:17:38/00:37:46, 0.683s/it]: train_loss_raw=1.9867, running_loss=2.0046, LR=0.000100
[2025-08-26 01:20:12,591][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011296] [Batch 01558/04869] [00:17:43/00:37:41, 0.683s/it]: train_loss_raw=2.0652, running_loss=2.0048, LR=0.000100
[2025-08-26 01:20:17,816][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011304] [Batch 01566/04869] [00:17:49/00:37:35, 0.683s/it]: train_loss_raw=2.0462, running_loss=2.0046, LR=0.000100
[2025-08-26 01:20:23,990][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011312] [Batch 01574/04869] [00:17:55/00:37:31, 0.683s/it]: train_loss_raw=1.9793, running_loss=2.0034, LR=0.000100
[2025-08-26 01:20:29,860][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011320] [Batch 01582/04869] [00:18:01/00:37:26, 0.683s/it]: train_loss_raw=1.9533, running_loss=2.0042, LR=0.000100
[2025-08-26 01:20:35,318][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011328] [Batch 01590/04869] [00:18:06/00:37:20, 0.683s/it]: train_loss_raw=2.0599, running_loss=2.0041, LR=0.000100
[2025-08-26 01:20:40,917][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011336] [Batch 01598/04869] [00:18:12/00:37:15, 0.684s/it]: train_loss_raw=2.0671, running_loss=2.0019, LR=0.000100
[2025-08-26 01:20:46,709][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011344] [Batch 01606/04869] [00:18:18/00:37:10, 0.684s/it]: train_loss_raw=2.0702, running_loss=2.0021, LR=0.000100
[2025-08-26 01:20:52,389][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011352] [Batch 01614/04869] [00:18:23/00:37:05, 0.684s/it]: train_loss_raw=2.0407, running_loss=2.0026, LR=0.000100
[2025-08-26 01:20:58,180][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011360] [Batch 01622/04869] [00:18:29/00:37:01, 0.684s/it]: train_loss_raw=2.1612, running_loss=2.0066, LR=0.000100
[2025-08-26 01:21:03,768][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011368] [Batch 01630/04869] [00:18:35/00:36:55, 0.684s/it]: train_loss_raw=1.9960, running_loss=2.0080, LR=0.000100
[2025-08-26 01:21:09,021][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011376] [Batch 01638/04869] [00:18:40/00:36:49, 0.684s/it]: train_loss_raw=1.9585, running_loss=2.0065, LR=0.000100
[2025-08-26 01:21:14,260][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011384] [Batch 01646/04869] [00:18:45/00:36:44, 0.684s/it]: train_loss_raw=2.0050, running_loss=2.0066, LR=0.000100
[2025-08-26 01:21:19,448][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011392] [Batch 01654/04869] [00:18:50/00:36:38, 0.684s/it]: train_loss_raw=2.0755, running_loss=2.0043, LR=0.000100
[2025-08-26 01:21:24,670][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011400] [Batch 01662/04869] [00:18:56/00:36:32, 0.684s/it]: train_loss_raw=2.0833, running_loss=2.0033, LR=0.000100
[2025-08-26 01:21:29,939][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011408] [Batch 01670/04869] [00:19:01/00:36:26, 0.683s/it]: train_loss_raw=1.9793, running_loss=2.0039, LR=0.000100
[2025-08-26 01:21:35,806][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011416] [Batch 01678/04869] [00:19:07/00:36:21, 0.684s/it]: train_loss_raw=2.0325, running_loss=2.0024, LR=0.000100
[2025-08-26 01:21:41,291][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011424] [Batch 01686/04869] [00:19:12/00:36:16, 0.684s/it]: train_loss_raw=2.0359, running_loss=2.0035, LR=0.000100
[2025-08-26 01:21:46,618][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011432] [Batch 01694/04869] [00:19:17/00:36:10, 0.684s/it]: train_loss_raw=1.9320, running_loss=2.0016, LR=0.000100
[2025-08-26 01:21:51,854][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011440] [Batch 01702/04869] [00:19:23/00:36:04, 0.683s/it]: train_loss_raw=2.0014, running_loss=2.0006, LR=0.000100
[2025-08-26 01:21:57,768][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011448] [Batch 01710/04869] [00:19:29/00:35:59, 0.684s/it]: train_loss_raw=1.9652, running_loss=2.0002, LR=0.000100
[2025-08-26 01:22:03,028][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011456] [Batch 01718/04869] [00:19:34/00:35:53, 0.684s/it]: train_loss_raw=1.9941, running_loss=2.0006, LR=0.000100
[2025-08-26 01:22:08,710][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011464] [Batch 01726/04869] [00:19:40/00:35:48, 0.684s/it]: train_loss_raw=2.1106, running_loss=2.0009, LR=0.000100
[2025-08-26 01:22:14,526][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011472] [Batch 01734/04869] [00:19:45/00:35:44, 0.684s/it]: train_loss_raw=1.9647, running_loss=1.9997, LR=0.000100
[2025-08-26 01:22:19,958][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011480] [Batch 01742/04869] [00:19:51/00:35:38, 0.684s/it]: train_loss_raw=2.0961, running_loss=1.9986, LR=0.000100
[2025-08-26 01:22:25,176][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011488] [Batch 01750/04869] [00:19:56/00:35:32, 0.684s/it]: train_loss_raw=1.9833, running_loss=1.9961, LR=0.000100
[2025-08-26 01:22:30,652][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011496] [Batch 01758/04869] [00:20:01/00:35:27, 0.684s/it]: train_loss_raw=1.9802, running_loss=1.9951, LR=0.000100
[2025-08-26 01:22:36,121][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011504] [Batch 01766/04869] [00:20:07/00:35:21, 0.684s/it]: train_loss_raw=1.9976, running_loss=1.9962, LR=0.000100
[2025-08-26 01:22:41,581][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011512] [Batch 01774/04869] [00:20:12/00:35:16, 0.684s/it]: train_loss_raw=2.0507, running_loss=1.9978, LR=0.000100
[2025-08-26 01:22:46,809][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011520] [Batch 01782/04869] [00:20:18/00:35:10, 0.684s/it]: train_loss_raw=1.8950, running_loss=1.9970, LR=0.000100
[2025-08-26 01:22:52,372][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011528] [Batch 01790/04869] [00:20:23/00:35:04, 0.684s/it]: train_loss_raw=1.9279, running_loss=1.9957, LR=0.000100
[2025-08-26 01:22:57,546][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011536] [Batch 01798/04869] [00:20:28/00:34:58, 0.683s/it]: train_loss_raw=1.9716, running_loss=1.9913, LR=0.000100
[2025-08-26 01:23:03,086][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011544] [Batch 01806/04869] [00:20:34/00:34:53, 0.684s/it]: train_loss_raw=2.0494, running_loss=1.9913, LR=0.000100
[2025-08-26 01:23:08,342][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011552] [Batch 01814/04869] [00:20:39/00:34:47, 0.683s/it]: train_loss_raw=1.9611, running_loss=1.9917, LR=0.000100
[2025-08-26 01:23:13,569][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011560] [Batch 01822/04869] [00:20:44/00:34:41, 0.683s/it]: train_loss_raw=2.0016, running_loss=1.9914, LR=0.000100
[2025-08-26 01:23:18,820][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011568] [Batch 01830/04869] [00:20:50/00:34:36, 0.683s/it]: train_loss_raw=2.0075, running_loss=1.9922, LR=0.000100
[2025-08-26 01:23:24,080][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011576] [Batch 01838/04869] [00:20:55/00:34:30, 0.683s/it]: train_loss_raw=1.9509, running_loss=1.9912, LR=0.000100
[2025-08-26 01:23:29,625][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011584] [Batch 01846/04869] [00:21:00/00:34:24, 0.683s/it]: train_loss_raw=2.0103, running_loss=1.9907, LR=0.000100
[2025-08-26 01:23:35,536][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011592] [Batch 01854/04869] [00:21:06/00:34:20, 0.683s/it]: train_loss_raw=2.0005, running_loss=1.9898, LR=0.000100
[2025-08-26 01:23:41,112][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011600] [Batch 01862/04869] [00:21:12/00:34:14, 0.683s/it]: train_loss_raw=2.0526, running_loss=1.9932, LR=0.000100
[2025-08-26 01:23:46,382][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011608] [Batch 01870/04869] [00:21:17/00:34:09, 0.683s/it]: train_loss_raw=1.9799, running_loss=1.9933, LR=0.000100
[2025-08-26 01:23:52,193][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011616] [Batch 01878/04869] [00:21:23/00:34:04, 0.683s/it]: train_loss_raw=2.0485, running_loss=1.9945, LR=0.000100
[2025-08-26 01:23:57,949][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011624] [Batch 01886/04869] [00:21:29/00:33:59, 0.684s/it]: train_loss_raw=1.9888, running_loss=1.9945, LR=0.000100
[2025-08-26 01:24:03,141][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011632] [Batch 01894/04869] [00:21:34/00:33:53, 0.683s/it]: train_loss_raw=1.9945, running_loss=1.9948, LR=0.000100
[2025-08-26 01:24:08,422][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011640] [Batch 01902/04869] [00:21:39/00:33:47, 0.683s/it]: train_loss_raw=1.9532, running_loss=1.9935, LR=0.000100
[2025-08-26 01:24:14,026][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011648] [Batch 01910/04869] [00:21:45/00:33:42, 0.683s/it]: train_loss_raw=2.0373, running_loss=1.9936, LR=0.000100
[2025-08-26 01:24:19,843][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011656] [Batch 01918/04869] [00:21:51/00:33:37, 0.684s/it]: train_loss_raw=1.9077, running_loss=1.9943, LR=0.000100
[2025-08-26 01:24:25,198][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011664] [Batch 01926/04869] [00:21:56/00:33:31, 0.684s/it]: train_loss_raw=1.9422, running_loss=1.9945, LR=0.000100
[2025-08-26 01:24:30,920][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011672] [Batch 01934/04869] [00:22:02/00:33:26, 0.684s/it]: train_loss_raw=2.0379, running_loss=1.9939, LR=0.000100
[2025-08-26 01:24:36,181][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011680] [Batch 01942/04869] [00:22:07/00:33:20, 0.684s/it]: train_loss_raw=1.9892, running_loss=1.9966, LR=0.000100
[2025-08-26 01:24:41,622][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011688] [Batch 01950/04869] [00:22:12/00:33:15, 0.684s/it]: train_loss_raw=1.9851, running_loss=1.9984, LR=0.000100
[2025-08-26 01:24:47,231][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011696] [Batch 01958/04869] [00:22:18/00:33:10, 0.684s/it]: train_loss_raw=1.8873, running_loss=1.9992, LR=0.000100
[2025-08-26 01:24:52,448][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011704] [Batch 01966/04869] [00:22:23/00:33:04, 0.684s/it]: train_loss_raw=2.0245, running_loss=1.9983, LR=0.000100
[2025-08-26 01:24:57,686][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011712] [Batch 01974/04869] [00:22:29/00:32:58, 0.683s/it]: train_loss_raw=1.9617, running_loss=1.9991, LR=0.000100
[2025-08-26 01:25:03,151][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011720] [Batch 01982/04869] [00:22:34/00:32:52, 0.683s/it]: train_loss_raw=2.0025, running_loss=1.9976, LR=0.000100
[2025-08-26 01:25:08,364][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011728] [Batch 01990/04869] [00:22:39/00:32:47, 0.683s/it]: train_loss_raw=1.9913, running_loss=1.9983, LR=0.000100
[2025-08-26 01:25:13,755][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011736] [Batch 01998/04869] [00:22:45/00:32:41, 0.683s/it]: train_loss_raw=2.0703, running_loss=1.9993, LR=0.000100
[2025-08-26 01:25:18,975][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011744] [Batch 02006/04869] [00:22:50/00:32:35, 0.683s/it]: train_loss_raw=1.9989, running_loss=1.9994, LR=0.000100
[2025-08-26 01:25:24,179][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011752] [Batch 02014/04869] [00:22:55/00:32:29, 0.683s/it]: train_loss_raw=2.0716, running_loss=1.9995, LR=0.000100
[2025-08-26 01:25:29,412][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011760] [Batch 02022/04869] [00:23:00/00:32:24, 0.683s/it]: train_loss_raw=1.9450, running_loss=1.9996, LR=0.000100
[2025-08-26 01:25:34,625][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011768] [Batch 02030/04869] [00:23:05/00:32:18, 0.683s/it]: train_loss_raw=2.0560, running_loss=2.0019, LR=0.000100
[2025-08-26 01:25:40,305][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011776] [Batch 02038/04869] [00:23:11/00:32:13, 0.683s/it]: train_loss_raw=2.0270, running_loss=2.0004, LR=0.000100
[2025-08-26 01:25:45,820][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011784] [Batch 02046/04869] [00:23:17/00:32:07, 0.683s/it]: train_loss_raw=1.9471, running_loss=1.9985, LR=0.000100
[2025-08-26 01:25:51,067][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011792] [Batch 02054/04869] [00:23:22/00:32:02, 0.683s/it]: train_loss_raw=2.0571, running_loss=1.9971, LR=0.000100
[2025-08-26 01:25:56,325][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011800] [Batch 02062/04869] [00:23:27/00:31:56, 0.683s/it]: train_loss_raw=1.9698, running_loss=1.9985, LR=0.000100
[2025-08-26 01:26:01,977][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011808] [Batch 02070/04869] [00:23:33/00:31:51, 0.683s/it]: train_loss_raw=2.0506, running_loss=1.9966, LR=0.000100
[2025-08-26 01:26:07,347][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011816] [Batch 02078/04869] [00:23:38/00:31:45, 0.683s/it]: train_loss_raw=1.9851, running_loss=1.9946, LR=0.000100
[2025-08-26 01:26:12,583][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011824] [Batch 02086/04869] [00:23:43/00:31:39, 0.683s/it]: train_loss_raw=2.0323, running_loss=1.9949, LR=0.000100
[2025-08-26 01:26:17,836][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011832] [Batch 02094/04869] [00:23:49/00:31:33, 0.683s/it]: train_loss_raw=1.9711, running_loss=1.9943, LR=0.000100
[2025-08-26 01:26:23,052][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011840] [Batch 02102/04869] [00:23:54/00:31:28, 0.682s/it]: train_loss_raw=1.9221, running_loss=1.9928, LR=0.000100
[2025-08-26 01:26:28,273][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011848] [Batch 02110/04869] [00:23:59/00:31:22, 0.682s/it]: train_loss_raw=2.0148, running_loss=1.9943, LR=0.000100
[2025-08-26 01:26:33,537][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011856] [Batch 02118/04869] [00:24:04/00:31:16, 0.682s/it]: train_loss_raw=2.0197, running_loss=1.9935, LR=0.000100
[2025-08-26 01:26:38,776][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011864] [Batch 02126/04869] [00:24:10/00:31:10, 0.682s/it]: train_loss_raw=1.9832, running_loss=1.9916, LR=0.000100
[2025-08-26 01:26:44,168][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011872] [Batch 02134/04869] [00:24:15/00:31:05, 0.682s/it]: train_loss_raw=1.8857, running_loss=1.9903, LR=0.000100
[2025-08-26 01:26:49,637][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011880] [Batch 02142/04869] [00:24:20/00:30:59, 0.682s/it]: train_loss_raw=2.0706, running_loss=1.9916, LR=0.000100
[2025-08-26 01:26:54,831][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011888] [Batch 02150/04869] [00:24:26/00:30:54, 0.682s/it]: train_loss_raw=2.0255, running_loss=1.9908, LR=0.000100
[2025-08-26 01:27:00,036][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011896] [Batch 02158/04869] [00:24:31/00:30:48, 0.682s/it]: train_loss_raw=1.9820, running_loss=1.9902, LR=0.000100
[2025-08-26 01:27:05,805][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011904] [Batch 02166/04869] [00:24:37/00:30:43, 0.682s/it]: train_loss_raw=1.9544, running_loss=1.9887, LR=0.000100
[2025-08-26 01:27:11,351][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011912] [Batch 02174/04869] [00:24:42/00:30:38, 0.682s/it]: train_loss_raw=1.9556, running_loss=1.9864, LR=0.000100
[2025-08-26 01:27:16,864][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011920] [Batch 02182/04869] [00:24:48/00:30:32, 0.682s/it]: train_loss_raw=2.0189, running_loss=1.9874, LR=0.000100
[2025-08-26 01:27:22,145][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011928] [Batch 02190/04869] [00:24:53/00:30:26, 0.682s/it]: train_loss_raw=1.9848, running_loss=1.9878, LR=0.000100
[2025-08-26 01:27:27,903][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011936] [Batch 02198/04869] [00:24:59/00:30:21, 0.682s/it]: train_loss_raw=1.9758, running_loss=1.9890, LR=0.000100
[2025-08-26 01:27:33,413][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011944] [Batch 02206/04869] [00:25:04/00:30:16, 0.682s/it]: train_loss_raw=1.8851, running_loss=1.9885, LR=0.000100
[2025-08-26 01:27:38,637][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011952] [Batch 02214/04869] [00:25:09/00:30:10, 0.682s/it]: train_loss_raw=1.9769, running_loss=1.9879, LR=0.000100
[2025-08-26 01:27:43,855][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011960] [Batch 02222/04869] [00:25:15/00:30:05, 0.682s/it]: train_loss_raw=1.9651, running_loss=1.9894, LR=0.000100
[2025-08-26 01:27:49,133][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011968] [Batch 02230/04869] [00:25:20/00:29:59, 0.682s/it]: train_loss_raw=1.9189, running_loss=1.9882, LR=0.000100
[2025-08-26 01:27:54,386][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011976] [Batch 02238/04869] [00:25:25/00:29:53, 0.682s/it]: train_loss_raw=2.0416, running_loss=1.9906, LR=0.000100
[2025-08-26 01:27:59,709][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011984] [Batch 02246/04869] [00:25:31/00:29:48, 0.682s/it]: train_loss_raw=1.9421, running_loss=1.9894, LR=0.000100
[2025-08-26 01:28:05,272][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 011992] [Batch 02254/04869] [00:25:36/00:29:42, 0.682s/it]: train_loss_raw=2.0051, running_loss=1.9889, LR=0.000100
[2025-08-26 01:28:10,502][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012000] [Batch 02262/04869] [00:25:41/00:29:37, 0.682s/it]: train_loss_raw=1.9651, running_loss=1.9905, LR=0.000100
[2025-08-26 01:28:19,470][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012008] [Batch 02270/04869] [00:25:50/00:29:35, 0.683s/it]: train_loss_raw=1.9504, running_loss=1.9892, LR=0.000100
[2025-08-26 01:28:25,003][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012016] [Batch 02278/04869] [00:25:56/00:29:30, 0.683s/it]: train_loss_raw=2.1418, running_loss=1.9907, LR=0.000100
[2025-08-26 01:28:30,493][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012024] [Batch 02286/04869] [00:26:01/00:29:24, 0.683s/it]: train_loss_raw=2.0528, running_loss=1.9911, LR=0.000100
[2025-08-26 01:28:35,756][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012032] [Batch 02294/04869] [00:26:07/00:29:19, 0.683s/it]: train_loss_raw=1.9236, running_loss=1.9908, LR=0.000100
[2025-08-26 01:28:40,961][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012040] [Batch 02302/04869] [00:26:12/00:29:13, 0.683s/it]: train_loss_raw=1.9542, running_loss=1.9905, LR=0.000100
[2025-08-26 01:28:46,189][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012048] [Batch 02310/04869] [00:26:17/00:29:07, 0.683s/it]: train_loss_raw=1.9556, running_loss=1.9896, LR=0.000100
[2025-08-26 01:28:51,394][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012056] [Batch 02318/04869] [00:26:22/00:29:01, 0.683s/it]: train_loss_raw=2.0119, running_loss=1.9870, LR=0.000100
[2025-08-26 01:28:56,586][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012064] [Batch 02326/04869] [00:26:27/00:28:56, 0.683s/it]: train_loss_raw=2.0448, running_loss=1.9879, LR=0.000100
[2025-08-26 01:29:01,831][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012072] [Batch 02334/04869] [00:26:33/00:28:50, 0.683s/it]: train_loss_raw=2.0376, running_loss=1.9876, LR=0.000100
[2025-08-26 01:29:07,421][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012080] [Batch 02342/04869] [00:26:38/00:28:45, 0.683s/it]: train_loss_raw=2.0338, running_loss=1.9873, LR=0.000100
[2025-08-26 01:29:12,589][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012088] [Batch 02350/04869] [00:26:43/00:28:39, 0.683s/it]: train_loss_raw=2.0363, running_loss=1.9839, LR=0.000100
[2025-08-26 01:29:17,803][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012096] [Batch 02358/04869] [00:26:49/00:28:33, 0.682s/it]: train_loss_raw=2.0008, running_loss=1.9842, LR=0.000100
[2025-08-26 01:29:22,983][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012104] [Batch 02366/04869] [00:26:54/00:28:27, 0.682s/it]: train_loss_raw=1.9498, running_loss=1.9858, LR=0.000100
[2025-08-26 01:29:28,182][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012112] [Batch 02374/04869] [00:26:59/00:28:22, 0.682s/it]: train_loss_raw=2.0068, running_loss=1.9835, LR=0.000100
[2025-08-26 01:29:33,995][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012120] [Batch 02382/04869] [00:27:05/00:28:16, 0.682s/it]: train_loss_raw=2.0064, running_loss=1.9857, LR=0.000100
[2025-08-26 01:29:39,654][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012128] [Batch 02390/04869] [00:27:11/00:28:11, 0.682s/it]: train_loss_raw=1.9840, running_loss=1.9868, LR=0.000100
[2025-08-26 01:29:44,883][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012136] [Batch 02398/04869] [00:27:16/00:28:06, 0.682s/it]: train_loss_raw=1.9535, running_loss=1.9842, LR=0.000100
[2025-08-26 01:29:50,091][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012144] [Batch 02406/04869] [00:27:21/00:28:00, 0.682s/it]: train_loss_raw=2.0502, running_loss=1.9839, LR=0.000100
[2025-08-26 01:29:55,374][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012152] [Batch 02414/04869] [00:27:26/00:27:54, 0.682s/it]: train_loss_raw=2.1181, running_loss=1.9859, LR=0.000100
[2025-08-26 01:30:00,554][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012160] [Batch 02422/04869] [00:27:31/00:27:48, 0.682s/it]: train_loss_raw=2.0156, running_loss=1.9876, LR=0.000100
[2025-08-26 01:30:05,933][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012168] [Batch 02430/04869] [00:27:37/00:27:43, 0.682s/it]: train_loss_raw=1.9358, running_loss=1.9854, LR=0.000100
[2025-08-26 01:30:11,156][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012176] [Batch 02438/04869] [00:27:42/00:27:37, 0.682s/it]: train_loss_raw=2.0383, running_loss=1.9851, LR=0.000100
[2025-08-26 01:30:16,410][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012184] [Batch 02446/04869] [00:27:47/00:27:32, 0.682s/it]: train_loss_raw=1.9916, running_loss=1.9836, LR=0.000100
[2025-08-26 01:30:21,601][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012192] [Batch 02454/04869] [00:27:52/00:27:26, 0.682s/it]: train_loss_raw=1.9723, running_loss=1.9830, LR=0.000100
[2025-08-26 01:30:26,767][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012200] [Batch 02462/04869] [00:27:58/00:27:20, 0.682s/it]: train_loss_raw=2.0690, running_loss=1.9821, LR=0.000100
[2025-08-26 01:30:31,952][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012208] [Batch 02470/04869] [00:28:03/00:27:14, 0.681s/it]: train_loss_raw=2.0184, running_loss=1.9824, LR=0.000100
[2025-08-26 01:30:37,167][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012216] [Batch 02478/04869] [00:28:08/00:27:09, 0.681s/it]: train_loss_raw=2.0348, running_loss=1.9830, LR=0.000100
[2025-08-26 01:30:42,465][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012224] [Batch 02486/04869] [00:28:13/00:27:03, 0.681s/it]: train_loss_raw=1.9886, running_loss=1.9810, LR=0.000100
[2025-08-26 01:30:48,084][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012232] [Batch 02494/04869] [00:28:19/00:26:58, 0.681s/it]: train_loss_raw=1.9161, running_loss=1.9797, LR=0.000100
[2025-08-26 01:30:54,274][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012240] [Batch 02502/04869] [00:28:25/00:26:53, 0.682s/it]: train_loss_raw=1.9607, running_loss=1.9805, LR=0.000100
[2025-08-26 01:31:00,613][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012248] [Batch 02510/04869] [00:28:31/00:26:48, 0.682s/it]: train_loss_raw=2.0882, running_loss=1.9817, LR=0.000100
[2025-08-26 01:31:06,237][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012256] [Batch 02518/04869] [00:28:37/00:26:43, 0.682s/it]: train_loss_raw=1.9243, running_loss=1.9824, LR=0.000100
[2025-08-26 01:31:11,807][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012264] [Batch 02526/04869] [00:28:43/00:26:38, 0.682s/it]: train_loss_raw=1.9644, running_loss=1.9815, LR=0.000100
[2025-08-26 01:31:17,737][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012272] [Batch 02534/04869] [00:28:49/00:26:33, 0.682s/it]: train_loss_raw=1.9899, running_loss=1.9850, LR=0.000100
[2025-08-26 01:31:23,799][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012280] [Batch 02542/04869] [00:28:55/00:26:28, 0.683s/it]: train_loss_raw=1.9186, running_loss=1.9851, LR=0.000100
[2025-08-26 01:31:29,413][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012288] [Batch 02550/04869] [00:29:00/00:26:23, 0.683s/it]: train_loss_raw=2.0670, running_loss=1.9841, LR=0.000100
[2025-08-26 01:31:35,231][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012296] [Batch 02558/04869] [00:29:06/00:26:17, 0.683s/it]: train_loss_raw=1.9446, running_loss=1.9837, LR=0.000100
[2025-08-26 01:31:40,588][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012304] [Batch 02566/04869] [00:29:11/00:26:12, 0.683s/it]: train_loss_raw=2.0098, running_loss=1.9827, LR=0.000100
[2025-08-26 01:31:46,412][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012312] [Batch 02574/04869] [00:29:17/00:26:07, 0.683s/it]: train_loss_raw=1.9643, running_loss=1.9803, LR=0.000100
[2025-08-26 01:31:51,731][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012320] [Batch 02582/04869] [00:29:23/00:26:01, 0.683s/it]: train_loss_raw=2.0241, running_loss=1.9821, LR=0.000100
[2025-08-26 01:31:57,392][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012328] [Batch 02590/04869] [00:29:28/00:25:56, 0.683s/it]: train_loss_raw=1.9877, running_loss=1.9822, LR=0.000100
[2025-08-26 01:32:02,713][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012336] [Batch 02598/04869] [00:29:34/00:25:50, 0.683s/it]: train_loss_raw=1.9644, running_loss=1.9823, LR=0.000100
[2025-08-26 01:32:08,487][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012344] [Batch 02606/04869] [00:29:39/00:25:45, 0.683s/it]: train_loss_raw=1.9887, running_loss=1.9799, LR=0.000100
[2025-08-26 01:32:13,978][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012352] [Batch 02614/04869] [00:29:45/00:25:40, 0.683s/it]: train_loss_raw=2.0430, running_loss=1.9813, LR=0.000100
[2025-08-26 01:32:19,347][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012360] [Batch 02622/04869] [00:29:50/00:25:34, 0.683s/it]: train_loss_raw=1.9031, running_loss=1.9796, LR=0.000100
[2025-08-26 01:32:24,541][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012368] [Batch 02630/04869] [00:29:55/00:25:28, 0.683s/it]: train_loss_raw=1.9825, running_loss=1.9808, LR=0.000100
[2025-08-26 01:32:30,096][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012376] [Batch 02638/04869] [00:30:01/00:25:23, 0.683s/it]: train_loss_raw=1.9511, running_loss=1.9806, LR=0.000100
[2025-08-26 01:32:35,752][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012384] [Batch 02646/04869] [00:30:07/00:25:18, 0.683s/it]: train_loss_raw=1.9309, running_loss=1.9782, LR=0.000100
[2025-08-26 01:32:41,764][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012392] [Batch 02654/04869] [00:30:13/00:25:13, 0.683s/it]: train_loss_raw=1.9977, running_loss=1.9794, LR=0.000100
[2025-08-26 01:32:47,909][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012400] [Batch 02662/04869] [00:30:19/00:25:08, 0.683s/it]: train_loss_raw=1.9704, running_loss=1.9783, LR=0.000100
[2025-08-26 01:32:53,654][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012408] [Batch 02670/04869] [00:30:25/00:25:03, 0.684s/it]: train_loss_raw=1.8841, running_loss=1.9766, LR=0.000100
[2025-08-26 01:32:58,877][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012416] [Batch 02678/04869] [00:30:30/00:24:57, 0.683s/it]: train_loss_raw=1.9596, running_loss=1.9755, LR=0.000100
[2025-08-26 01:33:04,137][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012424] [Batch 02686/04869] [00:30:35/00:24:51, 0.683s/it]: train_loss_raw=1.9959, running_loss=1.9766, LR=0.000100
[2025-08-26 01:33:09,853][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012432] [Batch 02694/04869] [00:30:41/00:24:46, 0.683s/it]: train_loss_raw=2.0992, running_loss=1.9771, LR=0.000100
[2025-08-26 01:33:15,356][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012440] [Batch 02702/04869] [00:30:46/00:24:41, 0.683s/it]: train_loss_raw=1.9340, running_loss=1.9782, LR=0.000100
[2025-08-26 01:33:20,549][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012448] [Batch 02710/04869] [00:30:51/00:24:35, 0.683s/it]: train_loss_raw=2.0312, running_loss=1.9777, LR=0.000100
[2025-08-26 01:33:26,017][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012456] [Batch 02718/04869] [00:30:57/00:24:29, 0.683s/it]: train_loss_raw=1.9985, running_loss=1.9801, LR=0.000100
[2025-08-26 01:33:31,256][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012464] [Batch 02726/04869] [00:31:02/00:24:24, 0.683s/it]: train_loss_raw=1.9557, running_loss=1.9778, LR=0.000100
[2025-08-26 01:33:36,459][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012472] [Batch 02734/04869] [00:31:07/00:24:18, 0.683s/it]: train_loss_raw=1.9889, running_loss=1.9794, LR=0.000100
[2025-08-26 01:33:41,690][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012480] [Batch 02742/04869] [00:31:13/00:24:12, 0.683s/it]: train_loss_raw=1.9434, running_loss=1.9795, LR=0.000100
[2025-08-26 01:33:47,089][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012488] [Batch 02750/04869] [00:31:18/00:24:07, 0.683s/it]: train_loss_raw=2.0479, running_loss=1.9782, LR=0.000100
[2025-08-26 01:33:52,887][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012496] [Batch 02758/04869] [00:31:24/00:24:02, 0.683s/it]: train_loss_raw=1.8668, running_loss=1.9766, LR=0.000100
[2025-08-26 01:33:58,902][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012504] [Batch 02766/04869] [00:31:30/00:23:57, 0.683s/it]: train_loss_raw=1.9516, running_loss=1.9753, LR=0.000100
[2025-08-26 01:34:04,888][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012512] [Batch 02774/04869] [00:31:36/00:23:52, 0.684s/it]: train_loss_raw=1.9037, running_loss=1.9728, LR=0.000100
[2025-08-26 01:34:10,774][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012520] [Batch 02782/04869] [00:31:42/00:23:46, 0.684s/it]: train_loss_raw=2.0718, running_loss=1.9750, LR=0.000100
[2025-08-26 01:34:16,351][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012528] [Batch 02790/04869] [00:31:47/00:23:41, 0.684s/it]: train_loss_raw=2.0137, running_loss=1.9745, LR=0.000100
[2025-08-26 01:34:21,806][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012536] [Batch 02798/04869] [00:31:53/00:23:36, 0.684s/it]: train_loss_raw=2.0768, running_loss=1.9752, LR=0.000100
[2025-08-26 01:34:27,023][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012544] [Batch 02806/04869] [00:31:58/00:23:30, 0.684s/it]: train_loss_raw=1.9420, running_loss=1.9744, LR=0.000100
[2025-08-26 01:34:32,819][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012552] [Batch 02814/04869] [00:32:04/00:23:25, 0.684s/it]: train_loss_raw=1.9933, running_loss=1.9753, LR=0.000100
[2025-08-26 01:34:38,389][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012560] [Batch 02822/04869] [00:32:09/00:23:19, 0.684s/it]: train_loss_raw=1.9771, running_loss=1.9752, LR=0.000100
[2025-08-26 01:34:43,609][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012568] [Batch 02830/04869] [00:32:14/00:23:14, 0.684s/it]: train_loss_raw=2.0661, running_loss=1.9743, LR=0.000100
[2025-08-26 01:34:48,834][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012576] [Batch 02838/04869] [00:32:20/00:23:08, 0.684s/it]: train_loss_raw=1.9522, running_loss=1.9710, LR=0.000100
[2025-08-26 01:34:54,599][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012584] [Batch 02846/04869] [00:32:25/00:23:03, 0.684s/it]: train_loss_raw=1.9744, running_loss=1.9685, LR=0.000100
[2025-08-26 01:34:59,830][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012592] [Batch 02854/04869] [00:32:31/00:22:57, 0.684s/it]: train_loss_raw=1.9730, running_loss=1.9686, LR=0.000100
[2025-08-26 01:35:05,073][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012600] [Batch 02862/04869] [00:32:36/00:22:51, 0.684s/it]: train_loss_raw=2.0403, running_loss=1.9697, LR=0.000100
[2025-08-26 01:35:10,570][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012608] [Batch 02870/04869] [00:32:41/00:22:46, 0.684s/it]: train_loss_raw=1.9223, running_loss=1.9704, LR=0.000100
[2025-08-26 01:35:16,128][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012616] [Batch 02878/04869] [00:32:47/00:22:41, 0.684s/it]: train_loss_raw=1.9212, running_loss=1.9717, LR=0.000100
[2025-08-26 01:35:21,772][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012624] [Batch 02886/04869] [00:32:53/00:22:35, 0.684s/it]: train_loss_raw=1.9735, running_loss=1.9725, LR=0.000100
[2025-08-26 01:35:27,052][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012632] [Batch 02894/04869] [00:32:58/00:22:30, 0.684s/it]: train_loss_raw=2.0545, running_loss=1.9729, LR=0.000100
[2025-08-26 01:35:32,777][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012640] [Batch 02902/04869] [00:33:04/00:22:24, 0.684s/it]: train_loss_raw=1.9511, running_loss=1.9745, LR=0.000100
[2025-08-26 01:35:38,105][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012648] [Batch 02910/04869] [00:33:09/00:22:19, 0.684s/it]: train_loss_raw=2.0346, running_loss=1.9760, LR=0.000100
[2025-08-26 01:35:43,341][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012656] [Batch 02918/04869] [00:33:14/00:22:13, 0.684s/it]: train_loss_raw=1.9084, running_loss=1.9739, LR=0.000100
[2025-08-26 01:35:48,560][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012664] [Batch 02926/04869] [00:33:19/00:22:08, 0.683s/it]: train_loss_raw=1.9953, running_loss=1.9753, LR=0.000100
[2025-08-26 01:35:53,723][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012672] [Batch 02934/04869] [00:33:25/00:22:02, 0.683s/it]: train_loss_raw=1.9392, running_loss=1.9752, LR=0.000100
[2025-08-26 01:35:58,903][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012680] [Batch 02942/04869] [00:33:30/00:21:56, 0.683s/it]: train_loss_raw=2.0081, running_loss=1.9734, LR=0.000100
[2025-08-26 01:36:04,471][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012688] [Batch 02950/04869] [00:33:35/00:21:51, 0.683s/it]: train_loss_raw=1.9445, running_loss=1.9731, LR=0.000100
[2025-08-26 01:36:09,869][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012696] [Batch 02958/04869] [00:33:41/00:21:45, 0.683s/it]: train_loss_raw=1.9421, running_loss=1.9725, LR=0.000100
[2025-08-26 01:36:15,373][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012704] [Batch 02966/04869] [00:33:46/00:21:40, 0.683s/it]: train_loss_raw=1.9962, running_loss=1.9711, LR=0.000100
[2025-08-26 01:36:21,389][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012712] [Batch 02974/04869] [00:33:52/00:21:35, 0.684s/it]: train_loss_raw=1.9839, running_loss=1.9728, LR=0.000100
[2025-08-26 01:36:27,089][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012720] [Batch 02982/04869] [00:33:58/00:21:29, 0.684s/it]: train_loss_raw=2.0008, running_loss=1.9722, LR=0.000100
[2025-08-26 01:36:32,572][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012728] [Batch 02990/04869] [00:34:03/00:21:24, 0.684s/it]: train_loss_raw=1.9205, running_loss=1.9734, LR=0.000100
[2025-08-26 01:36:38,442][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012736] [Batch 02998/04869] [00:34:09/00:21:19, 0.684s/it]: train_loss_raw=1.9628, running_loss=1.9742, LR=0.000100
[2025-08-26 01:36:44,225][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012744] [Batch 03006/04869] [00:34:15/00:21:13, 0.684s/it]: train_loss_raw=1.9579, running_loss=1.9741, LR=0.000100
[2025-08-26 01:36:49,505][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012752] [Batch 03014/04869] [00:34:20/00:21:08, 0.684s/it]: train_loss_raw=1.9379, running_loss=1.9732, LR=0.000100
[2025-08-26 01:36:54,696][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012760] [Batch 03022/04869] [00:34:26/00:21:02, 0.684s/it]: train_loss_raw=1.9067, running_loss=1.9730, LR=0.000100
[2025-08-26 01:36:59,897][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012768] [Batch 03030/04869] [00:34:31/00:20:57, 0.684s/it]: train_loss_raw=1.9436, running_loss=1.9713, LR=0.000100
[2025-08-26 01:37:05,095][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012776] [Batch 03038/04869] [00:34:36/00:20:51, 0.683s/it]: train_loss_raw=2.0193, running_loss=1.9723, LR=0.000100
[2025-08-26 01:37:10,308][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012784] [Batch 03046/04869] [00:34:41/00:20:45, 0.683s/it]: train_loss_raw=1.8991, running_loss=1.9692, LR=0.000100
[2025-08-26 01:37:16,069][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012792] [Batch 03054/04869] [00:34:47/00:20:40, 0.684s/it]: train_loss_raw=1.9421, running_loss=1.9683, LR=0.000100
[2025-08-26 01:37:21,264][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012800] [Batch 03062/04869] [00:34:52/00:20:34, 0.683s/it]: train_loss_raw=1.9031, running_loss=1.9681, LR=0.000100
[2025-08-26 01:37:26,897][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012808] [Batch 03070/04869] [00:34:58/00:20:29, 0.683s/it]: train_loss_raw=1.9937, running_loss=1.9661, LR=0.000100
[2025-08-26 01:37:32,159][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012816] [Batch 03078/04869] [00:35:03/00:20:23, 0.683s/it]: train_loss_raw=2.0337, running_loss=1.9676, LR=0.000100
[2025-08-26 01:37:37,409][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012824] [Batch 03086/04869] [00:35:08/00:20:18, 0.683s/it]: train_loss_raw=1.8060, running_loss=1.9670, LR=0.000100
[2025-08-26 01:37:42,992][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012832] [Batch 03094/04869] [00:35:14/00:20:12, 0.683s/it]: train_loss_raw=1.9667, running_loss=1.9669, LR=0.000100
[2025-08-26 01:37:48,352][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012840] [Batch 03102/04869] [00:35:19/00:20:07, 0.683s/it]: train_loss_raw=1.9229, running_loss=1.9663, LR=0.000100
[2025-08-26 01:37:53,924][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012848] [Batch 03110/04869] [00:35:25/00:20:02, 0.683s/it]: train_loss_raw=1.9440, running_loss=1.9658, LR=0.000100
[2025-08-26 01:37:59,522][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012856] [Batch 03118/04869] [00:35:30/00:19:56, 0.683s/it]: train_loss_raw=1.8574, running_loss=1.9658, LR=0.000100
[2025-08-26 01:38:05,507][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012864] [Batch 03126/04869] [00:35:36/00:19:51, 0.684s/it]: train_loss_raw=1.9552, running_loss=1.9627, LR=0.000100
[2025-08-26 01:38:10,963][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012872] [Batch 03134/04869] [00:35:42/00:19:45, 0.684s/it]: train_loss_raw=1.9804, running_loss=1.9627, LR=0.000100
[2025-08-26 01:38:16,220][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012880] [Batch 03142/04869] [00:35:47/00:19:40, 0.684s/it]: train_loss_raw=1.9918, running_loss=1.9624, LR=0.000100
[2025-08-26 01:38:22,195][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012888] [Batch 03150/04869] [00:35:53/00:19:35, 0.684s/it]: train_loss_raw=1.8775, running_loss=1.9624, LR=0.000100
[2025-08-26 01:38:27,422][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012896] [Batch 03158/04869] [00:35:58/00:19:29, 0.684s/it]: train_loss_raw=1.9280, running_loss=1.9622, LR=0.000100
[2025-08-26 01:38:32,677][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012904] [Batch 03166/04869] [00:36:04/00:19:24, 0.684s/it]: train_loss_raw=1.9686, running_loss=1.9634, LR=0.000100
[2025-08-26 01:38:38,077][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012912] [Batch 03174/04869] [00:36:09/00:19:18, 0.683s/it]: train_loss_raw=2.0227, running_loss=1.9644, LR=0.000100
[2025-08-26 01:38:43,726][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012920] [Batch 03182/04869] [00:36:15/00:19:13, 0.684s/it]: train_loss_raw=1.9460, running_loss=1.9650, LR=0.000100
[2025-08-26 01:38:49,164][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012928] [Batch 03190/04869] [00:36:20/00:19:07, 0.684s/it]: train_loss_raw=1.9358, running_loss=1.9641, LR=0.000100
[2025-08-26 01:38:54,333][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012936] [Batch 03198/04869] [00:36:25/00:19:02, 0.683s/it]: train_loss_raw=2.0014, running_loss=1.9634, LR=0.000100
[2025-08-26 01:38:59,671][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012944] [Batch 03206/04869] [00:36:31/00:18:56, 0.683s/it]: train_loss_raw=1.9194, running_loss=1.9629, LR=0.000100
[2025-08-26 01:39:04,874][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012952] [Batch 03214/04869] [00:36:36/00:18:50, 0.683s/it]: train_loss_raw=1.9733, running_loss=1.9615, LR=0.000100
[2025-08-26 01:39:10,138][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012960] [Batch 03222/04869] [00:36:41/00:18:45, 0.683s/it]: train_loss_raw=2.0418, running_loss=1.9629, LR=0.000100
[2025-08-26 01:39:15,760][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012968] [Batch 03230/04869] [00:36:47/00:18:39, 0.683s/it]: train_loss_raw=2.0167, running_loss=1.9640, LR=0.000100
[2025-08-26 01:39:20,989][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012976] [Batch 03238/04869] [00:36:52/00:18:34, 0.683s/it]: train_loss_raw=2.0196, running_loss=1.9651, LR=0.000100
[2025-08-26 01:39:26,628][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012984] [Batch 03246/04869] [00:36:57/00:18:28, 0.683s/it]: train_loss_raw=1.9853, running_loss=1.9658, LR=0.000100
[2025-08-26 01:39:32,127][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 012992] [Batch 03254/04869] [00:37:03/00:18:23, 0.683s/it]: train_loss_raw=2.0036, running_loss=1.9658, LR=0.000100
[2025-08-26 01:39:38,127][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013000] [Batch 03262/04869] [00:37:09/00:18:18, 0.683s/it]: train_loss_raw=1.9319, running_loss=1.9647, LR=0.000100
[2025-08-26 01:39:44,250][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013008] [Batch 03270/04869] [00:37:15/00:18:13, 0.684s/it]: train_loss_raw=1.9880, running_loss=1.9650, LR=0.000100
[2025-08-26 01:39:49,441][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013016] [Batch 03278/04869] [00:37:20/00:18:07, 0.684s/it]: train_loss_raw=1.9207, running_loss=1.9653, LR=0.000100
[2025-08-26 01:39:54,646][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013024] [Batch 03286/04869] [00:37:25/00:18:01, 0.684s/it]: train_loss_raw=2.0626, running_loss=1.9661, LR=0.000100
[2025-08-26 01:39:59,821][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013032] [Batch 03294/04869] [00:37:31/00:17:56, 0.683s/it]: train_loss_raw=1.9385, running_loss=1.9676, LR=0.000100
[2025-08-26 01:40:05,003][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013040] [Batch 03302/04869] [00:37:36/00:17:50, 0.683s/it]: train_loss_raw=1.9644, running_loss=1.9667, LR=0.000100
[2025-08-26 01:40:10,175][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013048] [Batch 03310/04869] [00:37:41/00:17:45, 0.683s/it]: train_loss_raw=1.8934, running_loss=1.9645, LR=0.000100
[2025-08-26 01:40:15,354][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013056] [Batch 03318/04869] [00:37:46/00:17:39, 0.683s/it]: train_loss_raw=1.9381, running_loss=1.9661, LR=0.000100
[2025-08-26 01:40:20,547][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013064] [Batch 03326/04869] [00:37:51/00:17:33, 0.683s/it]: train_loss_raw=2.0160, running_loss=1.9670, LR=0.000100
[2025-08-26 01:40:25,721][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013072] [Batch 03334/04869] [00:37:57/00:17:28, 0.683s/it]: train_loss_raw=1.9631, running_loss=1.9668, LR=0.000100
[2025-08-26 01:40:30,916][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013080] [Batch 03342/04869] [00:38:02/00:17:22, 0.683s/it]: train_loss_raw=1.9533, running_loss=1.9663, LR=0.000100
[2025-08-26 01:40:36,099][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013088] [Batch 03350/04869] [00:38:07/00:17:17, 0.683s/it]: train_loss_raw=2.0364, running_loss=1.9670, LR=0.000100
[2025-08-26 01:40:41,297][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013096] [Batch 03358/04869] [00:38:12/00:17:11, 0.683s/it]: train_loss_raw=2.0180, running_loss=1.9687, LR=0.000100
[2025-08-26 01:40:46,478][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013104] [Batch 03366/04869] [00:38:17/00:17:06, 0.683s/it]: train_loss_raw=1.9196, running_loss=1.9679, LR=0.000100
[2025-08-26 01:40:51,642][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013112] [Batch 03374/04869] [00:38:22/00:17:00, 0.683s/it]: train_loss_raw=1.9294, running_loss=1.9675, LR=0.000100
[2025-08-26 01:40:56,845][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013120] [Batch 03382/04869] [00:38:28/00:16:54, 0.682s/it]: train_loss_raw=1.9157, running_loss=1.9680, LR=0.000100
[2025-08-26 01:41:02,442][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013128] [Batch 03390/04869] [00:38:33/00:16:49, 0.683s/it]: train_loss_raw=2.0624, running_loss=1.9706, LR=0.000100
[2025-08-26 01:41:07,744][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013136] [Batch 03398/04869] [00:38:39/00:16:43, 0.682s/it]: train_loss_raw=1.9782, running_loss=1.9700, LR=0.000100
[2025-08-26 01:41:12,949][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013144] [Batch 03406/04869] [00:38:44/00:16:38, 0.682s/it]: train_loss_raw=1.9931, running_loss=1.9704, LR=0.000100
[2025-08-26 01:41:18,560][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013152] [Batch 03414/04869] [00:38:49/00:16:32, 0.682s/it]: train_loss_raw=1.9553, running_loss=1.9696, LR=0.000100
[2025-08-26 01:41:24,055][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013160] [Batch 03422/04869] [00:38:55/00:16:27, 0.682s/it]: train_loss_raw=1.9275, running_loss=1.9691, LR=0.000100
[2025-08-26 01:41:29,571][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013168] [Batch 03430/04869] [00:39:00/00:16:22, 0.682s/it]: train_loss_raw=2.0491, running_loss=1.9695, LR=0.000100
[2025-08-26 01:41:34,763][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013176] [Batch 03438/04869] [00:39:06/00:16:16, 0.682s/it]: train_loss_raw=1.9912, running_loss=1.9684, LR=0.000100
[2025-08-26 01:41:40,217][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013184] [Batch 03446/04869] [00:39:11/00:16:11, 0.682s/it]: train_loss_raw=1.8873, running_loss=1.9667, LR=0.000100
[2025-08-26 01:41:45,441][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013192] [Batch 03454/04869] [00:39:16/00:16:05, 0.682s/it]: train_loss_raw=1.9142, running_loss=1.9648, LR=0.000100
[2025-08-26 01:41:50,809][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013200] [Batch 03462/04869] [00:39:22/00:16:00, 0.682s/it]: train_loss_raw=1.9048, running_loss=1.9631, LR=0.000100
[2025-08-26 01:41:56,290][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013208] [Batch 03470/04869] [00:39:27/00:15:54, 0.682s/it]: train_loss_raw=1.8836, running_loss=1.9611, LR=0.000100
[2025-08-26 01:42:01,720][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013216] [Batch 03478/04869] [00:39:33/00:15:49, 0.682s/it]: train_loss_raw=2.0691, running_loss=1.9610, LR=0.000100
[2025-08-26 01:42:07,268][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013224] [Batch 03486/04869] [00:39:38/00:15:43, 0.682s/it]: train_loss_raw=2.0166, running_loss=1.9593, LR=0.000100
[2025-08-26 01:42:12,448][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013232] [Batch 03494/04869] [00:39:43/00:15:38, 0.682s/it]: train_loss_raw=1.9984, running_loss=1.9579, LR=0.000100
[2025-08-26 01:42:17,630][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013240] [Batch 03502/04869] [00:39:48/00:15:32, 0.682s/it]: train_loss_raw=1.8843, running_loss=1.9603, LR=0.000100
[2025-08-26 01:42:23,412][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013248] [Batch 03510/04869] [00:39:54/00:15:27, 0.682s/it]: train_loss_raw=1.9625, running_loss=1.9613, LR=0.000100
[2025-08-26 01:42:28,638][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013256] [Batch 03518/04869] [00:39:59/00:15:21, 0.682s/it]: train_loss_raw=1.9227, running_loss=1.9609, LR=0.000100
[2025-08-26 01:42:33,851][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013264] [Batch 03526/04869] [00:40:05/00:15:16, 0.682s/it]: train_loss_raw=2.0013, running_loss=1.9593, LR=0.000100
[2025-08-26 01:42:39,494][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013272] [Batch 03534/04869] [00:40:10/00:15:10, 0.682s/it]: train_loss_raw=1.9184, running_loss=1.9578, LR=0.000100
[2025-08-26 01:42:45,220][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013280] [Batch 03542/04869] [00:40:16/00:15:05, 0.682s/it]: train_loss_raw=2.0263, running_loss=1.9570, LR=0.000100
[2025-08-26 01:42:50,626][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013288] [Batch 03550/04869] [00:40:21/00:14:59, 0.682s/it]: train_loss_raw=1.9434, running_loss=1.9567, LR=0.000100
[2025-08-26 01:42:56,439][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013296] [Batch 03558/04869] [00:40:27/00:14:54, 0.682s/it]: train_loss_raw=1.9855, running_loss=1.9559, LR=0.000100
[2025-08-26 01:43:01,641][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013304] [Batch 03566/04869] [00:40:32/00:14:49, 0.682s/it]: train_loss_raw=1.8870, running_loss=1.9549, LR=0.000100
[2025-08-26 01:43:06,813][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013312] [Batch 03574/04869] [00:40:38/00:14:43, 0.682s/it]: train_loss_raw=1.9233, running_loss=1.9543, LR=0.000100
[2025-08-26 01:43:11,998][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013320] [Batch 03582/04869] [00:40:43/00:14:37, 0.682s/it]: train_loss_raw=1.9808, running_loss=1.9533, LR=0.000100
[2025-08-26 01:43:17,199][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013328] [Batch 03590/04869] [00:40:48/00:14:32, 0.682s/it]: train_loss_raw=1.9877, running_loss=1.9521, LR=0.000100
[2025-08-26 01:43:22,835][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013336] [Batch 03598/04869] [00:40:54/00:14:26, 0.682s/it]: train_loss_raw=2.0401, running_loss=1.9527, LR=0.000100
[2025-08-26 01:43:28,023][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013344] [Batch 03606/04869] [00:40:59/00:14:21, 0.682s/it]: train_loss_raw=2.0287, running_loss=1.9534, LR=0.000100
[2025-08-26 01:43:33,318][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013352] [Batch 03614/04869] [00:41:04/00:14:15, 0.682s/it]: train_loss_raw=2.0297, running_loss=1.9544, LR=0.000100
[2025-08-26 01:43:38,955][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013360] [Batch 03622/04869] [00:41:10/00:14:10, 0.682s/it]: train_loss_raw=1.9909, running_loss=1.9539, LR=0.000100
[2025-08-26 01:43:44,512][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013368] [Batch 03630/04869] [00:41:15/00:14:05, 0.682s/it]: train_loss_raw=2.0195, running_loss=1.9538, LR=0.000100
[2025-08-26 01:43:49,732][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013376] [Batch 03638/04869] [00:41:21/00:13:59, 0.682s/it]: train_loss_raw=1.8992, running_loss=1.9510, LR=0.000100
[2025-08-26 01:43:55,457][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013384] [Batch 03646/04869] [00:41:26/00:13:54, 0.682s/it]: train_loss_raw=1.9062, running_loss=1.9499, LR=0.000100
[2025-08-26 01:44:01,189][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013392] [Batch 03654/04869] [00:41:32/00:13:48, 0.682s/it]: train_loss_raw=2.0042, running_loss=1.9524, LR=0.000100
[2025-08-26 01:44:06,851][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013400] [Batch 03662/04869] [00:41:38/00:13:43, 0.682s/it]: train_loss_raw=1.9925, running_loss=1.9522, LR=0.000100
[2025-08-26 01:44:12,067][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013408] [Batch 03670/04869] [00:41:43/00:13:37, 0.682s/it]: train_loss_raw=1.8986, running_loss=1.9525, LR=0.000100
[2025-08-26 01:44:17,745][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013416] [Batch 03678/04869] [00:41:49/00:13:32, 0.682s/it]: train_loss_raw=1.9653, running_loss=1.9534, LR=0.000100
[2025-08-26 01:44:23,380][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013424] [Batch 03686/04869] [00:41:54/00:13:27, 0.682s/it]: train_loss_raw=1.9567, running_loss=1.9532, LR=0.000100
[2025-08-26 01:44:29,516][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013432] [Batch 03694/04869] [00:42:00/00:13:21, 0.682s/it]: train_loss_raw=1.9603, running_loss=1.9515, LR=0.000100
[2025-08-26 01:44:34,716][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013440] [Batch 03702/04869] [00:42:06/00:13:16, 0.682s/it]: train_loss_raw=2.0093, running_loss=1.9518, LR=0.000100
[2025-08-26 01:44:40,065][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013448] [Batch 03710/04869] [00:42:11/00:13:10, 0.682s/it]: train_loss_raw=1.9986, running_loss=1.9517, LR=0.000100
[2025-08-26 01:44:45,408][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013456] [Batch 03718/04869] [00:42:16/00:13:05, 0.682s/it]: train_loss_raw=1.9924, running_loss=1.9533, LR=0.000100
[2025-08-26 01:44:50,592][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013464] [Batch 03726/04869] [00:42:21/00:12:59, 0.682s/it]: train_loss_raw=1.9217, running_loss=1.9530, LR=0.000100
[2025-08-26 01:44:55,765][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013472] [Batch 03734/04869] [00:42:27/00:12:54, 0.682s/it]: train_loss_raw=2.0244, running_loss=1.9520, LR=0.000100
[2025-08-26 01:45:00,959][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013480] [Batch 03742/04869] [00:42:32/00:12:48, 0.682s/it]: train_loss_raw=1.9104, running_loss=1.9522, LR=0.000100
[2025-08-26 01:45:06,465][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013488] [Batch 03750/04869] [00:42:37/00:12:43, 0.682s/it]: train_loss_raw=1.9888, running_loss=1.9525, LR=0.000100
[2025-08-26 01:45:12,469][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013496] [Batch 03758/04869] [00:42:43/00:12:37, 0.682s/it]: train_loss_raw=2.0459, running_loss=1.9522, LR=0.000100
[2025-08-26 01:45:18,446][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013504] [Batch 03766/04869] [00:42:49/00:12:32, 0.682s/it]: train_loss_raw=1.9601, running_loss=1.9528, LR=0.000100
[2025-08-26 01:45:24,469][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013512] [Batch 03774/04869] [00:42:55/00:12:27, 0.683s/it]: train_loss_raw=1.9623, running_loss=1.9524, LR=0.000100
[2025-08-26 01:45:30,479][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013520] [Batch 03782/04869] [00:43:01/00:12:22, 0.683s/it]: train_loss_raw=1.9664, running_loss=1.9511, LR=0.000100
[2025-08-26 01:45:36,442][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013528] [Batch 03790/04869] [00:43:07/00:12:16, 0.683s/it]: train_loss_raw=1.9508, running_loss=1.9490, LR=0.000100
[2025-08-26 01:45:42,516][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013536] [Batch 03798/04869] [00:43:13/00:12:11, 0.683s/it]: train_loss_raw=2.0018, running_loss=1.9489, LR=0.000100
[2025-08-26 01:45:47,767][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013544] [Batch 03806/04869] [00:43:19/00:12:05, 0.683s/it]: train_loss_raw=1.9889, running_loss=1.9505, LR=0.000100
[2025-08-26 01:45:52,999][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013552] [Batch 03814/04869] [00:43:24/00:12:00, 0.683s/it]: train_loss_raw=1.9147, running_loss=1.9491, LR=0.000100
[2025-08-26 01:45:58,212][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013560] [Batch 03822/04869] [00:43:29/00:11:54, 0.683s/it]: train_loss_raw=1.9856, running_loss=1.9498, LR=0.000100
[2025-08-26 01:46:03,434][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013568] [Batch 03830/04869] [00:43:34/00:11:49, 0.683s/it]: train_loss_raw=1.9467, running_loss=1.9482, LR=0.000100
[2025-08-26 01:46:08,700][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013576] [Batch 03838/04869] [00:43:40/00:11:43, 0.683s/it]: train_loss_raw=1.9878, running_loss=1.9478, LR=0.000100
[2025-08-26 01:46:14,101][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013584] [Batch 03846/04869] [00:43:45/00:11:38, 0.683s/it]: train_loss_raw=1.9526, running_loss=1.9484, LR=0.000100
[2025-08-26 01:46:19,289][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013592] [Batch 03854/04869] [00:43:50/00:11:32, 0.683s/it]: train_loss_raw=2.0586, running_loss=1.9478, LR=0.000100
[2025-08-26 01:46:31,887][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013600] [Batch 03862/04869] [00:44:03/00:11:29, 0.684s/it]: train_loss_raw=1.9339, running_loss=1.9487, LR=0.000100
[2025-08-26 01:46:37,100][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013608] [Batch 03870/04869] [00:44:08/00:11:23, 0.684s/it]: train_loss_raw=1.9719, running_loss=1.9475, LR=0.000100
[2025-08-26 01:46:42,342][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013616] [Batch 03878/04869] [00:44:13/00:11:18, 0.684s/it]: train_loss_raw=1.9361, running_loss=1.9482, LR=0.000100
[2025-08-26 01:46:47,560][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013624] [Batch 03886/04869] [00:44:18/00:11:12, 0.684s/it]: train_loss_raw=1.9836, running_loss=1.9485, LR=0.000100
[2025-08-26 01:46:52,789][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013632] [Batch 03894/04869] [00:44:24/00:11:07, 0.684s/it]: train_loss_raw=2.0048, running_loss=1.9475, LR=0.000100
[2025-08-26 01:46:58,445][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013640] [Batch 03902/04869] [00:44:29/00:11:01, 0.684s/it]: train_loss_raw=1.9007, running_loss=1.9481, LR=0.000100
[2025-08-26 01:47:04,161][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013648] [Batch 03910/04869] [00:44:35/00:10:56, 0.684s/it]: train_loss_raw=2.0179, running_loss=1.9480, LR=0.000100
[2025-08-26 01:47:09,955][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013656] [Batch 03918/04869] [00:44:41/00:10:50, 0.684s/it]: train_loss_raw=1.8665, running_loss=1.9464, LR=0.000100
[2025-08-26 01:47:15,246][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013664] [Batch 03926/04869] [00:44:46/00:10:45, 0.684s/it]: train_loss_raw=1.8891, running_loss=1.9446, LR=0.000100
[2025-08-26 01:47:20,819][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013672] [Batch 03934/04869] [00:44:52/00:10:39, 0.684s/it]: train_loss_raw=1.9401, running_loss=1.9462, LR=0.000100
[2025-08-26 01:47:26,010][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013680] [Batch 03942/04869] [00:44:57/00:10:34, 0.684s/it]: train_loss_raw=1.9972, running_loss=1.9470, LR=0.000100
[2025-08-26 01:47:31,651][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013688] [Batch 03950/04869] [00:45:02/00:10:28, 0.684s/it]: train_loss_raw=1.8814, running_loss=1.9456, LR=0.000100
[2025-08-26 01:47:37,095][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013696] [Batch 03958/04869] [00:45:08/00:10:23, 0.684s/it]: train_loss_raw=1.9123, running_loss=1.9462, LR=0.000100
[2025-08-26 01:47:42,984][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013704] [Batch 03966/04869] [00:45:14/00:10:18, 0.684s/it]: train_loss_raw=1.9368, running_loss=1.9446, LR=0.000100
[2025-08-26 01:47:48,976][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013712] [Batch 03974/04869] [00:45:20/00:10:12, 0.685s/it]: train_loss_raw=1.9538, running_loss=1.9452, LR=0.000100
[2025-08-26 01:47:54,191][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013720] [Batch 03982/04869] [00:45:25/00:10:07, 0.684s/it]: train_loss_raw=1.9665, running_loss=1.9446, LR=0.000100
[2025-08-26 01:47:59,424][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013728] [Batch 03990/04869] [00:45:30/00:10:01, 0.684s/it]: train_loss_raw=1.9435, running_loss=1.9455, LR=0.000100
[2025-08-26 01:48:04,663][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013736] [Batch 03998/04869] [00:45:36/00:09:56, 0.684s/it]: train_loss_raw=2.0345, running_loss=1.9444, LR=0.000100
[2025-08-26 01:48:09,900][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013744] [Batch 04006/04869] [00:45:41/00:09:50, 0.684s/it]: train_loss_raw=1.9179, running_loss=1.9432, LR=0.000100
[2025-08-26 01:48:15,167][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013752] [Batch 04014/04869] [00:45:46/00:09:45, 0.684s/it]: train_loss_raw=1.9068, running_loss=1.9452, LR=0.000100
[2025-08-26 01:48:20,882][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013760] [Batch 04022/04869] [00:45:52/00:09:39, 0.684s/it]: train_loss_raw=2.0237, running_loss=1.9469, LR=0.000100
[2025-08-26 01:48:26,527][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013768] [Batch 04030/04869] [00:45:57/00:09:34, 0.684s/it]: train_loss_raw=1.8917, running_loss=1.9468, LR=0.000100
[2025-08-26 01:48:31,848][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013776] [Batch 04038/04869] [00:46:03/00:09:28, 0.684s/it]: train_loss_raw=2.0019, running_loss=1.9491, LR=0.000100
[2025-08-26 01:48:37,195][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013784] [Batch 04046/04869] [00:46:08/00:09:23, 0.684s/it]: train_loss_raw=1.9466, running_loss=1.9478, LR=0.000100
[2025-08-26 01:48:42,384][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013792] [Batch 04054/04869] [00:46:13/00:09:17, 0.684s/it]: train_loss_raw=2.0037, running_loss=1.9459, LR=0.000100
[2025-08-26 01:48:47,711][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013800] [Batch 04062/04869] [00:46:19/00:09:12, 0.684s/it]: train_loss_raw=1.9808, running_loss=1.9453, LR=0.000100
[2025-08-26 01:48:53,183][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013808] [Batch 04070/04869] [00:46:24/00:09:06, 0.684s/it]: train_loss_raw=1.9947, running_loss=1.9455, LR=0.000100
[2025-08-26 01:48:58,662][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013816] [Batch 04078/04869] [00:46:30/00:09:01, 0.684s/it]: train_loss_raw=1.9141, running_loss=1.9444, LR=0.000100
[2025-08-26 01:49:03,842][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013824] [Batch 04086/04869] [00:46:35/00:08:55, 0.684s/it]: train_loss_raw=1.8895, running_loss=1.9429, LR=0.000100
[2025-08-26 01:49:09,024][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013832] [Batch 04094/04869] [00:46:40/00:08:50, 0.684s/it]: train_loss_raw=1.9479, running_loss=1.9419, LR=0.000100
[2025-08-26 01:49:14,439][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013840] [Batch 04102/04869] [00:46:45/00:08:44, 0.684s/it]: train_loss_raw=1.8588, running_loss=1.9386, LR=0.000100
[2025-08-26 01:49:19,748][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013848] [Batch 04110/04869] [00:46:51/00:08:39, 0.684s/it]: train_loss_raw=1.9767, running_loss=1.9384, LR=0.000100
[2025-08-26 01:49:25,215][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013856] [Batch 04118/04869] [00:46:56/00:08:33, 0.684s/it]: train_loss_raw=1.8370, running_loss=1.9387, LR=0.000100
[2025-08-26 01:49:30,478][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013864] [Batch 04126/04869] [00:47:01/00:08:28, 0.684s/it]: train_loss_raw=2.0268, running_loss=1.9382, LR=0.000100
[2025-08-26 01:49:36,530][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013872] [Batch 04134/04869] [00:47:07/00:08:22, 0.684s/it]: train_loss_raw=1.8928, running_loss=1.9370, LR=0.000100
[2025-08-26 01:49:42,030][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013880] [Batch 04142/04869] [00:47:13/00:08:17, 0.684s/it]: train_loss_raw=1.8987, running_loss=1.9380, LR=0.000100
[2025-08-26 01:49:47,859][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013888] [Batch 04150/04869] [00:47:19/00:08:11, 0.684s/it]: train_loss_raw=1.9937, running_loss=1.9384, LR=0.000100
[2025-08-26 01:49:53,097][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013896] [Batch 04158/04869] [00:47:24/00:08:06, 0.684s/it]: train_loss_raw=2.0370, running_loss=1.9396, LR=0.000100
[2025-08-26 01:49:58,595][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013904] [Batch 04166/04869] [00:47:29/00:08:00, 0.684s/it]: train_loss_raw=1.8866, running_loss=1.9408, LR=0.000100
[2025-08-26 01:50:03,974][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013912] [Batch 04174/04869] [00:47:35/00:07:55, 0.684s/it]: train_loss_raw=1.8899, running_loss=1.9374, LR=0.000100
[2025-08-26 01:50:09,381][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013920] [Batch 04182/04869] [00:47:40/00:07:49, 0.684s/it]: train_loss_raw=1.9563, running_loss=1.9386, LR=0.000100
[2025-08-26 01:50:15,074][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013928] [Batch 04190/04869] [00:47:46/00:07:44, 0.684s/it]: train_loss_raw=1.8856, running_loss=1.9372, LR=0.000100
[2025-08-26 01:50:20,412][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013936] [Batch 04198/04869] [00:47:51/00:07:39, 0.684s/it]: train_loss_raw=2.0424, running_loss=1.9374, LR=0.000100
[2025-08-26 01:50:25,759][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013944] [Batch 04206/04869] [00:47:57/00:07:33, 0.684s/it]: train_loss_raw=1.9264, running_loss=1.9396, LR=0.000100
[2025-08-26 01:50:31,329][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013952] [Batch 04214/04869] [00:48:02/00:07:28, 0.684s/it]: train_loss_raw=2.0754, running_loss=1.9397, LR=0.000100
[2025-08-26 01:50:37,318][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013960] [Batch 04222/04869] [00:48:08/00:07:22, 0.684s/it]: train_loss_raw=1.8888, running_loss=1.9400, LR=0.000100
[2025-08-26 01:50:43,074][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013968] [Batch 04230/04869] [00:48:14/00:07:17, 0.684s/it]: train_loss_raw=1.8536, running_loss=1.9367, LR=0.000100
[2025-08-26 01:50:48,342][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013976] [Batch 04238/04869] [00:48:19/00:07:11, 0.684s/it]: train_loss_raw=1.9565, running_loss=1.9342, LR=0.000100
[2025-08-26 01:50:54,123][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013984] [Batch 04246/04869] [00:48:25/00:07:06, 0.684s/it]: train_loss_raw=1.9978, running_loss=1.9328, LR=0.000100
[2025-08-26 01:50:59,322][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 013992] [Batch 04254/04869] [00:48:30/00:07:00, 0.684s/it]: train_loss_raw=1.9926, running_loss=1.9349, LR=0.000100
[2025-08-26 01:51:04,919][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014000] [Batch 04262/04869] [00:48:36/00:06:55, 0.684s/it]: train_loss_raw=1.8177, running_loss=1.9321, LR=0.000100
[2025-08-26 01:51:13,692][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014008] [Batch 04270/04869] [00:48:45/00:06:50, 0.685s/it]: train_loss_raw=1.8644, running_loss=1.9284, LR=0.000100
[2025-08-26 01:51:18,903][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014016] [Batch 04278/04869] [00:48:50/00:06:44, 0.685s/it]: train_loss_raw=1.9340, running_loss=1.9284, LR=0.000100
[2025-08-26 01:51:24,086][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014024] [Batch 04286/04869] [00:48:55/00:06:39, 0.685s/it]: train_loss_raw=1.8736, running_loss=1.9257, LR=0.000100
[2025-08-26 01:51:29,287][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014032] [Batch 04294/04869] [00:49:00/00:06:33, 0.685s/it]: train_loss_raw=1.9085, running_loss=1.9282, LR=0.000100
[2025-08-26 01:51:34,794][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014040] [Batch 04302/04869] [00:49:06/00:06:28, 0.685s/it]: train_loss_raw=2.0995, running_loss=1.9301, LR=0.000100
[2025-08-26 01:51:40,483][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014048] [Batch 04310/04869] [00:49:11/00:06:22, 0.685s/it]: train_loss_raw=1.9679, running_loss=1.9303, LR=0.000100
[2025-08-26 01:51:45,774][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014056] [Batch 04318/04869] [00:49:17/00:06:17, 0.685s/it]: train_loss_raw=1.8817, running_loss=1.9309, LR=0.000100
[2025-08-26 01:51:51,520][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014064] [Batch 04326/04869] [00:49:22/00:06:11, 0.685s/it]: train_loss_raw=1.8798, running_loss=1.9298, LR=0.000100
[2025-08-26 01:51:56,720][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014072] [Batch 04334/04869] [00:49:28/00:06:06, 0.685s/it]: train_loss_raw=1.8824, running_loss=1.9280, LR=0.000100
[2025-08-26 01:52:02,222][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014080] [Batch 04342/04869] [00:49:33/00:06:00, 0.685s/it]: train_loss_raw=1.9962, running_loss=1.9278, LR=0.000100
[2025-08-26 01:52:07,580][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014088] [Batch 04350/04869] [00:49:38/00:05:55, 0.685s/it]: train_loss_raw=1.9341, running_loss=1.9298, LR=0.000100
[2025-08-26 01:52:12,835][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014096] [Batch 04358/04869] [00:49:44/00:05:49, 0.685s/it]: train_loss_raw=1.9449, running_loss=1.9319, LR=0.000100
[2025-08-26 01:52:18,097][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014104] [Batch 04366/04869] [00:49:49/00:05:44, 0.685s/it]: train_loss_raw=1.9237, running_loss=1.9333, LR=0.000100
[2025-08-26 01:52:23,349][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014112] [Batch 04374/04869] [00:49:54/00:05:38, 0.685s/it]: train_loss_raw=1.9321, running_loss=1.9347, LR=0.000100
[2025-08-26 01:52:28,597][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014120] [Batch 04382/04869] [00:49:59/00:05:33, 0.685s/it]: train_loss_raw=1.9740, running_loss=1.9362, LR=0.000100
[2025-08-26 01:52:33,871][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014128] [Batch 04390/04869] [00:50:05/00:05:27, 0.685s/it]: train_loss_raw=1.9569, running_loss=1.9372, LR=0.000100
[2025-08-26 01:52:39,286][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014136] [Batch 04398/04869] [00:50:10/00:05:22, 0.685s/it]: train_loss_raw=1.9629, running_loss=1.9365, LR=0.000100
[2025-08-26 01:52:44,889][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014144] [Batch 04406/04869] [00:50:16/00:05:16, 0.685s/it]: train_loss_raw=1.8650, running_loss=1.9336, LR=0.000100
[2025-08-26 01:52:50,423][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014152] [Batch 04414/04869] [00:50:21/00:05:11, 0.685s/it]: train_loss_raw=1.9173, running_loss=1.9337, LR=0.000100
[2025-08-26 01:52:55,616][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014160] [Batch 04422/04869] [00:50:26/00:05:05, 0.685s/it]: train_loss_raw=2.0011, running_loss=1.9329, LR=0.000100
[2025-08-26 01:53:01,148][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014168] [Batch 04430/04869] [00:50:32/00:05:00, 0.685s/it]: train_loss_raw=1.9690, running_loss=1.9341, LR=0.000100
[2025-08-26 01:53:06,905][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014176] [Batch 04438/04869] [00:50:38/00:04:55, 0.685s/it]: train_loss_raw=1.8843, running_loss=1.9341, LR=0.000100
[2025-08-26 01:53:12,526][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014184] [Batch 04446/04869] [00:50:43/00:04:49, 0.685s/it]: train_loss_raw=1.8635, running_loss=1.9345, LR=0.000100
[2025-08-26 01:53:17,988][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014192] [Batch 04454/04869] [00:50:49/00:04:44, 0.685s/it]: train_loss_raw=1.8698, running_loss=1.9347, LR=0.000100
[2025-08-26 01:53:23,320][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014200] [Batch 04462/04869] [00:50:54/00:04:38, 0.685s/it]: train_loss_raw=1.9876, running_loss=1.9341, LR=0.000100
[2025-08-26 01:53:28,511][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014208] [Batch 04470/04869] [00:50:59/00:04:33, 0.685s/it]: train_loss_raw=1.7692, running_loss=1.9328, LR=0.000100
[2025-08-26 01:53:33,761][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014216] [Batch 04478/04869] [00:51:05/00:04:27, 0.684s/it]: train_loss_raw=1.9768, running_loss=1.9309, LR=0.000100
[2025-08-26 01:53:39,161][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014224] [Batch 04486/04869] [00:51:10/00:04:22, 0.684s/it]: train_loss_raw=1.9895, running_loss=1.9321, LR=0.000100
[2025-08-26 01:53:44,776][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014232] [Batch 04494/04869] [00:51:16/00:04:16, 0.684s/it]: train_loss_raw=1.9753, running_loss=1.9325, LR=0.000100
[2025-08-26 01:53:50,188][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014240] [Batch 04502/04869] [00:51:21/00:04:11, 0.684s/it]: train_loss_raw=1.8553, running_loss=1.9320, LR=0.000100
[2025-08-26 01:53:55,412][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014248] [Batch 04510/04869] [00:51:26/00:04:05, 0.684s/it]: train_loss_raw=1.9558, running_loss=1.9342, LR=0.000100
[2025-08-26 01:54:00,615][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014256] [Batch 04518/04869] [00:51:31/00:04:00, 0.684s/it]: train_loss_raw=1.8813, running_loss=1.9337, LR=0.000100
[2025-08-26 01:54:05,832][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014264] [Batch 04526/04869] [00:51:37/00:03:54, 0.684s/it]: train_loss_raw=1.9791, running_loss=1.9335, LR=0.000100
[2025-08-26 01:54:11,260][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014272] [Batch 04534/04869] [00:51:42/00:03:49, 0.684s/it]: train_loss_raw=1.9670, running_loss=1.9336, LR=0.000100
[2025-08-26 01:54:17,179][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014280] [Batch 04542/04869] [00:51:48/00:03:43, 0.684s/it]: train_loss_raw=1.8562, running_loss=1.9337, LR=0.000100
[2025-08-26 01:54:22,565][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014288] [Batch 04550/04869] [00:51:53/00:03:38, 0.684s/it]: train_loss_raw=1.8726, running_loss=1.9331, LR=0.000100
[2025-08-26 01:54:28,046][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014296] [Batch 04558/04869] [00:51:59/00:03:32, 0.684s/it]: train_loss_raw=1.9064, running_loss=1.9318, LR=0.000100
[2025-08-26 01:54:33,698][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014304] [Batch 04566/04869] [00:52:05/00:03:27, 0.684s/it]: train_loss_raw=1.9408, running_loss=1.9321, LR=0.000100
[2025-08-26 01:54:38,916][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014312] [Batch 04574/04869] [00:52:10/00:03:21, 0.684s/it]: train_loss_raw=1.8262, running_loss=1.9311, LR=0.000100
[2025-08-26 01:54:44,155][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014320] [Batch 04582/04869] [00:52:15/00:03:16, 0.684s/it]: train_loss_raw=2.0015, running_loss=1.9314, LR=0.000100
[2025-08-26 01:54:49,723][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014328] [Batch 04590/04869] [00:52:21/00:03:10, 0.684s/it]: train_loss_raw=1.9188, running_loss=1.9319, LR=0.000100
[2025-08-26 01:54:54,945][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014336] [Batch 04598/04869] [00:52:26/00:03:05, 0.684s/it]: train_loss_raw=1.9617, running_loss=1.9318, LR=0.000100
[2025-08-26 01:55:00,127][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014344] [Batch 04606/04869] [00:52:31/00:02:59, 0.684s/it]: train_loss_raw=1.8403, running_loss=1.9310, LR=0.000100
[2025-08-26 01:55:06,027][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014352] [Batch 04614/04869] [00:52:37/00:02:54, 0.684s/it]: train_loss_raw=1.9386, running_loss=1.9313, LR=0.000100
[2025-08-26 01:55:11,198][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014360] [Batch 04622/04869] [00:52:42/00:02:49, 0.684s/it]: train_loss_raw=1.9117, running_loss=1.9329, LR=0.000100
[2025-08-26 01:55:17,024][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014368] [Batch 04630/04869] [00:52:48/00:02:43, 0.684s/it]: train_loss_raw=1.8701, running_loss=1.9307, LR=0.000100
[2025-08-26 01:55:22,379][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014376] [Batch 04638/04869] [00:52:53/00:02:38, 0.684s/it]: train_loss_raw=1.8780, running_loss=1.9309, LR=0.000100
[2025-08-26 01:55:27,679][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014384] [Batch 04646/04869] [00:52:59/00:02:32, 0.684s/it]: train_loss_raw=2.0252, running_loss=1.9318, LR=0.000100
[2025-08-26 01:55:32,895][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014392] [Batch 04654/04869] [00:53:04/00:02:27, 0.684s/it]: train_loss_raw=1.7658, running_loss=1.9303, LR=0.000100
[2025-08-26 01:55:38,119][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014400] [Batch 04662/04869] [00:53:09/00:02:21, 0.684s/it]: train_loss_raw=1.7675, running_loss=1.9291, LR=0.000100
[2025-08-26 01:55:43,339][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014408] [Batch 04670/04869] [00:53:14/00:02:16, 0.684s/it]: train_loss_raw=1.9374, running_loss=1.9284, LR=0.000100
[2025-08-26 01:55:48,555][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014416] [Batch 04678/04869] [00:53:19/00:02:10, 0.684s/it]: train_loss_raw=1.9963, running_loss=1.9285, LR=0.000100
[2025-08-26 01:55:53,747][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014424] [Batch 04686/04869] [00:53:25/00:02:05, 0.684s/it]: train_loss_raw=1.9028, running_loss=1.9290, LR=0.000100
[2025-08-26 01:55:59,136][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014432] [Batch 04694/04869] [00:53:30/00:01:59, 0.684s/it]: train_loss_raw=1.9560, running_loss=1.9321, LR=0.000100
[2025-08-26 01:56:04,387][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014440] [Batch 04702/04869] [00:53:35/00:01:54, 0.684s/it]: train_loss_raw=1.8705, running_loss=1.9328, LR=0.000100
[2025-08-26 01:56:09,993][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014448] [Batch 04710/04869] [00:53:41/00:01:48, 0.684s/it]: train_loss_raw=1.9114, running_loss=1.9323, LR=0.000100
[2025-08-26 01:56:15,414][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014456] [Batch 04718/04869] [00:53:46/00:01:43, 0.684s/it]: train_loss_raw=1.9939, running_loss=1.9325, LR=0.000100
[2025-08-26 01:56:20,636][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014464] [Batch 04726/04869] [00:53:51/00:01:37, 0.684s/it]: train_loss_raw=1.8960, running_loss=1.9317, LR=0.000100
[2025-08-26 01:56:26,534][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014472] [Batch 04734/04869] [00:53:57/00:01:32, 0.684s/it]: train_loss_raw=1.8731, running_loss=1.9294, LR=0.000100
[2025-08-26 01:56:32,259][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014480] [Batch 04742/04869] [00:54:03/00:01:26, 0.684s/it]: train_loss_raw=1.9412, running_loss=1.9287, LR=0.000100
[2025-08-26 01:56:37,970][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014488] [Batch 04750/04869] [00:54:09/00:01:21, 0.684s/it]: train_loss_raw=1.9991, running_loss=1.9278, LR=0.000100
[2025-08-26 01:56:43,180][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014496] [Batch 04758/04869] [00:54:14/00:01:15, 0.684s/it]: train_loss_raw=1.8935, running_loss=1.9257, LR=0.000100
[2025-08-26 01:56:48,504][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014504] [Batch 04766/04869] [00:54:19/00:01:10, 0.684s/it]: train_loss_raw=1.9003, running_loss=1.9271, LR=0.000100
[2025-08-26 01:56:53,810][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014512] [Batch 04774/04869] [00:54:25/00:01:04, 0.684s/it]: train_loss_raw=1.8679, running_loss=1.9266, LR=0.000100
[2025-08-26 01:56:59,537][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014520] [Batch 04782/04869] [00:54:30/00:00:59, 0.684s/it]: train_loss_raw=1.9483, running_loss=1.9268, LR=0.000100
[2025-08-26 01:57:05,158][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014528] [Batch 04790/04869] [00:54:36/00:00:54, 0.684s/it]: train_loss_raw=1.9012, running_loss=1.9256, LR=0.000100
[2025-08-26 01:57:11,264][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014536] [Batch 04798/04869] [00:54:42/00:00:48, 0.684s/it]: train_loss_raw=1.9765, running_loss=1.9238, LR=0.000100
[2025-08-26 01:57:17,232][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014544] [Batch 04806/04869] [00:54:48/00:00:43, 0.684s/it]: train_loss_raw=1.9800, running_loss=1.9235, LR=0.000100
[2025-08-26 01:57:22,672][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014552] [Batch 04814/04869] [00:54:54/00:00:37, 0.684s/it]: train_loss_raw=1.9143, running_loss=1.9239, LR=0.000100
[2025-08-26 01:57:27,966][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014560] [Batch 04822/04869] [00:54:59/00:00:32, 0.684s/it]: train_loss_raw=1.9112, running_loss=1.9261, LR=0.000100
[2025-08-26 01:57:33,783][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014568] [Batch 04830/04869] [00:55:05/00:00:26, 0.684s/it]: train_loss_raw=1.9398, running_loss=1.9266, LR=0.000100
[2025-08-26 01:57:39,800][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014576] [Batch 04838/04869] [00:55:11/00:00:21, 0.684s/it]: train_loss_raw=1.9288, running_loss=1.9274, LR=0.000100
[2025-08-26 01:57:44,991][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014584] [Batch 04846/04869] [00:55:16/00:00:15, 0.684s/it]: train_loss_raw=1.8935, running_loss=1.9269, LR=0.000100
[2025-08-26 01:57:50,202][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014592] [Batch 04854/04869] [00:55:21/00:00:10, 0.684s/it]: train_loss_raw=1.8623, running_loss=1.9244, LR=0.000100
[2025-08-26 01:57:55,460][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 014600] [Batch 04862/04869] [00:55:26/00:00:04, 0.684s/it]: train_loss_raw=1.9485, running_loss=1.9235, LR=0.000100
[2025-08-26 01:58:19,912][__main__][INFO] - [VALIDATION] [Epoch 02/29] Starting validation.
[2025-08-26 01:58:30,210][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00007/00124] [00:00:10/00:02:29, 1.287s/it]
[2025-08-26 01:58:42,357][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00015/00124] [00:00:22/00:02:31, 1.403s/it]
[2025-08-26 01:58:52,785][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00023/00124] [00:00:32/00:02:16, 1.370s/it]
[2025-08-26 01:59:13,876][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00031/00124] [00:00:53/00:02:35, 1.686s/it]
[2025-08-26 01:59:24,464][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00039/00124] [00:01:04/00:02:15, 1.614s/it]
[2025-08-26 01:59:35,526][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00047/00124] [00:01:15/00:01:59, 1.575s/it]
[2025-08-26 01:59:46,253][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00055/00124] [00:01:26/00:01:44, 1.542s/it]
[2025-08-26 01:59:57,794][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00063/00124] [00:01:37/00:01:31, 1.529s/it]
[2025-08-26 02:00:10,051][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00071/00124] [00:01:50/00:01:19, 1.530s/it]
[2025-08-26 02:00:21,858][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00079/00124] [00:02:01/00:01:07, 1.524s/it]
[2025-08-26 02:00:33,322][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00087/00124] [00:02:13/00:00:54, 1.516s/it]
[2025-08-26 02:00:43,752][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00095/00124] [00:02:23/00:00:41, 1.498s/it]
[2025-08-26 02:00:54,088][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00103/00124] [00:02:34/00:00:29, 1.482s/it]
[2025-08-26 02:01:04,464][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00111/00124] [00:02:44/00:00:17, 1.469s/it]
[2025-08-26 02:01:14,886][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 014608] [Batch 00119/00124] [00:02:54/00:00:05, 1.458s/it]
[2025-08-26 02:01:19,462][__main__][INFO] - [VALIDATION] [Epoch 02/29] train_loss=1.92049, valid_loss=1.93457
[2025-08-26 02:01:19,462][__main__][INFO] - [VALIDATION] [Epoch 02/29] Metrics:
[2025-08-26 02:01:19,462][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_er      0.792
[2025-08-26 02:01:19,462][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_prec    0.029
[2025-08-26 02:01:19,462][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_recall  0.031
[2025-08-26 02:01:19,462][__main__][INFO] - [VALIDATION] [Epoch 02/29] - pep_recall 0.002
[2025-08-26 02:01:19,466][__main__][INFO] - [TRAIN] [Epoch 02/29] Epoch complete, total time 02:56:59, remaining time 26:32:55, 00:58:59 per epoch
[2025-08-26 02:01:19,751][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014608] [Batch 00001/04869] [00:00:00/00:11:53, 0.147s/it]: train_loss_raw=1.8962, running_loss=1.8962, LR=0.000100
[2025-08-26 02:01:25,201][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014616] [Batch 00009/04869] [00:00:05/00:50:22, 0.622s/it]: train_loss_raw=1.9176, running_loss=1.8981, LR=0.000100
[2025-08-26 02:01:30,665][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014624] [Batch 00017/04869] [00:00:11/00:52:36, 0.651s/it]: train_loss_raw=1.8906, running_loss=1.8966, LR=0.000100
[2025-08-26 02:01:35,884][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014632] [Batch 00025/04869] [00:00:16/00:52:34, 0.651s/it]: train_loss_raw=1.8713, running_loss=1.8983, LR=0.000100
[2025-08-26 02:01:41,108][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014640] [Batch 00033/04869] [00:00:21/00:52:31, 0.652s/it]: train_loss_raw=1.9550, running_loss=1.9007, LR=0.000100
[2025-08-26 02:01:46,318][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014648] [Batch 00041/04869] [00:00:26/00:52:25, 0.652s/it]: train_loss_raw=1.9871, running_loss=1.9011, LR=0.000100
[2025-08-26 02:01:51,538][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014656] [Batch 00049/04869] [00:00:31/00:52:21, 0.652s/it]: train_loss_raw=2.0164, running_loss=1.9023, LR=0.000100
[2025-08-26 02:01:57,326][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014664] [Batch 00057/04869] [00:00:37/00:53:04, 0.662s/it]: train_loss_raw=1.8155, running_loss=1.9030, LR=0.000100
[2025-08-26 02:02:02,853][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014672] [Batch 00065/04869] [00:00:43/00:53:16, 0.665s/it]: train_loss_raw=1.9545, running_loss=1.9029, LR=0.000100
[2025-08-26 02:02:08,079][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014680] [Batch 00073/04869] [00:00:48/00:53:04, 0.664s/it]: train_loss_raw=1.8392, running_loss=1.9027, LR=0.000100
[2025-08-26 02:02:13,452][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014688] [Batch 00081/04869] [00:00:53/00:53:02, 0.665s/it]: train_loss_raw=1.9639, running_loss=1.9059, LR=0.000100
[2025-08-26 02:02:18,967][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014696] [Batch 00089/04869] [00:00:59/00:53:08, 0.667s/it]: train_loss_raw=1.8713, running_loss=1.9055, LR=0.000100
[2025-08-26 02:02:24,189][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014704] [Batch 00097/04869] [00:01:04/00:52:57, 0.666s/it]: train_loss_raw=1.9847, running_loss=1.9048, LR=0.000100
[2025-08-26 02:02:29,373][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014712] [Batch 00105/04869] [00:01:09/00:52:45, 0.664s/it]: train_loss_raw=1.9970, running_loss=1.9061, LR=0.000100
[2025-08-26 02:02:34,553][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014720] [Batch 00113/04869] [00:01:14/00:52:34, 0.663s/it]: train_loss_raw=1.9338, running_loss=1.9063, LR=0.000100
[2025-08-26 02:02:39,722][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014728] [Batch 00121/04869] [00:01:20/00:52:23, 0.662s/it]: train_loss_raw=1.8504, running_loss=1.9039, LR=0.000100
[2025-08-26 02:02:44,908][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014736] [Batch 00129/04869] [00:01:25/00:52:14, 0.661s/it]: train_loss_raw=1.9766, running_loss=1.9040, LR=0.000100
[2025-08-26 02:02:50,420][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014744] [Batch 00137/04869] [00:01:30/00:52:16, 0.663s/it]: train_loss_raw=1.8797, running_loss=1.9024, LR=0.000100
[2025-08-26 02:02:55,635][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014752] [Batch 00145/04869] [00:01:36/00:52:08, 0.662s/it]: train_loss_raw=1.9786, running_loss=1.9034, LR=0.000100
[2025-08-26 02:03:00,852][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014760] [Batch 00153/04869] [00:01:41/00:52:00, 0.662s/it]: train_loss_raw=1.8918, running_loss=1.9039, LR=0.000100
[2025-08-26 02:03:06,060][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014768] [Batch 00161/04869] [00:01:46/00:51:53, 0.661s/it]: train_loss_raw=1.8899, running_loss=1.9034, LR=0.000100
[2025-08-26 02:03:11,437][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014776] [Batch 00169/04869] [00:01:51/00:51:50, 0.662s/it]: train_loss_raw=1.9238, running_loss=1.9020, LR=0.000100
[2025-08-26 02:03:16,891][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014784] [Batch 00177/04869] [00:01:57/00:51:49, 0.663s/it]: train_loss_raw=1.8550, running_loss=1.9018, LR=0.000100
[2025-08-26 02:03:22,107][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014792] [Batch 00185/04869] [00:02:02/00:51:41, 0.662s/it]: train_loss_raw=1.8689, running_loss=1.8999, LR=0.000100
[2025-08-26 02:03:28,179][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014800] [Batch 00193/04869] [00:02:08/00:51:55, 0.666s/it]: train_loss_raw=1.9434, running_loss=1.8993, LR=0.000100
[2025-08-26 02:03:33,770][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014808] [Batch 00201/04869] [00:02:14/00:51:55, 0.667s/it]: train_loss_raw=1.9392, running_loss=1.8993, LR=0.000100
[2025-08-26 02:03:39,358][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014816] [Batch 00209/04869] [00:02:19/00:51:56, 0.669s/it]: train_loss_raw=1.8462, running_loss=1.8989, LR=0.000100
[2025-08-26 02:03:44,587][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014824] [Batch 00217/04869] [00:02:24/00:51:48, 0.668s/it]: train_loss_raw=1.9034, running_loss=1.9008, LR=0.000100
[2025-08-26 02:03:49,910][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014832] [Batch 00225/04869] [00:02:30/00:51:42, 0.668s/it]: train_loss_raw=1.9585, running_loss=1.9021, LR=0.000100
[2025-08-26 02:03:55,229][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014840] [Batch 00233/04869] [00:02:35/00:51:36, 0.668s/it]: train_loss_raw=1.8911, running_loss=1.9045, LR=0.000100
[2025-08-26 02:04:00,683][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014848] [Batch 00241/04869] [00:02:41/00:51:33, 0.668s/it]: train_loss_raw=1.7831, running_loss=1.9001, LR=0.000100
[2025-08-26 02:04:06,576][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014856] [Batch 00249/04869] [00:02:46/00:51:38, 0.671s/it]: train_loss_raw=1.9466, running_loss=1.9014, LR=0.000100
[2025-08-26 02:04:11,763][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014864] [Batch 00257/04869] [00:02:52/00:51:29, 0.670s/it]: train_loss_raw=1.8907, running_loss=1.9023, LR=0.000100
[2025-08-26 02:04:17,187][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014872] [Batch 00265/04869] [00:02:57/00:51:25, 0.670s/it]: train_loss_raw=1.8974, running_loss=1.9031, LR=0.000100
[2025-08-26 02:04:22,654][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014880] [Batch 00273/04869] [00:03:03/00:51:21, 0.671s/it]: train_loss_raw=1.9104, running_loss=1.9029, LR=0.000100
[2025-08-26 02:04:27,875][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014888] [Batch 00281/04869] [00:03:08/00:51:13, 0.670s/it]: train_loss_raw=1.9553, running_loss=1.9051, LR=0.000100
[2025-08-26 02:04:33,116][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014896] [Batch 00289/04869] [00:03:13/00:51:06, 0.670s/it]: train_loss_raw=1.9465, running_loss=1.9055, LR=0.000100
[2025-08-26 02:04:38,453][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014904] [Batch 00297/04869] [00:03:18/00:51:01, 0.670s/it]: train_loss_raw=1.8566, running_loss=1.9039, LR=0.000100
[2025-08-26 02:04:44,014][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014912] [Batch 00305/04869] [00:03:24/00:50:58, 0.670s/it]: train_loss_raw=1.9254, running_loss=1.9047, LR=0.000100
[2025-08-26 02:04:49,229][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014920] [Batch 00313/04869] [00:03:29/00:50:51, 0.670s/it]: train_loss_raw=1.9097, running_loss=1.9038, LR=0.000100
[2025-08-26 02:04:54,443][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014928] [Batch 00321/04869] [00:03:34/00:50:43, 0.669s/it]: train_loss_raw=1.8880, running_loss=1.9001, LR=0.000100
[2025-08-26 02:04:59,693][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014936] [Batch 00329/04869] [00:03:40/00:50:37, 0.669s/it]: train_loss_raw=1.9822, running_loss=1.9011, LR=0.000100
[2025-08-26 02:05:05,035][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014944] [Batch 00337/04869] [00:03:45/00:50:31, 0.669s/it]: train_loss_raw=1.8138, running_loss=1.9001, LR=0.000100
[2025-08-26 02:05:10,616][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014952] [Batch 00345/04869] [00:03:51/00:50:29, 0.670s/it]: train_loss_raw=1.8995, running_loss=1.8993, LR=0.000100
[2025-08-26 02:05:15,904][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014960] [Batch 00353/04869] [00:03:56/00:50:23, 0.669s/it]: train_loss_raw=1.9293, running_loss=1.8990, LR=0.000100
[2025-08-26 02:05:21,565][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014968] [Batch 00361/04869] [00:04:01/00:50:21, 0.670s/it]: train_loss_raw=1.9946, running_loss=1.9014, LR=0.000100
[2025-08-26 02:05:27,064][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014976] [Batch 00369/04869] [00:04:07/00:50:17, 0.671s/it]: train_loss_raw=1.9004, running_loss=1.9014, LR=0.000100
[2025-08-26 02:05:32,310][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014984] [Batch 00377/04869] [00:04:12/00:50:11, 0.670s/it]: train_loss_raw=1.8981, running_loss=1.9019, LR=0.000100
[2025-08-26 02:05:38,025][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 014992] [Batch 00385/04869] [00:04:18/00:50:09, 0.671s/it]: train_loss_raw=1.9272, running_loss=1.9009, LR=0.000100
[2025-08-26 02:05:43,531][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015000] [Batch 00393/04869] [00:04:23/00:50:05, 0.672s/it]: train_loss_raw=1.8855, running_loss=1.8994, LR=0.000100
[2025-08-26 02:05:48,919][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015008] [Batch 00401/04869] [00:04:29/00:50:00, 0.672s/it]: train_loss_raw=1.9231, running_loss=1.8981, LR=0.000100
[2025-08-26 02:05:54,144][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015016] [Batch 00409/04869] [00:04:34/00:49:53, 0.671s/it]: train_loss_raw=1.9387, running_loss=1.8995, LR=0.000100
[2025-08-26 02:05:59,401][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015024] [Batch 00417/04869] [00:04:39/00:49:47, 0.671s/it]: train_loss_raw=1.8447, running_loss=1.8995, LR=0.000100
[2025-08-26 02:06:04,870][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015032] [Batch 00425/04869] [00:04:45/00:49:42, 0.671s/it]: train_loss_raw=1.9159, running_loss=1.9003, LR=0.000100
[2025-08-26 02:06:10,946][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015040] [Batch 00433/04869] [00:04:51/00:49:44, 0.673s/it]: train_loss_raw=1.9717, running_loss=1.8991, LR=0.000100
[2025-08-26 02:06:16,888][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015048] [Batch 00441/04869] [00:04:57/00:49:44, 0.674s/it]: train_loss_raw=1.9035, running_loss=1.8984, LR=0.000100
[2025-08-26 02:06:22,846][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015056] [Batch 00449/04869] [00:05:03/00:49:45, 0.675s/it]: train_loss_raw=1.9424, running_loss=1.8973, LR=0.000100
[2025-08-26 02:06:28,548][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015064] [Batch 00457/04869] [00:05:08/00:49:42, 0.676s/it]: train_loss_raw=1.8791, running_loss=1.8971, LR=0.000100
[2025-08-26 02:06:33,939][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015072] [Batch 00465/04869] [00:05:14/00:49:37, 0.676s/it]: train_loss_raw=1.8541, running_loss=1.8970, LR=0.000100
[2025-08-26 02:06:39,839][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015080] [Batch 00473/04869] [00:05:20/00:49:36, 0.677s/it]: train_loss_raw=1.8231, running_loss=1.8981, LR=0.000100
[2025-08-26 02:06:45,320][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015088] [Batch 00481/04869] [00:05:25/00:49:31, 0.677s/it]: train_loss_raw=1.9774, running_loss=1.8986, LR=0.000100
[2025-08-26 02:06:50,531][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015096] [Batch 00489/04869] [00:05:30/00:49:24, 0.677s/it]: train_loss_raw=1.8692, running_loss=1.8983, LR=0.000100
[2025-08-26 02:06:55,728][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015104] [Batch 00497/04869] [00:05:36/00:49:16, 0.676s/it]: train_loss_raw=1.7655, running_loss=1.8947, LR=0.000100
[2025-08-26 02:07:01,151][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015112] [Batch 00505/04869] [00:05:41/00:49:11, 0.676s/it]: train_loss_raw=2.0062, running_loss=1.8950, LR=0.000100
[2025-08-26 02:07:06,464][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015120] [Batch 00513/04869] [00:05:46/00:49:05, 0.676s/it]: train_loss_raw=1.8439, running_loss=1.8980, LR=0.000100
[2025-08-26 02:07:11,668][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015128] [Batch 00521/04869] [00:05:52/00:48:58, 0.676s/it]: train_loss_raw=1.7890, running_loss=1.8980, LR=0.000100
[2025-08-26 02:07:16,869][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015136] [Batch 00529/04869] [00:05:57/00:48:51, 0.675s/it]: train_loss_raw=1.8912, running_loss=1.8974, LR=0.000100
[2025-08-26 02:07:22,082][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015144] [Batch 00537/04869] [00:06:02/00:48:44, 0.675s/it]: train_loss_raw=1.9644, running_loss=1.8963, LR=0.000100
[2025-08-26 02:07:27,698][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015152] [Batch 00545/04869] [00:06:08/00:48:40, 0.675s/it]: train_loss_raw=1.9111, running_loss=1.8974, LR=0.000100
[2025-08-26 02:07:33,026][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015160] [Batch 00553/04869] [00:06:13/00:48:34, 0.675s/it]: train_loss_raw=1.9655, running_loss=1.8983, LR=0.000100
[2025-08-26 02:07:38,354][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015168] [Batch 00561/04869] [00:06:18/00:48:28, 0.675s/it]: train_loss_raw=1.8525, running_loss=1.8975, LR=0.000100
[2025-08-26 02:07:43,804][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015176] [Batch 00569/04869] [00:06:24/00:48:23, 0.675s/it]: train_loss_raw=1.9677, running_loss=1.8976, LR=0.000100
[2025-08-26 02:07:49,271][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015184] [Batch 00577/04869] [00:06:29/00:48:18, 0.675s/it]: train_loss_raw=1.9289, running_loss=1.8971, LR=0.000100
[2025-08-26 02:07:54,857][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015192] [Batch 00585/04869] [00:06:35/00:48:14, 0.676s/it]: train_loss_raw=1.9328, running_loss=1.8967, LR=0.000100
[2025-08-26 02:08:00,070][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015200] [Batch 00593/04869] [00:06:40/00:48:07, 0.675s/it]: train_loss_raw=2.0338, running_loss=1.8983, LR=0.000100
[2025-08-26 02:08:05,273][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015208] [Batch 00601/04869] [00:06:45/00:48:00, 0.675s/it]: train_loss_raw=1.8964, running_loss=1.8974, LR=0.000100
[2025-08-26 02:08:10,481][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015216] [Batch 00609/04869] [00:06:50/00:47:54, 0.675s/it]: train_loss_raw=1.8735, running_loss=1.8970, LR=0.000100
[2025-08-26 02:08:16,256][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015224] [Batch 00617/04869] [00:06:56/00:47:51, 0.675s/it]: train_loss_raw=1.8291, running_loss=1.8943, LR=0.000100
[2025-08-26 02:08:21,483][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015232] [Batch 00625/04869] [00:07:01/00:47:44, 0.675s/it]: train_loss_raw=1.8835, running_loss=1.8937, LR=0.000100
[2025-08-26 02:08:26,670][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015240] [Batch 00633/04869] [00:07:07/00:47:37, 0.675s/it]: train_loss_raw=1.8787, running_loss=1.8964, LR=0.000100
[2025-08-26 02:08:31,862][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015248] [Batch 00641/04869] [00:07:12/00:47:31, 0.674s/it]: train_loss_raw=1.7841, running_loss=1.8955, LR=0.000100
[2025-08-26 02:08:37,070][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015256] [Batch 00649/04869] [00:07:17/00:47:24, 0.674s/it]: train_loss_raw=1.8499, running_loss=1.8981, LR=0.000100
[2025-08-26 02:08:42,369][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015264] [Batch 00657/04869] [00:07:22/00:47:18, 0.674s/it]: train_loss_raw=1.8245, running_loss=1.8971, LR=0.000100
[2025-08-26 02:08:47,641][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015272] [Batch 00665/04869] [00:07:28/00:47:12, 0.674s/it]: train_loss_raw=1.8585, running_loss=1.8945, LR=0.000100
[2025-08-26 02:08:52,917][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015280] [Batch 00673/04869] [00:07:33/00:47:06, 0.674s/it]: train_loss_raw=1.8249, running_loss=1.8933, LR=0.000100
[2025-08-26 02:08:58,215][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015288] [Batch 00681/04869] [00:07:38/00:47:00, 0.673s/it]: train_loss_raw=1.9657, running_loss=1.8941, LR=0.000100
[2025-08-26 02:09:03,832][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015296] [Batch 00689/04869] [00:07:44/00:46:56, 0.674s/it]: train_loss_raw=1.9323, running_loss=1.8945, LR=0.000100
[2025-08-26 02:09:09,625][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015304] [Batch 00697/04869] [00:07:50/00:46:53, 0.674s/it]: train_loss_raw=1.9598, running_loss=1.8978, LR=0.000100
[2025-08-26 02:09:15,119][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015312] [Batch 00705/04869] [00:07:55/00:46:48, 0.674s/it]: train_loss_raw=1.8811, running_loss=1.8968, LR=0.000100
[2025-08-26 02:09:20,358][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015320] [Batch 00713/04869] [00:08:00/00:46:42, 0.674s/it]: train_loss_raw=1.9945, running_loss=1.8935, LR=0.000100
[2025-08-26 02:09:25,580][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015328] [Batch 00721/04869] [00:08:05/00:46:35, 0.674s/it]: train_loss_raw=1.8247, running_loss=1.8935, LR=0.000100
[2025-08-26 02:09:30,826][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015336] [Batch 00729/04869] [00:08:11/00:46:29, 0.674s/it]: train_loss_raw=1.8728, running_loss=1.8911, LR=0.000100
[2025-08-26 02:09:36,105][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015344] [Batch 00737/04869] [00:08:16/00:46:23, 0.674s/it]: train_loss_raw=1.8543, running_loss=1.8897, LR=0.000100
[2025-08-26 02:09:42,061][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015352] [Batch 00745/04869] [00:08:22/00:46:21, 0.674s/it]: train_loss_raw=1.8351, running_loss=1.8894, LR=0.000100
[2025-08-26 02:09:47,873][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015360] [Batch 00753/04869] [00:08:28/00:46:18, 0.675s/it]: train_loss_raw=1.8779, running_loss=1.8868, LR=0.000100
[2025-08-26 02:09:53,080][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015368] [Batch 00761/04869] [00:08:33/00:46:11, 0.675s/it]: train_loss_raw=1.9531, running_loss=1.8876, LR=0.000100
[2025-08-26 02:09:58,298][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015376] [Batch 00769/04869] [00:08:38/00:46:05, 0.675s/it]: train_loss_raw=1.8633, running_loss=1.8895, LR=0.000100
[2025-08-26 02:10:04,028][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015384] [Batch 00777/04869] [00:08:44/00:46:01, 0.675s/it]: train_loss_raw=1.8637, running_loss=1.8893, LR=0.000100
[2025-08-26 02:10:09,489][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015392] [Batch 00785/04869] [00:08:49/00:45:56, 0.675s/it]: train_loss_raw=1.7977, running_loss=1.8893, LR=0.000100
[2025-08-26 02:10:14,693][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015400] [Batch 00793/04869] [00:08:55/00:45:50, 0.675s/it]: train_loss_raw=1.9340, running_loss=1.8864, LR=0.000100
[2025-08-26 02:10:19,934][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015408] [Batch 00801/04869] [00:09:00/00:45:44, 0.675s/it]: train_loss_raw=1.9376, running_loss=1.8854, LR=0.000100
[2025-08-26 02:10:25,846][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015416] [Batch 00809/04869] [00:09:06/00:45:41, 0.675s/it]: train_loss_raw=1.8504, running_loss=1.8850, LR=0.000100
[2025-08-26 02:10:31,293][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015424] [Batch 00817/04869] [00:09:11/00:45:36, 0.675s/it]: train_loss_raw=1.8503, running_loss=1.8834, LR=0.000100
[2025-08-26 02:10:36,924][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015432] [Batch 00825/04869] [00:09:17/00:45:31, 0.676s/it]: train_loss_raw=1.9041, running_loss=1.8848, LR=0.000100
[2025-08-26 02:10:42,194][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015440] [Batch 00833/04869] [00:09:22/00:45:25, 0.675s/it]: train_loss_raw=1.8895, running_loss=1.8850, LR=0.000100
[2025-08-26 02:10:47,992][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015448] [Batch 00841/04869] [00:09:28/00:45:22, 0.676s/it]: train_loss_raw=1.9238, running_loss=1.8866, LR=0.000100
[2025-08-26 02:10:53,277][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015456] [Batch 00849/04869] [00:09:33/00:45:16, 0.676s/it]: train_loss_raw=1.7955, running_loss=1.8860, LR=0.000100
[2025-08-26 02:10:58,531][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015464] [Batch 00857/04869] [00:09:38/00:45:10, 0.676s/it]: train_loss_raw=1.8996, running_loss=1.8863, LR=0.000100
[2025-08-26 02:11:03,803][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015472] [Batch 00865/04869] [00:09:44/00:45:04, 0.675s/it]: train_loss_raw=1.9098, running_loss=1.8843, LR=0.000100
[2025-08-26 02:11:09,105][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015480] [Batch 00873/04869] [00:09:49/00:44:58, 0.675s/it]: train_loss_raw=1.9325, running_loss=1.8849, LR=0.000100
[2025-08-26 02:11:14,819][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015488] [Batch 00881/04869] [00:09:55/00:44:54, 0.676s/it]: train_loss_raw=1.8957, running_loss=1.8854, LR=0.000100
[2025-08-26 02:11:20,332][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015496] [Batch 00889/04869] [00:10:00/00:44:49, 0.676s/it]: train_loss_raw=1.8415, running_loss=1.8846, LR=0.000100
[2025-08-26 02:11:25,952][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015504] [Batch 00897/04869] [00:10:06/00:44:44, 0.676s/it]: train_loss_raw=1.9213, running_loss=1.8837, LR=0.000100
[2025-08-26 02:11:31,596][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015512] [Batch 00905/04869] [00:10:11/00:44:40, 0.676s/it]: train_loss_raw=1.9957, running_loss=1.8851, LR=0.000100
[2025-08-26 02:11:37,351][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015520] [Batch 00913/04869] [00:10:17/00:44:36, 0.677s/it]: train_loss_raw=1.9718, running_loss=1.8878, LR=0.000100
[2025-08-26 02:11:42,822][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015528] [Batch 00921/04869] [00:10:23/00:44:31, 0.677s/it]: train_loss_raw=1.8794, running_loss=1.8866, LR=0.000100
[2025-08-26 02:11:48,379][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015536] [Batch 00929/04869] [00:10:28/00:44:26, 0.677s/it]: train_loss_raw=1.8771, running_loss=1.8870, LR=0.000100
[2025-08-26 02:11:53,592][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015544] [Batch 00937/04869] [00:10:33/00:44:20, 0.677s/it]: train_loss_raw=1.8693, running_loss=1.8885, LR=0.000100
[2025-08-26 02:11:59,715][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015552] [Batch 00945/04869] [00:10:40/00:44:17, 0.677s/it]: train_loss_raw=1.8876, running_loss=1.8871, LR=0.000100
[2025-08-26 02:12:05,349][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015560] [Batch 00953/04869] [00:10:45/00:44:13, 0.678s/it]: train_loss_raw=1.8805, running_loss=1.8863, LR=0.000100
[2025-08-26 02:12:10,903][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015568] [Batch 00961/04869] [00:10:51/00:44:08, 0.678s/it]: train_loss_raw=1.9001, running_loss=1.8847, LR=0.000100
[2025-08-26 02:12:16,239][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015576] [Batch 00969/04869] [00:10:56/00:44:02, 0.678s/it]: train_loss_raw=1.9530, running_loss=1.8863, LR=0.000100
[2025-08-26 02:12:21,480][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015584] [Batch 00977/04869] [00:11:01/00:43:56, 0.677s/it]: train_loss_raw=1.9553, running_loss=1.8865, LR=0.000100
[2025-08-26 02:12:26,863][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015592] [Batch 00985/04869] [00:11:07/00:43:51, 0.677s/it]: train_loss_raw=1.8592, running_loss=1.8876, LR=0.000100
[2025-08-26 02:12:32,069][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015600] [Batch 00993/04869] [00:11:12/00:43:44, 0.677s/it]: train_loss_raw=1.9653, running_loss=1.8894, LR=0.000100
[2025-08-26 02:12:37,312][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015608] [Batch 01001/04869] [00:11:17/00:43:38, 0.677s/it]: train_loss_raw=1.9894, running_loss=1.8905, LR=0.000100
[2025-08-26 02:12:42,526][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015616] [Batch 01009/04869] [00:11:22/00:43:32, 0.677s/it]: train_loss_raw=1.8122, running_loss=1.8879, LR=0.000100
[2025-08-26 02:12:47,751][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015624] [Batch 01017/04869] [00:11:28/00:43:26, 0.677s/it]: train_loss_raw=1.8968, running_loss=1.8868, LR=0.000100
[2025-08-26 02:12:53,432][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015632] [Batch 01025/04869] [00:11:33/00:43:22, 0.677s/it]: train_loss_raw=1.8593, running_loss=1.8870, LR=0.000100
[2025-08-26 02:12:58,937][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015640] [Batch 01033/04869] [00:11:39/00:43:16, 0.677s/it]: train_loss_raw=1.7986, running_loss=1.8871, LR=0.000100
[2025-08-26 02:13:04,224][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015648] [Batch 01041/04869] [00:11:44/00:43:11, 0.677s/it]: train_loss_raw=1.8723, running_loss=1.8864, LR=0.000100
[2025-08-26 02:13:09,524][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015656] [Batch 01049/04869] [00:11:49/00:43:05, 0.677s/it]: train_loss_raw=1.9196, running_loss=1.8867, LR=0.000100
[2025-08-26 02:13:15,489][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015664] [Batch 01057/04869] [00:11:55/00:43:01, 0.677s/it]: train_loss_raw=1.8433, running_loss=1.8868, LR=0.000100
[2025-08-26 02:13:21,251][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015672] [Batch 01065/04869] [00:12:01/00:42:57, 0.678s/it]: train_loss_raw=1.8509, running_loss=1.8855, LR=0.000100
[2025-08-26 02:13:26,801][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015680] [Batch 01073/04869] [00:12:07/00:42:52, 0.678s/it]: train_loss_raw=1.9154, running_loss=1.8852, LR=0.000100
[2025-08-26 02:13:33,043][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015688] [Batch 01081/04869] [00:12:13/00:42:50, 0.678s/it]: train_loss_raw=1.9348, running_loss=1.8854, LR=0.000100
[2025-08-26 02:13:38,408][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015696] [Batch 01089/04869] [00:12:18/00:42:44, 0.678s/it]: train_loss_raw=1.8569, running_loss=1.8840, LR=0.000100
[2025-08-26 02:13:43,672][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015704] [Batch 01097/04869] [00:12:24/00:42:38, 0.678s/it]: train_loss_raw=1.9266, running_loss=1.8863, LR=0.000100
[2025-08-26 02:13:49,343][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015712] [Batch 01105/04869] [00:12:29/00:42:33, 0.678s/it]: train_loss_raw=1.8378, running_loss=1.8842, LR=0.000100
[2025-08-26 02:13:55,281][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015720] [Batch 01113/04869] [00:12:35/00:42:30, 0.679s/it]: train_loss_raw=1.9249, running_loss=1.8838, LR=0.000100
[2025-08-26 02:14:00,991][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015728] [Batch 01121/04869] [00:12:41/00:42:25, 0.679s/it]: train_loss_raw=1.9000, running_loss=1.8867, LR=0.000100
[2025-08-26 02:14:06,541][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015736] [Batch 01129/04869] [00:12:46/00:42:20, 0.679s/it]: train_loss_raw=1.8894, running_loss=1.8841, LR=0.000100
[2025-08-26 02:14:11,847][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015744] [Batch 01137/04869] [00:12:52/00:42:14, 0.679s/it]: train_loss_raw=1.8269, running_loss=1.8815, LR=0.000100
[2025-08-26 02:14:17,285][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015752] [Batch 01145/04869] [00:12:57/00:42:09, 0.679s/it]: train_loss_raw=1.8469, running_loss=1.8813, LR=0.000100
[2025-08-26 02:14:22,516][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015760] [Batch 01153/04869] [00:13:02/00:42:03, 0.679s/it]: train_loss_raw=1.9196, running_loss=1.8809, LR=0.000100
[2025-08-26 02:14:28,037][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015768] [Batch 01161/04869] [00:13:08/00:41:58, 0.679s/it]: train_loss_raw=1.8585, running_loss=1.8816, LR=0.000100
[2025-08-26 02:14:34,068][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015776] [Batch 01169/04869] [00:13:14/00:41:54, 0.680s/it]: train_loss_raw=1.9033, running_loss=1.8827, LR=0.000100
[2025-08-26 02:14:40,211][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015784] [Batch 01177/04869] [00:13:20/00:41:51, 0.680s/it]: train_loss_raw=1.8790, running_loss=1.8822, LR=0.000100
[2025-08-26 02:14:46,118][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015792] [Batch 01185/04869] [00:13:26/00:41:47, 0.681s/it]: train_loss_raw=1.8810, running_loss=1.8819, LR=0.000100
[2025-08-26 02:14:52,044][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015800] [Batch 01193/04869] [00:13:32/00:41:43, 0.681s/it]: train_loss_raw=1.8767, running_loss=1.8829, LR=0.000100
[2025-08-26 02:14:58,447][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015808] [Batch 01201/04869] [00:13:38/00:41:40, 0.682s/it]: train_loss_raw=1.9647, running_loss=1.8834, LR=0.000100
[2025-08-26 02:15:04,090][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015816] [Batch 01209/04869] [00:13:44/00:41:35, 0.682s/it]: train_loss_raw=1.9025, running_loss=1.8823, LR=0.000100
[2025-08-26 02:15:09,371][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015824] [Batch 01217/04869] [00:13:49/00:41:29, 0.682s/it]: train_loss_raw=1.8461, running_loss=1.8819, LR=0.000100
[2025-08-26 02:15:14,956][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015832] [Batch 01225/04869] [00:13:55/00:41:24, 0.682s/it]: train_loss_raw=1.8343, running_loss=1.8798, LR=0.000100
[2025-08-26 02:15:20,411][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015840] [Batch 01233/04869] [00:14:00/00:41:19, 0.682s/it]: train_loss_raw=1.9602, running_loss=1.8774, LR=0.000100
[2025-08-26 02:15:25,627][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015848] [Batch 01241/04869] [00:14:06/00:41:13, 0.682s/it]: train_loss_raw=1.8356, running_loss=1.8776, LR=0.000100
[2025-08-26 02:15:30,835][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015856] [Batch 01249/04869] [00:14:11/00:41:07, 0.682s/it]: train_loss_raw=1.8804, running_loss=1.8794, LR=0.000100
[2025-08-26 02:15:36,016][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015864] [Batch 01257/04869] [00:14:16/00:41:00, 0.681s/it]: train_loss_raw=1.9061, running_loss=1.8774, LR=0.000100
[2025-08-26 02:15:41,194][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015872] [Batch 01265/04869] [00:14:21/00:40:54, 0.681s/it]: train_loss_raw=1.8680, running_loss=1.8734, LR=0.000100
[2025-08-26 02:15:46,375][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015880] [Batch 01273/04869] [00:14:26/00:40:48, 0.681s/it]: train_loss_raw=1.8790, running_loss=1.8747, LR=0.000100
[2025-08-26 02:15:51,845][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015888] [Batch 01281/04869] [00:14:32/00:40:43, 0.681s/it]: train_loss_raw=1.9531, running_loss=1.8745, LR=0.000100
[2025-08-26 02:15:57,082][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015896] [Batch 01289/04869] [00:14:37/00:40:37, 0.681s/it]: train_loss_raw=1.8817, running_loss=1.8744, LR=0.000100
[2025-08-26 02:16:02,343][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015904] [Batch 01297/04869] [00:14:42/00:40:31, 0.681s/it]: train_loss_raw=1.9326, running_loss=1.8757, LR=0.000100
[2025-08-26 02:16:07,763][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015912] [Batch 01305/04869] [00:14:48/00:40:25, 0.681s/it]: train_loss_raw=1.8711, running_loss=1.8764, LR=0.000100
[2025-08-26 02:16:14,041][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015920] [Batch 01313/04869] [00:14:54/00:40:22, 0.681s/it]: train_loss_raw=1.8240, running_loss=1.8770, LR=0.000100
[2025-08-26 02:16:19,731][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015928] [Batch 01321/04869] [00:15:00/00:40:17, 0.681s/it]: train_loss_raw=1.8707, running_loss=1.8778, LR=0.000100
[2025-08-26 02:16:25,651][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015936] [Batch 01329/04869] [00:15:06/00:40:13, 0.682s/it]: train_loss_raw=1.8005, running_loss=1.8775, LR=0.000100
[2025-08-26 02:16:30,956][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015944] [Batch 01337/04869] [00:15:11/00:40:07, 0.682s/it]: train_loss_raw=1.9329, running_loss=1.8763, LR=0.000100
[2025-08-26 02:16:36,608][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015952] [Batch 01345/04869] [00:15:17/00:40:02, 0.682s/it]: train_loss_raw=1.8589, running_loss=1.8763, LR=0.000100
[2025-08-26 02:16:42,049][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015960] [Batch 01353/04869] [00:15:22/00:39:57, 0.682s/it]: train_loss_raw=1.8593, running_loss=1.8752, LR=0.000100
[2025-08-26 02:16:47,308][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015968] [Batch 01361/04869] [00:15:27/00:39:51, 0.682s/it]: train_loss_raw=1.7733, running_loss=1.8729, LR=0.000100
[2025-08-26 02:16:52,511][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015976] [Batch 01369/04869] [00:15:32/00:39:45, 0.681s/it]: train_loss_raw=1.8845, running_loss=1.8744, LR=0.000100
[2025-08-26 02:16:57,715][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015984] [Batch 01377/04869] [00:15:38/00:39:38, 0.681s/it]: train_loss_raw=1.8770, running_loss=1.8712, LR=0.000100
[2025-08-26 02:17:03,278][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 015992] [Batch 01385/04869] [00:15:43/00:39:33, 0.681s/it]: train_loss_raw=1.8115, running_loss=1.8731, LR=0.000100
[2025-08-26 02:17:08,637][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016000] [Batch 01393/04869] [00:15:49/00:39:28, 0.681s/it]: train_loss_raw=1.8153, running_loss=1.8719, LR=0.000100
[2025-08-26 02:17:17,618][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016008] [Batch 01401/04869] [00:15:58/00:39:31, 0.684s/it]: train_loss_raw=1.8758, running_loss=1.8706, LR=0.000100
[2025-08-26 02:17:23,451][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016016] [Batch 01409/04869] [00:16:03/00:39:26, 0.684s/it]: train_loss_raw=1.7682, running_loss=1.8707, LR=0.000100
[2025-08-26 02:17:29,256][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016024] [Batch 01417/04869] [00:16:09/00:39:22, 0.684s/it]: train_loss_raw=1.9378, running_loss=1.8706, LR=0.000100
[2025-08-26 02:17:34,473][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016032] [Batch 01425/04869] [00:16:14/00:39:16, 0.684s/it]: train_loss_raw=1.8015, running_loss=1.8691, LR=0.000100
[2025-08-26 02:17:39,687][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016040] [Batch 01433/04869] [00:16:20/00:39:10, 0.684s/it]: train_loss_raw=1.7983, running_loss=1.8660, LR=0.000100
[2025-08-26 02:17:44,902][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016048] [Batch 01441/04869] [00:16:25/00:39:03, 0.684s/it]: train_loss_raw=1.8617, running_loss=1.8661, LR=0.000100
[2025-08-26 02:17:50,125][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016056] [Batch 01449/04869] [00:16:30/00:38:57, 0.684s/it]: train_loss_raw=1.8550, running_loss=1.8659, LR=0.000100
[2025-08-26 02:17:55,374][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016064] [Batch 01457/04869] [00:16:35/00:38:51, 0.683s/it]: train_loss_raw=1.7547, running_loss=1.8655, LR=0.000100
[2025-08-26 02:18:00,652][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016072] [Batch 01465/04869] [00:16:41/00:38:45, 0.683s/it]: train_loss_raw=1.7739, running_loss=1.8684, LR=0.000100
[2025-08-26 02:18:06,027][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016080] [Batch 01473/04869] [00:16:46/00:38:40, 0.683s/it]: train_loss_raw=1.8355, running_loss=1.8701, LR=0.000100
[2025-08-26 02:18:11,552][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016088] [Batch 01481/04869] [00:16:51/00:38:34, 0.683s/it]: train_loss_raw=1.8634, running_loss=1.8729, LR=0.000100
[2025-08-26 02:18:17,311][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016096] [Batch 01489/04869] [00:16:57/00:38:30, 0.683s/it]: train_loss_raw=1.7991, running_loss=1.8728, LR=0.000100
[2025-08-26 02:18:22,689][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016104] [Batch 01497/04869] [00:17:03/00:38:24, 0.683s/it]: train_loss_raw=1.8244, running_loss=1.8747, LR=0.000100
[2025-08-26 02:18:28,289][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016112] [Batch 01505/04869] [00:17:08/00:38:19, 0.684s/it]: train_loss_raw=1.8327, running_loss=1.8733, LR=0.000100
[2025-08-26 02:18:33,504][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016120] [Batch 01513/04869] [00:17:13/00:38:13, 0.683s/it]: train_loss_raw=1.9791, running_loss=1.8734, LR=0.000100
[2025-08-26 02:18:38,702][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016128] [Batch 01521/04869] [00:17:19/00:38:07, 0.683s/it]: train_loss_raw=1.8985, running_loss=1.8722, LR=0.000100
[2025-08-26 02:18:43,909][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016136] [Batch 01529/04869] [00:17:24/00:38:01, 0.683s/it]: train_loss_raw=1.8916, running_loss=1.8749, LR=0.000100
[2025-08-26 02:18:49,133][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016144] [Batch 01537/04869] [00:17:29/00:37:55, 0.683s/it]: train_loss_raw=1.8420, running_loss=1.8727, LR=0.000100
[2025-08-26 02:18:54,509][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016152] [Batch 01545/04869] [00:17:34/00:37:49, 0.683s/it]: train_loss_raw=1.7966, running_loss=1.8719, LR=0.000100
[2025-08-26 02:18:59,722][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016160] [Batch 01553/04869] [00:17:40/00:37:43, 0.683s/it]: train_loss_raw=1.8338, running_loss=1.8700, LR=0.000100
[2025-08-26 02:19:05,018][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016168] [Batch 01561/04869] [00:17:45/00:37:37, 0.683s/it]: train_loss_raw=1.8702, running_loss=1.8683, LR=0.000100
[2025-08-26 02:19:10,492][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016176] [Batch 01569/04869] [00:17:50/00:37:32, 0.683s/it]: train_loss_raw=1.9636, running_loss=1.8693, LR=0.000100
[2025-08-26 02:19:15,796][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016184] [Batch 01577/04869] [00:17:56/00:37:26, 0.682s/it]: train_loss_raw=1.9272, running_loss=1.8708, LR=0.000100
[2025-08-26 02:19:20,999][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016192] [Batch 01585/04869] [00:18:01/00:37:20, 0.682s/it]: train_loss_raw=1.8580, running_loss=1.8712, LR=0.000100
[2025-08-26 02:19:26,196][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016200] [Batch 01593/04869] [00:18:06/00:37:14, 0.682s/it]: train_loss_raw=1.7809, running_loss=1.8689, LR=0.000100
[2025-08-26 02:19:31,807][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016208] [Batch 01601/04869] [00:18:12/00:37:09, 0.682s/it]: train_loss_raw=1.9065, running_loss=1.8687, LR=0.000100
[2025-08-26 02:19:37,080][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016216] [Batch 01609/04869] [00:18:17/00:37:03, 0.682s/it]: train_loss_raw=1.8315, running_loss=1.8675, LR=0.000100
[2025-08-26 02:19:42,743][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016224] [Batch 01617/04869] [00:18:23/00:36:58, 0.682s/it]: train_loss_raw=1.8957, running_loss=1.8664, LR=0.000100
[2025-08-26 02:19:47,942][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016232] [Batch 01625/04869] [00:18:28/00:36:52, 0.682s/it]: train_loss_raw=1.7996, running_loss=1.8643, LR=0.000100
[2025-08-26 02:19:53,126][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016240] [Batch 01633/04869] [00:18:33/00:36:46, 0.682s/it]: train_loss_raw=1.7980, running_loss=1.8654, LR=0.000100
[2025-08-26 02:19:58,297][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016248] [Batch 01641/04869] [00:18:38/00:36:40, 0.682s/it]: train_loss_raw=1.8972, running_loss=1.8673, LR=0.000100
[2025-08-26 02:20:03,492][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016256] [Batch 01649/04869] [00:18:43/00:36:34, 0.682s/it]: train_loss_raw=1.8389, running_loss=1.8673, LR=0.000100
[2025-08-26 02:20:08,685][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016264] [Batch 01657/04869] [00:18:49/00:36:28, 0.681s/it]: train_loss_raw=1.8700, running_loss=1.8675, LR=0.000100
[2025-08-26 02:20:14,290][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016272] [Batch 01665/04869] [00:18:54/00:36:23, 0.681s/it]: train_loss_raw=1.9930, running_loss=1.8681, LR=0.000100
[2025-08-26 02:20:20,199][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016280] [Batch 01673/04869] [00:19:00/00:36:18, 0.682s/it]: train_loss_raw=1.8486, running_loss=1.8674, LR=0.000100
[2025-08-26 02:20:25,629][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016288] [Batch 01681/04869] [00:19:06/00:36:13, 0.682s/it]: train_loss_raw=1.8400, running_loss=1.8684, LR=0.000100
[2025-08-26 02:20:30,894][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016296] [Batch 01689/04869] [00:19:11/00:36:07, 0.682s/it]: train_loss_raw=1.8865, running_loss=1.8668, LR=0.000100
[2025-08-26 02:20:36,642][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016304] [Batch 01697/04869] [00:19:17/00:36:02, 0.682s/it]: train_loss_raw=1.8718, running_loss=1.8653, LR=0.000100
[2025-08-26 02:20:42,025][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016312] [Batch 01705/04869] [00:19:22/00:35:57, 0.682s/it]: train_loss_raw=1.9117, running_loss=1.8659, LR=0.000100
[2025-08-26 02:20:47,923][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016320] [Batch 01713/04869] [00:19:28/00:35:52, 0.682s/it]: train_loss_raw=1.8835, running_loss=1.8656, LR=0.000100
[2025-08-26 02:20:53,464][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016328] [Batch 01721/04869] [00:19:33/00:35:47, 0.682s/it]: train_loss_raw=1.7402, running_loss=1.8640, LR=0.000100
[2025-08-26 02:20:58,973][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016336] [Batch 01729/04869] [00:19:39/00:35:41, 0.682s/it]: train_loss_raw=1.7989, running_loss=1.8653, LR=0.000100
[2025-08-26 02:21:04,538][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016344] [Batch 01737/04869] [00:19:44/00:35:36, 0.682s/it]: train_loss_raw=1.8261, running_loss=1.8630, LR=0.000100
[2025-08-26 02:21:10,000][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016352] [Batch 01745/04869] [00:19:50/00:35:31, 0.682s/it]: train_loss_raw=1.8189, running_loss=1.8624, LR=0.000100
[2025-08-26 02:21:15,530][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016360] [Batch 01753/04869] [00:19:55/00:35:25, 0.682s/it]: train_loss_raw=1.8336, running_loss=1.8629, LR=0.000100
[2025-08-26 02:21:21,602][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016368] [Batch 01761/04869] [00:20:01/00:35:21, 0.683s/it]: train_loss_raw=1.8839, running_loss=1.8645, LR=0.000100
[2025-08-26 02:21:27,126][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016376] [Batch 01769/04869] [00:20:07/00:35:16, 0.683s/it]: train_loss_raw=1.8816, running_loss=1.8636, LR=0.000100
[2025-08-26 02:21:32,699][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016384] [Batch 01777/04869] [00:20:13/00:35:10, 0.683s/it]: train_loss_raw=1.8343, running_loss=1.8632, LR=0.000100
[2025-08-26 02:21:38,243][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016392] [Batch 01785/04869] [00:20:18/00:35:05, 0.683s/it]: train_loss_raw=1.9164, running_loss=1.8642, LR=0.000100
[2025-08-26 02:21:43,979][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016400] [Batch 01793/04869] [00:20:24/00:35:00, 0.683s/it]: train_loss_raw=1.7820, running_loss=1.8636, LR=0.000100
[2025-08-26 02:21:49,183][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016408] [Batch 01801/04869] [00:20:29/00:34:54, 0.683s/it]: train_loss_raw=1.8691, running_loss=1.8642, LR=0.000100
[2025-08-26 02:21:54,599][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016416] [Batch 01809/04869] [00:20:34/00:34:49, 0.683s/it]: train_loss_raw=1.7545, running_loss=1.8635, LR=0.000100
[2025-08-26 02:22:00,113][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016424] [Batch 01817/04869] [00:20:40/00:34:43, 0.683s/it]: train_loss_raw=1.8299, running_loss=1.8641, LR=0.000100
[2025-08-26 02:22:05,769][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016432] [Batch 01825/04869] [00:20:46/00:34:38, 0.683s/it]: train_loss_raw=1.8729, running_loss=1.8636, LR=0.000100
[2025-08-26 02:22:11,358][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016440] [Batch 01833/04869] [00:20:51/00:34:33, 0.683s/it]: train_loss_raw=1.9848, running_loss=1.8638, LR=0.000100
[2025-08-26 02:22:16,569][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016448] [Batch 01841/04869] [00:20:56/00:34:27, 0.683s/it]: train_loss_raw=1.8634, running_loss=1.8623, LR=0.000100
[2025-08-26 02:22:21,760][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016456] [Batch 01849/04869] [00:21:02/00:34:21, 0.683s/it]: train_loss_raw=1.9258, running_loss=1.8623, LR=0.000100
[2025-08-26 02:22:27,307][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016464] [Batch 01857/04869] [00:21:07/00:34:16, 0.683s/it]: train_loss_raw=1.8586, running_loss=1.8620, LR=0.000100
[2025-08-26 02:22:33,027][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016472] [Batch 01865/04869] [00:21:13/00:34:11, 0.683s/it]: train_loss_raw=1.8979, running_loss=1.8623, LR=0.000100
[2025-08-26 02:22:38,517][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016480] [Batch 01873/04869] [00:21:18/00:34:05, 0.683s/it]: train_loss_raw=1.8848, running_loss=1.8645, LR=0.000100
[2025-08-26 02:22:43,732][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016488] [Batch 01881/04869] [00:21:24/00:33:59, 0.683s/it]: train_loss_raw=1.8606, running_loss=1.8648, LR=0.000100
[2025-08-26 02:22:49,558][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016496] [Batch 01889/04869] [00:21:29/00:33:54, 0.683s/it]: train_loss_raw=1.8528, running_loss=1.8661, LR=0.000100
[2025-08-26 02:22:54,795][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016504] [Batch 01897/04869] [00:21:35/00:33:49, 0.683s/it]: train_loss_raw=1.8731, running_loss=1.8676, LR=0.000100
[2025-08-26 02:23:00,125][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016512] [Batch 01905/04869] [00:21:40/00:33:43, 0.683s/it]: train_loss_raw=1.7777, running_loss=1.8654, LR=0.000100
[2025-08-26 02:23:06,259][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016520] [Batch 01913/04869] [00:21:46/00:33:39, 0.683s/it]: train_loss_raw=1.8114, running_loss=1.8652, LR=0.000100
[2025-08-26 02:23:11,554][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016528] [Batch 01921/04869] [00:21:51/00:33:33, 0.683s/it]: train_loss_raw=1.8325, running_loss=1.8628, LR=0.000100
[2025-08-26 02:23:17,091][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016536] [Batch 01929/04869] [00:21:57/00:33:27, 0.683s/it]: train_loss_raw=1.8463, running_loss=1.8631, LR=0.000100
[2025-08-26 02:23:22,972][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016544] [Batch 01937/04869] [00:22:03/00:33:23, 0.683s/it]: train_loss_raw=1.8628, running_loss=1.8621, LR=0.000100
[2025-08-26 02:23:28,484][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016552] [Batch 01945/04869] [00:22:08/00:33:17, 0.683s/it]: train_loss_raw=1.9403, running_loss=1.8633, LR=0.000100
[2025-08-26 02:23:33,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016560] [Batch 01953/04869] [00:22:14/00:33:12, 0.683s/it]: train_loss_raw=1.8730, running_loss=1.8632, LR=0.000100
[2025-08-26 02:23:39,756][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016568] [Batch 01961/04869] [00:22:20/00:33:07, 0.683s/it]: train_loss_raw=1.8249, running_loss=1.8618, LR=0.000100
[2025-08-26 02:23:45,237][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016576] [Batch 01969/04869] [00:22:25/00:33:01, 0.683s/it]: train_loss_raw=1.9068, running_loss=1.8620, LR=0.000100
[2025-08-26 02:23:51,016][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016584] [Batch 01977/04869] [00:22:31/00:32:56, 0.684s/it]: train_loss_raw=1.7147, running_loss=1.8610, LR=0.000100
[2025-08-26 02:23:57,220][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016592] [Batch 01985/04869] [00:22:37/00:32:52, 0.684s/it]: train_loss_raw=1.9060, running_loss=1.8596, LR=0.000100
[2025-08-26 02:24:02,923][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016600] [Batch 01993/04869] [00:22:43/00:32:47, 0.684s/it]: train_loss_raw=1.8191, running_loss=1.8621, LR=0.000100
[2025-08-26 02:24:08,731][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016608] [Batch 02001/04869] [00:22:49/00:32:42, 0.684s/it]: train_loss_raw=1.9198, running_loss=1.8611, LR=0.000100
[2025-08-26 02:24:13,912][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016616] [Batch 02009/04869] [00:22:54/00:32:36, 0.684s/it]: train_loss_raw=1.8703, running_loss=1.8607, LR=0.000100
[2025-08-26 02:24:19,106][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016624] [Batch 02017/04869] [00:22:59/00:32:30, 0.684s/it]: train_loss_raw=1.8793, running_loss=1.8605, LR=0.000100
[2025-08-26 02:24:24,745][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016632] [Batch 02025/04869] [00:23:05/00:32:25, 0.684s/it]: train_loss_raw=1.8158, running_loss=1.8588, LR=0.000100
[2025-08-26 02:24:29,967][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016640] [Batch 02033/04869] [00:23:10/00:32:19, 0.684s/it]: train_loss_raw=1.9463, running_loss=1.8589, LR=0.000100
[2025-08-26 02:24:35,506][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016648] [Batch 02041/04869] [00:23:15/00:32:14, 0.684s/it]: train_loss_raw=1.8431, running_loss=1.8590, LR=0.000100
[2025-08-26 02:24:41,033][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016656] [Batch 02049/04869] [00:23:21/00:32:08, 0.684s/it]: train_loss_raw=1.8535, running_loss=1.8593, LR=0.000100
[2025-08-26 02:24:46,216][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016664] [Batch 02057/04869] [00:23:26/00:32:02, 0.684s/it]: train_loss_raw=1.8842, running_loss=1.8593, LR=0.000100
[2025-08-26 02:24:51,398][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016672] [Batch 02065/04869] [00:23:31/00:31:57, 0.684s/it]: train_loss_raw=1.8596, running_loss=1.8582, LR=0.000100
[2025-08-26 02:24:57,034][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016680] [Batch 02073/04869] [00:23:37/00:31:51, 0.684s/it]: train_loss_raw=1.8834, running_loss=1.8567, LR=0.000100
[2025-08-26 02:25:02,513][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016688] [Batch 02081/04869] [00:23:42/00:31:46, 0.684s/it]: train_loss_raw=1.8624, running_loss=1.8553, LR=0.000100
[2025-08-26 02:25:07,711][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016696] [Batch 02089/04869] [00:23:48/00:31:40, 0.684s/it]: train_loss_raw=1.9133, running_loss=1.8559, LR=0.000100
[2025-08-26 02:25:13,044][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016704] [Batch 02097/04869] [00:23:53/00:31:34, 0.684s/it]: train_loss_raw=1.8995, running_loss=1.8563, LR=0.000100
[2025-08-26 02:25:19,193][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016712] [Batch 02105/04869] [00:23:59/00:31:30, 0.684s/it]: train_loss_raw=1.7858, running_loss=1.8539, LR=0.000100
[2025-08-26 02:25:24,878][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016720] [Batch 02113/04869] [00:24:05/00:31:25, 0.684s/it]: train_loss_raw=1.7980, running_loss=1.8540, LR=0.000100
[2025-08-26 02:25:30,826][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016728] [Batch 02121/04869] [00:24:11/00:31:20, 0.684s/it]: train_loss_raw=1.8485, running_loss=1.8529, LR=0.000100
[2025-08-26 02:25:36,538][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016736] [Batch 02129/04869] [00:24:16/00:31:15, 0.684s/it]: train_loss_raw=1.8177, running_loss=1.8519, LR=0.000100
[2025-08-26 02:25:41,912][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016744] [Batch 02137/04869] [00:24:22/00:31:09, 0.684s/it]: train_loss_raw=1.7524, running_loss=1.8505, LR=0.000100
[2025-08-26 02:25:47,136][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016752] [Batch 02145/04869] [00:24:27/00:31:03, 0.684s/it]: train_loss_raw=1.7927, running_loss=1.8490, LR=0.000100
[2025-08-26 02:25:52,554][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016760] [Batch 02153/04869] [00:24:32/00:30:58, 0.684s/it]: train_loss_raw=1.8108, running_loss=1.8490, LR=0.000100
[2025-08-26 02:25:57,828][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016768] [Batch 02161/04869] [00:24:38/00:30:52, 0.684s/it]: train_loss_raw=1.9192, running_loss=1.8507, LR=0.000100
[2025-08-26 02:26:03,358][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016776] [Batch 02169/04869] [00:24:43/00:30:46, 0.684s/it]: train_loss_raw=1.8938, running_loss=1.8513, LR=0.000100
[2025-08-26 02:26:08,622][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016784] [Batch 02177/04869] [00:24:49/00:30:41, 0.684s/it]: train_loss_raw=1.7829, running_loss=1.8507, LR=0.000100
[2025-08-26 02:26:13,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016792] [Batch 02185/04869] [00:24:54/00:30:35, 0.684s/it]: train_loss_raw=1.7818, running_loss=1.8508, LR=0.000100
[2025-08-26 02:26:19,098][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016800] [Batch 02193/04869] [00:24:59/00:30:29, 0.684s/it]: train_loss_raw=1.8746, running_loss=1.8501, LR=0.000100
[2025-08-26 02:26:24,504][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016808] [Batch 02201/04869] [00:25:04/00:30:24, 0.684s/it]: train_loss_raw=1.8471, running_loss=1.8495, LR=0.000100
[2025-08-26 02:26:30,103][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016816] [Batch 02209/04869] [00:25:10/00:30:18, 0.684s/it]: train_loss_raw=1.8399, running_loss=1.8471, LR=0.000100
[2025-08-26 02:26:35,360][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016824] [Batch 02217/04869] [00:25:15/00:30:13, 0.684s/it]: train_loss_raw=1.7957, running_loss=1.8446, LR=0.000100
[2025-08-26 02:26:40,821][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016832] [Batch 02225/04869] [00:25:21/00:30:07, 0.684s/it]: train_loss_raw=1.7784, running_loss=1.8450, LR=0.000100
[2025-08-26 02:26:46,050][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016840] [Batch 02233/04869] [00:25:26/00:30:01, 0.684s/it]: train_loss_raw=1.8651, running_loss=1.8462, LR=0.000100
[2025-08-26 02:26:51,273][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016848] [Batch 02241/04869] [00:25:31/00:29:56, 0.683s/it]: train_loss_raw=1.8698, running_loss=1.8481, LR=0.000100
[2025-08-26 02:26:56,487][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016856] [Batch 02249/04869] [00:25:36/00:29:50, 0.683s/it]: train_loss_raw=1.8274, running_loss=1.8466, LR=0.000100
[2025-08-26 02:27:01,928][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016864] [Batch 02257/04869] [00:25:42/00:29:44, 0.683s/it]: train_loss_raw=1.8745, running_loss=1.8433, LR=0.000100
[2025-08-26 02:27:07,254][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016872] [Batch 02265/04869] [00:25:47/00:29:39, 0.683s/it]: train_loss_raw=1.8421, running_loss=1.8466, LR=0.000100
[2025-08-26 02:27:12,809][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016880] [Batch 02273/04869] [00:25:53/00:29:33, 0.683s/it]: train_loss_raw=1.8859, running_loss=1.8458, LR=0.000100
[2025-08-26 02:27:18,044][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016888] [Batch 02281/04869] [00:25:58/00:29:28, 0.683s/it]: train_loss_raw=1.8369, running_loss=1.8468, LR=0.000100
[2025-08-26 02:27:23,315][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016896] [Batch 02289/04869] [00:26:03/00:29:22, 0.683s/it]: train_loss_raw=1.8570, running_loss=1.8494, LR=0.000100
[2025-08-26 02:27:28,734][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016904] [Batch 02297/04869] [00:26:09/00:29:16, 0.683s/it]: train_loss_raw=1.8430, running_loss=1.8487, LR=0.000100
[2025-08-26 02:27:34,260][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016912] [Batch 02305/04869] [00:26:14/00:29:11, 0.683s/it]: train_loss_raw=1.8318, running_loss=1.8490, LR=0.000100
[2025-08-26 02:27:39,476][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016920] [Batch 02313/04869] [00:26:19/00:29:05, 0.683s/it]: train_loss_raw=1.8121, running_loss=1.8466, LR=0.000100
[2025-08-26 02:27:44,695][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016928] [Batch 02321/04869] [00:26:25/00:29:00, 0.683s/it]: train_loss_raw=1.8011, running_loss=1.8471, LR=0.000100
[2025-08-26 02:27:49,908][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016936] [Batch 02329/04869] [00:26:30/00:28:54, 0.683s/it]: train_loss_raw=1.8656, running_loss=1.8483, LR=0.000100
[2025-08-26 02:27:55,182][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016944] [Batch 02337/04869] [00:26:35/00:28:48, 0.683s/it]: train_loss_raw=1.8325, running_loss=1.8490, LR=0.000100
[2025-08-26 02:28:00,410][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016952] [Batch 02345/04869] [00:26:40/00:28:42, 0.683s/it]: train_loss_raw=1.7913, running_loss=1.8521, LR=0.000100
[2025-08-26 02:28:05,698][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016960] [Batch 02353/04869] [00:26:46/00:28:37, 0.683s/it]: train_loss_raw=1.7806, running_loss=1.8535, LR=0.000100
[2025-08-26 02:28:11,244][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016968] [Batch 02361/04869] [00:26:51/00:28:31, 0.683s/it]: train_loss_raw=1.9427, running_loss=1.8543, LR=0.000100
[2025-08-26 02:28:16,730][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016976] [Batch 02369/04869] [00:26:57/00:28:26, 0.683s/it]: train_loss_raw=1.8341, running_loss=1.8534, LR=0.000100
[2025-08-26 02:28:22,620][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016984] [Batch 02377/04869] [00:27:03/00:28:21, 0.683s/it]: train_loss_raw=1.7842, running_loss=1.8515, LR=0.000100
[2025-08-26 02:28:27,956][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 016992] [Batch 02385/04869] [00:27:08/00:28:15, 0.683s/it]: train_loss_raw=1.7704, running_loss=1.8512, LR=0.000100
[2025-08-26 02:28:33,786][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017000] [Batch 02393/04869] [00:27:14/00:28:10, 0.683s/it]: train_loss_raw=1.8098, running_loss=1.8515, LR=0.000100
[2025-08-26 02:28:39,137][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017008] [Batch 02401/04869] [00:27:19/00:28:05, 0.683s/it]: train_loss_raw=1.7933, running_loss=1.8496, LR=0.000100
[2025-08-26 02:28:44,790][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017016] [Batch 02409/04869] [00:27:25/00:28:00, 0.683s/it]: train_loss_raw=1.9816, running_loss=1.8520, LR=0.000100
[2025-08-26 02:28:50,505][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017024] [Batch 02417/04869] [00:27:30/00:27:54, 0.683s/it]: train_loss_raw=1.9049, running_loss=1.8513, LR=0.000100
[2025-08-26 02:28:55,993][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017032] [Batch 02425/04869] [00:27:36/00:27:49, 0.683s/it]: train_loss_raw=2.0143, running_loss=1.8514, LR=0.000100
[2025-08-26 02:29:02,134][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017040] [Batch 02433/04869] [00:27:42/00:27:44, 0.683s/it]: train_loss_raw=1.9054, running_loss=1.8519, LR=0.000100
[2025-08-26 02:29:08,130][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017048] [Batch 02441/04869] [00:27:48/00:27:39, 0.684s/it]: train_loss_raw=1.8375, running_loss=1.8508, LR=0.000100
[2025-08-26 02:29:14,104][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017056] [Batch 02449/04869] [00:27:54/00:27:34, 0.684s/it]: train_loss_raw=1.8412, running_loss=1.8490, LR=0.000100
[2025-08-26 02:29:20,049][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017064] [Batch 02457/04869] [00:28:00/00:27:29, 0.684s/it]: train_loss_raw=1.8932, running_loss=1.8497, LR=0.000100
[2025-08-26 02:29:25,999][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017072] [Batch 02465/04869] [00:28:06/00:27:24, 0.684s/it]: train_loss_raw=1.9530, running_loss=1.8524, LR=0.000100
[2025-08-26 02:29:31,928][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017080] [Batch 02473/04869] [00:28:12/00:27:19, 0.684s/it]: train_loss_raw=1.8536, running_loss=1.8524, LR=0.000100
[2025-08-26 02:29:37,676][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017088] [Batch 02481/04869] [00:28:18/00:27:14, 0.684s/it]: train_loss_raw=1.8450, running_loss=1.8526, LR=0.000100
[2025-08-26 02:29:43,114][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017096] [Batch 02489/04869] [00:28:23/00:27:08, 0.684s/it]: train_loss_raw=1.8232, running_loss=1.8507, LR=0.000100
[2025-08-26 02:29:48,293][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017104] [Batch 02497/04869] [00:28:28/00:27:03, 0.684s/it]: train_loss_raw=1.8383, running_loss=1.8499, LR=0.000100
[2025-08-26 02:29:54,163][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017112] [Batch 02505/04869] [00:28:34/00:26:58, 0.684s/it]: train_loss_raw=1.8734, running_loss=1.8512, LR=0.000100
[2025-08-26 02:29:59,723][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017120] [Batch 02513/04869] [00:28:40/00:26:52, 0.684s/it]: train_loss_raw=1.8256, running_loss=1.8478, LR=0.000100
[2025-08-26 02:30:04,934][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017128] [Batch 02521/04869] [00:28:45/00:26:46, 0.684s/it]: train_loss_raw=1.7576, running_loss=1.8468, LR=0.000100
[2025-08-26 02:30:10,119][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017136] [Batch 02529/04869] [00:28:50/00:26:41, 0.684s/it]: train_loss_raw=1.6868, running_loss=1.8450, LR=0.000100
[2025-08-26 02:30:15,330][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017144] [Batch 02537/04869] [00:28:55/00:26:35, 0.684s/it]: train_loss_raw=1.8292, running_loss=1.8443, LR=0.000100
[2025-08-26 02:30:20,811][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017152] [Batch 02545/04869] [00:29:01/00:26:30, 0.684s/it]: train_loss_raw=1.9319, running_loss=1.8446, LR=0.000100
[2025-08-26 02:30:26,066][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017160] [Batch 02553/04869] [00:29:06/00:26:24, 0.684s/it]: train_loss_raw=1.8288, running_loss=1.8453, LR=0.000100
[2025-08-26 02:30:31,254][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017168] [Batch 02561/04869] [00:29:11/00:26:18, 0.684s/it]: train_loss_raw=1.6947, running_loss=1.8446, LR=0.000100
[2025-08-26 02:30:36,460][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017176] [Batch 02569/04869] [00:29:16/00:26:12, 0.684s/it]: train_loss_raw=1.8815, running_loss=1.8459, LR=0.000100
[2025-08-26 02:30:41,739][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017184] [Batch 02577/04869] [00:29:22/00:26:07, 0.684s/it]: train_loss_raw=1.7579, running_loss=1.8437, LR=0.000100
[2025-08-26 02:30:47,008][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017192] [Batch 02585/04869] [00:29:27/00:26:01, 0.684s/it]: train_loss_raw=1.8148, running_loss=1.8438, LR=0.000100
[2025-08-26 02:30:52,650][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017200] [Batch 02593/04869] [00:29:33/00:25:56, 0.684s/it]: train_loss_raw=1.8751, running_loss=1.8429, LR=0.000100
[2025-08-26 02:30:58,093][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017208] [Batch 02601/04869] [00:29:38/00:25:50, 0.684s/it]: train_loss_raw=1.7757, running_loss=1.8395, LR=0.000100
[2025-08-26 02:31:03,847][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017216] [Batch 02609/04869] [00:29:44/00:25:45, 0.684s/it]: train_loss_raw=1.7673, running_loss=1.8378, LR=0.000100
[2025-08-26 02:31:09,955][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017224] [Batch 02617/04869] [00:29:50/00:25:40, 0.684s/it]: train_loss_raw=1.7405, running_loss=1.8382, LR=0.000100
[2025-08-26 02:31:15,253][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017232] [Batch 02625/04869] [00:29:55/00:25:35, 0.684s/it]: train_loss_raw=1.8505, running_loss=1.8365, LR=0.000100
[2025-08-26 02:31:20,515][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017240] [Batch 02633/04869] [00:30:00/00:25:29, 0.684s/it]: train_loss_raw=1.7147, running_loss=1.8363, LR=0.000100
[2025-08-26 02:31:25,867][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017248] [Batch 02641/04869] [00:30:06/00:25:23, 0.684s/it]: train_loss_raw=1.8654, running_loss=1.8371, LR=0.000100
[2025-08-26 02:31:31,318][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017256] [Batch 02649/04869] [00:30:11/00:25:18, 0.684s/it]: train_loss_raw=1.8371, running_loss=1.8368, LR=0.000100
[2025-08-26 02:31:36,553][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017264] [Batch 02657/04869] [00:30:16/00:25:12, 0.684s/it]: train_loss_raw=1.8420, running_loss=1.8343, LR=0.000100
[2025-08-26 02:31:41,843][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017272] [Batch 02665/04869] [00:30:22/00:25:07, 0.684s/it]: train_loss_raw=1.7680, running_loss=1.8335, LR=0.000100
[2025-08-26 02:31:47,096][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017280] [Batch 02673/04869] [00:30:27/00:25:01, 0.684s/it]: train_loss_raw=1.8808, running_loss=1.8347, LR=0.000100
[2025-08-26 02:31:52,340][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017288] [Batch 02681/04869] [00:30:32/00:24:55, 0.684s/it]: train_loss_raw=1.8517, running_loss=1.8343, LR=0.000100
[2025-08-26 02:31:57,588][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017296] [Batch 02689/04869] [00:30:37/00:24:50, 0.684s/it]: train_loss_raw=1.8100, running_loss=1.8340, LR=0.000100
[2025-08-26 02:32:02,872][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017304] [Batch 02697/04869] [00:30:43/00:24:44, 0.683s/it]: train_loss_raw=1.9180, running_loss=1.8356, LR=0.000100
[2025-08-26 02:32:08,790][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017312] [Batch 02705/04869] [00:30:49/00:24:39, 0.684s/it]: train_loss_raw=1.8024, running_loss=1.8324, LR=0.000100
[2025-08-26 02:32:14,306][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017320] [Batch 02713/04869] [00:30:54/00:24:33, 0.684s/it]: train_loss_raw=1.8721, running_loss=1.8312, LR=0.000100
[2025-08-26 02:32:19,660][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017328] [Batch 02721/04869] [00:31:00/00:24:28, 0.684s/it]: train_loss_raw=1.7502, running_loss=1.8324, LR=0.000100
[2025-08-26 02:32:25,239][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017336] [Batch 02729/04869] [00:31:05/00:24:22, 0.684s/it]: train_loss_raw=1.8814, running_loss=1.8328, LR=0.000100
[2025-08-26 02:32:30,509][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017344] [Batch 02737/04869] [00:31:10/00:24:17, 0.684s/it]: train_loss_raw=1.8574, running_loss=1.8329, LR=0.000100
[2025-08-26 02:32:36,419][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017352] [Batch 02745/04869] [00:31:16/00:24:12, 0.684s/it]: train_loss_raw=1.8860, running_loss=1.8319, LR=0.000100
[2025-08-26 02:32:42,732][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017360] [Batch 02753/04869] [00:31:23/00:24:07, 0.684s/it]: train_loss_raw=1.8560, running_loss=1.8314, LR=0.000100
[2025-08-26 02:32:48,198][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017368] [Batch 02761/04869] [00:31:28/00:24:01, 0.684s/it]: train_loss_raw=1.7524, running_loss=1.8291, LR=0.000100
[2025-08-26 02:32:53,430][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017376] [Batch 02769/04869] [00:31:33/00:23:56, 0.684s/it]: train_loss_raw=1.8817, running_loss=1.8279, LR=0.000100
[2025-08-26 02:32:58,658][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017384] [Batch 02777/04869] [00:31:39/00:23:50, 0.684s/it]: train_loss_raw=1.8827, running_loss=1.8295, LR=0.000100
[2025-08-26 02:33:03,874][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017392] [Batch 02785/04869] [00:31:44/00:23:44, 0.684s/it]: train_loss_raw=1.7905, running_loss=1.8296, LR=0.000100
[2025-08-26 02:33:09,092][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017400] [Batch 02793/04869] [00:31:49/00:23:39, 0.684s/it]: train_loss_raw=1.8878, running_loss=1.8309, LR=0.000100
[2025-08-26 02:33:14,395][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017408] [Batch 02801/04869] [00:31:54/00:23:33, 0.684s/it]: train_loss_raw=1.7701, running_loss=1.8302, LR=0.000100
[2025-08-26 02:33:20,002][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017416] [Batch 02809/04869] [00:32:00/00:23:28, 0.684s/it]: train_loss_raw=1.8420, running_loss=1.8283, LR=0.000100
[2025-08-26 02:33:25,840][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017424] [Batch 02817/04869] [00:32:06/00:23:23, 0.684s/it]: train_loss_raw=1.9774, running_loss=1.8301, LR=0.000100
[2025-08-26 02:33:31,627][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017432] [Batch 02825/04869] [00:32:12/00:23:17, 0.684s/it]: train_loss_raw=1.8049, running_loss=1.8291, LR=0.000100
[2025-08-26 02:33:37,067][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017440] [Batch 02833/04869] [00:32:17/00:23:12, 0.684s/it]: train_loss_raw=1.9440, running_loss=1.8275, LR=0.000100
[2025-08-26 02:33:42,278][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017448] [Batch 02841/04869] [00:32:22/00:23:06, 0.684s/it]: train_loss_raw=1.7577, running_loss=1.8284, LR=0.000100
[2025-08-26 02:33:47,491][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017456] [Batch 02849/04869] [00:32:27/00:23:01, 0.684s/it]: train_loss_raw=1.7618, running_loss=1.8253, LR=0.000100
[2025-08-26 02:33:52,925][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017464] [Batch 02857/04869] [00:32:33/00:22:55, 0.684s/it]: train_loss_raw=1.7678, running_loss=1.8255, LR=0.000100
[2025-08-26 02:33:58,143][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017472] [Batch 02865/04869] [00:32:38/00:22:49, 0.684s/it]: train_loss_raw=1.8828, running_loss=1.8254, LR=0.000100
[2025-08-26 02:34:04,002][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017480] [Batch 02873/04869] [00:32:44/00:22:44, 0.684s/it]: train_loss_raw=1.7373, running_loss=1.8239, LR=0.000100
[2025-08-26 02:34:09,400][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017488] [Batch 02881/04869] [00:32:49/00:22:39, 0.684s/it]: train_loss_raw=1.8396, running_loss=1.8257, LR=0.000100
[2025-08-26 02:34:14,616][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017496] [Batch 02889/04869] [00:32:55/00:22:33, 0.684s/it]: train_loss_raw=1.8806, running_loss=1.8250, LR=0.000100
[2025-08-26 02:34:20,230][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017504] [Batch 02897/04869] [00:33:00/00:22:28, 0.684s/it]: train_loss_raw=1.8589, running_loss=1.8246, LR=0.000100
[2025-08-26 02:34:25,573][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017512] [Batch 02905/04869] [00:33:05/00:22:22, 0.684s/it]: train_loss_raw=1.7814, running_loss=1.8242, LR=0.000100
[2025-08-26 02:34:30,782][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017520] [Batch 02913/04869] [00:33:11/00:22:17, 0.684s/it]: train_loss_raw=1.9082, running_loss=1.8259, LR=0.000100
[2025-08-26 02:34:36,006][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017528] [Batch 02921/04869] [00:33:16/00:22:11, 0.683s/it]: train_loss_raw=1.8113, running_loss=1.8261, LR=0.000100
[2025-08-26 02:34:41,233][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017536] [Batch 02929/04869] [00:33:21/00:22:05, 0.683s/it]: train_loss_raw=1.8969, running_loss=1.8264, LR=0.000100
[2025-08-26 02:34:46,473][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017544] [Batch 02937/04869] [00:33:26/00:22:00, 0.683s/it]: train_loss_raw=1.8911, running_loss=1.8267, LR=0.000100
[2025-08-26 02:34:51,728][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017552] [Batch 02945/04869] [00:33:32/00:21:54, 0.683s/it]: train_loss_raw=1.8281, running_loss=1.8278, LR=0.000100
[2025-08-26 02:34:56,950][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017560] [Batch 02953/04869] [00:33:37/00:21:48, 0.683s/it]: train_loss_raw=1.8424, running_loss=1.8290, LR=0.000100
[2025-08-26 02:35:02,168][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017568] [Batch 02961/04869] [00:33:42/00:21:43, 0.683s/it]: train_loss_raw=1.8968, running_loss=1.8290, LR=0.000100
[2025-08-26 02:35:07,657][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017576] [Batch 02969/04869] [00:33:48/00:21:37, 0.683s/it]: train_loss_raw=1.7034, running_loss=1.8285, LR=0.000100
[2025-08-26 02:35:12,864][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017584] [Batch 02977/04869] [00:33:53/00:21:32, 0.683s/it]: train_loss_raw=1.7225, running_loss=1.8262, LR=0.000100
[2025-08-26 02:35:18,127][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017592] [Batch 02985/04869] [00:33:58/00:21:26, 0.683s/it]: train_loss_raw=1.8963, running_loss=1.8251, LR=0.000100
[2025-08-26 02:35:23,765][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017600] [Batch 02993/04869] [00:34:04/00:21:21, 0.683s/it]: train_loss_raw=1.8286, running_loss=1.8263, LR=0.000100
[2025-08-26 02:35:29,866][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017608] [Batch 03001/04869] [00:34:10/00:21:16, 0.683s/it]: train_loss_raw=1.8625, running_loss=1.8267, LR=0.000100
[2025-08-26 02:35:35,731][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017616] [Batch 03009/04869] [00:34:16/00:21:10, 0.683s/it]: train_loss_raw=1.8333, running_loss=1.8275, LR=0.000100
[2025-08-26 02:35:41,419][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017624] [Batch 03017/04869] [00:34:21/00:21:05, 0.683s/it]: train_loss_raw=1.7660, running_loss=1.8236, LR=0.000100
[2025-08-26 02:35:46,650][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017632] [Batch 03025/04869] [00:34:27/00:21:00, 0.683s/it]: train_loss_raw=1.7820, running_loss=1.8254, LR=0.000100
[2025-08-26 02:35:52,236][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017640] [Batch 03033/04869] [00:34:32/00:20:54, 0.683s/it]: train_loss_raw=1.9117, running_loss=1.8251, LR=0.000100
[2025-08-26 02:35:57,943][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017648] [Batch 03041/04869] [00:34:38/00:20:49, 0.683s/it]: train_loss_raw=1.7206, running_loss=1.8264, LR=0.000100
[2025-08-26 02:36:03,428][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017656] [Batch 03049/04869] [00:34:43/00:20:43, 0.683s/it]: train_loss_raw=1.8128, running_loss=1.8257, LR=0.000100
[2025-08-26 02:36:09,511][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017664] [Batch 03057/04869] [00:34:49/00:20:38, 0.684s/it]: train_loss_raw=1.8556, running_loss=1.8250, LR=0.000100
[2025-08-26 02:36:14,844][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017672] [Batch 03065/04869] [00:34:55/00:20:33, 0.684s/it]: train_loss_raw=1.8711, running_loss=1.8253, LR=0.000100
[2025-08-26 02:36:20,596][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017680] [Batch 03073/04869] [00:35:00/00:20:27, 0.684s/it]: train_loss_raw=1.7812, running_loss=1.8210, LR=0.000100
[2025-08-26 02:36:25,862][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017688] [Batch 03081/04869] [00:35:06/00:20:22, 0.684s/it]: train_loss_raw=1.7590, running_loss=1.8199, LR=0.000100
[2025-08-26 02:36:31,976][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017696] [Batch 03089/04869] [00:35:12/00:20:17, 0.684s/it]: train_loss_raw=1.8137, running_loss=1.8214, LR=0.000100
[2025-08-26 02:36:37,594][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017704] [Batch 03097/04869] [00:35:17/00:20:11, 0.684s/it]: train_loss_raw=1.8225, running_loss=1.8208, LR=0.000100
[2025-08-26 02:36:43,066][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017712] [Batch 03105/04869] [00:35:23/00:20:06, 0.684s/it]: train_loss_raw=1.7514, running_loss=1.8229, LR=0.000100
[2025-08-26 02:36:48,860][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017720] [Batch 03113/04869] [00:35:29/00:20:01, 0.684s/it]: train_loss_raw=1.8118, running_loss=1.8226, LR=0.000100
[2025-08-26 02:36:54,187][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017728] [Batch 03121/04869] [00:35:34/00:19:55, 0.684s/it]: train_loss_raw=1.8107, running_loss=1.8195, LR=0.000100
[2025-08-26 02:36:59,468][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017736] [Batch 03129/04869] [00:35:39/00:19:49, 0.684s/it]: train_loss_raw=1.8339, running_loss=1.8205, LR=0.000100
[2025-08-26 02:37:04,921][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017744] [Batch 03137/04869] [00:35:45/00:19:44, 0.684s/it]: train_loss_raw=1.8230, running_loss=1.8178, LR=0.000100
[2025-08-26 02:37:10,181][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017752] [Batch 03145/04869] [00:35:50/00:19:38, 0.684s/it]: train_loss_raw=1.7279, running_loss=1.8181, LR=0.000100
[2025-08-26 02:37:15,460][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017760] [Batch 03153/04869] [00:35:55/00:19:33, 0.684s/it]: train_loss_raw=1.7836, running_loss=1.8178, LR=0.000100
[2025-08-26 02:37:20,878][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017768] [Batch 03161/04869] [00:36:01/00:19:27, 0.684s/it]: train_loss_raw=1.7550, running_loss=1.8184, LR=0.000100
[2025-08-26 02:37:26,064][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017776] [Batch 03169/04869] [00:36:06/00:19:22, 0.684s/it]: train_loss_raw=1.8913, running_loss=1.8203, LR=0.000100
[2025-08-26 02:37:31,308][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017784] [Batch 03177/04869] [00:36:11/00:19:16, 0.684s/it]: train_loss_raw=1.7774, running_loss=1.8192, LR=0.000100
[2025-08-26 02:37:36,809][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017792] [Batch 03185/04869] [00:36:17/00:19:11, 0.684s/it]: train_loss_raw=1.9007, running_loss=1.8220, LR=0.000100
[2025-08-26 02:37:42,043][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017800] [Batch 03193/04869] [00:36:22/00:19:05, 0.684s/it]: train_loss_raw=1.8356, running_loss=1.8230, LR=0.000100
[2025-08-26 02:37:47,533][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017808] [Batch 03201/04869] [00:36:27/00:19:00, 0.684s/it]: train_loss_raw=1.8139, running_loss=1.8218, LR=0.000100
[2025-08-26 02:37:52,729][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017816] [Batch 03209/04869] [00:36:33/00:18:54, 0.683s/it]: train_loss_raw=1.7000, running_loss=1.8186, LR=0.000100
[2025-08-26 02:37:57,919][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017824] [Batch 03217/04869] [00:36:38/00:18:48, 0.683s/it]: train_loss_raw=1.8549, running_loss=1.8194, LR=0.000100
[2025-08-26 02:38:03,543][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017832] [Batch 03225/04869] [00:36:43/00:18:43, 0.683s/it]: train_loss_raw=1.8883, running_loss=1.8188, LR=0.000100
[2025-08-26 02:38:09,333][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017840] [Batch 03233/04869] [00:36:49/00:18:38, 0.683s/it]: train_loss_raw=1.8260, running_loss=1.8182, LR=0.000100
[2025-08-26 02:38:15,182][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017848] [Batch 03241/04869] [00:36:55/00:18:32, 0.684s/it]: train_loss_raw=1.9193, running_loss=1.8191, LR=0.000100
[2025-08-26 02:38:20,422][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017856] [Batch 03249/04869] [00:37:00/00:18:27, 0.684s/it]: train_loss_raw=1.7476, running_loss=1.8183, LR=0.000100
[2025-08-26 02:38:26,005][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017864] [Batch 03257/04869] [00:37:06/00:18:21, 0.684s/it]: train_loss_raw=1.8064, running_loss=1.8194, LR=0.000100
[2025-08-26 02:38:31,184][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017872] [Batch 03265/04869] [00:37:11/00:18:16, 0.683s/it]: train_loss_raw=1.7658, running_loss=1.8209, LR=0.000100
[2025-08-26 02:38:36,396][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017880] [Batch 03273/04869] [00:37:16/00:18:10, 0.683s/it]: train_loss_raw=1.8432, running_loss=1.8201, LR=0.000100
[2025-08-26 02:38:42,234][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017888] [Batch 03281/04869] [00:37:22/00:18:05, 0.684s/it]: train_loss_raw=1.8562, running_loss=1.8216, LR=0.000100
[2025-08-26 02:38:47,703][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017896] [Batch 03289/04869] [00:37:28/00:17:59, 0.684s/it]: train_loss_raw=1.8701, running_loss=1.8214, LR=0.000100
[2025-08-26 02:38:52,885][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017904] [Batch 03297/04869] [00:37:33/00:17:54, 0.683s/it]: train_loss_raw=1.9265, running_loss=1.8234, LR=0.000100
[2025-08-26 02:38:58,063][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017912] [Batch 03305/04869] [00:37:38/00:17:48, 0.683s/it]: train_loss_raw=1.9005, running_loss=1.8241, LR=0.000100
[2025-08-26 02:39:03,393][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017920] [Batch 03313/04869] [00:37:43/00:17:43, 0.683s/it]: train_loss_raw=1.8434, running_loss=1.8232, LR=0.000100
[2025-08-26 02:39:09,071][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017928] [Batch 03321/04869] [00:37:49/00:17:37, 0.683s/it]: train_loss_raw=1.9184, running_loss=1.8239, LR=0.000100
[2025-08-26 02:39:14,323][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017936] [Batch 03329/04869] [00:37:54/00:17:32, 0.683s/it]: train_loss_raw=1.8869, running_loss=1.8255, LR=0.000100
[2025-08-26 02:39:19,863][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017944] [Batch 03337/04869] [00:38:00/00:17:26, 0.683s/it]: train_loss_raw=1.8021, running_loss=1.8237, LR=0.000100
[2025-08-26 02:39:25,562][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017952] [Batch 03345/04869] [00:38:05/00:17:21, 0.683s/it]: train_loss_raw=1.8400, running_loss=1.8238, LR=0.000100
[2025-08-26 02:39:31,131][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017960] [Batch 03353/04869] [00:38:11/00:17:16, 0.683s/it]: train_loss_raw=1.7358, running_loss=1.8213, LR=0.000100
[2025-08-26 02:39:36,728][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017968] [Batch 03361/04869] [00:38:17/00:17:10, 0.683s/it]: train_loss_raw=1.7974, running_loss=1.8208, LR=0.000100
[2025-08-26 02:39:42,019][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017976] [Batch 03369/04869] [00:38:22/00:17:05, 0.683s/it]: train_loss_raw=1.8294, running_loss=1.8199, LR=0.000100
[2025-08-26 02:39:47,541][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017984] [Batch 03377/04869] [00:38:27/00:16:59, 0.683s/it]: train_loss_raw=1.8725, running_loss=1.8196, LR=0.000100
[2025-08-26 02:39:53,358][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 017992] [Batch 03385/04869] [00:38:33/00:16:54, 0.684s/it]: train_loss_raw=1.8813, running_loss=1.8185, LR=0.000100
[2025-08-26 02:39:58,626][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018000] [Batch 03393/04869] [00:38:39/00:16:48, 0.683s/it]: train_loss_raw=1.8436, running_loss=1.8199, LR=0.000100
[2025-08-26 02:40:08,039][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018008] [Batch 03401/04869] [00:38:48/00:16:45, 0.685s/it]: train_loss_raw=1.7998, running_loss=1.8165, LR=0.000100
[2025-08-26 02:40:13,299][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018016] [Batch 03409/04869] [00:38:53/00:16:39, 0.685s/it]: train_loss_raw=1.7248, running_loss=1.8179, LR=0.000100
[2025-08-26 02:40:18,547][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018024] [Batch 03417/04869] [00:38:58/00:16:33, 0.685s/it]: train_loss_raw=1.8268, running_loss=1.8174, LR=0.000100
[2025-08-26 02:40:24,020][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018032] [Batch 03425/04869] [00:39:04/00:16:28, 0.685s/it]: train_loss_raw=1.9011, running_loss=1.8178, LR=0.000100
[2025-08-26 02:40:29,689][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018040] [Batch 03433/04869] [00:39:10/00:16:23, 0.685s/it]: train_loss_raw=1.8443, running_loss=1.8182, LR=0.000100
[2025-08-26 02:40:35,541][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018048] [Batch 03441/04869] [00:39:15/00:16:17, 0.685s/it]: train_loss_raw=1.8679, running_loss=1.8173, LR=0.000100
[2025-08-26 02:40:41,089][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018056] [Batch 03449/04869] [00:39:21/00:16:12, 0.685s/it]: train_loss_raw=1.8446, running_loss=1.8140, LR=0.000100
[2025-08-26 02:40:46,277][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018064] [Batch 03457/04869] [00:39:26/00:16:06, 0.685s/it]: train_loss_raw=1.8097, running_loss=1.8129, LR=0.000100
[2025-08-26 02:40:51,518][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018072] [Batch 03465/04869] [00:39:31/00:16:01, 0.685s/it]: train_loss_raw=1.7963, running_loss=1.8121, LR=0.000100
[2025-08-26 02:40:56,727][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018080] [Batch 03473/04869] [00:39:37/00:15:55, 0.684s/it]: train_loss_raw=1.7634, running_loss=1.8131, LR=0.000100
[2025-08-26 02:41:02,198][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018088] [Batch 03481/04869] [00:39:42/00:15:50, 0.684s/it]: train_loss_raw=1.7551, running_loss=1.8110, LR=0.000100
[2025-08-26 02:41:08,055][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018096] [Batch 03489/04869] [00:39:48/00:15:44, 0.685s/it]: train_loss_raw=1.8811, running_loss=1.8113, LR=0.000100
[2025-08-26 02:41:13,993][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018104] [Batch 03497/04869] [00:39:54/00:15:39, 0.685s/it]: train_loss_raw=1.8218, running_loss=1.8115, LR=0.000100
[2025-08-26 02:41:19,780][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018112] [Batch 03505/04869] [00:40:00/00:15:34, 0.685s/it]: train_loss_raw=1.7308, running_loss=1.8100, LR=0.000100
[2025-08-26 02:41:25,276][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018120] [Batch 03513/04869] [00:40:05/00:15:28, 0.685s/it]: train_loss_raw=1.8670, running_loss=1.8122, LR=0.000100
[2025-08-26 02:41:30,621][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018128] [Batch 03521/04869] [00:40:11/00:15:23, 0.685s/it]: train_loss_raw=1.8323, running_loss=1.8126, LR=0.000100
[2025-08-26 02:41:35,795][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018136] [Batch 03529/04869] [00:40:16/00:15:17, 0.685s/it]: train_loss_raw=1.6839, running_loss=1.8100, LR=0.000100
[2025-08-26 02:41:41,087][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018144] [Batch 03537/04869] [00:40:21/00:15:11, 0.685s/it]: train_loss_raw=1.7764, running_loss=1.8107, LR=0.000100
[2025-08-26 02:41:46,980][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018152] [Batch 03545/04869] [00:40:27/00:15:06, 0.685s/it]: train_loss_raw=1.6940, running_loss=1.8115, LR=0.000100
[2025-08-26 02:41:52,476][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018160] [Batch 03553/04869] [00:40:32/00:15:01, 0.685s/it]: train_loss_raw=1.7735, running_loss=1.8126, LR=0.000100
[2025-08-26 02:41:57,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018168] [Batch 03561/04869] [00:40:38/00:14:55, 0.685s/it]: train_loss_raw=1.9186, running_loss=1.8120, LR=0.000100
[2025-08-26 02:42:03,570][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018176] [Batch 03569/04869] [00:40:43/00:14:50, 0.685s/it]: train_loss_raw=1.7698, running_loss=1.8117, LR=0.000100
[2025-08-26 02:42:08,754][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018184] [Batch 03577/04869] [00:40:49/00:14:44, 0.685s/it]: train_loss_raw=1.8602, running_loss=1.8131, LR=0.000100
[2025-08-26 02:42:14,951][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018192] [Batch 03585/04869] [00:40:55/00:14:39, 0.685s/it]: train_loss_raw=1.7077, running_loss=1.8110, LR=0.000100
[2025-08-26 02:42:20,894][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018200] [Batch 03593/04869] [00:41:01/00:14:34, 0.685s/it]: train_loss_raw=1.8203, running_loss=1.8103, LR=0.000100
[2025-08-26 02:42:26,462][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018208] [Batch 03601/04869] [00:41:06/00:14:28, 0.685s/it]: train_loss_raw=1.8288, running_loss=1.8096, LR=0.000100
[2025-08-26 02:42:31,778][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018216] [Batch 03609/04869] [00:41:12/00:14:23, 0.685s/it]: train_loss_raw=1.8197, running_loss=1.8077, LR=0.000100
[2025-08-26 02:42:37,446][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018224] [Batch 03617/04869] [00:41:17/00:14:17, 0.685s/it]: train_loss_raw=1.8502, running_loss=1.8097, LR=0.000100
[2025-08-26 02:42:42,658][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018232] [Batch 03625/04869] [00:41:23/00:14:12, 0.685s/it]: train_loss_raw=1.7986, running_loss=1.8097, LR=0.000100
[2025-08-26 02:42:47,935][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018240] [Batch 03633/04869] [00:41:28/00:14:06, 0.685s/it]: train_loss_raw=1.7737, running_loss=1.8103, LR=0.000100
[2025-08-26 02:42:53,122][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018248] [Batch 03641/04869] [00:41:33/00:14:00, 0.685s/it]: train_loss_raw=1.8924, running_loss=1.8130, LR=0.000100
[2025-08-26 02:42:58,703][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018256] [Batch 03649/04869] [00:41:39/00:13:55, 0.685s/it]: train_loss_raw=1.7800, running_loss=1.8119, LR=0.000100
[2025-08-26 02:43:03,883][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018264] [Batch 03657/04869] [00:41:44/00:13:49, 0.685s/it]: train_loss_raw=1.8465, running_loss=1.8128, LR=0.000100
[2025-08-26 02:43:09,379][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018272] [Batch 03665/04869] [00:41:49/00:13:44, 0.685s/it]: train_loss_raw=1.6793, running_loss=1.8114, LR=0.000100
[2025-08-26 02:43:14,879][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018280] [Batch 03673/04869] [00:41:55/00:13:39, 0.685s/it]: train_loss_raw=1.8289, running_loss=1.8096, LR=0.000100
[2025-08-26 02:43:20,033][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018288] [Batch 03681/04869] [00:42:00/00:13:33, 0.685s/it]: train_loss_raw=1.8206, running_loss=1.8087, LR=0.000100
[2025-08-26 02:43:25,227][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018296] [Batch 03689/04869] [00:42:05/00:13:27, 0.685s/it]: train_loss_raw=1.8707, running_loss=1.8076, LR=0.000100
[2025-08-26 02:43:30,695][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018304] [Batch 03697/04869] [00:42:11/00:13:22, 0.685s/it]: train_loss_raw=1.7860, running_loss=1.8055, LR=0.000100
[2025-08-26 02:43:36,760][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018312] [Batch 03705/04869] [00:42:17/00:13:17, 0.685s/it]: train_loss_raw=1.8214, running_loss=1.8054, LR=0.000100
[2025-08-26 02:43:42,648][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018320] [Batch 03713/04869] [00:42:23/00:13:11, 0.685s/it]: train_loss_raw=1.8592, running_loss=1.8076, LR=0.000100
[2025-08-26 02:43:48,020][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018328] [Batch 03721/04869] [00:42:28/00:13:06, 0.685s/it]: train_loss_raw=1.8351, running_loss=1.8068, LR=0.000100
[2025-08-26 02:43:53,718][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018336] [Batch 03729/04869] [00:42:34/00:13:00, 0.685s/it]: train_loss_raw=1.7458, running_loss=1.8038, LR=0.000100
[2025-08-26 02:43:59,980][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018344] [Batch 03737/04869] [00:42:40/00:12:55, 0.685s/it]: train_loss_raw=1.7553, running_loss=1.8043, LR=0.000100
[2025-08-26 02:44:05,894][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018352] [Batch 03745/04869] [00:42:46/00:12:50, 0.685s/it]: train_loss_raw=1.8686, running_loss=1.8047, LR=0.000100
[2025-08-26 02:44:11,179][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018360] [Batch 03753/04869] [00:42:51/00:12:44, 0.685s/it]: train_loss_raw=1.7229, running_loss=1.8044, LR=0.000100
[2025-08-26 02:44:17,431][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018368] [Batch 03761/04869] [00:42:57/00:12:39, 0.685s/it]: train_loss_raw=1.8179, running_loss=1.8046, LR=0.000100
[2025-08-26 02:44:23,635][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018376] [Batch 03769/04869] [00:43:04/00:12:34, 0.686s/it]: train_loss_raw=1.8094, running_loss=1.8028, LR=0.000100
[2025-08-26 02:44:29,390][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018384] [Batch 03777/04869] [00:43:09/00:12:28, 0.686s/it]: train_loss_raw=1.7940, running_loss=1.8008, LR=0.000100
[2025-08-26 02:44:35,057][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018392] [Batch 03785/04869] [00:43:15/00:12:23, 0.686s/it]: train_loss_raw=1.7847, running_loss=1.8008, LR=0.000100
[2025-08-26 02:44:40,291][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018400] [Batch 03793/04869] [00:43:20/00:12:17, 0.686s/it]: train_loss_raw=1.7916, running_loss=1.8027, LR=0.000100
[2025-08-26 02:44:45,896][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018408] [Batch 03801/04869] [00:43:26/00:12:12, 0.686s/it]: train_loss_raw=1.7725, running_loss=1.8009, LR=0.000100
[2025-08-26 02:44:51,443][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018416] [Batch 03809/04869] [00:43:31/00:12:06, 0.686s/it]: train_loss_raw=1.7505, running_loss=1.8018, LR=0.000100
[2025-08-26 02:44:56,732][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018424] [Batch 03817/04869] [00:43:37/00:12:01, 0.686s/it]: train_loss_raw=1.7925, running_loss=1.8035, LR=0.000100
[2025-08-26 02:45:02,308][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018432] [Batch 03825/04869] [00:43:42/00:11:55, 0.686s/it]: train_loss_raw=1.8325, running_loss=1.8029, LR=0.000100
[2025-08-26 02:45:07,816][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018440] [Batch 03833/04869] [00:43:48/00:11:50, 0.686s/it]: train_loss_raw=1.7340, running_loss=1.8037, LR=0.000100
[2025-08-26 02:45:13,028][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018448] [Batch 03841/04869] [00:43:53/00:11:44, 0.686s/it]: train_loss_raw=1.7705, running_loss=1.8033, LR=0.000100
[2025-08-26 02:45:18,380][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018456] [Batch 03849/04869] [00:43:58/00:11:39, 0.686s/it]: train_loss_raw=1.7812, running_loss=1.8018, LR=0.000100
[2025-08-26 02:45:30,460][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018464] [Batch 03857/04869] [00:44:10/00:11:35, 0.687s/it]: train_loss_raw=1.8558, running_loss=1.8021, LR=0.000100
[2025-08-26 02:45:35,933][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018472] [Batch 03865/04869] [00:44:16/00:11:30, 0.687s/it]: train_loss_raw=1.8063, running_loss=1.8000, LR=0.000100
[2025-08-26 02:45:41,319][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018480] [Batch 03873/04869] [00:44:21/00:11:24, 0.687s/it]: train_loss_raw=1.8524, running_loss=1.7989, LR=0.000100
[2025-08-26 02:45:46,581][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018488] [Batch 03881/04869] [00:44:26/00:11:18, 0.687s/it]: train_loss_raw=1.7082, running_loss=1.7977, LR=0.000100
[2025-08-26 02:45:51,975][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018496] [Batch 03889/04869] [00:44:32/00:11:13, 0.687s/it]: train_loss_raw=1.7915, running_loss=1.7971, LR=0.000100
[2025-08-26 02:45:57,148][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018504] [Batch 03897/04869] [00:44:37/00:11:07, 0.687s/it]: train_loss_raw=1.7425, running_loss=1.7963, LR=0.000100
[2025-08-26 02:46:02,326][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018512] [Batch 03905/04869] [00:44:42/00:11:02, 0.687s/it]: train_loss_raw=1.7272, running_loss=1.7970, LR=0.000100
[2025-08-26 02:46:07,687][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018520] [Batch 03913/04869] [00:44:48/00:10:56, 0.687s/it]: train_loss_raw=1.8307, running_loss=1.7982, LR=0.000100
[2025-08-26 02:46:13,208][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018528] [Batch 03921/04869] [00:44:53/00:10:51, 0.687s/it]: train_loss_raw=1.7891, running_loss=1.7973, LR=0.000100
[2025-08-26 02:46:18,515][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018536] [Batch 03929/04869] [00:44:58/00:10:45, 0.687s/it]: train_loss_raw=1.8615, running_loss=1.7984, LR=0.000100
[2025-08-26 02:46:24,225][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018544] [Batch 03937/04869] [00:45:04/00:10:40, 0.687s/it]: train_loss_raw=1.7565, running_loss=1.7969, LR=0.000100
[2025-08-26 02:46:29,702][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018552] [Batch 03945/04869] [00:45:10/00:10:34, 0.687s/it]: train_loss_raw=1.7822, running_loss=1.7954, LR=0.000100
[2025-08-26 02:46:34,979][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018560] [Batch 03953/04869] [00:45:15/00:10:29, 0.687s/it]: train_loss_raw=1.6821, running_loss=1.7935, LR=0.000100
[2025-08-26 02:46:40,563][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018568] [Batch 03961/04869] [00:45:20/00:10:23, 0.687s/it]: train_loss_raw=1.8566, running_loss=1.7941, LR=0.000100
[2025-08-26 02:46:46,689][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018576] [Batch 03969/04869] [00:45:27/00:10:18, 0.687s/it]: train_loss_raw=1.8532, running_loss=1.7967, LR=0.000100
[2025-08-26 02:46:52,555][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018584] [Batch 03977/04869] [00:45:32/00:10:12, 0.687s/it]: train_loss_raw=1.7563, running_loss=1.7962, LR=0.000100
[2025-08-26 02:46:57,869][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018592] [Batch 03985/04869] [00:45:38/00:10:07, 0.687s/it]: train_loss_raw=1.6518, running_loss=1.7972, LR=0.000100
[2025-08-26 02:47:03,202][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018600] [Batch 03993/04869] [00:45:43/00:10:01, 0.687s/it]: train_loss_raw=1.8153, running_loss=1.7974, LR=0.000100
[2025-08-26 02:47:08,496][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018608] [Batch 04001/04869] [00:45:48/00:09:56, 0.687s/it]: train_loss_raw=1.8389, running_loss=1.7957, LR=0.000100
[2025-08-26 02:47:13,792][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018616] [Batch 04009/04869] [00:45:54/00:09:50, 0.687s/it]: train_loss_raw=1.7033, running_loss=1.7910, LR=0.000100
[2025-08-26 02:47:19,610][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018624] [Batch 04017/04869] [00:46:00/00:09:45, 0.687s/it]: train_loss_raw=1.8615, running_loss=1.7938, LR=0.000100
[2025-08-26 02:47:25,150][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018632] [Batch 04025/04869] [00:46:05/00:09:39, 0.687s/it]: train_loss_raw=1.8643, running_loss=1.7973, LR=0.000100
[2025-08-26 02:47:30,333][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018640] [Batch 04033/04869] [00:46:10/00:09:34, 0.687s/it]: train_loss_raw=1.8530, running_loss=1.7979, LR=0.000100
[2025-08-26 02:47:35,847][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018648] [Batch 04041/04869] [00:46:16/00:09:28, 0.687s/it]: train_loss_raw=1.7452, running_loss=1.7984, LR=0.000100
[2025-08-26 02:47:41,217][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018656] [Batch 04049/04869] [00:46:21/00:09:23, 0.687s/it]: train_loss_raw=1.8312, running_loss=1.7984, LR=0.000100
[2025-08-26 02:47:46,597][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018664] [Batch 04057/04869] [00:46:26/00:09:17, 0.687s/it]: train_loss_raw=1.8188, running_loss=1.7981, LR=0.000100
[2025-08-26 02:47:51,788][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018672] [Batch 04065/04869] [00:46:32/00:09:12, 0.687s/it]: train_loss_raw=1.7615, running_loss=1.7987, LR=0.000100
[2025-08-26 02:47:57,407][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018680] [Batch 04073/04869] [00:46:37/00:09:06, 0.687s/it]: train_loss_raw=1.8341, running_loss=1.7976, LR=0.000100
[2025-08-26 02:48:02,663][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018688] [Batch 04081/04869] [00:46:43/00:09:01, 0.687s/it]: train_loss_raw=1.7763, running_loss=1.7984, LR=0.000100
[2025-08-26 02:48:08,396][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018696] [Batch 04089/04869] [00:46:48/00:08:55, 0.687s/it]: train_loss_raw=1.7061, running_loss=1.7987, LR=0.000100
[2025-08-26 02:48:13,920][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018704] [Batch 04097/04869] [00:46:54/00:08:50, 0.687s/it]: train_loss_raw=1.7405, running_loss=1.7973, LR=0.000100
[2025-08-26 02:48:19,381][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018712] [Batch 04105/04869] [00:46:59/00:08:44, 0.687s/it]: train_loss_raw=1.8033, running_loss=1.7973, LR=0.000100
[2025-08-26 02:48:24,595][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018720] [Batch 04113/04869] [00:47:04/00:08:39, 0.687s/it]: train_loss_raw=1.8016, running_loss=1.7950, LR=0.000100
[2025-08-26 02:48:30,145][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018728] [Batch 04121/04869] [00:47:10/00:08:33, 0.687s/it]: train_loss_raw=1.8332, running_loss=1.7965, LR=0.000100
[2025-08-26 02:48:35,371][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018736] [Batch 04129/04869] [00:47:15/00:08:28, 0.687s/it]: train_loss_raw=1.9054, running_loss=1.7934, LR=0.000100
[2025-08-26 02:48:41,224][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018744] [Batch 04137/04869] [00:47:21/00:08:22, 0.687s/it]: train_loss_raw=1.8699, running_loss=1.7951, LR=0.000100
[2025-08-26 02:48:46,454][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018752] [Batch 04145/04869] [00:47:26/00:08:17, 0.687s/it]: train_loss_raw=1.8469, running_loss=1.7975, LR=0.000100
[2025-08-26 02:48:52,027][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018760] [Batch 04153/04869] [00:47:32/00:08:11, 0.687s/it]: train_loss_raw=1.7904, running_loss=1.8006, LR=0.000100
[2025-08-26 02:48:57,344][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018768] [Batch 04161/04869] [00:47:37/00:08:06, 0.687s/it]: train_loss_raw=1.7891, running_loss=1.7992, LR=0.000100
[2025-08-26 02:49:03,224][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018776] [Batch 04169/04869] [00:47:43/00:08:00, 0.687s/it]: train_loss_raw=1.7937, running_loss=1.7988, LR=0.000100
[2025-08-26 02:49:08,752][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018784] [Batch 04177/04869] [00:47:49/00:07:55, 0.687s/it]: train_loss_raw=1.7907, running_loss=1.7993, LR=0.000100
[2025-08-26 02:49:14,091][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018792] [Batch 04185/04869] [00:47:54/00:07:49, 0.687s/it]: train_loss_raw=1.7481, running_loss=1.7985, LR=0.000100
[2025-08-26 02:49:19,989][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018800] [Batch 04193/04869] [00:48:00/00:07:44, 0.687s/it]: train_loss_raw=1.8004, running_loss=1.7962, LR=0.000100
[2025-08-26 02:49:25,393][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018808] [Batch 04201/04869] [00:48:05/00:07:38, 0.687s/it]: train_loss_raw=1.7585, running_loss=1.7953, LR=0.000100
[2025-08-26 02:49:31,185][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018816] [Batch 04209/04869] [00:48:11/00:07:33, 0.687s/it]: train_loss_raw=1.7041, running_loss=1.7944, LR=0.000100
[2025-08-26 02:49:36,790][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018824] [Batch 04217/04869] [00:48:17/00:07:27, 0.687s/it]: train_loss_raw=1.7772, running_loss=1.7946, LR=0.000100
[2025-08-26 02:49:42,090][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018832] [Batch 04225/04869] [00:48:22/00:07:22, 0.687s/it]: train_loss_raw=1.8733, running_loss=1.7937, LR=0.000100
[2025-08-26 02:49:47,633][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018840] [Batch 04233/04869] [00:48:28/00:07:16, 0.687s/it]: train_loss_raw=1.7861, running_loss=1.7929, LR=0.000100
[2025-08-26 02:49:53,035][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018848] [Batch 04241/04869] [00:48:33/00:07:11, 0.687s/it]: train_loss_raw=1.6348, running_loss=1.7893, LR=0.000100
[2025-08-26 02:49:58,436][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018856] [Batch 04249/04869] [00:48:38/00:07:05, 0.687s/it]: train_loss_raw=1.7655, running_loss=1.7883, LR=0.000100
[2025-08-26 02:50:03,651][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018864] [Batch 04257/04869] [00:48:44/00:07:00, 0.687s/it]: train_loss_raw=1.7883, running_loss=1.7859, LR=0.000100
[2025-08-26 02:50:08,859][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018872] [Batch 04265/04869] [00:48:49/00:06:54, 0.687s/it]: train_loss_raw=1.8687, running_loss=1.7891, LR=0.000100
[2025-08-26 02:50:14,472][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018880] [Batch 04273/04869] [00:48:54/00:06:49, 0.687s/it]: train_loss_raw=1.8533, running_loss=1.7892, LR=0.000100
[2025-08-26 02:50:20,069][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018888] [Batch 04281/04869] [00:49:00/00:06:43, 0.687s/it]: train_loss_raw=1.8414, running_loss=1.7899, LR=0.000100
[2025-08-26 02:50:25,525][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018896] [Batch 04289/04869] [00:49:05/00:06:38, 0.687s/it]: train_loss_raw=1.7737, running_loss=1.7898, LR=0.000100
[2025-08-26 02:50:31,286][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018904] [Batch 04297/04869] [00:49:11/00:06:32, 0.687s/it]: train_loss_raw=1.7874, running_loss=1.7922, LR=0.000100
[2025-08-26 02:50:37,101][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018912] [Batch 04305/04869] [00:49:17/00:06:27, 0.687s/it]: train_loss_raw=1.7931, running_loss=1.7912, LR=0.000100
[2025-08-26 02:50:42,523][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018920] [Batch 04313/04869] [00:49:22/00:06:21, 0.687s/it]: train_loss_raw=1.7091, running_loss=1.7911, LR=0.000100
[2025-08-26 02:50:48,079][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018928] [Batch 04321/04869] [00:49:28/00:06:16, 0.687s/it]: train_loss_raw=1.7684, running_loss=1.7883, LR=0.000100
[2025-08-26 02:50:53,789][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018936] [Batch 04329/04869] [00:49:34/00:06:11, 0.687s/it]: train_loss_raw=1.8237, running_loss=1.7880, LR=0.000100
[2025-08-26 02:50:58,988][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018944] [Batch 04337/04869] [00:49:39/00:06:05, 0.687s/it]: train_loss_raw=1.6725, running_loss=1.7866, LR=0.000100
[2025-08-26 02:51:04,211][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018952] [Batch 04345/04869] [00:49:44/00:05:59, 0.687s/it]: train_loss_raw=1.8389, running_loss=1.7866, LR=0.000100
[2025-08-26 02:51:09,499][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018960] [Batch 04353/04869] [00:49:49/00:05:54, 0.687s/it]: train_loss_raw=1.8289, running_loss=1.7873, LR=0.000100
[2025-08-26 02:51:14,708][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018968] [Batch 04361/04869] [00:49:55/00:05:48, 0.687s/it]: train_loss_raw=1.8711, running_loss=1.7877, LR=0.000100
[2025-08-26 02:51:19,936][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018976] [Batch 04369/04869] [00:50:00/00:05:43, 0.687s/it]: train_loss_raw=1.7634, running_loss=1.7864, LR=0.000100
[2025-08-26 02:51:25,151][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018984] [Batch 04377/04869] [00:50:05/00:05:37, 0.687s/it]: train_loss_raw=1.7358, running_loss=1.7878, LR=0.000100
[2025-08-26 02:51:30,671][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 018992] [Batch 04385/04869] [00:50:11/00:05:32, 0.687s/it]: train_loss_raw=1.8363, running_loss=1.7890, LR=0.000100
[2025-08-26 02:51:35,909][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019000] [Batch 04393/04869] [00:50:16/00:05:26, 0.687s/it]: train_loss_raw=1.6947, running_loss=1.7872, LR=0.000100
[2025-08-26 02:51:41,102][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019008] [Batch 04401/04869] [00:50:21/00:05:21, 0.687s/it]: train_loss_raw=1.7957, running_loss=1.7866, LR=0.000100
[2025-08-26 02:51:46,302][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019016] [Batch 04409/04869] [00:50:26/00:05:15, 0.686s/it]: train_loss_raw=1.8221, running_loss=1.7876, LR=0.000100
[2025-08-26 02:51:51,521][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019024] [Batch 04417/04869] [00:50:31/00:05:10, 0.686s/it]: train_loss_raw=1.7463, running_loss=1.7862, LR=0.000100
[2025-08-26 02:51:57,057][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019032] [Batch 04425/04869] [00:50:37/00:05:04, 0.686s/it]: train_loss_raw=1.7928, running_loss=1.7878, LR=0.000100
[2025-08-26 02:52:03,015][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019040] [Batch 04433/04869] [00:50:43/00:04:59, 0.687s/it]: train_loss_raw=1.7773, running_loss=1.7858, LR=0.000100
[2025-08-26 02:52:08,451][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019048] [Batch 04441/04869] [00:50:48/00:04:53, 0.687s/it]: train_loss_raw=1.7657, running_loss=1.7846, LR=0.000100
[2025-08-26 02:52:13,702][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019056] [Batch 04449/04869] [00:50:54/00:04:48, 0.686s/it]: train_loss_raw=1.7621, running_loss=1.7825, LR=0.000100
[2025-08-26 02:52:18,959][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019064] [Batch 04457/04869] [00:50:59/00:04:42, 0.686s/it]: train_loss_raw=1.7148, running_loss=1.7821, LR=0.000100
[2025-08-26 02:52:24,924][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019072] [Batch 04465/04869] [00:51:05/00:04:37, 0.687s/it]: train_loss_raw=1.7802, running_loss=1.7828, LR=0.000100
[2025-08-26 02:52:30,168][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019080] [Batch 04473/04869] [00:51:10/00:04:31, 0.686s/it]: train_loss_raw=1.7877, running_loss=1.7826, LR=0.000100
[2025-08-26 02:52:35,551][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019088] [Batch 04481/04869] [00:51:15/00:04:26, 0.686s/it]: train_loss_raw=1.7536, running_loss=1.7826, LR=0.000100
[2025-08-26 02:52:40,760][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019096] [Batch 04489/04869] [00:51:21/00:04:20, 0.686s/it]: train_loss_raw=1.6817, running_loss=1.7827, LR=0.000100
[2025-08-26 02:52:45,967][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019104] [Batch 04497/04869] [00:51:26/00:04:15, 0.686s/it]: train_loss_raw=1.8012, running_loss=1.7825, LR=0.000100
[2025-08-26 02:52:51,580][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019112] [Batch 04505/04869] [00:51:31/00:04:09, 0.686s/it]: train_loss_raw=1.7907, running_loss=1.7796, LR=0.000100
[2025-08-26 02:52:56,782][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019120] [Batch 04513/04869] [00:51:37/00:04:04, 0.686s/it]: train_loss_raw=1.7663, running_loss=1.7796, LR=0.000100
[2025-08-26 02:53:02,292][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019128] [Batch 04521/04869] [00:51:42/00:03:58, 0.686s/it]: train_loss_raw=1.7542, running_loss=1.7790, LR=0.000100
[2025-08-26 02:53:08,368][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019136] [Batch 04529/04869] [00:51:48/00:03:53, 0.686s/it]: train_loss_raw=1.7943, running_loss=1.7794, LR=0.000100
[2025-08-26 02:53:13,574][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019144] [Batch 04537/04869] [00:51:53/00:03:47, 0.686s/it]: train_loss_raw=1.7779, running_loss=1.7778, LR=0.000100
[2025-08-26 02:53:19,010][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019152] [Batch 04545/04869] [00:51:59/00:03:42, 0.686s/it]: train_loss_raw=1.8398, running_loss=1.7771, LR=0.000100
[2025-08-26 02:53:24,723][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019160] [Batch 04553/04869] [00:52:05/00:03:36, 0.686s/it]: train_loss_raw=1.7621, running_loss=1.7793, LR=0.000100
[2025-08-26 02:53:30,916][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019168] [Batch 04561/04869] [00:52:11/00:03:31, 0.687s/it]: train_loss_raw=1.8183, running_loss=1.7784, LR=0.000100
[2025-08-26 02:53:36,531][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019176] [Batch 04569/04869] [00:52:16/00:03:25, 0.687s/it]: train_loss_raw=1.7366, running_loss=1.7767, LR=0.000100
[2025-08-26 02:53:41,888][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019184] [Batch 04577/04869] [00:52:22/00:03:20, 0.687s/it]: train_loss_raw=1.8012, running_loss=1.7760, LR=0.000100
[2025-08-26 02:53:47,407][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019192] [Batch 04585/04869] [00:52:27/00:03:14, 0.687s/it]: train_loss_raw=1.7578, running_loss=1.7754, LR=0.000100
[2025-08-26 02:53:52,780][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019200] [Batch 04593/04869] [00:52:33/00:03:09, 0.687s/it]: train_loss_raw=1.7279, running_loss=1.7775, LR=0.000100
[2025-08-26 02:53:58,135][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019208] [Batch 04601/04869] [00:52:38/00:03:03, 0.686s/it]: train_loss_raw=1.8554, running_loss=1.7787, LR=0.000100
[2025-08-26 02:54:03,504][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019216] [Batch 04609/04869] [00:52:43/00:02:58, 0.686s/it]: train_loss_raw=1.7966, running_loss=1.7795, LR=0.000100
[2025-08-26 02:54:09,071][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019224] [Batch 04617/04869] [00:52:49/00:02:52, 0.686s/it]: train_loss_raw=1.7913, running_loss=1.7779, LR=0.000100
[2025-08-26 02:54:14,323][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019232] [Batch 04625/04869] [00:52:54/00:02:47, 0.686s/it]: train_loss_raw=1.8049, running_loss=1.7767, LR=0.000100
[2025-08-26 02:54:19,820][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019240] [Batch 04633/04869] [00:53:00/00:02:41, 0.686s/it]: train_loss_raw=1.7376, running_loss=1.7785, LR=0.000100
[2025-08-26 02:54:25,385][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019248] [Batch 04641/04869] [00:53:05/00:02:36, 0.686s/it]: train_loss_raw=1.6808, running_loss=1.7773, LR=0.000100
[2025-08-26 02:54:30,919][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019256] [Batch 04649/04869] [00:53:11/00:02:31, 0.686s/it]: train_loss_raw=1.7224, running_loss=1.7755, LR=0.000100
[2025-08-26 02:54:36,155][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019264] [Batch 04657/04869] [00:53:16/00:02:25, 0.686s/it]: train_loss_raw=1.8076, running_loss=1.7753, LR=0.000100
[2025-08-26 02:54:41,381][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019272] [Batch 04665/04869] [00:53:21/00:02:20, 0.686s/it]: train_loss_raw=1.7863, running_loss=1.7765, LR=0.000100
[2025-08-26 02:54:46,717][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019280] [Batch 04673/04869] [00:53:27/00:02:14, 0.686s/it]: train_loss_raw=1.8613, running_loss=1.7795, LR=0.000100
[2025-08-26 02:54:52,029][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019288] [Batch 04681/04869] [00:53:32/00:02:09, 0.686s/it]: train_loss_raw=1.8154, running_loss=1.7830, LR=0.000100
[2025-08-26 02:54:57,395][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019296] [Batch 04689/04869] [00:53:37/00:02:03, 0.686s/it]: train_loss_raw=1.8294, running_loss=1.7838, LR=0.000100
[2025-08-26 02:55:02,932][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019304] [Batch 04697/04869] [00:53:43/00:01:58, 0.686s/it]: train_loss_raw=1.7037, running_loss=1.7824, LR=0.000100
[2025-08-26 02:55:08,406][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019312] [Batch 04705/04869] [00:53:48/00:01:52, 0.686s/it]: train_loss_raw=1.7790, running_loss=1.7839, LR=0.000100
[2025-08-26 02:55:13,636][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019320] [Batch 04713/04869] [00:53:54/00:01:47, 0.686s/it]: train_loss_raw=1.7600, running_loss=1.7847, LR=0.000100
[2025-08-26 02:55:19,311][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019328] [Batch 04721/04869] [00:53:59/00:01:41, 0.686s/it]: train_loss_raw=1.6980, running_loss=1.7872, LR=0.000100
[2025-08-26 02:55:24,886][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019336] [Batch 04729/04869] [00:54:05/00:01:36, 0.686s/it]: train_loss_raw=1.6976, running_loss=1.7848, LR=0.000100
[2025-08-26 02:55:30,316][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019344] [Batch 04737/04869] [00:54:10/00:01:30, 0.686s/it]: train_loss_raw=1.7764, running_loss=1.7876, LR=0.000100
[2025-08-26 02:55:35,514][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019352] [Batch 04745/04869] [00:54:15/00:01:25, 0.686s/it]: train_loss_raw=1.6647, running_loss=1.7823, LR=0.000100
[2025-08-26 02:55:41,049][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019360] [Batch 04753/04869] [00:54:21/00:01:19, 0.686s/it]: train_loss_raw=1.7585, running_loss=1.7813, LR=0.000100
[2025-08-26 02:55:46,301][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019368] [Batch 04761/04869] [00:54:26/00:01:14, 0.686s/it]: train_loss_raw=1.6992, running_loss=1.7789, LR=0.000100
[2025-08-26 02:55:52,389][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019376] [Batch 04769/04869] [00:54:32/00:01:08, 0.686s/it]: train_loss_raw=1.7235, running_loss=1.7792, LR=0.000100
[2025-08-26 02:55:58,128][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019384] [Batch 04777/04869] [00:54:38/00:01:03, 0.686s/it]: train_loss_raw=1.8201, running_loss=1.7790, LR=0.000100
[2025-08-26 02:56:03,575][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019392] [Batch 04785/04869] [00:54:43/00:00:57, 0.686s/it]: train_loss_raw=1.7636, running_loss=1.7799, LR=0.000100
[2025-08-26 02:56:08,765][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019400] [Batch 04793/04869] [00:54:49/00:00:52, 0.686s/it]: train_loss_raw=1.8357, running_loss=1.7798, LR=0.000100
[2025-08-26 02:56:13,942][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019408] [Batch 04801/04869] [00:54:54/00:00:46, 0.686s/it]: train_loss_raw=1.7471, running_loss=1.7777, LR=0.000100
[2025-08-26 02:56:19,132][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019416] [Batch 04809/04869] [00:54:59/00:00:41, 0.686s/it]: train_loss_raw=1.7939, running_loss=1.7796, LR=0.000100
[2025-08-26 02:56:24,784][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019424] [Batch 04817/04869] [00:55:05/00:00:35, 0.686s/it]: train_loss_raw=1.8030, running_loss=1.7794, LR=0.000100
[2025-08-26 02:56:30,151][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019432] [Batch 04825/04869] [00:55:10/00:00:30, 0.686s/it]: train_loss_raw=1.7762, running_loss=1.7788, LR=0.000100
[2025-08-26 02:56:35,751][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019440] [Batch 04833/04869] [00:55:16/00:00:24, 0.686s/it]: train_loss_raw=1.8099, running_loss=1.7779, LR=0.000100
[2025-08-26 02:56:41,503][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019448] [Batch 04841/04869] [00:55:21/00:00:19, 0.686s/it]: train_loss_raw=1.7356, running_loss=1.7782, LR=0.000100
[2025-08-26 02:56:46,939][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019456] [Batch 04849/04869] [00:55:27/00:00:13, 0.686s/it]: train_loss_raw=1.7485, running_loss=1.7793, LR=0.000100
[2025-08-26 02:56:52,145][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019464] [Batch 04857/04869] [00:55:32/00:00:08, 0.686s/it]: train_loss_raw=1.7192, running_loss=1.7774, LR=0.000100
[2025-08-26 02:56:57,341][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 019472] [Batch 04865/04869] [00:55:37/00:00:02, 0.686s/it]: train_loss_raw=1.7270, running_loss=1.7762, LR=0.000100
[2025-08-26 02:57:13,902][__main__][INFO] - [VALIDATION] [Epoch 03/29] Starting validation.
[2025-08-26 02:57:24,126][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00007/00124] [00:00:10/00:02:28, 1.278s/it]
[2025-08-26 02:57:34,473][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00015/00124] [00:00:20/00:02:18, 1.286s/it]
[2025-08-26 02:57:44,926][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00023/00124] [00:00:31/00:02:09, 1.293s/it]
[2025-08-26 02:58:05,471][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00031/00124] [00:00:51/00:02:28, 1.612s/it]
[2025-08-26 02:58:16,236][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00039/00124] [00:01:02/00:02:10, 1.558s/it]
[2025-08-26 02:58:27,404][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00047/00124] [00:01:13/00:01:56, 1.531s/it]
[2025-08-26 02:58:39,086][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00055/00124] [00:01:25/00:01:43, 1.521s/it]
[2025-08-26 02:58:51,049][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00063/00124] [00:01:37/00:01:31, 1.518s/it]
[2025-08-26 02:59:01,948][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00071/00124] [00:01:48/00:01:18, 1.501s/it]
[2025-08-26 02:59:12,090][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00079/00124] [00:01:58/00:01:05, 1.477s/it]
[2025-08-26 02:59:22,430][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00087/00124] [00:02:08/00:00:52, 1.461s/it]
[2025-08-26 02:59:33,609][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00095/00124] [00:02:19/00:00:40, 1.455s/it]
[2025-08-26 02:59:44,429][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00103/00124] [00:02:30/00:00:28, 1.447s/it]
[2025-08-26 02:59:54,686][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00111/00124] [00:02:40/00:00:17, 1.436s/it]
[2025-08-26 03:00:05,006][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 019477] [Batch 00119/00124] [00:02:51/00:00:05, 1.426s/it]
[2025-08-26 03:00:09,538][__main__][INFO] - [VALIDATION] [Epoch 03/29] train_loss=1.77361, valid_loss=1.76786
[2025-08-26 03:00:09,538][__main__][INFO] - [VALIDATION] [Epoch 03/29] Metrics:
[2025-08-26 03:00:09,538][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_er      0.692
[2025-08-26 03:00:09,538][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_prec    0.045
[2025-08-26 03:00:09,538][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_recall  0.046
[2025-08-26 03:00:09,538][__main__][INFO] - [VALIDATION] [Epoch 03/29] - pep_recall 0.011
[2025-08-26 03:00:09,542][__main__][INFO] - [TRAIN] [Epoch 03/29] Epoch complete, total time 03:55:49, remaining time 25:32:52, 00:58:57 per epoch
[2025-08-26 03:00:11,979][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019480] [Batch 00004/04869] [00:00:02/00:46:34, 0.574s/it]: train_loss_raw=1.7824, running_loss=1.7719, LR=0.000100
[2025-08-26 03:00:17,861][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019488] [Batch 00012/04869] [00:00:08/00:55:10, 0.682s/it]: train_loss_raw=1.6445, running_loss=1.7670, LR=0.000100
[2025-08-26 03:00:23,621][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019496] [Batch 00020/04869] [00:00:13/00:56:19, 0.697s/it]: train_loss_raw=1.6397, running_loss=1.7620, LR=0.000100
[2025-08-26 03:00:29,427][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019504] [Batch 00028/04869] [00:00:19/00:56:53, 0.705s/it]: train_loss_raw=1.6529, running_loss=1.7584, LR=0.000100
[2025-08-26 03:00:34,886][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019512] [Batch 00036/04869] [00:00:25/00:56:23, 0.700s/it]: train_loss_raw=1.7114, running_loss=1.7544, LR=0.000100
[2025-08-26 03:00:40,096][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019520] [Batch 00044/04869] [00:00:30/00:55:35, 0.691s/it]: train_loss_raw=1.7055, running_loss=1.7545, LR=0.000100
[2025-08-26 03:00:45,648][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019528] [Batch 00052/04869] [00:00:35/00:55:31, 0.692s/it]: train_loss_raw=1.6728, running_loss=1.7491, LR=0.000100
[2025-08-26 03:00:50,857][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019536] [Batch 00060/04869] [00:00:41/00:55:00, 0.686s/it]: train_loss_raw=1.6781, running_loss=1.7464, LR=0.000100
[2025-08-26 03:00:56,879][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019544] [Batch 00068/04869] [00:00:47/00:55:32, 0.694s/it]: train_loss_raw=1.7772, running_loss=1.7443, LR=0.000100
[2025-08-26 03:01:02,611][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019552] [Batch 00076/04869] [00:00:52/00:55:38, 0.696s/it]: train_loss_raw=1.6166, running_loss=1.7401, LR=0.000100
[2025-08-26 03:01:08,655][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019560] [Batch 00084/04869] [00:00:58/00:55:59, 0.702s/it]: train_loss_raw=1.6792, running_loss=1.7430, LR=0.000100
[2025-08-26 03:01:14,579][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019568] [Batch 00092/04869] [00:01:04/00:56:09, 0.705s/it]: train_loss_raw=1.7236, running_loss=1.7457, LR=0.000100
[2025-08-26 03:01:19,942][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019576] [Batch 00100/04869] [00:01:10/00:55:50, 0.703s/it]: train_loss_raw=1.7199, running_loss=1.7472, LR=0.000100
[2025-08-26 03:01:25,433][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019584] [Batch 00108/04869] [00:01:15/00:55:39, 0.701s/it]: train_loss_raw=1.7395, running_loss=1.7464, LR=0.000100
[2025-08-26 03:01:30,689][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019592] [Batch 00116/04869] [00:01:21/00:55:19, 0.698s/it]: train_loss_raw=1.7445, running_loss=1.7451, LR=0.000100
[2025-08-26 03:01:35,898][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019600] [Batch 00124/04869] [00:01:26/00:54:59, 0.695s/it]: train_loss_raw=1.7589, running_loss=1.7458, LR=0.000100
[2025-08-26 03:01:41,519][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019608] [Batch 00132/04869] [00:01:31/00:54:55, 0.696s/it]: train_loss_raw=1.7864, running_loss=1.7436, LR=0.000100
[2025-08-26 03:01:46,708][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019616] [Batch 00140/04869] [00:01:37/00:54:37, 0.693s/it]: train_loss_raw=1.7243, running_loss=1.7416, LR=0.000100
[2025-08-26 03:01:51,865][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019624] [Batch 00148/04869] [00:01:42/00:54:19, 0.690s/it]: train_loss_raw=1.6488, running_loss=1.7402, LR=0.000100
[2025-08-26 03:01:57,049][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019632] [Batch 00156/04869] [00:01:47/00:54:03, 0.688s/it]: train_loss_raw=1.6953, running_loss=1.7377, LR=0.000100
[2025-08-26 03:02:02,424][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019640] [Batch 00164/04869] [00:01:52/00:53:54, 0.687s/it]: train_loss_raw=1.8009, running_loss=1.7380, LR=0.000100
[2025-08-26 03:02:07,618][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019648] [Batch 00172/04869] [00:01:57/00:53:40, 0.686s/it]: train_loss_raw=1.7335, running_loss=1.7374, LR=0.000100
[2025-08-26 03:02:12,799][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019656] [Batch 00180/04869] [00:02:03/00:53:27, 0.684s/it]: train_loss_raw=1.8046, running_loss=1.7370, LR=0.000100
[2025-08-26 03:02:18,010][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019664] [Batch 00188/04869] [00:02:08/00:53:15, 0.683s/it]: train_loss_raw=1.7492, running_loss=1.7362, LR=0.000100
[2025-08-26 03:02:23,338][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019672] [Batch 00196/04869] [00:02:13/00:53:06, 0.682s/it]: train_loss_raw=1.8040, running_loss=1.7344, LR=0.000100
[2025-08-26 03:02:28,609][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019680] [Batch 00204/04869] [00:02:18/00:52:56, 0.681s/it]: train_loss_raw=1.7143, running_loss=1.7344, LR=0.000100
[2025-08-26 03:02:33,815][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019688] [Batch 00212/04869] [00:02:24/00:52:46, 0.680s/it]: train_loss_raw=1.7191, running_loss=1.7337, LR=0.000100
[2025-08-26 03:02:39,028][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019696] [Batch 00220/04869] [00:02:29/00:52:35, 0.679s/it]: train_loss_raw=1.7876, running_loss=1.7361, LR=0.000100
[2025-08-26 03:02:44,245][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019704] [Batch 00228/04869] [00:02:34/00:52:26, 0.678s/it]: train_loss_raw=1.7927, running_loss=1.7361, LR=0.000100
[2025-08-26 03:02:49,624][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019712] [Batch 00236/04869] [00:02:39/00:52:19, 0.678s/it]: train_loss_raw=1.6516, running_loss=1.7353, LR=0.000100
[2025-08-26 03:02:55,346][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019720] [Batch 00244/04869] [00:02:45/00:52:20, 0.679s/it]: train_loss_raw=1.7768, running_loss=1.7379, LR=0.000100
[2025-08-26 03:03:00,800][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019728] [Batch 00252/04869] [00:02:51/00:52:15, 0.679s/it]: train_loss_raw=1.7378, running_loss=1.7354, LR=0.000100
[2025-08-26 03:03:06,036][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019736] [Batch 00260/04869] [00:02:56/00:52:06, 0.678s/it]: train_loss_raw=1.7817, running_loss=1.7343, LR=0.000100
[2025-08-26 03:03:11,530][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019744] [Batch 00268/04869] [00:03:01/00:52:01, 0.679s/it]: train_loss_raw=1.5993, running_loss=1.7320, LR=0.000100
[2025-08-26 03:03:16,717][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019752] [Batch 00276/04869] [00:03:07/00:51:52, 0.678s/it]: train_loss_raw=1.7279, running_loss=1.7296, LR=0.000100
[2025-08-26 03:03:22,024][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019760] [Batch 00284/04869] [00:03:12/00:51:45, 0.677s/it]: train_loss_raw=1.7842, running_loss=1.7317, LR=0.000100
[2025-08-26 03:03:27,208][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019768] [Batch 00292/04869] [00:03:17/00:51:36, 0.676s/it]: train_loss_raw=1.7635, running_loss=1.7284, LR=0.000100
[2025-08-26 03:03:32,732][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019776] [Batch 00300/04869] [00:03:23/00:51:32, 0.677s/it]: train_loss_raw=1.6774, running_loss=1.7284, LR=0.000100
[2025-08-26 03:03:37,930][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019784] [Batch 00308/04869] [00:03:28/00:51:23, 0.676s/it]: train_loss_raw=1.7294, running_loss=1.7294, LR=0.000100
[2025-08-26 03:03:43,502][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019792] [Batch 00316/04869] [00:03:33/00:51:20, 0.677s/it]: train_loss_raw=1.7776, running_loss=1.7306, LR=0.000100
[2025-08-26 03:03:48,960][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019800] [Batch 00324/04869] [00:03:39/00:51:16, 0.677s/it]: train_loss_raw=1.6835, running_loss=1.7316, LR=0.000100
[2025-08-26 03:03:54,226][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019808] [Batch 00332/04869] [00:03:44/00:51:08, 0.676s/it]: train_loss_raw=1.7082, running_loss=1.7305, LR=0.000100
[2025-08-26 03:03:59,852][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019816] [Batch 00340/04869] [00:03:50/00:51:06, 0.677s/it]: train_loss_raw=1.6911, running_loss=1.7303, LR=0.000100
[2025-08-26 03:04:05,084][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019824] [Batch 00348/04869] [00:03:55/00:50:58, 0.676s/it]: train_loss_raw=1.6899, running_loss=1.7266, LR=0.000100
[2025-08-26 03:04:11,207][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019832] [Batch 00356/04869] [00:04:01/00:51:01, 0.678s/it]: train_loss_raw=1.8003, running_loss=1.7271, LR=0.000100
[2025-08-26 03:04:16,585][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019840] [Batch 00364/04869] [00:04:06/00:50:55, 0.678s/it]: train_loss_raw=1.7005, running_loss=1.7283, LR=0.000100
[2025-08-26 03:04:21,900][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019848] [Batch 00372/04869] [00:04:12/00:50:49, 0.678s/it]: train_loss_raw=1.7421, running_loss=1.7280, LR=0.000100
[2025-08-26 03:04:27,595][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019856] [Batch 00380/04869] [00:04:17/00:50:46, 0.679s/it]: train_loss_raw=1.6951, running_loss=1.7278, LR=0.000100
[2025-08-26 03:04:33,319][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019864] [Batch 00388/04869] [00:04:23/00:50:44, 0.679s/it]: train_loss_raw=1.8039, running_loss=1.7305, LR=0.000100
[2025-08-26 03:04:38,535][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019872] [Batch 00396/04869] [00:04:28/00:50:36, 0.679s/it]: train_loss_raw=1.6960, running_loss=1.7301, LR=0.000100
[2025-08-26 03:04:43,958][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019880] [Batch 00404/04869] [00:04:34/00:50:31, 0.679s/it]: train_loss_raw=1.7830, running_loss=1.7321, LR=0.000100
[2025-08-26 03:04:49,344][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019888] [Batch 00412/04869] [00:04:39/00:50:25, 0.679s/it]: train_loss_raw=1.7212, running_loss=1.7329, LR=0.000100
[2025-08-26 03:04:54,540][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019896] [Batch 00420/04869] [00:04:44/00:50:17, 0.678s/it]: train_loss_raw=1.7909, running_loss=1.7337, LR=0.000100
[2025-08-26 03:04:59,970][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019904] [Batch 00428/04869] [00:04:50/00:50:12, 0.678s/it]: train_loss_raw=1.7255, running_loss=1.7350, LR=0.000100
[2025-08-26 03:05:05,176][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019912] [Batch 00436/04869] [00:04:55/00:50:04, 0.678s/it]: train_loss_raw=1.7581, running_loss=1.7326, LR=0.000100
[2025-08-26 03:05:10,391][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019920] [Batch 00444/04869] [00:05:00/00:49:56, 0.677s/it]: train_loss_raw=1.7628, running_loss=1.7331, LR=0.000100
[2025-08-26 03:05:15,598][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019928] [Batch 00452/04869] [00:05:05/00:49:49, 0.677s/it]: train_loss_raw=1.6479, running_loss=1.7320, LR=0.000100
[2025-08-26 03:05:20,816][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019936] [Batch 00460/04869] [00:05:11/00:49:42, 0.676s/it]: train_loss_raw=1.7856, running_loss=1.7302, LR=0.000100
[2025-08-26 03:05:26,023][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019944] [Batch 00468/04869] [00:05:16/00:49:34, 0.676s/it]: train_loss_raw=1.6711, running_loss=1.7301, LR=0.000100
[2025-08-26 03:05:31,493][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019952] [Batch 00476/04869] [00:05:21/00:49:30, 0.676s/it]: train_loss_raw=1.7263, running_loss=1.7294, LR=0.000100
[2025-08-26 03:05:36,901][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019960] [Batch 00484/04869] [00:05:27/00:49:24, 0.676s/it]: train_loss_raw=1.6690, running_loss=1.7285, LR=0.000100
[2025-08-26 03:05:42,294][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019968] [Batch 00492/04869] [00:05:32/00:49:19, 0.676s/it]: train_loss_raw=1.7715, running_loss=1.7271, LR=0.000100
[2025-08-26 03:05:48,109][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019976] [Batch 00500/04869] [00:05:38/00:49:17, 0.677s/it]: train_loss_raw=1.7403, running_loss=1.7257, LR=0.000100
[2025-08-26 03:05:53,662][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019984] [Batch 00508/04869] [00:05:43/00:49:12, 0.677s/it]: train_loss_raw=1.6840, running_loss=1.7203, LR=0.000100
[2025-08-26 03:05:59,267][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 019992] [Batch 00516/04869] [00:05:49/00:49:09, 0.677s/it]: train_loss_raw=1.6856, running_loss=1.7208, LR=0.000100
[2025-08-26 03:06:04,567][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020000] [Batch 00524/04869] [00:05:54/00:49:02, 0.677s/it]: train_loss_raw=1.6612, running_loss=1.7201, LR=0.000100
[2025-08-26 03:06:13,523][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020008] [Batch 00532/04869] [00:06:03/00:49:26, 0.684s/it]: train_loss_raw=1.7265, running_loss=1.7202, LR=0.000100
[2025-08-26 03:06:18,736][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020016] [Batch 00540/04869] [00:06:09/00:49:18, 0.683s/it]: train_loss_raw=1.7599, running_loss=1.7214, LR=0.000100
[2025-08-26 03:06:23,928][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020024] [Batch 00548/04869] [00:06:14/00:49:10, 0.683s/it]: train_loss_raw=1.7142, running_loss=1.7232, LR=0.000100
[2025-08-26 03:06:29,128][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020032] [Batch 00556/04869] [00:06:19/00:49:03, 0.682s/it]: train_loss_raw=1.7064, running_loss=1.7241, LR=0.000100
[2025-08-26 03:06:34,509][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020040] [Batch 00564/04869] [00:06:24/00:48:57, 0.682s/it]: train_loss_raw=1.7672, running_loss=1.7256, LR=0.000100
[2025-08-26 03:06:40,075][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020048] [Batch 00572/04869] [00:06:30/00:48:52, 0.683s/it]: train_loss_raw=1.5557, running_loss=1.7227, LR=0.000100
[2025-08-26 03:06:45,286][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020056] [Batch 00580/04869] [00:06:35/00:48:45, 0.682s/it]: train_loss_raw=1.7958, running_loss=1.7226, LR=0.000100
[2025-08-26 03:06:50,497][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020064] [Batch 00588/04869] [00:06:40/00:48:38, 0.682s/it]: train_loss_raw=1.8196, running_loss=1.7225, LR=0.000100
[2025-08-26 03:06:55,698][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020072] [Batch 00596/04869] [00:06:46/00:48:30, 0.681s/it]: train_loss_raw=1.7192, running_loss=1.7217, LR=0.000100
[2025-08-26 03:07:01,243][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020080] [Batch 00604/04869] [00:06:51/00:48:26, 0.681s/it]: train_loss_raw=1.6987, running_loss=1.7209, LR=0.000100
[2025-08-26 03:07:06,714][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020088] [Batch 00612/04869] [00:06:57/00:48:20, 0.681s/it]: train_loss_raw=1.7993, running_loss=1.7221, LR=0.000100
[2025-08-26 03:07:11,894][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020096] [Batch 00620/04869] [00:07:02/00:48:13, 0.681s/it]: train_loss_raw=1.7136, running_loss=1.7211, LR=0.000100
[2025-08-26 03:07:17,345][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020104] [Batch 00628/04869] [00:07:07/00:48:08, 0.681s/it]: train_loss_raw=1.7360, running_loss=1.7207, LR=0.000100
[2025-08-26 03:07:22,623][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020112] [Batch 00636/04869] [00:07:12/00:48:01, 0.681s/it]: train_loss_raw=1.7723, running_loss=1.7201, LR=0.000100
[2025-08-26 03:07:27,865][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020120] [Batch 00644/04869] [00:07:18/00:47:54, 0.680s/it]: train_loss_raw=1.7513, running_loss=1.7196, LR=0.000100
[2025-08-26 03:07:33,434][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020128] [Batch 00652/04869] [00:07:23/00:47:50, 0.681s/it]: train_loss_raw=1.6825, running_loss=1.7191, LR=0.000100
[2025-08-26 03:07:38,908][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020136] [Batch 00660/04869] [00:07:29/00:47:44, 0.681s/it]: train_loss_raw=1.7132, running_loss=1.7189, LR=0.000100
[2025-08-26 03:07:44,146][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020144] [Batch 00668/04869] [00:07:34/00:47:38, 0.680s/it]: train_loss_raw=1.7735, running_loss=1.7204, LR=0.000100
[2025-08-26 03:07:49,381][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020152] [Batch 00676/04869] [00:07:39/00:47:31, 0.680s/it]: train_loss_raw=1.7002, running_loss=1.7194, LR=0.000100
[2025-08-26 03:07:54,838][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020160] [Batch 00684/04869] [00:07:45/00:47:26, 0.680s/it]: train_loss_raw=1.7659, running_loss=1.7200, LR=0.000100
[2025-08-26 03:08:00,828][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020168] [Batch 00692/04869] [00:07:51/00:47:23, 0.681s/it]: train_loss_raw=1.7423, running_loss=1.7210, LR=0.000100
[2025-08-26 03:08:06,511][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020176] [Batch 00700/04869] [00:07:56/00:47:19, 0.681s/it]: train_loss_raw=1.7438, running_loss=1.7207, LR=0.000100
[2025-08-26 03:08:11,732][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020184] [Batch 00708/04869] [00:08:02/00:47:13, 0.681s/it]: train_loss_raw=1.7740, running_loss=1.7212, LR=0.000100
[2025-08-26 03:08:16,963][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020192] [Batch 00716/04869] [00:08:07/00:47:06, 0.681s/it]: train_loss_raw=1.7463, running_loss=1.7220, LR=0.000100
[2025-08-26 03:08:22,230][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020200] [Batch 00724/04869] [00:08:12/00:46:59, 0.680s/it]: train_loss_raw=1.6492, running_loss=1.7221, LR=0.000100
[2025-08-26 03:08:27,716][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020208] [Batch 00732/04869] [00:08:18/00:46:54, 0.680s/it]: train_loss_raw=1.7203, running_loss=1.7213, LR=0.000100
[2025-08-26 03:08:32,958][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020216] [Batch 00740/04869] [00:08:23/00:46:48, 0.680s/it]: train_loss_raw=1.7426, running_loss=1.7205, LR=0.000100
[2025-08-26 03:08:38,219][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020224] [Batch 00748/04869] [00:08:28/00:46:41, 0.680s/it]: train_loss_raw=1.7312, running_loss=1.7211, LR=0.000100
[2025-08-26 03:08:43,559][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020232] [Batch 00756/04869] [00:08:33/00:46:35, 0.680s/it]: train_loss_raw=1.7524, running_loss=1.7225, LR=0.000100
[2025-08-26 03:08:49,059][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020240] [Batch 00764/04869] [00:08:39/00:46:30, 0.680s/it]: train_loss_raw=1.7599, running_loss=1.7215, LR=0.000100
[2025-08-26 03:08:54,481][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020248] [Batch 00772/04869] [00:08:44/00:46:25, 0.680s/it]: train_loss_raw=1.8166, running_loss=1.7202, LR=0.000100
[2025-08-26 03:08:59,739][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020256] [Batch 00780/04869] [00:08:50/00:46:18, 0.680s/it]: train_loss_raw=1.7900, running_loss=1.7219, LR=0.000100
[2025-08-26 03:09:04,969][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020264] [Batch 00788/04869] [00:08:55/00:46:12, 0.679s/it]: train_loss_raw=1.7682, running_loss=1.7227, LR=0.000100
[2025-08-26 03:09:10,330][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020272] [Batch 00796/04869] [00:09:00/00:46:06, 0.679s/it]: train_loss_raw=1.7149, running_loss=1.7213, LR=0.000100
[2025-08-26 03:09:15,551][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020280] [Batch 00804/04869] [00:09:05/00:45:59, 0.679s/it]: train_loss_raw=1.6915, running_loss=1.7206, LR=0.000100
[2025-08-26 03:09:20,787][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020288] [Batch 00812/04869] [00:09:11/00:45:53, 0.679s/it]: train_loss_raw=1.7550, running_loss=1.7224, LR=0.000100
[2025-08-26 03:09:26,018][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020296] [Batch 00820/04869] [00:09:16/00:45:47, 0.678s/it]: train_loss_raw=1.8207, running_loss=1.7244, LR=0.000100
[2025-08-26 03:09:31,468][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020304] [Batch 00828/04869] [00:09:21/00:45:41, 0.678s/it]: train_loss_raw=1.7095, running_loss=1.7235, LR=0.000100
[2025-08-26 03:09:37,341][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020312] [Batch 00836/04869] [00:09:27/00:45:38, 0.679s/it]: train_loss_raw=1.6354, running_loss=1.7239, LR=0.000100
[2025-08-26 03:09:42,884][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020320] [Batch 00844/04869] [00:09:33/00:45:33, 0.679s/it]: train_loss_raw=1.7281, running_loss=1.7227, LR=0.000100
[2025-08-26 03:09:48,103][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020328] [Batch 00852/04869] [00:09:38/00:45:27, 0.679s/it]: train_loss_raw=1.7685, running_loss=1.7239, LR=0.000100
[2025-08-26 03:09:53,328][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020336] [Batch 00860/04869] [00:09:43/00:45:20, 0.679s/it]: train_loss_raw=1.6541, running_loss=1.7241, LR=0.000100
[2025-08-26 03:09:58,561][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020344] [Batch 00868/04869] [00:09:48/00:45:14, 0.678s/it]: train_loss_raw=1.7749, running_loss=1.7246, LR=0.000100
[2025-08-26 03:10:03,928][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020352] [Batch 00876/04869] [00:09:54/00:45:08, 0.678s/it]: train_loss_raw=1.7578, running_loss=1.7240, LR=0.000100
[2025-08-26 03:10:09,190][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020360] [Batch 00884/04869] [00:09:59/00:45:02, 0.678s/it]: train_loss_raw=1.7845, running_loss=1.7232, LR=0.000100
[2025-08-26 03:10:14,638][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020368] [Batch 00892/04869] [00:10:04/00:44:57, 0.678s/it]: train_loss_raw=1.7664, running_loss=1.7236, LR=0.000100
[2025-08-26 03:10:20,178][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020376] [Batch 00900/04869] [00:10:10/00:44:52, 0.678s/it]: train_loss_raw=1.7637, running_loss=1.7234, LR=0.000100
[2025-08-26 03:10:25,358][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020384] [Batch 00908/04869] [00:10:15/00:44:45, 0.678s/it]: train_loss_raw=1.6200, running_loss=1.7229, LR=0.000100
[2025-08-26 03:10:30,610][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020392] [Batch 00916/04869] [00:10:20/00:44:39, 0.678s/it]: train_loss_raw=1.6851, running_loss=1.7224, LR=0.000100
[2025-08-26 03:10:35,816][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020400] [Batch 00924/04869] [00:10:26/00:44:33, 0.678s/it]: train_loss_raw=1.7449, running_loss=1.7260, LR=0.000100
[2025-08-26 03:10:41,014][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020408] [Batch 00932/04869] [00:10:31/00:44:26, 0.677s/it]: train_loss_raw=1.7426, running_loss=1.7255, LR=0.000100
[2025-08-26 03:10:46,200][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020416] [Batch 00940/04869] [00:10:36/00:44:20, 0.677s/it]: train_loss_raw=1.7368, running_loss=1.7262, LR=0.000100
[2025-08-26 03:10:51,478][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020424] [Batch 00948/04869] [00:10:41/00:44:14, 0.677s/it]: train_loss_raw=1.7384, running_loss=1.7267, LR=0.000100
[2025-08-26 03:10:57,117][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020432] [Batch 00956/04869] [00:10:47/00:44:10, 0.677s/it]: train_loss_raw=1.7082, running_loss=1.7285, LR=0.000100
[2025-08-26 03:11:02,573][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020440] [Batch 00964/04869] [00:10:52/00:44:04, 0.677s/it]: train_loss_raw=1.7327, running_loss=1.7282, LR=0.000100
[2025-08-26 03:11:08,190][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020448] [Batch 00972/04869] [00:10:58/00:44:00, 0.677s/it]: train_loss_raw=1.7422, running_loss=1.7299, LR=0.000100
[2025-08-26 03:11:13,884][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020456] [Batch 00980/04869] [00:11:04/00:43:55, 0.678s/it]: train_loss_raw=1.7783, running_loss=1.7272, LR=0.000100
[2025-08-26 03:11:19,285][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020464] [Batch 00988/04869] [00:11:09/00:43:50, 0.678s/it]: train_loss_raw=1.6675, running_loss=1.7266, LR=0.000100
[2025-08-26 03:11:24,482][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020472] [Batch 00996/04869] [00:11:14/00:43:44, 0.678s/it]: train_loss_raw=1.7147, running_loss=1.7272, LR=0.000100
[2025-08-26 03:11:29,817][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020480] [Batch 01004/04869] [00:11:20/00:43:38, 0.677s/it]: train_loss_raw=1.6883, running_loss=1.7232, LR=0.000100
[2025-08-26 03:11:48,808][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020488] [Batch 01012/04869] [00:11:39/00:44:24, 0.691s/it]: train_loss_raw=1.7056, running_loss=1.7204, LR=0.000100
[2025-08-26 03:11:53,989][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020496] [Batch 01020/04869] [00:11:44/00:44:17, 0.690s/it]: train_loss_raw=1.7982, running_loss=1.7215, LR=0.000100
[2025-08-26 03:11:59,173][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020504] [Batch 01028/04869] [00:11:49/00:44:10, 0.690s/it]: train_loss_raw=1.6231, running_loss=1.7236, LR=0.000100
[2025-08-26 03:12:04,953][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020512] [Batch 01036/04869] [00:11:55/00:44:06, 0.690s/it]: train_loss_raw=1.7829, running_loss=1.7237, LR=0.000100
[2025-08-26 03:12:10,743][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020520] [Batch 01044/04869] [00:12:01/00:44:01, 0.691s/it]: train_loss_raw=1.7030, running_loss=1.7228, LR=0.000100
[2025-08-26 03:12:16,171][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020528] [Batch 01052/04869] [00:12:06/00:43:55, 0.691s/it]: train_loss_raw=1.6316, running_loss=1.7228, LR=0.000100
[2025-08-26 03:12:21,431][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020536] [Batch 01060/04869] [00:12:11/00:43:49, 0.690s/it]: train_loss_raw=1.7736, running_loss=1.7284, LR=0.000100
[2025-08-26 03:12:26,676][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020544] [Batch 01068/04869] [00:12:16/00:43:42, 0.690s/it]: train_loss_raw=1.7524, running_loss=1.7257, LR=0.000100
[2025-08-26 03:12:32,534][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020552] [Batch 01076/04869] [00:12:22/00:43:38, 0.690s/it]: train_loss_raw=1.8360, running_loss=1.7283, LR=0.000100
[2025-08-26 03:12:37,727][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020560] [Batch 01084/04869] [00:12:28/00:43:31, 0.690s/it]: train_loss_raw=1.7547, running_loss=1.7265, LR=0.000100
[2025-08-26 03:12:42,918][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020568] [Batch 01092/04869] [00:12:33/00:43:25, 0.690s/it]: train_loss_raw=1.7107, running_loss=1.7257, LR=0.000100
[2025-08-26 03:12:48,126][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020576] [Batch 01100/04869] [00:12:38/00:43:18, 0.689s/it]: train_loss_raw=1.7959, running_loss=1.7263, LR=0.000100
[2025-08-26 03:12:53,989][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020584] [Batch 01108/04869] [00:12:44/00:43:14, 0.690s/it]: train_loss_raw=1.7383, running_loss=1.7272, LR=0.000100
[2025-08-26 03:12:59,278][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020592] [Batch 01116/04869] [00:12:49/00:43:08, 0.690s/it]: train_loss_raw=1.7424, running_loss=1.7267, LR=0.000100
[2025-08-26 03:13:05,463][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020600] [Batch 01124/04869] [00:12:55/00:43:04, 0.690s/it]: train_loss_raw=1.7108, running_loss=1.7246, LR=0.000100
[2025-08-26 03:13:11,557][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020608] [Batch 01132/04869] [00:13:01/00:43:01, 0.691s/it]: train_loss_raw=1.6371, running_loss=1.7224, LR=0.000100
[2025-08-26 03:13:17,004][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020616] [Batch 01140/04869] [00:13:07/00:42:55, 0.691s/it]: train_loss_raw=1.6522, running_loss=1.7202, LR=0.000100
[2025-08-26 03:13:23,032][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020624] [Batch 01148/04869] [00:13:13/00:42:51, 0.691s/it]: train_loss_raw=1.7221, running_loss=1.7189, LR=0.000100
[2025-08-26 03:13:29,170][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020632] [Batch 01156/04869] [00:13:19/00:42:47, 0.692s/it]: train_loss_raw=1.7099, running_loss=1.7190, LR=0.000100
[2025-08-26 03:13:35,234][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020640] [Batch 01164/04869] [00:13:25/00:42:44, 0.692s/it]: train_loss_raw=1.8146, running_loss=1.7214, LR=0.000100
[2025-08-26 03:13:41,508][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020648] [Batch 01172/04869] [00:13:31/00:42:40, 0.693s/it]: train_loss_raw=1.6864, running_loss=1.7224, LR=0.000100
[2025-08-26 03:13:46,888][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020656] [Batch 01180/04869] [00:13:37/00:42:34, 0.693s/it]: train_loss_raw=1.6565, running_loss=1.7200, LR=0.000100
[2025-08-26 03:13:52,629][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020664] [Batch 01188/04869] [00:13:42/00:42:29, 0.693s/it]: train_loss_raw=1.6882, running_loss=1.7176, LR=0.000100
[2025-08-26 03:13:58,352][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020672] [Batch 01196/04869] [00:13:48/00:42:24, 0.693s/it]: train_loss_raw=1.6938, running_loss=1.7172, LR=0.000100
[2025-08-26 03:14:03,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020680] [Batch 01204/04869] [00:13:54/00:42:18, 0.693s/it]: train_loss_raw=1.8091, running_loss=1.7179, LR=0.000100
[2025-08-26 03:14:08,959][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020688] [Batch 01212/04869] [00:13:59/00:42:12, 0.692s/it]: train_loss_raw=1.7128, running_loss=1.7195, LR=0.000100
[2025-08-26 03:14:14,380][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020696] [Batch 01220/04869] [00:14:04/00:42:06, 0.692s/it]: train_loss_raw=1.7135, running_loss=1.7206, LR=0.000100
[2025-08-26 03:14:19,619][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020704] [Batch 01228/04869] [00:14:09/00:42:00, 0.692s/it]: train_loss_raw=1.6867, running_loss=1.7193, LR=0.000100
[2025-08-26 03:14:24,831][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020712] [Batch 01236/04869] [00:14:15/00:41:53, 0.692s/it]: train_loss_raw=1.6118, running_loss=1.7165, LR=0.000100
[2025-08-26 03:14:30,039][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020720] [Batch 01244/04869] [00:14:20/00:41:47, 0.692s/it]: train_loss_raw=1.7420, running_loss=1.7168, LR=0.000100
[2025-08-26 03:14:35,683][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020728] [Batch 01252/04869] [00:14:26/00:41:41, 0.692s/it]: train_loss_raw=1.8446, running_loss=1.7165, LR=0.000100
[2025-08-26 03:14:40,866][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020736] [Batch 01260/04869] [00:14:31/00:41:35, 0.691s/it]: train_loss_raw=1.6401, running_loss=1.7159, LR=0.000100
[2025-08-26 03:14:46,096][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020744] [Batch 01268/04869] [00:14:36/00:41:28, 0.691s/it]: train_loss_raw=1.8762, running_loss=1.7168, LR=0.000100
[2025-08-26 03:14:51,945][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020752] [Batch 01276/04869] [00:14:42/00:41:24, 0.691s/it]: train_loss_raw=1.7396, running_loss=1.7158, LR=0.000100
[2025-08-26 03:14:57,935][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020760] [Batch 01284/04869] [00:14:48/00:41:20, 0.692s/it]: train_loss_raw=1.7041, running_loss=1.7143, LR=0.000100
[2025-08-26 03:15:03,247][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020768] [Batch 01292/04869] [00:14:53/00:41:13, 0.692s/it]: train_loss_raw=1.5187, running_loss=1.7115, LR=0.000100
[2025-08-26 03:15:08,434][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020776] [Batch 01300/04869] [00:14:58/00:41:07, 0.691s/it]: train_loss_raw=1.6755, running_loss=1.7117, LR=0.000100
[2025-08-26 03:15:13,624][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020784] [Batch 01308/04869] [00:15:03/00:41:00, 0.691s/it]: train_loss_raw=1.7625, running_loss=1.7139, LR=0.000100
[2025-08-26 03:15:19,064][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020792] [Batch 01316/04869] [00:15:09/00:40:55, 0.691s/it]: train_loss_raw=1.8114, running_loss=1.7146, LR=0.000100
[2025-08-26 03:15:24,337][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020800] [Batch 01324/04869] [00:15:14/00:40:48, 0.691s/it]: train_loss_raw=1.7444, running_loss=1.7148, LR=0.000100
[2025-08-26 03:15:30,230][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020808] [Batch 01332/04869] [00:15:20/00:40:44, 0.691s/it]: train_loss_raw=1.7098, running_loss=1.7154, LR=0.000100
[2025-08-26 03:15:35,633][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020816] [Batch 01340/04869] [00:15:25/00:40:38, 0.691s/it]: train_loss_raw=1.7258, running_loss=1.7161, LR=0.000100
[2025-08-26 03:15:40,837][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020824] [Batch 01348/04869] [00:15:31/00:40:32, 0.691s/it]: train_loss_raw=1.7293, running_loss=1.7155, LR=0.000100
[2025-08-26 03:15:46,076][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020832] [Batch 01356/04869] [00:15:36/00:40:25, 0.691s/it]: train_loss_raw=1.7164, running_loss=1.7158, LR=0.000100
[2025-08-26 03:15:51,650][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020840] [Batch 01364/04869] [00:15:41/00:40:20, 0.691s/it]: train_loss_raw=1.7463, running_loss=1.7153, LR=0.000100
[2025-08-26 03:15:57,133][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020848] [Batch 01372/04869] [00:15:47/00:40:14, 0.691s/it]: train_loss_raw=1.6609, running_loss=1.7146, LR=0.000100
[2025-08-26 03:16:02,340][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020856] [Batch 01380/04869] [00:15:52/00:40:08, 0.690s/it]: train_loss_raw=1.7324, running_loss=1.7149, LR=0.000100
[2025-08-26 03:16:07,778][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020864] [Batch 01388/04869] [00:15:58/00:40:02, 0.690s/it]: train_loss_raw=1.7848, running_loss=1.7176, LR=0.000100
[2025-08-26 03:16:13,035][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020872] [Batch 01396/04869] [00:16:03/00:39:56, 0.690s/it]: train_loss_raw=1.7355, running_loss=1.7178, LR=0.000100
[2025-08-26 03:16:18,351][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020880] [Batch 01404/04869] [00:16:08/00:39:50, 0.690s/it]: train_loss_raw=1.6610, running_loss=1.7161, LR=0.000100
[2025-08-26 03:16:23,902][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020888] [Batch 01412/04869] [00:16:14/00:39:45, 0.690s/it]: train_loss_raw=1.7382, running_loss=1.7159, LR=0.000100
[2025-08-26 03:16:29,162][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020896] [Batch 01420/04869] [00:16:19/00:39:39, 0.690s/it]: train_loss_raw=1.7148, running_loss=1.7153, LR=0.000100
[2025-08-26 03:16:34,366][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020904] [Batch 01428/04869] [00:16:24/00:39:32, 0.690s/it]: train_loss_raw=1.7499, running_loss=1.7136, LR=0.000100
[2025-08-26 03:16:39,553][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020912] [Batch 01436/04869] [00:16:29/00:39:26, 0.689s/it]: train_loss_raw=1.7039, running_loss=1.7154, LR=0.000100
[2025-08-26 03:16:44,718][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020920] [Batch 01444/04869] [00:16:35/00:39:20, 0.689s/it]: train_loss_raw=1.7658, running_loss=1.7154, LR=0.000100
[2025-08-26 03:16:50,315][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020928] [Batch 01452/04869] [00:16:40/00:39:14, 0.689s/it]: train_loss_raw=1.7888, running_loss=1.7188, LR=0.000100
[2025-08-26 03:16:56,356][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020936] [Batch 01460/04869] [00:16:46/00:39:10, 0.690s/it]: train_loss_raw=1.6852, running_loss=1.7169, LR=0.000100
[2025-08-26 03:17:01,846][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020944] [Batch 01468/04869] [00:16:52/00:39:04, 0.689s/it]: train_loss_raw=1.7593, running_loss=1.7149, LR=0.000100
[2025-08-26 03:17:07,411][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020952] [Batch 01476/04869] [00:16:57/00:38:59, 0.690s/it]: train_loss_raw=1.7761, running_loss=1.7131, LR=0.000100
[2025-08-26 03:17:13,251][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020960] [Batch 01484/04869] [00:17:03/00:38:54, 0.690s/it]: train_loss_raw=1.6869, running_loss=1.7135, LR=0.000100
[2025-08-26 03:17:18,829][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020968] [Batch 01492/04869] [00:17:09/00:38:49, 0.690s/it]: train_loss_raw=1.6364, running_loss=1.7117, LR=0.000100
[2025-08-26 03:17:24,104][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020976] [Batch 01500/04869] [00:17:14/00:38:43, 0.690s/it]: train_loss_raw=1.7475, running_loss=1.7128, LR=0.000100
[2025-08-26 03:17:29,775][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020984] [Batch 01508/04869] [00:17:20/00:38:38, 0.690s/it]: train_loss_raw=1.7269, running_loss=1.7127, LR=0.000100
[2025-08-26 03:17:35,217][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 020992] [Batch 01516/04869] [00:17:25/00:38:32, 0.690s/it]: train_loss_raw=1.6884, running_loss=1.7110, LR=0.000100
[2025-08-26 03:17:40,416][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021000] [Batch 01524/04869] [00:17:30/00:38:26, 0.689s/it]: train_loss_raw=1.6580, running_loss=1.7080, LR=0.000100
[2025-08-26 03:17:45,622][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021008] [Batch 01532/04869] [00:17:35/00:38:20, 0.689s/it]: train_loss_raw=1.7385, running_loss=1.7080, LR=0.000100
[2025-08-26 03:17:50,824][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021016] [Batch 01540/04869] [00:17:41/00:38:13, 0.689s/it]: train_loss_raw=1.7214, running_loss=1.7073, LR=0.000100
[2025-08-26 03:17:56,013][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021024] [Batch 01548/04869] [00:17:46/00:38:07, 0.689s/it]: train_loss_raw=1.6965, running_loss=1.7056, LR=0.000100
[2025-08-26 03:18:01,384][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021032] [Batch 01556/04869] [00:17:51/00:38:01, 0.689s/it]: train_loss_raw=1.7894, running_loss=1.7064, LR=0.000100
[2025-08-26 03:18:06,649][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021040] [Batch 01564/04869] [00:17:56/00:37:55, 0.689s/it]: train_loss_raw=1.6975, running_loss=1.7052, LR=0.000100
[2025-08-26 03:18:11,920][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021048] [Batch 01572/04869] [00:18:02/00:37:49, 0.688s/it]: train_loss_raw=1.6584, running_loss=1.7023, LR=0.000100
[2025-08-26 03:18:17,164][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021056] [Batch 01580/04869] [00:18:07/00:37:43, 0.688s/it]: train_loss_raw=1.7046, running_loss=1.7019, LR=0.000100
[2025-08-26 03:18:22,767][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021064] [Batch 01588/04869] [00:18:13/00:37:38, 0.688s/it]: train_loss_raw=1.7552, running_loss=1.7003, LR=0.000100
[2025-08-26 03:18:28,785][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021072] [Batch 01596/04869] [00:18:19/00:37:33, 0.689s/it]: train_loss_raw=1.8262, running_loss=1.7015, LR=0.000100
[2025-08-26 03:18:34,572][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021080] [Batch 01604/04869] [00:18:24/00:37:29, 0.689s/it]: train_loss_raw=1.6962, running_loss=1.6981, LR=0.000100
[2025-08-26 03:18:40,202][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021088] [Batch 01612/04869] [00:18:30/00:37:23, 0.689s/it]: train_loss_raw=1.6254, running_loss=1.6977, LR=0.000100
[2025-08-26 03:18:45,773][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021096] [Batch 01620/04869] [00:18:36/00:37:18, 0.689s/it]: train_loss_raw=1.6966, running_loss=1.6992, LR=0.000100
[2025-08-26 03:18:51,349][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021104] [Batch 01628/04869] [00:18:41/00:37:13, 0.689s/it]: train_loss_raw=1.7843, running_loss=1.7034, LR=0.000100
[2025-08-26 03:18:56,844][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021112] [Batch 01636/04869] [00:18:47/00:37:07, 0.689s/it]: train_loss_raw=1.6470, running_loss=1.6998, LR=0.000100
[2025-08-26 03:19:02,659][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021120] [Batch 01644/04869] [00:18:52/00:37:02, 0.689s/it]: train_loss_raw=1.6198, running_loss=1.6983, LR=0.000100
[2025-08-26 03:19:08,424][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021128] [Batch 01652/04869] [00:18:58/00:36:57, 0.689s/it]: train_loss_raw=1.7109, running_loss=1.6991, LR=0.000100
[2025-08-26 03:19:13,619][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021136] [Batch 01660/04869] [00:19:03/00:36:51, 0.689s/it]: train_loss_raw=1.7936, running_loss=1.7009, LR=0.000100
[2025-08-26 03:19:19,283][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021144] [Batch 01668/04869] [00:19:09/00:36:46, 0.689s/it]: train_loss_raw=1.6415, running_loss=1.7022, LR=0.000100
[2025-08-26 03:19:24,461][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021152] [Batch 01676/04869] [00:19:14/00:36:40, 0.689s/it]: train_loss_raw=1.7324, running_loss=1.7019, LR=0.000100
[2025-08-26 03:19:29,646][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021160] [Batch 01684/04869] [00:19:19/00:36:33, 0.689s/it]: train_loss_raw=1.6110, running_loss=1.6998, LR=0.000100
[2025-08-26 03:19:34,937][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021168] [Batch 01692/04869] [00:19:25/00:36:27, 0.689s/it]: train_loss_raw=1.6308, running_loss=1.7018, LR=0.000100
[2025-08-26 03:19:40,091][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021176] [Batch 01700/04869] [00:19:30/00:36:21, 0.688s/it]: train_loss_raw=1.7366, running_loss=1.7016, LR=0.000100
[2025-08-26 03:19:45,283][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021184] [Batch 01708/04869] [00:19:35/00:36:15, 0.688s/it]: train_loss_raw=1.7074, running_loss=1.7028, LR=0.000100
[2025-08-26 03:19:50,476][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021192] [Batch 01716/04869] [00:19:40/00:36:09, 0.688s/it]: train_loss_raw=1.6706, running_loss=1.7034, LR=0.000100
[2025-08-26 03:19:56,436][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021200] [Batch 01724/04869] [00:19:46/00:36:04, 0.688s/it]: train_loss_raw=1.7156, running_loss=1.7026, LR=0.000100
[2025-08-26 03:20:02,027][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021208] [Batch 01732/04869] [00:19:52/00:35:59, 0.688s/it]: train_loss_raw=1.6494, running_loss=1.7031, LR=0.000100
[2025-08-26 03:20:07,629][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021216] [Batch 01740/04869] [00:19:57/00:35:54, 0.688s/it]: train_loss_raw=1.7509, running_loss=1.7021, LR=0.000100
[2025-08-26 03:20:13,315][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021224] [Batch 01748/04869] [00:20:03/00:35:49, 0.689s/it]: train_loss_raw=1.6536, running_loss=1.7002, LR=0.000100
[2025-08-26 03:20:19,217][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021232] [Batch 01756/04869] [00:20:09/00:35:44, 0.689s/it]: train_loss_raw=1.7257, running_loss=1.6987, LR=0.000100
[2025-08-26 03:20:24,418][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021240] [Batch 01764/04869] [00:20:14/00:35:38, 0.689s/it]: train_loss_raw=1.6205, running_loss=1.6978, LR=0.000100
[2025-08-26 03:20:29,610][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021248] [Batch 01772/04869] [00:20:19/00:35:32, 0.688s/it]: train_loss_raw=1.6454, running_loss=1.6967, LR=0.000100
[2025-08-26 03:20:34,887][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021256] [Batch 01780/04869] [00:20:25/00:35:26, 0.688s/it]: train_loss_raw=1.6951, running_loss=1.6946, LR=0.000100
[2025-08-26 03:20:40,176][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021264] [Batch 01788/04869] [00:20:30/00:35:20, 0.688s/it]: train_loss_raw=1.6575, running_loss=1.6932, LR=0.000100
[2025-08-26 03:20:45,470][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021272] [Batch 01796/04869] [00:20:35/00:35:14, 0.688s/it]: train_loss_raw=1.6989, running_loss=1.6947, LR=0.000100
[2025-08-26 03:20:51,219][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021280] [Batch 01804/04869] [00:20:41/00:35:09, 0.688s/it]: train_loss_raw=1.7606, running_loss=1.6942, LR=0.000100
[2025-08-26 03:20:57,088][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021288] [Batch 01812/04869] [00:20:47/00:35:04, 0.688s/it]: train_loss_raw=1.6709, running_loss=1.6900, LR=0.000100
[2025-08-26 03:21:02,935][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021296] [Batch 01820/04869] [00:20:53/00:34:59, 0.689s/it]: train_loss_raw=1.6637, running_loss=1.6895, LR=0.000100
[2025-08-26 03:21:08,942][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021304] [Batch 01828/04869] [00:20:59/00:34:54, 0.689s/it]: train_loss_raw=1.7720, running_loss=1.6896, LR=0.000100
[2025-08-26 03:21:14,467][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021312] [Batch 01836/04869] [00:21:04/00:34:49, 0.689s/it]: train_loss_raw=1.7493, running_loss=1.6921, LR=0.000100
[2025-08-26 03:21:20,191][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021320] [Batch 01844/04869] [00:21:10/00:34:44, 0.689s/it]: train_loss_raw=1.5961, running_loss=1.6900, LR=0.000100
[2025-08-26 03:21:25,972][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021328] [Batch 01852/04869] [00:21:16/00:34:39, 0.689s/it]: train_loss_raw=1.7245, running_loss=1.6918, LR=0.000100
[2025-08-26 03:21:31,197][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021336] [Batch 01860/04869] [00:21:21/00:34:33, 0.689s/it]: train_loss_raw=1.7259, running_loss=1.6899, LR=0.000100
[2025-08-26 03:21:36,391][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021344] [Batch 01868/04869] [00:21:26/00:34:27, 0.689s/it]: train_loss_raw=1.7142, running_loss=1.6902, LR=0.000100
[2025-08-26 03:21:42,010][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021352] [Batch 01876/04869] [00:21:32/00:34:21, 0.689s/it]: train_loss_raw=1.6280, running_loss=1.6905, LR=0.000100
[2025-08-26 03:21:47,609][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021360] [Batch 01884/04869] [00:21:37/00:34:16, 0.689s/it]: train_loss_raw=1.6917, running_loss=1.6900, LR=0.000100
[2025-08-26 03:21:52,942][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021368] [Batch 01892/04869] [00:21:43/00:34:10, 0.689s/it]: train_loss_raw=1.6423, running_loss=1.6882, LR=0.000100
[2025-08-26 03:21:58,664][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021376] [Batch 01900/04869] [00:21:48/00:34:05, 0.689s/it]: train_loss_raw=1.6379, running_loss=1.6887, LR=0.000100
[2025-08-26 03:22:04,552][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021384] [Batch 01908/04869] [00:21:54/00:34:00, 0.689s/it]: train_loss_raw=1.6617, running_loss=1.6879, LR=0.000100
[2025-08-26 03:22:10,147][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021392] [Batch 01916/04869] [00:22:00/00:33:55, 0.689s/it]: train_loss_raw=1.5831, running_loss=1.6895, LR=0.000100
[2025-08-26 03:22:15,654][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021400] [Batch 01924/04869] [00:22:05/00:33:49, 0.689s/it]: train_loss_raw=1.7760, running_loss=1.6919, LR=0.000100
[2025-08-26 03:22:20,873][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021408] [Batch 01932/04869] [00:22:11/00:33:43, 0.689s/it]: train_loss_raw=1.6648, running_loss=1.6905, LR=0.000100
[2025-08-26 03:22:26,398][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021416] [Batch 01940/04869] [00:22:16/00:33:38, 0.689s/it]: train_loss_raw=1.7314, running_loss=1.6908, LR=0.000100
[2025-08-26 03:22:32,201][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021424] [Batch 01948/04869] [00:22:22/00:33:33, 0.689s/it]: train_loss_raw=1.6745, running_loss=1.6924, LR=0.000100
[2025-08-26 03:22:38,107][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021432] [Batch 01956/04869] [00:22:28/00:33:28, 0.689s/it]: train_loss_raw=1.7262, running_loss=1.6921, LR=0.000100
[2025-08-26 03:22:43,640][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021440] [Batch 01964/04869] [00:22:33/00:33:22, 0.689s/it]: train_loss_raw=1.6862, running_loss=1.6914, LR=0.000100
[2025-08-26 03:22:49,283][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021448] [Batch 01972/04869] [00:22:39/00:33:17, 0.689s/it]: train_loss_raw=1.7655, running_loss=1.6894, LR=0.000100
[2025-08-26 03:22:55,117][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021456] [Batch 01980/04869] [00:22:45/00:33:12, 0.690s/it]: train_loss_raw=1.6741, running_loss=1.6857, LR=0.000100
[2025-08-26 03:23:00,450][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021464] [Batch 01988/04869] [00:22:50/00:33:06, 0.690s/it]: train_loss_raw=1.6812, running_loss=1.6858, LR=0.000100
[2025-08-26 03:23:06,110][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021472] [Batch 01996/04869] [00:22:56/00:33:01, 0.690s/it]: train_loss_raw=1.7156, running_loss=1.6839, LR=0.000100
[2025-08-26 03:23:11,488][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021480] [Batch 02004/04869] [00:23:01/00:32:55, 0.690s/it]: train_loss_raw=1.6996, running_loss=1.6849, LR=0.000100
[2025-08-26 03:23:16,832][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021488] [Batch 02012/04869] [00:23:07/00:32:49, 0.689s/it]: train_loss_raw=1.8085, running_loss=1.6855, LR=0.000100
[2025-08-26 03:23:22,383][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021496] [Batch 02020/04869] [00:23:12/00:32:44, 0.689s/it]: train_loss_raw=1.6491, running_loss=1.6842, LR=0.000100
[2025-08-26 03:23:27,770][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021504] [Batch 02028/04869] [00:23:18/00:32:38, 0.689s/it]: train_loss_raw=1.6443, running_loss=1.6854, LR=0.000100
[2025-08-26 03:23:33,122][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021512] [Batch 02036/04869] [00:23:23/00:32:32, 0.689s/it]: train_loss_raw=1.7976, running_loss=1.6857, LR=0.000100
[2025-08-26 03:23:38,725][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021520] [Batch 02044/04869] [00:23:29/00:32:27, 0.689s/it]: train_loss_raw=1.5957, running_loss=1.6855, LR=0.000100
[2025-08-26 03:23:43,924][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021528] [Batch 02052/04869] [00:23:34/00:32:21, 0.689s/it]: train_loss_raw=1.7343, running_loss=1.6850, LR=0.000100
[2025-08-26 03:23:49,313][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021536] [Batch 02060/04869] [00:23:39/00:32:15, 0.689s/it]: train_loss_raw=1.6350, running_loss=1.6828, LR=0.000100
[2025-08-26 03:23:54,724][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021544] [Batch 02068/04869] [00:23:45/00:32:10, 0.689s/it]: train_loss_raw=1.5984, running_loss=1.6803, LR=0.000100
[2025-08-26 03:24:00,098][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021552] [Batch 02076/04869] [00:23:50/00:32:04, 0.689s/it]: train_loss_raw=1.7356, running_loss=1.6825, LR=0.000100
[2025-08-26 03:24:05,622][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021560] [Batch 02084/04869] [00:23:55/00:31:58, 0.689s/it]: train_loss_raw=1.7116, running_loss=1.6823, LR=0.000100
[2025-08-26 03:24:11,157][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021568] [Batch 02092/04869] [00:24:01/00:31:53, 0.689s/it]: train_loss_raw=1.6643, running_loss=1.6816, LR=0.000100
[2025-08-26 03:24:16,381][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021576] [Batch 02100/04869] [00:24:06/00:31:47, 0.689s/it]: train_loss_raw=1.6588, running_loss=1.6808, LR=0.000100
[2025-08-26 03:24:21,604][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021584] [Batch 02108/04869] [00:24:11/00:31:41, 0.689s/it]: train_loss_raw=1.7505, running_loss=1.6803, LR=0.000100
[2025-08-26 03:24:26,792][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021592] [Batch 02116/04869] [00:24:17/00:31:35, 0.689s/it]: train_loss_raw=1.6233, running_loss=1.6785, LR=0.000100
[2025-08-26 03:24:32,341][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021600] [Batch 02124/04869] [00:24:22/00:31:30, 0.689s/it]: train_loss_raw=1.6730, running_loss=1.6754, LR=0.000100
[2025-08-26 03:24:37,704][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021608] [Batch 02132/04869] [00:24:28/00:31:24, 0.689s/it]: train_loss_raw=1.7332, running_loss=1.6775, LR=0.000100
[2025-08-26 03:24:43,015][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021616] [Batch 02140/04869] [00:24:33/00:31:18, 0.688s/it]: train_loss_raw=1.6405, running_loss=1.6775, LR=0.000100
[2025-08-26 03:24:48,243][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021624] [Batch 02148/04869] [00:24:38/00:31:12, 0.688s/it]: train_loss_raw=1.6454, running_loss=1.6754, LR=0.000100
[2025-08-26 03:24:53,491][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021632] [Batch 02156/04869] [00:24:43/00:31:07, 0.688s/it]: train_loss_raw=1.7138, running_loss=1.6764, LR=0.000100
[2025-08-26 03:24:58,781][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021640] [Batch 02164/04869] [00:24:49/00:31:01, 0.688s/it]: train_loss_raw=1.7892, running_loss=1.6766, LR=0.000100
[2025-08-26 03:25:04,334][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021648] [Batch 02172/04869] [00:24:54/00:30:55, 0.688s/it]: train_loss_raw=1.6455, running_loss=1.6757, LR=0.000100
[2025-08-26 03:25:09,831][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021656] [Batch 02180/04869] [00:25:00/00:30:50, 0.688s/it]: train_loss_raw=1.6186, running_loss=1.6747, LR=0.000100
[2025-08-26 03:25:15,333][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021664] [Batch 02188/04869] [00:25:05/00:30:44, 0.688s/it]: train_loss_raw=1.8028, running_loss=1.6745, LR=0.000100
[2025-08-26 03:25:20,522][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021672] [Batch 02196/04869] [00:25:10/00:30:39, 0.688s/it]: train_loss_raw=1.5996, running_loss=1.6739, LR=0.000100
[2025-08-26 03:25:25,747][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021680] [Batch 02204/04869] [00:25:16/00:30:33, 0.688s/it]: train_loss_raw=1.6190, running_loss=1.6766, LR=0.000100
[2025-08-26 03:25:31,096][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021688] [Batch 02212/04869] [00:25:21/00:30:27, 0.688s/it]: train_loss_raw=1.6747, running_loss=1.6761, LR=0.000100
[2025-08-26 03:25:36,397][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021696] [Batch 02220/04869] [00:25:26/00:30:21, 0.688s/it]: train_loss_raw=1.6555, running_loss=1.6756, LR=0.000100
[2025-08-26 03:25:41,679][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021704] [Batch 02228/04869] [00:25:31/00:30:15, 0.688s/it]: train_loss_raw=1.6694, running_loss=1.6763, LR=0.000100
[2025-08-26 03:25:47,035][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021712] [Batch 02236/04869] [00:25:37/00:30:10, 0.688s/it]: train_loss_raw=1.7261, running_loss=1.6765, LR=0.000100
[2025-08-26 03:25:52,817][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021720] [Batch 02244/04869] [00:25:43/00:30:05, 0.688s/it]: train_loss_raw=1.6745, running_loss=1.6745, LR=0.000100
[2025-08-26 03:25:58,553][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021728] [Batch 02252/04869] [00:25:48/00:29:59, 0.688s/it]: train_loss_raw=1.6455, running_loss=1.6744, LR=0.000100
[2025-08-26 03:26:04,079][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021736] [Batch 02260/04869] [00:25:54/00:29:54, 0.688s/it]: train_loss_raw=1.7177, running_loss=1.6736, LR=0.000100
[2025-08-26 03:26:09,885][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021744] [Batch 02268/04869] [00:26:00/00:29:49, 0.688s/it]: train_loss_raw=1.6780, running_loss=1.6741, LR=0.000100
[2025-08-26 03:26:15,084][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021752] [Batch 02276/04869] [00:26:05/00:29:43, 0.688s/it]: train_loss_raw=1.6372, running_loss=1.6736, LR=0.000100
[2025-08-26 03:26:20,329][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021760] [Batch 02284/04869] [00:26:10/00:29:37, 0.688s/it]: train_loss_raw=1.6760, running_loss=1.6737, LR=0.000100
[2025-08-26 03:26:25,532][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021768] [Batch 02292/04869] [00:26:15/00:29:31, 0.688s/it]: train_loss_raw=1.6486, running_loss=1.6739, LR=0.000100
[2025-08-26 03:26:30,768][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021776] [Batch 02300/04869] [00:26:21/00:29:26, 0.687s/it]: train_loss_raw=1.6977, running_loss=1.6730, LR=0.000100
[2025-08-26 03:26:35,963][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021784] [Batch 02308/04869] [00:26:26/00:29:20, 0.687s/it]: train_loss_raw=1.6764, running_loss=1.6725, LR=0.000100
[2025-08-26 03:26:41,176][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021792] [Batch 02316/04869] [00:26:31/00:29:14, 0.687s/it]: train_loss_raw=1.6547, running_loss=1.6694, LR=0.000100
[2025-08-26 03:26:46,416][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021800] [Batch 02324/04869] [00:26:36/00:29:08, 0.687s/it]: train_loss_raw=1.5642, running_loss=1.6680, LR=0.000100
[2025-08-26 03:26:51,667][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021808] [Batch 02332/04869] [00:26:41/00:29:02, 0.687s/it]: train_loss_raw=1.6606, running_loss=1.6670, LR=0.000100
[2025-08-26 03:26:57,555][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021816] [Batch 02340/04869] [00:26:47/00:28:57, 0.687s/it]: train_loss_raw=1.6928, running_loss=1.6668, LR=0.000100
[2025-08-26 03:27:02,862][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021824] [Batch 02348/04869] [00:26:53/00:28:52, 0.687s/it]: train_loss_raw=1.6487, running_loss=1.6674, LR=0.000100
[2025-08-26 03:27:08,112][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021832] [Batch 02356/04869] [00:26:58/00:28:46, 0.687s/it]: train_loss_raw=1.6076, running_loss=1.6666, LR=0.000100
[2025-08-26 03:27:13,704][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021840] [Batch 02364/04869] [00:27:04/00:28:40, 0.687s/it]: train_loss_raw=1.5556, running_loss=1.6660, LR=0.000100
[2025-08-26 03:27:18,941][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021848] [Batch 02372/04869] [00:27:09/00:28:35, 0.687s/it]: train_loss_raw=1.6927, running_loss=1.6725, LR=0.000100
[2025-08-26 03:27:24,712][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021856] [Batch 02380/04869] [00:27:15/00:28:29, 0.687s/it]: train_loss_raw=1.7311, running_loss=1.6744, LR=0.000100
[2025-08-26 03:27:30,296][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021864] [Batch 02388/04869] [00:27:20/00:28:24, 0.687s/it]: train_loss_raw=1.6956, running_loss=1.6754, LR=0.000100
[2025-08-26 03:27:35,908][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021872] [Batch 02396/04869] [00:27:26/00:28:19, 0.687s/it]: train_loss_raw=1.5810, running_loss=1.6740, LR=0.000100
[2025-08-26 03:27:41,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021880] [Batch 02404/04869] [00:27:31/00:28:13, 0.687s/it]: train_loss_raw=1.6341, running_loss=1.6719, LR=0.000100
[2025-08-26 03:27:47,075][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021888] [Batch 02412/04869] [00:27:37/00:28:08, 0.687s/it]: train_loss_raw=1.7430, running_loss=1.6763, LR=0.000100
[2025-08-26 03:27:52,783][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021896] [Batch 02420/04869] [00:27:43/00:28:03, 0.687s/it]: train_loss_raw=1.6326, running_loss=1.6753, LR=0.000100
[2025-08-26 03:27:58,644][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021904] [Batch 02428/04869] [00:27:48/00:27:57, 0.687s/it]: train_loss_raw=1.5835, running_loss=1.6733, LR=0.000100
[2025-08-26 03:28:04,552][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021912] [Batch 02436/04869] [00:27:54/00:27:52, 0.688s/it]: train_loss_raw=1.5227, running_loss=1.6723, LR=0.000100
[2025-08-26 03:28:10,859][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021920] [Batch 02444/04869] [00:28:01/00:27:48, 0.688s/it]: train_loss_raw=1.6245, running_loss=1.6717, LR=0.000100
[2025-08-26 03:28:17,061][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021928] [Batch 02452/04869] [00:28:07/00:27:43, 0.688s/it]: train_loss_raw=1.7416, running_loss=1.6703, LR=0.000100
[2025-08-26 03:28:22,806][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021936] [Batch 02460/04869] [00:28:13/00:27:38, 0.688s/it]: train_loss_raw=1.6804, running_loss=1.6699, LR=0.000100
[2025-08-26 03:28:28,396][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021944] [Batch 02468/04869] [00:28:18/00:27:32, 0.688s/it]: train_loss_raw=1.6359, running_loss=1.6715, LR=0.000100
[2025-08-26 03:28:33,982][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021952] [Batch 02476/04869] [00:28:24/00:27:27, 0.688s/it]: train_loss_raw=1.5965, running_loss=1.6684, LR=0.000100
[2025-08-26 03:28:39,260][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021960] [Batch 02484/04869] [00:28:29/00:27:21, 0.688s/it]: train_loss_raw=1.7109, running_loss=1.6662, LR=0.000100
[2025-08-26 03:28:44,739][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021968] [Batch 02492/04869] [00:28:35/00:27:15, 0.688s/it]: train_loss_raw=1.5629, running_loss=1.6661, LR=0.000100
[2025-08-26 03:28:50,372][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021976] [Batch 02500/04869] [00:28:40/00:27:10, 0.688s/it]: train_loss_raw=1.6710, running_loss=1.6657, LR=0.000100
[2025-08-26 03:28:55,597][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021984] [Batch 02508/04869] [00:28:45/00:27:04, 0.688s/it]: train_loss_raw=1.6683, running_loss=1.6649, LR=0.000100
[2025-08-26 03:29:01,002][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 021992] [Batch 02516/04869] [00:28:51/00:26:59, 0.688s/it]: train_loss_raw=1.6241, running_loss=1.6650, LR=0.000100
[2025-08-26 03:29:06,215][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022000] [Batch 02524/04869] [00:28:56/00:26:53, 0.688s/it]: train_loss_raw=1.5675, running_loss=1.6637, LR=0.000100
[2025-08-26 03:29:15,585][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022008] [Batch 02532/04869] [00:29:05/00:26:51, 0.690s/it]: train_loss_raw=1.6171, running_loss=1.6629, LR=0.000100
[2025-08-26 03:29:20,868][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022016] [Batch 02540/04869] [00:29:11/00:26:45, 0.689s/it]: train_loss_raw=1.6338, running_loss=1.6613, LR=0.000100
[2025-08-26 03:29:26,067][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022024] [Batch 02548/04869] [00:29:16/00:26:39, 0.689s/it]: train_loss_raw=1.5827, running_loss=1.6592, LR=0.000100
[2025-08-26 03:29:31,259][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022032] [Batch 02556/04869] [00:29:21/00:26:34, 0.689s/it]: train_loss_raw=1.5964, running_loss=1.6594, LR=0.000100
[2025-08-26 03:29:36,709][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022040] [Batch 02564/04869] [00:29:27/00:26:28, 0.689s/it]: train_loss_raw=1.7055, running_loss=1.6607, LR=0.000100
[2025-08-26 03:29:42,388][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022048] [Batch 02572/04869] [00:29:32/00:26:23, 0.689s/it]: train_loss_raw=1.6543, running_loss=1.6608, LR=0.000100
[2025-08-26 03:29:47,558][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022056] [Batch 02580/04869] [00:29:37/00:26:17, 0.689s/it]: train_loss_raw=1.6146, running_loss=1.6568, LR=0.000100
[2025-08-26 03:29:53,161][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022064] [Batch 02588/04869] [00:29:43/00:26:11, 0.689s/it]: train_loss_raw=1.6261, running_loss=1.6563, LR=0.000100
[2025-08-26 03:29:58,843][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022072] [Batch 02596/04869] [00:29:49/00:26:06, 0.689s/it]: train_loss_raw=1.7237, running_loss=1.6569, LR=0.000100
[2025-08-26 03:30:04,337][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022080] [Batch 02604/04869] [00:29:54/00:26:01, 0.689s/it]: train_loss_raw=1.7530, running_loss=1.6559, LR=0.000100
[2025-08-26 03:30:09,535][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022088] [Batch 02612/04869] [00:29:59/00:25:55, 0.689s/it]: train_loss_raw=1.6871, running_loss=1.6545, LR=0.000100
[2025-08-26 03:30:14,697][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022096] [Batch 02620/04869] [00:30:05/00:25:49, 0.689s/it]: train_loss_raw=1.5516, running_loss=1.6498, LR=0.000100
[2025-08-26 03:30:19,905][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022104] [Batch 02628/04869] [00:30:10/00:25:43, 0.689s/it]: train_loss_raw=1.6605, running_loss=1.6499, LR=0.000100
[2025-08-26 03:30:25,090][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022112] [Batch 02636/04869] [00:30:15/00:25:37, 0.689s/it]: train_loss_raw=1.7379, running_loss=1.6502, LR=0.000100
[2025-08-26 03:30:30,715][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022120] [Batch 02644/04869] [00:30:21/00:25:32, 0.689s/it]: train_loss_raw=1.5540, running_loss=1.6522, LR=0.000100
[2025-08-26 03:30:36,226][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022128] [Batch 02652/04869] [00:30:26/00:25:26, 0.689s/it]: train_loss_raw=1.7286, running_loss=1.6554, LR=0.000100
[2025-08-26 03:30:41,920][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022136] [Batch 02660/04869] [00:30:32/00:25:21, 0.689s/it]: train_loss_raw=1.6278, running_loss=1.6570, LR=0.000100
[2025-08-26 03:30:47,600][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022144] [Batch 02668/04869] [00:30:37/00:25:16, 0.689s/it]: train_loss_raw=1.6726, running_loss=1.6605, LR=0.000100
[2025-08-26 03:30:52,782][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022152] [Batch 02676/04869] [00:30:43/00:25:10, 0.689s/it]: train_loss_raw=1.6190, running_loss=1.6621, LR=0.000100
[2025-08-26 03:30:57,956][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022160] [Batch 02684/04869] [00:30:48/00:25:04, 0.689s/it]: train_loss_raw=1.6429, running_loss=1.6610, LR=0.000100
[2025-08-26 03:31:03,162][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022168] [Batch 02692/04869] [00:30:53/00:24:58, 0.689s/it]: train_loss_raw=1.6400, running_loss=1.6604, LR=0.000100
[2025-08-26 03:31:08,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022176] [Batch 02700/04869] [00:30:58/00:24:53, 0.688s/it]: train_loss_raw=1.6633, running_loss=1.6591, LR=0.000100
[2025-08-26 03:31:13,917][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022184] [Batch 02708/04869] [00:31:04/00:24:47, 0.688s/it]: train_loss_raw=1.6834, running_loss=1.6585, LR=0.000100
[2025-08-26 03:31:19,162][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022192] [Batch 02716/04869] [00:31:09/00:24:41, 0.688s/it]: train_loss_raw=1.6555, running_loss=1.6576, LR=0.000100
[2025-08-26 03:31:24,395][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022200] [Batch 02724/04869] [00:31:14/00:24:36, 0.688s/it]: train_loss_raw=1.6210, running_loss=1.6567, LR=0.000100
[2025-08-26 03:31:29,963][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022208] [Batch 02732/04869] [00:31:20/00:24:30, 0.688s/it]: train_loss_raw=1.6857, running_loss=1.6542, LR=0.000100
[2025-08-26 03:31:35,492][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022216] [Batch 02740/04869] [00:31:25/00:24:25, 0.688s/it]: train_loss_raw=1.6045, running_loss=1.6548, LR=0.000100
[2025-08-26 03:31:41,351][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022224] [Batch 02748/04869] [00:31:31/00:24:20, 0.688s/it]: train_loss_raw=1.6204, running_loss=1.6558, LR=0.000100
[2025-08-26 03:31:47,324][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022232] [Batch 02756/04869] [00:31:37/00:24:14, 0.689s/it]: train_loss_raw=1.5835, running_loss=1.6551, LR=0.000100
[2025-08-26 03:31:52,822][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022240] [Batch 02764/04869] [00:31:43/00:24:09, 0.689s/it]: train_loss_raw=1.6400, running_loss=1.6545, LR=0.000100
[2025-08-26 03:31:58,154][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022248] [Batch 02772/04869] [00:31:48/00:24:03, 0.688s/it]: train_loss_raw=1.6464, running_loss=1.6557, LR=0.000100
[2025-08-26 03:32:03,484][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022256] [Batch 02780/04869] [00:31:53/00:23:58, 0.688s/it]: train_loss_raw=1.6656, running_loss=1.6565, LR=0.000100
[2025-08-26 03:32:08,988][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022264] [Batch 02788/04869] [00:31:59/00:23:52, 0.688s/it]: train_loss_raw=1.6398, running_loss=1.6556, LR=0.000100
[2025-08-26 03:32:14,588][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022272] [Batch 02796/04869] [00:32:04/00:23:47, 0.688s/it]: train_loss_raw=1.6180, running_loss=1.6559, LR=0.000100
[2025-08-26 03:32:20,560][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022280] [Batch 02804/04869] [00:32:10/00:23:41, 0.689s/it]: train_loss_raw=1.5943, running_loss=1.6571, LR=0.000100
[2025-08-26 03:32:26,736][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022288] [Batch 02812/04869] [00:32:17/00:23:36, 0.689s/it]: train_loss_raw=1.6851, running_loss=1.6572, LR=0.000100
[2025-08-26 03:32:32,680][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022296] [Batch 02820/04869] [00:32:22/00:23:31, 0.689s/it]: train_loss_raw=1.6231, running_loss=1.6577, LR=0.000100
[2025-08-26 03:32:38,374][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022304] [Batch 02828/04869] [00:32:28/00:23:26, 0.689s/it]: train_loss_raw=1.5857, running_loss=1.6580, LR=0.000100
[2025-08-26 03:32:43,894][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022312] [Batch 02836/04869] [00:32:34/00:23:20, 0.689s/it]: train_loss_raw=1.6568, running_loss=1.6577, LR=0.000100
[2025-08-26 03:32:49,226][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022320] [Batch 02844/04869] [00:32:39/00:23:15, 0.689s/it]: train_loss_raw=1.6388, running_loss=1.6571, LR=0.000100
[2025-08-26 03:32:54,848][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022328] [Batch 02852/04869] [00:32:45/00:23:09, 0.689s/it]: train_loss_raw=1.6147, running_loss=1.6565, LR=0.000100
[2025-08-26 03:33:00,753][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022336] [Batch 02860/04869] [00:32:51/00:23:04, 0.689s/it]: train_loss_raw=1.5912, running_loss=1.6546, LR=0.000100
[2025-08-26 03:33:05,956][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022344] [Batch 02868/04869] [00:32:56/00:22:58, 0.689s/it]: train_loss_raw=1.6367, running_loss=1.6560, LR=0.000100
[2025-08-26 03:33:11,833][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022352] [Batch 02876/04869] [00:33:02/00:22:53, 0.689s/it]: train_loss_raw=1.6401, running_loss=1.6540, LR=0.000100
[2025-08-26 03:33:17,759][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022360] [Batch 02884/04869] [00:33:08/00:22:48, 0.689s/it]: train_loss_raw=1.7363, running_loss=1.6555, LR=0.000100
[2025-08-26 03:33:23,564][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022368] [Batch 02892/04869] [00:33:13/00:22:43, 0.689s/it]: train_loss_raw=1.6380, running_loss=1.6554, LR=0.000100
[2025-08-26 03:33:28,781][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022376] [Batch 02900/04869] [00:33:19/00:22:37, 0.689s/it]: train_loss_raw=1.7053, running_loss=1.6554, LR=0.000100
[2025-08-26 03:33:34,378][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022384] [Batch 02908/04869] [00:33:24/00:22:31, 0.689s/it]: train_loss_raw=1.6933, running_loss=1.6564, LR=0.000100
[2025-08-26 03:33:39,687][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022392] [Batch 02916/04869] [00:33:30/00:22:26, 0.689s/it]: train_loss_raw=1.7347, running_loss=1.6573, LR=0.000100
[2025-08-26 03:33:45,070][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022400] [Batch 02924/04869] [00:33:35/00:22:20, 0.689s/it]: train_loss_raw=1.6722, running_loss=1.6573, LR=0.000100
[2025-08-26 03:33:50,640][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022408] [Batch 02932/04869] [00:33:40/00:22:15, 0.689s/it]: train_loss_raw=1.5799, running_loss=1.6578, LR=0.000100
[2025-08-26 03:33:56,189][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022416] [Batch 02940/04869] [00:33:46/00:22:09, 0.689s/it]: train_loss_raw=1.5770, running_loss=1.6579, LR=0.000100
[2025-08-26 03:34:01,944][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022424] [Batch 02948/04869] [00:33:52/00:22:04, 0.689s/it]: train_loss_raw=1.6630, running_loss=1.6555, LR=0.000100
[2025-08-26 03:34:07,584][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022432] [Batch 02956/04869] [00:33:57/00:21:58, 0.689s/it]: train_loss_raw=1.6442, running_loss=1.6565, LR=0.000100
[2025-08-26 03:34:12,787][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022440] [Batch 02964/04869] [00:34:03/00:21:53, 0.689s/it]: train_loss_raw=1.5895, running_loss=1.6557, LR=0.000100
[2025-08-26 03:34:18,009][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022448] [Batch 02972/04869] [00:34:08/00:21:47, 0.689s/it]: train_loss_raw=1.6061, running_loss=1.6559, LR=0.000100
[2025-08-26 03:34:23,766][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022456] [Batch 02980/04869] [00:34:14/00:21:42, 0.689s/it]: train_loss_raw=1.5509, running_loss=1.6536, LR=0.000100
[2025-08-26 03:34:29,265][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022464] [Batch 02988/04869] [00:34:19/00:21:36, 0.689s/it]: train_loss_raw=1.6352, running_loss=1.6526, LR=0.000100
[2025-08-26 03:34:34,538][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022472] [Batch 02996/04869] [00:34:24/00:21:30, 0.689s/it]: train_loss_raw=1.7021, running_loss=1.6540, LR=0.000100
[2025-08-26 03:34:40,013][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022480] [Batch 03004/04869] [00:34:30/00:21:25, 0.689s/it]: train_loss_raw=1.5759, running_loss=1.6546, LR=0.000100
[2025-08-26 03:34:45,398][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022488] [Batch 03012/04869] [00:34:35/00:21:19, 0.689s/it]: train_loss_raw=1.6807, running_loss=1.6547, LR=0.000100
[2025-08-26 03:34:50,636][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022496] [Batch 03020/04869] [00:34:40/00:21:14, 0.689s/it]: train_loss_raw=1.6420, running_loss=1.6539, LR=0.000100
[2025-08-26 03:34:55,903][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022504] [Batch 03028/04869] [00:34:46/00:21:08, 0.689s/it]: train_loss_raw=1.6007, running_loss=1.6517, LR=0.000100
[2025-08-26 03:35:01,186][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022512] [Batch 03036/04869] [00:34:51/00:21:02, 0.689s/it]: train_loss_raw=1.6353, running_loss=1.6493, LR=0.000100
[2025-08-26 03:35:06,431][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022520] [Batch 03044/04869] [00:34:56/00:20:57, 0.689s/it]: train_loss_raw=1.6432, running_loss=1.6481, LR=0.000100
[2025-08-26 03:35:12,301][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022528] [Batch 03052/04869] [00:35:02/00:20:51, 0.689s/it]: train_loss_raw=1.6691, running_loss=1.6487, LR=0.000100
[2025-08-26 03:35:17,521][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022536] [Batch 03060/04869] [00:35:07/00:20:46, 0.689s/it]: train_loss_raw=1.6251, running_loss=1.6480, LR=0.000100
[2025-08-26 03:35:22,718][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022544] [Batch 03068/04869] [00:35:13/00:20:40, 0.689s/it]: train_loss_raw=1.6818, running_loss=1.6502, LR=0.000100
[2025-08-26 03:35:28,405][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022552] [Batch 03076/04869] [00:35:18/00:20:35, 0.689s/it]: train_loss_raw=1.6265, running_loss=1.6523, LR=0.000100
[2025-08-26 03:35:33,795][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022560] [Batch 03084/04869] [00:35:24/00:20:29, 0.689s/it]: train_loss_raw=1.6384, running_loss=1.6527, LR=0.000100
[2025-08-26 03:35:39,376][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022568] [Batch 03092/04869] [00:35:29/00:20:23, 0.689s/it]: train_loss_raw=1.6331, running_loss=1.6500, LR=0.000100
[2025-08-26 03:35:44,606][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022576] [Batch 03100/04869] [00:35:34/00:20:18, 0.689s/it]: train_loss_raw=1.6666, running_loss=1.6513, LR=0.000100
[2025-08-26 03:35:50,144][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022584] [Batch 03108/04869] [00:35:40/00:20:12, 0.689s/it]: train_loss_raw=1.5601, running_loss=1.6519, LR=0.000100
[2025-08-26 03:35:55,889][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022592] [Batch 03116/04869] [00:35:46/00:20:07, 0.689s/it]: train_loss_raw=1.6964, running_loss=1.6545, LR=0.000100
[2025-08-26 03:36:02,109][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022600] [Batch 03124/04869] [00:35:52/00:20:02, 0.689s/it]: train_loss_raw=1.7405, running_loss=1.6566, LR=0.000100
[2025-08-26 03:36:08,153][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022608] [Batch 03132/04869] [00:35:58/00:19:57, 0.689s/it]: train_loss_raw=1.6491, running_loss=1.6549, LR=0.000100
[2025-08-26 03:36:13,542][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022616] [Batch 03140/04869] [00:36:03/00:19:51, 0.689s/it]: train_loss_raw=1.6991, running_loss=1.6544, LR=0.000100
[2025-08-26 03:36:19,269][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022624] [Batch 03148/04869] [00:36:09/00:19:46, 0.689s/it]: train_loss_raw=1.5947, running_loss=1.6534, LR=0.000100
[2025-08-26 03:36:24,667][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022632] [Batch 03156/04869] [00:36:14/00:19:40, 0.689s/it]: train_loss_raw=1.6758, running_loss=1.6510, LR=0.000100
[2025-08-26 03:36:30,805][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022640] [Batch 03164/04869] [00:36:21/00:19:35, 0.689s/it]: train_loss_raw=1.6288, running_loss=1.6516, LR=0.000100
[2025-08-26 03:36:36,466][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022648] [Batch 03172/04869] [00:36:26/00:19:29, 0.689s/it]: train_loss_raw=1.6323, running_loss=1.6504, LR=0.000100
[2025-08-26 03:36:41,944][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022656] [Batch 03180/04869] [00:36:32/00:19:24, 0.689s/it]: train_loss_raw=1.5800, running_loss=1.6486, LR=0.000100
[2025-08-26 03:36:47,250][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022664] [Batch 03188/04869] [00:36:37/00:19:18, 0.689s/it]: train_loss_raw=1.6977, running_loss=1.6473, LR=0.000100
[2025-08-26 03:36:52,756][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022672] [Batch 03196/04869] [00:36:43/00:19:13, 0.689s/it]: train_loss_raw=1.6795, running_loss=1.6469, LR=0.000100
[2025-08-26 03:36:57,927][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022680] [Batch 03204/04869] [00:36:48/00:19:07, 0.689s/it]: train_loss_raw=1.7442, running_loss=1.6459, LR=0.000100
[2025-08-26 03:37:03,710][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022688] [Batch 03212/04869] [00:36:54/00:19:02, 0.689s/it]: train_loss_raw=1.6190, running_loss=1.6456, LR=0.000100
[2025-08-26 03:37:09,261][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022696] [Batch 03220/04869] [00:36:59/00:18:56, 0.689s/it]: train_loss_raw=1.6211, running_loss=1.6463, LR=0.000100
[2025-08-26 03:37:14,801][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022704] [Batch 03228/04869] [00:37:05/00:18:51, 0.689s/it]: train_loss_raw=1.6447, running_loss=1.6424, LR=0.000100
[2025-08-26 03:37:20,741][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022712] [Batch 03236/04869] [00:37:11/00:18:45, 0.689s/it]: train_loss_raw=1.6618, running_loss=1.6415, LR=0.000100
[2025-08-26 03:37:26,031][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022720] [Batch 03244/04869] [00:37:16/00:18:40, 0.689s/it]: train_loss_raw=1.6166, running_loss=1.6395, LR=0.000100
[2025-08-26 03:37:31,720][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022728] [Batch 03252/04869] [00:37:22/00:18:34, 0.689s/it]: train_loss_raw=1.6327, running_loss=1.6370, LR=0.000100
[2025-08-26 03:37:37,255][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022736] [Batch 03260/04869] [00:37:27/00:18:29, 0.689s/it]: train_loss_raw=1.5763, running_loss=1.6373, LR=0.000100
[2025-08-26 03:37:42,606][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022744] [Batch 03268/04869] [00:37:32/00:18:23, 0.689s/it]: train_loss_raw=1.5627, running_loss=1.6370, LR=0.000100
[2025-08-26 03:37:48,028][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022752] [Batch 03276/04869] [00:37:38/00:18:18, 0.689s/it]: train_loss_raw=1.5911, running_loss=1.6367, LR=0.000100
[2025-08-26 03:37:53,623][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022760] [Batch 03284/04869] [00:37:43/00:18:12, 0.689s/it]: train_loss_raw=1.5084, running_loss=1.6333, LR=0.000100
[2025-08-26 03:37:59,113][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022768] [Batch 03292/04869] [00:37:49/00:18:07, 0.689s/it]: train_loss_raw=1.6549, running_loss=1.6342, LR=0.000100
[2025-08-26 03:38:05,083][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022776] [Batch 03300/04869] [00:37:55/00:18:01, 0.690s/it]: train_loss_raw=1.7669, running_loss=1.6313, LR=0.000100
[2025-08-26 03:38:11,246][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022784] [Batch 03308/04869] [00:38:01/00:17:56, 0.690s/it]: train_loss_raw=1.7168, running_loss=1.6338, LR=0.000100
[2025-08-26 03:38:16,816][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022792] [Batch 03316/04869] [00:38:07/00:17:51, 0.690s/it]: train_loss_raw=1.6544, running_loss=1.6324, LR=0.000100
[2025-08-26 03:38:22,029][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022800] [Batch 03324/04869] [00:38:12/00:17:45, 0.690s/it]: train_loss_raw=1.6630, running_loss=1.6327, LR=0.000100
[2025-08-26 03:38:27,229][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022808] [Batch 03332/04869] [00:38:17/00:17:39, 0.690s/it]: train_loss_raw=1.6018, running_loss=1.6336, LR=0.000100
[2025-08-26 03:38:32,481][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022816] [Batch 03340/04869] [00:38:22/00:17:34, 0.689s/it]: train_loss_raw=1.5887, running_loss=1.6341, LR=0.000100
[2025-08-26 03:38:38,539][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022824] [Batch 03348/04869] [00:38:28/00:17:28, 0.690s/it]: train_loss_raw=1.6479, running_loss=1.6341, LR=0.000100
[2025-08-26 03:38:44,158][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022832] [Batch 03356/04869] [00:38:34/00:17:23, 0.690s/it]: train_loss_raw=1.6531, running_loss=1.6327, LR=0.000100
[2025-08-26 03:38:49,376][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022840] [Batch 03364/04869] [00:38:39/00:17:17, 0.690s/it]: train_loss_raw=1.5828, running_loss=1.6322, LR=0.000100
[2025-08-26 03:38:54,562][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022848] [Batch 03372/04869] [00:38:44/00:17:12, 0.689s/it]: train_loss_raw=1.7111, running_loss=1.6340, LR=0.000100
[2025-08-26 03:38:59,735][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022856] [Batch 03380/04869] [00:38:50/00:17:06, 0.689s/it]: train_loss_raw=1.6389, running_loss=1.6326, LR=0.000100
[2025-08-26 03:39:05,191][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022864] [Batch 03388/04869] [00:38:55/00:17:00, 0.689s/it]: train_loss_raw=1.5154, running_loss=1.6324, LR=0.000100
[2025-08-26 03:39:11,031][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022872] [Batch 03396/04869] [00:39:01/00:16:55, 0.689s/it]: train_loss_raw=1.6297, running_loss=1.6349, LR=0.000100
[2025-08-26 03:39:16,255][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022880] [Batch 03404/04869] [00:39:06/00:16:49, 0.689s/it]: train_loss_raw=1.5966, running_loss=1.6332, LR=0.000100
[2025-08-26 03:39:21,608][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022888] [Batch 03412/04869] [00:39:11/00:16:44, 0.689s/it]: train_loss_raw=1.5785, running_loss=1.6315, LR=0.000100
[2025-08-26 03:39:27,079][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022896] [Batch 03420/04869] [00:39:17/00:16:38, 0.689s/it]: train_loss_raw=1.6908, running_loss=1.6321, LR=0.000100
[2025-08-26 03:39:32,410][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022904] [Batch 03428/04869] [00:39:22/00:16:33, 0.689s/it]: train_loss_raw=1.6046, running_loss=1.6301, LR=0.000100
[2025-08-26 03:39:37,820][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022912] [Batch 03436/04869] [00:39:28/00:16:27, 0.689s/it]: train_loss_raw=1.6586, running_loss=1.6307, LR=0.000100
[2025-08-26 03:39:43,049][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022920] [Batch 03444/04869] [00:39:33/00:16:22, 0.689s/it]: train_loss_raw=1.5857, running_loss=1.6303, LR=0.000100
[2025-08-26 03:39:48,401][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022928] [Batch 03452/04869] [00:39:38/00:16:16, 0.689s/it]: train_loss_raw=1.5655, running_loss=1.6317, LR=0.000100
[2025-08-26 03:39:54,130][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022936] [Batch 03460/04869] [00:39:44/00:16:11, 0.689s/it]: train_loss_raw=1.5374, running_loss=1.6307, LR=0.000100
[2025-08-26 03:39:59,643][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022944] [Batch 03468/04869] [00:39:49/00:16:05, 0.689s/it]: train_loss_raw=1.5955, running_loss=1.6311, LR=0.000100
[2025-08-26 03:40:05,255][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022952] [Batch 03476/04869] [00:39:55/00:16:00, 0.689s/it]: train_loss_raw=1.6406, running_loss=1.6304, LR=0.000100
[2025-08-26 03:40:10,467][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022960] [Batch 03484/04869] [00:40:00/00:15:54, 0.689s/it]: train_loss_raw=1.5417, running_loss=1.6314, LR=0.000100
[2025-08-26 03:40:15,952][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022968] [Batch 03492/04869] [00:40:06/00:15:48, 0.689s/it]: train_loss_raw=1.6575, running_loss=1.6321, LR=0.000100
[2025-08-26 03:40:21,514][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022976] [Batch 03500/04869] [00:40:11/00:15:43, 0.689s/it]: train_loss_raw=1.5993, running_loss=1.6322, LR=0.000100
[2025-08-26 03:40:27,494][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022984] [Batch 03508/04869] [00:40:17/00:15:38, 0.689s/it]: train_loss_raw=1.5695, running_loss=1.6323, LR=0.000100
[2025-08-26 03:40:32,736][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 022992] [Batch 03516/04869] [00:40:23/00:15:32, 0.689s/it]: train_loss_raw=1.5595, running_loss=1.6340, LR=0.000100
[2025-08-26 03:40:38,182][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023000] [Batch 03524/04869] [00:40:28/00:15:26, 0.689s/it]: train_loss_raw=1.6471, running_loss=1.6330, LR=0.000100
[2025-08-26 03:40:43,432][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023008] [Batch 03532/04869] [00:40:33/00:15:21, 0.689s/it]: train_loss_raw=1.6505, running_loss=1.6306, LR=0.000100
[2025-08-26 03:40:49,059][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023016] [Batch 03540/04869] [00:40:39/00:15:15, 0.689s/it]: train_loss_raw=1.5874, running_loss=1.6310, LR=0.000100
[2025-08-26 03:40:55,266][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023024] [Batch 03548/04869] [00:40:45/00:15:10, 0.689s/it]: train_loss_raw=1.6161, running_loss=1.6309, LR=0.000100
[2025-08-26 03:41:01,157][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023032] [Batch 03556/04869] [00:40:51/00:15:05, 0.689s/it]: train_loss_raw=1.4976, running_loss=1.6286, LR=0.000100
[2025-08-26 03:41:06,629][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023040] [Batch 03564/04869] [00:40:56/00:14:59, 0.689s/it]: train_loss_raw=1.6686, running_loss=1.6257, LR=0.000100
[2025-08-26 03:41:11,847][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023048] [Batch 03572/04869] [00:41:02/00:14:54, 0.689s/it]: train_loss_raw=1.6580, running_loss=1.6246, LR=0.000100
[2025-08-26 03:41:17,623][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023056] [Batch 03580/04869] [00:41:07/00:14:48, 0.689s/it]: train_loss_raw=1.6892, running_loss=1.6247, LR=0.000100
[2025-08-26 03:41:22,816][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023064] [Batch 03588/04869] [00:41:13/00:14:42, 0.689s/it]: train_loss_raw=1.6140, running_loss=1.6237, LR=0.000100
[2025-08-26 03:41:28,045][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023072] [Batch 03596/04869] [00:41:18/00:14:37, 0.689s/it]: train_loss_raw=1.5851, running_loss=1.6260, LR=0.000100
[2025-08-26 03:41:33,242][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023080] [Batch 03604/04869] [00:41:23/00:14:31, 0.689s/it]: train_loss_raw=1.6467, running_loss=1.6259, LR=0.000100
[2025-08-26 03:41:38,435][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023088] [Batch 03612/04869] [00:41:28/00:14:26, 0.689s/it]: train_loss_raw=1.5528, running_loss=1.6239, LR=0.000100
[2025-08-26 03:41:43,691][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023096] [Batch 03620/04869] [00:41:34/00:14:20, 0.689s/it]: train_loss_raw=1.6624, running_loss=1.6222, LR=0.000100
[2025-08-26 03:41:48,941][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023104] [Batch 03628/04869] [00:41:39/00:14:14, 0.689s/it]: train_loss_raw=1.6356, running_loss=1.6219, LR=0.000100
[2025-08-26 03:41:54,135][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023112] [Batch 03636/04869] [00:41:44/00:14:09, 0.689s/it]: train_loss_raw=1.6692, running_loss=1.6229, LR=0.000100
[2025-08-26 03:41:59,316][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023120] [Batch 03644/04869] [00:41:49/00:14:03, 0.689s/it]: train_loss_raw=1.7061, running_loss=1.6232, LR=0.000100
[2025-08-26 03:42:04,875][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023128] [Batch 03652/04869] [00:41:55/00:13:58, 0.689s/it]: train_loss_raw=1.6076, running_loss=1.6259, LR=0.000100
[2025-08-26 03:42:11,062][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023136] [Batch 03660/04869] [00:42:01/00:13:52, 0.689s/it]: train_loss_raw=1.6079, running_loss=1.6264, LR=0.000100
[2025-08-26 03:42:17,326][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023144] [Batch 03668/04869] [00:42:07/00:13:47, 0.689s/it]: train_loss_raw=1.6666, running_loss=1.6284, LR=0.000100
[2025-08-26 03:42:23,808][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023152] [Batch 03676/04869] [00:42:14/00:13:42, 0.689s/it]: train_loss_raw=1.6480, running_loss=1.6296, LR=0.000100
[2025-08-26 03:42:29,846][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023160] [Batch 03684/04869] [00:42:20/00:13:37, 0.690s/it]: train_loss_raw=1.6316, running_loss=1.6302, LR=0.000100
[2025-08-26 03:42:35,824][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023168] [Batch 03692/04869] [00:42:26/00:13:31, 0.690s/it]: train_loss_raw=1.5856, running_loss=1.6288, LR=0.000100
[2025-08-26 03:42:41,915][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023176] [Batch 03700/04869] [00:42:32/00:13:26, 0.690s/it]: train_loss_raw=1.5909, running_loss=1.6241, LR=0.000100
[2025-08-26 03:42:47,569][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023184] [Batch 03708/04869] [00:42:37/00:13:20, 0.690s/it]: train_loss_raw=1.6666, running_loss=1.6222, LR=0.000100
[2025-08-26 03:42:52,826][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023192] [Batch 03716/04869] [00:42:43/00:13:15, 0.690s/it]: train_loss_raw=1.6022, running_loss=1.6228, LR=0.000100
[2025-08-26 03:42:58,050][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023200] [Batch 03724/04869] [00:42:48/00:13:09, 0.690s/it]: train_loss_raw=1.6753, running_loss=1.6189, LR=0.000100
[2025-08-26 03:43:03,684][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023208] [Batch 03732/04869] [00:42:54/00:13:04, 0.690s/it]: train_loss_raw=1.5230, running_loss=1.6201, LR=0.000100
[2025-08-26 03:43:09,317][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023216] [Batch 03740/04869] [00:42:59/00:12:58, 0.690s/it]: train_loss_raw=1.6568, running_loss=1.6200, LR=0.000100
[2025-08-26 03:43:15,230][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023224] [Batch 03748/04869] [00:43:05/00:12:53, 0.690s/it]: train_loss_raw=1.6070, running_loss=1.6201, LR=0.000100
[2025-08-26 03:43:21,546][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023232] [Batch 03756/04869] [00:43:11/00:12:48, 0.690s/it]: train_loss_raw=1.5551, running_loss=1.6231, LR=0.000100
[2025-08-26 03:43:27,828][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023240] [Batch 03764/04869] [00:43:18/00:12:42, 0.690s/it]: train_loss_raw=1.5700, running_loss=1.6217, LR=0.000100
[2025-08-26 03:43:34,100][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023248] [Batch 03772/04869] [00:43:24/00:12:37, 0.690s/it]: train_loss_raw=1.6144, running_loss=1.6237, LR=0.000100
[2025-08-26 03:43:40,031][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023256] [Batch 03780/04869] [00:43:30/00:12:32, 0.691s/it]: train_loss_raw=1.6357, running_loss=1.6247, LR=0.000100
[2025-08-26 03:43:45,497][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023264] [Batch 03788/04869] [00:43:35/00:12:26, 0.691s/it]: train_loss_raw=1.6910, running_loss=1.6259, LR=0.000100
[2025-08-26 03:43:50,718][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023272] [Batch 03796/04869] [00:43:41/00:12:20, 0.690s/it]: train_loss_raw=1.6168, running_loss=1.6273, LR=0.000100
[2025-08-26 03:43:56,800][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023280] [Batch 03804/04869] [00:43:47/00:12:15, 0.691s/it]: train_loss_raw=1.6174, running_loss=1.6265, LR=0.000100
[2025-08-26 03:44:02,557][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023288] [Batch 03812/04869] [00:43:52/00:12:10, 0.691s/it]: train_loss_raw=1.5993, running_loss=1.6246, LR=0.000100
[2025-08-26 03:44:08,122][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023296] [Batch 03820/04869] [00:43:58/00:12:04, 0.691s/it]: train_loss_raw=1.5785, running_loss=1.6248, LR=0.000100
[2025-08-26 03:44:14,180][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023304] [Batch 03828/04869] [00:44:04/00:11:59, 0.691s/it]: train_loss_raw=1.6189, running_loss=1.6246, LR=0.000100
[2025-08-26 03:44:19,848][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023312] [Batch 03836/04869] [00:44:10/00:11:53, 0.691s/it]: train_loss_raw=1.5667, running_loss=1.6225, LR=0.000100
[2025-08-26 03:44:25,069][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023320] [Batch 03844/04869] [00:44:15/00:11:48, 0.691s/it]: train_loss_raw=1.5725, running_loss=1.6230, LR=0.000100
[2025-08-26 03:44:30,272][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023328] [Batch 03852/04869] [00:44:20/00:11:42, 0.691s/it]: train_loss_raw=1.5684, running_loss=1.6216, LR=0.000100
[2025-08-26 03:44:35,530][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023336] [Batch 03860/04869] [00:44:25/00:11:36, 0.691s/it]: train_loss_raw=1.7460, running_loss=1.6230, LR=0.000100
[2025-08-26 03:44:40,821][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023344] [Batch 03868/04869] [00:44:31/00:11:31, 0.691s/it]: train_loss_raw=1.6625, running_loss=1.6203, LR=0.000100
[2025-08-26 03:44:46,029][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023352] [Batch 03876/04869] [00:44:36/00:11:25, 0.690s/it]: train_loss_raw=1.5373, running_loss=1.6184, LR=0.000100
[2025-08-26 03:44:51,931][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023360] [Batch 03884/04869] [00:44:42/00:11:20, 0.691s/it]: train_loss_raw=1.5781, running_loss=1.6180, LR=0.000100
[2025-08-26 03:44:58,091][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023368] [Batch 03892/04869] [00:44:48/00:11:14, 0.691s/it]: train_loss_raw=1.6140, running_loss=1.6164, LR=0.000100
[2025-08-26 03:45:04,294][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023376] [Batch 03900/04869] [00:44:54/00:11:09, 0.691s/it]: train_loss_raw=1.5673, running_loss=1.6158, LR=0.000100
[2025-08-26 03:45:10,082][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023384] [Batch 03908/04869] [00:45:00/00:11:04, 0.691s/it]: train_loss_raw=1.5590, running_loss=1.6175, LR=0.000100
[2025-08-26 03:45:15,766][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023392] [Batch 03916/04869] [00:45:06/00:10:58, 0.691s/it]: train_loss_raw=1.6635, running_loss=1.6200, LR=0.000100
[2025-08-26 03:45:20,971][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023400] [Batch 03924/04869] [00:45:11/00:10:52, 0.691s/it]: train_loss_raw=1.5774, running_loss=1.6213, LR=0.000100
[2025-08-26 03:45:26,363][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023408] [Batch 03932/04869] [00:45:16/00:10:47, 0.691s/it]: train_loss_raw=1.5691, running_loss=1.6208, LR=0.000100
[2025-08-26 03:45:31,670][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023416] [Batch 03940/04869] [00:45:21/00:10:41, 0.691s/it]: train_loss_raw=1.5561, running_loss=1.6176, LR=0.000100
[2025-08-26 03:45:37,496][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023424] [Batch 03948/04869] [00:45:27/00:10:36, 0.691s/it]: train_loss_raw=1.6100, running_loss=1.6167, LR=0.000100
[2025-08-26 03:45:42,960][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023432] [Batch 03956/04869] [00:45:33/00:10:30, 0.691s/it]: train_loss_raw=1.6174, running_loss=1.6175, LR=0.000100
[2025-08-26 03:45:48,498][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023440] [Batch 03964/04869] [00:45:38/00:10:25, 0.691s/it]: train_loss_raw=1.6531, running_loss=1.6171, LR=0.000100
[2025-08-26 03:45:53,695][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023448] [Batch 03972/04869] [00:45:44/00:10:19, 0.691s/it]: train_loss_raw=1.5679, running_loss=1.6176, LR=0.000100
[2025-08-26 03:45:59,042][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023456] [Batch 03980/04869] [00:45:49/00:10:14, 0.691s/it]: train_loss_raw=1.5087, running_loss=1.6179, LR=0.000100
[2025-08-26 03:46:04,735][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023464] [Batch 03988/04869] [00:45:55/00:10:08, 0.691s/it]: train_loss_raw=1.6174, running_loss=1.6166, LR=0.000100
[2025-08-26 03:46:09,955][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023472] [Batch 03996/04869] [00:46:00/00:10:03, 0.691s/it]: train_loss_raw=1.4372, running_loss=1.6154, LR=0.000100
[2025-08-26 03:46:15,690][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023480] [Batch 04004/04869] [00:46:06/00:09:57, 0.691s/it]: train_loss_raw=1.7124, running_loss=1.6174, LR=0.000100
[2025-08-26 03:46:20,891][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023488] [Batch 04012/04869] [00:46:11/00:09:51, 0.691s/it]: train_loss_raw=1.6367, running_loss=1.6140, LR=0.000100
[2025-08-26 03:46:26,369][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023496] [Batch 04020/04869] [00:46:16/00:09:46, 0.691s/it]: train_loss_raw=1.4777, running_loss=1.6131, LR=0.000100
[2025-08-26 03:46:31,693][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023504] [Batch 04028/04869] [00:46:22/00:09:40, 0.691s/it]: train_loss_raw=1.6268, running_loss=1.6124, LR=0.000100
[2025-08-26 03:46:37,149][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023512] [Batch 04036/04869] [00:46:27/00:09:35, 0.691s/it]: train_loss_raw=1.5375, running_loss=1.6117, LR=0.000100
[2025-08-26 03:46:42,323][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023520] [Batch 04044/04869] [00:46:32/00:09:29, 0.691s/it]: train_loss_raw=1.6031, running_loss=1.6111, LR=0.000100
[2025-08-26 03:46:47,606][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023528] [Batch 04052/04869] [00:46:37/00:09:24, 0.691s/it]: train_loss_raw=1.6325, running_loss=1.6124, LR=0.000100
[2025-08-26 03:46:52,948][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023536] [Batch 04060/04869] [00:46:43/00:09:18, 0.690s/it]: train_loss_raw=1.5481, running_loss=1.6135, LR=0.000100
[2025-08-26 03:46:58,814][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023544] [Batch 04068/04869] [00:46:49/00:09:13, 0.691s/it]: train_loss_raw=1.5542, running_loss=1.6122, LR=0.000100
[2025-08-26 03:47:04,570][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023552] [Batch 04076/04869] [00:46:54/00:09:07, 0.691s/it]: train_loss_raw=1.6353, running_loss=1.6102, LR=0.000100
[2025-08-26 03:47:09,818][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023560] [Batch 04084/04869] [00:47:00/00:09:02, 0.691s/it]: train_loss_raw=1.6829, running_loss=1.6110, LR=0.000100
[2025-08-26 03:47:15,592][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023568] [Batch 04092/04869] [00:47:05/00:08:56, 0.691s/it]: train_loss_raw=1.6273, running_loss=1.6112, LR=0.000100
[2025-08-26 03:47:21,099][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023576] [Batch 04100/04869] [00:47:11/00:08:51, 0.691s/it]: train_loss_raw=1.5963, running_loss=1.6134, LR=0.000100
[2025-08-26 03:47:26,689][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023584] [Batch 04108/04869] [00:47:17/00:08:45, 0.691s/it]: train_loss_raw=1.6185, running_loss=1.6124, LR=0.000100
[2025-08-26 03:47:32,219][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023592] [Batch 04116/04869] [00:47:22/00:08:40, 0.691s/it]: train_loss_raw=1.5576, running_loss=1.6096, LR=0.000100
[2025-08-26 03:47:37,491][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023600] [Batch 04124/04869] [00:47:27/00:08:34, 0.691s/it]: train_loss_raw=1.7466, running_loss=1.6117, LR=0.000100
[2025-08-26 03:47:42,835][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023608] [Batch 04132/04869] [00:47:33/00:08:28, 0.691s/it]: train_loss_raw=1.6686, running_loss=1.6098, LR=0.000100
[2025-08-26 03:47:48,289][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023616] [Batch 04140/04869] [00:47:38/00:08:23, 0.690s/it]: train_loss_raw=1.5859, running_loss=1.6081, LR=0.000100
[2025-08-26 03:47:53,497][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023624] [Batch 04148/04869] [00:47:43/00:08:17, 0.690s/it]: train_loss_raw=1.6416, running_loss=1.6104, LR=0.000100
[2025-08-26 03:47:58,943][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023632] [Batch 04156/04869] [00:47:49/00:08:12, 0.690s/it]: train_loss_raw=1.6503, running_loss=1.6085, LR=0.000100
[2025-08-26 03:48:04,477][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023640] [Batch 04164/04869] [00:47:54/00:08:06, 0.690s/it]: train_loss_raw=1.7440, running_loss=1.6098, LR=0.000100
[2025-08-26 03:48:09,711][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023648] [Batch 04172/04869] [00:48:00/00:08:01, 0.690s/it]: train_loss_raw=1.5858, running_loss=1.6105, LR=0.000100
[2025-08-26 03:48:15,310][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023656] [Batch 04180/04869] [00:48:05/00:07:55, 0.690s/it]: train_loss_raw=1.5663, running_loss=1.6090, LR=0.000100
[2025-08-26 03:48:20,571][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023664] [Batch 04188/04869] [00:48:10/00:07:50, 0.690s/it]: train_loss_raw=1.5316, running_loss=1.6055, LR=0.000100
[2025-08-26 03:48:25,854][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023672] [Batch 04196/04869] [00:48:16/00:07:44, 0.690s/it]: train_loss_raw=1.6858, running_loss=1.6060, LR=0.000100
[2025-08-26 03:48:31,329][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023680] [Batch 04204/04869] [00:48:21/00:07:38, 0.690s/it]: train_loss_raw=1.6407, running_loss=1.6064, LR=0.000100
[2025-08-26 03:48:36,774][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023688] [Batch 04212/04869] [00:48:27/00:07:33, 0.690s/it]: train_loss_raw=1.4474, running_loss=1.6044, LR=0.000100
[2025-08-26 03:48:42,089][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023696] [Batch 04220/04869] [00:48:32/00:07:27, 0.690s/it]: train_loss_raw=1.6308, running_loss=1.6051, LR=0.000100
[2025-08-26 03:48:47,511][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023704] [Batch 04228/04869] [00:48:37/00:07:22, 0.690s/it]: train_loss_raw=1.7395, running_loss=1.6087, LR=0.000100
[2025-08-26 03:48:52,753][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023712] [Batch 04236/04869] [00:48:43/00:07:16, 0.690s/it]: train_loss_raw=1.6744, running_loss=1.6092, LR=0.000100
[2025-08-26 03:48:58,137][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023720] [Batch 04244/04869] [00:48:48/00:07:11, 0.690s/it]: train_loss_raw=1.5830, running_loss=1.6098, LR=0.000100
[2025-08-26 03:49:03,771][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023728] [Batch 04252/04869] [00:48:54/00:07:05, 0.690s/it]: train_loss_raw=1.5309, running_loss=1.6084, LR=0.000100
[2025-08-26 03:49:08,993][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023736] [Batch 04260/04869] [00:48:59/00:07:00, 0.690s/it]: train_loss_raw=1.6895, running_loss=1.6059, LR=0.000100
[2025-08-26 03:49:14,188][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023744] [Batch 04268/04869] [00:49:04/00:06:54, 0.690s/it]: train_loss_raw=1.5678, running_loss=1.6042, LR=0.000100
[2025-08-26 03:49:19,684][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023752] [Batch 04276/04869] [00:49:10/00:06:49, 0.690s/it]: train_loss_raw=1.5890, running_loss=1.6024, LR=0.000100
[2025-08-26 03:49:24,916][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023760] [Batch 04284/04869] [00:49:15/00:06:43, 0.690s/it]: train_loss_raw=1.6631, running_loss=1.6033, LR=0.000100
[2025-08-26 03:49:30,165][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023768] [Batch 04292/04869] [00:49:20/00:06:37, 0.690s/it]: train_loss_raw=1.5064, running_loss=1.6041, LR=0.000100
[2025-08-26 03:49:35,535][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023776] [Batch 04300/04869] [00:49:25/00:06:32, 0.690s/it]: train_loss_raw=1.6902, running_loss=1.6064, LR=0.000100
[2025-08-26 03:49:41,087][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023784] [Batch 04308/04869] [00:49:31/00:06:26, 0.690s/it]: train_loss_raw=1.6372, running_loss=1.6084, LR=0.000100
[2025-08-26 03:49:46,609][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023792] [Batch 04316/04869] [00:49:36/00:06:21, 0.690s/it]: train_loss_raw=1.6965, running_loss=1.6086, LR=0.000100
[2025-08-26 03:49:52,120][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023800] [Batch 04324/04869] [00:49:42/00:06:15, 0.690s/it]: train_loss_raw=1.6387, running_loss=1.6097, LR=0.000100
[2025-08-26 03:49:57,464][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023808] [Batch 04332/04869] [00:49:47/00:06:10, 0.690s/it]: train_loss_raw=1.5262, running_loss=1.6057, LR=0.000100
[2025-08-26 03:50:03,061][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023816] [Batch 04340/04869] [00:49:53/00:06:04, 0.690s/it]: train_loss_raw=1.6474, running_loss=1.6055, LR=0.000100
[2025-08-26 03:50:08,375][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023824] [Batch 04348/04869] [00:49:58/00:05:59, 0.690s/it]: train_loss_raw=1.5412, running_loss=1.6062, LR=0.000100
[2025-08-26 03:50:13,811][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023832] [Batch 04356/04869] [00:50:04/00:05:53, 0.690s/it]: train_loss_raw=1.4783, running_loss=1.6018, LR=0.000100
[2025-08-26 03:50:19,356][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023840] [Batch 04364/04869] [00:50:09/00:05:48, 0.690s/it]: train_loss_raw=1.5978, running_loss=1.6048, LR=0.000100
[2025-08-26 03:50:25,628][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023848] [Batch 04372/04869] [00:50:15/00:05:42, 0.690s/it]: train_loss_raw=1.5879, running_loss=1.6026, LR=0.000100
[2025-08-26 03:50:31,478][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023856] [Batch 04380/04869] [00:50:21/00:05:37, 0.690s/it]: train_loss_raw=1.5852, running_loss=1.6027, LR=0.000100
[2025-08-26 03:50:37,067][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023864] [Batch 04388/04869] [00:50:27/00:05:31, 0.690s/it]: train_loss_raw=1.6114, running_loss=1.6031, LR=0.000100
[2025-08-26 03:50:42,247][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023872] [Batch 04396/04869] [00:50:32/00:05:26, 0.690s/it]: train_loss_raw=1.7351, running_loss=1.6057, LR=0.000100
[2025-08-26 03:50:48,099][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023880] [Batch 04404/04869] [00:50:38/00:05:20, 0.690s/it]: train_loss_raw=1.6174, running_loss=1.6083, LR=0.000100
[2025-08-26 03:50:54,039][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023888] [Batch 04412/04869] [00:50:44/00:05:15, 0.690s/it]: train_loss_raw=1.6773, running_loss=1.6076, LR=0.000100
[2025-08-26 03:50:59,899][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023896] [Batch 04420/04869] [00:50:50/00:05:09, 0.690s/it]: train_loss_raw=1.5555, running_loss=1.6063, LR=0.000100
[2025-08-26 03:51:05,282][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023904] [Batch 04428/04869] [00:50:55/00:05:04, 0.690s/it]: train_loss_raw=1.6783, running_loss=1.6050, LR=0.000100
[2025-08-26 03:51:11,017][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023912] [Batch 04436/04869] [00:51:01/00:04:58, 0.690s/it]: train_loss_raw=1.6093, running_loss=1.6074, LR=0.000100
[2025-08-26 03:51:16,707][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023920] [Batch 04444/04869] [00:51:07/00:04:53, 0.690s/it]: train_loss_raw=1.6678, running_loss=1.6072, LR=0.000100
[2025-08-26 03:51:22,653][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023928] [Batch 04452/04869] [00:51:12/00:04:47, 0.690s/it]: train_loss_raw=1.6086, running_loss=1.6043, LR=0.000100
[2025-08-26 03:51:28,253][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023936] [Batch 04460/04869] [00:51:18/00:04:42, 0.690s/it]: train_loss_raw=1.7083, running_loss=1.6036, LR=0.000100
[2025-08-26 03:51:33,537][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023944] [Batch 04468/04869] [00:51:23/00:04:36, 0.690s/it]: train_loss_raw=1.5573, running_loss=1.6027, LR=0.000100
[2025-08-26 03:51:39,025][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023952] [Batch 04476/04869] [00:51:29/00:04:31, 0.690s/it]: train_loss_raw=1.5098, running_loss=1.5999, LR=0.000100
[2025-08-26 03:51:44,233][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023960] [Batch 04484/04869] [00:51:34/00:04:25, 0.690s/it]: train_loss_raw=1.5656, running_loss=1.5988, LR=0.000100
[2025-08-26 03:51:49,739][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023968] [Batch 04492/04869] [00:51:40/00:04:20, 0.690s/it]: train_loss_raw=1.6031, running_loss=1.5967, LR=0.000100
[2025-08-26 03:51:55,490][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023976] [Batch 04500/04869] [00:51:45/00:04:14, 0.690s/it]: train_loss_raw=1.6220, running_loss=1.5947, LR=0.000100
[2025-08-26 03:52:00,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023984] [Batch 04508/04869] [00:51:51/00:04:09, 0.690s/it]: train_loss_raw=1.4873, running_loss=1.5939, LR=0.000100
[2025-08-26 03:52:06,685][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 023992] [Batch 04516/04869] [00:51:57/00:04:03, 0.690s/it]: train_loss_raw=1.6024, running_loss=1.5927, LR=0.000100
[2025-08-26 03:52:12,116][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024000] [Batch 04524/04869] [00:52:02/00:03:58, 0.690s/it]: train_loss_raw=1.5893, running_loss=1.5934, LR=0.000100
[2025-08-26 03:52:21,575][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024008] [Batch 04532/04869] [00:52:11/00:03:52, 0.691s/it]: train_loss_raw=1.5632, running_loss=1.5924, LR=0.000100
[2025-08-26 03:52:26,764][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024016] [Batch 04540/04869] [00:52:17/00:03:47, 0.691s/it]: train_loss_raw=1.5903, running_loss=1.5942, LR=0.000100
[2025-08-26 03:52:31,998][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024024] [Batch 04548/04869] [00:52:22/00:03:41, 0.691s/it]: train_loss_raw=1.5054, running_loss=1.5958, LR=0.000100
[2025-08-26 03:52:37,187][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024032] [Batch 04556/04869] [00:52:27/00:03:36, 0.691s/it]: train_loss_raw=1.6776, running_loss=1.5951, LR=0.000100
[2025-08-26 03:52:42,381][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024040] [Batch 04564/04869] [00:52:32/00:03:30, 0.691s/it]: train_loss_raw=1.5307, running_loss=1.5944, LR=0.000100
[2025-08-26 03:52:47,691][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024048] [Batch 04572/04869] [00:52:38/00:03:25, 0.691s/it]: train_loss_raw=1.5692, running_loss=1.5927, LR=0.000100
[2025-08-26 03:52:52,929][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024056] [Batch 04580/04869] [00:52:43/00:03:19, 0.691s/it]: train_loss_raw=1.5472, running_loss=1.5902, LR=0.000100
[2025-08-26 03:52:58,627][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024064] [Batch 04588/04869] [00:52:48/00:03:14, 0.691s/it]: train_loss_raw=1.5855, running_loss=1.5904, LR=0.000100
[2025-08-26 03:53:04,196][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024072] [Batch 04596/04869] [00:52:54/00:03:08, 0.691s/it]: train_loss_raw=1.5216, running_loss=1.5934, LR=0.000100
[2025-08-26 03:53:09,389][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024080] [Batch 04604/04869] [00:52:59/00:03:03, 0.691s/it]: train_loss_raw=1.6568, running_loss=1.5929, LR=0.000100
[2025-08-26 03:53:14,579][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024088] [Batch 04612/04869] [00:53:04/00:02:57, 0.691s/it]: train_loss_raw=1.5949, running_loss=1.5934, LR=0.000100
[2025-08-26 03:53:19,907][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024096] [Batch 04620/04869] [00:53:10/00:02:51, 0.691s/it]: train_loss_raw=1.5448, running_loss=1.5925, LR=0.000100
[2025-08-26 03:53:25,209][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024104] [Batch 04628/04869] [00:53:15/00:02:46, 0.690s/it]: train_loss_raw=1.6697, running_loss=1.5919, LR=0.000100
[2025-08-26 03:53:30,848][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024112] [Batch 04636/04869] [00:53:21/00:02:40, 0.691s/it]: train_loss_raw=1.4957, running_loss=1.5915, LR=0.000100
[2025-08-26 03:53:36,669][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024120] [Batch 04644/04869] [00:53:26/00:02:35, 0.691s/it]: train_loss_raw=1.4895, running_loss=1.5928, LR=0.000100
[2025-08-26 03:53:41,850][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024128] [Batch 04652/04869] [00:53:32/00:02:29, 0.690s/it]: train_loss_raw=1.6218, running_loss=1.5937, LR=0.000100
[2025-08-26 03:53:47,352][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024136] [Batch 04660/04869] [00:53:37/00:02:24, 0.690s/it]: train_loss_raw=1.5594, running_loss=1.5922, LR=0.000100
[2025-08-26 03:53:52,981][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024144] [Batch 04668/04869] [00:53:43/00:02:18, 0.691s/it]: train_loss_raw=1.4842, running_loss=1.5926, LR=0.000100
[2025-08-26 03:53:58,182][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024152] [Batch 04676/04869] [00:53:48/00:02:13, 0.690s/it]: train_loss_raw=1.5844, running_loss=1.5955, LR=0.000100
[2025-08-26 03:54:03,856][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024160] [Batch 04684/04869] [00:53:54/00:02:07, 0.690s/it]: train_loss_raw=1.5395, running_loss=1.5934, LR=0.000100
[2025-08-26 03:54:09,202][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024168] [Batch 04692/04869] [00:53:59/00:02:02, 0.690s/it]: train_loss_raw=1.4712, running_loss=1.5941, LR=0.000100
[2025-08-26 03:54:14,408][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024176] [Batch 04700/04869] [00:54:04/00:01:56, 0.690s/it]: train_loss_raw=1.5233, running_loss=1.5917, LR=0.000100
[2025-08-26 03:54:19,629][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024184] [Batch 04708/04869] [00:54:09/00:01:51, 0.690s/it]: train_loss_raw=1.6513, running_loss=1.5915, LR=0.000100
[2025-08-26 03:54:24,938][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024192] [Batch 04716/04869] [00:54:15/00:01:45, 0.690s/it]: train_loss_raw=1.4844, running_loss=1.5916, LR=0.000100
[2025-08-26 03:54:30,677][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024200] [Batch 04724/04869] [00:54:20/00:01:40, 0.690s/it]: train_loss_raw=1.5561, running_loss=1.5908, LR=0.000100
[2025-08-26 03:54:35,895][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024208] [Batch 04732/04869] [00:54:26/00:01:34, 0.690s/it]: train_loss_raw=1.6483, running_loss=1.5916, LR=0.000100
[2025-08-26 03:54:41,371][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024216] [Batch 04740/04869] [00:54:31/00:01:29, 0.690s/it]: train_loss_raw=1.4787, running_loss=1.5916, LR=0.000100
[2025-08-26 03:54:46,735][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024224] [Batch 04748/04869] [00:54:37/00:01:23, 0.690s/it]: train_loss_raw=1.5635, running_loss=1.5946, LR=0.000100
[2025-08-26 03:54:52,160][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024232] [Batch 04756/04869] [00:54:42/00:01:17, 0.690s/it]: train_loss_raw=1.6553, running_loss=1.5932, LR=0.000100
[2025-08-26 03:54:57,363][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024240] [Batch 04764/04869] [00:54:47/00:01:12, 0.690s/it]: train_loss_raw=1.6352, running_loss=1.5952, LR=0.000100
[2025-08-26 03:55:02,952][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024248] [Batch 04772/04869] [00:54:53/00:01:06, 0.690s/it]: train_loss_raw=1.6219, running_loss=1.5951, LR=0.000100
[2025-08-26 03:55:08,545][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024256] [Batch 04780/04869] [00:54:58/00:01:01, 0.690s/it]: train_loss_raw=1.5520, running_loss=1.5939, LR=0.000100
[2025-08-26 03:55:13,967][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024264] [Batch 04788/04869] [00:55:04/00:00:55, 0.690s/it]: train_loss_raw=1.5705, running_loss=1.5954, LR=0.000100
[2025-08-26 03:55:19,453][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024272] [Batch 04796/04869] [00:55:09/00:00:50, 0.690s/it]: train_loss_raw=1.5770, running_loss=1.5924, LR=0.000100
[2025-08-26 03:55:24,688][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024280] [Batch 04804/04869] [00:55:15/00:00:44, 0.690s/it]: train_loss_raw=1.6009, running_loss=1.5918, LR=0.000100
[2025-08-26 03:55:30,112][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024288] [Batch 04812/04869] [00:55:20/00:00:39, 0.690s/it]: train_loss_raw=1.5758, running_loss=1.5892, LR=0.000100
[2025-08-26 03:55:35,314][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024296] [Batch 04820/04869] [00:55:25/00:00:33, 0.690s/it]: train_loss_raw=1.5731, running_loss=1.5894, LR=0.000100
[2025-08-26 03:55:40,498][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024304] [Batch 04828/04869] [00:55:30/00:00:28, 0.690s/it]: train_loss_raw=1.5882, running_loss=1.5888, LR=0.000100
[2025-08-26 03:55:45,715][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024312] [Batch 04836/04869] [00:55:36/00:00:22, 0.690s/it]: train_loss_raw=1.5191, running_loss=1.5871, LR=0.000100
[2025-08-26 03:55:51,462][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024320] [Batch 04844/04869] [00:55:41/00:00:17, 0.690s/it]: train_loss_raw=1.5789, running_loss=1.5874, LR=0.000100
[2025-08-26 03:55:56,831][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024328] [Batch 04852/04869] [00:55:47/00:00:11, 0.690s/it]: train_loss_raw=1.5688, running_loss=1.5853, LR=0.000100
[2025-08-26 03:56:02,332][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024336] [Batch 04860/04869] [00:55:52/00:00:06, 0.690s/it]: train_loss_raw=1.6124, running_loss=1.5861, LR=0.000100
[2025-08-26 03:56:14,320][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 024344] [Batch 04868/04869] [00:56:04/00:00:00, 0.691s/it]: train_loss_raw=1.4817, running_loss=1.5859, LR=0.000100
[2025-08-26 03:56:20,867][__main__][INFO] - [VALIDATION] [Epoch 04/29] Starting validation.
[2025-08-26 03:56:30,976][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00007/00124] [00:00:10/00:02:26, 1.264s/it]
[2025-08-26 03:56:41,540][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00015/00124] [00:00:20/00:02:19, 1.292s/it]
[2025-08-26 03:56:52,627][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00023/00124] [00:00:31/00:02:12, 1.323s/it]
[2025-08-26 03:57:13,614][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00031/00124] [00:00:52/00:02:31, 1.648s/it]
[2025-08-26 03:57:25,048][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00039/00124] [00:01:04/00:02:14, 1.605s/it]
[2025-08-26 03:57:36,136][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00047/00124] [00:01:15/00:01:59, 1.568s/it]
[2025-08-26 03:57:46,171][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00055/00124] [00:01:25/00:01:43, 1.523s/it]
[2025-08-26 03:57:57,796][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00063/00124] [00:01:36/00:01:30, 1.515s/it]
[2025-08-26 03:58:09,013][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00071/00124] [00:01:48/00:01:18, 1.502s/it]
[2025-08-26 03:58:19,813][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00079/00124] [00:01:58/00:01:05, 1.487s/it]
[2025-08-26 03:58:30,319][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00087/00124] [00:02:09/00:00:52, 1.471s/it]
[2025-08-26 03:58:41,217][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00095/00124] [00:02:20/00:00:40, 1.462s/it]
[2025-08-26 03:58:52,041][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00103/00124] [00:02:31/00:00:29, 1.454s/it]
[2025-08-26 03:59:02,893][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00111/00124] [00:02:42/00:00:17, 1.447s/it]
[2025-08-26 03:59:14,084][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 024346] [Batch 00119/00124] [00:02:53/00:00:05, 1.443s/it]
[2025-08-26 03:59:19,046][__main__][INFO] - [VALIDATION] [Epoch 04/29] train_loss=1.58647, valid_loss=1.53600
[2025-08-26 03:59:19,046][__main__][INFO] - [VALIDATION] [Epoch 04/29] Metrics:
[2025-08-26 03:59:19,046][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_er      0.661
[2025-08-26 03:59:19,046][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_prec    0.081
[2025-08-26 03:59:19,046][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_recall  0.084
[2025-08-26 03:59:19,046][__main__][INFO] - [VALIDATION] [Epoch 04/29] - pep_recall 0.040
[2025-08-26 03:59:19,054][__main__][INFO] - [TRAIN] [Epoch 04/29] Epoch complete, total time 04:54:59, remaining time 24:34:55, 00:58:59 per epoch
[2025-08-26 03:59:24,007][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024352] [Batch 00007/04869] [00:00:04/00:54:17, 0.670s/it]: train_loss_raw=1.5503, running_loss=1.6092, LR=0.000100
[2025-08-26 03:59:29,855][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024360] [Batch 00015/04869] [00:00:10/00:56:50, 0.703s/it]: train_loss_raw=1.6045, running_loss=1.6055, LR=0.000100
[2025-08-26 03:59:35,370][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024368] [Batch 00023/04869] [00:00:16/00:56:22, 0.698s/it]: train_loss_raw=1.6211, running_loss=1.6017, LR=0.000100
[2025-08-26 03:59:40,766][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024376] [Batch 00031/04869] [00:00:21/00:55:47, 0.692s/it]: train_loss_raw=1.5925, running_loss=1.5999, LR=0.000100
[2025-08-26 03:59:46,287][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024384] [Batch 00039/04869] [00:00:26/00:55:40, 0.692s/it]: train_loss_raw=1.5311, running_loss=1.5955, LR=0.000100
[2025-08-26 03:59:51,616][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024392] [Batch 00047/04869] [00:00:32/00:55:13, 0.687s/it]: train_loss_raw=1.5514, running_loss=1.5946, LR=0.000100
[2025-08-26 03:59:56,808][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024400] [Batch 00055/04869] [00:00:37/00:54:41, 0.682s/it]: train_loss_raw=1.6758, running_loss=1.5928, LR=0.000100
[2025-08-26 04:00:02,206][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024408] [Batch 00063/04869] [00:00:42/00:54:31, 0.681s/it]: train_loss_raw=1.5939, running_loss=1.5910, LR=0.000100
[2025-08-26 04:00:07,561][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024416] [Batch 00071/04869] [00:00:48/00:54:20, 0.679s/it]: train_loss_raw=1.6607, running_loss=1.5905, LR=0.000100
[2025-08-26 04:00:12,780][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024424] [Batch 00079/04869] [00:00:53/00:54:01, 0.677s/it]: train_loss_raw=1.5537, running_loss=1.5896, LR=0.000100
[2025-08-26 04:00:18,886][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024432] [Batch 00087/04869] [00:00:59/00:54:34, 0.685s/it]: train_loss_raw=1.5652, running_loss=1.5868, LR=0.000100
[2025-08-26 04:00:24,342][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024440] [Batch 00095/04869] [00:01:05/00:54:27, 0.684s/it]: train_loss_raw=1.6001, running_loss=1.5884, LR=0.000100
[2025-08-26 04:00:29,684][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024448] [Batch 00103/04869] [00:01:10/00:54:16, 0.683s/it]: train_loss_raw=1.5153, running_loss=1.5858, LR=0.000100
[2025-08-26 04:00:35,400][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024456] [Batch 00111/04869] [00:01:16/00:54:21, 0.685s/it]: train_loss_raw=1.5273, running_loss=1.5840, LR=0.000100
[2025-08-26 04:00:41,328][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024464] [Batch 00119/04869] [00:01:22/00:54:33, 0.689s/it]: train_loss_raw=1.5982, running_loss=1.5843, LR=0.000100
[2025-08-26 04:00:46,847][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024472] [Batch 00127/04869] [00:01:27/00:54:28, 0.689s/it]: train_loss_raw=1.6344, running_loss=1.5830, LR=0.000100
[2025-08-26 04:00:52,786][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024480] [Batch 00135/04869] [00:01:33/00:54:37, 0.692s/it]: train_loss_raw=1.5357, running_loss=1.5821, LR=0.000100
[2025-08-26 04:00:58,033][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024488] [Batch 00143/04869] [00:01:38/00:54:22, 0.690s/it]: train_loss_raw=1.4967, running_loss=1.5799, LR=0.000100
[2025-08-26 04:01:03,650][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024496] [Batch 00151/04869] [00:01:44/00:54:19, 0.691s/it]: train_loss_raw=1.6454, running_loss=1.5813, LR=0.000100
[2025-08-26 04:01:08,852][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024504] [Batch 00159/04869] [00:01:49/00:54:04, 0.689s/it]: train_loss_raw=1.5461, running_loss=1.5777, LR=0.000100
[2025-08-26 04:01:14,176][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024512] [Batch 00167/04869] [00:01:54/00:53:53, 0.688s/it]: train_loss_raw=1.5558, running_loss=1.5801, LR=0.000100
[2025-08-26 04:01:19,674][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024520] [Batch 00175/04869] [00:02:00/00:53:48, 0.688s/it]: train_loss_raw=1.4611, running_loss=1.5772, LR=0.000100
[2025-08-26 04:01:25,221][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024528] [Batch 00183/04869] [00:02:05/00:53:43, 0.688s/it]: train_loss_raw=1.5378, running_loss=1.5743, LR=0.000100
[2025-08-26 04:01:31,270][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024536] [Batch 00191/04869] [00:02:11/00:53:51, 0.691s/it]: train_loss_raw=1.5220, running_loss=1.5734, LR=0.000100
[2025-08-26 04:01:37,287][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024544] [Batch 00199/04869] [00:02:17/00:53:57, 0.693s/it]: train_loss_raw=1.5970, running_loss=1.5708, LR=0.000100
[2025-08-26 04:01:43,113][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024552] [Batch 00207/04869] [00:02:23/00:53:58, 0.695s/it]: train_loss_raw=1.5178, running_loss=1.5678, LR=0.000100
[2025-08-26 04:01:49,106][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024560] [Batch 00215/04869] [00:02:29/00:54:02, 0.697s/it]: train_loss_raw=1.6456, running_loss=1.5669, LR=0.000100
[2025-08-26 04:01:54,737][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024568] [Batch 00223/04869] [00:02:35/00:53:58, 0.697s/it]: train_loss_raw=1.4938, running_loss=1.5652, LR=0.000100
[2025-08-26 04:02:00,448][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024576] [Batch 00231/04869] [00:02:41/00:53:55, 0.698s/it]: train_loss_raw=1.6460, running_loss=1.5697, LR=0.000100
[2025-08-26 04:02:06,045][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024584] [Batch 00239/04869] [00:02:46/00:53:49, 0.698s/it]: train_loss_raw=1.6096, running_loss=1.5695, LR=0.000100
[2025-08-26 04:02:11,291][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024592] [Batch 00247/04869] [00:02:51/00:53:38, 0.696s/it]: train_loss_raw=1.5067, running_loss=1.5691, LR=0.000100
[2025-08-26 04:02:17,104][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024600] [Batch 00255/04869] [00:02:57/00:53:36, 0.697s/it]: train_loss_raw=1.5937, running_loss=1.5679, LR=0.000100
[2025-08-26 04:02:22,285][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024608] [Batch 00263/04869] [00:03:02/00:53:24, 0.696s/it]: train_loss_raw=1.6277, running_loss=1.5681, LR=0.000100
[2025-08-26 04:02:28,057][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024616] [Batch 00271/04869] [00:03:08/00:53:22, 0.696s/it]: train_loss_raw=1.5940, running_loss=1.5665, LR=0.000100
[2025-08-26 04:02:34,018][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024624] [Batch 00279/04869] [00:03:14/00:53:23, 0.698s/it]: train_loss_raw=1.6591, running_loss=1.5680, LR=0.000100
[2025-08-26 04:02:39,234][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024632] [Batch 00287/04869] [00:03:19/00:53:11, 0.697s/it]: train_loss_raw=1.6028, running_loss=1.5687, LR=0.000100
[2025-08-26 04:02:44,449][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024640] [Batch 00295/04869] [00:03:25/00:53:00, 0.695s/it]: train_loss_raw=1.5785, running_loss=1.5679, LR=0.000100
[2025-08-26 04:02:49,922][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024648] [Batch 00303/04869] [00:03:30/00:52:53, 0.695s/it]: train_loss_raw=1.5878, running_loss=1.5673, LR=0.000100
[2025-08-26 04:02:55,463][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024656] [Batch 00311/04869] [00:03:36/00:52:47, 0.695s/it]: train_loss_raw=1.6276, running_loss=1.5683, LR=0.000100
[2025-08-26 04:03:00,670][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024664] [Batch 00319/04869] [00:03:41/00:52:37, 0.694s/it]: train_loss_raw=1.4429, running_loss=1.5673, LR=0.000100
[2025-08-26 04:03:05,861][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024672] [Batch 00327/04869] [00:03:46/00:52:26, 0.693s/it]: train_loss_raw=1.5015, running_loss=1.5657, LR=0.000100
[2025-08-26 04:03:11,046][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024680] [Batch 00335/04869] [00:03:51/00:52:16, 0.692s/it]: train_loss_raw=1.5115, running_loss=1.5663, LR=0.000100
[2025-08-26 04:03:16,357][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024688] [Batch 00343/04869] [00:03:57/00:52:07, 0.691s/it]: train_loss_raw=1.6225, running_loss=1.5656, LR=0.000100
[2025-08-26 04:03:22,076][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024696] [Batch 00351/04869] [00:04:02/00:52:04, 0.692s/it]: train_loss_raw=1.7482, running_loss=1.5682, LR=0.000100
[2025-08-26 04:03:27,461][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024704] [Batch 00359/04869] [00:04:08/00:51:57, 0.691s/it]: train_loss_raw=1.5801, running_loss=1.5684, LR=0.000100
[2025-08-26 04:03:32,746][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024712] [Batch 00367/04869] [00:04:13/00:51:48, 0.691s/it]: train_loss_raw=1.6101, running_loss=1.5691, LR=0.000100
[2025-08-26 04:03:38,098][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024720] [Batch 00375/04869] [00:04:18/00:51:41, 0.690s/it]: train_loss_raw=1.5990, running_loss=1.5685, LR=0.000100
[2025-08-26 04:03:43,733][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024728] [Batch 00383/04869] [00:04:24/00:51:37, 0.690s/it]: train_loss_raw=1.6631, running_loss=1.5698, LR=0.000100
[2025-08-26 04:03:49,045][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024736] [Batch 00391/04869] [00:04:29/00:51:29, 0.690s/it]: train_loss_raw=1.5113, running_loss=1.5684, LR=0.000100
[2025-08-26 04:03:54,787][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024744] [Batch 00399/04869] [00:04:35/00:51:26, 0.690s/it]: train_loss_raw=1.5485, running_loss=1.5680, LR=0.000100
[2025-08-26 04:04:00,406][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024752] [Batch 00407/04869] [00:04:41/00:51:21, 0.691s/it]: train_loss_raw=1.6014, running_loss=1.5709, LR=0.000100
[2025-08-26 04:04:05,997][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024760] [Batch 00415/04869] [00:04:46/00:51:16, 0.691s/it]: train_loss_raw=1.5114, running_loss=1.5718, LR=0.000100
[2025-08-26 04:04:11,176][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024768] [Batch 00423/04869] [00:04:51/00:51:07, 0.690s/it]: train_loss_raw=1.4741, running_loss=1.5709, LR=0.000100
[2025-08-26 04:04:16,356][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024776] [Batch 00431/04869] [00:04:57/00:50:58, 0.689s/it]: train_loss_raw=1.5239, running_loss=1.5734, LR=0.000100
[2025-08-26 04:04:21,528][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024784] [Batch 00439/04869] [00:05:02/00:50:49, 0.688s/it]: train_loss_raw=1.5145, running_loss=1.5705, LR=0.000100
[2025-08-26 04:04:26,716][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024792] [Batch 00447/04869] [00:05:07/00:50:40, 0.688s/it]: train_loss_raw=1.5381, running_loss=1.5687, LR=0.000100
[2025-08-26 04:04:31,931][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024800] [Batch 00455/04869] [00:05:12/00:50:32, 0.687s/it]: train_loss_raw=1.6301, running_loss=1.5711, LR=0.000100
[2025-08-26 04:04:37,141][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024808] [Batch 00463/04869] [00:05:17/00:50:24, 0.686s/it]: train_loss_raw=1.5312, running_loss=1.5717, LR=0.000100
[2025-08-26 04:04:42,692][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024816] [Batch 00471/04869] [00:05:23/00:50:19, 0.687s/it]: train_loss_raw=1.5586, running_loss=1.5723, LR=0.000100
[2025-08-26 04:04:48,414][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024824] [Batch 00479/04869] [00:05:29/00:50:16, 0.687s/it]: train_loss_raw=1.5141, running_loss=1.5709, LR=0.000100
[2025-08-26 04:04:54,137][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024832] [Batch 00487/04869] [00:05:34/00:50:12, 0.688s/it]: train_loss_raw=1.6588, running_loss=1.5730, LR=0.000100
[2025-08-26 04:04:59,596][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024840] [Batch 00495/04869] [00:05:40/00:50:06, 0.687s/it]: train_loss_raw=1.4762, running_loss=1.5715, LR=0.000100
[2025-08-26 04:05:05,137][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024848] [Batch 00503/04869] [00:05:45/00:50:01, 0.688s/it]: train_loss_raw=1.5171, running_loss=1.5714, LR=0.000100
[2025-08-26 04:05:10,344][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024856] [Batch 00511/04869] [00:05:51/00:49:53, 0.687s/it]: train_loss_raw=1.5777, running_loss=1.5733, LR=0.000100
[2025-08-26 04:05:15,554][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024864] [Batch 00519/04869] [00:05:56/00:49:45, 0.686s/it]: train_loss_raw=1.6425, running_loss=1.5713, LR=0.000100
[2025-08-26 04:05:20,777][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024872] [Batch 00527/04869] [00:06:01/00:49:38, 0.686s/it]: train_loss_raw=1.5316, running_loss=1.5672, LR=0.000100
[2025-08-26 04:05:26,485][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024880] [Batch 00535/04869] [00:06:07/00:49:34, 0.686s/it]: train_loss_raw=1.5589, running_loss=1.5677, LR=0.000100
[2025-08-26 04:05:31,704][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024888] [Batch 00543/04869] [00:06:12/00:49:26, 0.686s/it]: train_loss_raw=1.5372, running_loss=1.5656, LR=0.000100
[2025-08-26 04:05:36,906][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024896] [Batch 00551/04869] [00:06:17/00:49:19, 0.685s/it]: train_loss_raw=1.5906, running_loss=1.5697, LR=0.000100
[2025-08-26 04:05:42,441][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024904] [Batch 00559/04869] [00:06:23/00:49:13, 0.685s/it]: train_loss_raw=1.7023, running_loss=1.5715, LR=0.000100
[2025-08-26 04:05:47,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024912] [Batch 00567/04869] [00:06:28/00:49:07, 0.685s/it]: train_loss_raw=1.5403, running_loss=1.5707, LR=0.000100
[2025-08-26 04:05:52,934][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024920] [Batch 00575/04869] [00:06:33/00:48:59, 0.685s/it]: train_loss_raw=1.4897, running_loss=1.5671, LR=0.000100
[2025-08-26 04:05:58,128][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024928] [Batch 00583/04869] [00:06:38/00:48:51, 0.684s/it]: train_loss_raw=1.6099, running_loss=1.5651, LR=0.000100
[2025-08-26 04:06:03,362][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024936] [Batch 00591/04869] [00:06:44/00:48:44, 0.684s/it]: train_loss_raw=1.5889, running_loss=1.5665, LR=0.000100
[2025-08-26 04:06:08,596][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024944] [Batch 00599/04869] [00:06:49/00:48:37, 0.683s/it]: train_loss_raw=1.7127, running_loss=1.5681, LR=0.000100
[2025-08-26 04:06:13,796][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024952] [Batch 00607/04869] [00:06:54/00:48:30, 0.683s/it]: train_loss_raw=1.5347, running_loss=1.5697, LR=0.000100
[2025-08-26 04:06:19,001][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024960] [Batch 00615/04869] [00:06:59/00:48:22, 0.682s/it]: train_loss_raw=1.5405, running_loss=1.5704, LR=0.000100
[2025-08-26 04:06:24,213][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024968] [Batch 00623/04869] [00:07:04/00:48:15, 0.682s/it]: train_loss_raw=1.4738, running_loss=1.5711, LR=0.000100
[2025-08-26 04:06:29,408][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024976] [Batch 00631/04869] [00:07:10/00:48:08, 0.682s/it]: train_loss_raw=1.5459, running_loss=1.5695, LR=0.000100
[2025-08-26 04:06:34,637][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024984] [Batch 00639/04869] [00:07:15/00:48:01, 0.681s/it]: train_loss_raw=1.5422, running_loss=1.5672, LR=0.000100
[2025-08-26 04:06:39,859][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 024992] [Batch 00647/04869] [00:07:20/00:47:54, 0.681s/it]: train_loss_raw=1.5902, running_loss=1.5650, LR=0.000100
[2025-08-26 04:06:45,072][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025000] [Batch 00655/04869] [00:07:25/00:47:47, 0.681s/it]: train_loss_raw=1.5585, running_loss=1.5655, LR=0.000100
[2025-08-26 04:06:51,065][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025008] [Batch 00663/04869] [00:07:31/00:47:45, 0.681s/it]: train_loss_raw=1.5610, running_loss=1.5629, LR=0.000100
[2025-08-26 04:06:56,430][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025016] [Batch 00671/04869] [00:07:37/00:47:39, 0.681s/it]: train_loss_raw=1.5528, running_loss=1.5618, LR=0.000100
[2025-08-26 04:07:01,652][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025024] [Batch 00679/04869] [00:07:42/00:47:32, 0.681s/it]: train_loss_raw=1.5617, running_loss=1.5593, LR=0.000100
[2025-08-26 04:07:07,335][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025032] [Batch 00687/04869] [00:07:48/00:47:28, 0.681s/it]: train_loss_raw=1.5322, running_loss=1.5603, LR=0.000100
[2025-08-26 04:07:12,684][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025040] [Batch 00695/04869] [00:07:53/00:47:22, 0.681s/it]: train_loss_raw=1.5706, running_loss=1.5605, LR=0.000100
[2025-08-26 04:07:18,011][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025048] [Batch 00703/04869] [00:07:58/00:47:16, 0.681s/it]: train_loss_raw=1.6172, running_loss=1.5595, LR=0.000100
[2025-08-26 04:07:23,477][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025056] [Batch 00711/04869] [00:08:04/00:47:11, 0.681s/it]: train_loss_raw=1.5474, running_loss=1.5615, LR=0.000100
[2025-08-26 04:07:29,391][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025064] [Batch 00719/04869] [00:08:10/00:47:08, 0.682s/it]: train_loss_raw=1.5605, running_loss=1.5618, LR=0.000100
[2025-08-26 04:07:34,704][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025072] [Batch 00727/04869] [00:08:15/00:47:02, 0.681s/it]: train_loss_raw=1.5162, running_loss=1.5608, LR=0.000100
[2025-08-26 04:07:39,957][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025080] [Batch 00735/04869] [00:08:20/00:46:55, 0.681s/it]: train_loss_raw=1.4796, running_loss=1.5577, LR=0.000100
[2025-08-26 04:07:45,308][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025088] [Batch 00743/04869] [00:08:25/00:46:49, 0.681s/it]: train_loss_raw=1.5130, running_loss=1.5577, LR=0.000100
[2025-08-26 04:07:50,946][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025096] [Batch 00751/04869] [00:08:31/00:46:45, 0.681s/it]: train_loss_raw=1.5191, running_loss=1.5612, LR=0.000100
[2025-08-26 04:07:56,323][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025104] [Batch 00759/04869] [00:08:37/00:46:39, 0.681s/it]: train_loss_raw=1.4583, running_loss=1.5607, LR=0.000100
[2025-08-26 04:08:02,080][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025112] [Batch 00767/04869] [00:08:42/00:46:35, 0.682s/it]: train_loss_raw=1.5829, running_loss=1.5602, LR=0.000100
[2025-08-26 04:08:07,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025120] [Batch 00775/04869] [00:08:48/00:46:31, 0.682s/it]: train_loss_raw=1.6595, running_loss=1.5625, LR=0.000100
[2025-08-26 04:08:12,939][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025128] [Batch 00783/04869] [00:08:53/00:46:24, 0.682s/it]: train_loss_raw=1.5717, running_loss=1.5621, LR=0.000100
[2025-08-26 04:08:18,153][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025136] [Batch 00791/04869] [00:08:58/00:46:17, 0.681s/it]: train_loss_raw=1.5067, running_loss=1.5623, LR=0.000100
[2025-08-26 04:08:23,344][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025144] [Batch 00799/04869] [00:09:04/00:46:11, 0.681s/it]: train_loss_raw=1.5135, running_loss=1.5612, LR=0.000100
[2025-08-26 04:08:28,566][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025152] [Batch 00807/04869] [00:09:09/00:46:04, 0.681s/it]: train_loss_raw=1.5087, running_loss=1.5621, LR=0.000100
[2025-08-26 04:08:33,782][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025160] [Batch 00815/04869] [00:09:14/00:45:58, 0.680s/it]: train_loss_raw=1.6467, running_loss=1.5624, LR=0.000100
[2025-08-26 04:08:38,982][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025168] [Batch 00823/04869] [00:09:19/00:45:51, 0.680s/it]: train_loss_raw=1.6051, running_loss=1.5625, LR=0.000100
[2025-08-26 04:08:44,175][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025176] [Batch 00831/04869] [00:09:24/00:45:44, 0.680s/it]: train_loss_raw=1.7046, running_loss=1.5642, LR=0.000100
[2025-08-26 04:08:49,693][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025184] [Batch 00839/04869] [00:09:30/00:45:39, 0.680s/it]: train_loss_raw=1.5075, running_loss=1.5643, LR=0.000100
[2025-08-26 04:08:55,249][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025192] [Batch 00847/04869] [00:09:35/00:45:34, 0.680s/it]: train_loss_raw=1.5402, running_loss=1.5669, LR=0.000100
[2025-08-26 04:09:00,458][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025200] [Batch 00855/04869] [00:09:41/00:45:28, 0.680s/it]: train_loss_raw=1.6117, running_loss=1.5661, LR=0.000100
[2025-08-26 04:09:05,793][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025208] [Batch 00863/04869] [00:09:46/00:45:22, 0.680s/it]: train_loss_raw=1.5872, running_loss=1.5678, LR=0.000100
[2025-08-26 04:09:11,127][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025216] [Batch 00871/04869] [00:09:51/00:45:16, 0.679s/it]: train_loss_raw=1.5722, running_loss=1.5674, LR=0.000100
[2025-08-26 04:09:16,772][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025224] [Batch 00879/04869] [00:09:57/00:45:11, 0.680s/it]: train_loss_raw=1.5524, running_loss=1.5675, LR=0.000100
[2025-08-26 04:09:22,216][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025232] [Batch 00887/04869] [00:10:02/00:45:06, 0.680s/it]: train_loss_raw=1.5972, running_loss=1.5658, LR=0.000100
[2025-08-26 04:09:27,490][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025240] [Batch 00895/04869] [00:10:08/00:45:00, 0.680s/it]: train_loss_raw=1.5794, running_loss=1.5634, LR=0.000100
[2025-08-26 04:09:32,712][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025248] [Batch 00903/04869] [00:10:13/00:44:54, 0.679s/it]: train_loss_raw=1.5769, running_loss=1.5647, LR=0.000100
[2025-08-26 04:09:37,926][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025256] [Batch 00911/04869] [00:10:18/00:44:47, 0.679s/it]: train_loss_raw=1.5840, running_loss=1.5650, LR=0.000100
[2025-08-26 04:09:43,127][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025264] [Batch 00919/04869] [00:10:23/00:44:41, 0.679s/it]: train_loss_raw=1.6469, running_loss=1.5657, LR=0.000100
[2025-08-26 04:09:48,368][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025272] [Batch 00927/04869] [00:10:29/00:44:34, 0.679s/it]: train_loss_raw=1.6621, running_loss=1.5650, LR=0.000100
[2025-08-26 04:09:53,567][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025280] [Batch 00935/04869] [00:10:34/00:44:28, 0.678s/it]: train_loss_raw=1.6377, running_loss=1.5624, LR=0.000100
[2025-08-26 04:09:58,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025288] [Batch 00943/04869] [00:10:39/00:44:22, 0.678s/it]: train_loss_raw=1.6629, running_loss=1.5625, LR=0.000100
[2025-08-26 04:10:03,928][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025296] [Batch 00951/04869] [00:10:44/00:44:15, 0.678s/it]: train_loss_raw=1.3857, running_loss=1.5617, LR=0.000100
[2025-08-26 04:10:09,089][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025304] [Batch 00959/04869] [00:10:49/00:44:09, 0.678s/it]: train_loss_raw=1.5352, running_loss=1.5602, LR=0.000100
[2025-08-26 04:10:14,297][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025312] [Batch 00967/04869] [00:10:54/00:44:02, 0.677s/it]: train_loss_raw=1.4379, running_loss=1.5578, LR=0.000100
[2025-08-26 04:10:19,600][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025320] [Batch 00975/04869] [00:11:00/00:43:57, 0.677s/it]: train_loss_raw=1.4708, running_loss=1.5562, LR=0.000100
[2025-08-26 04:10:25,090][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025328] [Batch 00983/04869] [00:11:05/00:43:51, 0.677s/it]: train_loss_raw=1.4945, running_loss=1.5546, LR=0.000100
[2025-08-26 04:10:30,401][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025336] [Batch 00991/04869] [00:11:11/00:43:46, 0.677s/it]: train_loss_raw=1.4784, running_loss=1.5561, LR=0.000100
[2025-08-26 04:10:35,632][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025344] [Batch 00999/04869] [00:11:16/00:43:39, 0.677s/it]: train_loss_raw=1.5015, running_loss=1.5524, LR=0.000100
[2025-08-26 04:10:40,828][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025352] [Batch 01007/04869] [00:11:21/00:43:33, 0.677s/it]: train_loss_raw=1.6473, running_loss=1.5551, LR=0.000100
[2025-08-26 04:11:00,419][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025360] [Batch 01015/04869] [00:11:41/00:44:22, 0.691s/it]: train_loss_raw=1.5486, running_loss=1.5533, LR=0.000100
[2025-08-26 04:11:06,148][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025368] [Batch 01023/04869] [00:11:46/00:44:17, 0.691s/it]: train_loss_raw=1.5275, running_loss=1.5534, LR=0.000100
[2025-08-26 04:11:11,682][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025376] [Batch 01031/04869] [00:11:52/00:44:11, 0.691s/it]: train_loss_raw=1.5347, running_loss=1.5483, LR=0.000100
[2025-08-26 04:11:17,154][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025384] [Batch 01039/04869] [00:11:57/00:44:06, 0.691s/it]: train_loss_raw=1.5496, running_loss=1.5476, LR=0.000100
[2025-08-26 04:11:23,100][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025392] [Batch 01047/04869] [00:12:03/00:44:02, 0.691s/it]: train_loss_raw=1.5587, running_loss=1.5478, LR=0.000100
[2025-08-26 04:11:28,354][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025400] [Batch 01055/04869] [00:12:09/00:43:55, 0.691s/it]: train_loss_raw=1.5529, running_loss=1.5464, LR=0.000100
[2025-08-26 04:11:33,572][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025408] [Batch 01063/04869] [00:12:14/00:43:48, 0.691s/it]: train_loss_raw=1.6039, running_loss=1.5430, LR=0.000100
[2025-08-26 04:11:38,890][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025416] [Batch 01071/04869] [00:12:19/00:43:42, 0.691s/it]: train_loss_raw=1.5463, running_loss=1.5432, LR=0.000100
[2025-08-26 04:11:44,585][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025424] [Batch 01079/04869] [00:12:25/00:43:37, 0.691s/it]: train_loss_raw=1.5622, running_loss=1.5421, LR=0.000100
[2025-08-26 04:11:50,753][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025432] [Batch 01087/04869] [00:12:31/00:43:34, 0.691s/it]: train_loss_raw=1.5270, running_loss=1.5424, LR=0.000100
[2025-08-26 04:11:56,981][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025440] [Batch 01095/04869] [00:12:37/00:43:31, 0.692s/it]: train_loss_raw=1.5717, running_loss=1.5426, LR=0.000100
[2025-08-26 04:12:02,680][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025448] [Batch 01103/04869] [00:12:43/00:43:26, 0.692s/it]: train_loss_raw=1.5766, running_loss=1.5403, LR=0.000100
[2025-08-26 04:12:08,087][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025456] [Batch 01111/04869] [00:12:48/00:43:20, 0.692s/it]: train_loss_raw=1.5289, running_loss=1.5400, LR=0.000100
[2025-08-26 04:12:13,983][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025464] [Batch 01119/04869] [00:12:54/00:43:16, 0.692s/it]: train_loss_raw=1.4760, running_loss=1.5393, LR=0.000100
[2025-08-26 04:12:19,337][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025472] [Batch 01127/04869] [00:13:00/00:43:09, 0.692s/it]: train_loss_raw=1.4757, running_loss=1.5383, LR=0.000100
[2025-08-26 04:12:24,549][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025480] [Batch 01135/04869] [00:13:05/00:43:03, 0.692s/it]: train_loss_raw=1.5196, running_loss=1.5363, LR=0.000100
[2025-08-26 04:12:30,297][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025488] [Batch 01143/04869] [00:13:10/00:42:58, 0.692s/it]: train_loss_raw=1.5027, running_loss=1.5361, LR=0.000100
[2025-08-26 04:12:35,518][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025496] [Batch 01151/04869] [00:13:16/00:42:51, 0.692s/it]: train_loss_raw=1.5593, running_loss=1.5359, LR=0.000100
[2025-08-26 04:12:40,743][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025504] [Batch 01159/04869] [00:13:21/00:42:45, 0.691s/it]: train_loss_raw=1.5970, running_loss=1.5369, LR=0.000100
[2025-08-26 04:12:45,971][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025512] [Batch 01167/04869] [00:13:26/00:42:38, 0.691s/it]: train_loss_raw=1.5126, running_loss=1.5368, LR=0.000100
[2025-08-26 04:12:51,202][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025520] [Batch 01175/04869] [00:13:31/00:42:32, 0.691s/it]: train_loss_raw=1.6068, running_loss=1.5356, LR=0.000100
[2025-08-26 04:12:56,645][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025528] [Batch 01183/04869] [00:13:37/00:42:26, 0.691s/it]: train_loss_raw=1.5926, running_loss=1.5354, LR=0.000100
[2025-08-26 04:13:02,535][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025536] [Batch 01191/04869] [00:13:43/00:42:22, 0.691s/it]: train_loss_raw=1.4640, running_loss=1.5347, LR=0.000100
[2025-08-26 04:13:08,452][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025544] [Batch 01199/04869] [00:13:49/00:42:17, 0.692s/it]: train_loss_raw=1.5460, running_loss=1.5329, LR=0.000100
[2025-08-26 04:13:13,621][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025552] [Batch 01207/04869] [00:13:54/00:42:11, 0.691s/it]: train_loss_raw=1.5145, running_loss=1.5327, LR=0.000100
[2025-08-26 04:13:19,209][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025560] [Batch 01215/04869] [00:13:59/00:42:05, 0.691s/it]: train_loss_raw=1.5178, running_loss=1.5332, LR=0.000100
[2025-08-26 04:13:24,983][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025568] [Batch 01223/04869] [00:14:05/00:42:01, 0.691s/it]: train_loss_raw=1.5653, running_loss=1.5331, LR=0.000100
[2025-08-26 04:13:30,775][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025576] [Batch 01231/04869] [00:14:11/00:41:56, 0.692s/it]: train_loss_raw=1.5290, running_loss=1.5335, LR=0.000100
[2025-08-26 04:13:36,012][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025584] [Batch 01239/04869] [00:14:16/00:41:49, 0.691s/it]: train_loss_raw=1.5145, running_loss=1.5336, LR=0.000100
[2025-08-26 04:13:41,229][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025592] [Batch 01247/04869] [00:14:21/00:41:43, 0.691s/it]: train_loss_raw=1.5085, running_loss=1.5317, LR=0.000100
[2025-08-26 04:13:46,760][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025600] [Batch 01255/04869] [00:14:27/00:41:37, 0.691s/it]: train_loss_raw=1.5951, running_loss=1.5353, LR=0.000100
[2025-08-26 04:13:52,528][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025608] [Batch 01263/04869] [00:14:33/00:41:33, 0.691s/it]: train_loss_raw=1.6063, running_loss=1.5367, LR=0.000100
[2025-08-26 04:13:58,178][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025616] [Batch 01271/04869] [00:14:38/00:41:27, 0.691s/it]: train_loss_raw=1.5868, running_loss=1.5376, LR=0.000100
[2025-08-26 04:14:03,432][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025624] [Batch 01279/04869] [00:14:44/00:41:21, 0.691s/it]: train_loss_raw=1.5768, running_loss=1.5366, LR=0.000100
[2025-08-26 04:14:08,672][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025632] [Batch 01287/04869] [00:14:49/00:41:15, 0.691s/it]: train_loss_raw=1.6182, running_loss=1.5355, LR=0.000100
[2025-08-26 04:14:13,987][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025640] [Batch 01295/04869] [00:14:54/00:41:09, 0.691s/it]: train_loss_raw=1.5361, running_loss=1.5356, LR=0.000100
[2025-08-26 04:14:20,082][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025648] [Batch 01303/04869] [00:15:00/00:41:05, 0.691s/it]: train_loss_raw=1.5249, running_loss=1.5350, LR=0.000100
[2025-08-26 04:14:25,320][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025656] [Batch 01311/04869] [00:15:06/00:40:58, 0.691s/it]: train_loss_raw=1.5128, running_loss=1.5322, LR=0.000100
[2025-08-26 04:14:30,962][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025664] [Batch 01319/04869] [00:15:11/00:40:53, 0.691s/it]: train_loss_raw=1.5991, running_loss=1.5336, LR=0.000100
[2025-08-26 04:14:36,398][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025672] [Batch 01327/04869] [00:15:17/00:40:47, 0.691s/it]: train_loss_raw=1.6420, running_loss=1.5354, LR=0.000100
[2025-08-26 04:14:42,050][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025680] [Batch 01335/04869] [00:15:22/00:40:42, 0.691s/it]: train_loss_raw=1.5536, running_loss=1.5346, LR=0.000100
[2025-08-26 04:14:47,301][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025688] [Batch 01343/04869] [00:15:27/00:40:36, 0.691s/it]: train_loss_raw=1.5130, running_loss=1.5320, LR=0.000100
[2025-08-26 04:14:52,480][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025696] [Batch 01351/04869] [00:15:33/00:40:29, 0.691s/it]: train_loss_raw=1.4829, running_loss=1.5333, LR=0.000100
[2025-08-26 04:14:57,672][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025704] [Batch 01359/04869] [00:15:38/00:40:23, 0.690s/it]: train_loss_raw=1.5561, running_loss=1.5290, LR=0.000100
[2025-08-26 04:15:03,327][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025712] [Batch 01367/04869] [00:15:44/00:40:18, 0.691s/it]: train_loss_raw=1.5153, running_loss=1.5265, LR=0.000100
[2025-08-26 04:15:08,757][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025720] [Batch 01375/04869] [00:15:49/00:40:12, 0.691s/it]: train_loss_raw=1.6314, running_loss=1.5269, LR=0.000100
[2025-08-26 04:15:14,428][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025728] [Batch 01383/04869] [00:15:55/00:40:07, 0.691s/it]: train_loss_raw=1.5635, running_loss=1.5259, LR=0.000100
[2025-08-26 04:15:20,001][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025736] [Batch 01391/04869] [00:16:00/00:40:02, 0.691s/it]: train_loss_raw=1.3882, running_loss=1.5252, LR=0.000100
[2025-08-26 04:15:26,346][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025744] [Batch 01399/04869] [00:16:07/00:39:58, 0.691s/it]: train_loss_raw=1.5524, running_loss=1.5218, LR=0.000100
[2025-08-26 04:15:31,977][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025752] [Batch 01407/04869] [00:16:12/00:39:53, 0.691s/it]: train_loss_raw=1.5096, running_loss=1.5237, LR=0.000100
[2025-08-26 04:15:37,791][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025760] [Batch 01415/04869] [00:16:18/00:39:48, 0.692s/it]: train_loss_raw=1.4706, running_loss=1.5260, LR=0.000100
[2025-08-26 04:15:43,182][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025768] [Batch 01423/04869] [00:16:23/00:39:42, 0.691s/it]: train_loss_raw=1.5667, running_loss=1.5249, LR=0.000100
[2025-08-26 04:15:48,973][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025776] [Batch 01431/04869] [00:16:29/00:39:37, 0.692s/it]: train_loss_raw=1.4628, running_loss=1.5258, LR=0.000100
[2025-08-26 04:15:54,426][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025784] [Batch 01439/04869] [00:16:35/00:39:31, 0.692s/it]: train_loss_raw=1.4862, running_loss=1.5255, LR=0.000100
[2025-08-26 04:15:59,631][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025792] [Batch 01447/04869] [00:16:40/00:39:25, 0.691s/it]: train_loss_raw=1.5583, running_loss=1.5249, LR=0.000100
[2025-08-26 04:16:05,460][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025800] [Batch 01455/04869] [00:16:46/00:39:20, 0.692s/it]: train_loss_raw=1.5560, running_loss=1.5252, LR=0.000100
[2025-08-26 04:16:11,555][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025808] [Batch 01463/04869] [00:16:52/00:39:16, 0.692s/it]: train_loss_raw=1.5360, running_loss=1.5252, LR=0.000100
[2025-08-26 04:16:16,835][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025816] [Batch 01471/04869] [00:16:57/00:39:10, 0.692s/it]: train_loss_raw=1.6078, running_loss=1.5271, LR=0.000100
[2025-08-26 04:16:22,384][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025824] [Batch 01479/04869] [00:17:03/00:39:04, 0.692s/it]: train_loss_raw=1.5368, running_loss=1.5294, LR=0.000100
[2025-08-26 04:16:27,573][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025832] [Batch 01487/04869] [00:17:08/00:38:58, 0.691s/it]: train_loss_raw=1.6221, running_loss=1.5297, LR=0.000100
[2025-08-26 04:16:32,808][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025840] [Batch 01495/04869] [00:17:13/00:38:52, 0.691s/it]: train_loss_raw=1.5031, running_loss=1.5318, LR=0.000100
[2025-08-26 04:16:38,004][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025848] [Batch 01503/04869] [00:17:18/00:38:46, 0.691s/it]: train_loss_raw=1.5988, running_loss=1.5321, LR=0.000100
[2025-08-26 04:16:43,347][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025856] [Batch 01511/04869] [00:17:24/00:38:40, 0.691s/it]: train_loss_raw=1.4934, running_loss=1.5275, LR=0.000100
[2025-08-26 04:16:48,782][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025864] [Batch 01519/04869] [00:17:29/00:38:34, 0.691s/it]: train_loss_raw=1.5091, running_loss=1.5270, LR=0.000100
[2025-08-26 04:16:54,279][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025872] [Batch 01527/04869] [00:17:34/00:38:28, 0.691s/it]: train_loss_raw=1.5390, running_loss=1.5296, LR=0.000100
[2025-08-26 04:17:00,156][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025880] [Batch 01535/04869] [00:17:40/00:38:24, 0.691s/it]: train_loss_raw=1.5107, running_loss=1.5274, LR=0.000100
[2025-08-26 04:17:05,566][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025888] [Batch 01543/04869] [00:17:46/00:38:18, 0.691s/it]: train_loss_raw=1.5079, running_loss=1.5280, LR=0.000100
[2025-08-26 04:17:10,755][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025896] [Batch 01551/04869] [00:17:51/00:38:12, 0.691s/it]: train_loss_raw=1.4968, running_loss=1.5244, LR=0.000100
[2025-08-26 04:17:16,354][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025904] [Batch 01559/04869] [00:17:57/00:38:06, 0.691s/it]: train_loss_raw=1.4884, running_loss=1.5226, LR=0.000100
[2025-08-26 04:17:21,617][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025912] [Batch 01567/04869] [00:18:02/00:38:00, 0.691s/it]: train_loss_raw=1.5665, running_loss=1.5229, LR=0.000100
[2025-08-26 04:17:26,850][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025920] [Batch 01575/04869] [00:18:07/00:37:54, 0.690s/it]: train_loss_raw=1.4071, running_loss=1.5203, LR=0.000100
[2025-08-26 04:17:32,049][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025928] [Batch 01583/04869] [00:18:12/00:37:48, 0.690s/it]: train_loss_raw=1.5820, running_loss=1.5213, LR=0.000100
[2025-08-26 04:17:37,261][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025936] [Batch 01591/04869] [00:18:17/00:37:42, 0.690s/it]: train_loss_raw=1.5079, running_loss=1.5211, LR=0.000100
[2025-08-26 04:17:42,487][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025944] [Batch 01599/04869] [00:18:23/00:37:36, 0.690s/it]: train_loss_raw=1.4869, running_loss=1.5201, LR=0.000100
[2025-08-26 04:17:47,685][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025952] [Batch 01607/04869] [00:18:28/00:37:29, 0.690s/it]: train_loss_raw=1.6883, running_loss=1.5213, LR=0.000100
[2025-08-26 04:17:53,386][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025960] [Batch 01615/04869] [00:18:34/00:37:24, 0.690s/it]: train_loss_raw=1.4628, running_loss=1.5217, LR=0.000100
[2025-08-26 04:17:58,606][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025968] [Batch 01623/04869] [00:18:39/00:37:18, 0.690s/it]: train_loss_raw=1.5476, running_loss=1.5171, LR=0.000100
[2025-08-26 04:18:04,256][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025976] [Batch 01631/04869] [00:18:44/00:37:13, 0.690s/it]: train_loss_raw=1.5203, running_loss=1.5185, LR=0.000100
[2025-08-26 04:18:09,447][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025984] [Batch 01639/04869] [00:18:50/00:37:07, 0.690s/it]: train_loss_raw=1.5551, running_loss=1.5202, LR=0.000100
[2025-08-26 04:18:14,650][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 025992] [Batch 01647/04869] [00:18:55/00:37:01, 0.689s/it]: train_loss_raw=1.4652, running_loss=1.5190, LR=0.000100
[2025-08-26 04:18:19,876][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026000] [Batch 01655/04869] [00:19:00/00:36:54, 0.689s/it]: train_loss_raw=1.5177, running_loss=1.5179, LR=0.000100
[2025-08-26 04:18:29,351][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026008] [Batch 01663/04869] [00:19:10/00:36:57, 0.692s/it]: train_loss_raw=1.5067, running_loss=1.5179, LR=0.000100
[2025-08-26 04:18:34,916][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026016] [Batch 01671/04869] [00:19:15/00:36:51, 0.692s/it]: train_loss_raw=1.4445, running_loss=1.5182, LR=0.000100
[2025-08-26 04:18:40,323][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026024] [Batch 01679/04869] [00:19:21/00:36:45, 0.691s/it]: train_loss_raw=1.5270, running_loss=1.5193, LR=0.000100
[2025-08-26 04:18:45,787][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026032] [Batch 01687/04869] [00:19:26/00:36:40, 0.691s/it]: train_loss_raw=1.5818, running_loss=1.5213, LR=0.000100
[2025-08-26 04:18:51,320][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026040] [Batch 01695/04869] [00:19:32/00:36:34, 0.691s/it]: train_loss_raw=1.5512, running_loss=1.5223, LR=0.000100
[2025-08-26 04:18:56,765][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026048] [Batch 01703/04869] [00:19:37/00:36:28, 0.691s/it]: train_loss_raw=1.5559, running_loss=1.5222, LR=0.000100
[2025-08-26 04:19:02,544][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026056] [Batch 01711/04869] [00:19:43/00:36:23, 0.692s/it]: train_loss_raw=1.5051, running_loss=1.5238, LR=0.000100
[2025-08-26 04:19:07,736][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026064] [Batch 01719/04869] [00:19:48/00:36:17, 0.691s/it]: train_loss_raw=1.5259, running_loss=1.5252, LR=0.000100
[2025-08-26 04:19:12,962][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026072] [Batch 01727/04869] [00:19:53/00:36:11, 0.691s/it]: train_loss_raw=1.5167, running_loss=1.5277, LR=0.000100
[2025-08-26 04:19:18,713][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026080] [Batch 01735/04869] [00:19:59/00:36:06, 0.691s/it]: train_loss_raw=1.5571, running_loss=1.5283, LR=0.000100
[2025-08-26 04:19:24,442][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026088] [Batch 01743/04869] [00:20:05/00:36:01, 0.691s/it]: train_loss_raw=1.4225, running_loss=1.5264, LR=0.000100
[2025-08-26 04:19:30,041][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026096] [Batch 01751/04869] [00:20:10/00:35:55, 0.691s/it]: train_loss_raw=1.5535, running_loss=1.5258, LR=0.000100
[2025-08-26 04:19:36,371][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026104] [Batch 01759/04869] [00:20:17/00:35:51, 0.692s/it]: train_loss_raw=1.5310, running_loss=1.5273, LR=0.000100
[2025-08-26 04:19:42,596][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026112] [Batch 01767/04869] [00:20:23/00:35:47, 0.692s/it]: train_loss_raw=1.5925, running_loss=1.5260, LR=0.000100
[2025-08-26 04:19:48,595][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026120] [Batch 01775/04869] [00:20:29/00:35:42, 0.693s/it]: train_loss_raw=1.5732, running_loss=1.5272, LR=0.000100
[2025-08-26 04:19:54,282][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026128] [Batch 01783/04869] [00:20:34/00:35:37, 0.693s/it]: train_loss_raw=1.5130, running_loss=1.5280, LR=0.000100
[2025-08-26 04:19:59,682][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026136] [Batch 01791/04869] [00:20:40/00:35:31, 0.693s/it]: train_loss_raw=1.6142, running_loss=1.5300, LR=0.000100
[2025-08-26 04:20:04,881][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026144] [Batch 01799/04869] [00:20:45/00:35:25, 0.692s/it]: train_loss_raw=1.4973, running_loss=1.5263, LR=0.000100
[2025-08-26 04:20:10,136][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026152] [Batch 01807/04869] [00:20:50/00:35:19, 0.692s/it]: train_loss_raw=1.5381, running_loss=1.5255, LR=0.000100
[2025-08-26 04:20:15,348][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026160] [Batch 01815/04869] [00:20:56/00:35:13, 0.692s/it]: train_loss_raw=1.5469, running_loss=1.5251, LR=0.000100
[2025-08-26 04:20:20,578][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026168] [Batch 01823/04869] [00:21:01/00:35:07, 0.692s/it]: train_loss_raw=1.5707, running_loss=1.5242, LR=0.000100
[2025-08-26 04:20:25,811][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026176] [Batch 01831/04869] [00:21:06/00:35:01, 0.692s/it]: train_loss_raw=1.5429, running_loss=1.5245, LR=0.000100
[2025-08-26 04:20:31,522][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026184] [Batch 01839/04869] [00:21:12/00:34:56, 0.692s/it]: train_loss_raw=1.4622, running_loss=1.5254, LR=0.000100
[2025-08-26 04:20:36,744][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026192] [Batch 01847/04869] [00:21:17/00:34:50, 0.692s/it]: train_loss_raw=1.5545, running_loss=1.5228, LR=0.000100
[2025-08-26 04:20:41,954][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026200] [Batch 01855/04869] [00:21:22/00:34:44, 0.691s/it]: train_loss_raw=1.5517, running_loss=1.5206, LR=0.000100
[2025-08-26 04:20:47,555][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026208] [Batch 01863/04869] [00:21:28/00:34:38, 0.691s/it]: train_loss_raw=1.5481, running_loss=1.5218, LR=0.000100
[2025-08-26 04:20:53,172][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026216] [Batch 01871/04869] [00:21:33/00:34:33, 0.692s/it]: train_loss_raw=1.5951, running_loss=1.5220, LR=0.000100
[2025-08-26 04:20:58,664][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026224] [Batch 01879/04869] [00:21:39/00:34:27, 0.692s/it]: train_loss_raw=1.3795, running_loss=1.5218, LR=0.000100
[2025-08-26 04:21:03,896][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026232] [Batch 01887/04869] [00:21:44/00:34:21, 0.691s/it]: train_loss_raw=1.5733, running_loss=1.5196, LR=0.000100
[2025-08-26 04:21:09,086][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026240] [Batch 01895/04869] [00:21:49/00:34:15, 0.691s/it]: train_loss_raw=1.4666, running_loss=1.5190, LR=0.000100
[2025-08-26 04:21:14,322][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026248] [Batch 01903/04869] [00:21:55/00:34:09, 0.691s/it]: train_loss_raw=1.4401, running_loss=1.5205, LR=0.000100
[2025-08-26 04:21:19,535][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026256] [Batch 01911/04869] [00:22:00/00:34:03, 0.691s/it]: train_loss_raw=1.5539, running_loss=1.5209, LR=0.000100
[2025-08-26 04:21:24,839][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026264] [Batch 01919/04869] [00:22:05/00:33:57, 0.691s/it]: train_loss_raw=1.6080, running_loss=1.5215, LR=0.000100
[2025-08-26 04:21:30,973][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026272] [Batch 01927/04869] [00:22:11/00:33:53, 0.691s/it]: train_loss_raw=1.5912, running_loss=1.5224, LR=0.000100
[2025-08-26 04:21:37,129][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026280] [Batch 01935/04869] [00:22:17/00:33:48, 0.691s/it]: train_loss_raw=1.6412, running_loss=1.5261, LR=0.000100
[2025-08-26 04:21:42,469][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026288] [Batch 01943/04869] [00:22:23/00:33:42, 0.691s/it]: train_loss_raw=1.5105, running_loss=1.5276, LR=0.000100
[2025-08-26 04:21:47,682][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026296] [Batch 01951/04869] [00:22:28/00:33:36, 0.691s/it]: train_loss_raw=1.4815, running_loss=1.5265, LR=0.000100
[2025-08-26 04:21:52,902][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026304] [Batch 01959/04869] [00:22:33/00:33:30, 0.691s/it]: train_loss_raw=1.4386, running_loss=1.5249, LR=0.000100
[2025-08-26 04:21:58,615][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026312] [Batch 01967/04869] [00:22:39/00:33:25, 0.691s/it]: train_loss_raw=1.5704, running_loss=1.5249, LR=0.000100
[2025-08-26 04:22:04,250][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026320] [Batch 01975/04869] [00:22:44/00:33:20, 0.691s/it]: train_loss_raw=1.5180, running_loss=1.5240, LR=0.000100
[2025-08-26 04:22:09,879][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026328] [Batch 01983/04869] [00:22:50/00:33:14, 0.691s/it]: train_loss_raw=1.3660, running_loss=1.5205, LR=0.000100
[2025-08-26 04:22:15,109][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026336] [Batch 01991/04869] [00:22:55/00:33:08, 0.691s/it]: train_loss_raw=1.5494, running_loss=1.5186, LR=0.000100
[2025-08-26 04:22:20,314][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026344] [Batch 01999/04869] [00:23:00/00:33:02, 0.691s/it]: train_loss_raw=1.6337, running_loss=1.5208, LR=0.000100
[2025-08-26 04:22:26,169][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026352] [Batch 02007/04869] [00:23:06/00:32:57, 0.691s/it]: train_loss_raw=1.5463, running_loss=1.5225, LR=0.000100
[2025-08-26 04:22:32,105][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026360] [Batch 02015/04869] [00:23:12/00:32:52, 0.691s/it]: train_loss_raw=1.5166, running_loss=1.5197, LR=0.000100
[2025-08-26 04:22:37,293][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026368] [Batch 02023/04869] [00:23:17/00:32:46, 0.691s/it]: train_loss_raw=1.4869, running_loss=1.5168, LR=0.000100
[2025-08-26 04:22:42,500][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026376] [Batch 02031/04869] [00:23:23/00:32:40, 0.691s/it]: train_loss_raw=1.5362, running_loss=1.5190, LR=0.000100
[2025-08-26 04:22:47,782][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026384] [Batch 02039/04869] [00:23:28/00:32:34, 0.691s/it]: train_loss_raw=1.4873, running_loss=1.5184, LR=0.000100
[2025-08-26 04:22:53,848][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026392] [Batch 02047/04869] [00:23:34/00:32:30, 0.691s/it]: train_loss_raw=1.5259, running_loss=1.5177, LR=0.000100
[2025-08-26 04:22:59,610][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026400] [Batch 02055/04869] [00:23:40/00:32:24, 0.691s/it]: train_loss_raw=1.4399, running_loss=1.5176, LR=0.000100
[2025-08-26 04:23:04,826][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026408] [Batch 02063/04869] [00:23:45/00:32:18, 0.691s/it]: train_loss_raw=1.5850, running_loss=1.5211, LR=0.000100
[2025-08-26 04:23:10,275][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026416] [Batch 02071/04869] [00:23:50/00:32:13, 0.691s/it]: train_loss_raw=1.5281, running_loss=1.5208, LR=0.000100
[2025-08-26 04:23:15,980][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026424] [Batch 02079/04869] [00:23:56/00:32:07, 0.691s/it]: train_loss_raw=1.4489, running_loss=1.5194, LR=0.000100
[2025-08-26 04:23:21,883][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026432] [Batch 02087/04869] [00:24:02/00:32:02, 0.691s/it]: train_loss_raw=1.4103, running_loss=1.5206, LR=0.000100
[2025-08-26 04:23:27,077][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026440] [Batch 02095/04869] [00:24:07/00:31:56, 0.691s/it]: train_loss_raw=1.5123, running_loss=1.5204, LR=0.000100
[2025-08-26 04:23:32,508][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026448] [Batch 02103/04869] [00:24:13/00:31:51, 0.691s/it]: train_loss_raw=1.5963, running_loss=1.5218, LR=0.000100
[2025-08-26 04:23:37,705][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026456] [Batch 02111/04869] [00:24:18/00:31:45, 0.691s/it]: train_loss_raw=1.4358, running_loss=1.5207, LR=0.000100
[2025-08-26 04:23:43,862][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026464] [Batch 02119/04869] [00:24:24/00:31:40, 0.691s/it]: train_loss_raw=1.5302, running_loss=1.5207, LR=0.000100
[2025-08-26 04:23:49,109][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026472] [Batch 02127/04869] [00:24:29/00:31:34, 0.691s/it]: train_loss_raw=1.6082, running_loss=1.5223, LR=0.000100
[2025-08-26 04:23:54,441][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026480] [Batch 02135/04869] [00:24:35/00:31:28, 0.691s/it]: train_loss_raw=1.6125, running_loss=1.5235, LR=0.000100
[2025-08-26 04:24:00,016][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026488] [Batch 02143/04869] [00:24:40/00:31:23, 0.691s/it]: train_loss_raw=1.5643, running_loss=1.5249, LR=0.000100
[2025-08-26 04:24:05,494][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026496] [Batch 02151/04869] [00:24:46/00:31:17, 0.691s/it]: train_loss_raw=1.4927, running_loss=1.5240, LR=0.000100
[2025-08-26 04:24:11,079][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026504] [Batch 02159/04869] [00:24:51/00:31:12, 0.691s/it]: train_loss_raw=1.5234, running_loss=1.5225, LR=0.000100
[2025-08-26 04:24:16,338][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026512] [Batch 02167/04869] [00:24:57/00:31:06, 0.691s/it]: train_loss_raw=1.4186, running_loss=1.5216, LR=0.000100
[2025-08-26 04:24:21,663][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026520] [Batch 02175/04869] [00:25:02/00:31:00, 0.691s/it]: train_loss_raw=1.5066, running_loss=1.5203, LR=0.000100
[2025-08-26 04:24:27,009][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026528] [Batch 02183/04869] [00:25:07/00:30:55, 0.691s/it]: train_loss_raw=1.4292, running_loss=1.5194, LR=0.000100
[2025-08-26 04:24:32,611][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026536] [Batch 02191/04869] [00:25:13/00:30:49, 0.691s/it]: train_loss_raw=1.5098, running_loss=1.5191, LR=0.000100
[2025-08-26 04:24:38,385][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026544] [Batch 02199/04869] [00:25:19/00:30:44, 0.691s/it]: train_loss_raw=1.5291, running_loss=1.5234, LR=0.000100
[2025-08-26 04:24:43,877][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026552] [Batch 02207/04869] [00:25:24/00:30:38, 0.691s/it]: train_loss_raw=1.6025, running_loss=1.5244, LR=0.000100
[2025-08-26 04:24:49,463][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026560] [Batch 02215/04869] [00:25:30/00:30:33, 0.691s/it]: train_loss_raw=1.4802, running_loss=1.5236, LR=0.000100
[2025-08-26 04:24:54,799][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026568] [Batch 02223/04869] [00:25:35/00:30:27, 0.691s/it]: train_loss_raw=1.3907, running_loss=1.5213, LR=0.000100
[2025-08-26 04:25:00,669][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026576] [Batch 02231/04869] [00:25:41/00:30:22, 0.691s/it]: train_loss_raw=1.4982, running_loss=1.5205, LR=0.000100
[2025-08-26 04:25:06,671][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026584] [Batch 02239/04869] [00:25:47/00:30:17, 0.691s/it]: train_loss_raw=1.6338, running_loss=1.5222, LR=0.000100
[2025-08-26 04:25:12,745][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026592] [Batch 02247/04869] [00:25:53/00:30:12, 0.691s/it]: train_loss_raw=1.5853, running_loss=1.5245, LR=0.000100
[2025-08-26 04:25:18,081][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026600] [Batch 02255/04869] [00:25:58/00:30:06, 0.691s/it]: train_loss_raw=1.5670, running_loss=1.5235, LR=0.000100
[2025-08-26 04:25:23,294][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026608] [Batch 02263/04869] [00:26:03/00:30:01, 0.691s/it]: train_loss_raw=1.5347, running_loss=1.5234, LR=0.000100
[2025-08-26 04:25:28,697][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026616] [Batch 02271/04869] [00:26:09/00:29:55, 0.691s/it]: train_loss_raw=1.5256, running_loss=1.5203, LR=0.000100
[2025-08-26 04:25:34,411][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026624] [Batch 02279/04869] [00:26:15/00:29:50, 0.691s/it]: train_loss_raw=1.4397, running_loss=1.5202, LR=0.000100
[2025-08-26 04:25:39,912][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026632] [Batch 02287/04869] [00:26:20/00:29:44, 0.691s/it]: train_loss_raw=1.5775, running_loss=1.5213, LR=0.000100
[2025-08-26 04:25:45,094][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026640] [Batch 02295/04869] [00:26:25/00:29:38, 0.691s/it]: train_loss_raw=1.5071, running_loss=1.5214, LR=0.000100
[2025-08-26 04:25:50,475][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026648] [Batch 02303/04869] [00:26:31/00:29:32, 0.691s/it]: train_loss_raw=1.5442, running_loss=1.5213, LR=0.000100
[2025-08-26 04:25:55,890][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026656] [Batch 02311/04869] [00:26:36/00:29:27, 0.691s/it]: train_loss_raw=1.5021, running_loss=1.5206, LR=0.000100
[2025-08-26 04:26:02,004][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026664] [Batch 02319/04869] [00:26:42/00:29:22, 0.691s/it]: train_loss_raw=1.6202, running_loss=1.5208, LR=0.000100
[2025-08-26 04:26:07,905][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026672] [Batch 02327/04869] [00:26:48/00:29:17, 0.691s/it]: train_loss_raw=1.5124, running_loss=1.5218, LR=0.000100
[2025-08-26 04:26:13,310][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026680] [Batch 02335/04869] [00:26:53/00:29:11, 0.691s/it]: train_loss_raw=1.4382, running_loss=1.5177, LR=0.000100
[2025-08-26 04:26:18,642][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026688] [Batch 02343/04869] [00:26:59/00:29:05, 0.691s/it]: train_loss_raw=1.5565, running_loss=1.5211, LR=0.000100
[2025-08-26 04:26:23,840][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026696] [Batch 02351/04869] [00:27:04/00:28:59, 0.691s/it]: train_loss_raw=1.5380, running_loss=1.5193, LR=0.000100
[2025-08-26 04:26:29,076][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026704] [Batch 02359/04869] [00:27:09/00:28:54, 0.691s/it]: train_loss_raw=1.4210, running_loss=1.5202, LR=0.000100
[2025-08-26 04:26:35,192][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026712] [Batch 02367/04869] [00:27:15/00:28:49, 0.691s/it]: train_loss_raw=1.4080, running_loss=1.5155, LR=0.000100
[2025-08-26 04:26:41,291][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026720] [Batch 02375/04869] [00:27:21/00:28:44, 0.691s/it]: train_loss_raw=1.5455, running_loss=1.5150, LR=0.000100
[2025-08-26 04:26:47,544][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026728] [Batch 02383/04869] [00:27:28/00:28:39, 0.692s/it]: train_loss_raw=1.4015, running_loss=1.5098, LR=0.000100
[2025-08-26 04:26:53,949][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026736] [Batch 02391/04869] [00:27:34/00:28:34, 0.692s/it]: train_loss_raw=1.5699, running_loss=1.5095, LR=0.000100
[2025-08-26 04:26:59,766][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026744] [Batch 02399/04869] [00:27:40/00:28:29, 0.692s/it]: train_loss_raw=1.5652, running_loss=1.5120, LR=0.000100
[2025-08-26 04:27:05,536][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026752] [Batch 02407/04869] [00:27:46/00:28:24, 0.692s/it]: train_loss_raw=1.5401, running_loss=1.5117, LR=0.000100
[2025-08-26 04:27:11,624][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026760] [Batch 02415/04869] [00:27:52/00:28:19, 0.692s/it]: train_loss_raw=1.5376, running_loss=1.5122, LR=0.000100
[2025-08-26 04:27:17,537][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026768] [Batch 02423/04869] [00:27:58/00:28:14, 0.693s/it]: train_loss_raw=1.5307, running_loss=1.5124, LR=0.000100
[2025-08-26 04:27:23,360][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026776] [Batch 02431/04869] [00:28:04/00:28:08, 0.693s/it]: train_loss_raw=1.5490, running_loss=1.5155, LR=0.000100
[2025-08-26 04:27:28,634][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026784] [Batch 02439/04869] [00:28:09/00:28:03, 0.693s/it]: train_loss_raw=1.5642, running_loss=1.5164, LR=0.000100
[2025-08-26 04:27:34,194][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026792] [Batch 02447/04869] [00:28:14/00:27:57, 0.693s/it]: train_loss_raw=1.4636, running_loss=1.5175, LR=0.000100
[2025-08-26 04:27:39,402][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026800] [Batch 02455/04869] [00:28:20/00:27:51, 0.692s/it]: train_loss_raw=1.4875, running_loss=1.5178, LR=0.000100
[2025-08-26 04:27:44,862][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026808] [Batch 02463/04869] [00:28:25/00:27:46, 0.692s/it]: train_loss_raw=1.4788, running_loss=1.5166, LR=0.000100
[2025-08-26 04:27:50,756][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026816] [Batch 02471/04869] [00:28:31/00:27:40, 0.693s/it]: train_loss_raw=1.5409, running_loss=1.5173, LR=0.000100
[2025-08-26 04:27:56,507][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026824] [Batch 02479/04869] [00:28:37/00:27:35, 0.693s/it]: train_loss_raw=1.4863, running_loss=1.5165, LR=0.000100
[2025-08-26 04:28:01,747][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026832] [Batch 02487/04869] [00:28:42/00:27:29, 0.693s/it]: train_loss_raw=1.4977, running_loss=1.5164, LR=0.000100
[2025-08-26 04:28:07,020][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026840] [Batch 02495/04869] [00:28:47/00:27:23, 0.692s/it]: train_loss_raw=1.5686, running_loss=1.5159, LR=0.000100
[2025-08-26 04:28:12,492][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026848] [Batch 02503/04869] [00:28:53/00:27:18, 0.692s/it]: train_loss_raw=1.6375, running_loss=1.5170, LR=0.000100
[2025-08-26 04:28:17,765][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026856] [Batch 02511/04869] [00:28:58/00:27:12, 0.692s/it]: train_loss_raw=1.5393, running_loss=1.5162, LR=0.000100
[2025-08-26 04:28:22,972][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026864] [Batch 02519/04869] [00:29:03/00:27:06, 0.692s/it]: train_loss_raw=1.5017, running_loss=1.5138, LR=0.000100
[2025-08-26 04:28:28,182][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026872] [Batch 02527/04869] [00:29:08/00:27:00, 0.692s/it]: train_loss_raw=1.4626, running_loss=1.5158, LR=0.000100
[2025-08-26 04:28:33,904][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026880] [Batch 02535/04869] [00:29:14/00:26:55, 0.692s/it]: train_loss_raw=1.5154, running_loss=1.5169, LR=0.000100
[2025-08-26 04:28:39,261][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026888] [Batch 02543/04869] [00:29:19/00:26:49, 0.692s/it]: train_loss_raw=1.5927, running_loss=1.5177, LR=0.000100
[2025-08-26 04:28:44,459][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026896] [Batch 02551/04869] [00:29:25/00:26:43, 0.692s/it]: train_loss_raw=1.5401, running_loss=1.5158, LR=0.000100
[2025-08-26 04:28:49,818][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026904] [Batch 02559/04869] [00:29:30/00:26:38, 0.692s/it]: train_loss_raw=1.3734, running_loss=1.5131, LR=0.000100
[2025-08-26 04:28:55,472][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026912] [Batch 02567/04869] [00:29:36/00:26:32, 0.692s/it]: train_loss_raw=1.4485, running_loss=1.5113, LR=0.000100
[2025-08-26 04:29:00,921][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026920] [Batch 02575/04869] [00:29:41/00:26:27, 0.692s/it]: train_loss_raw=1.5323, running_loss=1.5123, LR=0.000100
[2025-08-26 04:29:06,108][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026928] [Batch 02583/04869] [00:29:46/00:26:21, 0.692s/it]: train_loss_raw=1.5193, running_loss=1.5125, LR=0.000100
[2025-08-26 04:29:11,723][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026936] [Batch 02591/04869] [00:29:52/00:26:15, 0.692s/it]: train_loss_raw=1.5246, running_loss=1.5131, LR=0.000100
[2025-08-26 04:29:16,945][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026944] [Batch 02599/04869] [00:29:57/00:26:10, 0.692s/it]: train_loss_raw=1.5402, running_loss=1.5120, LR=0.000100
[2025-08-26 04:29:22,212][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026952] [Batch 02607/04869] [00:30:02/00:26:04, 0.692s/it]: train_loss_raw=1.4876, running_loss=1.5132, LR=0.000100
[2025-08-26 04:29:27,546][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026960] [Batch 02615/04869] [00:30:08/00:25:58, 0.691s/it]: train_loss_raw=1.5320, running_loss=1.5125, LR=0.000100
[2025-08-26 04:29:32,895][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026968] [Batch 02623/04869] [00:30:13/00:25:52, 0.691s/it]: train_loss_raw=1.4746, running_loss=1.5122, LR=0.000100
[2025-08-26 04:29:38,777][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026976] [Batch 02631/04869] [00:30:19/00:25:47, 0.692s/it]: train_loss_raw=1.5790, running_loss=1.5144, LR=0.000100
[2025-08-26 04:29:44,202][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026984] [Batch 02639/04869] [00:30:24/00:25:42, 0.692s/it]: train_loss_raw=1.4948, running_loss=1.5154, LR=0.000100
[2025-08-26 04:29:49,584][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 026992] [Batch 02647/04869] [00:30:30/00:25:36, 0.691s/it]: train_loss_raw=1.4656, running_loss=1.5157, LR=0.000100
[2025-08-26 04:29:55,230][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027000] [Batch 02655/04869] [00:30:35/00:25:30, 0.691s/it]: train_loss_raw=1.4862, running_loss=1.5140, LR=0.000100
[2025-08-26 04:30:01,400][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027008] [Batch 02663/04869] [00:30:42/00:25:25, 0.692s/it]: train_loss_raw=1.4484, running_loss=1.5092, LR=0.000100
[2025-08-26 04:30:07,007][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027016] [Batch 02671/04869] [00:30:47/00:25:20, 0.692s/it]: train_loss_raw=1.5503, running_loss=1.5108, LR=0.000100
[2025-08-26 04:30:12,272][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027024] [Batch 02679/04869] [00:30:52/00:25:14, 0.692s/it]: train_loss_raw=1.4963, running_loss=1.5097, LR=0.000100
[2025-08-26 04:30:17,751][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027032] [Batch 02687/04869] [00:30:58/00:25:09, 0.692s/it]: train_loss_raw=1.5359, running_loss=1.5085, LR=0.000100
[2025-08-26 04:30:23,682][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027040] [Batch 02695/04869] [00:31:04/00:25:03, 0.692s/it]: train_loss_raw=1.5206, running_loss=1.5069, LR=0.000100
[2025-08-26 04:30:29,224][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027048] [Batch 02703/04869] [00:31:09/00:24:58, 0.692s/it]: train_loss_raw=1.4128, running_loss=1.5063, LR=0.000100
[2025-08-26 04:30:35,003][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027056] [Batch 02711/04869] [00:31:15/00:24:53, 0.692s/it]: train_loss_raw=1.4241, running_loss=1.5082, LR=0.000100
[2025-08-26 04:30:40,354][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027064] [Batch 02719/04869] [00:31:21/00:24:47, 0.692s/it]: train_loss_raw=1.4665, running_loss=1.5087, LR=0.000100
[2025-08-26 04:30:45,717][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027072] [Batch 02727/04869] [00:31:26/00:24:41, 0.692s/it]: train_loss_raw=1.3988, running_loss=1.5064, LR=0.000100
[2025-08-26 04:30:51,195][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027080] [Batch 02735/04869] [00:31:31/00:24:36, 0.692s/it]: train_loss_raw=1.5569, running_loss=1.5063, LR=0.000100
[2025-08-26 04:30:57,314][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027088] [Batch 02743/04869] [00:31:37/00:24:31, 0.692s/it]: train_loss_raw=1.3757, running_loss=1.5049, LR=0.000100
[2025-08-26 04:31:02,925][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027096] [Batch 02751/04869] [00:31:43/00:24:25, 0.692s/it]: train_loss_raw=1.5643, running_loss=1.5076, LR=0.000100
[2025-08-26 04:31:08,359][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027104] [Batch 02759/04869] [00:31:49/00:24:19, 0.692s/it]: train_loss_raw=1.4992, running_loss=1.5060, LR=0.000100
[2025-08-26 04:31:13,896][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027112] [Batch 02767/04869] [00:31:54/00:24:14, 0.692s/it]: train_loss_raw=1.4782, running_loss=1.5019, LR=0.000100
[2025-08-26 04:31:19,573][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027120] [Batch 02775/04869] [00:32:00/00:24:09, 0.692s/it]: train_loss_raw=1.3850, running_loss=1.4993, LR=0.000100
[2025-08-26 04:31:25,592][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027128] [Batch 02783/04869] [00:32:06/00:24:03, 0.692s/it]: train_loss_raw=1.5164, running_loss=1.5014, LR=0.000100
[2025-08-26 04:31:31,620][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027136] [Batch 02791/04869] [00:32:12/00:23:58, 0.692s/it]: train_loss_raw=1.4610, running_loss=1.5032, LR=0.000100
[2025-08-26 04:31:36,904][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027144] [Batch 02799/04869] [00:32:17/00:23:52, 0.692s/it]: train_loss_raw=1.5320, running_loss=1.5014, LR=0.000100
[2025-08-26 04:31:42,221][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027152] [Batch 02807/04869] [00:32:22/00:23:47, 0.692s/it]: train_loss_raw=1.5598, running_loss=1.5010, LR=0.000100
[2025-08-26 04:31:47,565][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027160] [Batch 02815/04869] [00:32:28/00:23:41, 0.692s/it]: train_loss_raw=1.5057, running_loss=1.5008, LR=0.000100
[2025-08-26 04:31:53,004][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027168] [Batch 02823/04869] [00:32:33/00:23:35, 0.692s/it]: train_loss_raw=1.4538, running_loss=1.5043, LR=0.000100
[2025-08-26 04:31:58,630][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027176] [Batch 02831/04869] [00:32:39/00:23:30, 0.692s/it]: train_loss_raw=1.5210, running_loss=1.5045, LR=0.000100
[2025-08-26 04:32:04,252][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027184] [Batch 02839/04869] [00:32:44/00:23:25, 0.692s/it]: train_loss_raw=1.5801, running_loss=1.5060, LR=0.000100
[2025-08-26 04:32:09,775][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027192] [Batch 02847/04869] [00:32:50/00:23:19, 0.692s/it]: train_loss_raw=1.6061, running_loss=1.5081, LR=0.000100
[2025-08-26 04:32:14,983][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027200] [Batch 02855/04869] [00:32:55/00:23:13, 0.692s/it]: train_loss_raw=1.5816, running_loss=1.5071, LR=0.000100
[2025-08-26 04:32:20,199][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027208] [Batch 02863/04869] [00:33:00/00:23:07, 0.692s/it]: train_loss_raw=1.5654, running_loss=1.5062, LR=0.000100
[2025-08-26 04:32:25,878][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027216] [Batch 02871/04869] [00:33:06/00:23:02, 0.692s/it]: train_loss_raw=1.4203, running_loss=1.5039, LR=0.000100
[2025-08-26 04:32:31,685][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027224] [Batch 02879/04869] [00:33:12/00:22:57, 0.692s/it]: train_loss_raw=1.5802, running_loss=1.5060, LR=0.000100
[2025-08-26 04:32:37,860][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027232] [Batch 02887/04869] [00:33:18/00:22:52, 0.692s/it]: train_loss_raw=1.5416, running_loss=1.5074, LR=0.000100
[2025-08-26 04:32:43,048][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027240] [Batch 02895/04869] [00:33:23/00:22:46, 0.692s/it]: train_loss_raw=1.4589, running_loss=1.5066, LR=0.000100
[2025-08-26 04:32:48,605][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027248] [Batch 02903/04869] [00:33:29/00:22:40, 0.692s/it]: train_loss_raw=1.6107, running_loss=1.5080, LR=0.000100
[2025-08-26 04:32:53,971][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027256] [Batch 02911/04869] [00:33:34/00:22:35, 0.692s/it]: train_loss_raw=1.4869, running_loss=1.5097, LR=0.000100
[2025-08-26 04:32:59,687][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027264] [Batch 02919/04869] [00:33:40/00:22:29, 0.692s/it]: train_loss_raw=1.4749, running_loss=1.5072, LR=0.000100
[2025-08-26 04:33:05,108][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027272] [Batch 02927/04869] [00:33:45/00:22:24, 0.692s/it]: train_loss_raw=1.5104, running_loss=1.5045, LR=0.000100
[2025-08-26 04:33:10,620][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027280] [Batch 02935/04869] [00:33:51/00:22:18, 0.692s/it]: train_loss_raw=1.5118, running_loss=1.5066, LR=0.000100
[2025-08-26 04:33:16,260][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027288] [Batch 02943/04869] [00:33:56/00:22:13, 0.692s/it]: train_loss_raw=1.4822, running_loss=1.5066, LR=0.000100
[2025-08-26 04:33:21,642][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027296] [Batch 02951/04869] [00:34:02/00:22:07, 0.692s/it]: train_loss_raw=1.4680, running_loss=1.5075, LR=0.000100
[2025-08-26 04:33:26,996][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027304] [Batch 02959/04869] [00:34:07/00:22:01, 0.692s/it]: train_loss_raw=1.4467, running_loss=1.5069, LR=0.000100
[2025-08-26 04:33:32,224][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027312] [Batch 02967/04869] [00:34:12/00:21:56, 0.692s/it]: train_loss_raw=1.5956, running_loss=1.5073, LR=0.000100
[2025-08-26 04:33:37,474][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027320] [Batch 02975/04869] [00:34:18/00:21:50, 0.692s/it]: train_loss_raw=1.5798, running_loss=1.5068, LR=0.000100
[2025-08-26 04:33:43,004][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027328] [Batch 02983/04869] [00:34:23/00:21:44, 0.692s/it]: train_loss_raw=1.4969, running_loss=1.5069, LR=0.000100
[2025-08-26 04:33:48,293][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027336] [Batch 02991/04869] [00:34:28/00:21:39, 0.692s/it]: train_loss_raw=1.4338, running_loss=1.5074, LR=0.000100
[2025-08-26 04:33:53,546][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027344] [Batch 02999/04869] [00:34:34/00:21:33, 0.692s/it]: train_loss_raw=1.5358, running_loss=1.5073, LR=0.000100
[2025-08-26 04:33:58,881][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027352] [Batch 03007/04869] [00:34:39/00:21:27, 0.692s/it]: train_loss_raw=1.5294, running_loss=1.5080, LR=0.000100
[2025-08-26 04:34:04,449][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027360] [Batch 03015/04869] [00:34:45/00:21:22, 0.692s/it]: train_loss_raw=1.4540, running_loss=1.5044, LR=0.000100
[2025-08-26 04:34:10,273][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027368] [Batch 03023/04869] [00:34:50/00:21:16, 0.692s/it]: train_loss_raw=1.5779, running_loss=1.5035, LR=0.000100
[2025-08-26 04:34:15,502][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027376] [Batch 03031/04869] [00:34:56/00:21:11, 0.692s/it]: train_loss_raw=1.5293, running_loss=1.5026, LR=0.000100
[2025-08-26 04:34:21,424][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027384] [Batch 03039/04869] [00:35:02/00:21:05, 0.692s/it]: train_loss_raw=1.4521, running_loss=1.5032, LR=0.000100
[2025-08-26 04:34:26,655][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027392] [Batch 03047/04869] [00:35:07/00:21:00, 0.692s/it]: train_loss_raw=1.5247, running_loss=1.5043, LR=0.000100
[2025-08-26 04:34:32,532][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027400] [Batch 03055/04869] [00:35:13/00:20:54, 0.692s/it]: train_loss_raw=1.5515, running_loss=1.5042, LR=0.000100
[2025-08-26 04:34:38,089][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027408] [Batch 03063/04869] [00:35:18/00:20:49, 0.692s/it]: train_loss_raw=1.5123, running_loss=1.5026, LR=0.000100
[2025-08-26 04:34:43,309][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027416] [Batch 03071/04869] [00:35:23/00:20:43, 0.692s/it]: train_loss_raw=1.4770, running_loss=1.5008, LR=0.000100
[2025-08-26 04:34:48,550][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027424] [Batch 03079/04869] [00:35:29/00:20:37, 0.692s/it]: train_loss_raw=1.4663, running_loss=1.5001, LR=0.000100
[2025-08-26 04:34:54,218][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027432] [Batch 03087/04869] [00:35:34/00:20:32, 0.692s/it]: train_loss_raw=1.3687, running_loss=1.4975, LR=0.000100
[2025-08-26 04:34:59,884][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027440] [Batch 03095/04869] [00:35:40/00:20:26, 0.692s/it]: train_loss_raw=1.7162, running_loss=1.5000, LR=0.000100
[2025-08-26 04:35:05,068][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027448] [Batch 03103/04869] [00:35:45/00:20:21, 0.692s/it]: train_loss_raw=1.3392, running_loss=1.4980, LR=0.000100
[2025-08-26 04:35:10,306][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027456] [Batch 03111/04869] [00:35:50/00:20:15, 0.691s/it]: train_loss_raw=1.4600, running_loss=1.4955, LR=0.000100
[2025-08-26 04:35:15,540][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027464] [Batch 03119/04869] [00:35:56/00:20:09, 0.691s/it]: train_loss_raw=1.5342, running_loss=1.4963, LR=0.000100
[2025-08-26 04:35:20,749][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027472] [Batch 03127/04869] [00:36:01/00:20:04, 0.691s/it]: train_loss_raw=1.5145, running_loss=1.4953, LR=0.000100
[2025-08-26 04:35:26,228][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027480] [Batch 03135/04869] [00:36:06/00:19:58, 0.691s/it]: train_loss_raw=1.4932, running_loss=1.4948, LR=0.000100
[2025-08-26 04:35:32,293][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027488] [Batch 03143/04869] [00:36:12/00:19:53, 0.691s/it]: train_loss_raw=1.4790, running_loss=1.4966, LR=0.000100
[2025-08-26 04:35:37,622][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027496] [Batch 03151/04869] [00:36:18/00:19:47, 0.691s/it]: train_loss_raw=1.4565, running_loss=1.4958, LR=0.000100
[2025-08-26 04:35:42,884][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027504] [Batch 03159/04869] [00:36:23/00:19:41, 0.691s/it]: train_loss_raw=1.4800, running_loss=1.4937, LR=0.000100
[2025-08-26 04:35:48,160][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027512] [Batch 03167/04869] [00:36:28/00:19:36, 0.691s/it]: train_loss_raw=1.4445, running_loss=1.4937, LR=0.000100
[2025-08-26 04:35:53,437][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027520] [Batch 03175/04869] [00:36:34/00:19:30, 0.691s/it]: train_loss_raw=1.4601, running_loss=1.4944, LR=0.000100
[2025-08-26 04:35:58,709][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027528] [Batch 03183/04869] [00:36:39/00:19:24, 0.691s/it]: train_loss_raw=1.4314, running_loss=1.4936, LR=0.000100
[2025-08-26 04:36:04,597][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027536] [Batch 03191/04869] [00:36:45/00:19:19, 0.691s/it]: train_loss_raw=1.5641, running_loss=1.4941, LR=0.000100
[2025-08-26 04:36:10,450][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027544] [Batch 03199/04869] [00:36:51/00:19:14, 0.691s/it]: train_loss_raw=1.5029, running_loss=1.4960, LR=0.000100
[2025-08-26 04:36:16,287][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027552] [Batch 03207/04869] [00:36:56/00:19:08, 0.691s/it]: train_loss_raw=1.5702, running_loss=1.4967, LR=0.000100
[2025-08-26 04:36:21,601][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027560] [Batch 03215/04869] [00:37:02/00:19:03, 0.691s/it]: train_loss_raw=1.5502, running_loss=1.4961, LR=0.000100
[2025-08-26 04:36:26,837][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027568] [Batch 03223/04869] [00:37:07/00:18:57, 0.691s/it]: train_loss_raw=1.4295, running_loss=1.4939, LR=0.000100
[2025-08-26 04:36:32,802][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027576] [Batch 03231/04869] [00:37:13/00:18:52, 0.691s/it]: train_loss_raw=1.4445, running_loss=1.4952, LR=0.000100
[2025-08-26 04:36:38,044][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027584] [Batch 03239/04869] [00:37:18/00:18:46, 0.691s/it]: train_loss_raw=1.5314, running_loss=1.4925, LR=0.000100
[2025-08-26 04:36:43,891][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027592] [Batch 03247/04869] [00:37:24/00:18:41, 0.691s/it]: train_loss_raw=1.5477, running_loss=1.4924, LR=0.000100
[2025-08-26 04:36:49,134][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027600] [Batch 03255/04869] [00:37:29/00:18:35, 0.691s/it]: train_loss_raw=1.5399, running_loss=1.4922, LR=0.000100
[2025-08-26 04:36:54,572][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027608] [Batch 03263/04869] [00:37:35/00:18:30, 0.691s/it]: train_loss_raw=1.5386, running_loss=1.4914, LR=0.000100
[2025-08-26 04:37:00,421][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027616] [Batch 03271/04869] [00:37:41/00:18:24, 0.691s/it]: train_loss_raw=1.4966, running_loss=1.4963, LR=0.000100
[2025-08-26 04:37:05,641][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027624] [Batch 03279/04869] [00:37:46/00:18:18, 0.691s/it]: train_loss_raw=1.5305, running_loss=1.4970, LR=0.000100
[2025-08-26 04:37:10,983][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027632] [Batch 03287/04869] [00:37:51/00:18:13, 0.691s/it]: train_loss_raw=1.4950, running_loss=1.4945, LR=0.000100
[2025-08-26 04:37:16,204][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027640] [Batch 03295/04869] [00:37:56/00:18:07, 0.691s/it]: train_loss_raw=1.4036, running_loss=1.4929, LR=0.000100
[2025-08-26 04:37:21,649][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027648] [Batch 03303/04869] [00:38:02/00:18:02, 0.691s/it]: train_loss_raw=1.5908, running_loss=1.4945, LR=0.000100
[2025-08-26 04:37:27,039][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027656] [Batch 03311/04869] [00:38:07/00:17:56, 0.691s/it]: train_loss_raw=1.5677, running_loss=1.4943, LR=0.000100
[2025-08-26 04:37:32,697][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027664] [Batch 03319/04869] [00:38:13/00:17:51, 0.691s/it]: train_loss_raw=1.4284, running_loss=1.4937, LR=0.000100
[2025-08-26 04:37:38,018][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027672] [Batch 03327/04869] [00:38:18/00:17:45, 0.691s/it]: train_loss_raw=1.6211, running_loss=1.4958, LR=0.000100
[2025-08-26 04:37:43,352][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027680] [Batch 03335/04869] [00:38:24/00:17:39, 0.691s/it]: train_loss_raw=1.5008, running_loss=1.4960, LR=0.000100
[2025-08-26 04:37:48,752][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027688] [Batch 03343/04869] [00:38:29/00:17:34, 0.691s/it]: train_loss_raw=1.5030, running_loss=1.4943, LR=0.000100
[2025-08-26 04:37:54,664][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027696] [Batch 03351/04869] [00:38:35/00:17:28, 0.691s/it]: train_loss_raw=1.6037, running_loss=1.4942, LR=0.000100
[2025-08-26 04:38:00,715][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027704] [Batch 03359/04869] [00:38:41/00:17:23, 0.691s/it]: train_loss_raw=1.4553, running_loss=1.4903, LR=0.000100
[2025-08-26 04:38:06,985][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027712] [Batch 03367/04869] [00:38:47/00:17:18, 0.691s/it]: train_loss_raw=1.5304, running_loss=1.4906, LR=0.000100
[2025-08-26 04:38:12,381][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027720] [Batch 03375/04869] [00:38:53/00:17:12, 0.691s/it]: train_loss_raw=1.5801, running_loss=1.4902, LR=0.000100
[2025-08-26 04:38:17,597][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027728] [Batch 03383/04869] [00:38:58/00:17:07, 0.691s/it]: train_loss_raw=1.4300, running_loss=1.4908, LR=0.000100
[2025-08-26 04:38:22,804][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027736] [Batch 03391/04869] [00:39:03/00:17:01, 0.691s/it]: train_loss_raw=1.4903, running_loss=1.4945, LR=0.000100
[2025-08-26 04:38:28,073][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027744] [Batch 03399/04869] [00:39:08/00:16:55, 0.691s/it]: train_loss_raw=1.5377, running_loss=1.4948, LR=0.000100
[2025-08-26 04:38:33,393][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027752] [Batch 03407/04869] [00:39:14/00:16:50, 0.691s/it]: train_loss_raw=1.4877, running_loss=1.4962, LR=0.000100
[2025-08-26 04:38:38,771][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027760] [Batch 03415/04869] [00:39:19/00:16:44, 0.691s/it]: train_loss_raw=1.4951, running_loss=1.4999, LR=0.000100
[2025-08-26 04:38:44,518][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027768] [Batch 03423/04869] [00:39:25/00:16:39, 0.691s/it]: train_loss_raw=1.5682, running_loss=1.4995, LR=0.000100
[2025-08-26 04:38:50,072][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027776] [Batch 03431/04869] [00:39:30/00:16:33, 0.691s/it]: train_loss_raw=1.5595, running_loss=1.4977, LR=0.000100
[2025-08-26 04:38:55,401][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027784] [Batch 03439/04869] [00:39:36/00:16:28, 0.691s/it]: train_loss_raw=1.4487, running_loss=1.4972, LR=0.000100
[2025-08-26 04:39:01,121][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027792] [Batch 03447/04869] [00:39:41/00:16:22, 0.691s/it]: train_loss_raw=1.5480, running_loss=1.4946, LR=0.000100
[2025-08-26 04:39:06,692][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027800] [Batch 03455/04869] [00:39:47/00:16:17, 0.691s/it]: train_loss_raw=1.3871, running_loss=1.4909, LR=0.000100
[2025-08-26 04:39:11,956][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027808] [Batch 03463/04869] [00:39:52/00:16:11, 0.691s/it]: train_loss_raw=1.5794, running_loss=1.4912, LR=0.000100
[2025-08-26 04:39:17,318][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027816] [Batch 03471/04869] [00:39:58/00:16:05, 0.691s/it]: train_loss_raw=1.4150, running_loss=1.4901, LR=0.000100
[2025-08-26 04:39:22,621][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027824] [Batch 03479/04869] [00:40:03/00:16:00, 0.691s/it]: train_loss_raw=1.5438, running_loss=1.4906, LR=0.000100
[2025-08-26 04:39:28,414][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027832] [Batch 03487/04869] [00:40:09/00:15:54, 0.691s/it]: train_loss_raw=1.4935, running_loss=1.4909, LR=0.000100
[2025-08-26 04:39:34,494][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027840] [Batch 03495/04869] [00:40:15/00:15:49, 0.691s/it]: train_loss_raw=1.4573, running_loss=1.4915, LR=0.000100
[2025-08-26 04:39:40,165][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027848] [Batch 03503/04869] [00:40:20/00:15:44, 0.691s/it]: train_loss_raw=1.5578, running_loss=1.4914, LR=0.000100
[2025-08-26 04:39:45,882][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027856] [Batch 03511/04869] [00:40:26/00:15:38, 0.691s/it]: train_loss_raw=1.6004, running_loss=1.4899, LR=0.000100
[2025-08-26 04:39:51,158][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027864] [Batch 03519/04869] [00:40:31/00:15:32, 0.691s/it]: train_loss_raw=1.4566, running_loss=1.4924, LR=0.000100
[2025-08-26 04:39:56,408][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027872] [Batch 03527/04869] [00:40:37/00:15:27, 0.691s/it]: train_loss_raw=1.5139, running_loss=1.4925, LR=0.000100
[2025-08-26 04:40:01,615][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027880] [Batch 03535/04869] [00:40:42/00:15:21, 0.691s/it]: train_loss_raw=1.5063, running_loss=1.4917, LR=0.000100
[2025-08-26 04:40:07,290][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027888] [Batch 03543/04869] [00:40:47/00:15:16, 0.691s/it]: train_loss_raw=1.4119, running_loss=1.4928, LR=0.000100
[2025-08-26 04:40:12,823][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027896] [Batch 03551/04869] [00:40:53/00:15:10, 0.691s/it]: train_loss_raw=1.3875, running_loss=1.4914, LR=0.000100
[2025-08-26 04:40:18,241][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027904] [Batch 03559/04869] [00:40:58/00:15:05, 0.691s/it]: train_loss_raw=1.5551, running_loss=1.4919, LR=0.000100
[2025-08-26 04:40:24,311][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027912] [Batch 03567/04869] [00:41:04/00:14:59, 0.691s/it]: train_loss_raw=1.4526, running_loss=1.4894, LR=0.000100
[2025-08-26 04:40:30,368][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027920] [Batch 03575/04869] [00:41:11/00:14:54, 0.691s/it]: train_loss_raw=1.4646, running_loss=1.4917, LR=0.000100
[2025-08-26 04:40:35,674][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027928] [Batch 03583/04869] [00:41:16/00:14:48, 0.691s/it]: train_loss_raw=1.5278, running_loss=1.4919, LR=0.000100
[2025-08-26 04:40:41,097][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027936] [Batch 03591/04869] [00:41:21/00:14:43, 0.691s/it]: train_loss_raw=1.5515, running_loss=1.4908, LR=0.000100
[2025-08-26 04:40:46,377][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027944] [Batch 03599/04869] [00:41:27/00:14:37, 0.691s/it]: train_loss_raw=1.5075, running_loss=1.4886, LR=0.000100
[2025-08-26 04:40:51,780][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027952] [Batch 03607/04869] [00:41:32/00:14:32, 0.691s/it]: train_loss_raw=1.6023, running_loss=1.4893, LR=0.000100
[2025-08-26 04:40:57,089][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027960] [Batch 03615/04869] [00:41:37/00:14:26, 0.691s/it]: train_loss_raw=1.3948, running_loss=1.4869, LR=0.000100
[2025-08-26 04:41:02,427][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027968] [Batch 03623/04869] [00:41:43/00:14:20, 0.691s/it]: train_loss_raw=1.5168, running_loss=1.4874, LR=0.000100
[2025-08-26 04:41:08,016][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027976] [Batch 03631/04869] [00:41:48/00:14:15, 0.691s/it]: train_loss_raw=1.3973, running_loss=1.4870, LR=0.000100
[2025-08-26 04:41:13,676][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027984] [Batch 03639/04869] [00:41:54/00:14:09, 0.691s/it]: train_loss_raw=1.4918, running_loss=1.4875, LR=0.000100
[2025-08-26 04:41:19,851][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 027992] [Batch 03647/04869] [00:42:00/00:14:04, 0.691s/it]: train_loss_raw=1.4712, running_loss=1.4841, LR=0.000100
[2025-08-26 04:41:26,082][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028000] [Batch 03655/04869] [00:42:06/00:13:59, 0.691s/it]: train_loss_raw=1.4153, running_loss=1.4829, LR=0.000100
[2025-08-26 04:41:36,778][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028008] [Batch 03663/04869] [00:42:17/00:13:55, 0.693s/it]: train_loss_raw=1.5580, running_loss=1.4837, LR=0.000100
[2025-08-26 04:41:42,739][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028016] [Batch 03671/04869] [00:42:23/00:13:50, 0.693s/it]: train_loss_raw=1.4858, running_loss=1.4851, LR=0.000100
[2025-08-26 04:41:48,535][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028024] [Batch 03679/04869] [00:42:29/00:13:44, 0.693s/it]: train_loss_raw=1.5130, running_loss=1.4833, LR=0.000100
[2025-08-26 04:41:53,999][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028032] [Batch 03687/04869] [00:42:34/00:13:38, 0.693s/it]: train_loss_raw=1.4678, running_loss=1.4832, LR=0.000100
[2025-08-26 04:41:59,268][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028040] [Batch 03695/04869] [00:42:39/00:13:33, 0.693s/it]: train_loss_raw=1.4632, running_loss=1.4807, LR=0.000100
[2025-08-26 04:42:04,522][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028048] [Batch 03703/04869] [00:42:45/00:13:27, 0.693s/it]: train_loss_raw=1.4768, running_loss=1.4826, LR=0.000100
[2025-08-26 04:42:10,166][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028056] [Batch 03711/04869] [00:42:50/00:13:22, 0.693s/it]: train_loss_raw=1.5466, running_loss=1.4824, LR=0.000100
[2025-08-26 04:42:15,348][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028064] [Batch 03719/04869] [00:42:56/00:13:16, 0.693s/it]: train_loss_raw=1.5817, running_loss=1.4830, LR=0.000100
[2025-08-26 04:42:20,542][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028072] [Batch 03727/04869] [00:43:01/00:13:10, 0.693s/it]: train_loss_raw=1.4581, running_loss=1.4822, LR=0.000100
[2025-08-26 04:42:25,812][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028080] [Batch 03735/04869] [00:43:06/00:13:05, 0.693s/it]: train_loss_raw=1.5328, running_loss=1.4817, LR=0.000100
[2025-08-26 04:42:31,547][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028088] [Batch 03743/04869] [00:43:12/00:12:59, 0.693s/it]: train_loss_raw=1.6131, running_loss=1.4837, LR=0.000100
[2025-08-26 04:42:37,752][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028096] [Batch 03751/04869] [00:43:18/00:12:54, 0.693s/it]: train_loss_raw=1.5220, running_loss=1.4850, LR=0.000100
[2025-08-26 04:42:43,345][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028104] [Batch 03759/04869] [00:43:24/00:12:48, 0.693s/it]: train_loss_raw=1.4271, running_loss=1.4833, LR=0.000100
[2025-08-26 04:42:48,678][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028112] [Batch 03767/04869] [00:43:29/00:12:43, 0.693s/it]: train_loss_raw=1.4925, running_loss=1.4830, LR=0.000100
[2025-08-26 04:42:54,581][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028120] [Batch 03775/04869] [00:43:35/00:12:37, 0.693s/it]: train_loss_raw=1.4698, running_loss=1.4802, LR=0.000100
[2025-08-26 04:43:00,252][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028128] [Batch 03783/04869] [00:43:40/00:12:32, 0.693s/it]: train_loss_raw=1.3907, running_loss=1.4804, LR=0.000100
[2025-08-26 04:43:05,544][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028136] [Batch 03791/04869] [00:43:46/00:12:26, 0.693s/it]: train_loss_raw=1.4519, running_loss=1.4796, LR=0.000100
[2025-08-26 04:43:10,916][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028144] [Batch 03799/04869] [00:43:51/00:12:21, 0.693s/it]: train_loss_raw=1.3634, running_loss=1.4781, LR=0.000100
[2025-08-26 04:43:16,139][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028152] [Batch 03807/04869] [00:43:56/00:12:15, 0.693s/it]: train_loss_raw=1.4922, running_loss=1.4800, LR=0.000100
[2025-08-26 04:43:21,672][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028160] [Batch 03815/04869] [00:44:02/00:12:10, 0.693s/it]: train_loss_raw=1.3388, running_loss=1.4787, LR=0.000100
[2025-08-26 04:43:27,282][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028168] [Batch 03823/04869] [00:44:07/00:12:04, 0.693s/it]: train_loss_raw=1.4896, running_loss=1.4798, LR=0.000100
[2025-08-26 04:43:32,664][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028176] [Batch 03831/04869] [00:44:13/00:11:58, 0.693s/it]: train_loss_raw=1.4394, running_loss=1.4811, LR=0.000100
[2025-08-26 04:43:37,974][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028184] [Batch 03839/04869] [00:44:18/00:11:53, 0.693s/it]: train_loss_raw=1.4189, running_loss=1.4794, LR=0.000100
[2025-08-26 04:43:43,744][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028192] [Batch 03847/04869] [00:44:24/00:11:47, 0.693s/it]: train_loss_raw=1.5717, running_loss=1.4809, LR=0.000100
[2025-08-26 04:43:49,270][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028200] [Batch 03855/04869] [00:44:29/00:11:42, 0.693s/it]: train_loss_raw=1.4370, running_loss=1.4808, LR=0.000100
[2025-08-26 04:43:54,888][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028208] [Batch 03863/04869] [00:44:35/00:11:36, 0.693s/it]: train_loss_raw=1.6191, running_loss=1.4793, LR=0.000100
[2025-08-26 04:44:00,091][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028216] [Batch 03871/04869] [00:44:40/00:11:31, 0.693s/it]: train_loss_raw=1.4551, running_loss=1.4790, LR=0.000100
[2025-08-26 04:44:05,338][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028224] [Batch 03879/04869] [00:44:46/00:11:25, 0.692s/it]: train_loss_raw=1.4874, running_loss=1.4783, LR=0.000100
[2025-08-26 04:44:10,965][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028232] [Batch 03887/04869] [00:44:51/00:11:20, 0.692s/it]: train_loss_raw=1.5152, running_loss=1.4806, LR=0.000100
[2025-08-26 04:44:16,135][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028240] [Batch 03895/04869] [00:44:56/00:11:14, 0.692s/it]: train_loss_raw=1.5062, running_loss=1.4803, LR=0.000100
[2025-08-26 04:44:21,740][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028248] [Batch 03903/04869] [00:45:02/00:11:08, 0.692s/it]: train_loss_raw=1.5571, running_loss=1.4819, LR=0.000100
[2025-08-26 04:44:27,228][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028256] [Batch 03911/04869] [00:45:07/00:11:03, 0.692s/it]: train_loss_raw=1.4554, running_loss=1.4811, LR=0.000100
[2025-08-26 04:44:32,899][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028264] [Batch 03919/04869] [00:45:13/00:10:57, 0.692s/it]: train_loss_raw=1.3860, running_loss=1.4794, LR=0.000100
[2025-08-26 04:44:38,994][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028272] [Batch 03927/04869] [00:45:19/00:10:52, 0.693s/it]: train_loss_raw=1.4871, running_loss=1.4790, LR=0.000100
[2025-08-26 04:44:44,457][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028280] [Batch 03935/04869] [00:45:25/00:10:46, 0.693s/it]: train_loss_raw=1.5956, running_loss=1.4821, LR=0.000100
[2025-08-26 04:44:49,684][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028288] [Batch 03943/04869] [00:45:30/00:10:41, 0.692s/it]: train_loss_raw=1.4288, running_loss=1.4826, LR=0.000100
[2025-08-26 04:44:54,978][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028296] [Batch 03951/04869] [00:45:35/00:10:35, 0.692s/it]: train_loss_raw=1.4397, running_loss=1.4826, LR=0.000100
[2025-08-26 04:45:00,602][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028304] [Batch 03959/04869] [00:45:41/00:10:30, 0.692s/it]: train_loss_raw=1.5341, running_loss=1.4834, LR=0.000100
[2025-08-26 04:45:05,931][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028312] [Batch 03967/04869] [00:45:46/00:10:24, 0.692s/it]: train_loss_raw=1.4594, running_loss=1.4829, LR=0.000100
[2025-08-26 04:45:11,830][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028320] [Batch 03975/04869] [00:45:52/00:10:19, 0.692s/it]: train_loss_raw=1.4729, running_loss=1.4839, LR=0.000100
[2025-08-26 04:45:17,192][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028328] [Batch 03983/04869] [00:45:57/00:10:13, 0.692s/it]: train_loss_raw=1.4302, running_loss=1.4830, LR=0.000100
[2025-08-26 04:45:22,813][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028336] [Batch 03991/04869] [00:46:03/00:10:07, 0.692s/it]: train_loss_raw=1.4524, running_loss=1.4812, LR=0.000100
[2025-08-26 04:45:27,974][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028344] [Batch 03999/04869] [00:46:08/00:10:02, 0.692s/it]: train_loss_raw=1.4963, running_loss=1.4812, LR=0.000100
[2025-08-26 04:45:33,372][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028352] [Batch 04007/04869] [00:46:14/00:09:56, 0.692s/it]: train_loss_raw=1.5306, running_loss=1.4809, LR=0.000100
[2025-08-26 04:45:38,571][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028360] [Batch 04015/04869] [00:46:19/00:09:51, 0.692s/it]: train_loss_raw=1.5167, running_loss=1.4782, LR=0.000100
[2025-08-26 04:45:44,446][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028368] [Batch 04023/04869] [00:46:25/00:09:45, 0.692s/it]: train_loss_raw=1.4020, running_loss=1.4785, LR=0.000100
[2025-08-26 04:45:49,868][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028376] [Batch 04031/04869] [00:46:30/00:09:40, 0.692s/it]: train_loss_raw=1.4742, running_loss=1.4794, LR=0.000100
[2025-08-26 04:45:55,921][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028384] [Batch 04039/04869] [00:46:36/00:09:34, 0.692s/it]: train_loss_raw=1.5102, running_loss=1.4806, LR=0.000100
[2025-08-26 04:46:01,247][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028392] [Batch 04047/04869] [00:46:41/00:09:29, 0.692s/it]: train_loss_raw=1.4758, running_loss=1.4791, LR=0.000100
[2025-08-26 04:46:06,898][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028400] [Batch 04055/04869] [00:46:47/00:09:23, 0.692s/it]: train_loss_raw=1.4221, running_loss=1.4785, LR=0.000100
[2025-08-26 04:46:12,121][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028408] [Batch 04063/04869] [00:46:52/00:09:17, 0.692s/it]: train_loss_raw=1.4377, running_loss=1.4800, LR=0.000100
[2025-08-26 04:46:17,335][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028416] [Batch 04071/04869] [00:46:58/00:09:12, 0.692s/it]: train_loss_raw=1.4668, running_loss=1.4794, LR=0.000100
[2025-08-26 04:46:22,872][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028424] [Batch 04079/04869] [00:47:03/00:09:06, 0.692s/it]: train_loss_raw=1.4844, running_loss=1.4800, LR=0.000100
[2025-08-26 04:46:28,757][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028432] [Batch 04087/04869] [00:47:09/00:09:01, 0.692s/it]: train_loss_raw=1.5253, running_loss=1.4787, LR=0.000100
[2025-08-26 04:46:34,804][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028440] [Batch 04095/04869] [00:47:15/00:08:55, 0.692s/it]: train_loss_raw=1.4789, running_loss=1.4794, LR=0.000100
[2025-08-26 04:46:40,339][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028448] [Batch 04103/04869] [00:47:21/00:08:50, 0.692s/it]: train_loss_raw=1.5099, running_loss=1.4797, LR=0.000100
[2025-08-26 04:46:45,960][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028456] [Batch 04111/04869] [00:47:26/00:08:44, 0.692s/it]: train_loss_raw=1.5084, running_loss=1.4806, LR=0.000100
[2025-08-26 04:46:51,346][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028464] [Batch 04119/04869] [00:47:32/00:08:39, 0.692s/it]: train_loss_raw=1.4417, running_loss=1.4791, LR=0.000100
[2025-08-26 04:46:56,559][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028472] [Batch 04127/04869] [00:47:37/00:08:33, 0.692s/it]: train_loss_raw=1.5108, running_loss=1.4813, LR=0.000100
[2025-08-26 04:47:01,775][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028480] [Batch 04135/04869] [00:47:42/00:08:28, 0.692s/it]: train_loss_raw=1.5093, running_loss=1.4793, LR=0.000100
[2025-08-26 04:47:07,006][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028488] [Batch 04143/04869] [00:47:47/00:08:22, 0.692s/it]: train_loss_raw=1.4546, running_loss=1.4777, LR=0.000100
[2025-08-26 04:47:12,219][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028496] [Batch 04151/04869] [00:47:52/00:08:16, 0.692s/it]: train_loss_raw=1.5645, running_loss=1.4783, LR=0.000100
[2025-08-26 04:47:17,434][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028504] [Batch 04159/04869] [00:47:58/00:08:11, 0.692s/it]: train_loss_raw=1.5534, running_loss=1.4804, LR=0.000100
[2025-08-26 04:47:23,130][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028512] [Batch 04167/04869] [00:48:03/00:08:05, 0.692s/it]: train_loss_raw=1.4578, running_loss=1.4773, LR=0.000100
[2025-08-26 04:47:28,946][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028520] [Batch 04175/04869] [00:48:09/00:08:00, 0.692s/it]: train_loss_raw=1.5403, running_loss=1.4795, LR=0.000100
[2025-08-26 04:47:34,176][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028528] [Batch 04183/04869] [00:48:14/00:07:54, 0.692s/it]: train_loss_raw=1.4934, running_loss=1.4815, LR=0.000100
[2025-08-26 04:47:39,371][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028536] [Batch 04191/04869] [00:48:20/00:07:49, 0.692s/it]: train_loss_raw=1.2510, running_loss=1.4782, LR=0.000100
[2025-08-26 04:47:44,554][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028544] [Batch 04199/04869] [00:48:25/00:07:43, 0.692s/it]: train_loss_raw=1.4262, running_loss=1.4794, LR=0.000100
[2025-08-26 04:47:50,082][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028552] [Batch 04207/04869] [00:48:30/00:07:38, 0.692s/it]: train_loss_raw=1.5222, running_loss=1.4824, LR=0.000100
[2025-08-26 04:47:55,677][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028560] [Batch 04215/04869] [00:48:36/00:07:32, 0.692s/it]: train_loss_raw=1.5010, running_loss=1.4795, LR=0.000100
[2025-08-26 04:48:01,382][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028568] [Batch 04223/04869] [00:48:42/00:07:26, 0.692s/it]: train_loss_raw=1.4690, running_loss=1.4785, LR=0.000100
[2025-08-26 04:48:06,817][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028576] [Batch 04231/04869] [00:48:47/00:07:21, 0.692s/it]: train_loss_raw=1.4274, running_loss=1.4755, LR=0.000100
[2025-08-26 04:48:12,159][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028584] [Batch 04239/04869] [00:48:52/00:07:15, 0.692s/it]: train_loss_raw=1.4850, running_loss=1.4765, LR=0.000100
[2025-08-26 04:48:17,614][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028592] [Batch 04247/04869] [00:48:58/00:07:10, 0.692s/it]: train_loss_raw=1.4420, running_loss=1.4768, LR=0.000100
[2025-08-26 04:48:22,954][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028600] [Batch 04255/04869] [00:49:03/00:07:04, 0.692s/it]: train_loss_raw=1.5864, running_loss=1.4776, LR=0.000100
[2025-08-26 04:48:28,394][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028608] [Batch 04263/04869] [00:49:09/00:06:59, 0.692s/it]: train_loss_raw=1.4163, running_loss=1.4763, LR=0.000100
[2025-08-26 04:48:33,581][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028616] [Batch 04271/04869] [00:49:14/00:06:53, 0.692s/it]: train_loss_raw=1.5153, running_loss=1.4767, LR=0.000100
[2025-08-26 04:48:38,785][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028624] [Batch 04279/04869] [00:49:19/00:06:48, 0.692s/it]: train_loss_raw=1.5296, running_loss=1.4766, LR=0.000100
[2025-08-26 04:48:44,449][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028632] [Batch 04287/04869] [00:49:25/00:06:42, 0.692s/it]: train_loss_raw=1.5352, running_loss=1.4784, LR=0.000100
[2025-08-26 04:48:50,121][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028640] [Batch 04295/04869] [00:49:30/00:06:37, 0.692s/it]: train_loss_raw=1.4699, running_loss=1.4798, LR=0.000100
[2025-08-26 04:48:55,325][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028648] [Batch 04303/04869] [00:49:36/00:06:31, 0.692s/it]: train_loss_raw=1.4957, running_loss=1.4780, LR=0.000100
[2025-08-26 04:49:00,901][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028656] [Batch 04311/04869] [00:49:41/00:06:25, 0.692s/it]: train_loss_raw=1.4035, running_loss=1.4786, LR=0.000100
[2025-08-26 04:49:06,533][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028664] [Batch 04319/04869] [00:49:47/00:06:20, 0.692s/it]: train_loss_raw=1.5415, running_loss=1.4808, LR=0.000100
[2025-08-26 04:49:11,776][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028672] [Batch 04327/04869] [00:49:52/00:06:14, 0.692s/it]: train_loss_raw=1.5002, running_loss=1.4793, LR=0.000100
[2025-08-26 04:49:16,991][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028680] [Batch 04335/04869] [00:49:57/00:06:09, 0.692s/it]: train_loss_raw=1.4654, running_loss=1.4783, LR=0.000100
[2025-08-26 04:49:22,228][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028688] [Batch 04343/04869] [00:50:02/00:06:03, 0.691s/it]: train_loss_raw=1.4995, running_loss=1.4783, LR=0.000100
[2025-08-26 04:49:27,453][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028696] [Batch 04351/04869] [00:50:08/00:05:58, 0.691s/it]: train_loss_raw=1.5398, running_loss=1.4770, LR=0.000100
[2025-08-26 04:49:32,713][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028704] [Batch 04359/04869] [00:50:13/00:05:52, 0.691s/it]: train_loss_raw=1.3428, running_loss=1.4764, LR=0.000100
[2025-08-26 04:49:37,950][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028712] [Batch 04367/04869] [00:50:18/00:05:47, 0.691s/it]: train_loss_raw=1.4506, running_loss=1.4787, LR=0.000100
[2025-08-26 04:49:43,173][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028720] [Batch 04375/04869] [00:50:23/00:05:41, 0.691s/it]: train_loss_raw=1.4380, running_loss=1.4770, LR=0.000100
[2025-08-26 04:49:48,747][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028728] [Batch 04383/04869] [00:50:29/00:05:35, 0.691s/it]: train_loss_raw=1.5251, running_loss=1.4772, LR=0.000100
[2025-08-26 04:49:54,394][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028736] [Batch 04391/04869] [00:50:35/00:05:30, 0.691s/it]: train_loss_raw=1.4296, running_loss=1.4744, LR=0.000100
[2025-08-26 04:50:00,178][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028744] [Batch 04399/04869] [00:50:40/00:05:24, 0.691s/it]: train_loss_raw=1.4384, running_loss=1.4772, LR=0.000100
[2025-08-26 04:50:05,998][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028752] [Batch 04407/04869] [00:50:46/00:05:19, 0.691s/it]: train_loss_raw=1.4523, running_loss=1.4763, LR=0.000100
[2025-08-26 04:50:11,750][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028760] [Batch 04415/04869] [00:50:52/00:05:13, 0.691s/it]: train_loss_raw=1.4848, running_loss=1.4773, LR=0.000100
[2025-08-26 04:50:17,121][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028768] [Batch 04423/04869] [00:50:57/00:05:08, 0.691s/it]: train_loss_raw=1.5053, running_loss=1.4772, LR=0.000100
[2025-08-26 04:50:22,896][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028776] [Batch 04431/04869] [00:51:03/00:05:02, 0.691s/it]: train_loss_raw=1.3532, running_loss=1.4740, LR=0.000100
[2025-08-26 04:50:28,188][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028784] [Batch 04439/04869] [00:51:08/00:04:57, 0.691s/it]: train_loss_raw=1.6072, running_loss=1.4725, LR=0.000100
[2025-08-26 04:50:34,007][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028792] [Batch 04447/04869] [00:51:14/00:04:51, 0.691s/it]: train_loss_raw=1.5312, running_loss=1.4747, LR=0.000100
[2025-08-26 04:50:39,363][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028800] [Batch 04455/04869] [00:51:20/00:04:46, 0.691s/it]: train_loss_raw=1.5143, running_loss=1.4733, LR=0.000100
[2025-08-26 04:50:44,827][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028808] [Batch 04463/04869] [00:51:25/00:04:40, 0.691s/it]: train_loss_raw=1.5020, running_loss=1.4714, LR=0.000100
[2025-08-26 04:50:50,091][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028816] [Batch 04471/04869] [00:51:30/00:04:35, 0.691s/it]: train_loss_raw=1.4850, running_loss=1.4717, LR=0.000100
[2025-08-26 04:50:55,592][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028824] [Batch 04479/04869] [00:51:36/00:04:29, 0.691s/it]: train_loss_raw=1.5262, running_loss=1.4707, LR=0.000100
[2025-08-26 04:51:00,799][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028832] [Batch 04487/04869] [00:51:41/00:04:24, 0.691s/it]: train_loss_raw=1.4339, running_loss=1.4721, LR=0.000100
[2025-08-26 04:51:06,063][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028840] [Batch 04495/04869] [00:51:46/00:04:18, 0.691s/it]: train_loss_raw=1.4175, running_loss=1.4718, LR=0.000100
[2025-08-26 04:51:11,689][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028848] [Batch 04503/04869] [00:51:52/00:04:12, 0.691s/it]: train_loss_raw=1.4512, running_loss=1.4719, LR=0.000100
[2025-08-26 04:51:17,369][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028856] [Batch 04511/04869] [00:51:58/00:04:07, 0.691s/it]: train_loss_raw=1.4652, running_loss=1.4728, LR=0.000100
[2025-08-26 04:51:22,568][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028864] [Batch 04519/04869] [00:52:03/00:04:01, 0.691s/it]: train_loss_raw=1.5837, running_loss=1.4749, LR=0.000100
[2025-08-26 04:51:27,756][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028872] [Batch 04527/04869] [00:52:08/00:03:56, 0.691s/it]: train_loss_raw=1.4169, running_loss=1.4727, LR=0.000100
[2025-08-26 04:51:33,024][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028880] [Batch 04535/04869] [00:52:13/00:03:50, 0.691s/it]: train_loss_raw=1.5288, running_loss=1.4736, LR=0.000100
[2025-08-26 04:51:38,287][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028888] [Batch 04543/04869] [00:52:18/00:03:45, 0.691s/it]: train_loss_raw=1.5921, running_loss=1.4757, LR=0.000100
[2025-08-26 04:51:43,489][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028896] [Batch 04551/04869] [00:52:24/00:03:39, 0.691s/it]: train_loss_raw=1.4360, running_loss=1.4748, LR=0.000100
[2025-08-26 04:51:49,043][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028904] [Batch 04559/04869] [00:52:29/00:03:34, 0.691s/it]: train_loss_raw=1.4283, running_loss=1.4780, LR=0.000100
[2025-08-26 04:51:54,260][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028912] [Batch 04567/04869] [00:52:34/00:03:28, 0.691s/it]: train_loss_raw=1.5053, running_loss=1.4755, LR=0.000100
[2025-08-26 04:51:59,473][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028920] [Batch 04575/04869] [00:52:40/00:03:23, 0.691s/it]: train_loss_raw=1.5526, running_loss=1.4768, LR=0.000100
[2025-08-26 04:52:05,178][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028928] [Batch 04583/04869] [00:52:45/00:03:17, 0.691s/it]: train_loss_raw=1.4839, running_loss=1.4757, LR=0.000100
[2025-08-26 04:52:10,521][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028936] [Batch 04591/04869] [00:52:51/00:03:12, 0.691s/it]: train_loss_raw=1.5160, running_loss=1.4755, LR=0.000100
[2025-08-26 04:52:15,756][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028944] [Batch 04599/04869] [00:52:56/00:03:06, 0.691s/it]: train_loss_raw=1.4874, running_loss=1.4775, LR=0.000100
[2025-08-26 04:52:20,970][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028952] [Batch 04607/04869] [00:53:01/00:03:00, 0.691s/it]: train_loss_raw=1.4567, running_loss=1.4791, LR=0.000100
[2025-08-26 04:52:26,577][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028960] [Batch 04615/04869] [00:53:07/00:02:55, 0.691s/it]: train_loss_raw=1.5572, running_loss=1.4814, LR=0.000100
[2025-08-26 04:52:32,362][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028968] [Batch 04623/04869] [00:53:13/00:02:49, 0.691s/it]: train_loss_raw=1.4925, running_loss=1.4810, LR=0.000100
[2025-08-26 04:52:37,785][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028976] [Batch 04631/04869] [00:53:18/00:02:44, 0.691s/it]: train_loss_raw=1.4509, running_loss=1.4787, LR=0.000100
[2025-08-26 04:52:42,984][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028984] [Batch 04639/04869] [00:53:23/00:02:38, 0.691s/it]: train_loss_raw=1.4434, running_loss=1.4781, LR=0.000100
[2025-08-26 04:52:48,212][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 028992] [Batch 04647/04869] [00:53:28/00:02:33, 0.691s/it]: train_loss_raw=1.4072, running_loss=1.4777, LR=0.000100
[2025-08-26 04:52:53,513][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029000] [Batch 04655/04869] [00:53:34/00:02:27, 0.690s/it]: train_loss_raw=1.4836, running_loss=1.4783, LR=0.000100
[2025-08-26 04:52:58,842][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029008] [Batch 04663/04869] [00:53:39/00:02:22, 0.690s/it]: train_loss_raw=1.4136, running_loss=1.4776, LR=0.000100
[2025-08-26 04:53:04,532][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029016] [Batch 04671/04869] [00:53:45/00:02:16, 0.690s/it]: train_loss_raw=1.4073, running_loss=1.4777, LR=0.000100
[2025-08-26 04:53:10,385][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029024] [Batch 04679/04869] [00:53:51/00:02:11, 0.691s/it]: train_loss_raw=1.4721, running_loss=1.4766, LR=0.000100
[2025-08-26 04:53:15,925][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029032] [Batch 04687/04869] [00:53:56/00:02:05, 0.691s/it]: train_loss_raw=1.5563, running_loss=1.4765, LR=0.000100
[2025-08-26 04:53:21,303][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029040] [Batch 04695/04869] [00:54:01/00:02:00, 0.691s/it]: train_loss_raw=1.4853, running_loss=1.4736, LR=0.000100
[2025-08-26 04:53:26,520][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029048] [Batch 04703/04869] [00:54:07/00:01:54, 0.690s/it]: train_loss_raw=1.4457, running_loss=1.4718, LR=0.000100
[2025-08-26 04:53:31,694][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029056] [Batch 04711/04869] [00:54:12/00:01:49, 0.690s/it]: train_loss_raw=1.5782, running_loss=1.4735, LR=0.000100
[2025-08-26 04:53:37,409][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029064] [Batch 04719/04869] [00:54:18/00:01:43, 0.690s/it]: train_loss_raw=1.5498, running_loss=1.4721, LR=0.000100
[2025-08-26 04:53:42,906][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029072] [Batch 04727/04869] [00:54:23/00:01:38, 0.690s/it]: train_loss_raw=1.4742, running_loss=1.4720, LR=0.000100
[2025-08-26 04:53:48,210][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029080] [Batch 04735/04869] [00:54:28/00:01:32, 0.690s/it]: train_loss_raw=1.4871, running_loss=1.4700, LR=0.000100
[2025-08-26 04:53:53,940][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029088] [Batch 04743/04869] [00:54:34/00:01:26, 0.690s/it]: train_loss_raw=1.4380, running_loss=1.4694, LR=0.000100
[2025-08-26 04:53:59,241][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029096] [Batch 04751/04869] [00:54:39/00:01:21, 0.690s/it]: train_loss_raw=1.5772, running_loss=1.4707, LR=0.000100
[2025-08-26 04:54:05,426][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029104] [Batch 04759/04869] [00:54:46/00:01:15, 0.691s/it]: train_loss_raw=1.4984, running_loss=1.4707, LR=0.000100
[2025-08-26 04:54:11,623][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029112] [Batch 04767/04869] [00:54:52/00:01:10, 0.691s/it]: train_loss_raw=1.3784, running_loss=1.4684, LR=0.000100
[2025-08-26 04:54:17,118][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029120] [Batch 04775/04869] [00:54:57/00:01:04, 0.691s/it]: train_loss_raw=1.4919, running_loss=1.4693, LR=0.000100
[2025-08-26 04:54:22,338][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029128] [Batch 04783/04869] [00:55:03/00:00:59, 0.691s/it]: train_loss_raw=1.4940, running_loss=1.4710, LR=0.000100
[2025-08-26 04:54:27,956][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029136] [Batch 04791/04869] [00:55:08/00:00:53, 0.691s/it]: train_loss_raw=1.4564, running_loss=1.4717, LR=0.000100
[2025-08-26 04:54:33,571][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029144] [Batch 04799/04869] [00:55:14/00:00:48, 0.691s/it]: train_loss_raw=1.4349, running_loss=1.4709, LR=0.000100
[2025-08-26 04:54:38,896][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029152] [Batch 04807/04869] [00:55:19/00:00:42, 0.691s/it]: train_loss_raw=1.3663, running_loss=1.4716, LR=0.000100
[2025-08-26 04:54:44,083][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029160] [Batch 04815/04869] [00:55:24/00:00:37, 0.691s/it]: train_loss_raw=1.4910, running_loss=1.4734, LR=0.000100
[2025-08-26 04:54:49,685][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029168] [Batch 04823/04869] [00:55:30/00:00:31, 0.691s/it]: train_loss_raw=1.4593, running_loss=1.4726, LR=0.000100
[2025-08-26 04:54:55,498][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029176] [Batch 04831/04869] [00:55:36/00:00:26, 0.691s/it]: train_loss_raw=1.4290, running_loss=1.4685, LR=0.000100
[2025-08-26 04:55:01,409][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029184] [Batch 04839/04869] [00:55:42/00:00:20, 0.691s/it]: train_loss_raw=1.4605, running_loss=1.4705, LR=0.000100
[2025-08-26 04:55:07,412][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029192] [Batch 04847/04869] [00:55:48/00:00:15, 0.691s/it]: train_loss_raw=1.5135, running_loss=1.4717, LR=0.000100
[2025-08-26 04:55:13,163][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029200] [Batch 04855/04869] [00:55:53/00:00:09, 0.691s/it]: train_loss_raw=1.4920, running_loss=1.4726, LR=0.000100
[2025-08-26 04:55:18,555][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 029208] [Batch 04863/04869] [00:55:59/00:00:04, 0.691s/it]: train_loss_raw=1.4618, running_loss=1.4727, LR=0.000100
[2025-08-26 04:55:36,338][__main__][INFO] - [VALIDATION] [Epoch 05/29] Starting validation.
[2025-08-26 04:55:46,914][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00007/00124] [00:00:10/00:02:33, 1.322s/it]
[2025-08-26 04:55:57,841][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00015/00124] [00:00:21/00:02:25, 1.344s/it]
[2025-08-26 04:56:09,815][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00023/00124] [00:00:33/00:02:19, 1.395s/it]
[2025-08-26 04:56:33,336][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00031/00124] [00:00:56/00:02:43, 1.781s/it]
[2025-08-26 04:56:43,795][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00039/00124] [00:01:07/00:02:21, 1.686s/it]
[2025-08-26 04:56:55,340][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00047/00124] [00:01:19/00:02:05, 1.646s/it]
[2025-08-26 04:57:06,046][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00055/00124] [00:01:29/00:01:48, 1.602s/it]
[2025-08-26 04:57:17,012][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00063/00124] [00:01:40/00:01:34, 1.573s/it]
[2025-08-26 04:57:28,777][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00071/00124] [00:01:52/00:01:21, 1.562s/it]
[2025-08-26 04:57:39,354][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00079/00124] [00:02:03/00:01:07, 1.538s/it]
[2025-08-26 04:57:50,542][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00087/00124] [00:02:14/00:00:54, 1.525s/it]
[2025-08-26 04:58:02,354][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00095/00124] [00:02:26/00:00:42, 1.521s/it]
[2025-08-26 04:58:12,759][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00103/00124] [00:02:36/00:00:30, 1.504s/it]
[2025-08-26 04:58:23,572][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00111/00124] [00:02:47/00:00:17, 1.493s/it]
[2025-08-26 04:58:34,844][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 029215] [Batch 00119/00124] [00:02:58/00:00:05, 1.488s/it]
[2025-08-26 04:58:40,249][__main__][INFO] - [VALIDATION] [Epoch 05/29] train_loss=1.47324, valid_loss=1.38884
[2025-08-26 04:58:40,249][__main__][INFO] - [VALIDATION] [Epoch 05/29] Metrics:
[2025-08-26 04:58:40,249][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_er      0.614
[2025-08-26 04:58:40,249][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_prec    0.102
[2025-08-26 04:58:40,249][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_recall  0.106
[2025-08-26 04:58:40,249][__main__][INFO] - [VALIDATION] [Epoch 05/29] - pep_recall 0.058
[2025-08-26 04:58:40,257][__main__][INFO] - [TRAIN] [Epoch 05/29] Epoch complete, total time 05:54:20, remaining time 23:37:21, 00:59:03 per epoch
[2025-08-26 04:58:41,491][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029216] [Batch 00002/04869] [00:00:00/00:38:21, 0.473s/it]: train_loss_raw=1.3311, running_loss=1.4073, LR=0.000100
[2025-08-26 04:58:47,662][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029224] [Batch 00010/04869] [00:00:07/00:57:38, 0.712s/it]: train_loss_raw=1.5377, running_loss=1.4118, LR=0.000100
[2025-08-26 04:58:53,256][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029232] [Batch 00018/04869] [00:00:12/00:57:05, 0.706s/it]: train_loss_raw=1.5059, running_loss=1.4164, LR=0.000100
[2025-08-26 04:58:58,890][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029240] [Batch 00026/04869] [00:00:18/00:56:57, 0.706s/it]: train_loss_raw=1.4643, running_loss=1.4190, LR=0.000100
[2025-08-26 04:59:04,132][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029248] [Batch 00034/04869] [00:00:23/00:55:54, 0.694s/it]: train_loss_raw=1.4083, running_loss=1.4237, LR=0.000100
[2025-08-26 04:59:10,052][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029256] [Batch 00042/04869] [00:00:29/00:56:31, 0.703s/it]: train_loss_raw=1.5082, running_loss=1.4290, LR=0.000100
[2025-08-26 04:59:15,508][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029264] [Batch 00050/04869] [00:00:34/00:56:09, 0.699s/it]: train_loss_raw=1.5373, running_loss=1.4327, LR=0.000100
[2025-08-26 04:59:21,036][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029272] [Batch 00058/04869] [00:00:40/00:55:58, 0.698s/it]: train_loss_raw=1.4019, running_loss=1.4334, LR=0.000100
[2025-08-26 04:59:26,244][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029280] [Batch 00066/04869] [00:00:45/00:55:25, 0.692s/it]: train_loss_raw=1.5744, running_loss=1.4367, LR=0.000100
[2025-08-26 04:59:31,619][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029288] [Batch 00074/04869] [00:00:51/00:55:09, 0.690s/it]: train_loss_raw=1.4666, running_loss=1.4375, LR=0.000100
[2025-08-26 04:59:37,083][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029296] [Batch 00082/04869] [00:00:56/00:55:00, 0.689s/it]: train_loss_raw=1.5248, running_loss=1.4404, LR=0.000100
[2025-08-26 04:59:42,261][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029304] [Batch 00090/04869] [00:01:01/00:54:37, 0.686s/it]: train_loss_raw=1.3752, running_loss=1.4414, LR=0.000100
[2025-08-26 04:59:47,429][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029312] [Batch 00098/04869] [00:01:06/00:54:16, 0.682s/it]: train_loss_raw=1.4913, running_loss=1.4441, LR=0.000100
[2025-08-26 04:59:52,622][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029320] [Batch 00106/04869] [00:01:12/00:53:58, 0.680s/it]: train_loss_raw=1.4874, running_loss=1.4446, LR=0.000100
[2025-08-26 04:59:57,843][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029328] [Batch 00114/04869] [00:01:17/00:53:44, 0.678s/it]: train_loss_raw=1.5562, running_loss=1.4470, LR=0.000100
[2025-08-26 05:00:03,031][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029336] [Batch 00122/04869] [00:01:22/00:53:29, 0.676s/it]: train_loss_raw=1.6128, running_loss=1.4519, LR=0.000100
[2025-08-26 05:00:08,607][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029344] [Batch 00130/04869] [00:01:28/00:53:30, 0.677s/it]: train_loss_raw=1.4562, running_loss=1.4518, LR=0.000100
[2025-08-26 05:00:13,881][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029352] [Batch 00138/04869] [00:01:33/00:53:19, 0.676s/it]: train_loss_raw=1.4035, running_loss=1.4518, LR=0.000100
[2025-08-26 05:00:19,547][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029360] [Batch 00146/04869] [00:01:39/00:53:22, 0.678s/it]: train_loss_raw=1.4929, running_loss=1.4513, LR=0.000100
[2025-08-26 05:00:24,981][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029368] [Batch 00154/04869] [00:01:44/00:53:17, 0.678s/it]: train_loss_raw=1.3244, running_loss=1.4489, LR=0.000100
[2025-08-26 05:00:30,859][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029376] [Batch 00162/04869] [00:01:50/00:53:25, 0.681s/it]: train_loss_raw=1.5218, running_loss=1.4479, LR=0.000100
[2025-08-26 05:00:36,308][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029384] [Batch 00170/04869] [00:01:55/00:53:19, 0.681s/it]: train_loss_raw=1.4391, running_loss=1.4469, LR=0.000100
[2025-08-26 05:00:41,902][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029392] [Batch 00178/04869] [00:02:01/00:53:18, 0.682s/it]: train_loss_raw=1.3973, running_loss=1.4477, LR=0.000100
[2025-08-26 05:00:47,412][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029400] [Batch 00186/04869] [00:02:06/00:53:14, 0.682s/it]: train_loss_raw=1.3551, running_loss=1.4476, LR=0.000100
[2025-08-26 05:00:52,620][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029408] [Batch 00194/04869] [00:02:12/00:53:02, 0.681s/it]: train_loss_raw=1.4557, running_loss=1.4504, LR=0.000100
[2025-08-26 05:00:57,818][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029416] [Batch 00202/04869] [00:02:17/00:52:51, 0.680s/it]: train_loss_raw=1.5984, running_loss=1.4507, LR=0.000100
[2025-08-26 05:01:03,298][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029424] [Batch 00210/04869] [00:02:22/00:52:47, 0.680s/it]: train_loss_raw=1.5378, running_loss=1.4522, LR=0.000100
[2025-08-26 05:01:09,155][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029432] [Batch 00218/04869] [00:02:28/00:52:50, 0.682s/it]: train_loss_raw=1.4243, running_loss=1.4530, LR=0.000100
[2025-08-26 05:01:14,500][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029440] [Batch 00226/04869] [00:02:33/00:52:42, 0.681s/it]: train_loss_raw=1.3715, running_loss=1.4525, LR=0.000100
[2025-08-26 05:01:20,144][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029448] [Batch 00234/04869] [00:02:39/00:52:41, 0.682s/it]: train_loss_raw=1.2688, running_loss=1.4477, LR=0.000100
[2025-08-26 05:01:25,691][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029456] [Batch 00242/04869] [00:02:45/00:52:37, 0.682s/it]: train_loss_raw=1.4497, running_loss=1.4484, LR=0.000100
[2025-08-26 05:01:30,940][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029464] [Batch 00250/04869] [00:02:50/00:52:28, 0.682s/it]: train_loss_raw=1.5316, running_loss=1.4493, LR=0.000100
[2025-08-26 05:01:36,758][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029472] [Batch 00258/04869] [00:02:56/00:52:29, 0.683s/it]: train_loss_raw=1.3660, running_loss=1.4476, LR=0.000100
[2025-08-26 05:01:42,381][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029480] [Batch 00266/04869] [00:03:01/00:52:26, 0.684s/it]: train_loss_raw=1.4534, running_loss=1.4512, LR=0.000100
[2025-08-26 05:01:48,234][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029488] [Batch 00274/04869] [00:03:07/00:52:27, 0.685s/it]: train_loss_raw=1.4227, running_loss=1.4561, LR=0.000100
[2025-08-26 05:01:53,514][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029496] [Batch 00282/04869] [00:03:12/00:52:18, 0.684s/it]: train_loss_raw=1.4543, running_loss=1.4522, LR=0.000100
[2025-08-26 05:01:59,388][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029504] [Batch 00290/04869] [00:03:18/00:52:19, 0.686s/it]: train_loss_raw=1.4187, running_loss=1.4490, LR=0.000100
[2025-08-26 05:02:05,363][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029512] [Batch 00298/04869] [00:03:24/00:52:21, 0.687s/it]: train_loss_raw=1.4564, running_loss=1.4470, LR=0.000100
[2025-08-26 05:02:11,033][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029520] [Batch 00306/04869] [00:03:30/00:52:18, 0.688s/it]: train_loss_raw=1.4480, running_loss=1.4469, LR=0.000100
[2025-08-26 05:02:16,614][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029528] [Batch 00314/04869] [00:03:36/00:52:14, 0.688s/it]: train_loss_raw=1.4504, running_loss=1.4449, LR=0.000100
[2025-08-26 05:02:21,802][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029536] [Batch 00322/04869] [00:03:41/00:52:04, 0.687s/it]: train_loss_raw=1.4500, running_loss=1.4437, LR=0.000100
[2025-08-26 05:02:27,515][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029544] [Batch 00330/04869] [00:03:46/00:52:01, 0.688s/it]: train_loss_raw=1.3977, running_loss=1.4429, LR=0.000100
[2025-08-26 05:02:32,732][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029552] [Batch 00338/04869] [00:03:52/00:51:52, 0.687s/it]: train_loss_raw=1.3883, running_loss=1.4420, LR=0.000100
[2025-08-26 05:02:38,380][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029560] [Batch 00346/04869] [00:03:57/00:51:49, 0.687s/it]: train_loss_raw=1.3650, running_loss=1.4397, LR=0.000100
[2025-08-26 05:02:43,695][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029568] [Batch 00354/04869] [00:04:03/00:51:41, 0.687s/it]: train_loss_raw=1.4521, running_loss=1.4395, LR=0.000100
[2025-08-26 05:02:50,024][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029576] [Batch 00362/04869] [00:04:09/00:51:46, 0.689s/it]: train_loss_raw=1.5181, running_loss=1.4415, LR=0.000100
[2025-08-26 05:02:55,523][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029584] [Batch 00370/04869] [00:04:14/00:51:40, 0.689s/it]: train_loss_raw=1.4423, running_loss=1.4409, LR=0.000100
[2025-08-26 05:03:00,747][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029592] [Batch 00378/04869] [00:04:20/00:51:31, 0.688s/it]: train_loss_raw=1.5588, running_loss=1.4422, LR=0.000100
[2025-08-26 05:03:05,988][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029600] [Batch 00386/04869] [00:04:25/00:51:22, 0.688s/it]: train_loss_raw=1.4173, running_loss=1.4409, LR=0.000100
[2025-08-26 05:03:11,354][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029608] [Batch 00394/04869] [00:04:30/00:51:15, 0.687s/it]: train_loss_raw=1.5867, running_loss=1.4408, LR=0.000100
[2025-08-26 05:03:16,560][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029616] [Batch 00402/04869] [00:04:36/00:51:07, 0.687s/it]: train_loss_raw=1.4223, running_loss=1.4422, LR=0.000100
[2025-08-26 05:03:21,722][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029624] [Batch 00410/04869] [00:04:41/00:50:57, 0.686s/it]: train_loss_raw=1.3811, running_loss=1.4443, LR=0.000100
[2025-08-26 05:03:26,967][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029632] [Batch 00418/04869] [00:04:46/00:50:49, 0.685s/it]: train_loss_raw=1.4728, running_loss=1.4435, LR=0.000100
[2025-08-26 05:03:32,751][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029640] [Batch 00426/04869] [00:04:52/00:50:47, 0.686s/it]: train_loss_raw=1.3450, running_loss=1.4429, LR=0.000100
[2025-08-26 05:03:38,353][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029648] [Batch 00434/04869] [00:04:57/00:50:43, 0.686s/it]: train_loss_raw=1.4025, running_loss=1.4445, LR=0.000100
[2025-08-26 05:03:43,999][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029656] [Batch 00442/04869] [00:05:03/00:50:39, 0.687s/it]: train_loss_raw=1.4358, running_loss=1.4445, LR=0.000100
[2025-08-26 05:03:49,200][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029664] [Batch 00450/04869] [00:05:08/00:50:30, 0.686s/it]: train_loss_raw=1.5319, running_loss=1.4446, LR=0.000100
[2025-08-26 05:03:54,354][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029672] [Batch 00458/04869] [00:05:13/00:50:22, 0.685s/it]: train_loss_raw=1.3918, running_loss=1.4404, LR=0.000100
[2025-08-26 05:03:59,958][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029680] [Batch 00466/04869] [00:05:19/00:50:17, 0.685s/it]: train_loss_raw=1.4199, running_loss=1.4398, LR=0.000100
[2025-08-26 05:04:05,186][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029688] [Batch 00474/04869] [00:05:24/00:50:10, 0.685s/it]: train_loss_raw=1.3658, running_loss=1.4395, LR=0.000100
[2025-08-26 05:04:10,437][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029696] [Batch 00482/04869] [00:05:29/00:50:02, 0.684s/it]: train_loss_raw=1.4685, running_loss=1.4429, LR=0.000100
[2025-08-26 05:04:16,092][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029704] [Batch 00490/04869] [00:05:35/00:49:58, 0.685s/it]: train_loss_raw=1.3862, running_loss=1.4424, LR=0.000100
[2025-08-26 05:04:21,334][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029712] [Batch 00498/04869] [00:05:40/00:49:51, 0.684s/it]: train_loss_raw=1.5237, running_loss=1.4428, LR=0.000100
[2025-08-26 05:04:26,526][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029720] [Batch 00506/04869] [00:05:45/00:49:43, 0.684s/it]: train_loss_raw=1.3887, running_loss=1.4436, LR=0.000100
[2025-08-26 05:04:31,706][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029728] [Batch 00514/04869] [00:05:51/00:49:35, 0.683s/it]: train_loss_raw=1.4133, running_loss=1.4422, LR=0.000100
[2025-08-26 05:04:36,897][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029736] [Batch 00522/04869] [00:05:56/00:49:27, 0.683s/it]: train_loss_raw=1.4761, running_loss=1.4444, LR=0.000100
[2025-08-26 05:04:42,801][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029744] [Batch 00530/04869] [00:06:02/00:49:25, 0.684s/it]: train_loss_raw=1.3986, running_loss=1.4473, LR=0.000100
[2025-08-26 05:04:48,382][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029752] [Batch 00538/04869] [00:06:07/00:49:21, 0.684s/it]: train_loss_raw=1.4482, running_loss=1.4485, LR=0.000100
[2025-08-26 05:04:53,617][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029760] [Batch 00546/04869] [00:06:13/00:49:13, 0.683s/it]: train_loss_raw=1.5160, running_loss=1.4499, LR=0.000100
[2025-08-26 05:04:59,007][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029768] [Batch 00554/04869] [00:06:18/00:49:07, 0.683s/it]: train_loss_raw=1.4122, running_loss=1.4506, LR=0.000100
[2025-08-26 05:05:04,313][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029776] [Batch 00562/04869] [00:06:23/00:49:01, 0.683s/it]: train_loss_raw=1.3772, running_loss=1.4467, LR=0.000100
[2025-08-26 05:05:09,504][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029784] [Batch 00570/04869] [00:06:28/00:48:53, 0.682s/it]: train_loss_raw=1.3281, running_loss=1.4451, LR=0.000100
[2025-08-26 05:05:14,713][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029792] [Batch 00578/04869] [00:06:34/00:48:46, 0.682s/it]: train_loss_raw=1.4244, running_loss=1.4438, LR=0.000100
[2025-08-26 05:05:20,274][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029800] [Batch 00586/04869] [00:06:39/00:48:41, 0.682s/it]: train_loss_raw=1.3921, running_loss=1.4452, LR=0.000100
[2025-08-26 05:05:25,486][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029808] [Batch 00594/04869] [00:06:44/00:48:34, 0.682s/it]: train_loss_raw=1.5033, running_loss=1.4453, LR=0.000100
[2025-08-26 05:05:30,704][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029816] [Batch 00602/04869] [00:06:50/00:48:27, 0.681s/it]: train_loss_raw=1.4179, running_loss=1.4451, LR=0.000100
[2025-08-26 05:05:36,141][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029824] [Batch 00610/04869] [00:06:55/00:48:21, 0.681s/it]: train_loss_raw=1.5117, running_loss=1.4457, LR=0.000100
[2025-08-26 05:05:41,339][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029832] [Batch 00618/04869] [00:07:00/00:48:14, 0.681s/it]: train_loss_raw=1.5257, running_loss=1.4499, LR=0.000100
[2025-08-26 05:05:46,853][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029840] [Batch 00626/04869] [00:07:06/00:48:09, 0.681s/it]: train_loss_raw=1.4617, running_loss=1.4502, LR=0.000100
[2025-08-26 05:05:52,969][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029848] [Batch 00634/04869] [00:07:12/00:48:08, 0.682s/it]: train_loss_raw=1.4197, running_loss=1.4482, LR=0.000100
[2025-08-26 05:05:59,215][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029856] [Batch 00642/04869] [00:07:18/00:48:08, 0.683s/it]: train_loss_raw=1.5083, running_loss=1.4470, LR=0.000100
[2025-08-26 05:06:05,660][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029864] [Batch 00650/04869] [00:07:25/00:48:09, 0.685s/it]: train_loss_raw=1.5190, running_loss=1.4493, LR=0.000100
[2025-08-26 05:06:11,703][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029872] [Batch 00658/04869] [00:07:31/00:48:07, 0.686s/it]: train_loss_raw=1.3373, running_loss=1.4470, LR=0.000100
[2025-08-26 05:06:16,917][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029880] [Batch 00666/04869] [00:07:36/00:48:00, 0.685s/it]: train_loss_raw=1.5381, running_loss=1.4470, LR=0.000100
[2025-08-26 05:06:22,122][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029888] [Batch 00674/04869] [00:07:41/00:47:52, 0.685s/it]: train_loss_raw=1.5051, running_loss=1.4459, LR=0.000100
[2025-08-26 05:06:27,721][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029896] [Batch 00682/04869] [00:07:47/00:47:48, 0.685s/it]: train_loss_raw=1.3647, running_loss=1.4446, LR=0.000100
[2025-08-26 05:06:32,921][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029904] [Batch 00690/04869] [00:07:52/00:47:40, 0.685s/it]: train_loss_raw=1.4461, running_loss=1.4431, LR=0.000100
[2025-08-26 05:06:38,103][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029912] [Batch 00698/04869] [00:07:57/00:47:33, 0.684s/it]: train_loss_raw=1.5145, running_loss=1.4400, LR=0.000100
[2025-08-26 05:06:43,491][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029920] [Batch 00706/04869] [00:08:02/00:47:27, 0.684s/it]: train_loss_raw=1.3793, running_loss=1.4372, LR=0.000100
[2025-08-26 05:06:49,255][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029928] [Batch 00714/04869] [00:08:08/00:47:23, 0.684s/it]: train_loss_raw=1.4695, running_loss=1.4382, LR=0.000100
[2025-08-26 05:06:54,451][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029936] [Batch 00722/04869] [00:08:13/00:47:16, 0.684s/it]: train_loss_raw=1.5555, running_loss=1.4386, LR=0.000100
[2025-08-26 05:06:59,630][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029944] [Batch 00730/04869] [00:08:19/00:47:09, 0.684s/it]: train_loss_raw=1.4604, running_loss=1.4404, LR=0.000100
[2025-08-26 05:07:05,336][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029952] [Batch 00738/04869] [00:08:24/00:47:05, 0.684s/it]: train_loss_raw=1.5221, running_loss=1.4426, LR=0.000100
[2025-08-26 05:07:10,958][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029960] [Batch 00746/04869] [00:08:30/00:47:00, 0.684s/it]: train_loss_raw=1.3976, running_loss=1.4427, LR=0.000100
[2025-08-26 05:07:16,478][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029968] [Batch 00754/04869] [00:08:35/00:46:55, 0.684s/it]: train_loss_raw=1.4489, running_loss=1.4420, LR=0.000100
[2025-08-26 05:07:21,649][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029976] [Batch 00762/04869] [00:08:41/00:46:48, 0.684s/it]: train_loss_raw=1.5509, running_loss=1.4411, LR=0.000100
[2025-08-26 05:07:27,297][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029984] [Batch 00770/04869] [00:08:46/00:46:44, 0.684s/it]: train_loss_raw=1.4082, running_loss=1.4377, LR=0.000100
[2025-08-26 05:07:32,640][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 029992] [Batch 00778/04869] [00:08:52/00:46:37, 0.684s/it]: train_loss_raw=1.5543, running_loss=1.4387, LR=0.000100
[2025-08-26 05:07:37,856][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030000] [Batch 00786/04869] [00:08:57/00:46:31, 0.684s/it]: train_loss_raw=1.4085, running_loss=1.4402, LR=0.000100
[2025-08-26 05:07:47,833][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030008] [Batch 00794/04869] [00:09:07/00:46:48, 0.689s/it]: train_loss_raw=1.3466, running_loss=1.4426, LR=0.000100
[2025-08-26 05:07:53,928][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030016] [Batch 00802/04869] [00:09:13/00:46:46, 0.690s/it]: train_loss_raw=1.3986, running_loss=1.4423, LR=0.000100
[2025-08-26 05:07:59,778][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030024] [Batch 00810/04869] [00:09:19/00:46:42, 0.690s/it]: train_loss_raw=1.4103, running_loss=1.4415, LR=0.000100
[2025-08-26 05:08:05,731][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030032] [Batch 00818/04869] [00:09:25/00:46:38, 0.691s/it]: train_loss_raw=1.3535, running_loss=1.4404, LR=0.000100
[2025-08-26 05:08:11,052][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030040] [Batch 00826/04869] [00:09:30/00:46:32, 0.691s/it]: train_loss_raw=1.3945, running_loss=1.4420, LR=0.000100
[2025-08-26 05:08:16,400][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030048] [Batch 00834/04869] [00:09:35/00:46:26, 0.690s/it]: train_loss_raw=1.4388, running_loss=1.4408, LR=0.000100
[2025-08-26 05:08:21,711][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030056] [Batch 00842/04869] [00:09:41/00:46:19, 0.690s/it]: train_loss_raw=1.3981, running_loss=1.4424, LR=0.000100
[2025-08-26 05:08:27,011][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030064] [Batch 00850/04869] [00:09:46/00:46:12, 0.690s/it]: train_loss_raw=1.3514, running_loss=1.4411, LR=0.000100
[2025-08-26 05:08:32,300][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030072] [Batch 00858/04869] [00:09:51/00:46:06, 0.690s/it]: train_loss_raw=1.4551, running_loss=1.4425, LR=0.000100
[2025-08-26 05:08:37,834][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030080] [Batch 00866/04869] [00:09:57/00:46:00, 0.690s/it]: train_loss_raw=1.5443, running_loss=1.4442, LR=0.000100
[2025-08-26 05:08:43,406][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030088] [Batch 00874/04869] [00:10:02/00:45:55, 0.690s/it]: train_loss_raw=1.4510, running_loss=1.4437, LR=0.000100
[2025-08-26 05:08:49,203][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030096] [Batch 00882/04869] [00:10:08/00:45:51, 0.690s/it]: train_loss_raw=1.4525, running_loss=1.4443, LR=0.000100
[2025-08-26 05:08:54,785][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030104] [Batch 00890/04869] [00:10:14/00:45:46, 0.690s/it]: train_loss_raw=1.3781, running_loss=1.4398, LR=0.000100
[2025-08-26 05:08:59,998][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030112] [Batch 00898/04869] [00:10:19/00:45:39, 0.690s/it]: train_loss_raw=1.3869, running_loss=1.4389, LR=0.000100
[2025-08-26 05:09:05,223][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030120] [Batch 00906/04869] [00:10:24/00:45:32, 0.689s/it]: train_loss_raw=1.5810, running_loss=1.4407, LR=0.000100
[2025-08-26 05:09:10,431][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030128] [Batch 00914/04869] [00:10:29/00:45:25, 0.689s/it]: train_loss_raw=1.4836, running_loss=1.4389, LR=0.000100
[2025-08-26 05:09:15,624][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030136] [Batch 00922/04869] [00:10:35/00:45:18, 0.689s/it]: train_loss_raw=1.3405, running_loss=1.4378, LR=0.000100
[2025-08-26 05:09:20,859][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030144] [Batch 00930/04869] [00:10:40/00:45:12, 0.689s/it]: train_loss_raw=1.2541, running_loss=1.4363, LR=0.000100
[2025-08-26 05:09:26,430][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030152] [Batch 00938/04869] [00:10:45/00:45:06, 0.689s/it]: train_loss_raw=1.3784, running_loss=1.4363, LR=0.000100
[2025-08-26 05:09:31,625][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030160] [Batch 00946/04869] [00:10:51/00:44:59, 0.688s/it]: train_loss_raw=1.3419, running_loss=1.4344, LR=0.000100
[2025-08-26 05:09:36,826][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030168] [Batch 00954/04869] [00:10:56/00:44:53, 0.688s/it]: train_loss_raw=1.4068, running_loss=1.4368, LR=0.000100
[2025-08-26 05:09:42,042][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030176] [Batch 00962/04869] [00:11:01/00:44:46, 0.688s/it]: train_loss_raw=1.4037, running_loss=1.4367, LR=0.000100
[2025-08-26 05:09:47,273][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030184] [Batch 00970/04869] [00:11:06/00:44:39, 0.687s/it]: train_loss_raw=1.4451, running_loss=1.4360, LR=0.000100
[2025-08-26 05:09:52,827][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030192] [Batch 00978/04869] [00:11:12/00:44:34, 0.687s/it]: train_loss_raw=1.4491, running_loss=1.4366, LR=0.000100
[2025-08-26 05:09:58,796][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030200] [Batch 00986/04869] [00:11:18/00:44:31, 0.688s/it]: train_loss_raw=1.3901, running_loss=1.4362, LR=0.000100
[2025-08-26 05:10:04,333][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030208] [Batch 00994/04869] [00:11:23/00:44:25, 0.688s/it]: train_loss_raw=1.4369, running_loss=1.4354, LR=0.000100
[2025-08-26 05:10:09,970][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030216] [Batch 01002/04869] [00:11:29/00:44:20, 0.688s/it]: train_loss_raw=1.5174, running_loss=1.4368, LR=0.000100
[2025-08-26 05:10:28,268][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030224] [Batch 01010/04869] [00:11:47/00:45:04, 0.701s/it]: train_loss_raw=1.4861, running_loss=1.4366, LR=0.000100
[2025-08-26 05:10:33,867][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030232] [Batch 01018/04869] [00:11:53/00:44:58, 0.701s/it]: train_loss_raw=1.3798, running_loss=1.4326, LR=0.000100
[2025-08-26 05:10:39,069][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030240] [Batch 01026/04869] [00:11:58/00:44:51, 0.700s/it]: train_loss_raw=1.4822, running_loss=1.4313, LR=0.000100
[2025-08-26 05:10:44,907][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030248] [Batch 01034/04869] [00:12:04/00:44:46, 0.701s/it]: train_loss_raw=1.4220, running_loss=1.4289, LR=0.000100
[2025-08-26 05:10:50,730][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030256] [Batch 01042/04869] [00:12:10/00:44:41, 0.701s/it]: train_loss_raw=1.3620, running_loss=1.4283, LR=0.000100
[2025-08-26 05:10:56,537][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030264] [Batch 01050/04869] [00:12:15/00:44:36, 0.701s/it]: train_loss_raw=1.3532, running_loss=1.4268, LR=0.000100
[2025-08-26 05:11:02,063][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030272] [Batch 01058/04869] [00:12:21/00:44:31, 0.701s/it]: train_loss_raw=1.5060, running_loss=1.4248, LR=0.000100
[2025-08-26 05:11:07,904][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030280] [Batch 01066/04869] [00:12:27/00:44:26, 0.701s/it]: train_loss_raw=1.3777, running_loss=1.4255, LR=0.000100
[2025-08-26 05:11:14,021][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030288] [Batch 01074/04869] [00:12:33/00:44:22, 0.702s/it]: train_loss_raw=1.3880, running_loss=1.4234, LR=0.000100
[2025-08-26 05:11:19,998][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030296] [Batch 01082/04869] [00:12:39/00:44:18, 0.702s/it]: train_loss_raw=1.3372, running_loss=1.4221, LR=0.000100
[2025-08-26 05:11:26,251][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030304] [Batch 01090/04869] [00:12:45/00:44:14, 0.702s/it]: train_loss_raw=1.4000, running_loss=1.4223, LR=0.000100
[2025-08-26 05:11:31,651][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030312] [Batch 01098/04869] [00:12:51/00:44:08, 0.702s/it]: train_loss_raw=1.3853, running_loss=1.4243, LR=0.000100
[2025-08-26 05:11:37,034][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030320] [Batch 01106/04869] [00:12:56/00:44:01, 0.702s/it]: train_loss_raw=1.4689, running_loss=1.4238, LR=0.000100
[2025-08-26 05:11:42,407][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030328] [Batch 01114/04869] [00:13:01/00:43:55, 0.702s/it]: train_loss_raw=1.4637, running_loss=1.4259, LR=0.000100
[2025-08-26 05:11:48,179][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030336] [Batch 01122/04869] [00:13:07/00:43:50, 0.702s/it]: train_loss_raw=1.5785, running_loss=1.4291, LR=0.000100
[2025-08-26 05:11:53,721][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030344] [Batch 01130/04869] [00:13:13/00:43:44, 0.702s/it]: train_loss_raw=1.4320, running_loss=1.4288, LR=0.000100
[2025-08-26 05:11:59,116][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030352] [Batch 01138/04869] [00:13:18/00:43:38, 0.702s/it]: train_loss_raw=1.3126, running_loss=1.4277, LR=0.000100
[2025-08-26 05:12:04,652][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030360] [Batch 01146/04869] [00:13:24/00:43:32, 0.702s/it]: train_loss_raw=1.4716, running_loss=1.4272, LR=0.000100
[2025-08-26 05:12:10,378][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030368] [Batch 01154/04869] [00:13:29/00:43:27, 0.702s/it]: train_loss_raw=1.3943, running_loss=1.4234, LR=0.000100
[2025-08-26 05:12:15,610][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030376] [Batch 01162/04869] [00:13:35/00:43:20, 0.701s/it]: train_loss_raw=1.3476, running_loss=1.4230, LR=0.000100
[2025-08-26 05:12:20,838][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030384] [Batch 01170/04869] [00:13:40/00:43:13, 0.701s/it]: train_loss_raw=1.3686, running_loss=1.4271, LR=0.000100
[2025-08-26 05:12:26,060][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030392] [Batch 01178/04869] [00:13:45/00:43:06, 0.701s/it]: train_loss_raw=1.4970, running_loss=1.4294, LR=0.000100
[2025-08-26 05:12:31,674][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030400] [Batch 01186/04869] [00:13:51/00:43:00, 0.701s/it]: train_loss_raw=1.4893, running_loss=1.4306, LR=0.000100
[2025-08-26 05:12:36,855][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030408] [Batch 01194/04869] [00:13:56/00:42:54, 0.700s/it]: train_loss_raw=1.3105, running_loss=1.4284, LR=0.000100
[2025-08-26 05:12:42,031][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030416] [Batch 01202/04869] [00:14:01/00:42:47, 0.700s/it]: train_loss_raw=1.4830, running_loss=1.4279, LR=0.000100
[2025-08-26 05:12:47,238][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030424] [Batch 01210/04869] [00:14:06/00:42:40, 0.700s/it]: train_loss_raw=1.3618, running_loss=1.4297, LR=0.000100
[2025-08-26 05:12:52,766][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030432] [Batch 01218/04869] [00:14:12/00:42:34, 0.700s/it]: train_loss_raw=1.4055, running_loss=1.4290, LR=0.000100
[2025-08-26 05:12:58,000][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030440] [Batch 01226/04869] [00:14:17/00:42:27, 0.699s/it]: train_loss_raw=1.3586, running_loss=1.4280, LR=0.000100
[2025-08-26 05:13:03,228][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030448] [Batch 01234/04869] [00:14:22/00:42:21, 0.699s/it]: train_loss_raw=1.4744, running_loss=1.4300, LR=0.000100
[2025-08-26 05:13:08,965][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030456] [Batch 01242/04869] [00:14:28/00:42:16, 0.699s/it]: train_loss_raw=1.3597, running_loss=1.4304, LR=0.000100
[2025-08-26 05:13:14,382][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030464] [Batch 01250/04869] [00:14:33/00:42:09, 0.699s/it]: train_loss_raw=1.4501, running_loss=1.4300, LR=0.000100
[2025-08-26 05:13:19,603][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030472] [Batch 01258/04869] [00:14:39/00:42:03, 0.699s/it]: train_loss_raw=1.5027, running_loss=1.4276, LR=0.000100
[2025-08-26 05:13:24,948][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030480] [Batch 01266/04869] [00:14:44/00:41:56, 0.699s/it]: train_loss_raw=1.3631, running_loss=1.4276, LR=0.000100
[2025-08-26 05:13:31,112][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030488] [Batch 01274/04869] [00:14:50/00:41:53, 0.699s/it]: train_loss_raw=1.4737, running_loss=1.4285, LR=0.000100
[2025-08-26 05:13:36,924][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030496] [Batch 01282/04869] [00:14:56/00:41:48, 0.699s/it]: train_loss_raw=1.4331, running_loss=1.4250, LR=0.000100
[2025-08-26 05:13:42,452][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030504] [Batch 01290/04869] [00:15:01/00:41:42, 0.699s/it]: train_loss_raw=1.4535, running_loss=1.4231, LR=0.000100
[2025-08-26 05:13:48,230][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030512] [Batch 01298/04869] [00:15:07/00:41:37, 0.699s/it]: train_loss_raw=1.5128, running_loss=1.4213, LR=0.000100
[2025-08-26 05:13:53,646][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030520] [Batch 01306/04869] [00:15:13/00:41:31, 0.699s/it]: train_loss_raw=1.3714, running_loss=1.4190, LR=0.000100
[2025-08-26 05:13:59,146][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030528] [Batch 01314/04869] [00:15:18/00:41:25, 0.699s/it]: train_loss_raw=1.4504, running_loss=1.4172, LR=0.000100
[2025-08-26 05:14:04,592][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030536] [Batch 01322/04869] [00:15:24/00:41:19, 0.699s/it]: train_loss_raw=1.4520, running_loss=1.4187, LR=0.000100
[2025-08-26 05:14:10,077][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030544] [Batch 01330/04869] [00:15:29/00:41:13, 0.699s/it]: train_loss_raw=1.4630, running_loss=1.4200, LR=0.000100
[2025-08-26 05:14:15,315][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030552] [Batch 01338/04869] [00:15:34/00:41:06, 0.699s/it]: train_loss_raw=1.4124, running_loss=1.4206, LR=0.000100
[2025-08-26 05:14:20,536][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030560] [Batch 01346/04869] [00:15:39/00:41:00, 0.698s/it]: train_loss_raw=1.3821, running_loss=1.4226, LR=0.000100
[2025-08-26 05:14:25,757][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030568] [Batch 01354/04869] [00:15:45/00:40:53, 0.698s/it]: train_loss_raw=1.4713, running_loss=1.4237, LR=0.000100
[2025-08-26 05:14:30,971][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030576] [Batch 01362/04869] [00:15:50/00:40:47, 0.698s/it]: train_loss_raw=1.4794, running_loss=1.4229, LR=0.000100
[2025-08-26 05:14:36,187][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030584] [Batch 01370/04869] [00:15:55/00:40:40, 0.698s/it]: train_loss_raw=1.4927, running_loss=1.4250, LR=0.000100
[2025-08-26 05:14:41,754][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030592] [Batch 01378/04869] [00:16:01/00:40:35, 0.698s/it]: train_loss_raw=1.3500, running_loss=1.4228, LR=0.000100
[2025-08-26 05:14:47,300][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030600] [Batch 01386/04869] [00:16:06/00:40:29, 0.698s/it]: train_loss_raw=1.4127, running_loss=1.4206, LR=0.000100
[2025-08-26 05:14:52,481][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030608] [Batch 01394/04869] [00:16:11/00:40:22, 0.697s/it]: train_loss_raw=1.4043, running_loss=1.4218, LR=0.000100
[2025-08-26 05:14:57,689][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030616] [Batch 01402/04869] [00:16:17/00:40:16, 0.697s/it]: train_loss_raw=1.4620, running_loss=1.4211, LR=0.000100
[2025-08-26 05:15:02,926][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030624] [Batch 01410/04869] [00:16:22/00:40:09, 0.697s/it]: train_loss_raw=1.3772, running_loss=1.4181, LR=0.000100
[2025-08-26 05:15:08,335][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030632] [Batch 01418/04869] [00:16:27/00:40:03, 0.697s/it]: train_loss_raw=1.3893, running_loss=1.4208, LR=0.000100
[2025-08-26 05:15:13,728][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030640] [Batch 01426/04869] [00:16:33/00:39:57, 0.696s/it]: train_loss_raw=1.3373, running_loss=1.4180, LR=0.000100
[2025-08-26 05:15:19,174][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030648] [Batch 01434/04869] [00:16:38/00:39:52, 0.696s/it]: train_loss_raw=1.4198, running_loss=1.4190, LR=0.000100
[2025-08-26 05:15:25,317][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030656] [Batch 01442/04869] [00:16:44/00:39:47, 0.697s/it]: train_loss_raw=1.4296, running_loss=1.4165, LR=0.000100
[2025-08-26 05:15:30,493][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030664] [Batch 01450/04869] [00:16:49/00:39:41, 0.697s/it]: train_loss_raw=1.5132, running_loss=1.4142, LR=0.000100
[2025-08-26 05:15:35,896][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030672] [Batch 01458/04869] [00:16:55/00:39:35, 0.696s/it]: train_loss_raw=1.5316, running_loss=1.4130, LR=0.000100
[2025-08-26 05:15:41,512][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030680] [Batch 01466/04869] [00:17:00/00:39:29, 0.696s/it]: train_loss_raw=1.4727, running_loss=1.4130, LR=0.000100
[2025-08-26 05:15:46,945][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030688] [Batch 01474/04869] [00:17:06/00:39:24, 0.696s/it]: train_loss_raw=1.3491, running_loss=1.4150, LR=0.000100
[2025-08-26 05:15:52,584][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030696] [Batch 01482/04869] [00:17:12/00:39:18, 0.696s/it]: train_loss_raw=1.4418, running_loss=1.4168, LR=0.000100
[2025-08-26 05:15:58,549][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030704] [Batch 01490/04869] [00:17:18/00:39:13, 0.697s/it]: train_loss_raw=1.4249, running_loss=1.4177, LR=0.000100
[2025-08-26 05:16:04,136][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030712] [Batch 01498/04869] [00:17:23/00:39:08, 0.697s/it]: train_loss_raw=1.4443, running_loss=1.4141, LR=0.000100
[2025-08-26 05:16:09,317][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030720] [Batch 01506/04869] [00:17:28/00:39:01, 0.696s/it]: train_loss_raw=1.3586, running_loss=1.4124, LR=0.000100
[2025-08-26 05:16:14,488][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030728] [Batch 01514/04869] [00:17:33/00:38:55, 0.696s/it]: train_loss_raw=1.3311, running_loss=1.4095, LR=0.000100
[2025-08-26 05:16:19,719][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030736] [Batch 01522/04869] [00:17:39/00:38:49, 0.696s/it]: train_loss_raw=1.4493, running_loss=1.4127, LR=0.000100
[2025-08-26 05:16:24,914][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030744] [Batch 01530/04869] [00:17:44/00:38:42, 0.696s/it]: train_loss_raw=1.4825, running_loss=1.4143, LR=0.000100
[2025-08-26 05:16:30,361][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030752] [Batch 01538/04869] [00:17:49/00:38:37, 0.696s/it]: train_loss_raw=1.2890, running_loss=1.4122, LR=0.000100
[2025-08-26 05:16:36,206][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030760] [Batch 01546/04869] [00:17:55/00:38:32, 0.696s/it]: train_loss_raw=1.4140, running_loss=1.4117, LR=0.000100
[2025-08-26 05:16:41,398][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030768] [Batch 01554/04869] [00:18:00/00:38:25, 0.696s/it]: train_loss_raw=1.5232, running_loss=1.4103, LR=0.000100
[2025-08-26 05:16:46,609][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030776] [Batch 01562/04869] [00:18:06/00:38:19, 0.695s/it]: train_loss_raw=1.3867, running_loss=1.4088, LR=0.000100
[2025-08-26 05:16:51,915][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030784] [Batch 01570/04869] [00:18:11/00:38:13, 0.695s/it]: train_loss_raw=1.4507, running_loss=1.4113, LR=0.000100
[2025-08-26 05:16:57,118][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030792] [Batch 01578/04869] [00:18:16/00:38:06, 0.695s/it]: train_loss_raw=1.3416, running_loss=1.4120, LR=0.000100
[2025-08-26 05:17:02,457][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030800] [Batch 01586/04869] [00:18:21/00:38:00, 0.695s/it]: train_loss_raw=1.3871, running_loss=1.4139, LR=0.000100
[2025-08-26 05:17:07,674][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030808] [Batch 01594/04869] [00:18:27/00:37:54, 0.695s/it]: train_loss_raw=1.4094, running_loss=1.4163, LR=0.000100
[2025-08-26 05:17:13,362][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030816] [Batch 01602/04869] [00:18:32/00:37:49, 0.695s/it]: train_loss_raw=1.4022, running_loss=1.4175, LR=0.000100
[2025-08-26 05:17:18,921][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030824] [Batch 01610/04869] [00:18:38/00:37:43, 0.695s/it]: train_loss_raw=1.5391, running_loss=1.4167, LR=0.000100
[2025-08-26 05:17:25,202][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030832] [Batch 01618/04869] [00:18:44/00:37:39, 0.695s/it]: train_loss_raw=1.4140, running_loss=1.4170, LR=0.000100
[2025-08-26 05:17:30,638][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030840] [Batch 01626/04869] [00:18:50/00:37:33, 0.695s/it]: train_loss_raw=1.5117, running_loss=1.4203, LR=0.000100
[2025-08-26 05:17:36,427][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030848] [Batch 01634/04869] [00:18:55/00:37:28, 0.695s/it]: train_loss_raw=1.4260, running_loss=1.4202, LR=0.000100
[2025-08-26 05:17:42,063][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030856] [Batch 01642/04869] [00:19:01/00:37:23, 0.695s/it]: train_loss_raw=1.3951, running_loss=1.4204, LR=0.000100
[2025-08-26 05:17:47,478][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030864] [Batch 01650/04869] [00:19:06/00:37:17, 0.695s/it]: train_loss_raw=1.3486, running_loss=1.4217, LR=0.000100
[2025-08-26 05:17:53,004][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030872] [Batch 01658/04869] [00:19:12/00:37:11, 0.695s/it]: train_loss_raw=1.4433, running_loss=1.4213, LR=0.000100
[2025-08-26 05:17:58,239][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030880] [Batch 01666/04869] [00:19:17/00:37:05, 0.695s/it]: train_loss_raw=1.4482, running_loss=1.4220, LR=0.000100
[2025-08-26 05:18:04,150][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030888] [Batch 01674/04869] [00:19:23/00:37:00, 0.695s/it]: train_loss_raw=1.4522, running_loss=1.4205, LR=0.000100
[2025-08-26 05:18:10,222][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030896] [Batch 01682/04869] [00:19:29/00:36:56, 0.695s/it]: train_loss_raw=1.3821, running_loss=1.4188, LR=0.000100
[2025-08-26 05:18:15,815][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030904] [Batch 01690/04869] [00:19:35/00:36:50, 0.695s/it]: train_loss_raw=1.3938, running_loss=1.4177, LR=0.000100
[2025-08-26 05:18:21,057][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030912] [Batch 01698/04869] [00:19:40/00:36:44, 0.695s/it]: train_loss_raw=1.5303, running_loss=1.4192, LR=0.000100
[2025-08-26 05:18:26,741][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030920] [Batch 01706/04869] [00:19:46/00:36:39, 0.695s/it]: train_loss_raw=1.3572, running_loss=1.4207, LR=0.000100
[2025-08-26 05:18:32,212][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030928] [Batch 01714/04869] [00:19:51/00:36:33, 0.695s/it]: train_loss_raw=1.3097, running_loss=1.4216, LR=0.000100
[2025-08-26 05:18:37,453][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030936] [Batch 01722/04869] [00:19:56/00:36:27, 0.695s/it]: train_loss_raw=1.3515, running_loss=1.4210, LR=0.000100
[2025-08-26 05:18:43,539][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030944] [Batch 01730/04869] [00:20:02/00:36:22, 0.695s/it]: train_loss_raw=1.4305, running_loss=1.4204, LR=0.000100
[2025-08-26 05:18:49,218][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030952] [Batch 01738/04869] [00:20:08/00:36:17, 0.695s/it]: train_loss_raw=1.4253, running_loss=1.4201, LR=0.000100
[2025-08-26 05:18:54,570][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030960] [Batch 01746/04869] [00:20:14/00:36:11, 0.695s/it]: train_loss_raw=1.4071, running_loss=1.4173, LR=0.000100
[2025-08-26 05:18:59,762][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030968] [Batch 01754/04869] [00:20:19/00:36:05, 0.695s/it]: train_loss_raw=1.4404, running_loss=1.4207, LR=0.000100
[2025-08-26 05:19:05,559][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030976] [Batch 01762/04869] [00:20:25/00:36:00, 0.695s/it]: train_loss_raw=1.4476, running_loss=1.4207, LR=0.000100
[2025-08-26 05:19:10,831][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030984] [Batch 01770/04869] [00:20:30/00:35:54, 0.695s/it]: train_loss_raw=1.3696, running_loss=1.4197, LR=0.000100
[2025-08-26 05:19:16,817][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 030992] [Batch 01778/04869] [00:20:36/00:35:49, 0.695s/it]: train_loss_raw=1.4417, running_loss=1.4198, LR=0.000100
[2025-08-26 05:19:22,112][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031000] [Batch 01786/04869] [00:20:41/00:35:43, 0.695s/it]: train_loss_raw=1.3461, running_loss=1.4219, LR=0.000100
[2025-08-26 05:19:27,333][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031008] [Batch 01794/04869] [00:20:46/00:35:37, 0.695s/it]: train_loss_raw=1.4210, running_loss=1.4199, LR=0.000100
[2025-08-26 05:19:32,557][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031016] [Batch 01802/04869] [00:20:52/00:35:30, 0.695s/it]: train_loss_raw=1.5033, running_loss=1.4180, LR=0.000100
[2025-08-26 05:19:37,767][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031024] [Batch 01810/04869] [00:20:57/00:35:24, 0.695s/it]: train_loss_raw=1.4075, running_loss=1.4171, LR=0.000100
[2025-08-26 05:19:42,966][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031032] [Batch 01818/04869] [00:21:02/00:35:18, 0.694s/it]: train_loss_raw=1.3517, running_loss=1.4159, LR=0.000100
[2025-08-26 05:19:48,234][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031040] [Batch 01826/04869] [00:21:07/00:35:12, 0.694s/it]: train_loss_raw=1.2945, running_loss=1.4165, LR=0.000100
[2025-08-26 05:19:53,689][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031048] [Batch 01834/04869] [00:21:13/00:35:06, 0.694s/it]: train_loss_raw=1.3718, running_loss=1.4177, LR=0.000100
[2025-08-26 05:19:58,964][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031056] [Batch 01842/04869] [00:21:18/00:35:00, 0.694s/it]: train_loss_raw=1.3749, running_loss=1.4169, LR=0.000100
[2025-08-26 05:20:04,420][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031064] [Batch 01850/04869] [00:21:23/00:34:55, 0.694s/it]: train_loss_raw=1.4065, running_loss=1.4171, LR=0.000100
[2025-08-26 05:20:09,744][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031072] [Batch 01858/04869] [00:21:29/00:34:49, 0.694s/it]: train_loss_raw=1.4011, running_loss=1.4157, LR=0.000100
[2025-08-26 05:20:15,483][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031080] [Batch 01866/04869] [00:21:34/00:34:43, 0.694s/it]: train_loss_raw=1.3646, running_loss=1.4141, LR=0.000100
[2025-08-26 05:20:20,756][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031088] [Batch 01874/04869] [00:21:40/00:34:37, 0.694s/it]: train_loss_raw=1.4451, running_loss=1.4136, LR=0.000100
[2025-08-26 05:20:25,907][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031096] [Batch 01882/04869] [00:21:45/00:34:31, 0.694s/it]: train_loss_raw=1.5000, running_loss=1.4119, LR=0.000100
[2025-08-26 05:20:31,075][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031104] [Batch 01890/04869] [00:21:50/00:34:25, 0.693s/it]: train_loss_raw=1.6199, running_loss=1.4145, LR=0.000100
[2025-08-26 05:20:36,244][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031112] [Batch 01898/04869] [00:21:55/00:34:19, 0.693s/it]: train_loss_raw=1.2926, running_loss=1.4129, LR=0.000100
[2025-08-26 05:20:41,525][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031120] [Batch 01906/04869] [00:22:00/00:34:13, 0.693s/it]: train_loss_raw=1.4952, running_loss=1.4156, LR=0.000100
[2025-08-26 05:20:47,077][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031128] [Batch 01914/04869] [00:22:06/00:34:08, 0.693s/it]: train_loss_raw=1.3389, running_loss=1.4130, LR=0.000100
[2025-08-26 05:20:52,621][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031136] [Batch 01922/04869] [00:22:12/00:34:02, 0.693s/it]: train_loss_raw=1.3574, running_loss=1.4107, LR=0.000100
[2025-08-26 05:20:57,843][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031144] [Batch 01930/04869] [00:22:17/00:33:56, 0.693s/it]: train_loss_raw=1.4535, running_loss=1.4111, LR=0.000100
[2025-08-26 05:21:03,221][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031152] [Batch 01938/04869] [00:22:22/00:33:50, 0.693s/it]: train_loss_raw=1.4057, running_loss=1.4112, LR=0.000100
[2025-08-26 05:21:08,620][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031160] [Batch 01946/04869] [00:22:28/00:33:44, 0.693s/it]: train_loss_raw=1.4710, running_loss=1.4131, LR=0.000100
[2025-08-26 05:21:14,333][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031168] [Batch 01954/04869] [00:22:33/00:33:39, 0.693s/it]: train_loss_raw=1.3857, running_loss=1.4100, LR=0.000100
[2025-08-26 05:21:19,536][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031176] [Batch 01962/04869] [00:22:38/00:33:33, 0.693s/it]: train_loss_raw=1.4374, running_loss=1.4083, LR=0.000100
[2025-08-26 05:21:24,741][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031184] [Batch 01970/04869] [00:22:44/00:33:27, 0.692s/it]: train_loss_raw=1.3328, running_loss=1.4053, LR=0.000100
[2025-08-26 05:21:29,943][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031192] [Batch 01978/04869] [00:22:49/00:33:21, 0.692s/it]: train_loss_raw=1.3826, running_loss=1.4042, LR=0.000100
[2025-08-26 05:21:35,689][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031200] [Batch 01986/04869] [00:22:55/00:33:16, 0.692s/it]: train_loss_raw=1.3520, running_loss=1.4036, LR=0.000100
[2025-08-26 05:21:41,010][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031208] [Batch 01994/04869] [00:23:00/00:33:10, 0.692s/it]: train_loss_raw=1.4466, running_loss=1.4047, LR=0.000100
[2025-08-26 05:21:46,186][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031216] [Batch 02002/04869] [00:23:05/00:33:04, 0.692s/it]: train_loss_raw=1.4324, running_loss=1.4048, LR=0.000100
[2025-08-26 05:21:51,369][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031224] [Batch 02010/04869] [00:23:10/00:32:58, 0.692s/it]: train_loss_raw=1.3760, running_loss=1.4049, LR=0.000100
[2025-08-26 05:21:56,731][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031232] [Batch 02018/04869] [00:23:16/00:32:52, 0.692s/it]: train_loss_raw=1.3565, running_loss=1.4037, LR=0.000100
[2025-08-26 05:22:01,902][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031240] [Batch 02026/04869] [00:23:21/00:32:46, 0.692s/it]: train_loss_raw=1.4766, running_loss=1.4024, LR=0.000100
[2025-08-26 05:22:07,064][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031248] [Batch 02034/04869] [00:23:26/00:32:40, 0.692s/it]: train_loss_raw=1.4135, running_loss=1.4022, LR=0.000100
[2025-08-26 05:22:12,238][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031256] [Batch 02042/04869] [00:23:31/00:32:34, 0.691s/it]: train_loss_raw=1.3669, running_loss=1.3983, LR=0.000100
[2025-08-26 05:22:17,405][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031264] [Batch 02050/04869] [00:23:36/00:32:28, 0.691s/it]: train_loss_raw=1.4014, running_loss=1.3993, LR=0.000100
[2025-08-26 05:22:22,881][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031272] [Batch 02058/04869] [00:23:42/00:32:22, 0.691s/it]: train_loss_raw=1.3422, running_loss=1.3970, LR=0.000100
[2025-08-26 05:22:28,032][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031280] [Batch 02066/04869] [00:23:47/00:32:16, 0.691s/it]: train_loss_raw=1.4347, running_loss=1.3985, LR=0.000100
[2025-08-26 05:22:33,214][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031288] [Batch 02074/04869] [00:23:52/00:32:10, 0.691s/it]: train_loss_raw=1.3565, running_loss=1.3986, LR=0.000100
[2025-08-26 05:22:38,411][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031296] [Batch 02082/04869] [00:23:57/00:32:04, 0.691s/it]: train_loss_raw=1.4126, running_loss=1.3994, LR=0.000100
[2025-08-26 05:22:43,661][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031304] [Batch 02090/04869] [00:24:03/00:31:58, 0.690s/it]: train_loss_raw=1.4169, running_loss=1.4004, LR=0.000100
[2025-08-26 05:22:49,102][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031312] [Batch 02098/04869] [00:24:08/00:31:53, 0.690s/it]: train_loss_raw=1.3053, running_loss=1.3986, LR=0.000100
[2025-08-26 05:22:54,264][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031320] [Batch 02106/04869] [00:24:13/00:31:47, 0.690s/it]: train_loss_raw=1.3407, running_loss=1.3985, LR=0.000100
[2025-08-26 05:22:59,451][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031328] [Batch 02114/04869] [00:24:18/00:31:41, 0.690s/it]: train_loss_raw=1.4772, running_loss=1.4001, LR=0.000100
[2025-08-26 05:23:04,623][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031336] [Batch 02122/04869] [00:24:24/00:31:35, 0.690s/it]: train_loss_raw=1.3465, running_loss=1.3995, LR=0.000100
[2025-08-26 05:23:09,776][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031344] [Batch 02130/04869] [00:24:29/00:31:29, 0.690s/it]: train_loss_raw=1.4304, running_loss=1.3996, LR=0.000100
[2025-08-26 05:23:14,946][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031352] [Batch 02138/04869] [00:24:34/00:31:23, 0.690s/it]: train_loss_raw=1.4584, running_loss=1.4007, LR=0.000100
[2025-08-26 05:23:20,098][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031360] [Batch 02146/04869] [00:24:39/00:31:17, 0.689s/it]: train_loss_raw=1.3120, running_loss=1.3989, LR=0.000100
[2025-08-26 05:23:25,241][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031368] [Batch 02154/04869] [00:24:44/00:31:11, 0.689s/it]: train_loss_raw=1.3612, running_loss=1.3950, LR=0.000100
[2025-08-26 05:23:30,388][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031376] [Batch 02162/04869] [00:24:49/00:31:05, 0.689s/it]: train_loss_raw=1.4261, running_loss=1.3961, LR=0.000100
[2025-08-26 05:23:35,520][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031384] [Batch 02170/04869] [00:24:54/00:30:59, 0.689s/it]: train_loss_raw=1.4687, running_loss=1.3960, LR=0.000100
[2025-08-26 05:23:40,662][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031392] [Batch 02178/04869] [00:25:00/00:30:53, 0.689s/it]: train_loss_raw=1.3364, running_loss=1.3934, LR=0.000100
[2025-08-26 05:23:45,836][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031400] [Batch 02186/04869] [00:25:05/00:30:47, 0.689s/it]: train_loss_raw=1.5635, running_loss=1.3913, LR=0.000100
[2025-08-26 05:23:50,999][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031408] [Batch 02194/04869] [00:25:10/00:30:41, 0.688s/it]: train_loss_raw=1.4310, running_loss=1.3931, LR=0.000100
[2025-08-26 05:23:56,153][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031416] [Batch 02202/04869] [00:25:15/00:30:35, 0.688s/it]: train_loss_raw=1.4127, running_loss=1.3950, LR=0.000100
[2025-08-26 05:24:01,589][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031424] [Batch 02210/04869] [00:25:21/00:30:30, 0.688s/it]: train_loss_raw=1.5127, running_loss=1.3971, LR=0.000100
[2025-08-26 05:24:06,709][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031432] [Batch 02218/04869] [00:25:26/00:30:24, 0.688s/it]: train_loss_raw=1.3320, running_loss=1.3947, LR=0.000100
[2025-08-26 05:24:11,945][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031440] [Batch 02226/04869] [00:25:31/00:30:18, 0.688s/it]: train_loss_raw=1.3412, running_loss=1.3941, LR=0.000100
[2025-08-26 05:24:17,153][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031448] [Batch 02234/04869] [00:25:36/00:30:12, 0.688s/it]: train_loss_raw=1.4273, running_loss=1.3972, LR=0.000100
[2025-08-26 05:24:22,330][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031456] [Batch 02242/04869] [00:25:41/00:30:06, 0.688s/it]: train_loss_raw=1.3983, running_loss=1.3979, LR=0.000100
[2025-08-26 05:24:27,684][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031464] [Batch 02250/04869] [00:25:47/00:30:00, 0.688s/it]: train_loss_raw=1.3361, running_loss=1.3968, LR=0.000100
[2025-08-26 05:24:32,858][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031472] [Batch 02258/04869] [00:25:52/00:29:54, 0.687s/it]: train_loss_raw=1.3632, running_loss=1.3951, LR=0.000100
[2025-08-26 05:24:38,024][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031480] [Batch 02266/04869] [00:25:57/00:29:49, 0.687s/it]: train_loss_raw=1.4270, running_loss=1.3954, LR=0.000100
[2025-08-26 05:24:43,222][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031488] [Batch 02274/04869] [00:26:02/00:29:43, 0.687s/it]: train_loss_raw=1.4444, running_loss=1.3995, LR=0.000100
[2025-08-26 05:24:48,615][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031496] [Batch 02282/04869] [00:26:08/00:29:37, 0.687s/it]: train_loss_raw=1.4412, running_loss=1.3981, LR=0.000100
[2025-08-26 05:24:53,831][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031504] [Batch 02290/04869] [00:26:13/00:29:31, 0.687s/it]: train_loss_raw=1.4314, running_loss=1.3982, LR=0.000100
[2025-08-26 05:24:59,030][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031512] [Batch 02298/04869] [00:26:18/00:29:26, 0.687s/it]: train_loss_raw=1.4200, running_loss=1.3976, LR=0.000100
[2025-08-26 05:25:04,392][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031520] [Batch 02306/04869] [00:26:23/00:29:20, 0.687s/it]: train_loss_raw=1.3297, running_loss=1.3975, LR=0.000100
[2025-08-26 05:25:10,363][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031528] [Batch 02314/04869] [00:26:29/00:29:15, 0.687s/it]: train_loss_raw=1.3479, running_loss=1.3983, LR=0.000100
[2025-08-26 05:25:15,749][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031536] [Batch 02322/04869] [00:26:35/00:29:09, 0.687s/it]: train_loss_raw=1.3467, running_loss=1.4003, LR=0.000100
[2025-08-26 05:25:21,330][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031544] [Batch 02330/04869] [00:26:40/00:29:04, 0.687s/it]: train_loss_raw=1.4351, running_loss=1.4026, LR=0.000100
[2025-08-26 05:25:26,494][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031552] [Batch 02338/04869] [00:26:45/00:28:58, 0.687s/it]: train_loss_raw=1.4520, running_loss=1.4033, LR=0.000100
[2025-08-26 05:25:31,826][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031560] [Batch 02346/04869] [00:26:51/00:28:52, 0.687s/it]: train_loss_raw=1.5636, running_loss=1.4043, LR=0.000100
[2025-08-26 05:25:36,975][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031568] [Batch 02354/04869] [00:26:56/00:28:46, 0.687s/it]: train_loss_raw=1.2110, running_loss=1.4026, LR=0.000100
[2025-08-26 05:25:42,119][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031576] [Batch 02362/04869] [00:27:01/00:28:41, 0.687s/it]: train_loss_raw=1.3550, running_loss=1.4018, LR=0.000100
[2025-08-26 05:25:47,364][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031584] [Batch 02370/04869] [00:27:06/00:28:35, 0.686s/it]: train_loss_raw=1.5077, running_loss=1.4039, LR=0.000100
[2025-08-26 05:25:52,836][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031592] [Batch 02378/04869] [00:27:12/00:28:29, 0.686s/it]: train_loss_raw=1.4380, running_loss=1.4028, LR=0.000100
[2025-08-26 05:25:58,012][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031600] [Batch 02386/04869] [00:27:17/00:28:24, 0.686s/it]: train_loss_raw=1.4663, running_loss=1.4048, LR=0.000100
[2025-08-26 05:26:03,257][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031608] [Batch 02394/04869] [00:27:22/00:28:18, 0.686s/it]: train_loss_raw=1.4378, running_loss=1.4084, LR=0.000100
[2025-08-26 05:26:08,410][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031616] [Batch 02402/04869] [00:27:27/00:28:12, 0.686s/it]: train_loss_raw=1.4267, running_loss=1.4080, LR=0.000100
[2025-08-26 05:26:13,579][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031624] [Batch 02410/04869] [00:27:33/00:28:06, 0.686s/it]: train_loss_raw=1.4690, running_loss=1.4107, LR=0.000100
[2025-08-26 05:26:18,738][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031632] [Batch 02418/04869] [00:27:38/00:28:00, 0.686s/it]: train_loss_raw=1.3815, running_loss=1.4118, LR=0.000100
[2025-08-26 05:26:23,906][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031640] [Batch 02426/04869] [00:27:43/00:27:55, 0.686s/it]: train_loss_raw=1.4855, running_loss=1.4128, LR=0.000100
[2025-08-26 05:26:29,062][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031648] [Batch 02434/04869] [00:27:48/00:27:49, 0.686s/it]: train_loss_raw=1.2670, running_loss=1.4106, LR=0.000100
[2025-08-26 05:26:34,470][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031656] [Batch 02442/04869] [00:27:53/00:27:43, 0.685s/it]: train_loss_raw=1.5447, running_loss=1.4105, LR=0.000100
[2025-08-26 05:26:39,631][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031664] [Batch 02450/04869] [00:27:59/00:27:37, 0.685s/it]: train_loss_raw=1.4062, running_loss=1.4114, LR=0.000100
[2025-08-26 05:26:44,789][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031672] [Batch 02458/04869] [00:28:04/00:27:32, 0.685s/it]: train_loss_raw=1.3709, running_loss=1.4107, LR=0.000100
[2025-08-26 05:26:50,126][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031680] [Batch 02466/04869] [00:28:09/00:27:26, 0.685s/it]: train_loss_raw=1.3865, running_loss=1.4112, LR=0.000100
[2025-08-26 05:26:55,434][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031688] [Batch 02474/04869] [00:28:14/00:27:20, 0.685s/it]: train_loss_raw=1.5415, running_loss=1.4116, LR=0.000100
[2025-08-26 05:27:00,608][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031696] [Batch 02482/04869] [00:28:20/00:27:14, 0.685s/it]: train_loss_raw=1.5678, running_loss=1.4105, LR=0.000100
[2025-08-26 05:27:05,771][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031704] [Batch 02490/04869] [00:28:25/00:27:09, 0.685s/it]: train_loss_raw=1.3435, running_loss=1.4087, LR=0.000100
[2025-08-26 05:27:10,939][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031712] [Batch 02498/04869] [00:28:30/00:27:03, 0.685s/it]: train_loss_raw=1.4485, running_loss=1.4097, LR=0.000100
[2025-08-26 05:27:16,108][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031720] [Batch 02506/04869] [00:28:35/00:26:57, 0.685s/it]: train_loss_raw=1.3255, running_loss=1.4054, LR=0.000100
[2025-08-26 05:27:21,287][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031728] [Batch 02514/04869] [00:28:40/00:26:51, 0.684s/it]: train_loss_raw=1.4753, running_loss=1.4073, LR=0.000100
[2025-08-26 05:27:26,464][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031736] [Batch 02522/04869] [00:28:45/00:26:46, 0.684s/it]: train_loss_raw=1.4267, running_loss=1.4062, LR=0.000100
[2025-08-26 05:27:31,890][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031744] [Batch 02530/04869] [00:28:51/00:26:40, 0.684s/it]: train_loss_raw=1.4183, running_loss=1.4038, LR=0.000100
[2025-08-26 05:27:37,381][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031752] [Batch 02538/04869] [00:28:56/00:26:35, 0.684s/it]: train_loss_raw=1.4622, running_loss=1.4039, LR=0.000100
[2025-08-26 05:27:42,973][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031760] [Batch 02546/04869] [00:29:02/00:26:29, 0.684s/it]: train_loss_raw=1.3847, running_loss=1.4040, LR=0.000100
[2025-08-26 05:27:48,159][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031768] [Batch 02554/04869] [00:29:07/00:26:24, 0.684s/it]: train_loss_raw=1.5213, running_loss=1.4061, LR=0.000100
[2025-08-26 05:27:53,559][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031776] [Batch 02562/04869] [00:29:13/00:26:18, 0.684s/it]: train_loss_raw=1.4242, running_loss=1.4078, LR=0.000100
[2025-08-26 05:27:58,720][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031784] [Batch 02570/04869] [00:29:18/00:26:12, 0.684s/it]: train_loss_raw=1.4005, running_loss=1.4093, LR=0.000100
[2025-08-26 05:28:03,899][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031792] [Batch 02578/04869] [00:29:23/00:26:07, 0.684s/it]: train_loss_raw=1.4747, running_loss=1.4083, LR=0.000100
[2025-08-26 05:28:09,149][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031800] [Batch 02586/04869] [00:29:28/00:26:01, 0.684s/it]: train_loss_raw=1.4059, running_loss=1.4055, LR=0.000100
[2025-08-26 05:28:14,278][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031808] [Batch 02594/04869] [00:29:33/00:25:55, 0.684s/it]: train_loss_raw=1.3591, running_loss=1.4039, LR=0.000100
[2025-08-26 05:28:20,008][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031816] [Batch 02602/04869] [00:29:39/00:25:50, 0.684s/it]: train_loss_raw=1.4650, running_loss=1.4041, LR=0.000100
[2025-08-26 05:28:25,670][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031824] [Batch 02610/04869] [00:29:45/00:25:45, 0.684s/it]: train_loss_raw=1.3123, running_loss=1.4071, LR=0.000100
[2025-08-26 05:28:30,842][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031832] [Batch 02618/04869] [00:29:50/00:25:39, 0.684s/it]: train_loss_raw=1.4126, running_loss=1.4055, LR=0.000100
[2025-08-26 05:28:36,003][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031840] [Batch 02626/04869] [00:29:55/00:25:33, 0.684s/it]: train_loss_raw=1.3837, running_loss=1.4052, LR=0.000100
[2025-08-26 05:28:41,564][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031848] [Batch 02634/04869] [00:30:01/00:25:28, 0.684s/it]: train_loss_raw=1.4095, running_loss=1.4055, LR=0.000100
[2025-08-26 05:28:46,729][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031856] [Batch 02642/04869] [00:30:06/00:25:22, 0.684s/it]: train_loss_raw=1.4045, running_loss=1.4050, LR=0.000100
[2025-08-26 05:28:51,875][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031864] [Batch 02650/04869] [00:30:11/00:25:16, 0.684s/it]: train_loss_raw=1.3986, running_loss=1.4049, LR=0.000100
[2025-08-26 05:28:57,054][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031872] [Batch 02658/04869] [00:30:16/00:25:11, 0.683s/it]: train_loss_raw=1.4360, running_loss=1.4059, LR=0.000100
[2025-08-26 05:29:02,227][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031880] [Batch 02666/04869] [00:30:21/00:25:05, 0.683s/it]: train_loss_raw=1.4533, running_loss=1.4058, LR=0.000100
[2025-08-26 05:29:07,370][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031888] [Batch 02674/04869] [00:30:26/00:24:59, 0.683s/it]: train_loss_raw=1.4087, running_loss=1.4089, LR=0.000100
[2025-08-26 05:29:12,489][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031896] [Batch 02682/04869] [00:30:31/00:24:53, 0.683s/it]: train_loss_raw=1.3026, running_loss=1.4077, LR=0.000100
[2025-08-26 05:29:18,347][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031904] [Batch 02690/04869] [00:30:37/00:24:48, 0.683s/it]: train_loss_raw=1.4110, running_loss=1.4096, LR=0.000100
[2025-08-26 05:29:24,062][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031912] [Batch 02698/04869] [00:30:43/00:24:43, 0.683s/it]: train_loss_raw=1.4073, running_loss=1.4069, LR=0.000100
[2025-08-26 05:29:29,488][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031920] [Batch 02706/04869] [00:30:48/00:24:37, 0.683s/it]: train_loss_raw=1.4569, running_loss=1.4089, LR=0.000100
[2025-08-26 05:29:34,983][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031928] [Batch 02714/04869] [00:30:54/00:24:32, 0.683s/it]: train_loss_raw=1.4942, running_loss=1.4042, LR=0.000100
[2025-08-26 05:29:40,148][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031936] [Batch 02722/04869] [00:30:59/00:24:26, 0.683s/it]: train_loss_raw=1.4452, running_loss=1.4052, LR=0.000100
[2025-08-26 05:29:45,453][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031944] [Batch 02730/04869] [00:31:04/00:24:21, 0.683s/it]: train_loss_raw=1.3406, running_loss=1.4042, LR=0.000100
[2025-08-26 05:29:51,254][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031952] [Batch 02738/04869] [00:31:10/00:24:15, 0.683s/it]: train_loss_raw=1.3877, running_loss=1.4044, LR=0.000100
[2025-08-26 05:29:56,738][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031960] [Batch 02746/04869] [00:31:16/00:24:10, 0.683s/it]: train_loss_raw=1.4384, running_loss=1.4035, LR=0.000100
[2025-08-26 05:30:02,189][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031968] [Batch 02754/04869] [00:31:21/00:24:05, 0.683s/it]: train_loss_raw=1.3210, running_loss=1.4031, LR=0.000100
[2025-08-26 05:30:07,787][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031976] [Batch 02762/04869] [00:31:27/00:23:59, 0.683s/it]: train_loss_raw=1.3446, running_loss=1.4045, LR=0.000100
[2025-08-26 05:30:12,919][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031984] [Batch 02770/04869] [00:31:32/00:23:53, 0.683s/it]: train_loss_raw=1.3553, running_loss=1.4015, LR=0.000100
[2025-08-26 05:30:18,478][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 031992] [Batch 02778/04869] [00:31:37/00:23:48, 0.683s/it]: train_loss_raw=1.2320, running_loss=1.3993, LR=0.000100
[2025-08-26 05:30:23,932][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032000] [Batch 02786/04869] [00:31:43/00:23:43, 0.683s/it]: train_loss_raw=1.4796, running_loss=1.4007, LR=0.000100
[2025-08-26 05:30:33,260][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032008] [Batch 02794/04869] [00:31:52/00:23:40, 0.685s/it]: train_loss_raw=1.3840, running_loss=1.4006, LR=0.000100
[2025-08-26 05:30:39,243][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032016] [Batch 02802/04869] [00:31:58/00:23:35, 0.685s/it]: train_loss_raw=1.3605, running_loss=1.4020, LR=0.000100
[2025-08-26 05:30:44,395][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032024] [Batch 02810/04869] [00:32:03/00:23:29, 0.685s/it]: train_loss_raw=1.3470, running_loss=1.4005, LR=0.000100
[2025-08-26 05:30:50,088][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032032] [Batch 02818/04869] [00:32:09/00:23:24, 0.685s/it]: train_loss_raw=1.4484, running_loss=1.4024, LR=0.000100
[2025-08-26 05:30:55,705][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032040] [Batch 02826/04869] [00:32:15/00:23:18, 0.685s/it]: train_loss_raw=1.2895, running_loss=1.4007, LR=0.000100
[2025-08-26 05:31:01,286][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032048] [Batch 02834/04869] [00:32:20/00:23:13, 0.685s/it]: train_loss_raw=1.3747, running_loss=1.4000, LR=0.000100
[2025-08-26 05:31:06,413][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032056] [Batch 02842/04869] [00:32:25/00:23:07, 0.685s/it]: train_loss_raw=1.3732, running_loss=1.3991, LR=0.000100
[2025-08-26 05:31:11,539][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032064] [Batch 02850/04869] [00:32:30/00:23:02, 0.685s/it]: train_loss_raw=1.5137, running_loss=1.3989, LR=0.000100
[2025-08-26 05:31:17,251][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032072] [Batch 02858/04869] [00:32:36/00:22:56, 0.685s/it]: train_loss_raw=1.3659, running_loss=1.4007, LR=0.000100
[2025-08-26 05:31:22,415][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032080] [Batch 02866/04869] [00:32:41/00:22:51, 0.685s/it]: train_loss_raw=1.3781, running_loss=1.4014, LR=0.000100
[2025-08-26 05:31:27,542][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032088] [Batch 02874/04869] [00:32:46/00:22:45, 0.684s/it]: train_loss_raw=1.3782, running_loss=1.3998, LR=0.000100
[2025-08-26 05:31:32,817][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032096] [Batch 02882/04869] [00:32:52/00:22:39, 0.684s/it]: train_loss_raw=1.3956, running_loss=1.4001, LR=0.000100
[2025-08-26 05:31:37,971][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032104] [Batch 02890/04869] [00:32:57/00:22:34, 0.684s/it]: train_loss_raw=1.4012, running_loss=1.4018, LR=0.000100
[2025-08-26 05:31:43,184][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032112] [Batch 02898/04869] [00:33:02/00:22:28, 0.684s/it]: train_loss_raw=1.3383, running_loss=1.3989, LR=0.000100
[2025-08-26 05:31:48,334][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032120] [Batch 02906/04869] [00:33:07/00:22:22, 0.684s/it]: train_loss_raw=1.3831, running_loss=1.3974, LR=0.000100
[2025-08-26 05:31:53,467][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032128] [Batch 02914/04869] [00:33:12/00:22:17, 0.684s/it]: train_loss_raw=1.4630, running_loss=1.3957, LR=0.000100
[2025-08-26 05:31:58,927][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032136] [Batch 02922/04869] [00:33:18/00:22:11, 0.684s/it]: train_loss_raw=1.3697, running_loss=1.3946, LR=0.000100
[2025-08-26 05:32:04,096][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032144] [Batch 02930/04869] [00:33:23/00:22:05, 0.684s/it]: train_loss_raw=1.3895, running_loss=1.3930, LR=0.000100
[2025-08-26 05:32:09,227][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032152] [Batch 02938/04869] [00:33:28/00:22:00, 0.684s/it]: train_loss_raw=1.4965, running_loss=1.3941, LR=0.000100
[2025-08-26 05:32:14,359][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032160] [Batch 02946/04869] [00:33:33/00:21:54, 0.684s/it]: train_loss_raw=1.3618, running_loss=1.3968, LR=0.000100
[2025-08-26 05:32:19,747][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032168] [Batch 02954/04869] [00:33:39/00:21:48, 0.684s/it]: train_loss_raw=1.3971, running_loss=1.3952, LR=0.000100
[2025-08-26 05:32:25,543][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032176] [Batch 02962/04869] [00:33:44/00:21:43, 0.684s/it]: train_loss_raw=1.4230, running_loss=1.3942, LR=0.000100
[2025-08-26 05:32:30,714][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032184] [Batch 02970/04869] [00:33:50/00:21:38, 0.684s/it]: train_loss_raw=1.3837, running_loss=1.3946, LR=0.000100
[2025-08-26 05:32:36,107][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032192] [Batch 02978/04869] [00:33:55/00:21:32, 0.684s/it]: train_loss_raw=1.4135, running_loss=1.3944, LR=0.000100
[2025-08-26 05:32:41,257][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032200] [Batch 02986/04869] [00:34:00/00:21:26, 0.683s/it]: train_loss_raw=1.4345, running_loss=1.3937, LR=0.000100
[2025-08-26 05:32:46,428][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032208] [Batch 02994/04869] [00:34:05/00:21:21, 0.683s/it]: train_loss_raw=1.3474, running_loss=1.3904, LR=0.000100
[2025-08-26 05:32:51,657][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032216] [Batch 03002/04869] [00:34:11/00:21:15, 0.683s/it]: train_loss_raw=1.4523, running_loss=1.3883, LR=0.000100
[2025-08-26 05:32:57,600][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032224] [Batch 03010/04869] [00:34:17/00:21:10, 0.683s/it]: train_loss_raw=1.3102, running_loss=1.3890, LR=0.000100
[2025-08-26 05:33:02,875][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032232] [Batch 03018/04869] [00:34:22/00:21:04, 0.683s/it]: train_loss_raw=1.3797, running_loss=1.3892, LR=0.000100
[2025-08-26 05:33:08,017][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032240] [Batch 03026/04869] [00:34:27/00:20:59, 0.683s/it]: train_loss_raw=1.3947, running_loss=1.3920, LR=0.000100
[2025-08-26 05:33:13,618][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032248] [Batch 03034/04869] [00:34:33/00:20:53, 0.683s/it]: train_loss_raw=1.3908, running_loss=1.3965, LR=0.000100
[2025-08-26 05:33:18,768][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032256] [Batch 03042/04869] [00:34:38/00:20:48, 0.683s/it]: train_loss_raw=1.4416, running_loss=1.3941, LR=0.000100
[2025-08-26 05:33:24,303][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032264] [Batch 03050/04869] [00:34:43/00:20:42, 0.683s/it]: train_loss_raw=1.2707, running_loss=1.3918, LR=0.000100
[2025-08-26 05:33:30,050][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032272] [Batch 03058/04869] [00:34:49/00:20:37, 0.683s/it]: train_loss_raw=1.5096, running_loss=1.3954, LR=0.000100
[2025-08-26 05:33:35,238][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032280] [Batch 03066/04869] [00:34:54/00:20:31, 0.683s/it]: train_loss_raw=1.4736, running_loss=1.3964, LR=0.000100
[2025-08-26 05:33:40,385][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032288] [Batch 03074/04869] [00:34:59/00:20:26, 0.683s/it]: train_loss_raw=1.4194, running_loss=1.3977, LR=0.000100
[2025-08-26 05:33:45,795][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032296] [Batch 03082/04869] [00:35:05/00:20:20, 0.683s/it]: train_loss_raw=1.4461, running_loss=1.3989, LR=0.000100
[2025-08-26 05:33:50,926][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032304] [Batch 03090/04869] [00:35:10/00:20:15, 0.683s/it]: train_loss_raw=1.3980, running_loss=1.3985, LR=0.000100
[2025-08-26 05:33:56,202][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032312] [Batch 03098/04869] [00:35:15/00:20:09, 0.683s/it]: train_loss_raw=1.5189, running_loss=1.3987, LR=0.000100
[2025-08-26 05:34:01,822][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032320] [Batch 03106/04869] [00:35:21/00:20:04, 0.683s/it]: train_loss_raw=1.3583, running_loss=1.3982, LR=0.000100
[2025-08-26 05:34:07,244][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032328] [Batch 03114/04869] [00:35:26/00:19:58, 0.683s/it]: train_loss_raw=1.3980, running_loss=1.3968, LR=0.000100
[2025-08-26 05:34:12,384][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032336] [Batch 03122/04869] [00:35:31/00:19:52, 0.683s/it]: train_loss_raw=1.5227, running_loss=1.3978, LR=0.000100
[2025-08-26 05:34:17,566][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032344] [Batch 03130/04869] [00:35:37/00:19:47, 0.683s/it]: train_loss_raw=1.3410, running_loss=1.3962, LR=0.000100
[2025-08-26 05:34:23,194][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032352] [Batch 03138/04869] [00:35:42/00:19:41, 0.683s/it]: train_loss_raw=1.5109, running_loss=1.3974, LR=0.000100
[2025-08-26 05:34:28,320][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032360] [Batch 03146/04869] [00:35:47/00:19:36, 0.683s/it]: train_loss_raw=1.3488, running_loss=1.3958, LR=0.000100
[2025-08-26 05:34:33,748][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032368] [Batch 03154/04869] [00:35:53/00:19:30, 0.683s/it]: train_loss_raw=1.3540, running_loss=1.3975, LR=0.000100
[2025-08-26 05:34:38,901][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032376] [Batch 03162/04869] [00:35:58/00:19:25, 0.683s/it]: train_loss_raw=1.3558, running_loss=1.3984, LR=0.000100
[2025-08-26 05:34:44,617][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032384] [Batch 03170/04869] [00:36:04/00:19:19, 0.683s/it]: train_loss_raw=1.3669, running_loss=1.3977, LR=0.000100
[2025-08-26 05:34:49,767][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032392] [Batch 03178/04869] [00:36:09/00:19:14, 0.683s/it]: train_loss_raw=1.4881, running_loss=1.4008, LR=0.000100
[2025-08-26 05:34:54,914][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032400] [Batch 03186/04869] [00:36:14/00:19:08, 0.682s/it]: train_loss_raw=1.3397, running_loss=1.3995, LR=0.000100
[2025-08-26 05:35:00,067][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032408] [Batch 03194/04869] [00:36:19/00:19:02, 0.682s/it]: train_loss_raw=1.3543, running_loss=1.4018, LR=0.000100
[2025-08-26 05:35:05,208][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032416] [Batch 03202/04869] [00:36:24/00:18:57, 0.682s/it]: train_loss_raw=1.3596, running_loss=1.4008, LR=0.000100
[2025-08-26 05:35:10,337][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032424] [Batch 03210/04869] [00:36:29/00:18:51, 0.682s/it]: train_loss_raw=1.4411, running_loss=1.4004, LR=0.000100
[2025-08-26 05:35:15,792][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032432] [Batch 03218/04869] [00:36:35/00:18:46, 0.682s/it]: train_loss_raw=1.4215, running_loss=1.4007, LR=0.000100
[2025-08-26 05:35:21,110][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032440] [Batch 03226/04869] [00:36:40/00:18:40, 0.682s/it]: train_loss_raw=1.3645, running_loss=1.4018, LR=0.000100
[2025-08-26 05:35:26,233][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032448] [Batch 03234/04869] [00:36:45/00:18:35, 0.682s/it]: train_loss_raw=1.3357, running_loss=1.3994, LR=0.000100
[2025-08-26 05:35:31,568][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032456] [Batch 03242/04869] [00:36:51/00:18:29, 0.682s/it]: train_loss_raw=1.3768, running_loss=1.4007, LR=0.000100
[2025-08-26 05:35:36,693][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032464] [Batch 03250/04869] [00:36:56/00:18:23, 0.682s/it]: train_loss_raw=1.3224, running_loss=1.3973, LR=0.000100
[2025-08-26 05:35:41,819][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032472] [Batch 03258/04869] [00:37:01/00:18:18, 0.682s/it]: train_loss_raw=1.3212, running_loss=1.3974, LR=0.000100
[2025-08-26 05:35:46,961][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032480] [Batch 03266/04869] [00:37:06/00:18:12, 0.682s/it]: train_loss_raw=1.3632, running_loss=1.3970, LR=0.000100
[2025-08-26 05:35:52,088][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032488] [Batch 03274/04869] [00:37:11/00:18:07, 0.682s/it]: train_loss_raw=1.4326, running_loss=1.3948, LR=0.000100
[2025-08-26 05:35:57,202][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032496] [Batch 03282/04869] [00:37:16/00:18:01, 0.681s/it]: train_loss_raw=1.3353, running_loss=1.3924, LR=0.000100
[2025-08-26 05:36:02,359][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032504] [Batch 03290/04869] [00:37:21/00:17:55, 0.681s/it]: train_loss_raw=1.2911, running_loss=1.3888, LR=0.000100
[2025-08-26 05:36:07,516][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032512] [Batch 03298/04869] [00:37:26/00:17:50, 0.681s/it]: train_loss_raw=1.4530, running_loss=1.3885, LR=0.000100
[2025-08-26 05:36:12,779][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032520] [Batch 03306/04869] [00:37:32/00:17:44, 0.681s/it]: train_loss_raw=1.4038, running_loss=1.3882, LR=0.000100
[2025-08-26 05:36:17,907][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032528] [Batch 03314/04869] [00:37:37/00:17:39, 0.681s/it]: train_loss_raw=1.3484, running_loss=1.3881, LR=0.000100
[2025-08-26 05:36:23,038][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032536] [Batch 03322/04869] [00:37:42/00:17:33, 0.681s/it]: train_loss_raw=1.4565, running_loss=1.3893, LR=0.000100
[2025-08-26 05:36:28,179][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032544] [Batch 03330/04869] [00:37:47/00:17:28, 0.681s/it]: train_loss_raw=1.4299, running_loss=1.3888, LR=0.000100
[2025-08-26 05:36:33,338][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032552] [Batch 03338/04869] [00:37:52/00:17:22, 0.681s/it]: train_loss_raw=1.3977, running_loss=1.3897, LR=0.000100
[2025-08-26 05:36:38,564][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032560] [Batch 03346/04869] [00:37:58/00:17:16, 0.681s/it]: train_loss_raw=1.3648, running_loss=1.3889, LR=0.000100
[2025-08-26 05:36:44,136][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032568] [Batch 03354/04869] [00:38:03/00:17:11, 0.681s/it]: train_loss_raw=1.3727, running_loss=1.3862, LR=0.000100
[2025-08-26 05:36:49,263][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032576] [Batch 03362/04869] [00:38:08/00:17:05, 0.681s/it]: train_loss_raw=1.3871, running_loss=1.3847, LR=0.000100
[2025-08-26 05:36:54,903][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032584] [Batch 03370/04869] [00:38:14/00:17:00, 0.681s/it]: train_loss_raw=1.3991, running_loss=1.3852, LR=0.000100
[2025-08-26 05:37:00,104][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032592] [Batch 03378/04869] [00:38:19/00:16:54, 0.681s/it]: train_loss_raw=1.2974, running_loss=1.3835, LR=0.000100
[2025-08-26 05:37:05,299][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032600] [Batch 03386/04869] [00:38:24/00:16:49, 0.681s/it]: train_loss_raw=1.3362, running_loss=1.3839, LR=0.000100
[2025-08-26 05:37:10,472][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032608] [Batch 03394/04869] [00:38:29/00:16:43, 0.681s/it]: train_loss_raw=1.3754, running_loss=1.3833, LR=0.000100
[2025-08-26 05:37:15,656][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032616] [Batch 03402/04869] [00:38:35/00:16:38, 0.681s/it]: train_loss_raw=1.3689, running_loss=1.3835, LR=0.000100
[2025-08-26 05:37:20,824][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032624] [Batch 03410/04869] [00:38:40/00:16:32, 0.680s/it]: train_loss_raw=1.3979, running_loss=1.3847, LR=0.000100
[2025-08-26 05:37:26,005][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032632] [Batch 03418/04869] [00:38:45/00:16:27, 0.680s/it]: train_loss_raw=1.4552, running_loss=1.3859, LR=0.000100
[2025-08-26 05:37:31,202][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032640] [Batch 03426/04869] [00:38:50/00:16:21, 0.680s/it]: train_loss_raw=1.4583, running_loss=1.3857, LR=0.000100
[2025-08-26 05:37:36,457][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032648] [Batch 03434/04869] [00:38:55/00:16:16, 0.680s/it]: train_loss_raw=1.3819, running_loss=1.3862, LR=0.000100
[2025-08-26 05:37:42,106][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032656] [Batch 03442/04869] [00:39:01/00:16:10, 0.680s/it]: train_loss_raw=1.3675, running_loss=1.3851, LR=0.000100
[2025-08-26 05:37:47,252][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032664] [Batch 03450/04869] [00:39:06/00:16:05, 0.680s/it]: train_loss_raw=1.4615, running_loss=1.3871, LR=0.000100
[2025-08-26 05:37:52,378][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032672] [Batch 03458/04869] [00:39:11/00:15:59, 0.680s/it]: train_loss_raw=1.3802, running_loss=1.3850, LR=0.000100
[2025-08-26 05:37:57,822][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032680] [Batch 03466/04869] [00:39:17/00:15:54, 0.680s/it]: train_loss_raw=1.2948, running_loss=1.3833, LR=0.000100
[2025-08-26 05:38:02,992][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032688] [Batch 03474/04869] [00:39:22/00:15:48, 0.680s/it]: train_loss_raw=1.4028, running_loss=1.3852, LR=0.000100
[2025-08-26 05:38:08,430][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032696] [Batch 03482/04869] [00:39:27/00:15:43, 0.680s/it]: train_loss_raw=1.3758, running_loss=1.3864, LR=0.000100
[2025-08-26 05:38:13,565][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032704] [Batch 03490/04869] [00:39:33/00:15:37, 0.680s/it]: train_loss_raw=1.3264, running_loss=1.3859, LR=0.000100
[2025-08-26 05:38:18,695][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032712] [Batch 03498/04869] [00:39:38/00:15:32, 0.680s/it]: train_loss_raw=1.3372, running_loss=1.3885, LR=0.000100
[2025-08-26 05:38:23,837][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032720] [Batch 03506/04869] [00:39:43/00:15:26, 0.680s/it]: train_loss_raw=1.2984, running_loss=1.3856, LR=0.000100
[2025-08-26 05:38:29,018][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032728] [Batch 03514/04869] [00:39:48/00:15:20, 0.680s/it]: train_loss_raw=1.3192, running_loss=1.3863, LR=0.000100
[2025-08-26 05:38:34,277][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032736] [Batch 03522/04869] [00:39:53/00:15:15, 0.680s/it]: train_loss_raw=1.4129, running_loss=1.3868, LR=0.000100
[2025-08-26 05:38:39,494][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032744] [Batch 03530/04869] [00:39:58/00:15:09, 0.680s/it]: train_loss_raw=1.4978, running_loss=1.3854, LR=0.000100
[2025-08-26 05:38:44,630][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032752] [Batch 03538/04869] [00:40:04/00:15:04, 0.680s/it]: train_loss_raw=1.4168, running_loss=1.3873, LR=0.000100
[2025-08-26 05:38:49,764][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032760] [Batch 03546/04869] [00:40:09/00:14:58, 0.679s/it]: train_loss_raw=1.3893, running_loss=1.3864, LR=0.000100
[2025-08-26 05:38:54,913][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032768] [Batch 03554/04869] [00:40:14/00:14:53, 0.679s/it]: train_loss_raw=1.3942, running_loss=1.3873, LR=0.000100
[2025-08-26 05:39:00,037][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032776] [Batch 03562/04869] [00:40:19/00:14:47, 0.679s/it]: train_loss_raw=1.3892, running_loss=1.3888, LR=0.000100
[2025-08-26 05:39:05,189][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032784] [Batch 03570/04869] [00:40:24/00:14:42, 0.679s/it]: train_loss_raw=1.4362, running_loss=1.3909, LR=0.000100
[2025-08-26 05:39:10,308][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032792] [Batch 03578/04869] [00:40:29/00:14:36, 0.679s/it]: train_loss_raw=1.3637, running_loss=1.3877, LR=0.000100
[2025-08-26 05:39:15,441][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032800] [Batch 03586/04869] [00:40:34/00:14:31, 0.679s/it]: train_loss_raw=1.4057, running_loss=1.3912, LR=0.000100
[2025-08-26 05:39:20,579][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032808] [Batch 03594/04869] [00:40:40/00:14:25, 0.679s/it]: train_loss_raw=1.3879, running_loss=1.3952, LR=0.000100
[2025-08-26 05:39:25,693][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032816] [Batch 03602/04869] [00:40:45/00:14:20, 0.679s/it]: train_loss_raw=1.3061, running_loss=1.3925, LR=0.000100
[2025-08-26 05:39:30,848][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032824] [Batch 03610/04869] [00:40:50/00:14:14, 0.679s/it]: train_loss_raw=1.4325, running_loss=1.3926, LR=0.000100
[2025-08-26 05:39:36,081][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032832] [Batch 03618/04869] [00:40:55/00:14:09, 0.679s/it]: train_loss_raw=1.4346, running_loss=1.3933, LR=0.000100
[2025-08-26 05:39:41,210][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032840] [Batch 03626/04869] [00:41:00/00:14:03, 0.679s/it]: train_loss_raw=1.3948, running_loss=1.3927, LR=0.000100
[2025-08-26 05:39:46,337][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032848] [Batch 03634/04869] [00:41:05/00:13:57, 0.679s/it]: train_loss_raw=1.4326, running_loss=1.3917, LR=0.000100
[2025-08-26 05:39:51,463][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032856] [Batch 03642/04869] [00:41:10/00:13:52, 0.678s/it]: train_loss_raw=1.4018, running_loss=1.3904, LR=0.000100
[2025-08-26 05:39:56,603][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032864] [Batch 03650/04869] [00:41:16/00:13:46, 0.678s/it]: train_loss_raw=1.4487, running_loss=1.3903, LR=0.000100
[2025-08-26 05:40:02,051][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032872] [Batch 03658/04869] [00:41:21/00:13:41, 0.678s/it]: train_loss_raw=1.4341, running_loss=1.3903, LR=0.000100
[2025-08-26 05:40:07,177][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032880] [Batch 03666/04869] [00:41:26/00:13:35, 0.678s/it]: train_loss_raw=1.3633, running_loss=1.3871, LR=0.000100
[2025-08-26 05:40:12,551][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032888] [Batch 03674/04869] [00:41:32/00:13:30, 0.678s/it]: train_loss_raw=1.2886, running_loss=1.3851, LR=0.000100
[2025-08-26 05:40:17,704][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032896] [Batch 03682/04869] [00:41:37/00:13:25, 0.678s/it]: train_loss_raw=1.3203, running_loss=1.3823, LR=0.000100
[2025-08-26 05:40:22,832][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032904] [Batch 03690/04869] [00:41:42/00:13:19, 0.678s/it]: train_loss_raw=1.3226, running_loss=1.3819, LR=0.000100
[2025-08-26 05:40:27,959][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032912] [Batch 03698/04869] [00:41:47/00:13:13, 0.678s/it]: train_loss_raw=1.4793, running_loss=1.3827, LR=0.000100
[2025-08-26 05:40:33,079][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032920] [Batch 03706/04869] [00:41:52/00:13:08, 0.678s/it]: train_loss_raw=1.3445, running_loss=1.3824, LR=0.000100
[2025-08-26 05:40:38,221][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032928] [Batch 03714/04869] [00:41:57/00:13:02, 0.678s/it]: train_loss_raw=1.3914, running_loss=1.3844, LR=0.000100
[2025-08-26 05:40:44,043][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032936] [Batch 03722/04869] [00:42:03/00:12:57, 0.678s/it]: train_loss_raw=1.2528, running_loss=1.3834, LR=0.000100
[2025-08-26 05:40:49,206][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032944] [Batch 03730/04869] [00:42:08/00:12:52, 0.678s/it]: train_loss_raw=1.4248, running_loss=1.3852, LR=0.000100
[2025-08-26 05:40:54,500][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032952] [Batch 03738/04869] [00:42:13/00:12:46, 0.678s/it]: train_loss_raw=1.3908, running_loss=1.3866, LR=0.000100
[2025-08-26 05:40:59,732][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032960] [Batch 03746/04869] [00:42:19/00:12:41, 0.678s/it]: train_loss_raw=1.3678, running_loss=1.3851, LR=0.000100
[2025-08-26 05:41:05,201][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032968] [Batch 03754/04869] [00:42:24/00:12:35, 0.678s/it]: train_loss_raw=1.5072, running_loss=1.3864, LR=0.000100
[2025-08-26 05:41:10,403][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032976] [Batch 03762/04869] [00:42:29/00:12:30, 0.678s/it]: train_loss_raw=1.4887, running_loss=1.3893, LR=0.000100
[2025-08-26 05:41:15,547][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032984] [Batch 03770/04869] [00:42:35/00:12:24, 0.678s/it]: train_loss_raw=1.3607, running_loss=1.3893, LR=0.000100
[2025-08-26 05:41:20,675][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 032992] [Batch 03778/04869] [00:42:40/00:12:19, 0.678s/it]: train_loss_raw=1.3597, running_loss=1.3883, LR=0.000100
[2025-08-26 05:41:25,813][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033000] [Batch 03786/04869] [00:42:45/00:12:13, 0.678s/it]: train_loss_raw=1.4939, running_loss=1.3882, LR=0.000100
[2025-08-26 05:41:30,946][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033008] [Batch 03794/04869] [00:42:50/00:12:08, 0.677s/it]: train_loss_raw=1.3184, running_loss=1.3872, LR=0.000100
[2025-08-26 05:41:36,082][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033016] [Batch 03802/04869] [00:42:55/00:12:02, 0.677s/it]: train_loss_raw=1.3646, running_loss=1.3845, LR=0.000100
[2025-08-26 05:41:41,231][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033024] [Batch 03810/04869] [00:43:00/00:11:57, 0.677s/it]: train_loss_raw=1.3966, running_loss=1.3869, LR=0.000100
[2025-08-26 05:41:46,385][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033032] [Batch 03818/04869] [00:43:05/00:11:51, 0.677s/it]: train_loss_raw=1.3048, running_loss=1.3853, LR=0.000100
[2025-08-26 05:41:52,056][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033040] [Batch 03826/04869] [00:43:11/00:11:46, 0.677s/it]: train_loss_raw=1.4390, running_loss=1.3859, LR=0.000100
[2025-08-26 05:41:57,205][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033048] [Batch 03834/04869] [00:43:16/00:11:40, 0.677s/it]: train_loss_raw=1.4001, running_loss=1.3859, LR=0.000100
[2025-08-26 05:42:02,342][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033056] [Batch 03842/04869] [00:43:21/00:11:35, 0.677s/it]: train_loss_raw=1.4604, running_loss=1.3864, LR=0.000100
[2025-08-26 05:42:07,472][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033064] [Batch 03850/04869] [00:43:26/00:11:29, 0.677s/it]: train_loss_raw=1.5751, running_loss=1.3911, LR=0.000100
[2025-08-26 05:42:12,615][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033072] [Batch 03858/04869] [00:43:32/00:11:24, 0.677s/it]: train_loss_raw=1.2484, running_loss=1.3907, LR=0.000100
[2025-08-26 05:42:17,770][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033080] [Batch 03866/04869] [00:43:37/00:11:19, 0.677s/it]: train_loss_raw=1.3170, running_loss=1.3908, LR=0.000100
[2025-08-26 05:42:23,562][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033088] [Batch 03874/04869] [00:43:43/00:11:13, 0.677s/it]: train_loss_raw=1.4004, running_loss=1.3922, LR=0.000100
[2025-08-26 05:42:28,690][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033096] [Batch 03882/04869] [00:43:48/00:11:08, 0.677s/it]: train_loss_raw=1.4481, running_loss=1.3911, LR=0.000100
[2025-08-26 05:42:34,023][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033104] [Batch 03890/04869] [00:43:53/00:11:02, 0.677s/it]: train_loss_raw=1.4118, running_loss=1.3891, LR=0.000100
[2025-08-26 05:42:39,307][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033112] [Batch 03898/04869] [00:43:58/00:10:57, 0.677s/it]: train_loss_raw=1.3275, running_loss=1.3883, LR=0.000100
[2025-08-26 05:42:44,447][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033120] [Batch 03906/04869] [00:44:03/00:10:51, 0.677s/it]: train_loss_raw=1.3663, running_loss=1.3899, LR=0.000100
[2025-08-26 05:42:49,592][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033128] [Batch 03914/04869] [00:44:09/00:10:46, 0.677s/it]: train_loss_raw=1.5284, running_loss=1.3884, LR=0.000100
[2025-08-26 05:42:54,721][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033136] [Batch 03922/04869] [00:44:14/00:10:40, 0.677s/it]: train_loss_raw=1.3773, running_loss=1.3881, LR=0.000100
[2025-08-26 05:42:59,839][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033144] [Batch 03930/04869] [00:44:19/00:10:35, 0.677s/it]: train_loss_raw=1.3627, running_loss=1.3861, LR=0.000100
[2025-08-26 05:43:04,970][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033152] [Batch 03938/04869] [00:44:24/00:10:29, 0.677s/it]: train_loss_raw=1.4099, running_loss=1.3863, LR=0.000100
[2025-08-26 05:43:10,105][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033160] [Batch 03946/04869] [00:44:29/00:10:24, 0.677s/it]: train_loss_raw=1.3217, running_loss=1.3875, LR=0.000100
[2025-08-26 05:43:15,229][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033168] [Batch 03954/04869] [00:44:34/00:10:18, 0.676s/it]: train_loss_raw=1.3833, running_loss=1.3870, LR=0.000100
[2025-08-26 05:43:20,377][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033176] [Batch 03962/04869] [00:44:39/00:10:13, 0.676s/it]: train_loss_raw=1.3414, running_loss=1.3854, LR=0.000100
[2025-08-26 05:43:25,504][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033184] [Batch 03970/04869] [00:44:44/00:10:08, 0.676s/it]: train_loss_raw=1.3682, running_loss=1.3816, LR=0.000100
[2025-08-26 05:43:30,630][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033192] [Batch 03978/04869] [00:44:50/00:10:02, 0.676s/it]: train_loss_raw=1.5101, running_loss=1.3807, LR=0.000100
[2025-08-26 05:43:35,761][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033200] [Batch 03986/04869] [00:44:55/00:09:57, 0.676s/it]: train_loss_raw=1.4415, running_loss=1.3811, LR=0.000100
[2025-08-26 05:43:40,906][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033208] [Batch 03994/04869] [00:45:00/00:09:51, 0.676s/it]: train_loss_raw=1.4868, running_loss=1.3803, LR=0.000100
[2025-08-26 05:43:46,041][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033216] [Batch 04002/04869] [00:45:05/00:09:46, 0.676s/it]: train_loss_raw=1.3637, running_loss=1.3776, LR=0.000100
[2025-08-26 05:43:51,496][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033224] [Batch 04010/04869] [00:45:10/00:09:40, 0.676s/it]: train_loss_raw=1.3664, running_loss=1.3792, LR=0.000100
[2025-08-26 05:43:56,823][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033232] [Batch 04018/04869] [00:45:16/00:09:35, 0.676s/it]: train_loss_raw=1.3358, running_loss=1.3798, LR=0.000100
[2025-08-26 05:44:02,045][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033240] [Batch 04026/04869] [00:45:21/00:09:29, 0.676s/it]: train_loss_raw=1.1974, running_loss=1.3751, LR=0.000100
[2025-08-26 05:44:07,797][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033248] [Batch 04034/04869] [00:45:27/00:09:24, 0.676s/it]: train_loss_raw=1.3614, running_loss=1.3735, LR=0.000100
[2025-08-26 05:44:13,099][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033256] [Batch 04042/04869] [00:45:32/00:09:19, 0.676s/it]: train_loss_raw=1.4275, running_loss=1.3764, LR=0.000100
[2025-08-26 05:44:19,108][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033264] [Batch 04050/04869] [00:45:38/00:09:13, 0.676s/it]: train_loss_raw=1.3203, running_loss=1.3745, LR=0.000100
[2025-08-26 05:44:24,251][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033272] [Batch 04058/04869] [00:45:43/00:09:08, 0.676s/it]: train_loss_raw=1.3910, running_loss=1.3748, LR=0.000100
[2025-08-26 05:44:29,389][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033280] [Batch 04066/04869] [00:45:48/00:09:02, 0.676s/it]: train_loss_raw=1.3451, running_loss=1.3750, LR=0.000100
[2025-08-26 05:44:34,525][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033288] [Batch 04074/04869] [00:45:53/00:08:57, 0.676s/it]: train_loss_raw=1.4405, running_loss=1.3730, LR=0.000100
[2025-08-26 05:44:39,657][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033296] [Batch 04082/04869] [00:45:59/00:08:51, 0.676s/it]: train_loss_raw=1.4042, running_loss=1.3737, LR=0.000100
[2025-08-26 05:44:44,795][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033304] [Batch 04090/04869] [00:46:04/00:08:46, 0.676s/it]: train_loss_raw=1.4014, running_loss=1.3744, LR=0.000100
[2025-08-26 05:44:49,928][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033312] [Batch 04098/04869] [00:46:09/00:08:41, 0.676s/it]: train_loss_raw=1.3487, running_loss=1.3746, LR=0.000100
[2025-08-26 05:44:55,062][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033320] [Batch 04106/04869] [00:46:14/00:08:35, 0.676s/it]: train_loss_raw=1.3684, running_loss=1.3751, LR=0.000100
[2025-08-26 05:45:00,850][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033328] [Batch 04114/04869] [00:46:20/00:08:30, 0.676s/it]: train_loss_raw=1.3763, running_loss=1.3756, LR=0.000100
[2025-08-26 05:45:06,004][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033336] [Batch 04122/04869] [00:46:25/00:08:24, 0.676s/it]: train_loss_raw=1.3326, running_loss=1.3749, LR=0.000100
[2025-08-26 05:45:11,701][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033344] [Batch 04130/04869] [00:46:31/00:08:19, 0.676s/it]: train_loss_raw=1.3090, running_loss=1.3750, LR=0.000100
[2025-08-26 05:45:16,843][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033352] [Batch 04138/04869] [00:46:36/00:08:13, 0.676s/it]: train_loss_raw=1.4210, running_loss=1.3744, LR=0.000100
[2025-08-26 05:45:22,122][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033360] [Batch 04146/04869] [00:46:41/00:08:08, 0.676s/it]: train_loss_raw=1.3510, running_loss=1.3777, LR=0.000100
[2025-08-26 05:45:27,266][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033368] [Batch 04154/04869] [00:46:46/00:08:03, 0.676s/it]: train_loss_raw=1.3612, running_loss=1.3776, LR=0.000100
[2025-08-26 05:45:32,901][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033376] [Batch 04162/04869] [00:46:52/00:07:57, 0.676s/it]: train_loss_raw=1.2151, running_loss=1.3765, LR=0.000100
[2025-08-26 05:45:38,248][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033384] [Batch 04170/04869] [00:46:57/00:07:52, 0.676s/it]: train_loss_raw=1.3669, running_loss=1.3743, LR=0.000100
[2025-08-26 05:45:43,676][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033392] [Batch 04178/04869] [00:47:03/00:07:46, 0.676s/it]: train_loss_raw=1.3676, running_loss=1.3771, LR=0.000100
[2025-08-26 05:45:48,891][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033400] [Batch 04186/04869] [00:47:08/00:07:41, 0.676s/it]: train_loss_raw=1.4268, running_loss=1.3792, LR=0.000100
[2025-08-26 05:45:54,115][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033408] [Batch 04194/04869] [00:47:13/00:07:36, 0.676s/it]: train_loss_raw=1.3157, running_loss=1.3787, LR=0.000100
[2025-08-26 05:45:59,864][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033416] [Batch 04202/04869] [00:47:19/00:07:30, 0.676s/it]: train_loss_raw=1.3880, running_loss=1.3794, LR=0.000100
[2025-08-26 05:46:05,131][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033424] [Batch 04210/04869] [00:47:24/00:07:25, 0.676s/it]: train_loss_raw=1.4611, running_loss=1.3818, LR=0.000100
[2025-08-26 05:46:10,281][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033432] [Batch 04218/04869] [00:47:29/00:07:19, 0.676s/it]: train_loss_raw=1.3680, running_loss=1.3816, LR=0.000100
[2025-08-26 05:46:15,942][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033440] [Batch 04226/04869] [00:47:35/00:07:14, 0.676s/it]: train_loss_raw=1.4404, running_loss=1.3823, LR=0.000100
[2025-08-26 05:46:21,126][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033448] [Batch 04234/04869] [00:47:40/00:07:09, 0.676s/it]: train_loss_raw=1.4847, running_loss=1.3823, LR=0.000100
[2025-08-26 05:46:26,252][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033456] [Batch 04242/04869] [00:47:45/00:07:03, 0.676s/it]: train_loss_raw=1.3214, running_loss=1.3788, LR=0.000100
[2025-08-26 05:46:31,486][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033464] [Batch 04250/04869] [00:47:50/00:06:58, 0.676s/it]: train_loss_raw=1.3650, running_loss=1.3773, LR=0.000100
[2025-08-26 05:46:36,916][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033472] [Batch 04258/04869] [00:47:56/00:06:52, 0.676s/it]: train_loss_raw=1.5013, running_loss=1.3808, LR=0.000100
[2025-08-26 05:46:42,482][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033480] [Batch 04266/04869] [00:48:01/00:06:47, 0.676s/it]: train_loss_raw=1.3383, running_loss=1.3789, LR=0.000100
[2025-08-26 05:46:47,881][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033488] [Batch 04274/04869] [00:48:07/00:06:41, 0.676s/it]: train_loss_raw=1.3768, running_loss=1.3772, LR=0.000100
[2025-08-26 05:46:53,014][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033496] [Batch 04282/04869] [00:48:12/00:06:36, 0.675s/it]: train_loss_raw=1.4088, running_loss=1.3785, LR=0.000100
[2025-08-26 05:46:58,432][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033504] [Batch 04290/04869] [00:48:17/00:06:31, 0.675s/it]: train_loss_raw=1.3374, running_loss=1.3798, LR=0.000100
[2025-08-26 05:47:04,038][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033512] [Batch 04298/04869] [00:48:23/00:06:25, 0.676s/it]: train_loss_raw=1.3539, running_loss=1.3778, LR=0.000100
[2025-08-26 05:47:09,193][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033520] [Batch 04306/04869] [00:48:28/00:06:20, 0.675s/it]: train_loss_raw=1.3838, running_loss=1.3788, LR=0.000100
[2025-08-26 05:47:14,562][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033528] [Batch 04314/04869] [00:48:34/00:06:14, 0.675s/it]: train_loss_raw=1.3584, running_loss=1.3753, LR=0.000100
[2025-08-26 05:47:19,976][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033536] [Batch 04322/04869] [00:48:39/00:06:09, 0.675s/it]: train_loss_raw=1.4506, running_loss=1.3719, LR=0.000100
[2025-08-26 05:47:25,102][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033544] [Batch 04330/04869] [00:48:44/00:06:04, 0.675s/it]: train_loss_raw=1.3679, running_loss=1.3735, LR=0.000100
[2025-08-26 05:47:30,231][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033552] [Batch 04338/04869] [00:48:49/00:05:58, 0.675s/it]: train_loss_raw=1.4093, running_loss=1.3749, LR=0.000100
[2025-08-26 05:47:35,567][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033560] [Batch 04346/04869] [00:48:55/00:05:53, 0.675s/it]: train_loss_raw=1.3614, running_loss=1.3746, LR=0.000100
[2025-08-26 05:47:40,969][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033568] [Batch 04354/04869] [00:49:00/00:05:47, 0.675s/it]: train_loss_raw=1.3373, running_loss=1.3722, LR=0.000100
[2025-08-26 05:47:46,132][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033576] [Batch 04362/04869] [00:49:05/00:05:42, 0.675s/it]: train_loss_raw=1.4084, running_loss=1.3731, LR=0.000100
[2025-08-26 05:47:51,719][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033584] [Batch 04370/04869] [00:49:11/00:05:36, 0.675s/it]: train_loss_raw=1.3996, running_loss=1.3739, LR=0.000100
[2025-08-26 05:47:56,887][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033592] [Batch 04378/04869] [00:49:16/00:05:31, 0.675s/it]: train_loss_raw=1.3760, running_loss=1.3724, LR=0.000100
[2025-08-26 05:48:02,081][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033600] [Batch 04386/04869] [00:49:21/00:05:26, 0.675s/it]: train_loss_raw=1.4404, running_loss=1.3740, LR=0.000100
[2025-08-26 05:48:07,262][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033608] [Batch 04394/04869] [00:49:26/00:05:20, 0.675s/it]: train_loss_raw=1.3395, running_loss=1.3726, LR=0.000100
[2025-08-26 05:48:12,540][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033616] [Batch 04402/04869] [00:49:31/00:05:15, 0.675s/it]: train_loss_raw=1.3642, running_loss=1.3731, LR=0.000100
[2025-08-26 05:48:17,877][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033624] [Batch 04410/04869] [00:49:37/00:05:09, 0.675s/it]: train_loss_raw=1.3883, running_loss=1.3732, LR=0.000100
[2025-08-26 05:48:23,054][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033632] [Batch 04418/04869] [00:49:42/00:05:04, 0.675s/it]: train_loss_raw=1.3106, running_loss=1.3737, LR=0.000100
[2025-08-26 05:48:28,787][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033640] [Batch 04426/04869] [00:49:48/00:04:59, 0.675s/it]: train_loss_raw=1.4097, running_loss=1.3714, LR=0.000100
[2025-08-26 05:48:34,862][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033648] [Batch 04434/04869] [00:49:54/00:04:53, 0.675s/it]: train_loss_raw=1.4123, running_loss=1.3706, LR=0.000100
[2025-08-26 05:48:41,135][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033656] [Batch 04442/04869] [00:50:00/00:04:48, 0.676s/it]: train_loss_raw=1.3487, running_loss=1.3676, LR=0.000100
[2025-08-26 05:48:47,315][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033664] [Batch 04450/04869] [00:50:06/00:04:43, 0.676s/it]: train_loss_raw=1.4313, running_loss=1.3705, LR=0.000100
[2025-08-26 05:48:52,767][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033672] [Batch 04458/04869] [00:50:12/00:04:37, 0.676s/it]: train_loss_raw=1.3006, running_loss=1.3696, LR=0.000100
[2025-08-26 05:48:57,905][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033680] [Batch 04466/04869] [00:50:17/00:04:32, 0.676s/it]: train_loss_raw=1.4343, running_loss=1.3707, LR=0.000100
[2025-08-26 05:49:03,683][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033688] [Batch 04474/04869] [00:50:23/00:04:26, 0.676s/it]: train_loss_raw=1.3547, running_loss=1.3713, LR=0.000100
[2025-08-26 05:49:08,992][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033696] [Batch 04482/04869] [00:50:28/00:04:21, 0.676s/it]: train_loss_raw=1.3867, running_loss=1.3694, LR=0.000100
[2025-08-26 05:49:14,150][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033704] [Batch 04490/04869] [00:50:33/00:04:16, 0.676s/it]: train_loss_raw=1.4186, running_loss=1.3687, LR=0.000100
[2025-08-26 05:49:19,312][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033712] [Batch 04498/04869] [00:50:38/00:04:10, 0.676s/it]: train_loss_raw=1.4942, running_loss=1.3712, LR=0.000100
[2025-08-26 05:49:24,775][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033720] [Batch 04506/04869] [00:50:44/00:04:05, 0.676s/it]: train_loss_raw=1.3556, running_loss=1.3715, LR=0.000100
[2025-08-26 05:49:30,229][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033728] [Batch 04514/04869] [00:50:49/00:03:59, 0.676s/it]: train_loss_raw=1.4932, running_loss=1.3737, LR=0.000100
[2025-08-26 05:49:35,394][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033736] [Batch 04522/04869] [00:50:54/00:03:54, 0.676s/it]: train_loss_raw=1.4073, running_loss=1.3746, LR=0.000100
[2025-08-26 05:49:40,539][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033744] [Batch 04530/04869] [00:50:59/00:03:48, 0.675s/it]: train_loss_raw=1.4413, running_loss=1.3763, LR=0.000100
[2025-08-26 05:49:45,780][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033752] [Batch 04538/04869] [00:51:05/00:03:43, 0.675s/it]: train_loss_raw=1.3883, running_loss=1.3756, LR=0.000100
[2025-08-26 05:49:50,979][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033760] [Batch 04546/04869] [00:51:10/00:03:38, 0.675s/it]: train_loss_raw=1.2310, running_loss=1.3700, LR=0.000100
[2025-08-26 05:49:56,234][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033768] [Batch 04554/04869] [00:51:15/00:03:32, 0.675s/it]: train_loss_raw=1.4191, running_loss=1.3730, LR=0.000100
[2025-08-26 05:50:01,475][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033776] [Batch 04562/04869] [00:51:20/00:03:27, 0.675s/it]: train_loss_raw=1.4116, running_loss=1.3757, LR=0.000100
[2025-08-26 05:50:07,236][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033784] [Batch 04570/04869] [00:51:26/00:03:21, 0.675s/it]: train_loss_raw=1.3397, running_loss=1.3712, LR=0.000100
[2025-08-26 05:50:12,508][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033792] [Batch 04578/04869] [00:51:31/00:03:16, 0.675s/it]: train_loss_raw=1.3370, running_loss=1.3706, LR=0.000100
[2025-08-26 05:50:17,646][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033800] [Batch 04586/04869] [00:51:37/00:03:11, 0.675s/it]: train_loss_raw=1.2991, running_loss=1.3683, LR=0.000100
[2025-08-26 05:50:22,775][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033808] [Batch 04594/04869] [00:51:42/00:03:05, 0.675s/it]: train_loss_raw=1.3378, running_loss=1.3668, LR=0.000100
[2025-08-26 05:50:27,899][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033816] [Batch 04602/04869] [00:51:47/00:03:00, 0.675s/it]: train_loss_raw=1.3840, running_loss=1.3666, LR=0.000100
[2025-08-26 05:50:33,025][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033824] [Batch 04610/04869] [00:51:52/00:02:54, 0.675s/it]: train_loss_raw=1.3868, running_loss=1.3658, LR=0.000100
[2025-08-26 05:50:38,163][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033832] [Batch 04618/04869] [00:51:57/00:02:49, 0.675s/it]: train_loss_raw=1.4373, running_loss=1.3690, LR=0.000100
[2025-08-26 05:50:43,277][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033840] [Batch 04626/04869] [00:52:02/00:02:44, 0.675s/it]: train_loss_raw=1.3326, running_loss=1.3675, LR=0.000100
[2025-08-26 05:50:48,432][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033848] [Batch 04634/04869] [00:52:07/00:02:38, 0.675s/it]: train_loss_raw=1.3428, running_loss=1.3682, LR=0.000100
[2025-08-26 05:50:54,036][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033856] [Batch 04642/04869] [00:52:13/00:02:33, 0.675s/it]: train_loss_raw=1.3276, running_loss=1.3676, LR=0.000100
[2025-08-26 05:50:59,421][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033864] [Batch 04650/04869] [00:52:18/00:02:27, 0.675s/it]: train_loss_raw=1.4543, running_loss=1.3675, LR=0.000100
[2025-08-26 05:51:04,557][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033872] [Batch 04658/04869] [00:52:24/00:02:22, 0.675s/it]: train_loss_raw=1.3913, running_loss=1.3666, LR=0.000100
[2025-08-26 05:51:09,679][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033880] [Batch 04666/04869] [00:52:29/00:02:17, 0.675s/it]: train_loss_raw=1.3062, running_loss=1.3651, LR=0.000100
[2025-08-26 05:51:15,211][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033888] [Batch 04674/04869] [00:52:34/00:02:11, 0.675s/it]: train_loss_raw=1.3599, running_loss=1.3647, LR=0.000100
[2025-08-26 05:51:20,670][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033896] [Batch 04682/04869] [00:52:40/00:02:06, 0.675s/it]: train_loss_raw=1.3760, running_loss=1.3664, LR=0.000100
[2025-08-26 05:51:26,681][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033904] [Batch 04690/04869] [00:52:46/00:02:00, 0.675s/it]: train_loss_raw=1.3341, running_loss=1.3683, LR=0.000100
[2025-08-26 05:51:31,838][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033912] [Batch 04698/04869] [00:52:51/00:01:55, 0.675s/it]: train_loss_raw=1.3441, running_loss=1.3679, LR=0.000100
[2025-08-26 05:51:37,318][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033920] [Batch 04706/04869] [00:52:56/00:01:50, 0.675s/it]: train_loss_raw=1.3280, running_loss=1.3683, LR=0.000100
[2025-08-26 05:51:42,473][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033928] [Batch 04714/04869] [00:53:01/00:01:44, 0.675s/it]: train_loss_raw=1.4391, running_loss=1.3699, LR=0.000100
[2025-08-26 05:51:48,069][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033936] [Batch 04722/04869] [00:53:07/00:01:39, 0.675s/it]: train_loss_raw=1.4391, running_loss=1.3700, LR=0.000100
[2025-08-26 05:51:53,252][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033944] [Batch 04730/04869] [00:53:12/00:01:33, 0.675s/it]: train_loss_raw=1.3847, running_loss=1.3702, LR=0.000100
[2025-08-26 05:51:59,148][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033952] [Batch 04738/04869] [00:53:18/00:01:28, 0.675s/it]: train_loss_raw=1.4586, running_loss=1.3716, LR=0.000100
[2025-08-26 05:52:04,743][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033960] [Batch 04746/04869] [00:53:24/00:01:23, 0.675s/it]: train_loss_raw=1.3111, running_loss=1.3705, LR=0.000100
[2025-08-26 05:52:09,932][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033968] [Batch 04754/04869] [00:53:29/00:01:17, 0.675s/it]: train_loss_raw=1.3432, running_loss=1.3709, LR=0.000100
[2025-08-26 05:52:15,137][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033976] [Batch 04762/04869] [00:53:34/00:01:12, 0.675s/it]: train_loss_raw=1.2722, running_loss=1.3689, LR=0.000100
[2025-08-26 05:52:20,557][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033984] [Batch 04770/04869] [00:53:40/00:01:06, 0.675s/it]: train_loss_raw=1.4036, running_loss=1.3686, LR=0.000100
[2025-08-26 05:52:25,743][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 033992] [Batch 04778/04869] [00:53:45/00:01:01, 0.675s/it]: train_loss_raw=1.3433, running_loss=1.3683, LR=0.000100
[2025-08-26 05:52:30,960][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034000] [Batch 04786/04869] [00:53:50/00:00:56, 0.675s/it]: train_loss_raw=1.2666, running_loss=1.3655, LR=0.000100
[2025-08-26 05:52:39,847][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034008] [Batch 04794/04869] [00:53:59/00:00:50, 0.676s/it]: train_loss_raw=1.3112, running_loss=1.3687, LR=0.000100
[2025-08-26 05:52:45,037][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034016] [Batch 04802/04869] [00:54:04/00:00:45, 0.676s/it]: train_loss_raw=1.3235, running_loss=1.3664, LR=0.000100
[2025-08-26 05:52:50,238][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034024] [Batch 04810/04869] [00:54:09/00:00:39, 0.676s/it]: train_loss_raw=1.3606, running_loss=1.3654, LR=0.000100
[2025-08-26 05:52:55,442][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034032] [Batch 04818/04869] [00:54:14/00:00:34, 0.676s/it]: train_loss_raw=1.2951, running_loss=1.3645, LR=0.000100
[2025-08-26 05:53:00,625][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034040] [Batch 04826/04869] [00:54:20/00:00:29, 0.676s/it]: train_loss_raw=1.3686, running_loss=1.3650, LR=0.000100
[2025-08-26 05:53:06,211][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034048] [Batch 04834/04869] [00:54:25/00:00:23, 0.676s/it]: train_loss_raw=1.3095, running_loss=1.3661, LR=0.000100
[2025-08-26 05:53:11,459][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034056] [Batch 04842/04869] [00:54:30/00:00:18, 0.676s/it]: train_loss_raw=1.3798, running_loss=1.3667, LR=0.000100
[2025-08-26 05:53:16,721][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034064] [Batch 04850/04869] [00:54:36/00:00:12, 0.676s/it]: train_loss_raw=1.3262, running_loss=1.3642, LR=0.000100
[2025-08-26 05:53:22,353][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034072] [Batch 04858/04869] [00:54:41/00:00:07, 0.676s/it]: train_loss_raw=1.3271, running_loss=1.3668, LR=0.000100
[2025-08-26 05:53:27,817][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 034080] [Batch 04866/04869] [00:54:47/00:00:02, 0.676s/it]: train_loss_raw=1.3788, running_loss=1.3653, LR=0.000100
[2025-08-26 05:53:48,739][__main__][INFO] - [VALIDATION] [Epoch 06/29] Starting validation.
[2025-08-26 05:53:58,547][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00007/00124] [00:00:09/00:02:22, 1.226s/it]
[2025-08-26 05:54:08,634][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00015/00124] [00:00:19/00:02:14, 1.243s/it]
[2025-08-26 05:54:20,114][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00023/00124] [00:00:31/00:02:10, 1.307s/it]
[2025-08-26 05:54:37,795][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00031/00124] [00:00:49/00:02:21, 1.533s/it]
[2025-08-26 05:54:47,902][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00039/00124] [00:00:59/00:02:04, 1.479s/it]
[2025-08-26 05:54:58,067][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00047/00124] [00:01:09/00:01:49, 1.444s/it]
[2025-08-26 05:55:07,875][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00055/00124] [00:01:19/00:01:36, 1.413s/it]
[2025-08-26 05:55:18,151][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00063/00124] [00:01:29/00:01:23, 1.397s/it]
[2025-08-26 05:55:28,625][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00071/00124] [00:01:39/00:01:12, 1.387s/it]
[2025-08-26 05:55:39,070][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00079/00124] [00:01:50/00:01:00, 1.379s/it]
[2025-08-26 05:55:49,379][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00087/00124] [00:02:00/00:00:49, 1.371s/it]
[2025-08-26 05:56:00,166][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00095/00124] [00:02:11/00:00:38, 1.369s/it]
[2025-08-26 05:56:09,774][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00103/00124] [00:02:21/00:00:27, 1.356s/it]
[2025-08-26 05:56:19,721][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00111/00124] [00:02:30/00:00:16, 1.348s/it]
[2025-08-26 05:56:29,843][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 034084] [Batch 00119/00124] [00:02:41/00:00:05, 1.343s/it]
[2025-08-26 05:56:34,296][__main__][INFO] - [VALIDATION] [Epoch 06/29] train_loss=1.36556, valid_loss=1.26518
[2025-08-26 05:56:34,296][__main__][INFO] - [VALIDATION] [Epoch 06/29] Metrics:
[2025-08-26 05:56:34,296][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_er      0.589
[2025-08-26 05:56:34,296][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_prec    0.131
[2025-08-26 05:56:34,297][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_recall  0.138
[2025-08-26 05:56:34,297][__main__][INFO] - [VALIDATION] [Epoch 06/29] - pep_recall 0.083
[2025-08-26 05:56:34,300][__main__][INFO] - [TRAIN] [Epoch 06/29] Epoch complete, total time 06:52:14, remaining time 22:34:29, 00:58:53 per epoch
[2025-08-26 05:56:37,549][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034088] [Batch 00005/04869] [00:00:03/00:50:26, 0.622s/it]: train_loss_raw=1.2611, running_loss=1.4424, LR=0.000100
[2025-08-26 05:56:43,420][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034096] [Batch 00013/04869] [00:00:08/00:55:55, 0.691s/it]: train_loss_raw=1.3941, running_loss=1.4336, LR=0.000100
[2025-08-26 05:56:48,580][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034104] [Batch 00021/04869] [00:00:14/00:54:24, 0.673s/it]: train_loss_raw=1.3536, running_loss=1.4254, LR=0.000100
[2025-08-26 05:56:53,752][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034112] [Batch 00029/04869] [00:00:19/00:53:43, 0.666s/it]: train_loss_raw=1.3972, running_loss=1.4190, LR=0.000100
[2025-08-26 05:56:59,019][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034120] [Batch 00037/04869] [00:00:24/00:53:30, 0.664s/it]: train_loss_raw=1.3076, running_loss=1.4124, LR=0.000100
[2025-08-26 05:57:04,779][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034128] [Batch 00045/04869] [00:00:30/00:54:12, 0.674s/it]: train_loss_raw=1.3657, running_loss=1.4061, LR=0.000100
[2025-08-26 05:57:09,952][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034136] [Batch 00053/04869] [00:00:35/00:53:47, 0.670s/it]: train_loss_raw=1.2357, running_loss=1.3966, LR=0.000100
[2025-08-26 05:57:15,136][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034144] [Batch 00061/04869] [00:00:40/00:53:27, 0.667s/it]: train_loss_raw=1.3610, running_loss=1.3934, LR=0.000100
[2025-08-26 05:57:20,397][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034152] [Batch 00069/04869] [00:00:45/00:53:17, 0.666s/it]: train_loss_raw=1.2823, running_loss=1.3868, LR=0.000100
[2025-08-26 05:57:25,896][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034160] [Batch 00077/04869] [00:00:51/00:53:22, 0.668s/it]: train_loss_raw=1.2120, running_loss=1.3826, LR=0.000100
[2025-08-26 05:57:31,079][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034168] [Batch 00085/04869] [00:00:56/00:53:07, 0.666s/it]: train_loss_raw=1.4693, running_loss=1.3760, LR=0.000100
[2025-08-26 05:57:36,263][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034176] [Batch 00093/04869] [00:01:01/00:52:55, 0.665s/it]: train_loss_raw=1.2884, running_loss=1.3718, LR=0.000100
[2025-08-26 05:57:41,872][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034184] [Batch 00101/04869] [00:01:07/00:53:03, 0.668s/it]: train_loss_raw=1.3570, running_loss=1.3687, LR=0.000100
[2025-08-26 05:57:47,044][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034192] [Batch 00109/04869] [00:01:12/00:52:50, 0.666s/it]: train_loss_raw=1.3190, running_loss=1.3634, LR=0.000100
[2025-08-26 05:57:52,488][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034200] [Batch 00117/04869] [00:01:18/00:52:50, 0.667s/it]: train_loss_raw=1.3985, running_loss=1.3591, LR=0.000100
[2025-08-26 05:57:57,668][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034208] [Batch 00125/04869] [00:01:23/00:52:38, 0.666s/it]: train_loss_raw=1.2984, running_loss=1.3574, LR=0.000100
[2025-08-26 05:58:02,832][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034216] [Batch 00133/04869] [00:01:28/00:52:27, 0.665s/it]: train_loss_raw=1.3193, running_loss=1.3551, LR=0.000100
[2025-08-26 05:58:07,995][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034224] [Batch 00141/04869] [00:01:33/00:52:17, 0.664s/it]: train_loss_raw=1.2498, running_loss=1.3516, LR=0.000100
[2025-08-26 05:58:13,150][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034232] [Batch 00149/04869] [00:01:38/00:52:07, 0.663s/it]: train_loss_raw=1.3538, running_loss=1.3490, LR=0.000100
[2025-08-26 05:58:18,314][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034240] [Batch 00157/04869] [00:01:43/00:51:57, 0.662s/it]: train_loss_raw=1.3729, running_loss=1.3467, LR=0.000100
[2025-08-26 05:58:23,488][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034248] [Batch 00165/04869] [00:01:49/00:51:48, 0.661s/it]: train_loss_raw=1.3876, running_loss=1.3500, LR=0.000100
[2025-08-26 05:58:29,050][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034256] [Batch 00173/04869] [00:01:54/00:51:51, 0.662s/it]: train_loss_raw=1.4053, running_loss=1.3496, LR=0.000100
[2025-08-26 05:58:35,194][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034264] [Batch 00181/04869] [00:02:00/00:52:07, 0.667s/it]: train_loss_raw=1.3109, running_loss=1.3468, LR=0.000100
[2025-08-26 05:58:40,490][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034272] [Batch 00189/04869] [00:02:06/00:52:01, 0.667s/it]: train_loss_raw=1.3293, running_loss=1.3471, LR=0.000100
[2025-08-26 05:58:45,644][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034280] [Batch 00197/04869] [00:02:11/00:51:51, 0.666s/it]: train_loss_raw=1.3023, running_loss=1.3436, LR=0.000100
[2025-08-26 05:58:50,852][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034288] [Batch 00205/04869] [00:02:16/00:51:43, 0.665s/it]: train_loss_raw=1.3990, running_loss=1.3439, LR=0.000100
[2025-08-26 05:58:56,009][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034296] [Batch 00213/04869] [00:02:21/00:51:34, 0.665s/it]: train_loss_raw=1.3054, running_loss=1.3456, LR=0.000100
[2025-08-26 05:59:01,148][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034304] [Batch 00221/04869] [00:02:26/00:51:25, 0.664s/it]: train_loss_raw=1.3750, running_loss=1.3459, LR=0.000100
[2025-08-26 05:59:06,509][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034312] [Batch 00229/04869] [00:02:32/00:51:21, 0.664s/it]: train_loss_raw=1.4025, running_loss=1.3466, LR=0.000100
[2025-08-26 05:59:11,967][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034320] [Batch 00237/04869] [00:02:37/00:51:18, 0.665s/it]: train_loss_raw=1.3503, running_loss=1.3413, LR=0.000100
[2025-08-26 05:59:17,612][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034328] [Batch 00245/04869] [00:02:43/00:51:19, 0.666s/it]: train_loss_raw=1.3393, running_loss=1.3414, LR=0.000100
[2025-08-26 05:59:22,760][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034336] [Batch 00253/04869] [00:02:48/00:51:11, 0.665s/it]: train_loss_raw=1.3220, running_loss=1.3439, LR=0.000100
[2025-08-26 05:59:28,588][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034344] [Batch 00261/04869] [00:02:54/00:51:14, 0.667s/it]: train_loss_raw=1.3578, running_loss=1.3453, LR=0.000100
[2025-08-26 05:59:33,831][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034352] [Batch 00269/04869] [00:02:59/00:51:07, 0.667s/it]: train_loss_raw=1.3982, running_loss=1.3445, LR=0.000100
[2025-08-26 05:59:39,576][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034360] [Batch 00277/04869] [00:03:05/00:51:09, 0.668s/it]: train_loss_raw=1.3098, running_loss=1.3435, LR=0.000100
[2025-08-26 05:59:44,928][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034368] [Batch 00285/04869] [00:03:10/00:51:03, 0.668s/it]: train_loss_raw=1.3798, running_loss=1.3405, LR=0.000100
[2025-08-26 05:59:50,105][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034376] [Batch 00293/04869] [00:03:15/00:50:55, 0.668s/it]: train_loss_raw=1.2591, running_loss=1.3389, LR=0.000100
[2025-08-26 05:59:55,281][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034384] [Batch 00301/04869] [00:03:20/00:50:48, 0.667s/it]: train_loss_raw=1.2919, running_loss=1.3363, LR=0.000100
[2025-08-26 06:00:00,436][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034392] [Batch 00309/04869] [00:03:25/00:50:39, 0.667s/it]: train_loss_raw=1.3384, running_loss=1.3370, LR=0.000100
[2025-08-26 06:00:05,906][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034400] [Batch 00317/04869] [00:03:31/00:50:36, 0.667s/it]: train_loss_raw=1.2749, running_loss=1.3354, LR=0.000100
[2025-08-26 06:00:11,069][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034408] [Batch 00325/04869] [00:03:36/00:50:28, 0.667s/it]: train_loss_raw=1.2661, running_loss=1.3348, LR=0.000100
[2025-08-26 06:00:16,197][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034416] [Batch 00333/04869] [00:03:41/00:50:20, 0.666s/it]: train_loss_raw=1.3512, running_loss=1.3380, LR=0.000100
[2025-08-26 06:00:22,037][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034424] [Batch 00341/04869] [00:03:47/00:50:22, 0.667s/it]: train_loss_raw=1.3728, running_loss=1.3416, LR=0.000100
[2025-08-26 06:00:27,191][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034432] [Batch 00349/04869] [00:03:52/00:50:14, 0.667s/it]: train_loss_raw=1.3159, running_loss=1.3385, LR=0.000100
[2025-08-26 06:00:32,480][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034440] [Batch 00357/04869] [00:03:58/00:50:08, 0.667s/it]: train_loss_raw=1.3577, running_loss=1.3426, LR=0.000100
[2025-08-26 06:00:37,627][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034448] [Batch 00365/04869] [00:04:03/00:50:00, 0.666s/it]: train_loss_raw=1.4578, running_loss=1.3428, LR=0.000100
[2025-08-26 06:00:43,043][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034456] [Batch 00373/04869] [00:04:08/00:49:56, 0.667s/it]: train_loss_raw=1.3252, running_loss=1.3431, LR=0.000100
[2025-08-26 06:00:48,183][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034464] [Batch 00381/04869] [00:04:13/00:49:49, 0.666s/it]: train_loss_raw=1.4155, running_loss=1.3430, LR=0.000100
[2025-08-26 06:00:53,318][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034472] [Batch 00389/04869] [00:04:18/00:49:41, 0.666s/it]: train_loss_raw=1.3262, running_loss=1.3397, LR=0.000100
[2025-08-26 06:00:58,650][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034480] [Batch 00397/04869] [00:04:24/00:49:36, 0.666s/it]: train_loss_raw=1.3860, running_loss=1.3373, LR=0.000100
[2025-08-26 06:01:03,801][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034488] [Batch 00405/04869] [00:04:29/00:49:28, 0.665s/it]: train_loss_raw=1.3273, running_loss=1.3348, LR=0.000100
[2025-08-26 06:01:09,084][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034496] [Batch 00413/04869] [00:04:34/00:49:23, 0.665s/it]: train_loss_raw=1.2369, running_loss=1.3333, LR=0.000100
[2025-08-26 06:01:14,442][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034504] [Batch 00421/04869] [00:04:40/00:49:18, 0.665s/it]: train_loss_raw=1.3038, running_loss=1.3337, LR=0.000100
[2025-08-26 06:01:19,774][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034512] [Batch 00429/04869] [00:04:45/00:49:13, 0.665s/it]: train_loss_raw=1.1944, running_loss=1.3305, LR=0.000100
[2025-08-26 06:01:24,909][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034520] [Batch 00437/04869] [00:04:50/00:49:05, 0.665s/it]: train_loss_raw=1.2494, running_loss=1.3308, LR=0.000100
[2025-08-26 06:01:30,347][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034528] [Batch 00445/04869] [00:04:55/00:49:01, 0.665s/it]: train_loss_raw=1.3220, running_loss=1.3306, LR=0.000100
[2025-08-26 06:01:35,483][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034536] [Batch 00453/04869] [00:05:01/00:48:54, 0.665s/it]: train_loss_raw=1.4696, running_loss=1.3289, LR=0.000100
[2025-08-26 06:01:40,920][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034544] [Batch 00461/04869] [00:05:06/00:48:50, 0.665s/it]: train_loss_raw=1.3150, running_loss=1.3301, LR=0.000100
[2025-08-26 06:01:46,055][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034552] [Batch 00469/04869] [00:05:11/00:48:43, 0.664s/it]: train_loss_raw=1.3225, running_loss=1.3288, LR=0.000100
[2025-08-26 06:01:51,493][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034560] [Batch 00477/04869] [00:05:17/00:48:39, 0.665s/it]: train_loss_raw=1.3166, running_loss=1.3301, LR=0.000100
[2025-08-26 06:01:56,630][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034568] [Batch 00485/04869] [00:05:22/00:48:32, 0.664s/it]: train_loss_raw=1.3386, running_loss=1.3304, LR=0.000100
[2025-08-26 06:02:01,788][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034576] [Batch 00493/04869] [00:05:27/00:48:25, 0.664s/it]: train_loss_raw=1.2664, running_loss=1.3297, LR=0.000100
[2025-08-26 06:02:06,934][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034584] [Batch 00501/04869] [00:05:32/00:48:18, 0.664s/it]: train_loss_raw=1.3891, running_loss=1.3310, LR=0.000100
[2025-08-26 06:02:12,866][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034592] [Batch 00509/04869] [00:05:38/00:48:18, 0.665s/it]: train_loss_raw=1.4215, running_loss=1.3313, LR=0.000100
[2025-08-26 06:02:18,426][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034600] [Batch 00517/04869] [00:05:43/00:48:15, 0.665s/it]: train_loss_raw=1.4621, running_loss=1.3352, LR=0.000100
[2025-08-26 06:02:23,954][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034608] [Batch 00525/04869] [00:05:49/00:48:11, 0.666s/it]: train_loss_raw=1.3407, running_loss=1.3342, LR=0.000100
[2025-08-26 06:02:29,129][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034616] [Batch 00533/04869] [00:05:54/00:48:05, 0.665s/it]: train_loss_raw=1.1953, running_loss=1.3313, LR=0.000100
[2025-08-26 06:02:34,277][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034624] [Batch 00541/04869] [00:05:59/00:47:58, 0.665s/it]: train_loss_raw=1.3211, running_loss=1.3351, LR=0.000100
[2025-08-26 06:02:39,420][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034632] [Batch 00549/04869] [00:06:04/00:47:51, 0.665s/it]: train_loss_raw=1.3517, running_loss=1.3310, LR=0.000100
[2025-08-26 06:02:44,768][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034640] [Batch 00557/04869] [00:06:10/00:47:46, 0.665s/it]: train_loss_raw=1.3936, running_loss=1.3329, LR=0.000100
[2025-08-26 06:02:50,208][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034648] [Batch 00565/04869] [00:06:15/00:47:42, 0.665s/it]: train_loss_raw=1.2374, running_loss=1.3324, LR=0.000100
[2025-08-26 06:02:55,711][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034656] [Batch 00573/04869] [00:06:21/00:47:38, 0.665s/it]: train_loss_raw=1.2585, running_loss=1.3318, LR=0.000100
[2025-08-26 06:03:00,901][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034664] [Batch 00581/04869] [00:06:26/00:47:32, 0.665s/it]: train_loss_raw=1.3822, running_loss=1.3346, LR=0.000100
[2025-08-26 06:03:06,043][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034672] [Batch 00589/04869] [00:06:31/00:47:25, 0.665s/it]: train_loss_raw=1.3104, running_loss=1.3363, LR=0.000100
[2025-08-26 06:03:11,313][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034680] [Batch 00597/04869] [00:06:36/00:47:19, 0.665s/it]: train_loss_raw=1.1651, running_loss=1.3347, LR=0.000100
[2025-08-26 06:03:17,279][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034688] [Batch 00605/04869] [00:06:42/00:47:19, 0.666s/it]: train_loss_raw=1.2786, running_loss=1.3328, LR=0.000100
[2025-08-26 06:03:22,622][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034696] [Batch 00613/04869] [00:06:48/00:47:13, 0.666s/it]: train_loss_raw=1.2113, running_loss=1.3343, LR=0.000100
[2025-08-26 06:03:28,241][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034704] [Batch 00621/04869] [00:06:53/00:47:10, 0.666s/it]: train_loss_raw=1.2160, running_loss=1.3315, LR=0.000100
[2025-08-26 06:03:33,407][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034712] [Batch 00629/04869] [00:06:58/00:47:04, 0.666s/it]: train_loss_raw=1.3081, running_loss=1.3315, LR=0.000100
[2025-08-26 06:03:39,146][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034720] [Batch 00637/04869] [00:07:04/00:47:01, 0.667s/it]: train_loss_raw=1.3816, running_loss=1.3303, LR=0.000100
[2025-08-26 06:03:44,292][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034728] [Batch 00645/04869] [00:07:09/00:46:55, 0.666s/it]: train_loss_raw=1.3718, running_loss=1.3314, LR=0.000100
[2025-08-26 06:03:49,419][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034736] [Batch 00653/04869] [00:07:14/00:46:48, 0.666s/it]: train_loss_raw=1.3082, running_loss=1.3287, LR=0.000100
[2025-08-26 06:03:54,562][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034744] [Batch 00661/04869] [00:07:20/00:46:41, 0.666s/it]: train_loss_raw=1.4510, running_loss=1.3288, LR=0.000100
[2025-08-26 06:03:59,762][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034752] [Batch 00669/04869] [00:07:25/00:46:35, 0.666s/it]: train_loss_raw=1.4626, running_loss=1.3298, LR=0.000100
[2025-08-26 06:04:04,903][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034760] [Batch 00677/04869] [00:07:30/00:46:29, 0.665s/it]: train_loss_raw=1.2214, running_loss=1.3309, LR=0.000100
[2025-08-26 06:04:10,036][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034768] [Batch 00685/04869] [00:07:35/00:46:22, 0.665s/it]: train_loss_raw=1.4019, running_loss=1.3298, LR=0.000100
[2025-08-26 06:04:15,355][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034776] [Batch 00693/04869] [00:07:40/00:46:17, 0.665s/it]: train_loss_raw=1.4034, running_loss=1.3319, LR=0.000100
[2025-08-26 06:04:20,514][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034784] [Batch 00701/04869] [00:07:46/00:46:11, 0.665s/it]: train_loss_raw=1.4813, running_loss=1.3342, LR=0.000100
[2025-08-26 06:04:25,686][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034792] [Batch 00709/04869] [00:07:51/00:46:05, 0.665s/it]: train_loss_raw=1.3846, running_loss=1.3339, LR=0.000100
[2025-08-26 06:04:30,941][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034800] [Batch 00717/04869] [00:07:56/00:45:59, 0.665s/it]: train_loss_raw=1.3949, running_loss=1.3365, LR=0.000100
[2025-08-26 06:04:36,113][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034808] [Batch 00725/04869] [00:08:01/00:45:53, 0.664s/it]: train_loss_raw=1.4248, running_loss=1.3361, LR=0.000100
[2025-08-26 06:04:41,284][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034816] [Batch 00733/04869] [00:08:06/00:45:47, 0.664s/it]: train_loss_raw=1.2088, running_loss=1.3365, LR=0.000100
[2025-08-26 06:04:46,460][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034824] [Batch 00741/04869] [00:08:12/00:45:40, 0.664s/it]: train_loss_raw=1.4154, running_loss=1.3341, LR=0.000100
[2025-08-26 06:04:51,624][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034832] [Batch 00749/04869] [00:08:17/00:45:34, 0.664s/it]: train_loss_raw=1.3741, running_loss=1.3355, LR=0.000100
[2025-08-26 06:04:56,787][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034840] [Batch 00757/04869] [00:08:22/00:45:28, 0.664s/it]: train_loss_raw=1.3734, running_loss=1.3363, LR=0.000100
[2025-08-26 06:05:02,231][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034848] [Batch 00765/04869] [00:08:27/00:45:24, 0.664s/it]: train_loss_raw=1.2653, running_loss=1.3340, LR=0.000100
[2025-08-26 06:05:07,369][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034856] [Batch 00773/04869] [00:08:32/00:45:17, 0.664s/it]: train_loss_raw=1.3358, running_loss=1.3338, LR=0.000100
[2025-08-26 06:05:12,528][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034864] [Batch 00781/04869] [00:08:38/00:45:11, 0.663s/it]: train_loss_raw=1.4118, running_loss=1.3339, LR=0.000100
[2025-08-26 06:05:17,724][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034872] [Batch 00789/04869] [00:08:43/00:45:05, 0.663s/it]: train_loss_raw=1.3280, running_loss=1.3322, LR=0.000100
[2025-08-26 06:05:23,139][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034880] [Batch 00797/04869] [00:08:48/00:45:01, 0.663s/it]: train_loss_raw=1.4175, running_loss=1.3332, LR=0.000100
[2025-08-26 06:05:28,574][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034888] [Batch 00805/04869] [00:08:54/00:44:56, 0.664s/it]: train_loss_raw=1.2465, running_loss=1.3318, LR=0.000100
[2025-08-26 06:05:33,869][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034896] [Batch 00813/04869] [00:08:59/00:44:51, 0.664s/it]: train_loss_raw=1.4241, running_loss=1.3313, LR=0.000100
[2025-08-26 06:05:39,018][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034904] [Batch 00821/04869] [00:09:04/00:44:45, 0.663s/it]: train_loss_raw=1.4022, running_loss=1.3313, LR=0.000100
[2025-08-26 06:05:44,221][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034912] [Batch 00829/04869] [00:09:09/00:44:39, 0.663s/it]: train_loss_raw=1.2334, running_loss=1.3295, LR=0.000100
[2025-08-26 06:05:49,352][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034920] [Batch 00837/04869] [00:09:14/00:44:33, 0.663s/it]: train_loss_raw=1.3653, running_loss=1.3287, LR=0.000100
[2025-08-26 06:05:54,629][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034928] [Batch 00845/04869] [00:09:20/00:44:27, 0.663s/it]: train_loss_raw=1.3426, running_loss=1.3258, LR=0.000100
[2025-08-26 06:05:59,787][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034936] [Batch 00853/04869] [00:09:25/00:44:21, 0.663s/it]: train_loss_raw=1.3466, running_loss=1.3245, LR=0.000100
[2025-08-26 06:06:04,924][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034944] [Batch 00861/04869] [00:09:30/00:44:15, 0.663s/it]: train_loss_raw=1.3362, running_loss=1.3261, LR=0.000100
[2025-08-26 06:06:10,069][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034952] [Batch 00869/04869] [00:09:35/00:44:09, 0.662s/it]: train_loss_raw=1.3116, running_loss=1.3256, LR=0.000100
[2025-08-26 06:06:15,286][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034960] [Batch 00877/04869] [00:09:40/00:44:03, 0.662s/it]: train_loss_raw=1.3799, running_loss=1.3288, LR=0.000100
[2025-08-26 06:06:20,990][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034968] [Batch 00885/04869] [00:09:46/00:44:00, 0.663s/it]: train_loss_raw=1.3124, running_loss=1.3303, LR=0.000100
[2025-08-26 06:06:26,134][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034976] [Batch 00893/04869] [00:09:51/00:43:54, 0.663s/it]: train_loss_raw=1.2520, running_loss=1.3313, LR=0.000100
[2025-08-26 06:06:31,564][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034984] [Batch 00901/04869] [00:09:57/00:43:49, 0.663s/it]: train_loss_raw=1.3399, running_loss=1.3293, LR=0.000100
[2025-08-26 06:06:36,730][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 034992] [Batch 00909/04869] [00:10:02/00:43:43, 0.663s/it]: train_loss_raw=1.2894, running_loss=1.3292, LR=0.000100
[2025-08-26 06:06:41,884][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035000] [Batch 00917/04869] [00:10:07/00:43:37, 0.662s/it]: train_loss_raw=1.3944, running_loss=1.3318, LR=0.000100
[2025-08-26 06:06:47,062][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035008] [Batch 00925/04869] [00:10:12/00:43:32, 0.662s/it]: train_loss_raw=1.2972, running_loss=1.3310, LR=0.000100
[2025-08-26 06:06:52,235][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035016] [Batch 00933/04869] [00:10:17/00:43:26, 0.662s/it]: train_loss_raw=1.2723, running_loss=1.3302, LR=0.000100
[2025-08-26 06:06:57,489][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035024] [Batch 00941/04869] [00:10:23/00:43:20, 0.662s/it]: train_loss_raw=1.3393, running_loss=1.3312, LR=0.000100
[2025-08-26 06:07:03,046][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035032] [Batch 00949/04869] [00:10:28/00:43:16, 0.662s/it]: train_loss_raw=1.3670, running_loss=1.3292, LR=0.000100
[2025-08-26 06:07:08,191][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035040] [Batch 00957/04869] [00:10:33/00:43:10, 0.662s/it]: train_loss_raw=1.3163, running_loss=1.3309, LR=0.000100
[2025-08-26 06:07:13,573][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035048] [Batch 00965/04869] [00:10:39/00:43:05, 0.662s/it]: train_loss_raw=1.3394, running_loss=1.3306, LR=0.000100
[2025-08-26 06:07:19,232][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035056] [Batch 00973/04869] [00:10:44/00:43:01, 0.663s/it]: train_loss_raw=1.3357, running_loss=1.3327, LR=0.000100
[2025-08-26 06:07:24,433][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035064] [Batch 00981/04869] [00:10:49/00:42:56, 0.663s/it]: train_loss_raw=1.3079, running_loss=1.3310, LR=0.000100
[2025-08-26 06:07:30,073][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035072] [Batch 00989/04869] [00:10:55/00:42:52, 0.663s/it]: train_loss_raw=1.1992, running_loss=1.3293, LR=0.000100
[2025-08-26 06:07:35,519][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035080] [Batch 00997/04869] [00:11:01/00:42:47, 0.663s/it]: train_loss_raw=1.3861, running_loss=1.3359, LR=0.000100
[2025-08-26 06:07:41,196][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035088] [Batch 01005/04869] [00:11:06/00:42:43, 0.663s/it]: train_loss_raw=1.3380, running_loss=1.3390, LR=0.000100
[2025-08-26 06:07:46,360][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035096] [Batch 01013/04869] [00:11:11/00:42:37, 0.663s/it]: train_loss_raw=1.3163, running_loss=1.3408, LR=0.000100
[2025-08-26 06:07:51,537][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035104] [Batch 01021/04869] [00:11:17/00:42:31, 0.663s/it]: train_loss_raw=1.3879, running_loss=1.3417, LR=0.000100
[2025-08-26 06:07:57,279][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035112] [Batch 01029/04869] [00:11:22/00:42:28, 0.664s/it]: train_loss_raw=1.2979, running_loss=1.3413, LR=0.000100
[2025-08-26 06:08:02,593][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035120] [Batch 01037/04869] [00:11:28/00:42:22, 0.664s/it]: train_loss_raw=1.3947, running_loss=1.3414, LR=0.000100
[2025-08-26 06:08:08,453][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035128] [Batch 01045/04869] [00:11:34/00:42:19, 0.664s/it]: train_loss_raw=1.3074, running_loss=1.3378, LR=0.000100
[2025-08-26 06:08:13,734][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035136] [Batch 01053/04869] [00:11:39/00:42:14, 0.664s/it]: train_loss_raw=1.2581, running_loss=1.3346, LR=0.000100
[2025-08-26 06:08:19,204][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035144] [Batch 01061/04869] [00:11:44/00:42:09, 0.664s/it]: train_loss_raw=1.3091, running_loss=1.3366, LR=0.000100
[2025-08-26 06:08:24,330][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035152] [Batch 01069/04869] [00:11:49/00:42:03, 0.664s/it]: train_loss_raw=1.3126, running_loss=1.3353, LR=0.000100
[2025-08-26 06:08:29,463][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035160] [Batch 01077/04869] [00:11:55/00:41:57, 0.664s/it]: train_loss_raw=1.2212, running_loss=1.3345, LR=0.000100
[2025-08-26 06:08:35,223][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035168] [Batch 01085/04869] [00:12:00/00:41:53, 0.664s/it]: train_loss_raw=1.2607, running_loss=1.3320, LR=0.000100
[2025-08-26 06:08:40,724][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035176] [Batch 01093/04869] [00:12:06/00:41:49, 0.664s/it]: train_loss_raw=1.4949, running_loss=1.3335, LR=0.000100
[2025-08-26 06:08:45,972][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035184] [Batch 01101/04869] [00:12:11/00:41:43, 0.664s/it]: train_loss_raw=1.3009, running_loss=1.3328, LR=0.000100
[2025-08-26 06:08:51,117][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035192] [Batch 01109/04869] [00:12:16/00:41:37, 0.664s/it]: train_loss_raw=1.3454, running_loss=1.3310, LR=0.000100
[2025-08-26 06:08:56,265][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035200] [Batch 01117/04869] [00:12:21/00:41:31, 0.664s/it]: train_loss_raw=1.3294, running_loss=1.3316, LR=0.000100
[2025-08-26 06:09:01,429][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035208] [Batch 01125/04869] [00:12:26/00:41:25, 0.664s/it]: train_loss_raw=1.3574, running_loss=1.3320, LR=0.000100
[2025-08-26 06:09:06,582][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035216] [Batch 01133/04869] [00:12:32/00:41:20, 0.664s/it]: train_loss_raw=1.3466, running_loss=1.3312, LR=0.000100
[2025-08-26 06:09:11,950][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035224] [Batch 01141/04869] [00:12:37/00:41:15, 0.664s/it]: train_loss_raw=1.3147, running_loss=1.3326, LR=0.000100
[2025-08-26 06:09:17,121][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035232] [Batch 01149/04869] [00:12:42/00:41:09, 0.664s/it]: train_loss_raw=1.4018, running_loss=1.3308, LR=0.000100
[2025-08-26 06:09:22,272][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035240] [Batch 01157/04869] [00:12:47/00:41:03, 0.664s/it]: train_loss_raw=1.3418, running_loss=1.3314, LR=0.000100
[2025-08-26 06:09:27,422][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035248] [Batch 01165/04869] [00:12:52/00:40:57, 0.664s/it]: train_loss_raw=1.2604, running_loss=1.3314, LR=0.000100
[2025-08-26 06:09:32,881][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035256] [Batch 01173/04869] [00:12:58/00:40:52, 0.664s/it]: train_loss_raw=1.3184, running_loss=1.3340, LR=0.000100
[2025-08-26 06:09:38,235][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035264] [Batch 01181/04869] [00:13:03/00:40:47, 0.664s/it]: train_loss_raw=1.3400, running_loss=1.3330, LR=0.000100
[2025-08-26 06:09:43,367][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035272] [Batch 01189/04869] [00:13:08/00:40:41, 0.664s/it]: train_loss_raw=1.3763, running_loss=1.3324, LR=0.000100
[2025-08-26 06:09:49,012][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035280] [Batch 01197/04869] [00:13:14/00:40:37, 0.664s/it]: train_loss_raw=1.3355, running_loss=1.3344, LR=0.000100
[2025-08-26 06:09:54,187][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035288] [Batch 01205/04869] [00:13:19/00:40:31, 0.664s/it]: train_loss_raw=1.3780, running_loss=1.3323, LR=0.000100
[2025-08-26 06:09:59,423][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035296] [Batch 01213/04869] [00:13:24/00:40:26, 0.664s/it]: train_loss_raw=1.3907, running_loss=1.3336, LR=0.000100
[2025-08-26 06:10:04,588][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035304] [Batch 01221/04869] [00:13:30/00:40:20, 0.664s/it]: train_loss_raw=1.2529, running_loss=1.3327, LR=0.000100
[2025-08-26 06:10:10,016][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035312] [Batch 01229/04869] [00:13:35/00:40:15, 0.664s/it]: train_loss_raw=1.3046, running_loss=1.3324, LR=0.000100
[2025-08-26 06:10:15,160][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035320] [Batch 01237/04869] [00:13:40/00:40:09, 0.663s/it]: train_loss_raw=1.3148, running_loss=1.3310, LR=0.000100
[2025-08-26 06:10:20,334][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035328] [Batch 01245/04869] [00:13:45/00:40:04, 0.663s/it]: train_loss_raw=1.2924, running_loss=1.3297, LR=0.000100
[2025-08-26 06:10:25,473][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035336] [Batch 01253/04869] [00:13:51/00:39:58, 0.663s/it]: train_loss_raw=1.3309, running_loss=1.3302, LR=0.000100
[2025-08-26 06:10:30,628][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035344] [Batch 01261/04869] [00:13:56/00:39:52, 0.663s/it]: train_loss_raw=1.3943, running_loss=1.3317, LR=0.000100
[2025-08-26 06:10:35,773][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035352] [Batch 01269/04869] [00:14:01/00:39:46, 0.663s/it]: train_loss_raw=1.4011, running_loss=1.3307, LR=0.000100
[2025-08-26 06:10:41,463][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035360] [Batch 01277/04869] [00:14:07/00:39:42, 0.663s/it]: train_loss_raw=1.3418, running_loss=1.3320, LR=0.000100
[2025-08-26 06:10:46,597][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035368] [Batch 01285/04869] [00:14:12/00:39:36, 0.663s/it]: train_loss_raw=1.3035, running_loss=1.3298, LR=0.000100
[2025-08-26 06:10:51,761][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035376] [Batch 01293/04869] [00:14:17/00:39:31, 0.663s/it]: train_loss_raw=1.3890, running_loss=1.3298, LR=0.000100
[2025-08-26 06:10:57,046][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035384] [Batch 01301/04869] [00:14:22/00:39:25, 0.663s/it]: train_loss_raw=1.3826, running_loss=1.3294, LR=0.000100
[2025-08-26 06:11:02,265][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035392] [Batch 01309/04869] [00:14:27/00:39:20, 0.663s/it]: train_loss_raw=1.3624, running_loss=1.3287, LR=0.000100
[2025-08-26 06:11:07,773][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035400] [Batch 01317/04869] [00:14:33/00:39:15, 0.663s/it]: train_loss_raw=1.4065, running_loss=1.3319, LR=0.000100
[2025-08-26 06:11:13,129][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035408] [Batch 01325/04869] [00:14:38/00:39:10, 0.663s/it]: train_loss_raw=1.2256, running_loss=1.3292, LR=0.000100
[2025-08-26 06:11:18,394][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035416] [Batch 01333/04869] [00:14:43/00:39:04, 0.663s/it]: train_loss_raw=1.4120, running_loss=1.3265, LR=0.000100
[2025-08-26 06:11:23,536][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035424] [Batch 01341/04869] [00:14:49/00:38:59, 0.663s/it]: train_loss_raw=1.1378, running_loss=1.3261, LR=0.000100
[2025-08-26 06:11:28,664][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035432] [Batch 01349/04869] [00:14:54/00:38:53, 0.663s/it]: train_loss_raw=1.2821, running_loss=1.3251, LR=0.000100
[2025-08-26 06:11:34,073][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035440] [Batch 01357/04869] [00:14:59/00:38:48, 0.663s/it]: train_loss_raw=1.3156, running_loss=1.3245, LR=0.000100
[2025-08-26 06:11:39,225][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035448] [Batch 01365/04869] [00:15:04/00:38:42, 0.663s/it]: train_loss_raw=1.3095, running_loss=1.3263, LR=0.000100
[2025-08-26 06:11:44,375][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035456] [Batch 01373/04869] [00:15:09/00:38:36, 0.663s/it]: train_loss_raw=1.3717, running_loss=1.3279, LR=0.000100
[2025-08-26 06:11:49,811][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035464] [Batch 01381/04869] [00:15:15/00:38:31, 0.663s/it]: train_loss_raw=1.3326, running_loss=1.3265, LR=0.000100
[2025-08-26 06:11:55,027][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035472] [Batch 01389/04869] [00:15:20/00:38:26, 0.663s/it]: train_loss_raw=1.1963, running_loss=1.3247, LR=0.000100
[2025-08-26 06:12:00,263][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035480] [Batch 01397/04869] [00:15:25/00:38:20, 0.663s/it]: train_loss_raw=1.3557, running_loss=1.3224, LR=0.000100
[2025-08-26 06:12:05,547][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035488] [Batch 01405/04869] [00:15:31/00:38:15, 0.663s/it]: train_loss_raw=1.2574, running_loss=1.3229, LR=0.000100
[2025-08-26 06:12:10,997][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035496] [Batch 01413/04869] [00:15:36/00:38:10, 0.663s/it]: train_loss_raw=1.3268, running_loss=1.3248, LR=0.000100
[2025-08-26 06:12:16,139][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035504] [Batch 01421/04869] [00:15:41/00:38:05, 0.663s/it]: train_loss_raw=1.2761, running_loss=1.3275, LR=0.000100
[2025-08-26 06:12:21,280][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035512] [Batch 01429/04869] [00:15:46/00:37:59, 0.663s/it]: train_loss_raw=1.4773, running_loss=1.3289, LR=0.000100
[2025-08-26 06:12:26,418][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035520] [Batch 01437/04869] [00:15:51/00:37:53, 0.662s/it]: train_loss_raw=1.3346, running_loss=1.3297, LR=0.000100
[2025-08-26 06:12:31,982][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035528] [Batch 01445/04869] [00:15:57/00:37:48, 0.663s/it]: train_loss_raw=1.2303, running_loss=1.3290, LR=0.000100
[2025-08-26 06:12:37,239][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035536] [Batch 01453/04869] [00:16:02/00:37:43, 0.663s/it]: train_loss_raw=1.3750, running_loss=1.3314, LR=0.000100
[2025-08-26 06:12:42,397][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035544] [Batch 01461/04869] [00:16:07/00:37:37, 0.663s/it]: train_loss_raw=1.2723, running_loss=1.3297, LR=0.000100
[2025-08-26 06:12:47,560][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035552] [Batch 01469/04869] [00:16:13/00:37:32, 0.662s/it]: train_loss_raw=1.2239, running_loss=1.3291, LR=0.000100
[2025-08-26 06:12:52,746][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035560] [Batch 01477/04869] [00:16:18/00:37:26, 0.662s/it]: train_loss_raw=1.4797, running_loss=1.3342, LR=0.000100
[2025-08-26 06:12:57,907][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035568] [Batch 01485/04869] [00:16:23/00:37:21, 0.662s/it]: train_loss_raw=1.2994, running_loss=1.3361, LR=0.000100
[2025-08-26 06:13:03,076][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035576] [Batch 01493/04869] [00:16:28/00:37:15, 0.662s/it]: train_loss_raw=1.3381, running_loss=1.3367, LR=0.000100
[2025-08-26 06:13:08,242][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035584] [Batch 01501/04869] [00:16:33/00:37:09, 0.662s/it]: train_loss_raw=1.2027, running_loss=1.3338, LR=0.000100
[2025-08-26 06:13:13,404][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035592] [Batch 01509/04869] [00:16:38/00:37:04, 0.662s/it]: train_loss_raw=1.3591, running_loss=1.3333, LR=0.000100
[2025-08-26 06:13:18,598][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035600] [Batch 01517/04869] [00:16:44/00:36:58, 0.662s/it]: train_loss_raw=1.4083, running_loss=1.3347, LR=0.000100
[2025-08-26 06:13:23,754][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035608] [Batch 01525/04869] [00:16:49/00:36:53, 0.662s/it]: train_loss_raw=1.2845, running_loss=1.3322, LR=0.000100
[2025-08-26 06:13:28,915][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035616] [Batch 01533/04869] [00:16:54/00:36:47, 0.662s/it]: train_loss_raw=1.4062, running_loss=1.3310, LR=0.000100
[2025-08-26 06:13:34,275][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035624] [Batch 01541/04869] [00:16:59/00:36:42, 0.662s/it]: train_loss_raw=1.3183, running_loss=1.3323, LR=0.000100
[2025-08-26 06:13:39,603][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035632] [Batch 01549/04869] [00:17:05/00:36:37, 0.662s/it]: train_loss_raw=1.4133, running_loss=1.3310, LR=0.000100
[2025-08-26 06:13:44,775][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035640] [Batch 01557/04869] [00:17:10/00:36:31, 0.662s/it]: train_loss_raw=1.3757, running_loss=1.3296, LR=0.000100
[2025-08-26 06:13:49,907][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035648] [Batch 01565/04869] [00:17:15/00:36:26, 0.662s/it]: train_loss_raw=1.2836, running_loss=1.3296, LR=0.000100
[2025-08-26 06:13:55,051][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035656] [Batch 01573/04869] [00:17:20/00:36:20, 0.662s/it]: train_loss_raw=1.2676, running_loss=1.3299, LR=0.000100
[2025-08-26 06:14:00,193][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035664] [Batch 01581/04869] [00:17:25/00:36:14, 0.661s/it]: train_loss_raw=1.2173, running_loss=1.3285, LR=0.000100
[2025-08-26 06:14:05,340][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035672] [Batch 01589/04869] [00:17:30/00:36:09, 0.661s/it]: train_loss_raw=1.3612, running_loss=1.3268, LR=0.000100
[2025-08-26 06:14:10,680][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035680] [Batch 01597/04869] [00:17:36/00:36:04, 0.661s/it]: train_loss_raw=1.2056, running_loss=1.3258, LR=0.000100
[2025-08-26 06:14:15,883][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035688] [Batch 01605/04869] [00:17:41/00:35:58, 0.661s/it]: train_loss_raw=1.3320, running_loss=1.3258, LR=0.000100
[2025-08-26 06:14:21,063][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035696] [Batch 01613/04869] [00:17:46/00:35:53, 0.661s/it]: train_loss_raw=1.3867, running_loss=1.3257, LR=0.000100
[2025-08-26 06:14:26,588][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035704] [Batch 01621/04869] [00:17:52/00:35:48, 0.661s/it]: train_loss_raw=1.3572, running_loss=1.3275, LR=0.000100
[2025-08-26 06:14:32,008][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035712] [Batch 01629/04869] [00:17:57/00:35:43, 0.661s/it]: train_loss_raw=1.3627, running_loss=1.3290, LR=0.000100
[2025-08-26 06:14:37,169][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035720] [Batch 01637/04869] [00:18:02/00:35:37, 0.661s/it]: train_loss_raw=1.2403, running_loss=1.3292, LR=0.000100
[2025-08-26 06:14:42,336][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035728] [Batch 01645/04869] [00:18:07/00:35:32, 0.661s/it]: train_loss_raw=1.2914, running_loss=1.3286, LR=0.000100
[2025-08-26 06:14:47,511][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035736] [Batch 01653/04869] [00:18:13/00:35:26, 0.661s/it]: train_loss_raw=1.2522, running_loss=1.3309, LR=0.000100
[2025-08-26 06:14:52,683][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035744] [Batch 01661/04869] [00:18:18/00:35:21, 0.661s/it]: train_loss_raw=1.3657, running_loss=1.3326, LR=0.000100
[2025-08-26 06:14:57,851][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035752] [Batch 01669/04869] [00:18:23/00:35:15, 0.661s/it]: train_loss_raw=1.3681, running_loss=1.3300, LR=0.000100
[2025-08-26 06:15:03,025][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035760] [Batch 01677/04869] [00:18:28/00:35:10, 0.661s/it]: train_loss_raw=1.3139, running_loss=1.3273, LR=0.000100
[2025-08-26 06:15:08,194][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035768] [Batch 01685/04869] [00:18:33/00:35:04, 0.661s/it]: train_loss_raw=1.3920, running_loss=1.3286, LR=0.000100
[2025-08-26 06:15:13,360][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035776] [Batch 01693/04869] [00:18:38/00:34:59, 0.661s/it]: train_loss_raw=1.3903, running_loss=1.3298, LR=0.000100
[2025-08-26 06:15:18,549][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035784] [Batch 01701/04869] [00:18:44/00:34:53, 0.661s/it]: train_loss_raw=1.3751, running_loss=1.3303, LR=0.000100
[2025-08-26 06:15:23,726][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035792] [Batch 01709/04869] [00:18:49/00:34:48, 0.661s/it]: train_loss_raw=1.3873, running_loss=1.3295, LR=0.000100
[2025-08-26 06:15:29,207][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035800] [Batch 01717/04869] [00:18:54/00:34:43, 0.661s/it]: train_loss_raw=1.2934, running_loss=1.3277, LR=0.000100
[2025-08-26 06:15:35,231][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035808] [Batch 01725/04869] [00:19:00/00:34:39, 0.661s/it]: train_loss_raw=1.3135, running_loss=1.3248, LR=0.000100
[2025-08-26 06:15:40,395][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035816] [Batch 01733/04869] [00:19:05/00:34:33, 0.661s/it]: train_loss_raw=1.3971, running_loss=1.3253, LR=0.000100
[2025-08-26 06:15:45,744][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035824] [Batch 01741/04869] [00:19:11/00:34:28, 0.661s/it]: train_loss_raw=1.3754, running_loss=1.3257, LR=0.000100
[2025-08-26 06:15:51,067][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035832] [Batch 01749/04869] [00:19:16/00:34:23, 0.661s/it]: train_loss_raw=1.3149, running_loss=1.3250, LR=0.000100
[2025-08-26 06:15:56,375][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035840] [Batch 01757/04869] [00:19:21/00:34:18, 0.661s/it]: train_loss_raw=1.3930, running_loss=1.3247, LR=0.000100
[2025-08-26 06:16:01,593][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035848] [Batch 01765/04869] [00:19:27/00:34:12, 0.661s/it]: train_loss_raw=1.4428, running_loss=1.3247, LR=0.000100
[2025-08-26 06:16:06,803][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035856] [Batch 01773/04869] [00:19:32/00:34:07, 0.661s/it]: train_loss_raw=1.3485, running_loss=1.3248, LR=0.000100
[2025-08-26 06:16:12,084][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035864] [Batch 01781/04869] [00:19:37/00:34:01, 0.661s/it]: train_loss_raw=1.3571, running_loss=1.3239, LR=0.000100
[2025-08-26 06:16:17,828][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035872] [Batch 01789/04869] [00:19:43/00:33:57, 0.661s/it]: train_loss_raw=1.1875, running_loss=1.3238, LR=0.000100
[2025-08-26 06:16:23,128][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035880] [Batch 01797/04869] [00:19:48/00:33:52, 0.661s/it]: train_loss_raw=1.3771, running_loss=1.3265, LR=0.000100
[2025-08-26 06:16:28,936][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035888] [Batch 01805/04869] [00:19:54/00:33:47, 0.662s/it]: train_loss_raw=1.3350, running_loss=1.3258, LR=0.000100
[2025-08-26 06:16:34,429][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035896] [Batch 01813/04869] [00:19:59/00:33:42, 0.662s/it]: train_loss_raw=1.4049, running_loss=1.3284, LR=0.000100
[2025-08-26 06:16:39,562][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035904] [Batch 01821/04869] [00:20:05/00:33:37, 0.662s/it]: train_loss_raw=1.2926, running_loss=1.3306, LR=0.000100
[2025-08-26 06:16:44,690][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035912] [Batch 01829/04869] [00:20:10/00:33:31, 0.662s/it]: train_loss_raw=1.2759, running_loss=1.3301, LR=0.000100
[2025-08-26 06:16:49,959][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035920] [Batch 01837/04869] [00:20:15/00:33:26, 0.662s/it]: train_loss_raw=1.3851, running_loss=1.3286, LR=0.000100
[2025-08-26 06:16:55,104][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035928] [Batch 01845/04869] [00:20:20/00:33:20, 0.662s/it]: train_loss_raw=1.2384, running_loss=1.3254, LR=0.000100
[2025-08-26 06:17:00,252][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035936] [Batch 01853/04869] [00:20:25/00:33:15, 0.662s/it]: train_loss_raw=1.4082, running_loss=1.3242, LR=0.000100
[2025-08-26 06:17:05,406][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035944] [Batch 01861/04869] [00:20:30/00:33:09, 0.661s/it]: train_loss_raw=1.3257, running_loss=1.3236, LR=0.000100
[2025-08-26 06:17:10,677][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035952] [Batch 01869/04869] [00:20:36/00:33:04, 0.661s/it]: train_loss_raw=1.3854, running_loss=1.3262, LR=0.000100
[2025-08-26 06:17:15,850][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035960] [Batch 01877/04869] [00:20:41/00:32:58, 0.661s/it]: train_loss_raw=1.3922, running_loss=1.3267, LR=0.000100
[2025-08-26 06:17:21,740][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035968] [Batch 01885/04869] [00:20:47/00:32:54, 0.662s/it]: train_loss_raw=1.2499, running_loss=1.3260, LR=0.000100
[2025-08-26 06:17:27,999][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035976] [Batch 01893/04869] [00:20:53/00:32:50, 0.662s/it]: train_loss_raw=1.2420, running_loss=1.3262, LR=0.000100
[2025-08-26 06:17:33,423][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035984] [Batch 01901/04869] [00:20:58/00:32:45, 0.662s/it]: train_loss_raw=1.3983, running_loss=1.3264, LR=0.000100
[2025-08-26 06:17:38,571][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 035992] [Batch 01909/04869] [00:21:04/00:32:40, 0.662s/it]: train_loss_raw=1.2494, running_loss=1.3236, LR=0.000100
[2025-08-26 06:17:44,653][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036000] [Batch 01917/04869] [00:21:10/00:32:36, 0.663s/it]: train_loss_raw=1.3485, running_loss=1.3241, LR=0.000100
[2025-08-26 06:17:53,738][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036008] [Batch 01925/04869] [00:21:19/00:32:36, 0.665s/it]: train_loss_raw=1.3417, running_loss=1.3221, LR=0.000100
[2025-08-26 06:17:59,214][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036016] [Batch 01933/04869] [00:21:24/00:32:31, 0.665s/it]: train_loss_raw=1.3946, running_loss=1.3227, LR=0.000100
[2025-08-26 06:18:04,334][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036024] [Batch 01941/04869] [00:21:29/00:32:25, 0.665s/it]: train_loss_raw=1.3332, running_loss=1.3221, LR=0.000100
[2025-08-26 06:18:09,457][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036032] [Batch 01949/04869] [00:21:35/00:32:20, 0.664s/it]: train_loss_raw=1.2974, running_loss=1.3225, LR=0.000100
[2025-08-26 06:18:14,589][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036040] [Batch 01957/04869] [00:21:40/00:32:14, 0.664s/it]: train_loss_raw=1.2521, running_loss=1.3231, LR=0.000100
[2025-08-26 06:18:19,830][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036048] [Batch 01965/04869] [00:21:45/00:32:09, 0.664s/it]: train_loss_raw=1.1786, running_loss=1.3184, LR=0.000100
[2025-08-26 06:18:24,968][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036056] [Batch 01973/04869] [00:21:50/00:32:03, 0.664s/it]: train_loss_raw=1.3948, running_loss=1.3195, LR=0.000100
[2025-08-26 06:18:30,096][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036064] [Batch 01981/04869] [00:21:55/00:31:58, 0.664s/it]: train_loss_raw=1.2333, running_loss=1.3209, LR=0.000100
[2025-08-26 06:18:35,233][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036072] [Batch 01989/04869] [00:22:00/00:31:52, 0.664s/it]: train_loss_raw=1.3720, running_loss=1.3226, LR=0.000100
[2025-08-26 06:18:40,861][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036080] [Batch 01997/04869] [00:22:06/00:31:47, 0.664s/it]: train_loss_raw=1.3906, running_loss=1.3233, LR=0.000100
[2025-08-26 06:18:45,982][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036088] [Batch 02005/04869] [00:22:11/00:31:42, 0.664s/it]: train_loss_raw=1.2142, running_loss=1.3209, LR=0.000100
[2025-08-26 06:18:51,119][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036096] [Batch 02013/04869] [00:22:16/00:31:36, 0.664s/it]: train_loss_raw=1.4480, running_loss=1.3197, LR=0.000100
[2025-08-26 06:18:56,386][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036104] [Batch 02021/04869] [00:22:21/00:31:31, 0.664s/it]: train_loss_raw=1.2685, running_loss=1.3179, LR=0.000100
[2025-08-26 06:19:01,661][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036112] [Batch 02029/04869] [00:22:27/00:31:25, 0.664s/it]: train_loss_raw=1.3283, running_loss=1.3198, LR=0.000100
[2025-08-26 06:19:06,803][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036120] [Batch 02037/04869] [00:22:32/00:31:20, 0.664s/it]: train_loss_raw=1.5793, running_loss=1.3206, LR=0.000100
[2025-08-26 06:19:11,936][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036128] [Batch 02045/04869] [00:22:37/00:31:14, 0.664s/it]: train_loss_raw=1.3876, running_loss=1.3230, LR=0.000100
[2025-08-26 06:19:17,084][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036136] [Batch 02053/04869] [00:22:42/00:31:09, 0.664s/it]: train_loss_raw=1.3785, running_loss=1.3230, LR=0.000100
[2025-08-26 06:19:22,219][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036144] [Batch 02061/04869] [00:22:47/00:31:03, 0.664s/it]: train_loss_raw=1.3735, running_loss=1.3242, LR=0.000100
[2025-08-26 06:19:27,441][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036152] [Batch 02069/04869] [00:22:53/00:30:58, 0.664s/it]: train_loss_raw=1.4385, running_loss=1.3267, LR=0.000100
[2025-08-26 06:19:32,657][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036160] [Batch 02077/04869] [00:22:58/00:30:52, 0.664s/it]: train_loss_raw=1.3236, running_loss=1.3295, LR=0.000100
[2025-08-26 06:19:37,776][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036168] [Batch 02085/04869] [00:23:03/00:30:47, 0.663s/it]: train_loss_raw=1.3075, running_loss=1.3325, LR=0.000100
[2025-08-26 06:19:42,893][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036176] [Batch 02093/04869] [00:23:08/00:30:41, 0.663s/it]: train_loss_raw=1.2414, running_loss=1.3301, LR=0.000100
[2025-08-26 06:19:48,024][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036184] [Batch 02101/04869] [00:23:13/00:30:36, 0.663s/it]: train_loss_raw=1.3074, running_loss=1.3325, LR=0.000100
[2025-08-26 06:19:53,154][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036192] [Batch 02109/04869] [00:23:18/00:30:30, 0.663s/it]: train_loss_raw=1.3785, running_loss=1.3344, LR=0.000100
[2025-08-26 06:19:58,275][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036200] [Batch 02117/04869] [00:23:23/00:30:24, 0.663s/it]: train_loss_raw=1.2624, running_loss=1.3324, LR=0.000100
[2025-08-26 06:20:03,409][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036208] [Batch 02125/04869] [00:23:28/00:30:19, 0.663s/it]: train_loss_raw=1.3363, running_loss=1.3307, LR=0.000100
[2025-08-26 06:20:08,528][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036216] [Batch 02133/04869] [00:23:34/00:30:13, 0.663s/it]: train_loss_raw=1.2927, running_loss=1.3305, LR=0.000100
[2025-08-26 06:20:13,649][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036224] [Batch 02141/04869] [00:23:39/00:30:08, 0.663s/it]: train_loss_raw=1.3194, running_loss=1.3303, LR=0.000100
[2025-08-26 06:20:18,771][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036232] [Batch 02149/04869] [00:23:44/00:30:02, 0.663s/it]: train_loss_raw=1.2834, running_loss=1.3310, LR=0.000100
[2025-08-26 06:20:24,115][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036240] [Batch 02157/04869] [00:23:49/00:29:57, 0.663s/it]: train_loss_raw=1.2879, running_loss=1.3263, LR=0.000100
[2025-08-26 06:20:29,248][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036248] [Batch 02165/04869] [00:23:54/00:29:52, 0.663s/it]: train_loss_raw=1.2806, running_loss=1.3262, LR=0.000100
[2025-08-26 06:20:34,383][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036256] [Batch 02173/04869] [00:23:59/00:29:46, 0.663s/it]: train_loss_raw=1.3126, running_loss=1.3251, LR=0.000100
[2025-08-26 06:20:39,498][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036264] [Batch 02181/04869] [00:24:05/00:29:40, 0.663s/it]: train_loss_raw=1.4643, running_loss=1.3251, LR=0.000100
[2025-08-26 06:20:44,761][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036272] [Batch 02189/04869] [00:24:10/00:29:35, 0.663s/it]: train_loss_raw=1.2860, running_loss=1.3222, LR=0.000100
[2025-08-26 06:20:49,888][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036280] [Batch 02197/04869] [00:24:15/00:29:30, 0.662s/it]: train_loss_raw=1.3174, running_loss=1.3198, LR=0.000100
[2025-08-26 06:20:55,400][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036288] [Batch 02205/04869] [00:24:20/00:29:25, 0.663s/it]: train_loss_raw=1.3087, running_loss=1.3201, LR=0.000100
[2025-08-26 06:21:00,666][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036296] [Batch 02213/04869] [00:24:26/00:29:19, 0.663s/it]: train_loss_raw=1.2654, running_loss=1.3185, LR=0.000100
[2025-08-26 06:21:05,941][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036304] [Batch 02221/04869] [00:24:31/00:29:14, 0.663s/it]: train_loss_raw=1.3469, running_loss=1.3169, LR=0.000100
[2025-08-26 06:21:11,064][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036312] [Batch 02229/04869] [00:24:36/00:29:08, 0.662s/it]: train_loss_raw=1.3355, running_loss=1.3177, LR=0.000100
[2025-08-26 06:21:16,284][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036320] [Batch 02237/04869] [00:24:41/00:29:03, 0.662s/it]: train_loss_raw=1.2933, running_loss=1.3172, LR=0.000100
[2025-08-26 06:21:21,423][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036328] [Batch 02245/04869] [00:24:46/00:28:58, 0.662s/it]: train_loss_raw=1.2680, running_loss=1.3163, LR=0.000100
[2025-08-26 06:21:26,575][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036336] [Batch 02253/04869] [00:24:52/00:28:52, 0.662s/it]: train_loss_raw=1.3373, running_loss=1.3184, LR=0.000100
[2025-08-26 06:21:31,726][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036344] [Batch 02261/04869] [00:24:57/00:28:47, 0.662s/it]: train_loss_raw=1.4178, running_loss=1.3190, LR=0.000100
[2025-08-26 06:21:36,858][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036352] [Batch 02269/04869] [00:25:02/00:28:41, 0.662s/it]: train_loss_raw=1.2617, running_loss=1.3193, LR=0.000100
[2025-08-26 06:21:41,997][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036360] [Batch 02277/04869] [00:25:07/00:28:36, 0.662s/it]: train_loss_raw=1.3582, running_loss=1.3203, LR=0.000100
[2025-08-26 06:21:47,225][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036368] [Batch 02285/04869] [00:25:12/00:28:30, 0.662s/it]: train_loss_raw=1.3754, running_loss=1.3199, LR=0.000100
[2025-08-26 06:21:52,816][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036376] [Batch 02293/04869] [00:25:18/00:28:25, 0.662s/it]: train_loss_raw=1.2646, running_loss=1.3183, LR=0.000100
[2025-08-26 06:21:58,051][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036384] [Batch 02301/04869] [00:25:23/00:28:20, 0.662s/it]: train_loss_raw=1.3099, running_loss=1.3191, LR=0.000100
[2025-08-26 06:22:03,206][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036392] [Batch 02309/04869] [00:25:28/00:28:14, 0.662s/it]: train_loss_raw=1.2567, running_loss=1.3166, LR=0.000100
[2025-08-26 06:22:08,464][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036400] [Batch 02317/04869] [00:25:34/00:28:09, 0.662s/it]: train_loss_raw=1.3054, running_loss=1.3173, LR=0.000100
[2025-08-26 06:22:13,832][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036408] [Batch 02325/04869] [00:25:39/00:28:04, 0.662s/it]: train_loss_raw=1.3815, running_loss=1.3167, LR=0.000100
[2025-08-26 06:22:19,446][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036416] [Batch 02333/04869] [00:25:45/00:27:59, 0.662s/it]: train_loss_raw=1.2829, running_loss=1.3149, LR=0.000100
[2025-08-26 06:22:24,664][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036424] [Batch 02341/04869] [00:25:50/00:27:54, 0.662s/it]: train_loss_raw=1.2908, running_loss=1.3156, LR=0.000100
[2025-08-26 06:22:29,926][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036432] [Batch 02349/04869] [00:25:55/00:27:48, 0.662s/it]: train_loss_raw=1.3923, running_loss=1.3175, LR=0.000100
[2025-08-26 06:22:35,155][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036440] [Batch 02357/04869] [00:26:00/00:27:43, 0.662s/it]: train_loss_raw=1.4568, running_loss=1.3182, LR=0.000100
[2025-08-26 06:22:40,354][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036448] [Batch 02365/04869] [00:26:05/00:27:37, 0.662s/it]: train_loss_raw=1.1939, running_loss=1.3158, LR=0.000100
[2025-08-26 06:22:45,994][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036456] [Batch 02373/04869] [00:26:11/00:27:33, 0.662s/it]: train_loss_raw=1.2672, running_loss=1.3140, LR=0.000100
[2025-08-26 06:22:51,951][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036464] [Batch 02381/04869] [00:26:17/00:27:28, 0.663s/it]: train_loss_raw=1.2129, running_loss=1.3152, LR=0.000100
[2025-08-26 06:22:57,086][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036472] [Batch 02389/04869] [00:26:22/00:27:22, 0.662s/it]: train_loss_raw=1.3388, running_loss=1.3155, LR=0.000100
[2025-08-26 06:23:02,238][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036480] [Batch 02397/04869] [00:26:27/00:27:17, 0.662s/it]: train_loss_raw=1.3236, running_loss=1.3123, LR=0.000100
[2025-08-26 06:23:07,390][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036488] [Batch 02405/04869] [00:26:32/00:27:12, 0.662s/it]: train_loss_raw=1.3821, running_loss=1.3146, LR=0.000100
[2025-08-26 06:23:12,533][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036496] [Batch 02413/04869] [00:26:38/00:27:06, 0.662s/it]: train_loss_raw=1.3239, running_loss=1.3142, LR=0.000100
[2025-08-26 06:23:17,684][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036504] [Batch 02421/04869] [00:26:43/00:27:01, 0.662s/it]: train_loss_raw=1.3690, running_loss=1.3164, LR=0.000100
[2025-08-26 06:23:23,046][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036512] [Batch 02429/04869] [00:26:48/00:26:55, 0.662s/it]: train_loss_raw=1.2985, running_loss=1.3169, LR=0.000100
[2025-08-26 06:23:28,169][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036520] [Batch 02437/04869] [00:26:53/00:26:50, 0.662s/it]: train_loss_raw=1.2315, running_loss=1.3161, LR=0.000100
[2025-08-26 06:23:33,315][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036528] [Batch 02445/04869] [00:26:58/00:26:44, 0.662s/it]: train_loss_raw=1.3299, running_loss=1.3165, LR=0.000100
[2025-08-26 06:23:38,454][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036536] [Batch 02453/04869] [00:27:04/00:26:39, 0.662s/it]: train_loss_raw=1.3061, running_loss=1.3182, LR=0.000100
[2025-08-26 06:23:43,593][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036544] [Batch 02461/04869] [00:27:09/00:26:34, 0.662s/it]: train_loss_raw=1.2798, running_loss=1.3151, LR=0.000100
[2025-08-26 06:23:48,740][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036552] [Batch 02469/04869] [00:27:14/00:26:28, 0.662s/it]: train_loss_raw=1.2969, running_loss=1.3155, LR=0.000100
[2025-08-26 06:23:53,881][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036560] [Batch 02477/04869] [00:27:19/00:26:23, 0.662s/it]: train_loss_raw=1.1878, running_loss=1.3167, LR=0.000100
[2025-08-26 06:23:59,022][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036568] [Batch 02485/04869] [00:27:24/00:26:17, 0.662s/it]: train_loss_raw=1.2692, running_loss=1.3138, LR=0.000100
[2025-08-26 06:24:04,174][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036576] [Batch 02493/04869] [00:27:29/00:26:12, 0.662s/it]: train_loss_raw=1.2725, running_loss=1.3141, LR=0.000100
[2025-08-26 06:24:09,303][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036584] [Batch 02501/04869] [00:27:34/00:26:06, 0.662s/it]: train_loss_raw=1.1774, running_loss=1.3132, LR=0.000100
[2025-08-26 06:24:14,431][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036592] [Batch 02509/04869] [00:27:39/00:26:01, 0.662s/it]: train_loss_raw=1.3278, running_loss=1.3131, LR=0.000100
[2025-08-26 06:24:19,580][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036600] [Batch 02517/04869] [00:27:45/00:25:55, 0.662s/it]: train_loss_raw=1.2555, running_loss=1.3150, LR=0.000100
[2025-08-26 06:24:24,721][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036608] [Batch 02525/04869] [00:27:50/00:25:50, 0.661s/it]: train_loss_raw=1.3321, running_loss=1.3176, LR=0.000100
[2025-08-26 06:24:30,046][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036616] [Batch 02533/04869] [00:27:55/00:25:45, 0.662s/it]: train_loss_raw=1.2338, running_loss=1.3182, LR=0.000100
[2025-08-26 06:24:35,209][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036624] [Batch 02541/04869] [00:28:00/00:25:39, 0.661s/it]: train_loss_raw=1.3149, running_loss=1.3148, LR=0.000100
[2025-08-26 06:24:40,363][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036632] [Batch 02549/04869] [00:28:05/00:25:34, 0.661s/it]: train_loss_raw=1.2576, running_loss=1.3144, LR=0.000100
[2025-08-26 06:24:45,512][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036640] [Batch 02557/04869] [00:28:11/00:25:29, 0.661s/it]: train_loss_raw=1.4082, running_loss=1.3167, LR=0.000100
[2025-08-26 06:24:50,664][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036648] [Batch 02565/04869] [00:28:16/00:25:23, 0.661s/it]: train_loss_raw=1.2125, running_loss=1.3177, LR=0.000100
[2025-08-26 06:24:55,831][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036656] [Batch 02573/04869] [00:28:21/00:25:18, 0.661s/it]: train_loss_raw=1.3125, running_loss=1.3206, LR=0.000100
[2025-08-26 06:25:01,672][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036664] [Batch 02581/04869] [00:28:27/00:25:13, 0.661s/it]: train_loss_raw=1.3197, running_loss=1.3219, LR=0.000100
[2025-08-26 06:25:07,130][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036672] [Batch 02589/04869] [00:28:32/00:25:08, 0.662s/it]: train_loss_raw=1.1931, running_loss=1.3181, LR=0.000100
[2025-08-26 06:25:12,286][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036680] [Batch 02597/04869] [00:28:37/00:25:02, 0.661s/it]: train_loss_raw=1.2949, running_loss=1.3177, LR=0.000100
[2025-08-26 06:25:17,466][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036688] [Batch 02605/04869] [00:28:43/00:24:57, 0.661s/it]: train_loss_raw=1.4314, running_loss=1.3175, LR=0.000100
[2025-08-26 06:25:22,919][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036696] [Batch 02613/04869] [00:28:48/00:24:52, 0.661s/it]: train_loss_raw=1.2859, running_loss=1.3157, LR=0.000100
[2025-08-26 06:25:28,294][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036704] [Batch 02621/04869] [00:28:53/00:24:47, 0.662s/it]: train_loss_raw=1.2615, running_loss=1.3151, LR=0.000100
[2025-08-26 06:25:33,474][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036712] [Batch 02629/04869] [00:28:59/00:24:41, 0.661s/it]: train_loss_raw=1.2412, running_loss=1.3145, LR=0.000100
[2025-08-26 06:25:38,612][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036720] [Batch 02637/04869] [00:29:04/00:24:36, 0.661s/it]: train_loss_raw=1.3138, running_loss=1.3143, LR=0.000100
[2025-08-26 06:25:43,758][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036728] [Batch 02645/04869] [00:29:09/00:24:30, 0.661s/it]: train_loss_raw=1.3300, running_loss=1.3129, LR=0.000100
[2025-08-26 06:25:49,067][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036736] [Batch 02653/04869] [00:29:14/00:24:25, 0.661s/it]: train_loss_raw=1.3850, running_loss=1.3164, LR=0.000100
[2025-08-26 06:25:54,213][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036744] [Batch 02661/04869] [00:29:19/00:24:20, 0.661s/it]: train_loss_raw=1.4112, running_loss=1.3198, LR=0.000100
[2025-08-26 06:25:59,365][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036752] [Batch 02669/04869] [00:29:24/00:24:14, 0.661s/it]: train_loss_raw=1.3642, running_loss=1.3198, LR=0.000100
[2025-08-26 06:26:04,667][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036760] [Batch 02677/04869] [00:29:30/00:24:09, 0.661s/it]: train_loss_raw=1.3340, running_loss=1.3209, LR=0.000100
[2025-08-26 06:26:10,312][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036768] [Batch 02685/04869] [00:29:35/00:24:04, 0.661s/it]: train_loss_raw=1.3572, running_loss=1.3228, LR=0.000100
[2025-08-26 06:26:15,465][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036776] [Batch 02693/04869] [00:29:41/00:23:59, 0.661s/it]: train_loss_raw=1.2223, running_loss=1.3188, LR=0.000100
[2025-08-26 06:26:20,613][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036784] [Batch 02701/04869] [00:29:46/00:23:53, 0.661s/it]: train_loss_raw=1.2734, running_loss=1.3166, LR=0.000100
[2025-08-26 06:26:25,766][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036792] [Batch 02709/04869] [00:29:51/00:23:48, 0.661s/it]: train_loss_raw=1.2591, running_loss=1.3150, LR=0.000100
[2025-08-26 06:26:30,935][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036800] [Batch 02717/04869] [00:29:56/00:23:42, 0.661s/it]: train_loss_raw=1.3262, running_loss=1.3190, LR=0.000100
[2025-08-26 06:26:36,094][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036808] [Batch 02725/04869] [00:30:01/00:23:37, 0.661s/it]: train_loss_raw=1.3416, running_loss=1.3199, LR=0.000100
[2025-08-26 06:26:41,581][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036816] [Batch 02733/04869] [00:30:07/00:23:32, 0.661s/it]: train_loss_raw=1.3278, running_loss=1.3193, LR=0.000100
[2025-08-26 06:26:46,744][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036824] [Batch 02741/04869] [00:30:12/00:23:27, 0.661s/it]: train_loss_raw=1.2909, running_loss=1.3199, LR=0.000100
[2025-08-26 06:26:51,900][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036832] [Batch 02749/04869] [00:30:17/00:23:21, 0.661s/it]: train_loss_raw=1.3521, running_loss=1.3158, LR=0.000100
[2025-08-26 06:26:57,046][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036840] [Batch 02757/04869] [00:30:22/00:23:16, 0.661s/it]: train_loss_raw=1.3273, running_loss=1.3139, LR=0.000100
[2025-08-26 06:27:02,208][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036848] [Batch 02765/04869] [00:30:27/00:23:10, 0.661s/it]: train_loss_raw=1.4288, running_loss=1.3177, LR=0.000100
[2025-08-26 06:27:07,358][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036856] [Batch 02773/04869] [00:30:32/00:23:05, 0.661s/it]: train_loss_raw=1.3244, running_loss=1.3166, LR=0.000100
[2025-08-26 06:27:13,020][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036864] [Batch 02781/04869] [00:30:38/00:23:00, 0.661s/it]: train_loss_raw=1.2709, running_loss=1.3149, LR=0.000100
[2025-08-26 06:27:18,421][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036872] [Batch 02789/04869] [00:30:43/00:22:55, 0.661s/it]: train_loss_raw=1.3080, running_loss=1.3130, LR=0.000100
[2025-08-26 06:27:23,568][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036880] [Batch 02797/04869] [00:30:49/00:22:49, 0.661s/it]: train_loss_raw=1.2432, running_loss=1.3116, LR=0.000100
[2025-08-26 06:27:28,712][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036888] [Batch 02805/04869] [00:30:54/00:22:44, 0.661s/it]: train_loss_raw=1.3203, running_loss=1.3120, LR=0.000100
[2025-08-26 06:27:34,347][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036896] [Batch 02813/04869] [00:30:59/00:22:39, 0.661s/it]: train_loss_raw=1.2601, running_loss=1.3127, LR=0.000100
[2025-08-26 06:27:39,493][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036904] [Batch 02821/04869] [00:31:05/00:22:33, 0.661s/it]: train_loss_raw=1.3463, running_loss=1.3107, LR=0.000100
[2025-08-26 06:27:44,637][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036912] [Batch 02829/04869] [00:31:10/00:22:28, 0.661s/it]: train_loss_raw=1.3400, running_loss=1.3108, LR=0.000100
[2025-08-26 06:27:49,790][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036920] [Batch 02837/04869] [00:31:15/00:22:23, 0.661s/it]: train_loss_raw=1.3129, running_loss=1.3110, LR=0.000100
[2025-08-26 06:27:54,932][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036928] [Batch 02845/04869] [00:31:20/00:22:17, 0.661s/it]: train_loss_raw=1.3297, running_loss=1.3138, LR=0.000100
[2025-08-26 06:28:00,560][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036936] [Batch 02853/04869] [00:31:26/00:22:12, 0.661s/it]: train_loss_raw=1.3891, running_loss=1.3145, LR=0.000100
[2025-08-26 06:28:05,706][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036944] [Batch 02861/04869] [00:31:31/00:22:07, 0.661s/it]: train_loss_raw=1.4239, running_loss=1.3154, LR=0.000100
[2025-08-26 06:28:10,853][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036952] [Batch 02869/04869] [00:31:36/00:22:02, 0.661s/it]: train_loss_raw=1.2791, running_loss=1.3134, LR=0.000100
[2025-08-26 06:28:16,283][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036960] [Batch 02877/04869] [00:31:41/00:21:56, 0.661s/it]: train_loss_raw=1.3757, running_loss=1.3140, LR=0.000100
[2025-08-26 06:28:21,577][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036968] [Batch 02885/04869] [00:31:47/00:21:51, 0.661s/it]: train_loss_raw=1.1810, running_loss=1.3141, LR=0.000100
[2025-08-26 06:28:26,726][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036976] [Batch 02893/04869] [00:31:52/00:21:46, 0.661s/it]: train_loss_raw=1.2802, running_loss=1.3137, LR=0.000100
[2025-08-26 06:28:31,869][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036984] [Batch 02901/04869] [00:31:57/00:21:40, 0.661s/it]: train_loss_raw=1.3552, running_loss=1.3140, LR=0.000100
[2025-08-26 06:28:37,015][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 036992] [Batch 02909/04869] [00:32:02/00:21:35, 0.661s/it]: train_loss_raw=1.3069, running_loss=1.3120, LR=0.000100
[2025-08-26 06:28:42,353][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037000] [Batch 02917/04869] [00:32:07/00:21:30, 0.661s/it]: train_loss_raw=1.2663, running_loss=1.3125, LR=0.000100
[2025-08-26 06:28:47,991][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037008] [Batch 02925/04869] [00:32:13/00:21:25, 0.661s/it]: train_loss_raw=1.2935, running_loss=1.3103, LR=0.000100
[2025-08-26 06:28:54,040][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037016] [Batch 02933/04869] [00:32:19/00:21:20, 0.661s/it]: train_loss_raw=1.1734, running_loss=1.3090, LR=0.000100
[2025-08-26 06:28:59,316][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037024] [Batch 02941/04869] [00:32:24/00:21:14, 0.661s/it]: train_loss_raw=1.3577, running_loss=1.3101, LR=0.000100
[2025-08-26 06:29:04,510][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037032] [Batch 02949/04869] [00:32:30/00:21:09, 0.661s/it]: train_loss_raw=1.4741, running_loss=1.3125, LR=0.000100
[2025-08-26 06:29:09,699][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037040] [Batch 02957/04869] [00:32:35/00:21:04, 0.661s/it]: train_loss_raw=1.2796, running_loss=1.3136, LR=0.000100
[2025-08-26 06:29:15,311][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037048] [Batch 02965/04869] [00:32:40/00:20:59, 0.661s/it]: train_loss_raw=1.2957, running_loss=1.3133, LR=0.000100
[2025-08-26 06:29:20,737][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037056] [Batch 02973/04869] [00:32:46/00:20:53, 0.661s/it]: train_loss_raw=1.3301, running_loss=1.3115, LR=0.000100
[2025-08-26 06:29:26,070][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037064] [Batch 02981/04869] [00:32:51/00:20:48, 0.661s/it]: train_loss_raw=1.3394, running_loss=1.3129, LR=0.000100
[2025-08-26 06:29:31,337][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037072] [Batch 02989/04869] [00:32:56/00:20:43, 0.661s/it]: train_loss_raw=1.3776, running_loss=1.3109, LR=0.000100
[2025-08-26 06:29:36,776][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037080] [Batch 02997/04869] [00:33:02/00:20:38, 0.661s/it]: train_loss_raw=1.4194, running_loss=1.3126, LR=0.000100
[2025-08-26 06:29:41,910][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037088] [Batch 03005/04869] [00:33:07/00:20:32, 0.661s/it]: train_loss_raw=1.3274, running_loss=1.3115, LR=0.000100
[2025-08-26 06:29:47,052][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037096] [Batch 03013/04869] [00:33:12/00:20:27, 0.661s/it]: train_loss_raw=1.2483, running_loss=1.3110, LR=0.000100
[2025-08-26 06:29:52,193][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037104] [Batch 03021/04869] [00:33:17/00:20:22, 0.661s/it]: train_loss_raw=1.3347, running_loss=1.3101, LR=0.000100
[2025-08-26 06:29:57,557][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037112] [Batch 03029/04869] [00:33:23/00:20:16, 0.661s/it]: train_loss_raw=1.2299, running_loss=1.3117, LR=0.000100
[2025-08-26 06:30:02,710][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037120] [Batch 03037/04869] [00:33:28/00:20:11, 0.661s/it]: train_loss_raw=1.3817, running_loss=1.3144, LR=0.000100
[2025-08-26 06:30:07,968][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037128] [Batch 03045/04869] [00:33:33/00:20:06, 0.661s/it]: train_loss_raw=1.3373, running_loss=1.3166, LR=0.000100
[2025-08-26 06:30:14,296][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037136] [Batch 03053/04869] [00:33:39/00:20:01, 0.662s/it]: train_loss_raw=1.3595, running_loss=1.3144, LR=0.000100
[2025-08-26 06:30:19,815][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037144] [Batch 03061/04869] [00:33:45/00:19:56, 0.662s/it]: train_loss_raw=1.3342, running_loss=1.3151, LR=0.000100
[2025-08-26 06:30:25,083][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037152] [Batch 03069/04869] [00:33:50/00:19:50, 0.662s/it]: train_loss_raw=1.2880, running_loss=1.3124, LR=0.000100
[2025-08-26 06:30:31,026][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037160] [Batch 03077/04869] [00:33:56/00:19:46, 0.662s/it]: train_loss_raw=1.3227, running_loss=1.3114, LR=0.000100
[2025-08-26 06:30:36,333][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037168] [Batch 03085/04869] [00:34:01/00:19:40, 0.662s/it]: train_loss_raw=1.4244, running_loss=1.3121, LR=0.000100
[2025-08-26 06:30:41,789][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037176] [Batch 03093/04869] [00:34:07/00:19:35, 0.662s/it]: train_loss_raw=1.4414, running_loss=1.3131, LR=0.000100
[2025-08-26 06:30:47,076][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037184] [Batch 03101/04869] [00:34:12/00:19:30, 0.662s/it]: train_loss_raw=1.3924, running_loss=1.3122, LR=0.000100
[2025-08-26 06:30:52,697][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037192] [Batch 03109/04869] [00:34:18/00:19:25, 0.662s/it]: train_loss_raw=1.3347, running_loss=1.3140, LR=0.000100
[2025-08-26 06:30:57,844][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037200] [Batch 03117/04869] [00:34:23/00:19:19, 0.662s/it]: train_loss_raw=1.3974, running_loss=1.3145, LR=0.000100
[2025-08-26 06:31:03,367][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037208] [Batch 03125/04869] [00:34:28/00:19:14, 0.662s/it]: train_loss_raw=1.4071, running_loss=1.3156, LR=0.000100
[2025-08-26 06:31:08,633][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037216] [Batch 03133/04869] [00:34:34/00:19:09, 0.662s/it]: train_loss_raw=1.3001, running_loss=1.3157, LR=0.000100
[2025-08-26 06:31:14,140][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037224] [Batch 03141/04869] [00:34:39/00:19:04, 0.662s/it]: train_loss_raw=1.2106, running_loss=1.3161, LR=0.000100
[2025-08-26 06:31:19,275][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037232] [Batch 03149/04869] [00:34:44/00:18:58, 0.662s/it]: train_loss_raw=1.3503, running_loss=1.3179, LR=0.000100
[2025-08-26 06:31:24,404][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037240] [Batch 03157/04869] [00:34:49/00:18:53, 0.662s/it]: train_loss_raw=1.2583, running_loss=1.3170, LR=0.000100
[2025-08-26 06:31:29,547][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037248] [Batch 03165/04869] [00:34:55/00:18:47, 0.662s/it]: train_loss_raw=1.2721, running_loss=1.3164, LR=0.000100
[2025-08-26 06:31:34,723][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037256] [Batch 03173/04869] [00:35:00/00:18:42, 0.662s/it]: train_loss_raw=1.2144, running_loss=1.3154, LR=0.000100
[2025-08-26 06:31:40,127][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037264] [Batch 03181/04869] [00:35:05/00:18:37, 0.662s/it]: train_loss_raw=1.3749, running_loss=1.3124, LR=0.000100
[2025-08-26 06:31:45,406][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037272] [Batch 03189/04869] [00:35:10/00:18:32, 0.662s/it]: train_loss_raw=1.3309, running_loss=1.3104, LR=0.000100
[2025-08-26 06:31:50,634][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037280] [Batch 03197/04869] [00:35:16/00:18:26, 0.662s/it]: train_loss_raw=1.3981, running_loss=1.3125, LR=0.000100
[2025-08-26 06:31:55,772][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037288] [Batch 03205/04869] [00:35:21/00:18:21, 0.662s/it]: train_loss_raw=1.3492, running_loss=1.3113, LR=0.000100
[2025-08-26 06:32:01,676][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037296] [Batch 03213/04869] [00:35:27/00:18:16, 0.662s/it]: train_loss_raw=1.3780, running_loss=1.3126, LR=0.000100
[2025-08-26 06:32:07,375][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037304] [Batch 03221/04869] [00:35:32/00:18:11, 0.662s/it]: train_loss_raw=1.3047, running_loss=1.3130, LR=0.000100
[2025-08-26 06:32:13,217][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037312] [Batch 03229/04869] [00:35:38/00:18:06, 0.662s/it]: train_loss_raw=1.3723, running_loss=1.3179, LR=0.000100
[2025-08-26 06:32:18,672][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037320] [Batch 03237/04869] [00:35:44/00:18:01, 0.662s/it]: train_loss_raw=1.1940, running_loss=1.3170, LR=0.000100
[2025-08-26 06:32:23,815][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037328] [Batch 03245/04869] [00:35:49/00:17:55, 0.662s/it]: train_loss_raw=1.2444, running_loss=1.3155, LR=0.000100
[2025-08-26 06:32:28,957][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037336] [Batch 03253/04869] [00:35:54/00:17:50, 0.662s/it]: train_loss_raw=1.2314, running_loss=1.3147, LR=0.000100
[2025-08-26 06:32:34,332][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037344] [Batch 03261/04869] [00:35:59/00:17:45, 0.662s/it]: train_loss_raw=1.2356, running_loss=1.3129, LR=0.000100
[2025-08-26 06:32:39,461][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037352] [Batch 03269/04869] [00:36:05/00:17:39, 0.662s/it]: train_loss_raw=1.3022, running_loss=1.3119, LR=0.000100
[2025-08-26 06:32:44,811][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037360] [Batch 03277/04869] [00:36:10/00:17:34, 0.662s/it]: train_loss_raw=1.3207, running_loss=1.3113, LR=0.000100
[2025-08-26 06:32:49,927][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037368] [Batch 03285/04869] [00:36:15/00:17:29, 0.662s/it]: train_loss_raw=1.2620, running_loss=1.3122, LR=0.000100
[2025-08-26 06:32:55,060][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037376] [Batch 03293/04869] [00:36:20/00:17:23, 0.662s/it]: train_loss_raw=1.2299, running_loss=1.3107, LR=0.000100
[2025-08-26 06:33:00,221][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037384] [Batch 03301/04869] [00:36:25/00:17:18, 0.662s/it]: train_loss_raw=1.3995, running_loss=1.3113, LR=0.000100
[2025-08-26 06:33:05,385][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037392] [Batch 03309/04869] [00:36:30/00:17:12, 0.662s/it]: train_loss_raw=1.3087, running_loss=1.3104, LR=0.000100
[2025-08-26 06:33:10,672][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037400] [Batch 03317/04869] [00:36:36/00:17:07, 0.662s/it]: train_loss_raw=1.3539, running_loss=1.3116, LR=0.000100
[2025-08-26 06:33:15,813][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037408] [Batch 03325/04869] [00:36:41/00:17:02, 0.662s/it]: train_loss_raw=1.3322, running_loss=1.3125, LR=0.000100
[2025-08-26 06:33:20,945][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037416] [Batch 03333/04869] [00:36:46/00:16:56, 0.662s/it]: train_loss_raw=1.2999, running_loss=1.3118, LR=0.000100
[2025-08-26 06:33:26,065][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037424] [Batch 03341/04869] [00:36:51/00:16:51, 0.662s/it]: train_loss_raw=1.3445, running_loss=1.3108, LR=0.000100
[2025-08-26 06:33:31,190][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037432] [Batch 03349/04869] [00:36:56/00:16:46, 0.662s/it]: train_loss_raw=1.2703, running_loss=1.3127, LR=0.000100
[2025-08-26 06:33:36,310][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037440] [Batch 03357/04869] [00:37:01/00:16:40, 0.662s/it]: train_loss_raw=1.3876, running_loss=1.3116, LR=0.000100
[2025-08-26 06:33:41,430][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037448] [Batch 03365/04869] [00:37:06/00:16:35, 0.662s/it]: train_loss_raw=1.2512, running_loss=1.3082, LR=0.000100
[2025-08-26 06:33:46,568][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037456] [Batch 03373/04869] [00:37:12/00:16:29, 0.662s/it]: train_loss_raw=1.2735, running_loss=1.3093, LR=0.000100
[2025-08-26 06:33:51,998][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037464] [Batch 03381/04869] [00:37:17/00:16:24, 0.662s/it]: train_loss_raw=1.2411, running_loss=1.3090, LR=0.000100
[2025-08-26 06:33:57,540][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037472] [Batch 03389/04869] [00:37:23/00:16:19, 0.662s/it]: train_loss_raw=1.2733, running_loss=1.3079, LR=0.000100
[2025-08-26 06:34:02,674][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037480] [Batch 03397/04869] [00:37:28/00:16:14, 0.662s/it]: train_loss_raw=1.3295, running_loss=1.3073, LR=0.000100
[2025-08-26 06:34:07,802][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037488] [Batch 03405/04869] [00:37:33/00:16:08, 0.662s/it]: train_loss_raw=1.2253, running_loss=1.3048, LR=0.000100
[2025-08-26 06:34:12,928][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037496] [Batch 03413/04869] [00:37:38/00:16:03, 0.662s/it]: train_loss_raw=1.3919, running_loss=1.3060, LR=0.000100
[2025-08-26 06:34:18,053][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037504] [Batch 03421/04869] [00:37:43/00:15:58, 0.662s/it]: train_loss_raw=1.4441, running_loss=1.3052, LR=0.000100
[2025-08-26 06:34:23,173][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037512] [Batch 03429/04869] [00:37:48/00:15:52, 0.662s/it]: train_loss_raw=1.2240, running_loss=1.3032, LR=0.000100
[2025-08-26 06:34:28,294][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037520] [Batch 03437/04869] [00:37:53/00:15:47, 0.662s/it]: train_loss_raw=1.2946, running_loss=1.3003, LR=0.000100
[2025-08-26 06:34:33,766][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037528] [Batch 03445/04869] [00:37:59/00:15:42, 0.662s/it]: train_loss_raw=1.3333, running_loss=1.2996, LR=0.000100
[2025-08-26 06:34:38,888][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037536] [Batch 03453/04869] [00:38:04/00:15:36, 0.662s/it]: train_loss_raw=1.4373, running_loss=1.3007, LR=0.000100
[2025-08-26 06:34:44,013][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037544] [Batch 03461/04869] [00:38:09/00:15:31, 0.662s/it]: train_loss_raw=1.3170, running_loss=1.3007, LR=0.000100
[2025-08-26 06:34:49,218][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037552] [Batch 03469/04869] [00:38:14/00:15:26, 0.662s/it]: train_loss_raw=1.3215, running_loss=1.3009, LR=0.000100
[2025-08-26 06:34:54,327][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037560] [Batch 03477/04869] [00:38:19/00:15:20, 0.661s/it]: train_loss_raw=1.2582, running_loss=1.3012, LR=0.000100
[2025-08-26 06:34:59,452][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037568] [Batch 03485/04869] [00:38:25/00:15:15, 0.661s/it]: train_loss_raw=1.4126, running_loss=1.3017, LR=0.000100
[2025-08-26 06:35:04,586][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037576] [Batch 03493/04869] [00:38:30/00:15:10, 0.661s/it]: train_loss_raw=1.2392, running_loss=1.3020, LR=0.000100
[2025-08-26 06:35:09,719][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037584] [Batch 03501/04869] [00:38:35/00:15:04, 0.661s/it]: train_loss_raw=1.2256, running_loss=1.3017, LR=0.000100
[2025-08-26 06:35:14,966][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037592] [Batch 03509/04869] [00:38:40/00:14:59, 0.661s/it]: train_loss_raw=1.4395, running_loss=1.3048, LR=0.000100
[2025-08-26 06:35:20,096][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037600] [Batch 03517/04869] [00:38:45/00:14:54, 0.661s/it]: train_loss_raw=1.3083, running_loss=1.3050, LR=0.000100
[2025-08-26 06:35:25,238][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037608] [Batch 03525/04869] [00:38:50/00:14:48, 0.661s/it]: train_loss_raw=1.3649, running_loss=1.3057, LR=0.000100
[2025-08-26 06:35:30,378][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037616] [Batch 03533/04869] [00:38:55/00:14:43, 0.661s/it]: train_loss_raw=1.3182, running_loss=1.3054, LR=0.000100
[2025-08-26 06:35:35,519][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037624] [Batch 03541/04869] [00:39:01/00:14:37, 0.661s/it]: train_loss_raw=1.3344, running_loss=1.3073, LR=0.000100
[2025-08-26 06:35:40,746][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037632] [Batch 03549/04869] [00:39:06/00:14:32, 0.661s/it]: train_loss_raw=1.2966, running_loss=1.3075, LR=0.000100
[2025-08-26 06:35:45,898][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037640] [Batch 03557/04869] [00:39:11/00:14:27, 0.661s/it]: train_loss_raw=1.3796, running_loss=1.3065, LR=0.000100
[2025-08-26 06:35:51,925][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037648] [Batch 03565/04869] [00:39:17/00:14:22, 0.661s/it]: train_loss_raw=1.3945, running_loss=1.3065, LR=0.000100
[2025-08-26 06:35:57,476][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037656] [Batch 03573/04869] [00:39:23/00:14:17, 0.661s/it]: train_loss_raw=1.2196, running_loss=1.3063, LR=0.000100
[2025-08-26 06:36:02,591][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037664] [Batch 03581/04869] [00:39:28/00:14:11, 0.661s/it]: train_loss_raw=1.3070, running_loss=1.3068, LR=0.000100
[2025-08-26 06:36:07,711][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037672] [Batch 03589/04869] [00:39:33/00:14:06, 0.661s/it]: train_loss_raw=1.3291, running_loss=1.3054, LR=0.000100
[2025-08-26 06:36:12,852][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037680] [Batch 03597/04869] [00:39:38/00:14:01, 0.661s/it]: train_loss_raw=1.3092, running_loss=1.3048, LR=0.000100
[2025-08-26 06:36:18,339][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037688] [Batch 03605/04869] [00:39:43/00:13:55, 0.661s/it]: train_loss_raw=1.4172, running_loss=1.3070, LR=0.000100
[2025-08-26 06:36:23,467][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037696] [Batch 03613/04869] [00:39:49/00:13:50, 0.661s/it]: train_loss_raw=1.1492, running_loss=1.3040, LR=0.000100
[2025-08-26 06:36:28,592][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037704] [Batch 03621/04869] [00:39:54/00:13:45, 0.661s/it]: train_loss_raw=1.3925, running_loss=1.3054, LR=0.000100
[2025-08-26 06:36:34,047][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037712] [Batch 03629/04869] [00:39:59/00:13:39, 0.661s/it]: train_loss_raw=1.3353, running_loss=1.3087, LR=0.000100
[2025-08-26 06:36:39,187][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037720] [Batch 03637/04869] [00:40:04/00:13:34, 0.661s/it]: train_loss_raw=1.3032, running_loss=1.3104, LR=0.000100
[2025-08-26 06:36:44,927][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037728] [Batch 03645/04869] [00:40:10/00:13:29, 0.661s/it]: train_loss_raw=1.3770, running_loss=1.3098, LR=0.000100
[2025-08-26 06:36:50,058][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037736] [Batch 03653/04869] [00:40:15/00:13:24, 0.661s/it]: train_loss_raw=1.3428, running_loss=1.3106, LR=0.000100
[2025-08-26 06:36:55,190][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037744] [Batch 03661/04869] [00:40:20/00:13:18, 0.661s/it]: train_loss_raw=1.4763, running_loss=1.3133, LR=0.000100
[2025-08-26 06:37:00,335][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037752] [Batch 03669/04869] [00:40:25/00:13:13, 0.661s/it]: train_loss_raw=1.3220, running_loss=1.3109, LR=0.000100
[2025-08-26 06:37:05,476][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037760] [Batch 03677/04869] [00:40:31/00:13:08, 0.661s/it]: train_loss_raw=1.2836, running_loss=1.3119, LR=0.000100
[2025-08-26 06:37:11,376][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037768] [Batch 03685/04869] [00:40:36/00:13:02, 0.661s/it]: train_loss_raw=1.2623, running_loss=1.3076, LR=0.000100
[2025-08-26 06:37:16,912][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037776] [Batch 03693/04869] [00:40:42/00:12:57, 0.661s/it]: train_loss_raw=1.2877, running_loss=1.3070, LR=0.000100
[2025-08-26 06:37:22,174][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037784] [Batch 03701/04869] [00:40:47/00:12:52, 0.661s/it]: train_loss_raw=1.2611, running_loss=1.3052, LR=0.000100
[2025-08-26 06:37:27,336][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037792] [Batch 03709/04869] [00:40:52/00:12:47, 0.661s/it]: train_loss_raw=1.3164, running_loss=1.3051, LR=0.000100
[2025-08-26 06:37:32,844][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037800] [Batch 03717/04869] [00:40:58/00:12:41, 0.661s/it]: train_loss_raw=1.3269, running_loss=1.3032, LR=0.000100
[2025-08-26 06:37:38,103][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037808] [Batch 03725/04869] [00:41:03/00:12:36, 0.661s/it]: train_loss_raw=1.2584, running_loss=1.3026, LR=0.000100
[2025-08-26 06:37:43,258][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037816] [Batch 03733/04869] [00:41:08/00:12:31, 0.661s/it]: train_loss_raw=1.2861, running_loss=1.3016, LR=0.000100
[2025-08-26 06:37:48,438][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037824] [Batch 03741/04869] [00:41:13/00:12:25, 0.661s/it]: train_loss_raw=1.3170, running_loss=1.3031, LR=0.000100
[2025-08-26 06:37:53,592][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037832] [Batch 03749/04869] [00:41:19/00:12:20, 0.661s/it]: train_loss_raw=1.3016, running_loss=1.3027, LR=0.000100
[2025-08-26 06:37:58,779][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037840] [Batch 03757/04869] [00:41:24/00:12:15, 0.661s/it]: train_loss_raw=1.1820, running_loss=1.3031, LR=0.000100
[2025-08-26 06:38:03,920][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037848] [Batch 03765/04869] [00:41:29/00:12:09, 0.661s/it]: train_loss_raw=1.2277, running_loss=1.3046, LR=0.000100
[2025-08-26 06:38:09,062][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037856] [Batch 03773/04869] [00:41:34/00:12:04, 0.661s/it]: train_loss_raw=1.3627, running_loss=1.3063, LR=0.000100
[2025-08-26 06:38:14,280][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037864] [Batch 03781/04869] [00:41:39/00:11:59, 0.661s/it]: train_loss_raw=1.2844, running_loss=1.3080, LR=0.000100
[2025-08-26 06:38:19,414][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037872] [Batch 03789/04869] [00:41:44/00:11:54, 0.661s/it]: train_loss_raw=1.4173, running_loss=1.3119, LR=0.000100
[2025-08-26 06:38:24,794][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037880] [Batch 03797/04869] [00:41:50/00:11:48, 0.661s/it]: train_loss_raw=1.2759, running_loss=1.3085, LR=0.000100
[2025-08-26 06:38:30,102][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037888] [Batch 03805/04869] [00:41:55/00:11:43, 0.661s/it]: train_loss_raw=1.2407, running_loss=1.3051, LR=0.000100
[2025-08-26 06:38:35,354][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037896] [Batch 03813/04869] [00:42:00/00:11:38, 0.661s/it]: train_loss_raw=1.2861, running_loss=1.3038, LR=0.000100
[2025-08-26 06:38:40,501][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037904] [Batch 03821/04869] [00:42:06/00:11:32, 0.661s/it]: train_loss_raw=1.2972, running_loss=1.3035, LR=0.000100
[2025-08-26 06:38:45,654][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037912] [Batch 03829/04869] [00:42:11/00:11:27, 0.661s/it]: train_loss_raw=1.2708, running_loss=1.3034, LR=0.000100
[2025-08-26 06:38:50,801][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037920] [Batch 03837/04869] [00:42:16/00:11:22, 0.661s/it]: train_loss_raw=1.1725, running_loss=1.2987, LR=0.000100
[2025-08-26 06:38:57,001][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037928] [Batch 03845/04869] [00:42:22/00:11:17, 0.661s/it]: train_loss_raw=1.2171, running_loss=1.2990, LR=0.000100
[2025-08-26 06:39:02,307][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037936] [Batch 03853/04869] [00:42:27/00:11:11, 0.661s/it]: train_loss_raw=1.3492, running_loss=1.3004, LR=0.000100
[2025-08-26 06:39:14,074][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037944] [Batch 03861/04869] [00:42:39/00:11:08, 0.663s/it]: train_loss_raw=1.3300, running_loss=1.3006, LR=0.000100
[2025-08-26 06:39:19,541][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037952] [Batch 03869/04869] [00:42:45/00:11:02, 0.663s/it]: train_loss_raw=1.3063, running_loss=1.3019, LR=0.000100
[2025-08-26 06:39:24,693][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037960] [Batch 03877/04869] [00:42:50/00:10:57, 0.663s/it]: train_loss_raw=1.2627, running_loss=1.3015, LR=0.000100
[2025-08-26 06:39:29,849][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037968] [Batch 03885/04869] [00:42:55/00:10:52, 0.663s/it]: train_loss_raw=1.3618, running_loss=1.3019, LR=0.000100
[2025-08-26 06:39:35,005][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037976] [Batch 03893/04869] [00:43:00/00:10:46, 0.663s/it]: train_loss_raw=1.2877, running_loss=1.3033, LR=0.000100
[2025-08-26 06:39:40,157][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037984] [Batch 03901/04869] [00:43:05/00:10:41, 0.663s/it]: train_loss_raw=1.2155, running_loss=1.3031, LR=0.000100
[2025-08-26 06:39:45,299][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 037992] [Batch 03909/04869] [00:43:10/00:10:36, 0.663s/it]: train_loss_raw=1.2168, running_loss=1.3004, LR=0.000100
[2025-08-26 06:39:50,593][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038000] [Batch 03917/04869] [00:43:16/00:10:30, 0.663s/it]: train_loss_raw=1.3637, running_loss=1.3019, LR=0.000100
[2025-08-26 06:39:59,438][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038008] [Batch 03925/04869] [00:43:25/00:10:26, 0.664s/it]: train_loss_raw=1.3344, running_loss=1.3017, LR=0.000100
[2025-08-26 06:40:04,593][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038016] [Batch 03933/04869] [00:43:30/00:10:21, 0.664s/it]: train_loss_raw=1.3492, running_loss=1.3003, LR=0.000100
[2025-08-26 06:40:09,729][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038024] [Batch 03941/04869] [00:43:35/00:10:15, 0.664s/it]: train_loss_raw=1.2474, running_loss=1.3002, LR=0.000100
[2025-08-26 06:40:14,865][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038032] [Batch 03949/04869] [00:43:40/00:10:10, 0.664s/it]: train_loss_raw=1.2014, running_loss=1.3000, LR=0.000100
[2025-08-26 06:40:20,228][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038040] [Batch 03957/04869] [00:43:45/00:10:05, 0.664s/it]: train_loss_raw=1.2277, running_loss=1.3026, LR=0.000100
[2025-08-26 06:40:25,370][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038048] [Batch 03965/04869] [00:43:50/00:09:59, 0.664s/it]: train_loss_raw=1.2852, running_loss=1.3020, LR=0.000100
[2025-08-26 06:40:30,509][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038056] [Batch 03973/04869] [00:43:56/00:09:54, 0.663s/it]: train_loss_raw=1.3664, running_loss=1.3057, LR=0.000100
[2025-08-26 06:40:35,735][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038064] [Batch 03981/04869] [00:44:01/00:09:49, 0.663s/it]: train_loss_raw=1.3281, running_loss=1.3035, LR=0.000100
[2025-08-26 06:40:41,172][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038072] [Batch 03989/04869] [00:44:06/00:09:43, 0.664s/it]: train_loss_raw=1.2245, running_loss=1.3053, LR=0.000100
[2025-08-26 06:40:46,314][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038080] [Batch 03997/04869] [00:44:11/00:09:38, 0.663s/it]: train_loss_raw=1.3499, running_loss=1.3068, LR=0.000100
[2025-08-26 06:40:51,459][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038088] [Batch 04005/04869] [00:44:17/00:09:33, 0.663s/it]: train_loss_raw=1.3128, running_loss=1.3088, LR=0.000100
[2025-08-26 06:40:56,579][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038096] [Batch 04013/04869] [00:44:22/00:09:27, 0.663s/it]: train_loss_raw=1.2602, running_loss=1.3088, LR=0.000100
[2025-08-26 06:41:02,138][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038104] [Batch 04021/04869] [00:44:27/00:09:22, 0.663s/it]: train_loss_raw=1.3202, running_loss=1.3078, LR=0.000100
[2025-08-26 06:41:07,268][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038112] [Batch 04029/04869] [00:44:32/00:09:17, 0.663s/it]: train_loss_raw=1.3147, running_loss=1.3101, LR=0.000100
[2025-08-26 06:41:12,403][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038120] [Batch 04037/04869] [00:44:37/00:09:11, 0.663s/it]: train_loss_raw=1.3112, running_loss=1.3096, LR=0.000100
[2025-08-26 06:41:17,532][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038128] [Batch 04045/04869] [00:44:43/00:09:06, 0.663s/it]: train_loss_raw=1.3063, running_loss=1.3111, LR=0.000100
[2025-08-26 06:41:22,663][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038136] [Batch 04053/04869] [00:44:48/00:09:01, 0.663s/it]: train_loss_raw=1.2712, running_loss=1.3142, LR=0.000100
[2025-08-26 06:41:27,797][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038144] [Batch 04061/04869] [00:44:53/00:08:55, 0.663s/it]: train_loss_raw=1.2625, running_loss=1.3120, LR=0.000100
[2025-08-26 06:41:32,936][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038152] [Batch 04069/04869] [00:44:58/00:08:50, 0.663s/it]: train_loss_raw=1.3701, running_loss=1.3130, LR=0.000100
[2025-08-26 06:41:38,411][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038160] [Batch 04077/04869] [00:45:03/00:08:45, 0.663s/it]: train_loss_raw=1.2311, running_loss=1.3112, LR=0.000100
[2025-08-26 06:41:43,643][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038168] [Batch 04085/04869] [00:45:09/00:08:39, 0.663s/it]: train_loss_raw=1.3914, running_loss=1.3099, LR=0.000100
[2025-08-26 06:41:49,792][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038176] [Batch 04093/04869] [00:45:15/00:08:34, 0.663s/it]: train_loss_raw=1.3470, running_loss=1.3131, LR=0.000100
[2025-08-26 06:41:55,486][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038184] [Batch 04101/04869] [00:45:21/00:08:29, 0.664s/it]: train_loss_raw=1.1370, running_loss=1.3100, LR=0.000100
[2025-08-26 06:42:00,651][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038192] [Batch 04109/04869] [00:45:26/00:08:24, 0.663s/it]: train_loss_raw=1.3861, running_loss=1.3123, LR=0.000100
[2025-08-26 06:42:05,817][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038200] [Batch 04117/04869] [00:45:31/00:08:18, 0.663s/it]: train_loss_raw=1.3444, running_loss=1.3133, LR=0.000100
[2025-08-26 06:42:11,239][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038208] [Batch 04125/04869] [00:45:36/00:08:13, 0.663s/it]: train_loss_raw=1.3434, running_loss=1.3140, LR=0.000100
[2025-08-26 06:42:16,392][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038216] [Batch 04133/04869] [00:45:41/00:08:08, 0.663s/it]: train_loss_raw=1.3580, running_loss=1.3118, LR=0.000100
[2025-08-26 06:42:22,013][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038224] [Batch 04141/04869] [00:45:47/00:08:03, 0.664s/it]: train_loss_raw=1.3311, running_loss=1.3121, LR=0.000100
[2025-08-26 06:42:27,513][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038232] [Batch 04149/04869] [00:45:53/00:07:57, 0.664s/it]: train_loss_raw=1.3322, running_loss=1.3120, LR=0.000100
[2025-08-26 06:42:32,677][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038240] [Batch 04157/04869] [00:45:58/00:07:52, 0.664s/it]: train_loss_raw=1.1567, running_loss=1.3136, LR=0.000100
[2025-08-26 06:42:37,972][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038248] [Batch 04165/04869] [00:46:03/00:07:47, 0.664s/it]: train_loss_raw=1.2201, running_loss=1.3135, LR=0.000100
[2025-08-26 06:42:43,106][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038256] [Batch 04173/04869] [00:46:08/00:07:41, 0.663s/it]: train_loss_raw=1.2370, running_loss=1.3160, LR=0.000100
[2025-08-26 06:42:48,599][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038264] [Batch 04181/04869] [00:46:14/00:07:36, 0.664s/it]: train_loss_raw=1.2984, running_loss=1.3128, LR=0.000100
[2025-08-26 06:42:53,795][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038272] [Batch 04189/04869] [00:46:19/00:07:31, 0.663s/it]: train_loss_raw=1.3143, running_loss=1.3122, LR=0.000100
[2025-08-26 06:42:59,280][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038280] [Batch 04197/04869] [00:46:24/00:07:25, 0.664s/it]: train_loss_raw=1.2454, running_loss=1.3098, LR=0.000100
[2025-08-26 06:43:04,612][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038288] [Batch 04205/04869] [00:46:30/00:07:20, 0.664s/it]: train_loss_raw=1.4275, running_loss=1.3093, LR=0.000100
[2025-08-26 06:43:09,835][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038296] [Batch 04213/04869] [00:46:35/00:07:15, 0.664s/it]: train_loss_raw=1.3505, running_loss=1.3073, LR=0.000100
[2025-08-26 06:43:14,975][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038304] [Batch 04221/04869] [00:46:40/00:07:09, 0.663s/it]: train_loss_raw=1.2167, running_loss=1.3050, LR=0.000100
[2025-08-26 06:43:20,117][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038312] [Batch 04229/04869] [00:46:45/00:07:04, 0.663s/it]: train_loss_raw=1.4051, running_loss=1.3064, LR=0.000100
[2025-08-26 06:43:25,283][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038320] [Batch 04237/04869] [00:46:50/00:06:59, 0.663s/it]: train_loss_raw=1.2935, running_loss=1.3090, LR=0.000100
[2025-08-26 06:43:30,718][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038328] [Batch 04245/04869] [00:46:56/00:06:53, 0.663s/it]: train_loss_raw=1.3736, running_loss=1.3101, LR=0.000100
[2025-08-26 06:43:35,937][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038336] [Batch 04253/04869] [00:47:01/00:06:48, 0.663s/it]: train_loss_raw=1.3535, running_loss=1.3117, LR=0.000100
[2025-08-26 06:43:41,745][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038344] [Batch 04261/04869] [00:47:07/00:06:43, 0.664s/it]: train_loss_raw=1.4202, running_loss=1.3113, LR=0.000100
[2025-08-26 06:43:47,048][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038352] [Batch 04269/04869] [00:47:12/00:06:38, 0.664s/it]: train_loss_raw=1.4131, running_loss=1.3136, LR=0.000100
[2025-08-26 06:43:52,372][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038360] [Batch 04277/04869] [00:47:17/00:06:32, 0.664s/it]: train_loss_raw=1.3102, running_loss=1.3150, LR=0.000100
[2025-08-26 06:43:57,765][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038368] [Batch 04285/04869] [00:47:23/00:06:27, 0.664s/it]: train_loss_raw=1.4638, running_loss=1.3149, LR=0.000100
[2025-08-26 06:44:04,192][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038376] [Batch 04293/04869] [00:47:29/00:06:22, 0.664s/it]: train_loss_raw=1.4497, running_loss=1.3133, LR=0.000100
[2025-08-26 06:44:09,716][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038384] [Batch 04301/04869] [00:47:35/00:06:17, 0.664s/it]: train_loss_raw=1.2227, running_loss=1.3108, LR=0.000100
[2025-08-26 06:44:15,005][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038392] [Batch 04309/04869] [00:47:40/00:06:11, 0.664s/it]: train_loss_raw=1.3048, running_loss=1.3105, LR=0.000100
[2025-08-26 06:44:20,147][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038400] [Batch 04317/04869] [00:47:45/00:06:06, 0.664s/it]: train_loss_raw=1.3028, running_loss=1.3130, LR=0.000100
[2025-08-26 06:44:25,274][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038408] [Batch 04325/04869] [00:47:50/00:06:01, 0.664s/it]: train_loss_raw=1.3148, running_loss=1.3131, LR=0.000100
[2025-08-26 06:44:30,393][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038416] [Batch 04333/04869] [00:47:55/00:05:55, 0.664s/it]: train_loss_raw=1.3582, running_loss=1.3120, LR=0.000100
[2025-08-26 06:44:35,529][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038424] [Batch 04341/04869] [00:48:01/00:05:50, 0.664s/it]: train_loss_raw=1.3759, running_loss=1.3143, LR=0.000100
[2025-08-26 06:44:40,647][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038432] [Batch 04349/04869] [00:48:06/00:05:45, 0.664s/it]: train_loss_raw=1.2539, running_loss=1.3109, LR=0.000100
[2025-08-26 06:44:45,798][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038440] [Batch 04357/04869] [00:48:11/00:05:39, 0.664s/it]: train_loss_raw=1.4163, running_loss=1.3111, LR=0.000100
[2025-08-26 06:44:50,921][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038448] [Batch 04365/04869] [00:48:16/00:05:34, 0.664s/it]: train_loss_raw=1.3390, running_loss=1.3114, LR=0.000100
[2025-08-26 06:44:56,043][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038456] [Batch 04373/04869] [00:48:21/00:05:29, 0.664s/it]: train_loss_raw=1.3974, running_loss=1.3137, LR=0.000100
[2025-08-26 06:45:01,427][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038464] [Batch 04381/04869] [00:48:26/00:05:23, 0.664s/it]: train_loss_raw=1.2635, running_loss=1.3143, LR=0.000100
[2025-08-26 06:45:07,069][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038472] [Batch 04389/04869] [00:48:32/00:05:18, 0.664s/it]: train_loss_raw=1.3138, running_loss=1.3139, LR=0.000100
[2025-08-26 06:45:12,695][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038480] [Batch 04397/04869] [00:48:38/00:05:13, 0.664s/it]: train_loss_raw=1.2386, running_loss=1.3128, LR=0.000100
[2025-08-26 06:45:17,849][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038488] [Batch 04405/04869] [00:48:43/00:05:07, 0.664s/it]: train_loss_raw=1.3544, running_loss=1.3149, LR=0.000100
[2025-08-26 06:45:23,584][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038496] [Batch 04413/04869] [00:48:49/00:05:02, 0.664s/it]: train_loss_raw=1.4554, running_loss=1.3154, LR=0.000100
[2025-08-26 06:45:29,544][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038504] [Batch 04421/04869] [00:48:55/00:04:57, 0.664s/it]: train_loss_raw=1.4034, running_loss=1.3145, LR=0.000100
[2025-08-26 06:45:34,706][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038512] [Batch 04429/04869] [00:49:00/00:04:52, 0.664s/it]: train_loss_raw=1.3207, running_loss=1.3145, LR=0.000100
[2025-08-26 06:45:39,848][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038520] [Batch 04437/04869] [00:49:05/00:04:46, 0.664s/it]: train_loss_raw=1.3803, running_loss=1.3161, LR=0.000100
[2025-08-26 06:45:44,985][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038528] [Batch 04445/04869] [00:49:10/00:04:41, 0.664s/it]: train_loss_raw=1.3494, running_loss=1.3137, LR=0.000100
[2025-08-26 06:45:50,135][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038536] [Batch 04453/04869] [00:49:15/00:04:36, 0.664s/it]: train_loss_raw=1.3477, running_loss=1.3139, LR=0.000100
[2025-08-26 06:45:55,793][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038544] [Batch 04461/04869] [00:49:21/00:04:30, 0.664s/it]: train_loss_raw=1.3074, running_loss=1.3144, LR=0.000100
[2025-08-26 06:46:00,933][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038552] [Batch 04469/04869] [00:49:26/00:04:25, 0.664s/it]: train_loss_raw=1.3535, running_loss=1.3135, LR=0.000100
[2025-08-26 06:46:06,075][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038560] [Batch 04477/04869] [00:49:31/00:04:20, 0.664s/it]: train_loss_raw=1.3038, running_loss=1.3095, LR=0.000100
[2025-08-26 06:46:11,201][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038568] [Batch 04485/04869] [00:49:36/00:04:14, 0.664s/it]: train_loss_raw=1.2857, running_loss=1.3107, LR=0.000100
[2025-08-26 06:46:16,766][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038576] [Batch 04493/04869] [00:49:42/00:04:09, 0.664s/it]: train_loss_raw=1.3606, running_loss=1.3090, LR=0.000100
[2025-08-26 06:46:21,922][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038584] [Batch 04501/04869] [00:49:47/00:04:04, 0.664s/it]: train_loss_raw=1.2837, running_loss=1.3104, LR=0.000100
[2025-08-26 06:46:27,073][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038592] [Batch 04509/04869] [00:49:52/00:03:58, 0.664s/it]: train_loss_raw=1.2993, running_loss=1.3081, LR=0.000100
[2025-08-26 06:46:32,763][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038600] [Batch 04517/04869] [00:49:58/00:03:53, 0.664s/it]: train_loss_raw=1.3685, running_loss=1.3069, LR=0.000100
[2025-08-26 06:46:38,070][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038608] [Batch 04525/04869] [00:50:03/00:03:48, 0.664s/it]: train_loss_raw=1.3243, running_loss=1.3082, LR=0.000100
[2025-08-26 06:46:43,286][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038616] [Batch 04533/04869] [00:50:08/00:03:43, 0.664s/it]: train_loss_raw=1.2804, running_loss=1.3097, LR=0.000100
[2025-08-26 06:46:48,435][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038624] [Batch 04541/04869] [00:50:13/00:03:37, 0.664s/it]: train_loss_raw=1.2167, running_loss=1.3068, LR=0.000100
[2025-08-26 06:46:53,562][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038632] [Batch 04549/04869] [00:50:19/00:03:32, 0.664s/it]: train_loss_raw=1.3116, running_loss=1.3060, LR=0.000100
[2025-08-26 06:46:58,705][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038640] [Batch 04557/04869] [00:50:24/00:03:27, 0.664s/it]: train_loss_raw=1.2602, running_loss=1.3035, LR=0.000100
[2025-08-26 06:47:04,025][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038648] [Batch 04565/04869] [00:50:29/00:03:21, 0.664s/it]: train_loss_raw=1.2891, running_loss=1.2996, LR=0.000100
[2025-08-26 06:47:09,335][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038656] [Batch 04573/04869] [00:50:34/00:03:16, 0.664s/it]: train_loss_raw=1.4174, running_loss=1.3010, LR=0.000100
[2025-08-26 06:47:14,495][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038664] [Batch 04581/04869] [00:50:40/00:03:11, 0.664s/it]: train_loss_raw=1.3011, running_loss=1.3004, LR=0.000100
[2025-08-26 06:47:19,844][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038672] [Batch 04589/04869] [00:50:45/00:03:05, 0.664s/it]: train_loss_raw=1.2288, running_loss=1.2985, LR=0.000100
[2025-08-26 06:47:24,971][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038680] [Batch 04597/04869] [00:50:50/00:03:00, 0.664s/it]: train_loss_raw=1.2759, running_loss=1.2966, LR=0.000100
[2025-08-26 06:47:30,100][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038688] [Batch 04605/04869] [00:50:55/00:02:55, 0.664s/it]: train_loss_raw=1.3000, running_loss=1.2976, LR=0.000100
[2025-08-26 06:47:35,735][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038696] [Batch 04613/04869] [00:51:01/00:02:49, 0.664s/it]: train_loss_raw=1.3631, running_loss=1.3017, LR=0.000100
[2025-08-26 06:47:41,032][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038704] [Batch 04621/04869] [00:51:06/00:02:44, 0.664s/it]: train_loss_raw=1.2299, running_loss=1.3049, LR=0.000100
[2025-08-26 06:47:46,316][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038712] [Batch 04629/04869] [00:51:11/00:02:39, 0.664s/it]: train_loss_raw=1.2442, running_loss=1.3032, LR=0.000100
[2025-08-26 06:47:51,605][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038720] [Batch 04637/04869] [00:51:17/00:02:33, 0.664s/it]: train_loss_raw=1.3307, running_loss=1.3065, LR=0.000100
[2025-08-26 06:47:57,171][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038728] [Batch 04645/04869] [00:51:22/00:02:28, 0.664s/it]: train_loss_raw=1.3318, running_loss=1.3081, LR=0.000100
[2025-08-26 06:48:02,314][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038736] [Batch 04653/04869] [00:51:27/00:02:23, 0.664s/it]: train_loss_raw=1.3623, running_loss=1.3087, LR=0.000100
[2025-08-26 06:48:07,452][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038744] [Batch 04661/04869] [00:51:33/00:02:18, 0.664s/it]: train_loss_raw=1.3199, running_loss=1.3098, LR=0.000100
[2025-08-26 06:48:12,583][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038752] [Batch 04669/04869] [00:51:38/00:02:12, 0.664s/it]: train_loss_raw=1.2212, running_loss=1.3059, LR=0.000100
[2025-08-26 06:48:17,743][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038760] [Batch 04677/04869] [00:51:43/00:02:07, 0.664s/it]: train_loss_raw=1.3580, running_loss=1.3054, LR=0.000100
[2025-08-26 06:48:22,888][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038768] [Batch 04685/04869] [00:51:48/00:02:02, 0.663s/it]: train_loss_raw=1.2984, running_loss=1.3058, LR=0.000100
[2025-08-26 06:48:28,367][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038776] [Batch 04693/04869] [00:51:53/00:01:56, 0.664s/it]: train_loss_raw=1.2801, running_loss=1.3078, LR=0.000100
[2025-08-26 06:48:34,397][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038784] [Batch 04701/04869] [00:51:59/00:01:51, 0.664s/it]: train_loss_raw=1.3527, running_loss=1.3095, LR=0.000100
[2025-08-26 06:48:39,538][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038792] [Batch 04709/04869] [00:52:05/00:01:46, 0.664s/it]: train_loss_raw=1.3342, running_loss=1.3090, LR=0.000100
[2025-08-26 06:48:45,009][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038800] [Batch 04717/04869] [00:52:10/00:01:40, 0.664s/it]: train_loss_raw=1.1842, running_loss=1.3074, LR=0.000100
[2025-08-26 06:48:50,140][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038808] [Batch 04725/04869] [00:52:15/00:01:35, 0.664s/it]: train_loss_raw=1.2823, running_loss=1.3050, LR=0.000100
[2025-08-26 06:48:55,597][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038816] [Batch 04733/04869] [00:52:21/00:01:30, 0.664s/it]: train_loss_raw=1.4546, running_loss=1.3062, LR=0.000100
[2025-08-26 06:49:00,889][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038824] [Batch 04741/04869] [00:52:26/00:01:24, 0.664s/it]: train_loss_raw=1.3317, running_loss=1.3073, LR=0.000100
[2025-08-26 06:49:06,022][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038832] [Batch 04749/04869] [00:52:31/00:01:19, 0.664s/it]: train_loss_raw=1.4136, running_loss=1.3074, LR=0.000100
[2025-08-26 06:49:11,153][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038840] [Batch 04757/04869] [00:52:36/00:01:14, 0.664s/it]: train_loss_raw=1.3451, running_loss=1.3079, LR=0.000100
[2025-08-26 06:49:16,290][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038848] [Batch 04765/04869] [00:52:41/00:01:09, 0.664s/it]: train_loss_raw=1.4055, running_loss=1.3065, LR=0.000100
[2025-08-26 06:49:21,904][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038856] [Batch 04773/04869] [00:52:47/00:01:03, 0.664s/it]: train_loss_raw=1.4063, running_loss=1.3070, LR=0.000100
[2025-08-26 06:49:27,038][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038864] [Batch 04781/04869] [00:52:52/00:00:58, 0.664s/it]: train_loss_raw=1.3377, running_loss=1.3052, LR=0.000100
[2025-08-26 06:49:32,175][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038872] [Batch 04789/04869] [00:52:57/00:00:53, 0.664s/it]: train_loss_raw=1.3688, running_loss=1.3068, LR=0.000100
[2025-08-26 06:49:37,296][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038880] [Batch 04797/04869] [00:53:02/00:00:47, 0.664s/it]: train_loss_raw=1.2922, running_loss=1.3061, LR=0.000100
[2025-08-26 06:49:42,538][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038888] [Batch 04805/04869] [00:53:08/00:00:42, 0.663s/it]: train_loss_raw=1.3226, running_loss=1.3051, LR=0.000100
[2025-08-26 06:49:47,689][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038896] [Batch 04813/04869] [00:53:13/00:00:37, 0.663s/it]: train_loss_raw=1.3327, running_loss=1.3066, LR=0.000100
[2025-08-26 06:49:53,034][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038904] [Batch 04821/04869] [00:53:18/00:00:31, 0.663s/it]: train_loss_raw=1.3250, running_loss=1.3064, LR=0.000100
[2025-08-26 06:49:58,185][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038912] [Batch 04829/04869] [00:53:23/00:00:26, 0.663s/it]: train_loss_raw=1.3340, running_loss=1.3107, LR=0.000100
[2025-08-26 06:50:03,335][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038920] [Batch 04837/04869] [00:53:28/00:00:21, 0.663s/it]: train_loss_raw=1.3361, running_loss=1.3115, LR=0.000100
[2025-08-26 06:50:08,841][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038928] [Batch 04845/04869] [00:53:34/00:00:15, 0.663s/it]: train_loss_raw=1.3401, running_loss=1.3095, LR=0.000100
[2025-08-26 06:50:13,974][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038936] [Batch 04853/04869] [00:53:39/00:00:10, 0.663s/it]: train_loss_raw=1.2665, running_loss=1.3072, LR=0.000100
[2025-08-26 06:50:19,221][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038944] [Batch 04861/04869] [00:53:44/00:00:05, 0.663s/it]: train_loss_raw=1.4268, running_loss=1.3076, LR=0.000100
[2025-08-26 06:50:38,971][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 038952] [Batch 04869/04869] [00:54:04/00:00:00, 0.666s/it]: train_loss_raw=1.2280, running_loss=1.3058, LR=0.000100
[2025-08-26 06:50:44,552][__main__][INFO] - [VALIDATION] [Epoch 07/29] Starting validation.
[2025-08-26 06:50:55,009][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00007/00124] [00:00:10/00:02:31, 1.307s/it]
[2025-08-26 06:51:05,167][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00015/00124] [00:00:20/00:02:19, 1.288s/it]
[2025-08-26 06:51:15,174][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00023/00124] [00:00:30/00:02:07, 1.276s/it]
[2025-08-26 06:51:34,344][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00031/00124] [00:00:49/00:02:23, 1.556s/it]
[2025-08-26 06:51:44,376][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00039/00124] [00:00:59/00:02:05, 1.496s/it]
[2025-08-26 06:51:55,190][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00047/00124] [00:01:10/00:01:51, 1.472s/it]
[2025-08-26 06:52:04,747][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00055/00124] [00:01:20/00:01:37, 1.432s/it]
[2025-08-26 06:52:14,813][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00063/00124] [00:01:30/00:01:24, 1.410s/it]
[2025-08-26 06:52:25,726][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00071/00124] [00:01:41/00:01:13, 1.405s/it]
[2025-08-26 06:52:35,128][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00079/00124] [00:01:50/00:01:00, 1.382s/it]
[2025-08-26 06:52:45,042][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00087/00124] [00:02:00/00:00:49, 1.369s/it]
[2025-08-26 06:52:55,178][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00095/00124] [00:02:10/00:00:38, 1.361s/it]
[2025-08-26 06:53:05,320][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00103/00124] [00:02:20/00:00:27, 1.354s/it]
[2025-08-26 06:53:15,165][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00111/00124] [00:02:30/00:00:16, 1.345s/it]
[2025-08-26 06:53:25,937][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 038953] [Batch 00119/00124] [00:02:41/00:00:05, 1.345s/it]
[2025-08-26 06:53:30,366][__main__][INFO] - [VALIDATION] [Epoch 07/29] train_loss=1.30580, valid_loss=1.19652
[2025-08-26 06:53:30,367][__main__][INFO] - [VALIDATION] [Epoch 07/29] Metrics:
[2025-08-26 06:53:30,367][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_er      0.549
[2025-08-26 06:53:30,367][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_prec    0.160
[2025-08-26 06:53:30,367][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_recall  0.166
[2025-08-26 06:53:30,367][__main__][INFO] - [VALIDATION] [Epoch 07/29] - pep_recall 0.111
[2025-08-26 06:53:30,371][__main__][INFO] - [TRAIN] [Epoch 07/29] Epoch complete, total time 07:49:10, remaining time 21:30:13, 00:58:38 per epoch
[2025-08-26 06:53:35,157][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 038960] [Batch 00008/04869] [00:00:04/00:47:08, 0.582s/it]: train_loss_raw=1.4075, running_loss=1.2476, LR=0.000100
[2025-08-26 06:53:40,289][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 038968] [Batch 00016/04869] [00:00:09/00:49:28, 0.612s/it]: train_loss_raw=1.2712, running_loss=1.2497, LR=0.000100
[2025-08-26 06:53:45,437][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 038976] [Batch 00024/04869] [00:00:14/00:50:15, 0.622s/it]: train_loss_raw=1.2590, running_loss=1.2519, LR=0.000100
[2025-08-26 06:53:50,568][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 038984] [Batch 00032/04869] [00:00:20/00:50:33, 0.627s/it]: train_loss_raw=1.2955, running_loss=1.2518, LR=0.000100
[2025-08-26 06:53:55,708][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 038992] [Batch 00040/04869] [00:00:25/00:50:43, 0.630s/it]: train_loss_raw=1.3211, running_loss=1.2519, LR=0.000100
[2025-08-26 06:54:00,936][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039000] [Batch 00048/04869] [00:00:30/00:50:56, 0.634s/it]: train_loss_raw=1.2779, running_loss=1.2521, LR=0.000100
[2025-08-26 06:54:06,228][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039008] [Batch 00056/04869] [00:00:35/00:51:10, 0.638s/it]: train_loss_raw=1.3153, running_loss=1.2551, LR=0.000100
[2025-08-26 06:54:11,373][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039016] [Batch 00064/04869] [00:00:40/00:51:08, 0.639s/it]: train_loss_raw=1.2687, running_loss=1.2562, LR=0.000100
[2025-08-26 06:54:16,532][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039024] [Batch 00072/04869] [00:00:46/00:51:06, 0.639s/it]: train_loss_raw=1.2941, running_loss=1.2587, LR=0.000100
[2025-08-26 06:54:21,784][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039032] [Batch 00080/04869] [00:00:51/00:51:09, 0.641s/it]: train_loss_raw=1.3382, running_loss=1.2573, LR=0.000100
[2025-08-26 06:54:26,921][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039040] [Batch 00088/04869] [00:00:56/00:51:05, 0.641s/it]: train_loss_raw=1.2630, running_loss=1.2579, LR=0.000100
[2025-08-26 06:54:32,308][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039048] [Batch 00096/04869] [00:01:01/00:51:12, 0.644s/it]: train_loss_raw=1.3039, running_loss=1.2590, LR=0.000100
[2025-08-26 06:54:37,450][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039056] [Batch 00104/04869] [00:01:06/00:51:07, 0.644s/it]: train_loss_raw=1.1823, running_loss=1.2594, LR=0.000100
[2025-08-26 06:54:42,582][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039064] [Batch 00112/04869] [00:01:12/00:51:01, 0.644s/it]: train_loss_raw=1.0445, running_loss=1.2582, LR=0.000100
[2025-08-26 06:54:47,735][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039072] [Batch 00120/04869] [00:01:17/00:50:56, 0.644s/it]: train_loss_raw=1.2546, running_loss=1.2598, LR=0.000100
[2025-08-26 06:54:52,883][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039080] [Batch 00128/04869] [00:01:22/00:50:51, 0.644s/it]: train_loss_raw=1.2776, running_loss=1.2587, LR=0.000100
[2025-08-26 06:54:58,121][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039088] [Batch 00136/04869] [00:01:27/00:50:49, 0.644s/it]: train_loss_raw=1.2591, running_loss=1.2578, LR=0.000100
[2025-08-26 06:55:03,249][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039096] [Batch 00144/04869] [00:01:32/00:50:43, 0.644s/it]: train_loss_raw=1.2526, running_loss=1.2570, LR=0.000100
[2025-08-26 06:55:08,387][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039104] [Batch 00152/04869] [00:01:37/00:50:37, 0.644s/it]: train_loss_raw=1.2203, running_loss=1.2591, LR=0.000100
[2025-08-26 06:55:13,522][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039112] [Batch 00160/04869] [00:01:43/00:50:32, 0.644s/it]: train_loss_raw=1.2841, running_loss=1.2607, LR=0.000100
[2025-08-26 06:55:18,638][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039120] [Batch 00168/04869] [00:01:48/00:50:25, 0.644s/it]: train_loss_raw=1.2332, running_loss=1.2602, LR=0.000100
[2025-08-26 06:55:24,002][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039128] [Batch 00176/04869] [00:01:53/00:50:26, 0.645s/it]: train_loss_raw=1.1671, running_loss=1.2591, LR=0.000100
[2025-08-26 06:55:29,158][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039136] [Batch 00184/04869] [00:01:58/00:50:21, 0.645s/it]: train_loss_raw=1.3170, running_loss=1.2603, LR=0.000100
[2025-08-26 06:55:34,933][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039144] [Batch 00192/04869] [00:02:04/00:50:31, 0.648s/it]: train_loss_raw=1.2878, running_loss=1.2605, LR=0.000100
[2025-08-26 06:55:40,056][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039152] [Batch 00200/04869] [00:02:09/00:50:24, 0.648s/it]: train_loss_raw=1.3091, running_loss=1.2598, LR=0.000100
[2025-08-26 06:55:45,187][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039160] [Batch 00208/04869] [00:02:14/00:50:18, 0.648s/it]: train_loss_raw=1.2820, running_loss=1.2605, LR=0.000100
[2025-08-26 06:55:50,474][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039168] [Batch 00216/04869] [00:02:19/00:50:15, 0.648s/it]: train_loss_raw=1.2943, running_loss=1.2612, LR=0.000100
[2025-08-26 06:55:55,617][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039176] [Batch 00224/04869] [00:02:25/00:50:09, 0.648s/it]: train_loss_raw=1.2647, running_loss=1.2611, LR=0.000100
[2025-08-26 06:56:00,750][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039184] [Batch 00232/04869] [00:02:30/00:50:03, 0.648s/it]: train_loss_raw=1.3772, running_loss=1.2644, LR=0.000100
[2025-08-26 06:56:05,883][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039192] [Batch 00240/04869] [00:02:35/00:49:56, 0.647s/it]: train_loss_raw=1.3393, running_loss=1.2647, LR=0.000100
[2025-08-26 06:56:11,007][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039200] [Batch 00248/04869] [00:02:40/00:49:50, 0.647s/it]: train_loss_raw=1.1141, running_loss=1.2631, LR=0.000100
[2025-08-26 06:56:16,127][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039208] [Batch 00256/04869] [00:02:45/00:49:44, 0.647s/it]: train_loss_raw=1.2626, running_loss=1.2654, LR=0.000100
[2025-08-26 06:56:21,237][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039216] [Batch 00264/04869] [00:02:50/00:49:38, 0.647s/it]: train_loss_raw=1.2718, running_loss=1.2635, LR=0.000100
[2025-08-26 06:56:26,951][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039224] [Batch 00272/04869] [00:02:56/00:49:42, 0.649s/it]: train_loss_raw=1.2249, running_loss=1.2615, LR=0.000100
[2025-08-26 06:56:32,102][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039232] [Batch 00280/04869] [00:03:01/00:49:36, 0.649s/it]: train_loss_raw=1.3171, running_loss=1.2627, LR=0.000100
[2025-08-26 06:56:37,250][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039240] [Batch 00288/04869] [00:03:06/00:49:30, 0.648s/it]: train_loss_raw=1.2224, running_loss=1.2599, LR=0.000100
[2025-08-26 06:56:42,396][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039248] [Batch 00296/04869] [00:03:11/00:49:24, 0.648s/it]: train_loss_raw=1.2636, running_loss=1.2613, LR=0.000100
[2025-08-26 06:56:47,533][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039256] [Batch 00304/04869] [00:03:17/00:49:18, 0.648s/it]: train_loss_raw=1.2606, running_loss=1.2609, LR=0.000100
[2025-08-26 06:56:52,671][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039264] [Batch 00312/04869] [00:03:22/00:49:12, 0.648s/it]: train_loss_raw=1.3406, running_loss=1.2616, LR=0.000100
[2025-08-26 06:56:57,796][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039272] [Batch 00320/04869] [00:03:27/00:49:06, 0.648s/it]: train_loss_raw=1.2951, running_loss=1.2620, LR=0.000100
[2025-08-26 06:57:02,941][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039280] [Batch 00328/04869] [00:03:32/00:49:01, 0.648s/it]: train_loss_raw=1.3110, running_loss=1.2652, LR=0.000100
[2025-08-26 06:57:08,897][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039288] [Batch 00336/04869] [00:03:38/00:49:06, 0.650s/it]: train_loss_raw=1.2845, running_loss=1.2657, LR=0.000100
[2025-08-26 06:57:14,166][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039296] [Batch 00344/04869] [00:03:43/00:49:02, 0.650s/it]: train_loss_raw=1.2835, running_loss=1.2670, LR=0.000100
[2025-08-26 06:57:20,008][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039304] [Batch 00352/04869] [00:03:49/00:49:05, 0.652s/it]: train_loss_raw=1.2342, running_loss=1.2645, LR=0.000100
[2025-08-26 06:57:25,142][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039312] [Batch 00360/04869] [00:03:54/00:48:58, 0.652s/it]: train_loss_raw=1.1489, running_loss=1.2634, LR=0.000100
[2025-08-26 06:57:30,289][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039320] [Batch 00368/04869] [00:03:59/00:48:52, 0.652s/it]: train_loss_raw=1.3609, running_loss=1.2661, LR=0.000100
[2025-08-26 06:57:35,443][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039328] [Batch 00376/04869] [00:04:04/00:48:46, 0.651s/it]: train_loss_raw=1.2247, running_loss=1.2684, LR=0.000100
[2025-08-26 06:57:40,593][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039336] [Batch 00384/04869] [00:04:10/00:48:40, 0.651s/it]: train_loss_raw=1.2287, running_loss=1.2712, LR=0.000100
[2025-08-26 06:57:45,742][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039344] [Batch 00392/04869] [00:04:15/00:48:35, 0.651s/it]: train_loss_raw=1.2315, running_loss=1.2697, LR=0.000100
[2025-08-26 06:57:51,275][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039352] [Batch 00400/04869] [00:04:20/00:48:33, 0.652s/it]: train_loss_raw=1.3030, running_loss=1.2700, LR=0.000100
[2025-08-26 06:57:56,422][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039360] [Batch 00408/04869] [00:04:25/00:48:27, 0.652s/it]: train_loss_raw=1.3090, running_loss=1.2678, LR=0.000100
[2025-08-26 06:58:01,605][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039368] [Batch 00416/04869] [00:04:31/00:48:21, 0.652s/it]: train_loss_raw=1.2786, running_loss=1.2665, LR=0.000100
[2025-08-26 06:58:07,443][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039376] [Batch 00424/04869] [00:04:36/00:48:23, 0.653s/it]: train_loss_raw=1.2096, running_loss=1.2673, LR=0.000100
[2025-08-26 06:58:12,944][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039384] [Batch 00432/04869] [00:04:42/00:48:20, 0.654s/it]: train_loss_raw=1.3123, running_loss=1.2663, LR=0.000100
[2025-08-26 06:58:18,205][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039392] [Batch 00440/04869] [00:04:47/00:48:15, 0.654s/it]: train_loss_raw=1.2630, running_loss=1.2677, LR=0.000100
[2025-08-26 06:58:23,906][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039400] [Batch 00448/04869] [00:04:53/00:48:15, 0.655s/it]: train_loss_raw=1.3079, running_loss=1.2653, LR=0.000100
[2025-08-26 06:58:29,044][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039408] [Batch 00456/04869] [00:04:58/00:48:09, 0.655s/it]: train_loss_raw=1.2060, running_loss=1.2658, LR=0.000100
[2025-08-26 06:58:34,180][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039416] [Batch 00464/04869] [00:05:03/00:48:02, 0.654s/it]: train_loss_raw=1.1819, running_loss=1.2629, LR=0.000100
[2025-08-26 06:58:39,314][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039424] [Batch 00472/04869] [00:05:08/00:47:56, 0.654s/it]: train_loss_raw=1.3066, running_loss=1.2660, LR=0.000100
[2025-08-26 06:58:44,993][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039432] [Batch 00480/04869] [00:05:14/00:47:55, 0.655s/it]: train_loss_raw=1.2587, running_loss=1.2653, LR=0.000100
[2025-08-26 06:58:50,138][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039440] [Batch 00488/04869] [00:05:19/00:47:49, 0.655s/it]: train_loss_raw=1.3573, running_loss=1.2665, LR=0.000100
[2025-08-26 06:58:55,565][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039448] [Batch 00496/04869] [00:05:25/00:47:45, 0.655s/it]: train_loss_raw=1.2555, running_loss=1.2692, LR=0.000100
[2025-08-26 06:59:00,705][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039456] [Batch 00504/04869] [00:05:30/00:47:39, 0.655s/it]: train_loss_raw=1.2595, running_loss=1.2670, LR=0.000100
[2025-08-26 06:59:06,523][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039464] [Batch 00512/04869] [00:05:36/00:47:39, 0.656s/it]: train_loss_raw=1.2320, running_loss=1.2656, LR=0.000100
[2025-08-26 06:59:11,684][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039472] [Batch 00520/04869] [00:05:41/00:47:33, 0.656s/it]: train_loss_raw=1.3292, running_loss=1.2674, LR=0.000100
[2025-08-26 06:59:16,853][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039480] [Batch 00528/04869] [00:05:46/00:47:27, 0.656s/it]: train_loss_raw=1.2714, running_loss=1.2662, LR=0.000100
[2025-08-26 06:59:22,240][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039488] [Batch 00536/04869] [00:05:51/00:47:23, 0.656s/it]: train_loss_raw=1.2920, running_loss=1.2674, LR=0.000100
[2025-08-26 06:59:27,629][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039496] [Batch 00544/04869] [00:05:57/00:47:19, 0.656s/it]: train_loss_raw=1.2629, running_loss=1.2682, LR=0.000100
[2025-08-26 06:59:33,355][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039504] [Batch 00552/04869] [00:06:02/00:47:17, 0.657s/it]: train_loss_raw=1.3369, running_loss=1.2692, LR=0.000100
[2025-08-26 06:59:38,532][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039512] [Batch 00560/04869] [00:06:08/00:47:11, 0.657s/it]: train_loss_raw=1.1478, running_loss=1.2683, LR=0.000100
[2025-08-26 06:59:43,682][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039520] [Batch 00568/04869] [00:06:13/00:47:05, 0.657s/it]: train_loss_raw=1.2655, running_loss=1.2666, LR=0.000100
[2025-08-26 06:59:48,920][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039528] [Batch 00576/04869] [00:06:18/00:47:00, 0.657s/it]: train_loss_raw=1.3043, running_loss=1.2670, LR=0.000100
[2025-08-26 06:59:54,403][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039536] [Batch 00584/04869] [00:06:23/00:46:56, 0.657s/it]: train_loss_raw=1.2339, running_loss=1.2692, LR=0.000100
[2025-08-26 06:59:59,568][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039544] [Batch 00592/04869] [00:06:29/00:46:50, 0.657s/it]: train_loss_raw=1.2877, running_loss=1.2702, LR=0.000100
[2025-08-26 07:00:04,751][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039552] [Batch 00600/04869] [00:06:34/00:46:45, 0.657s/it]: train_loss_raw=1.3011, running_loss=1.2658, LR=0.000100
[2025-08-26 07:00:10,460][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039560] [Batch 00608/04869] [00:06:39/00:46:42, 0.658s/it]: train_loss_raw=1.2890, running_loss=1.2660, LR=0.000100
[2025-08-26 07:00:15,630][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039568] [Batch 00616/04869] [00:06:45/00:46:37, 0.658s/it]: train_loss_raw=1.1962, running_loss=1.2682, LR=0.000100
[2025-08-26 07:00:20,906][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039576] [Batch 00624/04869] [00:06:50/00:46:31, 0.658s/it]: train_loss_raw=1.2925, running_loss=1.2654, LR=0.000100
[2025-08-26 07:00:26,146][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039584] [Batch 00632/04869] [00:06:55/00:46:26, 0.658s/it]: train_loss_raw=1.2124, running_loss=1.2647, LR=0.000100
[2025-08-26 07:00:31,453][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039592] [Batch 00640/04869] [00:07:00/00:46:21, 0.658s/it]: train_loss_raw=1.2468, running_loss=1.2651, LR=0.000100
[2025-08-26 07:00:36,608][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039600] [Batch 00648/04869] [00:07:06/00:46:15, 0.658s/it]: train_loss_raw=1.2348, running_loss=1.2635, LR=0.000100
[2025-08-26 07:00:41,760][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039608] [Batch 00656/04869] [00:07:11/00:46:09, 0.657s/it]: train_loss_raw=1.2126, running_loss=1.2612, LR=0.000100
[2025-08-26 07:00:46,900][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039616] [Batch 00664/04869] [00:07:16/00:46:03, 0.657s/it]: train_loss_raw=1.2470, running_loss=1.2584, LR=0.000100
[2025-08-26 07:00:52,040][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039624] [Batch 00672/04869] [00:07:21/00:45:57, 0.657s/it]: train_loss_raw=1.3201, running_loss=1.2568, LR=0.000100
[2025-08-26 07:00:57,189][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039632] [Batch 00680/04869] [00:07:26/00:45:51, 0.657s/it]: train_loss_raw=1.2639, running_loss=1.2564, LR=0.000100
[2025-08-26 07:01:02,337][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039640] [Batch 00688/04869] [00:07:31/00:45:45, 0.657s/it]: train_loss_raw=1.3379, running_loss=1.2578, LR=0.000100
[2025-08-26 07:01:07,630][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039648] [Batch 00696/04869] [00:07:37/00:45:40, 0.657s/it]: train_loss_raw=1.2427, running_loss=1.2572, LR=0.000100
[2025-08-26 07:01:12,781][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039656] [Batch 00704/04869] [00:07:42/00:45:34, 0.657s/it]: train_loss_raw=1.2256, running_loss=1.2583, LR=0.000100
[2025-08-26 07:01:17,922][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039664] [Batch 00712/04869] [00:07:47/00:45:29, 0.656s/it]: train_loss_raw=1.3577, running_loss=1.2558, LR=0.000100
[2025-08-26 07:01:23,471][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039672] [Batch 00720/04869] [00:07:52/00:45:25, 0.657s/it]: train_loss_raw=1.3768, running_loss=1.2585, LR=0.000100
[2025-08-26 07:01:28,642][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039680] [Batch 00728/04869] [00:07:58/00:45:19, 0.657s/it]: train_loss_raw=1.1822, running_loss=1.2588, LR=0.000100
[2025-08-26 07:01:34,196][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039688] [Batch 00736/04869] [00:08:03/00:45:16, 0.657s/it]: train_loss_raw=1.2056, running_loss=1.2613, LR=0.000100
[2025-08-26 07:01:39,517][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039696] [Batch 00744/04869] [00:08:09/00:45:11, 0.657s/it]: train_loss_raw=1.1466, running_loss=1.2611, LR=0.000100
[2025-08-26 07:01:44,821][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039704] [Batch 00752/04869] [00:08:14/00:45:06, 0.657s/it]: train_loss_raw=1.3669, running_loss=1.2605, LR=0.000100
[2025-08-26 07:01:49,956][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039712] [Batch 00760/04869] [00:08:19/00:45:00, 0.657s/it]: train_loss_raw=1.2570, running_loss=1.2619, LR=0.000100
[2025-08-26 07:01:55,100][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039720] [Batch 00768/04869] [00:08:24/00:44:54, 0.657s/it]: train_loss_raw=1.3245, running_loss=1.2625, LR=0.000100
[2025-08-26 07:02:00,244][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039728] [Batch 00776/04869] [00:08:29/00:44:48, 0.657s/it]: train_loss_raw=1.3686, running_loss=1.2640, LR=0.000100
[2025-08-26 07:02:05,699][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039736] [Batch 00784/04869] [00:08:35/00:44:44, 0.657s/it]: train_loss_raw=1.3146, running_loss=1.2644, LR=0.000100
[2025-08-26 07:02:10,851][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039744] [Batch 00792/04869] [00:08:40/00:44:38, 0.657s/it]: train_loss_raw=1.1664, running_loss=1.2632, LR=0.000100
[2025-08-26 07:02:16,003][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039752] [Batch 00800/04869] [00:08:45/00:44:32, 0.657s/it]: train_loss_raw=1.2823, running_loss=1.2648, LR=0.000100
[2025-08-26 07:02:21,208][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039760] [Batch 00808/04869] [00:08:50/00:44:27, 0.657s/it]: train_loss_raw=1.3062, running_loss=1.2612, LR=0.000100
[2025-08-26 07:02:26,351][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039768] [Batch 00816/04869] [00:08:55/00:44:21, 0.657s/it]: train_loss_raw=1.2150, running_loss=1.2628, LR=0.000100
[2025-08-26 07:02:31,520][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039776] [Batch 00824/04869] [00:09:01/00:44:15, 0.657s/it]: train_loss_raw=1.2032, running_loss=1.2611, LR=0.000100
[2025-08-26 07:02:36,677][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039784] [Batch 00832/04869] [00:09:06/00:44:10, 0.656s/it]: train_loss_raw=1.2907, running_loss=1.2608, LR=0.000100
[2025-08-26 07:02:41,837][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039792] [Batch 00840/04869] [00:09:11/00:44:04, 0.656s/it]: train_loss_raw=1.2911, running_loss=1.2608, LR=0.000100
[2025-08-26 07:02:47,738][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039800] [Batch 00848/04869] [00:09:17/00:44:02, 0.657s/it]: train_loss_raw=1.2108, running_loss=1.2598, LR=0.000100
[2025-08-26 07:02:53,442][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039808] [Batch 00856/04869] [00:09:22/00:43:59, 0.658s/it]: train_loss_raw=1.2990, running_loss=1.2576, LR=0.000100
[2025-08-26 07:02:59,179][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039816] [Batch 00864/04869] [00:09:28/00:43:56, 0.658s/it]: train_loss_raw=1.2571, running_loss=1.2561, LR=0.000100
[2025-08-26 07:03:04,483][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039824] [Batch 00872/04869] [00:09:33/00:43:50, 0.658s/it]: train_loss_raw=1.2933, running_loss=1.2586, LR=0.000100
[2025-08-26 07:03:10,395][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039832] [Batch 00880/04869] [00:09:39/00:43:48, 0.659s/it]: train_loss_raw=1.2701, running_loss=1.2580, LR=0.000100
[2025-08-26 07:03:15,792][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039840] [Batch 00888/04869] [00:09:45/00:43:43, 0.659s/it]: train_loss_raw=1.2583, running_loss=1.2595, LR=0.000100
[2025-08-26 07:03:20,946][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039848] [Batch 00896/04869] [00:09:50/00:43:38, 0.659s/it]: train_loss_raw=1.1383, running_loss=1.2598, LR=0.000100
[2025-08-26 07:03:26,171][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039856] [Batch 00904/04869] [00:09:55/00:43:32, 0.659s/it]: train_loss_raw=1.2510, running_loss=1.2594, LR=0.000100
[2025-08-26 07:03:31,296][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039864] [Batch 00912/04869] [00:10:00/00:43:26, 0.659s/it]: train_loss_raw=1.3272, running_loss=1.2610, LR=0.000100
[2025-08-26 07:03:36,418][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039872] [Batch 00920/04869] [00:10:05/00:43:20, 0.659s/it]: train_loss_raw=1.2809, running_loss=1.2599, LR=0.000100
[2025-08-26 07:03:42,218][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039880] [Batch 00928/04869] [00:10:11/00:43:17, 0.659s/it]: train_loss_raw=1.4404, running_loss=1.2637, LR=0.000100
[2025-08-26 07:03:47,342][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039888] [Batch 00936/04869] [00:10:16/00:43:11, 0.659s/it]: train_loss_raw=1.2105, running_loss=1.2633, LR=0.000100
[2025-08-26 07:03:52,456][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039896] [Batch 00944/04869] [00:10:21/00:43:05, 0.659s/it]: train_loss_raw=1.2930, running_loss=1.2645, LR=0.000100
[2025-08-26 07:03:57,573][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039904] [Batch 00952/04869] [00:10:27/00:43:00, 0.659s/it]: train_loss_raw=1.2203, running_loss=1.2638, LR=0.000100
[2025-08-26 07:04:02,973][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039912] [Batch 00960/04869] [00:10:32/00:42:55, 0.659s/it]: train_loss_raw=1.2450, running_loss=1.2641, LR=0.000100
[2025-08-26 07:04:08,096][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039920] [Batch 00968/04869] [00:10:37/00:42:49, 0.659s/it]: train_loss_raw=1.0963, running_loss=1.2645, LR=0.000100
[2025-08-26 07:04:13,212][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039928] [Batch 00976/04869] [00:10:42/00:42:43, 0.659s/it]: train_loss_raw=1.1923, running_loss=1.2626, LR=0.000100
[2025-08-26 07:04:19,376][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039936] [Batch 00984/04869] [00:10:48/00:42:41, 0.659s/it]: train_loss_raw=1.1249, running_loss=1.2623, LR=0.000100
[2025-08-26 07:04:24,535][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039944] [Batch 00992/04869] [00:10:54/00:42:36, 0.659s/it]: train_loss_raw=1.2506, running_loss=1.2611, LR=0.000100
[2025-08-26 07:04:30,183][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039952] [Batch 01000/04869] [00:10:59/00:42:32, 0.660s/it]: train_loss_raw=1.2591, running_loss=1.2597, LR=0.000100
[2025-08-26 07:04:35,696][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039960] [Batch 01008/04869] [00:11:05/00:42:27, 0.660s/it]: train_loss_raw=1.3205, running_loss=1.2621, LR=0.000100
[2025-08-26 07:04:40,833][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039968] [Batch 01016/04869] [00:11:10/00:42:22, 0.660s/it]: train_loss_raw=1.1936, running_loss=1.2607, LR=0.000100
[2025-08-26 07:04:45,963][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039976] [Batch 01024/04869] [00:11:15/00:42:16, 0.660s/it]: train_loss_raw=1.2377, running_loss=1.2589, LR=0.000100
[2025-08-26 07:04:51,105][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039984] [Batch 01032/04869] [00:11:20/00:42:10, 0.659s/it]: train_loss_raw=1.2240, running_loss=1.2599, LR=0.000100
[2025-08-26 07:04:56,532][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 039992] [Batch 01040/04869] [00:11:26/00:42:05, 0.660s/it]: train_loss_raw=1.2189, running_loss=1.2579, LR=0.000100
[2025-08-26 07:05:01,662][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040000] [Batch 01048/04869] [00:11:31/00:41:59, 0.660s/it]: train_loss_raw=1.2632, running_loss=1.2569, LR=0.000100
[2025-08-26 07:05:10,341][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040008] [Batch 01056/04869] [00:11:39/00:42:06, 0.663s/it]: train_loss_raw=1.1118, running_loss=1.2556, LR=0.000100
[2025-08-26 07:05:15,474][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040016] [Batch 01064/04869] [00:11:44/00:42:01, 0.663s/it]: train_loss_raw=1.2266, running_loss=1.2550, LR=0.000100
[2025-08-26 07:05:20,671][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040024] [Batch 01072/04869] [00:11:50/00:41:55, 0.662s/it]: train_loss_raw=1.3054, running_loss=1.2565, LR=0.000100
[2025-08-26 07:05:26,246][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040032] [Batch 01080/04869] [00:11:55/00:41:51, 0.663s/it]: train_loss_raw=1.2539, running_loss=1.2622, LR=0.000100
[2025-08-26 07:05:31,390][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040040] [Batch 01088/04869] [00:12:00/00:41:45, 0.663s/it]: train_loss_raw=1.2415, running_loss=1.2632, LR=0.000100
[2025-08-26 07:05:36,540][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040048] [Batch 01096/04869] [00:12:06/00:41:39, 0.662s/it]: train_loss_raw=1.4386, running_loss=1.2656, LR=0.000100
[2025-08-26 07:05:41,687][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040056] [Batch 01104/04869] [00:12:11/00:41:33, 0.662s/it]: train_loss_raw=1.1843, running_loss=1.2660, LR=0.000100
[2025-08-26 07:05:47,118][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040064] [Batch 01112/04869] [00:12:16/00:41:28, 0.662s/it]: train_loss_raw=1.3061, running_loss=1.2654, LR=0.000100
[2025-08-26 07:05:52,238][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040072] [Batch 01120/04869] [00:12:21/00:41:22, 0.662s/it]: train_loss_raw=1.2176, running_loss=1.2628, LR=0.000100
[2025-08-26 07:05:57,372][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040080] [Batch 01128/04869] [00:12:26/00:41:16, 0.662s/it]: train_loss_raw=1.3417, running_loss=1.2648, LR=0.000100
[2025-08-26 07:06:02,981][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040088] [Batch 01136/04869] [00:12:32/00:41:12, 0.662s/it]: train_loss_raw=1.2232, running_loss=1.2616, LR=0.000100
[2025-08-26 07:06:08,106][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040096] [Batch 01144/04869] [00:12:37/00:41:06, 0.662s/it]: train_loss_raw=1.2793, running_loss=1.2590, LR=0.000100
[2025-08-26 07:06:13,816][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040104] [Batch 01152/04869] [00:12:43/00:41:02, 0.663s/it]: train_loss_raw=1.2875, running_loss=1.2600, LR=0.000100
[2025-08-26 07:06:18,952][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040112] [Batch 01160/04869] [00:12:48/00:40:57, 0.662s/it]: train_loss_raw=1.2315, running_loss=1.2597, LR=0.000100
[2025-08-26 07:06:24,075][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040120] [Batch 01168/04869] [00:12:53/00:40:51, 0.662s/it]: train_loss_raw=1.2756, running_loss=1.2592, LR=0.000100
[2025-08-26 07:06:29,279][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040128] [Batch 01176/04869] [00:12:58/00:40:45, 0.662s/it]: train_loss_raw=1.2049, running_loss=1.2564, LR=0.000100
[2025-08-26 07:06:34,453][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040136] [Batch 01184/04869] [00:13:03/00:40:39, 0.662s/it]: train_loss_raw=1.3415, running_loss=1.2570, LR=0.000100
[2025-08-26 07:06:39,579][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040144] [Batch 01192/04869] [00:13:09/00:40:34, 0.662s/it]: train_loss_raw=1.2323, running_loss=1.2560, LR=0.000100
[2025-08-26 07:06:45,049][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040152] [Batch 01200/04869] [00:13:14/00:40:29, 0.662s/it]: train_loss_raw=1.3277, running_loss=1.2596, LR=0.000100
[2025-08-26 07:06:50,185][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040160] [Batch 01208/04869] [00:13:19/00:40:23, 0.662s/it]: train_loss_raw=1.3159, running_loss=1.2607, LR=0.000100
[2025-08-26 07:06:55,308][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040168] [Batch 01216/04869] [00:13:24/00:40:17, 0.662s/it]: train_loss_raw=1.3068, running_loss=1.2620, LR=0.000100
[2025-08-26 07:07:00,430][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040176] [Batch 01224/04869] [00:13:29/00:40:11, 0.662s/it]: train_loss_raw=1.2994, running_loss=1.2609, LR=0.000100
[2025-08-26 07:07:06,165][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040184] [Batch 01232/04869] [00:13:35/00:40:07, 0.662s/it]: train_loss_raw=1.2786, running_loss=1.2623, LR=0.000100
[2025-08-26 07:07:11,427][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040192] [Batch 01240/04869] [00:13:40/00:40:02, 0.662s/it]: train_loss_raw=1.4062, running_loss=1.2629, LR=0.000100
[2025-08-26 07:07:16,569][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040200] [Batch 01248/04869] [00:13:46/00:39:56, 0.662s/it]: train_loss_raw=1.2740, running_loss=1.2622, LR=0.000100
[2025-08-26 07:07:21,685][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040208] [Batch 01256/04869] [00:13:51/00:39:50, 0.662s/it]: train_loss_raw=1.4104, running_loss=1.2631, LR=0.000100
[2025-08-26 07:07:26,802][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040216] [Batch 01264/04869] [00:13:56/00:39:45, 0.662s/it]: train_loss_raw=1.2913, running_loss=1.2631, LR=0.000100
[2025-08-26 07:07:31,924][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040224] [Batch 01272/04869] [00:14:01/00:39:39, 0.661s/it]: train_loss_raw=1.2143, running_loss=1.2613, LR=0.000100
[2025-08-26 07:07:37,074][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040232] [Batch 01280/04869] [00:14:06/00:39:33, 0.661s/it]: train_loss_raw=1.3297, running_loss=1.2597, LR=0.000100
[2025-08-26 07:07:42,818][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040240] [Batch 01288/04869] [00:14:12/00:39:29, 0.662s/it]: train_loss_raw=1.3162, running_loss=1.2608, LR=0.000100
[2025-08-26 07:07:47,944][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040248] [Batch 01296/04869] [00:14:17/00:39:23, 0.662s/it]: train_loss_raw=1.2804, running_loss=1.2584, LR=0.000100
[2025-08-26 07:07:53,069][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040256] [Batch 01304/04869] [00:14:22/00:39:18, 0.661s/it]: train_loss_raw=1.2095, running_loss=1.2587, LR=0.000100
[2025-08-26 07:07:58,181][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040264] [Batch 01312/04869] [00:14:27/00:39:12, 0.661s/it]: train_loss_raw=1.2259, running_loss=1.2573, LR=0.000100
[2025-08-26 07:08:03,652][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040272] [Batch 01320/04869] [00:14:33/00:39:07, 0.661s/it]: train_loss_raw=1.3380, running_loss=1.2592, LR=0.000100
[2025-08-26 07:08:08,771][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040280] [Batch 01328/04869] [00:14:38/00:39:01, 0.661s/it]: train_loss_raw=1.2053, running_loss=1.2589, LR=0.000100
[2025-08-26 07:08:13,893][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040288] [Batch 01336/04869] [00:14:43/00:38:56, 0.661s/it]: train_loss_raw=1.2637, running_loss=1.2585, LR=0.000100
[2025-08-26 07:08:19,249][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040296] [Batch 01344/04869] [00:14:48/00:38:50, 0.661s/it]: train_loss_raw=1.2872, running_loss=1.2573, LR=0.000100
[2025-08-26 07:08:24,372][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040304] [Batch 01352/04869] [00:14:53/00:38:45, 0.661s/it]: train_loss_raw=1.2303, running_loss=1.2561, LR=0.000100
[2025-08-26 07:08:29,761][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040312] [Batch 01360/04869] [00:14:59/00:38:40, 0.661s/it]: train_loss_raw=1.2963, running_loss=1.2560, LR=0.000100
[2025-08-26 07:08:35,111][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040320] [Batch 01368/04869] [00:15:04/00:38:35, 0.661s/it]: train_loss_raw=1.2620, running_loss=1.2551, LR=0.000100
[2025-08-26 07:08:40,241][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040328] [Batch 01376/04869] [00:15:09/00:38:29, 0.661s/it]: train_loss_raw=1.2054, running_loss=1.2570, LR=0.000100
[2025-08-26 07:08:45,366][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040336] [Batch 01384/04869] [00:15:14/00:38:23, 0.661s/it]: train_loss_raw=1.3628, running_loss=1.2575, LR=0.000100
[2025-08-26 07:08:50,757][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040344] [Batch 01392/04869] [00:15:20/00:38:18, 0.661s/it]: train_loss_raw=1.1653, running_loss=1.2568, LR=0.000100
[2025-08-26 07:08:56,017][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040352] [Batch 01400/04869] [00:15:25/00:38:13, 0.661s/it]: train_loss_raw=1.2282, running_loss=1.2575, LR=0.000100
[2025-08-26 07:09:01,151][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040360] [Batch 01408/04869] [00:15:30/00:38:07, 0.661s/it]: train_loss_raw=1.2103, running_loss=1.2590, LR=0.000100
[2025-08-26 07:09:06,299][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040368] [Batch 01416/04869] [00:15:35/00:38:01, 0.661s/it]: train_loss_raw=1.2105, running_loss=1.2599, LR=0.000100
[2025-08-26 07:09:11,716][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040376] [Batch 01424/04869] [00:15:41/00:37:57, 0.661s/it]: train_loss_raw=1.3893, running_loss=1.2644, LR=0.000100
[2025-08-26 07:09:16,849][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040384] [Batch 01432/04869] [00:15:46/00:37:51, 0.661s/it]: train_loss_raw=1.2494, running_loss=1.2645, LR=0.000100
[2025-08-26 07:09:21,977][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040392] [Batch 01440/04869] [00:15:51/00:37:45, 0.661s/it]: train_loss_raw=1.3055, running_loss=1.2632, LR=0.000100
[2025-08-26 07:09:27,672][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040400] [Batch 01448/04869] [00:15:57/00:37:41, 0.661s/it]: train_loss_raw=1.2514, running_loss=1.2646, LR=0.000100
[2025-08-26 07:09:33,473][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040408] [Batch 01456/04869] [00:16:02/00:37:37, 0.661s/it]: train_loss_raw=1.3203, running_loss=1.2625, LR=0.000100
[2025-08-26 07:09:38,789][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040416] [Batch 01464/04869] [00:16:08/00:37:32, 0.661s/it]: train_loss_raw=1.2825, running_loss=1.2642, LR=0.000100
[2025-08-26 07:09:43,944][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040424] [Batch 01472/04869] [00:16:13/00:37:26, 0.661s/it]: train_loss_raw=1.1659, running_loss=1.2625, LR=0.000100
[2025-08-26 07:09:49,110][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040432] [Batch 01480/04869] [00:16:18/00:37:20, 0.661s/it]: train_loss_raw=1.1579, running_loss=1.2595, LR=0.000100
[2025-08-26 07:09:54,725][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040440] [Batch 01488/04869] [00:16:24/00:37:16, 0.661s/it]: train_loss_raw=1.1950, running_loss=1.2560, LR=0.000100
[2025-08-26 07:09:59,887][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040448] [Batch 01496/04869] [00:16:29/00:37:10, 0.661s/it]: train_loss_raw=1.1817, running_loss=1.2551, LR=0.000100
[2025-08-26 07:10:05,044][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040456] [Batch 01504/04869] [00:16:34/00:37:05, 0.661s/it]: train_loss_raw=1.3738, running_loss=1.2571, LR=0.000100
[2025-08-26 07:10:10,204][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040464] [Batch 01512/04869] [00:16:39/00:36:59, 0.661s/it]: train_loss_raw=1.2367, running_loss=1.2567, LR=0.000100
[2025-08-26 07:10:15,373][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040472] [Batch 01520/04869] [00:16:44/00:36:54, 0.661s/it]: train_loss_raw=1.2450, running_loss=1.2604, LR=0.000100
[2025-08-26 07:10:20,521][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040480] [Batch 01528/04869] [00:16:50/00:36:48, 0.661s/it]: train_loss_raw=1.1874, running_loss=1.2592, LR=0.000100
[2025-08-26 07:10:25,667][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040488] [Batch 01536/04869] [00:16:55/00:36:42, 0.661s/it]: train_loss_raw=1.3173, running_loss=1.2591, LR=0.000100
[2025-08-26 07:10:31,176][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040496] [Batch 01544/04869] [00:17:00/00:36:38, 0.661s/it]: train_loss_raw=1.2797, running_loss=1.2569, LR=0.000100
[2025-08-26 07:10:36,327][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040504] [Batch 01552/04869] [00:17:05/00:36:32, 0.661s/it]: train_loss_raw=1.2107, running_loss=1.2593, LR=0.000100
[2025-08-26 07:10:41,469][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040512] [Batch 01560/04869] [00:17:10/00:36:26, 0.661s/it]: train_loss_raw=1.2844, running_loss=1.2604, LR=0.000100
[2025-08-26 07:10:46,623][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040520] [Batch 01568/04869] [00:17:16/00:36:21, 0.661s/it]: train_loss_raw=1.3313, running_loss=1.2602, LR=0.000100
[2025-08-26 07:10:51,766][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040528] [Batch 01576/04869] [00:17:21/00:36:15, 0.661s/it]: train_loss_raw=1.2780, running_loss=1.2587, LR=0.000100
[2025-08-26 07:10:56,917][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040536] [Batch 01584/04869] [00:17:26/00:36:10, 0.661s/it]: train_loss_raw=1.3556, running_loss=1.2623, LR=0.000100
[2025-08-26 07:11:02,080][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040544] [Batch 01592/04869] [00:17:31/00:36:04, 0.661s/it]: train_loss_raw=1.2580, running_loss=1.2611, LR=0.000100
[2025-08-26 07:11:07,406][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040552] [Batch 01600/04869] [00:17:36/00:35:59, 0.661s/it]: train_loss_raw=1.2335, running_loss=1.2587, LR=0.000100
[2025-08-26 07:11:12,562][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040560] [Batch 01608/04869] [00:17:42/00:35:53, 0.660s/it]: train_loss_raw=1.2876, running_loss=1.2598, LR=0.000100
[2025-08-26 07:11:17,732][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040568] [Batch 01616/04869] [00:17:47/00:35:48, 0.660s/it]: train_loss_raw=1.4249, running_loss=1.2614, LR=0.000100
[2025-08-26 07:11:23,072][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040576] [Batch 01624/04869] [00:17:52/00:35:43, 0.660s/it]: train_loss_raw=1.2501, running_loss=1.2583, LR=0.000100
[2025-08-26 07:11:28,398][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040584] [Batch 01632/04869] [00:17:57/00:35:37, 0.660s/it]: train_loss_raw=1.2591, running_loss=1.2573, LR=0.000100
[2025-08-26 07:11:33,554][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040592] [Batch 01640/04869] [00:18:03/00:35:32, 0.660s/it]: train_loss_raw=1.4560, running_loss=1.2574, LR=0.000100
[2025-08-26 07:11:38,688][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040600] [Batch 01648/04869] [00:18:08/00:35:26, 0.660s/it]: train_loss_raw=1.2468, running_loss=1.2550, LR=0.000100
[2025-08-26 07:11:43,923][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040608] [Batch 01656/04869] [00:18:13/00:35:21, 0.660s/it]: train_loss_raw=1.3012, running_loss=1.2558, LR=0.000100
[2025-08-26 07:11:49,404][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040616] [Batch 01664/04869] [00:18:18/00:35:16, 0.660s/it]: train_loss_raw=1.1912, running_loss=1.2561, LR=0.000100
[2025-08-26 07:11:54,674][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040624] [Batch 01672/04869] [00:18:24/00:35:11, 0.660s/it]: train_loss_raw=1.2466, running_loss=1.2550, LR=0.000100
[2025-08-26 07:11:59,827][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040632] [Batch 01680/04869] [00:18:29/00:35:05, 0.660s/it]: train_loss_raw=1.1325, running_loss=1.2534, LR=0.000100
[2025-08-26 07:12:04,979][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040640] [Batch 01688/04869] [00:18:34/00:35:00, 0.660s/it]: train_loss_raw=1.1944, running_loss=1.2510, LR=0.000100
[2025-08-26 07:12:10,122][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040648] [Batch 01696/04869] [00:18:39/00:34:54, 0.660s/it]: train_loss_raw=1.1056, running_loss=1.2472, LR=0.000100
[2025-08-26 07:12:15,377][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040656] [Batch 01704/04869] [00:18:44/00:34:49, 0.660s/it]: train_loss_raw=1.3725, running_loss=1.2479, LR=0.000100
[2025-08-26 07:12:20,670][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040664] [Batch 01712/04869] [00:18:50/00:34:44, 0.660s/it]: train_loss_raw=1.3143, running_loss=1.2494, LR=0.000100
[2025-08-26 07:12:25,815][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040672] [Batch 01720/04869] [00:18:55/00:34:38, 0.660s/it]: train_loss_raw=1.2968, running_loss=1.2482, LR=0.000100
[2025-08-26 07:12:31,132][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040680] [Batch 01728/04869] [00:19:00/00:34:33, 0.660s/it]: train_loss_raw=1.4261, running_loss=1.2511, LR=0.000100
[2025-08-26 07:12:36,294][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040688] [Batch 01736/04869] [00:19:05/00:34:27, 0.660s/it]: train_loss_raw=1.2936, running_loss=1.2518, LR=0.000100
[2025-08-26 07:12:41,446][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040696] [Batch 01744/04869] [00:19:10/00:34:22, 0.660s/it]: train_loss_raw=1.1869, running_loss=1.2514, LR=0.000100
[2025-08-26 07:12:47,643][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040704] [Batch 01752/04869] [00:19:17/00:34:18, 0.660s/it]: train_loss_raw=1.2621, running_loss=1.2527, LR=0.000100
[2025-08-26 07:12:54,028][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040712] [Batch 01760/04869] [00:19:23/00:34:15, 0.661s/it]: train_loss_raw=1.1367, running_loss=1.2512, LR=0.000100
[2025-08-26 07:12:59,193][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040720] [Batch 01768/04869] [00:19:28/00:34:09, 0.661s/it]: train_loss_raw=1.2486, running_loss=1.2533, LR=0.000100
[2025-08-26 07:13:04,567][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040728] [Batch 01776/04869] [00:19:34/00:34:04, 0.661s/it]: train_loss_raw=1.2261, running_loss=1.2524, LR=0.000100
[2025-08-26 07:13:09,727][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040736] [Batch 01784/04869] [00:19:39/00:33:59, 0.661s/it]: train_loss_raw=1.2392, running_loss=1.2535, LR=0.000100
[2025-08-26 07:13:14,881][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040744] [Batch 01792/04869] [00:19:44/00:33:53, 0.661s/it]: train_loss_raw=1.2048, running_loss=1.2542, LR=0.000100
[2025-08-26 07:13:20,024][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040752] [Batch 01800/04869] [00:19:49/00:33:48, 0.661s/it]: train_loss_raw=1.1821, running_loss=1.2533, LR=0.000100
[2025-08-26 07:13:25,291][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040760] [Batch 01808/04869] [00:19:54/00:33:42, 0.661s/it]: train_loss_raw=1.1700, running_loss=1.2521, LR=0.000100
[2025-08-26 07:13:30,764][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040768] [Batch 01816/04869] [00:20:00/00:33:37, 0.661s/it]: train_loss_raw=1.2318, running_loss=1.2539, LR=0.000100
[2025-08-26 07:13:35,915][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040776] [Batch 01824/04869] [00:20:05/00:33:32, 0.661s/it]: train_loss_raw=1.2762, running_loss=1.2541, LR=0.000100
[2025-08-26 07:13:41,470][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040784] [Batch 01832/04869] [00:20:10/00:33:27, 0.661s/it]: train_loss_raw=1.2825, running_loss=1.2574, LR=0.000100
[2025-08-26 07:13:46,758][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040792] [Batch 01840/04869] [00:20:16/00:33:22, 0.661s/it]: train_loss_raw=1.1696, running_loss=1.2574, LR=0.000100
[2025-08-26 07:13:51,903][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040800] [Batch 01848/04869] [00:20:21/00:33:16, 0.661s/it]: train_loss_raw=1.2843, running_loss=1.2587, LR=0.000100
[2025-08-26 07:13:57,532][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040808] [Batch 01856/04869] [00:20:27/00:33:11, 0.661s/it]: train_loss_raw=1.2320, running_loss=1.2575, LR=0.000100
[2025-08-26 07:14:02,685][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040816] [Batch 01864/04869] [00:20:32/00:33:06, 0.661s/it]: train_loss_raw=1.1983, running_loss=1.2571, LR=0.000100
[2025-08-26 07:14:07,938][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040824] [Batch 01872/04869] [00:20:37/00:33:01, 0.661s/it]: train_loss_raw=1.1962, running_loss=1.2554, LR=0.000100
[2025-08-26 07:14:13,631][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040832] [Batch 01880/04869] [00:20:43/00:32:56, 0.661s/it]: train_loss_raw=1.3691, running_loss=1.2574, LR=0.000100
[2025-08-26 07:14:19,380][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040840] [Batch 01888/04869] [00:20:48/00:32:51, 0.661s/it]: train_loss_raw=1.2599, running_loss=1.2589, LR=0.000100
[2025-08-26 07:14:24,917][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040848] [Batch 01896/04869] [00:20:54/00:32:46, 0.662s/it]: train_loss_raw=1.2236, running_loss=1.2593, LR=0.000100
[2025-08-26 07:14:30,329][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040856] [Batch 01904/04869] [00:20:59/00:32:41, 0.662s/it]: train_loss_raw=1.2657, running_loss=1.2572, LR=0.000100
[2025-08-26 07:14:35,467][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040864] [Batch 01912/04869] [00:21:04/00:32:36, 0.662s/it]: train_loss_raw=1.1750, running_loss=1.2568, LR=0.000100
[2025-08-26 07:14:40,615][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040872] [Batch 01920/04869] [00:21:10/00:32:30, 0.662s/it]: train_loss_raw=1.2538, running_loss=1.2572, LR=0.000100
[2025-08-26 07:14:45,771][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040880] [Batch 01928/04869] [00:21:15/00:32:25, 0.661s/it]: train_loss_raw=1.1723, running_loss=1.2572, LR=0.000100
[2025-08-26 07:14:50,921][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040888] [Batch 01936/04869] [00:21:20/00:32:19, 0.661s/it]: train_loss_raw=1.2092, running_loss=1.2574, LR=0.000100
[2025-08-26 07:14:56,065][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040896] [Batch 01944/04869] [00:21:25/00:32:14, 0.661s/it]: train_loss_raw=1.2429, running_loss=1.2588, LR=0.000100
[2025-08-26 07:15:01,211][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040904] [Batch 01952/04869] [00:21:30/00:32:08, 0.661s/it]: train_loss_raw=1.2153, running_loss=1.2579, LR=0.000100
[2025-08-26 07:15:06,352][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040912] [Batch 01960/04869] [00:21:35/00:32:03, 0.661s/it]: train_loss_raw=1.2879, running_loss=1.2575, LR=0.000100
[2025-08-26 07:15:11,545][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040920] [Batch 01968/04869] [00:21:41/00:31:57, 0.661s/it]: train_loss_raw=1.2872, running_loss=1.2561, LR=0.000100
[2025-08-26 07:15:17,255][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040928] [Batch 01976/04869] [00:21:46/00:31:53, 0.661s/it]: train_loss_raw=1.2678, running_loss=1.2560, LR=0.000100
[2025-08-26 07:15:22,840][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040936] [Batch 01984/04869] [00:21:52/00:31:48, 0.661s/it]: train_loss_raw=1.1917, running_loss=1.2526, LR=0.000100
[2025-08-26 07:15:28,146][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040944] [Batch 01992/04869] [00:21:57/00:31:43, 0.661s/it]: train_loss_raw=1.3142, running_loss=1.2528, LR=0.000100
[2025-08-26 07:15:33,715][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040952] [Batch 02000/04869] [00:22:03/00:31:38, 0.662s/it]: train_loss_raw=1.3197, running_loss=1.2532, LR=0.000100
[2025-08-26 07:15:39,850][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040960] [Batch 02008/04869] [00:22:09/00:31:34, 0.662s/it]: train_loss_raw=1.2821, running_loss=1.2515, LR=0.000100
[2025-08-26 07:15:45,142][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040968] [Batch 02016/04869] [00:22:14/00:31:28, 0.662s/it]: train_loss_raw=1.2735, running_loss=1.2541, LR=0.000100
[2025-08-26 07:15:50,308][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040976] [Batch 02024/04869] [00:22:19/00:31:23, 0.662s/it]: train_loss_raw=1.3075, running_loss=1.2565, LR=0.000100
[2025-08-26 07:15:55,451][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040984] [Batch 02032/04869] [00:22:24/00:31:17, 0.662s/it]: train_loss_raw=1.2369, running_loss=1.2547, LR=0.000100
[2025-08-26 07:16:00,592][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 040992] [Batch 02040/04869] [00:22:30/00:31:12, 0.662s/it]: train_loss_raw=1.2315, running_loss=1.2527, LR=0.000100
[2025-08-26 07:16:05,804][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041000] [Batch 02048/04869] [00:22:35/00:31:06, 0.662s/it]: train_loss_raw=1.2710, running_loss=1.2518, LR=0.000100
[2025-08-26 07:16:10,943][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041008] [Batch 02056/04869] [00:22:40/00:31:01, 0.662s/it]: train_loss_raw=1.2398, running_loss=1.2498, LR=0.000100
[2025-08-26 07:16:16,519][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041016] [Batch 02064/04869] [00:22:46/00:30:56, 0.662s/it]: train_loss_raw=1.2657, running_loss=1.2494, LR=0.000100
[2025-08-26 07:16:21,784][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041024] [Batch 02072/04869] [00:22:51/00:30:51, 0.662s/it]: train_loss_raw=1.3472, running_loss=1.2494, LR=0.000100
[2025-08-26 07:16:27,012][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041032] [Batch 02080/04869] [00:22:56/00:30:45, 0.662s/it]: train_loss_raw=1.2681, running_loss=1.2510, LR=0.000100
[2025-08-26 07:16:32,193][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041040] [Batch 02088/04869] [00:23:01/00:30:40, 0.662s/it]: train_loss_raw=1.2458, running_loss=1.2493, LR=0.000100
[2025-08-26 07:16:37,486][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041048] [Batch 02096/04869] [00:23:06/00:30:34, 0.662s/it]: train_loss_raw=1.3152, running_loss=1.2541, LR=0.000100
[2025-08-26 07:16:42,668][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041056] [Batch 02104/04869] [00:23:12/00:30:29, 0.662s/it]: train_loss_raw=1.2489, running_loss=1.2550, LR=0.000100
[2025-08-26 07:16:48,012][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041064] [Batch 02112/04869] [00:23:17/00:30:24, 0.662s/it]: train_loss_raw=1.1590, running_loss=1.2546, LR=0.000100
[2025-08-26 07:16:53,321][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041072] [Batch 02120/04869] [00:23:22/00:30:19, 0.662s/it]: train_loss_raw=1.1841, running_loss=1.2505, LR=0.000100
[2025-08-26 07:16:58,469][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041080] [Batch 02128/04869] [00:23:27/00:30:13, 0.662s/it]: train_loss_raw=1.1922, running_loss=1.2488, LR=0.000100
[2025-08-26 07:17:03,890][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041088] [Batch 02136/04869] [00:23:33/00:30:08, 0.662s/it]: train_loss_raw=1.3543, running_loss=1.2478, LR=0.000100
[2025-08-26 07:17:09,025][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041096] [Batch 02144/04869] [00:23:38/00:30:02, 0.662s/it]: train_loss_raw=1.2051, running_loss=1.2459, LR=0.000100
[2025-08-26 07:17:14,175][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041104] [Batch 02152/04869] [00:23:43/00:29:57, 0.662s/it]: train_loss_raw=1.2109, running_loss=1.2435, LR=0.000100
[2025-08-26 07:17:19,571][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041112] [Batch 02160/04869] [00:23:49/00:29:52, 0.662s/it]: train_loss_raw=1.1852, running_loss=1.2436, LR=0.000100
[2025-08-26 07:17:24,719][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041120] [Batch 02168/04869] [00:23:54/00:29:46, 0.662s/it]: train_loss_raw=1.1731, running_loss=1.2431, LR=0.000100
[2025-08-26 07:17:30,164][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041128] [Batch 02176/04869] [00:23:59/00:29:41, 0.662s/it]: train_loss_raw=1.1923, running_loss=1.2437, LR=0.000100
[2025-08-26 07:17:35,355][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041136] [Batch 02184/04869] [00:24:04/00:29:36, 0.662s/it]: train_loss_raw=1.0946, running_loss=1.2439, LR=0.000100
[2025-08-26 07:17:40,722][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041144] [Batch 02192/04869] [00:24:10/00:29:31, 0.662s/it]: train_loss_raw=1.2093, running_loss=1.2443, LR=0.000100
[2025-08-26 07:17:46,311][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041152] [Batch 02200/04869] [00:24:15/00:29:26, 0.662s/it]: train_loss_raw=1.2948, running_loss=1.2469, LR=0.000100
[2025-08-26 07:17:51,528][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041160] [Batch 02208/04869] [00:24:21/00:29:20, 0.662s/it]: train_loss_raw=1.3990, running_loss=1.2505, LR=0.000100
[2025-08-26 07:17:56,678][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041168] [Batch 02216/04869] [00:24:26/00:29:15, 0.662s/it]: train_loss_raw=1.2073, running_loss=1.2472, LR=0.000100
[2025-08-26 07:18:02,081][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041176] [Batch 02224/04869] [00:24:31/00:29:10, 0.662s/it]: train_loss_raw=1.2129, running_loss=1.2474, LR=0.000100
[2025-08-26 07:18:07,210][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041184] [Batch 02232/04869] [00:24:36/00:29:04, 0.662s/it]: train_loss_raw=1.3376, running_loss=1.2471, LR=0.000100
[2025-08-26 07:18:12,327][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041192] [Batch 02240/04869] [00:24:41/00:28:59, 0.662s/it]: train_loss_raw=1.2149, running_loss=1.2466, LR=0.000100
[2025-08-26 07:18:17,445][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041200] [Batch 02248/04869] [00:24:46/00:28:53, 0.661s/it]: train_loss_raw=1.1950, running_loss=1.2457, LR=0.000100
[2025-08-26 07:18:22,648][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041208] [Batch 02256/04869] [00:24:52/00:28:48, 0.661s/it]: train_loss_raw=1.2377, running_loss=1.2446, LR=0.000100
[2025-08-26 07:18:28,051][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041216] [Batch 02264/04869] [00:24:57/00:28:43, 0.661s/it]: train_loss_raw=1.2291, running_loss=1.2416, LR=0.000100
[2025-08-26 07:18:33,179][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041224] [Batch 02272/04869] [00:25:02/00:28:37, 0.661s/it]: train_loss_raw=1.3562, running_loss=1.2454, LR=0.000100
[2025-08-26 07:18:38,294][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041232] [Batch 02280/04869] [00:25:07/00:28:32, 0.661s/it]: train_loss_raw=1.1292, running_loss=1.2450, LR=0.000100
[2025-08-26 07:18:43,653][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041240] [Batch 02288/04869] [00:25:13/00:28:26, 0.661s/it]: train_loss_raw=1.3171, running_loss=1.2442, LR=0.000100
[2025-08-26 07:18:49,050][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041248] [Batch 02296/04869] [00:25:18/00:28:21, 0.661s/it]: train_loss_raw=1.2329, running_loss=1.2473, LR=0.000100
[2025-08-26 07:18:54,189][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041256] [Batch 02304/04869] [00:25:23/00:28:16, 0.661s/it]: train_loss_raw=1.1460, running_loss=1.2434, LR=0.000100
[2025-08-26 07:18:59,596][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041264] [Batch 02312/04869] [00:25:29/00:28:11, 0.661s/it]: train_loss_raw=1.2580, running_loss=1.2464, LR=0.000100
[2025-08-26 07:19:04,894][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041272] [Batch 02320/04869] [00:25:34/00:28:05, 0.661s/it]: train_loss_raw=1.2130, running_loss=1.2458, LR=0.000100
[2025-08-26 07:19:10,031][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041280] [Batch 02328/04869] [00:25:39/00:28:00, 0.661s/it]: train_loss_raw=1.2099, running_loss=1.2470, LR=0.000100
[2025-08-26 07:19:15,386][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041288] [Batch 02336/04869] [00:25:44/00:27:55, 0.661s/it]: train_loss_raw=1.1963, running_loss=1.2495, LR=0.000100
[2025-08-26 07:19:20,529][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041296] [Batch 02344/04869] [00:25:50/00:27:49, 0.661s/it]: train_loss_raw=1.2024, running_loss=1.2495, LR=0.000100
[2025-08-26 07:19:25,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041304] [Batch 02352/04869] [00:25:55/00:27:44, 0.661s/it]: train_loss_raw=1.2248, running_loss=1.2501, LR=0.000100
[2025-08-26 07:19:30,836][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041312] [Batch 02360/04869] [00:26:00/00:27:38, 0.661s/it]: train_loss_raw=1.3046, running_loss=1.2483, LR=0.000100
[2025-08-26 07:19:36,381][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041320] [Batch 02368/04869] [00:26:05/00:27:33, 0.661s/it]: train_loss_raw=1.2728, running_loss=1.2479, LR=0.000100
[2025-08-26 07:19:41,528][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041328] [Batch 02376/04869] [00:26:11/00:27:28, 0.661s/it]: train_loss_raw=1.2425, running_loss=1.2455, LR=0.000100
[2025-08-26 07:19:46,683][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041336] [Batch 02384/04869] [00:26:16/00:27:22, 0.661s/it]: train_loss_raw=1.3876, running_loss=1.2488, LR=0.000100
[2025-08-26 07:19:52,400][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041344] [Batch 02392/04869] [00:26:21/00:27:18, 0.661s/it]: train_loss_raw=1.3063, running_loss=1.2493, LR=0.000100
[2025-08-26 07:19:57,880][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041352] [Batch 02400/04869] [00:26:27/00:27:13, 0.661s/it]: train_loss_raw=1.2701, running_loss=1.2462, LR=0.000100
[2025-08-26 07:20:03,069][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041360] [Batch 02408/04869] [00:26:32/00:27:07, 0.661s/it]: train_loss_raw=1.2797, running_loss=1.2452, LR=0.000100
[2025-08-26 07:20:08,627][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041368] [Batch 02416/04869] [00:26:38/00:27:02, 0.661s/it]: train_loss_raw=1.2423, running_loss=1.2443, LR=0.000100
[2025-08-26 07:20:13,752][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041376] [Batch 02424/04869] [00:26:43/00:26:57, 0.661s/it]: train_loss_raw=1.2652, running_loss=1.2465, LR=0.000100
[2025-08-26 07:20:18,872][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041384] [Batch 02432/04869] [00:26:48/00:26:51, 0.661s/it]: train_loss_raw=1.3619, running_loss=1.2468, LR=0.000100
[2025-08-26 07:20:24,230][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041392] [Batch 02440/04869] [00:26:53/00:26:46, 0.661s/it]: train_loss_raw=1.3450, running_loss=1.2477, LR=0.000100
[2025-08-26 07:20:29,502][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041400] [Batch 02448/04869] [00:26:59/00:26:41, 0.661s/it]: train_loss_raw=1.3015, running_loss=1.2482, LR=0.000100
[2025-08-26 07:20:34,661][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041408] [Batch 02456/04869] [00:27:04/00:26:35, 0.661s/it]: train_loss_raw=1.2579, running_loss=1.2502, LR=0.000100
[2025-08-26 07:20:39,783][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041416] [Batch 02464/04869] [00:27:09/00:26:30, 0.661s/it]: train_loss_raw=1.2733, running_loss=1.2514, LR=0.000100
[2025-08-26 07:20:45,265][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041424] [Batch 02472/04869] [00:27:14/00:26:25, 0.661s/it]: train_loss_raw=1.2683, running_loss=1.2516, LR=0.000100
[2025-08-26 07:20:50,826][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041432] [Batch 02480/04869] [00:27:20/00:26:20, 0.661s/it]: train_loss_raw=1.1763, running_loss=1.2495, LR=0.000100
[2025-08-26 07:20:56,576][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041440] [Batch 02488/04869] [00:27:26/00:26:15, 0.662s/it]: train_loss_raw=1.1603, running_loss=1.2481, LR=0.000100
[2025-08-26 07:21:02,037][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041448] [Batch 02496/04869] [00:27:31/00:26:10, 0.662s/it]: train_loss_raw=1.1950, running_loss=1.2478, LR=0.000100
[2025-08-26 07:21:07,202][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041456] [Batch 02504/04869] [00:27:36/00:26:04, 0.662s/it]: train_loss_raw=1.2209, running_loss=1.2501, LR=0.000100
[2025-08-26 07:21:12,359][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041464] [Batch 02512/04869] [00:27:41/00:25:59, 0.662s/it]: train_loss_raw=1.2690, running_loss=1.2492, LR=0.000100
[2025-08-26 07:21:17,513][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041472] [Batch 02520/04869] [00:27:47/00:25:53, 0.662s/it]: train_loss_raw=1.1955, running_loss=1.2484, LR=0.000100
[2025-08-26 07:21:23,228][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041480] [Batch 02528/04869] [00:27:52/00:25:48, 0.662s/it]: train_loss_raw=1.2235, running_loss=1.2476, LR=0.000100
[2025-08-26 07:21:28,661][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041488] [Batch 02536/04869] [00:27:58/00:25:43, 0.662s/it]: train_loss_raw=1.3569, running_loss=1.2495, LR=0.000100
[2025-08-26 07:21:33,822][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041496] [Batch 02544/04869] [00:28:03/00:25:38, 0.662s/it]: train_loss_raw=1.3575, running_loss=1.2492, LR=0.000100
[2025-08-26 07:21:39,048][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041504] [Batch 02552/04869] [00:28:08/00:25:33, 0.662s/it]: train_loss_raw=1.2526, running_loss=1.2494, LR=0.000100
[2025-08-26 07:21:44,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041512] [Batch 02560/04869] [00:28:14/00:25:28, 0.662s/it]: train_loss_raw=1.2754, running_loss=1.2524, LR=0.000100
[2025-08-26 07:21:50,141][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041520] [Batch 02568/04869] [00:28:19/00:25:22, 0.662s/it]: train_loss_raw=1.3135, running_loss=1.2530, LR=0.000100
[2025-08-26 07:21:55,377][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041528] [Batch 02576/04869] [00:28:24/00:25:17, 0.662s/it]: train_loss_raw=1.2227, running_loss=1.2510, LR=0.000100
[2025-08-26 07:22:00,563][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041536] [Batch 02584/04869] [00:28:30/00:25:12, 0.662s/it]: train_loss_raw=1.1496, running_loss=1.2501, LR=0.000100
[2025-08-26 07:22:05,714][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041544] [Batch 02592/04869] [00:28:35/00:25:06, 0.662s/it]: train_loss_raw=1.2577, running_loss=1.2505, LR=0.000100
[2025-08-26 07:22:11,182][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041552] [Batch 02600/04869] [00:28:40/00:25:01, 0.662s/it]: train_loss_raw=1.2336, running_loss=1.2500, LR=0.000100
[2025-08-26 07:22:16,324][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041560] [Batch 02608/04869] [00:28:45/00:24:56, 0.662s/it]: train_loss_raw=1.3530, running_loss=1.2524, LR=0.000100
[2025-08-26 07:22:21,887][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041568] [Batch 02616/04869] [00:28:51/00:24:51, 0.662s/it]: train_loss_raw=1.3392, running_loss=1.2517, LR=0.000100
[2025-08-26 07:22:27,604][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041576] [Batch 02624/04869] [00:28:57/00:24:46, 0.662s/it]: train_loss_raw=1.1803, running_loss=1.2511, LR=0.000100
[2025-08-26 07:22:32,775][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041584] [Batch 02632/04869] [00:29:02/00:24:40, 0.662s/it]: train_loss_raw=1.2393, running_loss=1.2499, LR=0.000100
[2025-08-26 07:22:37,924][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041592] [Batch 02640/04869] [00:29:07/00:24:35, 0.662s/it]: train_loss_raw=1.3138, running_loss=1.2508, LR=0.000100
[2025-08-26 07:22:43,479][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041600] [Batch 02648/04869] [00:29:12/00:24:30, 0.662s/it]: train_loss_raw=1.1068, running_loss=1.2506, LR=0.000100
[2025-08-26 07:22:48,884][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041608] [Batch 02656/04869] [00:29:18/00:24:25, 0.662s/it]: train_loss_raw=1.0975, running_loss=1.2487, LR=0.000100
[2025-08-26 07:22:54,023][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041616] [Batch 02664/04869] [00:29:23/00:24:19, 0.662s/it]: train_loss_raw=1.3267, running_loss=1.2527, LR=0.000100
[2025-08-26 07:22:59,170][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041624] [Batch 02672/04869] [00:29:28/00:24:14, 0.662s/it]: train_loss_raw=1.2178, running_loss=1.2519, LR=0.000100
[2025-08-26 07:23:04,310][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041632] [Batch 02680/04869] [00:29:33/00:24:08, 0.662s/it]: train_loss_raw=1.2662, running_loss=1.2528, LR=0.000100
[2025-08-26 07:23:09,449][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041640] [Batch 02688/04869] [00:29:38/00:24:03, 0.662s/it]: train_loss_raw=1.1918, running_loss=1.2509, LR=0.000100
[2025-08-26 07:23:14,672][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041648] [Batch 02696/04869] [00:29:44/00:23:58, 0.662s/it]: train_loss_raw=1.2490, running_loss=1.2502, LR=0.000100
[2025-08-26 07:23:19,862][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041656] [Batch 02704/04869] [00:29:49/00:23:52, 0.662s/it]: train_loss_raw=1.2805, running_loss=1.2504, LR=0.000100
[2025-08-26 07:23:25,284][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041664] [Batch 02712/04869] [00:29:54/00:23:47, 0.662s/it]: train_loss_raw=1.2401, running_loss=1.2522, LR=0.000100
[2025-08-26 07:23:30,842][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041672] [Batch 02720/04869] [00:30:00/00:23:42, 0.662s/it]: train_loss_raw=1.2386, running_loss=1.2502, LR=0.000100
[2025-08-26 07:23:36,050][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041680] [Batch 02728/04869] [00:30:05/00:23:37, 0.662s/it]: train_loss_raw=1.2087, running_loss=1.2496, LR=0.000100
[2025-08-26 07:23:41,201][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041688] [Batch 02736/04869] [00:30:10/00:23:31, 0.662s/it]: train_loss_raw=1.3540, running_loss=1.2490, LR=0.000100
[2025-08-26 07:23:46,340][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041696] [Batch 02744/04869] [00:30:15/00:23:26, 0.662s/it]: train_loss_raw=1.3370, running_loss=1.2491, LR=0.000100
[2025-08-26 07:23:51,606][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041704] [Batch 02752/04869] [00:30:21/00:23:20, 0.662s/it]: train_loss_raw=1.3301, running_loss=1.2513, LR=0.000100
[2025-08-26 07:23:56,728][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041712] [Batch 02760/04869] [00:30:26/00:23:15, 0.662s/it]: train_loss_raw=1.3623, running_loss=1.2516, LR=0.000100
[2025-08-26 07:24:01,857][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041720] [Batch 02768/04869] [00:30:31/00:23:10, 0.662s/it]: train_loss_raw=1.2517, running_loss=1.2517, LR=0.000100
[2025-08-26 07:24:06,973][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041728] [Batch 02776/04869] [00:30:36/00:23:04, 0.662s/it]: train_loss_raw=1.2858, running_loss=1.2524, LR=0.000100
[2025-08-26 07:24:12,097][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041736] [Batch 02784/04869] [00:30:41/00:22:59, 0.661s/it]: train_loss_raw=1.2189, running_loss=1.2522, LR=0.000100
[2025-08-26 07:24:17,229][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041744] [Batch 02792/04869] [00:30:46/00:22:53, 0.661s/it]: train_loss_raw=1.1882, running_loss=1.2525, LR=0.000100
[2025-08-26 07:24:22,352][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041752] [Batch 02800/04869] [00:30:51/00:22:48, 0.661s/it]: train_loss_raw=1.2627, running_loss=1.2520, LR=0.000100
[2025-08-26 07:24:27,488][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041760] [Batch 02808/04869] [00:30:56/00:22:42, 0.661s/it]: train_loss_raw=1.1307, running_loss=1.2493, LR=0.000100
[2025-08-26 07:24:32,613][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041768] [Batch 02816/04869] [00:31:02/00:22:37, 0.661s/it]: train_loss_raw=1.2449, running_loss=1.2519, LR=0.000100
[2025-08-26 07:24:37,755][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041776] [Batch 02824/04869] [00:31:07/00:22:32, 0.661s/it]: train_loss_raw=1.2483, running_loss=1.2518, LR=0.000100
[2025-08-26 07:24:43,118][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041784] [Batch 02832/04869] [00:31:12/00:22:26, 0.661s/it]: train_loss_raw=1.3421, running_loss=1.2535, LR=0.000100
[2025-08-26 07:24:48,415][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041792] [Batch 02840/04869] [00:31:17/00:22:21, 0.661s/it]: train_loss_raw=1.1481, running_loss=1.2525, LR=0.000100
[2025-08-26 07:24:53,554][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041800] [Batch 02848/04869] [00:31:23/00:22:16, 0.661s/it]: train_loss_raw=1.1851, running_loss=1.2529, LR=0.000100
[2025-08-26 07:24:58,694][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041808] [Batch 02856/04869] [00:31:28/00:22:10, 0.661s/it]: train_loss_raw=1.1895, running_loss=1.2516, LR=0.000100
[2025-08-26 07:25:04,007][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041816] [Batch 02864/04869] [00:31:33/00:22:05, 0.661s/it]: train_loss_raw=1.2125, running_loss=1.2514, LR=0.000100
[2025-08-26 07:25:09,142][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041824] [Batch 02872/04869] [00:31:38/00:22:00, 0.661s/it]: train_loss_raw=1.1781, running_loss=1.2497, LR=0.000100
[2025-08-26 07:25:14,281][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041832] [Batch 02880/04869] [00:31:43/00:21:54, 0.661s/it]: train_loss_raw=1.2404, running_loss=1.2474, LR=0.000100
[2025-08-26 07:25:19,747][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041840] [Batch 02888/04869] [00:31:49/00:21:49, 0.661s/it]: train_loss_raw=1.2609, running_loss=1.2463, LR=0.000100
[2025-08-26 07:25:24,900][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041848] [Batch 02896/04869] [00:31:54/00:21:44, 0.661s/it]: train_loss_raw=1.2814, running_loss=1.2468, LR=0.000100
[2025-08-26 07:25:30,111][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041856] [Batch 02904/04869] [00:31:59/00:21:38, 0.661s/it]: train_loss_raw=1.1535, running_loss=1.2448, LR=0.000100
[2025-08-26 07:25:35,272][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041864] [Batch 02912/04869] [00:32:04/00:21:33, 0.661s/it]: train_loss_raw=1.2261, running_loss=1.2439, LR=0.000100
[2025-08-26 07:25:40,925][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041872] [Batch 02920/04869] [00:32:10/00:21:28, 0.661s/it]: train_loss_raw=1.3084, running_loss=1.2447, LR=0.000100
[2025-08-26 07:25:46,064][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041880] [Batch 02928/04869] [00:32:15/00:21:23, 0.661s/it]: train_loss_raw=1.3874, running_loss=1.2461, LR=0.000100
[2025-08-26 07:25:51,945][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041888] [Batch 02936/04869] [00:32:21/00:21:18, 0.661s/it]: train_loss_raw=1.2428, running_loss=1.2441, LR=0.000100
[2025-08-26 07:25:57,863][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041896] [Batch 02944/04869] [00:32:27/00:21:13, 0.661s/it]: train_loss_raw=1.3336, running_loss=1.2450, LR=0.000100
[2025-08-26 07:26:03,005][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041904] [Batch 02952/04869] [00:32:32/00:21:07, 0.661s/it]: train_loss_raw=1.2143, running_loss=1.2446, LR=0.000100
[2025-08-26 07:26:08,155][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041912] [Batch 02960/04869] [00:32:37/00:21:02, 0.661s/it]: train_loss_raw=1.2870, running_loss=1.2458, LR=0.000100
[2025-08-26 07:26:13,550][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041920] [Batch 02968/04869] [00:32:43/00:20:57, 0.661s/it]: train_loss_raw=1.2452, running_loss=1.2456, LR=0.000100
[2025-08-26 07:26:18,853][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041928] [Batch 02976/04869] [00:32:48/00:20:52, 0.661s/it]: train_loss_raw=1.3163, running_loss=1.2470, LR=0.000100
[2025-08-26 07:26:23,997][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041936] [Batch 02984/04869] [00:32:53/00:20:46, 0.661s/it]: train_loss_raw=1.2455, running_loss=1.2494, LR=0.000100
[2025-08-26 07:26:29,134][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041944] [Batch 02992/04869] [00:32:58/00:20:41, 0.661s/it]: train_loss_raw=1.1152, running_loss=1.2474, LR=0.000100
[2025-08-26 07:26:34,272][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041952] [Batch 03000/04869] [00:33:03/00:20:35, 0.661s/it]: train_loss_raw=1.1999, running_loss=1.2468, LR=0.000100
[2025-08-26 07:26:39,410][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041960] [Batch 03008/04869] [00:33:08/00:20:30, 0.661s/it]: train_loss_raw=1.2756, running_loss=1.2463, LR=0.000100
[2025-08-26 07:26:44,813][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041968] [Batch 03016/04869] [00:33:14/00:20:25, 0.661s/it]: train_loss_raw=1.1925, running_loss=1.2478, LR=0.000100
[2025-08-26 07:26:49,971][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041976] [Batch 03024/04869] [00:33:19/00:20:19, 0.661s/it]: train_loss_raw=1.2073, running_loss=1.2472, LR=0.000100
[2025-08-26 07:26:55,464][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041984] [Batch 03032/04869] [00:33:24/00:20:14, 0.661s/it]: train_loss_raw=1.2778, running_loss=1.2471, LR=0.000100
[2025-08-26 07:27:00,795][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 041992] [Batch 03040/04869] [00:33:30/00:20:09, 0.661s/it]: train_loss_raw=1.3698, running_loss=1.2492, LR=0.000100
[2025-08-26 07:27:06,287][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042000] [Batch 03048/04869] [00:33:35/00:20:04, 0.661s/it]: train_loss_raw=1.2684, running_loss=1.2489, LR=0.000100
[2025-08-26 07:27:15,654][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042008] [Batch 03056/04869] [00:33:45/00:20:01, 0.663s/it]: train_loss_raw=1.3942, running_loss=1.2509, LR=0.000100
[2025-08-26 07:27:20,799][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042016] [Batch 03064/04869] [00:33:50/00:19:56, 0.663s/it]: train_loss_raw=1.3073, running_loss=1.2530, LR=0.000100
[2025-08-26 07:27:26,084][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042024] [Batch 03072/04869] [00:33:55/00:19:50, 0.663s/it]: train_loss_raw=1.3023, running_loss=1.2535, LR=0.000100
[2025-08-26 07:27:31,443][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042032] [Batch 03080/04869] [00:34:00/00:19:45, 0.663s/it]: train_loss_raw=1.3138, running_loss=1.2518, LR=0.000100
[2025-08-26 07:27:36,576][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042040] [Batch 03088/04869] [00:34:06/00:19:40, 0.663s/it]: train_loss_raw=1.2991, running_loss=1.2520, LR=0.000100
[2025-08-26 07:27:41,711][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042048] [Batch 03096/04869] [00:34:11/00:19:34, 0.663s/it]: train_loss_raw=1.2036, running_loss=1.2539, LR=0.000100
[2025-08-26 07:27:47,012][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042056] [Batch 03104/04869] [00:34:16/00:19:29, 0.663s/it]: train_loss_raw=1.2726, running_loss=1.2545, LR=0.000100
[2025-08-26 07:27:52,164][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042064] [Batch 03112/04869] [00:34:21/00:19:23, 0.662s/it]: train_loss_raw=1.2256, running_loss=1.2531, LR=0.000100
[2025-08-26 07:27:57,289][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042072] [Batch 03120/04869] [00:34:26/00:19:18, 0.662s/it]: train_loss_raw=1.1746, running_loss=1.2495, LR=0.000100
[2025-08-26 07:28:02,410][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042080] [Batch 03128/04869] [00:34:31/00:19:13, 0.662s/it]: train_loss_raw=1.3366, running_loss=1.2488, LR=0.000100
[2025-08-26 07:28:07,535][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042088] [Batch 03136/04869] [00:34:37/00:19:07, 0.662s/it]: train_loss_raw=1.2500, running_loss=1.2486, LR=0.000100
[2025-08-26 07:28:12,651][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042096] [Batch 03144/04869] [00:34:42/00:19:02, 0.662s/it]: train_loss_raw=1.2772, running_loss=1.2483, LR=0.000100
[2025-08-26 07:28:17,840][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042104] [Batch 03152/04869] [00:34:47/00:18:57, 0.662s/it]: train_loss_raw=1.2105, running_loss=1.2463, LR=0.000100
[2025-08-26 07:28:23,640][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042112] [Batch 03160/04869] [00:34:53/00:18:52, 0.662s/it]: train_loss_raw=1.3404, running_loss=1.2443, LR=0.000100
[2025-08-26 07:28:29,255][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042120] [Batch 03168/04869] [00:34:58/00:18:46, 0.662s/it]: train_loss_raw=1.2795, running_loss=1.2442, LR=0.000100
[2025-08-26 07:28:34,557][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042128] [Batch 03176/04869] [00:35:04/00:18:41, 0.662s/it]: train_loss_raw=1.3565, running_loss=1.2432, LR=0.000100
[2025-08-26 07:28:40,095][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042136] [Batch 03184/04869] [00:35:09/00:18:36, 0.663s/it]: train_loss_raw=1.1880, running_loss=1.2423, LR=0.000100
[2025-08-26 07:28:45,221][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042144] [Batch 03192/04869] [00:35:14/00:18:31, 0.663s/it]: train_loss_raw=1.2331, running_loss=1.2446, LR=0.000100
[2025-08-26 07:28:50,618][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042152] [Batch 03200/04869] [00:35:20/00:18:25, 0.663s/it]: train_loss_raw=1.2060, running_loss=1.2444, LR=0.000100
[2025-08-26 07:28:56,325][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042160] [Batch 03208/04869] [00:35:25/00:18:20, 0.663s/it]: train_loss_raw=1.1722, running_loss=1.2441, LR=0.000100
[2025-08-26 07:29:01,477][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042168] [Batch 03216/04869] [00:35:30/00:18:15, 0.663s/it]: train_loss_raw=1.2536, running_loss=1.2447, LR=0.000100
[2025-08-26 07:29:06,834][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042176] [Batch 03224/04869] [00:35:36/00:18:10, 0.663s/it]: train_loss_raw=1.2640, running_loss=1.2421, LR=0.000100
[2025-08-26 07:29:11,958][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042184] [Batch 03232/04869] [00:35:41/00:18:04, 0.663s/it]: train_loss_raw=1.2860, running_loss=1.2450, LR=0.000100
[2025-08-26 07:29:17,102][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042192] [Batch 03240/04869] [00:35:46/00:17:59, 0.663s/it]: train_loss_raw=1.2284, running_loss=1.2467, LR=0.000100
[2025-08-26 07:29:22,442][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042200] [Batch 03248/04869] [00:35:51/00:17:53, 0.663s/it]: train_loss_raw=1.2292, running_loss=1.2483, LR=0.000100
[2025-08-26 07:29:27,564][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042208] [Batch 03256/04869] [00:35:57/00:17:48, 0.662s/it]: train_loss_raw=1.2849, running_loss=1.2480, LR=0.000100
[2025-08-26 07:29:33,325][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042216] [Batch 03264/04869] [00:36:02/00:17:43, 0.663s/it]: train_loss_raw=1.1324, running_loss=1.2461, LR=0.000100
[2025-08-26 07:29:38,452][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042224] [Batch 03272/04869] [00:36:07/00:17:38, 0.663s/it]: train_loss_raw=1.2004, running_loss=1.2451, LR=0.000100
[2025-08-26 07:29:43,569][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042232] [Batch 03280/04869] [00:36:13/00:17:32, 0.663s/it]: train_loss_raw=1.1637, running_loss=1.2417, LR=0.000100
[2025-08-26 07:29:48,904][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042240] [Batch 03288/04869] [00:36:18/00:17:27, 0.663s/it]: train_loss_raw=1.2623, running_loss=1.2384, LR=0.000100
[2025-08-26 07:29:54,413][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042248] [Batch 03296/04869] [00:36:23/00:17:22, 0.663s/it]: train_loss_raw=1.1644, running_loss=1.2385, LR=0.000100
[2025-08-26 07:29:59,713][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042256] [Batch 03304/04869] [00:36:29/00:17:16, 0.663s/it]: train_loss_raw=1.2434, running_loss=1.2394, LR=0.000100
[2025-08-26 07:30:04,894][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042264] [Batch 03312/04869] [00:36:34/00:17:11, 0.663s/it]: train_loss_raw=1.1656, running_loss=1.2395, LR=0.000100
[2025-08-26 07:30:10,034][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042272] [Batch 03320/04869] [00:36:39/00:17:06, 0.663s/it]: train_loss_raw=1.2044, running_loss=1.2403, LR=0.000100
[2025-08-26 07:30:15,170][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042280] [Batch 03328/04869] [00:36:44/00:17:00, 0.662s/it]: train_loss_raw=1.2026, running_loss=1.2385, LR=0.000100
[2025-08-26 07:30:20,396][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042288] [Batch 03336/04869] [00:36:49/00:16:55, 0.662s/it]: train_loss_raw=1.2778, running_loss=1.2403, LR=0.000100
[2025-08-26 07:30:26,089][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042296] [Batch 03344/04869] [00:36:55/00:16:50, 0.663s/it]: train_loss_raw=1.2676, running_loss=1.2417, LR=0.000100
[2025-08-26 07:30:31,761][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042304] [Batch 03352/04869] [00:37:01/00:16:45, 0.663s/it]: train_loss_raw=1.3215, running_loss=1.2428, LR=0.000100
[2025-08-26 07:30:36,902][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042312] [Batch 03360/04869] [00:37:06/00:16:39, 0.663s/it]: train_loss_raw=1.2174, running_loss=1.2439, LR=0.000100
[2025-08-26 07:30:42,026][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042320] [Batch 03368/04869] [00:37:11/00:16:34, 0.663s/it]: train_loss_raw=1.3274, running_loss=1.2441, LR=0.000100
[2025-08-26 07:30:47,185][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042328] [Batch 03376/04869] [00:37:16/00:16:29, 0.663s/it]: train_loss_raw=1.2354, running_loss=1.2420, LR=0.000100
[2025-08-26 07:30:52,371][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042336] [Batch 03384/04869] [00:37:21/00:16:23, 0.662s/it]: train_loss_raw=1.1299, running_loss=1.2401, LR=0.000100
[2025-08-26 07:30:57,499][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042344] [Batch 03392/04869] [00:37:26/00:16:18, 0.662s/it]: train_loss_raw=1.3140, running_loss=1.2399, LR=0.000100
[2025-08-26 07:31:02,629][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042352] [Batch 03400/04869] [00:37:32/00:16:13, 0.662s/it]: train_loss_raw=1.1591, running_loss=1.2394, LR=0.000100
[2025-08-26 07:31:07,927][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042360] [Batch 03408/04869] [00:37:37/00:16:07, 0.662s/it]: train_loss_raw=1.2181, running_loss=1.2400, LR=0.000100
[2025-08-26 07:31:13,058][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042368] [Batch 03416/04869] [00:37:42/00:16:02, 0.662s/it]: train_loss_raw=1.2479, running_loss=1.2398, LR=0.000100
[2025-08-26 07:31:18,527][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042376] [Batch 03424/04869] [00:37:48/00:15:57, 0.662s/it]: train_loss_raw=1.1960, running_loss=1.2395, LR=0.000100
[2025-08-26 07:31:24,155][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042384] [Batch 03432/04869] [00:37:53/00:15:51, 0.662s/it]: train_loss_raw=1.2278, running_loss=1.2384, LR=0.000100
[2025-08-26 07:31:29,450][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042392] [Batch 03440/04869] [00:37:58/00:15:46, 0.662s/it]: train_loss_raw=1.3188, running_loss=1.2412, LR=0.000100
[2025-08-26 07:31:34,596][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042400] [Batch 03448/04869] [00:38:04/00:15:41, 0.662s/it]: train_loss_raw=1.3126, running_loss=1.2442, LR=0.000100
[2025-08-26 07:31:39,842][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042408] [Batch 03456/04869] [00:38:09/00:15:36, 0.662s/it]: train_loss_raw=1.3095, running_loss=1.2433, LR=0.000100
[2025-08-26 07:31:45,224][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042416] [Batch 03464/04869] [00:38:14/00:15:30, 0.662s/it]: train_loss_raw=1.2992, running_loss=1.2433, LR=0.000100
[2025-08-26 07:31:50,371][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042424] [Batch 03472/04869] [00:38:19/00:15:25, 0.662s/it]: train_loss_raw=1.2720, running_loss=1.2403, LR=0.000100
[2025-08-26 07:31:55,510][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042432] [Batch 03480/04869] [00:38:25/00:15:20, 0.662s/it]: train_loss_raw=1.1972, running_loss=1.2413, LR=0.000100
[2025-08-26 07:32:00,703][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042440] [Batch 03488/04869] [00:38:30/00:15:14, 0.662s/it]: train_loss_raw=1.2614, running_loss=1.2410, LR=0.000100
[2025-08-26 07:32:06,459][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042448] [Batch 03496/04869] [00:38:35/00:15:09, 0.662s/it]: train_loss_raw=1.2811, running_loss=1.2415, LR=0.000100
[2025-08-26 07:32:11,698][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042456] [Batch 03504/04869] [00:38:41/00:15:04, 0.662s/it]: train_loss_raw=1.2463, running_loss=1.2414, LR=0.000100
[2025-08-26 07:32:16,931][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042464] [Batch 03512/04869] [00:38:46/00:14:58, 0.662s/it]: train_loss_raw=1.2940, running_loss=1.2417, LR=0.000100
[2025-08-26 07:32:22,516][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042472] [Batch 03520/04869] [00:38:52/00:14:53, 0.663s/it]: train_loss_raw=1.1876, running_loss=1.2404, LR=0.000100
[2025-08-26 07:32:27,928][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042480] [Batch 03528/04869] [00:38:57/00:14:48, 0.663s/it]: train_loss_raw=1.2580, running_loss=1.2397, LR=0.000100
[2025-08-26 07:32:33,087][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042488] [Batch 03536/04869] [00:39:02/00:14:43, 0.662s/it]: train_loss_raw=1.2530, running_loss=1.2418, LR=0.000100
[2025-08-26 07:32:38,403][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042496] [Batch 03544/04869] [00:39:07/00:14:37, 0.663s/it]: train_loss_raw=1.2512, running_loss=1.2424, LR=0.000100
[2025-08-26 07:32:43,555][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042504] [Batch 03552/04869] [00:39:13/00:14:32, 0.662s/it]: train_loss_raw=1.1475, running_loss=1.2405, LR=0.000100
[2025-08-26 07:32:48,734][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042512] [Batch 03560/04869] [00:39:18/00:14:27, 0.662s/it]: train_loss_raw=1.2200, running_loss=1.2378, LR=0.000100
[2025-08-26 07:32:53,924][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042520] [Batch 03568/04869] [00:39:23/00:14:21, 0.662s/it]: train_loss_raw=1.1727, running_loss=1.2403, LR=0.000100
[2025-08-26 07:32:59,536][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042528] [Batch 03576/04869] [00:39:29/00:14:16, 0.662s/it]: train_loss_raw=1.2306, running_loss=1.2396, LR=0.000100
[2025-08-26 07:33:04,675][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042536] [Batch 03584/04869] [00:39:34/00:14:11, 0.662s/it]: train_loss_raw=1.2629, running_loss=1.2397, LR=0.000100
[2025-08-26 07:33:10,054][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042544] [Batch 03592/04869] [00:39:39/00:14:05, 0.662s/it]: train_loss_raw=1.2342, running_loss=1.2404, LR=0.000100
[2025-08-26 07:33:15,189][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042552] [Batch 03600/04869] [00:39:44/00:14:00, 0.662s/it]: train_loss_raw=1.1710, running_loss=1.2408, LR=0.000100
[2025-08-26 07:33:20,520][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042560] [Batch 03608/04869] [00:39:50/00:13:55, 0.662s/it]: train_loss_raw=1.2024, running_loss=1.2380, LR=0.000100
[2025-08-26 07:33:25,658][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042568] [Batch 03616/04869] [00:39:55/00:13:49, 0.662s/it]: train_loss_raw=1.1124, running_loss=1.2385, LR=0.000100
[2025-08-26 07:33:30,791][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042576] [Batch 03624/04869] [00:40:00/00:13:44, 0.662s/it]: train_loss_raw=1.2705, running_loss=1.2364, LR=0.000100
[2025-08-26 07:33:36,137][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042584] [Batch 03632/04869] [00:40:05/00:13:39, 0.662s/it]: train_loss_raw=1.2743, running_loss=1.2372, LR=0.000100
[2025-08-26 07:33:41,609][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042592] [Batch 03640/04869] [00:40:11/00:13:34, 0.662s/it]: train_loss_raw=1.2549, running_loss=1.2368, LR=0.000100
[2025-08-26 07:33:46,942][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042600] [Batch 03648/04869] [00:40:16/00:13:28, 0.662s/it]: train_loss_raw=1.1469, running_loss=1.2355, LR=0.000100
[2025-08-26 07:33:52,625][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042608] [Batch 03656/04869] [00:40:22/00:13:23, 0.663s/it]: train_loss_raw=1.1725, running_loss=1.2317, LR=0.000100
[2025-08-26 07:33:57,756][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042616] [Batch 03664/04869] [00:40:27/00:13:18, 0.662s/it]: train_loss_raw=1.3123, running_loss=1.2369, LR=0.000100
[2025-08-26 07:34:02,890][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042624] [Batch 03672/04869] [00:40:32/00:13:12, 0.662s/it]: train_loss_raw=1.2235, running_loss=1.2361, LR=0.000100
[2025-08-26 07:34:08,009][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042632] [Batch 03680/04869] [00:40:37/00:13:07, 0.662s/it]: train_loss_raw=1.2729, running_loss=1.2334, LR=0.000100
[2025-08-26 07:34:13,483][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042640] [Batch 03688/04869] [00:40:42/00:13:02, 0.662s/it]: train_loss_raw=1.1095, running_loss=1.2346, LR=0.000100
[2025-08-26 07:34:18,637][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042648] [Batch 03696/04869] [00:40:48/00:12:56, 0.662s/it]: train_loss_raw=1.2041, running_loss=1.2365, LR=0.000100
[2025-08-26 07:34:24,118][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042656] [Batch 03704/04869] [00:40:53/00:12:51, 0.662s/it]: train_loss_raw=1.1995, running_loss=1.2374, LR=0.000100
[2025-08-26 07:34:29,247][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042664] [Batch 03712/04869] [00:40:58/00:12:46, 0.662s/it]: train_loss_raw=1.2143, running_loss=1.2334, LR=0.000100
[2025-08-26 07:34:34,388][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042672] [Batch 03720/04869] [00:41:03/00:12:41, 0.662s/it]: train_loss_raw=1.2101, running_loss=1.2312, LR=0.000100
[2025-08-26 07:34:39,667][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042680] [Batch 03728/04869] [00:41:09/00:12:35, 0.662s/it]: train_loss_raw=1.2191, running_loss=1.2341, LR=0.000100
[2025-08-26 07:34:44,955][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042688] [Batch 03736/04869] [00:41:14/00:12:30, 0.662s/it]: train_loss_raw=1.3309, running_loss=1.2355, LR=0.000100
[2025-08-26 07:34:50,085][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042696] [Batch 03744/04869] [00:41:19/00:12:25, 0.662s/it]: train_loss_raw=1.2930, running_loss=1.2364, LR=0.000100
[2025-08-26 07:34:55,223][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042704] [Batch 03752/04869] [00:41:24/00:12:19, 0.662s/it]: train_loss_raw=1.2761, running_loss=1.2393, LR=0.000100
[2025-08-26 07:35:00,355][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042712] [Batch 03760/04869] [00:41:29/00:12:14, 0.662s/it]: train_loss_raw=1.1741, running_loss=1.2374, LR=0.000100
[2025-08-26 07:35:05,497][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042720] [Batch 03768/04869] [00:41:34/00:12:09, 0.662s/it]: train_loss_raw=1.1920, running_loss=1.2403, LR=0.000100
[2025-08-26 07:35:10,632][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042728] [Batch 03776/04869] [00:41:40/00:12:03, 0.662s/it]: train_loss_raw=1.2292, running_loss=1.2389, LR=0.000100
[2025-08-26 07:35:16,063][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042736] [Batch 03784/04869] [00:41:45/00:11:58, 0.662s/it]: train_loss_raw=1.2797, running_loss=1.2387, LR=0.000100
[2025-08-26 07:35:21,303][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042744] [Batch 03792/04869] [00:41:50/00:11:53, 0.662s/it]: train_loss_raw=1.2746, running_loss=1.2425, LR=0.000100
[2025-08-26 07:35:26,448][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042752] [Batch 03800/04869] [00:41:55/00:11:47, 0.662s/it]: train_loss_raw=1.3052, running_loss=1.2442, LR=0.000100
[2025-08-26 07:35:31,904][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042760] [Batch 03808/04869] [00:42:01/00:11:42, 0.662s/it]: train_loss_raw=1.2577, running_loss=1.2433, LR=0.000100
[2025-08-26 07:35:37,039][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042768] [Batch 03816/04869] [00:42:06/00:11:37, 0.662s/it]: train_loss_raw=1.1567, running_loss=1.2421, LR=0.000100
[2025-08-26 07:35:42,174][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042776] [Batch 03824/04869] [00:42:11/00:11:31, 0.662s/it]: train_loss_raw=1.2111, running_loss=1.2420, LR=0.000100
[2025-08-26 07:35:47,428][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042784] [Batch 03832/04869] [00:42:16/00:11:26, 0.662s/it]: train_loss_raw=1.3259, running_loss=1.2394, LR=0.000100
[2025-08-26 07:35:52,561][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042792] [Batch 03840/04869] [00:42:22/00:11:21, 0.662s/it]: train_loss_raw=1.1801, running_loss=1.2400, LR=0.000100
[2025-08-26 07:35:57,691][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042800] [Batch 03848/04869] [00:42:27/00:11:15, 0.662s/it]: train_loss_raw=1.1591, running_loss=1.2375, LR=0.000100
[2025-08-26 07:36:02,824][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042808] [Batch 03856/04869] [00:42:32/00:11:10, 0.662s/it]: train_loss_raw=1.1805, running_loss=1.2371, LR=0.000100
[2025-08-26 07:36:16,479][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042816] [Batch 03864/04869] [00:42:45/00:11:07, 0.664s/it]: train_loss_raw=1.1742, running_loss=1.2357, LR=0.000100
[2025-08-26 07:36:21,628][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042824] [Batch 03872/04869] [00:42:51/00:11:02, 0.664s/it]: train_loss_raw=1.3085, running_loss=1.2346, LR=0.000100
[2025-08-26 07:36:26,768][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042832] [Batch 03880/04869] [00:42:56/00:10:56, 0.664s/it]: train_loss_raw=1.1959, running_loss=1.2345, LR=0.000100
[2025-08-26 07:36:31,903][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042840] [Batch 03888/04869] [00:43:01/00:10:51, 0.664s/it]: train_loss_raw=1.2350, running_loss=1.2332, LR=0.000100
[2025-08-26 07:36:37,067][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042848] [Batch 03896/04869] [00:43:06/00:10:45, 0.664s/it]: train_loss_raw=1.3134, running_loss=1.2330, LR=0.000100
[2025-08-26 07:36:42,194][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042856] [Batch 03904/04869] [00:43:11/00:10:40, 0.664s/it]: train_loss_raw=1.2749, running_loss=1.2308, LR=0.000100
[2025-08-26 07:36:47,365][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042864] [Batch 03912/04869] [00:43:16/00:10:35, 0.664s/it]: train_loss_raw=1.1727, running_loss=1.2322, LR=0.000100
[2025-08-26 07:36:52,499][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042872] [Batch 03920/04869] [00:43:21/00:10:29, 0.664s/it]: train_loss_raw=1.1731, running_loss=1.2314, LR=0.000100
[2025-08-26 07:36:57,713][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042880] [Batch 03928/04869] [00:43:27/00:10:24, 0.664s/it]: train_loss_raw=1.3456, running_loss=1.2337, LR=0.000100
[2025-08-26 07:37:02,914][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042888] [Batch 03936/04869] [00:43:32/00:10:19, 0.664s/it]: train_loss_raw=1.2114, running_loss=1.2319, LR=0.000100
[2025-08-26 07:37:08,072][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042896] [Batch 03944/04869] [00:43:37/00:10:13, 0.664s/it]: train_loss_raw=1.2301, running_loss=1.2320, LR=0.000100
[2025-08-26 07:37:13,619][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042904] [Batch 03952/04869] [00:43:43/00:10:08, 0.664s/it]: train_loss_raw=1.2715, running_loss=1.2376, LR=0.000100
[2025-08-26 07:37:19,385][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042912] [Batch 03960/04869] [00:43:48/00:10:03, 0.664s/it]: train_loss_raw=1.4350, running_loss=1.2430, LR=0.000100
[2025-08-26 07:37:24,544][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042920] [Batch 03968/04869] [00:43:54/00:09:58, 0.664s/it]: train_loss_raw=1.1747, running_loss=1.2382, LR=0.000100
[2025-08-26 07:37:30,244][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042928] [Batch 03976/04869] [00:43:59/00:09:52, 0.664s/it]: train_loss_raw=1.1862, running_loss=1.2382, LR=0.000100
[2025-08-26 07:37:35,386][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042936] [Batch 03984/04869] [00:44:04/00:09:47, 0.664s/it]: train_loss_raw=1.2193, running_loss=1.2350, LR=0.000100
[2025-08-26 07:37:40,682][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042944] [Batch 03992/04869] [00:44:10/00:09:42, 0.664s/it]: train_loss_raw=1.2127, running_loss=1.2344, LR=0.000100
[2025-08-26 07:37:46,380][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042952] [Batch 04000/04869] [00:44:15/00:09:36, 0.664s/it]: train_loss_raw=1.3360, running_loss=1.2382, LR=0.000100
[2025-08-26 07:37:51,527][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042960] [Batch 04008/04869] [00:44:21/00:09:31, 0.664s/it]: train_loss_raw=1.3035, running_loss=1.2400, LR=0.000100
[2025-08-26 07:37:56,667][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042968] [Batch 04016/04869] [00:44:26/00:09:26, 0.664s/it]: train_loss_raw=1.3585, running_loss=1.2409, LR=0.000100
[2025-08-26 07:38:01,855][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042976] [Batch 04024/04869] [00:44:31/00:09:20, 0.664s/it]: train_loss_raw=1.2038, running_loss=1.2411, LR=0.000100
[2025-08-26 07:38:07,259][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042984] [Batch 04032/04869] [00:44:36/00:09:15, 0.664s/it]: train_loss_raw=1.1956, running_loss=1.2400, LR=0.000100
[2025-08-26 07:38:12,784][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 042992] [Batch 04040/04869] [00:44:42/00:09:10, 0.664s/it]: train_loss_raw=1.2353, running_loss=1.2409, LR=0.000100
[2025-08-26 07:38:17,919][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043000] [Batch 04048/04869] [00:44:47/00:09:05, 0.664s/it]: train_loss_raw=1.2000, running_loss=1.2402, LR=0.000100
[2025-08-26 07:38:23,050][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043008] [Batch 04056/04869] [00:44:52/00:08:59, 0.664s/it]: train_loss_raw=1.2775, running_loss=1.2415, LR=0.000100
[2025-08-26 07:38:28,839][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043016] [Batch 04064/04869] [00:44:58/00:08:54, 0.664s/it]: train_loss_raw=1.2418, running_loss=1.2420, LR=0.000100
[2025-08-26 07:38:34,321][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043024] [Batch 04072/04869] [00:45:03/00:08:49, 0.664s/it]: train_loss_raw=1.2523, running_loss=1.2442, LR=0.000100
[2025-08-26 07:38:40,011][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043032] [Batch 04080/04869] [00:45:09/00:08:43, 0.664s/it]: train_loss_raw=1.1787, running_loss=1.2427, LR=0.000100
[2025-08-26 07:38:45,171][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043040] [Batch 04088/04869] [00:45:14/00:08:38, 0.664s/it]: train_loss_raw=1.1577, running_loss=1.2397, LR=0.000100
[2025-08-26 07:38:50,354][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043048] [Batch 04096/04869] [00:45:19/00:08:33, 0.664s/it]: train_loss_raw=1.2776, running_loss=1.2411, LR=0.000100
[2025-08-26 07:38:55,787][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043056] [Batch 04104/04869] [00:45:25/00:08:28, 0.664s/it]: train_loss_raw=1.2707, running_loss=1.2422, LR=0.000100
[2025-08-26 07:39:01,063][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043064] [Batch 04112/04869] [00:45:30/00:08:22, 0.664s/it]: train_loss_raw=1.2545, running_loss=1.2431, LR=0.000100
[2025-08-26 07:39:06,690][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043072] [Batch 04120/04869] [00:45:36/00:08:17, 0.664s/it]: train_loss_raw=1.3087, running_loss=1.2426, LR=0.000100
[2025-08-26 07:39:11,835][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043080] [Batch 04128/04869] [00:45:41/00:08:12, 0.664s/it]: train_loss_raw=1.1088, running_loss=1.2399, LR=0.000100
[2025-08-26 07:39:16,986][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043088] [Batch 04136/04869] [00:45:46/00:08:06, 0.664s/it]: train_loss_raw=1.2286, running_loss=1.2402, LR=0.000100
[2025-08-26 07:39:22,146][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043096] [Batch 04144/04869] [00:45:51/00:08:01, 0.664s/it]: train_loss_raw=1.2041, running_loss=1.2374, LR=0.000100
[2025-08-26 07:39:27,460][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043104] [Batch 04152/04869] [00:45:56/00:07:56, 0.664s/it]: train_loss_raw=1.2981, running_loss=1.2376, LR=0.000100
[2025-08-26 07:39:33,399][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043112] [Batch 04160/04869] [00:46:02/00:07:50, 0.664s/it]: train_loss_raw=1.1707, running_loss=1.2373, LR=0.000100
[2025-08-26 07:39:38,610][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043120] [Batch 04168/04869] [00:46:08/00:07:45, 0.664s/it]: train_loss_raw=1.2642, running_loss=1.2377, LR=0.000100
[2025-08-26 07:39:43,928][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043128] [Batch 04176/04869] [00:46:13/00:07:40, 0.664s/it]: train_loss_raw=1.1797, running_loss=1.2373, LR=0.000100
[2025-08-26 07:39:49,102][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043136] [Batch 04184/04869] [00:46:18/00:07:34, 0.664s/it]: train_loss_raw=1.4368, running_loss=1.2386, LR=0.000100
[2025-08-26 07:39:54,263][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043144] [Batch 04192/04869] [00:46:23/00:07:29, 0.664s/it]: train_loss_raw=1.1608, running_loss=1.2406, LR=0.000100
[2025-08-26 07:39:59,421][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043152] [Batch 04200/04869] [00:46:28/00:07:24, 0.664s/it]: train_loss_raw=1.1944, running_loss=1.2396, LR=0.000100
[2025-08-26 07:40:04,579][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043160] [Batch 04208/04869] [00:46:34/00:07:18, 0.664s/it]: train_loss_raw=1.2421, running_loss=1.2407, LR=0.000100
[2025-08-26 07:40:09,856][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043168] [Batch 04216/04869] [00:46:39/00:07:13, 0.664s/it]: train_loss_raw=1.2232, running_loss=1.2413, LR=0.000100
[2025-08-26 07:40:15,068][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043176] [Batch 04224/04869] [00:46:44/00:07:08, 0.664s/it]: train_loss_raw=1.2180, running_loss=1.2429, LR=0.000100
[2025-08-26 07:40:20,226][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043184] [Batch 04232/04869] [00:46:49/00:07:02, 0.664s/it]: train_loss_raw=1.2376, running_loss=1.2427, LR=0.000100
[2025-08-26 07:40:25,446][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043192] [Batch 04240/04869] [00:46:54/00:06:57, 0.664s/it]: train_loss_raw=1.3753, running_loss=1.2435, LR=0.000100
[2025-08-26 07:40:31,113][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043200] [Batch 04248/04869] [00:47:00/00:06:52, 0.664s/it]: train_loss_raw=1.2532, running_loss=1.2420, LR=0.000100
[2025-08-26 07:40:36,574][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043208] [Batch 04256/04869] [00:47:06/00:06:47, 0.664s/it]: train_loss_raw=1.3356, running_loss=1.2456, LR=0.000100
[2025-08-26 07:40:42,304][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043216] [Batch 04264/04869] [00:47:11/00:06:41, 0.664s/it]: train_loss_raw=1.2678, running_loss=1.2494, LR=0.000100
[2025-08-26 07:40:47,770][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043224] [Batch 04272/04869] [00:47:17/00:06:36, 0.664s/it]: train_loss_raw=1.1977, running_loss=1.2498, LR=0.000100
[2025-08-26 07:40:53,130][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043232] [Batch 04280/04869] [00:47:22/00:06:31, 0.664s/it]: train_loss_raw=1.1493, running_loss=1.2488, LR=0.000100
[2025-08-26 07:40:58,796][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043240] [Batch 04288/04869] [00:47:28/00:06:25, 0.664s/it]: train_loss_raw=1.2663, running_loss=1.2476, LR=0.000100
[2025-08-26 07:41:04,363][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043248] [Batch 04296/04869] [00:47:33/00:06:20, 0.664s/it]: train_loss_raw=1.3216, running_loss=1.2461, LR=0.000100
[2025-08-26 07:41:09,762][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043256] [Batch 04304/04869] [00:47:39/00:06:15, 0.664s/it]: train_loss_raw=1.1671, running_loss=1.2461, LR=0.000100
[2025-08-26 07:41:14,916][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043264] [Batch 04312/04869] [00:47:44/00:06:10, 0.664s/it]: train_loss_raw=1.2540, running_loss=1.2472, LR=0.000100
[2025-08-26 07:41:20,308][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043272] [Batch 04320/04869] [00:47:49/00:06:04, 0.664s/it]: train_loss_raw=1.2068, running_loss=1.2458, LR=0.000100
[2025-08-26 07:41:25,867][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043280] [Batch 04328/04869] [00:47:55/00:05:59, 0.664s/it]: train_loss_raw=1.3488, running_loss=1.2450, LR=0.000100
[2025-08-26 07:41:31,027][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043288] [Batch 04336/04869] [00:48:00/00:05:54, 0.664s/it]: train_loss_raw=1.1137, running_loss=1.2421, LR=0.000100
[2025-08-26 07:41:36,185][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043296] [Batch 04344/04869] [00:48:05/00:05:48, 0.664s/it]: train_loss_raw=1.1847, running_loss=1.2412, LR=0.000100
[2025-08-26 07:41:41,337][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043304] [Batch 04352/04869] [00:48:10/00:05:43, 0.664s/it]: train_loss_raw=1.2569, running_loss=1.2406, LR=0.000100
[2025-08-26 07:41:46,770][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043312] [Batch 04360/04869] [00:48:16/00:05:38, 0.664s/it]: train_loss_raw=1.2540, running_loss=1.2393, LR=0.000100
[2025-08-26 07:41:51,928][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043320] [Batch 04368/04869] [00:48:21/00:05:32, 0.664s/it]: train_loss_raw=1.3086, running_loss=1.2381, LR=0.000100
[2025-08-26 07:41:57,088][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043328] [Batch 04376/04869] [00:48:26/00:05:27, 0.664s/it]: train_loss_raw=1.2816, running_loss=1.2378, LR=0.000100
[2025-08-26 07:42:02,811][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043336] [Batch 04384/04869] [00:48:32/00:05:22, 0.664s/it]: train_loss_raw=1.1695, running_loss=1.2376, LR=0.000100
[2025-08-26 07:42:07,983][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043344] [Batch 04392/04869] [00:48:37/00:05:16, 0.664s/it]: train_loss_raw=1.1061, running_loss=1.2355, LR=0.000100
[2025-08-26 07:42:13,445][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043352] [Batch 04400/04869] [00:48:42/00:05:11, 0.664s/it]: train_loss_raw=1.2953, running_loss=1.2351, LR=0.000100
[2025-08-26 07:42:18,614][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043360] [Batch 04408/04869] [00:48:48/00:05:06, 0.664s/it]: train_loss_raw=1.2543, running_loss=1.2365, LR=0.000100
[2025-08-26 07:42:23,780][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043368] [Batch 04416/04869] [00:48:53/00:05:00, 0.664s/it]: train_loss_raw=1.2148, running_loss=1.2364, LR=0.000100
[2025-08-26 07:42:28,948][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043376] [Batch 04424/04869] [00:48:58/00:04:55, 0.664s/it]: train_loss_raw=1.2475, running_loss=1.2376, LR=0.000100
[2025-08-26 07:42:34,123][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043384] [Batch 04432/04869] [00:49:03/00:04:50, 0.664s/it]: train_loss_raw=1.1718, running_loss=1.2378, LR=0.000100
[2025-08-26 07:42:40,219][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043392] [Batch 04440/04869] [00:49:09/00:04:45, 0.664s/it]: train_loss_raw=1.2073, running_loss=1.2396, LR=0.000100
[2025-08-26 07:42:45,574][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043400] [Batch 04448/04869] [00:49:15/00:04:39, 0.664s/it]: train_loss_raw=1.2292, running_loss=1.2407, LR=0.000100
[2025-08-26 07:42:51,248][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043408] [Batch 04456/04869] [00:49:20/00:04:34, 0.664s/it]: train_loss_raw=1.1611, running_loss=1.2371, LR=0.000100
[2025-08-26 07:42:56,488][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043416] [Batch 04464/04869] [00:49:25/00:04:29, 0.664s/it]: train_loss_raw=1.2584, running_loss=1.2375, LR=0.000100
[2025-08-26 07:43:01,627][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043424] [Batch 04472/04869] [00:49:31/00:04:23, 0.664s/it]: train_loss_raw=1.2266, running_loss=1.2370, LR=0.000100
[2025-08-26 07:43:06,762][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043432] [Batch 04480/04869] [00:49:36/00:04:18, 0.664s/it]: train_loss_raw=1.2121, running_loss=1.2386, LR=0.000100
[2025-08-26 07:43:12,548][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043440] [Batch 04488/04869] [00:49:42/00:04:13, 0.664s/it]: train_loss_raw=1.1971, running_loss=1.2380, LR=0.000100
[2025-08-26 07:43:17,710][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043448] [Batch 04496/04869] [00:49:47/00:04:07, 0.664s/it]: train_loss_raw=1.1642, running_loss=1.2390, LR=0.000100
[2025-08-26 07:43:22,853][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043456] [Batch 04504/04869] [00:49:52/00:04:02, 0.664s/it]: train_loss_raw=1.2703, running_loss=1.2397, LR=0.000100
[2025-08-26 07:43:28,285][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043464] [Batch 04512/04869] [00:49:57/00:03:57, 0.664s/it]: train_loss_raw=1.2860, running_loss=1.2393, LR=0.000100
[2025-08-26 07:43:33,433][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043472] [Batch 04520/04869] [00:50:02/00:03:51, 0.664s/it]: train_loss_raw=1.2212, running_loss=1.2405, LR=0.000100
[2025-08-26 07:43:38,567][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043480] [Batch 04528/04869] [00:50:08/00:03:46, 0.664s/it]: train_loss_raw=1.2311, running_loss=1.2384, LR=0.000100
[2025-08-26 07:43:44,104][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043488] [Batch 04536/04869] [00:50:13/00:03:41, 0.664s/it]: train_loss_raw=1.2788, running_loss=1.2366, LR=0.000100
[2025-08-26 07:43:49,221][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043496] [Batch 04544/04869] [00:50:18/00:03:35, 0.664s/it]: train_loss_raw=1.2221, running_loss=1.2368, LR=0.000100
[2025-08-26 07:43:54,337][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043504] [Batch 04552/04869] [00:50:23/00:03:30, 0.664s/it]: train_loss_raw=1.3979, running_loss=1.2363, LR=0.000100
[2025-08-26 07:43:59,451][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043512] [Batch 04560/04869] [00:50:28/00:03:25, 0.664s/it]: train_loss_raw=1.1991, running_loss=1.2355, LR=0.000100
[2025-08-26 07:44:04,574][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043520] [Batch 04568/04869] [00:50:34/00:03:19, 0.664s/it]: train_loss_raw=1.2963, running_loss=1.2350, LR=0.000100
[2025-08-26 07:44:09,686][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043528] [Batch 04576/04869] [00:50:39/00:03:14, 0.664s/it]: train_loss_raw=1.2157, running_loss=1.2345, LR=0.000100
[2025-08-26 07:44:14,809][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043536] [Batch 04584/04869] [00:50:44/00:03:09, 0.664s/it]: train_loss_raw=1.3017, running_loss=1.2346, LR=0.000100
[2025-08-26 07:44:19,923][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043544] [Batch 04592/04869] [00:50:49/00:03:03, 0.664s/it]: train_loss_raw=1.3739, running_loss=1.2361, LR=0.000100
[2025-08-26 07:44:25,049][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043552] [Batch 04600/04869] [00:50:54/00:02:58, 0.664s/it]: train_loss_raw=1.1572, running_loss=1.2353, LR=0.000100
[2025-08-26 07:44:30,168][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043560] [Batch 04608/04869] [00:50:59/00:02:53, 0.664s/it]: train_loss_raw=1.1678, running_loss=1.2336, LR=0.000100
[2025-08-26 07:44:35,296][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043568] [Batch 04616/04869] [00:51:04/00:02:47, 0.664s/it]: train_loss_raw=1.2582, running_loss=1.2366, LR=0.000100
[2025-08-26 07:44:40,414][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043576] [Batch 04624/04869] [00:51:09/00:02:42, 0.664s/it]: train_loss_raw=1.3448, running_loss=1.2363, LR=0.000100
[2025-08-26 07:44:45,531][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043584] [Batch 04632/04869] [00:51:15/00:02:37, 0.664s/it]: train_loss_raw=1.1745, running_loss=1.2352, LR=0.000100
[2025-08-26 07:44:50,665][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043592] [Batch 04640/04869] [00:51:20/00:02:32, 0.664s/it]: train_loss_raw=1.2533, running_loss=1.2356, LR=0.000100
[2025-08-26 07:44:55,813][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043600] [Batch 04648/04869] [00:51:25/00:02:26, 0.664s/it]: train_loss_raw=1.2190, running_loss=1.2357, LR=0.000100
[2025-08-26 07:45:01,117][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043608] [Batch 04656/04869] [00:51:30/00:02:21, 0.664s/it]: train_loss_raw=1.1481, running_loss=1.2366, LR=0.000100
[2025-08-26 07:45:06,251][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043616] [Batch 04664/04869] [00:51:35/00:02:16, 0.664s/it]: train_loss_raw=1.2028, running_loss=1.2340, LR=0.000100
[2025-08-26 07:45:11,396][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043624] [Batch 04672/04869] [00:51:40/00:02:10, 0.664s/it]: train_loss_raw=1.3026, running_loss=1.2376, LR=0.000100
[2025-08-26 07:45:16,536][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043632] [Batch 04680/04869] [00:51:46/00:02:05, 0.664s/it]: train_loss_raw=1.2864, running_loss=1.2396, LR=0.000100
[2025-08-26 07:45:21,943][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043640] [Batch 04688/04869] [00:51:51/00:02:00, 0.664s/it]: train_loss_raw=1.1338, running_loss=1.2382, LR=0.000100
[2025-08-26 07:45:27,356][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043648] [Batch 04696/04869] [00:51:56/00:01:54, 0.664s/it]: train_loss_raw=1.3802, running_loss=1.2400, LR=0.000100
[2025-08-26 07:45:32,475][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043656] [Batch 04704/04869] [00:52:01/00:01:49, 0.664s/it]: train_loss_raw=1.2312, running_loss=1.2400, LR=0.000100
[2025-08-26 07:45:37,583][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043664] [Batch 04712/04869] [00:52:07/00:01:44, 0.664s/it]: train_loss_raw=1.1689, running_loss=1.2382, LR=0.000100
[2025-08-26 07:45:42,700][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043672] [Batch 04720/04869] [00:52:12/00:01:38, 0.664s/it]: train_loss_raw=1.2931, running_loss=1.2380, LR=0.000100
[2025-08-26 07:45:47,838][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043680] [Batch 04728/04869] [00:52:17/00:01:33, 0.664s/it]: train_loss_raw=1.1635, running_loss=1.2355, LR=0.000100
[2025-08-26 07:45:52,965][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043688] [Batch 04736/04869] [00:52:22/00:01:28, 0.664s/it]: train_loss_raw=1.3219, running_loss=1.2371, LR=0.000100
[2025-08-26 07:45:58,086][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043696] [Batch 04744/04869] [00:52:27/00:01:22, 0.663s/it]: train_loss_raw=1.1583, running_loss=1.2343, LR=0.000100
[2025-08-26 07:46:03,427][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043704] [Batch 04752/04869] [00:52:32/00:01:17, 0.663s/it]: train_loss_raw=1.3402, running_loss=1.2348, LR=0.000100
[2025-08-26 07:46:08,558][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043712] [Batch 04760/04869] [00:52:38/00:01:12, 0.663s/it]: train_loss_raw=1.1430, running_loss=1.2326, LR=0.000100
[2025-08-26 07:46:13,707][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043720] [Batch 04768/04869] [00:52:43/00:01:07, 0.663s/it]: train_loss_raw=1.2573, running_loss=1.2307, LR=0.000100
[2025-08-26 07:46:18,861][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043728] [Batch 04776/04869] [00:52:48/00:01:01, 0.663s/it]: train_loss_raw=1.1715, running_loss=1.2339, LR=0.000100
[2025-08-26 07:46:23,990][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043736] [Batch 04784/04869] [00:52:53/00:00:56, 0.663s/it]: train_loss_raw=1.3146, running_loss=1.2333, LR=0.000100
[2025-08-26 07:46:29,127][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043744] [Batch 04792/04869] [00:52:58/00:00:51, 0.663s/it]: train_loss_raw=1.2050, running_loss=1.2317, LR=0.000100
[2025-08-26 07:46:34,732][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043752] [Batch 04800/04869] [00:53:04/00:00:45, 0.663s/it]: train_loss_raw=1.1948, running_loss=1.2288, LR=0.000100
[2025-08-26 07:46:40,190][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043760] [Batch 04808/04869] [00:53:09/00:00:40, 0.663s/it]: train_loss_raw=1.1733, running_loss=1.2309, LR=0.000100
[2025-08-26 07:46:45,902][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043768] [Batch 04816/04869] [00:53:15/00:00:35, 0.663s/it]: train_loss_raw=1.2904, running_loss=1.2313, LR=0.000100
[2025-08-26 07:46:51,033][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043776] [Batch 04824/04869] [00:53:20/00:00:29, 0.663s/it]: train_loss_raw=1.2132, running_loss=1.2320, LR=0.000100
[2025-08-26 07:46:56,158][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043784] [Batch 04832/04869] [00:53:25/00:00:24, 0.663s/it]: train_loss_raw=1.1963, running_loss=1.2304, LR=0.000100
[2025-08-26 07:47:01,275][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043792] [Batch 04840/04869] [00:53:30/00:00:19, 0.663s/it]: train_loss_raw=1.3000, running_loss=1.2314, LR=0.000100
[2025-08-26 07:47:06,396][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043800] [Batch 04848/04869] [00:53:35/00:00:13, 0.663s/it]: train_loss_raw=1.1544, running_loss=1.2308, LR=0.000100
[2025-08-26 07:47:11,540][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043808] [Batch 04856/04869] [00:53:41/00:00:08, 0.663s/it]: train_loss_raw=1.2185, running_loss=1.2320, LR=0.000100
[2025-08-26 07:47:16,672][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 043816] [Batch 04864/04869] [00:53:46/00:00:03, 0.663s/it]: train_loss_raw=1.1956, running_loss=1.2337, LR=0.000100
[2025-08-26 07:47:31,660][__main__][INFO] - [VALIDATION] [Epoch 08/29] Starting validation.
[2025-08-26 07:47:41,272][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00007/00124] [00:00:09/00:02:19, 1.201s/it]
[2025-08-26 07:47:51,002][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00015/00124] [00:00:19/00:02:10, 1.209s/it]
[2025-08-26 07:48:00,993][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00023/00124] [00:00:29/00:02:02, 1.222s/it]
[2025-08-26 07:48:20,597][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00031/00124] [00:00:48/00:02:20, 1.529s/it]
[2025-08-26 07:48:30,496][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00039/00124] [00:00:58/00:02:03, 1.471s/it]
[2025-08-26 07:48:40,720][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00047/00124] [00:01:09/00:01:49, 1.439s/it]
[2025-08-26 07:48:50,976][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00055/00124] [00:01:19/00:01:36, 1.416s/it]
[2025-08-26 07:49:01,512][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00063/00124] [00:01:29/00:01:24, 1.404s/it]
[2025-08-26 07:49:11,457][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00071/00124] [00:01:39/00:01:12, 1.386s/it]
[2025-08-26 07:49:20,766][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00079/00124] [00:01:49/00:01:00, 1.364s/it]
[2025-08-26 07:49:30,484][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00087/00124] [00:01:58/00:00:48, 1.350s/it]
[2025-08-26 07:49:40,458][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00095/00124] [00:02:08/00:00:37, 1.342s/it]
[2025-08-26 07:49:49,767][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00103/00124] [00:02:18/00:00:26, 1.328s/it]
[2025-08-26 07:49:59,719][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00111/00124] [00:02:28/00:00:15, 1.322s/it]
[2025-08-26 07:50:09,690][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 043822] [Batch 00119/00124] [00:02:38/00:00:05, 1.317s/it]
[2025-08-26 07:50:14,084][__main__][INFO] - [VALIDATION] [Epoch 08/29] train_loss=1.23443, valid_loss=1.12400
[2025-08-26 07:50:14,085][__main__][INFO] - [VALIDATION] [Epoch 08/29] Metrics:
[2025-08-26 07:50:14,085][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_er      0.508
[2025-08-26 07:50:14,085][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_prec    0.209
[2025-08-26 07:50:14,085][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_recall  0.212
[2025-08-26 07:50:14,085][__main__][INFO] - [VALIDATION] [Epoch 08/29] - pep_recall 0.155
[2025-08-26 07:50:14,089][__main__][INFO] - [TRAIN] [Epoch 08/29] Epoch complete, total time 08:45:54, remaining time 20:27:06, 00:58:26 per epoch
[2025-08-26 07:50:15,673][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043824] [Batch 00003/04869] [00:00:01/00:39:06, 0.482s/it]: train_loss_raw=1.1768, running_loss=1.2426, LR=0.000100
[2025-08-26 07:50:21,263][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043832] [Batch 00011/04869] [00:00:07/00:51:47, 0.640s/it]: train_loss_raw=1.2632, running_loss=1.2379, LR=0.000100
[2025-08-26 07:50:27,351][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043840] [Batch 00019/04869] [00:00:13/00:55:50, 0.691s/it]: train_loss_raw=1.0955, running_loss=1.2309, LR=0.000100
[2025-08-26 07:50:33,224][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043848] [Batch 00027/04869] [00:00:18/00:56:46, 0.704s/it]: train_loss_raw=1.1112, running_loss=1.2260, LR=0.000100
[2025-08-26 07:50:38,533][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043856] [Batch 00035/04869] [00:00:24/00:55:57, 0.694s/it]: train_loss_raw=1.2983, running_loss=1.2234, LR=0.000100
[2025-08-26 07:50:43,839][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043864] [Batch 00043/04869] [00:00:29/00:55:23, 0.689s/it]: train_loss_raw=1.0814, running_loss=1.2147, LR=0.000100
[2025-08-26 07:50:49,339][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043872] [Batch 00051/04869] [00:00:35/00:55:17, 0.688s/it]: train_loss_raw=1.2226, running_loss=1.2113, LR=0.000100
[2025-08-26 07:50:54,732][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043880] [Batch 00059/04869] [00:00:40/00:55:02, 0.687s/it]: train_loss_raw=1.1231, running_loss=1.2067, LR=0.000100
[2025-08-26 07:50:59,865][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043888] [Batch 00067/04869] [00:00:45/00:54:30, 0.681s/it]: train_loss_raw=1.3002, running_loss=1.2067, LR=0.000100
[2025-08-26 07:51:05,010][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043896] [Batch 00075/04869] [00:00:50/00:54:06, 0.677s/it]: train_loss_raw=1.1276, running_loss=1.2048, LR=0.000100
[2025-08-26 07:51:10,350][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043904] [Batch 00083/04869] [00:00:56/00:53:56, 0.676s/it]: train_loss_raw=1.0513, running_loss=1.2007, LR=0.000100
[2025-08-26 07:51:15,494][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043912] [Batch 00091/04869] [00:01:01/00:53:36, 0.673s/it]: train_loss_raw=1.1517, running_loss=1.1977, LR=0.000100
[2025-08-26 07:51:20,636][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043920] [Batch 00099/04869] [00:01:06/00:53:19, 0.671s/it]: train_loss_raw=1.2331, running_loss=1.1974, LR=0.000100
[2025-08-26 07:51:25,930][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043928] [Batch 00107/04869] [00:01:11/00:53:11, 0.670s/it]: train_loss_raw=1.1801, running_loss=1.1950, LR=0.000100
[2025-08-26 07:51:31,924][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043936] [Batch 00115/04869] [00:01:17/00:53:31, 0.676s/it]: train_loss_raw=1.1640, running_loss=1.1936, LR=0.000100
[2025-08-26 07:51:38,084][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043944] [Batch 00123/04869] [00:01:23/00:53:55, 0.682s/it]: train_loss_raw=1.2985, running_loss=1.1941, LR=0.000100
[2025-08-26 07:51:43,957][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043952] [Batch 00131/04869] [00:01:29/00:54:05, 0.685s/it]: train_loss_raw=1.1816, running_loss=1.1921, LR=0.000100
[2025-08-26 07:51:49,077][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043960] [Batch 00139/04869] [00:01:34/00:53:47, 0.682s/it]: train_loss_raw=1.2549, running_loss=1.1920, LR=0.000100
[2025-08-26 07:51:54,553][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043968] [Batch 00147/04869] [00:01:40/00:53:42, 0.682s/it]: train_loss_raw=1.1810, running_loss=1.1937, LR=0.000100
[2025-08-26 07:51:59,894][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043976] [Batch 00155/04869] [00:01:45/00:53:33, 0.682s/it]: train_loss_raw=1.2130, running_loss=1.1899, LR=0.000100
[2025-08-26 07:52:05,354][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043984] [Batch 00163/04869] [00:01:51/00:53:28, 0.682s/it]: train_loss_raw=1.1274, running_loss=1.1874, LR=0.000100
[2025-08-26 07:52:10,501][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 043992] [Batch 00171/04869] [00:01:56/00:53:14, 0.680s/it]: train_loss_raw=1.2385, running_loss=1.1886, LR=0.000100
[2025-08-26 07:52:15,918][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044000] [Batch 00179/04869] [00:02:01/00:53:08, 0.680s/it]: train_loss_raw=1.1248, running_loss=1.1861, LR=0.000100
[2025-08-26 07:52:25,373][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044008] [Batch 00187/04869] [00:02:11/00:54:43, 0.701s/it]: train_loss_raw=1.1836, running_loss=1.1826, LR=0.000100
[2025-08-26 07:52:30,949][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044016] [Batch 00195/04869] [00:02:16/00:54:37, 0.701s/it]: train_loss_raw=1.1158, running_loss=1.1779, LR=0.000100
[2025-08-26 07:52:36,091][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044024] [Batch 00203/04869] [00:02:21/00:54:20, 0.699s/it]: train_loss_raw=1.1741, running_loss=1.1768, LR=0.000100
[2025-08-26 07:52:41,851][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044032] [Batch 00211/04869] [00:02:27/00:54:18, 0.700s/it]: train_loss_raw=1.1768, running_loss=1.1778, LR=0.000100
[2025-08-26 07:52:47,966][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044040] [Batch 00219/04869] [00:02:33/00:54:24, 0.702s/it]: train_loss_raw=1.1063, running_loss=1.1793, LR=0.000100
[2025-08-26 07:52:53,401][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044048] [Batch 00227/04869] [00:02:39/00:54:15, 0.701s/it]: train_loss_raw=1.1576, running_loss=1.1767, LR=0.000100
[2025-08-26 07:52:58,575][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044056] [Batch 00235/04869] [00:02:44/00:54:00, 0.699s/it]: train_loss_raw=1.1513, running_loss=1.1795, LR=0.000100
[2025-08-26 07:53:03,744][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044064] [Batch 00243/04869] [00:02:49/00:53:47, 0.698s/it]: train_loss_raw=1.1325, running_loss=1.1825, LR=0.000100
[2025-08-26 07:53:08,902][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044072] [Batch 00251/04869] [00:02:54/00:53:33, 0.696s/it]: train_loss_raw=1.2001, running_loss=1.1828, LR=0.000100
[2025-08-26 07:53:14,394][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044080] [Batch 00259/04869] [00:03:00/00:53:26, 0.696s/it]: train_loss_raw=1.1109, running_loss=1.1848, LR=0.000100
[2025-08-26 07:53:19,547][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044088] [Batch 00267/04869] [00:03:05/00:53:14, 0.694s/it]: train_loss_raw=1.2317, running_loss=1.1865, LR=0.000100
[2025-08-26 07:53:24,699][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044096] [Batch 00275/04869] [00:03:10/00:53:01, 0.693s/it]: train_loss_raw=1.2465, running_loss=1.1828, LR=0.000100
[2025-08-26 07:53:30,628][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044104] [Batch 00283/04869] [00:03:16/00:53:02, 0.694s/it]: train_loss_raw=1.1724, running_loss=1.1826, LR=0.000100
[2025-08-26 07:53:35,803][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044112] [Batch 00291/04869] [00:03:21/00:52:51, 0.693s/it]: train_loss_raw=1.1449, running_loss=1.1838, LR=0.000100
[2025-08-26 07:53:40,959][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044120] [Batch 00299/04869] [00:03:26/00:52:39, 0.691s/it]: train_loss_raw=1.3437, running_loss=1.1838, LR=0.000100
[2025-08-26 07:53:46,115][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044128] [Batch 00307/04869] [00:03:31/00:52:28, 0.690s/it]: train_loss_raw=1.3424, running_loss=1.1825, LR=0.000100
[2025-08-26 07:53:51,807][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044136] [Batch 00315/04869] [00:03:37/00:52:25, 0.691s/it]: train_loss_raw=1.1528, running_loss=1.1820, LR=0.000100
[2025-08-26 07:53:56,965][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044144] [Batch 00323/04869] [00:03:42/00:52:14, 0.690s/it]: train_loss_raw=1.1932, running_loss=1.1834, LR=0.000100
[2025-08-26 07:54:02,471][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044152] [Batch 00331/04869] [00:03:48/00:52:09, 0.690s/it]: train_loss_raw=1.1919, running_loss=1.1840, LR=0.000100
[2025-08-26 07:54:07,761][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044160] [Batch 00339/04869] [00:03:53/00:52:00, 0.689s/it]: train_loss_raw=1.1287, running_loss=1.1830, LR=0.000100
[2025-08-26 07:54:12,911][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044168] [Batch 00347/04869] [00:03:58/00:51:50, 0.688s/it]: train_loss_raw=1.1518, running_loss=1.1830, LR=0.000100
[2025-08-26 07:54:18,052][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044176] [Batch 00355/04869] [00:04:03/00:51:40, 0.687s/it]: train_loss_raw=1.1834, running_loss=1.1836, LR=0.000100
[2025-08-26 07:54:23,579][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044184] [Batch 00363/04869] [00:04:09/00:51:35, 0.687s/it]: train_loss_raw=1.2419, running_loss=1.1819, LR=0.000100
[2025-08-26 07:54:29,007][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044192] [Batch 00371/04869] [00:04:14/00:51:28, 0.687s/it]: train_loss_raw=1.1398, running_loss=1.1820, LR=0.000100
[2025-08-26 07:54:34,296][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044200] [Batch 00379/04869] [00:04:20/00:51:21, 0.686s/it]: train_loss_raw=1.2060, running_loss=1.1835, LR=0.000100
[2025-08-26 07:54:39,583][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044208] [Batch 00387/04869] [00:04:25/00:51:13, 0.686s/it]: train_loss_raw=1.1850, running_loss=1.1863, LR=0.000100
[2025-08-26 07:54:44,731][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044216] [Batch 00395/04869] [00:04:30/00:51:03, 0.685s/it]: train_loss_raw=1.2571, running_loss=1.1875, LR=0.000100
[2025-08-26 07:54:49,878][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044224] [Batch 00403/04869] [00:04:35/00:50:54, 0.684s/it]: train_loss_raw=1.3044, running_loss=1.1891, LR=0.000100
[2025-08-26 07:54:55,026][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044232] [Batch 00411/04869] [00:04:40/00:50:45, 0.683s/it]: train_loss_raw=1.2133, running_loss=1.1921, LR=0.000100
[2025-08-26 07:55:00,172][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044240] [Batch 00419/04869] [00:04:45/00:50:36, 0.682s/it]: train_loss_raw=1.2327, running_loss=1.1899, LR=0.000100
[2025-08-26 07:55:05,357][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044248] [Batch 00427/04869] [00:04:51/00:50:28, 0.682s/it]: train_loss_raw=1.2441, running_loss=1.1910, LR=0.000100
[2025-08-26 07:55:10,592][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044256] [Batch 00435/04869] [00:04:56/00:50:20, 0.681s/it]: train_loss_raw=1.1806, running_loss=1.1908, LR=0.000100
[2025-08-26 07:55:16,334][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044264] [Batch 00443/04869] [00:05:02/00:50:18, 0.682s/it]: train_loss_raw=1.1768, running_loss=1.1878, LR=0.000100
[2025-08-26 07:55:21,807][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044272] [Batch 00451/04869] [00:05:07/00:50:13, 0.682s/it]: train_loss_raw=1.1626, running_loss=1.1844, LR=0.000100
[2025-08-26 07:55:26,972][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044280] [Batch 00459/04869] [00:05:12/00:50:04, 0.681s/it]: train_loss_raw=1.1804, running_loss=1.1856, LR=0.000100
[2025-08-26 07:55:32,159][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044288] [Batch 00467/04869] [00:05:17/00:49:56, 0.681s/it]: train_loss_raw=1.2509, running_loss=1.1891, LR=0.000100
[2025-08-26 07:55:37,651][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044296] [Batch 00475/04869] [00:05:23/00:49:51, 0.681s/it]: train_loss_raw=1.1046, running_loss=1.1880, LR=0.000100
[2025-08-26 07:55:42,798][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044304] [Batch 00483/04869] [00:05:28/00:49:43, 0.680s/it]: train_loss_raw=1.1686, running_loss=1.1864, LR=0.000100
[2025-08-26 07:55:48,530][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044312] [Batch 00491/04869] [00:05:34/00:49:40, 0.681s/it]: train_loss_raw=1.2098, running_loss=1.1853, LR=0.000100
[2025-08-26 07:55:53,678][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044320] [Batch 00499/04869] [00:05:39/00:49:32, 0.680s/it]: train_loss_raw=1.1479, running_loss=1.1852, LR=0.000100
[2025-08-26 07:55:58,826][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044328] [Batch 00507/04869] [00:05:44/00:49:24, 0.680s/it]: train_loss_raw=1.1265, running_loss=1.1838, LR=0.000100
[2025-08-26 07:56:03,973][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044336] [Batch 00515/04869] [00:05:49/00:49:16, 0.679s/it]: train_loss_raw=1.2060, running_loss=1.1827, LR=0.000100
[2025-08-26 07:56:09,489][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044344] [Batch 00523/04869] [00:05:55/00:49:12, 0.679s/it]: train_loss_raw=1.1550, running_loss=1.1834, LR=0.000100
[2025-08-26 07:56:14,649][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044352] [Batch 00531/04869] [00:06:00/00:49:04, 0.679s/it]: train_loss_raw=1.1180, running_loss=1.1808, LR=0.000100
[2025-08-26 07:56:19,797][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044360] [Batch 00539/04869] [00:06:05/00:48:56, 0.678s/it]: train_loss_raw=1.1205, running_loss=1.1830, LR=0.000100
[2025-08-26 07:56:25,054][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044368] [Batch 00547/04869] [00:06:10/00:48:50, 0.678s/it]: train_loss_raw=1.2020, running_loss=1.1811, LR=0.000100
[2025-08-26 07:56:30,427][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044376] [Batch 00555/04869] [00:06:16/00:48:44, 0.678s/it]: train_loss_raw=1.1794, running_loss=1.1798, LR=0.000100
[2025-08-26 07:56:35,900][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044384] [Batch 00563/04869] [00:06:21/00:48:39, 0.678s/it]: train_loss_raw=1.2319, running_loss=1.1832, LR=0.000100
[2025-08-26 07:56:41,035][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044392] [Batch 00571/04869] [00:06:26/00:48:31, 0.677s/it]: train_loss_raw=1.1749, running_loss=1.1822, LR=0.000100
[2025-08-26 07:56:46,168][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044400] [Batch 00579/04869] [00:06:31/00:48:24, 0.677s/it]: train_loss_raw=1.1519, running_loss=1.1804, LR=0.000100
[2025-08-26 07:56:51,784][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044408] [Batch 00587/04869] [00:06:37/00:48:20, 0.677s/it]: train_loss_raw=1.2074, running_loss=1.1838, LR=0.000100
[2025-08-26 07:56:56,919][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044416] [Batch 00595/04869] [00:06:42/00:48:12, 0.677s/it]: train_loss_raw=1.1488, running_loss=1.1829, LR=0.000100
[2025-08-26 07:57:02,080][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044424] [Batch 00603/04869] [00:06:47/00:48:05, 0.676s/it]: train_loss_raw=1.1755, running_loss=1.1852, LR=0.000100
[2025-08-26 07:57:07,255][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044432] [Batch 00611/04869] [00:06:53/00:47:58, 0.676s/it]: train_loss_raw=1.2941, running_loss=1.1849, LR=0.000100
[2025-08-26 07:57:12,407][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044440] [Batch 00619/04869] [00:06:58/00:47:51, 0.676s/it]: train_loss_raw=1.1490, running_loss=1.1860, LR=0.000100
[2025-08-26 07:57:17,554][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044448] [Batch 00627/04869] [00:07:03/00:47:44, 0.675s/it]: train_loss_raw=1.1969, running_loss=1.1879, LR=0.000100
[2025-08-26 07:57:22,679][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044456] [Batch 00635/04869] [00:07:08/00:47:36, 0.675s/it]: train_loss_raw=1.2795, running_loss=1.1883, LR=0.000100
[2025-08-26 07:57:27,812][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044464] [Batch 00643/04869] [00:07:13/00:47:29, 0.674s/it]: train_loss_raw=1.1739, running_loss=1.1875, LR=0.000100
[2025-08-26 07:57:32,947][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044472] [Batch 00651/04869] [00:07:18/00:47:22, 0.674s/it]: train_loss_raw=1.1914, running_loss=1.1900, LR=0.000100
[2025-08-26 07:57:38,200][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044480] [Batch 00659/04869] [00:07:23/00:47:16, 0.674s/it]: train_loss_raw=1.1511, running_loss=1.1909, LR=0.000100
[2025-08-26 07:57:43,431][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044488] [Batch 00667/04869] [00:07:29/00:47:09, 0.673s/it]: train_loss_raw=1.0924, running_loss=1.1903, LR=0.000100
[2025-08-26 07:57:48,884][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044496] [Batch 00675/04869] [00:07:34/00:47:04, 0.674s/it]: train_loss_raw=1.2364, running_loss=1.1907, LR=0.000100
[2025-08-26 07:57:54,063][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044504] [Batch 00683/04869] [00:07:39/00:46:58, 0.673s/it]: train_loss_raw=1.2470, running_loss=1.1945, LR=0.000100
[2025-08-26 07:57:59,942][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044512] [Batch 00691/04869] [00:07:45/00:46:55, 0.674s/it]: train_loss_raw=1.2789, running_loss=1.1948, LR=0.000100
[2025-08-26 07:58:05,524][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044520] [Batch 00699/04869] [00:07:51/00:46:51, 0.674s/it]: train_loss_raw=1.2163, running_loss=1.1949, LR=0.000100
[2025-08-26 07:58:10,683][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044528] [Batch 00707/04869] [00:07:56/00:46:44, 0.674s/it]: train_loss_raw=1.1140, running_loss=1.1963, LR=0.000100
[2025-08-26 07:58:15,957][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044536] [Batch 00715/04869] [00:08:01/00:46:38, 0.674s/it]: train_loss_raw=1.1882, running_loss=1.1975, LR=0.000100
[2025-08-26 07:58:21,117][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044544] [Batch 00723/04869] [00:08:06/00:46:32, 0.673s/it]: train_loss_raw=1.2113, running_loss=1.1987, LR=0.000100
[2025-08-26 07:58:26,257][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044552] [Batch 00731/04869] [00:08:12/00:46:25, 0.673s/it]: train_loss_raw=1.2259, running_loss=1.1985, LR=0.000100
[2025-08-26 07:58:31,387][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044560] [Batch 00739/04869] [00:08:17/00:46:18, 0.673s/it]: train_loss_raw=1.1637, running_loss=1.1983, LR=0.000100
[2025-08-26 07:58:36,519][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044568] [Batch 00747/04869] [00:08:22/00:46:11, 0.672s/it]: train_loss_raw=1.2359, running_loss=1.1991, LR=0.000100
[2025-08-26 07:58:41,662][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044576] [Batch 00755/04869] [00:08:27/00:46:05, 0.672s/it]: train_loss_raw=1.2551, running_loss=1.2005, LR=0.000100
[2025-08-26 07:58:46,975][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044584] [Batch 00763/04869] [00:08:32/00:45:59, 0.672s/it]: train_loss_raw=1.2193, running_loss=1.2016, LR=0.000100
[2025-08-26 07:58:52,099][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044592] [Batch 00771/04869] [00:08:37/00:45:52, 0.672s/it]: train_loss_raw=1.1443, running_loss=1.2016, LR=0.000100
[2025-08-26 07:58:57,219][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044600] [Batch 00779/04869] [00:08:42/00:45:45, 0.671s/it]: train_loss_raw=1.1546, running_loss=1.2024, LR=0.000100
[2025-08-26 07:59:02,412][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044608] [Batch 00787/04869] [00:08:48/00:45:39, 0.671s/it]: train_loss_raw=1.1437, running_loss=1.2007, LR=0.000100
[2025-08-26 07:59:07,541][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044616] [Batch 00795/04869] [00:08:53/00:45:32, 0.671s/it]: train_loss_raw=1.2227, running_loss=1.1993, LR=0.000100
[2025-08-26 07:59:12,695][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044624] [Batch 00803/04869] [00:08:58/00:45:26, 0.671s/it]: train_loss_raw=1.2248, running_loss=1.1994, LR=0.000100
[2025-08-26 07:59:17,828][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044632] [Batch 00811/04869] [00:09:03/00:45:20, 0.670s/it]: train_loss_raw=1.0315, running_loss=1.1992, LR=0.000100
[2025-08-26 07:59:22,965][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044640] [Batch 00819/04869] [00:09:08/00:45:13, 0.670s/it]: train_loss_raw=1.1676, running_loss=1.1983, LR=0.000100
[2025-08-26 07:59:28,093][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044648] [Batch 00827/04869] [00:09:13/00:45:07, 0.670s/it]: train_loss_raw=1.2465, running_loss=1.1997, LR=0.000100
[2025-08-26 07:59:33,252][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044656] [Batch 00835/04869] [00:09:19/00:45:00, 0.669s/it]: train_loss_raw=1.2026, running_loss=1.1987, LR=0.000100
[2025-08-26 07:59:38,392][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044664] [Batch 00843/04869] [00:09:24/00:44:54, 0.669s/it]: train_loss_raw=1.1889, running_loss=1.1976, LR=0.000100
[2025-08-26 07:59:43,535][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044672] [Batch 00851/04869] [00:09:29/00:44:47, 0.669s/it]: train_loss_raw=1.0761, running_loss=1.1951, LR=0.000100
[2025-08-26 07:59:48,713][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044680] [Batch 00859/04869] [00:09:34/00:44:41, 0.669s/it]: train_loss_raw=1.1287, running_loss=1.1943, LR=0.000100
[2025-08-26 07:59:54,017][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044688] [Batch 00867/04869] [00:09:39/00:44:36, 0.669s/it]: train_loss_raw=1.2094, running_loss=1.1930, LR=0.000100
[2025-08-26 07:59:59,165][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044696] [Batch 00875/04869] [00:09:44/00:44:29, 0.669s/it]: train_loss_raw=1.2260, running_loss=1.1883, LR=0.000100
[2025-08-26 08:00:04,486][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044704] [Batch 00883/04869] [00:09:50/00:44:24, 0.668s/it]: train_loss_raw=1.2175, running_loss=1.1884, LR=0.000100
[2025-08-26 08:00:10,442][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044712] [Batch 00891/04869] [00:09:56/00:44:21, 0.669s/it]: train_loss_raw=1.1676, running_loss=1.1907, LR=0.000100
[2025-08-26 08:00:15,580][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044720] [Batch 00899/04869] [00:10:01/00:44:15, 0.669s/it]: train_loss_raw=1.2359, running_loss=1.1922, LR=0.000100
[2025-08-26 08:00:21,233][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044728] [Batch 00907/04869] [00:10:07/00:44:11, 0.669s/it]: train_loss_raw=1.2489, running_loss=1.1946, LR=0.000100
[2025-08-26 08:00:26,562][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044736] [Batch 00915/04869] [00:10:12/00:44:06, 0.669s/it]: train_loss_raw=1.1854, running_loss=1.1959, LR=0.000100
[2025-08-26 08:00:32,092][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044744] [Batch 00923/04869] [00:10:17/00:44:01, 0.669s/it]: train_loss_raw=1.1860, running_loss=1.1974, LR=0.000100
[2025-08-26 08:00:37,230][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044752] [Batch 00931/04869] [00:10:23/00:43:55, 0.669s/it]: train_loss_raw=1.2932, running_loss=1.1979, LR=0.000100
[2025-08-26 08:00:42,374][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044760] [Batch 00939/04869] [00:10:28/00:43:48, 0.669s/it]: train_loss_raw=1.1307, running_loss=1.1987, LR=0.000100
[2025-08-26 08:00:47,521][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044768] [Batch 00947/04869] [00:10:33/00:43:42, 0.669s/it]: train_loss_raw=1.1793, running_loss=1.1967, LR=0.000100
[2025-08-26 08:00:52,670][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044776] [Batch 00955/04869] [00:10:38/00:43:36, 0.669s/it]: train_loss_raw=1.1173, running_loss=1.1954, LR=0.000100
[2025-08-26 08:00:57,810][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044784] [Batch 00963/04869] [00:10:43/00:43:30, 0.668s/it]: train_loss_raw=1.1455, running_loss=1.1946, LR=0.000100
[2025-08-26 08:01:02,957][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044792] [Batch 00971/04869] [00:10:48/00:43:24, 0.668s/it]: train_loss_raw=1.2158, running_loss=1.1966, LR=0.000100
[2025-08-26 08:01:08,365][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044800] [Batch 00979/04869] [00:10:54/00:43:19, 0.668s/it]: train_loss_raw=1.1485, running_loss=1.1937, LR=0.000100
[2025-08-26 08:01:13,875][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044808] [Batch 00987/04869] [00:10:59/00:43:14, 0.668s/it]: train_loss_raw=1.2763, running_loss=1.1964, LR=0.000100
[2025-08-26 08:01:19,019][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044816] [Batch 00995/04869] [00:11:04/00:43:08, 0.668s/it]: train_loss_raw=1.2506, running_loss=1.1980, LR=0.000100
[2025-08-26 08:01:24,313][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044824] [Batch 01003/04869] [00:11:10/00:43:02, 0.668s/it]: train_loss_raw=1.2220, running_loss=1.1974, LR=0.000100
[2025-08-26 08:01:45,297][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044832] [Batch 01011/04869] [00:11:31/00:43:57, 0.684s/it]: train_loss_raw=1.2205, running_loss=1.1965, LR=0.000100
[2025-08-26 08:01:50,476][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044840] [Batch 01019/04869] [00:11:36/00:43:50, 0.683s/it]: train_loss_raw=1.1720, running_loss=1.1976, LR=0.000100
[2025-08-26 08:01:55,933][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044848] [Batch 01027/04869] [00:11:41/00:43:45, 0.683s/it]: train_loss_raw=1.2615, running_loss=1.1989, LR=0.000100
[2025-08-26 08:02:01,908][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044856] [Batch 01035/04869] [00:11:47/00:43:41, 0.684s/it]: train_loss_raw=1.1753, running_loss=1.1974, LR=0.000100
[2025-08-26 08:02:07,290][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044864] [Batch 01043/04869] [00:11:53/00:43:35, 0.684s/it]: train_loss_raw=1.2779, running_loss=1.1974, LR=0.000100
[2025-08-26 08:02:12,462][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044872] [Batch 01051/04869] [00:11:58/00:43:29, 0.683s/it]: train_loss_raw=1.1407, running_loss=1.1981, LR=0.000100
[2025-08-26 08:02:17,626][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044880] [Batch 01059/04869] [00:12:03/00:43:22, 0.683s/it]: train_loss_raw=1.1797, running_loss=1.1978, LR=0.000100
[2025-08-26 08:02:22,786][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044888] [Batch 01067/04869] [00:12:08/00:43:16, 0.683s/it]: train_loss_raw=1.1964, running_loss=1.1967, LR=0.000100
[2025-08-26 08:02:27,953][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044896] [Batch 01075/04869] [00:12:13/00:43:09, 0.683s/it]: train_loss_raw=1.1874, running_loss=1.1965, LR=0.000100
[2025-08-26 08:02:33,624][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044904] [Batch 01083/04869] [00:12:19/00:43:04, 0.683s/it]: train_loss_raw=1.1386, running_loss=1.1949, LR=0.000100
[2025-08-26 08:02:38,775][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044912] [Batch 01091/04869] [00:12:24/00:42:58, 0.682s/it]: train_loss_raw=1.1116, running_loss=1.1933, LR=0.000100
[2025-08-26 08:02:43,910][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044920] [Batch 01099/04869] [00:12:29/00:42:51, 0.682s/it]: train_loss_raw=1.2287, running_loss=1.1939, LR=0.000100
[2025-08-26 08:02:49,294][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044928] [Batch 01107/04869] [00:12:35/00:42:46, 0.682s/it]: train_loss_raw=1.2422, running_loss=1.1968, LR=0.000100
[2025-08-26 08:02:54,436][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044936] [Batch 01115/04869] [00:12:40/00:42:39, 0.682s/it]: train_loss_raw=1.3432, running_loss=1.1995, LR=0.000100
[2025-08-26 08:02:59,548][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044944] [Batch 01123/04869] [00:12:45/00:42:32, 0.681s/it]: train_loss_raw=1.1484, running_loss=1.1998, LR=0.000100
[2025-08-26 08:03:04,685][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044952] [Batch 01131/04869] [00:12:50/00:42:26, 0.681s/it]: train_loss_raw=1.1462, running_loss=1.1990, LR=0.000100
[2025-08-26 08:03:09,816][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044960] [Batch 01139/04869] [00:12:55/00:42:19, 0.681s/it]: train_loss_raw=1.0575, running_loss=1.1976, LR=0.000100
[2025-08-26 08:03:14,943][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044968] [Batch 01147/04869] [00:13:00/00:42:13, 0.681s/it]: train_loss_raw=1.1846, running_loss=1.1967, LR=0.000100
[2025-08-26 08:03:20,061][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044976] [Batch 01155/04869] [00:13:05/00:42:06, 0.680s/it]: train_loss_raw=1.1299, running_loss=1.1950, LR=0.000100
[2025-08-26 08:03:25,174][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044984] [Batch 01163/04869] [00:13:10/00:42:00, 0.680s/it]: train_loss_raw=1.2587, running_loss=1.1957, LR=0.000100
[2025-08-26 08:03:30,285][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 044992] [Batch 01171/04869] [00:13:16/00:41:53, 0.680s/it]: train_loss_raw=1.1840, running_loss=1.1941, LR=0.000100
[2025-08-26 08:03:35,402][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045000] [Batch 01179/04869] [00:13:21/00:41:47, 0.680s/it]: train_loss_raw=1.1626, running_loss=1.1945, LR=0.000100
[2025-08-26 08:03:41,245][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045008] [Batch 01187/04869] [00:13:27/00:41:43, 0.680s/it]: train_loss_raw=1.1919, running_loss=1.1955, LR=0.000100
[2025-08-26 08:03:46,392][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045016] [Batch 01195/04869] [00:13:32/00:41:36, 0.680s/it]: train_loss_raw=1.1797, running_loss=1.1945, LR=0.000100
[2025-08-26 08:03:51,522][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045024] [Batch 01203/04869] [00:13:37/00:41:30, 0.679s/it]: train_loss_raw=1.1853, running_loss=1.1944, LR=0.000100
[2025-08-26 08:03:56,651][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045032] [Batch 01211/04869] [00:13:42/00:41:24, 0.679s/it]: train_loss_raw=1.2235, running_loss=1.1958, LR=0.000100
[2025-08-26 08:04:02,339][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045040] [Batch 01219/04869] [00:13:48/00:41:19, 0.679s/it]: train_loss_raw=1.2334, running_loss=1.1967, LR=0.000100
[2025-08-26 08:04:07,476][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045048] [Batch 01227/04869] [00:13:53/00:41:13, 0.679s/it]: train_loss_raw=1.2528, running_loss=1.1992, LR=0.000100
[2025-08-26 08:04:13,023][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045056] [Batch 01235/04869] [00:13:58/00:41:08, 0.679s/it]: train_loss_raw=1.0994, running_loss=1.1993, LR=0.000100
[2025-08-26 08:04:18,226][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045064] [Batch 01243/04869] [00:14:03/00:41:02, 0.679s/it]: train_loss_raw=1.1952, running_loss=1.1991, LR=0.000100
[2025-08-26 08:04:23,634][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045072] [Batch 01251/04869] [00:14:09/00:40:56, 0.679s/it]: train_loss_raw=1.1138, running_loss=1.1979, LR=0.000100
[2025-08-26 08:04:29,297][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045080] [Batch 01259/04869] [00:14:15/00:40:51, 0.679s/it]: train_loss_raw=1.2951, running_loss=1.1988, LR=0.000100
[2025-08-26 08:04:34,457][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045088] [Batch 01267/04869] [00:14:20/00:40:45, 0.679s/it]: train_loss_raw=1.1439, running_loss=1.1982, LR=0.000100
[2025-08-26 08:04:39,815][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045096] [Batch 01275/04869] [00:14:25/00:40:39, 0.679s/it]: train_loss_raw=1.2250, running_loss=1.2028, LR=0.000100
[2025-08-26 08:04:45,701][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045104] [Batch 01283/04869] [00:14:31/00:40:35, 0.679s/it]: train_loss_raw=1.0834, running_loss=1.2048, LR=0.000100
[2025-08-26 08:04:50,870][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045112] [Batch 01291/04869] [00:14:36/00:40:29, 0.679s/it]: train_loss_raw=1.1902, running_loss=1.2059, LR=0.000100
[2025-08-26 08:04:56,015][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045120] [Batch 01299/04869] [00:14:41/00:40:23, 0.679s/it]: train_loss_raw=1.2065, running_loss=1.2022, LR=0.000100
[2025-08-26 08:05:01,596][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045128] [Batch 01307/04869] [00:14:47/00:40:18, 0.679s/it]: train_loss_raw=1.2393, running_loss=1.2033, LR=0.000100
[2025-08-26 08:05:07,210][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045136] [Batch 01315/04869] [00:14:52/00:40:13, 0.679s/it]: train_loss_raw=1.0878, running_loss=1.2015, LR=0.000100
[2025-08-26 08:05:12,403][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045144] [Batch 01323/04869] [00:14:58/00:40:07, 0.679s/it]: train_loss_raw=1.2739, running_loss=1.2022, LR=0.000100
[2025-08-26 08:05:17,504][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045152] [Batch 01331/04869] [00:15:03/00:40:01, 0.679s/it]: train_loss_raw=1.0540, running_loss=1.1995, LR=0.000100
[2025-08-26 08:05:22,605][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045160] [Batch 01339/04869] [00:15:08/00:39:54, 0.678s/it]: train_loss_raw=1.1902, running_loss=1.1981, LR=0.000100
[2025-08-26 08:05:27,718][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045168] [Batch 01347/04869] [00:15:13/00:39:48, 0.678s/it]: train_loss_raw=1.0969, running_loss=1.1995, LR=0.000100
[2025-08-26 08:05:32,959][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045176] [Batch 01355/04869] [00:15:18/00:39:42, 0.678s/it]: train_loss_raw=1.2263, running_loss=1.2014, LR=0.000100
[2025-08-26 08:05:38,669][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045184] [Batch 01363/04869] [00:15:24/00:39:37, 0.678s/it]: train_loss_raw=1.3399, running_loss=1.2031, LR=0.000100
[2025-08-26 08:05:43,983][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045192] [Batch 01371/04869] [00:15:29/00:39:32, 0.678s/it]: train_loss_raw=1.1947, running_loss=1.2027, LR=0.000100
[2025-08-26 08:05:49,574][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045200] [Batch 01379/04869] [00:15:35/00:39:27, 0.678s/it]: train_loss_raw=1.3444, running_loss=1.2046, LR=0.000100
[2025-08-26 08:05:54,700][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045208] [Batch 01387/04869] [00:15:40/00:39:21, 0.678s/it]: train_loss_raw=1.2597, running_loss=1.2066, LR=0.000100
[2025-08-26 08:06:00,204][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045216] [Batch 01395/04869] [00:15:45/00:39:15, 0.678s/it]: train_loss_raw=1.3500, running_loss=1.2065, LR=0.000100
[2025-08-26 08:06:05,337][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045224] [Batch 01403/04869] [00:15:51/00:39:09, 0.678s/it]: train_loss_raw=1.1681, running_loss=1.2050, LR=0.000100
[2025-08-26 08:06:10,467][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045232] [Batch 01411/04869] [00:15:56/00:39:03, 0.678s/it]: train_loss_raw=1.2052, running_loss=1.2032, LR=0.000100
[2025-08-26 08:06:15,727][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045240] [Batch 01419/04869] [00:16:01/00:38:57, 0.678s/it]: train_loss_raw=1.2335, running_loss=1.2029, LR=0.000100
[2025-08-26 08:06:21,198][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045248] [Batch 01427/04869] [00:16:06/00:38:52, 0.678s/it]: train_loss_raw=1.2372, running_loss=1.2014, LR=0.000100
[2025-08-26 08:06:26,337][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045256] [Batch 01435/04869] [00:16:12/00:38:46, 0.677s/it]: train_loss_raw=1.0710, running_loss=1.2018, LR=0.000100
[2025-08-26 08:06:31,471][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045264] [Batch 01443/04869] [00:16:17/00:38:40, 0.677s/it]: train_loss_raw=1.1351, running_loss=1.2025, LR=0.000100
[2025-08-26 08:06:36,596][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045272] [Batch 01451/04869] [00:16:22/00:38:34, 0.677s/it]: train_loss_raw=1.2420, running_loss=1.2015, LR=0.000100
[2025-08-26 08:06:41,738][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045280] [Batch 01459/04869] [00:16:27/00:38:28, 0.677s/it]: train_loss_raw=1.2499, running_loss=1.2013, LR=0.000100
[2025-08-26 08:06:46,880][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045288] [Batch 01467/04869] [00:16:32/00:38:21, 0.677s/it]: train_loss_raw=1.0838, running_loss=1.1993, LR=0.000100
[2025-08-26 08:06:52,017][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045296] [Batch 01475/04869] [00:16:37/00:38:15, 0.676s/it]: train_loss_raw=1.2517, running_loss=1.2006, LR=0.000100
[2025-08-26 08:06:57,268][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045304] [Batch 01483/04869] [00:16:43/00:38:10, 0.676s/it]: train_loss_raw=1.2357, running_loss=1.1987, LR=0.000100
[2025-08-26 08:07:02,543][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045312] [Batch 01491/04869] [00:16:48/00:38:04, 0.676s/it]: train_loss_raw=1.2183, running_loss=1.1989, LR=0.000100
[2025-08-26 08:07:07,667][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045320] [Batch 01499/04869] [00:16:53/00:37:58, 0.676s/it]: train_loss_raw=1.1719, running_loss=1.1970, LR=0.000100
[2025-08-26 08:07:12,950][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045328] [Batch 01507/04869] [00:16:58/00:37:52, 0.676s/it]: train_loss_raw=1.1302, running_loss=1.1963, LR=0.000100
[2025-08-26 08:07:18,101][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045336] [Batch 01515/04869] [00:17:03/00:37:46, 0.676s/it]: train_loss_raw=1.2055, running_loss=1.1971, LR=0.000100
[2025-08-26 08:07:23,458][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045344] [Batch 01523/04869] [00:17:09/00:37:41, 0.676s/it]: train_loss_raw=1.2074, running_loss=1.1962, LR=0.000100
[2025-08-26 08:07:28,851][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045352] [Batch 01531/04869] [00:17:14/00:37:35, 0.676s/it]: train_loss_raw=1.2095, running_loss=1.1948, LR=0.000100
[2025-08-26 08:07:33,981][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045360] [Batch 01539/04869] [00:17:19/00:37:29, 0.676s/it]: train_loss_raw=1.2040, running_loss=1.1924, LR=0.000100
[2025-08-26 08:07:39,091][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045368] [Batch 01547/04869] [00:17:24/00:37:23, 0.675s/it]: train_loss_raw=1.1581, running_loss=1.1923, LR=0.000100
[2025-08-26 08:07:44,220][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045376] [Batch 01555/04869] [00:17:29/00:37:17, 0.675s/it]: train_loss_raw=1.0737, running_loss=1.1924, LR=0.000100
[2025-08-26 08:07:49,718][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045384] [Batch 01563/04869] [00:17:35/00:37:12, 0.675s/it]: train_loss_raw=1.1514, running_loss=1.1945, LR=0.000100
[2025-08-26 08:07:55,009][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045392] [Batch 01571/04869] [00:17:40/00:37:06, 0.675s/it]: train_loss_raw=1.2821, running_loss=1.1967, LR=0.000100
[2025-08-26 08:08:00,789][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045400] [Batch 01579/04869] [00:17:46/00:37:02, 0.675s/it]: train_loss_raw=1.1721, running_loss=1.1978, LR=0.000100
[2025-08-26 08:08:05,928][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045408] [Batch 01587/04869] [00:17:51/00:36:56, 0.675s/it]: train_loss_raw=1.2459, running_loss=1.2011, LR=0.000100
[2025-08-26 08:08:11,075][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045416] [Batch 01595/04869] [00:17:56/00:36:50, 0.675s/it]: train_loss_raw=1.2208, running_loss=1.2038, LR=0.000100
[2025-08-26 08:08:16,251][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045424] [Batch 01603/04869] [00:18:02/00:36:44, 0.675s/it]: train_loss_raw=1.1812, running_loss=1.2035, LR=0.000100
[2025-08-26 08:08:21,443][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045432] [Batch 01611/04869] [00:18:07/00:36:38, 0.675s/it]: train_loss_raw=1.2079, running_loss=1.2021, LR=0.000100
[2025-08-26 08:08:26,589][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045440] [Batch 01619/04869] [00:18:12/00:36:32, 0.675s/it]: train_loss_raw=1.1073, running_loss=1.2011, LR=0.000100
[2025-08-26 08:08:32,146][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045448] [Batch 01627/04869] [00:18:17/00:36:27, 0.675s/it]: train_loss_raw=1.2350, running_loss=1.2026, LR=0.000100
[2025-08-26 08:08:37,314][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045456] [Batch 01635/04869] [00:18:23/00:36:21, 0.675s/it]: train_loss_raw=1.2017, running_loss=1.1989, LR=0.000100
[2025-08-26 08:08:42,433][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045464] [Batch 01643/04869] [00:18:28/00:36:15, 0.675s/it]: train_loss_raw=1.2094, running_loss=1.1947, LR=0.000100
[2025-08-26 08:08:48,190][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045472] [Batch 01651/04869] [00:18:33/00:36:11, 0.675s/it]: train_loss_raw=1.2115, running_loss=1.1962, LR=0.000100
[2025-08-26 08:08:53,506][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045480] [Batch 01659/04869] [00:18:39/00:36:05, 0.675s/it]: train_loss_raw=1.2646, running_loss=1.1953, LR=0.000100
[2025-08-26 08:08:58,955][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045488] [Batch 01667/04869] [00:18:44/00:36:00, 0.675s/it]: train_loss_raw=1.1182, running_loss=1.1939, LR=0.000100
[2025-08-26 08:09:04,484][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045496] [Batch 01675/04869] [00:18:50/00:35:55, 0.675s/it]: train_loss_raw=1.1155, running_loss=1.1945, LR=0.000100
[2025-08-26 08:09:09,638][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045504] [Batch 01683/04869] [00:18:55/00:35:49, 0.675s/it]: train_loss_raw=1.2205, running_loss=1.1954, LR=0.000100
[2025-08-26 08:09:15,548][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045512] [Batch 01691/04869] [00:19:01/00:35:44, 0.675s/it]: train_loss_raw=1.1442, running_loss=1.1954, LR=0.000100
[2025-08-26 08:09:21,162][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045520] [Batch 01699/04869] [00:19:06/00:35:39, 0.675s/it]: train_loss_raw=1.2329, running_loss=1.1960, LR=0.000100
[2025-08-26 08:09:26,314][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045528] [Batch 01707/04869] [00:19:12/00:35:34, 0.675s/it]: train_loss_raw=1.2574, running_loss=1.1980, LR=0.000100
[2025-08-26 08:09:31,472][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045536] [Batch 01715/04869] [00:19:17/00:35:28, 0.675s/it]: train_loss_raw=1.2029, running_loss=1.1965, LR=0.000100
[2025-08-26 08:09:36,619][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045544] [Batch 01723/04869] [00:19:22/00:35:22, 0.675s/it]: train_loss_raw=1.2426, running_loss=1.1952, LR=0.000100
[2025-08-26 08:09:42,330][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045552] [Batch 01731/04869] [00:19:28/00:35:17, 0.675s/it]: train_loss_raw=1.1185, running_loss=1.1946, LR=0.000100
[2025-08-26 08:09:47,494][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045560] [Batch 01739/04869] [00:19:33/00:35:11, 0.675s/it]: train_loss_raw=1.2450, running_loss=1.1973, LR=0.000100
[2025-08-26 08:09:52,661][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045568] [Batch 01747/04869] [00:19:38/00:35:05, 0.675s/it]: train_loss_raw=1.2490, running_loss=1.1994, LR=0.000100
[2025-08-26 08:09:57,885][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045576] [Batch 01755/04869] [00:19:43/00:35:00, 0.674s/it]: train_loss_raw=1.1256, running_loss=1.2002, LR=0.000100
[2025-08-26 08:10:03,030][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045584] [Batch 01763/04869] [00:19:48/00:34:54, 0.674s/it]: train_loss_raw=1.1381, running_loss=1.1976, LR=0.000100
[2025-08-26 08:10:08,177][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045592] [Batch 01771/04869] [00:19:53/00:34:48, 0.674s/it]: train_loss_raw=1.2002, running_loss=1.1971, LR=0.000100
[2025-08-26 08:10:13,327][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045600] [Batch 01779/04869] [00:19:59/00:34:42, 0.674s/it]: train_loss_raw=1.1794, running_loss=1.1953, LR=0.000100
[2025-08-26 08:10:18,881][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045608] [Batch 01787/04869] [00:20:04/00:34:37, 0.674s/it]: train_loss_raw=1.1148, running_loss=1.1939, LR=0.000100
[2025-08-26 08:10:24,126][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045616] [Batch 01795/04869] [00:20:09/00:34:31, 0.674s/it]: train_loss_raw=1.1328, running_loss=1.1927, LR=0.000100
[2025-08-26 08:10:29,283][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045624] [Batch 01803/04869] [00:20:15/00:34:26, 0.674s/it]: train_loss_raw=1.1500, running_loss=1.1939, LR=0.000100
[2025-08-26 08:10:34,450][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045632] [Batch 01811/04869] [00:20:20/00:34:20, 0.674s/it]: train_loss_raw=1.2912, running_loss=1.1969, LR=0.000100
[2025-08-26 08:10:39,615][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045640] [Batch 01819/04869] [00:20:25/00:34:14, 0.674s/it]: train_loss_raw=1.3001, running_loss=1.2002, LR=0.000100
[2025-08-26 08:10:44,784][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045648] [Batch 01827/04869] [00:20:30/00:34:08, 0.674s/it]: train_loss_raw=1.1691, running_loss=1.2004, LR=0.000100
[2025-08-26 08:10:49,956][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045656] [Batch 01835/04869] [00:20:35/00:34:03, 0.673s/it]: train_loss_raw=1.3116, running_loss=1.2007, LR=0.000100
[2025-08-26 08:10:55,117][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045664] [Batch 01843/04869] [00:20:40/00:33:57, 0.673s/it]: train_loss_raw=1.1618, running_loss=1.1991, LR=0.000100
[2025-08-26 08:11:00,277][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045672] [Batch 01851/04869] [00:20:46/00:33:51, 0.673s/it]: train_loss_raw=1.2314, running_loss=1.1984, LR=0.000100
[2025-08-26 08:11:05,648][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045680] [Batch 01859/04869] [00:20:51/00:33:46, 0.673s/it]: train_loss_raw=1.0909, running_loss=1.1960, LR=0.000100
[2025-08-26 08:11:10,793][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045688] [Batch 01867/04869] [00:20:56/00:33:40, 0.673s/it]: train_loss_raw=1.2442, running_loss=1.1934, LR=0.000100
[2025-08-26 08:11:16,325][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045696] [Batch 01875/04869] [00:21:02/00:33:35, 0.673s/it]: train_loss_raw=1.2597, running_loss=1.1940, LR=0.000100
[2025-08-26 08:11:21,483][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045704] [Batch 01883/04869] [00:21:07/00:33:29, 0.673s/it]: train_loss_raw=1.2819, running_loss=1.1943, LR=0.000100
[2025-08-26 08:11:26,646][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045712] [Batch 01891/04869] [00:21:12/00:33:23, 0.673s/it]: train_loss_raw=1.1136, running_loss=1.1927, LR=0.000100
[2025-08-26 08:11:32,073][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045720] [Batch 01899/04869] [00:21:17/00:33:18, 0.673s/it]: train_loss_raw=1.1810, running_loss=1.1925, LR=0.000100
[2025-08-26 08:11:37,246][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045728] [Batch 01907/04869] [00:21:23/00:33:12, 0.673s/it]: train_loss_raw=1.2723, running_loss=1.1943, LR=0.000100
[2025-08-26 08:11:42,423][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045736] [Batch 01915/04869] [00:21:28/00:33:07, 0.673s/it]: train_loss_raw=1.1881, running_loss=1.1952, LR=0.000100
[2025-08-26 08:11:47,853][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045744] [Batch 01923/04869] [00:21:33/00:33:01, 0.673s/it]: train_loss_raw=1.3260, running_loss=1.1977, LR=0.000100
[2025-08-26 08:11:53,151][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045752] [Batch 01931/04869] [00:21:38/00:32:56, 0.673s/it]: train_loss_raw=1.2173, running_loss=1.1979, LR=0.000100
[2025-08-26 08:11:58,314][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045760] [Batch 01939/04869] [00:21:44/00:32:50, 0.673s/it]: train_loss_raw=1.2092, running_loss=1.1978, LR=0.000100
[2025-08-26 08:12:04,273][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045768] [Batch 01947/04869] [00:21:50/00:32:46, 0.673s/it]: train_loss_raw=1.2187, running_loss=1.1983, LR=0.000100
[2025-08-26 08:12:09,607][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045776] [Batch 01955/04869] [00:21:55/00:32:40, 0.673s/it]: train_loss_raw=1.1529, running_loss=1.1980, LR=0.000100
[2025-08-26 08:12:14,732][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045784] [Batch 01963/04869] [00:22:00/00:32:34, 0.673s/it]: train_loss_raw=1.0841, running_loss=1.1949, LR=0.000100
[2025-08-26 08:12:19,962][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045792] [Batch 01971/04869] [00:22:05/00:32:29, 0.673s/it]: train_loss_raw=1.1867, running_loss=1.1964, LR=0.000100
[2025-08-26 08:12:25,380][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045800] [Batch 01979/04869] [00:22:11/00:32:23, 0.673s/it]: train_loss_raw=1.1108, running_loss=1.1945, LR=0.000100
[2025-08-26 08:12:30,532][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045808] [Batch 01987/04869] [00:22:16/00:32:18, 0.673s/it]: train_loss_raw=1.1827, running_loss=1.1925, LR=0.000100
[2025-08-26 08:12:36,340][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045816] [Batch 01995/04869] [00:22:22/00:32:13, 0.673s/it]: train_loss_raw=1.2090, running_loss=1.1919, LR=0.000100
[2025-08-26 08:12:41,647][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045824] [Batch 02003/04869] [00:22:27/00:32:07, 0.673s/it]: train_loss_raw=1.2491, running_loss=1.1930, LR=0.000100
[2025-08-26 08:12:47,072][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045832] [Batch 02011/04869] [00:22:32/00:32:02, 0.673s/it]: train_loss_raw=1.1170, running_loss=1.1896, LR=0.000100
[2025-08-26 08:12:52,220][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045840] [Batch 02019/04869] [00:22:37/00:31:56, 0.673s/it]: train_loss_raw=1.2200, running_loss=1.1905, LR=0.000100
[2025-08-26 08:12:57,367][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045848] [Batch 02027/04869] [00:22:43/00:31:51, 0.672s/it]: train_loss_raw=1.2688, running_loss=1.1894, LR=0.000100
[2025-08-26 08:13:02,522][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045856] [Batch 02035/04869] [00:22:48/00:31:45, 0.672s/it]: train_loss_raw=1.2209, running_loss=1.1870, LR=0.000100
[2025-08-26 08:13:07,666][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045864] [Batch 02043/04869] [00:22:53/00:31:39, 0.672s/it]: train_loss_raw=1.2717, running_loss=1.1867, LR=0.000100
[2025-08-26 08:13:13,206][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045872] [Batch 02051/04869] [00:22:58/00:31:34, 0.672s/it]: train_loss_raw=1.2704, running_loss=1.1909, LR=0.000100
[2025-08-26 08:13:18,369][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045880] [Batch 02059/04869] [00:23:04/00:31:28, 0.672s/it]: train_loss_raw=1.2057, running_loss=1.1908, LR=0.000100
[2025-08-26 08:13:23,515][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045888] [Batch 02067/04869] [00:23:09/00:31:23, 0.672s/it]: train_loss_raw=1.2157, running_loss=1.1917, LR=0.000100
[2025-08-26 08:13:28,654][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045896] [Batch 02075/04869] [00:23:14/00:31:17, 0.672s/it]: train_loss_raw=1.1857, running_loss=1.1902, LR=0.000100
[2025-08-26 08:13:33,794][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045904] [Batch 02083/04869] [00:23:19/00:31:11, 0.672s/it]: train_loss_raw=1.1334, running_loss=1.1923, LR=0.000100
[2025-08-26 08:13:38,940][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045912] [Batch 02091/04869] [00:23:24/00:31:06, 0.672s/it]: train_loss_raw=1.1731, running_loss=1.1921, LR=0.000100
[2025-08-26 08:13:44,286][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045920] [Batch 02099/04869] [00:23:30/00:31:00, 0.672s/it]: train_loss_raw=1.1680, running_loss=1.1938, LR=0.000100
[2025-08-26 08:13:49,458][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045928] [Batch 02107/04869] [00:23:35/00:30:55, 0.672s/it]: train_loss_raw=1.2491, running_loss=1.1939, LR=0.000100
[2025-08-26 08:13:54,630][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045936] [Batch 02115/04869] [00:23:40/00:30:49, 0.672s/it]: train_loss_raw=1.1383, running_loss=1.1915, LR=0.000100
[2025-08-26 08:13:59,797][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045944] [Batch 02123/04869] [00:23:45/00:30:43, 0.671s/it]: train_loss_raw=1.1473, running_loss=1.1889, LR=0.000100
[2025-08-26 08:14:04,953][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045952] [Batch 02131/04869] [00:23:50/00:30:38, 0.671s/it]: train_loss_raw=1.2656, running_loss=1.1893, LR=0.000100
[2025-08-26 08:14:10,108][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045960] [Batch 02139/04869] [00:23:55/00:30:32, 0.671s/it]: train_loss_raw=1.2637, running_loss=1.1902, LR=0.000100
[2025-08-26 08:14:15,270][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045968] [Batch 02147/04869] [00:24:01/00:30:26, 0.671s/it]: train_loss_raw=1.0866, running_loss=1.1902, LR=0.000100
[2025-08-26 08:14:20,439][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045976] [Batch 02155/04869] [00:24:06/00:30:21, 0.671s/it]: train_loss_raw=1.0931, running_loss=1.1896, LR=0.000100
[2025-08-26 08:14:25,897][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045984] [Batch 02163/04869] [00:24:11/00:30:16, 0.671s/it]: train_loss_raw=1.1543, running_loss=1.1894, LR=0.000100
[2025-08-26 08:14:31,071][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 045992] [Batch 02171/04869] [00:24:16/00:30:10, 0.671s/it]: train_loss_raw=1.2066, running_loss=1.1908, LR=0.000100
[2025-08-26 08:14:36,227][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046000] [Batch 02179/04869] [00:24:22/00:30:04, 0.671s/it]: train_loss_raw=1.1967, running_loss=1.1877, LR=0.000100
[2025-08-26 08:14:45,128][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046008] [Batch 02187/04869] [00:24:30/00:30:03, 0.673s/it]: train_loss_raw=1.1892, running_loss=1.1868, LR=0.000100
[2025-08-26 08:14:50,294][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046016] [Batch 02195/04869] [00:24:36/00:29:58, 0.672s/it]: train_loss_raw=1.1416, running_loss=1.1844, LR=0.000100
[2025-08-26 08:14:55,453][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046024] [Batch 02203/04869] [00:24:41/00:29:52, 0.672s/it]: train_loss_raw=1.1817, running_loss=1.1870, LR=0.000100
[2025-08-26 08:15:00,621][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046032] [Batch 02211/04869] [00:24:46/00:29:46, 0.672s/it]: train_loss_raw=1.1612, running_loss=1.1878, LR=0.000100
[2025-08-26 08:15:05,801][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046040] [Batch 02219/04869] [00:24:51/00:29:41, 0.672s/it]: train_loss_raw=1.2325, running_loss=1.1885, LR=0.000100
[2025-08-26 08:15:11,234][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046048] [Batch 02227/04869] [00:24:57/00:29:35, 0.672s/it]: train_loss_raw=1.2009, running_loss=1.1889, LR=0.000100
[2025-08-26 08:15:16,427][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046056] [Batch 02235/04869] [00:25:02/00:29:30, 0.672s/it]: train_loss_raw=1.1890, running_loss=1.1889, LR=0.000100
[2025-08-26 08:15:21,588][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046064] [Batch 02243/04869] [00:25:07/00:29:24, 0.672s/it]: train_loss_raw=1.1999, running_loss=1.1889, LR=0.000100
[2025-08-26 08:15:26,743][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046072] [Batch 02251/04869] [00:25:12/00:29:19, 0.672s/it]: train_loss_raw=1.2967, running_loss=1.1892, LR=0.000100
[2025-08-26 08:15:31,895][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046080] [Batch 02259/04869] [00:25:17/00:29:13, 0.672s/it]: train_loss_raw=1.2142, running_loss=1.1878, LR=0.000100
[2025-08-26 08:15:37,053][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046088] [Batch 02267/04869] [00:25:22/00:29:07, 0.672s/it]: train_loss_raw=1.3693, running_loss=1.1906, LR=0.000100
[2025-08-26 08:15:42,215][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046096] [Batch 02275/04869] [00:25:27/00:29:02, 0.672s/it]: train_loss_raw=1.1874, running_loss=1.1884, LR=0.000100
[2025-08-26 08:15:47,377][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046104] [Batch 02283/04869] [00:25:33/00:28:56, 0.672s/it]: train_loss_raw=1.1611, running_loss=1.1883, LR=0.000100
[2025-08-26 08:15:52,537][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046112] [Batch 02291/04869] [00:25:38/00:28:51, 0.671s/it]: train_loss_raw=1.2337, running_loss=1.1863, LR=0.000100
[2025-08-26 08:15:57,687][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046120] [Batch 02299/04869] [00:25:43/00:28:45, 0.671s/it]: train_loss_raw=1.2646, running_loss=1.1864, LR=0.000100
[2025-08-26 08:16:02,844][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046128] [Batch 02307/04869] [00:25:48/00:28:39, 0.671s/it]: train_loss_raw=1.0956, running_loss=1.1883, LR=0.000100
[2025-08-26 08:16:08,001][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046136] [Batch 02315/04869] [00:25:53/00:28:34, 0.671s/it]: train_loss_raw=1.1042, running_loss=1.1904, LR=0.000100
[2025-08-26 08:16:13,156][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046144] [Batch 02323/04869] [00:25:58/00:28:28, 0.671s/it]: train_loss_raw=1.0918, running_loss=1.1871, LR=0.000100
[2025-08-26 08:16:18,366][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046152] [Batch 02331/04869] [00:26:04/00:28:23, 0.671s/it]: train_loss_raw=1.1534, running_loss=1.1880, LR=0.000100
[2025-08-26 08:16:23,535][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046160] [Batch 02339/04869] [00:26:09/00:28:17, 0.671s/it]: train_loss_raw=1.2120, running_loss=1.1905, LR=0.000100
[2025-08-26 08:16:28,904][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046168] [Batch 02347/04869] [00:26:14/00:28:12, 0.671s/it]: train_loss_raw=1.1883, running_loss=1.1924, LR=0.000100
[2025-08-26 08:16:34,154][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046176] [Batch 02355/04869] [00:26:19/00:28:06, 0.671s/it]: train_loss_raw=1.2038, running_loss=1.1946, LR=0.000100
[2025-08-26 08:16:39,632][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046184] [Batch 02363/04869] [00:26:25/00:28:01, 0.671s/it]: train_loss_raw=1.1785, running_loss=1.1994, LR=0.000100
[2025-08-26 08:16:44,765][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046192] [Batch 02371/04869] [00:26:30/00:27:55, 0.671s/it]: train_loss_raw=1.1315, running_loss=1.1993, LR=0.000100
[2025-08-26 08:16:50,000][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046200] [Batch 02379/04869] [00:26:35/00:27:50, 0.671s/it]: train_loss_raw=1.2294, running_loss=1.1971, LR=0.000100
[2025-08-26 08:16:55,157][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046208] [Batch 02387/04869] [00:26:40/00:27:44, 0.671s/it]: train_loss_raw=1.2587, running_loss=1.2005, LR=0.000100
[2025-08-26 08:17:00,363][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046216] [Batch 02395/04869] [00:26:46/00:27:39, 0.671s/it]: train_loss_raw=1.1853, running_loss=1.2020, LR=0.000100
[2025-08-26 08:17:05,577][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046224] [Batch 02403/04869] [00:26:51/00:27:33, 0.671s/it]: train_loss_raw=1.1911, running_loss=1.1997, LR=0.000100
[2025-08-26 08:17:11,446][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046232] [Batch 02411/04869] [00:26:57/00:27:28, 0.671s/it]: train_loss_raw=1.1595, running_loss=1.1963, LR=0.000100
[2025-08-26 08:17:17,319][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046240] [Batch 02419/04869] [00:27:03/00:27:23, 0.671s/it]: train_loss_raw=1.1496, running_loss=1.1981, LR=0.000100
[2025-08-26 08:17:23,248][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046248] [Batch 02427/04869] [00:27:09/00:27:19, 0.671s/it]: train_loss_raw=1.1913, running_loss=1.2002, LR=0.000100
[2025-08-26 08:17:28,499][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046256] [Batch 02435/04869] [00:27:14/00:27:13, 0.671s/it]: train_loss_raw=1.2381, running_loss=1.1967, LR=0.000100
[2025-08-26 08:17:33,634][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046264] [Batch 02443/04869] [00:27:19/00:27:07, 0.671s/it]: train_loss_raw=1.1021, running_loss=1.1966, LR=0.000100
[2025-08-26 08:17:38,757][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046272] [Batch 02451/04869] [00:27:24/00:27:02, 0.671s/it]: train_loss_raw=1.1226, running_loss=1.1942, LR=0.000100
[2025-08-26 08:17:44,563][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046280] [Batch 02459/04869] [00:27:30/00:26:57, 0.671s/it]: train_loss_raw=1.1696, running_loss=1.1924, LR=0.000100
[2025-08-26 08:17:50,127][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046288] [Batch 02467/04869] [00:27:35/00:26:52, 0.671s/it]: train_loss_raw=1.2692, running_loss=1.1919, LR=0.000100
[2025-08-26 08:17:55,441][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046296] [Batch 02475/04869] [00:27:41/00:26:46, 0.671s/it]: train_loss_raw=1.1468, running_loss=1.1901, LR=0.000100
[2025-08-26 08:18:00,566][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046304] [Batch 02483/04869] [00:27:46/00:26:41, 0.671s/it]: train_loss_raw=1.2395, running_loss=1.1914, LR=0.000100
[2025-08-26 08:18:05,904][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046312] [Batch 02491/04869] [00:27:51/00:26:35, 0.671s/it]: train_loss_raw=1.2447, running_loss=1.1940, LR=0.000100
[2025-08-26 08:18:11,561][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046320] [Batch 02499/04869] [00:27:57/00:26:30, 0.671s/it]: train_loss_raw=1.2303, running_loss=1.1952, LR=0.000100
[2025-08-26 08:18:17,006][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046328] [Batch 02507/04869] [00:28:02/00:26:25, 0.671s/it]: train_loss_raw=1.1223, running_loss=1.1931, LR=0.000100
[2025-08-26 08:18:22,138][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046336] [Batch 02515/04869] [00:28:07/00:26:19, 0.671s/it]: train_loss_raw=1.0679, running_loss=1.1946, LR=0.000100
[2025-08-26 08:18:27,990][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046344] [Batch 02523/04869] [00:28:13/00:26:14, 0.671s/it]: train_loss_raw=1.0941, running_loss=1.1902, LR=0.000100
[2025-08-26 08:18:33,139][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046352] [Batch 02531/04869] [00:28:18/00:26:09, 0.671s/it]: train_loss_raw=1.1169, running_loss=1.1873, LR=0.000100
[2025-08-26 08:18:38,289][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046360] [Batch 02539/04869] [00:28:24/00:26:03, 0.671s/it]: train_loss_raw=1.1088, running_loss=1.1824, LR=0.000100
[2025-08-26 08:18:43,450][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046368] [Batch 02547/04869] [00:28:29/00:25:58, 0.671s/it]: train_loss_raw=1.2513, running_loss=1.1810, LR=0.000100
[2025-08-26 08:18:48,611][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046376] [Batch 02555/04869] [00:28:34/00:25:52, 0.671s/it]: train_loss_raw=1.1933, running_loss=1.1811, LR=0.000100
[2025-08-26 08:18:53,771][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046384] [Batch 02563/04869] [00:28:39/00:25:47, 0.671s/it]: train_loss_raw=1.1337, running_loss=1.1818, LR=0.000100
[2025-08-26 08:18:58,924][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046392] [Batch 02571/04869] [00:28:44/00:25:41, 0.671s/it]: train_loss_raw=1.1643, running_loss=1.1798, LR=0.000100
[2025-08-26 08:19:04,258][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046400] [Batch 02579/04869] [00:28:50/00:25:36, 0.671s/it]: train_loss_raw=1.1838, running_loss=1.1805, LR=0.000100
[2025-08-26 08:19:09,583][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046408] [Batch 02587/04869] [00:28:55/00:25:30, 0.671s/it]: train_loss_raw=1.2221, running_loss=1.1828, LR=0.000100
[2025-08-26 08:19:14,728][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046416] [Batch 02595/04869] [00:29:00/00:25:25, 0.671s/it]: train_loss_raw=1.1404, running_loss=1.1861, LR=0.000100
[2025-08-26 08:19:20,192][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046424] [Batch 02603/04869] [00:29:05/00:25:19, 0.671s/it]: train_loss_raw=1.2996, running_loss=1.1864, LR=0.000100
[2025-08-26 08:19:25,351][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046432] [Batch 02611/04869] [00:29:11/00:25:14, 0.671s/it]: train_loss_raw=1.1597, running_loss=1.1870, LR=0.000100
[2025-08-26 08:19:30,518][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046440] [Batch 02619/04869] [00:29:16/00:25:08, 0.671s/it]: train_loss_raw=1.3846, running_loss=1.1902, LR=0.000100
[2025-08-26 08:19:35,677][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046448] [Batch 02627/04869] [00:29:21/00:25:03, 0.671s/it]: train_loss_raw=1.2464, running_loss=1.1926, LR=0.000100
[2025-08-26 08:19:40,860][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046456] [Batch 02635/04869] [00:29:26/00:24:57, 0.670s/it]: train_loss_raw=1.1280, running_loss=1.1924, LR=0.000100
[2025-08-26 08:19:46,500][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046464] [Batch 02643/04869] [00:29:32/00:24:52, 0.671s/it]: train_loss_raw=1.1895, running_loss=1.1931, LR=0.000100
[2025-08-26 08:19:52,023][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046472] [Batch 02651/04869] [00:29:37/00:24:47, 0.671s/it]: train_loss_raw=1.1674, running_loss=1.1911, LR=0.000100
[2025-08-26 08:19:57,269][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046480] [Batch 02659/04869] [00:29:43/00:24:41, 0.671s/it]: train_loss_raw=1.0105, running_loss=1.1882, LR=0.000100
[2025-08-26 08:20:02,434][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046488] [Batch 02667/04869] [00:29:48/00:24:36, 0.670s/it]: train_loss_raw=1.2620, running_loss=1.1889, LR=0.000100
[2025-08-26 08:20:07,587][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046496] [Batch 02675/04869] [00:29:53/00:24:30, 0.670s/it]: train_loss_raw=1.2001, running_loss=1.1894, LR=0.000100
[2025-08-26 08:20:12,735][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046504] [Batch 02683/04869] [00:29:58/00:24:25, 0.670s/it]: train_loss_raw=1.1877, running_loss=1.1908, LR=0.000100
[2025-08-26 08:20:17,884][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046512] [Batch 02691/04869] [00:30:03/00:24:19, 0.670s/it]: train_loss_raw=1.1130, running_loss=1.1864, LR=0.000100
[2025-08-26 08:20:23,038][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046520] [Batch 02699/04869] [00:30:08/00:24:14, 0.670s/it]: train_loss_raw=1.1560, running_loss=1.1859, LR=0.000100
[2025-08-26 08:20:28,188][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046528] [Batch 02707/04869] [00:30:13/00:24:08, 0.670s/it]: train_loss_raw=1.1349, running_loss=1.1838, LR=0.000100
[2025-08-26 08:20:33,491][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046536] [Batch 02715/04869] [00:30:19/00:24:03, 0.670s/it]: train_loss_raw=1.1350, running_loss=1.1831, LR=0.000100
[2025-08-26 08:20:38,805][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046544] [Batch 02723/04869] [00:30:24/00:23:57, 0.670s/it]: train_loss_raw=1.1560, running_loss=1.1829, LR=0.000100
[2025-08-26 08:20:43,957][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046552] [Batch 02731/04869] [00:30:29/00:23:52, 0.670s/it]: train_loss_raw=1.1416, running_loss=1.1836, LR=0.000100
[2025-08-26 08:20:49,116][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046560] [Batch 02739/04869] [00:30:34/00:23:46, 0.670s/it]: train_loss_raw=1.1769, running_loss=1.1824, LR=0.000100
[2025-08-26 08:20:54,269][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046568] [Batch 02747/04869] [00:30:40/00:23:41, 0.670s/it]: train_loss_raw=1.2335, running_loss=1.1862, LR=0.000100
[2025-08-26 08:20:59,427][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046576] [Batch 02755/04869] [00:30:45/00:23:35, 0.670s/it]: train_loss_raw=1.1788, running_loss=1.1858, LR=0.000100
[2025-08-26 08:21:04,581][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046584] [Batch 02763/04869] [00:30:50/00:23:30, 0.670s/it]: train_loss_raw=1.1959, running_loss=1.1847, LR=0.000100
[2025-08-26 08:21:09,729][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046592] [Batch 02771/04869] [00:30:55/00:23:24, 0.670s/it]: train_loss_raw=1.1642, running_loss=1.1826, LR=0.000100
[2025-08-26 08:21:14,884][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046600] [Batch 02779/04869] [00:31:00/00:23:19, 0.670s/it]: train_loss_raw=1.2014, running_loss=1.1841, LR=0.000100
[2025-08-26 08:21:20,020][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046608] [Batch 02787/04869] [00:31:05/00:23:13, 0.669s/it]: train_loss_raw=1.1745, running_loss=1.1799, LR=0.000100
[2025-08-26 08:21:25,166][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046616] [Batch 02795/04869] [00:31:10/00:23:08, 0.669s/it]: train_loss_raw=1.1835, running_loss=1.1801, LR=0.000100
[2025-08-26 08:21:30,314][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046624] [Batch 02803/04869] [00:31:16/00:23:02, 0.669s/it]: train_loss_raw=1.2131, running_loss=1.1797, LR=0.000100
[2025-08-26 08:21:35,461][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046632] [Batch 02811/04869] [00:31:21/00:22:57, 0.669s/it]: train_loss_raw=1.2715, running_loss=1.1785, LR=0.000100
[2025-08-26 08:21:40,728][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046640] [Batch 02819/04869] [00:31:26/00:22:51, 0.669s/it]: train_loss_raw=1.1809, running_loss=1.1796, LR=0.000100
[2025-08-26 08:21:45,898][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046648] [Batch 02827/04869] [00:31:31/00:22:46, 0.669s/it]: train_loss_raw=1.2183, running_loss=1.1831, LR=0.000100
[2025-08-26 08:21:51,041][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046656] [Batch 02835/04869] [00:31:36/00:22:40, 0.669s/it]: train_loss_raw=1.0692, running_loss=1.1857, LR=0.000100
[2025-08-26 08:21:56,220][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046664] [Batch 02843/04869] [00:31:41/00:22:35, 0.669s/it]: train_loss_raw=1.1326, running_loss=1.1865, LR=0.000100
[2025-08-26 08:22:02,023][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046672] [Batch 02851/04869] [00:31:47/00:22:30, 0.669s/it]: train_loss_raw=1.1208, running_loss=1.1837, LR=0.000100
[2025-08-26 08:22:07,191][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046680] [Batch 02859/04869] [00:31:52/00:22:24, 0.669s/it]: train_loss_raw=1.2394, running_loss=1.1858, LR=0.000100
[2025-08-26 08:22:12,330][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046688] [Batch 02867/04869] [00:31:58/00:22:19, 0.669s/it]: train_loss_raw=1.2415, running_loss=1.1844, LR=0.000100
[2025-08-26 08:22:17,469][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046696] [Batch 02875/04869] [00:32:03/00:22:13, 0.669s/it]: train_loss_raw=1.1298, running_loss=1.1869, LR=0.000100
[2025-08-26 08:22:22,886][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046704] [Batch 02883/04869] [00:32:08/00:22:08, 0.669s/it]: train_loss_raw=1.1948, running_loss=1.1860, LR=0.000100
[2025-08-26 08:22:28,290][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046712] [Batch 02891/04869] [00:32:14/00:22:03, 0.669s/it]: train_loss_raw=1.1792, running_loss=1.1860, LR=0.000100
[2025-08-26 08:22:33,848][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046720] [Batch 02899/04869] [00:32:19/00:21:58, 0.669s/it]: train_loss_raw=1.1837, running_loss=1.1857, LR=0.000100
[2025-08-26 08:22:39,022][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046728] [Batch 02907/04869] [00:32:24/00:21:52, 0.669s/it]: train_loss_raw=1.2632, running_loss=1.1869, LR=0.000100
[2025-08-26 08:22:44,170][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046736] [Batch 02915/04869] [00:32:29/00:21:47, 0.669s/it]: train_loss_raw=1.0515, running_loss=1.1872, LR=0.000100
[2025-08-26 08:22:49,826][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046744] [Batch 02923/04869] [00:32:35/00:21:41, 0.669s/it]: train_loss_raw=1.2540, running_loss=1.1885, LR=0.000100
[2025-08-26 08:22:54,991][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046752] [Batch 02931/04869] [00:32:40/00:21:36, 0.669s/it]: train_loss_raw=1.1554, running_loss=1.1891, LR=0.000100
[2025-08-26 08:23:00,147][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 046760] [Batch 02939/04869] [00:32:45/00:21:30, 0.669s/it]: train_loss_raw=1.1304, running_loss=1.1888, LR=0.000100
