[2025-08-26 08:29:52,980][__main__][INFO] - Initializing training.
[2025-08-26 08:29:52,980][__main__][INFO] - Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
[2025-08-26 08:29:52,980][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-26 08:29:52,980][__main__][INFO] - CUDA version: 12.1
[2025-08-26 08:29:52,984][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/345_3HCD_high/*.parquet
profiler: false
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: 300k_3HCD_192BS
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 192
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
train_subset: 1
valid_subset_of_train: 0.01
valid_subset: 1
val_check_interval: 1.0
lazy_loading: true
max_shard_size: 1000000
preshuffle_shards: false
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
resume_checkpoint: null
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-26 08:29:52,988][__main__][INFO] - Starting transformer training
[2025-08-26 08:29:52,988][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-26 08:29:52,988][__main__][INFO] - Loading data
[2025-08-26 08:29:57,228][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-26 08:30:01,517][__main__][INFO] - Validation path not specified, generating from training set.
[2025-08-26 08:30:18,426][__main__][INFO] - Data splits saved to /data/48/wuqian/fast/TipsNovo/model_save/splits.csv
[2025-08-26 08:30:18,426][__main__][INFO] - Checking for unknown residues in 319,144 rows.
[2025-08-26 08:30:38,417][__main__][INFO] - Data loaded: 315,873 training samples; 3,271 validation samples
[2025-08-26 08:30:38,607][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-26 08:30:38,634][__main__][INFO] - No data leakage!
[2025-08-26 08:30:38,634][__main__][INFO] - Model checkpointing every 1.22 epochs.
[2025-08-26 08:30:38,635][__main__][INFO] - Updates per epoch: 1,646, step_scale=0.16666666666666666
[2025-08-26 08:30:49,736][__main__][INFO] - Sample batch:
[2025-08-26 08:30:49,737][__main__][INFO] -  - spectra.shape=torch.Size([192, 200, 2])
[2025-08-26 08:30:49,737][__main__][INFO] -  - precursors.shape=torch.Size([192, 3])
[2025-08-26 08:30:49,737][__main__][INFO] -  - spectra_mask.shape=torch.Size([192, 200])
[2025-08-26 08:30:49,737][__main__][INFO] -  - peptides.shape=torch.Size([192, 41])
[2025-08-26 08:30:49,737][__main__][INFO] -  - peptides_mask.shape=torch.Size([192, 41])
[2025-08-26 08:30:49,863][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-26 08:30:49,864][__main__][INFO] - Test forward pass:
[2025-08-26 08:30:59,505][__main__][INFO] -  - y.shape=torch.Size([192, 42, 33])
[2025-08-26 08:31:01,015][__main__][INFO] - Model saving enabled
[2025-08-26 08:31:01,016][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save/
[2025-08-26 08:31:01,016][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-26 08:31:01,027][__main__][INFO] - InstaNovo training started.
[2025-08-26 08:32:22,337][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-26 08:32:33,186][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 000001] [Batch 00007/00013] [00:00:10/00:00:06, 1.356s/it]
[2025-08-26 08:32:41,606][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000008] [Batch 00008/00823] [00:00:05/00:09:07, 0.672s/it]: train_loss_raw=3.5024, running_loss=3.5992, LR=0.000001
[2025-08-26 08:32:47,636][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000016] [Batch 00016/00823] [00:00:11/00:09:35, 0.713s/it]: train_loss_raw=3.2118, running_loss=3.5785, LR=0.000003
[2025-08-26 08:32:53,665][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/00823] [00:00:17/00:09:40, 0.727s/it]: train_loss_raw=3.0657, running_loss=3.5425, LR=0.000005
[2025-08-26 08:32:59,489][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000032] [Batch 00032/00823] [00:00:23/00:09:34, 0.727s/it]: train_loss_raw=3.0246, running_loss=3.5032, LR=0.000006
[2025-08-26 08:33:05,543][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000040] [Batch 00040/00823] [00:00:29/00:09:33, 0.733s/it]: train_loss_raw=2.9580, running_loss=3.4626, LR=0.000008
[2025-08-26 08:33:11,534][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/00823] [00:00:35/00:09:30, 0.736s/it]: train_loss_raw=2.9532, running_loss=3.4236, LR=0.000010
[2025-08-26 08:33:17,568][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000056] [Batch 00056/00823] [00:00:41/00:09:26, 0.738s/it]: train_loss_raw=2.9058, running_loss=3.3855, LR=0.000011
[2025-08-26 08:33:23,623][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000064] [Batch 00064/00823] [00:00:47/00:09:22, 0.741s/it]: train_loss_raw=2.8389, running_loss=3.3455, LR=0.000013
[2025-08-26 08:33:29,726][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/00823] [00:00:53/00:09:18, 0.743s/it]: train_loss_raw=2.7726, running_loss=3.3030, LR=0.000015
[2025-08-26 08:33:35,623][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000080] [Batch 00080/00823] [00:00:59/00:09:11, 0.742s/it]: train_loss_raw=2.7264, running_loss=3.2607, LR=0.000016
[2025-08-26 08:33:41,249][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000088] [Batch 00088/00823] [00:01:05/00:09:03, 0.739s/it]: train_loss_raw=2.7626, running_loss=3.2224, LR=0.000018
[2025-08-26 08:33:47,242][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/00823] [00:01:11/00:08:57, 0.740s/it]: train_loss_raw=2.7380, running_loss=3.1852, LR=0.000020
[2025-08-26 08:33:53,277][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000104] [Batch 00104/00823] [00:01:17/00:08:52, 0.741s/it]: train_loss_raw=2.7587, running_loss=3.1508, LR=0.000021
[2025-08-26 08:33:59,370][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000112] [Batch 00112/00823] [00:01:23/00:08:47, 0.742s/it]: train_loss_raw=2.7203, running_loss=3.1180, LR=0.000023
[2025-08-26 08:34:05,005][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/00823] [00:01:28/00:08:40, 0.740s/it]: train_loss_raw=2.7409, running_loss=3.0874, LR=0.000025
[2025-08-26 08:34:10,727][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000128] [Batch 00128/00823] [00:01:34/00:08:33, 0.738s/it]: train_loss_raw=2.6986, running_loss=3.0585, LR=0.000026
[2025-08-26 08:34:16,688][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000136] [Batch 00136/00823] [00:01:40/00:08:27, 0.739s/it]: train_loss_raw=2.7167, running_loss=3.0315, LR=0.000028
[2025-08-26 08:34:22,554][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/00823] [00:01:46/00:08:21, 0.738s/it]: train_loss_raw=2.7074, running_loss=3.0065, LR=0.000030
[2025-08-26 08:34:28,622][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000152] [Batch 00152/00823] [00:01:52/00:08:16, 0.739s/it]: train_loss_raw=2.7155, running_loss=2.9827, LR=0.000031
[2025-08-26 08:34:34,602][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000160] [Batch 00160/00823] [00:01:58/00:08:10, 0.740s/it]: train_loss_raw=2.6985, running_loss=2.9611, LR=0.000033
[2025-08-26 08:34:40,414][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/00823] [00:02:04/00:08:04, 0.739s/it]: train_loss_raw=2.7054, running_loss=2.9410, LR=0.000035
[2025-08-26 08:34:46,323][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000176] [Batch 00176/00823] [00:02:10/00:07:58, 0.739s/it]: train_loss_raw=2.7094, running_loss=2.9219, LR=0.000036
[2025-08-26 08:34:52,263][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000184] [Batch 00184/00823] [00:02:16/00:07:52, 0.739s/it]: train_loss_raw=2.6556, running_loss=2.9038, LR=0.000038
[2025-08-26 08:34:58,127][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/00823] [00:02:21/00:07:46, 0.739s/it]: train_loss_raw=2.7168, running_loss=2.8882, LR=0.000040
[2025-08-26 08:35:04,291][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000200] [Batch 00200/00823] [00:02:28/00:07:41, 0.740s/it]: train_loss_raw=2.7033, running_loss=2.8739, LR=0.000041
[2025-08-26 08:35:10,284][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000208] [Batch 00208/00823] [00:02:34/00:07:35, 0.741s/it]: train_loss_raw=2.6950, running_loss=2.8600, LR=0.000043
[2025-08-26 08:35:16,201][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/00823] [00:02:39/00:07:29, 0.741s/it]: train_loss_raw=2.6775, running_loss=2.8463, LR=0.000045
[2025-08-26 08:35:22,031][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000224] [Batch 00224/00823] [00:02:45/00:07:23, 0.740s/it]: train_loss_raw=2.6755, running_loss=2.8336, LR=0.000046
[2025-08-26 08:35:27,844][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000232] [Batch 00232/00823] [00:02:51/00:07:17, 0.740s/it]: train_loss_raw=2.6728, running_loss=2.8221, LR=0.000048
[2025-08-26 08:35:33,796][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/00823] [00:02:57/00:07:11, 0.740s/it]: train_loss_raw=2.6688, running_loss=2.8114, LR=0.000050
[2025-08-26 08:35:39,282][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000248] [Batch 00248/00823] [00:03:03/00:07:04, 0.738s/it]: train_loss_raw=2.6857, running_loss=2.8016, LR=0.000051
[2025-08-26 08:35:45,328][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000256] [Batch 00256/00823] [00:03:09/00:06:58, 0.739s/it]: train_loss_raw=2.6590, running_loss=2.7927, LR=0.000053
[2025-08-26 08:35:51,052][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/00823] [00:03:14/00:06:52, 0.738s/it]: train_loss_raw=2.6856, running_loss=2.7836, LR=0.000055
[2025-08-26 08:35:56,663][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000272] [Batch 00272/00823] [00:03:20/00:06:46, 0.737s/it]: train_loss_raw=2.6786, running_loss=2.7759, LR=0.000056
[2025-08-26 08:36:02,901][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000280] [Batch 00280/00823] [00:03:26/00:06:40, 0.738s/it]: train_loss_raw=2.6828, running_loss=2.7681, LR=0.000058
[2025-08-26 08:36:09,220][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/00823] [00:03:32/00:06:35, 0.740s/it]: train_loss_raw=2.6561, running_loss=2.7604, LR=0.000060
[2025-08-26 08:36:15,073][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000296] [Batch 00296/00823] [00:03:38/00:06:29, 0.739s/it]: train_loss_raw=2.6533, running_loss=2.7535, LR=0.000061
[2025-08-26 08:36:20,870][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000304] [Batch 00304/00823] [00:03:44/00:06:23, 0.739s/it]: train_loss_raw=2.6432, running_loss=2.7453, LR=0.000063
[2025-08-26 08:36:26,833][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/00823] [00:03:50/00:06:17, 0.739s/it]: train_loss_raw=2.6482, running_loss=2.7381, LR=0.000065
[2025-08-26 08:36:32,829][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000320] [Batch 00320/00823] [00:03:56/00:06:11, 0.739s/it]: train_loss_raw=2.6191, running_loss=2.7303, LR=0.000066
[2025-08-26 08:36:38,540][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000328] [Batch 00328/00823] [00:04:02/00:06:05, 0.739s/it]: train_loss_raw=2.6434, running_loss=2.7226, LR=0.000068
[2025-08-26 08:36:44,662][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/00823] [00:04:08/00:06:00, 0.739s/it]: train_loss_raw=2.5920, running_loss=2.7147, LR=0.000070
[2025-08-26 08:36:50,611][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000344] [Batch 00344/00823] [00:04:14/00:05:54, 0.739s/it]: train_loss_raw=2.5984, running_loss=2.7069, LR=0.000071
[2025-08-26 08:36:56,641][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000352] [Batch 00352/00823] [00:04:20/00:05:48, 0.740s/it]: train_loss_raw=2.5904, running_loss=2.6997, LR=0.000073
[2025-08-26 08:37:02,190][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/00823] [00:04:25/00:05:42, 0.739s/it]: train_loss_raw=2.6023, running_loss=2.6919, LR=0.000075
[2025-08-26 08:37:08,194][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000368] [Batch 00368/00823] [00:04:31/00:05:36, 0.739s/it]: train_loss_raw=2.5572, running_loss=2.6829, LR=0.000076
[2025-08-26 08:37:14,274][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000376] [Batch 00376/00823] [00:04:38/00:05:30, 0.739s/it]: train_loss_raw=2.6195, running_loss=2.6758, LR=0.000078
[2025-08-26 08:37:20,177][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/00823] [00:04:43/00:05:24, 0.739s/it]: train_loss_raw=2.5787, running_loss=2.6688, LR=0.000080
[2025-08-26 08:37:26,177][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000392] [Batch 00392/00823] [00:04:49/00:05:18, 0.740s/it]: train_loss_raw=2.5714, running_loss=2.6622, LR=0.000081
[2025-08-26 08:37:31,880][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000400] [Batch 00400/00823] [00:04:55/00:05:12, 0.739s/it]: train_loss_raw=2.5862, running_loss=2.6560, LR=0.000083
[2025-08-26 08:37:38,032][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/00823] [00:05:01/00:05:06, 0.740s/it]: train_loss_raw=2.5717, running_loss=2.6502, LR=0.000085
[2025-08-26 08:37:44,188][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000416] [Batch 00416/00823] [00:05:07/00:05:01, 0.740s/it]: train_loss_raw=2.5419, running_loss=2.6436, LR=0.000086
[2025-08-26 08:37:49,913][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000424] [Batch 00424/00823] [00:05:13/00:04:55, 0.740s/it]: train_loss_raw=2.5329, running_loss=2.6362, LR=0.000088
[2025-08-26 08:37:55,772][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/00823] [00:05:19/00:04:49, 0.740s/it]: train_loss_raw=2.5502, running_loss=2.6300, LR=0.000090
[2025-08-26 08:38:01,835][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000440] [Batch 00440/00823] [00:05:25/00:04:43, 0.740s/it]: train_loss_raw=2.5778, running_loss=2.6247, LR=0.000091
[2025-08-26 08:38:07,868][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000448] [Batch 00448/00823] [00:05:31/00:04:37, 0.740s/it]: train_loss_raw=2.5291, running_loss=2.6189, LR=0.000093
[2025-08-26 08:38:13,648][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/00823] [00:05:37/00:04:31, 0.740s/it]: train_loss_raw=2.5639, running_loss=2.6125, LR=0.000095
[2025-08-26 08:38:19,617][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000464] [Batch 00464/00823] [00:05:43/00:04:25, 0.740s/it]: train_loss_raw=2.5476, running_loss=2.6069, LR=0.000096
[2025-08-26 08:38:25,416][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000472] [Batch 00472/00823] [00:05:49/00:04:19, 0.740s/it]: train_loss_raw=2.5119, running_loss=2.6019, LR=0.000098
[2025-08-26 08:38:30,899][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/00823] [00:05:54/00:04:13, 0.739s/it]: train_loss_raw=2.5240, running_loss=2.5958, LR=0.000100
[2025-08-26 08:38:36,356][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000488] [Batch 00488/00823] [00:06:00/00:04:07, 0.738s/it]: train_loss_raw=2.5150, running_loss=2.5898, LR=0.000100
[2025-08-26 08:38:41,770][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000496] [Batch 00496/00823] [00:06:05/00:04:00, 0.737s/it]: train_loss_raw=2.5049, running_loss=2.5841, LR=0.000100
[2025-08-26 08:38:47,518][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/00823] [00:06:11/00:03:55, 0.737s/it]: train_loss_raw=2.5102, running_loss=2.5778, LR=0.000100
[2025-08-26 08:38:53,739][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000512] [Batch 00512/00823] [00:06:17/00:03:49, 0.737s/it]: train_loss_raw=2.5432, running_loss=2.5722, LR=0.000100
[2025-08-26 08:38:59,546][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000520] [Batch 00520/00823] [00:06:23/00:03:43, 0.737s/it]: train_loss_raw=2.4923, running_loss=2.5664, LR=0.000100
[2025-08-26 08:39:05,524][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/00823] [00:06:29/00:03:37, 0.737s/it]: train_loss_raw=2.4541, running_loss=2.5601, LR=0.000100
[2025-08-26 08:39:11,556][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000536] [Batch 00536/00823] [00:06:35/00:03:31, 0.738s/it]: train_loss_raw=2.4606, running_loss=2.5551, LR=0.000100
[2025-08-26 08:39:17,647][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000544] [Batch 00544/00823] [00:06:41/00:03:25, 0.738s/it]: train_loss_raw=2.4877, running_loss=2.5501, LR=0.000100
[2025-08-26 08:39:23,498][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/00823] [00:06:47/00:03:19, 0.738s/it]: train_loss_raw=2.4776, running_loss=2.5437, LR=0.000100
[2025-08-26 08:39:29,228][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000560] [Batch 00560/00823] [00:06:53/00:03:13, 0.738s/it]: train_loss_raw=2.5018, running_loss=2.5387, LR=0.000100
[2025-08-26 08:39:34,889][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000568] [Batch 00568/00823] [00:06:58/00:03:07, 0.737s/it]: train_loss_raw=2.4442, running_loss=2.5324, LR=0.000100
[2025-08-26 08:39:40,235][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/00823] [00:07:04/00:03:01, 0.736s/it]: train_loss_raw=2.4319, running_loss=2.5265, LR=0.000100
[2025-08-26 08:39:46,058][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000584] [Batch 00584/00823] [00:07:09/00:02:55, 0.736s/it]: train_loss_raw=2.4520, running_loss=2.5206, LR=0.000100
[2025-08-26 08:39:51,870][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000592] [Batch 00592/00823] [00:07:15/00:02:49, 0.736s/it]: train_loss_raw=2.4260, running_loss=2.5151, LR=0.000100
[2025-08-26 08:39:57,525][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/00823] [00:07:21/00:02:44, 0.735s/it]: train_loss_raw=2.4773, running_loss=2.5098, LR=0.000100
[2025-08-26 08:40:03,645][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000608] [Batch 00608/00823] [00:07:27/00:02:38, 0.736s/it]: train_loss_raw=2.4602, running_loss=2.5043, LR=0.000100
[2025-08-26 08:40:09,360][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000616] [Batch 00616/00823] [00:07:33/00:02:32, 0.736s/it]: train_loss_raw=2.3838, running_loss=2.4988, LR=0.000100
[2025-08-26 08:40:14,975][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/00823] [00:07:38/00:02:26, 0.735s/it]: train_loss_raw=2.4389, running_loss=2.4935, LR=0.000100
[2025-08-26 08:40:20,935][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000632] [Batch 00632/00823] [00:07:44/00:02:20, 0.735s/it]: train_loss_raw=2.3917, running_loss=2.4885, LR=0.000100
[2025-08-26 08:40:26,616][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000640] [Batch 00640/00823] [00:07:50/00:02:14, 0.735s/it]: train_loss_raw=2.4168, running_loss=2.4842, LR=0.000100
[2025-08-26 08:40:32,293][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/00823] [00:07:56/00:02:08, 0.735s/it]: train_loss_raw=2.3427, running_loss=2.4786, LR=0.000100
[2025-08-26 08:40:37,916][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000656] [Batch 00656/00823] [00:08:01/00:02:02, 0.734s/it]: train_loss_raw=2.4195, running_loss=2.4729, LR=0.000100
[2025-08-26 08:40:43,287][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000664] [Batch 00664/00823] [00:08:07/00:01:56, 0.734s/it]: train_loss_raw=2.3880, running_loss=2.4672, LR=0.000100
[2025-08-26 08:40:48,709][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/00823] [00:08:12/00:01:50, 0.733s/it]: train_loss_raw=2.4164, running_loss=2.4627, LR=0.000100
[2025-08-26 08:40:54,101][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000680] [Batch 00680/00823] [00:08:17/00:01:44, 0.732s/it]: train_loss_raw=2.4242, running_loss=2.4583, LR=0.000100
[2025-08-26 08:40:59,537][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000688] [Batch 00688/00823] [00:08:23/00:01:38, 0.732s/it]: train_loss_raw=2.3193, running_loss=2.4521, LR=0.000100
[2025-08-26 08:41:05,266][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/00823] [00:08:29/00:01:32, 0.731s/it]: train_loss_raw=2.3784, running_loss=2.4485, LR=0.000100
[2025-08-26 08:41:10,808][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000704] [Batch 00704/00823] [00:08:34/00:01:26, 0.731s/it]: train_loss_raw=2.3396, running_loss=2.4423, LR=0.000100
[2025-08-26 08:41:16,792][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000712] [Batch 00712/00823] [00:08:40/00:01:21, 0.731s/it]: train_loss_raw=2.3986, running_loss=2.4384, LR=0.000100
[2025-08-26 08:41:22,334][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/00823] [00:08:46/00:01:15, 0.731s/it]: train_loss_raw=2.3352, running_loss=2.4344, LR=0.000100
[2025-08-26 08:41:28,181][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000728] [Batch 00728/00823] [00:08:51/00:01:09, 0.731s/it]: train_loss_raw=2.3725, running_loss=2.4306, LR=0.000100
[2025-08-26 08:41:33,849][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000736] [Batch 00736/00823] [00:08:57/00:01:03, 0.730s/it]: train_loss_raw=2.3329, running_loss=2.4257, LR=0.000100
[2025-08-26 08:41:39,700][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/00823] [00:09:03/00:00:57, 0.730s/it]: train_loss_raw=2.3546, running_loss=2.4204, LR=0.000100
[2025-08-26 08:41:45,506][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000752] [Batch 00752/00823] [00:09:09/00:00:51, 0.730s/it]: train_loss_raw=2.3285, running_loss=2.4148, LR=0.000100
[2025-08-26 08:41:51,423][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000760] [Batch 00760/00823] [00:09:15/00:00:46, 0.731s/it]: train_loss_raw=2.3258, running_loss=2.4101, LR=0.000100
[2025-08-26 08:41:57,252][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/00823] [00:09:21/00:00:40, 0.731s/it]: train_loss_raw=2.3084, running_loss=2.4063, LR=0.000100
[2025-08-26 08:42:03,378][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000776] [Batch 00776/00823] [00:09:27/00:00:34, 0.731s/it]: train_loss_raw=2.3956, running_loss=2.4027, LR=0.000100
[2025-08-26 08:42:09,377][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000784] [Batch 00784/00823] [00:09:33/00:00:28, 0.731s/it]: train_loss_raw=2.3319, running_loss=2.3974, LR=0.000100
[2025-08-26 08:42:15,435][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/00823] [00:09:39/00:00:22, 0.731s/it]: train_loss_raw=2.3869, running_loss=2.3945, LR=0.000100
[2025-08-26 08:42:21,488][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000800] [Batch 00800/00823] [00:09:45/00:00:16, 0.732s/it]: train_loss_raw=2.3434, running_loss=2.3917, LR=0.000100
[2025-08-26 08:42:27,504][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000808] [Batch 00808/00823] [00:09:51/00:00:10, 0.732s/it]: train_loss_raw=2.3556, running_loss=2.3870, LR=0.000100
[2025-08-26 08:42:33,596][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/00823] [00:09:57/00:00:05, 0.732s/it]: train_loss_raw=2.3708, running_loss=2.3836, LR=0.000100
[2025-08-26 08:42:39,042][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-26 08:42:47,659][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 000824] [Batch 00002/00013] [00:00:08/00:00:28, 2.872s/it]
[2025-08-26 08:42:58,020][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=2.37883, valid_loss=2.37566
[2025-08-26 08:42:58,021][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-26 08:42:58,021][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.873
[2025-08-26 08:42:58,021][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.018
[2025-08-26 08:42:58,021][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.019
[2025-08-26 08:42:58,021][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.000
[2025-08-26 08:42:58,024][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:10:21, remaining time 05:00:32, 00:10:21 per epoch
[2025-08-26 08:42:58,472][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000824] [Batch 00001/00823] [00:00:00/00:02:01, 0.147s/it]: train_loss_raw=2.2929, running_loss=2.2929, LR=0.000100
[2025-08-26 08:43:04,621][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000832] [Batch 00009/00823] [00:00:06/00:09:29, 0.700s/it]: train_loss_raw=2.3424, running_loss=2.2956, LR=0.000100
[2025-08-26 08:43:10,614][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000840] [Batch 00017/00823] [00:00:12/00:09:42, 0.723s/it]: train_loss_raw=2.4212, running_loss=2.2996, LR=0.000100
[2025-08-26 08:43:16,339][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000848] [Batch 00025/00823] [00:00:18/00:09:35, 0.721s/it]: train_loss_raw=2.3183, running_loss=2.3016, LR=0.000100
[2025-08-26 08:43:22,175][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000856] [Batch 00033/00823] [00:00:23/00:09:30, 0.723s/it]: train_loss_raw=2.4074, running_loss=2.3053, LR=0.000100
[2025-08-26 08:43:27,841][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000864] [Batch 00041/00823] [00:00:29/00:09:22, 0.720s/it]: train_loss_raw=2.2590, running_loss=2.3041, LR=0.000100
[2025-08-26 08:43:33,553][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000872] [Batch 00049/00823] [00:00:35/00:09:16, 0.719s/it]: train_loss_raw=2.3397, running_loss=2.3057, LR=0.000100
[2025-08-26 08:43:39,383][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000880] [Batch 00057/00823] [00:00:41/00:09:11, 0.720s/it]: train_loss_raw=2.3000, running_loss=2.3065, LR=0.000100
[2025-08-26 08:43:44,821][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000888] [Batch 00065/00823] [00:00:46/00:09:02, 0.715s/it]: train_loss_raw=2.3536, running_loss=2.3067, LR=0.000100
[2025-08-26 08:43:50,179][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000896] [Batch 00073/00823] [00:00:51/00:08:52, 0.710s/it]: train_loss_raw=2.3493, running_loss=2.3086, LR=0.000100
[2025-08-26 08:43:56,015][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000904] [Batch 00081/00823] [00:00:57/00:08:48, 0.712s/it]: train_loss_raw=2.3201, running_loss=2.3085, LR=0.000100
[2025-08-26 08:44:01,418][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000912] [Batch 00089/00823] [00:01:03/00:08:40, 0.709s/it]: train_loss_raw=2.3337, running_loss=2.3103, LR=0.000100
[2025-08-26 08:44:06,822][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000920] [Batch 00097/00823] [00:01:08/00:08:32, 0.706s/it]: train_loss_raw=2.2767, running_loss=2.3104, LR=0.000100
[2025-08-26 08:44:12,561][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000928] [Batch 00105/00823] [00:01:14/00:08:27, 0.707s/it]: train_loss_raw=2.3003, running_loss=2.3093, LR=0.000100
[2025-08-26 08:44:18,023][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000936] [Batch 00113/00823] [00:01:19/00:08:20, 0.705s/it]: train_loss_raw=2.2408, running_loss=2.3085, LR=0.000100
[2025-08-26 08:44:23,678][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000944] [Batch 00121/00823] [00:01:25/00:08:15, 0.705s/it]: train_loss_raw=2.2085, running_loss=2.3057, LR=0.000100
[2025-08-26 08:44:29,717][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000952] [Batch 00129/00823] [00:01:31/00:08:11, 0.708s/it]: train_loss_raw=2.3120, running_loss=2.3049, LR=0.000100
[2025-08-26 08:44:35,628][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000960] [Batch 00137/00823] [00:01:37/00:08:07, 0.710s/it]: train_loss_raw=2.3108, running_loss=2.3031, LR=0.000100
[2025-08-26 08:44:41,602][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000968] [Batch 00145/00823] [00:01:43/00:08:02, 0.712s/it]: train_loss_raw=2.2594, running_loss=2.3013, LR=0.000100
[2025-08-26 08:44:47,339][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000976] [Batch 00153/00823] [00:01:49/00:07:57, 0.713s/it]: train_loss_raw=2.3319, running_loss=2.3024, LR=0.000100
[2025-08-26 08:44:53,218][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000984] [Batch 00161/00823] [00:01:54/00:07:52, 0.714s/it]: train_loss_raw=2.3440, running_loss=2.3025, LR=0.000100
[2025-08-26 08:44:58,891][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000992] [Batch 00169/00823] [00:02:00/00:07:46, 0.713s/it]: train_loss_raw=2.2726, running_loss=2.3008, LR=0.000100
[2025-08-26 08:45:04,787][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001000] [Batch 00177/00823] [00:02:06/00:07:41, 0.714s/it]: train_loss_raw=2.3267, running_loss=2.2991, LR=0.000100
[2025-08-26 08:45:10,619][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001008] [Batch 00185/00823] [00:02:12/00:07:36, 0.715s/it]: train_loss_raw=2.2429, running_loss=2.2972, LR=0.000100
[2025-08-26 08:45:16,421][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001016] [Batch 00193/00823] [00:02:18/00:07:30, 0.716s/it]: train_loss_raw=2.2597, running_loss=2.2941, LR=0.000100
[2025-08-26 08:45:22,056][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001024] [Batch 00201/00823] [00:02:23/00:07:24, 0.715s/it]: train_loss_raw=2.2871, running_loss=2.2933, LR=0.000100
[2025-08-26 08:45:27,458][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001032] [Batch 00209/00823] [00:02:29/00:07:18, 0.714s/it]: train_loss_raw=2.3019, running_loss=2.2917, LR=0.000100
[2025-08-26 08:45:33,566][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001040] [Batch 00217/00823] [00:02:35/00:07:13, 0.715s/it]: train_loss_raw=2.2695, running_loss=2.2900, LR=0.000100
[2025-08-26 08:45:39,348][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001048] [Batch 00225/00823] [00:02:41/00:07:07, 0.716s/it]: train_loss_raw=2.2731, running_loss=2.2895, LR=0.000100
[2025-08-26 08:45:44,903][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001056] [Batch 00233/00823] [00:02:46/00:07:01, 0.715s/it]: train_loss_raw=2.3293, running_loss=2.2879, LR=0.000100
[2025-08-26 08:45:50,812][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001064] [Batch 00241/00823] [00:02:52/00:06:56, 0.716s/it]: train_loss_raw=2.2097, running_loss=2.2860, LR=0.000100
[2025-08-26 08:45:56,297][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001072] [Batch 00249/00823] [00:02:57/00:06:50, 0.715s/it]: train_loss_raw=2.2648, running_loss=2.2838, LR=0.000100
[2025-08-26 08:46:02,247][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001080] [Batch 00257/00823] [00:03:03/00:06:45, 0.716s/it]: train_loss_raw=2.2554, running_loss=2.2830, LR=0.000100
[2025-08-26 08:46:08,332][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001088] [Batch 00265/00823] [00:03:10/00:06:40, 0.717s/it]: train_loss_raw=2.1254, running_loss=2.2802, LR=0.000100
[2025-08-26 08:46:14,343][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001096] [Batch 00273/00823] [00:03:16/00:06:34, 0.718s/it]: train_loss_raw=2.2944, running_loss=2.2794, LR=0.000100
[2025-08-26 08:46:19,906][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001104] [Batch 00281/00823] [00:03:21/00:06:28, 0.717s/it]: train_loss_raw=2.2140, running_loss=2.2749, LR=0.000100
[2025-08-26 08:46:25,942][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001112] [Batch 00289/00823] [00:03:27/00:06:23, 0.718s/it]: train_loss_raw=2.2488, running_loss=2.2735, LR=0.000100
[2025-08-26 08:46:31,709][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001120] [Batch 00297/00823] [00:03:33/00:06:17, 0.718s/it]: train_loss_raw=2.2551, running_loss=2.2722, LR=0.000100
[2025-08-26 08:46:37,142][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001128] [Batch 00305/00823] [00:03:38/00:06:11, 0.717s/it]: train_loss_raw=2.2554, running_loss=2.2702, LR=0.000100
[2025-08-26 08:46:42,908][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001136] [Batch 00313/00823] [00:03:44/00:06:05, 0.718s/it]: train_loss_raw=2.2190, running_loss=2.2696, LR=0.000100
[2025-08-26 08:46:48,490][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001144] [Batch 00321/00823] [00:03:50/00:05:59, 0.717s/it]: train_loss_raw=2.1882, running_loss=2.2675, LR=0.000100
[2025-08-26 08:46:54,135][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001152] [Batch 00329/00823] [00:03:55/00:05:54, 0.717s/it]: train_loss_raw=2.2394, running_loss=2.2660, LR=0.000100
[2025-08-26 08:46:59,805][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001160] [Batch 00337/00823] [00:04:01/00:05:48, 0.717s/it]: train_loss_raw=2.2626, running_loss=2.2652, LR=0.000100
[2025-08-26 08:47:05,761][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001168] [Batch 00345/00823] [00:04:07/00:05:42, 0.717s/it]: train_loss_raw=2.3204, running_loss=2.2620, LR=0.000100
[2025-08-26 08:47:11,503][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001176] [Batch 00353/00823] [00:04:13/00:05:37, 0.717s/it]: train_loss_raw=2.2653, running_loss=2.2595, LR=0.000100
[2025-08-26 08:47:17,357][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001184] [Batch 00361/00823] [00:04:19/00:05:31, 0.718s/it]: train_loss_raw=2.2228, running_loss=2.2567, LR=0.000100
[2025-08-26 08:47:23,283][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001192] [Batch 00369/00823] [00:04:24/00:05:25, 0.718s/it]: train_loss_raw=2.2143, running_loss=2.2551, LR=0.000100
[2025-08-26 08:47:29,171][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001200] [Batch 00377/00823] [00:04:30/00:05:20, 0.718s/it]: train_loss_raw=2.2324, running_loss=2.2522, LR=0.000100
[2025-08-26 08:47:34,874][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001208] [Batch 00385/00823] [00:04:36/00:05:14, 0.718s/it]: train_loss_raw=2.1997, running_loss=2.2489, LR=0.000100
[2025-08-26 08:47:40,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001216] [Batch 00393/00823] [00:04:41/00:05:08, 0.717s/it]: train_loss_raw=2.1795, running_loss=2.2447, LR=0.000100
[2025-08-26 08:47:45,679][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001224] [Batch 00401/00823] [00:04:47/00:05:02, 0.717s/it]: train_loss_raw=2.2382, running_loss=2.2421, LR=0.000100
[2025-08-26 08:47:51,745][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001232] [Batch 00409/00823] [00:04:53/00:04:57, 0.717s/it]: train_loss_raw=2.1572, running_loss=2.2394, LR=0.000100
[2025-08-26 08:47:57,729][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001240] [Batch 00417/00823] [00:04:59/00:04:51, 0.718s/it]: train_loss_raw=2.2745, running_loss=2.2365, LR=0.000100
[2025-08-26 08:48:03,615][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001248] [Batch 00425/00823] [00:05:05/00:04:45, 0.718s/it]: train_loss_raw=2.2467, running_loss=2.2348, LR=0.000100
[2025-08-26 08:48:09,542][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001256] [Batch 00433/00823] [00:05:11/00:04:40, 0.719s/it]: train_loss_raw=2.2252, running_loss=2.2323, LR=0.000100
[2025-08-26 08:48:15,453][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001264] [Batch 00441/00823] [00:05:17/00:04:34, 0.719s/it]: train_loss_raw=2.2827, running_loss=2.2297, LR=0.000100
[2025-08-26 08:48:21,180][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001272] [Batch 00449/00823] [00:05:22/00:04:28, 0.719s/it]: train_loss_raw=2.1737, running_loss=2.2271, LR=0.000100
[2025-08-26 08:48:26,780][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001280] [Batch 00457/00823] [00:05:28/00:04:23, 0.719s/it]: train_loss_raw=2.2295, running_loss=2.2251, LR=0.000100
[2025-08-26 08:48:32,711][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001288] [Batch 00465/00823] [00:05:34/00:04:17, 0.719s/it]: train_loss_raw=2.2006, running_loss=2.2219, LR=0.000100
[2025-08-26 08:48:38,756][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001296] [Batch 00473/00823] [00:05:40/00:04:11, 0.720s/it]: train_loss_raw=2.2471, running_loss=2.2213, LR=0.000100
[2025-08-26 08:48:44,786][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001304] [Batch 00481/00823] [00:05:46/00:04:06, 0.720s/it]: train_loss_raw=2.2517, running_loss=2.2197, LR=0.000100
[2025-08-26 08:48:50,415][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001312] [Batch 00489/00823] [00:05:52/00:04:00, 0.720s/it]: train_loss_raw=2.2489, running_loss=2.2158, LR=0.000100
[2025-08-26 08:48:56,283][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001320] [Batch 00497/00823] [00:05:57/00:03:54, 0.720s/it]: train_loss_raw=2.1693, running_loss=2.2124, LR=0.000100
[2025-08-26 08:49:01,876][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001328] [Batch 00505/00823] [00:06:03/00:03:48, 0.720s/it]: train_loss_raw=2.1924, running_loss=2.2115, LR=0.000100
[2025-08-26 08:49:07,847][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001336] [Batch 00513/00823] [00:06:09/00:03:43, 0.720s/it]: train_loss_raw=2.2717, running_loss=2.2118, LR=0.000100
[2025-08-26 08:49:13,529][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001344] [Batch 00521/00823] [00:06:15/00:03:37, 0.720s/it]: train_loss_raw=2.1650, running_loss=2.2091, LR=0.000100
[2025-08-26 08:49:19,531][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001352] [Batch 00529/00823] [00:06:21/00:03:31, 0.721s/it]: train_loss_raw=2.1773, running_loss=2.2066, LR=0.000100
[2025-08-26 08:49:25,471][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001360] [Batch 00537/00823] [00:06:27/00:03:26, 0.721s/it]: train_loss_raw=2.1891, running_loss=2.2034, LR=0.000100
[2025-08-26 08:49:31,154][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001368] [Batch 00545/00823] [00:06:32/00:03:20, 0.721s/it]: train_loss_raw=2.0927, running_loss=2.2006, LR=0.000100
[2025-08-26 08:49:37,197][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001376] [Batch 00553/00823] [00:06:38/00:03:14, 0.721s/it]: train_loss_raw=2.1980, running_loss=2.2022, LR=0.000100
[2025-08-26 08:49:43,239][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001384] [Batch 00561/00823] [00:06:44/00:03:09, 0.722s/it]: train_loss_raw=2.1603, running_loss=2.1998, LR=0.000100
[2025-08-26 08:49:49,385][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001392] [Batch 00569/00823] [00:06:51/00:03:03, 0.722s/it]: train_loss_raw=2.0992, running_loss=2.1972, LR=0.000100
[2025-08-26 08:49:55,365][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001400] [Batch 00577/00823] [00:06:57/00:02:57, 0.723s/it]: train_loss_raw=2.1551, running_loss=2.1962, LR=0.000100
[2025-08-26 08:50:01,409][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001408] [Batch 00585/00823] [00:07:03/00:02:52, 0.723s/it]: train_loss_raw=2.0391, running_loss=2.1925, LR=0.000100
[2025-08-26 08:50:07,275][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001416] [Batch 00593/00823] [00:07:08/00:02:46, 0.723s/it]: train_loss_raw=2.1771, running_loss=2.1901, LR=0.000100
[2025-08-26 08:50:12,725][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001424] [Batch 00601/00823] [00:07:14/00:02:40, 0.723s/it]: train_loss_raw=2.1371, running_loss=2.1892, LR=0.000100
[2025-08-26 08:50:18,663][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001432] [Batch 00609/00823] [00:07:20/00:02:34, 0.723s/it]: train_loss_raw=2.2093, running_loss=2.1859, LR=0.000100
[2025-08-26 08:50:24,684][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001440] [Batch 00617/00823] [00:07:26/00:02:29, 0.723s/it]: train_loss_raw=2.1056, running_loss=2.1843, LR=0.000100
[2025-08-26 08:50:30,698][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001448] [Batch 00625/00823] [00:07:32/00:02:23, 0.724s/it]: train_loss_raw=2.1873, running_loss=2.1808, LR=0.000100
[2025-08-26 08:50:36,768][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001456] [Batch 00633/00823] [00:07:38/00:02:17, 0.724s/it]: train_loss_raw=2.1325, running_loss=2.1811, LR=0.000100
[2025-08-26 08:50:42,570][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001464] [Batch 00641/00823] [00:07:44/00:02:11, 0.724s/it]: train_loss_raw=2.2151, running_loss=2.1813, LR=0.000100
[2025-08-26 08:50:48,250][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001472] [Batch 00649/00823] [00:07:49/00:02:05, 0.724s/it]: train_loss_raw=2.2136, running_loss=2.1797, LR=0.000100
[2025-08-26 08:50:54,171][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001480] [Batch 00657/00823] [00:07:55/00:02:00, 0.724s/it]: train_loss_raw=2.1479, running_loss=2.1788, LR=0.000100
[2025-08-26 08:51:00,173][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001488] [Batch 00665/00823] [00:08:01/00:01:54, 0.725s/it]: train_loss_raw=2.0950, running_loss=2.1758, LR=0.000100
[2025-08-26 08:51:06,233][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001496] [Batch 00673/00823] [00:08:07/00:01:48, 0.725s/it]: train_loss_raw=2.1361, running_loss=2.1740, LR=0.000100
[2025-08-26 08:51:12,311][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001504] [Batch 00681/00823] [00:08:13/00:01:43, 0.725s/it]: train_loss_raw=2.2127, running_loss=2.1718, LR=0.000100
[2025-08-26 08:51:18,353][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001512] [Batch 00689/00823] [00:08:20/00:01:37, 0.726s/it]: train_loss_raw=2.1011, running_loss=2.1691, LR=0.000100
[2025-08-26 08:51:24,367][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001520] [Batch 00697/00823] [00:08:26/00:01:31, 0.726s/it]: train_loss_raw=2.1164, running_loss=2.1676, LR=0.000100
[2025-08-26 08:51:30,360][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001528] [Batch 00705/00823] [00:08:32/00:01:25, 0.726s/it]: train_loss_raw=2.0528, running_loss=2.1631, LR=0.000100
[2025-08-26 08:51:36,444][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001536] [Batch 00713/00823] [00:08:38/00:01:19, 0.727s/it]: train_loss_raw=2.2136, running_loss=2.1631, LR=0.000100
[2025-08-26 08:51:42,455][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001544] [Batch 00721/00823] [00:08:44/00:01:14, 0.727s/it]: train_loss_raw=2.1394, running_loss=2.1607, LR=0.000100
[2025-08-26 08:51:48,469][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001552] [Batch 00729/00823] [00:08:50/00:01:08, 0.727s/it]: train_loss_raw=2.2173, running_loss=2.1597, LR=0.000100
[2025-08-26 08:51:54,332][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001560] [Batch 00737/00823] [00:08:56/00:01:02, 0.727s/it]: train_loss_raw=2.1410, running_loss=2.1567, LR=0.000100
[2025-08-26 08:52:00,327][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001568] [Batch 00745/00823] [00:09:02/00:00:56, 0.728s/it]: train_loss_raw=1.9850, running_loss=2.1538, LR=0.000100
[2025-08-26 08:52:06,398][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001576] [Batch 00753/00823] [00:09:08/00:00:50, 0.728s/it]: train_loss_raw=2.0804, running_loss=2.1502, LR=0.000100
[2025-08-26 08:52:12,531][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001584] [Batch 00761/00823] [00:09:14/00:00:45, 0.728s/it]: train_loss_raw=2.1626, running_loss=2.1497, LR=0.000100
[2025-08-26 08:52:18,502][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001592] [Batch 00769/00823] [00:09:20/00:00:39, 0.728s/it]: train_loss_raw=2.1217, running_loss=2.1496, LR=0.000100
[2025-08-26 08:52:24,519][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001600] [Batch 00777/00823] [00:09:26/00:00:33, 0.729s/it]: train_loss_raw=2.0961, running_loss=2.1462, LR=0.000100
[2025-08-26 08:52:30,198][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001608] [Batch 00785/00823] [00:09:31/00:00:27, 0.729s/it]: train_loss_raw=2.1881, running_loss=2.1444, LR=0.000100
[2025-08-26 08:52:35,934][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001616] [Batch 00793/00823] [00:09:37/00:00:21, 0.728s/it]: train_loss_raw=2.0558, running_loss=2.1439, LR=0.000100
[2025-08-26 08:52:41,827][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001624] [Batch 00801/00823] [00:09:43/00:00:16, 0.728s/it]: train_loss_raw=2.1608, running_loss=2.1407, LR=0.000100
[2025-08-26 08:52:47,601][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001632] [Batch 00809/00823] [00:09:49/00:00:10, 0.728s/it]: train_loss_raw=2.1285, running_loss=2.1408, LR=0.000100
[2025-08-26 08:52:53,102][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001640] [Batch 00817/00823] [00:09:54/00:00:04, 0.728s/it]: train_loss_raw=2.2213, running_loss=2.1382, LR=0.000100
[2025-08-26 08:53:03,697][__main__][INFO] - [VALIDATION] [Epoch 01/29] Starting validation.
[2025-08-26 08:53:14,818][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 001647] [Batch 00007/00013] [00:00:11/00:00:06, 1.390s/it]
[2025-08-26 08:53:22,551][__main__][INFO] - [VALIDATION] [Epoch 01/29] train_loss=2.13647, valid_loss=2.15822
[2025-08-26 08:53:22,551][__main__][INFO] - [VALIDATION] [Epoch 01/29] Metrics:
[2025-08-26 08:53:22,551][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_er      0.807
[2025-08-26 08:53:22,551][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_prec    0.023
[2025-08-26 08:53:22,551][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_recall  0.023
[2025-08-26 08:53:22,552][__main__][INFO] - [VALIDATION] [Epoch 01/29] - pep_recall 0.000
[2025-08-26 08:53:22,553][__main__][INFO] - [TRAIN] [Epoch 01/29] Epoch complete, total time 00:20:46, remaining time 04:50:48, 00:10:23 per epoch
[2025-08-26 08:53:23,692][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001648] [Batch 00002/00823] [00:00:00/00:06:09, 0.450s/it]: train_loss_raw=2.1338, running_loss=2.1706, LR=0.000100
[2025-08-26 08:53:29,725][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001656] [Batch 00010/00823] [00:00:06/00:09:23, 0.693s/it]: train_loss_raw=2.1267, running_loss=2.1649, LR=0.000100
[2025-08-26 08:53:35,708][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001664] [Batch 00018/00823] [00:00:12/00:09:37, 0.718s/it]: train_loss_raw=2.1406, running_loss=2.1617, LR=0.000100
[2025-08-26 08:53:41,778][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001672] [Batch 00026/00823] [00:00:18/00:09:42, 0.730s/it]: train_loss_raw=2.1158, running_loss=2.1586, LR=0.000100
[2025-08-26 08:53:48,005][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001680] [Batch 00034/00823] [00:00:25/00:09:45, 0.742s/it]: train_loss_raw=2.1150, running_loss=2.1531, LR=0.000100
[2025-08-26 08:53:54,238][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001688] [Batch 00042/00823] [00:00:31/00:09:44, 0.749s/it]: train_loss_raw=2.1452, running_loss=2.1504, LR=0.000100
[2025-08-26 08:54:00,160][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001696] [Batch 00050/00823] [00:00:37/00:09:37, 0.747s/it]: train_loss_raw=2.1101, running_loss=2.1479, LR=0.000100
[2025-08-26 08:54:06,163][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001704] [Batch 00058/00823] [00:00:43/00:09:32, 0.748s/it]: train_loss_raw=2.1419, running_loss=2.1443, LR=0.000100
[2025-08-26 08:54:12,109][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001712] [Batch 00066/00823] [00:00:49/00:09:25, 0.747s/it]: train_loss_raw=2.0195, running_loss=2.1397, LR=0.000100
[2025-08-26 08:54:18,248][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001720] [Batch 00074/00823] [00:00:55/00:09:21, 0.749s/it]: train_loss_raw=2.0953, running_loss=2.1362, LR=0.000100
[2025-08-26 08:54:24,271][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001728] [Batch 00082/00823] [00:01:01/00:09:15, 0.750s/it]: train_loss_raw=2.0729, running_loss=2.1335, LR=0.000100
[2025-08-26 08:54:30,275][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001736] [Batch 00090/00823] [00:01:07/00:09:09, 0.750s/it]: train_loss_raw=2.0766, running_loss=2.1308, LR=0.000100
[2025-08-26 08:54:36,443][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001744] [Batch 00098/00823] [00:01:13/00:09:04, 0.752s/it]: train_loss_raw=2.1632, running_loss=2.1290, LR=0.000100
[2025-08-26 08:54:42,247][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001752] [Batch 00106/00823] [00:01:19/00:08:57, 0.750s/it]: train_loss_raw=2.0366, running_loss=2.1259, LR=0.000100
[2025-08-26 08:54:48,218][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001760] [Batch 00114/00823] [00:01:25/00:08:51, 0.749s/it]: train_loss_raw=2.0616, running_loss=2.1217, LR=0.000100
[2025-08-26 08:54:54,183][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001768] [Batch 00122/00823] [00:01:31/00:08:45, 0.749s/it]: train_loss_raw=2.0363, running_loss=2.1174, LR=0.000100
[2025-08-26 08:55:00,222][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001776] [Batch 00130/00823] [00:01:37/00:08:39, 0.749s/it]: train_loss_raw=2.1619, running_loss=2.1138, LR=0.000100
[2025-08-26 08:55:06,245][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001784] [Batch 00138/00823] [00:01:43/00:08:33, 0.750s/it]: train_loss_raw=2.0354, running_loss=2.1115, LR=0.000100
[2025-08-26 08:55:12,245][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001792] [Batch 00146/00823] [00:01:49/00:08:27, 0.750s/it]: train_loss_raw=2.1478, running_loss=2.1087, LR=0.000100
[2025-08-26 08:55:18,351][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001800] [Batch 00154/00823] [00:01:55/00:08:22, 0.750s/it]: train_loss_raw=1.9949, running_loss=2.1059, LR=0.000100
[2025-08-26 08:55:24,369][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001808] [Batch 00162/00823] [00:02:01/00:08:16, 0.750s/it]: train_loss_raw=2.0698, running_loss=2.1033, LR=0.000100
[2025-08-26 08:55:30,436][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001816] [Batch 00170/00823] [00:02:07/00:08:10, 0.751s/it]: train_loss_raw=2.0797, running_loss=2.1005, LR=0.000100
[2025-08-26 08:55:36,469][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001824] [Batch 00178/00823] [00:02:13/00:08:04, 0.751s/it]: train_loss_raw=2.0274, running_loss=2.0972, LR=0.000100
[2025-08-26 08:55:42,456][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001832] [Batch 00186/00823] [00:02:19/00:07:58, 0.751s/it]: train_loss_raw=1.9594, running_loss=2.0933, LR=0.000100
[2025-08-26 08:55:48,494][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001840] [Batch 00194/00823] [00:02:25/00:07:52, 0.751s/it]: train_loss_raw=2.1267, running_loss=2.0921, LR=0.000100
[2025-08-26 08:55:54,607][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001848] [Batch 00202/00823] [00:02:31/00:07:46, 0.752s/it]: train_loss_raw=2.0367, running_loss=2.0903, LR=0.000100
[2025-08-26 08:56:00,584][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001856] [Batch 00210/00823] [00:02:37/00:07:40, 0.751s/it]: train_loss_raw=2.1674, running_loss=2.0901, LR=0.000100
[2025-08-26 08:56:06,615][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001864] [Batch 00218/00823] [00:02:43/00:07:34, 0.751s/it]: train_loss_raw=2.0592, running_loss=2.0887, LR=0.000100
[2025-08-26 08:56:12,080][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001872] [Batch 00226/00823] [00:02:49/00:07:27, 0.749s/it]: train_loss_raw=2.0738, running_loss=2.0868, LR=0.000100
[2025-08-26 08:56:17,864][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001880] [Batch 00234/00823] [00:02:55/00:07:20, 0.748s/it]: train_loss_raw=2.0227, running_loss=2.0842, LR=0.000100
[2025-08-26 08:56:23,855][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001888] [Batch 00242/00823] [00:03:01/00:07:14, 0.748s/it]: train_loss_raw=2.0564, running_loss=2.0846, LR=0.000100
[2025-08-26 08:56:29,855][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001896] [Batch 00250/00823] [00:03:07/00:07:08, 0.748s/it]: train_loss_raw=1.9408, running_loss=2.0801, LR=0.000100
[2025-08-26 08:56:35,945][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001904] [Batch 00258/00823] [00:03:13/00:07:02, 0.749s/it]: train_loss_raw=2.0705, running_loss=2.0776, LR=0.000100
[2025-08-26 08:56:42,066][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001912] [Batch 00266/00823] [00:03:19/00:06:57, 0.749s/it]: train_loss_raw=2.1114, running_loss=2.0762, LR=0.000100
[2025-08-26 08:56:48,128][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001920] [Batch 00274/00823] [00:03:25/00:06:51, 0.749s/it]: train_loss_raw=2.0616, running_loss=2.0758, LR=0.000100
[2025-08-26 08:56:54,205][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001928] [Batch 00282/00823] [00:03:31/00:06:45, 0.750s/it]: train_loss_raw=2.0069, running_loss=2.0756, LR=0.000100
[2025-08-26 08:57:00,029][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001936] [Batch 00290/00823] [00:03:37/00:06:39, 0.749s/it]: train_loss_raw=2.0295, running_loss=2.0739, LR=0.000100
[2025-08-26 08:57:06,006][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001944] [Batch 00298/00823] [00:03:43/00:06:33, 0.749s/it]: train_loss_raw=2.1007, running_loss=2.0717, LR=0.000100
[2025-08-26 08:57:12,107][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001952] [Batch 00306/00823] [00:03:49/00:06:27, 0.749s/it]: train_loss_raw=2.0240, running_loss=2.0681, LR=0.000100
[2025-08-26 08:57:18,243][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001960] [Batch 00314/00823] [00:03:55/00:06:21, 0.750s/it]: train_loss_raw=2.0033, running_loss=2.0657, LR=0.000100
[2025-08-26 08:57:24,350][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001968] [Batch 00322/00823] [00:04:01/00:06:15, 0.750s/it]: train_loss_raw=2.0639, running_loss=2.0648, LR=0.000100
[2025-08-26 08:57:30,355][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001976] [Batch 00330/00823] [00:04:07/00:06:09, 0.750s/it]: train_loss_raw=1.9878, running_loss=2.0638, LR=0.000100
[2025-08-26 08:57:36,402][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001984] [Batch 00338/00823] [00:04:13/00:06:03, 0.750s/it]: train_loss_raw=2.0884, running_loss=2.0620, LR=0.000100
[2025-08-26 08:57:42,441][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001992] [Batch 00346/00823] [00:04:19/00:05:57, 0.750s/it]: train_loss_raw=2.0247, running_loss=2.0622, LR=0.000100
[2025-08-26 08:57:48,482][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002000] [Batch 00354/00823] [00:04:25/00:05:52, 0.751s/it]: train_loss_raw=2.0128, running_loss=2.0580, LR=0.000100
[2025-08-26 08:57:58,639][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002008] [Batch 00362/00823] [00:04:35/00:05:51, 0.762s/it]: train_loss_raw=2.0447, running_loss=2.0576, LR=0.000100
[2025-08-26 08:58:04,703][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002016] [Batch 00370/00823] [00:04:41/00:05:45, 0.762s/it]: train_loss_raw=2.0318, running_loss=2.0564, LR=0.000100
[2025-08-26 08:58:10,746][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002024] [Batch 00378/00823] [00:04:47/00:05:38, 0.762s/it]: train_loss_raw=1.9946, running_loss=2.0548, LR=0.000100
[2025-08-26 08:58:16,841][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002032] [Batch 00386/00823] [00:04:54/00:05:32, 0.762s/it]: train_loss_raw=1.8864, running_loss=2.0508, LR=0.000100
[2025-08-26 08:58:22,947][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002040] [Batch 00394/00823] [00:05:00/00:05:26, 0.762s/it]: train_loss_raw=1.9918, running_loss=2.0485, LR=0.000100
[2025-08-26 08:58:29,183][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002048] [Batch 00402/00823] [00:05:06/00:05:20, 0.762s/it]: train_loss_raw=2.0392, running_loss=2.0466, LR=0.000100
[2025-08-26 08:58:35,062][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002056] [Batch 00410/00823] [00:05:12/00:05:14, 0.762s/it]: train_loss_raw=1.9876, running_loss=2.0450, LR=0.000100
[2025-08-26 08:58:40,972][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002064] [Batch 00418/00823] [00:05:18/00:05:08, 0.761s/it]: train_loss_raw=2.0241, running_loss=2.0455, LR=0.000100
[2025-08-26 08:58:46,953][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002072] [Batch 00426/00823] [00:05:24/00:05:02, 0.761s/it]: train_loss_raw=1.9659, running_loss=2.0441, LR=0.000100
[2025-08-26 08:58:53,054][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002080] [Batch 00434/00823] [00:05:30/00:04:56, 0.761s/it]: train_loss_raw=1.9741, running_loss=2.0412, LR=0.000100
[2025-08-26 08:58:59,135][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002088] [Batch 00442/00823] [00:05:36/00:04:49, 0.761s/it]: train_loss_raw=1.9937, running_loss=2.0396, LR=0.000100
[2025-08-26 08:59:05,248][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002096] [Batch 00450/00823] [00:05:42/00:04:43, 0.761s/it]: train_loss_raw=2.0669, running_loss=2.0384, LR=0.000100
[2025-08-26 08:59:11,239][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002104] [Batch 00458/00823] [00:05:48/00:04:37, 0.761s/it]: train_loss_raw=2.0913, running_loss=2.0380, LR=0.000100
[2025-08-26 08:59:17,195][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002112] [Batch 00466/00823] [00:05:54/00:04:31, 0.761s/it]: train_loss_raw=2.1013, running_loss=2.0387, LR=0.000100
[2025-08-26 08:59:23,215][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002120] [Batch 00474/00823] [00:06:00/00:04:25, 0.760s/it]: train_loss_raw=2.0965, running_loss=2.0371, LR=0.000100
[2025-08-26 08:59:29,265][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002128] [Batch 00482/00823] [00:06:06/00:04:19, 0.760s/it]: train_loss_raw=1.9910, running_loss=2.0335, LR=0.000100
[2025-08-26 08:59:35,251][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002136] [Batch 00490/00823] [00:06:12/00:04:13, 0.760s/it]: train_loss_raw=2.0328, running_loss=2.0313, LR=0.000100
[2025-08-26 08:59:41,355][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002144] [Batch 00498/00823] [00:06:18/00:04:07, 0.760s/it]: train_loss_raw=1.9811, running_loss=2.0302, LR=0.000100
[2025-08-26 08:59:47,355][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002152] [Batch 00506/00823] [00:06:24/00:04:00, 0.760s/it]: train_loss_raw=2.0695, running_loss=2.0300, LR=0.000100
[2025-08-26 08:59:53,493][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002160] [Batch 00514/00823] [00:06:30/00:03:54, 0.760s/it]: train_loss_raw=1.9380, running_loss=2.0288, LR=0.000100
[2025-08-26 08:59:59,642][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002168] [Batch 00522/00823] [00:06:36/00:03:48, 0.760s/it]: train_loss_raw=2.0564, running_loss=2.0267, LR=0.000100
[2025-08-26 09:00:05,723][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002176] [Batch 00530/00823] [00:06:42/00:03:42, 0.760s/it]: train_loss_raw=2.0274, running_loss=2.0259, LR=0.000100
[2025-08-26 09:00:11,855][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002184] [Batch 00538/00823] [00:06:49/00:03:36, 0.760s/it]: train_loss_raw=2.0359, running_loss=2.0240, LR=0.000100
[2025-08-26 09:00:17,955][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002192] [Batch 00546/00823] [00:06:55/00:03:30, 0.760s/it]: train_loss_raw=2.0805, running_loss=2.0229, LR=0.000100
[2025-08-26 09:00:23,993][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002200] [Batch 00554/00823] [00:07:01/00:03:24, 0.760s/it]: train_loss_raw=2.0110, running_loss=2.0214, LR=0.000100
[2025-08-26 09:00:30,099][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002208] [Batch 00562/00823] [00:07:07/00:03:18, 0.760s/it]: train_loss_raw=2.0814, running_loss=2.0207, LR=0.000100
[2025-08-26 09:00:36,102][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002216] [Batch 00570/00823] [00:07:13/00:03:12, 0.760s/it]: train_loss_raw=2.0030, running_loss=2.0199, LR=0.000100
[2025-08-26 09:00:41,968][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002224] [Batch 00578/00823] [00:07:19/00:03:06, 0.760s/it]: train_loss_raw=1.9668, running_loss=2.0176, LR=0.000100
[2025-08-26 09:00:48,022][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002232] [Batch 00586/00823] [00:07:25/00:03:00, 0.760s/it]: train_loss_raw=2.0579, running_loss=2.0168, LR=0.000100
[2025-08-26 09:00:53,992][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002240] [Batch 00594/00823] [00:07:31/00:02:53, 0.760s/it]: train_loss_raw=1.9938, running_loss=2.0138, LR=0.000100
[2025-08-26 09:00:59,988][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002248] [Batch 00602/00823] [00:07:37/00:02:47, 0.759s/it]: train_loss_raw=1.9598, running_loss=2.0102, LR=0.000100
[2025-08-26 09:01:05,997][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002256] [Batch 00610/00823] [00:07:43/00:02:41, 0.759s/it]: train_loss_raw=1.9611, running_loss=2.0082, LR=0.000100
[2025-08-26 09:01:12,055][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002264] [Batch 00618/00823] [00:07:49/00:02:35, 0.759s/it]: train_loss_raw=1.9795, running_loss=2.0083, LR=0.000100
[2025-08-26 09:01:18,099][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002272] [Batch 00626/00823] [00:07:55/00:02:29, 0.759s/it]: train_loss_raw=1.9922, running_loss=2.0079, LR=0.000100
[2025-08-26 09:01:24,140][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002280] [Batch 00634/00823] [00:08:01/00:02:23, 0.759s/it]: train_loss_raw=2.0595, running_loss=2.0068, LR=0.000100
[2025-08-26 09:01:30,225][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002288] [Batch 00642/00823] [00:08:07/00:02:17, 0.759s/it]: train_loss_raw=1.9371, running_loss=2.0055, LR=0.000100
[2025-08-26 09:01:36,262][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002296] [Batch 00650/00823] [00:08:13/00:02:11, 0.759s/it]: train_loss_raw=2.0232, running_loss=2.0055, LR=0.000100
[2025-08-26 09:01:42,278][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002304] [Batch 00658/00823] [00:08:19/00:02:05, 0.759s/it]: train_loss_raw=2.0483, running_loss=2.0045, LR=0.000100
[2025-08-26 09:01:48,310][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002312] [Batch 00666/00823] [00:08:25/00:01:59, 0.759s/it]: train_loss_raw=2.0284, running_loss=2.0036, LR=0.000100
[2025-08-26 09:01:54,386][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002320] [Batch 00674/00823] [00:08:31/00:01:53, 0.759s/it]: train_loss_raw=2.0248, running_loss=2.0016, LR=0.000100
[2025-08-26 09:02:00,379][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002328] [Batch 00682/00823] [00:08:37/00:01:47, 0.759s/it]: train_loss_raw=1.9532, running_loss=2.0003, LR=0.000100
[2025-08-26 09:02:06,436][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002336] [Batch 00690/00823] [00:08:43/00:01:40, 0.759s/it]: train_loss_raw=2.0149, running_loss=1.9991, LR=0.000100
[2025-08-26 09:02:12,468][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002344] [Batch 00698/00823] [00:08:49/00:01:34, 0.759s/it]: train_loss_raw=2.0566, running_loss=1.9973, LR=0.000100
[2025-08-26 09:02:18,510][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002352] [Batch 00706/00823] [00:08:55/00:01:28, 0.759s/it]: train_loss_raw=1.9932, running_loss=1.9969, LR=0.000100
[2025-08-26 09:02:24,557][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002360] [Batch 00714/00823] [00:09:01/00:01:22, 0.759s/it]: train_loss_raw=1.9930, running_loss=1.9949, LR=0.000100
[2025-08-26 09:02:30,597][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002368] [Batch 00722/00823] [00:09:07/00:01:16, 0.759s/it]: train_loss_raw=1.9938, running_loss=1.9946, LR=0.000100
[2025-08-26 09:02:36,660][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002376] [Batch 00730/00823] [00:09:13/00:01:10, 0.759s/it]: train_loss_raw=2.0125, running_loss=1.9929, LR=0.000100
[2025-08-26 09:02:42,696][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002384] [Batch 00738/00823] [00:09:19/00:01:04, 0.759s/it]: train_loss_raw=1.9590, running_loss=1.9881, LR=0.000100
[2025-08-26 09:02:48,836][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002392] [Batch 00746/00823] [00:09:26/00:00:58, 0.759s/it]: train_loss_raw=1.9831, running_loss=1.9867, LR=0.000100
[2025-08-26 09:02:54,842][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002400] [Batch 00754/00823] [00:09:32/00:00:52, 0.759s/it]: train_loss_raw=2.0426, running_loss=1.9865, LR=0.000100
[2025-08-26 09:03:00,876][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002408] [Batch 00762/00823] [00:09:38/00:00:46, 0.759s/it]: train_loss_raw=1.9562, running_loss=1.9862, LR=0.000100
[2025-08-26 09:03:06,895][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002416] [Batch 00770/00823] [00:09:44/00:00:40, 0.759s/it]: train_loss_raw=1.9686, running_loss=1.9849, LR=0.000100
[2025-08-26 09:03:12,854][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002424] [Batch 00778/00823] [00:09:50/00:00:34, 0.758s/it]: train_loss_raw=1.9901, running_loss=1.9810, LR=0.000100
[2025-08-26 09:03:18,908][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002432] [Batch 00786/00823] [00:09:56/00:00:28, 0.758s/it]: train_loss_raw=1.9245, running_loss=1.9796, LR=0.000100
[2025-08-26 09:03:24,947][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002440] [Batch 00794/00823] [00:10:02/00:00:21, 0.758s/it]: train_loss_raw=1.9408, running_loss=1.9781, LR=0.000100
[2025-08-26 09:03:31,002][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002448] [Batch 00802/00823] [00:10:08/00:00:15, 0.758s/it]: train_loss_raw=1.9365, running_loss=1.9782, LR=0.000100
[2025-08-26 09:03:37,007][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002456] [Batch 00810/00823] [00:10:14/00:00:09, 0.758s/it]: train_loss_raw=1.9148, running_loss=1.9737, LR=0.000100
[2025-08-26 09:03:42,956][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002464] [Batch 00818/00823] [00:10:20/00:00:03, 0.758s/it]: train_loss_raw=1.9593, running_loss=1.9744, LR=0.000100
[2025-08-26 09:03:46,946][__main__][INFO] - [VALIDATION] [Epoch 02/29] Starting validation.
[2025-08-26 09:03:59,186][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 002470] [Batch 00007/00013] [00:00:12/00:00:07, 1.530s/it]
[2025-08-26 09:04:06,864][__main__][INFO] - [VALIDATION] [Epoch 02/29] train_loss=1.97335, valid_loss=2.00010
[2025-08-26 09:04:06,864][__main__][INFO] - [VALIDATION] [Epoch 02/29] Metrics:
[2025-08-26 09:04:06,865][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_er      0.795
[2025-08-26 09:04:06,865][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_prec    0.028
[2025-08-26 09:04:06,865][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_recall  0.030
[2025-08-26 09:04:06,865][__main__][INFO] - [VALIDATION] [Epoch 02/29] - pep_recall 0.001
[2025-08-26 09:04:06,867][__main__][INFO] - [TRAIN] [Epoch 02/29] Epoch complete, total time 00:31:30, remaining time 04:43:35, 00:10:30 per epoch
[2025-08-26 09:04:08,820][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002472] [Batch 00003/00823] [00:00:01/00:07:32, 0.552s/it]: train_loss_raw=2.0118, running_loss=1.9024, LR=0.000100
[2025-08-26 09:04:14,786][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002480] [Batch 00011/00823] [00:00:07/00:09:22, 0.693s/it]: train_loss_raw=1.9701, running_loss=1.9048, LR=0.000100
[2025-08-26 09:04:20,761][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002488] [Batch 00019/00823] [00:00:13/00:09:35, 0.716s/it]: train_loss_raw=1.9268, running_loss=1.9090, LR=0.000100
[2025-08-26 09:04:26,793][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002496] [Batch 00027/00823] [00:00:19/00:09:38, 0.727s/it]: train_loss_raw=1.8991, running_loss=1.9116, LR=0.000100
[2025-08-26 09:04:32,891][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002504] [Batch 00035/00823] [00:00:25/00:09:39, 0.735s/it]: train_loss_raw=1.8912, running_loss=1.9157, LR=0.000100
[2025-08-26 09:04:38,898][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002512] [Batch 00043/00823] [00:00:31/00:09:35, 0.738s/it]: train_loss_raw=1.9924, running_loss=1.9195, LR=0.000100
[2025-08-26 09:04:44,966][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002520] [Batch 00051/00823] [00:00:37/00:09:32, 0.741s/it]: train_loss_raw=1.9153, running_loss=1.9209, LR=0.000100
[2025-08-26 09:04:51,023][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002528] [Batch 00059/00823] [00:00:43/00:09:27, 0.743s/it]: train_loss_raw=2.0293, running_loss=1.9206, LR=0.000100
[2025-08-26 09:04:57,040][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002536] [Batch 00067/00823] [00:00:49/00:09:22, 0.744s/it]: train_loss_raw=1.9396, running_loss=1.9225, LR=0.000100
[2025-08-26 09:05:02,804][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002544] [Batch 00075/00823] [00:00:55/00:09:14, 0.742s/it]: train_loss_raw=1.9841, running_loss=1.9264, LR=0.000100
[2025-08-26 09:05:08,544][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002552] [Batch 00083/00823] [00:01:01/00:09:07, 0.740s/it]: train_loss_raw=1.8796, running_loss=1.9282, LR=0.000100
[2025-08-26 09:05:14,418][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002560] [Batch 00091/00823] [00:01:07/00:09:00, 0.739s/it]: train_loss_raw=1.9197, running_loss=1.9282, LR=0.000100
[2025-08-26 09:05:20,414][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002568] [Batch 00099/00823] [00:01:13/00:08:55, 0.740s/it]: train_loss_raw=1.9773, running_loss=1.9297, LR=0.000100
[2025-08-26 09:05:26,451][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002576] [Batch 00107/00823] [00:01:19/00:08:50, 0.741s/it]: train_loss_raw=1.9763, running_loss=1.9306, LR=0.000100
[2025-08-26 09:05:32,504][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002584] [Batch 00115/00823] [00:01:25/00:08:45, 0.742s/it]: train_loss_raw=1.9487, running_loss=1.9331, LR=0.000100
[2025-08-26 09:05:38,575][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002592] [Batch 00123/00823] [00:01:31/00:08:40, 0.743s/it]: train_loss_raw=1.9119, running_loss=1.9342, LR=0.000100
[2025-08-26 09:05:44,605][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002600] [Batch 00131/00823] [00:01:37/00:08:34, 0.744s/it]: train_loss_raw=2.0186, running_loss=1.9362, LR=0.000100
[2025-08-26 09:05:50,695][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002608] [Batch 00139/00823] [00:01:43/00:08:29, 0.745s/it]: train_loss_raw=1.9451, running_loss=1.9336, LR=0.000100
[2025-08-26 09:05:56,761][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002616] [Batch 00147/00823] [00:01:49/00:08:23, 0.746s/it]: train_loss_raw=1.9244, running_loss=1.9332, LR=0.000100
[2025-08-26 09:06:02,826][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002624] [Batch 00155/00823] [00:01:55/00:08:18, 0.746s/it]: train_loss_raw=1.9754, running_loss=1.9334, LR=0.000100
[2025-08-26 09:06:08,925][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002632] [Batch 00163/00823] [00:02:01/00:08:13, 0.747s/it]: train_loss_raw=2.0316, running_loss=1.9339, LR=0.000100
[2025-08-26 09:06:14,919][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002640] [Batch 00171/00823] [00:02:07/00:08:07, 0.747s/it]: train_loss_raw=1.9286, running_loss=1.9347, LR=0.000100
[2025-08-26 09:06:20,985][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002648] [Batch 00179/00823] [00:02:13/00:08:01, 0.748s/it]: train_loss_raw=1.9611, running_loss=1.9357, LR=0.000100
[2025-08-26 09:06:27,019][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002656] [Batch 00187/00823] [00:02:19/00:07:55, 0.748s/it]: train_loss_raw=1.8412, running_loss=1.9361, LR=0.000100
[2025-08-26 09:06:33,128][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002664] [Batch 00195/00823] [00:02:25/00:07:50, 0.749s/it]: train_loss_raw=2.0085, running_loss=1.9355, LR=0.000100
[2025-08-26 09:06:39,195][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002672] [Batch 00203/00823] [00:02:32/00:07:44, 0.749s/it]: train_loss_raw=1.8704, running_loss=1.9370, LR=0.000100
[2025-08-26 09:06:45,163][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002680] [Batch 00211/00823] [00:02:37/00:07:38, 0.749s/it]: train_loss_raw=1.9043, running_loss=1.9366, LR=0.000100
[2025-08-26 09:06:51,254][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002688] [Batch 00219/00823] [00:02:44/00:07:32, 0.749s/it]: train_loss_raw=1.9502, running_loss=1.9371, LR=0.000100
[2025-08-26 09:06:57,271][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002696] [Batch 00227/00823] [00:02:50/00:07:26, 0.749s/it]: train_loss_raw=1.9476, running_loss=1.9353, LR=0.000100
[2025-08-26 09:07:03,319][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002704] [Batch 00235/00823] [00:02:56/00:07:20, 0.750s/it]: train_loss_raw=1.9378, running_loss=1.9359, LR=0.000100
[2025-08-26 09:07:09,329][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002712] [Batch 00243/00823] [00:03:02/00:07:14, 0.750s/it]: train_loss_raw=2.0022, running_loss=1.9359, LR=0.000100
[2025-08-26 09:07:15,338][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002720] [Batch 00251/00823] [00:03:08/00:07:08, 0.750s/it]: train_loss_raw=1.8417, running_loss=1.9353, LR=0.000100
[2025-08-26 09:07:21,367][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002728] [Batch 00259/00823] [00:03:14/00:07:02, 0.750s/it]: train_loss_raw=1.8769, running_loss=1.9332, LR=0.000100
[2025-08-26 09:07:27,377][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002736] [Batch 00267/00823] [00:03:20/00:06:56, 0.750s/it]: train_loss_raw=1.9731, running_loss=1.9322, LR=0.000100
[2025-08-26 09:07:33,437][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002744] [Batch 00275/00823] [00:03:26/00:06:51, 0.750s/it]: train_loss_raw=1.9100, running_loss=1.9313, LR=0.000100
[2025-08-26 09:07:39,499][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002752] [Batch 00283/00823] [00:03:32/00:06:45, 0.750s/it]: train_loss_raw=1.8645, running_loss=1.9300, LR=0.000100
[2025-08-26 09:07:45,626][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002760] [Batch 00291/00823] [00:03:38/00:06:39, 0.751s/it]: train_loss_raw=1.8803, running_loss=1.9275, LR=0.000100
[2025-08-26 09:07:51,637][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002768] [Batch 00299/00823] [00:03:44/00:06:33, 0.751s/it]: train_loss_raw=1.9569, running_loss=1.9271, LR=0.000100
[2025-08-26 09:07:57,647][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002776] [Batch 00307/00823] [00:03:50/00:06:27, 0.751s/it]: train_loss_raw=1.9312, running_loss=1.9263, LR=0.000100
[2025-08-26 09:08:03,735][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002784] [Batch 00315/00823] [00:03:56/00:06:21, 0.751s/it]: train_loss_raw=1.8236, running_loss=1.9238, LR=0.000100
[2025-08-26 09:08:09,760][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002792] [Batch 00323/00823] [00:04:02/00:06:15, 0.751s/it]: train_loss_raw=1.8407, running_loss=1.9240, LR=0.000100
[2025-08-26 09:08:15,809][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002800] [Batch 00331/00823] [00:04:08/00:06:09, 0.751s/it]: train_loss_raw=1.9390, running_loss=1.9242, LR=0.000100
[2025-08-26 09:08:21,842][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002808] [Batch 00339/00823] [00:04:14/00:06:03, 0.751s/it]: train_loss_raw=1.9381, running_loss=1.9226, LR=0.000100
[2025-08-26 09:08:28,004][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002816] [Batch 00347/00823] [00:04:20/00:05:57, 0.752s/it]: train_loss_raw=1.9390, running_loss=1.9228, LR=0.000100
[2025-08-26 09:08:34,096][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002824] [Batch 00355/00823] [00:04:26/00:05:51, 0.752s/it]: train_loss_raw=1.8599, running_loss=1.9216, LR=0.000100
[2025-08-26 09:08:40,149][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002832] [Batch 00363/00823] [00:04:32/00:05:45, 0.752s/it]: train_loss_raw=1.8815, running_loss=1.9180, LR=0.000100
[2025-08-26 09:08:46,559][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002840] [Batch 00371/00823] [00:04:39/00:05:40, 0.753s/it]: train_loss_raw=1.9283, running_loss=1.9174, LR=0.000100
[2025-08-26 09:08:52,649][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002848] [Batch 00379/00823] [00:04:45/00:05:34, 0.753s/it]: train_loss_raw=1.9544, running_loss=1.9167, LR=0.000100
[2025-08-26 09:08:58,668][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002856] [Batch 00387/00823] [00:04:51/00:05:28, 0.753s/it]: train_loss_raw=1.8728, running_loss=1.9148, LR=0.000100
[2025-08-26 09:09:04,657][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002864] [Batch 00395/00823] [00:04:57/00:05:22, 0.753s/it]: train_loss_raw=1.9292, running_loss=1.9142, LR=0.000100
[2025-08-26 09:09:10,689][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002872] [Batch 00403/00823] [00:05:03/00:05:16, 0.753s/it]: train_loss_raw=1.9540, running_loss=1.9127, LR=0.000100
[2025-08-26 09:09:16,705][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002880] [Batch 00411/00823] [00:05:09/00:05:10, 0.753s/it]: train_loss_raw=1.9074, running_loss=1.9118, LR=0.000100
[2025-08-26 09:09:22,707][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002888] [Batch 00419/00823] [00:05:15/00:05:04, 0.753s/it]: train_loss_raw=1.9184, running_loss=1.9104, LR=0.000100
[2025-08-26 09:09:28,671][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002896] [Batch 00427/00823] [00:05:21/00:04:58, 0.753s/it]: train_loss_raw=1.8260, running_loss=1.9096, LR=0.000100
[2025-08-26 09:09:34,756][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002904] [Batch 00435/00823] [00:05:27/00:04:52, 0.753s/it]: train_loss_raw=1.9320, running_loss=1.9103, LR=0.000100
[2025-08-26 09:09:40,807][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002912] [Batch 00443/00823] [00:05:33/00:04:46, 0.753s/it]: train_loss_raw=1.9381, running_loss=1.9104, LR=0.000100
[2025-08-26 09:09:46,836][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002920] [Batch 00451/00823] [00:05:39/00:04:40, 0.753s/it]: train_loss_raw=1.9793, running_loss=1.9115, LR=0.000100
[2025-08-26 09:09:52,929][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002928] [Batch 00459/00823] [00:05:45/00:04:34, 0.753s/it]: train_loss_raw=1.9628, running_loss=1.9090, LR=0.000100
[2025-08-26 09:09:58,979][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002936] [Batch 00467/00823] [00:05:51/00:04:28, 0.753s/it]: train_loss_raw=1.8007, running_loss=1.9078, LR=0.000100
[2025-08-26 09:10:05,175][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002944] [Batch 00475/00823] [00:05:58/00:04:22, 0.754s/it]: train_loss_raw=1.9264, running_loss=1.9069, LR=0.000100
[2025-08-26 09:10:11,221][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002952] [Batch 00483/00823] [00:06:04/00:04:16, 0.754s/it]: train_loss_raw=1.8951, running_loss=1.9052, LR=0.000100
[2025-08-26 09:10:17,290][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002960] [Batch 00491/00823] [00:06:10/00:04:10, 0.754s/it]: train_loss_raw=1.8951, running_loss=1.9032, LR=0.000100
[2025-08-26 09:10:23,326][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002968] [Batch 00499/00823] [00:06:16/00:04:04, 0.754s/it]: train_loss_raw=1.7906, running_loss=1.9020, LR=0.000100
[2025-08-26 09:10:29,412][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002976] [Batch 00507/00823] [00:06:22/00:03:58, 0.754s/it]: train_loss_raw=1.8521, running_loss=1.8992, LR=0.000100
[2025-08-26 09:10:35,421][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002984] [Batch 00515/00823] [00:06:28/00:03:52, 0.754s/it]: train_loss_raw=1.9456, running_loss=1.8981, LR=0.000100
[2025-08-26 09:10:41,485][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002992] [Batch 00523/00823] [00:06:34/00:03:46, 0.754s/it]: train_loss_raw=1.8767, running_loss=1.8948, LR=0.000100
[2025-08-26 09:10:47,547][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003000] [Batch 00531/00823] [00:06:40/00:03:40, 0.754s/it]: train_loss_raw=1.9671, running_loss=1.8955, LR=0.000100
[2025-08-26 09:10:53,600][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003008] [Batch 00539/00823] [00:06:46/00:03:34, 0.754s/it]: train_loss_raw=1.9736, running_loss=1.8981, LR=0.000100
[2025-08-26 09:10:59,576][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003016] [Batch 00547/00823] [00:06:52/00:03:28, 0.754s/it]: train_loss_raw=1.8892, running_loss=1.8988, LR=0.000100
[2025-08-26 09:11:05,631][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003024] [Batch 00555/00823] [00:06:58/00:03:22, 0.754s/it]: train_loss_raw=1.8721, running_loss=1.8967, LR=0.000100
[2025-08-26 09:11:11,685][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003032] [Batch 00563/00823] [00:07:04/00:03:16, 0.754s/it]: train_loss_raw=1.8731, running_loss=1.8964, LR=0.000100
[2025-08-26 09:11:17,754][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003040] [Batch 00571/00823] [00:07:10/00:03:10, 0.754s/it]: train_loss_raw=1.8979, running_loss=1.8952, LR=0.000100
[2025-08-26 09:11:23,793][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003048] [Batch 00579/00823] [00:07:16/00:03:04, 0.754s/it]: train_loss_raw=1.8657, running_loss=1.8965, LR=0.000100
[2025-08-26 09:11:30,024][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003056] [Batch 00587/00823] [00:07:22/00:02:58, 0.754s/it]: train_loss_raw=1.8734, running_loss=1.8945, LR=0.000100
[2025-08-26 09:11:36,096][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003064] [Batch 00595/00823] [00:07:28/00:02:52, 0.755s/it]: train_loss_raw=1.8995, running_loss=1.8960, LR=0.000100
[2025-08-26 09:11:42,123][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003072] [Batch 00603/00823] [00:07:34/00:02:45, 0.754s/it]: train_loss_raw=1.9137, running_loss=1.8942, LR=0.000100
[2025-08-26 09:11:48,204][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003080] [Batch 00611/00823] [00:07:41/00:02:39, 0.755s/it]: train_loss_raw=1.8242, running_loss=1.8932, LR=0.000100
[2025-08-26 09:11:54,271][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003088] [Batch 00619/00823] [00:07:47/00:02:33, 0.755s/it]: train_loss_raw=1.7836, running_loss=1.8910, LR=0.000100
[2025-08-26 09:12:00,364][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003096] [Batch 00627/00823] [00:07:53/00:02:27, 0.755s/it]: train_loss_raw=1.8677, running_loss=1.8864, LR=0.000100
[2025-08-26 09:12:06,435][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003104] [Batch 00635/00823] [00:07:59/00:02:21, 0.755s/it]: train_loss_raw=1.7900, running_loss=1.8860, LR=0.000100
[2025-08-26 09:12:12,428][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003112] [Batch 00643/00823] [00:08:05/00:02:15, 0.755s/it]: train_loss_raw=1.9226, running_loss=1.8840, LR=0.000100
[2025-08-26 09:12:18,404][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003120] [Batch 00651/00823] [00:08:11/00:02:09, 0.755s/it]: train_loss_raw=1.8295, running_loss=1.8832, LR=0.000100
[2025-08-26 09:12:24,398][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003128] [Batch 00659/00823] [00:08:17/00:02:03, 0.755s/it]: train_loss_raw=1.8411, running_loss=1.8832, LR=0.000100
[2025-08-26 09:12:30,386][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003136] [Batch 00667/00823] [00:08:23/00:01:57, 0.754s/it]: train_loss_raw=1.8430, running_loss=1.8836, LR=0.000100
[2025-08-26 09:12:36,431][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003144] [Batch 00675/00823] [00:08:29/00:01:51, 0.754s/it]: train_loss_raw=1.9352, running_loss=1.8822, LR=0.000100
[2025-08-26 09:12:42,459][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003152] [Batch 00683/00823] [00:08:35/00:01:45, 0.754s/it]: train_loss_raw=1.7805, running_loss=1.8806, LR=0.000100
[2025-08-26 09:12:48,505][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003160] [Batch 00691/00823] [00:08:41/00:01:39, 0.754s/it]: train_loss_raw=1.8422, running_loss=1.8780, LR=0.000100
[2025-08-26 09:12:54,568][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003168] [Batch 00699/00823] [00:08:47/00:01:33, 0.755s/it]: train_loss_raw=1.9123, running_loss=1.8761, LR=0.000100
[2025-08-26 09:13:00,585][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003176] [Batch 00707/00823] [00:08:53/00:01:27, 0.754s/it]: train_loss_raw=1.8828, running_loss=1.8773, LR=0.000100
[2025-08-26 09:13:06,595][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003184] [Batch 00715/00823] [00:08:59/00:01:21, 0.754s/it]: train_loss_raw=1.8735, running_loss=1.8774, LR=0.000100
[2025-08-26 09:13:12,689][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003192] [Batch 00723/00823] [00:09:05/00:01:15, 0.755s/it]: train_loss_raw=1.8568, running_loss=1.8745, LR=0.000100
[2025-08-26 09:13:18,793][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003200] [Batch 00731/00823] [00:09:11/00:01:09, 0.755s/it]: train_loss_raw=1.8168, running_loss=1.8736, LR=0.000100
[2025-08-26 09:13:24,808][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003208] [Batch 00739/00823] [00:09:17/00:01:03, 0.755s/it]: train_loss_raw=1.9076, running_loss=1.8723, LR=0.000100
[2025-08-26 09:13:30,886][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003216] [Batch 00747/00823] [00:09:23/00:00:57, 0.755s/it]: train_loss_raw=1.9134, running_loss=1.8726, LR=0.000100
[2025-08-26 09:13:36,947][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003224] [Batch 00755/00823] [00:09:29/00:00:51, 0.755s/it]: train_loss_raw=1.9342, running_loss=1.8715, LR=0.000100
[2025-08-26 09:13:43,026][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003232] [Batch 00763/00823] [00:09:35/00:00:45, 0.755s/it]: train_loss_raw=1.8797, running_loss=1.8678, LR=0.000100
[2025-08-26 09:13:49,072][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003240] [Batch 00771/00823] [00:09:41/00:00:39, 0.755s/it]: train_loss_raw=1.8812, running_loss=1.8674, LR=0.000100
[2025-08-26 09:13:55,141][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003248] [Batch 00779/00823] [00:09:47/00:00:33, 0.755s/it]: train_loss_raw=1.8274, running_loss=1.8675, LR=0.000100
[2025-08-26 09:14:01,124][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003256] [Batch 00787/00823] [00:09:53/00:00:27, 0.755s/it]: train_loss_raw=1.8802, running_loss=1.8669, LR=0.000100
[2025-08-26 09:14:07,247][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003264] [Batch 00795/00823] [00:10:00/00:00:21, 0.755s/it]: train_loss_raw=1.8661, running_loss=1.8655, LR=0.000100
[2025-08-26 09:14:13,398][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003272] [Batch 00803/00823] [00:10:06/00:00:15, 0.755s/it]: train_loss_raw=1.8060, running_loss=1.8646, LR=0.000100
[2025-08-26 09:14:19,426][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003280] [Batch 00811/00823] [00:10:12/00:00:09, 0.755s/it]: train_loss_raw=1.9748, running_loss=1.8629, LR=0.000100
[2025-08-26 09:14:25,478][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003288] [Batch 00819/00823] [00:10:18/00:00:03, 0.755s/it]: train_loss_raw=1.7643, running_loss=1.8613, LR=0.000100
[2025-08-26 09:14:34,763][__main__][INFO] - [VALIDATION] [Epoch 03/29] Starting validation.
[2025-08-26 09:14:46,011][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 003293] [Batch 00007/00013] [00:00:11/00:00:07, 1.406s/it]
[2025-08-26 09:14:53,569][__main__][INFO] - [VALIDATION] [Epoch 03/29] train_loss=1.86123, valid_loss=1.86401
[2025-08-26 09:14:53,569][__main__][INFO] - [VALIDATION] [Epoch 03/29] Metrics:
[2025-08-26 09:14:53,570][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_er      0.762
[2025-08-26 09:14:53,570][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_prec    0.027
[2025-08-26 09:14:53,570][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_recall  0.028
[2025-08-26 09:14:53,570][__main__][INFO] - [VALIDATION] [Epoch 03/29] - pep_recall 0.002
[2025-08-26 09:14:53,572][__main__][INFO] - [TRAIN] [Epoch 03/29] Epoch complete, total time 00:42:17, remaining time 04:34:52, 00:10:34 per epoch
[2025-08-26 09:14:56,319][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003296] [Batch 00004/00823] [00:00:02/00:08:17, 0.607s/it]: train_loss_raw=1.8148, running_loss=1.8120, LR=0.000100
[2025-08-26 09:15:02,354][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003304] [Batch 00012/00823] [00:00:08/00:09:31, 0.705s/it]: train_loss_raw=1.8681, running_loss=1.8153, LR=0.000100
[2025-08-26 09:15:08,128][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003312] [Batch 00020/00823] [00:00:14/00:09:31, 0.712s/it]: train_loss_raw=1.8596, running_loss=1.8153, LR=0.000100
[2025-08-26 09:15:13,995][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003320] [Batch 00028/00823] [00:00:20/00:09:30, 0.718s/it]: train_loss_raw=1.8639, running_loss=1.8167, LR=0.000100
[2025-08-26 09:15:19,724][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003328] [Batch 00036/00823] [00:00:25/00:09:24, 0.718s/it]: train_loss_raw=1.8300, running_loss=1.8186, LR=0.000100
[2025-08-26 09:15:25,737][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003336] [Batch 00044/00823] [00:00:31/00:09:23, 0.724s/it]: train_loss_raw=1.8923, running_loss=1.8216, LR=0.000100
[2025-08-26 09:15:31,718][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003344] [Batch 00052/00823] [00:00:37/00:09:20, 0.727s/it]: train_loss_raw=1.7764, running_loss=1.8209, LR=0.000100
[2025-08-26 09:15:37,506][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003352] [Batch 00060/00823] [00:00:43/00:09:14, 0.727s/it]: train_loss_raw=1.7960, running_loss=1.8206, LR=0.000100
[2025-08-26 09:15:43,319][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003360] [Batch 00068/00823] [00:00:49/00:09:08, 0.727s/it]: train_loss_raw=1.8216, running_loss=1.8204, LR=0.000100
[2025-08-26 09:15:49,214][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003368] [Batch 00076/00823] [00:00:55/00:09:03, 0.728s/it]: train_loss_raw=1.9140, running_loss=1.8200, LR=0.000100
[2025-08-26 09:15:55,061][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003376] [Batch 00084/00823] [00:01:01/00:08:58, 0.728s/it]: train_loss_raw=1.8450, running_loss=1.8213, LR=0.000100
[2025-08-26 09:16:00,843][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003384] [Batch 00092/00823] [00:01:06/00:08:51, 0.728s/it]: train_loss_raw=1.7542, running_loss=1.8192, LR=0.000100
[2025-08-26 09:16:06,756][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003392] [Batch 00100/00823] [00:01:12/00:08:46, 0.729s/it]: train_loss_raw=1.8008, running_loss=1.8198, LR=0.000100
[2025-08-26 09:16:12,880][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003400] [Batch 00108/00823] [00:01:18/00:08:42, 0.731s/it]: train_loss_raw=1.8792, running_loss=1.8195, LR=0.000100
[2025-08-26 09:16:18,879][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003408] [Batch 00116/00823] [00:01:24/00:08:37, 0.733s/it]: train_loss_raw=1.7273, running_loss=1.8193, LR=0.000100
[2025-08-26 09:16:24,876][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003416] [Batch 00124/00823] [00:01:30/00:08:32, 0.734s/it]: train_loss_raw=1.7769, running_loss=1.8181, LR=0.000100
[2025-08-26 09:16:31,005][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003424] [Batch 00132/00823] [00:01:37/00:08:28, 0.736s/it]: train_loss_raw=1.8454, running_loss=1.8195, LR=0.000100
[2025-08-26 09:16:37,017][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003432] [Batch 00140/00823] [00:01:43/00:08:23, 0.737s/it]: train_loss_raw=1.8917, running_loss=1.8210, LR=0.000100
[2025-08-26 09:16:43,108][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003440] [Batch 00148/00823] [00:01:49/00:08:18, 0.738s/it]: train_loss_raw=1.8287, running_loss=1.8219, LR=0.000100
[2025-08-26 09:16:49,219][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003448] [Batch 00156/00823] [00:01:55/00:08:13, 0.739s/it]: train_loss_raw=1.6808, running_loss=1.8192, LR=0.000100
[2025-08-26 09:16:55,223][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003456] [Batch 00164/00823] [00:02:01/00:08:07, 0.740s/it]: train_loss_raw=1.7819, running_loss=1.8174, LR=0.000100
[2025-08-26 09:17:01,311][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003464] [Batch 00172/00823] [00:02:07/00:08:02, 0.741s/it]: train_loss_raw=1.8004, running_loss=1.8126, LR=0.000100
[2025-08-26 09:17:07,346][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003472] [Batch 00180/00823] [00:02:13/00:07:56, 0.741s/it]: train_loss_raw=1.7704, running_loss=1.8111, LR=0.000100
[2025-08-26 09:17:13,486][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003480] [Batch 00188/00823] [00:02:19/00:07:51, 0.743s/it]: train_loss_raw=1.8459, running_loss=1.8139, LR=0.000100
[2025-08-26 09:17:19,543][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003488] [Batch 00196/00823] [00:02:25/00:07:45, 0.743s/it]: train_loss_raw=1.8831, running_loss=1.8154, LR=0.000100
[2025-08-26 09:17:25,601][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003496] [Batch 00204/00823] [00:02:31/00:07:40, 0.744s/it]: train_loss_raw=1.8195, running_loss=1.8140, LR=0.000100
[2025-08-26 09:17:31,651][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003504] [Batch 00212/00823] [00:02:37/00:07:34, 0.744s/it]: train_loss_raw=1.8221, running_loss=1.8119, LR=0.000100
[2025-08-26 09:17:37,684][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003512] [Batch 00220/00823] [00:02:43/00:07:28, 0.745s/it]: train_loss_raw=1.8202, running_loss=1.8126, LR=0.000100
[2025-08-26 09:17:43,764][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003520] [Batch 00228/00823] [00:02:49/00:07:23, 0.745s/it]: train_loss_raw=1.7447, running_loss=1.8123, LR=0.000100
[2025-08-26 09:17:49,904][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003528] [Batch 00236/00823] [00:02:56/00:07:17, 0.746s/it]: train_loss_raw=1.7432, running_loss=1.8126, LR=0.000100
[2025-08-26 09:17:55,935][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003536] [Batch 00244/00823] [00:03:02/00:07:11, 0.746s/it]: train_loss_raw=1.8767, running_loss=1.8131, LR=0.000100
[2025-08-26 09:18:02,064][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003544] [Batch 00252/00823] [00:03:08/00:07:06, 0.747s/it]: train_loss_raw=1.7766, running_loss=1.8121, LR=0.000100
[2025-08-26 09:18:08,174][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003552] [Batch 00260/00823] [00:03:14/00:07:00, 0.747s/it]: train_loss_raw=1.8186, running_loss=1.8122, LR=0.000100
[2025-08-26 09:18:14,200][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003560] [Batch 00268/00823] [00:03:20/00:06:54, 0.747s/it]: train_loss_raw=1.8747, running_loss=1.8126, LR=0.000100
[2025-08-26 09:18:20,237][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003568] [Batch 00276/00823] [00:03:26/00:06:48, 0.748s/it]: train_loss_raw=1.8389, running_loss=1.8138, LR=0.000100
[2025-08-26 09:18:26,315][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003576] [Batch 00284/00823] [00:03:32/00:06:43, 0.748s/it]: train_loss_raw=1.8274, running_loss=1.8129, LR=0.000100
[2025-08-26 09:18:32,403][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003584] [Batch 00292/00823] [00:03:38/00:06:37, 0.748s/it]: train_loss_raw=1.7509, running_loss=1.8106, LR=0.000100
[2025-08-26 09:18:38,489][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003592] [Batch 00300/00823] [00:03:44/00:06:31, 0.749s/it]: train_loss_raw=1.7561, running_loss=1.8096, LR=0.000100
[2025-08-26 09:18:44,681][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003600] [Batch 00308/00823] [00:03:50/00:06:25, 0.749s/it]: train_loss_raw=1.8560, running_loss=1.8118, LR=0.000100
[2025-08-26 09:18:50,826][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003608] [Batch 00316/00823] [00:03:56/00:06:20, 0.750s/it]: train_loss_raw=1.8917, running_loss=1.8120, LR=0.000100
[2025-08-26 09:18:56,999][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003616] [Batch 00324/00823] [00:04:03/00:06:14, 0.750s/it]: train_loss_raw=1.7990, running_loss=1.8130, LR=0.000100
[2025-08-26 09:19:03,080][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003624] [Batch 00332/00823] [00:04:09/00:06:08, 0.751s/it]: train_loss_raw=1.8456, running_loss=1.8122, LR=0.000100
[2025-08-26 09:19:09,151][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003632] [Batch 00340/00823] [00:04:15/00:06:02, 0.751s/it]: train_loss_raw=1.8116, running_loss=1.8112, LR=0.000100
[2025-08-26 09:19:15,250][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003640] [Batch 00348/00823] [00:04:21/00:05:56, 0.751s/it]: train_loss_raw=1.8387, running_loss=1.8121, LR=0.000100
[2025-08-26 09:19:21,329][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003648] [Batch 00356/00823] [00:04:27/00:05:50, 0.751s/it]: train_loss_raw=1.7787, running_loss=1.8115, LR=0.000100
[2025-08-26 09:19:27,354][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003656] [Batch 00364/00823] [00:04:33/00:05:44, 0.751s/it]: train_loss_raw=1.7929, running_loss=1.8115, LR=0.000100
[2025-08-26 09:19:33,467][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003664] [Batch 00372/00823] [00:04:39/00:05:38, 0.752s/it]: train_loss_raw=1.8623, running_loss=1.8097, LR=0.000100
[2025-08-26 09:19:39,536][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003672] [Batch 00380/00823] [00:04:45/00:05:33, 0.752s/it]: train_loss_raw=1.8691, running_loss=1.8108, LR=0.000100
[2025-08-26 09:19:45,617][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003680] [Batch 00388/00823] [00:04:51/00:05:27, 0.752s/it]: train_loss_raw=1.7621, running_loss=1.8095, LR=0.000100
[2025-08-26 09:19:51,674][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003688] [Batch 00396/00823] [00:04:57/00:05:21, 0.752s/it]: train_loss_raw=1.8852, running_loss=1.8108, LR=0.000100
[2025-08-26 09:19:57,763][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003696] [Batch 00404/00823] [00:05:03/00:05:15, 0.752s/it]: train_loss_raw=1.8761, running_loss=1.8100, LR=0.000100
[2025-08-26 09:20:03,850][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003704] [Batch 00412/00823] [00:05:09/00:05:09, 0.752s/it]: train_loss_raw=1.8316, running_loss=1.8098, LR=0.000100
[2025-08-26 09:20:09,970][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003712] [Batch 00420/00823] [00:05:16/00:05:03, 0.753s/it]: train_loss_raw=1.7467, running_loss=1.8063, LR=0.000100
[2025-08-26 09:20:16,010][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003720] [Batch 00428/00823] [00:05:22/00:04:57, 0.753s/it]: train_loss_raw=1.8129, running_loss=1.8012, LR=0.000100
[2025-08-26 09:20:22,112][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003728] [Batch 00436/00823] [00:05:28/00:04:51, 0.753s/it]: train_loss_raw=1.8242, running_loss=1.8015, LR=0.000100
[2025-08-26 09:20:28,143][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003736] [Batch 00444/00823] [00:05:34/00:04:45, 0.753s/it]: train_loss_raw=1.7438, running_loss=1.8014, LR=0.000100
[2025-08-26 09:20:34,199][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003744] [Batch 00452/00823] [00:05:40/00:04:39, 0.753s/it]: train_loss_raw=1.8523, running_loss=1.8011, LR=0.000100
[2025-08-26 09:20:40,358][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003752] [Batch 00460/00823] [00:05:46/00:04:33, 0.753s/it]: train_loss_raw=1.7819, running_loss=1.7997, LR=0.000100
[2025-08-26 09:20:46,429][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003760] [Batch 00468/00823] [00:05:52/00:04:27, 0.753s/it]: train_loss_raw=1.8438, running_loss=1.7997, LR=0.000100
[2025-08-26 09:20:52,496][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003768] [Batch 00476/00823] [00:05:58/00:04:21, 0.753s/it]: train_loss_raw=1.8193, running_loss=1.7995, LR=0.000100
[2025-08-26 09:20:58,470][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003776] [Batch 00484/00823] [00:06:04/00:04:15, 0.753s/it]: train_loss_raw=1.7763, running_loss=1.8030, LR=0.000100
[2025-08-26 09:21:04,424][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003784] [Batch 00492/00823] [00:06:10/00:04:09, 0.753s/it]: train_loss_raw=1.7109, running_loss=1.8022, LR=0.000100
[2025-08-26 09:21:10,451][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003792] [Batch 00500/00823] [00:06:16/00:04:03, 0.753s/it]: train_loss_raw=1.7801, running_loss=1.7996, LR=0.000100
[2025-08-26 09:21:16,489][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003800] [Batch 00508/00823] [00:06:22/00:03:57, 0.753s/it]: train_loss_raw=1.7420, running_loss=1.7968, LR=0.000100
[2025-08-26 09:21:22,563][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003808] [Batch 00516/00823] [00:06:28/00:03:51, 0.753s/it]: train_loss_raw=1.7671, running_loss=1.7984, LR=0.000100
[2025-08-26 09:21:28,646][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003816] [Batch 00524/00823] [00:06:34/00:03:45, 0.753s/it]: train_loss_raw=1.8788, running_loss=1.7984, LR=0.000100
[2025-08-26 09:21:34,700][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003824] [Batch 00532/00823] [00:06:40/00:03:39, 0.753s/it]: train_loss_raw=1.7974, running_loss=1.7971, LR=0.000100
[2025-08-26 09:21:40,778][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003832] [Batch 00540/00823] [00:06:46/00:03:33, 0.753s/it]: train_loss_raw=1.8394, running_loss=1.7973, LR=0.000100
[2025-08-26 09:21:46,792][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003840] [Batch 00548/00823] [00:06:52/00:03:27, 0.753s/it]: train_loss_raw=1.7840, running_loss=1.7945, LR=0.000100
[2025-08-26 09:21:52,786][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003848] [Batch 00556/00823] [00:06:58/00:03:21, 0.753s/it]: train_loss_raw=1.7831, running_loss=1.7946, LR=0.000100
[2025-08-26 09:21:58,780][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003856] [Batch 00564/00823] [00:07:04/00:03:15, 0.753s/it]: train_loss_raw=1.8269, running_loss=1.7951, LR=0.000100
[2025-08-26 09:22:04,800][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003864] [Batch 00572/00823] [00:07:10/00:03:09, 0.753s/it]: train_loss_raw=1.9052, running_loss=1.7950, LR=0.000100
[2025-08-26 09:22:10,939][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003872] [Batch 00580/00823] [00:07:17/00:03:03, 0.754s/it]: train_loss_raw=1.8024, running_loss=1.7962, LR=0.000100
[2025-08-26 09:22:17,031][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003880] [Batch 00588/00823] [00:07:23/00:02:57, 0.754s/it]: train_loss_raw=1.7496, running_loss=1.7942, LR=0.000100
[2025-08-26 09:22:23,013][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003888] [Batch 00596/00823] [00:07:29/00:02:51, 0.754s/it]: train_loss_raw=1.8804, running_loss=1.7956, LR=0.000100
[2025-08-26 09:22:29,168][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003896] [Batch 00604/00823] [00:07:35/00:02:45, 0.754s/it]: train_loss_raw=1.9379, running_loss=1.7964, LR=0.000100
[2025-08-26 09:22:35,265][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003904] [Batch 00612/00823] [00:07:41/00:02:39, 0.754s/it]: train_loss_raw=1.7215, running_loss=1.7936, LR=0.000100
[2025-08-26 09:22:41,357][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003912] [Batch 00620/00823] [00:07:47/00:02:33, 0.754s/it]: train_loss_raw=1.8791, running_loss=1.7927, LR=0.000100
[2025-08-26 09:22:47,457][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003920] [Batch 00628/00823] [00:07:53/00:02:27, 0.754s/it]: train_loss_raw=1.8521, running_loss=1.7930, LR=0.000100
[2025-08-26 09:22:53,543][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003928] [Batch 00636/00823] [00:07:59/00:02:21, 0.754s/it]: train_loss_raw=1.7574, running_loss=1.7915, LR=0.000100
[2025-08-26 09:22:59,623][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003936] [Batch 00644/00823] [00:08:05/00:02:15, 0.754s/it]: train_loss_raw=1.7002, running_loss=1.7911, LR=0.000100
[2025-08-26 09:23:05,824][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003944] [Batch 00652/00823] [00:08:11/00:02:09, 0.754s/it]: train_loss_raw=1.7784, running_loss=1.7892, LR=0.000100
[2025-08-26 09:23:11,975][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003952] [Batch 00660/00823] [00:08:18/00:02:03, 0.755s/it]: train_loss_raw=1.7436, running_loss=1.7884, LR=0.000100
[2025-08-26 09:23:18,094][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003960] [Batch 00668/00823] [00:08:24/00:01:56, 0.755s/it]: train_loss_raw=1.8464, running_loss=1.7885, LR=0.000100
[2025-08-26 09:23:24,092][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003968] [Batch 00676/00823] [00:08:30/00:01:50, 0.755s/it]: train_loss_raw=1.7953, running_loss=1.7868, LR=0.000100
[2025-08-26 09:23:30,138][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003976] [Batch 00684/00823] [00:08:36/00:01:44, 0.755s/it]: train_loss_raw=1.8070, running_loss=1.7863, LR=0.000100
[2025-08-26 09:23:36,178][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003984] [Batch 00692/00823] [00:08:42/00:01:38, 0.755s/it]: train_loss_raw=1.7940, running_loss=1.7864, LR=0.000100
[2025-08-26 09:23:42,286][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003992] [Batch 00700/00823] [00:08:48/00:01:32, 0.755s/it]: train_loss_raw=1.7774, running_loss=1.7838, LR=0.000100
[2025-08-26 09:23:48,350][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004000] [Batch 00708/00823] [00:08:54/00:01:26, 0.755s/it]: train_loss_raw=1.7793, running_loss=1.7852, LR=0.000100
[2025-08-26 09:23:58,414][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004008] [Batch 00716/00823] [00:09:04/00:01:21, 0.761s/it]: train_loss_raw=1.8294, running_loss=1.7840, LR=0.000100
[2025-08-26 09:24:04,471][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004016] [Batch 00724/00823] [00:09:10/00:01:15, 0.760s/it]: train_loss_raw=1.7052, running_loss=1.7820, LR=0.000100
[2025-08-26 09:24:10,507][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004024] [Batch 00732/00823] [00:09:16/00:01:09, 0.760s/it]: train_loss_raw=1.7553, running_loss=1.7833, LR=0.000100
[2025-08-26 09:24:16,592][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004032] [Batch 00740/00823] [00:09:22/00:01:03, 0.760s/it]: train_loss_raw=1.8324, running_loss=1.7861, LR=0.000100
[2025-08-26 09:24:22,666][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004040] [Batch 00748/00823] [00:09:28/00:00:57, 0.760s/it]: train_loss_raw=1.7920, running_loss=1.7881, LR=0.000100
[2025-08-26 09:24:28,738][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004048] [Batch 00756/00823] [00:09:34/00:00:50, 0.760s/it]: train_loss_raw=1.7298, running_loss=1.7853, LR=0.000100
[2025-08-26 09:24:34,787][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004056] [Batch 00764/00823] [00:09:40/00:00:44, 0.760s/it]: train_loss_raw=1.7922, running_loss=1.7838, LR=0.000100
[2025-08-26 09:24:40,863][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004064] [Batch 00772/00823] [00:09:46/00:00:38, 0.760s/it]: train_loss_raw=1.7429, running_loss=1.7837, LR=0.000100
[2025-08-26 09:24:46,924][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004072] [Batch 00780/00823] [00:09:53/00:00:32, 0.760s/it]: train_loss_raw=1.7324, running_loss=1.7823, LR=0.000100
[2025-08-26 09:24:52,987][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004080] [Batch 00788/00823] [00:09:59/00:00:26, 0.760s/it]: train_loss_raw=1.6915, running_loss=1.7818, LR=0.000100
[2025-08-26 09:24:59,066][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004088] [Batch 00796/00823] [00:10:05/00:00:20, 0.760s/it]: train_loss_raw=1.7574, running_loss=1.7821, LR=0.000100
[2025-08-26 09:25:05,167][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004096] [Batch 00804/00823] [00:10:11/00:00:14, 0.760s/it]: train_loss_raw=1.6472, running_loss=1.7778, LR=0.000100
[2025-08-26 09:25:11,325][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004104] [Batch 00812/00823] [00:10:17/00:00:08, 0.760s/it]: train_loss_raw=1.6914, running_loss=1.7756, LR=0.000100
[2025-08-26 09:25:17,415][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004112] [Batch 00820/00823] [00:10:23/00:00:02, 0.760s/it]: train_loss_raw=1.7784, running_loss=1.7761, LR=0.000100
[2025-08-26 09:25:19,912][__main__][INFO] - [VALIDATION] [Epoch 04/29] Starting validation.
[2025-08-26 09:25:31,816][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 004116] [Batch 00007/00013] [00:00:11/00:00:07, 1.488s/it]
[2025-08-26 09:25:39,121][__main__][INFO] - [VALIDATION] [Epoch 04/29] train_loss=1.77525, valid_loss=1.77487
[2025-08-26 09:25:39,121][__main__][INFO] - [VALIDATION] [Epoch 04/29] Metrics:
[2025-08-26 09:25:39,121][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_er      0.757
[2025-08-26 09:25:39,121][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_prec    0.027
[2025-08-26 09:25:39,122][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_recall  0.029
[2025-08-26 09:25:39,122][__main__][INFO] - [VALIDATION] [Epoch 04/29] - pep_recall 0.002
[2025-08-26 09:25:39,124][__main__][INFO] - [TRAIN] [Epoch 04/29] Epoch complete, total time 00:53:02, remaining time 04:25:14, 00:10:36 per epoch
[2025-08-26 09:25:42,619][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004120] [Batch 00005/00823] [00:00:03/00:08:45, 0.643s/it]: train_loss_raw=1.7829, running_loss=1.8679, LR=0.000100
[2025-08-26 09:25:48,699][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004128] [Batch 00013/00823] [00:00:09/00:09:38, 0.715s/it]: train_loss_raw=1.7960, running_loss=1.8589, LR=0.000100
[2025-08-26 09:25:54,747][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004136] [Batch 00021/00823] [00:00:15/00:09:45, 0.731s/it]: train_loss_raw=1.6858, running_loss=1.8532, LR=0.000100
[2025-08-26 09:26:00,826][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004144] [Batch 00029/00823] [00:00:21/00:09:46, 0.739s/it]: train_loss_raw=1.6908, running_loss=1.8445, LR=0.000100
[2025-08-26 09:26:06,871][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004152] [Batch 00037/00823] [00:00:27/00:09:43, 0.742s/it]: train_loss_raw=1.7975, running_loss=1.8391, LR=0.000100
[2025-08-26 09:26:12,903][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004160] [Batch 00045/00823] [00:00:33/00:09:39, 0.744s/it]: train_loss_raw=1.8287, running_loss=1.8344, LR=0.000100
[2025-08-26 09:26:18,929][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004168] [Batch 00053/00823] [00:00:39/00:09:34, 0.746s/it]: train_loss_raw=1.7511, running_loss=1.8277, LR=0.000100
[2025-08-26 09:26:25,010][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004176] [Batch 00061/00823] [00:00:45/00:09:29, 0.748s/it]: train_loss_raw=1.8696, running_loss=1.8247, LR=0.000100
[2025-08-26 09:26:31,104][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004184] [Batch 00069/00823] [00:00:51/00:09:24, 0.749s/it]: train_loss_raw=1.8082, running_loss=1.8220, LR=0.000100
[2025-08-26 09:26:37,195][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004192] [Batch 00077/00823] [00:00:57/00:09:19, 0.751s/it]: train_loss_raw=1.7791, running_loss=1.8183, LR=0.000100
[2025-08-26 09:26:43,223][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004200] [Batch 00085/00823] [00:01:03/00:09:14, 0.751s/it]: train_loss_raw=1.7051, running_loss=1.8140, LR=0.000100
[2025-08-26 09:26:49,294][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004208] [Batch 00093/00823] [00:01:09/00:09:08, 0.751s/it]: train_loss_raw=1.7900, running_loss=1.8113, LR=0.000100
[2025-08-26 09:26:55,371][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004216] [Batch 00101/00823] [00:01:15/00:09:03, 0.752s/it]: train_loss_raw=1.7248, running_loss=1.8080, LR=0.000100
[2025-08-26 09:27:01,461][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004224] [Batch 00109/00823] [00:01:22/00:08:57, 0.753s/it]: train_loss_raw=1.7139, running_loss=1.8048, LR=0.000100
[2025-08-26 09:27:07,551][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004232] [Batch 00117/00823] [00:01:28/00:08:51, 0.753s/it]: train_loss_raw=1.7098, running_loss=1.8009, LR=0.000100
[2025-08-26 09:27:13,570][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004240] [Batch 00125/00823] [00:01:34/00:08:45, 0.753s/it]: train_loss_raw=1.7577, running_loss=1.7971, LR=0.000100
[2025-08-26 09:27:19,590][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004248] [Batch 00133/00823] [00:01:40/00:08:39, 0.753s/it]: train_loss_raw=1.7658, running_loss=1.7948, LR=0.000100
[2025-08-26 09:27:25,599][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004256] [Batch 00141/00823] [00:01:46/00:08:33, 0.753s/it]: train_loss_raw=1.6751, running_loss=1.7917, LR=0.000100
[2025-08-26 09:27:31,606][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004264] [Batch 00149/00823] [00:01:52/00:08:27, 0.753s/it]: train_loss_raw=1.7558, running_loss=1.7900, LR=0.000100
[2025-08-26 09:27:37,638][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004272] [Batch 00157/00823] [00:01:58/00:08:21, 0.753s/it]: train_loss_raw=1.6774, running_loss=1.7868, LR=0.000100
[2025-08-26 09:27:43,664][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004280] [Batch 00165/00823] [00:02:04/00:08:15, 0.753s/it]: train_loss_raw=1.7377, running_loss=1.7866, LR=0.000100
[2025-08-26 09:27:49,742][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004288] [Batch 00173/00823] [00:02:10/00:08:09, 0.753s/it]: train_loss_raw=1.7536, running_loss=1.7861, LR=0.000100
[2025-08-26 09:27:55,794][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004296] [Batch 00181/00823] [00:02:16/00:08:03, 0.754s/it]: train_loss_raw=1.7970, running_loss=1.7844, LR=0.000100
[2025-08-26 09:28:01,877][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004304] [Batch 00189/00823] [00:02:22/00:07:57, 0.754s/it]: train_loss_raw=1.7770, running_loss=1.7850, LR=0.000100
[2025-08-26 09:28:07,838][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004312] [Batch 00197/00823] [00:02:28/00:07:51, 0.753s/it]: train_loss_raw=1.7541, running_loss=1.7833, LR=0.000100
[2025-08-26 09:28:13,875][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004320] [Batch 00205/00823] [00:02:34/00:07:45, 0.754s/it]: train_loss_raw=1.8219, running_loss=1.7837, LR=0.000100
[2025-08-26 09:28:19,950][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004328] [Batch 00213/00823] [00:02:40/00:07:39, 0.754s/it]: train_loss_raw=1.7472, running_loss=1.7821, LR=0.000100
[2025-08-26 09:28:25,981][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004336] [Batch 00221/00823] [00:02:46/00:07:33, 0.754s/it]: train_loss_raw=1.8131, running_loss=1.7807, LR=0.000100
[2025-08-26 09:28:31,983][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004344] [Batch 00229/00823] [00:02:52/00:07:27, 0.754s/it]: train_loss_raw=1.7457, running_loss=1.7779, LR=0.000100
[2025-08-26 09:28:38,041][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004352] [Batch 00237/00823] [00:02:58/00:07:21, 0.754s/it]: train_loss_raw=1.7498, running_loss=1.7775, LR=0.000100
[2025-08-26 09:28:44,105][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004360] [Batch 00245/00823] [00:03:04/00:07:15, 0.754s/it]: train_loss_raw=1.7990, running_loss=1.7759, LR=0.000100
[2025-08-26 09:28:50,193][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004368] [Batch 00253/00823] [00:03:10/00:07:09, 0.754s/it]: train_loss_raw=1.7973, running_loss=1.7739, LR=0.000100
[2025-08-26 09:28:56,259][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004376] [Batch 00261/00823] [00:03:16/00:07:03, 0.754s/it]: train_loss_raw=1.6970, running_loss=1.7744, LR=0.000100
[2025-08-26 09:29:02,263][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004384] [Batch 00269/00823] [00:03:22/00:06:57, 0.754s/it]: train_loss_raw=1.7467, running_loss=1.7735, LR=0.000100
[2025-08-26 09:29:08,243][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004392] [Batch 00277/00823] [00:03:28/00:06:51, 0.754s/it]: train_loss_raw=1.7427, running_loss=1.7724, LR=0.000100
[2025-08-26 09:29:14,328][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004400] [Batch 00285/00823] [00:03:34/00:06:45, 0.754s/it]: train_loss_raw=1.7027, running_loss=1.7710, LR=0.000100
[2025-08-26 09:29:20,438][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004408] [Batch 00293/00823] [00:03:41/00:06:39, 0.754s/it]: train_loss_raw=1.7505, running_loss=1.7704, LR=0.000100
[2025-08-26 09:29:26,522][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004416] [Batch 00301/00823] [00:03:47/00:06:33, 0.755s/it]: train_loss_raw=1.7051, running_loss=1.7693, LR=0.000100
[2025-08-26 09:29:32,593][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004424] [Batch 00309/00823] [00:03:53/00:06:27, 0.755s/it]: train_loss_raw=1.7821, running_loss=1.7697, LR=0.000100
[2025-08-26 09:29:38,678][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004432] [Batch 00317/00823] [00:03:59/00:06:21, 0.755s/it]: train_loss_raw=1.7262, running_loss=1.7657, LR=0.000100
[2025-08-26 09:29:44,757][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004440] [Batch 00325/00823] [00:04:05/00:06:15, 0.755s/it]: train_loss_raw=1.8946, running_loss=1.7659, LR=0.000100
[2025-08-26 09:29:50,811][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004448] [Batch 00333/00823] [00:04:11/00:06:09, 0.755s/it]: train_loss_raw=1.7838, running_loss=1.7641, LR=0.000100
[2025-08-26 09:29:56,850][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004456] [Batch 00341/00823] [00:04:17/00:06:03, 0.755s/it]: train_loss_raw=1.7317, running_loss=1.7621, LR=0.000100
[2025-08-26 09:30:02,860][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004464] [Batch 00349/00823] [00:04:23/00:05:57, 0.755s/it]: train_loss_raw=1.6370, running_loss=1.7591, LR=0.000100
[2025-08-26 09:30:08,898][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004472] [Batch 00357/00823] [00:04:29/00:05:51, 0.755s/it]: train_loss_raw=1.6436, running_loss=1.7584, LR=0.000100
[2025-08-26 09:30:14,972][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004480] [Batch 00365/00823] [00:04:35/00:05:45, 0.755s/it]: train_loss_raw=1.7243, running_loss=1.7565, LR=0.000100
[2025-08-26 09:30:21,064][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004488] [Batch 00373/00823] [00:04:41/00:05:39, 0.755s/it]: train_loss_raw=1.7110, running_loss=1.7548, LR=0.000100
[2025-08-26 09:30:27,154][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004496] [Batch 00381/00823] [00:04:47/00:05:33, 0.755s/it]: train_loss_raw=1.7352, running_loss=1.7522, LR=0.000100
[2025-08-26 09:30:33,219][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004504] [Batch 00389/00823] [00:04:53/00:05:27, 0.755s/it]: train_loss_raw=1.7771, running_loss=1.7522, LR=0.000100
[2025-08-26 09:30:39,217][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004512] [Batch 00397/00823] [00:04:59/00:05:21, 0.755s/it]: train_loss_raw=1.6682, running_loss=1.7515, LR=0.000100
[2025-08-26 09:30:45,339][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004520] [Batch 00405/00823] [00:05:05/00:05:15, 0.755s/it]: train_loss_raw=1.6842, running_loss=1.7494, LR=0.000100
[2025-08-26 09:30:51,389][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004528] [Batch 00413/00823] [00:05:11/00:05:09, 0.755s/it]: train_loss_raw=1.8100, running_loss=1.7507, LR=0.000100
[2025-08-26 09:30:57,378][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004536] [Batch 00421/00823] [00:05:17/00:05:03, 0.755s/it]: train_loss_raw=1.7198, running_loss=1.7500, LR=0.000100
[2025-08-26 09:31:03,407][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004544] [Batch 00429/00823] [00:05:24/00:04:57, 0.755s/it]: train_loss_raw=1.8177, running_loss=1.7477, LR=0.000100
[2025-08-26 09:31:09,443][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004552] [Batch 00437/00823] [00:05:30/00:04:51, 0.755s/it]: train_loss_raw=1.7286, running_loss=1.7465, LR=0.000100
[2025-08-26 09:31:15,465][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004560] [Batch 00445/00823] [00:05:36/00:04:45, 0.755s/it]: train_loss_raw=1.6904, running_loss=1.7464, LR=0.000100
[2025-08-26 09:31:21,470][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004568] [Batch 00453/00823] [00:05:42/00:04:39, 0.755s/it]: train_loss_raw=1.7883, running_loss=1.7463, LR=0.000100
[2025-08-26 09:31:27,512][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004576] [Batch 00461/00823] [00:05:48/00:04:33, 0.755s/it]: train_loss_raw=1.7455, running_loss=1.7472, LR=0.000100
[2025-08-26 09:31:33,588][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004584] [Batch 00469/00823] [00:05:54/00:04:27, 0.755s/it]: train_loss_raw=1.7893, running_loss=1.7476, LR=0.000100
[2025-08-26 09:31:39,644][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004592] [Batch 00477/00823] [00:06:00/00:04:21, 0.755s/it]: train_loss_raw=1.7098, running_loss=1.7475, LR=0.000100
[2025-08-26 09:31:45,753][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004600] [Batch 00485/00823] [00:06:06/00:04:15, 0.755s/it]: train_loss_raw=1.7113, running_loss=1.7485, LR=0.000100
[2025-08-26 09:31:51,828][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004608] [Batch 00493/00823] [00:06:12/00:04:09, 0.755s/it]: train_loss_raw=1.6757, running_loss=1.7464, LR=0.000100
[2025-08-26 09:31:57,922][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004616] [Batch 00501/00823] [00:06:18/00:04:03, 0.756s/it]: train_loss_raw=1.7344, running_loss=1.7469, LR=0.000100
[2025-08-26 09:32:03,972][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004624] [Batch 00509/00823] [00:06:24/00:03:57, 0.756s/it]: train_loss_raw=1.6876, running_loss=1.7491, LR=0.000100
[2025-08-26 09:32:10,111][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004632] [Batch 00517/00823] [00:06:30/00:03:51, 0.756s/it]: train_loss_raw=1.6850, running_loss=1.7482, LR=0.000100
[2025-08-26 09:32:16,079][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004640] [Batch 00525/00823] [00:06:36/00:03:45, 0.756s/it]: train_loss_raw=1.7581, running_loss=1.7472, LR=0.000100
[2025-08-26 09:32:21,732][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004648] [Batch 00533/00823] [00:06:42/00:03:38, 0.755s/it]: train_loss_raw=1.8644, running_loss=1.7449, LR=0.000100
[2025-08-26 09:32:27,291][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004656] [Batch 00541/00823] [00:06:47/00:03:32, 0.754s/it]: train_loss_raw=1.7586, running_loss=1.7427, LR=0.000100
[2025-08-26 09:32:33,265][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004664] [Batch 00549/00823] [00:06:53/00:03:26, 0.754s/it]: train_loss_raw=1.6555, running_loss=1.7412, LR=0.000100
[2025-08-26 09:32:39,315][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004672] [Batch 00557/00823] [00:06:59/00:03:20, 0.754s/it]: train_loss_raw=1.6551, running_loss=1.7385, LR=0.000100
[2025-08-26 09:32:45,413][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004680] [Batch 00565/00823] [00:07:06/00:03:14, 0.754s/it]: train_loss_raw=1.7450, running_loss=1.7368, LR=0.000100
[2025-08-26 09:32:51,466][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004688] [Batch 00573/00823] [00:07:12/00:03:08, 0.754s/it]: train_loss_raw=1.7803, running_loss=1.7369, LR=0.000100
[2025-08-26 09:32:57,535][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004696] [Batch 00581/00823] [00:07:18/00:03:02, 0.754s/it]: train_loss_raw=1.7050, running_loss=1.7358, LR=0.000100
[2025-08-26 09:33:03,601][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004704] [Batch 00589/00823] [00:07:24/00:02:56, 0.754s/it]: train_loss_raw=1.7504, running_loss=1.7365, LR=0.000100
[2025-08-26 09:33:09,686][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004712] [Batch 00597/00823] [00:07:30/00:02:50, 0.754s/it]: train_loss_raw=1.7434, running_loss=1.7351, LR=0.000100
[2025-08-26 09:33:15,813][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004720] [Batch 00605/00823] [00:07:36/00:02:44, 0.754s/it]: train_loss_raw=1.7044, running_loss=1.7331, LR=0.000100
[2025-08-26 09:33:21,887][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004728] [Batch 00613/00823] [00:07:42/00:02:38, 0.754s/it]: train_loss_raw=1.7581, running_loss=1.7337, LR=0.000100
[2025-08-26 09:33:27,941][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004736] [Batch 00621/00823] [00:07:48/00:02:32, 0.754s/it]: train_loss_raw=1.7086, running_loss=1.7317, LR=0.000100
[2025-08-26 09:33:34,005][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004744] [Batch 00629/00823] [00:07:54/00:02:26, 0.755s/it]: train_loss_raw=1.8503, running_loss=1.7324, LR=0.000100
[2025-08-26 09:33:40,063][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004752] [Batch 00637/00823] [00:08:00/00:02:20, 0.755s/it]: train_loss_raw=1.7462, running_loss=1.7317, LR=0.000100
[2025-08-26 09:33:46,083][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004760] [Batch 00645/00823] [00:08:06/00:02:14, 0.755s/it]: train_loss_raw=1.7411, running_loss=1.7336, LR=0.000100
[2025-08-26 09:33:52,123][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004768] [Batch 00653/00823] [00:08:12/00:02:08, 0.755s/it]: train_loss_raw=1.7709, running_loss=1.7311, LR=0.000100
[2025-08-26 09:33:58,211][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004776] [Batch 00661/00823] [00:08:18/00:02:02, 0.755s/it]: train_loss_raw=1.6477, running_loss=1.7301, LR=0.000100
[2025-08-26 09:34:04,286][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004784] [Batch 00669/00823] [00:08:24/00:01:56, 0.755s/it]: train_loss_raw=1.6904, running_loss=1.7279, LR=0.000100
[2025-08-26 09:34:10,416][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004792] [Batch 00677/00823] [00:08:31/00:01:50, 0.755s/it]: train_loss_raw=1.6706, running_loss=1.7258, LR=0.000100
[2025-08-26 09:34:16,469][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004800] [Batch 00685/00823] [00:08:37/00:01:44, 0.755s/it]: train_loss_raw=1.7013, running_loss=1.7249, LR=0.000100
[2025-08-26 09:34:22,487][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004808] [Batch 00693/00823] [00:08:43/00:01:38, 0.755s/it]: train_loss_raw=1.8204, running_loss=1.7247, LR=0.000100
[2025-08-26 09:34:28,573][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004816] [Batch 00701/00823] [00:08:49/00:01:32, 0.755s/it]: train_loss_raw=1.7282, running_loss=1.7247, LR=0.000100
[2025-08-26 09:34:34,623][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004824] [Batch 00709/00823] [00:08:55/00:01:26, 0.755s/it]: train_loss_raw=1.7219, running_loss=1.7264, LR=0.000100
[2025-08-26 09:34:40,750][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004832] [Batch 00717/00823] [00:09:01/00:01:20, 0.755s/it]: train_loss_raw=1.6041, running_loss=1.7266, LR=0.000100
[2025-08-26 09:34:46,935][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004840] [Batch 00725/00823] [00:09:07/00:01:14, 0.755s/it]: train_loss_raw=1.7267, running_loss=1.7277, LR=0.000100
[2025-08-26 09:34:53,088][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004848] [Batch 00733/00823] [00:09:13/00:01:07, 0.755s/it]: train_loss_raw=1.7484, running_loss=1.7277, LR=0.000100
[2025-08-26 09:34:59,137][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004856] [Batch 00741/00823] [00:09:19/00:01:01, 0.755s/it]: train_loss_raw=1.6072, running_loss=1.7269, LR=0.000100
[2025-08-26 09:35:05,184][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004864] [Batch 00749/00823] [00:09:25/00:00:55, 0.755s/it]: train_loss_raw=1.7425, running_loss=1.7265, LR=0.000100
[2025-08-26 09:35:11,205][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004872] [Batch 00757/00823] [00:09:31/00:00:49, 0.755s/it]: train_loss_raw=1.7856, running_loss=1.7268, LR=0.000100
[2025-08-26 09:35:17,204][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004880] [Batch 00765/00823] [00:09:37/00:00:43, 0.755s/it]: train_loss_raw=1.7462, running_loss=1.7255, LR=0.000100
[2025-08-26 09:35:23,246][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004888] [Batch 00773/00823] [00:09:43/00:00:37, 0.755s/it]: train_loss_raw=1.7585, running_loss=1.7261, LR=0.000100
[2025-08-26 09:35:29,296][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004896] [Batch 00781/00823] [00:09:49/00:00:31, 0.755s/it]: train_loss_raw=1.7296, running_loss=1.7242, LR=0.000100
[2025-08-26 09:35:35,362][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004904] [Batch 00789/00823] [00:09:55/00:00:25, 0.755s/it]: train_loss_raw=1.7213, running_loss=1.7256, LR=0.000100
[2025-08-26 09:35:41,435][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004912] [Batch 00797/00823] [00:10:02/00:00:19, 0.755s/it]: train_loss_raw=1.7395, running_loss=1.7246, LR=0.000100
[2025-08-26 09:35:47,490][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004920] [Batch 00805/00823] [00:10:08/00:00:13, 0.755s/it]: train_loss_raw=1.7419, running_loss=1.7245, LR=0.000100
[2025-08-26 09:35:53,492][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004928] [Batch 00813/00823] [00:10:14/00:00:07, 0.755s/it]: train_loss_raw=1.7281, running_loss=1.7236, LR=0.000100
[2025-08-26 09:35:59,522][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004936] [Batch 00821/00823] [00:10:20/00:00:01, 0.755s/it]: train_loss_raw=1.6379, running_loss=1.7222, LR=0.000100
[2025-08-26 09:36:07,603][__main__][INFO] - [VALIDATION] [Epoch 05/29] Starting validation.
[2025-08-26 09:36:19,569][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 004939] [Batch 00007/00013] [00:00:11/00:00:07, 1.496s/it]
[2025-08-26 09:36:26,629][__main__][INFO] - [VALIDATION] [Epoch 05/29] train_loss=1.72164, valid_loss=1.75467
[2025-08-26 09:36:26,629][__main__][INFO] - [VALIDATION] [Epoch 05/29] Metrics:
[2025-08-26 09:36:26,629][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_er      0.740
[2025-08-26 09:36:26,630][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_prec    0.031
[2025-08-26 09:36:26,630][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_recall  0.032
[2025-08-26 09:36:26,630][__main__][INFO] - [VALIDATION] [Epoch 05/29] - pep_recall 0.001
[2025-08-26 09:36:26,632][__main__][INFO] - [TRAIN] [Epoch 05/29] Epoch complete, total time 01:03:50, remaining time 04:15:21, 00:10:38 per epoch
[2025-08-26 09:36:30,875][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004944] [Batch 00006/00823] [00:00:03/00:09:00, 0.662s/it]: train_loss_raw=1.7347, running_loss=1.7313, LR=0.000100
[2025-08-26 09:36:37,022][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004952] [Batch 00014/00823] [00:00:10/00:09:44, 0.723s/it]: train_loss_raw=1.6487, running_loss=1.7272, LR=0.000100
[2025-08-26 09:36:43,079][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004960] [Batch 00022/00823] [00:00:16/00:09:48, 0.735s/it]: train_loss_raw=1.5534, running_loss=1.7255, LR=0.000100
[2025-08-26 09:36:49,112][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004968] [Batch 00030/00823] [00:00:22/00:09:47, 0.740s/it]: train_loss_raw=1.7065, running_loss=1.7228, LR=0.000100
[2025-08-26 09:36:55,017][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004976] [Batch 00038/00823] [00:00:28/00:09:40, 0.740s/it]: train_loss_raw=1.7272, running_loss=1.7216, LR=0.000100
[2025-08-26 09:37:01,017][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004984] [Batch 00046/00823] [00:00:34/00:09:36, 0.742s/it]: train_loss_raw=1.7930, running_loss=1.7203, LR=0.000100
[2025-08-26 09:37:07,070][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004992] [Batch 00054/00823] [00:00:40/00:09:32, 0.744s/it]: train_loss_raw=1.6792, running_loss=1.7179, LR=0.000100
[2025-08-26 09:37:13,142][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005000] [Batch 00062/00823] [00:00:46/00:09:27, 0.746s/it]: train_loss_raw=1.6977, running_loss=1.7152, LR=0.000100
[2025-08-26 09:37:19,241][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005008] [Batch 00070/00823] [00:00:52/00:09:23, 0.748s/it]: train_loss_raw=1.7495, running_loss=1.7149, LR=0.000100
[2025-08-26 09:37:25,277][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005016] [Batch 00078/00823] [00:00:58/00:09:17, 0.748s/it]: train_loss_raw=1.6622, running_loss=1.7127, LR=0.000100
[2025-08-26 09:37:31,288][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005024] [Batch 00086/00823] [00:01:04/00:09:11, 0.749s/it]: train_loss_raw=1.7066, running_loss=1.7113, LR=0.000100
[2025-08-26 09:37:37,364][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005032] [Batch 00094/00823] [00:01:10/00:09:06, 0.750s/it]: train_loss_raw=1.7297, running_loss=1.7092, LR=0.000100
[2025-08-26 09:37:43,422][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005040] [Batch 00102/00823] [00:01:16/00:09:00, 0.750s/it]: train_loss_raw=1.7334, running_loss=1.7081, LR=0.000100
[2025-08-26 09:37:49,461][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005048] [Batch 00110/00823] [00:01:22/00:08:55, 0.751s/it]: train_loss_raw=1.6875, running_loss=1.7061, LR=0.000100
[2025-08-26 09:37:55,409][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005056] [Batch 00118/00823] [00:01:28/00:08:48, 0.750s/it]: train_loss_raw=1.6547, running_loss=1.7051, LR=0.000100
[2025-08-26 09:38:01,413][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005064] [Batch 00126/00823] [00:01:34/00:08:42, 0.750s/it]: train_loss_raw=1.6637, running_loss=1.7038, LR=0.000100
[2025-08-26 09:38:07,443][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005072] [Batch 00134/00823] [00:01:40/00:08:36, 0.750s/it]: train_loss_raw=1.6649, running_loss=1.7023, LR=0.000100
[2025-08-26 09:38:13,473][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005080] [Batch 00142/00823] [00:01:46/00:08:31, 0.751s/it]: train_loss_raw=1.6629, running_loss=1.6998, LR=0.000100
[2025-08-26 09:38:19,552][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005088] [Batch 00150/00823] [00:01:52/00:08:25, 0.751s/it]: train_loss_raw=1.6522, running_loss=1.6982, LR=0.000100
[2025-08-26 09:38:25,558][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005096] [Batch 00158/00823] [00:01:58/00:08:19, 0.751s/it]: train_loss_raw=1.7000, running_loss=1.6981, LR=0.000100
[2025-08-26 09:38:31,556][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005104] [Batch 00166/00823] [00:02:04/00:08:13, 0.751s/it]: train_loss_raw=1.6855, running_loss=1.6974, LR=0.000100
[2025-08-26 09:38:37,586][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005112] [Batch 00174/00823] [00:02:10/00:08:07, 0.751s/it]: train_loss_raw=1.7255, running_loss=1.6972, LR=0.000100
[2025-08-26 09:38:43,667][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005120] [Batch 00182/00823] [00:02:16/00:08:01, 0.751s/it]: train_loss_raw=1.6913, running_loss=1.6972, LR=0.000100
[2025-08-26 09:38:49,773][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005128] [Batch 00190/00823] [00:02:22/00:07:55, 0.752s/it]: train_loss_raw=1.6264, running_loss=1.6946, LR=0.000100
[2025-08-26 09:38:55,871][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005136] [Batch 00198/00823] [00:02:28/00:07:50, 0.752s/it]: train_loss_raw=1.6637, running_loss=1.6949, LR=0.000100
[2025-08-26 09:39:01,915][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005144] [Batch 00206/00823] [00:02:35/00:07:44, 0.752s/it]: train_loss_raw=1.7516, running_loss=1.6954, LR=0.000100
[2025-08-26 09:39:07,981][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005152] [Batch 00214/00823] [00:02:41/00:07:38, 0.753s/it]: train_loss_raw=1.7652, running_loss=1.6961, LR=0.000100
[2025-08-26 09:39:14,062][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005160] [Batch 00222/00823] [00:02:47/00:07:32, 0.753s/it]: train_loss_raw=1.6446, running_loss=1.6957, LR=0.000100
[2025-08-26 09:39:20,188][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005168] [Batch 00230/00823] [00:02:53/00:07:26, 0.753s/it]: train_loss_raw=1.7107, running_loss=1.6939, LR=0.000100
[2025-08-26 09:39:26,208][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005176] [Batch 00238/00823] [00:02:59/00:07:20, 0.753s/it]: train_loss_raw=1.7459, running_loss=1.6947, LR=0.000100
[2025-08-26 09:39:32,321][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005184] [Batch 00246/00823] [00:03:05/00:07:14, 0.754s/it]: train_loss_raw=1.7265, running_loss=1.6946, LR=0.000100
[2025-08-26 09:39:38,379][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005192] [Batch 00254/00823] [00:03:11/00:07:08, 0.754s/it]: train_loss_raw=1.7129, running_loss=1.6942, LR=0.000100
[2025-08-26 09:39:44,420][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005200] [Batch 00262/00823] [00:03:17/00:07:02, 0.754s/it]: train_loss_raw=1.5771, running_loss=1.6917, LR=0.000100
[2025-08-26 09:39:50,457][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005208] [Batch 00270/00823] [00:03:23/00:06:56, 0.754s/it]: train_loss_raw=1.6162, running_loss=1.6902, LR=0.000100
[2025-08-26 09:39:56,434][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005216] [Batch 00278/00823] [00:03:29/00:06:50, 0.754s/it]: train_loss_raw=1.7475, running_loss=1.6922, LR=0.000100
[2025-08-26 09:40:02,474][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005224] [Batch 00286/00823] [00:03:35/00:06:44, 0.754s/it]: train_loss_raw=1.6104, running_loss=1.6904, LR=0.000100
[2025-08-26 09:40:08,532][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005232] [Batch 00294/00823] [00:03:41/00:06:38, 0.754s/it]: train_loss_raw=1.6719, running_loss=1.6904, LR=0.000100
[2025-08-26 09:40:14,631][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005240] [Batch 00302/00823] [00:03:47/00:06:32, 0.754s/it]: train_loss_raw=1.7397, running_loss=1.6899, LR=0.000100
[2025-08-26 09:40:20,721][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005248] [Batch 00310/00823] [00:03:53/00:06:26, 0.754s/it]: train_loss_raw=1.6335, running_loss=1.6879, LR=0.000100
[2025-08-26 09:40:26,790][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005256] [Batch 00318/00823] [00:03:59/00:06:20, 0.754s/it]: train_loss_raw=1.7153, running_loss=1.6880, LR=0.000100
[2025-08-26 09:40:32,893][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005264] [Batch 00326/00823] [00:04:05/00:06:15, 0.755s/it]: train_loss_raw=1.6827, running_loss=1.6885, LR=0.000100
[2025-08-26 09:40:39,003][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005272] [Batch 00334/00823] [00:04:12/00:06:09, 0.755s/it]: train_loss_raw=1.6328, running_loss=1.6879, LR=0.000100
[2025-08-26 09:40:45,060][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005280] [Batch 00342/00823] [00:04:18/00:06:03, 0.755s/it]: train_loss_raw=1.7093, running_loss=1.6870, LR=0.000100
[2025-08-26 09:40:51,467][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005288] [Batch 00350/00823] [00:04:24/00:05:57, 0.756s/it]: train_loss_raw=1.7574, running_loss=1.6888, LR=0.000100
[2025-08-26 09:40:57,588][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005296] [Batch 00358/00823] [00:04:30/00:05:51, 0.756s/it]: train_loss_raw=1.6173, running_loss=1.6856, LR=0.000100
[2025-08-26 09:41:03,628][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005304] [Batch 00366/00823] [00:04:36/00:05:45, 0.756s/it]: train_loss_raw=1.7355, running_loss=1.6859, LR=0.000100
[2025-08-26 09:41:09,679][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005312] [Batch 00374/00823] [00:04:42/00:05:39, 0.756s/it]: train_loss_raw=1.6186, running_loss=1.6832, LR=0.000100
[2025-08-26 09:41:15,700][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005320] [Batch 00382/00823] [00:04:48/00:05:33, 0.756s/it]: train_loss_raw=1.7232, running_loss=1.6829, LR=0.000100
[2025-08-26 09:41:21,728][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005328] [Batch 00390/00823] [00:04:54/00:05:27, 0.756s/it]: train_loss_raw=1.6665, running_loss=1.6828, LR=0.000100
[2025-08-26 09:41:27,785][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005336] [Batch 00398/00823] [00:05:00/00:05:21, 0.756s/it]: train_loss_raw=1.7057, running_loss=1.6829, LR=0.000100
[2025-08-26 09:41:33,861][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005344] [Batch 00406/00823] [00:05:06/00:05:15, 0.756s/it]: train_loss_raw=1.6516, running_loss=1.6836, LR=0.000100
[2025-08-26 09:41:39,905][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005352] [Batch 00414/00823] [00:05:13/00:05:09, 0.756s/it]: train_loss_raw=1.6851, running_loss=1.6839, LR=0.000100
[2025-08-26 09:41:45,956][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005360] [Batch 00422/00823] [00:05:19/00:05:03, 0.756s/it]: train_loss_raw=1.6926, running_loss=1.6811, LR=0.000100
[2025-08-26 09:41:52,006][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005368] [Batch 00430/00823] [00:05:25/00:04:57, 0.756s/it]: train_loss_raw=1.7639, running_loss=1.6802, LR=0.000100
[2025-08-26 09:41:58,132][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005376] [Batch 00438/00823] [00:05:31/00:04:51, 0.756s/it]: train_loss_raw=1.6625, running_loss=1.6814, LR=0.000100
[2025-08-26 09:42:04,173][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005384] [Batch 00446/00823] [00:05:37/00:04:45, 0.756s/it]: train_loss_raw=1.5652, running_loss=1.6798, LR=0.000100
[2025-08-26 09:42:10,297][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005392] [Batch 00454/00823] [00:05:43/00:04:39, 0.756s/it]: train_loss_raw=1.6710, running_loss=1.6771, LR=0.000100
[2025-08-26 09:42:16,386][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005400] [Batch 00462/00823] [00:05:49/00:04:33, 0.756s/it]: train_loss_raw=1.6867, running_loss=1.6781, LR=0.000100
[2025-08-26 09:42:22,429][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005408] [Batch 00470/00823] [00:05:55/00:04:27, 0.756s/it]: train_loss_raw=1.5927, running_loss=1.6762, LR=0.000100
[2025-08-26 09:42:28,548][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005416] [Batch 00478/00823] [00:06:01/00:04:21, 0.757s/it]: train_loss_raw=1.6720, running_loss=1.6769, LR=0.000100
[2025-08-26 09:42:34,590][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005424] [Batch 00486/00823] [00:06:07/00:04:14, 0.757s/it]: train_loss_raw=1.7428, running_loss=1.6767, LR=0.000100
[2025-08-26 09:42:40,566][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005432] [Batch 00494/00823] [00:06:13/00:04:08, 0.756s/it]: train_loss_raw=1.7571, running_loss=1.6788, LR=0.000100
[2025-08-26 09:42:46,542][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005440] [Batch 00502/00823] [00:06:19/00:04:02, 0.756s/it]: train_loss_raw=1.6874, running_loss=1.6781, LR=0.000100
[2025-08-26 09:42:52,705][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005448] [Batch 00510/00823] [00:06:25/00:03:56, 0.756s/it]: train_loss_raw=1.6631, running_loss=1.6773, LR=0.000100
[2025-08-26 09:42:58,769][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005456] [Batch 00518/00823] [00:06:31/00:03:50, 0.757s/it]: train_loss_raw=1.5702, running_loss=1.6779, LR=0.000100
[2025-08-26 09:43:04,853][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005464] [Batch 00526/00823] [00:06:37/00:03:44, 0.757s/it]: train_loss_raw=1.7762, running_loss=1.6755, LR=0.000100
[2025-08-26 09:43:11,126][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005472] [Batch 00534/00823] [00:06:44/00:03:38, 0.757s/it]: train_loss_raw=1.7384, running_loss=1.6763, LR=0.000100
[2025-08-26 09:43:17,155][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005480] [Batch 00542/00823] [00:06:50/00:03:32, 0.757s/it]: train_loss_raw=1.6382, running_loss=1.6768, LR=0.000100
[2025-08-26 09:43:23,161][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005488] [Batch 00550/00823] [00:06:56/00:03:26, 0.757s/it]: train_loss_raw=1.7243, running_loss=1.6794, LR=0.000100
[2025-08-26 09:43:29,144][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005496] [Batch 00558/00823] [00:07:02/00:03:20, 0.757s/it]: train_loss_raw=1.6985, running_loss=1.6770, LR=0.000100
[2025-08-26 09:43:35,129][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005504] [Batch 00566/00823] [00:07:08/00:03:14, 0.757s/it]: train_loss_raw=1.6803, running_loss=1.6761, LR=0.000100
[2025-08-26 09:43:41,183][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005512] [Batch 00574/00823] [00:07:14/00:03:08, 0.757s/it]: train_loss_raw=1.6210, running_loss=1.6763, LR=0.000100
[2025-08-26 09:43:47,259][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005520] [Batch 00582/00823] [00:07:20/00:03:02, 0.757s/it]: train_loss_raw=1.7658, running_loss=1.6778, LR=0.000100
[2025-08-26 09:43:53,295][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005528] [Batch 00590/00823] [00:07:26/00:02:56, 0.757s/it]: train_loss_raw=1.5657, running_loss=1.6755, LR=0.000100
[2025-08-26 09:43:59,358][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005536] [Batch 00598/00823] [00:07:32/00:02:50, 0.757s/it]: train_loss_raw=1.6449, running_loss=1.6743, LR=0.000100
[2025-08-26 09:44:05,407][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005544] [Batch 00606/00823] [00:07:38/00:02:44, 0.757s/it]: train_loss_raw=1.6045, running_loss=1.6721, LR=0.000100
[2025-08-26 09:44:11,455][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005552] [Batch 00614/00823] [00:07:44/00:02:38, 0.757s/it]: train_loss_raw=1.6667, running_loss=1.6711, LR=0.000100
[2025-08-26 09:44:17,460][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005560] [Batch 00622/00823] [00:07:50/00:02:32, 0.757s/it]: train_loss_raw=1.5731, running_loss=1.6671, LR=0.000100
[2025-08-26 09:44:23,555][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005568] [Batch 00630/00823] [00:07:56/00:02:26, 0.757s/it]: train_loss_raw=1.6890, running_loss=1.6676, LR=0.000100
[2025-08-26 09:44:29,662][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005576] [Batch 00638/00823] [00:08:02/00:02:19, 0.757s/it]: train_loss_raw=1.6382, running_loss=1.6656, LR=0.000100
[2025-08-26 09:44:35,724][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005584] [Batch 00646/00823] [00:08:08/00:02:13, 0.757s/it]: train_loss_raw=1.6436, running_loss=1.6636, LR=0.000100
[2025-08-26 09:44:41,747][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005592] [Batch 00654/00823] [00:08:14/00:02:07, 0.757s/it]: train_loss_raw=1.6388, running_loss=1.6649, LR=0.000100
[2025-08-26 09:44:47,813][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005600] [Batch 00662/00823] [00:08:20/00:02:01, 0.757s/it]: train_loss_raw=1.6500, running_loss=1.6655, LR=0.000100
[2025-08-26 09:44:53,897][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005608] [Batch 00670/00823] [00:08:26/00:01:55, 0.757s/it]: train_loss_raw=1.6286, running_loss=1.6661, LR=0.000100
[2025-08-26 09:44:59,952][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005616] [Batch 00678/00823] [00:08:33/00:01:49, 0.757s/it]: train_loss_raw=1.7231, running_loss=1.6686, LR=0.000100
[2025-08-26 09:45:06,027][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005624] [Batch 00686/00823] [00:08:39/00:01:43, 0.757s/it]: train_loss_raw=1.6750, running_loss=1.6697, LR=0.000100
[2025-08-26 09:45:12,071][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005632] [Batch 00694/00823] [00:08:45/00:01:37, 0.757s/it]: train_loss_raw=1.6580, running_loss=1.6687, LR=0.000100
[2025-08-26 09:45:17,966][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005640] [Batch 00702/00823] [00:08:51/00:01:31, 0.757s/it]: train_loss_raw=1.6398, running_loss=1.6682, LR=0.000100
[2025-08-26 09:45:23,967][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005648] [Batch 00710/00823] [00:08:57/00:01:25, 0.756s/it]: train_loss_raw=1.6066, running_loss=1.6665, LR=0.000100
[2025-08-26 09:45:29,949][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005656] [Batch 00718/00823] [00:09:03/00:01:19, 0.756s/it]: train_loss_raw=1.5898, running_loss=1.6668, LR=0.000100
[2025-08-26 09:45:35,999][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005664] [Batch 00726/00823] [00:09:09/00:01:13, 0.756s/it]: train_loss_raw=1.6317, running_loss=1.6655, LR=0.000100
[2025-08-26 09:45:42,027][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005672] [Batch 00734/00823] [00:09:15/00:01:07, 0.756s/it]: train_loss_raw=1.7303, running_loss=1.6648, LR=0.000100
[2025-08-26 09:45:48,043][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005680] [Batch 00742/00823] [00:09:21/00:01:01, 0.756s/it]: train_loss_raw=1.6409, running_loss=1.6625, LR=0.000100
[2025-08-26 09:45:54,101][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005688] [Batch 00750/00823] [00:09:27/00:00:55, 0.756s/it]: train_loss_raw=1.6509, running_loss=1.6631, LR=0.000100
[2025-08-26 09:46:00,156][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005696] [Batch 00758/00823] [00:09:33/00:00:49, 0.756s/it]: train_loss_raw=1.6293, running_loss=1.6625, LR=0.000100
[2025-08-26 09:46:06,321][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005704] [Batch 00766/00823] [00:09:39/00:00:43, 0.756s/it]: train_loss_raw=1.7058, running_loss=1.6642, LR=0.000100
[2025-08-26 09:46:12,565][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005712] [Batch 00774/00823] [00:09:45/00:00:37, 0.757s/it]: train_loss_raw=1.6841, running_loss=1.6648, LR=0.000100
[2025-08-26 09:46:18,700][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005720] [Batch 00782/00823] [00:09:51/00:00:31, 0.757s/it]: train_loss_raw=1.6600, running_loss=1.6663, LR=0.000100
[2025-08-26 09:46:24,858][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005728] [Batch 00790/00823] [00:09:57/00:00:24, 0.757s/it]: train_loss_raw=1.7015, running_loss=1.6646, LR=0.000100
[2025-08-26 09:46:30,885][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005736] [Batch 00798/00823] [00:10:03/00:00:18, 0.757s/it]: train_loss_raw=1.6968, running_loss=1.6649, LR=0.000100
[2025-08-26 09:46:36,969][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005744] [Batch 00806/00823] [00:10:10/00:00:12, 0.757s/it]: train_loss_raw=1.6411, running_loss=1.6669, LR=0.000100
[2025-08-26 09:46:43,015][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005752] [Batch 00814/00823] [00:10:16/00:00:06, 0.757s/it]: train_loss_raw=1.6004, running_loss=1.6679, LR=0.000100
[2025-08-26 09:46:49,089][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005760] [Batch 00822/00823] [00:10:22/00:00:00, 0.757s/it]: train_loss_raw=1.7195, running_loss=1.6689, LR=0.000100
[2025-08-26 09:46:50,082][__main__][INFO] - [VALIDATION] [Epoch 06/29] Starting validation.
[2025-08-26 09:47:01,762][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 005762] [Batch 00007/00013] [00:00:11/00:00:07, 1.460s/it]
[2025-08-26 09:47:09,330][__main__][INFO] - [VALIDATION] [Epoch 06/29] train_loss=1.66882, valid_loss=1.70002
[2025-08-26 09:47:09,330][__main__][INFO] - [VALIDATION] [Epoch 06/29] Metrics:
[2025-08-26 09:47:09,330][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_er      0.713
[2025-08-26 09:47:09,330][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_prec    0.031
[2025-08-26 09:47:09,331][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_recall  0.031
[2025-08-26 09:47:09,331][__main__][INFO] - [VALIDATION] [Epoch 06/29] - pep_recall 0.005
[2025-08-26 09:47:09,333][__main__][INFO] - [TRAIN] [Epoch 06/29] Epoch complete, total time 01:14:33, remaining time 04:04:57, 00:10:39 per epoch
[2025-08-26 09:47:14,327][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005768] [Batch 00007/00823] [00:00:04/00:09:07, 0.671s/it]: train_loss_raw=1.6101, running_loss=1.6342, LR=0.000100
[2025-08-26 09:47:20,327][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005776] [Batch 00015/00823] [00:00:10/00:09:36, 0.713s/it]: train_loss_raw=1.6469, running_loss=1.6356, LR=0.000100
[2025-08-26 09:47:26,278][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005784] [Batch 00023/00823] [00:00:16/00:09:39, 0.724s/it]: train_loss_raw=1.6545, running_loss=1.6373, LR=0.000100
[2025-08-26 09:47:32,296][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005792] [Batch 00031/00823] [00:00:22/00:09:39, 0.731s/it]: train_loss_raw=1.7176, running_loss=1.6382, LR=0.000100
[2025-08-26 09:47:38,378][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005800] [Batch 00039/00823] [00:00:28/00:09:37, 0.737s/it]: train_loss_raw=1.7331, running_loss=1.6400, LR=0.000100
[2025-08-26 09:47:44,408][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005808] [Batch 00047/00823] [00:00:34/00:09:34, 0.740s/it]: train_loss_raw=1.6778, running_loss=1.6402, LR=0.000100
[2025-08-26 09:47:50,395][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005816] [Batch 00055/00823] [00:00:40/00:09:29, 0.741s/it]: train_loss_raw=1.6560, running_loss=1.6418, LR=0.000100
[2025-08-26 09:47:56,439][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005824] [Batch 00063/00823] [00:00:46/00:09:24, 0.743s/it]: train_loss_raw=1.6694, running_loss=1.6431, LR=0.000100
[2025-08-26 09:48:02,527][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005832] [Batch 00071/00823] [00:00:52/00:09:20, 0.745s/it]: train_loss_raw=1.7682, running_loss=1.6453, LR=0.000100
[2025-08-26 09:48:08,566][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005840] [Batch 00079/00823] [00:00:58/00:09:15, 0.746s/it]: train_loss_raw=1.6720, running_loss=1.6488, LR=0.000100
[2025-08-26 09:48:14,634][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005848] [Batch 00087/00823] [00:01:05/00:09:09, 0.747s/it]: train_loss_raw=1.6873, running_loss=1.6484, LR=0.000100
[2025-08-26 09:48:20,688][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005856] [Batch 00095/00823] [00:01:11/00:09:04, 0.748s/it]: train_loss_raw=1.6511, running_loss=1.6507, LR=0.000100
[2025-08-26 09:48:26,767][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005864] [Batch 00103/00823] [00:01:17/00:08:59, 0.749s/it]: train_loss_raw=1.6593, running_loss=1.6505, LR=0.000100
[2025-08-26 09:48:32,772][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005872] [Batch 00111/00823] [00:01:23/00:08:53, 0.749s/it]: train_loss_raw=1.5408, running_loss=1.6472, LR=0.000100
[2025-08-26 09:48:38,798][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005880] [Batch 00119/00823] [00:01:29/00:08:47, 0.749s/it]: train_loss_raw=1.6609, running_loss=1.6474, LR=0.000100
[2025-08-26 09:48:44,860][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005888] [Batch 00127/00823] [00:01:35/00:08:41, 0.750s/it]: train_loss_raw=1.5639, running_loss=1.6457, LR=0.000100
[2025-08-26 09:48:50,940][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005896] [Batch 00135/00823] [00:01:41/00:08:36, 0.750s/it]: train_loss_raw=1.5769, running_loss=1.6455, LR=0.000100
[2025-08-26 09:48:56,967][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005904] [Batch 00143/00823] [00:01:47/00:08:30, 0.751s/it]: train_loss_raw=1.5974, running_loss=1.6458, LR=0.000100
[2025-08-26 09:49:02,969][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005912] [Batch 00151/00823] [00:01:53/00:08:24, 0.751s/it]: train_loss_raw=1.7421, running_loss=1.6483, LR=0.000100
[2025-08-26 09:49:09,001][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005920] [Batch 00159/00823] [00:01:59/00:08:18, 0.751s/it]: train_loss_raw=1.7011, running_loss=1.6479, LR=0.000100
[2025-08-26 09:49:15,048][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005928] [Batch 00167/00823] [00:02:05/00:08:12, 0.751s/it]: train_loss_raw=1.5828, running_loss=1.6469, LR=0.000100
[2025-08-26 09:49:21,212][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005936] [Batch 00175/00823] [00:02:11/00:08:07, 0.752s/it]: train_loss_raw=1.6500, running_loss=1.6464, LR=0.000100
[2025-08-26 09:49:27,215][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005944] [Batch 00183/00823] [00:02:17/00:08:01, 0.752s/it]: train_loss_raw=1.6765, running_loss=1.6453, LR=0.000100
[2025-08-26 09:49:33,307][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005952] [Batch 00191/00823] [00:02:23/00:07:55, 0.752s/it]: train_loss_raw=1.5973, running_loss=1.6444, LR=0.000100
[2025-08-26 09:49:39,395][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005960] [Batch 00199/00823] [00:02:29/00:07:49, 0.753s/it]: train_loss_raw=1.7614, running_loss=1.6458, LR=0.000100
[2025-08-26 09:49:45,533][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005968] [Batch 00207/00823] [00:02:35/00:07:43, 0.753s/it]: train_loss_raw=1.5649, running_loss=1.6447, LR=0.000100
[2025-08-26 09:49:51,706][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005976] [Batch 00215/00823] [00:02:42/00:07:38, 0.754s/it]: train_loss_raw=1.6842, running_loss=1.6459, LR=0.000100
[2025-08-26 09:49:57,731][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005984] [Batch 00223/00823] [00:02:48/00:07:32, 0.754s/it]: train_loss_raw=1.6148, running_loss=1.6479, LR=0.000100
[2025-08-26 09:50:03,792][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005992] [Batch 00231/00823] [00:02:54/00:07:26, 0.754s/it]: train_loss_raw=1.6681, running_loss=1.6479, LR=0.000100
[2025-08-26 09:50:09,807][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006000] [Batch 00239/00823] [00:03:00/00:07:20, 0.754s/it]: train_loss_raw=1.7188, running_loss=1.6464, LR=0.000100
[2025-08-26 09:50:19,659][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006008] [Batch 00247/00823] [00:03:10/00:07:23, 0.769s/it]: train_loss_raw=1.5303, running_loss=1.6451, LR=0.000100
[2025-08-26 09:50:25,686][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006016] [Batch 00255/00823] [00:03:16/00:07:16, 0.769s/it]: train_loss_raw=1.6887, running_loss=1.6469, LR=0.000100
[2025-08-26 09:50:31,823][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006024] [Batch 00263/00823] [00:03:22/00:07:10, 0.769s/it]: train_loss_raw=1.6219, running_loss=1.6435, LR=0.000100
[2025-08-26 09:50:37,872][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006032] [Batch 00271/00823] [00:03:28/00:07:04, 0.768s/it]: train_loss_raw=1.7018, running_loss=1.6453, LR=0.000100
[2025-08-26 09:50:43,916][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006040] [Batch 00279/00823] [00:03:34/00:06:57, 0.768s/it]: train_loss_raw=1.7013, running_loss=1.6447, LR=0.000100
[2025-08-26 09:50:50,006][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006048] [Batch 00287/00823] [00:03:40/00:06:51, 0.768s/it]: train_loss_raw=1.7293, running_loss=1.6462, LR=0.000100
[2025-08-26 09:50:56,152][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006056] [Batch 00295/00823] [00:03:46/00:06:45, 0.768s/it]: train_loss_raw=1.6557, running_loss=1.6462, LR=0.000100
[2025-08-26 09:51:02,219][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006064] [Batch 00303/00823] [00:03:52/00:06:39, 0.768s/it]: train_loss_raw=1.6352, running_loss=1.6463, LR=0.000100
[2025-08-26 09:51:08,254][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006072] [Batch 00311/00823] [00:03:58/00:06:32, 0.767s/it]: train_loss_raw=1.6782, running_loss=1.6470, LR=0.000100
[2025-08-26 09:51:14,325][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006080] [Batch 00319/00823] [00:04:04/00:06:26, 0.767s/it]: train_loss_raw=1.6078, running_loss=1.6463, LR=0.000100
[2025-08-26 09:51:20,352][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006088] [Batch 00327/00823] [00:04:10/00:06:20, 0.767s/it]: train_loss_raw=1.6917, running_loss=1.6464, LR=0.000100
[2025-08-26 09:51:26,307][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006096] [Batch 00335/00823] [00:04:16/00:06:13, 0.766s/it]: train_loss_raw=1.7685, running_loss=1.6484, LR=0.000100
[2025-08-26 09:51:32,324][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006104] [Batch 00343/00823] [00:04:22/00:06:07, 0.766s/it]: train_loss_raw=1.6938, running_loss=1.6484, LR=0.000100
[2025-08-26 09:51:38,293][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006112] [Batch 00351/00823] [00:04:28/00:06:01, 0.765s/it]: train_loss_raw=1.6659, running_loss=1.6456, LR=0.000100
[2025-08-26 09:51:44,375][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006120] [Batch 00359/00823] [00:04:34/00:05:55, 0.765s/it]: train_loss_raw=1.5384, running_loss=1.6446, LR=0.000100
[2025-08-26 09:51:50,433][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006128] [Batch 00367/00823] [00:04:40/00:05:48, 0.765s/it]: train_loss_raw=1.6020, running_loss=1.6446, LR=0.000100
[2025-08-26 09:51:56,436][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006136] [Batch 00375/00823] [00:04:46/00:05:42, 0.765s/it]: train_loss_raw=1.5853, running_loss=1.6454, LR=0.000100
[2025-08-26 09:52:02,513][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006144] [Batch 00383/00823] [00:04:52/00:05:36, 0.765s/it]: train_loss_raw=1.5878, running_loss=1.6446, LR=0.000100
[2025-08-26 09:52:08,588][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006152] [Batch 00391/00823] [00:04:58/00:05:30, 0.765s/it]: train_loss_raw=1.5842, running_loss=1.6435, LR=0.000100
[2025-08-26 09:52:14,637][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006160] [Batch 00399/00823] [00:05:05/00:05:24, 0.764s/it]: train_loss_raw=1.6804, running_loss=1.6453, LR=0.000100
[2025-08-26 09:52:20,722][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006168] [Batch 00407/00823] [00:05:11/00:05:17, 0.764s/it]: train_loss_raw=1.6594, running_loss=1.6446, LR=0.000100
[2025-08-26 09:52:26,745][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006176] [Batch 00415/00823] [00:05:17/00:05:11, 0.764s/it]: train_loss_raw=1.6456, running_loss=1.6458, LR=0.000100
[2025-08-26 09:52:32,770][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006184] [Batch 00423/00823] [00:05:23/00:05:05, 0.764s/it]: train_loss_raw=1.5824, running_loss=1.6459, LR=0.000100
[2025-08-26 09:52:38,813][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006192] [Batch 00431/00823] [00:05:29/00:04:59, 0.764s/it]: train_loss_raw=1.6702, running_loss=1.6439, LR=0.000100
[2025-08-26 09:52:44,843][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006200] [Batch 00439/00823] [00:05:35/00:04:53, 0.764s/it]: train_loss_raw=1.7212, running_loss=1.6454, LR=0.000100
[2025-08-26 09:52:50,871][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006208] [Batch 00447/00823] [00:05:41/00:04:47, 0.763s/it]: train_loss_raw=1.6477, running_loss=1.6450, LR=0.000100
[2025-08-26 09:52:56,927][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006216] [Batch 00455/00823] [00:05:47/00:04:40, 0.763s/it]: train_loss_raw=1.6321, running_loss=1.6436, LR=0.000100
[2025-08-26 09:53:02,803][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006224] [Batch 00463/00823] [00:05:53/00:04:34, 0.763s/it]: train_loss_raw=1.6667, running_loss=1.6447, LR=0.000100
[2025-08-26 09:53:08,566][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006232] [Batch 00471/00823] [00:05:58/00:04:28, 0.762s/it]: train_loss_raw=1.6959, running_loss=1.6461, LR=0.000100
[2025-08-26 09:53:14,295][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006240] [Batch 00479/00823] [00:06:04/00:04:21, 0.761s/it]: train_loss_raw=1.6937, running_loss=1.6446, LR=0.000100
[2025-08-26 09:53:19,918][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006248] [Batch 00487/00823] [00:06:10/00:04:15, 0.760s/it]: train_loss_raw=1.5818, running_loss=1.6411, LR=0.000100
[2025-08-26 09:53:25,616][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006256] [Batch 00495/00823] [00:06:15/00:04:09, 0.760s/it]: train_loss_raw=1.5641, running_loss=1.6386, LR=0.000100
[2025-08-26 09:53:31,075][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006264] [Batch 00503/00823] [00:06:21/00:04:02, 0.758s/it]: train_loss_raw=1.6586, running_loss=1.6372, LR=0.000100
[2025-08-26 09:53:36,656][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006272] [Batch 00511/00823] [00:06:27/00:03:56, 0.757s/it]: train_loss_raw=1.5274, running_loss=1.6349, LR=0.000100
[2025-08-26 09:53:42,401][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006280] [Batch 00519/00823] [00:06:32/00:03:50, 0.757s/it]: train_loss_raw=1.6960, running_loss=1.6364, LR=0.000100
[2025-08-26 09:53:48,246][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006288] [Batch 00527/00823] [00:06:38/00:03:43, 0.756s/it]: train_loss_raw=1.6903, running_loss=1.6375, LR=0.000100
[2025-08-26 09:53:54,115][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006296] [Batch 00535/00823] [00:06:44/00:03:37, 0.756s/it]: train_loss_raw=1.7130, running_loss=1.6395, LR=0.000100
[2025-08-26 09:54:00,048][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006304] [Batch 00543/00823] [00:06:50/00:03:31, 0.756s/it]: train_loss_raw=1.6109, running_loss=1.6391, LR=0.000100
[2025-08-26 09:54:05,888][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006312] [Batch 00551/00823] [00:06:56/00:03:25, 0.755s/it]: train_loss_raw=1.6136, running_loss=1.6395, LR=0.000100
[2025-08-26 09:54:11,739][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006320] [Batch 00559/00823] [00:07:02/00:03:19, 0.755s/it]: train_loss_raw=1.6133, running_loss=1.6377, LR=0.000100
[2025-08-26 09:54:17,631][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006328] [Batch 00567/00823] [00:07:08/00:03:13, 0.755s/it]: train_loss_raw=1.6401, running_loss=1.6383, LR=0.000100
[2025-08-26 09:54:23,441][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006336] [Batch 00575/00823] [00:07:13/00:03:07, 0.754s/it]: train_loss_raw=1.5888, running_loss=1.6373, LR=0.000100
[2025-08-26 09:54:29,175][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006344] [Batch 00583/00823] [00:07:19/00:03:00, 0.754s/it]: train_loss_raw=1.6257, running_loss=1.6372, LR=0.000100
[2025-08-26 09:54:34,970][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006352] [Batch 00591/00823] [00:07:25/00:02:54, 0.754s/it]: train_loss_raw=1.6116, running_loss=1.6352, LR=0.000100
[2025-08-26 09:54:40,804][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006360] [Batch 00599/00823] [00:07:31/00:02:48, 0.753s/it]: train_loss_raw=1.5592, running_loss=1.6347, LR=0.000100
[2025-08-26 09:54:46,539][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006368] [Batch 00607/00823] [00:07:36/00:02:42, 0.753s/it]: train_loss_raw=1.5990, running_loss=1.6334, LR=0.000100
[2025-08-26 09:54:52,256][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006376] [Batch 00615/00823] [00:07:42/00:02:36, 0.752s/it]: train_loss_raw=1.7233, running_loss=1.6337, LR=0.000100
[2025-08-26 09:54:57,948][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006384] [Batch 00623/00823] [00:07:48/00:02:30, 0.752s/it]: train_loss_raw=1.6133, running_loss=1.6329, LR=0.000100
[2025-08-26 09:55:03,868][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006392] [Batch 00631/00823] [00:07:54/00:02:24, 0.752s/it]: train_loss_raw=1.6254, running_loss=1.6336, LR=0.000100
[2025-08-26 09:55:09,618][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006400] [Batch 00639/00823] [00:07:59/00:02:18, 0.751s/it]: train_loss_raw=1.6066, running_loss=1.6342, LR=0.000100
[2025-08-26 09:55:15,471][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006408] [Batch 00647/00823] [00:08:05/00:02:12, 0.751s/it]: train_loss_raw=1.5823, running_loss=1.6356, LR=0.000100
[2025-08-26 09:55:21,191][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006416] [Batch 00655/00823] [00:08:11/00:02:06, 0.750s/it]: train_loss_raw=1.4933, running_loss=1.6342, LR=0.000100
[2025-08-26 09:55:26,930][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006424] [Batch 00663/00823] [00:08:17/00:02:00, 0.750s/it]: train_loss_raw=1.6130, running_loss=1.6351, LR=0.000100
[2025-08-26 09:55:32,649][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006432] [Batch 00671/00823] [00:08:23/00:01:53, 0.750s/it]: train_loss_raw=1.6132, running_loss=1.6339, LR=0.000100
[2025-08-26 09:55:38,468][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006440] [Batch 00679/00823] [00:08:28/00:01:47, 0.749s/it]: train_loss_raw=1.6775, running_loss=1.6341, LR=0.000100
[2025-08-26 09:55:44,196][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006448] [Batch 00687/00823] [00:08:34/00:01:41, 0.749s/it]: train_loss_raw=1.6217, running_loss=1.6325, LR=0.000100
[2025-08-26 09:55:49,944][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006456] [Batch 00695/00823] [00:08:40/00:01:35, 0.749s/it]: train_loss_raw=1.5943, running_loss=1.6282, LR=0.000100
[2025-08-26 09:55:55,774][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006464] [Batch 00703/00823] [00:08:46/00:01:29, 0.748s/it]: train_loss_raw=1.6901, running_loss=1.6258, LR=0.000100
[2025-08-26 09:56:01,765][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006472] [Batch 00711/00823] [00:08:52/00:01:23, 0.748s/it]: train_loss_raw=1.5515, running_loss=1.6281, LR=0.000100
[2025-08-26 09:56:07,718][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006480] [Batch 00719/00823] [00:08:58/00:01:17, 0.748s/it]: train_loss_raw=1.6409, running_loss=1.6263, LR=0.000100
[2025-08-26 09:56:13,676][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006488] [Batch 00727/00823] [00:09:04/00:01:11, 0.748s/it]: train_loss_raw=1.6078, running_loss=1.6240, LR=0.000100
[2025-08-26 09:56:19,392][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006496] [Batch 00735/00823] [00:09:09/00:01:05, 0.748s/it]: train_loss_raw=1.5441, running_loss=1.6211, LR=0.000100
[2025-08-26 09:56:25,162][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006504] [Batch 00743/00823] [00:09:15/00:00:59, 0.748s/it]: train_loss_raw=1.6712, running_loss=1.6211, LR=0.000100
[2025-08-26 09:56:31,059][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006512] [Batch 00751/00823] [00:09:21/00:00:53, 0.748s/it]: train_loss_raw=1.6528, running_loss=1.6209, LR=0.000100
[2025-08-26 09:56:36,876][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006520] [Batch 00759/00823] [00:09:27/00:00:47, 0.747s/it]: train_loss_raw=1.5352, running_loss=1.6200, LR=0.000100
[2025-08-26 09:56:42,645][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006528] [Batch 00767/00823] [00:09:33/00:00:41, 0.747s/it]: train_loss_raw=1.6893, running_loss=1.6208, LR=0.000100
[2025-08-26 09:56:48,442][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006536] [Batch 00775/00823] [00:09:38/00:00:35, 0.747s/it]: train_loss_raw=1.7397, running_loss=1.6222, LR=0.000100
[2025-08-26 09:56:54,268][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006544] [Batch 00783/00823] [00:09:44/00:00:29, 0.747s/it]: train_loss_raw=1.6947, running_loss=1.6224, LR=0.000100
[2025-08-26 09:57:00,027][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006552] [Batch 00791/00823] [00:09:50/00:00:23, 0.746s/it]: train_loss_raw=1.6333, running_loss=1.6219, LR=0.000100
[2025-08-26 09:57:05,773][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006560] [Batch 00799/00823] [00:09:56/00:00:17, 0.746s/it]: train_loss_raw=1.5519, running_loss=1.6231, LR=0.000100
[2025-08-26 09:57:11,606][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006568] [Batch 00807/00823] [00:10:01/00:00:11, 0.746s/it]: train_loss_raw=1.5589, running_loss=1.6216, LR=0.000100
[2025-08-26 09:57:17,095][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006576] [Batch 00815/00823] [00:10:07/00:00:05, 0.745s/it]: train_loss_raw=1.6077, running_loss=1.6197, LR=0.000100
[2025-08-26 09:57:28,656][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006584] [Batch 00823/00823] [00:10:19/00:00:00, 0.752s/it]: train_loss_raw=1.6718, running_loss=1.6180, LR=0.000100
[2025-08-26 09:57:29,023][__main__][INFO] - [VALIDATION] [Epoch 07/29] Starting validation.
[2025-08-26 09:57:40,832][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 006585] [Batch 00007/00013] [00:00:11/00:00:07, 1.476s/it]
[2025-08-26 09:57:48,091][__main__][INFO] - [VALIDATION] [Epoch 07/29] train_loss=1.61805, valid_loss=1.66397
[2025-08-26 09:57:48,092][__main__][INFO] - [VALIDATION] [Epoch 07/29] Metrics:
[2025-08-26 09:57:48,092][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_er      0.674
[2025-08-26 09:57:48,092][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_prec    0.044
[2025-08-26 09:57:48,092][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_recall  0.045
[2025-08-26 09:57:48,092][__main__][INFO] - [VALIDATION] [Epoch 07/29] - pep_recall 0.008
[2025-08-26 09:57:48,094][__main__][INFO] - [TRAIN] [Epoch 07/29] Epoch complete, total time 01:25:11, remaining time 03:54:17, 00:10:38 per epoch
[2025-08-26 09:57:53,894][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006592] [Batch 00008/00823] [00:00:05/00:09:20, 0.687s/it]: train_loss_raw=1.6148, running_loss=1.5902, LR=0.000100
[2025-08-26 09:58:00,027][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006600] [Batch 00016/00823] [00:00:11/00:09:46, 0.727s/it]: train_loss_raw=1.6401, running_loss=1.5906, LR=0.000100
[2025-08-26 09:58:05,711][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006608] [Batch 00024/00823] [00:00:17/00:09:36, 0.722s/it]: train_loss_raw=1.5877, running_loss=1.5918, LR=0.000100
[2025-08-26 09:58:11,435][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006616] [Batch 00032/00823] [00:00:23/00:09:29, 0.720s/it]: train_loss_raw=1.6125, running_loss=1.5933, LR=0.000100
[2025-08-26 09:58:17,514][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006624] [Batch 00040/00823] [00:00:29/00:09:30, 0.728s/it]: train_loss_raw=1.4853, running_loss=1.5911, LR=0.000100
[2025-08-26 09:58:23,424][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006632] [Batch 00048/00823] [00:00:35/00:09:25, 0.730s/it]: train_loss_raw=1.5550, running_loss=1.5911, LR=0.000100
[2025-08-26 09:58:29,264][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006640] [Batch 00056/00823] [00:00:40/00:09:19, 0.730s/it]: train_loss_raw=1.6112, running_loss=1.5928, LR=0.000100
[2025-08-26 09:58:35,071][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006648] [Batch 00064/00823] [00:00:46/00:09:13, 0.729s/it]: train_loss_raw=1.6429, running_loss=1.5947, LR=0.000100
[2025-08-26 09:58:40,932][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006656] [Batch 00072/00823] [00:00:52/00:09:08, 0.730s/it]: train_loss_raw=1.5638, running_loss=1.5936, LR=0.000100
[2025-08-26 09:58:46,803][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006664] [Batch 00080/00823] [00:00:58/00:09:02, 0.730s/it]: train_loss_raw=1.5757, running_loss=1.5921, LR=0.000100
[2025-08-26 09:58:52,653][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006672] [Batch 00088/00823] [00:01:04/00:08:56, 0.730s/it]: train_loss_raw=1.5476, running_loss=1.5923, LR=0.000100
[2025-08-26 09:58:58,617][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006680] [Batch 00096/00823] [00:01:10/00:08:51, 0.731s/it]: train_loss_raw=1.5786, running_loss=1.5938, LR=0.000100
[2025-08-26 09:59:04,489][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006688] [Batch 00104/00823] [00:01:16/00:08:46, 0.732s/it]: train_loss_raw=1.5478, running_loss=1.5950, LR=0.000100
[2025-08-26 09:59:10,081][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006696] [Batch 00112/00823] [00:01:21/00:08:38, 0.729s/it]: train_loss_raw=1.4904, running_loss=1.5946, LR=0.000100
[2025-08-26 09:59:15,850][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006704] [Batch 00120/00823] [00:01:27/00:08:32, 0.729s/it]: train_loss_raw=1.6592, running_loss=1.5938, LR=0.000100
[2025-08-26 09:59:21,646][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006712] [Batch 00128/00823] [00:01:33/00:08:26, 0.729s/it]: train_loss_raw=1.5583, running_loss=1.5923, LR=0.000100
[2025-08-26 09:59:27,462][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006720] [Batch 00136/00823] [00:01:39/00:08:20, 0.728s/it]: train_loss_raw=1.6020, running_loss=1.5926, LR=0.000100
[2025-08-26 09:59:33,278][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006728] [Batch 00144/00823] [00:01:44/00:08:14, 0.728s/it]: train_loss_raw=1.6116, running_loss=1.5930, LR=0.000100
[2025-08-26 09:59:39,073][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006736] [Batch 00152/00823] [00:01:50/00:08:08, 0.728s/it]: train_loss_raw=1.5668, running_loss=1.5946, LR=0.000100
[2025-08-26 09:59:44,802][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006744] [Batch 00160/00823] [00:01:56/00:08:02, 0.728s/it]: train_loss_raw=1.5372, running_loss=1.5941, LR=0.000100
[2025-08-26 09:59:50,749][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006752] [Batch 00168/00823] [00:02:02/00:07:57, 0.728s/it]: train_loss_raw=1.6573, running_loss=1.5953, LR=0.000100
[2025-08-26 09:59:56,573][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006760] [Batch 00176/00823] [00:02:08/00:07:51, 0.728s/it]: train_loss_raw=1.5757, running_loss=1.5941, LR=0.000100
[2025-08-26 10:00:02,396][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006768] [Batch 00184/00823] [00:02:14/00:07:45, 0.728s/it]: train_loss_raw=1.4993, running_loss=1.5917, LR=0.000100
[2025-08-26 10:00:08,272][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006776] [Batch 00192/00823] [00:02:19/00:07:39, 0.729s/it]: train_loss_raw=1.5484, running_loss=1.5903, LR=0.000100
[2025-08-26 10:00:14,234][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006784] [Batch 00200/00823] [00:02:25/00:07:34, 0.729s/it]: train_loss_raw=1.5982, running_loss=1.5888, LR=0.000100
[2025-08-26 10:00:20,161][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006792] [Batch 00208/00823] [00:02:31/00:07:28, 0.730s/it]: train_loss_raw=1.5655, running_loss=1.5895, LR=0.000100
[2025-08-26 10:00:26,105][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006800] [Batch 00216/00823] [00:02:37/00:07:23, 0.730s/it]: train_loss_raw=1.5305, running_loss=1.5895, LR=0.000100
[2025-08-26 10:00:32,220][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006808] [Batch 00224/00823] [00:02:43/00:07:18, 0.731s/it]: train_loss_raw=1.5260, running_loss=1.5875, LR=0.000100
[2025-08-26 10:00:38,073][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006816] [Batch 00232/00823] [00:02:49/00:07:12, 0.731s/it]: train_loss_raw=1.6085, running_loss=1.5897, LR=0.000100
[2025-08-26 10:00:44,050][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006824] [Batch 00240/00823] [00:02:55/00:07:06, 0.732s/it]: train_loss_raw=1.5761, running_loss=1.5899, LR=0.000100
[2025-08-26 10:00:49,573][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006832] [Batch 00248/00823] [00:03:01/00:07:00, 0.731s/it]: train_loss_raw=1.6523, running_loss=1.5903, LR=0.000100
[2025-08-26 10:00:55,041][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006840] [Batch 00256/00823] [00:03:06/00:06:53, 0.729s/it]: train_loss_raw=1.5740, running_loss=1.5899, LR=0.000100
[2025-08-26 10:01:00,802][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006848] [Batch 00264/00823] [00:03:12/00:06:47, 0.729s/it]: train_loss_raw=1.5152, running_loss=1.5874, LR=0.000100
[2025-08-26 10:01:06,405][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006856] [Batch 00272/00823] [00:03:18/00:06:41, 0.728s/it]: train_loss_raw=1.4839, running_loss=1.5873, LR=0.000100
[2025-08-26 10:01:12,000][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006864] [Batch 00280/00823] [00:03:23/00:06:34, 0.727s/it]: train_loss_raw=1.6458, running_loss=1.5891, LR=0.000100
[2025-08-26 10:01:17,788][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006872] [Batch 00288/00823] [00:03:29/00:06:28, 0.727s/it]: train_loss_raw=1.6295, running_loss=1.5900, LR=0.000100
[2025-08-26 10:01:23,587][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006880] [Batch 00296/00823] [00:03:35/00:06:23, 0.727s/it]: train_loss_raw=1.5547, running_loss=1.5922, LR=0.000100
[2025-08-26 10:01:29,533][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006888] [Batch 00304/00823] [00:03:41/00:06:17, 0.727s/it]: train_loss_raw=1.5668, running_loss=1.5916, LR=0.000100
[2025-08-26 10:01:35,338][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006896] [Batch 00312/00823] [00:03:46/00:06:11, 0.727s/it]: train_loss_raw=1.6920, running_loss=1.5933, LR=0.000100
[2025-08-26 10:01:40,948][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006904] [Batch 00320/00823] [00:03:52/00:06:05, 0.727s/it]: train_loss_raw=1.6378, running_loss=1.5899, LR=0.000100
[2025-08-26 10:01:46,825][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006912] [Batch 00328/00823] [00:03:58/00:05:59, 0.727s/it]: train_loss_raw=1.5851, running_loss=1.5887, LR=0.000100
[2025-08-26 10:01:52,532][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006920] [Batch 00336/00823] [00:04:04/00:05:53, 0.727s/it]: train_loss_raw=1.6281, running_loss=1.5910, LR=0.000100
[2025-08-26 10:01:58,414][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006928] [Batch 00344/00823] [00:04:10/00:05:48, 0.727s/it]: train_loss_raw=1.6290, running_loss=1.5910, LR=0.000100
[2025-08-26 10:02:04,163][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006936] [Batch 00352/00823] [00:04:15/00:05:42, 0.727s/it]: train_loss_raw=1.6106, running_loss=1.5910, LR=0.000100
[2025-08-26 10:02:09,876][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006944] [Batch 00360/00823] [00:04:21/00:05:36, 0.726s/it]: train_loss_raw=1.5619, running_loss=1.5890, LR=0.000100
[2025-08-26 10:02:15,631][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006952] [Batch 00368/00823] [00:04:27/00:05:30, 0.726s/it]: train_loss_raw=1.5457, running_loss=1.5865, LR=0.000100
[2025-08-26 10:02:21,525][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006960] [Batch 00376/00823] [00:04:33/00:05:24, 0.726s/it]: train_loss_raw=1.6349, running_loss=1.5840, LR=0.000100
[2025-08-26 10:02:27,126][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006968] [Batch 00384/00823] [00:04:38/00:05:18, 0.726s/it]: train_loss_raw=1.6263, running_loss=1.5826, LR=0.000100
[2025-08-26 10:02:32,937][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006976] [Batch 00392/00823] [00:04:44/00:05:12, 0.726s/it]: train_loss_raw=1.6120, running_loss=1.5848, LR=0.000100
[2025-08-26 10:02:38,729][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006984] [Batch 00400/00823] [00:04:50/00:05:07, 0.726s/it]: train_loss_raw=1.6500, running_loss=1.5868, LR=0.000100
[2025-08-26 10:02:44,520][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006992] [Batch 00408/00823] [00:04:56/00:05:01, 0.726s/it]: train_loss_raw=1.5581, running_loss=1.5861, LR=0.000100
[2025-08-26 10:02:50,369][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007000] [Batch 00416/00823] [00:05:01/00:04:55, 0.726s/it]: train_loss_raw=1.6534, running_loss=1.5868, LR=0.000100
[2025-08-26 10:02:56,140][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007008] [Batch 00424/00823] [00:05:07/00:04:49, 0.726s/it]: train_loss_raw=1.4976, running_loss=1.5849, LR=0.000100
[2025-08-26 10:03:02,064][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007016] [Batch 00432/00823] [00:05:13/00:04:43, 0.726s/it]: train_loss_raw=1.5417, running_loss=1.5836, LR=0.000100
[2025-08-26 10:03:07,857][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007024] [Batch 00440/00823] [00:05:19/00:04:38, 0.726s/it]: train_loss_raw=1.6310, running_loss=1.5854, LR=0.000100
[2025-08-26 10:03:13,738][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007032] [Batch 00448/00823] [00:05:25/00:04:32, 0.726s/it]: train_loss_raw=1.5641, running_loss=1.5861, LR=0.000100
[2025-08-26 10:03:19,598][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007040] [Batch 00456/00823] [00:05:31/00:04:26, 0.726s/it]: train_loss_raw=1.5385, running_loss=1.5884, LR=0.000100
[2025-08-26 10:03:25,415][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007048] [Batch 00464/00823] [00:05:37/00:04:20, 0.726s/it]: train_loss_raw=1.6643, running_loss=1.5900, LR=0.000100
[2025-08-26 10:03:31,165][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007056] [Batch 00472/00823] [00:05:42/00:04:14, 0.726s/it]: train_loss_raw=1.5940, running_loss=1.5908, LR=0.000100
[2025-08-26 10:03:36,912][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007064] [Batch 00480/00823] [00:05:48/00:04:09, 0.726s/it]: train_loss_raw=1.6386, running_loss=1.5893, LR=0.000100
[2025-08-26 10:03:42,913][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007072] [Batch 00488/00823] [00:05:54/00:04:03, 0.726s/it]: train_loss_raw=1.5996, running_loss=1.5885, LR=0.000100
[2025-08-26 10:03:48,718][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007080] [Batch 00496/00823] [00:06:00/00:03:57, 0.726s/it]: train_loss_raw=1.5723, running_loss=1.5881, LR=0.000100
[2025-08-26 10:03:54,580][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007088] [Batch 00504/00823] [00:06:06/00:03:51, 0.727s/it]: train_loss_raw=1.5967, running_loss=1.5873, LR=0.000100
[2025-08-26 10:04:00,485][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007096] [Batch 00512/00823] [00:06:12/00:03:46, 0.727s/it]: train_loss_raw=1.6226, running_loss=1.5895, LR=0.000100
[2025-08-26 10:04:06,448][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007104] [Batch 00520/00823] [00:06:18/00:03:40, 0.727s/it]: train_loss_raw=1.6437, running_loss=1.5894, LR=0.000100
[2025-08-26 10:04:12,432][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007112] [Batch 00528/00823] [00:06:24/00:03:34, 0.727s/it]: train_loss_raw=1.6367, running_loss=1.5885, LR=0.000100
[2025-08-26 10:04:18,356][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007120] [Batch 00536/00823] [00:06:29/00:03:28, 0.728s/it]: train_loss_raw=1.5648, running_loss=1.5864, LR=0.000100
[2025-08-26 10:04:24,337][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007128] [Batch 00544/00823] [00:06:35/00:03:23, 0.728s/it]: train_loss_raw=1.6049, running_loss=1.5847, LR=0.000100
[2025-08-26 10:04:30,159][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007136] [Batch 00552/00823] [00:06:41/00:03:17, 0.728s/it]: train_loss_raw=1.6426, running_loss=1.5865, LR=0.000100
[2025-08-26 10:04:35,982][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007144] [Batch 00560/00823] [00:06:47/00:03:11, 0.728s/it]: train_loss_raw=1.5717, running_loss=1.5828, LR=0.000100
[2025-08-26 10:04:41,778][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007152] [Batch 00568/00823] [00:06:53/00:03:05, 0.728s/it]: train_loss_raw=1.5523, running_loss=1.5796, LR=0.000100
[2025-08-26 10:04:47,571][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007160] [Batch 00576/00823] [00:06:59/00:02:59, 0.728s/it]: train_loss_raw=1.6364, running_loss=1.5790, LR=0.000100
[2025-08-26 10:04:53,439][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007168] [Batch 00584/00823] [00:07:05/00:02:53, 0.728s/it]: train_loss_raw=1.5614, running_loss=1.5788, LR=0.000100
[2025-08-26 10:04:59,225][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007176] [Batch 00592/00823] [00:07:10/00:02:48, 0.728s/it]: train_loss_raw=1.4574, running_loss=1.5790, LR=0.000100
[2025-08-26 10:05:04,994][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007184] [Batch 00600/00823] [00:07:16/00:02:42, 0.728s/it]: train_loss_raw=1.6708, running_loss=1.5778, LR=0.000100
[2025-08-26 10:05:10,766][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007192] [Batch 00608/00823] [00:07:22/00:02:36, 0.728s/it]: train_loss_raw=1.5301, running_loss=1.5764, LR=0.000100
[2025-08-26 10:05:16,676][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007200] [Batch 00616/00823] [00:07:28/00:02:30, 0.728s/it]: train_loss_raw=1.5632, running_loss=1.5741, LR=0.000100
[2025-08-26 10:05:22,817][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007208] [Batch 00624/00823] [00:07:34/00:02:24, 0.728s/it]: train_loss_raw=1.6308, running_loss=1.5726, LR=0.000100
[2025-08-26 10:05:28,701][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007216] [Batch 00632/00823] [00:07:40/00:02:19, 0.728s/it]: train_loss_raw=1.5602, running_loss=1.5726, LR=0.000100
[2025-08-26 10:05:34,508][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007224] [Batch 00640/00823] [00:07:46/00:02:13, 0.728s/it]: train_loss_raw=1.6135, running_loss=1.5742, LR=0.000100
[2025-08-26 10:05:40,415][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007232] [Batch 00648/00823] [00:07:52/00:02:07, 0.728s/it]: train_loss_raw=1.4962, running_loss=1.5734, LR=0.000100
[2025-08-26 10:05:46,407][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007240] [Batch 00656/00823] [00:07:58/00:02:01, 0.729s/it]: train_loss_raw=1.5819, running_loss=1.5747, LR=0.000100
[2025-08-26 10:05:52,675][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007248] [Batch 00664/00823] [00:08:04/00:01:55, 0.729s/it]: train_loss_raw=1.5853, running_loss=1.5723, LR=0.000100
[2025-08-26 10:05:58,472][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007256] [Batch 00672/00823] [00:08:10/00:01:50, 0.729s/it]: train_loss_raw=1.6717, running_loss=1.5719, LR=0.000100
[2025-08-26 10:06:04,255][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007264] [Batch 00680/00823] [00:08:15/00:01:44, 0.729s/it]: train_loss_raw=1.6568, running_loss=1.5708, LR=0.000100
[2025-08-26 10:06:10,055][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007272] [Batch 00688/00823] [00:08:21/00:01:38, 0.729s/it]: train_loss_raw=1.6045, running_loss=1.5717, LR=0.000100
[2025-08-26 10:06:15,866][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007280] [Batch 00696/00823] [00:08:27/00:01:32, 0.729s/it]: train_loss_raw=1.5811, running_loss=1.5743, LR=0.000100
[2025-08-26 10:06:21,679][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007288] [Batch 00704/00823] [00:08:33/00:01:26, 0.729s/it]: train_loss_raw=1.5875, running_loss=1.5727, LR=0.000100
[2025-08-26 10:06:27,539][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007296] [Batch 00712/00823] [00:08:39/00:01:20, 0.729s/it]: train_loss_raw=1.5924, running_loss=1.5723, LR=0.000100
[2025-08-26 10:06:33,213][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007304] [Batch 00720/00823] [00:08:44/00:01:15, 0.729s/it]: train_loss_raw=1.5675, running_loss=1.5706, LR=0.000100
[2025-08-26 10:06:38,837][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007312] [Batch 00728/00823] [00:08:50/00:01:09, 0.729s/it]: train_loss_raw=1.5127, running_loss=1.5678, LR=0.000100
[2025-08-26 10:06:44,853][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007320] [Batch 00736/00823] [00:08:56/00:01:03, 0.729s/it]: train_loss_raw=1.5225, running_loss=1.5663, LR=0.000100
[2025-08-26 10:06:50,667][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007328] [Batch 00744/00823] [00:09:02/00:00:57, 0.729s/it]: train_loss_raw=1.6957, running_loss=1.5674, LR=0.000100
[2025-08-26 10:06:56,511][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007336] [Batch 00752/00823] [00:09:08/00:00:51, 0.729s/it]: train_loss_raw=1.5732, running_loss=1.5665, LR=0.000100
[2025-08-26 10:07:02,457][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007344] [Batch 00760/00823] [00:09:14/00:00:45, 0.729s/it]: train_loss_raw=1.5897, running_loss=1.5661, LR=0.000100
[2025-08-26 10:07:08,260][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007352] [Batch 00768/00823] [00:09:19/00:00:40, 0.729s/it]: train_loss_raw=1.5177, running_loss=1.5636, LR=0.000100
[2025-08-26 10:07:14,175][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007360] [Batch 00776/00823] [00:09:25/00:00:34, 0.729s/it]: train_loss_raw=1.4769, running_loss=1.5607, LR=0.000100
[2025-08-26 10:07:20,120][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007368] [Batch 00784/00823] [00:09:31/00:00:28, 0.729s/it]: train_loss_raw=1.5579, running_loss=1.5638, LR=0.000100
[2025-08-26 10:07:25,864][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007376] [Batch 00792/00823] [00:09:37/00:00:22, 0.729s/it]: train_loss_raw=1.5380, running_loss=1.5654, LR=0.000100
[2025-08-26 10:07:31,765][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007384] [Batch 00800/00823] [00:09:43/00:00:16, 0.729s/it]: train_loss_raw=1.4361, running_loss=1.5634, LR=0.000100
[2025-08-26 10:07:37,826][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007392] [Batch 00808/00823] [00:09:49/00:00:10, 0.729s/it]: train_loss_raw=1.5783, running_loss=1.5645, LR=0.000100
[2025-08-26 10:07:43,731][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007400] [Batch 00816/00823] [00:09:55/00:00:05, 0.730s/it]: train_loss_raw=1.5220, running_loss=1.5629, LR=0.000100
[2025-08-26 10:07:49,252][__main__][INFO] - [VALIDATION] [Epoch 08/29] Starting validation.
[2025-08-26 10:07:59,974][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 007408] [Batch 00007/00013] [00:00:10/00:00:06, 1.340s/it]
[2025-08-26 10:08:06,997][__main__][INFO] - [VALIDATION] [Epoch 08/29] train_loss=1.56471, valid_loss=1.63154
[2025-08-26 10:08:06,997][__main__][INFO] - [VALIDATION] [Epoch 08/29] Metrics:
[2025-08-26 10:08:06,997][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_er      0.700
[2025-08-26 10:08:06,997][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_prec    0.038
[2025-08-26 10:08:06,997][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_recall  0.039
[2025-08-26 10:08:06,997][__main__][INFO] - [VALIDATION] [Epoch 08/29] - pep_recall 0.008
[2025-08-26 10:08:06,999][__main__][INFO] - [TRAIN] [Epoch 08/29] Epoch complete, total time 01:35:30, remaining time 03:42:51, 00:10:36 per epoch
[2025-08-26 10:08:07,400][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007408] [Batch 00001/00823] [00:00:00/00:02:01, 0.148s/it]: train_loss_raw=1.5805, running_loss=1.5805, LR=0.000100
[2025-08-26 10:08:13,550][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007416] [Batch 00009/00823] [00:00:06/00:09:29, 0.700s/it]: train_loss_raw=1.5940, running_loss=1.5767, LR=0.000100
[2025-08-26 10:08:19,642][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007424] [Batch 00017/00823] [00:00:12/00:09:47, 0.729s/it]: train_loss_raw=1.5273, running_loss=1.5760, LR=0.000100
[2025-08-26 10:08:25,679][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007432] [Batch 00025/00823] [00:00:18/00:09:48, 0.737s/it]: train_loss_raw=1.5680, running_loss=1.5750, LR=0.000100
[2025-08-26 10:08:31,531][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007440] [Batch 00033/00823] [00:00:24/00:09:41, 0.736s/it]: train_loss_raw=1.5802, running_loss=1.5737, LR=0.000100
[2025-08-26 10:08:37,393][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007448] [Batch 00041/00823] [00:00:30/00:09:34, 0.735s/it]: train_loss_raw=1.4755, running_loss=1.5715, LR=0.000100
[2025-08-26 10:08:43,261][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007456] [Batch 00049/00823] [00:00:36/00:09:28, 0.735s/it]: train_loss_raw=1.5067, running_loss=1.5691, LR=0.000100
[2025-08-26 10:08:49,153][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007464] [Batch 00057/00823] [00:00:41/00:09:23, 0.735s/it]: train_loss_raw=1.5094, running_loss=1.5685, LR=0.000100
[2025-08-26 10:08:54,809][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007472] [Batch 00065/00823] [00:00:47/00:09:14, 0.732s/it]: train_loss_raw=1.6160, running_loss=1.5675, LR=0.000100
[2025-08-26 10:09:00,616][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007480] [Batch 00073/00823] [00:00:53/00:09:08, 0.731s/it]: train_loss_raw=1.5764, running_loss=1.5699, LR=0.000100
[2025-08-26 10:09:06,330][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007488] [Batch 00081/00823] [00:00:59/00:09:01, 0.729s/it]: train_loss_raw=1.5168, running_loss=1.5684, LR=0.000100
[2025-08-26 10:09:12,084][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007496] [Batch 00089/00823] [00:01:04/00:08:54, 0.728s/it]: train_loss_raw=1.5509, running_loss=1.5688, LR=0.000100
[2025-08-26 10:09:17,966][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007504] [Batch 00097/00823] [00:01:10/00:08:49, 0.729s/it]: train_loss_raw=1.6268, running_loss=1.5681, LR=0.000100
[2025-08-26 10:09:24,015][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007512] [Batch 00105/00823] [00:01:16/00:08:44, 0.731s/it]: train_loss_raw=1.5109, running_loss=1.5652, LR=0.000100
[2025-08-26 10:09:29,727][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007520] [Batch 00113/00823] [00:01:22/00:08:38, 0.730s/it]: train_loss_raw=1.5966, running_loss=1.5665, LR=0.000100
[2025-08-26 10:09:35,442][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007528] [Batch 00121/00823] [00:01:28/00:08:31, 0.729s/it]: train_loss_raw=1.6317, running_loss=1.5657, LR=0.000100
[2025-08-26 10:09:41,347][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007536] [Batch 00129/00823] [00:01:34/00:08:26, 0.729s/it]: train_loss_raw=1.5038, running_loss=1.5613, LR=0.000100
[2025-08-26 10:09:47,375][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007544] [Batch 00137/00823] [00:01:40/00:08:21, 0.731s/it]: train_loss_raw=1.4823, running_loss=1.5591, LR=0.000100
[2025-08-26 10:09:53,096][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007552] [Batch 00145/00823] [00:01:45/00:08:14, 0.730s/it]: train_loss_raw=1.6414, running_loss=1.5586, LR=0.000100
[2025-08-26 10:09:58,885][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007560] [Batch 00153/00823] [00:01:51/00:08:08, 0.730s/it]: train_loss_raw=1.5945, running_loss=1.5586, LR=0.000100
[2025-08-26 10:10:04,676][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007568] [Batch 00161/00823] [00:01:57/00:08:02, 0.729s/it]: train_loss_raw=1.5359, running_loss=1.5602, LR=0.000100
[2025-08-26 10:10:10,483][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007576] [Batch 00169/00823] [00:02:03/00:07:56, 0.729s/it]: train_loss_raw=1.6898, running_loss=1.5605, LR=0.000100
[2025-08-26 10:10:16,334][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007584] [Batch 00177/00823] [00:02:09/00:07:51, 0.729s/it]: train_loss_raw=1.5341, running_loss=1.5601, LR=0.000100
[2025-08-26 10:10:22,243][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007592] [Batch 00185/00823] [00:02:14/00:07:45, 0.730s/it]: train_loss_raw=1.5128, running_loss=1.5606, LR=0.000100
[2025-08-26 10:10:28,197][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007600] [Batch 00193/00823] [00:02:20/00:07:40, 0.730s/it]: train_loss_raw=1.4682, running_loss=1.5594, LR=0.000100
[2025-08-26 10:10:34,086][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007608] [Batch 00201/00823] [00:02:26/00:07:34, 0.731s/it]: train_loss_raw=1.4609, running_loss=1.5576, LR=0.000100
[2025-08-26 10:10:39,839][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007616] [Batch 00209/00823] [00:02:32/00:07:28, 0.730s/it]: train_loss_raw=1.5075, running_loss=1.5582, LR=0.000100
[2025-08-26 10:10:45,691][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007624] [Batch 00217/00823] [00:02:38/00:07:22, 0.730s/it]: train_loss_raw=1.5166, running_loss=1.5557, LR=0.000100
[2025-08-26 10:10:51,467][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007632] [Batch 00225/00823] [00:02:44/00:07:16, 0.730s/it]: train_loss_raw=1.5163, running_loss=1.5549, LR=0.000100
[2025-08-26 10:10:57,127][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007640] [Batch 00233/00823] [00:02:49/00:07:10, 0.729s/it]: train_loss_raw=1.5868, running_loss=1.5556, LR=0.000100
[2025-08-26 10:11:02,885][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007648] [Batch 00241/00823] [00:02:55/00:07:04, 0.729s/it]: train_loss_raw=1.4720, running_loss=1.5556, LR=0.000100
[2025-08-26 10:11:08,970][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007656] [Batch 00249/00823] [00:03:01/00:06:58, 0.730s/it]: train_loss_raw=1.6213, running_loss=1.5546, LR=0.000100
[2025-08-26 10:11:14,837][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007664] [Batch 00257/00823] [00:03:07/00:06:53, 0.730s/it]: train_loss_raw=1.4667, running_loss=1.5544, LR=0.000100
[2025-08-26 10:11:20,618][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007672] [Batch 00265/00823] [00:03:13/00:06:47, 0.730s/it]: train_loss_raw=1.5471, running_loss=1.5543, LR=0.000100
[2025-08-26 10:11:26,406][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007680] [Batch 00273/00823] [00:03:19/00:06:41, 0.730s/it]: train_loss_raw=1.4668, running_loss=1.5540, LR=0.000100
[2025-08-26 10:11:32,307][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007688] [Batch 00281/00823] [00:03:25/00:06:35, 0.730s/it]: train_loss_raw=1.6179, running_loss=1.5532, LR=0.000100
[2025-08-26 10:11:38,216][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007696] [Batch 00289/00823] [00:03:30/00:06:29, 0.730s/it]: train_loss_raw=1.5207, running_loss=1.5552, LR=0.000100
[2025-08-26 10:11:44,317][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007704] [Batch 00297/00823] [00:03:37/00:06:24, 0.731s/it]: train_loss_raw=1.6036, running_loss=1.5558, LR=0.000100
[2025-08-26 10:11:50,350][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007712] [Batch 00305/00823] [00:03:43/00:06:18, 0.731s/it]: train_loss_raw=1.6010, running_loss=1.5537, LR=0.000100
[2025-08-26 10:11:56,416][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007720] [Batch 00313/00823] [00:03:49/00:06:13, 0.732s/it]: train_loss_raw=1.5386, running_loss=1.5541, LR=0.000100
[2025-08-26 10:12:02,465][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007728] [Batch 00321/00823] [00:03:55/00:06:07, 0.733s/it]: train_loss_raw=1.5040, running_loss=1.5545, LR=0.000100
[2025-08-26 10:12:08,577][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007736] [Batch 00329/00823] [00:04:01/00:06:02, 0.734s/it]: train_loss_raw=1.5292, running_loss=1.5570, LR=0.000100
[2025-08-26 10:12:14,663][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007744] [Batch 00337/00823] [00:04:07/00:05:56, 0.734s/it]: train_loss_raw=1.5743, running_loss=1.5556, LR=0.000100
[2025-08-26 10:12:20,765][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007752] [Batch 00345/00823] [00:04:13/00:05:51, 0.735s/it]: train_loss_raw=1.5431, running_loss=1.5548, LR=0.000100
[2025-08-26 10:12:26,870][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007760] [Batch 00353/00823] [00:04:19/00:05:45, 0.735s/it]: train_loss_raw=1.5639, running_loss=1.5552, LR=0.000100
[2025-08-26 10:12:32,946][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007768] [Batch 00361/00823] [00:04:25/00:05:40, 0.736s/it]: train_loss_raw=1.5799, running_loss=1.5548, LR=0.000100
[2025-08-26 10:12:39,028][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007776] [Batch 00369/00823] [00:04:31/00:05:34, 0.737s/it]: train_loss_raw=1.4407, running_loss=1.5532, LR=0.000100
[2025-08-26 10:12:45,116][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007784] [Batch 00377/00823] [00:04:37/00:05:28, 0.737s/it]: train_loss_raw=1.5287, running_loss=1.5535, LR=0.000100
[2025-08-26 10:12:51,095][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007792] [Batch 00385/00823] [00:04:43/00:05:22, 0.737s/it]: train_loss_raw=1.4647, running_loss=1.5530, LR=0.000100
[2025-08-26 10:12:57,261][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007800] [Batch 00393/00823] [00:04:50/00:05:17, 0.738s/it]: train_loss_raw=1.5800, running_loss=1.5512, LR=0.000100
[2025-08-26 10:13:03,322][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007808] [Batch 00401/00823] [00:04:56/00:05:11, 0.738s/it]: train_loss_raw=1.5317, running_loss=1.5490, LR=0.000100
[2025-08-26 10:13:09,434][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007816] [Batch 00409/00823] [00:05:02/00:05:05, 0.739s/it]: train_loss_raw=1.5502, running_loss=1.5480, LR=0.000100
[2025-08-26 10:13:15,492][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007824] [Batch 00417/00823] [00:05:08/00:05:00, 0.739s/it]: train_loss_raw=1.5077, running_loss=1.5482, LR=0.000100
[2025-08-26 10:13:21,580][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007832] [Batch 00425/00823] [00:05:14/00:04:54, 0.740s/it]: train_loss_raw=1.6408, running_loss=1.5481, LR=0.000100
[2025-08-26 10:13:27,880][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007840] [Batch 00433/00823] [00:05:20/00:04:48, 0.740s/it]: train_loss_raw=1.4615, running_loss=1.5434, LR=0.000100
[2025-08-26 10:13:33,871][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007848] [Batch 00441/00823] [00:05:26/00:04:42, 0.741s/it]: train_loss_raw=1.5184, running_loss=1.5422, LR=0.000100
[2025-08-26 10:13:39,895][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007856] [Batch 00449/00823] [00:05:32/00:04:37, 0.741s/it]: train_loss_raw=1.4890, running_loss=1.5413, LR=0.000100
[2025-08-26 10:13:46,086][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007864] [Batch 00457/00823] [00:05:38/00:04:31, 0.741s/it]: train_loss_raw=1.5275, running_loss=1.5427, LR=0.000100
[2025-08-26 10:13:52,182][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007872] [Batch 00465/00823] [00:05:44/00:04:25, 0.742s/it]: train_loss_raw=1.5791, running_loss=1.5438, LR=0.000100
[2025-08-26 10:13:58,269][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007880] [Batch 00473/00823] [00:05:51/00:04:19, 0.742s/it]: train_loss_raw=1.5375, running_loss=1.5446, LR=0.000100
[2025-08-26 10:14:04,353][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007888] [Batch 00481/00823] [00:05:57/00:04:13, 0.742s/it]: train_loss_raw=1.5701, running_loss=1.5471, LR=0.000100
[2025-08-26 10:14:10,448][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007896] [Batch 00489/00823] [00:06:03/00:04:08, 0.743s/it]: train_loss_raw=1.5080, running_loss=1.5466, LR=0.000100
[2025-08-26 10:14:16,482][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007904] [Batch 00497/00823] [00:06:09/00:04:02, 0.743s/it]: train_loss_raw=1.5556, running_loss=1.5471, LR=0.000100
[2025-08-26 10:14:22,552][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007912] [Batch 00505/00823] [00:06:15/00:03:56, 0.743s/it]: train_loss_raw=1.5463, running_loss=1.5472, LR=0.000100
[2025-08-26 10:14:28,567][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007920] [Batch 00513/00823] [00:06:21/00:03:50, 0.743s/it]: train_loss_raw=1.5908, running_loss=1.5483, LR=0.000100
[2025-08-26 10:14:34,558][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007928] [Batch 00521/00823] [00:06:27/00:03:44, 0.743s/it]: train_loss_raw=1.5523, running_loss=1.5486, LR=0.000100
[2025-08-26 10:14:40,611][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007936] [Batch 00529/00823] [00:06:33/00:03:38, 0.744s/it]: train_loss_raw=1.5886, running_loss=1.5508, LR=0.000100
[2025-08-26 10:14:46,681][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007944] [Batch 00537/00823] [00:06:39/00:03:32, 0.744s/it]: train_loss_raw=1.5378, running_loss=1.5490, LR=0.000100
[2025-08-26 10:14:52,776][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007952] [Batch 00545/00823] [00:06:45/00:03:26, 0.744s/it]: train_loss_raw=1.6252, running_loss=1.5507, LR=0.000100
[2025-08-26 10:14:58,901][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007960] [Batch 00553/00823] [00:06:51/00:03:20, 0.744s/it]: train_loss_raw=1.5647, running_loss=1.5490, LR=0.000100
[2025-08-26 10:15:04,983][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007968] [Batch 00561/00823] [00:06:57/00:03:15, 0.745s/it]: train_loss_raw=1.5436, running_loss=1.5500, LR=0.000100
[2025-08-26 10:15:11,005][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007976] [Batch 00569/00823] [00:07:03/00:03:09, 0.745s/it]: train_loss_raw=1.5332, running_loss=1.5471, LR=0.000100
[2025-08-26 10:15:17,035][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007984] [Batch 00577/00823] [00:07:09/00:03:03, 0.745s/it]: train_loss_raw=1.5283, running_loss=1.5465, LR=0.000100
[2025-08-26 10:15:23,145][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007992] [Batch 00585/00823] [00:07:15/00:02:57, 0.745s/it]: train_loss_raw=1.5462, running_loss=1.5477, LR=0.000100
[2025-08-26 10:15:29,189][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008000] [Batch 00593/00823] [00:07:21/00:02:51, 0.745s/it]: train_loss_raw=1.4588, running_loss=1.5479, LR=0.000100
[2025-08-26 10:15:40,245][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008008] [Batch 00601/00823] [00:07:32/00:02:47, 0.754s/it]: train_loss_raw=1.5627, running_loss=1.5470, LR=0.000100
[2025-08-26 10:15:46,298][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008016] [Batch 00609/00823] [00:07:39/00:02:41, 0.754s/it]: train_loss_raw=1.4554, running_loss=1.5432, LR=0.000100
[2025-08-26 10:15:52,335][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008024] [Batch 00617/00823] [00:07:45/00:02:35, 0.754s/it]: train_loss_raw=1.5571, running_loss=1.5424, LR=0.000100
[2025-08-26 10:15:58,359][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008032] [Batch 00625/00823] [00:07:51/00:02:29, 0.754s/it]: train_loss_raw=1.6118, running_loss=1.5434, LR=0.000100
[2025-08-26 10:16:04,470][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008040] [Batch 00633/00823] [00:07:57/00:02:23, 0.754s/it]: train_loss_raw=1.4439, running_loss=1.5437, LR=0.000100
[2025-08-26 10:16:10,601][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008048] [Batch 00641/00823] [00:08:03/00:02:17, 0.754s/it]: train_loss_raw=1.6057, running_loss=1.5455, LR=0.000100
[2025-08-26 10:16:16,598][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008056] [Batch 00649/00823] [00:08:09/00:02:11, 0.754s/it]: train_loss_raw=1.5811, running_loss=1.5447, LR=0.000100
[2025-08-26 10:16:22,602][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008064] [Batch 00657/00823] [00:08:15/00:02:05, 0.754s/it]: train_loss_raw=1.5131, running_loss=1.5425, LR=0.000100
[2025-08-26 10:16:28,718][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008072] [Batch 00665/00823] [00:08:21/00:01:59, 0.754s/it]: train_loss_raw=1.5206, running_loss=1.5432, LR=0.000100
[2025-08-26 10:16:34,814][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008080] [Batch 00673/00823] [00:08:27/00:01:53, 0.754s/it]: train_loss_raw=1.4593, running_loss=1.5405, LR=0.000100
[2025-08-26 10:16:40,909][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008088] [Batch 00681/00823] [00:08:33/00:01:47, 0.754s/it]: train_loss_raw=1.4303, running_loss=1.5397, LR=0.000100
[2025-08-26 10:16:47,096][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008096] [Batch 00689/00823] [00:08:39/00:01:41, 0.754s/it]: train_loss_raw=1.5848, running_loss=1.5386, LR=0.000100
[2025-08-26 10:16:53,161][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008104] [Batch 00697/00823] [00:08:45/00:01:35, 0.755s/it]: train_loss_raw=1.4753, running_loss=1.5384, LR=0.000100
[2025-08-26 10:16:59,239][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008112] [Batch 00705/00823] [00:08:51/00:01:29, 0.755s/it]: train_loss_raw=1.5995, running_loss=1.5403, LR=0.000100
[2025-08-26 10:17:05,285][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008120] [Batch 00713/00823] [00:08:58/00:01:23, 0.755s/it]: train_loss_raw=1.4330, running_loss=1.5409, LR=0.000100
[2025-08-26 10:17:11,370][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008128] [Batch 00721/00823] [00:09:04/00:01:16, 0.755s/it]: train_loss_raw=1.5747, running_loss=1.5435, LR=0.000100
[2025-08-26 10:17:17,502][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008136] [Batch 00729/00823] [00:09:10/00:01:10, 0.755s/it]: train_loss_raw=1.5983, running_loss=1.5443, LR=0.000100
[2025-08-26 10:17:23,569][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008144] [Batch 00737/00823] [00:09:16/00:01:04, 0.755s/it]: train_loss_raw=1.5898, running_loss=1.5452, LR=0.000100
[2025-08-26 10:17:29,648][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008152] [Batch 00745/00823] [00:09:22/00:00:58, 0.755s/it]: train_loss_raw=1.4548, running_loss=1.5414, LR=0.000100
[2025-08-26 10:17:35,526][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008160] [Batch 00753/00823] [00:09:28/00:00:52, 0.755s/it]: train_loss_raw=1.5747, running_loss=1.5389, LR=0.000100
[2025-08-26 10:17:41,562][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008168] [Batch 00761/00823] [00:09:34/00:00:46, 0.755s/it]: train_loss_raw=1.5079, running_loss=1.5378, LR=0.000100
[2025-08-26 10:17:47,685][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008176] [Batch 00769/00823] [00:09:40/00:00:40, 0.755s/it]: train_loss_raw=1.5536, running_loss=1.5376, LR=0.000100
[2025-08-26 10:17:53,830][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008184] [Batch 00777/00823] [00:09:46/00:00:34, 0.755s/it]: train_loss_raw=1.4316, running_loss=1.5376, LR=0.000100
[2025-08-26 10:17:59,899][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008192] [Batch 00785/00823] [00:09:52/00:00:28, 0.755s/it]: train_loss_raw=1.4490, running_loss=1.5352, LR=0.000100
[2025-08-26 10:18:05,915][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008200] [Batch 00793/00823] [00:09:58/00:00:22, 0.755s/it]: train_loss_raw=1.5920, running_loss=1.5351, LR=0.000100
[2025-08-26 10:18:11,876][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008208] [Batch 00801/00823] [00:10:04/00:00:16, 0.755s/it]: train_loss_raw=1.5656, running_loss=1.5365, LR=0.000100
[2025-08-26 10:18:17,970][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008216] [Batch 00809/00823] [00:10:10/00:00:10, 0.755s/it]: train_loss_raw=1.4987, running_loss=1.5333, LR=0.000100
[2025-08-26 10:18:24,033][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008224] [Batch 00817/00823] [00:10:16/00:00:04, 0.755s/it]: train_loss_raw=1.5064, running_loss=1.5328, LR=0.000100
[2025-08-26 10:18:34,144][__main__][INFO] - [VALIDATION] [Epoch 09/29] Starting validation.
[2025-08-26 10:18:45,695][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 008231] [Batch 00007/00013] [00:00:11/00:00:07, 1.444s/it]
[2025-08-26 10:18:53,080][__main__][INFO] - [VALIDATION] [Epoch 09/29] train_loss=1.53193, valid_loss=1.58339
[2025-08-26 10:18:53,081][__main__][INFO] - [VALIDATION] [Epoch 09/29] Metrics:
[2025-08-26 10:18:53,081][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_er      0.674
[2025-08-26 10:18:53,081][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_prec    0.039
[2025-08-26 10:18:53,081][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_recall  0.040
[2025-08-26 10:18:53,081][__main__][INFO] - [VALIDATION] [Epoch 09/29] - pep_recall 0.008
[2025-08-26 10:18:53,083][__main__][INFO] - [TRAIN] [Epoch 09/29] Epoch complete, total time 01:46:16, remaining time 03:32:33, 00:10:37 per epoch
[2025-08-26 10:18:54,211][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008232] [Batch 00002/00823] [00:00:00/00:06:09, 0.451s/it]: train_loss_raw=1.5336, running_loss=1.5511, LR=0.000100
[2025-08-26 10:19:00,212][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008240] [Batch 00010/00823] [00:00:06/00:09:21, 0.690s/it]: train_loss_raw=1.4318, running_loss=1.5476, LR=0.000100
[2025-08-26 10:19:06,237][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008248] [Batch 00018/00823] [00:00:12/00:09:38, 0.718s/it]: train_loss_raw=1.5007, running_loss=1.5457, LR=0.000100
[2025-08-26 10:19:12,330][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008256] [Batch 00026/00823] [00:00:19/00:09:43, 0.732s/it]: train_loss_raw=1.4936, running_loss=1.5431, LR=0.000100
[2025-08-26 10:19:18,484][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008264] [Batch 00034/00823] [00:00:25/00:09:44, 0.740s/it]: train_loss_raw=1.5593, running_loss=1.5418, LR=0.000100
[2025-08-26 10:19:24,600][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008272] [Batch 00042/00823] [00:00:31/00:09:41, 0.745s/it]: train_loss_raw=1.5899, running_loss=1.5407, LR=0.000100
[2025-08-26 10:19:30,766][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008280] [Batch 00050/00823] [00:00:37/00:09:39, 0.749s/it]: train_loss_raw=1.5464, running_loss=1.5385, LR=0.000100
[2025-08-26 10:19:36,839][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008288] [Batch 00058/00823] [00:00:43/00:09:34, 0.750s/it]: train_loss_raw=1.4416, running_loss=1.5339, LR=0.000100
[2025-08-26 10:19:42,833][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008296] [Batch 00066/00823] [00:00:49/00:09:28, 0.750s/it]: train_loss_raw=1.4136, running_loss=1.5303, LR=0.000100
[2025-08-26 10:19:48,894][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008304] [Batch 00074/00823] [00:00:55/00:09:22, 0.751s/it]: train_loss_raw=1.4299, running_loss=1.5269, LR=0.000100
[2025-08-26 10:19:54,953][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008312] [Batch 00082/00823] [00:01:01/00:09:17, 0.752s/it]: train_loss_raw=1.4645, running_loss=1.5221, LR=0.000100
[2025-08-26 10:20:00,998][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008320] [Batch 00090/00823] [00:01:07/00:09:11, 0.752s/it]: train_loss_raw=1.4182, running_loss=1.5206, LR=0.000100
[2025-08-26 10:20:07,075][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008328] [Batch 00098/00823] [00:01:13/00:09:05, 0.753s/it]: train_loss_raw=1.6014, running_loss=1.5194, LR=0.000100
[2025-08-26 10:20:13,137][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008336] [Batch 00106/00823] [00:01:19/00:08:59, 0.753s/it]: train_loss_raw=1.5532, running_loss=1.5194, LR=0.000100
[2025-08-26 10:20:19,298][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008344] [Batch 00114/00823] [00:01:25/00:08:54, 0.754s/it]: train_loss_raw=1.4647, running_loss=1.5164, LR=0.000100
[2025-08-26 10:20:25,354][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008352] [Batch 00122/00823] [00:01:32/00:08:48, 0.754s/it]: train_loss_raw=1.4580, running_loss=1.5127, LR=0.000100
[2025-08-26 10:20:31,388][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008360] [Batch 00130/00823] [00:01:38/00:08:42, 0.754s/it]: train_loss_raw=1.5623, running_loss=1.5126, LR=0.000100
[2025-08-26 10:20:37,480][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008368] [Batch 00138/00823] [00:01:44/00:08:37, 0.755s/it]: train_loss_raw=1.5616, running_loss=1.5109, LR=0.000100
[2025-08-26 10:20:43,677][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008376] [Batch 00146/00823] [00:01:50/00:08:31, 0.756s/it]: train_loss_raw=1.4904, running_loss=1.5120, LR=0.000100
[2025-08-26 10:20:49,786][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008384] [Batch 00154/00823] [00:01:56/00:08:25, 0.756s/it]: train_loss_raw=1.3647, running_loss=1.5087, LR=0.000100
[2025-08-26 10:20:55,804][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008392] [Batch 00162/00823] [00:02:02/00:08:19, 0.756s/it]: train_loss_raw=1.5655, running_loss=1.5074, LR=0.000100
[2025-08-26 10:21:01,878][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008400] [Batch 00170/00823] [00:02:08/00:08:13, 0.756s/it]: train_loss_raw=1.4213, running_loss=1.5041, LR=0.000100
[2025-08-26 10:21:07,962][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008408] [Batch 00178/00823] [00:02:14/00:08:07, 0.756s/it]: train_loss_raw=1.5223, running_loss=1.5038, LR=0.000100
[2025-08-26 10:21:14,018][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008416] [Batch 00186/00823] [00:02:20/00:08:01, 0.756s/it]: train_loss_raw=1.4784, running_loss=1.5037, LR=0.000100
[2025-08-26 10:21:19,995][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008424] [Batch 00194/00823] [00:02:26/00:07:55, 0.756s/it]: train_loss_raw=1.5705, running_loss=1.5042, LR=0.000100
[2025-08-26 10:21:26,012][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008432] [Batch 00202/00823] [00:02:32/00:07:49, 0.756s/it]: train_loss_raw=1.4957, running_loss=1.5032, LR=0.000100
[2025-08-26 10:21:32,062][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008440] [Batch 00210/00823] [00:02:38/00:07:43, 0.756s/it]: train_loss_raw=1.4378, running_loss=1.5045, LR=0.000100
[2025-08-26 10:21:38,120][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008448] [Batch 00218/00823] [00:02:44/00:07:37, 0.756s/it]: train_loss_raw=1.5238, running_loss=1.5015, LR=0.000100
[2025-08-26 10:21:44,195][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008456] [Batch 00226/00823] [00:02:50/00:07:31, 0.756s/it]: train_loss_raw=1.5740, running_loss=1.5015, LR=0.000100
[2025-08-26 10:21:50,190][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008464] [Batch 00234/00823] [00:02:56/00:07:25, 0.756s/it]: train_loss_raw=1.5491, running_loss=1.5017, LR=0.000100
[2025-08-26 10:21:56,205][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008472] [Batch 00242/00823] [00:03:02/00:07:19, 0.756s/it]: train_loss_raw=1.5213, running_loss=1.5037, LR=0.000100
[2025-08-26 10:22:02,289][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008480] [Batch 00250/00823] [00:03:08/00:07:13, 0.756s/it]: train_loss_raw=1.5980, running_loss=1.5040, LR=0.000100
[2025-08-26 10:22:08,340][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008488] [Batch 00258/00823] [00:03:15/00:07:07, 0.756s/it]: train_loss_raw=1.5230, running_loss=1.5043, LR=0.000100
[2025-08-26 10:22:14,420][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008496] [Batch 00266/00823] [00:03:21/00:07:01, 0.756s/it]: train_loss_raw=1.5060, running_loss=1.5060, LR=0.000100
[2025-08-26 10:22:20,454][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008504] [Batch 00274/00823] [00:03:27/00:06:55, 0.756s/it]: train_loss_raw=1.5833, running_loss=1.5052, LR=0.000100
[2025-08-26 10:22:26,481][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008512] [Batch 00282/00823] [00:03:33/00:06:48, 0.756s/it]: train_loss_raw=1.3952, running_loss=1.5032, LR=0.000100
[2025-08-26 10:22:32,547][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008520] [Batch 00290/00823] [00:03:39/00:06:42, 0.756s/it]: train_loss_raw=1.4988, running_loss=1.5018, LR=0.000100
[2025-08-26 10:22:38,603][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008528] [Batch 00298/00823] [00:03:45/00:06:36, 0.756s/it]: train_loss_raw=1.5218, running_loss=1.5006, LR=0.000100
[2025-08-26 10:22:44,733][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008536] [Batch 00306/00823] [00:03:51/00:06:30, 0.756s/it]: train_loss_raw=1.4735, running_loss=1.5007, LR=0.000100
[2025-08-26 10:22:50,827][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008544] [Batch 00314/00823] [00:03:57/00:06:25, 0.756s/it]: train_loss_raw=1.5083, running_loss=1.5010, LR=0.000100
[2025-08-26 10:22:56,958][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008552] [Batch 00322/00823] [00:04:03/00:06:19, 0.757s/it]: train_loss_raw=1.4808, running_loss=1.4983, LR=0.000100
[2025-08-26 10:23:03,035][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008560] [Batch 00330/00823] [00:04:09/00:06:13, 0.757s/it]: train_loss_raw=1.5610, running_loss=1.4981, LR=0.000100
[2025-08-26 10:23:09,098][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008568] [Batch 00338/00823] [00:04:15/00:06:07, 0.757s/it]: train_loss_raw=1.4780, running_loss=1.4985, LR=0.000100
[2025-08-26 10:23:15,230][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008576] [Batch 00346/00823] [00:04:21/00:06:01, 0.757s/it]: train_loss_raw=1.4914, running_loss=1.4985, LR=0.000100
[2025-08-26 10:23:21,363][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008584] [Batch 00354/00823] [00:04:28/00:05:55, 0.757s/it]: train_loss_raw=1.5670, running_loss=1.4978, LR=0.000100
[2025-08-26 10:23:27,402][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008592] [Batch 00362/00823] [00:04:34/00:05:49, 0.757s/it]: train_loss_raw=1.4554, running_loss=1.4972, LR=0.000100
[2025-08-26 10:23:33,467][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008600] [Batch 00370/00823] [00:04:40/00:05:43, 0.757s/it]: train_loss_raw=1.5053, running_loss=1.4974, LR=0.000100
[2025-08-26 10:23:39,535][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008608] [Batch 00378/00823] [00:04:46/00:05:36, 0.757s/it]: train_loss_raw=1.5767, running_loss=1.4999, LR=0.000100
[2025-08-26 10:23:45,669][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008616] [Batch 00386/00823] [00:04:52/00:05:30, 0.757s/it]: train_loss_raw=1.4803, running_loss=1.4996, LR=0.000100
[2025-08-26 10:23:51,766][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008624] [Batch 00394/00823] [00:04:58/00:05:24, 0.758s/it]: train_loss_raw=1.4986, running_loss=1.4986, LR=0.000100
[2025-08-26 10:23:57,794][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008632] [Batch 00402/00823] [00:05:04/00:05:18, 0.757s/it]: train_loss_raw=1.5144, running_loss=1.4991, LR=0.000100
[2025-08-26 10:24:03,900][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008640] [Batch 00410/00823] [00:05:10/00:05:12, 0.758s/it]: train_loss_raw=1.5350, running_loss=1.5023, LR=0.000100
[2025-08-26 10:24:09,865][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008648] [Batch 00418/00823] [00:05:16/00:05:06, 0.757s/it]: train_loss_raw=1.4114, running_loss=1.5006, LR=0.000100
[2025-08-26 10:24:15,825][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008656] [Batch 00426/00823] [00:05:22/00:05:00, 0.757s/it]: train_loss_raw=1.5280, running_loss=1.5008, LR=0.000100
[2025-08-26 10:24:21,839][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008664] [Batch 00434/00823] [00:05:28/00:04:54, 0.757s/it]: train_loss_raw=1.3754, running_loss=1.4988, LR=0.000100
[2025-08-26 10:24:27,900][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008672] [Batch 00442/00823] [00:05:34/00:04:48, 0.757s/it]: train_loss_raw=1.3983, running_loss=1.4967, LR=0.000100
[2025-08-26 10:24:33,984][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008680] [Batch 00450/00823] [00:05:40/00:04:42, 0.757s/it]: train_loss_raw=1.4561, running_loss=1.4945, LR=0.000100
[2025-08-26 10:24:40,042][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008688] [Batch 00458/00823] [00:05:46/00:04:36, 0.757s/it]: train_loss_raw=1.4952, running_loss=1.4946, LR=0.000100
[2025-08-26 10:24:46,100][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008696] [Batch 00466/00823] [00:05:52/00:04:30, 0.757s/it]: train_loss_raw=1.5296, running_loss=1.4943, LR=0.000100
[2025-08-26 10:24:52,167][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008704] [Batch 00474/00823] [00:05:58/00:04:24, 0.757s/it]: train_loss_raw=1.4907, running_loss=1.4939, LR=0.000100
[2025-08-26 10:24:58,183][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008712] [Batch 00482/00823] [00:06:04/00:04:18, 0.757s/it]: train_loss_raw=1.4561, running_loss=1.4928, LR=0.000100
[2025-08-26 10:25:04,205][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008720] [Batch 00490/00823] [00:06:10/00:04:12, 0.757s/it]: train_loss_raw=1.5251, running_loss=1.4929, LR=0.000100
[2025-08-26 10:25:10,342][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008728] [Batch 00498/00823] [00:06:17/00:04:06, 0.757s/it]: train_loss_raw=1.4147, running_loss=1.4911, LR=0.000100
[2025-08-26 10:25:16,456][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008736] [Batch 00506/00823] [00:06:23/00:04:00, 0.757s/it]: train_loss_raw=1.5761, running_loss=1.4894, LR=0.000100
[2025-08-26 10:25:22,512][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008744] [Batch 00514/00823] [00:06:29/00:03:53, 0.757s/it]: train_loss_raw=1.4418, running_loss=1.4889, LR=0.000100
[2025-08-26 10:25:28,527][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008752] [Batch 00522/00823] [00:06:35/00:03:47, 0.757s/it]: train_loss_raw=1.4987, running_loss=1.4903, LR=0.000100
[2025-08-26 10:25:34,571][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008760] [Batch 00530/00823] [00:06:41/00:03:41, 0.757s/it]: train_loss_raw=1.4793, running_loss=1.4893, LR=0.000100
[2025-08-26 10:25:40,621][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008768] [Batch 00538/00823] [00:06:47/00:03:35, 0.757s/it]: train_loss_raw=1.5775, running_loss=1.4921, LR=0.000100
[2025-08-26 10:25:46,703][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008776] [Batch 00546/00823] [00:06:53/00:03:29, 0.757s/it]: train_loss_raw=1.5157, running_loss=1.4926, LR=0.000100
[2025-08-26 10:25:52,719][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008784] [Batch 00554/00823] [00:06:59/00:03:23, 0.757s/it]: train_loss_raw=1.5380, running_loss=1.4940, LR=0.000100
[2025-08-26 10:25:58,783][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008792] [Batch 00562/00823] [00:07:05/00:03:17, 0.757s/it]: train_loss_raw=1.4441, running_loss=1.4940, LR=0.000100
[2025-08-26 10:26:04,844][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008800] [Batch 00570/00823] [00:07:11/00:03:11, 0.757s/it]: train_loss_raw=1.5419, running_loss=1.4952, LR=0.000100
[2025-08-26 10:26:10,916][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008808] [Batch 00578/00823] [00:07:17/00:03:05, 0.757s/it]: train_loss_raw=1.5254, running_loss=1.4938, LR=0.000100
[2025-08-26 10:26:16,985][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008816] [Batch 00586/00823] [00:07:23/00:02:59, 0.757s/it]: train_loss_raw=1.4876, running_loss=1.4935, LR=0.000100
[2025-08-26 10:26:23,034][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008824] [Batch 00594/00823] [00:07:29/00:02:53, 0.757s/it]: train_loss_raw=1.4116, running_loss=1.4901, LR=0.000100
[2025-08-26 10:26:29,058][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008832] [Batch 00602/00823] [00:07:35/00:02:47, 0.757s/it]: train_loss_raw=1.5153, running_loss=1.4891, LR=0.000100
[2025-08-26 10:26:35,119][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008840] [Batch 00610/00823] [00:07:41/00:02:41, 0.757s/it]: train_loss_raw=1.4937, running_loss=1.4889, LR=0.000100
[2025-08-26 10:26:41,162][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008848] [Batch 00618/00823] [00:07:47/00:02:35, 0.757s/it]: train_loss_raw=1.5028, running_loss=1.4888, LR=0.000100
[2025-08-26 10:26:47,222][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008856] [Batch 00626/00823] [00:07:53/00:02:29, 0.757s/it]: train_loss_raw=1.4669, running_loss=1.4877, LR=0.000100
[2025-08-26 10:26:53,290][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008864] [Batch 00634/00823] [00:07:59/00:02:23, 0.757s/it]: train_loss_raw=1.4870, running_loss=1.4874, LR=0.000100
[2025-08-26 10:26:59,382][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008872] [Batch 00642/00823] [00:08:06/00:02:17, 0.757s/it]: train_loss_raw=1.5084, running_loss=1.4881, LR=0.000100
[2025-08-26 10:27:05,520][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008880] [Batch 00650/00823] [00:08:12/00:02:11, 0.757s/it]: train_loss_raw=1.3782, running_loss=1.4867, LR=0.000100
[2025-08-26 10:27:11,646][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008888] [Batch 00658/00823] [00:08:18/00:02:04, 0.757s/it]: train_loss_raw=1.4928, running_loss=1.4841, LR=0.000100
[2025-08-26 10:27:17,671][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008896] [Batch 00666/00823] [00:08:24/00:01:58, 0.757s/it]: train_loss_raw=1.5402, running_loss=1.4840, LR=0.000100
[2025-08-26 10:27:23,701][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008904] [Batch 00674/00823] [00:08:30/00:01:52, 0.757s/it]: train_loss_raw=1.4440, running_loss=1.4839, LR=0.000100
[2025-08-26 10:27:29,736][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008912] [Batch 00682/00823] [00:08:36/00:01:46, 0.757s/it]: train_loss_raw=1.5197, running_loss=1.4830, LR=0.000100
[2025-08-26 10:27:35,769][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008920] [Batch 00690/00823] [00:08:42/00:01:40, 0.757s/it]: train_loss_raw=1.4333, running_loss=1.4830, LR=0.000100
[2025-08-26 10:27:41,404][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008928] [Batch 00698/00823] [00:08:48/00:01:34, 0.757s/it]: train_loss_raw=1.4783, running_loss=1.4835, LR=0.000100
[2025-08-26 10:27:47,287][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008936] [Batch 00706/00823] [00:08:53/00:01:28, 0.756s/it]: train_loss_raw=1.5199, running_loss=1.4817, LR=0.000100
[2025-08-26 10:27:53,302][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008944] [Batch 00714/00823] [00:08:59/00:01:22, 0.756s/it]: train_loss_raw=1.3793, running_loss=1.4810, LR=0.000100
[2025-08-26 10:27:59,381][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008952] [Batch 00722/00823] [00:09:06/00:01:16, 0.756s/it]: train_loss_raw=1.4700, running_loss=1.4776, LR=0.000100
[2025-08-26 10:28:05,460][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008960] [Batch 00730/00823] [00:09:12/00:01:10, 0.756s/it]: train_loss_raw=1.4867, running_loss=1.4773, LR=0.000100
[2025-08-26 10:28:11,518][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008968] [Batch 00738/00823] [00:09:18/00:01:04, 0.756s/it]: train_loss_raw=1.4749, running_loss=1.4784, LR=0.000100
[2025-08-26 10:28:17,595][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008976] [Batch 00746/00823] [00:09:24/00:00:58, 0.756s/it]: train_loss_raw=1.5095, running_loss=1.4783, LR=0.000100
[2025-08-26 10:28:23,690][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008984] [Batch 00754/00823] [00:09:30/00:00:52, 0.756s/it]: train_loss_raw=1.5123, running_loss=1.4788, LR=0.000100
[2025-08-26 10:28:29,722][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008992] [Batch 00762/00823] [00:09:36/00:00:46, 0.756s/it]: train_loss_raw=1.4602, running_loss=1.4784, LR=0.000100
[2025-08-26 10:28:35,842][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009000] [Batch 00770/00823] [00:09:42/00:00:40, 0.757s/it]: train_loss_raw=1.5128, running_loss=1.4785, LR=0.000100
[2025-08-26 10:28:41,914][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009008] [Batch 00778/00823] [00:09:48/00:00:34, 0.757s/it]: train_loss_raw=1.4570, running_loss=1.4798, LR=0.000100
[2025-08-26 10:28:48,038][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009016] [Batch 00786/00823] [00:09:54/00:00:27, 0.757s/it]: train_loss_raw=1.3960, running_loss=1.4798, LR=0.000100
[2025-08-26 10:28:54,031][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009024] [Batch 00794/00823] [00:10:00/00:00:21, 0.757s/it]: train_loss_raw=1.5155, running_loss=1.4821, LR=0.000100
[2025-08-26 10:29:00,102][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009032] [Batch 00802/00823] [00:10:06/00:00:15, 0.757s/it]: train_loss_raw=1.4901, running_loss=1.4817, LR=0.000100
[2025-08-26 10:29:06,179][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009040] [Batch 00810/00823] [00:10:12/00:00:09, 0.757s/it]: train_loss_raw=1.4519, running_loss=1.4816, LR=0.000100
[2025-08-26 10:29:12,273][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009048] [Batch 00818/00823] [00:10:18/00:00:03, 0.757s/it]: train_loss_raw=1.5649, running_loss=1.4817, LR=0.000100
[2025-08-26 10:29:16,310][__main__][INFO] - [VALIDATION] [Epoch 10/29] Starting validation.
[2025-08-26 10:29:28,097][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 009054] [Batch 00007/00013] [00:00:11/00:00:07, 1.473s/it]
[2025-08-26 10:29:35,435][__main__][INFO] - [VALIDATION] [Epoch 10/29] train_loss=1.48097, valid_loss=1.57227
[2025-08-26 10:29:35,436][__main__][INFO] - [VALIDATION] [Epoch 10/29] Metrics:
[2025-08-26 10:29:35,436][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_er      0.672
[2025-08-26 10:29:35,436][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_prec    0.037
[2025-08-26 10:29:35,436][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_recall  0.038
[2025-08-26 10:29:35,436][__main__][INFO] - [VALIDATION] [Epoch 10/29] - pep_recall 0.008
[2025-08-26 10:29:35,438][__main__][INFO] - [TRAIN] [Epoch 10/29] Epoch complete, total time 01:56:59, remaining time 03:22:04, 00:10:38 per epoch
[2025-08-26 10:29:37,381][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009056] [Batch 00003/00823] [00:00:01/00:07:31, 0.550s/it]: train_loss_raw=1.4354, running_loss=1.3933, LR=0.000100
[2025-08-26 10:29:43,478][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009064] [Batch 00011/00823] [00:00:07/00:09:31, 0.704s/it]: train_loss_raw=1.5240, running_loss=1.3981, LR=0.000100
[2025-08-26 10:29:49,613][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009072] [Batch 00019/00823] [00:00:13/00:09:47, 0.731s/it]: train_loss_raw=1.5678, running_loss=1.4026, LR=0.000100
[2025-08-26 10:29:55,713][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009080] [Batch 00027/00823] [00:00:19/00:09:49, 0.740s/it]: train_loss_raw=1.5000, running_loss=1.4102, LR=0.000100
[2025-08-26 10:30:01,816][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009088] [Batch 00035/00823] [00:00:26/00:09:47, 0.745s/it]: train_loss_raw=1.5176, running_loss=1.4157, LR=0.000100
[2025-08-26 10:30:07,919][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009096] [Batch 00043/00823] [00:00:32/00:09:43, 0.749s/it]: train_loss_raw=1.4805, running_loss=1.4210, LR=0.000100
[2025-08-26 10:30:14,033][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009104] [Batch 00051/00823] [00:00:38/00:09:39, 0.751s/it]: train_loss_raw=1.4939, running_loss=1.4242, LR=0.000100
[2025-08-26 10:30:20,127][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009112] [Batch 00059/00823] [00:00:44/00:09:34, 0.752s/it]: train_loss_raw=1.5379, running_loss=1.4276, LR=0.000100
[2025-08-26 10:30:26,211][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009120] [Batch 00067/00823] [00:00:50/00:09:29, 0.753s/it]: train_loss_raw=1.5309, running_loss=1.4326, LR=0.000100
[2025-08-26 10:30:32,307][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009128] [Batch 00075/00823] [00:00:56/00:09:24, 0.754s/it]: train_loss_raw=1.4946, running_loss=1.4355, LR=0.000100
[2025-08-26 10:30:38,382][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009136] [Batch 00083/00823] [00:01:02/00:09:18, 0.755s/it]: train_loss_raw=1.4561, running_loss=1.4383, LR=0.000100
[2025-08-26 10:30:44,445][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009144] [Batch 00091/00823] [00:01:08/00:09:12, 0.755s/it]: train_loss_raw=1.4895, running_loss=1.4414, LR=0.000100
[2025-08-26 10:30:50,468][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009152] [Batch 00099/00823] [00:01:14/00:09:06, 0.755s/it]: train_loss_raw=1.4398, running_loss=1.4432, LR=0.000100
[2025-08-26 10:30:56,520][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009160] [Batch 00107/00823] [00:01:20/00:09:00, 0.755s/it]: train_loss_raw=1.5654, running_loss=1.4463, LR=0.000100
[2025-08-26 10:31:02,608][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009168] [Batch 00115/00823] [00:01:26/00:08:54, 0.755s/it]: train_loss_raw=1.5096, running_loss=1.4480, LR=0.000100
[2025-08-26 10:31:08,705][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009176] [Batch 00123/00823] [00:01:32/00:08:49, 0.756s/it]: train_loss_raw=1.5451, running_loss=1.4500, LR=0.000100
[2025-08-26 10:31:14,814][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009184] [Batch 00131/00823] [00:01:39/00:08:43, 0.756s/it]: train_loss_raw=1.3680, running_loss=1.4493, LR=0.000100
[2025-08-26 10:31:20,958][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009192] [Batch 00139/00823] [00:01:45/00:08:37, 0.757s/it]: train_loss_raw=1.4177, running_loss=1.4505, LR=0.000100
[2025-08-26 10:31:27,051][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009200] [Batch 00147/00823] [00:01:51/00:08:31, 0.757s/it]: train_loss_raw=1.4145, running_loss=1.4525, LR=0.000100
[2025-08-26 10:31:33,127][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009208] [Batch 00155/00823] [00:01:57/00:08:25, 0.757s/it]: train_loss_raw=1.4107, running_loss=1.4515, LR=0.000100
[2025-08-26 10:31:39,183][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009216] [Batch 00163/00823] [00:02:03/00:08:19, 0.757s/it]: train_loss_raw=1.4898, running_loss=1.4541, LR=0.000100
[2025-08-26 10:31:45,268][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009224] [Batch 00171/00823] [00:02:09/00:08:13, 0.758s/it]: train_loss_raw=1.4120, running_loss=1.4538, LR=0.000100
[2025-08-26 10:31:51,374][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009232] [Batch 00179/00823] [00:02:15/00:08:08, 0.758s/it]: train_loss_raw=1.5235, running_loss=1.4569, LR=0.000100
[2025-08-26 10:31:57,531][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009240] [Batch 00187/00823] [00:02:21/00:08:02, 0.758s/it]: train_loss_raw=1.4186, running_loss=1.4580, LR=0.000100
[2025-08-26 10:32:03,634][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009248] [Batch 00195/00823] [00:02:27/00:07:56, 0.758s/it]: train_loss_raw=1.4859, running_loss=1.4598, LR=0.000100
[2025-08-26 10:32:09,747][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009256] [Batch 00203/00823] [00:02:34/00:07:50, 0.759s/it]: train_loss_raw=1.5991, running_loss=1.4626, LR=0.000100
[2025-08-26 10:32:15,737][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009264] [Batch 00211/00823] [00:02:40/00:07:44, 0.758s/it]: train_loss_raw=1.4220, running_loss=1.4606, LR=0.000100
[2025-08-26 10:32:21,753][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009272] [Batch 00219/00823] [00:02:46/00:07:37, 0.758s/it]: train_loss_raw=1.4543, running_loss=1.4623, LR=0.000100
[2025-08-26 10:32:27,835][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009280] [Batch 00227/00823] [00:02:52/00:07:31, 0.758s/it]: train_loss_raw=1.5629, running_loss=1.4670, LR=0.000100
[2025-08-26 10:32:33,920][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009288] [Batch 00235/00823] [00:02:58/00:07:25, 0.758s/it]: train_loss_raw=1.4317, running_loss=1.4651, LR=0.000100
[2025-08-26 10:32:39,955][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009296] [Batch 00243/00823] [00:03:04/00:07:19, 0.758s/it]: train_loss_raw=1.6025, running_loss=1.4690, LR=0.000100
[2025-08-26 10:32:46,005][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009304] [Batch 00251/00823] [00:03:10/00:07:13, 0.758s/it]: train_loss_raw=1.4877, running_loss=1.4679, LR=0.000100
[2025-08-26 10:32:52,092][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009312] [Batch 00259/00823] [00:03:16/00:07:07, 0.758s/it]: train_loss_raw=1.5710, running_loss=1.4666, LR=0.000100
[2025-08-26 10:32:58,195][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009320] [Batch 00267/00823] [00:03:22/00:07:01, 0.758s/it]: train_loss_raw=1.5364, running_loss=1.4660, LR=0.000100
[2025-08-26 10:33:04,306][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009328] [Batch 00275/00823] [00:03:28/00:06:55, 0.758s/it]: train_loss_raw=1.4999, running_loss=1.4650, LR=0.000100
[2025-08-26 10:33:10,405][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009336] [Batch 00283/00823] [00:03:34/00:06:49, 0.759s/it]: train_loss_raw=1.5458, running_loss=1.4669, LR=0.000100
[2025-08-26 10:33:16,514][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009344] [Batch 00291/00823] [00:03:40/00:06:43, 0.759s/it]: train_loss_raw=1.4877, running_loss=1.4668, LR=0.000100
[2025-08-26 10:33:22,679][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009352] [Batch 00299/00823] [00:03:46/00:06:37, 0.759s/it]: train_loss_raw=1.3841, running_loss=1.4669, LR=0.000100
[2025-08-26 10:33:28,859][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009360] [Batch 00307/00823] [00:03:53/00:06:31, 0.759s/it]: train_loss_raw=1.5855, running_loss=1.4682, LR=0.000100
[2025-08-26 10:33:34,986][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009368] [Batch 00315/00823] [00:03:59/00:06:25, 0.760s/it]: train_loss_raw=1.4940, running_loss=1.4694, LR=0.000100
[2025-08-26 10:33:41,112][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009376] [Batch 00323/00823] [00:04:05/00:06:19, 0.760s/it]: train_loss_raw=1.4769, running_loss=1.4690, LR=0.000100
[2025-08-26 10:33:47,146][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009384] [Batch 00331/00823] [00:04:11/00:06:13, 0.760s/it]: train_loss_raw=1.4649, running_loss=1.4688, LR=0.000100
[2025-08-26 10:33:53,164][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009392] [Batch 00339/00823] [00:04:17/00:06:07, 0.759s/it]: train_loss_raw=1.4939, running_loss=1.4688, LR=0.000100
[2025-08-26 10:33:59,114][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009400] [Batch 00347/00823] [00:04:23/00:06:01, 0.759s/it]: train_loss_raw=1.4198, running_loss=1.4671, LR=0.000100
[2025-08-26 10:34:05,092][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009408] [Batch 00355/00823] [00:04:29/00:05:55, 0.759s/it]: train_loss_raw=1.5341, running_loss=1.4663, LR=0.000100
[2025-08-26 10:34:11,075][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009416] [Batch 00363/00823] [00:04:35/00:05:48, 0.759s/it]: train_loss_raw=1.4008, running_loss=1.4661, LR=0.000100
[2025-08-26 10:34:17,210][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009424] [Batch 00371/00823] [00:04:41/00:05:42, 0.759s/it]: train_loss_raw=1.5201, running_loss=1.4669, LR=0.000100
[2025-08-26 10:34:23,248][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009432] [Batch 00379/00823] [00:04:47/00:05:36, 0.759s/it]: train_loss_raw=1.4158, running_loss=1.4649, LR=0.000100
[2025-08-26 10:34:29,344][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009440] [Batch 00387/00823] [00:04:53/00:05:30, 0.759s/it]: train_loss_raw=1.3173, running_loss=1.4637, LR=0.000100
[2025-08-26 10:34:35,414][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009448] [Batch 00395/00823] [00:04:59/00:05:24, 0.759s/it]: train_loss_raw=1.4221, running_loss=1.4644, LR=0.000100
[2025-08-26 10:34:41,471][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009456] [Batch 00403/00823] [00:05:05/00:05:18, 0.759s/it]: train_loss_raw=1.3591, running_loss=1.4590, LR=0.000100
[2025-08-26 10:34:47,484][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009464] [Batch 00411/00823] [00:05:11/00:05:12, 0.759s/it]: train_loss_raw=1.5956, running_loss=1.4603, LR=0.000100
[2025-08-26 10:34:53,579][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009472] [Batch 00419/00823] [00:05:17/00:05:06, 0.759s/it]: train_loss_raw=1.4076, running_loss=1.4601, LR=0.000100
[2025-08-26 10:34:59,682][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009480] [Batch 00427/00823] [00:05:23/00:05:00, 0.759s/it]: train_loss_raw=1.4723, running_loss=1.4618, LR=0.000100
[2025-08-26 10:35:05,828][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009488] [Batch 00435/00823] [00:05:30/00:04:54, 0.759s/it]: train_loss_raw=1.4857, running_loss=1.4624, LR=0.000100
[2025-08-26 10:35:11,982][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009496] [Batch 00443/00823] [00:05:36/00:04:48, 0.759s/it]: train_loss_raw=1.5057, running_loss=1.4633, LR=0.000100
[2025-08-26 10:35:18,091][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009504] [Batch 00451/00823] [00:05:42/00:04:42, 0.759s/it]: train_loss_raw=1.4230, running_loss=1.4609, LR=0.000100
[2025-08-26 10:35:23,855][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009512] [Batch 00459/00823] [00:05:48/00:04:36, 0.758s/it]: train_loss_raw=1.4657, running_loss=1.4593, LR=0.000100
[2025-08-26 10:35:29,868][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009520] [Batch 00467/00823] [00:05:54/00:04:29, 0.758s/it]: train_loss_raw=1.4424, running_loss=1.4585, LR=0.000100
[2025-08-26 10:35:35,843][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009528] [Batch 00475/00823] [00:06:00/00:04:23, 0.758s/it]: train_loss_raw=1.4775, running_loss=1.4584, LR=0.000100
[2025-08-26 10:35:41,857][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009536] [Batch 00483/00823] [00:06:06/00:04:17, 0.758s/it]: train_loss_raw=1.3913, running_loss=1.4611, LR=0.000100
[2025-08-26 10:35:48,001][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009544] [Batch 00491/00823] [00:06:12/00:04:11, 0.758s/it]: train_loss_raw=1.4687, running_loss=1.4607, LR=0.000100
[2025-08-26 10:35:54,076][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009552] [Batch 00499/00823] [00:06:18/00:04:05, 0.758s/it]: train_loss_raw=1.4464, running_loss=1.4570, LR=0.000100
[2025-08-26 10:36:00,201][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009560] [Batch 00507/00823] [00:06:24/00:03:59, 0.758s/it]: train_loss_raw=1.5398, running_loss=1.4588, LR=0.000100
[2025-08-26 10:36:06,435][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009568] [Batch 00515/00823] [00:06:30/00:03:53, 0.759s/it]: train_loss_raw=1.4252, running_loss=1.4583, LR=0.000100
[2025-08-26 10:36:12,552][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009576] [Batch 00523/00823] [00:06:36/00:03:47, 0.759s/it]: train_loss_raw=1.4419, running_loss=1.4569, LR=0.000100
[2025-08-26 10:36:18,631][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009584] [Batch 00531/00823] [00:06:42/00:03:41, 0.759s/it]: train_loss_raw=1.4095, running_loss=1.4547, LR=0.000100
[2025-08-26 10:36:24,729][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009592] [Batch 00539/00823] [00:06:48/00:03:35, 0.759s/it]: train_loss_raw=1.4285, running_loss=1.4560, LR=0.000100
[2025-08-26 10:36:30,831][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009600] [Batch 00547/00823] [00:06:55/00:03:29, 0.759s/it]: train_loss_raw=1.4493, running_loss=1.4580, LR=0.000100
[2025-08-26 10:36:36,892][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009608] [Batch 00555/00823] [00:07:01/00:03:23, 0.759s/it]: train_loss_raw=1.4336, running_loss=1.4558, LR=0.000100
[2025-08-26 10:36:42,963][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009616] [Batch 00563/00823] [00:07:07/00:03:17, 0.759s/it]: train_loss_raw=1.4184, running_loss=1.4549, LR=0.000100
[2025-08-26 10:36:49,106][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009624] [Batch 00571/00823] [00:07:13/00:03:11, 0.759s/it]: train_loss_raw=1.4795, running_loss=1.4557, LR=0.000100
[2025-08-26 10:36:55,211][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009632] [Batch 00579/00823] [00:07:19/00:03:05, 0.759s/it]: train_loss_raw=1.5631, running_loss=1.4590, LR=0.000100
[2025-08-26 10:37:01,322][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009640] [Batch 00587/00823] [00:07:25/00:02:59, 0.759s/it]: train_loss_raw=1.5325, running_loss=1.4579, LR=0.000100
[2025-08-26 10:37:07,356][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009648] [Batch 00595/00823] [00:07:31/00:02:53, 0.759s/it]: train_loss_raw=1.4353, running_loss=1.4587, LR=0.000100
[2025-08-26 10:37:13,500][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009656] [Batch 00603/00823] [00:07:37/00:02:47, 0.759s/it]: train_loss_raw=1.4255, running_loss=1.4591, LR=0.000100
[2025-08-26 10:37:19,567][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009664] [Batch 00611/00823] [00:07:43/00:02:40, 0.759s/it]: train_loss_raw=1.4483, running_loss=1.4576, LR=0.000100
[2025-08-26 10:37:25,647][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009672] [Batch 00619/00823] [00:07:49/00:02:34, 0.759s/it]: train_loss_raw=1.4174, running_loss=1.4574, LR=0.000100
[2025-08-26 10:37:31,722][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009680] [Batch 00627/00823] [00:07:55/00:02:28, 0.759s/it]: train_loss_raw=1.4284, running_loss=1.4559, LR=0.000100
[2025-08-26 10:37:37,805][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009688] [Batch 00635/00823] [00:08:02/00:02:22, 0.759s/it]: train_loss_raw=1.4732, running_loss=1.4552, LR=0.000100
[2025-08-26 10:37:43,958][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009696] [Batch 00643/00823] [00:08:08/00:02:16, 0.759s/it]: train_loss_raw=1.4319, running_loss=1.4566, LR=0.000100
[2025-08-26 10:37:50,019][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009704] [Batch 00651/00823] [00:08:14/00:02:10, 0.759s/it]: train_loss_raw=1.4315, running_loss=1.4552, LR=0.000100
[2025-08-26 10:37:56,047][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009712] [Batch 00659/00823] [00:08:20/00:02:04, 0.759s/it]: train_loss_raw=1.4786, running_loss=1.4549, LR=0.000100
[2025-08-26 10:38:02,115][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009720] [Batch 00667/00823] [00:08:26/00:01:58, 0.759s/it]: train_loss_raw=1.5444, running_loss=1.4584, LR=0.000100
[2025-08-26 10:38:08,258][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009728] [Batch 00675/00823] [00:08:32/00:01:52, 0.759s/it]: train_loss_raw=1.4539, running_loss=1.4598, LR=0.000100
[2025-08-26 10:38:14,385][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009736] [Batch 00683/00823] [00:08:38/00:01:46, 0.759s/it]: train_loss_raw=1.4202, running_loss=1.4582, LR=0.000100
[2025-08-26 10:38:20,493][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009744] [Batch 00691/00823] [00:08:44/00:01:40, 0.759s/it]: train_loss_raw=1.3878, running_loss=1.4545, LR=0.000100
[2025-08-26 10:38:26,543][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009752] [Batch 00699/00823] [00:08:50/00:01:34, 0.759s/it]: train_loss_raw=1.5050, running_loss=1.4571, LR=0.000100
[2025-08-26 10:38:32,627][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009760] [Batch 00707/00823] [00:08:56/00:01:28, 0.759s/it]: train_loss_raw=1.3605, running_loss=1.4528, LR=0.000100
[2025-08-26 10:38:38,710][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009768] [Batch 00715/00823] [00:09:02/00:01:22, 0.759s/it]: train_loss_raw=1.4348, running_loss=1.4518, LR=0.000100
[2025-08-26 10:38:44,775][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009776] [Batch 00723/00823] [00:09:09/00:01:15, 0.759s/it]: train_loss_raw=1.4806, running_loss=1.4511, LR=0.000100
[2025-08-26 10:38:50,903][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009784] [Batch 00731/00823] [00:09:15/00:01:09, 0.759s/it]: train_loss_raw=1.4098, running_loss=1.4522, LR=0.000100
[2025-08-26 10:38:56,958][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009792] [Batch 00739/00823] [00:09:21/00:01:03, 0.759s/it]: train_loss_raw=1.3389, running_loss=1.4505, LR=0.000100
[2025-08-26 10:39:02,935][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009800] [Batch 00747/00823] [00:09:27/00:00:57, 0.759s/it]: train_loss_raw=1.4505, running_loss=1.4519, LR=0.000100
[2025-08-26 10:39:08,990][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009808] [Batch 00755/00823] [00:09:33/00:00:51, 0.759s/it]: train_loss_raw=1.4331, running_loss=1.4528, LR=0.000100
[2025-08-26 10:39:15,012][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009816] [Batch 00763/00823] [00:09:39/00:00:45, 0.759s/it]: train_loss_raw=1.4146, running_loss=1.4541, LR=0.000100
[2025-08-26 10:39:21,066][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009824] [Batch 00771/00823] [00:09:45/00:00:39, 0.759s/it]: train_loss_raw=1.4130, running_loss=1.4528, LR=0.000100
[2025-08-26 10:39:27,123][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009832] [Batch 00779/00823] [00:09:51/00:00:33, 0.759s/it]: train_loss_raw=1.4586, running_loss=1.4547, LR=0.000100
[2025-08-26 10:39:33,196][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009840] [Batch 00787/00823] [00:09:57/00:00:27, 0.759s/it]: train_loss_raw=1.5184, running_loss=1.4554, LR=0.000100
[2025-08-26 10:39:39,287][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009848] [Batch 00795/00823] [00:10:03/00:00:21, 0.759s/it]: train_loss_raw=1.3511, running_loss=1.4513, LR=0.000100
[2025-08-26 10:39:45,366][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009856] [Batch 00803/00823] [00:10:09/00:00:15, 0.759s/it]: train_loss_raw=1.4682, running_loss=1.4528, LR=0.000100
[2025-08-26 10:39:51,452][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009864] [Batch 00811/00823] [00:10:15/00:00:09, 0.759s/it]: train_loss_raw=1.4624, running_loss=1.4511, LR=0.000100
[2025-08-26 10:39:57,533][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009872] [Batch 00819/00823] [00:10:21/00:00:03, 0.759s/it]: train_loss_raw=1.4094, running_loss=1.4507, LR=0.000100
[2025-08-26 10:40:07,474][__main__][INFO] - [VALIDATION] [Epoch 11/29] Starting validation.
[2025-08-26 10:40:19,414][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 009877] [Batch 00007/00013] [00:00:11/00:00:07, 1.493s/it]
[2025-08-26 10:40:27,130][__main__][INFO] - [VALIDATION] [Epoch 11/29] train_loss=1.45195, valid_loss=1.54205
[2025-08-26 10:40:27,130][__main__][INFO] - [VALIDATION] [Epoch 11/29] Metrics:
[2025-08-26 10:40:27,130][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_er      0.667
[2025-08-26 10:40:27,131][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_prec    0.041
[2025-08-26 10:40:27,131][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_recall  0.042
[2025-08-26 10:40:27,131][__main__][INFO] - [VALIDATION] [Epoch 11/29] - pep_recall 0.013
[2025-08-26 10:40:27,133][__main__][INFO] - [TRAIN] [Epoch 11/29] Epoch complete, total time 02:07:50, remaining time 03:11:46, 00:10:39 per epoch
[2025-08-26 10:40:29,710][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009880] [Batch 00004/00823] [00:00:02/00:08:05, 0.593s/it]: train_loss_raw=1.4403, running_loss=1.4880, LR=0.000100
[2025-08-26 10:40:35,765][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009888] [Batch 00012/00823] [00:00:08/00:09:29, 0.702s/it]: train_loss_raw=1.4270, running_loss=1.4816, LR=0.000100
[2025-08-26 10:40:41,828][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009896] [Batch 00020/00823] [00:00:14/00:09:41, 0.725s/it]: train_loss_raw=1.3581, running_loss=1.4753, LR=0.000100
[2025-08-26 10:40:47,832][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009904] [Batch 00028/00823] [00:00:20/00:09:41, 0.732s/it]: train_loss_raw=1.3812, running_loss=1.4709, LR=0.000100
[2025-08-26 10:40:53,949][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009912] [Batch 00036/00823] [00:00:26/00:09:41, 0.739s/it]: train_loss_raw=1.3835, running_loss=1.4688, LR=0.000100
[2025-08-26 10:41:00,076][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009920] [Batch 00044/00823] [00:00:32/00:09:39, 0.744s/it]: train_loss_raw=1.4170, running_loss=1.4634, LR=0.000100
[2025-08-26 10:41:06,167][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009928] [Batch 00052/00823] [00:00:38/00:09:35, 0.747s/it]: train_loss_raw=1.3171, running_loss=1.4591, LR=0.000100
[2025-08-26 10:41:12,307][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009936] [Batch 00060/00823] [00:00:44/00:09:31, 0.749s/it]: train_loss_raw=1.4193, running_loss=1.4560, LR=0.000100
[2025-08-26 10:41:18,378][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009944] [Batch 00068/00823] [00:00:51/00:09:26, 0.751s/it]: train_loss_raw=1.3995, running_loss=1.4519, LR=0.000100
[2025-08-26 10:41:24,439][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009952] [Batch 00076/00823] [00:00:57/00:09:21, 0.751s/it]: train_loss_raw=1.4966, running_loss=1.4486, LR=0.000100
[2025-08-26 10:41:30,454][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009960] [Batch 00084/00823] [00:01:03/00:09:15, 0.751s/it]: train_loss_raw=1.5501, running_loss=1.4451, LR=0.000100
[2025-08-26 10:41:36,569][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009968] [Batch 00092/00823] [00:01:09/00:09:10, 0.753s/it]: train_loss_raw=1.4689, running_loss=1.4448, LR=0.000100
[2025-08-26 10:41:42,654][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009976] [Batch 00100/00823] [00:01:15/00:09:04, 0.753s/it]: train_loss_raw=1.3916, running_loss=1.4402, LR=0.000100
[2025-08-26 10:41:48,739][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009984] [Batch 00108/00823] [00:01:21/00:08:58, 0.754s/it]: train_loss_raw=1.3528, running_loss=1.4366, LR=0.000100
[2025-08-26 10:41:54,802][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009992] [Batch 00116/00823] [00:01:27/00:08:53, 0.754s/it]: train_loss_raw=1.5089, running_loss=1.4362, LR=0.000100
[2025-08-26 10:42:00,793][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010000] [Batch 00124/00823] [00:01:33/00:08:46, 0.754s/it]: train_loss_raw=1.2719, running_loss=1.4332, LR=0.000100
[2025-08-26 10:42:11,242][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010008] [Batch 00132/00823] [00:01:43/00:09:03, 0.787s/it]: train_loss_raw=1.4007, running_loss=1.4281, LR=0.000100
[2025-08-26 10:42:17,342][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010016] [Batch 00140/00823] [00:01:50/00:08:56, 0.786s/it]: train_loss_raw=1.4995, running_loss=1.4278, LR=0.000100
[2025-08-26 10:42:23,459][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010024] [Batch 00148/00823] [00:01:56/00:08:49, 0.785s/it]: train_loss_raw=1.3651, running_loss=1.4249, LR=0.000100
[2025-08-26 10:42:29,458][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010032] [Batch 00156/00823] [00:02:02/00:08:42, 0.783s/it]: train_loss_raw=1.3279, running_loss=1.4202, LR=0.000100
[2025-08-26 10:42:35,551][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010040] [Batch 00164/00823] [00:02:08/00:08:35, 0.782s/it]: train_loss_raw=1.4608, running_loss=1.4203, LR=0.000100
[2025-08-26 10:42:41,671][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010048] [Batch 00172/00823] [00:02:14/00:08:28, 0.781s/it]: train_loss_raw=1.2827, running_loss=1.4205, LR=0.000100
[2025-08-26 10:42:47,670][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010056] [Batch 00180/00823] [00:02:20/00:08:21, 0.780s/it]: train_loss_raw=1.3867, running_loss=1.4200, LR=0.000100
[2025-08-26 10:42:53,765][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010064] [Batch 00188/00823] [00:02:26/00:08:14, 0.779s/it]: train_loss_raw=1.3731, running_loss=1.4211, LR=0.000100
[2025-08-26 10:42:59,840][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010072] [Batch 00196/00823] [00:02:32/00:08:07, 0.778s/it]: train_loss_raw=1.4206, running_loss=1.4199, LR=0.000100
[2025-08-26 10:43:05,921][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010080] [Batch 00204/00823] [00:02:38/00:08:01, 0.777s/it]: train_loss_raw=1.4063, running_loss=1.4204, LR=0.000100
[2025-08-26 10:43:12,029][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010088] [Batch 00212/00823] [00:02:44/00:07:54, 0.777s/it]: train_loss_raw=1.4519, running_loss=1.4203, LR=0.000100
[2025-08-26 10:43:18,024][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010096] [Batch 00220/00823] [00:02:50/00:07:47, 0.776s/it]: train_loss_raw=1.3962, running_loss=1.4210, LR=0.000100
[2025-08-26 10:43:24,072][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010104] [Batch 00228/00823] [00:02:56/00:07:41, 0.775s/it]: train_loss_raw=1.4020, running_loss=1.4210, LR=0.000100
[2025-08-26 10:43:30,100][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010112] [Batch 00236/00823] [00:03:02/00:07:34, 0.774s/it]: train_loss_raw=1.4175, running_loss=1.4195, LR=0.000100
[2025-08-26 10:43:36,111][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010120] [Batch 00244/00823] [00:03:08/00:07:27, 0.774s/it]: train_loss_raw=1.4397, running_loss=1.4207, LR=0.000100
[2025-08-26 10:43:42,222][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010128] [Batch 00252/00823] [00:03:14/00:07:21, 0.773s/it]: train_loss_raw=1.4167, running_loss=1.4178, LR=0.000100
[2025-08-26 10:43:48,246][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010136] [Batch 00260/00823] [00:03:20/00:07:15, 0.773s/it]: train_loss_raw=1.3743, running_loss=1.4177, LR=0.000100
[2025-08-26 10:43:54,343][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010144] [Batch 00268/00823] [00:03:27/00:07:08, 0.772s/it]: train_loss_raw=1.4354, running_loss=1.4151, LR=0.000100
[2025-08-26 10:44:00,486][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010152] [Batch 00276/00823] [00:03:33/00:07:02, 0.772s/it]: train_loss_raw=1.4858, running_loss=1.4151, LR=0.000100
[2025-08-26 10:44:06,653][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010160] [Batch 00284/00823] [00:03:39/00:06:56, 0.772s/it]: train_loss_raw=1.4352, running_loss=1.4144, LR=0.000100
[2025-08-26 10:44:12,662][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010168] [Batch 00292/00823] [00:03:45/00:06:49, 0.772s/it]: train_loss_raw=1.4280, running_loss=1.4164, LR=0.000100
[2025-08-26 10:44:18,717][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010176] [Batch 00300/00823] [00:03:51/00:06:43, 0.771s/it]: train_loss_raw=1.4454, running_loss=1.4167, LR=0.000100
[2025-08-26 10:44:25,239][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010184] [Batch 00308/00823] [00:03:57/00:06:37, 0.772s/it]: train_loss_raw=1.4096, running_loss=1.4165, LR=0.000100
[2025-08-26 10:44:31,216][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010192] [Batch 00316/00823] [00:04:03/00:06:31, 0.772s/it]: train_loss_raw=1.3575, running_loss=1.4156, LR=0.000100
[2025-08-26 10:44:37,258][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010200] [Batch 00324/00823] [00:04:09/00:06:24, 0.771s/it]: train_loss_raw=1.4674, running_loss=1.4164, LR=0.000100
[2025-08-26 10:44:43,256][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010208] [Batch 00332/00823] [00:04:15/00:06:18, 0.771s/it]: train_loss_raw=1.4472, running_loss=1.4159, LR=0.000100
[2025-08-26 10:44:49,359][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010216] [Batch 00340/00823] [00:04:22/00:06:12, 0.771s/it]: train_loss_raw=1.3649, running_loss=1.4125, LR=0.000100
[2025-08-26 10:44:55,425][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010224] [Batch 00348/00823] [00:04:28/00:06:05, 0.770s/it]: train_loss_raw=1.3627, running_loss=1.4105, LR=0.000100
[2025-08-26 10:45:01,520][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010232] [Batch 00356/00823] [00:04:34/00:05:59, 0.770s/it]: train_loss_raw=1.4823, running_loss=1.4139, LR=0.000100
[2025-08-26 10:45:07,664][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010240] [Batch 00364/00823] [00:04:40/00:05:53, 0.770s/it]: train_loss_raw=1.3311, running_loss=1.4148, LR=0.000100
[2025-08-26 10:45:13,684][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010248] [Batch 00372/00823] [00:04:46/00:05:47, 0.770s/it]: train_loss_raw=1.3857, running_loss=1.4128, LR=0.000100
[2025-08-26 10:45:19,465][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010256] [Batch 00380/00823] [00:04:52/00:05:40, 0.769s/it]: train_loss_raw=1.4868, running_loss=1.4129, LR=0.000100
[2025-08-26 10:45:25,599][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010264] [Batch 00388/00823] [00:04:58/00:05:34, 0.769s/it]: train_loss_raw=1.5009, running_loss=1.4137, LR=0.000100
[2025-08-26 10:45:31,681][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010272] [Batch 00396/00823] [00:05:04/00:05:28, 0.769s/it]: train_loss_raw=1.4177, running_loss=1.4147, LR=0.000100
[2025-08-26 10:45:37,781][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010280] [Batch 00404/00823] [00:05:10/00:05:21, 0.768s/it]: train_loss_raw=1.3745, running_loss=1.4145, LR=0.000100
[2025-08-26 10:45:43,833][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010288] [Batch 00412/00823] [00:05:16/00:05:15, 0.768s/it]: train_loss_raw=1.3977, running_loss=1.4123, LR=0.000100
[2025-08-26 10:45:49,897][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010296] [Batch 00420/00823] [00:05:22/00:05:09, 0.768s/it]: train_loss_raw=1.4515, running_loss=1.4122, LR=0.000100
[2025-08-26 10:45:55,976][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010304] [Batch 00428/00823] [00:05:28/00:05:03, 0.768s/it]: train_loss_raw=1.4307, running_loss=1.4123, LR=0.000100
[2025-08-26 10:46:01,983][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010312] [Batch 00436/00823] [00:05:34/00:04:57, 0.768s/it]: train_loss_raw=1.3701, running_loss=1.4115, LR=0.000100
[2025-08-26 10:46:08,034][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010320] [Batch 00444/00823] [00:05:40/00:04:50, 0.767s/it]: train_loss_raw=1.4668, running_loss=1.4123, LR=0.000100
[2025-08-26 10:46:13,857][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010328] [Batch 00452/00823] [00:05:46/00:04:44, 0.767s/it]: train_loss_raw=1.4231, running_loss=1.4155, LR=0.000100
[2025-08-26 10:46:19,838][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010336] [Batch 00460/00823] [00:05:52/00:04:38, 0.766s/it]: train_loss_raw=1.4138, running_loss=1.4146, LR=0.000100
[2025-08-26 10:46:25,687][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010344] [Batch 00468/00823] [00:05:58/00:04:31, 0.766s/it]: train_loss_raw=1.3943, running_loss=1.4161, LR=0.000100
[2025-08-26 10:46:31,740][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010352] [Batch 00476/00823] [00:06:04/00:04:25, 0.766s/it]: train_loss_raw=1.2158, running_loss=1.4132, LR=0.000100
[2025-08-26 10:46:37,683][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010360] [Batch 00484/00823] [00:06:10/00:04:19, 0.765s/it]: train_loss_raw=1.4371, running_loss=1.4120, LR=0.000100
[2025-08-26 10:46:43,372][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010368] [Batch 00492/00823] [00:06:16/00:04:12, 0.764s/it]: train_loss_raw=1.3717, running_loss=1.4110, LR=0.000100
[2025-08-26 10:46:49,179][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010376] [Batch 00500/00823] [00:06:21/00:04:06, 0.764s/it]: train_loss_raw=1.4462, running_loss=1.4104, LR=0.000100
[2025-08-26 10:46:55,148][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010384] [Batch 00508/00823] [00:06:27/00:04:00, 0.763s/it]: train_loss_raw=1.4577, running_loss=1.4123, LR=0.000100
[2025-08-26 10:47:01,274][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010392] [Batch 00516/00823] [00:06:33/00:03:54, 0.763s/it]: train_loss_raw=1.4031, running_loss=1.4108, LR=0.000100
[2025-08-26 10:47:07,377][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010400] [Batch 00524/00823] [00:06:40/00:03:48, 0.763s/it]: train_loss_raw=1.4002, running_loss=1.4102, LR=0.000100
[2025-08-26 10:47:13,464][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010408] [Batch 00532/00823] [00:06:46/00:03:42, 0.763s/it]: train_loss_raw=1.3758, running_loss=1.4075, LR=0.000100
[2025-08-26 10:47:19,593][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010416] [Batch 00540/00823] [00:06:52/00:03:36, 0.763s/it]: train_loss_raw=1.4024, running_loss=1.4051, LR=0.000100
[2025-08-26 10:47:25,690][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010424] [Batch 00548/00823] [00:06:58/00:03:29, 0.763s/it]: train_loss_raw=1.3141, running_loss=1.4031, LR=0.000100
[2025-08-26 10:47:31,792][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010432] [Batch 00556/00823] [00:07:04/00:03:23, 0.763s/it]: train_loss_raw=1.3740, running_loss=1.4034, LR=0.000100
[2025-08-26 10:47:37,867][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010440] [Batch 00564/00823] [00:07:10/00:03:17, 0.763s/it]: train_loss_raw=1.4295, running_loss=1.4052, LR=0.000100
[2025-08-26 10:47:43,929][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010448] [Batch 00572/00823] [00:07:16/00:03:11, 0.763s/it]: train_loss_raw=1.4912, running_loss=1.4035, LR=0.000100
[2025-08-26 10:47:49,971][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010456] [Batch 00580/00823] [00:07:22/00:03:05, 0.763s/it]: train_loss_raw=1.3475, running_loss=1.4019, LR=0.000100
[2025-08-26 10:47:56,017][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010464] [Batch 00588/00823] [00:07:28/00:02:59, 0.763s/it]: train_loss_raw=1.3837, running_loss=1.4031, LR=0.000100
[2025-08-26 10:48:02,171][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010472] [Batch 00596/00823] [00:07:34/00:02:53, 0.763s/it]: train_loss_raw=1.3152, running_loss=1.4039, LR=0.000100
[2025-08-26 10:48:08,244][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010480] [Batch 00604/00823] [00:07:40/00:02:47, 0.763s/it]: train_loss_raw=1.3995, running_loss=1.4048, LR=0.000100
[2025-08-26 10:48:14,348][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010488] [Batch 00612/00823] [00:07:47/00:02:41, 0.763s/it]: train_loss_raw=1.3427, running_loss=1.4044, LR=0.000100
[2025-08-26 10:48:20,481][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010496] [Batch 00620/00823] [00:07:53/00:02:34, 0.763s/it]: train_loss_raw=1.3510, running_loss=1.4037, LR=0.000100
[2025-08-26 10:48:26,528][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010504] [Batch 00628/00823] [00:07:59/00:02:28, 0.763s/it]: train_loss_raw=1.4728, running_loss=1.4021, LR=0.000100
[2025-08-26 10:48:32,575][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010512] [Batch 00636/00823] [00:08:05/00:02:22, 0.763s/it]: train_loss_raw=1.3492, running_loss=1.3992, LR=0.000100
[2025-08-26 10:48:38,674][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010520] [Batch 00644/00823] [00:08:11/00:02:16, 0.763s/it]: train_loss_raw=1.4329, running_loss=1.4001, LR=0.000100
[2025-08-26 10:48:44,820][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010528] [Batch 00652/00823] [00:08:17/00:02:10, 0.763s/it]: train_loss_raw=1.4625, running_loss=1.4041, LR=0.000100
[2025-08-26 10:48:50,961][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010536] [Batch 00660/00823] [00:08:23/00:02:04, 0.763s/it]: train_loss_raw=1.4216, running_loss=1.4058, LR=0.000100
[2025-08-26 10:48:57,045][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010544] [Batch 00668/00823] [00:08:29/00:01:58, 0.763s/it]: train_loss_raw=1.4272, running_loss=1.4064, LR=0.000100
[2025-08-26 10:49:03,065][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010552] [Batch 00676/00823] [00:08:35/00:01:52, 0.763s/it]: train_loss_raw=1.3751, running_loss=1.4061, LR=0.000100
[2025-08-26 10:49:09,125][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010560] [Batch 00684/00823] [00:08:41/00:01:46, 0.763s/it]: train_loss_raw=1.4498, running_loss=1.4048, LR=0.000100
[2025-08-26 10:49:15,182][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010568] [Batch 00692/00823] [00:08:47/00:01:39, 0.763s/it]: train_loss_raw=1.3665, running_loss=1.4032, LR=0.000100
[2025-08-26 10:49:21,314][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010576] [Batch 00700/00823] [00:08:53/00:01:33, 0.763s/it]: train_loss_raw=1.4448, running_loss=1.4037, LR=0.000100
[2025-08-26 10:49:27,427][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010584] [Batch 00708/00823] [00:09:00/00:01:27, 0.763s/it]: train_loss_raw=1.4730, running_loss=1.4051, LR=0.000100
[2025-08-26 10:49:33,460][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010592] [Batch 00716/00823] [00:09:06/00:01:21, 0.763s/it]: train_loss_raw=1.4089, running_loss=1.4046, LR=0.000100
[2025-08-26 10:49:39,539][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010600] [Batch 00724/00823] [00:09:12/00:01:15, 0.763s/it]: train_loss_raw=1.3661, running_loss=1.4026, LR=0.000100
[2025-08-26 10:49:45,596][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010608] [Batch 00732/00823] [00:09:18/00:01:09, 0.763s/it]: train_loss_raw=1.3727, running_loss=1.4016, LR=0.000100
[2025-08-26 10:49:51,698][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010616] [Batch 00740/00823] [00:09:24/00:01:03, 0.763s/it]: train_loss_raw=1.3453, running_loss=1.4006, LR=0.000100
[2025-08-26 10:49:57,731][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010624] [Batch 00748/00823] [00:09:30/00:00:57, 0.763s/it]: train_loss_raw=1.4380, running_loss=1.4018, LR=0.000100
[2025-08-26 10:50:03,760][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010632] [Batch 00756/00823] [00:09:36/00:00:51, 0.762s/it]: train_loss_raw=1.3633, running_loss=1.4031, LR=0.000100
[2025-08-26 10:50:09,781][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010640] [Batch 00764/00823] [00:09:42/00:00:44, 0.762s/it]: train_loss_raw=1.3632, running_loss=1.4040, LR=0.000100
[2025-08-26 10:50:15,637][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010648] [Batch 00772/00823] [00:09:48/00:00:38, 0.762s/it]: train_loss_raw=1.3712, running_loss=1.4045, LR=0.000100
[2025-08-26 10:50:21,502][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010656] [Batch 00780/00823] [00:09:54/00:00:32, 0.762s/it]: train_loss_raw=1.3176, running_loss=1.4034, LR=0.000100
[2025-08-26 10:50:27,399][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010664] [Batch 00788/00823] [00:10:00/00:00:26, 0.761s/it]: train_loss_raw=1.4092, running_loss=1.4025, LR=0.000100
[2025-08-26 10:50:33,329][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010672] [Batch 00796/00823] [00:10:05/00:00:20, 0.761s/it]: train_loss_raw=1.3879, running_loss=1.4015, LR=0.000100
[2025-08-26 10:50:39,315][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010680] [Batch 00804/00823] [00:10:11/00:00:14, 0.761s/it]: train_loss_raw=1.4600, running_loss=1.4036, LR=0.000100
[2025-08-26 10:50:45,424][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010688] [Batch 00812/00823] [00:10:18/00:00:08, 0.761s/it]: train_loss_raw=1.4035, running_loss=1.4024, LR=0.000100
[2025-08-26 10:50:51,503][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010696] [Batch 00820/00823] [00:10:24/00:00:02, 0.761s/it]: train_loss_raw=1.3366, running_loss=1.4011, LR=0.000100
[2025-08-26 10:50:54,009][__main__][INFO] - [VALIDATION] [Epoch 12/29] Starting validation.
[2025-08-26 10:51:05,384][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 010700] [Batch 00007/00013] [00:00:11/00:00:07, 1.422s/it]
[2025-08-26 10:51:12,649][__main__][INFO] - [VALIDATION] [Epoch 12/29] train_loss=1.39988, valid_loss=1.50985
[2025-08-26 10:51:12,649][__main__][INFO] - [VALIDATION] [Epoch 12/29] Metrics:
[2025-08-26 10:51:12,650][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_er      0.656
[2025-08-26 10:51:12,650][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_prec    0.046
[2025-08-26 10:51:12,650][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_recall  0.047
[2025-08-26 10:51:12,650][__main__][INFO] - [VALIDATION] [Epoch 12/29] - pep_recall 0.014
[2025-08-26 10:51:12,652][__main__][INFO] - [TRAIN] [Epoch 12/29] Epoch complete, total time 02:18:36, remaining time 03:01:15, 00:10:39 per epoch
[2025-08-26 10:51:16,059][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010704] [Batch 00005/00823] [00:00:03/00:08:38, 0.634s/it]: train_loss_raw=1.3799, running_loss=1.4094, LR=0.000100
[2025-08-26 10:51:22,117][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010712] [Batch 00013/00823] [00:00:09/00:09:35, 0.710s/it]: train_loss_raw=1.4154, running_loss=1.4087, LR=0.000100
[2025-08-26 10:51:28,240][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010720] [Batch 00021/00823] [00:00:15/00:09:46, 0.731s/it]: train_loss_raw=1.3798, running_loss=1.4054, LR=0.000100
[2025-08-26 10:51:34,303][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010728] [Batch 00029/00823] [00:00:21/00:09:46, 0.738s/it]: train_loss_raw=1.4360, running_loss=1.4064, LR=0.000100
[2025-08-26 10:51:40,399][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010736] [Batch 00037/00823] [00:00:27/00:09:44, 0.744s/it]: train_loss_raw=1.3988, running_loss=1.4030, LR=0.000100
[2025-08-26 10:51:46,481][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010744] [Batch 00045/00823] [00:00:33/00:09:40, 0.747s/it]: train_loss_raw=1.3924, running_loss=1.4009, LR=0.000100
[2025-08-26 10:51:52,477][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010752] [Batch 00053/00823] [00:00:39/00:09:35, 0.747s/it]: train_loss_raw=1.3330, running_loss=1.4024, LR=0.000100
[2025-08-26 10:51:58,449][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010760] [Batch 00061/00823] [00:00:45/00:09:29, 0.747s/it]: train_loss_raw=1.4407, running_loss=1.4019, LR=0.000100
[2025-08-26 10:52:04,436][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010768] [Batch 00069/00823] [00:00:51/00:09:23, 0.747s/it]: train_loss_raw=1.5226, running_loss=1.4015, LR=0.000100
[2025-08-26 10:52:10,534][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010776] [Batch 00077/00823] [00:00:57/00:09:18, 0.749s/it]: train_loss_raw=1.4200, running_loss=1.4023, LR=0.000100
[2025-08-26 10:52:16,642][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010784] [Batch 00085/00823] [00:01:03/00:09:13, 0.750s/it]: train_loss_raw=1.3690, running_loss=1.3999, LR=0.000100
[2025-08-26 10:52:22,779][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010792] [Batch 00093/00823] [00:01:09/00:09:08, 0.752s/it]: train_loss_raw=1.3352, running_loss=1.3972, LR=0.000100
[2025-08-26 10:52:28,867][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010800] [Batch 00101/00823] [00:01:15/00:09:03, 0.752s/it]: train_loss_raw=1.2970, running_loss=1.3945, LR=0.000100
[2025-08-26 10:52:34,873][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010808] [Batch 00109/00823] [00:01:21/00:08:57, 0.752s/it]: train_loss_raw=1.4279, running_loss=1.3953, LR=0.000100
[2025-08-26 10:52:40,903][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010816] [Batch 00117/00823] [00:01:28/00:08:51, 0.752s/it]: train_loss_raw=1.3332, running_loss=1.3966, LR=0.000100
[2025-08-26 10:52:46,930][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010824] [Batch 00125/00823] [00:01:34/00:08:45, 0.752s/it]: train_loss_raw=1.3511, running_loss=1.3961, LR=0.000100
[2025-08-26 10:52:52,932][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010832] [Batch 00133/00823] [00:01:40/00:08:39, 0.752s/it]: train_loss_raw=1.3479, running_loss=1.3968, LR=0.000100
[2025-08-26 10:52:58,646][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010840] [Batch 00141/00823] [00:01:45/00:08:31, 0.750s/it]: train_loss_raw=1.3768, running_loss=1.3935, LR=0.000100
[2025-08-26 10:53:04,460][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010848] [Batch 00149/00823] [00:01:51/00:08:24, 0.749s/it]: train_loss_raw=1.2761, running_loss=1.3916, LR=0.000100
[2025-08-26 10:53:10,240][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010856] [Batch 00157/00823] [00:01:57/00:08:17, 0.747s/it]: train_loss_raw=1.4256, running_loss=1.3928, LR=0.000100
[2025-08-26 10:53:16,221][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010864] [Batch 00165/00823] [00:02:03/00:08:11, 0.747s/it]: train_loss_raw=1.4429, running_loss=1.3954, LR=0.000100
[2025-08-26 10:53:22,193][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010872] [Batch 00173/00823] [00:02:09/00:08:05, 0.747s/it]: train_loss_raw=1.3990, running_loss=1.3960, LR=0.000100
[2025-08-26 10:53:27,976][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010880] [Batch 00181/00823] [00:02:15/00:07:59, 0.746s/it]: train_loss_raw=1.4577, running_loss=1.3983, LR=0.000100
[2025-08-26 10:53:33,959][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010888] [Batch 00189/00823] [00:02:21/00:07:53, 0.746s/it]: train_loss_raw=1.3030, running_loss=1.3957, LR=0.000100
[2025-08-26 10:53:39,760][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010896] [Batch 00197/00823] [00:02:26/00:07:46, 0.746s/it]: train_loss_raw=1.3849, running_loss=1.3933, LR=0.000100
[2025-08-26 10:53:45,578][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010904] [Batch 00205/00823] [00:02:32/00:07:40, 0.745s/it]: train_loss_raw=1.3530, running_loss=1.3942, LR=0.000100
[2025-08-26 10:53:51,366][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010912] [Batch 00213/00823] [00:02:38/00:07:33, 0.744s/it]: train_loss_raw=1.3663, running_loss=1.3931, LR=0.000100
[2025-08-26 10:53:56,972][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010920] [Batch 00221/00823] [00:02:44/00:07:26, 0.742s/it]: train_loss_raw=1.3154, running_loss=1.3937, LR=0.000100
[2025-08-26 10:54:02,617][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010928] [Batch 00229/00823] [00:02:49/00:07:20, 0.741s/it]: train_loss_raw=1.4192, running_loss=1.3932, LR=0.000100
[2025-08-26 10:54:08,245][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010936] [Batch 00237/00823] [00:02:55/00:07:13, 0.740s/it]: train_loss_raw=1.4268, running_loss=1.3921, LR=0.000100
[2025-08-26 10:54:14,037][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010944] [Batch 00245/00823] [00:03:01/00:07:07, 0.739s/it]: train_loss_raw=1.3935, running_loss=1.3907, LR=0.000100
[2025-08-26 10:54:19,916][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010952] [Batch 00253/00823] [00:03:07/00:07:01, 0.739s/it]: train_loss_raw=1.4347, running_loss=1.3900, LR=0.000100
[2025-08-26 10:54:25,817][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010960] [Batch 00261/00823] [00:03:12/00:06:55, 0.739s/it]: train_loss_raw=1.4883, running_loss=1.3933, LR=0.000100
[2025-08-26 10:54:31,596][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010968] [Batch 00269/00823] [00:03:18/00:06:49, 0.739s/it]: train_loss_raw=1.3780, running_loss=1.3932, LR=0.000100
[2025-08-26 10:54:37,506][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010976] [Batch 00277/00823] [00:03:24/00:06:43, 0.739s/it]: train_loss_raw=1.3672, running_loss=1.3925, LR=0.000100
[2025-08-26 10:54:43,354][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010984] [Batch 00285/00823] [00:03:30/00:06:37, 0.738s/it]: train_loss_raw=1.4587, running_loss=1.3920, LR=0.000100
[2025-08-26 10:54:49,138][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010992] [Batch 00293/00823] [00:03:36/00:06:31, 0.738s/it]: train_loss_raw=1.4223, running_loss=1.3920, LR=0.000100
[2025-08-26 10:54:55,146][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011000] [Batch 00301/00823] [00:03:42/00:06:25, 0.738s/it]: train_loss_raw=1.4009, running_loss=1.3935, LR=0.000100
[2025-08-26 10:55:00,990][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011008] [Batch 00309/00823] [00:03:48/00:06:19, 0.738s/it]: train_loss_raw=1.3880, running_loss=1.3953, LR=0.000100
[2025-08-26 10:55:06,822][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011016] [Batch 00317/00823] [00:03:53/00:06:13, 0.738s/it]: train_loss_raw=1.4194, running_loss=1.3941, LR=0.000100
[2025-08-26 10:55:12,577][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011024] [Batch 00325/00823] [00:03:59/00:06:07, 0.738s/it]: train_loss_raw=1.4100, running_loss=1.3934, LR=0.000100
[2025-08-26 10:55:18,316][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011032] [Batch 00333/00823] [00:04:05/00:06:01, 0.737s/it]: train_loss_raw=1.3603, running_loss=1.3908, LR=0.000100
[2025-08-26 10:55:24,121][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011040] [Batch 00341/00823] [00:04:11/00:05:55, 0.737s/it]: train_loss_raw=1.3964, running_loss=1.3881, LR=0.000100
[2025-08-26 10:55:29,902][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011048] [Batch 00349/00823] [00:04:17/00:05:49, 0.736s/it]: train_loss_raw=1.4150, running_loss=1.3890, LR=0.000100
[2025-08-26 10:55:35,756][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011056] [Batch 00357/00823] [00:04:22/00:05:43, 0.736s/it]: train_loss_raw=1.3736, running_loss=1.3887, LR=0.000100
[2025-08-26 10:55:41,615][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011064] [Batch 00365/00823] [00:04:28/00:05:37, 0.736s/it]: train_loss_raw=1.3191, running_loss=1.3870, LR=0.000100
[2025-08-26 10:55:47,727][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011072] [Batch 00373/00823] [00:04:34/00:05:31, 0.737s/it]: train_loss_raw=1.3948, running_loss=1.3860, LR=0.000100
[2025-08-26 10:55:53,570][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011080] [Batch 00381/00823] [00:04:40/00:05:25, 0.737s/it]: train_loss_raw=1.4259, running_loss=1.3846, LR=0.000100
[2025-08-26 10:55:59,444][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011088] [Batch 00389/00823] [00:04:46/00:05:19, 0.737s/it]: train_loss_raw=1.3389, running_loss=1.3832, LR=0.000100
[2025-08-26 10:56:05,428][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011096] [Batch 00397/00823] [00:04:52/00:05:13, 0.737s/it]: train_loss_raw=1.3697, running_loss=1.3835, LR=0.000100
[2025-08-26 10:56:11,200][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011104] [Batch 00405/00823] [00:04:58/00:05:07, 0.737s/it]: train_loss_raw=1.3179, running_loss=1.3845, LR=0.000100
[2025-08-26 10:56:16,959][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011112] [Batch 00413/00823] [00:05:04/00:05:01, 0.736s/it]: train_loss_raw=1.3619, running_loss=1.3835, LR=0.000100
[2025-08-26 10:56:22,788][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011120] [Batch 00421/00823] [00:05:09/00:04:55, 0.736s/it]: train_loss_raw=1.4084, running_loss=1.3827, LR=0.000100
[2025-08-26 10:56:28,548][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011128] [Batch 00429/00823] [00:05:15/00:04:49, 0.736s/it]: train_loss_raw=1.3998, running_loss=1.3831, LR=0.000100
[2025-08-26 10:56:34,282][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011136] [Batch 00437/00823] [00:05:21/00:04:43, 0.735s/it]: train_loss_raw=1.2998, running_loss=1.3850, LR=0.000100
[2025-08-26 10:56:40,009][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011144] [Batch 00445/00823] [00:05:27/00:04:37, 0.735s/it]: train_loss_raw=1.3138, running_loss=1.3858, LR=0.000100
[2025-08-26 10:56:45,899][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011152] [Batch 00453/00823] [00:05:33/00:04:31, 0.735s/it]: train_loss_raw=1.4434, running_loss=1.3873, LR=0.000100
[2025-08-26 10:56:51,826][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011160] [Batch 00461/00823] [00:05:38/00:04:26, 0.735s/it]: train_loss_raw=1.4428, running_loss=1.3880, LR=0.000100
[2025-08-26 10:56:57,753][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011168] [Batch 00469/00823] [00:05:44/00:04:20, 0.735s/it]: train_loss_raw=1.3360, running_loss=1.3890, LR=0.000100
[2025-08-26 10:57:03,675][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011176] [Batch 00477/00823] [00:05:50/00:04:14, 0.735s/it]: train_loss_raw=1.4717, running_loss=1.3875, LR=0.000100
[2025-08-26 10:57:09,442][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011184] [Batch 00485/00823] [00:05:56/00:04:08, 0.735s/it]: train_loss_raw=1.4330, running_loss=1.3867, LR=0.000100
[2025-08-26 10:57:15,202][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011192] [Batch 00493/00823] [00:06:02/00:04:02, 0.735s/it]: train_loss_raw=1.3935, running_loss=1.3889, LR=0.000100
[2025-08-26 10:57:21,002][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011200] [Batch 00501/00823] [00:06:08/00:03:56, 0.735s/it]: train_loss_raw=1.3929, running_loss=1.3887, LR=0.000100
[2025-08-26 10:57:26,839][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011208] [Batch 00509/00823] [00:06:13/00:03:50, 0.735s/it]: train_loss_raw=1.3479, running_loss=1.3869, LR=0.000100
[2025-08-26 10:57:32,823][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011216] [Batch 00517/00823] [00:06:19/00:03:44, 0.735s/it]: train_loss_raw=1.3633, running_loss=1.3876, LR=0.000100
[2025-08-26 10:57:38,642][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011224] [Batch 00525/00823] [00:06:25/00:03:38, 0.735s/it]: train_loss_raw=1.4365, running_loss=1.3877, LR=0.000100
[2025-08-26 10:57:44,416][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011232] [Batch 00533/00823] [00:06:31/00:03:33, 0.735s/it]: train_loss_raw=1.3514, running_loss=1.3850, LR=0.000100
[2025-08-26 10:57:50,235][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011240] [Batch 00541/00823] [00:06:37/00:03:27, 0.734s/it]: train_loss_raw=1.4345, running_loss=1.3852, LR=0.000100
[2025-08-26 10:57:56,035][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011248] [Batch 00549/00823] [00:06:43/00:03:21, 0.734s/it]: train_loss_raw=1.3591, running_loss=1.3838, LR=0.000100
[2025-08-26 10:58:01,871][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011256] [Batch 00557/00823] [00:06:48/00:03:15, 0.734s/it]: train_loss_raw=1.3602, running_loss=1.3841, LR=0.000100
[2025-08-26 10:58:07,615][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011264] [Batch 00565/00823] [00:06:54/00:03:09, 0.734s/it]: train_loss_raw=1.4726, running_loss=1.3873, LR=0.000100
[2025-08-26 10:58:13,658][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011272] [Batch 00573/00823] [00:07:00/00:03:03, 0.734s/it]: train_loss_raw=1.3536, running_loss=1.3870, LR=0.000100
[2025-08-26 10:58:19,573][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011280] [Batch 00581/00823] [00:07:06/00:02:57, 0.734s/it]: train_loss_raw=1.4429, running_loss=1.3850, LR=0.000100
[2025-08-26 10:58:25,383][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011288] [Batch 00589/00823] [00:07:12/00:02:51, 0.734s/it]: train_loss_raw=1.3540, running_loss=1.3850, LR=0.000100
[2025-08-26 10:58:31,073][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011296] [Batch 00597/00823] [00:07:18/00:02:45, 0.734s/it]: train_loss_raw=1.4669, running_loss=1.3865, LR=0.000100
[2025-08-26 10:58:36,712][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011304] [Batch 00605/00823] [00:07:23/00:02:39, 0.734s/it]: train_loss_raw=1.4306, running_loss=1.3863, LR=0.000100
[2025-08-26 10:58:42,497][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011312] [Batch 00613/00823] [00:07:29/00:02:34, 0.733s/it]: train_loss_raw=1.3768, running_loss=1.3869, LR=0.000100
[2025-08-26 10:58:48,441][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011320] [Batch 00621/00823] [00:07:35/00:02:28, 0.734s/it]: train_loss_raw=1.4239, running_loss=1.3893, LR=0.000100
[2025-08-26 10:58:54,231][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011328] [Batch 00629/00823] [00:07:41/00:02:22, 0.733s/it]: train_loss_raw=1.3094, running_loss=1.3855, LR=0.000100
[2025-08-26 10:58:59,963][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011336] [Batch 00637/00823] [00:07:47/00:02:16, 0.733s/it]: train_loss_raw=1.3828, running_loss=1.3851, LR=0.000100
[2025-08-26 10:59:05,855][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011344] [Batch 00645/00823] [00:07:52/00:02:10, 0.733s/it]: train_loss_raw=1.3923, running_loss=1.3867, LR=0.000100
[2025-08-26 10:59:11,566][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011352] [Batch 00653/00823] [00:07:58/00:02:04, 0.733s/it]: train_loss_raw=1.3671, running_loss=1.3860, LR=0.000100
[2025-08-26 10:59:17,321][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011360] [Batch 00661/00823] [00:08:04/00:01:58, 0.733s/it]: train_loss_raw=1.3377, running_loss=1.3852, LR=0.000100
[2025-08-26 10:59:23,061][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011368] [Batch 00669/00823] [00:08:10/00:01:52, 0.733s/it]: train_loss_raw=1.3840, running_loss=1.3843, LR=0.000100
[2025-08-26 10:59:28,821][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011376] [Batch 00677/00823] [00:08:15/00:01:46, 0.733s/it]: train_loss_raw=1.3855, running_loss=1.3845, LR=0.000100
[2025-08-26 10:59:34,650][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011384] [Batch 00685/00823] [00:08:21/00:01:41, 0.732s/it]: train_loss_raw=1.4001, running_loss=1.3854, LR=0.000100
[2025-08-26 10:59:40,360][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011392] [Batch 00693/00823] [00:08:27/00:01:35, 0.732s/it]: train_loss_raw=1.3745, running_loss=1.3845, LR=0.000100
[2025-08-26 10:59:46,263][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011400] [Batch 00701/00823] [00:08:33/00:01:29, 0.732s/it]: train_loss_raw=1.5191, running_loss=1.3845, LR=0.000100
[2025-08-26 10:59:52,163][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011408] [Batch 00709/00823] [00:08:39/00:01:23, 0.732s/it]: train_loss_raw=1.3749, running_loss=1.3825, LR=0.000100
[2025-08-26 10:59:57,897][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011416] [Batch 00717/00823] [00:08:45/00:01:17, 0.732s/it]: train_loss_raw=1.4095, running_loss=1.3828, LR=0.000100
[2025-08-26 11:00:03,636][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011424] [Batch 00725/00823] [00:08:50/00:01:11, 0.732s/it]: train_loss_raw=1.3982, running_loss=1.3822, LR=0.000100
[2025-08-26 11:00:09,383][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011432] [Batch 00733/00823] [00:08:56/00:01:05, 0.732s/it]: train_loss_raw=1.3132, running_loss=1.3825, LR=0.000100
[2025-08-26 11:00:15,125][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011440] [Batch 00741/00823] [00:09:02/00:01:00, 0.732s/it]: train_loss_raw=1.3941, running_loss=1.3805, LR=0.000100
[2025-08-26 11:00:21,205][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011448] [Batch 00749/00823] [00:09:08/00:00:54, 0.732s/it]: train_loss_raw=1.4787, running_loss=1.3824, LR=0.000100
[2025-08-26 11:00:27,093][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011456] [Batch 00757/00823] [00:09:14/00:00:48, 0.732s/it]: train_loss_raw=1.4308, running_loss=1.3826, LR=0.000100
[2025-08-26 11:00:32,831][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011464] [Batch 00765/00823] [00:09:19/00:00:42, 0.732s/it]: train_loss_raw=1.4321, running_loss=1.3825, LR=0.000100
[2025-08-26 11:00:38,454][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011472] [Batch 00773/00823] [00:09:25/00:00:36, 0.732s/it]: train_loss_raw=1.2772, running_loss=1.3789, LR=0.000100
[2025-08-26 11:00:44,271][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011480] [Batch 00781/00823] [00:09:31/00:00:30, 0.732s/it]: train_loss_raw=1.3706, running_loss=1.3787, LR=0.000100
[2025-08-26 11:00:50,022][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011488] [Batch 00789/00823] [00:09:37/00:00:24, 0.731s/it]: train_loss_raw=1.3166, running_loss=1.3800, LR=0.000100
[2025-08-26 11:00:55,862][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011496] [Batch 00797/00823] [00:09:42/00:00:19, 0.731s/it]: train_loss_raw=1.3975, running_loss=1.3791, LR=0.000100
[2025-08-26 11:01:01,742][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011504] [Batch 00805/00823] [00:09:48/00:00:13, 0.731s/it]: train_loss_raw=1.3298, running_loss=1.3778, LR=0.000100
[2025-08-26 11:01:07,529][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011512] [Batch 00813/00823] [00:09:54/00:00:07, 0.731s/it]: train_loss_raw=1.3009, running_loss=1.3761, LR=0.000100
[2025-08-26 11:01:13,440][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011520] [Batch 00821/00823] [00:10:00/00:00:01, 0.731s/it]: train_loss_raw=1.3900, running_loss=1.3747, LR=0.000100
[2025-08-26 11:01:20,940][__main__][INFO] - [VALIDATION] [Epoch 13/29] Starting validation.
[2025-08-26 11:01:32,358][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 011523] [Batch 00007/00013] [00:00:11/00:00:07, 1.427s/it]
[2025-08-26 11:01:39,785][__main__][INFO] - [VALIDATION] [Epoch 13/29] train_loss=1.37405, valid_loss=1.48753
[2025-08-26 11:01:39,785][__main__][INFO] - [VALIDATION] [Epoch 13/29] Metrics:
[2025-08-26 11:01:39,785][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_er      0.630
[2025-08-26 11:01:39,786][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_prec    0.054
[2025-08-26 11:01:39,786][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_recall  0.055
[2025-08-26 11:01:39,786][__main__][INFO] - [VALIDATION] [Epoch 13/29] - pep_recall 0.016
[2025-08-26 11:01:39,788][__main__][INFO] - [TRAIN] [Epoch 13/29] Epoch complete, total time 02:29:03, remaining time 02:50:21, 00:10:38 per epoch
[2025-08-26 11:01:43,774][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011528] [Batch 00006/00823] [00:00:03/00:08:32, 0.627s/it]: train_loss_raw=1.3064, running_loss=1.3183, LR=0.000100
[2025-08-26 11:01:49,538][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011536] [Batch 00014/00823] [00:00:09/00:09:10, 0.680s/it]: train_loss_raw=1.2657, running_loss=1.3178, LR=0.000100
[2025-08-26 11:01:55,383][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011544] [Batch 00022/00823] [00:00:15/00:09:19, 0.699s/it]: train_loss_raw=1.2762, running_loss=1.3194, LR=0.000100
[2025-08-26 11:02:01,225][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011552] [Batch 00030/00823] [00:00:21/00:09:20, 0.707s/it]: train_loss_raw=1.3045, running_loss=1.3202, LR=0.000100
[2025-08-26 11:02:06,950][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011560] [Batch 00038/00823] [00:00:26/00:09:16, 0.709s/it]: train_loss_raw=1.3399, running_loss=1.3214, LR=0.000100
[2025-08-26 11:02:12,687][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011568] [Batch 00046/00823] [00:00:32/00:09:11, 0.710s/it]: train_loss_raw=1.2954, running_loss=1.3225, LR=0.000100
[2025-08-26 11:02:18,590][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011576] [Batch 00054/00823] [00:00:38/00:09:09, 0.714s/it]: train_loss_raw=1.3240, running_loss=1.3225, LR=0.000100
[2025-08-26 11:02:24,374][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011584] [Batch 00062/00823] [00:00:44/00:09:04, 0.715s/it]: train_loss_raw=1.3723, running_loss=1.3229, LR=0.000100
[2025-08-26 11:02:30,199][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011592] [Batch 00070/00823] [00:00:50/00:08:59, 0.717s/it]: train_loss_raw=1.3796, running_loss=1.3217, LR=0.000100
[2025-08-26 11:02:36,063][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011600] [Batch 00078/00823] [00:00:56/00:08:55, 0.719s/it]: train_loss_raw=1.3873, running_loss=1.3233, LR=0.000100
[2025-08-26 11:02:41,793][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011608] [Batch 00086/00823] [00:01:01/00:08:49, 0.718s/it]: train_loss_raw=1.3837, running_loss=1.3261, LR=0.000100
[2025-08-26 11:02:47,581][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011616] [Batch 00094/00823] [00:01:07/00:08:44, 0.719s/it]: train_loss_raw=1.3127, running_loss=1.3258, LR=0.000100
[2025-08-26 11:02:53,349][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011624] [Batch 00102/00823] [00:01:13/00:08:38, 0.719s/it]: train_loss_raw=1.2571, running_loss=1.3256, LR=0.000100
[2025-08-26 11:02:59,260][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011632] [Batch 00110/00823] [00:01:19/00:08:33, 0.720s/it]: train_loss_raw=1.2791, running_loss=1.3247, LR=0.000100
[2025-08-26 11:03:05,079][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011640] [Batch 00118/00823] [00:01:25/00:08:28, 0.721s/it]: train_loss_raw=1.3470, running_loss=1.3261, LR=0.000100
[2025-08-26 11:03:10,816][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011648] [Batch 00126/00823] [00:01:30/00:08:22, 0.721s/it]: train_loss_raw=1.3717, running_loss=1.3256, LR=0.000100
[2025-08-26 11:03:16,579][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011656] [Batch 00134/00823] [00:01:36/00:08:16, 0.721s/it]: train_loss_raw=1.3546, running_loss=1.3256, LR=0.000100
[2025-08-26 11:03:22,343][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011664] [Batch 00142/00823] [00:01:42/00:08:10, 0.721s/it]: train_loss_raw=1.3845, running_loss=1.3252, LR=0.000100
[2025-08-26 11:03:28,212][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011672] [Batch 00150/00823] [00:01:48/00:08:05, 0.721s/it]: train_loss_raw=1.2494, running_loss=1.3247, LR=0.000100
[2025-08-26 11:03:34,245][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011680] [Batch 00158/00823] [00:01:54/00:08:00, 0.723s/it]: train_loss_raw=1.3853, running_loss=1.3282, LR=0.000100
[2025-08-26 11:03:40,042][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011688] [Batch 00166/00823] [00:02:00/00:07:55, 0.723s/it]: train_loss_raw=1.3289, running_loss=1.3281, LR=0.000100
[2025-08-26 11:03:45,859][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011696] [Batch 00174/00823] [00:02:05/00:07:49, 0.723s/it]: train_loss_raw=1.4104, running_loss=1.3268, LR=0.000100
[2025-08-26 11:03:51,779][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011704] [Batch 00182/00823] [00:02:11/00:07:44, 0.724s/it]: train_loss_raw=1.3394, running_loss=1.3251, LR=0.000100
[2025-08-26 11:03:57,601][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011712] [Batch 00190/00823] [00:02:17/00:07:38, 0.724s/it]: train_loss_raw=1.4207, running_loss=1.3263, LR=0.000100
[2025-08-26 11:04:03,393][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011720] [Batch 00198/00823] [00:02:23/00:07:32, 0.724s/it]: train_loss_raw=1.3940, running_loss=1.3265, LR=0.000100
[2025-08-26 11:04:09,375][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011728] [Batch 00206/00823] [00:02:29/00:07:27, 0.725s/it]: train_loss_raw=1.3004, running_loss=1.3265, LR=0.000100
[2025-08-26 11:04:15,230][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011736] [Batch 00214/00823] [00:02:35/00:07:21, 0.725s/it]: train_loss_raw=1.3852, running_loss=1.3272, LR=0.000100
[2025-08-26 11:04:21,000][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011744] [Batch 00222/00823] [00:02:40/00:07:15, 0.725s/it]: train_loss_raw=1.3498, running_loss=1.3277, LR=0.000100
[2025-08-26 11:04:26,858][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011752] [Batch 00230/00823] [00:02:46/00:07:10, 0.725s/it]: train_loss_raw=1.3135, running_loss=1.3295, LR=0.000100
[2025-08-26 11:04:32,779][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011760] [Batch 00238/00823] [00:02:52/00:07:04, 0.726s/it]: train_loss_raw=1.2885, running_loss=1.3281, LR=0.000100
[2025-08-26 11:04:38,557][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011768] [Batch 00246/00823] [00:02:58/00:06:58, 0.726s/it]: train_loss_raw=1.3491, running_loss=1.3277, LR=0.000100
[2025-08-26 11:04:44,371][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011776] [Batch 00254/00823] [00:03:04/00:06:52, 0.726s/it]: train_loss_raw=1.3064, running_loss=1.3276, LR=0.000100
[2025-08-26 11:04:50,140][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011784] [Batch 00262/00823] [00:03:10/00:06:47, 0.726s/it]: train_loss_raw=1.2627, running_loss=1.3257, LR=0.000100
[2025-08-26 11:04:55,951][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011792] [Batch 00270/00823] [00:03:15/00:06:41, 0.726s/it]: train_loss_raw=1.3945, running_loss=1.3260, LR=0.000100
[2025-08-26 11:05:01,855][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011800] [Batch 00278/00823] [00:03:21/00:06:35, 0.726s/it]: train_loss_raw=1.3058, running_loss=1.3252, LR=0.000100
[2025-08-26 11:05:07,599][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011808] [Batch 00286/00823] [00:03:27/00:06:29, 0.726s/it]: train_loss_raw=1.2931, running_loss=1.3227, LR=0.000100
[2025-08-26 11:05:13,353][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011816] [Batch 00294/00823] [00:03:33/00:06:23, 0.726s/it]: train_loss_raw=1.3063, running_loss=1.3236, LR=0.000100
[2025-08-26 11:05:19,149][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011824] [Batch 00302/00823] [00:03:39/00:06:18, 0.726s/it]: train_loss_raw=1.4220, running_loss=1.3229, LR=0.000100
[2025-08-26 11:05:24,883][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011832] [Batch 00310/00823] [00:03:44/00:06:12, 0.725s/it]: train_loss_raw=1.3504, running_loss=1.3256, LR=0.000100
[2025-08-26 11:05:30,691][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011840] [Batch 00318/00823] [00:03:50/00:06:06, 0.725s/it]: train_loss_raw=1.4430, running_loss=1.3270, LR=0.000100
[2025-08-26 11:05:36,483][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011848] [Batch 00326/00823] [00:03:56/00:06:00, 0.725s/it]: train_loss_raw=1.4256, running_loss=1.3272, LR=0.000100
[2025-08-26 11:05:42,305][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011856] [Batch 00334/00823] [00:04:02/00:05:54, 0.725s/it]: train_loss_raw=1.3022, running_loss=1.3287, LR=0.000100
[2025-08-26 11:05:48,091][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011864] [Batch 00342/00823] [00:04:08/00:05:48, 0.725s/it]: train_loss_raw=1.4184, running_loss=1.3322, LR=0.000100
[2025-08-26 11:05:53,869][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011872] [Batch 00350/00823] [00:04:13/00:05:43, 0.725s/it]: train_loss_raw=1.3403, running_loss=1.3331, LR=0.000100
[2025-08-26 11:05:59,824][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011880] [Batch 00358/00823] [00:04:19/00:05:37, 0.726s/it]: train_loss_raw=1.3283, running_loss=1.3326, LR=0.000100
[2025-08-26 11:06:05,676][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011888] [Batch 00366/00823] [00:04:25/00:05:31, 0.726s/it]: train_loss_raw=1.3636, running_loss=1.3299, LR=0.000100
[2025-08-26 11:06:11,477][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011896] [Batch 00374/00823] [00:04:31/00:05:25, 0.726s/it]: train_loss_raw=1.3160, running_loss=1.3304, LR=0.000100
[2025-08-26 11:06:17,254][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011904] [Batch 00382/00823] [00:04:37/00:05:20, 0.726s/it]: train_loss_raw=1.4165, running_loss=1.3312, LR=0.000100
[2025-08-26 11:06:22,982][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011912] [Batch 00390/00823] [00:04:42/00:05:14, 0.726s/it]: train_loss_raw=1.4026, running_loss=1.3318, LR=0.000100
[2025-08-26 11:06:28,782][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011920] [Batch 00398/00823] [00:04:48/00:05:08, 0.726s/it]: train_loss_raw=1.2435, running_loss=1.3296, LR=0.000100
[2025-08-26 11:06:34,665][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011928] [Batch 00406/00823] [00:04:54/00:05:02, 0.726s/it]: train_loss_raw=1.3975, running_loss=1.3282, LR=0.000100
[2025-08-26 11:06:40,410][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011936] [Batch 00414/00823] [00:05:00/00:04:56, 0.726s/it]: train_loss_raw=1.2492, running_loss=1.3268, LR=0.000100
[2025-08-26 11:06:46,224][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011944] [Batch 00422/00823] [00:05:06/00:04:50, 0.726s/it]: train_loss_raw=1.1858, running_loss=1.3243, LR=0.000100
[2025-08-26 11:06:52,009][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011952] [Batch 00430/00823] [00:05:11/00:04:45, 0.726s/it]: train_loss_raw=1.3874, running_loss=1.3263, LR=0.000100
[2025-08-26 11:06:57,842][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011960] [Batch 00438/00823] [00:05:17/00:04:39, 0.726s/it]: train_loss_raw=1.3177, running_loss=1.3268, LR=0.000100
[2025-08-26 11:07:03,644][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011968] [Batch 00446/00823] [00:05:23/00:04:33, 0.726s/it]: train_loss_raw=1.3967, running_loss=1.3268, LR=0.000100
[2025-08-26 11:07:09,380][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011976] [Batch 00454/00823] [00:05:29/00:04:27, 0.725s/it]: train_loss_raw=1.3528, running_loss=1.3259, LR=0.000100
[2025-08-26 11:07:15,067][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011984] [Batch 00462/00823] [00:05:35/00:04:21, 0.725s/it]: train_loss_raw=1.2227, running_loss=1.3224, LR=0.000100
[2025-08-26 11:07:20,837][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011992] [Batch 00470/00823] [00:05:40/00:04:15, 0.725s/it]: train_loss_raw=1.3537, running_loss=1.3230, LR=0.000100
[2025-08-26 11:07:26,509][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012000] [Batch 00478/00823] [00:05:46/00:04:10, 0.725s/it]: train_loss_raw=1.2949, running_loss=1.3214, LR=0.000100
[2025-08-26 11:07:35,596][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012008] [Batch 00486/00823] [00:05:55/00:04:06, 0.732s/it]: train_loss_raw=1.3400, running_loss=1.3215, LR=0.000100
[2025-08-26 11:07:41,379][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012016] [Batch 00494/00823] [00:06:01/00:04:00, 0.732s/it]: train_loss_raw=1.3254, running_loss=1.3202, LR=0.000100
[2025-08-26 11:07:47,172][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012024] [Batch 00502/00823] [00:06:07/00:03:54, 0.731s/it]: train_loss_raw=1.2623, running_loss=1.3200, LR=0.000100
[2025-08-26 11:07:52,954][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012032] [Batch 00510/00823] [00:06:12/00:03:48, 0.731s/it]: train_loss_raw=1.2626, running_loss=1.3157, LR=0.000100
[2025-08-26 11:07:58,711][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012040] [Batch 00518/00823] [00:06:18/00:03:42, 0.731s/it]: train_loss_raw=1.2142, running_loss=1.3158, LR=0.000100
[2025-08-26 11:08:04,470][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012048] [Batch 00526/00823] [00:06:24/00:03:37, 0.731s/it]: train_loss_raw=1.3343, running_loss=1.3167, LR=0.000100
[2025-08-26 11:08:10,213][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012056] [Batch 00534/00823] [00:06:30/00:03:31, 0.731s/it]: train_loss_raw=1.2829, running_loss=1.3190, LR=0.000100
[2025-08-26 11:08:15,988][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012064] [Batch 00542/00823] [00:06:35/00:03:25, 0.731s/it]: train_loss_raw=1.2836, running_loss=1.3206, LR=0.000100
[2025-08-26 11:08:22,012][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012072] [Batch 00550/00823] [00:06:41/00:03:19, 0.731s/it]: train_loss_raw=1.3242, running_loss=1.3191, LR=0.000100
[2025-08-26 11:08:28,009][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012080] [Batch 00558/00823] [00:06:47/00:03:13, 0.731s/it]: train_loss_raw=1.3010, running_loss=1.3181, LR=0.000100
[2025-08-26 11:08:33,793][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012088] [Batch 00566/00823] [00:06:53/00:03:07, 0.731s/it]: train_loss_raw=1.3085, running_loss=1.3199, LR=0.000100
[2025-08-26 11:08:39,547][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012096] [Batch 00574/00823] [00:06:59/00:03:01, 0.731s/it]: train_loss_raw=1.3355, running_loss=1.3189, LR=0.000100
[2025-08-26 11:08:45,380][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012104] [Batch 00582/00823] [00:07:05/00:02:56, 0.731s/it]: train_loss_raw=1.3855, running_loss=1.3208, LR=0.000100
[2025-08-26 11:08:51,134][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012112] [Batch 00590/00823] [00:07:11/00:02:50, 0.731s/it]: train_loss_raw=1.3679, running_loss=1.3210, LR=0.000100
[2025-08-26 11:08:56,830][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012120] [Batch 00598/00823] [00:07:16/00:02:44, 0.730s/it]: train_loss_raw=1.3570, running_loss=1.3230, LR=0.000100
[2025-08-26 11:09:02,500][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012128] [Batch 00606/00823] [00:07:22/00:02:38, 0.730s/it]: train_loss_raw=1.3294, running_loss=1.3214, LR=0.000100
[2025-08-26 11:09:08,181][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012136] [Batch 00614/00823] [00:07:28/00:02:32, 0.730s/it]: train_loss_raw=1.3266, running_loss=1.3217, LR=0.000100
[2025-08-26 11:09:13,837][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012144] [Batch 00622/00823] [00:07:33/00:02:26, 0.730s/it]: train_loss_raw=1.3592, running_loss=1.3235, LR=0.000100
[2025-08-26 11:09:19,530][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012152] [Batch 00630/00823] [00:07:39/00:02:20, 0.729s/it]: train_loss_raw=1.3131, running_loss=1.3241, LR=0.000100
[2025-08-26 11:09:25,360][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012160] [Batch 00638/00823] [00:07:45/00:02:14, 0.729s/it]: train_loss_raw=1.2787, running_loss=1.3242, LR=0.000100
[2025-08-26 11:09:31,290][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012168] [Batch 00646/00823] [00:07:51/00:02:09, 0.730s/it]: train_loss_raw=1.3399, running_loss=1.3234, LR=0.000100
[2025-08-26 11:09:37,211][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012176] [Batch 00654/00823] [00:07:57/00:02:03, 0.730s/it]: train_loss_raw=1.3710, running_loss=1.3236, LR=0.000100
[2025-08-26 11:09:43,106][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012184] [Batch 00662/00823] [00:08:03/00:01:57, 0.730s/it]: train_loss_raw=1.2370, running_loss=1.3231, LR=0.000100
[2025-08-26 11:09:48,968][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012192] [Batch 00670/00823] [00:08:08/00:01:51, 0.730s/it]: train_loss_raw=1.4507, running_loss=1.3241, LR=0.000100
[2025-08-26 11:09:54,792][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012200] [Batch 00678/00823] [00:08:14/00:01:45, 0.730s/it]: train_loss_raw=1.3569, running_loss=1.3244, LR=0.000100
[2025-08-26 11:10:00,798][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012208] [Batch 00686/00823] [00:08:20/00:01:40, 0.730s/it]: train_loss_raw=1.3259, running_loss=1.3260, LR=0.000100
[2025-08-26 11:10:06,712][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012216] [Batch 00694/00823] [00:08:26/00:01:34, 0.730s/it]: train_loss_raw=1.2502, running_loss=1.3278, LR=0.000100
[2025-08-26 11:10:12,496][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012224] [Batch 00702/00823] [00:08:32/00:01:28, 0.730s/it]: train_loss_raw=1.3452, running_loss=1.3276, LR=0.000100
[2025-08-26 11:10:18,264][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012232] [Batch 00710/00823] [00:08:38/00:01:22, 0.730s/it]: train_loss_raw=1.2710, running_loss=1.3240, LR=0.000100
[2025-08-26 11:10:24,041][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012240] [Batch 00718/00823] [00:08:44/00:01:16, 0.730s/it]: train_loss_raw=1.4142, running_loss=1.3233, LR=0.000100
[2025-08-26 11:10:30,175][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012248] [Batch 00726/00823] [00:08:50/00:01:10, 0.730s/it]: train_loss_raw=1.3112, running_loss=1.3224, LR=0.000100
[2025-08-26 11:10:36,087][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012256] [Batch 00734/00823] [00:08:56/00:01:05, 0.730s/it]: train_loss_raw=1.4122, running_loss=1.3226, LR=0.000100
[2025-08-26 11:10:41,996][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012264] [Batch 00742/00823] [00:09:01/00:00:59, 0.730s/it]: train_loss_raw=1.2474, running_loss=1.3195, LR=0.000100
[2025-08-26 11:10:47,861][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012272] [Batch 00750/00823] [00:09:07/00:00:53, 0.730s/it]: train_loss_raw=1.2573, running_loss=1.3161, LR=0.000100
[2025-08-26 11:10:53,687][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012280] [Batch 00758/00823] [00:09:13/00:00:47, 0.730s/it]: train_loss_raw=1.3064, running_loss=1.3173, LR=0.000100
[2025-08-26 11:10:59,459][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012288] [Batch 00766/00823] [00:09:19/00:00:41, 0.730s/it]: train_loss_raw=1.3628, running_loss=1.3186, LR=0.000100
[2025-08-26 11:11:05,236][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012296] [Batch 00774/00823] [00:09:25/00:00:35, 0.730s/it]: train_loss_raw=1.3848, running_loss=1.3195, LR=0.000100
[2025-08-26 11:11:10,999][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012304] [Batch 00782/00823] [00:09:30/00:00:29, 0.730s/it]: train_loss_raw=1.4268, running_loss=1.3197, LR=0.000100
[2025-08-26 11:11:16,774][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012312] [Batch 00790/00823] [00:09:36/00:00:24, 0.730s/it]: train_loss_raw=1.2894, running_loss=1.3186, LR=0.000100
[2025-08-26 11:11:22,617][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012320] [Batch 00798/00823] [00:09:42/00:00:18, 0.730s/it]: train_loss_raw=1.2673, running_loss=1.3174, LR=0.000100
[2025-08-26 11:11:28,427][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012328] [Batch 00806/00823] [00:09:48/00:00:12, 0.730s/it]: train_loss_raw=1.4400, running_loss=1.3187, LR=0.000100
[2025-08-26 11:11:34,197][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012336] [Batch 00814/00823] [00:09:54/00:00:06, 0.730s/it]: train_loss_raw=1.2053, running_loss=1.3158, LR=0.000100
[2025-08-26 11:11:40,032][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012344] [Batch 00822/00823] [00:10:00/00:00:00, 0.730s/it]: train_loss_raw=1.2251, running_loss=1.3154, LR=0.000100
[2025-08-26 11:11:40,979][__main__][INFO] - [VALIDATION] [Epoch 14/29] Starting validation.
[2025-08-26 11:11:52,315][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 012346] [Batch 00007/00013] [00:00:11/00:00:07, 1.417s/it]
[2025-08-26 11:11:59,500][__main__][INFO] - [VALIDATION] [Epoch 14/29] train_loss=1.31400, valid_loss=1.46307
[2025-08-26 11:11:59,500][__main__][INFO] - [VALIDATION] [Epoch 14/29] Metrics:
[2025-08-26 11:11:59,500][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_er      0.631
[2025-08-26 11:11:59,500][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_prec    0.060
[2025-08-26 11:11:59,500][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_recall  0.061
[2025-08-26 11:11:59,500][__main__][INFO] - [VALIDATION] [Epoch 14/29] - pep_recall 0.020
[2025-08-26 11:11:59,502][__main__][INFO] - [TRAIN] [Epoch 14/29] Epoch complete, total time 02:39:23, remaining time 02:39:23, 00:10:37 per epoch
[2025-08-26 11:12:04,279][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012352] [Batch 00007/00823] [00:00:04/00:08:48, 0.648s/it]: train_loss_raw=1.2674, running_loss=1.2508, LR=0.000100
[2025-08-26 11:12:10,137][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012360] [Batch 00015/00823] [00:00:10/00:09:19, 0.693s/it]: train_loss_raw=1.3624, running_loss=1.2554, LR=0.000100
[2025-08-26 11:12:16,433][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012368] [Batch 00023/00823] [00:00:16/00:09:40, 0.726s/it]: train_loss_raw=1.3377, running_loss=1.2585, LR=0.000100
[2025-08-26 11:12:22,300][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012376] [Batch 00031/00823] [00:00:22/00:09:36, 0.728s/it]: train_loss_raw=1.2884, running_loss=1.2643, LR=0.000100
[2025-08-26 11:12:28,290][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012384] [Batch 00039/00823] [00:00:28/00:09:33, 0.732s/it]: train_loss_raw=1.3882, running_loss=1.2693, LR=0.000100
[2025-08-26 11:12:34,195][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012392] [Batch 00047/00823] [00:00:34/00:09:28, 0.733s/it]: train_loss_raw=1.3112, running_loss=1.2728, LR=0.000100
[2025-08-26 11:12:40,014][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012400] [Batch 00055/00823] [00:00:40/00:09:22, 0.732s/it]: train_loss_raw=1.3370, running_loss=1.2769, LR=0.000100
[2025-08-26 11:12:45,709][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012408] [Batch 00063/00823] [00:00:45/00:09:14, 0.730s/it]: train_loss_raw=1.3203, running_loss=1.2816, LR=0.000100
[2025-08-26 11:12:51,567][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012416] [Batch 00071/00823] [00:00:51/00:09:08, 0.730s/it]: train_loss_raw=1.2136, running_loss=1.2839, LR=0.000100
[2025-08-26 11:12:57,356][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012424] [Batch 00079/00823] [00:00:57/00:09:02, 0.729s/it]: train_loss_raw=1.2880, running_loss=1.2860, LR=0.000100
[2025-08-26 11:13:03,211][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012432] [Batch 00087/00823] [00:01:03/00:08:56, 0.730s/it]: train_loss_raw=1.2745, running_loss=1.2860, LR=0.000100
[2025-08-26 11:13:09,001][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012440] [Batch 00095/00823] [00:01:09/00:08:50, 0.729s/it]: train_loss_raw=1.3135, running_loss=1.2858, LR=0.000100
[2025-08-26 11:13:14,867][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012448] [Batch 00103/00823] [00:01:15/00:08:45, 0.729s/it]: train_loss_raw=1.3264, running_loss=1.2883, LR=0.000100
[2025-08-26 11:13:20,656][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012456] [Batch 00111/00823] [00:01:20/00:08:39, 0.729s/it]: train_loss_raw=1.2827, running_loss=1.2916, LR=0.000100
[2025-08-26 11:13:26,455][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012464] [Batch 00119/00823] [00:01:26/00:08:32, 0.729s/it]: train_loss_raw=1.2650, running_loss=1.2908, LR=0.000100
[2025-08-26 11:13:32,404][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012472] [Batch 00127/00823] [00:01:32/00:08:27, 0.730s/it]: train_loss_raw=1.3596, running_loss=1.2930, LR=0.000100
[2025-08-26 11:13:38,478][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012480] [Batch 00135/00823] [00:01:38/00:08:23, 0.731s/it]: train_loss_raw=1.3618, running_loss=1.2934, LR=0.000100
[2025-08-26 11:13:44,426][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012488] [Batch 00143/00823] [00:01:44/00:08:17, 0.732s/it]: train_loss_raw=1.2152, running_loss=1.2902, LR=0.000100
[2025-08-26 11:13:50,423][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012496] [Batch 00151/00823] [00:01:50/00:08:12, 0.733s/it]: train_loss_raw=1.3107, running_loss=1.2939, LR=0.000100
[2025-08-26 11:13:56,247][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012504] [Batch 00159/00823] [00:01:56/00:08:06, 0.733s/it]: train_loss_raw=1.2976, running_loss=1.2954, LR=0.000100
[2025-08-26 11:14:02,038][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012512] [Batch 00167/00823] [00:02:02/00:08:00, 0.732s/it]: train_loss_raw=1.3587, running_loss=1.2979, LR=0.000100
[2025-08-26 11:14:07,947][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012520] [Batch 00175/00823] [00:02:08/00:07:54, 0.733s/it]: train_loss_raw=1.3132, running_loss=1.2991, LR=0.000100
[2025-08-26 11:14:13,700][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012528] [Batch 00183/00823] [00:02:13/00:07:48, 0.732s/it]: train_loss_raw=1.2899, running_loss=1.2996, LR=0.000100
[2025-08-26 11:14:19,472][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012536] [Batch 00191/00823] [00:02:19/00:07:42, 0.732s/it]: train_loss_raw=1.2938, running_loss=1.3019, LR=0.000100
[2025-08-26 11:14:25,317][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012544] [Batch 00199/00823] [00:02:25/00:07:36, 0.732s/it]: train_loss_raw=1.2468, running_loss=1.3025, LR=0.000100
[2025-08-26 11:14:31,168][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012552] [Batch 00207/00823] [00:02:31/00:07:30, 0.732s/it]: train_loss_raw=1.3429, running_loss=1.3034, LR=0.000100
[2025-08-26 11:14:37,189][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012560] [Batch 00215/00823] [00:02:37/00:07:25, 0.732s/it]: train_loss_raw=1.2644, running_loss=1.3047, LR=0.000100
[2025-08-26 11:14:43,078][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012568] [Batch 00223/00823] [00:02:43/00:07:19, 0.732s/it]: train_loss_raw=1.4704, running_loss=1.3090, LR=0.000100
[2025-08-26 11:14:48,826][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012576] [Batch 00231/00823] [00:02:49/00:07:13, 0.732s/it]: train_loss_raw=1.2657, running_loss=1.3063, LR=0.000100
[2025-08-26 11:14:54,697][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012584] [Batch 00239/00823] [00:02:54/00:07:07, 0.732s/it]: train_loss_raw=1.3646, running_loss=1.3057, LR=0.000100
[2025-08-26 11:15:00,636][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012592] [Batch 00247/00823] [00:03:00/00:07:01, 0.732s/it]: train_loss_raw=1.3785, running_loss=1.3078, LR=0.000100
[2025-08-26 11:15:06,558][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012600] [Batch 00255/00823] [00:03:06/00:06:56, 0.733s/it]: train_loss_raw=1.3394, running_loss=1.3086, LR=0.000100
[2025-08-26 11:15:12,474][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012608] [Batch 00263/00823] [00:03:12/00:06:50, 0.733s/it]: train_loss_raw=1.2625, running_loss=1.3081, LR=0.000100
[2025-08-26 11:15:18,314][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012616] [Batch 00271/00823] [00:03:18/00:06:44, 0.733s/it]: train_loss_raw=1.2428, running_loss=1.3078, LR=0.000100
[2025-08-26 11:15:24,203][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012624] [Batch 00279/00823] [00:03:24/00:06:38, 0.733s/it]: train_loss_raw=1.3464, running_loss=1.3082, LR=0.000100
[2025-08-26 11:15:30,010][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012632] [Batch 00287/00823] [00:03:30/00:06:32, 0.733s/it]: train_loss_raw=1.2665, running_loss=1.3112, LR=0.000100
[2025-08-26 11:15:35,955][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012640] [Batch 00295/00823] [00:03:36/00:06:26, 0.733s/it]: train_loss_raw=1.3607, running_loss=1.3112, LR=0.000100
[2025-08-26 11:15:41,835][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012648] [Batch 00303/00823] [00:03:42/00:06:21, 0.733s/it]: train_loss_raw=1.3998, running_loss=1.3138, LR=0.000100
[2025-08-26 11:15:47,771][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012656] [Batch 00311/00823] [00:03:48/00:06:15, 0.733s/it]: train_loss_raw=1.3088, running_loss=1.3126, LR=0.000100
[2025-08-26 11:15:53,703][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012664] [Batch 00319/00823] [00:03:53/00:06:09, 0.733s/it]: train_loss_raw=1.3234, running_loss=1.3128, LR=0.000100
[2025-08-26 11:15:59,414][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012672] [Batch 00327/00823] [00:03:59/00:06:03, 0.733s/it]: train_loss_raw=1.2625, running_loss=1.3128, LR=0.000100
[2025-08-26 11:16:05,283][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012680] [Batch 00335/00823] [00:04:05/00:05:57, 0.733s/it]: train_loss_raw=1.3027, running_loss=1.3139, LR=0.000100
[2025-08-26 11:16:11,107][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012688] [Batch 00343/00823] [00:04:11/00:05:51, 0.733s/it]: train_loss_raw=1.3730, running_loss=1.3142, LR=0.000100
[2025-08-26 11:16:16,864][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012696] [Batch 00351/00823] [00:04:17/00:05:45, 0.733s/it]: train_loss_raw=1.3176, running_loss=1.3155, LR=0.000100
[2025-08-26 11:16:22,658][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012704] [Batch 00359/00823] [00:04:22/00:05:39, 0.732s/it]: train_loss_raw=1.2991, running_loss=1.3128, LR=0.000100
[2025-08-26 11:16:28,420][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012712] [Batch 00367/00823] [00:04:28/00:05:33, 0.732s/it]: train_loss_raw=1.2091, running_loss=1.3120, LR=0.000100
[2025-08-26 11:16:34,191][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012720] [Batch 00375/00823] [00:04:34/00:05:27, 0.732s/it]: train_loss_raw=1.3255, running_loss=1.3116, LR=0.000100
[2025-08-26 11:16:40,003][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012728] [Batch 00383/00823] [00:04:40/00:05:21, 0.732s/it]: train_loss_raw=1.3098, running_loss=1.3108, LR=0.000100
[2025-08-26 11:16:45,827][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012736] [Batch 00391/00823] [00:04:46/00:05:16, 0.732s/it]: train_loss_raw=1.2712, running_loss=1.3100, LR=0.000100
[2025-08-26 11:16:51,620][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012744] [Batch 00399/00823] [00:04:51/00:05:10, 0.732s/it]: train_loss_raw=1.2205, running_loss=1.3098, LR=0.000100
[2025-08-26 11:16:57,557][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012752] [Batch 00407/00823] [00:04:57/00:05:04, 0.732s/it]: train_loss_raw=1.3485, running_loss=1.3100, LR=0.000100
[2025-08-26 11:17:03,414][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012760] [Batch 00415/00823] [00:05:03/00:04:58, 0.732s/it]: train_loss_raw=1.2995, running_loss=1.3101, LR=0.000100
[2025-08-26 11:17:09,228][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012768] [Batch 00423/00823] [00:05:09/00:04:52, 0.732s/it]: train_loss_raw=1.2929, running_loss=1.3095, LR=0.000100
[2025-08-26 11:17:15,041][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012776] [Batch 00431/00823] [00:05:15/00:04:46, 0.732s/it]: train_loss_raw=1.3162, running_loss=1.3091, LR=0.000100
[2025-08-26 11:17:20,809][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012784] [Batch 00439/00823] [00:05:21/00:04:40, 0.731s/it]: train_loss_raw=1.2952, running_loss=1.3084, LR=0.000100
[2025-08-26 11:17:26,754][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012792] [Batch 00447/00823] [00:05:27/00:04:35, 0.732s/it]: train_loss_raw=1.1840, running_loss=1.3080, LR=0.000100
[2025-08-26 11:17:32,728][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012800] [Batch 00455/00823] [00:05:32/00:04:29, 0.732s/it]: train_loss_raw=1.3508, running_loss=1.3055, LR=0.000100
[2025-08-26 11:17:38,582][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012808] [Batch 00463/00823] [00:05:38/00:04:23, 0.732s/it]: train_loss_raw=1.2241, running_loss=1.3047, LR=0.000100
[2025-08-26 11:17:44,450][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012816] [Batch 00471/00823] [00:05:44/00:04:17, 0.732s/it]: train_loss_raw=1.3034, running_loss=1.3031, LR=0.000100
[2025-08-26 11:17:50,223][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012824] [Batch 00479/00823] [00:05:50/00:04:11, 0.732s/it]: train_loss_raw=1.2725, running_loss=1.3002, LR=0.000100
[2025-08-26 11:17:55,962][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012832] [Batch 00487/00823] [00:05:56/00:04:05, 0.731s/it]: train_loss_raw=1.2923, running_loss=1.3018, LR=0.000100
[2025-08-26 11:18:01,793][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012840] [Batch 00495/00823] [00:06:02/00:03:59, 0.731s/it]: train_loss_raw=1.3345, running_loss=1.3020, LR=0.000100
[2025-08-26 11:18:07,646][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012848] [Batch 00503/00823] [00:06:07/00:03:54, 0.731s/it]: train_loss_raw=1.2629, running_loss=1.3027, LR=0.000100
[2025-08-26 11:18:13,457][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012856] [Batch 00511/00823] [00:06:13/00:03:48, 0.731s/it]: train_loss_raw=1.3494, running_loss=1.3031, LR=0.000100
[2025-08-26 11:18:19,444][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012864] [Batch 00519/00823] [00:06:19/00:03:42, 0.732s/it]: train_loss_raw=1.3218, running_loss=1.3008, LR=0.000100
[2025-08-26 11:18:25,342][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012872] [Batch 00527/00823] [00:06:25/00:03:36, 0.732s/it]: train_loss_raw=1.2668, running_loss=1.2967, LR=0.000100
[2025-08-26 11:18:31,141][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012880] [Batch 00535/00823] [00:06:31/00:03:30, 0.732s/it]: train_loss_raw=1.2361, running_loss=1.2955, LR=0.000100
[2025-08-26 11:18:37,041][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012888] [Batch 00543/00823] [00:06:37/00:03:24, 0.732s/it]: train_loss_raw=1.3084, running_loss=1.2984, LR=0.000100
[2025-08-26 11:18:42,803][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012896] [Batch 00551/00823] [00:06:43/00:03:18, 0.732s/it]: train_loss_raw=1.3119, running_loss=1.3006, LR=0.000100
[2025-08-26 11:18:48,562][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012904] [Batch 00559/00823] [00:06:48/00:03:13, 0.731s/it]: train_loss_raw=1.3303, running_loss=1.3022, LR=0.000100
[2025-08-26 11:18:54,367][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012912] [Batch 00567/00823] [00:06:54/00:03:07, 0.731s/it]: train_loss_raw=1.2575, running_loss=1.3029, LR=0.000100
[2025-08-26 11:19:00,368][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012920] [Batch 00575/00823] [00:07:00/00:03:01, 0.732s/it]: train_loss_raw=1.3987, running_loss=1.3044, LR=0.000100
[2025-08-26 11:19:06,223][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012928] [Batch 00583/00823] [00:07:06/00:02:55, 0.732s/it]: train_loss_raw=1.1936, running_loss=1.3042, LR=0.000100
[2025-08-26 11:19:11,795][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012936] [Batch 00591/00823] [00:07:12/00:02:49, 0.731s/it]: train_loss_raw=1.2999, running_loss=1.3058, LR=0.000100
[2025-08-26 11:19:17,499][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012944] [Batch 00599/00823] [00:07:17/00:02:43, 0.731s/it]: train_loss_raw=1.2605, running_loss=1.3094, LR=0.000100
[2025-08-26 11:19:23,314][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012952] [Batch 00607/00823] [00:07:23/00:02:37, 0.731s/it]: train_loss_raw=1.2792, running_loss=1.3085, LR=0.000100
[2025-08-26 11:19:29,125][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012960] [Batch 00615/00823] [00:07:29/00:02:31, 0.731s/it]: train_loss_raw=1.3042, running_loss=1.3089, LR=0.000100
[2025-08-26 11:19:35,092][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012968] [Batch 00623/00823] [00:07:35/00:02:26, 0.731s/it]: train_loss_raw=1.2145, running_loss=1.3090, LR=0.000100
[2025-08-26 11:19:40,966][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012976] [Batch 00631/00823] [00:07:41/00:02:20, 0.731s/it]: train_loss_raw=1.1818, running_loss=1.3054, LR=0.000100
[2025-08-26 11:19:46,802][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012984] [Batch 00639/00823] [00:07:47/00:02:14, 0.731s/it]: train_loss_raw=1.2594, running_loss=1.3047, LR=0.000100
[2025-08-26 11:19:52,663][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012992] [Batch 00647/00823] [00:07:52/00:02:08, 0.731s/it]: train_loss_raw=1.3083, running_loss=1.3040, LR=0.000100
[2025-08-26 11:19:58,529][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013000] [Batch 00655/00823] [00:07:58/00:02:02, 0.731s/it]: train_loss_raw=1.2780, running_loss=1.3058, LR=0.000100
[2025-08-26 11:20:04,452][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013008] [Batch 00663/00823] [00:08:04/00:01:56, 0.731s/it]: train_loss_raw=1.3706, running_loss=1.3075, LR=0.000100
[2025-08-26 11:20:10,400][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013016] [Batch 00671/00823] [00:08:10/00:01:51, 0.731s/it]: train_loss_raw=1.3051, running_loss=1.3056, LR=0.000100
[2025-08-26 11:20:16,303][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013024] [Batch 00679/00823] [00:08:16/00:01:45, 0.731s/it]: train_loss_raw=1.3954, running_loss=1.3045, LR=0.000100
[2025-08-26 11:20:22,263][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013032] [Batch 00687/00823] [00:08:22/00:01:39, 0.731s/it]: train_loss_raw=1.4112, running_loss=1.3030, LR=0.000100
[2025-08-26 11:20:28,264][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013040] [Batch 00695/00823] [00:08:28/00:01:33, 0.732s/it]: train_loss_raw=1.2744, running_loss=1.3015, LR=0.000100
[2025-08-26 11:20:34,201][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013048] [Batch 00703/00823] [00:08:34/00:01:27, 0.732s/it]: train_loss_raw=1.3208, running_loss=1.3027, LR=0.000100
[2025-08-26 11:20:40,006][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013056] [Batch 00711/00823] [00:08:40/00:01:21, 0.732s/it]: train_loss_raw=1.2975, running_loss=1.3033, LR=0.000100
[2025-08-26 11:20:45,835][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013064] [Batch 00719/00823] [00:08:46/00:01:16, 0.732s/it]: train_loss_raw=1.2281, running_loss=1.3028, LR=0.000100
[2025-08-26 11:20:51,633][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013072] [Batch 00727/00823] [00:08:51/00:01:10, 0.732s/it]: train_loss_raw=1.2769, running_loss=1.3040, LR=0.000100
[2025-08-26 11:20:57,391][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013080] [Batch 00735/00823] [00:08:57/00:01:04, 0.731s/it]: train_loss_raw=1.2507, running_loss=1.3015, LR=0.000100
[2025-08-26 11:21:03,107][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013088] [Batch 00743/00823] [00:09:03/00:00:58, 0.731s/it]: train_loss_raw=1.1076, running_loss=1.2987, LR=0.000100
[2025-08-26 11:21:08,890][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013096] [Batch 00751/00823] [00:09:09/00:00:52, 0.731s/it]: train_loss_raw=1.2677, running_loss=1.2984, LR=0.000100
[2025-08-26 11:21:14,686][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013104] [Batch 00759/00823] [00:09:14/00:00:46, 0.731s/it]: train_loss_raw=1.2472, running_loss=1.2955, LR=0.000100
[2025-08-26 11:21:20,480][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013112] [Batch 00767/00823] [00:09:20/00:00:40, 0.731s/it]: train_loss_raw=1.3397, running_loss=1.2965, LR=0.000100
[2025-08-26 11:21:26,494][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013120] [Batch 00775/00823] [00:09:26/00:00:35, 0.731s/it]: train_loss_raw=1.2169, running_loss=1.2950, LR=0.000100
[2025-08-26 11:21:32,418][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013128] [Batch 00783/00823] [00:09:32/00:00:29, 0.731s/it]: train_loss_raw=1.3110, running_loss=1.2946, LR=0.000100
[2025-08-26 11:21:38,323][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013136] [Batch 00791/00823] [00:09:38/00:00:23, 0.731s/it]: train_loss_raw=1.2579, running_loss=1.2924, LR=0.000100
[2025-08-26 11:21:44,199][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013144] [Batch 00799/00823] [00:09:44/00:00:17, 0.731s/it]: train_loss_raw=1.3573, running_loss=1.2934, LR=0.000100
[2025-08-26 11:21:50,034][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013152] [Batch 00807/00823] [00:09:50/00:00:11, 0.731s/it]: train_loss_raw=1.2342, running_loss=1.2949, LR=0.000100
[2025-08-26 11:21:56,010][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013160] [Batch 00815/00823] [00:09:56/00:00:05, 0.732s/it]: train_loss_raw=1.2640, running_loss=1.2938, LR=0.000100
[2025-08-26 11:22:07,045][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013168] [Batch 00823/00823] [00:10:07/00:00:00, 0.738s/it]: train_loss_raw=1.2560, running_loss=1.2939, LR=0.000100
[2025-08-26 11:22:07,410][__main__][INFO] - [VALIDATION] [Epoch 15/29] Starting validation.
[2025-08-26 11:22:18,336][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 013169] [Batch 00007/00013] [00:00:10/00:00:06, 1.366s/it]
[2025-08-26 11:22:25,519][__main__][INFO] - [VALIDATION] [Epoch 15/29] train_loss=1.29389, valid_loss=1.43497
[2025-08-26 11:22:25,519][__main__][INFO] - [VALIDATION] [Epoch 15/29] Metrics:
[2025-08-26 11:22:25,519][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_er      0.601
[2025-08-26 11:22:25,519][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_prec    0.069
[2025-08-26 11:22:25,519][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_recall  0.070
[2025-08-26 11:22:25,519][__main__][INFO] - [VALIDATION] [Epoch 15/29] - pep_recall 0.029
[2025-08-26 11:22:25,521][__main__][INFO] - [TRAIN] [Epoch 15/29] Epoch complete, total time 02:49:49, remaining time 02:28:35, 00:10:36 per epoch
[2025-08-26 11:22:31,776][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013176] [Batch 00008/00823] [00:00:06/00:10:15, 0.755s/it]: train_loss_raw=1.2603, running_loss=1.2843, LR=0.000100
[2025-08-26 11:22:37,658][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013184] [Batch 00016/00823] [00:00:11/00:10:01, 0.745s/it]: train_loss_raw=1.2065, running_loss=1.2799, LR=0.000100
[2025-08-26 11:22:43,395][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013192] [Batch 00024/00823] [00:00:17/00:09:47, 0.736s/it]: train_loss_raw=1.1725, running_loss=1.2777, LR=0.000100
[2025-08-26 11:22:49,145][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013200] [Batch 00032/00823] [00:00:23/00:09:38, 0.731s/it]: train_loss_raw=1.2668, running_loss=1.2746, LR=0.000100
[2025-08-26 11:22:54,918][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013208] [Batch 00040/00823] [00:00:29/00:09:31, 0.730s/it]: train_loss_raw=1.2416, running_loss=1.2727, LR=0.000100
[2025-08-26 11:23:00,833][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013216] [Batch 00048/00823] [00:00:35/00:09:26, 0.731s/it]: train_loss_raw=1.2977, running_loss=1.2707, LR=0.000100
[2025-08-26 11:23:06,588][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013224] [Batch 00056/00823] [00:00:40/00:09:19, 0.729s/it]: train_loss_raw=1.2135, running_loss=1.2677, LR=0.000100
[2025-08-26 11:23:12,420][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013232] [Batch 00064/00823] [00:00:46/00:09:13, 0.729s/it]: train_loss_raw=1.1953, running_loss=1.2632, LR=0.000100
[2025-08-26 11:23:18,170][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013240] [Batch 00072/00823] [00:00:52/00:09:06, 0.728s/it]: train_loss_raw=1.2401, running_loss=1.2620, LR=0.000100
[2025-08-26 11:23:23,975][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013248] [Batch 00080/00823] [00:00:58/00:09:00, 0.728s/it]: train_loss_raw=1.1687, running_loss=1.2605, LR=0.000100
[2025-08-26 11:23:29,829][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013256] [Batch 00088/00823] [00:01:04/00:08:55, 0.728s/it]: train_loss_raw=1.1645, running_loss=1.2594, LR=0.000100
[2025-08-26 11:23:35,831][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013264] [Batch 00096/00823] [00:01:10/00:08:50, 0.730s/it]: train_loss_raw=1.2229, running_loss=1.2584, LR=0.000100
[2025-08-26 11:23:41,723][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013272] [Batch 00104/00823] [00:01:15/00:08:45, 0.731s/it]: train_loss_raw=1.1966, running_loss=1.2592, LR=0.000100
[2025-08-26 11:23:47,776][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013280] [Batch 00112/00823] [00:01:22/00:08:40, 0.732s/it]: train_loss_raw=1.2821, running_loss=1.2596, LR=0.000100
[2025-08-26 11:23:53,832][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013288] [Batch 00120/00823] [00:01:28/00:08:36, 0.734s/it]: train_loss_raw=1.3060, running_loss=1.2587, LR=0.000100
[2025-08-26 11:23:59,699][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013296] [Batch 00128/00823] [00:01:33/00:08:30, 0.734s/it]: train_loss_raw=1.3260, running_loss=1.2577, LR=0.000100
[2025-08-26 11:24:05,606][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013304] [Batch 00136/00823] [00:01:39/00:08:24, 0.734s/it]: train_loss_raw=1.2439, running_loss=1.2590, LR=0.000100
[2025-08-26 11:24:11,440][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013312] [Batch 00144/00823] [00:01:45/00:08:18, 0.734s/it]: train_loss_raw=1.2541, running_loss=1.2570, LR=0.000100
[2025-08-26 11:24:17,178][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013320] [Batch 00152/00823] [00:01:51/00:08:11, 0.733s/it]: train_loss_raw=1.1676, running_loss=1.2555, LR=0.000100
[2025-08-26 11:24:22,968][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013328] [Batch 00160/00823] [00:01:57/00:08:05, 0.733s/it]: train_loss_raw=1.0756, running_loss=1.2526, LR=0.000100
[2025-08-26 11:24:28,852][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013336] [Batch 00168/00823] [00:02:03/00:08:00, 0.733s/it]: train_loss_raw=1.2356, running_loss=1.2523, LR=0.000100
[2025-08-26 11:24:34,850][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013344] [Batch 00176/00823] [00:02:09/00:07:54, 0.734s/it]: train_loss_raw=1.2308, running_loss=1.2526, LR=0.000100
[2025-08-26 11:24:40,604][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013352] [Batch 00184/00823] [00:02:14/00:07:48, 0.733s/it]: train_loss_raw=1.2496, running_loss=1.2541, LR=0.000100
[2025-08-26 11:24:46,545][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013360] [Batch 00192/00823] [00:02:20/00:07:42, 0.733s/it]: train_loss_raw=1.2767, running_loss=1.2540, LR=0.000100
[2025-08-26 11:24:52,440][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013368] [Batch 00200/00823] [00:02:26/00:07:36, 0.734s/it]: train_loss_raw=1.2287, running_loss=1.2529, LR=0.000100
[2025-08-26 11:24:58,204][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013376] [Batch 00208/00823] [00:02:32/00:07:30, 0.733s/it]: train_loss_raw=1.2706, running_loss=1.2534, LR=0.000100
[2025-08-26 11:25:04,006][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013384] [Batch 00216/00823] [00:02:38/00:07:24, 0.733s/it]: train_loss_raw=1.3144, running_loss=1.2545, LR=0.000100
[2025-08-26 11:25:10,007][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013392] [Batch 00224/00823] [00:02:44/00:07:19, 0.733s/it]: train_loss_raw=1.3339, running_loss=1.2538, LR=0.000100
[2025-08-26 11:25:15,832][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013400] [Batch 00232/00823] [00:02:50/00:07:13, 0.733s/it]: train_loss_raw=1.2639, running_loss=1.2539, LR=0.000100
[2025-08-26 11:25:21,868][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013408] [Batch 00240/00823] [00:02:56/00:07:07, 0.734s/it]: train_loss_raw=1.2069, running_loss=1.2556, LR=0.000100
[2025-08-26 11:25:27,661][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013416] [Batch 00248/00823] [00:03:01/00:07:01, 0.734s/it]: train_loss_raw=1.3464, running_loss=1.2583, LR=0.000100
[2025-08-26 11:25:33,612][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013424] [Batch 00256/00823] [00:03:07/00:06:56, 0.734s/it]: train_loss_raw=1.2612, running_loss=1.2583, LR=0.000100
[2025-08-26 11:25:39,654][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013432] [Batch 00264/00823] [00:03:13/00:06:50, 0.735s/it]: train_loss_raw=1.2533, running_loss=1.2570, LR=0.000100
[2025-08-26 11:25:45,376][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013440] [Batch 00272/00823] [00:03:19/00:06:44, 0.734s/it]: train_loss_raw=1.2205, running_loss=1.2586, LR=0.000100
[2025-08-26 11:25:51,305][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013448] [Batch 00280/00823] [00:03:25/00:06:38, 0.734s/it]: train_loss_raw=1.1849, running_loss=1.2561, LR=0.000100
[2025-08-26 11:25:57,304][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013456] [Batch 00288/00823] [00:03:31/00:06:33, 0.735s/it]: train_loss_raw=1.2740, running_loss=1.2540, LR=0.000100
[2025-08-26 11:26:03,220][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013464] [Batch 00296/00823] [00:03:37/00:06:27, 0.735s/it]: train_loss_raw=1.2440, running_loss=1.2542, LR=0.000100
[2025-08-26 11:26:09,146][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013472] [Batch 00304/00823] [00:03:43/00:06:21, 0.735s/it]: train_loss_raw=1.1865, running_loss=1.2543, LR=0.000100
[2025-08-26 11:26:15,052][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013480] [Batch 00312/00823] [00:03:49/00:06:15, 0.735s/it]: train_loss_raw=1.2053, running_loss=1.2535, LR=0.000100
[2025-08-26 11:26:20,929][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013488] [Batch 00320/00823] [00:03:55/00:06:09, 0.735s/it]: train_loss_raw=1.0276, running_loss=1.2480, LR=0.000100
[2025-08-26 11:26:26,883][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013496] [Batch 00328/00823] [00:04:01/00:06:03, 0.735s/it]: train_loss_raw=1.2855, running_loss=1.2467, LR=0.000100
[2025-08-26 11:26:32,715][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013504] [Batch 00336/00823] [00:04:06/00:05:57, 0.735s/it]: train_loss_raw=1.3421, running_loss=1.2488, LR=0.000100
[2025-08-26 11:26:38,539][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013512] [Batch 00344/00823] [00:04:12/00:05:52, 0.735s/it]: train_loss_raw=1.3064, running_loss=1.2504, LR=0.000100
[2025-08-26 11:26:44,289][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013520] [Batch 00352/00823] [00:04:18/00:05:45, 0.735s/it]: train_loss_raw=1.1960, running_loss=1.2504, LR=0.000100
[2025-08-26 11:26:50,133][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013528] [Batch 00360/00823] [00:04:24/00:05:40, 0.734s/it]: train_loss_raw=1.3719, running_loss=1.2523, LR=0.000100
[2025-08-26 11:26:55,979][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013536] [Batch 00368/00823] [00:04:30/00:05:34, 0.734s/it]: train_loss_raw=1.2258, running_loss=1.2508, LR=0.000100
[2025-08-26 11:27:01,834][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013544] [Batch 00376/00823] [00:04:36/00:05:28, 0.734s/it]: train_loss_raw=1.3079, running_loss=1.2514, LR=0.000100
[2025-08-26 11:27:07,673][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013552] [Batch 00384/00823] [00:04:41/00:05:22, 0.734s/it]: train_loss_raw=1.3054, running_loss=1.2519, LR=0.000100
[2025-08-26 11:27:13,546][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013560] [Batch 00392/00823] [00:04:47/00:05:16, 0.734s/it]: train_loss_raw=1.2594, running_loss=1.2521, LR=0.000100
[2025-08-26 11:27:19,396][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013568] [Batch 00400/00823] [00:04:53/00:05:10, 0.734s/it]: train_loss_raw=1.2304, running_loss=1.2537, LR=0.000100
[2025-08-26 11:27:25,250][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013576] [Batch 00408/00823] [00:04:59/00:05:04, 0.734s/it]: train_loss_raw=1.2602, running_loss=1.2500, LR=0.000100
[2025-08-26 11:27:31,198][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013584] [Batch 00416/00823] [00:05:05/00:04:58, 0.734s/it]: train_loss_raw=1.2686, running_loss=1.2512, LR=0.000100
[2025-08-26 11:27:37,032][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013592] [Batch 00424/00823] [00:05:11/00:04:52, 0.734s/it]: train_loss_raw=1.2675, running_loss=1.2509, LR=0.000100
[2025-08-26 11:27:42,967][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013600] [Batch 00432/00823] [00:05:17/00:04:47, 0.734s/it]: train_loss_raw=1.1586, running_loss=1.2493, LR=0.000100
[2025-08-26 11:27:48,759][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013608] [Batch 00440/00823] [00:05:23/00:04:41, 0.734s/it]: train_loss_raw=1.2126, running_loss=1.2491, LR=0.000100
[2025-08-26 11:27:54,580][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013616] [Batch 00448/00823] [00:05:28/00:04:35, 0.734s/it]: train_loss_raw=1.2844, running_loss=1.2488, LR=0.000100
[2025-08-26 11:28:00,649][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013624] [Batch 00456/00823] [00:05:34/00:04:29, 0.734s/it]: train_loss_raw=1.1705, running_loss=1.2468, LR=0.000100
[2025-08-26 11:28:06,767][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013632] [Batch 00464/00823] [00:05:41/00:04:23, 0.735s/it]: train_loss_raw=1.2710, running_loss=1.2461, LR=0.000100
[2025-08-26 11:28:12,833][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013640] [Batch 00472/00823] [00:05:47/00:04:18, 0.735s/it]: train_loss_raw=1.3094, running_loss=1.2462, LR=0.000100
[2025-08-26 11:28:18,781][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013648] [Batch 00480/00823] [00:05:53/00:04:12, 0.736s/it]: train_loss_raw=1.1935, running_loss=1.2431, LR=0.000100
[2025-08-26 11:28:24,612][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013656] [Batch 00488/00823] [00:05:58/00:04:06, 0.735s/it]: train_loss_raw=1.2583, running_loss=1.2436, LR=0.000100
[2025-08-26 11:28:30,400][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013664] [Batch 00496/00823] [00:06:04/00:04:00, 0.735s/it]: train_loss_raw=1.2315, running_loss=1.2423, LR=0.000100
[2025-08-26 11:28:36,242][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013672] [Batch 00504/00823] [00:06:10/00:03:54, 0.735s/it]: train_loss_raw=1.2934, running_loss=1.2419, LR=0.000100
[2025-08-26 11:28:42,192][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013680] [Batch 00512/00823] [00:06:16/00:03:48, 0.735s/it]: train_loss_raw=1.2669, running_loss=1.2417, LR=0.000100
[2025-08-26 11:28:47,999][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013688] [Batch 00520/00823] [00:06:22/00:03:42, 0.735s/it]: train_loss_raw=1.2352, running_loss=1.2409, LR=0.000100
[2025-08-26 11:28:53,903][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013696] [Batch 00528/00823] [00:06:28/00:03:36, 0.735s/it]: train_loss_raw=1.1916, running_loss=1.2405, LR=0.000100
[2025-08-26 11:28:59,811][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013704] [Batch 00536/00823] [00:06:34/00:03:31, 0.735s/it]: train_loss_raw=1.2256, running_loss=1.2410, LR=0.000100
[2025-08-26 11:29:05,877][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013712] [Batch 00544/00823] [00:06:40/00:03:25, 0.736s/it]: train_loss_raw=1.2604, running_loss=1.2432, LR=0.000100
[2025-08-26 11:29:11,668][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013720] [Batch 00552/00823] [00:06:45/00:03:19, 0.735s/it]: train_loss_raw=1.3414, running_loss=1.2445, LR=0.000100
[2025-08-26 11:29:17,447][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013728] [Batch 00560/00823] [00:06:51/00:03:13, 0.735s/it]: train_loss_raw=1.2300, running_loss=1.2459, LR=0.000100
[2025-08-26 11:29:23,194][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013736] [Batch 00568/00823] [00:06:57/00:03:07, 0.735s/it]: train_loss_raw=1.1819, running_loss=1.2470, LR=0.000100
[2025-08-26 11:29:28,991][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013744] [Batch 00576/00823] [00:07:03/00:03:01, 0.735s/it]: train_loss_raw=1.2804, running_loss=1.2459, LR=0.000100
[2025-08-26 11:29:34,799][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013752] [Batch 00584/00823] [00:07:09/00:02:55, 0.735s/it]: train_loss_raw=1.2371, running_loss=1.2464, LR=0.000100
[2025-08-26 11:29:40,846][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013760] [Batch 00592/00823] [00:07:15/00:02:49, 0.735s/it]: train_loss_raw=1.2636, running_loss=1.2474, LR=0.000100
[2025-08-26 11:29:46,901][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013768] [Batch 00600/00823] [00:07:21/00:02:43, 0.735s/it]: train_loss_raw=1.2271, running_loss=1.2461, LR=0.000100
[2025-08-26 11:29:52,732][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013776] [Batch 00608/00823] [00:07:26/00:02:38, 0.735s/it]: train_loss_raw=1.2386, running_loss=1.2465, LR=0.000100
[2025-08-26 11:29:58,708][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013784] [Batch 00616/00823] [00:07:32/00:02:32, 0.735s/it]: train_loss_raw=1.2796, running_loss=1.2457, LR=0.000100
[2025-08-26 11:30:04,496][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013792] [Batch 00624/00823] [00:07:38/00:02:26, 0.735s/it]: train_loss_raw=1.2601, running_loss=1.2457, LR=0.000100
[2025-08-26 11:30:10,271][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013800] [Batch 00632/00823] [00:07:44/00:02:20, 0.735s/it]: train_loss_raw=1.1484, running_loss=1.2475, LR=0.000100
[2025-08-26 11:30:16,096][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013808] [Batch 00640/00823] [00:07:50/00:02:14, 0.735s/it]: train_loss_raw=1.3123, running_loss=1.2497, LR=0.000100
[2025-08-26 11:30:21,778][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013816] [Batch 00648/00823] [00:07:56/00:02:08, 0.735s/it]: train_loss_raw=1.2588, running_loss=1.2505, LR=0.000100
[2025-08-26 11:30:27,414][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013824] [Batch 00656/00823] [00:08:01/00:02:02, 0.734s/it]: train_loss_raw=1.2382, running_loss=1.2503, LR=0.000100
[2025-08-26 11:30:33,085][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013832] [Batch 00664/00823] [00:08:07/00:01:56, 0.734s/it]: train_loss_raw=1.2026, running_loss=1.2490, LR=0.000100
[2025-08-26 11:30:38,929][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013840] [Batch 00672/00823] [00:08:13/00:01:50, 0.734s/it]: train_loss_raw=1.2956, running_loss=1.2498, LR=0.000100
[2025-08-26 11:30:44,881][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013848] [Batch 00680/00823] [00:08:19/00:01:44, 0.734s/it]: train_loss_raw=1.2782, running_loss=1.2486, LR=0.000100
[2025-08-26 11:30:50,632][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013856] [Batch 00688/00823] [00:08:24/00:01:39, 0.734s/it]: train_loss_raw=1.2184, running_loss=1.2473, LR=0.000100
[2025-08-26 11:30:56,372][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013864] [Batch 00696/00823] [00:08:30/00:01:33, 0.734s/it]: train_loss_raw=1.2400, running_loss=1.2490, LR=0.000100
[2025-08-26 11:31:01,896][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013872] [Batch 00704/00823] [00:08:36/00:01:27, 0.733s/it]: train_loss_raw=1.1600, running_loss=1.2486, LR=0.000100
[2025-08-26 11:31:07,434][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013880] [Batch 00712/00823] [00:08:41/00:01:21, 0.733s/it]: train_loss_raw=1.2091, running_loss=1.2489, LR=0.000100
[2025-08-26 11:31:12,957][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013888] [Batch 00720/00823] [00:08:47/00:01:15, 0.732s/it]: train_loss_raw=1.1508, running_loss=1.2463, LR=0.000100
[2025-08-26 11:31:18,623][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013896] [Batch 00728/00823] [00:08:52/00:01:09, 0.732s/it]: train_loss_raw=1.1798, running_loss=1.2457, LR=0.000100
[2025-08-26 11:31:24,285][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013904] [Batch 00736/00823] [00:08:58/00:01:03, 0.732s/it]: train_loss_raw=1.1923, running_loss=1.2429, LR=0.000100
[2025-08-26 11:31:30,111][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013912] [Batch 00744/00823] [00:09:04/00:00:57, 0.732s/it]: train_loss_raw=1.2201, running_loss=1.2433, LR=0.000100
[2025-08-26 11:31:36,072][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013920] [Batch 00752/00823] [00:09:10/00:00:51, 0.732s/it]: train_loss_raw=1.0911, running_loss=1.2423, LR=0.000100
[2025-08-26 11:31:41,844][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013928] [Batch 00760/00823] [00:09:16/00:00:46, 0.732s/it]: train_loss_raw=1.0124, running_loss=1.2413, LR=0.000100
[2025-08-26 11:31:47,559][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013936] [Batch 00768/00823] [00:09:21/00:00:40, 0.732s/it]: train_loss_raw=1.1749, running_loss=1.2413, LR=0.000100
[2025-08-26 11:31:53,431][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013944] [Batch 00776/00823] [00:09:27/00:00:34, 0.732s/it]: train_loss_raw=1.2382, running_loss=1.2412, LR=0.000100
[2025-08-26 11:31:59,231][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013952] [Batch 00784/00823] [00:09:33/00:00:28, 0.731s/it]: train_loss_raw=1.2376, running_loss=1.2423, LR=0.000100
[2025-08-26 11:32:05,146][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013960] [Batch 00792/00823] [00:09:39/00:00:22, 0.732s/it]: train_loss_raw=1.2935, running_loss=1.2416, LR=0.000100
[2025-08-26 11:32:11,090][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013968] [Batch 00800/00823] [00:09:45/00:00:16, 0.732s/it]: train_loss_raw=1.2064, running_loss=1.2395, LR=0.000100
[2025-08-26 11:32:17,030][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013976] [Batch 00808/00823] [00:09:51/00:00:10, 0.732s/it]: train_loss_raw=1.2676, running_loss=1.2402, LR=0.000100
[2025-08-26 11:32:22,845][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013984] [Batch 00816/00823] [00:09:57/00:00:05, 0.732s/it]: train_loss_raw=1.2661, running_loss=1.2403, LR=0.000100
[2025-08-26 11:32:28,224][__main__][INFO] - [VALIDATION] [Epoch 16/29] Starting validation.
[2025-08-26 11:32:39,545][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 013992] [Batch 00007/00013] [00:00:11/00:00:07, 1.415s/it]
[2025-08-26 11:32:46,798][__main__][INFO] - [VALIDATION] [Epoch 16/29] train_loss=1.23954, valid_loss=1.41586
[2025-08-26 11:32:46,798][__main__][INFO] - [VALIDATION] [Epoch 16/29] Metrics:
[2025-08-26 11:32:46,798][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_er      0.608
[2025-08-26 11:32:46,798][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_prec    0.066
[2025-08-26 11:32:46,798][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_recall  0.067
[2025-08-26 11:32:46,798][__main__][INFO] - [VALIDATION] [Epoch 16/29] - pep_recall 0.025
[2025-08-26 11:32:46,800][__main__][INFO] - [TRAIN] [Epoch 16/29] Epoch complete, total time 03:00:10, remaining time 02:17:46, 00:10:35 per epoch
[2025-08-26 11:32:47,163][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 013992] [Batch 00001/00823] [00:00:00/00:02:01, 0.147s/it]: train_loss_raw=1.2637, running_loss=1.2637, LR=0.000100
[2025-08-26 11:32:53,116][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014000] [Batch 00009/00823] [00:00:06/00:09:11, 0.678s/it]: train_loss_raw=1.2580, running_loss=1.2604, LR=0.000100
[2025-08-26 11:33:02,511][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014008] [Batch 00017/00823] [00:00:15/00:12:14, 0.912s/it]: train_loss_raw=1.2733, running_loss=1.2603, LR=0.000100
[2025-08-26 11:33:08,282][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014016] [Batch 00025/00823] [00:00:21/00:11:18, 0.851s/it]: train_loss_raw=1.1953, running_loss=1.2582, LR=0.000100
[2025-08-26 11:33:14,053][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014024] [Batch 00033/00823] [00:00:27/00:10:47, 0.819s/it]: train_loss_raw=1.1994, running_loss=1.2564, LR=0.000100
[2025-08-26 11:33:19,920][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014032] [Batch 00041/00823] [00:00:32/00:10:27, 0.803s/it]: train_loss_raw=1.2304, running_loss=1.2544, LR=0.000100
[2025-08-26 11:33:25,882][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014040] [Batch 00049/00823] [00:00:38/00:10:13, 0.793s/it]: train_loss_raw=1.2314, running_loss=1.2502, LR=0.000100
[2025-08-26 11:33:31,637][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014048] [Batch 00057/00823] [00:00:44/00:09:59, 0.783s/it]: train_loss_raw=1.1776, running_loss=1.2493, LR=0.000100
[2025-08-26 11:33:37,596][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014056] [Batch 00065/00823] [00:00:50/00:09:49, 0.778s/it]: train_loss_raw=1.1885, running_loss=1.2451, LR=0.000100
[2025-08-26 11:33:43,506][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014064] [Batch 00073/00823] [00:00:56/00:09:40, 0.774s/it]: train_loss_raw=1.1238, running_loss=1.2425, LR=0.000100
[2025-08-26 11:33:49,479][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014072] [Batch 00081/00823] [00:01:02/00:09:32, 0.771s/it]: train_loss_raw=1.2775, running_loss=1.2402, LR=0.000100
[2025-08-26 11:33:55,236][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014080] [Batch 00089/00823] [00:01:08/00:09:22, 0.767s/it]: train_loss_raw=1.1859, running_loss=1.2390, LR=0.000100
[2025-08-26 11:34:00,940][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014088] [Batch 00097/00823] [00:01:13/00:09:13, 0.762s/it]: train_loss_raw=1.2761, running_loss=1.2353, LR=0.000100
[2025-08-26 11:34:06,971][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014096] [Batch 00105/00823] [00:01:19/00:09:06, 0.761s/it]: train_loss_raw=1.2822, running_loss=1.2366, LR=0.000100
[2025-08-26 11:34:12,772][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014104] [Batch 00113/00823] [00:01:25/00:08:58, 0.759s/it]: train_loss_raw=1.2851, running_loss=1.2361, LR=0.000100
[2025-08-26 11:34:18,648][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014112] [Batch 00121/00823] [00:01:31/00:08:51, 0.757s/it]: train_loss_raw=1.1529, running_loss=1.2316, LR=0.000100
[2025-08-26 11:34:24,458][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014120] [Batch 00129/00823] [00:01:37/00:08:44, 0.755s/it]: train_loss_raw=1.2373, running_loss=1.2342, LR=0.000100
[2025-08-26 11:34:30,314][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014128] [Batch 00137/00823] [00:01:43/00:08:37, 0.754s/it]: train_loss_raw=1.3009, running_loss=1.2333, LR=0.000100
[2025-08-26 11:34:36,399][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014136] [Batch 00145/00823] [00:01:49/00:08:31, 0.754s/it]: train_loss_raw=1.2347, running_loss=1.2352, LR=0.000100
[2025-08-26 11:34:42,319][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014144] [Batch 00153/00823] [00:01:55/00:08:24, 0.754s/it]: train_loss_raw=1.3293, running_loss=1.2349, LR=0.000100
[2025-08-26 11:34:48,193][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014152] [Batch 00161/00823] [00:02:01/00:08:18, 0.753s/it]: train_loss_raw=1.2475, running_loss=1.2343, LR=0.000100
[2025-08-26 11:34:54,105][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014160] [Batch 00169/00823] [00:02:07/00:08:11, 0.752s/it]: train_loss_raw=1.2728, running_loss=1.2333, LR=0.000100
[2025-08-26 11:34:59,903][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014168] [Batch 00177/00823] [00:02:12/00:08:05, 0.751s/it]: train_loss_raw=1.2721, running_loss=1.2369, LR=0.000100
[2025-08-26 11:35:05,817][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014176] [Batch 00185/00823] [00:02:18/00:07:58, 0.750s/it]: train_loss_raw=1.3206, running_loss=1.2399, LR=0.000100
[2025-08-26 11:35:11,823][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014184] [Batch 00193/00823] [00:02:24/00:07:52, 0.750s/it]: train_loss_raw=1.2015, running_loss=1.2376, LR=0.000100
[2025-08-26 11:35:17,827][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014192] [Batch 00201/00823] [00:02:30/00:07:46, 0.750s/it]: train_loss_raw=1.2721, running_loss=1.2372, LR=0.000100
[2025-08-26 11:35:23,765][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014200] [Batch 00209/00823] [00:02:36/00:07:40, 0.750s/it]: train_loss_raw=1.3145, running_loss=1.2412, LR=0.000100
[2025-08-26 11:35:29,632][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014208] [Batch 00217/00823] [00:02:42/00:07:34, 0.749s/it]: train_loss_raw=1.1622, running_loss=1.2391, LR=0.000100
[2025-08-26 11:35:35,774][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014216] [Batch 00225/00823] [00:02:48/00:07:28, 0.750s/it]: train_loss_raw=1.1334, running_loss=1.2385, LR=0.000100
[2025-08-26 11:35:41,762][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014224] [Batch 00233/00823] [00:02:54/00:07:22, 0.750s/it]: train_loss_raw=1.2137, running_loss=1.2377, LR=0.000100
[2025-08-26 11:35:47,607][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014232] [Batch 00241/00823] [00:03:00/00:07:16, 0.749s/it]: train_loss_raw=1.2353, running_loss=1.2375, LR=0.000100
[2025-08-26 11:35:53,606][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014240] [Batch 00249/00823] [00:03:06/00:07:10, 0.749s/it]: train_loss_raw=1.2611, running_loss=1.2392, LR=0.000100
[2025-08-26 11:35:59,625][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014248] [Batch 00257/00823] [00:03:12/00:07:04, 0.749s/it]: train_loss_raw=1.2309, running_loss=1.2396, LR=0.000100
[2025-08-26 11:36:05,597][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014256] [Batch 00265/00823] [00:03:18/00:06:58, 0.749s/it]: train_loss_raw=1.2817, running_loss=1.2404, LR=0.000100
[2025-08-26 11:36:11,591][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014264] [Batch 00273/00823] [00:03:24/00:06:52, 0.749s/it]: train_loss_raw=1.1829, running_loss=1.2417, LR=0.000100
[2025-08-26 11:36:17,405][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014272] [Batch 00281/00823] [00:03:30/00:06:45, 0.749s/it]: train_loss_raw=1.2811, running_loss=1.2424, LR=0.000100
[2025-08-26 11:36:23,427][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014280] [Batch 00289/00823] [00:03:36/00:06:39, 0.749s/it]: train_loss_raw=1.2660, running_loss=1.2409, LR=0.000100
[2025-08-26 11:36:29,311][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014288] [Batch 00297/00823] [00:03:42/00:06:33, 0.748s/it]: train_loss_raw=1.1854, running_loss=1.2391, LR=0.000100
[2025-08-26 11:36:34,948][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014296] [Batch 00305/00823] [00:03:47/00:06:27, 0.747s/it]: train_loss_raw=1.2954, running_loss=1.2419, LR=0.000100
[2025-08-26 11:36:40,749][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014304] [Batch 00313/00823] [00:03:53/00:06:20, 0.747s/it]: train_loss_raw=1.2769, running_loss=1.2436, LR=0.000100
[2025-08-26 11:36:46,531][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014312] [Batch 00321/00823] [00:03:59/00:06:14, 0.746s/it]: train_loss_raw=1.2312, running_loss=1.2422, LR=0.000100
[2025-08-26 11:36:52,254][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014320] [Batch 00329/00823] [00:04:05/00:06:08, 0.745s/it]: train_loss_raw=1.2728, running_loss=1.2418, LR=0.000100
[2025-08-26 11:36:58,031][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014328] [Batch 00337/00823] [00:04:11/00:06:01, 0.745s/it]: train_loss_raw=1.2060, running_loss=1.2414, LR=0.000100
[2025-08-26 11:37:03,790][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014336] [Batch 00345/00823] [00:04:16/00:05:55, 0.744s/it]: train_loss_raw=1.2158, running_loss=1.2413, LR=0.000100
[2025-08-26 11:37:09,728][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014344] [Batch 00353/00823] [00:04:22/00:05:49, 0.744s/it]: train_loss_raw=1.3027, running_loss=1.2422, LR=0.000100
[2025-08-26 11:37:15,697][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014352] [Batch 00361/00823] [00:04:28/00:05:43, 0.744s/it]: train_loss_raw=1.2667, running_loss=1.2412, LR=0.000100
[2025-08-26 11:37:21,541][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014360] [Batch 00369/00823] [00:04:34/00:05:37, 0.744s/it]: train_loss_raw=1.1766, running_loss=1.2388, LR=0.000100
[2025-08-26 11:37:27,340][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014368] [Batch 00377/00823] [00:04:40/00:05:31, 0.744s/it]: train_loss_raw=1.1667, running_loss=1.2391, LR=0.000100
[2025-08-26 11:37:33,119][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014376] [Batch 00385/00823] [00:04:46/00:05:25, 0.743s/it]: train_loss_raw=1.1778, running_loss=1.2353, LR=0.000100
[2025-08-26 11:37:39,140][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014384] [Batch 00393/00823] [00:04:52/00:05:19, 0.743s/it]: train_loss_raw=1.1929, running_loss=1.2339, LR=0.000100
[2025-08-26 11:37:45,187][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014392] [Batch 00401/00823] [00:04:58/00:05:13, 0.744s/it]: train_loss_raw=1.3318, running_loss=1.2328, LR=0.000100
[2025-08-26 11:37:51,062][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014400] [Batch 00409/00823] [00:05:04/00:05:07, 0.743s/it]: train_loss_raw=1.1900, running_loss=1.2329, LR=0.000100
[2025-08-26 11:37:56,945][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014408] [Batch 00417/00823] [00:05:09/00:05:01, 0.743s/it]: train_loss_raw=1.2290, running_loss=1.2355, LR=0.000100
[2025-08-26 11:38:02,867][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014416] [Batch 00425/00823] [00:05:15/00:04:55, 0.743s/it]: train_loss_raw=1.2266, running_loss=1.2355, LR=0.000100
[2025-08-26 11:38:08,769][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014424] [Batch 00433/00823] [00:05:21/00:04:49, 0.743s/it]: train_loss_raw=1.2404, running_loss=1.2356, LR=0.000100
[2025-08-26 11:38:14,590][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014432] [Batch 00441/00823] [00:05:27/00:04:43, 0.743s/it]: train_loss_raw=1.2058, running_loss=1.2354, LR=0.000100
[2025-08-26 11:38:20,363][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014440] [Batch 00449/00823] [00:05:33/00:04:37, 0.742s/it]: train_loss_raw=1.2035, running_loss=1.2343, LR=0.000100
[2025-08-26 11:38:26,213][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014448] [Batch 00457/00823] [00:05:39/00:04:31, 0.742s/it]: train_loss_raw=1.0934, running_loss=1.2332, LR=0.000100
[2025-08-26 11:38:31,937][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014456] [Batch 00465/00823] [00:05:44/00:04:25, 0.742s/it]: train_loss_raw=1.2048, running_loss=1.2327, LR=0.000100
[2025-08-26 11:38:37,704][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014464] [Batch 00473/00823] [00:05:50/00:04:19, 0.741s/it]: train_loss_raw=1.2364, running_loss=1.2337, LR=0.000100
[2025-08-26 11:38:43,531][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014472] [Batch 00481/00823] [00:05:56/00:04:13, 0.741s/it]: train_loss_raw=1.2349, running_loss=1.2321, LR=0.000100
[2025-08-26 11:38:49,371][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014480] [Batch 00489/00823] [00:06:02/00:04:07, 0.741s/it]: train_loss_raw=1.1989, running_loss=1.2316, LR=0.000100
[2025-08-26 11:38:55,185][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014488] [Batch 00497/00823] [00:06:08/00:04:01, 0.741s/it]: train_loss_raw=1.2006, running_loss=1.2307, LR=0.000100
[2025-08-26 11:39:01,038][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014496] [Batch 00505/00823] [00:06:14/00:03:55, 0.741s/it]: train_loss_raw=1.2522, running_loss=1.2336, LR=0.000100
[2025-08-26 11:39:06,854][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014504] [Batch 00513/00823] [00:06:19/00:03:49, 0.740s/it]: train_loss_raw=1.2709, running_loss=1.2314, LR=0.000100
[2025-08-26 11:39:12,386][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014512] [Batch 00521/00823] [00:06:25/00:03:43, 0.740s/it]: train_loss_raw=1.1864, running_loss=1.2303, LR=0.000100
[2025-08-26 11:39:18,172][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014520] [Batch 00529/00823] [00:06:31/00:03:37, 0.739s/it]: train_loss_raw=1.2163, running_loss=1.2322, LR=0.000100
[2025-08-26 11:39:24,100][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014528] [Batch 00537/00823] [00:06:37/00:03:31, 0.739s/it]: train_loss_raw=1.2150, running_loss=1.2320, LR=0.000100
[2025-08-26 11:39:30,057][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014536] [Batch 00545/00823] [00:06:43/00:03:25, 0.740s/it]: train_loss_raw=1.2210, running_loss=1.2302, LR=0.000100
[2025-08-26 11:39:35,998][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014544] [Batch 00553/00823] [00:06:48/00:03:19, 0.740s/it]: train_loss_raw=1.1595, running_loss=1.2305, LR=0.000100
[2025-08-26 11:39:41,938][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014552] [Batch 00561/00823] [00:06:54/00:03:13, 0.740s/it]: train_loss_raw=1.2429, running_loss=1.2287, LR=0.000100
[2025-08-26 11:39:47,657][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014560] [Batch 00569/00823] [00:07:00/00:03:07, 0.739s/it]: train_loss_raw=1.2144, running_loss=1.2283, LR=0.000100
[2025-08-26 11:39:53,431][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014568] [Batch 00577/00823] [00:07:06/00:03:01, 0.739s/it]: train_loss_raw=1.1403, running_loss=1.2281, LR=0.000100
[2025-08-26 11:39:59,281][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014576] [Batch 00585/00823] [00:07:12/00:02:55, 0.739s/it]: train_loss_raw=1.2581, running_loss=1.2292, LR=0.000100
[2025-08-26 11:40:05,036][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014584] [Batch 00593/00823] [00:07:18/00:02:49, 0.739s/it]: train_loss_raw=1.2184, running_loss=1.2298, LR=0.000100
[2025-08-26 11:40:10,882][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014592] [Batch 00601/00823] [00:07:23/00:02:43, 0.739s/it]: train_loss_raw=1.2253, running_loss=1.2269, LR=0.000100
[2025-08-26 11:40:16,623][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014600] [Batch 00609/00823] [00:07:29/00:02:37, 0.738s/it]: train_loss_raw=1.3032, running_loss=1.2296, LR=0.000100
[2025-08-26 11:40:22,486][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014608] [Batch 00617/00823] [00:07:35/00:02:32, 0.738s/it]: train_loss_raw=1.2155, running_loss=1.2291, LR=0.000100
[2025-08-26 11:40:28,207][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014616] [Batch 00625/00823] [00:07:41/00:02:26, 0.738s/it]: train_loss_raw=1.2494, running_loss=1.2276, LR=0.000100
[2025-08-26 11:40:33,985][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014624] [Batch 00633/00823] [00:07:46/00:02:20, 0.738s/it]: train_loss_raw=1.1782, running_loss=1.2273, LR=0.000100
[2025-08-26 11:40:39,763][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014632] [Batch 00641/00823] [00:07:52/00:02:14, 0.738s/it]: train_loss_raw=1.1492, running_loss=1.2278, LR=0.000100
[2025-08-26 11:40:45,543][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014640] [Batch 00649/00823] [00:07:58/00:02:08, 0.737s/it]: train_loss_raw=1.2088, running_loss=1.2254, LR=0.000100
[2025-08-26 11:40:51,300][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014648] [Batch 00657/00823] [00:08:04/00:02:02, 0.737s/it]: train_loss_raw=1.0831, running_loss=1.2218, LR=0.000100
[2025-08-26 11:40:57,102][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014656] [Batch 00665/00823] [00:08:10/00:01:56, 0.737s/it]: train_loss_raw=1.2303, running_loss=1.2232, LR=0.000100
[2025-08-26 11:41:03,162][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014664] [Batch 00673/00823] [00:08:16/00:01:50, 0.737s/it]: train_loss_raw=1.3502, running_loss=1.2212, LR=0.000100
[2025-08-26 11:41:09,049][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014672] [Batch 00681/00823] [00:08:22/00:01:44, 0.737s/it]: train_loss_raw=1.2135, running_loss=1.2209, LR=0.000100
[2025-08-26 11:41:14,890][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014680] [Batch 00689/00823] [00:08:27/00:01:38, 0.737s/it]: train_loss_raw=1.1953, running_loss=1.2217, LR=0.000100
[2025-08-26 11:41:20,725][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014688] [Batch 00697/00823] [00:08:33/00:01:32, 0.737s/it]: train_loss_raw=1.2985, running_loss=1.2264, LR=0.000100
[2025-08-26 11:41:26,530][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014696] [Batch 00705/00823] [00:08:39/00:01:26, 0.737s/it]: train_loss_raw=1.2290, running_loss=1.2276, LR=0.000100
[2025-08-26 11:41:32,391][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014704] [Batch 00713/00823] [00:08:45/00:01:21, 0.737s/it]: train_loss_raw=1.1545, running_loss=1.2242, LR=0.000100
[2025-08-26 11:41:38,138][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014712] [Batch 00721/00823] [00:08:51/00:01:15, 0.737s/it]: train_loss_raw=1.1030, running_loss=1.2187, LR=0.000100
[2025-08-26 11:41:43,949][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014720] [Batch 00729/00823] [00:08:56/00:01:09, 0.737s/it]: train_loss_raw=1.2105, running_loss=1.2179, LR=0.000100
[2025-08-26 11:41:49,919][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014728] [Batch 00737/00823] [00:09:02/00:01:03, 0.737s/it]: train_loss_raw=1.1855, running_loss=1.2202, LR=0.000100
[2025-08-26 11:41:55,850][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014736] [Batch 00745/00823] [00:09:08/00:00:57, 0.737s/it]: train_loss_raw=1.2210, running_loss=1.2207, LR=0.000100
[2025-08-26 11:42:01,640][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014744] [Batch 00753/00823] [00:09:14/00:00:51, 0.737s/it]: train_loss_raw=1.2466, running_loss=1.2206, LR=0.000100
[2025-08-26 11:42:07,511][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014752] [Batch 00761/00823] [00:09:20/00:00:45, 0.737s/it]: train_loss_raw=1.2910, running_loss=1.2202, LR=0.000100
[2025-08-26 11:42:13,227][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014760] [Batch 00769/00823] [00:09:26/00:00:39, 0.736s/it]: train_loss_raw=1.1743, running_loss=1.2201, LR=0.000100
[2025-08-26 11:42:18,931][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014768] [Batch 00777/00823] [00:09:31/00:00:33, 0.736s/it]: train_loss_raw=1.1722, running_loss=1.2205, LR=0.000100
[2025-08-26 11:42:24,741][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014776] [Batch 00785/00823] [00:09:37/00:00:27, 0.736s/it]: train_loss_raw=1.2224, running_loss=1.2198, LR=0.000100
[2025-08-26 11:42:30,534][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014784] [Batch 00793/00823] [00:09:43/00:00:22, 0.736s/it]: train_loss_raw=1.2703, running_loss=1.2200, LR=0.000100
[2025-08-26 11:42:36,287][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014792] [Batch 00801/00823] [00:09:49/00:00:16, 0.736s/it]: train_loss_raw=1.2851, running_loss=1.2186, LR=0.000100
[2025-08-26 11:42:42,079][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014800] [Batch 00809/00823] [00:09:55/00:00:10, 0.736s/it]: train_loss_raw=1.2051, running_loss=1.2196, LR=0.000100
[2025-08-26 11:42:47,851][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014808] [Batch 00817/00823] [00:10:00/00:00:04, 0.735s/it]: train_loss_raw=1.1928, running_loss=1.2192, LR=0.000100
[2025-08-26 11:42:58,042][__main__][INFO] - [VALIDATION] [Epoch 17/29] Starting validation.
[2025-08-26 11:43:09,933][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 014815] [Batch 00007/00013] [00:00:11/00:00:07, 1.486s/it]
[2025-08-26 11:43:17,391][__main__][INFO] - [VALIDATION] [Epoch 17/29] train_loss=1.21960, valid_loss=1.41018
[2025-08-26 11:43:17,391][__main__][INFO] - [VALIDATION] [Epoch 17/29] Metrics:
[2025-08-26 11:43:17,392][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_er      0.590
[2025-08-26 11:43:17,392][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_prec    0.073
[2025-08-26 11:43:17,392][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_recall  0.075
[2025-08-26 11:43:17,392][__main__][INFO] - [VALIDATION] [Epoch 17/29] - pep_recall 0.032
[2025-08-26 11:43:17,394][__main__][INFO] - [TRAIN] [Epoch 17/29] Epoch complete, total time 03:10:41, remaining time 02:07:07, 00:10:35 per epoch
[2025-08-26 11:43:18,571][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014816] [Batch 00002/00823] [00:00:00/00:06:18, 0.462s/it]: train_loss_raw=1.2264, running_loss=1.1843, LR=0.000100
[2025-08-26 11:43:24,756][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014824] [Batch 00010/00823] [00:00:07/00:09:37, 0.711s/it]: train_loss_raw=1.1851, running_loss=1.1841, LR=0.000100
[2025-08-26 11:43:30,896][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014832] [Batch 00018/00823] [00:00:13/00:09:52, 0.736s/it]: train_loss_raw=1.0980, running_loss=1.1832, LR=0.000100
[2025-08-26 11:43:36,692][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014840] [Batch 00026/00823] [00:00:19/00:09:43, 0.732s/it]: train_loss_raw=1.0623, running_loss=1.1790, LR=0.000100
[2025-08-26 11:43:42,412][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014848] [Batch 00034/00823] [00:00:24/00:09:34, 0.728s/it]: train_loss_raw=1.2384, running_loss=1.1776, LR=0.000100
[2025-08-26 11:43:48,226][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014856] [Batch 00042/00823] [00:00:30/00:09:28, 0.728s/it]: train_loss_raw=1.2023, running_loss=1.1797, LR=0.000100
[2025-08-26 11:43:53,994][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014864] [Batch 00050/00823] [00:00:36/00:09:21, 0.727s/it]: train_loss_raw=1.1713, running_loss=1.1794, LR=0.000100
[2025-08-26 11:43:59,874][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014872] [Batch 00058/00823] [00:00:42/00:09:16, 0.728s/it]: train_loss_raw=1.2324, running_loss=1.1780, LR=0.000100
[2025-08-26 11:44:05,649][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014880] [Batch 00066/00823] [00:00:48/00:09:10, 0.727s/it]: train_loss_raw=1.1518, running_loss=1.1762, LR=0.000100
[2025-08-26 11:44:11,532][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014888] [Batch 00074/00823] [00:00:53/00:09:05, 0.728s/it]: train_loss_raw=1.2491, running_loss=1.1765, LR=0.000100
[2025-08-26 11:44:17,289][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014896] [Batch 00082/00823] [00:00:59/00:08:58, 0.727s/it]: train_loss_raw=1.2271, running_loss=1.1769, LR=0.000100
[2025-08-26 11:44:23,133][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014904] [Batch 00090/00823] [00:01:05/00:08:53, 0.728s/it]: train_loss_raw=1.1054, running_loss=1.1768, LR=0.000100
[2025-08-26 11:44:28,994][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014912] [Batch 00098/00823] [00:01:11/00:08:47, 0.728s/it]: train_loss_raw=1.2450, running_loss=1.1787, LR=0.000100
[2025-08-26 11:44:34,904][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014920] [Batch 00106/00823] [00:01:17/00:08:42, 0.729s/it]: train_loss_raw=1.1445, running_loss=1.1787, LR=0.000100
[2025-08-26 11:44:40,724][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014928] [Batch 00114/00823] [00:01:23/00:08:36, 0.729s/it]: train_loss_raw=1.1445, running_loss=1.1784, LR=0.000100
[2025-08-26 11:44:46,490][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014936] [Batch 00122/00823] [00:01:28/00:08:30, 0.728s/it]: train_loss_raw=1.1206, running_loss=1.1764, LR=0.000100
[2025-08-26 11:44:52,473][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014944] [Batch 00130/00823] [00:01:34/00:08:25, 0.729s/it]: train_loss_raw=1.1849, running_loss=1.1786, LR=0.000100
[2025-08-26 11:44:58,296][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014952] [Batch 00138/00823] [00:01:40/00:08:19, 0.729s/it]: train_loss_raw=1.0826, running_loss=1.1773, LR=0.000100
[2025-08-26 11:45:04,095][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014960] [Batch 00146/00823] [00:01:46/00:08:13, 0.729s/it]: train_loss_raw=1.0666, running_loss=1.1747, LR=0.000100
[2025-08-26 11:45:09,892][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014968] [Batch 00154/00823] [00:01:52/00:08:07, 0.729s/it]: train_loss_raw=1.1262, running_loss=1.1742, LR=0.000100
[2025-08-26 11:45:15,754][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014976] [Batch 00162/00823] [00:01:58/00:08:01, 0.729s/it]: train_loss_raw=1.1129, running_loss=1.1744, LR=0.000100
[2025-08-26 11:45:21,640][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014984] [Batch 00170/00823] [00:02:03/00:07:56, 0.729s/it]: train_loss_raw=1.1453, running_loss=1.1720, LR=0.000100
[2025-08-26 11:45:27,550][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014992] [Batch 00178/00823] [00:02:09/00:07:50, 0.730s/it]: train_loss_raw=1.2239, running_loss=1.1717, LR=0.000100
[2025-08-26 11:45:33,420][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015000] [Batch 00186/00823] [00:02:15/00:07:44, 0.730s/it]: train_loss_raw=1.2537, running_loss=1.1747, LR=0.000100
[2025-08-26 11:45:39,238][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015008] [Batch 00194/00823] [00:02:21/00:07:39, 0.730s/it]: train_loss_raw=1.1817, running_loss=1.1737, LR=0.000100
[2025-08-26 11:45:44,970][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015016] [Batch 00202/00823] [00:02:27/00:07:32, 0.729s/it]: train_loss_raw=1.1994, running_loss=1.1736, LR=0.000100
[2025-08-26 11:45:50,733][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015024] [Batch 00210/00823] [00:02:33/00:07:26, 0.729s/it]: train_loss_raw=1.2420, running_loss=1.1726, LR=0.000100
[2025-08-26 11:45:56,539][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015032] [Batch 00218/00823] [00:02:38/00:07:20, 0.729s/it]: train_loss_raw=1.2010, running_loss=1.1732, LR=0.000100
[2025-08-26 11:46:02,510][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015040] [Batch 00226/00823] [00:02:44/00:07:15, 0.729s/it]: train_loss_raw=1.1971, running_loss=1.1741, LR=0.000100
[2025-08-26 11:46:08,170][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015048] [Batch 00234/00823] [00:02:50/00:07:09, 0.729s/it]: train_loss_raw=1.0636, running_loss=1.1733, LR=0.000100
[2025-08-26 11:46:14,041][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015056] [Batch 00242/00823] [00:02:56/00:07:03, 0.729s/it]: train_loss_raw=1.2558, running_loss=1.1745, LR=0.000100
[2025-08-26 11:46:19,996][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015064] [Batch 00250/00823] [00:03:02/00:06:57, 0.729s/it]: train_loss_raw=1.2043, running_loss=1.1748, LR=0.000100
[2025-08-26 11:46:25,760][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015072] [Batch 00258/00823] [00:03:08/00:06:51, 0.729s/it]: train_loss_raw=1.0727, running_loss=1.1742, LR=0.000100
[2025-08-26 11:46:31,701][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015080] [Batch 00266/00823] [00:03:14/00:06:46, 0.730s/it]: train_loss_raw=1.3044, running_loss=1.1753, LR=0.000100
[2025-08-26 11:46:37,747][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015088] [Batch 00274/00823] [00:03:20/00:06:40, 0.730s/it]: train_loss_raw=1.0733, running_loss=1.1757, LR=0.000100
[2025-08-26 11:46:43,778][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015096] [Batch 00282/00823] [00:03:26/00:06:35, 0.731s/it]: train_loss_raw=1.2505, running_loss=1.1761, LR=0.000100
[2025-08-26 11:46:49,559][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015104] [Batch 00290/00823] [00:03:31/00:06:29, 0.731s/it]: train_loss_raw=1.1343, running_loss=1.1746, LR=0.000100
[2025-08-26 11:46:55,332][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015112] [Batch 00298/00823] [00:03:37/00:06:23, 0.730s/it]: train_loss_raw=1.1959, running_loss=1.1747, LR=0.000100
[2025-08-26 11:47:01,166][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015120] [Batch 00306/00823] [00:03:43/00:06:17, 0.730s/it]: train_loss_raw=1.3763, running_loss=1.1769, LR=0.000100
[2025-08-26 11:47:06,991][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015128] [Batch 00314/00823] [00:03:49/00:06:11, 0.730s/it]: train_loss_raw=1.1802, running_loss=1.1757, LR=0.000100
[2025-08-26 11:47:12,809][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015136] [Batch 00322/00823] [00:03:55/00:06:05, 0.730s/it]: train_loss_raw=1.1387, running_loss=1.1757, LR=0.000100
[2025-08-26 11:47:18,779][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015144] [Batch 00330/00823] [00:04:01/00:06:00, 0.731s/it]: train_loss_raw=1.2511, running_loss=1.1760, LR=0.000100
[2025-08-26 11:47:24,697][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015152] [Batch 00338/00823] [00:04:07/00:05:54, 0.731s/it]: train_loss_raw=1.2211, running_loss=1.1788, LR=0.000100
[2025-08-26 11:47:30,743][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015160] [Batch 00346/00823] [00:04:13/00:05:48, 0.731s/it]: train_loss_raw=1.1393, running_loss=1.1781, LR=0.000100
[2025-08-26 11:47:36,527][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015168] [Batch 00354/00823] [00:04:18/00:05:42, 0.731s/it]: train_loss_raw=1.1011, running_loss=1.1782, LR=0.000100
[2025-08-26 11:47:42,343][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015176] [Batch 00362/00823] [00:04:24/00:05:37, 0.731s/it]: train_loss_raw=1.1558, running_loss=1.1781, LR=0.000100
[2025-08-26 11:47:48,271][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015184] [Batch 00370/00823] [00:04:30/00:05:31, 0.731s/it]: train_loss_raw=1.1790, running_loss=1.1809, LR=0.000100
[2025-08-26 11:47:54,269][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015192] [Batch 00378/00823] [00:04:36/00:05:25, 0.732s/it]: train_loss_raw=1.2135, running_loss=1.1803, LR=0.000100
[2025-08-26 11:48:00,077][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015200] [Batch 00386/00823] [00:04:42/00:05:19, 0.732s/it]: train_loss_raw=1.1304, running_loss=1.1775, LR=0.000100
[2025-08-26 11:48:05,895][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015208] [Batch 00394/00823] [00:04:48/00:05:13, 0.732s/it]: train_loss_raw=1.1703, running_loss=1.1779, LR=0.000100
[2025-08-26 11:48:11,869][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015216] [Batch 00402/00823] [00:04:54/00:05:08, 0.732s/it]: train_loss_raw=1.2081, running_loss=1.1785, LR=0.000100
[2025-08-26 11:48:17,747][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015224] [Batch 00410/00823] [00:05:00/00:05:02, 0.732s/it]: train_loss_raw=1.1853, running_loss=1.1765, LR=0.000100
[2025-08-26 11:48:23,520][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015232] [Batch 00418/00823] [00:05:05/00:04:56, 0.732s/it]: train_loss_raw=1.2745, running_loss=1.1771, LR=0.000100
[2025-08-26 11:48:29,309][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015240] [Batch 00426/00823] [00:05:11/00:04:50, 0.732s/it]: train_loss_raw=1.1592, running_loss=1.1764, LR=0.000100
[2025-08-26 11:48:35,167][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015248] [Batch 00434/00823] [00:05:17/00:04:44, 0.732s/it]: train_loss_raw=1.2528, running_loss=1.1791, LR=0.000100
[2025-08-26 11:48:40,995][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015256] [Batch 00442/00823] [00:05:23/00:04:38, 0.732s/it]: train_loss_raw=1.1555, running_loss=1.1785, LR=0.000100
[2025-08-26 11:48:46,887][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015264] [Batch 00450/00823] [00:05:29/00:04:32, 0.732s/it]: train_loss_raw=1.1600, running_loss=1.1788, LR=0.000100
[2025-08-26 11:48:52,773][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015272] [Batch 00458/00823] [00:05:35/00:04:27, 0.732s/it]: train_loss_raw=1.1536, running_loss=1.1770, LR=0.000100
[2025-08-26 11:48:58,632][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015280] [Batch 00466/00823] [00:05:40/00:04:21, 0.732s/it]: train_loss_raw=1.1601, running_loss=1.1787, LR=0.000100
[2025-08-26 11:49:04,646][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015288] [Batch 00474/00823] [00:05:46/00:04:15, 0.732s/it]: train_loss_raw=1.1762, running_loss=1.1809, LR=0.000100
[2025-08-26 11:49:10,374][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015296] [Batch 00482/00823] [00:05:52/00:04:09, 0.732s/it]: train_loss_raw=1.1957, running_loss=1.1822, LR=0.000100
[2025-08-26 11:49:16,250][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015304] [Batch 00490/00823] [00:05:58/00:04:03, 0.732s/it]: train_loss_raw=1.2577, running_loss=1.1810, LR=0.000100
[2025-08-26 11:49:22,244][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015312] [Batch 00498/00823] [00:06:04/00:03:57, 0.732s/it]: train_loss_raw=1.1294, running_loss=1.1782, LR=0.000100
[2025-08-26 11:49:28,233][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015320] [Batch 00506/00823] [00:06:10/00:03:52, 0.732s/it]: train_loss_raw=1.2228, running_loss=1.1770, LR=0.000100
[2025-08-26 11:49:34,088][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015328] [Batch 00514/00823] [00:06:16/00:03:46, 0.732s/it]: train_loss_raw=1.1697, running_loss=1.1754, LR=0.000100
[2025-08-26 11:49:39,989][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015336] [Batch 00522/00823] [00:06:22/00:03:40, 0.732s/it]: train_loss_raw=1.1395, running_loss=1.1747, LR=0.000100
[2025-08-26 11:49:45,861][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015344] [Batch 00530/00823] [00:06:28/00:03:34, 0.732s/it]: train_loss_raw=1.1604, running_loss=1.1729, LR=0.000100
[2025-08-26 11:49:51,740][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015352] [Batch 00538/00823] [00:06:34/00:03:28, 0.733s/it]: train_loss_raw=1.1670, running_loss=1.1743, LR=0.000100
[2025-08-26 11:49:57,579][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015360] [Batch 00546/00823] [00:06:39/00:03:22, 0.732s/it]: train_loss_raw=1.1182, running_loss=1.1751, LR=0.000100
[2025-08-26 11:50:03,344][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015368] [Batch 00554/00823] [00:06:45/00:03:16, 0.732s/it]: train_loss_raw=1.0891, running_loss=1.1750, LR=0.000100
[2025-08-26 11:50:09,134][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015376] [Batch 00562/00823] [00:06:51/00:03:11, 0.732s/it]: train_loss_raw=1.1393, running_loss=1.1741, LR=0.000100
[2025-08-26 11:50:15,077][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015384] [Batch 00570/00823] [00:06:57/00:03:05, 0.732s/it]: train_loss_raw=1.0948, running_loss=1.1723, LR=0.000100
[2025-08-26 11:50:20,918][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015392] [Batch 00578/00823] [00:07:03/00:02:59, 0.732s/it]: train_loss_raw=1.2064, running_loss=1.1731, LR=0.000100
[2025-08-26 11:50:26,762][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015400] [Batch 00586/00823] [00:07:09/00:02:53, 0.732s/it]: train_loss_raw=1.2897, running_loss=1.1740, LR=0.000100
[2025-08-26 11:50:32,521][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015408] [Batch 00594/00823] [00:07:14/00:02:47, 0.732s/it]: train_loss_raw=1.1379, running_loss=1.1736, LR=0.000100
[2025-08-26 11:50:38,387][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015416] [Batch 00602/00823] [00:07:20/00:02:41, 0.732s/it]: train_loss_raw=1.1399, running_loss=1.1714, LR=0.000100
[2025-08-26 11:50:44,258][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015424] [Batch 00610/00823] [00:07:26/00:02:35, 0.732s/it]: train_loss_raw=1.1431, running_loss=1.1696, LR=0.000100
[2025-08-26 11:50:50,157][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015432] [Batch 00618/00823] [00:07:32/00:02:30, 0.732s/it]: train_loss_raw=1.2099, running_loss=1.1724, LR=0.000100
[2025-08-26 11:50:56,104][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015440] [Batch 00626/00823] [00:07:38/00:02:24, 0.732s/it]: train_loss_raw=1.2513, running_loss=1.1746, LR=0.000100
[2025-08-26 11:51:01,959][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015448] [Batch 00634/00823] [00:07:44/00:02:18, 0.732s/it]: train_loss_raw=1.2892, running_loss=1.1762, LR=0.000100
[2025-08-26 11:51:07,713][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015456] [Batch 00642/00823] [00:07:50/00:02:12, 0.732s/it]: train_loss_raw=1.1790, running_loss=1.1737, LR=0.000100
[2025-08-26 11:51:13,469][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015464] [Batch 00650/00823] [00:07:55/00:02:06, 0.732s/it]: train_loss_raw=1.1744, running_loss=1.1696, LR=0.000100
[2025-08-26 11:51:19,444][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015472] [Batch 00658/00823] [00:08:01/00:02:00, 0.732s/it]: train_loss_raw=1.1464, running_loss=1.1665, LR=0.000100
[2025-08-26 11:51:25,256][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015480] [Batch 00666/00823] [00:08:07/00:01:54, 0.732s/it]: train_loss_raw=1.2193, running_loss=1.1685, LR=0.000100
[2025-08-26 11:51:31,171][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015488] [Batch 00674/00823] [00:08:13/00:01:49, 0.732s/it]: train_loss_raw=1.1918, running_loss=1.1689, LR=0.000100
[2025-08-26 11:51:37,152][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015496] [Batch 00682/00823] [00:08:19/00:01:43, 0.732s/it]: train_loss_raw=1.0750, running_loss=1.1686, LR=0.000100
[2025-08-26 11:51:42,917][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015504] [Batch 00690/00823] [00:08:25/00:01:37, 0.732s/it]: train_loss_raw=1.2355, running_loss=1.1705, LR=0.000100
[2025-08-26 11:51:48,764][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015512] [Batch 00698/00823] [00:08:31/00:01:31, 0.732s/it]: train_loss_raw=1.1432, running_loss=1.1685, LR=0.000100
[2025-08-26 11:51:54,483][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015520] [Batch 00706/00823] [00:08:36/00:01:25, 0.732s/it]: train_loss_raw=1.1510, running_loss=1.1673, LR=0.000100
[2025-08-26 11:52:00,322][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015528] [Batch 00714/00823] [00:08:42/00:01:19, 0.732s/it]: train_loss_raw=1.1632, running_loss=1.1681, LR=0.000100
[2025-08-26 11:52:06,282][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015536] [Batch 00722/00823] [00:08:48/00:01:13, 0.732s/it]: train_loss_raw=1.1225, running_loss=1.1673, LR=0.000100
[2025-08-26 11:52:12,260][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015544] [Batch 00730/00823] [00:08:54/00:01:08, 0.732s/it]: train_loss_raw=1.1277, running_loss=1.1652, LR=0.000100
[2025-08-26 11:52:18,088][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015552] [Batch 00738/00823] [00:09:00/00:01:02, 0.732s/it]: train_loss_raw=1.1336, running_loss=1.1651, LR=0.000100
[2025-08-26 11:52:23,932][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015560] [Batch 00746/00823] [00:09:06/00:00:56, 0.732s/it]: train_loss_raw=1.0660, running_loss=1.1625, LR=0.000100
[2025-08-26 11:52:29,798][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015568] [Batch 00754/00823] [00:09:12/00:00:50, 0.732s/it]: train_loss_raw=1.1760, running_loss=1.1619, LR=0.000100
[2025-08-26 11:52:35,624][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015576] [Batch 00762/00823] [00:09:17/00:00:44, 0.732s/it]: train_loss_raw=1.2819, running_loss=1.1629, LR=0.000100
[2025-08-26 11:52:41,503][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015584] [Batch 00770/00823] [00:09:23/00:00:38, 0.732s/it]: train_loss_raw=1.1636, running_loss=1.1647, LR=0.000100
[2025-08-26 11:52:47,449][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015592] [Batch 00778/00823] [00:09:29/00:00:32, 0.732s/it]: train_loss_raw=1.2342, running_loss=1.1659, LR=0.000100
[2025-08-26 11:52:53,289][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015600] [Batch 00786/00823] [00:09:35/00:00:27, 0.732s/it]: train_loss_raw=1.2426, running_loss=1.1657, LR=0.000100
[2025-08-26 11:52:59,189][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015608] [Batch 00794/00823] [00:09:41/00:00:21, 0.732s/it]: train_loss_raw=1.2047, running_loss=1.1658, LR=0.000100
[2025-08-26 11:53:05,016][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015616] [Batch 00802/00823] [00:09:47/00:00:15, 0.732s/it]: train_loss_raw=1.0614, running_loss=1.1635, LR=0.000100
[2025-08-26 11:53:10,761][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015624] [Batch 00810/00823] [00:09:53/00:00:09, 0.732s/it]: train_loss_raw=1.2450, running_loss=1.1632, LR=0.000100
[2025-08-26 11:53:16,823][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015632] [Batch 00818/00823] [00:09:59/00:00:03, 0.732s/it]: train_loss_raw=1.2042, running_loss=1.1641, LR=0.000100
[2025-08-26 11:53:20,813][__main__][INFO] - [VALIDATION] [Epoch 18/29] Starting validation.
[2025-08-26 11:53:31,733][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 015638] [Batch 00007/00013] [00:00:10/00:00:06, 1.365s/it]
[2025-08-26 11:53:38,963][__main__][INFO] - [VALIDATION] [Epoch 18/29] train_loss=1.16364, valid_loss=1.40440
[2025-08-26 11:53:38,964][__main__][INFO] - [VALIDATION] [Epoch 18/29] Metrics:
[2025-08-26 11:53:38,964][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_er      0.591
[2025-08-26 11:53:38,964][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_prec    0.073
[2025-08-26 11:53:38,964][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_recall  0.074
[2025-08-26 11:53:38,964][__main__][INFO] - [VALIDATION] [Epoch 18/29] - pep_recall 0.032
[2025-08-26 11:53:38,966][__main__][INFO] - [TRAIN] [Epoch 18/29] Epoch complete, total time 03:21:02, remaining time 01:56:23, 00:10:34 per epoch
[2025-08-26 11:53:40,920][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015640] [Batch 00003/00823] [00:00:01/00:07:32, 0.552s/it]: train_loss_raw=1.1871, running_loss=1.1329, LR=0.000100
[2025-08-26 11:53:46,807][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015648] [Batch 00011/00823] [00:00:07/00:09:16, 0.686s/it]: train_loss_raw=1.1888, running_loss=1.1378, LR=0.000100
[2025-08-26 11:53:52,610][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015656] [Batch 00019/00823] [00:00:13/00:09:24, 0.702s/it]: train_loss_raw=1.1191, running_loss=1.1400, LR=0.000100
[2025-08-26 11:53:58,450][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015664] [Batch 00027/00823] [00:00:19/00:09:25, 0.711s/it]: train_loss_raw=1.0514, running_loss=1.1404, LR=0.000100
[2025-08-26 11:54:04,212][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015672] [Batch 00035/00823] [00:00:24/00:09:21, 0.713s/it]: train_loss_raw=1.2115, running_loss=1.1419, LR=0.000100
[2025-08-26 11:54:09,948][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015680] [Batch 00043/00823] [00:00:30/00:09:16, 0.714s/it]: train_loss_raw=1.2308, running_loss=1.1462, LR=0.000100
[2025-08-26 11:54:15,664][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015688] [Batch 00051/00823] [00:00:36/00:09:10, 0.714s/it]: train_loss_raw=1.2093, running_loss=1.1505, LR=0.000100
[2025-08-26 11:54:21,558][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015696] [Batch 00059/00823] [00:00:42/00:09:07, 0.717s/it]: train_loss_raw=1.0846, running_loss=1.1512, LR=0.000100
[2025-08-26 11:54:27,315][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015704] [Batch 00067/00823] [00:00:48/00:09:02, 0.717s/it]: train_loss_raw=1.0805, running_loss=1.1509, LR=0.000100
[2025-08-26 11:54:33,080][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015712] [Batch 00075/00823] [00:00:53/00:08:56, 0.718s/it]: train_loss_raw=1.2548, running_loss=1.1510, LR=0.000100
[2025-08-26 11:54:38,881][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015720] [Batch 00083/00823] [00:00:59/00:08:51, 0.718s/it]: train_loss_raw=1.2061, running_loss=1.1529, LR=0.000100
[2025-08-26 11:54:44,966][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015728] [Batch 00091/00823] [00:01:05/00:08:48, 0.722s/it]: train_loss_raw=1.1405, running_loss=1.1531, LR=0.000100
[2025-08-26 11:54:50,868][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015736] [Batch 00099/00823] [00:01:11/00:08:43, 0.723s/it]: train_loss_raw=1.1706, running_loss=1.1549, LR=0.000100
[2025-08-26 11:54:56,379][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015744] [Batch 00107/00823] [00:01:17/00:08:36, 0.721s/it]: train_loss_raw=1.2002, running_loss=1.1550, LR=0.000100
[2025-08-26 11:55:02,140][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015752] [Batch 00115/00823] [00:01:22/00:08:30, 0.721s/it]: train_loss_raw=1.1672, running_loss=1.1571, LR=0.000100
[2025-08-26 11:55:08,091][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015760] [Batch 00123/00823] [00:01:28/00:08:25, 0.722s/it]: train_loss_raw=1.1683, running_loss=1.1590, LR=0.000100
[2025-08-26 11:55:14,047][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015768] [Batch 00131/00823] [00:01:34/00:08:20, 0.724s/it]: train_loss_raw=1.1241, running_loss=1.1594, LR=0.000100
[2025-08-26 11:55:19,777][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015776] [Batch 00139/00823] [00:01:40/00:08:14, 0.723s/it]: train_loss_raw=1.1604, running_loss=1.1621, LR=0.000100
[2025-08-26 11:55:25,735][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015784] [Batch 00147/00823] [00:01:46/00:08:09, 0.724s/it]: train_loss_raw=1.1416, running_loss=1.1586, LR=0.000100
[2025-08-26 11:55:31,522][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015792] [Batch 00155/00823] [00:01:52/00:08:03, 0.724s/it]: train_loss_raw=1.0372, running_loss=1.1562, LR=0.000100
[2025-08-26 11:55:37,278][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015800] [Batch 00163/00823] [00:01:58/00:07:57, 0.724s/it]: train_loss_raw=1.2244, running_loss=1.1610, LR=0.000100
[2025-08-26 11:55:43,129][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015808] [Batch 00171/00823] [00:02:03/00:07:52, 0.724s/it]: train_loss_raw=1.1222, running_loss=1.1621, LR=0.000100
[2025-08-26 11:55:48,925][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015816] [Batch 00179/00823] [00:02:09/00:07:46, 0.724s/it]: train_loss_raw=1.1936, running_loss=1.1619, LR=0.000100
[2025-08-26 11:55:54,842][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015824] [Batch 00187/00823] [00:02:15/00:07:41, 0.725s/it]: train_loss_raw=1.1294, running_loss=1.1620, LR=0.000100
[2025-08-26 11:56:00,929][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015832] [Batch 00195/00823] [00:02:21/00:07:36, 0.726s/it]: train_loss_raw=1.1939, running_loss=1.1613, LR=0.000100
[2025-08-26 11:56:06,922][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015840] [Batch 00203/00823] [00:02:27/00:07:30, 0.727s/it]: train_loss_raw=1.1278, running_loss=1.1599, LR=0.000100
[2025-08-26 11:56:12,874][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015848] [Batch 00211/00823] [00:02:33/00:07:25, 0.728s/it]: train_loss_raw=1.1314, running_loss=1.1575, LR=0.000100
[2025-08-26 11:56:18,978][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015856] [Batch 00219/00823] [00:02:39/00:07:20, 0.729s/it]: train_loss_raw=1.1508, running_loss=1.1562, LR=0.000100
[2025-08-26 11:56:24,726][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015864] [Batch 00227/00823] [00:02:45/00:07:14, 0.729s/it]: train_loss_raw=1.0662, running_loss=1.1569, LR=0.000100
[2025-08-26 11:56:30,514][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015872] [Batch 00235/00823] [00:02:51/00:07:08, 0.729s/it]: train_loss_raw=1.1303, running_loss=1.1572, LR=0.000100
[2025-08-26 11:56:36,333][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015880] [Batch 00243/00823] [00:02:57/00:07:02, 0.729s/it]: train_loss_raw=1.1604, running_loss=1.1571, LR=0.000100
[2025-08-26 11:56:42,089][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015888] [Batch 00251/00823] [00:03:02/00:06:56, 0.728s/it]: train_loss_raw=1.1754, running_loss=1.1562, LR=0.000100
[2025-08-26 11:56:47,891][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015896] [Batch 00259/00823] [00:03:08/00:06:50, 0.728s/it]: train_loss_raw=1.1226, running_loss=1.1574, LR=0.000100
[2025-08-26 11:56:53,615][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015904] [Batch 00267/00823] [00:03:14/00:06:44, 0.728s/it]: train_loss_raw=1.0672, running_loss=1.1548, LR=0.000100
[2025-08-26 11:56:59,278][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015912] [Batch 00275/00823] [00:03:20/00:06:38, 0.727s/it]: train_loss_raw=1.1329, running_loss=1.1562, LR=0.000100
[2025-08-26 11:57:05,139][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015920] [Batch 00283/00823] [00:03:25/00:06:32, 0.727s/it]: train_loss_raw=1.1067, running_loss=1.1564, LR=0.000100
[2025-08-26 11:57:10,913][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015928] [Batch 00291/00823] [00:03:31/00:06:26, 0.727s/it]: train_loss_raw=1.0941, running_loss=1.1555, LR=0.000100
[2025-08-26 11:57:16,758][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015936] [Batch 00299/00823] [00:03:37/00:06:21, 0.727s/it]: train_loss_raw=1.3268, running_loss=1.1571, LR=0.000100
[2025-08-26 11:57:22,523][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015944] [Batch 00307/00823] [00:03:43/00:06:15, 0.727s/it]: train_loss_raw=1.2395, running_loss=1.1572, LR=0.000100
[2025-08-26 11:57:28,503][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015952] [Batch 00315/00823] [00:03:49/00:06:09, 0.728s/it]: train_loss_raw=1.1545, running_loss=1.1566, LR=0.000100
[2025-08-26 11:57:34,456][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015960] [Batch 00323/00823] [00:03:55/00:06:04, 0.728s/it]: train_loss_raw=1.1858, running_loss=1.1593, LR=0.000100
[2025-08-26 11:57:40,457][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015968] [Batch 00331/00823] [00:04:01/00:05:58, 0.729s/it]: train_loss_raw=1.1311, running_loss=1.1606, LR=0.000100
[2025-08-26 11:57:46,265][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015976] [Batch 00339/00823] [00:04:07/00:05:52, 0.729s/it]: train_loss_raw=1.1411, running_loss=1.1604, LR=0.000100
[2025-08-26 11:57:51,983][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015984] [Batch 00347/00823] [00:04:12/00:05:46, 0.728s/it]: train_loss_raw=1.1354, running_loss=1.1610, LR=0.000100
[2025-08-26 11:57:57,727][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015992] [Batch 00355/00823] [00:04:18/00:05:40, 0.728s/it]: train_loss_raw=1.1150, running_loss=1.1616, LR=0.000100
[2025-08-26 11:58:03,679][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016000] [Batch 00363/00823] [00:04:24/00:05:35, 0.728s/it]: train_loss_raw=1.2886, running_loss=1.1621, LR=0.000100
[2025-08-26 11:58:13,483][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016008] [Batch 00371/00823] [00:04:34/00:05:34, 0.739s/it]: train_loss_raw=1.1975, running_loss=1.1634, LR=0.000100
[2025-08-26 11:58:19,222][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016016] [Batch 00379/00823] [00:04:39/00:05:27, 0.739s/it]: train_loss_raw=1.1597, running_loss=1.1638, LR=0.000100
[2025-08-26 11:58:25,005][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016024] [Batch 00387/00823] [00:04:45/00:05:21, 0.738s/it]: train_loss_raw=1.1457, running_loss=1.1636, LR=0.000100
[2025-08-26 11:58:30,790][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016032] [Batch 00395/00823] [00:04:51/00:05:15, 0.738s/it]: train_loss_raw=1.0993, running_loss=1.1634, LR=0.000100
[2025-08-26 11:58:36,592][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016040] [Batch 00403/00823] [00:04:57/00:05:09, 0.738s/it]: train_loss_raw=1.0713, running_loss=1.1620, LR=0.000100
[2025-08-26 11:58:42,331][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016048] [Batch 00411/00823] [00:05:03/00:05:03, 0.737s/it]: train_loss_raw=1.1648, running_loss=1.1612, LR=0.000100
[2025-08-26 11:58:48,107][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016056] [Batch 00419/00823] [00:05:08/00:04:57, 0.737s/it]: train_loss_raw=1.2431, running_loss=1.1632, LR=0.000100
[2025-08-26 11:58:54,175][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016064] [Batch 00427/00823] [00:05:14/00:04:52, 0.737s/it]: train_loss_raw=1.2073, running_loss=1.1649, LR=0.000100
[2025-08-26 11:59:00,145][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016072] [Batch 00435/00823] [00:05:20/00:04:46, 0.738s/it]: train_loss_raw=1.2092, running_loss=1.1632, LR=0.000100
[2025-08-26 11:59:06,021][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016080] [Batch 00443/00823] [00:05:26/00:04:40, 0.738s/it]: train_loss_raw=1.1368, running_loss=1.1607, LR=0.000100
[2025-08-26 11:59:11,888][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016088] [Batch 00451/00823] [00:05:32/00:04:34, 0.738s/it]: train_loss_raw=1.2188, running_loss=1.1615, LR=0.000100
[2025-08-26 11:59:17,721][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016096] [Batch 00459/00823] [00:05:38/00:04:28, 0.737s/it]: train_loss_raw=1.0916, running_loss=1.1633, LR=0.000100
[2025-08-26 11:59:23,483][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016104] [Batch 00467/00823] [00:05:44/00:04:22, 0.737s/it]: train_loss_raw=1.0786, running_loss=1.1626, LR=0.000100
[2025-08-26 11:59:29,407][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016112] [Batch 00475/00823] [00:05:50/00:04:16, 0.737s/it]: train_loss_raw=1.1894, running_loss=1.1598, LR=0.000100
[2025-08-26 11:59:35,449][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016120] [Batch 00483/00823] [00:05:56/00:04:10, 0.737s/it]: train_loss_raw=1.1644, running_loss=1.1593, LR=0.000100
[2025-08-26 11:59:41,285][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016128] [Batch 00491/00823] [00:06:02/00:04:04, 0.737s/it]: train_loss_raw=1.0230, running_loss=1.1574, LR=0.000100
[2025-08-26 11:59:47,052][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016136] [Batch 00499/00823] [00:06:07/00:03:58, 0.737s/it]: train_loss_raw=1.1890, running_loss=1.1595, LR=0.000100
[2025-08-26 11:59:52,945][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016144] [Batch 00507/00823] [00:06:13/00:03:52, 0.737s/it]: train_loss_raw=1.2217, running_loss=1.1618, LR=0.000100
[2025-08-26 11:59:58,724][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016152] [Batch 00515/00823] [00:06:19/00:03:46, 0.737s/it]: train_loss_raw=1.0824, running_loss=1.1570, LR=0.000100
[2025-08-26 12:00:04,619][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016160] [Batch 00523/00823] [00:06:25/00:03:41, 0.737s/it]: train_loss_raw=1.1466, running_loss=1.1566, LR=0.000100
[2025-08-26 12:00:10,423][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016168] [Batch 00531/00823] [00:06:31/00:03:35, 0.737s/it]: train_loss_raw=1.1648, running_loss=1.1566, LR=0.000100
[2025-08-26 12:00:16,216][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016176] [Batch 00539/00823] [00:06:36/00:03:29, 0.736s/it]: train_loss_raw=1.0158, running_loss=1.1556, LR=0.000100
[2025-08-26 12:00:22,211][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016184] [Batch 00547/00823] [00:06:42/00:03:23, 0.737s/it]: train_loss_raw=1.1884, running_loss=1.1573, LR=0.000100
[2025-08-26 12:00:28,075][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016192] [Batch 00555/00823] [00:06:48/00:03:17, 0.737s/it]: train_loss_raw=1.1877, running_loss=1.1585, LR=0.000100
[2025-08-26 12:00:33,946][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016200] [Batch 00563/00823] [00:06:54/00:03:11, 0.737s/it]: train_loss_raw=1.1371, running_loss=1.1575, LR=0.000100
[2025-08-26 12:00:39,937][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016208] [Batch 00571/00823] [00:07:00/00:03:05, 0.737s/it]: train_loss_raw=1.1149, running_loss=1.1594, LR=0.000100
[2025-08-26 12:00:45,687][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016216] [Batch 00579/00823] [00:07:06/00:02:59, 0.736s/it]: train_loss_raw=1.1305, running_loss=1.1582, LR=0.000100
[2025-08-26 12:00:51,408][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016224] [Batch 00587/00823] [00:07:12/00:02:53, 0.736s/it]: train_loss_raw=1.1112, running_loss=1.1581, LR=0.000100
[2025-08-26 12:00:57,233][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016232] [Batch 00595/00823] [00:07:17/00:02:47, 0.736s/it]: train_loss_raw=1.1600, running_loss=1.1584, LR=0.000100
[2025-08-26 12:01:03,028][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016240] [Batch 00603/00823] [00:07:23/00:02:41, 0.736s/it]: train_loss_raw=1.1508, running_loss=1.1594, LR=0.000100
[2025-08-26 12:01:08,800][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016248] [Batch 00611/00823] [00:07:29/00:02:35, 0.736s/it]: train_loss_raw=1.0300, running_loss=1.1589, LR=0.000100
[2025-08-26 12:01:14,581][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016256] [Batch 00619/00823] [00:07:35/00:02:30, 0.736s/it]: train_loss_raw=1.1841, running_loss=1.1584, LR=0.000100
[2025-08-26 12:01:20,508][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016264] [Batch 00627/00823] [00:07:41/00:02:24, 0.736s/it]: train_loss_raw=1.2307, running_loss=1.1591, LR=0.000100
[2025-08-26 12:01:26,387][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016272] [Batch 00635/00823] [00:07:47/00:02:18, 0.736s/it]: train_loss_raw=1.2422, running_loss=1.1583, LR=0.000100
[2025-08-26 12:01:32,302][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016280] [Batch 00643/00823] [00:07:53/00:02:12, 0.736s/it]: train_loss_raw=1.1785, running_loss=1.1573, LR=0.000100
[2025-08-26 12:01:38,176][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016288] [Batch 00651/00823] [00:07:58/00:02:06, 0.736s/it]: train_loss_raw=1.1187, running_loss=1.1558, LR=0.000100
[2025-08-26 12:01:44,006][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016296] [Batch 00659/00823] [00:08:04/00:02:00, 0.736s/it]: train_loss_raw=1.1590, running_loss=1.1580, LR=0.000100
[2025-08-26 12:01:49,721][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016304] [Batch 00667/00823] [00:08:10/00:01:54, 0.735s/it]: train_loss_raw=1.1969, running_loss=1.1603, LR=0.000100
[2025-08-26 12:01:55,403][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016312] [Batch 00675/00823] [00:08:16/00:01:48, 0.735s/it]: train_loss_raw=1.1245, running_loss=1.1599, LR=0.000100
[2025-08-26 12:02:01,088][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016320] [Batch 00683/00823] [00:08:21/00:01:42, 0.735s/it]: train_loss_raw=1.2024, running_loss=1.1582, LR=0.000100
[2025-08-26 12:02:06,884][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016328] [Batch 00691/00823] [00:08:27/00:01:36, 0.735s/it]: train_loss_raw=1.2023, running_loss=1.1580, LR=0.000100
[2025-08-26 12:02:12,735][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016336] [Batch 00699/00823] [00:08:33/00:01:31, 0.735s/it]: train_loss_raw=1.0828, running_loss=1.1585, LR=0.000100
[2025-08-26 12:02:18,505][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016344] [Batch 00707/00823] [00:08:39/00:01:25, 0.734s/it]: train_loss_raw=1.0015, running_loss=1.1584, LR=0.000100
[2025-08-26 12:02:24,299][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016352] [Batch 00715/00823] [00:08:45/00:01:19, 0.734s/it]: train_loss_raw=1.1020, running_loss=1.1561, LR=0.000100
[2025-08-26 12:02:30,166][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016360] [Batch 00723/00823] [00:08:50/00:01:13, 0.734s/it]: train_loss_raw=1.0909, running_loss=1.1567, LR=0.000100
[2025-08-26 12:02:35,910][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016368] [Batch 00731/00823] [00:08:56/00:01:07, 0.734s/it]: train_loss_raw=1.1276, running_loss=1.1563, LR=0.000100
[2025-08-26 12:02:41,646][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016376] [Batch 00739/00823] [00:09:02/00:01:01, 0.734s/it]: train_loss_raw=1.1509, running_loss=1.1555, LR=0.000100
[2025-08-26 12:02:47,423][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016384] [Batch 00747/00823] [00:09:08/00:00:55, 0.734s/it]: train_loss_raw=1.1681, running_loss=1.1527, LR=0.000100
[2025-08-26 12:02:53,275][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016392] [Batch 00755/00823] [00:09:14/00:00:49, 0.734s/it]: train_loss_raw=1.1408, running_loss=1.1511, LR=0.000100
[2025-08-26 12:02:58,934][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016400] [Batch 00763/00823] [00:09:19/00:00:44, 0.734s/it]: train_loss_raw=1.0813, running_loss=1.1489, LR=0.000100
[2025-08-26 12:03:04,598][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016408] [Batch 00771/00823] [00:09:25/00:00:38, 0.733s/it]: train_loss_raw=1.1314, running_loss=1.1507, LR=0.000100
[2025-08-26 12:03:10,267][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016416] [Batch 00779/00823] [00:09:31/00:00:32, 0.733s/it]: train_loss_raw=1.0999, running_loss=1.1515, LR=0.000100
[2025-08-26 12:03:15,968][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016424] [Batch 00787/00823] [00:09:36/00:00:26, 0.733s/it]: train_loss_raw=1.1553, running_loss=1.1521, LR=0.000100
[2025-08-26 12:03:21,636][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016432] [Batch 00795/00823] [00:09:42/00:00:20, 0.733s/it]: train_loss_raw=1.1458, running_loss=1.1508, LR=0.000100
[2025-08-26 12:03:27,177][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016440] [Batch 00803/00823] [00:09:47/00:00:14, 0.732s/it]: train_loss_raw=1.1495, running_loss=1.1506, LR=0.000100
[2025-08-26 12:03:32,799][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016448] [Batch 00811/00823] [00:09:53/00:00:08, 0.732s/it]: train_loss_raw=1.1724, running_loss=1.1523, LR=0.000100
[2025-08-26 12:03:38,547][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016456] [Batch 00819/00823] [00:09:59/00:00:02, 0.732s/it]: train_loss_raw=1.1461, running_loss=1.1512, LR=0.000100
[2025-08-26 12:03:47,057][__main__][INFO] - [VALIDATION] [Epoch 19/29] Starting validation.
[2025-08-26 12:03:57,272][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 016461] [Batch 00007/00013] [00:00:10/00:00:06, 1.277s/it]
[2025-08-26 12:04:04,197][__main__][INFO] - [VALIDATION] [Epoch 19/29] train_loss=1.15021, valid_loss=1.38775
[2025-08-26 12:04:04,197][__main__][INFO] - [VALIDATION] [Epoch 19/29] Metrics:
[2025-08-26 12:04:04,197][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_er      0.594
[2025-08-26 12:04:04,197][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_prec    0.073
[2025-08-26 12:04:04,197][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_recall  0.075
[2025-08-26 12:04:04,197][__main__][INFO] - [VALIDATION] [Epoch 19/29] - pep_recall 0.032
[2025-08-26 12:04:04,199][__main__][INFO] - [TRAIN] [Epoch 19/29] Epoch complete, total time 03:31:27, remaining time 01:45:43, 00:10:34 per epoch
[2025-08-26 12:04:07,604][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016464] [Batch 00004/00823] [00:00:03/00:10:46, 0.790s/it]: train_loss_raw=1.0945, running_loss=1.0591, LR=0.000100
[2025-08-26 12:04:13,676][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016472] [Batch 00012/00823] [00:00:09/00:10:23, 0.769s/it]: train_loss_raw=1.0595, running_loss=1.0608, LR=0.000100
[2025-08-26 12:04:19,757][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016480] [Batch 00020/00823] [00:00:15/00:10:14, 0.766s/it]: train_loss_raw=1.1528, running_loss=1.0639, LR=0.000100
[2025-08-26 12:04:25,813][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016488] [Batch 00028/00823] [00:00:21/00:10:06, 0.763s/it]: train_loss_raw=0.9155, running_loss=1.0665, LR=0.000100
[2025-08-26 12:04:31,903][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016496] [Batch 00036/00823] [00:00:27/00:10:00, 0.763s/it]: train_loss_raw=1.0567, running_loss=1.0673, LR=0.000100
[2025-08-26 12:04:37,963][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016504] [Batch 00044/00823] [00:00:33/00:09:53, 0.762s/it]: train_loss_raw=1.2087, running_loss=1.0691, LR=0.000100
[2025-08-26 12:04:43,987][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016512] [Batch 00052/00823] [00:00:39/00:09:46, 0.760s/it]: train_loss_raw=1.1364, running_loss=1.0735, LR=0.000100
[2025-08-26 12:04:50,014][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016520] [Batch 00060/00823] [00:00:45/00:09:39, 0.760s/it]: train_loss_raw=1.1494, running_loss=1.0751, LR=0.000100
[2025-08-26 12:04:56,101][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016528] [Batch 00068/00823] [00:00:51/00:09:33, 0.760s/it]: train_loss_raw=1.1225, running_loss=1.0773, LR=0.000100
[2025-08-26 12:05:02,178][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016536] [Batch 00076/00823] [00:00:57/00:09:27, 0.760s/it]: train_loss_raw=1.1241, running_loss=1.0783, LR=0.000100
[2025-08-26 12:05:08,219][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016544] [Batch 00084/00823] [00:01:03/00:09:21, 0.759s/it]: train_loss_raw=1.1612, running_loss=1.0793, LR=0.000100
[2025-08-26 12:05:14,276][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016552] [Batch 00092/00823] [00:01:09/00:09:14, 0.759s/it]: train_loss_raw=1.0702, running_loss=1.0818, LR=0.000100
[2025-08-26 12:05:20,307][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016560] [Batch 00100/00823] [00:01:15/00:09:08, 0.759s/it]: train_loss_raw=1.1085, running_loss=1.0844, LR=0.000100
[2025-08-26 12:05:26,390][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016568] [Batch 00108/00823] [00:01:21/00:09:02, 0.759s/it]: train_loss_raw=1.0266, running_loss=1.0862, LR=0.000100
[2025-08-26 12:05:32,449][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016576] [Batch 00116/00823] [00:01:28/00:08:56, 0.759s/it]: train_loss_raw=1.1391, running_loss=1.0862, LR=0.000100
[2025-08-26 12:05:38,530][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016584] [Batch 00124/00823] [00:01:34/00:08:50, 0.759s/it]: train_loss_raw=1.1244, running_loss=1.0871, LR=0.000100
[2025-08-26 12:05:44,682][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016592] [Batch 00132/00823] [00:01:40/00:08:44, 0.759s/it]: train_loss_raw=1.0463, running_loss=1.0884, LR=0.000100
[2025-08-26 12:05:50,674][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016600] [Batch 00140/00823] [00:01:46/00:08:38, 0.759s/it]: train_loss_raw=1.1577, running_loss=1.0905, LR=0.000100
[2025-08-26 12:05:56,548][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016608] [Batch 00148/00823] [00:01:52/00:08:31, 0.757s/it]: train_loss_raw=1.0730, running_loss=1.0916, LR=0.000100
[2025-08-26 12:06:02,495][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016616] [Batch 00156/00823] [00:01:58/00:08:24, 0.757s/it]: train_loss_raw=1.0515, running_loss=1.0933, LR=0.000100
[2025-08-26 12:06:08,581][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016624] [Batch 00164/00823] [00:02:04/00:08:18, 0.757s/it]: train_loss_raw=1.1398, running_loss=1.0933, LR=0.000100
[2025-08-26 12:06:14,637][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016632] [Batch 00172/00823] [00:02:10/00:08:12, 0.757s/it]: train_loss_raw=1.0658, running_loss=1.0918, LR=0.000100
[2025-08-26 12:06:20,690][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016640] [Batch 00180/00823] [00:02:16/00:08:06, 0.757s/it]: train_loss_raw=1.0933, running_loss=1.0943, LR=0.000100
[2025-08-26 12:06:26,773][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016648] [Batch 00188/00823] [00:02:22/00:08:00, 0.757s/it]: train_loss_raw=1.0813, running_loss=1.0964, LR=0.000100
[2025-08-26 12:06:32,872][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016656] [Batch 00196/00823] [00:02:28/00:07:54, 0.757s/it]: train_loss_raw=1.0776, running_loss=1.0960, LR=0.000100
[2025-08-26 12:06:38,930][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016664] [Batch 00204/00823] [00:02:34/00:07:48, 0.757s/it]: train_loss_raw=1.0803, running_loss=1.0959, LR=0.000100
[2025-08-26 12:06:44,988][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016672] [Batch 00212/00823] [00:02:40/00:07:42, 0.757s/it]: train_loss_raw=1.0921, running_loss=1.0949, LR=0.000100
[2025-08-26 12:06:51,100][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016680] [Batch 00220/00823] [00:02:46/00:07:36, 0.758s/it]: train_loss_raw=1.0273, running_loss=1.0931, LR=0.000100
[2025-08-26 12:06:57,172][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016688] [Batch 00228/00823] [00:02:52/00:07:30, 0.758s/it]: train_loss_raw=1.1405, running_loss=1.0918, LR=0.000100
[2025-08-26 12:07:03,229][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016696] [Batch 00236/00823] [00:02:58/00:07:24, 0.758s/it]: train_loss_raw=1.0108, running_loss=1.0912, LR=0.000100
[2025-08-26 12:07:09,249][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016704] [Batch 00244/00823] [00:03:04/00:07:18, 0.757s/it]: train_loss_raw=1.1114, running_loss=1.0940, LR=0.000100
[2025-08-26 12:07:15,300][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016712] [Batch 00252/00823] [00:03:10/00:07:12, 0.757s/it]: train_loss_raw=1.1993, running_loss=1.0925, LR=0.000100
[2025-08-26 12:07:21,379][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016720] [Batch 00260/00823] [00:03:16/00:07:06, 0.757s/it]: train_loss_raw=1.0615, running_loss=1.0923, LR=0.000100
[2025-08-26 12:07:27,409][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016728] [Batch 00268/00823] [00:03:22/00:07:00, 0.757s/it]: train_loss_raw=1.0242, running_loss=1.0920, LR=0.000100
[2025-08-26 12:07:33,497][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016736] [Batch 00276/00823] [00:03:29/00:06:54, 0.757s/it]: train_loss_raw=1.1133, running_loss=1.0950, LR=0.000100
[2025-08-26 12:07:39,603][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016744] [Batch 00284/00823] [00:03:35/00:06:48, 0.758s/it]: train_loss_raw=1.0724, running_loss=1.0960, LR=0.000100
[2025-08-26 12:07:45,665][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016752] [Batch 00292/00823] [00:03:41/00:06:42, 0.758s/it]: train_loss_raw=1.0583, running_loss=1.0949, LR=0.000100
[2025-08-26 12:07:51,729][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016760] [Batch 00300/00823] [00:03:47/00:06:36, 0.758s/it]: train_loss_raw=1.1231, running_loss=1.0949, LR=0.000100
[2025-08-26 12:07:57,798][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016768] [Batch 00308/00823] [00:03:53/00:06:30, 0.758s/it]: train_loss_raw=1.0460, running_loss=1.0944, LR=0.000100
[2025-08-26 12:08:03,933][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016776] [Batch 00316/00823] [00:03:59/00:06:24, 0.758s/it]: train_loss_raw=1.1215, running_loss=1.0956, LR=0.000100
[2025-08-26 12:08:10,055][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016784] [Batch 00324/00823] [00:04:05/00:06:18, 0.758s/it]: train_loss_raw=1.1124, running_loss=1.0995, LR=0.000100
[2025-08-26 12:08:16,110][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016792] [Batch 00332/00823] [00:04:11/00:06:12, 0.758s/it]: train_loss_raw=0.9868, running_loss=1.0964, LR=0.000100
[2025-08-26 12:08:22,181][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016800] [Batch 00340/00823] [00:04:17/00:06:06, 0.758s/it]: train_loss_raw=1.1207, running_loss=1.0976, LR=0.000100
[2025-08-26 12:08:28,284][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016808] [Batch 00348/00823] [00:04:23/00:06:00, 0.758s/it]: train_loss_raw=1.0216, running_loss=1.0986, LR=0.000100
[2025-08-26 12:08:34,320][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016816] [Batch 00356/00823] [00:04:29/00:05:54, 0.758s/it]: train_loss_raw=1.1219, running_loss=1.1005, LR=0.000100
[2025-08-26 12:08:40,386][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016824] [Batch 00364/00823] [00:04:35/00:05:47, 0.758s/it]: train_loss_raw=1.1603, running_loss=1.1025, LR=0.000100
[2025-08-26 12:08:46,481][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016832] [Batch 00372/00823] [00:04:42/00:05:41, 0.758s/it]: train_loss_raw=1.1350, running_loss=1.0998, LR=0.000100
[2025-08-26 12:08:52,515][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016840] [Batch 00380/00823] [00:04:48/00:05:35, 0.758s/it]: train_loss_raw=1.2165, running_loss=1.1012, LR=0.000100
[2025-08-26 12:08:58,584][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016848] [Batch 00388/00823] [00:04:54/00:05:29, 0.758s/it]: train_loss_raw=1.0846, running_loss=1.0970, LR=0.000100
[2025-08-26 12:09:04,681][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016856] [Batch 00396/00823] [00:05:00/00:05:23, 0.758s/it]: train_loss_raw=1.1411, running_loss=1.0972, LR=0.000100
[2025-08-26 12:09:10,737][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016864] [Batch 00404/00823] [00:05:06/00:05:17, 0.758s/it]: train_loss_raw=0.9514, running_loss=1.0968, LR=0.000100
[2025-08-26 12:09:16,753][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016872] [Batch 00412/00823] [00:05:12/00:05:11, 0.758s/it]: train_loss_raw=1.0955, running_loss=1.0973, LR=0.000100
[2025-08-26 12:09:22,791][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016880] [Batch 00420/00823] [00:05:18/00:05:05, 0.758s/it]: train_loss_raw=1.0940, running_loss=1.0987, LR=0.000100
[2025-08-26 12:09:28,863][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016888] [Batch 00428/00823] [00:05:24/00:04:59, 0.758s/it]: train_loss_raw=1.0363, running_loss=1.0978, LR=0.000100
[2025-08-26 12:09:34,953][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016896] [Batch 00436/00823] [00:05:30/00:04:53, 0.758s/it]: train_loss_raw=1.0645, running_loss=1.0957, LR=0.000100
[2025-08-26 12:09:41,014][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016904] [Batch 00444/00823] [00:05:36/00:04:47, 0.758s/it]: train_loss_raw=1.1841, running_loss=1.0960, LR=0.000100
[2025-08-26 12:09:47,122][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016912] [Batch 00452/00823] [00:05:42/00:04:41, 0.758s/it]: train_loss_raw=1.0231, running_loss=1.0963, LR=0.000100
[2025-08-26 12:09:53,330][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016920] [Batch 00460/00823] [00:05:48/00:04:35, 0.758s/it]: train_loss_raw=1.1180, running_loss=1.0999, LR=0.000100
[2025-08-26 12:09:59,388][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016928] [Batch 00468/00823] [00:05:54/00:04:29, 0.758s/it]: train_loss_raw=0.9956, running_loss=1.0992, LR=0.000100
[2025-08-26 12:10:05,492][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016936] [Batch 00476/00823] [00:06:01/00:04:23, 0.759s/it]: train_loss_raw=1.1753, running_loss=1.0991, LR=0.000100
[2025-08-26 12:10:11,559][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016944] [Batch 00484/00823] [00:06:07/00:04:17, 0.759s/it]: train_loss_raw=1.1672, running_loss=1.0987, LR=0.000100
[2025-08-26 12:10:17,677][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016952] [Batch 00492/00823] [00:06:13/00:04:11, 0.759s/it]: train_loss_raw=1.0520, running_loss=1.0989, LR=0.000100
[2025-08-26 12:10:23,793][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016960] [Batch 00500/00823] [00:06:19/00:04:05, 0.759s/it]: train_loss_raw=1.0170, running_loss=1.0999, LR=0.000100
[2025-08-26 12:10:29,940][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016968] [Batch 00508/00823] [00:06:25/00:03:59, 0.759s/it]: train_loss_raw=1.0655, running_loss=1.0976, LR=0.000100
[2025-08-26 12:10:36,044][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016976] [Batch 00516/00823] [00:06:31/00:03:52, 0.759s/it]: train_loss_raw=1.0572, running_loss=1.0980, LR=0.000100
[2025-08-26 12:10:42,145][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016984] [Batch 00524/00823] [00:06:37/00:03:46, 0.759s/it]: train_loss_raw=1.1652, running_loss=1.0975, LR=0.000100
[2025-08-26 12:10:48,238][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016992] [Batch 00532/00823] [00:06:43/00:03:40, 0.759s/it]: train_loss_raw=1.0288, running_loss=1.0966, LR=0.000100
[2025-08-26 12:10:54,298][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017000] [Batch 00540/00823] [00:06:49/00:03:34, 0.759s/it]: train_loss_raw=1.0221, running_loss=1.0973, LR=0.000100
[2025-08-26 12:11:00,351][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017008] [Batch 00548/00823] [00:06:55/00:03:28, 0.759s/it]: train_loss_raw=1.0991, running_loss=1.0970, LR=0.000100
[2025-08-26 12:11:06,368][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017016] [Batch 00556/00823] [00:07:01/00:03:22, 0.759s/it]: train_loss_raw=1.1527, running_loss=1.1007, LR=0.000100
[2025-08-26 12:11:12,430][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017024] [Batch 00564/00823] [00:07:07/00:03:16, 0.759s/it]: train_loss_raw=1.0377, running_loss=1.1003, LR=0.000100
[2025-08-26 12:11:18,510][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017032] [Batch 00572/00823] [00:07:14/00:03:10, 0.759s/it]: train_loss_raw=1.0460, running_loss=1.0993, LR=0.000100
[2025-08-26 12:11:24,636][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017040] [Batch 00580/00823] [00:07:20/00:03:04, 0.759s/it]: train_loss_raw=1.0786, running_loss=1.1015, LR=0.000100
[2025-08-26 12:11:30,753][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017048] [Batch 00588/00823] [00:07:26/00:02:58, 0.759s/it]: train_loss_raw=1.1619, running_loss=1.0991, LR=0.000100
[2025-08-26 12:11:36,824][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017056] [Batch 00596/00823] [00:07:32/00:02:52, 0.759s/it]: train_loss_raw=1.1298, running_loss=1.0998, LR=0.000100
[2025-08-26 12:11:42,897][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017064] [Batch 00604/00823] [00:07:38/00:02:46, 0.759s/it]: train_loss_raw=1.0689, running_loss=1.1001, LR=0.000100
[2025-08-26 12:11:48,966][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017072] [Batch 00612/00823] [00:07:44/00:02:40, 0.759s/it]: train_loss_raw=1.1570, running_loss=1.1009, LR=0.000100
[2025-08-26 12:11:55,061][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017080] [Batch 00620/00823] [00:07:50/00:02:34, 0.759s/it]: train_loss_raw=1.1549, running_loss=1.1038, LR=0.000100
[2025-08-26 12:12:01,166][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017088] [Batch 00628/00823] [00:07:56/00:02:28, 0.759s/it]: train_loss_raw=1.1048, running_loss=1.1023, LR=0.000100
[2025-08-26 12:12:07,258][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017096] [Batch 00636/00823] [00:08:02/00:02:21, 0.759s/it]: train_loss_raw=1.1144, running_loss=1.1032, LR=0.000100
[2025-08-26 12:12:13,346][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017104] [Batch 00644/00823] [00:08:08/00:02:15, 0.759s/it]: train_loss_raw=1.1693, running_loss=1.1039, LR=0.000100
[2025-08-26 12:12:19,486][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017112] [Batch 00652/00823] [00:08:15/00:02:09, 0.759s/it]: train_loss_raw=1.1641, running_loss=1.1038, LR=0.000100
[2025-08-26 12:12:25,593][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017120] [Batch 00660/00823] [00:08:21/00:02:03, 0.759s/it]: train_loss_raw=1.1140, running_loss=1.1018, LR=0.000100
[2025-08-26 12:12:31,628][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017128] [Batch 00668/00823] [00:08:27/00:01:57, 0.759s/it]: train_loss_raw=1.0664, running_loss=1.1020, LR=0.000100
[2025-08-26 12:12:37,663][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017136] [Batch 00676/00823] [00:08:33/00:01:51, 0.759s/it]: train_loss_raw=1.0643, running_loss=1.0986, LR=0.000100
[2025-08-26 12:12:43,814][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017144] [Batch 00684/00823] [00:08:39/00:01:45, 0.759s/it]: train_loss_raw=1.0971, running_loss=1.0982, LR=0.000100
[2025-08-26 12:12:49,787][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017152] [Batch 00692/00823] [00:08:45/00:01:39, 0.759s/it]: train_loss_raw=0.9728, running_loss=1.0933, LR=0.000100
[2025-08-26 12:12:55,881][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017160] [Batch 00700/00823] [00:08:51/00:01:33, 0.759s/it]: train_loss_raw=1.0258, running_loss=1.0952, LR=0.000100
[2025-08-26 12:13:01,998][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017168] [Batch 00708/00823] [00:08:57/00:01:27, 0.759s/it]: train_loss_raw=1.0522, running_loss=1.0964, LR=0.000100
[2025-08-26 12:13:08,100][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017176] [Batch 00716/00823] [00:09:03/00:01:21, 0.759s/it]: train_loss_raw=1.0124, running_loss=1.0958, LR=0.000100
[2025-08-26 12:13:14,140][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017184] [Batch 00724/00823] [00:09:09/00:01:15, 0.759s/it]: train_loss_raw=1.0764, running_loss=1.0972, LR=0.000100
[2025-08-26 12:13:20,154][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017192] [Batch 00732/00823] [00:09:15/00:01:09, 0.759s/it]: train_loss_raw=1.1736, running_loss=1.0984, LR=0.000100
[2025-08-26 12:13:26,224][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017200] [Batch 00740/00823] [00:09:21/00:01:03, 0.759s/it]: train_loss_raw=1.1156, running_loss=1.0968, LR=0.000100
[2025-08-26 12:13:32,407][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017208] [Batch 00748/00823] [00:09:27/00:00:56, 0.759s/it]: train_loss_raw=1.1335, running_loss=1.0966, LR=0.000100
[2025-08-26 12:13:38,935][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017216] [Batch 00756/00823] [00:09:34/00:00:50, 0.760s/it]: train_loss_raw=1.1133, running_loss=1.0989, LR=0.000100
[2025-08-26 12:13:45,061][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017224] [Batch 00764/00823] [00:09:40/00:00:44, 0.760s/it]: train_loss_raw=1.0722, running_loss=1.0972, LR=0.000100
[2025-08-26 12:13:51,093][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017232] [Batch 00772/00823] [00:09:46/00:00:38, 0.760s/it]: train_loss_raw=1.0036, running_loss=1.0961, LR=0.000100
[2025-08-26 12:13:57,085][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017240] [Batch 00780/00823] [00:09:52/00:00:32, 0.760s/it]: train_loss_raw=1.1872, running_loss=1.0962, LR=0.000100
[2025-08-26 12:14:03,317][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017248] [Batch 00788/00823] [00:09:58/00:00:26, 0.760s/it]: train_loss_raw=0.9808, running_loss=1.0940, LR=0.000100
[2025-08-26 12:14:09,456][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017256] [Batch 00796/00823] [00:10:05/00:00:20, 0.760s/it]: train_loss_raw=1.0955, running_loss=1.0942, LR=0.000100
[2025-08-26 12:14:15,557][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017264] [Batch 00804/00823] [00:10:11/00:00:14, 0.760s/it]: train_loss_raw=1.1220, running_loss=1.0952, LR=0.000100
[2025-08-26 12:14:21,602][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017272] [Batch 00812/00823] [00:10:17/00:00:08, 0.760s/it]: train_loss_raw=1.1470, running_loss=1.0989, LR=0.000100
[2025-08-26 12:14:27,720][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017280] [Batch 00820/00823] [00:10:23/00:00:02, 0.760s/it]: train_loss_raw=1.1294, running_loss=1.0996, LR=0.000100
[2025-08-26 12:14:30,217][__main__][INFO] - [VALIDATION] [Epoch 20/29] Starting validation.
[2025-08-26 12:14:41,202][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 017284] [Batch 00007/00013] [00:00:10/00:00:06, 1.373s/it]
[2025-08-26 12:14:48,446][__main__][INFO] - [VALIDATION] [Epoch 20/29] train_loss=1.10008, valid_loss=1.36826
[2025-08-26 12:14:48,446][__main__][INFO] - [VALIDATION] [Epoch 20/29] Metrics:
[2025-08-26 12:14:48,446][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_er      0.589
[2025-08-26 12:14:48,446][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_prec    0.075
[2025-08-26 12:14:48,446][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_recall  0.077
[2025-08-26 12:14:48,447][__main__][INFO] - [VALIDATION] [Epoch 20/29] - pep_recall 0.036
[2025-08-26 12:14:48,449][__main__][INFO] - [TRAIN] [Epoch 20/29] Epoch complete, total time 03:42:12, remaining time 01:35:13, 00:10:34 per epoch
[2025-08-26 12:14:51,896][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017288] [Batch 00005/00823] [00:00:03/00:08:43, 0.640s/it]: train_loss_raw=1.0716, running_loss=1.2003, LR=0.000100
[2025-08-26 12:14:57,924][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017296] [Batch 00013/00823] [00:00:09/00:09:35, 0.710s/it]: train_loss_raw=1.1266, running_loss=1.1948, LR=0.000100
[2025-08-26 12:15:03,958][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017304] [Batch 00021/00823] [00:00:15/00:09:42, 0.727s/it]: train_loss_raw=1.1026, running_loss=1.1880, LR=0.000100
[2025-08-26 12:15:10,005][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017312] [Batch 00029/00823] [00:00:21/00:09:43, 0.735s/it]: train_loss_raw=1.0821, running_loss=1.1813, LR=0.000100
[2025-08-26 12:15:16,383][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017320] [Batch 00037/00823] [00:00:27/00:09:48, 0.748s/it]: train_loss_raw=1.1581, running_loss=1.1722, LR=0.000100
[2025-08-26 12:15:22,424][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017328] [Batch 00045/00823] [00:00:33/00:09:43, 0.750s/it]: train_loss_raw=1.1114, running_loss=1.1655, LR=0.000100
[2025-08-26 12:15:28,440][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017336] [Batch 00053/00823] [00:00:39/00:09:37, 0.750s/it]: train_loss_raw=1.1440, running_loss=1.1588, LR=0.000100
[2025-08-26 12:15:34,469][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017344] [Batch 00061/00823] [00:00:45/00:09:31, 0.750s/it]: train_loss_raw=1.0619, running_loss=1.1546, LR=0.000100
[2025-08-26 12:15:40,480][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017352] [Batch 00069/00823] [00:00:51/00:09:25, 0.751s/it]: train_loss_raw=1.0374, running_loss=1.1516, LR=0.000100
[2025-08-26 12:15:46,576][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017360] [Batch 00077/00823] [00:00:57/00:09:20, 0.752s/it]: train_loss_raw=1.0897, running_loss=1.1481, LR=0.000100
[2025-08-26 12:15:52,728][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017368] [Batch 00085/00823] [00:01:04/00:09:15, 0.753s/it]: train_loss_raw=1.1714, running_loss=1.1425, LR=0.000100
[2025-08-26 12:15:58,797][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017376] [Batch 00093/00823] [00:01:10/00:09:10, 0.754s/it]: train_loss_raw=1.0978, running_loss=1.1386, LR=0.000100
[2025-08-26 12:16:04,823][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017384] [Batch 00101/00823] [00:01:16/00:09:04, 0.754s/it]: train_loss_raw=1.2403, running_loss=1.1380, LR=0.000100
[2025-08-26 12:16:10,953][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017392] [Batch 00109/00823] [00:01:22/00:08:58, 0.755s/it]: train_loss_raw=1.1089, running_loss=1.1378, LR=0.000100
[2025-08-26 12:16:17,014][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017400] [Batch 00117/00823] [00:01:28/00:08:52, 0.755s/it]: train_loss_raw=1.1458, running_loss=1.1361, LR=0.000100
[2025-08-26 12:16:23,020][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017408] [Batch 00125/00823] [00:01:34/00:08:46, 0.755s/it]: train_loss_raw=0.9710, running_loss=1.1337, LR=0.000100
[2025-08-26 12:16:29,117][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017416] [Batch 00133/00823] [00:01:40/00:08:40, 0.755s/it]: train_loss_raw=1.0058, running_loss=1.1329, LR=0.000100
[2025-08-26 12:16:35,167][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017424] [Batch 00141/00823] [00:01:46/00:08:35, 0.755s/it]: train_loss_raw=1.1513, running_loss=1.1325, LR=0.000100
[2025-08-26 12:16:41,269][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017432] [Batch 00149/00823] [00:01:52/00:08:29, 0.756s/it]: train_loss_raw=1.1760, running_loss=1.1291, LR=0.000100
[2025-08-26 12:16:47,333][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017440] [Batch 00157/00823] [00:01:58/00:08:23, 0.756s/it]: train_loss_raw=1.0885, running_loss=1.1263, LR=0.000100
[2025-08-26 12:16:53,390][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017448] [Batch 00165/00823] [00:02:04/00:08:17, 0.756s/it]: train_loss_raw=1.0983, running_loss=1.1235, LR=0.000100
[2025-08-26 12:16:59,402][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017456] [Batch 00173/00823] [00:02:10/00:08:11, 0.756s/it]: train_loss_raw=1.0272, running_loss=1.1180, LR=0.000100
[2025-08-26 12:17:05,489][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017464] [Batch 00181/00823] [00:02:16/00:08:05, 0.756s/it]: train_loss_raw=1.0589, running_loss=1.1173, LR=0.000100
[2025-08-26 12:17:11,559][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017472] [Batch 00189/00823] [00:02:22/00:07:59, 0.756s/it]: train_loss_raw=0.9814, running_loss=1.1140, LR=0.000100
[2025-08-26 12:17:17,616][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017480] [Batch 00197/00823] [00:02:28/00:07:53, 0.756s/it]: train_loss_raw=1.0892, running_loss=1.1127, LR=0.000100
[2025-08-26 12:17:23,736][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017488] [Batch 00205/00823] [00:02:35/00:07:47, 0.756s/it]: train_loss_raw=1.0980, running_loss=1.1105, LR=0.000100
[2025-08-26 12:17:29,836][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017496] [Batch 00213/00823] [00:02:41/00:07:41, 0.757s/it]: train_loss_raw=1.1360, running_loss=1.1081, LR=0.000100
[2025-08-26 12:17:36,011][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017504] [Batch 00221/00823] [00:02:47/00:07:35, 0.757s/it]: train_loss_raw=1.0596, running_loss=1.1064, LR=0.000100
[2025-08-26 12:17:42,087][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017512] [Batch 00229/00823] [00:02:53/00:07:29, 0.757s/it]: train_loss_raw=1.0483, running_loss=1.1029, LR=0.000100
[2025-08-26 12:17:48,115][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017520] [Batch 00237/00823] [00:02:59/00:07:23, 0.757s/it]: train_loss_raw=1.0777, running_loss=1.1045, LR=0.000100
[2025-08-26 12:17:54,169][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017528] [Batch 00245/00823] [00:03:05/00:07:17, 0.757s/it]: train_loss_raw=1.0728, running_loss=1.1044, LR=0.000100
[2025-08-26 12:18:00,242][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017536] [Batch 00253/00823] [00:03:11/00:07:11, 0.757s/it]: train_loss_raw=1.1197, running_loss=1.1035, LR=0.000100
[2025-08-26 12:18:06,325][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017544] [Batch 00261/00823] [00:03:17/00:07:05, 0.757s/it]: train_loss_raw=1.0361, running_loss=1.1029, LR=0.000100
[2025-08-26 12:18:12,387][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017552] [Batch 00269/00823] [00:03:23/00:06:59, 0.757s/it]: train_loss_raw=1.1682, running_loss=1.1026, LR=0.000100
[2025-08-26 12:18:18,432][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017560] [Batch 00277/00823] [00:03:29/00:06:53, 0.757s/it]: train_loss_raw=1.1058, running_loss=1.1018, LR=0.000100
[2025-08-26 12:18:24,504][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017568] [Batch 00285/00823] [00:03:35/00:06:47, 0.757s/it]: train_loss_raw=1.1589, running_loss=1.1029, LR=0.000100
[2025-08-26 12:18:30,564][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017576] [Batch 00293/00823] [00:03:41/00:06:41, 0.757s/it]: train_loss_raw=1.1172, running_loss=1.1014, LR=0.000100
[2025-08-26 12:18:36,604][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017584] [Batch 00301/00823] [00:03:47/00:06:35, 0.757s/it]: train_loss_raw=1.1235, running_loss=1.0995, LR=0.000100
[2025-08-26 12:18:42,646][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017592] [Batch 00309/00823] [00:03:53/00:06:29, 0.757s/it]: train_loss_raw=1.0972, running_loss=1.0984, LR=0.000100
[2025-08-26 12:18:48,734][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017600] [Batch 00317/00823] [00:04:00/00:06:23, 0.757s/it]: train_loss_raw=1.0614, running_loss=1.0968, LR=0.000100
[2025-08-26 12:18:54,744][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017608] [Batch 00325/00823] [00:04:06/00:06:17, 0.757s/it]: train_loss_raw=1.1328, running_loss=1.0968, LR=0.000100
[2025-08-26 12:19:00,816][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017616] [Batch 00333/00823] [00:04:12/00:06:10, 0.757s/it]: train_loss_raw=1.0804, running_loss=1.0956, LR=0.000100
[2025-08-26 12:19:06,849][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017624] [Batch 00341/00823] [00:04:18/00:06:04, 0.757s/it]: train_loss_raw=1.0870, running_loss=1.0943, LR=0.000100
[2025-08-26 12:19:12,999][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017632] [Batch 00349/00823] [00:04:24/00:05:58, 0.757s/it]: train_loss_raw=1.0818, running_loss=1.0968, LR=0.000100
[2025-08-26 12:19:19,046][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017640] [Batch 00357/00823] [00:04:30/00:05:52, 0.757s/it]: train_loss_raw=1.0376, running_loss=1.0959, LR=0.000100
[2025-08-26 12:19:25,094][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017648] [Batch 00365/00823] [00:04:36/00:05:46, 0.757s/it]: train_loss_raw=1.0752, running_loss=1.0965, LR=0.000100
[2025-08-26 12:19:31,134][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017656] [Batch 00373/00823] [00:04:42/00:05:40, 0.757s/it]: train_loss_raw=1.0849, running_loss=1.0958, LR=0.000100
[2025-08-26 12:19:37,186][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017664] [Batch 00381/00823] [00:04:48/00:05:34, 0.757s/it]: train_loss_raw=1.0942, running_loss=1.0930, LR=0.000100
[2025-08-26 12:19:43,291][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017672] [Batch 00389/00823] [00:04:54/00:05:28, 0.757s/it]: train_loss_raw=1.1001, running_loss=1.0917, LR=0.000100
[2025-08-26 12:19:49,387][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017680] [Batch 00397/00823] [00:05:00/00:05:22, 0.757s/it]: train_loss_raw=1.1185, running_loss=1.0936, LR=0.000100
[2025-08-26 12:19:55,499][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017688] [Batch 00405/00823] [00:05:06/00:05:16, 0.758s/it]: train_loss_raw=1.1435, running_loss=1.0966, LR=0.000100
[2025-08-26 12:20:01,585][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017696] [Batch 00413/00823] [00:05:12/00:05:10, 0.758s/it]: train_loss_raw=1.1280, running_loss=1.0973, LR=0.000100
[2025-08-26 12:20:07,654][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017704] [Batch 00421/00823] [00:05:18/00:05:04, 0.758s/it]: train_loss_raw=1.0723, running_loss=1.0968, LR=0.000100
[2025-08-26 12:20:13,725][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017712] [Batch 00429/00823] [00:05:25/00:04:58, 0.758s/it]: train_loss_raw=1.0158, running_loss=1.0930, LR=0.000100
[2025-08-26 12:20:19,792][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017720] [Batch 00437/00823] [00:05:31/00:04:52, 0.758s/it]: train_loss_raw=1.1059, running_loss=1.0931, LR=0.000100
[2025-08-26 12:20:25,853][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017728] [Batch 00445/00823] [00:05:37/00:04:46, 0.758s/it]: train_loss_raw=1.1173, running_loss=1.0913, LR=0.000100
[2025-08-26 12:20:31,989][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017736] [Batch 00453/00823] [00:05:43/00:04:40, 0.758s/it]: train_loss_raw=1.1567, running_loss=1.0934, LR=0.000100
[2025-08-26 12:20:38,066][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017744] [Batch 00461/00823] [00:05:49/00:04:34, 0.758s/it]: train_loss_raw=1.1749, running_loss=1.0925, LR=0.000100
[2025-08-26 12:20:44,170][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017752] [Batch 00469/00823] [00:05:55/00:04:28, 0.758s/it]: train_loss_raw=1.0277, running_loss=1.0917, LR=0.000100
[2025-08-26 12:20:50,262][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017760] [Batch 00477/00823] [00:06:01/00:04:22, 0.758s/it]: train_loss_raw=1.1828, running_loss=1.0936, LR=0.000100
[2025-08-26 12:20:56,317][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017768] [Batch 00485/00823] [00:06:07/00:04:16, 0.758s/it]: train_loss_raw=1.0383, running_loss=1.0932, LR=0.000100
[2025-08-26 12:21:02,361][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017776] [Batch 00493/00823] [00:06:13/00:04:10, 0.758s/it]: train_loss_raw=1.0999, running_loss=1.0914, LR=0.000100
[2025-08-26 12:21:08,458][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017784] [Batch 00501/00823] [00:06:19/00:04:04, 0.758s/it]: train_loss_raw=1.0847, running_loss=1.0902, LR=0.000100
[2025-08-26 12:21:14,493][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017792] [Batch 00509/00823] [00:06:25/00:03:57, 0.758s/it]: train_loss_raw=1.0403, running_loss=1.0880, LR=0.000100
[2025-08-26 12:21:20,537][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017800] [Batch 00517/00823] [00:06:31/00:03:51, 0.758s/it]: train_loss_raw=1.0773, running_loss=1.0862, LR=0.000100
[2025-08-26 12:21:26,628][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017808] [Batch 00525/00823] [00:06:37/00:03:45, 0.758s/it]: train_loss_raw=1.1330, running_loss=1.0873, LR=0.000100
[2025-08-26 12:21:32,680][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017816] [Batch 00533/00823] [00:06:43/00:03:39, 0.758s/it]: train_loss_raw=1.0400, running_loss=1.0855, LR=0.000100
[2025-08-26 12:21:38,744][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017824] [Batch 00541/00823] [00:06:50/00:03:33, 0.758s/it]: train_loss_raw=1.0632, running_loss=1.0854, LR=0.000100
[2025-08-26 12:21:44,841][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017832] [Batch 00549/00823] [00:06:56/00:03:27, 0.758s/it]: train_loss_raw=1.1669, running_loss=1.0862, LR=0.000100
[2025-08-26 12:21:50,853][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017840] [Batch 00557/00823] [00:07:02/00:03:21, 0.758s/it]: train_loss_raw=1.0191, running_loss=1.0858, LR=0.000100
[2025-08-26 12:21:56,980][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017848] [Batch 00565/00823] [00:07:08/00:03:15, 0.758s/it]: train_loss_raw=1.0327, running_loss=1.0853, LR=0.000100
[2025-08-26 12:22:03,000][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017856] [Batch 00573/00823] [00:07:14/00:03:09, 0.758s/it]: train_loss_raw=1.0232, running_loss=1.0812, LR=0.000100
[2025-08-26 12:22:09,073][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017864] [Batch 00581/00823] [00:07:20/00:03:03, 0.758s/it]: train_loss_raw=1.0017, running_loss=1.0839, LR=0.000100
[2025-08-26 12:22:15,142][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017872] [Batch 00589/00823] [00:07:26/00:02:57, 0.758s/it]: train_loss_raw=1.1536, running_loss=1.0870, LR=0.000100
[2025-08-26 12:22:21,228][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017880] [Batch 00597/00823] [00:07:32/00:02:51, 0.758s/it]: train_loss_raw=1.1078, running_loss=1.0873, LR=0.000100
[2025-08-26 12:22:27,323][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017888] [Batch 00605/00823] [00:07:38/00:02:45, 0.758s/it]: train_loss_raw=1.1799, running_loss=1.0879, LR=0.000100
[2025-08-26 12:22:33,372][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017896] [Batch 00613/00823] [00:07:44/00:02:39, 0.758s/it]: train_loss_raw=1.2574, running_loss=1.0907, LR=0.000100
[2025-08-26 12:22:39,403][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017904] [Batch 00621/00823] [00:07:50/00:02:33, 0.758s/it]: train_loss_raw=1.0855, running_loss=1.0892, LR=0.000100
[2025-08-26 12:22:45,440][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017912] [Batch 00629/00823] [00:07:56/00:02:27, 0.758s/it]: train_loss_raw=1.1115, running_loss=1.0914, LR=0.000100
[2025-08-26 12:22:51,514][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017920] [Batch 00637/00823] [00:08:02/00:02:20, 0.758s/it]: train_loss_raw=1.1410, running_loss=1.0924, LR=0.000100
[2025-08-26 12:22:57,530][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017928] [Batch 00645/00823] [00:08:08/00:02:14, 0.758s/it]: train_loss_raw=1.1151, running_loss=1.0920, LR=0.000100
[2025-08-26 12:23:03,527][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017936] [Batch 00653/00823] [00:08:14/00:02:08, 0.758s/it]: train_loss_raw=1.1287, running_loss=1.0919, LR=0.000100
[2025-08-26 12:23:09,564][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017944] [Batch 00661/00823] [00:08:20/00:02:02, 0.758s/it]: train_loss_raw=1.0588, running_loss=1.0912, LR=0.000100
[2025-08-26 12:23:15,659][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017952] [Batch 00669/00823] [00:08:26/00:01:56, 0.758s/it]: train_loss_raw=1.0274, running_loss=1.0885, LR=0.000100
[2025-08-26 12:23:21,692][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017960] [Batch 00677/00823] [00:08:32/00:01:50, 0.758s/it]: train_loss_raw=1.0459, running_loss=1.0882, LR=0.000100
[2025-08-26 12:23:27,729][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017968] [Batch 00685/00823] [00:08:39/00:01:44, 0.758s/it]: train_loss_raw=1.0660, running_loss=1.0900, LR=0.000100
[2025-08-26 12:23:33,835][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017976] [Batch 00693/00823] [00:08:45/00:01:38, 0.758s/it]: train_loss_raw=1.1039, running_loss=1.0888, LR=0.000100
[2025-08-26 12:23:39,855][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017984] [Batch 00701/00823] [00:08:51/00:01:32, 0.758s/it]: train_loss_raw=1.0541, running_loss=1.0889, LR=0.000100
[2025-08-26 12:23:45,907][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017992] [Batch 00709/00823] [00:08:57/00:01:26, 0.758s/it]: train_loss_raw=1.1883, running_loss=1.0887, LR=0.000100
[2025-08-26 12:23:51,933][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018000] [Batch 00717/00823] [00:09:03/00:01:20, 0.758s/it]: train_loss_raw=1.1307, running_loss=1.0910, LR=0.000100
[2025-08-26 12:24:02,932][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018008] [Batch 00725/00823] [00:09:14/00:01:14, 0.764s/it]: train_loss_raw=1.1975, running_loss=1.0931, LR=0.000100
[2025-08-26 12:24:09,144][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018016] [Batch 00733/00823] [00:09:20/00:01:08, 0.765s/it]: train_loss_raw=1.0764, running_loss=1.0912, LR=0.000100
[2025-08-26 12:24:15,288][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018024] [Batch 00741/00823] [00:09:26/00:01:02, 0.765s/it]: train_loss_raw=1.1220, running_loss=1.0913, LR=0.000100
[2025-08-26 12:24:21,378][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018032] [Batch 00749/00823] [00:09:32/00:00:56, 0.765s/it]: train_loss_raw=1.0275, running_loss=1.0910, LR=0.000100
[2025-08-26 12:24:27,486][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018040] [Batch 00757/00823] [00:09:38/00:00:50, 0.765s/it]: train_loss_raw=1.0415, running_loss=1.0880, LR=0.000100
[2025-08-26 12:24:33,525][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018048] [Batch 00765/00823] [00:09:44/00:00:44, 0.764s/it]: train_loss_raw=0.9925, running_loss=1.0838, LR=0.000100
[2025-08-26 12:24:39,569][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018056] [Batch 00773/00823] [00:09:50/00:00:38, 0.764s/it]: train_loss_raw=1.1387, running_loss=1.0859, LR=0.000100
[2025-08-26 12:24:45,671][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018064] [Batch 00781/00823] [00:09:56/00:00:32, 0.764s/it]: train_loss_raw=1.0337, running_loss=1.0830, LR=0.000100
[2025-08-26 12:24:51,724][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018072] [Batch 00789/00823] [00:10:03/00:00:25, 0.764s/it]: train_loss_raw=1.1830, running_loss=1.0820, LR=0.000100
[2025-08-26 12:24:57,805][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018080] [Batch 00797/00823] [00:10:09/00:00:19, 0.764s/it]: train_loss_raw=1.1281, running_loss=1.0782, LR=0.000100
[2025-08-26 12:25:03,875][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018088] [Batch 00805/00823] [00:10:15/00:00:13, 0.764s/it]: train_loss_raw=1.0236, running_loss=1.0770, LR=0.000100
[2025-08-26 12:25:10,004][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018096] [Batch 00813/00823] [00:10:21/00:00:07, 0.764s/it]: train_loss_raw=1.0095, running_loss=1.0765, LR=0.000100
[2025-08-26 12:25:16,110][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018104] [Batch 00821/00823] [00:10:27/00:00:01, 0.764s/it]: train_loss_raw=0.9993, running_loss=1.0754, LR=0.000100
[2025-08-26 12:25:23,311][__main__][INFO] - [VALIDATION] [Epoch 21/29] Starting validation.
[2025-08-26 12:25:33,849][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 018107] [Batch 00007/00013] [00:00:10/00:00:06, 1.317s/it]
[2025-08-26 12:25:40,763][__main__][INFO] - [VALIDATION] [Epoch 21/29] train_loss=1.07464, valid_loss=1.35052
[2025-08-26 12:25:40,763][__main__][INFO] - [VALIDATION] [Epoch 21/29] Metrics:
[2025-08-26 12:25:40,763][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_er      0.567
[2025-08-26 12:25:40,763][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_prec    0.078
[2025-08-26 12:25:40,764][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_recall  0.079
[2025-08-26 12:25:40,764][__main__][INFO] - [VALIDATION] [Epoch 21/29] - pep_recall 0.034
[2025-08-26 12:25:40,766][__main__][INFO] - [TRAIN] [Epoch 21/29] Epoch complete, total time 03:53:04, remaining time 01:24:45, 00:10:35 per epoch
[2025-08-26 12:25:44,928][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018112] [Batch 00006/00823] [00:00:03/00:08:56, 0.656s/it]: train_loss_raw=1.0255, running_loss=1.0148, LR=0.000100
[2025-08-26 12:25:51,003][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018120] [Batch 00014/00823] [00:00:10/00:09:38, 0.715s/it]: train_loss_raw=1.0286, running_loss=1.0168, LR=0.000100
[2025-08-26 12:25:57,166][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018128] [Batch 00022/00823] [00:00:16/00:09:48, 0.735s/it]: train_loss_raw=1.0431, running_loss=1.0169, LR=0.000100
[2025-08-26 12:26:03,235][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018136] [Batch 00030/00823] [00:00:22/00:09:48, 0.741s/it]: train_loss_raw=1.0291, running_loss=1.0193, LR=0.000100
[2025-08-26 12:26:09,352][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018144] [Batch 00038/00823] [00:00:28/00:09:45, 0.746s/it]: train_loss_raw=1.0667, running_loss=1.0237, LR=0.000100
[2025-08-26 12:26:15,196][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018152] [Batch 00046/00823] [00:00:34/00:09:37, 0.744s/it]: train_loss_raw=1.0280, running_loss=1.0221, LR=0.000100
[2025-08-26 12:26:20,999][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018160] [Batch 00054/00823] [00:00:40/00:09:29, 0.741s/it]: train_loss_raw=1.0476, running_loss=1.0237, LR=0.000100
[2025-08-26 12:26:26,733][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018168] [Batch 00062/00823] [00:00:45/00:09:21, 0.738s/it]: train_loss_raw=0.9552, running_loss=1.0257, LR=0.000100
[2025-08-26 12:26:32,540][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018176] [Batch 00070/00823] [00:00:51/00:09:14, 0.736s/it]: train_loss_raw=0.9408, running_loss=1.0229, LR=0.000100
[2025-08-26 12:26:38,161][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018184] [Batch 00078/00823] [00:00:57/00:09:06, 0.733s/it]: train_loss_raw=1.0564, running_loss=1.0242, LR=0.000100
[2025-08-26 12:26:43,831][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018192] [Batch 00086/00823] [00:01:02/00:08:58, 0.731s/it]: train_loss_raw=1.0871, running_loss=1.0266, LR=0.000100
[2025-08-26 12:26:49,464][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018200] [Batch 00094/00823] [00:01:08/00:08:51, 0.728s/it]: train_loss_raw=1.0332, running_loss=1.0285, LR=0.000100
[2025-08-26 12:26:55,338][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018208] [Batch 00102/00823] [00:01:14/00:08:45, 0.729s/it]: train_loss_raw=1.0000, running_loss=1.0279, LR=0.000100
[2025-08-26 12:27:01,430][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018216] [Batch 00110/00823] [00:01:20/00:08:41, 0.731s/it]: train_loss_raw=1.1165, running_loss=1.0322, LR=0.000100
[2025-08-26 12:27:07,557][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018224] [Batch 00118/00823] [00:01:26/00:08:37, 0.734s/it]: train_loss_raw=0.9589, running_loss=1.0325, LR=0.000100
[2025-08-26 12:27:13,621][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018232] [Batch 00126/00823] [00:01:32/00:08:32, 0.735s/it]: train_loss_raw=1.0450, running_loss=1.0299, LR=0.000100
[2025-08-26 12:27:19,763][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018240] [Batch 00134/00823] [00:01:38/00:08:27, 0.737s/it]: train_loss_raw=1.0317, running_loss=1.0295, LR=0.000100
[2025-08-26 12:27:25,894][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018248] [Batch 00142/00823] [00:01:44/00:08:23, 0.739s/it]: train_loss_raw=1.1752, running_loss=1.0310, LR=0.000100
[2025-08-26 12:27:31,965][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018256] [Batch 00150/00823] [00:01:50/00:08:17, 0.740s/it]: train_loss_raw=1.0808, running_loss=1.0300, LR=0.000100
[2025-08-26 12:27:38,031][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018264] [Batch 00158/00823] [00:01:57/00:08:12, 0.741s/it]: train_loss_raw=1.0089, running_loss=1.0311, LR=0.000100
[2025-08-26 12:27:44,039][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018272] [Batch 00166/00823] [00:02:03/00:08:07, 0.741s/it]: train_loss_raw=0.9656, running_loss=1.0319, LR=0.000100
[2025-08-26 12:27:50,116][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018280] [Batch 00174/00823] [00:02:09/00:08:01, 0.742s/it]: train_loss_raw=1.0051, running_loss=1.0319, LR=0.000100
[2025-08-26 12:27:56,158][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018288] [Batch 00182/00823] [00:02:15/00:07:56, 0.743s/it]: train_loss_raw=1.0288, running_loss=1.0325, LR=0.000100
[2025-08-26 12:28:02,181][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018296] [Batch 00190/00823] [00:02:21/00:07:50, 0.743s/it]: train_loss_raw=0.9315, running_loss=1.0324, LR=0.000100
[2025-08-26 12:28:08,315][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018304] [Batch 00198/00823] [00:02:27/00:07:45, 0.744s/it]: train_loss_raw=1.0118, running_loss=1.0329, LR=0.000100
[2025-08-26 12:28:14,287][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018312] [Batch 00206/00823] [00:02:33/00:07:39, 0.744s/it]: train_loss_raw=1.0360, running_loss=1.0299, LR=0.000100
[2025-08-26 12:28:20,302][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018320] [Batch 00214/00823] [00:02:39/00:07:33, 0.744s/it]: train_loss_raw=1.0838, running_loss=1.0325, LR=0.000100
[2025-08-26 12:28:26,381][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018328] [Batch 00222/00823] [00:02:45/00:07:27, 0.745s/it]: train_loss_raw=1.1216, running_loss=1.0301, LR=0.000100
[2025-08-26 12:28:32,521][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018336] [Batch 00230/00823] [00:02:51/00:07:22, 0.746s/it]: train_loss_raw=1.0084, running_loss=1.0293, LR=0.000100
[2025-08-26 12:28:38,506][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018344] [Batch 00238/00823] [00:02:57/00:07:16, 0.746s/it]: train_loss_raw=1.0776, running_loss=1.0312, LR=0.000100
[2025-08-26 12:28:44,515][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018352] [Batch 00246/00823] [00:03:03/00:07:10, 0.746s/it]: train_loss_raw=0.9496, running_loss=1.0292, LR=0.000100
[2025-08-26 12:28:50,554][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018360] [Batch 00254/00823] [00:03:09/00:07:04, 0.746s/it]: train_loss_raw=0.9397, running_loss=1.0243, LR=0.000100
[2025-08-26 12:28:56,579][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018368] [Batch 00262/00823] [00:03:15/00:06:58, 0.747s/it]: train_loss_raw=1.0732, running_loss=1.0236, LR=0.000100
[2025-08-26 12:29:02,671][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018376] [Batch 00270/00823] [00:03:21/00:06:53, 0.747s/it]: train_loss_raw=1.0496, running_loss=1.0268, LR=0.000100
[2025-08-26 12:29:08,729][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018384] [Batch 00278/00823] [00:03:27/00:06:47, 0.747s/it]: train_loss_raw=0.9890, running_loss=1.0260, LR=0.000100
[2025-08-26 12:29:14,942][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018392] [Batch 00286/00823] [00:03:33/00:06:41, 0.748s/it]: train_loss_raw=0.9798, running_loss=1.0262, LR=0.000100
[2025-08-26 12:29:21,038][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018400] [Batch 00294/00823] [00:03:40/00:06:35, 0.748s/it]: train_loss_raw=1.0695, running_loss=1.0271, LR=0.000100
[2025-08-26 12:29:27,031][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018408] [Batch 00302/00823] [00:03:46/00:06:29, 0.748s/it]: train_loss_raw=1.1303, running_loss=1.0287, LR=0.000100
[2025-08-26 12:29:32,833][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018416] [Batch 00310/00823] [00:03:51/00:06:23, 0.748s/it]: train_loss_raw=1.0508, running_loss=1.0286, LR=0.000100
[2025-08-26 12:29:38,596][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018424] [Batch 00318/00823] [00:03:57/00:06:17, 0.747s/it]: train_loss_raw=1.0487, running_loss=1.0274, LR=0.000100
[2025-08-26 12:29:44,478][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018432] [Batch 00326/00823] [00:04:03/00:06:11, 0.747s/it]: train_loss_raw=0.9890, running_loss=1.0269, LR=0.000100
[2025-08-26 12:29:50,426][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018440] [Batch 00334/00823] [00:04:09/00:06:05, 0.747s/it]: train_loss_raw=1.0354, running_loss=1.0264, LR=0.000100
[2025-08-26 12:29:56,223][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018448] [Batch 00342/00823] [00:04:15/00:05:58, 0.746s/it]: train_loss_raw=1.0565, running_loss=1.0270, LR=0.000100
[2025-08-26 12:30:02,283][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018456] [Batch 00350/00823] [00:04:21/00:05:53, 0.747s/it]: train_loss_raw=0.9941, running_loss=1.0264, LR=0.000100
[2025-08-26 12:30:08,356][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018464] [Batch 00358/00823] [00:04:27/00:05:47, 0.747s/it]: train_loss_raw=1.1457, running_loss=1.0299, LR=0.000100
[2025-08-26 12:30:14,426][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018472] [Batch 00366/00823] [00:04:33/00:05:41, 0.747s/it]: train_loss_raw=1.1088, running_loss=1.0302, LR=0.000100
[2025-08-26 12:30:20,545][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018480] [Batch 00374/00823] [00:04:39/00:05:35, 0.747s/it]: train_loss_raw=1.1271, running_loss=1.0291, LR=0.000100
[2025-08-26 12:30:26,701][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018488] [Batch 00382/00823] [00:04:45/00:05:29, 0.748s/it]: train_loss_raw=1.0660, running_loss=1.0283, LR=0.000100
[2025-08-26 12:30:32,959][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018496] [Batch 00390/00823] [00:04:51/00:05:24, 0.749s/it]: train_loss_raw=1.0038, running_loss=1.0297, LR=0.000100
[2025-08-26 12:30:39,378][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018504] [Batch 00398/00823] [00:04:58/00:05:18, 0.750s/it]: train_loss_raw=0.9776, running_loss=1.0290, LR=0.000100
[2025-08-26 12:30:45,682][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018512] [Batch 00406/00823] [00:05:04/00:05:12, 0.750s/it]: train_loss_raw=0.9788, running_loss=1.0284, LR=0.000100
[2025-08-26 12:30:51,917][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018520] [Batch 00414/00823] [00:05:10/00:05:07, 0.751s/it]: train_loss_raw=1.0551, running_loss=1.0288, LR=0.000100
[2025-08-26 12:30:57,997][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018528] [Batch 00422/00823] [00:05:17/00:05:01, 0.751s/it]: train_loss_raw=1.0749, running_loss=1.0263, LR=0.000100
[2025-08-26 12:31:04,031][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018536] [Batch 00430/00823] [00:05:23/00:04:55, 0.751s/it]: train_loss_raw=1.0098, running_loss=1.0252, LR=0.000100
[2025-08-26 12:31:10,298][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018544] [Batch 00438/00823] [00:05:29/00:04:49, 0.752s/it]: train_loss_raw=0.9955, running_loss=1.0260, LR=0.000100
[2025-08-26 12:31:16,570][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018552] [Batch 00446/00823] [00:05:35/00:04:43, 0.752s/it]: train_loss_raw=1.0912, running_loss=1.0308, LR=0.000100
[2025-08-26 12:31:22,979][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018560] [Batch 00454/00823] [00:05:41/00:04:37, 0.753s/it]: train_loss_raw=0.9912, running_loss=1.0308, LR=0.000100
[2025-08-26 12:31:29,091][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018568] [Batch 00462/00823] [00:05:48/00:04:32, 0.753s/it]: train_loss_raw=0.9895, running_loss=1.0298, LR=0.000100
[2025-08-26 12:31:35,178][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018576] [Batch 00470/00823] [00:05:54/00:04:26, 0.754s/it]: train_loss_raw=0.9822, running_loss=1.0295, LR=0.000100
[2025-08-26 12:31:41,668][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018584] [Batch 00478/00823] [00:06:00/00:04:20, 0.755s/it]: train_loss_raw=0.9051, running_loss=1.0298, LR=0.000100
[2025-08-26 12:31:48,375][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018592] [Batch 00486/00823] [00:06:07/00:04:14, 0.756s/it]: train_loss_raw=0.9437, running_loss=1.0296, LR=0.000100
[2025-08-26 12:31:54,755][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018600] [Batch 00494/00823] [00:06:13/00:04:08, 0.757s/it]: train_loss_raw=1.0436, running_loss=1.0307, LR=0.000100
[2025-08-26 12:32:01,178][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018608] [Batch 00502/00823] [00:06:20/00:04:03, 0.757s/it]: train_loss_raw=1.0571, running_loss=1.0300, LR=0.000100
[2025-08-26 12:32:07,503][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018616] [Batch 00510/00823] [00:06:26/00:03:57, 0.758s/it]: train_loss_raw=1.0561, running_loss=1.0304, LR=0.000100
[2025-08-26 12:32:13,580][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018624] [Batch 00518/00823] [00:06:32/00:03:51, 0.758s/it]: train_loss_raw=1.0676, running_loss=1.0309, LR=0.000100
[2025-08-26 12:32:20,119][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018632] [Batch 00526/00823] [00:06:39/00:03:45, 0.759s/it]: train_loss_raw=1.0985, running_loss=1.0351, LR=0.000100
[2025-08-26 12:32:26,271][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018640] [Batch 00534/00823] [00:06:45/00:03:39, 0.759s/it]: train_loss_raw=1.0002, running_loss=1.0347, LR=0.000100
[2025-08-26 12:32:32,672][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018648] [Batch 00542/00823] [00:06:51/00:03:33, 0.760s/it]: train_loss_raw=1.0574, running_loss=1.0326, LR=0.000100
[2025-08-26 12:32:38,929][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018656] [Batch 00550/00823] [00:06:57/00:03:27, 0.760s/it]: train_loss_raw=0.9850, running_loss=1.0316, LR=0.000100
[2025-08-26 12:32:45,070][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018664] [Batch 00558/00823] [00:07:04/00:03:21, 0.760s/it]: train_loss_raw=1.0018, running_loss=1.0330, LR=0.000100
[2025-08-26 12:32:51,247][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018672] [Batch 00566/00823] [00:07:10/00:03:15, 0.760s/it]: train_loss_raw=1.1384, running_loss=1.0338, LR=0.000100
[2025-08-26 12:32:57,468][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018680] [Batch 00574/00823] [00:07:16/00:03:09, 0.760s/it]: train_loss_raw=1.0260, running_loss=1.0331, LR=0.000100
[2025-08-26 12:33:03,637][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018688] [Batch 00582/00823] [00:07:22/00:03:03, 0.761s/it]: train_loss_raw=1.0746, running_loss=1.0354, LR=0.000100
[2025-08-26 12:33:09,926][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018696] [Batch 00590/00823] [00:07:28/00:02:57, 0.761s/it]: train_loss_raw=1.0945, running_loss=1.0354, LR=0.000100
[2025-08-26 12:33:16,421][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018704] [Batch 00598/00823] [00:07:35/00:02:51, 0.762s/it]: train_loss_raw=0.9905, running_loss=1.0342, LR=0.000100
[2025-08-26 12:33:23,001][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018712] [Batch 00606/00823] [00:07:42/00:02:45, 0.762s/it]: train_loss_raw=0.9793, running_loss=1.0323, LR=0.000100
[2025-08-26 12:33:29,351][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018720] [Batch 00614/00823] [00:07:48/00:02:39, 0.763s/it]: train_loss_raw=1.0873, running_loss=1.0332, LR=0.000100
[2025-08-26 12:33:35,928][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018728] [Batch 00622/00823] [00:07:54/00:02:33, 0.764s/it]: train_loss_raw=0.9484, running_loss=1.0315, LR=0.000100
[2025-08-26 12:33:42,204][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018736] [Batch 00630/00823] [00:08:01/00:02:27, 0.764s/it]: train_loss_raw=0.9180, running_loss=1.0288, LR=0.000100
[2025-08-26 12:33:48,332][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018744] [Batch 00638/00823] [00:08:07/00:02:21, 0.764s/it]: train_loss_raw=0.9369, running_loss=1.0290, LR=0.000100
[2025-08-26 12:33:54,677][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018752] [Batch 00646/00823] [00:08:13/00:02:15, 0.764s/it]: train_loss_raw=1.0708, running_loss=1.0294, LR=0.000100
[2025-08-26 12:34:00,987][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018760] [Batch 00654/00823] [00:08:19/00:02:09, 0.765s/it]: train_loss_raw=1.0179, running_loss=1.0284, LR=0.000100
[2025-08-26 12:34:07,575][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018768] [Batch 00662/00823] [00:08:26/00:02:03, 0.765s/it]: train_loss_raw=1.0897, running_loss=1.0281, LR=0.000100
[2025-08-26 12:34:13,877][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018776] [Batch 00670/00823] [00:08:32/00:01:57, 0.766s/it]: train_loss_raw=1.0622, running_loss=1.0317, LR=0.000100
[2025-08-26 12:34:20,117][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018784] [Batch 00678/00823] [00:08:39/00:01:51, 0.766s/it]: train_loss_raw=1.0226, running_loss=1.0306, LR=0.000100
[2025-08-26 12:34:26,296][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018792] [Batch 00686/00823] [00:08:45/00:01:44, 0.766s/it]: train_loss_raw=1.1583, running_loss=1.0315, LR=0.000100
[2025-08-26 12:34:32,622][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018800] [Batch 00694/00823] [00:08:51/00:01:38, 0.766s/it]: train_loss_raw=1.0212, running_loss=1.0277, LR=0.000100
[2025-08-26 12:34:38,899][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018808] [Batch 00702/00823] [00:08:57/00:01:32, 0.766s/it]: train_loss_raw=1.0424, running_loss=1.0279, LR=0.000100
[2025-08-26 12:34:45,442][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018816] [Batch 00710/00823] [00:09:04/00:01:26, 0.767s/it]: train_loss_raw=1.0264, running_loss=1.0289, LR=0.000100
[2025-08-26 12:34:51,567][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018824] [Batch 00718/00823] [00:09:10/00:01:20, 0.767s/it]: train_loss_raw=0.9791, running_loss=1.0301, LR=0.000100
[2025-08-26 12:34:57,872][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018832] [Batch 00726/00823] [00:09:16/00:01:14, 0.767s/it]: train_loss_raw=0.9914, running_loss=1.0288, LR=0.000100
[2025-08-26 12:35:04,093][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018840] [Batch 00734/00823] [00:09:23/00:01:08, 0.767s/it]: train_loss_raw=0.9964, running_loss=1.0275, LR=0.000100
[2025-08-26 12:35:10,396][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018848] [Batch 00742/00823] [00:09:29/00:01:02, 0.767s/it]: train_loss_raw=0.9790, running_loss=1.0287, LR=0.000100
[2025-08-26 12:35:16,547][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018856] [Batch 00750/00823] [00:09:35/00:00:56, 0.767s/it]: train_loss_raw=1.0035, running_loss=1.0278, LR=0.000100
[2025-08-26 12:35:22,575][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018864] [Batch 00758/00823] [00:09:41/00:00:49, 0.767s/it]: train_loss_raw=0.9785, running_loss=1.0272, LR=0.000100
[2025-08-26 12:35:28,848][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018872] [Batch 00766/00823] [00:09:47/00:00:43, 0.767s/it]: train_loss_raw=1.0442, running_loss=1.0293, LR=0.000100
[2025-08-26 12:35:35,138][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018880] [Batch 00774/00823] [00:09:54/00:00:37, 0.768s/it]: train_loss_raw=1.0789, running_loss=1.0293, LR=0.000100
[2025-08-26 12:35:41,483][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018888] [Batch 00782/00823] [00:10:00/00:00:31, 0.768s/it]: train_loss_raw=1.0845, running_loss=1.0288, LR=0.000100
[2025-08-26 12:35:47,393][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018896] [Batch 00790/00823] [00:10:06/00:00:25, 0.768s/it]: train_loss_raw=1.0072, running_loss=1.0278, LR=0.000100
[2025-08-26 12:35:53,448][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018904] [Batch 00798/00823] [00:10:12/00:00:19, 0.767s/it]: train_loss_raw=0.9808, running_loss=1.0272, LR=0.000100
[2025-08-26 12:35:59,362][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018912] [Batch 00806/00823] [00:10:18/00:00:13, 0.767s/it]: train_loss_raw=1.0698, running_loss=1.0286, LR=0.000100
[2025-08-26 12:36:05,190][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018920] [Batch 00814/00823] [00:10:24/00:00:06, 0.767s/it]: train_loss_raw=1.0205, running_loss=1.0282, LR=0.000100
[2025-08-26 12:36:11,159][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018928] [Batch 00822/00823] [00:10:30/00:00:00, 0.767s/it]: train_loss_raw=1.1233, running_loss=1.0288, LR=0.000100
[2025-08-26 12:36:12,138][__main__][INFO] - [VALIDATION] [Epoch 22/29] Starting validation.
[2025-08-26 12:36:23,776][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 018930] [Batch 00007/00013] [00:00:11/00:00:07, 1.455s/it]
[2025-08-26 12:36:31,168][__main__][INFO] - [VALIDATION] [Epoch 22/29] train_loss=1.02877, valid_loss=1.36699
[2025-08-26 12:36:31,169][__main__][INFO] - [VALIDATION] [Epoch 22/29] Metrics:
[2025-08-26 12:36:31,169][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_er      0.584
[2025-08-26 12:36:31,170][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_prec    0.071
[2025-08-26 12:36:31,170][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_recall  0.073
[2025-08-26 12:36:31,170][__main__][INFO] - [VALIDATION] [Epoch 22/29] - pep_recall 0.036
[2025-08-26 12:36:31,172][__main__][INFO] - [TRAIN] [Epoch 22/29] Epoch complete, total time 04:03:54, remaining time 01:14:14, 00:10:36 per epoch
[2025-08-26 12:36:36,464][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018936] [Batch 00007/00823] [00:00:05/00:09:47, 0.720s/it]: train_loss_raw=0.9072, running_loss=1.0396, LR=0.000100
[2025-08-26 12:36:42,663][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018944] [Batch 00015/00823] [00:00:11/00:10:05, 0.749s/it]: train_loss_raw=1.1144, running_loss=1.0402, LR=0.000100
[2025-08-26 12:36:48,772][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018952] [Batch 00023/00823] [00:00:17/00:10:03, 0.754s/it]: train_loss_raw=0.9647, running_loss=1.0395, LR=0.000100
[2025-08-26 12:36:54,654][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018960] [Batch 00031/00823] [00:00:23/00:09:53, 0.749s/it]: train_loss_raw=0.9153, running_loss=1.0359, LR=0.000100
[2025-08-26 12:37:00,674][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018968] [Batch 00039/00823] [00:00:29/00:09:48, 0.750s/it]: train_loss_raw=1.0673, running_loss=1.0363, LR=0.000100
[2025-08-26 12:37:06,741][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018976] [Batch 00047/00823] [00:00:35/00:09:43, 0.751s/it]: train_loss_raw=1.0970, running_loss=1.0386, LR=0.000100
[2025-08-26 12:37:13,049][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018984] [Batch 00055/00823] [00:00:41/00:09:41, 0.757s/it]: train_loss_raw=1.0122, running_loss=1.0366, LR=0.000100
[2025-08-26 12:37:19,064][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018992] [Batch 00063/00823] [00:00:47/00:09:34, 0.756s/it]: train_loss_raw=1.0791, running_loss=1.0347, LR=0.000100
[2025-08-26 12:37:25,402][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019000] [Batch 00071/00823] [00:00:53/00:09:31, 0.760s/it]: train_loss_raw=1.0487, running_loss=1.0364, LR=0.000100
[2025-08-26 12:37:32,039][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019008] [Batch 00079/00823] [00:01:00/00:09:30, 0.767s/it]: train_loss_raw=1.0661, running_loss=1.0365, LR=0.000100
[2025-08-26 12:37:38,178][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019016] [Batch 00087/00823] [00:01:06/00:09:24, 0.767s/it]: train_loss_raw=1.0511, running_loss=1.0363, LR=0.000100
[2025-08-26 12:37:43,877][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019024] [Batch 00095/00823] [00:01:12/00:09:15, 0.763s/it]: train_loss_raw=1.0644, running_loss=1.0376, LR=0.000100
[2025-08-26 12:37:49,668][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019032] [Batch 00103/00823] [00:01:18/00:09:06, 0.760s/it]: train_loss_raw=1.0582, running_loss=1.0389, LR=0.000100
[2025-08-26 12:37:55,442][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019040] [Batch 00111/00823] [00:01:24/00:08:58, 0.757s/it]: train_loss_raw=1.0949, running_loss=1.0371, LR=0.000100
[2025-08-26 12:38:01,272][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019048] [Batch 00119/00823] [00:01:29/00:08:51, 0.755s/it]: train_loss_raw=1.0387, running_loss=1.0339, LR=0.000100
[2025-08-26 12:38:07,183][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019056] [Batch 00127/00823] [00:01:35/00:08:44, 0.754s/it]: train_loss_raw=0.9358, running_loss=1.0325, LR=0.000100
[2025-08-26 12:38:12,950][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019064] [Batch 00135/00823] [00:01:41/00:08:37, 0.752s/it]: train_loss_raw=1.0497, running_loss=1.0338, LR=0.000100
[2025-08-26 12:38:18,777][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019072] [Batch 00143/00823] [00:01:47/00:08:30, 0.751s/it]: train_loss_raw=1.0698, running_loss=1.0333, LR=0.000100
[2025-08-26 12:38:24,682][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019080] [Batch 00151/00823] [00:01:53/00:08:24, 0.750s/it]: train_loss_raw=1.0264, running_loss=1.0328, LR=0.000100
[2025-08-26 12:38:30,491][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019088] [Batch 00159/00823] [00:01:59/00:08:17, 0.749s/it]: train_loss_raw=0.9679, running_loss=1.0319, LR=0.000100
[2025-08-26 12:38:36,489][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019096] [Batch 00167/00823] [00:02:05/00:08:11, 0.749s/it]: train_loss_raw=1.0301, running_loss=1.0333, LR=0.000100
[2025-08-26 12:38:42,615][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019104] [Batch 00175/00823] [00:02:11/00:08:05, 0.750s/it]: train_loss_raw=1.0764, running_loss=1.0329, LR=0.000100
[2025-08-26 12:38:48,717][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019112] [Batch 00183/00823] [00:02:17/00:08:00, 0.750s/it]: train_loss_raw=1.0128, running_loss=1.0329, LR=0.000100
[2025-08-26 12:38:54,747][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019120] [Batch 00191/00823] [00:02:23/00:07:54, 0.750s/it]: train_loss_raw=1.1154, running_loss=1.0331, LR=0.000100
[2025-08-26 12:39:00,841][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019128] [Batch 00199/00823] [00:02:29/00:07:48, 0.751s/it]: train_loss_raw=1.0641, running_loss=1.0327, LR=0.000100
[2025-08-26 12:39:06,887][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019136] [Batch 00207/00823] [00:02:35/00:07:42, 0.751s/it]: train_loss_raw=1.0144, running_loss=1.0290, LR=0.000100
[2025-08-26 12:39:12,954][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019144] [Batch 00215/00823] [00:02:41/00:07:36, 0.751s/it]: train_loss_raw=1.0655, running_loss=1.0282, LR=0.000100
[2025-08-26 12:39:19,074][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019152] [Batch 00223/00823] [00:02:47/00:07:31, 0.752s/it]: train_loss_raw=1.0421, running_loss=1.0275, LR=0.000100
[2025-08-26 12:39:25,184][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019160] [Batch 00231/00823] [00:02:53/00:07:25, 0.752s/it]: train_loss_raw=1.0103, running_loss=1.0277, LR=0.000100
[2025-08-26 12:39:31,253][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019168] [Batch 00239/00823] [00:02:59/00:07:19, 0.752s/it]: train_loss_raw=1.0397, running_loss=1.0273, LR=0.000100
[2025-08-26 12:39:37,340][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019176] [Batch 00247/00823] [00:03:05/00:07:13, 0.753s/it]: train_loss_raw=1.0452, running_loss=1.0287, LR=0.000100
[2025-08-26 12:39:43,402][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019184] [Batch 00255/00823] [00:03:11/00:07:07, 0.753s/it]: train_loss_raw=0.9953, running_loss=1.0305, LR=0.000100
[2025-08-26 12:39:49,495][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019192] [Batch 00263/00823] [00:03:18/00:07:01, 0.753s/it]: train_loss_raw=1.1506, running_loss=1.0323, LR=0.000100
[2025-08-26 12:39:55,518][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019200] [Batch 00271/00823] [00:03:24/00:06:55, 0.753s/it]: train_loss_raw=1.0964, running_loss=1.0336, LR=0.000100
[2025-08-26 12:40:01,548][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019208] [Batch 00279/00823] [00:03:30/00:06:49, 0.753s/it]: train_loss_raw=1.0322, running_loss=1.0343, LR=0.000100
[2025-08-26 12:40:07,605][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019216] [Batch 00287/00823] [00:03:36/00:06:43, 0.753s/it]: train_loss_raw=1.0282, running_loss=1.0333, LR=0.000100
[2025-08-26 12:40:13,657][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019224] [Batch 00295/00823] [00:03:42/00:06:37, 0.753s/it]: train_loss_raw=1.0045, running_loss=1.0333, LR=0.000100
[2025-08-26 12:40:19,643][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019232] [Batch 00303/00823] [00:03:48/00:06:31, 0.753s/it]: train_loss_raw=1.0747, running_loss=1.0344, LR=0.000100
[2025-08-26 12:40:25,782][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019240] [Batch 00311/00823] [00:03:54/00:06:25, 0.754s/it]: train_loss_raw=0.9462, running_loss=1.0306, LR=0.000100
[2025-08-26 12:40:31,869][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019248] [Batch 00319/00823] [00:04:00/00:06:19, 0.754s/it]: train_loss_raw=1.0701, running_loss=1.0309, LR=0.000100
[2025-08-26 12:40:37,970][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019256] [Batch 00327/00823] [00:04:06/00:06:13, 0.754s/it]: train_loss_raw=1.0484, running_loss=1.0297, LR=0.000100
[2025-08-26 12:40:44,018][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019264] [Batch 00335/00823] [00:04:12/00:06:07, 0.754s/it]: train_loss_raw=1.0118, running_loss=1.0302, LR=0.000100
[2025-08-26 12:40:50,048][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019272] [Batch 00343/00823] [00:04:18/00:06:01, 0.754s/it]: train_loss_raw=1.0884, running_loss=1.0308, LR=0.000100
[2025-08-26 12:40:56,119][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019280] [Batch 00351/00823] [00:04:24/00:05:55, 0.754s/it]: train_loss_raw=1.0312, running_loss=1.0301, LR=0.000100
[2025-08-26 12:41:02,232][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019288] [Batch 00359/00823] [00:04:30/00:05:50, 0.754s/it]: train_loss_raw=1.0553, running_loss=1.0281, LR=0.000100
[2025-08-26 12:41:08,343][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019296] [Batch 00367/00823] [00:04:36/00:05:44, 0.755s/it]: train_loss_raw=0.9442, running_loss=1.0285, LR=0.000100
[2025-08-26 12:41:14,380][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019304] [Batch 00375/00823] [00:04:42/00:05:38, 0.755s/it]: train_loss_raw=0.9730, running_loss=1.0276, LR=0.000100
[2025-08-26 12:41:20,440][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019312] [Batch 00383/00823] [00:04:49/00:05:32, 0.755s/it]: train_loss_raw=1.0849, running_loss=1.0268, LR=0.000100
[2025-08-26 12:41:26,505][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019320] [Batch 00391/00823] [00:04:55/00:05:26, 0.755s/it]: train_loss_raw=1.0000, running_loss=1.0243, LR=0.000100
[2025-08-26 12:41:32,540][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019328] [Batch 00399/00823] [00:05:01/00:05:19, 0.755s/it]: train_loss_raw=1.0032, running_loss=1.0244, LR=0.000100
[2025-08-26 12:41:38,560][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019336] [Batch 00407/00823] [00:05:07/00:05:13, 0.755s/it]: train_loss_raw=0.9776, running_loss=1.0229, LR=0.000100
[2025-08-26 12:41:44,602][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019344] [Batch 00415/00823] [00:05:13/00:05:07, 0.755s/it]: train_loss_raw=1.1022, running_loss=1.0236, LR=0.000100
[2025-08-26 12:41:50,710][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019352] [Batch 00423/00823] [00:05:19/00:05:01, 0.755s/it]: train_loss_raw=1.1330, running_loss=1.0228, LR=0.000100
[2025-08-26 12:41:56,794][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019360] [Batch 00431/00823] [00:05:25/00:04:55, 0.755s/it]: train_loss_raw=1.0928, running_loss=1.0230, LR=0.000100
[2025-08-26 12:42:02,799][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019368] [Batch 00439/00823] [00:05:31/00:04:49, 0.755s/it]: train_loss_raw=1.1116, running_loss=1.0243, LR=0.000100
[2025-08-26 12:42:08,880][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019376] [Batch 00447/00823] [00:05:37/00:04:43, 0.755s/it]: train_loss_raw=1.0166, running_loss=1.0252, LR=0.000100
[2025-08-26 12:42:14,991][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019384] [Batch 00455/00823] [00:05:43/00:04:37, 0.755s/it]: train_loss_raw=0.9623, running_loss=1.0236, LR=0.000100
[2025-08-26 12:42:21,037][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019392] [Batch 00463/00823] [00:05:49/00:04:31, 0.755s/it]: train_loss_raw=1.0588, running_loss=1.0270, LR=0.000100
[2025-08-26 12:42:27,084][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019400] [Batch 00471/00823] [00:05:55/00:04:25, 0.755s/it]: train_loss_raw=1.1777, running_loss=1.0293, LR=0.000100
[2025-08-26 12:42:33,174][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019408] [Batch 00479/00823] [00:06:01/00:04:19, 0.755s/it]: train_loss_raw=0.9226, running_loss=1.0274, LR=0.000100
[2025-08-26 12:42:39,270][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019416] [Batch 00487/00823] [00:06:07/00:04:13, 0.755s/it]: train_loss_raw=0.9783, running_loss=1.0258, LR=0.000100
[2025-08-26 12:42:45,337][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019424] [Batch 00495/00823] [00:06:13/00:04:07, 0.755s/it]: train_loss_raw=0.9307, running_loss=1.0239, LR=0.000100
[2025-08-26 12:42:51,408][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019432] [Batch 00503/00823] [00:06:19/00:04:01, 0.755s/it]: train_loss_raw=0.9607, running_loss=1.0231, LR=0.000100
[2025-08-26 12:42:57,525][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019440] [Batch 00511/00823] [00:06:26/00:03:55, 0.756s/it]: train_loss_raw=1.0039, running_loss=1.0222, LR=0.000100
[2025-08-26 12:43:03,607][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019448] [Batch 00519/00823] [00:06:32/00:03:49, 0.756s/it]: train_loss_raw=1.0172, running_loss=1.0208, LR=0.000100
[2025-08-26 12:43:09,653][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019456] [Batch 00527/00823] [00:06:38/00:03:43, 0.756s/it]: train_loss_raw=0.9995, running_loss=1.0219, LR=0.000100
[2025-08-26 12:43:15,708][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019464] [Batch 00535/00823] [00:06:44/00:03:37, 0.756s/it]: train_loss_raw=1.0789, running_loss=1.0209, LR=0.000100
[2025-08-26 12:43:21,757][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019472] [Batch 00543/00823] [00:06:50/00:03:31, 0.756s/it]: train_loss_raw=1.0029, running_loss=1.0213, LR=0.000100
[2025-08-26 12:43:27,784][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019480] [Batch 00551/00823] [00:06:56/00:03:25, 0.756s/it]: train_loss_raw=0.9869, running_loss=1.0198, LR=0.000100
[2025-08-26 12:43:33,843][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019488] [Batch 00559/00823] [00:07:02/00:03:19, 0.756s/it]: train_loss_raw=0.9768, running_loss=1.0210, LR=0.000100
[2025-08-26 12:43:39,895][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019496] [Batch 00567/00823] [00:07:08/00:03:13, 0.756s/it]: train_loss_raw=1.0147, running_loss=1.0200, LR=0.000100
[2025-08-26 12:43:45,996][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019504] [Batch 00575/00823] [00:07:14/00:03:07, 0.756s/it]: train_loss_raw=1.0298, running_loss=1.0197, LR=0.000100
[2025-08-26 12:43:52,103][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019512] [Batch 00583/00823] [00:07:20/00:03:01, 0.756s/it]: train_loss_raw=1.0559, running_loss=1.0200, LR=0.000100
[2025-08-26 12:43:58,170][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019520] [Batch 00591/00823] [00:07:26/00:02:55, 0.756s/it]: train_loss_raw=1.1171, running_loss=1.0202, LR=0.000100
[2025-08-26 12:44:04,273][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019528] [Batch 00599/00823] [00:07:32/00:02:49, 0.756s/it]: train_loss_raw=1.0434, running_loss=1.0175, LR=0.000100
[2025-08-26 12:44:10,382][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019536] [Batch 00607/00823] [00:07:38/00:02:43, 0.756s/it]: train_loss_raw=1.0123, running_loss=1.0174, LR=0.000100
[2025-08-26 12:44:16,384][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019544] [Batch 00615/00823] [00:07:44/00:02:37, 0.756s/it]: train_loss_raw=1.0526, running_loss=1.0167, LR=0.000100
[2025-08-26 12:44:22,439][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019552] [Batch 00623/00823] [00:07:51/00:02:31, 0.756s/it]: train_loss_raw=0.9523, running_loss=1.0165, LR=0.000100
[2025-08-26 12:44:28,447][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019560] [Batch 00631/00823] [00:07:57/00:02:25, 0.756s/it]: train_loss_raw=0.9741, running_loss=1.0121, LR=0.000100
[2025-08-26 12:44:34,405][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019568] [Batch 00639/00823] [00:08:02/00:02:19, 0.756s/it]: train_loss_raw=1.0798, running_loss=1.0139, LR=0.000100
[2025-08-26 12:44:40,589][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019576] [Batch 00647/00823] [00:08:09/00:02:13, 0.756s/it]: train_loss_raw=1.0496, running_loss=1.0140, LR=0.000100
[2025-08-26 12:44:46,492][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019584] [Batch 00655/00823] [00:08:15/00:02:06, 0.756s/it]: train_loss_raw=0.9349, running_loss=1.0148, LR=0.000100
[2025-08-26 12:44:52,317][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019592] [Batch 00663/00823] [00:08:20/00:02:00, 0.755s/it]: train_loss_raw=0.9924, running_loss=1.0147, LR=0.000100
[2025-08-26 12:44:58,311][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019600] [Batch 00671/00823] [00:08:26/00:01:54, 0.755s/it]: train_loss_raw=1.0175, running_loss=1.0164, LR=0.000100
[2025-08-26 12:45:04,344][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019608] [Batch 00679/00823] [00:08:32/00:01:48, 0.755s/it]: train_loss_raw=0.9835, running_loss=1.0129, LR=0.000100
[2025-08-26 12:45:10,341][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019616] [Batch 00687/00823] [00:08:38/00:01:42, 0.755s/it]: train_loss_raw=1.0051, running_loss=1.0161, LR=0.000100
[2025-08-26 12:45:16,433][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019624] [Batch 00695/00823] [00:08:45/00:01:36, 0.755s/it]: train_loss_raw=1.0717, running_loss=1.0161, LR=0.000100
[2025-08-26 12:45:22,496][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019632] [Batch 00703/00823] [00:08:51/00:01:30, 0.755s/it]: train_loss_raw=1.0748, running_loss=1.0165, LR=0.000100
[2025-08-26 12:45:28,552][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019640] [Batch 00711/00823] [00:08:57/00:01:24, 0.755s/it]: train_loss_raw=1.0147, running_loss=1.0165, LR=0.000100
[2025-08-26 12:45:34,585][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019648] [Batch 00719/00823] [00:09:03/00:01:18, 0.755s/it]: train_loss_raw=0.9849, running_loss=1.0155, LR=0.000100
[2025-08-26 12:45:40,622][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019656] [Batch 00727/00823] [00:09:09/00:01:12, 0.755s/it]: train_loss_raw=1.0746, running_loss=1.0180, LR=0.000100
[2025-08-26 12:45:46,669][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019664] [Batch 00735/00823] [00:09:15/00:01:06, 0.755s/it]: train_loss_raw=1.1332, running_loss=1.0196, LR=0.000100
[2025-08-26 12:45:52,705][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019672] [Batch 00743/00823] [00:09:21/00:01:00, 0.755s/it]: train_loss_raw=1.1135, running_loss=1.0213, LR=0.000100
[2025-08-26 12:45:58,715][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019680] [Batch 00751/00823] [00:09:27/00:00:54, 0.755s/it]: train_loss_raw=1.0482, running_loss=1.0204, LR=0.000100
[2025-08-26 12:46:04,756][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019688] [Batch 00759/00823] [00:09:33/00:00:48, 0.755s/it]: train_loss_raw=0.9855, running_loss=1.0189, LR=0.000100
[2025-08-26 12:46:10,865][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019696] [Batch 00767/00823] [00:09:39/00:00:42, 0.755s/it]: train_loss_raw=0.9899, running_loss=1.0171, LR=0.000100
[2025-08-26 12:46:16,898][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019704] [Batch 00775/00823] [00:09:45/00:00:36, 0.755s/it]: train_loss_raw=0.9193, running_loss=1.0164, LR=0.000100
[2025-08-26 12:46:22,890][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019712] [Batch 00783/00823] [00:09:51/00:00:30, 0.755s/it]: train_loss_raw=0.9660, running_loss=1.0150, LR=0.000100
[2025-08-26 12:46:28,948][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019720] [Batch 00791/00823] [00:09:57/00:00:24, 0.755s/it]: train_loss_raw=1.0165, running_loss=1.0156, LR=0.000100
[2025-08-26 12:46:35,001][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019728] [Batch 00799/00823] [00:10:03/00:00:18, 0.755s/it]: train_loss_raw=1.1032, running_loss=1.0180, LR=0.000100
[2025-08-26 12:46:41,021][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019736] [Batch 00807/00823] [00:10:09/00:00:12, 0.755s/it]: train_loss_raw=0.9401, running_loss=1.0166, LR=0.000100
[2025-08-26 12:46:47,078][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019744] [Batch 00815/00823] [00:10:15/00:00:06, 0.755s/it]: train_loss_raw=1.0054, running_loss=1.0179, LR=0.000100
[2025-08-26 12:46:59,084][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019752] [Batch 00823/00823] [00:10:27/00:00:00, 0.763s/it]: train_loss_raw=0.8780, running_loss=1.0152, LR=0.000100
[2025-08-26 12:46:59,464][__main__][INFO] - [VALIDATION] [Epoch 23/29] Starting validation.
[2025-08-26 12:47:10,805][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 019753] [Batch 00007/00013] [00:00:11/00:00:07, 1.418s/it]
[2025-08-26 12:47:18,136][__main__][INFO] - [VALIDATION] [Epoch 23/29] train_loss=1.01522, valid_loss=1.37019
[2025-08-26 12:47:18,136][__main__][INFO] - [VALIDATION] [Epoch 23/29] Metrics:
[2025-08-26 12:47:18,136][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_er      0.553
[2025-08-26 12:47:18,136][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_prec    0.089
[2025-08-26 12:47:18,136][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_recall  0.090
[2025-08-26 12:47:18,137][__main__][INFO] - [VALIDATION] [Epoch 23/29] - pep_recall 0.046
[2025-08-26 12:47:18,139][__main__][INFO] - [TRAIN] [Epoch 23/29] Epoch complete, total time 04:14:41, remaining time 01:03:40, 00:10:36 per epoch
[2025-08-26 12:47:23,816][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019760] [Batch 00008/00823] [00:00:05/00:09:13, 0.680s/it]: train_loss_raw=1.0059, running_loss=0.9756, LR=0.000100
[2025-08-26 12:47:29,890][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019768] [Batch 00016/00823] [00:00:11/00:09:40, 0.719s/it]: train_loss_raw=0.9562, running_loss=0.9724, LR=0.000100
[2025-08-26 12:47:35,916][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019776] [Batch 00024/00823] [00:00:17/00:09:43, 0.731s/it]: train_loss_raw=1.0484, running_loss=0.9733, LR=0.000100
[2025-08-26 12:47:41,997][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019784] [Batch 00032/00823] [00:00:23/00:09:43, 0.738s/it]: train_loss_raw=0.8987, running_loss=0.9705, LR=0.000100
[2025-08-26 12:47:48,105][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019792] [Batch 00040/00823] [00:00:29/00:09:41, 0.743s/it]: train_loss_raw=0.9072, running_loss=0.9668, LR=0.000100
[2025-08-26 12:47:54,151][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019800] [Batch 00048/00823] [00:00:35/00:09:37, 0.745s/it]: train_loss_raw=0.9886, running_loss=0.9667, LR=0.000100
[2025-08-26 12:48:00,242][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019808] [Batch 00056/00823] [00:00:41/00:09:33, 0.748s/it]: train_loss_raw=0.9236, running_loss=0.9647, LR=0.000100
[2025-08-26 12:48:06,248][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019816] [Batch 00064/00823] [00:00:47/00:09:27, 0.748s/it]: train_loss_raw=0.9620, running_loss=0.9645, LR=0.000100
[2025-08-26 12:48:12,322][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019824] [Batch 00072/00823] [00:00:53/00:09:22, 0.749s/it]: train_loss_raw=0.9765, running_loss=0.9643, LR=0.000100
[2025-08-26 12:48:18,357][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019832] [Batch 00080/00823] [00:00:59/00:09:17, 0.750s/it]: train_loss_raw=1.0234, running_loss=0.9649, LR=0.000100
[2025-08-26 12:48:24,366][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019840] [Batch 00088/00823] [00:01:05/00:09:11, 0.750s/it]: train_loss_raw=0.9499, running_loss=0.9662, LR=0.000100
[2025-08-26 12:48:30,429][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019848] [Batch 00096/00823] [00:01:12/00:09:05, 0.751s/it]: train_loss_raw=0.9391, running_loss=0.9657, LR=0.000100
[2025-08-26 12:48:36,415][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019856] [Batch 00104/00823] [00:01:18/00:08:59, 0.750s/it]: train_loss_raw=0.9505, running_loss=0.9656, LR=0.000100
[2025-08-26 12:48:42,509][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019864] [Batch 00112/00823] [00:01:24/00:08:54, 0.751s/it]: train_loss_raw=1.0224, running_loss=0.9661, LR=0.000100
[2025-08-26 12:48:48,548][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019872] [Batch 00120/00823] [00:01:30/00:08:48, 0.751s/it]: train_loss_raw=0.9602, running_loss=0.9646, LR=0.000100
[2025-08-26 12:48:54,664][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019880] [Batch 00128/00823] [00:01:36/00:08:42, 0.752s/it]: train_loss_raw=0.9379, running_loss=0.9663, LR=0.000100
[2025-08-26 12:49:00,719][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019888] [Batch 00136/00823] [00:01:42/00:08:36, 0.752s/it]: train_loss_raw=0.9207, running_loss=0.9654, LR=0.000100
[2025-08-26 12:49:06,711][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019896] [Batch 00144/00823] [00:01:48/00:08:30, 0.752s/it]: train_loss_raw=0.9669, running_loss=0.9659, LR=0.000100
[2025-08-26 12:49:12,777][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019904] [Batch 00152/00823] [00:01:54/00:08:25, 0.753s/it]: train_loss_raw=1.0047, running_loss=0.9657, LR=0.000100
[2025-08-26 12:49:18,921][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019912] [Batch 00160/00823] [00:02:00/00:08:19, 0.753s/it]: train_loss_raw=0.9467, running_loss=0.9657, LR=0.000100
[2025-08-26 12:49:25,113][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019920] [Batch 00168/00823] [00:02:06/00:08:14, 0.754s/it]: train_loss_raw=1.0553, running_loss=0.9633, LR=0.000100
[2025-08-26 12:49:31,070][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019928] [Batch 00176/00823] [00:02:12/00:08:07, 0.754s/it]: train_loss_raw=1.0312, running_loss=0.9639, LR=0.000100
[2025-08-26 12:49:37,060][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019936] [Batch 00184/00823] [00:02:18/00:08:01, 0.754s/it]: train_loss_raw=0.9958, running_loss=0.9648, LR=0.000100
[2025-08-26 12:49:42,842][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019944] [Batch 00192/00823] [00:02:24/00:07:54, 0.752s/it]: train_loss_raw=0.9570, running_loss=0.9637, LR=0.000100
[2025-08-26 12:49:48,655][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019952] [Batch 00200/00823] [00:02:30/00:07:48, 0.751s/it]: train_loss_raw=0.9151, running_loss=0.9609, LR=0.000100
[2025-08-26 12:49:54,378][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019960] [Batch 00208/00823] [00:02:35/00:07:41, 0.750s/it]: train_loss_raw=0.9337, running_loss=0.9601, LR=0.000100
[2025-08-26 12:50:00,132][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019968] [Batch 00216/00823] [00:02:41/00:07:34, 0.749s/it]: train_loss_raw=1.0148, running_loss=0.9610, LR=0.000100
[2025-08-26 12:50:05,876][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019976] [Batch 00224/00823] [00:02:47/00:07:27, 0.748s/it]: train_loss_raw=0.9737, running_loss=0.9585, LR=0.000100
[2025-08-26 12:50:11,651][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019984] [Batch 00232/00823] [00:02:53/00:07:21, 0.747s/it]: train_loss_raw=0.9518, running_loss=0.9603, LR=0.000100
[2025-08-26 12:50:17,404][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019992] [Batch 00240/00823] [00:02:59/00:07:14, 0.746s/it]: train_loss_raw=1.0151, running_loss=0.9614, LR=0.000100
[2025-08-26 12:50:23,238][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020000] [Batch 00248/00823] [00:03:04/00:07:08, 0.745s/it]: train_loss_raw=0.9824, running_loss=0.9628, LR=0.000100
[2025-08-26 12:50:33,591][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020008] [Batch 00256/00823] [00:03:15/00:07:12, 0.763s/it]: train_loss_raw=1.0042, running_loss=0.9637, LR=0.000100
[2025-08-26 12:50:39,469][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020016] [Batch 00264/00823] [00:03:21/00:07:05, 0.762s/it]: train_loss_raw=0.9864, running_loss=0.9627, LR=0.000100
[2025-08-26 12:50:45,234][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020024] [Batch 00272/00823] [00:03:26/00:06:59, 0.760s/it]: train_loss_raw=0.9412, running_loss=0.9646, LR=0.000100
[2025-08-26 12:50:51,125][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020032] [Batch 00280/00823] [00:03:32/00:06:52, 0.760s/it]: train_loss_raw=0.9566, running_loss=0.9637, LR=0.000100
[2025-08-26 12:50:56,899][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020040] [Batch 00288/00823] [00:03:38/00:06:45, 0.759s/it]: train_loss_raw=0.8935, running_loss=0.9628, LR=0.000100
[2025-08-26 12:51:02,693][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020048] [Batch 00296/00823] [00:03:44/00:06:39, 0.758s/it]: train_loss_raw=0.9933, running_loss=0.9627, LR=0.000100
[2025-08-26 12:51:08,333][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020056] [Batch 00304/00823] [00:03:49/00:06:32, 0.756s/it]: train_loss_raw=0.9722, running_loss=0.9590, LR=0.000100
[2025-08-26 12:51:14,321][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020064] [Batch 00312/00823] [00:03:55/00:06:26, 0.756s/it]: train_loss_raw=0.9173, running_loss=0.9587, LR=0.000100
[2025-08-26 12:51:20,238][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020072] [Batch 00320/00823] [00:04:01/00:06:20, 0.756s/it]: train_loss_raw=0.9952, running_loss=0.9632, LR=0.000100
[2025-08-26 12:51:26,015][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020080] [Batch 00328/00823] [00:04:07/00:06:13, 0.755s/it]: train_loss_raw=0.9987, running_loss=0.9648, LR=0.000100
[2025-08-26 12:51:31,885][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020088] [Batch 00336/00823] [00:04:13/00:06:07, 0.754s/it]: train_loss_raw=0.9177, running_loss=0.9646, LR=0.000100
[2025-08-26 12:51:37,798][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020096] [Batch 00344/00823] [00:04:19/00:06:01, 0.754s/it]: train_loss_raw=0.8974, running_loss=0.9647, LR=0.000100
[2025-08-26 12:51:43,604][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020104] [Batch 00352/00823] [00:04:25/00:05:54, 0.753s/it]: train_loss_raw=0.9489, running_loss=0.9653, LR=0.000100
[2025-08-26 12:51:49,328][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020112] [Batch 00360/00823] [00:04:30/00:05:48, 0.753s/it]: train_loss_raw=0.9987, running_loss=0.9661, LR=0.000100
[2025-08-26 12:51:55,226][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020120] [Batch 00368/00823] [00:04:36/00:05:42, 0.752s/it]: train_loss_raw=1.0018, running_loss=0.9662, LR=0.000100
[2025-08-26 12:52:01,146][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020128] [Batch 00376/00823] [00:04:42/00:05:36, 0.752s/it]: train_loss_raw=0.8825, running_loss=0.9665, LR=0.000100
[2025-08-26 12:52:06,937][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020136] [Batch 00384/00823] [00:04:48/00:05:29, 0.751s/it]: train_loss_raw=0.9410, running_loss=0.9652, LR=0.000100
[2025-08-26 12:52:12,683][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020144] [Batch 00392/00823] [00:04:54/00:05:23, 0.751s/it]: train_loss_raw=0.9763, running_loss=0.9668, LR=0.000100
[2025-08-26 12:52:18,522][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020152] [Batch 00400/00823] [00:05:00/00:05:17, 0.750s/it]: train_loss_raw=0.9979, running_loss=0.9665, LR=0.000100
[2025-08-26 12:52:24,293][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020160] [Batch 00408/00823] [00:05:05/00:05:11, 0.750s/it]: train_loss_raw=0.9321, running_loss=0.9659, LR=0.000100
[2025-08-26 12:52:30,172][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020168] [Batch 00416/00823] [00:05:11/00:05:05, 0.750s/it]: train_loss_raw=0.9034, running_loss=0.9640, LR=0.000100
[2025-08-26 12:52:36,028][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020176] [Batch 00424/00823] [00:05:17/00:04:58, 0.749s/it]: train_loss_raw=1.0185, running_loss=0.9650, LR=0.000100
[2025-08-26 12:52:42,052][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020184] [Batch 00432/00823] [00:05:23/00:04:52, 0.749s/it]: train_loss_raw=0.9090, running_loss=0.9639, LR=0.000100
[2025-08-26 12:52:47,779][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020192] [Batch 00440/00823] [00:05:29/00:04:46, 0.749s/it]: train_loss_raw=0.9166, running_loss=0.9655, LR=0.000100
[2025-08-26 12:52:53,691][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020200] [Batch 00448/00823] [00:05:35/00:04:40, 0.748s/it]: train_loss_raw=1.0188, running_loss=0.9663, LR=0.000100
[2025-08-26 12:52:59,559][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020208] [Batch 00456/00823] [00:05:41/00:04:34, 0.748s/it]: train_loss_raw=1.0184, running_loss=0.9671, LR=0.000100
[2025-08-26 12:53:05,453][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020216] [Batch 00464/00823] [00:05:47/00:04:28, 0.748s/it]: train_loss_raw=0.9270, running_loss=0.9651, LR=0.000100
[2025-08-26 12:53:11,271][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020224] [Batch 00472/00823] [00:05:52/00:04:22, 0.748s/it]: train_loss_raw=1.0471, running_loss=0.9669, LR=0.000100
[2025-08-26 12:53:17,111][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020232] [Batch 00480/00823] [00:05:58/00:04:16, 0.747s/it]: train_loss_raw=1.0511, running_loss=0.9661, LR=0.000100
[2025-08-26 12:53:23,128][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020240] [Batch 00488/00823] [00:06:04/00:04:10, 0.747s/it]: train_loss_raw=0.9162, running_loss=0.9660, LR=0.000100
[2025-08-26 12:53:28,979][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020248] [Batch 00496/00823] [00:06:10/00:04:04, 0.747s/it]: train_loss_raw=0.9707, running_loss=0.9663, LR=0.000100
[2025-08-26 12:53:35,010][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020256] [Batch 00504/00823] [00:06:16/00:03:58, 0.747s/it]: train_loss_raw=0.9906, running_loss=0.9683, LR=0.000100
[2025-08-26 12:53:40,946][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020264] [Batch 00512/00823] [00:06:22/00:03:52, 0.747s/it]: train_loss_raw=1.0509, running_loss=0.9691, LR=0.000100
[2025-08-26 12:53:46,698][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020272] [Batch 00520/00823] [00:06:28/00:03:46, 0.747s/it]: train_loss_raw=0.9769, running_loss=0.9688, LR=0.000100
[2025-08-26 12:53:52,403][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020280] [Batch 00528/00823] [00:06:34/00:03:40, 0.746s/it]: train_loss_raw=1.0104, running_loss=0.9689, LR=0.000100
[2025-08-26 12:53:58,116][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020288] [Batch 00536/00823] [00:06:39/00:03:34, 0.746s/it]: train_loss_raw=1.0451, running_loss=0.9698, LR=0.000100
[2025-08-26 12:54:03,974][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020296] [Batch 00544/00823] [00:06:45/00:03:28, 0.746s/it]: train_loss_raw=1.0282, running_loss=0.9721, LR=0.000100
[2025-08-26 12:54:09,850][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020304] [Batch 00552/00823] [00:06:51/00:03:22, 0.745s/it]: train_loss_raw=1.0238, running_loss=0.9696, LR=0.000100
[2025-08-26 12:54:15,851][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020312] [Batch 00560/00823] [00:06:57/00:03:16, 0.745s/it]: train_loss_raw=1.0040, running_loss=0.9709, LR=0.000100
[2025-08-26 12:54:21,753][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020320] [Batch 00568/00823] [00:07:03/00:03:10, 0.745s/it]: train_loss_raw=1.0626, running_loss=0.9717, LR=0.000100
[2025-08-26 12:54:27,518][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020328] [Batch 00576/00823] [00:07:09/00:03:04, 0.745s/it]: train_loss_raw=0.9716, running_loss=0.9722, LR=0.000100
[2025-08-26 12:54:33,353][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020336] [Batch 00584/00823] [00:07:14/00:02:58, 0.745s/it]: train_loss_raw=0.8860, running_loss=0.9695, LR=0.000100
[2025-08-26 12:54:39,334][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020344] [Batch 00592/00823] [00:07:20/00:02:52, 0.745s/it]: train_loss_raw=1.0020, running_loss=0.9722, LR=0.000100
[2025-08-26 12:54:45,180][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020352] [Batch 00600/00823] [00:07:26/00:02:46, 0.745s/it]: train_loss_raw=1.0099, running_loss=0.9743, LR=0.000100
[2025-08-26 12:54:51,037][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020360] [Batch 00608/00823] [00:07:32/00:02:40, 0.745s/it]: train_loss_raw=0.9811, running_loss=0.9741, LR=0.000100
[2025-08-26 12:54:56,832][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020368] [Batch 00616/00823] [00:07:38/00:02:34, 0.744s/it]: train_loss_raw=1.0130, running_loss=0.9709, LR=0.000100
[2025-08-26 12:55:02,742][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020376] [Batch 00624/00823] [00:07:44/00:02:28, 0.744s/it]: train_loss_raw=0.9636, running_loss=0.9687, LR=0.000100
[2025-08-26 12:55:08,598][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020384] [Batch 00632/00823] [00:07:50/00:02:22, 0.744s/it]: train_loss_raw=0.8066, running_loss=0.9683, LR=0.000100
[2025-08-26 12:55:14,407][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020392] [Batch 00640/00823] [00:07:56/00:02:16, 0.744s/it]: train_loss_raw=0.9561, running_loss=0.9690, LR=0.000100
[2025-08-26 12:55:20,309][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020400] [Batch 00648/00823] [00:08:01/00:02:10, 0.744s/it]: train_loss_raw=0.9252, running_loss=0.9654, LR=0.000100
[2025-08-26 12:55:26,133][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020408] [Batch 00656/00823] [00:08:07/00:02:04, 0.744s/it]: train_loss_raw=1.0206, running_loss=0.9647, LR=0.000100
[2025-08-26 12:55:32,034][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020416] [Batch 00664/00823] [00:08:13/00:01:58, 0.743s/it]: train_loss_raw=1.0551, running_loss=0.9641, LR=0.000100
[2025-08-26 12:55:37,915][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020424] [Batch 00672/00823] [00:08:19/00:01:52, 0.743s/it]: train_loss_raw=0.8640, running_loss=0.9627, LR=0.000100
[2025-08-26 12:55:43,760][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020432] [Batch 00680/00823] [00:08:25/00:01:46, 0.743s/it]: train_loss_raw=0.9988, running_loss=0.9612, LR=0.000100
[2025-08-26 12:55:49,683][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020440] [Batch 00688/00823] [00:08:31/00:01:40, 0.743s/it]: train_loss_raw=0.9576, running_loss=0.9606, LR=0.000100
[2025-08-26 12:55:55,622][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020448] [Batch 00696/00823] [00:08:37/00:01:34, 0.743s/it]: train_loss_raw=1.0546, running_loss=0.9619, LR=0.000100
[2025-08-26 12:56:01,441][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020456] [Batch 00704/00823] [00:08:43/00:01:28, 0.743s/it]: train_loss_raw=1.0168, running_loss=0.9632, LR=0.000100
[2025-08-26 12:56:07,302][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020464] [Batch 00712/00823] [00:08:48/00:01:22, 0.743s/it]: train_loss_raw=1.0225, running_loss=0.9638, LR=0.000100
[2025-08-26 12:56:13,067][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020472] [Batch 00720/00823] [00:08:54/00:01:16, 0.743s/it]: train_loss_raw=0.9281, running_loss=0.9642, LR=0.000100
[2025-08-26 12:56:19,094][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020480] [Batch 00728/00823] [00:09:00/00:01:10, 0.743s/it]: train_loss_raw=0.9116, running_loss=0.9647, LR=0.000100
[2025-08-26 12:56:24,955][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020488] [Batch 00736/00823] [00:09:06/00:01:04, 0.743s/it]: train_loss_raw=0.9276, running_loss=0.9654, LR=0.000100
[2025-08-26 12:56:30,817][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020496] [Batch 00744/00823] [00:09:12/00:00:58, 0.743s/it]: train_loss_raw=1.0043, running_loss=0.9693, LR=0.000100
[2025-08-26 12:56:36,774][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020504] [Batch 00752/00823] [00:09:18/00:00:52, 0.743s/it]: train_loss_raw=1.0073, running_loss=0.9697, LR=0.000100
[2025-08-26 12:56:42,487][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020512] [Batch 00760/00823] [00:09:24/00:00:46, 0.742s/it]: train_loss_raw=0.9169, running_loss=0.9673, LR=0.000100
[2025-08-26 12:56:48,411][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020520] [Batch 00768/00823] [00:09:30/00:00:40, 0.742s/it]: train_loss_raw=0.9421, running_loss=0.9656, LR=0.000100
[2025-08-26 12:56:54,275][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020528] [Batch 00776/00823] [00:09:35/00:00:34, 0.742s/it]: train_loss_raw=0.9969, running_loss=0.9673, LR=0.000100
[2025-08-26 12:57:00,041][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020536] [Batch 00784/00823] [00:09:41/00:00:28, 0.742s/it]: train_loss_raw=0.9796, running_loss=0.9689, LR=0.000100
[2025-08-26 12:57:05,903][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020544] [Batch 00792/00823] [00:09:47/00:00:22, 0.742s/it]: train_loss_raw=0.9424, running_loss=0.9682, LR=0.000100
[2025-08-26 12:57:11,755][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020552] [Batch 00800/00823] [00:09:53/00:00:17, 0.742s/it]: train_loss_raw=0.9626, running_loss=0.9676, LR=0.000100
[2025-08-26 12:57:17,603][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020560] [Batch 00808/00823] [00:09:59/00:00:11, 0.742s/it]: train_loss_raw=0.9744, running_loss=0.9688, LR=0.000100
[2025-08-26 12:57:23,338][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020568] [Batch 00816/00823] [00:10:04/00:00:05, 0.741s/it]: train_loss_raw=1.0845, running_loss=0.9719, LR=0.000100
[2025-08-26 12:57:28,595][__main__][INFO] - [VALIDATION] [Epoch 24/29] Starting validation.
[2025-08-26 12:57:39,699][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 020576] [Batch 00007/00013] [00:00:11/00:00:06, 1.388s/it]
[2025-08-26 12:57:47,050][__main__][INFO] - [VALIDATION] [Epoch 24/29] train_loss=0.96897, valid_loss=1.36258
[2025-08-26 12:57:47,050][__main__][INFO] - [VALIDATION] [Epoch 24/29] Metrics:
[2025-08-26 12:57:47,050][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_er      0.560
[2025-08-26 12:57:47,050][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_prec    0.083
[2025-08-26 12:57:47,050][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_recall  0.084
[2025-08-26 12:57:47,050][__main__][INFO] - [VALIDATION] [Epoch 24/29] - pep_recall 0.043
[2025-08-26 12:57:47,052][__main__][INFO] - [TRAIN] [Epoch 24/29] Epoch complete, total time 04:25:10, remaining time 00:53:02, 00:10:36 per epoch
[2025-08-26 12:57:47,395][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020576] [Batch 00001/00823] [00:00:00/00:02:00, 0.147s/it]: train_loss_raw=1.0270, running_loss=1.0270, LR=0.000100
[2025-08-26 12:57:53,361][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020584] [Batch 00009/00823] [00:00:06/00:09:12, 0.679s/it]: train_loss_raw=0.9986, running_loss=1.0240, LR=0.000100
[2025-08-26 12:57:59,219][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020592] [Batch 00017/00823] [00:00:11/00:09:27, 0.704s/it]: train_loss_raw=0.9869, running_loss=1.0197, LR=0.000100
[2025-08-26 12:58:05,155][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020600] [Batch 00025/00823] [00:00:17/00:09:31, 0.716s/it]: train_loss_raw=1.0235, running_loss=1.0155, LR=0.000100
[2025-08-26 12:58:11,071][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020608] [Batch 00033/00823] [00:00:23/00:09:30, 0.722s/it]: train_loss_raw=0.9209, running_loss=1.0106, LR=0.000100
[2025-08-26 12:58:16,879][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020616] [Batch 00041/00823] [00:00:29/00:09:25, 0.723s/it]: train_loss_raw=0.9212, running_loss=1.0068, LR=0.000100
[2025-08-26 12:58:22,663][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020624] [Batch 00049/00823] [00:00:35/00:09:19, 0.723s/it]: train_loss_raw=0.9072, running_loss=1.0049, LR=0.000100
[2025-08-26 12:58:28,661][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020632] [Batch 00057/00823] [00:00:41/00:09:16, 0.727s/it]: train_loss_raw=1.0035, running_loss=1.0050, LR=0.000100
[2025-08-26 12:58:34,472][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020640] [Batch 00065/00823] [00:00:47/00:09:10, 0.727s/it]: train_loss_raw=0.9516, running_loss=1.0016, LR=0.000100
[2025-08-26 12:58:40,169][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020648] [Batch 00073/00823] [00:00:52/00:09:03, 0.725s/it]: train_loss_raw=0.9229, running_loss=0.9985, LR=0.000100
[2025-08-26 12:58:46,117][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020656] [Batch 00081/00823] [00:00:58/00:08:59, 0.727s/it]: train_loss_raw=0.9799, running_loss=0.9960, LR=0.000100
[2025-08-26 12:58:52,071][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020664] [Batch 00089/00823] [00:01:04/00:08:54, 0.728s/it]: train_loss_raw=1.0331, running_loss=0.9947, LR=0.000100
[2025-08-26 12:58:57,951][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020672] [Batch 00097/00823] [00:01:10/00:08:49, 0.729s/it]: train_loss_raw=0.9953, running_loss=0.9922, LR=0.000100
[2025-08-26 12:59:03,853][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020680] [Batch 00105/00823] [00:01:16/00:08:43, 0.730s/it]: train_loss_raw=0.9748, running_loss=0.9889, LR=0.000100
[2025-08-26 12:59:09,657][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020688] [Batch 00113/00823] [00:01:22/00:08:37, 0.729s/it]: train_loss_raw=1.0278, running_loss=0.9917, LR=0.000100
[2025-08-26 12:59:15,737][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020696] [Batch 00121/00823] [00:01:28/00:08:33, 0.731s/it]: train_loss_raw=0.9747, running_loss=0.9904, LR=0.000100
[2025-08-26 12:59:21,529][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020704] [Batch 00129/00823] [00:01:34/00:08:27, 0.731s/it]: train_loss_raw=0.9376, running_loss=0.9891, LR=0.000100
[2025-08-26 12:59:27,555][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020712] [Batch 00137/00823] [00:01:40/00:08:22, 0.732s/it]: train_loss_raw=0.9993, running_loss=0.9886, LR=0.000100
[2025-08-26 12:59:33,499][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020720] [Batch 00145/00823] [00:01:46/00:08:16, 0.733s/it]: train_loss_raw=0.9899, running_loss=0.9879, LR=0.000100
[2025-08-26 12:59:39,417][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020728] [Batch 00153/00823] [00:01:52/00:08:11, 0.733s/it]: train_loss_raw=0.9706, running_loss=0.9865, LR=0.000100
[2025-08-26 12:59:45,401][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020736] [Batch 00161/00823] [00:01:58/00:08:05, 0.734s/it]: train_loss_raw=0.9442, running_loss=0.9840, LR=0.000100
[2025-08-26 12:59:51,347][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020744] [Batch 00169/00823] [00:02:04/00:08:00, 0.734s/it]: train_loss_raw=1.0145, running_loss=0.9852, LR=0.000100
[2025-08-26 12:59:57,156][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020752] [Batch 00177/00823] [00:02:09/00:07:54, 0.734s/it]: train_loss_raw=0.9626, running_loss=0.9849, LR=0.000100
[2025-08-26 13:00:02,908][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020760] [Batch 00185/00823] [00:02:15/00:07:47, 0.733s/it]: train_loss_raw=0.9230, running_loss=0.9839, LR=0.000100
[2025-08-26 13:00:08,845][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020768] [Batch 00193/00823] [00:02:21/00:07:42, 0.734s/it]: train_loss_raw=0.9071, running_loss=0.9804, LR=0.000100
[2025-08-26 13:00:14,721][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020776] [Batch 00201/00823] [00:02:27/00:07:36, 0.734s/it]: train_loss_raw=0.9270, running_loss=0.9787, LR=0.000100
[2025-08-26 13:00:20,556][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020784] [Batch 00209/00823] [00:02:33/00:07:30, 0.734s/it]: train_loss_raw=0.8463, running_loss=0.9762, LR=0.000100
[2025-08-26 13:00:26,260][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020792] [Batch 00217/00823] [00:02:39/00:07:24, 0.733s/it]: train_loss_raw=0.9578, running_loss=0.9775, LR=0.000100
[2025-08-26 13:00:32,109][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020800] [Batch 00225/00823] [00:02:44/00:07:18, 0.733s/it]: train_loss_raw=0.9185, running_loss=0.9738, LR=0.000100
[2025-08-26 13:00:38,160][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020808] [Batch 00233/00823] [00:02:50/00:07:12, 0.734s/it]: train_loss_raw=0.8695, running_loss=0.9723, LR=0.000100
[2025-08-26 13:00:43,980][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020816] [Batch 00241/00823] [00:02:56/00:07:06, 0.733s/it]: train_loss_raw=0.8715, running_loss=0.9722, LR=0.000100
[2025-08-26 13:00:49,852][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020824] [Batch 00249/00823] [00:03:02/00:07:00, 0.733s/it]: train_loss_raw=1.0427, running_loss=0.9707, LR=0.000100
[2025-08-26 13:00:55,706][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020832] [Batch 00257/00823] [00:03:08/00:06:55, 0.733s/it]: train_loss_raw=0.9940, running_loss=0.9707, LR=0.000100
[2025-08-26 13:01:01,590][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020840] [Batch 00265/00823] [00:03:14/00:06:49, 0.733s/it]: train_loss_raw=1.0176, running_loss=0.9712, LR=0.000100
[2025-08-26 13:01:07,503][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020848] [Batch 00273/00823] [00:03:20/00:06:43, 0.734s/it]: train_loss_raw=0.9171, running_loss=0.9707, LR=0.000100
[2025-08-26 13:01:13,347][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020856] [Batch 00281/00823] [00:03:26/00:06:37, 0.733s/it]: train_loss_raw=1.0172, running_loss=0.9720, LR=0.000100
[2025-08-26 13:01:19,159][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020864] [Batch 00289/00823] [00:03:31/00:06:31, 0.733s/it]: train_loss_raw=0.9885, running_loss=0.9736, LR=0.000100
[2025-08-26 13:01:25,142][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020872] [Batch 00297/00823] [00:03:37/00:06:25, 0.734s/it]: train_loss_raw=0.9804, running_loss=0.9711, LR=0.000100
[2025-08-26 13:01:30,970][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020880] [Batch 00305/00823] [00:03:43/00:06:19, 0.734s/it]: train_loss_raw=0.9306, running_loss=0.9714, LR=0.000100
[2025-08-26 13:01:36,786][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020888] [Batch 00313/00823] [00:03:49/00:06:14, 0.733s/it]: train_loss_raw=0.9316, running_loss=0.9693, LR=0.000100
[2025-08-26 13:01:42,659][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020896] [Batch 00321/00823] [00:03:55/00:06:08, 0.733s/it]: train_loss_raw=1.0150, running_loss=0.9715, LR=0.000100
[2025-08-26 13:01:48,402][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020904] [Batch 00329/00823] [00:04:01/00:06:02, 0.733s/it]: train_loss_raw=0.9712, running_loss=0.9670, LR=0.000100
[2025-08-26 13:01:54,205][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020912] [Batch 00337/00823] [00:04:06/00:05:56, 0.733s/it]: train_loss_raw=0.9849, running_loss=0.9653, LR=0.000100
[2025-08-26 13:02:00,112][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020920] [Batch 00345/00823] [00:04:12/00:05:50, 0.733s/it]: train_loss_raw=0.9426, running_loss=0.9646, LR=0.000100
[2025-08-26 13:02:06,034][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020928] [Batch 00353/00823] [00:04:18/00:05:44, 0.733s/it]: train_loss_raw=1.0459, running_loss=0.9615, LR=0.000100
[2025-08-26 13:02:11,880][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020936] [Batch 00361/00823] [00:04:24/00:05:38, 0.733s/it]: train_loss_raw=0.9972, running_loss=0.9620, LR=0.000100
[2025-08-26 13:02:17,811][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020944] [Batch 00369/00823] [00:04:30/00:05:32, 0.733s/it]: train_loss_raw=0.9722, running_loss=0.9623, LR=0.000100
[2025-08-26 13:02:23,616][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020952] [Batch 00377/00823] [00:04:36/00:05:26, 0.733s/it]: train_loss_raw=1.0122, running_loss=0.9629, LR=0.000100
[2025-08-26 13:02:29,536][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020960] [Batch 00385/00823] [00:04:42/00:05:21, 0.733s/it]: train_loss_raw=0.9211, running_loss=0.9628, LR=0.000100
[2025-08-26 13:02:35,466][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020968] [Batch 00393/00823] [00:04:48/00:05:15, 0.733s/it]: train_loss_raw=0.9508, running_loss=0.9625, LR=0.000100
[2025-08-26 13:02:41,227][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020976] [Batch 00401/00823] [00:04:53/00:05:09, 0.733s/it]: train_loss_raw=1.0086, running_loss=0.9631, LR=0.000100
[2025-08-26 13:02:46,780][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020984] [Batch 00409/00823] [00:04:59/00:05:03, 0.732s/it]: train_loss_raw=1.0248, running_loss=0.9623, LR=0.000100
[2025-08-26 13:02:52,726][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020992] [Batch 00417/00823] [00:05:05/00:04:57, 0.733s/it]: train_loss_raw=0.9306, running_loss=0.9623, LR=0.000100
[2025-08-26 13:02:58,589][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021000] [Batch 00425/00823] [00:05:11/00:04:51, 0.733s/it]: train_loss_raw=0.9779, running_loss=0.9617, LR=0.000100
[2025-08-26 13:03:04,517][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021008] [Batch 00433/00823] [00:05:17/00:04:45, 0.733s/it]: train_loss_raw=1.0041, running_loss=0.9622, LR=0.000100
[2025-08-26 13:03:10,438][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021016] [Batch 00441/00823] [00:05:23/00:04:39, 0.733s/it]: train_loss_raw=1.0047, running_loss=0.9630, LR=0.000100
[2025-08-26 13:03:16,437][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021024] [Batch 00449/00823] [00:05:29/00:04:34, 0.733s/it]: train_loss_raw=0.9032, running_loss=0.9636, LR=0.000100
[2025-08-26 13:03:22,433][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021032] [Batch 00457/00823] [00:05:35/00:04:28, 0.733s/it]: train_loss_raw=0.9183, running_loss=0.9630, LR=0.000100
[2025-08-26 13:03:28,353][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021040] [Batch 00465/00823] [00:05:41/00:04:22, 0.734s/it]: train_loss_raw=1.0304, running_loss=0.9640, LR=0.000100
[2025-08-26 13:03:34,431][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021048] [Batch 00473/00823] [00:05:47/00:04:16, 0.734s/it]: train_loss_raw=0.8902, running_loss=0.9651, LR=0.000100
[2025-08-26 13:03:40,259][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021056] [Batch 00481/00823] [00:05:53/00:04:10, 0.734s/it]: train_loss_raw=1.0612, running_loss=0.9661, LR=0.000100
[2025-08-26 13:03:46,131][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021064] [Batch 00489/00823] [00:05:58/00:04:05, 0.734s/it]: train_loss_raw=0.9166, running_loss=0.9647, LR=0.000100
[2025-08-26 13:03:51,912][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021072] [Batch 00497/00823] [00:06:04/00:03:59, 0.734s/it]: train_loss_raw=0.9823, running_loss=0.9645, LR=0.000100
[2025-08-26 13:03:57,884][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021080] [Batch 00505/00823] [00:06:10/00:03:53, 0.734s/it]: train_loss_raw=0.9961, running_loss=0.9626, LR=0.000100
[2025-08-26 13:04:03,724][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021088] [Batch 00513/00823] [00:06:16/00:03:47, 0.734s/it]: train_loss_raw=0.9495, running_loss=0.9612, LR=0.000100
[2025-08-26 13:04:09,488][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021096] [Batch 00521/00823] [00:06:22/00:03:41, 0.734s/it]: train_loss_raw=1.0037, running_loss=0.9614, LR=0.000100
[2025-08-26 13:04:15,190][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021104] [Batch 00529/00823] [00:06:27/00:03:35, 0.733s/it]: train_loss_raw=1.0047, running_loss=0.9609, LR=0.000100
[2025-08-26 13:04:20,966][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021112] [Batch 00537/00823] [00:06:33/00:03:29, 0.733s/it]: train_loss_raw=0.7414, running_loss=0.9578, LR=0.000100
[2025-08-26 13:04:26,670][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021120] [Batch 00545/00823] [00:06:39/00:03:23, 0.733s/it]: train_loss_raw=0.9188, running_loss=0.9563, LR=0.000100
[2025-08-26 13:04:32,480][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021128] [Batch 00553/00823] [00:06:45/00:03:17, 0.733s/it]: train_loss_raw=0.9248, running_loss=0.9526, LR=0.000100
[2025-08-26 13:04:38,375][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021136] [Batch 00561/00823] [00:06:51/00:03:12, 0.733s/it]: train_loss_raw=0.9533, running_loss=0.9543, LR=0.000100
[2025-08-26 13:04:44,257][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021144] [Batch 00569/00823] [00:06:57/00:03:06, 0.733s/it]: train_loss_raw=0.9595, running_loss=0.9571, LR=0.000100
[2025-08-26 13:04:50,205][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021152] [Batch 00577/00823] [00:07:02/00:03:00, 0.733s/it]: train_loss_raw=0.9281, running_loss=0.9579, LR=0.000100
[2025-08-26 13:04:56,327][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021160] [Batch 00585/00823] [00:07:09/00:02:54, 0.733s/it]: train_loss_raw=0.9170, running_loss=0.9576, LR=0.000100
[2025-08-26 13:05:02,272][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021168] [Batch 00593/00823] [00:07:15/00:02:48, 0.734s/it]: train_loss_raw=0.8980, running_loss=0.9598, LR=0.000100
[2025-08-26 13:05:08,161][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021176] [Batch 00601/00823] [00:07:20/00:02:42, 0.734s/it]: train_loss_raw=0.9488, running_loss=0.9584, LR=0.000100
[2025-08-26 13:05:13,953][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021184] [Batch 00609/00823] [00:07:26/00:02:36, 0.734s/it]: train_loss_raw=0.8519, running_loss=0.9564, LR=0.000100
[2025-08-26 13:05:19,895][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021192] [Batch 00617/00823] [00:07:32/00:02:31, 0.734s/it]: train_loss_raw=0.9745, running_loss=0.9584, LR=0.000100
[2025-08-26 13:05:25,858][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021200] [Batch 00625/00823] [00:07:38/00:02:25, 0.734s/it]: train_loss_raw=1.0119, running_loss=0.9581, LR=0.000100
[2025-08-26 13:05:31,746][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021208] [Batch 00633/00823] [00:07:44/00:02:19, 0.734s/it]: train_loss_raw=0.9078, running_loss=0.9562, LR=0.000100
[2025-08-26 13:05:37,534][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021216] [Batch 00641/00823] [00:07:50/00:02:13, 0.734s/it]: train_loss_raw=0.8633, running_loss=0.9549, LR=0.000100
[2025-08-26 13:05:43,318][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021224] [Batch 00649/00823] [00:07:56/00:02:07, 0.734s/it]: train_loss_raw=0.8328, running_loss=0.9521, LR=0.000100
[2025-08-26 13:05:49,117][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021232] [Batch 00657/00823] [00:08:01/00:02:01, 0.733s/it]: train_loss_raw=0.9129, running_loss=0.9495, LR=0.000100
[2025-08-26 13:05:54,859][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021240] [Batch 00665/00823] [00:08:07/00:01:55, 0.733s/it]: train_loss_raw=1.0721, running_loss=0.9512, LR=0.000100
[2025-08-26 13:06:00,912][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021248] [Batch 00673/00823] [00:08:13/00:01:50, 0.734s/it]: train_loss_raw=0.8767, running_loss=0.9505, LR=0.000100
[2025-08-26 13:06:07,004][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021256] [Batch 00681/00823] [00:08:19/00:01:44, 0.734s/it]: train_loss_raw=0.9423, running_loss=0.9487, LR=0.000100
[2025-08-26 13:06:12,863][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021264] [Batch 00689/00823] [00:08:25/00:01:38, 0.734s/it]: train_loss_raw=0.9084, running_loss=0.9493, LR=0.000100
[2025-08-26 13:06:18,913][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021272] [Batch 00697/00823] [00:08:31/00:01:32, 0.734s/it]: train_loss_raw=0.9234, running_loss=0.9463, LR=0.000100
[2025-08-26 13:06:24,804][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021280] [Batch 00705/00823] [00:08:37/00:01:26, 0.734s/it]: train_loss_raw=0.9202, running_loss=0.9459, LR=0.000100
[2025-08-26 13:06:30,619][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021288] [Batch 00713/00823] [00:08:43/00:01:20, 0.734s/it]: train_loss_raw=0.8085, running_loss=0.9465, LR=0.000100
[2025-08-26 13:06:36,367][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021296] [Batch 00721/00823] [00:08:49/00:01:14, 0.734s/it]: train_loss_raw=0.8425, running_loss=0.9464, LR=0.000100
[2025-08-26 13:06:42,192][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021304] [Batch 00729/00823] [00:08:54/00:01:08, 0.734s/it]: train_loss_raw=0.8902, running_loss=0.9440, LR=0.000100
[2025-08-26 13:06:47,974][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021312] [Batch 00737/00823] [00:09:00/00:01:03, 0.734s/it]: train_loss_raw=0.8994, running_loss=0.9460, LR=0.000100
[2025-08-26 13:06:53,806][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021320] [Batch 00745/00823] [00:09:06/00:00:57, 0.734s/it]: train_loss_raw=0.9640, running_loss=0.9458, LR=0.000100
[2025-08-26 13:06:59,649][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021328] [Batch 00753/00823] [00:09:12/00:00:51, 0.734s/it]: train_loss_raw=1.0364, running_loss=0.9465, LR=0.000100
[2025-08-26 13:07:05,616][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021336] [Batch 00761/00823] [00:09:18/00:00:45, 0.734s/it]: train_loss_raw=0.8570, running_loss=0.9468, LR=0.000100
[2025-08-26 13:07:11,484][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021344] [Batch 00769/00823] [00:09:24/00:00:39, 0.734s/it]: train_loss_raw=0.9139, running_loss=0.9477, LR=0.000100
[2025-08-26 13:07:17,283][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021352] [Batch 00777/00823] [00:09:30/00:00:33, 0.734s/it]: train_loss_raw=0.9103, running_loss=0.9463, LR=0.000100
[2025-08-26 13:07:23,028][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021360] [Batch 00785/00823] [00:09:35/00:00:27, 0.733s/it]: train_loss_raw=0.8297, running_loss=0.9472, LR=0.000100
[2025-08-26 13:07:28,772][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021368] [Batch 00793/00823] [00:09:41/00:00:21, 0.733s/it]: train_loss_raw=0.9068, running_loss=0.9480, LR=0.000100
[2025-08-26 13:07:34,557][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021376] [Batch 00801/00823] [00:09:47/00:00:16, 0.733s/it]: train_loss_raw=0.8948, running_loss=0.9474, LR=0.000100
[2025-08-26 13:07:40,517][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021384] [Batch 00809/00823] [00:09:53/00:00:10, 0.733s/it]: train_loss_raw=1.0660, running_loss=0.9514, LR=0.000100
[2025-08-26 13:07:46,609][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021392] [Batch 00817/00823] [00:09:59/00:00:04, 0.734s/it]: train_loss_raw=0.9392, running_loss=0.9519, LR=0.000100
[2025-08-26 13:07:56,876][__main__][INFO] - [VALIDATION] [Epoch 25/29] Starting validation.
[2025-08-26 13:08:07,903][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 021399] [Batch 00007/00013] [00:00:11/00:00:06, 1.378s/it]
[2025-08-26 13:08:15,265][__main__][INFO] - [VALIDATION] [Epoch 25/29] train_loss=0.95135, valid_loss=1.36840
[2025-08-26 13:08:15,266][__main__][INFO] - [VALIDATION] [Epoch 25/29] Metrics:
[2025-08-26 13:08:15,266][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_er      0.554
[2025-08-26 13:08:15,266][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_prec    0.090
[2025-08-26 13:08:15,266][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_recall  0.092
[2025-08-26 13:08:15,267][__main__][INFO] - [VALIDATION] [Epoch 25/29] - pep_recall 0.050
[2025-08-26 13:08:15,269][__main__][INFO] - [TRAIN] [Epoch 25/29] Epoch complete, total time 04:35:39, remaining time 00:42:24, 00:10:36 per epoch
[2025-08-26 13:08:16,503][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021400] [Batch 00002/00823] [00:00:00/00:06:19, 0.463s/it]: train_loss_raw=0.9088, running_loss=0.8362, LR=0.000100
[2025-08-26 13:08:22,650][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021408] [Batch 00010/00823] [00:00:07/00:09:34, 0.707s/it]: train_loss_raw=0.8958, running_loss=0.8384, LR=0.000100
[2025-08-26 13:08:28,570][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021416] [Batch 00018/00823] [00:00:12/00:09:41, 0.722s/it]: train_loss_raw=0.8183, running_loss=0.8451, LR=0.000100
[2025-08-26 13:08:34,339][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021424] [Batch 00026/00823] [00:00:18/00:09:35, 0.722s/it]: train_loss_raw=0.8614, running_loss=0.8492, LR=0.000100
[2025-08-26 13:08:40,092][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021432] [Batch 00034/00823] [00:00:24/00:09:28, 0.721s/it]: train_loss_raw=0.8942, running_loss=0.8546, LR=0.000100
[2025-08-26 13:08:45,892][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021440] [Batch 00042/00823] [00:00:30/00:09:23, 0.722s/it]: train_loss_raw=0.8277, running_loss=0.8548, LR=0.000100
[2025-08-26 13:08:51,828][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021448] [Batch 00050/00823] [00:00:36/00:09:20, 0.725s/it]: train_loss_raw=0.9679, running_loss=0.8603, LR=0.000100
[2025-08-26 13:08:57,686][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021456] [Batch 00058/00823] [00:00:42/00:09:15, 0.726s/it]: train_loss_raw=0.9657, running_loss=0.8643, LR=0.000100
[2025-08-26 13:09:03,572][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021464] [Batch 00066/00823] [00:00:47/00:09:10, 0.727s/it]: train_loss_raw=0.9643, running_loss=0.8672, LR=0.000100
[2025-08-26 13:09:09,708][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021472] [Batch 00074/00823] [00:00:54/00:09:07, 0.731s/it]: train_loss_raw=0.8452, running_loss=0.8692, LR=0.000100
[2025-08-26 13:09:15,641][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021480] [Batch 00082/00823] [00:01:00/00:09:02, 0.732s/it]: train_loss_raw=0.8826, running_loss=0.8714, LR=0.000100
[2025-08-26 13:09:21,618][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021488] [Batch 00090/00823] [00:01:06/00:08:57, 0.734s/it]: train_loss_raw=0.8874, running_loss=0.8736, LR=0.000100
[2025-08-26 13:09:27,514][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021496] [Batch 00098/00823] [00:01:11/00:08:52, 0.734s/it]: train_loss_raw=0.9026, running_loss=0.8744, LR=0.000100
[2025-08-26 13:09:33,491][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021504] [Batch 00106/00823] [00:01:17/00:08:47, 0.735s/it]: train_loss_raw=0.9130, running_loss=0.8774, LR=0.000100
[2025-08-26 13:09:39,410][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021512] [Batch 00114/00823] [00:01:23/00:08:41, 0.735s/it]: train_loss_raw=0.8335, running_loss=0.8786, LR=0.000100
[2025-08-26 13:09:45,209][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021520] [Batch 00122/00823] [00:01:29/00:08:35, 0.735s/it]: train_loss_raw=0.9182, running_loss=0.8803, LR=0.000100
[2025-08-26 13:09:50,970][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021528] [Batch 00130/00823] [00:01:35/00:08:28, 0.734s/it]: train_loss_raw=0.7902, running_loss=0.8826, LR=0.000100
[2025-08-26 13:09:56,639][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021536] [Batch 00138/00823] [00:01:41/00:08:21, 0.732s/it]: train_loss_raw=0.9428, running_loss=0.8848, LR=0.000100
[2025-08-26 13:10:02,628][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021544] [Batch 00146/00823] [00:01:47/00:08:16, 0.733s/it]: train_loss_raw=0.9688, running_loss=0.8840, LR=0.000100
[2025-08-26 13:10:08,517][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021552] [Batch 00154/00823] [00:01:52/00:08:10, 0.733s/it]: train_loss_raw=0.8777, running_loss=0.8854, LR=0.000100
[2025-08-26 13:10:14,416][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021560] [Batch 00162/00823] [00:01:58/00:08:04, 0.734s/it]: train_loss_raw=0.9389, running_loss=0.8864, LR=0.000100
[2025-08-26 13:10:20,530][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021568] [Batch 00170/00823] [00:02:04/00:07:59, 0.735s/it]: train_loss_raw=0.7715, running_loss=0.8858, LR=0.000100
[2025-08-26 13:10:26,441][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021576] [Batch 00178/00823] [00:02:10/00:07:54, 0.735s/it]: train_loss_raw=0.9091, running_loss=0.8853, LR=0.000100
[2025-08-26 13:10:32,303][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021584] [Batch 00186/00823] [00:02:16/00:07:48, 0.735s/it]: train_loss_raw=0.9449, running_loss=0.8889, LR=0.000100
[2025-08-26 13:10:38,183][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021592] [Batch 00194/00823] [00:02:22/00:07:42, 0.735s/it]: train_loss_raw=0.9147, running_loss=0.8922, LR=0.000100
[2025-08-26 13:10:43,989][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021600] [Batch 00202/00823] [00:02:28/00:07:36, 0.735s/it]: train_loss_raw=0.8974, running_loss=0.8937, LR=0.000100
[2025-08-26 13:10:49,978][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021608] [Batch 00210/00823] [00:02:34/00:07:30, 0.735s/it]: train_loss_raw=0.8642, running_loss=0.8927, LR=0.000100
[2025-08-26 13:10:55,697][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021616] [Batch 00218/00823] [00:02:40/00:07:24, 0.734s/it]: train_loss_raw=0.9782, running_loss=0.8950, LR=0.000100
[2025-08-26 13:11:01,429][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021624] [Batch 00226/00823] [00:02:45/00:07:18, 0.734s/it]: train_loss_raw=0.8637, running_loss=0.8918, LR=0.000100
[2025-08-26 13:11:07,330][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021632] [Batch 00234/00823] [00:02:51/00:07:12, 0.734s/it]: train_loss_raw=0.9517, running_loss=0.8915, LR=0.000100
[2025-08-26 13:11:12,954][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021640] [Batch 00242/00823] [00:02:57/00:07:05, 0.733s/it]: train_loss_raw=0.8914, running_loss=0.8911, LR=0.000100
[2025-08-26 13:11:18,816][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021648] [Batch 00250/00823] [00:03:03/00:06:59, 0.733s/it]: train_loss_raw=0.9201, running_loss=0.8924, LR=0.000100
[2025-08-26 13:11:24,783][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021656] [Batch 00258/00823] [00:03:09/00:06:54, 0.733s/it]: train_loss_raw=0.8725, running_loss=0.8925, LR=0.000100
[2025-08-26 13:11:30,619][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021664] [Batch 00266/00823] [00:03:15/00:06:48, 0.733s/it]: train_loss_raw=0.9159, running_loss=0.8932, LR=0.000100
[2025-08-26 13:11:36,365][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021672] [Batch 00274/00823] [00:03:20/00:06:42, 0.733s/it]: train_loss_raw=0.9995, running_loss=0.8949, LR=0.000100
[2025-08-26 13:11:42,282][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021680] [Batch 00282/00823] [00:03:26/00:06:36, 0.733s/it]: train_loss_raw=0.8517, running_loss=0.8942, LR=0.000100
[2025-08-26 13:11:48,153][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021688] [Batch 00290/00823] [00:03:32/00:06:30, 0.733s/it]: train_loss_raw=0.8014, running_loss=0.8947, LR=0.000100
[2025-08-26 13:11:54,176][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021696] [Batch 00298/00823] [00:03:38/00:06:25, 0.734s/it]: train_loss_raw=0.8617, running_loss=0.8952, LR=0.000100
[2025-08-26 13:12:00,078][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021704] [Batch 00306/00823] [00:03:44/00:06:19, 0.734s/it]: train_loss_raw=0.9213, running_loss=0.8941, LR=0.000100
[2025-08-26 13:12:05,858][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021712] [Batch 00314/00823] [00:03:50/00:06:13, 0.733s/it]: train_loss_raw=0.9159, running_loss=0.8952, LR=0.000100
[2025-08-26 13:12:11,573][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021720] [Batch 00322/00823] [00:03:55/00:06:07, 0.733s/it]: train_loss_raw=0.9196, running_loss=0.8914, LR=0.000100
[2025-08-26 13:12:17,486][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021728] [Batch 00330/00823] [00:04:01/00:06:01, 0.733s/it]: train_loss_raw=0.8877, running_loss=0.8926, LR=0.000100
[2025-08-26 13:12:23,427][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021736] [Batch 00338/00823] [00:04:07/00:05:55, 0.733s/it]: train_loss_raw=0.9577, running_loss=0.8944, LR=0.000100
[2025-08-26 13:12:29,385][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021744] [Batch 00346/00823] [00:04:13/00:05:49, 0.734s/it]: train_loss_raw=0.8885, running_loss=0.8957, LR=0.000100
[2025-08-26 13:12:35,253][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021752] [Batch 00354/00823] [00:04:19/00:05:44, 0.734s/it]: train_loss_raw=0.8933, running_loss=0.8940, LR=0.000100
[2025-08-26 13:12:41,189][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021760] [Batch 00362/00823] [00:04:25/00:05:38, 0.734s/it]: train_loss_raw=0.9527, running_loss=0.8960, LR=0.000100
[2025-08-26 13:12:47,070][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021768] [Batch 00370/00823] [00:04:31/00:05:32, 0.734s/it]: train_loss_raw=0.9060, running_loss=0.8962, LR=0.000100
[2025-08-26 13:12:53,163][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021776] [Batch 00378/00823] [00:04:37/00:05:26, 0.734s/it]: train_loss_raw=0.9384, running_loss=0.8974, LR=0.000100
[2025-08-26 13:12:58,908][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021784] [Batch 00386/00823] [00:04:43/00:05:20, 0.734s/it]: train_loss_raw=0.7458, running_loss=0.8974, LR=0.000100
[2025-08-26 13:13:04,671][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021792] [Batch 00394/00823] [00:04:49/00:05:14, 0.734s/it]: train_loss_raw=0.9933, running_loss=0.8964, LR=0.000100
[2025-08-26 13:13:10,617][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021800] [Batch 00402/00823] [00:04:55/00:05:08, 0.734s/it]: train_loss_raw=0.9209, running_loss=0.8952, LR=0.000100
[2025-08-26 13:13:16,404][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021808] [Batch 00410/00823] [00:05:00/00:05:03, 0.734s/it]: train_loss_raw=0.8951, running_loss=0.8949, LR=0.000100
[2025-08-26 13:13:22,303][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021816] [Batch 00418/00823] [00:05:06/00:04:57, 0.734s/it]: train_loss_raw=0.8451, running_loss=0.8920, LR=0.000100
[2025-08-26 13:13:27,972][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021824] [Batch 00426/00823] [00:05:12/00:04:51, 0.733s/it]: train_loss_raw=0.8099, running_loss=0.8907, LR=0.000100
[2025-08-26 13:13:33,728][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021832] [Batch 00434/00823] [00:05:18/00:04:45, 0.733s/it]: train_loss_raw=0.9524, running_loss=0.8936, LR=0.000100
[2025-08-26 13:13:39,768][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021840] [Batch 00442/00823] [00:05:24/00:04:39, 0.733s/it]: train_loss_raw=0.9366, running_loss=0.8933, LR=0.000100
[2025-08-26 13:13:45,733][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021848] [Batch 00450/00823] [00:05:30/00:04:33, 0.734s/it]: train_loss_raw=0.9224, running_loss=0.8946, LR=0.000100
[2025-08-26 13:13:51,553][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021856] [Batch 00458/00823] [00:05:35/00:04:27, 0.734s/it]: train_loss_raw=0.8641, running_loss=0.8944, LR=0.000100
[2025-08-26 13:13:57,208][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021864] [Batch 00466/00823] [00:05:41/00:04:21, 0.733s/it]: train_loss_raw=0.9282, running_loss=0.8968, LR=0.000100
[2025-08-26 13:14:03,091][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021872] [Batch 00474/00823] [00:05:47/00:04:15, 0.733s/it]: train_loss_raw=0.9647, running_loss=0.8973, LR=0.000100
[2025-08-26 13:14:08,836][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021880] [Batch 00482/00823] [00:05:53/00:04:09, 0.733s/it]: train_loss_raw=0.9135, running_loss=0.8979, LR=0.000100
[2025-08-26 13:14:14,606][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021888] [Batch 00490/00823] [00:05:59/00:04:03, 0.733s/it]: train_loss_raw=1.0305, running_loss=0.9017, LR=0.000100
[2025-08-26 13:14:20,297][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021896] [Batch 00498/00823] [00:06:04/00:03:58, 0.732s/it]: train_loss_raw=0.8417, running_loss=0.9035, LR=0.000100
[2025-08-26 13:14:26,225][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021904] [Batch 00506/00823] [00:06:10/00:03:52, 0.733s/it]: train_loss_raw=0.8014, running_loss=0.9030, LR=0.000100
[2025-08-26 13:14:32,087][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021912] [Batch 00514/00823] [00:06:16/00:03:46, 0.733s/it]: train_loss_raw=0.8328, running_loss=0.9004, LR=0.000100
[2025-08-26 13:14:38,355][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021920] [Batch 00522/00823] [00:06:22/00:03:40, 0.733s/it]: train_loss_raw=0.9455, running_loss=0.9012, LR=0.000100
[2025-08-26 13:14:44,379][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021928] [Batch 00530/00823] [00:06:28/00:03:34, 0.734s/it]: train_loss_raw=0.9676, running_loss=0.9017, LR=0.000100
[2025-08-26 13:14:50,580][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021936] [Batch 00538/00823] [00:06:35/00:03:29, 0.734s/it]: train_loss_raw=0.8593, running_loss=0.9010, LR=0.000100
[2025-08-26 13:14:56,649][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021944] [Batch 00546/00823] [00:06:41/00:03:23, 0.735s/it]: train_loss_raw=0.8291, running_loss=0.8992, LR=0.000100
[2025-08-26 13:15:02,665][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021952] [Batch 00554/00823] [00:06:47/00:03:17, 0.735s/it]: train_loss_raw=1.0046, running_loss=0.8984, LR=0.000100
[2025-08-26 13:15:08,711][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021960] [Batch 00562/00823] [00:06:53/00:03:11, 0.735s/it]: train_loss_raw=0.7994, running_loss=0.8989, LR=0.000100
[2025-08-26 13:15:14,704][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021968] [Batch 00570/00823] [00:06:59/00:03:06, 0.735s/it]: train_loss_raw=0.9869, running_loss=0.8989, LR=0.000100
[2025-08-26 13:15:20,771][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021976] [Batch 00578/00823] [00:07:05/00:03:00, 0.736s/it]: train_loss_raw=0.9097, running_loss=0.9028, LR=0.000100
[2025-08-26 13:15:26,864][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021984] [Batch 00586/00823] [00:07:11/00:02:54, 0.736s/it]: train_loss_raw=0.8233, running_loss=0.9014, LR=0.000100
[2025-08-26 13:15:32,898][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021992] [Batch 00594/00823] [00:07:17/00:02:48, 0.736s/it]: train_loss_raw=0.8722, running_loss=0.9024, LR=0.000100
[2025-08-26 13:15:38,930][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022000] [Batch 00602/00823] [00:07:23/00:02:42, 0.736s/it]: train_loss_raw=0.8927, running_loss=0.9054, LR=0.000100
[2025-08-26 13:15:49,151][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022008] [Batch 00610/00823] [00:07:33/00:02:38, 0.744s/it]: train_loss_raw=0.9278, running_loss=0.9071, LR=0.000100
[2025-08-26 13:15:55,068][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022016] [Batch 00618/00823] [00:07:39/00:02:32, 0.744s/it]: train_loss_raw=0.8448, running_loss=0.9073, LR=0.000100
[2025-08-26 13:16:00,966][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022024] [Batch 00626/00823] [00:07:45/00:02:26, 0.743s/it]: train_loss_raw=0.8717, running_loss=0.9067, LR=0.000100
[2025-08-26 13:16:06,763][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022032] [Batch 00634/00823] [00:07:51/00:02:20, 0.743s/it]: train_loss_raw=0.9435, running_loss=0.9055, LR=0.000100
[2025-08-26 13:16:12,663][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022040] [Batch 00642/00823] [00:07:57/00:02:14, 0.743s/it]: train_loss_raw=0.8824, running_loss=0.9047, LR=0.000100
[2025-08-26 13:16:18,454][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022048] [Batch 00650/00823] [00:08:02/00:02:08, 0.743s/it]: train_loss_raw=1.0113, running_loss=0.9063, LR=0.000100
[2025-08-26 13:16:24,242][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022056] [Batch 00658/00823] [00:08:08/00:02:02, 0.743s/it]: train_loss_raw=0.8489, running_loss=0.9033, LR=0.000100
[2025-08-26 13:16:30,263][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022064] [Batch 00666/00823] [00:08:14/00:01:56, 0.743s/it]: train_loss_raw=0.9223, running_loss=0.9053, LR=0.000100
[2025-08-26 13:16:36,225][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022072] [Batch 00674/00823] [00:08:20/00:01:50, 0.743s/it]: train_loss_raw=0.9568, running_loss=0.9052, LR=0.000100
[2025-08-26 13:16:41,864][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022080] [Batch 00682/00823] [00:08:26/00:01:44, 0.742s/it]: train_loss_raw=0.8578, running_loss=0.9020, LR=0.000100
[2025-08-26 13:16:47,721][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022088] [Batch 00690/00823] [00:08:32/00:01:38, 0.742s/it]: train_loss_raw=0.9658, running_loss=0.9030, LR=0.000100
[2025-08-26 13:16:53,601][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022096] [Batch 00698/00823] [00:08:38/00:01:32, 0.742s/it]: train_loss_raw=0.9107, running_loss=0.9023, LR=0.000100
[2025-08-26 13:16:59,486][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022104] [Batch 00706/00823] [00:08:43/00:01:26, 0.742s/it]: train_loss_raw=0.9423, running_loss=0.9047, LR=0.000100
[2025-08-26 13:17:05,287][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022112] [Batch 00714/00823] [00:08:49/00:01:20, 0.742s/it]: train_loss_raw=0.8842, running_loss=0.9037, LR=0.000100
[2025-08-26 13:17:11,039][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022120] [Batch 00722/00823] [00:08:55/00:01:14, 0.742s/it]: train_loss_raw=0.9731, running_loss=0.9064, LR=0.000100
[2025-08-26 13:17:16,794][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022128] [Batch 00730/00823] [00:09:01/00:01:08, 0.741s/it]: train_loss_raw=0.8445, running_loss=0.9052, LR=0.000100
[2025-08-26 13:17:22,576][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022136] [Batch 00738/00823] [00:09:06/00:01:03, 0.741s/it]: train_loss_raw=0.9204, running_loss=0.9051, LR=0.000100
[2025-08-26 13:17:28,537][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022144] [Batch 00746/00823] [00:09:12/00:00:57, 0.741s/it]: train_loss_raw=0.9609, running_loss=0.9026, LR=0.000100
[2025-08-26 13:17:34,421][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022152] [Batch 00754/00823] [00:09:18/00:00:51, 0.741s/it]: train_loss_raw=0.9501, running_loss=0.9030, LR=0.000100
[2025-08-26 13:17:40,280][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022160] [Batch 00762/00823] [00:09:24/00:00:45, 0.741s/it]: train_loss_raw=0.8890, running_loss=0.9021, LR=0.000100
[2025-08-26 13:17:46,289][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022168] [Batch 00770/00823] [00:09:30/00:00:39, 0.741s/it]: train_loss_raw=0.9183, running_loss=0.9017, LR=0.000100
[2025-08-26 13:17:52,321][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022176] [Batch 00778/00823] [00:09:36/00:00:33, 0.741s/it]: train_loss_raw=0.8385, running_loss=0.9013, LR=0.000100
[2025-08-26 13:17:58,320][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022184] [Batch 00786/00823] [00:09:42/00:00:27, 0.741s/it]: train_loss_raw=0.8892, running_loss=0.9010, LR=0.000100
[2025-08-26 13:18:04,082][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022192] [Batch 00794/00823] [00:09:48/00:00:21, 0.741s/it]: train_loss_raw=0.9625, running_loss=0.9029, LR=0.000100
[2025-08-26 13:18:09,691][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022200] [Batch 00802/00823] [00:09:54/00:00:15, 0.741s/it]: train_loss_raw=0.9402, running_loss=0.9033, LR=0.000100
[2025-08-26 13:18:15,494][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022208] [Batch 00810/00823] [00:09:59/00:00:09, 0.741s/it]: train_loss_raw=0.9411, running_loss=0.9037, LR=0.000100
[2025-08-26 13:18:21,451][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022216] [Batch 00818/00823] [00:10:05/00:00:03, 0.741s/it]: train_loss_raw=0.9150, running_loss=0.9014, LR=0.000100
[2025-08-26 13:18:25,369][__main__][INFO] - [VALIDATION] [Epoch 26/29] Starting validation.
[2025-08-26 13:18:36,674][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 022222] [Batch 00007/00013] [00:00:11/00:00:07, 1.413s/it]
[2025-08-26 13:18:43,857][__main__][INFO] - [VALIDATION] [Epoch 26/29] train_loss=0.90190, valid_loss=1.40120
[2025-08-26 13:18:43,858][__main__][INFO] - [VALIDATION] [Epoch 26/29] Metrics:
[2025-08-26 13:18:43,858][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_er      0.552
[2025-08-26 13:18:43,858][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_prec    0.087
[2025-08-26 13:18:43,858][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_recall  0.088
[2025-08-26 13:18:43,858][__main__][INFO] - [VALIDATION] [Epoch 26/29] - pep_recall 0.050
[2025-08-26 13:18:43,860][__main__][INFO] - [TRAIN] [Epoch 26/29] Epoch complete, total time 04:46:07, remaining time 00:31:47, 00:10:35 per epoch
[2025-08-26 13:18:45,723][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022224] [Batch 00003/00823] [00:00:01/00:07:28, 0.547s/it]: train_loss_raw=0.9631, running_loss=0.9621, LR=0.000100
[2025-08-26 13:18:51,702][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022232] [Batch 00011/00823] [00:00:07/00:09:22, 0.693s/it]: train_loss_raw=0.7451, running_loss=0.9567, LR=0.000100
[2025-08-26 13:18:57,720][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022240] [Batch 00019/00823] [00:00:13/00:09:37, 0.718s/it]: train_loss_raw=0.9650, running_loss=0.9507, LR=0.000100
[2025-08-26 13:19:03,741][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022248] [Batch 00027/00823] [00:00:19/00:09:39, 0.728s/it]: train_loss_raw=0.7967, running_loss=0.9437, LR=0.000100
[2025-08-26 13:19:09,621][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022256] [Batch 00035/00823] [00:00:25/00:09:34, 0.730s/it]: train_loss_raw=0.8791, running_loss=0.9416, LR=0.000100
[2025-08-26 13:19:15,443][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022264] [Batch 00043/00823] [00:00:31/00:09:28, 0.729s/it]: train_loss_raw=0.9470, running_loss=0.9400, LR=0.000100
[2025-08-26 13:19:21,353][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022272] [Batch 00051/00823] [00:00:37/00:09:24, 0.731s/it]: train_loss_raw=0.7913, running_loss=0.9381, LR=0.000100
[2025-08-26 13:19:27,112][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022280] [Batch 00059/00823] [00:00:43/00:09:17, 0.729s/it]: train_loss_raw=0.9796, running_loss=0.9365, LR=0.000100
[2025-08-26 13:19:32,953][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022288] [Batch 00067/00823] [00:00:48/00:09:11, 0.729s/it]: train_loss_raw=0.8678, running_loss=0.9346, LR=0.000100
[2025-08-26 13:19:38,809][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022296] [Batch 00075/00823] [00:00:54/00:09:05, 0.730s/it]: train_loss_raw=0.8909, running_loss=0.9345, LR=0.000100
[2025-08-26 13:19:44,657][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022304] [Batch 00083/00823] [00:01:00/00:09:00, 0.730s/it]: train_loss_raw=0.8702, running_loss=0.9317, LR=0.000100
[2025-08-26 13:19:50,613][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022312] [Batch 00091/00823] [00:01:06/00:08:55, 0.731s/it]: train_loss_raw=0.9431, running_loss=0.9303, LR=0.000100
[2025-08-26 13:19:56,463][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022320] [Batch 00099/00823] [00:01:12/00:08:49, 0.731s/it]: train_loss_raw=0.9211, running_loss=0.9294, LR=0.000100
[2025-08-26 13:20:02,278][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022328] [Batch 00107/00823] [00:01:18/00:08:43, 0.731s/it]: train_loss_raw=0.8604, running_loss=0.9264, LR=0.000100
[2025-08-26 13:20:08,071][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022336] [Batch 00115/00823] [00:01:23/00:08:37, 0.730s/it]: train_loss_raw=0.9401, running_loss=0.9272, LR=0.000100
[2025-08-26 13:20:13,901][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022344] [Batch 00123/00823] [00:01:29/00:08:31, 0.730s/it]: train_loss_raw=0.9365, running_loss=0.9273, LR=0.000100
[2025-08-26 13:20:19,691][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022352] [Batch 00131/00823] [00:01:35/00:08:25, 0.730s/it]: train_loss_raw=0.8956, running_loss=0.9255, LR=0.000100
[2025-08-26 13:20:25,388][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022360] [Batch 00139/00823] [00:01:41/00:08:18, 0.729s/it]: train_loss_raw=0.9225, running_loss=0.9240, LR=0.000100
[2025-08-26 13:20:31,200][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022368] [Batch 00147/00823] [00:01:47/00:08:12, 0.729s/it]: train_loss_raw=0.8553, running_loss=0.9215, LR=0.000100
[2025-08-26 13:20:37,343][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022376] [Batch 00155/00823] [00:01:53/00:08:08, 0.731s/it]: train_loss_raw=0.8711, running_loss=0.9194, LR=0.000100
[2025-08-26 13:20:43,303][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022384] [Batch 00163/00823] [00:01:59/00:08:02, 0.731s/it]: train_loss_raw=0.8274, running_loss=0.9176, LR=0.000100
[2025-08-26 13:20:49,250][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022392] [Batch 00171/00823] [00:02:05/00:07:57, 0.732s/it]: train_loss_raw=0.8735, running_loss=0.9173, LR=0.000100
[2025-08-26 13:20:55,063][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022400] [Batch 00179/00823] [00:02:10/00:07:51, 0.732s/it]: train_loss_raw=0.8475, running_loss=0.9197, LR=0.000100
[2025-08-26 13:21:00,752][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022408] [Batch 00187/00823] [00:02:16/00:07:44, 0.731s/it]: train_loss_raw=1.0026, running_loss=0.9196, LR=0.000100
[2025-08-26 13:21:06,472][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022416] [Batch 00195/00823] [00:02:22/00:07:38, 0.730s/it]: train_loss_raw=0.9072, running_loss=0.9185, LR=0.000100
[2025-08-26 13:21:12,325][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022424] [Batch 00203/00823] [00:02:28/00:07:32, 0.730s/it]: train_loss_raw=0.8249, running_loss=0.9167, LR=0.000100
[2025-08-26 13:21:18,250][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022432] [Batch 00211/00823] [00:02:34/00:07:27, 0.731s/it]: train_loss_raw=0.8277, running_loss=0.9148, LR=0.000100
[2025-08-26 13:21:24,083][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022440] [Batch 00219/00823] [00:02:39/00:07:21, 0.731s/it]: train_loss_raw=0.9680, running_loss=0.9141, LR=0.000100
[2025-08-26 13:21:29,853][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022448] [Batch 00227/00823] [00:02:45/00:07:15, 0.730s/it]: train_loss_raw=0.9734, running_loss=0.9151, LR=0.000100
[2025-08-26 13:21:35,688][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022456] [Batch 00235/00823] [00:02:51/00:07:09, 0.730s/it]: train_loss_raw=0.8766, running_loss=0.9159, LR=0.000100
[2025-08-26 13:21:41,700][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022464] [Batch 00243/00823] [00:02:57/00:07:03, 0.731s/it]: train_loss_raw=0.9314, running_loss=0.9162, LR=0.000100
[2025-08-26 13:21:47,563][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022472] [Batch 00251/00823] [00:03:03/00:06:58, 0.731s/it]: train_loss_raw=0.9040, running_loss=0.9156, LR=0.000100
[2025-08-26 13:21:53,333][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022480] [Batch 00259/00823] [00:03:09/00:06:52, 0.731s/it]: train_loss_raw=0.9626, running_loss=0.9147, LR=0.000100
[2025-08-26 13:21:59,132][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022488] [Batch 00267/00823] [00:03:15/00:06:46, 0.731s/it]: train_loss_raw=0.8441, running_loss=0.9109, LR=0.000100
[2025-08-26 13:22:04,880][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022496] [Batch 00275/00823] [00:03:20/00:06:40, 0.730s/it]: train_loss_raw=0.8518, running_loss=0.9085, LR=0.000100
[2025-08-26 13:22:10,798][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022504] [Batch 00283/00823] [00:03:26/00:06:34, 0.730s/it]: train_loss_raw=0.9382, running_loss=0.9065, LR=0.000100
[2025-08-26 13:22:16,728][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022512] [Batch 00291/00823] [00:03:32/00:06:28, 0.731s/it]: train_loss_raw=0.8057, running_loss=0.9035, LR=0.000100
[2025-08-26 13:22:22,618][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022520] [Batch 00299/00823] [00:03:38/00:06:22, 0.731s/it]: train_loss_raw=0.8046, running_loss=0.9014, LR=0.000100
[2025-08-26 13:22:28,375][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022528] [Batch 00307/00823] [00:03:44/00:06:16, 0.731s/it]: train_loss_raw=0.9441, running_loss=0.9018, LR=0.000100
[2025-08-26 13:22:34,138][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022536] [Batch 00315/00823] [00:03:50/00:06:11, 0.730s/it]: train_loss_raw=0.8675, running_loss=0.9007, LR=0.000100
[2025-08-26 13:22:39,937][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022544] [Batch 00323/00823] [00:03:55/00:06:05, 0.730s/it]: train_loss_raw=0.9088, running_loss=0.8995, LR=0.000100
[2025-08-26 13:22:45,824][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022552] [Batch 00331/00823] [00:04:01/00:05:59, 0.730s/it]: train_loss_raw=0.9423, running_loss=0.9010, LR=0.000100
[2025-08-26 13:22:51,715][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022560] [Batch 00339/00823] [00:04:07/00:05:53, 0.730s/it]: train_loss_raw=0.9339, running_loss=0.9029, LR=0.000100
[2025-08-26 13:22:57,498][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022568] [Batch 00347/00823] [00:04:13/00:05:47, 0.730s/it]: train_loss_raw=0.8621, running_loss=0.9025, LR=0.000100
[2025-08-26 13:23:03,020][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022576] [Batch 00355/00823] [00:04:18/00:05:41, 0.729s/it]: train_loss_raw=0.8731, running_loss=0.9003, LR=0.000100
[2025-08-26 13:23:08,691][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022584] [Batch 00363/00823] [00:04:24/00:05:35, 0.729s/it]: train_loss_raw=0.8353, running_loss=0.8968, LR=0.000100
[2025-08-26 13:23:14,338][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022592] [Batch 00371/00823] [00:04:30/00:05:29, 0.728s/it]: train_loss_raw=0.8789, running_loss=0.8957, LR=0.000100
[2025-08-26 13:23:20,083][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022600] [Batch 00379/00823] [00:04:36/00:05:23, 0.728s/it]: train_loss_raw=0.8278, running_loss=0.8961, LR=0.000100
[2025-08-26 13:23:25,677][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022608] [Batch 00387/00823] [00:04:41/00:05:17, 0.728s/it]: train_loss_raw=0.8784, running_loss=0.8963, LR=0.000100
[2025-08-26 13:23:31,418][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022616] [Batch 00395/00823] [00:04:47/00:05:11, 0.727s/it]: train_loss_raw=0.8740, running_loss=0.8947, LR=0.000100
[2025-08-26 13:23:37,102][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022624] [Batch 00403/00823] [00:04:53/00:05:05, 0.727s/it]: train_loss_raw=0.8975, running_loss=0.8937, LR=0.000100
[2025-08-26 13:23:42,760][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022632] [Batch 00411/00823] [00:04:58/00:04:59, 0.727s/it]: train_loss_raw=0.8353, running_loss=0.8942, LR=0.000100
[2025-08-26 13:23:48,346][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022640] [Batch 00419/00823] [00:05:04/00:04:53, 0.726s/it]: train_loss_raw=0.8787, running_loss=0.8937, LR=0.000100
[2025-08-26 13:23:54,024][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022648] [Batch 00427/00823] [00:05:09/00:04:47, 0.726s/it]: train_loss_raw=0.9657, running_loss=0.8956, LR=0.000100
[2025-08-26 13:23:59,931][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022656] [Batch 00435/00823] [00:05:15/00:04:41, 0.726s/it]: train_loss_raw=0.7994, running_loss=0.8950, LR=0.000100
[2025-08-26 13:24:05,725][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022664] [Batch 00443/00823] [00:05:21/00:04:35, 0.726s/it]: train_loss_raw=0.8624, running_loss=0.8942, LR=0.000100
[2025-08-26 13:24:11,584][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022672] [Batch 00451/00823] [00:05:27/00:04:30, 0.726s/it]: train_loss_raw=0.8302, running_loss=0.8934, LR=0.000100
[2025-08-26 13:24:17,257][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022680] [Batch 00459/00823] [00:05:33/00:04:24, 0.726s/it]: train_loss_raw=0.8700, running_loss=0.8921, LR=0.000100
[2025-08-26 13:24:23,103][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022688] [Batch 00467/00823] [00:05:39/00:04:18, 0.726s/it]: train_loss_raw=0.8818, running_loss=0.8907, LR=0.000100
[2025-08-26 13:24:28,952][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022696] [Batch 00475/00823] [00:05:44/00:04:12, 0.726s/it]: train_loss_raw=0.9810, running_loss=0.8928, LR=0.000100
[2025-08-26 13:24:34,619][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022704] [Batch 00483/00823] [00:05:50/00:04:06, 0.726s/it]: train_loss_raw=0.8715, running_loss=0.8960, LR=0.000100
[2025-08-26 13:24:40,545][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022712] [Batch 00491/00823] [00:05:56/00:04:01, 0.726s/it]: train_loss_raw=0.9371, running_loss=0.8973, LR=0.000100
[2025-08-26 13:24:46,246][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022720] [Batch 00499/00823] [00:06:02/00:03:55, 0.726s/it]: train_loss_raw=0.9256, running_loss=0.8974, LR=0.000100
[2025-08-26 13:24:52,047][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022728] [Batch 00507/00823] [00:06:07/00:03:49, 0.726s/it]: train_loss_raw=0.7752, running_loss=0.8963, LR=0.000100
[2025-08-26 13:24:57,968][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022736] [Batch 00515/00823] [00:06:13/00:03:43, 0.726s/it]: train_loss_raw=0.9351, running_loss=0.8998, LR=0.000100
[2025-08-26 13:25:03,753][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022744] [Batch 00523/00823] [00:06:19/00:03:37, 0.726s/it]: train_loss_raw=0.8915, running_loss=0.9005, LR=0.000100
[2025-08-26 13:25:09,587][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022752] [Batch 00531/00823] [00:06:25/00:03:31, 0.726s/it]: train_loss_raw=0.8443, running_loss=0.9012, LR=0.000100
[2025-08-26 13:25:15,400][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022760] [Batch 00539/00823] [00:06:31/00:03:26, 0.726s/it]: train_loss_raw=0.8844, running_loss=0.9018, LR=0.000100
[2025-08-26 13:25:21,298][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022768] [Batch 00547/00823] [00:06:37/00:03:20, 0.726s/it]: train_loss_raw=0.8759, running_loss=0.9008, LR=0.000100
[2025-08-26 13:25:27,110][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022776] [Batch 00555/00823] [00:06:43/00:03:14, 0.726s/it]: train_loss_raw=0.9372, running_loss=0.9024, LR=0.000100
[2025-08-26 13:25:32,841][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022784] [Batch 00563/00823] [00:06:48/00:03:08, 0.726s/it]: train_loss_raw=0.9070, running_loss=0.9015, LR=0.000100
[2025-08-26 13:25:38,535][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022792] [Batch 00571/00823] [00:06:54/00:03:02, 0.726s/it]: train_loss_raw=0.9183, running_loss=0.9025, LR=0.000100
[2025-08-26 13:25:44,403][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022800] [Batch 00579/00823] [00:07:00/00:02:57, 0.726s/it]: train_loss_raw=0.9224, running_loss=0.9026, LR=0.000100
[2025-08-26 13:25:50,252][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022808] [Batch 00587/00823] [00:07:06/00:02:51, 0.726s/it]: train_loss_raw=0.8983, running_loss=0.9030, LR=0.000100
[2025-08-26 13:25:56,048][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022816] [Batch 00595/00823] [00:07:11/00:02:45, 0.726s/it]: train_loss_raw=0.9537, running_loss=0.9017, LR=0.000100
[2025-08-26 13:26:01,933][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022824] [Batch 00603/00823] [00:07:17/00:02:39, 0.726s/it]: train_loss_raw=0.8906, running_loss=0.9005, LR=0.000100
[2025-08-26 13:26:07,890][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022832] [Batch 00611/00823] [00:07:23/00:02:33, 0.726s/it]: train_loss_raw=0.8294, running_loss=0.8987, LR=0.000100
[2025-08-26 13:26:13,927][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022840] [Batch 00619/00823] [00:07:29/00:02:28, 0.727s/it]: train_loss_raw=0.8249, running_loss=0.8982, LR=0.000100
[2025-08-26 13:26:19,681][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022848] [Batch 00627/00823] [00:07:35/00:02:22, 0.727s/it]: train_loss_raw=0.8816, running_loss=0.8967, LR=0.000100
[2025-08-26 13:26:25,515][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022856] [Batch 00635/00823] [00:07:41/00:02:16, 0.727s/it]: train_loss_raw=0.9012, running_loss=0.8951, LR=0.000100
[2025-08-26 13:26:31,355][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022864] [Batch 00643/00823] [00:07:47/00:02:10, 0.727s/it]: train_loss_raw=0.9337, running_loss=0.8938, LR=0.000100
[2025-08-26 13:26:36,987][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022872] [Batch 00651/00823] [00:07:52/00:02:04, 0.726s/it]: train_loss_raw=0.8781, running_loss=0.8950, LR=0.000100
[2025-08-26 13:26:42,815][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022880] [Batch 00659/00823] [00:07:58/00:01:59, 0.726s/it]: train_loss_raw=0.8647, running_loss=0.8983, LR=0.000100
[2025-08-26 13:26:48,840][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022888] [Batch 00667/00823] [00:08:04/00:01:53, 0.727s/it]: train_loss_raw=0.8915, running_loss=0.8988, LR=0.000100
[2025-08-26 13:26:54,540][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022896] [Batch 00675/00823] [00:08:10/00:01:47, 0.727s/it]: train_loss_raw=0.9081, running_loss=0.8983, LR=0.000100
[2025-08-26 13:27:00,425][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022904] [Batch 00683/00823] [00:08:16/00:01:41, 0.727s/it]: train_loss_raw=0.7993, running_loss=0.8949, LR=0.000100
[2025-08-26 13:27:06,400][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022912] [Batch 00691/00823] [00:08:22/00:01:35, 0.727s/it]: train_loss_raw=0.8506, running_loss=0.8931, LR=0.000100
[2025-08-26 13:27:12,241][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022920] [Batch 00699/00823] [00:08:28/00:01:30, 0.727s/it]: train_loss_raw=0.9435, running_loss=0.8933, LR=0.000100
[2025-08-26 13:27:18,063][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022928] [Batch 00707/00823] [00:08:33/00:01:24, 0.727s/it]: train_loss_raw=0.8995, running_loss=0.8930, LR=0.000100
[2025-08-26 13:27:23,892][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022936] [Batch 00715/00823] [00:08:39/00:01:18, 0.727s/it]: train_loss_raw=0.8926, running_loss=0.8929, LR=0.000100
[2025-08-26 13:27:29,839][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022944] [Batch 00723/00823] [00:08:45/00:01:12, 0.727s/it]: train_loss_raw=0.8269, running_loss=0.8920, LR=0.000100
[2025-08-26 13:27:35,766][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022952] [Batch 00731/00823] [00:08:51/00:01:06, 0.727s/it]: train_loss_raw=0.9411, running_loss=0.8926, LR=0.000100
[2025-08-26 13:27:41,391][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022960] [Batch 00739/00823] [00:08:57/00:01:01, 0.727s/it]: train_loss_raw=0.8613, running_loss=0.8941, LR=0.000100
[2025-08-26 13:27:46,989][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022968] [Batch 00747/00823] [00:09:02/00:00:55, 0.727s/it]: train_loss_raw=0.9152, running_loss=0.8960, LR=0.000100
[2025-08-26 13:27:52,923][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022976] [Batch 00755/00823] [00:09:08/00:00:49, 0.727s/it]: train_loss_raw=0.9016, running_loss=0.8947, LR=0.000100
[2025-08-26 13:27:58,699][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022984] [Batch 00763/00823] [00:09:14/00:00:43, 0.727s/it]: train_loss_raw=0.9474, running_loss=0.8922, LR=0.000100
[2025-08-26 13:28:04,451][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022992] [Batch 00771/00823] [00:09:20/00:00:37, 0.727s/it]: train_loss_raw=0.8398, running_loss=0.8915, LR=0.000100
[2025-08-26 13:28:10,367][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023000] [Batch 00779/00823] [00:09:26/00:00:31, 0.727s/it]: train_loss_raw=0.7223, running_loss=0.8886, LR=0.000100
[2025-08-26 13:28:16,252][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023008] [Batch 00787/00823] [00:09:32/00:00:26, 0.727s/it]: train_loss_raw=0.8658, running_loss=0.8886, LR=0.000100
[2025-08-26 13:28:21,969][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023016] [Batch 00795/00823] [00:09:37/00:00:20, 0.727s/it]: train_loss_raw=0.8465, running_loss=0.8908, LR=0.000100
[2025-08-26 13:28:27,676][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023024] [Batch 00803/00823] [00:09:43/00:00:14, 0.727s/it]: train_loss_raw=0.8408, running_loss=0.8930, LR=0.000100
[2025-08-26 13:28:33,400][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023032] [Batch 00811/00823] [00:09:49/00:00:08, 0.727s/it]: train_loss_raw=0.8836, running_loss=0.8944, LR=0.000100
[2025-08-26 13:28:39,190][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023040] [Batch 00819/00823] [00:09:55/00:00:02, 0.727s/it]: train_loss_raw=0.8796, running_loss=0.8939, LR=0.000100
[2025-08-26 13:28:47,709][__main__][INFO] - [VALIDATION] [Epoch 27/29] Starting validation.
[2025-08-26 13:28:58,487][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 023045] [Batch 00007/00013] [00:00:10/00:00:06, 1.347s/it]
[2025-08-26 13:29:05,272][__main__][INFO] - [VALIDATION] [Epoch 27/29] train_loss=0.89277, valid_loss=1.40517
[2025-08-26 13:29:05,273][__main__][INFO] - [VALIDATION] [Epoch 27/29] Metrics:
[2025-08-26 13:29:05,273][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_er      0.559
[2025-08-26 13:29:05,273][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_prec    0.081
[2025-08-26 13:29:05,273][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_recall  0.082
[2025-08-26 13:29:05,273][__main__][INFO] - [VALIDATION] [Epoch 27/29] - pep_recall 0.046
[2025-08-26 13:29:05,275][__main__][INFO] - [TRAIN] [Epoch 27/29] Epoch complete, total time 04:56:29, remaining time 00:21:10, 00:10:35 per epoch
[2025-08-26 13:29:08,550][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023048] [Batch 00004/00823] [00:00:03/00:10:34, 0.774s/it]: train_loss_raw=0.7173, running_loss=0.8085, LR=0.000100
[2025-08-26 13:29:14,416][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023056] [Batch 00012/00823] [00:00:08/00:10:05, 0.747s/it]: train_loss_raw=0.8140, running_loss=0.8097, LR=0.000100
[2025-08-26 13:29:20,254][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023064] [Batch 00020/00823] [00:00:14/00:09:54, 0.740s/it]: train_loss_raw=0.9072, running_loss=0.8119, LR=0.000100
[2025-08-26 13:29:26,211][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023072] [Batch 00028/00823] [00:00:20/00:09:49, 0.741s/it]: train_loss_raw=0.8292, running_loss=0.8125, LR=0.000100
[2025-08-26 13:29:31,819][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023080] [Batch 00036/00823] [00:00:26/00:09:36, 0.732s/it]: train_loss_raw=0.8829, running_loss=0.8161, LR=0.000100
[2025-08-26 13:29:37,783][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023088] [Batch 00044/00823] [00:00:32/00:09:32, 0.735s/it]: train_loss_raw=0.8861, running_loss=0.8164, LR=0.000100
[2025-08-26 13:29:43,684][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023096] [Batch 00052/00823] [00:00:38/00:09:26, 0.735s/it]: train_loss_raw=0.8421, running_loss=0.8173, LR=0.000100
[2025-08-26 13:29:49,525][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023104] [Batch 00060/00823] [00:00:44/00:09:20, 0.735s/it]: train_loss_raw=0.7885, running_loss=0.8165, LR=0.000100
[2025-08-26 13:29:55,431][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023112] [Batch 00068/00823] [00:00:49/00:09:14, 0.735s/it]: train_loss_raw=0.8558, running_loss=0.8173, LR=0.000100
[2025-08-26 13:30:01,302][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023120] [Batch 00076/00823] [00:00:55/00:09:08, 0.735s/it]: train_loss_raw=0.8277, running_loss=0.8184, LR=0.000100
[2025-08-26 13:30:06,973][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023128] [Batch 00084/00823] [00:01:01/00:09:01, 0.732s/it]: train_loss_raw=0.9777, running_loss=0.8204, LR=0.000100
[2025-08-26 13:30:12,644][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023136] [Batch 00092/00823] [00:01:07/00:08:53, 0.730s/it]: train_loss_raw=0.7853, running_loss=0.8209, LR=0.000100
[2025-08-26 13:30:18,410][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023144] [Batch 00100/00823] [00:01:12/00:08:47, 0.730s/it]: train_loss_raw=0.8919, running_loss=0.8214, LR=0.000100
[2025-08-26 13:30:24,180][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023152] [Batch 00108/00823] [00:01:18/00:08:41, 0.729s/it]: train_loss_raw=0.8104, running_loss=0.8216, LR=0.000100
[2025-08-26 13:30:29,935][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023160] [Batch 00116/00823] [00:01:24/00:08:34, 0.728s/it]: train_loss_raw=0.7815, running_loss=0.8215, LR=0.000100
[2025-08-26 13:30:35,770][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023168] [Batch 00124/00823] [00:01:30/00:08:29, 0.728s/it]: train_loss_raw=0.8434, running_loss=0.8215, LR=0.000100
[2025-08-26 13:30:41,673][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023176] [Batch 00132/00823] [00:01:36/00:08:23, 0.729s/it]: train_loss_raw=0.8700, running_loss=0.8213, LR=0.000100
[2025-08-26 13:30:47,582][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023184] [Batch 00140/00823] [00:01:42/00:08:18, 0.729s/it]: train_loss_raw=0.7150, running_loss=0.8210, LR=0.000100
[2025-08-26 13:30:53,103][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023192] [Batch 00148/00823] [00:01:47/00:08:10, 0.727s/it]: train_loss_raw=0.7578, running_loss=0.8216, LR=0.000100
[2025-08-26 13:30:58,731][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023200] [Batch 00156/00823] [00:01:53/00:08:04, 0.726s/it]: train_loss_raw=0.9299, running_loss=0.8242, LR=0.000100
[2025-08-26 13:31:04,602][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023208] [Batch 00164/00823] [00:01:59/00:07:58, 0.727s/it]: train_loss_raw=0.9361, running_loss=0.8281, LR=0.000100
[2025-08-26 13:31:10,432][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023216] [Batch 00172/00823] [00:02:04/00:07:53, 0.727s/it]: train_loss_raw=0.7602, running_loss=0.8258, LR=0.000100
[2025-08-26 13:31:16,404][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023224] [Batch 00180/00823] [00:02:10/00:07:47, 0.728s/it]: train_loss_raw=0.7989, running_loss=0.8259, LR=0.000100
[2025-08-26 13:31:22,219][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023232] [Batch 00188/00823] [00:02:16/00:07:41, 0.727s/it]: train_loss_raw=0.8207, running_loss=0.8251, LR=0.000100
[2025-08-26 13:31:27,982][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023240] [Batch 00196/00823] [00:02:22/00:07:35, 0.727s/it]: train_loss_raw=0.8780, running_loss=0.8258, LR=0.000100
[2025-08-26 13:31:33,834][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023248] [Batch 00204/00823] [00:02:28/00:07:30, 0.727s/it]: train_loss_raw=0.7641, running_loss=0.8259, LR=0.000100
[2025-08-26 13:31:39,608][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023256] [Batch 00212/00823] [00:02:34/00:07:24, 0.727s/it]: train_loss_raw=0.8351, running_loss=0.8261, LR=0.000100
[2025-08-26 13:31:45,489][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023264] [Batch 00220/00823] [00:02:40/00:07:18, 0.727s/it]: train_loss_raw=0.8303, running_loss=0.8268, LR=0.000100
[2025-08-26 13:31:51,205][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023272] [Batch 00228/00823] [00:02:45/00:07:12, 0.727s/it]: train_loss_raw=0.7759, running_loss=0.8282, LR=0.000100
[2025-08-26 13:31:57,052][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023280] [Batch 00236/00823] [00:02:51/00:07:06, 0.727s/it]: train_loss_raw=0.7927, running_loss=0.8257, LR=0.000100
[2025-08-26 13:32:02,787][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023288] [Batch 00244/00823] [00:02:57/00:07:00, 0.727s/it]: train_loss_raw=0.8132, running_loss=0.8285, LR=0.000100
[2025-08-26 13:32:08,568][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023296] [Batch 00252/00823] [00:03:03/00:06:54, 0.727s/it]: train_loss_raw=0.8382, running_loss=0.8287, LR=0.000100
[2025-08-26 13:32:14,247][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023304] [Batch 00260/00823] [00:03:08/00:06:48, 0.726s/it]: train_loss_raw=0.8910, running_loss=0.8299, LR=0.000100
[2025-08-26 13:32:19,948][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023312] [Batch 00268/00823] [00:03:14/00:06:42, 0.726s/it]: train_loss_raw=0.9202, running_loss=0.8317, LR=0.000100
[2025-08-26 13:32:25,724][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023320] [Batch 00276/00823] [00:03:20/00:06:36, 0.726s/it]: train_loss_raw=0.7774, running_loss=0.8309, LR=0.000100
[2025-08-26 13:32:31,571][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023328] [Batch 00284/00823] [00:03:26/00:06:31, 0.726s/it]: train_loss_raw=0.7832, running_loss=0.8300, LR=0.000100
[2025-08-26 13:32:37,634][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023336] [Batch 00292/00823] [00:03:32/00:06:25, 0.727s/it]: train_loss_raw=0.8905, running_loss=0.8319, LR=0.000100
[2025-08-26 13:32:43,563][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023344] [Batch 00300/00823] [00:03:38/00:06:20, 0.727s/it]: train_loss_raw=0.8798, running_loss=0.8322, LR=0.000100
[2025-08-26 13:32:49,541][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023352] [Batch 00308/00823] [00:03:44/00:06:14, 0.728s/it]: train_loss_raw=0.7937, running_loss=0.8306, LR=0.000100
[2025-08-26 13:32:55,506][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023360] [Batch 00316/00823] [00:03:50/00:06:09, 0.728s/it]: train_loss_raw=0.7794, running_loss=0.8303, LR=0.000100
[2025-08-26 13:33:01,250][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023368] [Batch 00324/00823] [00:03:55/00:06:03, 0.728s/it]: train_loss_raw=0.8406, running_loss=0.8328, LR=0.000100
[2025-08-26 13:33:07,099][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023376] [Batch 00332/00823] [00:04:01/00:05:57, 0.728s/it]: train_loss_raw=0.7884, running_loss=0.8343, LR=0.000100
[2025-08-26 13:33:12,933][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023384] [Batch 00340/00823] [00:04:07/00:05:51, 0.728s/it]: train_loss_raw=0.8550, running_loss=0.8331, LR=0.000100
[2025-08-26 13:33:18,664][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023392] [Batch 00348/00823] [00:04:13/00:05:45, 0.728s/it]: train_loss_raw=0.7873, running_loss=0.8327, LR=0.000100
[2025-08-26 13:33:24,394][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023400] [Batch 00356/00823] [00:04:18/00:05:39, 0.727s/it]: train_loss_raw=0.8977, running_loss=0.8341, LR=0.000100
[2025-08-26 13:33:30,155][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023408] [Batch 00364/00823] [00:04:24/00:05:33, 0.727s/it]: train_loss_raw=0.8058, running_loss=0.8330, LR=0.000100
[2025-08-26 13:33:35,952][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023416] [Batch 00372/00823] [00:04:30/00:05:27, 0.727s/it]: train_loss_raw=0.8177, running_loss=0.8307, LR=0.000100
[2025-08-26 13:33:41,826][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023424] [Batch 00380/00823] [00:04:36/00:05:22, 0.727s/it]: train_loss_raw=0.8714, running_loss=0.8340, LR=0.000100
[2025-08-26 13:33:47,824][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023432] [Batch 00388/00823] [00:04:42/00:05:16, 0.728s/it]: train_loss_raw=0.8052, running_loss=0.8338, LR=0.000100
[2025-08-26 13:33:53,518][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023440] [Batch 00396/00823] [00:04:48/00:05:10, 0.727s/it]: train_loss_raw=0.8407, running_loss=0.8354, LR=0.000100
[2025-08-26 13:33:59,261][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023448] [Batch 00404/00823] [00:04:53/00:05:04, 0.727s/it]: train_loss_raw=0.8758, running_loss=0.8383, LR=0.000100
[2025-08-26 13:34:05,079][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023456] [Batch 00412/00823] [00:04:59/00:04:58, 0.727s/it]: train_loss_raw=0.7709, running_loss=0.8348, LR=0.000100
[2025-08-26 13:34:10,986][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023464] [Batch 00420/00823] [00:05:05/00:04:53, 0.727s/it]: train_loss_raw=0.8494, running_loss=0.8369, LR=0.000100
[2025-08-26 13:34:16,719][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023472] [Batch 00428/00823] [00:05:11/00:04:47, 0.727s/it]: train_loss_raw=0.8535, running_loss=0.8379, LR=0.000100
[2025-08-26 13:34:22,548][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023480] [Batch 00436/00823] [00:05:17/00:04:41, 0.727s/it]: train_loss_raw=0.8587, running_loss=0.8395, LR=0.000100
[2025-08-26 13:34:28,442][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023488] [Batch 00444/00823] [00:05:22/00:04:35, 0.727s/it]: train_loss_raw=0.8985, running_loss=0.8413, LR=0.000100
[2025-08-26 13:34:34,328][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023496] [Batch 00452/00823] [00:05:28/00:04:29, 0.728s/it]: train_loss_raw=0.7691, running_loss=0.8407, LR=0.000100
[2025-08-26 13:34:40,242][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023504] [Batch 00460/00823] [00:05:34/00:04:24, 0.728s/it]: train_loss_raw=0.8921, running_loss=0.8405, LR=0.000100
[2025-08-26 13:34:46,254][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023512] [Batch 00468/00823] [00:05:40/00:04:18, 0.728s/it]: train_loss_raw=0.8205, running_loss=0.8396, LR=0.000100
[2025-08-26 13:34:52,206][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023520] [Batch 00476/00823] [00:05:46/00:04:12, 0.728s/it]: train_loss_raw=0.8108, running_loss=0.8390, LR=0.000100
[2025-08-26 13:34:58,023][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023528] [Batch 00484/00823] [00:05:52/00:04:06, 0.728s/it]: train_loss_raw=0.9353, running_loss=0.8396, LR=0.000100
[2025-08-26 13:35:03,954][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023536] [Batch 00492/00823] [00:05:58/00:04:01, 0.729s/it]: train_loss_raw=0.7792, running_loss=0.8379, LR=0.000100
[2025-08-26 13:35:09,684][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023544] [Batch 00500/00823] [00:06:04/00:03:55, 0.728s/it]: train_loss_raw=0.8320, running_loss=0.8389, LR=0.000100
[2025-08-26 13:35:15,483][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023552] [Batch 00508/00823] [00:06:10/00:03:49, 0.728s/it]: train_loss_raw=0.9037, running_loss=0.8406, LR=0.000100
[2025-08-26 13:35:21,241][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023560] [Batch 00516/00823] [00:06:15/00:03:43, 0.728s/it]: train_loss_raw=0.8325, running_loss=0.8408, LR=0.000100
[2025-08-26 13:35:27,230][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023568] [Batch 00524/00823] [00:06:21/00:03:37, 0.729s/it]: train_loss_raw=0.7595, running_loss=0.8411, LR=0.000100
[2025-08-26 13:35:33,291][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023576] [Batch 00532/00823] [00:06:27/00:03:32, 0.729s/it]: train_loss_raw=0.8724, running_loss=0.8411, LR=0.000100
[2025-08-26 13:35:39,010][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023584] [Batch 00540/00823] [00:06:33/00:03:26, 0.729s/it]: train_loss_raw=0.7881, running_loss=0.8403, LR=0.000100
[2025-08-26 13:35:44,883][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023592] [Batch 00548/00823] [00:06:39/00:03:20, 0.729s/it]: train_loss_raw=0.8820, running_loss=0.8397, LR=0.000100
[2025-08-26 13:35:51,029][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023600] [Batch 00556/00823] [00:06:45/00:03:14, 0.729s/it]: train_loss_raw=0.8355, running_loss=0.8405, LR=0.000100
[2025-08-26 13:35:56,931][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023608] [Batch 00564/00823] [00:06:51/00:03:08, 0.730s/it]: train_loss_raw=0.8614, running_loss=0.8402, LR=0.000100
[2025-08-26 13:36:02,731][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023616] [Batch 00572/00823] [00:06:57/00:03:03, 0.730s/it]: train_loss_raw=0.8493, running_loss=0.8402, LR=0.000100
[2025-08-26 13:36:08,639][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023624] [Batch 00580/00823] [00:07:03/00:02:57, 0.730s/it]: train_loss_raw=0.8983, running_loss=0.8442, LR=0.000100
[2025-08-26 13:36:14,587][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023632] [Batch 00588/00823] [00:07:09/00:02:51, 0.730s/it]: train_loss_raw=0.8623, running_loss=0.8457, LR=0.000100
[2025-08-26 13:36:20,750][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023640] [Batch 00596/00823] [00:07:15/00:02:45, 0.730s/it]: train_loss_raw=0.8567, running_loss=0.8480, LR=0.000100
[2025-08-26 13:36:26,605][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023648] [Batch 00604/00823] [00:07:21/00:02:39, 0.730s/it]: train_loss_raw=0.8137, running_loss=0.8461, LR=0.000100
[2025-08-26 13:36:32,636][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023656] [Batch 00612/00823] [00:07:27/00:02:34, 0.731s/it]: train_loss_raw=0.8941, running_loss=0.8449, LR=0.000100
[2025-08-26 13:36:38,673][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023664] [Batch 00620/00823] [00:07:33/00:02:28, 0.731s/it]: train_loss_raw=0.8770, running_loss=0.8431, LR=0.000100
[2025-08-26 13:36:44,758][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023672] [Batch 00628/00823] [00:07:39/00:02:22, 0.731s/it]: train_loss_raw=0.7870, running_loss=0.8441, LR=0.000100
[2025-08-26 13:36:50,754][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023680] [Batch 00636/00823] [00:07:45/00:02:16, 0.732s/it]: train_loss_raw=0.7650, running_loss=0.8446, LR=0.000100
[2025-08-26 13:36:56,721][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023688] [Batch 00644/00823] [00:07:51/00:02:10, 0.732s/it]: train_loss_raw=0.7941, running_loss=0.8416, LR=0.000100
[2025-08-26 13:37:02,816][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023696] [Batch 00652/00823] [00:07:57/00:02:05, 0.732s/it]: train_loss_raw=0.8118, running_loss=0.8417, LR=0.000100
[2025-08-26 13:37:08,776][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023704] [Batch 00660/00823] [00:08:03/00:01:59, 0.732s/it]: train_loss_raw=0.8575, running_loss=0.8423, LR=0.000100
[2025-08-26 13:37:14,680][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023712] [Batch 00668/00823] [00:08:09/00:01:53, 0.732s/it]: train_loss_raw=0.8277, running_loss=0.8407, LR=0.000100
[2025-08-26 13:37:20,676][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023720] [Batch 00676/00823] [00:08:15/00:01:47, 0.733s/it]: train_loss_raw=0.8486, running_loss=0.8400, LR=0.000100
[2025-08-26 13:37:26,644][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023728] [Batch 00684/00823] [00:08:21/00:01:41, 0.733s/it]: train_loss_raw=0.7825, running_loss=0.8413, LR=0.000100
[2025-08-26 13:37:32,364][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023736] [Batch 00692/00823] [00:08:26/00:01:35, 0.733s/it]: train_loss_raw=0.8108, running_loss=0.8445, LR=0.000100
[2025-08-26 13:37:38,197][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023744] [Batch 00700/00823] [00:08:32/00:01:30, 0.732s/it]: train_loss_raw=0.8709, running_loss=0.8437, LR=0.000100
[2025-08-26 13:37:44,150][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023752] [Batch 00708/00823] [00:08:38/00:01:24, 0.733s/it]: train_loss_raw=0.8791, running_loss=0.8421, LR=0.000100
[2025-08-26 13:37:50,147][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023760] [Batch 00716/00823] [00:08:44/00:01:18, 0.733s/it]: train_loss_raw=0.8246, running_loss=0.8413, LR=0.000100
[2025-08-26 13:37:56,029][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023768] [Batch 00724/00823] [00:08:50/00:01:12, 0.733s/it]: train_loss_raw=0.7365, running_loss=0.8422, LR=0.000100
[2025-08-26 13:38:01,936][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023776] [Batch 00732/00823] [00:08:56/00:01:06, 0.733s/it]: train_loss_raw=0.8051, running_loss=0.8442, LR=0.000100
[2025-08-26 13:38:07,786][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023784] [Batch 00740/00823] [00:09:02/00:01:00, 0.733s/it]: train_loss_raw=0.8399, running_loss=0.8442, LR=0.000100
[2025-08-26 13:38:13,564][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023792] [Batch 00748/00823] [00:09:08/00:00:54, 0.733s/it]: train_loss_raw=0.8477, running_loss=0.8454, LR=0.000100
[2025-08-26 13:38:19,414][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023800] [Batch 00756/00823] [00:09:13/00:00:49, 0.733s/it]: train_loss_raw=0.8191, running_loss=0.8424, LR=0.000100
[2025-08-26 13:38:25,274][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023808] [Batch 00764/00823] [00:09:19/00:00:43, 0.733s/it]: train_loss_raw=0.9020, running_loss=0.8419, LR=0.000100
[2025-08-26 13:38:31,089][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023816] [Batch 00772/00823] [00:09:25/00:00:37, 0.733s/it]: train_loss_raw=0.8693, running_loss=0.8448, LR=0.000100
[2025-08-26 13:38:36,905][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023824] [Batch 00780/00823] [00:09:31/00:00:31, 0.733s/it]: train_loss_raw=0.7853, running_loss=0.8444, LR=0.000100
[2025-08-26 13:38:42,760][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023832] [Batch 00788/00823] [00:09:37/00:00:25, 0.733s/it]: train_loss_raw=0.8609, running_loss=0.8426, LR=0.000100
[2025-08-26 13:38:48,644][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023840] [Batch 00796/00823] [00:09:43/00:00:19, 0.733s/it]: train_loss_raw=0.7767, running_loss=0.8416, LR=0.000100
[2025-08-26 13:38:54,430][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023848] [Batch 00804/00823] [00:09:48/00:00:13, 0.733s/it]: train_loss_raw=0.9059, running_loss=0.8431, LR=0.000100
[2025-08-26 13:39:00,257][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023856] [Batch 00812/00823] [00:09:54/00:00:08, 0.733s/it]: train_loss_raw=0.8112, running_loss=0.8444, LR=0.000100
[2025-08-26 13:39:06,027][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023864] [Batch 00820/00823] [00:10:00/00:00:02, 0.732s/it]: train_loss_raw=0.8952, running_loss=0.8440, LR=0.000100
[2025-08-26 13:39:08,441][__main__][INFO] - [VALIDATION] [Epoch 28/29] Starting validation.
[2025-08-26 13:39:19,646][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 023868] [Batch 00007/00013] [00:00:11/00:00:07, 1.401s/it]
[2025-08-26 13:39:27,142][__main__][INFO] - [VALIDATION] [Epoch 28/29] train_loss=0.84713, valid_loss=1.42790
[2025-08-26 13:39:27,142][__main__][INFO] - [VALIDATION] [Epoch 28/29] Metrics:
[2025-08-26 13:39:27,142][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_er      0.545
[2025-08-26 13:39:27,142][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_prec    0.093
[2025-08-26 13:39:27,142][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_recall  0.095
[2025-08-26 13:39:27,142][__main__][INFO] - [VALIDATION] [Epoch 28/29] - pep_recall 0.055
[2025-08-26 13:39:27,144][__main__][INFO] - [TRAIN] [Epoch 28/29] Epoch complete, total time 05:06:50, remaining time 00:10:34, 00:10:34 per epoch
[2025-08-26 13:39:30,637][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023872] [Batch 00005/00823] [00:00:03/00:08:49, 0.647s/it]: train_loss_raw=0.8457, running_loss=0.7896, LR=0.000100
[2025-08-26 13:39:36,639][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023880] [Batch 00013/00823] [00:00:09/00:09:35, 0.710s/it]: train_loss_raw=0.9063, running_loss=0.7931, LR=0.000100
[2025-08-26 13:39:42,441][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023888] [Batch 00021/00823] [00:00:15/00:09:34, 0.716s/it]: train_loss_raw=0.9695, running_loss=0.7963, LR=0.000100
[2025-08-26 13:39:48,260][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023896] [Batch 00029/00823] [00:00:20/00:09:31, 0.719s/it]: train_loss_raw=0.7760, running_loss=0.8003, LR=0.000100
[2025-08-26 13:39:54,184][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023904] [Batch 00037/00823] [00:00:26/00:09:28, 0.724s/it]: train_loss_raw=0.8254, running_loss=0.8035, LR=0.000100
[2025-08-26 13:40:00,072][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023912] [Batch 00045/00823] [00:00:32/00:09:24, 0.726s/it]: train_loss_raw=0.9232, running_loss=0.8096, LR=0.000100
[2025-08-26 13:40:06,062][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023920] [Batch 00053/00823] [00:00:38/00:09:21, 0.729s/it]: train_loss_raw=0.9356, running_loss=0.8127, LR=0.000100
[2025-08-26 13:40:11,823][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023928] [Batch 00061/00823] [00:00:44/00:09:14, 0.728s/it]: train_loss_raw=0.8534, running_loss=0.8161, LR=0.000100
[2025-08-26 13:40:17,696][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023936] [Batch 00069/00823] [00:00:50/00:09:09, 0.729s/it]: train_loss_raw=0.9100, running_loss=0.8198, LR=0.000100
[2025-08-26 13:40:23,680][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023944] [Batch 00077/00823] [00:00:56/00:09:05, 0.731s/it]: train_loss_raw=0.8202, running_loss=0.8197, LR=0.000100
[2025-08-26 13:40:29,453][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023952] [Batch 00085/00823] [00:01:02/00:08:58, 0.730s/it]: train_loss_raw=0.8631, running_loss=0.8220, LR=0.000100
[2025-08-26 13:40:35,287][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023960] [Batch 00093/00823] [00:01:07/00:08:52, 0.730s/it]: train_loss_raw=0.8740, running_loss=0.8224, LR=0.000100
[2025-08-26 13:40:41,129][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023968] [Batch 00101/00823] [00:01:13/00:08:47, 0.730s/it]: train_loss_raw=0.8841, running_loss=0.8258, LR=0.000100
[2025-08-26 13:40:46,795][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023976] [Batch 00109/00823] [00:01:19/00:08:40, 0.728s/it]: train_loss_raw=0.8350, running_loss=0.8255, LR=0.000100
[2025-08-26 13:40:52,585][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023984] [Batch 00117/00823] [00:01:25/00:08:34, 0.728s/it]: train_loss_raw=0.8059, running_loss=0.8262, LR=0.000100
[2025-08-26 13:40:58,389][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023992] [Batch 00125/00823] [00:01:30/00:08:28, 0.728s/it]: train_loss_raw=0.8322, running_loss=0.8258, LR=0.000100
[2025-08-26 13:41:04,195][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024000] [Batch 00133/00823] [00:01:36/00:08:22, 0.728s/it]: train_loss_raw=0.7548, running_loss=0.8266, LR=0.000100
[2025-08-26 13:41:14,065][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024008] [Batch 00141/00823] [00:01:46/00:08:35, 0.756s/it]: train_loss_raw=0.8010, running_loss=0.8253, LR=0.000100
[2025-08-26 13:41:19,938][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024016] [Batch 00149/00823] [00:01:52/00:08:29, 0.755s/it]: train_loss_raw=0.8555, running_loss=0.8253, LR=0.000100
[2025-08-26 13:41:25,683][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024024] [Batch 00157/00823] [00:01:58/00:08:21, 0.753s/it]: train_loss_raw=0.8583, running_loss=0.8262, LR=0.000100
[2025-08-26 13:41:31,533][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024032] [Batch 00165/00823] [00:02:04/00:08:15, 0.752s/it]: train_loss_raw=0.7909, running_loss=0.8267, LR=0.000100
[2025-08-26 13:41:37,188][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024040] [Batch 00173/00823] [00:02:09/00:08:07, 0.750s/it]: train_loss_raw=0.8414, running_loss=0.8271, LR=0.000100
[2025-08-26 13:41:43,058][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024048] [Batch 00181/00823] [00:02:15/00:08:01, 0.749s/it]: train_loss_raw=0.8694, running_loss=0.8311, LR=0.000100
[2025-08-26 13:41:48,968][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024056] [Batch 00189/00823] [00:02:21/00:07:54, 0.749s/it]: train_loss_raw=0.8974, running_loss=0.8330, LR=0.000100
[2025-08-26 13:41:54,801][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024064] [Batch 00197/00823] [00:02:27/00:07:48, 0.748s/it]: train_loss_raw=0.7945, running_loss=0.8328, LR=0.000100
[2025-08-26 13:42:00,528][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024072] [Batch 00205/00823] [00:02:33/00:07:41, 0.747s/it]: train_loss_raw=0.6834, running_loss=0.8325, LR=0.000100
[2025-08-26 13:42:06,123][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024080] [Batch 00213/00823] [00:02:38/00:07:34, 0.745s/it]: train_loss_raw=0.9708, running_loss=0.8341, LR=0.000100
[2025-08-26 13:42:11,914][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024088] [Batch 00221/00823] [00:02:44/00:07:28, 0.744s/it]: train_loss_raw=0.8648, running_loss=0.8320, LR=0.000100
[2025-08-26 13:42:17,668][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024096] [Batch 00229/00823] [00:02:50/00:07:21, 0.744s/it]: train_loss_raw=0.8053, running_loss=0.8329, LR=0.000100
[2025-08-26 13:42:23,428][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024104] [Batch 00237/00823] [00:02:56/00:07:15, 0.743s/it]: train_loss_raw=0.8524, running_loss=0.8324, LR=0.000100
[2025-08-26 13:42:29,188][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024112] [Batch 00245/00823] [00:03:01/00:07:08, 0.742s/it]: train_loss_raw=0.8357, running_loss=0.8342, LR=0.000100
[2025-08-26 13:42:34,995][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024120] [Batch 00253/00823] [00:03:07/00:07:02, 0.741s/it]: train_loss_raw=0.8338, running_loss=0.8359, LR=0.000100
[2025-08-26 13:42:40,978][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024128] [Batch 00261/00823] [00:03:13/00:06:56, 0.742s/it]: train_loss_raw=0.8634, running_loss=0.8369, LR=0.000100
[2025-08-26 13:42:46,747][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024136] [Batch 00269/00823] [00:03:19/00:06:50, 0.741s/it]: train_loss_raw=0.8513, running_loss=0.8365, LR=0.000100
[2025-08-26 13:42:52,583][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024144] [Batch 00277/00823] [00:03:25/00:06:44, 0.741s/it]: train_loss_raw=0.8158, running_loss=0.8358, LR=0.000100
[2025-08-26 13:42:58,605][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024152] [Batch 00285/00823] [00:03:31/00:06:38, 0.741s/it]: train_loss_raw=0.7469, running_loss=0.8359, LR=0.000100
[2025-08-26 13:43:04,441][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024160] [Batch 00293/00823] [00:03:37/00:06:32, 0.741s/it]: train_loss_raw=0.9938, running_loss=0.8382, LR=0.000100
[2025-08-26 13:43:10,392][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024168] [Batch 00301/00823] [00:03:42/00:06:26, 0.741s/it]: train_loss_raw=0.8256, running_loss=0.8375, LR=0.000100
[2025-08-26 13:43:16,284][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024176] [Batch 00309/00823] [00:03:48/00:06:20, 0.741s/it]: train_loss_raw=0.8845, running_loss=0.8390, LR=0.000100
[2025-08-26 13:43:22,035][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024184] [Batch 00317/00823] [00:03:54/00:06:14, 0.740s/it]: train_loss_raw=0.8459, running_loss=0.8374, LR=0.000100
[2025-08-26 13:43:27,963][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024192] [Batch 00325/00823] [00:04:00/00:06:08, 0.740s/it]: train_loss_raw=0.9199, running_loss=0.8394, LR=0.000100
[2025-08-26 13:43:33,715][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024200] [Batch 00333/00823] [00:04:06/00:06:02, 0.740s/it]: train_loss_raw=0.8406, running_loss=0.8379, LR=0.000100
[2025-08-26 13:43:39,569][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024208] [Batch 00341/00823] [00:04:12/00:05:56, 0.739s/it]: train_loss_raw=0.8382, running_loss=0.8388, LR=0.000100
[2025-08-26 13:43:45,481][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024216] [Batch 00349/00823] [00:04:18/00:05:50, 0.739s/it]: train_loss_raw=0.8277, running_loss=0.8397, LR=0.000100
[2025-08-26 13:43:51,171][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024224] [Batch 00357/00823] [00:04:23/00:05:44, 0.739s/it]: train_loss_raw=0.8380, running_loss=0.8394, LR=0.000100
[2025-08-26 13:43:56,808][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024232] [Batch 00365/00823] [00:04:29/00:05:38, 0.738s/it]: train_loss_raw=0.8253, running_loss=0.8391, LR=0.000100
[2025-08-26 13:44:02,612][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024240] [Batch 00373/00823] [00:04:35/00:05:32, 0.738s/it]: train_loss_raw=0.7685, running_loss=0.8385, LR=0.000100
[2025-08-26 13:44:08,291][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024248] [Batch 00381/00823] [00:04:40/00:05:25, 0.737s/it]: train_loss_raw=0.8045, running_loss=0.8398, LR=0.000100
[2025-08-26 13:44:13,964][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024256] [Batch 00389/00823] [00:04:46/00:05:19, 0.737s/it]: train_loss_raw=0.9012, running_loss=0.8422, LR=0.000100
[2025-08-26 13:44:20,200][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024264] [Batch 00397/00823] [00:04:52/00:05:14, 0.738s/it]: train_loss_raw=0.8594, running_loss=0.8418, LR=0.000100
[2025-08-26 13:44:25,932][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024272] [Batch 00405/00823] [00:04:58/00:05:08, 0.737s/it]: train_loss_raw=0.7886, running_loss=0.8424, LR=0.000100
[2025-08-26 13:44:31,741][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024280] [Batch 00413/00823] [00:05:04/00:05:02, 0.737s/it]: train_loss_raw=0.9716, running_loss=0.8434, LR=0.000100
[2025-08-26 13:44:37,550][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024288] [Batch 00421/00823] [00:05:10/00:04:56, 0.737s/it]: train_loss_raw=0.7935, running_loss=0.8431, LR=0.000100
[2025-08-26 13:44:43,489][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024296] [Batch 00429/00823] [00:05:16/00:04:50, 0.737s/it]: train_loss_raw=0.9737, running_loss=0.8437, LR=0.000100
[2025-08-26 13:44:49,450][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024304] [Batch 00437/00823] [00:05:22/00:04:44, 0.737s/it]: train_loss_raw=0.7997, running_loss=0.8441, LR=0.000100
[2025-08-26 13:44:55,302][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024312] [Batch 00445/00823] [00:05:27/00:04:38, 0.737s/it]: train_loss_raw=0.8038, running_loss=0.8444, LR=0.000100
[2025-08-26 13:45:01,279][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024320] [Batch 00453/00823] [00:05:33/00:04:32, 0.737s/it]: train_loss_raw=0.8624, running_loss=0.8426, LR=0.000100
[2025-08-26 13:45:07,048][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024328] [Batch 00461/00823] [00:05:39/00:04:26, 0.737s/it]: train_loss_raw=0.8630, running_loss=0.8416, LR=0.000100
[2025-08-26 13:45:12,862][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024336] [Batch 00469/00823] [00:05:45/00:04:20, 0.737s/it]: train_loss_raw=0.8797, running_loss=0.8412, LR=0.000100
[2025-08-26 13:45:18,841][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024344] [Batch 00477/00823] [00:05:51/00:04:14, 0.737s/it]: train_loss_raw=0.8489, running_loss=0.8410, LR=0.000100
[2025-08-26 13:45:24,660][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024352] [Batch 00485/00823] [00:05:57/00:04:08, 0.737s/it]: train_loss_raw=0.7588, running_loss=0.8385, LR=0.000100
[2025-08-26 13:45:30,542][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024360] [Batch 00493/00823] [00:06:03/00:04:03, 0.737s/it]: train_loss_raw=0.8383, running_loss=0.8390, LR=0.000100
[2025-08-26 13:45:36,426][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024368] [Batch 00501/00823] [00:06:09/00:03:57, 0.737s/it]: train_loss_raw=0.8290, running_loss=0.8409, LR=0.000100
[2025-08-26 13:45:42,100][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024376] [Batch 00509/00823] [00:06:14/00:03:51, 0.736s/it]: train_loss_raw=0.9544, running_loss=0.8409, LR=0.000100
[2025-08-26 13:45:47,880][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024384] [Batch 00517/00823] [00:06:20/00:03:45, 0.736s/it]: train_loss_raw=0.8022, running_loss=0.8410, LR=0.000100
[2025-08-26 13:45:53,808][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024392] [Batch 00525/00823] [00:06:26/00:03:39, 0.736s/it]: train_loss_raw=0.9215, running_loss=0.8436, LR=0.000100
[2025-08-26 13:45:59,639][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024400] [Batch 00533/00823] [00:06:32/00:03:33, 0.736s/it]: train_loss_raw=0.9202, running_loss=0.8439, LR=0.000100
[2025-08-26 13:46:05,365][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024408] [Batch 00541/00823] [00:06:37/00:03:27, 0.736s/it]: train_loss_raw=0.8952, running_loss=0.8430, LR=0.000100
[2025-08-26 13:46:11,132][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024416] [Batch 00549/00823] [00:06:43/00:03:21, 0.735s/it]: train_loss_raw=0.8374, running_loss=0.8405, LR=0.000100
[2025-08-26 13:46:17,221][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024424] [Batch 00557/00823] [00:06:49/00:03:15, 0.736s/it]: train_loss_raw=0.7871, running_loss=0.8416, LR=0.000100
[2025-08-26 13:46:23,031][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024432] [Batch 00565/00823] [00:06:55/00:03:09, 0.736s/it]: train_loss_raw=0.8914, running_loss=0.8420, LR=0.000100
[2025-08-26 13:46:28,948][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024440] [Batch 00573/00823] [00:07:01/00:03:03, 0.736s/it]: train_loss_raw=0.8401, running_loss=0.8413, LR=0.000100
[2025-08-26 13:46:34,740][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024448] [Batch 00581/00823] [00:07:07/00:02:57, 0.736s/it]: train_loss_raw=0.8159, running_loss=0.8406, LR=0.000100
[2025-08-26 13:46:40,746][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024456] [Batch 00589/00823] [00:07:13/00:02:52, 0.736s/it]: train_loss_raw=0.7995, running_loss=0.8394, LR=0.000100
[2025-08-26 13:46:46,635][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024464] [Batch 00597/00823] [00:07:19/00:02:46, 0.736s/it]: train_loss_raw=0.8801, running_loss=0.8399, LR=0.000100
[2025-08-26 13:46:52,477][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024472] [Batch 00605/00823] [00:07:25/00:02:40, 0.736s/it]: train_loss_raw=0.8550, running_loss=0.8375, LR=0.000100
[2025-08-26 13:46:58,052][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024480] [Batch 00613/00823] [00:07:30/00:02:34, 0.735s/it]: train_loss_raw=0.7593, running_loss=0.8356, LR=0.000100
[2025-08-26 13:47:04,107][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024488] [Batch 00621/00823] [00:07:36/00:02:28, 0.735s/it]: train_loss_raw=0.7477, running_loss=0.8363, LR=0.000100
[2025-08-26 13:47:09,950][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024496] [Batch 00629/00823] [00:07:42/00:02:22, 0.735s/it]: train_loss_raw=0.7965, running_loss=0.8345, LR=0.000100
[2025-08-26 13:47:15,819][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024504] [Batch 00637/00823] [00:07:48/00:02:16, 0.735s/it]: train_loss_raw=0.8076, running_loss=0.8339, LR=0.000100
[2025-08-26 13:47:21,608][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024512] [Batch 00645/00823] [00:07:54/00:02:10, 0.735s/it]: train_loss_raw=0.7997, running_loss=0.8313, LR=0.000100
[2025-08-26 13:47:27,575][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024520] [Batch 00653/00823] [00:08:00/00:02:05, 0.735s/it]: train_loss_raw=0.8388, running_loss=0.8326, LR=0.000100
[2025-08-26 13:47:33,407][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024528] [Batch 00661/00823] [00:08:06/00:01:59, 0.735s/it]: train_loss_raw=0.9828, running_loss=0.8330, LR=0.000100
[2025-08-26 13:47:39,305][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024536] [Batch 00669/00823] [00:08:11/00:01:53, 0.735s/it]: train_loss_raw=0.7567, running_loss=0.8336, LR=0.000100
[2025-08-26 13:47:45,254][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024544] [Batch 00677/00823] [00:08:17/00:01:47, 0.735s/it]: train_loss_raw=0.8457, running_loss=0.8321, LR=0.000100
[2025-08-26 13:47:51,487][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024552] [Batch 00685/00823] [00:08:24/00:01:41, 0.736s/it]: train_loss_raw=0.9067, running_loss=0.8346, LR=0.000100
[2025-08-26 13:47:57,349][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024560] [Batch 00693/00823] [00:08:29/00:01:35, 0.736s/it]: train_loss_raw=0.8310, running_loss=0.8378, LR=0.000100
[2025-08-26 13:48:03,229][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024568] [Batch 00701/00823] [00:08:35/00:01:29, 0.736s/it]: train_loss_raw=0.9313, running_loss=0.8397, LR=0.000100
[2025-08-26 13:48:09,028][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024576] [Batch 00709/00823] [00:08:41/00:01:23, 0.736s/it]: train_loss_raw=0.7417, running_loss=0.8385, LR=0.000100
[2025-08-26 13:48:14,994][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024584] [Batch 00717/00823] [00:08:47/00:01:17, 0.736s/it]: train_loss_raw=0.8492, running_loss=0.8366, LR=0.000100
[2025-08-26 13:48:20,919][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024592] [Batch 00725/00823] [00:08:53/00:01:12, 0.736s/it]: train_loss_raw=0.8624, running_loss=0.8364, LR=0.000100
[2025-08-26 13:48:26,623][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024600] [Batch 00733/00823] [00:08:59/00:01:06, 0.736s/it]: train_loss_raw=0.8063, running_loss=0.8356, LR=0.000100
[2025-08-26 13:48:32,370][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024608] [Batch 00741/00823] [00:09:04/00:01:00, 0.735s/it]: train_loss_raw=0.8872, running_loss=0.8350, LR=0.000100
[2025-08-26 13:48:38,220][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024616] [Batch 00749/00823] [00:09:10/00:00:54, 0.735s/it]: train_loss_raw=0.8599, running_loss=0.8344, LR=0.000100
[2025-08-26 13:48:44,065][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024624] [Batch 00757/00823] [00:09:16/00:00:48, 0.735s/it]: train_loss_raw=0.8169, running_loss=0.8334, LR=0.000100
[2025-08-26 13:48:49,839][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024632] [Batch 00765/00823] [00:09:22/00:00:42, 0.735s/it]: train_loss_raw=0.7480, running_loss=0.8339, LR=0.000100
[2025-08-26 13:48:55,726][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024640] [Batch 00773/00823] [00:09:28/00:00:36, 0.735s/it]: train_loss_raw=0.8494, running_loss=0.8352, LR=0.000100
[2025-08-26 13:49:01,678][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024648] [Batch 00781/00823] [00:09:34/00:00:30, 0.735s/it]: train_loss_raw=0.8247, running_loss=0.8348, LR=0.000100
[2025-08-26 13:49:07,826][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024656] [Batch 00789/00823] [00:09:40/00:00:25, 0.736s/it]: train_loss_raw=0.8343, running_loss=0.8318, LR=0.000100
[2025-08-26 13:49:13,715][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024664] [Batch 00797/00823] [00:09:46/00:00:19, 0.736s/it]: train_loss_raw=0.9094, running_loss=0.8334, LR=0.000100
[2025-08-26 13:49:19,544][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024672] [Batch 00805/00823] [00:09:52/00:00:13, 0.736s/it]: train_loss_raw=0.8506, running_loss=0.8363, LR=0.000100
[2025-08-26 13:49:25,291][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024680] [Batch 00813/00823] [00:09:57/00:00:07, 0.735s/it]: train_loss_raw=0.8796, running_loss=0.8359, LR=0.000100
[2025-08-26 13:49:31,017][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024688] [Batch 00821/00823] [00:10:03/00:00:01, 0.735s/it]: train_loss_raw=0.8169, running_loss=0.8327, LR=0.000100
[2025-08-26 13:49:38,309][__main__][INFO] - [VALIDATION] [Epoch 29/29] Starting validation.
[2025-08-26 13:49:48,715][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 024691] [Batch 00007/00013] [00:00:10/00:00:06, 1.301s/it]
[2025-08-26 13:49:56,121][__main__][INFO] - [VALIDATION] [Epoch 29/29] train_loss=0.83427, valid_loss=1.45053
[2025-08-26 13:49:56,121][__main__][INFO] - [VALIDATION] [Epoch 29/29] Metrics:
[2025-08-26 13:49:56,121][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_er      0.542
[2025-08-26 13:49:56,121][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_prec    0.095
[2025-08-26 13:49:56,121][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_recall  0.095
[2025-08-26 13:49:56,121][__main__][INFO] - [VALIDATION] [Epoch 29/29] - pep_recall 0.049
[2025-08-26 13:49:56,123][__main__][INFO] - [TRAIN] [Epoch 29/29] Epoch complete, total time 05:17:19, remaining time 00:00:00, 00:10:34 per epoch
[2025-08-26 13:49:57,171][__main__][INFO] - InstaNovo training finished.
