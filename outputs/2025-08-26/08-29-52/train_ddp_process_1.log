[2025-08-26 08:31:08,978][__main__][INFO] - Initializing training.
[2025-08-26 08:31:08,978][__main__][INFO] - Python version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]
[2025-08-26 08:31:08,978][__main__][INFO] - Torch version: 2.4.1+cu121
[2025-08-26 08:31:08,978][__main__][INFO] - CUDA version: 12.1
[2025-08-26 08:31:08,982][__main__][INFO] - Imported hydra config:
train_path: /data/48/wuqian/Proteometools/part1/parquet/345_3HCD_high/*.parquet
profiler: false
epochs: 30
num_sanity_val_steps: 10
console_logging_steps: 50
tensorboard_logging_steps: 500
report_to: null
run_name: 300k_3HCD_192BS
dim_model: 768
n_head: 16
dim_feedforward: 1024
n_layers: 9
dropout: 0.1
use_flash_attention: false
conv_peak_encoder: false
n_peaks: 200
min_mz: 50.0
max_mz: 2500.0
min_intensity: 0.01
remove_precursor_tol: 2.0
max_charge: 10
precursor_mass_tol: 50
isotope_error_range:
- 0
- 1
predict_batch_size: 128
max_length: 40
tb_summarywriter: /data/48/wuqian/fast/TipsNovo/log
warmup_iters: 480
max_iters: 3000000
learning_rate: 0.0001
train_batch_size: 192
grad_accumulation: 1
weight_decay: 1.0e-05
gradient_clip_val: 10.0
n_beams: 5
compile_model: true
device: auto
n_gpu: 1
fp16: true
train_subset: 1
valid_subset_of_train: 0.01
valid_subset: 1
val_check_interval: 1.0
lazy_loading: true
max_shard_size: 1000000
preshuffle_shards: false
perform_data_checks: true
validate_precursor_mass: false
verbose_loading: true
model_save_folder_path: /data/48/wuqian/fast/TipsNovo/model_save/
save_model: true
save_weights_only: false
ckpt_interval: 2000
train_from_scratch: true
resume_checkpoint: null
residues:
  G: 57.021464
  A: 71.037114
  S: 87.032028
  P: 97.052764
  V: 99.068414
  T: 101.04767
  C: 103.009185
  L: 113.084064
  I: 113.084064
  'N': 114.042927
  D: 115.026943
  Q: 128.058578
  K: 128.094963
  E: 129.042593
  M: 131.040485
  H: 137.058912
  F: 147.068414
  R: 156.101111
  'Y': 163.063329
  W: 186.079313
  M[UNIMOD:35]: 147.0354
  C[UNIMOD:4]: 160.030649
  N[UNIMOD:7]: 115.026943
  Q[UNIMOD:7]: 129.042594
  S[UNIMOD:21]: 166.998028
  T[UNIMOD:21]: 181.01367
  Y[UNIMOD:21]: 243.029329
  '[UNIMOD:1]': 42.010565
  '[UNIMOD:5]': 43.005814
  '[UNIMOD:385]': -17.026549

[2025-08-26 08:31:08,986][__main__][INFO] - Starting transformer training
[2025-08-26 08:31:08,986][__main__][INFO] - Vocab: {0: '[PAD]', 1: '[SOS]', 2: '[EOS]', 3: 'G', 4: 'A', 5: 'S', 6: 'P', 7: 'V', 8: 'T', 9: 'C', 10: 'L', 11: 'I', 12: 'N', 13: 'D', 14: 'Q', 15: 'K', 16: 'E', 17: 'M', 18: 'H', 19: 'F', 20: 'R', 21: 'Y', 22: 'W', 23: 'M[UNIMOD:35]', 24: 'C[UNIMOD:4]', 25: 'N[UNIMOD:7]', 26: 'Q[UNIMOD:7]', 27: 'S[UNIMOD:21]', 28: 'T[UNIMOD:21]', 29: 'Y[UNIMOD:21]', 30: '[UNIMOD:1]', 31: '[UNIMOD:5]', 32: '[UNIMOD:385]'}
[2025-08-26 08:31:08,986][__main__][INFO] - Loading data
[2025-08-26 08:31:13,883][instanovo.utils.data_handler][INFO] - Verifying loaded data
[2025-08-26 08:31:17,642][__main__][INFO] - Validation path not specified, generating from training set.
[2025-08-26 08:31:34,499][__main__][INFO] - Data splits saved to /data/48/wuqian/fast/TipsNovo/model_save/splits.csv
[2025-08-26 08:31:34,499][__main__][INFO] - Checking for unknown residues in 319,144 rows.
[2025-08-26 08:31:54,454][__main__][INFO] - Data loaded: 315,873 training samples; 3,271 validation samples
[2025-08-26 08:31:54,634][__main__][INFO] - Checking if any validation set overlaps with training set...
[2025-08-26 08:31:54,660][__main__][INFO] - No data leakage!
[2025-08-26 08:31:54,660][__main__][INFO] - Model checkpointing every 1.22 epochs.
[2025-08-26 08:31:54,660][__main__][INFO] - Updates per epoch: 1,646, step_scale=0.16666666666666666
[2025-08-26 08:32:05,801][__main__][INFO] - Sample batch:
[2025-08-26 08:32:05,802][__main__][INFO] -  - spectra.shape=torch.Size([192, 200, 2])
[2025-08-26 08:32:05,802][__main__][INFO] -  - precursors.shape=torch.Size([192, 3])
[2025-08-26 08:32:05,802][__main__][INFO] -  - spectra_mask.shape=torch.Size([192, 200])
[2025-08-26 08:32:05,802][__main__][INFO] -  - peptides.shape=torch.Size([192, 41])
[2025-08-26 08:32:05,802][__main__][INFO] -  - peptides_mask.shape=torch.Size([192, 41])
[2025-08-26 08:32:05,977][__main__][INFO] - Model loaded with 94,619,169 parameters
[2025-08-26 08:32:05,977][__main__][INFO] - Test forward pass:
[2025-08-26 08:32:15,738][__main__][INFO] -  - y.shape=torch.Size([192, 42, 33])
[2025-08-26 08:32:17,127][__main__][INFO] - Model saving enabled
[2025-08-26 08:32:17,128][__main__][INFO] - Saving every 2000 training steps to /data/48/wuqian/fast/TipsNovo/model_save/
[2025-08-26 08:32:17,128][__main__][INFO] - Initializing Pytorch Lightning trainer.
[2025-08-26 08:32:17,139][__main__][INFO] - InstaNovo training started.
[2025-08-26 08:32:22,069][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-26 08:32:33,327][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 000001] [Batch 00007/00013] [00:00:11/00:00:07, 1.407s/it]
[2025-08-26 08:32:41,628][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000008] [Batch 00008/00823] [00:00:05/00:09:07, 0.672s/it]: train_loss_raw=3.4977, running_loss=3.5893, LR=0.000001
[2025-08-26 08:32:47,631][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000016] [Batch 00016/00823] [00:00:11/00:09:33, 0.711s/it]: train_loss_raw=3.1961, running_loss=3.5692, LR=0.000003
[2025-08-26 08:32:53,658][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000024] [Batch 00024/00823] [00:00:17/00:09:39, 0.725s/it]: train_loss_raw=3.0607, running_loss=3.5341, LR=0.000005
[2025-08-26 08:32:59,481][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000032] [Batch 00032/00823] [00:00:23/00:09:34, 0.726s/it]: train_loss_raw=2.9970, running_loss=3.4946, LR=0.000006
[2025-08-26 08:33:05,554][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000040] [Batch 00040/00823] [00:00:29/00:09:33, 0.732s/it]: train_loss_raw=2.9663, running_loss=3.4553, LR=0.000008
[2025-08-26 08:33:11,540][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000048] [Batch 00048/00823] [00:00:35/00:09:29, 0.735s/it]: train_loss_raw=2.9399, running_loss=3.4171, LR=0.000010
[2025-08-26 08:33:17,573][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000056] [Batch 00056/00823] [00:00:41/00:09:25, 0.738s/it]: train_loss_raw=2.9004, running_loss=3.3788, LR=0.000011
[2025-08-26 08:33:23,712][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000064] [Batch 00064/00823] [00:00:47/00:09:22, 0.742s/it]: train_loss_raw=2.8206, running_loss=3.3381, LR=0.000013
[2025-08-26 08:33:29,811][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000072] [Batch 00072/00823] [00:00:53/00:09:18, 0.744s/it]: train_loss_raw=2.8061, running_loss=3.2964, LR=0.000015
[2025-08-26 08:33:35,616][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000080] [Batch 00080/00823] [00:00:59/00:09:11, 0.742s/it]: train_loss_raw=2.7674, running_loss=3.2556, LR=0.000016
[2025-08-26 08:33:41,309][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000088] [Batch 00088/00823] [00:01:05/00:09:03, 0.739s/it]: train_loss_raw=2.7274, running_loss=3.2159, LR=0.000018
[2025-08-26 08:33:47,307][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000096] [Batch 00096/00823] [00:01:11/00:08:58, 0.740s/it]: train_loss_raw=2.7303, running_loss=3.1788, LR=0.000020
[2025-08-26 08:33:53,354][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000104] [Batch 00104/00823] [00:01:17/00:08:53, 0.741s/it]: train_loss_raw=2.7233, running_loss=3.1438, LR=0.000021
[2025-08-26 08:33:59,363][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000112] [Batch 00112/00823] [00:01:23/00:08:47, 0.742s/it]: train_loss_raw=2.7486, running_loss=3.1119, LR=0.000023
[2025-08-26 08:34:05,078][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000120] [Batch 00120/00823] [00:01:28/00:08:40, 0.740s/it]: train_loss_raw=2.7264, running_loss=3.0818, LR=0.000025
[2025-08-26 08:34:10,793][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000128] [Batch 00128/00823] [00:01:34/00:08:33, 0.739s/it]: train_loss_raw=2.7028, running_loss=3.0531, LR=0.000026
[2025-08-26 08:34:16,713][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000136] [Batch 00136/00823] [00:01:40/00:08:27, 0.739s/it]: train_loss_raw=2.7159, running_loss=3.0266, LR=0.000028
[2025-08-26 08:34:22,639][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000144] [Batch 00144/00823] [00:01:46/00:08:21, 0.739s/it]: train_loss_raw=2.7284, running_loss=3.0018, LR=0.000030
[2025-08-26 08:34:28,712][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000152] [Batch 00152/00823] [00:01:52/00:08:16, 0.740s/it]: train_loss_raw=2.7052, running_loss=2.9792, LR=0.000031
[2025-08-26 08:34:34,644][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000160] [Batch 00160/00823] [00:01:58/00:08:10, 0.740s/it]: train_loss_raw=2.6930, running_loss=2.9585, LR=0.000033
[2025-08-26 08:34:40,463][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000168] [Batch 00168/00823] [00:02:04/00:08:04, 0.739s/it]: train_loss_raw=2.7294, running_loss=2.9393, LR=0.000035
[2025-08-26 08:34:46,332][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000176] [Batch 00176/00823] [00:02:10/00:07:58, 0.739s/it]: train_loss_raw=2.6974, running_loss=2.9201, LR=0.000036
[2025-08-26 08:34:52,295][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000184] [Batch 00184/00823] [00:02:16/00:07:52, 0.739s/it]: train_loss_raw=2.6620, running_loss=2.9021, LR=0.000038
[2025-08-26 08:34:58,188][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000192] [Batch 00192/00823] [00:02:21/00:07:46, 0.739s/it]: train_loss_raw=2.7083, running_loss=2.8867, LR=0.000040
[2025-08-26 08:35:04,282][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000200] [Batch 00200/00823] [00:02:28/00:07:41, 0.740s/it]: train_loss_raw=2.7049, running_loss=2.8725, LR=0.000041
[2025-08-26 08:35:10,339][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000208] [Batch 00208/00823] [00:02:34/00:07:35, 0.741s/it]: train_loss_raw=2.6711, running_loss=2.8575, LR=0.000043
[2025-08-26 08:35:16,257][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000216] [Batch 00216/00823] [00:02:40/00:07:29, 0.741s/it]: train_loss_raw=2.6741, running_loss=2.8444, LR=0.000045
[2025-08-26 08:35:22,069][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000224] [Batch 00224/00823] [00:02:45/00:07:23, 0.740s/it]: train_loss_raw=2.6810, running_loss=2.8319, LR=0.000046
[2025-08-26 08:35:27,892][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000232] [Batch 00232/00823] [00:02:51/00:07:17, 0.740s/it]: train_loss_raw=2.6733, running_loss=2.8206, LR=0.000048
[2025-08-26 08:35:33,800][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000240] [Batch 00240/00823] [00:02:57/00:07:11, 0.740s/it]: train_loss_raw=2.6766, running_loss=2.8105, LR=0.000050
[2025-08-26 08:35:39,347][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000248] [Batch 00248/00823] [00:03:03/00:07:04, 0.738s/it]: train_loss_raw=2.6866, running_loss=2.8003, LR=0.000051
[2025-08-26 08:35:45,352][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000256] [Batch 00256/00823] [00:03:09/00:06:58, 0.739s/it]: train_loss_raw=2.6656, running_loss=2.7914, LR=0.000053
[2025-08-26 08:35:51,083][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000264] [Batch 00264/00823] [00:03:14/00:06:52, 0.738s/it]: train_loss_raw=2.6740, running_loss=2.7828, LR=0.000055
[2025-08-26 08:35:56,681][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000272] [Batch 00272/00823] [00:03:20/00:06:46, 0.737s/it]: train_loss_raw=2.6881, running_loss=2.7751, LR=0.000056
[2025-08-26 08:36:02,893][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000280] [Batch 00280/00823] [00:03:26/00:06:40, 0.738s/it]: train_loss_raw=2.7103, running_loss=2.7684, LR=0.000058
[2025-08-26 08:36:09,227][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000288] [Batch 00288/00823] [00:03:32/00:06:35, 0.739s/it]: train_loss_raw=2.6842, running_loss=2.7612, LR=0.000060
[2025-08-26 08:36:15,094][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000296] [Batch 00296/00823] [00:03:38/00:06:29, 0.739s/it]: train_loss_raw=2.6598, running_loss=2.7543, LR=0.000061
[2025-08-26 08:36:20,932][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000304] [Batch 00304/00823] [00:03:44/00:06:23, 0.739s/it]: train_loss_raw=2.6814, running_loss=2.7470, LR=0.000063
[2025-08-26 08:36:26,925][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000312] [Batch 00312/00823] [00:03:50/00:06:17, 0.739s/it]: train_loss_raw=2.6422, running_loss=2.7391, LR=0.000065
[2025-08-26 08:36:32,902][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000320] [Batch 00320/00823] [00:03:56/00:06:11, 0.740s/it]: train_loss_raw=2.6625, running_loss=2.7315, LR=0.000066
[2025-08-26 08:36:38,625][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000328] [Batch 00328/00823] [00:04:02/00:06:05, 0.739s/it]: train_loss_raw=2.6070, running_loss=2.7239, LR=0.000068
[2025-08-26 08:36:44,668][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000336] [Batch 00336/00823] [00:04:08/00:06:00, 0.739s/it]: train_loss_raw=2.6096, running_loss=2.7153, LR=0.000070
[2025-08-26 08:36:50,696][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000344] [Batch 00344/00823] [00:04:14/00:05:54, 0.740s/it]: train_loss_raw=2.5895, running_loss=2.7067, LR=0.000071
[2025-08-26 08:36:56,728][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000352] [Batch 00352/00823] [00:04:20/00:05:48, 0.740s/it]: train_loss_raw=2.6182, running_loss=2.6994, LR=0.000073
[2025-08-26 08:37:02,197][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000360] [Batch 00360/00823] [00:04:25/00:05:42, 0.739s/it]: train_loss_raw=2.5966, running_loss=2.6913, LR=0.000075
[2025-08-26 08:37:08,200][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000368] [Batch 00368/00823] [00:04:31/00:05:36, 0.739s/it]: train_loss_raw=2.5928, running_loss=2.6834, LR=0.000076
[2025-08-26 08:37:14,265][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000376] [Batch 00376/00823] [00:04:38/00:05:30, 0.739s/it]: train_loss_raw=2.6061, running_loss=2.6759, LR=0.000078
[2025-08-26 08:37:20,257][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000384] [Batch 00384/00823] [00:04:44/00:05:24, 0.740s/it]: train_loss_raw=2.5731, running_loss=2.6699, LR=0.000080
[2025-08-26 08:37:26,210][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000392] [Batch 00392/00823] [00:04:49/00:05:18, 0.740s/it]: train_loss_raw=2.5856, running_loss=2.6639, LR=0.000081
[2025-08-26 08:37:31,974][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000400] [Batch 00400/00823] [00:04:55/00:05:12, 0.739s/it]: train_loss_raw=2.5866, running_loss=2.6587, LR=0.000083
[2025-08-26 08:37:38,023][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000408] [Batch 00408/00823] [00:05:01/00:05:06, 0.740s/it]: train_loss_raw=2.5661, running_loss=2.6526, LR=0.000085
[2025-08-26 08:37:44,195][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000416] [Batch 00416/00823] [00:05:07/00:05:01, 0.740s/it]: train_loss_raw=2.5415, running_loss=2.6454, LR=0.000086
[2025-08-26 08:37:49,990][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000424] [Batch 00424/00823] [00:05:13/00:04:55, 0.740s/it]: train_loss_raw=2.5382, running_loss=2.6382, LR=0.000088
[2025-08-26 08:37:55,764][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000432] [Batch 00432/00823] [00:05:19/00:04:49, 0.740s/it]: train_loss_raw=2.5516, running_loss=2.6310, LR=0.000090
[2025-08-26 08:38:01,840][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000440] [Batch 00440/00823] [00:05:25/00:04:43, 0.740s/it]: train_loss_raw=2.5335, running_loss=2.6247, LR=0.000091
[2025-08-26 08:38:07,860][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000448] [Batch 00448/00823] [00:05:31/00:04:37, 0.740s/it]: train_loss_raw=2.5154, running_loss=2.6175, LR=0.000093
[2025-08-26 08:38:13,643][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000456] [Batch 00456/00823] [00:05:37/00:04:31, 0.740s/it]: train_loss_raw=2.4916, running_loss=2.6103, LR=0.000095
[2025-08-26 08:38:19,608][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000464] [Batch 00464/00823] [00:05:43/00:04:25, 0.740s/it]: train_loss_raw=2.5718, running_loss=2.6043, LR=0.000096
[2025-08-26 08:38:25,408][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000472] [Batch 00472/00823] [00:05:49/00:04:19, 0.740s/it]: train_loss_raw=2.5026, running_loss=2.5999, LR=0.000098
[2025-08-26 08:38:30,895][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000480] [Batch 00480/00823] [00:05:54/00:04:13, 0.739s/it]: train_loss_raw=2.5403, running_loss=2.5958, LR=0.000100
[2025-08-26 08:38:36,362][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000488] [Batch 00488/00823] [00:06:00/00:04:07, 0.738s/it]: train_loss_raw=2.5219, running_loss=2.5906, LR=0.000100
[2025-08-26 08:38:41,802][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000496] [Batch 00496/00823] [00:06:05/00:04:00, 0.737s/it]: train_loss_raw=2.5487, running_loss=2.5843, LR=0.000100
[2025-08-26 08:38:47,510][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000504] [Batch 00504/00823] [00:06:11/00:03:54, 0.737s/it]: train_loss_raw=2.5119, running_loss=2.5787, LR=0.000100
[2025-08-26 08:38:53,735][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000512] [Batch 00512/00823] [00:06:17/00:03:49, 0.737s/it]: train_loss_raw=2.4963, running_loss=2.5729, LR=0.000100
[2025-08-26 08:38:59,541][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000520] [Batch 00520/00823] [00:06:23/00:03:43, 0.737s/it]: train_loss_raw=2.5431, running_loss=2.5666, LR=0.000100
[2025-08-26 08:39:05,520][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000528] [Batch 00528/00823] [00:06:29/00:03:37, 0.737s/it]: train_loss_raw=2.5004, running_loss=2.5602, LR=0.000100
[2025-08-26 08:39:11,551][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000536] [Batch 00536/00823] [00:06:35/00:03:31, 0.737s/it]: train_loss_raw=2.4870, running_loss=2.5539, LR=0.000100
[2025-08-26 08:39:17,643][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000544] [Batch 00544/00823] [00:06:41/00:03:25, 0.738s/it]: train_loss_raw=2.4669, running_loss=2.5480, LR=0.000100
[2025-08-26 08:39:23,530][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000552] [Batch 00552/00823] [00:06:47/00:03:19, 0.738s/it]: train_loss_raw=2.4709, running_loss=2.5420, LR=0.000100
[2025-08-26 08:39:29,232][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000560] [Batch 00560/00823] [00:06:52/00:03:13, 0.737s/it]: train_loss_raw=2.4405, running_loss=2.5377, LR=0.000100
[2025-08-26 08:39:34,890][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000568] [Batch 00568/00823] [00:06:58/00:03:07, 0.737s/it]: train_loss_raw=2.4237, running_loss=2.5321, LR=0.000100
[2025-08-26 08:39:40,231][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000576] [Batch 00576/00823] [00:07:03/00:03:01, 0.736s/it]: train_loss_raw=2.4167, running_loss=2.5263, LR=0.000100
[2025-08-26 08:39:46,049][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000584] [Batch 00584/00823] [00:07:09/00:02:55, 0.736s/it]: train_loss_raw=2.4547, running_loss=2.5214, LR=0.000100
[2025-08-26 08:39:51,863][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000592] [Batch 00592/00823] [00:07:15/00:02:49, 0.736s/it]: train_loss_raw=2.4577, running_loss=2.5153, LR=0.000100
[2025-08-26 08:39:57,520][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000600] [Batch 00600/00823] [00:07:21/00:02:44, 0.735s/it]: train_loss_raw=2.4217, running_loss=2.5095, LR=0.000100
[2025-08-26 08:40:03,641][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000608] [Batch 00608/00823] [00:07:27/00:02:38, 0.736s/it]: train_loss_raw=2.4797, running_loss=2.5051, LR=0.000100
[2025-08-26 08:40:09,356][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000616] [Batch 00616/00823] [00:07:33/00:02:32, 0.736s/it]: train_loss_raw=2.4867, running_loss=2.4994, LR=0.000100
[2025-08-26 08:40:14,970][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000624] [Batch 00624/00823] [00:07:38/00:02:26, 0.735s/it]: train_loss_raw=2.4210, running_loss=2.4944, LR=0.000100
[2025-08-26 08:40:20,931][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000632] [Batch 00632/00823] [00:07:44/00:02:20, 0.735s/it]: train_loss_raw=2.4283, running_loss=2.4891, LR=0.000100
[2025-08-26 08:40:26,695][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000640] [Batch 00640/00823] [00:07:50/00:02:14, 0.735s/it]: train_loss_raw=2.4105, running_loss=2.4842, LR=0.000100
[2025-08-26 08:40:32,288][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000648] [Batch 00648/00823] [00:07:56/00:02:08, 0.735s/it]: train_loss_raw=2.4291, running_loss=2.4789, LR=0.000100
[2025-08-26 08:40:37,912][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000656] [Batch 00656/00823] [00:08:01/00:02:02, 0.734s/it]: train_loss_raw=2.4250, running_loss=2.4751, LR=0.000100
[2025-08-26 08:40:43,279][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000664] [Batch 00664/00823] [00:08:07/00:01:56, 0.733s/it]: train_loss_raw=2.3980, running_loss=2.4700, LR=0.000100
[2025-08-26 08:40:48,701][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000672] [Batch 00672/00823] [00:08:12/00:01:50, 0.733s/it]: train_loss_raw=2.4284, running_loss=2.4663, LR=0.000100
[2025-08-26 08:40:54,097][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000680] [Batch 00680/00823] [00:08:17/00:01:44, 0.732s/it]: train_loss_raw=2.3977, running_loss=2.4604, LR=0.000100
[2025-08-26 08:40:59,629][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000688] [Batch 00688/00823] [00:08:23/00:01:38, 0.732s/it]: train_loss_raw=2.4229, running_loss=2.4558, LR=0.000100
[2025-08-26 08:41:05,270][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000696] [Batch 00696/00823] [00:08:29/00:01:32, 0.731s/it]: train_loss_raw=2.3771, running_loss=2.4508, LR=0.000100
[2025-08-26 08:41:10,888][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000704] [Batch 00704/00823] [00:08:34/00:01:26, 0.731s/it]: train_loss_raw=2.3468, running_loss=2.4454, LR=0.000100
[2025-08-26 08:41:16,797][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000712] [Batch 00712/00823] [00:08:40/00:01:21, 0.731s/it]: train_loss_raw=2.4223, running_loss=2.4414, LR=0.000100
[2025-08-26 08:41:22,327][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000720] [Batch 00720/00823] [00:08:46/00:01:15, 0.731s/it]: train_loss_raw=2.3846, running_loss=2.4359, LR=0.000100
[2025-08-26 08:41:28,174][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000728] [Batch 00728/00823] [00:08:51/00:01:09, 0.731s/it]: train_loss_raw=2.3409, running_loss=2.4306, LR=0.000100
[2025-08-26 08:41:33,855][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000736] [Batch 00736/00823] [00:08:57/00:01:03, 0.730s/it]: train_loss_raw=2.3428, running_loss=2.4270, LR=0.000100
[2025-08-26 08:41:39,692][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000744] [Batch 00744/00823] [00:09:03/00:00:57, 0.730s/it]: train_loss_raw=2.2851, running_loss=2.4216, LR=0.000100
[2025-08-26 08:41:45,498][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000752] [Batch 00752/00823] [00:09:09/00:00:51, 0.730s/it]: train_loss_raw=2.3694, running_loss=2.4161, LR=0.000100
[2025-08-26 08:41:51,419][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000760] [Batch 00760/00823] [00:09:15/00:00:46, 0.730s/it]: train_loss_raw=2.3574, running_loss=2.4118, LR=0.000100
[2025-08-26 08:41:57,332][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000768] [Batch 00768/00823] [00:09:21/00:00:40, 0.731s/it]: train_loss_raw=2.3181, running_loss=2.4071, LR=0.000100
[2025-08-26 08:42:03,371][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000776] [Batch 00776/00823] [00:09:27/00:00:34, 0.731s/it]: train_loss_raw=2.3641, running_loss=2.4041, LR=0.000100
[2025-08-26 08:42:09,369][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000784] [Batch 00784/00823] [00:09:33/00:00:28, 0.731s/it]: train_loss_raw=2.3282, running_loss=2.4010, LR=0.000100
[2025-08-26 08:42:15,426][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000792] [Batch 00792/00823] [00:09:39/00:00:22, 0.731s/it]: train_loss_raw=2.3403, running_loss=2.3983, LR=0.000100
[2025-08-26 08:42:21,480][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000800] [Batch 00800/00823] [00:09:45/00:00:16, 0.732s/it]: train_loss_raw=2.3666, running_loss=2.3940, LR=0.000100
[2025-08-26 08:42:27,500][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000808] [Batch 00808/00823] [00:09:51/00:00:10, 0.732s/it]: train_loss_raw=2.3932, running_loss=2.3916, LR=0.000100
[2025-08-26 08:42:33,588][__main__][INFO] - [TRAIN] [Epoch 00/29 Step 000816] [Batch 00816/00823] [00:09:57/00:00:05, 0.732s/it]: train_loss_raw=2.2877, running_loss=2.3873, LR=0.000100
[2025-08-26 08:42:38,978][__main__][INFO] - [VALIDATION] [Epoch 00/29] Starting validation.
[2025-08-26 08:42:46,746][__main__][INFO] - [VALIDATION] [Epoch 00/29 Step 000824] [Batch 00002/00013] [00:00:07/00:00:25, 2.589s/it]
[2025-08-26 08:42:56,921][__main__][INFO] - [VALIDATION] [Epoch 00/29] train_loss=2.38199, valid_loss=2.36842
[2025-08-26 08:42:56,921][__main__][INFO] - [VALIDATION] [Epoch 00/29] Metrics:
[2025-08-26 08:42:56,921][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_er      0.873
[2025-08-26 08:42:56,921][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_prec    0.020
[2025-08-26 08:42:56,921][__main__][INFO] - [VALIDATION] [Epoch 00/29] - aa_recall  0.021
[2025-08-26 08:42:56,921][__main__][INFO] - [VALIDATION] [Epoch 00/29] - pep_recall 0.000
[2025-08-26 08:42:56,925][__main__][INFO] - [TRAIN] [Epoch 00/29] Epoch complete, total time 00:10:20, remaining time 04:59:59, 00:10:20 per epoch
[2025-08-26 08:42:58,461][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000824] [Batch 00001/00823] [00:00:00/00:01:58, 0.144s/it]: train_loss_raw=2.4161, running_loss=2.4161, LR=0.000100
[2025-08-26 08:43:04,613][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000832] [Batch 00009/00823] [00:00:06/00:09:29, 0.700s/it]: train_loss_raw=2.3073, running_loss=2.4118, LR=0.000100
[2025-08-26 08:43:10,606][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000840] [Batch 00017/00823] [00:00:12/00:09:42, 0.723s/it]: train_loss_raw=2.3120, running_loss=2.4064, LR=0.000100
[2025-08-26 08:43:16,412][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000848] [Batch 00025/00823] [00:00:18/00:09:37, 0.724s/it]: train_loss_raw=2.2947, running_loss=2.4017, LR=0.000100
[2025-08-26 08:43:22,167][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000856] [Batch 00033/00823] [00:00:23/00:09:30, 0.723s/it]: train_loss_raw=2.2682, running_loss=2.3967, LR=0.000100
[2025-08-26 08:43:27,835][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000864] [Batch 00041/00823] [00:00:29/00:09:22, 0.720s/it]: train_loss_raw=2.3262, running_loss=2.3912, LR=0.000100
[2025-08-26 08:43:33,545][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000872] [Batch 00049/00823] [00:00:35/00:09:16, 0.719s/it]: train_loss_raw=2.3916, running_loss=2.3858, LR=0.000100
[2025-08-26 08:43:39,378][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000880] [Batch 00057/00823] [00:00:41/00:09:11, 0.720s/it]: train_loss_raw=2.3097, running_loss=2.3808, LR=0.000100
[2025-08-26 08:43:44,813][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000888] [Batch 00065/00823] [00:00:46/00:09:02, 0.715s/it]: train_loss_raw=2.3334, running_loss=2.3759, LR=0.000100
[2025-08-26 08:43:50,239][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000896] [Batch 00073/00823] [00:00:51/00:08:53, 0.711s/it]: train_loss_raw=2.3439, running_loss=2.3720, LR=0.000100
[2025-08-26 08:43:56,007][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000904] [Batch 00081/00823] [00:00:57/00:08:48, 0.712s/it]: train_loss_raw=2.2851, running_loss=2.3668, LR=0.000100
[2025-08-26 08:44:01,423][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000912] [Batch 00089/00823] [00:01:03/00:08:40, 0.709s/it]: train_loss_raw=2.3511, running_loss=2.3612, LR=0.000100
[2025-08-26 08:44:06,915][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000920] [Batch 00097/00823] [00:01:08/00:08:33, 0.707s/it]: train_loss_raw=2.2564, running_loss=2.3577, LR=0.000100
[2025-08-26 08:44:12,564][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000928] [Batch 00105/00823] [00:01:14/00:08:27, 0.707s/it]: train_loss_raw=2.3030, running_loss=2.3546, LR=0.000100
[2025-08-26 08:44:18,028][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000936] [Batch 00113/00823] [00:01:19/00:08:20, 0.705s/it]: train_loss_raw=2.3428, running_loss=2.3520, LR=0.000100
[2025-08-26 08:44:23,673][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000944] [Batch 00121/00823] [00:01:25/00:08:15, 0.705s/it]: train_loss_raw=2.2788, running_loss=2.3470, LR=0.000100
[2025-08-26 08:44:29,712][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000952] [Batch 00129/00823] [00:01:31/00:08:11, 0.708s/it]: train_loss_raw=2.3242, running_loss=2.3429, LR=0.000100
[2025-08-26 08:44:35,642][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000960] [Batch 00137/00823] [00:01:37/00:08:07, 0.710s/it]: train_loss_raw=2.2523, running_loss=2.3379, LR=0.000100
[2025-08-26 08:44:41,685][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000968] [Batch 00145/00823] [00:01:43/00:08:03, 0.713s/it]: train_loss_raw=2.3295, running_loss=2.3344, LR=0.000100
[2025-08-26 08:44:47,335][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000976] [Batch 00153/00823] [00:01:49/00:07:57, 0.713s/it]: train_loss_raw=2.2860, running_loss=2.3321, LR=0.000100
[2025-08-26 08:44:53,211][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000984] [Batch 00161/00823] [00:01:54/00:07:52, 0.714s/it]: train_loss_raw=2.2934, running_loss=2.3308, LR=0.000100
[2025-08-26 08:44:58,882][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 000992] [Batch 00169/00823] [00:02:00/00:07:46, 0.713s/it]: train_loss_raw=2.3573, running_loss=2.3267, LR=0.000100
[2025-08-26 08:45:04,794][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001000] [Batch 00177/00823] [00:02:06/00:07:41, 0.715s/it]: train_loss_raw=2.2836, running_loss=2.3226, LR=0.000100
[2025-08-26 08:45:10,700][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001008] [Batch 00185/00823] [00:02:12/00:07:36, 0.716s/it]: train_loss_raw=2.2808, running_loss=2.3176, LR=0.000100
[2025-08-26 08:45:16,473][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001016] [Batch 00193/00823] [00:02:18/00:07:30, 0.716s/it]: train_loss_raw=2.2700, running_loss=2.3127, LR=0.000100
[2025-08-26 08:45:22,074][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001024] [Batch 00201/00823] [00:02:23/00:07:24, 0.715s/it]: train_loss_raw=2.2407, running_loss=2.3097, LR=0.000100
[2025-08-26 08:45:27,522][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001032] [Batch 00209/00823] [00:02:29/00:07:18, 0.714s/it]: train_loss_raw=2.2991, running_loss=2.3065, LR=0.000100
[2025-08-26 08:45:33,557][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001040] [Batch 00217/00823] [00:02:35/00:07:13, 0.715s/it]: train_loss_raw=2.2074, running_loss=2.3032, LR=0.000100
[2025-08-26 08:45:39,354][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001048] [Batch 00225/00823] [00:02:41/00:07:08, 0.716s/it]: train_loss_raw=2.3008, running_loss=2.3017, LR=0.000100
[2025-08-26 08:45:44,899][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001056] [Batch 00233/00823] [00:02:46/00:07:01, 0.715s/it]: train_loss_raw=2.2303, running_loss=2.2979, LR=0.000100
[2025-08-26 08:45:50,820][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001064] [Batch 00241/00823] [00:02:52/00:06:56, 0.716s/it]: train_loss_raw=2.1357, running_loss=2.2942, LR=0.000100
[2025-08-26 08:45:56,376][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001072] [Batch 00249/00823] [00:02:58/00:06:50, 0.715s/it]: train_loss_raw=2.3049, running_loss=2.2921, LR=0.000100
[2025-08-26 08:46:02,239][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001080] [Batch 00257/00823] [00:03:03/00:06:45, 0.716s/it]: train_loss_raw=2.2798, running_loss=2.2901, LR=0.000100
[2025-08-26 08:46:08,323][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001088] [Batch 00265/00823] [00:03:10/00:06:40, 0.717s/it]: train_loss_raw=2.2763, running_loss=2.2879, LR=0.000100
[2025-08-26 08:46:14,335][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001096] [Batch 00273/00823] [00:03:16/00:06:34, 0.718s/it]: train_loss_raw=2.2667, running_loss=2.2859, LR=0.000100
[2025-08-26 08:46:19,897][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001104] [Batch 00281/00823] [00:03:21/00:06:28, 0.717s/it]: train_loss_raw=2.2847, running_loss=2.2854, LR=0.000100
[2025-08-26 08:46:25,938][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001112] [Batch 00289/00823] [00:03:27/00:06:23, 0.718s/it]: train_loss_raw=2.2626, running_loss=2.2830, LR=0.000100
[2025-08-26 08:46:31,722][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001120] [Batch 00297/00823] [00:03:33/00:06:17, 0.719s/it]: train_loss_raw=2.1851, running_loss=2.2791, LR=0.000100
[2025-08-26 08:46:37,197][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001128] [Batch 00305/00823] [00:03:38/00:06:11, 0.718s/it]: train_loss_raw=2.2386, running_loss=2.2766, LR=0.000100
[2025-08-26 08:46:42,996][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001136] [Batch 00313/00823] [00:03:44/00:06:06, 0.718s/it]: train_loss_raw=2.3233, running_loss=2.2752, LR=0.000100
[2025-08-26 08:46:48,482][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001144] [Batch 00321/00823] [00:03:50/00:05:59, 0.717s/it]: train_loss_raw=2.2932, running_loss=2.2733, LR=0.000100
[2025-08-26 08:46:54,127][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001152] [Batch 00329/00823] [00:03:55/00:05:54, 0.717s/it]: train_loss_raw=2.1558, running_loss=2.2699, LR=0.000100
[2025-08-26 08:46:59,797][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001160] [Batch 00337/00823] [00:04:01/00:05:48, 0.717s/it]: train_loss_raw=2.1909, running_loss=2.2662, LR=0.000100
[2025-08-26 08:47:05,752][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001168] [Batch 00345/00823] [00:04:07/00:05:42, 0.717s/it]: train_loss_raw=2.2491, running_loss=2.2627, LR=0.000100
[2025-08-26 08:47:11,510][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001176] [Batch 00353/00823] [00:04:13/00:05:37, 0.717s/it]: train_loss_raw=2.2183, running_loss=2.2608, LR=0.000100
[2025-08-26 08:47:17,357][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001184] [Batch 00361/00823] [00:04:19/00:05:31, 0.718s/it]: train_loss_raw=2.2131, running_loss=2.2597, LR=0.000100
[2025-08-26 08:47:23,275][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001192] [Batch 00369/00823] [00:04:24/00:05:25, 0.718s/it]: train_loss_raw=2.3028, running_loss=2.2563, LR=0.000100
[2025-08-26 08:47:29,163][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001200] [Batch 00377/00823] [00:04:30/00:05:20, 0.718s/it]: train_loss_raw=2.2368, running_loss=2.2520, LR=0.000100
[2025-08-26 08:47:34,866][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001208] [Batch 00385/00823] [00:04:36/00:05:14, 0.718s/it]: train_loss_raw=2.2523, running_loss=2.2476, LR=0.000100
[2025-08-26 08:47:40,248][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001216] [Batch 00393/00823] [00:04:41/00:05:08, 0.717s/it]: train_loss_raw=2.2979, running_loss=2.2468, LR=0.000100
[2025-08-26 08:47:45,674][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001224] [Batch 00401/00823] [00:04:47/00:05:02, 0.717s/it]: train_loss_raw=2.2036, running_loss=2.2441, LR=0.000100
[2025-08-26 08:47:51,751][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001232] [Batch 00409/00823] [00:04:53/00:04:57, 0.717s/it]: train_loss_raw=2.1785, running_loss=2.2405, LR=0.000100
[2025-08-26 08:47:57,720][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001240] [Batch 00417/00823] [00:04:59/00:04:51, 0.718s/it]: train_loss_raw=2.1421, running_loss=2.2385, LR=0.000100
[2025-08-26 08:48:03,606][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001248] [Batch 00425/00823] [00:05:05/00:04:45, 0.718s/it]: train_loss_raw=2.1784, running_loss=2.2355, LR=0.000100
[2025-08-26 08:48:09,537][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001256] [Batch 00433/00823] [00:05:11/00:04:40, 0.719s/it]: train_loss_raw=2.2030, running_loss=2.2327, LR=0.000100
[2025-08-26 08:48:15,451][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001264] [Batch 00441/00823] [00:05:17/00:04:34, 0.719s/it]: train_loss_raw=2.2449, running_loss=2.2289, LR=0.000100
[2025-08-26 08:48:21,270][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001272] [Batch 00449/00823] [00:05:22/00:04:29, 0.719s/it]: train_loss_raw=2.2364, running_loss=2.2276, LR=0.000100
[2025-08-26 08:48:26,861][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001280] [Batch 00457/00823] [00:05:28/00:04:23, 0.719s/it]: train_loss_raw=2.2089, running_loss=2.2260, LR=0.000100
[2025-08-26 08:48:32,801][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001288] [Batch 00465/00823] [00:05:34/00:04:17, 0.719s/it]: train_loss_raw=2.1475, running_loss=2.2234, LR=0.000100
[2025-08-26 08:48:38,749][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001296] [Batch 00473/00823] [00:05:40/00:04:11, 0.720s/it]: train_loss_raw=2.2204, running_loss=2.2215, LR=0.000100
[2025-08-26 08:48:44,790][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001304] [Batch 00481/00823] [00:05:46/00:04:06, 0.720s/it]: train_loss_raw=2.1752, running_loss=2.2190, LR=0.000100
[2025-08-26 08:48:50,406][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001312] [Batch 00489/00823] [00:05:52/00:04:00, 0.720s/it]: train_loss_raw=2.1429, running_loss=2.2191, LR=0.000100
[2025-08-26 08:48:56,275][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001320] [Batch 00497/00823] [00:05:57/00:03:54, 0.720s/it]: train_loss_raw=2.1811, running_loss=2.2170, LR=0.000100
[2025-08-26 08:49:01,958][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001328] [Batch 00505/00823] [00:06:03/00:03:48, 0.720s/it]: train_loss_raw=2.1492, running_loss=2.2137, LR=0.000100
[2025-08-26 08:49:07,839][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001336] [Batch 00513/00823] [00:06:09/00:03:43, 0.720s/it]: train_loss_raw=2.1782, running_loss=2.2130, LR=0.000100
[2025-08-26 08:49:13,614][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001344] [Batch 00521/00823] [00:06:15/00:03:37, 0.720s/it]: train_loss_raw=2.1827, running_loss=2.2100, LR=0.000100
[2025-08-26 08:49:19,610][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001352] [Batch 00529/00823] [00:06:21/00:03:31, 0.721s/it]: train_loss_raw=2.1426, running_loss=2.2083, LR=0.000100
[2025-08-26 08:49:25,548][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001360] [Batch 00537/00823] [00:06:27/00:03:26, 0.721s/it]: train_loss_raw=2.2253, running_loss=2.2084, LR=0.000100
[2025-08-26 08:49:31,208][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001368] [Batch 00545/00823] [00:06:32/00:03:20, 0.721s/it]: train_loss_raw=2.1872, running_loss=2.2082, LR=0.000100
[2025-08-26 08:49:37,206][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001376] [Batch 00553/00823] [00:06:38/00:03:14, 0.721s/it]: train_loss_raw=2.1900, running_loss=2.2044, LR=0.000100
[2025-08-26 08:49:43,240][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001384] [Batch 00561/00823] [00:06:44/00:03:09, 0.722s/it]: train_loss_raw=2.1967, running_loss=2.2026, LR=0.000100
[2025-08-26 08:49:49,381][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001392] [Batch 00569/00823] [00:06:51/00:03:03, 0.722s/it]: train_loss_raw=2.1866, running_loss=2.2014, LR=0.000100
[2025-08-26 08:49:55,357][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001400] [Batch 00577/00823] [00:06:57/00:02:57, 0.723s/it]: train_loss_raw=2.1306, running_loss=2.1976, LR=0.000100
[2025-08-26 08:50:01,400][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001408] [Batch 00585/00823] [00:07:03/00:02:52, 0.723s/it]: train_loss_raw=2.1698, running_loss=2.1938, LR=0.000100
[2025-08-26 08:50:07,267][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001416] [Batch 00593/00823] [00:07:08/00:02:46, 0.723s/it]: train_loss_raw=2.2319, running_loss=2.1931, LR=0.000100
[2025-08-26 08:50:12,717][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001424] [Batch 00601/00823] [00:07:14/00:02:40, 0.723s/it]: train_loss_raw=2.1139, running_loss=2.1908, LR=0.000100
[2025-08-26 08:50:18,654][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001432] [Batch 00609/00823] [00:07:20/00:02:34, 0.723s/it]: train_loss_raw=2.1677, running_loss=2.1880, LR=0.000100
[2025-08-26 08:50:24,675][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001440] [Batch 00617/00823] [00:07:26/00:02:29, 0.723s/it]: train_loss_raw=2.1454, running_loss=2.1849, LR=0.000100
[2025-08-26 08:50:30,689][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001448] [Batch 00625/00823] [00:07:32/00:02:23, 0.724s/it]: train_loss_raw=2.1208, running_loss=2.1850, LR=0.000100
[2025-08-26 08:50:36,760][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001456] [Batch 00633/00823] [00:07:38/00:02:17, 0.724s/it]: train_loss_raw=2.1484, running_loss=2.1833, LR=0.000100
[2025-08-26 08:50:42,561][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001464] [Batch 00641/00823] [00:07:44/00:02:11, 0.724s/it]: train_loss_raw=2.1593, running_loss=2.1807, LR=0.000100
[2025-08-26 08:50:48,246][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001472] [Batch 00649/00823] [00:07:49/00:02:05, 0.724s/it]: train_loss_raw=2.1391, running_loss=2.1779, LR=0.000100
[2025-08-26 08:50:54,166][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001480] [Batch 00657/00823] [00:07:55/00:02:00, 0.724s/it]: train_loss_raw=2.1309, running_loss=2.1757, LR=0.000100
[2025-08-26 08:51:00,169][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001488] [Batch 00665/00823] [00:08:01/00:01:54, 0.725s/it]: train_loss_raw=2.1271, running_loss=2.1728, LR=0.000100
[2025-08-26 08:51:06,229][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001496] [Batch 00673/00823] [00:08:07/00:01:48, 0.725s/it]: train_loss_raw=2.1755, running_loss=2.1715, LR=0.000100
[2025-08-26 08:51:12,302][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001504] [Batch 00681/00823] [00:08:13/00:01:43, 0.725s/it]: train_loss_raw=2.2161, running_loss=2.1712, LR=0.000100
[2025-08-26 08:51:18,344][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001512] [Batch 00689/00823] [00:08:20/00:01:37, 0.726s/it]: train_loss_raw=2.1260, running_loss=2.1679, LR=0.000100
[2025-08-26 08:51:24,363][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001520] [Batch 00697/00823] [00:08:26/00:01:31, 0.726s/it]: train_loss_raw=2.1112, running_loss=2.1645, LR=0.000100
[2025-08-26 08:51:30,387][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001528] [Batch 00705/00823] [00:08:32/00:01:25, 0.726s/it]: train_loss_raw=2.1972, running_loss=2.1622, LR=0.000100
[2025-08-26 08:51:36,440][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001536] [Batch 00713/00823] [00:08:38/00:01:19, 0.727s/it]: train_loss_raw=2.1126, running_loss=2.1621, LR=0.000100
[2025-08-26 08:51:42,448][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001544] [Batch 00721/00823] [00:08:44/00:01:14, 0.727s/it]: train_loss_raw=2.1476, running_loss=2.1603, LR=0.000100
[2025-08-26 08:51:48,482][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001552] [Batch 00729/00823] [00:08:50/00:01:08, 0.727s/it]: train_loss_raw=2.1349, running_loss=2.1596, LR=0.000100
[2025-08-26 08:51:54,323][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001560] [Batch 00737/00823] [00:08:56/00:01:02, 0.727s/it]: train_loss_raw=2.1892, running_loss=2.1577, LR=0.000100
[2025-08-26 08:52:00,319][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001568] [Batch 00745/00823] [00:09:02/00:00:56, 0.728s/it]: train_loss_raw=2.1387, running_loss=2.1521, LR=0.000100
[2025-08-26 08:52:06,390][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001576] [Batch 00753/00823] [00:09:08/00:00:50, 0.728s/it]: train_loss_raw=2.1539, running_loss=2.1531, LR=0.000100
[2025-08-26 08:52:12,522][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001584] [Batch 00761/00823] [00:09:14/00:00:45, 0.728s/it]: train_loss_raw=2.0675, running_loss=2.1507, LR=0.000100
[2025-08-26 08:52:18,497][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001592] [Batch 00769/00823] [00:09:20/00:00:39, 0.728s/it]: train_loss_raw=2.1022, running_loss=2.1473, LR=0.000100
[2025-08-26 08:52:24,535][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001600] [Batch 00777/00823] [00:09:26/00:00:33, 0.729s/it]: train_loss_raw=2.0464, running_loss=2.1461, LR=0.000100
[2025-08-26 08:52:30,190][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001608] [Batch 00785/00823] [00:09:31/00:00:27, 0.729s/it]: train_loss_raw=2.1465, running_loss=2.1440, LR=0.000100
[2025-08-26 08:52:35,953][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001616] [Batch 00793/00823] [00:09:37/00:00:21, 0.728s/it]: train_loss_raw=2.0255, running_loss=2.1394, LR=0.000100
[2025-08-26 08:52:41,903][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001624] [Batch 00801/00823] [00:09:43/00:00:16, 0.729s/it]: train_loss_raw=2.1195, running_loss=2.1399, LR=0.000100
[2025-08-26 08:52:47,597][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001632] [Batch 00809/00823] [00:09:49/00:00:10, 0.728s/it]: train_loss_raw=2.1574, running_loss=2.1376, LR=0.000100
[2025-08-26 08:52:53,095][__main__][INFO] - [TRAIN] [Epoch 01/29 Step 001640] [Batch 00817/00823] [00:09:54/00:00:04, 0.728s/it]: train_loss_raw=2.1399, running_loss=2.1373, LR=0.000100
[2025-08-26 08:53:03,755][__main__][INFO] - [VALIDATION] [Epoch 01/29] Starting validation.
[2025-08-26 08:53:14,134][__main__][INFO] - [VALIDATION] [Epoch 01/29 Step 001647] [Batch 00007/00013] [00:00:10/00:00:06, 1.297s/it]
[2025-08-26 08:53:21,660][__main__][INFO] - [VALIDATION] [Epoch 01/29] train_loss=2.13738, valid_loss=2.15038
[2025-08-26 08:53:21,660][__main__][INFO] - [VALIDATION] [Epoch 01/29] Metrics:
[2025-08-26 08:53:21,660][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_er      0.811
[2025-08-26 08:53:21,660][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_prec    0.024
[2025-08-26 08:53:21,660][__main__][INFO] - [VALIDATION] [Epoch 01/29] - aa_recall  0.025
[2025-08-26 08:53:21,660][__main__][INFO] - [VALIDATION] [Epoch 01/29] - pep_recall 0.000
[2025-08-26 08:53:21,663][__main__][INFO] - [TRAIN] [Epoch 01/29] Epoch complete, total time 00:20:45, remaining time 04:50:35, 00:10:22 per epoch
[2025-08-26 08:53:23,683][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001648] [Batch 00002/00823] [00:00:00/00:06:35, 0.482s/it]: train_loss_raw=2.0841, running_loss=2.1283, LR=0.000100
[2025-08-26 08:53:29,716][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001656] [Batch 00010/00823] [00:00:06/00:09:28, 0.700s/it]: train_loss_raw=2.1017, running_loss=2.1293, LR=0.000100
[2025-08-26 08:53:35,700][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001664] [Batch 00018/00823] [00:00:12/00:09:40, 0.721s/it]: train_loss_raw=2.0845, running_loss=2.1271, LR=0.000100
[2025-08-26 08:53:41,769][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001672] [Batch 00026/00823] [00:00:19/00:09:43, 0.733s/it]: train_loss_raw=2.1107, running_loss=2.1259, LR=0.000100
[2025-08-26 08:53:48,044][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001680] [Batch 00034/00823] [00:00:25/00:09:47, 0.745s/it]: train_loss_raw=2.0992, running_loss=2.1256, LR=0.000100
[2025-08-26 08:53:54,277][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001688] [Batch 00042/00823] [00:00:31/00:09:46, 0.751s/it]: train_loss_raw=2.1282, running_loss=2.1228, LR=0.000100
[2025-08-26 08:54:00,223][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001696] [Batch 00050/00823] [00:00:37/00:09:39, 0.750s/it]: train_loss_raw=2.0958, running_loss=2.1198, LR=0.000100
[2025-08-26 08:54:06,154][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001704] [Batch 00058/00823] [00:00:43/00:09:32, 0.749s/it]: train_loss_raw=2.0961, running_loss=2.1192, LR=0.000100
[2025-08-26 08:54:12,152][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001712] [Batch 00066/00823] [00:00:49/00:09:26, 0.749s/it]: train_loss_raw=2.1005, running_loss=2.1178, LR=0.000100
[2025-08-26 08:54:18,243][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001720] [Batch 00074/00823] [00:00:55/00:09:21, 0.750s/it]: train_loss_raw=2.1374, running_loss=2.1169, LR=0.000100
[2025-08-26 08:54:24,264][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001728] [Batch 00082/00823] [00:01:01/00:09:16, 0.751s/it]: train_loss_raw=2.0077, running_loss=2.1157, LR=0.000100
[2025-08-26 08:54:30,303][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001736] [Batch 00090/00823] [00:01:07/00:09:10, 0.751s/it]: train_loss_raw=2.0764, running_loss=2.1147, LR=0.000100
[2025-08-26 08:54:36,434][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001744] [Batch 00098/00823] [00:01:13/00:09:05, 0.752s/it]: train_loss_raw=2.0368, running_loss=2.1128, LR=0.000100
[2025-08-26 08:54:42,241][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001752] [Batch 00106/00823] [00:01:19/00:08:57, 0.750s/it]: train_loss_raw=2.1179, running_loss=2.1110, LR=0.000100
[2025-08-26 08:54:48,214][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001760] [Batch 00114/00823] [00:01:25/00:08:51, 0.750s/it]: train_loss_raw=2.0767, running_loss=2.1095, LR=0.000100
[2025-08-26 08:54:54,177][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001768] [Batch 00122/00823] [00:01:31/00:08:45, 0.750s/it]: train_loss_raw=2.0482, running_loss=2.1066, LR=0.000100
[2025-08-26 08:55:00,231][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001776] [Batch 00130/00823] [00:01:37/00:08:39, 0.750s/it]: train_loss_raw=2.0545, running_loss=2.1046, LR=0.000100
[2025-08-26 08:55:06,240][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001784] [Batch 00138/00823] [00:01:43/00:08:33, 0.750s/it]: train_loss_raw=2.0292, running_loss=2.1043, LR=0.000100
[2025-08-26 08:55:12,251][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001792] [Batch 00146/00823] [00:01:49/00:08:27, 0.750s/it]: train_loss_raw=2.0600, running_loss=2.1016, LR=0.000100
[2025-08-26 08:55:18,348][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001800] [Batch 00154/00823] [00:01:55/00:08:22, 0.751s/it]: train_loss_raw=2.0234, running_loss=2.0985, LR=0.000100
[2025-08-26 08:55:24,365][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001808] [Batch 00162/00823] [00:02:01/00:08:16, 0.751s/it]: train_loss_raw=2.0982, running_loss=2.0970, LR=0.000100
[2025-08-26 08:55:30,440][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001816] [Batch 00170/00823] [00:02:07/00:08:10, 0.751s/it]: train_loss_raw=2.0288, running_loss=2.0943, LR=0.000100
[2025-08-26 08:55:36,465][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001824] [Batch 00178/00823] [00:02:13/00:08:04, 0.751s/it]: train_loss_raw=2.0325, running_loss=2.0927, LR=0.000100
[2025-08-26 08:55:42,452][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001832] [Batch 00186/00823] [00:02:19/00:07:58, 0.751s/it]: train_loss_raw=2.0510, running_loss=2.0913, LR=0.000100
[2025-08-26 08:55:48,488][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001840] [Batch 00194/00823] [00:02:25/00:07:52, 0.751s/it]: train_loss_raw=2.0229, running_loss=2.0894, LR=0.000100
[2025-08-26 08:55:54,602][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001848] [Batch 00202/00823] [00:02:31/00:07:46, 0.752s/it]: train_loss_raw=2.0874, running_loss=2.0883, LR=0.000100
[2025-08-26 08:56:00,575][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001856] [Batch 00210/00823] [00:02:37/00:07:40, 0.752s/it]: train_loss_raw=2.0949, running_loss=2.0869, LR=0.000100
[2025-08-26 08:56:06,611][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001864] [Batch 00218/00823] [00:02:43/00:07:34, 0.752s/it]: train_loss_raw=2.0321, running_loss=2.0841, LR=0.000100
[2025-08-26 08:56:12,073][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001872] [Batch 00226/00823] [00:02:49/00:07:27, 0.749s/it]: train_loss_raw=2.0026, running_loss=2.0825, LR=0.000100
[2025-08-26 08:56:17,857][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001880] [Batch 00234/00823] [00:02:55/00:07:20, 0.748s/it]: train_loss_raw=2.1019, running_loss=2.0816, LR=0.000100
[2025-08-26 08:56:23,849][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001888] [Batch 00242/00823] [00:03:01/00:07:14, 0.748s/it]: train_loss_raw=2.0405, running_loss=2.0802, LR=0.000100
[2025-08-26 08:56:29,846][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001896] [Batch 00250/00823] [00:03:07/00:07:08, 0.749s/it]: train_loss_raw=2.0567, running_loss=2.0783, LR=0.000100
[2025-08-26 08:56:35,936][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001904] [Batch 00258/00823] [00:03:13/00:07:03, 0.749s/it]: train_loss_raw=2.0668, running_loss=2.0790, LR=0.000100
[2025-08-26 08:56:42,075][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001912] [Batch 00266/00823] [00:03:19/00:06:57, 0.749s/it]: train_loss_raw=2.0068, running_loss=2.0756, LR=0.000100
[2025-08-26 08:56:48,120][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001920] [Batch 00274/00823] [00:03:25/00:06:51, 0.750s/it]: train_loss_raw=1.9810, running_loss=2.0730, LR=0.000100
[2025-08-26 08:56:54,212][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001928] [Batch 00282/00823] [00:03:31/00:06:45, 0.750s/it]: train_loss_raw=2.0273, running_loss=2.0724, LR=0.000100
[2025-08-26 08:57:00,024][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001936] [Batch 00290/00823] [00:03:37/00:06:39, 0.749s/it]: train_loss_raw=2.0342, running_loss=2.0732, LR=0.000100
[2025-08-26 08:57:05,998][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001944] [Batch 00298/00823] [00:03:43/00:06:33, 0.749s/it]: train_loss_raw=2.0439, running_loss=2.0713, LR=0.000100
[2025-08-26 08:57:12,103][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001952] [Batch 00306/00823] [00:03:49/00:06:27, 0.750s/it]: train_loss_raw=2.0305, running_loss=2.0667, LR=0.000100
[2025-08-26 08:57:18,234][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001960] [Batch 00314/00823] [00:03:55/00:06:21, 0.750s/it]: train_loss_raw=2.0235, running_loss=2.0622, LR=0.000100
[2025-08-26 08:57:24,340][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001968] [Batch 00322/00823] [00:04:01/00:06:15, 0.750s/it]: train_loss_raw=2.0270, running_loss=2.0607, LR=0.000100
[2025-08-26 08:57:30,364][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001976] [Batch 00330/00823] [00:04:07/00:06:09, 0.750s/it]: train_loss_raw=2.0610, running_loss=2.0624, LR=0.000100
[2025-08-26 08:57:36,398][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001984] [Batch 00338/00823] [00:04:13/00:06:04, 0.751s/it]: train_loss_raw=1.9952, running_loss=2.0596, LR=0.000100
[2025-08-26 08:57:42,433][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 001992] [Batch 00346/00823] [00:04:19/00:05:58, 0.751s/it]: train_loss_raw=2.0378, running_loss=2.0560, LR=0.000100
[2025-08-26 08:57:48,478][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002000] [Batch 00354/00823] [00:04:25/00:05:52, 0.751s/it]: train_loss_raw=2.0316, running_loss=2.0548, LR=0.000100
[2025-08-26 08:57:58,630][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002008] [Batch 00362/00823] [00:04:35/00:05:51, 0.762s/it]: train_loss_raw=2.0052, running_loss=2.0537, LR=0.000100
[2025-08-26 08:58:04,694][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002016] [Batch 00370/00823] [00:04:41/00:05:45, 0.762s/it]: train_loss_raw=2.0600, running_loss=2.0525, LR=0.000100
[2025-08-26 08:58:10,738][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002024] [Batch 00378/00823] [00:04:48/00:05:39, 0.762s/it]: train_loss_raw=1.9965, running_loss=2.0508, LR=0.000100
[2025-08-26 08:58:16,832][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002032] [Batch 00386/00823] [00:04:54/00:05:32, 0.762s/it]: train_loss_raw=2.0764, running_loss=2.0492, LR=0.000100
[2025-08-26 08:58:22,941][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002040] [Batch 00394/00823] [00:05:00/00:05:26, 0.762s/it]: train_loss_raw=2.0380, running_loss=2.0490, LR=0.000100
[2025-08-26 08:58:29,178][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002048] [Batch 00402/00823] [00:05:06/00:05:20, 0.762s/it]: train_loss_raw=1.9932, running_loss=2.0471, LR=0.000100
[2025-08-26 08:58:35,058][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002056] [Batch 00410/00823] [00:05:12/00:05:14, 0.762s/it]: train_loss_raw=2.0666, running_loss=2.0454, LR=0.000100
[2025-08-26 08:58:40,964][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002064] [Batch 00418/00823] [00:05:18/00:05:08, 0.761s/it]: train_loss_raw=2.0169, running_loss=2.0436, LR=0.000100
[2025-08-26 08:58:46,942][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002072] [Batch 00426/00823] [00:05:24/00:05:02, 0.761s/it]: train_loss_raw=2.0844, running_loss=2.0426, LR=0.000100
[2025-08-26 08:58:53,045][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002080] [Batch 00434/00823] [00:05:30/00:04:56, 0.761s/it]: train_loss_raw=2.0045, running_loss=2.0411, LR=0.000100
[2025-08-26 08:58:59,159][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002088] [Batch 00442/00823] [00:05:36/00:04:50, 0.761s/it]: train_loss_raw=2.0514, running_loss=2.0395, LR=0.000100
[2025-08-26 08:59:05,244][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002096] [Batch 00450/00823] [00:05:42/00:04:43, 0.761s/it]: train_loss_raw=2.0511, running_loss=2.0397, LR=0.000100
[2025-08-26 08:59:11,235][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002104] [Batch 00458/00823] [00:05:48/00:04:37, 0.761s/it]: train_loss_raw=2.0053, running_loss=2.0376, LR=0.000100
[2025-08-26 08:59:17,191][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002112] [Batch 00466/00823] [00:05:54/00:04:31, 0.761s/it]: train_loss_raw=2.0174, running_loss=2.0341, LR=0.000100
[2025-08-26 08:59:23,206][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002120] [Batch 00474/00823] [00:06:00/00:04:25, 0.761s/it]: train_loss_raw=2.0917, running_loss=2.0347, LR=0.000100
[2025-08-26 08:59:29,256][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002128] [Batch 00482/00823] [00:06:06/00:04:19, 0.760s/it]: train_loss_raw=2.0591, running_loss=2.0329, LR=0.000100
[2025-08-26 08:59:35,243][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002136] [Batch 00490/00823] [00:06:12/00:04:13, 0.760s/it]: train_loss_raw=2.0608, running_loss=2.0324, LR=0.000100
[2025-08-26 08:59:41,347][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002144] [Batch 00498/00823] [00:06:18/00:04:07, 0.760s/it]: train_loss_raw=2.0261, running_loss=2.0313, LR=0.000100
[2025-08-26 08:59:47,371][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002152] [Batch 00506/00823] [00:06:24/00:04:00, 0.760s/it]: train_loss_raw=1.9663, running_loss=2.0274, LR=0.000100
[2025-08-26 08:59:53,503][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002160] [Batch 00514/00823] [00:06:30/00:03:54, 0.760s/it]: train_loss_raw=1.9587, running_loss=2.0247, LR=0.000100
[2025-08-26 08:59:59,648][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002168] [Batch 00522/00823] [00:06:36/00:03:48, 0.760s/it]: train_loss_raw=2.0501, running_loss=2.0258, LR=0.000100
[2025-08-26 09:00:05,729][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002176] [Batch 00530/00823] [00:06:43/00:03:42, 0.760s/it]: train_loss_raw=1.9867, running_loss=2.0234, LR=0.000100
[2025-08-26 09:00:11,846][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002184] [Batch 00538/00823] [00:06:49/00:03:36, 0.760s/it]: train_loss_raw=2.0417, running_loss=2.0238, LR=0.000100
[2025-08-26 09:00:17,947][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002192] [Batch 00546/00823] [00:06:55/00:03:30, 0.760s/it]: train_loss_raw=2.0679, running_loss=2.0217, LR=0.000100
[2025-08-26 09:00:23,987][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002200] [Batch 00554/00823] [00:07:01/00:03:24, 0.760s/it]: train_loss_raw=1.9196, running_loss=2.0200, LR=0.000100
[2025-08-26 09:00:30,090][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002208] [Batch 00562/00823] [00:07:07/00:03:18, 0.760s/it]: train_loss_raw=2.0182, running_loss=2.0185, LR=0.000100
[2025-08-26 09:00:36,113][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002216] [Batch 00570/00823] [00:07:13/00:03:12, 0.760s/it]: train_loss_raw=2.0081, running_loss=2.0175, LR=0.000100
[2025-08-26 09:00:41,961][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002224] [Batch 00578/00823] [00:07:19/00:03:06, 0.760s/it]: train_loss_raw=1.9882, running_loss=2.0162, LR=0.000100
[2025-08-26 09:00:48,018][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002232] [Batch 00586/00823] [00:07:25/00:03:00, 0.760s/it]: train_loss_raw=1.9101, running_loss=2.0159, LR=0.000100
[2025-08-26 09:00:53,983][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002240] [Batch 00594/00823] [00:07:31/00:02:53, 0.760s/it]: train_loss_raw=1.9616, running_loss=2.0132, LR=0.000100
[2025-08-26 09:00:59,980][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002248] [Batch 00602/00823] [00:07:37/00:02:47, 0.760s/it]: train_loss_raw=2.0587, running_loss=2.0135, LR=0.000100
[2025-08-26 09:01:06,003][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002256] [Batch 00610/00823] [00:07:43/00:02:41, 0.759s/it]: train_loss_raw=2.0007, running_loss=2.0117, LR=0.000100
[2025-08-26 09:01:12,045][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002264] [Batch 00618/00823] [00:07:49/00:02:35, 0.759s/it]: train_loss_raw=2.0728, running_loss=2.0110, LR=0.000100
[2025-08-26 09:01:18,088][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002272] [Batch 00626/00823] [00:07:55/00:02:29, 0.759s/it]: train_loss_raw=1.9879, running_loss=2.0089, LR=0.000100
[2025-08-26 09:01:24,131][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002280] [Batch 00634/00823] [00:08:01/00:02:23, 0.759s/it]: train_loss_raw=1.9453, running_loss=2.0080, LR=0.000100
[2025-08-26 09:01:30,217][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002288] [Batch 00642/00823] [00:08:07/00:02:17, 0.759s/it]: train_loss_raw=2.0764, running_loss=2.0063, LR=0.000100
[2025-08-26 09:01:36,252][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002296] [Batch 00650/00823] [00:08:13/00:02:11, 0.759s/it]: train_loss_raw=1.9807, running_loss=2.0046, LR=0.000100
[2025-08-26 09:01:42,284][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002304] [Batch 00658/00823] [00:08:19/00:02:05, 0.759s/it]: train_loss_raw=1.9410, running_loss=2.0024, LR=0.000100
[2025-08-26 09:01:48,302][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002312] [Batch 00666/00823] [00:08:25/00:01:59, 0.759s/it]: train_loss_raw=2.0164, running_loss=1.9994, LR=0.000100
[2025-08-26 09:01:54,393][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002320] [Batch 00674/00823] [00:08:31/00:01:53, 0.759s/it]: train_loss_raw=2.0195, running_loss=1.9987, LR=0.000100
[2025-08-26 09:02:00,370][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002328] [Batch 00682/00823] [00:08:37/00:01:47, 0.759s/it]: train_loss_raw=1.9465, running_loss=1.9959, LR=0.000100
[2025-08-26 09:02:06,428][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002336] [Batch 00690/00823] [00:08:43/00:01:40, 0.759s/it]: train_loss_raw=2.0422, running_loss=1.9969, LR=0.000100
[2025-08-26 09:02:12,459][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002344] [Batch 00698/00823] [00:08:49/00:01:34, 0.759s/it]: train_loss_raw=1.9783, running_loss=1.9949, LR=0.000100
[2025-08-26 09:02:18,501][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002352] [Batch 00706/00823] [00:08:55/00:01:28, 0.759s/it]: train_loss_raw=1.8384, running_loss=1.9927, LR=0.000100
[2025-08-26 09:02:24,548][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002360] [Batch 00714/00823] [00:09:01/00:01:22, 0.759s/it]: train_loss_raw=2.0412, running_loss=1.9931, LR=0.000100
[2025-08-26 09:02:30,588][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002368] [Batch 00722/00823] [00:09:07/00:01:16, 0.759s/it]: train_loss_raw=1.9968, running_loss=1.9926, LR=0.000100
[2025-08-26 09:02:36,651][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002376] [Batch 00730/00823] [00:09:13/00:01:10, 0.759s/it]: train_loss_raw=2.0216, running_loss=1.9922, LR=0.000100
[2025-08-26 09:02:42,687][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002384] [Batch 00738/00823] [00:09:19/00:01:04, 0.759s/it]: train_loss_raw=1.9221, running_loss=1.9892, LR=0.000100
[2025-08-26 09:02:48,830][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002392] [Batch 00746/00823] [00:09:26/00:00:58, 0.759s/it]: train_loss_raw=1.9694, running_loss=1.9881, LR=0.000100
[2025-08-26 09:02:54,834][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002400] [Batch 00754/00823] [00:09:32/00:00:52, 0.759s/it]: train_loss_raw=1.9913, running_loss=1.9863, LR=0.000100
[2025-08-26 09:03:00,871][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002408] [Batch 00762/00823] [00:09:38/00:00:46, 0.759s/it]: train_loss_raw=1.9703, running_loss=1.9846, LR=0.000100
[2025-08-26 09:03:06,887][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002416] [Batch 00770/00823] [00:09:44/00:00:40, 0.759s/it]: train_loss_raw=1.9627, running_loss=1.9843, LR=0.000100
[2025-08-26 09:03:12,849][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002424] [Batch 00778/00823] [00:09:50/00:00:34, 0.759s/it]: train_loss_raw=2.0435, running_loss=1.9868, LR=0.000100
[2025-08-26 09:03:18,904][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002432] [Batch 00786/00823] [00:09:56/00:00:28, 0.759s/it]: train_loss_raw=1.9228, running_loss=1.9858, LR=0.000100
[2025-08-26 09:03:24,938][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002440] [Batch 00794/00823] [00:10:02/00:00:21, 0.758s/it]: train_loss_raw=1.8590, running_loss=1.9840, LR=0.000100
[2025-08-26 09:03:30,997][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002448] [Batch 00802/00823] [00:10:08/00:00:15, 0.758s/it]: train_loss_raw=1.9540, running_loss=1.9842, LR=0.000100
[2025-08-26 09:03:37,002][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002456] [Batch 00810/00823] [00:10:14/00:00:09, 0.758s/it]: train_loss_raw=1.9821, running_loss=1.9808, LR=0.000100
[2025-08-26 09:03:42,951][__main__][INFO] - [TRAIN] [Epoch 02/29 Step 002464] [Batch 00818/00823] [00:10:20/00:00:03, 0.758s/it]: train_loss_raw=1.9778, running_loss=1.9794, LR=0.000100
[2025-08-26 09:03:46,954][__main__][INFO] - [VALIDATION] [Epoch 02/29] Starting validation.
[2025-08-26 09:03:58,324][__main__][INFO] - [VALIDATION] [Epoch 02/29 Step 002470] [Batch 00007/00013] [00:00:11/00:00:07, 1.421s/it]
[2025-08-26 09:04:05,931][__main__][INFO] - [VALIDATION] [Epoch 02/29] train_loss=1.97751, valid_loss=2.00224
[2025-08-26 09:04:05,931][__main__][INFO] - [VALIDATION] [Epoch 02/29] Metrics:
[2025-08-26 09:04:05,931][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_er      0.790
[2025-08-26 09:04:05,931][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_prec    0.030
[2025-08-26 09:04:05,932][__main__][INFO] - [VALIDATION] [Epoch 02/29] - aa_recall  0.032
[2025-08-26 09:04:05,932][__main__][INFO] - [VALIDATION] [Epoch 02/29] - pep_recall 0.000
[2025-08-26 09:04:05,934][__main__][INFO] - [TRAIN] [Epoch 02/29] Epoch complete, total time 00:31:29, remaining time 04:43:27, 00:10:29 per epoch
[2025-08-26 09:04:08,828][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002472] [Batch 00003/00823] [00:00:01/00:07:38, 0.559s/it]: train_loss_raw=1.9549, running_loss=1.9923, LR=0.000100
[2025-08-26 09:04:14,782][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002480] [Batch 00011/00823] [00:00:07/00:09:23, 0.694s/it]: train_loss_raw=2.0365, running_loss=1.9909, LR=0.000100
[2025-08-26 09:04:20,752][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002488] [Batch 00019/00823] [00:00:13/00:09:35, 0.716s/it]: train_loss_raw=2.0380, running_loss=1.9886, LR=0.000100
[2025-08-26 09:04:26,784][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002496] [Batch 00027/00823] [00:00:19/00:09:38, 0.727s/it]: train_loss_raw=1.9448, running_loss=1.9850, LR=0.000100
[2025-08-26 09:04:32,883][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002504] [Batch 00035/00823] [00:00:25/00:09:39, 0.735s/it]: train_loss_raw=2.0305, running_loss=1.9852, LR=0.000100
[2025-08-26 09:04:38,890][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002512] [Batch 00043/00823] [00:00:31/00:09:35, 0.738s/it]: train_loss_raw=2.0046, running_loss=1.9849, LR=0.000100
[2025-08-26 09:04:44,970][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002520] [Batch 00051/00823] [00:00:37/00:09:32, 0.742s/it]: train_loss_raw=1.9142, running_loss=1.9814, LR=0.000100
[2025-08-26 09:04:51,014][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002528] [Batch 00059/00823] [00:00:43/00:09:28, 0.743s/it]: train_loss_raw=1.8400, running_loss=1.9766, LR=0.000100
[2025-08-26 09:04:57,051][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002536] [Batch 00067/00823] [00:00:49/00:09:23, 0.745s/it]: train_loss_raw=1.9860, running_loss=1.9742, LR=0.000100
[2025-08-26 09:05:02,795][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002544] [Batch 00075/00823] [00:00:55/00:09:14, 0.742s/it]: train_loss_raw=1.9141, running_loss=1.9728, LR=0.000100
[2025-08-26 09:05:08,598][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002552] [Batch 00083/00823] [00:01:01/00:09:07, 0.740s/it]: train_loss_raw=1.8448, running_loss=1.9689, LR=0.000100
[2025-08-26 09:05:14,493][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002560] [Batch 00091/00823] [00:01:07/00:09:01, 0.740s/it]: train_loss_raw=1.8846, running_loss=1.9675, LR=0.000100
[2025-08-26 09:05:20,406][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002568] [Batch 00099/00823] [00:01:13/00:08:55, 0.740s/it]: train_loss_raw=1.8508, running_loss=1.9659, LR=0.000100
[2025-08-26 09:05:26,443][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002576] [Batch 00107/00823] [00:01:19/00:08:50, 0.741s/it]: train_loss_raw=1.8917, running_loss=1.9634, LR=0.000100
[2025-08-26 09:05:32,496][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002584] [Batch 00115/00823] [00:01:25/00:08:45, 0.742s/it]: train_loss_raw=1.9152, running_loss=1.9606, LR=0.000100
[2025-08-26 09:05:38,567][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002592] [Batch 00123/00823] [00:01:31/00:08:40, 0.743s/it]: train_loss_raw=1.9824, running_loss=1.9618, LR=0.000100
[2025-08-26 09:05:44,596][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002600] [Batch 00131/00823] [00:01:37/00:08:34, 0.744s/it]: train_loss_raw=1.9430, running_loss=1.9608, LR=0.000100
[2025-08-26 09:05:50,687][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002608] [Batch 00139/00823] [00:01:43/00:08:29, 0.745s/it]: train_loss_raw=1.9010, running_loss=1.9577, LR=0.000100
[2025-08-26 09:05:56,753][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002616] [Batch 00147/00823] [00:01:49/00:08:24, 0.746s/it]: train_loss_raw=1.9792, running_loss=1.9571, LR=0.000100
[2025-08-26 09:06:02,819][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002624] [Batch 00155/00823] [00:01:55/00:08:18, 0.746s/it]: train_loss_raw=1.9367, running_loss=1.9549, LR=0.000100
[2025-08-26 09:06:08,917][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002632] [Batch 00163/00823] [00:02:01/00:08:13, 0.747s/it]: train_loss_raw=1.9262, running_loss=1.9519, LR=0.000100
[2025-08-26 09:06:14,915][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002640] [Batch 00171/00823] [00:02:07/00:08:07, 0.747s/it]: train_loss_raw=1.8966, running_loss=1.9490, LR=0.000100
[2025-08-26 09:06:20,977][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002648] [Batch 00179/00823] [00:02:13/00:08:01, 0.748s/it]: train_loss_raw=2.0028, running_loss=1.9476, LR=0.000100
[2025-08-26 09:06:27,011][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002656] [Batch 00187/00823] [00:02:19/00:07:55, 0.748s/it]: train_loss_raw=1.9658, running_loss=1.9455, LR=0.000100
[2025-08-26 09:06:33,133][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002664] [Batch 00195/00823] [00:02:25/00:07:50, 0.749s/it]: train_loss_raw=1.8680, running_loss=1.9454, LR=0.000100
[2025-08-26 09:06:39,187][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002672] [Batch 00203/00823] [00:02:32/00:07:44, 0.749s/it]: train_loss_raw=1.9261, running_loss=1.9421, LR=0.000100
[2025-08-26 09:06:45,158][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002680] [Batch 00211/00823] [00:02:38/00:07:38, 0.749s/it]: train_loss_raw=1.8928, running_loss=1.9400, LR=0.000100
[2025-08-26 09:06:51,246][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002688] [Batch 00219/00823] [00:02:44/00:07:32, 0.749s/it]: train_loss_raw=1.8882, running_loss=1.9389, LR=0.000100
[2025-08-26 09:06:57,263][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002696] [Batch 00227/00823] [00:02:50/00:07:26, 0.749s/it]: train_loss_raw=1.9100, running_loss=1.9370, LR=0.000100
[2025-08-26 09:07:03,310][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002704] [Batch 00235/00823] [00:02:56/00:07:20, 0.750s/it]: train_loss_raw=1.8634, running_loss=1.9345, LR=0.000100
[2025-08-26 09:07:09,321][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002712] [Batch 00243/00823] [00:03:02/00:07:14, 0.750s/it]: train_loss_raw=1.9796, running_loss=1.9344, LR=0.000100
[2025-08-26 09:07:15,330][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002720] [Batch 00251/00823] [00:03:08/00:07:08, 0.750s/it]: train_loss_raw=2.0235, running_loss=1.9348, LR=0.000100
[2025-08-26 09:07:21,359][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002728] [Batch 00259/00823] [00:03:14/00:07:02, 0.750s/it]: train_loss_raw=1.8962, running_loss=1.9340, LR=0.000100
[2025-08-26 09:07:27,371][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002736] [Batch 00267/00823] [00:03:20/00:06:56, 0.750s/it]: train_loss_raw=1.8746, running_loss=1.9301, LR=0.000100
[2025-08-26 09:07:33,429][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002744] [Batch 00275/00823] [00:03:26/00:06:51, 0.750s/it]: train_loss_raw=1.9080, running_loss=1.9286, LR=0.000100
[2025-08-26 09:07:39,505][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002752] [Batch 00283/00823] [00:03:32/00:06:45, 0.750s/it]: train_loss_raw=2.0182, running_loss=1.9303, LR=0.000100
[2025-08-26 09:07:45,628][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002760] [Batch 00291/00823] [00:03:38/00:06:39, 0.751s/it]: train_loss_raw=1.9220, running_loss=1.9273, LR=0.000100
[2025-08-26 09:07:51,630][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002768] [Batch 00299/00823] [00:03:44/00:06:33, 0.751s/it]: train_loss_raw=1.9276, running_loss=1.9280, LR=0.000100
[2025-08-26 09:07:57,638][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002776] [Batch 00307/00823] [00:03:50/00:06:27, 0.751s/it]: train_loss_raw=1.8985, running_loss=1.9263, LR=0.000100
[2025-08-26 09:08:03,727][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002784] [Batch 00315/00823] [00:03:56/00:06:21, 0.751s/it]: train_loss_raw=1.8750, running_loss=1.9258, LR=0.000100
[2025-08-26 09:08:09,752][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002792] [Batch 00323/00823] [00:04:02/00:06:15, 0.751s/it]: train_loss_raw=1.9756, running_loss=1.9269, LR=0.000100
[2025-08-26 09:08:15,800][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002800] [Batch 00331/00823] [00:04:08/00:06:09, 0.751s/it]: train_loss_raw=1.9478, running_loss=1.9271, LR=0.000100
[2025-08-26 09:08:21,837][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002808] [Batch 00339/00823] [00:04:14/00:06:03, 0.751s/it]: train_loss_raw=1.9643, running_loss=1.9261, LR=0.000100
[2025-08-26 09:08:27,996][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002816] [Batch 00347/00823] [00:04:20/00:05:57, 0.752s/it]: train_loss_raw=1.9862, running_loss=1.9245, LR=0.000100
[2025-08-26 09:08:34,092][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002824] [Batch 00355/00823] [00:04:26/00:05:51, 0.752s/it]: train_loss_raw=1.8713, running_loss=1.9234, LR=0.000100
[2025-08-26 09:08:40,140][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002832] [Batch 00363/00823] [00:04:32/00:05:45, 0.752s/it]: train_loss_raw=1.9146, running_loss=1.9212, LR=0.000100
[2025-08-26 09:08:46,551][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002840] [Batch 00371/00823] [00:04:39/00:05:40, 0.753s/it]: train_loss_raw=1.9037, running_loss=1.9196, LR=0.000100
[2025-08-26 09:08:52,641][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002848] [Batch 00379/00823] [00:04:45/00:05:34, 0.753s/it]: train_loss_raw=1.8436, running_loss=1.9169, LR=0.000100
[2025-08-26 09:08:58,660][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002856] [Batch 00387/00823] [00:04:51/00:05:28, 0.753s/it]: train_loss_raw=1.9524, running_loss=1.9149, LR=0.000100
[2025-08-26 09:09:04,649][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002864] [Batch 00395/00823] [00:04:57/00:05:22, 0.753s/it]: train_loss_raw=1.9080, running_loss=1.9152, LR=0.000100
[2025-08-26 09:09:10,680][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002872] [Batch 00403/00823] [00:05:03/00:05:16, 0.753s/it]: train_loss_raw=1.9923, running_loss=1.9170, LR=0.000100
[2025-08-26 09:09:16,700][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002880] [Batch 00411/00823] [00:05:09/00:05:10, 0.753s/it]: train_loss_raw=1.8508, running_loss=1.9146, LR=0.000100
[2025-08-26 09:09:22,698][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002888] [Batch 00419/00823] [00:05:15/00:05:04, 0.753s/it]: train_loss_raw=1.8017, running_loss=1.9113, LR=0.000100
[2025-08-26 09:09:28,667][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002896] [Batch 00427/00823] [00:05:21/00:04:58, 0.753s/it]: train_loss_raw=1.8818, running_loss=1.9098, LR=0.000100
[2025-08-26 09:09:34,749][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002904] [Batch 00435/00823] [00:05:27/00:04:52, 0.753s/it]: train_loss_raw=1.8991, running_loss=1.9084, LR=0.000100
[2025-08-26 09:09:40,798][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002912] [Batch 00443/00823] [00:05:33/00:04:46, 0.753s/it]: train_loss_raw=1.9250, running_loss=1.9080, LR=0.000100
[2025-08-26 09:09:46,827][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002920] [Batch 00451/00823] [00:05:39/00:04:40, 0.753s/it]: train_loss_raw=1.9095, running_loss=1.9068, LR=0.000100
[2025-08-26 09:09:52,920][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002928] [Batch 00459/00823] [00:05:45/00:04:34, 0.753s/it]: train_loss_raw=1.9191, running_loss=1.9056, LR=0.000100
[2025-08-26 09:09:58,970][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002936] [Batch 00467/00823] [00:05:51/00:04:28, 0.753s/it]: train_loss_raw=1.8894, running_loss=1.9028, LR=0.000100
[2025-08-26 09:10:05,166][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002944] [Batch 00475/00823] [00:05:58/00:04:22, 0.754s/it]: train_loss_raw=1.9063, running_loss=1.9024, LR=0.000100
[2025-08-26 09:10:11,212][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002952] [Batch 00483/00823] [00:06:04/00:04:16, 0.754s/it]: train_loss_raw=1.8889, running_loss=1.8996, LR=0.000100
[2025-08-26 09:10:17,281][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002960] [Batch 00491/00823] [00:06:10/00:04:10, 0.754s/it]: train_loss_raw=1.9045, running_loss=1.9007, LR=0.000100
[2025-08-26 09:10:23,321][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002968] [Batch 00499/00823] [00:06:16/00:04:04, 0.754s/it]: train_loss_raw=1.9421, running_loss=1.9000, LR=0.000100
[2025-08-26 09:10:29,407][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002976] [Batch 00507/00823] [00:06:22/00:03:58, 0.754s/it]: train_loss_raw=1.8353, running_loss=1.8999, LR=0.000100
[2025-08-26 09:10:35,412][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002984] [Batch 00515/00823] [00:06:28/00:03:52, 0.754s/it]: train_loss_raw=1.9536, running_loss=1.8982, LR=0.000100
[2025-08-26 09:10:41,477][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 002992] [Batch 00523/00823] [00:06:34/00:03:46, 0.754s/it]: train_loss_raw=1.8647, running_loss=1.8988, LR=0.000100
[2025-08-26 09:10:47,538][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003000] [Batch 00531/00823] [00:06:40/00:03:40, 0.754s/it]: train_loss_raw=1.8180, running_loss=1.8982, LR=0.000100
[2025-08-26 09:10:53,596][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003008] [Batch 00539/00823] [00:06:46/00:03:34, 0.754s/it]: train_loss_raw=1.8789, running_loss=1.8974, LR=0.000100
[2025-08-26 09:10:59,572][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003016] [Batch 00547/00823] [00:06:52/00:03:28, 0.754s/it]: train_loss_raw=1.9142, running_loss=1.8986, LR=0.000100
[2025-08-26 09:11:05,627][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003024] [Batch 00555/00823] [00:06:58/00:03:22, 0.754s/it]: train_loss_raw=1.8382, running_loss=1.8964, LR=0.000100
[2025-08-26 09:11:11,695][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003032] [Batch 00563/00823] [00:07:04/00:03:16, 0.754s/it]: train_loss_raw=1.9160, running_loss=1.8953, LR=0.000100
[2025-08-26 09:11:17,760][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003040] [Batch 00571/00823] [00:07:10/00:03:10, 0.754s/it]: train_loss_raw=1.9405, running_loss=1.8944, LR=0.000100
[2025-08-26 09:11:23,992][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003048] [Batch 00579/00823] [00:07:16/00:03:04, 0.754s/it]: train_loss_raw=1.8486, running_loss=1.8933, LR=0.000100
[2025-08-26 09:11:30,018][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003056] [Batch 00587/00823] [00:07:22/00:02:58, 0.754s/it]: train_loss_raw=1.8815, running_loss=1.8909, LR=0.000100
[2025-08-26 09:11:36,088][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003064] [Batch 00595/00823] [00:07:28/00:02:52, 0.755s/it]: train_loss_raw=1.9117, running_loss=1.8924, LR=0.000100
[2025-08-26 09:11:42,127][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003072] [Batch 00603/00823] [00:07:34/00:02:45, 0.755s/it]: train_loss_raw=1.7420, running_loss=1.8895, LR=0.000100
[2025-08-26 09:11:48,200][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003080] [Batch 00611/00823] [00:07:41/00:02:39, 0.755s/it]: train_loss_raw=1.8121, running_loss=1.8889, LR=0.000100
[2025-08-26 09:11:54,263][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003088] [Batch 00619/00823] [00:07:47/00:02:33, 0.755s/it]: train_loss_raw=1.9109, running_loss=1.8881, LR=0.000100
[2025-08-26 09:12:00,356][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003096] [Batch 00627/00823] [00:07:53/00:02:27, 0.755s/it]: train_loss_raw=1.8705, running_loss=1.8855, LR=0.000100
[2025-08-26 09:12:06,427][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003104] [Batch 00635/00823] [00:07:59/00:02:21, 0.755s/it]: train_loss_raw=1.8456, running_loss=1.8860, LR=0.000100
[2025-08-26 09:12:12,419][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003112] [Batch 00643/00823] [00:08:05/00:02:15, 0.755s/it]: train_loss_raw=1.8552, running_loss=1.8841, LR=0.000100
[2025-08-26 09:12:18,400][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003120] [Batch 00651/00823] [00:08:11/00:02:09, 0.755s/it]: train_loss_raw=1.8779, running_loss=1.8877, LR=0.000100
[2025-08-26 09:12:24,393][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003128] [Batch 00659/00823] [00:08:17/00:02:03, 0.755s/it]: train_loss_raw=1.8717, running_loss=1.8866, LR=0.000100
[2025-08-26 09:12:30,395][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003136] [Batch 00667/00823] [00:08:23/00:01:57, 0.754s/it]: train_loss_raw=1.8596, running_loss=1.8861, LR=0.000100
[2025-08-26 09:12:36,427][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003144] [Batch 00675/00823] [00:08:29/00:01:51, 0.754s/it]: train_loss_raw=1.8469, running_loss=1.8840, LR=0.000100
[2025-08-26 09:12:42,454][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003152] [Batch 00683/00823] [00:08:35/00:01:45, 0.754s/it]: train_loss_raw=1.9021, running_loss=1.8840, LR=0.000100
[2025-08-26 09:12:48,497][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003160] [Batch 00691/00823] [00:08:41/00:01:39, 0.754s/it]: train_loss_raw=1.8280, running_loss=1.8811, LR=0.000100
[2025-08-26 09:12:54,559][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003168] [Batch 00699/00823] [00:08:47/00:01:33, 0.755s/it]: train_loss_raw=1.8582, running_loss=1.8807, LR=0.000100
[2025-08-26 09:13:00,581][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003176] [Batch 00707/00823] [00:08:53/00:01:27, 0.755s/it]: train_loss_raw=1.7901, running_loss=1.8786, LR=0.000100
[2025-08-26 09:13:06,586][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003184] [Batch 00715/00823] [00:08:59/00:01:21, 0.754s/it]: train_loss_raw=1.8290, running_loss=1.8773, LR=0.000100
[2025-08-26 09:13:12,681][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003192] [Batch 00723/00823] [00:09:05/00:01:15, 0.755s/it]: train_loss_raw=1.8296, running_loss=1.8769, LR=0.000100
[2025-08-26 09:13:18,784][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003200] [Batch 00731/00823] [00:09:11/00:01:09, 0.755s/it]: train_loss_raw=1.8398, running_loss=1.8758, LR=0.000100
[2025-08-26 09:13:24,798][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003208] [Batch 00739/00823] [00:09:17/00:01:03, 0.755s/it]: train_loss_raw=1.8986, running_loss=1.8751, LR=0.000100
[2025-08-26 09:13:30,882][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003216] [Batch 00747/00823] [00:09:23/00:00:57, 0.755s/it]: train_loss_raw=1.8595, running_loss=1.8745, LR=0.000100
[2025-08-26 09:13:36,943][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003224] [Batch 00755/00823] [00:09:29/00:00:51, 0.755s/it]: train_loss_raw=1.8886, running_loss=1.8732, LR=0.000100
[2025-08-26 09:13:43,022][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003232] [Batch 00763/00823] [00:09:35/00:00:45, 0.755s/it]: train_loss_raw=1.7878, running_loss=1.8694, LR=0.000100
[2025-08-26 09:13:49,063][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003240] [Batch 00771/00823] [00:09:41/00:00:39, 0.755s/it]: train_loss_raw=1.8535, running_loss=1.8694, LR=0.000100
[2025-08-26 09:13:55,132][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003248] [Batch 00779/00823] [00:09:47/00:00:33, 0.755s/it]: train_loss_raw=1.8625, running_loss=1.8693, LR=0.000100
[2025-08-26 09:14:01,139][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003256] [Batch 00787/00823] [00:09:53/00:00:27, 0.755s/it]: train_loss_raw=1.7947, running_loss=1.8675, LR=0.000100
[2025-08-26 09:14:07,242][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003264] [Batch 00795/00823] [00:10:00/00:00:21, 0.755s/it]: train_loss_raw=1.7990, running_loss=1.8654, LR=0.000100
[2025-08-26 09:14:13,394][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003272] [Batch 00803/00823] [00:10:06/00:00:15, 0.755s/it]: train_loss_raw=1.8914, running_loss=1.8647, LR=0.000100
[2025-08-26 09:14:19,418][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003280] [Batch 00811/00823] [00:10:12/00:00:09, 0.755s/it]: train_loss_raw=1.8911, running_loss=1.8625, LR=0.000100
[2025-08-26 09:14:25,509][__main__][INFO] - [TRAIN] [Epoch 03/29 Step 003288] [Batch 00819/00823] [00:10:18/00:00:03, 0.755s/it]: train_loss_raw=1.8957, running_loss=1.8632, LR=0.000100
[2025-08-26 09:14:34,777][__main__][INFO] - [VALIDATION] [Epoch 03/29] Starting validation.
[2025-08-26 09:14:45,215][__main__][INFO] - [VALIDATION] [Epoch 03/29 Step 003293] [Batch 00007/00013] [00:00:10/00:00:06, 1.305s/it]
[2025-08-26 09:14:52,661][__main__][INFO] - [VALIDATION] [Epoch 03/29] train_loss=1.86419, valid_loss=1.86430
[2025-08-26 09:14:52,662][__main__][INFO] - [VALIDATION] [Epoch 03/29] Metrics:
[2025-08-26 09:14:52,662][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_er      0.752
[2025-08-26 09:14:52,662][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_prec    0.030
[2025-08-26 09:14:52,662][__main__][INFO] - [VALIDATION] [Epoch 03/29] - aa_recall  0.031
[2025-08-26 09:14:52,663][__main__][INFO] - [VALIDATION] [Epoch 03/29] - pep_recall 0.001
[2025-08-26 09:14:52,666][__main__][INFO] - [TRAIN] [Epoch 03/29] Epoch complete, total time 00:42:16, remaining time 04:34:46, 00:10:34 per epoch
[2025-08-26 09:14:56,325][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003296] [Batch 00004/00823] [00:00:02/00:08:20, 0.611s/it]: train_loss_raw=1.7336, running_loss=1.9051, LR=0.000100
[2025-08-26 09:15:02,345][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003304] [Batch 00012/00823] [00:00:08/00:09:31, 0.705s/it]: train_loss_raw=1.8522, running_loss=1.9014, LR=0.000100
[2025-08-26 09:15:08,123][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003312] [Batch 00020/00823] [00:00:14/00:09:31, 0.712s/it]: train_loss_raw=1.7913, running_loss=1.8941, LR=0.000100
[2025-08-26 09:15:13,987][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003320] [Batch 00028/00823] [00:00:20/00:09:30, 0.718s/it]: train_loss_raw=1.9110, running_loss=1.8915, LR=0.000100
[2025-08-26 09:15:19,734][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003328] [Batch 00036/00823] [00:00:25/00:09:25, 0.718s/it]: train_loss_raw=1.7476, running_loss=1.8837, LR=0.000100
[2025-08-26 09:15:25,730][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003336] [Batch 00044/00823] [00:00:31/00:09:23, 0.724s/it]: train_loss_raw=1.8999, running_loss=1.8788, LR=0.000100
[2025-08-26 09:15:31,709][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003344] [Batch 00052/00823] [00:00:37/00:09:20, 0.727s/it]: train_loss_raw=1.7886, running_loss=1.8760, LR=0.000100
[2025-08-26 09:15:37,497][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003352] [Batch 00060/00823] [00:00:43/00:09:14, 0.727s/it]: train_loss_raw=1.9443, running_loss=1.8752, LR=0.000100
[2025-08-26 09:15:43,313][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003360] [Batch 00068/00823] [00:00:49/00:09:08, 0.727s/it]: train_loss_raw=1.7994, running_loss=1.8714, LR=0.000100
[2025-08-26 09:15:49,209][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003368] [Batch 00076/00823] [00:00:55/00:09:03, 0.728s/it]: train_loss_raw=1.9319, running_loss=1.8677, LR=0.000100
[2025-08-26 09:15:55,053][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003376] [Batch 00084/00823] [00:01:01/00:08:58, 0.728s/it]: train_loss_raw=1.8427, running_loss=1.8654, LR=0.000100
[2025-08-26 09:16:00,835][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003384] [Batch 00092/00823] [00:01:06/00:08:51, 0.728s/it]: train_loss_raw=1.7995, running_loss=1.8611, LR=0.000100
[2025-08-26 09:16:06,747][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003392] [Batch 00100/00823] [00:01:12/00:08:46, 0.729s/it]: train_loss_raw=1.7678, running_loss=1.8587, LR=0.000100
[2025-08-26 09:16:12,871][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003400] [Batch 00108/00823] [00:01:18/00:08:42, 0.731s/it]: train_loss_raw=1.8440, running_loss=1.8579, LR=0.000100
[2025-08-26 09:16:18,870][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003408] [Batch 00116/00823] [00:01:24/00:08:37, 0.733s/it]: train_loss_raw=1.7395, running_loss=1.8544, LR=0.000100
[2025-08-26 09:16:24,872][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003416] [Batch 00124/00823] [00:01:30/00:08:32, 0.734s/it]: train_loss_raw=1.8575, running_loss=1.8535, LR=0.000100
[2025-08-26 09:16:31,001][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003424] [Batch 00132/00823] [00:01:37/00:08:28, 0.736s/it]: train_loss_raw=1.8440, running_loss=1.8525, LR=0.000100
[2025-08-26 09:16:37,009][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003432] [Batch 00140/00823] [00:01:43/00:08:23, 0.737s/it]: train_loss_raw=1.8297, running_loss=1.8541, LR=0.000100
[2025-08-26 09:16:43,099][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003440] [Batch 00148/00823] [00:01:49/00:08:18, 0.738s/it]: train_loss_raw=1.8697, running_loss=1.8542, LR=0.000100
[2025-08-26 09:16:49,211][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003448] [Batch 00156/00823] [00:01:55/00:08:13, 0.739s/it]: train_loss_raw=1.8284, running_loss=1.8514, LR=0.000100
[2025-08-26 09:16:55,215][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003456] [Batch 00164/00823] [00:02:01/00:08:07, 0.740s/it]: train_loss_raw=1.7681, running_loss=1.8493, LR=0.000100
[2025-08-26 09:17:01,302][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003464] [Batch 00172/00823] [00:02:07/00:08:02, 0.741s/it]: train_loss_raw=1.7923, running_loss=1.8482, LR=0.000100
[2025-08-26 09:17:07,337][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003472] [Batch 00180/00823] [00:02:13/00:07:56, 0.741s/it]: train_loss_raw=1.8331, running_loss=1.8478, LR=0.000100
[2025-08-26 09:17:13,477][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003480] [Batch 00188/00823] [00:02:19/00:07:51, 0.743s/it]: train_loss_raw=1.7883, running_loss=1.8470, LR=0.000100
[2025-08-26 09:17:19,535][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003488] [Batch 00196/00823] [00:02:25/00:07:45, 0.743s/it]: train_loss_raw=1.7128, running_loss=1.8414, LR=0.000100
[2025-08-26 09:17:25,592][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003496] [Batch 00204/00823] [00:02:31/00:07:40, 0.744s/it]: train_loss_raw=1.7361, running_loss=1.8382, LR=0.000100
[2025-08-26 09:17:31,643][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003504] [Batch 00212/00823] [00:02:37/00:07:34, 0.744s/it]: train_loss_raw=1.7825, running_loss=1.8347, LR=0.000100
[2025-08-26 09:17:37,675][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003512] [Batch 00220/00823] [00:02:43/00:07:28, 0.745s/it]: train_loss_raw=1.8631, running_loss=1.8318, LR=0.000100
[2025-08-26 09:17:43,755][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003520] [Batch 00228/00823] [00:02:49/00:07:23, 0.745s/it]: train_loss_raw=1.8467, running_loss=1.8319, LR=0.000100
[2025-08-26 09:17:49,895][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003528] [Batch 00236/00823] [00:02:56/00:07:17, 0.746s/it]: train_loss_raw=1.7804, running_loss=1.8295, LR=0.000100
[2025-08-26 09:17:55,931][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003536] [Batch 00244/00823] [00:03:02/00:07:11, 0.746s/it]: train_loss_raw=1.7250, running_loss=1.8275, LR=0.000100
[2025-08-26 09:18:02,055][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003544] [Batch 00252/00823] [00:03:08/00:07:06, 0.747s/it]: train_loss_raw=1.7959, running_loss=1.8281, LR=0.000100
[2025-08-26 09:18:08,165][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003552] [Batch 00260/00823] [00:03:14/00:07:00, 0.747s/it]: train_loss_raw=1.7229, running_loss=1.8263, LR=0.000100
[2025-08-26 09:18:14,196][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003560] [Batch 00268/00823] [00:03:20/00:06:54, 0.747s/it]: train_loss_raw=1.8608, running_loss=1.8251, LR=0.000100
[2025-08-26 09:18:20,233][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003568] [Batch 00276/00823] [00:03:26/00:06:48, 0.748s/it]: train_loss_raw=1.8103, running_loss=1.8218, LR=0.000100
[2025-08-26 09:18:26,306][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003576] [Batch 00284/00823] [00:03:32/00:06:43, 0.748s/it]: train_loss_raw=1.9057, running_loss=1.8229, LR=0.000100
[2025-08-26 09:18:32,398][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003584] [Batch 00292/00823] [00:03:38/00:06:37, 0.748s/it]: train_loss_raw=1.7982, running_loss=1.8233, LR=0.000100
[2025-08-26 09:18:38,485][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003592] [Batch 00300/00823] [00:03:44/00:06:31, 0.749s/it]: train_loss_raw=1.7250, running_loss=1.8212, LR=0.000100
[2025-08-26 09:18:44,673][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003600] [Batch 00308/00823] [00:03:50/00:06:25, 0.749s/it]: train_loss_raw=1.7999, running_loss=1.8234, LR=0.000100
[2025-08-26 09:18:50,817][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003608] [Batch 00316/00823] [00:03:56/00:06:20, 0.750s/it]: train_loss_raw=1.9448, running_loss=1.8260, LR=0.000100
[2025-08-26 09:18:56,990][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003616] [Batch 00324/00823] [00:04:03/00:06:14, 0.750s/it]: train_loss_raw=1.8377, running_loss=1.8278, LR=0.000100
[2025-08-26 09:19:03,072][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003624] [Batch 00332/00823] [00:04:09/00:06:08, 0.751s/it]: train_loss_raw=1.7650, running_loss=1.8267, LR=0.000100
[2025-08-26 09:19:09,146][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003632] [Batch 00340/00823] [00:04:15/00:06:02, 0.751s/it]: train_loss_raw=1.8238, running_loss=1.8247, LR=0.000100
[2025-08-26 09:19:15,242][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003640] [Batch 00348/00823] [00:04:21/00:05:56, 0.751s/it]: train_loss_raw=1.8579, running_loss=1.8237, LR=0.000100
[2025-08-26 09:19:21,321][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003648] [Batch 00356/00823] [00:04:27/00:05:50, 0.751s/it]: train_loss_raw=1.7567, running_loss=1.8225, LR=0.000100
[2025-08-26 09:19:27,343][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003656] [Batch 00364/00823] [00:04:33/00:05:44, 0.751s/it]: train_loss_raw=1.8106, running_loss=1.8215, LR=0.000100
[2025-08-26 09:19:33,458][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003664] [Batch 00372/00823] [00:04:39/00:05:38, 0.752s/it]: train_loss_raw=1.7889, running_loss=1.8190, LR=0.000100
[2025-08-26 09:19:39,527][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003672] [Batch 00380/00823] [00:04:45/00:05:33, 0.752s/it]: train_loss_raw=1.8057, running_loss=1.8181, LR=0.000100
[2025-08-26 09:19:45,608][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003680] [Batch 00388/00823] [00:04:51/00:05:27, 0.752s/it]: train_loss_raw=1.7563, running_loss=1.8165, LR=0.000100
[2025-08-26 09:19:51,665][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003688] [Batch 00396/00823] [00:04:57/00:05:21, 0.752s/it]: train_loss_raw=1.8488, running_loss=1.8145, LR=0.000100
[2025-08-26 09:19:57,754][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003696] [Batch 00404/00823] [00:05:03/00:05:15, 0.752s/it]: train_loss_raw=1.7804, running_loss=1.8092, LR=0.000100
[2025-08-26 09:20:03,841][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003704] [Batch 00412/00823] [00:05:09/00:05:09, 0.752s/it]: train_loss_raw=1.7683, running_loss=1.8070, LR=0.000100
[2025-08-26 09:20:09,963][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003712] [Batch 00420/00823] [00:05:16/00:05:03, 0.753s/it]: train_loss_raw=1.6710, running_loss=1.8040, LR=0.000100
[2025-08-26 09:20:16,001][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003720] [Batch 00428/00823] [00:05:22/00:04:57, 0.753s/it]: train_loss_raw=1.8526, running_loss=1.8028, LR=0.000100
[2025-08-26 09:20:22,108][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003728] [Batch 00436/00823] [00:05:28/00:04:51, 0.753s/it]: train_loss_raw=1.7695, running_loss=1.8043, LR=0.000100
[2025-08-26 09:20:28,135][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003736] [Batch 00444/00823] [00:05:34/00:04:45, 0.753s/it]: train_loss_raw=1.8447, running_loss=1.8049, LR=0.000100
[2025-08-26 09:20:34,190][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003744] [Batch 00452/00823] [00:05:40/00:04:39, 0.753s/it]: train_loss_raw=1.7817, running_loss=1.8041, LR=0.000100
[2025-08-26 09:20:40,349][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003752] [Batch 00460/00823] [00:05:46/00:04:33, 0.753s/it]: train_loss_raw=1.8362, running_loss=1.8044, LR=0.000100
[2025-08-26 09:20:46,420][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003760] [Batch 00468/00823] [00:05:52/00:04:27, 0.753s/it]: train_loss_raw=1.7960, running_loss=1.8030, LR=0.000100
[2025-08-26 09:20:52,487][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003768] [Batch 00476/00823] [00:05:58/00:04:21, 0.753s/it]: train_loss_raw=1.7250, running_loss=1.8030, LR=0.000100
[2025-08-26 09:20:58,461][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003776] [Batch 00484/00823] [00:06:04/00:04:15, 0.753s/it]: train_loss_raw=1.7920, running_loss=1.8026, LR=0.000100
[2025-08-26 09:21:04,420][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003784] [Batch 00492/00823] [00:06:10/00:04:09, 0.753s/it]: train_loss_raw=1.7975, running_loss=1.8020, LR=0.000100
[2025-08-26 09:21:10,442][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003792] [Batch 00500/00823] [00:06:16/00:04:03, 0.753s/it]: train_loss_raw=1.8728, running_loss=1.8022, LR=0.000100
[2025-08-26 09:21:16,500][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003800] [Batch 00508/00823] [00:06:22/00:03:57, 0.753s/it]: train_loss_raw=1.7990, running_loss=1.8012, LR=0.000100
[2025-08-26 09:21:22,554][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003808] [Batch 00516/00823] [00:06:28/00:03:51, 0.753s/it]: train_loss_raw=1.8574, running_loss=1.7998, LR=0.000100
[2025-08-26 09:21:28,651][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003816] [Batch 00524/00823] [00:06:34/00:03:45, 0.753s/it]: train_loss_raw=1.7239, running_loss=1.7983, LR=0.000100
[2025-08-26 09:21:34,692][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003824] [Batch 00532/00823] [00:06:40/00:03:39, 0.753s/it]: train_loss_raw=1.8165, running_loss=1.7977, LR=0.000100
[2025-08-26 09:21:40,773][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003832] [Batch 00540/00823] [00:06:46/00:03:33, 0.754s/it]: train_loss_raw=1.8004, running_loss=1.7995, LR=0.000100
[2025-08-26 09:21:46,784][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003840] [Batch 00548/00823] [00:06:52/00:03:27, 0.753s/it]: train_loss_raw=1.7959, running_loss=1.7997, LR=0.000100
[2025-08-26 09:21:52,778][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003848] [Batch 00556/00823] [00:06:58/00:03:21, 0.753s/it]: train_loss_raw=1.8169, running_loss=1.7983, LR=0.000100
[2025-08-26 09:21:58,771][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003856] [Batch 00564/00823] [00:07:04/00:03:15, 0.753s/it]: train_loss_raw=1.6791, running_loss=1.7956, LR=0.000100
[2025-08-26 09:22:04,792][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003864] [Batch 00572/00823] [00:07:10/00:03:09, 0.753s/it]: train_loss_raw=1.8738, running_loss=1.7968, LR=0.000100
[2025-08-26 09:22:10,931][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003872] [Batch 00580/00823] [00:07:17/00:03:03, 0.754s/it]: train_loss_raw=1.8431, running_loss=1.7981, LR=0.000100
[2025-08-26 09:22:17,023][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003880] [Batch 00588/00823] [00:07:23/00:02:57, 0.754s/it]: train_loss_raw=1.7888, running_loss=1.8000, LR=0.000100
[2025-08-26 09:22:23,005][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003888] [Batch 00596/00823] [00:07:29/00:02:51, 0.754s/it]: train_loss_raw=1.7587, running_loss=1.8003, LR=0.000100
[2025-08-26 09:22:29,160][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003896] [Batch 00604/00823] [00:07:35/00:02:45, 0.754s/it]: train_loss_raw=1.6348, running_loss=1.7949, LR=0.000100
[2025-08-26 09:22:35,256][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003904] [Batch 00612/00823] [00:07:41/00:02:39, 0.754s/it]: train_loss_raw=1.7765, running_loss=1.7929, LR=0.000100
[2025-08-26 09:22:41,349][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003912] [Batch 00620/00823] [00:07:47/00:02:33, 0.754s/it]: train_loss_raw=1.7216, running_loss=1.7920, LR=0.000100
[2025-08-26 09:22:47,448][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003920] [Batch 00628/00823] [00:07:53/00:02:27, 0.754s/it]: train_loss_raw=1.7201, running_loss=1.7882, LR=0.000100
[2025-08-26 09:22:53,538][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003928] [Batch 00636/00823] [00:07:59/00:02:21, 0.754s/it]: train_loss_raw=1.7855, running_loss=1.7884, LR=0.000100
[2025-08-26 09:22:59,618][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003936] [Batch 00644/00823] [00:08:05/00:02:15, 0.754s/it]: train_loss_raw=1.7425, running_loss=1.7901, LR=0.000100
[2025-08-26 09:23:05,815][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003944] [Batch 00652/00823] [00:08:11/00:02:09, 0.754s/it]: train_loss_raw=1.7759, running_loss=1.7911, LR=0.000100
[2025-08-26 09:23:11,967][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003952] [Batch 00660/00823] [00:08:18/00:02:03, 0.755s/it]: train_loss_raw=1.8415, running_loss=1.7902, LR=0.000100
[2025-08-26 09:23:18,085][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003960] [Batch 00668/00823] [00:08:24/00:01:56, 0.755s/it]: train_loss_raw=1.8084, running_loss=1.7891, LR=0.000100
[2025-08-26 09:23:24,084][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003968] [Batch 00676/00823] [00:08:30/00:01:50, 0.755s/it]: train_loss_raw=1.8635, running_loss=1.7885, LR=0.000100
[2025-08-26 09:23:30,129][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003976] [Batch 00684/00823] [00:08:36/00:01:44, 0.755s/it]: train_loss_raw=1.8572, running_loss=1.7881, LR=0.000100
[2025-08-26 09:23:36,170][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003984] [Batch 00692/00823] [00:08:42/00:01:38, 0.755s/it]: train_loss_raw=1.8540, running_loss=1.7887, LR=0.000100
[2025-08-26 09:23:42,278][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 003992] [Batch 00700/00823] [00:08:48/00:01:32, 0.755s/it]: train_loss_raw=1.8671, running_loss=1.7888, LR=0.000100
[2025-08-26 09:23:48,342][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004000] [Batch 00708/00823] [00:08:54/00:01:26, 0.755s/it]: train_loss_raw=1.8255, running_loss=1.7864, LR=0.000100
[2025-08-26 09:23:58,409][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004008] [Batch 00716/00823] [00:09:04/00:01:21, 0.761s/it]: train_loss_raw=1.8162, running_loss=1.7862, LR=0.000100
[2025-08-26 09:24:04,462][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004016] [Batch 00724/00823] [00:09:10/00:01:15, 0.760s/it]: train_loss_raw=1.8084, running_loss=1.7857, LR=0.000100
[2025-08-26 09:24:10,498][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004024] [Batch 00732/00823] [00:09:16/00:01:09, 0.760s/it]: train_loss_raw=1.8131, running_loss=1.7863, LR=0.000100
[2025-08-26 09:24:16,583][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004032] [Batch 00740/00823] [00:09:22/00:01:03, 0.760s/it]: train_loss_raw=1.7853, running_loss=1.7863, LR=0.000100
[2025-08-26 09:24:22,657][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004040] [Batch 00748/00823] [00:09:28/00:00:57, 0.760s/it]: train_loss_raw=1.8080, running_loss=1.7846, LR=0.000100
[2025-08-26 09:24:28,730][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004048] [Batch 00756/00823] [00:09:34/00:00:50, 0.760s/it]: train_loss_raw=1.7215, running_loss=1.7818, LR=0.000100
[2025-08-26 09:24:34,782][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004056] [Batch 00764/00823] [00:09:40/00:00:44, 0.760s/it]: train_loss_raw=1.6593, running_loss=1.7793, LR=0.000100
[2025-08-26 09:24:40,859][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004064] [Batch 00772/00823] [00:09:46/00:00:38, 0.760s/it]: train_loss_raw=1.7516, running_loss=1.7806, LR=0.000100
[2025-08-26 09:24:46,920][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004072] [Batch 00780/00823] [00:09:53/00:00:32, 0.760s/it]: train_loss_raw=1.7873, running_loss=1.7822, LR=0.000100
[2025-08-26 09:24:52,995][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004080] [Batch 00788/00823] [00:09:59/00:00:26, 0.760s/it]: train_loss_raw=1.8339, running_loss=1.7804, LR=0.000100
[2025-08-26 09:24:59,058][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004088] [Batch 00796/00823] [00:10:05/00:00:20, 0.760s/it]: train_loss_raw=1.8404, running_loss=1.7802, LR=0.000100
[2025-08-26 09:25:05,159][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004096] [Batch 00804/00823] [00:10:11/00:00:14, 0.760s/it]: train_loss_raw=1.8248, running_loss=1.7776, LR=0.000100
[2025-08-26 09:25:11,316][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004104] [Batch 00812/00823] [00:10:17/00:00:08, 0.760s/it]: train_loss_raw=1.8388, running_loss=1.7765, LR=0.000100
[2025-08-26 09:25:17,407][__main__][INFO] - [TRAIN] [Epoch 04/29 Step 004112] [Batch 00820/00823] [00:10:23/00:00:02, 0.760s/it]: train_loss_raw=1.7076, running_loss=1.7748, LR=0.000100
[2025-08-26 09:25:19,848][__main__][INFO] - [VALIDATION] [Epoch 04/29] Starting validation.
[2025-08-26 09:25:30,800][__main__][INFO] - [VALIDATION] [Epoch 04/29 Step 004116] [Batch 00007/00013] [00:00:10/00:00:06, 1.369s/it]
[2025-08-26 09:25:37,691][__main__][INFO] - [VALIDATION] [Epoch 04/29] train_loss=1.77483, valid_loss=1.77196
[2025-08-26 09:25:37,691][__main__][INFO] - [VALIDATION] [Epoch 04/29] Metrics:
[2025-08-26 09:25:37,692][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_er      0.755
[2025-08-26 09:25:37,692][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_prec    0.028
[2025-08-26 09:25:37,692][__main__][INFO] - [VALIDATION] [Epoch 04/29] - aa_recall  0.030
[2025-08-26 09:25:37,692][__main__][INFO] - [VALIDATION] [Epoch 04/29] - pep_recall 0.002
[2025-08-26 09:25:37,694][__main__][INFO] - [TRAIN] [Epoch 04/29] Epoch complete, total time 00:53:01, remaining time 04:25:07, 00:10:36 per epoch
[2025-08-26 09:25:42,610][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004120] [Batch 00005/00823] [00:00:03/00:08:40, 0.636s/it]: train_loss_raw=1.8660, running_loss=1.8410, LR=0.000100
[2025-08-26 09:25:48,694][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004128] [Batch 00013/00823] [00:00:09/00:09:37, 0.713s/it]: train_loss_raw=1.6736, running_loss=1.8362, LR=0.000100
[2025-08-26 09:25:54,738][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004136] [Batch 00021/00823] [00:00:15/00:09:44, 0.729s/it]: train_loss_raw=1.7528, running_loss=1.8314, LR=0.000100
[2025-08-26 09:26:00,817][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004144] [Batch 00029/00823] [00:00:21/00:09:45, 0.738s/it]: train_loss_raw=1.7733, running_loss=1.8244, LR=0.000100
[2025-08-26 09:26:06,862][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004152] [Batch 00037/00823] [00:00:27/00:09:42, 0.741s/it]: train_loss_raw=1.7424, running_loss=1.8213, LR=0.000100
[2025-08-26 09:26:12,894][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004160] [Batch 00045/00823] [00:00:33/00:09:38, 0.744s/it]: train_loss_raw=1.7534, running_loss=1.8181, LR=0.000100
[2025-08-26 09:26:18,925][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004168] [Batch 00053/00823] [00:00:39/00:09:33, 0.745s/it]: train_loss_raw=1.7280, running_loss=1.8132, LR=0.000100
[2025-08-26 09:26:25,001][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004176] [Batch 00061/00823] [00:00:45/00:09:29, 0.747s/it]: train_loss_raw=1.8096, running_loss=1.8127, LR=0.000100
[2025-08-26 09:26:31,095][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004184] [Batch 00069/00823] [00:00:51/00:09:24, 0.749s/it]: train_loss_raw=1.7842, running_loss=1.8105, LR=0.000100
[2025-08-26 09:26:37,188][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004192] [Batch 00077/00823] [00:00:57/00:09:19, 0.750s/it]: train_loss_raw=1.7137, running_loss=1.8084, LR=0.000100
[2025-08-26 09:26:43,215][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004200] [Batch 00085/00823] [00:01:03/00:09:13, 0.750s/it]: train_loss_raw=1.7462, running_loss=1.8033, LR=0.000100
[2025-08-26 09:26:49,285][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004208] [Batch 00093/00823] [00:01:09/00:09:08, 0.751s/it]: train_loss_raw=1.7429, running_loss=1.7988, LR=0.000100
[2025-08-26 09:26:55,362][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004216] [Batch 00101/00823] [00:01:15/00:09:02, 0.752s/it]: train_loss_raw=1.8071, running_loss=1.7939, LR=0.000100
[2025-08-26 09:27:01,452][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004224] [Batch 00109/00823] [00:01:22/00:08:57, 0.753s/it]: train_loss_raw=1.7318, running_loss=1.7885, LR=0.000100
[2025-08-26 09:27:07,547][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004232] [Batch 00117/00823] [00:01:28/00:08:51, 0.753s/it]: train_loss_raw=1.6992, running_loss=1.7862, LR=0.000100
[2025-08-26 09:27:13,561][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004240] [Batch 00125/00823] [00:01:34/00:08:45, 0.753s/it]: train_loss_raw=1.7603, running_loss=1.7819, LR=0.000100
[2025-08-26 09:27:19,581][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004248] [Batch 00133/00823] [00:01:40/00:08:39, 0.753s/it]: train_loss_raw=1.7359, running_loss=1.7803, LR=0.000100
[2025-08-26 09:27:25,593][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004256] [Batch 00141/00823] [00:01:46/00:08:33, 0.753s/it]: train_loss_raw=1.7164, running_loss=1.7800, LR=0.000100
[2025-08-26 09:27:31,597][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004264] [Batch 00149/00823] [00:01:52/00:08:27, 0.753s/it]: train_loss_raw=1.7026, running_loss=1.7777, LR=0.000100
[2025-08-26 09:27:37,629][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004272] [Batch 00157/00823] [00:01:58/00:08:21, 0.753s/it]: train_loss_raw=1.7776, running_loss=1.7774, LR=0.000100
[2025-08-26 09:27:43,656][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004280] [Batch 00165/00823] [00:02:04/00:08:15, 0.753s/it]: train_loss_raw=1.8095, running_loss=1.7764, LR=0.000100
[2025-08-26 09:27:49,733][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004288] [Batch 00173/00823] [00:02:10/00:08:09, 0.753s/it]: train_loss_raw=1.7749, running_loss=1.7747, LR=0.000100
[2025-08-26 09:27:55,786][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004296] [Batch 00181/00823] [00:02:16/00:08:03, 0.753s/it]: train_loss_raw=1.8179, running_loss=1.7753, LR=0.000100
[2025-08-26 09:28:01,868][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004304] [Batch 00189/00823] [00:02:22/00:07:57, 0.754s/it]: train_loss_raw=1.8106, running_loss=1.7757, LR=0.000100
[2025-08-26 09:28:07,829][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004312] [Batch 00197/00823] [00:02:28/00:07:51, 0.753s/it]: train_loss_raw=1.8114, running_loss=1.7759, LR=0.000100
[2025-08-26 09:28:13,868][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004320] [Batch 00205/00823] [00:02:34/00:07:45, 0.753s/it]: train_loss_raw=1.6473, running_loss=1.7726, LR=0.000100
[2025-08-26 09:28:19,944][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004328] [Batch 00213/00823] [00:02:40/00:07:39, 0.754s/it]: train_loss_raw=1.7273, running_loss=1.7726, LR=0.000100
[2025-08-26 09:28:25,975][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004336] [Batch 00221/00823] [00:02:46/00:07:33, 0.754s/it]: train_loss_raw=1.7418, running_loss=1.7720, LR=0.000100
[2025-08-26 09:28:31,978][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004344] [Batch 00229/00823] [00:02:52/00:07:27, 0.753s/it]: train_loss_raw=1.7486, running_loss=1.7695, LR=0.000100
[2025-08-26 09:28:38,033][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004352] [Batch 00237/00823] [00:02:58/00:07:21, 0.754s/it]: train_loss_raw=1.7273, running_loss=1.7692, LR=0.000100
[2025-08-26 09:28:44,096][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004360] [Batch 00245/00823] [00:03:04/00:07:15, 0.754s/it]: train_loss_raw=1.8643, running_loss=1.7682, LR=0.000100
[2025-08-26 09:28:50,185][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004368] [Batch 00253/00823] [00:03:10/00:07:09, 0.754s/it]: train_loss_raw=1.7085, running_loss=1.7667, LR=0.000100
[2025-08-26 09:28:56,253][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004376] [Batch 00261/00823] [00:03:16/00:07:03, 0.754s/it]: train_loss_raw=1.6802, running_loss=1.7662, LR=0.000100
[2025-08-26 09:29:02,254][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004384] [Batch 00269/00823] [00:03:22/00:06:57, 0.754s/it]: train_loss_raw=1.7433, running_loss=1.7650, LR=0.000100
[2025-08-26 09:29:08,234][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004392] [Batch 00277/00823] [00:03:28/00:06:51, 0.754s/it]: train_loss_raw=1.7161, running_loss=1.7633, LR=0.000100
[2025-08-26 09:29:14,320][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004400] [Batch 00285/00823] [00:03:34/00:06:45, 0.754s/it]: train_loss_raw=1.6906, running_loss=1.7632, LR=0.000100
[2025-08-26 09:29:20,430][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004408] [Batch 00293/00823] [00:03:41/00:06:39, 0.754s/it]: train_loss_raw=1.7760, running_loss=1.7633, LR=0.000100
[2025-08-26 09:29:26,514][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004416] [Batch 00301/00823] [00:03:47/00:06:33, 0.754s/it]: train_loss_raw=1.6927, running_loss=1.7608, LR=0.000100
[2025-08-26 09:29:32,616][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004424] [Batch 00309/00823] [00:03:53/00:06:27, 0.755s/it]: train_loss_raw=1.7879, running_loss=1.7582, LR=0.000100
[2025-08-26 09:29:38,670][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004432] [Batch 00317/00823] [00:03:59/00:06:21, 0.755s/it]: train_loss_raw=1.6870, running_loss=1.7567, LR=0.000100
[2025-08-26 09:29:44,748][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004440] [Batch 00325/00823] [00:04:05/00:06:15, 0.755s/it]: train_loss_raw=1.6835, running_loss=1.7558, LR=0.000100
[2025-08-26 09:29:50,803][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004448] [Batch 00333/00823] [00:04:11/00:06:09, 0.755s/it]: train_loss_raw=1.6858, running_loss=1.7548, LR=0.000100
[2025-08-26 09:29:56,842][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004456] [Batch 00341/00823] [00:04:17/00:06:03, 0.755s/it]: train_loss_raw=1.6993, running_loss=1.7541, LR=0.000100
[2025-08-26 09:30:02,851][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004464] [Batch 00349/00823] [00:04:23/00:05:57, 0.755s/it]: train_loss_raw=1.7861, running_loss=1.7534, LR=0.000100
[2025-08-26 09:30:08,890][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004472] [Batch 00357/00823] [00:04:29/00:05:51, 0.755s/it]: train_loss_raw=1.7752, running_loss=1.7518, LR=0.000100
[2025-08-26 09:30:14,964][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004480] [Batch 00365/00823] [00:04:35/00:05:45, 0.755s/it]: train_loss_raw=1.7643, running_loss=1.7522, LR=0.000100
[2025-08-26 09:30:21,055][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004488] [Batch 00373/00823] [00:04:41/00:05:39, 0.755s/it]: train_loss_raw=1.7533, running_loss=1.7516, LR=0.000100
[2025-08-26 09:30:27,146][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004496] [Batch 00381/00823] [00:04:47/00:05:33, 0.755s/it]: train_loss_raw=1.7470, running_loss=1.7512, LR=0.000100
[2025-08-26 09:30:33,210][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004504] [Batch 00389/00823] [00:04:53/00:05:27, 0.755s/it]: train_loss_raw=1.7388, running_loss=1.7483, LR=0.000100
[2025-08-26 09:30:39,212][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004512] [Batch 00397/00823] [00:04:59/00:05:21, 0.755s/it]: train_loss_raw=1.7776, running_loss=1.7514, LR=0.000100
[2025-08-26 09:30:45,332][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004520] [Batch 00405/00823] [00:05:05/00:05:15, 0.755s/it]: train_loss_raw=1.7388, running_loss=1.7505, LR=0.000100
[2025-08-26 09:30:51,383][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004528] [Batch 00413/00823] [00:05:11/00:05:09, 0.755s/it]: train_loss_raw=1.7780, running_loss=1.7507, LR=0.000100
[2025-08-26 09:30:57,369][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004536] [Batch 00421/00823] [00:05:17/00:05:03, 0.755s/it]: train_loss_raw=1.8013, running_loss=1.7503, LR=0.000100
[2025-08-26 09:31:03,403][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004544] [Batch 00429/00823] [00:05:23/00:04:57, 0.755s/it]: train_loss_raw=1.6629, running_loss=1.7493, LR=0.000100
[2025-08-26 09:31:09,435][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004552] [Batch 00437/00823] [00:05:30/00:04:51, 0.755s/it]: train_loss_raw=1.7045, running_loss=1.7472, LR=0.000100
[2025-08-26 09:31:15,456][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004560] [Batch 00445/00823] [00:05:36/00:04:45, 0.755s/it]: train_loss_raw=1.7556, running_loss=1.7462, LR=0.000100
[2025-08-26 09:31:21,461][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004568] [Batch 00453/00823] [00:05:42/00:04:39, 0.755s/it]: train_loss_raw=1.7693, running_loss=1.7469, LR=0.000100
[2025-08-26 09:31:27,503][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004576] [Batch 00461/00823] [00:05:48/00:04:33, 0.755s/it]: train_loss_raw=1.7242, running_loss=1.7425, LR=0.000100
[2025-08-26 09:31:33,594][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004584] [Batch 00469/00823] [00:05:54/00:04:27, 0.755s/it]: train_loss_raw=1.7562, running_loss=1.7440, LR=0.000100
[2025-08-26 09:31:39,635][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004592] [Batch 00477/00823] [00:06:00/00:04:21, 0.755s/it]: train_loss_raw=1.7365, running_loss=1.7425, LR=0.000100
[2025-08-26 09:31:45,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004600] [Batch 00485/00823] [00:06:06/00:04:15, 0.755s/it]: train_loss_raw=1.7440, running_loss=1.7420, LR=0.000100
[2025-08-26 09:31:51,820][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004608] [Batch 00493/00823] [00:06:12/00:04:09, 0.755s/it]: train_loss_raw=1.7873, running_loss=1.7411, LR=0.000100
[2025-08-26 09:31:57,913][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004616] [Batch 00501/00823] [00:06:18/00:04:03, 0.755s/it]: train_loss_raw=1.7121, running_loss=1.7386, LR=0.000100
[2025-08-26 09:32:03,963][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004624] [Batch 00509/00823] [00:06:24/00:03:57, 0.755s/it]: train_loss_raw=1.7163, running_loss=1.7359, LR=0.000100
[2025-08-26 09:32:10,103][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004632] [Batch 00517/00823] [00:06:30/00:03:51, 0.756s/it]: train_loss_raw=1.7348, running_loss=1.7387, LR=0.000100
[2025-08-26 09:32:16,136][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004640] [Batch 00525/00823] [00:06:36/00:03:45, 0.756s/it]: train_loss_raw=1.7562, running_loss=1.7388, LR=0.000100
[2025-08-26 09:32:21,728][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004648] [Batch 00533/00823] [00:06:42/00:03:38, 0.755s/it]: train_loss_raw=1.6615, running_loss=1.7399, LR=0.000100
[2025-08-26 09:32:27,283][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004656] [Batch 00541/00823] [00:06:47/00:03:32, 0.754s/it]: train_loss_raw=1.7927, running_loss=1.7396, LR=0.000100
[2025-08-26 09:32:33,269][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004664] [Batch 00549/00823] [00:06:53/00:03:26, 0.754s/it]: train_loss_raw=1.7383, running_loss=1.7392, LR=0.000100
[2025-08-26 09:32:39,306][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004672] [Batch 00557/00823] [00:06:59/00:03:20, 0.754s/it]: train_loss_raw=1.7116, running_loss=1.7383, LR=0.000100
[2025-08-26 09:32:45,405][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004680] [Batch 00565/00823] [00:07:05/00:03:14, 0.754s/it]: train_loss_raw=1.7444, running_loss=1.7379, LR=0.000100
[2025-08-26 09:32:51,476][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004688] [Batch 00573/00823] [00:07:12/00:03:08, 0.754s/it]: train_loss_raw=1.7055, running_loss=1.7364, LR=0.000100
[2025-08-26 09:32:57,526][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004696] [Batch 00581/00823] [00:07:18/00:03:02, 0.754s/it]: train_loss_raw=1.7083, running_loss=1.7346, LR=0.000100
[2025-08-26 09:33:03,592][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004704] [Batch 00589/00823] [00:07:24/00:02:56, 0.754s/it]: train_loss_raw=1.6760, running_loss=1.7311, LR=0.000100
[2025-08-26 09:33:09,677][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004712] [Batch 00597/00823] [00:07:30/00:02:50, 0.754s/it]: train_loss_raw=1.7299, running_loss=1.7297, LR=0.000100
[2025-08-26 09:33:15,804][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004720] [Batch 00605/00823] [00:07:36/00:02:44, 0.754s/it]: train_loss_raw=1.6714, running_loss=1.7277, LR=0.000100
[2025-08-26 09:33:21,879][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004728] [Batch 00613/00823] [00:07:42/00:02:38, 0.754s/it]: train_loss_raw=1.7341, running_loss=1.7282, LR=0.000100
[2025-08-26 09:33:27,932][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004736] [Batch 00621/00823] [00:07:48/00:02:32, 0.754s/it]: train_loss_raw=1.7640, running_loss=1.7286, LR=0.000100
[2025-08-26 09:33:33,996][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004744] [Batch 00629/00823] [00:07:54/00:02:26, 0.754s/it]: train_loss_raw=1.7392, running_loss=1.7285, LR=0.000100
[2025-08-26 09:33:40,054][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004752] [Batch 00637/00823] [00:08:00/00:02:20, 0.755s/it]: train_loss_raw=1.7222, running_loss=1.7273, LR=0.000100
[2025-08-26 09:33:46,100][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004760] [Batch 00645/00823] [00:08:06/00:02:14, 0.755s/it]: train_loss_raw=1.6619, running_loss=1.7276, LR=0.000100
[2025-08-26 09:33:52,114][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004768] [Batch 00653/00823] [00:08:12/00:02:08, 0.754s/it]: train_loss_raw=1.7298, running_loss=1.7255, LR=0.000100
[2025-08-26 09:33:58,202][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004776] [Batch 00661/00823] [00:08:18/00:02:02, 0.755s/it]: train_loss_raw=1.6275, running_loss=1.7238, LR=0.000100
[2025-08-26 09:34:04,277][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004784] [Batch 00669/00823] [00:08:24/00:01:56, 0.755s/it]: train_loss_raw=1.7041, running_loss=1.7214, LR=0.000100
[2025-08-26 09:34:10,407][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004792] [Batch 00677/00823] [00:08:30/00:01:50, 0.755s/it]: train_loss_raw=1.6542, running_loss=1.7247, LR=0.000100
[2025-08-26 09:34:16,460][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004800] [Batch 00685/00823] [00:08:37/00:01:44, 0.755s/it]: train_loss_raw=1.6449, running_loss=1.7229, LR=0.000100
[2025-08-26 09:34:22,478][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004808] [Batch 00693/00823] [00:08:43/00:01:38, 0.755s/it]: train_loss_raw=1.7616, running_loss=1.7231, LR=0.000100
[2025-08-26 09:34:28,565][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004816] [Batch 00701/00823] [00:08:49/00:01:32, 0.755s/it]: train_loss_raw=1.7167, running_loss=1.7245, LR=0.000100
[2025-08-26 09:34:34,615][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004824] [Batch 00709/00823] [00:08:55/00:01:26, 0.755s/it]: train_loss_raw=1.7899, running_loss=1.7266, LR=0.000100
[2025-08-26 09:34:40,741][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004832] [Batch 00717/00823] [00:09:01/00:01:20, 0.755s/it]: train_loss_raw=1.7669, running_loss=1.7260, LR=0.000100
[2025-08-26 09:34:46,926][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004840] [Batch 00725/00823] [00:09:07/00:01:14, 0.755s/it]: train_loss_raw=1.6976, running_loss=1.7244, LR=0.000100
[2025-08-26 09:34:53,080][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004848] [Batch 00733/00823] [00:09:13/00:01:07, 0.755s/it]: train_loss_raw=1.6854, running_loss=1.7254, LR=0.000100
[2025-08-26 09:34:59,129][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004856] [Batch 00741/00823] [00:09:19/00:01:01, 0.755s/it]: train_loss_raw=1.6960, running_loss=1.7261, LR=0.000100
[2025-08-26 09:35:05,180][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004864] [Batch 00749/00823] [00:09:25/00:00:55, 0.755s/it]: train_loss_raw=1.6614, running_loss=1.7262, LR=0.000100
[2025-08-26 09:35:11,200][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004872] [Batch 00757/00823] [00:09:31/00:00:49, 0.755s/it]: train_loss_raw=1.6952, running_loss=1.7251, LR=0.000100
[2025-08-26 09:35:17,195][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004880] [Batch 00765/00823] [00:09:37/00:00:43, 0.755s/it]: train_loss_raw=1.7462, running_loss=1.7244, LR=0.000100
[2025-08-26 09:35:23,239][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004888] [Batch 00773/00823] [00:09:43/00:00:37, 0.755s/it]: train_loss_raw=1.6757, running_loss=1.7220, LR=0.000100
[2025-08-26 09:35:29,303][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004896] [Batch 00781/00823] [00:09:49/00:00:31, 0.755s/it]: train_loss_raw=1.8026, running_loss=1.7204, LR=0.000100
[2025-08-26 09:35:35,368][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004904] [Batch 00789/00823] [00:09:55/00:00:25, 0.755s/it]: train_loss_raw=1.7300, running_loss=1.7193, LR=0.000100
[2025-08-26 09:35:41,426][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004912] [Batch 00797/00823] [00:10:01/00:00:19, 0.755s/it]: train_loss_raw=1.7601, running_loss=1.7198, LR=0.000100
[2025-08-26 09:35:47,482][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004920] [Batch 00805/00823] [00:10:08/00:00:13, 0.755s/it]: train_loss_raw=1.7566, running_loss=1.7223, LR=0.000100
[2025-08-26 09:35:53,483][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004928] [Batch 00813/00823] [00:10:14/00:00:07, 0.755s/it]: train_loss_raw=1.6404, running_loss=1.7214, LR=0.000100
[2025-08-26 09:35:59,513][__main__][INFO] - [TRAIN] [Epoch 05/29 Step 004936] [Batch 00821/00823] [00:10:20/00:00:01, 0.755s/it]: train_loss_raw=1.6910, running_loss=1.7216, LR=0.000100
[2025-08-26 09:36:07,534][__main__][INFO] - [VALIDATION] [Epoch 05/29] Starting validation.
[2025-08-26 09:36:18,549][__main__][INFO] - [VALIDATION] [Epoch 05/29 Step 004939] [Batch 00007/00013] [00:00:11/00:00:06, 1.377s/it]
[2025-08-26 09:36:25,835][__main__][INFO] - [VALIDATION] [Epoch 05/29] train_loss=1.72088, valid_loss=1.74774
[2025-08-26 09:36:25,835][__main__][INFO] - [VALIDATION] [Epoch 05/29] Metrics:
[2025-08-26 09:36:25,835][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_er      0.734
[2025-08-26 09:36:25,835][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_prec    0.030
[2025-08-26 09:36:25,835][__main__][INFO] - [VALIDATION] [Epoch 05/29] - aa_recall  0.032
[2025-08-26 09:36:25,835][__main__][INFO] - [VALIDATION] [Epoch 05/29] - pep_recall 0.003
[2025-08-26 09:36:25,837][__main__][INFO] - [TRAIN] [Epoch 05/29] Epoch complete, total time 01:03:49, remaining time 04:15:18, 00:10:38 per epoch
[2025-08-26 09:36:30,880][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004944] [Batch 00006/00823] [00:00:03/00:09:00, 0.661s/it]: train_loss_raw=1.6613, running_loss=1.7726, LR=0.000100
[2025-08-26 09:36:37,017][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004952] [Batch 00014/00823] [00:00:10/00:09:43, 0.722s/it]: train_loss_raw=1.7321, running_loss=1.7674, LR=0.000100
[2025-08-26 09:36:43,070][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004960] [Batch 00022/00823] [00:00:16/00:09:48, 0.734s/it]: train_loss_raw=1.6720, running_loss=1.7628, LR=0.000100
[2025-08-26 09:36:49,119][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004968] [Batch 00030/00823] [00:00:22/00:09:46, 0.740s/it]: train_loss_raw=1.6769, running_loss=1.7580, LR=0.000100
[2025-08-26 09:36:55,009][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004976] [Batch 00038/00823] [00:00:28/00:09:40, 0.739s/it]: train_loss_raw=1.7918, running_loss=1.7537, LR=0.000100
[2025-08-26 09:37:01,008][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004984] [Batch 00046/00823] [00:00:34/00:09:35, 0.741s/it]: train_loss_raw=1.7330, running_loss=1.7500, LR=0.000100
[2025-08-26 09:37:07,061][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 004992] [Batch 00054/00823] [00:00:40/00:09:31, 0.743s/it]: train_loss_raw=1.6625, running_loss=1.7441, LR=0.000100
[2025-08-26 09:37:13,133][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005000] [Batch 00062/00823] [00:00:46/00:09:27, 0.745s/it]: train_loss_raw=1.6375, running_loss=1.7382, LR=0.000100
[2025-08-26 09:37:19,231][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005008] [Batch 00070/00823] [00:00:52/00:09:22, 0.747s/it]: train_loss_raw=1.6343, running_loss=1.7312, LR=0.000100
[2025-08-26 09:37:25,268][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005016] [Batch 00078/00823] [00:00:58/00:09:17, 0.748s/it]: train_loss_raw=1.6299, running_loss=1.7258, LR=0.000100
[2025-08-26 09:37:31,279][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005024] [Batch 00086/00823] [00:01:04/00:09:11, 0.748s/it]: train_loss_raw=1.6668, running_loss=1.7238, LR=0.000100
[2025-08-26 09:37:37,359][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005032] [Batch 00094/00823] [00:01:10/00:09:06, 0.749s/it]: train_loss_raw=1.7120, running_loss=1.7227, LR=0.000100
[2025-08-26 09:37:43,414][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005040] [Batch 00102/00823] [00:01:16/00:09:00, 0.750s/it]: train_loss_raw=1.7046, running_loss=1.7204, LR=0.000100
[2025-08-26 09:37:49,453][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005048] [Batch 00110/00823] [00:01:22/00:08:55, 0.750s/it]: train_loss_raw=1.8034, running_loss=1.7212, LR=0.000100
[2025-08-26 09:37:55,401][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005056] [Batch 00118/00823] [00:01:28/00:08:48, 0.750s/it]: train_loss_raw=1.7383, running_loss=1.7201, LR=0.000100
[2025-08-26 09:38:01,408][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005064] [Batch 00126/00823] [00:01:34/00:08:42, 0.750s/it]: train_loss_raw=1.7608, running_loss=1.7192, LR=0.000100
[2025-08-26 09:38:07,438][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005072] [Batch 00134/00823] [00:01:40/00:08:36, 0.750s/it]: train_loss_raw=1.7826, running_loss=1.7160, LR=0.000100
[2025-08-26 09:38:13,465][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005080] [Batch 00142/00823] [00:01:46/00:08:30, 0.750s/it]: train_loss_raw=1.7176, running_loss=1.7142, LR=0.000100
[2025-08-26 09:38:19,547][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005088] [Batch 00150/00823] [00:01:52/00:08:25, 0.751s/it]: train_loss_raw=1.6961, running_loss=1.7124, LR=0.000100
[2025-08-26 09:38:25,553][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005096] [Batch 00158/00823] [00:01:58/00:08:19, 0.751s/it]: train_loss_raw=1.6835, running_loss=1.7088, LR=0.000100
[2025-08-26 09:38:31,551][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005104] [Batch 00166/00823] [00:02:04/00:08:13, 0.751s/it]: train_loss_raw=1.7900, running_loss=1.7100, LR=0.000100
[2025-08-26 09:38:37,581][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005112] [Batch 00174/00823] [00:02:10/00:08:07, 0.751s/it]: train_loss_raw=1.6766, running_loss=1.7042, LR=0.000100
[2025-08-26 09:38:43,658][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005120] [Batch 00182/00823] [00:02:16/00:08:01, 0.751s/it]: train_loss_raw=1.6942, running_loss=1.7025, LR=0.000100
[2025-08-26 09:38:49,764][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005128] [Batch 00190/00823] [00:02:22/00:07:55, 0.752s/it]: train_loss_raw=1.6914, running_loss=1.7000, LR=0.000100
[2025-08-26 09:38:55,888][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005136] [Batch 00198/00823] [00:02:28/00:07:50, 0.752s/it]: train_loss_raw=1.6921, running_loss=1.6991, LR=0.000100
[2025-08-26 09:39:01,907][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005144] [Batch 00206/00823] [00:02:34/00:07:44, 0.752s/it]: train_loss_raw=1.7111, running_loss=1.6998, LR=0.000100
[2025-08-26 09:39:07,972][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005152] [Batch 00214/00823] [00:02:41/00:07:38, 0.753s/it]: train_loss_raw=1.6406, running_loss=1.6997, LR=0.000100
[2025-08-26 09:39:14,053][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005160] [Batch 00222/00823] [00:02:47/00:07:32, 0.753s/it]: train_loss_raw=1.6477, running_loss=1.6979, LR=0.000100
[2025-08-26 09:39:20,183][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005168] [Batch 00230/00823] [00:02:53/00:07:26, 0.753s/it]: train_loss_raw=1.7930, running_loss=1.6969, LR=0.000100
[2025-08-26 09:39:26,204][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005176] [Batch 00238/00823] [00:02:59/00:07:20, 0.753s/it]: train_loss_raw=1.7385, running_loss=1.6979, LR=0.000100
[2025-08-26 09:39:32,312][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005184] [Batch 00246/00823] [00:03:05/00:07:14, 0.754s/it]: train_loss_raw=1.6729, running_loss=1.6969, LR=0.000100
[2025-08-26 09:39:38,375][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005192] [Batch 00254/00823] [00:03:11/00:07:08, 0.754s/it]: train_loss_raw=1.6293, running_loss=1.6952, LR=0.000100
[2025-08-26 09:39:44,437][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005200] [Batch 00262/00823] [00:03:17/00:07:02, 0.754s/it]: train_loss_raw=1.6700, running_loss=1.6936, LR=0.000100
[2025-08-26 09:39:50,449][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005208] [Batch 00270/00823] [00:03:23/00:06:56, 0.754s/it]: train_loss_raw=1.7349, running_loss=1.6941, LR=0.000100
[2025-08-26 09:39:56,425][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005216] [Batch 00278/00823] [00:03:29/00:06:50, 0.754s/it]: train_loss_raw=1.6955, running_loss=1.6929, LR=0.000100
[2025-08-26 09:40:02,466][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005224] [Batch 00286/00823] [00:03:35/00:06:44, 0.754s/it]: train_loss_raw=1.7531, running_loss=1.6923, LR=0.000100
[2025-08-26 09:40:08,523][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005232] [Batch 00294/00823] [00:03:41/00:06:38, 0.754s/it]: train_loss_raw=1.6905, running_loss=1.6908, LR=0.000100
[2025-08-26 09:40:14,627][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005240] [Batch 00302/00823] [00:03:47/00:06:32, 0.754s/it]: train_loss_raw=1.8185, running_loss=1.6904, LR=0.000100
[2025-08-26 09:40:20,727][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005248] [Batch 00310/00823] [00:03:53/00:06:26, 0.754s/it]: train_loss_raw=1.6400, running_loss=1.6894, LR=0.000100
[2025-08-26 09:40:26,786][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005256] [Batch 00318/00823] [00:03:59/00:06:20, 0.754s/it]: train_loss_raw=1.7653, running_loss=1.6895, LR=0.000100
[2025-08-26 09:40:32,884][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005264] [Batch 00326/00823] [00:04:05/00:06:14, 0.755s/it]: train_loss_raw=1.7284, running_loss=1.6874, LR=0.000100
[2025-08-26 09:40:38,995][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005272] [Batch 00334/00823] [00:04:12/00:06:09, 0.755s/it]: train_loss_raw=1.6972, running_loss=1.6869, LR=0.000100
[2025-08-26 09:40:45,052][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005280] [Batch 00342/00823] [00:04:18/00:06:03, 0.755s/it]: train_loss_raw=1.7596, running_loss=1.6883, LR=0.000100
[2025-08-26 09:40:51,494][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005288] [Batch 00350/00823] [00:04:24/00:05:57, 0.756s/it]: train_loss_raw=1.6793, running_loss=1.6868, LR=0.000100
[2025-08-26 09:40:57,580][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005296] [Batch 00358/00823] [00:04:30/00:05:51, 0.756s/it]: train_loss_raw=1.5959, running_loss=1.6812, LR=0.000100
[2025-08-26 09:41:03,620][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005304] [Batch 00366/00823] [00:04:36/00:05:45, 0.756s/it]: train_loss_raw=1.5824, running_loss=1.6802, LR=0.000100
[2025-08-26 09:41:09,670][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005312] [Batch 00374/00823] [00:04:42/00:05:39, 0.756s/it]: train_loss_raw=1.6439, running_loss=1.6792, LR=0.000100
[2025-08-26 09:41:15,691][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005320] [Batch 00382/00823] [00:04:48/00:05:33, 0.756s/it]: train_loss_raw=1.6561, running_loss=1.6783, LR=0.000100
[2025-08-26 09:41:21,719][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005328] [Batch 00390/00823] [00:04:54/00:05:27, 0.756s/it]: train_loss_raw=1.6179, running_loss=1.6787, LR=0.000100
[2025-08-26 09:41:27,781][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005336] [Batch 00398/00823] [00:05:00/00:05:21, 0.756s/it]: train_loss_raw=1.7149, running_loss=1.6793, LR=0.000100
[2025-08-26 09:41:33,871][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005344] [Batch 00406/00823] [00:05:06/00:05:15, 0.756s/it]: train_loss_raw=1.7188, running_loss=1.6802, LR=0.000100
[2025-08-26 09:41:39,897][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005352] [Batch 00414/00823] [00:05:12/00:05:09, 0.756s/it]: train_loss_raw=1.7142, running_loss=1.6804, LR=0.000100
[2025-08-26 09:41:45,947][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005360] [Batch 00422/00823] [00:05:19/00:05:03, 0.756s/it]: train_loss_raw=1.6320, running_loss=1.6827, LR=0.000100
[2025-08-26 09:41:51,998][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005368] [Batch 00430/00823] [00:05:25/00:04:57, 0.756s/it]: train_loss_raw=1.6765, running_loss=1.6807, LR=0.000100
[2025-08-26 09:41:58,124][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005376] [Batch 00438/00823] [00:05:31/00:04:51, 0.756s/it]: train_loss_raw=1.6883, running_loss=1.6813, LR=0.000100
[2025-08-26 09:42:04,189][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005384] [Batch 00446/00823] [00:05:37/00:04:45, 0.756s/it]: train_loss_raw=1.6446, running_loss=1.6782, LR=0.000100
[2025-08-26 09:42:10,288][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005392] [Batch 00454/00823] [00:05:43/00:04:39, 0.756s/it]: train_loss_raw=1.6582, running_loss=1.6789, LR=0.000100
[2025-08-26 09:42:16,377][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005400] [Batch 00462/00823] [00:05:49/00:04:33, 0.756s/it]: train_loss_raw=1.6916, running_loss=1.6783, LR=0.000100
[2025-08-26 09:42:22,421][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005408] [Batch 00470/00823] [00:05:55/00:04:27, 0.756s/it]: train_loss_raw=1.7342, running_loss=1.6798, LR=0.000100
[2025-08-26 09:42:28,539][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005416] [Batch 00478/00823] [00:06:01/00:04:21, 0.757s/it]: train_loss_raw=1.6547, running_loss=1.6793, LR=0.000100
[2025-08-26 09:42:34,582][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005424] [Batch 00486/00823] [00:06:07/00:04:14, 0.757s/it]: train_loss_raw=1.5862, running_loss=1.6770, LR=0.000100
[2025-08-26 09:42:40,561][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005432] [Batch 00494/00823] [00:06:13/00:04:08, 0.756s/it]: train_loss_raw=1.7719, running_loss=1.6775, LR=0.000100
[2025-08-26 09:42:46,533][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005440] [Batch 00502/00823] [00:06:19/00:04:02, 0.756s/it]: train_loss_raw=1.7205, running_loss=1.6756, LR=0.000100
[2025-08-26 09:42:52,696][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005448] [Batch 00510/00823] [00:06:25/00:03:56, 0.756s/it]: train_loss_raw=1.7175, running_loss=1.6752, LR=0.000100
[2025-08-26 09:42:58,760][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005456] [Batch 00518/00823] [00:06:31/00:03:50, 0.756s/it]: train_loss_raw=1.7037, running_loss=1.6763, LR=0.000100
[2025-08-26 09:43:04,844][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005464] [Batch 00526/00823] [00:06:37/00:03:44, 0.757s/it]: train_loss_raw=1.6228, running_loss=1.6759, LR=0.000100
[2025-08-26 09:43:11,118][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005472] [Batch 00534/00823] [00:06:44/00:03:38, 0.757s/it]: train_loss_raw=1.6326, running_loss=1.6776, LR=0.000100
[2025-08-26 09:43:17,161][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005480] [Batch 00542/00823] [00:06:50/00:03:32, 0.757s/it]: train_loss_raw=1.5364, running_loss=1.6749, LR=0.000100
[2025-08-26 09:43:23,156][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005488] [Batch 00550/00823] [00:06:56/00:03:26, 0.757s/it]: train_loss_raw=1.6478, running_loss=1.6753, LR=0.000100
[2025-08-26 09:43:29,136][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005496] [Batch 00558/00823] [00:07:02/00:03:20, 0.757s/it]: train_loss_raw=1.6208, running_loss=1.6766, LR=0.000100
[2025-08-26 09:43:35,120][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005504] [Batch 00566/00823] [00:07:08/00:03:14, 0.757s/it]: train_loss_raw=1.7584, running_loss=1.6740, LR=0.000100
[2025-08-26 09:43:41,175][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005512] [Batch 00574/00823] [00:07:14/00:03:08, 0.757s/it]: train_loss_raw=1.7070, running_loss=1.6750, LR=0.000100
[2025-08-26 09:43:47,250][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005520] [Batch 00582/00823] [00:07:20/00:03:02, 0.757s/it]: train_loss_raw=1.6019, running_loss=1.6719, LR=0.000100
[2025-08-26 09:43:53,290][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005528] [Batch 00590/00823] [00:07:26/00:02:56, 0.757s/it]: train_loss_raw=1.5718, running_loss=1.6711, LR=0.000100
[2025-08-26 09:43:59,349][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005536] [Batch 00598/00823] [00:07:32/00:02:50, 0.757s/it]: train_loss_raw=1.5542, running_loss=1.6700, LR=0.000100
[2025-08-26 09:44:05,413][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005544] [Batch 00606/00823] [00:07:38/00:02:44, 0.757s/it]: train_loss_raw=1.6641, running_loss=1.6699, LR=0.000100
[2025-08-26 09:44:11,450][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005552] [Batch 00614/00823] [00:07:44/00:02:38, 0.757s/it]: train_loss_raw=1.6172, running_loss=1.6682, LR=0.000100
[2025-08-26 09:44:17,452][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005560] [Batch 00622/00823] [00:07:50/00:02:32, 0.756s/it]: train_loss_raw=1.6442, running_loss=1.6639, LR=0.000100
[2025-08-26 09:44:23,561][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005568] [Batch 00630/00823] [00:07:56/00:02:26, 0.757s/it]: train_loss_raw=1.6779, running_loss=1.6634, LR=0.000100
[2025-08-26 09:44:29,653][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005576] [Batch 00638/00823] [00:08:02/00:02:19, 0.757s/it]: train_loss_raw=1.6631, running_loss=1.6656, LR=0.000100
[2025-08-26 09:44:35,720][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005584] [Batch 00646/00823] [00:08:08/00:02:13, 0.757s/it]: train_loss_raw=1.6968, running_loss=1.6659, LR=0.000100
[2025-08-26 09:44:41,739][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005592] [Batch 00654/00823] [00:08:14/00:02:07, 0.757s/it]: train_loss_raw=1.5636, running_loss=1.6650, LR=0.000100
[2025-08-26 09:44:47,804][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005600] [Batch 00662/00823] [00:08:20/00:02:01, 0.757s/it]: train_loss_raw=1.6404, running_loss=1.6631, LR=0.000100
[2025-08-26 09:44:53,893][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005608] [Batch 00670/00823] [00:08:26/00:01:55, 0.757s/it]: train_loss_raw=1.6500, running_loss=1.6635, LR=0.000100
[2025-08-26 09:44:59,943][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005616] [Batch 00678/00823] [00:08:33/00:01:49, 0.757s/it]: train_loss_raw=1.5869, running_loss=1.6647, LR=0.000100
[2025-08-26 09:45:06,019][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005624] [Batch 00686/00823] [00:08:39/00:01:43, 0.757s/it]: train_loss_raw=1.6663, running_loss=1.6655, LR=0.000100
[2025-08-26 09:45:12,062][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005632] [Batch 00694/00823] [00:08:45/00:01:37, 0.757s/it]: train_loss_raw=1.7362, running_loss=1.6656, LR=0.000100
[2025-08-26 09:45:17,959][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005640] [Batch 00702/00823] [00:08:51/00:01:31, 0.756s/it]: train_loss_raw=1.7317, running_loss=1.6682, LR=0.000100
[2025-08-26 09:45:23,960][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005648] [Batch 00710/00823] [00:08:57/00:01:25, 0.756s/it]: train_loss_raw=1.7154, running_loss=1.6717, LR=0.000100
[2025-08-26 09:45:29,945][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005656] [Batch 00718/00823] [00:09:03/00:01:19, 0.756s/it]: train_loss_raw=1.7481, running_loss=1.6705, LR=0.000100
[2025-08-26 09:45:35,990][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005664] [Batch 00726/00823] [00:09:09/00:01:13, 0.756s/it]: train_loss_raw=1.7200, running_loss=1.6702, LR=0.000100
[2025-08-26 09:45:42,021][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005672] [Batch 00734/00823] [00:09:15/00:01:07, 0.756s/it]: train_loss_raw=1.6258, running_loss=1.6692, LR=0.000100
[2025-08-26 09:45:48,038][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005680] [Batch 00742/00823] [00:09:21/00:01:01, 0.756s/it]: train_loss_raw=1.6620, running_loss=1.6693, LR=0.000100
[2025-08-26 09:45:54,107][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005688] [Batch 00750/00823] [00:09:27/00:00:55, 0.756s/it]: train_loss_raw=1.6238, running_loss=1.6671, LR=0.000100
[2025-08-26 09:46:00,148][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005696] [Batch 00758/00823] [00:09:33/00:00:49, 0.756s/it]: train_loss_raw=1.5508, running_loss=1.6667, LR=0.000100
[2025-08-26 09:46:06,312][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005704] [Batch 00766/00823] [00:09:39/00:00:43, 0.756s/it]: train_loss_raw=1.6234, running_loss=1.6635, LR=0.000100
[2025-08-26 09:46:12,556][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005712] [Batch 00774/00823] [00:09:45/00:00:37, 0.757s/it]: train_loss_raw=1.6427, running_loss=1.6626, LR=0.000100
[2025-08-26 09:46:18,692][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005720] [Batch 00782/00823] [00:09:51/00:00:31, 0.757s/it]: train_loss_raw=1.6465, running_loss=1.6623, LR=0.000100
[2025-08-26 09:46:24,850][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005728] [Batch 00790/00823] [00:09:57/00:00:24, 0.757s/it]: train_loss_raw=1.6418, running_loss=1.6645, LR=0.000100
[2025-08-26 09:46:30,876][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005736] [Batch 00798/00823] [00:10:03/00:00:18, 0.757s/it]: train_loss_raw=1.6720, running_loss=1.6651, LR=0.000100
[2025-08-26 09:46:36,958][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005744] [Batch 00806/00823] [00:10:10/00:00:12, 0.757s/it]: train_loss_raw=1.6183, running_loss=1.6641, LR=0.000100
[2025-08-26 09:46:43,007][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005752] [Batch 00814/00823] [00:10:16/00:00:06, 0.757s/it]: train_loss_raw=1.6978, running_loss=1.6626, LR=0.000100
[2025-08-26 09:46:49,080][__main__][INFO] - [TRAIN] [Epoch 06/29 Step 005760] [Batch 00822/00823] [00:10:22/00:00:00, 0.757s/it]: train_loss_raw=1.6269, running_loss=1.6621, LR=0.000100
[2025-08-26 09:46:50,025][__main__][INFO] - [VALIDATION] [Epoch 06/29] Starting validation.
[2025-08-26 09:47:00,752][__main__][INFO] - [VALIDATION] [Epoch 06/29 Step 005762] [Batch 00007/00013] [00:00:10/00:00:06, 1.341s/it]
[2025-08-26 09:47:08,223][__main__][INFO] - [VALIDATION] [Epoch 06/29] train_loss=1.66104, valid_loss=1.68978
[2025-08-26 09:47:08,224][__main__][INFO] - [VALIDATION] [Epoch 06/29] Metrics:
[2025-08-26 09:47:08,224][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_er      0.714
[2025-08-26 09:47:08,224][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_prec    0.028
[2025-08-26 09:47:08,224][__main__][INFO] - [VALIDATION] [Epoch 06/29] - aa_recall  0.029
[2025-08-26 09:47:08,224][__main__][INFO] - [VALIDATION] [Epoch 06/29] - pep_recall 0.002
[2025-08-26 09:47:08,226][__main__][INFO] - [TRAIN] [Epoch 06/29] Epoch complete, total time 01:14:31, remaining time 04:04:53, 00:10:38 per epoch
[2025-08-26 09:47:14,344][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005768] [Batch 00007/00823] [00:00:04/00:09:09, 0.674s/it]: train_loss_raw=1.6425, running_loss=1.6702, LR=0.000100
[2025-08-26 09:47:20,319][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005776] [Batch 00015/00823] [00:00:10/00:09:35, 0.713s/it]: train_loss_raw=1.6685, running_loss=1.6701, LR=0.000100
[2025-08-26 09:47:26,274][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005784] [Batch 00023/00823] [00:00:16/00:09:39, 0.724s/it]: train_loss_raw=1.7142, running_loss=1.6701, LR=0.000100
[2025-08-26 09:47:32,288][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005792] [Batch 00031/00823] [00:00:22/00:09:38, 0.731s/it]: train_loss_raw=1.6689, running_loss=1.6717, LR=0.000100
[2025-08-26 09:47:38,369][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005800] [Batch 00039/00823] [00:00:28/00:09:37, 0.737s/it]: train_loss_raw=1.5759, running_loss=1.6664, LR=0.000100
[2025-08-26 09:47:44,399][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005808] [Batch 00047/00823] [00:00:34/00:09:34, 0.740s/it]: train_loss_raw=1.6345, running_loss=1.6664, LR=0.000100
[2025-08-26 09:47:50,386][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005816] [Batch 00055/00823] [00:00:40/00:09:29, 0.741s/it]: train_loss_raw=1.6281, running_loss=1.6640, LR=0.000100
[2025-08-26 09:47:56,435][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005824] [Batch 00063/00823] [00:00:46/00:09:24, 0.743s/it]: train_loss_raw=1.6371, running_loss=1.6632, LR=0.000100
[2025-08-26 09:48:02,522][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005832] [Batch 00071/00823] [00:00:52/00:09:20, 0.745s/it]: train_loss_raw=1.6924, running_loss=1.6634, LR=0.000100
[2025-08-26 09:48:08,557][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005840] [Batch 00079/00823] [00:00:58/00:09:14, 0.746s/it]: train_loss_raw=1.6207, running_loss=1.6629, LR=0.000100
[2025-08-26 09:48:14,630][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005848] [Batch 00087/00823] [00:01:05/00:09:09, 0.747s/it]: train_loss_raw=1.6911, running_loss=1.6614, LR=0.000100
[2025-08-26 09:48:20,718][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005856] [Batch 00095/00823] [00:01:11/00:09:04, 0.748s/it]: train_loss_raw=1.5689, running_loss=1.6577, LR=0.000100
[2025-08-26 09:48:26,763][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005864] [Batch 00103/00823] [00:01:17/00:08:59, 0.749s/it]: train_loss_raw=1.5927, running_loss=1.6583, LR=0.000100
[2025-08-26 09:48:32,764][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005872] [Batch 00111/00823] [00:01:23/00:08:53, 0.749s/it]: train_loss_raw=1.6198, running_loss=1.6575, LR=0.000100
[2025-08-26 09:48:38,792][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005880] [Batch 00119/00823] [00:01:29/00:08:47, 0.749s/it]: train_loss_raw=1.6254, running_loss=1.6581, LR=0.000100
[2025-08-26 09:48:44,860][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005888] [Batch 00127/00823] [00:01:35/00:08:41, 0.750s/it]: train_loss_raw=1.7293, running_loss=1.6584, LR=0.000100
[2025-08-26 09:48:50,932][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005896] [Batch 00135/00823] [00:01:41/00:08:36, 0.750s/it]: train_loss_raw=1.6744, running_loss=1.6579, LR=0.000100
[2025-08-26 09:48:56,959][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005904] [Batch 00143/00823] [00:01:47/00:08:30, 0.751s/it]: train_loss_raw=1.5849, running_loss=1.6562, LR=0.000100
[2025-08-26 09:49:02,960][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005912] [Batch 00151/00823] [00:01:53/00:08:24, 0.751s/it]: train_loss_raw=1.6512, running_loss=1.6556, LR=0.000100
[2025-08-26 09:49:09,010][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005920] [Batch 00159/00823] [00:01:59/00:08:18, 0.751s/it]: train_loss_raw=1.6762, running_loss=1.6569, LR=0.000100
[2025-08-26 09:49:15,039][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005928] [Batch 00167/00823] [00:02:05/00:08:12, 0.751s/it]: train_loss_raw=1.7196, running_loss=1.6559, LR=0.000100
[2025-08-26 09:49:21,204][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005936] [Batch 00175/00823] [00:02:11/00:08:07, 0.752s/it]: train_loss_raw=1.7161, running_loss=1.6554, LR=0.000100
[2025-08-26 09:49:27,208][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005944] [Batch 00183/00823] [00:02:17/00:08:01, 0.752s/it]: train_loss_raw=1.6534, running_loss=1.6578, LR=0.000100
[2025-08-26 09:49:33,299][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005952] [Batch 00191/00823] [00:02:23/00:07:55, 0.752s/it]: train_loss_raw=1.6818, running_loss=1.6583, LR=0.000100
[2025-08-26 09:49:39,386][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005960] [Batch 00199/00823] [00:02:29/00:07:49, 0.753s/it]: train_loss_raw=1.7004, running_loss=1.6619, LR=0.000100
[2025-08-26 09:49:45,525][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005968] [Batch 00207/00823] [00:02:35/00:07:43, 0.753s/it]: train_loss_raw=1.6237, running_loss=1.6593, LR=0.000100
[2025-08-26 09:49:51,697][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005976] [Batch 00215/00823] [00:02:42/00:07:38, 0.754s/it]: train_loss_raw=1.5355, running_loss=1.6583, LR=0.000100
[2025-08-26 09:49:57,727][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005984] [Batch 00223/00823] [00:02:48/00:07:32, 0.754s/it]: train_loss_raw=1.6986, running_loss=1.6559, LR=0.000100
[2025-08-26 09:50:03,787][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 005992] [Batch 00231/00823] [00:02:54/00:07:26, 0.754s/it]: train_loss_raw=1.6214, running_loss=1.6536, LR=0.000100
[2025-08-26 09:50:09,801][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006000] [Batch 00239/00823] [00:03:00/00:07:20, 0.754s/it]: train_loss_raw=1.6808, running_loss=1.6511, LR=0.000100
[2025-08-26 09:50:19,655][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006008] [Batch 00247/00823] [00:03:10/00:07:23, 0.769s/it]: train_loss_raw=1.7154, running_loss=1.6516, LR=0.000100
[2025-08-26 09:50:25,677][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006016] [Batch 00255/00823] [00:03:16/00:07:16, 0.769s/it]: train_loss_raw=1.6621, running_loss=1.6524, LR=0.000100
[2025-08-26 09:50:31,831][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006024] [Batch 00263/00823] [00:03:22/00:07:10, 0.769s/it]: train_loss_raw=1.6301, running_loss=1.6513, LR=0.000100
[2025-08-26 09:50:37,863][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006032] [Batch 00271/00823] [00:03:28/00:07:04, 0.768s/it]: train_loss_raw=1.6622, running_loss=1.6501, LR=0.000100
[2025-08-26 09:50:43,907][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006040] [Batch 00279/00823] [00:03:34/00:06:57, 0.768s/it]: train_loss_raw=1.5914, running_loss=1.6505, LR=0.000100
[2025-08-26 09:50:49,997][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006048] [Batch 00287/00823] [00:03:40/00:06:51, 0.768s/it]: train_loss_raw=1.6423, running_loss=1.6503, LR=0.000100
[2025-08-26 09:50:56,147][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006056] [Batch 00295/00823] [00:03:46/00:06:45, 0.768s/it]: train_loss_raw=1.6468, running_loss=1.6505, LR=0.000100
[2025-08-26 09:51:02,211][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006064] [Batch 00303/00823] [00:03:52/00:06:39, 0.768s/it]: train_loss_raw=1.6153, running_loss=1.6486, LR=0.000100
[2025-08-26 09:51:08,250][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006072] [Batch 00311/00823] [00:03:58/00:06:32, 0.767s/it]: train_loss_raw=1.5938, running_loss=1.6482, LR=0.000100
[2025-08-26 09:51:14,320][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006080] [Batch 00319/00823] [00:04:04/00:06:26, 0.767s/it]: train_loss_raw=1.5837, running_loss=1.6477, LR=0.000100
[2025-08-26 09:51:20,343][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006088] [Batch 00327/00823] [00:04:10/00:06:20, 0.767s/it]: train_loss_raw=1.5718, running_loss=1.6466, LR=0.000100
[2025-08-26 09:51:26,327][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006096] [Batch 00335/00823] [00:04:16/00:06:13, 0.766s/it]: train_loss_raw=1.6432, running_loss=1.6466, LR=0.000100
[2025-08-26 09:51:32,315][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006104] [Batch 00343/00823] [00:04:22/00:06:07, 0.766s/it]: train_loss_raw=1.6696, running_loss=1.6460, LR=0.000100
[2025-08-26 09:51:38,288][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006112] [Batch 00351/00823] [00:04:28/00:06:01, 0.765s/it]: train_loss_raw=1.7238, running_loss=1.6446, LR=0.000100
[2025-08-26 09:51:44,366][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006120] [Batch 00359/00823] [00:04:34/00:05:55, 0.765s/it]: train_loss_raw=1.6177, running_loss=1.6444, LR=0.000100
[2025-08-26 09:51:50,440][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006128] [Batch 00367/00823] [00:04:40/00:05:48, 0.765s/it]: train_loss_raw=1.7025, running_loss=1.6459, LR=0.000100
[2025-08-26 09:51:56,432][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006136] [Batch 00375/00823] [00:04:46/00:05:42, 0.765s/it]: train_loss_raw=1.6389, running_loss=1.6447, LR=0.000100
[2025-08-26 09:52:02,531][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006144] [Batch 00383/00823] [00:04:52/00:05:36, 0.765s/it]: train_loss_raw=1.6903, running_loss=1.6468, LR=0.000100
[2025-08-26 09:52:08,599][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006152] [Batch 00391/00823] [00:04:58/00:05:30, 0.765s/it]: train_loss_raw=1.6650, running_loss=1.6480, LR=0.000100
[2025-08-26 09:52:14,643][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006160] [Batch 00399/00823] [00:05:05/00:05:24, 0.764s/it]: train_loss_raw=1.7578, running_loss=1.6487, LR=0.000100
[2025-08-26 09:52:20,714][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006168] [Batch 00407/00823] [00:05:11/00:05:17, 0.764s/it]: train_loss_raw=1.6843, running_loss=1.6478, LR=0.000100
[2025-08-26 09:52:26,737][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006176] [Batch 00415/00823] [00:05:17/00:05:11, 0.764s/it]: train_loss_raw=1.5929, running_loss=1.6474, LR=0.000100
[2025-08-26 09:52:32,764][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006184] [Batch 00423/00823] [00:05:23/00:05:05, 0.764s/it]: train_loss_raw=1.6805, running_loss=1.6458, LR=0.000100
[2025-08-26 09:52:38,804][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006192] [Batch 00431/00823] [00:05:29/00:04:59, 0.764s/it]: train_loss_raw=1.6973, running_loss=1.6468, LR=0.000100
[2025-08-26 09:52:44,835][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006200] [Batch 00439/00823] [00:05:35/00:04:53, 0.764s/it]: train_loss_raw=1.8144, running_loss=1.6469, LR=0.000100
[2025-08-26 09:52:50,862][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006208] [Batch 00447/00823] [00:05:41/00:04:47, 0.763s/it]: train_loss_raw=1.6677, running_loss=1.6456, LR=0.000100
[2025-08-26 09:52:56,919][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006216] [Batch 00455/00823] [00:05:47/00:04:40, 0.763s/it]: train_loss_raw=1.7489, running_loss=1.6449, LR=0.000100
[2025-08-26 09:53:02,795][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006224] [Batch 00463/00823] [00:05:53/00:04:34, 0.763s/it]: train_loss_raw=1.5441, running_loss=1.6449, LR=0.000100
[2025-08-26 09:53:08,571][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006232] [Batch 00471/00823] [00:05:58/00:04:28, 0.762s/it]: train_loss_raw=1.6183, running_loss=1.6446, LR=0.000100
[2025-08-26 09:53:14,286][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006240] [Batch 00479/00823] [00:06:04/00:04:21, 0.761s/it]: train_loss_raw=1.6056, running_loss=1.6430, LR=0.000100
[2025-08-26 09:53:19,909][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006248] [Batch 00487/00823] [00:06:10/00:04:15, 0.760s/it]: train_loss_raw=1.5931, running_loss=1.6408, LR=0.000100
[2025-08-26 09:53:25,607][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006256] [Batch 00495/00823] [00:06:15/00:04:09, 0.760s/it]: train_loss_raw=1.6124, running_loss=1.6409, LR=0.000100
[2025-08-26 09:53:31,067][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006264] [Batch 00503/00823] [00:06:21/00:04:02, 0.758s/it]: train_loss_raw=1.7180, running_loss=1.6414, LR=0.000100
[2025-08-26 09:53:36,648][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006272] [Batch 00511/00823] [00:06:27/00:03:56, 0.757s/it]: train_loss_raw=1.6368, running_loss=1.6426, LR=0.000100
[2025-08-26 09:53:42,392][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006280] [Batch 00519/00823] [00:06:32/00:03:50, 0.757s/it]: train_loss_raw=1.6841, running_loss=1.6442, LR=0.000100
[2025-08-26 09:53:48,262][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006288] [Batch 00527/00823] [00:06:38/00:03:43, 0.756s/it]: train_loss_raw=1.6612, running_loss=1.6429, LR=0.000100
[2025-08-26 09:53:54,157][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006296] [Batch 00535/00823] [00:06:44/00:03:37, 0.756s/it]: train_loss_raw=1.7016, running_loss=1.6424, LR=0.000100
[2025-08-26 09:54:00,090][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006304] [Batch 00543/00823] [00:06:50/00:03:31, 0.756s/it]: train_loss_raw=1.6815, running_loss=1.6428, LR=0.000100
[2025-08-26 09:54:05,880][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006312] [Batch 00551/00823] [00:06:56/00:03:25, 0.755s/it]: train_loss_raw=1.6991, running_loss=1.6400, LR=0.000100
[2025-08-26 09:54:11,731][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006320] [Batch 00559/00823] [00:07:02/00:03:19, 0.755s/it]: train_loss_raw=1.5871, running_loss=1.6403, LR=0.000100
[2025-08-26 09:54:17,622][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006328] [Batch 00567/00823] [00:07:07/00:03:13, 0.755s/it]: train_loss_raw=1.6532, running_loss=1.6406, LR=0.000100
[2025-08-26 09:54:23,433][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006336] [Batch 00575/00823] [00:07:13/00:03:07, 0.754s/it]: train_loss_raw=1.5661, running_loss=1.6365, LR=0.000100
[2025-08-26 09:54:29,166][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006344] [Batch 00583/00823] [00:07:19/00:03:00, 0.754s/it]: train_loss_raw=1.6602, running_loss=1.6369, LR=0.000100
[2025-08-26 09:54:35,032][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006352] [Batch 00591/00823] [00:07:25/00:02:54, 0.754s/it]: train_loss_raw=1.6652, running_loss=1.6382, LR=0.000100
[2025-08-26 09:54:40,796][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006360] [Batch 00599/00823] [00:07:31/00:02:48, 0.753s/it]: train_loss_raw=1.5193, running_loss=1.6382, LR=0.000100
[2025-08-26 09:54:46,531][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006368] [Batch 00607/00823] [00:07:36/00:02:42, 0.753s/it]: train_loss_raw=1.5866, running_loss=1.6360, LR=0.000100
[2025-08-26 09:54:52,248][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006376] [Batch 00615/00823] [00:07:42/00:02:36, 0.752s/it]: train_loss_raw=1.6855, running_loss=1.6347, LR=0.000100
[2025-08-26 09:54:57,939][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006384] [Batch 00623/00823] [00:07:48/00:02:30, 0.752s/it]: train_loss_raw=1.5309, running_loss=1.6310, LR=0.000100
[2025-08-26 09:55:03,859][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006392] [Batch 00631/00823] [00:07:54/00:02:24, 0.752s/it]: train_loss_raw=1.6470, running_loss=1.6294, LR=0.000100
[2025-08-26 09:55:09,609][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006400] [Batch 00639/00823] [00:07:59/00:02:18, 0.751s/it]: train_loss_raw=1.6032, running_loss=1.6297, LR=0.000100
[2025-08-26 09:55:15,462][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006408] [Batch 00647/00823] [00:08:05/00:02:12, 0.751s/it]: train_loss_raw=1.6594, running_loss=1.6291, LR=0.000100
[2025-08-26 09:55:21,183][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006416] [Batch 00655/00823] [00:08:11/00:02:06, 0.750s/it]: train_loss_raw=1.5991, running_loss=1.6269, LR=0.000100
[2025-08-26 09:55:26,922][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006424] [Batch 00663/00823] [00:08:17/00:02:00, 0.750s/it]: train_loss_raw=1.6460, running_loss=1.6252, LR=0.000100
[2025-08-26 09:55:32,640][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006432] [Batch 00671/00823] [00:08:23/00:01:53, 0.750s/it]: train_loss_raw=1.7170, running_loss=1.6261, LR=0.000100
[2025-08-26 09:55:38,460][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006440] [Batch 00679/00823] [00:08:28/00:01:47, 0.749s/it]: train_loss_raw=1.5692, running_loss=1.6256, LR=0.000100
[2025-08-26 09:55:44,188][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006448] [Batch 00687/00823] [00:08:34/00:01:41, 0.749s/it]: train_loss_raw=1.6566, running_loss=1.6238, LR=0.000100
[2025-08-26 09:55:49,935][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006456] [Batch 00695/00823] [00:08:40/00:01:35, 0.749s/it]: train_loss_raw=1.6514, running_loss=1.6241, LR=0.000100
[2025-08-26 09:55:55,825][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006464] [Batch 00703/00823] [00:08:46/00:01:29, 0.749s/it]: train_loss_raw=1.6247, running_loss=1.6220, LR=0.000100
[2025-08-26 09:56:01,811][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006472] [Batch 00711/00823] [00:08:52/00:01:23, 0.749s/it]: train_loss_raw=1.5225, running_loss=1.6187, LR=0.000100
[2025-08-26 09:56:07,790][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006480] [Batch 00719/00823] [00:08:58/00:01:17, 0.748s/it]: train_loss_raw=1.5888, running_loss=1.6195, LR=0.000100
[2025-08-26 09:56:13,762][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006488] [Batch 00727/00823] [00:09:04/00:01:11, 0.748s/it]: train_loss_raw=1.5545, running_loss=1.6195, LR=0.000100
[2025-08-26 09:56:19,384][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006496] [Batch 00735/00823] [00:09:09/00:01:05, 0.748s/it]: train_loss_raw=1.6093, running_loss=1.6213, LR=0.000100
[2025-08-26 09:56:25,203][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006504] [Batch 00743/00823] [00:09:15/00:00:59, 0.748s/it]: train_loss_raw=1.6566, running_loss=1.6210, LR=0.000100
[2025-08-26 09:56:31,072][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006512] [Batch 00751/00823] [00:09:21/00:00:53, 0.748s/it]: train_loss_raw=1.7181, running_loss=1.6250, LR=0.000100
[2025-08-26 09:56:36,867][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006520] [Batch 00759/00823] [00:09:27/00:00:47, 0.747s/it]: train_loss_raw=1.6720, running_loss=1.6251, LR=0.000100
[2025-08-26 09:56:42,637][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006528] [Batch 00767/00823] [00:09:33/00:00:41, 0.747s/it]: train_loss_raw=1.5332, running_loss=1.6228, LR=0.000100
[2025-08-26 09:56:48,479][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006536] [Batch 00775/00823] [00:09:38/00:00:35, 0.747s/it]: train_loss_raw=1.6657, running_loss=1.6215, LR=0.000100
[2025-08-26 09:56:54,260][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006544] [Batch 00783/00823] [00:09:44/00:00:29, 0.747s/it]: train_loss_raw=1.6405, running_loss=1.6216, LR=0.000100
[2025-08-26 09:57:00,018][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006552] [Batch 00791/00823] [00:09:50/00:00:23, 0.746s/it]: train_loss_raw=1.6292, running_loss=1.6217, LR=0.000100
[2025-08-26 09:57:05,765][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006560] [Batch 00799/00823] [00:09:56/00:00:17, 0.746s/it]: train_loss_raw=1.6242, running_loss=1.6208, LR=0.000100
[2025-08-26 09:57:11,597][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006568] [Batch 00807/00823] [00:10:01/00:00:11, 0.746s/it]: train_loss_raw=1.5525, running_loss=1.6212, LR=0.000100
[2025-08-26 09:57:17,103][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006576] [Batch 00815/00823] [00:10:07/00:00:05, 0.745s/it]: train_loss_raw=1.6377, running_loss=1.6204, LR=0.000100
[2025-08-26 09:57:28,672][__main__][INFO] - [TRAIN] [Epoch 07/29 Step 006584] [Batch 00823/00823] [00:10:19/00:00:00, 0.752s/it]: train_loss_raw=1.5000, running_loss=1.6195, LR=0.000100
[2025-08-26 09:57:29,051][__main__][INFO] - [VALIDATION] [Epoch 07/29] Starting validation.
[2025-08-26 09:57:40,174][__main__][INFO] - [VALIDATION] [Epoch 07/29 Step 006585] [Batch 00007/00013] [00:00:11/00:00:06, 1.390s/it]
[2025-08-26 09:57:47,224][__main__][INFO] - [VALIDATION] [Epoch 07/29] train_loss=1.61949, valid_loss=1.65712
[2025-08-26 09:57:47,224][__main__][INFO] - [VALIDATION] [Epoch 07/29] Metrics:
[2025-08-26 09:57:47,224][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_er      0.675
[2025-08-26 09:57:47,224][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_prec    0.045
[2025-08-26 09:57:47,224][__main__][INFO] - [VALIDATION] [Epoch 07/29] - aa_recall  0.046
[2025-08-26 09:57:47,224][__main__][INFO] - [VALIDATION] [Epoch 07/29] - pep_recall 0.006
[2025-08-26 09:57:47,227][__main__][INFO] - [TRAIN] [Epoch 07/29] Epoch complete, total time 01:25:10, remaining time 03:54:15, 00:10:38 per epoch
[2025-08-26 09:57:53,900][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006592] [Batch 00008/00823] [00:00:05/00:09:23, 0.691s/it]: train_loss_raw=1.5453, running_loss=1.6349, LR=0.000100
[2025-08-26 09:58:00,038][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006600] [Batch 00016/00823] [00:00:11/00:09:48, 0.729s/it]: train_loss_raw=1.5185, running_loss=1.6296, LR=0.000100
[2025-08-26 09:58:05,704][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006608] [Batch 00024/00823] [00:00:17/00:09:37, 0.722s/it]: train_loss_raw=1.5701, running_loss=1.6256, LR=0.000100
[2025-08-26 09:58:11,427][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006616] [Batch 00032/00823] [00:00:23/00:09:29, 0.721s/it]: train_loss_raw=1.5388, running_loss=1.6229, LR=0.000100
[2025-08-26 09:58:17,505][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006624] [Batch 00040/00823] [00:00:29/00:09:30, 0.728s/it]: train_loss_raw=1.5915, running_loss=1.6200, LR=0.000100
[2025-08-26 09:58:23,415][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006632] [Batch 00048/00823] [00:00:35/00:09:25, 0.730s/it]: train_loss_raw=1.6486, running_loss=1.6179, LR=0.000100
[2025-08-26 09:58:29,256][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006640] [Batch 00056/00823] [00:00:40/00:09:19, 0.730s/it]: train_loss_raw=1.5874, running_loss=1.6184, LR=0.000100
[2025-08-26 09:58:35,096][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006648] [Batch 00064/00823] [00:00:46/00:09:14, 0.730s/it]: train_loss_raw=1.5881, running_loss=1.6146, LR=0.000100
[2025-08-26 09:58:41,001][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006656] [Batch 00072/00823] [00:00:52/00:09:08, 0.731s/it]: train_loss_raw=1.5395, running_loss=1.6102, LR=0.000100
[2025-08-26 09:58:46,836][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006664] [Batch 00080/00823] [00:00:58/00:09:03, 0.731s/it]: train_loss_raw=1.6343, running_loss=1.6094, LR=0.000100
[2025-08-26 09:58:52,697][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006672] [Batch 00088/00823] [00:01:04/00:08:57, 0.731s/it]: train_loss_raw=1.6136, running_loss=1.6079, LR=0.000100
[2025-08-26 09:58:58,647][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006680] [Batch 00096/00823] [00:01:10/00:08:52, 0.732s/it]: train_loss_raw=1.6324, running_loss=1.6067, LR=0.000100
[2025-08-26 09:59:04,480][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006688] [Batch 00104/00823] [00:01:16/00:08:46, 0.732s/it]: train_loss_raw=1.5515, running_loss=1.6060, LR=0.000100
[2025-08-26 09:59:10,072][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006696] [Batch 00112/00823] [00:01:21/00:08:38, 0.729s/it]: train_loss_raw=1.5864, running_loss=1.6042, LR=0.000100
[2025-08-26 09:59:15,842][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006704] [Batch 00120/00823] [00:01:27/00:08:32, 0.729s/it]: train_loss_raw=1.5783, running_loss=1.6035, LR=0.000100
[2025-08-26 09:59:21,637][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006712] [Batch 00128/00823] [00:01:33/00:08:26, 0.729s/it]: train_loss_raw=1.5760, running_loss=1.6024, LR=0.000100
[2025-08-26 09:59:27,453][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006720] [Batch 00136/00823] [00:01:39/00:08:20, 0.729s/it]: train_loss_raw=1.5915, running_loss=1.6032, LR=0.000100
[2025-08-26 09:59:33,269][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006728] [Batch 00144/00823] [00:01:44/00:08:14, 0.728s/it]: train_loss_raw=1.6043, running_loss=1.6030, LR=0.000100
[2025-08-26 09:59:39,065][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006736] [Batch 00152/00823] [00:01:50/00:08:08, 0.728s/it]: train_loss_raw=1.6002, running_loss=1.6020, LR=0.000100
[2025-08-26 09:59:44,883][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006744] [Batch 00160/00823] [00:01:56/00:08:02, 0.728s/it]: train_loss_raw=1.5532, running_loss=1.6015, LR=0.000100
[2025-08-26 09:59:50,740][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006752] [Batch 00168/00823] [00:02:02/00:07:57, 0.728s/it]: train_loss_raw=1.5572, running_loss=1.6016, LR=0.000100
[2025-08-26 09:59:56,564][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006760] [Batch 00176/00823] [00:02:08/00:07:51, 0.728s/it]: train_loss_raw=1.7000, running_loss=1.6004, LR=0.000100
[2025-08-26 10:00:02,387][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006768] [Batch 00184/00823] [00:02:14/00:07:45, 0.728s/it]: train_loss_raw=1.6300, running_loss=1.6009, LR=0.000100
[2025-08-26 10:00:08,263][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006776] [Batch 00192/00823] [00:02:19/00:07:39, 0.729s/it]: train_loss_raw=1.6387, running_loss=1.5991, LR=0.000100
[2025-08-26 10:00:14,225][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006784] [Batch 00200/00823] [00:02:25/00:07:34, 0.729s/it]: train_loss_raw=1.6459, running_loss=1.5983, LR=0.000100
[2025-08-26 10:00:20,152][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006792] [Batch 00208/00823] [00:02:31/00:07:28, 0.730s/it]: train_loss_raw=1.5692, running_loss=1.5963, LR=0.000100
[2025-08-26 10:00:26,153][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006800] [Batch 00216/00823] [00:02:37/00:07:23, 0.730s/it]: train_loss_raw=1.5626, running_loss=1.5964, LR=0.000100
[2025-08-26 10:00:32,225][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006808] [Batch 00224/00823] [00:02:43/00:07:18, 0.731s/it]: train_loss_raw=1.5869, running_loss=1.5953, LR=0.000100
[2025-08-26 10:00:38,147][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006816] [Batch 00232/00823] [00:02:49/00:07:12, 0.732s/it]: train_loss_raw=1.6322, running_loss=1.5961, LR=0.000100
[2025-08-26 10:00:44,043][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006824] [Batch 00240/00823] [00:02:55/00:07:06, 0.732s/it]: train_loss_raw=1.6733, running_loss=1.5964, LR=0.000100
[2025-08-26 10:00:49,565][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006832] [Batch 00248/00823] [00:03:01/00:07:00, 0.731s/it]: train_loss_raw=1.6276, running_loss=1.5938, LR=0.000100
[2025-08-26 10:00:55,120][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006840] [Batch 00256/00823] [00:03:06/00:06:53, 0.729s/it]: train_loss_raw=1.5991, running_loss=1.5942, LR=0.000100
[2025-08-26 10:01:00,793][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006848] [Batch 00264/00823] [00:03:12/00:06:47, 0.729s/it]: train_loss_raw=1.6069, running_loss=1.5925, LR=0.000100
[2025-08-26 10:01:06,397][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006856] [Batch 00272/00823] [00:03:18/00:06:41, 0.728s/it]: train_loss_raw=1.5907, running_loss=1.5922, LR=0.000100
[2025-08-26 10:01:11,992][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006864] [Batch 00280/00823] [00:03:23/00:06:34, 0.727s/it]: train_loss_raw=1.6445, running_loss=1.5906, LR=0.000100
[2025-08-26 10:01:17,779][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006872] [Batch 00288/00823] [00:03:29/00:06:29, 0.727s/it]: train_loss_raw=1.6232, running_loss=1.5889, LR=0.000100
[2025-08-26 10:01:23,615][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006880] [Batch 00296/00823] [00:03:35/00:06:23, 0.727s/it]: train_loss_raw=1.5963, running_loss=1.5883, LR=0.000100
[2025-08-26 10:01:29,525][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006888] [Batch 00304/00823] [00:03:41/00:06:17, 0.727s/it]: train_loss_raw=1.6621, running_loss=1.5883, LR=0.000100
[2025-08-26 10:01:35,330][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006896] [Batch 00312/00823] [00:03:46/00:06:11, 0.727s/it]: train_loss_raw=1.5465, running_loss=1.5869, LR=0.000100
[2025-08-26 10:01:41,010][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006904] [Batch 00320/00823] [00:03:52/00:06:05, 0.727s/it]: train_loss_raw=1.6537, running_loss=1.5890, LR=0.000100
[2025-08-26 10:01:46,817][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006912] [Batch 00328/00823] [00:03:58/00:05:59, 0.727s/it]: train_loss_raw=1.5985, running_loss=1.5879, LR=0.000100
[2025-08-26 10:01:52,524][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006920] [Batch 00336/00823] [00:04:04/00:05:53, 0.727s/it]: train_loss_raw=1.5644, running_loss=1.5883, LR=0.000100
[2025-08-26 10:01:58,405][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006928] [Batch 00344/00823] [00:04:10/00:05:48, 0.727s/it]: train_loss_raw=1.5994, running_loss=1.5882, LR=0.000100
[2025-08-26 10:02:04,155][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006936] [Batch 00352/00823] [00:04:15/00:05:42, 0.727s/it]: train_loss_raw=1.5433, running_loss=1.5877, LR=0.000100
[2025-08-26 10:02:09,867][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006944] [Batch 00360/00823] [00:04:21/00:05:36, 0.726s/it]: train_loss_raw=1.6504, running_loss=1.5902, LR=0.000100
[2025-08-26 10:02:15,622][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006952] [Batch 00368/00823] [00:04:27/00:05:30, 0.726s/it]: train_loss_raw=1.5525, running_loss=1.5868, LR=0.000100
[2025-08-26 10:02:21,571][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006960] [Batch 00376/00823] [00:04:33/00:05:24, 0.727s/it]: train_loss_raw=1.5638, running_loss=1.5861, LR=0.000100
[2025-08-26 10:02:27,117][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006968] [Batch 00384/00823] [00:04:38/00:05:18, 0.726s/it]: train_loss_raw=1.5982, running_loss=1.5869, LR=0.000100
[2025-08-26 10:02:32,929][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006976] [Batch 00392/00823] [00:04:44/00:05:12, 0.726s/it]: train_loss_raw=1.5678, running_loss=1.5871, LR=0.000100
[2025-08-26 10:02:38,720][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006984] [Batch 00400/00823] [00:04:50/00:05:07, 0.726s/it]: train_loss_raw=1.6083, running_loss=1.5875, LR=0.000100
[2025-08-26 10:02:44,511][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 006992] [Batch 00408/00823] [00:04:56/00:05:01, 0.726s/it]: train_loss_raw=1.6561, running_loss=1.5902, LR=0.000100
[2025-08-26 10:02:50,361][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007000] [Batch 00416/00823] [00:05:01/00:04:55, 0.726s/it]: train_loss_raw=1.5494, running_loss=1.5902, LR=0.000100
[2025-08-26 10:02:56,131][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007008] [Batch 00424/00823] [00:05:07/00:04:49, 0.726s/it]: train_loss_raw=1.5586, running_loss=1.5885, LR=0.000100
[2025-08-26 10:03:02,056][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007016] [Batch 00432/00823] [00:05:13/00:04:43, 0.726s/it]: train_loss_raw=1.5398, running_loss=1.5871, LR=0.000100
[2025-08-26 10:03:07,848][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007024] [Batch 00440/00823] [00:05:19/00:04:38, 0.726s/it]: train_loss_raw=1.5789, running_loss=1.5852, LR=0.000100
[2025-08-26 10:03:13,730][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007032] [Batch 00448/00823] [00:05:25/00:04:32, 0.726s/it]: train_loss_raw=1.5476, running_loss=1.5847, LR=0.000100
[2025-08-26 10:03:19,603][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007040] [Batch 00456/00823] [00:05:31/00:04:26, 0.726s/it]: train_loss_raw=1.6230, running_loss=1.5839, LR=0.000100
[2025-08-26 10:03:25,407][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007048] [Batch 00464/00823] [00:05:37/00:04:20, 0.726s/it]: train_loss_raw=1.5527, running_loss=1.5846, LR=0.000100
[2025-08-26 10:03:31,156][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007056] [Batch 00472/00823] [00:05:42/00:04:14, 0.726s/it]: train_loss_raw=1.6245, running_loss=1.5846, LR=0.000100
[2025-08-26 10:03:36,903][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007064] [Batch 00480/00823] [00:05:48/00:04:09, 0.726s/it]: train_loss_raw=1.4608, running_loss=1.5836, LR=0.000100
[2025-08-26 10:03:42,905][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007072] [Batch 00488/00823] [00:05:54/00:04:03, 0.727s/it]: train_loss_raw=1.6146, running_loss=1.5815, LR=0.000100
[2025-08-26 10:03:48,709][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007080] [Batch 00496/00823] [00:06:00/00:03:57, 0.726s/it]: train_loss_raw=1.5572, running_loss=1.5833, LR=0.000100
[2025-08-26 10:03:54,627][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007088] [Batch 00504/00823] [00:06:06/00:03:51, 0.727s/it]: train_loss_raw=1.5827, running_loss=1.5842, LR=0.000100
[2025-08-26 10:04:00,568][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007096] [Batch 00512/00823] [00:06:12/00:03:46, 0.727s/it]: train_loss_raw=1.6523, running_loss=1.5827, LR=0.000100
[2025-08-26 10:04:06,529][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007104] [Batch 00520/00823] [00:06:18/00:03:40, 0.727s/it]: train_loss_raw=1.5656, running_loss=1.5815, LR=0.000100
[2025-08-26 10:04:12,423][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007112] [Batch 00528/00823] [00:06:24/00:03:34, 0.727s/it]: train_loss_raw=1.6282, running_loss=1.5823, LR=0.000100
[2025-08-26 10:04:18,363][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007120] [Batch 00536/00823] [00:06:29/00:03:28, 0.728s/it]: train_loss_raw=1.5166, running_loss=1.5790, LR=0.000100
[2025-08-26 10:04:24,328][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007128] [Batch 00544/00823] [00:06:35/00:03:23, 0.728s/it]: train_loss_raw=1.6247, running_loss=1.5795, LR=0.000100
[2025-08-26 10:04:30,151][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007136] [Batch 00552/00823] [00:06:41/00:03:17, 0.728s/it]: train_loss_raw=1.6560, running_loss=1.5808, LR=0.000100
[2025-08-26 10:04:35,974][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007144] [Batch 00560/00823] [00:06:47/00:03:11, 0.728s/it]: train_loss_raw=1.5630, running_loss=1.5776, LR=0.000100
[2025-08-26 10:04:41,770][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007152] [Batch 00568/00823] [00:06:53/00:03:05, 0.728s/it]: train_loss_raw=1.6356, running_loss=1.5802, LR=0.000100
[2025-08-26 10:04:47,609][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007160] [Batch 00576/00823] [00:06:59/00:02:59, 0.728s/it]: train_loss_raw=1.5643, running_loss=1.5803, LR=0.000100
[2025-08-26 10:04:53,433][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007168] [Batch 00584/00823] [00:07:05/00:02:53, 0.728s/it]: train_loss_raw=1.5712, running_loss=1.5812, LR=0.000100
[2025-08-26 10:04:59,217][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007176] [Batch 00592/00823] [00:07:10/00:02:48, 0.728s/it]: train_loss_raw=1.4705, running_loss=1.5788, LR=0.000100
[2025-08-26 10:05:04,986][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007184] [Batch 00600/00823] [00:07:16/00:02:42, 0.728s/it]: train_loss_raw=1.5153, running_loss=1.5791, LR=0.000100
[2025-08-26 10:05:10,792][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007192] [Batch 00608/00823] [00:07:22/00:02:36, 0.728s/it]: train_loss_raw=1.4701, running_loss=1.5778, LR=0.000100
[2025-08-26 10:05:16,667][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007200] [Batch 00616/00823] [00:07:28/00:02:30, 0.728s/it]: train_loss_raw=1.5990, running_loss=1.5779, LR=0.000100
[2025-08-26 10:05:22,809][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007208] [Batch 00624/00823] [00:07:34/00:02:24, 0.728s/it]: train_loss_raw=1.5300, running_loss=1.5758, LR=0.000100
[2025-08-26 10:05:28,692][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007216] [Batch 00632/00823] [00:07:40/00:02:19, 0.728s/it]: train_loss_raw=1.6008, running_loss=1.5770, LR=0.000100
[2025-08-26 10:05:34,499][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007224] [Batch 00640/00823] [00:07:46/00:02:13, 0.728s/it]: train_loss_raw=1.5765, running_loss=1.5787, LR=0.000100
[2025-08-26 10:05:40,407][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007232] [Batch 00648/00823] [00:07:52/00:02:07, 0.728s/it]: train_loss_raw=1.4751, running_loss=1.5756, LR=0.000100
[2025-08-26 10:05:46,406][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007240] [Batch 00656/00823] [00:07:58/00:02:01, 0.729s/it]: train_loss_raw=1.6371, running_loss=1.5757, LR=0.000100
[2025-08-26 10:05:52,667][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007248] [Batch 00664/00823] [00:08:04/00:01:55, 0.729s/it]: train_loss_raw=1.4693, running_loss=1.5733, LR=0.000100
[2025-08-26 10:05:58,508][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007256] [Batch 00672/00823] [00:08:10/00:01:50, 0.729s/it]: train_loss_raw=1.5739, running_loss=1.5761, LR=0.000100
[2025-08-26 10:06:04,261][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007264] [Batch 00680/00823] [00:08:15/00:01:44, 0.729s/it]: train_loss_raw=1.5437, running_loss=1.5774, LR=0.000100
[2025-08-26 10:06:10,085][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007272] [Batch 00688/00823] [00:08:21/00:01:38, 0.729s/it]: train_loss_raw=1.5827, running_loss=1.5748, LR=0.000100
[2025-08-26 10:06:15,857][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007280] [Batch 00696/00823] [00:08:27/00:01:32, 0.729s/it]: train_loss_raw=1.6468, running_loss=1.5739, LR=0.000100
[2025-08-26 10:06:21,724][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007288] [Batch 00704/00823] [00:08:33/00:01:26, 0.729s/it]: train_loss_raw=1.5924, running_loss=1.5735, LR=0.000100
[2025-08-26 10:06:27,531][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007296] [Batch 00712/00823] [00:08:39/00:01:20, 0.729s/it]: train_loss_raw=1.5728, running_loss=1.5730, LR=0.000100
[2025-08-26 10:06:33,205][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007304] [Batch 00720/00823] [00:08:44/00:01:15, 0.729s/it]: train_loss_raw=1.5738, running_loss=1.5716, LR=0.000100
[2025-08-26 10:06:38,903][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007312] [Batch 00728/00823] [00:08:50/00:01:09, 0.729s/it]: train_loss_raw=1.5959, running_loss=1.5695, LR=0.000100
[2025-08-26 10:06:44,927][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007320] [Batch 00736/00823] [00:08:56/00:01:03, 0.729s/it]: train_loss_raw=1.6272, running_loss=1.5684, LR=0.000100
[2025-08-26 10:06:50,658][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007328] [Batch 00744/00823] [00:09:02/00:00:57, 0.729s/it]: train_loss_raw=1.6364, running_loss=1.5674, LR=0.000100
[2025-08-26 10:06:56,554][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007336] [Batch 00752/00823] [00:09:08/00:00:51, 0.729s/it]: train_loss_raw=1.5420, running_loss=1.5658, LR=0.000100
[2025-08-26 10:07:02,476][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007344] [Batch 00760/00823] [00:09:14/00:00:45, 0.729s/it]: train_loss_raw=1.5560, running_loss=1.5679, LR=0.000100
[2025-08-26 10:07:08,251][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007352] [Batch 00768/00823] [00:09:19/00:00:40, 0.729s/it]: train_loss_raw=1.6649, running_loss=1.5679, LR=0.000100
[2025-08-26 10:07:14,221][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007360] [Batch 00776/00823] [00:09:25/00:00:34, 0.729s/it]: train_loss_raw=1.5615, running_loss=1.5686, LR=0.000100
[2025-08-26 10:07:20,112][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007368] [Batch 00784/00823] [00:09:31/00:00:28, 0.729s/it]: train_loss_raw=1.6219, running_loss=1.5689, LR=0.000100
[2025-08-26 10:07:25,877][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007376] [Batch 00792/00823] [00:09:37/00:00:22, 0.729s/it]: train_loss_raw=1.5364, running_loss=1.5691, LR=0.000100
[2025-08-26 10:07:31,779][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007384] [Batch 00800/00823] [00:09:43/00:00:16, 0.729s/it]: train_loss_raw=1.4864, running_loss=1.5673, LR=0.000100
[2025-08-26 10:07:37,817][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007392] [Batch 00808/00823] [00:09:49/00:00:10, 0.730s/it]: train_loss_raw=1.5957, running_loss=1.5689, LR=0.000100
[2025-08-26 10:07:43,751][__main__][INFO] - [TRAIN] [Epoch 08/29 Step 007400] [Batch 00816/00823] [00:09:55/00:00:05, 0.730s/it]: train_loss_raw=1.6187, running_loss=1.5665, LR=0.000100
[2025-08-26 10:07:49,267][__main__][INFO] - [VALIDATION] [Epoch 08/29] Starting validation.
[2025-08-26 10:08:00,272][__main__][INFO] - [VALIDATION] [Epoch 08/29 Step 007408] [Batch 00007/00013] [00:00:11/00:00:06, 1.376s/it]
[2025-08-26 10:08:07,075][__main__][INFO] - [VALIDATION] [Epoch 08/29] train_loss=1.56886, valid_loss=1.62559
[2025-08-26 10:08:07,075][__main__][INFO] - [VALIDATION] [Epoch 08/29] Metrics:
[2025-08-26 10:08:07,075][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_er      0.699
[2025-08-26 10:08:07,076][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_prec    0.039
[2025-08-26 10:08:07,076][__main__][INFO] - [VALIDATION] [Epoch 08/29] - aa_recall  0.040
[2025-08-26 10:08:07,076][__main__][INFO] - [VALIDATION] [Epoch 08/29] - pep_recall 0.005
[2025-08-26 10:08:07,078][__main__][INFO] - [TRAIN] [Epoch 08/29] Epoch complete, total time 01:35:30, remaining time 03:42:51, 00:10:36 per epoch
[2025-08-26 10:08:07,472][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007408] [Batch 00001/00823] [00:00:00/00:01:58, 0.144s/it]: train_loss_raw=1.6510, running_loss=1.6510, LR=0.000100
[2025-08-26 10:08:13,569][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007416] [Batch 00009/00823] [00:00:06/00:09:24, 0.693s/it]: train_loss_raw=1.5990, running_loss=1.6453, LR=0.000100
[2025-08-26 10:08:19,681][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007424] [Batch 00017/00823] [00:00:12/00:09:45, 0.727s/it]: train_loss_raw=1.5361, running_loss=1.6399, LR=0.000100
[2025-08-26 10:08:25,670][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007432] [Batch 00025/00823] [00:00:18/00:09:45, 0.734s/it]: train_loss_raw=1.4910, running_loss=1.6324, LR=0.000100
[2025-08-26 10:08:31,565][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007440] [Batch 00033/00823] [00:00:24/00:09:40, 0.734s/it]: train_loss_raw=1.5419, running_loss=1.6247, LR=0.000100
[2025-08-26 10:08:37,384][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007448] [Batch 00041/00823] [00:00:30/00:09:33, 0.733s/it]: train_loss_raw=1.5387, running_loss=1.6189, LR=0.000100
[2025-08-26 10:08:43,297][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007456] [Batch 00049/00823] [00:00:35/00:09:28, 0.734s/it]: train_loss_raw=1.5423, running_loss=1.6139, LR=0.000100
[2025-08-26 10:08:49,197][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007464] [Batch 00057/00823] [00:00:41/00:09:22, 0.735s/it]: train_loss_raw=1.6692, running_loss=1.6121, LR=0.000100
[2025-08-26 10:08:54,801][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007472] [Batch 00065/00823] [00:00:47/00:09:13, 0.730s/it]: train_loss_raw=1.5379, running_loss=1.6078, LR=0.000100
[2025-08-26 10:09:00,608][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007480] [Batch 00073/00823] [00:00:53/00:09:07, 0.730s/it]: train_loss_raw=1.5963, running_loss=1.6071, LR=0.000100
[2025-08-26 10:09:06,322][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007488] [Batch 00081/00823] [00:00:58/00:09:00, 0.728s/it]: train_loss_raw=1.6221, running_loss=1.6031, LR=0.000100
[2025-08-26 10:09:12,075][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007496] [Batch 00089/00823] [00:01:04/00:08:53, 0.727s/it]: train_loss_raw=1.6007, running_loss=1.5984, LR=0.000100
[2025-08-26 10:09:17,958][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007504] [Batch 00097/00823] [00:01:10/00:08:48, 0.728s/it]: train_loss_raw=1.5743, running_loss=1.5971, LR=0.000100
[2025-08-26 10:09:24,007][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007512] [Batch 00105/00823] [00:01:16/00:08:44, 0.730s/it]: train_loss_raw=1.5536, running_loss=1.5936, LR=0.000100
[2025-08-26 10:09:29,718][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007520] [Batch 00113/00823] [00:01:22/00:08:37, 0.729s/it]: train_loss_raw=1.6346, running_loss=1.5931, LR=0.000100
[2025-08-26 10:09:35,433][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007528] [Batch 00121/00823] [00:01:28/00:08:31, 0.728s/it]: train_loss_raw=1.4753, running_loss=1.5904, LR=0.000100
[2025-08-26 10:09:41,385][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007536] [Batch 00129/00823] [00:01:34/00:08:26, 0.729s/it]: train_loss_raw=1.5488, running_loss=1.5847, LR=0.000100
[2025-08-26 10:09:47,367][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007544] [Batch 00137/00823] [00:01:40/00:08:20, 0.730s/it]: train_loss_raw=1.5778, running_loss=1.5840, LR=0.000100
[2025-08-26 10:09:53,087][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007552] [Batch 00145/00823] [00:01:45/00:08:14, 0.729s/it]: train_loss_raw=1.5631, running_loss=1.5800, LR=0.000100
[2025-08-26 10:09:58,876][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007560] [Batch 00153/00823] [00:01:51/00:08:08, 0.729s/it]: train_loss_raw=1.4804, running_loss=1.5785, LR=0.000100
[2025-08-26 10:10:04,699][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007568] [Batch 00161/00823] [00:01:57/00:08:02, 0.729s/it]: train_loss_raw=1.6098, running_loss=1.5767, LR=0.000100
[2025-08-26 10:10:10,558][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007576] [Batch 00169/00823] [00:02:03/00:07:56, 0.729s/it]: train_loss_raw=1.4935, running_loss=1.5725, LR=0.000100
[2025-08-26 10:10:16,325][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007584] [Batch 00177/00823] [00:02:08/00:07:50, 0.729s/it]: train_loss_raw=1.5704, running_loss=1.5730, LR=0.000100
[2025-08-26 10:10:22,235][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007592] [Batch 00185/00823] [00:02:14/00:07:45, 0.729s/it]: train_loss_raw=1.5813, running_loss=1.5722, LR=0.000100
[2025-08-26 10:10:28,190][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007600] [Batch 00193/00823] [00:02:20/00:07:39, 0.730s/it]: train_loss_raw=1.5535, running_loss=1.5696, LR=0.000100
[2025-08-26 10:10:34,078][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007608] [Batch 00201/00823] [00:02:26/00:07:34, 0.730s/it]: train_loss_raw=1.6287, running_loss=1.5686, LR=0.000100
[2025-08-26 10:10:39,863][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007616] [Batch 00209/00823] [00:02:32/00:07:28, 0.730s/it]: train_loss_raw=1.5735, running_loss=1.5675, LR=0.000100
[2025-08-26 10:10:45,683][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007624] [Batch 00217/00823] [00:02:38/00:07:22, 0.730s/it]: train_loss_raw=1.5599, running_loss=1.5652, LR=0.000100
[2025-08-26 10:10:51,459][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007632] [Batch 00225/00823] [00:02:44/00:07:16, 0.729s/it]: train_loss_raw=1.5315, running_loss=1.5635, LR=0.000100
[2025-08-26 10:10:57,119][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007640] [Batch 00233/00823] [00:02:49/00:07:09, 0.729s/it]: train_loss_raw=1.5667, running_loss=1.5616, LR=0.000100
[2025-08-26 10:11:02,878][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007648] [Batch 00241/00823] [00:02:55/00:07:03, 0.728s/it]: train_loss_raw=1.6028, running_loss=1.5611, LR=0.000100
[2025-08-26 10:11:09,008][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007656] [Batch 00249/00823] [00:03:01/00:06:58, 0.730s/it]: train_loss_raw=1.5582, running_loss=1.5610, LR=0.000100
[2025-08-26 10:11:14,853][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007664] [Batch 00257/00823] [00:03:07/00:06:52, 0.730s/it]: train_loss_raw=1.5077, running_loss=1.5628, LR=0.000100
[2025-08-26 10:11:20,609][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007672] [Batch 00265/00823] [00:03:13/00:06:46, 0.729s/it]: train_loss_raw=1.5056, running_loss=1.5605, LR=0.000100
[2025-08-26 10:11:26,398][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007680] [Batch 00273/00823] [00:03:19/00:06:41, 0.729s/it]: train_loss_raw=1.5711, running_loss=1.5602, LR=0.000100
[2025-08-26 10:11:32,313][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007688] [Batch 00281/00823] [00:03:24/00:06:35, 0.729s/it]: train_loss_raw=1.5132, running_loss=1.5598, LR=0.000100
[2025-08-26 10:11:38,207][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007696] [Batch 00289/00823] [00:03:30/00:06:29, 0.730s/it]: train_loss_raw=1.5055, running_loss=1.5590, LR=0.000100
[2025-08-26 10:11:44,308][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007704] [Batch 00297/00823] [00:03:36/00:06:24, 0.731s/it]: train_loss_raw=1.5143, running_loss=1.5570, LR=0.000100
[2025-08-26 10:11:50,341][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007712] [Batch 00305/00823] [00:03:43/00:06:18, 0.731s/it]: train_loss_raw=1.6410, running_loss=1.5580, LR=0.000100
[2025-08-26 10:11:56,408][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007720] [Batch 00313/00823] [00:03:49/00:06:13, 0.732s/it]: train_loss_raw=1.6268, running_loss=1.5579, LR=0.000100
[2025-08-26 10:12:02,456][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007728] [Batch 00321/00823] [00:03:55/00:06:07, 0.732s/it]: train_loss_raw=1.5270, running_loss=1.5576, LR=0.000100
[2025-08-26 10:12:08,568][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007736] [Batch 00329/00823] [00:04:01/00:06:02, 0.733s/it]: train_loss_raw=1.5800, running_loss=1.5578, LR=0.000100
[2025-08-26 10:12:14,654][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007744] [Batch 00337/00823] [00:04:07/00:05:56, 0.734s/it]: train_loss_raw=1.4439, running_loss=1.5565, LR=0.000100
[2025-08-26 10:12:20,756][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007752] [Batch 00345/00823] [00:04:13/00:05:51, 0.735s/it]: train_loss_raw=1.5813, running_loss=1.5542, LR=0.000100
[2025-08-26 10:12:26,862][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007760] [Batch 00353/00823] [00:04:19/00:05:45, 0.735s/it]: train_loss_raw=1.5750, running_loss=1.5537, LR=0.000100
[2025-08-26 10:12:32,938][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007768] [Batch 00361/00823] [00:04:25/00:05:39, 0.736s/it]: train_loss_raw=1.4954, running_loss=1.5535, LR=0.000100
[2025-08-26 10:12:39,019][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007776] [Batch 00369/00823] [00:04:31/00:05:34, 0.736s/it]: train_loss_raw=1.5117, running_loss=1.5553, LR=0.000100
[2025-08-26 10:12:45,107][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007784] [Batch 00377/00823] [00:04:37/00:05:28, 0.737s/it]: train_loss_raw=1.5512, running_loss=1.5554, LR=0.000100
[2025-08-26 10:12:51,086][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007792] [Batch 00385/00823] [00:04:43/00:05:22, 0.737s/it]: train_loss_raw=1.5683, running_loss=1.5553, LR=0.000100
[2025-08-26 10:12:57,252][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007800] [Batch 00393/00823] [00:04:49/00:05:17, 0.738s/it]: train_loss_raw=1.5513, running_loss=1.5546, LR=0.000100
[2025-08-26 10:13:03,313][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007808] [Batch 00401/00823] [00:04:55/00:05:11, 0.738s/it]: train_loss_raw=1.3771, running_loss=1.5537, LR=0.000100
[2025-08-26 10:13:09,425][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007816] [Batch 00409/00823] [00:05:02/00:05:05, 0.739s/it]: train_loss_raw=1.4073, running_loss=1.5518, LR=0.000100
[2025-08-26 10:13:15,483][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007824] [Batch 00417/00823] [00:05:08/00:05:00, 0.739s/it]: train_loss_raw=1.5073, running_loss=1.5498, LR=0.000100
[2025-08-26 10:13:21,571][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007832] [Batch 00425/00823] [00:05:14/00:04:54, 0.739s/it]: train_loss_raw=1.6128, running_loss=1.5505, LR=0.000100
[2025-08-26 10:13:27,869][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007840] [Batch 00433/00823] [00:05:20/00:04:48, 0.740s/it]: train_loss_raw=1.5488, running_loss=1.5509, LR=0.000100
[2025-08-26 10:13:33,862][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007848] [Batch 00441/00823] [00:05:26/00:04:42, 0.740s/it]: train_loss_raw=1.5468, running_loss=1.5524, LR=0.000100
[2025-08-26 10:13:39,886][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007856] [Batch 00449/00823] [00:05:32/00:04:37, 0.741s/it]: train_loss_raw=1.5885, running_loss=1.5513, LR=0.000100
[2025-08-26 10:13:46,078][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007864] [Batch 00457/00823] [00:05:38/00:04:31, 0.741s/it]: train_loss_raw=1.5888, running_loss=1.5528, LR=0.000100
[2025-08-26 10:13:52,173][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007872] [Batch 00465/00823] [00:05:44/00:04:25, 0.742s/it]: train_loss_raw=1.5890, running_loss=1.5542, LR=0.000100
[2025-08-26 10:13:58,261][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007880] [Batch 00473/00823] [00:05:50/00:04:19, 0.742s/it]: train_loss_raw=1.5453, running_loss=1.5535, LR=0.000100
[2025-08-26 10:14:04,344][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007888] [Batch 00481/00823] [00:05:57/00:04:13, 0.742s/it]: train_loss_raw=1.5650, running_loss=1.5516, LR=0.000100
[2025-08-26 10:14:10,439][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007896] [Batch 00489/00823] [00:06:03/00:04:08, 0.743s/it]: train_loss_raw=1.5204, running_loss=1.5498, LR=0.000100
[2025-08-26 10:14:16,474][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007904] [Batch 00497/00823] [00:06:09/00:04:02, 0.743s/it]: train_loss_raw=1.5801, running_loss=1.5509, LR=0.000100
[2025-08-26 10:14:22,543][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007912] [Batch 00505/00823] [00:06:15/00:03:56, 0.743s/it]: train_loss_raw=1.4841, running_loss=1.5514, LR=0.000100
[2025-08-26 10:14:28,558][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007920] [Batch 00513/00823] [00:06:21/00:03:50, 0.743s/it]: train_loss_raw=1.5183, running_loss=1.5500, LR=0.000100
[2025-08-26 10:14:34,549][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007928] [Batch 00521/00823] [00:06:27/00:03:44, 0.743s/it]: train_loss_raw=1.4427, running_loss=1.5499, LR=0.000100
[2025-08-26 10:14:40,602][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007936] [Batch 00529/00823] [00:06:33/00:03:38, 0.743s/it]: train_loss_raw=1.5100, running_loss=1.5476, LR=0.000100
[2025-08-26 10:14:46,673][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007944] [Batch 00537/00823] [00:06:39/00:03:32, 0.744s/it]: train_loss_raw=1.5370, running_loss=1.5479, LR=0.000100
[2025-08-26 10:14:52,771][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007952] [Batch 00545/00823] [00:06:45/00:03:26, 0.744s/it]: train_loss_raw=1.5357, running_loss=1.5465, LR=0.000100
[2025-08-26 10:14:58,893][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007960] [Batch 00553/00823] [00:06:51/00:03:20, 0.744s/it]: train_loss_raw=1.5233, running_loss=1.5460, LR=0.000100
[2025-08-26 10:15:04,974][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007968] [Batch 00561/00823] [00:06:57/00:03:15, 0.744s/it]: train_loss_raw=1.5965, running_loss=1.5472, LR=0.000100
[2025-08-26 10:15:10,997][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007976] [Batch 00569/00823] [00:07:03/00:03:09, 0.745s/it]: train_loss_raw=1.5560, running_loss=1.5468, LR=0.000100
[2025-08-26 10:15:17,026][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007984] [Batch 00577/00823] [00:07:09/00:03:03, 0.745s/it]: train_loss_raw=1.5393, running_loss=1.5472, LR=0.000100
[2025-08-26 10:15:23,136][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 007992] [Batch 00585/00823] [00:07:15/00:02:57, 0.745s/it]: train_loss_raw=1.4445, running_loss=1.5447, LR=0.000100
[2025-08-26 10:15:29,180][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008000] [Batch 00593/00823] [00:07:21/00:02:51, 0.745s/it]: train_loss_raw=1.4940, running_loss=1.5446, LR=0.000100
[2025-08-26 10:15:40,237][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008008] [Batch 00601/00823] [00:07:32/00:02:47, 0.754s/it]: train_loss_raw=1.5534, running_loss=1.5439, LR=0.000100
[2025-08-26 10:15:46,290][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008016] [Batch 00609/00823] [00:07:38/00:02:41, 0.754s/it]: train_loss_raw=1.5003, running_loss=1.5440, LR=0.000100
[2025-08-26 10:15:52,327][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008024] [Batch 00617/00823] [00:07:44/00:02:35, 0.754s/it]: train_loss_raw=1.4711, running_loss=1.5423, LR=0.000100
[2025-08-26 10:15:58,351][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008032] [Batch 00625/00823] [00:07:51/00:02:29, 0.754s/it]: train_loss_raw=1.5971, running_loss=1.5413, LR=0.000100
[2025-08-26 10:16:04,461][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008040] [Batch 00633/00823] [00:07:57/00:02:23, 0.754s/it]: train_loss_raw=1.5408, running_loss=1.5413, LR=0.000100
[2025-08-26 10:16:10,592][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008048] [Batch 00641/00823] [00:08:03/00:02:17, 0.754s/it]: train_loss_raw=1.4703, running_loss=1.5408, LR=0.000100
[2025-08-26 10:16:16,590][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008056] [Batch 00649/00823] [00:08:09/00:02:11, 0.754s/it]: train_loss_raw=1.5659, running_loss=1.5396, LR=0.000100
[2025-08-26 10:16:22,593][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008064] [Batch 00657/00823] [00:08:15/00:02:05, 0.754s/it]: train_loss_raw=1.5378, running_loss=1.5419, LR=0.000100
[2025-08-26 10:16:28,710][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008072] [Batch 00665/00823] [00:08:21/00:01:59, 0.754s/it]: train_loss_raw=1.4817, running_loss=1.5405, LR=0.000100
[2025-08-26 10:16:34,805][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008080] [Batch 00673/00823] [00:08:27/00:01:53, 0.754s/it]: train_loss_raw=1.5682, running_loss=1.5409, LR=0.000100
[2025-08-26 10:16:40,900][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008088] [Batch 00681/00823] [00:08:33/00:01:47, 0.754s/it]: train_loss_raw=1.5303, running_loss=1.5397, LR=0.000100
[2025-08-26 10:16:47,087][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008096] [Batch 00689/00823] [00:08:39/00:01:41, 0.754s/it]: train_loss_raw=1.5146, running_loss=1.5400, LR=0.000100
[2025-08-26 10:16:53,152][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008104] [Batch 00697/00823] [00:08:45/00:01:35, 0.754s/it]: train_loss_raw=1.5141, running_loss=1.5418, LR=0.000100
[2025-08-26 10:16:59,231][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008112] [Batch 00705/00823] [00:08:51/00:01:29, 0.754s/it]: train_loss_raw=1.5114, running_loss=1.5410, LR=0.000100
[2025-08-26 10:17:05,276][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008120] [Batch 00713/00823] [00:08:57/00:01:22, 0.754s/it]: train_loss_raw=1.5706, running_loss=1.5410, LR=0.000100
[2025-08-26 10:17:11,361][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008128] [Batch 00721/00823] [00:09:04/00:01:16, 0.755s/it]: train_loss_raw=1.5307, running_loss=1.5391, LR=0.000100
[2025-08-26 10:17:17,493][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008136] [Batch 00729/00823] [00:09:10/00:01:10, 0.755s/it]: train_loss_raw=1.5707, running_loss=1.5396, LR=0.000100
[2025-08-26 10:17:23,561][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008144] [Batch 00737/00823] [00:09:16/00:01:04, 0.755s/it]: train_loss_raw=1.6671, running_loss=1.5412, LR=0.000100
[2025-08-26 10:17:29,639][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008152] [Batch 00745/00823] [00:09:22/00:00:58, 0.755s/it]: train_loss_raw=1.5352, running_loss=1.5403, LR=0.000100
[2025-08-26 10:17:35,518][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008160] [Batch 00753/00823] [00:09:28/00:00:52, 0.755s/it]: train_loss_raw=1.5322, running_loss=1.5396, LR=0.000100
[2025-08-26 10:17:41,553][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008168] [Batch 00761/00823] [00:09:34/00:00:46, 0.755s/it]: train_loss_raw=1.4461, running_loss=1.5389, LR=0.000100
[2025-08-26 10:17:47,677][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008176] [Batch 00769/00823] [00:09:40/00:00:40, 0.755s/it]: train_loss_raw=1.6393, running_loss=1.5388, LR=0.000100
[2025-08-26 10:17:53,820][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008184] [Batch 00777/00823] [00:09:46/00:00:34, 0.755s/it]: train_loss_raw=1.5231, running_loss=1.5390, LR=0.000100
[2025-08-26 10:17:59,891][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008192] [Batch 00785/00823] [00:09:52/00:00:28, 0.755s/it]: train_loss_raw=1.4846, running_loss=1.5382, LR=0.000100
[2025-08-26 10:18:05,906][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008200] [Batch 00793/00823] [00:09:58/00:00:22, 0.755s/it]: train_loss_raw=1.5471, running_loss=1.5371, LR=0.000100
[2025-08-26 10:18:11,869][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008208] [Batch 00801/00823] [00:10:04/00:00:16, 0.755s/it]: train_loss_raw=1.5512, running_loss=1.5380, LR=0.000100
[2025-08-26 10:18:17,962][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008216] [Batch 00809/00823] [00:10:10/00:00:10, 0.755s/it]: train_loss_raw=1.4951, running_loss=1.5377, LR=0.000100
[2025-08-26 10:18:24,025][__main__][INFO] - [TRAIN] [Epoch 09/29 Step 008224] [Batch 00817/00823] [00:10:16/00:00:04, 0.755s/it]: train_loss_raw=1.5937, running_loss=1.5379, LR=0.000100
[2025-08-26 10:18:34,095][__main__][INFO] - [VALIDATION] [Epoch 09/29] Starting validation.
[2025-08-26 10:18:45,066][__main__][INFO] - [VALIDATION] [Epoch 09/29 Step 008231] [Batch 00007/00013] [00:00:10/00:00:06, 1.371s/it]
[2025-08-26 10:18:52,063][__main__][INFO] - [VALIDATION] [Epoch 09/29] train_loss=1.53531, valid_loss=1.57606
[2025-08-26 10:18:52,063][__main__][INFO] - [VALIDATION] [Epoch 09/29] Metrics:
[2025-08-26 10:18:52,063][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_er      0.673
[2025-08-26 10:18:52,063][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_prec    0.043
[2025-08-26 10:18:52,063][__main__][INFO] - [VALIDATION] [Epoch 09/29] - aa_recall  0.044
[2025-08-26 10:18:52,064][__main__][INFO] - [VALIDATION] [Epoch 09/29] - pep_recall 0.005
[2025-08-26 10:18:52,065][__main__][INFO] - [TRAIN] [Epoch 09/29] Epoch complete, total time 01:46:15, remaining time 03:32:31, 00:10:37 per epoch
[2025-08-26 10:18:54,203][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008232] [Batch 00002/00823] [00:00:00/00:06:35, 0.482s/it]: train_loss_raw=1.5131, running_loss=1.5083, LR=0.000100
[2025-08-26 10:19:00,203][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008240] [Batch 00010/00823] [00:00:06/00:09:26, 0.697s/it]: train_loss_raw=1.5243, running_loss=1.5077, LR=0.000100
[2025-08-26 10:19:06,229][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008248] [Batch 00018/00823] [00:00:12/00:09:40, 0.722s/it]: train_loss_raw=1.5364, running_loss=1.5081, LR=0.000100
[2025-08-26 10:19:12,321][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008256] [Batch 00026/00823] [00:00:19/00:09:44, 0.734s/it]: train_loss_raw=1.5279, running_loss=1.5057, LR=0.000100
[2025-08-26 10:19:18,475][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008264] [Batch 00034/00823] [00:00:25/00:09:45, 0.742s/it]: train_loss_raw=1.4082, running_loss=1.5022, LR=0.000100
[2025-08-26 10:19:24,591][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008272] [Batch 00042/00823] [00:00:31/00:09:43, 0.747s/it]: train_loss_raw=1.4775, running_loss=1.5008, LR=0.000100
[2025-08-26 10:19:30,757][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008280] [Batch 00050/00823] [00:00:37/00:09:40, 0.750s/it]: train_loss_raw=1.4763, running_loss=1.4983, LR=0.000100
[2025-08-26 10:19:36,830][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008288] [Batch 00058/00823] [00:00:43/00:09:34, 0.752s/it]: train_loss_raw=1.5474, running_loss=1.4981, LR=0.000100
[2025-08-26 10:19:42,825][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008296] [Batch 00066/00823] [00:00:49/00:09:28, 0.751s/it]: train_loss_raw=1.4680, running_loss=1.4966, LR=0.000100
[2025-08-26 10:19:48,886][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008304] [Batch 00074/00823] [00:00:55/00:09:23, 0.752s/it]: train_loss_raw=1.3381, running_loss=1.4978, LR=0.000100
[2025-08-26 10:19:54,944][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008312] [Batch 00082/00823] [00:01:01/00:09:17, 0.753s/it]: train_loss_raw=1.5161, running_loss=1.4967, LR=0.000100
[2025-08-26 10:20:00,989][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008320] [Batch 00090/00823] [00:01:07/00:09:11, 0.753s/it]: train_loss_raw=1.4526, running_loss=1.4975, LR=0.000100
[2025-08-26 10:20:07,067][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008328] [Batch 00098/00823] [00:01:13/00:09:06, 0.753s/it]: train_loss_raw=1.4852, running_loss=1.4961, LR=0.000100
[2025-08-26 10:20:13,128][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008336] [Batch 00106/00823] [00:01:19/00:09:00, 0.754s/it]: train_loss_raw=1.5519, running_loss=1.4974, LR=0.000100
[2025-08-26 10:20:19,289][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008344] [Batch 00114/00823] [00:01:26/00:08:55, 0.755s/it]: train_loss_raw=1.4906, running_loss=1.4977, LR=0.000100
[2025-08-26 10:20:25,346][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008352] [Batch 00122/00823] [00:01:32/00:08:49, 0.755s/it]: train_loss_raw=1.4230, running_loss=1.4954, LR=0.000100
[2025-08-26 10:20:31,379][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008360] [Batch 00130/00823] [00:01:38/00:08:43, 0.755s/it]: train_loss_raw=1.5386, running_loss=1.4975, LR=0.000100
[2025-08-26 10:20:37,472][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008368] [Batch 00138/00823] [00:01:44/00:08:37, 0.755s/it]: train_loss_raw=1.4473, running_loss=1.4968, LR=0.000100
[2025-08-26 10:20:43,669][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008376] [Batch 00146/00823] [00:01:50/00:08:32, 0.756s/it]: train_loss_raw=1.5756, running_loss=1.4952, LR=0.000100
[2025-08-26 10:20:49,778][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008384] [Batch 00154/00823] [00:01:56/00:08:26, 0.757s/it]: train_loss_raw=1.4512, running_loss=1.4949, LR=0.000100
[2025-08-26 10:20:55,795][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008392] [Batch 00162/00823] [00:02:02/00:08:20, 0.757s/it]: train_loss_raw=1.4716, running_loss=1.4952, LR=0.000100
[2025-08-26 10:21:01,869][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008400] [Batch 00170/00823] [00:02:08/00:08:14, 0.757s/it]: train_loss_raw=1.4823, running_loss=1.4930, LR=0.000100
[2025-08-26 10:21:07,953][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008408] [Batch 00178/00823] [00:02:14/00:08:08, 0.757s/it]: train_loss_raw=1.4239, running_loss=1.4909, LR=0.000100
[2025-08-26 10:21:14,010][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008416] [Batch 00186/00823] [00:02:20/00:08:02, 0.757s/it]: train_loss_raw=1.4937, running_loss=1.4931, LR=0.000100
[2025-08-26 10:21:19,987][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008424] [Batch 00194/00823] [00:02:26/00:07:55, 0.756s/it]: train_loss_raw=1.4597, running_loss=1.4945, LR=0.000100
[2025-08-26 10:21:26,004][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008432] [Batch 00202/00823] [00:02:32/00:07:49, 0.756s/it]: train_loss_raw=1.5109, running_loss=1.4959, LR=0.000100
[2025-08-26 10:21:32,070][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008440] [Batch 00210/00823] [00:02:38/00:07:43, 0.756s/it]: train_loss_raw=1.4342, running_loss=1.4951, LR=0.000100
[2025-08-26 10:21:38,112][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008448] [Batch 00218/00823] [00:02:44/00:07:37, 0.756s/it]: train_loss_raw=1.4133, running_loss=1.4941, LR=0.000100
[2025-08-26 10:21:44,186][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008456] [Batch 00226/00823] [00:02:50/00:07:31, 0.756s/it]: train_loss_raw=1.4747, running_loss=1.4947, LR=0.000100
[2025-08-26 10:21:50,182][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008464] [Batch 00234/00823] [00:02:56/00:07:25, 0.756s/it]: train_loss_raw=1.5381, running_loss=1.4950, LR=0.000100
[2025-08-26 10:21:56,197][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008472] [Batch 00242/00823] [00:03:02/00:07:19, 0.756s/it]: train_loss_raw=1.4347, running_loss=1.4956, LR=0.000100
[2025-08-26 10:22:02,281][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008480] [Batch 00250/00823] [00:03:09/00:07:13, 0.756s/it]: train_loss_raw=1.5204, running_loss=1.4963, LR=0.000100
[2025-08-26 10:22:08,331][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008488] [Batch 00258/00823] [00:03:15/00:07:07, 0.756s/it]: train_loss_raw=1.5047, running_loss=1.4967, LR=0.000100
[2025-08-26 10:22:14,411][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008496] [Batch 00266/00823] [00:03:21/00:07:01, 0.756s/it]: train_loss_raw=1.4162, running_loss=1.4940, LR=0.000100
[2025-08-26 10:22:20,445][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008504] [Batch 00274/00823] [00:03:27/00:06:55, 0.756s/it]: train_loss_raw=1.4665, running_loss=1.4917, LR=0.000100
[2025-08-26 10:22:26,473][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008512] [Batch 00282/00823] [00:03:33/00:06:49, 0.756s/it]: train_loss_raw=1.4526, running_loss=1.4919, LR=0.000100
[2025-08-26 10:22:32,538][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008520] [Batch 00290/00823] [00:03:39/00:06:43, 0.756s/it]: train_loss_raw=1.4158, running_loss=1.4933, LR=0.000100
[2025-08-26 10:22:38,595][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008528] [Batch 00298/00823] [00:03:45/00:06:37, 0.756s/it]: train_loss_raw=1.4876, running_loss=1.4909, LR=0.000100
[2025-08-26 10:22:44,724][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008536] [Batch 00306/00823] [00:03:51/00:06:31, 0.756s/it]: train_loss_raw=1.5594, running_loss=1.4908, LR=0.000100
[2025-08-26 10:22:50,819][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008544] [Batch 00314/00823] [00:03:57/00:06:25, 0.757s/it]: train_loss_raw=1.5408, running_loss=1.4885, LR=0.000100
[2025-08-26 10:22:56,949][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008552] [Batch 00322/00823] [00:04:03/00:06:19, 0.757s/it]: train_loss_raw=1.4492, running_loss=1.4876, LR=0.000100
[2025-08-26 10:23:03,026][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008560] [Batch 00330/00823] [00:04:09/00:06:13, 0.757s/it]: train_loss_raw=1.4899, running_loss=1.4883, LR=0.000100
[2025-08-26 10:23:09,088][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008568] [Batch 00338/00823] [00:04:15/00:06:07, 0.757s/it]: train_loss_raw=1.4596, running_loss=1.4867, LR=0.000100
[2025-08-26 10:23:15,221][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008576] [Batch 00346/00823] [00:04:21/00:06:01, 0.757s/it]: train_loss_raw=1.4247, running_loss=1.4876, LR=0.000100
[2025-08-26 10:23:21,354][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008584] [Batch 00354/00823] [00:04:28/00:05:55, 0.757s/it]: train_loss_raw=1.5082, running_loss=1.4881, LR=0.000100
[2025-08-26 10:23:27,393][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008592] [Batch 00362/00823] [00:04:34/00:05:49, 0.757s/it]: train_loss_raw=1.5327, running_loss=1.4896, LR=0.000100
[2025-08-26 10:23:33,458][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008600] [Batch 00370/00823] [00:04:40/00:05:43, 0.757s/it]: train_loss_raw=1.5013, running_loss=1.4882, LR=0.000100
[2025-08-26 10:23:39,526][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008608] [Batch 00378/00823] [00:04:46/00:05:37, 0.757s/it]: train_loss_raw=1.4888, running_loss=1.4872, LR=0.000100
[2025-08-26 10:23:45,660][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008616] [Batch 00386/00823] [00:04:52/00:05:31, 0.758s/it]: train_loss_raw=1.4717, running_loss=1.4877, LR=0.000100
[2025-08-26 10:23:51,757][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008624] [Batch 00394/00823] [00:04:58/00:05:25, 0.758s/it]: train_loss_raw=1.4670, running_loss=1.4858, LR=0.000100
[2025-08-26 10:23:57,785][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008632] [Batch 00402/00823] [00:05:04/00:05:18, 0.758s/it]: train_loss_raw=1.5424, running_loss=1.4867, LR=0.000100
[2025-08-26 10:24:03,892][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008640] [Batch 00410/00823] [00:05:10/00:05:12, 0.758s/it]: train_loss_raw=1.4806, running_loss=1.4871, LR=0.000100
[2025-08-26 10:24:09,856][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008648] [Batch 00418/00823] [00:05:16/00:05:06, 0.757s/it]: train_loss_raw=1.5535, running_loss=1.4870, LR=0.000100
[2025-08-26 10:24:15,816][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008656] [Batch 00426/00823] [00:05:22/00:05:00, 0.757s/it]: train_loss_raw=1.4968, running_loss=1.4876, LR=0.000100
[2025-08-26 10:24:21,830][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008664] [Batch 00434/00823] [00:05:28/00:04:54, 0.757s/it]: train_loss_raw=1.4493, running_loss=1.4869, LR=0.000100
[2025-08-26 10:24:27,891][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008672] [Batch 00442/00823] [00:05:34/00:04:48, 0.757s/it]: train_loss_raw=1.5535, running_loss=1.4860, LR=0.000100
[2025-08-26 10:24:33,975][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008680] [Batch 00450/00823] [00:05:40/00:04:42, 0.757s/it]: train_loss_raw=1.4440, running_loss=1.4863, LR=0.000100
[2025-08-26 10:24:40,034][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008688] [Batch 00458/00823] [00:05:46/00:04:36, 0.757s/it]: train_loss_raw=1.3759, running_loss=1.4835, LR=0.000100
[2025-08-26 10:24:46,091][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008696] [Batch 00466/00823] [00:05:52/00:04:30, 0.757s/it]: train_loss_raw=1.4728, running_loss=1.4828, LR=0.000100
[2025-08-26 10:24:52,158][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008704] [Batch 00474/00823] [00:05:58/00:04:24, 0.757s/it]: train_loss_raw=1.4367, running_loss=1.4836, LR=0.000100
[2025-08-26 10:24:58,175][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008712] [Batch 00482/00823] [00:06:04/00:04:18, 0.757s/it]: train_loss_raw=1.5072, running_loss=1.4845, LR=0.000100
[2025-08-26 10:25:04,196][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008720] [Batch 00490/00823] [00:06:10/00:04:12, 0.757s/it]: train_loss_raw=1.4262, running_loss=1.4811, LR=0.000100
[2025-08-26 10:25:10,333][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008728] [Batch 00498/00823] [00:06:17/00:04:06, 0.757s/it]: train_loss_raw=1.5108, running_loss=1.4816, LR=0.000100
[2025-08-26 10:25:16,448][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008736] [Batch 00506/00823] [00:06:23/00:04:00, 0.757s/it]: train_loss_raw=1.4184, running_loss=1.4822, LR=0.000100
[2025-08-26 10:25:22,503][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008744] [Batch 00514/00823] [00:06:29/00:03:54, 0.757s/it]: train_loss_raw=1.5074, running_loss=1.4818, LR=0.000100
[2025-08-26 10:25:28,519][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008752] [Batch 00522/00823] [00:06:35/00:03:47, 0.757s/it]: train_loss_raw=1.4953, running_loss=1.4818, LR=0.000100
[2025-08-26 10:25:34,562][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008760] [Batch 00530/00823] [00:06:41/00:03:41, 0.757s/it]: train_loss_raw=1.5447, running_loss=1.4848, LR=0.000100
[2025-08-26 10:25:40,612][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008768] [Batch 00538/00823] [00:06:47/00:03:35, 0.757s/it]: train_loss_raw=1.4626, running_loss=1.4860, LR=0.000100
[2025-08-26 10:25:46,695][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008776] [Batch 00546/00823] [00:06:53/00:03:29, 0.757s/it]: train_loss_raw=1.5132, running_loss=1.4878, LR=0.000100
[2025-08-26 10:25:52,711][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008784] [Batch 00554/00823] [00:06:59/00:03:23, 0.757s/it]: train_loss_raw=1.5862, running_loss=1.4927, LR=0.000100
[2025-08-26 10:25:58,774][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008792] [Batch 00562/00823] [00:07:05/00:03:17, 0.757s/it]: train_loss_raw=1.4245, running_loss=1.4939, LR=0.000100
[2025-08-26 10:26:04,835][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008800] [Batch 00570/00823] [00:07:11/00:03:11, 0.757s/it]: train_loss_raw=1.5187, running_loss=1.4927, LR=0.000100
[2025-08-26 10:26:10,908][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008808] [Batch 00578/00823] [00:07:17/00:03:05, 0.757s/it]: train_loss_raw=1.4965, running_loss=1.4925, LR=0.000100
[2025-08-26 10:26:16,977][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008816] [Batch 00586/00823] [00:07:23/00:02:59, 0.757s/it]: train_loss_raw=1.4388, running_loss=1.4947, LR=0.000100
[2025-08-26 10:26:23,026][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008824] [Batch 00594/00823] [00:07:29/00:02:53, 0.757s/it]: train_loss_raw=1.5451, running_loss=1.4962, LR=0.000100
[2025-08-26 10:26:29,049][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008832] [Batch 00602/00823] [00:07:35/00:02:47, 0.757s/it]: train_loss_raw=1.4956, running_loss=1.4958, LR=0.000100
[2025-08-26 10:26:35,110][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008840] [Batch 00610/00823] [00:07:41/00:02:41, 0.757s/it]: train_loss_raw=1.4196, running_loss=1.4958, LR=0.000100
[2025-08-26 10:26:41,153][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008848] [Batch 00618/00823] [00:07:47/00:02:35, 0.757s/it]: train_loss_raw=1.3767, running_loss=1.4930, LR=0.000100
[2025-08-26 10:26:47,214][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008856] [Batch 00626/00823] [00:07:53/00:02:29, 0.757s/it]: train_loss_raw=1.5393, running_loss=1.4912, LR=0.000100
[2025-08-26 10:26:53,281][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008864] [Batch 00634/00823] [00:08:00/00:02:23, 0.757s/it]: train_loss_raw=1.4392, running_loss=1.4905, LR=0.000100
[2025-08-26 10:26:59,373][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008872] [Batch 00642/00823] [00:08:06/00:02:17, 0.757s/it]: train_loss_raw=1.4815, running_loss=1.4909, LR=0.000100
[2025-08-26 10:27:05,511][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008880] [Batch 00650/00823] [00:08:12/00:02:11, 0.757s/it]: train_loss_raw=1.4881, running_loss=1.4900, LR=0.000100
[2025-08-26 10:27:11,638][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008888] [Batch 00658/00823] [00:08:18/00:02:04, 0.757s/it]: train_loss_raw=1.4941, running_loss=1.4883, LR=0.000100
[2025-08-26 10:27:17,662][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008896] [Batch 00666/00823] [00:08:24/00:01:58, 0.757s/it]: train_loss_raw=1.4639, running_loss=1.4853, LR=0.000100
[2025-08-26 10:27:23,692][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008904] [Batch 00674/00823] [00:08:30/00:01:52, 0.757s/it]: train_loss_raw=1.4335, running_loss=1.4810, LR=0.000100
[2025-08-26 10:27:29,728][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008912] [Batch 00682/00823] [00:08:36/00:01:46, 0.757s/it]: train_loss_raw=1.5389, running_loss=1.4832, LR=0.000100
[2025-08-26 10:27:35,760][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008920] [Batch 00690/00823] [00:08:42/00:01:40, 0.757s/it]: train_loss_raw=1.4691, running_loss=1.4861, LR=0.000100
[2025-08-26 10:27:41,450][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008928] [Batch 00698/00823] [00:08:48/00:01:34, 0.757s/it]: train_loss_raw=1.5452, running_loss=1.4861, LR=0.000100
[2025-08-26 10:27:47,278][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008936] [Batch 00706/00823] [00:08:54/00:01:28, 0.756s/it]: train_loss_raw=1.4673, running_loss=1.4857, LR=0.000100
[2025-08-26 10:27:53,293][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008944] [Batch 00714/00823] [00:09:00/00:01:22, 0.756s/it]: train_loss_raw=1.5093, running_loss=1.4856, LR=0.000100
[2025-08-26 10:27:59,372][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008952] [Batch 00722/00823] [00:09:06/00:01:16, 0.756s/it]: train_loss_raw=1.4830, running_loss=1.4875, LR=0.000100
[2025-08-26 10:28:05,450][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008960] [Batch 00730/00823] [00:09:12/00:01:10, 0.756s/it]: train_loss_raw=1.4325, running_loss=1.4893, LR=0.000100
[2025-08-26 10:28:11,509][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008968] [Batch 00738/00823] [00:09:18/00:01:04, 0.756s/it]: train_loss_raw=1.4642, running_loss=1.4915, LR=0.000100
[2025-08-26 10:28:17,587][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008976] [Batch 00746/00823] [00:09:24/00:00:58, 0.756s/it]: train_loss_raw=1.5045, running_loss=1.4899, LR=0.000100
[2025-08-26 10:28:23,681][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008984] [Batch 00754/00823] [00:09:30/00:00:52, 0.757s/it]: train_loss_raw=1.5364, running_loss=1.4924, LR=0.000100
[2025-08-26 10:28:29,713][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 008992] [Batch 00762/00823] [00:09:36/00:00:46, 0.757s/it]: train_loss_raw=1.5450, running_loss=1.4958, LR=0.000100
[2025-08-26 10:28:35,834][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009000] [Batch 00770/00823] [00:09:42/00:00:40, 0.757s/it]: train_loss_raw=1.4840, running_loss=1.4941, LR=0.000100
[2025-08-26 10:28:41,906][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009008] [Batch 00778/00823] [00:09:48/00:00:34, 0.757s/it]: train_loss_raw=1.5145, running_loss=1.4947, LR=0.000100
[2025-08-26 10:28:48,029][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009016] [Batch 00786/00823] [00:09:54/00:00:27, 0.757s/it]: train_loss_raw=1.5870, running_loss=1.4969, LR=0.000100
[2025-08-26 10:28:54,023][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009024] [Batch 00794/00823] [00:10:00/00:00:21, 0.757s/it]: train_loss_raw=1.4899, running_loss=1.4964, LR=0.000100
[2025-08-26 10:29:00,094][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009032] [Batch 00802/00823] [00:10:06/00:00:15, 0.757s/it]: train_loss_raw=1.4503, running_loss=1.4954, LR=0.000100
[2025-08-26 10:29:06,170][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009040] [Batch 00810/00823] [00:10:12/00:00:09, 0.757s/it]: train_loss_raw=1.4063, running_loss=1.4931, LR=0.000100
[2025-08-26 10:29:12,264][__main__][INFO] - [TRAIN] [Epoch 10/29 Step 009048] [Batch 00818/00823] [00:10:19/00:00:03, 0.757s/it]: train_loss_raw=1.3503, running_loss=1.4885, LR=0.000100
[2025-08-26 10:29:16,246][__main__][INFO] - [VALIDATION] [Epoch 10/29] Starting validation.
[2025-08-26 10:29:27,381][__main__][INFO] - [VALIDATION] [Epoch 10/29 Step 009054] [Batch 00007/00013] [00:00:11/00:00:06, 1.392s/it]
[2025-08-26 10:29:34,330][__main__][INFO] - [VALIDATION] [Epoch 10/29] train_loss=1.48695, valid_loss=1.57042
[2025-08-26 10:29:34,330][__main__][INFO] - [VALIDATION] [Epoch 10/29] Metrics:
[2025-08-26 10:29:34,330][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_er      0.676
[2025-08-26 10:29:34,330][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_prec    0.043
[2025-08-26 10:29:34,330][__main__][INFO] - [VALIDATION] [Epoch 10/29] - aa_recall  0.045
[2025-08-26 10:29:34,330][__main__][INFO] - [VALIDATION] [Epoch 10/29] - pep_recall 0.007
[2025-08-26 10:29:34,332][__main__][INFO] - [TRAIN] [Epoch 10/29] Epoch complete, total time 01:56:58, remaining time 03:22:02, 00:10:38 per epoch
[2025-08-26 10:29:37,372][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009056] [Batch 00003/00823] [00:00:01/00:07:48, 0.572s/it]: train_loss_raw=1.4440, running_loss=1.4509, LR=0.000100
[2025-08-26 10:29:43,469][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009064] [Batch 00011/00823] [00:00:07/00:09:36, 0.710s/it]: train_loss_raw=1.4921, running_loss=1.4539, LR=0.000100
[2025-08-26 10:29:49,604][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009072] [Batch 00019/00823] [00:00:13/00:09:50, 0.734s/it]: train_loss_raw=1.5570, running_loss=1.4564, LR=0.000100
[2025-08-26 10:29:55,705][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009080] [Batch 00027/00823] [00:00:20/00:09:51, 0.743s/it]: train_loss_raw=1.4689, running_loss=1.4571, LR=0.000100
[2025-08-26 10:30:01,807][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009088] [Batch 00035/00823] [00:00:26/00:09:48, 0.747s/it]: train_loss_raw=1.4912, running_loss=1.4583, LR=0.000100
[2025-08-26 10:30:07,910][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009096] [Batch 00043/00823] [00:00:32/00:09:45, 0.750s/it]: train_loss_raw=1.4768, running_loss=1.4576, LR=0.000100
[2025-08-26 10:30:14,024][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009104] [Batch 00051/00823] [00:00:38/00:09:40, 0.752s/it]: train_loss_raw=1.4891, running_loss=1.4566, LR=0.000100
[2025-08-26 10:30:20,119][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009112] [Batch 00059/00823] [00:00:44/00:09:35, 0.754s/it]: train_loss_raw=1.4976, running_loss=1.4546, LR=0.000100
[2025-08-26 10:30:26,202][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009120] [Batch 00067/00823] [00:00:50/00:09:30, 0.754s/it]: train_loss_raw=1.4526, running_loss=1.4565, LR=0.000100
[2025-08-26 10:30:32,298][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009128] [Batch 00075/00823] [00:00:56/00:09:24, 0.755s/it]: train_loss_raw=1.5449, running_loss=1.4587, LR=0.000100
[2025-08-26 10:30:38,374][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009136] [Batch 00083/00823] [00:01:02/00:09:19, 0.756s/it]: train_loss_raw=1.4159, running_loss=1.4598, LR=0.000100
[2025-08-26 10:30:44,436][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009144] [Batch 00091/00823] [00:01:08/00:09:13, 0.756s/it]: train_loss_raw=1.4353, running_loss=1.4605, LR=0.000100
[2025-08-26 10:30:50,459][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009152] [Batch 00099/00823] [00:01:14/00:09:07, 0.756s/it]: train_loss_raw=1.4700, running_loss=1.4619, LR=0.000100
[2025-08-26 10:30:56,511][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009160] [Batch 00107/00823] [00:01:20/00:09:01, 0.756s/it]: train_loss_raw=1.4486, running_loss=1.4619, LR=0.000100
[2025-08-26 10:31:02,599][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009168] [Batch 00115/00823] [00:01:26/00:08:55, 0.756s/it]: train_loss_raw=1.5659, running_loss=1.4634, LR=0.000100
[2025-08-26 10:31:08,696][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009176] [Batch 00123/00823] [00:01:33/00:08:49, 0.756s/it]: train_loss_raw=1.3989, running_loss=1.4612, LR=0.000100
[2025-08-26 10:31:14,805][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009184] [Batch 00131/00823] [00:01:39/00:08:43, 0.757s/it]: train_loss_raw=1.4848, running_loss=1.4642, LR=0.000100
[2025-08-26 10:31:20,949][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009192] [Batch 00139/00823] [00:01:45/00:08:38, 0.757s/it]: train_loss_raw=1.4962, running_loss=1.4648, LR=0.000100
[2025-08-26 10:31:27,042][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009200] [Batch 00147/00823] [00:01:51/00:08:32, 0.758s/it]: train_loss_raw=1.4835, running_loss=1.4651, LR=0.000100
[2025-08-26 10:31:33,117][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009208] [Batch 00155/00823] [00:01:57/00:08:26, 0.758s/it]: train_loss_raw=1.5333, running_loss=1.4670, LR=0.000100
[2025-08-26 10:31:39,175][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009216] [Batch 00163/00823] [00:02:03/00:08:20, 0.758s/it]: train_loss_raw=1.4484, running_loss=1.4671, LR=0.000100
[2025-08-26 10:31:45,259][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009224] [Batch 00171/00823] [00:02:09/00:08:14, 0.758s/it]: train_loss_raw=1.5211, running_loss=1.4687, LR=0.000100
[2025-08-26 10:31:51,366][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009232] [Batch 00179/00823] [00:02:15/00:08:08, 0.758s/it]: train_loss_raw=1.5376, running_loss=1.4692, LR=0.000100
[2025-08-26 10:31:57,522][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009240] [Batch 00187/00823] [00:02:21/00:08:02, 0.759s/it]: train_loss_raw=1.5541, running_loss=1.4698, LR=0.000100
[2025-08-26 10:32:03,626][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009248] [Batch 00195/00823] [00:02:27/00:07:56, 0.759s/it]: train_loss_raw=1.4619, running_loss=1.4699, LR=0.000100
[2025-08-26 10:32:09,738][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009256] [Batch 00203/00823] [00:02:34/00:07:50, 0.759s/it]: train_loss_raw=1.4955, running_loss=1.4698, LR=0.000100
[2025-08-26 10:32:15,728][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009264] [Batch 00211/00823] [00:02:40/00:07:44, 0.759s/it]: train_loss_raw=1.4379, running_loss=1.4705, LR=0.000100
[2025-08-26 10:32:21,744][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009272] [Batch 00219/00823] [00:02:46/00:07:38, 0.758s/it]: train_loss_raw=1.4854, running_loss=1.4740, LR=0.000100
[2025-08-26 10:32:27,827][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009280] [Batch 00227/00823] [00:02:52/00:07:32, 0.758s/it]: train_loss_raw=1.4867, running_loss=1.4728, LR=0.000100
[2025-08-26 10:32:33,912][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009288] [Batch 00235/00823] [00:02:58/00:07:26, 0.759s/it]: train_loss_raw=1.5056, running_loss=1.4740, LR=0.000100
[2025-08-26 10:32:39,946][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009296] [Batch 00243/00823] [00:03:04/00:07:19, 0.758s/it]: train_loss_raw=1.4687, running_loss=1.4737, LR=0.000100
[2025-08-26 10:32:45,997][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009304] [Batch 00251/00823] [00:03:10/00:07:13, 0.758s/it]: train_loss_raw=1.4514, running_loss=1.4729, LR=0.000100
[2025-08-26 10:32:52,084][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009312] [Batch 00259/00823] [00:03:16/00:07:07, 0.758s/it]: train_loss_raw=1.5068, running_loss=1.4732, LR=0.000100
[2025-08-26 10:32:58,186][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009320] [Batch 00267/00823] [00:03:22/00:07:01, 0.759s/it]: train_loss_raw=1.4391, running_loss=1.4732, LR=0.000100
[2025-08-26 10:33:04,297][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009328] [Batch 00275/00823] [00:03:28/00:06:55, 0.759s/it]: train_loss_raw=1.4459, running_loss=1.4722, LR=0.000100
[2025-08-26 10:33:10,397][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009336] [Batch 00283/00823] [00:03:34/00:06:49, 0.759s/it]: train_loss_raw=1.5192, running_loss=1.4705, LR=0.000100
[2025-08-26 10:33:16,506][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009344] [Batch 00291/00823] [00:03:40/00:06:43, 0.759s/it]: train_loss_raw=1.4386, running_loss=1.4696, LR=0.000100
[2025-08-26 10:33:22,670][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009352] [Batch 00299/00823] [00:03:47/00:06:37, 0.759s/it]: train_loss_raw=1.4806, running_loss=1.4686, LR=0.000100
[2025-08-26 10:33:28,850][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009360] [Batch 00307/00823] [00:03:53/00:06:31, 0.760s/it]: train_loss_raw=1.3952, running_loss=1.4691, LR=0.000100
[2025-08-26 10:33:34,978][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009368] [Batch 00315/00823] [00:03:59/00:06:25, 0.760s/it]: train_loss_raw=1.4069, running_loss=1.4672, LR=0.000100
[2025-08-26 10:33:41,103][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009376] [Batch 00323/00823] [00:04:05/00:06:19, 0.760s/it]: train_loss_raw=1.4551, running_loss=1.4664, LR=0.000100
[2025-08-26 10:33:47,138][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009384] [Batch 00331/00823] [00:04:11/00:06:13, 0.760s/it]: train_loss_raw=1.5582, running_loss=1.4682, LR=0.000100
[2025-08-26 10:33:53,156][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009392] [Batch 00339/00823] [00:04:17/00:06:07, 0.760s/it]: train_loss_raw=1.5751, running_loss=1.4689, LR=0.000100
[2025-08-26 10:33:59,105][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009400] [Batch 00347/00823] [00:04:23/00:06:01, 0.759s/it]: train_loss_raw=1.4438, running_loss=1.4689, LR=0.000100
[2025-08-26 10:34:05,083][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009408] [Batch 00355/00823] [00:04:29/00:05:55, 0.759s/it]: train_loss_raw=1.4686, running_loss=1.4689, LR=0.000100
[2025-08-26 10:34:11,067][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009416] [Batch 00363/00823] [00:04:35/00:05:49, 0.759s/it]: train_loss_raw=1.5257, running_loss=1.4705, LR=0.000100
[2025-08-26 10:34:17,201][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009424] [Batch 00371/00823] [00:04:41/00:05:43, 0.759s/it]: train_loss_raw=1.4169, running_loss=1.4731, LR=0.000100
[2025-08-26 10:34:23,240][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009432] [Batch 00379/00823] [00:04:47/00:05:36, 0.759s/it]: train_loss_raw=1.4522, running_loss=1.4732, LR=0.000100
[2025-08-26 10:34:29,335][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009440] [Batch 00387/00823] [00:04:53/00:05:30, 0.759s/it]: train_loss_raw=1.4197, running_loss=1.4724, LR=0.000100
[2025-08-26 10:34:35,405][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009448] [Batch 00395/00823] [00:04:59/00:05:24, 0.759s/it]: train_loss_raw=1.3907, running_loss=1.4706, LR=0.000100
[2025-08-26 10:34:41,467][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009456] [Batch 00403/00823] [00:05:05/00:05:18, 0.759s/it]: train_loss_raw=1.3976, running_loss=1.4749, LR=0.000100
[2025-08-26 10:34:47,476][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009464] [Batch 00411/00823] [00:05:11/00:05:12, 0.759s/it]: train_loss_raw=1.4240, running_loss=1.4757, LR=0.000100
[2025-08-26 10:34:53,571][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009472] [Batch 00419/00823] [00:05:17/00:05:06, 0.759s/it]: train_loss_raw=1.3666, running_loss=1.4700, LR=0.000100
[2025-08-26 10:34:59,678][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009480] [Batch 00427/00823] [00:05:24/00:05:00, 0.759s/it]: train_loss_raw=1.3804, running_loss=1.4691, LR=0.000100
[2025-08-26 10:35:05,820][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009488] [Batch 00435/00823] [00:05:30/00:04:54, 0.759s/it]: train_loss_raw=1.5019, running_loss=1.4671, LR=0.000100
[2025-08-26 10:35:11,974][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009496] [Batch 00443/00823] [00:05:36/00:04:48, 0.759s/it]: train_loss_raw=1.4873, running_loss=1.4665, LR=0.000100
[2025-08-26 10:35:18,115][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009504] [Batch 00451/00823] [00:05:42/00:04:42, 0.759s/it]: train_loss_raw=1.4720, running_loss=1.4671, LR=0.000100
[2025-08-26 10:35:23,847][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009512] [Batch 00459/00823] [00:05:48/00:04:36, 0.759s/it]: train_loss_raw=1.4166, running_loss=1.4656, LR=0.000100
[2025-08-26 10:35:29,860][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009520] [Batch 00467/00823] [00:05:54/00:04:30, 0.758s/it]: train_loss_raw=1.3984, running_loss=1.4658, LR=0.000100
[2025-08-26 10:35:35,835][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009528] [Batch 00475/00823] [00:06:00/00:04:23, 0.758s/it]: train_loss_raw=1.4744, running_loss=1.4685, LR=0.000100
[2025-08-26 10:35:41,847][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009536] [Batch 00483/00823] [00:06:06/00:04:17, 0.758s/it]: train_loss_raw=1.5576, running_loss=1.4664, LR=0.000100
[2025-08-26 10:35:48,006][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009544] [Batch 00491/00823] [00:06:12/00:04:11, 0.758s/it]: train_loss_raw=1.4741, running_loss=1.4655, LR=0.000100
[2025-08-26 10:35:54,067][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009552] [Batch 00499/00823] [00:06:18/00:04:05, 0.758s/it]: train_loss_raw=1.4931, running_loss=1.4649, LR=0.000100
[2025-08-26 10:36:00,193][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009560] [Batch 00507/00823] [00:06:24/00:03:59, 0.758s/it]: train_loss_raw=1.4925, running_loss=1.4633, LR=0.000100
[2025-08-26 10:36:06,426][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009568] [Batch 00515/00823] [00:06:30/00:03:53, 0.759s/it]: train_loss_raw=1.4507, running_loss=1.4644, LR=0.000100
[2025-08-26 10:36:12,544][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009576] [Batch 00523/00823] [00:06:36/00:03:47, 0.759s/it]: train_loss_raw=1.4736, running_loss=1.4656, LR=0.000100
[2025-08-26 10:36:18,622][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009584] [Batch 00531/00823] [00:06:42/00:03:41, 0.759s/it]: train_loss_raw=1.4111, running_loss=1.4645, LR=0.000100
[2025-08-26 10:36:24,721][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009592] [Batch 00539/00823] [00:06:49/00:03:35, 0.759s/it]: train_loss_raw=1.5077, running_loss=1.4618, LR=0.000100
[2025-08-26 10:36:30,823][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009600] [Batch 00547/00823] [00:06:55/00:03:29, 0.759s/it]: train_loss_raw=1.4967, running_loss=1.4634, LR=0.000100
[2025-08-26 10:36:36,883][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009608] [Batch 00555/00823] [00:07:01/00:03:23, 0.759s/it]: train_loss_raw=1.5342, running_loss=1.4599, LR=0.000100
[2025-08-26 10:36:42,955][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009616] [Batch 00563/00823] [00:07:07/00:03:17, 0.759s/it]: train_loss_raw=1.3638, running_loss=1.4577, LR=0.000100
[2025-08-26 10:36:49,097][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009624] [Batch 00571/00823] [00:07:13/00:03:11, 0.759s/it]: train_loss_raw=1.4724, running_loss=1.4572, LR=0.000100
[2025-08-26 10:36:55,204][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009632] [Batch 00579/00823] [00:07:19/00:03:05, 0.759s/it]: train_loss_raw=1.4802, running_loss=1.4568, LR=0.000100
[2025-08-26 10:37:01,314][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009640] [Batch 00587/00823] [00:07:25/00:02:59, 0.759s/it]: train_loss_raw=1.4040, running_loss=1.4565, LR=0.000100
[2025-08-26 10:37:07,347][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009648] [Batch 00595/00823] [00:07:31/00:02:53, 0.759s/it]: train_loss_raw=1.4689, running_loss=1.4563, LR=0.000100
[2025-08-26 10:37:13,491][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009656] [Batch 00603/00823] [00:07:37/00:02:47, 0.759s/it]: train_loss_raw=1.4329, running_loss=1.4553, LR=0.000100
[2025-08-26 10:37:19,558][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009664] [Batch 00611/00823] [00:07:43/00:02:40, 0.759s/it]: train_loss_raw=1.4165, running_loss=1.4560, LR=0.000100
[2025-08-26 10:37:25,639][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009672] [Batch 00619/00823] [00:07:49/00:02:34, 0.759s/it]: train_loss_raw=1.4069, running_loss=1.4563, LR=0.000100
[2025-08-26 10:37:31,714][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009680] [Batch 00627/00823] [00:07:56/00:02:28, 0.759s/it]: train_loss_raw=1.4248, running_loss=1.4566, LR=0.000100
[2025-08-26 10:37:37,797][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009688] [Batch 00635/00823] [00:08:02/00:02:22, 0.759s/it]: train_loss_raw=1.4433, running_loss=1.4580, LR=0.000100
[2025-08-26 10:37:43,949][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009696] [Batch 00643/00823] [00:08:08/00:02:16, 0.759s/it]: train_loss_raw=1.5235, running_loss=1.4597, LR=0.000100
[2025-08-26 10:37:50,011][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009704] [Batch 00651/00823] [00:08:14/00:02:10, 0.759s/it]: train_loss_raw=1.4583, running_loss=1.4570, LR=0.000100
[2025-08-26 10:37:56,038][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009712] [Batch 00659/00823] [00:08:20/00:02:04, 0.759s/it]: train_loss_raw=1.5347, running_loss=1.4584, LR=0.000100
[2025-08-26 10:38:02,107][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009720] [Batch 00667/00823] [00:08:26/00:01:58, 0.759s/it]: train_loss_raw=1.4386, running_loss=1.4568, LR=0.000100
[2025-08-26 10:38:08,249][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009728] [Batch 00675/00823] [00:08:32/00:01:52, 0.759s/it]: train_loss_raw=1.3798, running_loss=1.4574, LR=0.000100
[2025-08-26 10:38:14,376][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009736] [Batch 00683/00823] [00:08:38/00:01:46, 0.759s/it]: train_loss_raw=1.4453, running_loss=1.4582, LR=0.000100
[2025-08-26 10:38:20,484][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009744] [Batch 00691/00823] [00:08:44/00:01:40, 0.760s/it]: train_loss_raw=1.4415, running_loss=1.4573, LR=0.000100
[2025-08-26 10:38:26,534][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009752] [Batch 00699/00823] [00:08:50/00:01:34, 0.759s/it]: train_loss_raw=1.4346, running_loss=1.4586, LR=0.000100
[2025-08-26 10:38:32,619][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009760] [Batch 00707/00823] [00:08:56/00:01:28, 0.759s/it]: train_loss_raw=1.4225, running_loss=1.4569, LR=0.000100
[2025-08-26 10:38:38,702][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009768] [Batch 00715/00823] [00:09:03/00:01:22, 0.760s/it]: train_loss_raw=1.4272, running_loss=1.4582, LR=0.000100
[2025-08-26 10:38:44,767][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009776] [Batch 00723/00823] [00:09:09/00:01:15, 0.759s/it]: train_loss_raw=1.3767, running_loss=1.4573, LR=0.000100
[2025-08-26 10:38:50,895][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009784] [Batch 00731/00823] [00:09:15/00:01:09, 0.760s/it]: train_loss_raw=1.4900, running_loss=1.4561, LR=0.000100
[2025-08-26 10:38:56,951][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009792] [Batch 00739/00823] [00:09:21/00:01:03, 0.760s/it]: train_loss_raw=1.4082, running_loss=1.4583, LR=0.000100
[2025-08-26 10:39:02,926][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009800] [Batch 00747/00823] [00:09:27/00:00:57, 0.759s/it]: train_loss_raw=1.4537, running_loss=1.4556, LR=0.000100
[2025-08-26 10:39:08,981][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009808] [Batch 00755/00823] [00:09:33/00:00:51, 0.759s/it]: train_loss_raw=1.6330, running_loss=1.4572, LR=0.000100
[2025-08-26 10:39:15,004][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009816] [Batch 00763/00823] [00:09:39/00:00:45, 0.759s/it]: train_loss_raw=1.4501, running_loss=1.4572, LR=0.000100
[2025-08-26 10:39:21,057][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009824] [Batch 00771/00823] [00:09:45/00:00:39, 0.759s/it]: train_loss_raw=1.4745, running_loss=1.4569, LR=0.000100
[2025-08-26 10:39:27,114][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009832] [Batch 00779/00823] [00:09:51/00:00:33, 0.759s/it]: train_loss_raw=1.4353, running_loss=1.4548, LR=0.000100
[2025-08-26 10:39:33,188][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009840] [Batch 00787/00823] [00:09:57/00:00:27, 0.759s/it]: train_loss_raw=1.4022, running_loss=1.4553, LR=0.000100
[2025-08-26 10:39:39,279][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009848] [Batch 00795/00823] [00:10:03/00:00:21, 0.759s/it]: train_loss_raw=1.3728, running_loss=1.4555, LR=0.000100
[2025-08-26 10:39:45,376][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009856] [Batch 00803/00823] [00:10:09/00:00:15, 0.759s/it]: train_loss_raw=1.4494, running_loss=1.4551, LR=0.000100
[2025-08-26 10:39:51,447][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009864] [Batch 00811/00823] [00:10:15/00:00:09, 0.759s/it]: train_loss_raw=1.4812, running_loss=1.4528, LR=0.000100
[2025-08-26 10:39:57,529][__main__][INFO] - [TRAIN] [Epoch 11/29 Step 009872] [Batch 00819/00823] [00:10:21/00:00:03, 0.759s/it]: train_loss_raw=1.4135, running_loss=1.4533, LR=0.000100
[2025-08-26 10:40:07,443][__main__][INFO] - [VALIDATION] [Epoch 11/29] Starting validation.
[2025-08-26 10:40:19,324][__main__][INFO] - [VALIDATION] [Epoch 11/29 Step 009877] [Batch 00007/00013] [00:00:11/00:00:07, 1.485s/it]
[2025-08-26 10:40:26,656][__main__][INFO] - [VALIDATION] [Epoch 11/29] train_loss=1.45219, valid_loss=1.52987
[2025-08-26 10:40:26,656][__main__][INFO] - [VALIDATION] [Epoch 11/29] Metrics:
[2025-08-26 10:40:26,657][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_er      0.666
[2025-08-26 10:40:26,657][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_prec    0.044
[2025-08-26 10:40:26,657][__main__][INFO] - [VALIDATION] [Epoch 11/29] - aa_recall  0.044
[2025-08-26 10:40:26,657][__main__][INFO] - [VALIDATION] [Epoch 11/29] - pep_recall 0.008
[2025-08-26 10:40:26,659][__main__][INFO] - [TRAIN] [Epoch 11/29] Epoch complete, total time 02:07:50, remaining time 03:11:45, 00:10:39 per epoch
[2025-08-26 10:40:29,755][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009880] [Batch 00004/00823] [00:00:02/00:08:10, 0.599s/it]: train_loss_raw=1.4855, running_loss=1.3671, LR=0.000100
[2025-08-26 10:40:35,756][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009888] [Batch 00012/00823] [00:00:08/00:09:27, 0.700s/it]: train_loss_raw=1.4400, running_loss=1.3706, LR=0.000100
[2025-08-26 10:40:41,834][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009896] [Batch 00020/00823] [00:00:14/00:09:41, 0.724s/it]: train_loss_raw=1.4174, running_loss=1.3735, LR=0.000100
[2025-08-26 10:40:47,848][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009904] [Batch 00028/00823] [00:00:20/00:09:41, 0.732s/it]: train_loss_raw=1.5058, running_loss=1.3748, LR=0.000100
[2025-08-26 10:40:53,940][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009912] [Batch 00036/00823] [00:00:26/00:09:41, 0.738s/it]: train_loss_raw=1.4516, running_loss=1.3792, LR=0.000100
[2025-08-26 10:41:00,082][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009920] [Batch 00044/00823] [00:00:32/00:09:39, 0.744s/it]: train_loss_raw=1.4165, running_loss=1.3815, LR=0.000100
[2025-08-26 10:41:06,158][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009928] [Batch 00052/00823] [00:00:38/00:09:35, 0.746s/it]: train_loss_raw=1.4457, running_loss=1.3848, LR=0.000100
[2025-08-26 10:41:12,299][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009936] [Batch 00060/00823] [00:00:44/00:09:31, 0.749s/it]: train_loss_raw=1.3911, running_loss=1.3867, LR=0.000100
[2025-08-26 10:41:18,369][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009944] [Batch 00068/00823] [00:00:51/00:09:26, 0.750s/it]: train_loss_raw=1.3743, running_loss=1.3859, LR=0.000100
[2025-08-26 10:41:24,430][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009952] [Batch 00076/00823] [00:00:57/00:09:20, 0.751s/it]: train_loss_raw=1.4945, running_loss=1.3910, LR=0.000100
[2025-08-26 10:41:30,465][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009960] [Batch 00084/00823] [00:01:03/00:09:15, 0.751s/it]: train_loss_raw=1.4132, running_loss=1.3913, LR=0.000100
[2025-08-26 10:41:36,560][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009968] [Batch 00092/00823] [00:01:09/00:09:09, 0.752s/it]: train_loss_raw=1.3713, running_loss=1.3917, LR=0.000100
[2025-08-26 10:41:42,645][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009976] [Batch 00100/00823] [00:01:15/00:09:04, 0.753s/it]: train_loss_raw=1.4578, running_loss=1.3948, LR=0.000100
[2025-08-26 10:41:48,731][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009984] [Batch 00108/00823] [00:01:21/00:08:58, 0.753s/it]: train_loss_raw=1.4386, running_loss=1.3943, LR=0.000100
[2025-08-26 10:41:54,794][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 009992] [Batch 00116/00823] [00:01:27/00:08:52, 0.754s/it]: train_loss_raw=1.5147, running_loss=1.3966, LR=0.000100
[2025-08-26 10:42:00,799][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010000] [Batch 00124/00823] [00:01:33/00:08:46, 0.754s/it]: train_loss_raw=1.3744, running_loss=1.3986, LR=0.000100
[2025-08-26 10:42:11,234][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010008] [Batch 00132/00823] [00:01:43/00:09:03, 0.787s/it]: train_loss_raw=1.5238, running_loss=1.4026, LR=0.000100
[2025-08-26 10:42:17,348][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010016] [Batch 00140/00823] [00:01:49/00:08:56, 0.786s/it]: train_loss_raw=1.3926, running_loss=1.4020, LR=0.000100
[2025-08-26 10:42:23,451][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010024] [Batch 00148/00823] [00:01:56/00:08:49, 0.784s/it]: train_loss_raw=1.3754, running_loss=1.4017, LR=0.000100
[2025-08-26 10:42:29,450][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010032] [Batch 00156/00823] [00:02:02/00:08:42, 0.783s/it]: train_loss_raw=1.4412, running_loss=1.4048, LR=0.000100
[2025-08-26 10:42:35,545][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010040] [Batch 00164/00823] [00:02:08/00:08:35, 0.782s/it]: train_loss_raw=1.3328, running_loss=1.4031, LR=0.000100
[2025-08-26 10:42:41,662][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010048] [Batch 00172/00823] [00:02:14/00:08:28, 0.781s/it]: train_loss_raw=1.4317, running_loss=1.3995, LR=0.000100
[2025-08-26 10:42:47,661][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010056] [Batch 00180/00823] [00:02:20/00:08:21, 0.779s/it]: train_loss_raw=1.3711, running_loss=1.3983, LR=0.000100
[2025-08-26 10:42:53,756][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010064] [Batch 00188/00823] [00:02:26/00:08:14, 0.779s/it]: train_loss_raw=1.4219, running_loss=1.3991, LR=0.000100
[2025-08-26 10:42:59,832][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010072] [Batch 00196/00823] [00:02:32/00:08:07, 0.778s/it]: train_loss_raw=1.4339, running_loss=1.4026, LR=0.000100
[2025-08-26 10:43:05,913][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010080] [Batch 00204/00823] [00:02:38/00:08:01, 0.777s/it]: train_loss_raw=1.5043, running_loss=1.4080, LR=0.000100
[2025-08-26 10:43:12,022][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010088] [Batch 00212/00823] [00:02:44/00:07:54, 0.777s/it]: train_loss_raw=1.4441, running_loss=1.4088, LR=0.000100
[2025-08-26 10:43:18,015][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010096] [Batch 00220/00823] [00:02:50/00:07:47, 0.776s/it]: train_loss_raw=1.4292, running_loss=1.4105, LR=0.000100
[2025-08-26 10:43:24,063][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010104] [Batch 00228/00823] [00:02:56/00:07:41, 0.775s/it]: train_loss_raw=1.3520, running_loss=1.4099, LR=0.000100
[2025-08-26 10:43:30,092][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010112] [Batch 00236/00823] [00:03:02/00:07:34, 0.774s/it]: train_loss_raw=1.3558, running_loss=1.4095, LR=0.000100
[2025-08-26 10:43:36,102][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010120] [Batch 00244/00823] [00:03:08/00:07:27, 0.774s/it]: train_loss_raw=1.3220, running_loss=1.4095, LR=0.000100
[2025-08-26 10:43:42,213][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010128] [Batch 00252/00823] [00:03:14/00:07:21, 0.773s/it]: train_loss_raw=1.4787, running_loss=1.4104, LR=0.000100
[2025-08-26 10:43:48,237][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010136] [Batch 00260/00823] [00:03:20/00:07:14, 0.773s/it]: train_loss_raw=1.3319, running_loss=1.4090, LR=0.000100
[2025-08-26 10:43:54,334][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010144] [Batch 00268/00823] [00:03:26/00:07:08, 0.772s/it]: train_loss_raw=1.5095, running_loss=1.4095, LR=0.000100
[2025-08-26 10:44:00,477][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010152] [Batch 00276/00823] [00:03:33/00:07:02, 0.772s/it]: train_loss_raw=1.4712, running_loss=1.4117, LR=0.000100
[2025-08-26 10:44:06,661][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010160] [Batch 00284/00823] [00:03:39/00:06:56, 0.772s/it]: train_loss_raw=1.3667, running_loss=1.4108, LR=0.000100
[2025-08-26 10:44:12,653][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010168] [Batch 00292/00823] [00:03:45/00:06:49, 0.772s/it]: train_loss_raw=1.4704, running_loss=1.4124, LR=0.000100
[2025-08-26 10:44:18,710][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010176] [Batch 00300/00823] [00:03:51/00:06:43, 0.771s/it]: train_loss_raw=1.4189, running_loss=1.4145, LR=0.000100
[2025-08-26 10:44:25,230][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010184] [Batch 00308/00823] [00:03:57/00:06:37, 0.772s/it]: train_loss_raw=1.3705, running_loss=1.4153, LR=0.000100
[2025-08-26 10:44:31,207][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010192] [Batch 00316/00823] [00:04:03/00:06:31, 0.772s/it]: train_loss_raw=1.4419, running_loss=1.4124, LR=0.000100
[2025-08-26 10:44:37,250][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010200] [Batch 00324/00823] [00:04:09/00:06:24, 0.771s/it]: train_loss_raw=1.3927, running_loss=1.4137, LR=0.000100
[2025-08-26 10:44:43,249][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010208] [Batch 00332/00823] [00:04:15/00:06:18, 0.771s/it]: train_loss_raw=1.4589, running_loss=1.4130, LR=0.000100
[2025-08-26 10:44:49,353][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010216] [Batch 00340/00823] [00:04:21/00:06:12, 0.771s/it]: train_loss_raw=1.4062, running_loss=1.4120, LR=0.000100
[2025-08-26 10:44:55,416][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010224] [Batch 00348/00823] [00:04:28/00:06:05, 0.770s/it]: train_loss_raw=1.3846, running_loss=1.4103, LR=0.000100
[2025-08-26 10:45:01,511][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010232] [Batch 00356/00823] [00:04:34/00:05:59, 0.770s/it]: train_loss_raw=1.4809, running_loss=1.4125, LR=0.000100
[2025-08-26 10:45:07,656][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010240] [Batch 00364/00823] [00:04:40/00:05:53, 0.770s/it]: train_loss_raw=1.4734, running_loss=1.4103, LR=0.000100
[2025-08-26 10:45:13,675][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010248] [Batch 00372/00823] [00:04:46/00:05:47, 0.770s/it]: train_loss_raw=1.3176, running_loss=1.4080, LR=0.000100
[2025-08-26 10:45:19,503][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010256] [Batch 00380/00823] [00:04:52/00:05:40, 0.769s/it]: train_loss_raw=1.4664, running_loss=1.4104, LR=0.000100
[2025-08-26 10:45:25,616][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010264] [Batch 00388/00823] [00:04:58/00:05:34, 0.769s/it]: train_loss_raw=1.3672, running_loss=1.4089, LR=0.000100
[2025-08-26 10:45:31,672][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010272] [Batch 00396/00823] [00:05:04/00:05:28, 0.768s/it]: train_loss_raw=1.4079, running_loss=1.4082, LR=0.000100
[2025-08-26 10:45:37,772][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010280] [Batch 00404/00823] [00:05:10/00:05:21, 0.768s/it]: train_loss_raw=1.4509, running_loss=1.4075, LR=0.000100
[2025-08-26 10:45:43,826][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010288] [Batch 00412/00823] [00:05:16/00:05:15, 0.768s/it]: train_loss_raw=1.3445, running_loss=1.4072, LR=0.000100
[2025-08-26 10:45:49,888][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010296] [Batch 00420/00823] [00:05:22/00:05:09, 0.768s/it]: train_loss_raw=1.4195, running_loss=1.4071, LR=0.000100
[2025-08-26 10:45:55,967][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010304] [Batch 00428/00823] [00:05:28/00:05:03, 0.768s/it]: train_loss_raw=1.2687, running_loss=1.4039, LR=0.000100
[2025-08-26 10:46:01,974][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010312] [Batch 00436/00823] [00:05:34/00:04:57, 0.767s/it]: train_loss_raw=1.3212, running_loss=1.4026, LR=0.000100
[2025-08-26 10:46:08,025][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010320] [Batch 00444/00823] [00:05:40/00:04:50, 0.767s/it]: train_loss_raw=1.3841, running_loss=1.4024, LR=0.000100
[2025-08-26 10:46:13,892][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010328] [Batch 00452/00823] [00:05:46/00:04:44, 0.767s/it]: train_loss_raw=1.3728, running_loss=1.4032, LR=0.000100
[2025-08-26 10:46:19,829][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010336] [Batch 00460/00823] [00:05:52/00:04:38, 0.766s/it]: train_loss_raw=1.4008, running_loss=1.4027, LR=0.000100
[2025-08-26 10:46:25,678][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010344] [Batch 00468/00823] [00:05:58/00:04:31, 0.766s/it]: train_loss_raw=1.3932, running_loss=1.4027, LR=0.000100
[2025-08-26 10:46:31,731][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010352] [Batch 00476/00823] [00:06:04/00:04:25, 0.765s/it]: train_loss_raw=1.4105, running_loss=1.4033, LR=0.000100
[2025-08-26 10:46:37,674][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010360] [Batch 00484/00823] [00:06:10/00:04:19, 0.765s/it]: train_loss_raw=1.4442, running_loss=1.4068, LR=0.000100
[2025-08-26 10:46:43,363][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010368] [Batch 00492/00823] [00:06:16/00:04:12, 0.764s/it]: train_loss_raw=1.4935, running_loss=1.4064, LR=0.000100
[2025-08-26 10:46:49,217][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010376] [Batch 00500/00823] [00:06:21/00:04:06, 0.764s/it]: train_loss_raw=1.4798, running_loss=1.4067, LR=0.000100
[2025-08-26 10:46:55,140][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010384] [Batch 00508/00823] [00:06:27/00:04:00, 0.763s/it]: train_loss_raw=1.4372, running_loss=1.4088, LR=0.000100
[2025-08-26 10:47:01,265][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010392] [Batch 00516/00823] [00:06:33/00:03:54, 0.763s/it]: train_loss_raw=1.4631, running_loss=1.4066, LR=0.000100
[2025-08-26 10:47:07,368][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010400] [Batch 00524/00823] [00:06:40/00:03:48, 0.763s/it]: train_loss_raw=1.3986, running_loss=1.4057, LR=0.000100
[2025-08-26 10:47:13,455][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010408] [Batch 00532/00823] [00:06:46/00:03:42, 0.763s/it]: train_loss_raw=1.5143, running_loss=1.4074, LR=0.000100
[2025-08-26 10:47:19,585][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010416] [Batch 00540/00823] [00:06:52/00:03:36, 0.763s/it]: train_loss_raw=1.4146, running_loss=1.4060, LR=0.000100
[2025-08-26 10:47:25,681][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010424] [Batch 00548/00823] [00:06:58/00:03:29, 0.763s/it]: train_loss_raw=1.4163, running_loss=1.4064, LR=0.000100
[2025-08-26 10:47:31,783][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010432] [Batch 00556/00823] [00:07:04/00:03:23, 0.763s/it]: train_loss_raw=1.4691, running_loss=1.4080, LR=0.000100
[2025-08-26 10:47:37,858][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010440] [Batch 00564/00823] [00:07:10/00:03:17, 0.763s/it]: train_loss_raw=1.4506, running_loss=1.4073, LR=0.000100
[2025-08-26 10:47:43,920][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010448] [Batch 00572/00823] [00:07:16/00:03:11, 0.763s/it]: train_loss_raw=1.3461, running_loss=1.4073, LR=0.000100
[2025-08-26 10:47:49,962][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010456] [Batch 00580/00823] [00:07:22/00:03:05, 0.763s/it]: train_loss_raw=1.3587, running_loss=1.4087, LR=0.000100
[2025-08-26 10:47:56,008][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010464] [Batch 00588/00823] [00:07:28/00:02:59, 0.763s/it]: train_loss_raw=1.3590, running_loss=1.4088, LR=0.000100
[2025-08-26 10:48:02,162][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010472] [Batch 00596/00823] [00:07:34/00:02:53, 0.763s/it]: train_loss_raw=1.3462, running_loss=1.4072, LR=0.000100
[2025-08-26 10:48:08,235][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010480] [Batch 00604/00823] [00:07:40/00:02:47, 0.763s/it]: train_loss_raw=1.3786, running_loss=1.4072, LR=0.000100
[2025-08-26 10:48:14,339][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010488] [Batch 00612/00823] [00:07:46/00:02:41, 0.763s/it]: train_loss_raw=1.3803, running_loss=1.4073, LR=0.000100
[2025-08-26 10:48:20,473][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010496] [Batch 00620/00823] [00:07:53/00:02:34, 0.763s/it]: train_loss_raw=1.4275, running_loss=1.4078, LR=0.000100
[2025-08-26 10:48:26,520][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010504] [Batch 00628/00823] [00:07:59/00:02:28, 0.763s/it]: train_loss_raw=1.3561, running_loss=1.4071, LR=0.000100
[2025-08-26 10:48:32,566][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010512] [Batch 00636/00823] [00:08:05/00:02:22, 0.763s/it]: train_loss_raw=1.3858, running_loss=1.4062, LR=0.000100
[2025-08-26 10:48:38,666][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010520] [Batch 00644/00823] [00:08:11/00:02:16, 0.763s/it]: train_loss_raw=1.4317, running_loss=1.4067, LR=0.000100
[2025-08-26 10:48:44,811][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010528] [Batch 00652/00823] [00:08:17/00:02:10, 0.763s/it]: train_loss_raw=1.2527, running_loss=1.4051, LR=0.000100
[2025-08-26 10:48:50,952][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010536] [Batch 00660/00823] [00:08:23/00:02:04, 0.763s/it]: train_loss_raw=1.4409, running_loss=1.4034, LR=0.000100
[2025-08-26 10:48:57,036][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010544] [Batch 00668/00823] [00:08:29/00:01:58, 0.763s/it]: train_loss_raw=1.4979, running_loss=1.4055, LR=0.000100
[2025-08-26 10:49:03,056][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010552] [Batch 00676/00823] [00:08:35/00:01:52, 0.763s/it]: train_loss_raw=1.3364, running_loss=1.4061, LR=0.000100
[2025-08-26 10:49:09,116][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010560] [Batch 00684/00823] [00:08:41/00:01:46, 0.763s/it]: train_loss_raw=1.3069, running_loss=1.4028, LR=0.000100
[2025-08-26 10:49:15,173][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010568] [Batch 00692/00823] [00:08:47/00:01:39, 0.763s/it]: train_loss_raw=1.3820, running_loss=1.4011, LR=0.000100
[2025-08-26 10:49:21,305][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010576] [Batch 00700/00823] [00:08:53/00:01:33, 0.763s/it]: train_loss_raw=1.4305, running_loss=1.4014, LR=0.000100
[2025-08-26 10:49:27,418][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010584] [Batch 00708/00823] [00:09:00/00:01:27, 0.763s/it]: train_loss_raw=1.4063, running_loss=1.4008, LR=0.000100
[2025-08-26 10:49:33,453][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010592] [Batch 00716/00823] [00:09:06/00:01:21, 0.763s/it]: train_loss_raw=1.2717, running_loss=1.3992, LR=0.000100
[2025-08-26 10:49:39,530][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010600] [Batch 00724/00823] [00:09:12/00:01:15, 0.763s/it]: train_loss_raw=1.3730, running_loss=1.4005, LR=0.000100
[2025-08-26 10:49:45,588][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010608] [Batch 00732/00823] [00:09:18/00:01:09, 0.763s/it]: train_loss_raw=1.4672, running_loss=1.3995, LR=0.000100
[2025-08-26 10:49:51,689][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010616] [Batch 00740/00823] [00:09:24/00:01:03, 0.763s/it]: train_loss_raw=1.4398, running_loss=1.4000, LR=0.000100
[2025-08-26 10:49:57,722][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010624] [Batch 00748/00823] [00:09:30/00:00:57, 0.763s/it]: train_loss_raw=1.4243, running_loss=1.3978, LR=0.000100
[2025-08-26 10:50:03,751][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010632] [Batch 00756/00823] [00:09:36/00:00:51, 0.762s/it]: train_loss_raw=1.2877, running_loss=1.4000, LR=0.000100
[2025-08-26 10:50:09,772][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010640] [Batch 00764/00823] [00:09:42/00:00:44, 0.762s/it]: train_loss_raw=1.3242, running_loss=1.3967, LR=0.000100
[2025-08-26 10:50:15,628][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010648] [Batch 00772/00823] [00:09:48/00:00:38, 0.762s/it]: train_loss_raw=1.4600, running_loss=1.3968, LR=0.000100
[2025-08-26 10:50:21,494][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010656] [Batch 00780/00823] [00:09:54/00:00:32, 0.762s/it]: train_loss_raw=1.5184, running_loss=1.3993, LR=0.000100
[2025-08-26 10:50:27,391][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010664] [Batch 00788/00823] [00:10:00/00:00:26, 0.761s/it]: train_loss_raw=1.4365, running_loss=1.3993, LR=0.000100
[2025-08-26 10:50:33,320][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010672] [Batch 00796/00823] [00:10:05/00:00:20, 0.761s/it]: train_loss_raw=1.3899, running_loss=1.3983, LR=0.000100
[2025-08-26 10:50:39,306][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010680] [Batch 00804/00823] [00:10:11/00:00:14, 0.761s/it]: train_loss_raw=1.4240, running_loss=1.4003, LR=0.000100
[2025-08-26 10:50:45,415][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010688] [Batch 00812/00823] [00:10:18/00:00:08, 0.761s/it]: train_loss_raw=1.4626, running_loss=1.3990, LR=0.000100
[2025-08-26 10:50:51,494][__main__][INFO] - [TRAIN] [Epoch 12/29 Step 010696] [Batch 00820/00823] [00:10:24/00:00:02, 0.761s/it]: train_loss_raw=1.4825, running_loss=1.4010, LR=0.000100
[2025-08-26 10:50:53,945][__main__][INFO] - [VALIDATION] [Epoch 12/29] Starting validation.
[2025-08-26 10:51:04,521][__main__][INFO] - [VALIDATION] [Epoch 12/29 Step 010700] [Batch 00007/00013] [00:00:10/00:00:06, 1.322s/it]
[2025-08-26 10:51:11,830][__main__][INFO] - [VALIDATION] [Epoch 12/29] train_loss=1.40014, valid_loss=1.49540
[2025-08-26 10:51:11,831][__main__][INFO] - [VALIDATION] [Epoch 12/29] Metrics:
[2025-08-26 10:51:11,831][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_er      0.658
[2025-08-26 10:51:11,831][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_prec    0.042
[2025-08-26 10:51:11,831][__main__][INFO] - [VALIDATION] [Epoch 12/29] - aa_recall  0.043
[2025-08-26 10:51:11,831][__main__][INFO] - [VALIDATION] [Epoch 12/29] - pep_recall 0.007
[2025-08-26 10:51:11,833][__main__][INFO] - [TRAIN] [Epoch 12/29] Epoch complete, total time 02:18:35, remaining time 03:01:14, 00:10:39 per epoch
[2025-08-26 10:51:16,050][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010704] [Batch 00005/00823] [00:00:03/00:08:43, 0.640s/it]: train_loss_raw=1.4248, running_loss=1.4626, LR=0.000100
[2025-08-26 10:51:22,108][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010712] [Batch 00013/00823] [00:00:09/00:09:36, 0.712s/it]: train_loss_raw=1.3960, running_loss=1.4571, LR=0.000100
[2025-08-26 10:51:28,232][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010720] [Batch 00021/00823] [00:00:15/00:09:47, 0.732s/it]: train_loss_raw=1.4302, running_loss=1.4541, LR=0.000100
[2025-08-26 10:51:34,294][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010728] [Batch 00029/00823] [00:00:21/00:09:47, 0.739s/it]: train_loss_raw=1.4237, running_loss=1.4508, LR=0.000100
[2025-08-26 10:51:40,390][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010736] [Batch 00037/00823] [00:00:27/00:09:45, 0.744s/it]: train_loss_raw=1.4137, running_loss=1.4460, LR=0.000100
[2025-08-26 10:51:46,472][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010744] [Batch 00045/00823] [00:00:33/00:09:41, 0.747s/it]: train_loss_raw=1.3540, running_loss=1.4410, LR=0.000100
[2025-08-26 10:51:52,468][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010752] [Batch 00053/00823] [00:00:39/00:09:35, 0.748s/it]: train_loss_raw=1.4320, running_loss=1.4367, LR=0.000100
[2025-08-26 10:51:58,440][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010760] [Batch 00061/00823] [00:00:45/00:09:29, 0.747s/it]: train_loss_raw=1.3434, running_loss=1.4296, LR=0.000100
[2025-08-26 10:52:04,427][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010768] [Batch 00069/00823] [00:00:51/00:09:23, 0.748s/it]: train_loss_raw=1.3580, running_loss=1.4257, LR=0.000100
[2025-08-26 10:52:10,525][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010776] [Batch 00077/00823] [00:00:57/00:09:18, 0.749s/it]: train_loss_raw=1.3579, running_loss=1.4241, LR=0.000100
[2025-08-26 10:52:16,633][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010784] [Batch 00085/00823] [00:01:03/00:09:13, 0.750s/it]: train_loss_raw=1.4584, running_loss=1.4245, LR=0.000100
[2025-08-26 10:52:22,770][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010792] [Batch 00093/00823] [00:01:09/00:09:08, 0.752s/it]: train_loss_raw=1.3603, running_loss=1.4209, LR=0.000100
[2025-08-26 10:52:28,858][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010800] [Batch 00101/00823] [00:01:16/00:09:03, 0.753s/it]: train_loss_raw=1.3599, running_loss=1.4210, LR=0.000100
[2025-08-26 10:52:34,864][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010808] [Batch 00109/00823] [00:01:22/00:08:57, 0.752s/it]: train_loss_raw=1.3922, running_loss=1.4173, LR=0.000100
[2025-08-26 10:52:40,895][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010816] [Batch 00117/00823] [00:01:28/00:08:51, 0.753s/it]: train_loss_raw=1.4029, running_loss=1.4157, LR=0.000100
[2025-08-26 10:52:46,922][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010824] [Batch 00125/00823] [00:01:34/00:08:45, 0.753s/it]: train_loss_raw=1.3486, running_loss=1.4122, LR=0.000100
[2025-08-26 10:52:52,923][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010832] [Batch 00133/00823] [00:01:40/00:08:39, 0.752s/it]: train_loss_raw=1.3865, running_loss=1.4101, LR=0.000100
[2025-08-26 10:52:58,687][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010840] [Batch 00141/00823] [00:01:45/00:08:31, 0.751s/it]: train_loss_raw=1.4762, running_loss=1.4109, LR=0.000100
[2025-08-26 10:53:04,468][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010848] [Batch 00149/00823] [00:01:51/00:08:24, 0.749s/it]: train_loss_raw=1.4221, running_loss=1.4087, LR=0.000100
[2025-08-26 10:53:10,249][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010856] [Batch 00157/00823] [00:01:57/00:08:18, 0.748s/it]: train_loss_raw=1.4061, running_loss=1.4089, LR=0.000100
[2025-08-26 10:53:16,213][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010864] [Batch 00165/00823] [00:02:03/00:08:11, 0.748s/it]: train_loss_raw=1.4640, running_loss=1.4070, LR=0.000100
[2025-08-26 10:53:22,185][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010872] [Batch 00173/00823] [00:02:09/00:08:05, 0.748s/it]: train_loss_raw=1.3857, running_loss=1.4063, LR=0.000100
[2025-08-26 10:53:27,967][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010880] [Batch 00181/00823] [00:02:15/00:07:59, 0.747s/it]: train_loss_raw=1.3514, running_loss=1.4074, LR=0.000100
[2025-08-26 10:53:33,950][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010888] [Batch 00189/00823] [00:02:21/00:07:53, 0.747s/it]: train_loss_raw=1.3923, running_loss=1.4049, LR=0.000100
[2025-08-26 10:53:39,751][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010896] [Batch 00197/00823] [00:02:26/00:07:46, 0.746s/it]: train_loss_raw=1.3087, running_loss=1.4016, LR=0.000100
[2025-08-26 10:53:45,570][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010904] [Batch 00205/00823] [00:02:32/00:07:40, 0.745s/it]: train_loss_raw=1.3813, running_loss=1.3979, LR=0.000100
[2025-08-26 10:53:51,358][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010912] [Batch 00213/00823] [00:02:38/00:07:33, 0.744s/it]: train_loss_raw=1.3803, running_loss=1.3984, LR=0.000100
[2025-08-26 10:53:57,002][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010920] [Batch 00221/00823] [00:02:44/00:07:27, 0.743s/it]: train_loss_raw=1.3150, running_loss=1.3969, LR=0.000100
[2025-08-26 10:54:02,643][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010928] [Batch 00229/00823] [00:02:49/00:07:20, 0.741s/it]: train_loss_raw=1.4550, running_loss=1.3972, LR=0.000100
[2025-08-26 10:54:08,236][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010936] [Batch 00237/00823] [00:02:55/00:07:13, 0.740s/it]: train_loss_raw=1.3516, running_loss=1.3950, LR=0.000100
[2025-08-26 10:54:14,029][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010944] [Batch 00245/00823] [00:03:01/00:07:07, 0.740s/it]: train_loss_raw=1.3929, running_loss=1.3955, LR=0.000100
[2025-08-26 10:54:19,907][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010952] [Batch 00253/00823] [00:03:07/00:07:01, 0.739s/it]: train_loss_raw=1.4713, running_loss=1.3958, LR=0.000100
[2025-08-26 10:54:25,824][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010960] [Batch 00261/00823] [00:03:12/00:06:55, 0.739s/it]: train_loss_raw=1.3557, running_loss=1.3971, LR=0.000100
[2025-08-26 10:54:31,601][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010968] [Batch 00269/00823] [00:03:18/00:06:49, 0.739s/it]: train_loss_raw=1.4633, running_loss=1.3959, LR=0.000100
[2025-08-26 10:54:37,497][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010976] [Batch 00277/00823] [00:03:24/00:06:43, 0.739s/it]: train_loss_raw=1.4521, running_loss=1.3963, LR=0.000100
[2025-08-26 10:54:43,345][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010984] [Batch 00285/00823] [00:03:30/00:06:37, 0.739s/it]: train_loss_raw=1.2927, running_loss=1.3944, LR=0.000100
[2025-08-26 10:54:49,130][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 010992] [Batch 00293/00823] [00:03:36/00:06:31, 0.738s/it]: train_loss_raw=1.4035, running_loss=1.3933, LR=0.000100
[2025-08-26 10:54:55,137][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011000] [Batch 00301/00823] [00:03:42/00:06:25, 0.738s/it]: train_loss_raw=1.3484, running_loss=1.3935, LR=0.000100
[2025-08-26 10:55:00,982][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011008] [Batch 00309/00823] [00:03:48/00:06:19, 0.738s/it]: train_loss_raw=1.4519, running_loss=1.3955, LR=0.000100
[2025-08-26 10:55:06,813][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011016] [Batch 00317/00823] [00:03:53/00:06:13, 0.738s/it]: train_loss_raw=1.3869, running_loss=1.3976, LR=0.000100
[2025-08-26 10:55:12,569][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011024] [Batch 00325/00823] [00:03:59/00:06:07, 0.738s/it]: train_loss_raw=1.2405, running_loss=1.3962, LR=0.000100
[2025-08-26 10:55:18,324][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011032] [Batch 00333/00823] [00:04:05/00:06:01, 0.737s/it]: train_loss_raw=1.4192, running_loss=1.3957, LR=0.000100
[2025-08-26 10:55:24,112][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011040] [Batch 00341/00823] [00:04:11/00:05:55, 0.737s/it]: train_loss_raw=1.4094, running_loss=1.3955, LR=0.000100
[2025-08-26 10:55:29,893][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011048] [Batch 00349/00823] [00:04:17/00:05:49, 0.737s/it]: train_loss_raw=1.3585, running_loss=1.3934, LR=0.000100
[2025-08-26 10:55:35,747][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011056] [Batch 00357/00823] [00:04:22/00:05:43, 0.736s/it]: train_loss_raw=1.3654, running_loss=1.3944, LR=0.000100
[2025-08-26 10:55:41,606][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011064] [Batch 00365/00823] [00:04:28/00:05:37, 0.736s/it]: train_loss_raw=1.4863, running_loss=1.3961, LR=0.000100
[2025-08-26 10:55:47,718][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011072] [Batch 00373/00823] [00:04:34/00:05:31, 0.737s/it]: train_loss_raw=1.4415, running_loss=1.3963, LR=0.000100
[2025-08-26 10:55:53,562][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011080] [Batch 00381/00823] [00:04:40/00:05:25, 0.737s/it]: train_loss_raw=1.4051, running_loss=1.3956, LR=0.000100
[2025-08-26 10:55:59,435][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011088] [Batch 00389/00823] [00:04:46/00:05:19, 0.737s/it]: train_loss_raw=1.3638, running_loss=1.3958, LR=0.000100
[2025-08-26 10:56:05,419][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011096] [Batch 00397/00823] [00:04:52/00:05:13, 0.737s/it]: train_loss_raw=1.3484, running_loss=1.3937, LR=0.000100
[2025-08-26 10:56:11,192][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011104] [Batch 00405/00823] [00:04:58/00:05:07, 0.737s/it]: train_loss_raw=1.4586, running_loss=1.3937, LR=0.000100
[2025-08-26 10:56:16,951][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011112] [Batch 00413/00823] [00:05:04/00:05:01, 0.736s/it]: train_loss_raw=1.4134, running_loss=1.3946, LR=0.000100
[2025-08-26 10:56:22,779][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011120] [Batch 00421/00823] [00:05:09/00:04:55, 0.736s/it]: train_loss_raw=1.3982, running_loss=1.3953, LR=0.000100
[2025-08-26 10:56:28,553][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011128] [Batch 00429/00823] [00:05:15/00:04:49, 0.736s/it]: train_loss_raw=1.3790, running_loss=1.3957, LR=0.000100
[2025-08-26 10:56:34,274][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011136] [Batch 00437/00823] [00:05:21/00:04:43, 0.736s/it]: train_loss_raw=1.3618, running_loss=1.3964, LR=0.000100
[2025-08-26 10:56:40,015][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011144] [Batch 00445/00823] [00:05:27/00:04:37, 0.735s/it]: train_loss_raw=1.4559, running_loss=1.3970, LR=0.000100
[2025-08-26 10:56:45,890][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011152] [Batch 00453/00823] [00:05:33/00:04:32, 0.735s/it]: train_loss_raw=1.3642, running_loss=1.3983, LR=0.000100
[2025-08-26 10:56:51,818][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011160] [Batch 00461/00823] [00:05:38/00:04:26, 0.735s/it]: train_loss_raw=1.4396, running_loss=1.3980, LR=0.000100
[2025-08-26 10:56:57,745][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011168] [Batch 00469/00823] [00:05:44/00:04:20, 0.735s/it]: train_loss_raw=1.4296, running_loss=1.3971, LR=0.000100
[2025-08-26 10:57:03,688][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011176] [Batch 00477/00823] [00:05:50/00:04:14, 0.736s/it]: train_loss_raw=1.4061, running_loss=1.3956, LR=0.000100
[2025-08-26 10:57:09,448][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011184] [Batch 00485/00823] [00:05:56/00:04:08, 0.735s/it]: train_loss_raw=1.3525, running_loss=1.3945, LR=0.000100
[2025-08-26 10:57:15,193][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011192] [Batch 00493/00823] [00:06:02/00:04:02, 0.735s/it]: train_loss_raw=1.3108, running_loss=1.3912, LR=0.000100
[2025-08-26 10:57:20,993][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011200] [Batch 00501/00823] [00:06:08/00:03:56, 0.735s/it]: train_loss_raw=1.3629, running_loss=1.3907, LR=0.000100
[2025-08-26 10:57:26,830][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011208] [Batch 00509/00823] [00:06:13/00:03:50, 0.735s/it]: train_loss_raw=1.3871, running_loss=1.3897, LR=0.000100
[2025-08-26 10:57:32,815][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011216] [Batch 00517/00823] [00:06:19/00:03:44, 0.735s/it]: train_loss_raw=1.2753, running_loss=1.3883, LR=0.000100
[2025-08-26 10:57:38,633][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011224] [Batch 00525/00823] [00:06:25/00:03:38, 0.735s/it]: train_loss_raw=1.3626, running_loss=1.3862, LR=0.000100
[2025-08-26 10:57:44,408][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011232] [Batch 00533/00823] [00:06:31/00:03:33, 0.735s/it]: train_loss_raw=1.4310, running_loss=1.3887, LR=0.000100
[2025-08-26 10:57:50,226][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011240] [Batch 00541/00823] [00:06:37/00:03:27, 0.735s/it]: train_loss_raw=1.3915, running_loss=1.3879, LR=0.000100
[2025-08-26 10:57:56,026][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011248] [Batch 00549/00823] [00:06:43/00:03:21, 0.734s/it]: train_loss_raw=1.3900, running_loss=1.3879, LR=0.000100
[2025-08-26 10:58:01,862][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011256] [Batch 00557/00823] [00:06:49/00:03:15, 0.734s/it]: train_loss_raw=1.3664, running_loss=1.3888, LR=0.000100
[2025-08-26 10:58:07,606][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011264] [Batch 00565/00823] [00:06:54/00:03:09, 0.734s/it]: train_loss_raw=1.3465, running_loss=1.3903, LR=0.000100
[2025-08-26 10:58:13,649][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011272] [Batch 00573/00823] [00:07:00/00:03:03, 0.734s/it]: train_loss_raw=1.3473, running_loss=1.3898, LR=0.000100
[2025-08-26 10:58:19,564][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011280] [Batch 00581/00823] [00:07:06/00:02:57, 0.734s/it]: train_loss_raw=1.4078, running_loss=1.3896, LR=0.000100
[2025-08-26 10:58:25,374][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011288] [Batch 00589/00823] [00:07:12/00:02:51, 0.734s/it]: train_loss_raw=1.3401, running_loss=1.3881, LR=0.000100
[2025-08-26 10:58:31,105][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011296] [Batch 00597/00823] [00:07:18/00:02:45, 0.734s/it]: train_loss_raw=1.3291, running_loss=1.3869, LR=0.000100
[2025-08-26 10:58:36,748][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011304] [Batch 00605/00823] [00:07:23/00:02:39, 0.734s/it]: train_loss_raw=1.3376, running_loss=1.3868, LR=0.000100
[2025-08-26 10:58:42,488][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011312] [Batch 00613/00823] [00:07:29/00:02:34, 0.734s/it]: train_loss_raw=1.4278, running_loss=1.3873, LR=0.000100
[2025-08-26 10:58:48,432][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011320] [Batch 00621/00823] [00:07:35/00:02:28, 0.734s/it]: train_loss_raw=1.3512, running_loss=1.3837, LR=0.000100
[2025-08-26 10:58:54,222][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011328] [Batch 00629/00823] [00:07:41/00:02:22, 0.734s/it]: train_loss_raw=1.3451, running_loss=1.3824, LR=0.000100
[2025-08-26 10:58:59,954][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011336] [Batch 00637/00823] [00:07:47/00:02:16, 0.733s/it]: train_loss_raw=1.4947, running_loss=1.3846, LR=0.000100
[2025-08-26 10:59:05,846][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011344] [Batch 00645/00823] [00:07:52/00:02:10, 0.733s/it]: train_loss_raw=1.3765, running_loss=1.3827, LR=0.000100
[2025-08-26 10:59:11,558][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011352] [Batch 00653/00823] [00:07:58/00:02:04, 0.733s/it]: train_loss_raw=1.4080, running_loss=1.3811, LR=0.000100
[2025-08-26 10:59:17,313][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011360] [Batch 00661/00823] [00:08:04/00:01:58, 0.733s/it]: train_loss_raw=1.4127, running_loss=1.3799, LR=0.000100
[2025-08-26 10:59:23,052][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011368] [Batch 00669/00823] [00:08:10/00:01:52, 0.733s/it]: train_loss_raw=1.4211, running_loss=1.3803, LR=0.000100
[2025-08-26 10:59:28,828][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011376] [Batch 00677/00823] [00:08:15/00:01:46, 0.733s/it]: train_loss_raw=1.4297, running_loss=1.3798, LR=0.000100
[2025-08-26 10:59:34,641][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011384] [Batch 00685/00823] [00:08:21/00:01:41, 0.733s/it]: train_loss_raw=1.4199, running_loss=1.3803, LR=0.000100
[2025-08-26 10:59:40,352][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011392] [Batch 00693/00823] [00:08:27/00:01:35, 0.732s/it]: train_loss_raw=1.2943, running_loss=1.3782, LR=0.000100
[2025-08-26 10:59:46,254][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011400] [Batch 00701/00823] [00:08:33/00:01:29, 0.732s/it]: train_loss_raw=1.3989, running_loss=1.3764, LR=0.000100
[2025-08-26 10:59:52,169][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011408] [Batch 00709/00823] [00:08:39/00:01:23, 0.732s/it]: train_loss_raw=1.3112, running_loss=1.3761, LR=0.000100
[2025-08-26 10:59:57,904][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011416] [Batch 00717/00823] [00:08:45/00:01:17, 0.732s/it]: train_loss_raw=1.4942, running_loss=1.3763, LR=0.000100
[2025-08-26 11:00:03,643][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011424] [Batch 00725/00823] [00:08:50/00:01:11, 0.732s/it]: train_loss_raw=1.3087, running_loss=1.3747, LR=0.000100
[2025-08-26 11:00:09,374][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011432] [Batch 00733/00823] [00:08:56/00:01:05, 0.732s/it]: train_loss_raw=1.3941, running_loss=1.3765, LR=0.000100
[2025-08-26 11:00:15,116][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011440] [Batch 00741/00823] [00:09:02/00:01:00, 0.732s/it]: train_loss_raw=1.4297, running_loss=1.3786, LR=0.000100
[2025-08-26 11:00:21,196][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011448] [Batch 00749/00823] [00:09:08/00:00:54, 0.732s/it]: train_loss_raw=1.4174, running_loss=1.3795, LR=0.000100
[2025-08-26 11:00:27,084][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011456] [Batch 00757/00823] [00:09:14/00:00:48, 0.732s/it]: train_loss_raw=1.3647, running_loss=1.3796, LR=0.000100
[2025-08-26 11:00:32,822][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011464] [Batch 00765/00823] [00:09:19/00:00:42, 0.732s/it]: train_loss_raw=1.3836, running_loss=1.3790, LR=0.000100
[2025-08-26 11:00:38,446][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011472] [Batch 00773/00823] [00:09:25/00:00:36, 0.732s/it]: train_loss_raw=1.4107, running_loss=1.3801, LR=0.000100
[2025-08-26 11:00:44,262][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011480] [Batch 00781/00823] [00:09:31/00:00:30, 0.732s/it]: train_loss_raw=1.2791, running_loss=1.3767, LR=0.000100
[2025-08-26 11:00:50,014][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011488] [Batch 00789/00823] [00:09:37/00:00:24, 0.732s/it]: train_loss_raw=1.3445, running_loss=1.3741, LR=0.000100
[2025-08-26 11:00:55,853][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011496] [Batch 00797/00823] [00:09:43/00:00:19, 0.731s/it]: train_loss_raw=1.3918, running_loss=1.3767, LR=0.000100
[2025-08-26 11:01:01,761][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011504] [Batch 00805/00823] [00:09:48/00:00:13, 0.732s/it]: train_loss_raw=1.3451, running_loss=1.3748, LR=0.000100
[2025-08-26 11:01:07,535][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011512] [Batch 00813/00823] [00:09:54/00:00:07, 0.731s/it]: train_loss_raw=1.2980, running_loss=1.3743, LR=0.000100
[2025-08-26 11:01:13,431][__main__][INFO] - [TRAIN] [Epoch 13/29 Step 011520] [Batch 00821/00823] [00:10:00/00:00:01, 0.732s/it]: train_loss_raw=1.4345, running_loss=1.3762, LR=0.000100
[2025-08-26 11:01:20,925][__main__][INFO] - [VALIDATION] [Epoch 13/29] Starting validation.
[2025-08-26 11:01:31,677][__main__][INFO] - [VALIDATION] [Epoch 13/29 Step 011523] [Batch 00007/00013] [00:00:10/00:00:06, 1.344s/it]
[2025-08-26 11:01:38,898][__main__][INFO] - [VALIDATION] [Epoch 13/29] train_loss=1.37547, valid_loss=1.47537
[2025-08-26 11:01:38,898][__main__][INFO] - [VALIDATION] [Epoch 13/29] Metrics:
[2025-08-26 11:01:38,898][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_er      0.643
[2025-08-26 11:01:38,899][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_prec    0.052
[2025-08-26 11:01:38,899][__main__][INFO] - [VALIDATION] [Epoch 13/29] - aa_recall  0.054
[2025-08-26 11:01:38,899][__main__][INFO] - [VALIDATION] [Epoch 13/29] - pep_recall 0.010
[2025-08-26 11:01:38,901][__main__][INFO] - [TRAIN] [Epoch 13/29] Epoch complete, total time 02:29:02, remaining time 02:50:20, 00:10:38 per epoch
[2025-08-26 11:01:43,780][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011528] [Batch 00006/00823] [00:00:03/00:08:37, 0.633s/it]: train_loss_raw=1.3056, running_loss=1.3506, LR=0.000100
[2025-08-26 11:01:49,572][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011536] [Batch 00014/00823] [00:00:09/00:09:14, 0.685s/it]: train_loss_raw=1.3830, running_loss=1.3504, LR=0.000100
[2025-08-26 11:01:55,374][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011544] [Batch 00022/00823] [00:00:15/00:09:20, 0.700s/it]: train_loss_raw=1.2533, running_loss=1.3463, LR=0.000100
[2025-08-26 11:02:01,216][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011552] [Batch 00030/00823] [00:00:21/00:09:21, 0.708s/it]: train_loss_raw=1.3418, running_loss=1.3441, LR=0.000100
[2025-08-26 11:02:06,957][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011560] [Batch 00038/00823] [00:00:26/00:09:17, 0.710s/it]: train_loss_raw=1.3594, running_loss=1.3431, LR=0.000100
[2025-08-26 11:02:12,678][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011568] [Batch 00046/00823] [00:00:32/00:09:12, 0.711s/it]: train_loss_raw=1.2766, running_loss=1.3413, LR=0.000100
[2025-08-26 11:02:18,596][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011576] [Batch 00054/00823] [00:00:38/00:09:09, 0.715s/it]: train_loss_raw=1.4324, running_loss=1.3421, LR=0.000100
[2025-08-26 11:02:24,365][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011584] [Batch 00062/00823] [00:00:44/00:09:04, 0.716s/it]: train_loss_raw=1.3937, running_loss=1.3412, LR=0.000100
[2025-08-26 11:02:30,190][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011592] [Batch 00070/00823] [00:00:50/00:09:00, 0.717s/it]: train_loss_raw=1.2918, running_loss=1.3398, LR=0.000100
[2025-08-26 11:02:36,055][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011600] [Batch 00078/00823] [00:00:56/00:08:55, 0.719s/it]: train_loss_raw=1.3290, running_loss=1.3417, LR=0.000100
[2025-08-26 11:02:41,799][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011608] [Batch 00086/00823] [00:01:01/00:08:49, 0.719s/it]: train_loss_raw=1.3316, running_loss=1.3393, LR=0.000100
[2025-08-26 11:02:47,572][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011616] [Batch 00094/00823] [00:01:07/00:08:44, 0.719s/it]: train_loss_raw=1.2902, running_loss=1.3373, LR=0.000100
[2025-08-26 11:02:53,341][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011624] [Batch 00102/00823] [00:01:13/00:08:38, 0.719s/it]: train_loss_raw=1.2725, running_loss=1.3369, LR=0.000100
[2025-08-26 11:02:59,252][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011632] [Batch 00110/00823] [00:01:19/00:08:33, 0.721s/it]: train_loss_raw=1.2774, running_loss=1.3379, LR=0.000100
[2025-08-26 11:03:05,089][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011640] [Batch 00118/00823] [00:01:25/00:08:28, 0.721s/it]: train_loss_raw=1.2478, running_loss=1.3378, LR=0.000100
[2025-08-26 11:03:10,807][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011648] [Batch 00126/00823] [00:01:30/00:08:22, 0.721s/it]: train_loss_raw=1.3708, running_loss=1.3387, LR=0.000100
[2025-08-26 11:03:16,570][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011656] [Batch 00134/00823] [00:01:36/00:08:16, 0.721s/it]: train_loss_raw=1.3952, running_loss=1.3407, LR=0.000100
[2025-08-26 11:03:22,368][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011664] [Batch 00142/00823] [00:01:42/00:08:11, 0.721s/it]: train_loss_raw=1.2906, running_loss=1.3397, LR=0.000100
[2025-08-26 11:03:28,218][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011672] [Batch 00150/00823] [00:01:48/00:08:05, 0.722s/it]: train_loss_raw=1.4169, running_loss=1.3429, LR=0.000100
[2025-08-26 11:03:34,236][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011680] [Batch 00158/00823] [00:01:54/00:08:00, 0.723s/it]: train_loss_raw=1.2728, running_loss=1.3416, LR=0.000100
[2025-08-26 11:03:40,033][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011688] [Batch 00166/00823] [00:02:00/00:07:55, 0.723s/it]: train_loss_raw=1.4260, running_loss=1.3409, LR=0.000100
[2025-08-26 11:03:45,850][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011696] [Batch 00174/00823] [00:02:05/00:07:49, 0.723s/it]: train_loss_raw=1.3806, running_loss=1.3404, LR=0.000100
[2025-08-26 11:03:51,770][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011704] [Batch 00182/00823] [00:02:11/00:07:44, 0.724s/it]: train_loss_raw=1.3509, running_loss=1.3419, LR=0.000100
[2025-08-26 11:03:57,592][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011712] [Batch 00190/00823] [00:02:17/00:07:38, 0.724s/it]: train_loss_raw=1.3276, running_loss=1.3391, LR=0.000100
[2025-08-26 11:04:03,384][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011720] [Batch 00198/00823] [00:02:23/00:07:32, 0.724s/it]: train_loss_raw=1.2490, running_loss=1.3382, LR=0.000100
[2025-08-26 11:04:09,366][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011728] [Batch 00206/00823] [00:02:29/00:07:27, 0.725s/it]: train_loss_raw=1.1893, running_loss=1.3360, LR=0.000100
[2025-08-26 11:04:15,221][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011736] [Batch 00214/00823] [00:02:35/00:07:21, 0.725s/it]: train_loss_raw=1.3629, running_loss=1.3363, LR=0.000100
[2025-08-26 11:04:20,990][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011744] [Batch 00222/00823] [00:02:41/00:07:15, 0.725s/it]: train_loss_raw=1.3082, running_loss=1.3364, LR=0.000100
[2025-08-26 11:04:26,849][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011752] [Batch 00230/00823] [00:02:46/00:07:10, 0.726s/it]: train_loss_raw=1.3619, running_loss=1.3344, LR=0.000100
[2025-08-26 11:04:32,771][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011760] [Batch 00238/00823] [00:02:52/00:07:04, 0.726s/it]: train_loss_raw=1.3004, running_loss=1.3314, LR=0.000100
[2025-08-26 11:04:38,549][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011768] [Batch 00246/00823] [00:02:58/00:06:58, 0.726s/it]: train_loss_raw=1.2792, running_loss=1.3325, LR=0.000100
[2025-08-26 11:04:44,363][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011776] [Batch 00254/00823] [00:03:04/00:06:53, 0.726s/it]: train_loss_raw=1.3396, running_loss=1.3322, LR=0.000100
[2025-08-26 11:04:50,146][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011784] [Batch 00262/00823] [00:03:10/00:06:47, 0.726s/it]: train_loss_raw=1.3929, running_loss=1.3306, LR=0.000100
[2025-08-26 11:04:55,949][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011792] [Batch 00270/00823] [00:03:15/00:06:41, 0.726s/it]: train_loss_raw=1.3792, running_loss=1.3295, LR=0.000100
[2025-08-26 11:05:01,847][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011800] [Batch 00278/00823] [00:03:21/00:06:35, 0.726s/it]: train_loss_raw=1.4560, running_loss=1.3293, LR=0.000100
[2025-08-26 11:05:07,590][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011808] [Batch 00286/00823] [00:03:27/00:06:29, 0.726s/it]: train_loss_raw=1.3859, running_loss=1.3307, LR=0.000100
[2025-08-26 11:05:13,344][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011816] [Batch 00294/00823] [00:03:33/00:06:23, 0.726s/it]: train_loss_raw=1.3112, running_loss=1.3304, LR=0.000100
[2025-08-26 11:05:19,141][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011824] [Batch 00302/00823] [00:03:39/00:06:18, 0.726s/it]: train_loss_raw=1.2723, running_loss=1.3306, LR=0.000100
[2025-08-26 11:05:24,888][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011832] [Batch 00310/00823] [00:03:44/00:06:12, 0.726s/it]: train_loss_raw=1.2457, running_loss=1.3297, LR=0.000100
[2025-08-26 11:05:30,683][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011840] [Batch 00318/00823] [00:03:50/00:06:06, 0.725s/it]: train_loss_raw=1.3959, running_loss=1.3315, LR=0.000100
[2025-08-26 11:05:36,474][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011848] [Batch 00326/00823] [00:03:56/00:06:00, 0.725s/it]: train_loss_raw=1.3260, running_loss=1.3310, LR=0.000100
[2025-08-26 11:05:42,296][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011856] [Batch 00334/00823] [00:04:02/00:05:54, 0.725s/it]: train_loss_raw=1.2852, running_loss=1.3289, LR=0.000100
[2025-08-26 11:05:48,097][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011864] [Batch 00342/00823] [00:04:08/00:05:48, 0.725s/it]: train_loss_raw=1.2836, running_loss=1.3285, LR=0.000100
[2025-08-26 11:05:53,893][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011872] [Batch 00350/00823] [00:04:13/00:05:43, 0.725s/it]: train_loss_raw=1.2873, running_loss=1.3270, LR=0.000100
[2025-08-26 11:05:59,815][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011880] [Batch 00358/00823] [00:04:19/00:05:37, 0.726s/it]: train_loss_raw=1.3402, running_loss=1.3273, LR=0.000100
[2025-08-26 11:06:05,682][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011888] [Batch 00366/00823] [00:04:25/00:05:31, 0.726s/it]: train_loss_raw=1.3275, running_loss=1.3279, LR=0.000100
[2025-08-26 11:06:11,468][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011896] [Batch 00374/00823] [00:04:31/00:05:25, 0.726s/it]: train_loss_raw=1.3191, running_loss=1.3268, LR=0.000100
[2025-08-26 11:06:17,260][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011904] [Batch 00382/00823] [00:04:37/00:05:20, 0.726s/it]: train_loss_raw=1.2981, running_loss=1.3254, LR=0.000100
[2025-08-26 11:06:22,973][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011912] [Batch 00390/00823] [00:04:42/00:05:14, 0.726s/it]: train_loss_raw=1.3699, running_loss=1.3274, LR=0.000100
[2025-08-26 11:06:28,773][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011920] [Batch 00398/00823] [00:04:48/00:05:08, 0.726s/it]: train_loss_raw=1.3998, running_loss=1.3278, LR=0.000100
[2025-08-26 11:06:34,671][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011928] [Batch 00406/00823] [00:04:54/00:05:02, 0.726s/it]: train_loss_raw=1.3450, running_loss=1.3285, LR=0.000100
[2025-08-26 11:06:40,415][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011936] [Batch 00414/00823] [00:05:00/00:04:56, 0.726s/it]: train_loss_raw=1.2691, running_loss=1.3275, LR=0.000100
[2025-08-26 11:06:46,216][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011944] [Batch 00422/00823] [00:05:06/00:04:50, 0.726s/it]: train_loss_raw=1.3496, running_loss=1.3296, LR=0.000100
[2025-08-26 11:06:52,014][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011952] [Batch 00430/00823] [00:05:12/00:04:45, 0.726s/it]: train_loss_raw=1.2755, running_loss=1.3308, LR=0.000100
[2025-08-26 11:06:57,833][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011960] [Batch 00438/00823] [00:05:17/00:04:39, 0.726s/it]: train_loss_raw=1.3426, running_loss=1.3289, LR=0.000100
[2025-08-26 11:07:03,635][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011968] [Batch 00446/00823] [00:05:23/00:04:33, 0.726s/it]: train_loss_raw=1.2958, running_loss=1.3294, LR=0.000100
[2025-08-26 11:07:09,387][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011976] [Batch 00454/00823] [00:05:29/00:04:27, 0.726s/it]: train_loss_raw=1.3527, running_loss=1.3305, LR=0.000100
[2025-08-26 11:07:15,096][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011984] [Batch 00462/00823] [00:05:35/00:04:21, 0.725s/it]: train_loss_raw=1.3617, running_loss=1.3308, LR=0.000100
[2025-08-26 11:07:20,868][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 011992] [Batch 00470/00823] [00:05:40/00:04:16, 0.725s/it]: train_loss_raw=1.3286, running_loss=1.3307, LR=0.000100
[2025-08-26 11:07:26,541][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012000] [Batch 00478/00823] [00:05:46/00:04:10, 0.725s/it]: train_loss_raw=1.3109, running_loss=1.3306, LR=0.000100
[2025-08-26 11:07:35,603][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012008] [Batch 00486/00823] [00:05:55/00:04:06, 0.732s/it]: train_loss_raw=1.3394, running_loss=1.3320, LR=0.000100
[2025-08-26 11:07:41,384][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012016] [Batch 00494/00823] [00:06:01/00:04:00, 0.732s/it]: train_loss_raw=1.3467, running_loss=1.3327, LR=0.000100
[2025-08-26 11:07:47,163][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012024] [Batch 00502/00823] [00:06:07/00:03:54, 0.731s/it]: train_loss_raw=1.2625, running_loss=1.3299, LR=0.000100
[2025-08-26 11:07:52,945][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012032] [Batch 00510/00823] [00:06:12/00:03:48, 0.731s/it]: train_loss_raw=1.5132, running_loss=1.3304, LR=0.000100
[2025-08-26 11:07:58,716][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012040] [Batch 00518/00823] [00:06:18/00:03:42, 0.731s/it]: train_loss_raw=1.3613, running_loss=1.3314, LR=0.000100
[2025-08-26 11:08:04,476][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012048] [Batch 00526/00823] [00:06:24/00:03:37, 0.731s/it]: train_loss_raw=1.3232, running_loss=1.3314, LR=0.000100
[2025-08-26 11:08:10,218][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012056] [Batch 00534/00823] [00:06:30/00:03:31, 0.731s/it]: train_loss_raw=1.2973, running_loss=1.3299, LR=0.000100
[2025-08-26 11:08:16,010][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012064] [Batch 00542/00823] [00:06:36/00:03:25, 0.731s/it]: train_loss_raw=1.3635, running_loss=1.3297, LR=0.000100
[2025-08-26 11:08:22,003][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012072] [Batch 00550/00823] [00:06:42/00:03:19, 0.731s/it]: train_loss_raw=1.2602, running_loss=1.3303, LR=0.000100
[2025-08-26 11:08:28,000][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012080] [Batch 00558/00823] [00:06:48/00:03:13, 0.731s/it]: train_loss_raw=1.2760, running_loss=1.3269, LR=0.000100
[2025-08-26 11:08:33,800][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012088] [Batch 00566/00823] [00:06:53/00:03:07, 0.731s/it]: train_loss_raw=1.3508, running_loss=1.3291, LR=0.000100
[2025-08-26 11:08:39,564][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012096] [Batch 00574/00823] [00:06:59/00:03:02, 0.731s/it]: train_loss_raw=1.2997, running_loss=1.3266, LR=0.000100
[2025-08-26 11:08:45,371][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012104] [Batch 00582/00823] [00:07:05/00:02:56, 0.731s/it]: train_loss_raw=1.2961, running_loss=1.3258, LR=0.000100
[2025-08-26 11:08:51,140][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012112] [Batch 00590/00823] [00:07:11/00:02:50, 0.731s/it]: train_loss_raw=1.2691, running_loss=1.3259, LR=0.000100
[2025-08-26 11:08:56,836][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012120] [Batch 00598/00823] [00:07:16/00:02:44, 0.731s/it]: train_loss_raw=1.2821, running_loss=1.3260, LR=0.000100
[2025-08-26 11:09:02,532][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012128] [Batch 00606/00823] [00:07:22/00:02:38, 0.730s/it]: train_loss_raw=1.2718, running_loss=1.3251, LR=0.000100
[2025-08-26 11:09:08,194][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012136] [Batch 00614/00823] [00:07:28/00:02:32, 0.730s/it]: train_loss_raw=1.3767, running_loss=1.3256, LR=0.000100
[2025-08-26 11:09:13,843][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012144] [Batch 00622/00823] [00:07:33/00:02:26, 0.730s/it]: train_loss_raw=1.3595, running_loss=1.3236, LR=0.000100
[2025-08-26 11:09:19,540][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012152] [Batch 00630/00823] [00:07:39/00:02:20, 0.729s/it]: train_loss_raw=1.3039, running_loss=1.3235, LR=0.000100
[2025-08-26 11:09:25,398][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012160] [Batch 00638/00823] [00:07:45/00:02:14, 0.729s/it]: train_loss_raw=1.2812, running_loss=1.3241, LR=0.000100
[2025-08-26 11:09:31,282][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012168] [Batch 00646/00823] [00:07:51/00:02:09, 0.730s/it]: train_loss_raw=1.3406, running_loss=1.3226, LR=0.000100
[2025-08-26 11:09:37,202][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012176] [Batch 00654/00823] [00:07:57/00:02:03, 0.730s/it]: train_loss_raw=1.2664, running_loss=1.3215, LR=0.000100
[2025-08-26 11:09:43,113][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012184] [Batch 00662/00823] [00:08:03/00:01:57, 0.730s/it]: train_loss_raw=1.3426, running_loss=1.3217, LR=0.000100
[2025-08-26 11:09:48,960][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012192] [Batch 00670/00823] [00:08:08/00:01:51, 0.730s/it]: train_loss_raw=1.2463, running_loss=1.3209, LR=0.000100
[2025-08-26 11:09:54,783][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012200] [Batch 00678/00823] [00:08:14/00:01:45, 0.730s/it]: train_loss_raw=1.1896, running_loss=1.3207, LR=0.000100
[2025-08-26 11:10:00,790][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012208] [Batch 00686/00823] [00:08:20/00:01:40, 0.730s/it]: train_loss_raw=1.3949, running_loss=1.3221, LR=0.000100
[2025-08-26 11:10:06,703][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012216] [Batch 00694/00823] [00:08:26/00:01:34, 0.730s/it]: train_loss_raw=1.3049, running_loss=1.3218, LR=0.000100
[2025-08-26 11:10:12,501][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012224] [Batch 00702/00823] [00:08:32/00:01:28, 0.730s/it]: train_loss_raw=1.3343, running_loss=1.3229, LR=0.000100
[2025-08-26 11:10:18,256][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012232] [Batch 00710/00823] [00:08:38/00:01:22, 0.730s/it]: train_loss_raw=1.1972, running_loss=1.3217, LR=0.000100
[2025-08-26 11:10:24,031][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012240] [Batch 00718/00823] [00:08:44/00:01:16, 0.730s/it]: train_loss_raw=1.3361, running_loss=1.3217, LR=0.000100
[2025-08-26 11:10:30,165][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012248] [Batch 00726/00823] [00:08:50/00:01:10, 0.730s/it]: train_loss_raw=1.2776, running_loss=1.3211, LR=0.000100
[2025-08-26 11:10:36,078][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012256] [Batch 00734/00823] [00:08:56/00:01:05, 0.730s/it]: train_loss_raw=1.2781, running_loss=1.3207, LR=0.000100
[2025-08-26 11:10:41,987][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012264] [Batch 00742/00823] [00:09:02/00:00:59, 0.730s/it]: train_loss_raw=1.3244, running_loss=1.3212, LR=0.000100
[2025-08-26 11:10:47,853][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012272] [Batch 00750/00823] [00:09:07/00:00:53, 0.730s/it]: train_loss_raw=1.3489, running_loss=1.3222, LR=0.000100
[2025-08-26 11:10:53,679][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012280] [Batch 00758/00823] [00:09:13/00:00:47, 0.730s/it]: train_loss_raw=1.2950, running_loss=1.3197, LR=0.000100
[2025-08-26 11:10:59,451][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012288] [Batch 00766/00823] [00:09:19/00:00:41, 0.730s/it]: train_loss_raw=1.3572, running_loss=1.3185, LR=0.000100
[2025-08-26 11:11:05,227][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012296] [Batch 00774/00823] [00:09:25/00:00:35, 0.730s/it]: train_loss_raw=1.2653, running_loss=1.3182, LR=0.000100
[2025-08-26 11:11:10,991][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012304] [Batch 00782/00823] [00:09:31/00:00:29, 0.730s/it]: train_loss_raw=1.2544, running_loss=1.3177, LR=0.000100
[2025-08-26 11:11:16,791][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012312] [Batch 00790/00823] [00:09:36/00:00:24, 0.730s/it]: train_loss_raw=1.4131, running_loss=1.3193, LR=0.000100
[2025-08-26 11:11:22,609][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012320] [Batch 00798/00823] [00:09:42/00:00:18, 0.730s/it]: train_loss_raw=1.2900, running_loss=1.3167, LR=0.000100
[2025-08-26 11:11:28,418][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012328] [Batch 00806/00823] [00:09:48/00:00:12, 0.730s/it]: train_loss_raw=1.3025, running_loss=1.3151, LR=0.000100
[2025-08-26 11:11:34,189][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012336] [Batch 00814/00823] [00:09:54/00:00:06, 0.730s/it]: train_loss_raw=1.2142, running_loss=1.3141, LR=0.000100
[2025-08-26 11:11:40,023][__main__][INFO] - [TRAIN] [Epoch 14/29 Step 012344] [Batch 00822/00823] [00:10:00/00:00:00, 0.730s/it]: train_loss_raw=1.3480, running_loss=1.3140, LR=0.000100
[2025-08-26 11:11:40,945][__main__][INFO] - [VALIDATION] [Epoch 14/29] Starting validation.
[2025-08-26 11:11:51,473][__main__][INFO] - [VALIDATION] [Epoch 14/29 Step 012346] [Batch 00007/00013] [00:00:10/00:00:06, 1.316s/it]
[2025-08-26 11:11:58,698][__main__][INFO] - [VALIDATION] [Epoch 14/29] train_loss=1.31438, valid_loss=1.45881
[2025-08-26 11:11:58,698][__main__][INFO] - [VALIDATION] [Epoch 14/29] Metrics:
[2025-08-26 11:11:58,699][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_er      0.640
[2025-08-26 11:11:58,699][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_prec    0.057
[2025-08-26 11:11:58,699][__main__][INFO] - [VALIDATION] [Epoch 14/29] - aa_recall  0.058
[2025-08-26 11:11:58,699][__main__][INFO] - [VALIDATION] [Epoch 14/29] - pep_recall 0.014
[2025-08-26 11:11:58,702][__main__][INFO] - [TRAIN] [Epoch 14/29] Epoch complete, total time 02:39:22, remaining time 02:39:22, 00:10:37 per epoch
[2025-08-26 11:12:04,318][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012352] [Batch 00007/00823] [00:00:04/00:08:54, 0.655s/it]: train_loss_raw=1.3220, running_loss=1.3853, LR=0.000100
[2025-08-26 11:12:10,151][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012360] [Batch 00015/00823] [00:00:10/00:09:21, 0.694s/it]: train_loss_raw=1.3521, running_loss=1.3786, LR=0.000100
[2025-08-26 11:12:16,470][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012368] [Batch 00023/00823] [00:00:16/00:09:42, 0.728s/it]: train_loss_raw=1.3299, running_loss=1.3766, LR=0.000100
[2025-08-26 11:12:22,292][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012376] [Batch 00031/00823] [00:00:22/00:09:36, 0.728s/it]: train_loss_raw=1.3567, running_loss=1.3723, LR=0.000100
[2025-08-26 11:12:28,281][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012384] [Batch 00039/00823] [00:00:28/00:09:33, 0.732s/it]: train_loss_raw=1.3769, running_loss=1.3683, LR=0.000100
[2025-08-26 11:12:34,202][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012392] [Batch 00047/00823] [00:00:34/00:09:29, 0.733s/it]: train_loss_raw=1.1954, running_loss=1.3622, LR=0.000100
[2025-08-26 11:12:40,035][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012400] [Batch 00055/00823] [00:00:40/00:09:22, 0.733s/it]: train_loss_raw=1.3920, running_loss=1.3593, LR=0.000100
[2025-08-26 11:12:45,751][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012408] [Batch 00063/00823] [00:00:46/00:09:15, 0.730s/it]: train_loss_raw=1.3177, running_loss=1.3560, LR=0.000100
[2025-08-26 11:12:51,572][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012416] [Batch 00071/00823] [00:00:51/00:09:09, 0.730s/it]: train_loss_raw=1.2847, running_loss=1.3512, LR=0.000100
[2025-08-26 11:12:57,344][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012424] [Batch 00079/00823] [00:00:57/00:09:02, 0.729s/it]: train_loss_raw=1.3092, running_loss=1.3482, LR=0.000100
[2025-08-26 11:13:03,202][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012432] [Batch 00087/00823] [00:01:03/00:08:56, 0.730s/it]: train_loss_raw=1.3230, running_loss=1.3455, LR=0.000100
[2025-08-26 11:13:09,010][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012440] [Batch 00095/00823] [00:01:09/00:08:50, 0.729s/it]: train_loss_raw=1.2920, running_loss=1.3430, LR=0.000100
[2025-08-26 11:13:14,858][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012448] [Batch 00103/00823] [00:01:15/00:08:45, 0.729s/it]: train_loss_raw=1.2899, running_loss=1.3432, LR=0.000100
[2025-08-26 11:13:20,648][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012456] [Batch 00111/00823] [00:01:20/00:08:39, 0.729s/it]: train_loss_raw=1.2909, running_loss=1.3417, LR=0.000100
[2025-08-26 11:13:26,446][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012464] [Batch 00119/00823] [00:01:26/00:08:32, 0.729s/it]: train_loss_raw=1.2962, running_loss=1.3384, LR=0.000100
[2025-08-26 11:13:32,396][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012472] [Batch 00127/00823] [00:01:32/00:08:27, 0.730s/it]: train_loss_raw=1.3648, running_loss=1.3351, LR=0.000100
[2025-08-26 11:13:38,470][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012480] [Batch 00135/00823] [00:01:38/00:08:23, 0.731s/it]: train_loss_raw=1.2497, running_loss=1.3316, LR=0.000100
[2025-08-26 11:13:44,417][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012488] [Batch 00143/00823] [00:01:44/00:08:17, 0.732s/it]: train_loss_raw=1.3776, running_loss=1.3313, LR=0.000100
[2025-08-26 11:13:50,414][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012496] [Batch 00151/00823] [00:01:50/00:08:12, 0.733s/it]: train_loss_raw=1.2199, running_loss=1.3275, LR=0.000100
[2025-08-26 11:13:56,238][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012504] [Batch 00159/00823] [00:01:56/00:08:06, 0.733s/it]: train_loss_raw=1.3355, running_loss=1.3267, LR=0.000100
[2025-08-26 11:14:02,029][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012512] [Batch 00167/00823] [00:02:02/00:08:00, 0.732s/it]: train_loss_raw=1.3514, running_loss=1.3217, LR=0.000100
[2025-08-26 11:14:07,938][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012520] [Batch 00175/00823] [00:02:08/00:07:54, 0.733s/it]: train_loss_raw=1.2554, running_loss=1.3204, LR=0.000100
[2025-08-26 11:14:13,716][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012528] [Batch 00183/00823] [00:02:13/00:07:48, 0.732s/it]: train_loss_raw=1.4472, running_loss=1.3233, LR=0.000100
[2025-08-26 11:14:19,464][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012536] [Batch 00191/00823] [00:02:19/00:07:42, 0.732s/it]: train_loss_raw=1.2967, running_loss=1.3199, LR=0.000100
[2025-08-26 11:14:25,308][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012544] [Batch 00199/00823] [00:02:25/00:07:36, 0.732s/it]: train_loss_raw=1.3328, running_loss=1.3233, LR=0.000100
[2025-08-26 11:14:31,159][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012552] [Batch 00207/00823] [00:02:31/00:07:30, 0.732s/it]: train_loss_raw=1.2154, running_loss=1.3193, LR=0.000100
[2025-08-26 11:14:37,180][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012560] [Batch 00215/00823] [00:02:37/00:07:25, 0.732s/it]: train_loss_raw=1.3047, running_loss=1.3195, LR=0.000100
[2025-08-26 11:14:43,070][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012568] [Batch 00223/00823] [00:02:43/00:07:19, 0.732s/it]: train_loss_raw=1.2639, running_loss=1.3196, LR=0.000100
[2025-08-26 11:14:48,832][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012576] [Batch 00231/00823] [00:02:49/00:07:13, 0.732s/it]: train_loss_raw=1.2774, running_loss=1.3186, LR=0.000100
[2025-08-26 11:14:54,688][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012584] [Batch 00239/00823] [00:02:54/00:07:07, 0.732s/it]: train_loss_raw=1.4132, running_loss=1.3193, LR=0.000100
[2025-08-26 11:15:00,627][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012592] [Batch 00247/00823] [00:03:00/00:07:01, 0.732s/it]: train_loss_raw=1.3760, running_loss=1.3186, LR=0.000100
[2025-08-26 11:15:06,550][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012600] [Batch 00255/00823] [00:03:06/00:06:56, 0.733s/it]: train_loss_raw=1.4568, running_loss=1.3209, LR=0.000100
[2025-08-26 11:15:12,486][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012608] [Batch 00263/00823] [00:03:12/00:06:50, 0.733s/it]: train_loss_raw=1.1729, running_loss=1.3194, LR=0.000100
[2025-08-26 11:15:18,306][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012616] [Batch 00271/00823] [00:03:18/00:06:44, 0.733s/it]: train_loss_raw=1.2568, running_loss=1.3190, LR=0.000100
[2025-08-26 11:15:24,194][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012624] [Batch 00279/00823] [00:03:24/00:06:38, 0.733s/it]: train_loss_raw=1.3000, running_loss=1.3156, LR=0.000100
[2025-08-26 11:15:30,002][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012632] [Batch 00287/00823] [00:03:30/00:06:32, 0.733s/it]: train_loss_raw=1.3071, running_loss=1.3135, LR=0.000100
[2025-08-26 11:15:35,946][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012640] [Batch 00295/00823] [00:03:36/00:06:26, 0.733s/it]: train_loss_raw=1.2841, running_loss=1.3118, LR=0.000100
[2025-08-26 11:15:41,827][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012648] [Batch 00303/00823] [00:03:42/00:06:21, 0.733s/it]: train_loss_raw=1.2901, running_loss=1.3135, LR=0.000100
[2025-08-26 11:15:47,763][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012656] [Batch 00311/00823] [00:03:48/00:06:15, 0.733s/it]: train_loss_raw=1.3015, running_loss=1.3103, LR=0.000100
[2025-08-26 11:15:53,694][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012664] [Batch 00319/00823] [00:03:53/00:06:09, 0.733s/it]: train_loss_raw=1.2919, running_loss=1.3097, LR=0.000100
[2025-08-26 11:15:59,405][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012672] [Batch 00327/00823] [00:03:59/00:06:03, 0.733s/it]: train_loss_raw=1.2935, running_loss=1.3080, LR=0.000100
[2025-08-26 11:16:05,274][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012680] [Batch 00335/00823] [00:04:05/00:05:57, 0.733s/it]: train_loss_raw=1.2501, running_loss=1.3073, LR=0.000100
[2025-08-26 11:16:11,143][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012688] [Batch 00343/00823] [00:04:11/00:05:51, 0.733s/it]: train_loss_raw=1.3525, running_loss=1.3080, LR=0.000100
[2025-08-26 11:16:16,871][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012696] [Batch 00351/00823] [00:04:17/00:05:45, 0.733s/it]: train_loss_raw=1.2935, running_loss=1.3064, LR=0.000100
[2025-08-26 11:16:22,650][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012704] [Batch 00359/00823] [00:04:22/00:05:39, 0.732s/it]: train_loss_raw=1.3362, running_loss=1.3068, LR=0.000100
[2025-08-26 11:16:28,410][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012712] [Batch 00367/00823] [00:04:28/00:05:33, 0.732s/it]: train_loss_raw=1.3730, running_loss=1.3092, LR=0.000100
[2025-08-26 11:16:34,183][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012720] [Batch 00375/00823] [00:04:34/00:05:27, 0.732s/it]: train_loss_raw=1.2385, running_loss=1.3112, LR=0.000100
[2025-08-26 11:16:39,994][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012728] [Batch 00383/00823] [00:04:40/00:05:21, 0.732s/it]: train_loss_raw=1.3672, running_loss=1.3114, LR=0.000100
[2025-08-26 11:16:45,818][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012736] [Batch 00391/00823] [00:04:46/00:05:16, 0.732s/it]: train_loss_raw=1.3818, running_loss=1.3113, LR=0.000100
[2025-08-26 11:16:51,666][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012744] [Batch 00399/00823] [00:04:51/00:05:10, 0.732s/it]: train_loss_raw=1.2807, running_loss=1.3097, LR=0.000100
[2025-08-26 11:16:57,631][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012752] [Batch 00407/00823] [00:04:57/00:05:04, 0.732s/it]: train_loss_raw=1.3103, running_loss=1.3080, LR=0.000100
[2025-08-26 11:17:03,406][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012760] [Batch 00415/00823] [00:05:03/00:04:58, 0.732s/it]: train_loss_raw=1.3999, running_loss=1.3102, LR=0.000100
[2025-08-26 11:17:09,219][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012768] [Batch 00423/00823] [00:05:09/00:04:52, 0.732s/it]: train_loss_raw=1.2710, running_loss=1.3084, LR=0.000100
[2025-08-26 11:17:15,033][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012776] [Batch 00431/00823] [00:05:15/00:04:46, 0.732s/it]: train_loss_raw=1.2489, running_loss=1.3076, LR=0.000100
[2025-08-26 11:17:20,801][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012784] [Batch 00439/00823] [00:05:21/00:04:40, 0.731s/it]: train_loss_raw=1.3429, running_loss=1.3067, LR=0.000100
[2025-08-26 11:17:26,745][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012792] [Batch 00447/00823] [00:05:27/00:04:35, 0.732s/it]: train_loss_raw=1.3018, running_loss=1.3045, LR=0.000100
[2025-08-26 11:17:32,719][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012800] [Batch 00455/00823] [00:05:32/00:04:29, 0.732s/it]: train_loss_raw=1.1904, running_loss=1.3031, LR=0.000100
[2025-08-26 11:17:38,617][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012808] [Batch 00463/00823] [00:05:38/00:04:23, 0.732s/it]: train_loss_raw=1.2488, running_loss=1.3039, LR=0.000100
[2025-08-26 11:17:44,440][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012816] [Batch 00471/00823] [00:05:44/00:04:17, 0.732s/it]: train_loss_raw=1.3172, running_loss=1.3052, LR=0.000100
[2025-08-26 11:17:50,214][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012824] [Batch 00479/00823] [00:05:50/00:04:11, 0.732s/it]: train_loss_raw=1.3229, running_loss=1.3043, LR=0.000100
[2025-08-26 11:17:55,953][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012832] [Batch 00487/00823] [00:05:56/00:04:05, 0.731s/it]: train_loss_raw=1.3646, running_loss=1.3038, LR=0.000100
[2025-08-26 11:18:01,785][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012840] [Batch 00495/00823] [00:06:02/00:03:59, 0.731s/it]: train_loss_raw=1.3503, running_loss=1.3038, LR=0.000100
[2025-08-26 11:18:07,678][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012848] [Batch 00503/00823] [00:06:07/00:03:54, 0.731s/it]: train_loss_raw=1.2780, running_loss=1.3027, LR=0.000100
[2025-08-26 11:18:13,448][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012856] [Batch 00511/00823] [00:06:13/00:03:48, 0.731s/it]: train_loss_raw=1.3390, running_loss=1.3025, LR=0.000100
[2025-08-26 11:18:19,436][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012864] [Batch 00519/00823] [00:06:19/00:03:42, 0.732s/it]: train_loss_raw=1.3608, running_loss=1.3015, LR=0.000100
[2025-08-26 11:18:25,333][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012872] [Batch 00527/00823] [00:06:25/00:03:36, 0.732s/it]: train_loss_raw=1.2885, running_loss=1.3006, LR=0.000100
[2025-08-26 11:18:31,150][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012880] [Batch 00535/00823] [00:06:31/00:03:30, 0.732s/it]: train_loss_raw=1.3598, running_loss=1.3039, LR=0.000100
[2025-08-26 11:18:37,033][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012888] [Batch 00543/00823] [00:06:37/00:03:24, 0.732s/it]: train_loss_raw=1.2860, running_loss=1.3027, LR=0.000100
[2025-08-26 11:18:42,794][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012896] [Batch 00551/00823] [00:06:43/00:03:18, 0.732s/it]: train_loss_raw=1.2450, running_loss=1.3011, LR=0.000100
[2025-08-26 11:18:48,554][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012904] [Batch 00559/00823] [00:06:48/00:03:13, 0.731s/it]: train_loss_raw=1.3299, running_loss=1.3027, LR=0.000100
[2025-08-26 11:18:54,359][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012912] [Batch 00567/00823] [00:06:54/00:03:07, 0.731s/it]: train_loss_raw=1.2620, running_loss=1.2994, LR=0.000100
[2025-08-26 11:19:00,360][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012920] [Batch 00575/00823] [00:07:00/00:03:01, 0.732s/it]: train_loss_raw=1.2227, running_loss=1.3008, LR=0.000100
[2025-08-26 11:19:06,214][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012928] [Batch 00583/00823] [00:07:06/00:02:55, 0.732s/it]: train_loss_raw=1.3366, running_loss=1.3036, LR=0.000100
[2025-08-26 11:19:11,787][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012936] [Batch 00591/00823] [00:07:12/00:02:49, 0.731s/it]: train_loss_raw=1.2515, running_loss=1.3051, LR=0.000100
[2025-08-26 11:19:17,490][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012944] [Batch 00599/00823] [00:07:17/00:02:43, 0.731s/it]: train_loss_raw=1.2359, running_loss=1.3041, LR=0.000100
[2025-08-26 11:19:23,305][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012952] [Batch 00607/00823] [00:07:23/00:02:37, 0.731s/it]: train_loss_raw=1.2484, running_loss=1.3021, LR=0.000100
[2025-08-26 11:19:29,157][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012960] [Batch 00615/00823] [00:07:29/00:02:31, 0.731s/it]: train_loss_raw=1.3218, running_loss=1.2989, LR=0.000100
[2025-08-26 11:19:35,085][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012968] [Batch 00623/00823] [00:07:35/00:02:26, 0.731s/it]: train_loss_raw=1.3693, running_loss=1.2981, LR=0.000100
[2025-08-26 11:19:40,957][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012976] [Batch 00631/00823] [00:07:41/00:02:20, 0.731s/it]: train_loss_raw=1.3235, running_loss=1.2965, LR=0.000100
[2025-08-26 11:19:46,794][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012984] [Batch 00639/00823] [00:07:47/00:02:14, 0.731s/it]: train_loss_raw=1.4369, running_loss=1.3003, LR=0.000100
[2025-08-26 11:19:52,688][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 012992] [Batch 00647/00823] [00:07:52/00:02:08, 0.731s/it]: train_loss_raw=1.3329, running_loss=1.3029, LR=0.000100
[2025-08-26 11:19:58,522][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013000] [Batch 00655/00823] [00:07:58/00:02:02, 0.731s/it]: train_loss_raw=1.2986, running_loss=1.3039, LR=0.000100
[2025-08-26 11:20:04,477][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013008] [Batch 00663/00823] [00:08:04/00:01:56, 0.731s/it]: train_loss_raw=1.1931, running_loss=1.3007, LR=0.000100
[2025-08-26 11:20:10,391][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013016] [Batch 00671/00823] [00:08:10/00:01:51, 0.731s/it]: train_loss_raw=1.3303, running_loss=1.3009, LR=0.000100
[2025-08-26 11:20:16,340][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013024] [Batch 00679/00823] [00:08:16/00:01:45, 0.731s/it]: train_loss_raw=1.3105, running_loss=1.2977, LR=0.000100
[2025-08-26 11:20:22,345][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013032] [Batch 00687/00823] [00:08:22/00:01:39, 0.732s/it]: train_loss_raw=1.3887, running_loss=1.3012, LR=0.000100
[2025-08-26 11:20:28,256][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013040] [Batch 00695/00823] [00:08:28/00:01:33, 0.732s/it]: train_loss_raw=1.2683, running_loss=1.3018, LR=0.000100
[2025-08-26 11:20:34,241][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013048] [Batch 00703/00823] [00:08:34/00:01:27, 0.732s/it]: train_loss_raw=1.2965, running_loss=1.2999, LR=0.000100
[2025-08-26 11:20:39,997][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013056] [Batch 00711/00823] [00:08:40/00:01:21, 0.732s/it]: train_loss_raw=1.2987, running_loss=1.3012, LR=0.000100
[2025-08-26 11:20:45,865][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013064] [Batch 00719/00823] [00:08:46/00:01:16, 0.732s/it]: train_loss_raw=1.3117, running_loss=1.3009, LR=0.000100
[2025-08-26 11:20:51,647][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013072] [Batch 00727/00823] [00:08:51/00:01:10, 0.732s/it]: train_loss_raw=1.2958, running_loss=1.3010, LR=0.000100
[2025-08-26 11:20:57,383][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013080] [Batch 00735/00823] [00:08:57/00:01:04, 0.731s/it]: train_loss_raw=1.3944, running_loss=1.3012, LR=0.000100
[2025-08-26 11:21:03,121][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013088] [Batch 00743/00823] [00:09:03/00:00:58, 0.731s/it]: train_loss_raw=1.3008, running_loss=1.3010, LR=0.000100
[2025-08-26 11:21:08,882][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013096] [Batch 00751/00823] [00:09:09/00:00:52, 0.731s/it]: train_loss_raw=1.3077, running_loss=1.3007, LR=0.000100
[2025-08-26 11:21:14,676][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013104] [Batch 00759/00823] [00:09:14/00:00:46, 0.731s/it]: train_loss_raw=1.3020, running_loss=1.3010, LR=0.000100
[2025-08-26 11:21:20,572][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013112] [Batch 00767/00823] [00:09:20/00:00:40, 0.731s/it]: train_loss_raw=1.2754, running_loss=1.2980, LR=0.000100
[2025-08-26 11:21:26,517][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013120] [Batch 00775/00823] [00:09:26/00:00:35, 0.731s/it]: train_loss_raw=1.2329, running_loss=1.2960, LR=0.000100
[2025-08-26 11:21:32,451][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013128] [Batch 00783/00823] [00:09:32/00:00:29, 0.731s/it]: train_loss_raw=1.2184, running_loss=1.2968, LR=0.000100
[2025-08-26 11:21:38,314][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013136] [Batch 00791/00823] [00:09:38/00:00:23, 0.731s/it]: train_loss_raw=1.2880, running_loss=1.2954, LR=0.000100
[2025-08-26 11:21:44,232][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013144] [Batch 00799/00823] [00:09:44/00:00:17, 0.732s/it]: train_loss_raw=1.2101, running_loss=1.2952, LR=0.000100
[2025-08-26 11:21:50,064][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013152] [Batch 00807/00823] [00:09:50/00:00:11, 0.732s/it]: train_loss_raw=1.2460, running_loss=1.2938, LR=0.000100
[2025-08-26 11:21:56,029][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013160] [Batch 00815/00823] [00:09:56/00:00:05, 0.732s/it]: train_loss_raw=1.3043, running_loss=1.2937, LR=0.000100
[2025-08-26 11:22:07,062][__main__][INFO] - [TRAIN] [Epoch 15/29 Step 013168] [Batch 00823/00823] [00:10:07/00:00:00, 0.738s/it]: train_loss_raw=1.2377, running_loss=1.2935, LR=0.000100
[2025-08-26 11:22:07,433][__main__][INFO] - [VALIDATION] [Epoch 15/29] Starting validation.
[2025-08-26 11:22:18,865][__main__][INFO] - [VALIDATION] [Epoch 15/29 Step 013169] [Batch 00007/00013] [00:00:11/00:00:07, 1.429s/it]
[2025-08-26 11:22:26,185][__main__][INFO] - [VALIDATION] [Epoch 15/29] train_loss=1.29346, valid_loss=1.43293
[2025-08-26 11:22:26,185][__main__][INFO] - [VALIDATION] [Epoch 15/29] Metrics:
[2025-08-26 11:22:26,186][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_er      0.603
[2025-08-26 11:22:26,186][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_prec    0.062
[2025-08-26 11:22:26,186][__main__][INFO] - [VALIDATION] [Epoch 15/29] - aa_recall  0.063
[2025-08-26 11:22:26,186][__main__][INFO] - [VALIDATION] [Epoch 15/29] - pep_recall 0.019
[2025-08-26 11:22:26,188][__main__][INFO] - [TRAIN] [Epoch 15/29] Epoch complete, total time 02:49:49, remaining time 02:28:36, 00:10:36 per epoch
[2025-08-26 11:22:31,835][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013176] [Batch 00008/00823] [00:00:05/00:09:12, 0.678s/it]: train_loss_raw=1.2613, running_loss=1.2265, LR=0.000100
[2025-08-26 11:22:37,707][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013184] [Batch 00016/00823] [00:00:11/00:09:29, 0.706s/it]: train_loss_raw=1.1864, running_loss=1.2288, LR=0.000100
[2025-08-26 11:22:43,401][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013192] [Batch 00024/00823] [00:00:16/00:09:25, 0.708s/it]: train_loss_raw=1.3255, running_loss=1.2326, LR=0.000100
[2025-08-26 11:22:49,136][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013200] [Batch 00032/00823] [00:00:22/00:09:21, 0.710s/it]: train_loss_raw=1.2380, running_loss=1.2343, LR=0.000100
[2025-08-26 11:22:54,910][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013208] [Batch 00040/00823] [00:00:28/00:09:17, 0.712s/it]: train_loss_raw=1.2221, running_loss=1.2355, LR=0.000100
[2025-08-26 11:23:00,824][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013216] [Batch 00048/00823] [00:00:34/00:09:15, 0.717s/it]: train_loss_raw=1.2685, running_loss=1.2354, LR=0.000100
[2025-08-26 11:23:06,580][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013224] [Batch 00056/00823] [00:00:40/00:09:10, 0.717s/it]: train_loss_raw=1.2088, running_loss=1.2347, LR=0.000100
[2025-08-26 11:23:12,411][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013232] [Batch 00064/00823] [00:00:45/00:09:05, 0.719s/it]: train_loss_raw=1.2748, running_loss=1.2391, LR=0.000100
[2025-08-26 11:23:18,200][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013240] [Batch 00072/00823] [00:00:51/00:09:00, 0.719s/it]: train_loss_raw=1.3814, running_loss=1.2418, LR=0.000100
[2025-08-26 11:23:23,966][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013248] [Batch 00080/00823] [00:00:57/00:08:54, 0.719s/it]: train_loss_raw=1.3243, running_loss=1.2437, LR=0.000100
[2025-08-26 11:23:29,879][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013256] [Batch 00088/00823] [00:01:03/00:08:50, 0.721s/it]: train_loss_raw=1.2893, running_loss=1.2458, LR=0.000100
[2025-08-26 11:23:35,847][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013264] [Batch 00096/00823] [00:01:09/00:08:45, 0.723s/it]: train_loss_raw=1.2432, running_loss=1.2479, LR=0.000100
[2025-08-26 11:23:41,747][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013272] [Batch 00104/00823] [00:01:15/00:08:40, 0.724s/it]: train_loss_raw=1.1721, running_loss=1.2482, LR=0.000100
[2025-08-26 11:23:47,817][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013280] [Batch 00112/00823] [00:01:21/00:08:36, 0.727s/it]: train_loss_raw=1.2001, running_loss=1.2478, LR=0.000100
[2025-08-26 11:23:53,837][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013288] [Batch 00120/00823] [00:01:27/00:08:32, 0.729s/it]: train_loss_raw=1.2171, running_loss=1.2469, LR=0.000100
[2025-08-26 11:23:59,721][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013296] [Batch 00128/00823] [00:01:33/00:08:26, 0.729s/it]: train_loss_raw=1.3362, running_loss=1.2495, LR=0.000100
[2025-08-26 11:24:05,597][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013304] [Batch 00136/00823] [00:01:39/00:08:21, 0.729s/it]: train_loss_raw=1.2285, running_loss=1.2491, LR=0.000100
[2025-08-26 11:24:11,432][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013312] [Batch 00144/00823] [00:01:45/00:08:15, 0.729s/it]: train_loss_raw=1.2706, running_loss=1.2481, LR=0.000100
[2025-08-26 11:24:17,170][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013320] [Batch 00152/00823] [00:01:50/00:08:08, 0.729s/it]: train_loss_raw=1.1523, running_loss=1.2476, LR=0.000100
[2025-08-26 11:24:22,959][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013328] [Batch 00160/00823] [00:01:56/00:08:02, 0.728s/it]: train_loss_raw=1.2593, running_loss=1.2478, LR=0.000100
[2025-08-26 11:24:28,844][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013336] [Batch 00168/00823] [00:02:02/00:07:57, 0.729s/it]: train_loss_raw=1.2861, running_loss=1.2482, LR=0.000100
[2025-08-26 11:24:34,842][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013344] [Batch 00176/00823] [00:02:08/00:07:52, 0.730s/it]: train_loss_raw=1.2121, running_loss=1.2491, LR=0.000100
[2025-08-26 11:24:40,596][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013352] [Batch 00184/00823] [00:02:14/00:07:45, 0.729s/it]: train_loss_raw=1.2316, running_loss=1.2495, LR=0.000100
[2025-08-26 11:24:46,536][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013360] [Batch 00192/00823] [00:02:20/00:07:40, 0.730s/it]: train_loss_raw=1.3083, running_loss=1.2531, LR=0.000100
[2025-08-26 11:24:52,432][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013368] [Batch 00200/00823] [00:02:26/00:07:34, 0.730s/it]: train_loss_raw=1.2587, running_loss=1.2517, LR=0.000100
[2025-08-26 11:24:58,196][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013376] [Batch 00208/00823] [00:02:31/00:07:28, 0.730s/it]: train_loss_raw=1.2429, running_loss=1.2536, LR=0.000100
[2025-08-26 11:25:03,997][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013384] [Batch 00216/00823] [00:02:37/00:07:22, 0.730s/it]: train_loss_raw=1.2071, running_loss=1.2530, LR=0.000100
[2025-08-26 11:25:09,999][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013392] [Batch 00224/00823] [00:02:43/00:07:17, 0.730s/it]: train_loss_raw=1.2175, running_loss=1.2518, LR=0.000100
[2025-08-26 11:25:15,824][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013400] [Batch 00232/00823] [00:02:49/00:07:11, 0.730s/it]: train_loss_raw=1.1649, running_loss=1.2519, LR=0.000100
[2025-08-26 11:25:21,860][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013408] [Batch 00240/00823] [00:02:55/00:07:06, 0.731s/it]: train_loss_raw=1.2537, running_loss=1.2512, LR=0.000100
[2025-08-26 11:25:27,707][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013416] [Batch 00248/00823] [00:03:01/00:07:00, 0.731s/it]: train_loss_raw=1.3078, running_loss=1.2525, LR=0.000100
[2025-08-26 11:25:33,603][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013424] [Batch 00256/00823] [00:03:07/00:06:54, 0.731s/it]: train_loss_raw=1.3293, running_loss=1.2556, LR=0.000100
[2025-08-26 11:25:39,646][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013432] [Batch 00264/00823] [00:03:13/00:06:49, 0.732s/it]: train_loss_raw=1.3278, running_loss=1.2565, LR=0.000100
[2025-08-26 11:25:45,404][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013440] [Batch 00272/00823] [00:03:18/00:06:43, 0.732s/it]: train_loss_raw=1.2896, running_loss=1.2558, LR=0.000100
[2025-08-26 11:25:51,383][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013448] [Batch 00280/00823] [00:03:24/00:06:37, 0.732s/it]: train_loss_raw=1.2957, running_loss=1.2565, LR=0.000100
[2025-08-26 11:25:57,379][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013456] [Batch 00288/00823] [00:03:30/00:06:31, 0.733s/it]: train_loss_raw=1.0831, running_loss=1.2556, LR=0.000100
[2025-08-26 11:26:03,212][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013464] [Batch 00296/00823] [00:03:36/00:06:25, 0.732s/it]: train_loss_raw=1.2178, running_loss=1.2569, LR=0.000100
[2025-08-26 11:26:09,138][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013472] [Batch 00304/00823] [00:03:42/00:06:20, 0.733s/it]: train_loss_raw=1.3499, running_loss=1.2575, LR=0.000100
[2025-08-26 11:26:15,044][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013480] [Batch 00312/00823] [00:03:48/00:06:14, 0.733s/it]: train_loss_raw=1.3201, running_loss=1.2565, LR=0.000100
[2025-08-26 11:26:20,920][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013488] [Batch 00320/00823] [00:03:54/00:06:08, 0.733s/it]: train_loss_raw=1.2047, running_loss=1.2564, LR=0.000100
[2025-08-26 11:26:26,874][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013496] [Batch 00328/00823] [00:04:00/00:06:02, 0.733s/it]: train_loss_raw=1.2860, running_loss=1.2564, LR=0.000100
[2025-08-26 11:26:32,706][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013504] [Batch 00336/00823] [00:04:06/00:05:56, 0.733s/it]: train_loss_raw=1.1863, running_loss=1.2558, LR=0.000100
[2025-08-26 11:26:38,530][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013512] [Batch 00344/00823] [00:04:12/00:05:51, 0.733s/it]: train_loss_raw=1.2980, running_loss=1.2534, LR=0.000100
[2025-08-26 11:26:44,281][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013520] [Batch 00352/00823] [00:04:17/00:05:45, 0.733s/it]: train_loss_raw=1.2142, running_loss=1.2521, LR=0.000100
[2025-08-26 11:26:50,124][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013528] [Batch 00360/00823] [00:04:23/00:05:39, 0.733s/it]: train_loss_raw=1.2001, running_loss=1.2524, LR=0.000100
[2025-08-26 11:26:55,970][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013536] [Batch 00368/00823] [00:04:29/00:05:33, 0.732s/it]: train_loss_raw=1.2153, running_loss=1.2518, LR=0.000100
[2025-08-26 11:27:01,840][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013544] [Batch 00376/00823] [00:04:35/00:05:27, 0.733s/it]: train_loss_raw=1.2529, running_loss=1.2500, LR=0.000100
[2025-08-26 11:27:07,664][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013552] [Batch 00384/00823] [00:04:41/00:05:21, 0.732s/it]: train_loss_raw=1.2453, running_loss=1.2503, LR=0.000100
[2025-08-26 11:27:13,537][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013560] [Batch 00392/00823] [00:04:47/00:05:15, 0.732s/it]: train_loss_raw=1.3035, running_loss=1.2502, LR=0.000100
[2025-08-26 11:27:19,423][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013568] [Batch 00400/00823] [00:04:53/00:05:09, 0.733s/it]: train_loss_raw=1.2993, running_loss=1.2524, LR=0.000100
[2025-08-26 11:27:25,259][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013576] [Batch 00408/00823] [00:04:58/00:05:03, 0.732s/it]: train_loss_raw=1.3374, running_loss=1.2544, LR=0.000100
[2025-08-26 11:27:31,189][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013584] [Batch 00416/00823] [00:05:04/00:04:58, 0.733s/it]: train_loss_raw=1.1613, running_loss=1.2500, LR=0.000100
[2025-08-26 11:27:37,124][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013592] [Batch 00424/00823] [00:05:10/00:04:52, 0.733s/it]: train_loss_raw=1.3619, running_loss=1.2502, LR=0.000100
[2025-08-26 11:27:42,960][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013600] [Batch 00432/00823] [00:05:16/00:04:46, 0.733s/it]: train_loss_raw=1.2994, running_loss=1.2515, LR=0.000100
[2025-08-26 11:27:48,751][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013608] [Batch 00440/00823] [00:05:22/00:04:40, 0.733s/it]: train_loss_raw=1.2739, running_loss=1.2510, LR=0.000100
[2025-08-26 11:27:54,572][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013616] [Batch 00448/00823] [00:05:28/00:04:34, 0.732s/it]: train_loss_raw=1.3539, running_loss=1.2516, LR=0.000100
[2025-08-26 11:28:00,640][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013624] [Batch 00456/00823] [00:05:34/00:04:28, 0.733s/it]: train_loss_raw=1.2147, running_loss=1.2518, LR=0.000100
[2025-08-26 11:28:06,797][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013632] [Batch 00464/00823] [00:05:40/00:04:23, 0.734s/it]: train_loss_raw=1.2435, running_loss=1.2522, LR=0.000100
[2025-08-26 11:28:12,825][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013640] [Batch 00472/00823] [00:05:46/00:04:17, 0.734s/it]: train_loss_raw=1.2793, running_loss=1.2525, LR=0.000100
[2025-08-26 11:28:18,773][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013648] [Batch 00480/00823] [00:05:52/00:04:11, 0.734s/it]: train_loss_raw=1.1394, running_loss=1.2505, LR=0.000100
[2025-08-26 11:28:24,604][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013656] [Batch 00488/00823] [00:05:58/00:04:05, 0.734s/it]: train_loss_raw=1.3293, running_loss=1.2508, LR=0.000100
[2025-08-26 11:28:30,391][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013664] [Batch 00496/00823] [00:06:03/00:03:59, 0.734s/it]: train_loss_raw=1.2277, running_loss=1.2496, LR=0.000100
[2025-08-26 11:28:36,285][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013672] [Batch 00504/00823] [00:06:09/00:03:54, 0.734s/it]: train_loss_raw=1.2302, running_loss=1.2493, LR=0.000100
[2025-08-26 11:28:42,183][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013680] [Batch 00512/00823] [00:06:15/00:03:48, 0.734s/it]: train_loss_raw=1.2433, running_loss=1.2493, LR=0.000100
[2025-08-26 11:28:47,990][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013688] [Batch 00520/00823] [00:06:21/00:03:42, 0.734s/it]: train_loss_raw=1.2674, running_loss=1.2476, LR=0.000100
[2025-08-26 11:28:53,894][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013696] [Batch 00528/00823] [00:06:27/00:03:36, 0.734s/it]: train_loss_raw=1.2313, running_loss=1.2471, LR=0.000100
[2025-08-26 11:28:59,802][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013704] [Batch 00536/00823] [00:06:33/00:03:30, 0.734s/it]: train_loss_raw=1.1799, running_loss=1.2475, LR=0.000100
[2025-08-26 11:29:05,868][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013712] [Batch 00544/00823] [00:06:39/00:03:24, 0.734s/it]: train_loss_raw=1.3273, running_loss=1.2482, LR=0.000100
[2025-08-26 11:29:11,660][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013720] [Batch 00552/00823] [00:06:45/00:03:18, 0.734s/it]: train_loss_raw=1.3059, running_loss=1.2468, LR=0.000100
[2025-08-26 11:29:17,438][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013728] [Batch 00560/00823] [00:06:51/00:03:13, 0.734s/it]: train_loss_raw=1.3095, running_loss=1.2474, LR=0.000100
[2025-08-26 11:29:23,185][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013736] [Batch 00568/00823] [00:06:56/00:03:07, 0.734s/it]: train_loss_raw=1.2018, running_loss=1.2472, LR=0.000100
[2025-08-26 11:29:28,982][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013744] [Batch 00576/00823] [00:07:02/00:03:01, 0.734s/it]: train_loss_raw=1.1741, running_loss=1.2473, LR=0.000100
[2025-08-26 11:29:34,832][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013752] [Batch 00584/00823] [00:07:08/00:02:55, 0.734s/it]: train_loss_raw=1.2036, running_loss=1.2466, LR=0.000100
[2025-08-26 11:29:40,839][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013760] [Batch 00592/00823] [00:07:14/00:02:49, 0.734s/it]: train_loss_raw=1.2750, running_loss=1.2460, LR=0.000100
[2025-08-26 11:29:46,892][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013768] [Batch 00600/00823] [00:07:20/00:02:43, 0.734s/it]: train_loss_raw=1.2873, running_loss=1.2443, LR=0.000100
[2025-08-26 11:29:52,723][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013776] [Batch 00608/00823] [00:07:26/00:02:37, 0.734s/it]: train_loss_raw=1.2832, running_loss=1.2458, LR=0.000100
[2025-08-26 11:29:58,699][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013784] [Batch 00616/00823] [00:07:32/00:02:31, 0.734s/it]: train_loss_raw=1.1073, running_loss=1.2430, LR=0.000100
[2025-08-26 11:30:04,487][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013792] [Batch 00624/00823] [00:07:38/00:02:26, 0.734s/it]: train_loss_raw=1.1916, running_loss=1.2406, LR=0.000100
[2025-08-26 11:30:10,262][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013800] [Batch 00632/00823] [00:07:43/00:02:20, 0.734s/it]: train_loss_raw=1.2050, running_loss=1.2412, LR=0.000100
[2025-08-26 11:30:16,119][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013808] [Batch 00640/00823] [00:07:49/00:02:14, 0.734s/it]: train_loss_raw=1.2454, running_loss=1.2419, LR=0.000100
[2025-08-26 11:30:21,770][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013816] [Batch 00648/00823] [00:07:55/00:02:08, 0.734s/it]: train_loss_raw=1.2438, running_loss=1.2414, LR=0.000100
[2025-08-26 11:30:27,423][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013824] [Batch 00656/00823] [00:08:01/00:02:02, 0.733s/it]: train_loss_raw=1.2787, running_loss=1.2447, LR=0.000100
[2025-08-26 11:30:33,126][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013832] [Batch 00664/00823] [00:08:06/00:01:56, 0.733s/it]: train_loss_raw=1.2821, running_loss=1.2449, LR=0.000100
[2025-08-26 11:30:38,966][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013840] [Batch 00672/00823] [00:08:12/00:01:50, 0.733s/it]: train_loss_raw=1.1932, running_loss=1.2428, LR=0.000100
[2025-08-26 11:30:44,873][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013848] [Batch 00680/00823] [00:08:18/00:01:44, 0.733s/it]: train_loss_raw=1.2316, running_loss=1.2412, LR=0.000100
[2025-08-26 11:30:50,623][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013856] [Batch 00688/00823] [00:08:24/00:01:38, 0.733s/it]: train_loss_raw=1.2226, running_loss=1.2412, LR=0.000100
[2025-08-26 11:30:56,363][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013864] [Batch 00696/00823] [00:08:29/00:01:33, 0.733s/it]: train_loss_raw=1.1921, running_loss=1.2384, LR=0.000100
[2025-08-26 11:31:01,887][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013872] [Batch 00704/00823] [00:08:35/00:01:27, 0.732s/it]: train_loss_raw=1.1999, running_loss=1.2371, LR=0.000100
[2025-08-26 11:31:07,425][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013880] [Batch 00712/00823] [00:08:41/00:01:21, 0.732s/it]: train_loss_raw=1.2988, running_loss=1.2357, LR=0.000100
[2025-08-26 11:31:12,980][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013888] [Batch 00720/00823] [00:08:46/00:01:15, 0.731s/it]: train_loss_raw=1.2202, running_loss=1.2355, LR=0.000100
[2025-08-26 11:31:18,656][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013896] [Batch 00728/00823] [00:08:52/00:01:09, 0.731s/it]: train_loss_raw=1.1859, running_loss=1.2351, LR=0.000100
[2025-08-26 11:31:24,316][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013904] [Batch 00736/00823] [00:08:57/00:01:03, 0.731s/it]: train_loss_raw=1.1632, running_loss=1.2335, LR=0.000100
[2025-08-26 11:31:30,103][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013912] [Batch 00744/00823] [00:09:03/00:00:57, 0.731s/it]: train_loss_raw=1.1927, running_loss=1.2320, LR=0.000100
[2025-08-26 11:31:36,111][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013920] [Batch 00752/00823] [00:09:09/00:00:51, 0.731s/it]: train_loss_raw=1.2099, running_loss=1.2317, LR=0.000100
[2025-08-26 11:31:41,872][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013928] [Batch 00760/00823] [00:09:15/00:00:46, 0.731s/it]: train_loss_raw=1.2780, running_loss=1.2340, LR=0.000100
[2025-08-26 11:31:47,589][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013936] [Batch 00768/00823] [00:09:21/00:00:40, 0.731s/it]: train_loss_raw=1.1707, running_loss=1.2352, LR=0.000100
[2025-08-26 11:31:53,446][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013944] [Batch 00776/00823] [00:09:27/00:00:34, 0.731s/it]: train_loss_raw=1.2104, running_loss=1.2365, LR=0.000100
[2025-08-26 11:31:59,222][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013952] [Batch 00784/00823] [00:09:32/00:00:28, 0.731s/it]: train_loss_raw=1.3779, running_loss=1.2390, LR=0.000100
[2025-08-26 11:32:05,182][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013960] [Batch 00792/00823] [00:09:38/00:00:22, 0.731s/it]: train_loss_raw=1.2172, running_loss=1.2353, LR=0.000100
[2025-08-26 11:32:11,135][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013968] [Batch 00800/00823] [00:09:44/00:00:16, 0.731s/it]: train_loss_raw=1.2176, running_loss=1.2372, LR=0.000100
[2025-08-26 11:32:17,039][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013976] [Batch 00808/00823] [00:09:50/00:00:10, 0.731s/it]: train_loss_raw=1.2290, running_loss=1.2355, LR=0.000100
[2025-08-26 11:32:22,836][__main__][INFO] - [TRAIN] [Epoch 16/29 Step 013984] [Batch 00816/00823] [00:09:56/00:00:05, 0.731s/it]: train_loss_raw=1.2065, running_loss=1.2342, LR=0.000100
[2025-08-26 11:32:28,243][__main__][INFO] - [VALIDATION] [Epoch 16/29] Starting validation.
[2025-08-26 11:32:38,683][__main__][INFO] - [VALIDATION] [Epoch 16/29 Step 013992] [Batch 00007/00013] [00:00:10/00:00:06, 1.305s/it]
[2025-08-26 11:32:45,902][__main__][INFO] - [VALIDATION] [Epoch 16/29] train_loss=1.23433, valid_loss=1.41600
[2025-08-26 11:32:45,903][__main__][INFO] - [VALIDATION] [Epoch 16/29] Metrics:
[2025-08-26 11:32:45,903][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_er      0.619
[2025-08-26 11:32:45,903][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_prec    0.065
[2025-08-26 11:32:45,903][__main__][INFO] - [VALIDATION] [Epoch 16/29] - aa_recall  0.066
[2025-08-26 11:32:45,903][__main__][INFO] - [VALIDATION] [Epoch 16/29] - pep_recall 0.021
[2025-08-26 11:32:45,905][__main__][INFO] - [TRAIN] [Epoch 16/29] Epoch complete, total time 03:00:09, remaining time 02:17:46, 00:10:35 per epoch
[2025-08-26 11:32:47,092][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 013992] [Batch 00001/00823] [00:00:00/00:01:57, 0.143s/it]: train_loss_raw=1.2981, running_loss=1.2981, LR=0.000100
[2025-08-26 11:32:53,112][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014000] [Batch 00009/00823] [00:00:06/00:09:17, 0.685s/it]: train_loss_raw=1.2031, running_loss=1.2922, LR=0.000100
[2025-08-26 11:33:02,504][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014008] [Batch 00017/00823] [00:00:15/00:12:17, 0.915s/it]: train_loss_raw=1.2292, running_loss=1.2901, LR=0.000100
[2025-08-26 11:33:08,314][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014016] [Batch 00025/00823] [00:00:21/00:11:21, 0.855s/it]: train_loss_raw=1.1663, running_loss=1.2843, LR=0.000100
[2025-08-26 11:33:14,060][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014024] [Batch 00033/00823] [00:00:27/00:10:49, 0.822s/it]: train_loss_raw=1.2056, running_loss=1.2801, LR=0.000100
[2025-08-26 11:33:19,953][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014032] [Batch 00041/00823] [00:00:33/00:10:29, 0.805s/it]: train_loss_raw=1.3444, running_loss=1.2778, LR=0.000100
[2025-08-26 11:33:25,873][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014040] [Batch 00049/00823] [00:00:38/00:10:14, 0.794s/it]: train_loss_raw=1.1695, running_loss=1.2730, LR=0.000100
[2025-08-26 11:33:31,629][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014048] [Batch 00057/00823] [00:00:44/00:10:00, 0.784s/it]: train_loss_raw=1.2203, running_loss=1.2715, LR=0.000100
[2025-08-26 11:33:37,588][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014056] [Batch 00065/00823] [00:00:50/00:09:50, 0.779s/it]: train_loss_raw=1.3101, running_loss=1.2680, LR=0.000100
[2025-08-26 11:33:43,537][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014064] [Batch 00073/00823] [00:00:56/00:09:41, 0.775s/it]: train_loss_raw=1.2700, running_loss=1.2648, LR=0.000100
[2025-08-26 11:33:49,519][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014072] [Batch 00081/00823] [00:01:02/00:09:33, 0.772s/it]: train_loss_raw=1.2127, running_loss=1.2618, LR=0.000100
[2025-08-26 11:33:55,227][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014080] [Batch 00089/00823] [00:01:08/00:09:23, 0.767s/it]: train_loss_raw=1.2271, running_loss=1.2575, LR=0.000100
[2025-08-26 11:34:00,933][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014088] [Batch 00097/00823] [00:01:13/00:09:13, 0.763s/it]: train_loss_raw=1.2642, running_loss=1.2569, LR=0.000100
[2025-08-26 11:34:06,963][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014096] [Batch 00105/00823] [00:01:20/00:09:07, 0.762s/it]: train_loss_raw=1.2017, running_loss=1.2554, LR=0.000100
[2025-08-26 11:34:12,802][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014104] [Batch 00113/00823] [00:01:25/00:08:59, 0.760s/it]: train_loss_raw=1.2696, running_loss=1.2529, LR=0.000100
[2025-08-26 11:34:18,680][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014112] [Batch 00121/00823] [00:01:31/00:08:52, 0.758s/it]: train_loss_raw=1.2426, running_loss=1.2533, LR=0.000100
[2025-08-26 11:34:24,450][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014120] [Batch 00129/00823] [00:01:37/00:08:44, 0.756s/it]: train_loss_raw=1.1965, running_loss=1.2515, LR=0.000100
[2025-08-26 11:34:30,335][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014128] [Batch 00137/00823] [00:01:43/00:08:37, 0.755s/it]: train_loss_raw=1.3146, running_loss=1.2514, LR=0.000100
[2025-08-26 11:34:36,391][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014136] [Batch 00145/00823] [00:01:49/00:08:31, 0.755s/it]: train_loss_raw=1.2463, running_loss=1.2513, LR=0.000100
[2025-08-26 11:34:42,310][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014144] [Batch 00153/00823] [00:01:55/00:08:25, 0.754s/it]: train_loss_raw=1.1403, running_loss=1.2516, LR=0.000100
[2025-08-26 11:34:48,218][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014152] [Batch 00161/00823] [00:02:01/00:08:18, 0.753s/it]: train_loss_raw=1.2487, running_loss=1.2507, LR=0.000100
[2025-08-26 11:34:54,143][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014160] [Batch 00169/00823] [00:02:07/00:08:12, 0.753s/it]: train_loss_raw=1.2203, running_loss=1.2502, LR=0.000100
[2025-08-26 11:34:59,894][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014168] [Batch 00177/00823] [00:02:12/00:08:05, 0.751s/it]: train_loss_raw=1.2656, running_loss=1.2478, LR=0.000100
[2025-08-26 11:35:05,808][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014176] [Batch 00185/00823] [00:02:18/00:07:58, 0.751s/it]: train_loss_raw=1.1821, running_loss=1.2466, LR=0.000100
[2025-08-26 11:35:11,864][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014184] [Batch 00193/00823] [00:02:24/00:07:53, 0.751s/it]: train_loss_raw=1.2711, running_loss=1.2449, LR=0.000100
[2025-08-26 11:35:17,819][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014192] [Batch 00201/00823] [00:02:30/00:07:46, 0.751s/it]: train_loss_raw=1.1997, running_loss=1.2424, LR=0.000100
[2025-08-26 11:35:23,757][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014200] [Batch 00209/00823] [00:02:36/00:07:40, 0.750s/it]: train_loss_raw=1.2304, running_loss=1.2444, LR=0.000100
[2025-08-26 11:35:29,623][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014208] [Batch 00217/00823] [00:02:42/00:07:34, 0.750s/it]: train_loss_raw=1.1819, running_loss=1.2439, LR=0.000100
[2025-08-26 11:35:35,766][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014216] [Batch 00225/00823] [00:02:48/00:07:28, 0.750s/it]: train_loss_raw=1.1755, running_loss=1.2430, LR=0.000100
[2025-08-26 11:35:41,754][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014224] [Batch 00233/00823] [00:02:54/00:07:22, 0.750s/it]: train_loss_raw=1.2278, running_loss=1.2427, LR=0.000100
[2025-08-26 11:35:47,651][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014232] [Batch 00241/00823] [00:03:00/00:07:16, 0.750s/it]: train_loss_raw=1.1836, running_loss=1.2438, LR=0.000100
[2025-08-26 11:35:53,628][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014240] [Batch 00249/00823] [00:03:06/00:07:10, 0.750s/it]: train_loss_raw=1.1768, running_loss=1.2426, LR=0.000100
[2025-08-26 11:35:59,674][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014248] [Batch 00257/00823] [00:03:12/00:07:04, 0.750s/it]: train_loss_raw=1.2447, running_loss=1.2422, LR=0.000100
[2025-08-26 11:36:05,655][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014256] [Batch 00265/00823] [00:03:18/00:06:58, 0.750s/it]: train_loss_raw=1.2189, running_loss=1.2407, LR=0.000100
[2025-08-26 11:36:11,584][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014264] [Batch 00273/00823] [00:03:24/00:06:52, 0.750s/it]: train_loss_raw=1.3084, running_loss=1.2425, LR=0.000100
[2025-08-26 11:36:17,433][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014272] [Batch 00281/00823] [00:03:30/00:06:45, 0.749s/it]: train_loss_raw=1.2262, running_loss=1.2435, LR=0.000100
[2025-08-26 11:36:23,418][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014280] [Batch 00289/00823] [00:03:36/00:06:39, 0.749s/it]: train_loss_raw=1.2378, running_loss=1.2429, LR=0.000100
[2025-08-26 11:36:29,303][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014288] [Batch 00297/00823] [00:03:42/00:06:33, 0.749s/it]: train_loss_raw=1.2009, running_loss=1.2383, LR=0.000100
[2025-08-26 11:36:34,939][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014296] [Batch 00305/00823] [00:03:47/00:06:27, 0.748s/it]: train_loss_raw=1.2250, running_loss=1.2374, LR=0.000100
[2025-08-26 11:36:40,740][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014304] [Batch 00313/00823] [00:03:53/00:06:20, 0.747s/it]: train_loss_raw=1.2458, running_loss=1.2362, LR=0.000100
[2025-08-26 11:36:46,522][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014312] [Batch 00321/00823] [00:03:59/00:06:14, 0.746s/it]: train_loss_raw=1.2866, running_loss=1.2348, LR=0.000100
[2025-08-26 11:36:52,245][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014320] [Batch 00329/00823] [00:04:05/00:06:08, 0.746s/it]: train_loss_raw=1.1529, running_loss=1.2331, LR=0.000100
[2025-08-26 11:36:58,022][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014328] [Batch 00337/00823] [00:04:11/00:06:02, 0.745s/it]: train_loss_raw=1.2393, running_loss=1.2314, LR=0.000100
[2025-08-26 11:37:03,781][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014336] [Batch 00345/00823] [00:04:16/00:05:55, 0.744s/it]: train_loss_raw=1.2244, running_loss=1.2311, LR=0.000100
[2025-08-26 11:37:09,719][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014344] [Batch 00353/00823] [00:04:22/00:05:49, 0.744s/it]: train_loss_raw=1.2772, running_loss=1.2314, LR=0.000100
[2025-08-26 11:37:15,687][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014352] [Batch 00361/00823] [00:04:28/00:05:43, 0.744s/it]: train_loss_raw=1.2563, running_loss=1.2279, LR=0.000100
[2025-08-26 11:37:21,532][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014360] [Batch 00369/00823] [00:04:34/00:05:37, 0.744s/it]: train_loss_raw=1.2244, running_loss=1.2295, LR=0.000100
[2025-08-26 11:37:27,331][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014368] [Batch 00377/00823] [00:04:40/00:05:31, 0.744s/it]: train_loss_raw=1.2893, running_loss=1.2284, LR=0.000100
[2025-08-26 11:37:33,149][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014376] [Batch 00385/00823] [00:04:46/00:05:25, 0.743s/it]: train_loss_raw=1.3530, running_loss=1.2299, LR=0.000100
[2025-08-26 11:37:39,131][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014384] [Batch 00393/00823] [00:04:52/00:05:19, 0.743s/it]: train_loss_raw=1.2918, running_loss=1.2306, LR=0.000100
[2025-08-26 11:37:45,178][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014392] [Batch 00401/00823] [00:04:58/00:05:13, 0.744s/it]: train_loss_raw=1.2308, running_loss=1.2276, LR=0.000100
[2025-08-26 11:37:51,088][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014400] [Batch 00409/00823] [00:05:04/00:05:07, 0.744s/it]: train_loss_raw=1.2973, running_loss=1.2282, LR=0.000100
[2025-08-26 11:37:56,969][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014408] [Batch 00417/00823] [00:05:10/00:05:01, 0.743s/it]: train_loss_raw=1.2542, running_loss=1.2267, LR=0.000100
[2025-08-26 11:38:02,906][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014416] [Batch 00425/00823] [00:05:15/00:04:55, 0.743s/it]: train_loss_raw=1.2047, running_loss=1.2269, LR=0.000100
[2025-08-26 11:38:08,761][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014424] [Batch 00433/00823] [00:05:21/00:04:49, 0.743s/it]: train_loss_raw=1.3555, running_loss=1.2273, LR=0.000100
[2025-08-26 11:38:14,582][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014432] [Batch 00441/00823] [00:05:27/00:04:43, 0.743s/it]: train_loss_raw=1.2569, running_loss=1.2293, LR=0.000100
[2025-08-26 11:38:20,354][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014440] [Batch 00449/00823] [00:05:33/00:04:37, 0.743s/it]: train_loss_raw=1.1347, running_loss=1.2253, LR=0.000100
[2025-08-26 11:38:26,204][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014448] [Batch 00457/00823] [00:05:39/00:04:31, 0.742s/it]: train_loss_raw=1.3045, running_loss=1.2261, LR=0.000100
[2025-08-26 11:38:31,929][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014456] [Batch 00465/00823] [00:05:44/00:04:25, 0.742s/it]: train_loss_raw=1.1012, running_loss=1.2225, LR=0.000100
[2025-08-26 11:38:37,696][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014464] [Batch 00473/00823] [00:05:50/00:04:19, 0.742s/it]: train_loss_raw=1.3142, running_loss=1.2220, LR=0.000100
[2025-08-26 11:38:43,555][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014472] [Batch 00481/00823] [00:05:56/00:04:13, 0.741s/it]: train_loss_raw=1.1680, running_loss=1.2214, LR=0.000100
[2025-08-26 11:38:49,411][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014480] [Batch 00489/00823] [00:06:02/00:04:07, 0.741s/it]: train_loss_raw=1.2280, running_loss=1.2224, LR=0.000100
[2025-08-26 11:38:55,176][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014488] [Batch 00497/00823] [00:06:08/00:04:01, 0.741s/it]: train_loss_raw=1.1700, running_loss=1.2227, LR=0.000100
[2025-08-26 11:39:01,073][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014496] [Batch 00505/00823] [00:06:14/00:03:55, 0.741s/it]: train_loss_raw=1.1642, running_loss=1.2212, LR=0.000100
[2025-08-26 11:39:06,861][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014504] [Batch 00513/00823] [00:06:19/00:03:49, 0.741s/it]: train_loss_raw=1.2178, running_loss=1.2223, LR=0.000100
[2025-08-26 11:39:12,377][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014512] [Batch 00521/00823] [00:06:25/00:03:43, 0.740s/it]: train_loss_raw=1.2689, running_loss=1.2236, LR=0.000100
[2025-08-26 11:39:18,193][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014520] [Batch 00529/00823] [00:06:31/00:03:37, 0.740s/it]: train_loss_raw=1.2321, running_loss=1.2274, LR=0.000100
[2025-08-26 11:39:24,092][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014528] [Batch 00537/00823] [00:06:37/00:03:31, 0.740s/it]: train_loss_raw=1.2722, running_loss=1.2271, LR=0.000100
[2025-08-26 11:39:30,048][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014536] [Batch 00545/00823] [00:06:43/00:03:25, 0.740s/it]: train_loss_raw=1.2365, running_loss=1.2245, LR=0.000100
[2025-08-26 11:39:35,991][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014544] [Batch 00553/00823] [00:06:49/00:03:19, 0.740s/it]: train_loss_raw=1.2447, running_loss=1.2229, LR=0.000100
[2025-08-26 11:39:41,930][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014552] [Batch 00561/00823] [00:06:54/00:03:13, 0.740s/it]: train_loss_raw=1.1401, running_loss=1.2215, LR=0.000100
[2025-08-26 11:39:47,648][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014560] [Batch 00569/00823] [00:07:00/00:03:07, 0.739s/it]: train_loss_raw=1.1510, running_loss=1.2231, LR=0.000100
[2025-08-26 11:39:53,422][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014568] [Batch 00577/00823] [00:07:06/00:03:01, 0.739s/it]: train_loss_raw=1.3118, running_loss=1.2234, LR=0.000100
[2025-08-26 11:39:59,273][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014576] [Batch 00585/00823] [00:07:12/00:02:55, 0.739s/it]: train_loss_raw=1.2618, running_loss=1.2243, LR=0.000100
[2025-08-26 11:40:05,027][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014584] [Batch 00593/00823] [00:07:18/00:02:49, 0.739s/it]: train_loss_raw=1.2531, running_loss=1.2244, LR=0.000100
[2025-08-26 11:40:10,874][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014592] [Batch 00601/00823] [00:07:23/00:02:43, 0.739s/it]: train_loss_raw=1.2496, running_loss=1.2215, LR=0.000100
[2025-08-26 11:40:16,644][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014600] [Batch 00609/00823] [00:07:29/00:02:38, 0.738s/it]: train_loss_raw=1.2316, running_loss=1.2209, LR=0.000100
[2025-08-26 11:40:22,506][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014608] [Batch 00617/00823] [00:07:35/00:02:32, 0.738s/it]: train_loss_raw=1.2480, running_loss=1.2204, LR=0.000100
[2025-08-26 11:40:28,199][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014616] [Batch 00625/00823] [00:07:41/00:02:26, 0.738s/it]: train_loss_raw=1.2243, running_loss=1.2210, LR=0.000100
[2025-08-26 11:40:33,977][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014624] [Batch 00633/00823] [00:07:47/00:02:20, 0.738s/it]: train_loss_raw=1.2140, running_loss=1.2203, LR=0.000100
[2025-08-26 11:40:39,755][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014632] [Batch 00641/00823] [00:07:52/00:02:14, 0.738s/it]: train_loss_raw=1.2260, running_loss=1.2214, LR=0.000100
[2025-08-26 11:40:45,535][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014640] [Batch 00649/00823] [00:07:58/00:02:08, 0.737s/it]: train_loss_raw=1.1478, running_loss=1.2212, LR=0.000100
[2025-08-26 11:40:51,291][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014648] [Batch 00657/00823] [00:08:04/00:02:02, 0.737s/it]: train_loss_raw=1.2428, running_loss=1.2231, LR=0.000100
[2025-08-26 11:40:57,126][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014656] [Batch 00665/00823] [00:08:10/00:01:56, 0.737s/it]: train_loss_raw=1.2415, running_loss=1.2241, LR=0.000100
[2025-08-26 11:41:03,153][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014664] [Batch 00673/00823] [00:08:16/00:01:50, 0.737s/it]: train_loss_raw=1.2802, running_loss=1.2238, LR=0.000100
[2025-08-26 11:41:09,041][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014672] [Batch 00681/00823] [00:08:22/00:01:44, 0.737s/it]: train_loss_raw=1.1837, running_loss=1.2219, LR=0.000100
[2025-08-26 11:41:14,913][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014680] [Batch 00689/00823] [00:08:27/00:01:38, 0.737s/it]: train_loss_raw=1.2025, running_loss=1.2225, LR=0.000100
[2025-08-26 11:41:20,716][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014688] [Batch 00697/00823] [00:08:33/00:01:32, 0.737s/it]: train_loss_raw=1.2635, running_loss=1.2235, LR=0.000100
[2025-08-26 11:41:26,536][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014696] [Batch 00705/00823] [00:08:39/00:01:26, 0.737s/it]: train_loss_raw=1.2322, running_loss=1.2248, LR=0.000100
[2025-08-26 11:41:32,397][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014704] [Batch 00713/00823] [00:08:45/00:01:21, 0.737s/it]: train_loss_raw=1.2041, running_loss=1.2263, LR=0.000100
[2025-08-26 11:41:38,147][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014712] [Batch 00721/00823] [00:08:51/00:01:15, 0.737s/it]: train_loss_raw=1.1578, running_loss=1.2270, LR=0.000100
[2025-08-26 11:41:43,963][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014720] [Batch 00729/00823] [00:08:57/00:01:09, 0.737s/it]: train_loss_raw=1.1500, running_loss=1.2230, LR=0.000100
[2025-08-26 11:41:49,951][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014728] [Batch 00737/00823] [00:09:03/00:01:03, 0.737s/it]: train_loss_raw=1.2104, running_loss=1.2217, LR=0.000100
[2025-08-26 11:41:55,841][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014736] [Batch 00745/00823] [00:09:08/00:00:57, 0.737s/it]: train_loss_raw=1.1760, running_loss=1.2207, LR=0.000100
[2025-08-26 11:42:01,632][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014744] [Batch 00753/00823] [00:09:14/00:00:51, 0.737s/it]: train_loss_raw=1.1797, running_loss=1.2225, LR=0.000100
[2025-08-26 11:42:07,503][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014752] [Batch 00761/00823] [00:09:20/00:00:45, 0.737s/it]: train_loss_raw=1.2291, running_loss=1.2227, LR=0.000100
[2025-08-26 11:42:13,219][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014760] [Batch 00769/00823] [00:09:26/00:00:39, 0.736s/it]: train_loss_raw=1.1456, running_loss=1.2228, LR=0.000100
[2025-08-26 11:42:18,922][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014768] [Batch 00777/00823] [00:09:31/00:00:33, 0.736s/it]: train_loss_raw=1.1890, running_loss=1.2206, LR=0.000100
[2025-08-26 11:42:24,733][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014776] [Batch 00785/00823] [00:09:37/00:00:27, 0.736s/it]: train_loss_raw=1.1382, running_loss=1.2190, LR=0.000100
[2025-08-26 11:42:30,526][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014784] [Batch 00793/00823] [00:09:43/00:00:22, 0.736s/it]: train_loss_raw=1.2250, running_loss=1.2202, LR=0.000100
[2025-08-26 11:42:36,278][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014792] [Batch 00801/00823] [00:09:49/00:00:16, 0.736s/it]: train_loss_raw=1.1895, running_loss=1.2192, LR=0.000100
[2025-08-26 11:42:42,082][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014800] [Batch 00809/00823] [00:09:55/00:00:10, 0.736s/it]: train_loss_raw=1.3333, running_loss=1.2215, LR=0.000100
[2025-08-26 11:42:47,843][__main__][INFO] - [TRAIN] [Epoch 17/29 Step 014808] [Batch 00817/00823] [00:10:00/00:00:04, 0.735s/it]: train_loss_raw=1.2589, running_loss=1.2242, LR=0.000100
[2025-08-26 11:42:58,007][__main__][INFO] - [VALIDATION] [Epoch 17/29] Starting validation.
[2025-08-26 11:43:08,884][__main__][INFO] - [VALIDATION] [Epoch 17/29 Step 014815] [Batch 00007/00013] [00:00:10/00:00:06, 1.360s/it]
[2025-08-26 11:43:16,136][__main__][INFO] - [VALIDATION] [Epoch 17/29] train_loss=1.22315, valid_loss=1.40648
[2025-08-26 11:43:16,136][__main__][INFO] - [VALIDATION] [Epoch 17/29] Metrics:
[2025-08-26 11:43:16,136][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_er      0.593
[2025-08-26 11:43:16,137][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_prec    0.071
[2025-08-26 11:43:16,137][__main__][INFO] - [VALIDATION] [Epoch 17/29] - aa_recall  0.073
[2025-08-26 11:43:16,137][__main__][INFO] - [VALIDATION] [Epoch 17/29] - pep_recall 0.024
[2025-08-26 11:43:16,140][__main__][INFO] - [TRAIN] [Epoch 17/29] Epoch complete, total time 03:10:39, remaining time 02:07:06, 00:10:35 per epoch
[2025-08-26 11:43:18,564][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014816] [Batch 00002/00823] [00:00:01/00:07:00, 0.512s/it]: train_loss_raw=1.1401, running_loss=1.1658, LR=0.000100
[2025-08-26 11:43:24,748][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014824] [Batch 00010/00823] [00:00:07/00:09:45, 0.721s/it]: train_loss_raw=1.2118, running_loss=1.1659, LR=0.000100
[2025-08-26 11:43:30,887][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014832] [Batch 00018/00823] [00:00:13/00:09:56, 0.741s/it]: train_loss_raw=1.2178, running_loss=1.1671, LR=0.000100
[2025-08-26 11:43:36,683][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014840] [Batch 00026/00823] [00:00:19/00:09:46, 0.736s/it]: train_loss_raw=1.1881, running_loss=1.1694, LR=0.000100
[2025-08-26 11:43:42,403][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014848] [Batch 00034/00823] [00:00:24/00:09:36, 0.731s/it]: train_loss_raw=1.1012, running_loss=1.1666, LR=0.000100
[2025-08-26 11:43:48,253][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014856] [Batch 00042/00823] [00:00:30/00:09:31, 0.731s/it]: train_loss_raw=1.1526, running_loss=1.1676, LR=0.000100
[2025-08-26 11:43:54,028][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014864] [Batch 00050/00823] [00:00:36/00:09:24, 0.730s/it]: train_loss_raw=1.1299, running_loss=1.1666, LR=0.000100
[2025-08-26 11:43:59,866][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014872] [Batch 00058/00823] [00:00:42/00:09:18, 0.730s/it]: train_loss_raw=1.2061, running_loss=1.1649, LR=0.000100
[2025-08-26 11:44:05,640][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014880] [Batch 00066/00823] [00:00:48/00:09:11, 0.729s/it]: train_loss_raw=1.1858, running_loss=1.1664, LR=0.000100
[2025-08-26 11:44:11,523][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014888] [Batch 00074/00823] [00:00:53/00:09:06, 0.729s/it]: train_loss_raw=1.1231, running_loss=1.1687, LR=0.000100
[2025-08-26 11:44:17,280][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014896] [Batch 00082/00823] [00:00:59/00:08:59, 0.729s/it]: train_loss_raw=1.2603, running_loss=1.1716, LR=0.000100
[2025-08-26 11:44:23,124][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014904] [Batch 00090/00823] [00:01:05/00:08:54, 0.729s/it]: train_loss_raw=1.3054, running_loss=1.1737, LR=0.000100
[2025-08-26 11:44:29,038][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014912] [Batch 00098/00823] [00:01:11/00:08:48, 0.730s/it]: train_loss_raw=1.1103, running_loss=1.1723, LR=0.000100
[2025-08-26 11:44:34,895][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014920] [Batch 00106/00823] [00:01:17/00:08:43, 0.730s/it]: train_loss_raw=1.1074, running_loss=1.1710, LR=0.000100
[2025-08-26 11:44:40,715][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014928] [Batch 00114/00823] [00:01:23/00:08:37, 0.730s/it]: train_loss_raw=1.1571, running_loss=1.1713, LR=0.000100
[2025-08-26 11:44:46,481][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014936] [Batch 00122/00823] [00:01:28/00:08:31, 0.729s/it]: train_loss_raw=1.2453, running_loss=1.1736, LR=0.000100
[2025-08-26 11:44:52,464][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014944] [Batch 00130/00823] [00:01:34/00:08:26, 0.730s/it]: train_loss_raw=1.2291, running_loss=1.1749, LR=0.000100
[2025-08-26 11:44:58,288][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014952] [Batch 00138/00823] [00:01:40/00:08:20, 0.730s/it]: train_loss_raw=1.1369, running_loss=1.1760, LR=0.000100
[2025-08-26 11:45:04,087][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014960] [Batch 00146/00823] [00:01:46/00:08:14, 0.730s/it]: train_loss_raw=1.1898, running_loss=1.1749, LR=0.000100
[2025-08-26 11:45:09,883][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014968] [Batch 00154/00823] [00:01:52/00:08:08, 0.729s/it]: train_loss_raw=1.1898, running_loss=1.1749, LR=0.000100
[2025-08-26 11:45:15,773][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014976] [Batch 00162/00823] [00:01:58/00:08:02, 0.730s/it]: train_loss_raw=1.1166, running_loss=1.1757, LR=0.000100
[2025-08-26 11:45:21,631][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014984] [Batch 00170/00823] [00:02:04/00:07:56, 0.730s/it]: train_loss_raw=1.1396, running_loss=1.1750, LR=0.000100
[2025-08-26 11:45:27,541][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 014992] [Batch 00178/00823] [00:02:10/00:07:51, 0.730s/it]: train_loss_raw=1.1884, running_loss=1.1768, LR=0.000100
[2025-08-26 11:45:33,412][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015000] [Batch 00186/00823] [00:02:15/00:07:45, 0.730s/it]: train_loss_raw=1.2260, running_loss=1.1770, LR=0.000100
[2025-08-26 11:45:39,229][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015008] [Batch 00194/00823] [00:02:21/00:07:39, 0.730s/it]: train_loss_raw=1.1729, running_loss=1.1749, LR=0.000100
[2025-08-26 11:45:44,961][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015016] [Batch 00202/00823] [00:02:27/00:07:33, 0.730s/it]: train_loss_raw=1.1813, running_loss=1.1761, LR=0.000100
[2025-08-26 11:45:50,724][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015024] [Batch 00210/00823] [00:02:33/00:07:27, 0.729s/it]: train_loss_raw=1.1277, running_loss=1.1778, LR=0.000100
[2025-08-26 11:45:56,530][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015032] [Batch 00218/00823] [00:02:38/00:07:21, 0.729s/it]: train_loss_raw=1.2798, running_loss=1.1795, LR=0.000100
[2025-08-26 11:46:02,501][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015040] [Batch 00226/00823] [00:02:44/00:07:15, 0.730s/it]: train_loss_raw=1.1698, running_loss=1.1788, LR=0.000100
[2025-08-26 11:46:08,215][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015048] [Batch 00234/00823] [00:02:50/00:07:09, 0.729s/it]: train_loss_raw=1.1964, running_loss=1.1794, LR=0.000100
[2025-08-26 11:46:14,033][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015056] [Batch 00242/00823] [00:02:56/00:07:03, 0.729s/it]: train_loss_raw=1.2296, running_loss=1.1804, LR=0.000100
[2025-08-26 11:46:19,988][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015064] [Batch 00250/00823] [00:03:02/00:06:58, 0.730s/it]: train_loss_raw=1.2633, running_loss=1.1791, LR=0.000100
[2025-08-26 11:46:25,751][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015072] [Batch 00258/00823] [00:03:08/00:06:52, 0.730s/it]: train_loss_raw=1.1220, running_loss=1.1765, LR=0.000100
[2025-08-26 11:46:31,692][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015080] [Batch 00266/00823] [00:03:14/00:06:46, 0.730s/it]: train_loss_raw=1.2412, running_loss=1.1792, LR=0.000100
[2025-08-26 11:46:37,766][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015088] [Batch 00274/00823] [00:03:20/00:06:41, 0.731s/it]: train_loss_raw=1.1775, running_loss=1.1818, LR=0.000100
[2025-08-26 11:46:43,769][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015096] [Batch 00282/00823] [00:03:26/00:06:35, 0.731s/it]: train_loss_raw=1.1240, running_loss=1.1809, LR=0.000100
[2025-08-26 11:46:49,550][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015104] [Batch 00290/00823] [00:03:32/00:06:29, 0.731s/it]: train_loss_raw=1.1256, running_loss=1.1807, LR=0.000100
[2025-08-26 11:46:55,323][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015112] [Batch 00298/00823] [00:03:37/00:06:23, 0.731s/it]: train_loss_raw=1.1966, running_loss=1.1804, LR=0.000100
[2025-08-26 11:47:01,158][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015120] [Batch 00306/00823] [00:03:43/00:06:17, 0.731s/it]: train_loss_raw=1.1982, running_loss=1.1802, LR=0.000100
[2025-08-26 11:47:06,985][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015128] [Batch 00314/00823] [00:03:49/00:06:11, 0.731s/it]: train_loss_raw=1.1130, running_loss=1.1786, LR=0.000100
[2025-08-26 11:47:12,858][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015136] [Batch 00322/00823] [00:03:55/00:06:06, 0.731s/it]: train_loss_raw=1.1195, running_loss=1.1775, LR=0.000100
[2025-08-26 11:47:18,770][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015144] [Batch 00330/00823] [00:04:01/00:06:00, 0.731s/it]: train_loss_raw=1.1296, running_loss=1.1772, LR=0.000100
[2025-08-26 11:47:24,758][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015152] [Batch 00338/00823] [00:04:07/00:05:54, 0.731s/it]: train_loss_raw=1.1857, running_loss=1.1778, LR=0.000100
[2025-08-26 11:47:30,775][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015160] [Batch 00346/00823] [00:04:13/00:05:49, 0.732s/it]: train_loss_raw=1.2193, running_loss=1.1799, LR=0.000100
[2025-08-26 11:47:36,518][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015168] [Batch 00354/00823] [00:04:18/00:05:43, 0.732s/it]: train_loss_raw=1.1211, running_loss=1.1801, LR=0.000100
[2025-08-26 11:47:42,349][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015176] [Batch 00362/00823] [00:04:24/00:05:37, 0.732s/it]: train_loss_raw=1.1981, running_loss=1.1793, LR=0.000100
[2025-08-26 11:47:48,262][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015184] [Batch 00370/00823] [00:04:30/00:05:31, 0.732s/it]: train_loss_raw=1.2110, running_loss=1.1801, LR=0.000100
[2025-08-26 11:47:54,260][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015192] [Batch 00378/00823] [00:04:36/00:05:25, 0.732s/it]: train_loss_raw=1.1556, running_loss=1.1781, LR=0.000100
[2025-08-26 11:48:00,069][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015200] [Batch 00386/00823] [00:04:42/00:05:19, 0.732s/it]: train_loss_raw=1.1480, running_loss=1.1770, LR=0.000100
[2025-08-26 11:48:05,887][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015208] [Batch 00394/00823] [00:04:48/00:05:13, 0.732s/it]: train_loss_raw=1.1074, running_loss=1.1754, LR=0.000100
[2025-08-26 11:48:11,861][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015216] [Batch 00402/00823] [00:04:54/00:05:08, 0.732s/it]: train_loss_raw=1.1213, running_loss=1.1750, LR=0.000100
[2025-08-26 11:48:17,741][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015224] [Batch 00410/00823] [00:05:00/00:05:02, 0.732s/it]: train_loss_raw=1.0896, running_loss=1.1725, LR=0.000100
[2025-08-26 11:48:23,511][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015232] [Batch 00418/00823] [00:05:05/00:04:56, 0.732s/it]: train_loss_raw=1.1626, running_loss=1.1716, LR=0.000100
[2025-08-26 11:48:29,300][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015240] [Batch 00426/00823] [00:05:11/00:04:50, 0.732s/it]: train_loss_raw=1.0641, running_loss=1.1724, LR=0.000100
[2025-08-26 11:48:35,159][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015248] [Batch 00434/00823] [00:05:17/00:04:44, 0.732s/it]: train_loss_raw=1.1191, running_loss=1.1726, LR=0.000100
[2025-08-26 11:48:40,986][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015256] [Batch 00442/00823] [00:05:23/00:04:38, 0.732s/it]: train_loss_raw=1.2035, running_loss=1.1705, LR=0.000100
[2025-08-26 11:48:46,878][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015264] [Batch 00450/00823] [00:05:29/00:04:32, 0.732s/it]: train_loss_raw=1.0198, running_loss=1.1687, LR=0.000100
[2025-08-26 11:48:52,764][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015272] [Batch 00458/00823] [00:05:35/00:04:27, 0.732s/it]: train_loss_raw=1.1215, running_loss=1.1644, LR=0.000100
[2025-08-26 11:48:58,659][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015280] [Batch 00466/00823] [00:05:41/00:04:21, 0.732s/it]: train_loss_raw=1.2612, running_loss=1.1646, LR=0.000100
[2025-08-26 11:49:04,637][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015288] [Batch 00474/00823] [00:05:47/00:04:15, 0.732s/it]: train_loss_raw=1.1276, running_loss=1.1632, LR=0.000100
[2025-08-26 11:49:10,365][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015296] [Batch 00482/00823] [00:05:52/00:04:09, 0.732s/it]: train_loss_raw=1.1325, running_loss=1.1641, LR=0.000100
[2025-08-26 11:49:16,270][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015304] [Batch 00490/00823] [00:05:58/00:04:03, 0.732s/it]: train_loss_raw=1.1539, running_loss=1.1662, LR=0.000100
[2025-08-26 11:49:22,262][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015312] [Batch 00498/00823] [00:06:04/00:03:58, 0.732s/it]: train_loss_raw=1.1880, running_loss=1.1665, LR=0.000100
[2025-08-26 11:49:28,267][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015320] [Batch 00506/00823] [00:06:10/00:03:52, 0.733s/it]: train_loss_raw=1.1848, running_loss=1.1678, LR=0.000100
[2025-08-26 11:49:34,080][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015328] [Batch 00514/00823] [00:06:16/00:03:46, 0.733s/it]: train_loss_raw=1.1789, running_loss=1.1678, LR=0.000100
[2025-08-26 11:49:40,015][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015336] [Batch 00522/00823] [00:06:22/00:03:40, 0.733s/it]: train_loss_raw=1.2309, running_loss=1.1699, LR=0.000100
[2025-08-26 11:49:45,867][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015344] [Batch 00530/00823] [00:06:28/00:03:34, 0.733s/it]: train_loss_raw=1.0939, running_loss=1.1695, LR=0.000100
[2025-08-26 11:49:51,731][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015352] [Batch 00538/00823] [00:06:34/00:03:28, 0.733s/it]: train_loss_raw=1.1035, running_loss=1.1702, LR=0.000100
[2025-08-26 11:49:57,570][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015360] [Batch 00546/00823] [00:06:40/00:03:22, 0.733s/it]: train_loss_raw=1.2651, running_loss=1.1707, LR=0.000100
[2025-08-26 11:50:03,335][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015368] [Batch 00554/00823] [00:06:45/00:03:17, 0.732s/it]: train_loss_raw=1.1541, running_loss=1.1714, LR=0.000100
[2025-08-26 11:50:09,126][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015376] [Batch 00562/00823] [00:06:51/00:03:11, 0.732s/it]: train_loss_raw=1.1292, running_loss=1.1716, LR=0.000100
[2025-08-26 11:50:15,068][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015384] [Batch 00570/00823] [00:06:57/00:03:05, 0.733s/it]: train_loss_raw=1.1914, running_loss=1.1704, LR=0.000100
[2025-08-26 11:50:20,909][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015392] [Batch 00578/00823] [00:07:03/00:02:59, 0.732s/it]: train_loss_raw=1.1406, running_loss=1.1682, LR=0.000100
[2025-08-26 11:50:26,753][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015400] [Batch 00586/00823] [00:07:09/00:02:53, 0.732s/it]: train_loss_raw=1.1070, running_loss=1.1689, LR=0.000100
[2025-08-26 11:50:32,513][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015408] [Batch 00594/00823] [00:07:14/00:02:47, 0.732s/it]: train_loss_raw=1.1208, running_loss=1.1678, LR=0.000100
[2025-08-26 11:50:38,378][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015416] [Batch 00602/00823] [00:07:20/00:02:41, 0.732s/it]: train_loss_raw=1.1788, running_loss=1.1684, LR=0.000100
[2025-08-26 11:50:44,249][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015424] [Batch 00610/00823] [00:07:26/00:02:35, 0.732s/it]: train_loss_raw=1.1564, running_loss=1.1663, LR=0.000100
[2025-08-26 11:50:50,178][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015432] [Batch 00618/00823] [00:07:32/00:02:30, 0.732s/it]: train_loss_raw=1.1924, running_loss=1.1690, LR=0.000100
[2025-08-26 11:50:56,096][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015440] [Batch 00626/00823] [00:07:38/00:02:24, 0.733s/it]: train_loss_raw=1.2311, running_loss=1.1699, LR=0.000100
[2025-08-26 11:51:01,951][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015448] [Batch 00634/00823] [00:07:44/00:02:18, 0.733s/it]: train_loss_raw=1.2271, running_loss=1.1716, LR=0.000100
[2025-08-26 11:51:07,705][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015456] [Batch 00642/00823] [00:07:50/00:02:12, 0.732s/it]: train_loss_raw=1.2408, running_loss=1.1721, LR=0.000100
[2025-08-26 11:51:13,461][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015464] [Batch 00650/00823] [00:07:55/00:02:06, 0.732s/it]: train_loss_raw=1.0767, running_loss=1.1733, LR=0.000100
[2025-08-26 11:51:19,436][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015472] [Batch 00658/00823] [00:08:01/00:02:00, 0.732s/it]: train_loss_raw=1.1625, running_loss=1.1733, LR=0.000100
[2025-08-26 11:51:25,247][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015480] [Batch 00666/00823] [00:08:07/00:01:54, 0.732s/it]: train_loss_raw=1.2071, running_loss=1.1711, LR=0.000100
[2025-08-26 11:51:31,163][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015488] [Batch 00674/00823] [00:08:13/00:01:49, 0.732s/it]: train_loss_raw=1.1371, running_loss=1.1711, LR=0.000100
[2025-08-26 11:51:37,143][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015496] [Batch 00682/00823] [00:08:19/00:01:43, 0.733s/it]: train_loss_raw=1.1361, running_loss=1.1714, LR=0.000100
[2025-08-26 11:51:42,909][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015504] [Batch 00690/00823] [00:08:25/00:01:37, 0.732s/it]: train_loss_raw=1.0879, running_loss=1.1713, LR=0.000100
[2025-08-26 11:51:48,755][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015512] [Batch 00698/00823] [00:08:31/00:01:31, 0.732s/it]: train_loss_raw=1.2674, running_loss=1.1736, LR=0.000100
[2025-08-26 11:51:54,474][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015520] [Batch 00706/00823] [00:08:36/00:01:25, 0.732s/it]: train_loss_raw=1.1104, running_loss=1.1731, LR=0.000100
[2025-08-26 11:52:00,385][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015528] [Batch 00714/00823] [00:08:42/00:01:19, 0.732s/it]: train_loss_raw=1.1638, running_loss=1.1720, LR=0.000100
[2025-08-26 11:52:06,323][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015536] [Batch 00722/00823] [00:08:48/00:01:13, 0.732s/it]: train_loss_raw=1.1564, running_loss=1.1708, LR=0.000100
[2025-08-26 11:52:12,252][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015544] [Batch 00730/00823] [00:08:54/00:01:08, 0.732s/it]: train_loss_raw=1.1411, running_loss=1.1714, LR=0.000100
[2025-08-26 11:52:18,094][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015552] [Batch 00738/00823] [00:09:00/00:01:02, 0.732s/it]: train_loss_raw=1.1451, running_loss=1.1703, LR=0.000100
[2025-08-26 11:52:23,939][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015560] [Batch 00746/00823] [00:09:06/00:00:56, 0.732s/it]: train_loss_raw=1.0878, running_loss=1.1684, LR=0.000100
[2025-08-26 11:52:29,789][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015568] [Batch 00754/00823] [00:09:12/00:00:50, 0.732s/it]: train_loss_raw=1.0841, running_loss=1.1682, LR=0.000100
[2025-08-26 11:52:35,615][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015576] [Batch 00762/00823] [00:09:18/00:00:44, 0.732s/it]: train_loss_raw=1.1993, running_loss=1.1689, LR=0.000100
[2025-08-26 11:52:41,494][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015584] [Batch 00770/00823] [00:09:23/00:00:38, 0.732s/it]: train_loss_raw=1.1127, running_loss=1.1704, LR=0.000100
[2025-08-26 11:52:47,440][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015592] [Batch 00778/00823] [00:09:29/00:00:32, 0.733s/it]: train_loss_raw=1.1450, running_loss=1.1701, LR=0.000100
[2025-08-26 11:52:53,296][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015600] [Batch 00786/00823] [00:09:35/00:00:27, 0.733s/it]: train_loss_raw=1.1674, running_loss=1.1694, LR=0.000100
[2025-08-26 11:52:59,180][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015608] [Batch 00794/00823] [00:09:41/00:00:21, 0.733s/it]: train_loss_raw=1.2168, running_loss=1.1685, LR=0.000100
[2025-08-26 11:53:05,007][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015616] [Batch 00802/00823] [00:09:47/00:00:15, 0.733s/it]: train_loss_raw=1.1447, running_loss=1.1675, LR=0.000100
[2025-08-26 11:53:10,752][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015624] [Batch 00810/00823] [00:09:53/00:00:09, 0.732s/it]: train_loss_raw=1.1677, running_loss=1.1658, LR=0.000100
[2025-08-26 11:53:16,815][__main__][INFO] - [TRAIN] [Epoch 18/29 Step 015632] [Batch 00818/00823] [00:09:59/00:00:03, 0.733s/it]: train_loss_raw=1.1491, running_loss=1.1647, LR=0.000100
[2025-08-26 11:53:20,760][__main__][INFO] - [VALIDATION] [Epoch 18/29] Starting validation.
[2025-08-26 11:53:31,452][__main__][INFO] - [VALIDATION] [Epoch 18/29 Step 015638] [Batch 00007/00013] [00:00:10/00:00:06, 1.336s/it]
[2025-08-26 11:53:38,174][__main__][INFO] - [VALIDATION] [Epoch 18/29] train_loss=1.16556, valid_loss=1.40505
[2025-08-26 11:53:38,175][__main__][INFO] - [VALIDATION] [Epoch 18/29] Metrics:
[2025-08-26 11:53:38,175][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_er      0.596
[2025-08-26 11:53:38,175][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_prec    0.073
[2025-08-26 11:53:38,175][__main__][INFO] - [VALIDATION] [Epoch 18/29] - aa_recall  0.074
[2025-08-26 11:53:38,175][__main__][INFO] - [VALIDATION] [Epoch 18/29] - pep_recall 0.025
[2025-08-26 11:53:38,177][__main__][INFO] - [TRAIN] [Epoch 18/29] Epoch complete, total time 03:21:01, remaining time 01:56:23, 00:10:34 per epoch
[2025-08-26 11:53:40,930][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015640] [Batch 00003/00823] [00:00:01/00:07:38, 0.559s/it]: train_loss_raw=1.2574, running_loss=1.1466, LR=0.000100
[2025-08-26 11:53:46,798][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015648] [Batch 00011/00823] [00:00:07/00:09:17, 0.686s/it]: train_loss_raw=1.1750, running_loss=1.1504, LR=0.000100
[2025-08-26 11:53:52,602][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015656] [Batch 00019/00823] [00:00:13/00:09:24, 0.703s/it]: train_loss_raw=1.1240, running_loss=1.1510, LR=0.000100
[2025-08-26 11:53:58,441][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015664] [Batch 00027/00823] [00:00:19/00:09:25, 0.711s/it]: train_loss_raw=1.1518, running_loss=1.1517, LR=0.000100
[2025-08-26 11:54:04,203][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015672] [Batch 00035/00823] [00:00:24/00:09:21, 0.713s/it]: train_loss_raw=1.1184, running_loss=1.1521, LR=0.000100
[2025-08-26 11:54:09,940][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015680] [Batch 00043/00823] [00:00:30/00:09:16, 0.714s/it]: train_loss_raw=1.1664, running_loss=1.1546, LR=0.000100
[2025-08-26 11:54:15,655][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015688] [Batch 00051/00823] [00:00:36/00:09:11, 0.714s/it]: train_loss_raw=1.2072, running_loss=1.1570, LR=0.000100
[2025-08-26 11:54:21,549][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015696] [Batch 00059/00823] [00:00:42/00:09:07, 0.717s/it]: train_loss_raw=1.2254, running_loss=1.1592, LR=0.000100
[2025-08-26 11:54:27,306][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015704] [Batch 00067/00823] [00:00:48/00:09:02, 0.717s/it]: train_loss_raw=1.1474, running_loss=1.1594, LR=0.000100
[2025-08-26 11:54:33,072][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015712] [Batch 00075/00823] [00:00:53/00:08:56, 0.718s/it]: train_loss_raw=1.1795, running_loss=1.1603, LR=0.000100
[2025-08-26 11:54:38,872][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015720] [Batch 00083/00823] [00:00:59/00:08:51, 0.718s/it]: train_loss_raw=1.2009, running_loss=1.1596, LR=0.000100
[2025-08-26 11:54:44,957][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015728] [Batch 00091/00823] [00:01:05/00:08:48, 0.722s/it]: train_loss_raw=1.2477, running_loss=1.1626, LR=0.000100
[2025-08-26 11:54:50,860][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015736] [Batch 00099/00823] [00:01:11/00:08:43, 0.723s/it]: train_loss_raw=1.0307, running_loss=1.1611, LR=0.000100
[2025-08-26 11:54:56,371][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015744] [Batch 00107/00823] [00:01:17/00:08:36, 0.721s/it]: train_loss_raw=1.1363, running_loss=1.1599, LR=0.000100
[2025-08-26 11:55:02,178][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015752] [Batch 00115/00823] [00:01:22/00:08:30, 0.721s/it]: train_loss_raw=1.1407, running_loss=1.1575, LR=0.000100
[2025-08-26 11:55:08,163][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015760] [Batch 00123/00823] [00:01:28/00:08:25, 0.723s/it]: train_loss_raw=1.0891, running_loss=1.1559, LR=0.000100
[2025-08-26 11:55:14,038][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015768] [Batch 00131/00823] [00:01:34/00:08:20, 0.724s/it]: train_loss_raw=1.1928, running_loss=1.1556, LR=0.000100
[2025-08-26 11:55:19,768][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015776] [Batch 00139/00823] [00:01:40/00:08:14, 0.723s/it]: train_loss_raw=1.2030, running_loss=1.1554, LR=0.000100
[2025-08-26 11:55:25,727][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015784] [Batch 00147/00823] [00:01:46/00:08:09, 0.724s/it]: train_loss_raw=1.1781, running_loss=1.1565, LR=0.000100
[2025-08-26 11:55:31,513][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015792] [Batch 00155/00823] [00:01:52/00:08:03, 0.724s/it]: train_loss_raw=1.2139, running_loss=1.1558, LR=0.000100
[2025-08-26 11:55:37,269][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015800] [Batch 00163/00823] [00:01:58/00:07:57, 0.724s/it]: train_loss_raw=1.1304, running_loss=1.1565, LR=0.000100
[2025-08-26 11:55:43,184][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015808] [Batch 00171/00823] [00:02:03/00:07:52, 0.725s/it]: train_loss_raw=1.2774, running_loss=1.1601, LR=0.000100
[2025-08-26 11:55:48,917][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015816] [Batch 00179/00823] [00:02:09/00:07:46, 0.724s/it]: train_loss_raw=1.0970, running_loss=1.1603, LR=0.000100
[2025-08-26 11:55:54,834][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015824] [Batch 00187/00823] [00:02:15/00:07:41, 0.725s/it]: train_loss_raw=1.1218, running_loss=1.1608, LR=0.000100
[2025-08-26 11:56:00,965][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015832] [Batch 00195/00823] [00:02:21/00:07:36, 0.727s/it]: train_loss_raw=1.2357, running_loss=1.1619, LR=0.000100
[2025-08-26 11:56:06,958][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015840] [Batch 00203/00823] [00:02:27/00:07:31, 0.728s/it]: train_loss_raw=1.0527, running_loss=1.1615, LR=0.000100
[2025-08-26 11:56:12,921][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015848] [Batch 00211/00823] [00:02:33/00:07:25, 0.728s/it]: train_loss_raw=1.1885, running_loss=1.1603, LR=0.000100
[2025-08-26 11:56:18,969][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015856] [Batch 00219/00823] [00:02:39/00:07:20, 0.729s/it]: train_loss_raw=1.1759, running_loss=1.1602, LR=0.000100
[2025-08-26 11:56:24,718][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015864] [Batch 00227/00823] [00:02:45/00:07:14, 0.729s/it]: train_loss_raw=1.2412, running_loss=1.1579, LR=0.000100
[2025-08-26 11:56:30,527][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015872] [Batch 00235/00823] [00:02:51/00:07:08, 0.729s/it]: train_loss_raw=1.2199, running_loss=1.1586, LR=0.000100
[2025-08-26 11:56:36,324][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015880] [Batch 00243/00823] [00:02:57/00:07:02, 0.729s/it]: train_loss_raw=1.1622, running_loss=1.1587, LR=0.000100
[2025-08-26 11:56:42,080][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015888] [Batch 00251/00823] [00:03:02/00:06:56, 0.728s/it]: train_loss_raw=1.0088, running_loss=1.1575, LR=0.000100
[2025-08-26 11:56:47,884][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015896] [Batch 00259/00823] [00:03:08/00:06:50, 0.728s/it]: train_loss_raw=1.2746, running_loss=1.1592, LR=0.000100
[2025-08-26 11:56:53,607][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015904] [Batch 00267/00823] [00:03:14/00:06:44, 0.728s/it]: train_loss_raw=1.0879, running_loss=1.1571, LR=0.000100
[2025-08-26 11:56:59,269][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015912] [Batch 00275/00823] [00:03:20/00:06:38, 0.727s/it]: train_loss_raw=1.1402, running_loss=1.1564, LR=0.000100
[2025-08-26 11:57:05,131][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015920] [Batch 00283/00823] [00:03:25/00:06:32, 0.727s/it]: train_loss_raw=1.1540, running_loss=1.1585, LR=0.000100
[2025-08-26 11:57:10,904][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015928] [Batch 00291/00823] [00:03:31/00:06:26, 0.727s/it]: train_loss_raw=1.0597, running_loss=1.1549, LR=0.000100
[2025-08-26 11:57:16,749][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015936] [Batch 00299/00823] [00:03:37/00:06:21, 0.727s/it]: train_loss_raw=1.0708, running_loss=1.1535, LR=0.000100
[2025-08-26 11:57:22,514][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015944] [Batch 00307/00823] [00:03:43/00:06:15, 0.727s/it]: train_loss_raw=1.1066, running_loss=1.1533, LR=0.000100
[2025-08-26 11:57:28,509][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015952] [Batch 00315/00823] [00:03:49/00:06:09, 0.728s/it]: train_loss_raw=1.2071, running_loss=1.1529, LR=0.000100
[2025-08-26 11:57:34,447][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015960] [Batch 00323/00823] [00:03:55/00:06:04, 0.728s/it]: train_loss_raw=1.0277, running_loss=1.1537, LR=0.000100
[2025-08-26 11:57:40,448][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015968] [Batch 00331/00823] [00:04:01/00:05:58, 0.729s/it]: train_loss_raw=1.1238, running_loss=1.1535, LR=0.000100
[2025-08-26 11:57:46,257][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015976] [Batch 00339/00823] [00:04:07/00:05:52, 0.729s/it]: train_loss_raw=1.1066, running_loss=1.1533, LR=0.000100
[2025-08-26 11:57:51,976][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015984] [Batch 00347/00823] [00:04:12/00:05:46, 0.728s/it]: train_loss_raw=1.0681, running_loss=1.1513, LR=0.000100
[2025-08-26 11:57:57,719][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 015992] [Batch 00355/00823] [00:04:18/00:05:40, 0.728s/it]: train_loss_raw=1.1866, running_loss=1.1549, LR=0.000100
[2025-08-26 11:58:03,674][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016000] [Batch 00363/00823] [00:04:24/00:05:35, 0.728s/it]: train_loss_raw=1.1855, running_loss=1.1549, LR=0.000100
[2025-08-26 11:58:13,475][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016008] [Batch 00371/00823] [00:04:34/00:05:34, 0.739s/it]: train_loss_raw=1.1280, running_loss=1.1578, LR=0.000100
[2025-08-26 11:58:19,214][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016016] [Batch 00379/00823] [00:04:39/00:05:27, 0.739s/it]: train_loss_raw=1.2564, running_loss=1.1622, LR=0.000100
[2025-08-26 11:58:24,996][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016024] [Batch 00387/00823] [00:04:45/00:05:21, 0.738s/it]: train_loss_raw=1.2016, running_loss=1.1630, LR=0.000100
[2025-08-26 11:58:30,781][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016032] [Batch 00395/00823] [00:04:51/00:05:15, 0.738s/it]: train_loss_raw=1.0960, running_loss=1.1621, LR=0.000100
[2025-08-26 11:58:36,583][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016040] [Batch 00403/00823] [00:04:57/00:05:09, 0.738s/it]: train_loss_raw=1.1854, running_loss=1.1598, LR=0.000100
[2025-08-26 11:58:42,322][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016048] [Batch 00411/00823] [00:05:03/00:05:03, 0.737s/it]: train_loss_raw=1.1304, running_loss=1.1602, LR=0.000100
[2025-08-26 11:58:48,098][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016056] [Batch 00419/00823] [00:05:08/00:04:57, 0.737s/it]: train_loss_raw=1.2398, running_loss=1.1624, LR=0.000100
[2025-08-26 11:58:54,166][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016064] [Batch 00427/00823] [00:05:14/00:04:52, 0.738s/it]: train_loss_raw=1.1314, running_loss=1.1643, LR=0.000100
[2025-08-26 11:59:00,136][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016072] [Batch 00435/00823] [00:05:20/00:04:46, 0.738s/it]: train_loss_raw=1.1579, running_loss=1.1655, LR=0.000100
[2025-08-26 11:59:06,012][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016080] [Batch 00443/00823] [00:05:26/00:04:40, 0.738s/it]: train_loss_raw=1.1384, running_loss=1.1658, LR=0.000100
[2025-08-26 11:59:11,879][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016088] [Batch 00451/00823] [00:05:32/00:04:34, 0.738s/it]: train_loss_raw=1.2161, running_loss=1.1634, LR=0.000100
[2025-08-26 11:59:17,784][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016096] [Batch 00459/00823] [00:05:38/00:04:28, 0.738s/it]: train_loss_raw=1.0933, running_loss=1.1621, LR=0.000100
[2025-08-26 11:59:23,475][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016104] [Batch 00467/00823] [00:05:44/00:04:22, 0.737s/it]: train_loss_raw=1.1836, running_loss=1.1602, LR=0.000100
[2025-08-26 11:59:29,399][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016112] [Batch 00475/00823] [00:05:50/00:04:16, 0.737s/it]: train_loss_raw=1.0777, running_loss=1.1593, LR=0.000100
[2025-08-26 11:59:35,441][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016120] [Batch 00483/00823] [00:05:56/00:04:10, 0.737s/it]: train_loss_raw=1.2207, running_loss=1.1590, LR=0.000100
[2025-08-26 11:59:41,277][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016128] [Batch 00491/00823] [00:06:02/00:04:04, 0.737s/it]: train_loss_raw=1.1418, running_loss=1.1583, LR=0.000100
[2025-08-26 11:59:47,043][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016136] [Batch 00499/00823] [00:06:07/00:03:58, 0.737s/it]: train_loss_raw=1.1441, running_loss=1.1554, LR=0.000100
[2025-08-26 11:59:52,974][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016144] [Batch 00507/00823] [00:06:13/00:03:52, 0.737s/it]: train_loss_raw=1.1588, running_loss=1.1532, LR=0.000100
[2025-08-26 11:59:58,715][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016152] [Batch 00515/00823] [00:06:19/00:03:46, 0.737s/it]: train_loss_raw=1.1811, running_loss=1.1535, LR=0.000100
[2025-08-26 12:00:04,610][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016160] [Batch 00523/00823] [00:06:25/00:03:41, 0.737s/it]: train_loss_raw=1.1485, running_loss=1.1538, LR=0.000100
[2025-08-26 12:00:10,414][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016168] [Batch 00531/00823] [00:06:31/00:03:35, 0.737s/it]: train_loss_raw=1.1212, running_loss=1.1547, LR=0.000100
[2025-08-26 12:00:16,227][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016176] [Batch 00539/00823] [00:06:36/00:03:29, 0.737s/it]: train_loss_raw=1.1357, running_loss=1.1541, LR=0.000100
[2025-08-26 12:00:22,217][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016184] [Batch 00547/00823] [00:06:42/00:03:23, 0.737s/it]: train_loss_raw=1.1722, running_loss=1.1545, LR=0.000100
[2025-08-26 12:00:28,088][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016192] [Batch 00555/00823] [00:06:48/00:03:17, 0.737s/it]: train_loss_raw=1.2732, running_loss=1.1565, LR=0.000100
[2025-08-26 12:00:33,937][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016200] [Batch 00563/00823] [00:06:54/00:03:11, 0.737s/it]: train_loss_raw=1.2165, running_loss=1.1534, LR=0.000100
[2025-08-26 12:00:39,928][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016208] [Batch 00571/00823] [00:07:00/00:03:05, 0.737s/it]: train_loss_raw=1.1648, running_loss=1.1542, LR=0.000100
[2025-08-26 12:00:45,678][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016216] [Batch 00579/00823] [00:07:06/00:02:59, 0.736s/it]: train_loss_raw=1.1514, running_loss=1.1542, LR=0.000100
[2025-08-26 12:00:51,481][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016224] [Batch 00587/00823] [00:07:12/00:02:53, 0.736s/it]: train_loss_raw=1.1288, running_loss=1.1531, LR=0.000100
[2025-08-26 12:00:57,224][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016232] [Batch 00595/00823] [00:07:17/00:02:47, 0.736s/it]: train_loss_raw=1.0236, running_loss=1.1501, LR=0.000100
[2025-08-26 12:01:03,043][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016240] [Batch 00603/00823] [00:07:23/00:02:41, 0.736s/it]: train_loss_raw=1.2133, running_loss=1.1487, LR=0.000100
[2025-08-26 12:01:08,792][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016248] [Batch 00611/00823] [00:07:29/00:02:35, 0.736s/it]: train_loss_raw=1.2618, running_loss=1.1511, LR=0.000100
[2025-08-26 12:01:14,617][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016256] [Batch 00619/00823] [00:07:35/00:02:30, 0.736s/it]: train_loss_raw=1.0561, running_loss=1.1510, LR=0.000100
[2025-08-26 12:01:20,516][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016264] [Batch 00627/00823] [00:07:41/00:02:24, 0.736s/it]: train_loss_raw=1.2116, running_loss=1.1509, LR=0.000100
[2025-08-26 12:01:26,415][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016272] [Batch 00635/00823] [00:07:47/00:02:18, 0.736s/it]: train_loss_raw=1.0063, running_loss=1.1485, LR=0.000100
[2025-08-26 12:01:32,337][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016280] [Batch 00643/00823] [00:07:53/00:02:12, 0.736s/it]: train_loss_raw=1.3297, running_loss=1.1509, LR=0.000100
[2025-08-26 12:01:38,189][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016288] [Batch 00651/00823] [00:07:58/00:02:06, 0.736s/it]: train_loss_raw=1.1756, running_loss=1.1501, LR=0.000100
[2025-08-26 12:01:43,997][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016296] [Batch 00659/00823] [00:08:04/00:02:00, 0.736s/it]: train_loss_raw=1.2086, running_loss=1.1533, LR=0.000100
[2025-08-26 12:01:49,767][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016304] [Batch 00667/00823] [00:08:10/00:01:54, 0.735s/it]: train_loss_raw=1.0877, running_loss=1.1531, LR=0.000100
[2025-08-26 12:01:55,438][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016312] [Batch 00675/00823] [00:08:16/00:01:48, 0.735s/it]: train_loss_raw=1.1459, running_loss=1.1534, LR=0.000100
[2025-08-26 12:02:01,134][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016320] [Batch 00683/00823] [00:08:21/00:01:42, 0.735s/it]: train_loss_raw=1.0058, running_loss=1.1506, LR=0.000100
[2025-08-26 12:02:06,876][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016328] [Batch 00691/00823] [00:08:27/00:01:36, 0.735s/it]: train_loss_raw=1.1953, running_loss=1.1544, LR=0.000100
[2025-08-26 12:02:12,741][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016336] [Batch 00699/00823] [00:08:33/00:01:31, 0.735s/it]: train_loss_raw=1.1006, running_loss=1.1513, LR=0.000100
[2025-08-26 12:02:18,496][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016344] [Batch 00707/00823] [00:08:39/00:01:25, 0.734s/it]: train_loss_raw=1.2035, running_loss=1.1526, LR=0.000100
[2025-08-26 12:02:24,290][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016352] [Batch 00715/00823] [00:08:45/00:01:19, 0.734s/it]: train_loss_raw=1.1255, running_loss=1.1510, LR=0.000100
[2025-08-26 12:02:30,157][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016360] [Batch 00723/00823] [00:08:50/00:01:13, 0.734s/it]: train_loss_raw=1.1105, running_loss=1.1509, LR=0.000100
[2025-08-26 12:02:35,932][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016368] [Batch 00731/00823] [00:08:56/00:01:07, 0.734s/it]: train_loss_raw=1.1723, running_loss=1.1524, LR=0.000100
[2025-08-26 12:02:41,638][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016376] [Batch 00739/00823] [00:09:02/00:01:01, 0.734s/it]: train_loss_raw=1.2019, running_loss=1.1543, LR=0.000100
[2025-08-26 12:02:47,415][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016384] [Batch 00747/00823] [00:09:08/00:00:55, 0.734s/it]: train_loss_raw=1.1667, running_loss=1.1538, LR=0.000100
[2025-08-26 12:02:53,280][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016392] [Batch 00755/00823] [00:09:14/00:00:49, 0.734s/it]: train_loss_raw=1.1528, running_loss=1.1536, LR=0.000100
[2025-08-26 12:02:58,972][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016400] [Batch 00763/00823] [00:09:19/00:00:44, 0.734s/it]: train_loss_raw=1.1372, running_loss=1.1535, LR=0.000100
[2025-08-26 12:03:04,631][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016408] [Batch 00771/00823] [00:09:25/00:00:38, 0.733s/it]: train_loss_raw=1.0335, running_loss=1.1526, LR=0.000100
[2025-08-26 12:03:10,273][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016416] [Batch 00779/00823] [00:09:31/00:00:32, 0.733s/it]: train_loss_raw=1.1467, running_loss=1.1513, LR=0.000100
[2025-08-26 12:03:15,998][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016424] [Batch 00787/00823] [00:09:36/00:00:26, 0.733s/it]: train_loss_raw=1.1852, running_loss=1.1505, LR=0.000100
[2025-08-26 12:03:21,677][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016432] [Batch 00795/00823] [00:09:42/00:00:20, 0.733s/it]: train_loss_raw=1.1320, running_loss=1.1506, LR=0.000100
[2025-08-26 12:03:27,211][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016440] [Batch 00803/00823] [00:09:47/00:00:14, 0.732s/it]: train_loss_raw=1.1472, running_loss=1.1487, LR=0.000100
[2025-08-26 12:03:32,849][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016448] [Batch 00811/00823] [00:09:53/00:00:08, 0.732s/it]: train_loss_raw=1.1187, running_loss=1.1479, LR=0.000100
[2025-08-26 12:03:38,605][__main__][INFO] - [TRAIN] [Epoch 19/29 Step 016456] [Batch 00819/00823] [00:09:59/00:00:02, 0.732s/it]: train_loss_raw=1.1785, running_loss=1.1503, LR=0.000100
[2025-08-26 12:03:47,086][__main__][INFO] - [VALIDATION] [Epoch 19/29] Starting validation.
[2025-08-26 12:03:57,981][__main__][INFO] - [VALIDATION] [Epoch 19/29 Step 016461] [Batch 00007/00013] [00:00:10/00:00:06, 1.362s/it]
[2025-08-26 12:04:04,938][__main__][INFO] - [VALIDATION] [Epoch 19/29] train_loss=1.14993, valid_loss=1.39303
[2025-08-26 12:04:04,938][__main__][INFO] - [VALIDATION] [Epoch 19/29] Metrics:
[2025-08-26 12:04:04,938][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_er      0.600
[2025-08-26 12:04:04,938][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_prec    0.065
[2025-08-26 12:04:04,938][__main__][INFO] - [VALIDATION] [Epoch 19/29] - aa_recall  0.067
[2025-08-26 12:04:04,938][__main__][INFO] - [VALIDATION] [Epoch 19/29] - pep_recall 0.025
[2025-08-26 12:04:04,940][__main__][INFO] - [TRAIN] [Epoch 19/29] Epoch complete, total time 03:31:28, remaining time 01:45:44, 00:10:34 per epoch
[2025-08-26 12:04:07,595][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016464] [Batch 00004/00823] [00:00:02/00:08:20, 0.611s/it]: train_loss_raw=1.0705, running_loss=1.1028, LR=0.000100
[2025-08-26 12:04:13,667][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016472] [Batch 00012/00823] [00:00:08/00:09:35, 0.710s/it]: train_loss_raw=1.0286, running_loss=1.1029, LR=0.000100
[2025-08-26 12:04:19,748][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016480] [Batch 00020/00823] [00:00:14/00:09:46, 0.730s/it]: train_loss_raw=1.1570, running_loss=1.1026, LR=0.000100
[2025-08-26 12:04:25,804][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016488] [Batch 00028/00823] [00:00:20/00:09:46, 0.738s/it]: train_loss_raw=1.1337, running_loss=1.1016, LR=0.000100
[2025-08-26 12:04:31,895][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016496] [Batch 00036/00823] [00:00:26/00:09:44, 0.743s/it]: train_loss_raw=1.1374, running_loss=1.0971, LR=0.000100
[2025-08-26 12:04:37,954][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016504] [Batch 00044/00823] [00:00:32/00:09:40, 0.746s/it]: train_loss_raw=1.1043, running_loss=1.0978, LR=0.000100
[2025-08-26 12:04:43,979][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016512] [Batch 00052/00823] [00:00:38/00:09:35, 0.747s/it]: train_loss_raw=1.1738, running_loss=1.1009, LR=0.000100
[2025-08-26 12:04:50,006][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016520] [Batch 00060/00823] [00:00:44/00:09:30, 0.748s/it]: train_loss_raw=1.0922, running_loss=1.0995, LR=0.000100
[2025-08-26 12:04:56,092][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016528] [Batch 00068/00823] [00:00:50/00:09:25, 0.749s/it]: train_loss_raw=1.0079, running_loss=1.0986, LR=0.000100
[2025-08-26 12:05:02,168][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016536] [Batch 00076/00823] [00:00:57/00:09:20, 0.750s/it]: train_loss_raw=1.1223, running_loss=1.0971, LR=0.000100
[2025-08-26 12:05:08,210][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016544] [Batch 00084/00823] [00:01:03/00:09:14, 0.751s/it]: train_loss_raw=1.1596, running_loss=1.0959, LR=0.000100
[2025-08-26 12:05:14,267][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016552] [Batch 00092/00823] [00:01:09/00:09:09, 0.751s/it]: train_loss_raw=1.0191, running_loss=1.0980, LR=0.000100
[2025-08-26 12:05:20,299][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016560] [Batch 00100/00823] [00:01:15/00:09:03, 0.751s/it]: train_loss_raw=1.1716, running_loss=1.0977, LR=0.000100
[2025-08-26 12:05:26,381][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016568] [Batch 00108/00823] [00:01:21/00:08:57, 0.752s/it]: train_loss_raw=1.0031, running_loss=1.0973, LR=0.000100
[2025-08-26 12:05:32,440][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016576] [Batch 00116/00823] [00:01:27/00:08:52, 0.753s/it]: train_loss_raw=1.1763, running_loss=1.0999, LR=0.000100
[2025-08-26 12:05:38,521][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016584] [Batch 00124/00823] [00:01:33/00:08:46, 0.753s/it]: train_loss_raw=1.0820, running_loss=1.1021, LR=0.000100
[2025-08-26 12:05:44,673][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016592] [Batch 00132/00823] [00:01:39/00:08:40, 0.754s/it]: train_loss_raw=1.0597, running_loss=1.1027, LR=0.000100
[2025-08-26 12:05:50,665][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016600] [Batch 00140/00823] [00:01:45/00:08:34, 0.754s/it]: train_loss_raw=1.1224, running_loss=1.1030, LR=0.000100
[2025-08-26 12:05:56,539][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016608] [Batch 00148/00823] [00:01:51/00:08:28, 0.753s/it]: train_loss_raw=1.0574, running_loss=1.1019, LR=0.000100
[2025-08-26 12:06:02,486][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016616] [Batch 00156/00823] [00:01:57/00:08:21, 0.752s/it]: train_loss_raw=1.1142, running_loss=1.0995, LR=0.000100
[2025-08-26 12:06:08,572][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016624] [Batch 00164/00823] [00:02:03/00:08:15, 0.753s/it]: train_loss_raw=1.0232, running_loss=1.1001, LR=0.000100
[2025-08-26 12:06:14,628][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016632] [Batch 00172/00823] [00:02:09/00:08:10, 0.753s/it]: train_loss_raw=1.1666, running_loss=1.1000, LR=0.000100
[2025-08-26 12:06:20,681][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016640] [Batch 00180/00823] [00:02:15/00:08:04, 0.753s/it]: train_loss_raw=1.1055, running_loss=1.1029, LR=0.000100
[2025-08-26 12:06:26,765][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016648] [Batch 00188/00823] [00:02:21/00:07:58, 0.753s/it]: train_loss_raw=1.0993, running_loss=1.1055, LR=0.000100
[2025-08-26 12:06:32,863][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016656] [Batch 00196/00823] [00:02:27/00:07:52, 0.754s/it]: train_loss_raw=1.0272, running_loss=1.1056, LR=0.000100
[2025-08-26 12:06:38,922][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016664] [Batch 00204/00823] [00:02:33/00:07:46, 0.754s/it]: train_loss_raw=1.1085, running_loss=1.1068, LR=0.000100
[2025-08-26 12:06:44,979][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016672] [Batch 00212/00823] [00:02:39/00:07:40, 0.754s/it]: train_loss_raw=1.1556, running_loss=1.1074, LR=0.000100
[2025-08-26 12:06:51,091][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016680] [Batch 00220/00823] [00:02:45/00:07:34, 0.754s/it]: train_loss_raw=1.0982, running_loss=1.1037, LR=0.000100
[2025-08-26 12:06:57,164][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016688] [Batch 00228/00823] [00:02:52/00:07:28, 0.754s/it]: train_loss_raw=1.2306, running_loss=1.1038, LR=0.000100
[2025-08-26 12:07:03,220][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016696] [Batch 00236/00823] [00:02:58/00:07:22, 0.755s/it]: train_loss_raw=1.1165, running_loss=1.1020, LR=0.000100
[2025-08-26 12:07:09,240][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016704] [Batch 00244/00823] [00:03:04/00:07:16, 0.754s/it]: train_loss_raw=1.0160, running_loss=1.1015, LR=0.000100
[2025-08-26 12:07:15,291][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016712] [Batch 00252/00823] [00:03:10/00:07:10, 0.755s/it]: train_loss_raw=1.1348, running_loss=1.1020, LR=0.000100
[2025-08-26 12:07:21,371][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016720] [Batch 00260/00823] [00:03:16/00:07:04, 0.755s/it]: train_loss_raw=1.1806, running_loss=1.1020, LR=0.000100
[2025-08-26 12:07:27,401][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016728] [Batch 00268/00823] [00:03:22/00:06:58, 0.755s/it]: train_loss_raw=1.0943, running_loss=1.1032, LR=0.000100
[2025-08-26 12:07:33,489][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016736] [Batch 00276/00823] [00:03:28/00:06:52, 0.755s/it]: train_loss_raw=1.2056, running_loss=1.1036, LR=0.000100
[2025-08-26 12:07:39,595][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016744] [Batch 00284/00823] [00:03:34/00:06:46, 0.755s/it]: train_loss_raw=1.1245, running_loss=1.1035, LR=0.000100
[2025-08-26 12:07:45,657][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016752] [Batch 00292/00823] [00:03:40/00:06:40, 0.755s/it]: train_loss_raw=1.1662, running_loss=1.1035, LR=0.000100
[2025-08-26 12:07:51,719][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016760] [Batch 00300/00823] [00:03:46/00:06:34, 0.755s/it]: train_loss_raw=1.1764, running_loss=1.1040, LR=0.000100
[2025-08-26 12:07:57,790][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016768] [Batch 00308/00823] [00:03:52/00:06:28, 0.755s/it]: train_loss_raw=1.0855, running_loss=1.1014, LR=0.000100
[2025-08-26 12:08:03,925][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016776] [Batch 00316/00823] [00:03:58/00:06:23, 0.756s/it]: train_loss_raw=1.1910, running_loss=1.1023, LR=0.000100
[2025-08-26 12:08:10,046][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016784] [Batch 00324/00823] [00:04:04/00:06:17, 0.756s/it]: train_loss_raw=1.2077, running_loss=1.1026, LR=0.000100
[2025-08-26 12:08:16,101][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016792] [Batch 00332/00823] [00:04:10/00:06:11, 0.756s/it]: train_loss_raw=1.0556, running_loss=1.1034, LR=0.000100
[2025-08-26 12:08:22,172][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016800] [Batch 00340/00823] [00:04:17/00:06:05, 0.756s/it]: train_loss_raw=1.1214, running_loss=1.1069, LR=0.000100
[2025-08-26 12:08:28,276][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016808] [Batch 00348/00823] [00:04:23/00:05:59, 0.756s/it]: train_loss_raw=1.1782, running_loss=1.1062, LR=0.000100
[2025-08-26 12:08:34,326][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016816] [Batch 00356/00823] [00:04:29/00:05:53, 0.756s/it]: train_loss_raw=1.2013, running_loss=1.1054, LR=0.000100
[2025-08-26 12:08:40,378][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016824] [Batch 00364/00823] [00:04:35/00:05:47, 0.756s/it]: train_loss_raw=1.0647, running_loss=1.1051, LR=0.000100
[2025-08-26 12:08:46,472][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016832] [Batch 00372/00823] [00:04:41/00:05:41, 0.756s/it]: train_loss_raw=1.1214, running_loss=1.1054, LR=0.000100
[2025-08-26 12:08:52,506][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016840] [Batch 00380/00823] [00:04:47/00:05:34, 0.756s/it]: train_loss_raw=1.0873, running_loss=1.1024, LR=0.000100
[2025-08-26 12:08:58,575][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016848] [Batch 00388/00823] [00:04:53/00:05:28, 0.756s/it]: train_loss_raw=1.0101, running_loss=1.1008, LR=0.000100
[2025-08-26 12:09:04,673][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016856] [Batch 00396/00823] [00:04:59/00:05:22, 0.756s/it]: train_loss_raw=1.0694, running_loss=1.1034, LR=0.000100
[2025-08-26 12:09:10,728][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016864] [Batch 00404/00823] [00:05:05/00:05:16, 0.756s/it]: train_loss_raw=1.1171, running_loss=1.1024, LR=0.000100
[2025-08-26 12:09:16,744][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016872] [Batch 00412/00823] [00:05:11/00:05:10, 0.756s/it]: train_loss_raw=1.0819, running_loss=1.1026, LR=0.000100
[2025-08-26 12:09:22,782][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016880] [Batch 00420/00823] [00:05:17/00:05:04, 0.756s/it]: train_loss_raw=1.0711, running_loss=1.1011, LR=0.000100
[2025-08-26 12:09:28,854][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016888] [Batch 00428/00823] [00:05:23/00:04:58, 0.756s/it]: train_loss_raw=0.9573, running_loss=1.1011, LR=0.000100
[2025-08-26 12:09:34,944][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016896] [Batch 00436/00823] [00:05:29/00:04:52, 0.756s/it]: train_loss_raw=1.0828, running_loss=1.1010, LR=0.000100
[2025-08-26 12:09:41,006][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016904] [Batch 00444/00823] [00:05:35/00:04:46, 0.756s/it]: train_loss_raw=1.0977, running_loss=1.0988, LR=0.000100
[2025-08-26 12:09:47,114][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016912] [Batch 00452/00823] [00:05:41/00:04:40, 0.757s/it]: train_loss_raw=1.0733, running_loss=1.0977, LR=0.000100
[2025-08-26 12:09:53,322][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016920] [Batch 00460/00823] [00:05:48/00:04:34, 0.757s/it]: train_loss_raw=1.1359, running_loss=1.0974, LR=0.000100
[2025-08-26 12:09:59,379][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016928] [Batch 00468/00823] [00:05:54/00:04:28, 0.757s/it]: train_loss_raw=1.1220, running_loss=1.0950, LR=0.000100
[2025-08-26 12:10:05,483][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016936] [Batch 00476/00823] [00:06:00/00:04:22, 0.757s/it]: train_loss_raw=1.1324, running_loss=1.0947, LR=0.000100
[2025-08-26 12:10:11,550][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016944] [Batch 00484/00823] [00:06:06/00:04:16, 0.757s/it]: train_loss_raw=1.2297, running_loss=1.0944, LR=0.000100
[2025-08-26 12:10:17,668][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016952] [Batch 00492/00823] [00:06:12/00:04:10, 0.757s/it]: train_loss_raw=1.0727, running_loss=1.0965, LR=0.000100
[2025-08-26 12:10:23,784][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016960] [Batch 00500/00823] [00:06:18/00:04:04, 0.757s/it]: train_loss_raw=1.1473, running_loss=1.0947, LR=0.000100
[2025-08-26 12:10:29,931][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016968] [Batch 00508/00823] [00:06:24/00:03:58, 0.757s/it]: train_loss_raw=1.0540, running_loss=1.0954, LR=0.000100
[2025-08-26 12:10:36,036][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016976] [Batch 00516/00823] [00:06:30/00:03:52, 0.758s/it]: train_loss_raw=1.1651, running_loss=1.0967, LR=0.000100
[2025-08-26 12:10:42,136][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016984] [Batch 00524/00823] [00:06:36/00:03:46, 0.758s/it]: train_loss_raw=1.0178, running_loss=1.0957, LR=0.000100
[2025-08-26 12:10:48,230][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 016992] [Batch 00532/00823] [00:06:43/00:03:40, 0.758s/it]: train_loss_raw=1.1464, running_loss=1.0996, LR=0.000100
[2025-08-26 12:10:54,289][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017000] [Batch 00540/00823] [00:06:49/00:03:34, 0.758s/it]: train_loss_raw=1.0662, running_loss=1.0973, LR=0.000100
[2025-08-26 12:11:00,343][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017008] [Batch 00548/00823] [00:06:55/00:03:28, 0.758s/it]: train_loss_raw=1.0566, running_loss=1.0969, LR=0.000100
[2025-08-26 12:11:06,360][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017016] [Batch 00556/00823] [00:07:01/00:03:22, 0.758s/it]: train_loss_raw=1.0586, running_loss=1.0955, LR=0.000100
[2025-08-26 12:11:12,421][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017024] [Batch 00564/00823] [00:07:07/00:03:16, 0.758s/it]: train_loss_raw=1.1915, running_loss=1.0969, LR=0.000100
[2025-08-26 12:11:18,501][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017032] [Batch 00572/00823] [00:07:13/00:03:10, 0.758s/it]: train_loss_raw=1.0904, running_loss=1.0964, LR=0.000100
[2025-08-26 12:11:24,627][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017040] [Batch 00580/00823] [00:07:19/00:03:04, 0.758s/it]: train_loss_raw=1.1122, running_loss=1.0959, LR=0.000100
[2025-08-26 12:11:30,744][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017048] [Batch 00588/00823] [00:07:25/00:02:58, 0.758s/it]: train_loss_raw=1.1950, running_loss=1.0972, LR=0.000100
[2025-08-26 12:11:36,815][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017056] [Batch 00596/00823] [00:07:31/00:02:52, 0.758s/it]: train_loss_raw=1.1538, running_loss=1.0989, LR=0.000100
[2025-08-26 12:11:42,888][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017064] [Batch 00604/00823] [00:07:37/00:02:45, 0.758s/it]: train_loss_raw=1.0403, running_loss=1.0943, LR=0.000100
[2025-08-26 12:11:48,957][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017072] [Batch 00612/00823] [00:07:43/00:02:39, 0.758s/it]: train_loss_raw=1.0530, running_loss=1.0947, LR=0.000100
[2025-08-26 12:11:55,052][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017080] [Batch 00620/00823] [00:07:49/00:02:33, 0.758s/it]: train_loss_raw=1.0748, running_loss=1.0970, LR=0.000100
[2025-08-26 12:12:01,158][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017088] [Batch 00628/00823] [00:07:56/00:02:27, 0.758s/it]: train_loss_raw=1.0309, running_loss=1.0957, LR=0.000100
[2025-08-26 12:12:07,249][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017096] [Batch 00636/00823] [00:08:02/00:02:21, 0.758s/it]: train_loss_raw=1.0479, running_loss=1.0948, LR=0.000100
[2025-08-26 12:12:13,337][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017104] [Batch 00644/00823] [00:08:08/00:02:15, 0.758s/it]: train_loss_raw=1.0024, running_loss=1.0948, LR=0.000100
[2025-08-26 12:12:19,478][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017112] [Batch 00652/00823] [00:08:14/00:02:09, 0.758s/it]: train_loss_raw=1.0617, running_loss=1.0939, LR=0.000100
[2025-08-26 12:12:25,585][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017120] [Batch 00660/00823] [00:08:20/00:02:03, 0.758s/it]: train_loss_raw=1.1221, running_loss=1.0919, LR=0.000100
[2025-08-26 12:12:31,619][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017128] [Batch 00668/00823] [00:08:26/00:01:57, 0.758s/it]: train_loss_raw=1.0589, running_loss=1.0919, LR=0.000100
[2025-08-26 12:12:37,654][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017136] [Batch 00676/00823] [00:08:32/00:01:51, 0.758s/it]: train_loss_raw=1.1099, running_loss=1.0912, LR=0.000100
[2025-08-26 12:12:43,805][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017144] [Batch 00684/00823] [00:08:38/00:01:45, 0.758s/it]: train_loss_raw=0.9771, running_loss=1.0925, LR=0.000100
[2025-08-26 12:12:49,779][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017152] [Batch 00692/00823] [00:08:44/00:01:39, 0.758s/it]: train_loss_raw=1.0592, running_loss=1.0926, LR=0.000100
[2025-08-26 12:12:55,872][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017160] [Batch 00700/00823] [00:08:50/00:01:33, 0.758s/it]: train_loss_raw=1.0386, running_loss=1.0945, LR=0.000100
[2025-08-26 12:13:01,989][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017168] [Batch 00708/00823] [00:08:56/00:01:27, 0.758s/it]: train_loss_raw=1.0665, running_loss=1.0940, LR=0.000100
[2025-08-26 12:13:08,092][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017176] [Batch 00716/00823] [00:09:02/00:01:21, 0.758s/it]: train_loss_raw=1.0167, running_loss=1.0931, LR=0.000100
[2025-08-26 12:13:14,131][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017184] [Batch 00724/00823] [00:09:08/00:01:15, 0.758s/it]: train_loss_raw=1.0117, running_loss=1.0918, LR=0.000100
[2025-08-26 12:13:20,145][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017192] [Batch 00732/00823] [00:09:14/00:01:08, 0.758s/it]: train_loss_raw=1.0358, running_loss=1.0906, LR=0.000100
[2025-08-26 12:13:26,215][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017200] [Batch 00740/00823] [00:09:21/00:01:02, 0.758s/it]: train_loss_raw=1.2366, running_loss=1.0916, LR=0.000100
[2025-08-26 12:13:32,397][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017208] [Batch 00748/00823] [00:09:27/00:00:56, 0.758s/it]: train_loss_raw=1.0275, running_loss=1.0898, LR=0.000100
[2025-08-26 12:13:38,926][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017216] [Batch 00756/00823] [00:09:33/00:00:50, 0.759s/it]: train_loss_raw=1.1024, running_loss=1.0908, LR=0.000100
[2025-08-26 12:13:45,052][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017224] [Batch 00764/00823] [00:09:39/00:00:44, 0.759s/it]: train_loss_raw=1.0071, running_loss=1.0906, LR=0.000100
[2025-08-26 12:13:51,084][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017232] [Batch 00772/00823] [00:09:45/00:00:38, 0.759s/it]: train_loss_raw=1.1936, running_loss=1.0914, LR=0.000100
[2025-08-26 12:13:57,076][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017240] [Batch 00780/00823] [00:09:51/00:00:32, 0.759s/it]: train_loss_raw=1.2197, running_loss=1.0957, LR=0.000100
[2025-08-26 12:14:03,309][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017248] [Batch 00788/00823] [00:09:58/00:00:26, 0.759s/it]: train_loss_raw=1.1975, running_loss=1.0971, LR=0.000100
[2025-08-26 12:14:09,448][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017256] [Batch 00796/00823] [00:10:04/00:00:20, 0.759s/it]: train_loss_raw=1.0281, running_loss=1.0938, LR=0.000100
[2025-08-26 12:14:15,548][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017264] [Batch 00804/00823] [00:10:10/00:00:14, 0.759s/it]: train_loss_raw=1.1018, running_loss=1.0944, LR=0.000100
[2025-08-26 12:14:21,593][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017272] [Batch 00812/00823] [00:10:16/00:00:08, 0.759s/it]: train_loss_raw=1.0239, running_loss=1.0957, LR=0.000100
[2025-08-26 12:14:27,711][__main__][INFO] - [TRAIN] [Epoch 20/29 Step 017280] [Batch 00820/00823] [00:10:22/00:00:02, 0.759s/it]: train_loss_raw=1.1126, running_loss=1.0928, LR=0.000100
[2025-08-26 12:14:30,162][__main__][INFO] - [VALIDATION] [Epoch 20/29] Starting validation.
[2025-08-26 12:14:40,631][__main__][INFO] - [VALIDATION] [Epoch 20/29 Step 017284] [Batch 00007/00013] [00:00:10/00:00:06, 1.309s/it]
[2025-08-26 12:14:47,647][__main__][INFO] - [VALIDATION] [Epoch 20/29] train_loss=1.09269, valid_loss=1.36677
[2025-08-26 12:14:47,647][__main__][INFO] - [VALIDATION] [Epoch 20/29] Metrics:
[2025-08-26 12:14:47,647][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_er      0.591
[2025-08-26 12:14:47,647][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_prec    0.073
[2025-08-26 12:14:47,647][__main__][INFO] - [VALIDATION] [Epoch 20/29] - aa_recall  0.074
[2025-08-26 12:14:47,647][__main__][INFO] - [VALIDATION] [Epoch 20/29] - pep_recall 0.030
[2025-08-26 12:14:47,649][__main__][INFO] - [TRAIN] [Epoch 20/29] Epoch complete, total time 03:42:11, remaining time 01:35:13, 00:10:34 per epoch
[2025-08-26 12:14:51,887][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017288] [Batch 00005/00823] [00:00:03/00:08:54, 0.653s/it]: train_loss_raw=1.1264, running_loss=1.0804, LR=0.000100
[2025-08-26 12:14:57,915][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017296] [Batch 00013/00823] [00:00:09/00:09:39, 0.715s/it]: train_loss_raw=1.0191, running_loss=1.0803, LR=0.000100
[2025-08-26 12:15:03,949][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017304] [Batch 00021/00823] [00:00:15/00:09:45, 0.730s/it]: train_loss_raw=1.0738, running_loss=1.0803, LR=0.000100
[2025-08-26 12:15:09,996][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017312] [Batch 00029/00823] [00:00:21/00:09:45, 0.737s/it]: train_loss_raw=1.1616, running_loss=1.0799, LR=0.000100
[2025-08-26 12:15:16,374][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017320] [Batch 00037/00823] [00:00:27/00:09:49, 0.750s/it]: train_loss_raw=1.2294, running_loss=1.0810, LR=0.000100
[2025-08-26 12:15:22,416][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017328] [Batch 00045/00823] [00:00:33/00:09:44, 0.751s/it]: train_loss_raw=1.1238, running_loss=1.0815, LR=0.000100
[2025-08-26 12:15:28,432][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017336] [Batch 00053/00823] [00:00:39/00:09:38, 0.751s/it]: train_loss_raw=1.1857, running_loss=1.0838, LR=0.000100
[2025-08-26 12:15:34,460][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017344] [Batch 00061/00823] [00:00:45/00:09:32, 0.751s/it]: train_loss_raw=1.0616, running_loss=1.0839, LR=0.000100
[2025-08-26 12:15:40,471][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017352] [Batch 00069/00823] [00:00:51/00:09:26, 0.751s/it]: train_loss_raw=1.1100, running_loss=1.0837, LR=0.000100
[2025-08-26 12:15:46,568][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017360] [Batch 00077/00823] [00:00:57/00:09:21, 0.753s/it]: train_loss_raw=1.1068, running_loss=1.0846, LR=0.000100
[2025-08-26 12:15:52,720][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017368] [Batch 00085/00823] [00:01:04/00:09:16, 0.754s/it]: train_loss_raw=1.0907, running_loss=1.0861, LR=0.000100
[2025-08-26 12:15:58,789][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017376] [Batch 00093/00823] [00:01:10/00:09:10, 0.755s/it]: train_loss_raw=1.0748, running_loss=1.0848, LR=0.000100
[2025-08-26 12:16:04,814][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017384] [Batch 00101/00823] [00:01:16/00:09:04, 0.754s/it]: train_loss_raw=1.2191, running_loss=1.0855, LR=0.000100
[2025-08-26 12:16:10,944][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017392] [Batch 00109/00823] [00:01:22/00:08:59, 0.755s/it]: train_loss_raw=1.0931, running_loss=1.0858, LR=0.000100
[2025-08-26 12:16:17,005][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017400] [Batch 00117/00823] [00:01:28/00:08:53, 0.755s/it]: train_loss_raw=1.1963, running_loss=1.0863, LR=0.000100
[2025-08-26 12:16:23,011][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017408] [Batch 00125/00823] [00:01:34/00:08:47, 0.755s/it]: train_loss_raw=1.1123, running_loss=1.0858, LR=0.000100
[2025-08-26 12:16:29,108][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017416] [Batch 00133/00823] [00:01:40/00:08:41, 0.756s/it]: train_loss_raw=1.0340, running_loss=1.0856, LR=0.000100
[2025-08-26 12:16:35,158][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017424] [Batch 00141/00823] [00:01:46/00:08:35, 0.756s/it]: train_loss_raw=1.1229, running_loss=1.0865, LR=0.000100
[2025-08-26 12:16:41,260][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017432] [Batch 00149/00823] [00:01:52/00:08:29, 0.756s/it]: train_loss_raw=1.1086, running_loss=1.0849, LR=0.000100
[2025-08-26 12:16:47,325][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017440] [Batch 00157/00823] [00:01:58/00:08:23, 0.756s/it]: train_loss_raw=1.1668, running_loss=1.0833, LR=0.000100
[2025-08-26 12:16:53,381][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017448] [Batch 00165/00823] [00:02:04/00:08:17, 0.756s/it]: train_loss_raw=1.1032, running_loss=1.0850, LR=0.000100
[2025-08-26 12:16:59,393][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017456] [Batch 00173/00823] [00:02:10/00:08:11, 0.756s/it]: train_loss_raw=1.2623, running_loss=1.0877, LR=0.000100
[2025-08-26 12:17:05,481][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017464] [Batch 00181/00823] [00:02:16/00:08:05, 0.756s/it]: train_loss_raw=1.0783, running_loss=1.0874, LR=0.000100
[2025-08-26 12:17:11,550][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017472] [Batch 00189/00823] [00:02:22/00:07:59, 0.756s/it]: train_loss_raw=1.0350, running_loss=1.0884, LR=0.000100
[2025-08-26 12:17:17,607][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017480] [Batch 00197/00823] [00:02:28/00:07:53, 0.756s/it]: train_loss_raw=1.1294, running_loss=1.0903, LR=0.000100
[2025-08-26 12:17:23,728][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017488] [Batch 00205/00823] [00:02:35/00:07:47, 0.757s/it]: train_loss_raw=1.0832, running_loss=1.0898, LR=0.000100
[2025-08-26 12:17:29,827][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017496] [Batch 00213/00823] [00:02:41/00:07:41, 0.757s/it]: train_loss_raw=1.0753, running_loss=1.0896, LR=0.000100
[2025-08-26 12:17:36,002][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017504] [Batch 00221/00823] [00:02:47/00:07:35, 0.757s/it]: train_loss_raw=1.1231, running_loss=1.0902, LR=0.000100
[2025-08-26 12:17:42,078][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017512] [Batch 00229/00823] [00:02:53/00:07:29, 0.757s/it]: train_loss_raw=1.1363, running_loss=1.0902, LR=0.000100
[2025-08-26 12:17:48,106][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017520] [Batch 00237/00823] [00:02:59/00:07:23, 0.757s/it]: train_loss_raw=1.1183, running_loss=1.0884, LR=0.000100
[2025-08-26 12:17:54,161][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017528] [Batch 00245/00823] [00:03:05/00:07:17, 0.757s/it]: train_loss_raw=1.1143, running_loss=1.0886, LR=0.000100
[2025-08-26 12:18:00,233][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017536] [Batch 00253/00823] [00:03:11/00:07:11, 0.757s/it]: train_loss_raw=1.0371, running_loss=1.0875, LR=0.000100
[2025-08-26 12:18:06,317][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017544] [Batch 00261/00823] [00:03:17/00:07:05, 0.757s/it]: train_loss_raw=1.1138, running_loss=1.0880, LR=0.000100
[2025-08-26 12:18:12,378][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017552] [Batch 00269/00823] [00:03:23/00:06:59, 0.757s/it]: train_loss_raw=1.0924, running_loss=1.0857, LR=0.000100
[2025-08-26 12:18:18,423][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017560] [Batch 00277/00823] [00:03:29/00:06:53, 0.757s/it]: train_loss_raw=1.1566, running_loss=1.0879, LR=0.000100
[2025-08-26 12:18:24,495][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017568] [Batch 00285/00823] [00:03:35/00:06:47, 0.757s/it]: train_loss_raw=1.1002, running_loss=1.0885, LR=0.000100
[2025-08-26 12:18:30,555][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017576] [Batch 00293/00823] [00:03:41/00:06:41, 0.757s/it]: train_loss_raw=1.0182, running_loss=1.0858, LR=0.000100
[2025-08-26 12:18:36,595][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017584] [Batch 00301/00823] [00:03:47/00:06:35, 0.757s/it]: train_loss_raw=1.2227, running_loss=1.0889, LR=0.000100
[2025-08-26 12:18:42,637][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017592] [Batch 00309/00823] [00:03:54/00:06:29, 0.757s/it]: train_loss_raw=1.0757, running_loss=1.0904, LR=0.000100
[2025-08-26 12:18:48,726][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017600] [Batch 00317/00823] [00:04:00/00:06:23, 0.757s/it]: train_loss_raw=1.0917, running_loss=1.0925, LR=0.000100
[2025-08-26 12:18:54,736][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017608] [Batch 00325/00823] [00:04:06/00:06:17, 0.757s/it]: train_loss_raw=1.0887, running_loss=1.0925, LR=0.000100
[2025-08-26 12:19:00,807][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017616] [Batch 00333/00823] [00:04:12/00:06:11, 0.757s/it]: train_loss_raw=1.0274, running_loss=1.0931, LR=0.000100
[2025-08-26 12:19:06,841][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017624] [Batch 00341/00823] [00:04:18/00:06:04, 0.757s/it]: train_loss_raw=1.0781, running_loss=1.0944, LR=0.000100
[2025-08-26 12:19:12,991][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017632] [Batch 00349/00823] [00:04:24/00:05:59, 0.758s/it]: train_loss_raw=1.1082, running_loss=1.0952, LR=0.000100
[2025-08-26 12:19:19,038][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017640] [Batch 00357/00823] [00:04:30/00:05:52, 0.757s/it]: train_loss_raw=1.1429, running_loss=1.0968, LR=0.000100
[2025-08-26 12:19:25,085][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017648] [Batch 00365/00823] [00:04:36/00:05:46, 0.757s/it]: train_loss_raw=1.0340, running_loss=1.0949, LR=0.000100
[2025-08-26 12:19:31,125][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017656] [Batch 00373/00823] [00:04:42/00:05:40, 0.757s/it]: train_loss_raw=1.0613, running_loss=1.0939, LR=0.000100
[2025-08-26 12:19:37,177][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017664] [Batch 00381/00823] [00:04:48/00:05:34, 0.757s/it]: train_loss_raw=1.1495, running_loss=1.0954, LR=0.000100
[2025-08-26 12:19:43,282][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017672] [Batch 00389/00823] [00:04:54/00:05:28, 0.757s/it]: train_loss_raw=1.1565, running_loss=1.0972, LR=0.000100
[2025-08-26 12:19:49,378][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017680] [Batch 00397/00823] [00:05:00/00:05:22, 0.758s/it]: train_loss_raw=1.0328, running_loss=1.0958, LR=0.000100
[2025-08-26 12:19:55,490][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017688] [Batch 00405/00823] [00:05:06/00:05:16, 0.758s/it]: train_loss_raw=1.1673, running_loss=1.0973, LR=0.000100
[2025-08-26 12:20:01,576][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017696] [Batch 00413/00823] [00:05:12/00:05:10, 0.758s/it]: train_loss_raw=1.1187, running_loss=1.0998, LR=0.000100
[2025-08-26 12:20:07,645][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017704] [Batch 00421/00823] [00:05:19/00:05:04, 0.758s/it]: train_loss_raw=1.1515, running_loss=1.0991, LR=0.000100
[2025-08-26 12:20:13,716][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017712] [Batch 00429/00823] [00:05:25/00:04:58, 0.758s/it]: train_loss_raw=0.9264, running_loss=1.0950, LR=0.000100
[2025-08-26 12:20:19,783][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017720] [Batch 00437/00823] [00:05:31/00:04:52, 0.758s/it]: train_loss_raw=1.0586, running_loss=1.0927, LR=0.000100
[2025-08-26 12:20:25,845][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017728] [Batch 00445/00823] [00:05:37/00:04:46, 0.758s/it]: train_loss_raw=1.1396, running_loss=1.0918, LR=0.000100
[2025-08-26 12:20:31,980][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017736] [Batch 00453/00823] [00:05:43/00:04:40, 0.758s/it]: train_loss_raw=1.0665, running_loss=1.0953, LR=0.000100
[2025-08-26 12:20:38,057][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017744] [Batch 00461/00823] [00:05:49/00:04:34, 0.758s/it]: train_loss_raw=1.0702, running_loss=1.0939, LR=0.000100
[2025-08-26 12:20:44,162][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017752] [Batch 00469/00823] [00:05:55/00:04:28, 0.758s/it]: train_loss_raw=1.1495, running_loss=1.0919, LR=0.000100
[2025-08-26 12:20:50,253][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017760] [Batch 00477/00823] [00:06:01/00:04:22, 0.758s/it]: train_loss_raw=1.1160, running_loss=1.0928, LR=0.000100
[2025-08-26 12:20:56,309][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017768] [Batch 00485/00823] [00:06:07/00:04:16, 0.758s/it]: train_loss_raw=1.1003, running_loss=1.0951, LR=0.000100
[2025-08-26 12:21:02,353][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017776] [Batch 00493/00823] [00:06:13/00:04:10, 0.758s/it]: train_loss_raw=1.1221, running_loss=1.0962, LR=0.000100
[2025-08-26 12:21:08,449][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017784] [Batch 00501/00823] [00:06:19/00:04:04, 0.758s/it]: train_loss_raw=0.9568, running_loss=1.0948, LR=0.000100
[2025-08-26 12:21:14,484][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017792] [Batch 00509/00823] [00:06:25/00:03:58, 0.758s/it]: train_loss_raw=1.1707, running_loss=1.0977, LR=0.000100
[2025-08-26 12:21:20,529][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017800] [Batch 00517/00823] [00:06:31/00:03:51, 0.758s/it]: train_loss_raw=1.0136, running_loss=1.0953, LR=0.000100
[2025-08-26 12:21:26,619][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017808] [Batch 00525/00823] [00:06:37/00:03:45, 0.758s/it]: train_loss_raw=1.0381, running_loss=1.0965, LR=0.000100
[2025-08-26 12:21:32,672][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017816] [Batch 00533/00823] [00:06:44/00:03:39, 0.758s/it]: train_loss_raw=1.0683, running_loss=1.0934, LR=0.000100
[2025-08-26 12:21:38,735][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017824] [Batch 00541/00823] [00:06:50/00:03:33, 0.758s/it]: train_loss_raw=1.1314, running_loss=1.0945, LR=0.000100
[2025-08-26 12:21:44,833][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017832] [Batch 00549/00823] [00:06:56/00:03:27, 0.758s/it]: train_loss_raw=1.1464, running_loss=1.0955, LR=0.000100
[2025-08-26 12:21:50,845][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017840] [Batch 00557/00823] [00:07:02/00:03:21, 0.758s/it]: train_loss_raw=1.1131, running_loss=1.0949, LR=0.000100
[2025-08-26 12:21:56,971][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017848] [Batch 00565/00823] [00:07:08/00:03:15, 0.758s/it]: train_loss_raw=1.0949, running_loss=1.0959, LR=0.000100
[2025-08-26 12:22:02,992][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017856] [Batch 00573/00823] [00:07:14/00:03:09, 0.758s/it]: train_loss_raw=1.1327, running_loss=1.0946, LR=0.000100
[2025-08-26 12:22:09,064][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017864] [Batch 00581/00823] [00:07:20/00:03:03, 0.758s/it]: train_loss_raw=1.1395, running_loss=1.0929, LR=0.000100
[2025-08-26 12:22:15,133][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017872] [Batch 00589/00823] [00:07:26/00:02:57, 0.758s/it]: train_loss_raw=1.1314, running_loss=1.0925, LR=0.000100
[2025-08-26 12:22:21,219][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017880] [Batch 00597/00823] [00:07:32/00:02:51, 0.758s/it]: train_loss_raw=1.0700, running_loss=1.0914, LR=0.000100
[2025-08-26 12:22:27,313][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017888] [Batch 00605/00823] [00:07:38/00:02:45, 0.758s/it]: train_loss_raw=1.1537, running_loss=1.0909, LR=0.000100
[2025-08-26 12:22:33,363][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017896] [Batch 00613/00823] [00:07:44/00:02:39, 0.758s/it]: train_loss_raw=1.2427, running_loss=1.0901, LR=0.000100
[2025-08-26 12:22:39,395][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017904] [Batch 00621/00823] [00:07:50/00:02:33, 0.758s/it]: train_loss_raw=0.9824, running_loss=1.0879, LR=0.000100
[2025-08-26 12:22:45,431][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017912] [Batch 00629/00823] [00:07:56/00:02:27, 0.758s/it]: train_loss_raw=1.0187, running_loss=1.0851, LR=0.000100
[2025-08-26 12:22:51,505][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017920] [Batch 00637/00823] [00:08:02/00:02:20, 0.758s/it]: train_loss_raw=1.0675, running_loss=1.0834, LR=0.000100
[2025-08-26 12:22:57,521][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017928] [Batch 00645/00823] [00:08:08/00:02:14, 0.758s/it]: train_loss_raw=1.1145, running_loss=1.0847, LR=0.000100
[2025-08-26 12:23:03,519][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017936] [Batch 00653/00823] [00:08:14/00:02:08, 0.758s/it]: train_loss_raw=1.0434, running_loss=1.0859, LR=0.000100
[2025-08-26 12:23:09,556][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017944] [Batch 00661/00823] [00:08:20/00:02:02, 0.758s/it]: train_loss_raw=1.1677, running_loss=1.0893, LR=0.000100
[2025-08-26 12:23:15,650][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017952] [Batch 00669/00823] [00:08:27/00:01:56, 0.758s/it]: train_loss_raw=1.1104, running_loss=1.0902, LR=0.000100
[2025-08-26 12:23:21,683][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017960] [Batch 00677/00823] [00:08:33/00:01:50, 0.758s/it]: train_loss_raw=1.0707, running_loss=1.0899, LR=0.000100
[2025-08-26 12:23:27,720][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017968] [Batch 00685/00823] [00:08:39/00:01:44, 0.758s/it]: train_loss_raw=1.1645, running_loss=1.0891, LR=0.000100
[2025-08-26 12:23:33,826][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017976] [Batch 00693/00823] [00:08:45/00:01:38, 0.758s/it]: train_loss_raw=1.0837, running_loss=1.0889, LR=0.000100
[2025-08-26 12:23:39,847][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017984] [Batch 00701/00823] [00:08:51/00:01:32, 0.758s/it]: train_loss_raw=0.9691, running_loss=1.0886, LR=0.000100
[2025-08-26 12:23:45,898][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 017992] [Batch 00709/00823] [00:08:57/00:01:26, 0.758s/it]: train_loss_raw=1.1260, running_loss=1.0906, LR=0.000100
[2025-08-26 12:23:51,925][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018000] [Batch 00717/00823] [00:09:03/00:01:20, 0.758s/it]: train_loss_raw=0.9484, running_loss=1.0896, LR=0.000100
[2025-08-26 12:24:02,923][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018008] [Batch 00725/00823] [00:09:14/00:01:14, 0.765s/it]: train_loss_raw=1.1187, running_loss=1.0883, LR=0.000100
[2025-08-26 12:24:09,136][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018016] [Batch 00733/00823] [00:09:20/00:01:08, 0.765s/it]: train_loss_raw=1.1310, running_loss=1.0872, LR=0.000100
[2025-08-26 12:24:15,279][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018024] [Batch 00741/00823] [00:09:26/00:01:02, 0.765s/it]: train_loss_raw=1.0366, running_loss=1.0892, LR=0.000100
[2025-08-26 12:24:21,370][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018032] [Batch 00749/00823] [00:09:32/00:00:56, 0.765s/it]: train_loss_raw=1.1540, running_loss=1.0906, LR=0.000100
[2025-08-26 12:24:27,477][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018040] [Batch 00757/00823] [00:09:38/00:00:50, 0.765s/it]: train_loss_raw=1.1337, running_loss=1.0900, LR=0.000100
[2025-08-26 12:24:33,516][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018048] [Batch 00765/00823] [00:09:44/00:00:44, 0.765s/it]: train_loss_raw=1.0862, running_loss=1.0892, LR=0.000100
[2025-08-26 12:24:39,560][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018056] [Batch 00773/00823] [00:09:50/00:00:38, 0.764s/it]: train_loss_raw=1.1250, running_loss=1.0898, LR=0.000100
[2025-08-26 12:24:45,662][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018064] [Batch 00781/00823] [00:09:57/00:00:32, 0.764s/it]: train_loss_raw=1.1811, running_loss=1.0934, LR=0.000100
[2025-08-26 12:24:51,715][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018072] [Batch 00789/00823] [00:10:03/00:00:25, 0.764s/it]: train_loss_raw=1.0469, running_loss=1.0921, LR=0.000100
[2025-08-26 12:24:57,796][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018080] [Batch 00797/00823] [00:10:09/00:00:19, 0.764s/it]: train_loss_raw=1.0421, running_loss=1.0915, LR=0.000100
[2025-08-26 12:25:03,866][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018088] [Batch 00805/00823] [00:10:15/00:00:13, 0.764s/it]: train_loss_raw=1.0650, running_loss=1.0886, LR=0.000100
[2025-08-26 12:25:09,996][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018096] [Batch 00813/00823] [00:10:21/00:00:07, 0.764s/it]: train_loss_raw=1.0572, running_loss=1.0860, LR=0.000100
[2025-08-26 12:25:16,102][__main__][INFO] - [TRAIN] [Epoch 21/29 Step 018104] [Batch 00821/00823] [00:10:27/00:00:01, 0.764s/it]: train_loss_raw=1.1533, running_loss=1.0851, LR=0.000100
[2025-08-26 12:25:23,273][__main__][INFO] - [VALIDATION] [Epoch 21/29] Starting validation.
[2025-08-26 12:25:33,938][__main__][INFO] - [VALIDATION] [Epoch 21/29 Step 018107] [Batch 00007/00013] [00:00:10/00:00:06, 1.333s/it]
[2025-08-26 12:25:40,604][__main__][INFO] - [VALIDATION] [Epoch 21/29] train_loss=1.08322, valid_loss=1.34678
[2025-08-26 12:25:40,604][__main__][INFO] - [VALIDATION] [Epoch 21/29] Metrics:
[2025-08-26 12:25:40,604][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_er      0.576
[2025-08-26 12:25:40,604][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_prec    0.075
[2025-08-26 12:25:40,604][__main__][INFO] - [VALIDATION] [Epoch 21/29] - aa_recall  0.077
[2025-08-26 12:25:40,604][__main__][INFO] - [VALIDATION] [Epoch 21/29] - pep_recall 0.033
[2025-08-26 12:25:40,606][__main__][INFO] - [TRAIN] [Epoch 21/29] Epoch complete, total time 03:53:04, remaining time 01:24:45, 00:10:35 per epoch
[2025-08-26 12:25:44,919][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018112] [Batch 00006/00823] [00:00:03/00:08:57, 0.658s/it]: train_loss_raw=0.9496, running_loss=0.9556, LR=0.000100
[2025-08-26 12:25:50,994][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018120] [Batch 00014/00823] [00:00:10/00:09:39, 0.716s/it]: train_loss_raw=1.0131, running_loss=0.9623, LR=0.000100
[2025-08-26 12:25:57,156][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018128] [Batch 00022/00823] [00:00:16/00:09:49, 0.736s/it]: train_loss_raw=0.9670, running_loss=0.9704, LR=0.000100
[2025-08-26 12:26:03,227][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018136] [Batch 00030/00823] [00:00:22/00:09:48, 0.742s/it]: train_loss_raw=1.0428, running_loss=0.9752, LR=0.000100
[2025-08-26 12:26:09,344][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018144] [Batch 00038/00823] [00:00:28/00:09:46, 0.747s/it]: train_loss_raw=0.9425, running_loss=0.9790, LR=0.000100
[2025-08-26 12:26:15,203][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018152] [Batch 00046/00823] [00:00:34/00:09:38, 0.744s/it]: train_loss_raw=1.0026, running_loss=0.9830, LR=0.000100
[2025-08-26 12:26:20,990][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018160] [Batch 00054/00823] [00:00:40/00:09:29, 0.741s/it]: train_loss_raw=1.0175, running_loss=0.9854, LR=0.000100
[2025-08-26 12:26:26,739][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018168] [Batch 00062/00823] [00:00:45/00:09:21, 0.738s/it]: train_loss_raw=1.0411, running_loss=0.9881, LR=0.000100
[2025-08-26 12:26:32,570][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018176] [Batch 00070/00823] [00:00:51/00:09:15, 0.737s/it]: train_loss_raw=0.9648, running_loss=0.9910, LR=0.000100
[2025-08-26 12:26:38,221][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018184] [Batch 00078/00823] [00:00:57/00:09:06, 0.734s/it]: train_loss_raw=1.0535, running_loss=0.9939, LR=0.000100
[2025-08-26 12:26:43,823][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018192] [Batch 00086/00823] [00:01:02/00:08:58, 0.731s/it]: train_loss_raw=1.0125, running_loss=0.9964, LR=0.000100
[2025-08-26 12:26:49,455][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018200] [Batch 00094/00823] [00:01:08/00:08:51, 0.729s/it]: train_loss_raw=0.9767, running_loss=0.9994, LR=0.000100
[2025-08-26 12:26:55,330][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018208] [Batch 00102/00823] [00:01:14/00:08:45, 0.729s/it]: train_loss_raw=1.0619, running_loss=1.0019, LR=0.000100
[2025-08-26 12:27:01,421][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018216] [Batch 00110/00823] [00:01:20/00:08:41, 0.731s/it]: train_loss_raw=1.0614, running_loss=1.0072, LR=0.000100
[2025-08-26 12:27:07,548][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018224] [Batch 00118/00823] [00:01:26/00:08:37, 0.734s/it]: train_loss_raw=1.0695, running_loss=1.0102, LR=0.000100
[2025-08-26 12:27:13,612][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018232] [Batch 00126/00823] [00:01:32/00:08:32, 0.735s/it]: train_loss_raw=0.9752, running_loss=1.0116, LR=0.000100
[2025-08-26 12:27:19,754][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018240] [Batch 00134/00823] [00:01:38/00:08:27, 0.737s/it]: train_loss_raw=1.0893, running_loss=1.0127, LR=0.000100
[2025-08-26 12:27:25,886][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018248] [Batch 00142/00823] [00:01:44/00:08:23, 0.739s/it]: train_loss_raw=1.0249, running_loss=1.0139, LR=0.000100
[2025-08-26 12:27:31,957][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018256] [Batch 00150/00823] [00:01:50/00:08:17, 0.740s/it]: train_loss_raw=1.0133, running_loss=1.0147, LR=0.000100
[2025-08-26 12:27:38,022][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018264] [Batch 00158/00823] [00:01:57/00:08:12, 0.741s/it]: train_loss_raw=0.9647, running_loss=1.0166, LR=0.000100
[2025-08-26 12:27:44,030][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018272] [Batch 00166/00823] [00:02:03/00:08:07, 0.741s/it]: train_loss_raw=1.0288, running_loss=1.0192, LR=0.000100
[2025-08-26 12:27:50,108][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018280] [Batch 00174/00823] [00:02:09/00:08:01, 0.742s/it]: train_loss_raw=0.9842, running_loss=1.0190, LR=0.000100
[2025-08-26 12:27:56,150][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018288] [Batch 00182/00823] [00:02:15/00:07:56, 0.743s/it]: train_loss_raw=1.0158, running_loss=1.0219, LR=0.000100
[2025-08-26 12:28:02,172][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018296] [Batch 00190/00823] [00:02:21/00:07:50, 0.743s/it]: train_loss_raw=0.9564, running_loss=1.0213, LR=0.000100
[2025-08-26 12:28:08,306][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018304] [Batch 00198/00823] [00:02:27/00:07:45, 0.744s/it]: train_loss_raw=1.0413, running_loss=1.0229, LR=0.000100
[2025-08-26 12:28:14,278][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018312] [Batch 00206/00823] [00:02:33/00:07:39, 0.744s/it]: train_loss_raw=1.1295, running_loss=1.0255, LR=0.000100
[2025-08-26 12:28:20,293][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018320] [Batch 00214/00823] [00:02:39/00:07:33, 0.745s/it]: train_loss_raw=1.0434, running_loss=1.0241, LR=0.000100
[2025-08-26 12:28:26,373][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018328] [Batch 00222/00823] [00:02:45/00:07:27, 0.745s/it]: train_loss_raw=1.0373, running_loss=1.0218, LR=0.000100
[2025-08-26 12:28:32,512][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018336] [Batch 00230/00823] [00:02:51/00:07:22, 0.746s/it]: train_loss_raw=1.0337, running_loss=1.0217, LR=0.000100
[2025-08-26 12:28:38,497][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018344] [Batch 00238/00823] [00:02:57/00:07:16, 0.746s/it]: train_loss_raw=1.0376, running_loss=1.0198, LR=0.000100
[2025-08-26 12:28:44,506][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018352] [Batch 00246/00823] [00:03:03/00:07:10, 0.746s/it]: train_loss_raw=0.9433, running_loss=1.0205, LR=0.000100
[2025-08-26 12:28:50,545][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018360] [Batch 00254/00823] [00:03:09/00:07:04, 0.746s/it]: train_loss_raw=1.0582, running_loss=1.0209, LR=0.000100
[2025-08-26 12:28:56,570][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018368] [Batch 00262/00823] [00:03:15/00:06:58, 0.747s/it]: train_loss_raw=1.1025, running_loss=1.0240, LR=0.000100
[2025-08-26 12:29:02,662][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018376] [Batch 00270/00823] [00:03:21/00:06:53, 0.747s/it]: train_loss_raw=1.0774, running_loss=1.0248, LR=0.000100
[2025-08-26 12:29:08,720][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018384] [Batch 00278/00823] [00:03:27/00:06:47, 0.747s/it]: train_loss_raw=0.9335, running_loss=1.0245, LR=0.000100
[2025-08-26 12:29:14,933][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018392] [Batch 00286/00823] [00:03:33/00:06:41, 0.748s/it]: train_loss_raw=1.0046, running_loss=1.0241, LR=0.000100
[2025-08-26 12:29:21,029][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018400] [Batch 00294/00823] [00:03:40/00:06:35, 0.749s/it]: train_loss_raw=1.1055, running_loss=1.0246, LR=0.000100
[2025-08-26 12:29:27,023][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018408] [Batch 00302/00823] [00:03:46/00:06:29, 0.749s/it]: train_loss_raw=1.0594, running_loss=1.0247, LR=0.000100
[2025-08-26 12:29:32,824][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018416] [Batch 00310/00823] [00:03:51/00:06:23, 0.748s/it]: train_loss_raw=1.0808, running_loss=1.0276, LR=0.000100
[2025-08-26 12:29:38,588][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018424] [Batch 00318/00823] [00:03:57/00:06:17, 0.747s/it]: train_loss_raw=1.0829, running_loss=1.0273, LR=0.000100
[2025-08-26 12:29:44,469][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018432] [Batch 00326/00823] [00:04:03/00:06:11, 0.747s/it]: train_loss_raw=0.9651, running_loss=1.0286, LR=0.000100
[2025-08-26 12:29:50,418][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018440] [Batch 00334/00823] [00:04:09/00:06:05, 0.747s/it]: train_loss_raw=1.0469, running_loss=1.0281, LR=0.000100
[2025-08-26 12:29:56,215][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018448] [Batch 00342/00823] [00:04:15/00:05:58, 0.746s/it]: train_loss_raw=1.1355, running_loss=1.0294, LR=0.000100
[2025-08-26 12:30:02,274][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018456] [Batch 00350/00823] [00:04:21/00:05:53, 0.747s/it]: train_loss_raw=0.9383, running_loss=1.0291, LR=0.000100
[2025-08-26 12:30:08,347][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018464] [Batch 00358/00823] [00:04:27/00:05:47, 0.747s/it]: train_loss_raw=1.0012, running_loss=1.0280, LR=0.000100
[2025-08-26 12:30:14,417][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018472] [Batch 00366/00823] [00:04:33/00:05:41, 0.747s/it]: train_loss_raw=0.9733, running_loss=1.0253, LR=0.000100
[2025-08-26 12:30:20,537][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018480] [Batch 00374/00823] [00:04:39/00:05:35, 0.748s/it]: train_loss_raw=0.9832, running_loss=1.0247, LR=0.000100
[2025-08-26 12:30:26,693][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018488] [Batch 00382/00823] [00:04:45/00:05:29, 0.748s/it]: train_loss_raw=1.0023, running_loss=1.0260, LR=0.000100
[2025-08-26 12:30:32,951][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018496] [Batch 00390/00823] [00:04:51/00:05:24, 0.749s/it]: train_loss_raw=0.9558, running_loss=1.0269, LR=0.000100
[2025-08-26 12:30:39,370][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018504] [Batch 00398/00823] [00:04:58/00:05:18, 0.750s/it]: train_loss_raw=1.0469, running_loss=1.0286, LR=0.000100
[2025-08-26 12:30:45,673][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018512] [Batch 00406/00823] [00:05:04/00:05:12, 0.751s/it]: train_loss_raw=0.9507, running_loss=1.0274, LR=0.000100
[2025-08-26 12:30:51,908][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018520] [Batch 00414/00823] [00:05:10/00:05:07, 0.751s/it]: train_loss_raw=1.0931, running_loss=1.0254, LR=0.000100
[2025-08-26 12:30:57,986][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018528] [Batch 00422/00823] [00:05:17/00:05:01, 0.751s/it]: train_loss_raw=0.9423, running_loss=1.0250, LR=0.000100
[2025-08-26 12:31:04,020][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018536] [Batch 00430/00823] [00:05:23/00:04:55, 0.751s/it]: train_loss_raw=1.0169, running_loss=1.0269, LR=0.000100
[2025-08-26 12:31:10,290][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018544] [Batch 00438/00823] [00:05:29/00:04:49, 0.752s/it]: train_loss_raw=0.9535, running_loss=1.0258, LR=0.000100
[2025-08-26 12:31:16,560][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018552] [Batch 00446/00823] [00:05:35/00:04:43, 0.752s/it]: train_loss_raw=1.0942, running_loss=1.0248, LR=0.000100
[2025-08-26 12:31:22,970][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018560] [Batch 00454/00823] [00:05:42/00:04:37, 0.753s/it]: train_loss_raw=1.1052, running_loss=1.0264, LR=0.000100
[2025-08-26 12:31:29,083][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018568] [Batch 00462/00823] [00:05:48/00:04:32, 0.753s/it]: train_loss_raw=0.9645, running_loss=1.0274, LR=0.000100
[2025-08-26 12:31:35,169][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018576] [Batch 00470/00823] [00:05:54/00:04:26, 0.754s/it]: train_loss_raw=1.0167, running_loss=1.0279, LR=0.000100
[2025-08-26 12:31:41,659][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018584] [Batch 00478/00823] [00:06:00/00:04:20, 0.755s/it]: train_loss_raw=0.9573, running_loss=1.0302, LR=0.000100
[2025-08-26 12:31:48,366][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018592] [Batch 00486/00823] [00:06:07/00:04:14, 0.756s/it]: train_loss_raw=0.9965, running_loss=1.0297, LR=0.000100
[2025-08-26 12:31:54,746][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018600] [Batch 00494/00823] [00:06:13/00:04:08, 0.757s/it]: train_loss_raw=1.0054, running_loss=1.0297, LR=0.000100
[2025-08-26 12:32:01,169][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018608] [Batch 00502/00823] [00:06:20/00:04:03, 0.757s/it]: train_loss_raw=1.0116, running_loss=1.0294, LR=0.000100
[2025-08-26 12:32:07,495][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018616] [Batch 00510/00823] [00:06:26/00:03:57, 0.758s/it]: train_loss_raw=0.9885, running_loss=1.0291, LR=0.000100
[2025-08-26 12:32:13,572][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018624] [Batch 00518/00823] [00:06:32/00:03:51, 0.758s/it]: train_loss_raw=0.9829, running_loss=1.0314, LR=0.000100
[2025-08-26 12:32:20,110][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018632] [Batch 00526/00823] [00:06:39/00:03:45, 0.759s/it]: train_loss_raw=1.0797, running_loss=1.0309, LR=0.000100
[2025-08-26 12:32:26,263][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018640] [Batch 00534/00823] [00:06:45/00:03:39, 0.759s/it]: train_loss_raw=1.0132, running_loss=1.0306, LR=0.000100
[2025-08-26 12:32:32,663][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018648] [Batch 00542/00823] [00:06:51/00:03:33, 0.760s/it]: train_loss_raw=1.0154, running_loss=1.0296, LR=0.000100
[2025-08-26 12:32:38,920][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018656] [Batch 00550/00823] [00:06:57/00:03:27, 0.760s/it]: train_loss_raw=1.0948, running_loss=1.0303, LR=0.000100
[2025-08-26 12:32:45,061][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018664] [Batch 00558/00823] [00:07:04/00:03:21, 0.760s/it]: train_loss_raw=1.0347, running_loss=1.0301, LR=0.000100
[2025-08-26 12:32:51,238][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018672] [Batch 00566/00823] [00:07:10/00:03:15, 0.760s/it]: train_loss_raw=1.0726, running_loss=1.0283, LR=0.000100
[2025-08-26 12:32:57,459][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018680] [Batch 00574/00823] [00:07:16/00:03:09, 0.760s/it]: train_loss_raw=0.9691, running_loss=1.0290, LR=0.000100
[2025-08-26 12:33:03,629][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018688] [Batch 00582/00823] [00:07:22/00:03:03, 0.761s/it]: train_loss_raw=1.0227, running_loss=1.0298, LR=0.000100
[2025-08-26 12:33:09,916][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018696] [Batch 00590/00823] [00:07:28/00:02:57, 0.761s/it]: train_loss_raw=1.1087, running_loss=1.0312, LR=0.000100
[2025-08-26 12:33:16,412][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018704] [Batch 00598/00823] [00:07:35/00:02:51, 0.762s/it]: train_loss_raw=1.0547, running_loss=1.0297, LR=0.000100
[2025-08-26 12:33:22,991][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018712] [Batch 00606/00823] [00:07:42/00:02:45, 0.762s/it]: train_loss_raw=1.0705, running_loss=1.0317, LR=0.000100
[2025-08-26 12:33:29,342][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018720] [Batch 00614/00823] [00:07:48/00:02:39, 0.763s/it]: train_loss_raw=1.1221, running_loss=1.0289, LR=0.000100
[2025-08-26 12:33:35,919][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018728] [Batch 00622/00823] [00:07:54/00:02:33, 0.764s/it]: train_loss_raw=1.0132, running_loss=1.0304, LR=0.000100
[2025-08-26 12:33:42,196][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018736] [Batch 00630/00823] [00:08:01/00:02:27, 0.764s/it]: train_loss_raw=0.9875, running_loss=1.0295, LR=0.000100
[2025-08-26 12:33:48,347][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018744] [Batch 00638/00823] [00:08:07/00:02:21, 0.764s/it]: train_loss_raw=1.1006, running_loss=1.0285, LR=0.000100
[2025-08-26 12:33:54,668][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018752] [Batch 00646/00823] [00:08:13/00:02:15, 0.764s/it]: train_loss_raw=0.9975, running_loss=1.0265, LR=0.000100
[2025-08-26 12:34:00,978][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018760] [Batch 00654/00823] [00:08:20/00:02:09, 0.765s/it]: train_loss_raw=1.0128, running_loss=1.0269, LR=0.000100
[2025-08-26 12:34:07,596][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018768] [Batch 00662/00823] [00:08:26/00:02:03, 0.765s/it]: train_loss_raw=0.9723, running_loss=1.0293, LR=0.000100
[2025-08-26 12:34:13,869][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018776] [Batch 00670/00823] [00:08:32/00:01:57, 0.766s/it]: train_loss_raw=1.0063, running_loss=1.0303, LR=0.000100
[2025-08-26 12:34:20,108][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018784] [Batch 00678/00823] [00:08:39/00:01:51, 0.766s/it]: train_loss_raw=1.0060, running_loss=1.0292, LR=0.000100
[2025-08-26 12:34:26,312][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018792] [Batch 00686/00823] [00:08:45/00:01:44, 0.766s/it]: train_loss_raw=0.9716, running_loss=1.0292, LR=0.000100
[2025-08-26 12:34:32,613][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018800] [Batch 00694/00823] [00:08:51/00:01:38, 0.766s/it]: train_loss_raw=1.0711, running_loss=1.0297, LR=0.000100
[2025-08-26 12:34:38,908][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018808] [Batch 00702/00823] [00:08:57/00:01:32, 0.766s/it]: train_loss_raw=1.0257, running_loss=1.0315, LR=0.000100
[2025-08-26 12:34:45,434][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018816] [Batch 00710/00823] [00:09:04/00:01:26, 0.767s/it]: train_loss_raw=1.0162, running_loss=1.0291, LR=0.000100
[2025-08-26 12:34:51,558][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018824] [Batch 00718/00823] [00:09:10/00:01:20, 0.767s/it]: train_loss_raw=0.9995, running_loss=1.0284, LR=0.000100
[2025-08-26 12:34:57,890][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018832] [Batch 00726/00823] [00:09:16/00:01:14, 0.767s/it]: train_loss_raw=1.0316, running_loss=1.0286, LR=0.000100
[2025-08-26 12:35:04,084][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018840] [Batch 00734/00823] [00:09:23/00:01:08, 0.767s/it]: train_loss_raw=1.0264, running_loss=1.0300, LR=0.000100
[2025-08-26 12:35:10,388][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018848] [Batch 00742/00823] [00:09:29/00:01:02, 0.767s/it]: train_loss_raw=1.0533, running_loss=1.0319, LR=0.000100
[2025-08-26 12:35:16,538][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018856] [Batch 00750/00823] [00:09:35/00:00:56, 0.767s/it]: train_loss_raw=0.9841, running_loss=1.0315, LR=0.000100
[2025-08-26 12:35:22,581][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018864] [Batch 00758/00823] [00:09:41/00:00:49, 0.767s/it]: train_loss_raw=1.0108, running_loss=1.0319, LR=0.000100
[2025-08-26 12:35:28,839][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018872] [Batch 00766/00823] [00:09:47/00:00:43, 0.767s/it]: train_loss_raw=1.0940, running_loss=1.0334, LR=0.000100
[2025-08-26 12:35:35,188][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018880] [Batch 00774/00823] [00:09:54/00:00:37, 0.768s/it]: train_loss_raw=0.9027, running_loss=1.0340, LR=0.000100
[2025-08-26 12:35:41,489][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018888] [Batch 00782/00823] [00:10:00/00:00:31, 0.768s/it]: train_loss_raw=1.0978, running_loss=1.0339, LR=0.000100
[2025-08-26 12:35:47,384][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018896] [Batch 00790/00823] [00:10:06/00:00:25, 0.768s/it]: train_loss_raw=0.9510, running_loss=1.0324, LR=0.000100
[2025-08-26 12:35:53,434][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018904] [Batch 00798/00823] [00:10:12/00:00:19, 0.767s/it]: train_loss_raw=1.0704, running_loss=1.0310, LR=0.000100
[2025-08-26 12:35:59,354][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018912] [Batch 00806/00823] [00:10:18/00:00:13, 0.767s/it]: train_loss_raw=1.0318, running_loss=1.0307, LR=0.000100
[2025-08-26 12:36:05,181][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018920] [Batch 00814/00823] [00:10:24/00:00:06, 0.767s/it]: train_loss_raw=1.0575, running_loss=1.0304, LR=0.000100
[2025-08-26 12:36:11,150][__main__][INFO] - [TRAIN] [Epoch 22/29 Step 018928] [Batch 00822/00823] [00:10:30/00:00:00, 0.767s/it]: train_loss_raw=0.9368, running_loss=1.0265, LR=0.000100
[2025-08-26 12:36:12,099][__main__][INFO] - [VALIDATION] [Epoch 22/29] Starting validation.
[2025-08-26 12:36:22,952][__main__][INFO] - [VALIDATION] [Epoch 22/29 Step 018930] [Batch 00007/00013] [00:00:10/00:00:06, 1.357s/it]
[2025-08-26 12:36:30,112][__main__][INFO] - [VALIDATION] [Epoch 22/29] train_loss=1.02708, valid_loss=1.37256
[2025-08-26 12:36:30,113][__main__][INFO] - [VALIDATION] [Epoch 22/29] Metrics:
[2025-08-26 12:36:30,113][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_er      0.589
[2025-08-26 12:36:30,113][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_prec    0.063
[2025-08-26 12:36:30,113][__main__][INFO] - [VALIDATION] [Epoch 22/29] - aa_recall  0.065
[2025-08-26 12:36:30,113][__main__][INFO] - [VALIDATION] [Epoch 22/29] - pep_recall 0.025
[2025-08-26 12:36:30,115][__main__][INFO] - [TRAIN] [Epoch 22/29] Epoch complete, total time 04:03:53, remaining time 01:14:13, 00:10:36 per epoch
[2025-08-26 12:36:36,455][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018936] [Batch 00007/00823] [00:00:05/00:09:49, 0.723s/it]: train_loss_raw=1.0423, running_loss=0.9686, LR=0.000100
[2025-08-26 12:36:42,693][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018944] [Batch 00015/00823] [00:00:11/00:10:08, 0.753s/it]: train_loss_raw=0.9060, running_loss=0.9734, LR=0.000100
[2025-08-26 12:36:48,763][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018952] [Batch 00023/00823] [00:00:17/00:10:04, 0.755s/it]: train_loss_raw=1.0281, running_loss=0.9776, LR=0.000100
[2025-08-26 12:36:54,666][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018960] [Batch 00031/00823] [00:00:23/00:09:54, 0.751s/it]: train_loss_raw=1.0111, running_loss=0.9826, LR=0.000100
[2025-08-26 12:37:00,665][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018968] [Batch 00039/00823] [00:00:29/00:09:48, 0.751s/it]: train_loss_raw=1.0489, running_loss=0.9875, LR=0.000100
[2025-08-26 12:37:06,732][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018976] [Batch 00047/00823] [00:00:35/00:09:43, 0.752s/it]: train_loss_raw=1.0400, running_loss=0.9918, LR=0.000100
[2025-08-26 12:37:13,103][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018984] [Batch 00055/00823] [00:00:41/00:09:42, 0.758s/it]: train_loss_raw=1.0755, running_loss=0.9949, LR=0.000100
[2025-08-26 12:37:19,055][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 018992] [Batch 00063/00823] [00:00:47/00:09:34, 0.757s/it]: train_loss_raw=1.0654, running_loss=0.9983, LR=0.000100
[2025-08-26 12:37:25,393][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019000] [Batch 00071/00823] [00:00:53/00:09:31, 0.761s/it]: train_loss_raw=0.9795, running_loss=0.9988, LR=0.000100
[2025-08-26 12:37:32,030][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019008] [Batch 00079/00823] [00:01:00/00:09:31, 0.768s/it]: train_loss_raw=1.0512, running_loss=1.0018, LR=0.000100
[2025-08-26 12:37:38,213][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019016] [Batch 00087/00823] [00:01:06/00:09:25, 0.768s/it]: train_loss_raw=0.9637, running_loss=1.0028, LR=0.000100
[2025-08-26 12:37:43,869][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019024] [Batch 00095/00823] [00:01:12/00:09:15, 0.763s/it]: train_loss_raw=0.9652, running_loss=1.0027, LR=0.000100
[2025-08-26 12:37:49,659][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019032] [Batch 00103/00823] [00:01:18/00:09:07, 0.760s/it]: train_loss_raw=1.0378, running_loss=1.0049, LR=0.000100
[2025-08-26 12:37:55,433][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019040] [Batch 00111/00823] [00:01:24/00:08:59, 0.757s/it]: train_loss_raw=1.1339, running_loss=1.0072, LR=0.000100
[2025-08-26 12:38:01,263][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019048] [Batch 00119/00823] [00:01:29/00:08:51, 0.755s/it]: train_loss_raw=0.9534, running_loss=1.0084, LR=0.000100
[2025-08-26 12:38:07,175][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019056] [Batch 00127/00823] [00:01:35/00:08:44, 0.754s/it]: train_loss_raw=0.9243, running_loss=1.0081, LR=0.000100
[2025-08-26 12:38:12,941][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019064] [Batch 00135/00823] [00:01:41/00:08:37, 0.752s/it]: train_loss_raw=0.9348, running_loss=1.0096, LR=0.000100
[2025-08-26 12:38:18,769][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019072] [Batch 00143/00823] [00:01:47/00:08:30, 0.751s/it]: train_loss_raw=1.0524, running_loss=1.0145, LR=0.000100
[2025-08-26 12:38:24,673][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019080] [Batch 00151/00823] [00:01:53/00:08:24, 0.750s/it]: train_loss_raw=0.9672, running_loss=1.0155, LR=0.000100
[2025-08-26 12:38:30,482][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019088] [Batch 00159/00823] [00:01:59/00:08:17, 0.749s/it]: train_loss_raw=1.1449, running_loss=1.0185, LR=0.000100
[2025-08-26 12:38:36,481][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019096] [Batch 00167/00823] [00:02:05/00:08:11, 0.749s/it]: train_loss_raw=1.1062, running_loss=1.0198, LR=0.000100
[2025-08-26 12:38:42,606][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019104] [Batch 00175/00823] [00:02:11/00:08:05, 0.750s/it]: train_loss_raw=1.0974, running_loss=1.0201, LR=0.000100
[2025-08-26 12:38:48,708][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019112] [Batch 00183/00823] [00:02:17/00:08:00, 0.750s/it]: train_loss_raw=1.0250, running_loss=1.0212, LR=0.000100
[2025-08-26 12:38:54,738][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019120] [Batch 00191/00823] [00:02:23/00:07:54, 0.750s/it]: train_loss_raw=0.9828, running_loss=1.0236, LR=0.000100
[2025-08-26 12:39:00,832][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019128] [Batch 00199/00823] [00:02:29/00:07:48, 0.751s/it]: train_loss_raw=0.9019, running_loss=1.0211, LR=0.000100
[2025-08-26 12:39:06,879][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019136] [Batch 00207/00823] [00:02:35/00:07:42, 0.751s/it]: train_loss_raw=1.0554, running_loss=1.0218, LR=0.000100
[2025-08-26 12:39:12,945][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019144] [Batch 00215/00823] [00:02:41/00:07:36, 0.751s/it]: train_loss_raw=1.0782, running_loss=1.0209, LR=0.000100
[2025-08-26 12:39:19,065][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019152] [Batch 00223/00823] [00:02:47/00:07:31, 0.752s/it]: train_loss_raw=1.0194, running_loss=1.0205, LR=0.000100
[2025-08-26 12:39:25,175][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019160] [Batch 00231/00823] [00:02:53/00:07:25, 0.752s/it]: train_loss_raw=0.9657, running_loss=1.0198, LR=0.000100
[2025-08-26 12:39:31,245][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019168] [Batch 00239/00823] [00:02:59/00:07:19, 0.753s/it]: train_loss_raw=1.0925, running_loss=1.0211, LR=0.000100
[2025-08-26 12:39:37,331][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019176] [Batch 00247/00823] [00:03:05/00:07:13, 0.753s/it]: train_loss_raw=1.0043, running_loss=1.0232, LR=0.000100
[2025-08-26 12:39:43,394][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019184] [Batch 00255/00823] [00:03:11/00:07:07, 0.753s/it]: train_loss_raw=1.1001, running_loss=1.0243, LR=0.000100
[2025-08-26 12:39:49,487][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019192] [Batch 00263/00823] [00:03:18/00:07:01, 0.753s/it]: train_loss_raw=0.9935, running_loss=1.0234, LR=0.000100
[2025-08-26 12:39:55,509][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019200] [Batch 00271/00823] [00:03:24/00:06:55, 0.753s/it]: train_loss_raw=0.9131, running_loss=1.0217, LR=0.000100
[2025-08-26 12:40:01,540][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019208] [Batch 00279/00823] [00:03:30/00:06:49, 0.753s/it]: train_loss_raw=1.0397, running_loss=1.0246, LR=0.000100
[2025-08-26 12:40:07,597][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019216] [Batch 00287/00823] [00:03:36/00:06:43, 0.753s/it]: train_loss_raw=0.9521, running_loss=1.0239, LR=0.000100
[2025-08-26 12:40:13,648][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019224] [Batch 00295/00823] [00:03:42/00:06:37, 0.753s/it]: train_loss_raw=1.1063, running_loss=1.0237, LR=0.000100
[2025-08-26 12:40:19,635][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019232] [Batch 00303/00823] [00:03:48/00:06:31, 0.753s/it]: train_loss_raw=1.0843, running_loss=1.0253, LR=0.000100
[2025-08-26 12:40:25,774][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019240] [Batch 00311/00823] [00:03:54/00:06:25, 0.754s/it]: train_loss_raw=1.0430, running_loss=1.0257, LR=0.000100
[2025-08-26 12:40:31,861][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019248] [Batch 00319/00823] [00:04:00/00:06:19, 0.754s/it]: train_loss_raw=1.0277, running_loss=1.0283, LR=0.000100
[2025-08-26 12:40:37,962][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019256] [Batch 00327/00823] [00:04:06/00:06:13, 0.754s/it]: train_loss_raw=0.9807, running_loss=1.0292, LR=0.000100
[2025-08-26 12:40:44,010][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019264] [Batch 00335/00823] [00:04:12/00:06:07, 0.754s/it]: train_loss_raw=0.9632, running_loss=1.0273, LR=0.000100
[2025-08-26 12:40:50,039][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019272] [Batch 00343/00823] [00:04:18/00:06:01, 0.754s/it]: train_loss_raw=1.0129, running_loss=1.0267, LR=0.000100
[2025-08-26 12:40:56,111][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019280] [Batch 00351/00823] [00:04:24/00:05:55, 0.754s/it]: train_loss_raw=1.0206, running_loss=1.0253, LR=0.000100
[2025-08-26 12:41:02,223][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019288] [Batch 00359/00823] [00:04:30/00:05:50, 0.754s/it]: train_loss_raw=0.9906, running_loss=1.0267, LR=0.000100
[2025-08-26 12:41:08,334][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019296] [Batch 00367/00823] [00:04:36/00:05:44, 0.755s/it]: train_loss_raw=1.0571, running_loss=1.0279, LR=0.000100
[2025-08-26 12:41:14,372][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019304] [Batch 00375/00823] [00:04:42/00:05:38, 0.755s/it]: train_loss_raw=1.0201, running_loss=1.0288, LR=0.000100
[2025-08-26 12:41:20,431][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019312] [Batch 00383/00823] [00:04:49/00:05:32, 0.755s/it]: train_loss_raw=1.0201, running_loss=1.0292, LR=0.000100
[2025-08-26 12:41:26,496][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019320] [Batch 00391/00823] [00:04:55/00:05:26, 0.755s/it]: train_loss_raw=0.9158, running_loss=1.0257, LR=0.000100
[2025-08-26 12:41:32,531][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019328] [Batch 00399/00823] [00:05:01/00:05:20, 0.755s/it]: train_loss_raw=1.0725, running_loss=1.0243, LR=0.000100
[2025-08-26 12:41:38,551][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019336] [Batch 00407/00823] [00:05:07/00:05:13, 0.755s/it]: train_loss_raw=0.9469, running_loss=1.0235, LR=0.000100
[2025-08-26 12:41:44,595][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019344] [Batch 00415/00823] [00:05:13/00:05:07, 0.755s/it]: train_loss_raw=0.9539, running_loss=1.0221, LR=0.000100
[2025-08-26 12:41:50,702][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019352] [Batch 00423/00823] [00:05:19/00:05:01, 0.755s/it]: train_loss_raw=1.0203, running_loss=1.0229, LR=0.000100
[2025-08-26 12:41:56,786][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019360] [Batch 00431/00823] [00:05:25/00:04:55, 0.755s/it]: train_loss_raw=0.9907, running_loss=1.0203, LR=0.000100
[2025-08-26 12:42:02,791][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019368] [Batch 00439/00823] [00:05:31/00:04:49, 0.755s/it]: train_loss_raw=1.0038, running_loss=1.0203, LR=0.000100
[2025-08-26 12:42:08,872][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019376] [Batch 00447/00823] [00:05:37/00:04:43, 0.755s/it]: train_loss_raw=1.0890, running_loss=1.0190, LR=0.000100
[2025-08-26 12:42:14,982][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019384] [Batch 00455/00823] [00:05:43/00:04:37, 0.755s/it]: train_loss_raw=0.9805, running_loss=1.0182, LR=0.000100
[2025-08-26 12:42:21,028][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019392] [Batch 00463/00823] [00:05:49/00:04:31, 0.755s/it]: train_loss_raw=1.0891, running_loss=1.0199, LR=0.000100
[2025-08-26 12:42:27,075][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019400] [Batch 00471/00823] [00:05:55/00:04:25, 0.755s/it]: train_loss_raw=1.0059, running_loss=1.0184, LR=0.000100
[2025-08-26 12:42:33,166][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019408] [Batch 00479/00823] [00:06:01/00:04:19, 0.755s/it]: train_loss_raw=1.0589, running_loss=1.0216, LR=0.000100
[2025-08-26 12:42:39,262][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019416] [Batch 00487/00823] [00:06:07/00:04:13, 0.755s/it]: train_loss_raw=1.0300, running_loss=1.0196, LR=0.000100
[2025-08-26 12:42:45,328][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019424] [Batch 00495/00823] [00:06:13/00:04:07, 0.755s/it]: train_loss_raw=1.0134, running_loss=1.0208, LR=0.000100
[2025-08-26 12:42:51,400][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019432] [Batch 00503/00823] [00:06:20/00:04:01, 0.755s/it]: train_loss_raw=0.9359, running_loss=1.0213, LR=0.000100
[2025-08-26 12:42:57,517][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019440] [Batch 00511/00823] [00:06:26/00:03:55, 0.756s/it]: train_loss_raw=1.0392, running_loss=1.0221, LR=0.000100
[2025-08-26 12:43:03,598][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019448] [Batch 00519/00823] [00:06:32/00:03:49, 0.756s/it]: train_loss_raw=1.0799, running_loss=1.0245, LR=0.000100
[2025-08-26 12:43:09,645][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019456] [Batch 00527/00823] [00:06:38/00:03:43, 0.756s/it]: train_loss_raw=1.0308, running_loss=1.0237, LR=0.000100
[2025-08-26 12:43:15,699][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019464] [Batch 00535/00823] [00:06:44/00:03:37, 0.756s/it]: train_loss_raw=1.0418, running_loss=1.0237, LR=0.000100
[2025-08-26 12:43:21,749][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019472] [Batch 00543/00823] [00:06:50/00:03:31, 0.756s/it]: train_loss_raw=1.0052, running_loss=1.0260, LR=0.000100
[2025-08-26 12:43:27,775][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019480] [Batch 00551/00823] [00:06:56/00:03:25, 0.756s/it]: train_loss_raw=0.9871, running_loss=1.0279, LR=0.000100
[2025-08-26 12:43:33,835][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019488] [Batch 00559/00823] [00:07:02/00:03:19, 0.756s/it]: train_loss_raw=0.9828, running_loss=1.0297, LR=0.000100
[2025-08-26 12:43:39,887][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019496] [Batch 00567/00823] [00:07:08/00:03:13, 0.756s/it]: train_loss_raw=0.9573, running_loss=1.0282, LR=0.000100
[2025-08-26 12:43:45,987][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019504] [Batch 00575/00823] [00:07:14/00:03:07, 0.756s/it]: train_loss_raw=1.0217, running_loss=1.0260, LR=0.000100
[2025-08-26 12:43:52,094][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019512] [Batch 00583/00823] [00:07:20/00:03:01, 0.756s/it]: train_loss_raw=0.9868, running_loss=1.0233, LR=0.000100
[2025-08-26 12:43:58,161][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019520] [Batch 00591/00823] [00:07:26/00:02:55, 0.756s/it]: train_loss_raw=0.9484, running_loss=1.0211, LR=0.000100
[2025-08-26 12:44:04,265][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019528] [Batch 00599/00823] [00:07:32/00:02:49, 0.756s/it]: train_loss_raw=1.0853, running_loss=1.0216, LR=0.000100
[2025-08-26 12:44:10,373][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019536] [Batch 00607/00823] [00:07:38/00:02:43, 0.756s/it]: train_loss_raw=1.0532, running_loss=1.0197, LR=0.000100
[2025-08-26 12:44:16,375][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019544] [Batch 00615/00823] [00:07:44/00:02:37, 0.756s/it]: train_loss_raw=1.0213, running_loss=1.0196, LR=0.000100
[2025-08-26 12:44:22,431][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019552] [Batch 00623/00823] [00:07:51/00:02:31, 0.756s/it]: train_loss_raw=1.1620, running_loss=1.0213, LR=0.000100
[2025-08-26 12:44:28,438][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019560] [Batch 00631/00823] [00:07:57/00:02:25, 0.756s/it]: train_loss_raw=1.0407, running_loss=1.0217, LR=0.000100
[2025-08-26 12:44:34,397][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019568] [Batch 00639/00823] [00:08:03/00:02:19, 0.756s/it]: train_loss_raw=0.9989, running_loss=1.0190, LR=0.000100
[2025-08-26 12:44:40,580][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019576] [Batch 00647/00823] [00:08:09/00:02:13, 0.756s/it]: train_loss_raw=1.0460, running_loss=1.0199, LR=0.000100
[2025-08-26 12:44:46,483][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019584] [Batch 00655/00823] [00:08:15/00:02:06, 0.756s/it]: train_loss_raw=0.9547, running_loss=1.0205, LR=0.000100
[2025-08-26 12:44:52,308][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019592] [Batch 00663/00823] [00:08:20/00:02:00, 0.756s/it]: train_loss_raw=1.0462, running_loss=1.0199, LR=0.000100
[2025-08-26 12:44:58,303][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019600] [Batch 00671/00823] [00:08:26/00:01:54, 0.755s/it]: train_loss_raw=1.0496, running_loss=1.0215, LR=0.000100
[2025-08-26 12:45:04,336][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019608] [Batch 00679/00823] [00:08:32/00:01:48, 0.755s/it]: train_loss_raw=0.9564, running_loss=1.0195, LR=0.000100
[2025-08-26 12:45:10,333][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019616] [Batch 00687/00823] [00:08:38/00:01:42, 0.755s/it]: train_loss_raw=1.1049, running_loss=1.0203, LR=0.000100
[2025-08-26 12:45:16,424][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019624] [Batch 00695/00823] [00:08:45/00:01:36, 0.755s/it]: train_loss_raw=1.0800, running_loss=1.0209, LR=0.000100
[2025-08-26 12:45:22,487][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019632] [Batch 00703/00823] [00:08:51/00:01:30, 0.755s/it]: train_loss_raw=0.9448, running_loss=1.0189, LR=0.000100
[2025-08-26 12:45:28,543][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019640] [Batch 00711/00823] [00:08:57/00:01:24, 0.755s/it]: train_loss_raw=1.0545, running_loss=1.0177, LR=0.000100
[2025-08-26 12:45:34,576][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019648] [Batch 00719/00823] [00:09:03/00:01:18, 0.755s/it]: train_loss_raw=1.1036, running_loss=1.0201, LR=0.000100
[2025-08-26 12:45:40,613][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019656] [Batch 00727/00823] [00:09:09/00:01:12, 0.755s/it]: train_loss_raw=0.9655, running_loss=1.0162, LR=0.000100
[2025-08-26 12:45:46,660][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019664] [Batch 00735/00823] [00:09:15/00:01:06, 0.755s/it]: train_loss_raw=1.0156, running_loss=1.0173, LR=0.000100
[2025-08-26 12:45:52,696][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019672] [Batch 00743/00823] [00:09:21/00:01:00, 0.755s/it]: train_loss_raw=1.1217, running_loss=1.0207, LR=0.000100
[2025-08-26 12:45:58,709][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019680] [Batch 00751/00823] [00:09:27/00:00:54, 0.755s/it]: train_loss_raw=0.9496, running_loss=1.0222, LR=0.000100
[2025-08-26 12:46:04,748][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019688] [Batch 00759/00823] [00:09:33/00:00:48, 0.755s/it]: train_loss_raw=0.9700, running_loss=1.0218, LR=0.000100
[2025-08-26 12:46:10,857][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019696] [Batch 00767/00823] [00:09:39/00:00:42, 0.755s/it]: train_loss_raw=0.8884, running_loss=1.0179, LR=0.000100
[2025-08-26 12:46:16,889][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019704] [Batch 00775/00823] [00:09:45/00:00:36, 0.755s/it]: train_loss_raw=1.0542, running_loss=1.0196, LR=0.000100
[2025-08-26 12:46:22,882][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019712] [Batch 00783/00823] [00:09:51/00:00:30, 0.755s/it]: train_loss_raw=0.9750, running_loss=1.0178, LR=0.000100
[2025-08-26 12:46:28,939][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019720] [Batch 00791/00823] [00:09:57/00:00:24, 0.755s/it]: train_loss_raw=0.9514, running_loss=1.0191, LR=0.000100
[2025-08-26 12:46:34,992][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019728] [Batch 00799/00823] [00:10:03/00:00:18, 0.755s/it]: train_loss_raw=0.9748, running_loss=1.0192, LR=0.000100
[2025-08-26 12:46:41,012][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019736] [Batch 00807/00823] [00:10:09/00:00:12, 0.755s/it]: train_loss_raw=0.9764, running_loss=1.0191, LR=0.000100
[2025-08-26 12:46:47,070][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019744] [Batch 00815/00823] [00:10:15/00:00:06, 0.755s/it]: train_loss_raw=1.0644, running_loss=1.0187, LR=0.000100
[2025-08-26 12:46:59,075][__main__][INFO] - [TRAIN] [Epoch 23/29 Step 019752] [Batch 00823/00823] [00:10:27/00:00:00, 0.763s/it]: train_loss_raw=0.9814, running_loss=1.0181, LR=0.000100
[2025-08-26 12:46:59,407][__main__][INFO] - [VALIDATION] [Epoch 23/29] Starting validation.
[2025-08-26 12:47:10,289][__main__][INFO] - [VALIDATION] [Epoch 23/29 Step 019753] [Batch 00007/00013] [00:00:10/00:00:06, 1.360s/it]
[2025-08-26 12:47:17,261][__main__][INFO] - [VALIDATION] [Epoch 23/29] train_loss=1.01812, valid_loss=1.38334
[2025-08-26 12:47:17,262][__main__][INFO] - [VALIDATION] [Epoch 23/29] Metrics:
[2025-08-26 12:47:17,262][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_er      0.561
[2025-08-26 12:47:17,262][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_prec    0.084
[2025-08-26 12:47:17,262][__main__][INFO] - [VALIDATION] [Epoch 23/29] - aa_recall  0.085
[2025-08-26 12:47:17,262][__main__][INFO] - [VALIDATION] [Epoch 23/29] - pep_recall 0.037
[2025-08-26 12:47:17,264][__main__][INFO] - [TRAIN] [Epoch 23/29] Epoch complete, total time 04:14:41, remaining time 01:03:40, 00:10:36 per epoch
[2025-08-26 12:47:23,808][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019760] [Batch 00008/00823] [00:00:05/00:09:15, 0.682s/it]: train_loss_raw=0.9966, running_loss=0.9478, LR=0.000100
[2025-08-26 12:47:29,882][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019768] [Batch 00016/00823] [00:00:11/00:09:41, 0.721s/it]: train_loss_raw=0.9458, running_loss=0.9478, LR=0.000100
[2025-08-26 12:47:35,907][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019776] [Batch 00024/00823] [00:00:17/00:09:44, 0.731s/it]: train_loss_raw=0.9005, running_loss=0.9481, LR=0.000100
[2025-08-26 12:47:41,988][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019784] [Batch 00032/00823] [00:00:23/00:09:44, 0.739s/it]: train_loss_raw=0.9990, running_loss=0.9469, LR=0.000100
[2025-08-26 12:47:48,096][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019792] [Batch 00040/00823] [00:00:29/00:09:42, 0.744s/it]: train_loss_raw=0.9402, running_loss=0.9462, LR=0.000100
[2025-08-26 12:47:54,142][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019800] [Batch 00048/00823] [00:00:35/00:09:37, 0.746s/it]: train_loss_raw=0.8846, running_loss=0.9459, LR=0.000100
[2025-08-26 12:48:00,233][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019808] [Batch 00056/00823] [00:00:41/00:09:33, 0.748s/it]: train_loss_raw=0.9526, running_loss=0.9453, LR=0.000100
[2025-08-26 12:48:06,239][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019816] [Batch 00064/00823] [00:00:47/00:09:27, 0.748s/it]: train_loss_raw=1.0226, running_loss=0.9452, LR=0.000100
[2025-08-26 12:48:12,314][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019824] [Batch 00072/00823] [00:00:53/00:09:22, 0.749s/it]: train_loss_raw=0.9037, running_loss=0.9481, LR=0.000100
[2025-08-26 12:48:18,348][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019832] [Batch 00080/00823] [00:00:59/00:09:17, 0.750s/it]: train_loss_raw=0.9185, running_loss=0.9505, LR=0.000100
[2025-08-26 12:48:24,361][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019840] [Batch 00088/00823] [00:01:06/00:09:11, 0.750s/it]: train_loss_raw=1.0050, running_loss=0.9532, LR=0.000100
[2025-08-26 12:48:30,421][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019848] [Batch 00096/00823] [00:01:12/00:09:05, 0.751s/it]: train_loss_raw=1.0250, running_loss=0.9546, LR=0.000100
[2025-08-26 12:48:36,407][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019856] [Batch 00104/00823] [00:01:18/00:08:59, 0.751s/it]: train_loss_raw=0.9964, running_loss=0.9570, LR=0.000100
[2025-08-26 12:48:42,500][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019864] [Batch 00112/00823] [00:01:24/00:08:54, 0.751s/it]: train_loss_raw=0.9314, running_loss=0.9573, LR=0.000100
[2025-08-26 12:48:48,539][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019872] [Batch 00120/00823] [00:01:30/00:08:48, 0.752s/it]: train_loss_raw=0.9134, running_loss=0.9578, LR=0.000100
[2025-08-26 12:48:54,655][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019880] [Batch 00128/00823] [00:01:36/00:08:42, 0.752s/it]: train_loss_raw=0.8752, running_loss=0.9559, LR=0.000100
[2025-08-26 12:49:00,710][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019888] [Batch 00136/00823] [00:01:42/00:08:37, 0.753s/it]: train_loss_raw=0.9562, running_loss=0.9576, LR=0.000100
[2025-08-26 12:49:06,702][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019896] [Batch 00144/00823] [00:01:48/00:08:30, 0.752s/it]: train_loss_raw=0.9119, running_loss=0.9565, LR=0.000100
[2025-08-26 12:49:12,768][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019904] [Batch 00152/00823] [00:01:54/00:08:25, 0.753s/it]: train_loss_raw=1.0502, running_loss=0.9567, LR=0.000100
[2025-08-26 12:49:18,912][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019912] [Batch 00160/00823] [00:02:00/00:08:19, 0.753s/it]: train_loss_raw=0.9558, running_loss=0.9576, LR=0.000100
[2025-08-26 12:49:25,105][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019920] [Batch 00168/00823] [00:02:06/00:08:14, 0.754s/it]: train_loss_raw=0.9949, running_loss=0.9577, LR=0.000100
[2025-08-26 12:49:31,062][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019928] [Batch 00176/00823] [00:02:12/00:08:07, 0.754s/it]: train_loss_raw=0.9795, running_loss=0.9582, LR=0.000100
[2025-08-26 12:49:37,051][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019936] [Batch 00184/00823] [00:02:18/00:08:01, 0.754s/it]: train_loss_raw=0.9059, running_loss=0.9597, LR=0.000100
[2025-08-26 12:49:42,908][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019944] [Batch 00192/00823] [00:02:24/00:07:55, 0.753s/it]: train_loss_raw=0.9313, running_loss=0.9594, LR=0.000100
[2025-08-26 12:49:48,647][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019952] [Batch 00200/00823] [00:02:30/00:07:48, 0.751s/it]: train_loss_raw=0.9176, running_loss=0.9595, LR=0.000100
[2025-08-26 12:49:54,369][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019960] [Batch 00208/00823] [00:02:36/00:07:41, 0.750s/it]: train_loss_raw=1.0472, running_loss=0.9599, LR=0.000100
[2025-08-26 12:50:00,123][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019968] [Batch 00216/00823] [00:02:41/00:07:34, 0.749s/it]: train_loss_raw=0.8857, running_loss=0.9603, LR=0.000100
[2025-08-26 12:50:05,867][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019976] [Batch 00224/00823] [00:02:47/00:07:27, 0.748s/it]: train_loss_raw=0.9687, running_loss=0.9611, LR=0.000100
[2025-08-26 12:50:11,642][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019984] [Batch 00232/00823] [00:02:53/00:07:21, 0.747s/it]: train_loss_raw=0.9856, running_loss=0.9614, LR=0.000100
[2025-08-26 12:50:17,395][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 019992] [Batch 00240/00823] [00:02:59/00:07:14, 0.746s/it]: train_loss_raw=0.9755, running_loss=0.9618, LR=0.000100
[2025-08-26 12:50:23,229][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020000] [Batch 00248/00823] [00:03:04/00:07:08, 0.745s/it]: train_loss_raw=0.8861, running_loss=0.9620, LR=0.000100
[2025-08-26 12:50:33,631][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020008] [Batch 00256/00823] [00:03:15/00:07:12, 0.763s/it]: train_loss_raw=1.0401, running_loss=0.9630, LR=0.000100
[2025-08-26 12:50:39,460][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020016] [Batch 00264/00823] [00:03:21/00:07:05, 0.762s/it]: train_loss_raw=0.9070, running_loss=0.9639, LR=0.000100
[2025-08-26 12:50:45,225][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020024] [Batch 00272/00823] [00:03:26/00:06:59, 0.761s/it]: train_loss_raw=0.9767, running_loss=0.9648, LR=0.000100
[2025-08-26 12:50:51,141][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020032] [Batch 00280/00823] [00:03:32/00:06:52, 0.760s/it]: train_loss_raw=0.9675, running_loss=0.9606, LR=0.000100
[2025-08-26 12:50:56,936][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020040] [Batch 00288/00823] [00:03:38/00:06:46, 0.759s/it]: train_loss_raw=0.9959, running_loss=0.9627, LR=0.000100
[2025-08-26 12:51:02,700][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020048] [Batch 00296/00823] [00:03:44/00:06:39, 0.758s/it]: train_loss_raw=1.0764, running_loss=0.9643, LR=0.000100
[2025-08-26 12:51:08,418][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020056] [Batch 00304/00823] [00:03:50/00:06:32, 0.757s/it]: train_loss_raw=1.0133, running_loss=0.9652, LR=0.000100
[2025-08-26 12:51:14,312][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020064] [Batch 00312/00823] [00:03:55/00:06:26, 0.756s/it]: train_loss_raw=0.8964, running_loss=0.9639, LR=0.000100
[2025-08-26 12:51:20,229][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020072] [Batch 00320/00823] [00:04:01/00:06:20, 0.756s/it]: train_loss_raw=0.9077, running_loss=0.9652, LR=0.000100
[2025-08-26 12:51:26,006][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020080] [Batch 00328/00823] [00:04:07/00:06:13, 0.755s/it]: train_loss_raw=1.0282, running_loss=0.9618, LR=0.000100
[2025-08-26 12:51:31,920][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020088] [Batch 00336/00823] [00:04:13/00:06:07, 0.755s/it]: train_loss_raw=1.0406, running_loss=0.9604, LR=0.000100
[2025-08-26 12:51:37,789][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020096] [Batch 00344/00823] [00:04:19/00:06:01, 0.754s/it]: train_loss_raw=0.9871, running_loss=0.9619, LR=0.000100
[2025-08-26 12:51:43,595][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020104] [Batch 00352/00823] [00:04:25/00:05:54, 0.754s/it]: train_loss_raw=1.0350, running_loss=0.9663, LR=0.000100
[2025-08-26 12:51:49,368][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020112] [Batch 00360/00823] [00:04:31/00:05:48, 0.753s/it]: train_loss_raw=1.0722, running_loss=0.9672, LR=0.000100
[2025-08-26 12:51:55,255][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020120] [Batch 00368/00823] [00:04:36/00:05:42, 0.752s/it]: train_loss_raw=0.9245, running_loss=0.9677, LR=0.000100
[2025-08-26 12:52:01,188][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020128] [Batch 00376/00823] [00:04:42/00:05:36, 0.752s/it]: train_loss_raw=0.9760, running_loss=0.9677, LR=0.000100
[2025-08-26 12:52:06,928][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020136] [Batch 00384/00823] [00:04:48/00:05:29, 0.751s/it]: train_loss_raw=0.9312, running_loss=0.9684, LR=0.000100
[2025-08-26 12:52:12,718][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020144] [Batch 00392/00823] [00:04:54/00:05:23, 0.751s/it]: train_loss_raw=0.9803, running_loss=0.9664, LR=0.000100
[2025-08-26 12:52:18,513][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020152] [Batch 00400/00823] [00:05:00/00:05:17, 0.750s/it]: train_loss_raw=1.0169, running_loss=0.9675, LR=0.000100
[2025-08-26 12:52:24,285][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020160] [Batch 00408/00823] [00:05:05/00:05:11, 0.750s/it]: train_loss_raw=0.9559, running_loss=0.9658, LR=0.000100
[2025-08-26 12:52:30,164][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020168] [Batch 00416/00823] [00:05:11/00:05:05, 0.750s/it]: train_loss_raw=0.9895, running_loss=0.9658, LR=0.000100
[2025-08-26 12:52:36,047][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020176] [Batch 00424/00823] [00:05:17/00:04:58, 0.749s/it]: train_loss_raw=0.9350, running_loss=0.9640, LR=0.000100
[2025-08-26 12:52:42,044][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020184] [Batch 00432/00823] [00:05:23/00:04:52, 0.749s/it]: train_loss_raw=0.9912, running_loss=0.9645, LR=0.000100
[2025-08-26 12:52:47,816][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020192] [Batch 00440/00823] [00:05:29/00:04:46, 0.749s/it]: train_loss_raw=0.8934, running_loss=0.9642, LR=0.000100
[2025-08-26 12:52:53,682][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020200] [Batch 00448/00823] [00:05:35/00:04:40, 0.749s/it]: train_loss_raw=1.0155, running_loss=0.9664, LR=0.000100
[2025-08-26 12:52:59,591][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020208] [Batch 00456/00823] [00:05:41/00:04:34, 0.748s/it]: train_loss_raw=0.9268, running_loss=0.9671, LR=0.000100
[2025-08-26 12:53:05,444][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020216] [Batch 00464/00823] [00:05:47/00:04:28, 0.748s/it]: train_loss_raw=1.0521, running_loss=0.9667, LR=0.000100
[2025-08-26 12:53:11,262][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020224] [Batch 00472/00823] [00:05:52/00:04:22, 0.748s/it]: train_loss_raw=1.0735, running_loss=0.9696, LR=0.000100
[2025-08-26 12:53:17,103][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020232] [Batch 00480/00823] [00:05:58/00:04:16, 0.747s/it]: train_loss_raw=0.8784, running_loss=0.9688, LR=0.000100
[2025-08-26 12:53:23,119][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020240] [Batch 00488/00823] [00:06:04/00:04:10, 0.747s/it]: train_loss_raw=1.0108, running_loss=0.9680, LR=0.000100
[2025-08-26 12:53:28,970][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020248] [Batch 00496/00823] [00:06:10/00:04:04, 0.747s/it]: train_loss_raw=0.9627, running_loss=0.9690, LR=0.000100
[2025-08-26 12:53:35,001][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020256] [Batch 00504/00823] [00:06:16/00:03:58, 0.747s/it]: train_loss_raw=0.9624, running_loss=0.9684, LR=0.000100
[2025-08-26 12:53:40,937][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020264] [Batch 00512/00823] [00:06:22/00:03:52, 0.747s/it]: train_loss_raw=0.8934, running_loss=0.9664, LR=0.000100
[2025-08-26 12:53:46,690][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020272] [Batch 00520/00823] [00:06:28/00:03:46, 0.747s/it]: train_loss_raw=0.9816, running_loss=0.9667, LR=0.000100
[2025-08-26 12:53:52,394][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020280] [Batch 00528/00823] [00:06:34/00:03:40, 0.746s/it]: train_loss_raw=1.0371, running_loss=0.9678, LR=0.000100
[2025-08-26 12:53:58,108][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020288] [Batch 00536/00823] [00:06:39/00:03:34, 0.746s/it]: train_loss_raw=0.9880, running_loss=0.9667, LR=0.000100
[2025-08-26 12:54:03,975][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020296] [Batch 00544/00823] [00:06:45/00:03:28, 0.746s/it]: train_loss_raw=0.8592, running_loss=0.9648, LR=0.000100
[2025-08-26 12:54:09,883][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020304] [Batch 00552/00823] [00:06:51/00:03:22, 0.746s/it]: train_loss_raw=0.8759, running_loss=0.9650, LR=0.000100
[2025-08-26 12:54:15,895][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020312] [Batch 00560/00823] [00:06:57/00:03:16, 0.746s/it]: train_loss_raw=0.9372, running_loss=0.9652, LR=0.000100
[2025-08-26 12:54:21,744][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020320] [Batch 00568/00823] [00:07:03/00:03:10, 0.745s/it]: train_loss_raw=0.9762, running_loss=0.9668, LR=0.000100
[2025-08-26 12:54:27,533][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020328] [Batch 00576/00823] [00:07:09/00:03:04, 0.745s/it]: train_loss_raw=0.9845, running_loss=0.9674, LR=0.000100
[2025-08-26 12:54:33,363][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020336] [Batch 00584/00823] [00:07:15/00:02:58, 0.745s/it]: train_loss_raw=0.9054, running_loss=0.9672, LR=0.000100
[2025-08-26 12:54:39,325][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020344] [Batch 00592/00823] [00:07:20/00:02:52, 0.745s/it]: train_loss_raw=1.0055, running_loss=0.9663, LR=0.000100
[2025-08-26 12:54:45,171][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020352] [Batch 00600/00823] [00:07:26/00:02:46, 0.745s/it]: train_loss_raw=1.0616, running_loss=0.9690, LR=0.000100
[2025-08-26 12:54:51,029][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020360] [Batch 00608/00823] [00:07:32/00:02:40, 0.745s/it]: train_loss_raw=0.9936, running_loss=0.9697, LR=0.000100
[2025-08-26 12:54:56,851][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020368] [Batch 00616/00823] [00:07:38/00:02:34, 0.744s/it]: train_loss_raw=0.9414, running_loss=0.9680, LR=0.000100
[2025-08-26 12:55:02,783][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020376] [Batch 00624/00823] [00:07:44/00:02:28, 0.744s/it]: train_loss_raw=0.8788, running_loss=0.9678, LR=0.000100
[2025-08-26 12:55:08,613][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020384] [Batch 00632/00823] [00:07:50/00:02:22, 0.744s/it]: train_loss_raw=0.9583, running_loss=0.9670, LR=0.000100
[2025-08-26 12:55:14,454][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020392] [Batch 00640/00823] [00:07:56/00:02:16, 0.744s/it]: train_loss_raw=1.0220, running_loss=0.9664, LR=0.000100
[2025-08-26 12:55:20,301][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020400] [Batch 00648/00823] [00:08:01/00:02:10, 0.744s/it]: train_loss_raw=0.9541, running_loss=0.9667, LR=0.000100
[2025-08-26 12:55:26,158][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020408] [Batch 00656/00823] [00:08:07/00:02:04, 0.744s/it]: train_loss_raw=0.9376, running_loss=0.9679, LR=0.000100
[2025-08-26 12:55:32,053][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020416] [Batch 00664/00823] [00:08:13/00:01:58, 0.744s/it]: train_loss_raw=1.0459, running_loss=0.9698, LR=0.000100
[2025-08-26 12:55:38,005][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020424] [Batch 00672/00823] [00:08:19/00:01:52, 0.744s/it]: train_loss_raw=0.9614, running_loss=0.9707, LR=0.000100
[2025-08-26 12:55:43,797][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020432] [Batch 00680/00823] [00:08:25/00:01:46, 0.743s/it]: train_loss_raw=0.8891, running_loss=0.9693, LR=0.000100
[2025-08-26 12:55:49,764][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020440] [Batch 00688/00823] [00:08:31/00:01:40, 0.743s/it]: train_loss_raw=0.9206, running_loss=0.9658, LR=0.000100
[2025-08-26 12:55:55,613][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020448] [Batch 00696/00823] [00:08:37/00:01:34, 0.743s/it]: train_loss_raw=0.9337, running_loss=0.9631, LR=0.000100
[2025-08-26 12:56:01,511][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020456] [Batch 00704/00823] [00:08:43/00:01:28, 0.743s/it]: train_loss_raw=0.9993, running_loss=0.9658, LR=0.000100
[2025-08-26 12:56:07,294][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020464] [Batch 00712/00823] [00:08:48/00:01:22, 0.743s/it]: train_loss_raw=1.0044, running_loss=0.9651, LR=0.000100
[2025-08-26 12:56:13,058][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020472] [Batch 00720/00823] [00:08:54/00:01:16, 0.743s/it]: train_loss_raw=0.9770, running_loss=0.9639, LR=0.000100
[2025-08-26 12:56:19,086][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020480] [Batch 00728/00823] [00:09:00/00:01:10, 0.743s/it]: train_loss_raw=1.0358, running_loss=0.9632, LR=0.000100
[2025-08-26 12:56:24,946][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020488] [Batch 00736/00823] [00:09:06/00:01:04, 0.743s/it]: train_loss_raw=1.0095, running_loss=0.9628, LR=0.000100
[2025-08-26 12:56:30,841][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020496] [Batch 00744/00823] [00:09:12/00:00:58, 0.743s/it]: train_loss_raw=0.9578, running_loss=0.9625, LR=0.000100
[2025-08-26 12:56:36,765][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020504] [Batch 00752/00823] [00:09:18/00:00:52, 0.743s/it]: train_loss_raw=1.0132, running_loss=0.9644, LR=0.000100
[2025-08-26 12:56:42,536][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020512] [Batch 00760/00823] [00:09:24/00:00:46, 0.742s/it]: train_loss_raw=0.9490, running_loss=0.9628, LR=0.000100
[2025-08-26 12:56:48,471][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020520] [Batch 00768/00823] [00:09:30/00:00:40, 0.742s/it]: train_loss_raw=0.9993, running_loss=0.9646, LR=0.000100
[2025-08-26 12:56:54,266][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020528] [Batch 00776/00823] [00:09:35/00:00:34, 0.742s/it]: train_loss_raw=0.9636, running_loss=0.9637, LR=0.000100
[2025-08-26 12:57:00,031][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020536] [Batch 00784/00823] [00:09:41/00:00:28, 0.742s/it]: train_loss_raw=0.9538, running_loss=0.9662, LR=0.000100
[2025-08-26 12:57:05,895][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020544] [Batch 00792/00823] [00:09:47/00:00:22, 0.742s/it]: train_loss_raw=1.0133, running_loss=0.9670, LR=0.000100
[2025-08-26 12:57:11,798][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020552] [Batch 00800/00823] [00:09:53/00:00:17, 0.742s/it]: train_loss_raw=0.9997, running_loss=0.9679, LR=0.000100
[2025-08-26 12:57:17,598][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020560] [Batch 00808/00823] [00:09:59/00:00:11, 0.742s/it]: train_loss_raw=0.9674, running_loss=0.9673, LR=0.000100
[2025-08-26 12:57:23,330][__main__][INFO] - [TRAIN] [Epoch 24/29 Step 020568] [Batch 00816/00823] [00:10:04/00:00:05, 0.741s/it]: train_loss_raw=0.8988, running_loss=0.9651, LR=0.000100
[2025-08-26 12:57:28,553][__main__][INFO] - [VALIDATION] [Epoch 24/29] Starting validation.
[2025-08-26 12:57:39,372][__main__][INFO] - [VALIDATION] [Epoch 24/29 Step 020576] [Batch 00007/00013] [00:00:10/00:00:06, 1.352s/it]
[2025-08-26 12:57:46,241][__main__][INFO] - [VALIDATION] [Epoch 24/29] train_loss=0.96381, valid_loss=1.36503
[2025-08-26 12:57:46,242][__main__][INFO] - [VALIDATION] [Epoch 24/29] Metrics:
[2025-08-26 12:57:46,242][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_er      0.560
[2025-08-26 12:57:46,242][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_prec    0.079
[2025-08-26 12:57:46,242][__main__][INFO] - [VALIDATION] [Epoch 24/29] - aa_recall  0.080
[2025-08-26 12:57:46,242][__main__][INFO] - [VALIDATION] [Epoch 24/29] - pep_recall 0.035
[2025-08-26 12:57:46,244][__main__][INFO] - [TRAIN] [Epoch 24/29] Epoch complete, total time 04:25:09, remaining time 00:53:01, 00:10:36 per epoch
[2025-08-26 12:57:47,424][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020576] [Batch 00001/00823] [00:00:00/00:01:57, 0.143s/it]: train_loss_raw=0.8936, running_loss=0.8936, LR=0.000100
[2025-08-26 12:57:53,379][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020584] [Batch 00009/00823] [00:00:06/00:09:11, 0.678s/it]: train_loss_raw=1.0363, running_loss=0.8989, LR=0.000100
[2025-08-26 12:57:59,249][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020592] [Batch 00017/00823] [00:00:11/00:09:27, 0.704s/it]: train_loss_raw=0.8528, running_loss=0.9045, LR=0.000100
[2025-08-26 12:58:05,188][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020600] [Batch 00025/00823] [00:00:17/00:09:31, 0.716s/it]: train_loss_raw=0.8494, running_loss=0.9085, LR=0.000100
[2025-08-26 12:58:11,062][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020608] [Batch 00033/00823] [00:00:23/00:09:29, 0.721s/it]: train_loss_raw=0.9803, running_loss=0.9130, LR=0.000100
[2025-08-26 12:58:16,917][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020616] [Batch 00041/00823] [00:00:29/00:09:25, 0.723s/it]: train_loss_raw=0.9359, running_loss=0.9163, LR=0.000100
[2025-08-26 12:58:22,693][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020624] [Batch 00049/00823] [00:00:35/00:09:19, 0.723s/it]: train_loss_raw=1.0362, running_loss=0.9228, LR=0.000100
[2025-08-26 12:58:28,675][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020632] [Batch 00057/00823] [00:00:41/00:09:16, 0.726s/it]: train_loss_raw=0.9492, running_loss=0.9266, LR=0.000100
[2025-08-26 12:58:34,464][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020640] [Batch 00065/00823] [00:00:47/00:09:10, 0.726s/it]: train_loss_raw=0.9802, running_loss=0.9338, LR=0.000100
[2025-08-26 12:58:40,160][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020648] [Batch 00073/00823] [00:00:52/00:09:03, 0.724s/it]: train_loss_raw=0.8600, running_loss=0.9356, LR=0.000100
[2025-08-26 12:58:46,153][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020656] [Batch 00081/00823] [00:00:58/00:08:59, 0.727s/it]: train_loss_raw=0.9921, running_loss=0.9381, LR=0.000100
[2025-08-26 12:58:52,062][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020664] [Batch 00089/00823] [00:01:04/00:08:54, 0.728s/it]: train_loss_raw=1.0305, running_loss=0.9413, LR=0.000100
[2025-08-26 12:58:57,945][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020672] [Batch 00097/00823] [00:01:10/00:08:48, 0.728s/it]: train_loss_raw=0.9564, running_loss=0.9434, LR=0.000100
[2025-08-26 12:59:03,931][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020680] [Batch 00105/00823] [00:01:16/00:08:44, 0.730s/it]: train_loss_raw=0.9912, running_loss=0.9451, LR=0.000100
[2025-08-26 12:59:09,649][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020688] [Batch 00113/00823] [00:01:22/00:08:37, 0.729s/it]: train_loss_raw=0.9575, running_loss=0.9434, LR=0.000100
[2025-08-26 12:59:15,728][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020696] [Batch 00121/00823] [00:01:28/00:08:33, 0.731s/it]: train_loss_raw=1.0040, running_loss=0.9455, LR=0.000100
[2025-08-26 12:59:21,520][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020704] [Batch 00129/00823] [00:01:34/00:08:26, 0.731s/it]: train_loss_raw=0.9922, running_loss=0.9449, LR=0.000100
[2025-08-26 12:59:27,590][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020712] [Batch 00137/00823] [00:01:40/00:08:22, 0.732s/it]: train_loss_raw=0.9245, running_loss=0.9487, LR=0.000100
[2025-08-26 12:59:33,533][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020720] [Batch 00145/00823] [00:01:46/00:08:16, 0.733s/it]: train_loss_raw=0.9023, running_loss=0.9506, LR=0.000100
[2025-08-26 12:59:39,467][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020728] [Batch 00153/00823] [00:01:52/00:08:11, 0.733s/it]: train_loss_raw=1.0094, running_loss=0.9510, LR=0.000100
[2025-08-26 12:59:45,392][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020736] [Batch 00161/00823] [00:01:58/00:08:05, 0.734s/it]: train_loss_raw=0.9741, running_loss=0.9518, LR=0.000100
[2025-08-26 12:59:51,364][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020744] [Batch 00169/00823] [00:02:04/00:08:00, 0.734s/it]: train_loss_raw=0.9385, running_loss=0.9510, LR=0.000100
[2025-08-26 12:59:57,147][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020752] [Batch 00177/00823] [00:02:09/00:07:53, 0.734s/it]: train_loss_raw=0.9898, running_loss=0.9519, LR=0.000100
[2025-08-26 13:00:02,978][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020760] [Batch 00185/00823] [00:02:15/00:07:47, 0.733s/it]: train_loss_raw=0.9253, running_loss=0.9514, LR=0.000100
[2025-08-26 13:00:08,888][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020768] [Batch 00193/00823] [00:02:21/00:07:42, 0.734s/it]: train_loss_raw=0.9078, running_loss=0.9517, LR=0.000100
[2025-08-26 13:00:14,712][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020776] [Batch 00201/00823] [00:02:27/00:07:36, 0.733s/it]: train_loss_raw=0.9167, running_loss=0.9496, LR=0.000100
[2025-08-26 13:00:20,587][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020784] [Batch 00209/00823] [00:02:33/00:07:30, 0.734s/it]: train_loss_raw=0.9471, running_loss=0.9509, LR=0.000100
[2025-08-26 13:00:26,251][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020792] [Batch 00217/00823] [00:02:38/00:07:23, 0.733s/it]: train_loss_raw=1.0721, running_loss=0.9516, LR=0.000100
[2025-08-26 13:00:32,100][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020800] [Batch 00225/00823] [00:02:44/00:07:18, 0.733s/it]: train_loss_raw=1.0267, running_loss=0.9532, LR=0.000100
[2025-08-26 13:00:38,151][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020808] [Batch 00233/00823] [00:02:50/00:07:12, 0.733s/it]: train_loss_raw=0.9684, running_loss=0.9545, LR=0.000100
[2025-08-26 13:00:43,972][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020816] [Batch 00241/00823] [00:02:56/00:07:06, 0.733s/it]: train_loss_raw=1.0443, running_loss=0.9546, LR=0.000100
[2025-08-26 13:00:49,844][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020824] [Batch 00249/00823] [00:03:02/00:07:00, 0.733s/it]: train_loss_raw=0.9983, running_loss=0.9537, LR=0.000100
[2025-08-26 13:00:55,740][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020832] [Batch 00257/00823] [00:03:08/00:06:55, 0.733s/it]: train_loss_raw=0.9355, running_loss=0.9532, LR=0.000100
[2025-08-26 13:01:01,624][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020840] [Batch 00265/00823] [00:03:14/00:06:49, 0.733s/it]: train_loss_raw=1.0335, running_loss=0.9548, LR=0.000100
[2025-08-26 13:01:07,494][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020848] [Batch 00273/00823] [00:03:20/00:06:43, 0.733s/it]: train_loss_raw=1.0050, running_loss=0.9551, LR=0.000100
[2025-08-26 13:01:13,338][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020856] [Batch 00281/00823] [00:03:26/00:06:37, 0.733s/it]: train_loss_raw=0.9748, running_loss=0.9578, LR=0.000100
[2025-08-26 13:01:19,152][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020864] [Batch 00289/00823] [00:03:31/00:06:31, 0.733s/it]: train_loss_raw=1.0855, running_loss=0.9562, LR=0.000100
[2025-08-26 13:01:25,133][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020872] [Batch 00297/00823] [00:03:37/00:06:25, 0.734s/it]: train_loss_raw=0.9071, running_loss=0.9595, LR=0.000100
[2025-08-26 13:01:30,961][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020880] [Batch 00305/00823] [00:03:43/00:06:19, 0.733s/it]: train_loss_raw=0.9043, running_loss=0.9595, LR=0.000100
[2025-08-26 13:01:36,853][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020888] [Batch 00313/00823] [00:03:49/00:06:14, 0.733s/it]: train_loss_raw=0.9008, running_loss=0.9575, LR=0.000100
[2025-08-26 13:01:42,650][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020896] [Batch 00321/00823] [00:03:55/00:06:08, 0.733s/it]: train_loss_raw=0.9263, running_loss=0.9559, LR=0.000100
[2025-08-26 13:01:48,394][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020904] [Batch 00329/00823] [00:04:01/00:06:02, 0.733s/it]: train_loss_raw=0.8966, running_loss=0.9537, LR=0.000100
[2025-08-26 13:01:54,218][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020912] [Batch 00337/00823] [00:04:06/00:05:56, 0.733s/it]: train_loss_raw=1.0235, running_loss=0.9529, LR=0.000100
[2025-08-26 13:02:00,150][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020920] [Batch 00345/00823] [00:04:12/00:05:50, 0.733s/it]: train_loss_raw=1.0378, running_loss=0.9555, LR=0.000100
[2025-08-26 13:02:06,097][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020928] [Batch 00353/00823] [00:04:18/00:05:44, 0.733s/it]: train_loss_raw=0.8603, running_loss=0.9540, LR=0.000100
[2025-08-26 13:02:11,953][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020936] [Batch 00361/00823] [00:04:24/00:05:38, 0.733s/it]: train_loss_raw=1.0148, running_loss=0.9538, LR=0.000100
[2025-08-26 13:02:17,838][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020944] [Batch 00369/00823] [00:04:30/00:05:32, 0.733s/it]: train_loss_raw=0.9418, running_loss=0.9543, LR=0.000100
[2025-08-26 13:02:23,608][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020952] [Batch 00377/00823] [00:04:36/00:05:26, 0.733s/it]: train_loss_raw=0.8759, running_loss=0.9550, LR=0.000100
[2025-08-26 13:02:29,578][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020960] [Batch 00385/00823] [00:04:42/00:05:21, 0.733s/it]: train_loss_raw=1.0465, running_loss=0.9567, LR=0.000100
[2025-08-26 13:02:35,457][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020968] [Batch 00393/00823] [00:04:48/00:05:15, 0.733s/it]: train_loss_raw=0.9190, running_loss=0.9569, LR=0.000100
[2025-08-26 13:02:41,218][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020976] [Batch 00401/00823] [00:04:53/00:05:09, 0.733s/it]: train_loss_raw=1.0381, running_loss=0.9610, LR=0.000100
[2025-08-26 13:02:46,837][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020984] [Batch 00409/00823] [00:04:59/00:05:03, 0.732s/it]: train_loss_raw=0.9592, running_loss=0.9612, LR=0.000100
[2025-08-26 13:02:52,754][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 020992] [Batch 00417/00823] [00:05:05/00:04:57, 0.733s/it]: train_loss_raw=1.0058, running_loss=0.9604, LR=0.000100
[2025-08-26 13:02:58,649][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021000] [Batch 00425/00823] [00:05:11/00:04:51, 0.733s/it]: train_loss_raw=0.8985, running_loss=0.9601, LR=0.000100
[2025-08-26 13:03:04,560][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021008] [Batch 00433/00823] [00:05:17/00:04:45, 0.733s/it]: train_loss_raw=0.8965, running_loss=0.9565, LR=0.000100
[2025-08-26 13:03:10,512][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021016] [Batch 00441/00823] [00:05:23/00:04:39, 0.733s/it]: train_loss_raw=0.9324, running_loss=0.9562, LR=0.000100
[2025-08-26 13:03:16,483][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021024] [Batch 00449/00823] [00:05:29/00:04:34, 0.733s/it]: train_loss_raw=0.9812, running_loss=0.9576, LR=0.000100
[2025-08-26 13:03:22,456][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021032] [Batch 00457/00823] [00:05:35/00:04:28, 0.733s/it]: train_loss_raw=0.9383, running_loss=0.9593, LR=0.000100
[2025-08-26 13:03:28,381][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021040] [Batch 00465/00823] [00:05:41/00:04:22, 0.734s/it]: train_loss_raw=0.9551, running_loss=0.9606, LR=0.000100
[2025-08-26 13:03:34,423][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021048] [Batch 00473/00823] [00:05:47/00:04:16, 0.734s/it]: train_loss_raw=0.9677, running_loss=0.9615, LR=0.000100
[2025-08-26 13:03:40,293][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021056] [Batch 00481/00823] [00:05:53/00:04:10, 0.734s/it]: train_loss_raw=0.9169, running_loss=0.9595, LR=0.000100
[2025-08-26 13:03:46,131][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021064] [Batch 00489/00823] [00:05:58/00:04:05, 0.734s/it]: train_loss_raw=0.8817, running_loss=0.9608, LR=0.000100
[2025-08-26 13:03:51,958][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021072] [Batch 00497/00823] [00:06:04/00:03:59, 0.734s/it]: train_loss_raw=0.8459, running_loss=0.9573, LR=0.000100
[2025-08-26 13:03:57,895][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021080] [Batch 00505/00823] [00:06:10/00:03:53, 0.734s/it]: train_loss_raw=0.8976, running_loss=0.9593, LR=0.000100
[2025-08-26 13:04:03,736][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021088] [Batch 00513/00823] [00:06:16/00:03:47, 0.734s/it]: train_loss_raw=0.8707, running_loss=0.9610, LR=0.000100
[2025-08-26 13:04:09,520][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021096] [Batch 00521/00823] [00:06:22/00:03:41, 0.734s/it]: train_loss_raw=0.8811, running_loss=0.9601, LR=0.000100
[2025-08-26 13:04:15,181][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021104] [Batch 00529/00823] [00:06:27/00:03:35, 0.733s/it]: train_loss_raw=0.9196, running_loss=0.9583, LR=0.000100
[2025-08-26 13:04:20,957][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021112] [Batch 00537/00823] [00:06:33/00:03:29, 0.733s/it]: train_loss_raw=0.9899, running_loss=0.9575, LR=0.000100
[2025-08-26 13:04:26,684][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021120] [Batch 00545/00823] [00:06:39/00:03:23, 0.733s/it]: train_loss_raw=0.8673, running_loss=0.9580, LR=0.000100
[2025-08-26 13:04:32,472][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021128] [Batch 00553/00823] [00:06:45/00:03:17, 0.733s/it]: train_loss_raw=0.9548, running_loss=0.9594, LR=0.000100
[2025-08-26 13:04:38,366][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021136] [Batch 00561/00823] [00:06:51/00:03:11, 0.733s/it]: train_loss_raw=0.9096, running_loss=0.9575, LR=0.000100
[2025-08-26 13:04:44,284][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021144] [Batch 00569/00823] [00:06:57/00:03:06, 0.733s/it]: train_loss_raw=0.9880, running_loss=0.9593, LR=0.000100
[2025-08-26 13:04:50,247][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021152] [Batch 00577/00823] [00:07:02/00:03:00, 0.733s/it]: train_loss_raw=0.9507, running_loss=0.9574, LR=0.000100
[2025-08-26 13:04:56,333][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021160] [Batch 00585/00823] [00:07:09/00:02:54, 0.733s/it]: train_loss_raw=0.9136, running_loss=0.9566, LR=0.000100
[2025-08-26 13:05:02,264][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021168] [Batch 00593/00823] [00:07:14/00:02:48, 0.734s/it]: train_loss_raw=1.0254, running_loss=0.9596, LR=0.000100
[2025-08-26 13:05:08,152][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021176] [Batch 00601/00823] [00:07:20/00:02:42, 0.734s/it]: train_loss_raw=0.8750, running_loss=0.9573, LR=0.000100
[2025-08-26 13:05:13,945][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021184] [Batch 00609/00823] [00:07:26/00:02:36, 0.733s/it]: train_loss_raw=0.9588, running_loss=0.9561, LR=0.000100
[2025-08-26 13:05:19,886][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021192] [Batch 00617/00823] [00:07:32/00:02:31, 0.734s/it]: train_loss_raw=0.8243, running_loss=0.9544, LR=0.000100
[2025-08-26 13:05:25,849][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021200] [Batch 00625/00823] [00:07:38/00:02:25, 0.734s/it]: train_loss_raw=0.9800, running_loss=0.9556, LR=0.000100
[2025-08-26 13:05:31,776][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021208] [Batch 00633/00823] [00:07:44/00:02:19, 0.734s/it]: train_loss_raw=1.0674, running_loss=0.9578, LR=0.000100
[2025-08-26 13:05:37,526][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021216] [Batch 00641/00823] [00:07:50/00:02:13, 0.734s/it]: train_loss_raw=0.8938, running_loss=0.9559, LR=0.000100
[2025-08-26 13:05:43,310][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021224] [Batch 00649/00823] [00:07:56/00:02:07, 0.733s/it]: train_loss_raw=1.0364, running_loss=0.9554, LR=0.000100
[2025-08-26 13:05:49,109][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021232] [Batch 00657/00823] [00:08:01/00:02:01, 0.733s/it]: train_loss_raw=0.9686, running_loss=0.9543, LR=0.000100
[2025-08-26 13:05:54,853][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021240] [Batch 00665/00823] [00:08:07/00:01:55, 0.733s/it]: train_loss_raw=0.9983, running_loss=0.9576, LR=0.000100
[2025-08-26 13:06:00,920][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021248] [Batch 00673/00823] [00:08:13/00:01:50, 0.733s/it]: train_loss_raw=0.9380, running_loss=0.9561, LR=0.000100
[2025-08-26 13:06:06,995][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021256] [Batch 00681/00823] [00:08:19/00:01:44, 0.734s/it]: train_loss_raw=0.9603, running_loss=0.9582, LR=0.000100
[2025-08-26 13:06:12,900][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021264] [Batch 00689/00823] [00:08:25/00:01:38, 0.734s/it]: train_loss_raw=0.9010, running_loss=0.9574, LR=0.000100
[2025-08-26 13:06:18,904][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021272] [Batch 00697/00823] [00:08:31/00:01:32, 0.734s/it]: train_loss_raw=0.9522, running_loss=0.9564, LR=0.000100
[2025-08-26 13:06:24,795][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021280] [Batch 00705/00823] [00:08:37/00:01:26, 0.734s/it]: train_loss_raw=0.9242, running_loss=0.9565, LR=0.000100
[2025-08-26 13:06:30,610][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021288] [Batch 00713/00823] [00:08:43/00:01:20, 0.734s/it]: train_loss_raw=0.9822, running_loss=0.9568, LR=0.000100
[2025-08-26 13:06:36,358][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021296] [Batch 00721/00823] [00:08:49/00:01:14, 0.734s/it]: train_loss_raw=0.9770, running_loss=0.9561, LR=0.000100
[2025-08-26 13:06:42,184][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021304] [Batch 00729/00823] [00:08:54/00:01:08, 0.734s/it]: train_loss_raw=1.0230, running_loss=0.9565, LR=0.000100
[2025-08-26 13:06:47,965][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021312] [Batch 00737/00823] [00:09:00/00:01:03, 0.734s/it]: train_loss_raw=0.9361, running_loss=0.9592, LR=0.000100
[2025-08-26 13:06:53,797][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021320] [Batch 00745/00823] [00:09:06/00:00:57, 0.734s/it]: train_loss_raw=0.9682, running_loss=0.9578, LR=0.000100
[2025-08-26 13:06:59,667][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021328] [Batch 00753/00823] [00:09:12/00:00:51, 0.734s/it]: train_loss_raw=0.8594, running_loss=0.9550, LR=0.000100
[2025-08-26 13:07:05,631][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021336] [Batch 00761/00823] [00:09:18/00:00:45, 0.734s/it]: train_loss_raw=0.9505, running_loss=0.9570, LR=0.000100
[2025-08-26 13:07:11,476][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021344] [Batch 00769/00823] [00:09:24/00:00:39, 0.734s/it]: train_loss_raw=0.9889, running_loss=0.9589, LR=0.000100
[2025-08-26 13:07:17,277][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021352] [Batch 00777/00823] [00:09:29/00:00:33, 0.734s/it]: train_loss_raw=0.9496, running_loss=0.9600, LR=0.000100
[2025-08-26 13:07:23,019][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021360] [Batch 00785/00823] [00:09:35/00:00:27, 0.733s/it]: train_loss_raw=0.9645, running_loss=0.9602, LR=0.000100
[2025-08-26 13:07:28,763][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021368] [Batch 00793/00823] [00:09:41/00:00:21, 0.733s/it]: train_loss_raw=0.9025, running_loss=0.9584, LR=0.000100
[2025-08-26 13:07:34,548][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021376] [Batch 00801/00823] [00:09:47/00:00:16, 0.733s/it]: train_loss_raw=0.9202, running_loss=0.9566, LR=0.000100
[2025-08-26 13:07:40,509][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021384] [Batch 00809/00823] [00:09:53/00:00:10, 0.733s/it]: train_loss_raw=0.9215, running_loss=0.9582, LR=0.000100
[2025-08-26 13:07:46,600][__main__][INFO] - [TRAIN] [Epoch 25/29 Step 021392] [Batch 00817/00823] [00:09:59/00:00:04, 0.734s/it]: train_loss_raw=0.8674, running_loss=0.9544, LR=0.000100
[2025-08-26 13:07:56,921][__main__][INFO] - [VALIDATION] [Epoch 25/29] Starting validation.
[2025-08-26 13:08:07,945][__main__][INFO] - [VALIDATION] [Epoch 25/29 Step 021399] [Batch 00007/00013] [00:00:11/00:00:06, 1.378s/it]
[2025-08-26 13:08:14,913][__main__][INFO] - [VALIDATION] [Epoch 25/29] train_loss=0.95229, valid_loss=1.37938
[2025-08-26 13:08:14,914][__main__][INFO] - [VALIDATION] [Epoch 25/29] Metrics:
[2025-08-26 13:08:14,914][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_er      0.570
[2025-08-26 13:08:14,914][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_prec    0.085
[2025-08-26 13:08:14,914][__main__][INFO] - [VALIDATION] [Epoch 25/29] - aa_recall  0.088
[2025-08-26 13:08:14,914][__main__][INFO] - [VALIDATION] [Epoch 25/29] - pep_recall 0.042
[2025-08-26 13:08:14,917][__main__][INFO] - [TRAIN] [Epoch 25/29] Epoch complete, total time 04:35:38, remaining time 00:42:24, 00:10:36 per epoch
[2025-08-26 13:08:16,494][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021400] [Batch 00002/00823] [00:00:00/00:06:22, 0.465s/it]: train_loss_raw=0.8771, running_loss=0.8201, LR=0.000100
[2025-08-26 13:08:22,642][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021408] [Batch 00010/00823] [00:00:07/00:09:35, 0.708s/it]: train_loss_raw=0.8931, running_loss=0.8261, LR=0.000100
[2025-08-26 13:08:28,561][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021416] [Batch 00018/00823] [00:00:12/00:09:41, 0.722s/it]: train_loss_raw=0.8907, running_loss=0.8318, LR=0.000100
[2025-08-26 13:08:34,330][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021424] [Batch 00026/00823] [00:00:18/00:09:35, 0.722s/it]: train_loss_raw=0.9347, running_loss=0.8378, LR=0.000100
[2025-08-26 13:08:40,120][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021432] [Batch 00034/00823] [00:00:24/00:09:29, 0.722s/it]: train_loss_raw=0.9418, running_loss=0.8420, LR=0.000100
[2025-08-26 13:08:45,938][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021440] [Batch 00042/00823] [00:00:30/00:09:24, 0.723s/it]: train_loss_raw=0.9093, running_loss=0.8461, LR=0.000100
[2025-08-26 13:08:51,861][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021448] [Batch 00050/00823] [00:00:36/00:09:21, 0.726s/it]: train_loss_raw=0.8753, running_loss=0.8490, LR=0.000100
[2025-08-26 13:08:57,677][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021456] [Batch 00058/00823] [00:00:42/00:09:15, 0.726s/it]: train_loss_raw=0.8873, running_loss=0.8504, LR=0.000100
[2025-08-26 13:09:03,600][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021464] [Batch 00066/00823] [00:00:48/00:09:10, 0.728s/it]: train_loss_raw=0.9450, running_loss=0.8533, LR=0.000100
[2025-08-26 13:09:09,699][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021472] [Batch 00074/00823] [00:00:54/00:09:07, 0.732s/it]: train_loss_raw=0.9842, running_loss=0.8581, LR=0.000100
[2025-08-26 13:09:15,652][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021480] [Batch 00082/00823] [00:01:00/00:09:02, 0.733s/it]: train_loss_raw=0.8767, running_loss=0.8630, LR=0.000100
[2025-08-26 13:09:21,656][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021488] [Batch 00090/00823] [00:01:06/00:08:58, 0.734s/it]: train_loss_raw=0.8118, running_loss=0.8678, LR=0.000100
[2025-08-26 13:09:27,593][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021496] [Batch 00098/00823] [00:01:12/00:08:52, 0.735s/it]: train_loss_raw=0.8166, running_loss=0.8691, LR=0.000100
[2025-08-26 13:09:33,559][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021504] [Batch 00106/00823] [00:01:17/00:08:47, 0.736s/it]: train_loss_raw=0.8299, running_loss=0.8707, LR=0.000100
[2025-08-26 13:09:39,451][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021512] [Batch 00114/00823] [00:01:23/00:08:41, 0.736s/it]: train_loss_raw=0.7987, running_loss=0.8722, LR=0.000100
[2025-08-26 13:09:45,200][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021520] [Batch 00122/00823] [00:01:29/00:08:35, 0.735s/it]: train_loss_raw=0.9014, running_loss=0.8732, LR=0.000100
[2025-08-26 13:09:50,961][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021528] [Batch 00130/00823] [00:01:35/00:08:28, 0.734s/it]: train_loss_raw=0.9245, running_loss=0.8750, LR=0.000100
[2025-08-26 13:09:56,672][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021536] [Batch 00138/00823] [00:01:41/00:08:21, 0.733s/it]: train_loss_raw=0.9177, running_loss=0.8787, LR=0.000100
[2025-08-26 13:10:02,652][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021544] [Batch 00146/00823] [00:01:47/00:08:16, 0.733s/it]: train_loss_raw=0.8324, running_loss=0.8769, LR=0.000100
[2025-08-26 13:10:08,573][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021552] [Batch 00154/00823] [00:01:53/00:08:10, 0.734s/it]: train_loss_raw=0.9060, running_loss=0.8784, LR=0.000100
[2025-08-26 13:10:14,422][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021560] [Batch 00162/00823] [00:01:58/00:08:04, 0.734s/it]: train_loss_raw=0.8374, running_loss=0.8790, LR=0.000100
[2025-08-26 13:10:20,521][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021568] [Batch 00170/00823] [00:02:04/00:07:59, 0.735s/it]: train_loss_raw=0.8927, running_loss=0.8798, LR=0.000100
[2025-08-26 13:10:26,433][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021576] [Batch 00178/00823] [00:02:10/00:07:54, 0.735s/it]: train_loss_raw=0.9131, running_loss=0.8825, LR=0.000100
[2025-08-26 13:10:32,313][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021584] [Batch 00186/00823] [00:02:16/00:07:48, 0.735s/it]: train_loss_raw=0.9450, running_loss=0.8855, LR=0.000100
[2025-08-26 13:10:38,222][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021592] [Batch 00194/00823] [00:02:22/00:07:42, 0.735s/it]: train_loss_raw=0.8905, running_loss=0.8869, LR=0.000100
[2025-08-26 13:10:44,018][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021600] [Batch 00202/00823] [00:02:28/00:07:36, 0.735s/it]: train_loss_raw=0.8762, running_loss=0.8862, LR=0.000100
[2025-08-26 13:10:49,969][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021608] [Batch 00210/00823] [00:02:34/00:07:30, 0.735s/it]: train_loss_raw=0.8692, running_loss=0.8856, LR=0.000100
[2025-08-26 13:10:55,688][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021616] [Batch 00218/00823] [00:02:40/00:07:24, 0.735s/it]: train_loss_raw=0.8992, running_loss=0.8883, LR=0.000100
[2025-08-26 13:11:01,507][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021624] [Batch 00226/00823] [00:02:45/00:07:18, 0.734s/it]: train_loss_raw=0.9213, running_loss=0.8902, LR=0.000100
[2025-08-26 13:11:07,398][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021632] [Batch 00234/00823] [00:02:51/00:07:12, 0.734s/it]: train_loss_raw=0.8899, running_loss=0.8894, LR=0.000100
[2025-08-26 13:11:12,985][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021640] [Batch 00242/00823] [00:02:57/00:07:05, 0.733s/it]: train_loss_raw=0.8918, running_loss=0.8878, LR=0.000100
[2025-08-26 13:11:18,884][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021648] [Batch 00250/00823] [00:03:03/00:07:00, 0.733s/it]: train_loss_raw=0.9205, running_loss=0.8911, LR=0.000100
[2025-08-26 13:11:24,829][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021656] [Batch 00258/00823] [00:03:09/00:06:54, 0.734s/it]: train_loss_raw=0.9268, running_loss=0.8919, LR=0.000100
[2025-08-26 13:11:30,613][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021664] [Batch 00266/00823] [00:03:15/00:06:48, 0.733s/it]: train_loss_raw=0.8683, running_loss=0.8916, LR=0.000100
[2025-08-26 13:11:36,358][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021672] [Batch 00274/00823] [00:03:20/00:06:42, 0.733s/it]: train_loss_raw=0.9870, running_loss=0.8947, LR=0.000100
[2025-08-26 13:11:42,314][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021680] [Batch 00282/00823] [00:03:26/00:06:36, 0.733s/it]: train_loss_raw=0.8712, running_loss=0.8929, LR=0.000100
[2025-08-26 13:11:48,166][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021688] [Batch 00290/00823] [00:03:32/00:06:30, 0.733s/it]: train_loss_raw=0.8087, running_loss=0.8916, LR=0.000100
[2025-08-26 13:11:54,214][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021696] [Batch 00298/00823] [00:03:38/00:06:25, 0.734s/it]: train_loss_raw=0.8935, running_loss=0.8912, LR=0.000100
[2025-08-26 13:12:00,069][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021704] [Batch 00306/00823] [00:03:44/00:06:19, 0.734s/it]: train_loss_raw=0.9859, running_loss=0.8920, LR=0.000100
[2025-08-26 13:12:05,851][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021712] [Batch 00314/00823] [00:03:50/00:06:13, 0.733s/it]: train_loss_raw=0.8269, running_loss=0.8912, LR=0.000100
[2025-08-26 13:12:11,564][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021720] [Batch 00322/00823] [00:03:56/00:06:07, 0.733s/it]: train_loss_raw=1.0074, running_loss=0.8932, LR=0.000100
[2025-08-26 13:12:17,498][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021728] [Batch 00330/00823] [00:04:01/00:06:01, 0.733s/it]: train_loss_raw=0.9798, running_loss=0.8948, LR=0.000100
[2025-08-26 13:12:23,417][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021736] [Batch 00338/00823] [00:04:07/00:05:55, 0.733s/it]: train_loss_raw=0.9261, running_loss=0.8952, LR=0.000100
[2025-08-26 13:12:29,376][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021744] [Batch 00346/00823] [00:04:13/00:05:49, 0.734s/it]: train_loss_raw=0.9853, running_loss=0.8968, LR=0.000100
[2025-08-26 13:12:35,245][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021752] [Batch 00354/00823] [00:04:19/00:05:44, 0.734s/it]: train_loss_raw=0.7776, running_loss=0.8963, LR=0.000100
[2025-08-26 13:12:41,181][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021760] [Batch 00362/00823] [00:04:25/00:05:38, 0.734s/it]: train_loss_raw=0.8156, running_loss=0.8956, LR=0.000100
[2025-08-26 13:12:47,061][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021768] [Batch 00370/00823] [00:04:31/00:05:32, 0.734s/it]: train_loss_raw=0.9391, running_loss=0.8968, LR=0.000100
[2025-08-26 13:12:53,154][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021776] [Batch 00378/00823] [00:04:37/00:05:26, 0.734s/it]: train_loss_raw=0.9544, running_loss=0.8968, LR=0.000100
[2025-08-26 13:12:58,899][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021784] [Batch 00386/00823] [00:04:43/00:05:20, 0.734s/it]: train_loss_raw=0.8829, running_loss=0.8957, LR=0.000100
[2025-08-26 13:13:04,662][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021792] [Batch 00394/00823] [00:04:49/00:05:14, 0.734s/it]: train_loss_raw=0.9118, running_loss=0.8965, LR=0.000100
[2025-08-26 13:13:10,609][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021800] [Batch 00402/00823] [00:04:55/00:05:08, 0.734s/it]: train_loss_raw=0.8967, running_loss=0.8950, LR=0.000100
[2025-08-26 13:13:16,445][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021808] [Batch 00410/00823] [00:05:00/00:05:03, 0.734s/it]: train_loss_raw=0.8957, running_loss=0.8959, LR=0.000100
[2025-08-26 13:13:22,297][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021816] [Batch 00418/00823] [00:05:06/00:04:57, 0.734s/it]: train_loss_raw=0.9761, running_loss=0.8955, LR=0.000100
[2025-08-26 13:13:27,965][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021824] [Batch 00426/00823] [00:05:12/00:04:51, 0.733s/it]: train_loss_raw=1.0002, running_loss=0.8971, LR=0.000100
[2025-08-26 13:13:33,763][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021832] [Batch 00434/00823] [00:05:18/00:04:45, 0.733s/it]: train_loss_raw=0.9148, running_loss=0.8966, LR=0.000100
[2025-08-26 13:13:39,803][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021840] [Batch 00442/00823] [00:05:24/00:04:39, 0.734s/it]: train_loss_raw=0.8639, running_loss=0.8959, LR=0.000100
[2025-08-26 13:13:45,771][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021848] [Batch 00450/00823] [00:05:30/00:04:33, 0.734s/it]: train_loss_raw=0.9390, running_loss=0.8980, LR=0.000100
[2025-08-26 13:13:51,544][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021856] [Batch 00458/00823] [00:05:35/00:04:27, 0.734s/it]: train_loss_raw=0.8655, running_loss=0.8975, LR=0.000100
[2025-08-26 13:13:57,240][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021864] [Batch 00466/00823] [00:05:41/00:04:21, 0.733s/it]: train_loss_raw=0.9379, running_loss=0.8979, LR=0.000100
[2025-08-26 13:14:03,082][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021872] [Batch 00474/00823] [00:05:47/00:04:15, 0.733s/it]: train_loss_raw=0.8599, running_loss=0.8972, LR=0.000100
[2025-08-26 13:14:08,828][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021880] [Batch 00482/00823] [00:05:53/00:04:09, 0.733s/it]: train_loss_raw=0.9485, running_loss=0.9006, LR=0.000100
[2025-08-26 13:14:14,597][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021888] [Batch 00490/00823] [00:05:59/00:04:03, 0.733s/it]: train_loss_raw=0.8582, running_loss=0.9001, LR=0.000100
[2025-08-26 13:14:20,289][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021896] [Batch 00498/00823] [00:06:04/00:03:58, 0.732s/it]: train_loss_raw=0.9001, running_loss=0.8991, LR=0.000100
[2025-08-26 13:14:26,216][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021904] [Batch 00506/00823] [00:06:10/00:03:52, 0.733s/it]: train_loss_raw=0.9001, running_loss=0.9019, LR=0.000100
[2025-08-26 13:14:32,079][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021912] [Batch 00514/00823] [00:06:16/00:03:46, 0.733s/it]: train_loss_raw=0.8193, running_loss=0.9002, LR=0.000100
[2025-08-26 13:14:38,346][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021920] [Batch 00522/00823] [00:06:22/00:03:40, 0.733s/it]: train_loss_raw=0.8331, running_loss=0.8989, LR=0.000100
[2025-08-26 13:14:44,370][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021928] [Batch 00530/00823] [00:06:28/00:03:34, 0.734s/it]: train_loss_raw=0.8795, running_loss=0.8987, LR=0.000100
[2025-08-26 13:14:50,571][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021936] [Batch 00538/00823] [00:06:35/00:03:29, 0.734s/it]: train_loss_raw=0.9488, running_loss=0.8965, LR=0.000100
[2025-08-26 13:14:56,640][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021944] [Batch 00546/00823] [00:06:41/00:03:23, 0.735s/it]: train_loss_raw=0.9154, running_loss=0.8976, LR=0.000100
[2025-08-26 13:15:02,656][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021952] [Batch 00554/00823] [00:06:47/00:03:17, 0.735s/it]: train_loss_raw=0.7946, running_loss=0.8946, LR=0.000100
[2025-08-26 13:15:08,703][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021960] [Batch 00562/00823] [00:06:53/00:03:11, 0.735s/it]: train_loss_raw=0.8069, running_loss=0.8951, LR=0.000100
[2025-08-26 13:15:14,695][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021968] [Batch 00570/00823] [00:06:59/00:03:06, 0.735s/it]: train_loss_raw=1.0407, running_loss=0.8999, LR=0.000100
[2025-08-26 13:15:20,763][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021976] [Batch 00578/00823] [00:07:05/00:03:00, 0.736s/it]: train_loss_raw=0.8095, running_loss=0.8998, LR=0.000100
[2025-08-26 13:15:26,855][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021984] [Batch 00586/00823] [00:07:11/00:02:54, 0.736s/it]: train_loss_raw=0.9702, running_loss=0.9007, LR=0.000100
[2025-08-26 13:15:32,890][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 021992] [Batch 00594/00823] [00:07:17/00:02:48, 0.736s/it]: train_loss_raw=0.9176, running_loss=0.8982, LR=0.000100
[2025-08-26 13:15:38,923][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022000] [Batch 00602/00823] [00:07:23/00:02:42, 0.736s/it]: train_loss_raw=0.8287, running_loss=0.8965, LR=0.000100
[2025-08-26 13:15:49,187][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022008] [Batch 00610/00823] [00:07:33/00:02:38, 0.744s/it]: train_loss_raw=0.8899, running_loss=0.8976, LR=0.000100
[2025-08-26 13:15:55,059][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022016] [Batch 00618/00823] [00:07:39/00:02:32, 0.744s/it]: train_loss_raw=0.8436, running_loss=0.8989, LR=0.000100
[2025-08-26 13:16:00,957][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022024] [Batch 00626/00823] [00:07:45/00:02:26, 0.743s/it]: train_loss_raw=0.9030, running_loss=0.8980, LR=0.000100
[2025-08-26 13:16:06,821][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022032] [Batch 00634/00823] [00:07:51/00:02:20, 0.743s/it]: train_loss_raw=0.8105, running_loss=0.8974, LR=0.000100
[2025-08-26 13:16:12,655][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022040] [Batch 00642/00823] [00:07:57/00:02:14, 0.743s/it]: train_loss_raw=0.8029, running_loss=0.8986, LR=0.000100
[2025-08-26 13:16:18,446][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022048] [Batch 00650/00823] [00:08:02/00:02:08, 0.743s/it]: train_loss_raw=0.9078, running_loss=0.8973, LR=0.000100
[2025-08-26 13:16:24,277][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022056] [Batch 00658/00823] [00:08:08/00:02:02, 0.743s/it]: train_loss_raw=0.8535, running_loss=0.8981, LR=0.000100
[2025-08-26 13:16:30,300][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022064] [Batch 00666/00823] [00:08:14/00:01:56, 0.743s/it]: train_loss_raw=0.8766, running_loss=0.8996, LR=0.000100
[2025-08-26 13:16:36,217][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022072] [Batch 00674/00823] [00:08:20/00:01:50, 0.743s/it]: train_loss_raw=0.9344, running_loss=0.9010, LR=0.000100
[2025-08-26 13:16:41,855][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022080] [Batch 00682/00823] [00:08:26/00:01:44, 0.742s/it]: train_loss_raw=0.8974, running_loss=0.9025, LR=0.000100
[2025-08-26 13:16:47,766][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022088] [Batch 00690/00823] [00:08:32/00:01:38, 0.742s/it]: train_loss_raw=0.9563, running_loss=0.9040, LR=0.000100
[2025-08-26 13:16:53,647][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022096] [Batch 00698/00823] [00:08:38/00:01:32, 0.742s/it]: train_loss_raw=0.8518, running_loss=0.9048, LR=0.000100
[2025-08-26 13:16:59,478][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022104] [Batch 00706/00823] [00:08:43/00:01:26, 0.742s/it]: train_loss_raw=0.9254, running_loss=0.9051, LR=0.000100
[2025-08-26 13:17:05,282][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022112] [Batch 00714/00823] [00:08:49/00:01:20, 0.742s/it]: train_loss_raw=0.9139, running_loss=0.9049, LR=0.000100
[2025-08-26 13:17:11,031][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022120] [Batch 00722/00823] [00:08:55/00:01:14, 0.742s/it]: train_loss_raw=0.8508, running_loss=0.9040, LR=0.000100
[2025-08-26 13:17:16,785][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022128] [Batch 00730/00823] [00:09:01/00:01:08, 0.741s/it]: train_loss_raw=0.8941, running_loss=0.9047, LR=0.000100
[2025-08-26 13:17:22,567][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022136] [Batch 00738/00823] [00:09:07/00:01:03, 0.741s/it]: train_loss_raw=0.8663, running_loss=0.9036, LR=0.000100
[2025-08-26 13:17:28,543][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022144] [Batch 00746/00823] [00:09:12/00:00:57, 0.741s/it]: train_loss_raw=0.9122, running_loss=0.9019, LR=0.000100
[2025-08-26 13:17:34,412][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022152] [Batch 00754/00823] [00:09:18/00:00:51, 0.741s/it]: train_loss_raw=1.0151, running_loss=0.9031, LR=0.000100
[2025-08-26 13:17:40,272][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022160] [Batch 00762/00823] [00:09:24/00:00:45, 0.741s/it]: train_loss_raw=0.8844, running_loss=0.9038, LR=0.000100
[2025-08-26 13:17:46,468][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022168] [Batch 00770/00823] [00:09:30/00:00:39, 0.741s/it]: train_loss_raw=0.7712, running_loss=0.9022, LR=0.000100
[2025-08-26 13:17:52,378][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022176] [Batch 00778/00823] [00:09:36/00:00:33, 0.741s/it]: train_loss_raw=0.8644, running_loss=0.9021, LR=0.000100
[2025-08-26 13:17:58,311][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022184] [Batch 00786/00823] [00:09:42/00:00:27, 0.741s/it]: train_loss_raw=0.9708, running_loss=0.9036, LR=0.000100
[2025-08-26 13:18:04,074][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022192] [Batch 00794/00823] [00:09:48/00:00:21, 0.741s/it]: train_loss_raw=0.9373, running_loss=0.9039, LR=0.000100
[2025-08-26 13:18:09,701][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022200] [Batch 00802/00823] [00:09:54/00:00:15, 0.741s/it]: train_loss_raw=0.9465, running_loss=0.9039, LR=0.000100
[2025-08-26 13:18:15,485][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022208] [Batch 00810/00823] [00:09:59/00:00:09, 0.741s/it]: train_loss_raw=0.9703, running_loss=0.9041, LR=0.000100
[2025-08-26 13:18:21,442][__main__][INFO] - [TRAIN] [Epoch 26/29 Step 022216] [Batch 00818/00823] [00:10:05/00:00:03, 0.741s/it]: train_loss_raw=0.9287, running_loss=0.9050, LR=0.000100
[2025-08-26 13:18:25,319][__main__][INFO] - [VALIDATION] [Epoch 26/29] Starting validation.
[2025-08-26 13:18:35,991][__main__][INFO] - [VALIDATION] [Epoch 26/29 Step 022222] [Batch 00007/00013] [00:00:10/00:00:06, 1.334s/it]
[2025-08-26 13:18:43,073][__main__][INFO] - [VALIDATION] [Epoch 26/29] train_loss=0.90423, valid_loss=1.40188
[2025-08-26 13:18:43,073][__main__][INFO] - [VALIDATION] [Epoch 26/29] Metrics:
[2025-08-26 13:18:43,074][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_er      0.555
[2025-08-26 13:18:43,074][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_prec    0.085
[2025-08-26 13:18:43,074][__main__][INFO] - [VALIDATION] [Epoch 26/29] - aa_recall  0.087
[2025-08-26 13:18:43,074][__main__][INFO] - [VALIDATION] [Epoch 26/29] - pep_recall 0.037
[2025-08-26 13:18:43,076][__main__][INFO] - [TRAIN] [Epoch 26/29] Epoch complete, total time 04:46:06, remaining time 00:31:47, 00:10:35 per epoch
[2025-08-26 13:18:45,751][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022224] [Batch 00003/00823] [00:00:01/00:07:28, 0.547s/it]: train_loss_raw=0.8291, running_loss=0.9300, LR=0.000100
[2025-08-26 13:18:51,731][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022232] [Batch 00011/00823] [00:00:07/00:09:22, 0.693s/it]: train_loss_raw=0.8523, running_loss=0.9294, LR=0.000100
[2025-08-26 13:18:57,711][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022240] [Batch 00019/00823] [00:00:13/00:09:35, 0.716s/it]: train_loss_raw=0.7691, running_loss=0.9288, LR=0.000100
[2025-08-26 13:19:03,778][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022248] [Batch 00027/00823] [00:00:19/00:09:39, 0.728s/it]: train_loss_raw=1.0172, running_loss=0.9272, LR=0.000100
[2025-08-26 13:19:09,613][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022256] [Batch 00035/00823] [00:00:25/00:09:34, 0.729s/it]: train_loss_raw=0.9224, running_loss=0.9259, LR=0.000100
[2025-08-26 13:19:15,435][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022264] [Batch 00043/00823] [00:00:31/00:09:28, 0.728s/it]: train_loss_raw=0.9334, running_loss=0.9232, LR=0.000100
[2025-08-26 13:19:21,374][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022272] [Batch 00051/00823] [00:00:37/00:09:24, 0.731s/it]: train_loss_raw=0.8993, running_loss=0.9200, LR=0.000100
[2025-08-26 13:19:27,103][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022280] [Batch 00059/00823] [00:00:42/00:09:16, 0.729s/it]: train_loss_raw=0.9584, running_loss=0.9187, LR=0.000100
[2025-08-26 13:19:33,002][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022288] [Batch 00067/00823] [00:00:48/00:09:11, 0.730s/it]: train_loss_raw=0.9265, running_loss=0.9195, LR=0.000100
[2025-08-26 13:19:38,828][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022296] [Batch 00075/00823] [00:00:54/00:09:05, 0.730s/it]: train_loss_raw=0.9274, running_loss=0.9185, LR=0.000100
[2025-08-26 13:19:44,699][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022304] [Batch 00083/00823] [00:01:00/00:09:00, 0.730s/it]: train_loss_raw=0.9423, running_loss=0.9147, LR=0.000100
[2025-08-26 13:19:50,605][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022312] [Batch 00091/00823] [00:01:06/00:08:54, 0.731s/it]: train_loss_raw=0.9929, running_loss=0.9174, LR=0.000100
[2025-08-26 13:19:56,455][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022320] [Batch 00099/00823] [00:01:12/00:08:49, 0.731s/it]: train_loss_raw=0.9481, running_loss=0.9189, LR=0.000100
[2025-08-26 13:20:02,269][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022328] [Batch 00107/00823] [00:01:18/00:08:43, 0.730s/it]: train_loss_raw=0.9835, running_loss=0.9158, LR=0.000100
[2025-08-26 13:20:08,062][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022336] [Batch 00115/00823] [00:01:23/00:08:36, 0.730s/it]: train_loss_raw=0.9547, running_loss=0.9132, LR=0.000100
[2025-08-26 13:20:13,893][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022344] [Batch 00123/00823] [00:01:29/00:08:30, 0.730s/it]: train_loss_raw=0.8645, running_loss=0.9129, LR=0.000100
[2025-08-26 13:20:19,729][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022352] [Batch 00131/00823] [00:01:35/00:08:25, 0.730s/it]: train_loss_raw=0.9689, running_loss=0.9114, LR=0.000100
[2025-08-26 13:20:25,379][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022360] [Batch 00139/00823] [00:01:41/00:08:18, 0.729s/it]: train_loss_raw=0.9751, running_loss=0.9111, LR=0.000100
[2025-08-26 13:20:31,236][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022368] [Batch 00147/00823] [00:01:47/00:08:12, 0.729s/it]: train_loss_raw=0.8815, running_loss=0.9083, LR=0.000100
[2025-08-26 13:20:37,348][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022376] [Batch 00155/00823] [00:01:53/00:08:08, 0.731s/it]: train_loss_raw=0.8917, running_loss=0.9093, LR=0.000100
[2025-08-26 13:20:43,294][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022384] [Batch 00163/00823] [00:01:59/00:08:02, 0.731s/it]: train_loss_raw=0.8050, running_loss=0.9064, LR=0.000100
[2025-08-26 13:20:49,241][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022392] [Batch 00171/00823] [00:02:05/00:07:57, 0.732s/it]: train_loss_raw=0.8933, running_loss=0.9057, LR=0.000100
[2025-08-26 13:20:55,054][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022400] [Batch 00179/00823] [00:02:10/00:07:51, 0.732s/it]: train_loss_raw=0.8543, running_loss=0.9059, LR=0.000100
[2025-08-26 13:21:00,744][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022408] [Batch 00187/00823] [00:02:16/00:07:44, 0.731s/it]: train_loss_raw=0.8824, running_loss=0.9059, LR=0.000100
[2025-08-26 13:21:06,463][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022416] [Batch 00195/00823] [00:02:22/00:07:38, 0.730s/it]: train_loss_raw=0.8484, running_loss=0.9067, LR=0.000100
[2025-08-26 13:21:12,316][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022424] [Batch 00203/00823] [00:02:28/00:07:32, 0.730s/it]: train_loss_raw=0.8888, running_loss=0.9055, LR=0.000100
[2025-08-26 13:21:18,258][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022432] [Batch 00211/00823] [00:02:34/00:07:27, 0.731s/it]: train_loss_raw=0.8353, running_loss=0.9054, LR=0.000100
[2025-08-26 13:21:24,074][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022440] [Batch 00219/00823] [00:02:39/00:07:21, 0.730s/it]: train_loss_raw=1.0406, running_loss=0.9063, LR=0.000100
[2025-08-26 13:21:29,844][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022448] [Batch 00227/00823] [00:02:45/00:07:15, 0.730s/it]: train_loss_raw=0.9176, running_loss=0.9072, LR=0.000100
[2025-08-26 13:21:35,679][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022456] [Batch 00235/00823] [00:02:51/00:07:09, 0.730s/it]: train_loss_raw=0.9271, running_loss=0.9087, LR=0.000100
[2025-08-26 13:21:41,691][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022464] [Batch 00243/00823] [00:02:57/00:07:03, 0.731s/it]: train_loss_raw=0.8557, running_loss=0.9083, LR=0.000100
[2025-08-26 13:21:47,554][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022472] [Batch 00251/00823] [00:03:03/00:06:58, 0.731s/it]: train_loss_raw=0.9777, running_loss=0.9071, LR=0.000100
[2025-08-26 13:21:53,368][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022480] [Batch 00259/00823] [00:03:09/00:06:52, 0.731s/it]: train_loss_raw=1.0040, running_loss=0.9095, LR=0.000100
[2025-08-26 13:21:59,123][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022488] [Batch 00267/00823] [00:03:15/00:06:46, 0.730s/it]: train_loss_raw=0.8610, running_loss=0.9085, LR=0.000100
[2025-08-26 13:22:04,872][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022496] [Batch 00275/00823] [00:03:20/00:06:40, 0.730s/it]: train_loss_raw=0.9983, running_loss=0.9068, LR=0.000100
[2025-08-26 13:22:10,789][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022504] [Batch 00283/00823] [00:03:26/00:06:34, 0.730s/it]: train_loss_raw=0.9329, running_loss=0.9070, LR=0.000100
[2025-08-26 13:22:16,779][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022512] [Batch 00291/00823] [00:03:32/00:06:28, 0.731s/it]: train_loss_raw=0.9091, running_loss=0.9054, LR=0.000100
[2025-08-26 13:22:22,609][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022520] [Batch 00299/00823] [00:03:38/00:06:22, 0.731s/it]: train_loss_raw=0.8025, running_loss=0.9039, LR=0.000100
[2025-08-26 13:22:28,367][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022528] [Batch 00307/00823] [00:03:44/00:06:16, 0.730s/it]: train_loss_raw=0.8928, running_loss=0.9057, LR=0.000100
[2025-08-26 13:22:34,129][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022536] [Batch 00315/00823] [00:03:50/00:06:10, 0.730s/it]: train_loss_raw=0.8878, running_loss=0.9050, LR=0.000100
[2025-08-26 13:22:39,968][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022544] [Batch 00323/00823] [00:03:55/00:06:05, 0.730s/it]: train_loss_raw=0.9129, running_loss=0.9054, LR=0.000100
[2025-08-26 13:22:45,815][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022552] [Batch 00331/00823] [00:04:01/00:05:59, 0.730s/it]: train_loss_raw=0.9681, running_loss=0.9036, LR=0.000100
[2025-08-26 13:22:51,742][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022560] [Batch 00339/00823] [00:04:07/00:05:53, 0.730s/it]: train_loss_raw=0.9438, running_loss=0.9040, LR=0.000100
[2025-08-26 13:22:57,489][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022568] [Batch 00347/00823] [00:04:13/00:05:47, 0.730s/it]: train_loss_raw=0.9933, running_loss=0.9034, LR=0.000100
[2025-08-26 13:23:03,012][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022576] [Batch 00355/00823] [00:04:18/00:05:41, 0.729s/it]: train_loss_raw=0.9634, running_loss=0.9026, LR=0.000100
[2025-08-26 13:23:08,683][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022584] [Batch 00363/00823] [00:04:24/00:05:35, 0.729s/it]: train_loss_raw=0.8473, running_loss=0.9051, LR=0.000100
[2025-08-26 13:23:14,330][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022592] [Batch 00371/00823] [00:04:30/00:05:29, 0.728s/it]: train_loss_raw=0.8721, running_loss=0.9057, LR=0.000100
[2025-08-26 13:23:20,075][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022600] [Batch 00379/00823] [00:04:35/00:05:23, 0.728s/it]: train_loss_raw=0.8631, running_loss=0.9045, LR=0.000100
[2025-08-26 13:23:25,668][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022608] [Batch 00387/00823] [00:04:41/00:05:17, 0.728s/it]: train_loss_raw=0.9098, running_loss=0.9066, LR=0.000100
[2025-08-26 13:23:31,409][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022616] [Batch 00395/00823] [00:04:47/00:05:11, 0.727s/it]: train_loss_raw=0.8673, running_loss=0.9072, LR=0.000100
[2025-08-26 13:23:37,093][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022624] [Batch 00403/00823] [00:04:52/00:05:05, 0.727s/it]: train_loss_raw=0.9278, running_loss=0.9083, LR=0.000100
[2025-08-26 13:23:42,751][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022632] [Batch 00411/00823] [00:04:58/00:04:59, 0.727s/it]: train_loss_raw=0.8648, running_loss=0.9063, LR=0.000100
[2025-08-26 13:23:48,337][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022640] [Batch 00419/00823] [00:05:04/00:04:53, 0.726s/it]: train_loss_raw=0.9694, running_loss=0.9077, LR=0.000100
[2025-08-26 13:23:54,015][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022648] [Batch 00427/00823] [00:05:09/00:04:47, 0.726s/it]: train_loss_raw=0.9082, running_loss=0.9079, LR=0.000100
[2025-08-26 13:23:59,975][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022656] [Batch 00435/00823] [00:05:15/00:04:41, 0.726s/it]: train_loss_raw=0.9537, running_loss=0.9099, LR=0.000100
[2025-08-26 13:24:05,717][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022664] [Batch 00443/00823] [00:05:21/00:04:35, 0.726s/it]: train_loss_raw=0.9910, running_loss=0.9067, LR=0.000100
[2025-08-26 13:24:11,575][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022672] [Batch 00451/00823] [00:05:27/00:04:30, 0.726s/it]: train_loss_raw=0.9775, running_loss=0.9075, LR=0.000100
[2025-08-26 13:24:17,290][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022680] [Batch 00459/00823] [00:05:33/00:04:24, 0.726s/it]: train_loss_raw=0.9423, running_loss=0.9094, LR=0.000100
[2025-08-26 13:24:23,145][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022688] [Batch 00467/00823] [00:05:39/00:04:18, 0.726s/it]: train_loss_raw=0.9787, running_loss=0.9130, LR=0.000100
[2025-08-26 13:24:28,943][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022696] [Batch 00475/00823] [00:05:44/00:04:12, 0.726s/it]: train_loss_raw=0.8560, running_loss=0.9117, LR=0.000100
[2025-08-26 13:24:34,673][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022704] [Batch 00483/00823] [00:05:50/00:04:06, 0.726s/it]: train_loss_raw=0.8431, running_loss=0.9085, LR=0.000100
[2025-08-26 13:24:40,537][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022712] [Batch 00491/00823] [00:05:56/00:04:01, 0.726s/it]: train_loss_raw=0.8435, running_loss=0.9073, LR=0.000100
[2025-08-26 13:24:46,237][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022720] [Batch 00499/00823] [00:06:02/00:03:55, 0.726s/it]: train_loss_raw=0.9124, running_loss=0.9049, LR=0.000100
[2025-08-26 13:24:52,075][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022728] [Batch 00507/00823] [00:06:07/00:03:49, 0.726s/it]: train_loss_raw=0.9060, running_loss=0.9012, LR=0.000100
[2025-08-26 13:24:57,996][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022736] [Batch 00515/00823] [00:06:13/00:03:43, 0.726s/it]: train_loss_raw=0.8730, running_loss=0.9020, LR=0.000100
[2025-08-26 13:25:03,745][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022744] [Batch 00523/00823] [00:06:19/00:03:37, 0.726s/it]: train_loss_raw=0.8676, running_loss=0.8975, LR=0.000100
[2025-08-26 13:25:09,610][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022752] [Batch 00531/00823] [00:06:25/00:03:31, 0.726s/it]: train_loss_raw=0.8162, running_loss=0.8955, LR=0.000100
[2025-08-26 13:25:15,431][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022760] [Batch 00539/00823] [00:06:31/00:03:26, 0.726s/it]: train_loss_raw=0.8936, running_loss=0.8936, LR=0.000100
[2025-08-26 13:25:21,386][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022768] [Batch 00547/00823] [00:06:37/00:03:20, 0.726s/it]: train_loss_raw=0.9802, running_loss=0.8965, LR=0.000100
[2025-08-26 13:25:27,102][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022776] [Batch 00555/00823] [00:06:42/00:03:14, 0.726s/it]: train_loss_raw=0.8763, running_loss=0.8967, LR=0.000100
[2025-08-26 13:25:32,833][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022784] [Batch 00563/00823] [00:06:48/00:03:08, 0.726s/it]: train_loss_raw=0.8709, running_loss=0.8955, LR=0.000100
[2025-08-26 13:25:38,566][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022792] [Batch 00571/00823] [00:06:54/00:03:02, 0.726s/it]: train_loss_raw=0.8562, running_loss=0.8948, LR=0.000100
[2025-08-26 13:25:44,396][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022800] [Batch 00579/00823] [00:07:00/00:02:57, 0.726s/it]: train_loss_raw=0.9804, running_loss=0.8952, LR=0.000100
[2025-08-26 13:25:50,258][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022808] [Batch 00587/00823] [00:07:06/00:02:51, 0.726s/it]: train_loss_raw=0.8433, running_loss=0.8943, LR=0.000100
[2025-08-26 13:25:56,039][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022816] [Batch 00595/00823] [00:07:11/00:02:45, 0.726s/it]: train_loss_raw=0.8268, running_loss=0.8939, LR=0.000100
[2025-08-26 13:26:01,963][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022824] [Batch 00603/00823] [00:07:17/00:02:39, 0.726s/it]: train_loss_raw=0.9033, running_loss=0.8965, LR=0.000100
[2025-08-26 13:26:07,923][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022832] [Batch 00611/00823] [00:07:23/00:02:33, 0.726s/it]: train_loss_raw=0.8628, running_loss=0.8958, LR=0.000100
[2025-08-26 13:26:13,919][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022840] [Batch 00619/00823] [00:07:29/00:02:28, 0.727s/it]: train_loss_raw=0.8540, running_loss=0.8940, LR=0.000100
[2025-08-26 13:26:19,704][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022848] [Batch 00627/00823] [00:07:35/00:02:22, 0.727s/it]: train_loss_raw=0.9252, running_loss=0.8935, LR=0.000100
[2025-08-26 13:26:25,591][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022856] [Batch 00635/00823] [00:07:41/00:02:16, 0.727s/it]: train_loss_raw=0.9386, running_loss=0.8973, LR=0.000100
[2025-08-26 13:26:31,407][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022864] [Batch 00643/00823] [00:07:47/00:02:10, 0.727s/it]: train_loss_raw=0.8903, running_loss=0.8970, LR=0.000100
[2025-08-26 13:26:36,978][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022872] [Batch 00651/00823] [00:07:52/00:02:04, 0.726s/it]: train_loss_raw=0.9071, running_loss=0.8963, LR=0.000100
[2025-08-26 13:26:42,806][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022880] [Batch 00659/00823] [00:07:58/00:01:59, 0.726s/it]: train_loss_raw=0.8839, running_loss=0.8943, LR=0.000100
[2025-08-26 13:26:48,831][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022888] [Batch 00667/00823] [00:08:04/00:01:53, 0.727s/it]: train_loss_raw=1.0352, running_loss=0.8947, LR=0.000100
[2025-08-26 13:26:54,532][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022896] [Batch 00675/00823] [00:08:10/00:01:47, 0.727s/it]: train_loss_raw=0.8662, running_loss=0.8913, LR=0.000100
[2025-08-26 13:27:00,468][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022904] [Batch 00683/00823] [00:08:16/00:01:41, 0.727s/it]: train_loss_raw=0.8910, running_loss=0.8920, LR=0.000100
[2025-08-26 13:27:06,455][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022912] [Batch 00691/00823] [00:08:22/00:01:35, 0.727s/it]: train_loss_raw=0.8440, running_loss=0.8918, LR=0.000100
[2025-08-26 13:27:12,232][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022920] [Batch 00699/00823] [00:08:28/00:01:30, 0.727s/it]: train_loss_raw=0.8499, running_loss=0.8910, LR=0.000100
[2025-08-26 13:27:18,055][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022928] [Batch 00707/00823] [00:08:33/00:01:24, 0.727s/it]: train_loss_raw=0.9540, running_loss=0.8913, LR=0.000100
[2025-08-26 13:27:23,915][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022936] [Batch 00715/00823] [00:08:39/00:01:18, 0.727s/it]: train_loss_raw=0.8743, running_loss=0.8925, LR=0.000100
[2025-08-26 13:27:29,865][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022944] [Batch 00723/00823] [00:08:45/00:01:12, 0.727s/it]: train_loss_raw=0.8771, running_loss=0.8925, LR=0.000100
[2025-08-26 13:27:35,757][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022952] [Batch 00731/00823] [00:08:51/00:01:06, 0.727s/it]: train_loss_raw=0.8795, running_loss=0.8938, LR=0.000100
[2025-08-26 13:27:41,383][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022960] [Batch 00739/00823] [00:08:57/00:01:01, 0.727s/it]: train_loss_raw=0.7871, running_loss=0.8944, LR=0.000100
[2025-08-26 13:27:47,044][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022968] [Batch 00747/00823] [00:09:02/00:00:55, 0.727s/it]: train_loss_raw=0.9104, running_loss=0.8967, LR=0.000100
[2025-08-26 13:27:52,915][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022976] [Batch 00755/00823] [00:09:08/00:00:49, 0.727s/it]: train_loss_raw=0.7860, running_loss=0.8970, LR=0.000100
[2025-08-26 13:27:58,691][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022984] [Batch 00763/00823] [00:09:14/00:00:43, 0.727s/it]: train_loss_raw=0.8954, running_loss=0.8952, LR=0.000100
[2025-08-26 13:28:04,442][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 022992] [Batch 00771/00823] [00:09:20/00:00:37, 0.727s/it]: train_loss_raw=1.0105, running_loss=0.8965, LR=0.000100
[2025-08-26 13:28:10,358][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023000] [Batch 00779/00823] [00:09:26/00:00:31, 0.727s/it]: train_loss_raw=0.8646, running_loss=0.8949, LR=0.000100
[2025-08-26 13:28:16,244][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023008] [Batch 00787/00823] [00:09:32/00:00:26, 0.727s/it]: train_loss_raw=0.9183, running_loss=0.8946, LR=0.000100
[2025-08-26 13:28:21,961][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023016] [Batch 00795/00823] [00:09:37/00:00:20, 0.727s/it]: train_loss_raw=0.9075, running_loss=0.8951, LR=0.000100
[2025-08-26 13:28:27,667][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023024] [Batch 00803/00823] [00:09:43/00:00:14, 0.727s/it]: train_loss_raw=0.9173, running_loss=0.8949, LR=0.000100
[2025-08-26 13:28:33,391][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023032] [Batch 00811/00823] [00:09:49/00:00:08, 0.727s/it]: train_loss_raw=0.9232, running_loss=0.8931, LR=0.000100
[2025-08-26 13:28:39,182][__main__][INFO] - [TRAIN] [Epoch 27/29 Step 023040] [Batch 00819/00823] [00:09:55/00:00:02, 0.727s/it]: train_loss_raw=0.9715, running_loss=0.8936, LR=0.000100
[2025-08-26 13:28:47,671][__main__][INFO] - [VALIDATION] [Epoch 27/29] Starting validation.
[2025-08-26 13:28:58,941][__main__][INFO] - [VALIDATION] [Epoch 27/29 Step 023045] [Batch 00007/00013] [00:00:11/00:00:07, 1.409s/it]
[2025-08-26 13:29:06,083][__main__][INFO] - [VALIDATION] [Epoch 27/29] train_loss=0.89181, valid_loss=1.41497
[2025-08-26 13:29:06,083][__main__][INFO] - [VALIDATION] [Epoch 27/29] Metrics:
[2025-08-26 13:29:06,084][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_er      0.557
[2025-08-26 13:29:06,084][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_prec    0.083
[2025-08-26 13:29:06,084][__main__][INFO] - [VALIDATION] [Epoch 27/29] - aa_recall  0.085
[2025-08-26 13:29:06,084][__main__][INFO] - [VALIDATION] [Epoch 27/29] - pep_recall 0.040
[2025-08-26 13:29:06,086][__main__][INFO] - [TRAIN] [Epoch 27/29] Epoch complete, total time 04:56:29, remaining time 00:21:10, 00:10:35 per epoch
[2025-08-26 13:29:08,541][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023048] [Batch 00004/00823] [00:00:02/00:07:43, 0.566s/it]: train_loss_raw=0.7991, running_loss=0.8281, LR=0.000100
[2025-08-26 13:29:14,407][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023056] [Batch 00012/00823] [00:00:08/00:09:09, 0.677s/it]: train_loss_raw=0.8282, running_loss=0.8280, LR=0.000100
[2025-08-26 13:29:20,278][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023064] [Batch 00020/00823] [00:00:13/00:09:22, 0.700s/it]: train_loss_raw=0.8471, running_loss=0.8277, LR=0.000100
[2025-08-26 13:29:26,203][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023072] [Batch 00028/00823] [00:00:19/00:09:25, 0.712s/it]: train_loss_raw=0.7619, running_loss=0.8273, LR=0.000100
[2025-08-26 13:29:31,827][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023080] [Batch 00036/00823] [00:00:25/00:09:18, 0.710s/it]: train_loss_raw=0.8094, running_loss=0.8250, LR=0.000100
[2025-08-26 13:29:37,791][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023088] [Batch 00044/00823] [00:00:31/00:09:17, 0.716s/it]: train_loss_raw=0.8013, running_loss=0.8251, LR=0.000100
[2025-08-26 13:29:43,675][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023096] [Batch 00052/00823] [00:00:37/00:09:14, 0.719s/it]: train_loss_raw=0.7956, running_loss=0.8254, LR=0.000100
[2025-08-26 13:29:49,536][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023104] [Batch 00060/00823] [00:00:43/00:09:10, 0.721s/it]: train_loss_raw=0.8669, running_loss=0.8273, LR=0.000100
[2025-08-26 13:29:55,447][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023112] [Batch 00068/00823] [00:00:49/00:09:05, 0.723s/it]: train_loss_raw=0.7548, running_loss=0.8274, LR=0.000100
[2025-08-26 13:30:01,293][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023120] [Batch 00076/00823] [00:00:55/00:09:00, 0.724s/it]: train_loss_raw=0.6964, running_loss=0.8244, LR=0.000100
[2025-08-26 13:30:06,965][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023128] [Batch 00084/00823] [00:01:00/00:08:53, 0.722s/it]: train_loss_raw=0.7749, running_loss=0.8258, LR=0.000100
[2025-08-26 13:30:12,636][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023136] [Batch 00092/00823] [00:01:06/00:08:47, 0.721s/it]: train_loss_raw=0.8694, running_loss=0.8303, LR=0.000100
[2025-08-26 13:30:18,401][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023144] [Batch 00100/00823] [00:01:12/00:08:41, 0.721s/it]: train_loss_raw=0.7889, running_loss=0.8320, LR=0.000100
[2025-08-26 13:30:24,171][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023152] [Batch 00108/00823] [00:01:17/00:08:35, 0.721s/it]: train_loss_raw=0.6677, running_loss=0.8307, LR=0.000100
[2025-08-26 13:30:29,927][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023160] [Batch 00116/00823] [00:01:23/00:08:29, 0.721s/it]: train_loss_raw=0.7860, running_loss=0.8298, LR=0.000100
[2025-08-26 13:30:35,762][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023168] [Batch 00124/00823] [00:01:29/00:08:24, 0.722s/it]: train_loss_raw=0.9227, running_loss=0.8303, LR=0.000100
[2025-08-26 13:30:41,664][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023176] [Batch 00132/00823] [00:01:35/00:08:19, 0.723s/it]: train_loss_raw=0.8948, running_loss=0.8308, LR=0.000100
[2025-08-26 13:30:47,640][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023184] [Batch 00140/00823] [00:01:41/00:08:14, 0.724s/it]: train_loss_raw=0.8050, running_loss=0.8318, LR=0.000100
[2025-08-26 13:30:53,094][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023192] [Batch 00148/00823] [00:01:46/00:08:07, 0.722s/it]: train_loss_raw=0.7141, running_loss=0.8312, LR=0.000100
[2025-08-26 13:30:58,778][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023200] [Batch 00156/00823] [00:01:52/00:08:01, 0.721s/it]: train_loss_raw=0.8608, running_loss=0.8300, LR=0.000100
[2025-08-26 13:31:04,593][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023208] [Batch 00164/00823] [00:01:58/00:07:55, 0.721s/it]: train_loss_raw=0.8060, running_loss=0.8308, LR=0.000100
[2025-08-26 13:31:10,461][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023216] [Batch 00172/00823] [00:02:04/00:07:50, 0.722s/it]: train_loss_raw=0.9245, running_loss=0.8317, LR=0.000100
[2025-08-26 13:31:16,395][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023224] [Batch 00180/00823] [00:02:10/00:07:44, 0.723s/it]: train_loss_raw=0.8946, running_loss=0.8339, LR=0.000100
[2025-08-26 13:31:22,210][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023232] [Batch 00188/00823] [00:02:15/00:07:39, 0.723s/it]: train_loss_raw=0.8944, running_loss=0.8351, LR=0.000100
[2025-08-26 13:31:27,972][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023240] [Batch 00196/00823] [00:02:21/00:07:33, 0.723s/it]: train_loss_raw=0.8572, running_loss=0.8373, LR=0.000100
[2025-08-26 13:31:33,825][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023248] [Batch 00204/00823] [00:02:27/00:07:27, 0.723s/it]: train_loss_raw=0.8518, running_loss=0.8383, LR=0.000100
[2025-08-26 13:31:39,599][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023256] [Batch 00212/00823] [00:02:33/00:07:21, 0.723s/it]: train_loss_raw=0.8087, running_loss=0.8363, LR=0.000100
[2025-08-26 13:31:45,480][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023264] [Batch 00220/00823] [00:02:39/00:07:16, 0.724s/it]: train_loss_raw=0.8753, running_loss=0.8379, LR=0.000100
[2025-08-26 13:31:51,246][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023272] [Batch 00228/00823] [00:02:44/00:07:10, 0.724s/it]: train_loss_raw=0.7856, running_loss=0.8375, LR=0.000100
[2025-08-26 13:31:57,044][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023280] [Batch 00236/00823] [00:02:50/00:07:04, 0.724s/it]: train_loss_raw=0.8465, running_loss=0.8344, LR=0.000100
[2025-08-26 13:32:02,779][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023288] [Batch 00244/00823] [00:02:56/00:06:58, 0.723s/it]: train_loss_raw=0.7714, running_loss=0.8332, LR=0.000100
[2025-08-26 13:32:08,560][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023296] [Batch 00252/00823] [00:03:02/00:06:53, 0.723s/it]: train_loss_raw=0.8419, running_loss=0.8354, LR=0.000100
[2025-08-26 13:32:14,238][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023304] [Batch 00260/00823] [00:03:07/00:06:47, 0.723s/it]: train_loss_raw=0.8073, running_loss=0.8360, LR=0.000100
[2025-08-26 13:32:19,939][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023312] [Batch 00268/00823] [00:03:13/00:06:41, 0.723s/it]: train_loss_raw=0.9120, running_loss=0.8392, LR=0.000100
[2025-08-26 13:32:25,716][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023320] [Batch 00276/00823] [00:03:19/00:06:35, 0.723s/it]: train_loss_raw=0.7433, running_loss=0.8375, LR=0.000100
[2025-08-26 13:32:31,609][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023328] [Batch 00284/00823] [00:03:25/00:06:29, 0.723s/it]: train_loss_raw=0.8626, running_loss=0.8385, LR=0.000100
[2025-08-26 13:32:37,625][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023336] [Batch 00292/00823] [00:03:31/00:06:24, 0.724s/it]: train_loss_raw=0.8013, running_loss=0.8383, LR=0.000100
[2025-08-26 13:32:43,593][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023344] [Batch 00300/00823] [00:03:37/00:06:18, 0.724s/it]: train_loss_raw=0.7853, running_loss=0.8398, LR=0.000100
[2025-08-26 13:32:49,600][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023352] [Batch 00308/00823] [00:03:43/00:06:13, 0.725s/it]: train_loss_raw=0.9777, running_loss=0.8401, LR=0.000100
[2025-08-26 13:32:55,515][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023360] [Batch 00316/00823] [00:03:49/00:06:07, 0.725s/it]: train_loss_raw=0.9343, running_loss=0.8416, LR=0.000100
[2025-08-26 13:33:01,282][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023368] [Batch 00324/00823] [00:03:55/00:06:01, 0.725s/it]: train_loss_raw=0.9154, running_loss=0.8410, LR=0.000100
[2025-08-26 13:33:07,090][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023376] [Batch 00332/00823] [00:04:00/00:05:56, 0.725s/it]: train_loss_raw=0.7438, running_loss=0.8387, LR=0.000100
[2025-08-26 13:33:12,924][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023384] [Batch 00340/00823] [00:04:06/00:05:50, 0.725s/it]: train_loss_raw=0.7632, running_loss=0.8383, LR=0.000100
[2025-08-26 13:33:18,656][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023392] [Batch 00348/00823] [00:04:12/00:05:44, 0.725s/it]: train_loss_raw=0.9836, running_loss=0.8402, LR=0.000100
[2025-08-26 13:33:24,385][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023400] [Batch 00356/00823] [00:04:18/00:05:38, 0.725s/it]: train_loss_raw=0.8847, running_loss=0.8421, LR=0.000100
[2025-08-26 13:33:30,218][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023408] [Batch 00364/00823] [00:04:23/00:05:32, 0.725s/it]: train_loss_raw=0.8636, running_loss=0.8421, LR=0.000100
[2025-08-26 13:33:35,944][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023416] [Batch 00372/00823] [00:04:29/00:05:26, 0.725s/it]: train_loss_raw=0.8377, running_loss=0.8418, LR=0.000100
[2025-08-26 13:33:41,860][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023424] [Batch 00380/00823] [00:04:35/00:05:21, 0.725s/it]: train_loss_raw=0.7926, running_loss=0.8418, LR=0.000100
[2025-08-26 13:33:47,815][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023432] [Batch 00388/00823] [00:04:41/00:05:15, 0.726s/it]: train_loss_raw=0.7801, running_loss=0.8414, LR=0.000100
[2025-08-26 13:33:53,509][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023440] [Batch 00396/00823] [00:04:47/00:05:09, 0.725s/it]: train_loss_raw=0.8917, running_loss=0.8421, LR=0.000100
[2025-08-26 13:33:59,252][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023448] [Batch 00404/00823] [00:04:52/00:05:03, 0.725s/it]: train_loss_raw=0.8038, running_loss=0.8413, LR=0.000100
[2025-08-26 13:34:05,138][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023456] [Batch 00412/00823] [00:04:58/00:04:58, 0.725s/it]: train_loss_raw=0.9023, running_loss=0.8427, LR=0.000100
[2025-08-26 13:34:10,977][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023464] [Batch 00420/00823] [00:05:04/00:04:52, 0.725s/it]: train_loss_raw=0.8490, running_loss=0.8427, LR=0.000100
[2025-08-26 13:34:16,710][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023472] [Batch 00428/00823] [00:05:10/00:04:46, 0.725s/it]: train_loss_raw=0.8701, running_loss=0.8461, LR=0.000100
[2025-08-26 13:34:22,539][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023480] [Batch 00436/00823] [00:05:16/00:04:40, 0.725s/it]: train_loss_raw=0.7943, running_loss=0.8476, LR=0.000100
[2025-08-26 13:34:28,467][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023488] [Batch 00444/00823] [00:05:22/00:04:35, 0.726s/it]: train_loss_raw=0.7333, running_loss=0.8473, LR=0.000100
[2025-08-26 13:34:34,363][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023496] [Batch 00452/00823] [00:05:28/00:04:29, 0.726s/it]: train_loss_raw=0.9058, running_loss=0.8453, LR=0.000100
[2025-08-26 13:34:40,246][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023504] [Batch 00460/00823] [00:05:33/00:04:23, 0.726s/it]: train_loss_raw=0.8108, running_loss=0.8429, LR=0.000100
[2025-08-26 13:34:46,305][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023512] [Batch 00468/00823] [00:05:40/00:04:17, 0.727s/it]: train_loss_raw=0.7969, running_loss=0.8387, LR=0.000100
[2025-08-26 13:34:52,233][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023520] [Batch 00476/00823] [00:05:45/00:04:12, 0.727s/it]: train_loss_raw=0.8001, running_loss=0.8383, LR=0.000100
[2025-08-26 13:34:58,029][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023528] [Batch 00484/00823] [00:05:51/00:04:06, 0.727s/it]: train_loss_raw=0.8450, running_loss=0.8400, LR=0.000100
[2025-08-26 13:35:03,965][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023536] [Batch 00492/00823] [00:05:57/00:04:00, 0.727s/it]: train_loss_raw=0.7995, running_loss=0.8405, LR=0.000100
[2025-08-26 13:35:09,676][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023544] [Batch 00500/00823] [00:06:03/00:03:54, 0.727s/it]: train_loss_raw=0.8978, running_loss=0.8397, LR=0.000100
[2025-08-26 13:35:15,474][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023552] [Batch 00508/00823] [00:06:09/00:03:48, 0.727s/it]: train_loss_raw=0.8230, running_loss=0.8380, LR=0.000100
[2025-08-26 13:35:21,232][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023560] [Batch 00516/00823] [00:06:14/00:03:43, 0.727s/it]: train_loss_raw=0.8182, running_loss=0.8359, LR=0.000100
[2025-08-26 13:35:27,276][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023568] [Batch 00524/00823] [00:06:20/00:03:37, 0.727s/it]: train_loss_raw=0.8469, running_loss=0.8379, LR=0.000100
[2025-08-26 13:35:33,348][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023576] [Batch 00532/00823] [00:06:27/00:03:31, 0.728s/it]: train_loss_raw=0.8134, running_loss=0.8390, LR=0.000100
[2025-08-26 13:35:39,061][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023584] [Batch 00540/00823] [00:06:32/00:03:25, 0.727s/it]: train_loss_raw=0.7165, running_loss=0.8366, LR=0.000100
[2025-08-26 13:35:44,962][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023592] [Batch 00548/00823] [00:06:38/00:03:20, 0.728s/it]: train_loss_raw=0.8171, running_loss=0.8372, LR=0.000100
[2025-08-26 13:35:51,021][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023600] [Batch 00556/00823] [00:06:44/00:03:14, 0.728s/it]: train_loss_raw=0.8150, running_loss=0.8392, LR=0.000100
[2025-08-26 13:35:56,990][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023608] [Batch 00564/00823] [00:06:50/00:03:08, 0.728s/it]: train_loss_raw=0.9841, running_loss=0.8408, LR=0.000100
[2025-08-26 13:36:02,722][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023616] [Batch 00572/00823] [00:06:56/00:03:02, 0.728s/it]: train_loss_raw=0.9532, running_loss=0.8407, LR=0.000100
[2025-08-26 13:36:08,631][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023624] [Batch 00580/00823] [00:07:02/00:02:56, 0.728s/it]: train_loss_raw=0.8660, running_loss=0.8384, LR=0.000100
[2025-08-26 13:36:14,578][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023632] [Batch 00588/00823] [00:07:08/00:02:51, 0.728s/it]: train_loss_raw=0.8049, running_loss=0.8382, LR=0.000100
[2025-08-26 13:36:20,742][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023640] [Batch 00596/00823] [00:07:14/00:02:45, 0.729s/it]: train_loss_raw=0.8054, running_loss=0.8374, LR=0.000100
[2025-08-26 13:36:26,596][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023648] [Batch 00604/00823] [00:07:20/00:02:39, 0.729s/it]: train_loss_raw=0.7985, running_loss=0.8361, LR=0.000100
[2025-08-26 13:36:32,627][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023656] [Batch 00612/00823] [00:07:26/00:02:33, 0.729s/it]: train_loss_raw=0.8208, running_loss=0.8356, LR=0.000100
[2025-08-26 13:36:38,665][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023664] [Batch 00620/00823] [00:07:32/00:02:28, 0.730s/it]: train_loss_raw=0.8750, running_loss=0.8377, LR=0.000100
[2025-08-26 13:36:44,750][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023672] [Batch 00628/00823] [00:07:38/00:02:22, 0.730s/it]: train_loss_raw=0.8573, running_loss=0.8402, LR=0.000100
[2025-08-26 13:36:50,746][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023680] [Batch 00636/00823] [00:07:44/00:02:16, 0.730s/it]: train_loss_raw=0.7934, running_loss=0.8383, LR=0.000100
[2025-08-26 13:36:56,712][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023688] [Batch 00644/00823] [00:07:50/00:02:10, 0.730s/it]: train_loss_raw=0.8397, running_loss=0.8382, LR=0.000100
[2025-08-26 13:37:02,831][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023696] [Batch 00652/00823] [00:07:56/00:02:04, 0.731s/it]: train_loss_raw=0.8933, running_loss=0.8416, LR=0.000100
[2025-08-26 13:37:08,814][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023704] [Batch 00660/00823] [00:08:02/00:01:59, 0.731s/it]: train_loss_raw=0.7491, running_loss=0.8402, LR=0.000100
[2025-08-26 13:37:14,724][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023712] [Batch 00668/00823] [00:08:08/00:01:53, 0.731s/it]: train_loss_raw=0.8641, running_loss=0.8408, LR=0.000100
[2025-08-26 13:37:20,735][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023720] [Batch 00676/00823] [00:08:14/00:01:47, 0.731s/it]: train_loss_raw=0.8040, running_loss=0.8410, LR=0.000100
[2025-08-26 13:37:26,636][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023728] [Batch 00684/00823] [00:08:20/00:01:41, 0.732s/it]: train_loss_raw=0.7854, running_loss=0.8433, LR=0.000100
[2025-08-26 13:37:32,356][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023736] [Batch 00692/00823] [00:08:26/00:01:35, 0.731s/it]: train_loss_raw=0.8532, running_loss=0.8432, LR=0.000100
[2025-08-26 13:37:38,229][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023744] [Batch 00700/00823] [00:08:31/00:01:29, 0.731s/it]: train_loss_raw=0.8016, running_loss=0.8412, LR=0.000100
[2025-08-26 13:37:44,194][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023752] [Batch 00708/00823] [00:08:37/00:01:24, 0.732s/it]: train_loss_raw=0.8818, running_loss=0.8421, LR=0.000100
[2025-08-26 13:37:50,156][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023760] [Batch 00716/00823] [00:08:43/00:01:18, 0.732s/it]: train_loss_raw=0.8908, running_loss=0.8444, LR=0.000100
[2025-08-26 13:37:56,021][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023768] [Batch 00724/00823] [00:08:49/00:01:12, 0.732s/it]: train_loss_raw=0.8434, running_loss=0.8453, LR=0.000100
[2025-08-26 13:38:01,928][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023776] [Batch 00732/00823] [00:08:55/00:01:06, 0.732s/it]: train_loss_raw=0.9121, running_loss=0.8467, LR=0.000100
[2025-08-26 13:38:07,777][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023784] [Batch 00740/00823] [00:09:01/00:01:00, 0.732s/it]: train_loss_raw=0.7910, running_loss=0.8451, LR=0.000100
[2025-08-26 13:38:13,556][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023792] [Batch 00748/00823] [00:09:07/00:00:54, 0.732s/it]: train_loss_raw=0.7913, running_loss=0.8455, LR=0.000100
[2025-08-26 13:38:19,405][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023800] [Batch 00756/00823] [00:09:13/00:00:49, 0.732s/it]: train_loss_raw=0.7465, running_loss=0.8424, LR=0.000100
[2025-08-26 13:38:25,265][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023808] [Batch 00764/00823] [00:09:18/00:00:43, 0.732s/it]: train_loss_raw=0.8834, running_loss=0.8412, LR=0.000100
[2025-08-26 13:38:31,080][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023816] [Batch 00772/00823] [00:09:24/00:00:37, 0.732s/it]: train_loss_raw=0.8441, running_loss=0.8415, LR=0.000100
[2025-08-26 13:38:36,896][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023824] [Batch 00780/00823] [00:09:30/00:00:31, 0.732s/it]: train_loss_raw=0.7760, running_loss=0.8408, LR=0.000100
[2025-08-26 13:38:42,796][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023832] [Batch 00788/00823] [00:09:36/00:00:25, 0.732s/it]: train_loss_raw=0.8926, running_loss=0.8418, LR=0.000100
[2025-08-26 13:38:48,636][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023840] [Batch 00796/00823] [00:09:42/00:00:19, 0.732s/it]: train_loss_raw=0.8261, running_loss=0.8436, LR=0.000100
[2025-08-26 13:38:54,422][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023848] [Batch 00804/00823] [00:09:48/00:00:13, 0.732s/it]: train_loss_raw=0.8679, running_loss=0.8429, LR=0.000100
[2025-08-26 13:39:00,248][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023856] [Batch 00812/00823] [00:09:53/00:00:08, 0.731s/it]: train_loss_raw=0.8733, running_loss=0.8422, LR=0.000100
[2025-08-26 13:39:06,018][__main__][INFO] - [TRAIN] [Epoch 28/29 Step 023864] [Batch 00820/00823] [00:09:59/00:00:02, 0.731s/it]: train_loss_raw=0.8658, running_loss=0.8439, LR=0.000100
[2025-08-26 13:39:08,399][__main__][INFO] - [VALIDATION] [Epoch 28/29] Starting validation.
[2025-08-26 13:39:19,020][__main__][INFO] - [VALIDATION] [Epoch 28/29 Step 023868] [Batch 00007/00013] [00:00:10/00:00:06, 1.328s/it]
[2025-08-26 13:39:26,144][__main__][INFO] - [VALIDATION] [Epoch 28/29] train_loss=0.84358, valid_loss=1.42942
[2025-08-26 13:39:26,144][__main__][INFO] - [VALIDATION] [Epoch 28/29] Metrics:
[2025-08-26 13:39:26,145][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_er      0.549
[2025-08-26 13:39:26,145][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_prec    0.090
[2025-08-26 13:39:26,145][__main__][INFO] - [VALIDATION] [Epoch 28/29] - aa_recall  0.092
[2025-08-26 13:39:26,145][__main__][INFO] - [VALIDATION] [Epoch 28/29] - pep_recall 0.046
[2025-08-26 13:39:26,146][__main__][INFO] - [TRAIN] [Epoch 28/29] Epoch complete, total time 05:06:49, remaining time 00:10:34, 00:10:34 per epoch
[2025-08-26 13:39:30,628][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023872] [Batch 00005/00823] [00:00:03/00:09:05, 0.667s/it]: train_loss_raw=0.8918, running_loss=0.8523, LR=0.000100
[2025-08-26 13:39:36,630][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023880] [Batch 00013/00823] [00:00:09/00:09:41, 0.718s/it]: train_loss_raw=0.8506, running_loss=0.8495, LR=0.000100
[2025-08-26 13:39:42,433][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023888] [Batch 00021/00823] [00:00:15/00:09:38, 0.721s/it]: train_loss_raw=0.7938, running_loss=0.8461, LR=0.000100
[2025-08-26 13:39:48,251][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023896] [Batch 00029/00823] [00:00:20/00:09:33, 0.723s/it]: train_loss_raw=0.7667, running_loss=0.8439, LR=0.000100
[2025-08-26 13:39:54,207][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023904] [Batch 00037/00823] [00:00:26/00:09:31, 0.727s/it]: train_loss_raw=0.7642, running_loss=0.8431, LR=0.000100
[2025-08-26 13:40:00,130][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023912] [Batch 00045/00823] [00:00:32/00:09:27, 0.730s/it]: train_loss_raw=0.8893, running_loss=0.8422, LR=0.000100
[2025-08-26 13:40:06,054][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023920] [Batch 00053/00823] [00:00:38/00:09:23, 0.731s/it]: train_loss_raw=0.8363, running_loss=0.8404, LR=0.000100
[2025-08-26 13:40:11,814][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023928] [Batch 00061/00823] [00:00:44/00:09:16, 0.730s/it]: train_loss_raw=0.8204, running_loss=0.8406, LR=0.000100
[2025-08-26 13:40:17,687][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023936] [Batch 00069/00823] [00:00:50/00:09:10, 0.730s/it]: train_loss_raw=0.8218, running_loss=0.8396, LR=0.000100
[2025-08-26 13:40:23,672][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023944] [Batch 00077/00823] [00:00:56/00:09:06, 0.732s/it]: train_loss_raw=0.8716, running_loss=0.8416, LR=0.000100
[2025-08-26 13:40:29,462][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023952] [Batch 00085/00823] [00:01:02/00:08:59, 0.731s/it]: train_loss_raw=0.8583, running_loss=0.8427, LR=0.000100
[2025-08-26 13:40:35,318][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023960] [Batch 00093/00823] [00:01:08/00:08:53, 0.731s/it]: train_loss_raw=0.9299, running_loss=0.8437, LR=0.000100
[2025-08-26 13:40:41,121][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023968] [Batch 00101/00823] [00:01:13/00:08:47, 0.731s/it]: train_loss_raw=0.8984, running_loss=0.8463, LR=0.000100
[2025-08-26 13:40:46,787][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023976] [Batch 00109/00823] [00:01:19/00:08:40, 0.729s/it]: train_loss_raw=0.8213, running_loss=0.8460, LR=0.000100
[2025-08-26 13:40:52,596][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023984] [Batch 00117/00823] [00:01:25/00:08:34, 0.729s/it]: train_loss_raw=0.7831, running_loss=0.8440, LR=0.000100
[2025-08-26 13:40:58,381][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 023992] [Batch 00125/00823] [00:01:31/00:08:28, 0.729s/it]: train_loss_raw=0.9032, running_loss=0.8446, LR=0.000100
[2025-08-26 13:41:04,186][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024000] [Batch 00133/00823] [00:01:36/00:08:22, 0.729s/it]: train_loss_raw=0.8068, running_loss=0.8432, LR=0.000100
[2025-08-26 13:41:14,141][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024008] [Batch 00141/00823] [00:01:46/00:08:36, 0.758s/it]: train_loss_raw=0.9181, running_loss=0.8417, LR=0.000100
[2025-08-26 13:41:19,952][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024016] [Batch 00149/00823] [00:01:52/00:08:29, 0.756s/it]: train_loss_raw=0.7740, running_loss=0.8414, LR=0.000100
[2025-08-26 13:41:25,674][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024024] [Batch 00157/00823] [00:01:58/00:08:22, 0.754s/it]: train_loss_raw=0.8397, running_loss=0.8398, LR=0.000100
[2025-08-26 13:41:31,524][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024032] [Batch 00165/00823] [00:02:04/00:08:15, 0.753s/it]: train_loss_raw=0.7987, running_loss=0.8384, LR=0.000100
[2025-08-26 13:41:37,180][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024040] [Batch 00173/00823] [00:02:09/00:08:08, 0.751s/it]: train_loss_raw=0.8514, running_loss=0.8382, LR=0.000100
[2025-08-26 13:41:43,102][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024048] [Batch 00181/00823] [00:02:15/00:08:01, 0.750s/it]: train_loss_raw=0.8802, running_loss=0.8381, LR=0.000100
[2025-08-26 13:41:48,960][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024056] [Batch 00189/00823] [00:02:21/00:07:55, 0.750s/it]: train_loss_raw=0.8608, running_loss=0.8391, LR=0.000100
[2025-08-26 13:41:54,827][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024064] [Batch 00197/00823] [00:02:27/00:07:48, 0.749s/it]: train_loss_raw=0.9273, running_loss=0.8407, LR=0.000100
[2025-08-26 13:42:00,520][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024072] [Batch 00205/00823] [00:02:33/00:07:41, 0.747s/it]: train_loss_raw=0.8821, running_loss=0.8411, LR=0.000100
[2025-08-26 13:42:06,114][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024080] [Batch 00213/00823] [00:02:38/00:07:34, 0.746s/it]: train_loss_raw=0.8146, running_loss=0.8395, LR=0.000100
[2025-08-26 13:42:11,905][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024088] [Batch 00221/00823] [00:02:44/00:07:28, 0.745s/it]: train_loss_raw=0.8277, running_loss=0.8405, LR=0.000100
[2025-08-26 13:42:17,660][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024096] [Batch 00229/00823] [00:02:50/00:07:21, 0.744s/it]: train_loss_raw=0.8550, running_loss=0.8404, LR=0.000100
[2025-08-26 13:42:23,433][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024104] [Batch 00237/00823] [00:02:56/00:07:15, 0.743s/it]: train_loss_raw=0.7651, running_loss=0.8420, LR=0.000100
[2025-08-26 13:42:29,180][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024112] [Batch 00245/00823] [00:03:01/00:07:09, 0.742s/it]: train_loss_raw=0.7938, running_loss=0.8389, LR=0.000100
[2025-08-26 13:42:34,986][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024120] [Batch 00253/00823] [00:03:07/00:07:02, 0.742s/it]: train_loss_raw=0.8653, running_loss=0.8375, LR=0.000100
[2025-08-26 13:42:40,970][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024128] [Batch 00261/00823] [00:03:13/00:06:57, 0.742s/it]: train_loss_raw=0.9897, running_loss=0.8380, LR=0.000100
[2025-08-26 13:42:46,739][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024136] [Batch 00269/00823] [00:03:19/00:06:50, 0.741s/it]: train_loss_raw=0.7982, running_loss=0.8367, LR=0.000100
[2025-08-26 13:42:52,612][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024144] [Batch 00277/00823] [00:03:25/00:06:44, 0.741s/it]: train_loss_raw=0.8348, running_loss=0.8383, LR=0.000100
[2025-08-26 13:42:58,596][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024152] [Batch 00285/00823] [00:03:31/00:06:38, 0.741s/it]: train_loss_raw=0.9027, running_loss=0.8403, LR=0.000100
[2025-08-26 13:43:04,433][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024160] [Batch 00293/00823] [00:03:37/00:06:32, 0.741s/it]: train_loss_raw=0.8245, running_loss=0.8402, LR=0.000100
[2025-08-26 13:43:10,383][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024168] [Batch 00301/00823] [00:03:43/00:06:26, 0.741s/it]: train_loss_raw=0.8039, running_loss=0.8428, LR=0.000100
[2025-08-26 13:43:16,275][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024176] [Batch 00309/00823] [00:03:48/00:06:20, 0.741s/it]: train_loss_raw=1.0100, running_loss=0.8437, LR=0.000100
[2025-08-26 13:43:22,026][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024184] [Batch 00317/00823] [00:03:54/00:06:14, 0.740s/it]: train_loss_raw=0.7768, running_loss=0.8422, LR=0.000100
[2025-08-26 13:43:27,954][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024192] [Batch 00325/00823] [00:04:00/00:06:08, 0.740s/it]: train_loss_raw=0.9375, running_loss=0.8421, LR=0.000100
[2025-08-26 13:43:33,707][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024200] [Batch 00333/00823] [00:04:06/00:06:02, 0.740s/it]: train_loss_raw=0.8253, running_loss=0.8404, LR=0.000100
[2025-08-26 13:43:39,574][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024208] [Batch 00341/00823] [00:04:12/00:05:56, 0.740s/it]: train_loss_raw=0.7752, running_loss=0.8380, LR=0.000100
[2025-08-26 13:43:45,472][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024216] [Batch 00349/00823] [00:04:18/00:05:50, 0.740s/it]: train_loss_raw=0.8326, running_loss=0.8374, LR=0.000100
[2025-08-26 13:43:51,163][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024224] [Batch 00357/00823] [00:04:23/00:05:44, 0.739s/it]: train_loss_raw=0.8238, running_loss=0.8388, LR=0.000100
[2025-08-26 13:43:56,799][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024232] [Batch 00365/00823] [00:04:29/00:05:38, 0.738s/it]: train_loss_raw=0.8205, running_loss=0.8367, LR=0.000100
[2025-08-26 13:44:02,604][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024240] [Batch 00373/00823] [00:04:35/00:05:32, 0.738s/it]: train_loss_raw=0.8213, running_loss=0.8356, LR=0.000100
[2025-08-26 13:44:08,283][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024248] [Batch 00381/00823] [00:04:40/00:05:25, 0.738s/it]: train_loss_raw=0.8303, running_loss=0.8355, LR=0.000100
[2025-08-26 13:44:14,009][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024256] [Batch 00389/00823] [00:04:46/00:05:19, 0.737s/it]: train_loss_raw=0.9084, running_loss=0.8372, LR=0.000100
[2025-08-26 13:44:20,192][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024264] [Batch 00397/00823] [00:04:52/00:05:14, 0.738s/it]: train_loss_raw=0.8859, running_loss=0.8381, LR=0.000100
[2025-08-26 13:44:25,923][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024272] [Batch 00405/00823] [00:04:58/00:05:08, 0.737s/it]: train_loss_raw=0.8563, running_loss=0.8399, LR=0.000100
[2025-08-26 13:44:31,733][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024280] [Batch 00413/00823] [00:05:04/00:05:02, 0.737s/it]: train_loss_raw=0.8542, running_loss=0.8400, LR=0.000100
[2025-08-26 13:44:37,542][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024288] [Batch 00421/00823] [00:05:10/00:04:56, 0.737s/it]: train_loss_raw=0.8416, running_loss=0.8368, LR=0.000100
[2025-08-26 13:44:43,481][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024296] [Batch 00429/00823] [00:05:16/00:04:50, 0.737s/it]: train_loss_raw=0.7584, running_loss=0.8351, LR=0.000100
[2025-08-26 13:44:49,441][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024304] [Batch 00437/00823] [00:05:22/00:04:44, 0.737s/it]: train_loss_raw=0.7752, running_loss=0.8355, LR=0.000100
[2025-08-26 13:44:55,293][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024312] [Batch 00445/00823] [00:05:27/00:04:38, 0.737s/it]: train_loss_raw=0.8463, running_loss=0.8346, LR=0.000100
[2025-08-26 13:45:01,271][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024320] [Batch 00453/00823] [00:05:33/00:04:32, 0.737s/it]: train_loss_raw=0.8151, running_loss=0.8360, LR=0.000100
[2025-08-26 13:45:07,039][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024328] [Batch 00461/00823] [00:05:39/00:04:26, 0.737s/it]: train_loss_raw=0.8720, running_loss=0.8360, LR=0.000100
[2025-08-26 13:45:12,853][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024336] [Batch 00469/00823] [00:05:45/00:04:20, 0.737s/it]: train_loss_raw=0.7972, running_loss=0.8372, LR=0.000100
[2025-08-26 13:45:18,859][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024344] [Batch 00477/00823] [00:05:51/00:04:15, 0.737s/it]: train_loss_raw=0.9069, running_loss=0.8352, LR=0.000100
[2025-08-26 13:45:24,651][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024352] [Batch 00485/00823] [00:05:57/00:04:09, 0.737s/it]: train_loss_raw=0.8092, running_loss=0.8346, LR=0.000100
[2025-08-26 13:45:30,535][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024360] [Batch 00493/00823] [00:06:03/00:04:03, 0.737s/it]: train_loss_raw=0.8700, running_loss=0.8357, LR=0.000100
[2025-08-26 13:45:36,418][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024368] [Batch 00501/00823] [00:06:09/00:03:57, 0.737s/it]: train_loss_raw=0.8870, running_loss=0.8385, LR=0.000100
[2025-08-26 13:45:42,091][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024376] [Batch 00509/00823] [00:06:14/00:03:51, 0.736s/it]: train_loss_raw=0.8842, running_loss=0.8388, LR=0.000100
[2025-08-26 13:45:47,872][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024384] [Batch 00517/00823] [00:06:20/00:03:45, 0.736s/it]: train_loss_raw=0.9288, running_loss=0.8376, LR=0.000100
[2025-08-26 13:45:53,799][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024392] [Batch 00525/00823] [00:06:26/00:03:39, 0.736s/it]: train_loss_raw=0.8762, running_loss=0.8377, LR=0.000100
[2025-08-26 13:45:59,630][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024400] [Batch 00533/00823] [00:06:32/00:03:33, 0.736s/it]: train_loss_raw=0.9422, running_loss=0.8390, LR=0.000100
[2025-08-26 13:46:05,359][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024408] [Batch 00541/00823] [00:06:38/00:03:27, 0.736s/it]: train_loss_raw=0.8459, running_loss=0.8392, LR=0.000100
[2025-08-26 13:46:11,161][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024416] [Batch 00549/00823] [00:06:43/00:03:21, 0.736s/it]: train_loss_raw=0.7860, running_loss=0.8390, LR=0.000100
[2025-08-26 13:46:17,253][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024424] [Batch 00557/00823] [00:06:49/00:03:15, 0.736s/it]: train_loss_raw=0.8901, running_loss=0.8388, LR=0.000100
[2025-08-26 13:46:23,019][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024432] [Batch 00565/00823] [00:06:55/00:03:09, 0.736s/it]: train_loss_raw=0.8556, running_loss=0.8407, LR=0.000100
[2025-08-26 13:46:28,939][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024440] [Batch 00573/00823] [00:07:01/00:03:03, 0.736s/it]: train_loss_raw=0.8944, running_loss=0.8390, LR=0.000100
[2025-08-26 13:46:34,731][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024448] [Batch 00581/00823] [00:07:07/00:02:58, 0.736s/it]: train_loss_raw=0.8250, running_loss=0.8402, LR=0.000100
[2025-08-26 13:46:40,738][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024456] [Batch 00589/00823] [00:07:13/00:02:52, 0.736s/it]: train_loss_raw=0.8232, running_loss=0.8404, LR=0.000100
[2025-08-26 13:46:46,626][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024464] [Batch 00597/00823] [00:07:19/00:02:46, 0.736s/it]: train_loss_raw=0.7999, running_loss=0.8417, LR=0.000100
[2025-08-26 13:46:52,469][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024472] [Batch 00605/00823] [00:07:25/00:02:40, 0.736s/it]: train_loss_raw=0.9039, running_loss=0.8407, LR=0.000100
[2025-08-26 13:46:58,043][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024480] [Batch 00613/00823] [00:07:30/00:02:34, 0.735s/it]: train_loss_raw=0.8549, running_loss=0.8405, LR=0.000100
[2025-08-26 13:47:04,098][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024488] [Batch 00621/00823] [00:07:36/00:02:28, 0.736s/it]: train_loss_raw=0.8878, running_loss=0.8420, LR=0.000100
[2025-08-26 13:47:09,979][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024496] [Batch 00629/00823] [00:07:42/00:02:22, 0.736s/it]: train_loss_raw=0.8659, running_loss=0.8409, LR=0.000100
[2025-08-26 13:47:15,811][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024504] [Batch 00637/00823] [00:07:48/00:02:16, 0.736s/it]: train_loss_raw=0.8032, running_loss=0.8393, LR=0.000100
[2025-08-26 13:47:21,652][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024512] [Batch 00645/00823] [00:07:54/00:02:10, 0.735s/it]: train_loss_raw=0.8821, running_loss=0.8403, LR=0.000100
[2025-08-26 13:47:27,566][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024520] [Batch 00653/00823] [00:08:00/00:02:05, 0.735s/it]: train_loss_raw=0.8311, running_loss=0.8390, LR=0.000100
[2025-08-26 13:47:33,488][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024528] [Batch 00661/00823] [00:08:06/00:01:59, 0.736s/it]: train_loss_raw=0.8387, running_loss=0.8393, LR=0.000100
[2025-08-26 13:47:39,379][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024536] [Batch 00669/00823] [00:08:12/00:01:53, 0.736s/it]: train_loss_raw=0.8883, running_loss=0.8377, LR=0.000100
[2025-08-26 13:47:45,246][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024544] [Batch 00677/00823] [00:08:17/00:01:47, 0.736s/it]: train_loss_raw=0.8767, running_loss=0.8395, LR=0.000100
[2025-08-26 13:47:51,478][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024552] [Batch 00685/00823] [00:08:24/00:01:41, 0.736s/it]: train_loss_raw=0.9011, running_loss=0.8421, LR=0.000100
[2025-08-26 13:47:57,355][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024560] [Batch 00693/00823] [00:08:30/00:01:35, 0.736s/it]: train_loss_raw=0.7746, running_loss=0.8408, LR=0.000100
[2025-08-26 13:48:03,220][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024568] [Batch 00701/00823] [00:08:35/00:01:29, 0.736s/it]: train_loss_raw=0.8365, running_loss=0.8388, LR=0.000100
[2025-08-26 13:48:09,019][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024576] [Batch 00709/00823] [00:08:41/00:01:23, 0.736s/it]: train_loss_raw=0.7788, running_loss=0.8371, LR=0.000100
[2025-08-26 13:48:15,010][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024584] [Batch 00717/00823] [00:08:47/00:01:18, 0.736s/it]: train_loss_raw=0.9346, running_loss=0.8379, LR=0.000100
[2025-08-26 13:48:20,958][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024592] [Batch 00725/00823] [00:08:53/00:01:12, 0.736s/it]: train_loss_raw=0.8481, running_loss=0.8394, LR=0.000100
[2025-08-26 13:48:26,614][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024600] [Batch 00733/00823] [00:08:59/00:01:06, 0.736s/it]: train_loss_raw=0.9149, running_loss=0.8389, LR=0.000100
[2025-08-26 13:48:32,361][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024608] [Batch 00741/00823] [00:09:05/00:01:00, 0.736s/it]: train_loss_raw=0.7887, running_loss=0.8395, LR=0.000100
[2025-08-26 13:48:38,238][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024616] [Batch 00749/00823] [00:09:10/00:00:54, 0.736s/it]: train_loss_raw=0.8986, running_loss=0.8392, LR=0.000100
[2025-08-26 13:48:44,056][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024624] [Batch 00757/00823] [00:09:16/00:00:48, 0.735s/it]: train_loss_raw=0.8603, running_loss=0.8389, LR=0.000100
[2025-08-26 13:48:49,831][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024632] [Batch 00765/00823] [00:09:22/00:00:42, 0.735s/it]: train_loss_raw=0.9130, running_loss=0.8391, LR=0.000100
[2025-08-26 13:48:55,755][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024640] [Batch 00773/00823] [00:09:28/00:00:36, 0.735s/it]: train_loss_raw=0.8154, running_loss=0.8381, LR=0.000100
[2025-08-26 13:49:01,671][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024648] [Batch 00781/00823] [00:09:34/00:00:30, 0.735s/it]: train_loss_raw=0.7173, running_loss=0.8360, LR=0.000100
[2025-08-26 13:49:07,817][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024656] [Batch 00789/00823] [00:09:40/00:00:25, 0.736s/it]: train_loss_raw=0.8956, running_loss=0.8373, LR=0.000100
[2025-08-26 13:49:13,706][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024664] [Batch 00797/00823] [00:09:46/00:00:19, 0.736s/it]: train_loss_raw=0.9341, running_loss=0.8378, LR=0.000100
[2025-08-26 13:49:19,591][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024672] [Batch 00805/00823] [00:09:52/00:00:13, 0.736s/it]: train_loss_raw=0.7932, running_loss=0.8387, LR=0.000100
[2025-08-26 13:49:25,349][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024680] [Batch 00813/00823] [00:09:58/00:00:07, 0.736s/it]: train_loss_raw=0.8387, running_loss=0.8381, LR=0.000100
[2025-08-26 13:49:31,009][__main__][INFO] - [TRAIN] [Epoch 29/29 Step 024688] [Batch 00821/00823] [00:10:03/00:00:01, 0.735s/it]: train_loss_raw=0.7380, running_loss=0.8366, LR=0.000100
[2025-08-26 13:49:38,278][__main__][INFO] - [VALIDATION] [Epoch 29/29] Starting validation.
[2025-08-26 13:49:49,297][__main__][INFO] - [VALIDATION] [Epoch 29/29 Step 024691] [Batch 00007/00013] [00:00:11/00:00:06, 1.377s/it]
[2025-08-26 13:49:56,766][__main__][INFO] - [VALIDATION] [Epoch 29/29] train_loss=0.83599, valid_loss=1.45972
[2025-08-26 13:49:56,766][__main__][INFO] - [VALIDATION] [Epoch 29/29] Metrics:
[2025-08-26 13:49:56,766][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_er      0.542
[2025-08-26 13:49:56,766][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_prec    0.089
[2025-08-26 13:49:56,766][__main__][INFO] - [VALIDATION] [Epoch 29/29] - aa_recall  0.090
[2025-08-26 13:49:56,766][__main__][INFO] - [VALIDATION] [Epoch 29/29] - pep_recall 0.040
[2025-08-26 13:49:56,768][__main__][INFO] - [TRAIN] [Epoch 29/29] Epoch complete, total time 05:17:20, remaining time 00:00:00, 00:10:34 per epoch
[2025-08-26 13:49:57,737][__main__][INFO] - InstaNovo training finished.
